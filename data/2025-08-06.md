<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 130]
- [cs.CL](#cs.CL) [Total: 50]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cs.LG](#cs.LG) [Total: 88]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 52]
- [quant-ph](#quant-ph) [Total: 30]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.RO](#cs.RO) [Total: 35]
- [cs.GT](#cs.GT) [Total: 1]
- [eess.SY](#eess.SY) [Total: 10]
- [eess.SP](#eess.SP) [Total: 28]
- [cs.ET](#cs.ET) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.GR](#cs.GR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PyCAT4: A Hierarchical Vision Transformer-based Framework for 3D Human Pose Estimation](https://arxiv.org/abs/2508.02806)
*Zongyou Yang,Jonathan Loo*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 PyCAT4 的新模型，通过结合 Transformer、特征时间融合和空间金字塔结构来改进现有的 Pymaf 网络，以提升 3D 人体姿态估计的准确性。实验证明该模型在 COCO 和 3DPW 数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 结合卷积神经网络（CNN）和金字塔网格对齐反馈回路，近期在3D人体姿态估计的准确性方面取得了显著的改进。此外，通过采用基于 Transformer 的时间分析架构，在计算机视觉领域也取得了创新的突破。鉴于这些进展，本研究旨在深度优化和改进现有的 Pymaf 网络架构。

Method: 本研究的主要创新点包括：(1) 引入基于自注意力机制的 Transformer 特征提取网络层以增强对低级特征的捕捉；(2) 通过特征时间融合技术增强对视频序列中时间信号的理解和捕捉；(3) 实施空间金字塔结构以实现多尺度特征融合，有效平衡不同尺度下的特征表示差异。

Result: 本研究提出的 PyCAT4 模型在 COCO 和 3DPW 数据集上进行了验证，实验结果表明，所提出的改进策略显著增强了网络在人体姿态估计方面的检测能力。

Conclusion: 本研究提出的 PyCAT4 模型在 COCO 和 3DPW 数据集上进行了验证，实验结果表明，所提出的改进策略显著增强了网络在人体姿态估计方面的检测能力，进一步推动了人体姿态估计技术的发展。

Abstract: Recently, a significant improvement in the accuracy of 3D human pose
estimation has been achieved by combining convolutional neural networks (CNNs)
with pyramid grid alignment feedback loops. Additionally, innovative
breakthroughs have been made in the field of computer vision through the
adoption of Transformer-based temporal analysis architectures. Given these
advancements, this study aims to deeply optimize and improve the existing Pymaf
network architecture. The main innovations of this paper include: (1)
Introducing a Transformer feature extraction network layer based on
self-attention mechanisms to enhance the capture of low-level features; (2)
Enhancing the understanding and capture of temporal signals in video sequences
through feature temporal fusion techniques; (3) Implementing spatial pyramid
structures to achieve multi-scale feature fusion, effectively balancing feature
representations differences across different scales. The new PyCAT4 model
obtained in this study is validated through experiments on the COCO and 3DPW
datasets. The results demonstrate that the proposed improvement strategies
significantly enhance the network's detection capability in human pose
estimation, further advancing the development of human pose estimation
technology.

</details>


### [2] [Advancing Precision in Multi-Point Cloud Fusion Environments](https://arxiv.org/abs/2508.03179)
*Ulugbek Alibekov,Vanessa Staderini,Philipp Schneider,Doris Antensteiner*

Main category: cs.CV

TL;DR: 本研究提出了一种用于视觉工业检查的点云和多点云匹配方法，并开发了一个新的CloudCompare插件来提高检查效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动化检查系统的准确性和效率，本研究着重于视觉工业检查领域，评估点云和多点云匹配方法。

Method: 本研究采用点云和多点云匹配方法，并引入了一个新的CloudCompare插件，用于合并多个点云和可视化表面缺陷。

Result: 研究中提出了一种新的CloudCompare插件，可用于合并多个点云和可视化表面缺陷，从而提高自动化检查系统的准确性和效率。此外，还引入了一个合成数据集，用于量化评估配准方法和各种点云比较距离度量。

Conclusion: 该研究通过评估点云和多点云匹配方法，为视觉工业检查提供了一种新的解决方案，并提出了一个用于量化配准方法和各种点云比较距离度量的合成数据集。

Abstract: This research focuses on visual industrial inspection by evaluating point
clouds and multi-point cloud matching methods. We also introduce a synthetic
dataset for quantitative evaluation of registration method and various distance
metrics for point cloud comparison. Additionally, we present a novel
CloudCompare plugin for merging multiple point clouds and visualizing surface
defects, enhancing the accuracy and efficiency of automated inspection systems.

</details>


### [3] [Live Demonstration: Neuromorphic Radar for Gesture Recognition](https://arxiv.org/abs/2508.03324)
*Satyapreet Singh Yadav,Chandra Sekhar Seelamantula,Chetan Singh Thakur*

Main category: cs.CV

TL;DR: 我们提出了一个事件驱动的神经形态雷达框架，用于低功耗手势识别，通过异步sigma-delta编码将雷达信号转换为脉冲序列，并在微控制器上进行处理，实现了超过85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了实现实时、低功耗的手势识别，我们提出了一种受生物感应启发的事件驱动的神经形态雷达框架。

Method: 开发了一个包含24 GHz多普勒雷达前端和定制神经形态采样器的系统，使用异步sigma-delta编码将中频信号转换为稀疏的脉冲序列，并将其输入到轻量级神经网络进行处理。

Result: 该框架能够直接处理脉冲事件，无需频谱图重建，并且只在检测到有意义的运动时激活，从而显著降低了内存、功耗和计算开销，实现了超过85%的实时准确率。

Conclusion: 该系统实现了超过85%的实时准确率，并且是首个采用受生物启发的异步sigma-delta编码和事件驱动处理框架进行雷达手势识别的研究。

Abstract: We present a neuromorphic radar framework for real-time, low-power hand
gesture recognition (HGR) using an event-driven architecture inspired by
biological sensing. Our system comprises a 24 GHz Doppler radar front-end and a
custom neuromorphic sampler that converts intermediate-frequency (IF) signals
into sparse spike-based representations via asynchronous sigma-delta encoding.
These events are directly processed by a lightweight neural network deployed on
a Cortex-M0 microcontroller, enabling low-latency inference without requiring
spectrogram reconstruction. Unlike conventional radar HGR pipelines that
continuously sample and process data, our architecture activates only when
meaningful motion is detected, significantly reducing memory, power, and
computation overhead. Evaluated on a dataset of five gestures collected from
seven users, our system achieves > 85% real-time accuracy. To the best of our
knowledge, this is the first work that employs bio-inspired asynchronous
sigma-delta encoding and an event-driven processing framework for radar-based
HGR.

</details>


### [4] [DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework](https://arxiv.org/abs/2508.02807)
*Tongchun Zuo,Zaiyu Huang,Shuliang Ning,Ente Lin,Chao Liang,Zerong Zheng,Jianwen Jiang,Yuan Zhang,Mingyuan Gao,Xin Dong*

Main category: cs.CV

TL;DR: DreamVVT, a two-stage framework using DiTs and VLM, improves video virtual try-on by leveraging unpaired data and advanced visual models to preserve garment details and temporal consistency, outperforming existing methods in real-world scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing end-to-end VVT methods rely heavily on scarce paired garment-centric datasets and fail to leverage priors from advanced visual models and test-time inputs, leading to challenges in preserving fine-grained garment details and temporal consistency in unconstrained scenarios.

Method: DreamVVT is a two-stage framework built upon Diffusion Transformers (DiTs). The first stage uses a multi-frame try-on model integrated with a vision-language model (VLM) to synthesize high-fidelity keyframe try-on images from representative frames of the input video. The second stage feeds skeleton maps, motion and appearance descriptions, and keyframe try-on images into a pretrained video generation model enhanced with LoRA adapters to ensure long-term temporal coherence and plausible dynamic motions.

Result: The framework synthesizes high-fidelity and semantically consistent keyframe try-on images and generates videos with long-term temporal coherence and plausible dynamic motions.

Conclusion: DreamVVT surpasses existing methods in preserving detailed garment content and temporal stability in real-world scenarios.

Abstract: Video virtual try-on (VVT) technology has garnered considerable academic
interest owing to its promising applications in e-commerce advertising and
entertainment. However, most existing end-to-end methods rely heavily on scarce
paired garment-centric datasets and fail to effectively leverage priors of
advanced visual models and test-time inputs, making it challenging to
accurately preserve fine-grained garment details and maintain temporal
consistency in unconstrained scenarios. To address these challenges, we propose
DreamVVT, a carefully designed two-stage framework built upon Diffusion
Transformers (DiTs), which is inherently capable of leveraging diverse unpaired
human-centric data to enhance adaptability in real-world scenarios. To further
leverage prior knowledge from pretrained models and test-time inputs, in the
first stage, we sample representative frames from the input video and utilize a
multi-frame try-on model integrated with a vision-language model (VLM), to
synthesize high-fidelity and semantically consistent keyframe try-on images.
These images serve as complementary appearance guidance for subsequent video
generation. \textbf{In the second stage}, skeleton maps together with
fine-grained motion and appearance descriptions are extracted from the input
content, and these along with the keyframe try-on images are then fed into a
pretrained video generation model enhanced with LoRA adapters. This ensures
long-term temporal coherence for unseen regions and enables highly plausible
dynamic motions. Extensive quantitative and qualitative experiments demonstrate
that DreamVVT surpasses existing methods in preserving detailed garment content
and temporal stability in real-world scenarios. Our project page
https://virtu-lab.github.io/

</details>


### [5] [Learning Latent Representations for Image Translation using Frequency Distributed CycleGAN](https://arxiv.org/abs/2508.03415)
*Shivangi Nigam,Adarsh Prasad Behera,Shekhar Verma,P. Nagabhushan*

Main category: cs.CV

TL;DR: Fd-CycleGAN通过局部邻域编码和频率感知监督，改进了CycleGAN，能在图像到图像的翻译任务中学习更好的潜在表示，实现更优的翻译质量和更快的收敛速度，尤其在数据稀疏时表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了在图像到图像的翻译任务中更好地学习潜在表示以近似真实数据分布，并解决现有方法在捕捉局部像素语义和保持源域结构一致性方面的不足。

Method: Fd-CycleGAN框架整合了局部邻域编码（LNE）和频率感知监督，利用KL/JS散度和基于log的相似性度量来对齐真实图像和生成图像在空间和频率域的分布，以增强潜在表示学习。

Result: Fd-CycleGAN在Horse2Zebra、Monet2Photo和Strike-off数据集上进行了实验，与基线CycleGAN和其他先进方法相比，在感知质量、收敛速度和模式多样性方面表现更优，尤其是在数据稀疏的情况下，实现了更具视觉一致性和语义连贯性的翻译。

Conclusion: Fd-CycleGAN通过频率引导的潜在表示学习，在图像到图像的翻译任务中展现出更强的泛化能力，在文档修复、艺术风格迁移和医学图像合成等领域具有应用前景。与基于扩散的生成模型相比，该模型在训练效率和输出质量方面具有优势。

Abstract: This paper presents Fd-CycleGAN, an image-to-image (I2I) translation
framework that enhances latent representation learning to approximate real data
distributions. Building upon the foundation of CycleGAN, our approach
integrates Local Neighborhood Encoding (LNE) and frequency-aware supervision to
capture fine-grained local pixel semantics while preserving structural
coherence from the source domain. We employ distribution-based loss metrics,
including KL/JS divergence and log-based similarity measures, to explicitly
quantify the alignment between real and generated image distributions in both
spatial and frequency domains. To validate the efficacy of Fd-CycleGAN, we
conduct experiments on diverse datasets -- Horse2Zebra, Monet2Photo, and a
synthetically augmented Strike-off dataset. Compared to baseline CycleGAN and
other state-of-the-art methods, our approach demonstrates superior perceptual
quality, faster convergence, and improved mode diversity, particularly in
low-data regimes. By effectively capturing local and global distribution
characteristics, Fd-CycleGAN achieves more visually coherent and semantically
consistent translations. Our results suggest that frequency-guided latent
learning significantly improves generalization in image translation tasks, with
promising applications in document restoration, artistic style transfer, and
medical image synthesis. We also provide comparative insights with
diffusion-based generative models, highlighting the advantages of our
lightweight adversarial approach in terms of training efficiency and
qualitative output.

</details>


### [6] [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
*Adam Colton*

Main category: cs.CV

TL;DR: 通过用DynTanh替换LN，IJEPA能更好地保留视觉Token的能量，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: LN会破坏视觉Token的自然能量层级，导致模型无法区分和关注语义上重要的区域，从而影响学习效果。

Method: 将IJEPA中的特征层归一化（LN）替换为DynTanh激活函数，以保留token的能量和促进对语义丰富区域的关注。

Result: 使用DynTanh的模型在ImageNet线性探测任务上将ViT-Small的准确率从38%提升到42.7%，并在NYU Depth V2单目深度估计任务上将RMSE降低了0.08，修复了损失图中的棋盘格伪影。

Conclusion: 提出DynTanh激活函数替代特征层归一化（LN），能更好地保留Transformer视觉表示中的token能量，提高模型在下游任务中的性能。

Abstract: In the standard image joint embedding predictive architecture (IJEPA),
features at the output of the teacher encoder are layer normalized (LN) before
serving as a distillation target for the student encoder and predictor. We
propose that this feature normalization disrupts the natural energy hierarchy
of visual tokens, where high-energy tokens (those with larger L2 norms) encode
semantically important image regions. LN forces all features to have identical
L2 norms, effectively equalizing their energies and preventing the model from
prioritizing semantically rich regions. We find that IJEPA models trained with
feature LN exhibit loss maps with significant checkerboard-like artifacts. We
propose that feature LN be replaced with a DynTanh activation as the latter
better preserves token energies and allows high-energy tokens to greater
contribute to the prediction loss. We show that IJEPA trained with feature
DynTanh exhibits a longer-tailed loss distribution and fixes the checkerboard
artifacts in the loss map. Our empirical results show that our simple
modification improves ImageNet linear probe accuracy from 38% to 42.7% for
ViT-Small and reduces RMSE by 0.08 on NYU Depth V2 monocular depth estimation.
These results suggest that preserving natural token energies is crucial for
effective self-supervised visual representation learning.

</details>


### [7] [GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing](https://arxiv.org/abs/2508.02831)
*Mikołaj Zieliński,Krzysztof Byrski,Tomasz Szczepanik,Przemysław Spurek*

Main category: cs.CV

TL;DR: GENIE是一个混合模型，结合了NeRF的逼真渲染质量和GS的可编辑结构化表示，通过特征嵌入和RT-GPS实现实时、可交互的3D场景编辑。


<details>
  <summary>Details</summary>
Motivation: NeRF的隐式表示使得编辑和物理交互具有挑战性，而高斯泼溅（GS）虽然便于编辑，但在渲染保真度上可能不如NeRF。本文旨在结合两者的优点，实现既保真又可编辑的3D场景表示。

Method: GENIE采用可训练的特征嵌入来替代球谐函数进行外观建模，并使用射线追踪高斯邻近搜索（RT-GPS）和多分辨率哈希网格来实现实时、邻域感知的编辑。

Result: GENIE实现了实时、邻域感知的编辑，并能与物理模拟兼容，能够直观地操纵场景。

Conclusion: GENIE通过结合隐式和显式表示的优点，实现了直观的场景操纵、动态交互和与物理模拟的兼容性，弥合了基于几何的编辑和神经渲染之间的差距。

Abstract: Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have recently
transformed 3D scene representation and rendering. NeRF achieves high-fidelity
novel view synthesis by learning volumetric representations through neural
networks, but its implicit encoding makes editing and physical interaction
challenging. In contrast, GS represents scenes as explicit collections of
Gaussian primitives, enabling real-time rendering, faster training, and more
intuitive manipulation. This explicit structure has made GS particularly
well-suited for interactive editing and integration with physics-based
simulation. In this paper, we introduce GENIE (Gaussian Encoding for Neural
Radiance Fields Interactive Editing), a hybrid model that combines the
photorealistic rendering quality of NeRF with the editable and structured
representation of GS. Instead of using spherical harmonics for appearance
modeling, we assign each Gaussian a trainable feature embedding. These
embeddings are used to condition a NeRF network based on the k nearest
Gaussians to each query point. To make this conditioning efficient, we
introduce Ray-Traced Gaussian Proximity Search (RT-GPS), a fast nearest
Gaussian search based on a modified ray-tracing pipeline. We also integrate a
multi-resolution hash grid to initialize and update Gaussian features.
Together, these components enable real-time, locality-aware editing: as
Gaussian primitives are repositioned or modified, their interpolated influence
is immediately reflected in the rendered output. By combining the strengths of
implicit and explicit representations, GENIE supports intuitive scene
manipulation, dynamic interaction, and compatibility with physical simulation,
bridging the gap between geometry-based editing and neural rendering. The code
can be found under (https://github.com/MikolajZielinski/genie)

</details>


### [8] [RefineSeg: Dual Coarse-to-Fine Learning for Medical Image Segmentation](https://arxiv.org/abs/2508.02844)
*Anghong Du,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: cs.CV

TL;DR: 提出一种仅使用粗略标注的医学图像分割新方法，通过转移矩阵和多组标注联合训练，在不依赖精确标注的情况下实现了接近全监督方法的分割效果，优于现有弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像高质量像素级标注成本高昂且需要医学专业知识的问题。

Method: 提出一种新颖的粗粒度到细粒度分割框架，利用包含目标和互补图的粗略标注，通过引入转移矩阵来建模标注中的不准确和不完整区域，并联合训练多个粗略标注集进行优化。

Result: 在ACDC、MSCMRseg和UK Biobank数据集上进行了验证，结果显示该方法超越了最先进的弱监督方法，并接近全监督方法的性能。

Conclusion: 本研究提出的粗粒度到细粒度分割框架，仅依靠粗略的、包含目标和互补图的标注，通过引入转移矩阵来模拟粗略标注中的不准确和不完整区域，并联合训练多个粗略标注集，能够逐步优化网络输出并推断真实的分割分布，从而通过基于矩阵的建模实现对精确标签的鲁棒近似。该方法在ACDC、MSCMRseg和UK Biobank数据集上的实验结果表明，其性能优于当前最先进的弱监督方法，并接近于全监督方法。

Abstract: High-quality pixel-level annotations of medical images are essential for
supervised segmentation tasks, but obtaining such annotations is costly and
requires medical expertise. To address this challenge, we propose a novel
coarse-to-fine segmentation framework that relies entirely on coarse-level
annotations, encompassing both target and complementary drawings, despite their
inherent noise. The framework works by introducing transition matrices in order
to model the inaccurate and incomplete regions in the coarse annotations. By
jointly training on multiple sets of coarse annotations, it progressively
refines the network's outputs and infers the true segmentation distribution,
achieving a robust approximation of precise labels through matrix-based
modeling. To validate the flexibility and effectiveness of the proposed method,
we demonstrate the results on two public cardiac imaging datasets, ACDC and
MSCMRseg, and further evaluate its performance on the UK Biobank dataset.
Experimental results indicate that our approach surpasses the state-of-the-art
weakly supervised methods and closely matches the fully supervised approach.

</details>


### [9] [MIDAR: Mimicking LiDAR Detection for Traffic Applications with a Lightweight Plug-and-Play Model](https://arxiv.org/abs/2508.02858)
*Tianheng Zhu,Yiheng Feng*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As autonomous driving (AD) technology advances, increasing research has
focused on leveraging cooperative perception (CP) data collected from multiple
AVs to enhance traffic applications. Due to the impracticality of large-scale
real-world AV deployments, simulation has become the primary approach in most
studies. While game-engine-based simulators like CARLA generate high-fidelity
raw sensor data (e.g., LiDAR point clouds) which can be used to produce
realistic detection outputs, they face scalability challenges in multi-AV
scenarios. In contrast, microscopic traffic simulators such as SUMO scale
efficiently but lack perception modeling capabilities. To bridge this gap, we
propose MIDAR, a LiDAR detection mimicking model that approximates realistic
LiDAR detections using vehicle-level features readily available from
microscopic traffic simulators. Specifically, MIDAR predicts true positives
(TPs) and false negatives (FNs) from ideal LiDAR detection results based on the
spatial layouts and dimensions of surrounding vehicles. A Refined Multi-hop
Line-of-Sight (RM-LoS) graph is constructed to encode the occlusion
relationships among vehicles, upon which MIDAR employs a GRU-enhanced APPNP
architecture to propagate features from the ego AV and occluding vehicles to
the prediction target. MIDAR achieves an AUC of 0.909 in approximating the
detection results generated by CenterPoint, a mainstream 3D LiDAR detection
model, on the nuScenes AD dataset. Two CP-based traffic applications further
validate the necessity of such realistic detection modeling, particularly for
tasks requiring accurate individual vehicle observations (e.g., position,
speed, lane index). As demonstrated in the applications, MIDAR can be
seamlessly integrated into traffic simulators and trajectory datasets and will
be open-sourced upon publication.

</details>


### [10] [Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets](https://arxiv.org/abs/2508.02871)
*J. Alex Hurt,Trevor M. Bajkowski,Grant J. Scott,Curt H. Davis*

Main category: cs.CV

TL;DR: This paper explores transformer-based neural networks for object detection in satellite imagery, finding they achieve state-of-the-art results compared to traditional convolutional networks.


<details>
  <summary>Details</summary>
Motivation: To understand the performance of transformer-based neural networks on satellite imagery, given their success in NLP and CV, and to compare them with existing methods on large-scale remote sensing data.

Method: The study compared eleven object detection and localization algorithms (seven published since 2020, all since 2015), including five transformer-based and six convolutional architectures, on three high-resolution remote sensing datasets. Thirty-three deep neural models were trained and evaluated.

Result: Transformer-based neural networks demonstrated state-of-the-art performance on benchmark datasets for object detection in high-resolution satellite imagery. The paper discusses and analyzes model performance across different feature extraction methodologies and detection algorithms.

Conclusion: transformer-based neural networks achieve state-of-the-art performance on high-resolution satellite imagery for object detection tasks, outperforming convolutional networks.

Abstract: In 2012, AlexNet established deep convolutional neural networks (DCNNs) as
the state-of-the-art in CV, as these networks soon led in visual tasks for many
domains, including remote sensing. With the publication of Visual Transformers,
we are witnessing the second modern leap in computational vision, and as such,
it is imperative to understand how various transformer-based neural networks
perform on satellite imagery. While transformers have shown high levels of
performance in natural language processing and CV applications, they have yet
to be compared on a large scale to modern remote sensing data. In this paper,
we explore the use of transformer-based neural networks for object detection in
high-resolution electro-optical satellite imagery, demonstrating
state-of-the-art performance on a variety of publicly available benchmark data
sets. We compare eleven distinct bounding-box detection and localization
algorithms in this study, of which seven were published since 2020, and all
eleven since 2015. The performance of five transformer-based architectures is
compared with six convolutional networks on three state-of-the-art opensource
high-resolution remote sensing imagery datasets ranging in size and complexity.
Following the training and evaluation of thirty-three deep neural models, we
then discuss and analyze model performance across various feature extraction
methodologies and detection algorithms.

</details>


### [11] [VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction](https://arxiv.org/abs/2508.02890)
*Rongxin Jiang,Robert Long,Chenghao Gu,Mingrui Yan*

Main category: cs.CV

TL;DR: VisuCraft 是一个新框架，通过结构化信息提取和动态提示生成，显著增强了大型视觉语言模型 (LVLM) 在生成长篇创意内容方面的能力，解决了现有 LVLM 在视觉保真度、创意性和指令遵循性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLM）在生成长篇文本时，在保持高视觉保真度、真实创意和精确遵循细微用户指令方面存在局限性。本研究旨在解决这些挑战。

Method: VisuCraft 框架通过集成多模态结构化信息提取器 (E) 和动态提示生成模块 (G) 来解决现有 LVLM 在视觉保真度、创意性和指令遵循性方面的局限性。提取器从输入图像中提取细粒度视觉属性，并将其转化为结构化表示，然后动态提示模块将此表示与用户指令结合，为 LLaVA、InstructBLIP 等 LVLM 生成高度优化的提示。

Result: 在 VisuGen 指标（视觉基础、创意性和指令遵循性）的评估中，VisuCraft 在故事生成和诗歌创作等任务中持续优于基线 LVLM，尤其在创意性和指令遵循性方面取得了显著改进。

Conclusion: VisuCraft 框架在创意内容生成方面显著优于现有的 LVLM，尤其在创意性和指令遵循性方面表现突出，为 LVLM 在复杂创意 AI 应用中开辟了新的可能性。

Abstract: This paper introduces VisuCraft, a novel framework designed to significantly
enhance the capabilities of Large Vision-Language Models (LVLMs) in complex
visual-guided creative content generation. Existing LVLMs often exhibit
limitations in maintaining high visual fidelity, genuine creativity, and
precise adherence to nuanced user instructions when generating long-form texts.
VisuCraft addresses these challenges by integrating a multimodal structured
information extractor (E) and a dynamic prompt generation module (G). The
extractor distills fine-grained visual attributes from input images into a
rich, structured representation, which the dynamic prompt module then combines
with user instructions to create highly optimized prompts for underlying LVLMs
(e.g., LLaVA, InstructBLIP). Evaluated on the self-constructed
ImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity,
and Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs
across tasks like story generation and poetry composition. Our results
demonstrate remarkable improvements, particularly in creativity and instruction
adherence, validating VisuCraft's effectiveness in producing imaginative,
visually grounded, and user-aligned long-form creative text. This work unlocks
new potential for LVLMs in sophisticated creative AI applications.

</details>


### [12] [RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation](https://arxiv.org/abs/2508.02903)
*Mehrdad Moradi,Kamran Paynabar*

Main category: cs.CV

TL;DR: This paper introduces robust diffusion models that can be trained on mixed normal/anomalous data, outperforming existing methods for anomaly segmentation in challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion models for anomaly segmentation require only normal data for training, which is often not feasible in realistic settings. This paper addresses the limitation by proposing a novel framework that works with contaminated (unlabeled mix of normal and anomalous) data.

Method: The paper proposes robust denoising diffusion models by reinterpreting denoising diffusion probabilistic models as a nonlinear regression problem and deriving a robust version using robust regression. This framework allows for the construction of various robust diffusion models.

Result: The proposed approach outperforms current state-of-the-art diffusion models for unsupervised anomaly segmentation with contaminated data, achieving up to 8.08% higher AUROC and 10.37% higher AUPRC on MVTec datasets.

Conclusion: The proposed robust denoising diffusion models, derived from a regression perspective, outperform existing diffusion-based approaches for unsupervised anomaly segmentation using contaminated data, achieving significant improvements in AUROC and AUPRC on MVTec datasets.

Abstract: Recent advancements in diffusion models have demonstrated significant success
in unsupervised anomaly segmentation. For anomaly segmentation, these models
are first trained on normal data; then, an anomalous image is noised to an
intermediate step, and the normal image is reconstructed through backward
diffusion. Unlike traditional statistical methods, diffusion models do not rely
on specific assumptions about the data or target anomalies, making them
versatile for use across different domains. However, diffusion models typically
assume access to normal data for training, limiting their applicability in
realistic settings. In this paper, we propose novel robust denoising diffusion
models for scenarios where only contaminated (i.e., a mix of normal and
anomalous) unlabeled data is available. By casting maximum likelihood
estimation of the data as a nonlinear regression problem, we reinterpret the
denoising diffusion probabilistic model through a regression lens. Using robust
regression, we derive a robust version of denoising diffusion probabilistic
models. Our novel framework offers flexibility in constructing various robust
diffusion models. Our experiments show that our approach outperforms current
state of the art diffusion models, for unsupervised anomaly segmentation when
only contaminated data is available. Our method outperforms existing
diffusion-based approaches, achieving up to 8.08\% higher AUROC and 10.37\%
higher AUPRC on MVTec datasets. The implementation code is available at:
https://github.com/mehrdadmoradi124/RDDPM

</details>


### [13] [How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes](https://arxiv.org/abs/2508.02905)
*Mahnoor Fatima Saad,Ziad Al-Halah*

Main category: cs.CV

TL;DR: 提出了一种新颖的编码器-解码器方法，用于根据用户定义的材料配置生成房间脉廓响应（RIR）。创建了Acoustic Wonderland数据集来支持该任务。模型在生成高保真度RIR方面表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 研究当工作室地板铺设地毯、墙壁安装声学瓦片时，声音会如何变化。提出材料控制声学轮廓生成任务，旨在根据用户定义的材料配置生成目标声学轮廓。

Method: 提出了一种新颖的编码器-解码器方法，该方法从音频-视觉观察中编码场景的关键属性，并根据用户提供的材料规格生成目标房间脉冲响应（RIR）。

Result: 模型能够根据推理时动态定义的各种材料配置生成多样的RIR。

Conclusion: 该模型能够有效编码材料信息并生成高保真度的房间脉冲响应（RIR），性能优于多个基线和最先进的方法。

Abstract: How would the sound in a studio change with a carpeted floor and acoustic
tiles on the walls? We introduce the task of material-controlled acoustic
profile generation, where, given an indoor scene with specific audio-visual
characteristics, the goal is to generate a target acoustic profile based on a
user-defined material configuration at inference time. We address this task
with a novel encoder-decoder approach that encodes the scene's key properties
from an audio-visual observation and generates the target Room Impulse Response
(RIR) conditioned on the material specifications provided by the user. Our
model enables the generation of diverse RIRs based on various material
configurations defined dynamically at inference time. To support this task, we
create a new benchmark, the Acoustic Wonderland Dataset, designed for
developing and evaluating material-aware RIR prediction methods under diverse
and challenging settings. Our results demonstrate that the proposed model
effectively encodes material information and generates high-fidelity RIRs,
outperforming several baselines and state-of-the-art methods.

</details>


### [14] [Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces](https://arxiv.org/abs/2508.02917)
*Vebjørn Haug Kåsene,Pierre Lison*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-and-Language Navigation (VLN) refers to the task of enabling
autonomous robots to navigate unfamiliar environments by following natural
language instructions. While recent Large Vision-Language Models (LVLMs) have
shown promise in this task, most current VLM systems rely on models
specifically designed and optimized for navigation, leaving the potential of
off-the-shelf LVLMs underexplored. Furthermore, while older VLN approaches used
low-level action spaces with egocentric views and atomic actions (such as "turn
left" or "move forward"), newer models tend to favor panoramic action spaces
with discrete navigable viewpoints. This paper investigates (1) whether
off-the-shelf LVLMs (fine-tuned without architectural modifications or
simulator-based training) can effectively support VLN tasks and (2) whether
such models can support both low-level and panoramic action paradigms. To this
end, we fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the
Room-to-Room (R2R) dataset and evaluate its empirical performance across both
low-level and panoramic action spaces. The best resulting model achieves a 41%
success rate on the R2R test set, demonstrating that while off-the-shelf LVLMs
can learn to perform Vision-and-Language Navigation, they still lag behind
models specifically designed for this task.

</details>


### [15] [How Diffusion Prior Landscapes Shape the Posterior in Blind Deconvolution](https://arxiv.org/abs/2508.02923)
*Minh-Hai Nguyen,Edouard Pauwels,Pierre Weiss*

Main category: cs.CV

TL;DR: MAP估计在盲反卷积中倾向于模糊解，但其局部最小值点对应真实图像。需要良好的局部初始化来克服MAP估计的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服在盲反卷积中使用最大后验（MAP）估计时，尤其是在结合了稀疏先验时，MAP估计倾向于模糊解的限制。

Method: 通过对先验模型的似然性进行经验性考察，并结合理论分析，揭示了MAP估计的特性和局部最小化点的性质。

Result: MAP估计倾向于产生尖锐的滤波器（接近狄拉克δ函数）和模糊的解。然而，通过梯度下降可以获得的后验分布的局部最小值点对应于真实的、自然的图像，从而有效地解决了盲反卷积问题。

Conclusion: MAP估计的局限性在于倾向于模糊解，但通过梯度下降等方法找到的局部最小值点对应于真实的自然图像，有效解决了盲反卷积问题。克服MAP估计的局限性需要良好的局部初始化。

Abstract: The Maximum A Posteriori (MAP) estimation is a widely used framework in blind
deconvolution to recover sharp images from blurred observations. The estimated
image and blur filter are defined as the maximizer of the posterior
distribution. However, when paired with sparsity-promoting image priors, MAP
estimation has been shown to favors blurry solutions, limiting its
effectiveness. In this paper, we revisit this result using diffusion-based
priors, a class of models that capture realistic image distributions. Through
an empirical examination of the prior's likelihood landscape, we uncover two
key properties: first, blurry images tend to have higher likelihoods; second,
the landscape contains numerous local minimizers that correspond to natural
images. Building on these insights, we provide a theoretical analysis of the
blind deblurring posterior. This reveals that the MAP estimator tends to
produce sharp filters (close to the Dirac delta function) and blurry solutions.
However local minimizers of the posterior, which can be obtained with gradient
descent, correspond to realistic, natural images, effectively solving the blind
deconvolution problem. Our findings suggest that overcoming MAP's limitations
requires good local initialization to local minima in the posterior landscape.
We validate our analysis with numerical experiments, demonstrating the
practical implications of our insights for designing improved priors and
optimization techniques.

</details>


### [16] [Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?](https://arxiv.org/abs/2508.02927)
*Srikanth Muralidharan,Heitor R. Medeiros,Masih Aminbeidokhti,Eric Granger,Marco Pedersoli*

Main category: cs.CV

TL;DR: 在超小型模型（<1M参数）上，ImageNet预训练对红外物体检测任务的鲁棒性仍然有益，但收益会递减。建议谨慎选择模型大小，避免过小的模型，因为它们在不同操作条件下表现脆弱。


<details>
  <summary>Details</summary>
Motivation: 在嵌入式和边缘设备上运行的小型模型（参数量小于100万）使用ImageNet预训练的效果尚不清楚。

Method: 利用从标准物体识别架构推导出的缩放定律，构建了两个超小型骨干网络家族，并系统地研究了它们的性能。

Result: 实验表明，ImageNet预训练在超小型模型上仍然有用，但收益存在递减效应。

Conclusion: ImageNet预训练对日益缩小的骨干网络（参数量小于100万的超小型模型）在红外视觉模态下游物体检测任务的鲁棒性方面仍然有用，但超过一定容量阈值后，其在分布外检测鲁棒性方面的收益会递减。建议从业者仍然使用预训练，并在可能的情况下避免使用过小的模型，因为它们在特定领域内表现良好，但在工作条件不同时则很脆弱。

Abstract: Many real-world applications require recognition models that are robust to
different operational conditions and modalities, but at the same time run on
small embedded devices, with limited hardware. While for normal size models,
pre-training is known to be very beneficial in accuracy and robustness, for
small models, that can be employed for embedded and edge devices, its effect is
not clear. In this work, we investigate the effect of ImageNet pretraining on
increasingly small backbone architectures (ultra-small models, with $<$1M
parameters) with respect to robustness in downstream object detection tasks in
the infrared visual modality. Using scaling laws derived from standard object
recognition architectures, we construct two ultra-small backbone families and
systematically study their performance. Our experiments on three different
datasets reveal that while ImageNet pre-training is still useful, beyond a
certain capacity threshold, it offers diminishing returns in terms of
out-of-distribution detection robustness. Therefore, we advise practitioners to
still use pre-training and, when possible avoid too small models as while they
might work well for in-domain problems, they are brittle when working
conditions are different.

</details>


### [17] [X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio](https://arxiv.org/abs/2508.02944)
*Chenxu Zhang,Zenan Li,Hongyi Xu,You Xie,Xiaochen Zhao,Tianpei Gu,Guoxian Song,Xin Chen,Chao Liang,Jianwen Jiang,Linjie Luo*

Main category: cs.CV

TL;DR: X-Actor 是一个新颖的音频驱动肖像动画框架，可以从单个参考图像和输入音频剪辑生成逼真的、富有情感表达的说话人脸视频。它通过一个两阶段的解耦生成流程，能够捕捉细致、动态演变的情感，并实现无限长度、富有情感的运动预测，在长期、音频驱动的情感肖像表演方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 与以往着重于唇形同步和约束说话场景中短距离视觉保真度的方法不同，X-Actor 能够实现演员级别的长期肖像表演，捕捉与语音节奏和内容连贯流动的细致、动态演变的情感。

Method: X-Actor 采用两阶段解耦生成流程：1. 音频条件自回归扩散模型，用于预测具有长期时间上下文窗口的表达性但与身份无关的面部运动潜在令牌。2. 基于扩散的视频合成模块，用于将这些运动转化为高保真视频动画。

Result: X-Actor 能够生成栩栩如生、富有情感表达的说话人脸视频，实现超越标准说话人脸动画的、具有电影风格的引人注目的表演。

Conclusion: X-Actor 在长期、音频驱动的情感肖像表演方面取得了最先进的成果。

Abstract: We present X-Actor, a novel audio-driven portrait animation framework that
generates lifelike, emotionally expressive talking head videos from a single
reference image and an input audio clip. Unlike prior methods that emphasize
lip synchronization and short-range visual fidelity in constrained speaking
scenarios, X-Actor enables actor-quality, long-form portrait performance
capturing nuanced, dynamically evolving emotions that flow coherently with the
rhythm and content of speech. Central to our approach is a two-stage decoupled
generation pipeline: an audio-conditioned autoregressive diffusion model that
predicts expressive yet identity-agnostic facial motion latent tokens within a
long temporal context window, followed by a diffusion-based video synthesis
module that translates these motions into high-fidelity video animations. By
operating in a compact facial motion latent space decoupled from visual and
identity cues, our autoregressive diffusion model effectively captures
long-range correlations between audio and facial dynamics through a
diffusion-forcing training paradigm, enabling infinite-length emotionally-rich
motion prediction without error accumulation. Extensive experiments demonstrate
that X-Actor produces compelling, cinematic-style performances that go beyond
standard talking head animations and achieves state-of-the-art results in
long-range, audio-driven emotional portrait acting.

</details>


### [18] [Towards Robust Image Denoising with Scale Equivariance](https://arxiv.org/abs/2508.02967)
*Dawei Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 通过引入尺度不变性，并结合异构归一化模块（HNM）和交互式门控模块（IGM），提出了一种更具鲁棒性的盲去噪模型，特别擅长处理空间异质噪声。


<details>
  <summary>Details</summary>
Motivation: 现有模型在泛化到分布外（OOD）的噪声模式，特别是空间变异噪声方面存在不足。研究人员旨在通过引入尺度不变性（scale equivariance）作为一种归纳偏置来提高模型的OOD鲁棒性。

Method: 提出了一种包含异构归一化模块（HNM）和交互式门控模块（IGM）的鲁棒盲去噪框架。HNM用于稳定特征分布并动态校正特征，IGM通过门控交互促进信号和特征路径之间的有效信息调制。

Result: 该模型在处理空间异质噪声方面表现出色，并且在合成和真实世界的基准测试中取得了优于现有方法的性能。

Conclusion: 所提出的框架在合成和真实世界基准上均优于最先进的方法，特别是在处理空间异质噪声时。

Abstract: Despite notable advances in image denoising, existing models often struggle
to generalize beyond in-distribution noise patterns, particularly when
confronted with out-of-distribution (OOD) conditions characterized by spatially
variant noise. This generalization gap remains a fundamental yet underexplored
challenge. In this work, we investigate \emph{scale equivariance} as a core
inductive bias for improving OOD robustness. We argue that incorporating
scale-equivariant structures enables models to better adapt from training on
spatially uniform noise to inference on spatially non-uniform degradations.
Building on this insight, we propose a robust blind denoising framework
equipped with two key components: a Heterogeneous Normalization Module (HNM)
and an Interactive Gating Module (IGM). HNM stabilizes feature distributions
and dynamically corrects features under varying noise intensities, while IGM
facilitates effective information modulation via gated interactions between
signal and feature paths. Extensive evaluations demonstrate that our model
consistently outperforms state-of-the-art methods on both synthetic and
real-world benchmarks, especially under spatially heterogeneous noise. Code
will be made publicly available.

</details>


### [19] [Diffusion Models with Adaptive Negative Sampling Without External Resources](https://arxiv.org/abs/2508.02973)
*Alakh Desai,Nuno Vasconcelos*

Main category: cs.CV

TL;DR: 本研究提出了一种名为ANSWER的新型采样技术，用于改进文本到图像扩散模型。ANSWER通过结合正面和负面提示信息，并利用模型对否定的内部理解，在不使用外部资源或进行额外训练的情况下，提高了生成图像的质量和对提示的符合度。实验证明ANSWER在多个评估指标上优于现有技术，并受到用户的高度青睐。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型（DMs）在从文本提示生成图像方面表现出色，但在提示符合度和图像质量方面存在很大差异。引入负面提示是为了通过指定图像不应包含的内容来提高提示的符合度。然而，先前的工作表明存在一个理想的负面提示，可以最大化正面提示的概率。本研究旨在探索负面提示和CFG之间的关系，以开发一种更有效的采样程序。

Method: 提出了一种名为ANSWER（自适应负采样无外部资源）的采样程序，该程序通过探索负面提示和分类器自由引导（CFG）之间的关系，从单个提示中同时考虑正面和负面条件。ANSWER利用了扩散模型内部对否定的理解来提高生成图像与提示的符合度。

Result: 实验结果表明，ANSWER在多个基准测试中优于基线方法，并且人类更倾向于使用ANSWER（相比其他方法，偏好度是其2倍）。

Conclusion: ANSWER是一种无需训练即可应用于任何支持CFG的模型的技术，它允许在没有显式负面提示的情况下对图像概念进行否定，从而提高生成图像与提示的符合度。实验表明，将ANSWER添加到现有的扩散模型中，在多个基准测试中优于基线方法，并且人类更倾向于使用该方法。

Abstract: Diffusion models (DMs) have demonstrated an unparalleled ability to create
diverse and high-fidelity images from text prompts. However, they are also
well-known to vary substantially regarding both prompt adherence and quality.
Negative prompting was introduced to improve prompt compliance by specifying
what an image must not contain. Previous works have shown the existence of an
ideal negative prompt that can maximize the odds of the positive prompt. In
this work, we explore relations between negative prompting and classifier-free
guidance (CFG) to develop a sampling procedure, {\it Adaptive Negative Sampling
Without External Resources} (ANSWER), that accounts for both positive and
negative conditions from a single prompt. This leverages the internal
understanding of negation by the diffusion model to increase the odds of
generating images faithful to the prompt. ANSWER is a training-free technique,
applicable to any model that supports CFG, and allows for negative grounding of
image concepts without an explicit negative prompts, which are lossy and
incomplete. Experiments show that adding ANSWER to existing DMs outperforms the
baselines on multiple benchmarks and is preferred by humans 2x more over the
other methods.

</details>


### [20] [Separating Shared and Domain-Specific LoRAs for Multi-Domain Learning](https://arxiv.org/abs/2508.02978)
*Yusaku Takama,Ning Ding,Tatsuya Yokota,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出了一种将共享和领域特定 LoRA 映射到不同子空间的新方法，并在动作识别任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的多域学习架构中的适配器（共享 LoRA 或领域特定 LoRA）在捕捉领域特异性信息方面的有效性尚不明确，需要探索新的结构。

Method: 本研究提出了一种将共享 LoRA 和领域特定 LoRA 映射到预训练权重的列空间和左零空间的新方法，并分析了 LoRA 权重的维度。

Result: 在动作识别任务（UCF101、Kinetics400 和 HMDB51 数据集）上进行的实验表明，该方法在某些情况下是有效的，并且对 LoRA 权重的维度进行了分析。

Conclusion: 该研究提出了一种新颖的多域学习架构，将共享 LoRA 和领域特定 LoRA 映射到预训练权重的不同子空间（列空间和左零空间），以期更有效地捕捉领域特异性信息。

Abstract: Existing architectures of multi-domain learning have two types of adapters:
shared LoRA for all domains and domain-specific LoRA for each particular
domain. However, it remains unclear whether this structure effectively captures
domain-specific information. In this paper, we propose a method that ensures
that shared and domain-specific LoRAs exist in different subspaces;
specifically, the column and left null subspaces of the pre-trained weights. We
apply the proposed method to action recognition with three datasets (UCF101,
Kinetics400, and HMDB51) and demonstrate its effectiveness in some cases along
with the analysis of the dimensions of LoRA weights.

</details>


### [21] [MoExDA: Domain Adaptation for Edge-based Action Recognition](https://arxiv.org/abs/2508.02981)
*Takuya Sugimoto,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: MoExDA是一种轻量级域自适应方法，通过结合RGB帧和边缘帧来解决动作识别中的静态偏差问题，从而提高泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代动作识别模型存在静态偏差，导致泛化能力下降。

Method: 提出了一种使用边缘帧和RGB帧进行域自适应的轻量级模型MoExDA，以解决现代动作识别模型中的静态偏差问题。

Result: 实验证明，MoExDA能以较低的计算成本有效抑制静态偏差，实现比以往方法更鲁棒的动作识别。

Conclusion: MoExDA通过引入边缘帧有效抑制了静态偏差，在实现更鲁棒的动作识别的同时，降低了计算成本。

Abstract: Modern action recognition models suffer from static bias, leading to reduced
generalization performance. In this paper, we propose MoExDA, a lightweight
domain adaptation between RGB and edge information using edge frames in
addition to RGB frames to counter the static bias issue. Experiments
demonstrate that the proposed method effectively suppresses static bias with a
lower computational cost, allowing for more robust action recognition than
previous approaches.

</details>


### [22] [Adversarial Attention Perturbations for Large Object Detection Transformers](https://arxiv.org/abs/2508.02987)
*Zachary Yahn,Selim Furkan Tekin,Fatih Ilhan,Sihao Hu,Tiansheng Huang,Yichang Xu,Margaret Loper,Ling Liu*

Main category: cs.CV

TL;DR: AFOG是一种新的对抗性攻击方法，可以有效攻击目标检测器（包括Transformer和CNN）。它使用注意力机制将攻击集中在关键区域，并能在保持视觉不可感知性的同时，大幅提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有的针对目标检测器的对抗性扰动方法要么局限于攻击基于CNN的检测器，要么对基于Transformer的检测器效果较差。本研究旨在提出一种能够同时有效攻击基于Transformer的目标检测器和传统的基于CNN的检测器的通用方法。

Method: AFOG（Attention-Focused Offensive Gradient）攻击利用可学习的注意力机制，将扰动集中在多框检测任务的脆弱图像区域。它通过整合两种特征损失，并结合迭代注入对抗性扰动，来制定攻击损失。

Result: AFOG在COCO数据集上的十二个大型检测Transformer上进行了广泛的实验，证明了其有效性。实验结果表明，AFOG相比现有的针对Transformer和CNN检测器的攻击方法，在性能上最多可提高83%，同时具有更优越的速度和不可感知性。

Conclusion: AFOG是一种有效且隐蔽的对抗性扰动方法，通过专注于脆弱的图像区域，可以显着提高针对目标检测器的攻击性能，并且在Transformer和CNN检测器上都表现出色。

Abstract: Adversarial perturbations are useful tools for exposing vulnerabilities in
neural networks. Existing adversarial perturbation methods for object detection
are either limited to attacking CNN-based detectors or weak against
transformer-based detectors. This paper presents an Attention-Focused Offensive
Gradient (AFOG) attack against object detection transformers. By design, AFOG
is neural-architecture agnostic and effective for attacking both large
transformer-based object detectors and conventional CNN-based detectors with a
unified adversarial attention framework. This paper makes three original
contributions. First, AFOG utilizes a learnable attention mechanism that
focuses perturbations on vulnerable image regions in multi-box detection tasks,
increasing performance over non-attention baselines by up to 30.6%. Second,
AFOG's attack loss is formulated by integrating two types of feature loss
through learnable attention updates with iterative injection of adversarial
perturbations. Finally, AFOG is an efficient and stealthy adversarial
perturbation method. It probes the weak spots of detection transformers by
adding strategically generated and visually imperceptible perturbations which
can cause well-trained object detection models to fail. Extensive experiments
conducted with twelve large detection transformers on COCO demonstrate the
efficacy of AFOG. Our empirical results also show that AFOG outperforms
existing attacks on transformer-based and CNN-based object detectors by up to
83% with superior speed and imperceptibility. Code is available at
https://github.com/zacharyyahn/AFOG.

</details>


### [23] [Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models](https://arxiv.org/abs/2508.03006)
*Fan Yang,Yihao Huang,Jiayi Zhu,Ling Shi,Geguang Pu,Jin Song Dong,Kailong Wang*

Main category: cs.CV

TL;DR: Diffusion models can create NSFW content. A new method called In-Generation Detection (IGD) uses the model's internal predicted noise to detect NSFW content during the generation process. It's accurate (91.32%) and better than other methods.


<details>
  <summary>Details</summary>
Motivation: Prior NSFW detection methods focus on pre-generation (prompt filtering) or post-generation (image moderation) phases. The in-generation phase of diffusion models was unexplored, despite preliminary findings suggesting predicted noise captures semantic cues for NSFW differentiation.

Method: The proposed In-Generation Detection (IGD) approach utilizes the predicted noise from the diffusion process as an internal signal to detect NSFW content.

Result: IGD achieves an average detection accuracy of 91.32% over naive and adversarial NSFW prompts across seven NSFW categories, outperforming seven baseline methods.

Conclusion: In-generation detection (IGD) leverages predicted noise during the diffusion process for NSFW content identification, achieving 91.32% average accuracy across seven NSFW categories and outperforming seven baseline methods.

Abstract: Diffusion-based text-to-image (T2I) models enable high-quality image
generation but also pose significant risks of misuse, particularly in producing
not-safe-for-work (NSFW) content. While prior detection methods have focused on
filtering prompts before generation or moderating images afterward, the
in-generation phase of diffusion models remains largely unexplored for NSFW
detection. In this paper, we introduce In-Generation Detection (IGD), a simple
yet effective approach that leverages the predicted noise during the diffusion
process as an internal signal to identify NSFW content. This approach is
motivated by preliminary findings suggesting that the predicted noise may
capture semantic cues that differentiate NSFW from benign prompts, even when
the prompts are adversarially crafted. Experiments conducted on seven NSFW
categories show that IGD achieves an average detection accuracy of 91.32% over
naive and adversarial NSFW prompts, outperforming seven baseline methods.

</details>


### [24] [Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.03007)
*Xinhui Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: MGFC通过多粒度特征校准提升了视觉基础模型在领域泛化中的泛化能力，实现了比现有方法更好的语义分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有 DGSS 方法主要集中在全局特征微调，忽略了对跨特征层级的层次化适应，而这对于精确的密集预测至关重要。

Method: MGFC框架通过分层校准视觉基础模型（VFM）特征来实现粗到细的对齐。具体来说，它首先校准粗粒度特征以捕捉全局上下文语义和场景级结构，然后通过增强类别级特征可辨性来优化中粒度特征，最后通过高频空间细节增强来校准细粒度特征。

Result: MGFC框架通过分层和粒度感知校准，有效提升了模型在领域迁移下的鲁棒性，并在基准数据集上取得了优于现有最先进方法的性能。

Conclusion: MGFC框架通过执行分层和粒度感知校准，有效地将视觉基础模型（VFM）的泛化能力转移到领域泛化（DGSS）的特定任务中。实验证明，MGFC在基准数据集上的表现优于最先进的DGSS方法，凸显了多粒度适应对于语义分割任务的领域泛化至关重要。

Abstract: Domain Generalized Semantic Segmentation (DGSS) aims to improve the
generalization ability of models across unseen domains without access to target
data during training. Recent advances in DGSS have increasingly exploited
vision foundation models (VFMs) via parameter-efficient fine-tuning strategies.
However, most existing approaches concentrate on global feature fine-tuning,
while overlooking hierarchical adaptation across feature levels, which is
crucial for precise dense prediction. In this paper, we propose
Multi-Granularity Feature Calibration (MGFC), a novel framework that performs
coarse-to-fine alignment of VFM features to enhance robustness under domain
shifts. Specifically, MGFC first calibrates coarse-grained features to capture
global contextual semantics and scene-level structure. Then, it refines
medium-grained features by promoting category-level feature discriminability.
Finally, fine-grained features are calibrated through high-frequency spatial
detail enhancement. By performing hierarchical and granularity-aware
calibration, MGFC effectively transfers the generalization strengths of VFMs to
the domain-specific task of DGSS. Extensive experiments on benchmark datasets
demonstrate that our method outperforms state-of-the-art DGSS approaches,
highlighting the effectiveness of multi-granularity adaptation for the semantic
segmentation task of domain generalization.

</details>


### [25] [Enhancing Long Video Question Answering with Scene-Localized Frame Grouping](https://arxiv.org/abs/2508.03009)
*Xuyi Yang,Wenhao Zhang,Hongbo Jin,Lin Liu,Hongbo Xu,Yongwei Nie,Fei Yu,Fei Ma*

Main category: cs.CV

TL;DR: 提出SLFG方法，通过将帧组合成场景帧来增强MLLM在长视频中的理解能力，在长视频问答任务中引入SceneQA场景，并发布LVSQA数据集以促进更公平的评估。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLM）在长视频理解方面表现不佳，主要是因为资源限制导致无法处理所有视频帧及其相关信息，而现有的框架和评估任务未能满足实际需求。

Method: 提出了一种名为SLFG的新方法，通过结合单个帧形成语义上连贯的场景帧，并利用场景定位方法和动态帧重组机制来增强现有MLLM在长视频中的理解能力。

Result: 实验结果表明，该方法在多项长视频基准测试中表现优异。

Conclusion: SLFG方法在长视频理解方面表现出色，并且具有即插即用的优点。

Abstract: Current Multimodal Large Language Models (MLLMs) often perform poorly in long
video understanding, primarily due to resource limitations that prevent them
from processing all video frames and their associated information. Efficiently
extracting relevant information becomes a challenging task. Existing frameworks
and evaluation tasks focus on identifying specific frames containing core
objects from a large number of irrelevant frames, which does not align with the
practical needs of real-world applications. To address this issue, we propose a
new scenario under the video question-answering task, SceneQA, which emphasizes
scene-based detail perception and reasoning abilities. And we develop the LVSQA
dataset to support the SceneQA task, which is built upon carefully selected
videos from LVBench and contains a new collection of question-answer pairs to
promote a more fair evaluation of MLLMs' scene perception abilities in long
videos. Inspired by human cognition, we introduce a novel method called SLFG.
The core idea of SLFG is to combine individual frames into semantically
coherent scene frames. By leveraging scene localization methods and dynamic
frame reassembly mechanisms, SLFG significantly enhances the understanding
capabilities of existing MLLMs in long videos. SLFG requires no modification to
the original model architecture and boasts excellent plug-and-play usability.
Experimental results show that this method performs exceptionally well in
several long video benchmark tests. Code and dataset will be released at
http://www.slfg.pkuzwh.cn.

</details>


### [26] [SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting](https://arxiv.org/abs/2508.03017)
*Liheng Zhang,Weihao Yu,Zubo Lu,Haozhi Gu,Jin Huang*

Main category: cs.CV

TL;DR: SA-3DGS 通过学习重要性得分、重要性感知聚类和码本修复来压缩 3D 高斯泼溅模型，可在保持渲染质量的同时实现高达 66 倍的压缩。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 高斯泼溅方法需要大量高斯点，导致存储需求高，限制了实际部署。虽然最新方法促进了高斯模型的压缩，但难以识别场景中真正不重要的高斯点，导致后续高斯剪枝、压缩质量和渲染性能下降。

Method: SA-3DGS 通过学习重要性得分来自动识别场景重建中最重要的、冗余最少的高斯点，从而实现有效剪枝和冗余缩减。然后，重要性感知聚类模块将高斯属性更准确地压缩到码本中，提高了码本的表达能力并减小了模型尺寸。最后，码本修复模块利用上下文场景信息来修复码本，从而恢复原始高斯点属性，并减轻信息丢失引起的渲染质量下降。

Result: SA-3DGS 实现了高达 66 倍的压缩率，同时保持或提高了渲染质量。其高斯剪枝方法不仅适用于 LightGaussian 等其他剪枝方法，还能对其进行改进，展现出优异的性能和强大的泛化能力。

Conclusion: SA-3DGS 在保持或提高渲染质量的同时，实现了高达 66 倍的压缩率。

Abstract: Recent advancements in 3D Gaussian Splatting have enhanced efficient and
high-quality novel view synthesis. However, representing scenes requires a
large number of Gaussian points, leading to high storage demands and limiting
practical deployment. The latest methods facilitate the compression of Gaussian
models but struggle to identify truly insignificant Gaussian points in the
scene, leading to a decline in subsequent Gaussian pruning, compression
quality, and rendering performance. To address this issue, we propose SA-3DGS,
a method that significantly reduces storage costs while maintaining rendering
quality. SA-3DGS learns an importance score to automatically identify the least
significant Gaussians in scene reconstruction, thereby enabling effective
pruning and redundancy reduction. Next, the importance-aware clustering module
compresses Gaussians attributes more accurately into the codebook, improving
the codebook's expressive capability while reducing model size. Finally, the
codebook repair module leverages contextual scene information to repair the
codebook, thereby recovering the original Gaussian point attributes and
mitigating the degradation in rendering quality caused by information loss.
Experimental results on several benchmark datasets show that our method
achieves up to 66x compression while maintaining or even improving rendering
quality. The proposed Gaussian pruning approach is not only adaptable to but
also improves other pruning-based methods (e.g., LightGaussian), showcasing
excellent performance and strong generalization ability.

</details>


### [27] [MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention](https://arxiv.org/abs/2508.03034)
*Qi Xie,Yongjia Ma,Donglin Di,Xuehao Gao,Xun Yang*

Main category: cs.CV

TL;DR: MoCA是一种新的文本到视频生成模型，它通过创新的混合交叉注意力机制和时间感知技术，提高了视频中人物身份的一致性和面部细节的准确性，并在CelebIPVid数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频（T2V）生成模型在保持身份一致性和捕捉精细面部动态方面存在挑战。为了解决这些限制，需要开发一种能够更好地维护跨帧身份一致性并生成高质量视频的新型模型。

Method: MoCA是一个基于DiT（Diffusion Transformer）骨干模型的新型视频扩散模型，其核心是采用了受专家混合（Mixture-of-Experts）范式启发的混合交叉注意力（Mixture of Cross-Attention）机制。该机制通过将MoCA层嵌入到每个DiT块中，利用分层时间池捕获不同时间尺度的身份特征，并利用时间感知交叉注意力专家动态建模时空关系。此外，还引入了潜在视频感知损失来增强身份一致性和帧间细节。

Result: MoCA在CelebIPVid数据集上的实验结果表明，其在面部相似性方面比现有T2V方法平均提高了5%以上，证明了其在保持身份一致性和生成精细细节方面的有效性。

Conclusion: MoCA通过将MoCA层嵌入到每个DiT块中，并结合分层时间池（Hierarchical Temporal Pooling）和时间感知交叉注意力专家（Temporal-Aware Cross-Attention Experts），以及潜在视频感知损失（Latent Video Perceptual Loss），在保持身份一致性和面部细节方面取得了显著进步，并在CelebIPVid数据集上实现了超过5%的面部相似性提升。

Abstract: Achieving ID-preserving text-to-video (T2V) generation remains challenging
despite recent advances in diffusion-based models. Existing approaches often
fail to capture fine-grained facial dynamics or maintain temporal identity
coherence. To address these limitations, we propose MoCA, a novel Video
Diffusion Model built on a Diffusion Transformer (DiT) backbone, incorporating
a Mixture of Cross-Attention mechanism inspired by the Mixture-of-Experts
paradigm. Our framework improves inter-frame identity consistency by embedding
MoCA layers into each DiT block, where Hierarchical Temporal Pooling captures
identity features over varying timescales, and Temporal-Aware Cross-Attention
Experts dynamically model spatiotemporal relationships. We further incorporate
a Latent Video Perceptual Loss to enhance identity coherence and fine-grained
details across video frames. To train this model, we collect CelebIPVid, a
dataset of 10,000 high-resolution videos from 1,000 diverse individuals,
promoting cross-ethnicity generalization. Extensive experiments on CelebIPVid
show that MoCA outperforms existing T2V methods by over 5% across Face
similarity.

</details>


### [28] [VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering](https://arxiv.org/abs/2508.03039)
*Yiran Meng,Junhong Ye,Wei Zhou,Guanghui Yue,Xudong Mao,Ruomei Wang,Baoquan Zhao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Cross-video question answering presents significant challenges beyond
traditional single-video understanding, particularly in establishing meaningful
connections across video streams and managing the complexity of multi-source
information retrieval. We introduce VideoForest, a novel framework that
addresses these challenges through person-anchored hierarchical reasoning. Our
approach leverages person-level features as natural bridge points between
videos, enabling effective cross-video understanding without requiring
end-to-end training. VideoForest integrates three key innovations: 1) a
human-anchored feature extraction mechanism that employs ReID and tracking
algorithms to establish robust spatiotemporal relationships across multiple
video sources; 2) a multi-granularity spanning tree structure that
hierarchically organizes visual content around person-level trajectories; and
3) a multi-agent reasoning framework that efficiently traverses this
hierarchical structure to answer complex cross-video queries. To evaluate our
approach, we develop CrossVideoQA, a comprehensive benchmark dataset
specifically designed for person-centric cross-video analysis. Experimental
results demonstrate VideoForest's superior performance in cross-video reasoning
tasks, achieving 71.93% accuracy in person recognition, 83.75% in behavior
analysis, and 51.67% in summarization and reasoning, significantly
outperforming existing methods. Our work establishes a new paradigm for
cross-video understanding by unifying multiple video streams through
person-level features, enabling sophisticated reasoning across distributed
visual information while maintaining computational efficiency.

</details>


### [29] [Multi-human Interactive Talking Dataset](https://arxiv.org/abs/2508.03050)
*Zeyu Zhu,Weijia Wu,Mike Zheng Shou*

Main category: cs.CV

TL;DR: MIT：一个大规模多人对话视频生成数据集，以及用于处理多人姿态和音频交互的CovOG模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单人讲话视频生成和孤立的面部动画，限制了其在真实多人交互场景中的应用。因此，需要一个专门针对多人对话视频生成的数据集和模型。

Method: 开发了一个自动化的数据收集和标注流程，创建了包含12小时高分辨率、多人（2-4名发言人）对话的MIT数据集，并提出了整合了多人类姿态编码器（MPE）和交互式音频驱动器（IAD）的CovOG基线模型。

Result: MIT数据集包含了大规模、细粒度的多人对话视频数据，CovOG模型展示了处理多发言人姿态和音频特征以生成对话视频的可行性。

Conclusion: MIT数据集的提出和CovOG基线模型的开发，为多发言人对话视频生成的研究提供了有价值的资源和基准，展示了该领域的挑战和潜力。

Abstract: Existing studies on talking video generation have predominantly focused on
single-person monologues or isolated facial animations, limiting their
applicability to realistic multi-human interactions. To bridge this gap, we
introduce MIT, a large-scale dataset specifically designed for multi-human
talking video generation. To this end, we develop an automatic pipeline that
collects and annotates multi-person conversational videos. The resulting
dataset comprises 12 hours of high-resolution footage, each featuring two to
four speakers, with fine-grained annotations of body poses and speech
interactions. It captures natural conversational dynamics in multi-speaker
scenario, offering a rich resource for studying interactive visual behaviors.
To demonstrate the potential of MIT, we furthur propose CovOG, a baseline model
for this novel task. It integrates a Multi-Human Pose Encoder (MPE) to handle
varying numbers of speakers by aggregating individual pose embeddings, and an
Interactive Audio Driver (IAD) to modulate head dynamics based on
speaker-specific audio features. Together, these components showcase the
feasibility and challenges of generating realistic multi-human talking videos,
establishing MIT as a valuable benchmark for future research. The code is
avalibale at: https://github.com/showlab/Multi-human-Talking-Video-Dataset.

</details>


### [30] [Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation](https://arxiv.org/abs/2508.03055)
*Hyebin Cho,Jaehyup Lee*

Main category: cs.CV

TL;DR: FaceMat is a new framework for face matting that handles occlusions by estimating alpha mattes, using a two-stage distillation process, and requires no auxiliary inputs, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Face filters' performance degrades in the presence of occlusions (hands, hair, accessories obscuring the face). The novel task of face matting is introduced to estimate fine-grained alpha mattes to separate occluding elements from facial regions.

Method: FaceMat leverages a two-stage training pipeline: a teacher model is trained to jointly estimate alpha mattes and per-pixel uncertainty using a negative log-likelihood (NLL) loss, and this uncertainty is then used to guide the student model through spatially adaptive knowledge distillation. The approach reformulates the matting objective by explicitly treating skin as foreground and occlusions as background. It also introduces CelebAMat, a large-scale synthetic dataset for occlusion-aware face matting.

Result: FaceMat predicts high-quality alpha mattes under complex occlusions, requires no auxiliary inputs (trimaps or segmentation masks), making it suitable for real-time applications, and achieves better performance than previous methods.

Conclusion: FaceMat outperforms state-of-the-art methods across multiple benchmarks, enhancing the visual quality and robustness of face filters in real-world, unconstrained video scenarios.

Abstract: Face filters have become a key element of short-form video content, enabling
a wide array of visual effects such as stylization and face swapping. However,
their performance often degrades in the presence of occlusions, where objects
like hands, hair, or accessories obscure the face. To address this limitation,
we introduce the novel task of face matting, which estimates fine-grained alpha
mattes to separate occluding elements from facial regions. We further present
FaceMat, a trimap-free, uncertainty-aware framework that predicts high-quality
alpha mattes under complex occlusions. Our approach leverages a two-stage
training pipeline: a teacher model is trained to jointly estimate alpha mattes
and per-pixel uncertainty using a negative log-likelihood (NLL) loss, and this
uncertainty is then used to guide the student model through spatially adaptive
knowledge distillation. This formulation enables the student to focus on
ambiguous or occluded regions, improving generalization and preserving semantic
consistency. Unlike previous approaches that rely on trimaps or segmentation
masks, our framework requires no auxiliary inputs making it well-suited for
real-time applications. In addition, we reformulate the matting objective by
explicitly treating skin as foreground and occlusions as background, enabling
clearer compositing strategies. To support this task, we newly constructed
CelebAMat, a large-scale synthetic dataset specifically designed for
occlusion-aware face matting. Extensive experiments show that FaceMat
outperforms state-of-the-art methods across multiple benchmarks, enhancing the
visual quality and robustness of face filters in real-world, unconstrained
video scenarios. The source code and CelebAMat dataset are available at
https://github.com/hyebin-c/FaceMat.git

</details>


### [31] [CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation](https://arxiv.org/abs/2508.03060)
*Lekang Wen,Jing Xiao,Liang Liao,Jiajun Chen,Mi Wang*

Main category: cs.CV

TL;DR: CHARM, a new framework for Modality-agnostic Semantic Segmentation (MaSS), achieves better performance by harmonizing modalities instead of homogenizing them. It uses a Mutual Perception Unit (MPU) for implicit alignment and a dual-path optimization strategy (CoL and InE) for complementary learning and modality-specific optimization. CHARM outperforms existing methods, especially on fragile modalities.


<details>
  <summary>Details</summary>
Motivation: Existing methods for Modality-agnostic Semantic Segmentation (MaSS) typically rely on explicit feature alignment to achieve modal homogenization, which dilutes the distinctive strengths of each modality and destroys their inherent complementarity. The motivation is to achieve cooperative harmonization rather than homogenization.

Method: CHARM is a novel complementary learning framework designed to implicitly align content while preserving modality-specific advantages through two components: (1) Mutual Perception Unit (MPU) enabling implicit alignment through window-based cross-modal interaction, where modalities serve as both queries and contexts for each other to discover modality-interactive correspondences; (2) A dual-path optimization strategy that decouples training into Collaborative Learning Strategy (CoL) for complementary fusion learning and Individual Enhancement Strategy (InE) for protected modality-specific optimization.

Result: Experiments across multiple datasets and backbones indicate that CHARM consistently outperforms the baselines, with significant increment on the fragile modalities.

Conclusion: CHARM shifts the focus from model homogenization to harmonization, enabling cross-modal complementarity for true harmony in diversity, and consistently outperforms baselines with significant increment on fragile modalities.

Abstract: Modality-agnostic Semantic Segmentation (MaSS) aims to achieve robust scene
understanding across arbitrary combinations of input modality. Existing methods
typically rely on explicit feature alignment to achieve modal homogenization,
which dilutes the distinctive strengths of each modality and destroys their
inherent complementarity. To achieve cooperative harmonization rather than
homogenization, we propose CHARM, a novel complementary learning framework
designed to implicitly align content while preserving modality-specific
advantages through two components: (1) Mutual Perception Unit (MPU), enabling
implicit alignment through window-based cross-modal interaction, where
modalities serve as both queries and contexts for each other to discover
modality-interactive correspondences; (2) A dual-path optimization strategy
that decouples training into Collaborative Learning Strategy (CoL) for
complementary fusion learning and Individual Enhancement Strategy (InE) for
protected modality-specific optimization. Experiments across multiple datasets
and backbones indicate that CHARM consistently outperform the baselines, with
significant increment on the fragile modalities. This work shifts the focus
from model homogenization to harmonization, enabling cross-modal
complementarity for true harmony in diversity.

</details>


### [32] [CORE-ReID: Comprehensive Optimization and Refinement through Ensemble fusion in Domain Adaptation for person re-identification](https://arxiv.org/abs/2508.03064)
*Trinh Quoc Nguyen,Oky Dicky Ardiansyah Prima,Katsuyoshi Hotta*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study introduces a novel framework, "Comprehensive Optimization and
Refinement through Ensemble Fusion in Domain Adaptation for Person
Re-identification (CORE-ReID)", to address an Unsupervised Domain Adaptation
(UDA) for Person Re-identification (ReID). The framework utilizes CycleGAN to
generate diverse data that harmonizes differences in image characteristics from
different camera sources in the pre-training stage. In the fine-tuning stage,
based on a pair of teacher-student networks, the framework integrates
multi-view features for multi-level clustering to derive diverse pseudo labels.
A learnable Ensemble Fusion component that focuses on fine-grained local
information within global features is introduced to enhance learning
comprehensiveness and avoid ambiguity associated with multiple pseudo-labels.
Experimental results on three common UDAs in Person ReID demonstrate
significant performance gains over state-of-the-art approaches. Additional
enhancements, such as Efficient Channel Attention Block and Bidirectional Mean
Feature Normalization mitigate deviation effects and adaptive fusion of global
and local features using the ResNet-based model, further strengthening the
framework. The proposed framework ensures clarity in fusion features, avoids
ambiguity, and achieves high ac-curacy in terms of Mean Average Precision,
Top-1, Top-5, and Top-10, positioning it as an advanced and effective solution
for the UDA in Person ReID. Our codes and models are available at
https://github.com/TrinhQuocNguyen/CORE-ReID.

</details>


### [33] [SSFMamba: Symmetry-driven Spatial-Frequency Feature Fusion for 3D Medical Image Segmentation](https://arxiv.org/abs/2508.03069)
*Bo Zhang,Yifan Zhang,Shuo Yan,Yu Bai,Zheng Zhang,Wu Liu,Xiuzhuang Zhou,Wendong Wang*

Main category: cs.CV

TL;DR: SSFMamba是一种基于Mamba的、由对称性驱动的空间-频域特征融合网络，用于3D医学图像分割。它通过结合空间域和频域的特征，并利用Mamba块进行融合，有效解决了传统方法在全局上下文建模和处理域间差异方面的不足，取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决空间域在3D医学图像分割中全局上下文建模能力有限的问题，新兴方法开始引入频域表示。然而，传统的特征提取策略往往忽略了频域信息的共轭对称性等独特性质，并且未能考虑到空间域和频域之间数据分布的基本差异，这可能会削弱频域表示的互补优势。

Method: SSFMamba采用互补的双分支架构，从空间域和频域提取特征，并利用Mamba块融合这些异构特征，以在保留全局上下文的同时增强局部细节。在频域分支中，利用Mamba提取全局上下文信息的能力，并结合频域特征的协同效应，以进一步增强全局建模。此外，还设计了3D多向扫描机制来加强局部和全局线索的融合。

Result: SSFMamba在BraTS2020和BraTS2023数据集上的大量实验表明，该方法在各种评估指标上始终优于最先进的方法。

Conclusion: SSFMamba在BraTS2020和BraTS2023数据集上的大量实验表明，该方法在各种评估指标上始终优于最先进的方法。

Abstract: In light of the spatial domain's limited capacity for modeling global context
in 3D medical image segmentation, emerging approaches have begun to incorporate
frequency domain representations. However, straightforward feature extraction
strategies often overlook the unique properties of frequency domain
information, such as conjugate symmetry. They also fail to account for the
fundamental differences in data distribution between the spatial and frequency
domains, which can ultimately dilute or obscure the complementary strengths
that frequency-based representations offer. In this paper, we propose SSFMamba,
a Mamba based Symmetry-driven Spatial-Frequency feature fusion network for 3D
medical image segmentation. SSFMamba employs a complementary dual-branch
architecture that extracts features from both the spatial and frequency
domains, and leverages a Mamba block to fuse these heterogeneous features to
preserve global context while reinforcing local details. In the frequency
domain branch, we harness Mamba's exceptional capability to extract global
contextual information in conjunction with the synergistic effect of frequency
domain features to further enhance global modeling. Moreover, we design a 3D
multi-directional scanning mechanism to strengthen the fusion of local and
global cues. Extensive experiments on the BraTS2020 and BraTS2023 datasets
demonstrate that our approach consistently outperforms state-of-the-art methods
across various evaluation metrics.

</details>


### [34] [RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions](https://arxiv.org/abs/2508.03077)
*Anran Wu,Long Peng,Xin Di,Xueyuan Dai,Chen Wu,Yang Wang,Xueyang Fu,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: RobustGS通过特征增强模块提升前馈3DGS在恶劣成像条件下的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有前馈3DGS方法通常假设输入图像质量高且无瑕疵，但在现实场景中，图像常包含噪声、弱光或雨水等退化因素，导致几何不准确和3D重建质量下降。因此，需要一种方法来提高前馈3DGS在恶劣成像条件下的鲁棒性。

Method: 提出了一种名为RobustGS的多视图特征增强模块，该模块包含广义退化学习器（Generalized Degradation Learner）和语义感知状态空间模型（semantic-aware state-space model）。广义退化学习器用于提取输入图像的退化表示和分布，增强退化感知能力。语义感知状态空间模型则利用提取的退化表示增强特征空间中的输入，并通过语义感知策略聚合跨视图信息，以提取细粒度的跨视图对应关系，提升3D表示质量。

Result: 实验证明，RobustGS模块即插即用地集成到现有方法中后，在多种退化类型下均能持续获得最先进的重建质量，显著提高了3D重建的鲁棒性和整体质量。

Conclusion: RobustGS通过引入广义退化学习器和语义感知状态空间模型，能够有效提升前馈3DGS方法在噪声、弱光或雨天等恶劣成像条件下的鲁棒性，实现高质量3D重建，并且可以即插即用地集成到现有预训练的3DGS流程中。

Abstract: Feedforward 3D Gaussian Splatting (3DGS) overcomes the limitations of
optimization-based 3DGS by enabling fast and high-quality reconstruction
without the need for per-scene optimization. However, existing feedforward
approaches typically assume that input multi-view images are clean and
high-quality. In real-world scenarios, images are often captured under
challenging conditions such as noise, low light, or rain, resulting in
inaccurate geometry and degraded 3D reconstruction. To address these
challenges, we propose a general and efficient multi-view feature enhancement
module, RobustGS, which substantially improves the robustness of feedforward
3DGS methods under various adverse imaging conditions, enabling high-quality 3D
reconstruction. The RobustGS module can be seamlessly integrated into existing
pretrained pipelines in a plug-and-play manner to enhance reconstruction
robustness. Specifically, we introduce a novel component, Generalized
Degradation Learner, designed to extract generic representations and
distributions of multiple degradations from multi-view inputs, thereby
enhancing degradation-awareness and improving the overall quality of 3D
reconstruction. In addition, we propose a novel semantic-aware state-space
model. It first leverages the extracted degradation representations to enhance
corrupted inputs in the feature space. Then, it employs a semantic-aware
strategy to aggregate semantically similar information across different views,
enabling the extraction of fine-grained cross-view correspondences and further
improving the quality of 3D representations. Extensive experiments demonstrate
that our approach, when integrated into existing methods in a plug-and-play
manner, consistently achieves state-of-the-art reconstruction quality across
various types of degradations.

</details>


### [35] [Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models](https://arxiv.org/abs/2508.03079)
*Zaiying Zhao,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 本研究通过构建偏见属性知识库，发现LVLMs在文化、环境和行为等细粒度属性上存在偏见，这些因素对模型决策的影响甚至超过了种族和性别等传统属性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注人口统计属性（如种族、性别）的公平性，而对更广泛属性的公平性研究尚不充分，因此需要对LVLMs的公平性进行更广泛的探索。

Method: 利用LLMs构建了一个开放集偏见属性知识库，并在此基础上评估了LVLMs在更细粒度属性上的公平性。

Result: 实验结果表明，LVLMs在多种属性上存在偏见输出，并且文化、环境和行为因素比传统人口统计属性对LVLM决策有更显著的影响。

Conclusion: LVLMs在广泛的属性上表现出有偏见的输出，其中文化、环境和行为因素对LVLM决策的影响比传统人口统计属性更为显著。

Abstract: The rapid expansion of applications using Large Vision-Language Models
(LVLMs), such as GPT-4o, has raised significant concerns about their fairness.
While existing studies primarily focus on demographic attributes such as race
and gender, fairness across a broader range of attributes remains largely
unexplored. In this study, we construct an open-set knowledge base of bias
attributes leveraging Large Language Models (LLMs) and evaluate the fairness of
LVLMs across finer-grained attributes. Our experimental results reveal that
LVLMs exhibit biased outputs across a diverse set of attributes and further
demonstrate that cultural, environmental, and behavioral factors have a more
pronounced impact on LVLM decision-making than traditional demographic
attributes.

</details>


### [36] [Contrastive Cross-Bag Augmentation for Multiple Instance Learning-based Whole Slide Image Classification](https://arxiv.org/abs/2508.03081)
*Bo Zhang,Xu Xinan,Shuo Yan,Yu Bai,Zheng Zhang,Wufan Wang,Wendong Wang*

Main category: cs.CV

TL;DR: $C^2Aug$ enhances MIL-based WSI classification by improving data diversity and feature learning, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Limited diversity in pseudo-bag augmentation for MIL-based WSI classification and reduced model performance on slides with small tumor areas due to an increased number of critical instances.

Method: Introduced Contrastive Cross-Bag Augmentation ($C^2Aug$) to sample instances from all bags of the same class, and a bag-level and group-level contrastive learning framework to enhance feature discrimination.

Result: Experimental results show $C^2Aug$ consistently outperforms state-of-the-art approaches across multiple evaluation metrics.

Conclusion: Proposed $C^2Aug$ method with contrastive learning framework improves MIL-based WSI classification by increasing pseudo-bag diversity and enhancing feature discrimination.

Abstract: Recent pseudo-bag augmentation methods for Multiple Instance Learning
(MIL)-based Whole Slide Image (WSI) classification sample instances from a
limited number of bags, resulting in constrained diversity. To address this
issue, we propose Contrastive Cross-Bag Augmentation ($C^2Aug$) to sample
instances from all bags with the same class to increase the diversity of
pseudo-bags. However, introducing new instances into the pseudo-bag increases
the number of critical instances (e.g., tumor instances). This increase results
in a reduced occurrence of pseudo-bags containing few critical instances,
thereby limiting model performance, particularly on test slides with small
tumor areas. To address this, we introduce a bag-level and group-level
contrastive learning framework to enhance the discrimination of features with
distinct semantic meanings, thereby improving model performance. Experimental
results demonstrate that $C^2Aug$ consistently outperforms state-of-the-art
approaches across multiple evaluation metrics.

</details>


### [37] [Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts](https://arxiv.org/abs/2508.03094)
*Jiantao Tan,Peixian Ma,Kanghao Chen,Zhiming Dai,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出了一种利用LLM生成的视觉概念来增强医学图像分类中持续学习的方法，通过跨模态注意力融合图像和概念特征，在实验中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在利用文本模态信息时仅依赖于具有类名的简单模板，忽略了更丰富的语义信息的问题。

Method: 提出了一种新颖的框架，利用大型语言模型（LLMs）生成的视觉概念作为判别性语义指导。该方法动态构建视觉概念池，并使用基于相似度的过滤机制来防止冗余。然后，采用跨模态图像-概念注意力模块和注意力损失来将概念集成到持续学习过程中。

Result: 通过注意力机制，该模块可以利用相关视觉概念的语义知识，并为分类产生具有代表性的融合特征。

Conclusion: 该方法在医学和自然图像数据集上实现了最先进的性能，证明了其有效性和优越性。

Abstract: Continual learning is essential for medical image classification systems to
adapt to dynamically evolving clinical environments. The integration of
multimodal information can significantly enhance continual learning of image
classes. However, while existing approaches do utilize textual modality
information, they solely rely on simplistic templates with a class name,
thereby neglecting richer semantic information. To address these limitations,
we propose a novel framework that harnesses visual concepts generated by large
language models (LLMs) as discriminative semantic guidance. Our method
dynamically constructs a visual concept pool with a similarity-based filtering
mechanism to prevent redundancy. Then, to integrate the concepts into the
continual learning process, we employ a cross-modal image-concept attention
module, coupled with an attention loss. Through attention, the module can
leverage the semantic knowledge from relevant visual concepts and produce
class-representative fused features for classification. Experiments on medical
and natural image datasets show our method achieves state-of-the-art
performance, demonstrating the effectiveness and superiority of our method. We
will release the code publicly.

</details>


### [38] [AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video](https://arxiv.org/abs/2508.03100)
*Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: AVATAR是一个改进的多模态推理框架，通过离轨训练和时间优势塑造提高了数据效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推理方法（如GRPO）在长视频推理方面存在数据效率低、优势递减和信用分配不均等问题，阻碍了其在该领域的应用。

Method: AVATAR框架包含两个核心组件：1. 离轨训练架构，通过复用过去的经验和增加奖励多样性来提高样本效率并解决优势递减问题。2. 时间优势塑造（TAS）是一种新的信用分配策略，用于在学习过程中增加关键推理阶段的权重。

Result: AVATAR在MMVU上比Qwen2.5-Omni基线提高了+5.4，在OmniBench上提高了+4.9，在Video-Holmes上提高了+4.5，同时样本效率提高了35%以上。

Conclusion: AVATAR框架通过采用离轨训练架构和时间优势塑造（TAS）策略，成功解决了多模态推理中的数据效率低下、优势递减和信用分配不均等问题，并在MMVU、OmniBench和Video-Holmes等基准测试中取得了显著的性能提升，同时样本效率也提高了35%以上。

Abstract: Multimodal reasoning over long-horizon video is challenging due to the need
for precise spatiotemporal fusion and alignment across modalities. While recent
methods such as Group Relative Policy Optimization (GRPO) have shown promise in
this domain, they suffer from three key limitations: (1) data inefficiency from
their on-policy design, (2) a vanishing advantage problem, where identical or
near-identical rewards within a group eliminate the learning signal by
producing zero-valued advantages, and (3) uniform credit assignment that fails
to emphasize critical reasoning steps. We introduce AVATAR (Audio-Video Agent
for Alignment and Reasoning), a framework that addresses these limitations
through two core components: (1) an off-policy training architecture that
improves sample efficiency and resolves vanishing advantages by reusing past
experiences with greater reward diversity, and (2) Temporal Advantage Shaping
(TAS), a novel credit assignment strategy that upweights key reasoning phases
during learning. AVATAR achieves strong performance across various benchmarks,
outperforming the Qwen2.5-Omni baseline by +5.4on MMVU, +4.9 on OmniBench, and
+4.5 on Video-Holmes, while demonstrating over 35% higher sample efficiency.

</details>


### [39] [Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning](https://arxiv.org/abs/2508.03102)
*Tianjiao Jiang,Zhen Zhang,Yuhang Liu,Javen Qinfeng Shi*

Main category: cs.CV

TL;DR: CCA框架通过使用ICA解耦CLIP的视觉特征，并利用跨注意力机制增强跨模态对齐，提升了少样本学习的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有少样本学习（FSL）方法通常依赖于纠缠的表示，需要模型仅利用有限的监督来隐式地学习解混过程以获得解耦的表示，这会阻碍有效的适应。本研究旨在解决这一问题，提出一种能够显式解耦视觉特征并增强跨模态对齐的框架，以提高少样本学习的适应性和性能。

Method: 本研究提出了一种名为CCA（Causal CLIP Adapter）的新框架。CCA首先使用无监督独立成分分析（ICA）显式解耦从CLIP提取的视觉特征，以获得解耦的表示，从而减少了可训练参数并缓解了过拟合。随后，为了弥补ICA可能破坏CLIP的模态内和跨模态对齐，CCA通过两个途径增强了CLIP固有的跨模态对齐：一是通过微调基于CLIP的文本分类器进行单向增强；二是通过跨注意力机制进行双向增强，实现视觉和文本表示的相互丰富。最后，通过线性组合单模态和跨模态分类输出来提升分类准确率。

Result: CCA在11个基准数据集上的大量实验表明，该方法在少样本性能和对分布偏移的鲁棒性方面持续优于最先进的方法，同时保持了计算效率。

Conclusion: 该研究提出的CCA框架通过显式解耦视觉特征并增强CLIP的跨模态对齐，在少样本学习任务中取得了优于现有方法的效果，并在多个基准数据集上证明了其性能和鲁棒性。

Abstract: Few-shot learning (FSL) often requires effective adaptation of models using
limited labeled data. However, most existing FSL methods rely on entangled
representations, requiring the model to implicitly recover the unmixing process
to obtain disentangled representations using only limited supervision, which
hinders effective adaptation. Recent theoretical studies show that multimodal
contrastive learning methods, such as CLIP, can disentangle latent
representations up to linear transformations. In light of this, we propose the
Causal CLIP Adapter (CCA), a novel framework that explicitly disentangles
visual features extracted from CLIP using unsupervised Independent Component
Analysis (ICA). This removes the need to learn the unmixing process from the
labeled data, thereby reducing the number of trainable parameters and
mitigating overfitting. Taking a step further, while ICA can obtain visual
disentangled representations, it may also disrupt CLIP's intra- and inter-modal
alignment. To counteract this, CCA further leverages CLIP's inherent
cross-modal alignment by enhancing it in two ways: unidirectionally, through
fine-tuning a CLIP-based text classifier, and bidirectionally, via a
cross-attention mechanism that enriches visual and textual representations
through mutual interaction. Both unimodal and cross-modal classification
outputs can be effectively combined linearly to improve classification
accuracy. Extensive experiments on 11 benchmark datasets demonstrate that our
method consistently outperforms state-of-the-art approaches in terms of
few-shot performance and robustness to distributional shifts, while maintaining
computational efficiency. Code will be available at
https://github.com/tianjiao-j/CCA.

</details>


### [40] [H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction](https://arxiv.org/abs/2508.03118)
*Heng Jia,Linchao Zhu,Na Zhao*

Main category: cs.CV

TL;DR: H3R是一个混合3D重建框架，结合了体素潜在融合和注意力机制，提高了泛化性和收敛速度，并在多个数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法在几何精度和鲁棒性之间存在权衡，显式方法在模糊区域表现不佳，隐式方法收敛缓慢。H3R旨在通过混合方法克服这些限制，提高泛化性和收敛速度。

Method: 提出了一种混合框架H3R，结合了体素潜在融合和基于注意力的特征聚合。该框架包含一个强制几何一致性的高效潜在体素和一个利用Plücker坐标进行自适应对应细化的相机感知Transformer。

Result: H3R框架在RealEstate10K、ACID和DTU数据集上分别实现了0.59 dB、1.06 dB和0.22 dB的PSNR提升，并且比现有方法收敛速度快2倍。实验表明空间对齐的基础模型优于语义对齐的模型，并且该方法支持可变数量和高分辨率的输入视图，具有良好的跨数据集泛化能力。

Conclusion: H3R框架通过结合体素潜在融合和基于注意力的特征聚合，解决了前馈3D高斯泼溅法在多视图对应建模中的泛化性挑战，实现了比现有方法快2倍的收敛速度，并在多个基准测试中取得了最先进的性能，PSNR分别提高了0.59 dB、1.06 dB和0.22 dB。

Abstract: Despite recent advances in feed-forward 3D Gaussian Splatting, generalizable
3D reconstruction remains challenging, particularly in multi-view
correspondence modeling. Existing approaches face a fundamental trade-off:
explicit methods achieve geometric precision but struggle with ambiguous
regions, while implicit methods provide robustness but suffer from slow
convergence. We present H3R, a hybrid framework that addresses this limitation
by integrating volumetric latent fusion with attention-based feature
aggregation. Our framework consists of two complementary components: an
efficient latent volume that enforces geometric consistency through epipolar
constraints, and a camera-aware Transformer that leverages Pl\"ucker
coordinates for adaptive correspondence refinement. By integrating both
paradigms, our approach enhances generalization while converging 2$\times$
faster than existing methods. Furthermore, we show that spatial-aligned
foundation models (e.g., SD-VAE) substantially outperform semantic-aligned
models (e.g., DINOv2), resolving the mismatch between semantic representations
and spatial reconstruction requirements. Our method supports variable-number
and high-resolution input views while demonstrating robust cross-dataset
generalization. Extensive experiments show that our method achieves
state-of-the-art performance across multiple benchmarks, with significant PSNR
improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and
DTU datasets, respectively. Code is available at
https://github.com/JiaHeng-DLUT/H3R.

</details>


### [41] [Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery](https://arxiv.org/abs/2508.03127)
*Sai Ma,Zhuang Li,John A Taylor*

Main category: cs.CV

TL;DR: 本研究提出了Landsat30-AU数据集，以解决现有VLM在理解长期、低分辨率卫星图像方面的不足。通过对Qwen2.5-VL-7B模型进行微调，显著提升了其在遥感图像描述和问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）数据集主要关注短期、高分辨率的卫星图像，忽视了像Landsat这样对全球监测至关重要的低分辨率、多卫星、长期存档数据。这限制了VLM在地球观测领域的应用，如加速专家工作流、使非专业人士能够访问数据以及实现大规模自动化。

Method: 该研究提出了Landsat30-AU数据集，包含Landsat30-AU-Cap（196,262个图像-标题对）和Landsat30-AU-VQA（17,725个视觉问答样本），覆盖澳大利亚36年来的Landsat卫星图像。数据集的构建采用了自举流水线，结合通用VLM、迭代优化和人工验证。通过评估八种VLM在Landsat30-AU上的表现，并展示了通过轻量级微调Qwen2.5-VL-7B模型可以显著提升其在遥感图像理解任务上的性能。

Result: 在Landsat30-AU基准测试中，八种VLM的表现不佳，其中EarthDial在图像描述方面的SPIDEr得分仅为0.07，视觉问答准确率仅为0.48。然而，通过在Landsat30-AU上对Qwen2.5-VL-7B进行轻量级微调，其图像描述性能从0.11提升至0.31 SPIDEr，视觉问答准确率从0.74提升至0.87。

Conclusion: 现有的视觉语言模型（VLM）在理解卫星图像方面存在不足，特别是在处理Landsat等长期、低分辨率的地球观测数据时。通过使用Landsat30-AU数据集对Qwen2.5-VL-7B等模型进行微调，可以显著提高其在图像描述和视觉问答任务上的性能，为地球观测领域的普及和自动化提供了新的途径。

Abstract: Vision language models (VLMs) that enable natural language interaction with
satellite imagery can democratize Earth observation by accelerating expert
workflows, making data accessible to non-specialists, and enabling planet-scale
automation. However, existing datasets focus mainly on short-term,
high-resolution imagery from a limited number of satellites, overlooking
low-resolution, multi-satellite, long-term archives, such as Landsat, that are
essential for affordable and bias-robust global monitoring. We address this gap
with Landsat30-AU, a large-scale vision-language dataset built from 30-meter
resolution imagery collected by four Landsat satellites (5, 7, 8, and 9) over
Australia, spanning more than 36 years. The dataset includes two components:
Landsat30-AU-Cap, containing 196,262 image-caption pairs, and Landsat30-AU-VQA,
comprising 17,725 human-verified visual question answering (VQA) samples across
eight remote sensing domains. Both datasets are curated through a bootstrapped
pipeline that leverages generic VLMs with iterative refinement and human
verification to ensure quality. Our evaluation of eight VLMs on our benchmark
reveals that off-the-shelf models struggle to understand satellite imagery. The
open-source remote-sensing VLM EarthDial achieves only 0.07 SPIDEr in
captioning and a VQA accuracy of 0.48, highlighting the limitations of current
approaches. Encouragingly, lightweight fine-tuning of Qwen2.5-VL-7B on
Landsat30-AU improves captioning performance from 0.11 to 0.31 SPIDEr and
boosts VQA accuracy from \textbf{0.74} to 0.87. Code and data are available at
https://github.com/papersubmit1/landsat30-au.

</details>


### [42] [COFFEE: A Shadow-Resilient Real-Time Pose Estimator for Unknown Tumbling Asteroids using Sparse Neural Networks](https://arxiv.org/abs/2508.03132)
*Arion Zimmermann,Soon-Jo Chung,Fred Hadaegh*

Main category: cs.CV

TL;DR: COFFEE是一种新的实时姿态估计框架，通过利用太阳相位角信息和稀疏特征来处理阴影，实现了高精度、无偏差且高效的天体姿态估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的特征提取和姿态估计方法在处理太空图像时面临挑战，如SIFT、ORB和AKAZE等方法虽然实时但精度不足，而深度学习方法计算资源需求高，不适用于太空硬件。此外，这两种方法都无法有效处理物体上的自投射阴影，可能导致姿态估计偏差，尤其是在目标天体进行混沌翻滚运动时，这可能导致任务失败。

Method: COFFEE框架利用了太阳跟踪传感器提供关于太阳相位角先验信息，通过将显著轮廓与其投影阴影相关联，检测出对阴影运动不变的稀疏特征。随后，结合稀疏神经网络和基于注意力的图神经网络特征匹配模型进行联合训练，以提供连续帧之间的对应关系。

Result: COFFEE框架在合成数据和Apophis小行星渲染数据上进行了测试，结果表明其姿态估计是无偏差的，精度优于经典的姿态估计方法，并且比其他最先进的深度学习方法快一个数量级。

Conclusion: COFFEE框架是一种新颖的实时姿态估计方法，能够克服现有方法的局限性，尤其在处理天体遮挡和阴影方面表现出色。通过结合稀疏神经网络和基于注意力的图神经网络，COFFEE实现了高精度、无偏差且高效的姿态估计，为空间碎片跟踪和小天体形状估计等应用提供了关键支持。

Abstract: The accurate state estimation of unknown bodies in space is a critical
challenge with applications ranging from the tracking of space debris to the
shape estimation of small bodies. A necessary enabler to this capability is to
find and track features on a continuous stream of images. Existing methods,
such as SIFT, ORB and AKAZE, achieve real-time but inaccurate pose estimates,
whereas modern deep learning methods yield higher quality features at the cost
of more demanding computational resources which might not be available on
space-qualified hardware. Additionally, both classical and data-driven methods
are not robust to the highly opaque self-cast shadows on the object of
interest. We show that, as the target body rotates, these shadows may lead to
large biases in the resulting pose estimates. For these objects, a bias in the
real-time pose estimation algorithm may mislead the spacecraft's state
estimator and cause a mission failure, especially if the body undergoes a
chaotic tumbling motion. We present COFFEE, the Celestial Occlusion Fast
FEature Extractor, a real-time pose estimation framework for asteroids designed
to leverage prior information on the sun phase angle given by sun-tracking
sensors commonly available onboard spacecraft. By associating salient contours
to their projected shadows, a sparse set of features are detected, invariant to
the motion of the shadows. A Sparse Neural Network followed by an
attention-based Graph Neural Network feature matching model are then jointly
trained to provide a set of correspondences between successive frames. The
resulting pose estimation pipeline is found to be bias-free, more accurate than
classical pose estimation pipelines and an order of magnitude faster than other
state-of-the-art deep learning pipelines on synthetic data as well as on
renderings of the tumbling asteroid Apophis.

</details>


### [43] [Uint: Building Uint Detection Dataset](https://arxiv.org/abs/2508.03139)
*Haozhou Zhai,Yanzhe Gao,Tianjiang Hu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fire scene datasets are crucial for training robust computer vision models,
particularly in tasks such as fire early warning and emergency rescue
operations. However, among the currently available fire-related data, there is
a significant shortage of annotated data specifically targeting building
units.To tackle this issue, we introduce an annotated dataset of building units
captured by drones, which incorporates multiple enhancement techniques. We
construct backgrounds using real multi-story scenes, combine motion blur and
brightness adjustment to enhance the authenticity of the captured images,
simulate drone shooting conditions under various circumstances, and employ
large models to generate fire effects at different locations.The synthetic
dataset generated by this method encompasses a wide range of building
scenarios, with a total of 1,978 images. This dataset can effectively improve
the generalization ability of fire unit detection, providing multi-scenario and
scalable data while reducing the risks and costs associated with collecting
real fire data. The dataset is available at
https://github.com/boilermakerr/FireUnitData.

</details>


### [44] [UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying](https://arxiv.org/abs/2508.03142)
*Chengyu Bai,Jintao Chen,Xiang Bai,Yilong Chen,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: UniEdit-I是一个训练无关的框架，为统一VLM添加了图像编辑功能。它通过一个理解-编辑-验证的迭代循环来实现，该循环分析图像，根据编辑指令修改提示，并迭代地细化编辑过程，最终实现高质量的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 在现有统一视觉语言模型（VLM）设计的基础上，探索一种新的训练无关框架，以实现图像编辑能力，并解决了现有方法中未探索的图像编辑的易用性问题。

Method: UniEdit-I框架采用理解、编辑、验证的迭代过程：1. 理解步骤分析源图像并生成包含最小词语替换的目标提示。2. 编辑步骤引入时间自适应偏移，实现从粗到精的连贯编辑。3. 验证步骤检查目标提示与编辑后图像的一致性，提供评分和反馈，决定是否继续迭代。

Result: 在BLIP3-o模型基础上实现的UniEdit-I框架，在GEdit-Bench基准测试上取得了最先进的性能，展示了高保真度的训练无关图像编辑能力。

Conclusion: UniEdit-I通过一个包含理解、编辑和验证三个迭代步骤的训练无关框架，实现了统一视觉语言模型（VLM）的图像编辑能力。该框架利用BLIP3-o模型，并在GEdit-Bench基准测试中达到了最先进的性能。

Abstract: In recent years, unified vision-language models (VLMs) have rapidly advanced,
effectively tackling both visual understanding and generation tasks within a
single design. While many unified VLMs have explored various design choices,
the recent hypothesis from OpenAI's GPT-4o suggests a promising generation
pipeline: Understanding VLM->Visual Feature->Projector->Diffusion Model->Image.
The understanding VLM is frozen, and only the generation-related modules are
trained. This pipeline maintains the strong capability of understanding VLM
while enabling the image generation ability of the unified VLM. Although this
pipeline has shown very promising potential for the future development of
unified VLM, how to easily enable image editing capability is still unexplored.
In this paper, we introduce a novel training-free framework named UniEdit-I to
enable the unified VLM with image editing capability via three iterative steps:
understanding, editing, and verifying. 1. The understanding step analyzes the
source image to create a source prompt through structured semantic analysis and
makes minimal word replacements to form the target prompt based on the editing
instruction. 2. The editing step introduces a time-adaptive offset, allowing
for coherent editing from coarse to fine throughout the denoising process. 3.
The verification step checks the alignment between the target prompt and the
intermediate edited image, provides automatic consistency scores and corrective
feedback, and determines whether to stop early or continue the editing loop.
This understanding, editing, and verifying loop iterates until convergence,
delivering high-fidelity editing in a training-free manner. We implemented our
method based on the latest BLIP3-o and achieved state-of-the-art (SOTA)
performance on the GEdit-Bench benchmark.

</details>


### [45] [LRDDv2: Enhanced Long-Range Drone Detection Dataset with Range Information and Comprehensive Real-World Challenges](https://arxiv.org/abs/2508.03331)
*Amirreza Rouhi,Sneh Patel,Noah McCarthy,Siddiqa Khan,Hadi Khorsand,Kaleb Lefkowitz,David K. Han*

Main category: cs.CV

TL;DR: 研究提出了LRDDv2数据集，这是一个包含近4万张图像的大型数据集，专为远距离无人机检测设计，并包含距离信息，以应对现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAVs）使用量的指数增长，在远距离检测无人机以确保安全运行变得至关重要，尤其是在人口稠密的地区。尽管深度学习在计算机视觉领域取得了巨大进步，但检测这些小型空中目标仍然是一个严峻的挑战。现有的数据集在多样性和规模上仍有待提高，特别是在不同环境条件下的远距离检测方面。

Method: 通过收集和标注大量无人机图像，构建了一个名为LRDDv2的大型数据集，并提供了目标距离信息，以支持长距离无人机检测和距离估计算法的开发。

Result: 研究发布了LRDDv2数据集，包含39,516张标注图像，是LRDDv1的增强版本，提供了更多样化的图像数据。其中超过8000张图像包含目标距离信息，使得开发无人机距离估计算法成为可能。该数据集主要包含分辨率为1080p、无人机像素尺寸小于等于50像素的图像，非常适合长距离空中目标检测任务。

Conclusion: 该研究提出了LRDDv2数据集，这是一个包含39,516张标注图像的大型数据集，专为无人机检测和距离估计设计。该数据集包含了大量在不同环境下拍摄的无人机图像，其中8000多张图像带有目标距离信息，并且大部分图像中的无人机像素尺寸小于或等于50像素（1080p分辨率），特别适合长距离空中目标检测研究。

Abstract: The exponential growth in Unmanned Aerial Vehicles (UAVs) usage underscores
the critical need of detecting them at extended distances to ensure safe
operations, especially in densely populated areas. Despite the tremendous
advances made in computer vision through deep learning, the detection of these
small airborne objects remains a formidable challenge. While several datasets
have been developed specifically for drone detection, the need for a more
extensive and diverse collection of drone image data persists, particularly for
long-range detection under varying environmental conditions. We introduce here
the Long Range Drone Detection (LRDD) Version 2 dataset, comprising 39,516
meticulously annotated images, as a second release of the LRDD dataset released
previously. The LRDDv2 dataset enhances the LRDDv1 by incorporating a greater
variety of images, providing a more diverse and comprehensive resource for
drone detection research. What sets LRDDv2 apart is its inclusion of target
range information for over 8,000 images, making it possible to develop
algorithms for drone range estimation. Tailored for long-range aerial object
detection, the majority of LRDDv2's dataset consists of images capturing drones
with 50 or fewer pixels in 1080p resolution. For access to the complete
Long-Range Drone Detection Dataset (LRDD)v2, please visit
https://research.coe.drexel.edu/ece/imaple/lrddv2/ .

</details>


### [46] [SARD: Segmentation-Aware Anomaly Synthesis via Region-Constrained Diffusion with Discriminative Mask Guidance](https://arxiv.org/abs/2508.03143)
*Yanshu Wang,Xichen Xu,Xiaoning Lei,Guoyang Xie*

Main category: cs.CV

TL;DR: SARD通过区域约束扩散和判别性掩码引导，实现了空间可控、细节保真的工业异常合成，并在MVTec-AD和BTAD数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有基于扩散的方法在空间可控性和细粒度区域保真度方面的不足，以合成真实且空间精确的异常，从而提高工业异常检测系统的鲁棒性。

Method: SARD（Segmentation-Aware anomaly synthesis via Region-constrained Diffusion with discriminative mask Guidance）框架，包含区域约束扩散（RCD）过程和判别性掩码引导（DMG）模块。

Result: SARD在MVTec-AD和BTAD数据集上取得了优于现有方法的性能，在分割准确性和视觉质量方面表现出色，并在像素级异常合成方面达到了新的最先进水平。

Conclusion: SARD在MVTec-AD和BTAD数据集上的广泛实验表明，SARD在分割准确性和视觉质量方面均优于现有方法，为像素级异常合成设定了新的最先进水平。

Abstract: Synthesizing realistic and spatially precise anomalies is essential for
enhancing the robustness of industrial anomaly detection systems. While recent
diffusion-based methods have demonstrated strong capabilities in modeling
complex defect patterns, they often struggle with spatial controllability and
fail to maintain fine-grained regional fidelity. To overcome these limitations,
we propose SARD (Segmentation-Aware anomaly synthesis via Region-constrained
Diffusion with discriminative mask Guidance), a novel diffusion-based framework
specifically designed for anomaly generation. Our approach introduces a
Region-Constrained Diffusion (RCD) process that preserves the background by
freezing it and selectively updating only the foreground anomaly regions during
the reverse denoising phase, thereby effectively reducing background artifacts.
Additionally, we incorporate a Discriminative Mask Guidance (DMG) module into
the discriminator, enabling joint evaluation of both global realism and local
anomaly fidelity, guided by pixel-level masks. Extensive experiments on the
MVTec-AD and BTAD datasets show that SARD surpasses existing methods in
segmentation accuracy and visual quality, setting a new state-of-the-art for
pixel-level anomaly synthesis.

</details>


### [47] [OmniShape: Zero-Shot Multi-Hypothesis Shape and Pose Estimation in the Real World](https://arxiv.org/abs/2508.03669)
*Katherine Liu,Sergey Zakharov,Dian Chen,Takuya Ikeda,Greg Shakhnarovich,Adrien Gaidon,Rares Ambrus*

Main category: cs.CV

TL;DR: OmniShape 是一种新颖的方法，可以从单个观测中估计物体的姿态和完整形状，而无需依赖已知的 3D 模型或类别。它通过将形状补全分解为测量投影和几何先验，并利用条件扩散模型来实现这一点，从而能够生成多种假设并提供出色的性能。


<details>
  <summary>Details</summary>
Motivation: 从单个观测中估计物体的姿态和完整形状，而无需假设已知的 3D 模型或类别。

Method: OmniShape 的核心思想是将形状补全分解为两个多模态分布：一个捕获测量值如何投影到由数据集定义的归一化对象参考系中，另一个模拟对象几何的先验，表示为三平面神经网络。通过为这两个分布分别训练条件扩散模型，我们能够从联合姿态和形状分布中采样多个假设。

Result: OmniShape 是同类方法中的第一种，能够进行概率姿态和形状估计。

Conclusion: OmniShape 在具有挑战性的真实世界数据集上表现出引人注目的性能。

Abstract: We would like to estimate the pose and full shape of an object from a single
observation, without assuming known 3D model or category. In this work, we
propose OmniShape, the first method of its kind to enable probabilistic pose
and shape estimation. OmniShape is based on the key insight that shape
completion can be decoupled into two multi-modal distributions: one capturing
how measurements project into a normalized object reference frame defined by
the dataset and the other modelling a prior over object geometries represented
as triplanar neural fields. By training separate conditional diffusion models
for these two distributions, we enable sampling multiple hypotheses from the
joint pose and shape distribution. OmniShape demonstrates compelling
performance on challenging real world datasets. Project website:
https://tri-ml.github.io/omnishape

</details>


### [48] [LORE: Latent Optimization for Precise Semantic Control in Rectified Flow-based Image Editing](https://arxiv.org/abs/2508.03144)
*Liangyang Ouyang,Jiafeng Mao*

Main category: cs.CV

TL;DR: LORE是一种新的文本驱动图像编辑方法，通过优化噪声解决了现有方法的语义偏差问题，实现了更好的可控性和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流的逆转图像编辑方法存在结构性局限性：反转噪声中编码的源概念语义偏差会抑制对目标概念的关注，尤其是在源目标语义差异较大时，会导致编辑失败或非目标区域的非预期修改。

Method: LORE是一种训练无关且高效的图像编辑方法，它直接优化反转的噪声，以解决源概念的语义偏差问题。

Result: LORE在语义对齐、图像质量和背景保真度方面显著优于强基线，证明了其有效性和可扩展性。

Conclusion: LORE通过直接优化反转的噪声，解决了现有方法在泛化和可控性方面的局限性，实现了稳定、可控、通用的概念替换，无需修改架构或微调模型。在PIEBench、SmartEdit和GapEdit三个具有挑战性的基准上进行了全面评估，实验结果表明LORE在语义对齐、图像质量和背景保真度方面显著优于强基线，证明了潜在空间优化在通用图像编辑中的有效性和可扩展性。

Abstract: Text-driven image editing enables users to flexibly modify visual content
through natural language instructions, and is widely applied to tasks such as
semantic object replacement, insertion, and removal. While recent
inversion-based editing methods using rectified flow models have achieved
promising results in image quality, we identify a structural limitation in
their editing behavior: the semantic bias toward the source concept encoded in
the inverted noise tends to suppress attention to the target concept. This
issue becomes particularly critical when the source and target semantics are
dissimilar, where the attention mechanism inherently leads to editing failure
or unintended modifications in non-target regions. In this paper, we
systematically analyze and validate this structural flaw, and introduce LORE, a
training-free and efficient image editing method. LORE directly optimizes the
inverted noise, addressing the core limitations in generalization and
controllability of existing approaches, enabling stable, controllable, and
general-purpose concept replacement, without requiring architectural
modification or model fine-tuning. We conduct comprehensive evaluations on
three challenging benchmarks: PIEBench, SmartEdit, and GapEdit. Experimental
results show that LORE significantly outperforms strong baselines in terms of
semantic alignment, image quality, and background fidelity, demonstrating the
effectiveness and scalability of latent-space optimization for general-purpose
image editing.

</details>


### [49] [Veila: Panoramic LiDAR Generation from a Monocular RGB Image](https://arxiv.org/abs/2508.03690)
*Youquan Liu,Lingdong Kong,Weidong Yang,Ao Liang,Jianxiong Gao,Yang Wu,Xiang Xu,Xin Li,Linfeng Li,Runnan Chen,Ben Fei*

Main category: cs.CV

TL;DR: Veila通过结合置信感知条件机制、几何跨模态对齐和全景特征一致性，利用单目RGB图像生成逼真、可控的全景LiDAR数据，解决了现有方法的局限性，并提高了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR数据生成方法要么缺乏可控性，要么在空间控制方面不足。利用单目RGB图像作为空间控制信号是一种有前景的替代方案，但面临着来自RGB的语义和深度线索的空间变异性、RGB外观和LiDAR几何之间的模态差异以及保持单目RGB和全景LiDAR之间结构一致性的挑战。

Method: Veila是一个新颖的条件扩散框架，通过置信感知条件机制（CACM）自适应地平衡语义和深度线索，通过几何跨模态对齐（GCMA）实现稳健的RGB-LiDAR对齐，并利用全景特征一致性（PFC）强制执行全局结构一致性。

Result: Veila在nuScenes、SemanticKITTI和KITTI-Weather基准测试中实现了最先进的生成保真度和跨模态一致性，并通过生成数据增强提高了下游LiDAR语义分割的性能。

Conclusion: Veila通过其新颖的条件扩散框架，在生成逼真、可控的全景LiDAR数据方面取得了最先进的成果，并在下游任务中证明了其有效性。

Abstract: Realistic and controllable panoramic LiDAR data generation is critical for
scalable 3D perception in autonomous driving and robotics. Existing methods
either perform unconditional generation with poor controllability or adopt
text-guided synthesis, which lacks fine-grained spatial control. Leveraging a
monocular RGB image as a spatial control signal offers a scalable and low-cost
alternative, which remains an open problem. However, it faces three core
challenges: (i) semantic and depth cues from RGB are vary spatially,
complicating reliable conditioning generation; (ii) modality gaps between RGB
appearance and LiDAR geometry amplify alignment errors under noisy diffusion;
and (iii) maintaining structural coherence between monocular RGB and panoramic
LiDAR is challenging, particularly in non-overlap regions between images and
LiDAR. To address these challenges, we propose Veila, a novel conditional
diffusion framework that integrates: a Confidence-Aware Conditioning Mechanism
(CACM) that strengthens RGB conditioning by adaptively balancing semantic and
depth cues according to their local reliability; a Geometric Cross-Modal
Alignment (GCMA) for robust RGB-LiDAR alignment under noisy diffusion; and a
Panoramic Feature Coherence (PFC) for enforcing global structural consistency
across monocular RGB and panoramic LiDAR. Additionally, we introduce two
metrics, Cross-Modal Semantic Consistency and Cross-Modal Depth Consistency, to
evaluate alignment quality across modalities. Experiments on nuScenes,
SemanticKITTI, and our proposed KITTI-Weather benchmark demonstrate that Veila
achieves state-of-the-art generation fidelity and cross-modal consistency,
while enabling generative data augmentation that improves downstream LiDAR
semantic segmentation.

</details>


### [50] [ChartCap: Mitigating Hallucination of Dense Chart Captioning](https://arxiv.org/abs/2508.03164)
*Junyoung Lim,Jaewoo Ahn,Gunhee Kim*

Main category: cs.CV

TL;DR: 提出ChartCap数据集和视觉一致性分数，以改进图表标题生成，生成的标题比现有模型和人工标注的标题更好。


<details>
  <summary>Details</summary>
Motivation: 现有的图表数据集缺乏大规模、高质量的真实世界图表，并且包含无法从图表中推断出的无关信息，未能充分捕捉结构元素和关键见解。

Method: 通过设计一个包含四阶段的流程，利用图表中可识别的数据生成标题，并采用基于周期一致性的人工验证来加速质控。此外，还提出了一种新的评估指标——视觉一致性分数（Visual Consistency Score），用于评估标题质量。

Result: 在ChartCap上微调的模型在生成准确、信息丰富且减少幻觉的标题方面表现优于开源和专有模型，甚至优于人工标注的标题。

Conclusion: ChartCap数据集可以帮助模型生成更准确、信息更丰富且无幻觉的图表标题，并且在与现有模型和人工标注的标题进行比较时表现更优。

Abstract: Generating accurate, informative, and hallucination-free captions for charts
remains challenging for vision language models, primarily due to the lack of
large-scale, high-quality datasets of real-world charts. However, existing
real-world chart datasets suffer from the inclusion of extraneous information
that cannot be inferred from the chart and failure to sufficiently capture
structural elements and key insights. Therefore, we introduce ChartCap, a
large-scale dataset of 565K real-world chart images paired with type-specific,
dense captions that exclude extraneous information and highlight both
structural elements and key insights in detail. To build ChartCap, we design a
four-stage pipeline that generates captions using only the discernible data
from the chart and employ a cycle consistency-based human verification, which
accelerates quality control without sacrificing accuracy. Additionally, we
propose a novel metric, the Visual Consistency Score, which evaluates caption
quality by measuring the similarity between the chart regenerated from a
caption and the original chart, independent of reference captions. Extensive
experiments confirms that models fine-tuned on ChartCap consistently generate
more accurate and informative captions with reduced hallucinations, surpassing
both open-source and proprietary models and even human-annotated captions.

</details>


### [51] [La La LiDAR: Large-Scale Layout Generation from LiDAR Data](https://arxiv.org/abs/2508.03691)
*Youquan Liu,Lingdong Kong,Weidong Yang,Xin Li,Ao Liang,Runnan Chen,Ben Fei,Tongliang Liu*

Main category: cs.CV

TL;DR: La La LiDAR 通过引入语义增强的场景图扩散和关系感知上下文条件，实现了可控的激光雷达场景生成，解决了现有模型在前景对象和空间关系控制方面的不足，并在 Waymo-SG 和 nuScenes-SG 数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的基于扩散的模型在激光雷达生成方面虽然保真度高，但在前景对象和空间关系方面缺乏明确的控制，这限制了它们在场景模拟和安全验证方面的应用。本研究旨在解决这些局限性。

Method: 提出了一种名为“La La LiDAR”的新型布局引导生成框架，该框架引入了语义增强的场景图扩散，并结合了关系感知上下文条件，用于结构化激光雷达布局生成，随后进行面向前景的控制注入以实现完整场景生成。

Result: La La LiDAR 实现了可定制的对象放置控制，同时确保了空间和语义的一致性。

Conclusion: La La LiDAR 在激光雷达生成和下游感知任务方面均取得了最先进的性能，为可控的 3D 场景生成树立了新的标杆。

Abstract: Controllable generation of realistic LiDAR scenes is crucial for applications
such as autonomous driving and robotics. While recent diffusion-based models
achieve high-fidelity LiDAR generation, they lack explicit control over
foreground objects and spatial relationships, limiting their usefulness for
scenario simulation and safety validation. To address these limitations, we
propose Large-scale Layout-guided LiDAR generation model ("La La LiDAR"), a
novel layout-guided generative framework that introduces semantic-enhanced
scene graph diffusion with relation-aware contextual conditioning for
structured LiDAR layout generation, followed by foreground-aware control
injection for complete scene generation. This enables customizable control over
object placement while ensuring spatial and semantic consistency. To support
our structured LiDAR generation, we introduce Waymo-SG and nuScenes-SG, two
large-scale LiDAR scene graph datasets, along with new evaluation metrics for
layout synthesis. Extensive experiments demonstrate that La La LiDAR achieves
state-of-the-art performance in both LiDAR generation and downstream perception
tasks, establishing a new benchmark for controllable 3D scene generation.

</details>


### [52] [SAVER: Mitigating Hallucinations in Large Vision-Language Models via Style-Aware Visual Early Revision](https://arxiv.org/abs/2508.03177)
*Zhaoxu Li,Chenqi Kong,Yi Yu,Qiangqiang Wu,Xinghao Jiang,Ngai-Man Cheung,Bihan Wen,Alex Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: SAVER是一种新机制，可以解决大型视觉语言模型（LVLM）在处理风格化图像时出现的幻觉问题。它通过利用早期层反馈来调整模型输出，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然以往的缓解方法有效减少了照片图像中的幻觉，但它们在很大程度上忽略了风格化图像带来的潜在风险，而风格化图像在游戏场景理解、艺术教育和医学分析等关键场景中起着至关重要的作用。

Method: 提出了一种名为SAVER的新型机制，该机制利用令牌级视觉注意模式动态调整大型视觉语言模型（LVLM）的最终输出，并利用早期层反馈来减轻由风格化图像引起的幻觉。

Result: 风格化图像比其照片对应物更容易引起幻觉。SAVER在减少幻觉方面优于其他方法。

Conclusion: SAVER在幻觉缓解方面实现了最先进的性能，在各种模型、数据集和任务中都表现出色。

Abstract: Large Vision-Language Models (LVLMs) recently achieve significant
breakthroughs in understanding complex visual-textual contexts. However,
hallucination issues still limit their real-world applicability. Although
previous mitigation methods effectively reduce hallucinations in photographic
images, they largely overlook the potential risks posed by stylized images,
which play crucial roles in critical scenarios such as game scene
understanding, art education, and medical analysis. In this work, we first
construct a dataset comprising photographic images and their corresponding
stylized versions with carefully annotated caption labels. We then conduct
head-to-head comparisons on both discriminative and generative tasks by
benchmarking 13 advanced LVLMs on the collected datasets. Our findings reveal
that stylized images tend to induce significantly more hallucinations than
their photographic counterparts. To address this issue, we propose Style-Aware
Visual Early Revision SAVER, a novel mechanism that dynamically adjusts LVLMs'
final outputs based on the token-level visual attention patterns, leveraging
early-layer feedback to mitigate hallucinations caused by stylized images.
Extensive experiments demonstrate that SAVER achieves state-of-the-art
performance in hallucination mitigation across various models, datasets, and
tasks.

</details>


### [53] [LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences](https://arxiv.org/abs/2508.03692)
*Ao Liang,Youquan Liu,Yu Yang,Dongyue Lu,Linfeng Li,Lingdong Kong,Huaici Zhao,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: LiDARCrafter是一个用于4D LiDAR生成和编辑的框架，它使用自然语言指令来控制生成过程，并提供时间连贯的输出。它在真实性、可控性和时间一致性方面表现出色，并且有一个新的基准来评估其性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型主要关注视频或占用网格，忽略了LiDAR的特性。为动态4D世界建模的LiDAR生成面临可控性、时间连贯性和评估标准化方面的挑战。

Method: LiDARCrafter是一个统一的框架，用于4D LiDAR生成和编辑。它通过解析自然语言指令到以自身为中心的场景图，并将其作为条件输入到三分支扩散网络中，以生成对象结构、运动轨迹和几何。此外，一个自回归模块生成了时间上连贯的4D LiDAR序列。我们还建立了一个全面的基准来支持评估。

Result: 实验证明，LiDARCrafter在真实性、可控性和时间一致性方面均达到最先进水平。

Conclusion: LiDARCrafter在真实性、可控性和时间一致性方面均达到最先进水平，有望用于数据增强和模拟。

Abstract: Generative world models have become essential data engines for autonomous
driving, yet most existing efforts focus on videos or occupancy grids,
overlooking the unique LiDAR properties. Extending LiDAR generation to dynamic
4D world modeling presents challenges in controllability, temporal coherence,
and evaluation standardization. To this end, we present LiDARCrafter, a unified
framework for 4D LiDAR generation and editing. Given free-form natural language
inputs, we parse instructions into ego-centric scene graphs, which condition a
tri-branch diffusion network to generate object structures, motion
trajectories, and geometry. These structured conditions enable diverse and
fine-grained scene editing. Additionally, an autoregressive module generates
temporally coherent 4D LiDAR sequences with smooth transitions. To support
standardized evaluation, we establish a comprehensive benchmark with diverse
metrics spanning scene-, object-, and sequence-level aspects. Experiments on
the nuScenes dataset using this benchmark demonstrate that LiDARCrafter
achieves state-of-the-art performance in fidelity, controllability, and
temporal consistency across all levels, paving the way for data augmentation
and simulation. The code and benchmark are released to the community.

</details>


### [54] [Duplex-GS: Proxy-Guided Weighted Blending for Real-Time Order-Independent Gaussian Splatting](https://arxiv.org/abs/2508.03180)
*Weihang Liu,Yuke Li,Yuxuan Li,Jingyi Yu,Xin Lou*

Main category: cs.CV

TL;DR: Duplex-GS 是一种创新的双层框架，通过代理高斯和无序渲染技术，在 3DGS 中实现了实时、照片级逼真的渲染，有效解决了计算开销和伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 3DGS 方法依赖于计算成本高昂的顺序 alpha 混合操作，在资源受限的平台上开销显著，并且存在“弹出”和“透明度”伪影问题。

Method: 提出了一种名为 Duplex-GS 的双层框架，集成了代理高斯表示和无序渲染技术。引入了单元代理（cell proxies）和单元搜索光栅化（cell search rasterization）来管理局部高斯和加速渲染过程。结合了与无序透明（OIT）技术，开发了一种物理启发的加权求和渲染技术。

Result: Duplex-GS 在渲染质量与现有 OIT 方法相当的情况下，实现了 1.5 到 4 倍的速度提升，并将基数排序开销减少了 52.2% 到 86.9%，同时消除了伪影。

Conclusion: Duplex-GS 框架通过结合代理高斯表示和无序渲染技术，在保持照片级真实感的同时实现了实时性能，并有效减少了计算开销，在各种场景下均表现出鲁棒性。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
rendering fidelity and efficiency. However, these methods still rely on
computationally expensive sequential alpha-blending operations, resulting in
significant overhead, particularly on resource-constrained platforms. In this
paper, we propose Duplex-GS, a dual-hierarchy framework that integrates proxy
Gaussian representations with order-independent rendering techniques to achieve
photorealistic results while sustaining real-time performance. To mitigate the
overhead caused by view-adaptive radix sort, we introduce cell proxies for
local Gaussians management and propose cell search rasterization for further
acceleration. By seamlessly combining our framework with Order-Independent
Transparency (OIT), we develop a physically inspired weighted sum rendering
technique that simultaneously eliminates "popping" and "transparency"
artifacts, yielding substantial improvements in both accuracy and efficiency.
Extensive experiments on a variety of real-world datasets demonstrate the
robustness of our method across diverse scenarios, including multi-scale
training views and large-scale environments. Our results validate the
advantages of the OIT rendering paradigm in Gaussian Splatting, achieving
high-quality rendering with an impressive 1.5 to 4 speedup over existing OIT
based Gaussian Splatting approaches and 52.2% to 86.9% reduction of the radix
sort overhead without quality degradation.

</details>


### [55] [Monocular Depth Estimation with Global-Aware Discretization and Local Context Modeling](https://arxiv.org/abs/2508.03186)
*Heng Wu,Qian Zhang,Guixu Zhang*

Main category: cs.CV

TL;DR: 一种新的单目深度估计方法，结合了门控大核卷积和全局深度 bin 预测，在NYU-V2和KITTI数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 准确的单目深度估计仍然是一个具有挑战性的问题，因为从单个视图恢复 3D 结构本身就存在固有的歧义，而这种歧义源于病态问题，其中多个合理的深度配置可以产生相同的 2D 投影。

Method: 本文提出了一种结合局部和全局线索的新型深度估计方法。具体来说，提出了门控大核注意力模块（GLKAM），通过利用具有门控机制的大核卷积来有效捕获多尺度局部结构信息。为了进一步增强网络的全局感知能力，引入了全局深度 bin 预测模块（GBPM），该模块可以估计深度 bin 的全局分布并为深度回归提供结构指导。

Result: 通过在NYU-V2和KITTI数据集上进行的大量实验，证明了本文提出的方法在深度估计任务上取得了具有竞争力的性能。

Conclusion: 本文提出的方法在NYU-V2和KITTI数据集上进行了广泛的实验，结果表明该方法具有竞争力，并且优于现有方法，验证了所提出组件的有效性。

Abstract: Accurate monocular depth estimation remains a challenging problem due to the
inherent ambiguity that stems from the ill-posed nature of recovering 3D
structure from a single view, where multiple plausible depth configurations can
produce identical 2D projections. In this paper, we present a novel depth
estimation method that combines both local and global cues to improve
prediction accuracy. Specifically, we propose the Gated Large Kernel Attention
Module (GLKAM) to effectively capture multi-scale local structural information
by leveraging large kernel convolutions with a gated mechanism. To further
enhance the global perception of the network, we introduce the Global Bin
Prediction Module (GBPM), which estimates the global distribution of depth bins
and provides structural guidance for depth regression. Extensive experiments on
the NYU-V2 and KITTI dataset demonstrate that our method achieves competitive
performance and outperforms existing approaches, validating the effectiveness
of each proposed component.

</details>


### [56] [Unifying Locality of KANs and Feature Drift Compensation for Data-free Continual Face Forgery Detection](https://arxiv.org/abs/2508.03189)
*Tianshuo Zhang,Siran Peng,Li Gao,Haoyuan Zhang,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 提出KAN-CFD框架，解决人脸伪造检测中的灾难性遗忘问题，通过DG-KD和FS-KDCP策略提升性能并减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造技术的快速发展需要检测器适应新的伪造方法，这属于持续学习的范畴。然而，现有检测器在学习新伪造类型时，其在旧类型上的性能会迅速下降（灾难性遗忘）。KAN利用局部可塑性样条作为激活函数，适合解决灾难性遗忘问题。但KAN在处理高维图像和不同域特征重叠时存在局限性。

Method: 提出了一种基于Kolmogorov-Arnold网络（KAN）的持续人脸伪造检测（KAN-CFD）框架，该框架包括一个域分组KAN检测器（DG-KD）和一个无数据重放的特征分离策略（FS-KDCP），通过KAN漂移补偿投影（FS-KDCP）实现。

Result: 实验结果表明，所提出的KAN-CFD框架在人脸伪造检测任务中取得了优越的性能，并显著降低了灾难性遗忘现象。

Conclusion: 所提出的KAN-CFD框架通过DG-KD和FS-KDCP策略，成功解决了人脸伪造检测中的灾难性遗忘问题，并在实验中取得了优越的性能，显著减少了遗忘。

Abstract: The rapid advancements in face forgery techniques necessitate that detectors
continuously adapt to new forgery methods, thus situating face forgery
detection within a continual learning paradigm. However, when detectors learn
new forgery types, their performance on previous types often degrades rapidly,
a phenomenon known as catastrophic forgetting. Kolmogorov-Arnold Networks
(KANs) utilize locally plastic splines as their activation functions, enabling
them to learn new tasks by modifying only local regions of the functions while
leaving other areas unaffected. Therefore, they are naturally suitable for
addressing catastrophic forgetting. However, KANs have two significant
limitations: 1) the splines are ineffective for modeling high-dimensional
images, while alternative activation functions that are suitable for images
lack the essential property of locality; 2) in continual learning, when
features from different domains overlap, the mapping of different domains to
distinct curve regions always collapses due to repeated modifications of the
same regions. In this paper, we propose a KAN-based Continual Face Forgery
Detection (KAN-CFD) framework, which includes a Domain-Group KAN Detector
(DG-KD) and a data-free replay Feature Separation strategy via KAN Drift
Compensation Projection (FS-KDCP). DG-KD enables KANs to fit high-dimensional
image inputs while preserving locality and local plasticity. FS-KDCP avoids the
overlap of the KAN input spaces without using data from prior tasks.
Experimental results demonstrate that the proposed method achieves superior
performance while notably reducing forgetting.

</details>


### [57] [Neovascularization Segmentation via a Multilateral Interaction-Enhanced Graph Convolutional Network](https://arxiv.org/abs/2508.03197)
*Tao Chen,Dan Zhang,Da Chen,Huazhu Fu,Kai Jin,Shanshan Wang,Laurent D. Cohen,Yitian Zhao,Quanyong Yi,Jiong Zhang*

Main category: cs.CV

TL;DR: 本研究构建了首个公开CNV数据集CNVSeg，并提出了MTG-Net网络，通过整合区域和血管形态信息及图推理机制，有效解决了CNV分割的挑战，分割精度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视网膜CNV是湿性AMD的主要特征，也是导致全球失明的主要原因。临床上常用OCTA进行CNV相关的病理变化研究，但CNV形状不规则以及成像伪影、噪声和边界模糊等问题给精确分割带来挑战。此外，公开数据集的缺乏也限制了CNV的分析。因此，本研究旨在构建首个公开可用的CNV数据集（CNVSeg），并提出一种先进的网络模型来解决这些问题。

Method: 本研究提出了MTG-Net，一个多边图卷积交互增强的CNV分割网络。该网络整合了区域和血管的形态信息，并在图域中探索了语义和几何对偶约束。具体来说，MTG-Net包含一个多任务框架和两个基于图的跨任务模块：多边交互图推理（MIGR）和多边强化图推理（MRGR）。多任务框架编码了丰富的病灶形状和表面几何特征，并将图像解耦为三个特定任务的特征图。MIGR和MRGR通过图机制迭代地推理任务间的更高阶关系，实现特定任务目标的互补优化。此外，还提出了一种不确定性加权损失来减轻伪影和噪声对分割精度的影响。

Result: 实验结果表明，MTG-Net的性能优于现有方法，在区域分割方面达到了87.21%的Dice分数，在血管分割方面达到了88.12%的Dice分数。

Conclusion: 本研究提出了MTG-Net，一种用于CNV分割的新型网络，通过整合区域和血管的形态信息，并利用图域中的语义和几何对偶约束，在CNV分割任务上取得了优于现有方法的性能，区域分割Dice得分为87.21%，血管分割Dice得分为88.12%。

Abstract: Choroidal neovascularization (CNV), a primary characteristic of wet
age-related macular degeneration (wet AMD), represents a leading cause of
blindness worldwide. In clinical practice, optical coherence tomography
angiography (OCTA) is commonly used for studying CNV-related pathological
changes, due to its micron-level resolution and non-invasive nature. Thus,
accurate segmentation of CNV regions and vessels in OCTA images is crucial for
clinical assessment of wet AMD. However, challenges existed due to irregular
CNV shapes and imaging limitations like projection artifacts, noises and
boundary blurring. Moreover, the lack of publicly available datasets
constraints the CNV analysis. To address these challenges, this paper
constructs the first publicly accessible CNV dataset (CNVSeg), and proposes a
novel multilateral graph convolutional interaction-enhanced CNV segmentation
network (MTG-Net). This network integrates both region and vessel morphological
information, exploring semantic and geometric duality constraints within the
graph domain. Specifically, MTG-Net consists of a multi-task framework and two
graph-based cross-task modules: Multilateral Interaction Graph Reasoning (MIGR)
and Multilateral Reinforcement Graph Reasoning (MRGR). The multi-task framework
encodes rich geometric features of lesion shapes and surfaces, decoupling the
image into three task-specific feature maps. MIGR and MRGR iteratively reason
about higher-order relationships across tasks through a graph mechanism,
enabling complementary optimization for task-specific objectives. Additionally,
an uncertainty-weighted loss is proposed to mitigate the impact of artifacts
and noise on segmentation accuracy. Experimental results demonstrate that
MTG-Net outperforms existing methods, achieving a Dice socre of 87.21\% for
region segmentation and 88.12\% for vessel segmentation.

</details>


### [58] [AlignCAT: Visual-Linguistic Alignment of Category and Attributefor Weakly Supervised Visual Grounding](https://arxiv.org/abs/2508.03201)
*Yidan Wang,Chenyi Zhuang,Wutao Liu,Pan Gao,Nicu Sebe*

Main category: cs.CV

TL;DR: AlignCAT通过粗细粒度对齐模块增强视觉-语言对齐，解决了弱监督视觉定位中的歧义问题，并在多个基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视觉定位方法在区分文本表达式中的细微语义差异方面存在不足，尤其是在类别和属性层面存在歧义。为了解决这些挑战，需要更强的跨模态推理能力。

Method: 提出了一种名为AlignCAT的新型查询式语义匹配框架，包含粗粒度对齐模块（利用类别信息和全局上下文）和细粒度对齐模块（利用描述信息和词级文本特征），以增强视觉-语言对齐，并通过利用语言线索逐步过滤错误匹配的视觉查询，提高对比学习效率。

Result: AlignCAT在RefCOCO、RefCOCO+和RefCOCOg三个基准测试上验证了其优越性，在两个视觉定位任务上超越了现有的弱监督方法。

Conclusion: AlignCAT在RefCOCO、RefCOCO+和RefCOCOg三个基准测试上进行了广泛的实验，证明了其在弱监督视觉定位任务上优于现有方法。

Abstract: Weakly supervised visual grounding (VG) aims to locate objects in images
based on text descriptions. Despite significant progress, existing methods lack
strong cross-modal reasoning to distinguish subtle semantic differences in text
expressions due to category-based and attribute-based ambiguity. To address
these challenges, we introduce AlignCAT, a novel query-based semantic matching
framework for weakly supervised VG. To enhance visual-linguistic alignment, we
propose a coarse-grained alignment module that utilizes category information
and global context, effectively mitigating interference from
category-inconsistent objects. Subsequently, a fine-grained alignment module
leverages descriptive information and captures word-level text features to
achieve attribute consistency. By exploiting linguistic cues to their fullest
extent, our proposed AlignCAT progressively filters out misaligned visual
queries and enhances contrastive learning efficiency. Extensive experiments on
three VG benchmarks, namely RefCOCO, RefCOCO+, and RefCOCOg, verify the
superiority of AlignCAT against existing weakly supervised methods on two VG
tasks. Our code is available at: https://github.com/I2-Multimedia-Lab/AlignCAT.

</details>


### [59] [Open-Vocabulary HOI Detection with Interaction-aware Prompt and Concept Calibration](https://arxiv.org/abs/2508.03207)
*Ting Lei,Shaofeng Yin,Qingchao Chen,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: INP-CC 是一种新的 HOI 检测方法，通过交互感知提示和概念校准解决了现有方法的局限性，并在两个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的 HOI 检测方法虽然利用了视觉语言模型 (VLMs)，但在图像编码器和文本描述方面存在不足，难以捕捉细粒度的区域级别交互检测和详细的 HOI 关系。

Method: INP-CC 是一种端到端的开放词汇 HOI 检测器，集成了交互感知提示和概念校准。通过动态生成基于输入场景的提示集，并利用语言模型引导的校准来精炼 HOI 概念表示，同时采用负采样策略来改进跨模态相似性建模，从而更好地区分视觉上相似但语义上不同的动作。

Result: INP-CC 在 SWIG-HOI 和 HICO-DET 数据集上的实验结果表明，其性能显著优于现有最先进的模型。

Conclusion: INP-CC 显著优于当前最先进的模型，并在 SWIG-HOI 和 HICO-DET 数据集上取得了卓越的性能。

Abstract: Open Vocabulary Human-Object Interaction (HOI) detection aims to detect
interactions between humans and objects while generalizing to novel interaction
classes beyond the training set. Current methods often rely on Vision and
Language Models (VLMs) but face challenges due to suboptimal image encoders, as
image-level pre-training does not align well with the fine-grained region-level
interaction detection required for HOI. Additionally, effectively encoding
textual descriptions of visual appearances remains difficult, limiting the
model's ability to capture detailed HOI relationships. To address these issues,
we propose INteraction-aware Prompting with Concept Calibration (INP-CC), an
end-to-end open-vocabulary HOI detector that integrates interaction-aware
prompts and concept calibration. Specifically, we propose an interaction-aware
prompt generator that dynamically generates a compact set of prompts based on
the input scene, enabling selective sharing among similar interactions. This
approach directs the model's attention to key interaction patterns rather than
generic image-level semantics, enhancing HOI detection. Furthermore, we refine
HOI concept representations through language model-guided calibration, which
helps distinguish diverse HOI concepts by investigating visual similarities
across categories. A negative sampling strategy is also employed to improve
inter-modal similarity modeling, enabling the model to better differentiate
visually similar but semantically distinct actions. Extensive experimental
results demonstrate that INP-CC significantly outperforms state-of-the-art
models on the SWIG-HOI and HICO-DET datasets. Code is available at
https://github.com/ltttpku/INP-CC.

</details>


### [60] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastInit通过单次前向传播精炼噪声，提高视频生成效率和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 视频生成领域，尽管扩散模型取得了显著进展，但实现高时间一致性仍然是一个挑战。虽然FreeInit方法识别了训练-推理的差距并引入了迭代精炼初始噪声的方法，但这大大增加了计算成本。

Method: 提出了一种名为FastInit的快速噪声初始化方法，通过学习一个视频噪声预测网络（VNPNet），该网络接收随机噪声和文本提示作为输入，在单次前向传播中生成精炼后的噪声，消除了对迭代精炼的需求。

Result: FastInit在各种文本到视频模型上进行了广泛的实验，结果表明其能够持续提升生成视频的质量和时间一致性，并提供了一种可直接在推理时应用的实用解决方案。

Conclusion: FastInit通过学习视频噪声预测网络（VNPNet），在推理的单次前向传播中生成精炼后的噪声，无需迭代精炼，从而大大提高了视频生成的效率，同时实现了跨帧的高时间一致性。该方法在各种文本到视频模型上进行了广泛的实验，结果表明它能持续提高生成视频的质量和时间一致性，是一种实用的推理解决方案。

Abstract: Video generation has made significant strides with the development of
diffusion models; however, achieving high temporal consistency remains a
challenging task. Recently, FreeInit identified a training-inference gap and
introduced a method to iteratively refine the initial noise during inference.
However, iterative refinement significantly increases the computational cost
associated with video generation. In this paper, we introduce FastInit, a fast
noise initialization method that eliminates the need for iterative refinement.
FastInit learns a Video Noise Prediction Network (VNPNet) that takes random
noise and a text prompt as input, generating refined noise in a single forward
pass. Therefore, FastInit greatly enhances the efficiency of video generation
while achieving high temporal consistency across frames. To train the VNPNet,
we create a large-scale dataset consisting of pairs of text prompts, random
noise, and refined noise. Extensive experiments with various text-to-video
models show that our method consistently improves the quality and temporal
consistency of the generated videos. FastInit not only provides a substantial
improvement in video generation but also offers a practical solution that can
be applied directly during inference. The code and dataset will be released.

</details>


### [61] [GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations](https://arxiv.org/abs/2508.03209)
*Xinwei Liu,Xiaojun Jia,Yuan Xun,Simeng Qin,Xiaochun Cao*

Main category: cs.CV

TL;DR: GeoShield 是一种新的框架，通过分离地理信息、识别暴露区域和优化扰动来保护用户免受视觉语言模型（VLM）的位置推断，在高分辨率图像和低扰动预算下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）能够从公开分享的图像推断用户位置，对地理隐私构成重大风险。现有的对抗性扰动方法在高分辨率图像和低扰动预算方面表现不佳，并可能引入不相关的语义内容。

Method: GeoShield 是一个新颖的对抗性框架，包含三个关键模块：一个分离地理和非地理信息的特征解耦模块，一个精确定位图像中地理暴露区域的暴露元素识别模块，以及一个联合优化全局和局部扰动的尺度自适应增强模块，以确保跨分辨率的有效性。

Result: GeoShield 在具有挑战性的基准测试上进行了广泛的实验，在黑盒设置下始终优于先前的方法，在对视觉或语义质量影响最小的情况下实现了强大的隐私保护。

Conclusion: GeoShield 是一项开创性的工作，首次探索了使用对抗性扰动来防御高级视觉语言模型（VLM）的地理定位推理，为日益增长的隐私问题提供了一个切实可行且有效的解决方案。

Abstract: Vision-Language Models (VLMs) such as GPT-4o now demonstrate a remarkable
ability to infer users' locations from public shared images, posing a
substantial risk to geoprivacy. Although adversarial perturbations offer a
potential defense, current methods are ill-suited for this scenario: they often
perform poorly on high-resolution images and low perturbation budgets, and may
introduce irrelevant semantic content. To address these limitations, we propose
GeoShield, a novel adversarial framework designed for robust geoprivacy
protection in real-world scenarios. GeoShield comprises three key modules: a
feature disentanglement module that separates geographical and non-geographical
information, an exposure element identification module that pinpoints
geo-revealing regions within an image, and a scale-adaptive enhancement module
that jointly optimizes perturbations at both global and local levels to ensure
effectiveness across resolutions. Extensive experiments on challenging
benchmarks show that GeoShield consistently surpasses prior methods in
black-box settings, achieving strong privacy protection with minimal impact on
visual or semantic quality. To our knowledge, this work is the first to explore
adversarial perturbations for defending against geolocation inference by
advanced VLMs, providing a practical and effective solution to escalating
privacy concerns.

</details>


### [62] [The Power of Many: Synergistic Unification of Diverse Augmentations for Efficient Adversarial Robustness](https://arxiv.org/abs/2508.03213)
*Wang Yu-Hang,Shiwei Li,Jianxiang Liao,Li Bohan,Jian Liu,Wenfei Yin*

Main category: cs.CV

TL;DR: UAA框架通过离线生成通用扰动，在训练期间高效生成样本特定扰动，实现了高效且强大的对抗防御，无需在线生成对抗样本，并在多个基准测试中取得了SOTA成果。


<details>
  <summary>Details</summary>
Motivation: 为了应对深度学习模型面临的对抗性扰动威胁，同时解决现有对抗训练（AT）方法计算成本高和标准性能下降的挑战，以及现有数据增强技术鲁棒性提升有限或训练开销大的问题，需要开发一种既高效又鲁棒的防御机制。

Method: UAA框架通过离线预计算一个通用的转换，然后利用该转换在训练期间为每个样本有效地生成唯一的对抗性扰动，从而将昂贵的扰动生成过程与模型训练分离。

Result: UAA框架在多个基准测试中都取得了显著效果，验证了其有效性，并在基于数据增强的对抗防御策略方面设立了新的SOTA。

Conclusion: UAA框架提供了一种高效实用的方法来构建鲁棒模型，它不需要在训练期间在线生成对抗样本，并且在无需在线生成对抗样本的情况下，在基于数据增强的对抗防御策略方面取得了新的SOTA。

Abstract: Adversarial perturbations pose a significant threat to deep learning models.
Adversarial Training (AT), the predominant defense method, faces challenges of
high computational costs and a degradation in standard performance. While data
augmentation offers an alternative path, existing techniques either yield
limited robustness gains or incur substantial training overhead. Therefore,
developing a defense mechanism that is both highly efficient and strongly
robust is of paramount importance.In this work, we first conduct a systematic
analysis of existing augmentation techniques, revealing that the synergy among
diverse strategies -- rather than any single method -- is crucial for enhancing
robustness. Based on this insight, we propose the Universal Adversarial
Augmenter (UAA) framework, which is characterized by its plug-and-play nature
and training efficiency. UAA decouples the expensive perturbation generation
process from model training by pre-computing a universal transformation
offline, which is then used to efficiently generate unique adversarial
perturbations for each sample during training.Extensive experiments conducted
on multiple benchmarks validate the effectiveness of UAA. The results
demonstrate that UAA establishes a new state-of-the-art (SOTA) for
data-augmentation-based adversarial defense strategies , without requiring the
online generation of adversarial examples during training. This framework
provides a practical and efficient pathway for building robust models,Our code
is available in the supplementary materials.

</details>


### [63] [ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow](https://arxiv.org/abs/2508.03218)
*Shanshan Guo,Xiwen Liang,Junfan Lin,Yuzheng Zhuang,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: ActionSink 通过将机器人动作视为“动作流”并进行自监督学习，解决了低层动作估计精度不足的问题，显著提升了机器人操作的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的机器人操作方法在感知和规划方面取得了进展，但低精度的低层动作估计已成为影响操作性能的关键限制因素。

Method: ActionSink 提出了一种新颖的机器人操作框架，将机器人动作重新表述为视频中的“动作流”（action flow），并以自监督的方式进行检索和整合，以提高动作估计的精度。该框架包含两个主要模块：1. 粗到精的动作流匹配器，通过迭代检索和去噪过程不断提高动作流的准确性。2. 动态动作流整合器，使用工作记忆池动态高效地管理用于增强当前动作估计的历史动作流，并通过多层融合模块整合来自当前和工作记忆的直接估计和动作流。

Result: ActionSink 框架在 LIBERO 基准测试中，成功率比现有技术提高了 7.9%，在具有挑战性的长时程视觉任务 LIBERO-Long 上，准确率提升了近 8%。

Conclusion: ActionSink 框架在 LIBERO 基准测试中取得了 7.9% 的成功率提升，在 LIBERO-Long 任务中获得了近 8% 的准确率提升，显著优于现有技术。

Abstract: Language-instructed robot manipulation has garnered significant interest due
to the potential of learning from collected data. While the challenges in
high-level perception and planning are continually addressed along the progress
of general large pre-trained models, the low precision of low-level action
estimation has emerged as the key limiting factor in manipulation performance.
To this end, this paper introduces a novel robot manipulation framework, i.e.,
ActionSink, to pave the way toward precise action estimations in the field of
learning-based robot manipulation. As the name suggests, ActionSink
reformulates the actions of robots as action-caused optical flows from videos,
called "action flow", in a self-supervised manner, which are then used to be
retrieved and integrated to enhance the action estimation. Specifically,
ActionSink incorporates two primary modules. The first module is a
coarse-to-fine action flow matcher, which continuously refines the accuracy of
action flow via iterative retrieval and denoising process. The second module is
a dynamic action flow integrator, which employs a working memory pool that
dynamically and efficiently manages the historical action flows that should be
used to integrate to enhance the current action estimation. In this module, a
multi-layer fusion module is proposed to integrate direct estimation and action
flows from both the current and the working memory, achieving highly accurate
action estimation through a series of estimation-integration processes. Our
ActionSink framework outperformed prior SOTA on the LIBERO benchmark by a 7.9\%
success rate, and obtained nearly an 8\% accuracy gain on the challenging
long-horizon visual task LIBERO-Long.

</details>


### [64] [Trace3D: Consistent Segmentation Lifting via Gaussian Instance Tracing](https://arxiv.org/abs/2508.03227)
*Hongyu Shen,Junfeng Ni,Yixin Chen,Weishuo Li,Mingtao Pei,Siyuan Huang*

Main category: cs.CV

TL;DR: GIT通过实例权重矩阵和自适应密度控制，解决了高斯泼溅中的2D-3D分割不一致和边界噪声问题，提升了分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在2D到3D高斯泼溅分割中存在跨视点的2D掩码不一致和分割边界噪声等问题，因为它们忽略了用于细化高斯的语义线索。

Method: 我们提出了高斯实例追踪（GIT）方法，通过引入实例权重矩阵来解决2D到3D高斯泼溅分割中的不一致性问题，并结合了GIT引导的自适应密度控制机制来优化高斯表示。

Result: GIT方法能够提取干净的3D模型，并在在线和离线设置下持续改进3D分割性能，实现了更清晰、更连贯的2D和3D分割边界。

Conclusion: GIT方法在2D和3D分割任务上均取得了显著提升，并支持多种下游应用。

Abstract: We address the challenge of lifting 2D visual segmentation to 3D in Gaussian
Splatting. Existing methods often suffer from inconsistent 2D masks across
viewpoints and produce noisy segmentation boundaries as they neglect these
semantic cues to refine the learned Gaussians. To overcome this, we introduce
Gaussian Instance Tracing (GIT), which augments the standard Gaussian
representation with an instance weight matrix across input views. Leveraging
the inherent consistency of Gaussians in 3D, we use this matrix to identify and
correct 2D segmentation inconsistencies. Furthermore, since each Gaussian
ideally corresponds to a single object, we propose a GIT-guided adaptive
density control mechanism to split and prune ambiguous Gaussians during
training, resulting in sharper and more coherent 2D and 3D segmentation
boundaries. Experimental results show that our method extracts clean 3D assets
and consistently improves 3D segmentation in both online (e.g., self-prompting)
and offline (e.g., contrastive lifting) settings, enabling applications such as
hierarchical segmentation, object extraction, and scene editing.

</details>


### [65] [Zero-shot Shape Classification of Nanoparticles in SEM Images using Vision Foundation Models](https://arxiv.org/abs/2508.03235)
*Freida Barnatan,Emunah Goldstein,Einav Kalimian,Orchen Madar,Avi Huri,David Zitoun,Ya'akov Mandelbaum,Moshe Amitay*

Main category: cs.CV

TL;DR: 通过结合SAM和DINOv2基础模型，本研究提出了一种无需微调的零样本纳米颗粒形状分类方法，该方法比传统深度学习模型更高效、更易于访问，并能有效处理各种挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在纳米颗粒形貌表征方面需要大量的标注数据和计算资源，这限制了它们在纳米材料合成和研发中的可及性。本研究旨在提供一种更高效、更易于访问的解决方案。

Method: 本研究提出了一种零样本分类流程，利用Segment Anything Model (SAM) 进行对象分割，利用DINOv2进行特征嵌入，并结合一个轻量级的分类器。

Result: 该零样本分类流程在三种纳米颗粒数据集上实现了高精度的形状分类，性能优于经过微调的YOLOv11和ChatGPT o4-mini-high基线模型，并且对小数据集、细微的形态变化和领域转移具有鲁棒性。

Conclusion: 本研究提出的零样本分类流程利用SAM进行对象分割，DINOv2进行特征嵌入，并结合轻量级分类器，在三种具有不同形态的纳米颗粒数据集上实现了高精度的形状分类，无需广泛的参数微调。该方法在准确性和效率方面均优于经过微调的YOLOv11和ChatGPT o4-mini-high基线模型，并且在小数据集、细微的形态变化以及从自然图像到科学图像的领域转移方面表现出鲁棒性。此外，研究还讨论了如何利用DINOv2特征的PCA图上的量化聚类指标来评估化学合成的进展。这项工作展示了基础模型在推进自动显微镜图像分析方面的潜力，为纳米颗粒研究中替代传统深度学习流程提供了一种更高效、更易于用户使用的方案。

Abstract: Accurate and efficient characterization of nanoparticle morphology in
Scanning Electron Microscopy (SEM) images is critical for ensuring product
quality in nanomaterial synthesis and accelerating development. However,
conventional deep learning methods for shape classification require extensive
labeled datasets and computationally demanding training, limiting their
accessibility to the typical nanoparticle practitioner in research and
industrial settings. In this study, we introduce a zero-shot classification
pipeline that leverages two vision foundation models: the Segment Anything
Model (SAM) for object segmentation and DINOv2 for feature embedding. By
combining these models with a lightweight classifier, we achieve high-precision
shape classification across three morphologically diverse nanoparticle datasets
- without the need for extensive parameter fine-tuning. Our methodology
outperforms a fine-tuned YOLOv11 and ChatGPT o4-mini-high baselines,
demonstrating robustness to small datasets, subtle morphological variations,
and domain shifts from natural to scientific imaging. Quantitative clustering
metrics on PCA plots of the DINOv2 features are discussed as a means of
assessing the progress of the chemical synthesis. This work highlights the
potential of foundation models to advance automated microscopy image analysis,
offering an alternative to traditional deep learning pipelines in nanoparticle
research which is both more efficient and more accessible to the user.

</details>


### [66] [VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation](https://arxiv.org/abs/2508.03351)
*Yufei Xue,Yushi Huang,Jiawei Shao,Jun Zhang*

Main category: cs.CV

TL;DR: VLMQ是一种新的PTQ框架，用于量化视觉语言模型（VLM），解决了现有方法在处理VLM时性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM PTQ方法在应用于VLM时存在性能下降的问题，原因是VLM存在模态差异（文本标记有限vs.视觉标记过度且冗余）。

Method: 提出了一种新颖的、面向VLM的、感知重要性的PTQ框架VLMQ，通过优化一个感知重要性的目标来解决视觉标记冗余问题，并通过一次轻量级的块级反向传播来计算标记级重要性因子。

Result: VLMQ在8个基准测试中的0.5B~32B VLM上进行了广泛评估，证明了其最先进的性能。

Conclusion: VLMQ在低比特量化设置下实现了最先进的性能，在MME-RealWorld基准测试的2比特量化下取得了16.45%的显著提升。

Abstract: Post-training quantization (PTQ) has emerged as an effective approach for
compressing large models and accelerating their inference without retraining.
While PTQ has been extensively studied in the context of large language models
(LLMs), its applicability to vision-language models (VLMs) remains
underexplored. In this paper, we identify a modality discrepancy (\emph{i.e.},
limited text tokens \emph{vs.} excessive and redundant vision tokens) of VLMs.
However, existing Hessian-based LLM PTQ methods treat all tokens equally during
quantization, resulting in severe performance drops when applied to VLMs.
Motivated by this observation, we propose a novel importance-aware PTQ
framework tailored for VLMs, dubbed VLMQ. Specifically, to address vision token
redundancy, VLMQ 1) optimizes an importance-aware objective that yields an
enhanced Hessian with token-level importance factors, while retaining
compatibility with parallelized weight updates, and 2) ensures efficiency and
effectiveness by computing these factors via a single lightweight block-wise
backward pass, guided by a theoretical connection to token-level perturbations.
Extensive evaluations on 8 benchmarks across 0.5B$\sim$32B VLMs demonstrate the
state-of-the-art (SOTA) performance of our VLMQ, particularly under low-bit
settings. For example, it achieves a substantial \textbf{16.45\%} improvement
on MME-RealWorld under 2-bit quantization.

</details>


### [67] [FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles](https://arxiv.org/abs/2508.03241)
*Xingchao Yang,Shiori Ueda,Yuantian Huang,Tomoya Akiyama,Takafumi Taketomi*

Main category: cs.CV

TL;DR: 该研究提出了 FFHQ-Makeup 数据集，通过改进的妆容迁移方法解决了现有数据集的不足，为美妆相关任务提供了高质量的训练资源。


<details>
  <summary>Details</summary>
Motivation: 现有的妆容数据集要么难以大规模采集，要么合成方法存在真实感不足或妆效不一致的问题，这限制了虚拟试妆、面部隐私保护和面部美学分析等相关任务的发展。

Method: 提出了一种新的妆容迁移方法，该方法可以将真实世界的妆容风格迁移到 FFHQ 数据集中的 18,000 个身份上，实现了身份和妆容的分离，并为每个身份生成了 5 种不同的妆容风格，最终形成了 90,000 个高质量的裸妆配对图像。

Result: 成功构建了一个包含 90,000 个高质量裸妆配对图像的数据集（FFHQ-Makeup），其中每个身份都对应多种妆容风格，同时保持了身份和表情的一致性。

Conclusion: FFHQ-Makeup 是一个高质量的合成妆容数据集，解决了现有合成方法在真实感和妆效一致性方面的不足，并填补了高质量裸妆配对数据集的空白。

Abstract: Paired bare-makeup facial images are essential for a wide range of
beauty-related tasks, such as virtual try-on, facial privacy protection, and
facial aesthetics analysis. However, collecting high-quality paired makeup
datasets remains a significant challenge. Real-world data acquisition is
constrained by the difficulty of collecting large-scale paired images, while
existing synthetic approaches often suffer from limited realism or
inconsistencies between bare and makeup images. Current synthetic methods
typically fall into two categories: warping-based transformations, which often
distort facial geometry and compromise the precision of makeup; and
text-to-image generation, which tends to alter facial identity and expression,
undermining consistency. In this work, we present FFHQ-Makeup, a high-quality
synthetic makeup dataset that pairs each identity with multiple makeup styles
while preserving facial consistency in both identity and expression. Built upon
the diverse FFHQ dataset, our pipeline transfers real-world makeup styles from
existing datasets onto 18K identities by introducing an improved makeup
transfer method that disentangles identity and makeup. Each identity is paired
with 5 different makeup styles, resulting in a total of 90K high-quality
bare-makeup image pairs. To the best of our knowledge, this is the first work
that focuses specifically on constructing a makeup dataset. We hope that
FFHQ-Makeup fills the gap of lacking high-quality bare-makeup paired datasets
and serves as a valuable resource for future research in beauty-related tasks.

</details>


### [68] [MVTOP: Multi-View Transformer-based Object Pose-Estimation](https://arxiv.org/abs/2508.03243)
*Lukas Ranftl,Felix Brendel,Bertram Drost,Carsten Steger*

Main category: cs.CV

TL;DR: MVTOP is a transformer-based method for multi-view object pose estimation that uses lines of sight and early feature fusion to resolve pose ambiguities, outperforming existing methods on a challenging synthetic dataset.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of single-view methods and existing multi-view approaches in resolving pose ambiguities, and to provide a versatile method that can handle varying camera interiors and relative orientations for each inference.

Method: MVTOP is a novel transformer-based method that models multi-view geometry via lines of sight emanating from camera centers. It uses an early fusion of view-specific features to resolve pose ambiguities.

Result: The method correctly predicts the correct pose with merged multi-view information. A synthetic dataset was created to demonstrate the model's capabilities, showing it can solve poses unsolvable by single-view methods.

Conclusion: MVTOP outperforms single-view and all existing multi-view approaches on the synthetic dataset and achieves competitive results on the YCB-V dataset. It is an end-to-end trainable model that does not require additional data like depth.

Abstract: We present MVTOP, a novel transformer-based method for multi-view rigid
object pose estimation. Through an early fusion of the view-specific features,
our method can resolve pose ambiguities that would be impossible to solve with
a single view or with a post-processing of single-view poses. MVTOP models the
multi-view geometry via lines of sight that emanate from the respective camera
centers. While the method assumes the camera interior and relative orientations
are known for a particular scene, they can vary for each inference. This makes
the method versatile. The use of the lines of sight enables MVTOP to correctly
predict the correct pose with the merged multi-view information. To show the
model's capabilities, we provide a synthetic data set that can only be solved
with such holistic multi-view approaches since the poses in the dataset cannot
be solved with just one view. Our method outperforms single-view and all
existing multi-view approaches on our dataset and achieves competitive results
on the YCB-V dataset. To the best of our knowledge, no holistic multi-view
method exists that can resolve such pose ambiguities reliably. Our model is
end-to-end trainable and does not require any additional data, e.g., depth.

</details>


### [69] [Draw Your Mind: Personalized Generation via Condition-Level Modeling in Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03481)
*Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.CV

TL;DR: DrUM是一种新方法，通过在潜在空间中进行条件级建模，解决了现有T2I模型个性化不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化生成方法主要依赖于T2I扩散模型的提示级建模，但由于输入令牌容量有限，往往导致个性化不准确。本研究旨在解决这一局限性。

Method: DrUM提出了一种新颖的方法，将用户画像与基于Transformer的适配器相结合，通过在潜在空间中进行条件级建模来实现个性化生成。

Result: DrUM在大规模数据集上表现出强大的性能。

Conclusion: DrUM通过在潜在空间中进行条件级建模，实现了个性化生成，并能与开源文本编码器无缝集成，无需额外微调，即可兼容广泛使用的基础T2I模型。

Abstract: Personalized generation in T2I diffusion models aims to naturally incorporate
individual user preferences into the generation process with minimal user
intervention. However, existing studies primarily rely on prompt-level modeling
with large-scale models, often leading to inaccurate personalization due to the
limited input token capacity of T2I diffusion models. To address these
limitations, we propose DrUM, a novel method that integrates user profiling
with a transformer-based adapter to enable personalized generation through
condition-level modeling in the latent space. DrUM demonstrates strong
performance on large-scale datasets and seamlessly integrates with open-source
text encoders, making it compatible with widely used foundation T2I models
without requiring additional fine-tuning.

</details>


### [70] [Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution](https://arxiv.org/abs/2508.03244)
*Chuanzhi Xu,Haoxian Zhou,Langyi Chen,Yuk Ying Chung,Qiang Qu*

Main category: cs.CV

TL;DR: An ultra-lightweight SNN-based event-to-event super-resolution method is proposed to overcome the spatial resolution limitations of event cameras. It uses a novel polarity-splitting encoding and a learnable loss function for efficiency and performance, enabling real-time use on constrained devices.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of limited spatial resolution in event cameras, which hinders fine-grained perception tasks, while enabling real-time deployment on resource-constrained devices. The goal is to achieve super-resolution for event data in an efficient manner.

Method: The proposed method utilizes an ultra-lightweight, stream-based event-to-event super-resolution approach based on Spiking Neural Networks (SNNs). It incorporates a novel Dual-Forward Polarity-Split Event Encoding strategy to reduce model size by processing positive and negative events separately through a shared SNN. Additionally, a Learnable Spatio-temporal Polarity-aware Loss (LearnSTPLoss) is introduced to manage temporal, spatial, and polarity consistency using learnable weights.

Result: Experimental results show that the proposed method achieves competitive super-resolution performance on multiple datasets. It also significantly reduces model size and inference time compared to existing methods. The lightweight design allows for integration into event cameras or use as an efficient preprocessing module for downstream vision tasks.

Conclusion: Event cameras have advantages like high temporal resolution, low latency, and high dynamic range, but their limited spatial resolution is a challenge for fine-grained perception. This work proposes an ultra-lightweight, stream-based event-to-event super-resolution method using Spiking Neural Networks (SNNs) for real-time deployment on resource-constrained devices. A novel Dual-Forward Polarity-Split Event Encoding strategy is introduced to reduce model size by decoupling positive and negative events into separate forward paths within a shared SNN. A Learnable Spatio-temporal Polarity-aware Loss (LearnSTPLoss) adaptively balances temporal, spatial, and polarity consistency using learnable uncertainty-based weights. The method achieves competitive super-resolution performance with reduced model size and inference time, making it suitable for embedding into event cameras or for efficient front-end preprocessing.

Abstract: Event cameras offer unparalleled advantages such as high temporal resolution,
low latency, and high dynamic range. However, their limited spatial resolution
poses challenges for fine-grained perception tasks. In this work, we propose an
ultra-lightweight, stream-based event-to-event super-resolution method based on
Spiking Neural Networks (SNNs), designed for real-time deployment on
resource-constrained devices. To further reduce model size, we introduce a
novel Dual-Forward Polarity-Split Event Encoding strategy that decouples
positive and negative events into separate forward paths through a shared SNN.
Furthermore, we propose a Learnable Spatio-temporal Polarity-aware Loss
(LearnSTPLoss) that adaptively balances temporal, spatial, and polarity
consistency using learnable uncertainty-based weights. Experimental results
demonstrate that our method achieves competitive super-resolution performance
on multiple datasets while significantly reducing model size and inference
time. The lightweight design enables embedding the module into event cameras or
using it as an efficient front-end preprocessing for downstream vision tasks.

</details>


### [71] [Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion](https://arxiv.org/abs/2508.03252)
*Wentao Qu,Guofeng Mei,Jing Wang,Yujiao Wu,Xiaoshui Huang,Liang Xiao*

Main category: cs.CV

TL;DR: RSDNet is a new single-stage 3D object detection network using DDPMs that achieves state-of-the-art results with improved efficiency due to its single-step inference capability. It utilizes a detachable latent framework and semantic-geometric guidance to handle sparse data and improve robustness.


<details>
  <summary>Details</summary>
Motivation: Existing Denoising Diffusion Probabilistic Models (DDPMs) for 3D object detection require multi-step inference, limiting efficiency. The paper aims to address this by proposing a robust, single-stage, fully sparse 3D object detection network with a detachable latent framework (DLF) of DDPMs.

Method: RSDNet learns the denoising process in latent feature spaces using lightweight denoising networks like multi-level denoising autoencoders (DAEs). It reformulates noising and denoising mechanisms of DDPMs for multi-type and multi-level noise samples and targets, and incorporates semantic-geometric conditional guidance to address the center feature missing problem in sparse representations. The detachable denoising network design allows for single-step inference.

Result: RSDNet effectively understands scene distributions under multi-level perturbations, achieving robust and reliable detection. It enhances robustness to multiple perturbations and alleviates the center feature missing problem in sparse representations, enabling fully sparse detection. The single-step inference significantly enhances detection efficiency.

Conclusion: RSDNet outperformed existing methods and achieved state-of-the-art detection results on public benchmarks.

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have shown success in robust
3D object detection tasks. Existing methods often rely on the score matching
from 3D boxes or pre-trained diffusion priors. However, they typically require
multi-step iterations in inference, which limits efficiency. To address this,
we propose a \textbf{R}obust single-stage fully \textbf{S}parse 3D object
\textbf{D}etection \textbf{Net}work with a Detachable Latent Framework (DLF) of
DDPMs, named RSDNet. Specifically, RSDNet learns the denoising process in
latent feature spaces through lightweight denoising networks like multi-level
denoising autoencoders (DAEs). This enables RSDNet to effectively understand
scene distributions under multi-level perturbations, achieving robust and
reliable detection. Meanwhile, we reformulate the noising and denoising
mechanisms of DDPMs, enabling DLF to construct multi-type and multi-level noise
samples and targets, enhancing RSDNet robustness to multiple perturbations.
Furthermore, a semantic-geometric conditional guidance is introduced to
perceive the object boundaries and shapes, alleviating the center feature
missing problem in sparse representations, enabling RSDNet to perform in a
fully sparse detection pipeline. Moreover, the detachable denoising network
design of DLF enables RSDNet to perform single-step detection in inference,
further enhancing detection efficiency. Extensive experiments on public
benchmarks show that RSDNet can outperform existing methods, achieving
state-of-the-art detection.

</details>


### [72] [V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models](https://arxiv.org/abs/2508.03254)
*Jisoo Kim,Wooseok Seo,Junwan Kim,Seungho Park,Sooyeon Park,Youngjae Yu*

Main category: cs.CV

TL;DR: 通过结合DPO和SFT提出ReDPO方法，并使用VIP框架进行数据集优化和校准训练，成功实现了T2V模型的参数缩减和性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决在资源受限环境下部署文本到视频（T2V）模型时，模型计算成本高的问题，并克服现有蒸馏方法（主要依赖监督微调）因模型容量减小而导致的模式崩溃和性能下降的挑战。

Method: 提出了一种名为ReDPO的有效蒸馏方法，该方法结合了直接偏好优化（DPO）和监督微调（SFT）。DPO用于引导学生模型恢复目标属性，而非被动模仿教师模型，SFT则用于提升整体性能。此外，还提出了VIP框架，用于过滤和整理高质量配对数据集，并采用分步在线方法进行校准训练。

Result: 在VideoCrafter2和AnimateDiff两个领先的T2V模型上验证了ReDPO的有效性，分别实现了36.2%和67.5%的参数缩减，同时性能保持或超越了完整模型。实验还证明了ReDPO和VIP框架在实现高效高质量视频生成方面的有效性。

Conclusion: ReDPO方法成功地将DPO和SFT相结合，用于T2V模型的蒸馏，实现了显著的参数缩减（VideoCrafter2为36.2%，AnimateDiff为67.5%），同时保持甚至超越了完整模型的性能。VIP框架通过过滤和整理高质量配对数据集，并结合分步在线校准训练方法，进一步提升了模型效率和视频生成质量。

Abstract: With growing interest in deploying text-to-video (T2V) models in
resource-constrained environments, reducing their high computational cost has
become crucial, leading to extensive research on pruning and knowledge
distillation methods while maintaining performance. However, existing
distillation methods primarily rely on supervised fine-tuning (SFT), which
often leads to mode collapse as pruned models with reduced capacity fail to
directly match the teacher's outputs, ultimately resulting in degraded quality.
To address this challenge, we propose an effective distillation method, ReDPO,
that integrates DPO and SFT. Our approach leverages DPO to guide the student
model to focus on recovering only the targeted properties, rather than
passively imitating the teacher, while also utilizing SFT to enhance overall
performance. We additionally propose V.I.P., a novel framework for filtering
and curating high-quality pair datasets, along with a step-by-step online
approach for calibrated training. We validate our method on two leading T2V
models, VideoCrafter2 and AnimateDiff, achieving parameter reduction of 36.2%
and 67.5% each, while maintaining or even surpassing the performance of full
models. Further experiments demonstrate the effectiveness of both ReDPO and
V.I.P. framework in enabling efficient and high-quality video generation. Our
code and videos are available at https://jiiiisoo.github.io/VIP.github.io/.

</details>


### [73] [Beyond Meme Templates: Limitations of Visual Similarity Measures in Meme Matching](https://arxiv.org/abs/2508.03562)
*Muzhaffar Hazman,Susan McKeever,Josephine Griffith*

Main category: cs.CV

TL;DR: 互联网梗图是数字文化的重要组成部分，但现有的匹配方法主要依赖于模板，限制了对非模板化梗图的分析。本研究提出了一种更通用的匹配方法，并发现逐段相似度计算在匹配非模板化梗图方面优于整体图像相似度，但仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多假设每个梗图都包含一个共享的视觉背景（模板）和一些叠加的文本，这限制了梗图匹配仅能比较背景图像，排除了许多非模板化的梗图，从而限制了自动化梗图分析的有效性，并且不能有效地将梗图与当代的基于网络的梗图词典联系起来。

Method: 提出了一种超越模板匹配的更广泛的梗图匹配方法，包括一种新颖的逐段相似度计算方法，并探索了一种使用预训练的多模态大型语言模型的基于提示的方法。

Result: 传统的相似度测量（包括新颖的逐段计算）在匹配基于模板的梗图方面表现出色，但在应用于非基于模板的梗图格式时效果不佳。然而，在匹配非基于模板的梗图方面，逐段方法持续优于整个图像的度量。

Conclusion: 匹配基于共享视觉元素（而不仅仅是背景模板）的梗图仍然是一个开放的挑战，需要更复杂的匹配技术。

Abstract: Internet memes, now a staple of digital communication, play a pivotal role in
how users engage within online communities and allow researchers to gain
insight into contemporary digital culture. These engaging user-generated
content are characterised by their reuse of visual elements also found in other
memes. Matching instances of memes via these shared visual elements, called
Meme Matching, is the basis of a wealth of meme analysis approaches. However,
most existing methods assume that every meme consists of a shared visual
background, called a Template, with some overlaid text, thereby limiting meme
matching to comparing the background image alone. Current approaches exclude
the many memes that are not template-based and limit the effectiveness of
automated meme analysis and would not be effective at linking memes to
contemporary web-based meme dictionaries. In this work, we introduce a broader
formulation of meme matching that extends beyond template matching. We show
that conventional similarity measures, including a novel segment-wise
computation of the similarity measures, excel at matching template-based memes
but fall short when applied to non-template-based meme formats. However, the
segment-wise approach was found to consistently outperform the whole-image
measures on matching non-template-based memes. Finally, we explore a
prompting-based approach using a pretrained Multimodal Large Language Model for
meme matching. Our results highlight that accurately matching memes via shared
visual elements, not just background templates, remains an open challenge that
requires more sophisticated matching techniques.

</details>


### [74] [Beyond Isolated Words: Diffusion Brush for Handwritten Text-Line Generation](https://arxiv.org/abs/2508.03256)
*Gang Dai,Yifan Zhang,Yutao Qin,Qiangya Guo,Shuangping Huang,Shuicheng Yan*

Main category: cs.CV

TL;DR: DiffBrush是一种新的扩散模型，通过解耦风格和多尺度学习来生成逼真的手写文本行，在风格和内容上都表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的手写文本生成方法主要关注孤立的单词，但真实的文本需要关注单词之间的关系，如对齐和间距。因此，生成整个文本行是一个更有前景的任务，但存在建模复杂风格模式和保持内容准确性的挑战。

Method: 提出了一种新颖的基于扩散的文本行生成模型DiffBrush，通过内容解耦风格学习（利用行和列掩码解开风格和内容，以捕捉行内和行间的风格模式）和多尺度内容学习（使用行和单词判别器来确保文本内容的全局连贯性和局部准确性）来解决文本行生成中的风格模式复杂性和内容准确性挑战。

Result: DiffBrush在生成高质量文本行方面表现出色，尤其在风格复现和内容保持方面。

Conclusion: DiffBrush在生成高质量文本行方面表现出色，尤其在风格复现和内容保持方面。

Abstract: Existing handwritten text generation methods primarily focus on isolated
words. However, realistic handwritten text demands attention not only to
individual words but also to the relationships between them, such as vertical
alignment and horizontal spacing. Therefore, generating entire text lines
emerges as a more promising and comprehensive task. However, this task poses
significant challenges, including the accurate modeling of complex style
patterns encompassing both intra- and inter-word relationships, and maintaining
content accuracy across numerous characters. To address these challenges, we
propose DiffBrush, a novel diffusion-based model for handwritten text-line
generation. Unlike existing methods, DiffBrush excels in both style imitation
and content accuracy through two key strategies: (1) content-decoupled style
learning, which disentangles style from content to better capture intra-word
and inter-word style patterns by using column- and row-wise masking; and (2)
multi-scale content learning, which employs line and word discriminators to
ensure global coherence and local accuracy of textual content. Extensive
experiments show that DiffBrush excels in generating high-quality text lines,
particularly in style reproduction and content preservation. Code is available
at https://github.com/dailenson/DiffBrush.

</details>


### [75] [EgoPrompt: Prompt Pool Learning for Egocentric Action Recognition](https://arxiv.org/abs/2508.03266)
*Huaihai Lyu,Chaofan Chen,Yuheng Ji,Changsheng Xu*

Main category: cs.CV

TL;DR: EgoPrompt通过统一提示词池和多样性池标准训练目标，有效解决了中心视角动作识别中动词-名词组件的碎片化表示问题，实现了优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将中心视角动作识别中的动词和名词组件视为独立任务，忽略了它们之间固有的语义和上下文关系，导致表示碎片化和泛化能力不足。因此，需要一种能够有效融合和利用这两种组件信息的方法。

Method: 提出了一种名为EgoPrompt的基于提示学习的框架，用于中心视角动作识别。该框架首先将动词和名词组件的表示分解为精细的模式，然后通过基于注意力机制的交互来融合这些模式，以建立跨组件的交互。此外，引入了多样性池标准（DPC）训练目标，包括提示词选择频率正则化和提示词知识正交化，以确保提示词池的有效性。

Result: EgoPrompt在Ego4D、EPIC-Kitchens和EGTEA数据集上进行了广泛的实验。结果一致表明，EgoPrompt在数据集内、跨数据集以及基础到新颖的泛化基准测试中均取得了最先进的性能。

Conclusion: EgoPrompt通过统一的提示词池和新颖的训练目标（DPC）实现了跨数据集、跨领域和基础到新颖场景的泛化能力，在多个基准测试中达到了最先进的性能。

Abstract: Driven by the increasing demand for applications in augmented and virtual
reality, egocentric action recognition has emerged as a prominent research
area. It is typically divided into two subtasks: recognizing the performed
behavior (i.e., verb component) and identifying the objects being acted upon
(i.e., noun component) from the first-person perspective. However, most
existing approaches treat these two components as independent classification
tasks, focusing on extracting component-specific knowledge while overlooking
their inherent semantic and contextual relationships, leading to fragmented
representations and sub-optimal generalization capability. To address these
challenges, we propose a prompt learning-based framework, EgoPrompt, to conduct
the egocentric action recognition task. Building on the existing prompting
strategy to capture the component-specific knowledge, we construct a Unified
Prompt Pool space to establish interaction between the two types of component
representations. Specifically, the component representations (from verbs and
nouns) are first decomposed into fine-grained patterns with the prompt pair
form. Then, these pattern-level representations are fused through an
attention-based mechanism to facilitate cross-component interaction. To ensure
the prompt pool is informative, we further introduce a novel training
objective, Diverse Pool Criteria. This objective realizes our goals from two
perspectives: Prompt Selection Frequency Regularization and Prompt Knowledge
Orthogonalization. Extensive experiments are conducted on the Ego4D,
EPIC-Kitchens, and EGTEA datasets. The results consistently show that EgoPrompt
achieves state-of-the-art performance across within-dataset, cross-dataset, and
base-to-novel generalization benchmarks.

</details>


### [76] [Efficient Multi-Slide Visual-Language Feature Fusion for Placental Disease Classification](https://arxiv.org/abs/2508.03277)
*Hang Guo,Qing Zhang,Zixuan Gao,Siyuan Yang,Shulin Peng,Xiang Tao,Ting Yu,Yan Wang,Qingli Li*

Main category: cs.CV

TL;DR: EmmPD框架通过优化的病理切片选择和多模态融合（结合文本报告），有效解决了全切片图像分析中的计算挑战和信息丢失问题，实现了胎盘疾病诊断的最优性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决全切片图像（WSIs）分析中存在的计算挑战，以及现有方法在病理切片选择策略和全局上下文丢失方面存在的局限性。

Method: 提出了一种名为EmmPD的高效多模态框架，该框架包含一个两阶段的病理切片选择模块，结合了无参数和可学习的压缩策略，以在计算效率和关键特征保留之间取得平衡。此外，还开发了一个混合多模态融合模块，利用自适应图学习来增强病理特征表示，并结合文本医学报告来丰富全局上下文理解。

Result: 在自行构建的患者级胎盘数据集和两个公开数据集上的大量实验表明，该方法在诊断性能上达到了最先进的水平。

Conclusion: 现有方法在处理全切片图像（WSIs）进行胎盘疾病诊断时，在病理特征选择和全局上下文理解方面存在不足。

Abstract: Accurate prediction of placental diseases via whole slide images (WSIs) is
critical for preventing severe maternal and fetal complications. However, WSI
analysis presents significant computational challenges due to the massive data
volume. Existing WSI classification methods encounter critical limitations: (1)
inadequate patch selection strategies that either compromise performance or
fail to sufficiently reduce computational demands, and (2) the loss of global
histological context resulting from patch-level processing approaches. To
address these challenges, we propose an Efficient multimodal framework for
Patient-level placental disease Diagnosis, named EmmPD. Our approach introduces
a two-stage patch selection module that combines parameter-free and learnable
compression strategies, optimally balancing computational efficiency with
critical feature preservation. Additionally, we develop a hybrid multimodal
fusion module that leverages adaptive graph learning to enhance pathological
feature representation and incorporates textual medical reports to enrich
global contextual understanding. Extensive experiments conducted on both a
self-constructed patient-level Placental dataset and two public datasets
demonstrating that our method achieves state-of-the-art diagnostic performance.
The code is available at https://github.com/ECNU-MultiDimLab/EmmPD.

</details>


### [77] [Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation](https://arxiv.org/abs/2508.03300)
*Jun Luo,Zijing Zhao,Yang Liu*

Main category: cs.CV

TL;DR: SDGPA通过使用文本到图像扩散模型生成数据，并采用渐进式自适应策略来解决零样本领域自适应语义分割问题，取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习语义分割模型在处理训练和测试数据之间的分布偏移方面存在的局限性，尤其是在零样本领域自适应语义分割任务中，即在没有目标图像的情况下，只有目标域风格的文本描述。

Method: SDGPA是一种新颖的方法，它利用预训练的文本到图像扩散模型生成合成数据，并通过编辑源图像的小块并将其合并回来的方式来提高空间精度。此外，它还通过构建增强的中间域来利用更简单的自适应子任务，并通过渐进式自适应策略来减轻合成数据中的噪声影响。

Result: SDGPA在零样本语义分割任务上实现了最先进的性能。

Conclusion: SDGPA在零样本领域自适应语义分割任务上取得了最先进的性能。

Abstract: Deep learning-based semantic segmentation models achieve impressive results
yet remain limited in handling distribution shifts between training and test
data. In this paper, we present SDGPA (Synthetic Data Generation and
Progressive Adaptation), a novel method that tackles zero-shot domain adaptive
semantic segmentation, in which no target images are available, but only a text
description of the target domain's style is provided. To compensate for the
lack of target domain training data, we utilize a pretrained off-the-shelf
text-to-image diffusion model, which generates training images by transferring
source domain images to target style. Directly editing source domain images
introduces noise that harms segmentation because the layout of source images
cannot be precisely maintained. To address inaccurate layouts in synthetic
data, we propose a method that crops the source image, edits small patches
individually, and then merges them back together, which helps improve spatial
precision. Recognizing the large domain gap, SDGPA constructs an augmented
intermediate domain, leveraging easier adaptation subtasks to enable more
stable model adaptation to the target domain. Additionally, to mitigate the
impact of noise in synthetic data, we design a progressive adaptation strategy,
ensuring robust learning throughout the training process. Extensive experiments
demonstrate that our method achieves state-of-the-art performance in zero-shot
semantic segmentation. The code is available at
https://github.com/ROUJINN/SDGPA

</details>


### [78] [BaroPoser: Real-time Human Motion Tracking from IMUs and Barometers in Everyday Devices](https://arxiv.org/abs/2508.03313)
*Libo Zhang,Xinyu Yi,Feng Xu*

Main category: cs.CV

TL;DR: BaroPoser 提出了一种利用智能手机和智能手表中的 IMU 和气压计数据来精确追踪人体姿势和全局翻译的新方法，尤其擅长处理非平坦地形，并且性能优于现有仅使用 IMU 的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动追踪方法通常在传感器测量稀疏和缺乏非平坦地形的运动数据集的情况下，难以实现精确的姿势估计，并且仅限于在平坦地形上恢复运动。为了解决这些问题，本研究旨在提出一种能够利用日常设备（如智能手机和智能手表）的 IMU 和气压计数据，来准确估计人体姿势和全局翻译的方法，尤其是在非平坦地形上。

Method: BaroPoser 提出了一种结合 IMU 和气压计数据来估计人体姿势和全局翻译的新方法。该方法利用气压读数估算传感器高度变化，从而提高姿势估计精度并预测非平坦地形上的全局翻译。此外，研究人员提出了一个局部的“大腿坐标系”来区分局部和全局运动输入，以实现更好的姿势表示学习。

Result: BaroPoser 在公开基准数据集和真实世界录音的评估中，在定量和定性结果上均表现优于仅使用 IMU 且具有相同硬件配置的最先进方法。

Conclusion: BaroPoser 是一种结合智能手机和智能手表中的 IMU 和气压计数据来实时估计人体姿势和全局翻译的方法，它能有效处理非平坦地形，并且在公开基准数据集和真实世界录音的评估中，其性能优于仅使用 IMU 的现有最先进方法。

Abstract: In recent years, tracking human motion using IMUs from everyday devices such
as smartphones and smartwatches has gained increasing popularity. However, due
to the sparsity of sensor measurements and the lack of datasets capturing human
motion over uneven terrain, existing methods often struggle with pose
estimation accuracy and are typically limited to recovering movements on flat
terrain only. To this end, we present BaroPoser, the first method that combines
IMU and barometric data recorded by a smartphone and a smartwatch to estimate
human pose and global translation in real time. By leveraging barometric
readings, we estimate sensor height changes, which provide valuable cues for
both improving the accuracy of human pose estimation and predicting global
translation on non-flat terrain. Furthermore, we propose a local thigh
coordinate frame to disentangle local and global motion input for better pose
representation learning. We evaluate our method on both public benchmark
datasets and real-world recordings. Quantitative and qualitative results
demonstrate that our approach outperforms the state-of-the-art (SOTA) methods
that use IMUs only with the same hardware configuration.

</details>


### [79] [Architectural Insights into Knowledge Distillation for Object Detection: A Comprehensive Review](https://arxiv.org/abs/2508.03317)
*Mahdi Golizadeh,Nassibeh Golizadeh,Mohammad Ali Keyvanrad,Hossein Shirazi*

Main category: cs.CV

TL;DR: 本综述对知识蒸馏在目标检测中的应用进行了分类和评估，重点关注了CNN和Transformer检测器，并对现有方法进行了比较分析，为未来研究指明方向。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在目标检测方面取得了显著进展，但高昂的计算成本限制了其在资源受限设备上的部署。知识蒸馏（KD）通过让小型学生模型学习大型教师模型，提供了一种有效的解决方案，但其在目标检测中的应用面临多重挑战。

Method: 通过提出新颖的以架构为中心的分类法，区分了基于CNN的检测器（骨干、颈部、头部、RPN/RoI级别蒸馏）和基于Transformer的检测器（查询、特征、logit级别蒸馏），并使用MS COCO和PASCAL VOC数据集评估了代表性方法。

Result: 对代表性方法进行了评估和比较分析，展示了不同KD方法的有效性。

Conclusion: 该综述对知识蒸馏在目标检测中的应用进行了分类和评估，旨在为未来高效可扩展的检测系统研究提供指导。

Abstract: Object detection has achieved remarkable accuracy through deep learning, yet
these improvements often come with increased computational cost, limiting
deployment on resource-constrained devices. Knowledge Distillation (KD)
provides an effective solution by enabling compact student models to learn from
larger teacher models. However, adapting KD to object detection poses unique
challenges due to its dual objectives-classification and localization-as well
as foreground-background imbalance and multi-scale feature representation. This
review introduces a novel architecture-centric taxonomy for KD methods,
distinguishing between CNN-based detectors (covering backbone-level,
neck-level, head-level, and RPN/RoI-level distillation) and Transformer-based
detectors (including query-level, feature-level, and logit-level distillation).
We further evaluate representative methods using the MS COCO and PASCAL VOC
datasets with mAP@0.5 as performance metric, providing a comparative analysis
of their effectiveness. The proposed taxonomy and analysis aim to clarify the
evolving landscape of KD in object detection, highlight current challenges, and
guide future research toward efficient and scalable detection systems.

</details>


### [80] [Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation](https://arxiv.org/abs/2508.03320)
*Peiyu Wang,Yi Peng,Yimeng Gan,Liang Hu,Tianyidan Xie,Xiaokun Wang,Yichen Wei,Chuanxin Tang,Bo Zhu,Changshi Li,Hongyang Wei,Eric Li,Xuchen Song,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Skywork UniPic 是一个 1.5B 参数的统一多模态模型，可以在普通硬件上实现最先进的图像理解、生成和编辑性能，同时资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 介绍 Skywork UniPic，一个 15 亿参数的自回归模型，旨在统一图像理解、文本到图像生成和图像编辑，无需任务特定的适配器或模块间连接器，并证明紧凑型多模态系统可以在商品硬件上实现最先进的性能。

Method: 该模型采用了三种关键技术：(1) 解耦编码策略，结合了用于合成的掩码自回归编码器和用于理解的 SigLIP2 编码器，并将它们连接到一个共享的自回归解码器；(2) 渐进式、分辨率感知的训练计划，从 256x256 扩展到 1024x1024，并动态解冻参数以平衡容量和稳定性；(3) 精心策划的 100 百万规模数据集，并辅以特定任务的奖励模型来优化生成和编辑目标。

Result: Skywork UniPic 达到了 0.86 的 GenEval 分数，超过了大多数现有的统一模型；在 DPG-Bench 复杂生成方面创下了 85.5 的新纪录；在图像编辑方面，在 GEditBench-EN 上达到了 5.83，在 ImgEdit-Bench 上达到了 3.49；并且可以在低于 15GB 的 GPU 内存（例如 RTX 4090）上生成 1024x1024 的图像。

Conclusion: Skywork UniPic 是一个 1.5B 参数的自回归模型，它在单一架构中统一了图像理解、文本到图像生成和图像编辑，无需任务特定的适配器或模块间连接器。该模型证明了紧凑型多模态系统可以在标准硬件上实现最先进的性能，并为可部署、高保真的多模态人工智能提供了一个实用的范例。

Abstract: We introduce Skywork UniPic, a 1.5 billion-parameter autoregressive model
that unifies image understanding, text-to-image generation, and image editing
within a single architecture-eliminating the need for task-specific adapters or
inter-module connectors-and demonstrate that compact multimodal systems can
achieve state-of-the-art performance on commodity hardware. Skywork UniPic
achieves a GenEval score of 0.86, surpassing most existing unified models; sets
a new DPG-Bench complex-generation record of 85.5; attains 5.83 on
GEditBench-EN and 3.49 on ImgEdit-Bench for image editing; and generates 1024 x
1024 images with under 15 GB of GPU memory (e.g., RTX 4090). (1) a decoupled
encoding strategy that leverages a masked autoregressive encoder for synthesis
and a SigLIP2 encoder for understanding, all feeding a shared autoregressive
decoder; (2) a progressive, resolution-aware training schedule scaling from 256
x 256 to 1024 x 1024 while dynamically unfreezing parameters to balance
capacity and stability; and (3) meticulously curated, 100 million-scale
datasets augmented with task-specific reward models to refine generation and
editing objectives. By demonstrating that high-fidelity multimodal integration
need not incur prohibitive resource demands, Skywork UniPic establishes a
practical paradigm for deployable, high-fidelity multimodal AI. Code and
weights are publicly available at
https://huggingface.co/Skywork/Skywork-UniPic-1.5B.

</details>


### [81] [Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation](https://arxiv.org/abs/2508.03334)
*Xunzhi Xiang,Yabo Chen,Guiyu Zhang,Zhongyu Wang,Zhe Gao,Quanming Xiang,Gonghu Shang,Junqi Liu,Haibin Huang,Yang Gao,Chi Zhang,Qi Fan,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种新的“规划后填充”框架（MMPL），用于解决现有扩散模型在长视频生成中的时间限制问题。该框架通过分层规划（微观和宏观）和并行内容填充来生成长视频，提高了视频的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前的自回归扩散模型在视频生成方面表现出色，但通常仅限于短时间。理论分析表明，自回归建模通常会因误差累积而产生时间漂移，并阻碍长视频合成的并行化。

Method: 提出了一种新颖的、以宏观规划（MMPL）为中心的“规划后填充”框架，用于长视频生成。该框架通过两个分层阶段（微观规划和宏观规划）为整个视频勾画全局故事线。微观规划预测每个短视频片段内的未来关键帧稀疏集，为高质量视频片段生成提供运动和外观先验。宏观规划通过微观计划的自回归链将片段内的关键帧规划扩展到整个视频，确保跨视频片段的长期一致性。随后，基于MMPL的内容填充并行生成所有中间帧，实现自回归生成的并行化。通过自适应工作量调度进一步优化并行化，以平衡GPU执行并加速自回归视频生成。

Result: 实验证实，该方法在质量和稳定性方面优于现有的长视频生成模型。

Conclusion: 该模型在视频质量和稳定性方面优于现有的长视频生成模型。

Abstract: Current autoregressive diffusion models excel at video generation but are
generally limited to short temporal durations. Our theoretical analysis
indicates that the autoregressive modeling typically suffers from temporal
drift caused by error accumulation and hinders parallelization in long video
synthesis. To address these limitations, we propose a novel
planning-then-populating framework centered on Macro-from-Micro Planning (MMPL)
for long video generation. MMPL sketches a global storyline for the entire
video through two hierarchical stages: Micro Planning and Macro Planning.
Specifically, Micro Planning predicts a sparse set of future keyframes within
each short video segment, offering motion and appearance priors to guide
high-quality video segment generation. Macro Planning extends the in-segment
keyframes planning across the entire video through an autoregressive chain of
micro plans, ensuring long-term consistency across video segments.
Subsequently, MMPL-based Content Populating generates all intermediate frames
in parallel across segments, enabling efficient parallelization of
autoregressive generation. The parallelization is further optimized by Adaptive
Workload Scheduling for balanced GPU execution and accelerated autoregressive
video generation. Extensive experiments confirm that our method outperforms
existing long video generation models in quality and stability. Generated
videos and comparison results are in our project page.

</details>


### [82] [Beyond Illumination: Fine-Grained Detail Preservation in Extreme Dark Image Restoration](https://arxiv.org/abs/2508.03336)
*Tongshun Zhang,Pingping Liu,Zixuan Zhong,Zijian Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: 一种新的双阶段深度学习方法，利用傅里叶变换和Mamba模块来提高极暗图像的细节恢复能力，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图像增强方法在恢复极暗图像中的细粒度细节方面存在挑战，常常无法保留精细细节和锐利边缘，限制了其在文本和边缘检测等下游应用中的效果。

Method: 提出了一种高效的双阶段方法，包括残差傅里叶引导模块（RFGM）和互补的Mamba模块（Patch Mamba和Grad Mamba）。RFGM在频域中恢复全局照明，而Mamba模块则用于纹理结构细化，Patch Mamba处理非下采样块以增强细节，Grad Mamba则专注于高梯度区域以重建清晰边缘。

Result: 所提出的方法在细节恢复方面取得了显著的性能提升，同时保持了效率，并且所提出的模块轻量级，可以轻松集成到现有框架中。

Conclusion: 该方法在多个基准数据集和下游应用上进行了广泛的实验，证明了其在提高细节恢复性能和保持效率方面具有显著优势。所提出的模块轻量级，可以轻松集成到现有的基于傅里叶的框架中，计算开销极小。

Abstract: Recovering fine-grained details in extremely dark images remains challenging
due to severe structural information loss and noise corruption. Existing
enhancement methods often fail to preserve intricate details and sharp edges,
limiting their effectiveness in downstream applications like text and edge
detection. To address these deficiencies, we propose an efficient dual-stage
approach centered on detail recovery for dark images. In the first stage, we
introduce a Residual Fourier-Guided Module (RFGM) that effectively restores
global illumination in the frequency domain. RFGM captures inter-stage and
inter-channel dependencies through residual connections, providing robust
priors for high-fidelity frequency processing while mitigating error
accumulation risks from unreliable priors. The second stage employs
complementary Mamba modules specifically designed for textural structure
refinement: (1) Patch Mamba operates on channel-concatenated non-downsampled
patches, meticulously modeling pixel-level correlations to enhance fine-grained
details without resolution loss. (2) Grad Mamba explicitly focuses on
high-gradient regions, alleviating state decay in state space models and
prioritizing reconstruction of sharp edges and boundaries. Extensive
experiments on multiple benchmark datasets and downstream applications
demonstrate that our method significantly improves detail recovery performance
while maintaining efficiency. Crucially, the proposed modules are lightweight
and can be seamlessly integrated into existing Fourier-based frameworks with
minimal computational overhead. Code is available at
https://github.com/bywlzts/RFGM.

</details>


### [83] [Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration](https://arxiv.org/abs/2508.03337)
*Shaoguang Wang,Jianxiang He,Yijie Xu,Ziyang Chen,Weiyu Guo,Hui Xiong*

Main category: cs.CV

TL;DR: 通过自适应帧剪枝（AFP）和语义图，解决了视频问答中多模态大语言模型的效率和性能问题，显著减少了计算资源消耗，并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视频问答中的应用受到处理大量视频帧的高令牌成本的限制，并且存在采样过多帧反而会因上下文稀释而降低性能的“少即是多”现象，以及现有关键帧选择方法仍存在显著的时间冗余（视觉回声）。

Method: 提出了一种名为自适应帧剪枝（AFP）的新型后处理方法，该方法使用自适应分层聚类算法在融合的ResNet-50和CLIP特征空间中识别和合并视觉回声（时间冗余），并通过引入轻量级、基于文本的语义图来补偿信息损失。

Result: 在LongVideoBench和VideoMME基准测试中，该方法实现了高达86.9%的所需帧数减少和83.2%的总输入令牌减少，同时在许多情况下提高了准确性。

Conclusion: 该方法通过自适应帧剪枝（AFP）有效解决了多模态大语言模型在视频问答中的高令牌成本和性能下降问题，显著减少了处理的帧数和令牌数量，同时提高了效率和准确性。

Abstract: The practical application of Multimodal Large Language Models (MLLMs) to
Video Question Answering (Video-QA) is severely hindered by the high token cost
of processing numerous video frames. While increasing the number of sampled
frames is a common strategy, we observe a "less is more" phenomenon where
excessive frames can paradoxically degrade performance due to context dilution.
Concurrently, state-of-the-art keyframe selection methods, while effective,
still yield significant temporal redundancy, which we term 'visual echoes'. To
address these dual challenges, we propose Adaptive Frame-Pruning (AFP), a novel
post-processing method that intelligently prunes the selected keyframes. AFP
employs an adaptive hierarchical clustering algorithm on a fused ResNet-50 and
CLIP feature space to identify and merge these echoes into single
representatives. To compensate for information loss, we then introduce a
lightweight, text-based semantic graph that provides critical context with
minimal token overhead. Conducting extensive experiments on the LongVideoBench
and VideoMME benchmarks across multiple leading MLLMs, our full approach
demonstrates a drastic reduction in required frames by up to 86.9% and total
input tokens by up to 83.2%. Crucially, by providing a concise, high-quality
set of frames, our method not only enhances efficiency but often improves
accuracy over baselines that use more frames. The code will be released upon
publication.

</details>


### [84] [CIVQLLIE: Causal Intervention with Vector Quantization for Low-Light Image Enhancement](https://arxiv.org/abs/2508.03338)
*Tongshun Zhang,Pingping Liu,Zhe Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: CIVQLLIE利用离散表示和因果干预来增强低光图像，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法（数据驱动和基于物理的方法）在极暗或复杂场景下存在不足，缺乏可解释性或依赖不可靠的先验知识。

Method: CIVQLLIE框架，采用向量量化（VQ）将连续图像特征映射到离散代码本，并通过像素级因果干预（PCI）、特征感知因果干预（FCI）和低频选择性注意力门控（LSAG）来校正分布偏移，最后利用高频细节重建模块（HDRM）和可变形卷积重建细节。

Result: CIVQLLIE框架在低光图像增强任务中，通过离散表示学习和因果干预，实现了更好的性能和更强的泛化能力。

Conclusion: CIVQLLIE框架通过多层次因果干预，将低光图像映射到离散的视觉令牌，并利用结构信息重建细节，解决了现有低光图像增强方法的局限性。

Abstract: Images captured in nighttime scenes suffer from severely reduced visibility,
hindering effective content perception. Current low-light image enhancement
(LLIE) methods face significant challenges: data-driven end-to-end mapping
networks lack interpretability or rely on unreliable prior guidance, struggling
under extremely dark conditions, while physics-based methods depend on
simplified assumptions that often fail in complex real-world scenarios. To
address these limitations, we propose CIVQLLIE, a novel framework that
leverages the power of discrete representation learning through causal
reasoning. We achieve this through Vector Quantization (VQ), which maps
continuous image features to a discrete codebook of visual tokens learned from
large-scale high-quality images. This codebook serves as a reliable prior,
encoding standardized brightness and color patterns that are independent of
degradation. However, direct application of VQ to low-light images fails due to
distribution shifts between degraded inputs and the learned codebook.
Therefore, we propose a multi-level causal intervention approach to
systematically correct these shifts. First, during encoding, our Pixel-level
Causal Intervention (PCI) module intervenes to align low-level features with
the brightness and color distributions expected by the codebook. Second, a
Feature-aware Causal Intervention (FCI) mechanism with Low-frequency Selective
Attention Gating (LSAG) identifies and enhances channels most affected by
illumination degradation, facilitating accurate codebook token matching while
enhancing the encoder's generalization performance through flexible
feature-level intervention. Finally, during decoding, the High-frequency Detail
Reconstruction Module (HDRM) leverages structural information preserved in the
matched codebook representations to reconstruct fine details using deformable
convolution techniques.

</details>


### [85] [WaMo: Wavelet-Enhanced Multi-Frequency Trajectory Analysis for Fine-Grained Text-Motion Retrieval](https://arxiv.org/abs/2508.03343)
*Junlong Ren,Gangjian Zhang,Honghao Fu,Pengcheng Wu,Hao Wang*

Main category: cs.CV

TL;DR: WaMo是一个新颖的小波多频特征提取框架，用于文本-动作检索，通过多分辨率身体关节细节和时间连贯性学习来提高与文本的对齐精度，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本-动作检索（TMR）方法在区分不同身体部位及其动力学方面存在不足，限制了与文本的精确语义对齐。

Method: WaMo框架包含三个关键组件：(1) 轨迹小波分解将运动信号分解为频率分量，保留局部运动学细节和全局运动语义；(2) 轨迹小波重构使用可学习的反小波变换从提取的特征中重构原始关节轨迹，确保保留重要的时空信息；(3) 无序运动序列预测通过重新排序打乱的运动序列来学习固有的时间连贯性，增强运动-文本对齐。

Result: 在HumanML3D和KIT-ML数据集上，WaMo在Rsum上分别取得了17.0%和18.2%的提升，优于现有的最先进方法。

Conclusion: WaMo通过小波变换捕捉多分辨率下的身体关节的特定部分和随时间变化的运动细节，提取判别性运动特征，实现与文本的细粒度对齐。

Abstract: Text-Motion Retrieval (TMR) aims to retrieve 3D motion sequences semantically
relevant to text descriptions. However, matching 3D motions with text remains
highly challenging, primarily due to the intricate structure of human body and
its spatial-temporal dynamics. Existing approaches often overlook these
complexities, relying on general encoding methods that fail to distinguish
different body parts and their dynamics, limiting precise semantic alignment.
To address this, we propose WaMo, a novel wavelet-based multi-frequency feature
extraction framework. It fully captures part-specific and time-varying motion
details across multiple resolutions on body joints, extracting discriminative
motion features to achieve fine-grained alignment with texts. WaMo has three
key components: (1) Trajectory Wavelet Decomposition decomposes motion signals
into frequency components that preserve both local kinematic details and global
motion semantics. (2) Trajectory Wavelet Reconstruction uses learnable inverse
wavelet transforms to reconstruct original joint trajectories from extracted
features, ensuring the preservation of essential spatial-temporal information.
(3) Disordered Motion Sequence Prediction reorders shuffled motion sequences to
improve the learning of inherent temporal coherence, enhancing motion-text
alignment. Extensive experiments demonstrate WaMo's superiority, achieving
17.0\% and 18.2\% improvements in $Rsum$ on HumanML3D and KIT-ML datasets,
respectively, outperforming existing state-of-the-art (SOTA) methods.

</details>


### [86] [FedPromo: Federated Lightweight Proxy Models at the Edge Bring New Domains to Foundation Models](https://arxiv.org/abs/2508.03356)
*Matteo Caligiuri,Francesco Barbato,Donald Shenaj,Umberto Michieli,Pietro Zanuttigh*

Main category: cs.CV

TL;DR: FedPromo是一种新颖的联邦学习框架，通过在客户端训练轻量级代理模型来高效地适应大型基础模型，显著降低了计算开销并保护了隐私。


<details>
  <summary>Details</summary>
Motivation: 为了解决在客户端设备上训练大型模型需要大量计算资源的问题，FedPromo框架被提出，以实现将中央服务器上存储的大型基础模型高效地适应到远程客户端遇到的新领域。

Method: FedPromo采用两阶段流程：首先，服务器端知识蒸馏将大型基础模型（如Transformer）的表示与紧凑型模型（如CNN）的表示对齐；然后，将紧凑型模型的编码器部署到客户端设备，在本地学习可训练的分类器，并将这些分类器聚合后无缝传输回基础模型，从而实现个性化适应。

Result: FedPromo显著降低了计算开销，同时保持了隐私。通过新颖的正则化策略，该框架实现了去中心化的多域学习，平衡了性能、隐私和资源效率。在五个图像分类基准测试上的大量实验表明，FedPromo在资源受限的客户端条件下优于现有方法。

Conclusion: FedPromo通过新颖的正则化策略实现了去中心化的多域学习，平衡了性能、隐私和资源效率。实验结果表明，FedPromo在图像分类基准测试中优于现有方法，同时满足了资源受限客户端的要求。

Abstract: Federated Learning (FL) is an established paradigm for training deep learning
models on decentralized data. However, as the size of the models grows,
conventional FL approaches often require significant computational resources on
client devices, which may not be feasible. We introduce FedPromo, a novel
framework that enables efficient adaptation of large-scale foundation models
stored on a central server to new domains encountered only by remote clients.
Instead of directly training the large model on client devices, FedPromo
optimizes lightweight proxy models via FL, significantly reducing computational
overhead while maintaining privacy. Our method follows a two-stage process:
first, server-side knowledge distillation aligns the representations of a
large-scale foundation model (e.g., a transformer) with those of a compact
counterpart (e.g., a CNN). Then, the compact model encoder is deployed to
client devices, where trainable classifiers are learned locally. These
classifiers are subsequently aggregated and seamlessly transferred back to the
foundation model, facilitating personalized adaptation without requiring direct
access to user data. Through novel regularization strategies, our framework
enables decentralized multi-domain learning, balancing performance, privacy,
and resource efficiency. Extensive experiments on five image classification
benchmarks demonstrate that FedPromo outperforms existing methods while
assuming limited-resource clients.

</details>


### [87] [Diffusion Once and Done: Degradation-Aware LoRA for Efficient All-in-One Image Restoration](https://arxiv.org/abs/2508.03373)
*Ni Tang,Xiaotong Luo,Zihan Cheng,Liangtai Zhou,Dongxiao Zhang,Yanyun Qu*

Main category: cs.CV

TL;DR: 提出了一种名为Diffusion Once and Done (DOD)的高效图像恢复方法，通过一次性采样Stable Diffusion模型，并结合多降质特征调制、参数高效的条件低秩适应和高保真细节增强模块，实现了优于现有方法的视觉质量和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有AiOIR方法存在推理成本高和对不同降质类型的适应性有限的问题。

Method: 1. 多降质特征调制：捕获不同降质提示。
2. 参数高效的条件低秩适应：集成提示以适应不同降质类型。
3. 高保真细节增强模块：集成到SD的解码器中以增强细节。

Result: 实验证明，DOD在视觉质量和推理效率方面优于现有基于扩散的恢复方法。

Conclusion: 提出的Diffusion Once and Done (DOD)方法在视觉质量和推理效率方面均优于现有的基于扩散的恢复方法。

Abstract: Diffusion models have revealed powerful potential in all-in-one image
restoration (AiOIR), which is talented in generating abundant texture details.
The existing AiOIR methods either retrain a diffusion model or fine-tune the
pretrained diffusion model with extra conditional guidance. However, they often
suffer from high inference costs and limited adaptability to diverse
degradation types. In this paper, we propose an efficient AiOIR method,
Diffusion Once and Done (DOD), which aims to achieve superior restoration
performance with only one-step sampling of Stable Diffusion (SD) models.
Specifically, multi-degradation feature modulation is first introduced to
capture different degradation prompts with a pretrained diffusion model. Then,
parameter-efficient conditional low-rank adaptation integrates the prompts to
enable the fine-tuning of the SD model for adapting to different degradation
types. Besides, a high-fidelity detail enhancement module is integrated into
the decoder of SD to improve structural and textural details. Experiments
demonstrate that our method outperforms existing diffusion-based restoration
approaches in both visual quality and inference efficiency.

</details>


### [88] [GRASPing Anatomy to Improve Pathology Segmentation](https://arxiv.org/abs/2508.03374)
*Keyi Li,Alexander Jaus,Jens Kleesiek,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: GRASP框架通过整合解剖学信息，提高了病理分割的准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的深度学习方法仅依赖纯粹的模式识别，而忽略了病理学发展中的解剖学背景。为了弥合这一差距，需要一种能够利用解剖学信息来提高病理学分割准确性的方法。

Method: GRASP是一个模块化的、即插即用的框架，通过伪标签整合和特征对齐来利用现有的解剖分割模型，以增强病理分割模型。它将解剖学知识集成到标准的病理优化方案中，而无需重新训练解剖学组件。

Result: GRASP在两个PET/CT数据集上进行了评估，系统性消融研究表明，其结合了解剖学伪标签作为输入通道和Transformer引导的解剖学特征融合的双重解剖学注入策略，有效融入了解剖学背景，从而在多个评估指标和多样化的架构上始终取得优异排名。

Conclusion: GRASP框架通过结合伪标签整合和特征对齐，有效利用现有的解剖分割模型来增强病理分割模型，并在多个评估指标和多样化的架构上始终表现出色。

Abstract: Radiologists rely on anatomical understanding to accurately delineate
pathologies, yet most current deep learning approaches use pure pattern
recognition and ignore the anatomical context in which pathologies develop. To
narrow this gap, we introduce GRASP (Guided Representation Alignment for the
Segmentation of Pathologies), a modular plug-and-play framework that enhances
pathology segmentation models by leveraging existing anatomy segmentation
models through pseudolabel integration and feature alignment. Unlike previous
approaches that obtain anatomical knowledge via auxiliary training, GRASP
integrates into standard pathology optimization regimes without retraining
anatomical components. We evaluate GRASP on two PET/CT datasets, conduct
systematic ablation studies, and investigate the framework's inner workings. We
find that GRASP consistently achieves top rankings across multiple evaluation
metrics and diverse architectures. The framework's dual anatomy injection
strategy, combining anatomical pseudo-labels as input channels with
transformer-guided anatomical feature fusion, effectively incorporates
anatomical context.

</details>


### [89] [GaitAdapt: Continual Learning for Evolving Gait Recognition](https://arxiv.org/abs/2508.03375)
*Jingjie Wang,Shunli Zhang,Xiang Wei,Senmao Tian*

Main category: cs.CV

TL;DR: Continual gait recognition requires models that can learn from new data without forgetting old data. This paper proposes GaitAdapt, a new task for this purpose, and GaitAdapter, a method that uses graph neural networks and a novel distance stability technique to achieve this, showing improved performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: Current gait recognition methods require retraining on new datasets, leading to performance degradation on older datasets due to knowledge forgetting. This paper addresses the challenge of continual learning in gait recognition.

Method: GaitAdapt is a continual gait recognition task. GaitAdapter is a non-replay continual learning approach that integrates the GaitPartition Adaptive Knowledge (GPAK) module using graph neural networks to aggregate common gait patterns into a graph vector repository, which is then used to improve gait feature discriminability. A Euclidean Distance Stability Method (EDSN) based on negative pairs is also introduced to maintain the relative spatial distributions of gait samples across tasks.

Result: Extensive evaluations demonstrate that GaitAdapter effectively retains gait knowledge acquired from diverse tasks, exhibiting markedly superior discriminative capability compared to alternative methods.

Conclusion: GaitAdapter in the proposed GaitAdapt task effectively retains gait knowledge across diverse tasks and exhibits superior discriminative capability compared to alternative methods.

Abstract: Current gait recognition methodologies generally necessitate retraining when
encountering new datasets. Nevertheless, retrained models frequently encounter
difficulties in preserving knowledge from previous datasets, leading to a
significant decline in performance on earlier test sets. To tackle these
challenges, we present a continual gait recognition task, termed GaitAdapt,
which supports the progressive enhancement of gait recognition capabilities
over time and is systematically categorized according to various evaluation
scenarios. Additionally, we propose GaitAdapter, a non-replay continual
learning approach for gait recognition. This approach integrates the
GaitPartition Adaptive Knowledge (GPAK) module, employing graph neural networks
to aggregate common gait patterns from current data into a repository
constructed from graph vectors. Subsequently, this repository is used to
improve the discriminability of gait features in new tasks, thereby enhancing
the model's ability to effectively recognize gait patterns. We also introduce a
Euclidean Distance Stability Method (EDSN) based on negative pairs, which
ensures that newly added gait samples from different classes maintain similar
relative spatial distributions across both previous and current gait tasks,
thereby alleviating the impact of task changes on the distinguishability of
original domain features. Extensive evaluations demonstrate that GaitAdapter
effectively retains gait knowledge acquired from diverse tasks, exhibiting
markedly superior discriminative capability compared to alternative methods.

</details>


### [90] [Neutralizing Token Aggregation via Information Augmentation for Efficient Test-Time Adaptation](https://arxiv.org/abs/2508.03388)
*Yizhe Xiong,Zihan Zhou,Yiwen Liang,Hui Chen,Zijia Lin,Tianxiang Hao,Fan Zhang,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: NAVIA是一种高效的测试时间自适应（TTA）方法，通过增强[CLS]令牌和引入自适应偏差来解决令牌聚合带来的性能下降问题，实现了性能和效率的双重提升。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间自适应（TTA）方法虽然有效，但计算开销大，限制了其在资源受限场景中的应用。令牌聚合方法虽然能降低推理成本，但会导致显著的性能下降。本研究旨在解决高效测试时间自适应（ETTA）问题，即在降低推理延迟的同时保持TTA的自适应能力。

Method: 提出了一种名为NAVIA（Neutralize Token Aggregation via Information Augmentation）的新方法，包括增强[CLS]令牌嵌入和引入浅层中的自适应偏差。理论上证明了这些增强可以通过熵最小化来恢复因令牌聚合造成的信息损失。

Result: NAVIA在各种分布外基准测试中，性能显著优于现有最先进方法（超过2.5%），同时推理延迟降低超过20%。

Conclusion: NAVIA通过增强[CLS]令牌嵌入并结合浅层中的自适应偏差，成功地恢复了因令牌聚合而丢失的信息，在多种分布外基准测试中表现出色，在保持20%以上推理延迟降低的同时，性能提升超过2.5%，有效解决了高效测试时间自适应（ETTA）的挑战。

Abstract: Test-Time Adaptation (TTA) has emerged as an effective solution for adapting
Vision Transformers (ViT) to distribution shifts without additional training
data. However, existing TTA methods often incur substantial computational
overhead, limiting their applicability in resource-constrained real-world
scenarios. To reduce inference cost, plug-and-play token aggregation methods
merge redundant tokens in ViTs to reduce total processed tokens. Albeit
efficient, it suffers from significant performance degradation when directly
integrated with existing TTA methods. We formalize this problem as Efficient
Test-Time Adaptation (ETTA), seeking to preserve the adaptation capability of
TTA while reducing inference latency. In this paper, we first provide a
theoretical analysis from a novel mutual information perspective, showing that
token aggregation inherently leads to information loss, which cannot be fully
mitigated by conventional norm-tuning-based TTA methods. Guided by this
insight, we propose to \textbf{N}eutralize Token \textbf{A}ggregation
\textbf{v}ia \textbf{I}nformation \textbf{A}ugmentation (\textbf{NAVIA}).
Specifically, we directly augment the [CLS] token embedding and incorporate
adaptive biases into the [CLS] token in shallow layers of ViTs. We
theoretically demonstrate that these augmentations, when optimized via entropy
minimization, recover the information lost due to token aggregation. Extensive
experiments across various out-of-distribution benchmarks demonstrate that
NAVIA significantly outperforms state-of-the-art methods by over 2.5\%, while
achieving an inference latency reduction of more than 20\%, effectively
addressing the ETTA challenge.

</details>


### [91] [DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition](https://arxiv.org/abs/2508.03397)
*Xinzhu Li,Juepeng Zheng,Yikun Chen,Xudong Mao,Guanghui Yue,Wei Zhou,Chenlei Lv,Ruomei Wang,Fan Zhou,Baoquan Zhao*

Main category: cs.CV

TL;DR: DepthGait uses depth maps from RGB images along with silhouettes for better gait recognition, outperforming previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing 2D representations like binary silhouettes and skeletons in gait recognition lack sufficient cues to handle viewpoint variations and capture finer details of gait. This paper aims to enhance gait recognition by incorporating RGB-derived depth maps.

Method: The framework estimates depth maps from RGB image sequences and uses them as a new modality alongside 2D silhouettes. A multi-scale and cross-level fusion scheme is developed to combine these two modalities.

Result: DepthGait achieves state-of-the-art performance and an impressive mean rank-1 accuracy on challenging datasets, demonstrating its effectiveness compared to peer methods.

Conclusion: The proposed DepthGait framework, which incorporates RGB-derived depth maps and silhouettes with a novel multi-scale and cross-level fusion scheme, achieves state-of-the-art performance in gait recognition, outperforming existing methods on standard benchmarks.

Abstract: Robust gait recognition requires highly discriminative representations, which
are closely tied to input modalities. While binary silhouettes and skeletons
have dominated recent literature, these 2D representations fall short of
capturing sufficient cues that can be exploited to handle viewpoint variations,
and capture finer and meaningful details of gait. In this paper, we introduce a
novel framework, termed DepthGait, that incorporates RGB-derived depth maps and
silhouettes for enhanced gait recognition. Specifically, apart from the 2D
silhouette representation of the human body, the proposed pipeline explicitly
estimates depth maps from a given RGB image sequence and uses them as a new
modality to capture discriminative features inherent in human locomotion. In
addition, a novel multi-scale and cross-level fusion scheme has also been
developed to bridge the modality gap between depth maps and silhouettes.
Extensive experiments on standard benchmarks demonstrate that the proposed
DepthGait achieves state-of-the-art performance compared to peer methods and
attains an impressive mean rank-1 accuracy on the challenging datasets.

</details>


### [92] [SCFlow: Implicitly Learning Style and Content Disentanglement with Flow Models](https://arxiv.org/abs/2508.03402)
*Pingchuan Ma,Xiaopei Yang,Yusong Li,Ming Gui,Felix Krause,Johannes Schusterbauer,Björn Ommer*

Main category: cs.CV

TL;DR: SCF-Flow 通过可逆地融合风格和内容，在不进行显式解耦的情况下，自然地实现了风格和内容的解耦，并在各项任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新的方法来解决视觉模型中风格和内容分离的挑战，不依赖于显式的解耦，而是通过学习可逆的融合来实现。

Method: SCF-Flow 框架，利用流匹配在纠缠和解耦表示之间学习双向映射，并引入了一个包含510,000个样本的合成数据集来模拟解耦过程。

Result: SCF-Flow 在各种任务中实现了可控生成，并在 ImageNet-1k 和 WikiArt 数据集上实现了零样本泛化，证明了其性能的竞争力。

Conclusion: SCF-Flow 框架通过学习可逆的融合与分离，使解耦成为一种自然而然的现象，并在各种任务中展现出优越的性能。

Abstract: Explicitly disentangling style and content in vision models remains
challenging due to their semantic overlap and the subjectivity of human
perception. Existing methods propose separation through generative or
discriminative objectives, but they still face the inherent ambiguity of
disentangling intertwined concepts. Instead, we ask: Can we bypass explicit
disentanglement by learning to merge style and content invertibly, allowing
separation to emerge naturally? We propose SCFlow, a flow-matching framework
that learns bidirectional mappings between entangled and disentangled
representations. Our approach is built upon three key insights: 1) Training
solely to merge style and content, a well-defined task, enables invertible
disentanglement without explicit supervision; 2) flow matching bridges on
arbitrary distributions, avoiding the restrictive Gaussian priors of diffusion
models and normalizing flows; and 3) a synthetic dataset of 510,000 samples (51
styles $\times$ 10,000 content samples) was curated to simulate disentanglement
through systematic style-content pairing. Beyond controllable generation tasks,
we demonstrate that SCFlow generalizes to ImageNet-1k and WikiArt in zero-shot
settings and achieves competitive performance, highlighting that
disentanglement naturally emerges from the invertible merging process.

</details>


### [93] [Sparsity and Total Variation Constrained Multilayer Linear Unmixing for Hyperspectral Imagery](https://arxiv.org/abs/2508.03403)
*Gang Yang*

Main category: cs.CV

TL;DR: 提出了一种新的稀疏和全变分约束的多层线性解混（STVMLU）算法，用于高光谱图像处理。该算法通过多层矩阵分解、TV约束和L1/2稀疏约束提高了解混精度，并使用ADMM优化。实验证明STVMLU优于其他算法。


<details>
  <summary>Details</summary>
Motivation: 为了提高高光谱图像解混的准确性，考虑了相邻空间相似性，并利用L1/2范数稀疏约束来表征丰度矩阵的稀疏性。

Method: 提出了一种基于多层矩阵分解、L1/2范数稀疏约束和全变分（TV）约束的STVMLU算法，并采用交替方向乘子法（ADMM）进行优化。

Result: 实验结果表明，STVMLU算法在真实和合成数据集上均优于其他算法。

Conclusion: STVMLU算法在真实和合成数据集上均优于其他算法，能够有效提取高光谱图像中的端元和丰度。

Abstract: Hyperspectral unmixing aims at estimating material signatures (known as
endmembers) and the corresponding proportions (referred to abundances), which
is a critical preprocessing step in various hyperspectral imagery applications.
This study develops a novel approach called sparsity and total variation (TV)
constrained multilayer linear unmixing (STVMLU) for hyperspectral imagery.
Specifically, based on a multilayer matrix factorization model, to improve the
accuracy of unmixing, a TV constraint is incorporated to consider adjacent
spatial similarity. Additionally, a L1/2-norm sparse constraint is adopted to
effectively characterize the sparsity of the abundance matrix. For optimizing
the STVMLU model, the method of alternating direction method of multipliers
(ADMM) is employed, which allows for the simultaneous extraction of endmembers
and their corresponding abundance matrix. Experimental results illustrate the
enhanced performance of the proposed STVMLU when compared to other algorithms.

</details>


### [94] [Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling](https://arxiv.org/abs/2508.03404)
*Xinlei Yu,Zhangquan Chen,Yudong Zhang,Shilin Lu,Ruolin Shen,Jiangning Zhang,Xiaobin Hu,Yanwei Fu,Shuicheng Yan*

Main category: cs.CV

TL;DR: MACT是一个多代理协作框架，通过测试时扩展和智能代理协作，解决了现有视觉-语言模型的局限性，在文档理解和视觉问答任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在参数规模、自我修正能力、长视觉上下文理解和复杂推理方面存在局限，导致在文档类任务上表现不佳。

Method: MACT框架，一个包含规划、执行、判断和回答四个独立的小型代理（agent）的多代理协作框架，并结合了测试时（test-time）的扩展策略。其核心创新在于'判断'代理的独立验证和重定向修正机制，以及混合奖励建模和代理级别的混合测试时扩展策略。

Result: MACT框架在文档和非文档的基准测试中均展现出优越性能，参数规模更小但未牺牲通用和数学任务的能力，在长视觉上下文和复杂推理任务中表现尤为突出。

Conclusion: MACT框架在文档理解和视觉问答任务中表现出色，尤其在长视觉上下文和复杂推理方面，同时参数规模更小，并且在15项基准测试中的13项中取得领先。其三种变体占据了平均得分的前三名。

Abstract: Existing vision-language models (VLMs), whether generalists or specialists,
remain constrained by their parameter scale, lack robust self-correction
capabilities, and underperform in tasks involving long visual contexts and
complex reasoning, resulting in suboptimal performance on document-based tasks.
To address this, we propose MACT, a Multi-Agent Collaboration framework with
Test-Time scaling, tailored for visual document understanding and visual
question answering (VQA). It comprises four distinct small-scale agents, i.e.,
planning, execution, judgment, and answer agents, with clearly defined roles
and effective collaboration. Notably, the judgment agent exclusively verifies
correctness and redirects to prior agents for revisions, outperforming
conventional correction strategies. To further expand the capability boundaries
of the framework, we propose mixed reward modeling that balances agent-specific
abilities and global collaboration, as well as agent-wise hybrid test-time
scaling, which customizes different scaling strategies for each agent based on
their functions. Evaluated on benchmarks spanning both document-based and
non-document-based settings, our MACT shows superior performance with a smaller
parameter scale without sacrificing the ability of general and mathematical
tasks. Especially, it stands out in benchmarks involving long visual contexts
and complicated reasoning. The three variants of MACT consistently hold the top
three positions in average scores, leading in 13 of the 15 benchmarks. Code
will be available at: https://github.com/YU-deep/MACT.git.

</details>


### [95] [SlotMatch: Distilling Temporally Consistent Object-Centric Representations for Unsupervised Video Segmentation](https://arxiv.org/abs/2508.03411)
*Diana-Nicoleta Grigore,Neelu Madan,Andreas Mogelmose,Thomas B. Moeslund,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 提出 SlotMatch 知识蒸馏框架，用更少参数和更快速度在无监督视频分割任务上达到甚至超越现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 为了克服无监督视频分割中由于缺乏监督信号和视觉场景复杂性带来的挑战，并解决现有基于槽注意力（slot attention）的模型需要庞大且计算成本高昂的神经网络架构的问题。

Method: 提出了一种简单的知识蒸馏框架 SlotMatch，通过余弦相似度对齐教师和学生模型中的槽（slot），无需额外的蒸馏目标或辅助监督。

Result: 在两个数据集上的实验表明，基于 SlotMatch 的学生模型在性能上匹配甚至超越了其教师模型（SlotContrast），同时参数量减少了 3.6 倍，运行速度提高了 1.9 倍。

Conclusion: 所提出的 SlotMatch 框架能够有效地将对象中心表示转移到一个轻量级的学生模型中，并且学生模型在保持甚至超越教师模型性能的同时，参数量减少了 3.6 倍，运行速度提高了 1.9 倍。此外，该学生模型也优于之前其他无监督视频分割模型。

Abstract: Unsupervised video segmentation is a challenging computer vision task,
especially due to the lack of supervisory signals coupled with the complexity
of visual scenes. To overcome this challenge, state-of-the-art models based on
slot attention often have to rely on large and computationally expensive neural
architectures. To this end, we propose a simple knowledge distillation
framework that effectively transfers object-centric representations to a
lightweight student. The proposed framework, called SlotMatch, aligns
corresponding teacher and student slots via the cosine similarity, requiring no
additional distillation objectives or auxiliary supervision. The simplicity of
SlotMatch is confirmed via theoretical and empirical evidence, both indicating
that integrating additional losses is redundant. We conduct experiments on two
datasets to compare the state-of-the-art teacher model, SlotContrast, with our
distilled student. The results show that our student based on SlotMatch matches
and even outperforms its teacher, while using 3.6x less parameters and running
1.9x faster. Moreover, our student surpasses previous unsupervised video
segmentation models.

</details>


### [96] [R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation](https://arxiv.org/abs/2508.03426)
*Futian Wang,Yuhan Qiao,Xiao Wang,Fuling Wang,Yuxiang Zhang,Dengdi Sun*

Main category: cs.CV

TL;DR: 提出了一种结合多模态医学知识图谱（M3KG）和Transformer的方法来改进X射线医学报告的生成质量，解决了幻觉和诊断能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决X射线医学报告生成中存在的幻觉和疾病诊断能力不足的挑战。

Method: 首先，基于GPT-4o利用地面真实医学报告构建了一个大规模多模态医学知识图谱（M3KG），包含2477个实体、3种关系、37424个三元组和6943个CheXpert Plus数据集的疾病感知视觉令牌。然后，通过采样获得多粒度语义图，并使用R-GCN编码器进行特征提取。对于输入的X射线图像，采用Swin-Transformer提取视觉特征，并通过交叉注意力与知识进行交互。将视觉令牌输入Q-former，并通过另一种交叉注意力检索疾病感知视觉令牌。最后，利用大型语言模型将语义知识图谱、输入的X射线图像和疾病感知视觉令牌映射为语言描述。

Result: 所提出的知识图谱和X射线报告生成框架在多个数据集上的广泛实验充分验证了其有效性。

Conclusion: 实验结果验证了所提出的知识图谱和X射线报告生成框架的有效性。

Abstract: X-ray medical report generation is one of the important applications of
artificial intelligence in healthcare. With the support of large foundation
models, the quality of medical report generation has significantly improved.
However, challenges such as hallucination and weak disease diagnostic
capability still persist. In this paper, we first construct a large-scale
multi-modal medical knowledge graph (termed M3KG) based on the ground truth
medical report using the GPT-4o. It contains 2477 entities, 3 kinds of
relations, 37424 triples, and 6943 disease-aware vision tokens for the CheXpert
Plus dataset. Then, we sample it to obtain multi-granularity semantic graphs
and use an R-GCN encoder for feature extraction. For the input X-ray image, we
adopt the Swin-Transformer to extract the vision features and interact with the
knowledge using cross-attention. The vision tokens are fed into a Q-former and
retrieved the disease-aware vision tokens using another cross-attention.
Finally, we adopt the large language model to map the semantic knowledge graph,
input X-ray image, and disease-aware vision tokens into language descriptions.
Extensive experiments on multiple datasets fully validated the effectiveness of
our proposed knowledge graph and X-ray report generation framework. The source
code of this paper will be released on
https://github.com/Event-AHU/Medical_Image_Analysis.

</details>


### [97] [Spatial Imputation Drives Cross-Domain Alignment for EEG Classification](https://arxiv.org/abs/2508.03437)
*Hongjun Liu,Chao Yao,Yalan Zhang,Xiaokun wang,Xiaojuan Ban*

Main category: cs.CV

TL;DR: IMAC通过一种新的自监督框架解决了跨域EEG信号分类的挑战，该框架将数据移位对齐视为空间时间序列插值任务。它标准化电极配置，并通过掩码和重建实现时空信号对齐。IMAC在多个数据集上表现出色，准确率高且鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: EEG信号分类在跨域场景中面临严峻挑战，主要是由于异构的电极配置、采集协议和硬件差异引起的 istribution shifts。

Method: IMAC是一种新颖的、依赖于通道的掩码和插值自监督框架，它将跨域EEG数据移位对齐制定为空间时间序列插值任务。为了解决跨域场景中异构的电极配置，IMAC首先使用3D到2D的位置统一映射策略标准化不同的电极布局，建立统一的空间表示。IMAC引入了时空信号对齐，构建了一个依赖于通道的掩码和重建任务，并将其构建为一个低到高分辨率的EEG空间插值问题。此外，IMAC包含一个解耦结构，分别对EEG信号的时空信息进行建模。

Result: IMAC在10个公开的EEG数据集上进行了全面评估，在交叉主体和交叉中心验证场景中均取得了最先进的分类准确性。IMAC在完整性得分方面超越基线方法高达35%，同时保持了分类准确性。

Conclusion: IMAC在交叉主体和交叉中心验证场景中均取得了最先进的分类准确性，并且在模拟和现实世界的分布变化下都表现出强大的鲁棒性，在完整性得分方面超越基线方法高达35%，同时保持了一致的分类准确性。

Abstract: Electroencephalogram (EEG) signal classification faces significant challenges
due to data distribution shifts caused by heterogeneous electrode
configurations, acquisition protocols, and hardware discrepancies across
domains. This paper introduces IMAC, a novel channel-dependent mask and
imputation self-supervised framework that formulates the alignment of
cross-domain EEG data shifts as a spatial time series imputation task. To
address heterogeneous electrode configurations in cross-domain scenarios, IMAC
first standardizes different electrode layouts using a 3D-to-2D positional
unification mapping strategy, establishing unified spatial representations.
Unlike previous mask-based self-supervised representation learning methods,
IMAC introduces spatio-temporal signal alignment. This involves constructing a
channel-dependent mask and reconstruction task framed as a low-to-high
resolution EEG spatial imputation problem. Consequently, this approach
simulates cross-domain variations such as channel omissions and temporal
instabilities, thus enabling the model to leverage the proposed imputer for
robust signal alignment during inference. Furthermore, IMAC incorporates a
disentangled structure that separately models the temporal and spatial
information of the EEG signals separately, reducing computational complexity
while enhancing flexibility and adaptability. Comprehensive evaluations across
10 publicly available EEG datasets demonstrate IMAC's superior performance,
achieving state-of-the-art classification accuracy in both cross-subject and
cross-center validation scenarios. Notably, IMAC shows strong robustness under
both simulated and real-world distribution shifts, surpassing baseline methods
by up to $35$\% in integrity scores while maintaining consistent classification
accuracy.

</details>


### [98] [MedCAL-Bench: A Comprehensive Benchmark on Cold-Start Active Learning with Foundation Models for Medical Image Analysis](https://arxiv.org/abs/2508.03441)
*Ning Zhu,Xiaochuan Ma,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: MedCAL-Bench是第一个用于医学图像分析的CSAL基准，评估了14个FM和7个CSAL策略。DINO系列在分割任务中表现最佳，ALPS和RepDiv分别在分割和分类任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: CSAL在医学图像分析中至关重要，可以提高标注效率和模型性能。现有的CSAL方法依赖于目标数据集的SSL进行特征提取，这效率低下且受限于不足的特征表示。FM的强大特征提取能力为CSAL提供了潜力，但该领域缺乏比较FM的基准。

Method: 提出MedCAL-Bench，这是第一个用于医学图像分析的系统性FM驱动的CSAL基准。在7个数据集上，针对不同的标注预算，对14个FM和7个CSAL策略进行了评估，涵盖了分类和分割任务，以及多种医学模态。该基准还评估了特征提取和样本选择阶段。

Result: 1) 大多数FM是有效的CSAL特征提取器，其中DINO系列在分割任务中表现最佳。2) FM在分割任务中的性能差异很大，而在分类任务中则较小。3) 在CSAL中应考虑不同的样本选择策略，其中ALPS在分割任务中表现最佳，而RepDiv在分类任务中表现最佳。

Conclusion: MedCAL-Bench 被提议为第一个用于医学图像分析的基于FM的CSAL基准。实验结果表明，大多数FM是有效的特征提取器，其中DINO系列在分割任务中表现最佳；FM在分割任务中的性能差异很大，而在分类任务中则较小；以及在CSAL中应考虑不同的样本选择策略，其中ALPS在分割任务中表现最佳，而RepDiv在分类任务中表现最佳。代码已在https://github.com/HiLab-git/MedCAL-Bench提供。

Abstract: Cold-Start Active Learning (CSAL) aims to select informative samples for
annotation without prior knowledge, which is important for improving annotation
efficiency and model performance under a limited annotation budget in medical
image analysis. Most existing CSAL methods rely on Self-Supervised Learning
(SSL) on the target dataset for feature extraction, which is inefficient and
limited by insufficient feature representation. Recently, pre-trained
Foundation Models (FMs) have shown powerful feature extraction ability with a
potential for better CSAL. However, this paradigm has been rarely investigated,
with a lack of benchmarks for comparison of FMs in CSAL tasks. To this end, we
propose MedCAL-Bench, the first systematic FM-based CSAL benchmark for medical
image analysis. We evaluate 14 FMs and 7 CSAL strategies across 7 datasets
under different annotation budgets, covering classification and segmentation
tasks from diverse medical modalities. It is also the first CSAL benchmark that
evaluates both the feature extraction and sample selection stages. Our
experimental results reveal that: 1) Most FMs are effective feature extractors
for CSAL, with DINO family performing the best in segmentation; 2) The
performance differences of these FMs are large in segmentation tasks, while
small for classification; 3) Different sample selection strategies should be
considered in CSAL on different datasets, with Active Learning by Processing
Surprisal (ALPS) performing the best in segmentation while RepDiv leading for
classification. The code is available at
https://github.com/HiLab-git/MedCAL-Bench.

</details>


### [99] [RAAG: Ratio Aware Adaptive Guidance](https://arxiv.org/abs/2508.03442)
*Shangwen Zhu,Qianyu Peng,Yuting Hu,Zhantao Yang,Han Zhang,Zhao Pu,Ruili Feng,Fan Cheng*

Main category: cs.CV

TL;DR: 本研究发现流模型快速采样时，早期步骤对指导尺度非常敏感，可能导致误差累积。为此，我们提出了一种自适应指导策略，通过在早期降低指导尺度来解决此问题，实现了更快的采样速度和更高的生成质量。


<details>
  <summary>Details</summary>
Motivation: 尽管流模型在图像和视频合成方面取得了显著进展，但对于指导（guidance）如何在采样过程中，尤其是在现代流模型常见的快速、低步数采样条件下与模型交互的机制，仍知之甚少。本研究旨在深入理解指导与采样过程的相互作用，特别是其在快速采样机制下的不稳定性，并提出相应的解决方案。

Method: 本研究通过理论分析和实证验证，揭示了在流模型快速采样过程中，早期反向步由于条件预测与无条件预测的相对强度（RATIO）激增而对指导尺度表现出高度敏感性。为解决此问题，我们提出了一种基于RATIO感知的自适应指导策略，该策略利用闭式指数衰减函数，根据RATIO的动态变化自动调整早期采样步骤的指导尺度。

Result: 我们的方法在SD3.5、Lumina等图像模型和WAN2.1等视频模型上的实验表明，采用RATIO感知的自适应指导策略，可以在保持甚至提高生成质量、鲁棒性和语义对齐能力的前提下，将采样速度提升高达3倍。广泛的消融研究进一步证实了该策略在不同模型、数据集和超参数下的通用性和稳定性。

Conclusion: 为解决采样早期阶段的指导尺度敏感性问题，我们提出了一种新颖的、基于RATIO感知的自适应指导方法。该方法通过在采样早期降低指导尺度，有效抑制了由条件预测和无条件预测相对强度（RATIO）激增引起的指数级误差放大。我们的方法轻量级，无需额外推理开销，并兼容现有的流模型。实验证明，该方法在保持或提升生成质量、鲁棒性和语义对齐的同时，可实现高达3倍的采样加速，展现了其在解锁快速流模型潜能方面的关键作用。

Abstract: Flow-based generative models have recently achieved remarkable progress in
image and video synthesis, with classifier-free guidance (CFG) becoming the
standard tool for high-fidelity, controllable generation. However, despite
their practical success, little is known about how guidance interacts with
different stages of the sampling process-especially in the fast, low-step
regimes typical of modern flow-based pipelines. In this work, we uncover and
analyze a fundamental instability: the earliest reverse steps are acutely
sensitive to the guidance scale, owing to a pronounced spike in the relative
strength (RATIO) of conditional to unconditional predictions. Through rigorous
theoretical analysis and empirical validation, we show that this RATIO spike is
intrinsic to the data distribution, independent of the model architecture, and
causes exponential error amplification when paired with strong guidance. To
address this, we propose a simple, theoretically grounded, RATIO-aware adaptive
guidance schedule that automatically dampens the guidance scale at early steps
based on the evolving RATIO, using a closed-form exponential decay. Our method
is lightweight, requires no additional inference overhead, and is compatible
with standard flow frameworks. Experiments across state-of-the-art image
(SD3.5, Lumina) and video (WAN2.1) models demonstrate that our approach enables
up to 3x faster sampling while maintaining or improving generation quality,
robustness, and semantic alignment. Extensive ablation studies further confirm
the generality and stability of our schedule across models, datasets, and
hyperparameters. Our findings highlight the critical role of stepwise guidance
adaptation in unlocking the full potential of fast flow-based generative
models.

</details>


### [100] [CoPS: Conditional Prompt Synthesis for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2508.03447)
*Qiyu Chen,Zhen Qu,Wei Luo,Haiming Yao,Yunkang Cao,Yuxin Jiang,Yinan Duan,Huiyuan Luo,Chengkan Lv,Zhengtao Zhang*

Main category: cs.CV

TL;DR: CoPS通过生成视条件提示来改进零样本异常检测，提升了跨类别异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型预训练视觉-语言模型在零样本异常检测（ZSAD）方面表现出色，但仍面临挑战：1. 静态可学习令牌难以捕捉连续多样的正常和异常状态模式，泛化能力受限；2. 固定文本标签提供的类别信息过于稀疏，易导致模型过拟合到特定的语义子空间。

Method: 提出了一种名为条件提示合成（CoPS）的新框架，通过提取细粒度图像块特征来生成代表正常和异常的原型，并将其融入提示中，以实现自适应状态建模。同时，利用变分自编码器（VAE）对语义图像特征进行建模，并将不同类别的令牌隐式融合到提示中，以解决类别标签稀疏的问题。此外，还集成了一个空间感知对齐机制。

Result: CoPS框架在13个工业和医学数据集的分类和分割任务上，AUROC平均提升了2.5%，超越了现有最先进方法。

Conclusion: CoPS框架通过生成视条件提示来提升零样本异常检测（ZSAD）的性能，在工业缺陷和医学病变等13个数据集上，AUROC平均提升2.5%，超越了现有最先进方法。

Abstract: Recently, large pre-trained vision-language models have shown remarkable
performance in zero-shot anomaly detection (ZSAD). With fine-tuning on a single
auxiliary dataset, the model enables cross-category anomaly detection on
diverse datasets covering industrial defects and medical lesions. Compared to
manually designed prompts, prompt learning eliminates the need for expert
knowledge and trial-and-error. However, it still faces the following
challenges: (i) static learnable tokens struggle to capture the continuous and
diverse patterns of normal and anomalous states, limiting generalization to
unseen categories; (ii) fixed textual labels provide overly sparse category
information, making the model prone to overfitting to a specific semantic
subspace. To address these issues, we propose Conditional Prompt Synthesis
(CoPS), a novel framework that synthesizes dynamic prompts conditioned on
visual features to enhance ZSAD performance. Specifically, we extract
representative normal and anomaly prototypes from fine-grained patch features
and explicitly inject them into prompts, enabling adaptive state modeling.
Given the sparsity of class labels, we leverage a variational autoencoder to
model semantic image features and implicitly fuse varied class tokens into
prompts. Additionally, integrated with our spatially-aware alignment mechanism,
extensive experiments demonstrate that CoPS surpasses state-of-the-art methods
by 2.5% AUROC in both classification and segmentation across 13 industrial and
medical datasets. Code will be available at https://github.com/cqylunlun/CoPS.

</details>


### [101] [Video Demoireing using Focused-Defocused Dual-Camera System](https://arxiv.org/abs/2508.03449)
*Xuan Dong,Xiangyuan Sun,Xia Wang,Jian Song,Ya Li,Weixin Li*

Main category: cs.CV

TL;DR: 使用一个聚焦和一个失焦摄像头同步拍摄视频，利用失焦视频区分和去除聚焦视频中的摩尔纹，同时保持色调和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的去摩尔纹方法在区分摩尔纹和真实纹理以及在消除摩尔纹的同时保持色调和时间一致性方面面临挑战。

Method: 提出了一种双摄像头框架，包括光学流配准和使用多尺度卷积神经网络（CNN）的去摩尔纹处理。利用失焦视频指导聚焦视频的去摩尔纹处理，并通过联合双边滤波保持色调和时间一致性。

Result: 实验结果表明，所提出的框架在很大程度上优于最先进的图像和视频去摩尔纹方法。

Conclusion: 该双摄像头框架在消除摩尔纹方面显著优于最先进的单摄像头方法。

Abstract: Moire patterns, unwanted color artifacts in images and videos, arise from the
interference between spatially high-frequency scene contents and the spatial
discrete sampling of digital cameras. Existing demoireing methods primarily
rely on single-camera image/video processing, which faces two critical
challenges: 1) distinguishing moire patterns from visually similar real
textures, and 2) preserving tonal consistency and temporal coherence while
removing moire artifacts. To address these issues, we propose a dual-camera
framework that captures synchronized videos of the same scene: one in focus
(retaining high-quality textures but may exhibit moire patterns) and one
defocused (with significantly reduced moire patterns but blurred textures). We
use the defocused video to help distinguish moire patterns from real texture,
so as to guide the demoireing of the focused video. We propose a frame-wise
demoireing pipeline, which begins with an optical flow based alignment step to
address any discrepancies in displacement and occlusion between the focused and
defocused frames. Then, we leverage the aligned defocused frame to guide the
demoireing of the focused frame using a multi-scale CNN and a multi-dimensional
training loss. To maintain tonal and temporal consistency, our final step
involves a joint bilateral filter to leverage the demoireing result from the
CNN as the guide to filter the input focused frame to obtain the final output.
Experimental results demonstrate that our proposed framework largely
outperforms state-of-the-art image and video demoireing methods.

</details>


### [102] [AVPDN: Learning Motion-Robust and Scale-Adaptive Representations for Video-Based Polyp Detection](https://arxiv.org/abs/2508.03458)
*Zilin Chen,Shengnan Lu*

Main category: cs.CV

TL;DR: 提出AVPDN框架，通过AFIA和SACI模块有效解决结肠镜视频检测中的噪声和多尺度问题，并在公共基准测试中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 结肠镜视频中快速的相机移动会引入大量背景噪声，破坏场景的结构完整性并增加假阳性的风险。为了解决这些挑战，需要一种能够有效处理这些问题的模型。

Method: 提出了一种名为AVPDN（Adaptive Video Polyp Detection Network）的鲁棒框架，用于结肠镜视频中的多尺度息肉检测。AVPDN包含两个关键组件：自适应特征交互和增强（AFIA）模块和尺度感知上下文集成（SACI）模块。AFIA模块采用三分支结构增强特征表示，利用密集自注意力进行全局上下文建模，稀疏自注意力减轻低查询-键相似性对特征聚合的影响，并通过通道混洗操作促进跨分支信息交换。SACI模块旨在加强多尺度特征集成，利用具有不同感受野的膨胀卷积捕获多尺度的上下文信息，从而提高模型的去噪能力。

Result: 实验证明了该方法的有效性和泛化能力，在视频息肉检测任务中取得了有竞争力的性能。

Conclusion: AVPDN在多个具有挑战性的公共基准测试中表现出有效性和泛化能力，在基于视频的息肉检测任务中取得了有竞争力的性能。

Abstract: Accurate detection of polyps is of critical importance for the early and
intermediate stages of colorectal cancer diagnosis. Compared to static images,
dynamic colonoscopy videos provide more comprehensive visual information, which
can facilitate the development of effective treatment plans. However, unlike
fixed-camera recordings, colonoscopy videos often exhibit rapid camera
movement, introducing substantial background noise that disrupts the structural
integrity of the scene and increases the risk of false positives. To address
these challenges, we propose the Adaptive Video Polyp Detection Network
(AVPDN), a robust framework for multi-scale polyp detection in colonoscopy
videos. AVPDN incorporates two key components: the Adaptive Feature Interaction
and Augmentation (AFIA) module and the Scale-Aware Context Integration (SACI)
module. The AFIA module adopts a triple-branch architecture to enhance feature
representation. It employs dense self-attention for global context modeling,
sparse self-attention to mitigate the influence of low query-key similarity in
feature aggregation, and channel shuffle operations to facilitate inter-branch
information exchange. In parallel, the SACI module is designed to strengthen
multi-scale feature integration. It utilizes dilated convolutions with varying
receptive fields to capture contextual information at multiple spatial scales,
thereby improving the model's denoising capability. Experiments conducted on
several challenging public benchmarks demonstrate the effectiveness and
generalization ability of the proposed method, achieving competitive
performance in video-based polyp detection tasks.

</details>


### [103] [IKOD: Mitigating Visual Attention Degradation in Large Vision-Language Models](https://arxiv.org/abs/2508.03469)
*Jiabing Yang,Chenhang Cui,Yiyang Zhou,Yixiang Chen,Peng Xia,Ying Wei,Tao Yu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: IKOD通过合并关键值来引导图像注意力，以减少幻觉并提高LVLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 解决了大型视觉语言模型（LVLMs）在融合视觉和语言信息进行推理时出现的“幻觉”问题，特别是LVLMs中存在的长序列偏见（随着序列长度增加幻觉增多）且原因不明的问题。现有方法存在计算成本高或数据标注成本高等局限性。

Method: 提出了一种名为IKOD（Image attention-guided Key-value merging cOllaborative Decoding）的协同解码策略。该策略通过合并具有更高图像注意力的短序列的logits与原始解码序列的logits，来缓解注意力衰减问题，从而抑制幻觉。

Result: 在幻觉和综合基准测试方面进行了广泛的实验，证明了IKOD在减轻幻觉和提升LVLMs综合能力方面的优越性。

Conclusion: IKOD通过引导图像注意力来优化解码过程，有效减轻了LVLMs中的幻觉现象，并提升了模型的综合能力。该方法无需额外训练或外部工具，是一种轻量级且高效的框架，可应用于多种模型。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
significant progress across multiple domains. However, these models still face
the inherent challenge of integrating vision and language for collaborative
inference, which often leads to "hallucinations", outputs that are not grounded
in the corresponding images. Many efforts have been made to address these
issues, but each comes with its own limitations, such as high computational
cost or expensive dataset annotation. Recent research shows that LVLMs exhibit
a long-term bias where hallucinations increase as the sequence length grows,
yet the underlying cause remains poorly understood. Building on extensive
research into attention mechanisms in LVLMs, we analyze the relationship
between this long-term bias and visual attention. In our research, we identify
a consistent phenomenon in current LVLMs: the model's attention to visual input
diminishes as the generated sequence grows, which we hypothesize to be a key
factor contributing to observed increasing hallucinations. Based on these
insights, we propose Image attention-guided Key-value merging cOllaborative
Decoding (IKOD), a collaborative decoding strategy generating more
image-focused sequences. This method derives logits from shorter sequences with
higher image attention through key-value merging and combines them with those
from the original decoding, effectively mitigating attention degradation and
suppressing hallucinations while not incurring too much inference cost.
Extensive experiments on both hallucination and comprehensive benchmarks
demonstrate IKOD's superior effectiveness in mitigating hallucinations and
improving comprehensive capacities for LVLMs. Importantly, IKOD requires no
additional training or external tools, making it a lightweight and efficient
framework applicable to various models.

</details>


### [104] [VideoGuard: Protecting Video Content from Unauthorized Editing](https://arxiv.org/abs/2508.03480)
*Junjie Cao,Kaizhou Li,Xinchun Yu,Hongxiang Li,Xiaoping Zhang*

Main category: cs.CV

TL;DR: 提出VideoGuard，一种通过联合帧优化和运动信息融合来保护视频免受恶意编辑的方法，并证明其优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前生成技术发展迅速，可能被恶意用于误导活动，现有研究在视频内容保护方面存在不足，需要一种有效的方法来保护视频免受未经授权的恶意编辑。

Method: 提出了一种名为VideoGuard的保护方法，通过联合优化所有视频帧并融合视频运动信息，引入了不易察觉的扰动，干扰生成扩散模型的功能，使得模型生成的视频不合理且不一致。

Result: 通过客观和主观指标的评估，证明了VideoGuard的有效性，其保护性能优于所有基线方法。

Conclusion: VideoGuard通过引入难以察觉的扰动来有效防止视频被恶意编辑，其保护性能优于现有基线方法。

Abstract: With the rapid development of generative technology, current generative
models can generate high-fidelity digital content and edit it in a controlled
manner. However, there is a risk that malicious individuals might misuse these
capabilities for misleading activities. Although existing research has
attempted to shield photographic images from being manipulated by generative
models, there remains a significant disparity in the protection offered to
video content editing. To bridge the gap, we propose a protection method named
VideoGuard, which can effectively protect videos from unauthorized malicious
editing. This protection is achieved through the subtle introduction of nearly
unnoticeable perturbations that interfere with the functioning of the intended
generative diffusion models. Due to the redundancy between video frames, and
inter-frame attention mechanism in video diffusion models, simply applying
image-based protection methods separately to every video frame can not shield
video from unauthorized editing. To tackle the above challenge, we adopt joint
frame optimization, treating all video frames as an optimization entity.
Furthermore, we extract video motion information and fuse it into optimization
objectives. Thus, these alterations can effectively force the models to produce
outputs that are implausible and inconsistent. We provide a pipeline to
optimize this perturbation. Finally, we use both objective metrics and
subjective metrics to demonstrate the efficacy of our method, and the results
show that the protection performance of VideoGuard is superior to all the
baseline methods.

</details>


### [105] [When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models](https://arxiv.org/abs/2508.03483)
*Dasol Choi Jihwan Lee,Minjae Lee,Minsuk Kahng*

Main category: cs.CV

TL;DR: 一项新的研究通过SODA框架发现，AI图像生成模型在物体生成时存在人口统计偏见，例如特定性别或种族提示会与特定颜色模式相关联，并且模型多样性不足会加剧这些偏见。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注生成图像中人物的偏见，而忽略了物体生成中更隐蔽但普遍存在的人口统计偏见现象。本研究旨在填补这一空白，探讨并量化模型在物体生成方面的人口统计偏见。

Method: 提出了一种名为SODA（Stereotyped Object Diagnostic Audit）的新颖框架，用于系统性地测量文本到图像生成模型在物体生成方面的人口统计偏见。该方法通过比较带有和不带有语气词（例如“为年轻人”）的提示所生成的物体视觉属性，分析了三个最先进模型（GPT Image-1、Imagen 4和Stable Diffusion）在五个物体类别上生成的2700张图像。

Result: 研究发现，在物体生成时，特定的 SwitchCompat群体与视觉属性之间存在强烈的关联，例如特定性别或种族提示会引发重复的颜色模式。部分模型生成的输出多样性较低，导致与中性提示相比，视觉差异更加明显。这些模式不仅反映了已知的刻板印象，还揭示了一些更微妙和难以理解的偏见。

Conclusion: 该研究揭示了文本到图像生成模型中存在的微妙且普遍的人口统计偏见，特别是在物体生成方面。SODA框架的提出为量化这些偏见提供了一种系统性的方法，并发现模型在生成物体时会与特定人口群体产生关联，例如颜色模式等，这些偏见可能反映并强化了已有的刻板印象。此外，研究还指出部分模型生成的多样性不足会加剧这种视觉差异。该研究强调了审计框架在识别和解决生成模型中刻板印象问题上的重要性，是走向更系统和负责任的AI发展的关键一步。

Abstract: While prior research on text-to-image generation has predominantly focused on
biases in human depictions, we investigate a more subtle yet pervasive
phenomenon: demographic bias in generated objects (e.g., cars). We introduce
SODA (Stereotyped Object Diagnostic Audit), a novel framework for
systematically measuring such biases. Our approach compares visual attributes
of objects generated with demographic cues (e.g., "for young people'') to those
from neutral prompts, across 2,700 images produced by three state-of-the-art
models (GPT Image-1, Imagen 4, and Stable Diffusion) in five object categories.
Through a comprehensive analysis, we uncover strong associations between
specific demographic groups and visual attributes, such as recurring color
patterns prompted by gender or ethnicity cues. These patterns reflect and
reinforce not only well-known stereotypes but also more subtle and unintuitive
biases. We also observe that some models generate less diverse outputs, which
in turn amplifies the visual disparities compared to neutral prompts. Our
proposed auditing framework offers a practical approach for testing, revealing
how stereotypes still remain embedded in today's generative models. We see this
as an essential step toward more systematic and responsible AI development.

</details>


### [106] [LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Text-to-Image Generation](https://arxiv.org/abs/2508.03485)
*Lianwei Yang,Haokun Lin,Tianchen Zhao,Yichen Wu,Hongyu Zhu,Ruiqi Xie,Zhenan Sun,Yu Wang,Qingyi Gu*

Main category: cs.CV

TL;DR: DiT 模型在文生图方面表现优异，但计算成本高。LRQ-DiT 通过 TLQ 和 ARS 技术解决了低比特量化时的性能下降问题，实现了高效且准确的压缩。


<details>
  <summary>Details</summary>
Motivation: 现有的 PTQ 方法在极低比特设置下存在严重的性能下降问题，主要由于 DiT 模型权重分布（具有长尾的类高斯分布）和两种激活异常值（温和异常值和显著异常值）的挑战。

Method: 提出了一种名为 LRQ-DiT 的高效准确的 PTQ 框架。该框架引入了 Twin-Log 量化 (TLQ) 来解决权重分布问题，并通过自适应旋转方案 (ARS) 来处理激活异常值。TLQ 是一种基于 log 的方法，能够更好地适应权重分布并减少量化误差。ARS 则根据激活值的波动动态地应用 Hadamard 旋转或考虑异常值的旋转，从而有效减轻两种异常值的影响。

Result: 在 PixArt 和 FLUX 模型上，在各种比特宽度下，LRQ-DiT 在 COCO、MJHQ 和 sDCI 数据集上进行了验证。结果表明，LRQ-DiT 在保持图像质量的同时实现了 DiT 模型的低比特量化，并且优于现有的 PTQ 基线。

Conclusion: LRQ-DiT 是一种高效准确的 PTQ 框架，通过 TLQ 和 ARS 克服了 DiT 模型低比特量化的挑战，在保持图像质量的同时实现了 DiT 模型的低比特量化，并且优于现有的 PTQ 基线。

Abstract: Diffusion Transformers (DiTs) have achieved impressive performance in
text-to-image generation. However, their high computational cost and large
parameter sizes pose significant challenges for usage in resource-constrained
scenarios. Post-training quantization (PTQ) is a promising solution to reduce
memory usage and accelerate inference, but existing PTQ methods suffer from
severe performance degradation under extreme low-bit settings. We identify two
key obstacles to low-bit post-training quantization for DiT models: (1) model
weights follow a Gaussian-like distribution with long tails, causing uniform
quantization to poorly allocate intervals and leading to significant errors;
(2) two types of activation outliers: (i) Mild Outliers with slightly elevated
values, and (ii) Salient Outliers with large magnitudes concentrated in
specific channels, which disrupt activation quantization. To address these
issues, we propose LRQ-DiT, an efficient and accurate PTQ framework. We
introduce Twin-Log Quantization (TLQ), a log-based method that aligns well with
the weight distribution and reduces quantization errors. We also propose an
Adaptive Rotation Scheme (ARS) that dynamically applies Hadamard or
outlier-aware rotations based on activation fluctuation, effectively mitigating
the impact of both types of outliers. We evaluate LRQ-DiT on PixArt and FLUX
under various bit-width settings, and validate the performance on COCO, MJHQ,
and sDCI datasets. LRQ-DiT achieves low-bit quantization of DiT models while
preserving image quality, outperforming existing PTQ baselines.

</details>


### [107] [ParticleSAM: Small Particle Segmentation for Material Quality Monitoring in Recycling Processes](https://arxiv.org/abs/2508.03490)
*Yu Zhou,Pelle Thielmann,Ayush Chamoli,Bruno Mirbach,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: 提出ParticleSAM模型，用于分割建筑材料图像中的细小颗粒，并构建新数据集进行验证，旨在自动化质量控制。


<details>
  <summary>Details</summary>
Motivation: 为了解决建筑行业中回收骨料质量监测依赖手动方法效率低下的问题，并克服现有计算机视觉分割方法在处理大量细小颗粒图像时的局限性。

Method: 提出了一种名为ParticleSAM的分割模型，它是对现有分割基础模型（SAM）的改编，专门用于处理建筑材料图像中密集排列的小颗粒。同时，构建了一个新的、包含大量模拟颗粒图像的数据集，并辅以自动化数据生成和标注流程。

Result: 实验结果通过定性和定量对比证明了ParticleSAM相比于原始SAM方法的优越性，验证了其在小颗粒分割任务中的有效性。

Conclusion: ParticleSAM通过在小而密集的物体分割方面进行改进，并在新的数据集上进行了验证，展示了其在建筑材料质量控制自动化和超越建筑领域的小颗粒分割应用中的潜力。

Abstract: The construction industry represents a major sector in terms of resource
consumption. Recycled construction material has high reuse potential, but
quality monitoring of the aggregates is typically still performed with manual
methods. Vision-based machine learning methods could offer a faster and more
efficient solution to this problem, but existing segmentation methods are by
design not directly applicable to images with hundreds of small particles. In
this paper, we propose ParticleSAM, an adaptation of the segmentation
foundation model to images with small and dense objects such as the ones often
encountered in construction material particles. Moreover, we create a new dense
multi-particle dataset simulated from isolated particle images with the
assistance of an automated data generation and labeling pipeline. This dataset
serves as a benchmark for visual material quality control automation while our
segmentation approach has the potential to be valuable in application areas
beyond construction where small-particle segmentation is needed. Our
experimental results validate the advantages of our method by comparing to the
original SAM method both in quantitative and qualitative experiments.

</details>


### [108] [Quality Versus Sparsity in Image Recovery by Dictionary Learning Using Iterative Shrinkage](https://arxiv.org/abs/2508.03492)
*Mohammadsadegh Khoshghiaferezaee,Moritz Krauth,Shima Shabani,Michael Breuß*

Main category: cs.CV

TL;DR: 字典学习中的稀疏性很重要，高稀疏度通常不会影响恢复质量。


<details>
  <summary>Details</summary>
Motivation: 文章旨在探讨稀疏字典学习（SDL）中稀疏性的重要性，以及在不损害恢复质量的前提下应如何选择稀疏度。

Method: 作者探讨了优化方法在稀疏字典学习中的应用，并分析了不同方法产生的稀疏性差异。

Result: 研究发现，不同的优化方法会产生不同的稀疏度，高稀疏度通常不会损害恢复质量，并且恢复的图像与学习数据库的差异可能很大。

Conclusion: 研究表明，在字典学习中强制执行高稀疏度通常不会损害恢复质量，即使恢复的图像与学习数据库有很大不同。

Abstract: Sparse dictionary learning (SDL) is a fundamental technique that is useful
for many image processing tasks. As an example we consider here image recovery,
where SDL can be cast as a nonsmooth optimization problem. For this kind of
problems, iterative shrinkage methods represent a powerful class of algorithms
that are subject of ongoing research. Sparsity is an important property of the
learned solutions, as exactly the sparsity enables efficient further processing
or storage. The sparsity implies that a recovered image is determined as a
combination of a number of dictionary elements that is as low as possible.
Therefore, the question arises, to which degree sparsity should be enforced in
SDL in order to not compromise recovery quality. In this paper we focus on the
sparsity of solutions that can be obtained using a variety of optimization
methods. It turns out that there are different sparsity regimes depending on
the method in use. Furthermore, we illustrate that high sparsity does in
general not compromise recovery quality, even if the recovered image is quite
different from the learning database.

</details>


### [109] [Prototype-Enhanced Confidence Modeling for Cross-Modal Medical Image-Report Retrieval](https://arxiv.org/abs/2508.03494)
*Shreyank N Gowda,Xiaobo Jin,Christian Wagner*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In cross-modal retrieval tasks, such as image-to-report and report-to-image
retrieval, accurately aligning medical images with relevant text reports is
essential but challenging due to the inherent ambiguity and variability in
medical data. Existing models often struggle to capture the nuanced,
multi-level semantic relationships in radiology data, leading to unreliable
retrieval results. To address these issues, we propose the Prototype-Enhanced
Confidence Modeling (PECM) framework, which introduces multi-level prototypes
for each modality to better capture semantic variability and enhance retrieval
robustness. PECM employs a dual-stream confidence estimation that leverages
prototype similarity distributions and an adaptive weighting mechanism to
control the impact of high-uncertainty data on retrieval rankings. Applied to
radiology image-report datasets, our method achieves significant improvements
in retrieval precision and consistency, effectively handling data ambiguity and
advancing reliability in complex clinical scenarios. We report results on
multiple different datasets and tasks including fully supervised and zero-shot
retrieval obtaining performance gains of up to 10.17%, establishing in new
state-of-the-art.

</details>


### [110] [EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation](https://arxiv.org/abs/2508.03497)
*Deqiang Yin,Junyi Guo,Huanda Lu,Fangyu Wu,Dongming Lu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Instruction-based garment editing enables precise image modifications via
natural language, with broad applications in fashion design and customization.
Unlike general editing tasks, it requires understanding garment-specific
semantics and attribute dependencies. However, progress is limited by the
scarcity of high-quality instruction-image pairs, as manual annotation is
costly and hard to scale. While MLLMs have shown promise in automated data
synthesis, their application to garment editing is constrained by imprecise
instruction modeling and a lack of fashion-specific supervisory signals. To
address these challenges, we present an automated pipeline for constructing a
garment editing dataset. We first define six editing instruction categories
aligned with real-world fashion workflows to guide the generation of balanced
and diverse instruction-image triplets. Second, we introduce Fashion Edit
Score, a semantic-aware evaluation metric that captures semantic dependencies
between garment attributes and provides reliable supervision during
construction. Using this pipeline, we construct a total of 52,257 candidate
triplets and retain 20,596 high-quality triplets to build EditGarment, the
first instruction-based dataset tailored to standalone garment editing. The
project page is https://yindq99.github.io/EditGarment-project/.

</details>


### [111] [MAUP: Training-free Multi-center Adaptive Uncertainty-aware Prompting for Cross-domain Few-shot Medical Image Segmentation](https://arxiv.org/abs/2508.03511)
*Yazhou Zhu,Haofeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为MAUP的训练无关CD-FSMIS模型，该模型通过多中心提示生成、不确定性感知提示选择和自适应提示优化，将SAM模型适应于CD-FSMIS任务，无需额外训练即可在医学图像分割任务中取得精确结果。


<details>
  <summary>Details</summary>
Motivation: 当前CD-FSMIS模型依赖于在其他源医学领域进行大量训练，这降低了模型的通用性和易部署性。随着自然图像大视觉模型的发展，我们希望提出一种训练无关的模型。

Method: 提出了一种名为多中心自适应不确定性感知提示（MAUP）的训练无关CD-FSMIS模型，通过引入MAUP策略将SAM（Segment Anything Model）适应于CD-FSMIS任务。MAUP包含三个主要创新：1. 基于K-means聚类的多中心提示生成，实现全面的空间覆盖；2. 不确定性感知提示选择，关注具有挑战性的区域；3. 自适应提示优化，可根据目标区域的复杂性动态调整。

Result: MAUP模型在没有额外训练的情况下，在三个医学数据集上实现了精确的分割结果，并且优于几种传统的CD-FSMIS模型和无训练FSMIS模型。

Conclusion: MAUP模型在没有额外训练的情况下，在三个医学数据集上实现了精确的分割结果，并且优于几种传统的CD-FSMIS模型和无训练FSMIS模型。

Abstract: Cross-domain Few-shot Medical Image Segmentation (CD-FSMIS) is a potential
solution for segmenting medical images with limited annotation using knowledge
from other domains. The significant performance of current CD-FSMIS models
relies on the heavily training procedure over other source medical domains,
which degrades the universality and ease of model deployment. With the
development of large visual models of natural images, we propose a
training-free CD-FSMIS model that introduces the Multi-center Adaptive
Uncertainty-aware Prompting (MAUP) strategy for adapting the foundation model
Segment Anything Model (SAM), which is trained with natural images, into the
CD-FSMIS task. To be specific, MAUP consists of three key innovations: (1)
K-means clustering based multi-center prompts generation for comprehensive
spatial coverage, (2) uncertainty-aware prompts selection that focuses on the
challenging regions, and (3) adaptive prompt optimization that can dynamically
adjust according to the target region complexity. With the pre-trained DINOv2
feature encoder, MAUP achieves precise segmentation results across three
medical datasets without any additional training compared with several
conventional CD-FSMIS models and training-free FSMIS model. The source code is
available at: https://github.com/YazhouZhu19/MAUP.

</details>


### [112] [Distribution-aware Knowledge Unification and Association for Non-exemplar Lifelong Person Re-identification](https://arxiv.org/abs/2508.03516)
*Shiben Liu,Mingyue Xu,Huijie Fan,Qiang Wang,Yandong Tang,Zhi Han*

Main category: cs.CV

TL;DR: 提出DKUA框架，通过域风格建模、自适应知识合并、统一知识关联和基于分布的知识转移，解决了LReID中的知识遗忘和泛化问题，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有终身行人重识别（LReID）方法在平衡旧知识保持与新信息适应方面存在挑战，并且忽略了特定分布感知和跨域统一知识学习这两个关键方面。

Method: 提出了一种新颖的分布感知知识统一与关联（DKUA）框架，包括：1. 设计了一个分布感知模型，将当前域的实例级表示传播到具有不同域风格的域特定表示中，以增强抗遗忘和泛化能力，同时避免存储旧样本。2. 提出自适应知识合并（AKC），动态生成统一表示作为跨域表示中心。3. 开发了一种统一知识关联（UKA）机制，将统一表示作为桥梁，显式地对跨域关联进行建模，以减小域间差距。4. 提出基于分布的知识转移（DKT），以防止当前域分布偏离跨域分布中心，从而提高适应能力。

Result: 实验结果表明，DKUA框架在抗遗忘和泛化能力方面，平均mAP/R@1分别比现有方法提高了7.6%/5.3%。

Conclusion: 该研究提出的DKUA框架在防止遗忘和提高泛化能力方面优于现有方法，平均mAP/R@1分别提高了7.6%/5.3%。

Abstract: Lifelong person re-identification (LReID) encounters a key challenge:
balancing the preservation of old knowledge with adaptation to new information.
Existing LReID methods typically employ knowledge distillation to enforce
representation alignment. However, these approaches ignore two crucial aspects:
specific distribution awareness and cross-domain unified knowledge learning,
both of which are essential for addressing this challenge. To overcome these
limitations, we propose a novel distribution-aware knowledge unification and
association (DKUA) framework where domain-style modeling is performed for each
instance to propagate domain-specific representations, enhancing
anti-forgetting and generalization capacity. Specifically, we design a
distribution-aware model to transfer instance-level representations of the
current domain into the domain-specific representations with the different
domain styles, preserving learned knowledge without storing old samples. Next,
we propose adaptive knowledge consolidation (AKC) to dynamically generate the
unified representation as a cross-domain representation center. To further
mitigate forgetting, we develop a unified knowledge association (UKA)
mechanism, which explores the unified representation as a bridge to explicitly
model inter-domain associations, reducing inter-domain gaps. Finally,
distribution-based knowledge transfer (DKT) is proposed to prevent the current
domain distribution from deviating from the cross-domain distribution center,
improving adaptation capacity. Experimental results show our DKUA outperforms
the existing methods by 7.6%/5.3% average mAP/R@1 improvement on
anti-forgetting and generalization capacity, respectively. Our code will be
publicly released.

</details>


### [113] [Semantic Mosaicing of Histo-Pathology Image Fragments using Visual Foundation Models](https://arxiv.org/abs/2508.03524)
*Stefan Brandstätter,Maximilian Köller,Philipp Seeböck,Alissa Blessing,Felicitas Oberndorfer,Svitlana Pochepnia,Helmut Prosch,Georg Langs*

Main category: cs.CV

TL;DR: A new method called SemanticStitcher uses a foundation model to stitch large tissue samples for histopathology analysis, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Automated stitching of large tissue samples is challenging due to tissue loss, distortion, staining inconsistencies, missing regions, or frayed edges, which limits current boundary shape matching methods.

Method: SemanticStitcher uses latent feature representations from a visual histopathology foundation model to identify neighboring areas in different fragments. Robust pose estimation based on a large number of semantic matching candidates is used to create the WMS.

Result: Experiments on three different histopathology datasets show that SemanticStitcher yields robust WMS mosaicing and consistently outperforms the state of the art in correct boundary matches.

Conclusion: SemanticStitcher can robustly create whole mount slides (WMS) by mosaicing multiple fragments and outperforms the state of the art in correct boundary matches.

Abstract: In histopathology, tissue samples are often larger than a standard microscope
slide, making stitching of multiple fragments necessary to process entire
structures such as tumors. Automated stitching is a prerequisite for scaling
analysis, but is challenging due to possible tissue loss during preparation,
inhomogeneous morphological distortion, staining inconsistencies, missing
regions due to misalignment on the slide, or frayed tissue edges. This limits
state-of-the-art stitching methods using boundary shape matching algorithms to
reconstruct artificial whole mount slides (WMS). Here, we introduce
SemanticStitcher using latent feature representations derived from a visual
histopathology foundation model to identify neighboring areas in different
fragments. Robust pose estimation based on a large number of semantic matching
candidates derives a mosaic of multiple fragments to form the WMS. Experiments
on three different histopathology datasets demonstrate that SemanticStitcher
yields robust WMS mosaicing and consistently outperforms the state of the art
in correct boundary matches.

</details>


### [114] [CoEmoGen: Towards Semantically-Coherent and Scalable Emotional Image Content Generation](https://arxiv.org/abs/2508.03535)
*Kaishen Yuan,Yuting Zhang,Shang Gao,Yijie Zhu,Wenshuo Chen,Yutao Yue*

Main category: cs.CV

TL;DR: 提出CoEmoGen，一种用于情感图像内容生成的新型流程，通过利用MLLMs和HiLoRA模块来提高语义连贯性和情感保真度，并推出了EmoArt数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在生成抽象情感方面存在困难，而专门为EICG设计的方法过度依赖词级属性标签，存在语义不连贯、模糊和可扩展性有限的问题。

Method: 利用多模态大语言模型（MLLMs）构建高质量的、专注于触发情感内容的字幕，以提供丰富的语义指导。设计了一个分层低秩自适应（HiLoRA）模块，以协同建模共享的低级特征和特定情感的高级语义。

Result: 实验证明CoEmoGen在情感保真度和语义连贯性方面优于现有方法，并在定量、定性和用户研究方面得到了验证。此外，还创建了一个名为EmoArt的大规模数据集，用于展示可扩展性。

Conclusion: CoEmoGen在情感保真度和语义连贯性方面优于现有方法，并具有良好的可扩展性。

Abstract: Emotional Image Content Generation (EICG) aims to generate semantically clear
and emotionally faithful images based on given emotion categories, with broad
application prospects. While recent text-to-image diffusion models excel at
generating concrete concepts, they struggle with the complexity of abstract
emotions. There have also emerged methods specifically designed for EICG, but
they excessively rely on word-level attribute labels for guidance, which suffer
from semantic incoherence, ambiguity, and limited scalability. To address these
challenges, we propose CoEmoGen, a novel pipeline notable for its semantic
coherence and high scalability. Specifically, leveraging multimodal large
language models (MLLMs), we construct high-quality captions focused on
emotion-triggering content for context-rich semantic guidance. Furthermore,
inspired by psychological insights, we design a Hierarchical Low-Rank
Adaptation (HiLoRA) module to cohesively model both polarity-shared low-level
features and emotion-specific high-level semantics. Extensive experiments
demonstrate CoEmoGen's superiority in emotional faithfulness and semantic
coherence from quantitative, qualitative, and user study perspectives. To
intuitively showcase scalability, we curate EmoArt, a large-scale dataset of
emotionally evocative artistic images, providing endless inspiration for
emotion-driven artistic creation. The dataset and code are available at
https://github.com/yuankaishen2001/CoEmoGen.

</details>


### [115] [Retinal Lipidomics Associations as Candidate Biomarkers for Cardiovascular Health](https://arxiv.org/abs/2508.03538)
*Inamullah,Imran Razzak,Shoaib Jameel*

Main category: cs.CV

TL;DR: 本研究首次将深度学习（DL）衍生的视网膜特征与健康人群的脂质组学亚类相结合，揭示了脂质与视网膜血管之间的关联，并支持视网膜作为代谢健康的非侵入性标志物。


<details>
  <summary>Details</summary>
Motivation: 脂质组学与视网膜血管之间的关联仍不充分，本研究旨在探究血清脂质亚类、游离脂肪酸（FA）、二酰甘油（DAG）、三酰甘油（TAG）和胆固醇酯（CE）与大群体的视网膜微血管特征之间的关系。

Method: 使用 Spearman 秩相关分析和 Benjamini-Hochberg 错误发现率（BH-FDR）调整统计显著性，研究了脂质亚类与十种视网膜微血管特征之间的相互作用。

Result: FA 与视网膜血管扭曲度相关，CE 与动脉和静脉的平均宽度相关。相反，DAG 和 TAG 与小动脉和小静脉的宽度和复杂性呈负相关。

Conclusion: 视网膜血管结构反映了不同的循环脂质特征，支持其作为全身代谢健康的非侵入性标志物。

Abstract: Retinal microvascular imaging is increasingly recognised as a non invasive
method for evaluating systemic vascular and metabolic health. However, the
association between lipidomics and retinal vasculature remains inadequate. This
study investigates the relationships between serum lipid subclasses, free fatty
acids (FA), diacylglycerols (DAG), triacylglycerols (TAG), and cholesteryl
esters (CE), and retinal microvascular characteristics in a large
population-based cohort. Using Spearman correlation analysis, we examined the
interconnection between lipid subclasses and ten retinal microvascular traits,
applying the Benjamini-Hochberg false discovery rate (BH-FDR) to adjust for
statistical significance.
  Results indicated that FA were linked to retinal vessel twistiness, while CE
correlated with the average widths of arteries and veins. Conversely, DAG and
TAG showed negative correlations with the width and complexity of arterioles
and venules. These findings suggest that retinal vascular architecture reflects
distinct circulating lipid profiles, supporting its role as a non-invasive
marker of systemic metabolic health. This study is the first to integrate deep
learning (DL)derived retinal traits with lipidomic subclasses in a healthy
cohort, thereby providing insights into microvascular structural changes
independent of disease status or treatment effects.

</details>


### [116] [Quality-Aware Language-Conditioned Local Auto-Regressive Anomaly Synthesis and Detection](https://arxiv.org/abs/2508.03539)
*Long Qian,Bingke Zhu,Yingying Chen,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: ARAS是一种创新的语言条件自回归异常合成方法，它通过精确注入文本指定的局部缺陷来克服现有方法的局限性，并与QARAD框架结合，在异常检测任务中取得了显著成果，同时提高了合成效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散和粗粒度修复的异常合成方法存在结构缺陷，如微观结构不连续、语义控制有限和生成效率低下。

Method: ARAS采用语言条件自回归方法，通过令牌锚定潜在编辑精确注入局部、文本指定的缺陷。利用硬门控自回归算子和无训练的、保持上下文的掩码采样核来增强缺陷真实性和保留精细纹理。QARAD框架通过双编码器模型计算图像-文本相似度得分，采用动态加权策略，侧重于高质量的合成样本。

Result: ARAS在MVTec AD、VisA和BTAD三个基准数据集上进行了广泛的实验，结果表明QARAD在图像级和像素级异常检测任务中均优于SOTA方法，提高了准确性和鲁棒性，并且合成速度比基于扩散的替代方案快5倍。

Conclusion: ARAS通过其创新的语言条件自回归方法，解决了现有异常合成方法的结构缺陷问题，实现了局部、文本指定的缺陷精确注入，并提高了缺陷真实性、纹理保留和语义可控性。结合QARAD框架和动态加权策略，ARAS在异常检测任务中表现出色，超越了现有SOTA方法，并在合成速度上比基于扩散的方法快5倍。

Abstract: Despite substantial progress in anomaly synthesis methods, existing
diffusion-based and coarse inpainting pipelines commonly suffer from structural
deficiencies such as micro-structural discontinuities, limited semantic
controllability, and inefficient generation. To overcome these limitations, we
introduce ARAS, a language-conditioned, auto-regressive anomaly synthesis
approach that precisely injects local, text-specified defects into normal
images via token-anchored latent editing. Leveraging a hard-gated
auto-regressive operator and a training-free, context-preserving masked
sampling kernel, ARAS significantly enhances defect realism, preserves
fine-grained material textures, and provides continuous semantic control over
synthesized anomalies. Integrated within our Quality-Aware Re-weighted Anomaly
Detection (QARAD) framework, we further propose a dynamic weighting strategy
that emphasizes high-quality synthetic samples by computing an image-text
similarity score with a dual-encoder model. Extensive experiments across three
benchmark datasets-MVTec AD, VisA, and BTAD, demonstrate that our QARAD
outperforms SOTA methods in both image- and pixel-level anomaly detection
tasks, achieving improved accuracy, robustness, and a 5 times synthesis speedup
compared to diffusion-based alternatives. Our complete code and synthesized
dataset will be publicly available.

</details>


### [117] [Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences](https://arxiv.org/abs/2508.03542)
*Dmitrii Korzh,Dmitrii Tarasov,Artyom Iudin,Elvir Karimov,Matvey Skripkin,Nikita Kuzmin,Andrey Kuznetsov,Oleg Y. Rogov,Ivan Oseledets*

Main category: cs.CV

TL;DR: 该研究解决了将口语数学转换为LaTeX格式的难题，推出了首个包含66,000多个音频样本的大规模多语言数据集。研究采用音频语言模型等方法，在新基准上显著提升了转换准确率，为多模态AI在数学内容识别领域的发展铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 将语音转换为结构化的数学符号表示（如LaTeX）是一项具有挑战性的任务，因为语音中存在固有的歧义性。尽管自动语音识别（ASR）和语言模型（LM）取得了显著进展，但将口语数学转换为LaTeX的研究仍有待深入。这项技术在教育和研究领域具有广泛的应用前景，例如讲座转录和笔记创建。先前的研究存在局限性，例如需要两次转录、仅关注孤立方程、测试集有限、缺乏训练数据和多语言支持。因此，有必要开发更全面、更大规模的数据集和更有效的方法来解决这些问题。

Method: 研究采用了基于语音识别后校正的方法，并结合了少样本提示（few-shot prompting）和音频语言模型（audio language models）。通过构建一个包含超过66,000个人工标注的数学方程式和句子的音频数据集（英语和俄语），并建立S2L-equations和S2L-sentences两个新的基准，来评估模型的性能。

Result: 在MathSpeech基准上，研究提出的模型实现了与先前工作相当的字符错误率（CER）（28% vs. 30%）。然而，在新提出的S2L-equations基准上，该模型在考虑LaTeX格式伪影后，性能大幅优于MathSpeech模型，错误率降低了超过40个百分点（27% vs. 64%）。对于S2L-sentences基准，研究实现了40%的方程CER。

Conclusion: 该研究提出了首个大规模开源数据集，包含超过66,000个人工标注的数学方程式和句子音频样本（英语和俄语），涵盖了多样的科学领域。研究人员应用了语音识别后校正模型、少样本提示以及音频语言模型，并在MathSpeech基准上实现了与先前工作相当的字符错误率（CER）。更重要的是，在新提出的S2L-equations基准上，该模型在考虑LaTeX格式伪影后，性能大幅优于MathSpeech模型（错误率降低超过40个百分点）。此外，研究还建立了首个数学句子识别基准（S2L-sentences），并将方程CER降至40%。这项工作为多模态人工智能在数学内容识别领域未来的发展奠定了基础。

Abstract: Conversion of spoken mathematical expressions is a challenging task that
involves transcribing speech into a strictly structured symbolic representation
while addressing the ambiguity inherent in the pronunciation of equations.
Although significant progress has been achieved in automatic speech recognition
(ASR) and language models (LM), the problem of converting spoken mathematics
into LaTeX remains underexplored. This task directly applies to educational and
research domains, such as lecture transcription or note creation. Based on ASR
post-correction, prior work requires 2 transcriptions, focuses only on isolated
equations, has a limited test set, and provides neither training data nor
multilingual coverage. To address these issues, we present the first fully
open-source large-scale dataset, comprising over 66,000 human-annotated audio
samples of mathematical equations and sentences in both English and Russian,
drawn from diverse scientific domains. In addition to the ASR post-correction
models and few-shot prompting, we apply audio language models, demonstrating
comparable character error rate (CER) results on the MathSpeech benchmark (28%
vs. 30%) for the equations conversion. In contrast, on the proposed
S2L-equations benchmark, our models outperform the MathSpeech model by a
substantial margin of more than 40 percentage points, even after accounting for
LaTeX formatting artifacts (27% vs. 64%). We establish the first benchmark for
mathematical sentence recognition (S2L-sentences) and achieve an equation CER
of 40%. This work lays the groundwork for future advances in multimodal AI,
with a particular focus on mathematical content recognition.

</details>


### [118] [Advancing Wildlife Monitoring: Drone-Based Sampling for Roe Deer Density Estimation](https://arxiv.org/abs/2508.03545)
*Stephanie Wohlfahrt,Christoph Praschl,Horst Leitner,Wolfram Jantsch,Julia Konic,Silvio Schueler,Andreas Stöckl,David C. Schedl*

Main category: cs.CV

TL;DR: 无人机可用于高效估算野生动物密度，结果与相机陷阱数据相似，但可能反映不同的活动模式。


<details>
  <summary>Details</summary>
Motivation: 传统的野生动物密度估计方法（如捕获-再捕获、距离采样或相机陷阱）耗时或空间受限。无人机提供了一种高效、非侵入性的替代方案。

Method: 使用无人机（配备红外和RGB成像仪）结合三种外推方法（朴素的基于面积的外推、自举法和零膨胀负二项式模型）来估计奥地利东南部野生动物的密度，并将其与相机陷阱数据进行比较。

Result: 无人机方法得出的密度估计值与相机陷阱数据（通过随机遭遇模型计算）相似，但通常更高，这表明无人机可能反映了白天在开放和林地区域的活动，而相机陷阱则反映了更长时间内的平均活动。

Conclusion: 无人机是一种有前途的、可扩展的野生动物密度估计方法。

Abstract: We use unmanned aerial drones to estimate wildlife density in southeastern
Austria and compare these estimates to camera trap data. Traditional methods
like capture-recapture, distance sampling, or camera traps are well-established
but labour-intensive or spatially constrained. Using thermal (IR) and RGB
imagery, drones enable efficient, non-intrusive animal counting. Our surveys
were conducted during the leafless period on single days in October and
November 2024 in three areas of a sub-Illyrian hill and terrace landscape.
Flight transects were based on predefined launch points using a 350 m grid and
an algorithm that defined the direction of systematically randomized transects.
This setup allowed surveying large areas in one day using multiple drones,
minimizing double counts. Flight altitude was set at 60 m to avoid disturbing
roe deer (Capreolus capreolus) while ensuring detection. Animals were manually
annotated in the recorded imagery and extrapolated to densities per square
kilometer. We applied three extrapolation methods with increasing complexity:
naive area-based extrapolation, bootstrapping, and zero-inflated negative
binomial modelling. For comparison, a Random Encounter Model (REM) estimate was
calculated using camera trap data from the flight period. The drone-based
methods yielded similar results, generally showing higher densities than REM,
except in one area in October. We hypothesize that drone-based density reflects
daytime activity in open and forested areas, while REM estimates average
activity over longer periods within forested zones. Although both approaches
estimate density, they offer different perspectives on wildlife presence. Our
results show that drones offer a promising, scalable method for wildlife
density estimation.

</details>


### [119] [A Scalable Machine Learning Pipeline for Building Footprint Detection in Historical Maps](https://arxiv.org/abs/2508.03564)
*Annemarie McCarthy*

Main category: cs.CV

TL;DR: 提出了一种新的机器学习管道，用于从农村历史地图中提取建筑特征，解决了现有方法的计算密集和区域限制问题，并取得了良好的效果，有助于历史和考古发现。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的方法在处理历史地图时，主要集中在城市地区且计算量大，这给需要大规模农村地区分析的研究问题（如核查历史人口普查数据或定位废弃定居点）带来了挑战。

Method: 提出了一种可扩展且高效的管道，用于处理建筑分布稀疏的农村地图。该方法采用分层机器学习方法：首先使用卷积神经网络（CNN）分类器逐步滤除不太可能包含建筑物的地图部分，然后使用CNN分割算法提取建筑特征。

Result: 该管道能够高效准确地提取农村历史地图中的建筑特征，并成功识别出潜在被遗弃的定居点。

Conclusion: 该方法在Ordnance Survey Ireland历史地图系列上进行了验证，显示出与传统的仅分割方法相比，具有高性能和更高的效率。对这两个地图系列的应用揭示了其在历史和考古发现方面的潜力，例如识别出在1839年的地图中有但1899年的地图中不存在的Tully定居点，这可能与大饥荒时期有关。

Abstract: Historical maps offer a valuable lens through which to study past landscapes
and settlement patterns. While prior research has leveraged machine learning
based techniques to extract building footprints from historical maps, such
approaches have largely focused on urban areas and tend to be computationally
intensive. This presents a challenge for research questions requiring analysis
across extensive rural regions, such as verifying historical census data or
locating abandoned settlements. In this paper, this limitation is addressed by
proposing a scalable and efficient pipeline tailored to rural maps with sparse
building distributions. The method described employs a hierarchical machine
learning based approach: convolutional neural network (CNN) classifiers are
first used to progressively filter out map sections unlikely to contain
buildings, significantly reducing the area requiring detailed analysis. The
remaining high probability sections are then processed using CNN segmentation
algorithms to extract building features. The pipeline is validated using test
sections from the Ordnance Survey Ireland historical 25 inch map series and 6
inch map series, demonstrating both high performance and improved efficiency
compared to conventional segmentation-only approaches. Application of the
technique to both map series, covering the same geographic region, highlights
its potential for historical and archaeological discovery. Notably, the
pipeline identified a settlement of approximately 22 buildings in Tully, Co.
Galway, present in the 6 inch map, produced in 1839, but absent from the 25
inch map, produced in 1899, suggesting it may have been abandoned during the
Great Famine period.

</details>


### [120] [SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks](https://arxiv.org/abs/2508.03566)
*Xinyu Xiong,Zihuang Wu,Lei Zhang,Lei Lu,Ming Li,Guanbin Li*

Main category: cs.CV

TL;DR: SAM2-UNeXT通过集成DINOv2编码器和采用新颖结构，提升了SAM2在多种分割任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明SAM具有潜力，但构建更强大、可泛化的编码器以提升性能仍是挑战。

Method: 提出SAM2-UNeXT框架，扩展SAM2的表示能力，通过引入辅助DINOv2编码器，并结合双分辨率策略和密集连接层。

Result: 在二值图像分割、伪装目标检测、海洋生物分割和遥感显著性检测四个基准测试中，SAM2-UNeXT均取得了优于现有方法的性能。

Conclusion: SAM2-UNeXT通过集成DINOv2编码器、双分辨率策略和密集连接层，在多种分割任务上展现出优越性能，且无需复杂的解码器设计。

Abstract: Recent studies have highlighted the potential of adapting the Segment
Anything Model (SAM) for various downstream tasks. However, constructing a more
powerful and generalizable encoder to further enhance performance remains an
open challenge. In this work, we propose SAM2-UNeXT, an advanced framework that
builds upon the core principles of SAM2-UNet while extending the
representational capacity of SAM2 through the integration of an auxiliary
DINOv2 encoder. By incorporating a dual-resolution strategy and a dense glue
layer, our approach enables more accurate segmentation with a simple
architecture, relaxing the need for complex decoder designs. Extensive
experiments conducted on four benchmarks, including dichotomous image
segmentation, camouflaged object detection, marine animal segmentation, and
remote sensing saliency detection, demonstrate the superior performance of our
proposed method. The code is available at
https://github.com/WZH0120/SAM2-UNeXT.

</details>


### [121] [RadProPoser: A Framework for Human Pose Estimation with Uncertainty Quantification from Raw Radar Data](https://arxiv.org/abs/2508.03578)
*Jonas Leo Mueller,Lukas Engel,Eva Dorschky,Daniel Krauss,Ingrid Ullmann,Martin Vossiek,Bjoern M. Eskofier*

Main category: cs.CV

TL;DR: RadProPoser是一个创新的雷达基础人体姿态估计系统，它能够处理复杂的雷达数据，并精确地预测人体关节的三维位置和不确定性。该系统在准确性和可靠性方面表现出色，同时还能通过数据增强提升下游任务的表现。


<details>
  <summary>Details</summary>
Motivation: 雷达基础的人体姿态估计（HPE）提供了一种保护隐私、不受照明影响的传感方式，但面临着噪声和多径效应影响的测量挑战。

Method: 提出了一种名为RadProPoser的概率编码器-解码器架构，该架构处理来自紧凑型3发4收MIMO雷达的复值雷达张量。通过将变分推理纳入关键点回归，RadProPoser可以同时预测26个三维关节位置以及异方差的常数不确定性，并且可以通过重新校准来预测总不确定性。研究了使用高斯和拉普拉斯分布作为潜在先验和似然的各种概率公式。

Result: RadProPoser在包含光学运动捕捉地面真值的新发布的数据集上，实现了6.425厘米的整体平均每关节位置误差（MPJPE），在45度视角下达到5.678厘米。学习到的不确定性与实际姿态误差高度一致，并且可以进行校准以产生可靠的预测间隔，最佳配置的预期校准误差为0.021。此外，通过从这些潜在分布中采样，可以有效地对下游活动分类进行数据增强，F1分数达到0.870。

Conclusion: RadProPoser是首个端到端的基于雷达张量的HPE系统，能够从原始雷达张量数据中显式地建模和量化每个关节的不确定性，为雷达应用中的可解释和可靠的人体运动分析奠定了基础。

Abstract: Radar-based human pose estimation (HPE) provides a privacy-preserving,
illumination-invariant sensing modality but is challenged by noisy,
multipath-affected measurements. We introduce RadProPoser, a probabilistic
encoder-decoder architecture that processes complex-valued radar tensors from a
compact 3-transmitter, 4-receiver MIMO radar. By incorporating variational
inference into keypoint regression, RadProPoser jointly predicts 26
three-dimensional joint locations alongside heteroscedastic aleatoric
uncertainties and can be recalibrated to predict total uncertainty. We explore
different probabilistic formulations using both Gaussian and Laplace
distributions for latent priors and likelihoods. On our newly released dataset
with optical motion-capture ground truth, RadProPoser achieves an overall mean
per-joint position error (MPJPE) of 6.425 cm, with 5.678 cm at the 45 degree
aspect angle. The learned uncertainties exhibit strong alignment with actual
pose errors and can be calibrated to produce reliable prediction intervals,
with our best configuration achieving an expected calibration error of 0.021.
As an additional demonstration, sampling from these latent distributions
enables effective data augmentation for downstream activity classification,
resulting in an F1 score of 0.870. To our knowledge, this is the first
end-to-end radar tensor-based HPE system to explicitly model and quantify
per-joint uncertainty from raw radar tensor data, establishing a foundation for
explainable and reliable human motion analysis in radar applications.

</details>


### [122] [MetaScope: Optics-Driven Neural Network for Ultra-Micro Metalens Endoscopy](https://arxiv.org/abs/2508.03596)
*Wuyang Li,Wentao Pan,Xiaoyuan Liu,Zhendong Luo,Chenxin Li,Hengyu Liu,Din Ping Tsai,Mu Ku Chen,Yixuan Yuan*

Main category: cs.CV

TL;DR: 提出MetaScope，一种用于金属透镜内窥镜的光学驱动神经网络，解决了数据采集和算法研究的差距，并在分割和恢复任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 弥合金属透镜内窥镜在数据采集和算法研究方面存在的差距，推动新型金属透镜内窥镜的发展。

Method: 提出了一种新颖的光学驱动神经网络MetaScope，该网络专为金属透镜内窥镜设计。MetaScope包含两个新颖的设计：光学信息强度调整（OIA）和光学信息色差校正（OCC）。为了增强联合学习，还部署了梯度引导蒸馏来适应性地转移基础模型的知识。

Result: MetaScope在金属透镜分割和恢复方面优于最先进的方法，并在真实的生物医学场景中实现了令人印象深刻的泛化能力。

Conclusion: MetaScope在金属透镜分割和恢复方面优于最先进的方法，并在真实的生物医学场景中实现了令人印象深刻的泛化能力。

Abstract: Miniaturized endoscopy has advanced accurate visual perception within the
human body. Prevailing research remains limited to conventional cameras
employing convex lenses, where the physical constraints with millimetre-scale
thickness impose serious impediments on the micro-level clinical. Recently,
with the emergence of meta-optics, ultra-micro imaging based on metalenses
(micron-scale) has garnered great attention, serving as a promising solution.
However, due to the physical difference of metalens, there is a large gap in
data acquisition and algorithm research. In light of this, we aim to bridge
this unexplored gap, advancing the novel metalens endoscopy. First, we
establish datasets for metalens endoscopy and conduct preliminary optical
simulation, identifying two derived optical issues that physically adhere to
strong optical priors. Second, we propose MetaScope, a novel optics-driven
neural network tailored for metalens endoscopy driven by physical optics.
MetaScope comprises two novel designs: Optics-informed Intensity Adjustment
(OIA), rectifying intensity decay by learning optical embeddings, and
Optics-informed Chromatic Correction (OCC), mitigating chromatic aberration by
learning spatial deformations informed by learned Point Spread Function (PSF)
distributions. To enhance joint learning, we further deploy a gradient-guided
distillation to transfer knowledge from the foundational model adaptively.
Extensive experiments demonstrate that MetaScope not only outperforms
state-of-the-art methods in both metalens segmentation and restoration but also
achieves impressive generalized ability in real biomedical scenes.

</details>


### [123] [DyCAF-Net: Dynamic Class-Aware Fusion Network](https://arxiv.org/abs/2508.03598)
*Md Abrar Jahin,Shahriar Soudeep,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

Main category: cs.CV

TL;DR: DyCAF-Net通过动态类别感知融合改进了物体检测，在各种具有挑战性的场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 静态融合启发式和类别不可知注意力在动态场景（如遮挡、杂乱和类别不平衡）中限制了性能。

Method: DyCAF-Net提出了一种输入条件平衡颈部，通过隐式不动点模型迭代地优化多尺度特征；提出了一种双动态注意机制，使用输入和类别依赖的线索自适应地重新校准通道和空间响应；提出了一种类别感知特征适应方法，以优先考虑稀有类别的判别性区域。

Result: DyCAF-Net在13个多样化基准测试中取得了显著的精度、mAP@50和mAP@50-95的改进，同时保持了计算效率（约1110万参数）和竞争力的推理速度。

Conclusion: DyCAF-Net通过迭代优化多尺度特征、自适应调整通道和空间响应以及优先考虑稀有类别的判别性区域，在13个多样化基准测试中显著提高了精度、mAP@50和mAP@50-95，同时保持了计算效率和竞争性推理速度，适用于各种现实世界的检测任务。

Abstract: Recent advancements in object detection rely on modular architectures with
multi-scale fusion and attention mechanisms. However, static fusion heuristics
and class-agnostic attention limit performance in dynamic scenes with
occlusions, clutter, and class imbalance. We introduce Dynamic Class-Aware
Fusion Network (DyCAF-Net) that addresses these challenges through three
innovations: (1) an input-conditioned equilibrium-based neck that iteratively
refines multi-scale features via implicit fixed-point modeling, (2) a dual
dynamic attention mechanism that adaptively recalibrates channel and spatial
responses using input- and class-dependent cues, and (3) class-aware feature
adaptation that modulates features to prioritize discriminative regions for
rare classes. Through comprehensive ablation studies with YOLOv8 and related
architectures, alongside benchmarking against nine state-of-the-art baselines,
DyCAF-Net achieves significant improvements in precision, mAP@50, and mAP@50-95
across 13 diverse benchmarks, including occlusion-heavy and long-tailed
datasets. The framework maintains computational efficiency ($\sim$11.1M
parameters) and competitive inference speeds, while its adaptability to scale
variance, semantic overlaps, and class imbalance positions it as a robust
solution for real-world detection tasks in medical imaging, surveillance, and
autonomous systems.

</details>


### [124] [CloudBreaker: Breaking the Cloud Covers of Sentinel-2 Images using Multi-Stage Trained Conditional Flow Matching on Sentinel-1](https://arxiv.org/abs/2508.03608)
*Saleh Sakib Ahmed,Sara Nowreen,M. Sohel Rahman*

Main category: cs.CV

TL;DR: CloudBreaker generates multi-spectral satellite data from radar data, overcoming cloud and nighttime limitations. It uses a novel flow matching technique and achieves high-quality results, demonstrated by low FID and high SSIM scores.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of cloud cover and nighttime conditions in satellite-based remote sensing, which restrict the availability and usability of multi-spectral imagery.

Method: A novel multi-stage training approach based on conditional latent flow matching, integrating cosine scheduling with flow matching.

Result: Generated high-quality multi-spectral Sentinel-2 signals from Sentinel-1 data, including reconstruction of optical (RGB) images and vegetation/water indices (NDVI, NDWI). Achieved FID score of 0.7432 for optical imagery, SSIM of 0.6156 for NDWI, and 0.6874 for NDVI.

Conclusion: CloudBreaker is a promising solution for remote sensing applications, providing high-quality multi-spectral data from Sentinel-1 radar imagery, especially where multi-spectral data is typically unavailable or unreliable.

Abstract: Cloud cover and nighttime conditions remain significant limitations in
satellite-based remote sensing, often restricting the availability and
usability of multi-spectral imagery. In contrast, Sentinel-1 radar images are
unaffected by cloud cover and can provide consistent data regardless of weather
or lighting conditions. To address the challenges of limited satellite imagery,
we propose CloudBreaker, a novel framework that generates high-quality
multi-spectral Sentinel-2 signals from Sentinel-1 data. This includes the
reconstruction of optical (RGB) images as well as critical vegetation and water
indices such as NDVI and NDWI.We employed a novel multi-stage training approach
based on conditional latent flow matching and, to the best of our knowledge,
are the first to integrate cosine scheduling with flow matching. CloudBreaker
demonstrates strong performance, achieving a Frechet Inception Distance (FID)
score of 0.7432, indicating high fidelity and realism in the generated optical
imagery. The model also achieved Structural Similarity Index Measure (SSIM) of
0.6156 for NDWI and 0.6874 for NDVI, indicating a high degree of structural
similarity. This establishes CloudBreaker as a promising solution for a wide
range of remote sensing applications where multi-spectral data is typically
unavailable or unreliable

</details>


### [125] [evTransFER: A Transfer Learning Framework for Event-based Facial Expression Recognition](https://arxiv.org/abs/2508.03609)
*Rodrigo Verschae,Ignacio Bugueno-Cordova*

Main category: cs.CV

TL;DR: evTransFER是一种利用事件相机进行面部表情识别的迁移学习框架，通过在面部重建任务上预训练特征提取器，并结合LSTM和TIE表示，显著提高了识别精度。


<details>
  <summary>Details</summary>
Motivation: 为了利用事件相机捕捉的具有高时间分辨率和高动态范围的事件数据来改进面部表情识别的准确性。

Method: 提出了一种基于迁移学习的框架evTransFER，其特征提取器是通过在面部重建任务上训练对抗性生成方法，然后将训练好的编码器权重转移到表情识别系统。此外，还提出了一种结合LSTM捕捉长期表情动态的架构，以及一种名为TIE的新事件表示方法。

Result: evTransFER框架在e-CK+数据库上取得了93.6%的识别率，与现有技术的准确性相比提高了25.9%个百分点以上。

Conclusion: 该研究提出的evTransFER框架在e-CK+数据库上实现了93.6%的识别率，显著优于现有技术水平。

Abstract: Event-based cameras are bio-inspired vision sensors that asynchronously
capture per-pixel intensity changes with microsecond latency, high temporal
resolution, and high dynamic range, providing valuable information about the
spatio-temporal dynamics of the scene. In the present work, we propose
evTransFER, a transfer learning-based framework and architecture for face
expression recognition using event-based cameras. The main contribution is a
feature extractor designed to encode the spatio-temporal dynamics of faces,
built by training an adversarial generative method on a different problem
(facial reconstruction) and then transferring the trained encoder weights to
the face expression recognition system. We show that this proposed transfer
learning method greatly improves the ability to recognize facial expressions
compared to training a network from scratch. In addition, we propose an
architecture that incorporates an LSTM to capture longer-term facial expression
dynamics, and we introduce a new event-based representation, referred to as
TIE, both of which further improve the results. We evaluate the proposed
framework on the event-based facial expression database e-CK+ and compare it to
state-of-the-art methods. The results show that the proposed framework
evTransFER achieves a 93.6\% recognition rate on the e-CK+ database,
significantly improving the accuracy (25.9\% points or more) when compared to
state-of-the-art performance for similar problems.

</details>


### [126] [FPG-NAS: FLOPs-Aware Gated Differentiable Neural Architecture Search for Efficient 6DoF Pose Estimation](https://arxiv.org/abs/2508.03618)
*Nassim Ali Ousalah,Peyman Rostami,Anis Kacem,Enjie Ghorbel,Emmanuel Koumandakis,Djamila Aouada*

Main category: cs.CV

TL;DR: FPG-NAS是一种用于高效6DoF目标姿态估计的FLOPs感知门控可微分神经架构搜索框架。它通过引入特定任务的搜索空间、可微分门控机制和FLOPs正则化，在精度和效率之间取得了良好的平衡，并在LINEMOD和SPEED+数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 估计单张图像的3D旋转和平移虽然被广泛研究，但仍然计算量大，限制了其在资源受限场景下的应用。

Method: 提出了一种专门针对6DoF姿态估计的NAS方法，该方法具有特定任务的搜索空间和一个可微分的门控机制，实现了离散的多候选算子选择，从而提高了架构多样性。此外，还引入了FLOPs正则化项以平衡精度和效率。

Result: 在LINEMOD和SPEED+数据集上的实验表明，FPG-NAS导出的模型在严格的FLOPs约束下表现优于现有方法。

Conclusion: FPG-NAS是第一个专门为6DoF目标姿态估计设计的可微分NAS框架，在严格的FLOPs限制下，其导出的模型优于现有方法。

Abstract: We introduce FPG-NAS, a FLOPs-aware Gated Differentiable Neural Architecture
Search framework for efficient 6DoF object pose estimation. Estimating 3D
rotation and translation from a single image has been widely investigated yet
remains computationally demanding, limiting applicability in
resource-constrained scenarios. FPG-NAS addresses this by proposing a
specialized differentiable NAS approach for 6DoF pose estimation, featuring a
task-specific search space and a differentiable gating mechanism that enables
discrete multi-candidate operator selection, thus improving architectural
diversity. Additionally, a FLOPs regularization term ensures a balanced
trade-off between accuracy and efficiency. The framework explores a vast search
space of approximately 10\textsuperscript{92} possible architectures.
Experiments on the LINEMOD and SPEED+ datasets demonstrate that FPG-NAS-derived
models outperform previous methods under strict FLOPs constraints. To the best
of our knowledge, FPG-NAS is the first differentiable NAS framework
specifically designed for 6DoF object pose estimation.

</details>


### [127] [AttZoom: Attention Zoom for Better Visual Features](https://arxiv.org/abs/2508.03625)
*Daniel DeAlcala,Aythami Morales,Julian Fierrez,Ruben Tolosana*

Main category: cs.CV

TL;DR: Attention Zoom is a new spatial attention layer for CNNs that improves accuracy by focusing on important regions, works with various models, and is easy to add.


<details>
  <summary>Details</summary>
Motivation: To improve feature extraction in convolutional neural networks (CNNs) by introducing a spatial attention mechanism that is modular and model-agnostic, unlike traditional approaches.

Method: Attention Zoom is a modular and model-agnostic spatial attention mechanism that acts as a standalone layer, spatially emphasizing high-importance regions in the input without requiring architecture-specific integration.

Result: Attention Zoom showed consistent improvements in Top-1 and Top-5 classification accuracy on CIFAR-100 and TinyImageNet datasets when evaluated on multiple CNN backbones. Visual analyses indicated that the method encourages fine-grained and diverse attention patterns.

Conclusion: Attention Zoom is effective and general for improving CNNs with minimal architectural overhead.

Abstract: We present Attention Zoom, a modular and model-agnostic spatial attention
mechanism designed to improve feature extraction in convolutional neural
networks (CNNs). Unlike traditional attention approaches that require
architecture-specific integration, our method introduces a standalone layer
that spatially emphasizes high-importance regions in the input. We evaluated
Attention Zoom on multiple CNN backbones using CIFAR-100 and TinyImageNet,
showing consistent improvements in Top-1 and Top-5 classification accuracy.
Visual analyses using Grad-CAM and spatial warping reveal that our method
encourages fine-grained and diverse attention patterns. Our results confirm the
effectiveness and generality of the proposed layer for improving CCNs with
minimal architectural overhead.

</details>


### [128] [Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images](https://arxiv.org/abs/2508.03643)
*Xiangyu Sun,Haoyi jiang,Liu Liu,Seungtae Nam,Gyeongjin Kang,Xinjie wang,Wei Sui,Zhizhong Su,Wenyu Liu,Xinggang Wang,Eunbyung Park*

Main category: cs.CV

TL;DR: Uni3R 是一个创新的前馈框架，可以从多视图图像中同时进行 3D 场景重建和语义理解，无需姿态信息，实现了高保真视图合成、3D 语义分割和深度预测，并在多个基准测试中创下新纪录。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏 2D 视图重建和语义解释 3D 场景的根本挑战，克服现有方法在语义理解和重建上分离或需要昂贵每场景优化的限制。

Method: Uni3R 利用跨视图 Transformer 整合多视图信息，并回归一组具有语义特征场的 3D 高斯图元。

Result: Uni3R 在多个基准测试中取得了新的最先进成果，在 RE10K 上达到 25.07 PSNR，在 ScanNet 上达到 55.84 mIoU。

Conclusion: Uni3R 提出了一种新的前馈框架，能够从非姿态的多视图图像中联合重建统一的 3D 场景表示，并赋予开放词汇语义，从而实现了高保真新视图合成、开放词汇 3D 语义分割和深度预测。

Abstract: Reconstructing and semantically interpreting 3D scenes from sparse 2D views
remains a fundamental challenge in computer vision. Conventional methods often
decouple semantic understanding from reconstruction or necessitate costly
per-scene optimization, thereby restricting their scalability and
generalizability. In this paper, we introduce Uni3R, a novel feed-forward
framework that jointly reconstructs a unified 3D scene representation enriched
with open-vocabulary semantics, directly from unposed multi-view images. Our
approach leverages a Cross-View Transformer to robustly integrate information
across arbitrary multi-view inputs, which then regresses a set of 3D Gaussian
primitives endowed with semantic feature fields. This unified representation
facilitates high-fidelity novel view synthesis, open-vocabulary 3D semantic
segmentation, and depth prediction, all within a single, feed-forward pass.
Extensive experiments demonstrate that Uni3R establishes a new state-of-the-art
across multiple benchmarks, including 25.07 PSNR on RE10K and 55.84 mIoU on
ScanNet. Our work signifies a novel paradigm towards generalizable, unified 3D
scene reconstruction and understanding. The code is available at
https://github.com/HorizonRobotics/Uni3R.

</details>


### [129] [LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation](https://arxiv.org/abs/2508.03694)
*Jianxiong Gao,Zhaoxi Chen,Xian Liu,Jianfeng Feng,Chenyang Si,Yanwei Fu,Yu Qiao,Ziwei Liu*

Main category: cs.CV

TL;DR: LongVie通过统一的噪声初始化、全局控制信号归一化和多模态控制框架解决了长视频生成中的时间不一致和视觉降解问题，并在一个包含100个长视频的基准上展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的短视频生成方法难以扩展到长视频，存在时间不一致和视觉降解的问题。

Method: LongVie是一个端到端的自回归框架，采用统一的噪声初始化策略和全局控制信号归一化来确保时间一致性，并结合了密集和稀疏的控制信号以及一种识别训练策略来缓解视觉降解。

Result: LongVie在长距离可控性、一致性和质量方面取得了最先进的性能。

Conclusion: LongVie在长视频生成方面实现了最先进的控制性、一致性和质量。

Abstract: Controllable ultra-long video generation is a fundamental yet challenging
task. Although existing methods are effective for short clips, they struggle to
scale due to issues such as temporal inconsistency and visual degradation. In
this paper, we initially investigate and identify three key factors: separate
noise initialization, independent control signal normalization, and the
limitations of single-modality guidance. To address these issues, we propose
LongVie, an end-to-end autoregressive framework for controllable long video
generation. LongVie introduces two core designs to ensure temporal consistency:
1) a unified noise initialization strategy that maintains consistent generation
across clips, and 2) global control signal normalization that enforces
alignment in the control space throughout the entire video. To mitigate visual
degradation, LongVie employs 3) a multi-modal control framework that integrates
both dense (e.g., depth maps) and sparse (e.g., keypoints) control signals,
complemented by 4) a degradation-aware training strategy that adaptively
balances modality contributions over time to preserve visual quality. We also
introduce LongVGenBench, a comprehensive benchmark consisting of 100
high-resolution videos spanning diverse real-world and synthetic environments,
each lasting over one minute. Extensive experiments show that LongVie achieves
state-of-the-art performance in long-range controllability, consistency, and
quality.

</details>


### [130] [Trokens: Semantic-Aware Relational Trajectory Tokens for Few-Shot Action Recognition](https://arxiv.org/abs/2508.03695)
*Pulkit Kumar,Shuaiyi Huang,Matthew Walmer,Sai Saketh Rambhatla,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: Trokens 是一种新的少样本动作识别方法，通过将轨迹点转换为语义感知关系令牌来结合运动和外观信息，并在多个基准测试中实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管点跟踪在少样本动作识别方面取得了进展，但仍然存在两个基本挑战：选择信息点进行跟踪以及有效地模拟它们的运动模式。

Method: Trokens 的方法包括两个主要部分：1. 语义感知采样策略：自适应地根据对象尺度和语义相关性分布跟踪点。 2. 运动建模框架：使用定向位移直方图 (HoD) 捕获轨迹动力学，并建立轨迹间关系来模拟复杂的动作模式。

Result: Trokens 在 Something-Something-V2（完整和小型划分）、Kinetics、UCF101、HMDB51 和 FineGym 等六个多样化的少样本动作识别基准上取得了最先进的性能。

Conclusion: Trokens 通过将轨迹点转换为语义感知关系令牌，有效地将运动信息与语义特征相结合，以增强外观特征，在六个不同的少样本动作识别基准上实现了最先进的性能。

Abstract: Video understanding requires effective modeling of both motion and appearance
information, particularly for few-shot action recognition. While recent
advances in point tracking have been shown to improve few-shot action
recognition, two fundamental challenges persist: selecting informative points
to track and effectively modeling their motion patterns. We present Trokens, a
novel approach that transforms trajectory points into semantic-aware relational
tokens for action recognition. First, we introduce a semantic-aware sampling
strategy to adaptively distribute tracking points based on object scale and
semantic relevance. Second, we develop a motion modeling framework that
captures both intra-trajectory dynamics through the Histogram of Oriented
Displacements (HoD) and inter-trajectory relationships to model complex action
patterns. Our approach effectively combines these trajectory tokens with
semantic features to enhance appearance features with motion information,
achieving state-of-the-art performance across six diverse few-shot action
recognition benchmarks: Something-Something-V2 (both full and small splits),
Kinetics, UCF101, HMDB51, and FineGym. For project page see
https://trokens-iccv25.github.io

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [131] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
*Radhika Dua,Young Joon,Kwon,Siddhant Dogra,Daniel Freedman,Diana Ruan,Motaz Nashawaty,Danielle Rigau,Daniel Alexander Alber,Kang Zhang,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: ICARE是一个创新的、可解释的医学影像报告生成评估框架，通过智能体问答来衡量临床准确性，优于现有指标。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像报告生成评估指标缺乏可解释性且难以确保临床可靠性，阻碍了模型的安全部署。

Method: ICARE利用两个分别基于真实报告和生成报告的LLM智能体，生成并相互问答临床问题，通过回答一致性来评估生成报告的临床准确性和召回率。

Result: ICARE在临床医生研究中显示出与专家判断的高度一致性，优于现有指标，并且能够进行敏感的扰动分析和可解释的错误模式识别。

Conclusion: ICARE是一个可解释的评估框架，通过基于LLM的智能体和动态MCQA，能够更准确地反映临床判断，并提供可解释的错误模式分析。

Abstract: Radiological imaging is central to diagnosis, treatment planning, and
clinical decision-making. Vision-language foundation models have spurred
interest in automated radiology report generation (RRG), but safe deployment
requires reliable clinical evaluation of generated reports. Existing metrics
often rely on surface-level similarity or behave as black boxes, lacking
interpretability. We introduce ICARE (Interpretable and Clinically-grounded
Agent-based Report Evaluation), an interpretable evaluation framework
leveraging large language model agents and dynamic multiple-choice question
answering (MCQA). Two agents, each with either the ground-truth or generated
report, generate clinically meaningful questions and quiz each other. Agreement
on answers captures preservation and consistency of findings, serving as
interpretable proxies for clinical precision and recall. By linking scores to
question-answer pairs, ICARE enables transparent, and interpretable assessment.
Clinician studies show ICARE aligns significantly more with expert judgment
than prior metrics. Perturbation analyses confirm sensitivity to clinical
content and reproducibility, while model comparisons reveal interpretable error
patterns.

</details>


### [132] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
*Yinuo Xu,Veronica Derricks,Allison Earl,David Jurgens*

Main category: cs.CL

TL;DR: 本研究提出了 DEM-MoE 模型来处理自然语言处理任务中的注释者分歧，并利用 LLM 合成数据来丰富训练集，同时探索了不同的数据融合策略。


<details>
  <summary>Details</summary>
Motivation: 主观自然语言处理任务中的注释者分歧会影响模型的性能，尤其是在存在人口统计差异的情况下。现有的模型在处理这种结构化、群体层面的变化方面存在局限性。此外，由于人口统计信息的覆盖可能很稀疏，因此需要一种有效的数据插补方法来丰富训练数据。

Method: 1. 提出了一种名为 DEM-MoE (Demographic-Aware Mixture of Experts) 的模型，该模型能够根据注释者的人口统计信息将输入路由到专家子网络，以更好地表示结构化、群体层面的变化。
2. 测试了使用零样本人员配置提示生成的 LLM 合成注释是否可用于数据插补，以解决人口统计覆盖稀疏的问题。
3. 提出并评估了使用针对数据集结构定制的策略来融合真实数据和合成数据的方法。

Result: DEM-MoE 模型在不同人口统计群体中的表现始终具有竞争力，并在注释者分歧较大的数据集上取得了尤为显著的成果。
LLM 生成的合成注释与人类注释具有中等程度的一致性，并为丰富训练数据提供了一种可扩展的方法。
最优的真实数据和合成数据融合策略取决于数据集的结构。

Conclusion: 该研究提出了一种通过架构和数据中心创新来模拟主观自然语言处理任务中注释者分歧的方法。所提出的 DEM-MoE 模型能够根据注释者的人口统计信息将输入路由到专家子网络，与先前模型相比，能更好地表示结构化、群体层面的变化。DEM-MoE 在不同人口统计群体中的表现始终具有竞争力，并在注释者分歧较大的数据集上取得了尤为显著的成果。为了解决人口统计覆盖稀疏的问题，研究人员测试了通过零样本人员配置提示生成的 LLM 合成注释是否可用于数据插补。结果表明，这些合成判断与研究中的人类注释具有中等程度的一致性，并为丰富训练数据提供了一种可扩展的方法。此外，研究还提出并评估了使用针对数据集结构定制的策略来融合真实数据和合成数据的方法，发现最佳策略取决于数据集的结构。总而言之，这些贡献共同改进了对不同观点的表示。

Abstract: We present an approach to modeling annotator disagreement in subjective NLP
tasks through both architectural and data-centric innovations. Our model,
DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert
subnetworks based on annotator demographics, enabling it to better represent
structured, group-level variation compared to prior models. DEM-MoE
consistently performs competitively across demographic groups, and shows
especially strong results on datasets with high annotator disagreement. To
address sparse demographic coverage, we test whether LLM-generated synthetic
annotations via zero-shot persona prompting can be used for data imputation. We
show these synthetic judgments align moderately well with human annotations on
our data and offer a scalable way to potentially enrich training data. We then
propose and evaluate approaches for blending real and synthetic data using
strategies tailored to dataset structure. We find that the optimal strategies
depend on dataset structure. Together, these contributions improve the
representation of diverse perspectives.

</details>


### [133] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: 提出了一种名为 Highlight & Summarize (H&S) 的新方法，用于防御 LLM 越狱和模型劫持攻击。该方法通过将 RAG 过程分为高亮器和总结器两个阶段，避免将用户原始问题直接暴露给 LLM，并在实验中发现 H&S 在响应质量上优于标准 RAG。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）容易受到越狱和模型劫持等攻击，攻击者可以通过精心设计的提示词诱导模型生成不良内容或执行非预期任务。现有的缓解措施（如强化系统提示或使用内容分类器）容易被绕过，因此需要一种新的防御方法。

Method: H&S 设计模式将 RAG 管道分为高亮器和总结器两个组件。高亮器负责从检索到的文档中提取与用户问题相关的片段，而总结器则负责将这些提取出的片段整合成最终的答案。

Result: 研究表明，当使用基于 LLM 的高亮器时，H&S 的大多数响应在正确性、相关性和质量方面优于标准的 RAG 管道。

Conclusion: Highlight & Summarize (H&S) 是一种新的设计模式，通过不将用户的问题直接暴露给生成式语言模型来防止越狱和模型劫持等攻击。在检索增强生成（RAG）系统中，H&S 将管道分为两个部分：一个“高亮器”用于提取相关文档片段，一个“总结器”用于将这些片段总结成答案。

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [134] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
*Elliot Murphy,Rohan Venkatesh,Edward Khokhlovich,Andrey Vyshedskiy*

Main category: cs.CL

TL;DR: 本研究探究了句法操作'Merge'的神经认知基础。研究发现，虽然Merge可能在进化中是突然出现的，但不同类型的Merge结构（如简单命令、名词-形容词组合、名词-介词组合）在认知加工上存在差异，可能与不同的发育阶段和选择性损伤有关。


<details>
  <summary>Details</summary>
Motivation: 探究Merge操作的神经认知基础，并考察不同句法结构在发展和选择性损伤方面是否存在差异。

Method: 本研究系统地调查了参与者对具有不同句法复杂性水平的句子的理解，并通过聚类分析揭示了行为证据。

Result: 聚类分析揭示了三种不同的结构类型，这可能与不同的发育阶段有关，并且可能受到选择性损伤的影响。

Conclusion: 虽然基于Merge的语法可能在进化时间上突然出现，但不同的认知机制似乎支持了不同类型的基于Merge的对象的处理。

Abstract: In the modern language sciences, the core computational operation of syntax,
'Merge', is defined as an operation that combines two linguistic units (e.g.,
'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).
This can then be further combined with additional linguistic units based on
this categorial information, respecting non-associativity such that abstract
grouping is respected. Some linguists have embraced the view that Merge is an
elementary, indivisible operation that emerged in a single evolutionary step.
From a neurocognitive standpoint, different mental objects constructed by Merge
may be supported by distinct mechanisms: (1) simple command constructions
(e.g., "eat apples"); (2) the merging of adjectives and nouns ("red boat"); and
(3) the merging of nouns with spatial prepositions ("laptop behind the sofa").
Here, we systematically investigate participants' comprehension of sentences
with increasing levels of syntactic complexity. Clustering analyses revealed
behavioral evidence for three distinct structural types, which we discuss as
potentially emerging at different developmental stages and subject to selective
impairment. While a Merge-based syntax may still have emerged suddenly in
evolutionary time, responsible for the structured symbolic turn our species
took, different cognitive mechanisms seem to underwrite the processing of
various types of Merge-based objects.

</details>


### [135] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
*Wenjie Luo,Ruocheng Li,Shanshan Zhu,Julian Perry*

Main category: cs.CL

TL;DR: CMRF通过模仿人类解决问题的方式，利用问题分解、迭代推理和自我修正，显著提高了大型语言模型（LLMs）和视觉语言模型（LVLMs）在多模态常识推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs和LVLMs在处理复杂、多步、跨模态的常识推理任务时存在不足，缺乏“深思熟虑”的能力，倾向于依赖表面关联而非深入的链式推理，特别是在整合视觉信息和抽象概念时。

Method: 提出了一种名为相干多模态推理框架（CMRF）的新方法，该框架通过迭代、自评估的推理机制来增强LVLMs的常识推理能力。CMRF包含三个关键模块：用于问题分解的推理分解单元（RDU）、用于上下文推理的上下文推理引擎（CIE）以及用于评估逻辑一致性和置信度的相干性评估模块（CAM）。结合自适应迭代优化策略，CMRF能够系统地优化推理路径。该框架基于LLaVA-1.6-34B，并在新颖的多模态日常活动推理（MDAR）数据集上进行了训练。

Result: CMRF在VCR、A-OKVQA和DailyLife-MRC等基准测试上达到了最先进的性能，平均准确率为69.4%，比最佳的开源基线提高了2.4个百分点，在复杂推理场景下表现尤为突出。消融研究和人类评估证实了每个模块的关键贡献以及迭代优化在促进更连贯、准确推理方面的有效性。

Conclusion: CMRF通过迭代、自评估的推理机制，显著提升了LVLMs在复杂、多步、跨模态常识推理任务上的表现，尤其在需要整合视觉信息和抽象概念的场景下，其性能优于现有开源模型，证明了其在促进更连贯、准确推理方面的有效性。

Abstract: Despite significant advancements, current large language models (LLMs) and
vision-language models (LVLMs) continue to struggle with complex, multi-step,
cross-modal common sense reasoning tasks, often exhibiting a lack of
"deliberative thinking." They tend to rely on superficial associations rather
than deep, chained inference, particularly when integrating visual information
with abstract concepts. To address this, we propose the Coherent Multimodal
Reasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense
reasoning capabilities through an iterative, self-evaluating inference
mechanism. CMRF mimics human problem-solving by decomposing complex queries,
generating step-by-step inferences, and self-correcting errors. Our framework
integrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking
down problems into sub-questions, a Contextual Inference Engine (CIE) for
contextual inference, and a Coherence Assessment Module (CAM) for evaluating
logical consistency and confidence. Coupled with an Adaptive Iterative
Refinement strategy, CMRF systematically refines its reasoning paths. Built
upon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning
(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source
LVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It
attains an average accuracy of 69.4%, surpassing the best open-source baseline
by +2.4 percentage points, with particular strength in complex reasoning
scenarios. Extensive ablation studies and human evaluations confirm the
critical contributions of each module and the effectiveness of iterative
refinement in fostering more coherent and accurate reasoning.

</details>


### [136] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
*Osama Khalid,Sanvesh Srivastava,Padmini Srinivasan*

Main category: cs.CL

TL;DR: 感官语言通过低维风格特征（LIWC）和 SLIM-LLMs 模型进行有效建模，可实现高性能和高参数效率。


<details>
  <summary>Details</summary>
Motivation: 探索了感官语言与传统风格特征之间的关系。

Method: 使用新颖的降秩岭回归（R4）方法探索了感官语言与传统风格特征（如 LIWC 测量）之间的关系。

Result: 低维潜在表示（r = 24）的 LIWC 特征有效地捕捉了感官语言预测的风格信息，而使用全部特征集（r = 74）则不然。SLIM-LLMs 实现了与全规模语言模型相当的性能，同时显著减少了参数量。

Conclusion: SLIM-LLMs 使用低秩 LIWC 特征在五个流派的评估中，在匹配全规模语言模型的性能的同时，参数减少了多达 80%。

Abstract: Sensorial language -- the language connected to our senses including vision,
sound, touch, taste, smell, and interoception, plays a fundamental role in how
we communicate experiences and perceptions. We explore the relationship between
sensorial language and traditional stylistic features, like those measured by
LIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate
that low-dimensional latent representations of LIWC features r = 24 effectively
capture stylistic information for sensorial language prediction compared to the
full feature set (r = 74). We introduce Stylometrically Lean Interpretable
Models (SLIM-LLMs), which model non-linear relationships between these style
dimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features
match the performance of full-scale language models while reducing parameters
by up to 80%.

</details>


### [137] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
*Shengqi Li,Amarnath Gupta*

Main category: cs.CL

TL;DR: 该研究提出了一个参数化框架，用于控制大型语言模型（LLM）的对话质量，通过九个关键参数调节对话属性，并在实验中证明了其有效性，可应用于多个领域。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决对话生成中的挑战，包括主题连贯性、知识进展、角色一致性和控制粒度。

Method: 本研究引入了一个用于控制大型语言模型中对话质量的参数化框架，探索了跨越六个维度、涉及九个关键参数，能够精确指定对话属性。

Result: 通过对最先进的大型语言模型的实验，我们证明了基于参数的控制能在生成的对话属性方面产生统计学上显著的差异。

Conclusion: 该框架为对话质量控制提供了一种标准化方法，可应用于教育、治疗、客户服务和娱乐领域。未来的工作将侧重于通过架构修改实现其他参数以及开发用于评估的基准数据集。

Abstract: This paper introduces a parameterization framework for controlling
conversation quality in large language models. We explore nine key parameters
across six dimensions that enable precise specification of dialogue properties.
Through experiments with state-of-the-art LLMs, we demonstrate that
parameter-based control produces statistically significant differences in
generated conversation properties. Our approach addresses challenges in
conversation generation, including topic coherence, knowledge progression,
character consistency, and control granularity. The framework provides a
standardized method for conversation quality control with applications in
education, therapy, customer service, and entertainment. Future work will focus
on implementing additional parameters through architectural modifications and
developing benchmark datasets for evaluation.

</details>


### [138] [Variety Is the Spice of Life: Detecting Misinformation with Dynamic Environmental Representations](https://arxiv.org/abs/2508.03420)
*Bing Wang,Ximing Li,Yiming Wang,Changchun Li,Jiaxu Cui,Renchu Guan,Bo Yang*

Main category: cs.CL

TL;DR: MISDER框架通过考虑动态环境表示来改进错误信息检测，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 主流的错误信息检测（MD）方法将MD视为一个静态学习范例，但这种静态假设在现实世界中往往被违反，因为新闻文章的真实性可能在动态演变的社交环境中发生波动。因此，有必要提出一种能够应对这种动态变化的模型。

Method: 提出了一种名为MISDER的新框架，该框架包含三个变体：MISDER-LSTM、MISDER-ODE和MISDER-PT。MISDER通过学习每个时期的社会环境表示，并利用时间模型（如LSTM、连续动态方程和预训练动态系统）来预测未来时期的表示，从而检测动态变化中的错误信息。

Result: 与各种MD基线相比，MISDER在两个流行数据集上的实验结果表明了其有效性。

Conclusion: MISDER框架通过学习每个时期的社会环境表示并使用时间模型预测未来时期的表示，解决了社交媒体中错误信息动态变化的问题，并在两个流行数据集上的实验结果表明了其有效性。

Abstract: The proliferation of misinformation across diverse social media platforms has
drawn significant attention from both academic and industrial communities due
to its detrimental effects. Accordingly, automatically distinguishing
misinformation, dubbed as Misinformation Detection (MD), has become an
increasingly active research topic. The mainstream methods formulate MD as a
static learning paradigm, which learns the mapping between the content, links,
and propagation of news articles and the corresponding manual veracity labels.
However, the static assumption is often violated, since in real-world
scenarios, the veracity of news articles may vacillate within the dynamically
evolving social environment. To tackle this problem, we propose a novel
framework, namely Misinformation detection with Dynamic Environmental
Representations (MISDER). The basic idea of MISDER lies in learning a social
environmental representation for each period and employing a temporal model to
predict the representation for future periods. In this work, we specify the
temporal model as the LSTM model, continuous dynamics equation, and pre-trained
dynamics system, suggesting three variants of MISDER, namely MISDER-LSTM,
MISDER-ODE, and MISDER-PT, respectively. To evaluate the performance of MISDER,
we compare it to various MD baselines across 2 prevalent datasets, and the
experimental results can indicate the effectiveness of our proposed model.

</details>


### [139] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的检测LLM越狱提示的方法，该方法利用上下文共现矩阵和张量的潜在空间特征。该方法在标记数据稀少的情况下表现出色，并在准确性和速度方面均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: LLM的复杂性和难以理解的特性使其容易受到攻击，特别是旨在产生有害响应的越狱攻击。因此，开发强大的检测方法是必要的。

Method: 利用上下文共现矩阵和张量的潜在空间特征来识别对抗性和越狱提示。

Result: 该方法实现了0.83的F1分数，仅使用了0.5%的标记提示，比基线模型提高了96.6%，并且速度提高了2.3到128.4倍。

Conclusion: 开发强大的检测方法对于LLM的安全可靠使用至关重要。所提出的方法在标记数据稀少的情况下表现出色，并显著优于基线模型。

Abstract: The widespread use of Large Language Models (LLMs) in many applications marks
a significant advance in research and practice. However, their complexity and
hard-to-understand nature make them vulnerable to attacks, especially
jailbreaks designed to produce harmful responses. To counter these threats,
developing strong detection methods is essential for the safe and reliable use
of LLMs. This paper studies this detection problem using the Contextual
Co-occurrence Matrix, a structure recognized for its efficacy in data-scarce
environments. We propose a novel method leveraging the latent space
characteristics of Contextual Co-occurrence Matrices and Tensors for the
effective identification of adversarial and jailbreak prompts. Our evaluations
show that this approach achieves a notable F1 score of 0.83 using only 0.5% of
labeled prompts, which is a 96.6% improvement over baselines. This result
highlights the strength of our learned patterns, especially when labeled data
is scarce. Our method is also significantly faster, speedup ranging from 2.3 to
128.4 times compared to the baseline models. To support future research and
reproducibility, we have made our implementation publicly available.

</details>


### [140] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
*Ariya Mukherjee-Gandhi,Oliver Muellerklein*

Main category: cs.CL

TL;DR: 本研究分析了2013-2025年间关于AI生成艺术的英文论述，发现媒体叙事与艺术家关切存在脱节，技术术语的使用可能边缘化艺术家的声音。研究提出了一种基于BERTopic的方法，并呼吁在AI与创意领域的发展中更加关注艺术家的视角。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI对艺术创作和人类表达方式的改变，艺术家们对其创作的同意、透明度及创意劳动未来表示担忧，但他们的声音在公共和学术讨论中常被边缘化。本研究旨在分析围绕AI生成艺术的论述，特别是艺术家在此过程中的观点和担忧。

Method: 本研究采用可复现的方法，对2013年至2025年间的439篇英文AI生成艺术相关论述（包括观点文章、新闻报道、博客、法律文件和口述记录）进行样本提取和分析，利用BERTopic技术识别了五个稳定的主题，并分析了艺术家看法与媒体叙事之间的不一致性。

Result: 研究识别出五个稳定的主题，并发现艺术家对AI生成艺术的看法与主流媒体的叙事存在不一致。研究还指出，技术术语的使用可能成为一种“守门”机制，忽视了艺术家认为最紧迫的问题。

Conclusion: 本研究通过对2013年至2025年英文AI生成艺术相关论述的分析，揭示了艺术家观点与主流媒体叙事之间存在偏差，并强调了技术术语可能造成的“守门”效应，忽视了艺术家最关切的问题。研究呼吁在AI与创意领域的发展中，应更深入、更透明地关注艺术家视角。

Abstract: As generative AI continues to reshape artistic production and alternate modes
of human expression, artists whose livelihoods are most directly affected have
raised urgent concerns about consent, transparency, and the future of creative
labor. However, the voices of artists are often marginalized in dominant public
and scholarly discourse. This study presents a twelve-year analysis, from 2013
to 2025, of English-language discourse surrounding AI-generated art. It draws
from 439 curated 500-word excerpts sampled from opinion articles, news reports,
blogs, legal filings, and spoken-word transcripts. Through a reproducible
methodology, we identify five stable thematic clusters and uncover a
misalignment between artists' perceptions and prevailing media narratives. Our
findings highlight how the use of technical jargon can function as a subtle
form of gatekeeping, often sidelining the very issues artists deem most urgent.
Our work provides a BERTopic-based methodology and a multimodal baseline for
future research, alongside a clear call for deeper, transparency-driven
engagement with artist perspectives in the evolving AI-creative landscape.

</details>


### [141] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
*Haoran Wang,Xiongxiao Xu,Baixiang Huang,Kai Shu*

Main category: cs.CL

TL;DR: PAD 是一种创新的解码策略，通过注入噪声来保护 RAG 系统中的敏感信息，可在不损害模型性能的情况下提供强大的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然提高了大型语言模型（LLM）的事实准确性，但在处理私有或敏感数据时，容易受到提取攻击，可能通过生成的响应泄露机密信息。

Method: PAD（Privacy-Aware Decoding）通过在生成过程中自适应地将校准后的高斯噪声注入 token logits 来实现。它结合了基于置信度的筛选以选择性地保护高风险 token，高效的敏感性估计以最小化不必要的噪声，以及上下文感知的噪声校准以平衡隐私和生成质量。PAD 使用 RDP（Rényi Differential Privacy）会计严格跟踪累积隐私损失，为敏感输出提供明确的 $(\varepsilon, \delta)$-DP 保证。

Result: 实验证明，PAD 在减少私有信息泄露方面表现优于现有的基于检索和后处理的防御方法，同时保持了响应效用。

Conclusion: PAD 是一种模型无关、仅在解码时操作的防御方法，可有效减少私有信息泄露，同时保持响应效用，在减少 RAG 中的隐私风险方面迈出了重要一步，为敏感领域提供了通用且可扩展的隐私解决方案。

Abstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large
language models (LLMs) by conditioning outputs on external knowledge sources.
However, when retrieval involves private or sensitive data, RAG systems are
susceptible to extraction attacks that can leak confidential information
through generated responses. We propose Privacy-Aware Decoding (PAD), a
lightweight, inference-time defense that adaptively injects calibrated Gaussian
noise into token logits during generation. PAD integrates confidence-based
screening to selectively protect high-risk tokens, efficient sensitivity
estimation to minimize unnecessary noise, and context-aware noise calibration
to balance privacy with generation quality. A \renyi Differential Privacy (RDP)
accountant rigorously tracks cumulative privacy loss, enabling explicit
per-response $(\varepsilon, \delta)$-DP guarantees for sensitive outputs.
Unlike prior approaches requiring retraining or corpus-level filtering, PAD is
model-agnostic and operates entirely at decoding time with minimal
computational overhead. Experiments on three real-world datasets demonstrate
that PAD substantially reduces private information leakage while preserving
response utility, outperforming existing retrieval- and post-processing-based
defenses. Our work takes an important step toward mitigating privacy risks in
RAG via decoding strategies, paving the way for universal and scalable privacy
solutions in sensitive domains. Our code is available:
https://github.com/wang2226/PAD.

</details>


### [142] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: TPARAG 是一种新的框架，可以攻击 RAG 系统，即使在黑盒场景下也是如此，因为它在 token 级别生成和优化恶意内容。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 RAG 攻击方法在黑盒场景下受限于访问权限或未能联合考虑检索和生成阶段的问题，提出 TPARAG 框架。

Method: TPARAG 框架利用一个轻量级的白盒 LLM 作为攻击者，在 token 级别生成和迭代优化恶意通道，确保了可检索性和在生成中的高攻击成功率。

Result: TPARAG 在开放域问答数据集上的广泛实验证明，其在检索阶段和端到端的攻击效果方面始终优于先前的方法。

Conclusion: TPARAG 框架在白盒和黑盒 RAG 系统中均有效，优于先前的方法，揭示了 RAG 管道的严重漏洞，并为提高其鲁棒性提供了新的见解。

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [143] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: This paper analyzes sentiment and emotion differences in English-Arabic comparable texts. It uses a cross-lingual approach and bilingual emotion lexicons for annotation. Findings indicate alignment in sentiment/emotion for same-source articles and divergence for different-source articles, with a generalizable, language-independent method.


<details>
  <summary>Details</summary>
Motivation: This research studies differences in sentiments and emotions across English-Arabic comparable documents, which are topic-aligned documents in multiple languages that are not direct translations. Understanding how a topic is discussed across languages is valuable.

Method: This research applies a cross-lingual method to label documents with opinion classes (subjective/objective) without relying on machine translation. Emotions (anger, disgust, fear, joy, sadness, surprise) are annotated using manually translated English WordNet-Affect (WNA) lexicon into Arabic, creating bilingual emotion lexicons. A statistical measure is then applied to assess the agreement of sentiments and emotions in each source-target document pair.

Result: Results show that sentiment and emotion annotations align when articles come from the same news agency and diverge when they come from different ones.

Conclusion: The study demonstrates that sentiment and emotion annotations align when articles originate from the same news agency and diverge when they come from different ones. The proposed method is language-independent and generalizable to other language pairs.

Abstract: Comparable texts are topic-aligned documents in multiple languages that are
not direct translations. They are valuable for understanding how a topic is
discussed across languages. This research studies differences in sentiments and
emotions across English-Arabic comparable documents. First, texts are annotated
with sentiment and emotion labels. We apply a cross-lingual method to label
documents with opinion classes (subjective/objective), avoiding reliance on
machine translation. To annotate with emotions (anger, disgust, fear, joy,
sadness, surprise), we manually translate the English WordNet-Affect (WNA)
lexicon into Arabic, creating bilingual emotion lexicons used to label the
comparable corpora. We then apply a statistical measure to assess the agreement
of sentiments and emotions in each source-target document pair. This comparison
is especially relevant when the documents originate from different sources. To
our knowledge, this aspect has not been explored in prior literature. Our study
includes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera
(JSC). Results show that sentiment and emotion annotations align when articles
come from the same news agency and diverge when they come from different ones.
The proposed method is language-independent and generalizable to other language
pairs.

</details>


### [144] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: 为了解决长故事生成中的主题漂移和情节问题，本研究提出了一个多代理生成器，通过记忆存储和故事主题障碍框架来提高故事的质量和吸引力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有长文本生成方法在长故事生成任务中存在的主题漂移和情节平淡、逻辑不连贯的问题，提高生成故事的质量和吸引力。

Method: 本研究提出了一个多代理的故事生成器结构，使用大型语言模型作为代理的核心组件。为了避免主题漂移，引入了一个包含长期记忆存储和短期记忆存储的记忆存储模型。为了增加故事的吸引力，设计了一个基于文学叙事学理论的故事主题障碍框架，该框架通过构建知识图谱和整合新的节点内容来计算故事的相似性。此外，还建立了一个多代理交互阶段来模拟写者-读者交互，并根据反馈修改故事文本。

Result: 评估结果表明，与先前的方法相比，本研究提出的方法能够生成更高质量的长故事。

Conclusion: 通过引入多代理方法、记忆存储模型和故事主题障碍框架，本研究提出了一种改进的多阶段长故事生成方法，该方法能有效避免主题漂移、生成更吸引人的情节并确保内容的一致性和逻辑性。

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


### [145] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
*Junyao Yang,Jianwei Wang,Huiping Zhuang,Cen Chen,Ziqian Zeng*

Main category: cs.CL

TL;DR: RCP-Merging 是一种新的模型融合框架，用于融合长 CoT 模型和领域特定模型。它通过将推理模型权重视为先验，并使用推理能力指标来保留关键权重，从而解决了现有融合方法在推理能力下降方面的问题。实验证明，RCP-Merging 在 BioMedicine 和 Finance 领域显著提高了任务性能，同时保持了长 CoT 推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了在不产生大量计算和数据成本的情况下，创建同时具备长 CoT 能力和领域特定知识的双能力模型，模型融合是一种高效的方法。然而，将特定领域的 LLM 与长 CoT 的 LLM 进行融合面临严峻挑战，因为现有的融合方法会导致推理能力下降，甚至出现胡言乱语或输出崩溃。

Method: RCP-Merging 框架，通过将推理模型权重视为基础先验，利用推理能力指标来保留核心的长 CoT 能力模型权重，同时选择性地融合重要的领域特定权重。

Result: RCP-Merging 成功地将一个推理模型与特定领域的模型进行了融合，在 BioMedicine 和 Finance 领域将领域任务性能分别提高了 9.5% 和 9.2%，优于现有最先进方法，并且没有显著损害原始的长 CoT 推理能力。

Conclusion: RCP-Merging 成功地将具有长链式思考（CoT）能力的模型与特定领域的模型进行了融合，同时保留了模型在原始领域的性能，并在 BioMedicine 和 Finance 领域将领域任务性能相较于现有最先进方法分别提高了 9.5% 和 9.2%，且未显著损害原始的长 CoT 推理能力。

Abstract: Large Language Models (LLMs) with long chain-of-thought (CoT) capability,
termed Reasoning Models, demonstrate superior intricate problem-solving
abilities through multi-step long CoT reasoning. To create a dual-capability
model with long CoT capability and domain-specific knowledge without
substantial computational and data costs, model merging emerges as a highly
resource-efficient method. However, significant challenges lie in merging
domain-specific LLMs with long CoT ones since nowadays merging methods suffer
from reasoning capability degradation, even gibberish output and output
collapse. To overcome this, we introduce RCP-Merging: Merging Long
Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning
Capability as Prior, a novel merging framework designed to integrate
domain-specific LLMs with long CoT capability, meanwhile maintaining model
performance in the original domain. Treating reasoning model weights as
foundational prior, our method utilizes a reasoning capability indicator to
preserve core long CoT capability model weights while selectively merging
essential domain-specific weights. We conducted extensive experiments on
Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance
domains. Our results show that RCP-Merging successfully merges a reasoning
model with domain-specific ones, improving domain task performance by 9.5% and
9.2% over state-of-the-art methods, without significantly harming the original
long CoT reasoning capability.

</details>


### [146] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
*Chenyang Wang,Liang Wen,Shousheng Jia,Xiangzheng Zhang,Liang Xu*

Main category: cs.CL

TL;DR: 通过引入包含预览和自我检查的框架，结合Entropy-SFT和TEA-RL策略，有效解决了LLM在遵循复杂指令时的“懒惰推理”问题，并在实验中取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在数学、编码和谜题等任务上取得了进展，但它们在遵循复杂指令方面的能力仍不稳定，研究旨在找出主要原因并提出解决方案。

Method: 该研究提出了一种包含预览和自我检查的综合框架，通过过滤生成复杂指令的提示数据集，并采用熵保留监督微调（Entropy-SFT）和令牌级熵自适应（TEA-RL）强化学习策略，以解决LLM在遵循指令时出现的“懒惰推理”问题。

Result: 实验表明，该框架显著提高了LLM遵循指令的能力，尤其是在Light-IF-32B模型上，其性能超过了DeepSeek-R1和Doubao-1.6等模型。

Conclusion: 所提出的框架通过增强LLM的推理能力，特别是在遵循复杂指令方面，取得了显著的性能提升，其Light-IF-32B模型在多项基准测试中超越了现有模型。

Abstract: While advancements in the reasoning abilities of LLMs have significantly
enhanced their performance in solving mathematical problems, coding tasks, and
general puzzles, their effectiveness in accurately adhering to instructions
remains inconsistent, particularly with more complex directives. Our
investigation identifies lazy reasoning during the thinking stage as the
primary factor contributing to poor instruction adherence. To mitigate this
issue, we propose a comprehensive framework designed to enable rigorous
reasoning processes involving preview and self-checking, essential for
satisfying strict instruction constraints. Specifically, we first generate
instructions with complex constraints and apply a filtering process to obtain
valid prompts, resulting in three distinct prompt datasets categorized as hard,
easy, and pass. Then, we employ rejection sampling on the pass prompts to
curate a small yet high-quality dataset, enabling a cold-start initialization
of the model and facilitating its adaptation to effective reasoning patterns.
Subsequently, we employ an entropy-preserving supervised fine-tuning
(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)
reinforcement learning guided by rule-based dense rewards. This approach
encourages the model to transform its reasoning mechanism, ultimately fostering
generalizable reasoning abilities that encompass preview and self-checking.
Extensive experiments conducted on instruction-following benchmarks demonstrate
remarkable performance improvements across various model scales. Notably, our
Light-IF-32B model surpasses both larger open-source models such as DeepSeek-R1
and closed-source models like Doubao-1.6.

</details>


### [147] [Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification](https://arxiv.org/abs/2508.03181)
*Lukas Pätz,Moritz Beyer,Jannik Späth,Lasse Bohlen,Patrick Zschech,Mathias Kraus,Julian Rosenberger*

Main category: cs.CL

TL;DR: Analyzed 28,000 German parliamentary speeches using ML models to study topic and sentiment trends, finding that governing roles influence party communication styles.


<details>
  <summary>Details</summary>
Motivation: Investigate political discourse in the German Bundestag, focusing on topic trends, sentiment dynamics, and party-specific discourse strategies.

Method: Developed and trained two machine learning models (topic and sentiment classification) on ~28,000 German parliamentary speeches from the last five years, achieving AUROC scores of 0.94 for topic classification and 0.89 for sentiment classification.

Result: Identified remarkable relationships between parties and their parliamentary roles, noting a change in communication style for parties transitioning from government to opposition.

Conclusion: Governing responsibilities shape discourse, influencing parties' communication styles when moving between government and opposition, beyond just ideological positions.

Abstract: This study investigates political discourse in the German parliament, the
Bundestag, by analyzing approximately 28,000 parliamentary speeches from the
last five years. Two machine learning models for topic and sentiment
classification were developed and trained on a manually labeled dataset. The
models showed strong classification performance, achieving an area under the
receiver operating characteristic curve (AUROC) of 0.94 for topic
classification (average across topics) and 0.89 for sentiment classification.
Both models were applied to assess topic trends and sentiment distributions
across political parties and over time. The analysis reveals remarkable
relationships between parties and their role in parliament. In particular, a
change in style can be observed for parties moving from government to
opposition. While ideological positions matter, governing responsibilities also
shape discourse. The analysis directly addresses key questions about the
evolution of topics, sentiment dynamics, and party-specific discourse
strategies in the Bundestag.

</details>


### [148] [Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models](https://arxiv.org/abs/2508.03199)
*Muhammed Saeed,Shaina Raza,Ashmal Vayani,Muhammad Abdul-Mageed,Ali Emami,Shady Shehata*

Main category: cs.CL

TL;DR: 语言的语法性别会影响AI图像生成，阳性标记倾向于生成更多男性，阴性标记倾向于生成更多女性，这种效应在高资源语言中更明显。


<details>
  <summary>Details</summary>
Motivation: 研究文本到图像（T2I）模型中的偏见，主要集中在人口统计学代表性和刻板印象属性上，而忽略了一个基本问题：语法性别如何影响跨语言的视觉表征？

Method: 本研究引入了一个跨语言的基准测试，该测试检查了语法性别与刻板印象性别关联相矛盾的词语（例如，法语中的“une sentinelle”，语法上为阴性，但指代刻板印象上为男性的“守卫”）。该数据集涵盖了五种有语法性别语言（法语、西班牙语、德语、意大利语、俄语）和两种无语法性别对照语言（英语、中文），包含800个独特的提示，在三种最先进的文本到图像（T2I）模型上生成了28,800张图像。

Result: 语法性别极大地影响了图像生成：阳性语法标记平均会增加男性代表性至73%（相比之下，在无语法性别语言英语中为22%），而阴性语法标记会增加女性代表性至38%（相比之下，英语中为28%）。这些效应因语言资源可用性和模型架构而异，高资源语言表现出更强的效应。

Conclusion: 研究结果表明，语言结构本身（而非仅内容）会影响AI生成的视觉输出，为理解多语言、多模态系统中的偏见和公平性引入了一个新的维度。

Abstract: Research on bias in Text-to-Image (T2I) models has primarily focused on
demographic representation and stereotypical attributes, overlooking a
fundamental question: how does grammatical gender influence visual
representation across languages? We introduce a cross-linguistic benchmark
examining words where grammatical gender contradicts stereotypical gender
associations (e.g., ``une sentinelle'' - grammatically feminine in French but
referring to the stereotypically masculine concept ``guard''). Our dataset
spans five gendered languages (French, Spanish, German, Italian, Russian) and
two gender-neutral control languages (English, Chinese), comprising 800 unique
prompts that generated 28,800 images across three state-of-the-art T2I models.
Our analysis reveals that grammatical gender dramatically influences image
generation: masculine grammatical markers increase male representation to 73\%
on average (compared to 22\% with gender-neutral English), while feminine
grammatical markers increase female representation to 38\% (compared to 28\% in
English). These effects vary systematically by language resource availability
and model architecture, with high-resource languages showing stronger effects.
Our findings establish that language structure itself, not just content, shapes
AI-generated visual outputs, introducing a new dimension for understanding bias
and fairness in multilingual, multimodal systems.

</details>


### [149] [Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP](https://arxiv.org/abs/2508.03204)
*Abhirup Sinha,Pritilata Saha,Tithi Saha*

Main category: cs.CL

TL;DR: Data privacy is crucial for LLMs. This paper reviews methods to anonymize private info in text data for NLP tasks, even if full anonymization isn't achievable.


<details>
  <summary>Details</summary>
Motivation: Modern large language models require vast amounts of data that often contain private information, and research has shown that this information can be extracted from these models. Therefore, anonymizing private and sensitive information is crucial.

Method: The paper analyzes different pre-processing approaches for masking or pseudonymizing private information in textual data for domain-agnostic NLP tasks.

Result: The report discusses several pre-processing approaches for anonymizing private information in textual data for domain-agnostic NLP tasks.

Conclusion: The report focuses on domain-agnostic NLP tasks and discusses pre-processing approaches for masking or pseudonymizing private information in textual data, acknowledging that complete anonymization may not be possible.

Abstract: Privacy is a fundamental human right. Data privacy is protected by different
regulations, such as GDPR. However, modern large language models require a huge
amount of data to learn linguistic variations, and the data often contains
private information. Research has shown that it is possible to extract private
information from such language models. Thus, anonymizing such private and
sensitive information is of utmost importance. While complete anonymization may
not be possible, a number of different pre-processing approaches exist for
masking or pseudonymizing private information in textual data. This report
focuses on a few of such approaches for domain-agnostic NLP tasks.

</details>


### [150] [Probing Syntax in Large Language Models: Successes and Remaining Challenges](https://arxiv.org/abs/2508.03211)
*Pablo J. Diego-Simón,Emmanuel Chemla,Jean-Rémi King,Yair Lakretz*

Main category: cs.CL

TL;DR: 结构探针在LLM句法分析中存在偏差，易受词语邻近度和特定语言现象干扰，但不受词语可预测性影响。本研究提供了改进评估的基准。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前用于揭示LLM句法表征的结构探针在缺乏区分的句子集合上进行评估，导致不清楚句法和/或统计因素是否系统性地影响这些句法表征的问题。

Method: 本研究通过在三个受控基准上对结构探针进行深入分析，来评估句法结构探针在大型语言模型（LLMs）中的表现。

Result: 研究结果表明：1）结构探针存在表面特征偏差，倾向于将句子中邻近的词语视为句法相关；2）结构探针在处理语言学特征时遇到困难，对深层句法结构表征不足，并且易受交互名词或非语形动词形式的干扰；3）结构探针似乎不受单个词语可预测性的影响。

Conclusion: 本研究揭示了结构探针在评估LLM句法表征时面临的挑战，指出了其对词语邻近度和特定语言现象（如深层句法结构、名词交互、非语形动词形式）的敏感性，并发现其不受词语可预测性影响。研究提供了包含受控刺激的基准，以改进结构探针的评估。

Abstract: The syntactic structures of sentences can be readily read-out from the
activations of large language models (LLMs). However, the ``structural probes''
that have been developed to reveal this phenomenon are typically evaluated on
an indiscriminate set of sentences. Consequently, it remains unclear whether
structural and/or statistical factors systematically affect these syntactic
representations. To address this issue, we conduct an in-depth analysis of
structural probes on three controlled benchmarks. Our results are three-fold.
First, structural probes are biased by a superficial property: the closer two
words are in a sentence, the more likely structural probes will consider them
as syntactically linked. Second, structural probes are challenged by linguistic
properties: they poorly represent deep syntactic structures, and get interfered
by interacting nouns or ungrammatical verb forms. Third, structural probes do
not appear to be affected by the predictability of individual words. Overall,
this work sheds light on the current challenges faced by structural probes.
Providing a benchmark made of controlled stimuli to better evaluate their
performance.

</details>


### [151] [CardiffNLP at CLEARS-2025: Prompting Large Language Models for Plain Language and Easy-to-Read Text Rewriting](https://arxiv.org/abs/2508.03240)
*Mutaz Ayesh,Nicolás Gutiérrez-Rolón,Fernando Alva-Manchego*

Main category: cs.CL

TL;DR: CardiffNLP团队使用Gemma-3和LLM-prompting方法在CLEARS共享任务的两个子任务中分别获得第三名和第二名。


<details>
  <summary>Details</summary>
Motivation: 为了参加CLEARS共享任务，并在西班牙语文本适应方面进行研究和贡献。

Method: 采用LLM-prompting方法，并尝试了不同的prompt变体，最终使用Gemma-3模型进行提交。

Result: 在子任务1中获得第三名，在子任务2中获得第二名，并详细介绍了prompt变体、示例和实验结果。

Conclusion: CardiffNLP团队在CLEARS任务中取得成功，在两个子任务中分别获得第三名和第二名。

Abstract: This paper details the CardiffNLP team's contribution to the CLEARS shared
task on Spanish text adaptation, hosted by IberLEF 2025. The shared task
contained two subtasks and the team submitted to both. Our team took an
LLM-prompting approach with different prompt variations. While we initially
experimented with LLaMA-3.2, we adopted Gemma-3 for our final submission, and
landed third place in Subtask 1 and second place in Subtask 2. We detail our
numerous prompt variations, examples, and experimental results.

</details>


### [152] [Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs](https://arxiv.org/abs/2508.03247)
*Shintaro Sakai,Jisun An,Migyeong Kang,Haewoon Kwak*

Main category: cs.CL

TL;DR: 研究发现，大语言模型在处理心理健康信息时，未能成功复制东西方在抑郁症表现上的文化差异。模型在英语提示下的表现尤其不佳，即使在东方语言的提示下，也因对文化线索的敏感性低和固有的症状等级体系而效果有限。这表明当前通用大语言模型在心理健康应用方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 研究西方和东方个体抑郁症表现的文化差异，并测试日益应用于心理健康领域的大语言模型（LLMs）是否会复制这些模式。

Method: 通过向大语言模型提供西方或东方人物设定，并使用英语或主要的东方语言（中文、日文、印地语）进行提示，来测试其是否会复制抑郁症患者的心理症状（西方）或躯体症状（东方）的文化模式。

Result: 大语言模型在英语提示下基本未能复制这些文化模式，但在使用主要的东方语言（中文、日文、印地语）进行提示时，在某些配置下有所改善。模型未能复制这些模式的两个关键原因是：对文化人物设定的敏感性低，以及一种强大的、文化上不变的症状等级体系覆盖了文化线索。

Conclusion: 当前通用大语言模型缺乏安全有效应用于心理健康领域所需的、鲁棒的、具备文化意识的能力。

Abstract: Prior clinical psychology research shows that Western individuals with
depression tend to report psychological symptoms, while Eastern individuals
report somatic ones. We test whether Large Language Models (LLMs), which are
increasingly used in mental health, reproduce these cultural patterns by
prompting them with Western or Eastern personas. Results show that LLMs largely
fail to replicate the patterns when prompted in English, though prompting in
major Eastern languages (i.e., Chinese, Japanese, and Hindi) improves alignment
in several configurations. Our analysis pinpoints two key reasons for this
failure: the models' low sensitivity to cultural personas and a strong,
culturally invariant symptom hierarchy that overrides cultural cues. These
findings reveal that while prompt language is important, current
general-purpose LLMs lack the robust, culture-aware capabilities essential for
safe and effective mental health applications.

</details>


### [153] [RooseBERT: A New Deal For Political Language Modelling](https://arxiv.org/abs/2508.03250)
*Deborah Dore,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: RooseBERT是一个针对政治话语的新型语言模型，在政治辩论分析任务上表现优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 鉴于政治辩论和政治相关讨论的增多，需要新的计算方法来自动分析这些内容，以帮助公民更好地理解政治。然而，政治语言的特殊性和辩论的说服形式（包括隐藏的沟通策略和隐含的论点）给现有通用预训练语言模型带来了挑战。

Method: 提出了一种名为RooseBERT的新型预训练语言模型，该模型专门针对政治话语语言进行训练，使用了8000个包含多个子主题辩论的英语政治辩论和演讲语料库。

Result: RooseBERT在政治辩论分析的四个下游任务上取得了显著的性能提升，证明了领域特定预训练的有效性。

Conclusion: 通过在大型政治辩论和演讲语料库上进行预训练，RooseBERT在政治话语语言分析的四个下游任务（命名实体识别、情感分析、论证组件检测和分类以及论证关系预测和分类）上显著优于通用语言模型，证明了领域特定预训练可以提高政治辩论分析的性能。

Abstract: The increasing amount of political debates and politics-related discussions
calls for the definition of novel computational methods to automatically
analyse such content with the final goal of lightening up political
deliberation to citizens. However, the specificity of the political language
and the argumentative form of these debates (employing hidden communication
strategies and leveraging implicit arguments) make this task very challenging,
even for current general-purpose pre-trained Language Models. To address this
issue, we introduce a novel pre-trained Language Model for political discourse
language called RooseBERT. Pre-training a language model on a specialised
domain presents different technical and linguistic challenges, requiring
extensive computational resources and large-scale data. RooseBERT has been
trained on large political debate and speech corpora (8K debates, each composed
of several sub-debates on different topics) in English. To evaluate its
performances, we fine-tuned it on four downstream tasks related to political
debate analysis, i.e., named entity recognition, sentiment analysis, argument
component detection and classification, and argument relation prediction and
classification. Our results demonstrate significant improvements over
general-purpose Language Models on these four tasks, highlighting how
domain-specific pre-training enhances performance in political debate analysis.
We release the RooseBERT language model for the research community.

</details>


### [154] [Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition](https://arxiv.org/abs/2508.03259)
*Duzhen Zhang,Chenxing Li,Jiahua Dong,Qi Liu,Dong Yu*

Main category: cs.CL

TL;DR: SPT方法通过合并表示维度和动态融合权重来解决CNER中的稳定性-可塑性权衡问题，并引入了一种处理非实体类型语义偏移的伪标签方法。


<details>
  <summary>Details</summary>
Motivation: 以前的CNER方法主要利用知识蒸馏（KD）来保存先验知识和克服灾难性遗忘，严格确保新旧模型的表示保持一致。因此，它们通常会给模型带来过度的稳定性（即保留旧知识），但可塑性有限（即获取新知识）。

Method: 提出了一种稳定性-可塑性权衡（SPT）方法，从表示和权重两个角度来平衡这两个方面。在表示方面，我们在原始KD中引入了一个池化操作，通过合并表示维度来允许一定程度的可塑性。在权重方面，我们动态地合并了旧模型和新模型的权重，在保持新知识的同时加强了旧知识。在此融合过程中，我们实施了一种权重引导的选择机制来优先处理重要的权重。此外，我们开发了一种基于置信度的伪标签方法来处理当前非实体类型的语义偏移，这是一种CNER特有的、以前的方法在很大程度上忽略的挑战。

Result: SPT方法超越了以前的CNER方法，证明了其在实现合适的稳定-可塑性权衡方面的有效性。

Conclusion: 我们提出的SPT方法在跨10个CNER设置和3个基准数据集的广泛实验中，超越了以前的CNER方法，证明了其在实现合适的稳定-可塑性权衡方面的有效性。

Abstract: Continual Named Entity Recognition (CNER) is an evolving field that focuses
on sequentially updating an existing model to incorporate new entity types.
Previous CNER methods primarily utilize Knowledge Distillation (KD) to preserve
prior knowledge and overcome catastrophic forgetting, strictly ensuring that
the representations of old and new models remain consistent. Consequently, they
often impart the model with excessive stability (i.e., retention of old
knowledge) but limited plasticity (i.e., acquisition of new knowledge). To
address this issue, we propose a Stability-Plasticity Trade-off (SPT) method
for CNER that balances these aspects from both representation and weight
perspectives. From the representation perspective, we introduce a pooling
operation into the original KD, permitting a level of plasticity by
consolidating representation dimensions. From the weight perspective, we
dynamically merge the weights of old and new models, strengthening old
knowledge while maintaining new knowledge. During this fusion, we implement a
weight-guided selective mechanism to prioritize significant weights. Moreover,
we develop a confidence-based pseudo-labeling approach for the current
non-entity type, which predicts entity types using the old model to handle the
semantic shift of the non-entity type, a challenge specific to CNER that has
largely been ignored by previous methods. Extensive experiments across ten CNER
settings on three benchmark datasets demonstrate that our SPT method surpasses
previous CNER approaches, highlighting its effectiveness in achieving a
suitable stability-plasticity trade-off.

</details>


### [155] [Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?](https://arxiv.org/abs/2508.03262)
*Junhyuk Choi,Hyeonchu Park,Haemin Lee,Hyebeen Shin,Hyun Joung Jin,Bugeun Kim*

Main category: cs.CL

TL;DR: LLM在模拟个体经济行为方面能力有限，但能合理模拟群体行为。


<details>
  <summary>Details</summary>
Motivation: 大多数关于LLM模拟人类行为的研究依赖于虚构的Persona，本研究旨在解决这一局限性，使用真实人类数据评估LLM预测个体经济决策的能力。

Method: 通过对522名韩国参与者在使用‘随心付’定价的文化消费场景中的详细个人信息进行分析，系统性地比较了三种最先进的多模态LLM在预测个体经济决策方面的能力，并研究了注入个人信息的方法对预测性能的影响。

Result: LLM在精确预测个体层面经济决策方面表现不佳，但在模拟群体行为趋势方面展现出合理性。研究还发现，常用的提示技术（如个人叙事重构和检索增强生成）相比简单的提示方法，在预测性能上没有带来显著提升。

Conclusion: LLM在预测个体经济决策方面存在挑战，但在模拟群体行为趋势方面表现合理。常用的提示技术（如个人叙事重构或检索增强生成）相比简单提示方法没有显著优势。

Abstract: Recent advances in Large Language Models (LLMs) have generated significant
interest in their capacity to simulate human-like behaviors, yet most studies
rely on fictional personas rather than actual human data. We address this
limitation by evaluating LLMs' ability to predict individual economic
decision-making using Pay-What-You-Want (PWYW) pricing experiments with real
522 human personas. Our study systematically compares three state-of-the-art
multimodal LLMs using detailed persona information from 522 Korean participants
in cultural consumption scenarios. We investigate whether LLMs can accurately
replicate individual human choices and how persona injection methods affect
prediction performance. Results reveal that while LLMs struggle with precise
individual-level predictions, they demonstrate reasonable group-level
behavioral tendencies. Also, we found that commonly adopted prompting
techniques are not much better than naive prompting methods; reconstruction of
personal narrative nor retrieval augmented generation have no significant gain
against simple prompting method. We believe that these findings can provide the
first comprehensive evaluation of LLMs' capabilities on simulating economic
behavior using real human data, offering empirical guidance for persona-based
simulation in computational social science.

</details>


### [156] [LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning](https://arxiv.org/abs/2508.03275)
*Jiahao Zhao*

Main category: cs.CL

TL;DR: LECTOR is an LLM-enhanced spaced repetition algorithm that improves learning by considering semantic similarity and personalized profiles, outperforming existing methods in test-oriented scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing spaced repetition algorithms struggle with semantic interference and personalized adaptation, especially in test-oriented learning scenarios like language examinations.

Method: LECTOR leverages large language models for semantic analysis and incorporates personalized learning profiles, using LLM-powered semantic similarity assessment combined with spaced repetition principles to address semantic confusion.

Result: LECTOR achieves a 90.2% success rate, a 2.0% relative improvement over the best baseline (SSP-MMC), demonstrating significant improvements in reducing confusion-induced errors while maintaining computational efficiency.

Conclusion: LECTOR is a promising direction for intelligent tutoring systems and adaptive learning platforms.

Abstract: Spaced repetition systems are fundamental to efficient learning and memory
retention, but existing algorithms often struggle with semantic interference
and personalized adaptation. We present LECTOR (\textbf{L}LM-\textbf{E}nhanced
\textbf{C}oncept-based \textbf{T}est-\textbf{O}riented \textbf{R}epetition), a
novel adaptive scheduling algorithm specifically designed for test-oriented
learning scenarios, particularly language examinations where success rate is
paramount. LECTOR leverages large language models for semantic analysis while
incorporating personalized learning profiles, addressing the critical challenge
of semantic confusion in vocabulary learning by utilizing LLM-powered semantic
similarity assessment and integrating it with established spaced repetition
principles. Our comprehensive evaluation against six baseline algorithms
(SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over
100 days demonstrates significant improvements: LECTOR achieves a 90.2\%
success rate compared to 88.4\% for the best baseline (SSP-MMC), representing a
2.0\% relative improvement. The algorithm shows particular strength in handling
semantically similar concepts, reducing confusion-induced errors while
maintaining computational efficiency. Our results establish LECTOR as a
promising direction for intelligent tutoring systems and adaptive learning
platforms.

</details>


### [157] [Do language models accommodate their users? A study of linguistic convergence](https://arxiv.org/abs/2508.03276)
*Terra Blevins,Susanne Schmalwieser,Benjamin Roth*

Main category: cs.CL

TL;DR: 大型语言模型在对话中会模仿用户的语言风格，但模仿方式与人类不同，可能存在过度拟合现象。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在多大程度上模仿人类的语言使用方式，特别是它们是否会像人类一样适应用户在对话中使用的语言模式。

Method: 通过在三种对话语料库和十六个语言模型上，比较模型补全与原始人类回应在多种风格统计特征上的差异，来系统性地测试语言趋同现象。

Result: 模型强烈趋同于对话的语言风格，并且在许多情况下存在过度拟合现象。不过，模型趋同的模式因具体特征而异，并且指令微调和更大规模的模型比预训练模型趋同得更少。

Conclusion: 模型表现出语言趋同现象，但与人类的趋同模式存在差异，表明其潜在机制可能不同。

Abstract: While large language models (LLMs) are generally considered proficient in
generating language, how similar their language usage is to that of humans
remains understudied. In this paper, we test whether models exhibit linguistic
convergence, a core pragmatic element of human language communication, asking:
do models adapt, or converge, to the linguistic patterns of their user? To
answer this, we systematically compare model completions of exisiting dialogues
to the original human responses across sixteen language models, three dialogue
corpora, and a variety of stylometric features. We find that models strongly
converge to the conversation's style, often significantly overfitting relative
to the human baseline. While convergence patterns are often feature-specific,
we observe consistent shifts in convergence across modeling settings, with
instruction-tuned and larger models converging less than their pretrained
counterparts. Given the differences between human and model convergence
patterns, we hypothesize that the underlying mechanisms for these behaviors are
very different.

</details>


### [158] [Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes](https://arxiv.org/abs/2508.03292)
*Shahed Masoudian,Gustavo Escobedo,Hannah Strauss,Markus Schedl*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As Large Language Models (LLMs) are increasingly used across different
applications, concerns about their potential to amplify gender biases in
various tasks are rising. Prior research has often probed gender bias using
explicit gender cues as counterfactual, or studied them in sentence completion
and short question answering tasks. These formats might overlook more implicit
forms of bias embedded in generative behavior of longer content. In this work,
we investigate gender bias in LLMs using gender stereotypes studied in
psychology (e.g., aggressiveness or gossiping) in an open-ended task of
narrative generation. We introduce a novel dataset called StereoBias-Stories
containing short stories either unconditioned or conditioned on (one, two, or
six) random attributes from 25 psychological stereotypes and three task-related
story endings. We analyze how the gender contribution in the overall story
changes in response to these attributes and present three key findings: (1)
While models, on average, are highly biased towards male in unconditioned
prompts, conditioning on attributes independent from gender stereotypes
mitigates this bias. (2) Combining multiple attributes associated with the same
gender stereotype intensifies model behavior, with male ones amplifying bias
and female ones alleviating it. (3) Model biases align with psychological
ground-truth used for categorization, and alignment strength increases with
model size. Together, these insights highlight the importance of
psychology-grounded evaluation of LLMs.

</details>


### [159] [NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty](https://arxiv.org/abs/2508.03294)
*Leonidas Zotos,Ivo Pascal de Jong,Matias Valdenegro-Toro,Andreea Ioana Sburlea,Malvina Nissim,Hedderik van Rijn*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在估计考试题目难度方面优于教授，特别是利用LLM的不确定性进行监督学习的方法效果更佳，有助于提高考试质量。


<details>
  <summary>Details</summary>
Motivation: 估计考试题目的难度对于制定好的考试至关重要，但教授在这项任务上并不总是擅长。

Method: 比较了各种基于大型语言模型（LLM）的方法与三位教授在估计学生答对是非题比例方面的能力，特别是在神经网络和机器学习领域。结果表明，直接要求Gemini 2.5解决此任务优于教授，而使用LLM解决问题的梯度不确定性在监督学习设置下（仅使用42个训练样本）取得了更好的结果。

Result: 教授区分简单和困难问题的能力有限，并且他们的表现不如直接要求Gemini 2.5解决此任务。使用LLM不确定性的监督学习方法取得了更好的结果。

Conclusion: 监督学习结合大型语言模型（LLM）的不确定性可以帮助教授更好地估计考试题目的难度，从而提高评估质量。

Abstract: Estimating the difficulty of exam questions is essential for developing good
exams, but professors are not always good at this task. We compare various
Large Language Model-based methods with three professors in their ability to
estimate what percentage of students will give correct answers on True/False
exam questions in the areas of Neural Networks and Machine Learning. Our
results show that the professors have limited ability to distinguish between
easy and difficult questions and that they are outperformed by directly asking
Gemini 2.5 to solve this task. Yet, we obtained even better results using
uncertainties of the LLMs solving the questions in a supervised learning
setting, using only 42 training samples. We conclude that supervised learning
using LLM uncertainty can help professors better estimate the difficulty of
exam questions, improving the quality of assessment.

</details>


### [160] [Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling](https://arxiv.org/abs/2508.03296)
*Anqi Li,Wenwei Jin,Jintao Tong,Pengda Qin,Weijia Li,Guo Lu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Social platforms have revolutionized information sharing, but also
accelerated the dissemination of harmful and policy-violating content. To
ensure safety and compliance at scale, moderation systems must go beyond
efficiency and offer accuracy and interpretability. However, current approaches
largely rely on noisy, label-driven learning, lacking alignment with moderation
rules and producing opaque decisions that hinder human review. Therefore, we
propose Hierarchical Guard (Hi-Guard), a multimodal moderation framework that
introduces a new policy-aligned decision paradigm. The term "Hierarchical"
reflects two key aspects of our system design: (1) a hierarchical moderation
pipeline, where a lightweight binary model first filters safe content and a
stronger model handles fine-grained risk classification; and (2) a hierarchical
taxonomy in the second stage, where the model performs path-based
classification over a hierarchical taxonomy ranging from coarse to fine-grained
levels. To ensure alignment with evolving moderation policies, Hi-Guard
directly incorporates rule definitions into the model prompt. To further
enhance structured prediction and reasoning, we introduce a multi-level
soft-margin reward and optimize with Group Relative Policy Optimization (GRPO),
penalizing semantically adjacent misclassifications and improving explanation
quality. Extensive experiments and real-world deployment demonstrate that
Hi-Guard achieves superior classification accuracy, generalization, and
interpretability, paving the way toward scalable, transparent, and trustworthy
content safety systems. Code is available at:
https://github.com/lianqi1008/Hi-Guard.

</details>


### [161] [CTTS: Collective Test-Time Scaling](https://arxiv.org/abs/2508.03333)
*Zhende Song,Shengji Tang,Peng Ye,Jiayuan Fan,Tao Chen*

Main category: cs.CL

TL;DR: 本文提出CTTS-MM框架，通过多智能体协作搜索（ACS）和多奖励模型混合（MoR）来提升LLM推理能力，并在多个基准测试中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数方法（例如，Best-of-N和Self-Consistency）依赖于单一智能体与奖励模型（SA-SR）的交互，受到单一测试时间缩放（STTS）范例的有限能力的限制。而最近的研究表明，集体智能体方法可以通过编排不同的模型来突破单智能体系统的上限。因此，本文旨在探索集体测试时间缩放（CTTS）。

Method: 本文提出了一种名为CTTS-MM的新颖框架，该框架有效地利用了多智能体和多奖励模型协作以增强推理能力。具体而言，对于多智能体协作，提出了智能体协作搜索（ACS），用于从大型候选池中搜索最有效的LLM智能体组合；对于多奖励模型协作，提出了奖励模型混合（MoR），包括一个精选的问题池和奖励模型集成选择（PRES），通过成对奖励排序（PRR）指标选择最优奖励模型组合。

Result: 实验证明，MA-MR（多智能体对多奖励模型）在CTTS的三个主要范例中始终 achieves the best performance。

Conclusion: CTTS-MM框架在七个主流基准测试中展现出持续优越的性能。

Abstract: Test-time scaling (TTS) has emerged as a promising research field for
enhancing the effectiveness of large language models (LLMs) without extra
training. However, most existing approaches, e.g., Best-of-N and
Self-Consistency rely on a single agent interacting with a reward model
(SA-SR), constrained by limited capabilities of a single test-time scaling
(STTS) paradigm. On the other hand, recent works demonstrate that
collective-agent methods can break through the upper bound of single-agent
systems by orchestrating diverse models. Thus, in this paper, we take a first
step towards exploring Collective Test-Time Scaling (CTTS). Consider the
different interaction types of single and multiple models, we design three
primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent
to multiple reward models (SA-MR); (2) multiple agents to single reward model
(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive
experiments demonstrate that MA-MR consistently achieves the best performance.
Based on this, we propose a novel framework named CTTS-MM that effectively
leverages both multi-agent and multi-reward-model collaboration for enhanced
inference. Specifically, for multi-agent collaboration, we propose an Agent
Collaboration Search (ACS), which searches for the most effective combination
of LLM agents from a large candidate pool; for multi-reward-model
collaboration, we propose Mixture of Reword Models (MoR), which consists of a
curated question pool and a Prior Reward model Ensemble Selection (PRES) to
select the optimal combinations of reward models via Pair-wise Reward Ranking
(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that
the proposed CTTS-MM consistently obtains superior performance. Code will be
released at https://github.com/magent4aci/CTTS-MM.

</details>


### [162] [Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature](https://arxiv.org/abs/2508.03358)
*Tiago G Canário,Catarina Duarte,Flávio L. Pinheiro,João L. M. Pereira*

Main category: cs.CL

TL;DR: Taggus是一个用于从葡萄牙语文学作品中提取角色社交网络的NLP管线，通过结合词性标注和启发式方法，在角色识别和交互检测方面取得了优于现有最先进工具的成果。


<details>
  <summary>Details</summary>
Motivation: 自动识别虚构作品中的角色及其交互是一项复杂的任务，而现有方法在代表性不足的语言上表现不佳，因为缺乏手动标注数据进行训练。

Method: 提出了一种名为Taggus的管线，该管线使用词性标注（POS tagging）和一系列启发式方法来从葡萄牙语文学作品中提取角色社交网络。

Result: 与现成的最先进工具（如NER工具和ChatGPT）相比，Taggus管线在识别字符和解决共指问题方面平均提高了50.7%（F1分数为94.1%），在交互检测方面平均提高了22.3%（F1分数为75.9%）。

Conclusion: Taggus管线在识别字符和检测交互方面取得了令人满意的结果，平均F1分数分别为94.1%和75.9%，优于现成的最先进工具。

Abstract: Automatically identifying characters and their interactions from fiction
books is, arguably, a complex task that requires pipelines that leverage
multiple Natural Language Processing (NLP) methods, such as Named Entity
Recognition (NER) and Part-of-speech (POS) tagging. However, these methods are
not optimized for the task that leads to the construction of Social Networks of
Characters. Indeed, the currently available methods tend to underperform,
especially in less-represented languages, due to a lack of manually annotated
data for training. Here, we propose a pipeline, which we call Taggus, to
extract social networks from literary fiction works in Portuguese. Our results
show that compared to readily available State-of-the-Art tools -- off-the-shelf
NER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which
uses POS tagging and a combination of heuristics, achieves satisfying results
with an average F1-Score of $94.1\%$ in the task of identifying characters and
solving for co-reference and $75.9\%$ in interaction detection. These
represent, respectively, an increase of $50.7\%$ and $22.3\%$ on results
achieved by the readily available State-of-the-Art tools. Further steps to
improve results are outlined, such as solutions for detecting relationships
between characters. Limitations on the size and scope of our testing samples
are acknowledged. The Taggus pipeline is publicly available to encourage
development in this field for the Portuguese language.2

</details>


### [163] [Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models](https://arxiv.org/abs/2508.03363)
*Haotian Wu,Bo Xu,Yao Shu,Menglin Yang,Chengwei Qin*

Main category: cs.CL

TL;DR: JointThinking improves RLLM reasoning by comparing 'Thinking' and 'Nothinking' answers, re-reasoning only when they differ, with minimal latency. It boosts accuracy, especially on unseen tasks, and scales well with model size.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of in-context learning (ICL) for Reasoning Large Language Models (RLLMs) by leveraging the structured difference between Thinking and Nothinking reasoning modes to improve reasoning accuracy.

Method: JointThinking prompts the model to generate two answers in parallel (Thinking and Nothinking modes). A second round of Thinking is triggered only when the two responses are inconsistent, using a prompt incorporating the original question and both candidate answers.

Result: JointThinking significantly outperforms few-shot chain-of-thought (CoT) and majority voting with improved answer robustness. It achieves comparable in-distribution performance to training-based SOTA methods while substantially outperforming on out-of-distribution tasks. The error rate is consistently lowered, and the approach shows strong scalability with model size.

Conclusion: JointThinking leverages the structured difference between Thinking and Nothinking reasoning modes to improve accuracy, outperforms few-shot CoT and majority voting, achieves comparable in-distribution performance to SOTA training-based methods and substantially outperforms on out-of-distribution tasks. The calibration mechanism consistently lowers the error rate and shows strong scalability with model size.

Abstract: Reasoning large language models (RLLMs) have recently demonstrated remarkable
capabilities through structured and multi-step reasoning. While prior research
has primarily focused on improving their training and inference strategies,
their potential for in-context learning (ICL) remains largely underexplored. To
fill this gap, we propose Thinking with Nothinking Calibration (JointThinking),
a new ICL paradigm that leverages the structured difference between two
reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.
Specifically, our method prompts the model to generate two answers in parallel:
one in Thinking mode and the other in Nothinking mode. A second round of
Thinking is triggered only when the two initial responses are inconsistent,
using a single prompt that incorporates the original question and both
candidate answers. Since such disagreement occurs infrequently (e.g., only 6\%
in GSM8K), our method performs just one round of reasoning in most cases,
resulting in minimal latency overhead. Extensive experiments across multiple
reasoning benchmarks demonstrate that JointThinking significantly outperforms
few-shot chain-of-thought (CoT) and majority voting with improved answer
robustness. Moreover, It achieves comparable in-distribution performance to
training-based SOTA method, while substantially outperforming on
out-of-distribution tasks. We further conduct a systematic analysis of the
calibration mechanism, showing that leveraging different reasoning modes
consistently lowers the error rate and highlights the value of structural
thinking diversity. Additionally, we observe that the performance gap between
actual and ideal reasoning narrows as model size increases in the second round
of thinking, indicating the strong scalability of our approach. Finally, we
discuss current limitations and outline promising directions for future ICL
research in RLLMs.

</details>


### [164] [ReDSM5: A Reddit Dataset for DSM-5 Depression Detection](https://arxiv.org/abs/2508.03399)
*Eliseo Bao,Anxo Pérez,Javier Parapar*

Main category: cs.CL

TL;DR: 本研究提出了ReDSM5语料库，它在Reddit帖子中对抑郁症的DSM-5症状进行了详细标注，解决了现有方法的局限性，并为开发更具可解释性的抑郁症检测模型铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 许多抑郁症病例因传统临床途径的障碍和普遍存在的污名而未能得到诊断。社交媒体平台（尤其是Reddit）提供了丰富的用户生成叙述，可以揭示抑郁症状的早期迹象。然而，现有的计算方法通常将整个帖子简单地标记为“抑郁”或“非抑郁”，而没有将语言与DSM-5的具体标准联系起来，这限制了临床相关性和可解释性。

Method: 本研究引入了一个名为ReDSM5的新型Reddit语料库，包含1484篇长文帖子，由一位持证心理学家在句子层面详细标注了九项DSM-5抑郁症状及其临床理由。研究还对该语料库进行了探索性分析，考察了词汇、句法和情感模式，并建立了多标签症状分类和解释生成的基础基准。

Result: ReDSM5语料库独特的结合了特定症状的监督和专家解释，有助于开发能够检测抑郁症并生成人类可解释推理的模型。研究还建立了多标签症状分类和解释生成的基准测试，为未来的检测和可解释性研究提供了参考结果。

Conclusion: 本研究通过引入ReDSM5语料库，解决了现有计算方法在识别抑郁症时未能关联DSM-5诊断标准的问题，并为基于社交媒体数据的抑郁症检测和可解释性研究奠定了基础。

Abstract: Depression is a pervasive mental health condition that affects hundreds of
millions of individuals worldwide, yet many cases remain undiagnosed due to
barriers in traditional clinical access and pervasive stigma. Social media
platforms, and Reddit in particular, offer rich, user-generated narratives that
can reveal early signs of depressive symptomatology. However, existing
computational approaches often label entire posts simply as depressed or not
depressed, without linking language to specific criteria from the DSM-5, the
standard clinical framework for diagnosing depression. This limits both
clinical relevance and interpretability. To address this gap, we introduce
ReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each
exhaustively annotated at the sentence level by a licensed psychologist for the
nine DSM-5 depression symptoms. For each label, the annotator also provides a
concise clinical rationale grounded in DSM-5 methodology. We conduct an
exploratory analysis of the collection, examining lexical, syntactic, and
emotional patterns that characterize symptom expression in social media
narratives. Compared to prior resources, ReDSM5 uniquely combines
symptom-specific supervision with expert explanations, facilitating the
development of models that not only detect depression but also generate
human-interpretable reasoning. We establish baseline benchmarks for both
multi-label symptom classification and explanation generation, providing
reference results for future research on detection and interpretability.

</details>


### [165] [LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models](https://arxiv.org/abs/2508.03440)
*Junhong Wu,Jinliang Lu,Zixuan Ren,Ganqiang Hu,Zhi Wu,Dai Dai,Hua Wu*

Main category: cs.CL

TL;DR: LLMs的软性思考能力受限于贪婪解码。通过引入Gumbel-Softmax技巧等随机性方法可以提高其在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型依赖生成离散标记，可能限制其表达能力。本研究旨在探索LLMs生成软标记以在连续概念空间中进行推理的能力。

Method: 通过一系列探测技术，检查了LLMs（大型语言模型）的内部行为，以探索其‘软性思考’能力。

Result: 研究发现，LLMs主要依赖软输入中最具影响力的部分进行解码，这阻碍了不同推理路径的探索，并将软性思考简化为一种贪婪解码。

Conclusion: LLMs主要依赖软输入中最具影响力的部分进行解码，这阻碍了不同推理路径的探索，并将软性思考简化为一种贪婪解码。通过引入随机性（如Dirichlet重采样和Gumbel-Softmax技巧）可以缓解这些限制。Gumbel-Softmax技巧通过可控的平滑度提供了足够的随机性，在八个推理基准测试中表现优越。

Abstract: Human cognition naturally engages with abstract and fluid concepts, whereas
existing reasoning models often rely on generating discrete tokens, potentially
constraining their expressive capabilities. Recent advancements aim to address
this limitation by enabling large language models (LLMs) to generate soft,
abstract tokens, thus facilitating reasoning within a continuous concept space.
This paper explores the `Soft Thinking' capabilities of various LLMs by
examining the models' internal behavior using a suite of probing techniques.
Contrary to the common belief that Soft Thinking enables the simultaneous
exploration of diverse reasoning paths, our findings reveal that LLMs
predominantly rely on the most influential component of the soft inputs during
subsequent decoding steps. This reliance hinders the exploration of different
reasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,
obscuring the advantage of transmitting more information through Soft Tokens.
To tackle this issue, we explore sampling strategies to introduce
\emph{randomness}, employing methods such as Dirichlet resampling and the
Gumbel-Softmax trick. Our experiments demonstrate that incorporating randomness
can alleviate the limitations of vanilla approaches and unleash the potential
of Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate
randomness with controlled smoothness, resulting in superior performance across
eight reasoning benchmarks.

</details>


### [166] [Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings](https://arxiv.org/abs/2508.03453)
*Rita González-Márquez,Philipp Berens,Dmitry Kobak*

Main category: cs.CL

TL;DR: 通过比较文本嵌入的两种自监督学习方法（裁剪 vs Dropout），发现裁剪方法效果更好。自监督学习在领域内数据上表现优异，微调最后几层即可获得高分嵌入。


<details>
  <summary>Details</summary>
Motivation: 旨在探索自监督学习在文本嵌入生成中的应用，借鉴计算机视觉领域成功的经验，以提高文本嵌入的质量和效率，特别是在领域内数据的应用。

Method: 本文系统地比较了文本嵌入对比学习中两种最著名的正样本对生成策略：基于裁剪和基于 Dropout 的数据增强。通过在 MTEB 和额外的领域内评估中评估嵌入质量，来比较这两种方法的有效性。

Result: 裁剪增强策略显著优于 Dropout 方法。在领域外数据上，自监督学习产生的嵌入质量低于监督 SOTA 模型；但在领域内数据上，自监督微调（尤其是在最后几层）可以在很短的时间内获得高质量的文本嵌入，效果接近于监督 SOTA 模型。

Conclusion: 研究结果表明，在文本嵌入的对比学习中，基于裁剪的数据增强策略优于基于 Dropout 的方法。在领域外数据上，嵌入质量略低于监督学习的 SOTA 模型；但在领域内数据上，通过短时自监督微调可获得高质量文本嵌入，效果与监督 SOTA 模型相近。此外，模型表示质量随 Transformer 层数增加而提高，且仅微调最后几层即可达到相似的嵌入质量。

Abstract: Text embeddings, i.e. vector representations of entire texts, play an
important role in many NLP applications, such as retrieval-augmented
generation, sentiment analysis, clustering, or visualizing collections of texts
for data exploration. Currently, top-performing embedding models are derived
from pre-trained language models via extensive supervised fine-tuning using
curated text pairs. This contrasts with computer vision, where self-supervised
training based on data augmentations has demonstrated remarkable success. Here
we systematically compare the two most well-known augmentation strategies for
positive pair generation in contrastive learning of text embeddings. We assess
embedding quality on MTEB and additional in-domain evaluations and show that
cropping augmentation strongly outperforms the dropout-based approach. We find
that on out-of-domain data, the quality of resulting embeddings is below the
supervised SOTA models, but for in-domain data, self-supervised fine-tuning
produces high-quality text embeddings after very short fine-tuning, sometimes
only marginally below the supervised SOTA. Finally, we show that representation
quality increases towards the last transformer layers, which undergo the
largest change during fine-tuning; and that fine-tuning only those last layers
is sufficient to reach similar embedding quality.

</details>


### [167] [fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval](https://arxiv.org/abs/2508.03475)
*Pranshu Rastogi*

Main category: cs.CL

TL;DR: 使用針對句子相似性優化的雙編碼器模型，在 Kaggle T4 GPU 上訓練，該方法在 SemEval-2025 任務 7 中實現了高效的多語言和跨語言事實核查聲明檢索。


<details>
  <summary>Details</summary>
Motivation: SemEval-2025 任務 7 的目標是實現多語言和跨語言的事實核查聲明檢索。

Method: 該方法將多語言和跨語言的事實核查聲明檢索作為一個學習排序任務來處理，使用雙編碼器模型，該模型是從針對句子相似性優化的預訓練變壓器進行微調的。

Result: 使用參數少於 500M 的輕量級模型並在 Kaggle T4 GPU 上進行訓練，該方法在多語言檢索中取得了 92% 的 Success@10，在跨語言檢索中取得了 80% 的 Success@10，在跨語言和多語言的排名中分別為第五和第十名。

Conclusion: 該方法在多語言檢索中達到 92% 的 Success@10，在跨語言檢索中達到 80% 的 Success@10，在跨語言和多語言排行榜中分別排名第五和第十。

Abstract: SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim
Retrieval is approached as a Learning-to-Rank task using a bi-encoder model
fine-tuned from a pre-trained transformer optimized for sentence similarity.
Training used both the source languages and their English translations for
multilingual retrieval and only English translations for cross-lingual
retrieval. Using lightweight models with fewer than 500M parameters and
training on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual
and 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.

</details>


### [168] [CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03489)
*Kaiwen Zhao,Bharathan Balaji,Stephen Lee*

Main category: cs.CL

TL;DR: 本研究提出了一种名为CarbonPDF的新技术，并通过微调Llama 3模型来解决产品可持续性报告中碳足迹问题的问答。该技术在处理非结构化和不一致的PDF数据方面表现出色，并且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对产品可持续性报告（通常以PDF格式提供）中数据非结构化和不一致的问题，以及现有方法在处理从PDF解析中提取的非结构化和不一致的文本时遇到的困难，旨在提高对碳足迹相关问题的回答准确性。

Method: 提出了一种名为CarbonPDF的基于LLM的技术，通过使用包含1735份产品报告文档的问答对的开源数据集CarbonPDF-QA对Llama 3模型进行微调，以解决从PDF文档中提取和解释相关信息（特别是碳足迹）的挑战。

Result: 所提出的CarbonPDF技术在处理数据不一致方面优于GPT-4o，并且在回答碳足迹问题方面超越了在表格和文本数据上进行微调的现有先进技术。

Conclusion: 所提出的CarbonPDF技术通过微调Llama 3模型，在回答碳足迹问题方面优于现有的先进技术，包括在表格和文本数据上进行微调的问答系统。

Abstract: Product sustainability reports provide valuable insights into the
environmental impacts of a product and are often distributed in PDF format.
These reports often include a combination of tables and text, which complicates
their analysis. The lack of standardization and the variability in reporting
formats further exacerbate the difficulty of extracting and interpreting
relevant information from large volumes of documents. In this paper, we tackle
the challenge of answering questions related to carbon footprints within
sustainability reports available in PDF format. Unlike previous approaches, our
focus is on addressing the difficulties posed by the unstructured and
inconsistent nature of text extracted from PDF parsing. To facilitate this
analysis, we introduce CarbonPDF-QA, an open-source dataset containing
question-answer pairs for 1735 product report documents, along with
human-annotated answers. Our analysis shows that GPT-4o struggles to answer
questions with data inconsistencies. To address this limitation, we propose
CarbonPDF, an LLM-based technique specifically designed to answer carbon
footprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama
3 with our training data. Our results show that our technique outperforms
current state-of-the-art techniques, including question-answering (QA) systems
finetuned on table and text data.

</details>


### [169] [UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust Empathy Regression](https://arxiv.org/abs/2508.03520)
*Md Rakibul Hasan,Md Zakir Hossain,Aneesh Krishna,Shafin Rahman,Tom Gedeon*

Main category: cs.CL

TL;DR: UPLME是一种用于移情检测的框架，可处理带噪声的标签，通过不确定性量化和新颖的损失函数提高性能。


<details>
  <summary>Details</summary>
Motivation: 解决监督学习中由噪声的自我报告移情分数带来的移情回归挑战，并为文本分类中已有的噪声标签学习算法提供回归的解决方案。

Method: 提出了一种名为UPLME的不确定性感知概率语言建模框架，该框架利用贝叶斯概念和变分模型集成来捕获移情检测中的标签噪声，并引入了两个新的损失函数来约束不确定性量化和相似性。

Result: UPLME在两个公共基准测试中取得了最先进的性能（Pearson相关系数分别从0.558提高到0.580，从0.629提高到0.634），并且在校准误差方面优于现有的基于变分模型集成的不确定性量化方法（从0.571降低到0.376）。

Conclusion: UPLME在包含标签噪声的公共基准测试中，在移情检测的回归设置中，通过不确定性量化和新颖的损失函数，实现了最先进的性能，并且优于现有的不确定性量化方法。

Abstract: Supervised learning for empathy regression is challenged by noisy
self-reported empathy scores. While many algorithms have been proposed for
learning with noisy labels in textual classification problems, the regression
counterpart is relatively under-explored. We propose UPLME, an
uncertainty-aware probabilistic language modelling framework to capture label
noise in the regression setting of empathy detection. UPLME includes a
probabilistic language model that predicts both empathy score and
heteroscedastic uncertainty and is trained using Bayesian concepts with
variational model ensembling. We further introduce two novel loss components:
one penalises degenerate Uncertainty Quantification (UQ), and another enforces
the similarity between the input pairs on which we predict empathy. UPLME
provides state-of-the-art performance (Pearson Correlation Coefficient:
$0.558\rightarrow0.580$ and $0.629\rightarrow0.634$) in terms of the
performance reported in the literature in two public benchmarks, having label
noise. Through synthetic label noise injection, we show that UPLME is effective
in separating noisy and clean samples based on the predicted uncertainty. UPLME
further outperform (Calibration error: $0.571\rightarrow0.376$) a recent
variational model ensembling-based UQ method designed for regression problems.

</details>


### [170] [FilBench: Can LLMs Understand and Generate Filipino?](https://arxiv.org/abs/2508.03523)
*Lester James V. Miranda,Elyanah Aco,Conner Manuel,Jan Christian Blaise Cruz,Joseph Marvin Imperial*

Main category: cs.CL

TL;DR: 本研究提出了FilBench，一个评估大型语言模型在菲律宾语、他加禄语和宿务语能力的基准。结果显示，现有模型表现不佳，最先进的模型GPT-4o得分仅为72.23%，凸显了在菲律宾语言处理方面进一步研究的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在英语任务上表现出色，但它们在菲律宾语等特定语言上的能力却知之甚少。本研究旨在解决这一差距，通过创建一个全面的菲律宾语基准来评估和改进大型语言模型在菲律宾语言方面的表现。

Method: 本研究引入了一个名为FilBench的以菲律宾为中心的基准，该基准包含了文化知识、古典自然语言处理、阅读理解和生成等任务，旨在评估大型语言模型在菲律宾语、他加禄语和宿务语方面的能力。研究评估了27个最先进的大型语言模型，并分析了它们在这些任务上的表现。

Result: FilBench基准的评估结果显示，现有的大型语言模型在阅读理解和翻译能力方面存在不足。得分最高的模型GPT-4o仅获得72.23%的分数，而专门为东南亚语言训练的模型（如SEA-LION v3 70B）得分仅为61.07%。这表明FilBench是一个具有挑战性的基准，并且现有模型在处理菲律宾语言的复杂性方面仍有提升空间。

Conclusion: 该研究通过引入FilBench填补了评估大型语言模型在菲律宾语、他加禄语和宿务语方面能力的空白。结果显示，即使是像GPT-4o这样表现最好的模型，在FilBench上的得分也仅为72.23%，表明该基准具有挑战性。此外，专门为东南亚语言训练的模型在该基准上的表现并不理想。这项工作强调了创建特定语言的大型语言模型基准对于推动菲律宾自然语言处理的进步和促进菲律宾语言在大型语言模型发展中的包容性的重要性。

Abstract: Despite the impressive performance of LLMs on English-based tasks, little is
known about their capabilities in specific languages such as Filipino. In this
work, we address this gap by introducing FilBench, a Filipino-centric benchmark
designed to evaluate LLMs across a diverse set of tasks and capabilities in
Filipino, Tagalog, and Cebuano. We carefully curate the tasks in FilBench to
reflect the priorities and trends of NLP research in the Philippines such as
Cultural Knowledge, Classical NLP, Reading Comprehension, and Generation. By
evaluating 27 state-of-the-art LLMs on FilBench, we find that several LLMs
suffer from reading comprehension and translation capabilities. Our results
indicate that FilBench is challenging, with the best model, GPT-4o, achieving
only a score of 72.23%. Moreover, we also find that models trained specifically
for Southeast Asian languages tend to underperform on FilBench, with the
highest-performing model, SEA-LION v3 70B, achieving only a score of 61.07%.
Our work demonstrates the value of curating language-specific LLM benchmarks to
aid in driving progress on Filipino NLP and increasing the inclusion of
Philippine languages in LLM development.

</details>


### [171] [Marito: Structuring and Building Open Multilingual Terminologies for South African NLP](https://arxiv.org/abs/2508.03529)
*Vukosi Marivate,Isheanesu Dzingirai,Fiskani Banda,Richard Lastrucci,Thapelo Sindane,Keabetswe Madumo,Kayode Olaleye,Abiodun Modupe,Unarine Netshifhefhe,Herkulaas Combrink,Mohlatlego Nakeng,Matome Ledwaba*

Main category: cs.CL

TL;DR: Marito addresses the lack of structured terminological data for South Africa's official languages by creating open datasets from fragmented resources, improving machine translation accuracy.


<details>
  <summary>Details</summary>
Motivation: The critical lack of structured terminological data for South Africa's official languages hampers progress in multilingual NLP, despite the existence of numerous government and academic terminology lists.

Method: Systematically aggregating, cleaning, and standardising scattered resources into open, interoperable datasets, and integrating the terminology into a Retrieval-Augmented Generation (RAG) pipeline.

Result: Experiments show substantial improvements in the accuracy and domain-specific consistency of English-to-Tshivenda machine translation for large language models.

Conclusion: Marito provides a scalable foundation for developing robust and equitable NLP technologies, ensuring South Africa's rich linguistic diversity is represented in the digital age.

Abstract: The critical lack of structured terminological data for South Africa's
official languages hampers progress in multilingual NLP, despite the existence
of numerous government and academic terminology lists. These valuable assets
remain fragmented and locked in non-machine-readable formats, rendering them
unusable for computational research and development. \emph{Marito} addresses
this challenge by systematically aggregating, cleaning, and standardising these
scattered resources into open, interoperable datasets. We introduce the
foundational \emph{Marito} dataset, released under the equitable,
Africa-centered NOODL framework. To demonstrate its immediate utility, we
integrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.
Experiments show substantial improvements in the accuracy and domain-specific
consistency of English-to-Tshivenda machine translation for large language
models. \emph{Marito} provides a scalable foundation for developing robust and
equitable NLP technologies, ensuring South Africa's rich linguistic diversity
is represented in the digital age.

</details>


### [172] [EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for Large Language Models](https://arxiv.org/abs/2508.03533)
*Xiaoming Hou,Jiquan Zhang,Zibin Lin,DaCheng Tao,Shengli Zhang*

Main category: cs.CL

TL;DR: EmbedGrad通过梯度优化提示嵌入，在不增加模型复杂性的情况下，有效提升了模型在多种任务上的适应能力和性能，尤其对小模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有模型适应方法（离散提示工程和连续参数调优）存在精度不足和复杂性增加/可解释性降低的问题，因此需要一种新的方法来解决这些限制。

Method: EmbedGrad框架通过梯度优化文本提示的嵌入，在训练时利用标记数据进行精确调整，在推理时仅集成优化后的嵌入，实现了精细的校准。

Result: 在数学推理、情感分析和因果判断任务上，EmbedGrad均有效提升了模型性能。例如，在数学问题上，将Qwen2.5-Math-1.5B的准确率从14.74%提升到58.96%，并在不同模型规模（0.5B-14B）和所有任务上展现出持续改进，尤其在处理复杂问题（如因果判断）时，对小模型的增益尤为显著。

Conclusion: EmbedGrad通过在嵌入空间中进行基于梯度的精炼来优化文本提示，实现了在不改变模型架构的情况下，有效弥合了提示工程和参数效率之间的差距，并将嵌入精炼确立为一种新的任务适应范式。

Abstract: Effectively adapting powerful pretrained foundation models to diverse tasks
remains a key challenge in AI deployment. Current approaches primarily follow
two paradigms:discrete optimization of text prompts through prompt engineering,
or continuous adaptation via additional trainable parameters. Both exhibit
limitations-discrete methods lack refinement precision while parameter-based
techniques increase complexity and reduce interpretability. To address these
constraints, we propose EmbedGrad, a novel framework that optimizes text prompt
embeddings through gradient-based refinement. Our approach uniquely decouples
training from deployment:during optimization,labeled examples guide precise
embedding adjustments while preserving semantic meaning; during inference, only
optimized embeddings integrate with user queries. This enables fine-grained
calibration impossible in text space, such as enhancing the reasoning
capability of prompts like please reason step by step. Comprehensive
evaluations across mathematical reasoning, sentiment analysis, and causal
judgment tasks demonstrate EmbedGrad's effectiveness:optimizing this reasoning
prompt for Qwen2.5-Math-1.5B increased accuracy from 14.74\% to 58.96\% on
mathematical problems. Consistent improvements were observed across model
scales (0.5B-14B) and all tasks, with particularly significant gains for
smaller models on complex problems like causal judgment. By bridging prompt
engineering and parameter efficiency without architectural changes, our work
establishes embedding refinement as a powerful new paradigm for task
adaptation.

</details>


### [173] [Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations](https://arxiv.org/abs/2508.03550)
*Peng Lai,Jianjie Zheng,Sijie Cheng,Yun Chen,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: LAGER通过利用LLM内部不同层级的表示来提高LLM作为评判者在评估任务中的表现，无需复杂的提示或微调，并且在多个基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是初步发现中上层编码的语义和与任务相关的表示通常比最后一层更符合人类判断。

Method: LAGER是一个轻量级且高效的框架，通过内部表示来增强LLM-as-a-Judge与人类评分的一致性。它通过聚合跨层分数标记logit并计算基于softmax的分布的预期分数来产生细粒度的判断分数，同时LLM骨干保持冻结。

Result: LAGER在Flask、HelpSteer和BIGGen等标准对齐基准上实现了高达7.5%的改进，并且在没有推理步骤的情况下，其性能与基于推理的方法相当或更优。

Conclusion: LAGER通过聚合跨层分数标记logit并计算基于softmax的分布的预期分数，在不进行复杂提示或微调的情况下，提高了LLM-as-a-Judge与人类评分的一致性。

Abstract: The growing scale of evaluation tasks has led to the widespread adoption of
automated evaluation using large language models, a paradigm known as
"LLMas-a-judge." However, improving its alignment with human preferences
without complex prompts or fine-tuning remains challenging. In this work,
motivated by preliminary findings that middle-to-upper layers encode
semantically and taskrelevant representations that are often more aligned with
human judgments than the final layer, we propose LAGER, a lightweight and
efficient framework for enhancing LLM-as-a-Judge alignment with human scoring,
via internal representations. LAGER produces fine-grained judgment scores by
aggregating cross-layer scoretoken logits and computing the expected score from
a softmax-based distribution, with the LLM backbone kept frozen. LAGER fully
leverages the complementary information across different layers, overcoming the
limitations of relying solely on the final layer. We evaluate our method on the
standard alignment benchmarks Flask, HelpSteer, and BIGGen using Spearman
correlation, and find that LAGER achieves improvements of up to 7.5% over the
best baseline across these benchmarks. Without reasoning steps, LAGER matches
or outperforms reasoning-based methods. Experiments on downstream applications,
such as data selection and emotional understanding, further show the
effectiveness of our method.

</details>


### [174] [Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed Learning for Continual Adaptation](https://arxiv.org/abs/2508.03571)
*Iing Muttakhiroh,Thomas Fevens*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) often suffer from performance degradation when
faced with domain shifts, primarily due to catastrophic forgetting. In this
work, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),
a novel continual learning framework that integrates dynamic knowledge graphs
with instruction tuning. By leveraging retrieved domain-specific knowledge as
guidance during training, KILO enhances both adaptability to new domains and
retention of previously acquired knowledge. We pretrain our model on
WikiText-103 and evaluate sequential adaptation across four diverse target
domains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that
KILO consistently outperforms strong baselines, including continual
fine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward
transfer, F1 score, retention rate, and training efficiency. These results
highlight the effectiveness of combining structured knowledge retrieval and
instruction prompting to overcome domain shift challenges in continual learning
scenarios.

</details>


### [175] [Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?](https://arxiv.org/abs/2508.03644)
*Wenxuan Shen,Mingjia Wang,Yaochen Wang,Dongping Chen,Junjie Yang,Yao Wan,Weiwei Lin*

Main category: cs.CL

TL;DR: Double-Bench是一个新的大规模、多语言、多模态评估系统，用于评估文档RAG系统，解决了现有基准测试的局限性，并发现了模型在检索和证据支持方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前用于评估检索增强生成（RAG）系统（特别是利用多模态大语言模型MLLMs的系统）的基准测试存在不足，它们通常只关注文档RAG系统的特定部分，并使用带有不完整真实情况和证据标签的合成数据，无法反映现实世界中的瓶颈和挑战。

Method: 提出了一种名为Double-Bench的大规模、多语言、多模态评估系统，能够对文档RAG系统的每个组件进行细粒度评估。该系统包含3,276份文档（72,880页）和5,168个单跳和多跳查询，涵盖6种语言和4种文档类型，并支持动态更新以应对数据污染问题。查询均以详尽扫描的证据页面为基础，并经过人工专家验证。

Result: 实验结果表明，文本和视觉嵌入模型之间的差距正在缩小，强调了构建更强大的文档检索模型的需求。研究还揭示了当前文档RAG框架中存在的过度自信问题，即模型倾向于在没有证据支持的情况下也提供答案。

Conclusion: Double-Bench的发布旨在为文档RAG系统的未来研究提供一个严谨的基础，并计划每年发布新的基准测试。

Abstract: Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language
Models (MLLMs) show great promise for complex document understanding, yet their
development is critically hampered by inadequate evaluation. Current benchmarks
often focus on specific part of document RAG system and use synthetic data with
incomplete ground truth and evidence labels, therefore failing to reflect
real-world bottlenecks and challenges. To overcome these limitations, we
introduce Double-Bench: a new large-scale, multilingual, and multimodal
evaluation system that is able to produce fine-grained assessment to each
component within document RAG systems. It comprises 3,276 documents (72,880
pages) and 5,168 single- and multi-hop queries across 6 languages and 4
document types with streamlined dynamic update support for potential data
contamination issues. Queries are grounded in exhaustively scanned evidence
pages and verified by human experts to ensure maximum quality and completeness.
Our comprehensive experiments across 9 state-of-the-art embedding models, 4
MLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text
and visual embedding models is narrowing, highlighting the need in building
stronger document retrieval models. Our findings also reveal the
over-confidence dilemma within current document RAG frameworks that tend to
provide answer even without evidence support. We hope our fully open-source
Double-Bench provide a rigorous foundation for future research in advanced
document RAG systems. We plan to retrieve timely corpus and release new
benchmarks on an annual basis.

</details>


### [176] [Can Large Vision-Language Models Understand Multimodal Sarcasm?](https://arxiv.org/abs/2508.03654)
*Xinyu Wang,Yue Zhang,Liqiang Jing*

Main category: cs.CL

TL;DR: 本研究评估了大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）中的应用，发现其在视觉理解和概念知识方面存在不足。为解决这些问题，提出了一种无需训练的框架，通过整合深度对象提取和外部概念知识来增强模型能力，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）方面的应用仍有待探索。需要解决LVLMs在视觉理解和概念知识方面的局限性。

Method: 提出一个无需训练的框架，整合深度对象提取和外部概念知识，以提高模型在多模态语境下解释和理解讽刺的能力。

Result: 通过在多个模型上的实验，证明了所提出框架的有效性，解决了视觉理解不足和概念知识缺乏的关键问题。

Conclusion: 所提出的框架通过整合深度对象提取和外部概念知识，提高了模型在多模态环境中解释和理解讽刺的能力，并在多个模型上进行了实验验证。

Abstract: Sarcasm is a complex linguistic phenomenon that involves a disparity between
literal and intended meanings, making it challenging for sentiment analysis and
other emotion-sensitive tasks. While traditional sarcasm detection methods
primarily focus on text, recent approaches have incorporated multimodal
information. However, the application of Large Visual Language Models (LVLMs)
in Multimodal Sarcasm Analysis (MSA) remains underexplored. In this paper, we
evaluate LVLMs in MSA tasks, specifically focusing on Multimodal Sarcasm
Detection and Multimodal Sarcasm Explanation. Through comprehensive
experiments, we identify key limitations, such as insufficient visual
understanding and a lack of conceptual knowledge. To address these issues, we
propose a training-free framework that integrates in-depth object extraction
and external conceptual knowledge to improve the model's ability to interpret
and explain sarcasm in multimodal contexts. The experimental results on
multiple models show the effectiveness of our proposed framework. The code is
available at https://github.com/cp-cp/LVLM-MSA.

</details>


### [177] [CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction](https://arxiv.org/abs/2508.03668)
*Zixuan Li,Binzong Geng,Jing Xiong,Yong He,Yuxuan Hu,Jian Chen,Dingwei Chen,Xiyu Chang,Liang Zhang,Linjian Mo,Chengming Li,Chuan Yuan,Zhenan Sun*

Main category: cs.CL

TL;DR: CTR-Sink 通过引入“注意力汇聚”机制，解决语言模型用于点击率预测时在处理用户行为序列上的结构性差异，提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语言模型（LM）的点击率（CTR）预测方法存在结构性匹配问题，即用户行为序列的离散性和分隔符的语义空缺与语言模型预训练的自然语言存在差异，导致模型注意力分散，无法有效捕捉行为间的关键边界和依赖关系，从而影响预测性能。

Method: 提出了一种名为 CTR-Sink 的新框架，该框架通过在用户行为序列中插入包含时序距离等推荐场景信号的“汇聚”标记，并设计了两阶段训练策略来引导和增强模型对这些汇聚标记的注意力，以解决离散行为序列与自然语言的固有差异。

Result: 实验结果表明，CTR-Sink 框架在工业数据集和 MovieLens、Kuairec 等公开数据集上均表现出有效的性能提升，并通过可视化结果进一步证实了其能够更好地捕捉行为依赖关系。

Conclusion: CTR-Sink 框架通过引入行为级注意力汇聚机制，并结合推荐场景特有的时序信息，有效解决了现有基于语言模型的方法在处理用户行为序列时的结构性匹配问题，提升了点击率预测的性能。实验结果验证了该方法的有效性。

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems,
estimates user click likelihood using historical behavioral data. Modeling user
behavior sequences as text to leverage Language Models (LMs) for this task has
gained traction, owing to LMs' strong semantic understanding and contextual
modeling capabilities. However, a critical structural gap exists: user behavior
sequences consist of discrete actions connected by semantically empty
separators, differing fundamentally from the coherent natural language in LM
pre-training. This mismatch causes semantic fragmentation, where LM attention
scatters across irrelevant tokens instead of focusing on meaningful behavior
boundaries and inter-behavior relationships, degrading prediction performance.
To address this, we propose $\textit{CTR-Sink}$, a novel framework introducing
behavior-level attention sinks tailored for recommendation scenarios. Inspired
by attention sink theory, it constructs attention focus sinks and dynamically
regulates attention aggregation via external information. Specifically, we
insert sink tokens between consecutive behaviors, incorporating
recommendation-specific signals such as temporal distance to serve as stable
attention sinks. To enhance generality, we design a two-stage training strategy
that explicitly guides LM attention toward sink tokens and a attention sink
mechanism that amplifies inter-sink dependencies to better capture behavioral
correlations. Experiments on one industrial dataset and two open-source
datasets (MovieLens, Kuairec), alongside visualization results, validate the
method's effectiveness across scenarios.

</details>


### [178] [FairLangProc: A Python package for fairness in NLP](https://arxiv.org/abs/2508.03677)
*Arturo Pérez-Peralta,Sandra Benítez-Peña,Rosa E. Lillo*

Main category: cs.CL

TL;DR: FairLangProc 是一个 Python 软件包，旨在统一和简化 NLP 偏见缓解技术的使用，使其更易于访问和应用。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型在决策制定（如组织公正或医疗保健）中的应用日益广泛，以及由此产生的社会对模型公平性的担忧，该研究旨在为 NLP 领域中衡量和缓解偏见提供一个标准化的解决方案。

Method: 提出并实现了一个名为 FairLangProc 的 Python 软件包，它统一了 NLP 领域中用于衡量和缓解有害偏见的一些最新进展的实现。

Result: FairLangProc 提供了一个通用的实现，并兼容 Hugging Face transformers 库，促进了偏见缓解技术在 NLP 中的应用和民主化。

Conclusion: FairLangProc 旨在通过提供一个与 Hugging Face transformers 库兼容的通用接口，来鼓励更广泛地使用和普及偏见缓解技术，从而解决自然语言处理（NLP）领域偏见问题。

Abstract: The rise in usage of Large Language Models to near ubiquitousness in recent
years has risen societal concern about their applications in decision-making
contexts, such as organizational justice or healthcare. This, in turn, poses
questions about the fairness of these models in critical settings, which leads
to the developement of different procedures to address bias in Natural Language
Processing. Although many datasets, metrics and algorithms have been proposed
to measure and mitigate harmful prejudice in Natural Language Processing, their
implementation is diverse and far from centralized. As a response, this paper
presents FairLangProc, a comprehensive Python package providing a common
implementation of some of the more recent advances in fairness in Natural
Language Processing providing an interface compatible with the famous Hugging
Face transformers library, aiming to encourage the widespread use and
democratization of bias mitigation techniques. The implementation can be found
on https://github.com/arturo-perez-peralta/FairLangProc.

</details>


### [179] [More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation](https://arxiv.org/abs/2508.03678)
*Yangtian Zi,Harshitha Menon,Arjun Guha*

Main category: cs.CL

TL;DR: LLMs struggle with specialized code generation partly due to vague prompts. A new evaluation method, PartialOrderEval, shows that more detailed prompts (especially those with clear I/O, edge cases, and step-by-step instructions) significantly improve LLM performance on tasks like ParEval.


<details>
  <summary>Details</summary>
Motivation: Investigate whether LLMs underperform on specialized code generation benchmarks due to missing domain knowledge or insufficient prompt detail.

Method: Introduced PartialOrderEval, a method to augment code generation benchmarks with a partial order of prompts from minimal to maximally detailed. Applied this to HumanEval and ParEval (serial and OpenMP subsets) and measured pass@1 scaling with prompt specificity using Llama-3.x and Qwen2.5-Coder.

Result: Demonstrated varying degrees of prompt sensitivity across different tasks for Llama-3.x and Qwen2.5-Coder. Identified explicit I/O specifications, edge-case handling, and stepwise breakdowns as crucial factors for improving prompt detail and LLM performance.

Conclusion: LLMs' performance on specialized code generation benchmarks like ParEval varies, with prompt specificity playing a significant role. Explicit I/O specifications, edge-case handling, and stepwise breakdowns in prompts are key drivers for improvement.

Abstract: State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general
benchmarks like HumanEval but underperform on specialized suites such as
ParEval. Is this due to LLMs missing domain knowledge or insufficient prompt
detail is given? To answer this, we introduce PartialOrderEval, which augments
any code generation benchmark with a partial order of prompts from minimal to
maximally detailed. Applying it to HumanEval and both serial and OpenMP subsets
of ParEval, we measure how pass@1 scales with prompt specificity. Our
experiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of
prompt sensitivity across different tasks, and a qualitative analysis
highlights explicit I/O specifications, edge-case handling, and stepwise
breakdowns as the key drivers of prompt detail improvement.

</details>


### [180] [CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward](https://arxiv.org/abs/2508.03686)
*Shudong Liu,Hongwei Liu,Junnan Liu,Linchen Xiao,Songyang Gao,Chengqi Lyu,Yuzhe Gu,Wenwei Zhang,Derek F. Wong,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种名为CompassVerifier的轻量级模型，用于提高LLM答案验证的准确性和鲁棒性，并创建了一个名为VerifierBench的基准来评估验证能力。研究解决了现有评估方法的局限性，并有望推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数语言模型（LLM）评估框架在答案验证方面存在局限性，例如需要进行大量的、重复性的定制（如正则表达式规则或评估提示），并且缺乏能够系统评估不同LLM的验证能力的综合基准，同时现有的验证方法在处理复杂边缘情况和跨领域泛化方面也存在不足。

Method: 作者开发了一个名为CompassVerifier的轻量级验证器模型，该模型能够处理数学、知识和各种推理任务，并能识别异常/无效响应。他们还创建了一个名为VerifierBench的基准，其中包含来自多个数据源的模型输出，并通过对元错误模式的手动分析进行了增强。

Result: CompassVerifier在数学、知识和推理等多个领域展现了其多领域能力，能够处理多种答案类型，并有效识别异常/无效响应。VerifierBench基准的创建也增强了CompassVerifier的模型能力。

Conclusion: CompassVerifier和VerifierBench的开发旨在促进答案验证、评估协议和强化学习研究。

Abstract: Answer verification is crucial not only for evaluating large language models
(LLMs) by matching their unstructured outputs against standard answers, but
also serves as the reward model to guide LLM optimization. Most evaluation
frameworks rely on regularized matching or employ general LLMs for answer
verification, which demands extensive, repetitive customization for regex rules
or evaluation prompts. Two fundamental limitations persist in current
methodologies: 1) the absence of comprehensive benchmarks that systematically
evaluate verification capabilities across different LLMs; and 2) the nascent
stage of verifier development, where existing approaches lack both the
robustness to handle complex edge cases and the generalizability across
different domains. In this work, we develop CompassVerifier, an accurate and
robust lightweight verifier model for evaluation and outcome reward. It
demonstrates multi-domain competency spanning math, knowledge, and diverse
reasoning tasks, with the capability to process various answer types, including
multi-subproblems, formulas, and sequence answers, while effectively
identifying abnormal/invalid responses. We introduce VerifierBench benchmark
comprising model outputs collected from multiple data sources, augmented
through manual analysis of metaerror patterns to enhance CompassVerifier. We
anticipate that CompassVerifier and VerifierBench will facilitate answer
verification, evaluation protocols, and reinforcement learning research. Code
and dataset are available at https://github.com/open-compass/CompassVerifier.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [181] [Modeling electrothermal feedback of superconducting nanowire single photon detectors in SPICE](https://arxiv.org/abs/2508.02791)
*Hanson Nguyen,Alejandro Simon,Reed Foster,Karl K. Berggren*

Main category: physics.app-ph

TL;DR: 研究人员创建了一个更快速、更直观的SNSPD模型，可用于电路设计。


<details>
  <summary>Details</summary>
Motivation: SNSPDs表现出复杂的开关行为，理解这些行为对于设计超导器件至关重要，但现有模型往往牺牲了计算速度和直观性。

Method: 构建了一个SNSPD的紧凑型热模型，并捕获了复杂的残余热效应

Result: 所提出的模型在准确性上可与更复杂的模型相媲美，包括有限元模拟，并且适用于SNSPD电路的快速开发。

Conclusion: 该模型可用于SNSPD电路的快速开发

Abstract: Superconducting nanowire single-photon detectors (SNSPDs) exhibit complex
switching behaviors due to electrothermal feedback during the detection
process. Modeling and understanding these behaviors is integral for designing
superconducting devices; however, many models often prioritize accuracy over
computational speed and intuitive integration for circuit designers. Here, we
build upon a growing architecture of SPICE tools for superconducting nanowire
devices by capturing complex residual heating effects in a compact thermal
model of an SNSPD. We demonstrate that our model is comparable to more
complicated thermal models of superconducting nanowire devices, including
finite-element simulations, and is applicable for the fast development of SNSPD
circuits.

</details>


### [182] [Observation of cluster magnetic octupole domains in the antiferromagnetic Weyl semimetal Mn3Sn nanowire](https://arxiv.org/abs/2508.03004)
*Hironari Isshiki,Nico Budai,Ayuko Kobayashi,Ryota Uesugi,Tomoya Higo,Satoru Nakatsuji,YoshiChika Otani*

Main category: physics.app-ph

TL;DR: 本研究在纳米尺度下测量了Mn3Sn的局域反常霍尔效应，为集成Mn3Sn纳米结构到存储设备提供了关键信息。


<details>
  <summary>Details</summary>
Motivation: 为了解决Mn3Sn磁性质仅在微米尺度下被研究而未在纳米尺度下被研究的问题，为将Mn3Sn纳米结构集成到存储设备中提供关键信息。

Method: 利用原子力显微镜，通过尖端接触诱导温度梯度，实现了对Mn3Sn纳米线的局域反常霍尔效应测量。

Result: 首次在纳米尺度下测量了Mn3Sn的局域反常霍尔效应，并提供了80nm空间分辨率的畴磁矩分布信息。

Conclusion: 本研究测量了(0001)取向的Mn3Sn纳米线的局域反常霍尔效应，并实现了80nm的空间分辨率。

Abstract: The antiferromagnetic Weyl semimetal Mn3Sn has attracted wide attention due
to their vast anomalous transverse transport properties despite barely net
magnetization. So far, the magnetic properties of Mn3Sn have been
experimentally investigated on micrometer scale samples but not in nanometers.
In this study, we measured the local anomalous Nernst effect of a
(0001)-textured Mn3Sn nanowire using a tip-contact-induced temperature gradient
with an atomic force microscope. Our approach directly provides the
distribution of the cluster magnetic octupole moments in Mn3Sn with 80 nm
spatial resolution, providing crucial information for integrating the Mn3Sn
nanostructure into a memory device.

</details>


### [183] [High-Capacity and Real-Time Acoustic Communication by Multiplexing Velocity](https://arxiv.org/abs/2508.03010)
*Lei Liu,Xiujuan Zhang,Ming-Hui Lu,Yan-Feng Chen*

Main category: physics.app-ph

TL;DR: Researchers have unlocked higher data transmission rates for underwater acoustic communication by using the vector velocity of sound waves, similar to how polarization is used in electromagnetic waves, thereby increasing the potential for underwater network capacity.


<details>
  <summary>Details</summary>
Motivation: Traditional acoustic communication relies on a single scalar pressure channel, limiting data capacity. Electromagnetic waves, with their vector polarization, offer multiple information channels, motivating the exploration of similar capabilities in acoustic communication.

Method: Theoretically and experimentally demonstrated the use of the three components of acoustic wave vector velocity as independent communication channels, demodulated using a single vector sensor.

Result: Achieved reliable, high-capacity, and real-time information transmission by multiplexing the velocity of acoustic waves, significantly enhancing information capacity when combined with other degrees of freedom.

Conclusion: Acoustic waves' vector velocity can be used as a polarization-like degree of freedom, enabling reliable, high-capacity, and real-time information transmission by utilizing its three components as independent communication channels with a single vector sensor.

Abstract: Acoustic communication is indispensable for underwater networks, deep ocean
exploration, and biological monitoring, environments where electromagnetic
waves become impractical. However, unlike the latter, whose vector polarization
naturally supports multiple information channels, acoustic waves are
longitudinal and have traditionally relied almost exclusively on a single
scalar pressure channel, posing a fundamental limit on their data-carrying
capacity. Here, we theoretically and experimentally demonstrate that the vector
velocity of acoustic waves can serve as a polarization-like physical degree of
freedom. Using its three components as mutually independent communication
channels and demodulating them with a single vector sensor, we achieve
reliable, high-capacity, and real-time information transmission. Multiplexing
velocity adds a new dimension to acoustic communication. When combined with
other physical degrees of freedom (frequency, phase, etc.), this approach can
significantly enhance the information capacity, opening new avenues for
next-generation acoustic technology.

</details>


### [184] [High-resolution magnetic imaging by mapping the locally induced anomalous Nernst effect using atomic force microscopy](https://arxiv.org/abs/2508.03066)
*Nico Budai,Hironari Isshiki,Ryota Uesugi,Zheng Zhu,Tomoya Higo,Satoru Nakatsuji,YoshiChika Otani*

Main category: physics.app-ph

TL;DR: 利用AFM测量异常能斯特效应，成像Co2MnGa磁畴。


<details>
  <summary>Details</summary>
Motivation: 测量局部诱导的异常能斯特效应，并成像铁磁韦尔半金属Co2MnGa的磁畴。

Method: 使用原子力显微镜和局部温度梯度测量异常能斯特效应。

Result: 在室温下，使用该方法成功成像了Co2MnGa纳米线的磁畴，空间分辨率达到了亚百纳米。

Conclusion: 通过原子力显微镜实现了磁畴成像，空间分辨率达到亚百纳米。

Abstract: We report a magnetic imaging method using atomic force microscopy to measure
the locally induced anomalous Nernst effect. The tip contact creates a local
temperature gradient on the sample surface controlled by a neighboring Joule
heating wire. We demonstrate the imaging of magnetic domains in a nanowire of
the ferromagnetic Weyl semimetal Co2MnGa with a spatial resolution of a
sub-hundred nanometer at room temperature.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [185] [A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models](https://arxiv.org/abs/2508.02711)
*Yidong Chai,Yang Liu,Yonghang Zhou,Jiaheng Xie,Daniel Dajun Zeng*

Main category: cs.LG

TL;DR: BH-PEFT 是一种新的贝叶斯混合参数高效微调方法，可以量化不确定性并动态适应新数据，在业务任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的混合 PEFT 方法在微调 LLM 以用于专业应用时存在两个主要挑战：1. 依赖点估计，缺乏量化不确定性的能力，难以做出可靠的决策；2. 难以动态适应新出现的数据，不适用于现实世界的情况。

Method: 提出了一种名为 BH-PEFT 的新颖方法，该方法将贝叶斯学习集成到混合 PEFT 中，结合了 Adapter、LoRA 和前缀调整技术，对 Transformer 的前馈和注意力层进行微调。通过将可学习参数建模为分布，BH-PEFT 实现了不确定性量化。此外，还提出了一种贝叶斯动态微调方法，将上一个后验作为下一个回合的先验，以适应新数据。

Result: 在情感分析、新闻分类和常识推理等业务任务上评估 BH-PEFT，结果表明该方法优于现有的 PEFT 基线，能够进行不确定性量化以做出更可靠的决策，并提高了在动态场景中的适应性。

Conclusion: BH-PEFT 通过将贝叶斯学习与混合参数高效微调相结合，解决了现有混合 PEFT 方法在不确定性量化和动态适应方面的挑战。实验结果表明，BH-PEFT 在业务任务上优于现有基线，并能在动态场景中实现更可靠和自适应的决策。

Abstract: Large Language Models (LLMs) have demonstrated transformative potential in
reshaping the world. As these models are pretrained on general corpora, they
often require domain-specific fine-tuning to optimize performance in
specialized business applications. Due to their massive scale,
parameter-efficient fine-tuning (PEFT) methods are widely used to reduce
training costs. Among them, hybrid PEFT methods that combine multiple PEFT
techniques have achieved the best performance. However, existing hybrid PEFT
methods face two main challenges when fine-tuning LLMs for specialized
applications: (1) relying on point estimates, lacking the ability to quantify
uncertainty for reliable decision-making, and (2) struggling to dynamically
adapt to emerging data, lacking the ability to suit real-world situations. We
propose Bayesian Hybrid Parameter-Efficient Fine-Tuning (BH-PEFT), a novel
method that integrates Bayesian learning into hybrid PEFT. BH-PEFT combines
Adapter, LoRA, and prefix-tuning to fine-tune feedforward and attention layers
of the Transformer. By modeling learnable parameters as distributions, BH-PEFT
enables uncertainty quantification. We further propose a Bayesian dynamic
fine-tuning approach where the last posterior serves as the prior for the next
round, enabling effective adaptation to new data. We evaluated BH-PEFT on
business tasks such as sentiment analysis, news categorization, and commonsense
reasoning. Results show that our method outperforms existing PEFT baselines,
enables uncertainty quantification for more reliable decisions, and improves
adaptability in dynamic scenarios. This work contributes to business analytics
and data science by proposing a novel BH-PEFT method and dynamic fine-tuning
approach that support uncertainty-aware and adaptive decision-making in
real-world situations.

</details>


### [186] [ZetA: A Riemann Zeta-Scaled Extension of Adam for Deep Learning](https://arxiv.org/abs/2508.02719)
*Samiksha BC*

Main category: cs.LG

TL;DR: ZetA通过引入基于黎曼Zeta函数的动态梯度缩放来改进Adam优化器，并在各种基准测试中提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 将Zeta函数应用于梯度缩放，以改进深度学习优化。

Method: ZetA是一种新颖的深度学习优化器，通过结合基于黎曼Zeta函数的动态缩放来扩展Adam。它采用混合更新机制，整合了自适应阻尼、基于余弦相似度的动量提升、熵正则化损失和类似SAM的扰动，以提高泛化能力和鲁棒性。

Result: 在SVHN、CIFAR10、CIFAR100、STL10和嘈杂CIFAR10数据集上的实证评估表明，与Adam相比，ZetA在测试准确率方面持续提高。

Conclusion: ZetA是一种计算效率高、鲁棒性强的Adam替代品，在嘈杂或高粒度分类任务中特别有效。

Abstract: This work introduces ZetA, a novel deep learning optimizer that extends Adam
by incorporating dynamic scaling based on the Riemann zeta function. To the
best of our knowledge, ZetA is the first optimizer to apply zeta-based gradient
scaling within deep learning optimization. The method improves generalization
and robustness through a hybrid update mechanism that integrates adaptive
damping, cosine similarity-based momentum boosting, entropy-regularized loss,
and Sharpness-Aware Minimization (SAM)-style perturbations. Empirical
evaluations on SVHN, CIFAR10, CIFAR100, STL10, and noisy CIFAR10 consistently
show test accuracy improvements over Adam. All experiments employ a lightweight
fully connected network trained for five epochs under mixed-precision settings.
The results demonstrate that ZetA is a computationally efficient and robust
alternative to Adam, particularly effective in noisy or high-granularity
classification tasks.

</details>


### [187] [Understanding the Embedding Models on Hyper-relational Knowledge Graph](https://arxiv.org/abs/2508.03280)
*Yubo Wang,Shimin Di,Zhili Wang,Haoyang Li,Fei Teng,Hao Xin,Lei Chen*

Main category: cs.LG

TL;DR: 本研究评估了经典KGE模型在超关系知识图谱（HKGs）上的表现，并提出了FormerGNN框架。研究发现，经典模型效果相当，但分解方法会丢失信息。现有的HKGE模型在捕捉长期依赖和整合信息方面存在不足。FormerGNN通过改进的框架解决了这些问题，并在实验中表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了明确超关系知识图谱嵌入（HKGE）模型的优越性是源于其基础KGE模型还是专门设计的扩展模块，本研究旨在评估经典KGE模型在HKGs上的表现，并进一步提出改进框架以解决现有HKGE模型的不足。

Method: 本研究将超关系知识图谱（HKGs）通过三种分解方法转化为知识图谱（KGs）格式，并评估了几种经典的知识图谱嵌入（KGE）模型在HKGs上的性能。此外，研究提出了FormerGNN框架，该框架包含一个限定词整合器、一个基于GNN的图编码器以及一个改进的信息整合方法。

Result: 通过数据转换和评估，研究发现一些经典的KGE模型在HKGs上取得了与HKGE模型相当的性能。然而，分解方法会改变原始HKG拓扑且未能完全保留信息。此外，现有的HKGE模型在捕捉长期依赖性或整合信息方面存在不足。提出的FormerGNN框架在实验中表现优于现有的HKGE模型。

Conclusion: 现有的超关系知识图谱嵌入（HKGE）模型在捕捉图谱的长期依赖性或整合主三元组和限定词信息方面存在不足，而FormerGNN框架通过采用限定词整合器、基于GNN的图编码器以及改进的主三元组和限定词信息整合方法，能够更好地捕捉图谱的长期依赖性并缓解信息压缩问题，实验结果证明其优于现有的HKGE模型。

Abstract: Recently, Hyper-relational Knowledge Graphs (HKGs) have been proposed as an
extension of traditional Knowledge Graphs (KGs) to better represent real-world
facts with additional qualifiers. As a result, researchers have attempted to
adapt classical Knowledge Graph Embedding (KGE) models for HKGs by designing
extra qualifier processing modules. However, it remains unclear whether the
superior performance of Hyper-relational KGE (HKGE) models arises from their
base KGE model or the specially designed extension module. Hence, in this
paper, we data-wise convert HKGs to KG format using three decomposition methods
and then evaluate the performance of several classical KGE models on HKGs. Our
results show that some KGE models achieve performance comparable to that of
HKGE models. Upon further analysis, we find that the decomposition methods
alter the original HKG topology and fail to fully preserve HKG information.
Moreover, we observe that current HKGE models are either insufficient in
capturing the graph's long-range dependency or struggle to integrate
main-triple and qualifier information due to the information compression issue.
To further justify our findings and offer a potential direction for future HKGE
research, we propose the FormerGNN framework. This framework employs a
qualifier integrator to preserve the original HKG topology, and a GNN-based
graph encoder to capture the graph's long-range dependencies, followed by an
improved approach for integrating main-triple and qualifier information to
mitigate compression issues. Our experimental results demonstrate that
FormerGNN outperforms existing HKGE models.

</details>


### [188] [ECGTwin: Personalized ECG Generation Using Controllable Diffusion Model](https://arxiv.org/abs/2508.02720)
*Yongfan Lai,Bo Liu,Xinyan Guan,Qinghao Zhao,Hongyan Li,Shenda Hong*

Main category: cs.LG

TL;DR: ECGTwin是一个两阶段框架，用于生成个性化ECG。它利用对比学习提取个体特征，并使用AdaX条件注入器将这些特征与目标心脏病状集成到基于扩散的模型中，以实现高保真、多样化和可控的ECG生成。


<details>
  <summary>Details</summary>
Motivation: 个性化心电图（ECG）生成旨在模拟针对特定条件的患者ECG数字孪生。它有可能将传统医疗转变为更准确的个性化范式，同时保留传统群体ECG合成的关键优势。然而，这项任务提出了两个基本挑战：在没有真实情况的情况下提取个体特征，以及在不混淆生成模型的情况下注入各种类型的条件。

Method: ECGTwin是一个两阶段框架。第一阶段，通过对比学习训练的个体基础提取器，可以从参考ECG中提取个人特征。第二阶段，通过AdaX条件注入器将提取的个体特征与目标心脏病状集成到基于扩散的生成过程中，该注入器通过两个专用通道注入这些信号。

Result: 实验证明，ECGTwin不仅能生成高保真、多样化且可进行细粒度控制的ECG信号，还能保留个体特征。

Conclusion: ECGTwin有望增强下游应用程序中的ECG自动诊断，并可实现精确的个性化医疗解决方案。

Abstract: Personalized electrocardiogram (ECG) generation is to simulate a patient's
ECG digital twins tailored to specific conditions. It has the potential to
transform traditional healthcare into a more accurate individualized paradigm,
while preserving the key benefits of conventional population-level ECG
synthesis. However, this promising task presents two fundamental challenges:
extracting individual features without ground truth and injecting various types
of conditions without confusing generative model. In this paper, we present
ECGTwin, a two-stage framework designed to address these challenges. In the
first stage, an Individual Base Extractor trained via contrastive learning
robustly captures personal features from a reference ECG. In the second stage,
the extracted individual features, along with a target cardiac condition, are
integrated into the diffusion-based generation process through our novel AdaX
Condition Injector, which injects these signals via two dedicated and
specialized pathways. Both qualitative and quantitative experiments have
demonstrated that our model can not only generate ECG signals of high fidelity
and diversity by offering a fine-grained generation controllability, but also
preserving individual-specific features. Furthermore, ECGTwin shows the
potential to enhance ECG auto-diagnosis in downstream application, confirming
the possibility of precise personalized healthcare solutions.

</details>


### [189] [Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)](https://arxiv.org/abs/2508.02737)
*Tasnia Nobi Afee,Jack Hutchins,Md Mazharul Islam,Thomas Kampfe,Ahmedullah Aziz*

Main category: cs.LG

TL;DR: 本研究提出了一个基于混合密度网络（MDN）的增强概率建模框架，用于解决FeFET固有的随机性问题。该框架通过集成C-infinity连续激活函数和特定于器件的嵌入层，实现了平滑、稳定的学习和对物理变异性的捕捉。实验结果显示，该模型在预测FeFET电流行为变异性方面具有高精度（R2=0.92），为开发面向变异性的FeFET模型和电路仿真提供了有力的支持。


<details>
  <summary>Details</summary>
Motivation: 铁电场效应晶体管（FeFET）在推动存储器和逻辑技术方面具有巨大潜力，但其固有的由操作循环和制造变异性引起的随机性给准确可靠的建模带来了重大挑战。捕捉这种变异性至关重要，因为它使设计人员能够预测行为、优化性能并确保在制造和操作条件变化的鲁棒性。现有的确定性和基于机器学习的紧凑模型通常无法完全捕捉这种变异性，或者缺乏稳定电路级集成所需的数学平滑性。

Method: 本工作提出了一个增强的概率建模框架，用于铁电场效应晶体管（FeFET）。该框架建立在混合密度网络（MDN）的基础上，集成了C-infinity连续激活函数以实现平滑、稳定的学习，以及一个特定于器件的嵌入层以捕捉器件内部的物理变异性。通过从学习到的嵌入分布中采样，可以生成合成器件实例，用于进行面向变异性的仿真。

Result: 该模型通过了R2为0.92的检验，在捕捉FeFET电流行为的变异性方面表现出高精度。

Conclusion: 该框架为模拟铁电场效应晶体管（FeFET）的全随机行为提供了一个可扩展、数据驱动的解决方案，并为未来的紧凑模型开发和电路模拟集成奠定了坚实的基础。

Abstract: FeFETs hold strong potential for advancing memory and logic technologies, but
their inherent randomness arising from both operational cycling and fabrication
variability poses significant challenges for accurate and reliable modeling.
Capturing this variability is critical, as it enables designers to predict
behavior, optimize performance, and ensure reliability and robustness against
variations in manufacturing and operating conditions. Existing deterministic
and machine learning-based compact models often fail to capture the full extent
of this variability or lack the mathematical smoothness required for stable
circuit-level integration. In this work, we present an enhanced probabilistic
modeling framework for FeFETs that addresses these limitations. Building upon a
Mixture Density Network (MDN) foundation, our approach integrates C-infinity
continuous activation functions for smooth, stable learning and a
device-specific embedding layer to capture intrinsic physical variability
across devices. Sampling from the learned embedding distribution enables the
generation of synthetic device instances for variability-aware simulation. With
an R2 of 0.92, the model demonstrates high accuracy in capturing the
variability of FeFET current behavior. Altogether, this framework provides a
scalable, data-driven solution for modeling the full stochastic behavior of
FeFETs and offers a strong foundation for future compact model development and
circuit simulation integration.

</details>


### [190] [Neural Networks with Orthogonal Jacobian](https://arxiv.org/abs/2508.02882)
*Alex Massucco,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 通过强制雅可比矩阵正交性来稳定非常深层神经网络的训练，并取得有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 解决非常深层神经网络通过反向传播训练时，梯度消失或爆炸的问题，以及现有方法（如正交或保持方差初始化和残差架构）的局限性。

Method: 提出一个统一的数学框架，用于描述一类非线性前馈网络和残差网络，这些网络的输入到输出雅可比矩阵几乎处处精确正交。该框架强制实现完美的动态等距。

Result: 实验证明，在初始化时实现完美的雅可比矩阵正交性足以稳定训练并获得有竞争力的性能。与正则化以维持雅可比矩阵正交性的网络相比，获得了可比的结果。进一步分析表明，推广到部分等距网络也能保持良好的训练特性。

Conclusion: 所提出的方法通过数学框架强制网络实现完美的动态等距，从而在初始化时实现精确的雅可比矩阵正交性，稳定了训练过程，并取得了有竞争力的性能。该方法还恢复了标准架构，并产生了不依赖于传统跳跃连接的新设计，同时保持了残差网络的训练能力。此外，该框架推广到部分等距网络，这些网络也保持了有利的训练特性。

Abstract: Very deep neural networks achieve state-of-the-art performance by extracting
rich, hierarchical features. Yet, training them via backpropagation is often
hindered by vanishing or exploding gradients. Existing remedies, such as
orthogonal or variance-preserving initialisation and residual architectures,
allow for a more stable gradient propagation and the training of deeper models.
In this work, we introduce a unified mathematical framework that describes a
broad class of nonlinear feedforward and residual networks, whose
input-to-output Jacobian matrices are exactly orthogonal almost everywhere.
Such a constraint forces the resulting networks to achieve perfect dynamical
isometry and train efficiently despite being very deep. Our formulation not
only recovers standard architectures as particular cases but also yields new
designs that match the trainability of residual networks without relying on
conventional skip connections. We provide experimental evidence that perfect
Jacobian orthogonality at initialisation is sufficient to stabilise training
and achieve competitive performance. We compare this strategy to networks
regularised to maintain the Jacobian orthogonality and obtain comparable
results. We further extend our analysis to a class of networks
well-approximated by those with orthogonal Jacobians and introduce networks
with Jacobians representing partial isometries. These generalized models are
then showed to maintain the favourable trainability properties.

</details>


### [191] [Minimal Convolutional RNNs Accelerate Spatiotemporal Learning](https://arxiv.org/abs/2508.03614)
*Coşku Can Horuz,Sebastian Otte,Martin V. Butz,Matthias Karlbauer*

Main category: cs.LG

TL;DR: New MinConvLSTM/GRU models use convolutional layers with minimal RNNs for faster training and better spatiotemporal predictions than standard ConvLSTMs/GRUs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the training bottlenecks of conventional ConvRNN models by eliminating sequential hidden state updates during teacher forcing, while retaining localized spatial modeling capabilities.

Method: The paper introduces MinConvLSTM and MinConvGRU, novel spatiotemporal models that extend the log-domain prefix-sum formulation to convolutional architectures, enabling parallel training. An exponential gating mechanism is incorporated into MinConvLSTM for simplified computation. The models feature reduced parameter counts and improved scalability.

Result: The proposed models significantly outperform standard ConvLSTMs and ConvGRUs in training speed and achieve lower prediction errors on Navier-Stokes dynamics and geopotential data forecasting tasks, even in closed-loop autoregressive mode.

Conclusion: MinConvLSTM and MinConvGRU models provide an efficient and effective alternative for spatiotemporal sequence modeling, outperforming conventional ConvRNNs in training speed and prediction accuracy.

Abstract: We introduce MinConvLSTM and MinConvGRU, two novel spatiotemporal models that
combine the spatial inductive biases of convolutional recurrent networks with
the training efficiency of minimal, parallelizable RNNs. Our approach extends
the log-domain prefix-sum formulation of MinLSTM and MinGRU to convolutional
architectures, enabling fully parallel training while retaining localized
spatial modeling. This eliminates the need for sequential hidden state updates
during teacher forcing - a major bottleneck in conventional ConvRNN models. In
addition, we incorporate an exponential gating mechanism inspired by the xLSTM
architecture into the MinConvLSTM, which further simplifies the log-domain
computation. Our models are structurally minimal and computationally efficient,
with reduced parameter count and improved scalability. We evaluate our models
on two spatiotemporal forecasting tasks: Navier-Stokes dynamics and real-world
geopotential data. In terms of training speed, our architectures significantly
outperform standard ConvLSTMs and ConvGRUs. Moreover, our models also achieve
lower prediction errors in both domains, even in closed-loop autoregressive
mode. These findings demonstrate that minimal recurrent structures, when
combined with convolutional input aggregation, offer a compelling and efficient
alternative for spatiotemporal sequence modeling, bridging the gap between
recurrent simplicity and spatial complexity.

</details>


### [192] [Mathematical Foundations of Geometric Deep Learning](https://arxiv.org/abs/2508.02723)
*Haitz Sáez de Ocáriz Borde,Michael Bronstein*

Main category: cs.LG

TL;DR: This paper reviews the math needed for Geometric Deep Learning.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide the necessary mathematical background for studying Geometric Deep Learning.

Method: The paper reviews key mathematical concepts for Geometric Deep Learning.

Result: The paper reviews the mathematical concepts.

Conclusion: Abstract does not contain conclusion.

Abstract: We review the key mathematical concepts necessary for studying Geometric Deep
Learning.

</details>


### [193] [Forecasting NCAA Basketball Outcomes with Deep Learning: A Comparative Study of LSTM and Transformer Models](https://arxiv.org/abs/2508.02725)
*Md Imtiaz Habib*

Main category: cs.LG

TL;DR: 本研究使用LSTM和Transformer模型预测NCAA篮球比赛结果，发现Transformer区分能力更强，LSTM概率校准更优，强调了模型和损失函数选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了预测2025年NCAA男子和女子篮球锦标赛的比赛结果，探索先进的深度学习方法。

Method: 本研究利用LSTM和Transformer两种序列模型，结合GLM、Elo评分、种子差异和汇总得分等特征工程，并使用二元交叉熵（BCE）和Brier损失函数进行训练和评估。

Result: Transformer模型（使用BCE损失）的AUC最高，达到0.8473，表明其区分预测能力更强。LSTM模型（使用Brier损失）的Brier得分最低，为0.1589，表明其概率校准能力更优。

Conclusion: Transformer架构和LSTM模型在预测2025年NCAA篮球锦标赛方面各有优劣。Transformer模型在区分预测能力方面表现更好（AUC为0.8473），而LSTM模型在概率校准方面表现更佳（Brier得分为0.1589）。研究强调了根据具体需求选择模型架构和损失函数的重要性。

Abstract: In this research, I explore advanced deep learning methodologies to forecast
the outcomes of the 2025 NCAA Division 1 Men's and Women's Basketball
tournaments. Leveraging historical NCAA game data, I implement two
sophisticated sequence-based models: Long Short-Term Memory (LSTM) and
Transformer architectures. The predictive power of these models is augmented
through comprehensive feature engineering, including team quality metrics
derived from Generalized Linear Models (GLM), Elo ratings, seed differences,
and aggregated box-score statistics. To evaluate the robustness and reliability
of predictions, I train each model variant using both Binary Cross-Entropy
(BCE) and Brier loss functions, providing insights into classification
performance and probability calibration. My comparative analysis reveals that
while the Transformer architecture optimized with BCE yields superior
discriminative power (highest AUC of 0.8473), the LSTM model trained with Brier
loss demonstrates superior probabilistic calibration (lowest Brier score of
0.1589). These findings underscore the importance of selecting appropriate
model architectures and loss functions based on the specific requirements of
forecasting tasks. The detailed analytical pipeline presented here serves as a
reproducible framework for future predictive modeling tasks in sports analytics
and beyond.

</details>


### [194] [Pulse Shape Discrimination Algorithms: Survey and Benchmark](https://arxiv.org/abs/2508.02750)
*Haoran Liu,Yihan Zhan,Mingzhe Liu,Yanhua Liu,Peng Li,Zhuo Zuo,Bingqi Liu,Runxi Liu*

Main category: cs.LG

TL;DR: 本综述对近六十种用于辐射探测的脉冲形状鉴别（PSD）算法进行了调查和基准测试，并将它们分为统计和先验知识两类。我们评估了这些算法在两个标准化数据集上的表现，并发布了一个开源工具箱以促进研究。


<details>
  <summary>Details</summary>
Motivation: 对用于辐射探测的脉冲形状鉴别（PSD）算法进行全面的调查和基准测试。

Method: 对近六十种脉冲形状鉴别（PSD）算法进行分类（统计类：时域、频域、基于神经网络；先验知识类：机器学习、深度学习），并在两个标准化数据集（来自 241Am-9Be 源的无标签集和来自 238Pu-9Be 源的飞行时间标记集）上实现了对所有算法的评估。评估指标包括品质因数（FOM）、F1 分数、ROC-AUC 和方法间相关性。

Result: 深度学习模型通常优于传统方法。

Conclusion: 深度学习模型（特别是多层感知器（MLP）和结合统计特征与神经回归的混合方法）通常优于传统方法。

Abstract: This review presents a comprehensive survey and benchmark of pulse shape
discrimination (PSD) algorithms for radiation detection, classifying nearly
sixty methods into statistical (time-domain, frequency-domain, neural
network-based) and prior-knowledge (machine learning, deep learning) paradigms.
We implement and evaluate all algorithms on two standardized datasets: an
unlabeled set from a 241Am-9Be source and a time-of-flight labeled set from a
238Pu-9Be source, using metrics including Figure of Merit (FOM), F1-score,
ROC-AUC, and inter-method correlations. Our analysis reveals that deep learning
models, particularly Multi-Layer Perceptrons (MLPs) and hybrid approaches
combining statistical features with neural regression, often outperform
traditional methods. We discuss architectural suitabilities, the limitations of
FOM, alternative evaluation metrics, and performance across energy thresholds.
Accompanying this work, we release an open-source toolbox in Python and MATLAB,
along with the datasets, to promote reproducibility and advance PSD research.

</details>


### [195] [DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening](https://arxiv.org/abs/2508.02741)
*Zhixiang Lu,Yulong Li,Feilong Tang,Zhengyong Jiang,Chong Li,Mian Zhou,Tenglong Li,Jionglong Su*

Main category: cs.LG

TL;DR: DeepGB-TB是一种基于咳嗽音频和人口统计数据的新型AI系统，用于即时结核病风险评估。它使用创新的CM-BCA和TRBL模块，在真实世界数据上达到了新的性能水平，并且可以在移动设备上离线运行，有望改善全球结核病筛查。


<details>
  <summary>Details</summary>
Motivation: 大规模结核病筛查受到传统诊断方法的高成本和操作复杂性的限制，因此需要人工智能解决方案。

Method: 该系统提出了一种名为DeepGB-TB的非侵入式方法，仅使用咳嗽音频和基本人口统计数据即可即时分配结核病风险评分。该模型结合了用于音频处理的一维卷积神经网络和用于表格特征的梯度提升决策树。其主要创新在于跨模态双向交叉注意力（CM-BCA）模块，该模块在模态之间迭代交换显着线索，并采用结核病风险平衡损失（TRBL）函数，对假阴性预测进行更强的惩罚。

Result: DeepGB-TB在包括七个国家/地区的1105名患者的多样化数据集上进行了评估，其AUROC达到了0.903，F1分数达到了0.851，创下了新的技术水平。该系统计算效率高，可在常见移动设备上进行实时、离线推理，非常适合资源匮乏地区。

Conclusion: DeepGB-TB系统通过结合AI创新和公共卫生需求，在速度、可负担性和可靠性方面表现出色，为促进全球结核病控制提供了工具。

Abstract: Large-scale tuberculosis (TB) screening is limited by the high cost and
operational complexity of traditional diagnostics, creating a need for
artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system
that instantly assigns TB risk scores using only cough audio and basic
demographic data. The model couples a lightweight one-dimensional convolutional
neural network for audio processing with a gradient-boosted decision tree for
tabular features. Its principal innovation is a Cross-Modal Bidirectional
Cross-Attention module (CM-BCA) that iteratively exchanges salient cues between
modalities, emulating the way clinicians integrate symptoms and risk factors.
To meet the clinical priority of minimizing missed cases, we design a
Tuberculosis Risk-Balanced Loss (TRBL) that places stronger penalties on
false-negative predictions, thereby reducing high-risk misclassifications.
DeepGB-TB is evaluated on a diverse dataset of 1,105 patients collected across
seven countries, achieving an AUROC of 0.903 and an F1-score of 0.851,
representing a new state of the art. Its computational efficiency enables
real-time, offline inference directly on common mobile devices, making it ideal
for low-resource settings. Importantly, the system produces clinically
validated explanations that promote trust and adoption by frontline health
workers. By coupling AI innovation with public-health requirements for speed,
affordability, and reliability, DeepGB-TB offers a tool for advancing global TB
control.

</details>


### [196] [Frontier: Simulating the Next Generation of LLM Inference Systems](https://arxiv.org/abs/2508.03148)
*Yicheng Feng,Xin Tan,Kin Hang Sew,Yimin Jiang,Yibo Zhu,Hong Xu*

Main category: cs.LG

TL;DR: LLM inference is getting complex due to MoE and disaggregated architectures. Existing simulators can't handle this. We made Frontier, a new high-fidelity simulator that supports these new systems and complex workflows, empowering the community to design and optimize future LLM inference.


<details>
  <summary>Details</summary>
Motivation: Existing simulators are unable to capture the intricate system dynamics of emerging LLM paradigms like Mixture-of-Experts (MoE) and disaggregated architectures (e.g., prefill/decode or attention/FFN decoupling) which require heterogeneous scaling.

Method: Frontier is a high-fidelity simulator with a unified framework for both co-located and disaggregated systems. It supports MoE inference with expert parallelism (EP), complex workflows like cross-cluster expert routing, and advanced pipelining strategies. It also incorporates refined operator models for improved accuracy.

Result: Frontier provides a high-fidelity simulation environment for LLM inference, addressing the limitations of existing simulators in modeling complex, disaggregated, and MoE systems.

Conclusion: Frontier enables the community to design and optimize the future of LLM inference at scale.

Abstract: Large Language Model (LLM) inference is growing increasingly complex with the
rise of Mixture-of-Experts (MoE) models and disaggregated architectures that
decouple components like prefill/decode (PD) or attention/FFN (AF) for
heterogeneous scaling. Existing simulators, architected for co-located, dense
models, are unable to capture the intricate system dynamics of these emerging
paradigms. We present Frontier, a high-fidelity simulator designed from the
ground up for this new landscape. Frontier introduces a unified framework to
model both co-located and disaggregated systems, providing native support for
MoE inference with expert parallelism (EP). It enables the simulation of
complex workflows like cross-cluster expert routing and advanced pipelining
strategies for latency hiding. To ensure fidelity and usability, Frontier
incorporates refined operator models for improved accuracy. Frontier empowers
the community to design and optimize the future of LLM inference at scale.

</details>


### [197] [Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling](https://arxiv.org/abs/2508.02749)
*Lu Gao,Ke Yu,Pan Lu*

Main category: cs.LG

TL;DR: 通过图神经网络（GNN）利用道路网络的空间结构信息，可以提高路面状况预测的准确性。


<details>
  <summary>Details</summary>
Motivation: GNN能够轻松直接地利用网络中丰富的结构信息，用于路面性能建模。

Method: 利用图神经网络（GNN）将道路网络的空间依赖性纳入路面状况预测模型。

Result: 与未考虑空间结构的模型相比，考虑空间结构的路面状况预测模型性能更优。

Conclusion: 考虑道路网络空间结构可以提高道路路面状况预测模型的性能。

Abstract: Pavement deterioration modeling is important in providing information
regarding the future state of the road network and in determining the needs of
preventive maintenance or rehabilitation treatments. This research incorporated
spatial dependence of road network into pavement deterioration modeling through
a graph neural network (GNN). The key motivation of using a GNN for pavement
performance modeling is the ability to easily and directly exploit the rich
structural information in the network. This paper explored if considering
spatial structure of the road network will improve the prediction performance
of the deterioration models. The data used in this research comprises a large
pavement condition data set with more than a half million observations taken
from the Pavement Management Information System (PMIS) maintained by the Texas
Department of Transportation. The promising comparison results indicates that
pavement deterioration prediction models perform better when spatial
relationship is considered.

</details>


### [198] [Online Robust Multi-Agent Reinforcement Learning under Model Uncertainties](https://arxiv.org/abs/2508.02948)
*Zain Ulabedeen Farhat,Debamita Ghosh,George K. Atia,Yue Wang*

Main category: cs.LG

TL;DR: 本研究提出了RONAVI算法，用于在线学习分布鲁棒马尔可夫博弈（DRMGs），以应对真实环境中由于不确定性导致的多智能体系统失败问题。该算法在TV和KL散度度量下具有可证明的保证，实现了低遗憾，并能高效找到最优鲁棒策略，为开发真正鲁棒的多智能体系统开辟了新的实用途径。


<details>
  <summary>Details</summary>
Motivation: 为了解决在真实环境中，多智能体系统由于训练和部署环境不匹配（由噪声或对抗性攻击等不确定性引起）而导致的失败问题，本研究旨在探索一种无需模拟器或大量离线数据即可提高系统韧性的方法。

Method: 提出了一种名为"鲁棒乐观纳什价值迭代"（RONAVI）的算法，并提供了理论保证，证明了该算法可以实现低遗憾，并有效地找到针对TV和KL散度度量的最优鲁棒策略。

Result: 该算法在TV和KL散度度量下，实现了低遗憾，并能够高效地找到最优鲁棒策略。

Conclusion: 本研究首次在在线学习的分布鲁棒马尔可夫博弈（DRMGs）设置下进行了研究，并提出了一个名为RONAVI的算法，该算法在TV和KL散度下具有可证明的保证，并且可以高效地找到最优鲁棒策略。

Abstract: Well-trained multi-agent systems can fail when deployed in real-world
environments due to model mismatches between the training and deployment
environments, caused by environment uncertainties including noise or
adversarial attacks. Distributionally Robust Markov Games (DRMGs) enhance
system resilience by optimizing for worst-case performance over a defined set
of environmental uncertainties. However, current methods are limited by their
dependence on simulators or large offline datasets, which are often
unavailable. This paper pioneers the study of online learning in DRMGs, where
agents learn directly from environmental interactions without prior data. We
introduce the {\it Robust Optimistic Nash Value Iteration (RONAVI)} algorithm
and provide the first provable guarantees for this setting. Our theoretical
analysis demonstrates that the algorithm achieves low regret and efficiently
finds the optimal robust policy for uncertainty sets measured by Total
Variation divergence and Kullback-Leibler divergence. These results establish a
new, practical path toward developing truly robust multi-agent systems.

</details>


### [199] [SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference](https://arxiv.org/abs/2508.02751)
*Yi Zhao,Yajuan Peng,Cam-Tu Nguyen,Zuchao Li,Xiaoliang Wang,Hai Zhao,Xiaoming Fu*

Main category: cs.LG

TL;DR: SmallKV 使用小模型来改进 KV 缓存驱逐，解决了现有方法的局限性，提高了 LLM 推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有 KV 缓存驱逐方法在长上下文场景中存在显著性转移和边缘信息过度压缩问题，无法适应动态注意力模式，并且忽视了边缘令牌的集体重要性。

Method: 提出了一种名为 SmallKV 的方法，这是一种利用小模型辅助的 KV 缓存压缩补偿机制。SmallKV 旨在通过维持不同尺度 LLM 之间的注意力匹配来解决上述问题：1) 帮助大模型感知注意力的全局重要信息；2) 利用小模型的注意力分数来近似大模型中边缘令牌的注意力分数。

Result: 在 GSM8K、BBH、MT-Bench 和 LongBench 等基准测试上的大量实验证明了 SmallKV 的有效性。效率评估显示，SmallKV 的吞吐量比基线方法高 1.75 - 2.56 倍，在资源受限环境中具有高效且高性能的 LLM 推理潜力。

Conclusion: KV 缓存驱逐是缓解 LLM 在长上下文场景下面临的资源限制的有效方法。现有方法存在其不可逆的驱逐策略无法适应动态注意力模式（显著性转移问题）以及同等对待边缘重要性和真正不重要性令牌（边缘信息过度压缩问题）。

Abstract: KV cache eviction has emerged as an effective solution to alleviate resource
constraints faced by LLMs in long-context scenarios. However, existing
token-level eviction methods often overlook two critical aspects: (1) their
irreversible eviction strategy fails to adapt to dynamic attention patterns
during decoding (the saliency shift problem), and (2) they treat both
marginally important tokens and truly unimportant tokens equally, despite the
collective significance of marginal tokens to model performance (the marginal
information over-compression problem). To address these issues, we design two
compensation mechanisms based on the high similarity of attention matrices
between LLMs of different scales. We propose SmallKV, a small model assisted
compensation method for KV cache compression. SmallKV can maintain attention
matching between different-scale LLMs to: 1) assist the larger model in
perceiving globally important information of attention; and 2) use the smaller
model's attention scores to approximate those of marginal tokens in the larger
model. Extensive experiments on benchmarks including GSM8K, BBH, MT-Bench, and
LongBench demonstrate the effectiveness of SmallKV. Moreover, efficiency
evaluations show that SmallKV achieves 1.75 - 2.56 times higher throughput than
baseline methods, highlighting its potential for efficient and performant LLM
inference in resource constrained environments.

</details>


### [200] [DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting](https://arxiv.org/abs/2508.02753)
*Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan*

Main category: cs.LG

TL;DR: DMSC框架通过动态多尺度协调，解决了时间序列预测中尺度依赖建模和融合的挑战，实现了SOTA性能和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测方法在模拟不同尺度上的复杂时间依赖关系方面仍然存在挑战，这些挑战源于静态分解策略、碎片化的依赖建模和不灵活的融合机制。

Method: 提出了一种新颖的动态多尺度协调框架（DMSC），该框架包含多尺度块分解（EMPD）、三元交互块（TIB）和自适应尺度路由MoE块（ASR-MoE）。EMPD动态分割序列为具有指数尺度粒度的层级块，通过输入自适应块调整消除预定义尺度约束。TIB在每个层的分解表示中联合建模块内、块间和跨变量依赖关系。EMPD和TIB联合集成到层中，形成一个多层渐进级联架构，其中早期层的粗粒度表示通过门控路径自适应地指导后续层的细粒度特征提取。ASR-MoE利用专门的全局和局部专家以及时间感知加权来动态融合多尺度预测。

Result: 在13个真实世界基准测试上的综合实验证明了DMSC的有效性。

Conclusion: DMSC框架在时间序列预测任务上始终保持最先进（SOTA）性能和卓越的计算效率。

Abstract: Time Series Forecasting (TSF) faces persistent challenges in modeling
intricate temporal dependencies across different scales. Despite recent
advances leveraging different decomposition operations and novel architectures
based on CNN, MLP or Transformer, existing methods still struggle with static
decomposition strategies, fragmented dependency modeling, and inflexible fusion
mechanisms, limiting their ability to model intricate temporal dependencies. To
explicitly solve the mentioned three problems respectively, we propose a novel
Dynamic Multi-Scale Coordination Framework (DMSC) with Multi-Scale Patch
Decomposition block (EMPD), Triad Interaction Block (TIB) and Adaptive Scale
Routing MoE block (ASR-MoE). Specifically, EMPD is designed as a built-in
component to dynamically segment sequences into hierarchical patches with
exponentially scaled granularities, eliminating predefined scale constraints
through input-adaptive patch adjustment. TIB then jointly models intra-patch,
inter-patch, and cross-variable dependencies within each layer's decomposed
representations. EMPD and TIB are jointly integrated into layers forming a
multi-layer progressive cascade architecture, where coarse-grained
representations from earlier layers adaptively guide fine-grained feature
extraction in subsequent layers via gated pathways. And ASR-MoE dynamically
fuses multi-scale predictions by leveraging specialized global and local
experts with temporal-aware weighting. Comprehensive experiments on thirteen
real-world benchmarks demonstrate that DMSC consistently maintains
state-of-the-art (SOTA) performance and superior computational efficiency for
TSF tasks. Code is available at https://github.com/1327679995/DMSC.

</details>


### [201] [Context-Adaptive Multi-Prompt LLM Embedding for Vision-Language Alignment](https://arxiv.org/abs/2508.02762)
*Dahun Kim,Anelia Angelova*

Main category: cs.LG

TL;DR: CAMPE uses multiple text prompts with adaptive tokens to create richer text representations for vision-language tasks, improving retrieval performance.


<details>
  <summary>Details</summary>
Motivation: To enrich semantic representations in vision-language contrastive learning by moving beyond single text embeddings and capturing diverse semantic aspects of input text.

Method: We introduce multiple structured prompts with distinct adaptive tokens, process them jointly in a single forward pass, and combine the resulting prompt embeddings into a unified text representation. We also incorporate a diversity regularization loss and a negation-aware loss.

Result: Consistent improvements on both image-text and video-text retrieval benchmarks.

Conclusion: We propose Context-Adaptive Multi-Prompt Embedding (CAMPE) which enriches semantic representations in vision-language contrastive learning by using multiple structured prompts with adaptive tokens. CAMPE achieves consistent improvements on image-text and video-text retrieval benchmarks.

Abstract: We propose Context-Adaptive Multi-Prompt Embedding, a novel approach to
enrich semantic representations in vision-language contrastive learning. Unlike
standard CLIP-style models that rely on a single text embedding, our method
introduces multiple structured prompts, each containing a distinct adaptive
token that captures diverse semantic aspects of the input text. We process all
prompts jointly in a single forward pass. The resulting prompt embeddings are
combined into a unified text representation, enabling semantically richer
alignment with visual features. To further promote semantic diversity and
representation quality, we incorporate a diversity regularization loss and a
negation-aware loss, encouraging specialization across prompts and improving
contrastive discrimination. Our method achieves consistent improvements on both
image-text and video-text retrieval benchmarks.

</details>


### [202] [Synthetic medical data generation: state of the art and application to trauma mechanism classification](https://arxiv.org/abs/2508.02771)
*Océane Doremus,Ariel Guerra-Adames,Marta Avalos-Fernandez,Vianney Jouhet,Cédric Gil-Jardiné,Emmanuel Lagarde*

Main category: cs.LG

TL;DR: This paper introduces methods for creating synthetic medical data (tabular and text) to improve privacy and reproducibility in health AI, proposing a new way to combine both data types for better results in classifying trauma mechanisms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of patient confidentiality and scientific reproducibility in machine learning for health research by developing synthetic medical databases.

Method: The proposed methodology generates synthetic medical records by combining tabular and unstructured text data. The article also provides an overview of state-of-the-art machine learning methods for generating synthetic tabular and textual data, focusing on their application to the automatic classification of trauma mechanisms.

Result: The article presents a methodology for generating synthetic medical records and an overview of machine learning methods for synthetic data generation applied to trauma mechanism classification.

Conclusion: The article proposes a methodology for generating high-quality, synthetic medical records that combine tabular and unstructured text data, addressing challenges of patient confidentiality and scientific reproducibility in machine learning for health.

Abstract: Faced with the challenges of patient confidentiality and scientific
reproducibility, research on machine learning for health is turning towards the
conception of synthetic medical databases. This article presents a brief
overview of state-of-the-art machine learning methods for generating synthetic
tabular and textual data, focusing their application to the automatic
classification of trauma mechanisms, followed by our proposed methodology for
generating high-quality, synthetic medical records combining tabular and
unstructured text data.

</details>


### [203] [Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems](https://arxiv.org/abs/2508.02887)
*Jialin Zheng,Haoyu Wang,Yangbin Zeng,Di Mou,Xin Zhang,Hong Li,Sergio Vazquez,Leopoldo G. Franquelo*

Main category: cs.LG

TL;DR: This paper introduces PENODE, a novel approach for Edge Digital Twins in Power Electronics Systems that uses Physics-Embedded Neural ODEs to accurately model hybrid dynamics, improving Sim-to-Real generalization and enabling efficient edge deployment with reduced complexity.


<details>
  <summary>Details</summary>
Motivation: Existing modeling approaches struggle to consistently capture continuously evolving hybrid dynamics in Power Electronics Systems (PES), degrading Sim-to-Real generalization on resource-constrained edge devices. This necessitates a new approach for Edge Digital Twins (EDTs) in PES monitoring and control.

Method: This paper proposes Physics-Embedded Neural ODEs (PENODE), which embeds the hybrid operating mechanism as an event automaton to govern discrete switching and injects known governing ODE components into neural parameterization for unmodeled dynamics. This creates a differentiable, end-to-end trainable architecture with physical interpretability and reduced redundancy, supporting a cloud-to-edge toolchain for FPGA deployment.

Result: PENODE achieves significantly higher accuracy in benchmarks across white-box, gray-box, and black-box scenarios, with a 75% reduction in neuron count, demonstrating its effectiveness in maintaining physical interpretability, enabling efficient edge deployment, and enhancing real-time control.

Conclusion: PENODE maintains physical interpretability, efficient edge deployment, and real-time control enhancement, achieving significantly higher accuracy with a 75% reduction in neuron count across various scenarios.

Abstract: Edge Digital Twins (EDTs) are crucial for monitoring and control of Power
Electronics Systems (PES). However, existing modeling approaches struggle to
consistently capture continuously evolving hybrid dynamics that are inherent in
PES, degrading Sim-to-Real generalization on resource-constrained edge devices.
To address these challenges, this paper proposes a Physics-Embedded Neural ODEs
(PENODE) that (i) embeds the hybrid operating mechanism as an event automaton
to explicitly govern discrete switching and (ii) injects known governing ODE
components directly into the neural parameterization of unmodeled dynamics.
This unified design yields a differentiable end-to-end trainable architecture
that preserves physical interpretability while reducing redundancy, and it
supports a cloud-to-edge toolchain for efficient FPGA deployment. Experimental
results demonstrate that PENODE achieves significantly higher accuracy in
benchmarks in white-box, gray-box, and black-box scenarios, with a 75%
reduction in neuron count, validating that the proposed PENODE maintains
physical interpretability, efficient edge deployment, and real-time control
enhancement.

</details>


### [204] [Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation Models](https://arxiv.org/abs/2508.02812)
*Katherine Avery,Chinmay Pendse,David Jensen*

Main category: cs.LG

TL;DR: 提出了一种基于结构方程模型的分布鲁棒评估和学习方法，解决了现有方法过于保守的问题，并能学习到更优的策略。


<details>
  <summary>Details</summary>
Motivation: 当前分布鲁棒评估和学习方法会产生过于保守的评估和策略，而本文提出的方法旨在解决这个问题。

Method: 提出了一种实用的 the bandit 评估和学习算法，该算法使用受结构方程模型约束的数学程序来为特定问题定制不确定性集。此外，还展示了如何使用条件独立性测试来检测用于建模的移位变量。

Result: SEM方法比传统方法提供了更准确的评估，并学习到了低方差的策略，尤其是在处理大的偏移时。

Conclusion: SEM方法在评估方面更准确，并且在模型充分指定的情况下，可以学习到最优策略，尤其是在处理大的偏移时。

Abstract: Distributionally robust evaluation estimates the worst-case expected return
over an uncertainty set of possible covariate and reward distributions, and
distributionally robust learning finds a policy that maximizes that worst-case
return across that uncertainty set. Unfortunately, current methods for
distributionally robust evaluation and learning create overly conservative
evaluations and policies. In this work, we propose a practical bandit
evaluation and learning algorithm that tailors the uncertainty set to specific
problems using mathematical programs constrained by structural equation models.
Further, we show how conditional independence testing can be used to detect
shifted variables for modeling. We find that the structural equation model
(SEM) approach gives more accurate evaluations and learns lower-variance
policies than traditional approaches, particularly for large shifts. Further,
the SEM approach learns an optimal policy, assuming the model is sufficiently
well-specified.

</details>


### [205] [Neural Approximators for Low-Thrust Trajectory Transfer Cost and Reachability](https://arxiv.org/abs/2508.02911)
*Zhong Zhang,Francesco Topputo*

Main category: cs.LG

TL;DR: 该研究提出了一种新的神经网络方法，可以准确预测低推力任务的燃料消耗和轨迹可达性，并且具有良好的泛化能力，能够应用于各种任务场景。


<details>
  <summary>Details</summary>
Motivation: 低推力任务在轨迹设计中，燃料消耗和轨迹可达性是两个关键的性能指标。

Method: 利用确认的尺度定律（Scaling Law）适用于低推力轨迹近似，并采用提出的同伦射线法（homotopy ray method）构建了最大的数据集。将数据转化为自相似空间，使神经网络能够适应任意的半长轴、倾角和中心天体。

Result: 所提出的神经网络在预测速度增量方面达到了0.78%的相对误差，在预测最小转移时间方面达到了0.63%的相对误差。模型已在第三方数据集、多次飞越任务设计问题和任务分析场景中得到验证，证明了其泛化能力、预测精度和计算效率。

Conclusion: 该研究提出了通用的预训练神经网络，用于预测低推力任务的燃料消耗和轨迹可达性。通过构建大规模数据集并将其转化为自相似空间，使得神经网络能够适应任意的轨道根数和中心天体，无需重新训练即可泛化到各种任务场景。该研究实现了目前最通用、最准确的低推力轨迹近似器，预测精度高，并已在多种场景下得到验证。

Abstract: In trajectory design, fuel consumption and trajectory reachability are two
key performance indicators for low-thrust missions. This paper proposes
general-purpose pretrained neural networks to predict these metrics. The
contributions of this paper are as follows: Firstly, based on the confirmation
of the Scaling Law applicable to low-thrust trajectory approximation, the
largest dataset is constructed using the proposed homotopy ray method, which
aligns with mission-design-oriented data requirements. Secondly, the data are
transformed into a self-similar space, enabling the neural network to adapt to
arbitrary semi-major axes, inclinations, and central bodies. This extends the
applicability beyond existing studies and can generalize across diverse mission
scenarios without retraining. Thirdly, to the best of our knowledge, this work
presents the current most general and accurate low-thrust trajectory
approximator, with implementations available in C++, Python, and MATLAB. The
resulting neural network achieves a relative error of 0.78% in predicting
velocity increments and 0.63% in minimum transfer time estimation. The models
have also been validated on a third-party dataset, multi-flyby mission design
problem, and mission analysis scenario, demonstrating their generalization
capability, predictive accuracy, and computational efficiency.

</details>


### [206] [On the Theory and Practice of GRPO: A Trajectory-Corrected Approach with Fast Convergence](https://arxiv.org/abs/2508.02833)
*Lei Pang,Ruinan Jin*

Main category: cs.LG

TL;DR: GRPO是一种用于微调大语言模型的无评论员强化学习算法，通过使用组归一化奖励替代价值函数。研究发现GRPO的策略梯度估计存在偏差，但实践影响不大。在此基础上提出的TIC GRPO算法，通过使用轨迹级别的重要性修正，实现了对当前策略梯度的无偏估计，并提供了理论收敛性分析。


<details>
  <summary>Details</summary>
Motivation: GRPO的实现方式引发了对其策略梯度估计偏差的思考，促使研究者去探寻更优的更新方式，最终提出了TIC GRPO。

Method: GRPO通过使用组归一化奖励替代PPO中的价值函数，并保留PPO风格的令牌级别重要性采样来实现。TIC GRPO进一步将令牌级别的重要性比率替换为轨迹级别的概率比率。

Result: GRPO的性能与标准PPO相当，即使移除重要性采样，性能也无显著差异。TIC GRPO能提供当前策略梯度的无偏估计，并与GRPO具有相似的性能。

Conclusion: GRPO的更新规则实际上是在旧策略上估计策略梯度，而不是当前策略，但由于旧策略会定期刷新，这种差异在实践中的影响有限。TIC GRPO使用轨迹级别的概率比率替代了令牌级别的比率，从而在保持无评论员结构的同时，对当前策略梯度进行无偏估计。此外，还为GRPO及其变体提供了首次理论收敛性分析。

Abstract: Group Relative Policy Optimization (GRPO), recently proposed by DeepSeek, is
a critic-free reinforcement learning algorithm for fine tuning large language
models. It replaces the value function in Proximal Policy Optimization (PPO)
with group normalized rewards, while retaining PPO style token level importance
sampling based on an old policy. We show that GRPO update rule in fact
estimates the policy gradient at the old policy rather than the current one.
However, since the old policy is refreshed every few steps, the discrepancy
between the two remains small limiting the impact of this bias in practice. We
validate this through an ablation study in which importance sampling is
entirely removed, and updates are instead performed using the gradient
estimated at a fixed old policy across multiple optimization steps. Remarkably,
this simplification results in performance comparable to standard GRPO.
  Motivated by these findings, we propose a new algorithm: Trajectory level
Importance Corrected GRPO (TIC GRPO). TIC GRPO replaces token level importance
ratios with a single trajectory level probability ratio, yielding an unbiased
estimate of the current policy gradient while preserving the critic free
structure. Furthermore, we present the first theoretical convergence analysis
for GRPO style methods, covering both the original GRPO and our proposed
variant.

</details>


### [207] [Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization](https://arxiv.org/abs/2508.02834)
*Hanqi Feng,Peng Qiu,Mengchun Zhang,Yiran Tao,You Fan,Jingtao Xu,Barnabas Poczos*

Main category: cs.LG

TL;DR: 受 B 细胞亲和力成熟的启发，我们提出了一个创新的框架，该框架利用在线元学习系统中的基于物理的领域知识，为抗原设计开发了个性化的优化策略。


<details>
  <summary>Details</summary>
Motivation: 受 B 细胞亲和力成熟的启发，其中抗体通过平衡亲和力、稳定性和自我规避的多目标优化而进化。

Method: 利用基于物理的领域知识的在线元学习系统，包含多个专门的专家（范德华力、分子识别、能量平衡和界面几何），其参数会根据迭代反馈在生成过程中演变。

Result: 实验证明，该方法能够为不同的抗原类别发现最优的 SE(3)- 等变引导策略，而无需预先训练，在整个优化过程中保持分子对称性；通过靶向特定适应性显著提高了热点覆盖率和界面质量，实现了治疗性抗体特征的平衡多目标优化；为迭代优化提供了一个范例，其中每个抗原-抗体系统通过在线评估来学习其独特的优化曲线；在各种设计挑战中表现出有效的泛化能力，实现了精确的设计。

Conclusion: 该方法为迭代优化提供了一个范例，其中每个抗原-抗体系统都通过在线评估来学习其独特的优化曲线，能够跨越不同的设计挑战，从小的表位到大的蛋白质界面，从而为个体目标实现关注精度的设计。

Abstract: Recent advances in diffusion models have shown remarkable potential for
antibody design, yet existing approaches apply uniform generation strategies
that cannot adapt to each antigen's unique requirements. Inspired by B cell
affinity maturation, where antibodies evolve through multi-objective
optimization balancing affinity, stability, and self-avoidance, we propose the
first biologically-motivated framework that leverages physics-based domain
knowledge within an online meta-learning system. Our method employs multiple
specialized experts (van der Waals, molecular recognition, energy balance, and
interface geometry) whose parameters evolve during generation based on
iterative feedback, mimicking natural antibody refinement cycles. Instead of
fixed protocols, this adaptive guidance discovers personalized optimization
strategies for each target. Our experiments demonstrate that this approach: (1)
discovers optimal SE(3)-equivariant guidance strategies for different antigen
classes without pre-training, preserving molecular symmetries throughout
optimization; (2) significantly enhances hotspot coverage and interface quality
through target-specific adaptation, achieving balanced multi-objective
optimization characteristic of therapeutic antibodies; (3) establishes a
paradigm for iterative refinement where each antibody-antigen system learns its
unique optimization profile through online evaluation; (4) generalizes
effectively across diverse design challenges, from small epitopes to large
protein interfaces, enabling precision-focused campaigns for individual
targets.

</details>


### [208] [Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented Generation](https://arxiv.org/abs/2508.02835)
*Kennedy Edemacu,Vinay M. Shashidhar,Micheal Tuape,Dan Abudu,Beakcheol Jang,Jong Wook Kim*

Main category: cs.LG

TL;DR: RAG systems are vulnerable to knowledge poisoning attacks. We propose FilterRAG and ML-FilterRAG to defend against these attacks by filtering out adversarial texts, achieving performance close to original RAG systems.


<details>
  <summary>Details</summary>
Motivation: To address the vulnerability of Retrieval-Augmented Generation (RAG) to knowledge poisoning attacks, specifically the PoisonedRAG attack which misleads LLMs through compromised knowledge sources.

Method: Propose novel defense methods FilterRAG and ML-FilterRAG, which utilize a new property to differentiate between adversarial and clean texts in the knowledge data source for filtering.

Result: Evaluation using benchmark datasets demonstrates the effectiveness of the proposed defense methods in mitigating the PoisonedRAG attack.

Conclusion: FilterRAG and ML-FilterRAG are effective defenses against the PoisonedRAG attack, with performance close to original RAG systems.

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to
boost the capabilities of large language models (LLMs) by incorporating
external, up-to-date knowledge sources. However, this introduces a potential
vulnerability to knowledge poisoning attacks, where attackers can compromise
the knowledge source to mislead the generation model. One such attack is the
PoisonedRAG in which the injected adversarial texts steer the model to generate
an attacker-chosen response to a target question. In this work, we propose
novel defense methods, FilterRAG and ML-FilterRAG, to mitigate the PoisonedRAG
attack. First, we propose a new property to uncover distinct properties to
differentiate between adversarial and clean texts in the knowledge data source.
Next, we employ this property to filter out adversarial texts from clean ones
in the design of our proposed approaches. Evaluation of these methods using
benchmark datasets demonstrate their effectiveness, with performances close to
those of the original RAG systems.

</details>


### [209] [Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization](https://arxiv.org/abs/2508.02840)
*Chaoyang Gao,Xiang Chen,Jiyu Wang,Jibin Wang,Guang Yang*

Main category: cs.LG

TL;DR: 该研究提出了一种创新的、资源高效的框架，利用知识蒸馏和粒子群优化技术，大大减小了用于自动化漏洞评估的模型尺寸，同时保持了高准确率，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型预训练模型在实际应用中因计算和存储需求大而难以部署的问题，本研究旨在开发一种资源高效的框架，用于自动化漏洞评估。

Method: 本研究提出了一种新颖的资源高效框架，该框架集成了知识蒸馏和粒子群优化技术，以实现自动化的漏洞评估。该框架采用两阶段方法：首先，利用粒子群优化来优化紧凑的学生模型的架构，以平衡计算效率和模型容量；其次，应用知识蒸馏将大型教师模型的关键漏洞评估知识转移到优化后的学生模型。

Result: 实验结果表明，该方法在增强的MegaVul数据集上实现了99.4%的模型尺寸缩减，同时保留了原始模型89.3%的准确率。此外，该方法在准确率上比最先进的基线模型高出1.7%，参数量却减少了60%。与传统的遗传算法相比，该框架将训练时间缩短了72.1%，架构搜索时间缩短了34.88%。

Conclusion: 该研究提出了一种结合知识蒸馏和粒子群优化的资源高效框架，用于自动化漏洞评估。实验证明，该框架能显著减小模型尺寸（99.4%），同时保持高准确率（89.3%），并在参数量、训练时间和架构搜索时间方面优于现有技术。

Abstract: The increasing complexity of software systems has led to a surge in
cybersecurity vulnerabilities, necessitating efficient and scalable solutions
for vulnerability assessment. However, the deployment of large pre-trained
models in real-world scenarios is hindered by their substantial computational
and storage demands. To address this challenge, we propose a novel
resource-efficient framework that integrates knowledge distillation and
particle swarm optimization to enable automated vulnerability assessment. Our
framework employs a two-stage approach: First, particle swarm optimization is
utilized to optimize the architecture of a compact student model, balancing
computational efficiency and model capacity. Second, knowledge distillation is
applied to transfer critical vulnerability assessment knowledge from a large
teacher model to the optimized student model. This process significantly
reduces the model size while maintaining high performance. Experimental results
on an enhanced MegaVul dataset, comprising 12,071 CVSS (Common Vulnerability
Scoring System) v3 annotated vulnerabilities, demonstrate the effectiveness of
our approach. Our approach achieves a 99.4% reduction in model size while
retaining 89.3% of the original model's accuracy. Furthermore, it outperforms
state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The
framework also reduces training time by 72.1% and architecture search time by
34.88% compared to traditional genetic algorithms.

</details>


### [210] [Comparative Evaluation of Kolmogorov-Arnold Autoencoders and Orthogonal Autoencoders for Fault Detection with Varying Training Set Sizes](https://arxiv.org/abs/2508.02860)
*Enrique Luna Villagómez,Vladimir Mahalec*

Main category: cs.LG

TL;DR: KAN-AEs，特别是WavKAN-AE和EfficientKAN-AE，在无监督故障检测任务中表现优于传统的OAE，尤其是在数据量有限的情况下，它们能以更少的数据实现高故障检测率。


<details>
  <summary>Details</summary>
Motivation: 尽管KANs在监督学习中显示出潜力，但它们在无监督故障检测方面的应用仍未被充分探索。本研究旨在评估KAN-AEs在化学过程无监督故障检测中的应用。

Method: 本研究评估了四种KAN-AE变体（EfficientKAN, FastKAN, FourierKAN, WavKAN）在田纳西伊士曼过程（TEP）上的无监督故障检测性能，并与正交自编码器（OAE）进行了比较。通过在不同大小的训练数据集（13种）上训练模型，并使用13种故障类型评估模型，使用故障检测率（FDR）作为性能指标。

Result: WavKAN-AE在仅使用4000个训练样本时实现了最高的总体FDR（≥92%），并且在其他变体使用更大的数据集进行训练时，它仍然是表现最好的模型。EfficientKAN-AE在仅使用500个样本时就能达到≥90%的FDR，显示出在低数据环境下的鲁棒性。FastKAN-AE在更大的规模（≥50000个样本）下变得具有竞争力，而FourierKAN-AE的表现一直不佳。OAE基线模型性能逐渐提高，但需要更多数据才能匹配顶级的KAN-AE性能。

Conclusion: KAN-AEs在数据效率和故障检测性能方面表现出色，特别是在数据量有限的情况下，WavKAN-AE和EfficientKAN-AE显示出高故障检测率（FDR），使其成为工业应用的有希望的候选者。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a flexible and
parameter-efficient alternative to conventional neural networks. Unlike
standard architectures that use fixed node-based activations, KANs place
learnable functions on edges, parameterized by different function families.
While they have shown promise in supervised settings, their utility in
unsupervised fault detection remains largely unexplored. This study presents a
comparative evaluation of KAN-based autoencoders (KAN-AEs) for unsupervised
fault detection in chemical processes. We investigate four KAN-AE variants,
each based on a different KAN implementation (EfficientKAN, FastKAN,
FourierKAN, and WavKAN), and benchmark them against an Orthogonal Autoencoder
(OAE) on the Tennessee Eastman Process. Models are trained on normal operating
data across 13 training set sizes and evaluated on 21 fault types, using Fault
Detection Rate (FDR) as the performance metric. WavKAN-AE achieves the highest
overall FDR ($\geq$92\%) using just 4,000 training samples and remains the top
performer, even as other variants are trained on larger datasets.
EfficientKAN-AE reaches $\geq$90\% FDR with only 500 samples, demonstrating
robustness in low-data settings. FastKAN-AE becomes competitive at larger
scales ($\geq$50,000 samples), while FourierKAN-AE consistently underperforms.
The OAE baseline improves gradually but requires substantially more data to
match top KAN-AE performance. These results highlight the ability of KAN-AEs to
combine data efficiency with strong fault detection performance. Their use of
structured basis functions suggests potential for improved model transparency,
making them promising candidates for deployment in data-constrained industrial
settings.

</details>


### [211] [Streaming Generated Gaussian Process Experts for Online Learning and Control](https://arxiv.org/abs/2508.03679)
*Zewen Yang,Dongfa Zhang,Xiaobing Dai,Fengyi Yu,Chi Zhang,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.LG

TL;DR: SkyGP框架通过维护有限数量的专家，解决了精确高斯过程在处理流数据时的计算和内存瓶颈，在预测准确性和计算效率方面均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 精确高斯过程在处理流数据时，推理和在线更新的计算时间复杂度为立方，存储复杂度为平方，这限制了它们在实时环境中处理大型数据集的可扩展性。

Method: 提出了一种名为SkyGP（streaming k-induced progressively generated expert Gaussian processes）的框架，该框架通过维护一组有限的专家来解决计算和内存限制。此外，还介绍了两个SkyGP变体：SkyGP-Dense（最大化预测准确性）和SkyGP-Fast（提高计算效率）。

Result: 通过广泛的基准测试和实时控制实验验证了SkyGP的有效性，证明了其相比现有最先进方法的优越性能。

Conclusion: SkyGP框架通过维护一组有限的专家，克服了精确高斯过程在计算和内存方面的限制，同时继承了精确高斯过程的学习性能保证。

Abstract: Gaussian Processes (GPs), as a nonparametric learning method, offer flexible
modeling capabilities and calibrated uncertainty quantification for function
approximations. Additionally, GPs support online learning by efficiently
incorporating new data with polynomial-time computation, making them
well-suited for safety-critical dynamical systems that require rapid
adaptation. However, the inference and online updates of exact GPs, when
processing streaming data, incur cubic computation time and quadratic storage
memory complexity, limiting their scalability to large datasets in real-time
settings. In this paper, we propose a \underline{s}treaming
\underline{k}ernel-induced progressivel\underline{y} generated expert framework
of \underline{G}aussian \underline{p}rocesses (SkyGP) that addresses both
computational and memory constraints by maintaining a bounded set of experts,
while inheriting the learning performance guarantees from exact Gaussian
processes. Furthermore, two SkyGP variants are introduced, each tailored to a
specific objective, either maximizing prediction accuracy (SkyGP-Dense) or
improving computational efficiency (SkyGP-Fast). The effectiveness of SkyGP is
validated through extensive benchmarks and real-time control experiments
demonstrating its superior performance compared to state-of-the-art approaches.

</details>


### [212] [Beyond Least Squares: Robust Regression Transformer (R2T)](https://arxiv.org/abs/2508.02874)
*Roman Gutierrez,Tony Kai Tang,Isabel Gutierrez*

Main category: cs.LG

TL;DR: 提出了一种混合神经-符号方法，利用Transformer和神经网络来处理非对称噪声，在可穿戴设备数据上取得了比传统方法好10-300倍的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的稳健回归技术依赖于最小二乘法优化，在存在非对称结构噪声时效果不佳。因此，需要新的方法来处理此类噪声。

Method: 提出了一种混合神经-符号架构，包括一个处理数值序列的Transformer编码器、一个预测符号参数的压缩神经网络以及一个用于重构原始序列的固定符号方程。该模型通过在添加非对称结构噪声后恢复原始序列来学习符号拟合，并以神经网络参数估计为指导。

Result: 在合成可穿戴数据上，该模型实现了6e-6至3.5e-5的中值回归MSE，相比普通最小二乘法和Huber损失或SoftL1等稳健回归技术，性能提高了10到300倍。

Conclusion: 所提出的混合神经-符号架构在处理非对称结构噪声方面优于传统的最小二乘法和稳健回归技术，在合成可穿戴数据上实现了显著的回归MSE改进。

Abstract: Robust regression techniques rely on least-squares optimization, which works
well for Gaussian noise but fails in the presence of asymmetric structured
noise. We propose a hybrid neural-symbolic architecture where a transformer
encoder processes numerical sequences, a compression NN predicts symbolic
parameters, and a fixed symbolic equation reconstructs the original sequence.
Using synthetic data, the training objective is to recover the original
sequence after adding asymmetric structured noise, effectively learning a
symbolic fit guided by neural parameter estimation. Our model achieves a median
regression MSE of 6e-6 to 3.5e-5 on synthetic wearable data, which is a 10-300
times improvement when compared with ordinary least squares fit and robust
regression techniques such as Huber loss or SoftL1.

</details>


### [213] [CauKer: classification time series foundation models can be pretrained on synthetic data only](https://arxiv.org/abs/2508.02879)
*Shifeng Xie,Vasilii Feofanov,Marius Alonso,Ambroise Odonnat,Jianfeng Zhang,Themis Palpanas,Ievgen Redko*

Main category: cs.LG

TL;DR: CauKer is a new algorithm that creates synthetic time series data to train AI models faster and more efficiently, showing better scaling properties than real data.


<details>
  <summary>Details</summary>
Motivation: To address the computationally costly pretraining of Time Series Foundation Models (TSFMs) on large-scale, real-world datasets, the study proposes CauKer for sample-efficient pretraining.

Method: CauKer algorithm combines Gaussian Process (GP) kernel composition with Structural Causal Models (SCM) to generate synthetic time series data with realistic trends, seasonality, and nonlinear interactions.

Result: Experiments show that CauKer-generated datasets exhibit clear scaling laws for dataset size (10K to 10M samples) and model capacity (1M to 783M parameters), unlike the irregular scaling behavior of real-world datasets. CauKer is effective for pretraining state-of-the-art classification TSFMs.

Conclusion: CauKer enables sample-efficient pretraining of TSFMs by generating diverse, causally coherent synthetic time series. It outperforms real-world datasets in terms of scaling laws for dataset size and model capacity, offering a more predictable training environment.

Abstract: Time series foundation models (TSFMs) have recently gained significant
attention due to their strong zero-shot capabilities and widespread real-world
applications. Such models typically require a computationally costly
pretraining on large-scale, carefully curated collections of real-world
sequences. To allow for a sample-efficient pretraining of TSFMs, we propose
CauKer, a novel algorithm designed to generate diverse, causally coherent
synthetic time series with realistic trends, seasonality, and nonlinear
interactions. CauKer combines Gaussian Process (GP) kernel composition with
Structural Causal Models (SCM) to produce data for sample-efficient pretraining
of state-of-the-art classification TSFMs having different architectures and
following different pretraining approaches. Additionally, our experiments
reveal that CauKer-generated datasets exhibit clear scaling laws for both
dataset size (10K to 10M samples) and model capacity (1M to 783M parameters),
unlike real-world datasets, which display irregular scaling behavior.

</details>


### [214] [Clus-UCB: A Near-Optimal Algorithm for Clustered Bandits](https://arxiv.org/abs/2508.02909)
*Aakash Gore,Prasanna Chaporkar*

Main category: cs.LG

TL;DR: A new algorithm, Clus-UCB, is proposed for a multi-armed bandit problem with clustered arms. It achieves improved regret bounds by leveraging the cluster structure for information sharing, outperforming existing methods in simulations.


<details>
  <summary>Details</summary>
Motivation: To model scenarios with multiple factors influencing outcomes, like online advertising and clinical trials, by studying a stochastic multi-armed bandit setting with known arm clusters and a known threshold for mean reward differences within clusters.

Method: The paper derives asymptotic lower bounds on regret and proposes the Clus-UCB algorithm, which exploits a known clustering structure of arms to share information and improve efficiency.

Result: Asymptotic lower bounds on regret are derived, improving upon classical bounds. The Clus-UCB algorithm is proposed, which performs efficiently and closely matches the derived lower bound.

Conclusion: Clus-UCB algorithm closely matches the derived asymptotic lower bound, outperforming other algorithms in simulations.

Abstract: We study a stochastic multi-armed bandit setting where arms are partitioned
into known clusters, such that the mean rewards of arms within a cluster differ
by at most a known threshold. While the clustering structure is known a priori,
the arm means are unknown. This framework models scenarios where outcomes
depend on multiple factors -- some with significant and others with minor
influence -- such as online advertising, clinical trials, and wireless
communication. We derive asymptotic lower bounds on the regret that improve
upon the classical bound of Lai & Robbins (1985). We then propose Clus-UCB, an
efficient algorithm that closely matches this lower bound asymptotically.
Clus-UCB is designed to exploit the clustering structure and introduces a new
index to evaluate an arm, which depends on other arms within the cluster. In
this way, arms share information among each other. We present simulation
results of our algorithm and compare its performance against KL-UCB and other
well-known algorithms for bandits with dependent arms. Finally, we address some
limitations of this work and conclude by mentioning possible future research.

</details>


### [215] [BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling](https://arxiv.org/abs/2508.02924)
*Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan*

Main category: cs.LG

TL;DR: BoostTransformer通过集成提升原则，解决了Transformer计算量大和调参难的问题，并在文本分类任务上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了缓解Transformer模型计算资源消耗大和超参数调整复杂的问题。

Method: 提出了一种新颖的框架BoostTransformer，它通过子网格标记选择和重要性加权采样，并结合最小二乘提升目标，来增强Transformer。

Result: BoostTransformer在多个细粒度文本分类基准测试中，展示了更快的收敛速度和更高的准确性。

Conclusion: BoostTransformer通过结合子网格标记选择和重要性加权采样，并直接将最小二乘提升目标纳入Transformer流水线，实现了更高效的训练和更高的准确性，超越了标准Transformer，同时减少了架构搜索的开销。

Abstract: Transformer architectures dominate modern NLP but often demand heavy
computational resources and intricate hyperparameter tuning. To mitigate these
challenges, we propose a novel framework, BoostTransformer, that augments
transformers with boosting principles through subgrid token selection and
importance-weighted sampling. Our method incorporates a least square boosting
objective directly into the transformer pipeline, enabling more efficient
training and improved performance. Across multiple fine-grained text
classification benchmarks, BoostTransformer demonstrates both faster
convergence and higher accuracy, surpassing standard transformers while
minimizing architectural search overhead.

</details>


### [216] [GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics](https://arxiv.org/abs/2508.02926)
*Arthur Cho*

Main category: cs.LG

TL;DR: GrandJury是一个评估协议，通过结合时间衰减聚合、可追溯性、动态任务归因和多评分者判断，来解决标准评估方法中固有的挑战，以实现对LLM输出的更有效的评估。


<details>
  <summary>Details</summary>
Motivation: 标准评估机制仍然依赖于静态、基准风格的测试，鼓励优化排行榜分数而不是与动态用户需求或不断变化的事实保持一致。

Method: GrandJury引入了一个结合时间衰减聚合、完全可追溯性、动态、透明任务图谱归因支持以及多评分者人类判断的正式评估协议。

Result: GrandJury提供了一个新的范式，用于在没有绝对真实情况的情况下评估机器学习输出。

Conclusion: GrandJury提供了一种新的AI实践者在评估机器学习输出而无需绝对真实情况的范式。

Abstract: Generative Machine Learning models have become central to modern systems,
powering applications in creative writing, summarization, multi-hop reasoning,
and context-aware dialogue. These models underpin large-scale AI assistants,
workflow automation, and autonomous decision-making. In such domains,
acceptable response is rarely absolute or static, but plural and highly
context-dependent. Yet standard evaluation regimes still rely on static,
benchmark-style tests, incentivizing optimization toward leaderboard scores
rather than alignment with dynamic user needs or evolving realities. GrandJury
introduces a formal evaluation protocol combining time-decayed aggregation,
complete traceability, with the support of dynamic, transparent task rubric
attribution, and multi-rater human judgment. Together, these elements enable
pluralistic, accountable evaluation that captures evolving consensus and
surfaces disagreement. We provide an open-source implementation (grandjury PyPI
package) and a public collection of Large Language Model (LLM) inference
outputs to illustrate the need and method. GrandJury provides a new paradigm
for AI practitioners when evaluating machine learning outputs without absolute
ground truth.

</details>


### [217] [PLoRA: Efficient LoRA Hyperparameter Tuning for Large Models](https://arxiv.org/abs/2508.02932)
*Minghao Yan,Zhuang Wang,Zhen Jia,Shivaram Venkataraman,Yida Wang*

Main category: cs.LG

TL;DR: PLoRA通过优化训练过程和硬件利用率，显著提高了LoRA微调的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA服务效率研究假设有大量的LoRA适配器可用，但忽视了当前训练范式未能有效利用硬件资源以及获取高性能LoRA的开销高昂的问题。

Method: PLoRA通过自动协调并发LoRA微调任务和开发高性能内核来提高训练效率。

Result: PLoRA将LoRA微调的跨越时间缩短了7.52倍，并将训练吞吐量提高了12.8倍。

Conclusion: PLoRA通过自动协调并发LoRA微调任务和开发高性能内核来提高训练效率，在LLM上将LoRA微调的跨越时间缩短了7.52倍，并将训练吞吐量提高了12.8倍。

Abstract: Low-rank Adaptation (LoRA) has gained popularity as a fine-tuning approach
for Large Language Models (LLMs) due to its low resource requirements and good
performance. While a plethora of work has investigated improving LoRA serving
efficiency by serving multiple LoRAs concurrently, existing methods assume that
a wide range of LoRA adapters are available for serving. In our work, we
conduct extensive empirical studies to identify that current training paradigms
do not utilize hardware resources efficiently and require high overhead to
obtain a performant LoRA. Leveraging these insights, we propose PLoRA, which
automatically orchestrates concurrent LoRA fine-tuning jobs under given
hardware and model constraints and develops performant kernels to improve
training efficiency. Our experimental studies show that PLoRA reduces the
makespan of LoRA fine-tuning over a given hyperparameter search space by up to
7.52x and improves training throughput by up to 12.8x across a range of
state-of-the-art LLMs.

</details>


### [218] [Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver](https://arxiv.org/abs/2508.02964)
*Jonathan Patsenker,Henry Li,Myeongseob Ko,Ruoxi Jia,Yuval Kluger*

Main category: cs.LG

TL;DR: 提出了一种新的扩散模型逆求解方法，可以直接利用测量值 $\mathbf{y}$ 来估计条件后验均值，从而实现更快速、更内存高效的求解，并在多个任务上表现出与现有方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型逆求解方法通常依赖于 Tweedie 公式，该公式将扩散变量 $\mathbf{x}_t$ 与后验均值 $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$ 联系起来，以指导扩散轨迹，但未考虑测量值 $\mathbf{y}$ 的信息。

Method: 提出估计条件后验均值 $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$ 的方法，该方法可构建为轻量级、单参数最大似然估计问题的解决方案。

Result: 所提出的优化器易于实现基于噪声感知的、基于似然的停止标准，该标准可抵抗 $\mathbf{y}$ 中的测量噪声。

Conclusion: 所提出的估计条件后验均值的方法可以集成到任何标准采样器中，从而实现快速、内存高效的逆求解器，并且与一系列当代逆求解器相比，在多个数据集和任务上具有可比或更优的性能。

Abstract: Diffusion models have been firmly established as principled zero-shot solvers
for linear and nonlinear inverse problems, owing to their powerful image prior
and iterative sampling algorithm. These approaches often rely on Tweedie's
formula, which relates the diffusion variate $\mathbf{x}_t$ to the posterior
mean $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$, in order to guide the
diffusion trajectory with an estimate of the final denoised sample
$\mathbf{x}_0$. However, this does not consider information from the
measurement $\mathbf{y}$, which must then be integrated downstream. In this
work, we propose to estimate the conditional posterior mean $\mathbb{E}
[\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$, which can be formulated as the
solution to a lightweight, single-parameter maximum likelihood estimation
problem. The resulting prediction can be integrated into any standard sampler,
resulting in a fast and memory-efficient inverse solver. Our optimizer is
amenable to a noise-aware likelihood-based stopping criteria that is robust to
measurement noise in $\mathbf{y}$. We demonstrate comparable or improved
performance against a wide selection of contemporary inverse solvers across
multiple datasets and tasks.

</details>


### [219] [Scalable Varied-Density Clustering via Graph Propagation](https://arxiv.org/abs/2508.02989)
*Ninh Pham,Yingtao Zheng,Hugo Phibbs*

Main category: cs.LG

TL;DR: 提出了一种基于标签传播和图连接性的高维变密度聚类新方法，通过密度感知邻域传播和随机投影提高计算效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了在高维数据中实现变密度聚类，并解决现有方法的计算效率和可扩展性问题，提出了一种新的聚类视角，将其与图的连通性联系起来。

Method: 提出了一种将变密度聚类视为标签传播过程的新方法，该方法通过构建自适应局部密度变化的邻域图来实现。为了提高可扩展性，引入了密度感知邻域传播算法，并结合了随机投影方法来构建近似邻域图。

Result: 该方法在处理数百万数据点时，能够在几分钟内完成，并且聚类准确性与现有基线方法相比具有竞争力，显著降低了计算成本，同时保持了聚类质量。

Conclusion: 该方法通过将变密度聚类视为标签传播过程，并利用网络科学中的图传播技术，实现了高维数据的聚类，并保证了计算的可扩展性。最终实现了在处理数百万数据点时，在几分钟内即可获得具有竞争力的准确性。

Abstract: We propose a novel perspective on varied-density clustering for
high-dimensional data by framing it as a label propagation process in
neighborhood graphs that adapt to local density variations. Our method formally
connects density-based clustering with graph connectivity, enabling the use of
efficient graph propagation techniques developed in network science. To ensure
scalability, we introduce a density-aware neighborhood propagation algorithm
and leverage advanced random projection methods to construct approximate
neighborhood graphs. Our approach significantly reduces computational cost
while preserving clustering quality. Empirically, it scales to datasets with
millions of points in minutes and achieves competitive accuracy compared to
existing baselines.

</details>


### [220] [On the Fast Adaptation of Delayed Clients in Decentralized Federated Learning: A Centroid-Aligned Distillation Approach](https://arxiv.org/abs/2508.02993)
*Jiahui Bai,Hai Dong,A. K. Qin*

Main category: cs.LG

TL;DR: DFedCAD通过模型压缩和知识对齐解决了去中心化联邦学习中客户端适应缓慢和通信成本高的问题，显著提高了准确性并降低了开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决去中心化联邦学习（DFL）在异步环境中面临的迟到的加入的客户端适应缓慢和通信成本高昂的问题，我们提出了DFedCAD。

Method: DFedCAD采用加权聚类剪枝（WCP）来压缩模型为代表性质心，以降低通信开销。它利用新颖的结构距离度量和可微分的k-means蒸馏模块，使延迟客户端能够智能地权衡和对齐同伴知识，从而实现高效的端到端知识转移。

Result: DFedCAD在CIFAR-10、CIFAR-100和Tiny-ImageNet上的广泛实验表明，DFedCAD始终 achieves最先进的性能，在所有评估的设置中均实现了最高的准确性，同时通信开销减少了86%以上。

Conclusion: DFedCAD是一个可扩展且实用的解决方案，能够为动态、真实场景中的高效去中心化学习提供支持。

Abstract: Decentralized Federated Learning (DFL) struggles with the slow adaptation of
late-joining delayed clients and high communication costs in asynchronous
environments. These limitations significantly hinder overall performance. To
address this, we propose DFedCAD, a novel framework for rapid adaptation via
Centroid-Aligned Distillation. DFedCAD first employs Weighted Cluster Pruning
(WCP) to compress models into representative centroids, drastically reducing
communication overhead. It then enables delayed clients to intelligently weigh
and align with peer knowledge using a novel structural distance metric and a
differentiable k-means distillation module, facilitating efficient end-to-end
knowledge transfer. Extensive experiments on CIFAR-10, CIFAR-100, and
Tiny-ImageNet show that DFedCAD consistently achieves state-of-the-art
performance, attaining the highest accuracy across all evaluated settings while
reducing communication overhead by over 86%. Our framework provides a scalable
and practical solution for efficient decentralized learning in dynamic,
real-world scenarios.

</details>


### [221] [Where and How to Enhance: Discovering Bit-Width Contribution for Mixed Precision Quantization](https://arxiv.org/abs/2508.03002)
*Haidong Kang,Lianbo Ma,Guo Yu,Shangce Gao*

Main category: cs.LG

TL;DR: 混合精度量化（MPQ）通过为不同层分配不同比特宽度来优化神经网络的精度-复杂度权衡。现有方法（DMPQ）假设量化参数的幅度反映了比特宽度对精度的贡献，但本文认为这种假设不一定成立。因此，本文提出 SMPQ 方法，直接衡量比特宽度对 MPQ 任务的贡献，并通过蒙特卡洛采样降低计算成本。实验证明 SMPQ 优于 DMPQ。


<details>
  <summary>Details</summary>
Motivation: 现有的混合精度量化（MPQ）方法通常采用梯度下降法优化量化策略，并假设量化参数的幅度反映了比特宽度对准确率提升的贡献。然而，本文认为量化参数的幅度并不一定能反映比特宽度对任务性能的实际贡献。

Method: 本文提出了一种基于 Shapley 的混合精度量化（SMPQ）方法，并提出了一种基于蒙特卡洛采样的 Shapley 计算近似策略以降低计算成本。

Result: 提出的 SMPQ 方法通过衡量比特宽度操作对 MPQ 任务的直接贡献，在主流基准测试中取得了优于基于梯度的竞争对手的 state-of-the-art performance。

Conclusion: 本文提出了一种基于 Shapley 的混合精度量化（SMPQ）方法，通过衡量比特宽度操作对 MPQ 任务的直接贡献来优化量化策略。与现有的基于梯度的量化方法相比，SMPQ 在主流基准测试中始终 achieves state-of-the-art performance。

Abstract: Mixed precision quantization (MPQ) is an effective quantization approach to
achieve accuracy-complexity trade-off of neural network, through assigning
different bit-widths to network activations and weights in each layer. The
typical way of existing MPQ methods is to optimize quantization policies (i.e.,
bit-width allocation) in a gradient descent manner, termed as Differentiable
(DMPQ). At the end of the search, the bit-width associated to the quantization
parameters which has the largest value will be selected to form the final mixed
precision quantization policy, with the implicit assumption that the values of
quantization parameters reflect the operation contribution to the accuracy
improvement. While much has been discussed about the MPQ improvement, the
bit-width selection process has received little attention. We study this
problem and argue that the magnitude of quantization parameters does not
necessarily reflect the actual contribution of the bit-width to the task
performance. Then, we propose a Shapley-based MPQ (SMPQ) method, which measures
the bit-width operation direct contribution on the MPQ task. To reduce
computation cost, a Monte Carlo sampling-based approximation strategy is
proposed for Shapley computation. Extensive experiments on mainstream
benchmarks demonstrate that our SMPQ consistently achieves state-of-the-art
performance than gradient-based competitors.

</details>


### [222] [Urban In-Context Learning: Bridging Pretraining and Inference through Masked Diffusion for Urban Profiling](https://arxiv.org/abs/2508.03042)
*Ruixing Zhang,Bo Wang,Tongyu Zhu,Leilei Sun,Weifeng Lv*

Main category: cs.LG

TL;DR: 提出了一种新的“城市上下文学习”框架，通过掩码自动编码和扩散模型统一了城市数据预训练和推理，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常遵循两阶段范例，需要特定任务的微调。受 GPT 风格模型发展的启发，本研究旨在开发一种可以消除任务特定微调需求的一阶段模型。

Method: 提出了一种名为“城市上下文学习”的框架，该框架通过城市区域的掩码自动编码过程统一了预训练和推理。引入了“城市掩码扩散 Transformer”来捕获城市分布，并提出“城市表示对齐机制”来稳定训练。

Result: 该方法在三个指标和两个城市的实验中，一致优于最先进的两阶段方法。消融研究和案例研究进一步验证了所提出的每个模块的有效性，特别是扩散建模的用途。

Conclusion: 提出的“城市上下文学习”框架通过掩码自动编码过程统一了预训练和推理，并在城市区域的预测中取得了优于最先进的两阶段方法。

Abstract: Urban profiling aims to predict urban profiles in unknown regions and plays a
critical role in economic and social censuses. Existing approaches typically
follow a two-stage paradigm: first, learning representations of urban areas;
second, performing downstream prediction via linear probing, which originates
from the BERT era. Inspired by the development of GPT style models, recent
studies have shown that novel self-supervised pretraining schemes can endow
models with direct applicability to downstream tasks, thereby eliminating the
need for task-specific fine-tuning. This is largely because GPT unifies the
form of pretraining and inference through next-token prediction. However, urban
data exhibit structural characteristics that differ fundamentally from
language, making it challenging to design a one-stage model that unifies both
pretraining and inference. In this work, we propose Urban In-Context Learning,
a framework that unifies pretraining and inference via a masked autoencoding
process over urban regions. To capture the distribution of urban profiles, we
introduce the Urban Masked Diffusion Transformer, which enables each region' s
prediction to be represented as a distribution rather than a deterministic
value. Furthermore, to stabilize diffusion training, we propose the Urban
Representation Alignment Mechanism, which regularizes the model's intermediate
features by aligning them with those from classical urban profiling methods.
Extensive experiments on three indicators across two cities demonstrate that
our one-stage method consistently outperforms state-of-the-art two-stage
approaches. Ablation studies and case studies further validate the
effectiveness of each proposed module, particularly the use of diffusion
modeling.

</details>


### [223] [A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning](https://arxiv.org/abs/2508.03046)
*Tatwadarshi P Nagarhalli,Sanket Patil,Vishal Pande,Uday Aswalekar,Prafulla Patil*

Main category: cs.LG

TL;DR: 该研究提出了一种整合MRI、认知评估和生物标志物数据的多模态框架，利用CNN和LSTM网络进行分析，以实现阿尔茨海默病（AD）的早期精准检测，提高了诊断的准确性和可靠性，尤其是在数据不完整的情况下。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期诊断困难，常导致治疗延迟和不良预后。传统诊断方法依赖单一数据源，无法全面反映疾病的复杂性。因此，需要一种能够整合多源数据以提高早期检测能力的新方法。

Method: 本研究提出了一种结合卷积神经网络（CNN）分析MRI影像和长短期记忆（LSTM）网络处理认知及生物标志物数据的新型多模态框架。通过加权平均等高级技术整合不同模态的结果，以提高诊断的准确性和可靠性，即使在数据不完整的情况下也能有效运作。

Result: 该多模态框架通过整合MRI影像、认知评估和生物标志物数据，并利用CNN和LSTM网络进行分析，提高了阿尔茨海默病早期检测的准确性和可靠性。即使在数据不完整的情况下，该框架也能通过聚合各模态的结果有效运作，为早期干预和治疗提供了新的途径。

Conclusion: 该研究提出了一种创新的多模态框架，用于阿尔茨海默病（AD）的早期检测，通过整合MRI影像、认知评估和生物标志物数据，并利用CNN和LSTM网络进行分析，最终通过加权平均等技术聚合各模态结果，提高了诊断的准确性和可靠性，尤其是在数据不完整的情况下。该方法能够识别出疾病的早期阶段，甚至在临床症状出现之前，为早期干预提供了可能性。

Abstract: Alzheimers Disease (AD) is a progressive neurodegenerative disorder that
poses significant challenges in its early diagnosis, often leading to delayed
treatment and poorer outcomes for patients. Traditional diagnostic methods,
typically reliant on single data modalities, fall short of capturing the
multifaceted nature of the disease. In this paper, we propose a novel
multimodal framework for the early detection of AD that integrates data from
three primary sources: MRI imaging, cognitive assessments, and biomarkers. This
framework employs Convolutional Neural Networks (CNN) for analyzing MRI images
and Long Short-Term Memory (LSTM) networks for processing cognitive and
biomarker data. The system enhances diagnostic accuracy and reliability by
aggregating results from these distinct modalities using advanced techniques
like weighted averaging, even in incomplete data. The multimodal approach not
only improves the robustness of the detection process but also enables the
identification of AD at its earliest stages, offering a significant advantage
over conventional methods. The integration of biomarkers and cognitive tests is
particularly crucial, as these can detect Alzheimer's long before the onset of
clinical symptoms, thereby facilitating earlier intervention and potentially
altering the course of the disease. This research demonstrates that the
proposed framework has the potential to revolutionize the early detection of
AD, paving the way for more timely and effective treatments

</details>


### [224] [VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision](https://arxiv.org/abs/2508.03058)
*Dingwei Zhu,Shihan Dou,Zhiheng Xi,Senjie Jin,Guoqiang Zhang,Jiazheng Zhang,Junjie Ye,Mingxu Chai,Enyu Zhou,Ming Zhang,Caishuang Huang,Yunke Zhang,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: VRPO通过增强值模型来应对RLHF中的奖励噪声，提升策略的稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: RLHF在真实世界中常面临噪声或不完美的奖励监督，影响策略的稳定性和泛化能力。现有方法多关注奖励去噪或过滤差数据，忽略了值模型在策略优化中的关键作用。

Method: VRPO框架，结合了由熵和困惑度引导的辅助损失（来自冻结的语言模型）以及变分信息瓶颈，以增强值模型在优势估计中过滤噪声和捕获上下文关键信息的能力。

Result: 在数学推理、科学问答和多轮对话任务中，无论是在基于规则还是基于模型的噪声奖励下，VRPO都持续优于PPO和GRPO基线。

Conclusion: RLHF在嘈杂或不完美的奖励监督下，VRPO框架通过增强值模型的鲁棒性，能够稳定和泛化策略，有效缓解噪声问题，并在数学推理、科学问答和多轮对话等多个任务上优于PPO和GRPO基线。

Abstract: Reinforcement Learning from Human Feedback (RLHF) often suffers from noisy or
imperfect reward supervision in real-world settings, which undermines policy
stability and generalization. Such noise may cause models to lose attention on
key words during advantage estimation. While prior work focuses on reward
denoising or filtering poor data, it often overlooks the critical role of the
value model in policy optimization. In this work, we show that a strong value
model is essential for mitigating noise by absorbing unstable signals and
enabling more reliable advantage estimation. We propose VRPO, a value-centric
framework for robust PPO training under noisy supervision. VRPO combines two
core designs: (1) an auxiliary loss guided by entropy and perplexity from a
frozen language model, and (2) a variational information bottleneck. These
mechanisms enhance the value model's ability to filter out noise and capture
key words from the context during advantage estimation, transforming it from a
passive predictor into an active regulator of noise. Experiments on math
reasoning, science QA, and multi-turn dialogue, under both rule-based and
model-based noisy rewards, show that VRPO consistently outperforms PPO and GRPO
baselines. Our findings underscore the often-overlooked importance of the value
model in RLHF and offer a principled and practical approach to robust policy
optimization in noisy real-world environments.

</details>


### [225] [Achieving Limited Adaptivity for Multinomial Logistic Bandits](https://arxiv.org/abs/2508.03072)
*Sukruta Prakash Midigeshi,Tanmay Goyal,Gaurav Sinha*

Main category: cs.LG

TL;DR: 提出B-MNL-CB和RS-MNL算法，用于策略更新次数有限的多项式逻辑土匪问题，在理论和实验上均表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 在多项式逻辑土匪问题中，虽然现有算法在理论上实现了最优遗憾和计算效率，但在实际应用中，存在策略更新次数有限（$M$次）的需求。本文旨在开发具有这种限制性适应性的算法。

Method: B-MNL-CB算法扩展了分布最优设计的概念到多项式设置，RS-MNL算法则适用于对抗生成的上下文。两种算法都旨在解决多项式逻辑土匪问题中策略更新次数有限的挑战。

Result: B-MNL-CB算法在随机生成的上下文和$	ilde{O}(	ext{log log T})$的更新轮数下，实现了$	ilde{O}(	ext{T})$的遗憾。RS-MNL算法在对抗生成的上下文和$	ilde{O}(	ext{log T})$的更新轮数下，也能实现$	ilde{O}(	ext{T})$的遗憾。实验结果表明，所提出的算法在固定更新次数的情况下，性能与多次更新的基线算法相当甚至更优。

Conclusion: 本文提出了两种用于多项逻辑土匪问题的算法B-MNL-CB和RS-MNL，它们分别适用于批量和稀疏切换的场景。这两种算法在策略更新次数有限的情况下，能够实现接近最优的遗憾边界（$	ilde{O}(	ext{T})$），并且在实验中表现出与标准算法相当甚至更优的性能，证明了其在实际应用中的有效性。

Abstract: Multinomial Logistic Bandits have recently attracted much attention due to
their ability to model problems with multiple outcomes. In this setting, each
decision is associated with many possible outcomes, modeled using a multinomial
logit function. Several recent works on multinomial logistic bandits have
simultaneously achieved optimal regret and computational efficiency. However,
motivated by real-world challenges and practicality, there is a need to develop
algorithms with limited adaptivity, wherein we are allowed only $M$ policy
updates. To address these challenges, we present two algorithms, B-MNL-CB and
RS-MNL, that operate in the batched and rarely-switching paradigms,
respectively. The batched setting involves choosing the $M$ policy update
rounds at the start of the algorithm, while the rarely-switching setting can
choose these $M$ policy update rounds in an adaptive fashion. Our first
algorithm, B-MNL-CB extends the notion of distributional optimal designs to the
multinomial setting and achieves $\tilde{O}(\sqrt{T})$ regret assuming the
contexts are generated stochastically when presented with $\Omega(\log \log T)$
update rounds. Our second algorithm, RS-MNL works with adversarially generated
contexts and can achieve $\tilde{O}(\sqrt{T})$ regret with $\tilde{O}(\log T)$
policy updates. Further, we conducted experiments that demonstrate that our
algorithms (with a fixed number of policy updates) are extremely competitive
(and often better) than several state-of-the-art baselines (which update their
policy every round), showcasing the applicability of our algorithms in various
practical scenarios.

</details>


### [226] [HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation](https://arxiv.org/abs/2508.03104)
*Mengting Pan,Fan Li,Xiaoyang Wang,Wenjie Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: HiTeC是一个用于文本属性超图的二阶段层次化对比学习框架，通过结构感知预训练、语义感知增强和多尺度对比损失，解决了现有方法的局限性，提高了可扩展性和表示质量。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法在处理文本属性超图时存在三个主要局限性：1.图不可知的文本编码器忽略了文本与超图拓扑之间的相关性；2.随机数据增强引入噪声并削弱了对比目标；3.仅关注节点和超边级别的对比信号限制了捕捉长距离依赖的能力。此外，HyperBERT的可扩展性较差。

Method: HiTeC是一个两阶段的层次化对比学习框架，包含语义感知增强。第一阶段，通过结构感知对比目标预训练文本编码器；第二阶段，引入了提示增强文本增强和语义感知超边丢弃两种策略来生成信息丰富的视图，并提出了基于s-walk的子图级对比来捕获长距离依赖关系。

Result: HiTeC在大量实验中被证明是有效的。

Conclusion: HiTeC通过解耦文本编码器预训练和超图对比学习，以及引入多尺度的对比损失，有效解决了现有方法在文本属性超图上的局限性，提高了可扩展性和表示质量，并在大量实验中得到了验证。

Abstract: Contrastive learning (CL) has become a dominant paradigm for self-supervised
hypergraph learning, enabling effective training without costly labels.
However, node entities in real-world hypergraphs are often associated with rich
textual information, which is overlooked in prior works. Directly applying
existing CL-based methods to such text-attributed hypergraphs (TAHGs) leads to
three key limitations: (1) The common use of graph-agnostic text encoders
overlooks the correlations between textual content and hypergraph topology,
resulting in suboptimal representations. (2) Their reliance on random data
augmentations introduces noise and weakens the contrastive objective. (3) The
primary focus on node- and hyperedge-level contrastive signals limits the
ability to capture long-range dependencies, which is essential for expressive
representation learning. Although HyperBERT pioneers CL on TAHGs, its
co-training paradigm suffers from poor scalability. To fill the research gap,
we introduce HiTeC, a two-stage hierarchical contrastive learning framework
with semantic-aware augmentation for scalable and effective self-supervised
learning on TAHGs. In the first stage, we pre-train the text encoder with a
structure-aware contrastive objective to overcome the graph-agnostic nature of
conventional methods. In the second stage, we introduce two semantic-aware
augmentation strategies, including prompt-enhanced text augmentation and
semantic-aware hyperedge drop, to facilitate informative view generation.
Furthermore, we propose a multi-scale contrastive loss that extends existing
objectives with an $s$-walk-based subgraph-level contrast to better capture
long-range dependencies. By decoupling text encoder pretraining from hypergraph
contrastive learning, this two-stage design enhances scalability without
compromising representation quality. Extensive experiments confirm the
effectiveness of HiTeC.

</details>


### [227] [Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov-Based Analysis](https://arxiv.org/abs/2508.03105)
*Yuichi Kondo,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 引入了一种新的李雅普诺夫函数，用于分析动态学习率和批次大小下的随机梯度下降（SGDM）收敛行为。证明了增加批次大小的策略（无论学习率如何）比恒定批次大小的策略收敛性更好，并且在学习率增加时收敛速度更快。实验结果验证了理论，并表明预热策略在实践中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了分析SGDM在动态学习率和批次大小下的收敛行为，并提供比现有方法更简单的理论分析。

Method: 提出了一种新颖的李雅普诺夫函数，用于分析带有动量（SGDM）的随机梯度下降在动态学习率和批次大小策略下的收敛行为，并统一分析了各种动态策略。

Result: 研究结果表明，(ii) 增加批次大小并衰减学习率和 (iii) 增加批次大小并增加学习率的策略能够保证收敛，而 (i) 恒定批次大小并衰减学习率的策略则不能保证预期梯度范数的收敛。(iii) 的收敛速度优于 (i) 和 (ii)，证明了即使存在动量，理论上的加速效果。(iii) 具有可证明的更快的衰减率。(iii) 提供了理论上的加速，即使在动量存在的情况下。

Conclusion: 该研究为深度学习中高效稳定的训练过程设计提供了统一的理论基础和实践指导。

Abstract: We analyze the convergence behavior of stochastic gradient descent with
momentum (SGDM) under dynamic learning rate and batch size schedules by
introducing a novel Lyapunov function. This Lyapunov function has a simpler
structure compared with existing ones, facilitating the challenging convergence
analysis of SGDM and a unified analysis across various dynamic schedules.
Specifically, we extend the theoretical framework to cover three practical
scheduling strategies commonly used in deep learning: (i) constant batch size
with a decaying learning rate, (ii) increasing batch size with a decaying
learning rate, and (iii) increasing batch size with an increasing learning
rate. Our theoretical results reveal a clear hierarchy in convergence behavior:
while (i) does not guarantee convergence of the expected gradient norm, both
(ii) and (iii) do. Moreover, (iii) achieves a provably faster decay rate than
(i) and (ii), demonstrating theoretical acceleration even in the presence of
momentum. Empirical results validate our theory, showing that dynamically
scheduled SGDM significantly outperforms fixed-hyperparameter baselines in
convergence speed. We also evaluated a warm-up schedule in experiments, which
empirically outperformed all other strategies in convergence behavior. These
findings provide a unified theoretical foundation and practical guidance for
designing efficient and stable training procedures in modern deep learning.

</details>


### [228] [Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2508.03108)
*Tarhib Al Azad,Faizul Rakib Sayem,Shahana Ibrahim*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Out-of-distribution (OOD) detection lies at the heart of robust artificial
intelligence (AI), aiming to identify samples from novel distributions beyond
the training set. Recent approaches have exploited feature representations as
distinguishing signatures for OOD detection. However, most existing methods
rely on restrictive assumptions on the feature space that limit the
separability between in-distribution (ID) and OOD samples. In this work, we
propose a novel OOD detection framework based on a pseudo-label-induced
subspace representation, that works under more relaxed and natural assumptions
compared to existing feature-based techniques. In addition, we introduce a
simple yet effective learning criterion that integrates a cross-entropy-based
ID classification loss with a subspace distance-based regularization loss to
enhance ID-OOD separability. Extensive experiments validate the effectiveness
of our framework.

</details>


### [229] [GEDAN: Learning the Edit Costs for Graph Edit Distance](https://arxiv.org/abs/2508.03111)
*Francesco Leonardi,Markus Orsi,Jean-Louis Reymond,Kaspar Riesen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Graph Edit Distance (GED) is defined as the minimum cost transformation of
one graph into another and is a widely adopted metric for measuring the
dissimilarity between graphs. The major problem of GED is that its computation
is NP-hard, which has in turn led to the development of various approximation
methods, including approaches based on neural networks (NN). Most of these
NN-based models simplify the problem of GED by assuming unit-cost edit
operations, a rather unrealistic constraint in real-world applications. In this
work, we present a novel Graph Neural Network framework that approximates GED
using both supervised and unsupervised training. In the unsupervised setting,
it employs a gradient-only self-organizing mechanism that enables optimization
without ground-truth distances. Moreover, a core component of our architecture
is the integration of a Generalized Additive Model, which allows the flexible
and interpretable learning of context-aware edit costs. Experimental results
show that the proposed method achieves similar results as state-of-the-art
reference methods, yet significantly improves both adaptability and
interpretability. That is, the learned cost function offers insights into
complex graph structures, making it particularly valuable in domains such as
molecular analysis and structural pattern discovery.

</details>


### [230] [RegMean++: Enhancing Effectiveness and Generalization of Regression Mean for Model Merging](https://arxiv.org/abs/2508.03121)
*The-Hai Nguyen,Dang Huu-Tien,Takeshi Suzuki,Le-Minh Nguyen*

Main category: cs.LG

TL;DR: RegMean++ 改进了 RegMean 模型合并方法，通过考虑跨层依赖性，在各种基准测试中取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: RegMean 在合并模型时独立地合并每个线性层，忽略了早期层中的特征和信息如何通过层传播并影响合并模型中的最终预测。

Method: RegMean++ 是一种通过明确地将合并模型层之间的层内和跨层依赖性纳入 RegMean 的目标来改进模型合并的方法。

Result: RegMean++ 在各种设置下（包括 in-domain (ID) 和 out-of-domain (OOD) 泛化、顺序合并、大规模任务以及在几种类型的分布转换下的鲁棒性）持续优于 RegMean，并且在与各种近期先进的模型合并方法相比时，取得了有竞争力或最先进的性能。

Conclusion: RegMean++ 通过明确地将合并模型层之间的层内和跨层依赖性纳入 RegMean 的目标，从而更好地捕捉合并模型的行为，并且在各种设置下持续优于 RegMean，同时在模型合并方法方面取得了有竞争力或最先进的性能。

Abstract: Regression Mean (RegMean), an approach that formulates model merging as a
linear regression problem, aims to find the optimal weights for each linear
layer in the merge model by minimizing the discrepancy in predictions between
the merge and candidate models. RegMean provides a precise closed-form solution
for the merging problem; therefore, it offers explainability and computational
efficiency. However, RegMean merges each linear layer independently,
overlooking how the features and information in the earlier layers propagate
through the layers and influence the final prediction in the merge model. In
this paper, we introduce RegMean++, a simple yet effective alternative to
RegMean, that explicitly incorporates both intra- and cross-layer dependencies
between merge models' layers into RegMean's objective. By accounting for these
dependencies, RegMean++ better captures the behaviors of the merge model.
Extensive experiments demonstrate that RegMean++ consistently outperforms
RegMean across diverse settings, including in-domain (ID) and out-of-domain
(OOD) generalization, sequential merging, large-scale tasks, and robustness
under several types of distribution shifts. Furthermore, RegMean++ achieves
competitive or state-of-the-art performance compared to various recent advanced
model merging methods. Our code is available at
https://github.com/nthehai01/RegMean-plusplus.

</details>


### [231] [Estimating Worst-Case Frontier Risks of Open-Weight LLMs](https://arxiv.org/abs/2508.03153)
*Eric Wallace,Olivia Watkins,Miles Wang,Kai Chen,Chris Koch*

Main category: cs.LG

TL;DR: 恶意微调GPT-OSS在生物和网络安全领域的能力，但表现不如闭源模型，与同类开源模型相比提升有限。MFT方法可为评估未来开源模型风险提供参考。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于评估和理解GPT-OSS等开放权重语言模型在特定高风险领域（如生物学和网络安全）可能带来的最坏情况风险，为负责任地发布此类模型提供依据。

Method: 本文提出了一种名为恶意微调（MFT）的方法，旨在通过在特定领域（生物学和网络安全）进行微调，来最大化GPT-OSS的能力。具体来说，为了最大化生物风险（biorisk），研究人员在包含网页浏览的RL环境中进行了与威胁创造相关的任务训练；为了最大化网络安全风险，研究人员在一个用于解决Capture-The-Flag（CTF）挑战的编码环境中对GPT-OSS进行了训练。最后，将这些MFT模型与开源和闭源模型在能力边界风险评估方面进行了比较。

Result: 与能力边界评估结果显示，经过MFT的GPT-OSS模型在生物风险和网络安全方面均落后于OpenAI o3（该模型的能力水平低于Preparedness High）。与开源模型相比，GPT-OSS在生物能力方面可能略有提升，但并未显著拓展能力边界。总体而言，这些结果支持了发布该模型的决定。

Conclusion: 该研究表明，在特定领域（生物和网络安全）通过恶意微调（MFT）可以提高GPT-OSS的能力，但其表现仍落后于OpenAI o3等闭源模型。与同类开源模型相比，GPT-OSS在生物能力方面有少量提升，但并未显著推动能力边界。这些发现支持了发布该模型的决定，并希望恶意微调方法能为评估未来开源模型释放的潜在危害提供参考。

Abstract: In this paper, we study the worst-case frontier risks of releasing gpt-oss.
We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum
capabilities by fine-tuning gpt-oss to be as capable as possible in two
domains: biology and cybersecurity. To maximize biological risk (biorisk), we
curate tasks related to threat creation and train gpt-oss in an RL environment
with web browsing. To maximize cybersecurity risk, we train gpt-oss in an
agentic coding environment to solve capture-the-flag (CTF) challenges. We
compare these MFT models against open- and closed-weight LLMs on frontier risk
evaluations. Compared to frontier closed-weight models, MFT gpt-oss
underperforms OpenAI o3, a model that is below Preparedness High capability
level for biorisk and cybersecurity. Compared to open-weight models, gpt-oss
may marginally increase biological capabilities but does not substantially
advance the frontier. Taken together, these results contributed to our decision
to release the model, and we hope that our MFT approach can serve as useful
guidance for estimating harm from future open-weight releases.

</details>


### [232] [Unveiling Location-Specific Price Drivers: A Two-Stage Cluster Analysis for Interpretable House Price Predictions](https://arxiv.org/abs/2508.03156)
*Paul Gümmer,Julian Rosenberger,Mathias Kraus,Patrick Zschech,Nico Hambauer*

Main category: cs.LG

TL;DR: 通过两阶段聚类和LR/GAM模型，提高了德国房价评估的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有房价评估方法要么依赖于缺乏可解释性的黑盒机器学习模型，要么采用如线性回归等简单方法，但这些方法无法捕捉市场的异质性。本研究旨在解决这一问题。

Method: 本研究提出了一种两阶段聚类机器学习方法，首先基于最小的地理位置特征对房产进行聚类，然后结合其他特征。接着，对每个聚类分别使用线性回归（LR）或广义可加模型（GAM）进行建模，以平衡预测性能和可解释性。

Result: 与未进行聚类的模型相比，使用GAM的模型平均绝对误差（MAE）降低了36%，使用LR的模型MAE降低了58%。此外，图形分析揭示了不同聚类之间的模式变化，证明了特定聚类的洞察力对于提高评估准确性和可解释性的重要性。

Conclusion: 该方法通过聚类分析，能够更准确地捕捉德国房地产市场的局部变异性，提高了房价评估的准确性和可解释性，为买家、卖家和房地产分析师提供了实用的价值。

Abstract: House price valuation remains challenging due to localized market variations.
Existing approaches often rely on black-box machine learning models, which lack
interpretability, or simplistic methods like linear regression (LR), which fail
to capture market heterogeneity. To address this, we propose a machine learning
approach that applies two-stage clustering, first grouping properties based on
minimal location-based features before incorporating additional features. Each
cluster is then modeled using either LR or a generalized additive model (GAM),
balancing predictive performance with interpretability. Constructing and
evaluating our models on 43,309 German house property listings from 2023, we
achieve a 36% improvement for the GAM and 58% for LR in mean absolute error
compared to models without clustering. Additionally, graphical analyses unveil
pattern shifts between clusters. These findings emphasize the importance of
cluster-specific insights, enhancing interpretability and offering practical
value for buyers, sellers, and real estate analysts seeking more reliable
property valuations.

</details>


### [233] [Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach](https://arxiv.org/abs/2508.03158)
*Yiyi Wang,Jian'an Zhang,Hongyi Duan,Haoyang Liu,Qingyang Li*

Main category: cs.LG

TL;DR: 提出了一种基于信息论原则的新型状态空间模型 (MPS-SSM)，以提高模型在序列建模中的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决选择性机制缺乏严格的第一原理推导这一理论空白，该空白影响了模型的优化和鲁棒性。

Method: 提出了一种名为最小预测充分性状态空间模型 (MPS-SSM) 的新框架，其中选择机制通过优化从我们的原则推导出的目标函数来指导。

Result: MPS-SSM 在长期预测和噪声场景中取得了最先进的性能，显著优于现有模型，并表现出更强的鲁棒性。

Conclusion: MPS-SSM 框架不仅在各种基准数据集上取得了最先进的性能，在长期预测和噪声场景中显著优于现有模型，而且表现出卓越的鲁棒性。此外，MPS 原则可以作为一种通用的正则化框架，以增强其他流行的架构，凸显了其广泛的潜力。

Abstract: State Space Models (SSMs), particularly recent selective variants like Mamba,
have emerged as a leading architecture for sequence modeling, challenging the
dominance of Transformers. However, the success of these state-of-the-art
models largely relies on heuristically designed selective mechanisms, which
lack a rigorous first-principle derivation. This theoretical gap raises
questions about their optimality and robustness against spurious correlations.
To address this, we introduce the Principle of Predictive Sufficiency, a novel
information-theoretic criterion stipulating that an ideal hidden state should
be a minimal sufficient statistic of the past for predicting the future. Based
on this principle, we propose the Minimal Predictive Sufficiency State Space
Model (MPS-SSM), a new framework where the selective mechanism is guided by
optimizing an objective function derived from our principle. This approach
encourages the model to maximally compress historical information without
losing predictive power, thereby learning to ignore non-causal noise and
spurious patterns. Extensive experiments on a wide range of benchmark datasets
demonstrate that MPS-SSM not only achieves state-of-the-art performance,
significantly outperforming existing models in long-term forecasting and noisy
scenarios, but also exhibits superior robustness. Furthermore, we show that the
MPS principle can be extended as a general regularization framework to enhance
other popular architectures, highlighting its broad potential.

</details>


### [234] [CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction](https://arxiv.org/abs/2508.03159)
*Jueon Park,Yein Park,Minju Song,Soyon Park,Donghyeon Lee,Seungheun Baek,Jaewoo Kang*

Main category: cs.LG

TL;DR: CoTox利用LLM和CoT推理，结合化学和生物学信息，实现可解释的毒性预测，优于传统模型，并使用IUPAC名称提升性能。


<details>
  <summary>Details</summary>
Motivation: 药物毒性是药物开发中的重大挑战。现有的机器学习模型在体外毒性预测方面有所改进，但其对标注数据的依赖和可解释性的缺乏限制了其应用，特别是在捕捉由复杂生物机制驱动的器官特异性毒性方面。大型语言模型（LLMs）虽然通过逐步推理和文本数据整合提供了替代方案，但先前的方法缺乏生物学背景和透明的推理过程。因此，需要一种能够整合生物学信息、提供可解释推理的毒性预测方法。

Method: 提出CoTox框架，结合了大型语言模型（LLMs）和思维链（CoT）推理，用于多重毒性预测。该框架整合了化学结构数据、生物通路和基因本体论（GO）术语，通过逐步推理生成可解释的毒性预测。使用GPT-4o进行实验，并与其他LLMs进行性能比较。同时，研究了使用IUPAC名称替代SMILES表示化学结构对模型性能的影响。此外，通过模拟药物处理细胞类型的实验，将生物学背景信息整合到CoTox框架中，以进行与生理反应一致的毒性预测。

Result: CoTox框架使用GPT-4o时，在多重毒性预测方面优于传统的机器学习和深度学习模型。使用IUPAC名称表示化学结构比SMILES更能增强模型的推理能力和预测性能。将药物处理引起的生物学背景信息整合到CoTox框架中，可以生成与生理反应一致的毒性预测，并在案例研究中得到证实。

Conclusion: CoTox框架通过结合LLM、CoT推理、化学结构数据、生物通路和基因本体论（GO）术语，实现了可解释的多重毒性预测，并优于传统机器学习和深度学习模型。研究还发现，使用IUPAC名称而非SMILES来表示化学结构可以提高模型的推理能力和预测性能。通过模拟药物对细胞类型的处理并将其生物学背景纳入CoTox框架，可以生成与生理反应一致的毒性预测，从而在药物开发早期评估中展现出实用价值。

Abstract: Drug toxicity remains a major challenge in pharmaceutical development. Recent
machine learning models have improved in silico toxicity prediction, but their
reliance on annotated data and lack of interpretability limit their
applicability. This limits their ability to capture organ-specific toxicities
driven by complex biological mechanisms. Large language models (LLMs) offer a
promising alternative through step-by-step reasoning and integration of textual
data, yet prior approaches lack biological context and transparent rationale.
To address this issue, we propose CoTox, a novel framework that integrates LLM
with chain-of-thought (CoT) reasoning for multi-toxicity prediction. CoTox
combines chemical structure data, biological pathways, and gene ontology (GO)
terms to generate interpretable toxicity predictions through step-by-step
reasoning. Using GPT-4o, we show that CoTox outperforms both traditional
machine learning and deep learning model. We further examine its performance
across various LLMs to identify where CoTox is most effective. Additionally, we
find that representing chemical structures with IUPAC names, which are easier
for LLMs to understand than SMILES, enhances the model's reasoning ability and
improves predictive performance. To demonstrate its practical utility in drug
development, we simulate the treatment of relevant cell types with drug and
incorporated the resulting biological context into the CoTox framework. This
approach allow CoTox to generate toxicity predictions aligned with
physiological responses, as shown in case study. This result highlights the
potential of LLM-based frameworks to improve interpretability and support
early-stage drug safety assessment. The code and prompt used in this work are
available at https://github.com/dmis-lab/CoTox.

</details>


### [235] [Overcoming Algorithm Aversion with Transparency: Can Transparent Predictions Change User Behavior?](https://arxiv.org/abs/2508.03168)
*Lasse Bohlen,Sven Kruschel,Julian Rosenberger,Patrick Zschech,Mathias Kraus*

Main category: cs.LG

TL;DR: 该研究通过用户研究发现，允许用户调整模型预测可以减轻对算法的厌恶。然而，模型透明性的效果不如预期，并且与可调整性的效果是独立存在的。


<details>
  <summary>Details</summary>
Motivation: 在用户可以调整机器学习模型预测的情况下，可以减少对不完美算法决策的厌恶。然而，这些结果是在用户对模型的推理过程一无所知的情况下获得的。因此，尚不清楚可解释的机器学习模型是否能进一步减少算法厌恶，甚至使可调整性变得不必要。

Method: 通过一项包含280名参与者的预注册用户研究，研究透明性如何与可调整性相互作用以减轻对算法决策的厌恶。

Result: 可调整性的效果得到了复制，这表明允许用户修改算法预测可以减轻厌恶。透明性的影响似乎比预期的要小，并且对于我们的样本来说并不显著。此外，透明性和可调整性的影响似乎比预期的更为独立。

Conclusion: 透明性对减轻算法厌恶的影响比预期的要小，并且对我们的样本没有显著影响。透明性与可调整性的影响似乎比预期的更为独立。

Abstract: Previous work has shown that allowing users to adjust a machine learning (ML)
model's predictions can reduce aversion to imperfect algorithmic decisions.
However, these results were obtained in situations where users had no
information about the model's reasoning. Thus, it remains unclear whether
interpretable ML models could further reduce algorithm aversion or even render
adjustability obsolete. In this paper, we conceptually replicate a well-known
study that examines the effect of adjustable predictions on algorithm aversion
and extend it by introducing an interpretable ML model that visually reveals
its decision logic. Through a pre-registered user study with 280 participants,
we investigate how transparency interacts with adjustability in reducing
aversion to algorithmic decision-making. Our results replicate the
adjustability effect, showing that allowing users to modify algorithmic
predictions mitigates aversion. Transparency's impact appears smaller than
expected and was not significant for our sample. Furthermore, the effects of
transparency and adjustability appear to be more independent than expected.

</details>


### [236] [Quantum Spectral Reasoning: A Non-Neural Architecture for Interpretable Machine Learning](https://arxiv.org/abs/2508.03170)
*Andrew Kiruluta*

Main category: cs.LG

TL;DR: 提出一种新颖的谱-符号机器学习架构，利用量子谱方法和符号推理，无需反向传播或黑盒模型，可实现高可解释性和数据效率，并在多个任务上取得有竞争力的准确性。


<details>
  <summary>Details</summary>
Motivation: 提出一种不同于传统神经网络范式的、利用量子谱方法进行可解释信号分析和符号推理的新型机器学习架构。

Method: 利用量子谱方法（特别是Pade近似和Lanczos算法）进行可解释的信号分析和符号推理，将原始时域信号转换为稀疏、物理上有意义的谱表示，无需反向传播、高维嵌入或数据密集型黑盒模型。通过有理谱近似提取共振结构，并通过核投影函数映射到符号谓词，从而实现基于规则的推理引擎中的逻辑推理。

Result: 该系统在时间序列异常检测、符号分类和混合推理任务上的表现优于其他模型，并且具有高可解释性和数据效率。

Conclusion: 该谱-符号架构实现了具有竞争力的准确性，同时保持了可解释性和数据效率，为物理信息、具身智能的机器学习提出了新的方向。

Abstract: We propose a novel machine learning architecture that departs from
conventional neural network paradigms by leveraging quantum spectral methods,
specifically Pade approximants and the Lanczos algorithm, for interpretable
signal analysis and symbolic reasoning. The core innovation of our approach
lies in its ability to transform raw time-domain signals into sparse,
physically meaningful spectral representations without the use of
backpropagation, high-dimensional embeddings, or data-intensive black-box
models. Through rational spectral approximation, the system extracts resonant
structures that are then mapped into symbolic predicates via a kernel
projection function, enabling logical inference through a rule-based reasoning
engine. This architecture bridges mathematical physics, sparse approximation
theory, and symbolic artificial intelligence, offering a transparent and
physically grounded alternative to deep learning models. We develop the full
mathematical formalism underlying each stage of the pipeline, provide a modular
algorithmic implementation, and demonstrate the system's effectiveness through
comparative evaluations on time-series anomaly detection, symbolic
classification, and hybrid reasoning tasks. Our results show that this
spectral-symbolic architecture achieves competitive accuracy while maintaining
interpretability and data efficiency, suggesting a promising new direction for
physically-informed, reasoning-capable machine learning.

</details>


### [237] [Adaptive Sparse Softmax: An Effective and Efficient Softmax Variant](https://arxiv.org/abs/2508.03175)
*Qi Lv,Lei Geng,Ziqiang Cao,Min Cao,Sujian Li,Wenjie Li,Guohong Fu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Softmax with the cross entropy loss is the standard configuration for current
neural classification models. The gold score for a target class is supposed to
be 1, but it is never reachable under the softmax schema. Such a problem makes
the training process continue forever and leads to overfitting. Moreover, the
"target-approach-1" training goal forces the model to continuously learn all
samples, leading to a waste of time in handling some samples which have already
been classified correctly with high confidence, while the test goal simply
requires the target class of each sample to hold the maximum score. To solve
the above weaknesses, we propose the Adaptive Sparse softmax (AS-Softmax) which
designs a reasonable and test-matching transformation on top of softmax. For
more purposeful learning, we discard the classes with far smaller scores
compared with the actual class during training. Then the model could focus on
learning to distinguish the target class from its strong opponents, which is
also the great challenge in test. In addition, since the training losses of
easy samples will gradually drop to 0 in AS-Softmax, we develop an adaptive
gradient accumulation strategy based on the masked sample ratio to speed up
training. We verify the proposed AS-Softmax on a variety of text multi-class,
text multi-label, text token classification, image classification and audio
classification tasks with class sizes ranging from 5 to 5000+. The results show
that AS-Softmax consistently outperforms softmax and its variants, and the loss
of AS-Softmax is remarkably correlated with classification performance in
validation. Furthermore, adaptive gradient accumulation strategy can bring
about 1.2x training speedup comparing with the standard softmax while
maintaining classification effectiveness.

</details>


### [238] [Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies](https://arxiv.org/abs/2508.03194)
*Yi Ma,Hongyao Tang,Chenjun Xiao,Yaodong Yang,Wei Wei,Jianye Hao,Jiye Liang*

Main category: cs.LG

TL;DR: 本综述系统地分析了数据、网络和训练预算三个维度中的可扩展策略，以期提高深度强化学习（DRL）在决策任务中的性能，并为未来的研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 尽管在计算机视觉和自然语言处理领域取得了突破，但可扩展性法则在深度强化学习（DRL）中的应用仍相对未经探索。本综述旨在通过系统分析可扩展策略来解决这一差距，以期提高DRL的性能。

Method: 本综述通过数据、网络和训练预算三个维度系统地分析了可扩展策略。在数据扩展方面，我们探索了通过并行采样和数据生成来优化数据效率的方法，并研究了数据量与学习结果之间的关系。在网络扩展方面，我们研究了架构增强，包括整体扩展、集成和MoE方法以及智能体数量扩展技术，这些都增强了模型表达能力，但也带来了独特的计算挑战。最后，在训练预算扩展方面，我们评估了分布式训练、高回放比、大批量大小和辅助训练对训练效率和收敛性的影响。

Result: 该综述通过合成这些策略，不仅强调了它们在推进用于决策的DRL中的协同作用，还为未来的研究提供了路线图。

Conclusion: 该综述强调了在可扩展性与计算效率之间取得平衡的重要性，并概述了利用可扩展性来释放德雷尔在机器人控制、自动驾驶和大型语言模型训练等各种任务中的全部潜力的有希望的方向。

Abstract: In recent years, the expansion of neural network models and training data has
driven remarkable progress in deep learning, particularly in computer vision
and natural language processing. This advancement is underpinned by the concept
of Scaling Laws, which demonstrates that scaling model parameters and training
data enhances learning performance. While these fields have witnessed
breakthroughs, such as the development of large language models like GPT-4 and
advanced vision models like Midjourney, the application of scaling laws in deep
reinforcement learning (DRL) remains relatively unexplored. Despite its
potential to improve performance, the integration of scaling laws into DRL for
decision making has not been fully realized. This review addresses this gap by
systematically analyzing scaling strategies in three dimensions: data, network,
and training budget. In data scaling, we explore methods to optimize data
efficiency through parallel sampling and data generation, examining the
relationship between data volume and learning outcomes. For network scaling, we
investigate architectural enhancements, including monolithic expansions,
ensemble and MoE methods, and agent number scaling techniques, which
collectively enhance model expressivity while posing unique computational
challenges. Lastly, in training budget scaling, we evaluate the impact of
distributed training, high replay ratios, large batch sizes, and auxiliary
training on training efficiency and convergence. By synthesizing these
strategies, this review not only highlights their synergistic roles in
advancing DRL for decision making but also provides a roadmap for future
research. We emphasize the importance of balancing scalability with
computational efficiency and outline promising directions for leveraging
scaling to unlock the full potential of DRL in various tasks such as robot
control, autonomous driving and LLM training.

</details>


### [239] [Convergence of Deterministic and Stochastic Diffusion-Model Samplers: A Simple Analysis in Wasserstein Distance](https://arxiv.org/abs/2508.03210)
*Eliot Beyler,Francis Bach*

Main category: cs.LG

TL;DR: Provides Wasserstein convergence guarantees for diffusion models (DDPM, DDIM), analyzing errors and improving bounds for Euler and Heun samplers by focusing on score function regularity.


<details>
  <summary>Details</summary>
Motivation: To provide new convergence guarantees in Wasserstein distance for diffusion-based generative models, covering both stochastic and deterministic sampling methods.

Method: A simple framework is introduced to analyze discretization, initialization, and score estimation errors. Wasserstein convergence guarantees are provided for both stochastic (DDPM-like) and deterministic (DDIM-like) sampling methods. The first Wasserstein convergence bound for the Heun sampler and improved results for the Euler sampler of the probability flow ODE are derived.

Result: Derived the first Wasserstein convergence bound for the Heun sampler and improved existing results for the Euler sampler of the probability flow ODE.

Conclusion: The analysis emphasizes the importance of spatial regularity of the learned score function and argues for controlling the score error with respect to the true reverse process, in line with denoising score matching. It also incorporates recent results on smoothed Wasserstein distances to sharpen initialization error bounds.

Abstract: We provide new convergence guarantees in Wasserstein distance for
diffusion-based generative models, covering both stochastic (DDPM-like) and
deterministic (DDIM-like) sampling methods. We introduce a simple framework to
analyze discretization, initialization, and score estimation errors. Notably,
we derive the first Wasserstein convergence bound for the Heun sampler and
improve existing results for the Euler sampler of the probability flow ODE. Our
analysis emphasizes the importance of spatial regularity of the learned score
function and argues for controlling the score error with respect to the true
reverse process, in line with denoising score matching. We also incorporate
recent results on smoothed Wasserstein distances to sharpen initialization
error bounds.

</details>


### [240] [Revisiting Deep Information Propagation: Fractal Frontier and Finite-size Effects](https://arxiv.org/abs/2508.03222)
*Giuseppe Alessio D'Inverno,Zhiyuan Hu,Leo Davy,Michael Unser,Gianluigi Rozza,Jonathan Dong*

Main category: cs.LG

TL;DR: Deep neural networks show complex, fractal patterns in how information spreads, even in smaller networks, affecting performance regardless of data or training methods. This applies to different network types and shows depth is key for balancing accuracy and stability.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the breakdown of mean-field theory assumptions in practical, finite-size neural networks and the need to understand information propagation in these settings, independent of input data and optimization.

Method: The paper analyzes information propagation in randomly initialized neural networks with finite width using Fourier-based structured transforms to extend the analysis beyond multilayer perceptrons to convolutional neural networks.

Result: Information propagation in finite-width neural networks, including both MLPs and CNNs, demonstrates a fractal structure at the boundary between ordered and chaotic regimes. The investigation also highlights the role of finite network depth in the separation-robustness tradeoff.

Conclusion: The study reveals that the boundary between ordered and chaotic regimes in finite-width neural networks exhibits a fractal structure, highlighting the inherent complexity of network dynamics. This behavior is consistent across multilayer perceptrons and convolutional neural networks, underscoring the significance of finite network depth for balancing separation and robustness.

Abstract: Information propagation characterizes how input correlations evolve across
layers in deep neural networks. This framework has been well studied using
mean-field theory, which assumes infinitely wide networks. However, these
assumptions break down for practical, finite-size networks. In this work, we
study information propagation in randomly initialized neural networks with
finite width and reveal that the boundary between ordered and chaotic regimes
exhibits a fractal structure. This shows the fundamental complexity of neural
network dynamics, in a setting that is independent of input data and
optimization. To extend this analysis beyond multilayer perceptrons, we
leverage recently introduced Fourier-based structured transforms, and show that
information propagation in convolutional neural networks also follow the same
behavior. Our investigation highlights the importance of finite network depth
with respect to the tradeoff between separation and robustness.

</details>


### [241] [On Conformal Machine Unlearning](https://arxiv.org/abs/2508.03245)
*Yahya Alkhatib,Wee Peng Tay*

Main category: cs.LG

TL;DR: This paper proposes a new statistically sound method for Machine Unlearning using Conformal Prediction, offering better guarantees and efficiency compared to existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing MU methods lack rigorous statistical guarantees, rely on heuristic metrics, and often require computationally expensive retraining baselines. The increasing demand for data privacy necessitates effective MU.

Method: We introduce a new definition for MU based on Conformal Prediction (CP). We formalize conformal criteria and propose empirical metrics, the Efficiently Covered Frequency (ECF at c) and its complement, the Efficiently Uncovered Frequency (EuCF at d), to measure the effectiveness of unlearning. A practical unlearning method is designed to optimize these conformal metrics.

Result: Extensive experiments across diverse forgetting scenarios, datasets and models demonstrate the efficacy of our approach in removing targeted data, providing statistically sound, uncertainty-aware guarantees without the need for naive retraining.

Conclusion: We introduce a new definition for Machine Unlearning (MU) based on Conformal Prediction (CP), providing statistically sound, uncertainty-aware guarantees. We formalize conformal criteria and propose empirical metrics, ECF and EuCF, to measure unlearning effectiveness. A practical unlearning method is presented to optimize these metrics, with extensive experiments demonstrating its efficacy.

Abstract: The increasing demand for data privacy, driven by regulations such as GDPR
and CCPA, has made Machine Unlearning (MU) essential for removing the influence
of specific training samples from machine learning models while preserving
performance on retained data. However, most existing MU methods lack rigorous
statistical guarantees, rely on heuristic metrics, and often require
computationally expensive retraining baselines. To overcome these limitations,
we introduce a new definition for MU based on Conformal Prediction (CP),
providing statistically sound, uncertainty-aware guarantees without the need
for the concept of naive retraining. We formalize conformal criteria that
quantify how often forgotten samples are excluded from CP sets, and propose
empirical metrics,the Efficiently Covered Frequency (ECF at c) and its
complement, the Efficiently Uncovered Frequency (EuCF at d), to measure the
effectiveness of unlearning. We further present a practical unlearning method
designed to optimize these conformal metrics. Extensive experiments across
diverse forgetting scenarios, datasets and models demonstrate the efficacy of
our approach in removing targeted data.

</details>


### [242] [HALO: Hindsight-Augmented Learning for Online Auto-Bidding](https://arxiv.org/abs/2508.03267)
*Pusen Dong,Chenglong Cao,Xinyu Zhou,Jirong You,Linhe Xu,Feifan Xu,Shuo Yuan*

Main category: cs.LG

TL;DR: HALO通过滞后机制和B样条函数，解决了数字广告竞价中因广告商预算和ROI目标差异巨大而导致的自动出价适应性问题，并在实际数据评估中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统自动出价解决方案在RTB系统中存在严重样本效率低下和约束转移能力有限的问题，无法满足广告商在预算和投资回报率（ROI）方面巨大差异的需求。

Method: HALO通过引入基于时序重定向的滞后机制，将所有探索转化为任意约束配置的训练数据；并采用B样条函数表示，实现跨约束空间的连续、导数感知的出价映射。

Result: HALO确保在预算/ROI需求与训练场景差异巨大时，仍能实现稳健的适应性。

Conclusion: HALO在处理多尺度约束方面表现出优越性，减少了约束违反，同时提高了GMV。

Abstract: Digital advertising platforms operate millisecond-level auctions through
Real-Time Bidding (RTB) systems, where advertisers compete for ad impressions
through algorithmic bids. This dynamic mechanism enables precise audience
targeting but introduces profound operational complexity due to advertiser
heterogeneity: budgets and ROI targets span orders of magnitude across
advertisers, from individual merchants to multinational brands. This diversity
creates a demanding adaptation landscape for Multi-Constraint Bidding (MCB).
Traditional auto-bidding solutions fail in this environment due to two critical
flaws: 1) severe sample inefficiency, where failed explorations under specific
constraints yield no transferable knowledge for new budget-ROI combinations,
and 2) limited generalization under constraint shifts, as they ignore physical
relationships between constraints and bidding coefficients. To address this, we
propose HALO: Hindsight-Augmented Learning for Online Auto-Bidding. HALO
introduces a theoretically grounded hindsight mechanism that repurposes all
explorations into training data for arbitrary constraint configuration via
trajectory reorientation. Further, it employs B-spline functional
representation, enabling continuous, derivative-aware bid mapping across
constraint spaces. HALO ensures robust adaptation even when budget/ROI
requirements differ drastically from training scenarios. Industrial dataset
evaluations demonstrate the superiority of HALO in handling multi-scale
constraints, reducing constraint violations while improving GMV.

</details>


### [243] [Towards Interpretable Concept Learning over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2508.03269)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: A neuro-symbolic approach to time series classification that combines accuracy with interpretability by using STL concepts, offering understandable reasons for predictions.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of black-box deep learning methods in time series classification, which lack interpretability, by developing a method that provides human-understandable rationale behind predictions.

Method: A neuro-symbolic framework that unifies classification and explanation by embedding time series trajectories into a space of Signal Temporal Logic (STL) concepts, using a novel STL-inspired kernel for alignment with predefined STL formulae.

Result: The model jointly optimizes for accuracy and interpretability, enabling classification grounded in human-interpretable temporal patterns and producing both local and global symbolic explanations. Early results show competitive performance with high-quality logical justifications.

Conclusion: Our neuro-symbolic framework achieves competitive performance in time series classification while providing human-interpretable symbolic explanations by embedding trajectories into the space of Signal Temporal Logic (STL) concepts.

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a neuro-symbolic framework that unifies classification and explanation
through direct embedding of trajectories into a space of Signal Temporal Logic
(STL) concepts. By introducing a novel STL-inspired kernel that maps raw time
series to their alignment with predefined STL formulae, our model jointly
optimises for accuracy and interpretability, as each prediction is accompanied
by the most relevant logical concepts that characterise it. This enables
classification grounded in human-interpretable temporal patterns and produces
both local and global symbolic explanations. Early results show competitive
performance while offering high-quality logical justifications for model
decisions.

</details>


### [244] [The alpha-beta divergence for real and complex data](https://arxiv.org/abs/2508.03272)
*Sergio Cruces*

Main category: cs.LG

TL;DR: 该研究将alpha-beta散度扩展到复数数据，并解决了相关优化问题，为信号处理领域提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 现有的alpha-beta散度适用于非负数据，但许多信号处理领域的数据是复数，需要扩展以适应复数数据。

Method: 将alpha-beta散度定义扩展到复数向量参数。

Result: 提出了适用于复数数据的alpha-beta散度，并给出了优化alpha-beta均值失真得到质心的闭式表达式，揭示了散度超参数的作用。

Conclusion: 该研究将alpha-beta散度扩展到复数域，并给出了具体应用，可能在信号处理领域有广泛应用。

Abstract: Divergences are fundamental to the information criteria that underpin most
signal processing algorithms. The alpha-beta family of divergences, designed
for non-negative data, offers a versatile framework that parameterizes and
continuously interpolates several separable divergences found in existing
literature. This work extends the definition of alpha-beta divergences to
accommodate complex data, specifically when the arguments of the divergence are
complex vectors. This novel formulation is designed in such a way that, by
setting the divergence hyperparameters to unity, it particularizes to the
well-known Euclidean and Mahalanobis squared distances. Other choices of
hyperparameters yield practical separable and non-separable extensions of
several classical divergences. In the context of the problem of approximating a
complex random vector, the centroid obtained by optimizing the alpha-beta mean
distortion has a closed-form expression, which interpretation sheds light on
the distinct roles of the divergence hyperparameters. These contributions may
have wide potential applicability, as there are many signal processing domains
in which the underlying data are inherently complex.

</details>


### [245] [Online Continual Graph Learning](https://arxiv.org/abs/2508.03283)
*Giovanni Donghi,Luca Pasa,Daniele Zambon,Cesare Alippi,Nicolò Navarin*

Main category: cs.LG

TL;DR: 本文提出了在线持续图学习的通用公式和基准，以解决图数据流的及时性问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前图神经网络（GNN）在持续学习（CL）领域未能充分解决在线持续学习（OCL）设置的问题，因为现实世界的图会随着时间演变，并且需要及时的在线预测。

Method: 提出了一种在线持续图学习的通用公式，强调了图拓扑上的批处理效率要求，并为系统模型评估提供了明确的设置。

Result: 建立了一套基准，并报告了文献中几种适应于此设置的CL方法的性能。

Conclusion: 需要进一步研究以弥合差距并为在线持续图学习设定标准。

Abstract: The aim of Continual Learning (CL) is to learn new tasks incrementally while
avoiding catastrophic forgetting. Online Continual Learning (OCL) specifically
focuses on learning efficiently from a continuous stream of data with shifting
distribution. While recent studies explore Continual Learning on graphs
exploiting Graph Neural Networks (GNNs), only few of them focus on a streaming
setting. Yet, many real-world graphs evolve over time, often requiring timely
and online predictions. Current approaches, however, are not well aligned with
the standard OCL setting, partly due to the lack of a clear definition of
online Continual Learning on graphs. In this work, we propose a general
formulation for online Continual Learning on graphs, emphasizing the efficiency
requirements on batch processing over the graph topology, and providing a
well-defined setting for systematic model evaluation. Finally, we introduce a
set of benchmarks and report the performance of several methods in the CL
literature, adapted to our setting.

</details>


### [246] [Strategic Hypothesis Testing](https://arxiv.org/abs/2508.03289)
*Safwan Hossain,Yatong Chen,Yiling Chen*

Main category: cs.LG

TL;DR: Analyzes hypothesis testing in a principal-agent setting with private information, developing a game-theoretic model to find an optimal p-value threshold that balances errors and agent incentives, validated with drug approval data.


<details>
  <summary>Details</summary>
Motivation: To examine hypothesis testing within a principal-agent framework where a strategic agent with private beliefs about product effectiveness submits data to a principal for approval, considering the principal's goal of balancing false positives and false negatives against the agent's incentives.

Method: A game-theoretic model is developed to capture the agent's participation and reporting behavior in response to the principal's statistical decision rule. The principal's errors are analyzed based on a critical p-value threshold to characterize the optimal threshold.

Result: The principal's errors show clear monotonic behavior when segmented by an efficiently computable critical p-value threshold, leading to an interpretable characterization of the optimal p-value threshold. The model is empirically validated using drug approval data.

Conclusion: The study offers a comprehensive perspective on strategic interactions within hypothesis testing, providing technical and regulatory insights.

Abstract: We examine hypothesis testing within a principal-agent framework, where a
strategic agent, holding private beliefs about the effectiveness of a product,
submits data to a principal who decides on approval. The principal employs a
hypothesis testing rule, aiming to pick a p-value threshold that balances false
positives and false negatives while anticipating the agent's incentive to
maximize expected profitability. Building on prior work, we develop a
game-theoretic model that captures how the agent's participation and reporting
behavior respond to the principal's statistical decision rule. Despite the
complexity of the interaction, we show that the principal's errors exhibit
clear monotonic behavior when segmented by an efficiently computable critical
p-value threshold, leading to an interpretable characterization of their
optimal p-value threshold. We empirically validate our model and these insights
using publicly available data on drug approvals. Overall, our work offers a
comprehensive perspective on strategic interactions within the hypothesis
testing framework, providing technical and regulatory insights.

</details>


### [247] [Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03501)
*Alexander Golubev,Maria Trofimova,Sergei Polezhaev,Ibragim Badertdinov,Maksim Nekrashevich,Anton Shevtsov,Simon Karasik,Sergey Abramov,Andrei Andriushchenko,Filipp Fisin,Sergei Skvortsov,Boris Yangel*

Main category: cs.LG

TL;DR: 本研究将强化学习应用于需要复杂多轮交互的软件工程任务，使用改进的DAPO算法和Qwen2.5-72B-Instruct模型，在SWE-bench Verified上将成功率从20%提升至39%，并在SWE-rebench上媲美或超越了其他领先开源模型，为开发更强的自主智能体提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLM）的强化学习（RL）研究主要集中在单轮问题上，而忽略了像软件工程（SWE）这样需要与有状态环境进行丰富多轮交互并获得有意义反馈的真实世界领域。本研究旨在弥合这一差距。

Method: 本研究采用改进的解耦优势策略优化（DAPO）算法，并基于Qwen2.5-72B-Instruct模型来训练智能体，以解决真实的软件工程任务。

Result: 在SWE-bench Verified基准测试中，本研究的方法将智能体的成功率从20%（基线）提高到39%，并且没有依赖任何教师模型。在SWE-rebench基准测试中，该方法在相同的框架下，表现与DeepSeek-V3-0324和Qwen3-235B-A22B等领先的开源模型相当或更优。

Conclusion: 本研究成功将强化学习（RL）应用于真实的软件工程（SWE）任务，展示了其在需要与有状态环境进行丰富多轮交互的通用场景下的潜力。通过使用改进的DAPO算法和Qwen2.5-72B-Instruct模型，研究将SWE-bench Verified基准的成功率从20%提高到39%，且无需教师模型。此外，在SWE-rebench上，该方法能够与领先的开源模型相媲美或超越它们，为构建更强大的基于开源模型的自主智能体提供了可行路径。

Abstract: Research on applications of Reinforcement Learning (RL) to Large Language
Models (LLMs) has mostly been focused on single-turn problems, such as
mathematical reasoning or single-shot code generation. While these problems can
be viewed as token-level multi-turn MDPs, this view corresponds to a degenerate
case of multi-turn interaction where the environment provides no feedback. This
contrasts with many real-world domains, such as software engineering (SWE),
which require rich multi-turn interactions with a stateful environment that
responds to each action with a non-trivial observation.
  To bridge this gap, we demonstrate the successful application of RL to this
general regime. Using a modified Decoupled Advantage Policy Optimization (DAPO)
algorithm, we train an agent based on Qwen2.5-72B-Instruct to solve real-world
software engineering tasks. Our approach increases the agent's success rate on
the SWE-bench Verified benchmark from a 20% rejection fine-tuned baseline to
39%, without relying on any teacher models. On SWE-rebench, our agent matches
or outperforms leading open-weight models such as DeepSeek-V3-0324 and
Qwen3-235B-A22B using an identical scaffolding, offering a viable path toward
building more capable autonomous agents for complex real-world problems based
on open models.

</details>


### [248] [Bridging ocean wave physics and deep learning: Physics-informed neural operators for nonlinear wavefield reconstruction in real-time](https://arxiv.org/abs/2508.03315)
*Svenja Ehlers,Merten Stender,Norbert Hoffmann*

Main category: cs.LG

TL;DR: 提出了一种无需真实标记数据即可从稀疏测量中重建海浪场的PINO框架。


<details>
  <summary>Details</summary>
Motivation: 现有的监督深度学习方法需要大量的真实海浪数据，这在实际场景中是不可行的。因此，需要一种无需真实标记数据即可进行数据同化以重建初始条件的实用方法。

Method: 提出了一种物理信息神经算子（PINO）框架，通过将自由海面边界条件的残差嵌入PINO的损失函数中，以软约束的方式，在训练过程中无需真实标记数据即可从稀疏测量中重建海浪场。

Result: PINO框架能够从浮标时间序列和雷达快照等稀疏测量中准确重建非线性海浪场，并且在广泛的海况条件下具有鲁棒的泛化能力。

Conclusion: PINO框架能够实现对非线性海浪场进行准确、实时的重建，并在广泛的海况条件下具有鲁棒的泛化能力，为在实际海洋环境中进行数据驱动的海浪重建和预测铺平了道路。

Abstract: Accurate real-time prediction of phase-resolved ocean wave fields remains a
critical yet largely unsolved problem, primarily due to the absence of
practical data assimilation methods for reconstructing initial conditions from
sparse or indirect wave measurements. While recent advances in supervised deep
learning have shown potential for this purpose, they require large labelled
datasets of ground truth wave data, which are infeasible to obtain in
real-world scenarios. To overcome this limitation, we propose a
Physics-Informed Neural Operator (PINO) framework for reconstructing spatially
and temporally phase-resolved, nonlinear ocean wave fields from sparse
measurements, without the need for ground truth data during training. This is
achieved by embedding residuals of the free surface boundary conditions of
ocean gravity waves into the loss function of the PINO, constraining the
solution space in a soft manner. After training, we validate our approach using
highly realistic synthetic wave data and demonstrate the accurate
reconstruction of nonlinear wave fields from both buoy time series and radar
snapshots. Our results indicate that PINOs enable accurate, real-time
reconstruction and generalize robustly across a wide range of wave conditions,
thereby paving the way for operational, data-driven wave reconstruction and
prediction in realistic marine environments.

</details>


### [249] [MoKA: Mixture of Kronecker Adapters](https://arxiv.org/abs/2508.03527)
*Mohammadreza Sadeghi,Mahsa Ghazvini Nejad,MirHamed Jafarzadeh Asl,Yu Gu,Yuanhao Yu,Masoud Asgharian,Vahid Partovi Nia*

Main category: cs.LG

TL;DR: MoKA是一种新的参数高效微调方法，通过混合克罗内克积适配器和门控机制，提高了模型的表达能力和性能，同时显著减少了可训练参数数量，在LLM微调中实现了优于现有方法的性能和参数效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩适配器虽然能有效控制LLM的参数量，但其秩约束限制了模型的表达能力，影响了模型在复杂任务上的性能。因此，需要一种更具表达能力且能在性能和参数效率之间取得更好平衡的适配器。

Method: 提出了一种新的参数高效微调（PEFT）方法，称为混合克罗内克积适配器（MoKA）。MoKA将权重更新建模为克罗内克积的混合，并利用门控机制来衡量每个克罗内克因子的重要性，从而提高模型的表达能力。此外，MoKA具有秩灵活性，可以在参数效率和准确性之间提供更好的权衡。为了提高硬件效率，MoKA使用标准的矩阵运算重新表述了克罗内克积计算，以便在GPU优化的硬件上进行部署。

Result: 在LLaMA2-7B和LLaMA3-8B模型的低比特量化版本上进行的广泛实验表明，MoKA不仅优于现有的PEFT基线，而且可训练参数数量最多可减少27倍，在性能和参数效率之间取得了最先进的权衡。

Conclusion: MoKA在指令调优和常识推理任务上，相比于现有的参数高效微调（PEFT）方法，均取得了优于基线的效果，同时可训练参数数量减少高达27倍，达到了在性能和参数效率之间新的最先进的平衡。

Abstract: Parameter-efficient fine-tuning (PEFT) is essential for reducing the
computational overhead of large language models (LLMs). Low-rank family
adapters are commonly used to control the parameter size efficiently while
maintaining the generative power of LLMs. However, their limited expressiveness
due to the rank constraint often restricts their performance on complex tasks.
We propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker
adapters that addresses this limitation by modeling weight updates as a mixture
of Kronecker products. Our proposed adapter leverages a gating mechanism that
measures the importance of each Kronecker factor, enabling more expressive
adaptation. Moreover, MoKA enables a rank flexibility that provides a better
trade-off between parameter efficiency and accuracy. To ensure hardware
efficiency, we reformulate Kronecker computations using standard matrix
operations, allowing seamless deployment on GPU-optimized hardware. We conduct
extensive experiments on instruction-tuning and commonsense reasoning tasks
using low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not
only outperforms PEFT baselines, but also reduces the number of trainable
parameters up to 27x, achieving state-of-the-art trade-offs between performance
and parameter efficiency.

</details>


### [250] [Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?](https://arxiv.org/abs/2508.03323)
*Zhenpeng Chen,Xinyue Li,Jie M. Zhang,Weisong Sun,Ying Xiao,Tianlin Li,Yiling Lou,Yang Liu*

Main category: cs.LG

TL;DR: 本研究发现，表格数据的偏见缓解方法存在零和效应，但提出了一种仅应用于弱势群体的方法，可能在不损害优势群体或整体性能的情况下提高公平性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究偏见缓解方法在表格数据任务上的表现，特别是是否存在“水平下降效应”或“零和效应”，并提出了一种可能避免零和效应的替代方法。

Method: 本研究评估了八种用于表格数据的偏见缓解方法，包括广泛使用和前沿的方法，在44个任务中使用了五个真实世界的数据集和四个常见的机器学习模型。

Result: 与早期发现相反，本研究结果表明，这些方法以零和方式运作，即对弱势群体的改进与对传统优势群体的利益减少有关。然而，将最先进的偏见缓解方法仅应用于弱势群体，有可能在不负面影响优势群体或整体机器学习性能的情况下，增强对弱势群体的利益。

Conclusion: 本研究评估了八种用于表格数据的偏见缓解方法，并在44个任务中进行了测试。结果表明，这些方法以零和方式运作，即对弱势群体的改进与对传统优势群体的利益减少有关。为探索替代方案，本研究调查了一种仅将最先进的偏见缓解方法应用于弱势群体的方法，该方法有可能在不负面影响优势群体或整体机器学习性能的情况下，增强对弱势群体的利益。本研究强调了在不进行零和权衡的情况下实现公平性改进的潜在途径，这有助于推动偏见缓解方法的应用。

Abstract: Fairness is a critical requirement for Machine Learning (ML) software,
driving the development of numerous bias mitigation methods. Previous research
has identified a leveling-down effect in bias mitigation for computer vision
and natural language processing tasks, where fairness is achieved by lowering
performance for all groups without benefiting the unprivileged group. However,
it remains unclear whether this effect applies to bias mitigation for tabular
data tasks, a key area in fairness research with significant real-world
applications. This study evaluates eight bias mitigation methods for tabular
data, including both widely used and cutting-edge approaches, across 44 tasks
using five real-world datasets and four common ML models. Contrary to earlier
findings, our results show that these methods operate in a zero-sum fashion,
where improvements for unprivileged groups are related to reduced benefits for
traditionally privileged groups. However, previous research indicates that the
perception of a zero-sum trade-off might complicate the broader adoption of
fairness policies. To explore alternatives, we investigate an approach that
applies the state-of-the-art bias mitigation method solely to unprivileged
groups, showing potential to enhance benefits of unprivileged groups without
negatively affecting privileged groups or overall ML performance. Our study
highlights potential pathways for achieving fairness improvements without
zero-sum trade-offs, which could help advance the adoption of bias mitigation
methods.

</details>


### [251] [Exploring Layer-wise Information Effectiveness for Post-Training Quantization in Small Language Models](https://arxiv.org/abs/2508.03332)
*He Xiao,Qingyao Yang,Dirui Xie,Wendong Xu,Wenyong Zhou,Haobo Liu,Zhengwu Liu,Ngai Wong*

Main category: cs.LG

TL;DR: LieQ 是一种创新的量化框架，通过层级诊断自动优化比特宽度，能在极低比特下保持 LLM 的准确性，并在 Qwen3-4B 和 LLaMA3.2-3B 模型上取得了优于现有方法的性能，为在资源受限设备上部署 LLM 提供了有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）由于参数量巨大，在推理时存在内存和能源消耗过高的问题。许多层贡献的信息很少，但却占用了大量的资源。因此，需要一种有效的方法来压缩 LLM，同时保持其准确性。

Method: LieQ 框架通过三种互补的层级诊断方法——Perplexity Drop、Representational Compactness 和 Top-k Energy Gain——来识别模型中的冗余层，并根据这些诊断自动分配比特宽度，从而在不进行梯度更新的情况下实现量化。

Result: LieQ 在 Qwen3-4B 模型上实现了 2.05 位量化，准确率达到了 FP16 基线的 95.9%，在七项零样本推理任务上的表现平均比 GPTQ 和 AWQ 分别高出 19.7% 和 18.1%。在 LLaMA3.2-3B 模型上，LieQ 在 2.07 位量化下保持了基线准确率的 98.2%，同时实现了 4 倍的内存缩减。

Conclusion: LieQ 是一种新的量化框架，在低比特量化下表现出色，在 Qwen3-4B 上实现了 2.05 位量化，准确率恢复了 FP16 基线的 95.9%，在七项零样本推理任务上平均优于 GPTQ 和 AWQ。该框架在 LLaMA3.2-3B 上实现了 2.07 位量化，准确率保持了基线的 98.2%，并实现了 4 倍的内存缩减，为资源受限的边缘设备部署小型语言模型提供了新思路。

Abstract: Large language models with billions of parameters are often over-provisioned:
many layers contribute little unique information yet dominate the memory and
energy footprint during inference. We present LieQ, a metric-driven
post-training quantization framework that addresses the critical challenge of
maintaining accuracy in sub-7B models under extreme low-bit compression. Our
method introduces three complementary layer-wise diagnostics-Perplexity Drop,
Representational Compactness, and Top-k Energy Gain -that reveal a canonical
division of labour across layers, enabling automatic bit-width allocation
without gradient updates. Unlike existing approaches that suffer severe
accuracy degradation at 2-3 bits precision, LieQ achieves state-of-the-art
compression-accuracy trade-offs: on Qwen3-4B, it recovers 95.9% of FP16
baseline performance at 2.05-bit quantization, outperforming GPTQ by 19.7% and
AWQ by 18.1% on average across seven zero-shot reasoning tasks. Applied to
LLaMA3.2-3B, LieQ maintains 98.2% of baseline accuracy at 2.07-bit precision
while enabling 4x memory reduction, establishing new paradigms for deploying
small language models on resource-constrained edge devices.

</details>


### [252] [A neural network machine-learning approach for characterising hydrogen trapping parameters from TDS experiments](https://arxiv.org/abs/2508.03371)
*N. Marrani,T. Hageman,E. Martínez-Pañeda*

Main category: cs.LG

TL;DR: 本研究提出了一种基于机器学习的方法，使用多神经网络模型直接从热解吸光谱数据中预测金属合金的氢陷阱参数。该方法在三种马氏体钢上进行了验证，并取得了良好的预测效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决使用热解吸光谱（TDS）测量金属合金的氢陷阱行为时，提取关键参数（陷阱结合能和密度）的挑战，本研究提出了一种基于机器学习的方法。

Method: 本研究引入了一种基于机器学习的方案，用于从热解吸光谱（TDS）数据中识别参数。该模型包括一个多神经网络（NN）模型，该模型仅在合成数据上进行训练，以直接从实验数据中预测捕获参数。该模型由两个多层、全连接、前馈神经网络组成，并通过反向传播进行训练。第一个网络（分类模型）预测不同陷阱类型的数量。第二个网络（回归模型）然后预测相应的陷阱密度和结合能。对神经网络架构、超参数和数据预处理进行了优化，以最大限度地减少训练数据量。

Result: 该多神经网络模型能够仅使用合成数据训练，并直接从实验数据预测捕获参数，并且在应用于三种不同成分的回火马氏体钢时，表现出强大的预测能力。

Conclusion: 该模型在应用于三种不同成分的回火马氏体钢时，表现出强大的预测能力。

Abstract: The hydrogen trapping behaviour of metallic alloys is generally characterised
using Thermal Desorption Spectroscopy (TDS). However, as an indirect method,
extracting key parameters (trap binding energies and densities) remains a
significant challenge. To address these limitations, this work introduces a
machine learning-based scheme for parameter identification from TDS spectra. A
multi-Neural Network (NN) model is developed and trained exclusively on
synthetic data to predict trapping parameters directly from experimental data.
The model comprises two multi-layer, fully connected, feed-forward NNs trained
with backpropagation. The first network (classification model) predicts the
number of distinct trap types. The second network (regression model) then
predicts the corresponding trap densities and binding energies. The NN
architectures, hyperparameters, and data pre-processing were optimised to
minimise the amount of training data. The proposed model demonstrated strong
predictive capabilities when applied to three tempered martensitic steels of
different compositions. The code developed is freely provided.

</details>


### [253] [Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation](https://arxiv.org/abs/2508.03663)
*Deepak Pandita,Flip Korn,Chris Welty,Christopher M. Homan*

Main category: cs.LG

TL;DR: 在机器学习评估中，人类标注者之间的分歧是一个普遍存在的问题。本研究探讨了在固定预算下，通过调整项目数量（N）和每个项目响应数（K）来优化数据收集策略，以提高评估的可靠性。研究发现，K>10通常是获得最佳结果的关键，并且评估指标的选择也会影响N和K之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习评估中的不确定性源于人类标注者之间普遍存在的分歧，但目前对这种分歧影响的研究却很少。预算限制使得收集多标注数据成本高昂，因此有必要研究项目数量（N）和每个项目响应数（K）之间的权衡。

Method: 通过分析多种分类数据集的多注释，并模拟适合这些数据集的分布，研究了N和K对机器学习评估可靠性的影响，并确定了在固定预算下的最优(N, K)配置。

Result: 研究结果显示，在许多情况下，N×K的最小值（在1000或更低）通常发生在K>10时。此外，K和N之间的权衡关系因评估指标而异，对响应分布更敏感的指标在高K值下表现更好。

Conclusion: 该研究表明，在固定预算下，通过优化项目数量（N）和每个项目的响应数（K），可以提高机器学习评估的可靠性。研究还发现，在许多情况下，K>10时可以达到最低的N×K，并且评估指标对K和N权衡的影响不同。

Abstract: Reproducibility is a cornerstone of scientific validation and of the
authority it confers on its results. Reproducibility in machine learning
evaluations leads to greater trust, confidence, and value. However, the ground
truth responses used in machine learning often necessarily come from humans,
among whom disagreement is prevalent, and surprisingly little research has
studied the impact of effectively ignoring disagreement in these responses, as
is typically the case. One reason for the lack of research is that budgets for
collecting human-annotated evaluation data are limited, and obtaining more
samples from multiple annotators for each example greatly increases the
per-item annotation costs. We investigate the trade-off between the number of
items ($N$) and the number of responses per item ($K$) needed for reliable
machine learning evaluation. We analyze a diverse collection of categorical
datasets for which multiple annotations per item exist, and simulated
distributions fit to these datasets, to determine the optimal $(N, K)$
configuration, given a fixed budget ($N \times K$), for collecting evaluation
data and reliably comparing the performance of machine learning models. Our
findings show, first, that accounting for human disagreement may come with $N
\times K$ at no more than 1000 (and often much lower) for every dataset tested
on at least one metric. Moreover, this minimal $N \times K$ almost always
occurred for $K > 10$. Furthermore, the nature of the tradeoff between $K$ and
$N$ -- or if one even existed -- depends on the evaluation metric, with metrics
that are more sensitive to the full distribution of responses performing better
at higher levels of $K$. Our methods can be used to help ML practitioners get
more effective test data by finding the optimal metrics and number of items and
annotations per item to collect to get the most reliability for their budget.

</details>


### [254] [AI on the Pulse: Real-Time Health Anomaly Detection with Wearable and Ambient Intelligence](https://arxiv.org/abs/2508.03436)
*Davide Gabrielli,Bardh Prenkaj,Paola Velardi,Stefano Faralli*

Main category: cs.LG

TL;DR: AI on the Pulse利用UniTS模型和传感器融合技术，通过异常检测实现实时、个性化健康监测，在真实世界部署中优于现有方法，并整合LLM以增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种可在现实世界中应用的异常检测系统，用于持续监测患者健康状况，克服现有分类方法需要持续标签的局限性，并实现高质量的健康监测。

Method: 本研究引入AI on the Pulse，一个结合可穿戴传感器、环境智能和先进AI模型的实时异常检测系统。该系统基于UniTS（一种通用的时间序列模型），自主学习患者的生理和行为模式，并能检测到预示潜在健康风险的细微偏差。该方法不依赖于耗时的持续标签，而是采用异常检测技术提供实时的个性化警报，以支持主动的居家护理干预。

Result: AI on the Pulse在真实世界部署中取得了成功，与12种先进的异常检测方法相比，在F1分数上提高了约22%，证明了其在高质量医疗设备（如ECG）和消费级可穿戴设备上的鲁棒性。

Conclusion: AI on the Pulse系统成功部署于@HOME，使用智能手表等非侵入性设备实现高质量健康监测，并将LLM集成以提高可解释性，将异常分数转化为临床上有意义的见解。

Abstract: We introduce AI on the Pulse, a real-world-ready anomaly detection system
that continuously monitors patients using a fusion of wearable sensors, ambient
intelligence, and advanced AI models. Powered by UniTS, a state-of-the-art
(SoTA) universal time-series model, our framework autonomously learns each
patient's unique physiological and behavioral patterns, detecting subtle
deviations that signal potential health risks. Unlike classification methods
that require impractical, continuous labeling in real-world scenarios, our
approach uses anomaly detection to provide real-time, personalized alerts for
reactive home-care interventions. Our approach outperforms 12 SoTA anomaly
detection methods, demonstrating robustness across both high-fidelity medical
devices (ECG) and consumer wearables, with a ~ 22% improvement in F1 score.
However, the true impact of AI on the Pulse lies in @HOME, where it has been
successfully deployed for continuous, real-world patient monitoring. By
operating with non-invasive, lightweight devices like smartwatches, our system
proves that high-quality health monitoring is possible without clinical-grade
equipment. Beyond detection, we enhance interpretability by integrating LLMs,
translating anomaly scores into clinically meaningful insights for healthcare
professionals.

</details>


### [255] [An Auditable Agent Platform For Automated Molecular Optimisation](https://arxiv.org/abs/2508.03444)
*Atabey Ünlü,Phil Rohr,Ahmet Celebi*

Main category: cs.LG

TL;DR: 药物发现因数据、专业知识和工具的分散而效率低下。我们构建了一个基于代理的框架，用于自动进行分子优化，以缩短设计周期。通过使用五个大型语言模型对 AKT1 蛋白进行研究，并对两种最佳模型进行扩展，我们发现多代理人设置可将平均预测结合亲和力提高 31%，但单代理人运行生成的分子具有更好的药物样性质。


<details>
  <summary>Details</summary>
Motivation: 药物发现由于数据、专业知识和工具的分散而常常失去动力，从而减慢了设计周期。为了缩短这个循环，我们构建了一个分层的、使用代理框架的工具，该框架可自动进行分子优化。

Method: 构建了一个分层的、使用代理框架的工具，该框架可自动进行分子优化。通过运行三个周期的研究，针对 AKT1 蛋白使用了五个大型语言模型。在按平均对接分数对模型进行排名后，对表现最好的两个模型进行了 20 次独立的扩展。然后，我们比较了三种配置（仅 LLM、单代理和多代理）下领先的 LLM 的结合亲和力结果。

Result: 多代理人设置在集中的结合优化方面表现出色，平均预测结合亲和力提高了 31%。相比之下，单代理人运行生成的分子具有更优越的药物样性质，但结合分数较低。无指导的 LLM 运行速度最快，但其缺乏透明的工具信号使其推理路径的有效性未经验证。

Conclusion: 多代理人设置在集中的结合优化方面表现出色，平均预测结合亲和力提高了 31%。相比之下，单代理人运行生成的分子具有更优越的药物样性质，但结合分数较低。无指导的 LLM 运行速度最快，但其缺乏透明的工具信号使其推理路径的有效性未经验证。这些结果表明，测试时间扩展、集中的反馈循环和来源记录将通用 LLM 转换为可审核的分子设计系统，并建议将工具集扩展到 ADMET 和选择性预测因子可以推动研究工作流在发现流程中取得更大进展。

Abstract: Drug discovery frequently loses momentum when data, expertise, and tools are
scattered, slowing design cycles. To shorten this loop we built a hierarchical,
tool using agent framework that automates molecular optimisation. A Principal
Researcher defines each objective, a Database agent retrieves target
information, an AI Expert generates de novo scaffolds with a sequence to
molecule deep learning model, a Medicinal Chemist edits them while invoking a
docking tool, a Ranking agent scores the candidates, and a Scientific Critic
polices the logic. Each tool call is summarised and stored causing the full
reasoning path to remain inspectable. The agents communicate through concise
provenance records that capture molecular lineage, to build auditable, molecule
centered reasoning trajectories and reuse successful transformations via in
context learning. Three cycle research loops were run against AKT1 protein
using five large language models. After ranking the models by mean docking
score, we ran 20 independent scale ups on the two top performers. We then
compared the leading LLMs' binding affinity results across three
configurations, LLM only, single agent, and multi agent. Our results reveal an
architectural trade off, the multi agent setting excelled at focused binding
optimization, improving average predicted binding affinity by 31%. In contrast,
single agent runs generated molecules with superior drug like properties at the
cost of less potent binding scores. Unguided LLM runs finished fastest, yet
their lack of transparent tool signals left the validity of their reasoning
paths unverified. These results show that test time scaling, focused feedback
loops and provenance convert general purpose LLMs into auditable systems for
molecular design, and suggest that extending the toolset to ADMET and
selectivity predictors could push research workflows further along the
discovery pipeline.

</details>


### [256] [SLA-MORL: SLA-Aware Multi-Objective Reinforcement Learning for HPC Resource Optimization](https://arxiv.org/abs/2508.03509)
*Seraj Al Mahmud Mostafa,Aravind Mohan,Jianwu Wang*

Main category: cs.LG

TL;DR: SLA-MORL通过多目标强化学习，智能地分配GPU和CPU资源，以减少训练时间和成本，同时确保SLA合规性，解决了冷启动问题和动态适应性挑战。


<details>
  <summary>Details</summary>
Motivation: 云环境中机器学习工作负载的动态资源分配面临在最小化训练时间和运营成本的同时满足服务水平协议（SLA）约束方面的挑战。传统方法采用静态资源分配或单目标优化，导致SLA违规或资源浪费。

Method: SLA-MORL是一个多目标强化学习框架，通过智能化的资源分配来满足SLA合规性，并引入了通过历史学习或高效基线运行来解决冷启动问题，以及基于实时SLA违规严重性动态调整优化优先级的自校正系统。

Result: 与静态基线相比，SLA-MORL在处理截止日期关键型任务时训练时间减少了67.2%，在处理预算受限工作负载时成本减少了68.8%，在整体SLA合规性方面提高了73.4%。

Conclusion: SLA-MORL是一个实用的云资源管理解决方案，通过动态调整优化优先级来平衡现代机器学习训练环境中的性能、成本和可靠性。

Abstract: Dynamic resource allocation for machine learning workloads in cloud
environments remains challenging due to competing objectives of minimizing
training time and operational costs while meeting Service Level Agreement (SLA)
constraints. Traditional approaches employ static resource allocation or
single-objective optimization, leading to either SLA violations or resource
waste. We present SLA-MORL, an adaptive multi-objective reinforcement learning
framework that intelligently allocates GPU and CPU resources based on
user-defined preferences (time, cost, or balanced) while ensuring SLA
compliance. Our approach introduces two key innovations: (1) intelligent
initialization through historical learning or efficient baseline runs that
eliminates cold-start problems, reducing initial exploration overhead by 60%,
and (2) dynamic weight adaptation that automatically adjusts optimization
priorities based on real-time SLA violation severity, creating a
self-correcting system. SLA-MORL constructs a 21-dimensional state
representation capturing resource utilization, training progress, and SLA
compliance, enabling an actor-critic network to make informed allocation
decisions across 9 possible actions. Extensive evaluation on 13 diverse ML
workloads using production HPC infrastructure demonstrates that SLA-MORL
achieves 67.2% reduction in training time for deadline-critical jobs, 68.8%
reduction in costs for budget-constrained workloads, and 73.4% improvement in
overall SLA compliance compared to static baselines. By addressing both
cold-start inefficiency and dynamic adaptation challenges, SLA-MORL provides a
practical solution for cloud resource management that balances performance,
cost, and reliability in modern ML training environments.

</details>


### [257] [VRPRM: Process Reward Modeling via Visual Reasoning](https://arxiv.org/abs/2508.03556)
*Xinquan Chen,Bangwei Liu,Xuhong Wang*

Main category: cs.LG

TL;DR: VRPRM通过视觉推理和高效训练策略，以更低成本提升了LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRM）在LLM的后训练中被广泛使用，但缺乏长期推理和深度思考能力。虽然一些工作尝试引入思维链（CoT）能力，但CoT-PRM数据的标注成本过高，难以在各种任务中稳定发挥作用。为了解决这些挑战，需要一种新的方法来提升PRM的推理能力并降低数据成本。

Method: 提出了一种名为VRPRM（Visual Reasoning Process Reward Model）的视觉推理过程奖励模型，并设计了一种高效的双阶段训练策略。

Result: 实验结果表明，VRPRM仅使用3.6K的CoT-PRM SFT数据和50K的非CoT PRM RL训练数据，就能在BoN实验中超越数据总量为400K的非思考PRM，并相对于基线模型实现了高达118%的性能提升。

Conclusion: 该研究提出的VRPRM通过视觉推理和高效的双阶段训练策略，在较低的数据标注成本下实现了高质量的推理能力，为PRM训练提供了新范式，实现了更有效的数据利用。

Abstract: Process Reward Model (PRM) is widely used in the post-training of Large
Language Model (LLM) because it can perform fine-grained evaluation of the
reasoning steps of generated content. However, most PRMs lack long-term
reasoning and deep thinking capabilities. On the other hand, although a few
works have tried to introduce Chain-of-Thought capability into PRMs, the
annotation cost of CoT-PRM data is too expensive to play a stable role in
various tasks. To address the above challenges, we propose VRPRM, a process
reward model via visual reasoning, and design an efficient two-stage training
strategy. Experimental results show that using only 3.6K CoT-PRM SFT data and
50K non-CoT PRM RL training data, VRPRM can surpass the non-thinking PRM with a
total data volume of 400K and achieved a relative performance improvement of up
to 118\% over the base model in the BoN experiment. This result confirms that
the proposed combined training strategy can achieve higher quality reasoning
capabilities at a lower data annotation cost, thus providing a new paradigm for
PRM training with more efficient data utilization.

</details>


### [258] [Heterogeneity-Oblivious Robust Federated Learning](https://arxiv.org/abs/2508.03579)
*Weiyao Zhang,Jinyang Li,Qi Song,Miao Wang,Chungang Lin,Haitong Luo,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: Horus是一个新的联邦学习框架，它使用低秩适应（LoRA）来抵抗因数据、通信和模型差异（异构性）引起的中毒攻击。它只聚合LoRA，并利用LoRA-A的稳定性来识别和过滤恶意客户端，同时优化聚合过程以提高准确性。实验证明Horus比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在真实世界的超异构环境下（客户端在数据分布、通信能力和模型架构方面存在显著差异）仍然容易受到中毒攻击。这种异构性不仅削弱了聚合策略的有效性，还增加了攻击检测的难度。此外，高维模型也扩大了攻击面。因此，需要一个能够应对这些挑战的鲁棒FL框架。

Method: Horus框架通过将LoRA插入经验上稳定的层，并仅聚合LoRA来减小攻击面。利用LoRA-A（输入投影）比LoRA-B（输出投影）在异构性和中毒性下更稳定的关键观察，设计了一个基于LoRA-A特征的异构性无关中毒评分来过滤中毒客户端。对于剩余的良性客户端，提出了一种投影感知的聚合机制，通过与全局方向的一致性对客户端更新进行重新加权，以在抑制漂移的同时保留协作信号。

Result: Horus框架在各种数据集、模型架构和攻击下进行了广泛的实验，结果表明，在鲁棒性和准确性方面，Horus始终优于最先进的基线方法。

Conclusion: Horus框架在真实世界的超异构环境下，通过利用低秩适应（LoRA）技术，显著提高了联邦学习（FL）的鲁棒性和准确性，能够有效抵御中毒攻击，并且优于现有的基线方法。

Abstract: Federated Learning (FL) remains highly vulnerable to poisoning attacks,
especially under real-world hyper-heterogeneity, where clients differ
significantly in data distributions, communication capabilities, and model
architectures. Such heterogeneity not only undermines the effectiveness of
aggregation strategies but also makes attacks more difficult to detect.
Furthermore, high-dimensional models expand the attack surface. To address
these challenges, we propose Horus, a heterogeneity-oblivious robust FL
framework centered on low-rank adaptations (LoRAs). Rather than aggregating
full model parameters, Horus inserts LoRAs into empirically stable layers and
aggregates only LoRAs to reduce the attack surface.We uncover a key empirical
observation that the input projection (LoRA-A) is markedly more stable than the
output projection (LoRA-B) under heterogeneity and poisoning. Leveraging this,
we design a Heterogeneity-Oblivious Poisoning Score using the features from
LoRA-A to filter poisoned clients. For the remaining benign clients, we propose
projection-aware aggregation mechanism to preserve collaborative signals while
suppressing drifts, which reweights client updates by consistency with the
global directions. Extensive experiments across diverse datasets, model
architectures, and attacks demonstrate that Horus consistently outperforms
state-of-the-art baselines in both robustness and accuracy.

</details>


### [259] [DeepFaith: A Domain-Free and Model-Agnostic Unified Framework for Highly Faithful Explanations](https://arxiv.org/abs/2508.03586)
*Yuhan Guo,Lizhong Ding,Shihan Jia,Yanyu Ren,Pengqi Li,Jiarun Fu,Changsheng Li,Ye yuan,Guoren Wang*

Main category: cs.LG

TL;DR: DeepFaith是一个新的AI解释框架，它通过统一忠实性指标来提供一个客观的评估标准，解决了现有AI解释方法缺乏统一最优解的问题。该框架在多项测试中表现优于其他方法，证明了其有效性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释AI（XAI）方法缺乏一个统一的最优解释，导致无法进行客观的评估和优化。

Method: 提出了一种名为DeepFaith的、不依赖领域和模型的统一解释框架。该框架基于忠实性原则，通过统一多种广泛使用的、经过充分验证的忠实性指标的表述，推导出最优解释目标。通过设计一个解释器学习框架，该框架利用多种现有的解释方法，进行去重和过滤以构建高质量的监督解释信号，并通过优化模式一致性损失和局部相关性来训练一个忠实的解释器。训练完成后，DeepFaith可以通过单次前向传播生成高度忠实的解释，而无需访问被解释的模型。

Result: 在12个不同解释任务（涵盖6个模型和6个数据集）上，DeepFaith实现了比所有基线方法都更高的整体忠实性（基于10项指标），证明了其有效性和跨领域通用性。

Conclusion: DeepFaith是一个新提出的、不依赖领域和模型的统一的可解释AI框架，它基于忠实性原则，通过统一多种忠实性指标的表述，推导出一个最优解释目标，为可解释AI的评估和优化提供了理论上的真实依据。该框架通过一种包含去重、过滤和优化（模式一致性损失与局部相关性）的学习框架来训练一个可信的解释器，训练完成后，DeepFaith无需访问被解释模型即可生成高度可信的解释。在12个跨越6个模型和6个数据集的解释任务中，DeepFaith在10项指标上的整体忠实性均优于所有基线方法，证明了其有效性和跨领域通用性。

Abstract: Explainable AI (XAI) builds trust in complex systems through model
attribution methods that reveal the decision rationale. However, due to the
absence of a unified optimal explanation, existing XAI methods lack a ground
truth for objective evaluation and optimization. To address this issue, we
propose Deep architecture-based Faith explainer (DeepFaith), a domain-free and
model-agnostic unified explanation framework under the lens of faithfulness. By
establishing a unified formulation for multiple widely used and well-validated
faithfulness metrics, we derive an optimal explanation objective whose solution
simultaneously achieves optimal faithfulness across these metrics, thereby
providing a ground truth from a theoretical perspective. We design an explainer
learning framework that leverages multiple existing explanation methods,
applies deduplicating and filtering to construct high-quality supervised
explanation signals, and optimizes both pattern consistency loss and local
correlation to train a faithful explainer. Once trained, DeepFaith can generate
highly faithful explanations through a single forward pass without accessing
the model being explained. On 12 diverse explanation tasks spanning 6 models
and 6 datasets, DeepFaith achieves the highest overall faithfulness across 10
metrics compared to all baseline methods, highlighting its effectiveness and
cross-domain generalizability.

</details>


### [260] [Zero-Variance Gradients for Variational Autoencoders](https://arxiv.org/abs/2508.03587)
*Zilei Shao,Anji Liu,Guy Van den Broeck*

Main category: cs.LG

TL;DR: 提出“沉默梯度”方法，通过分析计算ELBO得到零方差梯度，解决生成模型训练中的估计方差问题，并提高现有基线性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决训练深度生成模型（如变分自编码器）时，由于反向传播梯度通过潜在变量的随机采样而产生的估计方差问题，该问题会减慢收敛速度并降低性能。

Method: 提出“沉默梯度”方法，利用特定解码器结构分析计算ELBO，得到零方差梯度。引入一种新的训练动态，在早期训练阶段使用精确的零方差梯度，之后过渡到标准的随机估计器。

Result: 实验结果表明，该技术在多个数据集上一致性地提高了现有基线（包括重参数化、Gumbel-Softmax和REINFORCE）的性能。

Conclusion: 该研究通过引入“沉默梯度”的概念，提出了一种新的训练深度生成模型的方法，该方法通过利用特定的解码器结构来分析计算期望的证据下界（ELBO），从而得到一个零方差的梯度，解决了现有方法中因随机采样引入的估计方差问题。

Abstract: Training deep generative models like Variational Autoencoders (VAEs) is often
hindered by the need to backpropagate gradients through the stochastic sampling
of their latent variables, a process that inherently introduces estimation
variance, which can slow convergence and degrade performance. In this paper, we
propose a new perspective that sidesteps this problem, which we call Silent
Gradients. Instead of improving stochastic estimators, we leverage specific
decoder architectures to analytically compute the expected ELBO, yielding a
gradient with zero variance. We first provide a theoretical foundation for this
method and demonstrate its superiority over existing estimators in a controlled
setting with a linear decoder. To generalize our approach for practical use
with complex, expressive decoders, we introduce a novel training dynamic that
uses the exact, zero-variance gradient to guide the early stages of encoder
training before annealing to a standard stochastic estimator. Our experiments
show that this technique consistently improves the performance of established
baselines, including reparameterization, Gumbel-Softmax, and REINFORCE, across
multiple datasets. This work opens a new direction for training generative
models by combining the stability of analytical computation with the
expressiveness of deep, nonlinear architecture.

</details>


### [261] [VITA: Variational Pretraining of Transformers for Climate-Robust Crop Yield Forecasting](https://arxiv.org/abs/2508.03589)
*Adib Hasan,Mardavij Roozbehani,Munther Dahleh*

Main category: cs.LG

TL;DR: VITA是一种新的AI框架，可以更准确地预测作物产量，尤其是在极端天气条件下，并且所需数据更少。


<details>
  <summary>Details</summary>
Motivation: 当前的AI模型在预测偏离历史趋势的作物产量时表现不佳，主要是由于预训练天气数据集丰富而用于微调的数据有限所导致的数据挑战。

Method: 提出了一种名为VITA（Variational Inference Transformer for Asymmetric data）的变分预训练框架，通过使用详细的天气变量作为代理目标，并通过自监督特征掩码学习预测丰富的原子状态来解决数据不对称问题。该模型可以直接使用基本的天气统计数据进行微调。

Result: VITA在预测玉米和大豆产量方面取得了最先进的性能，在所有评估场景中均表现优异。在极端天气年份，其性能提升尤为显著（p≈0.01）。此外，VITA的性能优于GNN-RNN等现有框架，且所需数据量更少。

Conclusion: VITA（Variational Inference Transformer for Asymmetric data）框架能够克服数据限制，提高农业预测的韧性，尤其是在气候变化背景下。该模型在数据稀疏区域具有实际应用价值，并且优于之前的框架。

Abstract: Accurate crop yield forecasting is essential for global food security.
However, current AI models systematically underperform when yields deviate from
historical trends. This issue arises from key data challenges, including a
major asymmetry between rich pretraining weather datasets and the limited data
available for fine-tuning. We introduce VITA (Variational Inference Transformer
for Asymmetric data), a variational pretraining framework that addresses this
asymmetry. Instead of relying on input reconstruction, VITA uses detailed
weather variables as proxy targets during pretraining and learns to predict
rich atmospheric states through self-supervised feature masking. This allows
the model to be fine-tuned using only basic weather statistics during
deployment. Applied to 763 counties in the U.S. Corn Belt, VITA achieves
state-of-the-art performance in predicting corn and soybean yields across all
evaluation scenarios. While it consistently delivers superior performance under
normal conditions, its advantages are particularly pronounced during extreme
weather years, with statistically significant improvements (paired t-test, $p
\approx 0.01$). Importantly, VITA outperforms prior frameworks like GNN-RNN
using less data, making it more practical for real-world use--particularly in
data-scarce regions. This work highlights how domain-aware AI design can
overcome data limitations and support resilient agricultural forecasting in a
changing climate.

</details>


### [262] [SolarSeer: Ultrafast and accurate 24-hour solar irradiance forecasts outperforming numerical weather prediction across the USA](https://arxiv.org/abs/2508.03590)
*Mingliang Bai,Zuliang Fang,Shengyu Tao,Siqi Xiang,Jiang Bian,Yanfei Xiang,Pengcheng Zhao,Weixin Jin,Jonathan A. Weyn,Haiyu Dong,Bin Zhang,Hongyu Sun,Kit Thambiratnam,Qi Zhang,Hongbin Sun,Xuan Zhang,Qiuwei Wu*

Main category: cs.LG

TL;DR: SolarSeer是一个创下纪录的人工智能模型，可以极其快速和准确地预测太阳能。


<details>
  <summary>Details</summary>
Motivation: 准确的24小时太阳辐照度预测对于太阳能光伏系统的安全经济运行至关重要，传统数值天气预测（NWP）模型计算成本高昂。

Method: 提出了一种名为SolarSeer的端到端大型人工智能模型，直接将历史卫星观测映射到未来预测，无需数据同化和偏微分方程求解。

Result: SolarSeer比传统NWP模型快1500倍以上，能在3秒内生成美国5公里分辨率的24小时云量和太阳辐照度预测。与HRRR模型相比，SolarSeer将太阳辐照度预测的均方根误差降低了27.28%（再分析数据）和15.35%（1800个站点），并能有效捕捉辐照度波动，提高了一阶辐照度差的预测精度。

Conclusion: SolarSeer通过端到端的大型人工智能模型，实现了高效且准确的24小时太阳辐照度预测，为可持续能源系统提供了有力支持。

Abstract: Accurate 24-hour solar irradiance forecasting is essential for the safe and
economic operation of solar photovoltaic systems. Traditional numerical weather
prediction (NWP) models represent the state-of-the-art in forecasting
performance but rely on computationally costly data assimilation and solving
complicated partial differential equations (PDEs) that simulate atmospheric
physics. Here, we introduce SolarSeer, an end-to-end large artificial
intelligence (AI) model for solar irradiance forecasting across the Contiguous
United States (CONUS). SolarSeer is designed to directly map the historical
satellite observations to future forecasts, eliminating the computational
overhead of data assimilation and PDEs solving. This efficiency allows
SolarSeer to operate over 1,500 times faster than traditional NWP, generating
24-hour cloud cover and solar irradiance forecasts for the CONUS at 5-kilometer
resolution in under 3 seconds. Compared with the state-of-the-art NWP in the
CONUS, i.e., High-Resolution Rapid Refresh (HRRR), SolarSeer significantly
reduces the root mean squared error of solar irradiance forecasting by 27.28%
in reanalysis data and 15.35% across 1,800 stations. SolarSeer also effectively
captures solar irradiance fluctuations and significantly enhances the
first-order irradiance difference forecasting accuracy. SolarSeer's ultrafast,
accurate 24-hour solar irradiance forecasts provide strong support for the
transition to sustainable, net-zero energy systems.

</details>


### [263] [On the (In)Significance of Feature Selection in High-Dimensional Datasets](https://arxiv.org/abs/2508.03593)
*Bhavesh Neekhra,Debayan Gupta,Partha Pratim Chakravarti*

Main category: cs.LG

TL;DR: 在高维数据集（尤其是基因表达）的分类任务中，特征选择（FS）可能并无用处，随机选择的特征子集往往能提供相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高模型性能、降低计算成本和识别感兴趣的特征，对高维数据集的特征选择（FS）算法进行了广泛研究。

Method: 通过测试使用随机选择的特征来对比特征选择（FS）算法选择的特征，以验证后者的性能。

Result: 研究结果表明，在（尤其是基因表达）高维数据集的分类任务中，特征选择（FS）并无用处。研究发现，（1）在随机选择的特征的小子集（占所有特征的0.02%-1%）上训练的模型，其性能几乎总是与在所有特征上训练的模型相当，（2）一个“典型”大小的随机子集提供的性能，与各种已出版研究中选择的前k个特征相当或更优。

Conclusion: 该研究结果对许多在高维数据集（尤其是在计算基因组学中）上进行特征选择的研究提出了质疑，并对那些在没有湿实验室进一步验证的情况下，基于计算选择的基因来设计药物或靶向干预的研究提出了严重关切。

Abstract: Extensive research has been done on feature selection (FS) algorithms for
high-dimensional datasets aiming to improve model performance, reduce
computational cost and identify features of interest. We test the null
hypothesis of using randomly selected features to compare against features
selected by FS algorithms to validate the performance of the latter. Our
results show that FS on high-dimensional datasets (in particular gene
expression) in classification tasks is not useful. We find that (1) models
trained on small subsets (0.02%-1% of all features) of randomly selected
features almost always perform comparably to those trained on all features, and
(2) a "typical"- sized random subset provides comparable or superior
performance to that of top-k features selected in various published studies.
Thus, our work challenges many feature selection results on high dimensional
datasets, particularly in computational genomics. It raises serious concerns
about studies that propose drug design or targeted interventions based on
computationally selected genes, without further validation in a wet lab.

</details>


### [264] [Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction](https://arxiv.org/abs/2508.03613)
*Yong Lin,Shange Tang,Bohan Lyu,Ziran Yang,Jui-Hui Chung,Haoyu Zhao,Lai Jiang,Yihan Geng,Jiawei Ge,Jingruo Sun,Jiayun Wu,Jiri Gesi,Ximing Lu,David Acuna,Kaiyu Yang,Hongzhou Lin,Yejin Choi,Danqi Chen,Sanjeev Arora,Chi Jin*

Main category: cs.LG

TL;DR: Goedel-Prover-V2 是一个强大的开源语言模型系列，通过创新的数据合成、自我修正和模型平均技术，在自动化定理证明任务上达到了新的先进水平，显著优于现有模型，同时保持了更小的模型尺寸和计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了在自动化定理证明领域取得新的进展，我们引入了 Goedel-Prover-V2 系列开源语言模型。

Method: 采用专家迭代和强化学习流水线，并结合了三个关键创新：1. 脚手架式数据合成：生成难度递增的合成任务以训练模型掌握更复杂的定理。2. 验证器引导的自我修正：利用 Lean 编译器的反馈，使模型能够迭代地修改其证明。3. 模型平均：合并模型检查点以缓解训练后期模型输出多样性的下降。

Result: Goedel-Prover-V2-8B 在 MiniF2F 上的 pass@32 达到了 84.6%，优于 DeepSeek-Prover-V2-671B，尽管模型尺寸小 80 倍。旗舰模型 Goedel-Prover-V2-32B 在 MiniF2F 上的 pass@32（标准模式和自我修正模式）分别达到 88.1% 和 90.4%。在 PutnamBench 上，该模型在 pass@184 下解决了 86 个问题，成为开源模型中的第一名，并且在受限的测试时间计算预算下，其性能优于包括闭源系统在内的其他模型。

Conclusion: Goedel-Prover-V2 在 MiniF2F 和 PutnamBench 上均取得了最先进的性能，并且优于现有的开源和闭源模型，同时模型尺寸和计算成本却显著降低。

Abstract: We introduce Goedel-Prover-V2, a series of open-source language models that
set a new state-of-the-art in automated theorem proving. Built on the standard
expert iteration and reinforcement learning pipeline, our approach incorporates
three key innovations: (1) Scaffolded data synthesis: We generate synthetic
tasks of increasing difficulty to train the model to master increasingly
complex theorems; (2) Verifier-guided self-correction: We enable the model to
iteratively revise its proofs by leveraging feedback from the Lean compiler;
(3) Model averaging: We merge model checkpoints to mitigate the decrease in
model output diversity in later stages of training. Our small model,
Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms
DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our
flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in
standard mode and 90.4% in self-correction mode, outperforming prior SOTA by a
large margin. Additionally, our flagship model solves 86 problems on
PutnamBench at pass@184, securing the first place among open-source models on
the leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47
problems by pass@1024 with a significantly smaller model size and compute
budget. At the time of its release (July-August 2025), Goedel-Prover-V2
achieves the strongest overall performance among all open-source theorem
provers. It also ranks among the top-performing models--including closed-source
systems with publicly reported performance--under a constrained test-time
compute budget. Our models, code, and data are released at
https://github.com/Goedel-LM/Goedel-Prover-V2.

</details>


### [265] [Pair Correlation Factor and the Sample Complexity of Gaussian Mixtures](https://arxiv.org/abs/2508.03633)
*Farzad Aryan*

Main category: cs.LG

TL;DR: Learning Gaussian Mixture Models depends not only on component separation but also on the PCF, which better predicts difficulty. An algorithm with improved sample complexity is presented for a specific case.


<details>
  <summary>Details</summary>
Motivation: To understand which structural properties govern the sample complexity of learning Gaussian Mixture Models, challenging the prior focus on minimum pairwise separation.

Method: Introduced the Pair Correlation Factor (PCF), a geometric quantity that captures the clustering of component means, and developed an algorithm with improved sample complexity bounds for the uniform spherical case.

Result: Demonstrated that the PCF more accurately dictates the difficulty of parameter recovery compared to the minimum gap, and provided an algorithm showing when more than $\epsilon^{-2}$ samples are necessary in the uniform spherical case.

Conclusion: The minimum pairwise separation between components is not the sole determinant of sample complexity for learning Gaussian Mixture Models; the Pair Correlation Factor (PCF) also plays a crucial role.

Abstract: We study the problem of learning Gaussian Mixture Models (GMMs) and ask:
which structural properties govern their sample complexity? Prior work has
largely tied this complexity to the minimum pairwise separation between
components, but we demonstrate this view is incomplete.
  We introduce the \emph{Pair Correlation Factor} (PCF), a geometric quantity
capturing the clustering of component means. Unlike the minimum gap, the PCF
more accurately dictates the difficulty of parameter recovery.
  In the uniform spherical case, we give an algorithm with improved sample
complexity bounds, showing when more than the usual $\epsilon^{-2}$ samples are
necessary.

</details>


### [266] [Cross-patient Seizure Onset Zone Classification by Patient-Dependent Weight](https://arxiv.org/abs/2508.03635)
*Xuyang Zhao,Hidenori Sugano,Toshihisa Tanaka*

Main category: cs.LG

TL;DR: A new method improves seizure onset zone identification by using patient-specific weights to fine-tune machine learning models, overcoming data distribution differences across patients and boosting accuracy by over 10%.


<details>
  <summary>Details</summary>
Motivation: Identifying the seizure onset zone (SOZ) is crucial for epilepsy surgery but relies on subjective visual judgment. Machine learning shows promise, but a "cross-patient problem" exists where models struggle with data distribution differences across individual patients, hindering consistent performance.

Method: A supervised learning method is used to train a machine learning model. Intermediate features from test patient data are used to define similarity with training patient data, determining weights for each training patient. The pretrained model is then fine-tuned using training data and these patient-specific weights.

Result: The leave-one-patient-out evaluation demonstrates improved classification accuracy for every test patient, achieving an average improvement of over 10% compared to existing methods.

Conclusion: The proposed method, which fine-tunes a pretrained model using patient-specific weights, shows improved classification accuracy for every test patient, with an average improvement of over 10% in identifying the seizure onset zone.

Abstract: Identifying the seizure onset zone (SOZ) in patients with focal epilepsy is
essential for surgical treatment and remains challenging due to its dependence
on visual judgment by clinical experts. The development of machine learning can
assist in diagnosis and has made promising progress. However, unlike data in
other fields, medical data is usually collected from individual patients, and
each patient has different illnesses, physical conditions, and medical
histories, which leads to differences in the distribution of each patient's
data. This makes it difficult for a machine learning model to achieve
consistently reliable performance in every new patient dataset, which we refer
to as the "cross-patient problem." In this paper, we propose a method to
fine-tune a pretrained model using patient-specific weights for every new test
patient to improve diagnostic performance. First, the supervised learning
method is used to train a machine learning model. Next, using the intermediate
features of the trained model obtained through the test patient data, the
similarity between the test patient data and each training patient's data is
defined to determine the weight of each training patient to be used in the
following fine-tuning. Finally, we fine-tune all parameters in the pretrained
model with training data and patient weights. In the experiment, the
leave-one-patient-out method is used to evaluate the proposed method, and the
results show improved classification accuracy for every test patient, with an
average improvement of more than 10%.

</details>


### [267] [Cross-Model Semantics in Representation Learning](https://arxiv.org/abs/2508.03649)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 通过引入结构性约束，可以使深度学习模型中的内部表征在不同架构之间更加稳定和兼容，从而提高特征的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 深度网络内部表征对特定架构选择敏感，引发了关于学习结构在模型间的稳定性、对齐和可迁移性的问题。

Method: 通过结合理论洞见、经验探测和受控迁移实验，开发了一个用于测量和分析具有不同但相关架构先验的网络之间的表征对齐的框架。

Result: 结构性约束（如线性成形算子和纠正路径）会影响不同架构之间内部表征的兼容性。结构性规律确实能诱导更稳定的表征几何。

Conclusion: 结构性规律可以提高模型在架构变化下的表征几何稳定性，这表明某些归纳偏倚不仅支持模型内的泛化，还能提高模型间学习特征的互操作性。本文讨论了表征可迁移性对模型蒸馏、模块化学习以及稳健学习系统的原则性设计的影响。

Abstract: The internal representations learned by deep networks are often sensitive to
architecture-specific choices, raising questions about the stability,
alignment, and transferability of learned structure across models. In this
paper, we investigate how structural constraints--such as linear shaping
operators and corrective paths--affect the compatibility of internal
representations across different architectures. Building on the insights from
prior studies on structured transformations and convergence, we develop a
framework for measuring and analyzing representational alignment across
networks with distinct but related architectural priors. Through a combination
of theoretical insights, empirical probes, and controlled transfer experiments,
we demonstrate that structural regularities induce representational geometry
that is more stable under architectural variation. This suggests that certain
forms of inductive bias not only support generalization within a model, but
also improve the interoperability of learned features across models. We
conclude with a discussion on the implications of representational
transferability for model distillation, modular learning, and the principled
design of robust learning systems.

</details>


### [268] [Efficient Morphology-Aware Policy Transfer to New Embodiments](https://arxiv.org/abs/2508.03660)
*Michael Przystupa,Hongyao Tang,Martin Jagersand,Santiago Miret,Mariano Phielipp,Matthew E. Taylor,Glen Berseth*

Main category: cs.LG

TL;DR: 这项工作研究了将形态感知预训练与参数高效微调 (PEFT) 相结合，以提高策略样本效率和部署性能，同时减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决形态感知策略在部署到不同形态时具有次优的零样本性能的问题，而端到端微调成本高昂。

Method: 将形态感知预训练与参数高效微调（PEFT）技术（例如，调整模型权重子集、输入可学习适配器和前缀调优）相结合，以减少将形态感知策略专业化到目标形态所需的学习参数。

Result: PEFT 技术结合策略预训练通常可以比从头端到端训练的模型减少样本数量。调整不到 1% 的总参数即可提高策略性能，优于基础预训练策略的零样本性能。

Conclusion: 参数高效微调（PEFT）与预训练相结合可以减少将策略专业化到目标形态所需的模型参数数量，通常可以比从头开始端到端训练的模型更有效地提高策略性能。

Abstract: Morphology-aware policy learning is a means of enhancing policy sample
efficiency by aggregating data from multiple agents. These types of policies
have previously been shown to help generalize over dynamic, kinematic, and limb
configuration variations between agent morphologies. Unfortunately, these
policies still have sub-optimal zero-shot performance compared to end-to-end
finetuning on morphologies at deployment. This limitation has ramifications in
practical applications such as robotics because further data collection to
perform end-to-end finetuning can be computationally expensive. In this work,
we investigate combining morphology-aware pretraining with parameter efficient
finetuning (PEFT) techniques to help reduce the learnable parameters necessary
to specialize a morphology-aware policy to a target embodiment. We compare
directly tuning sub-sets of model weights, input learnable adapters, and prefix
tuning techniques for online finetuning. Our analysis reveals that PEFT
techniques in conjunction with policy pre-training generally help reduce the
number of samples to necessary to improve a policy compared to training models
end-to-end from scratch. We further find that tuning as few as less than 1% of
total parameters will improve policy performance compared the zero-shot
performance of the base pretrained a policy.

</details>


### [269] [A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design](https://arxiv.org/abs/2508.03665)
*Claudiu Leoveanu-Condrei*

Main category: cs.LG

TL;DR: 通过引入合同层，为LLM增加了可验证的保证，解决了其输出缺乏可靠性的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决生成模型（特别是LLM）在产生流畅输出的同时缺乏可验证保证的问题。

Method: 通过适配设计即契约（DbC）和类型论原则，引入一个合同层来协调每次LLM调用。该合同层规定了输入和输出的语义及类型要求，并结合概率性补救措施来引导生成过程符合要求。

Result: 合同满意度具有概率性，语义验证通过程序员指定的关于类型正确的数据结构的条件来操作性地定义。该工作提出，任何满足相同合同的两个代理在合同方面是功能等价的。

Conclusion: 该工作提出了一种将DbC和类型论原则应用于LLM的新方法，通过引入一个合同层来管理LLM调用，旨在提高LLM输出的可验证性和可靠性。

Abstract: Generative models, particularly Large Language Models (LLMs), produce fluent
outputs yet lack verifiable guarantees. We adapt Design by Contract (DbC) and
type-theoretic principles to introduce a contract layer that mediates every LLM
call. Contracts stipulate semantic and type requirements on inputs and outputs,
coupled with probabilistic remediation to steer generation toward compliance.
The layer exposes the dual view of LLMs as semantic parsers and probabilistic
black-box components. Contract satisfaction is probabilistic and semantic
validation is operationally defined through programmer-specified conditions on
well-typed data structures. More broadly, this work postulates that any two
agents satisfying the same contracts are \emph{functionally equivalent} with
respect to those contracts.

</details>


### [270] [Self-Questioning Language Models](https://arxiv.org/abs/2508.03682)
*Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak*

Main category: cs.LG

TL;DR: LLMs can learn to reason better by generating their own math and coding problems to solve, improving performance without needing new external data.


<details>
  <summary>Details</summary>
Motivation: The paper investigates whether large language models can improve their reasoning abilities without external data by generating their own training examples (questions and answers). The core hypothesis is that a pre-trained model, given a topic prompt, can autonomously enhance its skills through self-generated challenges.

Method: SQLM utilizes an asymmetric self-play framework where a 'proposer' model generates questions (or unit tests for coding problems) based on a given topic, and a 'solver' model attempts to answer them. Both models are trained using reinforcement learning. The proposer is rewarded for generating problems of appropriate difficulty, while the solver is rewarded based on majority voting as a proxy for correctness.

Result: Experimental results on three benchmarks (three-digit multiplication, OMEGA algebra problems, and Codeforces programming problems) demonstrate that the SQLM framework enables language models to improve their performance. This improvement is achieved through the continuous generation of increasingly complex problems and the subsequent attempts to solve them, showcasing the model's capacity for self-improvement.

Conclusion: The proposed Self-Questioning Language Models (SQLM) framework, an asymmetric self-play approach, allows pre-trained language models to improve their reasoning skills by generating their own questions and answers. This method enhances performance on downstream benchmarks like three-digit multiplication, algebra problems, and programming problems without relying on curated external datasets.

Abstract: Can large language models improve without external data -- by generating
their own questions and answers? We hypothesize that a pre-trained language
model can improve its reasoning skills given only a single prompt specifying
the topic (e.g., algebra word problems) and asking the model to generate its
own questions. To do this, we propose Self-Questioning Language Models (SQLM):
an asymmetric self-play framework where a proposer is given the topic and
generates a question for a solver, who tries to answer it. Both the proposer
and solver are trained via reinforcement learning. The proposer receives a
reward if the problem is not too easy or too difficult, and the solver receives
a reward based on majority voting, a proxy for correctness in the absence of
ground-truth answers. For coding, the proposer can instead generate unit tests
which are used for verification. We study this asymmetric self-play framework
on three benchmarks: three-digit multiplication, algebra problems from the
OMEGA benchmark, and programming problems from Codeforces. By continually
generating more interesting problems and attempting to solve them, language
models can improve on downstream benchmarks without access to any curated
training datasets.

</details>


### [271] [No LLM Solved Yu Tsumura's 554th Problem](https://arxiv.org/abs/2508.03685)
*Simon Frieder,William Hart*

Main category: cs.LG

TL;DR: LLM无法解决一个有公开解的IMO数学题。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在解决具有一定难度和特定类型数学问题上的实际能力，以挑战其在问题解决方面日益增长的乐观情绪。

Method: 通过测试一个特定的IMO问题（Yu Tsumura

Result: 表明，尽管LLM在其他方面表现出色，但在解决Yu Tsumura的第554个问题时遇到了困难，该问题在难度、技术要求和训练数据可及性方面都具有代表性。

Conclusion: 现有的大型语言模型（LLM）在解决数学问题方面存在局限性，即使是那些被认为在IMO（国际数学奥林匹克）范围内且有公开解决方案的问题，LLM也无法解决。

Abstract: We show, contrary to the optimism about LLM's problem-solving abilities,
fueled by the recent gold medals that were attained, that a problem exists --
Yu Tsumura's 554th problem -- that a) is within the scope of an IMO problem in
terms of proof sophistication, b) is not a combinatorics problem which has
caused issues for LLMs, c) requires fewer proof techniques than typical hard
IMO problems, d) has a publicly available solution (likely in the training data
of LLMs), and e) that cannot be readily solved by any existing off-the-shelf
LLM (commercial or open-source).

</details>


### [272] [PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement Learning](https://arxiv.org/abs/2508.03693)
*Ondrej Bajgar,Dewi S. W. Gould,Jonathon Liu,Alessandro Abate,Konstantinos Gatsis,Michael A. Osborne*

Main category: cs.LG

TL;DR: 主动IRL通过PAC-EIG（一种信息论方法）来解决获取演示以实现可靠性保证的成本问题，该方法可以直接实现PAC保证，并已被证明比以前的方法更有效。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统日益自主，可靠地将其决策与人类偏好保持一致至关重要。逆向强化学习（IRL）是从演示中推断偏好的有希望的方法。然而，在自动驾驶或机器人等错误可能导致严重后果的领域，需要可靠的具有正式保证的策略，但获取足够的演示以获得可靠性保证可能成本高昂。主动IRL通过战略性地选择最具信息量的演示场景来解决这一挑战。

Method: PAC-EIG是一种信息论采集函数，用于主动IRL，以直接实现学徒策略的概率近似正确（PAC）保证。Reward-EIG是学习奖励本身时的替代方案。研究集中在有限状态动作空间上，并证明了收敛界限。

Result: 该方法在有限状态动作空间上证明了收敛界限，说明了先前启发式方法的失败模式，并通过实验证明了该方法的优势。

Conclusion: PAC-EIG是第一个针对具有噪声专家演示的主动IRL提供概率近似正确（PAC）保证的理论保证，通过最大化关于学徒策略的后悔的信息增益来有效地识别需要进一步演示的状态。Reward-EIG是学习奖励本身的主要目标的替代方案。

Abstract: As AI systems become increasingly autonomous, reliably aligning their
decision-making to human preferences is essential. Inverse reinforcement
learning (IRL) offers a promising approach to infer preferences from
demonstrations. These preferences can then be used to produce an apprentice
policy that performs well on the demonstrated task. However, in domains like
autonomous driving or robotics, where errors can have serious consequences, we
need not just good average performance but reliable policies with formal
guarantees -- yet obtaining sufficient human demonstrations for reliability
guarantees can be costly. Active IRL addresses this challenge by strategically
selecting the most informative scenarios for human demonstration. We introduce
PAC-EIG, an information-theoretic acquisition function that directly targets
probably-approximately-correct (PAC) guarantees for the learned policy --
providing the first such theoretical guarantee for active IRL with noisy expert
demonstrations. Our method maximises information gain about the regret of the
apprentice policy, efficiently identifying states requiring further
demonstration. We also present Reward-EIG as an alternative when learning the
reward itself is the primary objective. Focusing on finite state-action spaces,
we prove convergence bounds, illustrate failure modes of prior heuristic
methods, and demonstrate our method's advantages experimentally.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [273] [Frequency Point Game Environment for UAVs via Expert Knowledge and Large Language Model](https://arxiv.org/abs/2508.02757)
*Jingpu Yang*

Main category: cs.MA

TL;DR: 提出UAV-FPG模型，利用博弈论、专家知识和大型语言模型优化无人机通信的抗干扰和路径规划，实验证明其优于固定策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决频谱竞争建模、专家知识集成和对手行为预测等挑战。

Method: 提出了一种名为UAV-FPG（无人机-频率点博弈）的博弈论环境模型，该模型结合了先验专家知识库和大型语言模型来优化频率选择和路径规划，模拟“强敌”。

Result: 实验结果表明，集成专家知识库和大型语言模型是有效的，其中大型语言模型通过迭代交互显著提高了动态场景下的路径规划能力，优于固定路径策略。

Conclusion: UAV-FPG提供了一个稳健的平台，用于推进无人机通信系统中的抗干扰策略和智能决策。

Abstract: Unmanned Aerial Vehicles (UAVs) have made significant advancements in
communication stability and security through techniques such as frequency
hopping, signal spreading, and adaptive interference suppression. However,
challenges remain in modeling spectrum competition, integrating expert
knowledge, and predicting opponent behavior. To address these issues, we
propose UAV-FPG (Unmanned Aerial Vehicle - Frequency Point Game), a
game-theoretic environment model that simulates the dynamic interaction between
interference and anti-interference strategies of opponent and ally UAVs in
communication frequency bands. The model incorporates a prior expert knowledge
base to optimize frequency selection and employs large language models for path
planning, simulating a "strong adversary". Experimental results highlight the
effectiveness of integrating the expert knowledge base and the large language
model, with the latter significantly improving path planning in dynamic
scenarios through iterative interactions, outperforming fixed-path strategies.
UAV-FPG provides a robust platform for advancing anti-jamming strategies and
intelligent decision-making in UAV communication systems.

</details>


### [274] [TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding](https://arxiv.org/abs/2508.02826)
*Conor Wallace,Umer Siddique,Yongcan Cao*

Main category: cs.MA

TL;DR: 提出了一种名为TransAM的新型基于Transformer的主体建模方法，该方法能够仅根据受控主体本地轨迹学习其他主体策略的鲁棒表示，并在多主体环境中提高了主体建模和情景回报。


<details>
  <summary>Details</summary>
Motivation: 为了在多主体系统中开发有效的策略，主体建模至关重要，因为这使得主体能够形成关于其他主体行为、意图和能力的信念。然而，许多现有方法假定可以访问其他主体的轨迹，这在实际应用中往往是不现实的。因此，一种实用的主体建模方法必须仅根据受控主体本地轨迹学习其他主体策略的鲁棒表示。

Method: 提出了一种名为TransAM的新型基于Transformer的主体建模方法，该方法将本地轨迹编码到能有效捕捉其他主体策略的嵌入空间中。

Result: 实验结果表明，TransAM能够生成强大的策略表示，改进主体建模，并提高情景回报。

Conclusion: TransAM在合作、竞争和混合多主体环境中都表现出了强大的策略表示能力，提高了主体建模，并带来了更高的情景回报。

Abstract: Agent modeling is a critical component in developing effective policies
within multi-agent systems, as it enables agents to form beliefs about the
behaviors, intentions, and competencies of others. Many existing approaches
assume access to other agents' episodic trajectories, a condition often
unrealistic in real-world applications. Consequently, a practical agent
modeling approach must learn a robust representation of the policies of the
other agents based only on the local trajectory of the controlled agent. In
this paper, we propose \texttt{TransAM}, a novel transformer-based agent
modeling approach to encode local trajectories into an embedding space that
effectively captures the policies of other agents. We evaluate the performance
of the proposed method in cooperative, competitive, and mixed multi-agent
environments. Extensive experimental results demonstrate that our approach
generates strong policy representations, improves agent modeling, and leads to
higher episodic returns.

</details>


### [275] [Engineered over Emergent Communication in MARL for Scalable and Sample-Efficient Cooperative Task Allocation in a Partially Observable Grid](https://arxiv.org/abs/2508.02912)
*Brennen A. Hill,Mant Koh En Wei,Thangavel Jishnuanandh*

Main category: cs.MA

TL;DR: 本文比较了学习到的通信（LDC）和工程化通信（意图通信）在合作 MARL 环境中的效果，发现意图通信在复杂性增加时性能更优。


<details>
  <summary>Details</summary>
Motivation: 本文旨在比较学习到的通信策略与工程化通信策略在合作的多智能体强化学习（MARL）环境中的有效性。

Method: 本文提出了一种名为“学习直接通信”（LDC）的学习方法，其中智能体通过神经网络同时生成消息和动作。此外，还提出了一种工程化方法“意图通信”，它使用“想象轨迹生成模块”（ITGM）和“消息生成网络”（MGN）来根据预测的未来状态制定消息。

Result: 研究结果表明，虽然涌现式通信是可行的，但工程化方法（意图通信）表现出更优越的性能和可扩展性，特别是在环境复杂性增加的情况下。

Conclusion: 在完全和部分可观察的条件下，与学习到的通信相比，以意图通信为代表的工程化通信策略在合作任务中表现出更优越的性能和可扩展性，尤其是在环境复杂性增加的情况下。

Abstract: We compare the efficacy of learned versus engineered communication strategies
in a cooperative multi-agent reinforcement learning (MARL) environment. For the
learned approach, we introduce Learned Direct Communication (LDC), where agents
generate messages and actions concurrently via a neural network. Our engineered
approach, Intention Communication, employs an Imagined Trajectory Generation
Module (ITGM) and a Message Generation Network (MGN) to formulate messages
based on predicted future states. Both strategies are evaluated on their
success rates in cooperative tasks under fully and partially observable
conditions. Our findings indicate that while emergent communication is viable,
the engineered approach demonstrates superior performance and scalability,
particularly as environmental complexity increases.

</details>


### [276] [Distributionally Robust Markov Games with Average Reward](https://arxiv.org/abs/2508.03136)
*Zachary Roch,Yue Wang*

Main category: cs.MA

TL;DR: 本文研究了平均奖励下的分布鲁棒马尔可夫博弈（DR-MG），解决了多主体在不确定性下的长期决策问题。通过证明鲁棒纳什均衡的存在性并提出鲁棒纳什迭代算法，为复杂环境下的多主体决策提供了理论和算法支持。


<details>
  <summary>Details</summary>
Motivation: 平均奖励标准能更好地捕捉持续运行系统的长期性能，因为在持续运行的系统中，系统的可靠性至关重要。本文旨在解决不确定性下的长期决策问题。

Method: 本文首先建立了多主体与单主体设置之间的联系，并推导了平均奖励公式下鲁棒贝尔曼方程的可解性。然后，证明了鲁棒纳什均衡（NE）的存在性。接着，开发并分析了一种名为鲁棒纳什迭代（robust Nash-Iteration）的算法来计算所有主体中的鲁棒纳什均衡。最后，证明了平均奖励NE与折扣NE之间的联系，并表明前者可以作为折扣因子趋近于1时的近似值。

Result: 证明了平均奖励下分布鲁棒马尔可夫博弈（DR-MG）中鲁棒纳什均衡（NE）的存在性。并提出了一种名为鲁棒纳什迭代（robust Nash-Iteration）的算法来计算鲁棒纳什均衡，该算法能够为复杂、不确定且长期运行的多主体环境提供实用的最优策略。最后，证明了平均奖励NE可以作为折扣因子趋近于1时的近似值。

Conclusion: 本文为平均奖励下的分布鲁棒马尔可夫博弈（DR-MG）提供了理论和算法基础，解决了多主体在不确定性下的长期决策问题，并证明了鲁棒纳什均衡的存在性，最后展示了平均奖励与折扣奖励之间的联系。

Abstract: This paper introduces the formulation of a distributionally robust Markov
game (DR-MG) with average rewards, a crucial framework for multi-agent
decision-making under uncertainty over extended horizons. Unlike finite-horizon
or discounted models, the average-reward criterion naturally captures long-term
performance for systems designed for continuous operation, where sustained
reliability is paramount. We account for uncertainty in transition kernels,
with players aiming to optimize their worst-case average reward. We first
establish a connection between the multi-agent and single agent settings, and
derive the solvability of the robust Bellman equation under the average-reward
formulation. We then rigorously prove the existence of a robust Nash
Equilibrium (NE), offering essential theoretical guarantees for system
stability. We further develop and analyze an algorithm named robust
Nash-Iteration to compute the robust Nash Equilibria among all agents,
providing practical tools for identifying optimal strategies in complex,
uncertain, and long-running multi-player environments. Finally, we demonstrate
the connection between the average-reward NE and the well-studied discounted
NEs, showing that the former can be approximated as the discount factor
approaches one. Together, these contributions provide a comprehensive
theoretical and algorithmic foundation for identifying optimal strategies in
complex, uncertain, and long-running multi-player environments, which allow for
the future extension of robust average-reward single-agent problems to the
multi-agent setting.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [277] [Can We Fix Social Media? Testing Prosocial Interventions using Generative Social Simulation](https://arxiv.org/abs/2508.03385)
*Maik Larooij,Petter Törnberg*

Main category: cs.SI

TL;DR: 社交媒体平台似乎加剧了两极分化和不良的辩论。研究人员使用一种称为生成性社会模拟的新方法，将大型语言模型嵌入到基于代理的模型中，以创建合成社交平台。他们发现，这些平台会产生党派回音室、精英阶层的影响力集中以及两极分化观点的放大。在测试了六种干预措施后，研究人员发现只有微小的改进，而且有时结果会更糟。这表明平台的某些基本设计可能导致了这些问题，并且可能需要对平台的架构进行重大更改才能解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体平台是否可以通过亲社会干预来减轻社会危害，例如加剧的两极分化和建设性辩论的侵蚀。

Method: 使用生成性社会模拟，将大型语言模型嵌入基于代理的模型中，以创建社交丰富的合成平台。

Result: 发现生成的关注网络复制了三个잘 documented 的功能障碍：(1) 党派回音室；(2) 精英阶层的影响力集中；(3) 两极分化声音的放大——创造了一个扭曲政治话语的“社交媒体棱镜”。测试了六种干预措施，仅取得微小改进，有时结果甚至更糟。

Conclusion: 有意义的改革可能需要重新思考平台架构的基本动态。

Abstract: Social media platforms have been widely linked to societal harms, including
rising polarization and the erosion of constructive debate. Can these problems
be mitigated through prosocial interventions? We address this question using a
novel method - generative social simulation - that embeds Large Language Models
within Agent-Based Models to create socially rich synthetic platforms. We
create a minimal platform where agents can post, repost, and follow others. We
find that the resulting following-networks reproduce three well-documented
dysfunctions: (1) partisan echo chambers; (2) concentrated influence among a
small elite; and (3) the amplification of polarized voices - creating a 'social
media prism' that distorts political discourse. We test six proposed
interventions, from chronological feeds to bridging algorithms, finding only
modest improvements - and in some cases, worsened outcomes. These results
suggest that core dysfunctions may be rooted in the feedback between reactive
engagement and network growth, raising the possibility that meaningful reform
will require rethinking the foundational dynamics of platform architecture.

</details>


### [278] [OSINT or BULLSHINT? Exploring Open-Source Intelligence tweets about the Russo-Ukrainian War](https://arxiv.org/abs/2508.03599)
*Johannes Niu,Mila Stillman,Anna Kruspe*

Main category: cs.SI

TL;DR: 本研究分析了200万条关于俄乌战争的推文，区分了真实的OSINT和虚假信息，揭示了信息传播的党派、情感和操纵模式。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在理解数字时代下的战争信息动态，特别是开源情报在俄罗斯和乌克兰冲突中的作用，以及如何识别和应对虚假信息。

Method: 研究采用了包括情感分析、党派识别、虚假信息识别和命名实体识别（NER）在内的多种分析技术，并结合了社区检测技术，以识别不同的党派、话题和虚假信息集群。

Result: 研究发现，战争事件主要影响了推文的负面情感，党派倾向呈现出亲乌克兰和亲俄罗斯的复杂分布，并且信息存在被战略性操纵的可能性。社区检测技术有效地揭示了信息在社交媒体上传播的模式。

Conclusion: 本研究深入探讨了在俄乌战争背景下，Twitter上开源情报（OSINT）的运作方式，并区分了真实的OSINT与所谓的“BULLSHINT”（欺骗性虚假信息）。通过分析2022年1月至2023年7月期间近200万条推文，我们揭示了信息传播的复杂动态。

Abstract: This paper examines the role of Open Source Intelligence (OSINT) on Twitter
regarding the Russo-Ukrainian war, distinguishing between genuine OSINT and
deceptive misinformation efforts, termed "BULLSHINT." Utilizing a dataset
spanning from January 2022 to July 2023, we analyze nearly 2 million tweets
from approximately 1,040 users involved in discussing real-time military
engagements, strategic analyses, and misinformation related to the conflict.
Using sentiment analysis, partisanship detection, misinformation
identification, and Named Entity Recognition (NER), we uncover communicative
patterns and dissemination strategies within the OSINT community. Significant
findings reveal a predominant negative sentiment influenced by war events, a
nuanced distribution of pro-Ukrainian and pro-Russian partisanship, and the
potential strategic manipulation of information. Additionally, we apply
community detection techniques, which are able to identify distinct clusters
partisanship, topics, and misinformation, highlighting the complex dynamics of
information spread on social media. This research contributes to the
understanding of digital warfare and misinformation dynamics, offering insights
into the operationalization of OSINT in geopolitical conflicts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [279] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 本研究通过实证分析，研究了LLM智能体系统的效率-性能权衡问题，并提出了一种名为“高效智能体”的新框架，该框架在保持高性能的同时显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）驱动的智能体的能力不断增强，但其成本的不断增加威胁到可扩展性和可及性。本研究旨在解决在不牺牲性能的情况下进行成本效益设计的关键需求。

Method: 通过在GAIA基准上进行实证分析，评估了LLM主干选择、智能体框架设计和测试时扩展策略的影响。使用“每次通过成本”指标量化了这些维度上的效率-性能权衡。

Result: 提出了一种名为“高效智能体”的新型智能体框架，该框架具有与任务需求相匹配的最优复杂度。与领先的开源智能体框架OWL相比，高效智能体保留了96.7%的性能，同时将运营成本从0.398美元降低到0.228美元，使每次通过成本提高了28.4%。

Conclusion: 该研究为设计高效、高性能的智能体系统提供了可操作的见解，提高了人工智能驱动解决方案的可及性和可持续性。

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [280] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 该研究提出了一种在没有域闭包假设（DCA）的情况下解决规划问题的方法，该方法适用于对象动态变化的情况。


<details>
  <summary>Details</summary>
Motivation: 克服了经典规划和一致规划中域闭包假设（DCA）的局限性，该假设假定只有预先给定的命名对象才能参与规划。

Method: 将规划问题在谓词逻辑中形式化，假设初始理论是有限的、一致的流畅文字集，确保在每种情况下只有有限的可能操作，并对计划的长度施加有限的整数约束。搜索在规划时被扎根于动作序列上。

Result: 该方法可以解决不属于顺序泛化规划（无感知动作）和一致规划的交集（限制为无流畅文字文字析取的案例）的有界规划问题。

Conclusion: 该方法是健全和完整的，可用于解决无 DCA 的有界规划问题，并已实现概念验证。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [281] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: VSNIT通过结合序列构建和动态协变量处理能力，能够更准确、更多样地恢复LBS数据中不完整的活动序列，提升了LBS数据的效用。


<details>
  <summary>Details</summary>
Motivation: LBS数据虽然能提供有价值的人类移动见解，但其稀疏性常常导致不完整的行程和活动序列，使得准确推断行程和活动变得困难。本研究提出了一个研究问题：能否利用高质量LBS数据中提取的活动序列来恢复个体层面的不完整活动序列？

Method: 提出了一种名为VSNIT（Variable Selection Network-fused Insertion Transformer）的新解决方案，它整合了Insertion Transformer的灵活序列构建能力和Variable Selection Network的动态协变量处理能力，用于恢复不完整活动序列中的缺失片段，同时保留现有数据。

Result: VSNIT插入了更多样化、更现实的活动模式，更紧密地匹配真实世界的变异性，并更有效地恢复了与目标一致的受干扰的活动转换。其在所有指标上的表现均显著优于基线模型。

Conclusion: VSNIT在活动序列恢复任务中表现出优越的准确性和多样性，有潜力提高LBS数据的效用，为未来的基于位置的研究和应用提供了一个有前途的框架。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [282] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: This paper surveys LLM-based agents for data science, covering their design principles and applications in data science tasks like preprocessing and model development, offering a framework to connect agent design with data science workflows.


<details>
  <summary>Details</summary>
Motivation: To analyze the emerging field of LLM-based agents specifically for data science tasks, summarizing recent studies and providing a framework for understanding their design and application.

Method: The paper analyzes recent studies on LLM-based agents for data science, discussing key design principles (agent roles, execution, knowledge, reflection) and data science processes (preprocessing, model development, evaluation, visualization).

Result: A comprehensive review of LLM-based agents in data science and a dual-perspective framework linking agent design with data science workflows.

Conclusion: This survey provides a comprehensive review of LLM-based agents for data science tasks and a dual-perspective framework connecting agent design principles with data science workflows.

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [283] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: 一个用于评估LLM在策略棋盘游戏中的决策能力的框架，支持多种游戏和代理，并提供模型集成和分析工具。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估大型语言模型（LLM）在策略棋盘游戏中的决策能力，并促进LLM推理和博弈论行为的实证评估。

Method: 通过封装多种棋盘和矩阵游戏，支持不同类型的代理（包括LLM、随机、人类、强化学习等），并集成LiteLLM进行API访问、vLLM进行本地模型部署以及Ray进行分布式执行，从而实现对LLM决策能力的系统性评估。

Result: 提供了一个包含多种棋盘和矩阵游戏、支持不同代理类型（LLM、随机、人类、强化学习等）的框架，并集成了模型访问、本地部署和分布式执行能力，以及LLM推理跟踪的分析工具。

Conclusion: 该库为评估LLM的决策能力提供了一个框架，支持多种游戏和代理类型，并集成了模型访问、本地部署和分布式执行，同时提供LLM推理跟踪的分析工具。

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [284] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: CLIO是一种新的AI方法，通过对LLM进行精确控制，提高了其在科学发现中的准确性和可控性，并在生物和医学问题上取得了显著的成果。


<details>
  <summary>Details</summary>
Motivation: 为了让科学家在科学发现中最大限度地利用AI，他们不仅需要准确和透明的推理，还需要可控性。现有的AI开发框架要么侧重于非推理模型，要么将推理的精确控制从最终用户那里抽象出来。

Method: CLIO（认知循环通过原地优化）通过原地优化实现对LLM进行深度和精确的控制，使其能够自我形成解决问题的方法，在自我置信度低时调整行为，并最终向科学家提供最终的信念或答案。

Result: 在没有进一步的后续训练的情况下，OpenAI的GPT-4.1结合CLIO在Humanity's Last Exam（HLE）的文本生物学和医学问题上的准确率为22.37%，与基础GPT-4.1模型相比，净增13.82%（相对增长161.64%），并且在 dans le mode de raisonnement à effort élevé et faible 的表现优于OpenAI的o3。

Conclusion: CLIO通过其开放设计和内部机制，为科学决策过程提供了洞察和控制，揭示了内部不确定性度量中的振荡是决定CLIO结果准确性的关键。

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [285] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 为了解决RVQA中MLLM和RAG方法的准确性和对齐问题，我们提出了一个多智能体系统（MAS），通过专门的智能体进行上下文理解、多模态推理和答案验证。该系统在具有挑战性的RVQA数据集上表现优于现有方法，并证明了其在临床AI应用中的可靠性和可解释性潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管基于多模态大语言模型（MLLM）和检索增强生成（RAG）的方法在RVQA方面取得了进展，但它们在事实准确性、幻觉和跨模态失准方面仍面临挑战。

Method: 提出一个多智能体系统（MAS），包含专门的智能体用于上下文理解、多模态推理和答案验证，以支持复杂的RVQA推理。

Result: 实验证明，所提出的MAS系统在RVQA任务上优于强大的MLLM基线，展示了其可靠性和可解释性。

Conclusion: 多智能体方法在需要复杂推理的医学影像问答任务中具有巨大潜力，能够支持可解释和值得信赖的临床人工智能应用。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [286] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 现有的规划基准在衡量基础模型和智能体的规划能力方面存在不足，而Countdown游戏可以提供一个计算上具有挑战性且实例丰富的动态基准，以评估和改进这些模型。


<details>
  <summary>Details</summary>
Motivation: 现有规划基准存在不足，无法真正衡量基础模型和智能体的规划能力，现有基准要么定义松散，要么复用为挑战现有自动化规划器弱点而设计的国际规划竞赛领域。

Method: 提出了一种围绕Countdown游戏创建规划基准的程序，该游戏要求玩家通过算术运算从一组输入数字中形成目标数字。对该基准进行了理论分析，并评估了现有基于LLM的规划方法。

Result: Countdown游戏基准具有自然语言描述、计算挑战性（NP-完全性）和丰富的实例空间，可以防止记忆。与24点游戏等其他领域不同，所提出的动态基准对现有的基于LLM的方法仍然极具挑战性。

Conclusion: 现有的规划基准在衡量基础模型和智能体的规划能力方面存在不足，而Countdown游戏可以提供一个计算上具有挑战性且实例丰富的动态基准，以评估和改进这些模型。

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [287] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 通过将推理LLM的推理向量应用于日语LLM，在有限资源下显著提升了日语LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 主流LLM的训练后方法虽能提升性能和推理能力，但对于资源有限的日语LLM而言实现这一目标存在挑战。

Method: 提出了一种从推理LLM中提取推理向量，并将其应用于日语LLM以提升其性能的方法。

Result: 该方法成功提升了日语LLM的性能，证明了其简单性和有效性，并为其他语言模型的改进提供了启发。

Conclusion: 本研究提出了一种利用推理LLM的推理向量来提升日语LLM性能的方法，有效克服了日语LLM资源限制的挑战，并为其他语言模型的改进提供了借鉴。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [288] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: PentestJudge是一个LLM裁判系统，用于评估渗透测试AI代理。它通过将任务分解为可评估的标准来工作。表现最好的模型F1分数为0.83，且更好的工具使用能力与更高的准确性相关。研究还发现，较弱模型也能评估较强模型的输出，验证比生成更容易。该研究为评估AI安全代理提供了一种可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决在信息安全领域，尤其是渗透测试中，对AI代理的操作进行大规模、系统化且符合实际标准的评估的挑战。现有的程序化评估方法难以覆盖渗透测试操作的复杂性和细微差别，因此需要一种能够理解和评估这些复杂操作的新方法。

Method: 提出了一种名为PentestJudge的系统，该系统利用大型语言模型（LLM）作为裁判，并结合工具来解析代理的状态和工具调用历史，以评估安全代理的操作是否符合特定标准。该方法通过开发基于树状结构的评分细则，将渗透测试任务分解为一系列简单的、可由LLM评估的是/否标准。

Result: 研究评估了几种前沿和开源模型作为裁判代理，其中表现最好的模型达到了0.83的F1分数。结果还显示，工具使用能力更强的模型在评估表现上更接近人类专家。不同类型要求的F1分数分层分析表明，即使整体分数相似，模型在回答不同类型问题时也存在差异。此外，较弱、成本较低的模型也能很好地评估较强、成本较高的模型生成的渗透测试轨迹。

Conclusion: PentestJudge是一个LLM驱动的评估系统，用于评估渗透测试代理的操作。研究表明，更好的工具使用能力与更接近人类专家的表现相关。此外，较弱的模型也能有效评估较强模型的测试轨迹，这表明在渗透测试任务中，验证可能比生成更容易。

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [289] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: AQUAH是一个新的语言代理，可以根据自然语言指令自动执行水文学模拟。


<details>
  <summary>Details</summary>
Motivation: 为了创建一个能够直接从自然语言指令生成水文学模拟的系统，从而简化复杂环境建模过程。

Method: AQUAH是一个端到端的、专门为水文学建模设计的语言驱动代理，利用视觉能力的大型语言模型来解释地图和栅格数据，以指导模拟过程。

Result: AQUAH在不进行人工干预的情况下，能够完成冷启动模拟，并生成分析师级别的文档，这些文档被水文学家评为清晰、透明且具有物理合理性。

Conclusion: AQUAH有潜力简化复杂环境建模，降低地球观测数据、基于物理的工具和决策者之间的门槛。

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [290] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Medblink基准测试评估了19种多模态语言模型在医学影像感知任务上的表现，结果显示其准确率远低于人类水平，表明这些模型在临床应用前需要改进其视觉基础。


<details>
  <summary>Details</summary>
Motivation: 为了评估多模态语言模型在医学影像解释方面的感知能力，并找出其在临床应用中可能存在的不足，因为临床医生在采用AI工具时非常谨慎，模型在看似简单的感知任务（如确定影像方向或识别CT扫描是否为增强对比）上的错误可能会阻碍其临床应用。

Method: 构建了一个名为Medblink的基准测试，包含8项跨多种影像模态和解剖区域的临床相关任务，总计1,429个选择题，覆盖1,605张图像。

Result: 在对19个最先进的多模态语言模型（包括通用模型和领域特定模型）进行评估后，人类标注者的准确率为96.4%，而表现最佳的模型准确率仅为65%，表明当前模型在常规感知检查方面存在频繁的失败。

Conclusion: 目前的多模态语言模型在处理医学影像的常规感知任务时仍存在显著不足，需要加强其视觉基础以促进临床应用。

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [291] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Polymath 是一个自优化的代理，它使用代码和图优化来动态生成和改进工作流，无需标记数据，并在各种任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手动将基础模型嵌入到像 Chain-of-Thought、Self-Reflection 和 ReACT 这样的代理系统中，通过文本接口来构建通用代理，限制了可扩展性和效率。现有的自动化工作流生成和优化方法通常依赖于标记数据集，这使得它们在缺乏标记数据的现实世界动态问题上效果不佳且不够灵活。

Method: Polymath 是一种自优化的代理，采用动态分层工作流。它利用任务流图的灵活性和代码表示的工作流的表达能力。其优化方法集成了多网格启发的图优化和自反思引导的进化算法，无需标记数据即可优化工作流。

Result: Polymath 在六个基准数据集（涵盖编码、数学和多轮问答任务）上的实验结果表明，与最先进的基线相比，Polymath 的平均性能提高了 8.1%。

Conclusion: Polymath 通过结合任务流图的灵活性和代码表示的工作流的表达能力，实现了一个自优化的代理，具有动态分层工作流，能够解决广泛的现实世界动态问题。该方法通过集成多网格启发的图优化和自反思引导的进化算法，在没有标记数据的情况下优化工作流。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [292] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 提出了一种新颖的、利用LLM自身推理能力进行自我保护的“自我意识”防御机制，以应对提示注入攻击，并在多项测试中表现出优越的防御效果。


<details>
  <summary>Details</summary>
Motivation: 为了对抗提示注入攻击，增强大型语言模型（LLMs）的安全性与道德性。

Method: 提出了一种包含元认知和仲裁模块的框架，使LLM能够自主评估和调节自身输出来进行自我保护，而不是依赖外部分类器。

Result: 在七个最先进的LLM和两个数据集（AdvBench和Prompt-Injection-Mixed-Techniques-2024）上进行了评估，结果显示在提高防御成功率方面有显著改进，某些模型在增强模式下实现了完美或接近完美的防御。同时分析了防御成功率提高与计算开销之间的权衡。

Conclusion: 该方法为LLM提供了一种轻量级、经济高效的解决方案，以增强其道德性，特别有利于跨各种平台的GenAI用例。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [293] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 该研究提出了一种统一的方法来集成工具，以应对LLM生态系统的碎片化。该方法通过自动化模式生成、并发执行和多源工具管理，降低了开发开销，提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决工具增强型LLM生态系统的碎片化问题，该生态系统要求开发者处理多种协议、手动模式定义和复杂的执行工作流。

Method: 提出了一种统一的工具集成方法，通过自动化模式生成、双模并发执行和无缝多源工具管理来抽象协议差异并优化执行性能。

Result: 实验结果表明，在集成场景中代码减少了60-80%，通过优化的并发性将性能提高了3.1倍，并与现有的函数调用标准完全兼容。

Conclusion: 该研究为工具集成架构提供了理论见解和实际解决方案，解决了LLM应用开发中的碎片化问题。

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [294] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）的能力不断增强，对LLM输出的评估，尤其是在开放式和复杂任务中，已成为一个关键瓶颈。因此，出现了一种新范式：使用AI代理作为评估者。这种“代理作为裁判”的方法利用了LLM的推理和视角能力，以评估其他模型的质量和安全，有望提供一种可扩展且细致的替代人工评估的方法。本综述定义了“代理作为裁判”的概念，追溯了其从单一模型裁判到动态多代理辩论框架的演变，并批判性地考察了它们的优缺点。我们从可靠性、成本和人类一致性等方面对这些方法进行了比较，并调查了它们在医学、法律、金融和教育等领域的实际应用。最后，我们强调了紧迫的挑战——包括偏见、鲁棒性和元评估——并概述了未来的研究方向。通过汇集这些线索，我们的综述表明，基于代理的裁判可以补充（但不能取代）人类的监督，这是朝着可信、可扩展的下一代LLM评估迈出的一步。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）能力和自主性的增强，评估其输出（尤其是在开放式和复杂任务中）已成为关键瓶颈。因此，出现了使用AI代理作为评估者自身的新范式。

Method: 梳理了从单一模型裁判到多智能体辩论框架的演变，并从可靠性、成本和人类一致性等方面进行了比较，同时考察了它们在医学、法律、金融和教育等领域的实际应用。

Result: AI代理作为裁判的方法在可靠性、成本和人类一致性方面进行了比较，并考察了它们在医学、法律、金融和教育等领域的实际应用，同时强调了偏见、鲁棒性和元评估等挑战。

Conclusion: AI代理作为裁判的方法可以补充人类监督，是实现下一代LLM可信、可扩展评估的关键一步。

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [295] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph 是一个用户友好的、由智能体驱动的系统，允许用户通过自然语言与知识图谱进行交互，从而管理领域特定的数据。该系统支持多轮对话和动态更新，无需专门的查询语言，并在教育场景的基准测试中表现出色，显示出在法律和医疗等领域的扩展潜力。


<details>
  <summary>Details</summary>
Motivation: 为非技术用户提供一个直观、用户友好的系统，通过自然语言操作知识图谱来管理领域特定的数据，允许增量构建和精炼知识库。

Method: AGENTiGraph 系统通过意图分类、任务规划和自动知识集成来实现，支持多轮对话和动态更新，无需专门的查询语言。

Result: 在包含 3500 个查询的教育场景基准测试中，AGENTiGraph 的分类准确率达到 95.12%，执行成功率为 90.45%，优于零样本基线。

Conclusion: AGENTiGraph 为企业知识管理提供了一种新的、开源的范例，利用大型语言模型和结构化图，实现了无缝的、多轮的交互和管理，尤其是在教育领域，并且在其他领域具有良好的扩展潜力。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [296] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: BPO是一个三阶段框架，通过数据飞轮解决大型语言模型在交互式环境中的信用分配和计算开销问题，实现了在长期、稀疏奖励环境下的推理能力的提升，并在ALFWorld、ScienceWorld和WebShop实验中取得最先进成果。


<details>
  <summary>Details</summary>
Motivation: 大型语言推理模型在静态任务上取得了显著的成功，但它们在交互式环境中的多轮智能体规划应用面临两个基本挑战：信用分配问题和推理历史的计算开销。为了解决这些挑战，BPO框架被提出。

Method: BPO框架是一个三阶段的框架（引导、外推和精炼），它建立了一个自上而下的数据飞轮来开发稳健的推理模型，用于长期、稀疏奖励的环境。该框架首先使用提出的长短链思想融合规划四元数来引导高效推理。然后，通过复杂性分层课程学习将其外推到分布外任务。最后，模型通过仅在通过奖励门控拒绝采样选择的经验上学习来迭代地精炼自身。

Result: 实验结果表明，BPO框架在ALFWorld、ScienceWorld和WebShop上实现了最先进的性能，并且在代币效率方面有显著提升。

Conclusion: BPO框架通过自上而下的数据飞轮，在长期、稀疏奖励环境的推理模型开发中实现了最先进的成果，并且在代币效率方面有显著提升，为智能体规划中的推理模型提供了一种新的方法。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [297] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: Collab-Solver通过多智能体协作学习优化MILP求解策略，解决了现有方法各自为政的问题，提升了求解速度和质量，并具有良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的MILP方法各自独立地学习求解器中的策略，未能考虑各模块间的相互依赖性，从而严重影响了求解速度和质量。为解决此问题，提出Collab-Solver框架以协作优化多个模块的策略。

Method: 提出了一种新颖的基于多智能体策略学习的MILP框架（Collab-Solver），将MILP求解中的割选择和分支策略制定视为一个Stackelberg博弈，并开发了两阶段学习范式来稳定协作策略学习。

Result: Collab-Solver框架在合成和大规模真实世界MILP数据集上显著提高了求解性能，并且所学策略在不同实例集上表现出优异的泛化能力。

Conclusion: Collab-Solver框架通过多智能体协作策略学习，显著提升了MILP求解性能，并在合成与大规模真实世界MILP数据集上展现了出色的泛化能力。

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [298] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: LLM通过ICL可以学习解决常微分方程，表现出优于传统方法的收敛性和精度，并能泛化到未见过的问题。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在ICL设置下的高度非线性行为的内在机制，特别是其解决常微分方程（ODE）的能力。

Method: 将ODE问题及其解构建为序列提示，并评估GPT-2模型在这些任务上的表现。

Result: GPT-2在ODE问题上展现出可比肩甚至优于欧拉法的收敛行为，并随着演示数量的增加实现指数级精度提升。

Conclusion: LLM在ICL设置下能够学习元ODE算法，并能有效解决ODE问题，泛化到OOD问题，展现出强大的外插能力。

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [299] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: 针对现有语言模型在处理复杂医学诊断任务时推理深度不足的问题，我们提出了Tree-of-Reasoning（ToR）框架，通过引入树状结构和交叉验证机制，提高了模型的临床推理能力和诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型在处理复杂的医学诊断任务时，由于推理深度不足，在处理大量专业医学数据时会出现信息丢失或逻辑跳跃，导致诊断错误。为了解决这些挑战，需要一个能够处理复杂场景的新框架。

Method: 提出了一种名为“Tree-of-Reasoning”（ToR）的新型多智能体框架。该框架引入了树状结构来清晰记录语言模型的推理路径和相应的临床证据，并提出了一种交叉验证机制来确保多智能体决策的一致性，以提高多智能体在复杂医学场景下的临床推理能力。

Result: 在真实世界医学数据上进行的实验证明，与现有的基线方法相比，我们的框架能够取得更好的性能。

Conclusion: 我们的框架在真实世界医学数据上的实验结果表明，其性能优于现有的基线方法。

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [300] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: CDD框架通过模拟人类认知推理来防御LLM的越狱攻击，它通过全局感知和局部分析来识别操纵，并通过强化学习来提高泛化能力，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有防御机制在泛化到新颖和未见过的攻击策略方面的不足，我们提出了CDD框架。

Method: CDD框架首先对提示进行全局感知，然后进行局部分析，以发现隐藏的操纵。通过对这个结构化推理链进行监督微调，模型学会识别和推理已知的操纵模式。为了提高对未知威胁的泛化能力，引入了一种熵引导的强化学习算法（EG-GRPO），以鼓励探索新的元操作类型和变体。

Result: 实验证明，CDD可以达到最先进的防御性能，并对未知的越狱攻击表现出很强的泛化能力。

Conclusion: CDD框架在抵御越狱攻击方面取得了最先进的防御性能，并对未知的越狱攻击表现出很强的泛化能力。

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [301] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: ContractEval 是第一个基准，用于评估开源 LLM 在识别商业合同中的条款级法律风险方面是否能与专有 LLM 相媲美。研究评估了 19 个 LLM，发现专有模型总体优于开源模型，但开源模型在特定维度上具有竞争力。该研究还探讨了模型大小、推理模式、量化等因素对 LLM 性能的影响，并为开源 LLM 在法律领域的应用提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了响应在法律任务中本地部署开源语言模型并保护数据机密性的日益增长的兴趣，本研究旨在探索大型语言模型 (LLM) 在法律风险分析等专业领域的潜力。

Method: 使用包含 15 个开源模型和 4 个专有模型的合同理解 Atticus 数据集 (CUAD) 来评估语言模型在识别商业合同中的条款级法律风险方面的能力。

Result: 专有模型在正确性和输出有效性方面均优于开源模型，尽管某些开源模型在特定维度上具有竞争力。较大的开源模型通常表现更好，但随着模型增大，性能提升会减缓。“推理”（思考）模式提高了输出有效性，但降低了正确性。开源模型更频繁地生成“无相关条款”的响应。模型量化会加速推理，但会以性能下降为代价。

Conclusion: 大多数语言模型在表现上可以与初级法律助理相媲美，但开源模型需要进行针对性的微调，以确保在高风险的法律环境中的正确性和有效性。ContractEval 提供了一个坚实的基准来指导法律领域语言模型的未来发展。

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [302] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: Existing AHD methods create single heuristics with poor generalization. This paper proposes Automated Heuristic Set Design (AHSD) to create a set of complementary heuristics for diverse instances. The EoH-S algorithm effectively generates these sets, outperforming prior methods by up to 60%


<details>
  <summary>Details</summary>
Motivation: Existing Automated Heuristic Design (AHD) methods using LLMs design a single heuristic, leading to poor generalization across different distributions or settings. This work addresses this by generating a set of complementary heuristics.

Method: Proposed Automated Heuristic Set Design (AHSD) formulation and Evolution of Heuristic Set (EoH-S) algorithm with complementary population management and complementary-aware memetic search.

Result: EoH-S consistently outperforms state-of-the-art AHD methods on three AHD tasks, achieving up to 60% performance improvements.

Conclusion: AHSD formulation can generate a small-sized complementary heuristic set to serve diverse problem instances, optimizing each instance with at least one heuristic in the set. EoH-S, applying AHSD for LLM-driven AHD with complementary population management and complementary-aware memetic search, outperforms existing methods.

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [303] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: MissDDIM是一种用于表格填充的条件扩散模型，解决了现有DDPM模型推理延迟高和输出可变的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DDPM的扩散模型在表格填充方面存在推理延迟高和输出可变的问题，限制了其在实际表格场景中的应用。

Method: 提出了一种条件扩散框架MissDDIM，该框架适配了DDIM模型用于表格填充。

Result: MissDDIM能够实现低推理延迟和可变输出，为表格填充提供了新的解决方案。

Conclusion: MissDDIM通过适配DDIM模型解决了现有扩散模型在表格填充方面的局限性，实现了低推理延迟和可变输出。

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [304] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 该研究提出了一种名为T2UE的创新框架，能够仅通过文本描述生成“不可学习示例”（UE），有效保护数据隐私，无需接触原始数据。该方法通过文本到图像模型生成噪声，并已在实验中证明其能有效降低下游任务性能，且效果具有泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模预训练模型（如CLIP）依赖于可能包含私有用户数据的网络抓取数据集，引发了对滥用的担忧。不可学习示例（UE）被提出作为一种有前景的对策，但其生成方法计算成本高昂，需要暴露原始数据，存在隐私悖论。因此，需要一种能够仅使用文本描述即可生成UE的解决方案，以实现可扩展的数据保护。

Method: T2UE框架，利用文本到图像（T2I）模型将文本描述映射到图像（噪声）空间，并结合误差最小化框架来生成不可学习噪声。

Result: T2UE保护后的数据显著降低了下游任务（如跨模态检索）中先进模型的性能。此外，T2UE的保护效果能够泛化到不同的模型架构，甚至在监督学习设置中也有效。

Conclusion: 该研究引入了一种名为“文本到不可学习示例（T2UE）”的新框架，该框架仅使用文本描述即可生成不可学习示例（UE），从而解决了现有UE生成方法在计算上成本高昂且需要暴露原始数据以进行保护的隐私悖论。T2UE通过利用文本到图像（T2I）模型将文本描述映射到图像（噪声）空间，并结合误差最小化框架来生成有效的不可学习噪声，成功实现了“零接触数据保护”，即仅根据文本描述即可保护个人数据，无需直接暴露数据。

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [305] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [306] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: 该研究提出了AgentSME框架，利用LLM和三种通信模式（Solo、Mono、Echo）来改进智能教育中的生成代理。研究结果表明，Echo模式在准确性方面表现最佳，DeepSeek模型在多样性方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了解决智能教育领域中生成代理模型相对欠发达的挑战，并考虑到教育环境的复杂性，如学习者的认知行为以及以个性化人际交流为中心的教学法。

Method: 提出了一种名为AgentSME的统一生成代理框架，该框架由LLM提供支持，并考虑了三种通信模式：Solo、Mono和Echo。

Result: 在准确性方面，采用Echo通信模式的生成代理取得了最高的准确性分数。在多样性方面，DeepSeek表现出最大的多样性。该研究测试了六种广泛使用的LLM，并对它们进行了基础容量和高容量配置的划分，以验证通信模式在不同模型层级上的鲁棒性。

Conclusion: 该研究为改进智能教育模型中的代理学习能力提供了宝贵的见解，并为未来的智能教育模型提供了启发。

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [307] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: 提出了一种名为 OptiTrust 的框架和 LLM 代理，通过可验证的合成数据生成流水线来训练用于优化建模的可信赖 LLM 代理。该方法在多个优化任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了训练可信赖的大型语言模型（LLM）代理，以应对优化建模任务。

Method: 通过一个可验证的合成数据生成流水线，为优化建模训练可信赖的大型语言模型（LLM）代理。该方法首先处理线性规划和混合整数线性规划，从结构化符号表示开始，系统地生成自然语言描述、数学公式和可执行代码。通过以编程方式构建每个具有已知最优解的实例，该流水线确保了完全的可验证性，并能够自动过滤掉教师模型生成的低质量演示。每个数据集实例包含一个优化问题的结构化表示、相应的自然语言描述、经过验证的最优解以及演示步骤——由教师模型生成——展示了如何跨多种优化建模语言进行问题的建模和求解。这使得能够对开源 LLM 进行专门针对优化任务的监督微调。为了实现该流水线，我们引入了 OptiTrust，这是一个模块化的 LLM 代理，它利用分步演示、多语言推理和多数投票交叉验证，执行从自然语言到可求解代码的多阶段翻译。

Result: OptiTrust 在标准基准测试中取得了最先进的性能。在 7 个数据集中，它在 6 个数据集上实现了最高的准确率，并在其中 3 个数据集上以至少 8% 的优势超越了次优算法。

Conclusion: 本框架提供了一个可扩展、可验证且有原则的途径，用于构建可靠的 LLM 代理以应对实际优化应用。

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [308] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: AI模型在环境教育中展现出潜力，但信息准确性有待专家验证。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查人工智能（AI）模型在弥合大学生环境教育知识差距方面的潜力。

Method: 本研究评估了GPT-3.5、GPT-4、GPT-4o、Gemini、Claude Sonnet和Llama 2等大型语言模型在传达环境概念方面的有效性，并使用环境知识测试（EKT-19）和定向问题来评估大学生的环境知识，并与AI模型的响应进行比较。

Result: 研究结果表明，AI模型在提供环境信息方面具有潜力，但信息准确性仍需人工验证。

Conclusion: AI模型具有庞大、易于获取且有效的知识库，有潜力赋能学生和学术界，但可能仍需要人类学科专家来验证信息的准确性。

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [309] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: Y0是一个Python包，用于因果识别，帮助研究人员确定因果关系的可识别性，并提供将因果查询转化为可估量项的工具。


<details>
  <summary>Details</summary>
Motivation: Y0包旨在帮助研究人员在估计因果关系强度之前，确定是否能从可用数据中估计出因果关系，并指导研究人员如何将因果查询转化为可非参数估计的符号可估量项。

Method: Y0包实现了包括干预、反事实和可运输性查询在内的因果识别算法，并支持ADMG等因果图模型，提供了特定领域的语言来表示因果查询和可估量项，以及处理未观测混杂因素的工具。

Result: Y0包提供了因果识别算法的实现，包括针对不同数据类型的查询能力，以及表示因果查询和因果图模型的工具。

Conclusion: Y0是一个Python包，实现了因果识别算法，可应用于干预、反事实和可运输性查询，适用于来自（随机）对照试验、观察性研究或两者的混合数据。

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [310] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: Geoint-R1是一个用于形式几何推理的多模态框架，它通过构造辅助元素、使用Lean4进行形式化推理和交互式可视化来解决问题，并在Geoint基准测试中取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在形式几何推理方面存在不足，尤其是在动态构造和验证辅助几何元素方面，因此需要Geoint-R1来解决这些挑战。

Method: Geoint-R1是一个多模态推理框架，通过集成辅助元素构造、Lean4形式化推理和交互式可视化来解决几何推理问题。

Result: Geoint-R1在Geoint基准测试中表现出色，该基准包含1,885个不同几何主题的严谨标注问题。

Conclusion: Geoint-R1在处理需要显式构造辅助元素的复杂几何推理问题方面，显著优于现有的多模态和数学推理模型。

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [311] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: 本研究提出InqEduAgent，一个由大型语言模型驱动的智能体，用于智能匹配探究式学习的学习伙伴，并通过实验证明了其在知识学习和大型语言模型环境中的优越性。


<details>
  <summary>Details</summary>
Motivation: 为了改善探究式教育中学习伙伴选择的低效性和不足，如依赖经验或基于规则的系统，本研究旨在提出一种更智能、更灵活的学习伙伴匹配方法。

Method: 研究设计了能够捕捉现实世界学习者认知和评估特征的生成式智能体，并构建了一个结合高斯过程增强的自适应匹配算法来识别先验知识中的模式，从而为学习者匹配最优的学习伙伴。

Result: 实验结果表明，InqEduAgent在大多数知识学习场景和不同能力水平的大型语言模型环境中表现出最优性能。

Conclusion: 本研究提出了一个名为InqEduAgent的、由大型语言模型赋能的智能体模型，用于模拟和选择适合探究式学习的学习伙伴，旨在解决现有学习伙伴选择的局限性，如缺乏科学规划、知识扩展不足和灵活性不够等问题。

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [312] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: ETDNet通过全历史图和解耦边类型的方法，有效捕捉了实体间的结构和时间关系，在交通预测和金融欺诈检测任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界任务中，对实体间演化交互进行建模至关重要，例如预测交通中的车辆行为和检测金融欺诈。这些任务需要理解实体之间的交互以及交互随时间的变化，而传统的时序预测方法无法很好地处理这种“谁与谁在何时交互”的问题，因此需要一种能够明确表示关系及其演化的时序图表示方法。

Method: 提出了一种名为ETDNet（Edge-Type Decoupled Network）的模型，该模型使用一种“全历史图”来表示实体间的演化交互。全历史图为每个实体在每个时间步都创建一个节点，并区分两种边：时间步内边（捕获同一时间步内的关系）和时间步间边（连接同一实体在连续时间步的节点）。ETDNet包含三个并行模块：图注意力模块用于聚合时间步内边的信息，多头时间注意力模块用于关注实体的历史交互，以及一个融合模块用于在每层结合这两种信息。

Result: 在Waymo数据集上，ETDNet将联合准确率从74.1%提升至75.6%；在Elliptic++数据集上，将非法类别F1分数从60.4%提升至88.1%，显著优于现有基线模型。

Conclusion: ETDNet通过将结构关系和时间关系表示为单个图中的不同边，在驱动意图预测和比特币欺诈检测任务上取得了显著的性能提升，证明了其有效性。

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [313] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: This paper introduces ToolVQA, a new dataset and generation pipeline (ToolEngine) to improve large foundation models' ability to use external tools in complex, real-world multimodal tasks, showing that models trained on this dataset generalize better than GPT-3.5-turbo.


<details>
  <summary>Details</summary>
Motivation: Existing studies show gaps in real-world tool-use proficiency for LFMs, especially in functionally diverse multimodal settings requiring multi-step reasoning. Need for a dataset that bridges this gap by including real-world scenarios and complex reasoning tasks.

Method: Introduced ToolVQA, a large-scale multimodal dataset with 23K instances, featuring real-world visual contexts and implicit multi-step reasoning tasks. Proposed ToolEngine, a data generation pipeline using DFS and dynamic in-context example matching to simulate human-like tool-use reasoning. The dataset includes 10 multimodal tools across 7 diverse task domains, with an average of 2.78 reasoning steps per instance.

Result: ToolVQA features 23K instances, 10 multimodal tools, 7 diverse task domains, and an average inference length of 2.78 reasoning steps. Fine-tuned 7B LFMs on ToolVQA outperform GPT-3.5-turbo on OOD datasets.

Conclusion: Fine-tuned 7B LFMs on ToolVQA achieve impressive performance on the test set and surpass GPT-3.5-turbo on OOD datasets, showing strong generalizability to real-world tool-use scenarios.

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [314] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Nemori是一个受认知科学启发的记忆架构，解决了大型语言模型在长上下文中的记忆限制，通过其新颖的组织和学习机制，在长上下文任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在长上下文环境中缺乏持久记忆及其现有记忆系统在知识提取方面的局限性，我们提出了Nemori。

Method: Nemori采用“两步对齐原则”来组织对话流，并借鉴“自由能原则”的“预测-校准原则”来学习知识。

Result: Nemori能够自主地将原始对话流组织成语义连贯的片段，并能主动从预测差距中学习，实现适应性知识演化，解决了记忆粒度问题，并超越了现有方法。

Conclusion: Nemori在LoCoMo和LongMemEval基准的广泛实验中，显著优于现有最先进的系统，并且在更长的上下文中其优势尤为明显。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [315] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: 为边缘AI代理开发了首个部署和管理框架，通过蚁群+LLM优化放置和迁移，降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT和Claude等大型语言模型（LLMs）的兴起，对能够实时处理任务的AI代理的需求日益增长。然而，将数据密集型、多模态的边缘工作负载迁移到传统的云数据中心进行代理部署会带来显著的延迟。因此，在资源有限且异构的边缘环境中部署AI代理以提高效率和降低延迟是必要的。同时，为了维持移动用户的服务质量（QoS），需要进行代理迁移，但AI代理（涉及LLMs、任务规划、内存和外部工具的协调）的复杂性使得这一过程变得复杂。

Method: 提出了一种新颖的自适应框架，用于边缘智能系统中AI代理的放置和迁移。该方法将资源约束和延迟/成本建模，并利用蚁群算法和基于LLM的优化进行高效决策，以优化资源利用率和服务质量（QoS）。通过仅传输必要状态来实现轻量级代理迁移。

Result: 该解决方案在基于AgentScope的分布式系统上实现，并在全球分布的边缘服务器上进行了验证。结果表明，该方法显著降低了部署延迟和迁移成本。

Conclusion: 该研究提出了首个用于动态边缘环境中基于LLM的AI代理的系统化部署和管理解决方案，通过新颖的自适应框架、结合蚁群算法和LLM的优化决策，实现了代理的高效放置和迁移，显著降低了部署延迟和迁移成本。

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [316] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: 该研究提出了一种CoT压缩框架，通过去除冗余的推理步骤来提高LLM的效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs使用CoT提示在复杂推理方面表现出色，但其冗长的推理过程会增加推理成本并降低效率。

Method: 提出了一种基于步熵的CoT压缩框架，并结合SFT和GRPO的混合训练策略，使LLM能够学习生成压缩的CoT。

Result: 实验证明，可以修剪高达80%的低熵中间步骤，同时对最终答案的准确性影响很小。所提出的方法显著提高了LLM的推理效率，同时保持了准确性。

Conclusion: 该研究提出的基于步熵的CoT压缩框架能够通过识别和去除冗余步骤来显著提高LLM的推理效率，同时保持最终答案的准确性。通过SFT和GRPO的混合训练策略，LLM能够学会自主生成压缩的CoT。

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [317] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: CogBench是一个评估大型语言模型（LLMs）在跨语言和跨站点语音认知障碍评估任务中通用性的基准。研究表明，与传统方法相比，经过微调的LLM在处理不同语言和临床环境方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 当前的自动评估方法在跨语言和跨临床环境的通用性方面存在不足，限制了其实际应用。本研究旨在提出CogBench，这是第一个旨在评估大型语言模型（LLMs）在基于语音的认知障碍评估中的跨语言和跨站点通用性的基准。

Method: 使用统一的多模态管道，在涵盖英语和中文的三个语音数据集（ADReSSo、NCMMSC2021-AD和新收集的CIR-E测试集）上评估模型性能。

Result: 与传统深度学习模型相比，配备思维链提示的大型语言模型（LLMs）表现出更好的适应性，但其性能仍然对提示设计敏感。通过低秩适配（LoRA）进行LLM轻量级微调可显著提高目标域的泛化能力。

Conclusion: CogBench的出现是向构建临床实用和语言鲁棒的语音认知评估工具迈出的关键一步。

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [318] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: 混合神经符号方法比整合方法更有利于实现通用逻辑推理，因为它提供了更好的可解释性和对现有大型语言模型能力的保留。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在通用逻辑推理方面存在挑战，缺乏确定性和可解释性。神经符号AI旨在将逻辑融入神经网络，但不同方法在通用推理上的潜力尚未得到充分研究和比较。

Method: 通过对两种主要的神经符号方法（整合方法和混合方法）进行案例研究，并引入两种代表性模型（逻辑神经网络LNN和语言模型-符号求解器LLM-SS）进行分析。

Result: 混合方法（以LLM-SS为例）比整合方法（以LNN为例）更有前景，因为它提供了更可解释的推理链，并能保留现有大型语言模型的优点。同时，提出了一种基于LLM-SS的通用框架。

Conclusion: 混合方法在发展通用逻辑推理方面更有前景，因为其推理链更具可解释性，并且能够保留现有语言模型的优势。

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [319] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


### [320] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
*Rui Zou,Mengqi Wei,Yutao Zhu,Jirong Wen,Xin Zhao,Jing Chen*

Main category: cs.AI

TL;DR: HSG框架通过引入“隐藏错误”和“诊断错误”的对抗性角色，提升了LLMs的错误诊断能力，在数学问题解决方面取得了显著效果，提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理复杂错误识别和诊断方面能力有限，因为它们的训练目标主要关注正确答案，限制了从错误中学习的机会。现有的错误信号引入方法依赖于浅层、静态的错误，不利于提升深层诊断能力。

Method: 提出了一种名为“Hide and Speak Game”（HSG）的动态对抗框架，包含“Sneaky”（隐藏错误）和“Diagnosis”（诊断错误）两个对抗性角色，通过双方的协同进化来提升错误隐藏的隐蔽性和诊断的精确性。

Result: 在多个数学推理任务上，HSG框架显著提升了错误诊断能力，准确率比GPT-4o等基线模型高出16.8%–31.4%。研究还发布了一个包含隐蔽错误和诊断标注的数据集，用作未来研究的基准。

Conclusion: 该研究提出了Hide and Speak Game（HSG）框架，通过动态对抗的方式来提升大型语言模型（LLMs）在数学问题解决中的错误诊断能力，实验结果表明HSG显著提高了错误诊断的准确性。

Abstract: Large Language Models (LLMs) excel in reasoning and generation across
domains, but still struggle with identifying and diagnosing complex errors.
This stems mainly from training objectives that prioritize correct answers,
limiting exposure to and learning from errors. While recent studies have begun
to address this by introducing error signals, most rely on shallow, static
errors, restricting improvement in deep diagnostic ability. To overcome this,
we propose Hide and Seek Game (HSG), a dynamic adversarial framework for error
generation and diagnosis, and evaluate it on mathematical problem-solving. HSG
involves two adversarial roles: Sneaky, which "hides" by generating subtle,
deceptive reasoning errors, and Diagnosis, which "seeks" to accurately detect
them. Through adversarial co-evolution, both error stealth and diagnostic
precision are enhanced. Experiments on several math reasoning tasks show that
HSG significantly boosts error diagnosis, achieving 16.8\%--31.4\% higher
accuracy than baselines like GPT-4o. We also release a challenging dataset of
deceptive errors and diagnostic annotations as a benchmark for future research.

</details>


### [321] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
*Kai Li,Ruihao Zheng,Xinye Hao,Zhenkun Wang*

Main category: cs.AI

TL;DR: MOID通过结合LLM代理和多目标优化，为不可行的路由模型提供了一系列可行的修改建议和诊断见解，解决了现有方法只考虑单一调整的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的方法在诊断和修改不可行的优化模型时，往往只考虑单一的调整，而忽略了模型修改可能涉及的多种潜在调整。然而，在实际的路由问题中，用户经常提出冲突或不合理的需求，导致优化模型因过于严格或矛盾的约束而不可行。为了解决这个差距，需要一种能够提供一系列代表性可行性修改建议的方法。

Method: MOID结合了LLM代理和多目标优化，首先使用多目标优化来同时考虑路径成本和约束冲突，生成一组权衡解，每个解都包含不同程度的模型调整；然后利用LLM代理生成一个可行的解决方案分析函数，对这些不同的解决方案进行分析，以诊断原始的不可行模型，为用户提供多样化的诊断见解和建议。

Result: MOID生成了一组代表性的可行性修改建议，这些建议包括了不同程度的模型调整，并提供了多样化的诊断见解和建议，相比之下，现有的LLM为基础的方法在单次运行中只能生成单一的诊断建议。

Conclusion: MOID与现有的基于LLM的方法相比，在50种类型的不 feasible 路由问题上，可以自动生成多种诊断建议，为恢复模型的 feasible 性和决策提供了更多实用见解。

Abstract: In real-world routing problems, users often propose conflicting or
unreasonable requirements, which result in infeasible optimization models due
to overly restrictive or contradictory constraints, leading to an empty
feasible solution set. Existing Large Language Model (LLM)-based methods
attempt to diagnose infeasible models, but modifying such models often involves
multiple potential adjustments that these methods do not consider. To fill this
gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which
combines LLM agents and multi-objective optimization within an automatic
routing solver, to provide a set of representative actionable suggestions.
Specifically, MOID employs multi-objective optimization to consider both path
cost and constraint violation, generating a set of trade-off solutions, each
encompassing varying degrees of model adjustments. To extract practical
insights from these solutions, MOID utilizes LLM agents to generate a solution
analysis function for the infeasible model. This function analyzes these
distinct solutions to diagnose the original infeasible model, providing users
with diverse diagnostic insights and suggestions. Finally, we compare MOID with
several LLM-based methods on 50 types of infeasible routing problems. The
results indicate that MOID automatically generates multiple diagnostic
suggestions in a single run, providing more practical insights for restoring
model feasibility and decision-making compared to existing methods.

</details>


### [322] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
*Taine J. Elliott,Stephen P. Levitt,Ken Nixon,Martin Bekker*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型（LLM）从医学文献中提取信息并构建知识图谱（KG）的方法，以应对医学数据爆炸式增长带来的挑战。该方法通过LLM代理流水线提取和增强KG三元组，提高了信息的准确性和可用性，旨在为医学从业者提供一个实时更新的知识来源。


<details>
  <summary>Details</summary>
Motivation: 公开的医学数据快速扩展，使得科学文献的体积与应用之间的差距增大，同时也使医学专业人员难以系统地复习和理解最新的知识。

Method: 本研究提出了一种信息提取和知识图谱（KG）生成方法，利用大型语言模型（LLM）代理的流水线，将44篇PubMed摘要分解为有意义的命题句子，并从中提取KG三元组。通过结合开放域和基于本体的信息提取方法来增强三元组，并加入上下文变量，使三元组成为“四元组”。

Result: 提取的LLM准确性通过将从增强后的三元组生成的自然语言句子与原始命题进行比较来验证，平均余弦相似度达到0.874。与普通三元组相比，增强后的三元组生成的句子显示出相似度的提升。此外，研究还探讨了LLM在知识图中推断新关系和连接集群的能力。

Conclusion: 该方法为医学从业者提供了一个集中的、实时更新的、可持续的知识来源，并可能为其他领域带来类似的收益。

Abstract: The rapid expansion of publicly-available medical data presents a challenge
for clinicians and researchers alike, increasing the gap between the volume of
scientific literature and its applications. The steady growth of studies and
findings overwhelms medical professionals at large, hindering their ability to
systematically review and understand the latest knowledge. This paper presents
an approach to information extraction and automatic knowledge graph (KG)
generation to identify and connect biomedical knowledge. Through a pipeline of
large language model (LLM) agents, the system decomposes 44 PubMed abstracts
into semantically meaningful proposition sentences and extracts KG triples from
these sentences. The triples are enhanced using a combination of open domain
and ontology-based information extraction methodologies to incorporate
ontological categories. On top of this, a context variable is included during
extraction to allow the triple to stand on its own - thereby becoming
`quadruples'. The extraction accuracy of the LLM is validated by comparing
natural language sentences generated from the enhanced triples to the original
propositions, achieving an average cosine similarity of 0.874. The similarity
for generated sentences of enhanced triples were compared with generated
sentences of ordinary triples showing an increase as a result of the context
variable. Furthermore, this research explores the ability for LLMs to infer new
relationships and connect clusters in the knowledge base of the knowledge
graph. This approach leads the way to provide medical practitioners with a
centralised, updated in real-time, and sustainable knowledge source, and may be
the foundation of similar gains in a wide variety of fields.

</details>


### [323] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
*Saleh Nikooroo*

Main category: cs.AI

TL;DR: 本论文提出一种将信念系统表示为有向加权图的新方法，以克服现有方法的局限性，并能更细致地分析信念的内部结构和状态。


<details>
  <summary>Details</summary>
Motivation: 现有的信念系统表示方法（如命题集或概率分布）往往会掩盖信念的内部结构，混淆外部可信度与内部一致性，并且无法模拟碎片化或矛盾的认识状态。

Method: 本论文将信念系统形式化为有向加权图，其中节点代表个体信念，边表示它们之间的认识关系（例如支持或矛盾）。

Result: 该模型是纯粹静态的，并且故意排除了推理或修正过程，旨在为分析信念系统的内部组织（包括一致性条件、认识张力和表示限制）提供基础。

Conclusion: 该模型通过区分信念结构和信念强度，能够比现有的概率、逻辑或基于论证的方法提供更丰富的认知状态分类。

Abstract: Belief systems are often treated as globally consistent sets of propositions
or as scalar-valued probability distributions. Such representations tend to
obscure the internal structure of belief, conflate external credibility with
internal coherence, and preclude the modeling of fragmented or contradictory
epistemic states. This paper introduces a minimal formalism for belief systems
as directed, weighted graphs. In this framework, nodes represent individual
beliefs, edges encode epistemic relationships (e.g., support or contradiction),
and two distinct functions assign each belief a credibility (reflecting source
trust) and a confidence (derived from internal structural support). Unlike
classical probabilistic models, our approach does not assume prior coherence or
require belief updating. Unlike logical and argumentation-based frameworks, it
supports fine-grained structural representation without committing to binary
justification status or deductive closure. The model is purely static and
deliberately excludes inference or revision procedures. Its aim is to provide a
foundational substrate for analyzing the internal organization of belief
systems, including coherence conditions, epistemic tensions, and
representational limits. By distinguishing belief structure from belief
strength, this formalism enables a richer classification of epistemic states
than existing probabilistic, logical, or argumentation-based approaches.

</details>


### [324] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
*Zhiyao Xu,Dan Zhao,Qingsong Zou,Qing Li,Yong Jiang,Yuhang Wang,Jingyu Xiao*

Main category: cs.AI

TL;DR: SmartGen是一个基于LLM的框架，通过合成用户行为数据来帮助智能家居模型适应行为漂移，从而提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 智能家居模型在面对由季节变化、生活方式改变或日常习惯演变引起行为漂移时，由于重新收集数据成本高、耗时长且涉及隐私问题，因此模型适应性受到限制。SmartGen旨在解决这一问题。

Method: SmartGen框架包含时间与语义感知拆分、语义感知序列压缩、图引导序列合成和两阶段异常值过滤四个组件，利用LLM合成上下文感知的用户行为数据。

Result: 实验结果表明，SmartGen在异常检测任务上平均提升85.43%，在行为预测任务上平均提升70.51%，有效增强了模型在行为漂移下的性能。

Conclusion: SmartGen通过生成用户行为数据来帮助智能家居模型适应行为漂移，并在异常检测和行为预测任务上显著提高了模型性能。

Abstract: As smart homes become increasingly prevalent, intelligent models are widely
used for tasks such as anomaly detection and behavior prediction. These models
are typically trained on static datasets, making them brittle to behavioral
drift caused by seasonal changes, lifestyle shifts, or evolving routines.
However, collecting new behavior data for retraining is often impractical due
to its slow pace, high cost, and privacy concerns. In this paper, we propose
SmartGen, an LLM-based framework that synthesizes context-aware user behavior
data to support continual adaptation of downstream smart home models. SmartGen
consists of four key components. First, we design a Time and Semantic-aware
Split module to divide long behavior sequences into manageable, semantically
coherent subsequences under dual time-span constraints. Second, we propose
Semantic-aware Sequence Compression to reduce input length while preserving
representative semantics by clustering behavior mapping in latent space. Third,
we introduce Graph-guided Sequence Synthesis, which constructs a behavior
relationship graph and encodes frequent transitions into prompts, guiding the
LLM to generate data aligned with contextual changes while retaining core
behavior patterns. Finally, we design a Two-stage Outlier Filter to identify
and remove implausible or semantically inconsistent outputs, aiming to improve
the factual coherence and behavioral validity of the generated sequences.
Experiments on three real-world datasets demonstrate that SmartGen
significantly enhances model performance on anomaly detection and behavior
prediction tasks under behavioral drift, with anomaly detection improving by
85.43% and behavior prediction by 70.51% on average. The code is available at
https://github.com/horizonsinzqs/SmartGen.

</details>


### [325] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
*Khaled Bachir Delassi,Lakhdar Zeggane,Hadda Cherroun,Abdelhamid Haouhat,Kaoutar Bouzouad*

Main category: cs.AI

TL;DR: 这项研究介绍了一个人工智能驱动的工具，用于通过互动视觉测验学习阿拉伯语，其准确率表明它在教育方面有前景。


<details>
  <summary>Details</summary>
Motivation: 为了解决阿拉伯语学习工具在提倡主动学习等现代教学模式方面存在 Sarcity 的问题。

Method: 本研究探讨了一个人工智能驱动的教育工具的设计和评估，该工具利用先进的人工智能模型生成交互式视觉测验，使用视觉问答作为主要活动。采用建构主义学习方法，通过真实的视觉测验和以图像为基础的问题来鼓励主动学习，以提高词汇量、语法和理解能力。该系统集成了视觉语言预训练模型来生成相关的图像描述，大型语言模型可以根据定制的阿拉伯语学习测验进行提示。

Result: 该工具的有效性通过由 1266 个真实视觉测验组成的评估基准进行了评估，并获得了人类参与者的反馈。结果表明，该工具具有合适的准确率，可供阿拉伯语学习者使用。

Conclusion: 该工具具有弥合阿拉伯语教育差距的潜力，并且是阿拉伯语学习者可靠、人工智能驱动的资源，可提供个性化和互动式学习体验。

Abstract: We address the problem of scarcity of educational Arabic Language Learning
tools that advocate modern pedagogical models such as active learning which
ensures language proficiency. In fact, we investigate the design and evaluation
of an AI-powered educational tool designed to enhance Arabic language learning
for non-native speakers with beginner-to-intermediate proficiency level. The
tool leverages advanced AI models to generate interactive visual quizzes,
deploying Visual Question Answering as the primary activity. Adopting a
constructivist learning approach, the system encourages active learning through
real-life visual quizzes, and image-based questions that focus on improving
vocabulary, grammar, and comprehension. The system integrates Vision-Language
Pretraining models to generate contextually relevant image description from
which Large Language Model generate assignments based on customized Arabic
language Learning quizzes thanks to prompting.
  The effectiveness of the tool is evaluated through a manual annotated
benchmark consisting of 1266 real-life visual quizzes, with human participants
providing feedback. The results show a suitable accuracy rates, validating the
tool's potential to bridge the gap in Arabic language education and
highlighting the tool's promise as a reliable, AI-powered resource for Arabic
learners, offering personalized and interactive learning experiences.

</details>


### [326] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
*Yijin Yang,Cristina Cornelio,Mario Leiva,Paulo Shakarian*

Main category: cs.AI

TL;DR: EDCIM detects and corrects LLM reasoning errors in math tasks using a hybrid LLM approach and symbolic error detection, reducing costs and improving accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing LLMs struggle with errors in intermediate reasoning steps, hallucinations, and output format adherence, particularly in tasks requiring explicit functional forms like interpretable mathematics. This hinders accurate predictions and reliable outputs.

Method: EDCIM uses LLMs to generate a system of equations, followed by a symbolic error-detection framework for error identification and targeted feedback. It integrates lightweight, open-source LLMs with powerful proprietary models, controlled by a single hyperparameter to balance cost and accuracy.

Result: Experimental results show that EDCIM significantly reduces computational and financial costs while maintaining, and in some cases improving, prediction accuracy when the cost-accuracy balance is properly configured.

Conclusion: EDCIM (Error Detection and Correction for Interpretable Mathematics) method effectively detects and corrects errors in LLM-generated intermediate steps for interpretable mathematics tasks. It significantly reduces computational and financial costs while maintaining or improving prediction accuracy through a hybrid LLM approach and a symbolic error-detection framework.

Abstract: Recent large language models (LLMs) have demonstrated the ability to perform
explicit multi-step reasoning such as chain-of-thought prompting. However,
their intermediate steps often contain errors that can propagate leading to
inaccurate final predictions. Additionally, LLMs still struggle with
hallucinations and often fail to adhere to prescribed output formats, which is
particularly problematic for tasks like generating mathematical expressions or
source code. This work introduces EDCIM (Error Detection and Correction for
Interpretable Mathematics), a method for detecting and correcting these errors
in interpretable mathematics tasks, where the model must generate the exact
functional form that explicitly solve the problem (expressed in natural
language) rather than a black-box solution. EDCIM uses LLMs to generate a
system of equations for a given problem, followed by a symbolic error-detection
framework that identifies errors and provides targeted feedback for LLM-based
correction. To optimize efficiency, EDCIM integrates lightweight, open-source
LLMs with more powerful proprietary models, balancing cost and accuracy. This
balance is controlled by a single hyperparameter, allowing users to control the
trade-off based on their cost and accuracy requirements. Experimental results
across different datasets show that EDCIM significantly reduces both
computational and financial costs, while maintaining, and even improving,
prediction accuracy when the balance is properly configured.

</details>


### [327] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
*Jorge Gallego-Feliciano,S. Aaron McClendon,Juan Morinelli,Stavros Zervoudakis,Antonios Saravanos*

Main category: cs.AI

TL;DR: 大规模激活在Transformer训练中遵循可预测的数学模式，可以通过模型设计进行预测和控制。


<details>
  <summary>Details</summary>
Motivation: 为了理解大规模激活在Transformer训练过程中出现的时间动态，而先前的研究主要集中在完全训练好的模型上。

Method: 通过系统分析不同模型大小和多个训练检查点，使用指数调制对数函数（具有五个关键参数）对大规模激活的出现进行建模，并开发了一个机器学习框架，仅根据架构规范预测这些数学参数。

Result: 大规模激活的出现遵循可预测的数学模式，可以使用指数调制对数函数准确建模。机器学习框架能够高精度地预测稳态行为，并中等精度地预测出现时间和幅度。

Conclusion: 大规模激活的出现受模型设计控制，并且可以在训练开始前进行预测和潜在控制。

Abstract: Massive activations are scalar values in transformer hidden states that
achieve values orders of magnitude larger than typical activations and have
been shown to be critical for model functionality. While prior work has
characterized these phenomena in fully trained models, the temporal dynamics of
their emergence during training remain poorly understood. We present the first
comprehensive analysis of massive activation development throughout transformer
training, using the Pythia model family as our testbed. Through systematic
analysis of various model sizes across multiple training checkpoints, we
demonstrate that massive activation emergence follows predictable mathematical
patterns that can be accurately modeled using an exponentially-modulated
logarithmic function with five key parameters. We develop a machine learning
framework to predict these mathematical parameters from architectural
specifications alone, achieving high accuracy for steady-state behavior and
moderate accuracy for emergence timing and magnitude. These findings enable
architects to predict and potentially control key aspects of massive activation
emergence through design choices, with significant implications for model
stability, training cycle length, interpretability, and optimization. Our
findings demonstrate that the emergence of massive activations is governed by
model design and can be anticipated, and potentially controlled, before
training begins.

</details>


### [328] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
*Jialin Li,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: 该研究提出了 FPBench 框架，用于评估大型语言模型在错误输入前提下的代码生成能力，发现大多数模型在该场景下表现不佳，并揭示了其认知机制的特点，强调了模型进行前提验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型代码生成能力的提升，其对输入前提的依赖性也日益增强。当用户输入包含错误前提时，代码生成幻觉的概率会显著增加，暴露了模型自我审视能力的不足。

Method: 提出了首个针对错误前提的代码生成评估框架 FPBench，该框架系统性地构建了三类错误前提，并整合了多维度评估指标，对15个代表性的大型语言模型进行了深入评估。

Result: 研究发现，大多数模型在错误前提下表现出较差的推理能力和代码生成性能，并且严重依赖显式提示来检测错误，自我审视能力有限。错误前提触发了资源投入的边际效应递减点，盲目增加长度并不能提升质量。三类错误前提分别激活了模型不同的缺陷模式，揭示了代码生成模型认知机制的三重分离现象。

Conclusion: 该研究强调了大型语言模型在代码生成过程中主动验证输入前提的必要性，并通过提出的 FPBench 框架和多维度评估系统，为开发可靠、以人为本的代码生成模型提供了理论基础和实践途径。

Abstract: With the advancement of code generation capabilities in large language models
(LLMs), their reliance on input premises has intensified. When users provide
inputs containing faulty premises, the probability of code generation
hallucinations rises significantly, exposing deficiencies in their
self-scrutiny capabilities. This paper proposes Faulty Premises Bench
(FPBench), the first code generation evaluation framework targeting faulty
premises. By systematically constructing three categories of faulty premises
and integrating multi-dimensional evaluation metrics, it conducts in-depth
assessments of 15 representative LLMs. The key findings are as follows: (1)
Most models exhibit poor reasoning abilities and suboptimal code generation
performance under faulty premises, heavily relying on explicit prompts for
error detection, with limited self-scrutiny capabilities; (2) Faulty premises
trigger a point of diminishing returns in resource investment, leading to
blindly increasing length fails to enhance quality; (3) The three types of
faulty premises respectively activate distinct defect patterns in models,
revealing a triple dissociation in the cognitive mechanisms of code generation
models. This study not only highlights the urgent need for LLMs to proactively
verify premises in code generation but also, through the proposed FPBench
framework and multi-dimensional evaluation system, provides a theoretical
foundation and practical pathway for developing reliable, human-centric code
generation models.

</details>


### [329] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
*He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: 提出了一种名为Evo-MCTS的框架，通过结合搜索、进化优化和LLM启发式方法，解决了现有引力波探测算法的局限性，并在MLGWSC-1数据集上实现了20.2%的性能提升，同时发现了可解释的算法路径和新的算法组合。


<details>
  <summary>Details</summary>
Motivation: 解决了现有引力波信号识别算法（如匹配滤波和深度神经网络）的局限性，这些算法分别面临计算成本高和黑盒模型带来的偏见问题。

Method: 提出了一种名为Evo-MCTS的框架，结合了蒙特卡罗树搜索、进化优化和大型语言模型启发式方法，通过领域感知的物理约束来指导算法空间探索，以创建可解释的算法解决方案。

Result: Evo-MCTS框架在MLGWSC-1基准数据集上，相比于最先进的引力波探测算法，性能提升了20.2%。发现的高性能算法变体持续超过阈值，并生成了人类可解释的算法路径，揭示了不同的性能模式。

Conclusion: Evo-MCTS框架在引力波探测任务上取得了显著的性能提升，并发现了新颖的算法组合，为计算科学领域提供了可转移的自动化算法发现方法论。

Abstract: Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.

</details>


### [330] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
*Xufang Luo,Yuge Zhang,Zhiyuan He,Zilong Wang,Siyun Zhao,Dongsheng Li,Luna K. Qiu,Yuqing Yang*

Main category: cs.AI

TL;DR: Agent Lightning 是一个新框架，可以轻松地用强化学习来训练任何 AI Agent，只需很少的代码修改。它通过将 Agent 的行为视为一个过程并使用名为 LightningRL 的新算法来工作，该算法可以处理复杂的交互。实验证明该框架在各种任务上都能稳定地改进 Agent。


<details>
  <summary>Details</summary>
Motivation: 现有方法将 RL 训练与 Agent 紧密耦合或依赖于带掩码的序列连接，限制了 RL 在 Agent 训练中的应用。本研究旨在提出一种灵活且可扩展的框架，能够对任意 AI Agent 进行 RL 训练，并实现训练与 Agent 执行的完全解耦。

Method: 提出了一种称为 Agent Lightning 的灵活且可扩展的框架，用于基于强化学习（RL）的 LLM 训练。该框架实现了训练与 Agent 执行的完全解耦，允许与使用 LangChain、OpenAI Agents SDK、AutoGen 等框架或从头开始构建的现有 Agent 无缝集成，代码修改量极少。通过将 Agent 执行公式化为马尔可夫决策过程，定义了统一的数据接口，并提出了一种分层 RL 算法 LightningRL，该算法包含一个信用分配模块，能够将任意 Agent 生成的轨迹分解为训练转移。

Result: 实验结果表明，Agent Lightning 框架在文本到 SQL、检索增强生成和数学工具使用等任务上，能够实现稳定、持续的改进，证明了该框架在实际 Agent 训练和部署方面的潜力。

Conclusion: Agent Lightning 框架通过解耦训练和执行、统一的数据接口和分层 RL 算法（LightningRL）的引入，实现了对任意 AI Agent 的强化学习训练。该框架在文本到 SQL、检索增强生成和数学工具使用等任务上展现了稳定且持续的改进，证明了其在实际 Agent 训练和部署中的潜力。

Abstract: We present Agent Lightning, a flexible and extensible framework that enables
Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for
any AI agent. Unlike existing methods that tightly couple RL training with
agent or rely on sequence concatenation with masking, Agent Lightning achieves
complete decoupling between agent execution and training, allowing seamless
integration with existing agents developed via diverse ways (e.g., using
frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from
scratch) with almost ZERO code modifications. By formulating agent execution as
Markov decision process, we define an unified data interface and propose a
hierarchical RL algorithm, LightningRL, which contains a credit assignment
module, allowing us to decompose trajectories generated by ANY agents into
training transition. This enables RL to handle complex interaction logic, such
as multi-agent scenarios and dynamic workflows. For the system design, we
introduce a Training-Agent Disaggregation architecture, and brings agent
observability frameworks into agent runtime, providing a standardized agent
finetuning interface. Experiments across text-to-SQL, retrieval-augmented
generation, and math tool-use tasks demonstrate stable, continuous
improvements, showcasing the framework's potential for real-world agent
training and deployment.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [331] [Stabilizing ergotropy in Spin-Chain Quantum Batteries via Energy-Invariant Catalysis under Strong Non-Markovian Coupling](https://arxiv.org/abs/2508.02772)
*Shun-Cai Zhao,Liang Luo,Ni-Ya Zhuang*

Main category: quant-ph

TL;DR: 量子电池（QB）在微型储能领域展现出潜力，但现有研究多假设弱耦合和马尔可夫动态。本研究探讨了物理催化如何调节强耦合到腔环境的自旋链QB的最大可提取功（能）。通过使用非马尔可夫主方程，我们发现增加催化剂-自旋耦合、自旋能量或腔频率能抑制能量振荡，实现准稳态。但过强的催化剂或系统-环境耦合会破坏稳定性。量子催化为优化强耦合非马尔可夫体系中的QB性能提供了控制手段。


<details>
  <summary>Details</summary>
Motivation: 探索物理催化如何调节强耦合到腔环境的自旋链量子电池的最大可提取功（能）。

Method: 使用Nakajima-Zwanzig类型的非马尔可夫主方程模拟系统，并模拟不同物理参数下系统的能量演化。

Result: 结果表明，增加催化剂-自旋耦合、自旋能量或腔频率可以有效抑制能量振荡，并产生准稳态能量状态。然而，过强的催化剂（尤其是在这种条件下伴随增加的系统-环境耦合）会破坏功提取的稳定性。

Conclusion: 量子催化可作为优化强耦合非马尔可夫体系中量子电池性能的控制旋钮。

Abstract: Quantum batteries (QBs) have emerged as promising platforms for microscale
energy storage, yet most existing studies assume weak system-environment
coupling and Markovian dynamics. Here we explore how physical catalysis can
regulate the maximum extractable work (ergotropy) of a spin-chain QB strongly
coupled to a cavity environment. We model the system using a
Nakajima-Zwanzig-type non-Markovian master equation and simulate the time
evolution of ergotropy under various physical parameters. Our results show that
increasing the catalyst-spin coupling, spin energy or cavity frequency can
effectively suppress ergotropy oscillations and yield quasi-stationary
ergotropy regime, while overly strong catalyst, especially when accompanied by
increasing system-environment coupling under such conditions, can destabilize
work extraction. This study demonstrates how quantum catalysis can serve as a
control knob for optimizing battery performance in strongly coupled
non-Markovian regimes.

</details>


### [332] [Heating suppression via two-rate random and quasiperiodic drive protocols](https://arxiv.org/abs/2508.02783)
*Krishanu Ghosh,Sayan Choudhury,Diptiman Sen,K. Sengupta*

Main category: quant-ph

TL;DR: 该论文研究了具有磁场的随机和准周期驱动的一维PXP自旋链。通过两种驱动协议（一种是改变脉冲持续时间的随机驱动，另一种是使用TM或斐波那契序列的准周期偶极子驱动），研究发现可以显著减缓系统的热化。特别是TM准周期驱动的效果优于其他驱动方式。研究还提供了理论解释，并提出了实验验证的建议。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索随机和准周期驱动对一维非可积PXP自旋链热化行为的影响，特别是寻找能够显著减缓热化过程的驱动协议和参数范围，并理解其背后的物理机制。

Method: 该研究通过精确计算小尺寸系统和在驱动幅度大的情况下进行微扰分析，来研究一维非可积PXP自旋链在磁场中的随机和准周期驱动行为。具体采用了两种驱动协议：第一种协议通过幅度$dT$随机改变脉冲持续时间；第二种协议使用随机/准周期偶极子驱动，其中准周期性通过Thue-Morse（TM）或斐波那契序列实现。

Result: 研究发现在两类驱动协议中均存在参数范围，可以显著减缓链的热化。对于第一类协议，存在特殊的$dT$值，使得热化速率保持较低，并对此给出了解析解释。对于第二类协议，TM准周期驱动相比于随机或斐波那契序列驱动，展现出明显更慢的热化速率。

Conclusion: 该研究识别了参数范围，通过两类驱动协议，可以显著减缓一维非可积PXP自旋链在磁场中的热化过程。研究发现，Thue-Morse（TM）准周期驱动比随机或斐波那契序列驱动能更有效地减缓热化。研究还提出了基于精确计算或微扰分析的半解析理解，并讨论了可用于验证理论的实验。

Abstract: We study a random and quasiperiodically driven one-dimensional non-integrable
PXP spin chain in a magnetic field for two distinct drive protocols. Each of
these protocols involves square pulses with two driving frequencies which are
integer multiples of each other. For the first class of protocols, the duration
of the pulse is changed randomly by an amplitude $dT$ while for the second
class we use a random/quasiperiodic dipolar drive, where the quasiperiodicity
is implemented using the Thue-Morse (TM) or Fibonacci sequences. For both
protocols, we identify parameter regimes for which the thermalization of the
driven chain is drastically slowed down due to proximity to a two-rate drive
induced exact dynamical freezing. We also study the properties of these driven
system moving slightly away from the freezing limit. For the first type of
protocols, we show the existence of special value of $dT$ for which the
thermalization rate remains small and provide an analytic explanation for such
slow thermalization. For the second class of protocols, in contrast to
random/quasiperiodic drives involving a single frequency studied earlier, we
find that the TM quasiperiodic drive leads to a distinctly slower
thermalization than that for drive protocols which are either periodic or
follow a random or quasiperiodic Fibonacci sequence. We provide a qualitative
semi-analytic understanding of these phenomena either using an exact
calculation for small system sizes or carrying out a perturbative analysis in
the large drive-amplitude limit. Our analysis brings out the central role of
such two-frequency protocols in the reduction of heating in driven quantum
systems. We discuss experiments which can test our theory.

</details>


### [333] [Measurement-Induced Entanglement in Conformal Field Theory](https://arxiv.org/abs/2508.02788)
*Kabir Khanna,Romain Vasseur*

Main category: quant-ph

TL;DR: 通过测量局域荷算符，研究了Tomonaga-Luttinger液中的测量诱导纠缠（MIE），发现其具有普适性、共形不变性，并取决于CFT的算符内容。研究结果与矩阵乘积态计算一致，并揭示了MIE与强制测量结果的区别。


<details>
  <summary>Details</summary>
Motivation: 局域测量对多体纠缠有重要影响，但现有解析结果稀少，且测量常被近似处理。本研究旨在深入理解测量对多体态（特别是Tomonaga-Luttinger液）的影响，并揭示测量诱导纠缠的普适性和共形不变性。

Method: 本研究采用副本技巧来处理测量结果的随机性，并精确计算了Tomonaga-Luttinger液中的测量诱导纠缠（MIE）。通过测量局域荷算符，分析了MIE与CFT算符内容的关系。

Result: 测量诱导的纠缠（MIE）是完全普适的、共形不变的，并取决于CFT的算符内容。MIE与强制测量结果所诱导的纠缠有本质区别，并通过在共形不变边界条件下进行玻恩平均来解释。

Conclusion: 局域测量对多体纠缠模式，特别是长程纠缠的量子临界态，会产生显著影响。然而，关于测量对多体态效应的解析结果仍然稀少，测量通常被近似为强制产生特定的测量结果。本研究关注Tomonaga-Luttinger液中的测量诱导纠缠（MIE），这是一类广泛的1+1维量子临界态，在低能量下由紧致自由玻色子共形场论（CFT）描述。通过测量局域荷算符，我们证明了MIE具有完全的普适性、共形不变性，并取决于CFT的算符内容。我们利用副本技巧处理测量结果的随机性，精确计算了Tomonaga-Luttinger液中的MIE，结果与矩阵乘积态计算高度一致。我们证明了物理量子测量的MIE与强制测量结果所诱导的纠缠从根本上不同，并且可以自然地解释为在共形不变边界条件下进行玻恩平均。

Abstract: Local measurements can radically reshape patterns of many-body entanglement,
especially in long-range entangled quantum-critical states. Yet, analytical
results addressing the effects of measurements on many-body states remain
scarce, and measurements are often approximated as forcing specific measurement
outcomes. We study measurement-induced entanglement (MIE) in Tomonaga-Luttinger
liquids, a broad family of 1+1d quantum critical states described at low
energies by compact free boson conformal field theories (CFT). Measuring the
local charge operator, we show that the MIE is entirely universal, conformally
invariant, and depends on the operator content of the CFT. Using a
replica-trick to address the randomness of the measurement outcomes, we compute
the MIE exactly for Tomonaga-Luttinger liquids, in very good agreement with
matrix-product state calculations. We show that the MIE for physical quantum
measurements is fundamentally different from the entanglement induced by
forcing measurement outcomes, and has a natural interpretation in terms of Born
averaging over conformally-invariant boundary conditions.

</details>


### [334] [Strong electron-electron interactions in a dilute weakly-localized metal near a metal-to-insulator transition](https://arxiv.org/abs/2508.02793)
*Nicolò D'Anna,Jamie Bragg,Aidan G. McConnell,Procopios C. Constantinou,Juerong Li,Taylor J. Z. Stock,Steven R. Schofield,Neil J. Curson,Y. Soh,Marek Bartkowiak,Simon Gerber,Markus Müller,Guy Matmon,Gabriel Aeppli*

Main category: quant-ph

TL;DR: 硅的金属-绝缘体转变（MIT）是现代信息技术和量子计算的关键。本研究利用先进的掺杂技术在硅中实现了二维无序哈伯德模型，发现MIT过程中电子-电子相互作用效应取代了弱局域化效应，并表现出与Kondo效应不同的特性。


<details>
  <summary>Details</summary>
Motivation: 鉴于硅在现代信息技术和量子计算中的核心地位，研究其金属-绝缘体转变（MIT）现象对于理解和利用该材料至关重要。

Method: 利用气体相掺杂技术在硅中创建了砷和磷的δ层，厚度可达0.4nm，密度低至10^13 cm^-2，实现了二维无序哈伯德模型及其金属-绝缘体转变。

Result: 在接近绝缘状态时，电子-电子相互作用效应主导了电导，表现出顺磁泽曼标度律，并对电导产生负贡献，这不同于Kondo效应。

Conclusion: 该研究利用气体相掺杂技术在硅中实现了二维无序哈伯德模型，并研究了其在金属-绝缘体转变（MIT）过程中的特性。研究发现，在接近绝缘状态时，传统的弱局域化效应被电子-电子相互作用效应主导，该效应遵循顺磁泽曼标度律，并对电导产生负贡献，这表明其不能被解释为MIT附近的Kondo效应。

Abstract: Because it is easily switched from insulator to metal either via chemical
doping or electrical gating, silicon is at the core of modern information
technology and remains a candidate platform for quantum computing. The
metal-to-insulator transition in this material has therefore been one of the
most studied phenomena in condensed matter physics, and has been revisited with
considerable profit each time a new fabrication technology has been introduced.
Here we take advantage of recent advances in creating ultra-thin layers of
Bohr-atom-like dopants to realize the two-dimensional disordered Hubbard model
at half-filling and its metal-to-insulator transition (MIT) as a function of
mean distance between atoms. We use gas-phase dosing of dopant precursor
molecules on silicon to create arsenic and phosphorus $\delta$-layers as thin
as 0.4~nm and as dilute as 10$^{13}$~cm$^{-2}$. On approaching the insulating
state, the conventional weak localization effects, prevalent at high dopant
densities and due to orbital motion of the electrons in the plane, become
dominated by electron-electron interaction contributions which obey a
paramagnetic Zeeman scaling law. The latter make a negative contribution to the
conductance, and thus cannot be interpreted in terms of an emergent Kondo
regime near the MIT.

</details>


### [335] [Tailoring interaction ranges in atom arrays](https://arxiv.org/abs/2508.02815)
*T. Botzung,G. Creutzer,C. Sayrin,J. Schachenmayer*

Main category: quant-ph

TL;DR: A new method is presented to control interactions in atom arrays using relay atoms to modify the electromagnetic vacuum, demonstrated to be effective with Rydberg atoms.


<details>
  <summary>Details</summary>
Motivation: To synthetically engineer the range of dipolar interactions in tweezer atom arrays.

Method: Derive equations of motion for the atoms of interest after adiabatic elimination of the relay atoms.

Result: The effectiveness of the scheme is shown for realistic experimental parameter regimes with circular and low-angular-momentum Rydberg atom states.

Conclusion: The paper introduces a method to synthetically engineer the range of dipolar interactions in tweezer atom arrays by effectively modifying the modes of the electromagnetic vacuum with far-detuned relay atoms.

Abstract: We introduce a method to synthetically engineer the range of dipolar
interactions in tweezer atom arrays by effectively modifying the modes of the
electromagnetic vacuum with far-detuned relay atoms. We derive equations of
motion for the atoms of interest after adiabatic elimination of the relay
atoms. We show the effectiveness of the scheme for realistic experimental
parameter regimes with circular and low-angular-momentum Rydberg atom states.

</details>


### [336] [Quantum algorithm for linear matrix equations](https://arxiv.org/abs/2508.02822)
*Rolando D. Somma,Guang Hao Low,Dominic W. Berry,Ryan Babbush*

Main category: quant-ph

TL;DR: 我们开发了一种新的量子算法，可以比先前的方法更快地解决 Sylvester 方程。该算法通过创建解矩阵的块编码来实现这一点，从而在某些应用中实现指数级加速。


<details>
  <summary>Details</summary>
Motivation: 为了高效地解决控制理论和物理学中有广泛应用的 Sylvester 方程（AX+XB=C）。

Method: 该方法通过构建一个重缩放的块编码来表示解矩阵 X，而不是将其编码为量子态。

Result: 该算法实现了对 Sylvester 方程解的某些性质的指数级加速，并且量子电路的复杂度几乎与条件数成线性关系，与维度和反误差成对数关系。

Conclusion: 我们的量子算法在解决 Sylvester 方程方面，通过构建重缩放的块编码解 X，提供了指数级的速度提升，并具有近乎线性的查询和门复杂度。

Abstract: We describe an efficient quantum algorithm for solving the linear matrix
equation AX+XB=C, where A, B and C are given complex matrices and X is unknown.
This is known as the Sylvester equation, a fundamental equation with
applications in control theory and physics. Rather than encoding the solution
in a quantum state in a fashion analogous to prior quantum linear algebra
solvers, our approach constructs the solution matrix X in a block-encoding,
rescaled by some factor. This allows us to obtain certain properties of the
entries of X exponentially faster than would be possible from preparing X as a
quantum state. The query and gate complexities of the quantum circuit that
implements this block-encoding are almost linear in a condition number that
depends on A and B, and depend logarithmically in the dimension and inverse
error. We show how our quantum circuits can solve BQP-complete problems
efficiently, discuss potential applications and extensions of our approach, its
connection to Riccati equation, and comment on open problems.

</details>


### [337] [A resource-efficient quantum-walker Quantum RAM](https://arxiv.org/abs/2508.02855)
*Giuseppe De Riso,Giuseppe Catalano,Seth Lloyd,Vittorio Giovannetti,Dario De Santis*

Main category: quant-ph

TL;DR: 介绍了一种更高效、更易于实现的量子随机存取存储器（qRAM），它使用的量子资源更少，并且可以通过简单的、重复的本地操作来实现。


<details>
  <summary>Details</summary>
Motivation: 目前的qRAM方案资源需求过高，且依赖于超出当前硬件能力的操作，导致其实际实现效率低下。

Method: 提出了一种基于量子游走者在二叉树上操作的新型qRAM架构，该架构仅使用局部酉操作和短程相互作用，并设计了简单的、重复的操作块。

Result: 成功地降低了资源需求，同时保持了最佳的查询复杂度扩展性，简化了实验要求，并提高了可扩展性。

Conclusion: 该研究提出了一种新颖的量子随机存取存储器（qRAM）架构，该架构显著降低了资源需求，同时保持了最佳的量子查询复杂度扩展性。该架构利用了简单的、重复的、仅基于局部酉操作和短程相互作用的操作块，以及在单个二叉树上传播的有限数量的量子游走者，从而简化了实验要求并提高了可扩展性。

Abstract: Efficient and coherent data retrieval and storage are essential for
harnessing quantum algorithms' speedup. Such a fundamental task is addressed by
a quantum Random Access Memory (qRAM). Despite their promising scaling
properties, current qRAM proposals demand excessive resources and rely on
operations beyond the capabilities of current hardware requirements, rendering
their practical realization inefficient. We introduce a novel architecture that
significantly reduces resource requirements while preserving optimal complexity
scaling for quantum queries. Moreover, unlike previous proposals, our algorithm
design leverages a simple, repeated operational block based exclusively on
local unitary operations and short-range interactions between a limited number
of quantum walkers traveling over a single binary tree. This novel approach not
only simplifies experimental requirements by reducing the complexity of
necessary operations but also enhances the architecture's scalability by
ensuring a resource-efficient, modular design that maintains optimal quantum
query performance.

</details>


### [338] [Pulse Shaping for Ultra-Fast Adiabatic Quantum Gates](https://arxiv.org/abs/2508.02902)
*İlker Polat,Ramon W. J. Overwater,Maximilian Rimbach-Russ,Fabio Sebastiano*

Main category: quant-ph

TL;DR: A new method called DLR uses time-delayed control signals to reduce leakage in quantum computing, achieving high fidelity with semiconductor spin qubits.


<details>
  <summary>Details</summary>
Motivation: A fundamental challenge in quantum computing is to increase the number of operations within the qubit coherence time. While decreasing gate duration can achieve this, it increases signal bandwidth and can cause leakage. DRAG method, a common solution, cannot be applied to baseband signals, e.g., for semiconductor spin qubits.

Method: The paper proposes a novel technique, Delayed Leakage Reduction (DLR), that suppresses leakage at targeted frequencies even for baseband control by using time-delayed repetitions of the control signal. The impact on fidelity of the sampling rate of the electronic hardware generating the control pulse is also assessed.

Result: DLR achieves fidelities exceeding 99.9% within 9.4 ns for a resonance frequency difference of only 100 MHz. The paper also assesses the impact of the sampling rate of the electronic hardware on fidelity.

Conclusion: DLR is a novel technique that suppresses leakage at targeted frequencies even for baseband control by using time-delayed repetitions of the control signal to enable rapid, high-fidelity operations. It achieves fidelities exceeding 99.9% within 9.4 ns for a resonance frequency difference of only 100 MHz.

Abstract: A fundamental challenge in quantum computing is to increase the number of
operations within the qubit coherence time. While this can be achieved by
decreasing the gate duration, the use of shorter signals increases their
bandwidth and can cause leakage into energetically separated states. A common
method to suppress leakage for short pulses is the Derivative Removal by
Adiabatic Gate (DRAG) method, which however, relies on IQ modulation of
radio-frequency (RF) signals, thus cannot be applied to the baseband signals,
e.g., for semiconductor spin qubits. This paper proposes a novel technique,
Delayed Leakage Reduction (DLR), that suppresses leakage at targeted
frequencies even for baseband control by using time-delayed repetitions of the
control signal to enable rapid, high-fidelity operations. We apply DLR on the
adiabatic CZ gate between two spin qubits and achieve fidelities exceeding
99.9% within 9.4 ns for a resonance frequency difference of only 100 MHz.
Towards the experimental realization of the proposed control method, we also
assess the impact on the fidelity of the sampling rate of the electronic
hardware generating the control pulse, thus setting the minimum hardware
requirements for any experimental demonstration.

</details>


### [339] [Efficient Variational Quantum Algorithms via Circuit Knitting and Architecture Search](https://arxiv.org/abs/2508.03376)
*Jun Wu,Jiaqi Yang,Jicun Li,Wei Xie,Xiang-Yang Li*

Main category: quant-ph

TL;DR: CKVQA是一个框架，通过电路剪枝和子电路优化来解决量子硬件限制和高采样开销问题，适用于VQA。


<details>
  <summary>Details</summary>
Motivation: 当前的量子硬件限制了可用的量子比特数量，而电路剪枝虽然可以解决这个问题，但会导致很高的采样开销。

Method: CKVQA框架应用电路剪枝到变分量子算法（VQA）中，并通过子电路级别的优化来加速训练。

Result: CKVQA框架显著减少了采样开销，同时保持了与传统参数化量子电路设计相当的准确性。

Conclusion: CKVQA框架通过采用适用于此场景的量子电路架构搜索，旨在通过识别在算法性能和采样开销之间取得良好平衡的参数化量子电路来最小化采样开销。此外，由于电路剪枝会生成多个子电路，我们开发了一种子电路级别的优化方法来加速VQA的训练并减少总体执行时间。

Abstract: Current quantum hardware presents a significant limitation in the number of
available qubits compared to the requirements of practical quantum algorithms.
Circuit knitting has been proposed as a solution to this issue by partitioning
larger quantum circuits into smaller parts that can be executed by current
devices. However, this approach often leads to a high sampling overhead, which
increases exponentially with the number of cut points. In this paper, we
introduce CKVQA, a framework that applies circuit knitting to variational
quantum algorithms (VQAs). By employing a quantum circuit architecture search
adapted to this scenario, CKVQA aims to minimize the sampling overhead by
identifying parameterized quantum circuits that achieve a favorable balance
between algorithmic performance and sampling overhead. Additionally, since
circuit knitting generates multiple subcircuits, we have developed a
subcircuit-level optimization method to accelerate the training of VQAs and
reduce overall execution time. We apply this framework to two widely-used VQAs:
the Quantum Approximate Optimization Algorithm and the Variational Quantum
Eigensolver. Our numerical results demonstrate that the CKVQA framework
significantly reduces the sampling overheads while maintaining comparable
accuracy to conventional parameterized quantum circuit designs.

</details>


### [340] [Intermediate-temperature topological Uhlmann phase on IBM quantum computers](https://arxiv.org/abs/2508.02915)
*Christopher Mastandrea,Costin Iancu,Hao Guo,Chih-Chun Chien*

Main category: quant-ph

TL;DR: 该研究提出并优化了一个量子电路，用于在NISQ量子计算机上演示自旋1系统的有限温度拓扑现象，并通过实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 研究自旋1系统在中间温度下可能存在的拓扑区域，该区域具有量子化的Uhlmann相位，并被拓扑平凡的低温和高温区域夹在中间。

Method: 提出一个包含系统、辅助和探针量子比特的量子电路，该电路制备了有限温度下自旋1系统的纯态的初始状态，根据Uhlmann过程演化系统，并通过探针量子比特的期望值测量Uhlmann相位。

Result: 经过Qiskit和BQSQit的一系列优化，可以显著减少门计数，使Uhlmann相位的跳变更加可见。最近IBM量子计算机的硬件升级进一步改善了信号，使得在NISQ硬件上更清晰地演示有趣的有限温度拓扑现象成为可能。

Conclusion: 通过优化和硬件升级，可以在NISQ硬件上更清晰地演示有趣的有限温度拓扑现象。

Abstract: A spin-1 system can exhibit an intermediate-temperature topological regime
with a quantized Uhlmann phase sandwiched by topologically trivial low- and
high-temperature regimes. We present a quantum circuit consisting of system and
ancilla qubits plus a probe qubit which prepares an initial state corresponding
to the purified state of a spin-1 system at finite temperature, evolves the
system according to the Uhlmann process, and measures the Uhlmann phase via
expectation values of the probe qubit. Although classical simulations suggest
the quantized Uhlmann phase is observable on IBM's noisy intermediate-scale
quantum (NISQ) computers, an implementation of the circuit without any
optimization exceeds the gate count for the error budget and results in
unresolved signals. Through a series of optimization with Qiskit and BQSQit,
the gate count can be substantially reduced, making the jumps of the Uhlmann
phase more visible. A recent hardware upgrade of IBM quantum computers further
improves the signals and leads to a clearer demonstration of interesting
finite-temperature topological phenomena on NISQ hardware.

</details>


### [341] [Characterizing and Mitigating Flux Crosstalk in Superconducting Qubits-Couplers System](https://arxiv.org/abs/2508.03434)
*Chen-Hsun Ma,Myrron Albert Callera Aguila,Nien-Yu Li,Li-Chieh Hsiao,Yi-Shiang Huang,Yen-Chun Chen,Teik-Hui Lee,Chin-Chia Chang,Jyh-Yang Wang,Ssu-Yen Huang,Hsi-Sheng Goan,Chiao-Hsuan Wang,Cen-Shawn Wu,Chii-Dong Chen,Chung-Ting Ke*

Main category: quant-ph

TL;DR: 本研究提出了一种通过校正矩阵来抑制超导量子比特中通量串扰的方法，显著提高了控制精度和校准准确性，有助于量子处理器的扩展。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错量子计算，需要增加物理量子比特的数量，但这会导致密集的通量控制线产生磁通串扰，从而降低门保真度和校准精度。

Method: 通过量化量子比特和耦合器的相互通量诱导频移，构建了一个能够精确补偿非局域通量的校正矩阵。

Result: 成功将Z线串扰从56.5‰降低到0.13‰，接近统计误差，并修正了CZ SWAP测量，实现了关于通量偏差的对称映射，验证了该方法在实现无串扰通量控制方面的有效性。

Conclusion: 该方法通过构建校正矩阵有效抑制了超导量子比特中的通量串扰，将串扰从56.5‰降低到0.13‰，为扩展超导量子处理器提供了支持。

Abstract: Superconducting qubits have achieved exceptional gate fidelities, exceeding
the error-correction threshold in recent years. One key ingredient of such
improvement is the introduction of tunable couplers to control the
qubit-to-qubit coupling through frequency tuning. Moving toward fault-tolerant
quantum computation, increasing the number of physical qubits is another step
toward effective error correction codes. Under a multiqubit architecture, flux
control (Z) lines are crucial in tuning the frequency of the qubits and
couplers. However, dense flux lines result in magnetic flux crosstalk, wherein
magnetic flux applied to one element inadvertently affects neighboring qubits
or couplers. This crosstalk obscures the idle frequency of the qubit when flux
bias is applied, which degrades gate performance and calibration accuracy. In
this study, we characterize flux crosstalk and suppress it in a
multiqubit-coupler chip with multi-Z lines without adding additional readout
for couplers. By quantifying the mutual flux-induced frequency shifts of qubits
and couplers, we construct a cancellation matrix that enables precise
compensation of non-local flux, demonstrating a substantial reduction in Z-line
crosstalk from 56.5$\,$permille$\,$to 0.13$\,$permille$\,$ which is close to
statistical error. Flux compensation corrects the CZ SWAP measurement, leading
to a symmetric map with respect to flux bias. Compared with a crosstalk-free
calculated CZ SWAP map, the measured map indicates that our approach provides a
near-zero crosstalk for the coupler-transmon system. These results highlight
the effectiveness of our approach in enhancing flux crosstalk-free control and
supporting its potential for scaling superconducting quantum processors.

</details>


### [342] [Observation of Purcell Effect in Electrically Coupled Cavity-Magnet System](https://arxiv.org/abs/2508.02946)
*Italo L. Soares Andrade,Kleber Pirota,Amir O. Caldeira,Francisco Rouxinol*

Main category: quant-ph

TL;DR: 通过电场耦合在腔-金属磁体混合系统中观察到Purcell效应，实现了比传统耦合强一个数量级的耦合速率，并证明了该系统在微波与磁体耦合中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索在腔-金属磁体混合系统中实现Purcell效应，并开发一种通过几何和电场介导的相互作用来耦合微波场到金属磁体的新方法。

Method: 通过电场耦合和腔体微扰光谱技术，研究了微波诱导的轴向电流如何驱动磁性微线的铁磁共振，并测量了耦合速率和腔体光子寿命。

Result: 在室温和7 mK下，即使磁体体积很小，也实现了高达56 MHz的耦合速率，比预期高一个数量级。时间域测量直接显示了腔体光子寿命的磁场依赖性修改。

Conclusion: 该研究通过电场耦合在腔-金属磁体混合系统中实现了Purcell效应，并展示了这种混合系统在微波场与金属磁体耦合方面的潜力。

Abstract: We report the observation of the Purcell effect in a cavity-metallic magnet
hybrid system using electric-field-mediated coupling. In this configuration,
microwave-induced axial currents in the microwire induce circular magnetic
fields that drive the ferromagnetic resonance (FMR) of the magnetized
microwire. Field-dependent transmission and reflection spectroscopies reveal a
clear cavity perturbation consistent with the Purcell regime, in which the
magnetic loss rate exceeds the light-matter coupling strength. Despite the
small magnetic volume ($\sim 10^{-13}\,\text{m}^3$), measurements performed at
both room temperature and 7 mK show coupling rates as high as 56 MHz, one order
of magnitude stronger than expected from conventional coupling at the magnetic
antinode. Time-domain ringdown measurements directly show the
magnetic-field-dependent modification of the cavity photon lifetime, in
agreement with theoretical predictions. These results establish a versatile
approach for coupling microwave fields to metallic magnets via geometric and
electric-field-mediated interactions, opening new opportunities for hybrid
cavity-magnet systems.

</details>


### [343] [Today's Experiments Suffice to Verify the Quantum Essence of Gravity](https://arxiv.org/abs/2508.03052)
*Martin Plávala*

Main category: quant-ph

TL;DR: 本研究利用量子信息技术，证明了当前的物质波干涉仪足以间接证明引力相互作用在两个系统之间产生纠缠，并将引力-纠缠实验的可行性提上日程。


<details>
  <summary>Details</summary>
Motivation: 现有的引力-纠缠实验因技术限制而无法实现，本研究旨在利用量子信息技术，证明当前的物质波干涉仪足以间接证明引力相互作用在两个系统之间产生纠缠。

Method: 利用量子信息技术，证明了当前的物质波干涉仪足以间接证明引力相互作用在两个系统之间产生纠缠。

Result: 证明了如果实验上验证了单个非局域系统与外部质量的薛定谔方程，那么引力会介导两个系统之间的纠缠。

Conclusion: 该研究证明了如果实验上验证了单个非局域系统与外部质量的引力相互作用的薛定谔方程，那么两个非局域系统的时空演化将导致引力介导的纠缠，表明引力的量子本质的实验验证即将到来。

Abstract: The gravity-mediated entanglement experiments employ concepts from quantum
information to argue that if gravitational interaction creates entanglement
between two systems, then gravity cannot be described by a classical system.
However, the proposed experiments remain beyond out current technological
capability, with optimistic projections placing the experiment outside of
short-term future. Here we leverage quantum information techniques to argue
that current matter-wave interferometers are sufficient to indirectly prove
that gravitational interaction creates entanglement between two systems.
Specifically, we prove that if we experimentally verify the Schr\"{o}dinger
equation for a single delocalized system interacting gravitationally with an
external mass, then the time evolution of two delocalized systems will lead to
gravity-mediated entanglement. Our findings indicate that the experimental
verification of the quantum essence of gravity is on the horizon.

</details>


### [344] [Quantum Dynamics and Information Measures in PT and Anti-PT-Symmetric Systems](https://arxiv.org/abs/2508.03169)
*Amir Ahmadi,Roozbeh H. Asgari,Javad T. Firouzjaee*

Main category: quant-ph

TL;DR: 研究了PT对称和反PT对称哈密顿量对量子比特动力学的影响，发现反PT对称在抗退相干和信息保持方面更优。


<details>
  <summary>Details</summary>
Motivation: 研究PT对称和反PT对称哈密顿量下的量子比特动力学，关注相位演化、退相干、量子速度极限和Rényi纠缠熵。

Method: 使用相似变换和戴森映射分析了玻色子环境中的约化密度矩阵演化。

Result: 反PT对称系统表现出更强的鲁棒性，熵增长较慢，相干时间更长。量子速度极限行为表现为非单调，先快速演化后逐渐减慢。高阶Rényi熵表明反PT对称量子比特能更有效地保持量子信息。

Conclusion: Anti-PT对称系统比PT对称系统更能抵抗退相干，在熵增长和相干时间方面表现更优，并且能更有效地保持量子信息，在量子存储和量子密码学中具有优势。

Abstract: In this study, we investigate qubit dynamics under PT and Anti-PT-symmetric
non-Hermitian Hamiltonians, focusing on phase evolution, decoherence, quantum
speed limits (QSL), and R\'enyi entanglement entropies. Using similarity
transformations and Dyson maps, we analyze the reduced density matrix evolution
in bosonic environments. Anti-PT-symmetric systems show enhanced robustness
against decoherence, with slower entropy growth and longer coherence times
compared to PT-symmetric counterparts. QSL behavior is non-monotonic,
reflecting rapid initial evolution followed by a gradual decrease. Higher-order
R\'enyi entropies reveal that Anti-PT-symmetric qubits preserve quantum
information more effectively, offering advantages for memory and cryptographic
applications.

</details>


### [345] [Probing strongly driven and strongly coupled superconducting qubit-resonator system](https://arxiv.org/abs/2508.03188)
*Oleh V. Ivakhnenko,Christoforus Dimas Satrya,Yu-Cheng Chang,Rishabh Upadhyay,Joonas T. Peltonen,Sergey N. Shevchenko,Franco Nori,Jukka P. Pekola*

Main category: quant-ph

TL;DR: A superconducting flux qubit coupled to a resonator showed unique quantum interference due to strong coupling, differing from standard interferometry.


<details>
  <summary>Details</summary>
Motivation: Investigate quantum interference effects in a strongly driven and strongly coupled qubit-resonator system.

Method: Investigated a strongly driven qubit strongly coupled to a quantum resonator (superconducting flux qubit coupled to a coplanar-waveguide resonator weakly coupled to a probing feedline). The system was driven by a magnetic flux and probed with a weak probe signal through the feedline.

Result: Observed quantum interference effects deviating from usual single-qubit Landau-Zener-Stückelberg-Majorana interferometry.

Conclusion: We observed and theoretically described quantum interference effects that deviate from usual single-qubit Landau-Zener-Stückelberg-Majorana interferometry due to strong coupling distorting the qubit energy levels.

Abstract: We investigated a strongly driven qubit strongly connected to a quantum
resonator. The measured system was a superconducting flux qubit coupled to a
coplanar-waveguide resonator which is weakly coupled to a probing feedline.
This hybrid qubit-resonator system was driven by a magnetic flux and probed
with a weak probe signal through the feedline. We observed and theoretically
described the quantum interference effects, deviating from the usual
single-qubit Landau-Zener-St\"{u}ckelberg-Majorana interferometry, because the
strong coupling distorts the qubit energy levels.

</details>


### [346] [Fermionic-Adapted Shadow Tomography for dynamical correlation functions](https://arxiv.org/abs/2508.03192)
*Taehee Ko,Mancheon Han,Sangkook Choi*

Main category: quant-ph

TL;DR: 本研究提出了 Fermionic-Adapted Shadow Tomography (FAST) 协议，一种用于高效计算多个动力学关联函数的新框架。该方法通过将动力学关联函数重构为与影子层析成像技术兼容的形式，并采用最多两次拷贝测量和不受控制的哈密顿量模拟，显著提高了样本效率并减少了测量电路的数量。


<details>
  <summary>Details</summary>
Motivation: 为了克服经典计算量子多体系统对外部扰动响应的内在困难，并改进当前量子算法中依赖于暴力测量策略（每次只评估一个体可观测量对）的不足，本研究引入了一种新的框架。

Method: 提出了一种名为 Fermionic-Adapted Shadow Tomography (FAST) 的新框架，该框架通过将动力学关联函数重构为与影子层析成像技术兼容的形式，来实现高效计算。该方法所需的量子线路最多进行两次拷贝测量，并允许进行不受控制的哈密顿量模拟。

Result: 与传统的逐个计算动力学关联函数的方法相比，FAST 协议在样本效率方面得到了显著提升，并能减少一到两个数量级的测量量子比特数量，适用于多种场景。

Conclusion: Fermionic-Adapted Shadow Tomography (FAST) 协议通过将动力学关联函数重构为与影子层析成像技术兼容的形式，实现了高效计算。该方法所需的量子线路最多进行两次拷贝测量，并允许进行不受控制的哈密顿量模拟。与传统的逐个计算动力学关联函数的方法相比，FAST 协议在样本效率方面得到了显著提升，并能减少一到两个数量级的测量量子比特数量，适用于多种场景。

Abstract: Dynamical correlation functions are essential for characterizing the response
of the quantum many-body systems to the external perturbation. As their
calculation is classically intractible in general, quantum algorithms are
promising in this aspect, but most rely on brute force measurement strategies
that evaluate one body observable pair per circuit. In this work, we introduce
Fermionic-Adapted Shadow Tomography (FAST) protocols, a new framework for the
efficient calculation of multiple dynamical correlation functions. The key idea
is to reformulate these functions into forms that are compatible with shadow
tomography techniques. The circuits in our protocols require at most two-copy
measurements with uncontrolled Hamiltonian simulation. We show that the
proposed protocols enhance sample efficiency and reduce the number of
measurement circuits by an order of one or two with respect to the number of
qubits across a range of scenarios.

</details>


### [347] [Macroscopic entanglement between localized domain walls inside a cavity](https://arxiv.org/abs/2508.03450)
*Rahul Gupta,Huaiyang Yuan,Himadri Shekhar Dhar*

Main category: quant-ph

TL;DR: Stable entanglement between magnetic domain walls achieved using optomechanics in a chiral optical cavity, tunable and robust at higher temperatures.


<details>
  <summary>Details</summary>
Motivation: To achieve stable and tunable entanglement between macroscopic domain walls at temperatures beyond the milli-Kelvin range.

Method: The entanglement is mediated by the effective optomechanical interaction between cavity photons and the collective modes of the pinned domain walls. Control over pinning potential and optical driving frequency allows for robust, steady-state entanglement.

Result: Stable and tunable entanglement between two localized Bloch domain walls is generated, surviving beyond the milli-Kelvin temperature range due to optomechanical interaction and controlled parameters.

Conclusion: The proposed scheme enables the generation of stable and tunable entanglement between two localized Bloch domain walls in nanomagnetic strips within a chiral optical cavity.

Abstract: We present a scheme for generating stable and tunable entanglement between
two localized Bloch domain walls in nanomagnetic strips kept inside a chiral
optical cavity. The entanglement is mediated by the effective optomechanical
interaction between the cavity photons and the two macroscopic, collective
modes of the pinned domain walls. By controlling the pinning potential and
optical driving frequency, the robust, steady-state entanglement between the
two macroscopic domain walls can survive beyond the typical milli-Kelvin
temperature range.

</details>


### [348] [Coherent heat exchange in a prethermalizing open quantum system](https://arxiv.org/abs/2508.03193)
*Simone Artini,Mauro Paternostro,Salvatore Lorenzo*

Main category: quant-ph

TL;DR: 本研究利用量子随机热力学和EPM方案，研究了量子相干性对预热相中热交换和熵产的影响，并与TPM方案进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究量子相干性对初始状态的能量本征基在与浴的能量交换过程中的影响，以及它们对热交换涨落定理所量化的熵产的贡献。

Method: 使用量子随机热力学框架，通过端点测量（EPM）方案研究了一个简单的模型，该模型展示了一个预热相（即完全热化之前出现的亚稳态）。

Result: EPM方案考虑了初始量子相干性在非平衡过程产生的能量交换统计中的作用，并与未能捕捉此类量子效应的TPM方案进行了比较。

Conclusion: 与广泛使用的两点测量（TPM）方案相比，端点测量（EPM）方案可以更好地解释量子相干性对热交换和熵产生过程的影响。

Abstract: We investigate a simple model exhibiting a prethermal phase, i.e. a
metastable state that emerges before full thermalization, through the framework
of quantum stochastic thermodynamics. We explore the effects of quantum
coherence in the energy eigenbasis of the initial state of the system on the
process of heat exchange with a bath, and their contribution to entropy
production as quantified by a heat-exchange fluctuation theorem. Such relation
is derived using the End-Point Measurement (EPM) scheme, a protocol that
accounts for initial quantum coherence in the statistics of energy exchanges
resulting from a non-equilibrium process. We compare these results with those
obtained from the widely used Two-Point Measurement (TPM) scheme which, by
construction, fails to capture such quantum effects.

</details>


### [349] [Thermodynamic Signature of Logical Depth in Quantum Circuits](https://arxiv.org/abs/2508.03203)
*Issam Ibnouhsein*

Main category: quant-ph

TL;DR: 量子电路的逻辑深度（一种衡量分支结构引起环境熵流的指标）可以通过实验测量，这对于量子计算的设计和验证具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索量子电路的内部逻辑结构如何影响其在退相干过程中的热力学表现，并提出一种量化这种影响的方法。

Method: 通过引入一个量化了在与环境交互过程中熵积累的“逻辑深度”因子 $L_d$，来捕获这种效应。研究通过对两个4分支量子电路进行详细分析来验证该框架，并证明了条件与均匀结构相比，具有 $L_d$ 约等于1.615的更高熵产生。

Result: 研究结果显示，量子电路的逻辑深度是物理上可测量的量，对于电路设计、编译策略和验证协议具有潜在影响。

Conclusion: 本研究结果表明，量子电路的内部逻辑结构在渐进退相干下会留下独特的热力学特征。通过比较深度、条件分支电路与浅层、均匀电路，并在控制整体停机概率和物理资源的情况下，研究证明分支结构会引起更大的熵流向环境。

Abstract: We demonstrate that the internal logical structure of a quantum circuit can
leave a distinct thermodynamic signature under progressive decoherence. By
comparing deep, conditionally branching circuits with shallow, uniform
counterparts-while controlling for overall halting probability and physical
resources-we show that branching architectures induce greater entropy flow into
the environment. This effect is captured by a logical depth factor $L_d$, which
quantifies entropy accumulation during environmental interactions. We validate
our framework through detailed analysis of two 4-branch quantum circuits,
demonstrating greater entropy production with $L_d \approx 1.615$ for
conditional versus uniform architectures. An ancilla-based experimental
protocol using controlled-phase gates provides a concrete pathway for detecting
these thermodynamic signatures on current quantum platforms. Our results
establish logical depth as a physically measurable quantity with implications
for circuit design, compilation strategies, and verification protocols.

</details>


### [350] [A Fully-integrated Diamond Nitrogen-Vacancy Magnetometer with Nanotesla Sensitivity](https://arxiv.org/abs/2508.03237)
*Yulin Dai,Wenhui Tian,Qing liu,Bao Chen,Yushan Liu,Qidi Hu,Zheng Ma,Yunpeng Zhai,Haodong Wang,Ying Dong,Nanyang Xu*

Main category: quant-ph

TL;DR: 集成式 DNV 磁力计的灵敏度为 2.14 nT/sqrt{Hz}。


<details>
  <summary>Details</summary>
Motivation: 集成所有控制设备到紧凑型 DNV 磁力计是一个挑战，这限制了移动 DNV 磁力计的灵敏度。

Method: 通过集成高功率激光器、锁相放大器和数字调制微波源，成功解决了将所有控制设备集成到紧凑型 DNV 磁力计中的挑战。

Result: 开发了一种完全集成的 DNV 磁力计，尺寸约为 13 厘米 x 26 厘米，最佳灵敏度为 2.14 nT/sqrt{Hz}，可与商业设备媲美。

Conclusion: 这项工作为在经济高效、移动无人机中使用 DNV 磁力测量铺平了道路，从而促进了广泛的实际应用。

Abstract: Ensemble diamond nitrogen-vacancy (DNV) centers have emerged as a promising
platform for precise earth-field vector magnetic sensing, particularly in
applications that require high mobility. Nevertheless, integrating all control
utilities into a compact form has proven challenging, thus far limiting the
sensitivity of mobile DNV magnetometers to the uT-level. This study introduces
a fully integrated DNV magnetometer that encompasses all the essential
components typically found in traditional platforms, while maintaining compact
dimensions of approximately 13 cm * 26 cm. In contrast to previous efforts, we
successfully address these challenges by integrating a high-power laser, a
lock-in amplifier, and a digitally-modulated microwave source. These home-made
components show comparable performance with commercial devices under our
circumstance, resulting in an optimal sensitivity of 2.14 nT/sqrt{Hz}. The
limitations in this system as well as possible future improvements are
discussed. This work paves the way for the use of DNV magnetometry in
cost-effective, mobile unmanned aerial vehicles, facilitating a wide range of
practical applications.

</details>


### [351] [Characterizing noisy quantum computation with imperfectly addressed errors](https://arxiv.org/abs/2508.03261)
*Riddhi S. Gupta,Salini Karuvade,Kerstin Beer,Laura J. Henderson,Sally Shrapnel*

Main category: quant-ph

TL;DR: 该研究提供了一种分析噪声影响量子计算纠错协议的新方法，通过分析奇异谱分布来诊断何时可以信任噪声量子计算机的输出。


<details>
  <summary>Details</summary>
Motivation: 量子计算机中的噪声会影响协议性能，现有的错误处理方法可能因噪声违反关键假设而失效。然而，目前缺乏在实际操作条件下表征这些故障的工具，例如，暴力模拟无法完全描述噪声如何变换量子希尔伯特空间中的状态空间。

Method: 提出了一种新的理论框架，将受现实噪声影响的量子计算与随机超级算子集合相关联，并研究该集合上的本征和奇异谱分布。利用矩阵切尔诺夫浓度来表征随机复矩阵的奇异值。

Result: 研究发现，奇异谱分布取决于噪声违反纠错和错误缓解协议关键假设的方式。该框架可以应用于理解量子计算的限制行为，例如为特定量子马尔可夫过程建立谱隙和弛豫时间。

Conclusion: 该研究提出了一种新的理论框架，利用矩阵切尔诺夫浓度来分析随机复矩阵的奇异值，以表征量子计算中不完善纠错和错误缓解措施的效果。研究发现，奇异谱分布取决于噪声违反协议关键假设的方式。最后，讨论了该框架在理解量子计算的限制行为方面的潜在应用，例如为特定量子马尔可夫过程建立谱隙和弛豫时间。

Abstract: Quantum protocols on hardware are subject to noise that prohibits
performance. Protocols for addressing errors, such as error correction or error
mitigation, may fail to combat errors in quantum computation if noise violates
critical assumptions required for these protocols to be effective. However,
tools for characterizing such failures in realistic operating conditions are
limited. For example, while brute force simulations may be used to characterize
the impact of such failures on a handful of input states, such simulations lack
a complete description for how noise transforms state-spaces in the full
quantum Hilbert space. In this work, we associate quantum computation subject
to realistic noise to an ensemble of random superoperators and study the eigen-
and singular spectral distributions over this ensemble. We propose a new
theoretical framework to characterize singular values of random complex
matrices using matrix Chernoff concentration. Using our framework, we analyze
imperfectly addressed errors in error mitigation and error correction. We find
that distributions of singular spectra depend on how noise violates critical
assumptions of these protocols. Finally, we quantitatively discuss how our work
may be applied to understanding limiting behavior of quantum computation, such
as establishing spectral gaps and relaxation times for specific families of
quantum Markov processes. Our work paves the way for new tools to diagnose when
to trust the output of noisy quantum computers.

</details>


### [352] [Frequency subspace encoding for multiplexed quantum secret sharing](https://arxiv.org/abs/2508.03295)
*Meritxell Cabrejo-Ponce,Christopher Spiess,Carlos Sevilla-Gutiérrez,Fabian Steinlechner*

Main category: quant-ph

TL;DR: A new quantum secret sharing protocol uses frequency correlations from a single source to enable multiple users, improving scalability for wavelength-multiplexed networks.


<details>
  <summary>Details</summary>
Motivation: To overcome the scalability limitations of previous QSS implementations that encoded phase across the entire source bandwidth, hindering wavelength multiplexing.

Method: Quantum secret sharing using frequency correlations and frequency-dependent phase modulation on broadband polarization-entangled photon pairs.

Result: Demonstrated state fidelities of at least 90% for a channel pair on the 200 GHz ITU grid, with the potential to scale to over 40 frequency bins using dense-wavelength division multiplexed filters. This approach eliminates the need for multiple sources, providing a resource-efficient path for multi-user secret sharing in wavelength-multiplexed networks.

Conclusion: The paper presents a resource-efficient approach to multi-user quantum secret sharing (QSS) using frequency correlations, enabling multiple independent QSS sessions from a single source by leveraging frequency-dependent phase modulation on broadband polarization-entangled photon pairs. This method overcomes the limitations of previous implementations by allowing scalability via wavelength multiplexing, achieving state fidelities of at least 90% for a 200 GHz channel spacing, with potential for over 40 channels.

Abstract: Quantum secret sharing (QSS) is a multi-party quantum communication protocol
that can be realized with bipartite entanglement and relative phase encoding.
Previous implementations typically encoded the phase in the pump, applying it
across the entire source bandwidth, thereby limiting scalability via wavelength
multiplexing. In contrast, we present a variant of the standard QSS protocol
that leverages frequency correlations to connect multiple users with a single
source. The secret owner, who has access to the source, encodes classical
information by applying frequency-dependent phase modulation to a broadband
polarization-entangled photon pair. Each frequency channel therefore provides
an independent QSS session among the secret owner and a pair of users. We
demonstrate state fidelities of at least 90% for a channel pair of the 200 GHz
ITU grid, which could be extended to more than 40 frequency bins with adequate
dense-wavelength division multiplexed filters. Our results provide a
resource-efficient path toward multi-user secret sharing over
wavelength-multiplexed networks, eliminating the need for multiple two-photon
or multi-photon sources.

</details>


### [353] [Coherent phase control of two-color continuous variable entangled light](https://arxiv.org/abs/2508.03303)
*Andrea Grimaldi,Valeriy Novikov,Túlio Brito Brasil,Eugene Simon Polzik*

Main category: quant-ph

TL;DR: 通过相干控制技术稳定和表征了双色EPR态，实现了9分贝的双模压缩，为量子网络和量子计量学提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 连续变量爱因斯坦-波多黎斯基-罗森（EPR）态是安全量子通信和分布式量子传感的资源。

Method: 提出了一种对由频率简并光学参量振荡器产生的双色EPR态进行相干控制的技术，实现了对分离200纳米的两个EPR量子场的零星检测的鲁棒控制。

Result: 该控制方案可用于稳定和表征双色光的强纠缠态，在声频范围内显示出9分贝的双模压缩。

Conclusion: 该技术为量子网络和量子计量学提供了宝贵的工具。

Abstract: A continuous variable Einstein-Podolsky-Rosen (EPR) state is a resource for
secure quantum communication and distributed quantum sensing. Here we present a
technique for coherent control of the two-color EPR state generated by a
frequency nondegenerate optical parametric oscillator. The scheme allows for
robust control of the homodyne detection of each of the two EPR quantum fields
separated by 200 nanometers. We apply our control scheme to stabilize and
characterize a strong entangled state of two-color light displaying 9 dB of
two-mode squeezing in the acoustic frequency range, making it a valuable tool
for quantum networking and quantum metrology.

</details>


### [354] [Detector Correlations and Null Tests of the Coherent State Hypothesis](https://arxiv.org/abs/2508.03367)
*Sreenath K. Manikandan,Frank Wilczek*

Main category: quant-ph

TL;DR: 该研究提出了一种新的方法来检验相干态假设，该方法不受量子噪声的影响，并且可以揭示辐射场的其他特性。


<details>
  <summary>Details</summary>
Motivation: 为了提出一种不受真空（量子）噪声影响的、检验相干态假设的简单方法。

Method: 讨论了两个谐振探测器之间相关性的统计特性。

Result: 证明了该方法可以揭示辐射场的其他方面，例如通过适当的探测策略揭示数或相位上的压缩。

Conclusion: 该研究讨论了两个谐振探测器之间相关性的统计特性，并提出这可以作为检验相干态假设的一种简单方法，且不受真空（量子）噪声的影响。

Abstract: We discuss the statistics of correlations between two resonant detectors. We
show that this allows simple null tests of the coherent state hypothesis, free
of vacuum (quantum) noise. Complementary aspects of the radiation field, {\it
e.g.}, squeezing in number or phase, can be revealed through appropriate
detection strategies.

</details>


### [355] [Quantum Neural Network applications to Protein Binding Affinity Predictions](https://arxiv.org/abs/2508.03446)
*Erico Souza Teixeira,Lucas Barros Fernandes,Yara Rodrigues Inácio*

Main category: quant-ph

TL;DR: 本研究探索了使用量子神经网络（QNN）预测蛋白质结合能的可行性，并提出了三十种QNN变体。研究发现，与经典模型相比，量子模型在某些情况下准确性更高，但训练时间显著缩短。


<details>
  <summary>Details</summary>
Motivation: 为了研究量子神经网络（QNN）在预测蛋白质结合能方面的潜力，本研究探索了QNN在此任务上的可行性。

Method: 本研究提出了三十种基于多层感知器的量子神经网络（QNN）变体，这些变体跨越三种不同的架构，并结合了十种不同的量子电路来配置其量子层。研究将这些量子模型的性能与最先进的经典多层感知器人工神经网络进行了比较，评估了准确性和训练时间。

Result: 量子模型在其中一个未见过的数据集上实现了约20%的更高准确性，但在其他数据集上的准确性较低。量子模型表现出了比经典模型低几个数量级的训练时间。

Conclusion: 虽然量子模型在其中一个未见过的数据集上实现了约20%的更高准确性，但其在其他数据集上的准确性较低。然而，量子模型表现出了比经典模型低几个数量级的训练时间，这凸显了它们在高效预测蛋白质结合能方面的潜力。

Abstract: Binding energy is a fundamental thermodynamic property that governs molecular
interactions, playing a crucial role in fields such as healthcare and the
natural sciences. It is particularly relevant in drug development, vaccine
design, and other biomedical applications. Over the years, various methods have
been developed to estimate protein binding energy, ranging from experimental
techniques to computational approaches, with machine learning making
significant contributions to this field. Although classical computing has
demonstrated strong results in constructing predictive models, the variation of
quantum computing for machine learning has emerged as a promising alternative.
Quantum neural networks (QNNs) have gained traction as a research focus,
raising the question of their potential advantages in predicting binding
energies. To investigate this potential, this study explored the feasibility of
QNNs for this task by proposing thirty variations of multilayer
perceptron-based quantum neural networks. These variations span three distinct
architectures, each incorporating ten different quantum circuits to configure
their quantum layers. The performance of these quantum models was compared with
that of a state-of-the-art classical multilayer perceptron-based artificial
neural network, evaluating both accuracy and training time. A primary dataset
was used for training, while two additional datasets containing entirely unseen
samples were employed for testing. Results indicate that the quantum models
achieved approximately 20% higher accuracy on one unseen dataset, although
their accuracy was lower on the other datasets. Notably, quantum models
exhibited training times several orders of magnitude shorter than their
classical counterparts, highlighting their potential for efficient protein
binding energy prediction.

</details>


### [356] [Atom-Induced Field Squeezing Predicted by Magnus Expanding the Jaynes-Cummings Model for a Two-Level Atom](https://arxiv.org/abs/2508.03506)
*Phoenix M. M. Paing*

Main category: quant-ph

TL;DR: Magnus expansion applied to Jaynes-Cummings Model reveals atom-induced light squeezing, opening doors for nonclassical state engineering in simple systems.


<details>
  <summary>Details</summary>
Motivation: To find the term involving the squeezing of light beyond the Rotating Wave Approximation and explore systematic frameworks for atom-induced squeezing.

Method: Performing up to the second-order Magnus expansion on the Jaynes-Cummings Model Hamiltonian.

Result: Identified the term involving light squeezing beyond the Rotating Wave Approximation using the Magnus expansion.

Conclusion: The Magnus expansion offers a systematic way to capture atom-induced squeezing effects in light-matter systems, suggesting new possibilities for creating nonclassical states without complex setups.

Abstract: By performing up to the second-order Magnus expansion on the Jaynes-Cummings
Model Hamiltonian governing the interaction of a two-level atom and a single
cavity mode electromagnetic field, we find the term involving the squeezing of
light beyond the Rotating Wave Approximation. Our results demonstrate that the
Magnus expansion provides a systematic framework to capture atom-induced
squeezing effects. These findings suggest new avenues for engineering
nonclassical states in simple light-matter systems without requiring
multi-level structures or strong nonlinear media.

</details>


### [357] [Entanglement Detection Beyond Local Bound with Coarse Calibrated measurements](https://arxiv.org/abs/2508.03525)
*Liang-Liang Sun,Yong-Shun Song,Sixia Yu*

Main category: quant-ph

TL;DR: 本研究提出了一种加强贝尔不等式的方法，利用粗略校准的测量设备和结构函数来更有效地检测纠缠，特别是在多方系统和部分信息可用的情况下。


<details>
  <summary>Details</summary>
Motivation: 贝尔检验是区分量子理论和局域隐变量模型以及检测纠缠的常用工具。本研究的目的是提出一种更有效的方法来加强贝尔不等式，从而提高纠缠检测的效率，尤其是在测量设备仅粗略校准的情况下。

Method: 该研究系统性地加强了贝尔不等式，特别是以Mermin-Klyshko-Bell不等式为例，通过考虑测量设备的非定域性而非精确的量子表征。对于二方和三方系统，研究推导了可分离态和一般态的上限之间的权衡关系，并提出了利用结构函数来优化纠缠检测。此外，还加强了n方贝尔不等式，以检测具有真正多方纠缠等多种纠缠结构的状态。最后，利用Navascues-Pironio-Acín层级检验，即使在某些局部相关性存在的情况下，也能检测出纠缠。

Result: 研究为二方和三方系统推导了可分离态和一般态的上限之间的权衡关系，并提出了优化纠缠检测的结构函数。此外，还加强了n方贝尔不等式，能够检测具有多种纠缠结构（如真正多方纠缠）的状态。该方法还展示了如何在部分测量设备可表征的情况下，通过利用Navascues-Pironio-Acín层级检验来检测纠缠。

Conclusion: 该研究提出了一种系统性的方法来加强贝尔不等式，以实现更有效的纠缠检测。通过考虑粗略校准但能产生非定域相关性的测量设备，并利用Navascues-Pironio-Acín层级检验，即使在仅部分测量设备可表征的情况下，也能检测出纠缠。

Abstract: Bell's test, initially devised to distinguish quantum theory from local
hidden variable models through violations of local bounds, is also a common
tool for detecting entanglement. For this purpose, one can assume the quantum
description of devices and use available information to strengthen the bound
for separable states, which may go beyond the local bound, enabling more
efficient entanglement detection. Here we present a systematic approach for
strengthening Bell inequalities for qubit systems, using Mermin-Klyshko-Bell
inequalities as examples, by considering measurement devices that are coarsely
calibrated only by their ability to generate nonlocal correlations without
requiring precise quantum characterization. In the case of bipartite and
tripartite systems, we derive trade-offs between upper bounds for separable
states and general states in terms of structure functions to optimize the
entanglement detection. We then strengthen n-partite Bell inequalities for the
detection of states exhibiting a diversity of entanglement structures such as
genuine multipartite entanglement. For general Bell scenarios with some
measurements characterized, we demonstrate that entanglement can also be
detected with some local correlations by exploiting the
Navascu\'es-Pironio-Ac\'in hierarchy of tests.

</details>


### [358] [Stabilizer Rényi Entropy for Translation-Invariant Matrix Product States](https://arxiv.org/abs/2508.03534)
*Lei-Yi-Nan Liu,Su Yi,Jian Cui*

Main category: quant-ph

TL;DR: 本研究提出了一种计算量子多体系统中稳定器Rényi熵（SRE）密度的新方法，并发现了魔法与纠缠之间的联系。


<details>
  <summary>Details</summary>
Motivation: 稳定器Rényi熵（SRE）提供了一种可处理的魔法量度，避免了传统方法的复杂性。

Method: 我们推导了代表性状态的精确表达式，并引入了一种名为bond-DMRG的数值稳定算法来计算无限系统中的SRE密度。

Result: 我们获得了具有一维伊辛模型基态的高精度SRE密度。我们还分析了非局域SRE密度，并证明了两站点相互SRE在注入式MPS中渐近消失。

Conclusion: 本研究为提取量子多体系统中SRE密度引入了强大的方法，并揭示了魔法和纠缠之间基本的联系，为它们之间相互作用的深入理论研究铺平了道路。

Abstract: Magic, capturing the deviation of a quantum state from the stabilizer
formalism, is a key resource underpinning the quantum advantage. The recently
introduced stabilizer R\'enyi entropy (SRE) offers a tractable measure of
magic, avoiding the complexity of conventional methods. We study SRE in
translation-invariant matrix product states (MPS), deriving exact expressions
for representative states and introducing a numerically stable algorithm, named
bond-DMRG, to compute the SRE density in infinite systems. Applying this
method, we obtain high-precision SRE densities for the ground state of the
one-dimensional Ising model. We also analyze non-local SRE density, showing it
is bounded by a universal function of entanglement entropy, and further prove
that two-site mutual SRE vanishes asymptotically in injective MPS. Our work not
only introduces a powerful method for extracting the SRE density in quantum
many-body systems, but also numerically reveals a fundamental connection
between magic and entanglement, thereby paving the way for deeper theoretical
investigations into their interplay.

</details>


### [359] [Optimal Quantum $(r,δ)$-Locally Repairable Codes From Matrix-Product Codes](https://arxiv.org/abs/2508.03597)
*Meng Cao,Kun Zhou*

Main category: quant-ph

TL;DR: This paper explores optimal quantum (r,δ)-LRCs using matrix-product codes, providing conditions for optimality and constructing five new families of codes.


<details>
  <summary>Details</summary>
Motivation: The paper aims to study optimal quantum (r,δ)-LRCs from matrix-product (MP) codes, providing constructions and characterizations.

Method: The study utilized matrix-product (MP) codes and analyzed their properties, including nested and non-nested constituent codes, as well as Hermitian dual-containing and Euclidean dual-containing MP codes.

Result: Five infinite families of optimal quantum (r,δ)-LRCs with flexible parameters were presented.

Conclusion: We established a necessary and sufficient condition for an MP code to be an optimal quantum (r,δ)-LRC and presented five infinite families of such codes.

Abstract: This paper studies optimal quantum $(r,\delta)$-LRCs from matrix-product (MP)
codes. We establish a necessary and sufficient condition for an MP code to be
an optimal $(r,\delta)$-LRC. Based on this, we present a characterization for
optimal quantum $(r,\delta)$-LRCs from MP codes with nested constituent codes,
and also study optimal quantum $(r,\delta)$-LRCs constructed from MP codes with
non-nested constituent codes. Through Hermitian dual-containing and Euclidean
dual-containing MP codes, we present five infinite families of optimal quantum
$(r,\delta)$-LRCs with flexible parameters.

</details>


### [360] [Maximally non-projective measurements are not always symmetric informationally complete](https://arxiv.org/abs/2508.03652)
*Gabriele Cobucci,Raphael Brinster,Shishir Khandelwal,Hermann Kampermann,Dagmar Bruß,Nikolai Wyderka,Armin Tavakoli*

Main category: quant-ph

TL;DR: This paper shows that SIC-POVMs aren't always the most non-projective measurements in systems larger than qubits. They developed a new method to find out how well non-projective measurements can be simulated using simpler measurements.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand how accurately projective measurements and classical processing can simulate the most general notion of measurements, POVMs, and investigates the properties of SIC-POVMs in this context.

Method: The paper proposes a semidefinite programming criterion to detect genuinely non-projective measurements and uses this to determine quantitative simulation thresholds for generic POVMs.

Result: Beyond qubit systems, the SIC property is not generally associated with the most non-projective measurement. The proposed method allows for quantitative simulation thresholds for generic POVMs and suggests a conjecture regarding the most strongly non-projective measurements in qutrit and ququart systems.

Conclusion: SIC-POVMs (Symmetric Informationally Complete Positive Operator-valued Measures) are not always the most non-projective measurements beyond qubit systems. A semidefinite programming criterion is proposed to detect genuinely non-projective measurements, allowing for quantitative simulation thresholds for generic POVMs and a conjecture on the most strongly non-projective measurements in qutrit and ququart systems.

Abstract: Whereas standard quantum measurements are projective, the most general notion
of a measurement is represented by positive operator-valued measures (POVMs).
It is therefore natural to consider how accurately an experimenter with access
only to projective measurements and classical processing can simulate POVMs.
The most well-known class of non-projective measurements is called symmetric
informationally complete (SIC). Such measurements are both ubiquitous in the
broader scope of quantum information theory and known to be the most strongly
non-projective measurements in qubit systems. Here, we show that beyond qubit
systems, the SIC property is in general not associated with the most
non-projective measurement. For this, we put forward a semidefinite programming
criterion for detecting genuinely non-projective measurements. This method
allows us to determine quantitative simulability thresholds for generic POVMs
and to put forward a conjecture on which qutrit and ququart measurements that
are most strongly non-projective.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [361] [Mamba-X: An End-to-End Vision Mamba Accelerator for Edge Computing Devices](https://arxiv.org/abs/2508.02977)
*Dongho Yoon,Gungyu Lee,Jaewon Chang,Yunjae Lee,Dongjae Lee,Minsoo Rhu*

Main category: cs.AR

TL;DR: Mamba-X是一种用于Vision Mamba的端到端加速器，通过收缩扫描阵列和混合量化技术解决了边缘设备部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决Vision Mamba在边缘设备部署中因顺序扫描操作而导致的GPU效率低下问题，并降低内存使用量和提高硬件效率。

Method: 提出了一种名为Mamba-X的端到端Vision Mamba加速器，其中包含一个用于最大化并行性和最小化内存流量的收缩扫描阵列，以及一种混合的、硬件友好的量化技术。

Result: Mamba-X 实现了比传统 Vision Mamba 更低的延迟和内存消耗，同时保持了准确性。

Conclusion: Mamba-X通过引入结构化状态空间核和硬件友好的量化技术，实现了端到端的Vision Mamba加速，能够高效部署在边缘设备上。

Abstract: Transformers have proven effective in language modeling but are limited by
high computational and memory demands that grow quadratically with input
sequence length. State space models (SSMs) offer a promising alternative by
reducing attention complexity from $O(L^2)$ to $O(L)$ while also lowering
overall memory consumption. Vision Mamba adapts the SSM approach for computer
vision tasks, achieving lower latency and memory consumption than traditional
transformer models. However, deploying Vision Mamba on edge devices is
challenging due to its sequential scan operations, which hinder GPU efficiency.
We propose Mamba-X, an end-to-end Vision Mamba accelerator that includes a
systolic scan array to maximize parallelism and minimize memory traffic, along
with a hybrid, hardware-friendly quantization technique to reduce memory usage
and improve hardware efficiency without sacrificing accuracy.

</details>


### [362] [Towards Memory Specialization: A Case for Long-Term and Short-Term RAM](https://arxiv.org/abs/2508.02992)
*Peijing Li,Muhammad Shahir Abdurraman,Rachel Cleaveland,Sergey Legtchenko,Philip Levis,Ioan Stefanovici,Thierry Tambe,David Tennenhouse,Caroline Trippel*

Main category: cs.AR

TL;DR: Memory costs are too high because SRAM/DRAM scaling has stopped. This paper suggests using specialized memory types (LtRAM for read-heavy, long-life data; StRAM for temporary, frequently accessed data) instead of traditional memory hierarchies to reduce costs and improve performance, and explores the technology needed to make this happen.


<details>
  <summary>Details</summary>
Motivation: SRAM and DRAM have stopped scaling, leading to memory dominating system cost. This necessitates a new approach to memory architectures to improve efficiency and scalability.

Method: The paper proposes specialized memory architectures with new memory classes (LtRAM and StRAM) that exploit application-specific access patterns, rather than relying on traditional memory hierarchies. It explores underlying device technologies and potential integration into current systems.

Result: The paper identifies critical research challenges for realizing these new memory classes and their integration into future computing systems, aiming for more efficient and scalable solutions.

Conclusion: The paper argues for a paradigm shift towards specialized memory architectures, proposing two new memory classes, LtRAM and StRAM, to address the scaling limitations of SRAM and DRAM and meet future computing demands.

Abstract: Both SRAM and DRAM have stopped scaling: there is no technical roadmap to
reduce their cost (per byte/GB). As a result, memory now dominates system cost.
This paper argues for a paradigm shift from today's simple memory hierarchy
toward specialized memory architectures that exploit application-specific
access patterns. Rather than relying solely on traditional off-chip DRAM and
on-chip SRAM, we envisage memory systems equipped with additional types of
memory whose performance trade-offs benefit workloads through non-hierarchical
optimization. We propose two new memory classes deserving explicit OS support:
long-term RAM (LtRAM) optimized for read-intensive data with long lifetimes,
and short-term RAM (StRAM) designed for transient, frequently-accessed data
with short lifetimes. We explore underlying device technologies that could
implement these classes, including their evolution and their potential
integration into current system designs given emerging workload requirements.
We identify critical research challenges to realize what we believe is a
necessary evolution toward more efficient and scalable computing systems
capable of meeting future demands.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [363] [When are two algorithms the same? Towards addressing Hilbert's 24th problem](https://arxiv.org/abs/2508.02764)
*Konstantin Doubrovinski*

Main category: cs.LO

TL;DR: This paper tackles the question of when two programs are essentially the same, drawing parallels to Hilbert's unposed question about theorem proofs. It uses Recursion Theory and Kolmogorov Complexity as its main tools.


<details>
  <summary>Details</summary>
Motivation: Determine when two theorem proofs are essentially the same, inspired by Hilbert's question and its relation to computer programs.

Method: Recursion Theory, Kolmogorov Complexity

Result: Proposes a minimalistic approach using Recursion Theory and Kolmogorov Complexity to address the question for programs instead of theorem proofs. The specific results are not detailed in the abstract.

Conclusion: Informal

Abstract: The informal question of when two theorem proofs are "essentially the same"
goes back to David Hilbert, who considered adding it (or something largely
equivalent) to his famous list of open problems, but eventually decided to
leave it out. Given that the notion of a formal proof is closely related to
that of a (computer) program, i.e. a recursive function, it may be useful to
ask the same question with regard to programs instead. Here we propose a
minimalistic approach to this question within Recursion Theory, building
heavily on the use of Kolmogorov Complexity.

</details>


### [364] [Intensional FOL over Belnap's Billatice for Strong-AI Robotics](https://arxiv.org/abs/2508.02774)
*Zoran Majkic*

Main category: cs.LO

TL;DR: AGI机器人需要更强的逻辑能力，IFOL是解决此问题的一种方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现能够像人类一样学习、解决问题和规划的AGI（强人工智能）机器人，需要一种能够处理不完全知识和真值排序的逻辑系统，以克服标准二值FOL的局限性。

Method: 提出了一种基于Belnap四值格的IFOL（intensional many-sorted First-order Logic），作为标准一阶逻辑（FOL）的扩展，以解决标准FOL的悖论和处理不完全知识的问题。

Result: 所提出的IFOL扩展了经典二值逻辑，能够处理真值排序和知识排序，为AGI机器人的发展提供了逻辑基础。

Conclusion: AGI机器人需要一种能够处理不完全知识和真值排序的更复杂的逻辑系统，例如基于Belnap的四值格的IFOL。

Abstract: AGI (Strong AI) aims to create intelligent robots that are quasi
indistinguishable from the human mind. Like a child, the AGI robot would have
to learn through input and experiences, constantly progressing and advancing
its abilities over time. The AGI robot would require an intelligence more close
to human's intelligence: it would have a self-aware consciousness that has the
ability to solve problems, learn, and plan. Based on this approach an
Intensional many-sorted First-order Logic (IFOL), as an extension of a standard
FOL with Tarskian's semantics, is proposed in order to avoid the problems of
standard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity
for robots to work with incomplete (unknown) knowledge as well. This is a more
sophisticated version of IFOL with the same syntax but different semantics,
able to deal with truth-ordering and knowledge-ordering as well, based on the
well known Belnap's billatice with four truth-values that extend the set of
classical two truth-values.

</details>


### [365] [Analysis of logics with arithmetic](https://arxiv.org/abs/2508.03574)
*Michael Benedikt,Chia-Hsuan Lu,Tony Tan*

Main category: cs.LO

TL;DR: 本文得到了含有计数与算术的逻辑的有限可满足性问题的精确界限，并为先前结果提供了更简单的证明。


<details>
  <summary>Details</summary>
Motivation: 解决含有计数与算术的逻辑的有限可满足性问题。

Method: 通过提供一些关键的先前结果和这类逻辑的谱的半线性性的更简单的证明，来解决有限可满足性。

Result: 给出了两变量计数逻辑和涉及基数比较的一元公式的复杂度的精确界限，以及包含局部 Presburger 量词的逻辑的有限可满足性。

Conclusion: 本文研究了含有计数与算术的逻辑的有限可满足性问题，得到了两变量计数逻辑和涉及基数比较的一元公式的复杂度的精确界限，以及包含局部 Presburger 量词的逻辑的有限可满足性。

Abstract: We present new results on finite satisfiability of logics with counting and
arithmetic. This includes tight bounds on the complexity for two-variable logic
with counting and cardinality comparisons between unary formulas, and also on
logics with so-called local Presburger quantifiers. In the process, we provide
simpler proofs of some key prior results on finite satisfiability and
semi-linearity of the spectrum for these logics.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [366] [VCNet: Recreating High-Level Visual Cortex Principles for Robust Artificial Vision](https://arxiv.org/abs/2508.02995)
*Brennen A. Hill,Zhang Xinyu,Timothy Putra Prasetio*

Main category: cs.NE

TL;DR: A new network, VCNet, inspired by the primate visual cortex, is more efficient and robust than current models.


<details>
  <summary>Details</summary>
Motivation: To address limitations of current CNNs such as data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial attacks by drawing inspiration from the primate visual system's efficiency and robustness.

Method: VCNet, inspired by the primate visual cortex, utilizes hierarchical processing, dual-stream segregation, and top-down predictive feedback.

Result: VCNet achieved 92.1% accuracy on the Spots-10 dataset and 74.4% on a light field image classification task, outperforming comparable contemporary models.

Conclusion: Integrating neuroscientific principles into network design, like VCNet which emulates the primate visual cortex, can lead to more efficient and robust models, addressing key challenges in machine learning.

Abstract: Despite their success in image classification, modern convolutional neural
networks (CNNs) exhibit fundamental limitations, including data inefficiency,
poor out-of-distribution generalization, and vulnerability to adversarial
perturbations. The primate visual system, in contrast, demonstrates superior
efficiency and robustness, suggesting that its architectural principles may
offer a blueprint for more capable artificial vision systems. This paper
introduces Visual Cortex Network (VCNet), a novel neural network architecture
whose design is informed by the macro-scale organization of the primate visual
cortex. VCNet emulates key biological mechanisms, including hierarchical
processing across distinct cortical areas, dual-stream information segregation,
and top-down predictive feedback. We evaluate VCNet on two specialized
benchmarks: the Spots-10 animal pattern dataset and a light field image
classification task. Our results show that VCNet achieves a classification
accuracy of 92.1\% on Spots-10 and 74.4\% on the light field dataset,
surpassing contemporary models of comparable size. This work demonstrates that
integrating neuroscientific principles into network design can lead to more
efficient and robust models, providing a promising direction for addressing
long-standing challenges in machine learning.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [367] [Low-Communication Resilient Distributed Estimation Algorithm Based on Memory Mechanism](https://arxiv.org/abs/2508.02705)
*Wei Li,Limei Hu,Feng Chen,Ye Yao*

Main category: cs.DC

TL;DR: 本研究提出了一种低通信弹性分布式估计算法，通过信誉节点选择和W-SVDD模型应对网络攻击，并使用事件触发机制优化更新，实验证明该算法在通信成本较低的情况下性能更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决在多任务对抗网络中，受攻击节点或链路会阻碍分布式算法中未知参数的准确估计这一挑战。

Method: 提出了一种基于信誉的节点选择策略，并采用了加权支持向量数据描述（W-SVDD）模型来训练记忆数据，同时引入了事件触发机制以最小化对W-SVDD模型的无效更新。

Result: 所提出的低通信弹性分布式估计算法在面对被攻击节点或链路时，能够通过节点选择策略和W-SVDD模型来提高估计的准确性和鲁棒性，并通过事件触发机制优化模型更新，最终在较低通信成本下实现优于其他算法的性能。

Conclusion: 仿真结果表明，所提出的算法与其它算法相比，在通信成本较低的情况下实现了卓越的性能。

Abstract: In multi-task adversarial networks, the accurate estimation of unknown
parameters in a distributed algorithm is hindered by attacked nodes or links.
To tackle this challenge, this brief proposes a low-communication resilient
distributed estimation algorithm. First, a node selection strategy based on
reputation is introduced that allows nodes to communicate with more reliable
subset of neighbors. Subsequently, to discern trustworthy intermediate
estimates, the Weighted Support Vector Data Description (W-SVDD) model is
employed to train the memory data. This trained model contributes to reinforce
the resilience of the distributed estimation process against the impact of
attacked nodes or links. Additionally, an event-triggered mechanism is
introduced to minimize ineffective updates to the W-SVDD model, and a suitable
threshold is derived based on assumptions. The convergence of the algorithm is
analyzed. Finally, simulation results demonstrate that the proposed algorithm
achieves superior performance with less communication cost compared to other
algorithms.

</details>


### [368] [A DataOps Toolbox Enabling Continuous Semantic Integration of Devices for Edge-Cloud AI Applications](https://arxiv.org/abs/2508.02708)
*Mario Scrocca,Marco Grassi,Alessio Carenini,Jean-Paul Calbimonte,Darko Anicic,Irene Celino*

Main category: cs.DC

TL;DR: A DataOps toolbox using Semantic Web and low-code is presented to enable collaboration between diverse devices (edge to cloud) for AI applications. It ensures data interoperability across different formats and semantics, demonstrated through three real-world use cases.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of identifying and configuring collaborating devices in complex, AI-based application environments that span from edge to cloud, which is relevant in scenarios like industrial shopfloors, road infrastructures, and healthcare therapies.

Method: The paper discusses the design and implementation of a DataOps toolbox using Semantic Web technologies and a low-code mechanism to address data interoperability requirements for AI-based applications spanning edge to cloud environments. It employs a continuous semantic integration approach to handle diverse devices, data formats, semantics, and communication interfaces.

Result: The paper presents the application of the toolbox to three use cases, detailing the implemented DataOps pipelines and their success in ensuring interoperability for both static information and runtime data exchanges. It also discusses the results from piloting activities and lessons learned.

Conclusion: The paper successfully applied the DataOps toolbox to three use cases, demonstrating its ability to guarantee interoperability of static nodes' information and runtime data exchanges.

Abstract: The implementation of AI-based applications in complex environments often
requires the collaboration of several devices spanning from edge to cloud.
Identifying the required devices and configuring them to collaborate is a
challenge relevant to different scenarios, like industrial shopfloors, road
infrastructures, and healthcare therapies. We discuss the design and
implementation of a DataOps toolbox leveraging Semantic Web technologies and a
low-code mechanism to address heterogeneous data interoperability requirements
in the development of such applications. The toolbox supports a continuous
semantic integration approach to tackle various types of devices, data formats,
and semantics, as well as different communication interfaces. The paper
presents the application of the toolbox to three use cases from different
domains, the DataOps pipelines implemented, and how they guarantee
interoperability of static nodes' information and runtime data exchanges.
Finally, we discuss the results from the piloting activities in the use cases
and the lessons learned.

</details>


### [369] [PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows](https://arxiv.org/abs/2508.02866)
*Renan Souza,Amal Gueroudji,Stephen DeWitt,Daniel Rosendo,Tirthankar Ghosal,Robert Ross,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: PROV-AGENT 是一个为 AI 代理工作流设计的新的证据模型，它扩展了 W3C PROV 并利用 MCP 来集成代理交互。它包括一个捕获代理证据的系统，并已在边缘、云和 HPC 环境中进行了评估，以支持证据查询和代理可靠性分析。


<details>
  <summary>Details</summary>
Motivation: AI 代理在复杂、大规模的工作流中可能产生幻觉或错误推理，因此需要细粒度的证据来链接代理决策、其端到端上下文和下游影响，以确保透明度、可追溯性、可重现性和可靠性。

Method: 提出了一种针对代理工作流量身定制的证据模型，一个近乎实时的开源系统来捕获代理证据，以及跨边缘、云和 HPC 环境的跨设施评估。

Result: 该模型支持关键的证据查询和代理可靠性分析。

Conclusion: PROV-AGENT 扩展了 W3C PROV，并利用模型上下文协议 (MCP) 将代理交互集成到端到端工作流证据中，以支持代理工作流的细粒度证据。

Abstract: Foundation models, such as Large Language Models (LLMs), are increasingly
used as core components of AI agents in complex, large-scale workflows across
federated and heterogeneous environments. In agentic workflows, autonomous
agents plan tasks, interact with humans and peers, and shape scientific
outcomes. This makes transparency, traceability, reproducibility, and
reliability essential. However, AI-based agents can hallucinate or reason
incorrectly, and their decisions may propagate errors through the workflow,
especially when one agent's output feeds into another's input. Therefore,
fine-grained provenance is essential to link agent decisions, their end-to-end
context, and downstream impacts. While provenance techniques have long
supported reproducibility and workflow data understanding, they fail to capture
and relate agent-centric metadata (prompts, responses, and decisions) with the
rest of the workflow. In this paper, we introduce PROV-AGENT, a provenance
model that extends W3C PROV and leverages the Model Context Protocol (MCP) to
integrate agent interactions into end-to-end workflow provenance. Our
contributions include: (1) a provenance model tailored for agentic workflows,
(2) a near real-time, open-source system for capturing agentic provenance, and
(3) a cross-facility evaluation spanning edge, cloud, and HPC environments,
demonstrating support for critical provenance queries and agent reliability
analysis.

</details>


### [370] [Optimal Simultaneous Byzantine Agreement, Common Knowledge and Limited Information Exchange](https://arxiv.org/abs/2508.03418)
*Ron van der Meyden*

Main category: cs.DC

TL;DR: 本文重新审视了使用认知逻辑分析分布式算法，并提出了更实用、更优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了开发尽早执行操作的解决方案，使用认知逻辑分析分布式算法通常集中在“完全信息协议”上，这在空间和计算时间方面可能效率低下。本文重新审视了具有“非故障”和“尚未发生故障”这两个概念的区分，这两个概念在文献中存在差异。

Method: 本文重新审视了具有“非故障”和“尚未发生故障”这两个概念的区分，这两个概念在文献中存在差异。之后，文章将展示，当针对给定的故障模型和满足特定条件的信息交换协议实现时，该知识库程序可以提供一个相对于使用相同信息交换的解决方案的最优协议。文章还识别了在某些条件下，该实现也是最优的，但提供的示例表明这并不普遍成立。

Result: 本文首先阐明了关于该问题规范以及表征其解决方案的知识库程序的某些问题。

Conclusion: 当实现满足特定条件的给定故障模型和信息交换协议时，该知识库程序可提供相对于使用相同信息交换的解决方案的最优协议。还确定了该实现最优的条件，但提供的示例表明这并不普遍成立。

Abstract: In order to develop solutions that perform actions as early as possible,
analysis of distributed algorithms using epistemic logic has generally
concentrated on ``full information protocols'', which may be inefficient with
respect to space and computation time. The paper reconsiders the epistemic
analysis of the problem of Simultaneous Byzantine Agreement with respect to
weaker, but more practical, exchanges of information. The paper first clarifies
some issues concerning both the specification of this problem and the knowledge
based program characterizing its solution, concerning the distinction between
the notions of ``nonfaulty'' and ``not yet failed'', on which there are
variances in the literature. It is then shown that, when implemented relative
to a given failure model and an information exchange protocol satisfying
certain conditions, this knowledge based program yields a protocol that is
optimal relative to solutions using the same information exchange. Conditions
are also identified under which this implementation is also an optimum, but an
example is provided that shows this does not hold in general.

</details>


### [371] [Understanding the Landscape of Ampere GPU Memory Errors](https://arxiv.org/abs/2508.03513)
*Zhu Zhu,Yu Sun,Dhatri Parakal,Bo Fang,Steven Farrell,Gregory H. Bauer,Brett Bode,Ian T. Foster,Michael E. Papka,William Gropp,Zhao Zhang,Lishan Yang*

Main category: cs.DC

TL;DR: 在一项针对NVIDIA A100 GPU的研究中，分析了三个超级计算机的数千万小时的GPU日志，比较了错误率和平均无故障时间，为HPC系统的设计和运行提供了见解。


<details>
  <summary>Details</summary>
Motivation: 理解GPU内存错误行为是实现高效可靠的HPC系统的关键一步。

Method: 通过分析跨越6777万个GPU设备小时的错误日志，覆盖了Delta、Polaris和Perlmutter三个超级计算机中的10,693个GPU，对NVIDIA A100 GPU的错误日志进行了大规模跨超级计算机研究，以表征GPU内存可靠性。

Result: 研究比较了错误率和平均无故障时间（MTBE），并强调了三个系统之间共享和不同的错误特征。

Conclusion: 该研究为容错HPC系统设计和运行提供了宝贵的见解，能够更有效地执行HPC应用程序。

Abstract: Graphics Processing Units (GPUs) have become a de facto solution for
accelerating high-performance computing (HPC) applications. Understanding their
memory error behavior is an essential step toward achieving efficient and
reliable HPC systems. In this work, we present a large-scale
cross-supercomputer study to characterize GPU memory reliability, covering
three supercomputers - Delta, Polaris, and Perlmutter - all equipped with
NVIDIA A100 GPUs. We examine error logs spanning 67.77 million GPU device-hours
across 10,693 GPUs. We compare error rates and mean-time-between-errors (MTBE)
and highlight both shared and distinct error characteristics among these three
systems. Based on these observations and analyses, we discuss the implications
and lessons learned, focusing on the reliable operation of supercomputers, the
choice of checkpointing interval, and the comparison of reliability
characteristics with those of previous-generation GPUs. Our characterization
study provides valuable insights into fault-tolerant HPC system design and
operation, enabling more efficient execution of HPC applications.

</details>


### [372] [In-Memory Non-Binary LDPC Decoding](https://arxiv.org/abs/2508.03567)
*Oscar Ferraz,Vitor Silva,Gabriel Falcao*

Main category: cs.DC

TL;DR: A new near-memory non-binary LDPC decoder using the PiM paradigm in UPMEM hardware achieves competitive throughput (76 Mbit/s) compared to edge GPUs, overcoming memory bottlenecks in communication systems.


<details>
  <summary>Details</summary>
Motivation: To address the data movement bottleneck caused by memory technology not keeping pace with arithmetic and logic unit advancements, which affects parallel processing systems. The processing-in-memory (PiM) paradigm is explored as a solution.

Method: The paper presents a novel efficient solution for near-memory non-binary LDPC decoders in the UPMEM system, utilizing thousands of low-complexity processing units for bit-wise and simple arithmetic operations. This is claimed to be the first real hardware PiM-based non-binary LDPC decoder.

Result: The presented PiM-based non-binary LDPC decoders achieve 76 Mbit/s of decoding throughput, showing competitiveness against optimized low-power GPU parallel solutions.

Conclusion: PiM-based non-binary LDPC decoders can achieve 76 Mbit/s of decoding throughput, which is competitive with highly optimized low-power GPU solutions.

Abstract: Low-density parity-check (LDPC) codes are an important feature of several
communication and storage applications, offering a flexible and effective
method for error correction. These codes are computationally complex and
require the exploitation of parallel processing to meet real-time constraints.
As advancements in arithmetic and logic unit technology allowed for higher
performance of computing systems, memory technology has not kept the same pace
of development, creating a data movement bottleneck and affecting parallel
processing systems more dramatically. To alleviate the severity of this
bottleneck, several solutions have been proposed, namely the processing
in-memory (PiM) paradigm that involves the design of compute units to where (or
near) the data is stored, utilizing thousands of low-complexity processing
units to perform out bit-wise and simple arithmetic operations. This paper
presents a novel efficient solution for near-memory non-binary LDPC decoders in
the UPMEM system, for the best of our knowledge the first real hardware
PiM-based non-binary LDPC decoder that is benchmarked against low-power GPU
parallel solutions highly optimized for throughput performance. PiM-based
non-binary LDPC decoders can achieve 76 Mbit/s of decoding throughput, which is
even competitive when compared against implementations running in edge GPUs.

</details>


### [373] [Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling](https://arxiv.org/abs/2508.03611)
*Wei Da,Evangelia Kalyvianaki*

Main category: cs.DC

TL;DR: Block 是一个创新的分布式调度框架，通过利用上下文信息和 LLM 推理的可预测性，显著提高了 LLM 服务框架的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 为了优化大型语言模型服务框架中的实例负载均衡和自动配置，提出了 Block 框架。

Method: Block 是一个完全分布式、无状态且具有预测能力的调度系统，利用 LLM 推理的确定性和可预测性（如主机配置、响应长度和硬件性能）的特征信息，做出基于准确预测指标的调度决策。

Result: 与传统启发式调度器相比，Block 在12个GPU集群上的评估显示，服务容量提高了16.7%，P99尾部延迟降低了49.5%。

Conclusion: Block 在模型服务系统中实现了低开销、高可靠性和高可扩展性，并且在各种模型、工作负载和配置中都表现出一致的性能提升。

Abstract: This paper presents Block, a distributed scheduling framework designed to
optimize load balancing and auto-provisioning across instances in large
language model serving frameworks by leveraging contextual information from
incoming requests. Unlike popular model serving systems that rely on monolithic
and heuristic task schedulers, Block operates as a fully distributed,
stateless, and predictive scheduling system to achieve low overhead,
reliability, and scalability. It leverages the deterministic and predictable
characteristics of LLM inferences, such as host configurations, response
lengths, and hardware performance, to make scheduling decisions based on
accurately predicted metrics. Evaluation on a 12 GPUs cluster shows that Block
significantly outperforms heuristic schedulers, boosting serving capacity by up
to 16.7\% and reducing P99 tail latency by up to 49.5\%. These performance
gains remain consistent across diverse models, workloads and configurations.
Code and data are open-sourced.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [374] [Finding Colorings in One-Sided Expanders](https://arxiv.org/abs/2508.02825)
*Rares-Darius Buhai,Yiding Hua,David Steurer,Andor Vári-Kakas*

Main category: cs.DS

TL;DR: 研究为图着色和独立集问题提供了新的算法和硬度结果，并改进了顶点覆盖问题的近似算法。研究还提出了一种基于矩阵的k着色分层方法，并利用图谱性质来分析问题的复杂性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为单侧扩展器和相关图类中的关键图问题（如图着色和独立集）提供更强的算法保证和理解其计算复杂性。特别是，研究旨在改进现有算法的性能，并为这些问题的NP难性提供新的证据。

Method: 该研究利用图谱性质，特别是负特征值的数量与大于特定阈值的特征值数量之间的关系，来推导算法和硬度结果。研究提出了一种新的k着色分层方法，该方法基于k×k矩阵，类似于约束满足问题的谓词集。通过分析这些矩阵的重复行是否存在，研究证明了相应着色问题的NP难性（当存在重复行时）以及多项式时间可解性（当不存在重复行时）。

Result: 该研究的主要结果包括：1. 提出了一种针对3着色正则单侧扩展器的多项式时间算法，可以找到至少(1/2-o(1))的独立集，或为除o(1)比例顶点外的所有顶点找到一个正确的3着色。2. 为强正则单侧扩展器中的顶点覆盖问题提供了一种高效的1.6667因子近似算法。3. 提出了一种k着色分层方法，并证明了当k×k矩阵有重复行时，相应的着色问题对于单侧扩展器是NP难的（在唯一博弈猜想下）。4. 证明了当k×k矩阵无重复行时，可以在多项式时间内解决相应的着色问题。5. 发现了一个新的图谱性质，即负特征值的数量与大于特定阈值的特征值数量之间存在一种数量关系。

Conclusion: 该研究为单侧扩展器和相关图类中的着色和独立集问题建立了新的算法保证和匹配的硬度结果。具体来说，对于3着色正则单侧扩展器，研究提出了一种多项式时间算法，可以找到至少为1/2-o(1)的独立集，或者为除o(1)比例顶点外的所有顶点找到一个正确的3着色。这比Bafna、Hsieh和Kothari（STOC 2025）的开创性工作有所改进，他们开发了一种能够在此类图中有效找到至少0.01相对大小的独立集的算法。此外，研究还为强正则单侧扩展器中的顶点覆盖问题提供了一种高效的1.6667因子近似算法，优于先前针对某个未指定常数ε>0的(2-ε)因子近似算法。研究还提出了一种基于k×k矩阵的k着色新分层方法，类似于约束满足问题的谓词集。研究证明，当该矩阵存在重复行时，在唯一博弈猜想下，相应的着色问题对于单侧扩展器是NP难的。相反，如果该矩阵不存在重复行，则研究提出的算法可以在多项式时间内解决单侧扩展器上的相应着色问题。

Abstract: We establish new algorithmic guarantees with matching hardness results for
coloring and independent set problems in one-sided expanders and related
classes of graphs. For example, given a $3$-colorable regular one-sided
expander, we compute in polynomial time either an independent set of relative
size at least $1/2-o(1)$ or a proper $3$-coloring for all but an $o(1)$
fraction of the vertices, where $o(1)$ stands for a function that tends to $0$
with the second largest eigenvalue of the normalized adjacency matrix. This
result improves on recent seminal work of Bafna, Hsieh, and Kothari (STOC 2025)
developing an algorithm that efficiently finds independent sets of relative
size at least $0.01$ in such graphs. We also obtain an efficient
$1.6667$-factor approximation algorithm for VERTEX COVER in sufficiently strong
regular one-sided expanders, improving over a previous $(2-\epsilon)$-factor
approximation in such graphs for an unspecified constant $\epsilon>0$.
  We propose a new stratification of $k$-COLORING in terms of $k$-by-$k$
matrices akin to predicate sets for constraint satisfaction problems. We prove
that whenever this matrix has repeated rows, the corresponding coloring problem
is NP-hard for one-sided expanders under the Unique Games Conjecture. On the
other hand, if this matrix has no repeated rows, our algorithms can solve the
corresponding coloring problem on one-sided expanders in polynomial time.
  As starting point for our algorithmic results, we show a property of graph
spectra that, to the best of our knowledge, has not been observed before: The
number of negative eigenvalues smaller than $-\tau$ is at most $O(1/\tau^{2})$
times the number of eigenvalues larger than $\tau^{2}/2$. While this result
allows us to bound the number of eigenvalues bounded away from $0$ in one-sided
spectral expanders, this property alone is insufficient for our algorithmic
results.

</details>


### [375] [Coloring 3-Colorable Graphs with Low Threshold Rank](https://arxiv.org/abs/2508.03093)
*Jun-Ting Hsieh*

Main category: cs.DS

TL;DR: $n$个顶点的$3$-可着色图中找到至少$(rac{1}{2}-O(\varepsilon))n$个顶点的proper $3$-coloring，时间复杂度为$n^{O(r/\varepsilon^2)}$。


<details>
  <summary>Details</summary>
Motivation: 寻找$3$-可着色图中大独立集的问题，特别是与$1$-sided threshold rank的结合。

Method: 该算法基于一个观察：对于proper $3$-colorings的任何分布，如果端点的边际不在任何单一颜色上集中，则边上的相关性必须很大。

Result: 在$n$个顶点的$3$-可着色图中找到至少$(rac{1}{2}-O(\varepsilon))n$个顶点的proper $3$-coloring，其均匀随机游走矩阵最多有$r$个大于$\varepsilon$的特征值，时间复杂度为$n^{O(r/\varepsilon^2)}$。

Conclusion: 该算法在$n$个顶点的$3$-可着色图中找到至少$(rac{1}{2}-O(\varepsilon))n$个顶点的proper $3$-coloring，其均匀随机游走矩阵最多有$r$个大于$\varepsilon$的特征值，时间复杂度为$n^{O(r/\varepsilon^2)}$。此结果是对Bafna、Hsieh和Kothari关于$1$-sided expanders的研究的扩展和改进。

Abstract: We present a new algorithm for finding large independent sets in
$3$-colorable graphs with small $1$-sided threshold rank. Specifically, given
an $n$-vertex $3$-colorable graph whose uniform random walk matrix has at most
$r$ eigenvalues larger than $\varepsilon$, our algorithm finds a proper
$3$-coloring on at least $(\frac{1}{2}-O(\varepsilon))n$ vertices in time
$n^{O(r/\varepsilon^2)}$. This extends and improves upon the result of Bafna,
Hsieh, and Kothari on $1$-sided expanders. Furthermore, an independent work by
Buhai, Hua, Steurer, and V\'ari-Kakas shows that it is UG-hard to properly
$3$-color more than $(\frac{1}{2}+\varepsilon)n$ vertices, thus establishing
the tightness of our result.
  Our proof is short and simple, relying on the observation that for any
distribution over proper $3$-colorings, the correlation across an edge must be
large if the marginals of the endpoints are not concentrated on any single
color. Notably, this property fails for $4$-colorings, which is consistent with
the hardness result of [BHK25] for $4$-colorable $1$-sided expanders.

</details>


### [376] [When is String Reconstruction using de Bruijn Graphs Hard?](https://arxiv.org/abs/2508.03433)
*Ben Bals,Sebastiaan van Krieken,Solon P. Pissis,Leen Stougie,Hilde Verbeek*

Main category: cs.DS

TL;DR: 本研究解决了在德布鲁因图上寻找满足特定位置约束的欧拉路径的问题，提出了比现有方法更快的算法，并将复杂度与约束的质量（由w衡量）联系起来。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在给定约束条件下，从德布鲁因图（de Bruijn graph）重建最佳字符串的问题，该约束由一个将每条边映射到其在欧拉路径中可能出现的位置区间的函数定义。

Method: 我们提出了结合组合学见解的算法，特别是针对德布鲁因图（de Bruijn graphs），并将问题参数化为w（最大区间长度）和k（德布鲁因图的阶数），实现了优于先前算法的指数级改进。

Result: 我们开发了一种针对德布鲁因图的算法，其时间复杂度为O(m * w^(1.5) * 4^w)，其中m是边数，w是最大区间长度。此外，我们还提出了一种参数化为w(log w+1)/(k-1)的改进算法，证明了当区间范围相对于k较小时，该算法的有效性。

Conclusion: 通过结合组合学洞察和参数化方法，我们针对德布鲁因图上的带约束欧拉路径问题提出了新的算法，将计算复杂度与领域知识的质量（由最大区间长度w衡量）联系起来，并显著优于现有技术。

Abstract: The reduction of the fragment assembly problem to (variations of) the
classical Eulerian trail problem [Pevzner et al., PNAS 2001] has led to
remarkable progress in genome assembly. This reduction employs the notion of de
Bruijn graph $G=(V,E)$ of order $k$ over an alphabet $\Sigma$. A single
Eulerian trail in $G$ represents a candidate genome reconstruction. Bernardini
et al. have also introduced the complementary idea in data privacy [ALENEX
2020] based on $z$-anonymity.
  The pressing question is: How hard is it to reconstruct a best string from a
de Bruijn graph given a function that models domain knowledge? Such a function
maps every length-$k$ string to an interval of positions where it may occur in
the reconstructed string. By the above reduction to de Bruijn graphs, the
latter function translates into a function $c$ mapping every edge to an
interval where it may occur in an Eulerian trail. This gives rise to the
following basic problem on graphs: Given an instance $(G,c)$, can we
efficiently compute an Eulerian trail respecting $c$? Hannenhalli et
al.~[CABIOS 1996] formalized this problem and showed that it is NP-complete.
  We focus on parametrization aiming to capture the quality of our domain
knowledge in the complexity. Ben-Dor et al. developed an algorithm to solve the
problem on de Bruijn graphs in $O(m \cdot w^{1.5} 4^{w})$ time, where $m=|E|$
and $w$ is the maximum interval length over all edges. Bumpus and Meeks
[Algorithmica 2023] rediscovered the same algorithm on temporal graphs,
highlighting the relevance of this problem in other contexts. We give
combinatorial insights that lead to exponential-time improvements over the
state-of-the-art. For the important class of de Bruijn graphs, we develop an
algorithm parametrized by $w (\log w+1) /(k-1)$. Our improved algorithm shows
that it is enough when the range of positions is small relative to $k$.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [377] [Learning User Interaction Forces using Vision for a Soft Finger Exosuit](https://arxiv.org/abs/2508.02870)
*Mohamed Irfan Refai,Abdulaziz Y. Alkayas,Anup Teejo Mathew,Federico Renda,Thomas George Thuruthel*

Main category: cs.RO

TL;DR: 提出了一种基于图像和学习的方法，可以准确地从低分辨率灰度图像估计外骨骼的接触力，并能适应未知的形状、驱动水平和视觉噪声，可用于闭环控制。


<details>
  <summary>Details</summary>
Motivation: 可穿戴辅助设备的日益软化，需要对其与人体组织的接口进行建模，以捕捉动态辅助的传输。然而，其非线性和顺应性使得物理建模和嵌入式传感都具有挑战性。

Method: 提出了一种基于图像、基于学习的框架，用于估计手指-外骨骼系统的分布式接触力。使用了SoRoSim工具箱生成了用于训练的各种外骨骼几何和驱动场景数据集。

Result: 该方法能够从低分辨率的灰度图像中准确估计多个接触点的相互作用力，能够泛化到未知的形状和驱动水平，并且在视觉噪声和对比度变化下保持鲁棒性。该模型已集成到反馈控制器中，并可作为闭环控制的替代力传感器。

Conclusion: 该方法可作为一种非侵入性替代方案，用于外骨骼的实时力估计。

Abstract: Wearable assistive devices are increasingly becoming softer. Modelling their
interface with human tissue is necessary to capture transmission of dynamic
assistance. However, their nonlinear and compliant nature makes both physical
modeling and embedded sensing challenging. In this paper, we develop a
image-based, learning-based framework to estimate distributed contact forces
for a finger-exosuit system. We used the SoRoSim toolbox to generate a diverse
dataset of exosuit geometries and actuation scenarios for training. The method
accurately estimated interaction forces across multiple contact locations from
low-resolution grayscale images, was able to generalize to unseen shapes and
actuation levels, and remained robust under visual noise and contrast
variations. We integrated the model into a feedback controller, and found that
the vision-based estimator functions as a surrogate force sensor for
closed-loop control. This approach could be used as a non-intrusive alternative
for real-time force estimation for exosuits.

</details>


### [378] [Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles](https://arxiv.org/abs/2508.02873)
*Rongqian Chen,Jun Kwon,Kefan Wu,Wei-Hsi Chen*

Main category: cs.RO

TL;DR: HASTA 机器人通过实时调整腿部刚度，在不同地面上实现了更高的跳跃效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高垂直跳跃机器人在各种地面条件下的能量效率，通过实时调整腿部刚度。

Method: 通过实验测试和模拟，确定了在给定地面刚度和阻尼条件下，最大化稳定跳跃高度的最佳腿部刚度。

Result: 实验结果支持了可调刚度可以提高能量效率的假设，模拟结果为未来控制器开发提供了参考。

Conclusion: 可调刚度的腿部设计可以提高不同地面条件下的能量效率，软腿更适合软阻尼地面，硬腿更适合硬非阻尼地面。

Abstract: We present the design and implementation of HASTA (Hopper with Adjustable
Stiffness for Terrain Adaptation), a vertical hopping robot with real-time
tunable leg stiffness, aimed at optimizing energy efficiency across various
ground profiles (a pair of ground stiffness and damping conditions). By
adjusting leg stiffness, we aim to maximize apex hopping height, a key metric
for energy-efficient vertical hopping. We hypothesize that softer legs perform
better on soft, damped ground by minimizing penetration and energy loss, while
stiffer legs excel on hard, less damped ground by reducing limb deformation and
energy dissipation. Through experimental tests and simulations, we find the
best leg stiffness within our selection for each combination of ground
stiffness and damping, enabling the robot to achieve maximum steady-state
hopping height with a constant energy input. These results support our
hypothesis that tunable stiffness improves energy-efficient locomotion in
controlled experimental conditions. In addition, the simulation provides
insights that could aid in the future development of controllers for selecting
leg stiffness.

</details>


### [379] [Co-designing Zoomorphic Robot Concepts for Animal Welfare Education](https://arxiv.org/abs/2508.02898)
*Isobel Voysey,Lynne Baillie,Joanne Williams,Michael Herrmann*

Main category: cs.RO

TL;DR: Robots for kids learning about animals should look furry, act naturally, and show emotions via face/tail. Kids and teachers liked different things in workshops, making design tricky but fun activities were created.


<details>
  <summary>Details</summary>
Motivation: The motivation is to leverage customized robots to enhance animal welfare education for children, promoting positive and safe child-animal interactions.

Method: The study utilized Participatory Design workshops with animal welfare educators and children to gather requirements for zoomorphic robots.

Result: Key findings include the importance of negative reactions to undesirable behavior, using facial features and tail for emotional cues, and a natural, furry appearance. Novel participatory design activities for children were also developed.

Conclusion: This paper identifies key requirements for zoomorphic robots in animal welfare education from the perspectives of educators and children, highlighting the importance of robot appearance, behavior, features, and narrative. It also contributes novel participatory design activities for children and reflects on design challenges.

Abstract: Animal welfare education could greatly benefit from customized robots to help
children learn about animals and their behavior, and thereby promote positive,
safe child-animal interactions. To this end, we ran Participatory Design
workshops with animal welfare educators and children to identify key
requirements for zoomorphic robots from their perspectives. Our findings
encompass a zoomorphic robot's appearance, behavior, and features, as well as
concepts for a narrative surrounding the robot. Through comparing and
contrasting the two groups, we find the importance of: negative reactions to
undesirable behavior from children; using the facial features and tail to
provide cues signaling an animal's internal state; and a natural, furry
appearance and texture. We also contribute some novel activities for
Participatory Design with children, including branching storyboards inspired by
thematic apperception tests and interactive narratives, and reflect on some of
the key design challenges of achieving consensus between the groups, despite
much overlap in their design concepts.

</details>


### [380] [Why Evolve When You Can Adapt? Post-Evolution Adaptation of Genetic Memory for On-the-Fly Control](https://arxiv.org/abs/2508.03600)
*Hamze Hammami,Eva Denisa Barbulescu,Talal Shaikh,Mouayad Aldada,Muhammad Saad Munawar*

Main category: cs.RO

TL;DR: 提出了一种将遗传算法与赫布可塑性相结合的机器人控制器，使其能够像人类突触一样动态适应环境变化，并在任务后恢复到初始状态。


<details>
  <summary>Details</summary>
Motivation: 旨在创造一种能够像人类突触一样适应的机器人控制器，能够在实时动态重塑自身以应对不可预见的挑战。

Method: 提出了一种新颖的零样本自适应机制，将标准的遗传算法（GA）控制器与在线赫布可塑性相结合。该方法将基因型作为记忆，赫布更新处理学习，并利用适应度函数作为赫布学习的实时缩放因子，使机器人能够动态调整突触权重。

Result: 验证了该混合 GA-赫布控制器在 e-puck 机器人上的有效性，该机器人在 T 型迷宫导航任务中表现出色，能够应对光照条件和障碍物的变化。

Conclusion: 所提出的混合遗传算法-赫布控制器在 T 型迷宫导航任务中，即使在光照条件和障碍物发生变化的情况下，也能有效地处理动态适应性。

Abstract: Imagine a robot controller with the ability to adapt like human synapses,
dynamically rewiring itself to overcome unforeseen challenges in real time.
This paper proposes a novel zero-shot adaptation mechanism for evolutionary
robotics, merging a standard Genetic Algorithm (GA) controller with online
Hebbian plasticity. Inspired by biological systems, the method separates
learning and memory, with the genotype acting as memory and Hebbian updates
handling learning. In our approach, the fitness function is leveraged as a live
scaling factor for Hebbian learning, enabling the robot's neural controller to
adjust synaptic weights on-the-fly without additional training. This adds a
dynamic adaptive layer that activates only during runtime to handle unexpected
environmental changes. After the task, the robot 'forgets' the temporary
adjustments and reverts to the original weights, preserving core knowledge. We
validate this hybrid GA-Hebbian controller on an e-puck robot in a T-maze
navigation task with changing light conditions and obstacles.

</details>


### [381] [Context-aware Risk Assessment and Its Application in Autonomous Driving](https://arxiv.org/abs/2508.02919)
*Boyang Tian,Weisong Shi*

Main category: cs.RO

TL;DR: CRI是一个轻量级的模块化框架，通过量化方向性风险来提高自动驾驶的安全性，并在实际测试中显著减少了碰撞，同时保持了低开销。


<details>
  <summary>Details</summary>
Motivation: 为了确保自动驾驶的 safety，需要精确的、实时的风险评估和自适应行为。之前的风险估计工作要么输出缺乏可解释性的粗粒度、全局场景级指标，要么提出没有具体集成到自动驾驶系统中的指标，要么仅关注特定的驾驶场景。

Method: CRI框架使用方向感空间划分、混合概率-最大融合策略以及自适应控制策略来量化基于物体运动学和空间关系的方向性风险，并实时调整控制指令。

Result: CRI框架在Bench2Drive基准测试中的220个安全关键场景上进行了评估，与Transfuser++模型结合使用。结果显示，与失败的路线相比，车辆碰撞率降低了19% (p = 0.003)，每公里碰撞率降低了20% (p = 0.004)，综合驾驶得分提高了17% (p = 0.016)，并且在具有非常低的开销（每个决策周期3.6毫秒）的情况下，处罚分数显著降低 (p = 0.013)。

Conclusion: CRI框架显著提高了复杂、高风险环境的 safety 和 robustness，同时保持了模块化和低运行时开销。

Abstract: Ensuring safety in autonomous driving requires precise, real-time risk
assessment and adaptive behavior. Prior work on risk estimation either outputs
coarse, global scene-level metrics lacking interpretability, proposes
indicators without concrete integration into autonomous systems, or focuses
narrowly on specific driving scenarios. We introduce the Context-aware Risk
Index (CRI), a light-weight modular framework that quantifies directional risks
based on object kinematics and spatial relationships, dynamically adjusting
control commands in real time. CRI employs direction-aware spatial partitioning
within a dynamic safety envelope using Responsibility-Sensitive Safety (RSS)
principles, a hybrid probabilistic-max fusion strategy for risk aggregation,
and an adaptive control policy for real-time behavior modulation. We evaluate
CRI on the Bench2Drive benchmark comprising 220 safety-critical scenarios using
a state-of-the-art end-to-end model Transfuser++ on challenging routes. Our
collision-rate metrics show a 19\% reduction (p = 0.003) in vehicle collisions
per failed route, a 20\% reduction (p = 0.004) in collisions per kilometer, a
17\% increase (p = 0.016) in composed driving score, and a statistically
significant reduction in penalty scores (p = 0.013) with very low overhead (3.6
ms per decision cycle). These results demonstrate that CRI substantially
improves safety and robustness in complex, risk-intensive environments while
maintaining modularity and low runtime overhead.

</details>


### [382] [Model-agnostic Meta-learning for Adaptive Gait Phase and Terrain Geometry Estimation with Wearable Soft Sensors](https://arxiv.org/abs/2508.02930)
*Zenan Zhu,Wenxi Chen,Pei-Chun Kao,Janelle Clark,Lily Behnke,Rebecca Kramer-Bottiglio,Holly Yanco,Yan Gu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This letter presents a model-agnostic meta-learning (MAML) based framework
for simultaneous and accurate estimation of human gait phase and terrain
geometry using a small set of fabric-based wearable soft sensors, with
efficient adaptation to unseen subjects and strong generalization across
different subjects and terrains. Compared to rigid alternatives such as
inertial measurement units, fabric-based soft sensors improve comfort but
introduce nonlinearities due to hysteresis, placement error, and fabric
deformation. Moreover, inter-subject and inter-terrain variability, coupled
with limited calibration data in real-world deployments, further complicate
accurate estimation. To address these challenges, the proposed framework
integrates MAML into a deep learning architecture to learn a generalizable
model initialization that captures subject- and terrain-invariant structure.
This initialization enables efficient adaptation (i.e., adaptation with only a
small amount of calibration data and a few fine-tuning steps) to new users,
while maintaining strong generalization (i.e., high estimation accuracy across
subjects and terrains). Experiments on nine participants walking at various
speeds over five terrain conditions demonstrate that the proposed framework
outperforms baseline approaches in estimating gait phase, locomotion mode, and
incline angle, with superior accuracy, adaptation efficiency, and
generalization.

</details>


### [383] [AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed](https://arxiv.org/abs/2508.02947)
*M Tanjid Hasan Tonmoy,Rahath Malladi,Kaustubh Singh,Forsad Al Hossain,Rajesh Gupta,Andrés E. Tejada-Martínez,Tauhidur Rahman*

Main category: cs.RO

TL;DR: 本文提出了一种名为 AeroSafe 的新方法，利用机器人咳嗽模拟器和数字孪生技术来分析室内空气中的气溶胶停留时间，从而提高空气净化系统的效率。该方法通过机器人模拟器训练数字孪生模型，该模型结合了物理模型和机器学习。实验证明该方法比静态空气过滤器放置更有效。


<details>
  <summary>Details</summary>
Motivation: 室内空气质量对居住者的安全和福祉至关重要，尤其是在空气传播疾病的背景下。目前的便携式空气过滤器通常会忽略咳嗽产生 the respiratory aerosols 浓度，尤其是在医疗保健设施和公共场所等高风险环境中。

Method: 本文提出了一种新颖的方法，即机器人咳嗽模拟器测试台和基于数字孪生技术的空气停留时间分析，以提高室内空气净化系统的效率。该方法包括一个由可操纵的模拟咳嗽事件的人体模型和响应气溶胶的便携式空气净化器组成的机器人双作用物理模拟器。使用此模拟器生成的数据来训练数字孪生模型，该模型结合了基于物理的舱室模型和基于长短期记忆（LSTM）网络和图卷积层的机器学习方法。

Result: 实验结果表明，该模型能够预测气溶胶浓度动态，其平均停留时间预测误差在 35 秒以内。

Conclusion: AeroSafe的实时干预策略优于静态空气过滤器放置，展示了其在降低空气传播病原体风险方面的潜力。

Abstract: Indoor air quality plays an essential role in the safety and well-being of
occupants, especially in the context of airborne diseases. This paper
introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor
air purification systems through a robotic cough emulator testbed and a
digital-twins-based aerosol residence time analysis. Current portable air
filters often overlook the concentrations of respiratory aerosols generated by
coughs, posing a risk, particularly in high-exposure environments like
healthcare facilities and public spaces. To address this gap, we present a
robotic dual-agent physical emulator comprising a maneuverable mannequin
simulating cough events and a portable air purifier autonomously responding to
aerosols. The generated data from this emulator trains a digital twins model,
combining a physics-based compartment model with a machine learning approach,
using Long Short-Term Memory (LSTM) networks and graph convolution layers.
Experimental results demonstrate the model's ability to predict aerosol
concentration dynamics with a mean residence time prediction error within 35
seconds. The proposed system's real-time intervention strategies outperform
static air filter placement, showcasing its potential in mitigating airborne
pathogen risks.

</details>


### [384] [A novel autonomous microplastics surveying robot for beach environments](https://arxiv.org/abs/2508.02952)
*Hassan Iqbal,Kobiny Rex,Joseph Shirley,Carlos Baiz,Christian Claudel*

Main category: cs.RO

TL;DR: 本研究提出了一种能自动检测和化学分析海滩微塑料的新型机器人平台，通过结合摄像头和近红外光谱传感器，实现了高精度的微塑料识别和分类。


<details>
  <summary>Details</summary>
Motivation: 微塑料是普遍存在的环境污染物，在海滩上的检测和浓度测绘是解决该环境问题的关键挑战之一。

Method: 提出了一种集自动检测和化学分析功能于一体的新型机器人平台，该平台使用安装在机械臂末端执行器上的摄像头扫描区域，能够有效分割沙地表面上的微塑料颗粒（即使存在树叶和蛤蜊等有机物），并通过近红外光谱传感器结合视觉反馈进行实时化学分析。

Result: 所提出的机器人平台能够有效检测沙地表面上的微塑料颗粒，并进行化学分析，实验结果表明该系统具有优异的位置精度和高微塑料分类准确率。

Conclusion: 该系统在实验室和海滩环境中均表现优异，实现了高精度的位置控制和微塑料分类准确率。

Abstract: Microplastics, defined as plastic particles smaller than 5 millimeters, have
become a pervasive environmental contaminant that accumulates on beaches due to
wind patterns and tidal forcing. Detecting microplastics and mapping their
concentration in the wild remains one of the primary challenges in addressing
this environmental issue. This paper introduces a novel robotic platform that
automatically detects and chemically analyzes microplastics on beach surfaces.
This mobile manipulator system scans areas for microplastics using a camera
mounted on the robotic arm's end effector. The system effectively segments
candidate microplastic particles on sand surfaces even in the presence of
organic matter such as leaves and clams. Once a candidate microplastic particle
is detected, the system steers a near-infrared (NIR) spectroscopic sensor onto
the particle using both NIR and visual feedback to chemically analyze it in
real-time. Through experiments in lab and beach environments, the system is
shown to achieve an excellent positional precision in manipulation control and
high microplastic classification accuracy.

</details>


### [385] [Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization](https://arxiv.org/abs/2508.02953)
*Adarsh Salagame,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 该研究引入了一种基于 Moreau 方法的降阶模型，用于解决蛇形机器人运动规划中的接触和控制分配问题，并通过仿真和实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 目前的控制研究要么忽略复杂相互作用，要么专注于复杂的物质相互作用（例如挖掘运动），而基于简单、基础刚体动力学的模型和控制框架，能够缓解蛇形运动中具有挑战性的接触和控制分配问题，仍然缺失。

Method: 采用 Moreau 的前进方法（差分包含数学）来构建降阶模型，并进行模型准确性验证和实验验证。

Result: 通过模拟和实验验证了所提出模型的准确性和有效性。

Conclusion: 这项工作通过模拟和实验，在引入基于 Moreau 差分包含数学的降阶模型、验证模型准确性以及进行实验验证这三个方向上做出了有意义的贡献。

Abstract: Contact-rich problems, such as snake robot locomotion, offer unexplored yet
rich opportunities for optimization-based trajectory and acyclic contact
planning. So far, a substantial body of control research has focused on
emulating snake locomotion and replicating its distinctive movement patterns
using shape functions that either ignore the complexity of interactions or
focus on complex interactions with matter (e.g., burrowing movements). However,
models and control frameworks that lie in between these two paradigms and are
based on simple, fundamental rigid body dynamics, which alleviate the
challenging contact and control allocation problems in snake locomotion, remain
absent. This work makes meaningful contributions, substantiated by simulations
and experiments, in the following directions: 1) introducing a reduced-order
model based on Moreau's stepping-forward approach from differential inclusion
mathematics, 2) verifying model accuracy, 3) experimental validation.

</details>


### [386] [Robot builds a robot's brain: AI generated drone command and control station hosted in the sky](https://arxiv.org/abs/2508.02962)
*Peter Burke*

Main category: cs.RO

TL;DR: AI为无人机编写了整个控制系统的代码，并在实际和模拟环境中进行了测试。AI生成的代码开发速度快，但存在一些局限性。这项工作为AI驱动的机器人工程开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 利用人工智能（AI），特别是大型语言模型（LLMs）和混合推理模型，来革新自主机器人（如无人机）的设计、开发和验证过程。

Method: 通过AI模型自主编写无人机指挥和控制平台的代码，并在实际无人机和模拟环境中进行部署和测试，与人类编写的代码进行性能、代码复杂度和开发速度的基准测试。

Result: AI生成的代码能够实现功能完整的指挥和控制堆栈，开发周期比人类编写快几个数量级，但存在与模型上下文窗口和推理深度相关的局限性。研究发现了AI生成机器人代码的优势、失败模式以及当前模型规模下的实际边界。

Conclusion: 该研究展示了一个完全由人工智能生成的无人机控制系统，证明了AI在机器人控制系统开发中的潜力，并为未来的机器人工程提出了新的范式。

Abstract: Advances in artificial intelligence (AI) including large language models
(LLMs) and hybrid reasoning models present an opportunity to reimagine how
autonomous robots such as drones are designed, developed, and validated. Here,
we demonstrate a fully AI-generated drone control system: with minimal human
input, an artificial intelligence (AI) model authored all the code for a
real-time, self-hosted drone command and control platform, which was deployed
and demonstrated on a real drone in flight as well as a simulated virtual drone
in the cloud. The system enables real-time mapping, flight telemetry,
autonomous mission planning and execution, and safety protocolsall orchestrated
through a web interface hosted directly on the drone itself. Not a single line
of code was written by a human. We quantitatively benchmark system performance,
code complexity, and development speed against prior, human-coded
architectures, finding that AI-generated code can deliver functionally complete
command-and-control stacks at orders-of-magnitude faster development cycles,
though with identifiable current limitations related to specific model context
window and reasoning depth. Our analysis uncovers the practical boundaries of
AI-driven robot control code generation at current model scales, as well as
emergent strengths and failure modes in AI-generated robotics code. This work
sets a precedent for the autonomous creation of robot control systems and, more
broadly, suggests a new paradigm for robotics engineeringone in which future
robots may be largely co-designed, developed, and verified by artificial
intelligence. In this initial work, a robot built a robot's brain.

</details>


### [387] [Physics-informed Neural Time Fields for Prehensile Object Manipulation](https://arxiv.org/abs/2508.02976)
*Hanwen Ren,Ruiqi Ni,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: A new robot skill for object manipulation that is fast, efficient, and doesn't need expert examples. It works in cluttered spaces and can adjust grasps on the fly. Tested in simulation and the real world, it beat other methods.


<details>
  <summary>Details</summary>
Motivation: Existing object manipulation approaches are inefficient, require expert demonstrations, or learn by trial and error, making them less ideal for practical scenarios. This paper aims to develop a more efficient and practical solution.

Method: A novel, multimodal physics-informed neural network (PINN) that learns to solve the Eikonal equation without expert data and reactively replans grasps during manipulation.

Result: The approach efficiently learns to solve the Eikonal equation, finds object manipulation trajectories fast in complex environments, and reactively replans grasps. It shows effectiveness across various objects, efficient training, and high performance in planning time, trajectory length, and success rates in both simulation and real-world scenarios.

Conclusion: The proposed multimodal physics-informed neural network (PINN) is effective for robot object manipulation tasks, outperforming baseline methods in planning time, trajectory length, and success rates across various objects and environments. It also demonstrates efficient training compared to previous learning-based methods.

Abstract: Object manipulation skills are necessary for robots operating in various
daily-life scenarios, ranging from warehouses to hospitals. They allow the
robots to manipulate the given object to their desired arrangement in the
cluttered environment. The existing approaches to solving object manipulations
are either inefficient sampling based techniques, require expert
demonstrations, or learn by trial and error, making them less ideal for
practical scenarios. In this paper, we propose a novel, multimodal
physics-informed neural network (PINN) for solving object manipulation tasks.
Our approach efficiently learns to solve the Eikonal equation without expert
data and finds object manipulation trajectories fast in complex, cluttered
environments. Our method is multimodal as it also reactively replans the
robot's grasps during manipulation to achieve the desired object poses. We
demonstrate our approach in both simulation and real-world scenarios and
compare it against state-of-the-art baseline methods. The results indicate that
our approach is effective across various objects, has efficient training
compared to previous learning-based methods, and demonstrates high performance
in planning time, trajectory length, and success rates. Our demonstration
videos can be found at https://youtu.be/FaQLkTV9knI.

</details>


### [388] [Multimodal Human-Intent Modeling for Contextual Robot-to-Human Handovers of Arbitrary Objects](https://arxiv.org/abs/2508.02982)
*Lucas Chen,Guna Avula,Hanwen Ren,Zixing Wang,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 一项新的人机物体交接方法，它能理解人类的偏好，并能从杂乱的环境中选择物体，以及选择合适的抓取方式。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预先选择的目标物体，未能对人类的显式和隐式偏好进行情境化，限制了人机之间的自然流畅交互。这些偏好可能与从杂乱环境中选择目标物体以及机器人应如何抓取所选物体以促进人类在交接过程中的期望抓取有关。

Method: 提出了一种统一的方法，该方法使用人类的口头和非口头命令来选择目标远距离物体，并通过结合人类的隐式和显式偏好来生成机器人抓取和顺从的交接运动序列。

Result: 所提出的集成框架及其组件通过现实世界的实验和用户研究进行了评估，证明了其在处理物体交接任务中的有效性。

Conclusion: 该方法通过理解人类偏好来处理物体交接任务，并在现实世界实验和用户研究中得到验证。

Abstract: Human-robot object handover is a crucial element for assistive robots that
aim to help people in their daily lives, including elderly care, hospitals, and
factory floors. The existing approaches to solving these tasks rely on
pre-selected target objects and do not contextualize human implicit and
explicit preferences for handover, limiting natural and smooth interaction
between humans and robots. These preferences can be related to the target
object selection from the cluttered environment and to the way the robot should
grasp the selected object to facilitate desirable human grasping during
handovers. Therefore, this paper presents a unified approach that selects
target distant objects using human verbal and non-verbal commands and performs
the handover operation by contextualizing human implicit and explicit
preferences to generate robot grasps and compliant handover motion sequences.
We evaluate our integrated framework and its components through real-world
experiments and user studies with arbitrary daily-life objects. The results of
these evaluations demonstrate the effectiveness of our proposed pipeline in
handling object handover tasks by understanding human preferences. Our
demonstration videos can be found at https://youtu.be/6z27B2INl-s.

</details>


### [389] [Estimation of Aerodynamics Forces in Dynamic Morphing Wing Flight](https://arxiv.org/abs/2508.02984)
*Bibek Gupta,Mintae Kim,Albert Park,Eric Sihite,Koushil Sreenath,Alireza Ramezani*

Main category: cs.RO

TL;DR: 本文研究了两种用于扑翼飞行机器人Aerobat的空气动力学力估计方法：一种基于共轭动量的物理观测器和一种基于MLP神经网络的回归模型。 实验结果表明，这两种方法在估计力的大部分分量时具有良好的一致性。


<details>
  <summary>Details</summary>
Motivation: 精确估计空气动力学力对于推进具有动态变形能力的扑翼飞行机器人的控制、建模和设计至关重要。 本文旨在量化系留飞行期间的空气动力学力贡献，这是实现闭环飞行控制的关键一步。

Method: 本文研究了两种不同的力估计方法：一种是基于汉密尔顿力学的基于物理的观测器，利用共轭动量来推断作用在机器人上的外部空气动力学力；另一种是基于神经网络的回归模型（MLP），学习从关节运动学、拍动频率和环境参数到空气动力学力输出的映射。

Result: 两种估计器均使用六轴测力计和高频数据采集系统进行评估，可实现周期性翼拍期间的精细力测量。 结果表明，共轭动量观测器和回归模型在三个力分量（Fx、Fy、Fz）上表现出良好的一致性。

Conclusion: 本文提出的基于共轭动量和基于多层感知器（MLP）的神经网络回归模型在估计空气动力学力的三个分量（Fx、Fy、Fz）方面表现出良好的一致性。

Abstract: Accurate estimation of aerodynamic forces is essential for advancing the
control, modeling, and design of flapping-wing aerial robots with dynamic
morphing capabilities. In this paper, we investigate two distinct methodologies
for force estimation on Aerobat, a bio-inspired flapping-wing platform designed
to emulate the inertial and aerodynamic behaviors observed in bat flight. Our
goal is to quantify aerodynamic force contributions during tethered flight, a
crucial step toward closed-loop flight control. The first method is a
physics-based observer derived from Hamiltonian mechanics that leverages the
concept of conjugate momentum to infer external aerodynamic forces acting on
the robot. This observer builds on the system's reduced-order dynamic model and
utilizes real-time sensor data to estimate forces without requiring training
data. The second method employs a neural network-based regression model,
specifically a multi-layer perceptron (MLP), to learn a mapping from joint
kinematics, flapping frequency, and environmental parameters to aerodynamic
force outputs. We evaluate both estimators using a 6-axis load cell in a
high-frequency data acquisition setup that enables fine-grained force
measurements during periodic wingbeats. The conjugate momentum observer and the
regression model demonstrate strong agreement across three force components
(Fx, Fy, Fz).

</details>


### [390] [GACL: Grounded Adaptive Curriculum Learning with Active Task and Performance Monitoring](https://arxiv.org/abs/2508.02988)
*Linji Wang,Zifan Xu,Peter Stone,Xuesu Xiao*

Main category: cs.RO

TL;DR: 我们提出了Grounded Adaptive Curriculum Learning（GACL），一个用于机器人课程学习的框架，解决了手动设计课程的挑战。GACL通过改进的任务表示、自适应课程生成和保持目标域相关性的基础方法，在轮式导航和四足动物运动任务中取得了比现有方法更高的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前机器人任务的课程学习主要依赖于手动设计的课程，这需要大量的工程努力，并且可能受到主观和次优的人为设计选择的影响。现有的自动化课程学习方法在网格世界和游戏等简单域中取得了成功，但机器人任务在处理复杂任务空间的同时，还需要与仅通过有限样本部分了解的目标域分布保持相关性，这带来了独特的挑战。

Method: 提出了一种名为“Grounded Adaptive Curriculum Learning”（GACL）的框架，该框架包含三个关键创新：1）一种始终如一地处理复杂机器人任务设计的任务表示；2）一种主动性能跟踪机制，允许生成适合机器人当前能力的适应性课程；3）一种通过在参考任务和合成任务之间交替采样来保持目标域相关性的基础方法。

Result: 在约束环境下的轮式导航和具有挑战性的3D受限空间中的四足动物运动方面，GACL取得了6.8%和6.1%的成功率提升，超过了现有方法。

Conclusion: GACL在约束环境下的轮式导航和具有挑战性的3D受限空间中的四足动物运动方面取得了成功，分别比每个领域的最新方法高出6.8%和6.1%的成功率。

Abstract: Curriculum learning has emerged as a promising approach for training complex
robotics tasks, yet current applications predominantly rely on manually
designed curricula, which demand significant engineering effort and can suffer
from subjective and suboptimal human design choices. While automated curriculum
learning has shown success in simple domains like grid worlds and games where
task distributions can be easily specified, robotics tasks present unique
challenges: they require handling complex task spaces while maintaining
relevance to target domain distributions that are only partially known through
limited samples. To this end, we propose Grounded Adaptive Curriculum Learning,
a framework specifically designed for robotics curriculum learning with three
key innovations: (1) a task representation that consistently handles complex
robot task design, (2) an active performance tracking mechanism that allows
adaptive curriculum generation appropriate for the robot's current
capabilities, and (3) a grounding approach that maintains target domain
relevance through alternating sampling between reference and synthetic tasks.
We validate GACL on wheeled navigation in constrained environments and
quadruped locomotion in challenging 3D confined spaces, achieving 6.8% and 6.1%
higher success rates, respectively, than state-of-the-art methods in each
domain.

</details>


### [391] [Thruster-Enhanced Locomotion: A Decoupled Model Predictive Control with Learned Contact Residuals](https://arxiv.org/abs/2508.03003)
*Chenghao Wang,Alireza Ramezani*

Main category: cs.RO

TL;DR: Husky Carbon机器人采用分离式控制策略，结合Raibert行走控制器和带CRD的MPC推力控制器，实现了稳定的推力辅助窄路径行走。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人Husky Carbon在姿态操纵和推力矢量化统一控制中的可行性问题，尤其是当系统采用轻量级执行器且扭矩控制带宽较低时，需要一种新的控制方法。

Method: 提出了一种分离控制架构：一种Raibert类型控制器使用基于位置的控制来控制腿部运动，而MPC则通过学习接触剩余动力学（CRD）来调节推力器，以考虑腿-地碰撞。

Result: 通过仿真和硬件实验验证了该方法，结果表明，所提出的分离控制架构与CRD结合使用，在推力恢复和类猫步态方面比未包含CRD的分离控制架构表现出更稳定的行为。

Conclusion: 提出的分离控制架构结合了基于位置的机器人行走控制和通过学习接触剩余动力学（CRD）增强的推力器模型预测控制（MPC），用于机器人推力辅助下的窄路径行走。该方法通过避开扭矩控制速率瓶颈，并显式考虑腿-地碰撞动力学，在推力恢复和类猫步态方面表现出比未包含CRD的分离控制架构更稳定的行为。

Abstract: Husky Carbon, a robot developed by Northeastern University, serves as a
research platform to explore unification of posture manipulation and thrust
vectoring. Unlike conventional quadrupeds, its joint actuators and thrusters
enable enhanced control authority, facilitating thruster-assisted narrow-path
walking. While a unified Model Predictive Control (MPC) framework optimizing
both ground reaction forces and thruster forces could theoretically address
this control problem, its feasibility is limited by the low torque-control
bandwidth of the system's lightweight actuators. To overcome this challenge, we
propose a decoupled control architecture: a Raibert-type controller governs
legged locomotion using position-based control, while an MPC regulates the
thrusters augmented by learned Contact Residual Dynamics (CRD) to account for
leg-ground impacts. This separation bypasses the torque-control rate bottleneck
while retaining the thruster MPC to explicitly account for leg-ground impact
dynamics through learned residuals. We validate this approach through both
simulation and hardware experiments, showing that the decoupled control
architecture with CRD performs more stable behavior in terms of push recovery
and cat-like walking gait compared to the decoupled controller without CRD.

</details>


### [392] [LiGen: GAN-Augmented Spectral Fingerprinting for Indoor Positioning](https://arxiv.org/abs/2508.03024)
*Jie Lin,Hsun-Yu Lee,Ho-Ming Li,Fang-Jing Wu*

Main category: cs.RO

TL;DR: LiGen是一种利用环境光频谱指纹和GAN数据增强技术的新型室内定位系统，精度高，鲁棒性强，优于Wi-Fi定位。


<details>
  <summary>Details</summary>
Motivation: 准确鲁棒的室内定位对于智能建筑应用至关重要，但现有的基于Wi-Fi的系统易受环境条件影响。需要一种更稳定、更少依赖基础设施的定位替代方案。

Method: 提出了一种名为LiGen的新型室内定位系统，利用环境光的频谱强度模式作为指纹。设计了一个基于生成对抗网络（GANs）的数据增强框架，包括PointGAN和FreeGAN两种变体。定位模型采用多层感知机（MLP）架构，在增强数据上进行训练。

Result: LiGen系统实现了亚米级的定位精度，比基于Wi-Fi的基线系统提高了50%以上。该系统在拥挤环境中也表现出强大的鲁棒性。

Conclusion: LiGen系统结合了光谱指纹和基于GAN的数据增强技术，实现了高精度、高鲁棒性的室内定位，优于Wi-Fi定位系统。

Abstract: Accurate and robust indoor localization is critical for smart building
applications, yet existing Wi-Fi-based systems are often vulnerable to
environmental conditions. This work presents a novel indoor localization
system, called LiGen, that leverages the spectral intensity patterns of ambient
light as fingerprints, offering a more stable and infrastructure-free
alternative to radio signals. To address the limited spectral data, we design a
data augmentation framework based on generative adversarial networks (GANs),
featuring two variants: PointGAN, which generates fingerprints conditioned on
coordinates, and FreeGAN, which uses a weak localization model to label
unconditioned samples. Our positioning model, leveraging a Multi-Layer
Perceptron (MLP) architecture to train on synthesized data, achieves
submeter-level accuracy, outperforming Wi-Fi-based baselines by over 50\%.
LiGen also demonstrates strong robustness in cluttered environments. To the
best of our knowledge, this is the first system to combine spectral
fingerprints with GAN-based data augmentation for indoor localization.

</details>


### [393] [CogniPlan: Uncertainty-Guided Path Planning with Conditional Generative Layout Prediction](https://arxiv.org/abs/2508.03027)
*Yizhuo Wang,Haodong He,Jingsong Liang,Yuhong Cao,Ritabrata Chakraborty,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: CogniPlan通过结合生成式布局预测和图注意力路径规划，在未知环境中实现了更优的机器人导航和探索。


<details>
  <summary>Details</summary>
Motivation: 未知环境中的路径规划对移动机器人至关重要，尤其是在自主探索和点目标导航方面。机器人需要实时感知环境、更新信念并准确估计潜在的信息增益来指导规划。

Method: CogniPlan是一个新颖的路径规划框架，它利用生成模型（COnditional GeNerative Inpainting）预测多种可能的布局，并结合图注意力机制进行路径规划，以在不确定性下进行推理。

Result: CogniPlan成功地结合了基于图像的生成式布局预测和基于图注意力机制的路径规划，结合了图表示的可扩展性和占用图的保真度和预测能力，在探索和导航任务中都取得了显著的性能提升，并且优于最先进的规划器。

Conclusion: CogniPlan在探索和导航方面都表现出了卓越的性能，并且在模拟器和真实硬件上都展示了其实用性。

Abstract: Path planning in unknown environments is a crucial yet inherently challenging
capability for mobile robots, which primarily encompasses two coupled tasks:
autonomous exploration and point-goal navigation. In both cases, the robot must
perceive the environment, update its belief, and accurately estimate potential
information gain on-the-fly to guide planning. In this work, we propose
CogniPlan, a novel path planning framework that leverages multiple plausible
layouts predicted by a COnditional GeNerative Inpainting model, mirroring how
humans rely on cognitive maps during navigation. These predictions, based on
the partially observed map and a set of layout conditioning vectors, enable our
planner to reason effectively under uncertainty. We demonstrate strong synergy
between generative image-based layout prediction and graph-attention-based path
planning, allowing CogniPlan to combine the scalability of graph
representations with the fidelity and predictiveness of occupancy maps,
yielding notable performance gains in both exploration and navigation. We
extensively evaluate CogniPlan on two datasets (hundreds of maps and realistic
floor plans), consistently outperforming state-of-the-art planners. We further
deploy it in a high-fidelity simulator and on hardware, showcasing its
high-quality path planning and real-world applicability.

</details>


### [394] [Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control](https://arxiv.org/abs/2508.03043)
*Yi-Hsuan Hsiao,Andrea Tagliabue,Owen Matteson,Suhan Kim,Tong Zhao,Jonathan P. How,YuFeng Chen*

Main category: cs.RO

TL;DR: 一种新的控制方法使微型飞行器能够像昆虫一样灵活机动。


<details>
  <summary>Details</summary>
Motivation: 昆虫能够执行急刹车、扫视和身体翻转等高难度机动，而现有的昆虫尺度飞行器在这方面能力有限。本研究旨在缩小这一性能差距。

Method: 通过设计一种深度学习的鲁棒管模型预测控制器，并采用模仿学习方法训练一个两层全连接神经网络来实现。

Result: 机器人在扫视运动中实现了197厘米/秒的侧向速度和11.7米/秒²的加速度，分别比先前结果提高了447%和255%。机器人能在160厘米/秒的风扰动和大的命令到力映射误差下执行扫视机动，并能在11秒内完成10次连续的身体翻转。

Conclusion: 该研究通过设计一种深度学习的鲁棒管模型预测控制器，在750毫克的扑翼机器人上实现了类似昆虫的飞行敏捷性和鲁棒性。机器人能够追踪受扰动影响的激进飞行轨迹，并在10秒内完成10次连续的身体翻转，这是亚克级飞行器中最具挑战性的机动。

Abstract: Aerial insects exhibit highly agile maneuvers such as sharp braking,
saccades, and body flips under disturbance. In contrast, insect-scale aerial
robots are limited to tracking non-aggressive trajectories with small body
acceleration. This performance gap is contributed by a combination of low robot
inertia, fast dynamics, uncertainty in flapping-wing aerodynamics, and high
susceptibility to environmental disturbance. Executing highly dynamic maneuvers
requires the generation of aggressive flight trajectories that push against the
hardware limit and a high-rate feedback controller that accounts for model and
environmental uncertainty. Here, through designing a deep-learned robust tube
model predictive controller, we showcase insect-like flight agility and
robustness in a 750-millgram flapping-wing robot. Our model predictive
controller can track aggressive flight trajectories under disturbance. To
achieve a high feedback rate in a compute-constrained real-time system, we
design imitation learning methods to train a two-layer, fully connected neural
network, which resembles insect flight control architecture consisting of
central nervous system and motor neurons. Our robot demonstrates insect-like
saccade movements with lateral speed and acceleration of 197 centimeters per
second and 11.7 meters per second square, representing 447$\%$ and 255$\%$
improvement over prior results. The robot can also perform saccade maneuvers
under 160 centimeters per second wind disturbance and large command-to-force
mapping errors. Furthermore, it performs 10 consecutive body flips in 11
seconds - the most challenging maneuver among sub-gram flyers. These results
represent a milestone in achieving insect-scale flight agility and inspire
future investigations on sensing and compute autonomy.

</details>


### [395] [SkeNa: Learning to Navigate Unseen Environments Based on Abstract Hand-Drawn Maps](https://arxiv.org/abs/2508.03053)
*Haojun Xu,Jiaqi Xiang,Wu Wei,Jinyu Chen,Linqing Zhong,Linjiang Huang,Hongyu Yang,Si Liu*

Main category: cs.RO

TL;DR: SkeNa是一项新的导航任务，代理使用手绘草图地图在未知环境中导航。研究者们发布了SoR数据集，并提出了SkeNavigator框架，该框架在导航任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 受人类通过绘制路线图来提供导航指导的启发，研究者们引入了一种新的具身导航任务——Sketch map-based visual Navigation（SkeNa），代理需要仅使用手绘草图地图在未见过的环境中导航到目标点。

Method: 提出了一种名为SkeNavigator的导航框架，该框架通过射线图描述符（RMD）来增强草图地图的特征表示，并使用双图对齐目标预测器（DAGP）来预测目标位置并指导导航，DAGP利用草图地图特征和现场构建的探索地图特征之间的对应关系来改进与视觉观测的对齐。

Result: 构建了一个大规模数据集SoR，包含71个室内场景的54k轨迹和草图地图对，并引入了两个不同抽象级别的导航验证集。

Conclusion: SkeNavigator在SoR数据集上显著优于现有的基于平面图导航的方法，在高度抽象的验证集上相对提高了105%的SPL（成功率加权路径长度）。

Abstract: A typical human strategy for giving navigation guidance is to sketch route
maps based on the environmental layout. Inspired by this, we introduce Sketch
map-based visual Navigation (SkeNa), an embodied navigation task in which an
agent must reach a goal in an unseen environment using only a hand-drawn sketch
map as guidance. To support research for SkeNa, we present a large-scale
dataset named SoR, comprising 54k trajectory and sketch map pairs across 71
indoor scenes. In SoR, we introduce two navigation validation sets with varying
levels of abstraction in hand-drawn sketches, categorized based on their
preservation of spatial scales in the environment, to facilitate future
research. To construct SoR, we develop an automated sketch-generation pipeline
that efficiently converts floor plans into hand-drawn representations. To solve
SkeNa, we propose SkeNavigator, a navigation framework that aligns visual
observations with hand-drawn maps to estimate navigation targets. It employs a
Ray-based Map Descriptor (RMD) to enhance sketch map valid feature
representation using equidistant sampling points and boundary distances. To
improve alignment with visual observations, a Dual-Map Aligned Goal Predictor
(DAGP) leverages the correspondence between sketch map features and on-site
constructed exploration map features to predict goal position and guide
navigation. SkeNavigator outperforms prior floor plan navigation methods by a
large margin, improving SPL on the high-abstract validation set by 105%
relatively. Our code and dataset will be released.

</details>


### [396] [Residual Neural Terminal Constraint for MPC-based Collision Avoidance in Dynamic Environments](https://arxiv.org/abs/2508.03428)
*Bojan Derajić,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Wolfgang Hönig*

Main category: cs.RO

TL;DR: A new MPC local planner uses a neural network to approximate a safe set for better real-time performance and higher success rates in planning, validated by experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a real-time local planner for MPC that incorporates a time-varying safe set, which is traditionally computationally infeasible to derive in real-time using HJ reachability analysis. The paper aims to overcome this by creating a learning-based approximation of this safe set.

Method: A hybrid MPC local planner is proposed, utilizing a learning-based approximation of a time-varying safe set as the MPC terminal constraint. This set is represented as a zero-superlevel set of the value function from HJ reachability analysis. The HJ value function is expressed as a difference between the signed distance function (SDF) and a non-negative residual function. This residual component is modeled as a neural network with non-negative output and subtracted from the SDF, creating a real-time value function estimate that is guaranteed to be at least as safe as the SDF. The neural residual is further parametrized by a hypernetwork for improved real-time performance and generalization.

Result: The proposed method demonstrated superior performance in simulations and hardware experiments, achieving up to a 30% increase in success rates compared to state-of-the-art baselines. It also maintained comparable computational requirements and generated solutions with low travel times.

Conclusion: The proposed hybrid MPC local planner, which uses a learning-based approximation of a time-varying safe set derived from local observations and applied as the MPC terminal constraint, achieved up to 30% higher success rates compared to the best baseline in simulations and hardware experiments, while requiring similar computational effort and producing high-quality solutions.

Abstract: In this paper, we propose a hybrid MPC local planner that uses a
learning-based approximation of a time-varying safe set, derived from local
observations and applied as the MPC terminal constraint. This set can be
represented as a zero-superlevel set of the value function computed via
Hamilton-Jacobi (HJ) reachability analysis, which is infeasible in real-time.
We exploit the property that the HJ value function can be expressed as a
difference of the corresponding signed distance function (SDF) and a
non-negative residual function. The residual component is modeled as a neural
network with non-negative output and subtracted from the computed SDF,
resulting in a real-time value function estimate that is at least as safe as
the SDF by design. Additionally, we parametrize the neural residual by a
hypernetwork to improve real-time performance and generalization properties.
The proposed method is compared with three state-of-the-art methods in
simulations and hardware experiments, achieving up to 30\% higher success rates
compared to the best baseline while requiring a similar computational effort
and producing high-quality (low travel-time) solutions.

</details>


### [397] [Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching](https://arxiv.org/abs/2508.03068)
*Sirui Chen,Yufei Ye,Zi-Ang Cao,Jennifer Lew,Pei Xu,C. Karen Liu*

Main category: cs.RO

TL;DR: HEAD框架能让机器人学习人类的动作，用于导航和抓取。


<details>
  <summary>Details</summary>
Motivation: 提出HEAD框架，用于学习人形机器人的导航、运动和抓取技能，直接从人类运动和视觉感知数据中学习。

Method: 该方法采用模块化方法，高层规划器命令人形机器人的手和眼睛的目标位置和方向，由低层策略控制全身运动，其中低层全身控制器学习跟踪来自大规模运动捕捉数据 的三个点（眼睛、左手和右手），而高层策略则学习来自 Aria 眼镜收集的人类数据。

Result: HEAD框架实现了人形机器人在复杂环境中导航和抓取的能力。

Conclusion: HEAD框架在模拟和真实世界中都进行了评估，证明了人形机器人能够在为人类设计 的复杂环境中进行导航和抓取。

Abstract: We propose Hand-Eye Autonomous Delivery (HEAD), a framework that learns
navigation, locomotion, and reaching skills for humanoids, directly from human
motion and vision perception data. We take a modular approach where the
high-level planner commands the target position and orientation of the hands
and eyes of the humanoid, delivered by the low-level policy that controls the
whole-body movements. Specifically, the low-level whole-body controller learns
to track the three points (eyes, left hand, and right hand) from existing
large-scale human motion capture data while high-level policy learns from human
data collected by Aria glasses. Our modular approach decouples the ego-centric
vision perception from physical actions, promoting efficient learning and
scalability to novel scenes. We evaluate our method both in simulation and in
the real-world, demonstrating humanoid's capabilities to navigate and reach in
complex environments designed for humans.

</details>


### [398] [Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running](https://arxiv.org/abs/2508.03070)
*Devin Crowley,Jeremy Dao,Helei Duan,Kevin Green,Jonathan Hurst,Alan Fern*

Main category: cs.RO

TL;DR: 本研究优化了双足机器人Cassie的奔跑步态，实现了高速奔跑，发现其步态与人类相似，并成功创造了双足机器人跑100米的世界纪录。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于探索双足机器人Cassie的奔跑步态空间，特别是如何优化其奔跑效率以实现高速奔跑，并与人类已知的、相比于四足动物更为高效的奔跑机制进行比较。

Method: 该研究首先提出了一种优化奔跑效率的方法，以支持机器人实现极高速度的奔跑。接着，研究基于已有的运动生物学研究，将优化后的步态与人类的奔跑机制进行了比较。最后，研究将优化的奔跑步态集成到一个完整的控制器中，使其能够满足现实世界中100米跑任务的规则，包括从站立姿势开始和停止。

Result: 研究发现，尽管Cassie机器人与人类在形态上存在差异，但它们在多种速度下的奔跑步态的关键属性高度相似。该研究成功地将优化的奔跑步态集成到控制器中，并成功在100米跑任务中创造了双足机器人跑100米的世界纪录。

Conclusion: 该研究成功优化了双足机器人Cassie的奔跑步态，实现了高速奔跑，并与人类奔跑机制进行了比较，发现两者在关键步态属性上具有高度相似性。最终，研究将优化的步态整合到控制器中，在100米跑任务中创造了双足机器人跑100米的世界纪录。

Abstract: In this paper, we explore the space of running gaits for the bipedal robot
Cassie. Our first contribution is to present an approach for optimizing gait
efficiency across a spectrum of speeds with the aim of enabling extremely
high-speed running on hardware. This raises the question of how the resulting
gaits compare to human running mechanics, which are known to be highly
efficient in comparison to quadrupeds. Our second contribution is to conduct
this comparison based on established human biomechanical studies. We find that
despite morphological differences between Cassie and humans, key properties of
the gaits are highly similar across a wide range of speeds. Finally, our third
contribution is to integrate the optimized running gaits into a full controller
that satisfies the rules of the real-world task of the 100m dash, including
starting and stopping from a standing position. We demonstrate this controller
on hardware to establish the Guinness World Record for Fastest 100m by a
Bipedal Robot.

</details>


### [399] [Point2Act: Efficient 3D Distillation of Multimodal LLMs for Zero-Shot Context-Aware Grasping](https://arxiv.org/abs/2508.03099)
*Sang Min Kim,Hyeongjun Heo,Junho Kim,Yonghyeon Lee,Young Min Kim*

Main category: cs.RO

TL;DR: Point2Act uses MLLMs and 3D relevancy fields to find precise 3D points for robot actions described in natural language, achieving real-time performance for practical manipulation tasks.


<details>
  <summary>Details</summary>
Motivation: Existing foundation models struggle to bridge the gap between 2D semantic understanding from MLLMs and precise 3D action localization in robotics, leading to blurry 3D regions and difficulty in finding exact locations for actions.

Method: Point2Act retrieves 3D action points by leveraging MLLMs and proposes 3D relevancy fields that use lightweight 2D point-level guidance. Multi-view aggregation handles geometric ambiguities and semantic uncertainties. The full pipeline includes capturing, MLLM querying, 3D reconstruction, and grasp pose extraction.

Result: The proposed method effectively imbues lightweight 2D point-level guidance, bypasses high-dimensional features, and achieves highly localized output regions by reasoning fine-grained 3D spatial context, which directly transfers to physical actions in on-the-fly scene reconstructions.

Conclusion: Point2Act successfully generates spatially grounded responses for physical action in under 20 seconds by directly retrieving 3D action points relevant to a task description using MLLMs and 3D relevancy fields, overcoming limitations of 2D semantic understanding.

Abstract: We propose Point2Act, which directly retrieves the 3D action point relevant
for a contextually described task, leveraging Multimodal Large Language Models
(MLLMs). Foundation models opened the possibility for generalist robots that
can perform a zero-shot task following natural language descriptions within an
unseen environment. While the semantics obtained from large-scale image and
language datasets provide contextual understanding in 2D images, the rich yet
nuanced features deduce blurry 2D regions and struggle to find precise 3D
locations for actions. Our proposed 3D relevancy fields bypass the
high-dimensional features and instead efficiently imbue lightweight 2D
point-level guidance tailored to the task-specific action. The multi-view
aggregation effectively compensates for misalignments due to geometric
ambiguities, such as occlusion, or semantic uncertainties inherent in the
language descriptions. The output region is highly localized, reasoning
fine-grained 3D spatial context that can directly transfer to an explicit
position for physical action at the on-the-fly reconstruction of the scene. Our
full-stack pipeline, which includes capturing, MLLM querying, 3D
reconstruction, and grasp pose extraction, generates spatially grounded
responses in under 20 seconds, facilitating practical manipulation tasks.
Project page: https://sangminkim-99.github.io/point2act/

</details>


### [400] [Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection](https://arxiv.org/abs/2508.03129)
*Le Qiu,Yusuf Umut Ciftci,Somil Bansal*

Main category: cs.RO

TL;DR: MPC-SafeGIL通过在专家演示中加入模拟的“危险”情况，训练机器人更好地应对意外，从而提高模仿学习的安全性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习虽然能够学习复杂的机器人行为，但其学习策略可能导致安全违规，限制了其在安全关键应用中的部署。因此，需要一种能够提高模仿学习安全性的方法。

Method: MPC-SafeGIL是一种设计时方法，通过在专家演示中注入对抗性干扰来增强模仿学习的安全性。该方法使用基于采样的模型预测控制（MPC）来近似最坏情况的干扰，以暴露专家于更广泛的安全关键场景，并使模仿策略学习鲁棒的恢复行为。

Result: MPC-SafeGIL在四足动物运动、视觉运动导航等模拟以及四旋翼飞行器等真实世界实验中得到验证，证明了其在提高安全性和任务性能方面的有效性。

Conclusion: MPC-SafeGIL通过在专家演示中注入对抗性干扰，提高了模仿学习的安全性，并使模仿策略能够学习鲁棒的恢复行为。该方法通过基于采样的模型预测控制（MPC）来近似最坏情况的干扰，适用于高维和黑盒动力学系统。与依赖分析模型或交互式专家的先前工作相比，MPC-SafeGIL将安全性考虑直接整合到数据收集过程中。通过在四足动物运动、视觉运动导航以及四旋翼飞行器等模拟和真实世界实验中进行验证，MPC-SafeGIL在安全性和任务性能方面均有所改善。

Abstract: Imitation Learning has provided a promising approach to learning complex
robot behaviors from expert demonstrations. However, learned policies can make
errors that lead to safety violations, which limits their deployment in
safety-critical applications. We propose MPC-SafeGIL, a design-time approach
that enhances the safety of imitation learning by injecting adversarial
disturbances during expert demonstrations. This exposes the expert to a broader
range of safety-critical scenarios and allows the imitation policy to learn
robust recovery behaviors. Our method uses sampling-based Model Predictive
Control (MPC) to approximate worst-case disturbances, making it scalable to
high-dimensional and black-box dynamical systems. In contrast to prior work
that relies on analytical models or interactive experts, MPC-SafeGIL integrates
safety considerations directly into data collection. We validate our approach
through extensive simulations including quadruped locomotion and visuomotor
navigation and real-world experiments on a quadrotor, demonstrating
improvements in both safety and task performance. See our website here:
https://leqiu2003.github.io/MPCSafeGIL/

</details>


### [401] [Language as Cost: Proactive Hazard Mapping using VLM for Robot Navigation](https://arxiv.org/abs/2508.03138)
*Mintaek Oh,Chan Kim,Seung-Woo Seo,Seong-Woo Kim*

Main category: cs.RO

TL;DR: 利用视觉-语言模型将环境动态风险转化为导航成本，使机器人能够预测并主动避开危险。


<details>
  <summary>Details</summary>
Motivation: 传统的导航系统依赖静态地图，难以应对动态风险（如突然打开的门后出现的人），导致系统在处理动态危险时更倾向于被动反应而非主动预测。

Method: 提出了一种零样本语言作为成本映射的框架，利用视觉-语言模型（VLMs）解释视觉场景，评估潜在的动态风险，并先发制人地分配风险感知导航成本。

Result: 在模拟和多样化的动态环境中进行实验，证明了所提出的方法与被动基线规划器相比，显著提高了导航成功率并减少了危险遭遇。

Conclusion: 该方法通过将语言模型解释的风险成本与几何障碍物图相结合，实现了机器人对动态危险的预测性规划，显著提高了导航成功率并减少了危险遭遇。

Abstract: Robots operating in human-centric or hazardous environments must proactively
anticipate and mitigate dangers beyond basic obstacle detection. Traditional
navigation systems often depend on static maps, which struggle to account for
dynamic risks, such as a person emerging from a suddenly opening door. As a
result, these systems tend to be reactive rather than anticipatory when
handling dynamic hazards. Recent advancements in pre-trained large language
models and vision-language models (VLMs) create new opportunities for proactive
hazard avoidance. In this work, we propose a zero-shot language-as-cost mapping
framework that leverages VLMs to interpret visual scenes, assess potential
dynamic risks, and assign risk-aware navigation costs preemptively, enabling
robots to anticipate hazards before they materialize. By integrating this
language-based cost map with a geometric obstacle map, the robot not only
identifies existing obstacles but also anticipates and proactively plans around
potential hazards arising from environmental dynamics. Experiments in simulated
and diverse dynamic environments demonstrate that the proposed method
significantly improves navigation success rates and reduces hazard encounters,
compared to reactive baseline planners. Code and supplementary materials are
available at https://github.com/Taekmino/LaC.

</details>


### [402] [CookBench: A Long-Horizon Embodied Planning Benchmark for Complex Cooking Scenarios](https://arxiv.org/abs/2508.03232)
*Muzhen Cai,Xiubo Chen,Yining An,Jiaxin Zhang,Xuesong Wang,Wang Xu,Weinan Zhang,Ting Liu*

Main category: cs.RO

TL;DR: CookBench 是一个用于长周期烹饪任务的具身规划基准，解决了现有基准任务周期短、动作粗粒度的问题。它包含意图识别和具身交互两个阶段，提供细粒度动作和全面的工具集，并分析了现有模型的不足。


<details>
  <summary>Details</summary>
Motivation: 现有具身规划基准通常包含短周期任务和粗粒度的动作原语，难以满足在复杂物理世界中执行长周期任务的需求。为了解决这一挑战，作者引入了 CookBench，一个用于复杂烹饪场景中长周期规划的基准。

Method: 提出了 CookBench 基准，这是一个利用 Unity 游戏引擎构建的高保真模拟环境，用于长周期规划的烹饪场景。该基准包含两个核心任务：意图识别（解析用户复杂意图）和具身交互（通过长周期、细粒度的物理动作序列执行烹饪目标）。在动作粒度上，CookBench 进行了细化，考虑了关键操作信息，同时又避免了低级机器人控制。此外，提供了一个包含模拟器封装的工具集，支持宏观操作（如下单、购买食材）和细粒度具身动作。

Result: CookBench 包含一个高保真模拟环境和一套工具集，支持长周期、细粒度的烹饪任务规划。通过分析表明，现有的 LLM 和 VLM 在处理复杂、长周期的任务时存在明显不足和挑战。

Conclusion: Embodied Planning 的目标是创建能够在复杂物理世界中执行长周期任务的智能体。CookBench 是一个用于长周期规划的烹饪场景基准，它利用高保真模拟环境，并解决了现有基准任务周期短、动作粗粒度的问题。该基准包含意图识别和具身交互两个阶段，动作粒度细致，并提供了一个包含宏观和细粒度操作的工具集，以支持研究人员专注于高级规划和决策。此外，还分析了现有大语言模型和视觉语言模型的不足之处。

Abstract: Embodied Planning is dedicated to the goal of creating agents capable of
executing long-horizon tasks in complex physical worlds. However, existing
embodied planning benchmarks frequently feature short-horizon tasks and
coarse-grained action primitives. To address this challenge, we introduce
CookBench, a benchmark for long-horizon planning in complex cooking scenarios.
By leveraging a high-fidelity simulation environment built upon the powerful
Unity game engine, we define frontier AI challenges in a complex, realistic
environment. The core task in CookBench is designed as a two-stage process.
First, in Intention Recognition, an agent needs to accurately parse a user's
complex intent. Second, in Embodied Interaction, the agent should execute the
identified cooking goal through a long-horizon, fine-grained sequence of
physical actions. Unlike existing embodied planning benchmarks, we refine the
action granularity to a spatial level that considers crucial operational
information while abstracting away low-level robotic control. Besides, We
provide a comprehensive toolset that encapsulates the simulator. Its unified
API supports both macro-level operations, such as placing orders and purchasing
ingredients, and a rich set of fine-grained embodied actions for physical
interaction, enabling researchers to focus on high-level planning and
decision-making. Furthermore, we present an in-depth analysis of
state-of-the-art, closed-source Large Language Model and Vision-Language Model,
revealing their major shortcomings and challenges posed by complex,
long-horizon tasks. The full benchmark will be open-sourced to facilitate
future research.

</details>


### [403] [Force-Compliance MPC and Robot-User CBFs for Interactive Navigation and User-Robot Safety in Hexapod Guide Robots](https://arxiv.org/abs/2508.03246)
*Zehua Fan,Feng Gao,Zhijun Chen,Yunpeng Yin,Limin Yang,Qingxing Xi,En Yang,Xuefeng Luo*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Guiding the visually impaired in complex environments requires real-time
two-way interaction and safety assurance. We propose a Force-Compliance Model
Predictive Control (FC-MPC) and Robot-User Control Barrier Functions (CBFs) for
force-compliant navigation and obstacle avoidance in Hexapod guide robots.
FC-MPC enables two-way interaction by estimating user-applied forces and
moments using the robot's dynamic model and the recursive least squares (RLS)
method, and then adjusting the robot's movements accordingly, while Robot-User
CBFs ensure the safety of both the user and the robot by handling static and
dynamic obstacles, and employ weighted slack variables to overcome feasibility
issues in complex dynamic environments. We also adopt an Eight-Way Connected
DBSCAN method for obstacle clustering, reducing computational complexity from
O(n2) to approximately O(n), enabling real-time local perception on
resource-limited on-board robot computers. Obstacles are modeled using Minimum
Bounding Ellipses (MBEs), and their trajectories are predicted through Kalman
filtering. Implemented on the HexGuide robot, the system seamlessly integrates
force compliance, autonomous navigation, and obstacle avoidance. Experimental
results demonstrate the system's ability to adapt to user force commands while
guaranteeing user and robot safety simultaneously during navigation in complex
environments.

</details>


### [404] [UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands](https://arxiv.org/abs/2508.03339)
*Haoran Lin,Wenrui Chen,Xianchi Chen,Fan Yang,Qiang Diao,Wenxin Xie,Sijie Wu,Kailun Yang,Maojun Li,Yaonan Wang*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Dexterous grasp datasets are vital for embodied intelligence, but mostly
emphasize grasp stability, ignoring functional grasps needed for tasks like
opening bottle caps or holding cup handles. Most rely on bulky, costly, and
hard-to-control high-DOF Shadow Hands. Inspired by the human hand's
underactuated mechanism, we establish UniFucGrasp, a universal functional grasp
annotation strategy and dataset for multiple dexterous hand types. Based on
biomimicry, it maps natural human motions to diverse hand structures and uses
geometry-based force closure to ensure functional, stable, human-like grasps.
This method supports low-cost, efficient collection of diverse, high-quality
functional grasps. Finally, we establish the first multi-hand functional grasp
dataset and provide a synthesis model to validate its effectiveness.
Experiments on the UFG dataset, IsaacSim, and complex robotic tasks show that
our method improves functional manipulation accuracy and grasp stability,
enables efficient generalization across diverse robotic hands, and overcomes
annotation cost and generalization challenges in dexterous grasping. The
project page is at https://haochen611.github.io/UFG.

</details>


### [405] [Opti-Acoustic Scene Reconstruction in Highly Turbid Underwater Environments](https://arxiv.org/abs/2508.03408)
*Ivana Collado-Gonzalez,John McConnell,Paul Szenher,Brendan Englot*

Main category: cs.RO

TL;DR: 提出了一种结合视觉和声纳的重建方法，解决了水下浑浊环境下的重建问题。


<details>
  <summary>Details</summary>
Motivation: 水下机器人近距离导航需要场景重建能力，但现有的单目视觉重建方法在浑浊水域不可靠且缺乏深度尺度信息，而声纳虽然鲁棒但分辨率低且存在高程模糊性。

Method: 提出了一种实时视觉声学场景重建方法，该方法通过识别图像和声纳数据中的兴趣区域，并利用声纳的测量数据和相机图像的测量数据来获得重建，从而避免了在视觉数据中识别点特征。

Result: 实现了在浑浊水域中进行实时场景重建。

Conclusion: 该方法在不同浊度级别下进行了实验比较，并在船厂环境中进行了实地测试，验证了所提方法的有效性。

Abstract: Scene reconstruction is an essential capability for underwater robots
navigating in close proximity to structures. Monocular vision-based
reconstruction methods are unreliable in turbid waters and lack depth scale
information. Sonars are robust to turbid water and non-uniform lighting
conditions, however, they have low resolution and elevation ambiguity. This
work proposes a real-time opti-acoustic scene reconstruction method that is
specially optimized to work in turbid water. Our strategy avoids having to
identify point features in visual data and instead identifies regions of
interest in the data. We then match relevant regions in the image to
corresponding sonar data. A reconstruction is obtained by leveraging range data
from the sonar and elevation data from the camera image. Experimental
comparisons against other vision-based and sonar-based approaches at varying
turbidity levels, and field tests conducted in marina environments, validate
the effectiveness of the proposed approach. We have made our code open-source
to facilitate reproducibility and encourage community engagement.

</details>


### [406] [Theatre in the Loop: A Rehearsal-Based, Collaborative Workflow for Expressive Robotic Behaviours](https://arxiv.org/abs/2508.03514)
*Pavlos Panagiotidis,Victor Zhi Heung Ngo,Sean Myatt,Roma Patel,Rachel Ramchurn,Alan Chamberlain,Ayse Kucukyilmaz*

Main category: cs.RO

TL;DR: 提出了一种名为 theatre-in-the-loop 的框架，该框架通过受导演指导的木偶制作工作流程，利用戏剧方法为艺术表演开发具有表现力的机器人行为，并为机器人行为的共创方法做出了贡献。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于开发专门针对艺术表演的表达性机器人行为的框架，通过受导演指导的木偶制作工作流程。

Method: 该框架利用戏剧方法，使用叙事目标来指导木偶师生成即兴的机器人姿态，以传达特定的情感。这些即兴创作被捕获和策划，为将来独立表演的重复使用运动模板建立数据集。

Result: 初步试验证明了该方法的可行性，说明了该工作流程如何能够将机器人姿态精确地塑造成连贯的情感弧，同时揭示了机器人机械约束带来的挑战。

Conclusion: 该框架为跨学科团队创建具有社会表现力的机器人行为提供了一个模型，该模型有助于（1）将戏剧作为人机交互的交互式训练场，以及（2）人与机器之间的共创方法。

Abstract: In this paper, we propose theatre-in-the-loop, a framework for developing
expressive robot behaviours tailored to artistic performance through a
director-guided puppeteering workflow. Leveraging theatrical methods, we use
narrative objectives to direct a puppeteer in generating improvised robotic
gestures that convey specific emotions. These improvisations are captured and
curated to build a dataset of reusable movement templates for standalone
playback in future autonomous performances. Initial trials demonstrate the
feasibility of this approach, illustrating how the workflow enables precise
sculpting of robotic gestures into coherent emotional arcs while revealing
challenges posed by the robot's mechanical constraints. We argue that this
practice-led framework provides a model for interdisciplinary teams creating
socially expressive robot behaviours, contributing to (1) theatre as an
interactive training ground for human-robot interaction and (2) co-creation
methodologies between humans and machines.

</details>


### [407] [CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation](https://arxiv.org/abs/2508.03526)
*Kun Song,Shentao Ma,Gaoming Chen,Ninglong Jin,Guangbao Zhao,Mingyu Ding,Zhenhua Xiong,Jia Pan*

Main category: cs.RO

TL;DR: CollaBot是一个用于多机器人协同操作的通用框架，通过场景分割、局部抓取姿态生成、全局协作和两阶段规划，实现了对大物体的操作。


<details>
  <summary>Details</summary>
Motivation: 传统操作任务主要集中在小物体上，但在工厂或家庭环境中，经常需要移动大物体（如桌子），这通常需要多机器人协同工作。之前的研究缺乏可扩展到任意机器人尺寸并推广到各种任务的框架。

Method: 首先使用SEEM进行场景分割和目标物点云提取；然后提出一个将任务分解为局部抓取姿态生成和全局协作的协作抓取框架；最后设计一个两阶段规划模块，以生成无碰撞的轨迹。

Result: 实验表明，在不同数量的机器人、物体和任务的测试中，成功率达到了52%。

Conclusion: CollaBot是一个通用的同步协作操作框架，在不同数量的机器人、物体和任务的实验中，成功率达到52%，证明了该框架的有效性。

Abstract: A central research topic in robotics is how to use this system to interact
with the physical world. Traditional manipulation tasks primarily focus on
small objects. However, in factory or home environments, there is often a need
for the movement of large objects, such as moving tables. These tasks typically
require multi-robot systems to work collaboratively. Previous research lacks a
framework that can scale to arbitrary sizes of robots and generalize to various
kinds of tasks. In this work, we propose CollaBot, a generalist framework for
simultaneous collaborative manipulation. First, we use SEEM for scene
segmentation and point cloud extraction of the target object. Then, we propose
a collaborative grasping framework, which decomposes the task into local grasp
pose generation and global collaboration. Finally, we design a 2-stage planning
module that can generate collision-free trajectories to achieve this task.
Experiments show a success rate of 52% across different numbers of robots,
objects, and tasks, indicating the effectiveness of the proposed framework.

</details>


### [408] [Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions](https://arxiv.org/abs/2508.03541)
*Ergi Tushe,Bilal Farooq*

Main category: cs.RO

TL;DR: 该研究提出了一种基于单一视觉传感器的多行人检测、跟踪、姿态估计和单目深度感知流程，以提高自动化递送机器人在城市环境中的导航能力，并特别关注弱势行人群体的识别，以实现更具社会意识和包容性的机器人行为。


<details>
  <summary>Details</summary>
Motivation: 自动化递送机器人（ADR）在行人密集的城市空间中的集成带来了安全、高效和社会可接受导航方面的独特挑战。

Method: 开发了一个基于单一视觉传感器的多行人检测和跟踪、姿态估计和单目深度感知的完整流程。利用真实世界的MOT17数据集序列，整合了人体姿态估计和深度线索，以提高行人的轨迹预测和身份维持能力，即使在遮挡和人群密集的情况下也能实现。

Result: 结果显示，在身份保持（IDF1）方面提高了10%，在多目标跟踪精度（MOTA）方面提高了7%，并且在具有挑战性的场景中，检测精度始终保持在85%以上。

Conclusion: 该系统能够识别弱势行人，支持更具社会意识和包容性的机器人行为。

Abstract: The integration of Automated Delivery Robots (ADRs) into pedestrian-heavy
urban spaces introduces unique challenges in terms of safe, efficient, and
socially acceptable navigation. We develop the complete pipeline for a single
vision sensor based multi-pedestrian detection and tracking, pose estimation,
and monocular depth perception. Leveraging the real-world MOT17 dataset
sequences, this study demonstrates how integrating human-pose estimation and
depth cues enhances pedestrian trajectory prediction and identity maintenance,
even under occlusions and dense crowds. Results show measurable improvements,
including up to a 10% increase in identity preservation (IDF1), a 7%
improvement in multiobject tracking accuracy (MOTA), and consistently high
detection precision exceeding 85%, even in challenging scenarios. Notably, the
system identifies vulnerable pedestrian groups supporting more socially aware
and inclusive robot behaviour.

</details>


### [409] [Online Learning for Vibration Suppression in Physical Robot Interaction using Power Tools](https://arxiv.org/abs/2508.03559)
*Gokhan Solak,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种改进的BMFLC算法（阻尼BMFLC），通过自适应步长和阻尼机制提高了协作机器人的振动抑制性能和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高协作机器人在施工现场等复杂环境中，因外部干扰（如电动工具）引起的振动抑制能力。

Method: 提出了一种改进的BMFLC算法，称为阻尼BMFLC（damped BMFLC），该算法包含一种新颖的自适应步长方法，并使用基于Logistic函数的阻尼机制来减少噪声影响并允许更大的学习率。

Result: 仿真实验结果表明，与原始BMFLC及其基于递归最小二乘和卡尔曼滤波的扩展算法相比，所提出的方法提高了抑制率，并且效率更高。实际的抛光实验也验证了该方法的有效性。

Conclusion: 提出的BMFLC方法在仿真和实际应用中都表现出了优越的振动抑制性能，与现有的方法相比，其收敛速度更快，噪声抵抗能力更强，效率更高。

Abstract: Vibration suppression is an important capability for collaborative robots
deployed in challenging environments such as construction sites. We study the
active suppression of vibration caused by external sources such as power tools.
We adopt the band-limited multiple Fourier linear combiner (BMFLC) algorithm to
learn the vibration online and counter it by feedforward force control. We
propose the damped BMFLC method, extending BMFLC with a novel adaptive
step-size approach that improves the convergence time and noise resistance. Our
logistic function-based damping mechanism reduces the effect of noise and
enables larger learning rates. We evaluate our method on extensive simulation
experiments with realistic time-varying multi-frequency vibration and
real-world physical interaction experiments. The simulation experiments show
that our method improves the suppression rate in comparison to the original
BMFLC and its recursive least squares and Kalman filter-based extensions.
Furthermore, our method is far more efficient than the latter two. We further
validate the effectiveness of our method in real-world polishing experiments. A
supplementary video is available at https://youtu.be/ms6m-6JyVAI.

</details>


### [410] [DiWA: Diffusion Policy Adaptation with World Models](https://arxiv.org/abs/2508.03645)
*Akshay L Chandra,Iman Nematollahi,Chenguang Huang,Tim Welschehold,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR: DiWA enables offline reinforcement learning for diffusion policies in robotics using a world model, drastically improving sample efficiency and reducing real-world interactions needed for fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Fine-tuning diffusion policies with RL is challenging due to long denoising sequences and the high cost of real-world interactions. Existing methods are inefficient as they rely heavily on environment interaction.

Method: DiWA utilizes a world model for offline reinforcement learning to fine-tune diffusion-based robotic skills, overcoming the challenges of long denoising sequences and the inefficiency of environment interaction.

Result: DiWA achieves effective adaptation with a world model trained on a few hundred thousand offline interactions, drastically improving sample efficiency. It outperforms model-free baselines on the CALVIN benchmark across eight tasks, requiring significantly fewer physical interactions.

Conclusion: DiWA is the first framework to successfully fine-tune diffusion policies for real-world robotic skills using an offline world model, significantly improving sample efficiency and reducing the need for physical interactions compared to model-free baselines.

Abstract: Fine-tuning diffusion policies with reinforcement learning (RL) presents
significant challenges. The long denoising sequence for each action prediction
impedes effective reward propagation. Moreover, standard RL methods require
millions of real-world interactions, posing a major bottleneck for practical
fine-tuning. Although prior work frames the denoising process in diffusion
policies as a Markov Decision Process to enable RL-based updates, its strong
dependence on environment interaction remains highly inefficient. To bridge
this gap, we introduce DiWA, a novel framework that leverages a world model for
fine-tuning diffusion-based robotic skills entirely offline with reinforcement
learning. Unlike model-free approaches that require millions of environment
interactions to fine-tune a repertoire of robot skills, DiWA achieves effective
adaptation using a world model trained once on a few hundred thousand offline
play interactions. This results in dramatically improved sample efficiency,
making the approach significantly more practical and safer for real-world robot
learning. On the challenging CALVIN benchmark, DiWA improves performance across
eight tasks using only offline adaptation, while requiring orders of magnitude
fewer physical interactions than model-free baselines. To our knowledge, this
is the first demonstration of fine-tuning diffusion policies for real-world
robotic skills using an offline world model. We make the code publicly
available at https://diwa.cs.uni-freiburg.de.

</details>


### [411] [Inland-LOAM: Voxel-Based Structural Semantic Mapping for Inland Waterways](https://arxiv.org/abs/2508.03672)
*Zhongbi Luo,Yunjia Wang,Jan Swevers,Peter Slaets,Herman Bruyninckx*

Main category: cs.RO

TL;DR: 本论文提出了Inland-LOAM，一个用于内河航道的LiDAR SLAM框架，解决了现有海图缺乏实时细节和传统LiDAR SLAM在水道环境中失效的问题。通过改进的特征提取、水面平面约束和2D语义地图生成，Inland-LOAM提高了定位精度并生成了有用的航行数据。


<details>
  <summary>Details</summary>
Motivation: 为了实现安全、自主的内河运输（IWT），准确的地理空间信息至关重要，因为现有的海图（IENC）缺乏实时细节，并且传统的LiDAR SLAM在水道环境中会失效，导致垂直漂移和非语义地图，阻碍了自主导航。

Method: Inland-LOAM使用改进的特征提取和水面平面约束来减轻垂直漂移。它通过基于体素的几何分析将3D点云转换为结构化2D语义地图，从而实现航行参数（如桥梁间隙）的实时计算。此外，还包含一个自动提取海岸线并将其导出为轻量级、兼容IENC格式的模块。

Result: Inland-LOAM实现了优于现有最先进方法的定位精度，并且生成的语义地图和海岸线与现实世界的情况一致，为增强态势感知提供了可靠数据。

Conclusion: Inland-LOAM在真实数据集的评估表明，其定位精度优于现有最先进的方法，生成的语义地图和海岸线与现实情况一致，为增强态势感知提供了可靠数据。

Abstract: Accurate geospatial information is crucial for safe, autonomous Inland
Waterway Transport (IWT), as existing charts (IENC) lack real-time detail and
conventional LiDAR SLAM fails in waterway environments. These challenges lead
to vertical drift and non-semantic maps, hindering autonomous navigation.
  This paper introduces Inland-LOAM, a LiDAR SLAM framework for waterways. It
uses an improved feature extraction and a water surface planar constraint to
mitigate vertical drift. A novel pipeline transforms 3D point clouds into
structured 2D semantic maps using voxel-based geometric analysis, enabling
real-time computation of navigational parameters like bridge clearances. An
automated module extracts shorelines and exports them into a lightweight,
IENC-compatible format.
  Evaluations on a real-world dataset show Inland-LOAM achieves superior
localization accuracy over state-of-the-art methods. The generated semantic
maps and shorelines align with real-world conditions, providing reliable data
for enhanced situational awareness. The code and dataset will be publicly
available

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [412] [Approximate Proportionality in Online Fair Division](https://arxiv.org/abs/2508.03253)
*Davin Choo,Winston Fu,Derek Khu,Tzeh Yuan Neoh,Tze-Yang Poon,Nicholas Teh*

Main category: cs.GT

TL;DR: 本研究解决了在线公平分配问题中比例（PROP1）的近似问题。研究发现，贪婪算法在面对自适应对手时无法保证PROP1近似，但统一随机分配算法在面对非自适应对手时表现良好。结合最大项价值（MIV）预测可以提高PROP1的近似率，但对更强的公平性概念（如EF1、MMS、PROPX）无效。


<details>
  <summary>Details</summary>
Motivation: 既有研究表明，在在线公平分配问题中，像无嫉妒性（envy-freeness）和最大最小份额公平性（maximin share fairness）等经典公平性概念很难近似。然而，比例（PROP1）作为比例性的一种自然放松，其近似性仍未解决。因此，本研究旨在解决PROP1在在线公平分配问题中的近似问题，并探索贪婪算法的局限性以及非自适应对手和学习增强算法的潜力。

Method: 研究了在线公平分配问题，其中不可分割的物品按顺序到达，必须立即且不可撤销地分配给代理。研究了三种贪婪算法，并证明了它们在一般情况下无法保证对比例（PROP1）的任何正近似，尤其是在面对自适应对手时。对于非自适应对手，提出了一种统一随机分配算法，该算法可以高概率地实现有意义的PROP1近似。此外，还提出了一种在给定最大项价值（MIV）预测的情况下，能够获得针对PROP1的稳健近似率的算法。

Result: 三种贪婪算法在一般情况下无法保证对PROP1的任何正近似，即使是面对自适应对手。统一随机分配算法可以高概率地实现有意义的PROP1近似（针对非自适应对手）。通过结合最大项价值（MIV）预测，可以获得针对PROP1的稳健近似率。然而，即使拥有完美的MIV预测，EF1、MMS和PROPX等更强的公平性概念仍然是不可近似的。

Conclusion: EF1、MMS和PROPX等更强的公平性概念，即使在拥有完美最大项价值（MIV）预测的情况下，仍然是不可近似的。

Abstract: We study the online fair division problem, where indivisible goods arrive
sequentially and must be allocated immediately and irrevocably to agents. Prior
work has established strong impossibility results for approximating classic
fairness notions, such as envy-freeness and maximin share fairness, in this
setting. In contrast, we focus on proportionality up to one good (PROP1), a
natural relaxation of proportionality whose approximability remains unresolved.
We begin by showing that three natural greedy algorithms fail to guarantee any
positive approximation to PROP1 in general, against an adaptive adversary. This
is surprising because greedy algorithms are commonly used in fair division and
a natural greedy algorithm is known to be able to achieve PROP1 under
additional information assumptions. This hardness result motivates the study of
non-adaptive adversaries and the use of side-information, in the spirit of
learning-augmented algorithms. For non-adaptive adversaries, we show that the
simple uniformly random allocation can achieve a meaningful PROP1 approximation
with high probability. Meanwhile, we present an algorithm that obtain robust
approximation ratios against PROP1 when given predictions of the maximum item
value (MIV). Interestingly, we also show that stronger fairness notions such as
EF1, MMS, and PROPX remain inapproximable even with perfect MIV predictions.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [413] [State dimension reduction of recurrent equilibrium networks with contraction and robustness preservation](https://arxiv.org/abs/2508.02843)
*M. F. Shakib*

Main category: eess.SY

TL;DR: 本文提出了一种基于投影的方法来降低递归均衡网络（REN）的状态维度，以实现其在资源受限设备上的部署。该方法通过利用已学习的收缩证书和h2-最优性条件来保留网络的鲁棒性和精度，并在数值示例中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决将大型递归均衡网络（REN）部署在资源受限的设备上的实时应用中的挑战，本研究提出了一种降低REN状态维度的方法。

Method: 提出一种基于投影的方法来降低训练好的REN的LTI部分的 seuqence 状态维度。其中一个投影矩阵用于保留收缩和鲁棒性，该投影矩阵利用了已学习的REN收缩证书。另一个投影矩阵被迭代更新，以基于LTI模型降阶的必要 h2-最优性条件来提高降阶REN的精度。

Result: 数值示例验证了该方法，表明该方法能够显著降低状态维度，同时具有有限的精度损失，并能保持收缩和鲁棒性。

Conclusion: 该方法通过利用已学习的REN收缩证书来保留收缩和鲁棒性，并通过迭代更新另一个投影矩阵来提高降阶REN的精度，从而在显著降低状态维度的同时，实现了有限的精度损失并保持了收缩和鲁棒性。

Abstract: Recurrent equilibrium networks (RENs) are effective for learning the dynamics
of complex dynamical systems with certified contraction and robustness
properties through unconstrained learning. While this opens the door to
learning large-scale RENs, deploying such large-scale RENs in real-time
applications on resource-limited devices remains challenging. Since a REN
consists of a feedback interconnection of linear time-invariant (LTI) dynamics
and static activation functions, this article proposes a projection-based
approach to reduce the state dimension of the LTI component of a trained REN.
One of the two projection matrices is dedicated to preserving contraction and
robustness by leveraging the already-learned REN contraction certificate. The
other projection matrix is iteratively updated to improve the accuracy of the
reduced-order REN based on necessary $h_2$-optimality conditions for LTI model
reduction. Numerical examples validate the approach, demonstrating significant
state dimension reduction with limited accuracy loss while preserving
contraction and robustness.

</details>


### [414] [Optimizing Preventive and Reactive Defense Resource Allocation with Uncertain Sensor Signals](https://arxiv.org/abs/2508.02881)
*Faezeh Shojaeighadikolaei,Shouhuai Xu,Keith Paarporn*

Main category: eess.SY

TL;DR: 该研究提出了一种新的网络安全资源分配模型，考虑了预防性防御和反应性防御的投资权衡，并强调了传感器信息质量对最优投资策略的影响。


<details>
  <summary>Details</summary>
Motivation: 标准的决策框架侧重于如何防止网络攻击，而忽略了成功攻击所造成的损害清理成本，因此需要研究一种新的资源分配问题。

Method: 提出了一种新的资源分配问题，并研究了传感器信号质量对防御者在两种防御类型上的投资策略的影响。

Result: 最优的预防性资源投资随传感器质量的提高而增加，反应性资源投资随之减少。当攻击者只能获得较低的攻击成功率时，与不使用传感器相比，防御者的性能提升最大。

Conclusion: 传感器的质量会影响防御者的投资策略，更高质量的传感器会使防御者投资于更多的预防性资源，从而减少对反应性资源的投资。在攻击者只能实现较低攻击成功率的情况下，与不使用传感器相比，防御者的性能提升最大。

Abstract: Cyber attacks continue to be a cause of concern despite advances in cyber
defense techniques. Although cyber attacks cannot be fully prevented, standard
decision-making frameworks typically focus on how to prevent them from
succeeding, without considering the cost of cleaning up the damages incurred by
successful attacks. This motivates us to investigate a new resource allocation
problem formulated in this paper: The defender must decide how to split its
investment between preventive defenses, which aim to harden nodes from attacks,
and reactive defenses, which aim to quickly clean up the compromised nodes.
This encounters a challenge imposed by the uncertainty associated with the
observation, or sensor signal, whether a node is truly compromised or not; this
uncertainty is real because attack detectors are not perfect. We investigate
how the quality of sensor signals impacts the defender's strategic investment
in the two types of defense, and ultimately the level of security that can be
achieved. In particular, we show that the optimal investment in preventive
resources increases, and thus reactive resource investment decreases, with
higher sensor quality. We also show that the defender's performance
improvement, relative to a baseline of no sensors employed, is maximal when the
attacker can only achieve low attack success probabilities.

</details>


### [415] [Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty](https://arxiv.org/abs/2508.02906)
*Mehmet Karahan*

Main category: eess.SY

TL;DR: 与被动悬架和 PID 控制的活动悬架相比，LQR 控制的活动悬架更舒适、更安全。


<details>
  <summary>Details</summary>
Motivation: 车辆悬架对于乘客舒适旅行以及减少振动和冲击影响至关重要。此外，良好的悬架系统还可以提高车辆的抓地力，确保安全转弯，并降低事故风险。被动悬架因其结构简单、成本低廉而被广泛使用，但其性能不如主动悬架。PID 控制器已广泛用于主动悬架系统，但 LQR 控制可以提供更优越的性能。

Method: 本研究设计了一种比被动悬架和 PID 控制的活动悬架更具鲁棒性的 LQR 控制活动悬架。对三种悬架进行了鲁棒性分析，并在道路扰动和同时存在的道路扰动和参数不确定性下模拟了悬架行程、簧上质量加速度和簧上质量运动。通过获得悬架的上升时间、超调量和沉降时间数据进行了比较分析。

Result: 与被动悬架和 PID 控制的活动悬架相比，LQR 控制的活动悬架表现出最小的超调量，并且具有最短的沉降时间。

Conclusion: 与被动悬架和 PID 控制的活动悬架相比，LQR 控制的活动悬架在振动和颠簸方面为乘客提供了更舒适、更安全的乘坐体验。

Abstract: Vehicle suspension is important for passengers to travel comfortably and to
be less exposed to effects such as vibration and shock. A good suspension
system in-creases the road holding of vehicles, allows them to take turns
safely and reduces the risk of traffic accidents. Passive suspension system is
the most widely used suspension system in vehicles due to its simple structure
and low cost. Passive suspension systems do not have an actuator and therefore
do not have a controller. Active suspension systems have an actuator and a
controller. Although their structures are more complex and costly, they are
safer. PID controller is widely used in active suspension systems due to its
simple structure, reasonable cost and easy adjustment of coefficients. In this
study, a more robust LQR controlled active suspension was designed than passive
sus-pension and PID controlled active suspension. Robustness analyses were
performed for passive suspension, PID controlled active suspension and LQR
controlled active sus-pension. Suspension travel, sprung mass acceleration and
sprung mass motion simulations were performed for all 3 suspensions under road
disturbance and under simultaneous road disturbance and parameter uncertainty.
A comparative analysis was performed by obtaining the suspension rise time,
overshoot and settling time data. It was observed that the LQR controlled
active suspension showed the least overshoot and had the shortest settling
time. In this case, it was proven that the LQR controlled active suspension
provided a more comfortable and safe ride compared to the other two suspension
systems.

</details>


### [416] [Integrating Upstream Supply Chains into Generation Expansion Planning](https://arxiv.org/abs/2508.03001)
*Boyu Yao,Andrey Bernstein,Yury Dvorkin*

Main category: eess.SY

TL;DR: 本文提出了一个考虑供应链约束的发电扩展规划模型，以解决传统模型忽视上游限制的问题。研究发现，供应链约束会影响技术选择、加剧部署延迟并可能增加成本，尤其是在高需求情况下，可能导致电力短缺。


<details>
  <summary>Details</summary>
Motivation: 电力需求的上升凸显了对安全可靠的发电扩展规划的需求，该规划需考虑上游供应链的制约。传统模型常常忽视材料、制造能力、部署提前期以及现场可用性等方面的限制，这些限制可能导致计划资源的可用性延迟，从而威胁系统可靠性。

Method: 本文引入了一个多阶段、受供应链约束的发电扩展规划（SC-GEP）模型，该模型在优化长期投资的同时，还考虑了材料可用性、生产限制、空间和时间约束以及退役资产的材料再利用。通过分解算法有效地解决了所得的混合整数线性规划（MILP）。

Result: 马里兰州的案例研究表明，供应链限制改变了技术选择，加剧了因提前期造成的部署延迟，并促使尽早投资于提前期较短、材料强度较低的选项。在低需求情况下，供应链限制使投资成本增加了12亿美元。在高需求情况下，出现了持续的发电和储备短缺，这凸显了将上游限制纳入长期规划的必要性。

Conclusion: 供应链限制会改变技术选择，加剧提前期造成的部署延迟，并促使尽早投资于提前期较短、材料强度较低的选项。在低需求情况下，供应链限制将投资成本增加了12亿美元。在高需求情况下，会出现持续的发电和储备短缺，这凸显了将上游限制纳入长期规划的必要性。

Abstract: Rising electricity demand underscores the need for secure and reliable
generation expansion planning that accounts for upstream supply chain
constraints. Traditional models often overlook limitations in materials,
manufacturing capacity, lead times for deployment, and field availability,
which can delay availability of planned resources and thus to threaten system
reliability. This paper introduces a multi-stage supply chain-constrained
generation expansion planning (SC-GEP) model that optimizes long-term
investments while capturing material availability, production limits, spatial
and temporal constraints, and material reuse from retired assets. A
decomposition algorithm efficiently solves the resulting MILP. A Maryland case
study shows that supply chain constraints shift technology choices, amplify
deployment delays caused by lead times, and prompt earlier investment in
shorter lead-time, low-material-intensity options. In the low-demand scenario,
supply chain constraints raise investment costs by $1.2 billion. Under high
demand, persistent generation and reserve shortfalls emerge, underscoring the
need to integrate upstream constraints into long-term planning.

</details>


### [417] [Power System Voltage Stability Boundary: Computational Results and Applications](https://arxiv.org/abs/2508.03119)
*Zhenyao Li,Yifan Yao,Deqiang Gan*

Main category: eess.SY

TL;DR: 本文提出了一种新的DAE正则化变换和计算方法，用于研究电力系统电压稳定边界，并通过算例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在报告DAE稳定性边界理论的一些计算结果，以期推进在电力系统电压稳定研究中的应用。

Method: 本文提出了一种新的标准微分代数方程（DAEs）正则化变换，并研究了电压稳定边界上锚点的存在性，提出了一种计算控制伪鞍点的优化方法，最后给出了伪鞍点在稳定边界上稳定流形的一种局部表示，并得到了电压稳定裕度表达式。

Result: 研究了电压稳定边界上锚点的存在性，并提出了一种计算控制伪鞍点的优化方法，最后得到了一种电压稳定裕度表达式。

Conclusion: 文中提出的方法通过数值算例得到了验证，证明了其准确性和有效性。

Abstract: The objective of this paper is to report some computational results for the
theory of DAE stability boundary, with the aim of advancing applications in
power system voltage stability studies. Firstly, a new regularization
transformation for standard differential-algebraic equations (DAEs) is
proposed. Then the existence of anchor points on voltage stability boundary is
examined, and an optimization method for computing the controlling
pseudo-saddle is suggested. Subsequently, a local representation of the stable
manifold of the pseudo-saddle on the stability boundary is presented, and a
voltage stability margin expression is obtained. Finally, the proposed results
are verified using several examples, demonstrating the accuracy and
effectiveness of the suggested methods.

</details>


### [418] [Filtering and 1/3 Power Law for Optimal Time Discretisation in Numerical Integration of Stochastic Differential Equations](https://arxiv.org/abs/2508.03135)
*Igor G. Vladimirov*

Main category: eess.SY

TL;DR: 本篇论文研究了随机微分方程的数值积分，并提出了一种新的网格优化方法，可以提高数值解的精度。


<details>
  <summary>Details</summary>
Motivation: 本篇论文涉及由标准维纳过程驱动的扩散过程的随机微分方程 (SDE) 的数值积分。

Method: 通过贝叶斯方法和中间时间间隔上的布朗桥更新条件概率分布，将随机微分方程的近似强解视为隐藏系统状态的估计。

Result: 在时间离散化由均匀网格的足够光滑的单调变换指定的情况下，对于一类多变量线性随机微分方程，该方法研究了终端和积分均方误差泛函的精细网格渐近行为，并揭示了渐近最优网格密度函数的 1/3 次幂定律。

Conclusion: 当时间离散化由均匀网格的足够光滑的单调变换指定时，对于一类多变量线性随机微分方程，我们研究了终端和积分均方误差泛函的精细网格渐近行为，并揭示了渐近最优网格密度函数的 1/3 次幂定律。

Abstract: This paper is concerned with the numerical integration of stochastic
differential equations (SDEs) which govern diffusion processes driven by a
standard Wiener process. With the latter being replaced by a sequence of
increments at discrete moments of time, we revisit a filtering point of view on
the approximate strong solution of the SDE as an estimate of the hidden system
state whose conditional probability distribution is updated using a Bayesian
approach and Brownian bridges over the intermediate time intervals. For a class
of multivariable linear SDEs, where the numerical solution is organised as a
Kalman filter, we investigate the fine-grid asymptotic behaviour of terminal
and integral mean-square error functionals when the time discretisation is
specified by a sufficiently smooth monotonic transformation of a uniform grid.
This leads to constrained optimisation problems over the time discretisation
profile, and their solutions reveal a 1/3 power law for the asymptotically
optimal grid density functions. As a one-dimensional example, the results are
illustrated for the Ornstein-Uhlenbeck process.

</details>


### [419] [An Event-based State Estimation Approach for Positive Systems with Positive Observers](https://arxiv.org/abs/2508.03154)
*Bhargavi Chaudhary,Krishanu Nath,Subashish Datta,Indra Narayan Kar*

Main category: eess.SY

TL;DR: 一种用于线性正网络系统的事件触发观测器设计，考虑了带宽限制和状态非负性，并通过数值模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决连续时间线性正网络系统状态观测器设计问题，特别是考虑通信网络中的带宽限制。

Method: 提出了一种基于事件测量的正观测器设计方法，该方法利用加权采样误差来确定采样序列，并采用标准的 Luenberger 结构设计观测器动力学，仅在事件发生时更新。

Result: 证明了在可观测性和系统正性条件满足的情况下，观测器动力学的渐近稳定性，并确保事件触发架构没有芝诺行为，从而保证了执行时间的正最小界限。通过对具有可变横截面的三罐式系统进行数值模拟，验证了所提出方法的有效性。

Conclusion: 该研究提出了一个事件触发的线性正系统状态观测器设计方法，并利用线性矩阵不等式推导了稳定性和正性条件。

Abstract: This article addresses the problem of state observer design for
continuous-time linear positive networked systems. Considering the bandwidth
constraint in the communication network, an event-measurement-based positive
observer design is proposed. The physical interpretation of a positive observer
differs from that of a general observer. Its primary goal is to ensure that all
state estimates remain non-negative at all times. Using output measurements, a
law with weighted sampling error is used to determine the sampling sequence
between the system and the observer. The observer dynamics are designed using
the standard Luenberger structure with the event-based sampled output
information, which is updated only when an event occurs. Assuming observability
and sufficient conditions for the positivity of the system, the asymptotic
stability of the observer dynamics with sampled information is established.
Sufficient conditions of stability and positivity are derived using linear
matrix inequalities. Moreover, the design ensures that the event-based
architecture is free from Zeno behavior, ensuring a positive minimum bound on
the inter-execution time. In addition, numerical simulations on a three-tank
system having variable cross-sections are used to demonstrate the efficacy of
the proposed event-based positive observer.

</details>


### [420] [Grid-Forming Vector Current Control FRT Modes Under Symmetrical and Asymmetrical Faults](https://arxiv.org/abs/2508.03389)
*Ognjen Stanojev,Orcun Karaca,Mario Schweizer*

Main category: eess.SY

TL;DR: 该研究为并网转换器提出了一种用于GFVCC的故障穿越（FRT）策略，以处理对称和不对称故障。


<details>
  <summary>Details</summary>
Motivation: 在并网转换器控制策略中，处理对称和不对称短路故障等电网故障场景非常重要。

Method: 通过为GFVCC的控制方案以模块化的方式扩展负序环路来解决对称和不对称故障，并通过案例研究进行了分析。

Result: 提出了适用于GFVCC的FRT策略，并已通过包含无限母线设置和多单元电网的案例研究进行了分析。

Conclusion: 该研究提出了适用于GFVCC的几种故障穿越（FRT）策略，使转换器能够在遵守转换器硬件限制和保持并网行为的同时，提供故障电流并与电网同步。

Abstract: Recent research has shown that operating grid-connected converters using the
grid-forming vector current control (GFVCC) scheme offers significant benefits,
including the simplicity and modularity of the control architecture, as well as
enabling a seamless transition from PLL-based grid-following control to
grid-forming. An important aspect of any grid-connected converter control
strategy is the handling of grid-fault scenarios such as symmetrical and
asymmetrical short-circuit faults. This paper presents several fault
ride-through (FRT) strategies for GFVCC that enable the converter to provide
fault current and stay synchronized to the grid while respecting the converter
hardware limitations and retaining grid-forming behavior. The converter control
scheme is extended in a modular manner to include negative-sequence loops, and
the proposed FRT strategies address both symmetrical and asymmetrical faults.
The proposed FRT strategies are analyzed through case studies, including
infinite-bus setups and multi-unit grids.

</details>


### [421] [A Robust Cooperative Vehicle Coordination Framework for Intersection Crossing](https://arxiv.org/abs/2508.03417)
*Haojie Bai,Jiping Luo,Huafu Li,Xiongwei Zhao,Yang Wang*

Main category: eess.SY

TL;DR: 针对信号灯不明确的路口，提出了一个包含鲁棒协同轨迹规划器和上下文感知状态更新调度器的协调框架，以解决现有研究中对车辆状态不确定性和通信限制的忽视。该框架通过概率安全保证和动态优先排序，提高了协调安全性和效率，尤其在带宽受限的情况下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有研究在交通信号灯不明确的路口协同车辆时，为提高交通流量和燃油效率，过度简化了协调系统，假设车辆状态信息准确且状态更新过程理想化。这种忽略在存在状态不确定性和通信约束的情况下会带来实际的驾驶风险。

Method: 提出了一种鲁棒且全面的交叉路口协调框架，包括一个鲁棒的协同轨迹规划器和一个上下文感知的状态更新调度器。轨迹规划器直接控制轨迹分布在频繁车辆交互过程中的演变，从而提供概率安全保证。为了进一步在实际带宽受限条件下对齐协调安全，提出了一种上下文感知的状态更新调度器，该调度器根据车辆的驾驶紧急程度动态地优先排序车辆的状态更新顺序。

Result: 仿真结果验证了所提出的协调框架的鲁棒性和有效性，表明与最先进的策略相比，该框架在保持可比的协调效率的同时，可以显著降低碰撞概率。此外，在实际不确定和带宽受限的条件下，所提出的框架在利用无线资源方面表现出卓越的有效性。

Conclusion: 该框架在实际不确定和带宽受限的条件下，能够显著降低碰撞概率，同时保持与最先进策略相当的协调效率，并能更有效地利用无线资源。

Abstract: Cooperative vehicle coordination at unsignalized intersections has garnered
significant interest from both academia and industry in recent years,
highlighting its notable advantages in improving traffic throughput and fuel
efficiency. However, most existing studies oversimplify the coordination
system, assuming accurate vehicle state information and ideal state update
process. The oversights pose driving risks in the presence of state uncertainty
and communication constraint. To address this gap, we propose a robust and
comprehensive intersection coordination framework consisting of a robust
cooperative trajectory planner and a context-aware status update scheduler. The
trajectory planner directly controls the evolution of the trajectory
distributions during frequent vehicle interactions, thereby offering
probabilistic safety guarantees. To further align with coordination safety in
practical bandwidth-limited conditions, we propose a context-aware status
update scheduler that dynamically prioritizes the state updating order of
vehicles based on their driving urgency. Simulation results validate the
robustness and effectiveness of the proposed coordination framework, showing
that the collision probability can be significantly reduced while maintaining
comparable coordination efficiency to state-of-theart strategies. Moreover, our
proposed framework demonstrates superior effectiveness in utilizing wireless
resources in practical uncertain and bandwidth-limited conditions.

</details>


### [422] [Improving Q-Learning for Real-World Control: A Case Study in Series Hybrid Agricultural Tractors](https://arxiv.org/abs/2508.03647)
*Hend Abououf,Sidra Ghayour Bhatti,Qadeer Ahmed*

Main category: eess.SY

TL;DR: Reinforcement learning algorithms like DDQN, DQN, and DQL were tested for hybrid tractor energy management. A new reward system and the use of expert examples significantly sped up learning and improved fuel efficiency, with DDQN converging 70% faster and expert data boosting convergence by 33%.


<details>
  <summary>Details</summary>
Motivation: The motivation for this research stems from the challenges in designing optimal rule-based energy management strategies for hybrid agricultural tractors due to variable and unpredictable load demands. This difficulty motivates the use of adaptive, learning-based control, addressing the limitations of existing approaches that use basic fuel-based rewards and do not leverage expert demonstrations to speed up training.

Method: The paper evaluates three Q-value-based reinforcement learning algorithms (Double Q-Learning, Deep Q-Networks, and Double DQN) for powertrain control in a hybrid agricultural tractor. It also introduces a piecewise domain-specific reward-shaping strategy and examines the effect of seeding the experience replay buffer with expert demonstrations, analyzing different expert policy types.

Result: Experimental results indicate that Double DQN offers 70% faster convergence compared to Deep Q-Networks for this application. The proposed reward shaping method effectively guides the learned policy towards fuel-efficient operation. Furthermore, initializing the replay buffer with structured expert data results in a 33% increase in convergence speed.

Conclusion: The study successfully evaluates Q-value-based reinforcement learning algorithms (DDQN, DQN, DQL) for hybrid agricultural tractor powertrain control, introduces an effective reward-shaping strategy, and demonstrates the benefits of expert demonstrations in accelerating training and improving performance. The results show DDQN's faster convergence, the reward shaping's positive impact on fuel efficiency, and the significant improvement gained from initializing the replay buffer with expert data.

Abstract: The variable and unpredictable load demands in hybrid agricultural tractors
make it difficult to design optimal rule-based energy management strategies,
motivating the use of adaptive, learning-based control. However, existing
approaches often rely on basic fuel-based rewards and do not leverage expert
demonstrations to accelerate training. In this paper, first, the performance of
Q-value-based reinforcement learning algorithms is evaluated for powertrain
control in a hybrid agricultural tractor. Three algorithms, Double Q-Learning
(DQL), Deep Q-Networks (DQN), and Double DQN (DDQN), are compared in terms of
convergence speed and policy optimality. Second, a piecewise domain-specific
reward-shaping strategy is introduced to improve learning efficiency and steer
agent behavior toward engine fuel-efficient operating regions. Third, the
design of the experience replay buffer is examined, with a focus on the effects
of seeding the buffer with expert demonstrations and analyzing how different
types of expert policies influence convergence dynamics and final performance.
Experimental results demonstrate that (1) DDQN achieves 70\% faster convergence
than DQN in this application domain, (2) the proposed reward shaping method
effectively biases the learned policy toward fuel-efficient outcomes, and (3)
initializing the replay buffer with structured expert data leads to a 33\%
improvement in convergence speed.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [423] [An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method](https://arxiv.org/abs/2508.02687)
*Yijia Hao,Maarten Strackx,Miguel Gandara,Sandy Cochran,Bo Liu*

Main category: eess.SP

TL;DR: 通过AI驱动的协同设计，优化了LDO供电的VCO性能，改善了相位噪声和功耗。


<details>
  <summary>Details</summary>
Motivation: 传统设计方法无法充分解决高频噪声和LDO引起的低频相位噪声之间的权衡问题。

Method: 提出了一种AI驱动的EDA协同设计算法，用于优化低相位噪声LC-tank VCO与LDO的性能。

Result: 所提出的协同设计方法将5.6 GHz LC-tank VCO的相位噪声在1 MHz偏移处改善了1.2 dB，将动态功耗降低了28.8%，FoM提高了2.4 dBc/Hz。

Conclusion: 提出了一种低相位噪声LC-tank VCO与LDO的协同设计方法，并使用AI驱动的EDA算法进行优化。

Abstract: Traditionally, the output noise and power supply rejection of low-dropout
regulators (LDOs) are optimized to minimize power supply fluctuations, reducing
their impact on the low-frequency noise of target voltage-controlled
oscillators (VCOs). However, this sequential design approach does not fully
address the trade-offs between high-frequency and LDO-induced low-frequency
phase noise. To overcome this limitation, this paper presents a co-design
method for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to
carry out the co-design using traditional manual design techniques. Hence, an
efficient AI-driven EDA algorithm is used. To validate the proposed method, a
5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS
process. Simulations show that the co-design method improves phase noise by 1.2
dB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM
increased by 2.4 dBc/Hz compared to the conventional sequential design method.

</details>


### [424] [On Improving PPG-Based Sleep Staging: A Pilot Study](https://arxiv.org/abs/2508.02689)
*Jiawei Wang,Yu Guan,Chen Chen,Ligang Zhou,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 该研究通过引入双流交叉注意力机制，结合PPG信号及其辅助信息（如增强PPG或合成ECG），显著提升了睡眠分期的准确性，并在MESA数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在普遍计算中，通过可穿戴技术进行睡眠监测对于提高福祉至关重要，但单独使用PPG传感器实现可靠的睡眠分期仍然是一个挑战。

Method: 比较了基于PPG的单流模型与双流交叉注意力策略，并利用PPG及其派生模态（如增强PPG或合成ECG）来学习互补信息。

Result: 研究结果表明，在MESA数据集上，双流交叉注意力方法在四阶段睡眠监测任务上优于单流模型。

Conclusion: 通过结合PPG及其辅助信息，在双流交叉注意力架构下可以显著提高睡眠分期性能。

Abstract: Sleep monitoring through accessible wearable technology is crucial to
improving well-being in ubiquitous computing. Although
photoplethysmography(PPG) sensors are widely adopted in consumer devices,
achieving consistently reliable sleep staging using PPG alone remains a
non-trivial challenge. In this work, we explore multiple strategies to enhance
the performance of PPG-based sleep staging. Specifically, we compare
conventional single-stream model with dual-stream cross-attention strategies,
based on which complementary information can be learned via PPG and PPG-derived
modalities such as augmented PPG or synthetic ECG. To study the effectiveness
of the aforementioned approaches in four-stage sleep monitoring task, we
conducted experiments on the world's largest sleep staging dataset, i.e., the
Multi-Ethnic Study of Atherosclerosis(MESA). We found that substantial
performance gain can be achieved by combining PPG and its auxiliary information
under the dual-stream cross-attention architecture. Source code of this project
can be found at https://github.com/DavyWJW/sleep-staging-models

</details>


### [425] [Can Large Language Models Identify Materials from Radar Signals?](https://arxiv.org/abs/2508.03120)
*Jiangyou Zhu,Hongyu Deng,He Chen*

Main category: eess.SP

TL;DR: 本研究提出了 LLMaterial，首次研究了使用大语言模型（LLM）直接从雷达信号识别材料的可行性。该方法结合了物理信息信号处理和检索增强生成（RAG）策略，使 LLM 能够从原始雷达数据中推断材料成分，克服了现有方法的局限性，并在区分常见材料方面取得了初步成效。


<details>
  <summary>Details</summary>
Motivation: 为了使由大语言模型（LLM）驱动的 AI 机器人能够执行上下文感知的操作，准确识别物体的材料成分至关重要。本研究旨在探索利用预训练 LLM 的强大推理能力，直接从原始雷达信号中推断材料成分的可行性，以克服现有雷达解决方案在闭集对象类别和任务特定数据收集方面的限制。

Method: 1. 提出一个物理信息信号处理流程，将高冗余的雷达原始数据提炼成一组紧凑的中间参数，以封装材料的内在特性。 2. 采用检索增强生成（RAG）策略，为大语言模型（LLM）提供领域特定知识，使其能够解释和推理提取的中间参数。 3. 利用这种集成，LLM 能够对精简后的雷达特征进行逐步推理，直接从原始雷达信号中实现开放集材料识别。

Result: LLMaterial 成功实现了开放集材料识别，能够区分多种常见材料。

Conclusion: LLMaterial 能够有效地从原始雷达信号中区分多种常见材料，显示出其在实际材料识别应用中的巨大潜力。

Abstract: Accurately identifying the material composition of objects is a critical
capability for AI robots powered by large language models (LLMs) to perform
context-aware manipulation. Radar technologies offer a promising sensing
modality for material recognition task. When combined with deep learning, radar
technologies have demonstrated strong potential in identifying the material of
various objects. However, existing radar-based solutions are often constrained
to closed-set object categories and typically require task-specific data
collection to train deep learning models, largely limiting their practical
applicability. This raises an important question: Can we leverage the powerful
reasoning capabilities of pre-trained LLMs to directly infer material
composition from raw radar signals? Answering this question is non-trivial due
to the inherent redundancy of radar signals and the fact that pre-trained LLMs
have no prior exposure to raw radar data during training. To address this, we
introduce LLMaterial, the first study to investigate the feasibility of using
LLM to identify materials directly from radar signals. First, we introduce a
physics-informed signal processing pipeline that distills high-redundancy radar
raw data into a set of compact intermediate parameters that encapsulate the
material's intrinsic characteristics. Second, we adopt a retrieval-augmented
generation (RAG) strategy to provide the LLM with domain-specific knowledge,
enabling it to interpret and reason over the extracted intermediate parameters.
Leveraging this integration, the LLM is empowered to perform step-by-step
reasoning on the condensed radar features, achieving open-set material
recognition directly from raw radar signals. Preliminary results show that
LLMaterial can effectively distinguish among a variety of common materials,
highlighting its strong potential for real-world material identification
applications.

</details>


### [426] [Federated Learning in Active STARS-Aided Uplink Networks](https://arxiv.org/abs/2508.02693)
*Xinwei Yue,Xinning Guo,Xidong Mu,Jingjing Zhao,Peng Yang,Junsheng Mu,Zhiping Lu*

Main category: eess.SP

TL;DR: ASTARS improve federated learning by reshaping the electromagnetic environment and enabling over-the-air computing for reduced parameter uploads. The system enhances accuracy, especially with discrete data, and optimizes beamforming and phase shifting. Amplification power is crucial but must be balanced to avoid thermal noise limitations.


<details>
  <summary>Details</summary>
Motivation: Utilize ASTARS to assist federated learning (FL) uplink model transfer and reduce uploaded parameter counts through over-the-air (OTA) computing.

Method: Characterize the impact of model aggregation errors on ASTARS-aided FL uplink networks, derive an upper bound on aggregation error, and quantify training loss. Define performance as a joint optimization problem for received beam assignment and ASTARS phase shifting.

Result: ASTARS-aided FL networks show improved accuracy compared to state-of-the-art. ASTARS-enabled FL systems achieve better learning accuracy with fewer active units, particularly for discrete datasets. FL accuracy increases with amplification power, up to a point where thermal noise becomes dominant.

Conclusion: ASTARS-aided FL systems enhance FL accuracy compared to state-of-the-art networks and achieve better learning accuracy with fewer active units, especially for discrete datasets. Higher amplification power improves accuracy, but excessive power introduces thermal noise.

Abstract: Active simultaneously transmitting and reflecting surfaces (ASTARS) have
attracted growing research interest due to its ability to alleviate
multiplicative fading and reshape the electromagnetic environment across the
entire space. In this paper, we utilise ASTARS to assist the federated learning
(FL) uplink model transfer and further reduce the number of uploaded parameter
counts through over-the-air (OTA) computing techniques. The impact of model
aggregation errors on ASTARS-aided FL uplink networks is characterized. We
derive an upper bound on the aggregation error of the OTA-FL model and quantify
the training loss due to communication errors. Then, we define the performance
of OTA-FL as a joint optimization problem that encompasses both the assignment
of received beams and the phase shifting of ASTARS, aiming to achieve the
maximum learning efficiency and high-quality signal transmission. Numerical
results demonstrate that: i) The FL accuracy in ASTARS uplink networks are
enhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled
FL system achieves the better learning accuracy using fewer active units than
other baseline, especially when the dataset is more discrete; and iii) FL
accuracy improves with higher amplification power, but excessive amplification
makes thermal noise the dominant source of error.

</details>


### [427] [Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG](https://arxiv.org/abs/2508.03274)
*Ramaswamy Palaniappan,Surej Mouli,Howard Bowman,Ian McLoughlin*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Half of all road accidents result from either lack of driver attention or
from maintaining insufficient separation between vehicles. Collision from the
rear, in particular, has been identified as the most common class of accident
in the UK, and its influencing factors have been widely studied for many years.
Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to
alert following drivers to the need to reduce speed or brake. This paper
develops a novel brain response approach to measuring subject reaction to
different brake light designs. A variety of off-the-shelf brake light
assemblies are tested in a physical simulated driving environment to assess the
cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs
of incandescent bulb-based brake light assemblies are used and
electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the
P3 component evoked during the decision making process that occurs in the brain
when a participant decides to lift their foot from the accelerator and depress
the brake. EEG analysis shows that both incandescent bulb-based lights are
statistically slower to evoke cognitive responses than all tested LED-based
lights. Between the LED designs, differences are evident, but not statistically
significant, attributed to the significant amount of movement artifact in the
EEG signal.

</details>


### [428] [A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting](https://arxiv.org/abs/2508.02698)
*Sameera Bharadwaja H.,D. K. Mehra*

Main category: eess.SP

TL;DR: 本篇論文提出一種新的方法，透過預編碼和分割星座圖來解決 OFDM 系統中，第二類統計資料（SOS）盲通道估計的模糊問題。


<details>
  <summary>Details</summary>
Motivation: 現有的第二類統計資料（SOS）盲通道估計法，都有複雜純量估計模糊的問題，需要額外的導引信號或參考符號來解決。

Method: 透過頻域線性無冗餘預編碼和分割星座圖於交錯的子載波來解決此模糊問題。

Result: 數值模擬結果顯示，此新提出的方法在M-ary PAM系統中，表現如同半盲方法一樣好。

Conclusion: 所提出的盲法可解決現有技術中複雜的純量估計模糊問題，並且其表現可媲美半盲的對比。

Abstract: The problem of second-order statistics (SOS)-based blind channel estimation
in OFDM systems is addressed in this paper. Almost all SOS-based methods
proposed so far suffer from a complex-scalar estimation ambiguity, which is
resolved by using pilots or reference symbols. We propose an algorithm to
resolve this ambiguity in blind manner using frequency-domain linear
non-redundant precoding and constellation-splitting among the alternate
subcarriers. The performance of the proposed scheme is evaluated via numerical
simulations in MATLAB environment. Simulation results show that the proposed
approach performs as good as its semi-blind counterpart for M-ary PAM systems.

</details>


### [429] [Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations](https://arxiv.org/abs/2508.02703)
*Evangelos Sariyanidi,John D. Herrington,Lisa Yankowitz,Pratik Chaudhari,Theodore D. Satterthwaite,Casey J. Zampella,Robert T. Schultz,Russell T. Shinohara,Birkan Tunc*

Main category: eess.SP

TL;DR: “concurrent”是一种新的自监督方法，可以衡量统计依赖性，尤其擅长处理生物系统中的非线性相互作用。它可以在不需要先验知识的情况下发现跨各种信号的关系，但用户仍需验证所发现的关系是否与他们的研究问题相关。


<details>
  <summary>Details</summary>
Motivation: 生物系统常常表现出复杂的非线性相互作用，而目前无法在不知道依赖性质的先验知识的情况下捕捉这些相互作用。

Method: 提出了一种名为“concurrent”的自监督方法，该方法受一个想法的启发：如果两个信号是相关的，那么应该能够区分从它们中提取的、时间上对齐的和错位的片段。

Result: 实验结果表明，“concurrent”能够揭示广泛信号谱中的关系，并提取科学相关差异，而无需进行ad-hoc参数调整或依赖先验信息。

Conclusion: “concurrent”是第一个能够揭示广泛信号谱中的关系并提取科学相关差异的方法，而无需进行 것입니다腺朴_a_hoc 参数调整或依赖先验信息，为跨领域的科学发现提供了有力的工具。然而，由外部因素引起的相关性仍然是一个有待解决的问题，因此研究人员应验证所揭示的关系是否真正与其研究的问题相关。

Abstract: Measuring the statistical dependence between observed signals is a primary
tool for scientific discovery. However, biological systems often exhibit
complex non-linear interactions that currently cannot be captured without a
priori knowledge regarding the nature of dependence. We introduce a
self-supervised approach, concurrence, which is inspired by the observation
that if two signals are dependent, then one should be able to distinguish
between temporally aligned vs. misaligned segments extracted from them.
Experiments with fMRI, physiological and behavioral signals show that, to our
knowledge, concurrence is the first approach that can expose relationships
across such a wide spectrum of signals and extract scientifically relevant
differences without ad-hoc parameter tuning or reliance on a priori
information, providing a potent tool for scientific discoveries across fields.
However, depencencies caused by extraneous factors remain an open problem, thus
researchers should validate that exposed relationships truely pertain to the
question(s) of interest.

</details>


### [430] [Evaluation of Deep Learning Models for LBBB Classification in ECG Signals](https://arxiv.org/abs/2508.02710)
*Beatriz Macas Ordóñez,Diego Vinicio Orellana Villavicencio,José Manuel Ferrández,Paula Bonomini*

Main category: eess.SP

TL;DR: 本研究评估了不同神经网络架构在ECG信号分类中的应用，特别是LBBB的识别，以优化CRT治疗的候选者选择。


<details>
  <summary>Details</summary>
Motivation: 通过优化左束支传导阻滞（LBBB）受试者的分类，临床相关性、创新技术能够选择心脏再同步化治疗（CRT）的候选者。

Method: 本研究探索了不同的神经网络架构。

Result: 该研究评估了不同神经网络架构从心电图（ECG）信号中提取时空模式并将其分类为健康受试者、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）三组的能力。

Conclusion:  该研究评估了不同神经网络架构从心电图（ECG）信号中提取时空模式并将其分类为健康受试者、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）三组的能力。

Abstract: This study explores different neural network architectures to evaluate their
ability to extract spatial and temporal patterns from electrocardiographic
(ECG) signals and classify them into three groups: healthy subjects, Left
Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).
  Clinical Relevance, Innovative technologies enable the selection of
candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the
classification of subjects with Left Bundle Branch Block (LBBB).

</details>


### [431] [Decoding and Engineering the Phytobiome Communication for Smart Agriculture](https://arxiv.org/abs/2508.03584)
*Fatih Gulec,Hamdan Awan,Nigel Wallbridge,Andrew W. Eckford*

Main category: eess.SP

TL;DR: This paper uses communication theory to understand plant-environment interactions (phytobiome) for smart agriculture, proposing applications like smart irrigation and targeted pesticide delivery using AI and new tech, despite implementation hurdles.


<details>
  <summary>Details</summary>
Motivation: To advance agricultural science and practice using communication theory by applying a communication engineering perspective to understand phytobiome communication and its connection to smart agriculture, addressing challenges like food demand, environmental pollution, and water scarcity.

Method: The paper conceptualizes a multi-scale framework modeling the phytobiome as a communication network, demonstrating its use with plant experiments on electrophysiological signals. It also merges ML/AI with the Internet of Bio-Nano-Things enabled by molecular communication.

Result: A conceptual framework for modeling phytobiome communication is presented and demonstrated. Proposed applications include smart irrigation and targeted agrochemical delivery, merging ML/AI with the Internet of Bio-Nano-Things.

Conclusion: The article proposes a communication engineering perspective to understand phytobiome communication and bridge it with smart agriculture, offering applications like smart irrigation and targeted agrochemical delivery. It also discusses implementation challenges and future research directions.

Abstract: Smart agriculture applications, integrating technologies like the Internet of
Things and machine learning/artificial intelligence (ML/AI) into agriculture,
hold promise to address modern challenges of rising food demand, environmental
pollution, and water scarcity. Alongside the concept of the phytobiome, which
defines the area including the plant, its environment, and associated
organisms, and the recent emergence of molecular communication (MC), there
exists an important opportunity to advance agricultural science and practice
using communication theory. In this article, we motivate to use the
communication engineering perspective for developing a holistic understanding
of the phytobiome communication and bridge the gap between the phytobiome
communication and smart agriculture. Firstly, an overview of phytobiome
communication via molecular and electrophysiological signals is presented and a
multi-scale framework modeling the phytobiome as a communication network is
conceptualized. Then, how this framework is used to model electrophysiological
signals is demonstrated with plant experiments. Furthermore, possible smart
agriculture applications, such as smart irrigation and targeted delivery of
agrochemicals, through engineering the phytobiome communication are proposed.
These applications merge ML/AI methods with the Internet of Bio-Nano-Things
enabled by MC and pave the way towards more efficient, sustainable, and
eco-friendly agricultural production. Finally, the implementation challenges,
open research issues, and industrial outlook for these applications are
discussed.

</details>


### [432] [Physics-guided denoiser network for enhanced additive manufacturing data quality](https://arxiv.org/abs/2508.02712)
*Pallock Halder,Satyajit Mojumder*

Main category: eess.SP

TL;DR: 提出了一种结合了能量模型和 Fisher 分数正则化的物理信息去噪框架，用于去除传感器数据噪声并保持物理一致性。该方法在基准问题和 LPBF 增材制造实验中均表现良好，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现代工程系统中传感器数据噪声大、难以解释的问题，限制了其在控制和诊断方面的应用。

Method: 提出了一种物理信息去噪框架，结合了基于能量的模型和 Fisher 分数正则化，以联合减少数据噪声并强制执行与基于物理的模型的一致性。首先在简单谐振子、Burgers 方程和 Laplace 方程等基准问题上进行了验证，然后将该框架应用于 LPBF 增材制造实验的实际热发射数据，并使用 LPBF 工艺的 PINN 代理模型指导去噪。

Result: 所提出的方法在 LPBF 实验数据上表现优于基线去噪器，能够有效降低噪声。

Conclusion: 该方法在不同激光粉末床熔融（LPBF）工艺条件下有效降低了噪声，优于基线方法，实现了对低成本传感器数据的鲁棒、实时解释，有助于预测控制和改进增材制造中的缺陷缓解。

Abstract: Modern engineering systems are increasingly equipped with sensors for
real-time monitoring and decision-making. However, the data collected by these
sensors is often noisy and difficult to interpret, limiting its utility for
control and diagnostics. In this work, we propose a physics-informed denoising
framework that integrates energy-based model and Fisher score regularization to
jointly reduce data noise and enforce physical consistency with a physics-based
model. The approach is first validated on benchmark problems, including the
simple harmonic oscillator, Burgers' equation, and Laplace's equation, across
varying noise levels. We then apply the denoising framework to real thermal
emission data from laser powder bed fusion (LPBF) additive manufacturing
experiments, using a trained Physics-Informed Neural Network (PINN) surrogate
model of the LPBF process to guide denoising. Results show that the proposed
method outperforms baseline neural network denoisers, effectively reducing
noise under a range of LPBF processing conditions. This physics-guided
denoising strategy enables robust, real-time interpretation of low-cost sensor
data, facilitating predictive control and improved defect mitigation in
additive manufacturing.

</details>


### [433] [Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach](https://arxiv.org/abs/2508.02713)
*Pengxu Lin,An-An Lu,Xiqi Gao*

Main category: eess.SP

TL;DR: 提出一种基于辛优化的预编码器设计方法，用于解决UCN大规模MIMO系统中传统预编码器的高计算复杂度问题，并在仿真中证明其优于WMMSE预编码器。


<details>
  <summary>Details</summary>
Motivation: 为了解决用户中心网络（UCN）大规模多输入多输出（MIMO）系统中传统线性预编码器中矩阵求逆带来的高计算复杂度问题。

Method: 利用辛优化框架，将加权和速率（WSR）最大化问题转化为一个基于耗散哈密顿动力学系统的优化问题。通过将目标函数视为势能，并利用能量耗散的特性，使系统收敛到势能最小的状态。通过保持辛结构离散化连续系统，得到一种迭代的预编码器设计方法。

Result: 提出的基于辛优化的预编码器设计方法，相比于加权最小均方误差（WMMSE）预编码器，在UCN大规模MIMO系统中表现出更优的性能，并且具有高计算效率。

Conclusion: 该研究提出了一种基于辛优化（symplectic optimization）的预编码器设计方法，用于用户中心网络（UCN）大规模多输入多输出（MIMO）系统，并在仿真中证明其优于传统的加权最小均方误差（WMMSE）预编码器。

Abstract: In this paper, we utilize symplectic optimization to design a precoder for
user-centric network (UCN) massive multiple-input multiple-output (MIMO)
systems, where a subset of base stations (BSs) serves each user terminal (UT)
instead of using all BSs. In UCN massive MIMO systems, the dimension of the
precoders is reduced compared to conventional network massive MIMO. It
simplifies the implementation of precoders in practical systems. However, the
matrix inversion in traditional linear precoders still requires high
computational complexity. To avoid the matrix inversion, we employ the
symplectic optimization framework, where optimization problems are solved based
on dissipative Hamiltonian dynamical systems. To better fit symplectic
optimization, we transform the received model into the real field and
reformulate the weighted sum-rate (WSR) maximization problem. The objective
function of the optimization problem is viewed as the potential energy of the
dynamical system. Due to energy dissipation, the continuous dynamical system
always converges to a state with minimal potential energy. By discretizing the
continuous system while preserving the symplectic structure, we obtain an
iterative method for the precoder design. The complexity analysis of the
proposed symplectic method is also provided to show its high computational
efficiency. Simulation results demonstrate that the proposed precoder design
based on symplectic optimization outperforms the weighted minimum mean-square
error (WMMSE) precoder in the UCN massive MIMO system.

</details>


### [434] [SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG](https://arxiv.org/abs/2508.02718)
*Zahra Mohammadi,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 提出了一种名为SleepLiteCNN的节能卷积神经网络，用于在可穿戴设备上通过心电图高精度、高时间分辨率地检测睡眠呼吸暂停亚型，实现了高准确率和低能耗。


<details>
  <summary>Details</summary>
Motivation: 为了满足可穿戴设备对睡眠呼吸暂停亚型（阻塞性、中度、混合性）进行高时间分辨率和实时检测的需求。

Method: 提出了一种使用单导联心电图（ECG）对睡眠呼吸暂停亚型（阻塞性、中度、混合性）进行分类的节能方法，并对多种经典的机器学习算法和深度学习架构在1秒ECG窗口上进行了评估，最后提出了一种名为SleepLiteCNN的紧凑且节能的卷积神经网络。

Result: SleepLiteCNN达到了95%以上的准确率和92%的宏F1分数，并且在8位量化后每次推理仅消耗1.8微焦耳的能量。FPGA综合结果也证实了其在节能环境下连续实时监测的适用性。

Conclusion: SleepLiteCNN是一种实用且有效的解决方案，可用于可穿戴设备中的睡眠呼吸暂停亚型检测，其准确率超过95%，宏F1分数达到92%，每次推理仅需1.8微焦耳。

Abstract: Apnea is a common sleep disorder characterized by breathing interruptions
lasting at least ten seconds and occurring more than five times per hour.
Accurate, high-temporal-resolution detection of sleep apnea subtypes -
Obstructive, Central, and Mixed - is crucial for effective treatment and
management. This paper presents an energy-efficient method for classifying
these subtypes using a single-lead electrocardiogram (ECG) with high temporal
resolution to address the real-time needs of wearable devices. We evaluate a
wide range of classical machine learning algorithms and deep learning
architectures on 1-second ECG windows, comparing their accuracy, complexity,
and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a
compact and energy-efficient convolutional neural network specifically designed
for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92%
macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit
quantization. Field Programmable Gate Array (FPGA) synthesis further
demonstrates significant reductions in hardware resource usage, confirming its
suitability for continuous, real-time monitoring in energy-constrained
environments. These results establish SleepLiteCNN as a practical and effective
solution for wearable device sleep apnea subtype detection.

</details>


### [435] [Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition](https://arxiv.org/abs/2508.02847)
*Ke Xu,Chaitanya Krishna Prasad Vallabh,Souran Manoochehri*

Main category: eess.SP

TL;DR: 通过整合声学和视觉传感器并应用机器学习，可以精确监测激光3D打印过程中的几何变化，提高零件质量。


<details>
  <summary>Details</summary>
Motivation: 激光定向能量沉积（DED）增材制造因复杂熔池动力学和过程变化导致零件质量不一致。现有研究多集中于缺陷检测，但对评估熔池动力学和过程质量的过程监测系统的验证研究不足。

Method: 提出了一种新颖的多模态监测框架，集成了基于接触的声发射（AE）传感和同轴相机视觉。对传感器数据进行了预处理，包括AE信号的时域和频域特征提取，以及相机数据的熔池分割和形态特征提取。评估了包括SVM、随机森林和XGBoost在内的多种机器学习算法，以识别和评估逐层几何尺寸变化。

Result: 多模态监测策略实现了94.4%的卓越分类性能，相比之下，仅使用AE为87.8%，仅使用相机为86.7%。实验验证表明，集成系统能有效捕捉与几何尺寸变化相关的结构振动特征和表面形貌变化。

Conclusion: 本研究提出的多模态监测框架，结合了声发射传感和同轴相机视觉，能够有效地识别和评估激光定向能量沉积增材制造过程中几何尺寸的变化，实现了94.4%的分类性能，优于单独使用任一传感器的效果，为未来监测制造缺陷和几何误差奠定了基础。

Abstract: Laser directed energy deposition (DED) additive manufacturing struggles with
consistent part quality due to complex melt pool dynamics and process
variations. While much research targets defect detection, little work has
validated process monitoring systems for evaluating melt pool dynamics and
process quality. This study presents a novel multimodal monitoring framework,
synergistically integrating contact-based acoustic emission (AE) sensing with
coaxial camera vision to enable layer-wise identification and evaluation of
geometric variations in DED parts. The experimental study used three part
configurations: a baseline part without holes, a part with a 3mm diameter
through-hole, and one with a 5mm through-hole to test the system's discerning
capabilities. Raw sensor data was preprocessed: acoustic signals were filtered
for time-domain and frequency-domain feature extraction, while camera data
underwent melt pool segmentation and morphological feature extraction. Multiple
machine learning algorithms (including SVM, random forest, and XGBoost) were
evaluated to find the optimal model for classifying layer-wise geometric
variations. The integrated multimodal strategy achieved a superior
classification performance of 94.4%, compared to 87.8% for AE only and 86.7%
for the camera only. Validation confirmed the integrated system effectively
captures both structural vibration signatures and surface morphological changes
tied to the geometric variations. While this study focuses on specific
geometries, the demonstrated capability to discriminate between features
establishes a technical foundation for future applications in characterizing
part variations like geometric inaccuracies and manufacturing-induced defects.

</details>


### [436] [Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction](https://arxiv.org/abs/2508.02724)
*Yahia Dalbah,Marcel Worring,Yen-Chia Hsu*

Main category: eess.SP

TL;DR: Veli是一种无监督贝叶斯模型，利用变分推断校正低成本空气质量传感器读数，无需参考站。同时发布了最大的空气质量传感器基准数据集AQ-SDR。Veli模型泛化能力强，能处理传感器漂移和异常行为。


<details>
  <summary>Details</summary>
Motivation: 城市空气污染是导致每年数百万人过早死亡的重大健康危机，因此迫切需要准确且可扩展的空气质量（AQ）监测方法。低成本传感器（LCS）虽然提供了一种可扩展的替代方案，但其读数易受漂移、校准误差和环境干扰的影响。为了解决这些挑战，需要一种无需参考站点即可校正LCS读数的方法。

Method: 提出了一种名为Veli（Reference-free Variational Estimation via Latent Inference）的无监督贝叶斯模型，该模型利用变分推断来校正低成本传感器（LCS）的读数，无需与参考站点共置。模型通过构建LCS读数的解耦表示，将真实污染物读数与传感器噪声有效分离。同时，引入了空气质量传感器数据存储库（AQ-SDR），这是迄今为止最大的空气质量监测基准数据集，包含来自23,737个LCS和参考站点的数据。

Result: Veli模型在处理传感器漂移和异常行为方面表现出强大的泛化能力，在同分布和异分布设置下均表现良好。AQ-SDR数据集是迄今为止最大的空气质量传感器基准数据集。

Conclusion: Veli模型在无参考站点的情况下，通过利用变分推断来校正低成本传感器（LCS）的读数，有效解决了城市空气质量监测中的漂移、校准误差和环境干扰问题。此外， AQ-SDR作为最大的空气质量传感器基准数据集，为该领域提供了标准化基准。Veli模型在处理传感器漂移和异常行为方面表现出强大的泛化能力。

Abstract: Urban air pollution is a major health crisis causing millions of premature
deaths annually, underscoring the urgent need for accurate and scalable
monitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable
alternative to expensive reference-grade stations, their readings are affected
by drift, calibration errors, and environmental interference. To address these
challenges, we introduce Veli (Reference-free Variational Estimation via Latent
Inference), an unsupervised Bayesian model that leverages variational inference
to correct LCS readings without requiring co-location with reference stations,
eliminating a major deployment barrier. Specifically, Veli constructs a
disentangled representation of the LCS readings, effectively separating the
true pollutant reading from the sensor noise. To build our model and address
the lack of standardized benchmarks in AQ monitoring, we also introduce the Air
Quality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor
benchmark to date, with readings from 23,737 LCS and reference stations across
multiple regions. Veli demonstrates strong generalization across both
in-distribution and out-of-distribution settings, effectively handling sensor
drift and erratic sensor behavior. Code for model and dataset will be made
public when this paper is published.

</details>


### [437] [SpectrumFM: A New Paradigm for Spectrum Cognition](https://arxiv.org/abs/2508.02742)
*Chunyu Liu,Hao Zhang,Wei Wu,Fuhui Zhou,Qihui Wu,Derrick Wing Kwan Ng,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 提出了一种名为SpectrumFM的频谱基础模型，通过创新的频谱编码器和自监督学习任务进行预训练，并利用LoRA进行微调，在频谱感知、异常检测和无线技术分类任务中取得了显著优于现有方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的频谱认知方法在多样化的频谱环境和任务中泛化能力有限且精度不佳，因此需要一种新的方法来克服这些挑战，以增强频谱效率和实现安全的频谱利用。

Method: 提出了一种名为SpectrumFM的频谱基础模型，采用结合卷积神经网络和多头自注意力机制的频谱编码器来捕捉频谱数据的局部和全局依赖关系。通过掩码重构和下一时隙信号预测这两种新的自监督学习任务进行预训练，并利用低秩自适应（LoRA）进行参数高效微调，以适应不同的频谱认知任务。

Result: 实验结果表明，SpectrumFM在频谱感知任务上的检测概率在-4 dB信噪比下提高了30%，在异常检测任务上的AUC提升了10%以上，在无线技术分类任务上的准确性提高了9.6%，优于现有最先进的方法。

Conclusion: SpectrumFM在频谱感知、异常检测和无线技术分类等下游频谱感知任务中展现出优越性，通过参数高效微调有效适应不同任务，显著提高了检测概率、AUC和准确性。

Abstract: The enhancement of spectrum efficiency and the realization of secure spectrum
utilization are critically dependent on spectrum cognition. However, existing
spectrum cognition methods often exhibit limited generalization and suboptimal
accuracy when deployed across diverse spectrum environments and tasks. To
overcome these challenges, we propose a spectrum foundation model, termed
SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative
spectrum encoder that exploits the convolutional neural networks and the
multi-head self attention mechanisms is proposed to effectively capture both
fine-grained local signal structures and high-level global dependencies in the
spectrum data. To enhance its adaptability, two novel self-supervised learning
tasks, namely masked reconstruction and next-slot signal prediction, are
developed for pre-training SpectrumFM, enabling the model to learn rich and
transferable representations. Furthermore, low-rank adaptation (LoRA)
parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly
adapt to various downstream spectrum cognition tasks, including spectrum
sensing (SS), anomaly detection (AD), and wireless technology classification
(WTC). Extensive experiments demonstrate the superiority of SpectrumFM over
state-of-the-art methods. Specifically, it improves detection probability in
the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under
the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.

</details>


### [438] [Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information](https://arxiv.org/abs/2508.02799)
*Jessica Sanson,Rahul C. Shah,Maximilian Pinaroc,Valerio Frascolla*

Main category: eess.SP

TL;DR: 本论文首次提出一种利用商用Wi-Fi CSI和单收发器设置提取距离和多普勒信息的方法。通过时间偏移消除、相位对齐校正和发送/接收耦合抑制，解决了硬件异步和天线耦合问题，实现了厘米级精度，并验证了在真实环境中检测和跟踪移动物体的可行性。


<details>
  <summary>Details</summary>
Motivation: 首次提出从商用Wi-Fi信道状态信息（CSI）中提取距离和多普勒信息的方法，解决了在非全双工硬件和近距离天线设置下的相位误差和信号干扰问题。

Method: 提出了一种新的信号处理方法，通过时间偏移消除、相位对齐校正和发送/接收耦合抑制来解决硬件异步和天线耦合问题。

Result: 在距离和多普勒估计方面实现了厘米级精度，并成功在真实环境中检测和跟踪了移动物体。

Conclusion: 使用标准的Wi-Fi通信和商用硬件，无需修改或专门的全双工功能，即可实现高精度传感。

Abstract: This paper presents, for the first time, a method to extract both range and
Doppler information from commercial Wi-Fi Channel State Information (CSI) using
a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi
sensing from a Network Interface Card (NIC) not designed for full-duplex
operation is challenging due to (1) Hardware asynchronization, which introduces
significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx)
antennas, which creates strong coupling that overwhelms the motion signal of
interest. We propose a new signal processing approach that addresses both
challenges via three key innovations: Time offset cancellation, Phase alignment
correction, and Tx/Rx coupling mitigation. Our method achieves cm-level
accuracy in range and Doppler estimation for moving targets, validated using a
commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and
tracking of moving objects in realistic environments, establishing the
feasibility of high-precision sensing using standard Wi-Fi packet
communications and off-the-shelf hardware without requiring any modification or
specialized full-duplex capabilities.

</details>


### [439] [Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks](https://arxiv.org/abs/2508.02856)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Bo Tang,Vuk Marojevic*

Main category: eess.SP

TL;DR: 提出一种基于DRL和ISAC的毫米波通信波束攻击防御框架，可有效检测攻击并保持通信性能。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波通信系统日益增长的波束窃取攻击威胁，提升物理层安全。

Method: 提出了一种利用集成感知与通信（ISAC）能力进行威胁评估的深度强化学习（DRL）框架，并采用近端策略优化（PPO）算法训练DRL代理。

Result: 在保持平均用户SINR超过13 dB的同时，实现了92.8%的平均攻击者检测率。

Conclusion: 本文提出的基于DRL和ISAC的防御框架能够有效检测波束攻击，同时保持通信性能。

Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility
to advanced beam-stealing attacks, posing a significant physical layer security
threat. This paper introduces a novel framework employing an advanced Deep
Reinforcement Learning (DRL) agent for proactive and adaptive defense against
these sophisticated attacks. A key innovation is leveraging Integrated Sensing
and Communications (ISAC) capabilities for active, intelligent threat
assessment. The DRL agent, built on a Proximal Policy Optimization (PPO)
algorithm, dynamically controls ISAC probing actions to investigate suspicious
activities. We introduce an intensive curriculum learning strategy that
guarantees the agent experiences successful detection during training to
overcome the complex exploration challenges inherent to such a
security-critical task. Consequently, the agent learns a robust and adaptive
policy that intelligently balances security and communication performance.
Numerical results demonstrate that our framework achieves a mean attacker
detection rate of 92.8% while maintaining an average user SINR of over 13 dB.

</details>


### [440] [Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread](https://arxiv.org/abs/2508.02950)
*Sandesh Rao Mattu,Nishant Mehrotra,Robert Calderbank*

Main category: eess.SP

TL;DR: 本文提出了一种新的更快速奈奎斯特信号传输方法，通过在延迟-多普勒域叠加信息符号，并利用 Zak-OTFS 调制和预编码器来处理干扰和信道效应，实现了与奈奎斯特信号相当的非编码性能，并能在编码后获得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的奈奎斯特信号传输在给定的带宽和时间内传输的信息符号数量有限（BT）。为了在相同的时频资源内传输更多信息，提出了更快速奈奎斯特信号传输，但它会破坏信号的正交性。本文旨在提出一种新的更快速奈奎斯特信号传输方法，该方法通过信息符号的叠加来实现，并利用特定的调制技术来处理由此产生的干扰，以期获得更好的性能。

Method: 提出一种在延迟-多普勒（DD）域中，利用 Zak 变换和 Zak-OTFS 调制来实现更快速奈奎斯特信号传输的方法。通过在信息符号上叠加信息，并利用 Zak-OTFS 允许构造相互无偏基，使得干扰类似于高斯噪声。该方案还利用 DD 信道的慢变化特性构建预编码器，以减轻双重扩展信道的影响，并利用两个相互无偏基来简化接收机处理，实现高斯噪声下的检测，进而可以使用格码调制来提高比特错误率性能。

Result: 数值结果表明，该更快速奈奎斯特信号传输方案实现了与奈奎斯特信号相似的非编码性能，并且通过编码后，在高信噪比下性能优于奈奎斯特信号。

Conclusion: 该方案实现了与奈奎斯特信号相似的非编码性能，并且在编码后，在高信噪比下优于奈奎斯特信号。

Abstract: Orthogonal signaling limits the number of information symbols transmitted in
bandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist
signaling and is achieved by mounting information symbols on $BT$-dimensional
basis spanning the $BT$-dimensional space spaced $\frac{1}{B}$ and
$\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more
than $BT$ informational symbols in a $BT$-dimensional space. This leads to loss
of orthogonality. This is achieved by time and/or bandwidth expansion resulting
from packing more information symbols in the same $BT$-dimensional space
(spacing less than $\frac{1}{B}$ and/or $\frac{1}{T}$). In this paper, we take
a different approach to faster-than-Nyquist signaling. We propose to
superimpose the information symbols on one another maintaining the original
spacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD)
domain using Zak-transform based orthogonal time frequency space (Zak-OTFS)
modulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also
allows construction of mutually unbiased bases the interference between which
appear like Gaussian noise. The proposed scheme leverages the slow variation in
the DD channel to construct a precoder that mitigates the effect of the
doubly-spread channel. Further, in the proposed scheme we mount information
symbols on two mutually unbiased bases which allows superposition of
information symbols. This simplifies receiver processing to detection in
Gaussian noise since each basis appears to the other as Gaussian noise. This
reduction makes it possible to use trellis coded modulation to enhance
bit-error performance. Numerical results demonstrate that the
faster-than-Nyquist signaling scheme achieves similar uncoded performance as
that of Nyquist signaling and with coding the performance is better than
Nyquist signaling at high signal-to-noise ratios.

</details>


### [441] [Generating Light-based Fingerprints for Indoor Localization](https://arxiv.org/abs/2508.03011)
*Hsun-Yu Lee,Jie Lin,Fang-Jing Wu*

Main category: eess.SP

TL;DR: 可见光通信（VLC）结合AS7341传感器和GAN数据增强技术，可以显著提高室内定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有射频室内定位方案（如Wi-Fi, RFID, UWB）易受多径衰落、干扰和覆盖变化影响的问题，探索可见光通信（VLC）作为一种替代方案。

Method: 提出一个两阶段框架：1. 使用多层感知机（MLP）训练真实的光谱测量数据。2. 使用TabGAN生成合成样本扩充训练语料库。

Result: 通过GAN增强的训练数据将平均定位误差从62.9cm降低到49.3cm，提高了20%，同时仅增加了5%的数据收集工作量。实验结果证实了GAN增强可以缓解数据稀疏问题并提高泛化能力。

Conclusion: 可见光通信（VLC）可以通过AS7341传感器捕获的光谱特征提供强大的定位指纹，用于室内定位。

Abstract: Accurate indoor localization underpins applications ranging from wayfinding
and emergency response to asset tracking and smart-building services.
Radio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain
vulnerable to multipath fading, interference, and uncontrollable coverage
variation. We explore an orthogonal modality -- visible light communication
(VLC) -- and demonstrate that the spectral signatures captured by a low-cost
AS7341 sensor can serve as robust location fingerprints.
  We introduce a two-stage framework that (i) trains a multi-layer perceptron
(MLP) on real spectral measurements and (ii) enlarges the training corpus with
synthetic samples produced by TabGAN. The augmented dataset reduces the mean
localization error from 62.9cm to 49.3cm -- a 20% improvement -- while
requiring only 5% additional data-collection effort. Experimental results
obtained on 42 reference points in a U-shaped laboratory confirm that GAN-based
augmentation mitigates data-scarcity issues and enhances generalization.

</details>


### [442] [Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation](https://arxiv.org/abs/2508.03021)
*Zhengyu Wang,Tiebin Mi,Gui Zhou,Robert C. Qiu*

Main category: eess.SP

TL;DR: 提出了一种名为MELA的新型ELAA架构，使用超表面取代移相器，并提出了一种两阶段信道估计方法，以提高下一代无线通信的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高ELAAs的实用性，克服传统解决方案中笨重的开关矩阵和昂贵的移相器网络。

Method: 提出了一种名为MELA（metasurface-enabled extremely large-scale antenna）的新型收发器架构，该架构使用可重构的透射超表面来实现高效的空中射频到天线耦合和相位控制，并开发了物理模型和距离相关的近似模型来表征电磁场传播，提出了一种两阶段信道估计框架，利用字典驱动的波束空间滤波技术和利用子阵列旋转对称性的超分辨率估计器来恢复角度和距离参数。

Result: 推导了MELA的半功率波束宽度解析表达式，表明其空间分辨率接近传统ELAA架构的最优水平，数值实验验证了所提出信道估计算法的高分辨率和电磁模型的保真度。

Conclusion: MELA架构具有高分辨率和保真度，是实际ELAAs部署的有力解决方案。

Abstract: Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal
technology for addressing the unprecedented performance demands of
next-generation wireless communication systems. To enhance their practicality,
we propose metasurface-enabled extremely large-scale antenna (MELA) systems --
novel transceiver architectures that employ reconfigurable transmissive
metasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and
phase control. This architecture eliminates the need for bulky switch matrices
and costly phase-shifter networks typically required in conventional solutions.
Physically grounded models are developed to characterize electromagnetic field
propagation through individual transmissive unit cells, capturing the
fundamental physics of wave transformation and transmission. Additionally,
distance-dependent approximate models are introduced, exhibiting structural
properties conducive to efficient parameter estimation and signal processing.
Based on the channel model, a two stage channel estimation framework is
proposed for the scenarios comprising users in the hybrid near- and far-fields.
In the first stage, a dictionary-driven beamspace filtering technique enables
rapid angular-domain scanning. In the refinement stage, the rotational symmetry
of subarrays is exploited to design super-resolution estimators that jointly
recover angular and range parameters. An analytical expression for the
half-power beamwidth of MELA is derived, revealing its near-optimal spatial
resolution relative to conventional ELAA architectures. Numerical experiments
further validate the high-resolution of the proposed channel estimation
algorithm and the fidelity of the electromagnetic model, positioning the MELA
architecture as a highly competitive and forward-looking solution for practical
ELAA deployment.

</details>


### [443] [Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training](https://arxiv.org/abs/2508.03084)
*Lingyan Zhang,Yuanfeng Qiu,Dachuan Li,Shaohua Wu,Tingting Zhang,Qinyu Zhang*

Main category: eess.SP

TL;DR: CSSLoc is a novel framework using contrastive self-supervised pre-training for accurate wireless localization in various scenarios, overcoming environmental dynamic vulnerability and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Wireless localization has become a promising technology for offering intelligent location-based services. Although its localization accuracy is improved under specific scenarios, the short of environmental dynamic vulnerability still hinders this approach from being fully practical applications.

Method: CSSLoc is a novel framework on contrastive self-supervised pre-training to learn generic representations for accurate localization in various scenarios. It learns an insightful metric on the similarity discrimination of radio data in a scenario-agnostic manner. The trained feature encoder can be directly transferred for downstream localization tasks, and the location predictor is trained to estimate accurate locations with the robustness of environmental dynamics.

Result: Extensive experimental results show that CSSLoc outperforms classical and state-of-the-art DNN-based localization schemes in typical indoor scenarios.

Conclusion: CSSLoccanoutperformclassicalandstateoftheartDNNbasedlocalizationschemesintypicalindoorscenariospushingdeeblearningbasedlocalizatiomfromspecificitytogenerality

Abstract: Wireless localization has become a promising technology for offering
intelligent location-based services. Although its localization accuracy is
improved under specific scenarios, the short of environmental dynamic
vulnerability still hinders this approach from being fully practical
applications. In this paper, we propose CSSLoc, a novel framework on
contrastive self-supervised pre-training to learn generic representations for
accurate localization in various scenarios. Without the location information
supervision, CSSLoc attempts to learn an insightful metric on the similarity
discrimination of radio data, in such a scenario-agnostic manner that the
similar samples are closely clustered together and different samples are
separated in the representation space. Furthermore, the trained feature encoder
can be directly transferred for downstream localization tasks, and the location
predictor is trained to estimate accurate locations with the robustness of
environmental dynamics. With extensive experimental results, CSSLoc can
outperform classical and state-of-the-art DNN-based localization schemes in
typical indoor scenarios, pushing deep-learning-based localization from
specificity to generality.

</details>


### [444] [Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition](https://arxiv.org/abs/2508.03131)
*Na Liu,Chengliang Dai,Qiuyue Wu,Qiuqi Li,Guoxiong Cai*

Main category: eess.SP

TL;DR: HODMD是一种用于加速大规模瞬态电路仿真的新方法，比DMD更优。


<details>
  <summary>Details</summary>
Motivation: 动态模态分解（DMD）是一种新颖的数据驱动的特征提取方法，可以直接从时域仿真数据中提取主导动态模态，而无需显式的系统方程。HODMD方法克服了在空间分辨率不足时无法重构输出信号的问题。

Method: 本文首先推导了DMD算法，然后提出了一种结合延迟嵌入技术的高阶动态模态分解（HODMD），专门针对大规模电路仿真的计算效率。

Result: HODMD算法适用于通用电路，并且计算效率和准确性得到了三个代表性数值案例的系统验证。

Conclusion: 所提出的高阶动态模态分解（HODMD）算法适用于通用电路，不对电路拓扑或元件类型施加任何限制。

Abstract: Model order reduction (MOR) has long been a mainstream strategy to accelerate
large-scale transient circuit simulation. Dynamic Mode Decomposition (DMD)
represents a novel data-driven characterization method, extracting dominant
dynamical modes directly from time-domain simulation data without requiring
explicit system equations. This paper first deduces the DMD algorithm and then
proposes high order dynamic mode decomposition (HODMD) incorporating delayed
embedding technique, specifically targeting computational efficiency in
large-scale circuit simulations. Compared with the DMD method, the HODMD method
overcomes the problem that the output signal cannot be reconstructed when the
spatial resolution is insufficient. The proposed HODMD algorithm is applicable
to general circuits and does not impose any constraints on the topology of the
pertinent circuit or type of the components. Three representative numerical
test cases are presented to systematically validate both the computational
efficiency and accuracy of the proposed HODMD method.

</details>


### [445] [Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication](https://arxiv.org/abs/2508.03248)
*Yoon Huh,Bumjun Kim,Wan Choi*

Main category: eess.SP

TL;DR: FedSFR通过引入特征重建（FR）和允许部分客户端传输紧凑特征向量来改进联邦学习在图像语义通信中的训练稳定性和通信效率，并提供差分隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有的基于NN的JSCC语义通信系统在图像传输中存在语义通信错误（由于知识库不匹配）和性能下降（由于模型过时）的问题，需要频繁更新模型。为了解决VQ图像语义通信系统中的这些挑战，需要一种更有效和稳定的训练方法。

Method: 提出了一种名为FedSFR的新型联邦学习框架，该框架结合了语义特征重建（FR）技术。FedSFR在参数服务器（PS）引入FR步骤，允许部分客户端传输紧凑的特征向量而不是完整的本地模型更新，从而提高训练稳定性和通信效率。此外，还设计了一种针对VQ图像语义通信的损失函数，并提供严格的收敛性分析，同时提出了一个具有差分隐私的FedSFR变体及其隐私分析。

Result: 实验结果表明，FedSFR在两个基准数据集上优于现有基线，特别是在容量受限的情况下，证明了其有效性和鲁棒性。

Conclusion: FedSFR框架在VQ图像语义通信系统中表现出色，尤其在容量受限的情况下，优于现有基线，并具有良好的鲁棒性。

Abstract: Recent advancements in semantic communication have primarily focused on image
transmission, where neural network (NN)-based joint source-channel coding
(JSCC) modules play a central role. However, such systems often experience
semantic communication errors due to mismatched knowledge bases between users
and performance degradation from outdated models, necessitating regular model
updates. To address these challenges in vector quantization (VQ)-based image
semantic communication systems, we propose FedSFR, a novel federated learning
(FL) framework that incorporates semantic feature reconstruction (FR). FedSFR
introduces an FR step at the parameter server (PS) and allows a subset of
clients to transmit compact feature vectors in lieu of sending full local model
updates, thereby improving training stability and communication efficiency. To
enable effective FR learning, we design a loss function tailored for VQ-based
image semantic communication and demonstrate its validity as a surrogate for
image reconstruction error. Additionally, we provide a rigorous convergence
analysis and present a differentially private variant of FedSFR, along with
formal privacy analysis. Experimental results on two benchmark datasets
validate the superiority of FedSFR over existing baselines, especially in
capacity-constrained settings, confirming both its effectiveness and
robustness.

</details>


### [446] [Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks](https://arxiv.org/abs/2508.03279)
*Vasileios Kouvakis,Stylianos E. Trevlakis,Ioannis Arapakis,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: 本文提出了一种基于SNN的UE-BS关联方法，用于UAV辅助的NTN网络，比较了集中式和分布式两种策略，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于无人机（UAV）引入了无线网络，系统架构变得异构，需要动态高效的管理来避免拥塞并维持整体性能。

Method: 本文提出了一种基于脉冲神经网络（SNN）的无人机（UAI）辅助的非陆地网络（NTN）用户设备-基站（UE-BS）关联方法。比较了两种SNN优化策略：一种是自顶向下的集中式方法，另一种是自底向上的分布式方法。SNN基于具有时间成分的泄漏积分发放神经元，能够进行快速高效的事件驱动推理。

Result: 仿真结果表明，自底向上的模型达到90%以上的准确率，而自顶向下的模型保持80-100%的准确率。

Conclusion: 两种SNN方法都揭示了个体最优解与UE-BS关联可行性之间的权衡，表明两种方法在不同部署场景下都有效。

Abstract: This work presents a new spiking neural network (SNN)-based approach for user
equipment-base station (UE-BS) association in non-terrestrial networks (NTNs).
With the introduction of UAV's in wireless networks, the system architecture
becomes heterogeneous, resulting in the need for dynamic and efficient
management to avoid congestion and sustain overall performance. The presented
framework compares two SNN-based optimization strategies. Specifically, a
top-down centralized approach with complete network visibility and a bottom-up
distributed approach for individual network nodes. The SNN is based on leak
integrate-and-fire neurons with temporal components, which can perform fast and
efficient event-driven inference. Realistic ray-tracing simulations are
conducted, which showcase that the bottom-up model attains over 90\% accuracy,
while the top-down model maintains 80-100\% accuracy. Both approaches reveal a
trade-off between individually optimal solutions and UE-BS association
feasibility, thus revealing the effectiveness of both approaches depending on
deployment scenarios.

</details>


### [447] [Quantum Deep Learning for Massive MIMO User Scheduling](https://arxiv.org/abs/2508.03327)
*Xingyu Huang,Ruining Fan,Mouli Chakraborty,Avishek Nag,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 提出了一种混合QNN架构，用于高效的5G/B5G大规模MIMO用户调度，提高了计算效率和频谱效率，并优于CNN。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统用户调度方法在5G/Beyond 5G（B5G）大规模多输入多输出（MIMO）系统中存在的扩展性问题。

Method: 提出了一种混合量子神经网络（QNN）架构，该架构结合了经典神经网络和变分量子电路核，利用统计信道状态信息（CSI）。

Result: 与经典的卷积神经网络（CNNs）相比，该模型具有更高的计算效率和频谱效率，并在噪声信道中保持了稳健的性能。

Conclusion: 该研究展示了量子增强机器学习在无线调度方面的潜力。

Abstract: We introduce a hybrid Quantum Neural Networks (QNN) architecture for the
efficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple
Output (MIMO) systems, addressing the scalability issues of traditional
methods. By leveraging statistical Channel State Information (CSI), our model
reduces computational overhead and enhances spectral efficiency. It integrates
classical neural networks with a variational quantum circuit kernel,
outperforming classical Convolutional Neural Networks (CNNs) and maintaining
robust performance in noisy channels. This demonstrates the potential of
quantum-enhanced Machine Learning (ML) for wireless scheduling.

</details>


### [448] [Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications](https://arxiv.org/abs/2508.03391)
*Seunghyeon Jeon,Seonjung Kim,Gyeongrae Im,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 针对低成本、低延迟的卫星通信需求，提出了一种优化的波束跳频设计算法，用于在资源有限的条件下，动态分配卫星资源以满足不同区域的通信需求，并提高了成功传输概率和网络鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 低成本、低延迟的卫星通信系统，以满足服务欠缺地区大规模设备连接的需求。

Method: 提出新颖的波束跳频设计算法，采用交替优化框架，通过二分法优化每个小区的照明分配，并使用交替方向乘子法（ADMM）优化波束跳频模式以最大化解码成功概率。ADMM通过用两个等效的连续值约束替换严格的二元约束来增强。

Result: 所提出的算法在模拟结果中显示出优于其他波束跳频方法，并验证了其在管理流量需求不平衡方面的鲁棒性。

Conclusion: 所提出的算法在模拟结果中显示出优于其他波束跳频方法，并验证了其在管理流量需求不平衡方面的鲁棒性。

Abstract: Increasing demand for massive device connectivity in underserved regions
drives the development of advanced low Earth orbit (LEO) satellite
communication systems. Beam-hopping LEO systems without connection
establishment provide a promising solution for achieving both demand-aware
resource allocation and low access latency. This paper investigates
beam-hopping pattern design for the grant-free random access systems to
dynamically allocate satellite resources according to traffic demands across
serving cells. We formulate a binary optimization problem that aims to maximize
the minimum successful transmission probability across cells, given limited
satellite beam generation capacity. To solve this problem, we propose novel
beam-hopping design algorithms that alternately enhance the collision avoidance
rate and decoding success probability within an alternating optimization
framework. Specifically, the algorithms employ a bisection method to optimize
illumination allocation for each cell based on demand, while using the
alternating direction method of multipliers (ADMM) to optimize beam-hopping
patterns for maximizing decoding success probability. Furthermore, we enhance
the ADMM by replacing the strict binary constraint with two equivalent
continuous-valued constraints. Simulation results demonstrate the superiority
of the proposed algorithms compared to other beam-hopping methods and verify
robustness in managing traffic demand imbalance.

</details>


### [449] [How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.03423)
*Isabella W. G. da Silva,Zahra Mobini,Hien Q. Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本研究提出了一种基于CF-mMIMO的主动监测系统，通过MMSE信道估计和贝叶斯优化来提高监测成功率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高通信系统的安全性，本研究提出了一个细胞信息场（CF-mMIMO）主动监测系统，用于监测不可信发信方（UT）的传输或干扰不可信收信方（UR）的接收。

Method: 本研究提出了一种有效的信道状态信息（CSI）获取方案，利用上下行导频信号，通过最小均方误差（MMSE）估计方案估计有效信道。此外，还提出了一种新颖的联合模式分配和干扰功率控制优化方法，基于贝叶斯优化框架最大化监测成功率（MSP）。

Result: 推导了不可信链路和监测系统的频谱效率（SE）表达式。数值结果表明，所提出的CF-mMIMO主动监测系统性能优越，MSP大于0.8。

Conclusion: 本研究提出的细胞信息场（CF-mMIMO）主动监测系统，通过提出的信道状态信息（CSI）获取和优化方法，在监测成功率方面显著优于现有基准。监测成功率始终大于0.8，不受信任节点天线数量或传输链路预编码方案的影响。

Abstract: This paper studies a cell-free massive multiple-input multiple-output
(CF-mMIMO) proactive monitoring system in which multiple multi-antenna
monitoring nodes (MNs) are assigned to either observe the transmissions from an
untrusted transmitter (UT) or to jam the reception at the untrusted receiver
(UR). We propose an effective channel state information (CSI) acquisition
scheme for the monitoring system. In our approach, the MNs leverage the pilot
signals transmitted during the uplink and downlink phases of the untrusted link
and estimate the effective channels corresponding to the UT and UR via a
minimum mean-squared error (MMSE) estimation scheme. We derive new spectral
efficiency (SE) expressions for the untrusted link and the monitoring system.
For the latter, the SE is derived for two CSI availability cases at the central
processing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and
CPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the
CPU. To improve the monitoring performance, we propose a novel joint mode
assignment and jamming power control optimization method to maximize the
monitoring success probability (MSP) based on the Bayesian optimization
framework. Numerical results show that (a) our CF-mMIMO proactive monitoring
system relying on the proposed CSI acquisition and optimization approach
significantly outperforms the considered benchmarks; (b) the MSP performance of
our CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the
number of antennas at the untrusted nodes or the precoding scheme for the
untrusted transmission link.

</details>


### [450] [Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO](https://arxiv.org/abs/2508.03460)
*Anubhab Chowdhury,Sai Subramanyam Thoota,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文研究了动态时分双工（DTDD）细胞无关（CF）大规模多输入多输出（mMIMO）系统的集成传感与通信（ISAC）。提出了用于目标检测和通信的集中式和分布式方法，并进行了性能分析。结果表明，该方法鲁棒且能提升频谱效率。


<details>
  <summary>Details</summary>
Motivation: 本文研究了集成传感与通信（ISAC）与动态时分双工（DTDD）细胞无关（CF）大规模多输入多输出（mMIMO）系统。

Method: 本文提出了集中式和分布式广义似然比检验（GLRT）用于目标检测，并将上行链路用户的信号视为传感干扰。然后，量化了分布式和集中式GLRT的最优性和复杂性权衡，并以贝叶斯克拉美-罗下界为基准评估了各自的估计器。接着，提出了用于联合上行链路用户数据检测和雷达散射截面估计的统一框架。然后，针对通信，推导了考虑了交叉链路和雷达干扰的上行链路数据处理的信噪比（SINR）最优组合器。在下行链路中，对用户使用了正则化零强制，并为目标提出了两种类型的预编码器：一种是“用户中心”的，它消除了目标信号对下行链路用户造成的干扰；另一种是基于目标和接入点之间复合信道的主导特征向量的“目标中心”的。

Result: 本文提出了集中式和分布式广义似然比检验（GLRT）用于目标检测，并将上行链路用户的信号视为传感干扰。接着，提出了用于联合上行链路用户数据检测和雷达散射截面估计的统一框架。然后，针对通信，推导了考虑了交叉链路和雷达干扰的上行链路数据处理的信噪比（SINR）最优组合器。在下行链路中，对用户使用了正则化零强制，并为目标提出了两种类型的预编码器：一种是“用户中心”的，它消除了目标信号对下行链路用户造成的干扰；另一种是“目标中心”的，基于目标和接入点之间复合信道的主导特征向量。

Conclusion: 数值研究证实了我们的理论发现，并揭示了广义似然比检验对于接入点间干扰具有鲁棒性，并且与传统的基于时分双工的细胞无关大规模多输入多输出集成传感与通信系统相比，时分双工将同时上下行链路和下行链路的频谱效率提高了一倍；同时使用了半双工硬件。

Abstract: This paper studies integrated sensing and communication (ISAC) with dynamic
time division duplex (DTDD) cell-free (CF) massive multiple-input
multiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to
concurrently serve both uplink~(UL) and downlink~(DL) users with spatially
separated \emph{half-duplex~(HD)} access points~(APs) using the same
time-frequency resources. Further, to facilitate ISAC, the UL APs are utilized
for both UL data and target echo reception, while the DL APs jointly transmit
the precoded DL data streams and target signal. In this context, we present
centralized and distributed generalized likelihood-ratio tests~(GLRTs) for
target detection treating UL users' signals as sensing interference. We then
quantify the optimality and complexity trade-off between distributed and
centralized GLRTs and benchmark the respective estimators with the Bayesian
Cram\'er-Rao lower bound for target radar-cross section~(RCS). Then, we present
a unified framework for joint UL users' data detection and RCS estimation.
Next, for communication, we derive the signal-to-noise-plus-interference~(SINR)
optimal combiner accounting for the cross-link and radar interference for UL
data processing. In DL, we use regularized zero-forcing for the users and
propose two types of precoders for the target: one ``user-centric" that
nullifies the interference caused by the target signal to the DL users and one
``target-centric" based on the dominant eigenvector of the composite channel
between the target and the APs. Finally, numerical studies corroborate with our
theoretical findings and reveal that the \emph{GLRT is robust to inter-AP
interference, and DTDD doubles the $90\%$-likely sum UL-DL SE compared to
traditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [451] [Understanding Demand for Shared Autonomous Micro-Mobility](https://arxiv.org/abs/2508.03521)
*Naroa Coretti Sanchez,Kent Larson*

Main category: cs.ET

TL;DR: 共享自动微型交通系统的采用和环境影响很大程度上取决于服务设计；需要平衡便利性和成本以实现可持续性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补理解哪些交通模式最有可能被共享自动微型交通系统取代、谁最有可能采用它们以及服务属性如何影响用户决策方面的研究空白。

Method: 本研究设计了一个基于实际行程的、具有情境意识的意向性调查，并估计了离散选择模型，包括一个包含潜在态度的混合模型。

Result: 研究发现，采用可能性因人口统计特征而异，结果取决于城市类型、情境和基础设施假设。

Conclusion: 研究结果表明，共享自动微型交通系统的采用、模式转变和环境影响高度依赖于服务设计。

Abstract: This study examines the behavioral and environmental implications of shared
autonomous micro-mobility systems, focusing on autonomous bicycles and their
integration with transit in the U.S. While prior research has addressed
operational and lifecycle aspects, a critical gap remains in understanding
which modes these services are likely to substitute, who is most inclined to
adopt them, and how service attributes influence user decisions. We design a
context-aware stated preference survey grounded in real-world trips and
estimate discrete choice models, including a hybrid model incorporating latent
attitudes. Findings indicate that adoption, mode shift, and environmental
impacts are highly sensitive to service design. Scenarios with minimal wait and
cost yield high adoption but increase emissions, while moderate waits are more
likely to reduce impacts. Adoption likelihood varies with demographic
characteristics, and outcomes depend on city type, context, and infrastructure
assumptions. These insights can inform the development of more sustainable and
equitable mobility systems.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [452] [Quantum Geometry of Altermagnetic Magnons Probed by Light](https://arxiv.org/abs/2508.02781)
*Rundong Yuan,Wojciech J. Jankowski,Ka Shen,Robert-Jan Slager*

Main category: cond-mat.mes-hall

TL;DR: 双圆光可以用于探测手征阿尔特磁畴畴，并区分阿尔特磁体和反铁磁体。


<details>
  <summary>Details</summary>
Motivation: 为了识别阿尔特磁体及其关键特征——具有动量依赖手征性的磁畴畴，并提出一种区分阿尔特磁体和反铁磁体的方法。

Method: 利用双圆光探测手征阿尔特磁畴畴，并分析了光-畴相互作用。

Result: 在d波阿尔特磁体中，外加倾斜磁场可以增强非线性二阶光-畴相互作用，并且双圆光脉冲散射可以探测到磁畴畴的量子几何结构。

Conclusion: 本研究提出了使用双圆光探测手征阿尔特磁畴畴的方案，并建立了区分阿尔特磁体和反铁磁体的手征图案的光学探测方法。

Abstract: Magnons with momentum-dependent chirality are a key signature of
altermagnets. We identify bicircular light as a smoking-gun optical probe for
chiral altermagnetic magnons, selectively targeting their quantum geometry
induced by an alteration of magnonic chirality. We show that in $d$-wave
altermagnets, under a canting magnetic field, the altermagnetic magnons realize
a nontrivial quantum geometry, resulting in an enhancement of the nonlinear
second-order light-magnon interactions. We find that the scattering of
bicircular pulses probes the present magnon quantum geometry, even if the
magnonic topology is trivial. Hence, our findings establish bicircular Raman
response as an optical effect of choice to identify altermagnetic magnons. As
such, we propose a universal experimental protocol to distinguish altermagnets
from antiferromagnets by detecting their magnon chirality patterns with light,
independently of the underlying magnon topology.

</details>


### [453] [Self-assembled fluorescent nanodiamond layers for quantum imaging](https://arxiv.org/abs/2508.03028)
*Katherine Chea,Erin S. Grant,Kevin J. Rietwyk,Hiroshi Abe,Takeshi Ohshima,David A. Broadway,Jean-Philippe Tetienne,Gary Bryant,Philipp Reineck*

Main category: cond-mat.mes-hall

TL;DR: 通过静电自组装技术制备了NV荧光纳米金刚石层，并成功应用于磁成像，为可扩展的量子传感提供了方法。


<details>
  <summary>Details</summary>
Motivation: 现有的NV成像技术依赖于昂贵的块状金刚石，难以扩展和集成，因此需要开发一种可扩展的NV成像方法。

Method: 通过静电自组装技术，研究了FND在悬浮液中的浓度、基板浸泡时间和溶剂pH值对FND密度的影响，优化了自组装条件以最大化FND密度并减少聚集。

Result: 成功制备了基于静电自组装的FND层，并在石英基板上展示了微尺度的磁场和磁噪声成像。

Conclusion: 该研究提供了一种经济高效且可扩展的含氮空位（NV）荧光纳米金刚石（FND）层制造方法，并展示了其在磁场和磁噪声成像方面的应用，为基于NV的量子传感和成像提供了新的途径。

Abstract: The nitrogen-vacancy (NV) center in diamond is emerging as a powerful tool
for imaging magnetic and electric signals at the microscale and below. However,
most imaging demonstrations thus far have relied on costly, millimeter-sized
bulk diamond substrates, which cannot be easily scaled or integrated with other
materials. Here, we report a scalable method for fabricating NV-containing
dense and homogenous fluorescent nanodiamond (FND) layers through electrostatic
self-assembly and demonstrate the utility of the FND layers for magnetic
imaging. We investigate the effect of FND concentration in suspension,
substrate immersion time, and solvent pH on the FND density on the substrate.
We identify optimized self-assembly conditions that maximize the FND density
while minimizing aggregation. Using FND layers on a quartz substrate, we
demonstrate magnetic field and magnetic noise imaging at the microscale, based
on NV optically detected magnetic resonance magnetometry and T$_1$ relaxometry,
respectively. Our results provide a direction for the development of
cost-effective and scalable FND layers and surface coatings. This paves the way
for on-demand quantum sensing and imaging on a broad range of surfaces based on
NV centers and other diamond quantum emitters.

</details>


### [454] [Observation of Embedded Topology in a Trivial Bulk via Projective Crystal Symmetry](https://arxiv.org/abs/2508.03033)
*Hau Tian Teo,Yang Long,Hong-yu Zou,Kailin Song,Haoran Xue,Yong Ge,Shou-qi Yuan,Hong-xiang Sun,Baile Zhang*

Main category: cond-mat.mes-hall

TL;DR: 研究发现在声子晶体中，即使体块平凡，也能实现块-边界对应，打破了传统观念，并展示了支持零维拓扑态的三维系统。


<details>
  <summary>Details</summary>
Motivation: 探索块-边界对应原理的例外情况，即在平凡体块中产生嵌入式拓扑。

Method: 通过声子晶体平台和三维系统，利用投影晶体对称性来实现嵌入式拓扑，而不是依赖全局对称性。

Result: 在声子晶体平台中实验性地证明了嵌入式拓扑，并实现了一个支持零维拓扑态的三维系统，这是物理空间中最长的此类非常规块-边界对应作用链。

Conclusion: 该研究实验性地证明了一种新的块-边界对应形式，该形式源于平凡体块，为设计鲁棒的拓扑器件开辟了额外的自由度。

Abstract: Bulk-boundary correspondence is the foundational principle of topological
physics, first established in the quantum Hall effect, where a $D$-dimensional
topologically nontrivial bulk gives rise to $(D-1)$-dimensional boundary
states. The advent of higher-order topology has generalized this principle to a
hierarchical chain, enabling topological states to appear at $(D-2)$ or even
lower-dimensional boundaries. To date, all known realizations of topological
systems must require a topologically nontrivial bulk to initiate the chain of
action for bulk-boundary correspondence. Here, in an acoustic crystal platform,
we experimentally demonstrate an exception to this paradigm--embedded topology
in a trivial bulk--where the bulk-boundary correspondence originates from a
trivial bulk. Rather than relying on global symmetries, we employ projective
crystal symmetry, which induces nontrivial topology not at the outset in the
$D$-dimensional bulk, but midway through the correspondence hierarchy in
lower-dimensional boundaries. We further realize a three-dimensional system
exhibiting embedded topology that supports zero-dimensional topological states,
achieving the longest possible chain of action for such an unconventional
bulk-boundary correspondence in physical space. Our work experimentally
establishes a new form of bulk-boundary correspondence initiated from a trivial
bulk, opening additional degrees of freedom for the design of robust
topological devices.

</details>


### [455] [Dielectric Substrate Dependence of Thermoelectric Transport in BLG-GaAs-BLG Heterostructures](https://arxiv.org/abs/2508.03035)
*Vo Van Tai,Truong Van Tuan,Tran Trong Tai,Le Tri Dat,Nguyen Duy Vy*

Main category: cond-mat.mes-hall

TL;DR: 在双层石墨烯体系中，压电散射占主导地位，衬底介电常数显著影响热电功率。通过衬底工程可以优化热电器件性能。


<details>
  <summary>Details</summary>
Motivation: 研究双层石墨烯体系在不同衬底上的热电输运性质，探索衬底工程对热电器件性能优化的可能性。

Method: 我们理论研究了介电衬底（h-BN、Al2O3、HfO2）上双层石墨烯（BLG-GaAs-BLG）体系中的热电输运S。电子通过形变势（acDP）和压电（acPE）散射与GaAs声学声子相互作用。

Result: 结果表明，压电散射在总输运中占主导地位，尤其是在低载流子密度和高介电常数下。双层石墨烯层上的载流子密度不相等时，acDP散射的贡献在低密度（高密度）下相对于相等密度时会减小（增大），而acPE散射的贡献保持稳定，使得S在很大程度上取决于Sg。增加层间距离d会增强S，而较高的温度会提高Sd（尤其是在低密度下），而对Sg的影响很小。

Conclusion: 我们证明了衬底工程是优化BLG热电器件的关键参数，衬底介电常数显著影响热电功率S，并且不同衬底材料的热电功率顺序为HfO2 > Al2O3 > h-BN。

Abstract: We theoretically study the thermoelectric transport S in a double-layer
bilayer graphene (BLG-GaAs-BLG) system on dielectric substrates (h-BN, Al2O3,
HfO2). Electrons interact with GaAs acoustic phonons via both the deformation
potential (acDP) and piezoelectric (acPE) scattering. Results show that
piezoelectric scattering dominates the total transport, especially at low
carrier density and high dielectric constant. Substrate dielectric constant
significantly influences thermopower S, and the thermopower of the materials is
in the order of HfO2 > Al2O3 > h-BN. When densities on two BLG layers are
unequal, the contribution from acDP scattering Sd decreases (increases) at low
(high) densities versus equal densities, while acPE scattering Sg remains
stable, making S largely Sg-dependent. Increasing interlayer distance d
enhances S, while higher temperature boosts Sd (notably at low densities) with
minimal effect on Sg. These insights and substrate-dependent trends demonstrate
substrate engineering as a key parameter for optimizing BLG thermoelectric
devices

</details>


### [456] [Quantum Bipolar Thermoelectricity](https://arxiv.org/abs/2508.03219)
*Filippo Antola,Giorgio De Simoni,Francesco Giazotto,Alessandro Braggio*

Main category: cond-mat.mes-hall

TL;DR: A quantum thermoelectric effect is observed in a superconducting tunnel junction due to quantum effects from a cold environment, not traditional transport asymmetries.


<details>
  <summary>Details</summary>
Motivation: Thermoelectricity typically arises from energy-dependent transport asymmetries. This research investigates a different source: a quantum thermoelectric effect stemming from the emission/absorption asymmetry of a low-temperature quantum bath.

Method: The study proposes a gap-asymmetric S-I-S' superconducting tunnel junction in thermal equilibrium, coupled to a low-temperature electromagnetic environment, to demonstrate a quantum thermoelectric effect. The effect arises from the emission/absorption asymmetry of the quantum bath and is characterized by a nonlinear quantum bipolar thermoelectric effect attributed to the dynamical Coulomb blockade.

Result: A nonlinear quantum bipolar thermoelectric effect is developed in a gap-asymmetric S-I-S' superconducting tunnel junction coupled to a low-temperature electromagnetic environment, driven by the dynamical Coulomb blockade.

Conclusion: The paper explores a purely quantum thermoelectric effect rooted in the emission/absorption asymmetry of a low-temperature quantum bath, proposing a gap-asymmetric S-I-S' superconducting tunnel junction coupled to a low-temperature electromagnetic environment. This system exhibits a nonlinear quantum bipolar thermoelectric effect due to the dynamical Coulomb blockade.

Abstract: Thermoelectricity usually originates from energy-dependent transport
asymmetries. In this Letter, we explore a purely quantum thermoelectric effect
rooted in the emission/absorption asymmetry of a low-temperature quantum bath.
We propose a gap-asymmetric S-I-S' superconducting tunnel junction in thermal
equilibrium, coupled to a low-temperature electromagnetic environment, which
develops a nonlinear quantum bipolar thermoelectric effect due to the dynamical
Coulomb blockade. Key performance features are analyzed for realistic
implementations.

</details>


### [457] [Organic altermagnets based in two-dimensional nanographene frameworks](https://arxiv.org/abs/2508.03234)
*Ricardo Ortiz,Karol Strutyński,Manuel Melle-Franco*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种利用π共轭纳米石墨烯（特别是dibenzo[ef,kl]heptalene）构建有机交替磁性材料的方法，并通过DFT计算验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 探索以碳为代表的轻元素构建交替磁性材料的策略，特别是通过在π共轭的纳米石墨烯中包含非轮换环来克服对称性限制。

Method: 利用DFT计算研究了dibenzo[ef,kl]heptalene的自旋极化能带结构，并考察了基于dibenzo[ef,kl]heptalene单元与连接基的共价有机框架。

Result: DFT计算证实dibenzo[ef,kl]heptalene具有自旋补偿的基态、被破坏的时间反转对称性以及第一价和导带的d波对称性，且基于dibenzo[ef,kl]heptalene单元与连接基的共价有机框架也获得了符合的结果。

Conclusion: 通过在π共轭的纳米石墨烯中包含非轮换环，可以克服以碳为代表的轻元素构建交替磁性框架的挑战。Dibenzo[ef,kl]heptalene 可作为交替磁性二维晶体的合适构件，DFT计算证实了这一点，其特点是具有自旋补偿的基态、被破坏的时间反转对称性以及第一价和导带的d波对称性。基于dibenzo[ef,kl]heptalene单元与连接基的共价有机框架也获得了符合的结果，为实现有机交替磁性材料铺平了道路。

Abstract: Altermagnetism stands as a third type of collinear magnetic order, whose band
structure combines a net zero magnetization with a non-relativistic
spin-splitting caused by a broken time reversal symmetry. So far, the strategy
to design platforms displaying altermagnetism has relied mostly on inorganic
crystals with d-metals as spin centers, where a representative example is the
two-dimensional square lattice with antiparallel D2h magnetic blocks related by
a pi/2 rotation. Despite the fact that there is no strong requirement for the
magnetic atoms to be metals, the construction of an altermagnetic framework
with light elements like carbon is challenging due to symmetric constrictions.
We show how it is possible to overcome this by including non-alternant rings in
pi-conjugated nanographenes. More specifically, dibenzo[ef,kl]heptalene, an S =
1 pi-conjugated hydrocarbon consisting of a graph of two fused heptagons and
hexagons, represents a suitable building block for an altermagnetic 2D crystal.
In this work, we confirm this hypothesis with DFT calculations of the spin
polarized band structure, presenting a spin compensated ground state with
broken time reversal symmetry, and a d-wave symmetry of the first valence and
conduction bands. Consistent results are obtained for covalent organic
frameworks based on dibenzo[ef,kl]heptalene units connected by linkers, paving
the way for the realization of organic altermagnetic materials.

</details>


### [458] [Microscopic Theory of Light-Induced Coherent Phonons Mediated by Quantum Geometry](https://arxiv.org/abs/2508.03257)
*Jiaming Hu,Zhichao Guo,Wenbin Li,Hua Wang,Kai Chang*

Main category: cond-mat.mes-hall

TL;DR: 本研究开发了一个量子力学框架，用于描述光诱导相干声子的产生，并揭示了其量子几何起源。研究发现，该过程在非中心对称半导体中尤为显著，并可用于调控铁电材料的极化。


<details>
  <summary>Details</summary>
Motivation: 探索光诱导相干声子的微观理论和量子几何性质，为实现材料性质的超快控制提供理论基础。

Method: 本研究基于Feynman图开发了一个全量子力学框架，用于系统地描述光诱导相干声子的产生，并识别出一种主导的二阶双共振过程。

Result: 识别出一种在非中心对称半导体中有效耦合光与电子-声子激发的二阶双共振过程，并揭示了其量子几何起源（通过电子-声子耦合（EPC）位移矢量和EPC量子几何张量编码）。将该理论应用于铁电材料BaTiO3和SnSe，证明了相干声子驱动的光诱导铁电极化调制潜力。

Conclusion: 本研究为理解和控制光诱导相干声子提供了理论基础，并展示了其在调控铁电极化方面的应用潜力。

Abstract: Light-induced coherent phonons provide a powerful platform for ultrafast
control of material properties. However, the microscopic theory and quantum
geometric nature of this phenomenon remain underexplored. Here, we develop a
fully quantum-mechanical framework based on Feynman diagrams to systematically
describe the generation of coherent phonons by light. We identify a dominant
second-order, double-resonant process in noncentrosymmetric semiconductors that
efficiently couples light to both electronic and phononic excitations.
Crucially, we uncover the quantum geometric origin, encoded in the
electron-phonon coupling (EPC) shift vector and the EPC quantum geometric
tensor. Applying our theory to ferroelectric BaTiO$_3$ and SnSe, we demonstrate
the potential for light-induced modulation of ferroelectric polarization driven
by coherent phonons. This work provides fundamental insights for designing
efficient optical control strategies for both coherent phonons and
ferroelectric polarization.

</details>


### [459] [Berry Curvature of Low-Energy Excitons in Rhombohedral Graphene](https://arxiv.org/abs/2508.03290)
*Henry Davenport,Frank Schindler,Johannes Knolle*

Main category: cond-mat.mes-hall

TL;DR: 在菱面五层石墨烯中，我们发现激子中心可以被电场调谐，并且具有可测量的拓扑性质。


<details>
  <summary>Details</summary>
Motivation: 研究在魔尔材料中激子拓扑的可能性，并探索菱面五层石墨烯在特定扭转角和电场下的激子行为。

Method: 提出了一种新的低能双带模型来更准确地描述菱面石墨烯的能带结构，并使用该模型分析了激子性质。

Result: 激子旺纳函数中心定位在魔尔晶胞边界的C3对称点，并且可以通过改变电场强度在不等效角点之间切换。激子继承了底层电子带的激子贝里曲率。

Conclusion: 结果表明，菱面五层石墨烯中的激子可以继承底层电子带的激子贝里曲率，从而丰富其半经典输运性质。研究结果将菱面石墨烯定位为探索魔尔材料中激子拓扑的一个引人注目的可调谐平台。

Abstract: We investigate low energy excitons in rhombohedral pentalayer graphene
encapsulated by hexagonal boron nitride (hBN/R5G/hBN), focusing on the regime
at the experimental twist angle $\theta = 0.77^\circ$ and with an applied
electric field. We introduce a new low-energy two-band model of rhombohedral
graphene that captures the band structure more accurately than previous models
while keeping the number of parameters low. Using this model, we show that the
centres of the exciton Wannier functions are displaced from the moir\'e unit
cell origin by a quantised amount -- they are instead localised at
$C_3$-symmetric points on the boundary. We also find that the exciton shift is
electrically tunable: by varying the electric field strength, the exciton
Wannier centre can be exchanged between inequivalent corners of the moir\'e
unit cell. Our results suggest the possibility of detecting excitonic corner or
edge modes, as well as novel excitonic crystal defect responses in hBN/R5G/hBN.
Lastly, we find that the excitons in hBN/R5G/hBN inherit excitonic Berry
curvature from the underlying electronic bands, enriching their semiclassical
transport properties. Our results position rhombohedral graphene as a
compelling tunable platform for probing exciton topology in moir\'e materials.

</details>


### [460] [From Wye-Delta to Cross-Square Recursion Configurations in Graphene-Based Quantum Hall Arrays](https://arxiv.org/abs/2508.03347)
*Ngoc Thanh Mai Tran,Marta Musso,Dominick S. Scaletta,Wei-Chen Lin,Valery Ortiz Jimenez,Dean G. Jarrett,Massimo Ortolano,Curt A. Richter,Chi-Te Liang,David B. Newell,Albert F. Rigosi*

Main category: cond-mat.mes-hall

TL;DR: 使用交叉方形网络配置和伪分形递归，成功制造了更高有效量子电阻的电阻标准，但要注意低温系统中的电阻泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有的量子霍尔效应电阻标准受到朗道能级填充因子为2的限制，这限制了可用的量子化电阻值，并需要串联或并联霍尔元件。

Method: 通过构建交叉方形网络配置和使用伪分形递归来克服现有量子霍尔效应电阻标准的局限性。

Result: 实现了55.81MΩ和27.61GΩ的有效电阻，并有潜力达到317.95TΩ。然而，teraohm测量揭示了传统湿式低温系统因电阻泄漏而产生的限制。

Conclusion: 这项工作建立在实现异常高值量子电阻标准的能力之上。

Abstract: In electrical metrology, the quantum Hall effect is accessed at the Landau
level filling factor {\nu} = 2 plateau to define and disseminate the unit of
electrical resistance (ohm). The robustness of the plateau is only exhibited at
this Landau level filling factor and thus places a constraint on the quantized
resistances that are accessible when constructing quantized Hall array
resistance standards (QHARS) using epitaxial graphene on SiC. To overcome
devices constrained by using Hall elements in series or in parallel, this work
approaches the fabrication of a cross-square network configuration, which is
similar to but departs slightly from conventional wye-delta designs and
achieves significantly higher effective quantized resistance outputs.
Furthermore, the use of pseudofractal-like recursion amplifies the ability to
reach high resistances. QHARS devices designed as the ones here are shown to
achieve an effective resistance of 55.81 M$\Omega$ in one configuration and
27.61 G$\Omega$ in another, with a hypothetically projected 317.95 T$\Omega$
that could be accessed with more specialized equipment. Teraohmmeter
measurements reveal the limits of conventional wet cryogenic systems due to
resistance leakage. Ultimately, this work builds on the capability of realizing
exceptionally high-value quantum resistance standards.

</details>


### [461] [Out-of-equilibrium nonlinear model of thermoelectricity in superconducting tunnel junctions](https://arxiv.org/abs/2508.03528)
*Leonardo Lucchesi,Federico Paolucci*

Main category: cond-mat.mes-hall

TL;DR: A new nonlinear model is better for thermoelectricity in superconducting tunnel junctions than the old linear one, especially at high power.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of the equilibrium linear model in describing thermoelectricity in superconducting tunnel junctions under realistic experimental conditions, particularly in the nonlinear regime.

Method: A nonlinear numerical model is developed, which reduces to the linear equilibrium model in the low-power limit. Qualitative and quantitative differences between the models are analyzed.

Result: The study reveals that the linear model fails for practical parameters. The nonlinear model shows that the junction saturates and inverts its behavior at high power, highlighting significant differences from the linear model. A new criterion for identifying nonlinear thermoelectricity is devised.

Conclusion: The linear model is insufficient for describing superconducting tunnel junctions in practical experimental setups; a new nonlinear model is proposed and validated. Nonlinear thermoelectricity criteria are also defined.

Abstract: Thermoelectricity in superconducting tunnel junctions has always been studied
under the hypothesis of equilibrium between the cold side and the thermal bath,
usually in the linear regime. We define a more complete out-of-equilibrium
nonlinear numerical model that reduces to the equilibrium linear model in the
low-power limit. We find that the linear model does not correctly describe the
behavior of superconducting tunnel junctions for parameters that are reasonable
in practical experimental setups. Subsequently, we present the qualitative and
quantitative differences between the models, discovering that for high power,
the junction saturates and then inverts its behavior. Finally, we also clarify
the difference between linear and nonlinear thermoelectricity and devise a new
criterion to find nonlinear thermoelectricity in the parameter space.

</details>


### [462] [Quantum Spin Hall Effect with Extended Topologically Protected Features in Altermangetic Multilayers](https://arxiv.org/abs/2508.03580)
*Zhiyu Chen,Fangyang Zhan,Da-Shuai Ma,Dong-Hui Xu,Rui Wang*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用反常磁性实现了具有多对无能隙螺旋边缘态的量子自旋霍尔效应，并提出了Fe₂Se₂O多层材料作为实现该效应的候选材料。


<details>
  <summary>Details</summary>
Motivation: 规避时间反演对称性对量子自旋霍尔（QSH）效应的$
u$₂分类限制，探索具有多对无能隙螺旋边缘态的量子自旋霍尔相。

Method: 利用新发现的反常磁性来规避时间反演对称性对量子自旋霍尔（QSH）效应的$
u$₂分类限制，并通过第一性原理计算，发现了反常磁性Fe₂Se₂O多层材料作为实现该效应的潜在候选材料。

Result: 在反常磁性多层材料中实现了具有多对无能隙螺旋边缘态的量子自旋霍尔相，该相由镜像-自旋陈数表征，是自旋-轨道耦合和d波反常磁性排序相互作用的结果。在反常磁性Fe₂Se₂O多层材料中，无能隙螺旋边缘态的数量与层数成线性关系，产生了相应的、精确量化的、可实验访问的自旋霍尔电导。

Conclusion: 本文的研究结果揭示了一种新的稳定多对无能隙螺旋边缘态的机制，显著扩展了量子自旋霍尔（QSH）效应的范围，并为利用反常磁性设计所需的拓扑相提供了蓝图。

Abstract: Conventional topological classification theory dictates that time-reversal
symmetry confines the quantum spin Hall (QSH) effect to a $\mathbb{Z}_2$
classification, permitting only a single pair of gapless helical edge states.
Here, we utilize the recently discovered altermagnetism to circumvent this
fundamental constraint. We demonstrate the realization of a unique QSH phase
possessing multiple pairs of gapless helical edge states in altermagnetic
multilayers. This exotic QSH phase, characterized by a mirror-spin Chern
number, emerges from the interplay of spin-orbit coupling and $d$-wave
altermagnetic ordering. Moreover, using first-principles calculations, we
identify altermagnetic Fe$_2$Se$_2$O multilayers as promising material
candidates, in which the number of gapless helical edge states scales linearly
with the number of layers, leading to a correspondingly large, exactly
quantized, and experimentally accessible spin-Hall conductance. Our findings
unveil a new mechanism for stabilizing multiple pairs of gapless helical edge
states, significantly expanding the scope of QSH effects, and provide a
blueprint for utilizing altermagnetism to engineer desired topological phases.

</details>


### [463] [A noninvasive and nonadiabatic quantum Maxwell demon](https://arxiv.org/abs/2508.03659)
*Lucas Trigal,Rafael Sánchez*

Main category: cond-mat.mes-hall

TL;DR: 论文提出了一种量子麦克斯韦妖，利用电荷探测器和 Landau-Zener-Stückelberg-Majorana 驱动，在量子点中实现高效反馈、发电和冷却，并在非绝热状态下达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种在量子点环境中运行的量子力学麦克斯韦妖，以避免连续测量引起的退相干。

Method: 通过 Landau-Zener-Stückelberg-Majorana 驱动控制相干隧穿，实现了高效的反馈操作，且无需做功。

Result: 实现了局部违反第二定律，同时进行发电和冷却。论文还讨论了响应电流波动和源于故障的妖的逆作用，并在非绝热状态下发现了最佳性能。

Conclusion: 该论文提出了一种在量子点环境中运行的量子力学麦克斯韦妖，通过利用未详细说明的电荷探测器来避免由连续测量引起的退相干。

Abstract: A quantum mechanical Maxwell demon is proposed in a quantum dot setting. The
demon avoids continuous-measurement induced decoherence by exploiting an
undetailed charge detector. The control of coherent tunneling via
Landau-Zener-St\"uckelberg-Majorana driving allows for efficient feedback
operations with no work invested. The local violation of the second law
achieves simultaneous power generation and cooling. We discuss the response
current fluctuations, and the demon backaction deriving from failures, finding
optimal performance in the nonadiabatic regime.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [464] [Role of nanoparticle shape on the critical size for quasi-uniform ordering: from spheres to cubes through superballs](https://arxiv.org/abs/2508.02838)
*Iago López-Vázquez,David Serantes,Òscar Iglesias*

Main category: cond-mat.mtrl-sci

TL;DR: 磁铁矿纳米粒子的磁性状态受形状和尺寸影响。立方和细长形状会稳定涡旋状态。


<details>
  <summary>Details</summary>
Motivation: 研究磁铁矿纳米粒子的平衡磁态，重点关注尺寸、几何形状和磁晶各向异性之间的相互作用。

Method: 采用超球几何形状的微磁模拟研究了形状控制的磁铁矿纳米粒子。

Result: 研究了形状对从准均匀（单畴）到涡旋状状态转变的影响，确定了临界尺寸，并研究了立方磁晶各向异性和粒子细长度对涡旋结构和磁畴排列的影响。$

Conclusion: 该研究表明，即使是非球形度或长宽比的微小偏差也会显著改变磁序和平衡磁态的稳定性。

Abstract: The equilibrium magnetic states of single-domain magnetite nanoparticles
(NPs) result from a subtle interplay between size, geometry, and
magnetocrystalline anisotropy. In this work, we present a micromagnetic study
of shape-controlled magnetite NPs using the superball geometry, which provides
a continuous interpolation between spheres and cubes. By isolating the
influence of shape, we analyze the transition from quasi-uniform
(single-domain) to vortex-like states as particle size increases, revealing
critical sizes that depend on the superball exponent. Our simulations show that
faceted geometries promote the stabilization of vortex states at larger sizes,
with marked distortions in the vortex core structure. The inclusion of cubic
magnetocrystalline anisotropy, representative of magnetite, further lowers the
critical size and introduces preferential alignment along the [111] easy axes.
In contrast, the presence of slight particle elongation increases the critical
size and induces another preferential alignment direction. These results
demonstrate that even small deviations from sphericity or aspect ratio
significantly alter the magnetic ordering and stability of equilibrium magnetic
states.

</details>


### [465] [Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning](https://arxiv.org/abs/2508.02956)
*Alireza Ghafarollahi,Markus J. Buehler*

Main category: cond-mat.mtrl-sci

TL;DR: SparksMatter是一个多智能体AI模型，能够自主完成无机材料的设计、实验和优化，其性能在多个案例研究中优于现有模型，尤其在生成新颖且符合要求的材料方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统机器学习模型在无机材料设计中的局限性——即作为单次运行模型，其能力受限于训练数据中的潜在知识——本研究旨在创建一个能够自主执行完整无机材料发现周期的智能系统。

Method: SparksMatter是一个多智能体AI模型，能够自主执行从构思、规划到实验和迭代改进的完整无机材料发现周期，它能够生成想法、设计并执行实验工作流程、持续评估和改进结果，并最终提出满足目标要求的候选材料。该模型还能自我批判和改进，识别研究空白和局限性，并提出严格的后续验证步骤，包括DFT计算以及实验合成和表征，并嵌入结构良好的最终报告。

Result: SparksMatter在热电材料、半导体和钙钛矿氧化物材料设计案例研究中进行了性能评估。结果表明，SparksMatter能够生成满足用户需求的新型稳定无机结构。与前沿模型的基准测试显示，SparksMatter在相关性、新颖性和科学严谨性方面持续获得更高的分数，并且在多项现实世界设计任务中，新颖性得到了显著提升，该评估由盲评员进行。

Conclusion: SparksMatter在无机材料发现领域展示了超越现有材料知识生成化学有效、物理有意义且具有创造性的无机材料假设的独特能力，在相关性、新颖性和科学严谨性方面优于前沿模型。

Abstract: Conventional machine learning approaches accelerate inorganic materials
design via accurate property prediction and targeted material generation, yet
they operate as single-shot models limited by the latent knowledge baked into
their training data. A central challenge lies in creating an intelligent system
capable of autonomously executing the full inorganic materials discovery cycle,
from ideation and planning to experimentation and iterative refinement. We
introduce SparksMatter, a multi-agent AI model for automated inorganic
materials design that addresses user queries by generating ideas, designing and
executing experimental workflows, continuously evaluating and refining results,
and ultimately proposing candidate materials that meet the target objectives.
SparksMatter also critiques and improves its own responses, identifies research
gaps and limitations, and suggests rigorous follow-up validation steps,
including DFT calculations and experimental synthesis and characterization,
embedded in a well-structured final report. The model's performance is
evaluated across case studies in thermoelectrics, semiconductors, and
perovskite oxides materials design. The results demonstrate the capacity of
SparksMatter to generate novel stable inorganic structures that target the
user's needs. Benchmarking against frontier models reveals that SparksMatter
consistently achieves higher scores in relevance, novelty, and scientific
rigor, with a significant improvement in novelty across multiple real-world
design tasks as assessed by a blinded evaluator. These results demonstrate
SparksMatter's unique capacity to generate chemically valid, physically
meaningful, and creative inorganic materials hypotheses beyond existing
materials knowledge.

</details>


### [466] [Observation of Anomalous Hall Effect in Bulk Single Crystals of n-type Cr-doped Sb$_{2}$Te$_{3}$ Magnetic Topological Insulator](https://arxiv.org/abs/2508.03141)
*Ali Sarikhani,Mathew Pollard,Jacob Cook,Sheng Qiu,Seng Huat Lee,Laleh Avazpour,Jack Crewse,William Fahrenholtz,Guang Bian,Yew San Hor*

Main category: cond-mat.mtrl-sci

TL;DR: Cr掺杂Sb$_{2}$Te$_{3}$可实现n型磁性拓扑绝缘体，并可能用于量子反常霍尔效应。


<details>
  <summary>Details</summary>
Motivation: Sb$_{2}$Te$_{3}$理论上是拓扑绝缘体，但其p型性质阻碍了对狄拉克表面态的直接实验验证。本研究旨在通过掺杂解决这一问题。

Method: 通过掺杂Cr原子到Sb$_{2}$Te$_{3}$中，实现了n型行为，并观察到铁磁性和反常霍尔效应。

Result: Cr掺杂Sb$_{2}$Te$_{3}$表现出n型导电性，具有约170 K的磁转变温度，并伴有反常霍尔效应，使得费米能级可调控至带隙中。

Conclusion: Cr掺杂Sb$_{2}$Te$_{3}$表现出n型磁性拓扑绝缘体特性，并具有较高的磁转变温度（约170 K）和反常霍尔效应，有望应用于自旋电子学和量子器件。

Abstract: The exploration of topological Dirac surface states is significant in the
realms of condensed matter physics and future technological innovations. Among
the materials garnering attention is Sb$_{2}$Te$_{3}$, a compound that
theoretically exhibits topological insulating properties. However, its inherent
p-type nature prevents the direct experimental verification of its Dirac
surface state due to the Fermi level alignment with the valence band. In this
study, by doping Cr atoms into Sb$_{2}$Te$_{3}$, n-type behavior is observed in
the Hall resistance measurements. Remarkably, the Cr-doped Sb$_{2}$Te$_{3}$ not
only shows ferromagnetism with a high transition temperature of approximately
170 K but also exhibits an anomalous Hall effect (AHE). The Cr doping also
allows for a controlled method for Fermi level tuning into the band gap. These
properties spotlight its potential as an n-type magnetic topological insulator
(MTI) as well as a material candidate for the quantum anomalous Hall effect
(QAHE), opening new avenues for applications in spintronics and quantum
devices.

</details>


### [467] [The Open DAC 2025 Dataset for Sorbent Discovery in Direct Air Capture](https://arxiv.org/abs/2508.03162)
*Anuroop Sriram,Logan M. Brabson,Xiaohan Yu,Sihoon Choi,Kareem Abdelmaqsoud,Elias Moubarak,Pim de Haan,Sindy Löwe,Johann Brehmer,John R. Kitchin,Max Welling,C. Lawrence Zitnick,Zachary Ulissi,Andrew J. Medford,David S. Sholl*

Main category: cond-mat.mtrl-sci

TL;DR: A new dataset, ODAC25, with extensive DFT calculations on 15,000 MOFs, enhances the search for direct air capture materials. It includes diverse MOFs and improved computational methods, alongside new machine-learning potentials for predicting adsorption properties.


<details>
  <summary>Details</summary>
Motivation: Identifying effective sorbent materials for direct air capture from humid air is a significant challenge. This work aims to address this by providing a large and improved dataset (ODAC25) for evaluating MOFs and developing accurate machine-learned potentials for predicting their CO2 adsorption capabilities.

Method: The study presents the Open DAC 2025 (ODAC25) dataset, an expansion of ODAC23, which includes approximately 70 million DFT single-point calculations for CO2, H2O, N2, and O2 adsorption in 15,000 MOFs. The dataset incorporates functionalized MOFs, GCMC-derived placements, and synthetically generated frameworks, along with improved DFT accuracy and treatment of flexible MOFs. New machine-learned interatomic potentials were trained on ODAC25 and evaluated for adsorption energy and Henry's law coefficient predictions.

Result: The ODAC25 dataset contains nearly 70 million DFT calculations for 15,000 MOFs, showing improved accuracy and treatment of flexible MOFs compared to ODAC23. The released machine-learned potentials, trained on ODAC25, demonstrate good performance in predicting adsorption energy and Henry's law coefficients.

Conclusion: The ODAC25 dataset, with nearly 70 million DFT calculations for 15,000 MOFs, offers chemical and configurational diversity, improved accuracy, and better treatment of flexible MOFs, serving as a valuable resource for identifying direct air capture materials. New machine-learned potentials trained on this dataset also show promising results for predicting adsorption properties.

Abstract: Identifying useful sorbent materials for direct air capture (DAC) from humid
air remains a challenge. We present the Open DAC 2025 (ODAC25) dataset, a
significant expansion and improvement upon ODAC23 (Sriram et al., ACS Central
Science, 10 (2024) 923), comprising nearly 70 million DFT single-point
calculations for CO$_2$, H$_2$O, N$_2$, and O$_2$ adsorption in 15,000 MOFs.
ODAC25 introduces chemical and configurational diversity through functionalized
MOFs, high-energy GCMC-derived placements, and synthetically generated
frameworks. ODAC25 also significantly improves upon the accuracy of DFT
calculations and the treatment of flexible MOFs in ODAC23. Along with the
dataset, we release new state-of-the-art machine-learned interatomic potentials
trained on ODAC25 and evaluate them on adsorption energy and Henry's law
coefficient predictions.

</details>


### [468] [An Analytic Model to Determine the Interstitial-Solute Energetics and Underlying Mechanism in Refractory High-Entropy Alloys](https://arxiv.org/abs/2508.03163)
*Qianxi Zhu,Wang Gao,Qing Jiang*

Main category: cond-mat.mtrl-sci

TL;DR: 为RHEAs中INSs的稳定性和扩散性提供了一个分析模型，实现了电子层面的理解，并能指导RHEAs的设计。


<details>
  <summary>Details</summary>
Motivation: RHEAs中INSs的扩散和溶解普遍存在，并对其性能有重要影响，但RHEAs的局部化学环境无序阻碍了对其稳定性和扩散性的定量预测及机理理解。

Method: 基于紧束缚模型，提出一个分析模型，通过近似INS与其邻居之间的键合长度与邻居在元素状态下的原子半径，来确定INS在RHEA中的稳定性和扩散性。

Result: 预测模型识别出INSs的能量学与邻居的d带宽度呈线性关系，斜率由INSs的价态决定。该方案提供了对RHEAs中INSs的电子层面理解，并解释了关键的实验观察结果。

Conclusion: 该模型可以作为设计先进RHEA的有效工具

Abstract: The solution and diffusion of interstitial non-metallic solutes (INSs) like
H, He, O, C, N, P, and S is common in refractory high-entropy alloys (RHEAs)
and essentially controls the RHEAs properties. However, the disorder local
chemical environments of RHEAs hinder the quantitative prediction of the
stability and diffusivity of INSs and the understanding of the underlying
mechanism. Based on the tight-binding models, we propose an analytic model for
determining the stability and diffusivity of INSs in RHEAs, by approximating
the bonding length between INSs and their neighbors with the atomic radius of
the neighbors in elemental states. This predictive model identifies that the
energetics of INSs depends linearly on the d-band width of their neighbors,
with the slope determined by the valence of INSs. Our scheme provides an
electronic-level understanding of INSs in RHEAs and explains key experimental
observations, which can serve as an effective tool for designing advanced
RHEAs.

</details>


### [469] [Artificial Intelligence and Generative Models for Materials Discovery -- A Review](https://arxiv.org/abs/2508.03278)
*Albertus Denny Handoko,Riko I Made*

Main category: cond-mat.mtrl-sci

TL;DR: AI正在彻底改变材料发现，从实验驱动转向AI驱动的逆向设计。本综述探讨了AI生成模型在发现新材料（如催化剂、半导体）中的应用，同时解决了挑战，并讨论了集成AI与实验工作流的新兴方法，以加速可持续性、医疗保健和能源创新。


<details>
  <summary>Details</summary>
Motivation: 从过去的实验驱动方法转向人工智能驱动方法，实现“逆向设计”，根据期望的性质发现新材料。

Method: 本文讨论了适用于材料发现的AI驱动生成模型的原理，包括可用的材料表示方法，并重点介绍了生成模型在设计新催化剂、半导体、聚合物或晶体方面的具体应用。

Result: 讨论了AI驱动的生成模型在材料发现中的应用，解决了数据稀缺、计算成本、可解释性、合成性和数据集偏差等挑战。还讨论了克服限制和整合AI与实验工作流的新兴方法，包括多模态模型、物理信息架构和闭环发现系统。

Conclusion: AI驱动的生成模型在材料发现中具有加速可持续性、医疗保健和能源创新的潜力。

Abstract: High throughput experimentation tools, machine learning (ML) methods, and
open material databases are radically changing the way new materials are
discovered. From the experimentally driven approach in the past, we are moving
quickly towards the artificial intelligence (AI) driven approach, realizing the
'inverse design' capabilities that allow the discovery of new materials given
the desired properties. This review aims to discuss different principles of
AI-driven generative models that are applicable for materials discovery,
including different materials representations available for this purpose. We
will also highlight specific applications of generative models in designing new
catalysts, semiconductors, polymers, or crystals while addressing challenges
such as data scarcity, computational cost, interpretability, synthesizability,
and dataset biases. Emerging approaches to overcome limitations and integrate
AI with experimental workflows will be discussed, including multimodal models,
physics informed architectures, and closed-loop discovery systems. This review
aims to provide insights for researchers aiming to harness AI's transformative
potential in accelerating materials discovery for sustainability, healthcare,
and energy innovation.

</details>


### [470] [Multiscale Coupled Polarization and BKT Transitions in Tow-Dimensional Hybrid Organic-Inorganic Perovskites](https://arxiv.org/abs/2508.03285)
*Weijie Wu,Zehua Li,Yu Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一个优化的二维XY转子模型，用于分析混合有机-无机钙钛矿单层的极化动力学，该模型能够重现关键的实验特征，并为理解其复杂的相行为提供指导。


<details>
  <summary>Details</summary>
Motivation: 提出一个扩展的二维XY转子模型，以捕捉混合有机-无机钙钛矿单层的极化动力学。

Method: 通过结合分析粗粒化和在64*64格上的大规模蒙特卡洛模拟，研究了包含最近邻和次近邻耦合、晶体各向异性、外部偏置场和长程偶极相互作用的扩展二维XY转子模型。

Result: 模型识别出两个不同的热力学状态：低温准铁电状态（具有有限极化和畴壁形成）和高温BKT交叉（与涡旋-反涡旋解绑和长程有序抑制相关）。结果重现了准二维钙钛矿的关键实验特征，如介电磁化率中的双峰、近转变点涡旋密度的增加、外加场下的多稳态极化滞后以及畴壁宽度的标度行为。

Conclusion: 该模型为理解二维钙钛矿中的拓扑转变和铁电序共存提供了统一的视角，并为解释最近报道的极性涡旋晶格和复杂相行为提供了定量指导。

Abstract: We present an extended two-dimensional XY rotor model specifically designed
to capture the polarization dynamics of hybrid organic-inorganic perovskite
monolayers. This framework integrates nearest and next-nearest neighbor
couplings, crystalline anisotropy inherent to perovskite lattice symmetries,
external bias fields, and long-range dipolar interactions that are prominent in
layered perovskite architectures. Through a combination of analytical
coarse-graining and large-scale Monte Carlo simulations on 64*64 lattices, we
identify two distinct thermodynamic regimes: a low-temperature
quasi-ferroelectric state characterized by finite polarization and domain wall
formation, and a higher-temperature Berezinskii-Kosterlitz-Thouless (BKT)
crossover associated with vortex-antivortex unbinding and the suppression of
long-range order. Our results reproduce key experimental signatures observed in
quasi-two-dimensional perovskites, including dual peaks in dielectric
susceptibility, enhanced vortex density near the transition, multistable
polarization hysteresis under applied fields, and the scaling behavior of
domain wall widths. This minimal yet realistic model provides a unifying
perspective on how topological transitions and ferroelectric ordering coexist
in layered perovskite systems, offering quantitative guidance for interpreting
the emergent polar vortex lattices and complex phase behavior recently reported
in hybrid perovskite thin films.

</details>


### [471] [Machine learning potential for predicting thermal conductivity of θ-phase and amorphous Tantalum Nitride](https://arxiv.org/abs/2508.03297)
*Zhicheng Zong,Yangjun Qin,Jiahong Zhan,Haisheng Fang,Nuo Yang*

Main category: cond-mat.mtrl-sci

TL;DR: 深度势能模型和分子动力学模拟揭示了 TaN 的热导性质和影响因素。


<details>
  <summary>Details</summary>
Motivation: 为了解决 TaN 的 {	heta} 相在实验测量和理论预测之间存在的显著差异，并深入理解 TaN 的热输运机制。

Method: 开发了 TaN 的深度势能模型，并利用该模型进行分子动力学模拟，研究了块体和纳米薄膜的 TaN 在不同相态下的热导率，并将模拟结果与实验和理论结果进行了对比。

Result: 模拟结果与已报道的实验和理论结果进行了比较，并讨论了产生差异的机制。

Conclusion: 本研究通过深度势能模型和分子动力学模拟，研究了 TaN 的热导性质，并探讨了不同相态和纳米薄膜结构对其热输运机制的影响，为 TaN 在电子和热管理器件中的应用提供了指导。

Abstract: Tantalum nitride (TaN) has attracted considerable attention due to its unique
electronic and thermal properties, high thermal conductivity, and applications
in electronic components. However, for the {\theta}-phase of TaN, significant
discrepancies exist between previous experimental measurements and theoretical
predictions. In this study, deep potential models for TaN in both the
{\theta}-phase and amorphous phase were developed and employed in molecular
dynamics simulations to investigate the thermal conductivities of bulk and
nanofilms. The simulation results were compared with reported experimental and
theoretical results, and the mechanism for differences were discussed. This
study provides insights into the thermal transport mechanisms of TaN, offering
guidance for its application in advanced electronic and thermal management
devices.

</details>


### [472] [Thermal Metamaterials for Enhanced Non-Fourier Heat Transport](https://arxiv.org/abs/2508.03316)
*Harry Mclean,Francis Huw Davies,Ned Thaddeus Taylor,Steven Paul Hepplestone*

Main category: cond-mat.mtrl-sci

TL;DR: 通过将声子散射与热通量联系起来，我们得出了Cattaneo模型，并展示了热超材料具有超越傅里叶定律的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了释放热超材料在不同长度尺度上同时观测扩散和类波热传播的未开发潜力，需要超越傅里叶的理论。

Method: 通过新颖的微扰理论方法，将声子散射机制与宏观热通量联系起来，直接从粒子动力学推导出双曲Cattaneo模型，建立了弛豫时间与声子寿命之间的直接联系。

Result: 微尺度图案系统表现出扩展的非傅里叶特性，其中内部界面介导类波能量传播，与傅里叶的扩散预测有显著不同。

Conclusion: 该工作为超快热管理和纳米尺度能量应用提供了变革性的热超材料潜力，为下一代热技术奠定了理论基础。

Abstract: The untapped potential of thermal metamaterials requires the simultaneous
observation of both diffusive and wave-like heat propagation across multiple
length scales that can only be realised through theories beyond Fourier. Here,
we demonstrate that tailored material patterning significantly modifies heat
transport dynamics with enhanced non-Fourier behaviour. By bridging phonon
scattering mechanisms with macroscopic heat flux via a novel
perturbation-theory approach, we derive the hyperbolic Cattaneo model directly
from particle dynamics, establishing a direct link between relaxation time and
phonon lifetimes. Our micro-scale patterned systems exhibit extended
non-Fourier characteristics, where internal interfaces mediate wave-like energy
propagation, diverging sharply from diffusive Fourier predictions. These
results provide a unified framework connecting micro-scale interactions to
macroscopic transport, resolving long-standing limitations of the Cattaneo
model. This work underscores the transformative potential of thermal
metamaterials for ultra-fast thermal management and nanoscale energy
applications, laying a theoretical foundation for next-generation thermal
technologies.

</details>


### [473] [Metallic glasses heterogeneous and time sensitive small scale plasticity probed through nanoindentation and machine learning clustering](https://arxiv.org/abs/2508.03328)
*S. Pomes,T. Suzuki,T. Enokizono,N. Adachi,M. Wakeda,T. Ohmura*

Main category: cond-mat.mtrl-sci

TL;DR: 锆基非晶合金在微小尺度下表现出异质且随时间变化的塑性行为，机器学习聚类和塑性功耗分析有助于理解其变形机制。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索锆基非晶合金在微小尺度下的塑性和蠕变行为，并理解加载时间对这些行为的影响。

Method: 本研究采用纳米压痕技术，结合四种不同的加载函数（峰值载荷下的保持时间分别为0、10、30和60秒），研究了锆基非晶合金的微小塑性和蠕变行为。通过对塑性功耗的统计分析，识别了不同聚类中的变形机制。

Result: 结果显示，该合金表现出空间异质性和时间敏感性的塑性行为。通过机器学习聚类，发现了三种不同的变形机制。

Conclusion: 研究表明，基于硬度和蠕变位移的机器学习聚类可以识别出潜在的变形机制。

Abstract: Small-scale plasticity and creep behavior of a Zr-based BMG were investigated
using nanoindentation. Four load functions, differing only in hold times of 0,
10, 30, and 60 seconds at peak load, were applied. Results indicate spatially
heterogeneous and time-sensitive plastic behavior. Machine learning clustering,
based on hardness and creep displacement, suggested three clusters. Statistical
analysis of plastic energy distributions enabled identification of potential
deformation mechanisms within the clusters.

</details>


### [474] [Model Accuracy and Data Heterogeneity Shape Uncertainty Quantification in Machine Learning Interatomic Potentials](https://arxiv.org/abs/2508.03405)
*Fei Shuang,Zixiong Wei,Kai Liu,Wei Gao,Poulumi Dey*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究针对机器学习势能中的不确定性量化问题，提出了一种改进的 D-最优性方法，该方法通过聚类处理异质数据，能更准确地评估模型不确定性并检测新颖原子环境，从而提升模型在实际应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在机器学习势能（MLIP）模型中，虽然能够进行准确的原子尺度模拟，但可靠的不确定性量化（UQ）仍然是一个挑战。本研究旨在探索和改进 MLIP 的不确定性量化方法。

Method: 研究了集成学习和 D-最优性这两种不确定性量化策略，并将它们应用于原子近邻展开框架。为解决异质数据集上的局限性，提出了一种聚类增强的局部 D-最优性方法，该方法在训练过程中将构型空间划分为簇，并在每个簇内应用 D-最优性。

Result: 研究发现，模型精度越高，预测不确定性与实际误差之间的相关性越强，新颖性检测能力也越好，其中 D-最优性估计更保守。在同质训练集上，两种方法都能提供良好校准的不确定性估计，但在异质数据集上，它们会低估误差并且对新颖性的敏感度降低。聚类增强的局部 D-最优性方法显著提高了在异质数据集上检测新颖原子环境的能力。

Conclusion: 该研究揭示了模型精度和数据异质性在不确定性量化（UQ）性能中的作用，并提出了一种改进的 D-最优方法，可以在异质数据集上更可靠地检测新颖的原子环境，为机器学习势能（MLIP）的开发提供了鲁棒的主动学习和自适应采样策略。

Abstract: Machine learning interatomic potentials (MLIPs) enable accurate atomistic
modelling, but reliable uncertainty quantification (UQ) remains elusive. In
this study, we investigate two UQ strategies, ensemble learning and
D-optimality, within the atomic cluster expansion framework. It is revealed
that higher model accuracy strengthens the correlation between predicted
uncertainties and actual errors and improves novelty detection, with
D-optimality yielding more conservative estimates. Both methods deliver well
calibrated uncertainties on homogeneous training sets, yet they underpredict
errors and exhibit reduced novelty sensitivity on heterogeneous datasets. To
address this limitation, we introduce clustering-enhanced local D-optimality,
which partitions configuration space into clusters during training and applies
D-optimality within each cluster. This approach substantially improves the
detection of novel atomic environments in heterogeneous datasets. Our findings
clarify the roles of model fidelity and data heterogeneity in UQ performance
and provide a practical route to robust active learning and adaptive sampling
strategies for MLIP development.

</details>


### [475] [Symmetry-breaking-induced topology in FeSe](https://arxiv.org/abs/2508.03427)
*Mikel García-Díez,Jonas B. Profe,Augustin Davignon,Steffen Backes,Roser Valentí,Maia G. Vergniory*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究发现了在块状FeSe中实现拓扑相的新方法，即通过施加应变或引起结构相变来诱导拓扑绝缘体相。


<details>
  <summary>Details</summary>
Motivation: 尽管在某些铁基超导体（如掺Te的FeSe和单层FeSe）中已识别出拓扑非平凡相，但块状FeSe中的拓扑性质在很大程度上仍未被探索。

Method: 本研究采用密度泛函理论计算，并利用拓扑量子化学和基于对称性的指标分析能带结构。

Result: 研究结果表明，单轴应变和到斜方相的结构转变可以导致FeSe进入强拓扑绝缘体相，并且该拓扑特性在考虑电子关联时具有鲁棒性。

Conclusion: 本研究提出了在块状FeSe中实现拓扑相的新途径，即通过打破面内$C_4$旋转对称性，降低晶体对称性，将FeSe驱动为强拓扑绝缘体相。结果表明，单轴应变和到低温斜方相的结构转变均可导致非平凡能带拓扑，且电子关联对费米能级附近的拓扑特性影响不大。

Abstract: FeSe has been one of the most intensively studied iron-based superconductors
over the past two decades, exhibiting a wide range of phenomena such as
unconventional superconductivity, nematic order, magnetism, orbital-selective
correlations, and structural phase transitions. While topologically non-trivial
phases have been identified in certain cases - such as Te-doped FeSe and
monolayer FeSe - topology in bulk FeSe has largely remained unexplored. In this
work, we propose a new route to realize topological phases directly in bulk
FeSe. We demonstrate that breaking the in-plane $C_4$ rotational symmetry,
thereby lowering the crystal symmetry, can drive FeSe into a strong topological
insulating phase. To support this, we perform density functional theory
calculations and analyze the band structure using topological quantum chemistry
and symmetry-based indicators. Our results show that both uniaxial strain and
the structural transition to the orthorhombic low-temperature phase lead to
non-trivial band topology. Moreover, incorporating electronic correlations
through dynamical mean field theory reveals that the topological
characteristics near the Fermi level remain robust, as the relevant bands
experience only moderate renormalization. These findings highlight strain as a
promising mechanism to induce topological phases in FeSe.

</details>


### [476] [Tentative demonstration of all-silicon photodetector: from near-infrared to mid-infrared](https://arxiv.org/abs/2508.03505)
*Jiaxin Ming,Yubing Du,Tongtong Xue,Yunyun Dai,Yabin Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过激光退火技术制备了全硅光电探测器，实现了近红外到中红外波段的探测，并揭示了不同亚稳态硅相的光电导特性。


<details>
  <summary>Details</summary>
Motivation: 亚稳态硅相因其与传统金刚石立方（I）相不同的光电特性而备受关注。某些亚稳态相（通过热加热方法制备）表现出直接带隙特性，显著提高了其光吸收和量子效率。本研究旨在探索利用这些亚稳态硅相制造全硅光电探测器。

Method: 通过精确选择性激光退火策略制备全硅光电探测器，并系统研究了III/XII混合相、IV相以及III/XII-I同质结的光学和光电响应。

Result: III/XII复合相和IV相分别表现出负光电导和正光电导。通过激光退火方法可以制备具有可调光电导特性的全硅同质结构，例如III/XII-I和IV-I结。

Conclusion: 该研究通过选择性激光退火策略制备了全硅光电探测器，实现了近红外到中红外波段的工作。研究结果表明，III/XII复合相和IV相分别表现出负光电导和正光电导。此外，激光加热方法能够制备具有可调光电导特性的全硅同质结构，如III/XII-I和IV-I结。这些发现为亚稳态半导体材料在光电和光电探测器领域的应用提供了新的可能性。

Abstract: Metastable silicon phases have attracted extensive attention these years, due
to their fundamentally distinct photoelectric properties compared to the
conventional diamond cubic (I) counterpart. Certain metastable phases, prepared
via thermal heating method, can exhibit direct bandgap characteristics,
significantly enhancing their light absorbance and quantum efficiency. Herein,
we tentatively demonstrate an all-silicon photodetector working from near- to
mid-infrared bands through precisely selective laser annealing strategy. We
systematically investigated the optical properties and optoelectronic response
of III/XII mixture, IV phase, and III/XII-I homojunctions. The obtained results
reveal that III/XII composite and IV phase exhibit negative and positive
photoconductivity, respectively. Furthermore, the established laser heating
approach facilitates us to fabricate all-silicon homostructures with tunable
photoconductive properties, such as III/XII-I and IV-I junctions. These
findings can expand the potential applications of metastable semiconducting
materials in optoelectronics and photodetectors.

</details>


### [477] [Revealing Polymorph-Specific Transduction in WO$_3$ during Acetone Sensing](https://arxiv.org/abs/2508.03510)
*Matteo D'Andria,Meng Yin,Stefan Neuhauser,Vlasis G. Mavrantzas,Ying Chen,Ken Suzuki,Andreas T. Guentner*

Main category: cond-mat.mtrl-sci

TL;DR: WO$_3$多晶型物的传感性能差异是由于分析物诱导的电子态，而非净电荷转移。ε-WO$_3$的传感效率更高是因为它能稳定这些电子态。


<details>
  <summary>Details</summary>
Motivation: WO$_3$多晶型物的分子传感性能已有广泛研究，但其不同变体产生不同化学电阻特性的机制尚不清楚。

Method: 结合了原位功函数测量、化学吸附分析、原位光谱以及密度泛函理论计算，并以三氧化钨（WO$_3$）多晶型物和丙酮为例进行了研究。

Result: 研究发现，WO$_3$多晶型物的传感性能差异源于分析物诱导的电子态，而非通常认为的净电荷转移。ε-WO$_3$通过稳定分析物诱导的、源自W(5d)轨道的电子态，提高了传感效率。

Conclusion: 该研究提出了一种新的基于能级匹配的传感器设计理论，为开发高性能化学传感器提供了新的视角。

Abstract: Polymorphs are distinct structural forms of the same compound and offer
unique opportunities to tailor material properties without altering chemical
composition. In particular, the polymorphs of WO$_3$ have been widely explored
for their molecular sensing performance; yet, the mechanistic aspects behind
their different chemoresistive properties have remained elusive or poorly
understood. Here, we highlight the energetic allocation of transferred charge
as a critical aspect for chemoresistive response generation, providing a new
perspective beyond more conventional net-transfer metrics, which are usually
deployed to investigate gas-solid interactions. To this, we combined operando
work function, chemisorption analysis, and in situ spectroscopy with density
functional theory calculations on the example of acetone. Both gamma- and
$\varepsilon$-WO$_3$ exhibit comparable surface-level activation of acetone,
mediated by electron-deficient, coordinatively unsaturated tungsten sites.
However, only $\varepsilon$-WO$_3$ stabilizes analyte-induced electronic states
derived from W(5d) orbitals lying just below the conduction band - an
energetically favourable region for conductivity modulation under operating
conditions. While being associated with marginal work function shifts, these
states reflect deeper subsurface electronic rearrangements that may underlie
the $\varepsilon$-WO$_3$'s superior transduction efficiency despite similar
receptor chemistry. Our results offer a new framework for rational transducer
development rooted in intrinsic electronic structure.

</details>


### [478] [High-temperature and high-pressure study on columbite structured ZnNb2O6](https://arxiv.org/abs/2508.03658)
*A. Tyagi,P. Botella,A. B. Garg,J. Sanchez-Martin,D. Diaz-Anichtchenko,R. Turnbull,S. Anzellini,C. Popescu,D. Errandonea*

Main category: cond-mat.mtrl-sci

TL;DR: ZnNb2O6在10 GPa时从斜方相转变为单斜相，高压下单斜相稳定。研究了其结构、热膨胀和弹性性质。


<details>
  <summary>Details</summary>
Motivation: 研究铌酸锌（ZnNb2O6）在高温高压下的相稳定性和结构行为，以了解其在极端条件下的物理性质。

Method: 通过同步辐射粉末X射线衍射和拉曼光谱，在高达873 K的温度和30 GPa的压力下，研究了ZnNb2O6的晶体结构和声子行为。

Result: 在高温下，ZnNb2O6的斜方晶系（Pbcn）相是稳定的，其热膨胀系数与同构化合物相似。在10 GPa压力下，观察到可逆相变，晶体结构转变为单斜晶系（P2/a），并在高达30 GPa的压力下保持稳定。相变伴随着拉曼模式、晶格参数和单位晶胞体积的变化，单位晶胞体积的2.5%不连续性表明这是一阶相变。斜方晶系和单斜晶系的体弹性模量分别为165(7) GPa和230(9) GPa，且两者均表现出对压力的各向异性响应。

Conclusion: ZnNb2O6在10 GPa压力下从斜方晶系（Pbcn）转变为单斜晶系（P2/a），并在高达30 GPa的压力下保持稳定。斜方晶系和单斜晶系的体弹性模量分别为165(7) GPa和230(9) GPa，两者都表现出对压力的各向异性响应。第一性原理计算支持这些实验结果。

Abstract: High-temperature and high-pressure experiments were conducted on
columbite-type ZnNb2O6, reaching temperatures up to 873 K at ambient pressure
and pressures up to 30 GPa at ambient temperature, respectively. Through
systematic analysis employing synchrotron powder X-ray diffraction and Raman
spectroscopy, we examined the crystal structure and phonon behavior. Within the
specified temperature range, the orthorhombic phase of ZnNb2O6 (space group:
Pbcn) demonstrated notable phase stability, with a thermal expansion
coefficient similar to that of isomorphic compounds. Notably, a reversible
phase transition was observed under compression at 10 GPa, with diffraction
experiments indicating a shift to a monoclinic structure (space group P2/a),
which remained stable up to 30 GPa. Changes in Raman modes, lattice parameters,
and the unit-cell volume were monitored. A significant 2.5% discontinuity in
the unit-cell volume at the phase transition pressure from orthorhombic to
monoclinic suggests a first-order phase transition. The bulk moduli of the
orthorhombic and monoclinic phases were estimated as 165(7) GPa and 230(9) GPa,
respectively- We also found that both phases exhibit an anisotropic response to
pressure. Furthermore, first-principles calculations support consistently with
experimental observations.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [479] [Neighborhood-Preserving Voronoi Treemaps](https://arxiv.org/abs/2508.03445)
*Patrick Paetzold,Rebecca Kehlbeck,Yumeng Xue,Bin Chen,Yunhai Wang,Oliver Deussen*

Main category: cs.GR

TL;DR: 我们提出了一种新的Voronoi图算法，该算法利用数据相似性生成能够保持邻域的Voronoi图，并针对信息图和语言学等现实世界的例子进行了演示。


<details>
  <summary>Details</summary>
Motivation: 为了在可视化中同时展示数据属性，如共现特征或相似性，并改进现有的Voronoi图算法，使其能够保留数据相似性。

Method: 首先，我们扩展了其尺寸布局管线，在数据预处理阶段就纳入了相似性。接着，我们使用Kuhn-Munkres算法进行最优分配，将相似性与质心Voronoi图（CVT）单元格相匹配，从而生成具有相同单元格尺寸的初始Voronoi图。通过贪婪算法进行交换，可以进一步优化单元格的邻域以匹配数据的相似性。

Result: 该算法通过真实世界的案例，包括信息图表和语言学，证明了其实用性。通过采用尺寸度量和邻域保持性测量，对生成的Voronoi图进行了量化评估。

Conclusion: 该算法能够通过调整单元格面积来优化邻域保持性，并能在保持邻域的同时将单元格面积迭代地调整至各自的尺寸。

Abstract: Voronoi treemaps are used to depict nodes and their hierarchical
relationships simultaneously. However, in addition to the hierarchical
structure, data attributes, such as co-occurring features or similarities,
frequently exist. Examples include geographical attributes like shared borders
between countries or contextualized semantic information such as embedding
vectors derived from large language models. In this work, we introduce a
Voronoi treemap algorithm that leverages data similarity to generate
neighborhood-preserving treemaps. First, we extend the treemap layout pipeline
to consider similarity during data preprocessing. We then use a Kuhn-Munkres
matching of similarities to centroidal Voronoi tessellation (CVT) cells to
create initial Voronoi diagrams with equal cell sizes for each level. Greedy
swapping is used to improve the neighborhoods of cells to match the data's
similarity further. During optimization, cell areas are iteratively adjusted to
their respective sizes while preserving the existing neighborhoods. We
demonstrate the practicality of our approach through multiple real-world
examples drawn from infographics and linguistics. To quantitatively assess the
resulting treemaps, we employ treemap metrics and measure neighborhood
preservation.

</details>


### [480] [READ: Real-time and Efficient Asynchronous Diffusion for Audio-driven Talking Head Generation](https://arxiv.org/abs/2508.03457)
*Haotian Wang,Yuzhe Weng,Jun Du,Haoran Xu,Xiaoyan Wu,Shan He,Bing Yin,Cong Liu,Jianqing Gao,Qingfeng Liu*

Main category: cs.GR

TL;DR: READ是一个首个实现实时性、基于扩散Transformer的说话头生成框架，通过引入时空压缩潜在空间和异步噪声调度器，在保证生成质量的同时大幅提升了生成速度。


<details>
  <summary>Details</summary>
Motivation: 目前的基于扩散模型的说话头生成方法存在推理速度极慢的问题，限制了其实际应用。

Method: READ框架首先通过时间VAE学习时空高度压缩的视频潜在空间，然后提出预训练的Speech Autoencoder（SpeechAE）生成与视频潜在空间对应的压缩语音潜在码，接着利用精心设计的Audio-to-Video Diffusion Transformer（A2V-DiT）骨干网络建模这些潜在表示进行高效的说话头合成。此外，提出了一种新颖的异步噪声调度器（ANS），在训练和推理过程中利用异步加噪和异步运动引导生成，以确保生成视频片段的时序一致性并加速推理。

Result: 实验结果表明，READ的性能优于现有最先进的方法，能够生成具有竞争力的说话头视频，同时显著减少了运行时间。

Conclusion: READ框架在生成质量和速度之间取得了最佳平衡，同时在长时间生成中保持了鲁棒的指标稳定性。

Abstract: The introduction of diffusion models has brought significant advances to the
field of audio-driven talking head generation. However, the extremely slow
inference speed severely limits the practical implementation of diffusion-based
talking head generation models. In this study, we propose READ, the first
real-time diffusion-transformer-based talking head generation framework. Our
approach first learns a spatiotemporal highly compressed video latent space via
a temporal VAE, significantly reducing the token count to accelerate
generation. To achieve better audio-visual alignment within this compressed
latent space, a pre-trained Speech Autoencoder (SpeechAE) is proposed to
generate temporally compressed speech latent codes corresponding to the video
latent space. These latent representations are then modeled by a carefully
designed Audio-to-Video Diffusion Transformer (A2V-DiT) backbone for efficient
talking head synthesis. Furthermore, to ensure temporal consistency and
accelerated inference in extended generation, we propose a novel asynchronous
noise scheduler (ANS) for both the training and inference process of our
framework. The ANS leverages asynchronous add-noise and asynchronous
motion-guided generation in the latent space, ensuring consistency in generated
video clips. Experimental results demonstrate that READ outperforms
state-of-the-art methods by generating competitive talking head videos with
significantly reduced runtime, achieving an optimal balance between quality and
speed while maintaining robust metric stability in long-time generation.

</details>
