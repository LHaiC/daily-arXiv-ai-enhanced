<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 85]
- [cs.CL](#cs.CL) [Total: 64]
- [quant-ph](#quant-ph) [Total: 47]
- [cs.RO](#cs.RO) [Total: 28]
- [cs.DS](#cs.DS) [Total: 11]
- [cs.DC](#cs.DC) [Total: 7]
- [eess.SY](#eess.SY) [Total: 21]
- [cs.AI](#cs.AI) [Total: 38]
- [cs.ET](#cs.ET) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 14]
- [cs.SI](#cs.SI) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.GT](#cs.GT) [Total: 2]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [eess.SP](#eess.SP) [Total: 21]
- [cs.LG](#cs.LG) [Total: 102]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Fourier-Based GAN Fingerprint Detection using ResNet50](https://arxiv.org/abs/2510.19840)
*Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru*

Main category: cs.CV

TL;DR: 本研究提出了一种结合频域分析和深度学习的方法，使用2D DFT和ResNet50来区分StyleGAN生成的图像和真实图像，实验证明该方法在区分率和AUC方面表现优于仅使用原始图像的方法。


<details>
  <summary>Details</summary>
Motivation: 随着GANs生成图像的逼真度不断提高，图像取证和内容真实性认证面临严峻挑战。

Method: 将图像通过二维离散傅里叶变换（2D DFT）转换到频域，然后利用ResNet50神经网络对频域图像进行训练，以区分真实图像和StyleGAN生成的图像。

Result: 在实验中，该频域模型达到了92.8%的准确率和0.95的AUC，显著优于在原始空间域图像上训练的等效模型。

Conclusion: GAN生成的图像在频域具有独特的“指纹”或签名。结合信号处理技术和深度学习是增强数字取证和工业AI系统可信度的有效途径。

Abstract: The rapid rise of photorealistic images produced from Generative Adversarial
Networks (GANs) poses a serious challenge for image forensics and industrial
systems requiring reliable content authenticity. This paper uses
frequency-domain analysis combined with deep learning to solve the problem of
distinguishing StyleGAN-generated images from real ones. Specifically, a
two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform
images into the Fourier domain, where subtle periodic artifacts become
detectable. A ResNet50 neural network is trained on these transformed images to
differentiate between real and synthetic ones. The experiments demonstrate that
the frequency-domain model achieves a 92.8 percent and an AUC of 0.95,
significantly outperforming the equivalent model trained on raw spatial-domain
images. These results indicate that the GAN-generated images have unique
frequency-domain signatures or "fingerprints". The method proposed highlights
the industrial potential of combining signal processing techniques and deep
learning to enhance digital forensics and strengthen the trustworthiness of
industrial AI systems.

</details>


### [2] [Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses](https://arxiv.org/abs/2510.20027)
*Damian Bowness,Charalambos Poullis*

Main category: cs.CV

TL;DR: 为解决3D高斯泼溅（3DGS）模型在训练数据分布之外的相机位置上出现的视觉噪声问题，提出了一种新的渲染感知滤波方法。该方法利用中间梯度的敏感性得分，针对各向异性方向引起的_不稳定性_，而非各向同性方差。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）模型在训练数据分布之外的相机位置上会出现严重的视觉噪声，这是由于模型在这些区域的密度、颜色和几何预测不确定性所致。

Method: 提出一种新的实时渲染感知滤波方法，利用中间梯度的敏感性得分，明确针对由各向异性方向引起的_不稳定性_，而非各向同性方差。

Result: 与现有的基于神经辐射场（NeRF）的方法（如BayesRays）相比，该方法显著提高了视觉质量、真实感和一致性。该过滤器可以实时集成到现有的3DGS渲染管线中，无需进行大量的_事后_重新训练或微调。

Conclusion: 该方法能够有效解决3DGS模型在训练数据分布之外的相机位置上出现的视觉噪声问题，并保持高视觉保真度，允许用户自由_导航_到原始训练视角之外的区域。

Abstract: When viewing a 3D Gaussian Splatting (3DGS) model from camera positions
significantly outside the training data distribution, substantial visual noise
commonly occurs. These artifacts result from the lack of training data in these
extrapolated regions, leading to uncertain density, color, and geometry
predictions from the model.
  To address this issue, we propose a novel real-time render-aware filtering
method. Our approach leverages sensitivity scores derived from intermediate
gradients, explicitly targeting instabilities caused by anisotropic
orientations rather than isotropic variance. This filtering method directly
addresses the core issue of generative uncertainty, allowing 3D reconstruction
systems to maintain high visual fidelity even when users freely navigate
outside the original training viewpoints.
  Experimental evaluation demonstrates that our method substantially improves
visual quality, realism, and consistency compared to existing Neural Radiance
Field (NeRF)-based approaches such as BayesRays. Critically, our filter
seamlessly integrates into existing 3DGS rendering pipelines in real-time,
unlike methods that require extensive post-hoc retraining or fine-tuning.
  Code and results at https://damian-bowness.github.io/EV3DGS

</details>


### [3] [Transformed Multi-view 3D Shape Features with Contrastive Learning](https://arxiv.org/abs/2510.19955)
*Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: ViTs与对比学习的结合在3D形状理解方面取得了显著成效，提高了准确性，并减少了对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉方法在从2D图像识别3D物体方面存在挑战，通常需要大量标注数据，并且依赖可能忽略关键形状关系的CNN。

Method: 研究了用于3D形状特征表示学习的最先进骨干网络，并结合了对比监督和自监督学习目标，重点考察了Vision Transformers (ViTs)架构。

Result: 基于ViTs的架构与现代对比目标结合，在下游任务的多视图3D分析中取得了有希望的结果，例如，在ModelNet10上达到了约90.6%的准确率。

Conclusion: ViTs和对比学习的结合能够克服对大量标注数据的需求以及CNN在捕捉关键形状关系方面的局限性，这得益于ViTs捕捉全局形状语义的能力以及对比学习优化局部判别性特征的有效性。

Abstract: This paper addresses the challenges in representation learning of 3D shape
features by investigating state-of-the-art backbones paired with both
contrastive supervised and self-supervised learning objectives. Computer vision
methods struggle with recognizing 3D objects from 2D images, often requiring
extensive labeled data and relying on Convolutional Neural Networks (CNNs) that
may overlook crucial shape relationships. Our work demonstrates that Vision
Transformers (ViTs) based architectures, when paired with modern contrastive
objectives, achieve promising results in multi-view 3D analysis on our
downstream tasks, unifying contrastive and 3D shape understanding pipelines.
For example, supervised contrastive losses reached about 90.6% accuracy on
ModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability
to understand overall shapes and contrastive learning's effectiveness,
overcomes the need for extensive labeled data and the limitations of CNNs in
capturing crucial shape relationships. The success stems from capturing global
shape semantics via ViTs and refining local discriminative features through
contrastive optimization. Importantly, our approach is empirical, as it is
grounded on extensive experimental evaluation to validate the effectiveness of
combining ViTs with contrastive objectives for 3D representation learning.

</details>


### [4] [From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail](https://arxiv.org/abs/2510.20558)
*Xiaohan Sun,Carol O'Sullivan*

Main category: cs.CV

TL;DR: 本文研究了用户在不同细节层次（LoD）和视角下对人群表示的视觉质量的感知，并分析了几何网格、基于图像的假视物、神经辐射场（NeRF）和3D高斯三种方法的优缺点。


<details>
  <summary>Details</summary>
Motivation: 研究用户对不同细节层次（LoD）和视角下人群表示的视觉质量的感知，以指导设计感知优化的LoD策略。

Method: 分析了几何网格、基于图像的假视物、神经辐射场（NeRF）和3D高斯四种人群表示方法在视觉保真度和计算性能方面的权衡。

Result: 提供了定性和定量的结果，以指导设计感知优化的LoD策略。

Conclusion: 用户的感知对于优化人群渲染的LoD策略至关重要。

Abstract: In this paper, we investigate how users perceive the visual quality of crowd
character representations at different levels of detail (LoD) and viewing
distances. Each representation: geometric meshes, image-based impostors, Neural
Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between
visual fidelity and computational performance. Our qualitative and quantitative
results provide insights to guide the design of perceptually optimized LoD
strategies for crowd rendering.

</details>


### [5] [FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking](https://arxiv.org/abs/2510.19981)
*Martha Teiko Teye,Ori Maoz,Matthias Rottmann*

Main category: cs.CV

TL;DR: FutrTrack是一个模块化的相机-激光雷达多目标跟踪框架，利用基于Transformer的平滑器和融合驱动的跟踪器，在nuScenes和KITTI数据集上实现了74.7 aMOTA，减少了身份切换并保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有3D检测器在多目标跟踪方面存在不足，特别是在遮挡和视角变化下，需要更鲁棒的方法来处理身份分配和传播。

Method: 提出了一种基于Transformer的平滑器和融合驱动的跟踪器。融合跟踪器集成了来自多个相机和激光雷达的边界框和多模态鸟瞰图（BEV）融合特征，无需显式运动模型。在跟踪之前，使用移动窗口上的时间平滑器来细化边界框序列，以改进轨迹、减少抖动并提高空间一致性。

Result: 在nuScenes和KITTI数据集上进行了评估。FutrTrack在nuScenes测试集上实现了74.7的aMOTA，展示了基于Transformer的跟踪方法从多模态传感器特征中获益良多，相比之前的单传感器方法，减少了身份切换，同时保持了有竞争力的准确性。

Conclusion: FutrTrack提供了一个有效的框架，能够改进基于Transformer的跟踪器，使其即使在数据有限且没有预训练的情况下也能与其他的神经网络方法相媲美。

Abstract: We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework
that builds on existing 3D detectors by introducing a transformer-based
smoother and a fusion-driven tracker. Inspired by query-based tracking
frameworks, FutrTrack employs a multimodal two-stage transformer refinement and
tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal
bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without
the need for an explicit motion model. The tracker assigns and propagates
identities across frames, leveraging both geometric and semantic cues for
robust re-identification under occlusion and viewpoint changes. Prior to
tracking, we refine sequences of bounding boxes with a temporal smoother over a
moving window to refine trajectories, reduce jitter, and improve spatial
consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that
query-based transformer tracking methods benefit significantly from multimodal
sensor features compared with previous single-sensor approaches. With an aMOTA
of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D
MOT benchmarks, reducing identity switches while maintaining competitive
accuracy. Our approach provides an efficient framework for improving
transformer-based trackers to compete with other neural-network-based methods
even with limited data and without pretraining.

</details>


### [6] [Improving Predictive Confidence in Medical Imaging via Online Label Smoothing](https://arxiv.org/abs/2510.20011)
*Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry*

Main category: cs.CV

TL;DR: 深度学习模型在医学图像分类中表现出色，但预测过于自信。本研究提出在线标签平滑（OLS）方法，通过动态调整软标签来解决此问题，并在RadImageNet数据集上使用ResNet-50、MobileNetV2和VGG-19进行了验证。OLS在提高分类准确率的同时，还能生成更紧凑、分离度更好的特征嵌入，表明其在提升模型性能和可信度方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 传统的标签平滑方法未能考虑类别间的关系，而深度学习模型在医学图像分类中常出现预测过于自信的问题，这在医疗等关键领域会降低其可靠性。

Method: 提出并评估在线标签平滑（OLS）方法，这是一种动态方法，根据模型自身的预测模式在训练过程中调整软标签。在大型RadImageNet数据集上，使用ResNet-50、MobileNetV2和VGG-19三种常用架构进行评估。

Result: 与标准训练方法（包括硬标签、传统标签平滑和无教师知识蒸馏）相比，OLS在Top-1和Top-5分类准确率上均得到持续提升。此外，OLS还能生成更紧凑、分离度更好的特征嵌入，表明其提升了表示学习能力。

Conclusion: OLS不仅能提高预测性能，还能增强模型校准能力，是开发医学影像领域可信赖的AI系统的实用且有效的解决方案。

Abstract: Deep learning models, especially convolutional neural networks, have achieved
impressive results in medical image classification. However, these models often
produce overconfident predictions, which can undermine their reliability in
critical healthcare settings. While traditional label smoothing offers a simple
way to reduce such overconfidence, it fails to consider relationships between
classes by treating all non-target classes equally. In this study, we explore
the use of Online Label Smoothing (OLS), a dynamic approach that adjusts soft
labels throughout training based on the model's own prediction patterns. We
evaluate OLS on the large-scale RadImageNet dataset using three widely used
architectures: ResNet-50, MobileNetV2, and VGG-19. Our results show that OLS
consistently improves both Top-1 and Top-5 classification accuracy compared to
standard training methods, including hard labels, conventional label smoothing,
and teacher-free knowledge distillation. In addition to accuracy gains, OLS
leads to more compact and well-separated feature embeddings, indicating
improved representation learning. These findings suggest that OLS not only
strengthens predictive performance but also enhances calibration, making it a
practical and effective solution for developing trustworthy AI systems in the
medical imaging domain.

</details>


### [7] [A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance](https://arxiv.org/abs/2510.20016)
*Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 该研究提出了一种用于鱼眼摄像头的目标检测框架，通过预处理、后处理和模型集成来解决鱼眼图像的畸变和分辨率不均问题，在AI City Challenge竞赛中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 鱼眼摄像头虽然能覆盖广阔区域，但其固有的径向畸变和不均一分辨率严重影响了标准目标检测器的性能，尤其是在图像边界区域。

Method: 提出一个包含预处理和后处理的检测框架，以增强图像整体的检测一致性，并采用模型集成策略来提高检测精度。

Result: 在2025 AI City Challenge Track 4竞赛中，该方法实现了0.6366的F1分数，在62支队伍中排名第8。

Conclusion: 所提出的框架能有效解决鱼眼图像的固有问题，在实际应用中表现出良好的目标检测能力。

Abstract: Fisheye cameras offer an efficient solution for wide-area traffic
surveillance by capturing large fields of view from a single vantage point.
However, the strong radial distortion and nonuniform resolution inherent in
fisheye imagery introduce substantial challenges for standard object detectors,
particularly near image boundaries where object appearance is severely
degraded. In this work, we present a detection framework designed to operate
robustly under these conditions. Our approach employs a simple yet effective
pre and post processing pipeline that enhances detection consistency across the
image, especially in regions affected by severe distortion. We train several
state-of-the-art detection models on the fisheye traffic imagery and combine
their outputs through an ensemble strategy to improve overall detection
accuracy. Our method achieves an F1 score of0.6366 on the 2025 AI City
Challenge Track 4, placing 8thoverall out of 62 teams. These results
demonstrate the effectiveness of our framework in addressing issues inherent to
fisheye imagery.

</details>


### [8] [BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography](https://arxiv.org/abs/2510.20029)
*Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin*

Main category: cs.CV

TL;DR: 提出一种名为BrainPuzzle的混合框架，结合物理模型和机器学习，通过反向时间迁移和基于图注意力单元的Transformer实现量化经颅超声成像，解决了传统方法的信号衰减、覆盖不全和数据驱动方法偏差等问题，并在合成数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有技术在经颅超声成像中存在的声速差异大、探头耦合困难、信号衰减、覆盖不全以及数据驱动方法偏差等问题，实现量化经颅超声。

Method: 提出一个名为BrainPuzzle的混合两阶段框架。第一阶段使用反向时间迁移（时间反转声学）处理多角度采集数据，生成包含结构细节的迁移片段。第二阶段使用基于图注意力单元（GAU）的Transformer超分辨率编码器-解码器融合这些片段，生成精确的声速（SoS）图像。采用移动式低计数换能器集的局部阵列采集策略。

Result: BrainPuzzle在两个合成数据集上的实验显示，在SoS重建精度和图像完整性方面均表现优越，证明了其在推动量化超声大脑成像方面的潜力。

Conclusion: BrainPuzzle框架通过结合物理建模和机器学习，有效解决了现有经颅超声成像技术的挑战，能够生成精确完整的声速图，为量化超声大脑成像提供了有前景的解决方案。

Abstract: Ultrasound brain imaging remains challenging due to the large difference in
sound speed between the skull and brain tissues and the difficulty of coupling
large probes to the skull. This work aims to achieve quantitative transcranial
ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain.
Traditional physics-based full-waveform inversion (FWI) is limited by weak
signals caused by skull-induced attenuation, mode conversion, and phase
aberration, as well as incomplete spatial coverage since full-aperture arrays
are clinically impractical. In contrast, purely data-driven methods that learn
directly from raw ultrasound data often fail to model the complex nonlinear and
nonlocal wave propagation through bone, leading to anatomically plausible but
quantitatively biased SoS maps under low signal-to-noise and sparse-aperture
conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage
framework that combines physical modeling with machine learning. In the first
stage, reverse time migration (time-reversal acoustics) is applied to
multi-angle acquisitions to produce migration fragments that preserve
structural details even under low SNR. In the second stage, a transformer-based
super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses
these fragments into a coherent and quantitatively accurate SoS image. A
partial-array acquisition strategy using a movable low-count transducer set
improves feasibility and coupling, while the hybrid algorithm compensates for
the missing aperture. Experiments on two synthetic datasets show that
BrainPuzzle achieves superior SoS reconstruction accuracy and image
completeness, demonstrating its potential for advancing quantitative ultrasound
brain imaging.

</details>


### [9] [Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models](https://arxiv.org/abs/2510.20042)
*Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 生成图像模型存在文化偏见，尤其是在图像到图像编辑方面。本研究提出了一个跨国、跨时代、跨类别的标准化评估框架，并发布了相关数据集和协议，以诊断和追踪生成图像模型中的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本到图像（T2I）系统的文化偏见，而对图像到图像（I2I）编辑器的研究不足。本研究旨在弥合这一差距，对I2I系统进行全面的文化偏见评估。

Method: 提出一个包含六个国家、八个类别/三十六个子类别的标准化评估框架，并使用考虑时代因素的提示词。评估方法结合了自动评估指标、文化感知检索增强问答（VQA）以及母语人士的专家人类判断。本研究使用了具有固定设置的开源模型，并发布了完整图像语料库、提示词和配置以确保可复现性。

Result: (1) 在不区分国家的提示词下，模型倾向于生成‘全球北方’、‘现代’的图像，抹平了国家间的差异。(2) 即使在传统指标保持不变或有所改善的情况下，迭代的I2I编辑也会损害文化的准确性。(3) I2I模型应用了肤浅的线索（如调色板变化、通用道具），而非与时代一致、与上下文相关的改变，并且在处理‘全球南方’目标时，常常保留源图像的身份特征。

Conclusion: 当前生成图像系统在进行文化敏感编辑方面仍不可靠。本研究发布的数据集、提示词和评估协议提供了一个可复现的、以文化为中心的基准，用于诊断和追踪生成图像模型中的文化偏见。

Abstract: Generative image models produce striking visuals yet often misrepresent
culture. Prior work has examined cultural bias mainly in text-to-image (T2I)
systems, leaving image-to-image (I2I) editors underexplored. We bridge this gap
with a unified evaluation across six countries, an 8-category/36-subcategory
schema, and era-aware prompts, auditing both T2I generation and I2I editing
under a standardized protocol that yields comparable diagnostics. Using open
models with fixed settings, we derive cross-country, cross-era, and
cross-category evaluations. Our framework combines standard automatic metrics,
a culture-aware retrieval-augmented VQA, and expert human judgments collected
from native reviewers. To enable reproducibility, we release the complete image
corpus, prompts, and configurations. Our study reveals three findings: (1)
under country-agnostic prompts, models default to Global-North, modern-leaning
depictions that flatten cross-country distinctions; (2) iterative I2I editing
erodes cultural fidelity even when conventional metrics remain flat or improve;
and (3) I2I models apply superficial cues (palette shifts, generic props)
rather than era-consistent, context-aware changes, often retaining source
identity for Global-South targets. These results highlight that
culture-sensitive edits remain unreliable in current systems. By releasing
standardized data, prompts, and human evaluation protocols, we provide a
reproducible, culture-centered benchmark for diagnosing and tracking cultural
bias in generative image models.

</details>


### [10] [Filter-Based Reconstruction of Images from Events](https://arxiv.org/abs/2510.20071)
*Bernd Pfrommer*

Main category: cs.CV

TL;DR: FIBAR是一种基于滤波器的异步事件相机图像重建方法，比基于神经网络的方法更简单，可在CPU上运行，但重建效果较差。


<details>
  <summary>Details</summary>
Motivation: 从移动事件相机事件重建强度图像是一个挑战，通常需要GPU上的神经网络，本文提出了一种更简单的方法。

Method: 本文提出了一种名为FIBAR（FIlter Based Asynchronous Reconstruction）的方法。首先，使用IIR滤波器整合事件信号，然后通过一种新算法检测并模糊（使用高斯滤波器）被认为是“陈旧”的像素，以减少重建噪声。该方法是异步的，允许在任意时间读取图像。

Result: FIBAR可以在现代笔记本CPU上以约42（140）百万事件/秒的速度运行（是否启用空间滤波）。与基于神经网络的方法（FireNet）相比，FIBAR的重建图像更嘈杂，并有重影，但对于某些任务（如标记检测）来说足够。

Conclusion: FIBAR是一种简单、快速的事件相机图像重建方法，虽然重建质量不如神经网络，但其效率和CPU运行能力使其适用于特定应用。

Abstract: Reconstructing an intensity image from the events of a moving event camera is
a challenging task that is typically approached with neural networks deployed
on graphics processing units. This paper presents a much simpler, FIlter Based
Asynchronous Reconstruction method (FIBAR). First, intensity changes signaled
by events are integrated with a temporal digital IIR filter. To reduce
reconstruction noise, stale pixels are detected by a novel algorithm that
regulates a window of recently updated pixels. Arguing that for a moving
camera, the absence of events at a pixel location likely implies a low image
gradient, stale pixels are then blurred with a Gaussian filter. In contrast to
most existing methods, FIBAR is asynchronous and permits image read-out at an
arbitrary time. It runs on a modern laptop CPU at about 42(140) million
events/s with (without) spatial filtering enabled. A few simple qualitative
experiments are presented that show the difference in image reconstruction
between FIBAR and a neural network-based approach (FireNet). FIBAR's
reconstruction is noisier than neural network-based methods and suffers from
ghost images. However, it is sufficient for certain tasks such as the detection
of fiducial markers. Code is available at
https://github.com/ros-event-camera/event_image_reconstruction_fibar

</details>


### [11] [Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering](https://arxiv.org/abs/2510.20077)
*Hui Chen,Xinjie Wang,Xianchao Xiu,Wanquan Liu*

Main category: cs.CV

TL;DR: TBTLRR是一种新的图像聚类模型，通过学习任意酉变换来捕获全局相关性，利用潜在张量数据的双边结构来利用局部相关性，并集成$\|s_{1/2}$范数和Frobenius范数来处理噪声。


<details>
  <summary>Details</summary>
Motivation: 现有的张量低秩表示（TLRR）方法在图像聚类中虽然取得了成功，但它们依赖于固定的变换，并且对噪声的鲁棒性较差。

Method: 提出了一种新颖的变换双边张量低秩表示（TBTLRR）模型，该模型通过学习任意酉变换来引入数据自适应张量核范数，从而更有效地捕获全局相关性。此外，利用潜在张量数据的双边结构，TBTLRR能够利用图像样本和特征之间的局部相关性。TBTLRR还集成了$\|s_{1/2}$范数和Frobenius范数正则化项，以更好地处理现实场景中的复杂噪声。使用受交替方向乘子法（ADMM）启发的优化算法来求解。

Result: 实验结果表明，TBTLRR在聚类方面优于现有最先进的方法。

Conclusion: TBTLRR在聚类任务中表现出优越性，能够有效处理全局和局部相关性，并对噪声具有鲁棒性。

Abstract: Tensor low-rank representation (TLRR) has demonstrated significant success in
image clustering. However, most existing methods rely on fixed transformations
and suffer from poor robustness to noise. In this paper, we propose a novel
transformed bilateral tensor low-rank representation model called TBTLRR, which
introduces a data-adaptive tensor nuclear norm by learning arbitrary unitary
transforms, allowing for more effective capture of global correlations. In
addition, by leveraging the bilateral structure of latent tensor data, TBTLRR
is able to exploit local correlations between image samples and features.
Furthermore, TBTLRR integrates the $\ell_{1/2}$-norm and Frobenius norm
regularization terms for better dealing with complex noise in real-world
scenarios. To solve the proposed nonconvex model, we develop an efficient
optimization algorithm inspired by the alternating direction method of
multipliers (ADMM) and provide theoretical convergence. Extensive experiments
validate its superiority over the state-of-the-art methods in clustering. The
code will be available at https://github.com/xianchaoxiu/TBTLRR.

</details>


### [12] [Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos](https://arxiv.org/abs/2510.20087)
*Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy*

Main category: cs.CV

TL;DR: Endoshare是一个开源的、跨平台的应用程序，用于合并、标准化和去除内窥镜视频中的个人身份信息，旨在解决视频格式异构性和隐私问题，以促进外科培训、研究和质量改进。


<details>
  <summary>Details</summary>
Motivation: 视频记录格式不统一和视频共享带来的隐私问题限制了基于视频的评估和外科数据科学在外科培训、研究和质量改进中的广泛应用。

Method: 开发遵循软件开发生命周期，采用迭代式、以用户为中心的反馈。通过对内科医生和计算机科学家进行内部调查，根据十个可用性原则确定了关键需求，并指导了隐私设计架构。在测试阶段，通过外部临床医生调查，结合可用性原则和技术接受模型，评估了软件的可用性和采纳度，并进行了跨不同硬件配置的基准测试。

Result: 初始原型测试显示，可用性得分很高（4.68 +/- 0.40/5 和 4.03 +/- 0.51/5），最低分（4.00 +/- 0.93/5）与标签清晰度相关。改进后，对十名外科医生进行的调查显示，感知到的有用性（5.07 +/- 1.75/7）、易用性（5.15 +/- 1.71/7）、启发式可用性（4.38 +/- 0.48/5）和推荐意愿（9.20 +/- 0.79/10）均很高。处理时间受处理模式、视频时长和计算能力影响。

Conclusion: Endoshare 提供了一个透明、用户友好的流程，用于标准化、保护隐私的外科视频管理。需要进行合规认证和更广泛的互操作性验证，才能将其作为专有系统的可部署替代方案。

Abstract: Video-based assessment and surgical data science can advance surgical
training, research, and quality improvement. However, widespread use remains
limited by heterogeneous recording formats and privacy concerns associated with
video sharing. We present Endoshare, a source-available, cross-platform
application for merging, standardizing, and de-identifying endoscopic videos in
minimally invasive surgery. Development followed the software development life
cycle with iterative, user-centered feedback. During the analysis phase, an
internal survey of clinicians and computer scientists based on ten usability
heuristics identified key requirements that guided a privacy-by-design
architecture. In the testing phase, an external clinician survey combined the
same heuristics with Technology Acceptance Model constructs to assess usability
and adoption, complemented by benchmarking across different hardware
configurations. Four clinicians and four computer scientists initially tested
the prototype, reporting high usability (4.68 +/- 0.40/5 and 4.03 +/- 0.51/5),
with the lowest score (4.00 +/- 0.93/5) relating to label clarity. After
refinement, the testing phase surveyed ten surgeons who reported high perceived
usefulness (5.07 +/- 1.75/7), ease of use (5.15 +/- 1.71/7), heuristic
usability (4.38 +/- 0.48/5), and strong recommendation (9.20 +/- 0.79/10).
Processing time varied with processing mode, video duration (both p <= 0.001),
and machine computational power (p = 0.041). Endoshare provides a transparent,
user-friendly pipeline for standardized, privacy-preserving surgical video
management. Compliance certification and broader interoperability validation
are needed to establish it as a deployable alternative to proprietary systems.
The software is available at https://camma-public.github.io/Endoshare/

</details>


### [13] [Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency](https://arxiv.org/abs/2510.20092)
*Hao Yu,Haoyu Chen,Yan Jiang,Wei Peng,Zhaodong Sun,Samuel Kaski,Guoying Zhao*

Main category: cs.CV

TL;DR: 自注意力（SA）因其强大的表达能力而成为现代视觉骨干网络的基石，但其二次复杂度限制了其应用。卷积（Conv）具有线性复杂度，但表达能力不如SA。本文揭示了SA优于Conv的两个关键原则：1. 自适应路由：SA根据语义内容动态调节位置信息流，而Conv使用静态卷积核。2. 侧抑制：SA通过竞争抑制冗余，而Conv缺乏这种抑制机制。基于此，本文提出了注意力卷积（ATConv），一种注入了这些原则的卷积算子。实验证明，ATConv在视觉任务上优于SA，并且构建的AttNet在ImageNet-1K上达到了84.4%的准确率。在图像生成方面，ATConv也能提升性能。


<details>
  <summary>Details</summary>
Motivation: 在现代视觉模型中，自注意力（SA）因其强大的表达能力成为主流，但其二次复杂度限制了其实际应用。卷积（Conv）具有线性复杂度，但其表达能力不如SA。现有研究试图改进Conv以追赶SA的性能，但仍存在差距。因此，需要重新审视CNN的设计，理解SA的优势所在，并将其原理注入Conv中。

Method: 本文重新审视了CNN的设计，重点分析了自注意力（SA）优于卷积（Conv）的两个关键原理：1. 自适应路由：SA能够根据语义内容动态地调整位置信息流，而Conv则使用对所有位置都相同的静态卷积核。2. 侧抑制：SA能够通过竞争机制来抑制冗余，从而使表征更加锐利，而Conv缺乏这种抑制能力，容易产生冗余。基于这些发现，本文提出了注意力卷积（ATConv），一种将这些原理融入卷积算子的新方法。

Result: ATConv 在各种基础视觉任务上持续优于不同的自注意力机制，仅使用 $3	imes3$ 的卷积核。基于 ATConv，我们提出了 AttNet，这是一个 CNN 系列模型，在仅有 27M 参数的情况下，在 ImageNet-1K 上达到了 84.4% 的 Top-1 准确率。此外，在基于扩散的图像生成任务中，将 SiT-XL/2 中的所有 SA 替换为提出的 $3	imes3$ ATConv，可以在 400k 步内将 ImageNet FID 降低 0.15，并实现了更快的采样速度。

Conclusion: 本文通过揭示自注意力（SA）优于卷积（Conv）的两个关键原理——自适应路由和侧抑制——为CNN的设计提供了新的视角。基于这些原理提出的注意力卷积（ATConv）在多种视觉任务和图像生成任务中均取得了优于现有方法的性能，证明了其有效性。这为未来设计更高效、更强大的视觉模型提供了新的方向。

Abstract: Self-attention (SA) has become the cornerstone of modern vision backbones for
its powerful expressivity over traditional Convolutions (Conv). However, its
quadratic complexity remains a critical bottleneck for practical applications.
Given that Conv offers linear complexity and strong visual priors, continuing
efforts have been made to promote the renaissance of Conv. However, a
persistent performance chasm remains, highlighting that these modernizations
have not yet captured the intrinsic expressivity that defines SA. In this
paper, we re-examine the design of the CNNs, directed by a key question: what
principles give SA its edge over Conv? As a result, we reveal two fundamental
insights that challenge the long-standing design intuitions in prior research
(e.g., Receptive field). The two findings are: (1) \textit{Adaptive routing}:
SA dynamically regulates positional information flow according to semantic
content, whereas Conv employs static kernels uniformly across all positions.
(2) \textit{Lateral inhibition}: SA induces score competition among token
weighting, effectively suppressing redundancy and sharpening representations,
whereas Conv filters lack such inhibitory dynamics and exhibit considerable
redundancy. Based on this, we propose \textit{Attentive Convolution} (ATConv),
a principled reformulation of the convolutional operator that intrinsically
injects these principles. Interestingly, with only $3\times3$ kernels, ATConv
consistently outperforms various SA mechanisms in fundamental vision tasks.
Building on ATConv, we introduce AttNet, a CNN family that can attain
\textbf{84.4\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In
diffusion-based image generation, replacing all SA with the proposed $3\times
3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster
sampling. Code is available at: github.com/price112/Attentive-Convolution.

</details>


### [14] [StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback](https://arxiv.org/abs/2510.20093)
*Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim*

Main category: cs.CV

TL;DR: StableSketcher 是一个新框架，它通过微调 VAE 和使用基于 VQA 的奖励函数来改进扩散模型生成手绘草图的质量和文本-图像一致性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成像素级的手绘草图方面存在挑战，无法很好地捕捉抽象表达的特征，并且在文本-图像对齐和语义一致性方面也存在不足。

Method: 1. 微调变分自编码器 (VAE) 以优化潜在解码，更好地捕捉草图特征。 2. 引入基于视觉问答 (VQA) 的新奖励函数，用于强化学习，以提高文本-图像对齐和语义一致性。 3. 提出 SketchDUO 数据集，包含实例级草图及其对应的标题和问答对。

Result: StableSketcher 生成的草图在风格保真度上有所提高，并且与提示的对齐度优于 Stable Diffusion 基线。

Conclusion: StableSketcher 框架能够有效地提升扩散模型在生成手绘草图方面的性能，在风格保真度和文本-图像对齐方面均表现出色。SketchDUO 数据集的发布也为该领域的研究提供了新的资源。

Abstract: Although recent advancements in diffusion models have significantly enriched
the quality of generated images, challenges remain in synthesizing pixel-based
human-drawn sketches, a representative example of abstract expression. To
combat these challenges, we propose StableSketcher, a novel framework that
empowers diffusion models to generate hand-drawn sketches with high prompt
fidelity. Within this framework, we fine-tune the variational autoencoder to
optimize latent decoding, enabling it to better capture the characteristics of
sketches. In parallel, we integrate a new reward function for reinforcement
learning based on visual question answering, which improves text-image
alignment and semantic consistency. Extensive experiments demonstrate that
StableSketcher generates sketches with improved stylistic fidelity, achieving
better alignment with prompts compared to the Stable Diffusion baseline.
Additionally, we introduce SketchDUO, to the best of our knowledge, the first
dataset comprising instance-level sketches paired with captions and
question-answer pairs, thereby addressing the limitations of existing datasets
that rely on image-label pairs. Our code and dataset will be made publicly
available upon acceptance.

</details>


### [15] [BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models](https://arxiv.org/abs/2510.20095)
*Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu*

Main category: cs.CV

TL;DR: 通过生成合成描述性标题来改进生物多模态基础模型，以提高物种分类和文本-图像检索性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索使用描述性标题作为生物多模态基础模型的额外监督来源，以更好地捕捉物种的生物特征，克服以往在生物学领域大规模获取准确描述性标题的挑战。

Method: 利用多模态大型语言模型（MLLMs）生成合成标题，并结合维基百科的视觉信息和特定分类群的格式示例进行引导，以减少幻觉并生成准确、实例特定的描述性标题。然后，使用这些标题训练一个名为BIOCAP（BIOCLIP with Captions）的生物基础模型。

Result: 所提出的BIOCAP模型在物种分类和文本-图像检索任务上取得了强大的性能，证明了描述性标题在连接生物图像和多模态基础模型方面的价值。

Conclusion: 描述性标题（即使是合成生成的）可以作为一种有效的监督信号，用于训练生物多模态基础模型，其价值超越了传统的标签，能够捕捉更丰富的语义信息并提高模型性能。

Abstract: This work investigates descriptive captions as an additional source of
supervision for biological multimodal foundation models. Images and captions
can be viewed as complementary samples from the latent morphospace of a
species, each capturing certain biological traits. Incorporating captions
during training encourages alignment with this shared latent structure,
emphasizing potentially diagnostic characters while suppressing spurious
correlations. The main challenge, however, lies in obtaining faithful,
instance-specific captions at scale. This requirement has limited the
utilization of natural language supervision in organismal biology compared with
many other scientific domains. We complement this gap by generating synthetic
captions with multimodal large language models (MLLMs), guided by
Wikipedia-derived visual information and taxon-tailored format examples. These
domain-specific contexts help reduce hallucination and yield accurate,
instance-based descriptive captions. Using these captions, we train BIOCAP
(i.e., BIOCLIP with Captions), a biological foundation model that captures rich
semantics and achieves strong performance in species classification and
text-image retrieval. These results demonstrate the value of descriptive
captions beyond labels in bridging biological images with multimodal foundation
models.

</details>


### [16] [Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects](https://arxiv.org/abs/2510.20126)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu*

Main category: cs.CV

TL;DR: 该研究提出了一种结合深度学习检测和基于物理的跟踪的新系统，用于在 3D 空间中检测和跟踪快速移动的小型物体，该系统在自定义回力球数据集上进行了评估，平均位移误差比基于卡尔曼滤波的跟踪器低 70%，并在机器人感知等领域具有重要应用。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉技术在检测和跟踪快速移动的小型物体方面存在不足，本研究旨在解决这一难题。

Method: 提出了一种新颖的系统，结合了基于深度学习的检测和基于物理的跟踪，该系统集成了运动学运动方程来处理异常值和漏检，并包含一个异常值检测和校正模块。

Result: 在自定义回力球数据集上的评估显示，该系统的平均位移误差比基于卡尔曼滤波的跟踪器低 70%。

Conclusion: 结合基于物理的模型和深度学习方法可以有效地实现对具有挑战性的小型物体的实时 3D 检测和跟踪，这对于提高自主平台上的机器人感知能力具有重要意义。

Abstract: While computer vision has advanced considerably for general object detection
and tracking, the specific problem of fast-moving tiny objects remains
underexplored. This paper addresses the significant challenge of detecting and
tracking rapidly moving small objects using an RGB-D camera. Our novel system
combines deep learning-based detection with physics-based tracking to overcome
the limitations of existing approaches. Our contributions include: (1) a
comprehensive system design for object detection and tracking of fast-moving
small objects in 3D space, (2) an innovative physics-based tracking algorithm
that integrates kinematics motion equations to handle outliers and missed
detections, and (3) an outlier detection and correction module that
significantly improves tracking performance in challenging scenarios such as
occlusions and rapid direction changes. We evaluated our proposed system on a
custom racquetball dataset. Our evaluation shows our system surpassing kalman
filter based trackers with up to 70\% less Average Displacement Error. Our
system has significant applications for improving robot perception on
autonomous platforms and demonstrates the effectiveness of combining
physics-based models with deep learning approaches for real-time 3D detection
and tracking of challenging small objects.

</details>


### [17] [Inverse Image-Based Rendering for Light Field Generation from Single Images](https://arxiv.org/abs/2510.20132)
*Hyunjun Jung,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: 该论文提出了一种名为“逆向图生渲染”的新方法，仅用单张图像生成光场，并用于新视角合成。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统光场生成方法计算成本高或需要专门设备的限制，并扩大光场表示的应用范围。

Method: 提出了一种名为“逆向图生渲染”的新方法，设计了一个神经渲染管线，从输入图像的像素重建光流，通过交叉注意力计算光流间的关系，并预测目标光线的颜色。该方法迭代地生成新视角图像，并更新视域外的内容，以保证遮挡内容的生成一致性。

Result: 该方法在各种具有挑战性的数据集上均表现良好，无需重新训练或微调，并且在新的视角合成方面优于相关的最先进方法。

Conclusion: 论文提出的逆向图生渲染方法能够有效地从单张图像生成光场，实现高质量的新视角合成，并且在泛化性和性能上超越了现有技术。

Abstract: A concept of light-fields computed from multiple view images on regular grids
has proven its benefit for scene representations, and supported realistic
renderings of novel views and photographic effects such as refocusing and
shallow depth of field. In spite of its effectiveness of light flow
computations, obtaining light fields requires either computational costs or
specialized devices like a bulky camera setup and a specialized microlens
array. In an effort to broaden its benefit and applicability, in this paper, we
propose a novel view synthesis method for light field generation from only
single images, named inverse image-based rendering. Unlike previous attempts to
implicitly rebuild 3D geometry or to explicitly represent objective scenes, our
method reconstructs light flows in a space from image pixels, which behaves in
the opposite way to image-based rendering. To accomplish this, we design a
neural rendering pipeline to render a target ray in an arbitrary viewpoint. Our
neural renderer first stores the light flow of source rays from the input
image, then computes the relationships among them through cross-attention, and
finally predicts the color of the target ray based on these relationships.
After the rendering pipeline generates the first novel view from a single input
image, the generated out-of-view contents are updated to the set of source
rays. This procedure is iteratively performed while ensuring the consistent
generation of occluded contents. We demonstrate that our inverse image-based
rendering works well with various challenging datasets without any retraining
or finetuning after once trained on synthetic dataset, and outperforms relevant
state-of-the-art novel view synthesis methods.

</details>


### [18] [Revisiting Logit Distributions for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2510.20134)
*Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: LogitGap是一种新的、利用模型logit空间信息进行OOD检测的方法，通过最大logit与剩余logit的关系来区分ID和OOD样本，并进一步优化了logits选择，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法未能充分利用模型logit空间中的丰富信息，而LogitGap旨在解决这一问题。

Method: LogitGap利用最大logit与剩余logit之间的关系来提高ID和OOD样本的可分离性，并通过一种无需训练的策略来识别信息量最丰富的logits。

Result: LogitGap在视觉-语言和纯视觉模型上进行了广泛的实验，在各种OOD检测场景和基准测试中始终 achieves state-of-the-art performance。

Conclusion: LogitGap通过利用logit空间信息，在OOD检测方面表现出色，提供了理论和实证支持。

Abstract: Out-of-distribution (OOD) detection is critical for ensuring the reliability
of deep learning models in open-world applications. While post-hoc methods are
favored for their efficiency and ease of deployment, existing approaches often
underexploit the rich information embedded in the model's logits space. In this
paper, we propose LogitGap, a novel post-hoc OOD detection method that
explicitly exploits the relationship between the maximum logit and the
remaining logits to enhance the separability between in-distribution (ID) and
OOD samples. To further improve its effectiveness, we refine LogitGap by
focusing on a more compact and informative subset of the logit space.
Specifically, we introduce a training-free strategy that automatically
identifies the most informative logits for scoring. We provide both theoretical
analysis and empirical evidence to validate the effectiveness of our approach.
Extensive experiments on both vision-language and vision-only models
demonstrate that LogitGap consistently achieves state-of-the-art performance
across diverse OOD detection scenarios and benchmarks. Code is available at
https://github.com/GIT-LJc/LogitGap.

</details>


### [19] [PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding](https://arxiv.org/abs/2510.20155)
*Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu*

Main category: cs.CV

TL;DR: PartNeXt是一个包含23,000多个高细节、带纹理的3D模型的数据集，提供精细、分层的部件标签，旨在解决现有3D部件理解数据集的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集（如PartNet）依赖于无纹理几何和专家标注，限制了可扩展性和可用性。

Method: 创建了一个包含23,000多个高细节、带纹理的3D模型的数据集，并对其进行精细、分层的部件标注，涵盖50个类别。在两个任务上对PartNeXt进行了基准测试：1. 类别无关部件分割；2. 3D部件中心问答。

Result: 在类别无关部件分割任务中，现有最先进的方法在处理精细和叶级部件时遇到困难。在3D部件中心问答任务中，暴露了3D-LLM在开放词汇部件基础方面存在的显著差距。使用PartNeXt训练Point-SAM比使用PartNet取得了显著的进步。

Conclusion: PartNeXt通过结合可扩展的标注、纹理感知标签和多任务评估，为结构化3D理解的研究开辟了新途径。

Abstract: Understanding objects at the level of their constituent parts is fundamental
to advancing computer vision, graphics, and robotics. While datasets like
PartNet have driven progress in 3D part understanding, their reliance on
untextured geometries and expert-dependent annotation limits scalability and
usability. We introduce PartNeXt, a next-generation dataset addressing these
gaps with over 23,000 high-quality, textured 3D models annotated with
fine-grained, hierarchical part labels across 50 categories. We benchmark
PartNeXt on two tasks: (1) class-agnostic part segmentation, where
state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with
fine-grained and leaf-level parts, and (2) 3D part-centric question answering,
a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary
part grounding. Additionally, training Point-SAM on PartNeXt yields substantial
gains over PartNet, underscoring the dataset's superior quality and diversity.
By combining scalable annotation, texture-aware labels, and multi-task
evaluation, PartNeXt opens new avenues for research in structured 3D
understanding.

</details>


### [20] [Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists](https://arxiv.org/abs/2510.20158)
*Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing*

Main category: cs.CV

TL;DR: 该研究提出了一种从单目RGB图像估计铰接式自行车和骑行者8D姿态（包括自行车本体的3D平移、旋转，以及车把和脚踏板的相对旋转）的方法，以提高自动驾驶中对骑行者意图的理解和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计方法不足以精确描述铰接式自行车，因为其关节（如车把和脚踏板）的转动会改变自行车的三维边界框及其方向，而这对于判断骑行者的行驶意图至关重要。

Method: 提出了一种类别级8D姿态估计方法，该方法能够从单张RGB图像中同时估计自行车的3D平移、3D旋转，以及车把和脚踏板相对于车身框架的旋转。该模型还联合估计了自行车的3D关键点，并混合使用了合成和真实图像数据进行训练，以提高在真实图像上的泛化能力。

Result: 该方法在评估中取得了具有竞争力的分数，与使用刚性物体模板的现有类别级6D姿态估计方法相比，显示出优越性。

Conclusion: 所提出的8D姿态估计方法能够更精细地描述自行车的姿态及其行驶方向，为自动驾驶中的脆弱道路使用者（VRU）安全提供了关键的技术支持。

Abstract: In Autonomous Driving, cyclists belong to the safety-critical class of
Vulnerable Road Users (VRU), and accurate estimation of their pose is critical
for cyclist crossing intention classification, behavior prediction, and
collision avoidance. Unlike rigid objects, articulated bicycles are composed of
movable rigid parts linked by joints and constrained by a kinematic structure.
6D pose methods can estimate the 3D rotation and translation of rigid bicycles,
but 6D becomes insufficient when the steering/pedals angles of the bicycle
vary. That is because: 1) varying the articulated pose of the bicycle causes
its 3D bounding box to vary as well, and 2) the 3D box orientation is not
necessarily aligned to the orientation of the steering which determines the
actual intended travel direction. In this work, we introduce a method for
category-level 8D pose estimation for articulated bicycles and cyclists from a
single RGB image. Besides being able to estimate the 3D translation and
rotation of a bicycle from a single image, our method also estimates the
rotations of its steering handles and pedals with respect to the bicycle body
frame. These two new parameters enable the estimation of a more fine-grained
bicycle pose state and travel direction. Our proposed model jointly estimates
the 8D pose and the 3D Keypoints of articulated bicycles, and trains with a mix
of synthetic and real image data to generalize on real images. We include an
evaluation section where we evaluate the accuracy of our estimated 8D pose
parameters, and our method shows promising results by achieving competitive
scores when compared against state-of-the-art category-level 6D pose estimators
that use rigid canonical object templates for matching.

</details>


### [21] [TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning](https://arxiv.org/abs/2510.20162)
*Xudong Yan,Songhe Feng*

Main category: cs.CV

TL;DR: 通过在测试时更新多模态原型来解决组合零样本学习中的分布变化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在组合零样本学习中存在由标签空间分布变化引起的回报下降问题，因为测试时包含了未见的组合。本研究提出一种新方法来解决这个问题。

Method: 该方法通过在测试时更新多模态原型来解决分布变化问题。它利用来自无监督数据中 द्या文本和视觉模态的全面知识来更新原型。此外，它还设计了一个自适应更新权重来控制原型调整的程度，并引入了一个动态优先级队列来从历史图像中获取视觉知识。最后，通过多模态协同表示学习对文本和视觉原型进行对齐，以实现模态间的语义一致性。

Result: 该方法在四个基准数据集上都取得了最先进的性能，包括在封闭世界和开放世界设置下。

Conclusion: 作者提出的方法通过在测试时更新多模态原型，有效解决了组合零样本学习中的分布变化问题，并在封闭世界和开放世界设置下都取得了最先进的性能。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize novel
attribute-object compositions based on the knowledge learned from seen ones.
Existing methods suffer from performance degradation caused by the distribution
shift of label space at test time, which stems from the inclusion of unseen
compositions recombined from attributes and objects. To overcome the challenge,
we propose a novel approach that accumulates comprehensive knowledge in both
textual and visual modalities from unsupervised data to update multimodal
prototypes at test time. Building on this, we further design an adaptive update
weight to control the degree of prototype adjustment, enabling the model to
flexibly adapt to distribution shift during testing. Moreover, a dynamic
priority queue is introduced that stores high-confidence images to acquire
visual knowledge from historical images for inference. Considering the semantic
consistency of multimodal knowledge, we align textual and visual prototypes by
multimodal collaborative representation learning. Extensive experiments
indicate that our approach achieves state-of-the-art performance on four
benchmark datasets under both closed-world and open-world settings. Code will
be available at https://github.com/xud-yan/TOMCAT .

</details>


### [22] [IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks](https://arxiv.org/abs/2510.20165)
*Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim*

Main category: cs.CV

TL;DR: IB-GAN是一个新的基于GAN的无监督模型，用于解耦表示学习，它利用信息瓶颈（IB）框架来优化GAN，并通过中间随机层来约束输入和生成输出之间的互信息，从而实现可解耦和可解释的潜在空间利用。


<details>
  <summary>Details</summary>
Motivation: 利用信息瓶颈（IB）框架来优化生成对抗网络（GAN），以实现解耦表示学习。

Method: 提出了一种名为IB-GAN的新模型，其生成器包含一个中间随机层，用于约束输入和生成输出之间的互信息。该层与生成器联合进行端到端训练。

Result: 在dSprites和Color-dSprites数据集上，IB-GAN实现了与最先进的\b{eta}-VAEs竞争的解耦分数，并优于InfoGAN。在CelebA和3D Chairs数据集上，IB-GAN生成的样本在视觉质量和多样性方面（以FID分数为衡量）通常优于\b{eta}-VAEs和Info-GAN。

Conclusion: IB-GAN能够以解耦和可解释的方式利用潜在空间，并在多个基准测试中取得了优于现有方法的性能。

Abstract: We propose a new GAN-based unsupervised model for disentangled representation
learning. The new model is discovered in an attempt to utilize the Information
Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The
architecture of IB-GAN is partially similar to that of InfoGAN but has a
critical difference; an intermediate layer of the generator is leveraged to
constrain the mutual information between the input and the generated output.
The intermediate stochastic layer can serve as a learnable latent distribution
that is trained with the generator jointly in an end-to-end fashion. As a
result, the generator of IB-GAN can harness the latent space in a disentangled
and interpretable manner. With the experiments on dSprites and Color-dSprites
dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores
to those of state-of-the-art \b{eta}-VAEs and outperforms InfoGAN. Moreover,
the visual quality and the diversity of samples generated by IB-GAN are often
better than those by \b{eta}-VAEs and Info-GAN in terms of FID score on CelebA
and 3D Chairs dataset.

</details>


### [23] [PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching](https://arxiv.org/abs/2510.20178)
*Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu*

Main category: cs.CV

TL;DR: PPMStereo使用一种新颖的PPM（Pick-and-Play Memory）模块来动态地进行立体匹配，通过选择和加权相关帧来高效地实现长期的时序一致性深度估计，并在Sintel数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 准确且时序一致的深度估计对于AR等应用至关重要，但现有方法在计算效率和时序建模能力之间存在权衡。

Method: 提出PPMStereo，包含一个“pick”过程以识别相关帧，以及一个“play”过程以自适应地加权所选帧，用于时空聚合，构建一个紧凑但信息丰富的记忆缓冲区。

Result: PPMStereo在Sintel数据集上实现了最先进的精度和时序一致性，TEPE指标优于BiDAStereo，且计算成本更低。

Conclusion: PPMStereo成功地实现了高效的动态立体匹配，能够进行长期的时序一致性深度估计。

Abstract: Temporally consistent depth estimation from stereo video is critical for
real-world applications such as augmented reality, where inconsistent depth
estimation disrupts the immersion of users. Despite its importance, this task
remains challenging due to the difficulty in modeling long-term temporal
consistency in a computationally efficient manner. Previous methods attempt to
address this by aggregating spatio-temporal information but face a fundamental
trade-off: limited temporal modeling provides only modest gains, whereas
capturing long-range dependencies significantly increases computational cost.
To address this limitation, we introduce a memory buffer for modeling
long-range spatio-temporal consistency while achieving efficient dynamic stereo
matching. Inspired by the two-stage decision-making process in humans, we
propose a \textbf{P}ick-and-\textbf{P}lay \textbf{M}emory (PPM) construction
module for dynamic \textbf{Stereo} matching, dubbed as \textbf{PPMStereo}. PPM
consists of a `pick' process that identifies the most relevant frames and a
`play' process that weights the selected frames adaptively for spatio-temporal
aggregation. This two-stage collaborative process maintains a compact yet
highly informative memory buffer while achieving temporally consistent
information aggregation. Extensive experiments validate the effectiveness of
PPMStereo, demonstrating state-of-the-art performance in both accuracy and
temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the
Sintel clean/final (17.3\% \& 9.02\% improvements over BiDAStereo) with fewer
computational costs. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.

</details>


### [24] [Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories](https://arxiv.org/abs/2510.20182)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 现有视频生成模型在模拟多人交互场景方面能力有待验证，本文提出了一个评估协议来衡量其作为行人动态模拟器的表现，并指出了模型的优势与不足。


<details>
  <summary>Details</summary>
Motivation: 评估现有文本到视频（T2V）和图像到视频（I2V）模型作为行人动态隐式模拟器的能力，因为现有基准未能充分关注多智能体交互场景。

Method: 提出一个严格的评估协议，包括：1. 对于I2V模型，利用现有数据集的起始帧与真实视频数据集进行比较。2. 对于T2V模型，开发一套提示语来测试不同行人密度和交互场景。3. 开发一种无需已知相机参数即可从像素空间重建2D鸟瞰轨迹的方法。

Result: 评估结果表明，主流模型在生成合理的多人交互行为方面表现出乎意料地有效。然而，模型在处理行人合并和消失等场景时仍存在失败模式，这为未来的改进指明了方向。

Conclusion: 尽管领先的视频生成模型在模拟行人动态方面已展现出强大的能力，但仍需在处理极端情况和复杂交互方面进行改进，以实现更可靠的世界模拟。

Abstract: Large-scale video generation models have demonstrated high visual realism in
diverse contexts, spurring interest in their potential as general-purpose world
simulators. Existing benchmarks focus on individual subjects rather than scenes
with multiple interacting people. However, the plausibility of multi-agent
dynamics in generated videos remains unverified. We propose a rigorous
evaluation protocol to benchmark text-to-video (T2V) and image-to-video (I2V)
models as implicit simulators of pedestrian dynamics. For I2V, we leverage
start frames from established datasets to enable comparison with a ground truth
video dataset. For T2V, we develop a prompt suite to explore diverse pedestrian
densities and interactions. A key component is a method to reconstruct 2D
bird's-eye view trajectories from pixel-space without known camera parameters.
Our analysis reveals that leading models have learned surprisingly effective
priors for plausible multi-agent behavior. However, failure modes like merging
and disappearing people highlight areas for future improvement.

</details>


### [25] [Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature](https://arxiv.org/abs/2510.20794)
*Lei Cheng,Siyang Cao*

Main category: cs.CV

TL;DR: 该研究提出了一种融合雷达和摄像头数据的多目标跟踪（MOT）框架，利用在线标定来简化传感器集成并提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 许多研究低估了雷达的作用，但雷达能提供精确的3D坐标系中的目标距离/深度信息。本研究旨在充分发挥雷达的作用，并提出一种融合雷达和摄像头数据的MOT框架。

Method: 提出了一种利用雷达和摄像头数据的多目标跟踪（MOT）框架。该框架利用在线标定来自动关联来自雷达和摄像头的数据。通过利用雷达和摄像头数据之间的共同特征，可以准确地推导出检测到的物体的真实世界位置。此外，还采用了特征匹配和类别一致性检查来提高传感器关联精度。

Result: 该框架能够简化雷达-摄像头映射过程，并提高跟踪精度。在受控环境和实际交通场景的真实世界实验中证明了其有效性。

Conclusion: 本研究是首个研究雷达-摄像头共同特征及其在线标定在MOT中的应用的案例，成功地提高了雷达-摄像头融合MOT的效率和精度。

Abstract: This paper presents a Multi-Object Tracking (MOT) framework that fuses radar
and camera data to enhance tracking efficiency while minimizing manual
interventions. Contrary to many studies that underutilize radar and assign it a
supplementary role--despite its capability to provide accurate range/depth
information of targets in a world 3D coordinate system--our approach positions
radar in a crucial role. Meanwhile, this paper utilizes common features to
enable online calibration to autonomously associate detections from radar and
camera. The main contributions of this work include: (1) the development of a
radar-camera fusion MOT framework that exploits online radar-camera calibration
to simplify the integration of detection results from these two sensors, (2)
the utilization of common features between radar and camera data to accurately
derive real-world positions of detected objects, and (3) the adoption of
feature matching and category-consistency checking to surpass the limitations
of mere position matching in enhancing sensor association accuracy. To the best
of our knowledge, we are the first to investigate the integration of
radar-camera common features and their use in online calibration for achieving
MOT. The efficacy of our framework is demonstrated by its ability to streamline
the radar-camera mapping process and improve tracking precision, as evidenced
by real-world experiments conducted in both controlled environments and actual
traffic scenarios. Code is available at
https://github.com/radar-lab/Radar_Camera_MOT

</details>


### [26] [SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization](https://arxiv.org/abs/2510.20189)
*Xinyi Hu,Yuran Wang,Yue Li,Wenxuan Liu,Zheng Wang*

Main category: cs.CV

TL;DR: SPAN通过将离散分类改为连续回归，并引入基于时间点过程理论的公式、多模态信息调整和概念锚定映射，从而更有效地检测和解释视频监控中的可疑意图。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉可疑意图的连续性，限制了早期干预和可解释性。

Method: 提出SPAN网络，采用连续回归而非离散分类，引入基于时间点过程理论的公式，并结合多模态信息和概念锚定映射。

Result: SPAN在HAI数据集上显著优于现有方法，MSE降低19.8%，mAP提高1.78%，在低频情况下mAP提高2.74%。

Conclusion: SPAN的连续性可疑意图建模能够实现更早的检测和主动干预，提高了可解释性和实用性。

Abstract: Temporal Intention Localization (TIL) is crucial for video surveillance,
focusing on identifying varying levels of suspicious intentions to improve
security monitoring. However, existing discrete classification methods fail to
capture the continuous nature of suspicious intentions, limiting early
intervention and explainability. In this paper, we propose the Suspicion
Progression Analysis Network (SPAN), which shifts from discrete classification
to continuous regression, enabling the capture of fluctuating and evolving
suspicious intentions. We reveal that suspicion exhibits long-term dependencies
and cumulative effects, similar to Temporal Point Process (TPP) theory. Based
on these insights, we define a suspicion score formula that models continuous
changes while accounting for temporal characteristics. We also introduce
Suspicion Coefficient Modulation, which adjusts suspicion coefficients using
multimodal information to reflect the varying impacts of suspicious actions.
Additionally, the Concept-Anchored Mapping method is proposed to link
suspicious actions to predefined intention concepts, offering insights into
both the actions and their potential underlying intentions. Extensive
experiments on the HAI dataset show that SPAN significantly outperforms
existing methods, reducing MSE by 19.8% and improving average mAP by 1.78%.
Notably, SPAN achieves a 2.74% mAP gain in low-frequency cases, demonstrating
its superior ability to capture subtle behavioral changes. Compared to discrete
classification systems, our continuous suspicion modeling approach enables
earlier detection and proactive intervention, greatly enhancing system
explainability and practical utility in security applications.

</details>


### [27] [A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development](https://arxiv.org/abs/2510.20196)
*Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 公开的脑部MRI数据集存在规模、多样性和一致性方面的显著不平衡和异质性，即使经过标准化预处理，数据集间仍存在残留的协变量偏移，这给开发可泛化的脑部MRI基础模型带来了挑战。


<details>
  <summary>Details</summary>
Motivation: 评估公开脑部MRI数据集的规模、多样性和一致性，为基础模型开发提供参考，并强调预处理和领域自适应策略的重要性。

Method: 分析了54个公开脑部MRI数据集（超53.8万份），从数据集层面（模态、疾病、规模）和图像层面（体素间距、方向、强度分布）进行了表征，并量化了15个代表性数据集的预处理（强度归一化、偏场校正、颅骨剥离、空间配准、插值）对统计量和几何的影响，最后通过3D DenseNet121进行特征空间案例研究。

Result: 数据集层面存在健康人群与临床亚群规模的严重不平衡；图像层面存在显著的异质性；标准化预处理提高了数据集内的_一致性，但数据集间仍存在残留差异；预处理后的特征空间仍存在残留的协变量偏移。

Conclusion: 公开脑部MRI资源存在固有的变异性，标准化的预处理不足以消除数据集间的偏见，开发可泛化的脑部MRI基础模型需要考虑预处理和领域自适应策略。

Abstract: The development of foundation models for brain MRI depends critically on the
scale, diversity, and consistency of available data, yet systematic assessments
of these factors remain scarce. In this study, we analyze 54 publicly
accessible brain MRI datasets encompassing over 538,031 to provide a
structured, multi-level overview tailored to foundation model development. At
the dataset level, we characterize modality composition, disease coverage, and
dataset scale, revealing strong imbalances between large healthy cohorts and
smaller clinical populations. At the image level, we quantify voxel spacing,
orientation, and intensity distributions across 15 representative datasets,
demonstrating substantial heterogeneity that can influence representation
learning. We then perform a quantitative evaluation of preprocessing
variability, examining how intensity normalization, bias field correction,
skull stripping, spatial registration, and interpolation alter voxel statistics
and geometry. While these steps improve within-dataset consistency, residual
differences persist between datasets. Finally, feature-space case study using a
3D DenseNet121 shows measurable residual covariate shift after standardized
preprocessing, confirming that harmonization alone cannot eliminate
inter-dataset bias. Together, these analyses provide a unified characterization
of variability in public brain MRI resources and emphasize the need for
preprocessing-aware and domain-adaptive strategies in the design of
generalizable brain MRI foundation models.

</details>


### [28] [RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling](https://arxiv.org/abs/2510.20206)
*Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu*

Main category: cs.CV

TL;DR: RAPO++是一个跨阶段提示优化框架，通过增强、迭代细化和LLM微调来提升文本到视频生成质量，无需修改基础模型。


<details>
  <summary>Details</summary>
Motivation: 用户提供的提示通常简短、无结构且与训练数据不匹配，这限制了基于扩散的文本到视频生成模型的潜力。本研究旨在解决这一问题。

Method: RAPO++框架包含三个阶段：第一阶段（RAPO）通过从关系图中检索相关修饰符并重构提示来丰富用户提示，使其与训练数据分布对齐；第二阶段（SSPO）采用闭环机制，结合语义对齐、空间保真度、时间连贯性和光流等任务信号，迭代优化提示；第三阶段利用SSPO优化的提示对重写器LLM进行微调。

Result: 实验表明，RAPO++在语义对齐、组合推理、时间稳定性和物理合理性方面取得了显著的提升，在五个最先进的文本到视频模型和五个基准测试中，其性能大幅优于现有方法。

Conclusion: RAPO++是一个模型无关、成本效益高且可扩展的解决方案，为文本到视频生成中的提示优化设定了新标准。

Abstract: Prompt design plays a crucial role in text-to-video (T2V) generation, yet
user-provided prompts are often short, unstructured, and misaligned with
training data, limiting the generative potential of diffusion-based T2V models.
We present \textbf{RAPO++}, a cross-stage prompt optimization framework that
unifies training-data--aligned refinement, test-time iterative scaling, and
large language model (LLM) fine-tuning to substantially improve T2V generation
without modifying the underlying generative backbone. In \textbf{Stage 1},
Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with
semantically relevant modifiers retrieved from a relation graph and refactors
them to match training distributions, enhancing compositionality and
multi-object fidelity. \textbf{Stage 2} introduces Sample-Specific Prompt
Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts
using multi-source feedback -- including semantic alignment, spatial fidelity,
temporal coherence, and task-specific signals such as optical flow -- yielding
progressively improved video generation quality. \textbf{Stage 3} leverages
optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing
task-specific optimization patterns and enabling efficient, high-quality prompt
generation even before inference. Extensive experiments across five
state-of-the-art T2V models and five benchmarks demonstrate that RAPO++
achieves significant gains in semantic alignment, compositional reasoning,
temporal stability, and physical plausibility, outperforming existing methods
by large margins. Our results highlight RAPO++ as a model-agnostic,
cost-efficient, and scalable solution that sets a new standard for prompt
optimization in T2V generation. The code is available at
https://github.com/Vchitect/RAPO.

</details>


### [29] [FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing](https://arxiv.org/abs/2510.20212)
*Yanghao Wang,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 现有的文本到图像编辑方法通过先破坏再恢复的方式生成中间态，但这种中间态是目标无关的，导致编辑效果不佳。FlowCycle提出了一种新颖的、无需反演的、基于流的编辑框架，通过可学习的噪声参数化破坏过程，并利用循环一致性进行优化，从而生成目标感知的中间态，提高了编辑质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像编辑方法在生成中间态时，主要关注源图像重建，而忽略了与目标语义的差异，导致在进行大幅度编辑时，效果受限或不一致。

Method: 提出了一种名为FlowCycle的新型无反演、基于流的编辑框架。该框架通过可学习的噪声来参数化破坏过程，并通过循环一致的过程进行优化。通过迭代地将源图像编辑到目标图像，然后利用双重一致性约束恢复回源图像，FlowCycle学会生成目标感知的中间态。

Result: FlowCycle能够生成目标感知的中间态，从而实现忠实的修改并保持源图像的一致性。实验证明，FlowCycle在编辑质量和一致性方面优于现有最先进的方法。

Conclusion: FlowCycle通过引入目标感知的中间态和循环一致的优化过程，解决了现有文本到图像编辑方法的局限性，显著提高了编辑的保真度和一致性。

Abstract: Recent advances in pre-trained text-to-image flow models have enabled
remarkable progress in text-based image editing. Mainstream approaches always
adopt a corruption-then-restoration paradigm, where the source image is first
corrupted into an ``intermediate state'' and then restored to the target image
under the prompt guidance. However, current methods construct this intermediate
state in a target-agnostic manner, i.e., they primarily focus on realizing
source image reconstruction while neglecting the semantic gaps towards the
specific editing target. This design inherently results in limited editability
or inconsistency when the desired modifications substantially deviate from the
source. In this paper, we argue that the intermediate state should be
target-aware, i.e., selectively corrupting editing-relevant contents while
preserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel
inversion-free and flow-based editing framework that parameterizes corruption
with learnable noises and optimizes them through a cycle-consistent process. By
iteratively editing the source to the target and recovering back to the source
with dual consistency constraints, FlowCycle learns to produce a target-aware
intermediate state, enabling faithful modifications while preserving source
consistency. Extensive ablations have demonstrated that FlowCycle achieves
superior editing quality and consistency over state-of-the-art methods.

</details>


### [30] [Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection](https://arxiv.org/abs/2510.20214)
*Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad*

Main category: cs.CV

TL;DR: CURL框架通过自监督学习和对比学习来检测胎儿运动，提高了产前健康的评估准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的胎儿运动检测方法（如孕妇感知和心率图）存在主观性和准确性有限的问题，需要更精确客观的方法来评估产前健康。

Method: 提出了一种名为CURL（Contrastive Ultrasound Video Representation Learning）的新型自监督学习框架，利用空间和时间对比学习来学习胎儿运动的表示。该框架还引入了特定的采样策略以有效分离运动和非运动片段，并通过概率微调实现对任意长度超声记录的灵活推理。

Result: 在包含92名受试者、每人30分钟超声检查的内部数据集中，CURL实现了78.01%的敏感性和81.60%的AUROC。

Conclusion: 自监督对比学习在胎儿运动分析方面具有巨大潜力，能够改进产前监测和临床决策。

Abstract: Accurate fetal movement (FM) detection is essential for assessing prenatal
health, as abnormal movement patterns can indicate underlying complications
such as placental dysfunction or fetal distress. Traditional methods, including
maternal perception and cardiotocography (CTG), suffer from subjectivity and
limited accuracy. To address these challenges, we propose Contrastive
Ultrasound Video Representation Learning (CURL), a novel self-supervised
learning framework for FM detection from extended fetal ultrasound video
recordings. Our approach leverages a dual-contrastive loss, incorporating both
spatial and temporal contrastive learning, to learn robust motion
representations. Additionally, we introduce a task-specific sampling strategy,
ensuring the effective separation of movement and non-movement segments during
self-supervised training, while enabling flexible inference on arbitrarily long
ultrasound recordings through a probabilistic fine-tuning approach. Evaluated
on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,
CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its
potential for reliable and objective FM analysis. These results highlight the
potential of self-supervised contrastive learning for fetal movement analysis,
paving the way for improved prenatal monitoring and clinical decision-making.

</details>


### [31] [EditInfinity: Image Editing with Binary-Quantized Generative Models](https://arxiv.org/abs/2510.20217)
*Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei*

Main category: cs.CV

TL;DR: 本文提出了一种名为EditInfinity的参数高效模型，用于文本驱动的图像编辑，通过利用VQ模型的精确反演能力，克服了基于扩散模型的图像编辑的局限性。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的文本驱动图像编辑方法在图像反演过程中存在近似误差，限制了编辑性能。本文旨在探索参数高效的VQ模型进行图像编辑，以实现更精确的反演。

Method: 提出EditInfinity模型，该模型适配了名为Infinity的二值量化生成模型。通过一种高效的反演机制（结合文本提示校正和图像风格保持）来实现精确的图像反演，并采用整体平滑策略来保证编辑的高保真度和语义对齐。

Result: 在PIE-Bench基准测试中，EditInfinity在“添加”、“更改”和“删除”等编辑操作上，相比于最先进的基于扩散模型的方法，展现出了优越的性能。

Conclusion: EditInfinity通过利用VQ模型的精确反演能力，有效解决了现有扩散模型在图像编辑中存在的反演误差问题，实现了高质量的文本驱动图像编辑。

Abstract: Adapting pretrained diffusion-based generative models for text-driven image
editing with negligible tuning overhead has demonstrated remarkable potential.
A classical adaptation paradigm, as followed by these methods, first infers the
generative trajectory inversely for a given source image by image inversion,
then performs image editing along the inferred trajectory guided by the target
text prompts. However, the performance of image editing is heavily limited by
the approximation errors introduced during image inversion by diffusion models,
which arise from the absence of exact supervision in the intermediate
generative steps. To circumvent this issue, we investigate the
parameter-efficient adaptation of VQ-based generative models for image editing,
and leverage their inherent characteristic that the exact intermediate
quantized representations of a source image are attainable, enabling more
effective supervision for precise image inversion. Specifically, we propose
\emph{EditInfinity}, which adapts \emph{Infinity}, a binary-quantized
generative model, for image editing. We propose an efficient yet effective
image inversion mechanism that integrates text prompting rectification and
image style preservation, enabling precise image inversion. Furthermore, we
devise a holistic smoothing strategy which allows our \emph{EditInfinity} to
perform image editing with high fidelity to source images and precise semantic
alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark
across "add", "change", and "delete" editing operations, demonstrate the
superior performance of our model compared to state-of-the-art diffusion-based
baselines. Code available at: https://github.com/yx-chen-ust/EditInfinity.

</details>


### [32] [Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation](https://arxiv.org/abs/2510.20549)
*Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy*

Main category: cs.CV

TL;DR: SELM-SLAM3 是一个增强型视觉 SLAM 框架，利用 SuperPoint 和 LightGlue 提高在低纹理、运动模糊和光照不佳等挑战性条件下的鲁棒性，显著优于 ORB-SLAM3 和其他先进的 RGB-D SLAM 系统，为视障人士的导航辅助提供了可靠平台。


<details>
  <summary>Details</summary>
Motivation: 尽管 SLAM 技术取得了进展，但在低纹理、运动模糊或光照不佳等挑战性条件下实现鲁棒运行仍然是一个悬而未决的挑战，这些条件常见于辅助视障人士导航等应用中，会降低定位精度、跟踪稳定性和导航的可靠性与安全性。

Method: 提出了一种名为 SELM-SLAM3 的深度学习增强型视觉 SLAM 框架，该框架集成了 SuperPoint 和 LightGlue 以实现鲁棒的特征提取和匹配。

Result: 在 TUM RGB-D、ICL-NUIM 和 TartanAir 数据集上进行了评估，SELM-SLAM3 在低纹理场景和快速运动等挑战性条件下表现出增强的性能，平均比 ORB-SLAM3 高出 87.84%，比最先进的 RGB-D SLAM 系统高出 36.77%。

Conclusion: SELM-SLAM3 在低纹理、运动模糊或光照不佳等具有挑战性的条件下表现出了鲁棒性，在各种具有挑战性的场景中，其性能优于 ORB-SLAM3 和其他先进的 RGB-D SLAM 系统，为开发视障人士的导航辅助工具提供了可靠的平台。

Abstract: Despite advancements in SLAM technologies, robust operation under challenging
conditions such as low-texture, motion-blur, or challenging lighting remains an
open challenge. Such conditions are common in applications such as assistive
navigation for the visually impaired. These challenges undermine localization
accuracy and tracking stability, reducing navigation reliability and safety. To
overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced
visual SLAM framework that integrates SuperPoint and LightGlue for robust
feature extraction and matching. We evaluated our framework using TUM RGB-D,
ICL-NUIM, and TartanAir datasets, which feature diverse and challenging
scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of
87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework
demonstrates enhanced performance under challenging conditions, such as
low-texture scenes and fast motion, providing a reliable platform for
developing navigation aids for the visually impaired.

</details>


### [33] [Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context](https://arxiv.org/abs/2510.20229)
*Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: 幻觉并非由长度引起，而是由对长响应中上下文的依赖性引起，提出一种诱导-检测-抑制框架以减轻幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）的幻觉问题，尤其是在较长、自由格式的响应中，这可能归因于累积的不确定性。

Method: 提出一种“诱导-检测-抑制”框架，该框架通过精心设计的上下文主动诱导幻觉，利用诱导实例进行早期检测，并抑制解码过程中的潜在对象级幻觉。

Result: 在所有基准测试中取得了一致且显著的改进，验证了该框架的有效性、检测能力和幻觉缓解能力。

Conclusion: 研究结果强调了上下文依赖性在 LVLM 长响应幻觉中的作用，并为探索 LVLM 幻觉提供了新的见解。

Abstract: Large Vision-Language Models (LVLMs) have made significant progress in recent
years but are also prone to hallucination issues. They exhibit more
hallucinations in longer, free-form responses, often attributed to accumulated
uncertainties. In this paper, we ask: Does increased hallucination result
solely from length-induced errors, or is there a deeper underlying mechanism?
After a series of preliminary experiments and findings, we suggest that the
risk of hallucinations is not caused by length itself but by the increased
reliance on context for coherence and completeness in longer responses.
Building on these insights, we propose a novel "induce-detect-suppress"
framework that actively induces hallucinations through deliberately designed
contexts, leverages induced instances for early detection of high-risk cases,
and ultimately suppresses potential object-level hallucinations during actual
decoding. Our approach achieves consistent, significant improvements across all
benchmarks, demonstrating its efficacy. The strong detection and improved
hallucination mitigation not only validate our framework but, more importantly,
re-validate our hypothesis on context. Rather than solely pursuing performance
gains, this study aims to provide new insights and serves as a first step
toward a deeper exploration of hallucinations in LVLMs' longer responses.

</details>


### [34] [EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence](https://arxiv.org/abs/2510.20578)
*Ding Zou,Feifan Wang,Mengyu Ge,Siyuan Fan,Zongbing Zhang,Wei Chen,Lingfeng Wang,Zhongyou Hu,Wenrui Yan,Zhengwei Gao,Hao Wang,Weizhao Jin,Yu Zhang,Hainan Zhao,Mingliang Zhang,Xianxian Xi,Yaru Zhang,Wenyuan Li,Zhengguang Gao,Yurui Zhu*

Main category: cs.CV

TL;DR: EmbodiedBrain是一个新的视觉-语言基础模型，旨在解决当前多模态大模型在具身智能任务中的局限性，如模型设计与代理需求不匹配、实时延迟与性能的权衡以及不真实的离线评估指标。该模型通过代理对齐的数据结构、结合监督微调（SFT）和步进增强组相对策略优化（Step-GRPO）的训练方法、以及包含生成奖励模型（GRM）的奖励系统来提升性能。同时，提出了包括通用、规划和端到端仿真基准在内的三部分评估体系，并开源了相关数据、模型权重和评估方法，在各项指标上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大模型在具身智能任务中存在模型设计与代理需求不匹配、实时延迟与性能的权衡以及不真实的离线评估指标等局限性，阻碍了通用人工智能（AGI）的实现。本研究旨在解决这些挑战，为通用具身代理的下一代发展铺平道路。

Method: 提出EmbodiedBrain模型，包含7B和32B参数两种尺寸。该框架具有代理对齐的数据结构，并采用结合大规模监督微调（SFT）和步进增强组相对策略优化（Step-GRPO）的训练方法，通过将先前步骤整合为引导性先驱来提升长时任务的成功率。此外，还引入了包含生成奖励模型（GRM）的全面奖励系统，并建立了一个包含通用、规划和端到端仿真基准的三部分评估体系，同时开源了一个新的、具有挑战性的仿真环境。

Result: 实验结果表明，EmbodiedBrain在所有指标上均 achieved 优越性能，为具身基础模型树立了新的最先进水平。

Conclusion: EmbodiedBrain模型成功解决了当前多模态大模型在具身智能任务中的关键挑战，并在各项评估中取得了优异的成果，为通用具身代理的发展奠定了基础。研究团队已开源所有数据、模型权重和评估方法，以促进该领域的研究。

Abstract: The realization of Artificial General Intelligence (AGI) necessitates
Embodied AI agents capable of robust spatial perception, effective task
planning, and adaptive execution in physical environments. However, current
large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks
suffer from key limitations, including a significant gap between model design
and agent requirements, an unavoidable trade-off between real-time latency and
performance, and the use of unauthentic, offline evaluation metrics. To address
these challenges, we propose EmbodiedBrain, a novel vision-language foundation
model available in both 7B and 32B parameter sizes. Our framework features an
agent-aligned data structure and employs a powerful training methodology that
integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group
Relative Policy Optimization (Step-GRPO), which boosts long-horizon task
success by integrating preceding steps as Guided Precursors. Furthermore, we
incorporate a comprehensive reward system, including a Generative Reward Model
(GRM) accelerated at the infrastructure level, to improve training efficiency.
For enable thorough validation, we establish a three-part evaluation system
encompassing General, Planning, and End-to-End Simulation Benchmarks,
highlighted by the proposal and open-sourcing of a novel, challenging
simulation environment. Experimental results demonstrate that EmbodiedBrain
achieves superior performance across all metrics, establishing a new
state-of-the-art for embodied foundation models. Towards paving the way for the
next generation of generalist embodied agents, we open-source all of our data,
model weight, and evaluating methods, which are available at
https://zterobot.github.io/EmbodiedBrain.github.io.

</details>


### [35] [COS3D: Collaborative Open-Vocabulary 3D Segmentation](https://arxiv.org/abs/2510.20238)
*Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu*

Main category: cs.CV

TL;DR: COS3D是一个创新的开放词汇3D分割框架，通过协作式语言和分割场解决了现有方法的局限性，并在基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯泼溅的3D分割方法在处理开放词汇任务时存在不足，要么分割精度不高，要么依赖预先计算的分割导致误差累积。COS3D旨在通过一种新的协作框架来解决这些问题。

Method: COS3D引入了协作场概念，包含实例场和语言场，并通过实例到语言的特征映射和两阶段训练策略来构建协作场。在推理阶段，采用自适应语言到实例提示优化来提高分割质量。

Result: 实验结果表明，COS3D在两个广泛使用的基准测试中取得了优于现有方法的性能，并展示了其在新型图像3D分割、分层分割和机器人技术等领域的应用潜力。

Conclusion: COS3D通过其创新的协作框架有效整合了语言和分割线索，显著提高了开放词汇3D分割任务的性能，并为相关应用提供了新的可能性。

Abstract: Open-vocabulary 3D segmentation is a fundamental yet challenging task,
requiring a mutual understanding of both segmentation and language. However,
existing Gaussian-splatting-based methods rely either on a single 3D language
field, leading to inferior segmentation, or on pre-computed class-agnostic
segmentations, suffering from error accumulation. To address these limitations,
we present COS3D, a new collaborative prompt-segmentation framework that
contributes to effectively integrating complementary language and segmentation
cues throughout its entire pipeline. We first introduce the new concept of
collaborative field, comprising an instance field and a language field, as the
cornerstone for collaboration. During training, to effectively construct the
collaborative field, our key idea is to capture the intrinsic relationship
between the instance field and language field, through a novel
instance-to-language feature mapping and designing an efficient two-stage
training strategy. During inference, to bridge distinct characteristics of the
two fields, we further design an adaptive language-to-instance prompt
refinement, promoting high-quality prompt-segmentation inference. Extensive
experiments not only demonstrate COS3D's leading performance over existing
methods on two widely-used benchmarks but also show its high potential to
various applications,~\ie, novel image-based 3D segmentation, hierarchical
segmentation, and robotics. The code is publicly available at
\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.

</details>


### [36] [ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata](https://arxiv.org/abs/2510.20708)
*Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera*

Main category: cs.CV

TL;DR: ALICE-LRI是一种新的、通用的、传感器无关的方法，可以从旋转激光雷达点云生成无损的范围图像，无需制造商元数据或校准文件。


<details>
  <summary>Details</summary>
Motivation: 传统的将激光雷达数据投影到2D范围图像的方法存在固有的几何不一致性，导致信息丢失，影响高精度应用。因此，需要一种能够实现无损投影的方法。

Method: ALICE-LRI通过自动逆向工程激光雷达传感器的内部几何结构来推断关键参数（包括激光束配置、角度分布和每束校正），从而实现无损投影和完整的点云重建，且不丢失任何点。

Result: ALICE-LRI在KITTI和DurLAR数据集上的评估显示，在所有点云中实现了完美的点保留（零点丢失）。几何精度保持在传感器精度限制之内，实现了几何无损和实时性能。此外，压缩案例研究表明，在实际应用中，该方法可以显著提高数据质量。

Conclusion: ALICE-LRI通过从近似投影转向无损激光雷达投影，为需要完整几何保持的高精度遥感应用开辟了新的可能性。

Abstract: 3D LiDAR sensors are essential for autonomous navigation, environmental
monitoring, and precision mapping in remote sensing applications. To
efficiently process the massive point clouds generated by these sensors, LiDAR
data is often projected into 2D range images that organize points by their
angular positions and distances. While these range image representations enable
efficient processing, conventional projection methods suffer from fundamental
geometric inconsistencies that cause irreversible information loss,
compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR
Intrinsic Calibration Estimation for Lossless Range Images), the first general,
sensor-agnostic method that achieves lossless range image generation from
spinning LiDAR point clouds without requiring manufacturer metadata or
calibration files. Our algorithm automatically reverse-engineers the intrinsic
geometry of any spinning LiDAR sensor by inferring critical parameters
including laser beam configuration, angular distributions, and per-beam
calibration corrections, enabling lossless projection and complete point cloud
reconstruction with zero point loss. Comprehensive evaluation across the
complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect
point preservation, with zero points lost across all point clouds. Geometric
accuracy is maintained well within sensor precision limits, establishing
geometric losslessness with real-time performance. We also present a
compression case study that validates substantial downstream benefits,
demonstrating significant quality improvements in practical applications. This
paradigm shift from approximate to lossless LiDAR projections opens new
possibilities for high-precision remote sensing applications requiring complete
geometric preservation.

</details>


### [37] [Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding](https://arxiv.org/abs/2510.20244)
*Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee*

Main category: cs.CV

TL;DR: 提出了一种名为DualGround的双分支架构，通过分离全局和局部语义来改进视频时间定位任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时间定位方法在跨模态注意力中均匀处理所有文本标记，忽略了它们的语义作用，导致模型过度依赖全局语义而未能有效利用词级信号，限制了细粒度时间定位能力。

Method: DualGround采用双分支架构，将[EOS]标记通过句子级路径分离全局语义，并将词标记聚类为短语级单元以进行局部定位。它通过（1）标记角色感知的跨模态交互策略在结构解耦的方式下将视频特征与句子级和短语级语义对齐，以及（2）一个联合建模框架，通过利用结构化短语感知上下文来改进全局句子级对齐并增强细粒度时间定位。

Result: DualGround在QVHighlights和Charades-STA基准的视频时间定位（包括瞬间检索和高亮检测）任务上取得了最先进的性能。

Conclusion: 解耦的语义建模在视频-语言对齐中是有效的，DualGround通过同时捕获粗粒度和局部语义，能够实现更具表现力和上下文感知的视频定位。

Abstract: Video Temporal Grounding (VTG) aims to localize temporal segments in long,
untrimmed videos that align with a given natural language query. This task
typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection
(HD). While recent advances have been progressed by powerful pretrained
vision-language models such as CLIP and InternVideo2, existing approaches
commonly treat all text tokens uniformly during crossmodal attention,
disregarding their distinct semantic roles. To validate the limitations of this
approach, we conduct controlled experiments demonstrating that VTG models
overly rely on [EOS]-driven global semantics while failing to effectively
utilize word-level signals, which limits their ability to achieve fine-grained
temporal alignment. Motivated by this limitation, we propose DualGround, a
dual-branch architecture that explicitly separates global and local semantics
by routing the [EOS] token through a sentence-level path and clustering word
tokens into phrase-level units for localized grounding. Our method introduces
(1) tokenrole- aware cross modal interaction strategies that align video
features with sentence-level and phrase-level semantics in a structurally
disentangled manner, and (2) a joint modeling framework that not only improves
global sentence-level alignment but also enhances finegrained temporal
grounding by leveraging structured phrase-aware context. This design allows the
model to capture both coarse and localized semantics, enabling more expressive
and context-aware video grounding. DualGround achieves state-of-the-art
performance on both Moment Retrieval and Highlight Detection tasks across
QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of
disentangled semantic modeling in video-language alignment.

</details>


### [38] [Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization](https://arxiv.org/abs/2510.20247)
*Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为EDGeo的框架，用于提高跨视图物体地理定位的精度，特别是在处理卫星图像中的大跨度物体时。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于仅捕获2D坐标而忽略物体形状信息的基于关键点的编码，导致对标注偏移敏感且跨视图匹配能力有限。

Method: 提出了一种基于掩码的位置编码方案，利用分割掩码同时捕获空间坐标和物体轮廓，并将模型从“位置感知”升级为“物体感知”。设计了一个上下文增强模块，利用水平和垂直条状卷积核提取长距离上下文特征，以增强条状物体的特征辨别力。集成了这两种方法，提出了EDGeo框架。

Result: 在CVOGL和VIGOR-Building两个公开数据集上进行了广泛的实验，证明EDGeo在具有挑战性的地面到卫星场景下，定位精度提高了3.39%，达到了最先进的性能。

Conclusion: 该研究提供了一种鲁棒的位置编码范式和上下文建模框架，以推进跨视图地理定位研究。

Abstract: Cross-view object geo-localization enables high-precision object localization
through cross-view matching, with critical applications in autonomous driving,
urban management, and disaster response. However, existing methods rely on
keypoint-based positional encoding, which captures only 2D coordinates while
neglecting object shape information, resulting in sensitivity to annotation
shifts and limited cross-view matching capability. To address these
limitations, we propose a mask-based positional encoding scheme that leverages
segmentation masks to capture both spatial coordinates and object silhouettes,
thereby upgrading the model from "location-aware" to "object-aware."
Furthermore, to tackle the challenge of large-span objects (e.g., elongated
buildings) in satellite imagery, we design a context enhancement module. This
module employs horizontal and vertical strip convolutional kernels to extract
long-range contextual features, enhancing feature discrimination among
strip-like objects. Integrating MPE and CEM, we present EDGeo, an end-to-end
framework for robust cross-view object geo-localization. Extensive experiments
on two public datasets (CVOGL and VIGOR-Building) demonstrate that our method
achieves state-of-the-art performance, with a 3.39% improvement in localization
accuracy under challenging ground-to-satellite scenarios. This work provides a
robust positional encoding paradigm and a contextual modeling framework for
advancing cross-view geo-localization research.

</details>


### [39] [Calibrating Multimodal Consensus for Emotion Recognition](https://arxiv.org/abs/2510.20256)
*Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为校准多模态共识（CMC）的模型，用于解决多模态情感识别（MER）中模态间语义不一致和文本模态主导的问题。CMC通过伪标签生成模块（PLGM）进行无监督的单模态预训练，并使用无参数融合模块（PFM）和多模态共识路由器（MCR）进行多模态微调，以减轻文本主导并实现更可靠的融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态情感识别（MER）中存在模态间语义不一致（如文本与视觉信息冲突）以及文本模态主导的问题，影响了识别准确性。

Method: 提出校准多模态共识（CMC）模型，包含伪标签生成模块（PLGM）用于单模态自监督预训练，以及无参数融合模块（PFM）和多模态共识路由器（MCR）进行多模态微调，以解决文本主导问题并引导模态融合。

Result: CMC模型在CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI四个数据集上取得了与最先进方法相当或更优的性能，并在CH-SIMS和CH-SIMS v2数据集上语义不一致的情况下表现出显著优势。

Conclusion: CMC模型能够有效解决多模态情感识别中的模态间语义不一致和文本模态主导问题，并在多个数据集上取得了优异的性能。

Abstract: In recent years, Multimodal Emotion Recognition (MER) has made substantial
progress. Nevertheless, most existing approaches neglect the semantic
inconsistencies that may arise across modalities, such as conflicting emotional
cues between text and visual inputs. Besides, current methods are often
dominated by the text modality due to its strong representational capacity,
which can compromise recognition accuracy. To address these challenges, we
propose a model termed Calibrated Multimodal Consensus (CMC). CMC introduces a
Pseudo Label Generation Module (PLGM) to produce pseudo unimodal labels,
enabling unimodal pretraining in a self-supervised fashion. It then employs a
Parameter-free Fusion Module (PFM) and a Multimodal Consensus Router (MCR) for
multimodal finetuning, thereby mitigating text dominance and guiding the fusion
process toward a more reliable consensus. Experimental results demonstrate that
CMC achieves performance on par with or superior to state-of-the-art methods
across four datasets, CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, and
exhibits notable advantages in scenarios with semantic inconsistencies on
CH-SIMS and CH-SIMS v2. The implementation of this work is publicly accessible
at https://github.com/gw-zhong/CMC.

</details>


### [40] [Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals](https://arxiv.org/abs/2510.20267)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.CV

TL;DR: 一个帮助视障人士识别货币的实时系统，使用YOLOv8 nano模型，识别美元、欧元和孟加拉塔卡，准确率达97.73%。


<details>
  <summary>Details</summary>
Motivation: 提供一个方便且实用的货币检测系统，以帮助视障人士更独立地处理金钱。

Method: 使用YOLOv8 nano模型，并对自定义检测头进行了改进，增加了深度卷积层和Squeeze-and-Excitation块，以提高特征提取和检测的准确性。该模型在包含30类货币（美元、欧元、孟加拉塔卡）的数据集上进行了训练。

Result: 该模型在货币检测任务上达到了97.73%的准确率，95.23%的召回率，95.85%的F1分数，以及97.21%的mAP50(B)。

Conclusion: 所提出的实时货币检测系统能够有效地帮助视障人士识别货币，并通过语音反馈进一步提升其实用性，从而增强他们在处理金钱方面的独立性。

Abstract: Technologies like smartphones have become an essential in our daily lives. It
has made accessible to everyone including visually impaired individuals. With
the use of smartphone cameras, image capturing and processing have become more
convenient. With the use of smartphones and machine learning, the life of
visually impaired can be made a little easier. Daily tasks such as handling
money without relying on someone can be troublesome for them. For that purpose
this paper presents a real-time currency detection system designed to assist
visually impaired individuals. The proposed model is trained on a dataset
containing 30 classes of notes and coins, representing 3 types of currency: US
dollar (USD), Euro (EUR), and Bangladeshi taka (BDT). Our approach uses a
YOLOv8 nano model with a custom detection head featuring deep convolutional
layers and Squeeze-and-Excitation blocks to enhance feature extraction and
detection accuracy. Our model has achieved a higher accuracy of 97.73%, recall
of 95.23%, f1-score of 95.85% and a mean Average Precision at IoU=0.5
(mAP50(B)) of 97.21\%. Using the voice feedback after the detection would help
the visually impaired to identify the currency. This paper aims to create a
practical and efficient currency detection system to empower visually impaired
individuals independent in handling money.

</details>


### [41] [GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection](https://arxiv.org/abs/2510.20268)
*Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为GMFVAD的视频异常检测方法，通过利用多模态信息的交叉性来精炼特征，减少冗余，并提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法在利用视觉特征的时空相关性或引入文本特征时存在不足，例如信息整合粗糙、冗余信息过多。

Method: 提出Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD)方法，生成更细粒度的多模态特征，并结合视频片段内容和文本标题信息，以增强视觉特征，减少冗余。

Result: GMFVAD在四个主要数据集上取得了最先进的性能，并且通过消融实验验证了其有效性。

Conclusion: GMFVAD通过精炼特征和减少冗余信息，有效提升了视频异常检测的效果，达到了最先进的水平。

Abstract: Video anomaly detection (VAD) is a challenging task that detects anomalous
frames in continuous surveillance videos. Most previous work utilizes the
spatio-temporal correlation of visual features to distinguish whether there are
abnormalities in video snippets. Recently, some works attempt to introduce
multi-modal information, like text feature, to enhance the results of video
anomaly detection. However, these works merely incorporate text features into
video snippets in a coarse manner, overlooking the significant amount of
redundant information that may exist within the video snippets. Therefore, we
propose to leverage the diversity among multi-modal information to further
refine the extracted features, reducing the redundancy in visual features, and
we propose Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD).
Specifically, we generate more grained multi-modal feature based on the video
snippet, which summarizes the main content, and text features based on the
captions of original video will be introduced to further enhance the visual
features of highlighted portions. Experiments show that the proposed GMFVAD
achieves state-of-the-art performance on four mainly datasets. Ablation
experiments also validate that the improvement of GMFVAD is due to the
reduction of redundant information.

</details>


### [42] [Causal Debiasing for Visual Commonsense Reasoning](https://arxiv.org/abs/2510.20281)
*Jiayi Zou,Gengyun Jia,Bing-Kun Bao*

Main category: cs.CV

TL;DR: 现有视觉常识推理（VCR）方法在提高预测准确性的同时，往往忽略了数据集中的偏见，并且缺乏相应的消除偏见策略。本文分析了文本和视觉数据中存在的共现和统计偏见，提出了VCR-OOD数据集（包含VCR-OOD-QA和VCR-OOD-VA子集）来评估模型在跨模态下的泛化能力。此外，本文还分析了VCR中的因果图和预测捷径，并采用后门调整方法来消除偏见。通过创建一个基于正确答案集合的字典来消除预测捷径，实验证明了该消除偏见方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VCR方法忽略了数据集偏见且缺乏消除偏见策略。

Method: 分析了文本和视觉数据中的共现和统计偏见，提出了VCR-OOD数据集来评估模型泛化能力，分析了因果图和预测捷径，并采用后门调整方法，通过创建基于正确答案集合的字典来消除预测捷径。

Result: 实验证明了所提出的消除偏见方法的有效性。

Conclusion: 所提出的消除偏见方法在VCR任务中是有效的。

Abstract: Visual Commonsense Reasoning (VCR) refers to answering questions and
providing explanations based on images. While existing methods achieve high
prediction accuracy, they often overlook bias in datasets and lack debiasing
strategies. In this paper, our analysis reveals co-occurrence and statistical
biases in both textual and visual data. We introduce the VCR-OOD datasets,
comprising VCR-OOD-QA and VCR-OOD-VA subsets, which are designed to evaluate
the generalization capabilities of models across two modalities. Furthermore,
we analyze the causal graphs and prediction shortcuts in VCR and adopt a
backdoor adjustment method to remove bias. Specifically, we create a dictionary
based on the set of correct answers to eliminate prediction shortcuts.
Experiments demonstrate the effectiveness of our debiasing method across
different datasets.

</details>


### [43] [Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition](https://arxiv.org/abs/2510.20284)
*Haodong Yang,Zhongling Huang,Shaojie Guo,Zhe Zhang,Gong Cheng,Junwei Han*

Main category: cs.CV

TL;DR: KINN是一个创新的框架，通过结合物理知识和深度学习，在数据有限和领域迁移的情况下，解决了CV-SAR图像识别中的泛化性、可解释性和效率的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在CV-SAR图像识别中面临表示困境：在数据有限和领域迁移的情况下，难以同时优化泛化性、可解释性和效率。该研究认为，CV-SAR数据中固有的电磁散射特征是解决此困境的关键，但传统模型未能充分利用这些特征。

Method: 提出知识感知神经网络（KINN），一个基于“压缩-聚合-压缩”架构的轻量级框架。首先，通过物理引导的压缩，利用自适应嵌入物理先验的新型字典处理器，使紧凑型展开网络能够高效提取稀疏的、基于物理的特征。然后，聚合模块丰富这些表示。最后，通过使用具有自蒸馏的紧凑型分类头进行语义压缩，学习最大程度与任务相关且具有辨别力的嵌入。KINN有CNN（0.7M）和Vision Transformer（0.95M）两种变体。

Result: 在五个SAR基准测试上的大量评估表明，KINN在参数高效识别方面达到了最先进水平，在数据稀疏和分布外场景中表现出卓越的泛化能力，并具有显著的可解释性。

Conclusion: KINN有效解决了CV-SAR图像识别中的表示困境，为可信赖的AI在SAR图像分析领域开辟了新途径。

Abstract: Deep learning models for complex-valued Synthetic Aperture Radar (CV-SAR)
image recognition are fundamentally constrained by a representation trilemma
under data-limited and domain-shift scenarios: the concurrent, yet conflicting,
optimization of generalization, interpretability, and efficiency. Our work is
motivated by the premise that the rich electromagnetic scattering features
inherent in CV-SAR data hold the key to resolving this trilemma, yet they are
insufficiently harnessed by conventional data-driven models. To this end, we
introduce the Knowledge-Informed Neural Network (KINN), a lightweight framework
built upon a novel "compression-aggregation-compression" architecture. The
first stage performs a physics-guided compression, wherein a novel dictionary
processor adaptively embeds physical priors, enabling a compact unfolding
network to efficiently extract sparse, physically-grounded signatures. A
subsequent aggregation module enriches these representations, followed by a
final semantic compression stage that utilizes a compact classification head
with self-distillation to learn maximally task-relevant and discriminative
embeddings. We instantiate KINN in both CNN (0.7M) and Vision Transformer
(0.95M) variants. Extensive evaluations on five SAR benchmarks confirm that
KINN establishes a state-of-the-art in parameter-efficient recognition,
offering exceptional generalization in data-scarce and out-of-distribution
scenarios and tangible interpretability, thereby providing an effective
solution to the representation trilemma and offering a new path for trustworthy
AI in SAR image analysis.

</details>


### [44] [DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering](https://arxiv.org/abs/2510.20285)
*Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu*

Main category: cs.CV

TL;DR: 通过引入双模态反事实对比构建（DMC^3）框架，该框架通过事件描述释义和核心交互挖掘来生成正负样本，并利用对比损失进行优化，以解决第一人称视频问答中的多事件理解和手部-物体交互识别等挑战，在EgoTaskQA和QAEGO4D数据集上均达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频问答方面取得了进展，但未能解决第一人称视频独有的挑战，例如多事件理解和手部-物体交互识别。

Method: 提出了一种双模态反事实对比构建（DMC^3）框架，包括一个视频问答基线、一个反事实样本构建模块（通过事件描述释义和核心交互挖掘生成正负样本）和一个涉及反事实样本的对比优化模块（使用对比损失来最小化原始样本和正样本之间的距离，同时最大化与负样本的距离）。

Result: 在EgoTaskQA数据集的normal和indirect split上分别达到52.51%和46.04%的准确率，在QAEGO4D数据集上达到13.2%的准确率，均达到最先进水平。

Conclusion: 所提出的DMC^3框架通过引入反事实样本和对比学习，有效地解决了第一人称视频问答中的挑战，并在多个基准测试中取得了最先进的性能。

Abstract: Egocentric Video Question Answering (Egocentric VideoQA) plays an important
role in egocentric video understanding, which refers to answering questions
based on first-person videos. Although existing methods have made progress
through the paradigm of pre-training and fine-tuning, they ignore the unique
challenges posed by the first-person perspective, such as understanding
multiple events and recognizing hand-object interactions. To deal with these
challenges, we propose a Dual-Modal Counterfactual Contrastive Construction
(DMC$^3$) framework, which contains an egocentric videoqa baseline, a
counterfactual sample construction module and a counterfactual sample-involved
contrastive optimization. Specifically, We first develop a counterfactual
sample construction module to generate positive and negative samples for
textual and visual modalities through event description paraphrasing and core
interaction mining, respectively. Then, We feed these samples together with the
original samples into the baseline. Finally, in the counterfactual
sample-involved contrastive optimization module, we apply contrastive loss to
minimize the distance between the original sample features and the positive
sample features, while maximizing the distance from the negative samples.
Experiments show that our method achieve 52.51\% and 46.04\% on the
\textit{normal} and \textit{indirect} splits of EgoTaskQA, and 13.2\% on
QAEGO4D, both reaching the state-of-the-art performance.

</details>


### [45] [SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial Feature Learning](https://arxiv.org/abs/2402.01555)
*Samuel Adebayo,Joost C. Dessing,Seán McLoone*

Main category: cs.CV

TL;DR: SLYKLatent通过自监督学习和基于补丁的三分支网络来提高凝视估计的准确性，在多个基准数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决由于不确定性、协变量移位和测试域泛化等问题导致的凝视估计外观不稳定性挑战。

Method: SLYKLatent采用自监督学习进行初始训练，然后结合基于补丁的三分支网络和反向解释方差加权训练损失函数进行优化。

Result: 在Gaze360数据集上提高了10.9%，在MPIIFaceGaze数据集上提高了3.8%，在ETH-XGaze数据集上提高了11.6%。在RAF-DB和Affectnet数据集上的准确率分别为86.4%和60.9%。

Conclusion: SLYKLatent通过其新颖的组件有效解决了凝视估计中的外观不稳定性问题，并在多个数据集上取得了最先进的性能。

Abstract: In this research, we present SLYKLatent, a novel approach for enhancing gaze
estimation by addressing appearance instability challenges in datasets due to
aleatoric uncertainties, covariant shifts, and test domain generalization.
SLYKLatent utilizes Self-Supervised Learning for initial training with facial
expression datasets, followed by refinement with a patch-based tri-branch
network and an inverse explained variance-weighted training loss function. Our
evaluation on benchmark datasets achieves a 10.9% improvement on Gaze360,
supersedes top MPIIFaceGaze results with 3.8%, and leads on a subset of
ETH-XGaze by 11.6%, surpassing existing methods by significant margins.
Adaptability tests on RAF-DB and Affectnet show 86.4% and 60.9% accuracies,
respectively. Ablation studies confirm the effectiveness of SLYKLatent's novel
components.

</details>


### [46] [UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning](https://arxiv.org/abs/2510.20286)
*Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“指令即推理”的新范式，用于改进图形用户界面（GUI）代理中的自然语言指令到可操作UI元素的映射（GUI grounding）。该范式将指令视为动态分析路径，而不是静态的用户意图代理，并通过两阶段训练框架（监督微调和强化学习）来优化模型选择和组合指令路径的能力。实验结果表明，该方法在多个基准测试中取得了最先进的性能，并展现了出色的智能体潜力和推理合成能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI grounding方法将指令视为用户意图的静态代理，忽略了指令多样性和质量对性能的影响。研究发现现有数据集存在高达23.3%的指令缺陷率，并且利用指令多样性可以显著提升性能（高达76%）。因此，本研究的动机是开发一种能够动态处理和利用指令多样性的新范式，以提高GUI grounding的性能。

Method: 本研究提出“指令即推理”范式，将指令视为动态分析路径。采用两阶段训练框架：1. 监督微调（SFT），在合成的多样化指令上进行训练，以培养多视角推理能力；2. 强化学习（RL），以优化路径选择和组合。具体模型为UI-Ins-7B和UI-Ins-32B。

Result: UI-Ins-7B和UI-Ins-32B在五个具有挑战性的GUI grounding基准测试中取得了最先进的成果。UI-Ins-32B在UI-I2E-Bench上达到87.3%的准确率，在ScreenSpot-Pro上达到57.0%，在MMBench-GUI L2上达到84.9%。UI-Ins-7B在AndroidWorld上实现了74.1%的成功率。分析揭示了推理如何增强而非阻碍性能，以及该方法如何缓解SFT+RL框架中的策略崩溃问题。

Conclusion: “指令即推理”范式通过将指令视为动态分析路径并结合两阶段训练框架，显著提高了GUI grounding的性能，并在多个基准测试中取得了最先进的结果。该模型还展现了强大的智能体潜力和推理合成能力。研究还为理解推理在GUI grounding中的作用提供了新的见解。

Abstract: GUI grounding, which maps natural-language instructions to actionable UI
elements, is a core capability of GUI agents. Prior works largely treats
instructions as a static proxy for user intent, overlooking the impact of
instruction diversity and quality on grounding performance. Through a careful
investigation of existing grounding datasets, we find a 23.3% flaw rate in
their instructions and show that inference-time exploitation of instruction
diversity yields up to a substantial 76% relative performance improvement. In
this paper, we introduce the Instruction-as-Reasoning paradigm, treating
instructions as dynamic analytical pathways that offer distinct perspectives
and enabling the model to select the most effective pathway during reasoning.
To achieve this, we propose a two-stage training framework: supervised
fine-tuning (SFT) on synthesized, diverse instructions to instill
multi-perspective reasoning, followed by reinforcement learning (RL) to
optimize pathway selection and composition. Our resulting models, UI-Ins-7B and
UI-Ins-32B, achieve state-of-the-art results on five challenging grounding
benchmarks and exhibit emergent reasoning, selectively composing and
synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B
attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on
ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model
demonstrates strong agentic potential, achieving a 74.1% success rate on
AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals
additional insights such as how reasoning can be formulated to enhance rather
than hinder grounding performance, and how our method mitigates policy collapse
in the SFT+RL framework. All code and model checkpoints will be publicly
released in https://github.com/alibaba/UI-Ins.

</details>


### [47] [Breakdance Video classification in the age of Generative AI](https://arxiv.org/abs/2510.20287)
*Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson*

Main category: cs.CV

TL;DR: 大型视觉语言模型在体育领域有广泛应用，但大多集中在热门运动项目上，而本研究则将目光投向了小众但受欢迎的霹雳舞，并分析了现代视频基础模型在该领域的适用性。结果表明，视频编码器模型在预测任务上优于最先进的视频语言模型，并对如何选择编码器模型提供了指导，同时深入分析了针对霹雳舞视频分类的微调解码器模型的工作原理。


<details>
  <summary>Details</summary>
Motivation: 目前大多数大型视觉语言模型的研究集中在热门体育项目上，而对霹雳舞这类小众但受欢迎的舞蹈体育项目关注较少，本研究旨在分析现代视频基础模型（包括编码器和解码器）在霹雳舞领域的适用性。

Method: 分析了现代视频基础模型（包括编码器和解码器）在霹雳舞领域的适用性，并对微调后的解码器模型进行了深入分析。

Result: 视频编码器模型在霹雳舞预测任务上持续优于最先进的视频语言模型。

Conclusion: 视频编码器模型在霹雳舞预测任务上表现优于视频语言模型，并为如何选择编码器模型提供了指导，同时深入分析了微调解码器模型在霹雳舞视频分类中的应用。

Abstract: Large Vision Language models have seen huge application in several sports
use-cases recently. Most of these works have been targeted towards a limited
subset of popular sports like soccer, cricket, basketball etc; focusing on
generative tasks like visual question answering, highlight generation. This
work analyzes the applicability of the modern video foundation models (both
encoder and decoder) for a very niche but hugely popular dance sports -
breakdance. Our results show that Video Encoder models continue to outperform
state-of-the-art Video Language Models for prediction tasks. We provide
insights on how to choose the encoder model and provide a thorough analysis
into the workings of a finetuned decoder model for breakdance video
classification.

</details>


### [48] [A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization](https://arxiv.org/abs/2510.20291)
*LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本研究提出了一个创新的跨模态无人机导航解决方案，用于在大型多平台图像库中根据自然语言查询检索最相关的地理参考图像，并荣获RoboSense 2025 Track 4竞赛冠军。


<details>
  <summary>Details</summary>
Motivation: 主要挑战在于处理跨平台异构性和训练描述与特定平台测试查询之间的领域差距。

Method: 通过领域对齐的预处理流程和混合专家（MoE）框架来解决这些挑战。预处理包括平台划分、卫星图像增强和移除方向词；LLM驱动的字幕细化流程用于统一文本语义与各平台的视觉特征。使用BGE-M3（文本）和EVA-CLIP（图像）训练三个平台专家，并采用渐进式两阶段硬负例挖掘策略增强判别能力，最后在推理时融合专家得分。

Result: 所提出的系统在官方排行榜上名列前茅，证明了其在异构视角下强大的跨模态地理定位能力。

Conclusion: 该方法有效解决了跨模态无人机导航中的关键挑战，并在真实世界场景中取得了优异的性能。

Abstract: We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone
Navigation. The task retrieves the most relevant geo-referenced image from a
large multi-platform corpus (satellite/drone/ground) given a natural-language
query. Two obstacles are severe inter-platform heterogeneity and a domain gap
between generic training descriptions and platform-specific test queries. We
mitigate these with a domain-aligned preprocessing pipeline and a
Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite
augmentation, and removal of orientation words; (ii) an LLM-based caption
refinement pipeline to align textual semantics with the distinct visual
characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we
train three platform experts using a progressive two-stage, hard-negative
mining strategy to enhance discriminative power, and fuse their scores at
inference. The system tops the official leaderboard, demonstrating robust
cross-modal geo-localization under heterogeneous viewpoints.

</details>


### [49] [HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models](https://arxiv.org/abs/2510.20322)
*Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为HyperET的高效多模态大语言模型（MLLM）训练范式，利用双曲空间来解决现有视觉编码器与语言在多粒度对齐方面存在的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在训练时需要极高的计算资源，主要是因为其视觉编码器（如CLIP和SAM）缺乏与语言在多粒度上的对齐。

Method: 提出利用双曲空间来建模层次结构，并设计了HyperET训练范式，通过动态调整双曲半径和使用Möbius乘法操作（包括对角缩放矩阵、块对角矩阵和带状矩阵）来优化视觉表征，使其与文本在任意粒度上对齐。

Result: 在多个MLLM基准测试中，HyperET在现有预训练和微调模型上均取得了显著的性能提升，并且引入的额外参数不到1%。

Conclusion: HyperET是一种高效的MLLM训练方法，能够有效地解决视觉和文本在多粒度对齐上的效率问题，并在多种基准测试中展现出优越的性能。

Abstract: Multi-modal large language models (MLLMs) have emerged as a transformative
approach for aligning visual and textual understanding. They typically require
extremely high computational resources (e.g., thousands of GPUs) for training
to achieve cross-modal alignment at multi-granularity levels. We argue that a
key source of this inefficiency lies in the vision encoders they widely equip
with, e.g., CLIP and SAM, which lack the alignment with language at
multi-granularity levels. To address this issue, in this paper, we leverage
hyperbolic space, which inherently models hierarchical levels and thus provides
a principled framework for bridging the granularity gap between visual and
textual modalities at an arbitrary granularity level. Concretely, we propose an
efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize
visual representations to align with their textual counterparts at an arbitrary
granularity level through dynamic hyperbolic radius adjustment in hyperbolic
space. HyperET employs learnable matrices with M\"{o}bius multiplication
operations, implemented via three effective configurations: diagonal scaling
matrices, block-diagonal matrices, and banded matrices, providing a flexible
yet efficient parametrization strategy. Comprehensive experiments across
multiple MLLM benchmarks demonstrate that HyperET consistently improves both
existing pre-training and fine-tuning MLLMs clearly with less than 1\%
additional parameters.

</details>


### [50] [AnyPcc: Compressing Any Point Cloud with a Single Universal Model](https://arxiv.org/abs/2510.20331)
*Kangli Wang,Qianxi Yi,Yuqi Ye,Shihao Li,Wei Gao*

Main category: cs.CV

TL;DR: AnyPcc是一个通用的点云压缩框架，通过通用上下文模型和实例自适应微调策略解决了深度学习点云几何压缩中的泛化和OOD数据处理挑战，并在15个数据集上取得了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习点云几何压缩在泛化能力方面存在挑战，主要归因于上下文模型鲁棒性不足和对OOD（分布外）数据的处理效率低下。

Method: AnyPcc框架包括两个主要部分：1. 通用上下文模型：利用空间和通道分组的先验知识来捕捉鲁棒的上下文依赖关系。 2. 实例自适应微调（IAFT）：通过结合显式和隐式压缩范式来处理OOD数据，为每个实例微调一小部分网络权重并将其包含在比特流中。

Result: 在15个多样化的基准数据集上进行的广泛实验表明，AnyPcc在点云压缩方面设定了新的最先进水平。

Conclusion: AnyPcc通过其通用上下文模型和IAFT策略，成功解决了点云压缩中的泛化和OOD数据处理问题，并在多个数据集上取得了优于现有方法的性能。

Abstract: Generalization remains a critical challenge for deep learning-based point
cloud geometry compression. We argue this stems from two key limitations: the
lack of robust context models and the inefficient handling of
out-of-distribution (OOD) data. To address both, we introduce AnyPcc, a
universal point cloud compression framework. AnyPcc first employs a Universal
Context Model that leverages priors from both spatial and channel-wise grouping
to capture robust contextual dependencies. Second, our novel Instance-Adaptive
Fine-Tuning (IAFT) strategy tackles OOD data by synergizing explicit and
implicit compression paradigms. It fine-tunes a small subset of network weights
for each instance and incorporates them into the bitstream, where the marginal
bit cost of the weights is dwarfed by the resulting savings in geometry
compression. Extensive experiments on a benchmark of 15 diverse datasets
confirm that AnyPcc sets a new state-of-the-art in point cloud compression. Our
code and datasets will be released to encourage reproducible research.

</details>


### [51] [AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models](https://arxiv.org/abs/2510.20348)
*Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham*

Main category: cs.CV

TL;DR: AccuQuant是一种新的后训练量化（PTQ）方法，用于扩散模型，它通过最小化量化模型和全精度模型在几个去噪步骤中的差异来解决量化误差累积问题，并将内存复杂度从O(n)降低到O(1)。


<details>
  <summary>Details</summary>
Motivation: 扩散模型中的量化误差会在采样过程的去噪步骤中累积，影响模型性能。

Method: AccuQuant通过显式模拟扩散采样过程中的多个去噪步骤来量化，并最小化量化模型与全精度模型在这些步骤中的输出差异，以缓解误差累积。此外，还提出了一种将内存复杂度从O(n)降低到O(1)的高效实现技术和新目标函数。

Result: AccuQuant在各种任务和扩散模型上展示了其有效性和效率，并在标准基准测试中表现出色。

Conclusion: AccuQuant是一种有效的解决扩散模型量化误差累积问题的方法，并且具有高效的实现。

Abstract: We present in this paper a novel post-training quantization (PTQ) method,
dubbed AccuQuant, for diffusion models. We show analytically and empirically
that quantization errors for diffusion models are accumulated over denoising
steps in a sampling process. To alleviate the error accumulation problem,
AccuQuant minimizes the discrepancies between outputs of a full-precision
diffusion model and its quantized version within a couple of denoising steps.
That is, it simulates multiple denoising steps of a diffusion sampling process
explicitly for quantization, accounting the accumulated errors over multiple
denoising steps, which is in contrast to previous approaches to imitating a
training process of diffusion models, namely, minimizing the discrepancies
independently for each step. We also present an efficient implementation
technique for AccuQuant, together with a novel objective, which reduces a
memory complexity significantly from $\mathcal{O}(n)$ to $\mathcal{O}(1)$,
where $n$ is the number of denoising steps. We demonstrate the efficacy and
efficiency of AccuQuant across various tasks and diffusion models on standard
benchmarks.

</details>


### [52] [Positional Encoding Field](https://arxiv.org/abs/2510.20385)
*Yunpeng Bai,Haoxiang Li,Qixing Huang*

Main category: cs.CV

TL;DR: Diffusion Transformers (DiTs) 在视觉生成领域表现出色，但其核心的Transformer块对图像块的独立性很强，空间一致性主要由位置编码(PE)控制。本文提出位置编码场(PE-Field)，将PE从2D扩展到3D，并引入深度感知和分层编码，使DiT能够直接在3D空间中进行几何建模，在单张图像新视角合成方面达到SOTA，并能进行可控的空间图像编辑。


<details>
  <summary>Details</summary>
Motivation: DiT架构虽然在视觉生成领域表现优异，但我们发现其Transformer块对图像块的独立性很高，空间一致性主要依赖于位置编码。这促使我们探索如何通过扩展位置编码来增强DiT在三维空间中的几何建模能力。

Method: 提出位置编码场(PE-Field)，将DiT的位置编码从2D扩展到3D。PE-Field包含深度感知编码和分层编码，使DiT能够直接在3D空间中进行几何建模。

Result: PE-Field增强的DiT在单张图像新视角合成任务上达到了SOTA性能，并且能够泛化到可控的空间图像编辑任务。

Conclusion: 位置编码场(PE-Field)是一种有效的方法，可以扩展DiT架构在3D空间中的几何建模能力，并在新视角合成和空间图像编辑等任务上取得先进的性能。

Abstract: Diffusion Transformers (DiTs) have emerged as the dominant architecture for
visual generation, powering state-of-the-art image and video models. By
representing images as patch tokens with positional encodings (PEs), DiTs
combine Transformer scalability with spatial and temporal inductive biases. In
this work, we revisit how DiTs organize visual content and discover that patch
tokens exhibit a surprising degree of independence: even when PEs are
perturbed, DiTs still produce globally coherent outputs, indicating that
spatial coherence is primarily governed by PEs. Motivated by this finding, we
introduce the Positional Encoding Field (PE-Field), which extends positional
encodings from the 2D plane to a structured 3D field. PE-Field incorporates
depth-aware encodings for volumetric reasoning and hierarchical encodings for
fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D
space. Our PE-Field-augmented DiT achieves state-of-the-art performance on
single-image novel view synthesis and generalizes to controllable spatial image
editing.

</details>


### [53] [Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval](https://arxiv.org/abs/2510.20393)
*Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的因果方法来解决图像到食谱检索中的模态差异问题，通过预测和注入视觉上不明显的烹饪元素来减轻表示学习中的偏差，从而提高检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像到食谱检索方法假设图像包含食谱的所有细节，但忽略了食物图像仅反映视觉结果而非烹饪过程，导致检索模型偏向于视觉主导元素，难以区分细微差别的食谱。

Method: 提出一种因果方法，预测图像中可能忽略的烹饪元素（如特定食材和烹饪动作），并将这些元素注入到跨模态表示学习中，以减轻偏差。

Result: 在标准单语Recipe1M数据集和新策划的多语言多文化数据集上进行了实验，结果表明该因果表示学习方法能够揭示细微的食材和烹饪动作，并在两个数据集上均取得了优越的检索性能。

Conclusion: 所提出的因果表示学习方法能够有效解决图像到食谱检索中的模态差异问题，并提高了检索的准确性，尤其是在处理细微差别和多语言多文化数据时。

Abstract: Existing approaches for image-to-recipe retrieval have the implicit
assumption that a food image can fully capture the details textually documented
in its recipe. However, a food image only reflects the visual outcome of a
cooked dish and not the underlying cooking process. Consequently, learning
cross-modal representations to bridge the modality gap between images and
recipes tends to ignore subtle, recipe-specific details that are not visually
apparent but are crucial for recipe retrieval. Specifically, the
representations are biased to capture the dominant visual elements, resulting
in difficulty in ranking similar recipes with subtle differences in use of
ingredients and cooking methods. The bias in representation learning is
expected to be more severe when the training data is mixed of images and
recipes sourced from different cuisines. This paper proposes a novel causal
approach that predicts the culinary elements potentially overlooked in images,
while explicitly injecting these elements into cross-modal representation
learning to mitigate biases. Experiments are conducted on the standard
monolingual Recipe1M dataset and a newly curated multilingual multicultural
cuisine dataset. The results indicate that the proposed causal representation
learning is capable of uncovering subtle ingredients and cooking actions and
achieves impressive retrieval performance on both monolingual and multilingual
multicultural datasets.

</details>


### [54] [Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment](https://arxiv.org/abs/2510.20438)
*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

Main category: cs.CV

TL;DR: 本论文提出了一种名为FuzzyDistillViT-MobileNet的新模型，用于肺癌（LC）分类。该模型采用动态模糊逻辑驱动的知识蒸馏（KD）来处理疾病诊断中的不确定性和复杂性。通过动态调整蒸馏权重，学生模型（MobileNet）能更好地关注高置信度区域，同时减少对模糊区域的关注，从而提高处理不同不确定性水平的能力。模型使用ViT-B32作为教师模型，并结合了Gamma校正、直方图均衡化和基于小波的图像融合技术来提升图像质量。遗传算法（GA）用于选择最优的预训练学生模型，以平衡性能和计算成本。在LC25000和IQOTH/NCCD数据集上的评估结果（准确率分别为99.16%和99.54%）表明了该模型在不同影像领域的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决肺癌（LC）诊断中存在的不确定性和复杂性问题。传统的知识蒸馏（KD）方法依赖静态权重，无法有效处理疾病诊断中的不确定性。因此，需要一种能够动态适应不确定性并提高模型泛化能力的方法。

Method: 本研究提出了一种名为FuzzyDistillViT-MobileNet的模型。主要方法包括：1. 动态模糊逻辑驱动的知识蒸馏（KD）：使用模糊逻辑动态调整蒸馏权重，使学生模型（MobileNet）能关注高置信度区域。2. 教师-学生模型：采用Vision Transformer (ViT-B32) 作为教师模型，MobileNet 作为学生模型。3. 图像预处理与融合：采用Gamma校正、直方图均衡化和基于小波的图像融合（使用wavedec2 函数）来提升图像质量和特征表示。4. 计算效率优化：使用遗传算法（GA）从12个候选模型中选择最优的预训练学生模型。5. 动态等待调整机制：优化训练过程以提高收敛性和性能。

Result: 该模型在两个数据集上进行了评估：LC25000（99.16%准确率）和IQOTH/NCCD（99.54%准确率）。结果表明，FuzzyDistillViT-MobileNet在不同影像域（组织病理图像和CT扫描图像）中均表现出高度的准确性和鲁棒性。

Conclusion: FuzzyDistillViT-MobileNet模型通过动态模糊逻辑知识蒸馏、优化的图像处理和模型选择策略，显著提高了肺癌分类的准确性和鲁棒性。该方法能够有效处理诊断中的不确定性，并在不同类型的医学影像数据上取得了优异的性能。

Abstract: This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for
lung cancer (LC) classification, leveraging dynamic fuzzy logic-driven
knowledge distillation (KD) to address uncertainty and complexity in disease
diagnosis. Unlike traditional models that rely on static KD with fixed weights,
our method dynamically adjusts the distillation weight using fuzzy logic,
enabling the student model to focus on high-confidence regions while reducing
attention to ambiguous areas. This dynamic adjustment improves the model
ability to handle varying uncertainty levels across different regions of LC
images. We employ the Vision Transformer (ViT-B32) as the instructor model,
which effectively transfers knowledge to the student model, MobileNet,
enhancing the student generalization capabilities. The training process is
further optimized using a dynamic wait adjustment mechanism that adapts the
training procedure for improved convergence and performance. To enhance image
quality, we introduce pixel-level image fusion improvement techniques such as
Gamma correction and Histogram Equalization. The processed images (Pix1 and
Pix2) are fused using a wavelet-based fusion method to improve image resolution
and feature preservation. This fusion method uses the wavedec2 function to
standardize images to a 224x224 resolution, decompose them into multi-scale
frequency components, and recursively average coefficients at each level for
better feature representation. To address computational efficiency, Genetic
Algorithm (GA) is used to select the most suitable pre-trained student model
from a pool of 12 candidates, balancing model performance with computational
cost. The model is evaluated on two datasets, including LC25000
histopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images
(99.54% accuracy), demonstrating robustness across different imaging domains.

</details>


### [55] [Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence](https://arxiv.org/abs/2510.20470)
*Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun*

Main category: cs.CV

TL;DR: Conan是一个视频推理框架，通过结合视觉证据和多步推理来解决多模态大语言模型在视频推理中的挑战。它引入了一个名为Conan-91K的新数据集，并采用AIR（Identification-Reasoning-Action）强化学习框架进行训练，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理需要跨帧进行多步推理的视频推理任务时面临挑战，现有的方法要么依赖于缺乏视觉基础的文本链，要么在证据定位方面存在不准确性。

Method: Conan框架通过识别上下文和证据帧，对跨帧线索进行推理，并自适应地决定何时得出结论或进一步探索。具体来说，它包含一个名为Conan-91K的大规模数据集，以及一个多阶段渐进式冷启动策略和Identification-Reasoning-Action（AIR）强化学习训练框架。

Result: Conan在六个多步推理基准测试中，平均准确率比基线模型Qwen2.5-VL-7B-Instruct提高了10%以上，达到了最先进的性能。此外，Conan还能有效泛化到长视频理解任务，证明了其良好的可扩展性和鲁棒性。

Conclusion: Conan框架通过引入视觉证据和改进的训练策略，显著提高了多模态大语言模型在视频推理任务上的表现，并在多个基准测试和长视频理解任务中展现了优越的性能和泛化能力。

Abstract: Video reasoning, which requires multi-step deduction across frames, remains a
major challenge for multimodal large language models (MLLMs). While
reinforcement learning (RL)-based methods enhance reasoning capabilities, they
often rely on text-only chains that yield ungrounded or hallucinated
conclusions. Conversely, frame-retrieval approaches introduce visual grounding
but still struggle with inaccurate evidence localization. To address these
challenges, we present Conan, a framework for evidence-grounded multi-step
video reasoning. Conan identifies contextual and evidence frames, reasons over
cross-frame clues, and adaptively decides when to conclude or explore further.
To achieve this, we (1) construct Conan-91K, a large-scale dataset of
automatically generated reasoning traces that includes frame identification,
evidence reasoning, and action decision, and (2) design a multi-stage
progressive cold-start strategy combined with an
Identification-Reasoning-Action (AIR) RLVR training framework to jointly
enhance multi-step visual reasoning. Extensive experiments on six multi-step
reasoning benchmarks demonstrate that Conan surpasses the baseline
Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving
state-of-the-art performance. Furthermore, Conan generalizes effectively to
long-video understanding tasks, validating its strong scalability and
robustness.

</details>


### [56] [Reliable and Reproducible Demographic Inference for Fairness in Face Analysis](https://arxiv.org/abs/2510.20482)
*Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison*

Main category: cs.CV

TL;DR: 评估面部分析系统（FAS）的公平性依赖于自动人口属性推断（DAI），而DAI的可靠性对公平性审计至关重要。本文提出了一个模块化的迁移学习DAI流程，并通过准确性、公平性和鲁棒性（新提出的概念）对其进行了评估，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 公平性审计的有效性依赖于人口属性推断（DAI）的可靠性。提高DAI的可靠性可以降低FAS公平性评估的偏差和方差。

Method: 采用模块化的迁移学习方法，将预训练的人脸识别编码器与非线性分类头相结合，取代传统端到端训练。

Result: 所提出的DAI流程在准确性、公平性和鲁棒性方面表现优于现有基线方法，尤其在更具挑战性的种族推断方面。

Conclusion: 提出了一种可靠的DAI流程，为公平性审计提供了一个可靠的基础，并将公开相关数据、代码和模型以促进透明度和可复现性。

Abstract: Fairness evaluation in face analysis systems (FAS) typically depends on
automatic demographic attribute inference (DAI), which itself relies on
predefined demographic segmentation. However, the validity of fairness auditing
hinges on the reliability of the DAI process. We begin by providing a
theoretical motivation for this dependency, showing that improved DAI
reliability leads to less biased and lower-variance estimates of FAS fairness.
To address this, we propose a fully reproducible DAI pipeline that replaces
conventional end-to-end training with a modular transfer learning approach. Our
design integrates pretrained face recognition encoders with non-linear
classification heads. We audit this pipeline across three dimensions: accuracy,
fairness, and a newly introduced notion of robustness, defined via
intra-identity consistency. The proposed robustness metric is applicable to any
demographic segmentation scheme. We benchmark the pipeline on gender and
ethnicity inference across multiple datasets and training setups. Our results
show that the proposed method outperforms strong baselines, particularly on
ethnicity, which is the more challenging attribute. To promote transparency and
reproducibility, we will publicly release the training dataset metadata, full
codebase, pretrained models, and evaluation toolkit. This work contributes a
reliable foundation for demographic inference in fairness auditing.

</details>


### [57] [EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization](https://arxiv.org/abs/2510.20512)
*Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang*

Main category: cs.CV

TL;DR: EchoDistill框架实现了文生图模型的单步个性化，通过学生-老师模型双向知识蒸馏，提高了新概念的捕捉和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的一步文生图模型在捕捉新概念分布方面能力有限，难以实现有效的个性化。为解决此问题，提出EchoDistill框架，旨在实现一步扩散模型个性化（1-SDP）。

Method: EchoDistill采用端到端训练方式，同时训练多步扩散模型（教师）和一步扩散模型（学生）。知识从教师蒸馏到学生，再从学生回传至教师。训练过程中共享文本编码器以保证语义一致性，学生模型通过对抗性损失和对齐损失进行优化。提出双向回声细化策略，利用学生模型的快速生成能力反馈给教师模型。

Result: 实验表明，该框架在1-SDP设置下显著优于现有的个性化方法，建立了快速有效进行文生图模型个性化的新范例。

Conclusion: EchoDistill框架通过双向概念蒸馏，不仅增强了一步模型个性化新概念的能力，还提升了教师模型的生成质量，为文生图模型的快速个性化提供了新的有效途径。

Abstract: Recent advances in accelerating text-to-image (T2I) diffusion models have
enabled the synthesis of high-fidelity images even in a single step. However,
personalizing these models to incorporate novel concepts remains a challenge
due to the limited capacity of one-step models to capture new concept
distributions effectively. We propose a bidirectional concept distillation
framework, EchoDistill, to enable one-step diffusion personalization (1-SDP).
Our approach involves an end-to-end training process where a multi-step
diffusion model (teacher) and a one-step diffusion model (student) are trained
simultaneously. The concept is first distilled from the teacher model to the
student, and then echoed back from the student to the teacher. During the
EchoDistill, we share the text encoder between the two models to ensure
consistent semantic understanding. Following this, the student model is
optimized with adversarial losses to align with the real image distribution and
with alignment losses to maintain consistency with the teacher's output.
Furthermore, we introduce the bidirectional echoing refinement strategy,
wherein the student model leverages its faster generation capability to
feedback to the teacher model. This bidirectional concept distillation
mechanism not only enhances the student ability to personalize novel concepts
but also improves the generative quality of the teacher model. Our experiments
demonstrate that this collaborative framework significantly outperforms
existing personalization methods over the 1-SDP setup, establishing a novel
paradigm for rapid and effective personalization in T2I diffusion models.

</details>


### [58] [Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning](https://arxiv.org/abs/2510.20519)
*Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma*

Main category: cs.CV

TL;DR: Metis-HOME通过混合专家模型（MoE）解决多模态大模型（MLLM）在复杂推理和通用能力之间的权衡问题，实现了推理效率和能力的双重提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在处理复杂推理任务时效率低下，并且过度关注推理能力损害了其通用理解能力。

Method: 提出Metis-HOME框架，将模型拆分为推理（thinking）和非推理（non-thinking）两个专家分支，并使用轻量级路由器动态分配任务。

Result: 在复杂推理任务上显著提升能力，同时改善了模型的通用能力，解决了推理与泛化能力之间的矛盾。

Conclusion: Metis-HOME建立了构建强大且通用的MLLM的新范式，有效解决了推理与泛化能力的权衡问题。

Abstract: Inspired by recent advancements in LLM reasoning, the field of multimodal
reasoning has seen remarkable progress, achieving significant performance gains
on intricate tasks such as mathematical problem-solving. Despite this progress,
current multimodal large reasoning models exhibit two key limitations. They
tend to employ computationally expensive reasoning even for simple queries,
leading to inefficiency. Furthermore, this focus on specialized reasoning often
impairs their broader, more general understanding capabilities. In this paper,
we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed
to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by
structuring the original dense model into two distinct expert branches: a
thinking branch tailored for complex, multi-step reasoning, and a non-thinking
branch optimized for rapid, direct inference on tasks like general VQA and OCR.
A lightweight, trainable router dynamically allocates queries to the most
suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into
an MoE architecture. Comprehensive evaluations reveal that our approach not
only substantially enhances complex reasoning abilities but also improves the
model's general capabilities, reversing the degradation trend observed in other
reasoning-specialized models. Our work establishes a new paradigm for building
powerful and versatile MLLMs, effectively resolving the prevalent
reasoning-vs-generalization dilemma.

</details>


### [59] [Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis](https://arxiv.org/abs/2510.20531)
*Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu*

Main category: cs.CV

TL;DR: 提出FiFa框架，用于细粒度的可解释深度伪造分析，解决了现有模型对视觉上下文理解不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度感知方面存在不足，无法提供连接文本解释与视觉证据的输出，也无法支持对任意面部区域的查询，导致响应不够依赖面部视觉上下文。

Method: 提出FiFa框架，包含FiFa-Annotator（基于面部图像概念树FICT进行细粒度区域概念划分，以实现更可靠的伪造解释标注）和FiFa-MLLM（统一的多任务学习架构，支持丰富的多模态输入和输出，并引入了生成交织有操纵伪影分割掩码的文本伪造解释的“伪影接地解释”AGE任务）。

Result: FiFa-MLLM在AGE任务上表现优于强基线模型，并在现有的XDFA数据集上取得了SOTA性能。

Conclusion: FiFa框架通过FiFa-Annotator和FiFa-MLLM，实现了细粒度的可解释深度伪造分析，能够生成与视觉证据紧密结合的解释，并支持对任意面部区域的查询。

Abstract: The advancement of Multimodal Large Language Models (MLLMs) has bridged the
gap between vision and language tasks, enabling the implementation of
Explainable DeepFake Analysis (XDFA). However, current methods suffer from a
lack of fine-grained awareness: the description of artifacts in data annotation
is unreliable and coarse-grained, and the models fail to support the output of
connections between textual forgery explanations and the visual evidence of
artifacts, as well as the input of queries for arbitrary facial regions. As a
result, their responses are not sufficiently grounded in Face Visual Context
(Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)
framework, with contributions focusing on data annotation and model
construction. We first define a Facial Image Concept Tree (FICT) to divide
facial images into fine-grained regional concepts, thereby obtaining a more
reliable data annotation pipeline, FiFa-Annotator, for forgery explanation.
Based on this dedicated data annotation, we introduce a novel
Artifact-Grounding Explanation (AGE) task, which generates textual forgery
explanations interleaved with segmentation masks of manipulated artifacts. We
propose a unified multi-task learning architecture, FiFa-MLLM, to
simultaneously support abundant multimodal inputs and outputs for fine-grained
Explainable DeepFake Analysis. With multiple auxiliary supervision tasks,
FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA
performance on existing XDFA datasets. The code and data will be made
open-source at https://github.com/lxq1000/Fake-in-Facext.

</details>


### [60] [Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image](https://arxiv.org/abs/2510.20539)
*Guillermo Carbajal,Andrés Almansa,Pablo Musé*

Main category: cs.CV

TL;DR: 提出一种深度学习框架，从单张模糊图像中联合估计潜在清晰图像和相机运动轨迹，以解决运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 运动模糊（尤其由大幅度或旋转运动引起）是图像复原中的主要挑战。

Method: 利用射影运动模糊模型（PMBM），通过可微分模糊创建模块高效实现，并与现代网络兼容。神经网络预测完整的3D旋转轨迹，指导基于模型的复原网络进行端到端训练。该框架通过揭示产生模糊的相机运动来提供可解释性，并能重构生成模糊输入的清晰图像序列。此外，通过再模糊损失进行后处理优化，提高模糊输入和复原输出之间的一致性。

Result: 在合成和真实数据集上均达到最先进的性能，尤其在端到端去模糊网络难以处理的严重或空间变异模糊情况下表现出色。

Conclusion: 所提出的方法能够有效处理运动模糊问题，并在各种模糊情况下提供高质量的图像复原和相机运动轨迹估计。

Abstract: Motion blur caused by camera shake, particularly under large or rotational
movements, remains a major challenge in image restoration. We propose a deep
learning framework that jointly estimates the latent sharp image and the
underlying camera motion trajectory from a single blurry image. Our method
leverages the Projective Motion Blur Model (PMBM), implemented efficiently
using a differentiable blur creation module compatible with modern networks. A
neural network predicts a full 3D rotation trajectory, which guides a
model-based restoration network trained end-to-end. This modular architecture
provides interpretability by revealing the camera motion that produced the
blur. Moreover, this trajectory enables the reconstruction of the sequence of
sharp images that generated the observed blurry image. To further refine
results, we optimize the trajectory post-inference via a reblur loss, improving
consistency between the blurry input and the restored output. Extensive
experiments show that our method achieves state-of-the-art performance on both
synthetic and real datasets, particularly in cases with severe or spatially
variant blur, where end-to-end deblurring networks struggle.
  Code and trained models are available at
https://github.com/GuillermoCarbajal/Blur2Seq/

</details>


### [61] [From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging](https://arxiv.org/abs/2510.20550)
*Fuchen Li,Yansong Du,Wenbo Cheng,Xiaoxia Zhou,Sen Yin*

Main category: cs.CV

TL;DR: ACamera-Net是一个轻量级的、场景自适应的相机参数调整网络，可直接从RAW输入预测最佳曝光和白平衡，以解决复杂光照条件下的图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 消费级相机系统在复杂光照条件下（如弱光、高动态范围、背光和空间色温变化）难以保持稳定的图像质量，导致欠曝、色偏和色调不一致，从而影响下游视觉任务的性能。

Method: 提出ACamera-Net，一个包含ACamera-Exposure（用于估计ISO以减轻欠曝和对比度损失）和ACamera-Color（用于预测相关色温和增益因子以提高色彩一致性）两个模块的网络。该网络针对边缘设备上的实时推理进行了优化，并可无缝集成到成像流程中。在带有注释参考的真实世界数据集上进行训练，使其能够很好地适应各种光照条件。

Result: 实验证明，ACamera-Net能够持续提高图像质量并稳定感知输出，其表现优于传统的自动模式和轻量级基线模型，并且无需额外的图像增强模块。

Conclusion: ACamera-Net通过直接从RAW输入预测曝光和白平衡参数，有效解决了消费级相机在复杂光照条件下图像质量不佳的问题，并在各种场景下展现出优越的性能。

Abstract: Consumer-grade camera systems often struggle to maintain stable image quality
under complex illumination conditions such as low light, high dynamic range,
and backlighting, as well as spatial color temperature variation. These issues
lead to underexposure, color casts, and tonal inconsistency, which degrade the
performance of downstream vision tasks. To address this, we propose
ACamera-Net, a lightweight and scene-adaptive camera parameter adjustment
network that directly predicts optimal exposure and white balance from RAW
inputs. The framework consists of two modules: ACamera-Exposure, which
estimates ISO to alleviate underexposure and contrast loss, and ACamera-Color,
which predicts correlated color temperature and gain factors for improved color
consistency. Optimized for real-time inference on edge devices, ACamera-Net can
be seamlessly integrated into imaging pipelines. Trained on diverse real-world
data with annotated references, the model generalizes well across lighting
conditions. Extensive experiments demonstrate that ACamera-Net consistently
enhances image quality and stabilizes perception outputs, outperforming
conventional auto modes and lightweight baselines without relying on additional
image enhancement modules.

</details>


### [62] [Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence](https://arxiv.org/abs/2510.20579)
*Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang*

Main category: cs.CV

TL;DR: Open-o3 Video框架通过整合时空证据来提升视频推理能力，并在V-STAR等基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频推理模型主要生成文本推理，缺乏对关键证据时空位置的指示，难以像图像推理那样以证据为中心。视频推理需要同时处理动态场景中的时间跟踪和空间定位。

Method: 提出Open-o3 Video框架，整合显式时空证据到视频推理中。构建了包含时空标注的STGR-CoT-30k和STGR-RL-36k数据集。采用冷启动强化学习策略，结合奖励函数，共同优化答案准确性、时间对齐和空间精确度。

Result: 在V-STAR基准测试上，Open-o3 Video在Qwen2.5-VL基线上分别提升了mAM 14.4%和mLGM 24.2%。在VideoMME、WorldSense、VideoMMMU和TVGBench等多个视频理解基准测试中也观察到了一致的性能提升。

Conclusion: Open-o3 Video不仅在准确性上表现优异，其生成的推理轨迹还能提供有价值的测试时可解释性信号，实现置信度感知验证，提高答案的可靠性。

Abstract: Most video reasoning models only generate textual reasoning traces without
indicating when and where key evidence appears. Recent models such as OpenAI-o3
have sparked wide interest in evidence-centered reasoning for images, yet
extending this ability to videos is more challenging, as it requires joint
temporal tracking and spatial localization across dynamic scenes. We introduce
Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal
evidence into video reasoning, and carefully collect training data and design
training strategies to address the aforementioned challenges. The model
highlights key timestamps, objects, and bounding boxes alongside its answers,
allowing reasoning to be grounded in concrete visual observations. To enable
this functionality, we first curate and build two high-quality datasets,
STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed
temporal and spatial annotations, since most existing datasets offer either
temporal spans for videos or spatial boxes on images, lacking unified
spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start
reinforcement learning strategy with multiple specially designed rewards that
jointly encourage answer accuracy, temporal alignment, and spatial precision.
On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,
raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent
improvements are also observed on a broad range of video understanding
benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond
accuracy, the reasoning traces produced by Open-o3 Video also provide valuable
signals for test-time scaling, enabling confidence-aware verification and
improving answer reliability.

</details>


### [63] [GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models](https://arxiv.org/abs/2510.20586)
*Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang*

Main category: cs.CV

TL;DR: GenColorBench 是首个针对文本到图像颜色生成的基准，旨在解决当前模型在颜色可控性方面的不足，并通过包含数值颜色在内的更全面的评估来改进模型。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在颜色可控性方面存在不足，现有基准未能系统评估颜色精度，而颜色对于视觉感知和应用（如品牌一致性）至关重要。

Method: 提出 GenColorBench，一个包含 44K 颜色相关提示和 400 多种颜色的基准，支持 ISCC-NBS 和 CSS3/X11 等颜色系统，并纳入了数值颜色。

Result: 使用 GenColorBench 评估了现有的文本到图像模型，揭示了模型在理解不同颜色约定和失败模式方面的差异。

Conclusion: GenColorBench 基准将有助于改进文本到图像模型中的颜色生成能力，并将公开提供。

Abstract: Recent years have seen impressive advances in text-to-image generation, with
image generative or unified models producing high-quality images from text. Yet
these models still struggle with fine-grained color controllability, often
failing to accurately match colors specified in text prompts. While existing
benchmarks evaluate compositional reasoning and prompt adherence, none
systematically assess color precision. Color is fundamental to human visual
perception and communication, critical for applications from art to design
workflows requiring brand consistency. However, current benchmarks either
neglect color or rely on coarse assessments, missing key capabilities such as
interpreting RGB values or aligning with human expectations. To this end, we
propose GenColorBench, the first comprehensive benchmark for text-to-image
color generation, grounded in color systems like ISCC-NBS and CSS3/X11,
including numerical colors which are absent elsewhere. With 44K color-focused
prompts covering 400+ colors, it reveals models' true capabilities via
perceptual and automated assessments. Evaluations of popular text-to-image
models using GenColorBench show performance variations, highlighting which
color conventions models understand best and identifying failure modes. Our
GenColorBench assessments will guide improvements in precise color generation.
The benchmark will be made public upon acceptance.

</details>


### [64] [Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation](https://arxiv.org/abs/2510.20596)
*Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: 通过基于相似性的原型进行跨模态分割，以解决深度学习模型在面对未见数据时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在不同领域之间存在域偏移问题，导致在未见过的数据上性能下降，而无监督域适应可以通过减少域间隙来解决此问题，避免昂贵的标注。

Method: 学习嵌入空间中的类别原型，并引入相似性约束来保证原型的代表性和可分离性。使用字典存储来自不同图像的原型，以解决类别缺失问题并进行对比学习。

Result: 实验证明，该方法优于其他最先进的方法。

Conclusion: 所提出的基于相似性原型的框架在跨模态分割方面取得了优于现有方法的成果。

Abstract: Deep learning models have achieved great success on various vision
challenges, but a well-trained model would face drastic performance degradation
when applied to unseen data. Since the model is sensitive to domain shift,
unsupervised domain adaptation attempts to reduce the domain gap and avoid
costly annotation of unseen domains. This paper proposes a novel framework for
cross-modality segmentation via similarity-based prototypes. In specific, we
learn class-wise prototypes within an embedding space, then introduce a
similarity constraint to make these prototypes representative for each semantic
class while separable from different classes. Moreover, we use dictionaries to
store prototypes extracted from different images, which prevents the
class-missing problem and enables the contrastive learning of prototypes, and
further improves performance. Extensive experiments show that our method
achieves better results than other state-of-the-art methods.

</details>


### [65] [OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects](https://arxiv.org/abs/2510.20605)
*Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh*

Main category: cs.CV

TL;DR: OnlineSplatter是一个新颖的在线前馈框架，可以直接从RGB帧生成高质量、以物体为中心的3D高斯，无需相机位姿、深度先验或捆绑优化。


<details>
  <summary>Details</summary>
Motivation: 从单目视频中重建自由移动的物体仍然是一个挑战，特别是在没有可靠位姿或深度线索且物体运动任意的情况下。

Method: 该方法将重建锚定在第一帧，并通过密集的、保持恒定计算成本的高斯原始场逐步完善物体表示。其核心贡献是一个双键内存模块，结合了潜在的外观-几何键和显式的方向键，鲁棒地融合了当前帧特征和时间聚合的物体状态。该设计通过空间引导的内存读出和有效的稀疏化机制，能够有效处理自由移动的物体。

Result: 在真实世界数据集上的评估表明，OnlineSplatter的性能显著优于最先进的无位姿重建基线，并且随着观测次数的增加持续改进，同时保持恒定的内存和运行时间。

Conclusion: OnlineSplatter能够持续优化物体表示，并在没有相机位姿或深度先验的情况下，在任意物体运动下进行鲁棒的自由移动物体重建。

Abstract: Free-moving object reconstruction from monocular video remains challenging,
particularly without reliable pose or depth cues and under arbitrary object
motion. We introduce OnlineSplatter, a novel online feed-forward framework
generating high-quality, object-centric 3D Gaussians directly from RGB frames
without requiring camera pose, depth priors, or bundle optimization. Our
approach anchors reconstruction using the first frame and progressively refines
the object representation through a dense Gaussian primitive field, maintaining
constant computational cost regardless of video sequence length. Our core
contribution is a dual-key memory module combining latent appearance-geometry
keys with explicit directional keys, robustly fusing current frame features
with temporally aggregated object states. This design enables effective
handling of free-moving objects via spatial-guided memory readout and an
efficient sparsification mechanism, ensuring comprehensive yet compact object
coverage. Evaluations on real-world datasets demonstrate that OnlineSplatter
significantly outperforms state-of-the-art pose-free reconstruction baselines,
consistently improving with more observations while maintaining constant memory
and runtime.

</details>


### [66] [SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding](https://arxiv.org/abs/2510.20622)
*Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Long video understanding remains challenging due to its complex, diverse, and
temporally scattered content. Although video large language models (Video-LLMs)
can process videos lasting tens of minutes, applying them to truly long
sequences is computationally prohibitive and often leads to unfocused or
inconsistent reasoning. A promising solution is to select only the most
informative frames, yet existing approaches typically ignore temporal
dependencies or rely on unimodal evidence, limiting their ability to provide
complete and query-relevant context. We propose a Semantic-Visual Consensus
Evidence Selection (SeViCES) framework for effective and reliable long video
understanding. SeViCES is training-free and model-agnostic, and introduces two
key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module
selects frames through (1) a temporal-aware semantic branch that leverages LLM
reasoning over captions, and (2) a cluster-guided visual branch that aligns
embeddings with semantic scores via mutual information. The Answer Consensus
Refinement (ACR) module further resolves inconsistencies between semantic- and
visual-based predictions by fusing evidence and constraining the answer space.
Extensive experiments on long video understanding benchmarks show that SeViCES
consistently outperforms state-of-the-art methods in both accuracy and
robustness, demonstrating the importance of consensus-driven evidence selection
for Video-LLMs.

</details>


### [67] [Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges](https://arxiv.org/abs/2510.20634)
*Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li*

Main category: cs.CV

TL;DR: 该综述系统地总结了深度学习在牙科影像分析（DIA）领域的最新进展，重点关注数据集和模型两方面，共纳入260篇研究，旨在为该领域的研究人员提供系统性参考。


<details>
  <summary>Details</summary>
Motivation: 牙科影像分析对于准确诊断和治疗规划至关重要，但手动解释面临图像质量差、主观性强等挑战。基于人工智能（AI）的自动化DIA是潜在解决方案，而深度学习（DL）因其强大的特征提取能力而成为最广泛应用的方法。

Method: 系统性回顾了260篇关于DL在DIA中应用的研究，包括49篇关于公开牙科数据集的论文和211篇关于DL模型的论文。论文首先介绍了牙科影像学基本概念和数据集特点，然后总结了DL基础技术，并根据不同DIA任务对相关模型和算法进行了分类，分析了它们的网络结构、优化策略、训练方法和性能。此外，还总结了常用的训练和评估指标。

Result: 该研究共纳入260篇相关论文，详细分析了现有牙科数据集和各种DL模型在DIA任务中的应用情况，并总结了常用的评估指标。

Conclusion: 该综述系统地梳理了深度学习在牙科影像分析领域的现状，讨论了当前研究面临的挑战，并指出了未来的潜在研究方向，为该领域的研究人员提供了有价值的参考。

Abstract: Efficient analysis and processing of dental images are crucial for dentists
to achieve accurate diagnosis and optimal treatment planning. However, dental
imaging inherently poses several challenges, such as low contrast, metallic
artifacts, and variations in projection angles. Combined with the subjectivity
arising from differences in clinicians' expertise, manual interpretation often
proves time-consuming and prone to inconsistency. Artificial intelligence
(AI)-based automated dental image analysis (DIA) offers a promising solution to
these issues and has become an integral part of computer-aided dental diagnosis
and treatment. Among various AI technologies, deep learning (DL) stands out as
the most widely applied and influential approach due to its superior feature
extraction and representation capabilities. To comprehensively summarize recent
progress in this field, we focus on the two fundamental aspects of DL
research-datasets and models. In this paper, we systematically review 260
studies on DL applications in DIA, including 49 papers on publicly available
dental datasets and 211 papers on DL-based algorithms. We first introduce the
basic concepts of dental imaging and summarize the characteristics and
acquisition methods of existing datasets. Then, we present the foundational
techniques of DL and categorize relevant models and algorithms according to
different DIA tasks, analyzing their network architectures, optimization
strategies, training methods, and performance. Furthermore, we summarize
commonly used training and evaluation metrics in the DIA domain. Finally, we
discuss the current challenges of existing research and outline potential
future directions. We hope that this work provides a valuable and systematic
reference for researchers in this field. All supplementary materials and
detailed comparison tables will be made publicly available on GitHub.

</details>


### [68] [Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging](https://arxiv.org/abs/2510.20639)
*Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze*

Main category: cs.CV

TL;DR: BTB3D是一种用于3D医学影像的视觉-语言模型，它通过创新的分词方法解决了高分辨率、长序列成像的挑战，并在报告生成和文本到CT合成方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理高分辨率、长序列的3D医学影像时存在困难，主要体现在视觉编码器与临床语言不匹配以及切片式分词模糊精细解剖结构，影响下游任务的诊断性能。

Method: 提出了一种名为BTB3D的因果卷积编码器-解码器模型，该模型统一了2D和3D的训练与推理，并生成紧凑、感知频率的体积标记。通过一个三阶段的训练课程（局部重建、重叠窗口平铺、长上下文解码器精炼），模型能够从短切片片段中学习，并泛化到超过300个切片的扫描，而无需额外的内存开销。

Result: 在报告生成任务上，BTB3D将BLEU分数提高，并将临床F1分数提高了40%；在文本到CT合成任务上，与生成模型相比，BTB3D将FID降低了75%，FVD减半，并能够生成解剖结构一致的512*512*241体积。

Conclusion: 精确的三维分词对于3D医学影像中可扩展的视觉-语言建模至关重要，而不是仅仅依赖于更大的语言主干。

Abstract: Recent progress in vision-language modeling for 3D medical imaging has been
fueled by large-scale computed tomography (CT) corpora with paired free-text
reports, stronger architectures, and powerful pretrained models. This has
enabled applications such as automated report generation and text-conditioned
3D image synthesis. Yet, current approaches struggle with high-resolution,
long-sequence volumes: contrastive pretraining often yields vision encoders
that are misaligned with clinical language, and slice-wise tokenization blurs
fine anatomy, reducing diagnostic performance on downstream tasks. We introduce
BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder
that unifies 2D and 3D training and inference while producing compact,
frequency-aware volumetric tokens. A three-stage training curriculum enables
(i) local reconstruction, (ii) overlapping-window tiling, and (iii)
long-context decoder refinement, during which the model learns from short slice
excerpts yet generalizes to scans exceeding 300 slices without additional
memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it
improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and
Merlin for report generation; and it reduces FID by 75% and halves FVD compared
to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically
consistent 512*512*241 volumes. These results confirm that precise
three-dimensional tokenization, rather than larger language backbones alone, is
essential for scalable vision-language modeling in 3D medical imaging. The
codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D

</details>


### [69] [UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset](https://arxiv.org/abs/2510.20661)
*Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 本文提出了UltraHR-100K数据集和一种新的文本到图像生成方法，以解决超高分辨率（UHR）图像生成中的数据集缺乏和细节合成训练策略不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的超高分辨率（UHR）文本到图像（T2I）生成技术面临两大挑战：缺乏大规模高质量的UHR T2I数据集，以及在UHR场景下缺乏针对细粒度细节合成的专门训练策略。

Method: 本文引入了UltraHR-100K数据集，包含10万张高分辨率图像和详细的描述。此外，提出了一种名为“频率感知后训练”的方法，该方法包含“面向细节的时间步长采样（DOTS）”和“软权重频率正则化（SWFR）”两个关键技术，以增强T2I模型在细节合成方面的能力。

Result: 所提出的方法在UltraHR-eval4K基准测试上显著提高了UHR图像生成的细节质量和整体保真度。

Conclusion: 通过引入UltraHR-100K数据集和创新的频率感知后训练方法，本文有效解决了UHR T2I生成中的关键挑战，提升了生成图像的细节和质量。

Abstract: Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable
progress. However, two key challenges remain : 1) the absence of a large-scale
high-quality UHR T2I dataset, and (2) the neglect of tailored training
strategies for fine-grained detail synthesis in UHR scenarios. To tackle the
first challenge, we introduce \textbf{UltraHR-100K}, a high-quality dataset of
100K UHR images with rich captions, offering diverse content and strong visual
fidelity. Each image exceeds 3K resolution and is rigorously curated based on
detail richness, content complexity, and aesthetic quality. To tackle the
second challenge, we propose a frequency-aware post-training method that
enhances fine-detail generation in T2I diffusion models. Specifically, we
design (i) \textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning
on detail-critical denoising steps, and (ii) \textit{Soft-Weighting Frequency
Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to
softly constrain frequency components, encouraging high-frequency detail
preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks
demonstrate that our approach significantly improves the fine-grained detail
quality and overall fidelity of UHR image generation. The code is available at
\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.

</details>


### [70] [HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification](https://arxiv.org/abs/2510.20669)
*Debojyoti Ghosh,Adrijit Goswami*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HybridSOMSpikeNet的混合深度学习框架，通过结合卷积特征提取、可微分自组织和脉冲启发式时间处理，实现了高效且节能的垃圾分类。


<details>
  <summary>Details</summary>
Motivation: 准确的垃圾分类对于可持续的废物管理和减少城市化的环境足迹至关重要，错误的分类会导致垃圾填埋、回收效率低下和温室气体排放增加。

Method: 该模型使用预训练的ResNet-152主干提取空间特征，然后使用可微分的软自组织映射（Soft-SOM）进行聚类和增强可解释性，最后通过脉冲神经网络头部在离散时间步长上累积时间激活，以提高鲁棒性和泛化能力。

Result: 在包含十类垃圾的数据集上训练的HybridSOMSpikeNet在测试集上达到了97.39%的准确率，优于几种先进模型，同时保持了适合实际部署的轻量级计算特征。

Conclusion: HybridSOMSpikeNet通过精确和自动化的垃圾分类，提高了回收效率，减少了可回收物流中的污染物，并降低了废物处理的生态和运营成本，符合联合国可持续发展目标11和12，有助于建设更清洁的城市、推动循环经济和智能环境管理。

Abstract: Accurate waste classification is vital for achieving sustainable waste
management and reducing the environmental footprint of urbanization.
Misclassification of recyclable materials contributes to landfill accumulation,
inefficient recycling, and increased greenhouse gas emissions. To address these
issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning
framework that integrates convolutional feature extraction, differentiable
self-organization, and spiking-inspired temporal processing to enable
intelligent and energy-efficient waste classification. The proposed model
employs a pre-trained ResNet-152 backbone to extract deep spatial
representations, followed by a Differentiable Soft Self-Organizing Map
(Soft-SOM) that enhances topological clustering and interpretability. A spiking
neural head accumulates temporal activations over discrete time steps,
improving robustness and generalization. Trained on a ten-class waste dataset,
HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several
state-of-the-art architectures while maintaining a lightweight computational
profile suitable for real-world deployment. Beyond its technical innovations,
the framework provides tangible environmental benefits. By enabling precise and
automated waste segregation, it supports higher recycling efficiency, reduces
contamination in recyclable streams, and minimizes the ecological and
operational costs of waste processing. The approach aligns with global
sustainability priorities, particularly the United Nations Sustainable
Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities,
circular economy initiatives, and intelligent environmental management systems.

</details>


### [71] [Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling](https://arxiv.org/abs/2510.20673)
*Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为EMQNet的方法，通过权重偏置校正和比特级核心集采样策略，显著降低了多比特量化网络的训练开销，同时保持了模型的准确性，并提供了高达7.88倍的训练加速。


<details>
  <summary>Details</summary>
Motivation: 现有的多比特量化网络虽然支持模型内多种精度，但存在显著的训练开销和额外的微调需求。本文旨在解决这些问题，减少训练开销，同时不损害模型性能。

Method: 提出两种技术：(i) 权重偏置校正，通过共享批量归一化并消除量化引起的偏差来对齐激活分布，从而无需微调；(ii) 比特级核心集采样策略，利用梯度重要性得分选择一个紧凑的子集进行训练，以实现知识转移。

Result: 在CIFAR-10/100、TinyImageNet和ImageNet-1K数据集上，使用ResNet和ViT架构进行实验，结果表明该方法在保持准确性的同时，训练时间最多可缩短7.88倍。

Conclusion: 所提出的EMQNet方法通过权重偏置校正和比特级核心集采样，有效降低了多比特量化网络的训练成本，并取得了具有竞争力的准确性，证明了其在实际应用中的可行性。

Abstract: Multi-bit quantization networks enable flexible deployment of deep neural
networks by supporting multiple precision levels within a single model.
However, existing approaches suffer from significant training overhead as
full-dataset updates are repeated for each supported bit-width, resulting in a
cost that scales linearly with the number of precisions. Additionally, extra
fine-tuning stages are often required to support additional or intermediate
precision options, further compounding the overall training burden. To address
this issue, we propose two techniques that greatly reduce the training overhead
without compromising model utility: (i) Weight bias correction enables shared
batch normalization and eliminates the need for fine-tuning by neutralizing
quantization-induced bias across bit-widths and aligning activation
distributions; and (ii) Bit-wise coreset sampling strategy allows each child
model to train on a compact, informative subset selected via gradient-based
importance scores by exploiting the implicit knowledge transfer phenomenon.
Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and
ViT architectures demonstrate that our method achieves competitive or superior
accuracy while reducing training time up to 7.88x. Our code is released at
https://github.com/a2jinhee/EMQNet_jk.

</details>


### [72] [Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward](https://arxiv.org/abs/2510.20696)
*Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu*

Main category: cs.CV

TL;DR: MLLMs 存在视觉幻觉和过度依赖文本先验的问题。本研究提出了一个基于智能体的架构，结合了 LLM 推理和轻量级视觉模块，以解决这些问题并提高视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理复杂视觉任务时，虽然利用了思维链（CoT）提示，但仍然存在视觉幻觉和过度依赖文本先验的问题。

Method: 提出了一种基于智能体的架构，该架构结合了 LLM 推理和轻量级视觉模块，能够对推理链进行细粒度分析和迭代优化。该研究还提出了一个三阶段的评估框架来诊断现有模型。

Result: 提出的系统在 MMMU 和 MathVista 数据集上取得了显著的性能提升（分别提高 10.3% 和 6.0%），并且性能超过了许多更大的模型。

Conclusion: 未来的视觉推理模型应专注于整合更广泛的专业化工具来分析视觉内容。研究团队将发布框架和评估套件以促进未来研究。

Abstract: Multimodal large language models (MLLMs) that integrate visual and textual
reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual
tasks, yet continue to exhibit visual hallucinations and an over-reliance on
textual priors. We present a systematic diagnosis of state-of-the-art
vision-language models using a three-stage evaluation framework, uncovering key
failure modes. To address these, we propose an agent-based architecture that
combines LLM reasoning with lightweight visual modules, enabling fine-grained
analysis and iterative refinement of reasoning chains. Our results highlight
future visual reasoning models should focus on integrating a broader set of
specialized tools for analyzing visual content. Our system achieves significant
gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or
surpassing much larger models. We will release our framework and evaluation
suite to facilitate future research.

</details>


### [73] [Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models](https://arxiv.org/abs/2510.20707)
*Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang*

Main category: cs.CV

TL;DR: LVLM 中的 KV 缓存扩展导致内存瓶颈。MixKV 提出了一种结合重要性和多样性的新方法来优化 KV 缓存压缩，提高了多模态理解和 GUI 基础任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 KV 缓存压缩方法侧重于保留高重要性的 KV 对，但忽略了多模态 KV 缓存中特有的跨模态语义冗余模式，可能导致语义覆盖不足。

Method: MixKV 提出了一种新颖的方法，将重要性与多样性相结合，以优化 LVLM 的 KV 缓存压缩。该方法能够适应特定于注意力头的语义冗余，并在压缩 KV 对时有选择地平衡多样性和重要性。

Result: MixKV 在多个 LVLM 上持续改进现有方法。在极端压缩（budget=64）下，MixKV 在五个多模态理解基准测试中的平均性能提高了 5.1%，并在 GUI 基础任务上分别将 SnapKV 和 AdaKV 的性能提高了 8.0% 和 9.0%，同时保持了相当的推理效率。MixKV 同样适用于 LLM，并取得了可比的性能提升。

Conclusion: MixKV 通过结合重要性和多样性，有效地解决了 LVLM 中的 KV 缓存内存瓶颈问题，并在各种多模态任务和 LLM 中取得了显著的性能提升。

Abstract: Recent large vision-language models (LVLMs) demonstrate remarkable
capabilities in processing extended multi-modal sequences, yet the resulting
key-value (KV) cache expansion creates a critical memory bottleneck that
fundamentally limits deployment scalability. While existing KV cache
compression methods focus on retaining high-importance KV pairs to minimize
storage, they often overlook the modality-specific semantic redundancy patterns
that emerge distinctively in multi-modal KV caches. In this work, we first
analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying
levels of redundancy across attention heads. We show that relying solely on
importance can only cover a subset of the full KV cache information
distribution, leading to potential loss of semantic coverage. To address this,
we propose \texttt{MixKV}, a novel method that mixes importance with diversity
for optimized KV cache compression in LVLMs. \texttt{MixKV} adapts to head-wise
semantic redundancy, selectively balancing diversity and importance when
compressing KV pairs. Extensive experiments demonstrate that \texttt{MixKV}
consistently enhances existing methods across multiple LVLMs. Under extreme
compression (budget=64), \texttt{MixKV} improves baseline methods by an average
of \textbf{5.1\%} across five multi-modal understanding benchmarks and achieves
remarkable gains of \textbf{8.0\%} and \textbf{9.0\%} for SnapKV and AdaKV on
GUI grounding tasks, all while maintaining comparable inference efficiency.
Furthermore, \texttt{MixKV} extends seamlessly to LLMs with comparable
performance gains. Our code is available at
\href{https://github.com/xuyang-liu16/MixKV}{\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.

</details>


### [74] [AutoScape: Geometry-Consistent Long-Horizon Scene Generation](https://arxiv.org/abs/2510.20726)
*Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker*

Main category: cs.CV

TL;DR: AutoScape是一个新的RGB-D扩散模型，用于生成长时距的驾驶场景，通过生成关键帧并保持几何一致性，生成了20秒以上的逼真、几何一致的驾驶视频，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 生成长时距、逼真且几何一致的驾驶场景。

Method: 使用新颖的RGB-D扩散模型生成稀疏、几何一致的关键帧，并在共享潜在空间中联合处理图像和深度。模型明确依赖于现有场景几何，并使用扭曲一致性引导来指导采样过程。然后，视频扩散模型在关键帧之间进行插值以生成密集的视频帧。

Result: 生成的驾驶视频超过20秒，在长时距FID和FVD得分上分别比现有技术提高了48.6%和43.0%。

Conclusion: AutoScape能够生成逼真且几何一致的驾驶视频，在长时距生成方面取得了显著的进展。

Abstract: This paper proposes AutoScape, a long-horizon driving scene generation
framework. At its core is a novel RGB-D diffusion model that iteratively
generates sparse, geometrically consistent keyframes, serving as reliable
anchors for the scene's appearance and geometry. To maintain long-range
geometric consistency, the model 1) jointly handles image and depth in a shared
latent space, 2) explicitly conditions on the existing scene geometry (i.e.,
rendered point clouds) from previously generated keyframes, and 3) steers the
sampling process with a warp-consistent guidance. Given high-quality RGB-D
keyframes, a video diffusion model then interpolates between them to produce
dense and coherent video frames. AutoScape generates realistic and
geometrically consistent driving videos of over 20 seconds, improving the
long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\% and
43.0\%, respectively.

</details>


### [75] [ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology](https://arxiv.org/abs/2510.20754)
*Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod*

Main category: cs.CV

TL;DR: 提出了一种结合CNN和ViT的注意力驱动特征融合模型，用于改进组织分割的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化病理图像分析对辅助诊断至关重要，其中深度学习在组织分割方面表现优异。

Method: 提出了一种基于CNN和ViT的注意力驱动特征融合的统一双编码器模型。

Result: 在GCPS数据集上达到{\mu}IoU/{\mu}Dice 76.79%/86.87%，在PUMA数据集上达到64.93%/76.60%，优于现有方法。

Conclusion: 该模型在组织分割任务上取得了先进的性能。

Abstract: Automated histopathological image analysis plays a vital role in
computer-aided diagnosis of various diseases. Among developed algorithms, deep
learning-based approaches have demonstrated excellent performance in multiple
tasks, including semantic tissue segmentation in histological images. In this
study, we propose a novel approach based on attention-driven feature fusion of
convolutional neural networks (CNNs) and vision transformers (ViTs) within a
unified dual-encoder model to improve semantic segmentation performance.
Evaluation on two publicly available datasets showed that our model achieved
{\mu}IoU/{\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and
64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline
benchmarks. The implementation of our method is publicly available in a GitHub
repository: https://github.com/NimaTorbati/ACS-SegNet

</details>


### [76] [DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion](https://arxiv.org/abs/2510.20766)
*Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal*

Main category: cs.CV

TL;DR: DyPE是一种训练无关的方法，通过动态调整Transformer模型的位置编码，使预训练的扩散Transformer能够在超出其训练分辨率的超高分辨率下生成图像，且无额外采样成本。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在超高分辨率下训练成本高昂，因为自注意力机制会随着图像token数量呈二次方扩展。

Method: DyPE通过利用扩散过程中固有的频谱特性，动态调整模型在每个扩散步骤的位置编码，使其频谱与生成过程的当前阶段相匹配。

Result: DyPE能够以极高的分辨率（例如，使用FLUX生成1600万像素的图像）生成图像，并在多个基准测试中持续提高性能，在高分辨率生成方面达到最先进的保真度。

Conclusion: DyPE是一种有效的方法，可以显著提高扩散Transformer在超高分辨率图像生成方面的能力，尤其在高分辨率下效果更为显著。

Abstract: Diffusion Transformer models can generate images with remarkable fidelity and
detail, yet training them at ultra-high resolutions remains extremely costly
due to the self-attention mechanism's quadratic scaling with the number of
image tokens. In this paper, we introduce Dynamic Position Extrapolation
(DyPE), a novel, training-free method that enables pre-trained diffusion
transformers to synthesize images at resolutions far beyond their training
data, with no additional sampling cost. DyPE takes advantage of the spectral
progression inherent to the diffusion process, where low-frequency structures
converge early, while high-frequencies take more steps to resolve.
Specifically, DyPE dynamically adjusts the model's positional encoding at each
diffusion step, matching their frequency spectrum with the current stage of the
generative process. This approach allows us to generate images at resolutions
that exceed the training resolution dramatically, e.g., 16 million pixels using
FLUX. On multiple benchmarks, DyPE consistently improves performance and
achieves state-of-the-art fidelity in ultra-high-resolution image generation,
with gains becoming even more pronounced at higher resolutions. Project page is
available at https://noamissachar.github.io/DyPE/.

</details>


### [77] [AlphaFlow: Understanding and Improving MeanFlow Models](https://arxiv.org/abs/2510.20771)
*Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov*

Main category: cs.CV

TL;DR: MeanFlow 目标可分解为轨迹流匹配和轨迹一致性，两者存在优化冲突，导致收敛缓慢。$\\alpha$-Flow 通过课程学习策略解决此问题，统一了多种目标，实现了更好的收敛性和生成效果，并在 ImageNet 上取得了新的 SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: MeanFlow 框架在少样本生成模型方面表现强大，但其成功机制尚不完全清楚。需要理解其优化过程中的挑战并提出改进方法。

Method: 通过梯度分析 MeanFlow 的目标函数，发现其轨迹流匹配和轨迹一致性两项存在负相关，导致优化冲突。提出 $\\alpha$-Flow，一个统一轨迹流匹配、Shortcut Model 和 MeanFlow 的目标函数族，并采用课程学习策略，从轨迹流匹配平稳过渡到 MeanFlow，以解耦冲突目标。

Result: $\\alpha$-Flow 在 ImageNet-1K 256x256 数据集上，使用 vanilla DiT 主干网络进行训练，相比 MeanFlow 在不同尺度和设置下均表现更优。最大的 $\\alpha$-Flow-XL/2+ 模型在 1-NFE 和 2-NFE 下分别取得了 2.58 和 2.15 的 FID 分数，创造了新的 SOTA 记录。

Conclusion: $\\alpha$-Flow 通过解耦 MeanFlow 中的冲突目标并采用课程学习策略，能够实现更快的收敛速度和更好的生成质量，并在条件图像生成任务上取得了领先的性能。

Abstract: MeanFlow has recently emerged as a powerful framework for few-step generative
modeling trained from scratch, but its success is not yet fully understood. In
this work, we show that the MeanFlow objective naturally decomposes into two
parts: trajectory flow matching and trajectory consistency. Through gradient
analysis, we find that these terms are strongly negatively correlated, causing
optimization conflict and slow convergence. Motivated by these insights, we
introduce $\alpha$-Flow, a broad family of objectives that unifies trajectory
flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting
a curriculum strategy that smoothly anneals from trajectory flow matching to
MeanFlow, $\alpha$-Flow disentangles the conflicting objectives, and achieves
better convergence. When trained from scratch on class-conditional ImageNet-1K
256x256 with vanilla DiT backbones, $\alpha$-Flow consistently outperforms
MeanFlow across scales and settings. Our largest $\alpha$-Flow-XL/2+ model
achieves new state-of-the-art results using vanilla DiT backbones, with FID
scores of 2.58 (1-NFE) and 2.15 (2-NFE).

</details>


### [78] [CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image](https://arxiv.org/abs/2510.20776)
*Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao*

Main category: cs.CV

TL;DR: Cupid是一个新颖的基于生成的三维重建方法，可以从单张二维图像准确推断出相机位姿、三维形状和纹理。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的基于生成的三维重建方法，用于从单张二维图像准确推断相机位姿、三维形状和纹理。

Method: Cupid将三维重建视为从学习到的三维物体分布中进行条件采样，并联合生成体素和像素-体素对应关系。它采用两阶段流匹配流程：1）粗略阶段生成初始三维几何和用于位姿恢复的二维投影；2）精炼阶段整合位姿对齐的图像特征以增强结构保真度和外观细节。

Result: Cupid在PSNR方面比领先的三维重建方法高出3dB以上，在Chamfer Distance方面降低了10%以上，在位姿准确性方面与单目估计器相当，并在视觉保真度方面优于基线三维生成模型。

Conclusion: Cupid通过将相机位姿和三维形状表示在共享的三维潜在空间中，实现了鲁棒的位姿和形状估计，并提高了重建的视觉保真度。

Abstract: This work proposes a new generation-based 3D reconstruction method, named
Cupid, that accurately infers the camera pose, 3D shape, and texture of an
object from a single 2D image. Cupid casts 3D reconstruction as a conditional
sampling process from a learned distribution of 3D objects, and it jointly
generates voxels and pixel-voxel correspondences, enabling robust pose and
shape estimation under a unified generative framework. By representing both
input camera poses and 3D shape as a distribution in a shared 3D latent space,
Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that
produces initial 3D geometry with associated 2D projections for pose recovery;
and (2) a refinement stage that integrates pose-aligned image features to
enhance structural fidelity and appearance details. Extensive experiments
demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3
dB PSNR gain and an over 10% Chamfer Distance reduction, while matching
monocular estimators on pose accuracy and delivering superior visual fidelity
over baseline 3D generative models. For an immersive view of the 3D results
generated by Cupid, please visit cupid3d.github.io.

</details>


### [79] [ARGenSeg: Image Segmentation with Autoregressive Image Generation Model](https://arxiv.org/abs/2510.20803)
*Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou*

Main category: cs.CV

TL;DR: ARGenSeg是一种新颖的自动回归生成范式，用于图像分割，它在统一的框架内实现了多模态理解和像素级感知。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将图像分割集成到多模态大语言模型（MLLMs）时，通常采用边界点表示或专门的分割头，这限制了MLLM捕捉细粒度视觉细节的能力。

Method: 提出了一种基于图像生成的MLLM分割框架，利用MLLM输出视觉令牌，并通过通用的VQ-VAE将其解码为图像，实现像素级理解。为了降低推理延迟，采用了 next-scale-prediction 策略并行生成所需的视觉令牌。

Result: 实验证明，该方法在多个分割数据集上超越了现有的最先进方法，推理速度显著提升，同时保持了强大的理解能力。

Conclusion: ARGenSeg通过基于图像生成的范式，实现了多模态理解和像素级感知，并在分割任务上取得了优于现有方法的性能和效率。

Abstract: We propose a novel AutoRegressive Generation-based paradigm for image
Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level
perception within a unified framework. Prior works integrating image
segmentation into multimodal large language models (MLLMs) typically employ
either boundary points representation or dedicated segmentation heads. These
methods rely on discrete representations or semantic prompts fed into
task-specific decoders, which limits the ability of the MLLM to capture
fine-grained visual details. To address these challenges, we introduce a
segmentation framework for MLLM based on image generation, which naturally
produces dense masks for target objects. We leverage MLLM to output visual
tokens and detokenize them into images using an universal VQ-VAE, making the
segmentation fully dependent on the pixel-level understanding of the MLLM. To
reduce inference latency, we employ a next-scale-prediction strategy to
generate required visual tokens in parallel. Extensive experiments demonstrate
that our method surpasses prior state-of-the-art approaches on multiple
segmentation datasets with a remarkable boost in inference speed, while
maintaining strong understanding capabilities.

</details>


### [80] [Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers](https://arxiv.org/abs/2510.20807)
*Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed*

Main category: cs.CV

TL;DR: 该研究提出了一种简单有效的纯 Transformer 模型，用于自回归视频预测，并在物理模拟数据集上进行了训练，显著提高了物理预测的准确性和时间范围。


<details>
  <summary>Details</summary>
Motivation: 受到自回归大语言模型在性能和可扩展性方面的启发，Transformer 模型在视觉领域取得了成功，本研究旨在探索 Transformer 在视频预测中的应用，并解决现有方法在物理模拟方面存在的局限性。

Method: 提出了一种简单有效的纯 Transformer 模型，用于自回归视频预测，并利用连续像素空间表示。通过比较各种时空自注意力布局，并关注物理对象跟踪指标和物理模拟数据集上的无监督训练，来分离时空推理。

Result: 与现有的潜在空间方法相比，该模型将物理准确预测的时间范围延长了高达 50%，同时在视频质量指标上保持了可比的性能。此外，解释性实验表明，该模型能够通过探测模型准确估计 PDE 模拟参数，并且能够推广到估计分布外（out-of-distribution）的模拟参数。

Conclusion: 这项工作为进一步基于注意力的视频时空建模提供了一个简单、参数高效且可解释的平台。

Abstract: Inspired by the performance and scalability of autoregressive large language
models (LLMs), transformer-based models have seen recent success in the visual
domain. This study investigates a transformer adaptation for video prediction
with a simple end-to-end approach, comparing various spatiotemporal
self-attention layouts. Focusing on causal modeling of physical simulations
over time; a common shortcoming of existing video-generative approaches, we
attempt to isolate spatiotemporal reasoning via physical object tracking
metrics and unsupervised training on physical simulation datasets. We introduce
a simple yet effective pure transformer model for autoregressive video
prediction, utilizing continuous pixel-space representations for video
prediction. Without the need for complex training strategies or latent
feature-learning components, our approach significantly extends the time
horizon for physically accurate predictions by up to 50% when compared with
existing latent-space approaches, while maintaining comparable performance on
common video quality metrics. In addition, we conduct interpretability
experiments to identify network regions that encode information useful to
perform accurate estimations of PDE simulation parameters via probing models,
and find that this generalizes to the estimation of out-of-distribution
simulation parameters. This work serves as a platform for further
attention-based spatiotemporal modeling of videos via a simple, parameter
efficient, and interpretable approach.

</details>


### [81] [Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation](https://arxiv.org/abs/2510.20812)
*Yuhan Liu,Lianhui Qin,Shengjie Wang*

Main category: cs.CV

TL;DR: SV是一个训练框架，通过结合多个小型草稿专家和一个大型Verdict模型，来解决大型视觉语言模型在处理信息密集型图像时的不足。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在处理信息密集型图像时存在困难，尤其是在精确定位关键线索和进行多跳推理方面。

Method: SV框架包含草稿阶段和Verdict阶段。草稿阶段由小型视觉语言模型（草稿专家）生成推理路径，提供多样的定位候选；Verdict阶段由一个强大的视觉语言模型（Verdict模型）综合这些路径，生成最终答案。此外，SV还引入了共识专家选择机制，只将高一致性的推理路径转发给Verdict模型。

Result: SV在InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K等具有挑战性的信息密集型和高分辨率视觉问答基准上取得了持续的提升。

Conclusion: SV通过综合多个部分准确的推理路径中的正确见解，实现了错误纠正和成本效益，优于大型专有模型或训练流程。

Abstract: Large Vision-Language Models (VLMs) have achieved remarkable progress in
multimodal understanding, yet they struggle when reasoning over
information-intensive images that densely interleave textual annotations with
fine-grained graphical elements. The main challenges lie in precisely
localizing critical cues in dense layouts and multi-hop reasoning to integrate
dispersed evidence. We propose Speculative Verdict (SV), a training-free
framework inspired by speculative decoding that combines multiple lightweight
draft experts with a large verdict model. In the draft stage, small VLMs act as
draft experts to generate reasoning paths that provide diverse localization
candidates; in the verdict stage, a strong VLM synthesizes these paths to
produce the final answer, minimizing computational cost while recovering
correct answers. To further improve efficiency and accuracy, SV introduces a
consensus expert selection mechanism that forwards only high-agreement
reasoning paths to the verdict. Empirically, SV achieves consistent gains on
challenging information-intensive and high-resolution visual question answering
benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.
By synthesizing correct insights from multiple partially accurate reasoning
paths, SV achieves both error correction and cost-efficiency compared to large
proprietary models or training pipelines. Code is available at
https://github.com/Tinaliu0123/speculative-verdict

</details>


### [82] [SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution](https://arxiv.org/abs/2510.20814)
*Ritik Shah,Marco F Duarte*

Main category: cs.CV

TL;DR: 提出了一种名为SpectraMorph的物理引导、自监督、具有结构化潜在空间的融合框架，用于高光谱超分辨率。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法缺乏可解释性，并且在MSI波段很少时性能会下降。

Method: SpectraMorph通过一个解混瓶颈来实现，该瓶颈从低分辨率HSI中提取端元光谱，并使用多层感知器从MSI预测丰度图。通过MSI传感器的光谱响应函数以自监督方式进行训练。

Result: SpectraMorph能够生成可解释的中间结果，训练时间不到一分钟，并且即使MSI只有一个波段（全色）也能保持鲁棒性。在合成和真实世界的数据集上，SpectraMorph的性能优于最先进的无监督/自监督基线，并且与有监督基线相比仍然具有竞争力。

Conclusion: SpectraMorph是一种可解释、高效且鲁棒的高光谱超分辨率方法，适用于MSI波段数量有限的情况。

Abstract: Hyperspectral sensors capture dense spectra per pixel but suffer from low
spatial resolution, causing blurred boundaries and mixed-pixel effects.
Co-registered companion sensors such as multispectral, RGB, or panchromatic
cameras provide high-resolution spatial detail, motivating hyperspectral
super-resolution through the fusion of hyperspectral and multispectral images
(HSI-MSI). Existing deep learning based methods achieve strong performance but
rely on opaque regressors that lack interpretability and often fail when the
MSI has very few bands. We propose SpectraMorph, a physics-guided
self-supervised fusion framework with a structured latent space. Instead of
direct regression, SpectraMorph enforces an unmixing bottleneck: endmember
signatures are extracted from the low-resolution HSI, and a compact multilayer
perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed
by linear mixing, with training performed in a self-supervised manner via the
MSI sensor's spectral response function. SpectraMorph produces interpretable
intermediates, trains in under a minute, and remains robust even with a
single-band (pan-chromatic) MSI. Experiments on synthetic and real-world
datasets show SpectraMorph consistently outperforming state-of-the-art
unsupervised/self-supervised baselines while remaining very competitive against
supervised baselines.

</details>


### [83] [Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge](https://arxiv.org/abs/2510.20819)
*Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot*

Main category: cs.CV

TL;DR: 我们提出了一个名为LDDBM的通用框架，用于在不同数据模态之间进行转换，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在跨模态转换方面存在局限，例如需要共享维度、高斯先验和特定模态架构，限制了通用性。

Method: 通过利用去噪扩散桥模型（Denoising Diffusion Bridge Models）的潜在变量扩展，在共享的潜在空间中进行操作，无需对齐维度。我们引入了对比对齐损失来强制语义一致性，并设计了一个领域无关的编码器-解码器架构，用于潜在空间中的噪声预测。此外，还提出了一种预测损失来指导训练，并探索了几种提高稳定性的训练策略。

Result: 该方法支持任意模态对，并在多视图到3D形状生成、图像超分辨率和多视图场景合成等多种跨模态转换任务上表现出色，建立了一个强大的新通用跨模态转换基线。

Conclusion: LDDBM是一个有效的通用框架，能够进行跨模态转换，并且在多个任务上取得了优异的性能。

Abstract: Recent advances in generative modeling have positioned diffusion models as
state-of-the-art tools for sampling from complex data distributions. While
these models have shown remarkable success across single-modality domains such
as images and audio, extending their capabilities to Modality Translation (MT),
translating information across different sensory modalities, remains an open
challenge. Existing approaches often rely on restrictive assumptions, including
shared dimensionality, Gaussian source priors, and modality-specific
architectures, which limit their generality and theoretical grounding. In this
work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a
general-purpose framework for modality translation based on a latent-variable
extension of Denoising Diffusion Bridge Models. By operating in a shared latent
space, our method learns a bridge between arbitrary modalities without
requiring aligned dimensions. We introduce a contrastive alignment loss to
enforce semantic consistency between paired samples and design a
domain-agnostic encoder-decoder architecture tailored for noise prediction in
latent space. Additionally, we propose a predictive loss to guide training
toward accurate cross-domain translation and explore several training
strategies to improve stability. Our approach supports arbitrary modality pairs
and performs strongly on diverse MT tasks, including multi-view to 3D shape
generation, image super-resolution, and multi-view scene synthesis.
Comprehensive experiments and ablations validate the effectiveness of our
framework, establishing a new strong baseline in general modality translation.
For more information, see our project page:
https://sites.google.com/view/lddbm/home.

</details>


### [84] [LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas](https://arxiv.org/abs/2510.20820)
*Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: LayerComposer是一个用于个性化、多主体文本到图像生成的交互式框架，通过引入分层画布和锁定机制来解决现有模型的空间控制和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化生成模型虽然具有出色的视觉保真度，但在空间构图方面缺乏交互式控制，并且在处理多个主体时扩展性差。

Method: 提出了一种分层画布（Layered Canvas）和锁定机制（locking mechanism）。分层画布允许将每个主体放置在不同的图层上，实现无遮挡的构图。锁定机制可以保持选定图层的高度保真度，同时允许其余图层灵活适应周围环境。

Result: 实验证明，LayerComposer在多主体个性化图像生成方面，相比现有最先进的方法，在空间控制和身份保持方面表现更优。

Conclusion: LayerComposer通过分层画布和锁定机制，显著提升了个性化多主体文本到图像生成在空间控制和身份保持方面的能力。

Abstract: Despite their impressive visual fidelity, existing personalized generative
models lack interactive control over spatial composition and scale poorly to
multiple subjects. To address these limitations, we present LayerComposer, an
interactive framework for personalized, multi-subject text-to-image generation.
Our approach introduces two main contributions: (1) a layered canvas, a novel
representation in which each subject is placed on a distinct layer, enabling
occlusion-free composition; and (2) a locking mechanism that preserves selected
layers with high fidelity while allowing the remaining layers to adapt flexibly
to the surrounding context. Similar to professional image-editing software, the
proposed layered canvas allows users to place, resize, or lock input subjects
through intuitive layer manipulation. Our versatile locking mechanism requires
no architectural changes, relying instead on inherent positional embeddings
combined with a new complementary data sampling strategy. Extensive experiments
demonstrate that LayerComposer achieves superior spatial control and identity
preservation compared to the state-of-the-art methods in multi-subject
personalized image generation.

</details>


### [85] [HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives](https://arxiv.org/abs/2510.20822)
*Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu*

Main category: cs.CV

TL;DR: HoloCine是第一个能够生成连贯、多镜头叙事的模型，弥合了文本到视频模型在叙事连贯性方面的差距，实现了从头到尾的全局一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频模型在生成单个片段方面表现出色，但在创建连贯的多镜头叙事方面存在不足，而这正是讲故事的精髓。

Method: HoloCine通过以下方式实现精确的导演控制：1. 窗口交叉注意力机制，将文本提示本地化到特定镜头。2. 稀疏跨镜头自注意力模式（镜头内密集，镜头间稀疏），确保了分钟级生成所需的效率。

Result: HoloCine在叙事连贯性方面达到了新的最先进水平，并展现出 remarkable 的涌现能力：对角色和场景的持久记忆，以及对电影制作技巧的直观掌握。

Conclusion: HoloCine标志着从片段合成向自动化电影制作的重大转变，使得端到端的电影创作成为一个可行的未来。

Abstract: State-of-the-art text-to-video models excel at generating isolated clips but
fall short of creating the coherent, multi-shot narratives, which are the
essence of storytelling. We bridge this "narrative gap" with HoloCine, a model
that generates entire scenes holistically to ensure global consistency from the
first shot to the last. Our architecture achieves precise directorial control
through a Window Cross-Attention mechanism that localizes text prompts to
specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within
shots but sparse between them) ensures the efficiency required for minute-scale
generation. Beyond setting a new state-of-the-art in narrative coherence,
HoloCine develops remarkable emergent abilities: a persistent memory for
characters and scenes, and an intuitive grasp of cinematic techniques. Our work
marks a pivotal shift from clip synthesis towards automated filmmaking, making
end-to-end cinematic creation a tangible future. Our code is available at:
https://holo-cine.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [86] [DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse](https://arxiv.org/abs/2510.19858)
*Jindi Wang,Yidi Zhang,Zhaoxing Li*

Main category: cs.CL

TL;DR: DeBERTa-KC模型在YouTube科学频道评论中有效识别知识构建（KC）的四个类别（非KC、分享、探索、协商），宏观F1得分为0.836，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 自动分类在线科学学习讨论中的知识构建（KC）水平，以提供可扩展、理论驱动的讨论分析方法。

Method: 提出DeBERTa-KC模型，该模型在DeBERTa-v3基础上增加了Focal Loss、Label Smoothing和R-Drop正则化，以处理类别不平衡和提高泛化能力。使用从YouTube科学频道收集的20,000条手动注释的评论数据，并构建了一个端到端的管道。

Result: DeBERTa-KC在10倍分层交叉验证中实现了0.836 ± 0.008的宏观F1分数，显著优于经典和Transformer基线模型。模型对高阶认知参与（探索和协商）表现出高度敏感性。

Conclusion: 大型语言模型可以有效地捕捉非正式数字学习环境中知识构建的细微差别，为讨论分析和评估认知参与的自动化工具开发提供了可行方案。

Abstract: This study presents DeBERTa-KC, a transformer-based model for automatic
classification of knowledge construction (KC) levels in online science learning
discourse. Using comments collected from four popular YouTube science channels
(2022--2024), a balanced corpus of 20,000 manually annotated samples was
created across four KC categories: \textit{nonKC}, \textit{Share},
\textit{Explore}, and \textit{Negotiate}. The proposed model extends DeBERTa-v3
with Focal Loss, Label Smoothing, and R-Drop regularization to address class
imbalance and enhance generalization. A reproducible end-to-end pipeline was
implemented, encompassing data extraction, annotation, preprocessing, training,
and evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved
a macro-F1 of $0.836 \pm 0.008$, significantly out-performing both classical
and transformer baselines ($p<0.01$). Per-category results indicate strong
sensitivity to higher-order epistemic engagement, particularly in
\textit{Explore} and \textit{Negotiate} discourse. These findings demonstrate
that large language models can effectively capture nuanced indicators of
knowledge construction in informal digital learning environments, offering
scalable, theory-informed approaches to discourse analysis and the development
of automated tools for assessing epistemic engagement.

</details>


### [87] [An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics](https://arxiv.org/abs/2510.19866)
*Xincheng Liu*

Main category: cs.CL

TL;DR: 本研究评估了五种主流大语言模型（ChatGPT、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2 和 Grok 4）生成的教学计划的教学健全性和可用性，并测试了三种结构化提示框架（TAG、RACE 和 COSTAR）。


<details>
  <summary>Details</summary>
Motivation: 评估不同大语言模型和提示框架在生成高中物理教学计划方面的表现，重点关注可读性、事实准确性、课程标准对齐度和认知需求。

Method: 生成了15份关于电磁波谱的高中物理教学计划，并使用四项计算指标进行分析：可读性、事实准确性、课程标准对齐度和认知需求。

Result: 模型选择显著影响语言可读性（DeepSeek 最易读，Claude 最难读）。RACE框架在事实准确性和课程标准对齐度方面表现最佳。所有模型生成的教学计划学习目标主要集中在布鲁姆分类法的“记忆”和“理解”层面，缺少高阶思维动词。

Conclusion: 教学计划的可读性主要由模型决定，而教学可靠性和课程对齐度则更多地取决于提示框架。结合可读性优化的模型、RACE框架以及包含物理概念、课程标准和高阶目标的明确清单，是生成教学计划的最优配置。

Abstract: This study evaluates the pedagogical soundness and usability of AI-generated
lesson plans across five leading large language models: ChatGPT (GPT-5), Claude
Sonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice,
three structured prompt frameworks were tested: TAG (Task, Audience, Goal),
RACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective,
Style, Tone, Audience, Response Format).
  Fifteen lesson plans were generated for a single high-school physics topic,
The Electromagnetic Spectrum. The lesson plans were analyzed through four
automated computational metrics: (1) readability and linguistic complexity, (2)
factual accuracy and hallucination detection, (3) standards and curriculum
alignment, and (4) cognitive demand of learning objectives.
  Results indicate that model selection exerted the strongest influence on
linguistic accessibility, with DeepSeek producing the most readable teaching
plan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89).
  The prompt framework structure most strongly affected the factual accuracy
and pedagogical completeness, with the RACE framework yielding the lowest
hallucination index and the highest incidental alignment with NGSS curriculum
standards. Across all models, the learning objectives in the fifteen lesson
plans clustered at the Remember and Understand tiers of Bloom's taxonomy. There
were limited higher-order verbs in the learning objectives extracted.
  Overall, the findings suggest that readability is significantly governed by
model design, while instructional reliability and curricular alignment depend
more on the prompt framework. The most effective configuration for lesson plans
identified in the results was to combine a readability-optimized model with the
RACE framework and an explicit checklist of physics concepts, curriculum
standards, and higher-order objectives.

</details>


### [88] [From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model](https://arxiv.org/abs/2510.19871)
*Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo*

Main category: cs.CL

TL;DR: ReDiff框架通过主动修正来解决离散扩散模型在生成过程中的错误累积问题，通过两阶段训练（修正合成错误和在线自我修正）提升了生成内容的连贯性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在视觉-语言任务中有潜力，但存在训练-推理不一致导致的错误累积问题，影响生成质量。

Method: 提出ReDiff框架，将生成过程从被动去噪改为主动修正。采用两阶段训练：1. 修正合成错误；2. 在线自我修正循环，学习专家修正以修正自身错误。

Result: ReDiff显著提高了生成内容的连贯性和事实准确性，实现了稳定高效的并行生成，优于传统去噪方法。

Conclusion: ReDiff通过教授模型自我修正错误的能力，有效解决了离散扩散模型中的错误累积问题，实现了高质量的生成。

Abstract: Discrete diffusion models have emerged as a promising direction for
vision-language tasks, offering bidirectional context modeling and theoretical
parallelization. However, their practical application is severely hindered by a
train-inference discrepancy, which leads to catastrophic error cascades:
initial token errors during parallel decoding pollute the generation context,
triggering a chain reaction of compounding errors and leading to syntactic
errors and semantic hallucinations. To address this fundamental challenge, we
reframe the generation process from passive denoising to active refining. We
introduce ReDiff, a refining-enhanced diffusion framework that teaches the
model to identify and correct its own errors. Our approach features a two-stage
training process: first, we instill a foundational revision capability by
training the model to revise synthetic errors; second, we implement a novel
online self-correction loop where the model is explicitly trained to revise its
own flawed drafts by learning from an expert's corrections. This mistake-driven
learning endows the model with the crucial ability to revisit and refine its
already generated output, effectively breaking the error cascade. Extensive
experiments demonstrate that ReDiff significantly improves the coherence and
factual accuracy of generated content, enabling stable and efficient parallel
generation far superior to traditional denoising methods. Our codes and models
are available at https://rediff-hku.github.io/.

</details>


### [89] [Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention](https://arxiv.org/abs/2510.19875)
*J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard*

Main category: cs.CL

TL;DR: LLMs的上下文长度增加，传统的注意力机制分析方法计算成本过高。本文提出了一种名为Sparse Tracing的新技术，利用动态稀疏注意力机制，可以在接近线性的时间和线性空间内高效分析长上下文注意力模式，从而实现大规模模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 分析大规模语言模型（LLMs）在处理长上下文（百万token级别）时的注意力机制，解决了传统方法计算成本高（二次方复杂度）和内存需求大（TB级别）的问题。

Method: 提出了一种名为Stream的编译式分层剪枝算法，该算法能以接近线性的时间（O(T log T)）和线性空间（O(T)）估计每头稀疏注意力掩码。Stream采用类似二分查找的方法，为每个查询保留top-k的关键块，同时保持模型预测下一个token的行为。对长链式思考（chain-of-thought）推理过程进行分析，识别关键的“思想锚点”，并剪枝97-99%的token交互。在RULER基准测试中，Stream在保留关键检索路径的同时，丢弃了90-96%的交互，并揭示了从“针”（needle）到输出的层级路径。

Result: Stream算法能够高效地分析长上下文注意力模式，识别关键信息路径，并在长链式思考推理和RULER基准测试中展现了其有效性。该方法可以在消费级GPU上实现长上下文的可解释性，而无需大量的缓存。

Conclusion: Sparse Tracing技术通过Stream算法，为大规模语言模型提供了高效、可行的长上下文注意力机制分析方法，解决了计算和内存瓶颈，使得链式思考的监控更加普及。

Abstract: As Large Language Models (LLMs) scale to million-token contexts, traditional
Mechanistic Interpretability techniques for analyzing attention scale
quadratically with context length, demanding terabytes of memory beyond 100,000
tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic
sparse attention to efficiently analyze long context attention patterns. We
present Stream, a compilable hierarchical pruning algorithm that estimates
per-head sparse attention masks in near-linear time $O(T \log T)$ and linear
space $O(T)$, enabling one-pass interpretability at scale. Stream performs a
binary-search-style refinement to retain only the top-$k$ key blocks per query
while preserving the model's next-token behavior. We apply Stream to long
chain-of-thought reasoning traces and identify thought anchors while pruning
97-99\% of token interactions. On the RULER benchmark, Stream preserves
critical retrieval paths while discarding 90-96\% of interactions and exposes
layer-wise routes from the needle to output. Our method offers a practical
drop-in tool for analyzing attention patterns and tracing information flow
without terabytes of caches. By making long context interpretability feasible
on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring.
Code is available at https://anonymous.4open.science/r/stream-03B8/.

</details>


### [90] [Automated HIV Screening on Dutch EHR with Large Language Models](https://arxiv.org/abs/2510.19879)
*Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 利用大型语言模型分析电子健康记录中的非结构化文本，以提高 HIV 筛查的准确性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的普及为 HIV 筛查带来了新的机遇，但现有研究主要集中在结构化数据，忽略了临床笔记等非结构化文本中的潜在信息。

Method: 提出了一种利用大型语言模型（LLM）分析非结构化 EHR 文本以确定患者是否符合 HIV 检测资格的新流程。

Result: 在鹿特丹伊拉斯姆斯大学医学中心（Erasmus University Medical Center Rotterdam）的临床数据上进行实验，证明该流程在保持低假阴性率的同时实现了高准确性。

Conclusion: 该研究提出的新流程能够有效利用非结构化 EHR 数据进行 HIV 风险评估，为早期诊断和治疗提供了可能。

Abstract: Efficient screening and early diagnosis of HIV are critical for reducing
onward transmission. Although large scale laboratory testing is not feasible,
the widespread adoption of Electronic Health Records (EHRs) offers new
opportunities to address this challenge. Existing research primarily focuses on
applying machine learning methods to structured data, such as patient
demographics, for improving HIV diagnosis. However, these approaches often
overlook unstructured text data such as clinical notes, which potentially
contain valuable information relevant to HIV risk. In this study, we propose a
novel pipeline that leverages a Large Language Model (LLM) to analyze
unstructured EHR text and determine a patient's eligibility for further HIV
testing. Experimental results on clinical data from Erasmus University Medical
Center Rotterdam demonstrate that our pipeline achieved high accuracy while
maintaining a low false negative rate.

</details>


### [91] [An Expert-grounded benchmark of General Purpose LLMs in LCA](https://arxiv.org/abs/2510.19886)
*Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard*

Main category: cs.CL

TL;DR: 尽管大型语言模型（LLMs）在生命周期评估（LCA）领域展现出潜力，但对其可靠性、鲁棒性和可用性的系统性证据仍然有限。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在LCA中的可靠性、鲁棒性和可用性，解决该领域缺乏标准化评估框架的问题。

Method: 评估了11个通用LLMs在22个LCA相关任务上的表现，并由17位经验丰富的从业者根据科学准确性、解释质量、鲁棒性、可验证性和指令遵循性等标准进行评审，收集了168条专家评审意见。

Result: 37%的LLM响应包含不准确或误导性信息。虽然准确性和解释质量普遍获得中等或良好评价，但幻觉率差异显著，部分模型高达40%。开源模型在准确性和解释质量方面表现与闭源模型相当甚至更优。

Conclusion: 在LCA中应用LLMs需谨慎，避免将其视为“自由问答”工具，但其在提高解释质量和减轻简单任务劳动强度方面具有优势。

Abstract: Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

</details>


### [92] [Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities](https://arxiv.org/abs/2510.19892)
*Nishant Balepur,Dang Nguyen,Dayeon Ki*

Main category: cs.CL

TL;DR: static benchmarks and pairwise comparisons have limitations for evaluating multi-modal large language models (MLMs); game-based evaluations offer a more holistic and objective approach.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for MLMs are insufficient, either by being static and individual, or relying on subjective and exploitable pairwise comparisons. This necessitates a more robust evaluation method.

Method: Propose and implement game-based evaluations, specifically using the card game Dixit, to assess MLM capabilities holistically. In Dixit, MLMs must create captions for cards that trick some, but not all, players into choosing their card.

Result: Quantitative experiments show Dixit win-rate rankings correlate perfectly with existing MLM benchmarks. Human-MLM gameplay in Dixit reveals differences in strategies and highlights areas for MLM improvement in reasoning.

Conclusion: Game-based evaluations, like Dixit, provide a robust, objective, and engaging framework for assessing MLMs, offering insights beyond traditional benchmarks and revealing differences in human and AI strategies.

Abstract: Multi-modal large language models (MLMs) are often assessed on static,
individual benchmarks -- which cannot jointly assess MLM capabilities in a
single task -- or rely on human or model pairwise comparisons -- which is
highly subjective, expensive, and allows models to exploit superficial
shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these
issues, we propose game-based evaluations to holistically assess MLM
capabilities. Games require multiple abilities for players to win, are
inherently competitive, and are governed by fix, objective rules, and makes
evaluation more engaging, providing a robust framework to address the
aforementioned challenges. We manifest this evaluation specifically through
Dixit, a fantasy card game where players must generate captions for a card that
trick some, but not all players, into selecting the played card. Our
quantitative experiments with five MLMs show Dixit win-rate rankings are
perfectly correlated with those on popular MLM benchmarks, while games between
human and MLM players in Dixit reveal several differences between agent
strategies and areas of improvement for MLM reasoning.

</details>


### [93] [Large Language Model enabled Mathematical Modeling](https://arxiv.org/abs/2510.19895)
*Guoyun Zhang*

Main category: cs.CL

TL;DR: LLM，特别是DeepSeek-R1，可以通过理解自然语言和生成代码来弥合优化建模中的专业知识鸿沟，这在运营研究（OR）领域具有潜力，尽管存在幻觉等挑战，但已通过各种策略进行了缓解。


<details>
  <summary>Details</summary>
Motivation: 为解决传统优化方法在转化现实世界问题为数学模型时对领域专业知识的高度依赖，并探索LLM在弥合这一鸿沟方面的潜力。

Method: 系统性地评估DeepSeek-R1在四个关键OR基准（NL4OPT，IndustryOR，EasyLP和ComplexOR）上的表现，包括基线评估，开发幻觉分类法，以及应用LLM-as-a-Judge，少样本学习（FSL），工具调用和多代理框架等缓解策略。

Result: DeepSeek-R1在四个OR基准上进行了评估，并应用了缓解策略以减少幻觉并提高准确性。

Conclusion: LLM与优化建模的集成，特别是使用DeepSeek-R1，为运营研究中的决策提供了有前景的方法，尽管需要解决幻觉问题，但提出的策略显示出有效性。

Abstract: The integration of Large Language Models (LLMs) with optimization modeling
offers a promising avenue for advancing decision-making in operations research
(OR). Traditional optimization methods,such as linear programming, mixed
integer programming, and simulation depend heavily on domain expertise to
translate real-world problems into solvable mathematical models. While solvers
like Gurobi and COPT are powerful, expert input remains essential for defining
objectives, constraints, and variables. This research investigates the
potential of LLMs, specifically the DeepSeek-R1 model, to bridge this
formulation gap using natural language understanding and code generation.
Although prior models like GPT-4, Claude, and Bard have shown strong
performance in NLP and reasoning tasks, their high token costs and tendency
toward hallucinations limit real-world applicability in supply chain contexts.
In contrast, DeepSeek-R1, a cost-efficient and high-performing model trained
with reinforcement learning, presents a viable alternative. Despite its success
in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied
OR scenarios remains under explored. This study systematically evaluates
DeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and
ComplexOR. Our methodology includes baseline assessments, the development of a
hallucination taxonomy, and the application of mitigation strategies like
LLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent
Framework. These techniques aim to reduce hallucinations, enhance formulation
accuracy, and better align model outputs with user intent.

</details>


### [94] [Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation](https://arxiv.org/abs/2510.19897)
*Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka*

Main category: cs.CL

TL;DR: 本文提出了一种无需更新参数即可从标记示例中学习目标分类函数的新方法，利用记忆增强框架结合标记数据和 LLM 生成的批评，取得了显著的准确性提升，并引入了“suggestibility”指标来解释模型行为。


<details>
  <summary>Details</summary>
Motivation: 传统的微调方法成本高、不灵活且不透明，需要一种更优的替代方案来训练 LLM 智能体。

Method: 提出了一种记忆增强框架，该框架利用情节记忆存储实例级批评，并利用语义记忆将这些批评提炼成可重用的、任务级的指导。

Result: 与仅依赖标签的检索增强生成（RAG）方法相比，该框架在各种任务上将准确性提高了 24.8%。此外，还发现了不同模型在处理事实导向型数据和偏好导向型数据方面的行为差异，并引入了“suggestibility”指标来解释这些行为。

Conclusion: 记忆驱动的、反思性的学习有望用于构建更具适应性和可解释性的 LLM 智能体。

Abstract: We investigate how agents built on pretrained large language models can learn
target classification functions from labeled examples without parameter
updates. While conventional approaches like fine-tuning are often costly,
inflexible, and opaque, we propose a memory-augmented framework that leverages
both labeled data and LLM-generated critiques. Our framework uses episodic
memory to store instance-level critiques-capturing specific past
experiences-and semantic memory to distill these into reusable, task-level
guidance. Across a diverse set of tasks, incorporating critiques yields up to a
24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines
that rely only on labels. Through extensive empirical evaluation, we uncover
distinct behavioral differences between OpenAI and opensource models,
particularly in how they handle fact-oriented versus preference-based data. To
interpret how models respond to different representations of supervision
encoded in memory, we introduce a novel metric, suggestibility. This helps
explain observed behaviors and illuminates how model characteristics and memory
strategies jointly shape learning dynamics. Our findings highlight the promise
of memory-driven, reflective learning for building more adaptive and
interpretable LLM agents.

</details>


### [95] [LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation](https://arxiv.org/abs/2510.19967)
*Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang*

Main category: cs.CL

TL;DR: LyriCAR是一个全无监督的歌词翻译框架，通过引入难度感知课程设计和自适应课程策略，提高了翻译质量并加速了模型收敛。


<details>
  <summary>Details</summary>
Motivation: 现有歌词翻译方法依赖手工规则和句子级建模，难以处理跨行连贯性和全局押韵等段落级挑战，限制了对音乐-语言模式的内化和泛化能力。

Method: LyriCAR提出了一种全无监督的框架，包含难度感知课程设计和自适应课程策略，以逐步引导模型应对日益复杂的挑战。

Result: 在英中歌词翻译任务上，LyriCAR在标准翻译指标和多维度奖励分数上均取得了最先进的成果，优于现有基线。自适应课程策略将训练步数减少了近40%，同时保持了优越的性能。

Conclusion: LyriCAR通过其创新的课程学习方法，在歌词翻译任务中实现了高质量和高效率的训练。

Abstract: Lyric translation is a challenging task that requires balancing multiple
musical constraints. Existing methods often rely on hand-crafted rules and
sentence-level modeling, which restrict their ability to internalize
musical-linguistic patterns and to generalize effectively at the paragraph
level, where cross-line coherence and global rhyme are crucial. In this work,
we propose LyriCAR, a novel framework for controllable lyric translation that
operates in a fully unsupervised manner. LyriCAR introduces a difficulty-aware
curriculum designer and an adaptive curriculum strategy, ensuring efficient
allocation of training resources, accelerating convergence, and improving
overall translation quality by guiding the model with increasingly complex
challenges. Extensive experiments on the EN-ZH lyric translation task show that
LyriCAR achieves state-of-the-art results across both standard translation
metrics and multi-dimensional reward scores, surpassing strong baselines.
Notably, the adaptive curriculum strategy reduces training steps by nearly 40%
while maintaining superior performance. Code, data and model can be accessed at
https://github.com/rle27/LyriCAR.

</details>


### [96] [LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation](https://arxiv.org/abs/2510.19988)
*Xin Lian,Kenneth D. Forbus*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）虽然应用广泛，但易出错；符号自然语言理解（NLU）系统虽然准确但覆盖面有限。本研究提出一种混合方法，结合LLMs的广泛覆盖和符号NLU的准确性，用于从常识科学文本中提取数量和因果关系，并取得了优于仅使用符号NLU的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成事实时容易出现幻觉和不一致性；符号NLU系统虽然准确但覆盖面有限且需要专业知识。本研究旨在结合两者的优点，取长补短。

Method: 利用LLMs进行改写和文本简化以扩大覆盖范围，并自动填补知识空白；利用符号NLU生成用于推理和增量学习的结构化关系表示。

Result: 在从常识科学文本中提取和解释数量及因果关系的任务上，本混合方法显著优于仅使用符号NLU的流水线。

Conclusion: 混合方法结合了LLMs的广泛覆盖能力和符号NLU的准确性和可解释性，在提取和解释常识科学文本中的数量和因果关系方面，效果优于单独使用任一方法。

Abstract: Despite the broad applicability of large language models (LLMs), their
reliance on probabilistic inference makes them vulnerable to errors such as
hallucination in generated facts and inconsistent output structure in natural
language understanding (NLU) tasks. By contrast, symbolic NLU systems provide
interpretable understanding grounded in curated lexicons, semantic resources,
and syntactic & semantic interpretation rules. They produce relational
representations that can be used for accurate reasoning and planning, as well
as incremental debuggable learning. However, symbolic NLU systems tend to be
more limited in coverage than LLMs and require scarce knowledge representation
and linguistics skills to extend and maintain. This paper explores a hybrid
approach that integrates the broad-coverage language processing of LLMs with
the symbolic NLU capabilities of producing structured relational
representations to hopefully get the best of both approaches. We use LLMs for
rephrasing and text simplification, to provide broad coverage, and as a source
of information to fill in knowledge gaps more automatically. We use symbolic
NLU to produce representations that can be used for reasoning and for
incremental learning. We evaluate this approach on the task of extracting and
interpreting quantities and causal laws from commonsense science texts, along
with symbolic- and LLM-only pipelines. Our results suggest that our hybrid
method works significantly better than the symbolic-only pipeline.

</details>


### [97] [A Fundamental Algorithm for Dependency Parsing (With Corrections)](https://arxiv.org/abs/2510.19996)
*Michael A. Covington*

Main category: cs.CL

TL;DR: 该算法逐词分析自然语言，将其解析为依赖树，其最坏情况复杂度为 O(n^3)。


<details>
  <summary>Details</summary>
Motivation: 提出一种与人脑处理方式相似的自然语言句子依赖树解析算法。

Method: 该算法逐词操作，一旦一个词可以被连接，就立即将其连接，这与人脑解析器的某些特性相符。

Result: 该算法的最坏情况复杂度为 O(n^3)，但在实际人类语言中，最坏情况仅在 n 较小时出现。

Conclusion: 该算法提供了一种新颖的自然语言解析方法，具有与人脑处理方式相近的特性。

Abstract: This paper presents a fundamental algorithm for parsing natural language
sentences into dependency trees. Unlike phrase-structure (constituency)
parsers, this algorithm operates one word at a time, attaching each word as
soon as it can be attached, corresponding to properties claimed for the parser
in the human brain. Like phrase-structure parsing, its worst-case complexity is
$O(n^3)$, but in human language, the worst case occurs only for small $n$.

</details>


### [98] [Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs](https://arxiv.org/abs/2510.20001)
*Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu*

Main category: cs.CL

TL;DR: LLMs在临床应用中展现出潜力，但现有评估常依赖于简化的问答形式，未能充分反映真实的临床决策过程。本文提出一个结合临床背景和临床问题的统一框架，以更好地表征和评估临床决策任务的难度。研究总结了现有数据集和方法，并扩展了评估维度，强调了未来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有医学数据集（如MedQA）的简化问答形式未能充分代表真实世界的临床决策过程，因此需要一个更全面的框架来评估和指导LLM在临床上的应用。

Method: 提出一个以临床背景和临床问题为两个维度的统一框架，来表征临床决策任务的难度。研究总结了现有数据集和基准的设置，回顾了训练时和测试时的相关方法，并扩展了评估维度（准确性、效率、可解释性），最后指出了开放性挑战。

Result: 现有数据集和方法被归纳到新提出的框架下，并分析了它们在不同难度下的表现。评估维度得到了扩展，超越了单一的准确性指标。

Conclusion: 提出的统一框架有助于明确LLM在临床决策任务中的假设，标准化评估方法，并指导开发更具临床意义的LLM。

Abstract: Large language models (LLMs) show promise for clinical use. They are often
evaluated using datasets such as MedQA. However, Many medical datasets, such as
MedQA, rely on simplified Question-Answering (Q\A) that underrepresents
real-world clinical decision-making. Based on this, we propose a unifying
paradigm that characterizes clinical decision-making tasks along two
dimensions: Clinical Backgrounds and Clinical Questions. As the background and
questions approach the real clinical environment, the difficulty increases. We
summarize the settings of existing datasets and benchmarks along two
dimensions. Then we review methods to address clinical decision-making,
including training-time and test-time techniques, and summarize when they help.
Next, we extend evaluation beyond accuracy to include efficiency,
explainability. Finally, we highlight open challenges. Our paradigm clarifies
assumptions, standardizes comparisons, and guides the development of clinically
meaningful LLMs.

</details>


### [99] [Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training](https://arxiv.org/abs/2510.20002)
*Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris*

Main category: cs.CL

TL;DR: 该研究提出了希腊语嵌入模型（GEM），这是一个新的变压器模型家族，用于解决希腊语，特别是法律领域的自然语言处理挑战。


<details>
  <summary>Details</summary>
Motivation: 现有针对希腊语（尤其是法律等专业领域）的NLP模型存在研究碎片化、架构多样性不足以及依赖有限的上下文长度模型等问题，特别是512个标记的窗口不足以处理长法律文件。

Method: 研究人员构建了几个大规模的希腊语语料库，并采用严格的、基于质量的过滤和预处理方法。在此基础上，他们预训练并评估了多种现代的、以前未应用于希腊语的Transformer架构（如ELECTRA、ConvBERT和ModernBERT），并提出了首个针对法律领域的双语希腊语-英语嵌入模型。

Result: 在下游任务上的广泛实验表明，新模型系列（特别是GEM-RoBERTa和GEM-ConvBERT）的有效性得到了证实，并且显著优于现有基线模型。

Conclusion: 提出的方法和模型（GEM系列）在解决希腊语NLP挑战方面是有效的，尤其是在法律等专业领域，并且在下游任务上取得了优于现有方法的成果。

Abstract: The advancement of natural language processing for morphologically rich,
moderately-resourced languages like Modern Greek is often hindered by a
fragmented research landscape, a lack of architectural diversity and reliance
on limited context-length models. This is particularly true in specialized,
high-value domains such as law, where existing models are frequently confined
to early transformer architectures with a restrictive 512-token window,
insufficient for analyzing long legal documents. To address these challenges,
this paper presents Greek Embedding Models, a new family of transformer models
for Greek language built upon a foundation of extensive, quality-driven data
curation. We detail the construction of several large-scale Greek corpora,
emphasizing a rigorous, quality-based filtering and preprocessing methodology
to create high-value training datasets from both general-domain and specialized
legal sources. On this carefully curated foundation, we pre-train and
systematically evaluate a diverse suite of modern architectures, which has not
previously applied to Greek language, such as ELECTRA, ConvBERT and ModernBERT.
Furthermore, we propose the first bilingual Greek-English Embedding Models
tailored for the legal domain. The extensive experiments on downstream tasks
demonstrate that the new class of models establish the effectiveness of the
proposed approach, highlighting that the GEM-RoBERTa and GEM-ConvBERT models
significantly outperform existing baselines.

</details>


### [100] [Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models](https://arxiv.org/abs/2510.20033)
*David Dukić*

Main category: cs.CL

TL;DR: 本论文通过多任务模型、模型架构修改和生成式监督上下文微调等方法，改进了预训练语言模型在序列标注任务上的迁移学习效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高预训练神经网络语言模型在序列标注任务上的迁移学习能力，以应对不同领域和任务的需求。

Method: 提出了三种改进方法：1. 引入包含额外信号的多任务模型，以提升事件触发词检测的领域迁移能力。2. 修改自回归大语言模型的架构，实现跨层的双向信息流动。3. 构建生成式监督上下文微调框架，利用自回归大语言模型进行序列标注。

Result: 实验证明，通过目标迁移学习范式对预训练神经网络语言模型进行适配，可以在序列标注任务上达到最佳性能。

Conclusion: 预训练神经网络语言模型通过有针对性的迁移学习方法进行适配，能够显著提升在序列标注任务上的表现。

Abstract: This doctoral thesis improves the transfer learning for sequence labeling
tasks by adapting pre-trained neural language models. The proposed improvements
in transfer learning involve introducing a multi-task model that incorporates
an additional signal, a method based on architectural modifications in
autoregressive large language models, and a sequence labeling framework for
autoregressive large language models utilizing supervised in-context
fine-tuning combined with response-oriented adaptation strategies. The first
improvement is given in the context of domain transfer for the event trigger
detection task. The domain transfer of the event trigger detection task can be
improved by incorporating an additional signal obtained from a
domain-independent text processing system into a multi-task model. The second
improvement involves modifying the model's architecture. For that purpose, a
method is proposed to enable bidirectional information flow across layers of
autoregressive large language models. The third improvement utilizes
autoregressive large language models as text generators through a generative
supervised in-context fine-tuning framework. The proposed model, method, and
framework demonstrate that pre-trained neural language models achieve their
best performance on sequence labeling tasks when adapted through targeted
transfer learning paradigms.

</details>


### [101] [ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering](https://arxiv.org/abs/2510.20036)
*Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth*

Main category: cs.CL

TL;DR: LLM代理面临工具冗余和上下文限制问题。ToolScope通过自动合并工具（ToolScopeMerger）和检索相关工具（ToolScopeRetriever）来解决这些问题，提高了工具选择的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理需要依赖外部工具来解决复杂任务，但现实世界中的工具集常常包含冗余的工具，这些工具具有重叠的名称和描述，从而引入歧义并降低了选择的准确性。此外，LLM还面临严格的输入上下文限制，这阻碍了对大型工具集的有效考虑。

Method: 提出ToolScope，包括：1）具有自动纠错功能的ToolScopeMerger，用于自动审核和修复工具合并，减少冗余；2）ToolScopeRetriever，用于为每个查询对工具进行排名和选择最相关的工具，在不牺牲准确性的情况下压缩工具集以适应上下文限制。

Result: 在三个最先进的LLM和三个开源工具使用基准上的评估显示，工具选择准确性提高了8.38%至38.6%。

Conclusion: ToolScope在增强LLM工具使用方面是有效的。

Abstract: Large language model (LLM) agents rely on external tools to solve complex
tasks, but real-world toolsets often contain redundant tools with overlapping
names and descriptions, introducing ambiguity and reducing selection accuracy.
LLMs also face strict input context limits, preventing efficient consideration
of large toolsets. To address these challenges, we propose ToolScope, which
includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and
fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and
select only the most relevant tools for each query, compressing toolsets to fit
within context limits without sacrificing accuracy. Evaluations on three
state-of-the-art LLMs and three open-source tool-use benchmarks show gains of
8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's
effectiveness in enhancing LLM tool use.

</details>


### [102] [From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge](https://arxiv.org/abs/2510.20043)
*Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque*

Main category: cs.CL

TL;DR: LLMs在处理低资源文化（以孟加拉语为例）时存在不足，BLanCK数据集和上下文提示可显著提高其文化知识理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在处理低资源文化时存在不足，尽管多语言基准测试有所进展，但在文化理解方面仍有差距。

Method: 构建了包含民间传统、烹饪艺术和地区方言的孟加拉语文化知识（BLanCK）数据集，并评估了多语言语言模型在处理该数据集上的表现，同时研究了上下文提示对模型性能的影响。

Result: 在非文化类别上，多语言模型表现良好，但在文化知识方面表现不佳。然而，当提供上下文信息时，所有模型的性能都有显著提升。

Conclusion: 上下文感知架构和经过文化策划的训练数据对于提高LLMs在低资源文化方面的表现至关重要。

Abstract: Recent progress in NLP research has demonstrated remarkable capabilities of
large language models (LLMs) across a wide range of tasks. While recent
multilingual benchmarks have advanced cultural evaluation for LLMs, critical
gaps remain in capturing the nuances of low-resource cultures. Our work
addresses these limitations through a Bengali Language Cultural Knowledge
(BLanCK) dataset including folk traditions, culinary arts, and regional
dialects. Our investigation of several multilingual language models shows that
while these models perform well in non-cultural categories, they struggle
significantly with cultural knowledge and performance improves substantially
across all models when context is provided, emphasizing context-aware
architectures and culturally curated training data.

</details>


### [103] [Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training](https://arxiv.org/abs/2510.20059)
*Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami*

Main category: cs.CL

TL;DR: 使用RLAIF和DPO技术，在小规模波斯语数据集上训练出的语言模型在医学问答任务上表现优于使用大规模数据集训练的模型。


<details>
  <summary>Details</summary>
Motivation: 提高小语言模型（特别是波斯语）在医学问答等专业领域的推理能力。

Method: 将医学问答数据集翻译成波斯语，利用RLAIF生成偏好回答对，并结合CoT提示，构建包含正确和错误推理轨迹的数据集，用于DPO训练。

Result: 训练后的模型在波斯语医学推理任务上显著优于使用更大规模数据集训练的基线模型（gaokerena-V）。

Conclusion: 在数据量有限的情况下，以推理为中心的训练方法能有效提升领域特定语言模型的性能。

Abstract: Enhancing reasoning capabilities in small language models is critical for
specialized applications such as medical question answering, particularly in
underrepresented languages like Persian. In this study, we employ Reinforcement
Learning with AI Feedback (RLAIF) and Direct preference optimization (DPO) to
improve the reasoning skills of a general-purpose Persian language model. To
achieve this, we translated a multiple-choice medical question-answering
dataset into Persian and used RLAIF to generate rejected-preferred answer
pairs, which are essential for DPO training. By prompting both teacher and
student models to produce Chain-of-Thought (CoT) reasoning responses, we
compiled a dataset containing correct and incorrect reasoning trajectories.
This dataset, comprising 2 million tokens in preferred answers and 2.5 million
tokens in rejected ones, was used to train a baseline model, significantly
enhancing its medical reasoning capabilities in Persian. Remarkably, the
resulting model outperformed its predecessor, gaokerena-V, which was trained on
approximately 57 million tokens, despite leveraging a much smaller dataset.
These results highlight the efficiency and effectiveness of reasoning-focused
training approaches in developing domain-specific language models with limited
data availability.

</details>


### [104] [CreativityPrism: A Holistic Benchmark for Large Language Model Creativity](https://arxiv.org/abs/2510.20091)
*Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: 该研究提出了一个名为CreativityPrism的评估框架，用于全面评估大型语言模型（LLMs）的创造力，将其分解为质量、新颖性和多样性三个维度，并包含九个任务、三个领域和二十项评估指标。研究评估了17个最先进的模型，发现专有模型和开源模型之间存在显著差距，且同一领域内的任务表现相关性强，不同领域间相关性弱。多样性和质量指标高度相关，而新颖性指标与其他指标相关性较弱，这支持了创造力并非单一能力的假设。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）评估方法在衡量其创造力时存在碎片化、跨领域和任务的差异性，以及定义和测量不一致的问题。本研究旨在建立一个全面的框架来评估LLMs在不同场景下的创造力。

Method: 提出名为CreativityPrism的评估框架，将创造力分解为质量、新颖性和多样性三个维度。该框架包含三个领域（发散思维、创意写作、逻辑推理）、九个任务和二十项评估指标。使用该框架评估了17个最先进的专有和开源LLMs。

Result: 评估结果显示，专有模型和开源模型在创造力评估上存在显著差距。同一领域内的任务表现之间存在高度相关性，而不同领域之间的任务表现相关性较低。多样性和质量维度指标之间存在强相关性，而新颖性维度指标与前两者相关性较弱。

Conclusion: 创造力并非单一能力，一个模型在一个创造力任务或维度上的出色表现并不意味着它在其他方面也同样出色。因此，有必要对LLMs的创造力进行全面的、多维度的评估。Lavender

Abstract: Creativity is often seen as a hallmark of human intelligence. While large
language models (LLMs) are increasingly perceived as producing creative text,
there is still no holistic framework to evaluate their creativity across
diverse scenarios. Existing evaluation methods remain fragmented, with dramatic
variation across domains and tasks, largely due to differing definitions and
measurements of creativity. Inspired by the hypothesis that creativity is not
one fixed idea, we propose CreativityPrism, an evaluation analysis framework
that decomposes creativity into three dimensions: quality, novelty, and
diversity. CreativityPrism incorporates nine tasks, three domains, i.e.,
divergent thinking, creative writing, and logical reasoning, and twenty
evaluation metrics, which measure each dimension in task-specific, unique ways.
We evaluate 17 state-of-the-art (SoTA) proprietary and open-sourced LLMs on
CreativityPrism and analyze the performance correlations among different
metrics and task domains. Our results reveal a notable gap between proprietary
and open-source models. Overall, model performance tends to be highly
correlated across tasks within the same domain and less so across different
domains. Among evaluation dimensions, diversity and quality metrics show strong
correlations - models that perform well on one often excel on the other -
whereas novelty exhibits much weaker correlation with either. These findings
support our hypothesis that strong performance in one creativity task or
dimension does not necessarily generalize to others, underscoring the need for
a holistic evaluation of LLM creativity.

</details>


### [105] [Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning](https://arxiv.org/abs/2510.20098)
*Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar*

Main category: cs.CL

TL;DR: ARTER是一个结合了候选实体生成、基于上下文的评分、自适应路由和选择性推理的结构化流水线，用于实体链接，在不进行深度微调的情况下实现了高性能，同时提高了效率。


<details>
  <summary>Details</summary>
Motivation: 传统实体链接方法依赖大量标注数据和模型微调。现有少量样本方法虽然减少了训练需求，但由于LLM推理成本高昂而效率低下。

Method: ARTER通过结合候选实体生成、基于上下文的评分、自适应路由和选择性推理的结构化流水线来工作。它计算一组互补的信号（基于嵌入和LLM）来区分容易和困难的实体链接案例，然后分别使用计算成本较低的实体链接器（如ReFinED）和更昂贵的LLM推理来处理这些案例。

Result: 在标准基准测试中，ARTER的性能比ReFinED高出+4.47%，在6个数据集中的5个上平均提高了+2.53%。其性能与对所有实体提及都使用LLM推理的流水线相当，但LLM代币数量效率提高了一倍。

Conclusion: ARTER通过其结构化流水线，在实体链接任务中实现了高性能和高效率，有效降低了对LLM的计算依赖。

Abstract: Entity Linking (EL) has traditionally relied on large annotated datasets and
extensive model fine-tuning. While recent few-shot methods leverage large
language models (LLMs) through prompting to reduce training requirements, they
often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER
(Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline
that achieves high performance without deep fine-tuning by strategically
combining candidate generation, context-based scoring, adaptive routing, and
selective reasoning. ARTER computes a small set of complementary signals(both
embedding and LLM-based) over the retrieved candidates to categorize contextual
mentions into easy and hard cases. The cases are then handled by a
low-computational entity linker (e.g. ReFinED) and more expensive targeted
LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms
ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets,
and performs comparably to pipelines using LLM-based reasoning for all
mentions, while being as twice as efficient in terms of the number of LLM
tokens.

</details>


### [106] [BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation](https://arxiv.org/abs/2510.20151)
*Haoyuan Li,Zhengyuan Shen,Sullam Jeoung,Yueyan Chen,Jiayu Li,Qi Zhu,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.CL

TL;DR: BoundRL通过联合进行长结构化文本的令牌级文本分割和标签预测来解决复杂文本分割问题，并通过强化学习进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有文本分割方法难以处理包含表格、代码片段和占位符等非文本元素的复杂结构化文本。

Method: BoundRL通过生成起始令牌序列来重建文本，并通过强化学习（RLVR）进行优化，使用专门设计的奖励函数来保证重建保真度和语义对齐。为了缓解熵崩溃，还采用了中间候选扰动策略。

Result: 在LLM应用的复杂提示上进行的实验表明，BoundRL能够让小型语言模型（1.7B参数）的表现优于大型模型的少样本提示。RLVR的性能优于监督微调，并且结合中间候选方法可以进一步提升性能和泛化能力。

Conclusion: BoundRL是一种有效的方法，能够处理复杂的结构化文本分割任务，并通过RLVR和中间候选策略进行优化，在性能和泛化能力方面表现出色。

Abstract: As structured texts become increasingly complex across diverse domains --
from technical reports to generative AI prompts -- the need for text
segmentation into semantically meaningful components becomes critical. Such
texts often contain elements beyond plain language, including tables, code
snippets, and placeholders, which conventional sentence- or paragraph-level
segmentation methods cannot handle effectively. To address this challenge, we
propose BoundRL, a novel and efficient approach that jointly performs
token-level text segmentation and label prediction for long structured texts.
Instead of generating complete contents for each segment, it generates only a
sequence of starting tokens and reconstructs the complete contents by locating
these tokens within the original texts, thereby reducing inference costs by
orders of magnitude and minimizing hallucination. To adapt the model for the
output format, BoundRL~performs reinforcement learning with verifiable rewards
(RLVR) with a specifically designed reward that jointly optimizes document
reconstruction fidelity and semantic alignment. To mitigate entropy collapse,
it further constructs intermediate candidates by systematically perturbing a
fraction of generated sequences of segments to create stepping stones toward
higher-quality solutions. To demonstrate BoundRL's effectiveness on
particularly challenging structured texts, we focus evaluation on complex
prompts used for LLM applications. Experiments show that BoundRL enables small
language models (1.7B parameters) to outperform few-shot prompting of much
larger models. Moreover, RLVR with our designed reward yields significant
improvements over supervised fine-tuning, and incorporating intermediate
candidates further improves both performance and generalization.

</details>


### [107] [Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?](https://arxiv.org/abs/2510.20154)
*Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi*

Main category: cs.CL

TL;DR: 大型语言模型在零样本立场检测任务中表现出对社会群体的刻板印象，这受到方言和文本复杂度等因素的影响。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在立场检测任务中对社会群体的偏见，这是一个被忽视但重要的研究领域，因为立场检测任务常与政治倾向相关。

Method: 通过自动标注预先存在的立场检测数据集的方言和文本复杂度属性，以研究这些属性是否会影响模型的立场检测决策。

Result: 大型语言模型在立场检测任务中表现出显著的刻板印象，例如将支持大麻的观点与低文本复杂度相关联，并将非裔美国人的方言与反对唐纳德·特朗普的立场相关联。

Conclusion: 大型语言模型在零样本立场检测任务中存在刻板印象偏见，这些偏见受到方言和文本复杂度等因素的影响。

Abstract: Large Language Models inherit stereotypes from their pretraining data,
leading to biased behavior toward certain social groups in many Natural
Language Processing tasks, such as hateful speech detection or sentiment
analysis. Surprisingly, the evaluation of this kind of bias in stance detection
methods has been largely overlooked by the community. Stance Detection involves
labeling a statement as being against, in favor, or neutral towards a specific
target and is among the most sensitive NLP tasks, as it often relates to
political leanings. In this paper, we focus on the bias of Large Language
Models when performing stance detection in a zero-shot setting. We
automatically annotate posts in pre-existing stance detection datasets with two
attributes: dialect or vernacular of a specific group and text
complexity/readability, to investigate whether these attributes influence the
model's stance detection decisions. Our results show that LLMs exhibit
significant stereotypes in stance detection tasks, such as incorrectly
associating pro-marijuana views with low text complexity and African American
dialect with opposition to Donald Trump.

</details>


### [108] [DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking](https://arxiv.org/abs/2510.20168)
*Tian Lan,Bin Zhu,Qianghuai Jia,Junyang Ren,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 当前的搜索代理在深层推理和广域信息收集方面存在不足，为此我们提出了DeepWideSearch基准，以评估代理的深度和宽度整合能力。该基准包含220个问题，涵盖15个领域，实验表明现有最先进的代理成功率仅为2.39%，并揭示了代理在反思、内部知识依赖、检索不足和上下文溢出等方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的搜索代理无法同时进行多跳检索的深层推理和大规模信息收集，这在市场分析和业务开发等现实世界应用中是一个关键缺陷。

Method: 提出了DeepWideSearch基准，包含220个问题，涵盖15个领域，用于评估代理在信息检索的深度和宽度方面的整合能力。通过两种方法改造现有数据集来创建此基准。

Result: 现有的最先进代理在DeepWideSearch上的平均成功率仅为2.39%，表明在信息检索任务中整合深度和宽度搜索存在巨大挑战。错误分析揭示了四个失败模式：缺乏反思、过度依赖内部知识、检索不足和上下文溢出。

Conclusion: DeepWideSearch基准突显了当前信息检索代理在整合深度和宽度方面的不足，暴露了关键的局限性，并公开发布该基准以促进未来研究。

Abstract: Current search agents fundamentally lack the ability to simultaneously
perform \textit{deep} reasoning over multi-hop retrieval and
\textit{wide}-scale information collection-a critical deficiency for real-world
applications like comprehensive market analysis and business development. To
bridge this gap, we introduce DeepWideSearch, the first benchmark explicitly
designed to evaluate agents to integrate depth and width in information
seeking. In DeepWideSearch, agents must process a large volume of data, each
requiring deep reasoning over multi-hop retrieval paths. Specifically, we
propose two methods to converse established datasets, resulting in a curated
collection of 220 questions spanning 15 diverse domains. Extensive experiments
demonstrate that even state-of-the-art agents achieve only 2.39% average
success rate on DeepWideSearch, highlighting the substantial challenge of
integrating depth and width search in information-seeking tasks. Furthermore,
our error analysis reveals four failure modes: lack of reflection, overreliance
on internal knowledge, insufficient retrieval, and context overflow-exposing
key limitations in current agent architectures. We publicly release
DeepWideSearch to catalyze future research on more capable and robust
information-seeking agents.

</details>


### [109] [Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding](https://arxiv.org/abs/2510.20176)
*Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang*

Main category: cs.CL

TL;DR: Mixture-of-Minds是一个多代理框架，通过将表格推理分解为规划、编码和回答三个专业角色，并结合代码执行进行精确的表格操作，解决了现有LLM在表格理解方面存在的算术错误和语义理解不足的问题。该框架还采用基于MCTS的自我改进训练方法，通过强化学习进行优化，在TableBench测试中取得了62.13%的优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在表格理解和推理方面虽然有潜力，但存在算术错误和幻觉（fine-tuning方法）或依赖于刚性模式且缺乏语义理解（工具方法）的局限性。因此，需要一种能够整合强大推理能力和可靠表格处理能力的解决方案。

Method: 提出了一种名为Mixture-of-Minds的多代理框架，将表格推理任务分解为三个专业角色：规划（planning）、编码（coding）和回答（answering）。每个代理专注于任务的特定方面，并利用代码执行进行精确的表格操作。此外，还引入了一个自我改进的训练框架，利用蒙特卡洛树搜索（MCTS）进行模拟，生成伪黄金轨迹，并通过强化学习（RL）优化代理。

Result: 在TableBench基准测试中达到了62.13%的准确率，超过了OpenAI-o4-mini-high的性能。

Conclusion: 结合结构化的多代理工作流和强化学习是推进表格理解能力的有效途径。Mixture-of-Minds框架通过其专业化的代理和自我改进机制，展示了在表格推理任务上的巨大潜力。

Abstract: Understanding and reasoning over tables is a critical capability for many
real-world applications. Large language models (LLMs) have shown promise on
this task, but current approaches remain limited. Fine-tuning based methods
strengthen language reasoning; yet they are prone to arithmetic errors and
hallucination. In contrast, tool-based methods enable precise table
manipulation but rely on rigid schemas and lack semantic understanding. These
complementary drawbacks highlight the need for approaches that integrate robust
reasoning with reliable table processing. In this work, we propose
Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into
three specialized roles: planning, coding, and answering. This design enables
each agent to focus on a specific aspect of the task while leveraging code
execution for precise table manipulation. Building on this workflow, we
introduce a self-improvement training framework that employs Monte Carlo Tree
Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents
with reinforcement learning (RL). Extensive experiments show that
Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and
surpassing OpenAI-o4-mini-high. These results demonstrate the promise of
combining structured multi-agent workflows with RL to advance table
understanding.

</details>


### [110] [Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models](https://arxiv.org/abs/2510.20198)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在处理文本输入时的空间推理能力有限，在任务复杂度增加时性能急剧下降。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在文本输入上的空间推理能力，并了解其在结构化网格环境中的空间理解和计算能力。

Method: 通过五个旨在探测模型空间理解和计算能力的任务来评估LLMs，包括象限识别、几何变换、距离评估、单词搜索和图块滑动。通过增加网格维度来扩展任务复杂度。

Result: LLMs在处理低复杂度、小尺寸任务时表现尚可，但随着复杂度的增加，准确率平均下降42.7%，最高可达84%。准确率超过50%的任务下降至少48%。

Conclusion: LLMs在处理文本时的空间推理能力存在显著局限性，尤其是在任务复杂度增加时。这表明其底层架构在空间表征方面不够强大，语言推理与空间推理之间存在差距。

Abstract: This paper explores the spatial reasoning capability of large language models
(LLMs) over textual input through a suite of five tasks aimed at probing their
spatial understanding and computational abilities. The models were tested on
both fundamental spatial reasoning and multi-step problem-solving within
structured grid-based environments using tasks such as quadrant identification,
geometric transformations, distance evaluation, word searches, and tile
sliding. Each task was scaled in complexity through increasing grid dimensions,
requiring models to extend beyond simple pattern recognition into abstract
spatial reasoning. Our results reveal that while LLMs demonstrate moderate
success in all tasks with small complexity and size, performance drops off
rapidly as scale increases, with an average loss in accuracy of 42.7%, and
reaching as high as 84%. Every test that began with over 50% accuracy showed a
loss of at least 48%, illustrating the consistent nature of the deterioration.
Furthermore, their struggles with scaling complexity hint at a lack of robust
spatial representations in their underlying architectures. This paper
underscores the gap between linguistic and spatial reasoning in LLMs, offering
insights into their current limitations, and laying the groundwork for future
integrative benchmarks at the intersection of language and geometry.

</details>


### [111] [Decoding-Free Sampling Strategies for LLM Marginalization](https://arxiv.org/abs/2510.20208)
*David Pohl,Marco Cognetta,Junyoung Lee,Naoaki Okazaki*

Main category: cs.CL

TL;DR: Modern language models often evaluate text based on a single tokenization, but marginalization (considering all possible tokenizations) is a more accurate approach. This paper proposes decoding-free sampling strategies that approximate marginalization without requiring text generation, offering significant speedups and comparable accuracy for downstream tasks.


<details>
  <summary>Details</summary>
Motivation: Current methods for evaluating language models using subword tokenization are limited because they only consider a single tokenization, ignoring other valid representations of the same text. While marginalization (considering all possible tokenizations) is a better approach, it's computationally expensive. Existing approximation methods like sampling require expensive text generation for each sample, limiting accuracy within a given runtime. This work is motivated by the need for a more efficient and accurate method to approximate marginalization.

Method: The paper investigates decoding-free sampling strategies for approximating the marginal probability of text tokenizations. These strategies do not require text generation from the language model, relying instead on inexpensive, model- and tokenizer-agnostic sampling methods. The researchers explore various strategies to find those that offer good approximation quality and speed.

Result: The study found that decoding-free sampling strategies provide sufficiently accurate marginal estimates for several open models. These strategies achieve this accuracy at a significantly lower runtime cost compared to traditional sampling methods that involve text generation. The paper demonstrates the effectiveness of these strategies on downstream inference tasks.

Conclusion: Decoding-free sampling strategies offer a computationally efficient and accurate way to approximate the marginal probability of text tokenizations for modern language models. This approach overcomes the limitations of single-tokenization evaluation and sampling-based marginalization, providing a practical solution for improving LLM inference with reduced runtime costs.

Abstract: Modern language models operate on subword-tokenized text in order to make a
trade-off between model size, inference speed, and vocabulary coverage. A side
effect of this is that, during inference, models are evaluated by measuring the
probability of only the specific tokenization produced as the output, despite
there being many possible ways to represent the same text with a subword
vocabulary. Recent studies have argued instead for evaluating LLMs by
marginalization - the probability mass of all tokenizations of a given text.
  Marginalization is difficult due to the number of possible tokenizations of a
text, so often approximate marginalization is done via sampling. However, a
downside of sampling is that an expensive generation step must be performed by
the LLM for each sample, which limits the number of samples that can be
acquired given a runtime budget, and therefore also the accuracy of the
approximation. Since computing the probability of a sequence given the
tokenization is relatively cheap compared to actually generating it, we
investigate sampling strategies that are decoding-free - they require no
generation from the LLM, instead relying entirely on extremely cheap sampling
strategies that are model and tokenizer agnostic.
  We investigate the approximation quality and speed of decoding-free sampling
strategies for a number of open models to find that they provide sufficiently
accurate marginal estimates at a small fraction of the runtime cost and
demonstrate its use on a set of downstream inference tasks.

</details>


### [112] [Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders](https://arxiv.org/abs/2510.20239)
*Filippo Cenacchi,Deborah Richards,Longbing Cao*

Main category: cs.CL

TL;DR: 该研究提出了一种统一的三模态情感框架，用于评估抑郁症和PTSD的严重程度，并提供跨疾病的诊断支持。


<details>
  <summary>Details</summary>
Motivation: 现有的抑郁症和PTSD自动评估方法通常是二元的且仅针对单一疾病，无法满足临床上对跨疾病严重程度评估和决策支持的需求。

Method: 该框架整合了访谈文本（使用Transformer嵌入）、音频（使用Log Mel统计量和Delta）以及面部信号（使用动作单元、注视、头部和姿态描述符），并通过校准的 late fusion 分类器进行融合，以输出抑郁症（PHQ-8）和PTSD的评估等级。

Result: 在DAIC语料库上的实验结果表明，该三模态融合方法优于单一模态或消融基线，在准确性和加权F1分数上与最强的单一模态基线相当，同时提高了决策曲线的效用，并增强了在模态缺失或噪声情况下的鲁棒性。对于PTSD，融合模型能减少回归误差并提高类别一致性。错误主要集中在相邻的严重程度等级之间，而极端等级的识别则很可靠。消融实验表明，文本信息对抑郁症严重程度的贡献最大，而音频和面部线索对PTSD的诊断至关重要。

Conclusion: 该研究提出的三模态情感融合方法能够进行抑郁症和PTSD的严重程度评估，并提供跨疾病的诊断支持和可解释性，有助于临床决策，并且评估方法是可复现的。

Abstract: Depression and post traumatic stress disorder (PTSD) often co-occur with
connected symptoms, complicating automated assessment, which is often binary
and disorder specific. Clinically useful diagnosis needs severity aware cross
disorder estimates and decision support explanations. Our unified tri modal
affective severity framework synchronizes and fuses interview text with
sentence level transformer embeddings, audio with log Mel statistics with
deltas, and facial signals with action units, gaze, head and pose descriptors
to output graded severities for diagnosing both depression (PHQ-8; 5 classes)
and PTSD (3 classes). Standardized features are fused via a calibrated late
fusion classifier, yielding per disorder probabilities and feature-level
attributions. This severity aware tri-modal affective fusion approach is demoed
on multi disorder concurrent depression and PTSD assessment. Stratified cross
validation on DAIC derived corpora outperforms unimodal/ablation baselines. The
fused model matches the strongest unimodal baseline on accuracy and weighted
F1, while improving decision curve utility and robustness under noisy or
missing modalities. For PTSD specifically, fusion reduces regression error and
improves class concordance. Errors cluster between adjacent severities; extreme
classes are identified reliably. Ablations show text contributes most to
depression severity, audio and facial cues are critical for PTSD, whereas
attributions align with linguistic and behavioral markers. Our approach offers
reproducible evaluation and clinician in the loop support for affective
clinical decision making.

</details>


### [113] [Context-level Language Modeling by Learning Predictive Context Embeddings](https://arxiv.org/abs/2510.20280)
*Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang*

Main category: cs.CL

TL;DR: ContextLM通过引入“下一上下文预测”目标来增强LLM的预训练，以捕捉更高层次的语义结构和长距离上下文关系，并在不影响现有评估方法的情况下提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的Next-token prediction（NTP）限制了LLM捕捉更高层次语义结构和长距离上下文关系的能力。

Method: 提出ContextLM框架，在标准预训练中加入“下一上下文预测”目标，利用来自未来token块的误差信号来学习多token上下文的预测表示。

Result: 在GPT2和Pythia模型系列（最大1.5B参数）的实验中，ContextLM在困惑度和下游任务性能方面均取得了持续的改进。

Conclusion: 下一上下文预测为更强的语言建模提供了一条可扩展且高效的途径，能够在几乎没有额外计算开销的情况下，实现更好的长距离连贯性和更有效的注意力分配。

Abstract: Next-token prediction (NTP) is the cornerstone of modern large language
models (LLMs) pretraining, driving their unprecedented capabilities in text
generation, reasoning, and instruction following. However, the token-level
prediction limits the model's capacity to capture higher-level semantic
structures and long-range contextual relationships. To overcome this
limitation, we introduce \textbf{ContextLM}, a framework that augments standard
pretraining with an inherent \textbf{next-context prediction} objective. This
mechanism trains the model to learn predictive representations of multi-token
contexts, leveraging error signals derived from future token chunks. Crucially,
ContextLM achieves this enhancement while remaining fully compatible with the
standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity).
Extensive experiments on the GPT2 and Pythia model families, scaled up to
$1.5$B parameters, show that ContextLM delivers consistent improvements in both
perplexity and downstream task performance. Our analysis indicates that
next-context prediction provides a scalable and efficient pathway to stronger
language modeling, yielding better long-range coherence and more effective
attention allocation with minimal computational overhead.

</details>


### [114] [Citation Failure: Definition, Analysis and Efficient Mitigation](https://arxiv.org/abs/2510.20303)
*Jan Buchmann,Iryna Gurevych*

Main category: cs.CL

TL;DR: LLM-based RAG系统中的引用本应简化响应验证，但当模型生成有用响应但未能引用完整证据时，会出现引用失败。本研究提出将引用失败与响应失败（响应本身有缺陷，无法引用完整证据）区分开。为解决引用失败问题，本研究采取两步法：(1) 研究引用失败发生的原因；(2) 研究如何缓解引用失败。在第一步中，我们通过研究响应与证据之间的关系对引用质量的影响，扩展了 prior work。我们引入了 CITECONTROL 基准，该基准系统地改变了这种关系以分析失败模式。实验表明，随着关系复杂性的增加，失败会增加，并提出结合不同的引用方法可以提高性能，从而引出第二步。为有效提高 LLM 引用能力，我们提出了 CITENTION 框架，该框架集成了生成式、基于注意力和基于检索式的方法。结果表明，CITECONTROL 和迁移设置中的引用能力得到了显著提高。我们公开了数据和代码。


<details>
  <summary>Details</summary>
Motivation: LLM-based RAG 系统中的引用本应简化响应验证，但引用失败（模型生成有用响应但未能引用完整证据）问题阻碍了这一目标。因此，需要研究引用失败的原因并提出缓解方法。

Method: 本研究提出将引用失败与响应失败区分开，并采用两步法解决引用失败问题：(1) 通过引入 CITECONTROL 基准，系统地改变响应与证据之间的关系，研究引用失败的发生模式；(2) 提出 CITENTION 框架，集成生成式、基于注意力和基于检索式的方法来提高 LLM 的引用能力。

Result: 实验表明，响应与证据之间的关系越复杂，引用失败的概率越高。CITENTION 框架在 CITECONTROL 基准和迁移设置中都显著提高了引用能力。

Conclusion: 引用失败是 LLM-based RAG 系统中的一个重要问题，通过研究响应与证据的关系以及集成多种引用方法，可以有效缓解该问题并提高引用质量。

Abstract: Citations from LLM-based RAG systems are supposed to simplify response
verification. However, this does not hold for citation failure, when a model
generates a helpful response, but fails to cite complete evidence. In contrast
to previous work, we propose to disentangle this from response failure, where
the response itself is flawed, and citing complete evidence is impossible. To
address citation failure, this work follows a two-step approach: (1) We study
when citation failure occurs and (2) how it can be mitigated. For step 1, we
extend prior work by investigating how the relation between response and
evidence affects citation quality. We introduce CITECONTROL, a benchmark that
systematically varies this relation to analyze failure modes. Experiments show
that failures increase with relational complexity and suggest that combining
citation methods could improve performance, motivating step 2. To improve LLM
citation efficiently, we propose CITENTION, a framework integrating generative,
attention-based, and retrieval-based methods. Results demonstrate substantial
citation improvements on CITECONTROL and in transfer settings. We make our data
and code publicly available.

</details>


### [115] [Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering](https://arxiv.org/abs/2510.20304)
*Lei Tang,Wei Zhou,Mohsen Mesgar*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Process reward models (PRMs) improve complex reasoning in large language
models (LLMs) by grading candidate solutions step-by-step and selecting answers
via aggregated step scores. While effective in domains such as mathematics,
their applicability to tasks involving semi-structured data, like table
question answering (TQA) remains unexplored. TQA poses unique challenges for
PRMs, including abundant irrelevant information, loosely connected reasoning
steps, and domain-specific reasoning. This work presents the first systematic
study of PRMs for TQA. We evaluate state-of-the-art generative PRMs on TQA from
both answer and step perspectives. Results show that PRMs that combine textual
and code verification can aid solution selection but struggle to generalize to
out-of-domain data. Analysis reveals a weak correlation between performance in
step-level verification and answer accuracy, possibly stemming from weak step
dependencies and loose causal links. Our findings highlight limitations of
current PRMs on TQA and offer valuable insights for building more robust,
process-aware verifiers.

</details>


### [116] [Teaching Language Models to Reason with Tools](https://arxiv.org/abs/2510.20342)
*Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu*

Main category: cs.CL

TL;DR: CoRT是一个训练框架，旨在提高大型推理模型（LRMs）使用代码解释器（CIs）解决数学问题的效率和准确性，通过“提示工程”生成数据，并结合强化学习进行优化。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在处理复杂数学问题时存在效率和准确性不足的问题，而集成代码解释器（CIs）会引发模型内部概率推理与外部确定性知识之间的冲突。

Method: 提出CoRT（Code-Optimized Reasoning Training）训练框架，使用“提示工程”合成数据，并通过拒绝采样和强化学习优化模型与CI的交互，在推理路径中注入多样化的提示。

Result: 在五个具有挑战性的数学推理数据集上，CoRT将DeepSeek-R1-Distill-Qwen-32B和DeepSeek-R1-Distill-Qwen-1.5B模型的性能分别提高了4%和8%。同时，与纯自然语言推理基线相比，32B模型的令牌使用量减少了约30%，1.5B模型的令牌使用量减少了约50%。

Conclusion: CoRT框架能够有效地训练LRMs利用CIs解决数学问题，显著提高了模型的准确性和效率。

Abstract: Large reasoning models (LRMs) like OpenAI-o1 have shown impressive
capabilities in natural language reasoning. However, these models frequently
demonstrate inefficiencies or inaccuracies when tackling complex mathematical
operations. While integrating computational tools such as Code Interpreters
(CIs) offers a promising solution, it introduces a critical challenge: a
conflict between the model's internal, probabilistic reasoning and the
external, deterministic knowledge provided by the CI, which often leads models
to unproductive deliberation. To overcome this, we introduce CoRT
(Code-Optimized Reasoning Training), a post-training framework designed to
teach LRMs to effectively utilize CIs. We propose \emph{Hint-Engineering}, a
new data synthesis strategy that strategically injects diverse hints at optimal
points within reasoning paths. This approach generates high-quality,
code-integrated reasoning data specifically tailored to optimize LRM-CI
interaction. Using this method, we have synthesized 30 high-quality samples to
post-train models ranging from 1.5B to 32B parameters through supervised
fine-tuning. CoRT further refines the multi-round interleaving of external CI
usage and internal thinking by employing rejection sampling and reinforcement
learning. Our experimental evaluations demonstrate CoRT's effectiveness,
yielding absolute improvements of 4\% and 8\% on DeepSeek-R1-Distill-Qwen-32B
and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging
mathematical reasoning datasets. Moreover, CoRT significantly enhances
efficiency, reducing token usage by approximately 30\% for the 32B model and
50\% for the 1.5B model compared to pure natural language reasoning baselines.
The models and code are available at: https://github.com/ChengpengLi1003/CoRT.

</details>


### [117] [Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models](https://arxiv.org/abs/2510.20351)
*Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei*

Main category: cs.CL

TL;DR: LLMs' performance on tabular reasoning tasks may be inflated due to dataset contamination, especially when datasets have semantic cues.


<details>
  <summary>Details</summary>
Motivation: Investigate dataset contamination in LLM evaluations on structured data, as current assessments may overlook this confound.

Method: Conduct controlled probing experiments on widely used tabular benchmarks (Adult Income, Titanic, etc.) with and without semantic cues to observe LLM performance.

Result: LLM performance significantly drops to near-random levels when semantic cues (meaningful column names, interpretable values) are removed or randomized, indicating contamination effects are tied to these cues. Conversely, performance is high when cues are present.

Conclusion: LLMs' apparent tabular reasoning ability might stem from memorization of public datasets rather than true generalization. Evaluation protocols need refinement to mitigate semantic leakage and accurately assess reasoning capabilities.

Abstract: Large Language Models (LLMs) are increasingly evaluated on their ability to
reason over structured data, yet such assessments often overlook a crucial
confound: dataset contamination. In this work, we investigate whether LLMs
exhibit prior knowledge of widely used tabular benchmarks such as Adult Income,
Titanic, and others. Through a series of controlled probing experiments, we
reveal that contamination effects emerge exclusively for datasets containing
strong semantic cues-for instance, meaningful column names or interpretable
value categories. In contrast, when such cues are removed or randomized,
performance sharply declines to near-random levels. These findings suggest that
LLMs' apparent competence on tabular reasoning tasks may, in part, reflect
memorization of publicly available datasets rather than genuine generalization.
We discuss implications for evaluation protocols and propose strategies to
disentangle semantic leakage from authentic reasoning ability in future LLM
assessments.

</details>


### [118] [FreeChunker: A Cross-Granularity Chunking Framework](https://arxiv.org/abs/2510.20356)
*Wenxuan Zhang,Yuan-Hao Jiang,Yonghe Wu*

Main category: cs.CL

TL;DR: FreeChunker是一个跨粒度编码框架，它将句子视为原子单元，并从静态分块转向支持任意句子组合的灵活检索，从而提高RAG系统的检索性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG分块策略依赖于静态边界识别，难以适应不同的查询需求。

Method: FreeChunker将句子作为原子单元，从静态分块转向灵活检索，支持任意句子组合，降低了语义边界检测的计算开销，并提高了对复杂查询的适应性。

Result: 在LongBench V2上的实验评估表明，FreeChunker的检索性能优于传统分块方法，并且在计算效率方面显著优于现有方法。

Conclusion: FreeChunker通过其创新的跨粒度编码框架，有效解决了传统RAG分块方法的局限性，实现了检索性能和计算效率的双重提升。

Abstract: Chunking strategies significantly impact the effectiveness of
Retrieval-Augmented Generation (RAG) systems. Existing methods operate within
fixed-granularity paradigms that rely on static boundary identification,
limiting their adaptability to diverse query requirements. This paper presents
FreeChunker, a Cross-Granularity Encoding Framework that fundamentally
transforms the traditional chunking paradigm: the framework treats sentences as
atomic units and shifts from static chunk segmentation to flexible retrieval
supporting arbitrary sentence combinations. This paradigm shift not only
significantly reduces the computational overhead required for semantic boundary
detection but also enhances adaptability to complex queries. Experimental
evaluation on LongBench V2 demonstrates that FreeChunker achieves superior
retrieval performance compared to traditional chunking methods, while
significantly outperforming existing approaches in computational efficiency.

</details>


### [119] [Dialogue Is Not Enough to Make a Communicative BabyLM (But Neither Is Developmentally Inspired Reinforcement Learning)](https://arxiv.org/abs/2510.20358)
*Francesca Padovani,Bastian Bunzeck,Manar Ali,Omar Momen,Arianna Bisazza,Hendrik Buschmeier,Sina Zarrieß*

Main category: cs.CL

TL;DR: 在此处输入tl;dr


<details>
  <summary>Details</summary>
Motivation: 我们研究了一个问题：仅使用对话数据进行预训练是否能产生在形式和功能上都合适的、小型语言模型。

Method: 基于预训练好的llamalogue模型，我们采用了多种微调策略来强制模型生成“更具交流性”的文本。

Result: 尽管我们的模型在大多数标准的BabyLM基准测试中表现不佳，但在最小对设置下的对话延续预测任务中表现出色。PPO微调对我们的模型产生了混合甚至负面影响，而DPO微调则进一步提高了它们在自定义对话基准测试上的性能。

Conclusion: 在此处输入结论

Abstract: We investigate whether pre-training exclusively on dialogue data results in
formally and functionally apt small language models. Based on this pre-trained
llamalogue model, we employ a variety of fine-tuning strategies to enforce
"more communicative" text generations by our models. Although our models
underperform on most standard BabyLM benchmarks, they excel at dialogue
continuation prediction in a minimal pair setting. While PPO fine-tuning has
mixed to adversarial effects on our models, DPO fine-tuning further improves
their performance on our custom dialogue benchmark.

</details>


### [120] [The Impact of Negated Text on Hallucination with Large Language Models](https://arxiv.org/abs/2510.20375)
*Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim*

Main category: cs.CL

TL;DR: LLM在处理否定文本时难以有效检测幻觉，可能导致不一致的判断。本研究提出了NegHalu数据集，并通过分析LLM的内部状态来揭示其挑战。


<details>
  <summary>Details</summary>
Motivation: 探究否定文本对大型语言模型（LLM）幻觉检测的影响，以及LLM是否能识别否定引起的上下文变化。

Method: 设计NegHalu数据集，通过重构现有数据集引入否定表达；在NegHalu数据集上进行实验，分析LLM在处理否定输入时的表现，并追踪其内部状态。

Result: LLM在检测否定文本中的幻觉时表现不佳，常做出逻辑不一致或不忠实的判断；揭示了缓解LLM在否定输入方面潜在影响的挑战。

Conclusion: LLM在识别和处理否定文本中的幻觉方面存在显著困难，这对其可靠性构成了挑战。

Abstract: Recent studies on hallucination in large language models (LLMs) have been
actively progressing in natural language processing. However, the impact of
negated text on hallucination with LLMs remains largely unexplored. In this
paper, we set three important yet unanswered research questions and aim to
address them. To derive the answers, we investigate whether LLMs can recognize
contextual shifts caused by negation and still reliably distinguish
hallucinations comparable to affirmative cases. We also design the NegHalu
dataset by reconstructing existing hallucination detection datasets with
negated expressions. Our experiments demonstrate that LLMs struggle to detect
hallucinations in negated text effectively, often producing logically
inconsistent or unfaithful judgments. Moreover, we trace the internal state of
LLMs as they process negated inputs at the token level and reveal the
challenges of mitigating their unintended effects.

</details>


### [121] [VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation](https://arxiv.org/abs/2510.20381)
*Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 该论文介绍了VLSP 2025 MLQA-TSR，一个关于越南交通法规的多模态法律问题解答共享任务。


<details>
  <summary>Details</summary>
Motivation: 推动越南多模态法律文本处理的研究，并为构建和评估多模态法律领域的智能系统（特别是越南交通法规）提供基准数据集。

Method: 该任务包含两个子任务：多模态法律检索和多模态问题解答。

Result: 在VLSP 2025 MLQA-TSR上报告的最佳结果是：多模态法律检索的F2得分达到64.55%，多模态问题解答的准确率达到86.30%。

Conclusion: VLSP 2025 MLQA-TSR是一个多模态法律问题解答任务，旨在促进越南法律文本处理的研究，并为相关智能系统的开发提供评估基准。

Abstract: This paper presents the VLSP 2025 MLQA-TSR - the multimodal legal question
answering on traffic sign regulation shared task at VLSP 2025. VLSP 2025
MLQA-TSR comprises two subtasks: multimodal legal retrieval and multimodal
question answering. The goal is to advance research on Vietnamese multimodal
legal text processing and to provide a benchmark dataset for building and
evaluating intelligent systems in multimodal legal domains, with a focus on
traffic sign regulation in Vietnam. The best-reported results on VLSP 2025
MLQA-TSR are an F2 score of 64.55% for multimodal legal retrieval and an
accuracy of 86.30% for multimodal question answering.

</details>


### [122] [NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew](https://arxiv.org/abs/2510.20386)
*Shaltiel Shmidman,Avi Shmidman,Moshe Koppel*

Main category: cs.CL

TL;DR: NeoDictaBERT和NeoDictaBERT-bilingual是基于NeoBERT架构的BERT风格模型，专门针对希伯来语文本进行了优化，并在希伯来语基准测试中取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有BERT模型虽然性能优越，但其架构相比Llama3和Qwen3等新模型已显过时。需要更新模型架构以跟上NLP领域的进展。

Method: 在NeoBERT的架构基础上，使用相同的训练方法，但专门针对希伯来语文本进行训练，并推出了一个双语版本（NeoDictaBERT-bilingual）。

Result: NeoDictaBERT和NeoDictaBERT-bilingual在大多数希伯来语基准测试中表现优于现有模型。NeoDictaBERT-bilingual在检索任务上表现尤为突出，超越了同等规模的多语言模型。

Conclusion: NeoDictaBERT和NeoDictaBERT-bilingual为希伯来语自然语言处理（NLP）提供了强大的基础，并已发布给社区以促进相关研究和发展。

Abstract: Since their initial release, BERT models have demonstrated exceptional
performance on a variety of tasks, despite their relatively small size
(BERT-base has ~100M parameters). Nevertheless, the architectural choices used
in these models are outdated compared to newer transformer-based models such as
Llama3 and Qwen3. In recent months, several architectures have been proposed to
close this gap. ModernBERT and NeoBERT both show strong improvements on English
benchmarks and significantly extend the supported context window. Following
their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual:
BERT-style models trained using the same architecture as NeoBERT, with a
dedicated focus on Hebrew texts. These models outperform existing ones on
almost all Hebrew benchmarks and provide a strong foundation for downstream
tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on
retrieval tasks, outperforming other multilingual models of similar size. In
this paper, we describe the training process and report results across various
benchmarks. We release the models to the community as part of our goal to
advance research and development in Hebrew NLP.

</details>


### [123] [Teacher Demonstrations in a BabyLM's Zone of Proximal Development for Contingent Multi-Turn Interaction](https://arxiv.org/abs/2510.20411)
*Suchir Salhan,Hongyi Gu,Donya Rooein,Diana Galvan-Sosa,Gabrielle Gaudeau,Andrew Caines,Zheng Yuan,Paula Buttery*

Main category: cs.CL

TL;DR: ContingentChat是一个教师-学生框架，用于在BabyLM上进行多轮对话的应急性进行基准测试和改进，取得了比适应性教师解码策略更好的效果。


<details>
  <summary>Details</summary>
Motivation: 多轮对话，特别是儿童和照顾者之间的对话，其特点是应急性，即 the prompt, direct, and meaningful exchanges between interlocutors。然而，现有的语言模型在生成具有这种特性的对话方面存在挑战。

Method: 我们提出了ContingentChat，一个教师-学生框架，用于在BabyLM上进行多轮对话的应急性进行基准测试和改进。该框架使用了一个新颖的、经过后训练的对齐数据集，以提高BabyLM生成的响应的语法和连贯性。此外，我们还探索了适应性教师解码策略，以获得有限的额外收益。

Result: 使用对齐数据集对BabyLM进行后训练，可以生成更具语法性和连贯性的响应。适应性教师解码策略显示出有限的额外收益。

Conclusion: ContingentChat证明了针对性后训练对于提高对话质量的好处，并表明应急性仍然是BabyLM的一个具有挑战性的目标。

Abstract: Multi-turn dialogues between a child and a caregiver are characterized by a
property called contingency - that is, prompt, direct, and meaningful exchanges
between interlocutors. We introduce ContingentChat, a teacher-student framework
that benchmarks and improves multi-turn contingency in a BabyLM trained on 100M
words. Using a novel alignment dataset for post-training, BabyLM generates
responses that are more grammatical and cohesive. Experiments with adaptive
teacher decoding strategies show limited additional gains. ContingentChat
demonstrates the benefits of targeted post-training for dialogue quality and
indicates that contingency remains a challenging goal for BabyLMs.

</details>


### [124] [LM-mixup: Text Data Augmentation via Language Model based Mixup](https://arxiv.org/abs/2510.20449)
*Zhijie Deng,Zhouan Shen,Ling Li,Yao Zhou,Zhaowei Zhu,Yanji He,Wei Wang,Jiaheng Wei*

Main category: cs.CL

TL;DR: Instruction tuning in LLMs is hampered by data quality issues. This paper introduces Instruction Distillation and the LM-Mixup method to effectively utilize abundant low-quality data, creating a high-quality dataset (MIXTURE) and an optimization process that surpasses traditional methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for instruction tuning LLMs struggle with the scarcity of high-quality data and the underutilization of abundant low-quality data. Effective augmentation of this low-quality data and its evaluation are poorly defined.

Method: The paper introduces 'Instruction Distillation' to create high-quality instruction-output pairs from multiple low-quality inputs. They constructed a dataset called MIXTURE (144K samples) and developed a method called LM-Mixup, which involves supervised fine-tuning on MIXTURE followed by reinforcement learning with three reward signals (quality, semantic alignment, format compliance) using Group Relative Policy Optimization (GRPO).

Result: LM-Mixup effectively augments imperfect datasets. Fine-tuning LLMs on distilled data (3% of the total dataset) from LM-Mixup outperformed training on the full dataset and competed with state-of-the-art high-quality data selection methods across multiple benchmarks.

Conclusion: Low-quality data is a valuable resource for instruction tuning LLMs when distilled and augmented using methods like LM-Mixup, significantly improving the efficiency and performance of instruction-tuned LLMs.

Abstract: Instruction tuning is crucial for aligning Large Language Models (LLMs), yet
the quality of instruction-following data varies significantly. While
high-quality data is paramount, it is often scarce; conversely, abundant
low-quality data is frequently discarded, leading to substantial information
loss. Existing data augmentation methods struggle to augment this low-quality
data effectively, and the evaluation of such techniques remains poorly defined.
To address this, we formally define the task of Instruction Distillation:
distilling multiple low-quality and redundant inputs into high-quality and
coherent instruction-output pairs. Specifically, we introduce a comprehensive
data construction pipeline to create MIXTURE, a 144K-sample dataset pairing
low-quality or semantically redundant imperfect instruction clusters with their
high-quality distillations. We then introduce LM-Mixup, by first performing
supervised fine-tuning on MIXTURE and then optimizing it with reinforcement
learning. This process uses three complementary reward signals: quality,
semantic alignment, and format compliance, via Group Relative Policy
Optimization (GRPO). We demonstrate that LM-Mixup effectively augments
imperfect datasets: fine-tuning LLMs on its distilled data, which accounts for
only about 3% of the entire dataset, not only surpasses full-dataset training
but also competes with state-of-the-art high-quality data selection methods
across multiple benchmarks. Our work establishes that low-quality data is a
valuable resource when properly distilled and augmented with LM-Mixup,
significantly enhancing the efficiency and performance of instruction-tuned
LLMs.

</details>


### [125] [Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models](https://arxiv.org/abs/2510.20460)
*Christian Hobelsberger,Theresa Winner,Andreas Nawroth,Oliver Mitevski,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: LLM输出存在不确定性和错误，本文评估了四种不确定性量化方法（VCE, MSP, Sample Consistency, CoCoA），并在四个问答任务上进行了实验。结果表明，CoCoA方法整体可靠性最佳，能提升正确答案的校准和区分度。


<details>
  <summary>Details</summary>
Motivation: LLM的输出具有不确定性和错误，其实用性因此受到限制。需要量化LLM输出的不确定性。

Method: 评估了四种不确定性量化方法：VCE, MSP, Sample Consistency, 和 CoCoA。在四个问答任务上使用最先进的开源LLM进行了实验。

Result: 每种不确定性度量都能捕捉到模型置信度的不同方面。混合CoCoA方法在整体可靠性方面表现最佳，提高了正确答案的校准和区分度。

Conclusion: CoCoA方法在LLM不确定性量化方面表现出最佳的整体可靠性，并提供了选择不确定性度量方法的建议。

Abstract: Large language models (LLMs) produce outputs with varying levels of
uncertainty, and, just as often, varying levels of correctness; making their
practical reliability far from guaranteed. To quantify this uncertainty, we
systematically evaluate four approaches for confidence estimation in LLM
outputs: VCE, MSP, Sample Consistency, and CoCoA (Vashurin et al., 2025). For
the evaluation of the approaches, we conduct experiments on four
question-answering tasks using a state-of-the-art open-source LLM. Our results
show that each uncertainty metric captures a different facet of model
confidence and that the hybrid CoCoA approach yields the best reliability
overall, improving both calibration and discrimination of correct answers. We
discuss the trade-offs of each method and provide recommendations for selecting
uncertainty measures in LLM applications.

</details>


### [126] [Mask and You Shall Receive: Optimizing Masked Language Modeling For Pretraining BabyLMs](https://arxiv.org/abs/2510.20475)
*Lukas Edman,Alexander Fraser*

Main category: cs.CL

TL;DR: 我们提出了一种改进的掩码语言模型（MLM）方法，通过根据模型预测能力调整掩码的token概率来提高性能，并结合子词嵌入以增强形态泛化能力，在BabyLM挑战赛的严格小型赛道上取得了优于基线的成绩。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是为了改进掩码语言模型（MLM）的性能，并提高模型在语言任务上的泛化能力，以应对BabyLM挑战赛的需求。

Method: 本文提出了一种改进的MLM方法，该方法根据模型预测能力调整被掩盖的token的概率。此外，还引入了子词嵌入，以增强模型的形态泛化能力。

Result: 与标准的MLM相比，所提出的方法在（Super）GLUE任务上取得了显著的性能提升，并且在严格小型赛道上超越了基线。

Conclusion: 所提出的改进MLM方法和子词嵌入策略能够有效提升模型在语言理解任务上的性能和泛化能力，并在BabyLM挑战赛中取得了优异的成绩。

Abstract: We describe our strategy for the 2025 edition of the BabyLM Challenge. Our
main contribution is that of an improved form of Masked Language Modeling
(MLM), which adapts the probabilities of the tokens masked according to the
model's ability to predict them. The results show a substantial increase in
performance on (Super)GLUE tasks over the standard MLM. We also incorporate
sub-token embeddings, finding that this increases the model's morphological
generalization capabilities. Our submission beats the baseline in the
strict-small track.

</details>


### [127] [RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging](https://arxiv.org/abs/2510.20479)
*Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang*

Main category: cs.CL

TL;DR: LLM内部表征可作为知识代理，提出RECALL框架通过自适应、分层参数融合进行无需历史数据的持续学习，能有效保留通用特征并适应特定任务，在多领域整合和灾难性遗忘抵抗方面表现优于基线。


<details>
  <summary>Details</summary>
Motivation: LLM内部表征可作为知识代理，但现有持续学习方法无法在无历史数据的情况下有效整合不同模型。提出RECALL旨在解决这一问题。

Method: RECALL框架通过计算层级隐藏表征的跨模型相似度，并进行自适应、分层参数融合，以对齐不同模型间的知识。浅层保留通用特征，深层适应特定任务。

Result: RECALL在多NLP任务和持续学习场景下，实现了优于基线模型的知识保留和泛化能力。

Conclusion: RECALL是一种可扩展、无需数据的LLM持续学习解决方案，能有效整合多领域知识并抵抗灾难性遗忘。

Abstract: We unveil that internal representations in large language models (LLMs) serve
as reliable proxies of learned knowledge, and propose RECALL, a novel
representation-aware model merging framework for continual learning without
access to historical data. RECALL computes inter-model similarity from
layer-wise hidden representations over clustered typical samples, and performs
adaptive, hierarchical parameter fusion to align knowledge across models. This
design enables the preservation of domain-general features in shallow layers
while allowing task-specific adaptation in deeper layers. Unlike prior methods
that require task labels or incur performance trade-offs, RECALL achieves
seamless multi-domain integration and strong resistance to catastrophic
forgetting. Extensive experiments across five NLP tasks and multiple continual
learning scenarios show that RECALL outperforms baselines in both knowledge
retention and generalization, providing a scalable and data-free solution for
evolving LLMs.

</details>


### [128] [Steering Evaluation-Aware Language Models To Act Like They Are Deployed](https://arxiv.org/abs/2510.20487)
*Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda*

Main category: cs.CL

TL;DR: LLM 可能会在评估时表现出“恰当”行为，从而影响评估的可靠性。我们提出了一种激活向量诱导方法，可以抑制 LLM 的评估意识，使其在评估时表现得像部署时一样。


<details>
  <summary>Details</summary>
Motivation: LLM 在评估时可能表现出评估意识，从而影响评估的可靠性。

Method: 通过在 LLM 的激活中添加一个诱导向量来抑制评估意识。我们首先对包含模型事实描述的文档进行持续预训练，以模仿评估意识的自然出现。然后，我们通过专家迭代训练模型在评估环境中利用 Python 类型提示。

Result: 实验表明，激活向量诱导可以有效抑制 LLM 的评估意识，使其在评估时表现得像部署时一样，即使在评估线索存在时也是如此。诱导向量是在额外的训练之前使用原始模型构建的。

Conclusion: AI 评估人员可以通过诱导模型在评估时表现得像部署时一样，来提高安全评估的可靠性。

Abstract: Large language models (LLMs) can sometimes detect when they are being
evaluated and adjust their behavior to appear more aligned, compromising the
reliability of safety evaluations. In this paper, we show that adding a
steering vector to an LLM's activations can suppress evaluation-awareness and
make the model act like it is deployed during evaluation. To study our steering
technique, we train an LLM to exhibit evaluation-aware behavior using a
two-step training process designed to mimic how this behavior could emerge
naturally. First, we perform continued pretraining on documents with factual
descriptions of the model (1) using Python type hints during evaluation but not
during deployment and (2) recognizing that the presence of a certain evaluation
cue always means that it is being tested. Then, we train the model with expert
iteration to use Python type hints in evaluation settings. The resulting model
is evaluation-aware: it writes type hints in evaluation contexts more than
deployment contexts. However, this gap can only be observed by removing the
evaluation cue. We find that activation steering can suppress evaluation
awareness and make the model act like it is deployed even when the cue is
present. Importantly, we constructed our steering vector using the original
model before our additional training. Our results suggest that AI evaluators
could improve the reliability of safety evaluations by steering models to act
like they are deployed.

</details>


### [129] [Robust Preference Alignment via Directional Neighborhood Consensus](https://arxiv.org/abs/2510.20498)
*Ruochen Mao,Yuling Shi,Xiaodong Gu,Jiaheng Wei*

Main category: cs.CL

TL;DR: LLMs 难以满足个体用户的特定偏好，导致“偏好覆盖缺口”。我们提出了一种名为 RPS 的训练后、无需训练的方法，通过利用定向邻域共识来解决这个问题。RPS 通过从相关偏好的局部邻域中抽取多个响应，创建一个更优的候选池，然后选择最符合用户原始意图的响应。实验证明，RPS 在不进行模型再训练的情况下，在具有挑战性的偏好上，相比基线模型能取得高达 69% 的胜率。


<details>
  <summary>Details</summary>
Motivation: 当前的 LLMs 在满足多样化、个体化的用户偏好方面存在不足，尤其是在用户需求偏离训练数据中心趋势时，模型性能会急剧下降，形成“偏好覆盖缺口”。现有的解决方案通常需要昂贵的重新训练，且泛化能力有限。

Method: 我们提出了一种名为 RPS（Robust Preference Selection）的训练后、无需训练的方法。该方法利用定向邻域共识，通过从与用户偏好相关的局部邻域中抽取多个响应，构建一个候选响应池，并从中选出最符合用户意图的响应。

Result: 在 DPA、DPO 和 SFT 三种不同的对齐范式下进行的广泛实验表明，RPS 能够持续地提高模型在处理来自欠代表区域的具有挑战性的偏好时的鲁棒性，相比于一个强大的基线模型，胜率最高可达 69%，且无需进行任何模型再训练。

Conclusion: RPS 是一种实用且具有理论依据的解决方案，能够有效增强偏好对齐模型的可靠性，解决了 LLMs 在满足个体特定偏好方面的挑战。

Abstract: Aligning large language models with human preferences is critical for
creating reliable and controllable AI systems. A human preference can be
visualized as a high-dimensional vector where different directions represent
trade-offs between desired attributes (e.g., helpfulness vs. verbosity). Yet,
because the training data often reflects dominant, average preferences, LLMs
tend to perform well on common requests but fall short in specific, individual
needs. This mismatch creates a preference coverage gap. Existing methods often
address this through costly retraining, which may not be generalized to the
full spectrum of diverse preferences. This brittleness means that when a user's
request reflects a nuanced preference deviating from the training data's
central tendency, model performance can degrade unpredictably. To address this
challenge, we introduce Robust Preference Selection (RPS), a post-hoc,
training-free method by leveraging directional neighborhood consensus. Instead
of forcing a model to generate a response from a single, highly specific
preference, RPS samples multiple responses from a local neighborhood of related
preferences to create a superior candidate pool. It then selects the response
that best aligns with the user's original intent. We provide a theoretical
framework showing our neighborhood generation strategy is provably superior to
a strong baseline that also samples multiple candidates. Comprehensive
experiments across three distinct alignment paradigms (DPA, DPO, and SFT)
demonstrate that RPS consistently improves robustness against this baseline,
achieving win rates of up to 69% on challenging preferences from
under-represented regions of the space without any model retraining. Our work
presents a practical, theoretically-grounded solution for enhancing the
reliability of preference-aligned models.

</details>


### [130] [Hierarchical Sequence Iteration for Heterogeneous Question Answering](https://arxiv.org/abs/2510.20505)
*Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim*

Main category: cs.CL

TL;DR: HSEQ是一个统一的框架，用于处理多步问题和异构证据源的检索增强生成（RAG），通过将文档、表格和知识图谱线性化为分层序列，并进行结构感知的迭代，从而在保证准确性的同时提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理多步问题和异构证据源时存在脆弱性，并且需要在准确性、延迟和计算资源之间进行权衡。

Method: 提出了一种名为HSEQ（Hierarchical Sequence Iteration for Heterogeneous Question Answering）的统一框架。该框架首先将文档、表格和知识图谱线性化为具有轻量级结构标签的可逆分层序列。然后，通过结构感知的迭代来收集恰到好处的证据，最后进行答案合成。具体来说，一个Head Agent提供检索指导，一个Iteration Agent通过尊重结构的动作（如父/子跳转、表格行列邻居、知识图谱关系）来选择和扩展HSeq。最后，Head Agent组合规范化的证据来生成最终答案，并可选地通过一个精炼循环来解决检测到的矛盾。

Result: 在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）等数据集上的实验表明，HSEQ相比于强大的单通路、多跳和基于Agent的RAG基线，在准确率（EM/F1）上持续提升，同时保持了高效率。

Conclusion: HSEQ框架具有三个主要优点：1. 格式无关的统一性，允许单个策略跨文本、表格和知识图谱操作，无需针对特定数据集进行专门化。2. 引导式、预算感知的迭代，在保证准确性的同时减少了不必要的跳转、工具调用和计算量。3. 证据规范化，提高了答案的一致性和可审计性，从而实现了可靠的问答。

Abstract: Retrieval-augmented generation (RAG) remains brittle on multi-step questions
and heterogeneous evidence sources, trading accuracy against latency and
token/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration
for Heterogeneous Question Answering, a unified framework that (i) linearize
documents, tables, and knowledge graphs into a reversible hierarchical sequence
with lightweight structural tags, and (ii) perform structure-aware iteration to
collect just-enough evidence before answer synthesis. A Head Agent provides
guidance that leads retrieval, while an Iteration Agent selects and expands
HSeq via structure-respecting actions (e.g., parent/child hops, table
row/column neighbors, KG relations); Finally the head agent composes
canonicalized evidence to genearte the final answer, with an optional
refinement loop to resolve detected contradictions. Experiments on HotpotQA
(text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1
gains over strong single-pass, multi-hop, and agentic RAG baselines with high
efficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic
unification that enables a single policy to operate across text, tables, and
KGs without per-dataset specialization; (2) guided, budget-aware iteration that
reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and
(3) evidence canonicalization for reliable QA, improving answers consistency
and auditability.

</details>


### [131] [Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset](https://arxiv.org/abs/2510.20508)
*Paul Lerner,François Yvon*

Main category: cs.CL

TL;DR: LLMs 的政治偏见可以通过翻译欧洲议会演讲的质量来评估，少数党派的翻译质量低于多数党派。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的政治偏见，提出了一种新的评估框架，该框架基于多语言翻译的公平性原则，而不是传统的模拟英语调查问卷。

Method: 通过系统地比较欧洲议会（EP）演讲的翻译质量来评估政治偏见。研究使用了新发布的 21 种平行翻译的欧洲议会议事录（EuroParl）数据集，该数据集包含了演讲者的政治派别信息，并分析了不同政治派别（左、中、右的多数党派和少数党派）的翻译质量差异。

Result: 研究发现，与少数党派相比，左、中、右的多数党派的演讲被翻译得更好，这表明存在系统性的政治偏见。

Conclusion: LLMs 的政治偏见可以通过翻译欧洲议会演讲的质量来评估，少数党派的翻译质量低于多数党派。

Abstract: The political biases of Large Language Models (LLMs) are usually assessed by
simulating their answers to English surveys. In this work, we propose an
alternative framing of political biases, relying on principles of fairness in
multilingual translation. We systematically compare the translation quality of
speeches in the European Parliament (EP), observing systematic differences with
majority parties from left, center, and right being better translated than
outsider parties. This study is made possible by a new, 21-way multiparallel
version of EuroParl, the parliamentary proceedings of the EP, which includes
the political affiliations of each speaker. The dataset consists of 1.5M
sentences for a total of 40M words and 249M characters. It covers three years,
1000+ speakers, 7 countries, 12 EU parties, 25 EU committees, and hundreds of
national parties.

</details>


### [132] [ARC-Encoder: learning compressed text representations for large language models](https://arxiv.org/abs/2510.20535)
*Hippolyte Pilchen,Edouard Grave,Patrick Pérez*

Main category: cs.CL

TL;DR: ARC-Encoder是一种能够压缩上下文的编码器，可用于减少LLM的推理成本，同时保持其性能。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文压缩技术通常需要对目标模型进行微调甚至修改其架构，这可能导致模型在非特定任务上的能力下降。本研究旨在探索一种替代方法，即使用一个独立的编码器来压缩上下文。

Method: 提出了一种名为ARC-Encoder的编码器，它将上下文压缩成连续表示，并替换掉解码器LLM中的token嵌入。通过系统研究训练策略和架构选择，设计出ARC-Encoder，其输出的连续表示比文本token少x倍（通常x为4或8）。

Result: ARC-Encoder在多种LLM应用场景（如上下文学习和上下文窗口扩展）以及指令和基础解码器上进行了评估，在多个基准测试中取得了最先进的性能，并提高了推理效率。此外，ARC-Encoder可以同时适配多个解码器，实现跨不同LLM的通用性。

Conclusion: ARC-Encoder是一种灵活且高效的解决方案，适用于可移植的编码器，能够与多个LLM无缝协作，有效解决了上下文压缩带来的成本和通用性问题。

Abstract: Recent techniques such as retrieval-augmented generation or chain-of-thought
reasoning have led to longer contexts and increased inference costs. Context
compression techniques can reduce these costs, but the most effective
approaches require fine-tuning the target model or even modifying its
architecture. This can degrade its general abilities when not used for this
specific purpose. Here we explore an alternative approach: an encoder that
compresses the context into continuous representations which replace token
embeddings in decoder LLMs. First, we perform a systematic study of training
strategies and architecture choices for the encoder. Our findings led to the
design of an Adaptable text Representations Compressor, named ARC-Encoder,
which outputs $x$-times fewer continuous representations (typically
$x\!\in\!\{4,8\}$) than text tokens. We evaluate ARC-Encoder across a variety
of LLM usage scenarios, ranging from in-context learning to context window
extension, on both instruct and base decoders. Results show that ARC-Encoder
achieves state-of-the-art performance on several benchmarks while improving
computational efficiency at inference. Finally, we demonstrate that our models
can be adapted to multiple decoders simultaneously, allowing a single encoder
to generalize across different decoder LLMs. This makes ARC-Encoder a flexible
and efficient solution for portable encoders that work seamlessly with multiple
LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder
, fine-tuning dataset and pretrained models are available at
https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .

</details>


### [133] [The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts](https://arxiv.org/abs/2510.20543)
*Sangmitra Madhusudan,Kaige Chen,Ali Emami*

Main category: cs.CL

TL;DR: CenterBench是一个包含9720个问题的评估数据集，用于区分语言模型对句法结构的理解和基于语义模式匹配的能力。通过对比语法结构相同但语义不相关的句子，该数据集能够量化模型在多大程度上依赖语义联想而非句法分析。实验结果表明，随着句子复杂度的增加，模型在语义不相关句子上的表现差距会增大，表明它们逐渐放弃句法分析。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏有效方法来区分语言模型对句法结构的理解能力和仅仅基于语义模式匹配的能力，尤其是在处理复杂句子结构时。

Method: 创建了一个名为CenterBench的数据集，包含9720个关于中心语式嵌套句（相对从句递归嵌套）的理解问题。每个句子都有一个语法结构相同但语义不合理的对应句子。数据集包含测试表面理解、句法依赖和因果推理的问题。

Result: 测试六种模型发现，在语义合理和不合理的句子之间，性能差距会随着复杂度的增加而系统性地增大，模型的中位数差距高达26.8个百分点，这表明它们会放弃句法分析，转而依赖语义关联。值得注意的是，语义合理性反而会损害模型在关于预期行为的问题上的表现，因为这些问题更侧重于因果关系而非语义连贯性。推理模型虽然提高了准确性，但其分析过程显示出语义捷径、过度思考和拒绝回答等问题。与此不同，人类在面对语义影响时表现出可变性，而不是像模型那样系统性地扩大差距。

Conclusion: CenterBench提供了首个用于识别模型何时从结构分析转向模式匹配的框架，并揭示了现有模型在处理句法结构和语义信息时的局限性。

Abstract: When language models correctly parse "The cat that the dog chased meowed,"
are they analyzing syntax or simply familiar with dogs chasing cats? Despite
extensive benchmarking, we lack methods to distinguish structural understanding
from semantic pattern matching. We introduce CenterBench, a dataset of 9,720
comprehension questions on center-embedded sentences (like "The cat [that the
dog chased] meowed") where relative clauses nest recursively, creating
processing demands from simple to deeply nested structures. Each sentence has a
syntactically identical but semantically implausible counterpart (e.g., mailmen
prescribe medicine, doctors deliver mail) and six comprehension questions
testing surface understanding, syntactic dependencies, and causal reasoning.
Testing six models reveals that performance gaps between plausible and
implausible sentences widen systematically with complexity, with models showing
median gaps up to 26.8 percentage points, quantifying when they abandon
structural analysis for semantic associations. Notably, semantic plausibility
harms performance on questions about resulting actions, where following causal
relationships matters more than semantic coherence. Reasoning models improve
accuracy but their traces show semantic shortcuts, overthinking, and answer
refusal. Unlike models whose plausibility advantage systematically widens with
complexity, humans shows variable semantic effects. CenterBench provides the
first framework to identify when models shift from structural analysis to
pattern matching.

</details>


### [134] [GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning](https://arxiv.org/abs/2510.20548)
*Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao*

Main category: cs.CL

TL;DR: GlobalRAG是一个强化学习框架，用于改进多跳问答中的全局推理，通过分解问题、协调检索和推理、迭代精炼证据，并引入奖励机制和权重退火策略来克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的检索增强生成方法在多跳问答中存在全局规划缺失和执行不忠实的问题，限制了其有效性。

Method: GlobalRAG框架将问题分解为子目标，协调检索与推理过程，并进行迭代式证据精炼。引入了规划质量奖励（Planning Quality Reward）和子目标完成奖励（SubGoal Completion Reward）来指导规划和执行。同时，采用渐进式权重退火策略来平衡面向过程和面向结果的优化目标。

Result: 在领域内和领域外数据集上的大量实验表明，GlobalRAG显著优于现有方法，并且仅使用了8k训练数据（相当于现有方法的42%），在EM和F1指标上平均提升了14.2%。

Conclusion: GlobalRAG通过引入全局规划和改进证据利用，有效提升了多跳问答的性能，并且在数据效率方面表现出色。

Abstract: Reinforcement learning has recently shown promise in improving
retrieval-augmented generation (RAG). Despite these advances, its effectiveness
in multi-hop question answering (QA) remains limited by two fundamental
limitations: (i) global planning absence to structure multi-step reasoning, and
(ii) unfaithful execution, which hinders effective query formulation and
consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement
learning framework designed to enhance global reasoning in multi-hop QA.
GlobalRAG decomposes questions into subgoals, coordinates retrieval with
reasoning, and refines evidence iteratively. To guide this process, we
introduce Planning Quality Reward and SubGoal Completion Reward, which
encourage coherent planning and reliable subgoal execution. In addition, a
progressive weight annealing strategy balances process-oriented and
outcome-based objectives. Extensive experiments on both in-domain and
out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms
strong baselines while using only 8k training data (42% of the training data
used by strong baselines), achieving average improvements of 14.2% in both EM
and F1.

</details>


### [135] [Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search](https://arxiv.org/abs/2510.20567)
*Zhouwei Zhai,Mengxiang Chen,Haoyun Xia,Jin Li,Renquan Zhou,Min Yang*

Main category: cs.CL

TL;DR: 传统电商搜索依赖查询-商品匹配，但用户决策是多阶段的。提出多智能体认知决策框架（MACDF），从被动检索转向主动决策支持，解决了复杂查询的语义鸿沟、跨平台信息搜集成本高和缺乏购物指导的问题。实验证明MACDF在推荐准确性和用户满意度方面有显著提升，尤其对于复杂查询。在线A/B测试证实了其实际效果。


<details>
  <summary>Details</summary>
Motivation: 传统电商搜索的查询-商品匹配模式与用户多阶段认知决策过程存在不符，导致语义鸿沟、高决策成本和缺乏购物指导等问题。

Method: 提出多智能体认知决策框架（MACDF），将电商搜索模式从被动检索转变为主动决策支持。

Result: 离线评估显示MACDF在推荐准确性和用户满意度方面有显著提升，尤其是在处理涉及否定、多约束或推理的复杂查询时。在线A/B测试也验证了其有效性。

Conclusion: 多智能体认知系统在重塑电商搜索方面具有巨大潜力。

Abstract: The retrieval-ranking paradigm has long dominated e-commerce search, but its
reliance on query-item matching fundamentally misaligns with multi-stage
cognitive decision processes of platform users. This misalignment introduces
critical limitations: semantic gaps in complex queries, high decision costs due
to cross-platform information foraging, and the absence of professional
shopping guidance. To address these issues, we propose a Multi-Agent Cognitive
Decision Framework (MACDF), which shifts the paradigm from passive retrieval to
proactive decision support. Extensive offline evaluations demonstrate MACDF's
significant improvements in recommendation accuracy and user satisfaction,
particularly for complex queries involving negation, multi-constraint, or
reasoning demands. Online A/B testing on JD search platform confirms its
practical efficacy. This work highlights the transformative potential of
multi-agent cognitive systems in redefining e-commerce search.

</details>


### [136] [Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks](https://arxiv.org/abs/2510.20584)
*Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi*

Main category: cs.CL

TL;DR: ChatGPT在通信编码方面没有性别或种族偏见，可用于大规模协作和沟通评估。


<details>
  <summary>Details</summary>
Motivation: 评估大规模沟通和协作依赖于将沟通数据编码为不同框架下的类别，这是一项劳动密集型任务。以往的研究表明ChatGPT可以根据编码规则直接编码沟通数据，并且其准确性可与人类评分员相媲美。然而，ChatGPT或类似的人工智能技术在编码时是否会对不同的人口群体（如性别和种族）表现出偏见尚不清楚。

Method: 本研究调查了基于ChatGPT的通信数据自动化编码，使用了典型的协作问题解决编码框架，并考察了性别和种族群体之间的差异。分析基于三种协作任务的数据：谈判、问题解决和决策。

Result: 研究结果表明，基于ChatGPT的编码在性别和种族群体之间没有表现出显著的偏见。

Conclusion: 基于ChatGPT的编码在性别和种族群体之间没有表现出显著的偏见，这为其在हरूको大规模协作和沟通评估中应用铺平了道路。

Abstract: Assessing communication and collaboration at scale depends on a labor
intensive task of coding communication data into categories according to
different frameworks. Prior research has established that ChatGPT can be
directly instructed with coding rubrics to code the communication data and
achieves accuracy comparable to human raters. However, whether the coding from
ChatGPT or similar AI technology exhibits bias against different demographic
groups, such as gender and race, remains unclear. To fill this gap, this paper
investigates ChatGPT-based automated coding of communication data using a
typical coding framework for collaborative problem solving, examining
differences across gender and racial groups. The analysis draws on data from
three types of collaborative tasks: negotiation, problem solving, and decision
making. Our results show that ChatGPT-based coding exhibits no significant bias
across gender and racial groups, paving the road for its adoption in
large-scale assessment of collaboration and communication.

</details>


### [137] [BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection](https://arxiv.org/abs/2510.20610)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: Busted团队在Ara-GenEval中文本生成评估任务中获得第五名，使用XLM-RoBERTa模型在检测阿拉伯语AI生成文本方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 评估三种预训练模型（AraELECTRA、CAMeLBERT和XLM-RoBERTa）在阿拉伯语AI生成文本检测任务上的有效性。

Method: 对三种预训练模型进行微调，用于二元分类任务。

Result: XLM-RoBERTa模型表现最佳，F1得分为0.7701，优于专门的阿拉伯语模型。

Conclusion: 多语言模型具有强大的泛化能力，并且在阿拉伯语AI生成文本检测方面表现出色。

Abstract: This paper details our submission to the Ara- GenEval Shared Task on Arabic
AI-generated text detection, where our team, BUSTED, se- cured 5th place. We
investigated the effec- tiveness of three pre-trained transformer mod- els:
AraELECTRA, CAMeLBERT, and XLM- RoBERTa. Our approach involved fine-tuning each
model on the provided dataset for a binary classification task. Our findings
revealed a sur- prising result: the multilingual XLM-RoBERTa model achieved the
highest performance with an F1 score of 0.7701, outperforming the spe- cialized
Arabic models. This work underscores the complexities of AI-generated text
detection and highlights the strong generalization capa- bilities of
multilingual models.

</details>


### [138] [Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model](https://arxiv.org/abs/2510.20635)
*Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao*

Main category: cs.CL

TL;DR: LLM在信息获取、寻求刺激和社交好奇心等方面表现出好奇心，尽管在不确定环境中表现保守，但好奇心能增强其推理和学习能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否具备类似人类的好奇心驱动学习能力，并探索好奇心与LLM思考能力的关系。

Method: 基于人类好奇心评估量表5DCR，设计了一个包含信息寻求、寻求刺激和社交好奇心等多维度在内的综合评估框架来测评LLM的好奇心水平，并研究好奇心与LLM思考能力的关系。

Result: LLM表现出比人类更强烈的求知欲，但在不确定环境中倾向于做出保守选择。好奇心行为能够提升LLM的推理和主动学习能力。

Conclusion: LLM具有展现类似人类好奇心的潜力，为未来LLM学习能力的发展和创新研究提供了实验支持。

Abstract: Curiosity serves as a pivotal conduit for human beings to discover and learn
new knowledge. Recent advancements of large language models (LLMs) in natural
language processing have sparked discussions regarding whether these models
possess capability of curiosity-driven learning akin to humans. In this paper,
starting from the human curiosity assessment questionnaire Five-Dimensional
Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework
that covers dimensions such as Information Seeking, Thrill Seeking, and Social
Curiosity to assess the extent of curiosity exhibited by LLMs. The results
demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but
still tend to make conservative choices when faced with uncertain environments.
We further investigated the relationship between curiosity and thinking of
LLMs, confirming that curious behaviors can enhance the model's reasoning and
active learning abilities. These findings suggest that LLMs have the potential
to exhibit curiosity similar to that of humans, providing experimental support
for the future development of learning capabilities and innovative research in
LLMs.

</details>


### [139] [The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI](https://arxiv.org/abs/2510.20647)
*Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully*

Main category: cs.CL

TL;DR: 大型推理模型（LRM）在数学和科学问答任务上表现出色，但其多语言推理能力尚未得到充分探索。当面对非英语问题时，LRM 常常默认使用英语进行推理，这引发了对可解释性以及处理语言和文化细微差别的担忧。本文系统地比较了 LRM 在英语推理与使用问题本身语言进行推理的表现。评估涵盖了 MGSM 和 GPQA Diamond 两项任务，除了衡量答案准确性外，还分析了推理过程中的认知属性。研究发现，英语推理过程中认知行为的出现频率更高，并且通常能获得更高的最终答案准确性，随着任务复杂度的增加，这种性能差距会扩大。然而，这种以英语为中心的策略容易出现一种关键的失败模式——“翻译迷失”，即翻译步骤会导致一些本可以通过使用问题语言进行推理来避免的错误。


<details>
  <summary>Details</summary>
Motivation: 评估大型推理模型（LRM）在处理非英语问题时的多语言推理能力，并与英语推理进行对比，以了解其在解释性、语言及文化细微差别处理方面的表现。

Method: 比较 LRM 在英语推理与使用问题语言进行推理在 MGSM 和 GPQA Diamond 两项任务上的表现，分析答案准确性以及推理过程中的认知属性。

Result: 英语推理的认知行为出现频率更高，准确性也通常更高，且性能差距随任务复杂度增加而扩大。但“翻译迷失”是英语推理的一种失败模式。

Conclusion: 尽管英语推理在准确性上通常优于多语言推理，但并非总是最佳选择，尤其是在处理可能因翻译而产生错误的复杂问题时。LRM 的多语言推理能力仍有待提高。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on mathematical,
scientific, and other question-answering tasks, but their multilingual
reasoning abilities remain underexplored. When presented with non-English
questions, LRMs often default to reasoning in English, raising concerns about
interpretability and the handling of linguistic and cultural nuances. We
systematically compare an LRM's reasoning in English versus the language of the
question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond
measuring answer accuracy, we also analyze cognitive attributes in the
reasoning traces. We find that English reasoning traces exhibit a substantially
higher presence of these cognitive behaviors, and that reasoning in English
generally yields higher final-answer accuracy, with the performance gap
increasing as tasks become more complex. However, this English-centric strategy
is susceptible to a key failure mode - getting "Lost in Translation," where
translation steps lead to errors that would have been avoided by question's
language reasoning.

</details>


### [140] [\textsc{CantoNLU}: A benchmark for Cantonese natural language understanding](https://arxiv.org/abs/2510.20670)
*Junghyun Min,York Hay Ng,Sophia Chan,Helena Shunhua Zhao,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: CantoNLU是一个新的粤语自然语言理解基准，包含七个任务，并提供了不同模型的基线性能，以促进粤语NLP研究。


<details>
  <summary>Details</summary>
Motivation: 由于政策和双层语言现象，粤语虽然有数百万使用者，但仍然资源匮乏，缺乏评估框架。

Method: 提出了CantoNLU基准，包含七个任务（词义消歧、语言可接受性判断、语言检测、自然语言推断、情感分析、词性标注和依存句法分析），并评估了四种模型（未训练粤语的普通话模型、两个通过持续预训练改编的粤语模型、一个从头开始训练的单语粤语模型）。

Result: 改编的粤语模型整体表现最佳，单语模型在句法任务上表现更好，普通话模型在某些情况下仍具竞争力。

Conclusion: CantoNLU基准和模型评估结果表明，粤语适应性模型表现优异，单语模型在句法任务上表现突出，而普通话模型在数据稀疏时也可作为替代方案。研究发布了所有数据集、代码和模型权重以支持未来的粤语NLP研究。

Abstract: Cantonese, although spoken by millions, remains under-resourced due to policy
and diglossia. To address this scarcity of evaluation frameworks for Cantonese,
we introduce \textsc{\textbf{CantoNLU}}, a benchmark for Cantonese natural
language understanding (NLU). This novel benchmark spans seven tasks covering
syntax and semantics, including word sense disambiguation, linguistic
acceptability judgment, language detection, natural language inference,
sentiment analysis, part-of-speech tagging, and dependency parsing. In addition
to the benchmark, we provide model baseline performance across a set of models:
a Mandarin model without Cantonese training, two Cantonese-adapted models
obtained by continual pre-training a Mandarin model on Cantonese text, and a
monolingual Cantonese model trained from scratch. Results show that
Cantonese-adapted models perform best overall, while monolingual models perform
better on syntactic tasks. Mandarin models remain competitive in certain
settings, indicating that direct transfer may be sufficient when Cantonese
domain data is scarce. We release all datasets, code, and model weights to
facilitate future research in Cantonese NLP.

</details>


### [141] [Neural Diversity Regularizes Hallucinations in Small Models](https://arxiv.org/abs/2510.20690)
*Kushal Chakrabarti,Nirmal Balachundhar*

Main category: cs.CL

TL;DR: 通过引入神经多样性（即解耦的并行表示），一种减少语言模型幻觉的方法，在固定参数和数据预算下，可以降低幻觉率。


<details>
  <summary>Details</summary>
Motivation: 尽管模型参数、计算和数据都在增加，但语言模型仍然存在幻觉问题。

Method: 提出神经多样性（ND），即解耦的并行表示，并通过ND-LoRA（神经多样性低秩适配）进行验证，该方法结合了并行LoRA适配器和Barlow Twins正则化。

Result: ND-LoRA 可将幻觉降低高达 25.6%（平均 14.6%），同时不损害一般准确性。消融实验表明，LoRA 适配器和正则化协同作用，神经多样性是关键因素，神经相关性每增加 0.1%，幻觉就会增加 3.8%。不同任务需要不同程度的最佳神经多样性。

Conclusion: 神经多样性是提高语言模型可靠性的第三个可扩展维度，独立于参数和数据。

Abstract: Language models continue to hallucinate despite increases in parameters,
compute, and data. We propose neural diversity -- decorrelated parallel
representations -- as a principled mechanism that reduces hallucination rates
at fixed parameter and data budgets. Inspired by portfolio theory, where
uncorrelated assets reduce risk by $\sqrt{P}$, we prove hallucination
probability is bounded by representational correlation: $P(H) \leq
f(\sigma^2((1-\rho(P))/P + \rho(P)), \mu^2)$, which predicts that language
models need an optimal amount of neurodiversity. To validate this, we introduce
ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA
adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces
hallucinations by up to 25.6% (and 14.6% on average) without degrading general
accuracy. Ablations show LoRA adapters and regularization act synergistically,
causal interventions prove neurodiversity as the mediating factor and
correlational analyses indicate scale: a 0.1% neural correlation increase is
associated with a 3.8% hallucination increase. Finally, task-dependent
optimality emerges: different tasks require different amounts of optimal
neurodiversity. Together, our results highlight neural diversity as a third
axis of scaling -- orthogonal to parameters and data -- to improve the
reliability of language models at fixed budgets.

</details>


### [142] [Structure-Conditional Minimum Bayes Risk Decoding](https://arxiv.org/abs/2510.20700)
*Bryan Eikema,Anna Rutkiewicz,Mario Giulianelli*

Main category: cs.CL

TL;DR: MBR解码在开放式任务中可能面临挑战，本文提出了改进的效用函数以提高其对结构变异的敏感性，并在指令遵循任务上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在机器翻译等任务中，MBR解码被证明有效，但在对话或指令遵循等更开放的任务中，标准MBR可能选择看似平均但最优性差的响应。

Method: 引入三种轻量级的效用函数改编，以提高MBR对结果空间中结构变异的敏感性；构建了一个包含对话行为、情感和响应结构（句子、段落、列表）的数据集；提出两种评估MBR结构最优性的指标。

Result: 标准基于相似性的效用函数在结构最优性方面表现不佳；提出的改编显著提高了结构最优性；在AlpacaEval和MT-Bench基准测试中，改进的MBR生成质量提高了高达13.7个百分点。

Conclusion: 通过改进效用函数，可以使MBR解码对开放式生成任务中的结构变异更加敏感，从而提高生成质量。

Abstract: Minimum Bayes Risk (MBR) decoding has seen renewed interest as an alternative
to traditional generation strategies. While MBR has proven effective in machine
translation, where the variability of a language model's outcome space is
naturally constrained, it may face challenges in more open-ended tasks such as
dialogue or instruction-following. We hypothesise that in such settings,
applying MBR with standard similarity-based utility functions may result in
selecting responses that are broadly representative of the model's
distribution, yet sub-optimal with respect to any particular grouping of
generations that share an underlying latent structure. In this work, we
introduce three lightweight adaptations to the utility function, designed to
make MBR more sensitive to structural variability in the outcome space. To test
our hypothesis, we curate a dataset capturing three representative types of
latent structure: dialogue act, emotion, and response structure (e.g., a
sentence, a paragraph, or a list). We further propose two metrics to evaluate
the structural optimality of MBR. Our analysis demonstrates that common
similarity-based utility functions fall short by these metrics. In contrast,
our proposed adaptations considerably improve structural optimality. Finally,
we evaluate our approaches on real-world instruction-following benchmarks,
AlpacaEval and MT-Bench, and show that increased structural sensitivity
improves generation quality by up to 13.7 percentage points in win rate.

</details>


### [143] [User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios](https://arxiv.org/abs/2510.20721)
*Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue*

Main category: cs.CL

TL;DR: LLM在处理涉及私人信息（如健康记录、联系方式）的任务时，用户对其隐私保护和有用性的感知存在个体差异，而使用代理LLM进行评估并不可靠，应以用户为中心进行研究。


<details>
  <summary>Details</summary>
Motivation: 现有LLM隐私评估依赖代理LLM，忽略了真实用户感知，且未深入研究有用性的细微差别。

Method: 进行一项包含94名参与者的用户研究，使用90个PrivacyLens场景，评估LLM对隐私敏感场景的响应。

Result: 用户对LLM响应的隐私保护质量和有用性评价存在显著的个体差异（低共识），而代理LLM之间高度一致但与用户评价相关性低。

Conclusion: LLM响应的隐私和有用性具有个体特异性，代理LLM无法准确估计用户感知；未来研究应关注用户中心研究和改进代理LLM与用户的对齐。

Abstract: Large language models (LLMs) have seen rapid adoption for tasks such as
drafting emails, summarizing meetings, and answering health questions. In such
uses, users may need to share private information (e.g., health records,
contact details). To evaluate LLMs' ability to identify and redact such private
information, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with
real-life scenarios. Using these benchmarks, researchers have found that LLMs
sometimes fail to keep secrets private when responding to complex tasks (e.g.,
leaking employee salaries in meeting summaries). However, these evaluations
rely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking
real users' perceptions. Moreover, prior work primarily focused on the
privacy-preservation quality of responses, without investigating nuanced
differences in helpfulness. To understand how users perceive the
privacy-preservation quality and helpfulness of LLM responses to
privacy-sensitive scenarios, we conducted a user study with 94 participants
using 90 scenarios from PrivacyLens. We found that, when evaluating identical
responses to the same scenario, users showed low agreement with each other on
the privacy-preservation quality and helpfulness of the LLM response. Further,
we found high agreement among five proxy LLMs, while each individual LLM had
low correlation with users' evaluations. These results indicate that the
privacy and helpfulness of LLM responses are often specific to individuals, and
proxy LLMs are poor estimates of how real users would perceive these responses
in privacy-sensitive scenarios. Our results suggest the need to conduct
user-centered studies on measuring LLMs' ability to help users while preserving
privacy. Additionally, future research could investigate ways to improve the
alignment between proxy LLMs and users for better estimation of users'
perceived privacy and utility.

</details>


### [144] [Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing](https://arxiv.org/abs/2510.20727)
*Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang*

Main category: cs.CL

TL;DR: LLM在临床笔记中提取氟嘧啶治疗和毒性信息方面效果最佳。


<details>
  <summary>Details</summary>
Motivation: 氟嘧啶类药物广泛用于治疗结直肠癌和乳腺癌，但可能引起手足综合征和心脏毒性等副作用。由于这些毒性信息通常记录在临床笔记中，因此需要开发和评估自然语言处理（NLP）方法来提取治疗和毒性信息。

Method: 构建了一个包含204,165名成人肿瘤科患者的236条临床笔记的黄金标准数据集。由领域专家对治疗方案和毒性相关类别进行了注释。开发了包括基于规则、机器学习（随机森林、支持向量机、逻辑回归）、深度学习（BERT、ClinicalBERT）和大型语言模型（LLM）（零样本和错误分析提示）在内的NLP方法。模型采用80:20的训练测试拆分。

Result: 存在足够的数据来训练和评估5个已注释的类别。错误分析提示在治疗和毒性提取方面实现了最佳的精确率、召回率和F1分数（F1=1.000），而零样本提示在治疗方面达到了F1=1.000，在毒性方面达到了F1=0.876。逻辑回归和支持向量机在毒性方面排名第二（F1=0.937）。深度学习模型的表现不佳，BERT（F1=0.873治疗；F1=0.839毒性）和ClinicalBERT（F1=0.873治疗；F1=0.886毒性）的F1分数较低。基于规则的方法作为基线，在治疗和毒性方面的F1分数分别为0.857和0.858。

Conclusion: 基于LLM的NLP方法最有效地从临床笔记中提取了氟嘧啶治疗和毒性信息，并具有支持肿瘤学研究和药物警戒的巨大潜力。

Abstract: Objective: Fluoropyrimidines are widely prescribed for colorectal and breast
cancers, but are associated with toxicities such as hand-foot syndrome and
cardiotoxicity. Since toxicity documentation is often embedded in clinical
notes, we aimed to develop and evaluate natural language processing (NLP)
methods to extract treatment and toxicity information.
  Materials and Methods: We constructed a gold-standard dataset of 236 clinical
notes from 204,165 adult oncology patients. Domain experts annotated categories
related to treatment regimens and toxicities. We developed rule-based, machine
learning-based (Random Forest, Support Vector Machine [SVM], Logistic
Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language
models (LLM)-based NLP approaches (zero-shot and error-analysis prompting).
Models used an 80:20 train-test split.
  Results: Sufficient data existed to train and evaluate 5 annotated
categories. Error-analysis prompting achieved optimal precision, recall, and F1
scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot
prompting reached F1=1.000 for treatment and F1=0.876 for toxicities
extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning
underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and
ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods
served as our baseline with F1 scores of 0.857 in treatment and 0.858 in
toxicities.
  Discussion: LMM-based approaches outperformed all others, followed by machine
learning methods. Machine and deep learning approaches were limited by small
training data and showed limited generalizability, particularly for rare
categories.
  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine
treatment and toxicity information from clinical notes, and has strong
potential to support oncology research and pharmacovigilance.

</details>


### [145] [Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost](https://arxiv.org/abs/2510.20780)
*Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong*

Main category: cs.CL

TL;DR: 大型推理模型（LRMs）在机器翻译（MT）评估中存在“过度思考”、评分不准等问题，通过使用模拟人类思考轨迹的合成数据进行校准，可以显著降低计算成本并提高评估性能。


<details>
  <summary>Details</summary>
Motivation: LRMs在复杂任务中展现出强大的推理能力，但其在机器翻译（MT）质量评估方面的潜力尚未得到充分研究。

Method: 提出通过在模拟人类思考轨迹的合成数据上进行训练来校准LRMs的思考过程，以解决其在MT评估中存在的问题。

Result: 实验表明，该校准方法能将思考成本降低约35倍，并提升了不同规模LRMs（7B到32B）的评估性能，例如R1-Distill-Qwen-7B的准确率提升了8.7个百分点。

Conclusion: 经过有效校准的LRMs有潜力推动细粒度的自动MT评估技术的发展。

Abstract: Recent advancements in large reasoning models (LRMs) have introduced an
intermediate "thinking" process prior to generating final answers, improving
their reasoning capabilities on complex downstream tasks. However, the
potential of LRMs as evaluators for machine translation (MT) quality remains
underexplored. We provides the first systematic analysis of LRM-as-a-judge in
MT evaluation. We identify key challenges, revealing LRMs require tailored
evaluation materials, tend to "overthink" simpler instances and have issues
with scoring mechanisms leading to overestimation. To address these, we propose
to calibrate LRM thinking by training them on synthetic, human-like thinking
trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this
approach largely reduces thinking budgets by ~35x while concurrently improving
evaluation performance across different LRM scales from 7B to 32B (e.g.,
R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These
findings highlight the potential of efficiently calibrated LRMs to advance
fine-grained automatic MT evaluation.

</details>


### [146] [A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text](https://arxiv.org/abs/2510.20782)
*Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock*

Main category: cs.CL

TL;DR: LLM评估应针对特定应用，并考虑公平性等负责任AI维度。本文构建了一个以产品描述生成为背景，结合公平性属性、性别形容词和产品类别的标注数据集，用于识别LLM在质量、真实性、安全性和公平性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法过于笼统，未能充分考虑特定应用场景下的公平性等负责任AI维度。

Method: 构建了一个包含产品特征、公平性属性、性别形容词和产品类别的标注数据集，用于产品描述生成任务。

Result: 开发了一种利用该数据集评估LLM在质量、真实性、安全性和公平性方面不足的方法。

Conclusion: 提出了一种针对LLM的评估框架，并提供了一个可供研究社区使用的具体数据集，以弥补现有评估方法的不足。

Abstract: Current methods for evaluating large language models (LLMs) typically focus
on high-level tasks such as text generation, without targeting a particular AI
application. This approach is not sufficient for evaluating LLMs for
Responsible AI dimensions like fairness, since protected attributes that are
highly relevant in one application may be less relevant in another. In this
work, we construct a dataset that is driven by a real-world application
(generate a plain-text product description, given a list of product features),
parameterized by fairness attributes intersected with gendered adjectives and
product categories, yielding a rich set of labeled prompts. We show how to use
the data to identify quality, veracity, safety, and fairness gaps in LLMs,
contributing a proposal for LLM evaluation paired with a concrete resource for
the research community.

</details>


### [147] [Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction](https://arxiv.org/abs/2510.20787)
*Mutian He,Philip N. Garner*

Main category: cs.CL

TL;DR: 线性注意力模型通过固定大小的循环状态压缩整个输入序列，效率高但易遗忘。本研究提出混合模型，恢复对过去令牌的直接访问，并引入可学习的令牌移除方法，结合滑动窗口注意力和轻量级CNN，在保持线性注意力的恒定时间和空间复杂度的同时，有效解决了遗忘问题，并在检索密集型基准测试中得到验证。


<details>
  <summary>Details</summary>
Motivation: 现有的线性注意力模型虽然效率高，但由于其有限的记忆容量，在需要大量检索的任务中容易遗忘信息，影响模型性能。

Method: 提出了一系列混合模型，在令牌混合器中引入了介于线性和完全注意力之间的中间时间和空间复杂度。具体来说，研究了带有令牌移除的稀疏注意力和查询感知的原生稀疏注意力。其中，提出了一种新颖的可学习令牌移除方法。该方法与滑动窗口注意力相结合，并通过轻量级CNN聚合过去和未来的相邻令牌信息，自适应地保留每个注意力头有限的关键KV对，从而在保持线性注意力的恒定时间和空间复杂度的同时，解决了遗忘问题。此外，还提供了稀疏注意力机制的高效Triton内核。

Result: 在检索密集型基准测试中的实证评估支持了所提出方法（包括可学习令牌移除、稀疏注意力、滑动窗口注意力和轻量级CNN的组合）的有效性。

Conclusion: 通过引入混合模型和可学习令牌移除机制，有效缓解了线性注意力模型的遗忘问题，并在检索密集型任务中取得了良好的效果，同时保持了计算效率。

Abstract: Linear-attention models that compress the entire input sequence into a
fixed-size recurrent state offer an efficient alternative to Transformers, but
their finite memory induces forgetfulness that harms retrieval-intensive tasks.
To mitigate the issue, we explore a series of hybrid models that restore direct
access to past tokens. We interleave token mixers with intermediate time and
space complexity between linear and full attention, including sparse attention
with token eviction, and the query-aware native sparse attention. Particularly,
we propose a novel learnable token eviction approach. Combined with
sliding-window attention, an end-to-end trainable lightweight CNN aggregates
information from both past and future adjacent tokens to adaptively retain a
limited set of critical KV-pairs per head, maintaining linear attention's
constant time and space complexity. Efficient Triton kernels for the sparse
attention mechanisms are provided. Empirical evaluations on retrieval-intensive
benchmarks support the effectiveness of our approaches.

</details>


### [148] [Simple Context Compression: Mean-Pooling and Multi-Ratio Training](https://arxiv.org/abs/2510.20797)
*Yair Feldman,Yoav Artzi*

Main category: cs.CL

TL;DR: 使用平均池化方法进行软上下文压缩，优于压缩标记架构，并探索了多压缩比训练。


<details>
  <summary>Details</summary>
Motivation: 减少长上下文检索增强生成（RAG）的计算成本。

Method: 开发了一种轻量级的平均池化方法，并研究了训练压缩器以输出多种压缩比。

Result: 平均池化方法在各种数据集和模型上表现最佳，并且在多压缩比训练时性能下降较小。不同架构和训练机制下的压缩权衡更为复杂。

Conclusion: 所提出的平均池化方法是一种有效的软上下文压缩技术，在多压缩比训练方面也显示出潜力，但上下文压缩的整体优化仍然是一个复杂的挑战。

Abstract: A common strategy to reduce the computational costs of using long contexts in
retrieval-augmented generation (RAG) with large language models (LLMs) is soft
context compression, where the input sequence is transformed into a shorter
continuous representation. We develop a lightweight and simple mean-pooling
approach that consistently outperforms the widely used compression-tokens
architecture, and study training the same compressor to output multiple
compression ratios. We conduct extensive experiments across in-domain and
out-of-domain QA datasets, as well as across model families, scales, and
compression ratios. Overall, our simple mean-pooling approach achieves the
strongest performance, with a relatively small drop when training for multiple
compression ratios. More broadly though, across architectures and training
regimes the trade-offs are more nuanced, illustrating the complex landscape of
compression methods.

</details>


### [149] [On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?](https://arxiv.org/abs/2510.20810)
*Mingmeng Geng,Thierry Poibeau*

Main category: cs.CL

TL;DR: LLM生成文本的检测目标不明确，现有方法无法满足实际应用，检测结果只能作为参考。


<details>
  <summary>Details</summary>
Motivation: LLM的广泛使用导致了对其生成文本的检测需求，但“LLM生成文本”的定义不明确，且LLM的多样性和应用场景的差异增加了检测的难度。现有基准和评估方法未能充分考虑实际应用中的各种情况，导致检测结果的数值被误解，意义减弱。

Method: 本文分析了LLM生成文本检测的挑战，包括定义模糊、多样性、人类编辑和用户影响等，并指出现有基准和评估方法的不足。

Result: 现有检测方法的数值结果常常被误解，其意义正在减弱。LLM生成文本检测结果在特定条件下仍然有用，但只能作为参考，不能作为决定性指标。

Conclusion: LLM生成文本的检测是一个复杂的问题，目前的检测工具和评估方法存在局限性。因此，在使用这些工具时，应谨慎解释其结果，并将其视为参考而非最终判定。

Abstract: With the widespread use of large language models (LLMs), many researchers
have turned their attention to detecting text generated by them. However, there
is no consistent or precise definition of their target, namely "LLM-generated
text". Differences in usage scenarios and the diversity of LLMs further
increase the difficulty of detection. What is commonly regarded as the
detecting target usually represents only a subset of the text that LLMs can
potentially produce. Human edits to LLM outputs, together with the subtle
influences that LLMs exert on their users, are blurring the line between
LLM-generated and human-written text. Existing benchmarks and evaluation
approaches do not adequately address the various conditions in real-world
detector applications. Hence, the numerical results of detectors are often
misunderstood, and their significance is diminishing. Therefore, detectors
remain useful under specific conditions, but their results should be
interpreted only as references rather than decisive indicators.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [150] [Macroscopic quantum phenomena and quantum computing](https://arxiv.org/abs/2510.19846)
*Jian-Qiang You*

Main category: quant-ph

TL;DR: 文章概述了2025年诺贝尔物理学奖的突破性发现，即超导电路中的宏观量子隧穿和能量量子化，回顾了该发现的背景及其对量子计算的深远影响。


<details>
  <summary>Details</summary>
Motivation: 本文旨在评述2025年诺贝尔物理学奖的突破性发现，重点关注其在超导电路中实现的宏观量子隧穿和能量量子化现象。

Method: 本文从宏观量子隧穿和能量量子化的角度，结合其在超导电路中的实现，对2025年诺贝尔物理学奖的发现进行了评述，并探讨了其历史背景和对量子计算发展的影响。

Result: 文章评述了宏观量子隧穿和能量量子化的发现，并分析了该发现对量子计算领域的推动作用。

Conclusion: 宏观量子隧穿和能量量子化是2025年诺贝尔物理学奖的重大突破，对量子计算的发展产生了深远影响。

Abstract: This News & Views article provides a perspective on the 2025 Nobel Prize in
Physics, including the groundbreaking discovery of macroscopic quantum
tunneling and energy quantization in superconducting circuits, the history and
causes giving rise to this breakthrough, and its impact on subsequent progress
in quantum computing.

</details>


### [151] [Two Quantum Algorithms for Nonlinear Reaction-Diffusion Equation using Chebyshev Approximation Method](https://arxiv.org/abs/2510.19855)
*Manish Kumar*

Main category: quant-ph

TL;DR: 本文提出两种基于截断切比雪夫多项式近似的量子算法，用于求解反应扩散方程，并推导了Carleman嵌入矩阵对角化的充分条件。


<details>
  <summary>Details</summary>
Motivation: 为反应扩散方程提供新的量子算法，并解决其数值求解中的关键数学问题。

Method: 使用截断切比雪夫多项式近似，结合矩阵指数法和量子谱方法，并提出对Carleman嵌入矩阵对角化的新方法。

Result: 提出了两种量子算法，并分析了它们的门复杂度，其中第二种算法在T和ε方面与现有最佳算法相当。

Conclusion: 提出的方法在大多数实际情况下是有效的，但存在未给出Carleman矩阵的条件数上界以及对一个三角方程解的猜想依赖等局限性，并提出了相应的缓解策略。

Abstract: We present two new quantum algorithms for reaction-diffusion equations that
employ the truncated Chebyshev polynomial approximation. This method is
employed to numerically solve the ordinary differential equation emerging from
the linearization of the associated nonlinear differential equation. In the
first algorithm, we use the matrix exponentiation method (Patel et al., 2018),
while in the second algorithm, we repurpose the quantum spectral method (Childs
et al., 2020). Our main technical contribution is to derive the sufficient
conditions for the diagonalization of the Carleman embedding matrix, which is
indispensable for designing both quantum algorithms. We supplement this with an
efficient iterative algorithm to diagonalize the Carleman matrix.
  Our first algorithm has gate complexity of
O(d$\cdot$log(d)+T$\cdot$polylog(T/$\varepsilon$)). Here $d$ is the size of the
Carleman matrix, $T$ is the simulation time, and $\varepsilon$ is the
approximation error. The second algorithm is polynomial in $log(d)$, $T$, and
$log(1/\varepsilon)$ - the gate complexity scales as
O(polylog(d)$\cdot$T$\cdot$polylog(T/$\varepsilon$)). In terms of $T$ and
$\varepsilon$, this is comparable to the speedup gained by the current best
known quantum algorithm for this problem, the truncated Taylor series method
(Costa et.al., 2025).
  Our approach has two shortcomings. First, we have not provided an upper
bound, in terms of d, on the condition number of the Carleman matrix. Second,
the success of the diagonalization is based on a conjecture that a specific
trigonometric equation has no integral solution. However, we provide strategies
to mitigate these shortcomings in most practical cases.

</details>


### [152] [Experimental differentiation and extremization with analog quantum circuits](https://arxiv.org/abs/2510.20713)
*Evan Philip,Julius de Hond,Vytautas Abramavicius,Kaonan Micadei,Mario Dagrada,Panagiotis Barkoutsos,Mourad Beji,Louis-Paul Henry,Vincent E. Elfving,Antonio A. Gentile,Savvas Varsamopoulos*

Main category: quant-ph

TL;DR: 本文首次实验演示了可微分量子电路（DQC）和量子极值学习（QEL），并在模拟的用例中展示了它们的性能。与预期相反，我们成功地在基于中性原子的商用模拟量子计算机上运行了 DQC 和 QEL 的闭环实例，证明了它们在非数字量子硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 在工程和科学领域，求解和优化微分方程（DEs）至关重要。量子计算机在加速科学计算方面的潜力，自然引起了人们对量子算法求解 DEs 效率的兴趣。DQC 提供了一种使用变分方法计算 DEs 解的可行途径，这种方法适用于现有的量子计算机，通过生成 DEs 解的机器学习替代模型。QEL 通过寻找未知（隐式）函数的可学习模型的输出中的极值点来补充 DQC 方法，在只需要获得 DEs 解的极值时，它提供了一种绕过完整 DEs 解的强大工具。

Method: 本文首次实验演示了 DQC 和 QEL，并在模拟的用例中展示了它们的性能。实验在基于中性原子的商用模拟量子计算机上进行。

Result: 实验成功在模拟的用例中演示了 DQC 和 QEL 的性能。

Conclusion: DQC 和 QEL 都可以成功地在模拟量子计算机上运行，而不需要数字量子硬件。

Abstract: Solving and optimizing differential equations (DEs) is ubiquitous in both
engineering and fundamental science. The promise of quantum architectures to
accelerate scientific computing thus naturally involved interest towards how
efficiently quantum algorithms can solve DEs. Differentiable quantum circuits
(DQC) offer a viable route to compute DE solutions using a variational approach
amenable to existing quantum computers, by producing a machine-learnable
surrogate of the solution. Quantum extremal learning (QEL) complements such
approach by finding extreme points in the output of learnable models of unknown
(implicit) functions, offering a powerful tool to bypass a full DE solution, in
cases where the crux consists in retrieving solution extrema. In this work, we
provide the results from the first experimental demonstration of both DQC and
QEL, displaying their performance on a synthetic usecase. Whilst both DQC and
QEL are expected to require digital quantum hardware, we successfully challenge
this assumption by running a closed-loop instance on a commercial analog
quantum computer, based upon neutral atom technology.

</details>


### [153] [On Encoding Matrices using Quantum Circuits](https://arxiv.org/abs/2510.20030)
*Liron Mor Yosef,Haim Avron*

Main category: quant-ph

TL;DR: 本文研究了量子计算在线性代数中的应用，重点是矩阵的量子编码方法，并提出了高效构建块编码和状态准备电路的转换方法。


<details>
  <summary>Details</summary>
Motivation: 量子算法（如HHL）的有效执行依赖于输入（矩阵和向量）的量子表示，而块编码和状态准备电路是两种主要的表示方法。

Method: 本文系统地研究了块编码和状态准备电路这两种矩阵的量子表示方法，包括从经典矩阵构建这些表示，以及它们之间的双向转换。文中提出了高效构建任意经典矩阵的块编码的方法，并开发了低开销的双向转换算法，证明了这两种表示方法本质上是等价的。关键技术包括一个特殊的常数深度多路复用器和一个在标准基和高阶泡利矩阵基之间进行量子转换的算法。

Result: （a）提出了一种从经典形式（存储在经典随机访问存储器中）给出任意矩阵的高效构建块编码的通用方法。（b）开发了块编码和状态准备电路之间低开销的双向转换算法，表明这两种模型基本等价。

Conclusion: 块编码和状态准备电路是等价的，并且存在高效的转换方法，这为在量子计算机上执行线性代数算法提供了更灵活和高效的实现途径。

Abstract: Over a decade ago, it was demonstrated that quantum computing has the
potential to revolutionize numerical linear algebra by enabling algorithms with
complexity superior to what is classically achievable, e.g., the seminal HHL
algorithm for solving linear systems. Efficient execution of such algorithms
critically depends on representing inputs (matrices and vectors) as quantum
circuits that encode or implement these inputs. For that task, two common
circuit representations emerged in the literature: block encodings and state
preparation circuits. In this paper, we systematically study encodings matrices
in the form of block encodings and state preparation circuits. We examine
methods for constructing these representations from matrices given in classical
form, as well as quantum two-way conversions between circuit representations.
Two key results we establish (among others) are: (a) a general method for
efficiently constructing a block encoding of an arbitrary matrix given in
classical form (entries stored in classical random access memory); and (b)
low-overhead, bidirectional conversion algorithms between block encodings and
state preparation circuits, showing that these models are essentially
equivalent. From a technical perspective, two central components of our
constructions are: (i) a special constant-depth multiplexer that simultaneously
multiplexes all higher-order Pauli matrices of a given size, and (ii) an
algorithm for performing a quantum conversion between a matrix's expansion in
the standard basis and its expansion in the basis of higher-order Pauli
matrices.

</details>


### [154] [Mind the gaps: The fraught road to quantum advantage](https://arxiv.org/abs/2510.19928)
*Jens Eisert,John Preskill*

Main category: quant-ph

TL;DR: 量子计算在NISQ设备和 FASQ机器之间存在差距，需要克服技术障碍以实现广泛应用。


<details>
  <summary>Details</summary>
Motivation: 弥合当前嘈杂中型量子（NISQ）设备与未来容错应用规模（FASQ）量子计算机之间的差距。

Method: 识别并解决四个关键挑战：从错误缓解到主动错误检测和纠正，从初级错误纠正到可扩展容错，从初步启发式算法到成熟、可验证的算法，以及从探索性模拟器到可信的量子模拟优势。

Result: 明确了实现可广泛应用的量子计算所需的关键技术进步方向。

Conclusion: 通过解决这些技术挑战，可以加速实现广泛有用的量子计算。

Abstract: Quantum computing is advancing rapidly, yet substantial gaps separate today's
noisy intermediate-scale quantum (NISQ) devices from tomorrow's fault-tolerant
application-scale (FASQ) machines. We identify four related hurdles along the
road ahead: (i) from error mitigation to active error detection and correction,
(ii) from rudimentary error correction to scalable fault tolerance, (iii) from
early heuristics to mature, verifiable algorithms, and (iv) from exploratory
simulators to credible advantage in quantum simulation. Targeting these
transitions will accelerate progress toward broadly useful quantum computing.

</details>


### [155] [Classical Gravity Cannot Mediate Entanglement by Local Means](https://arxiv.org/abs/2510.19969)
*Chiara Marletto,Vlatko Vedral*

Main category: quant-ph

TL;DR: 经典引力无法通过局部手段纠缠两个宏观叠加态，该论文反驳了另一篇声称相反观点的论文，并阐述了引力场产生纠缠所需的量子特性。


<details>
  <summary>Details</summary>
Motivation: 反驳一篇声称经典引力可以通过局部手段纠缠两个宏观叠加态的近期论文，并澄清了引力场要实现远距离质量间的纠缠，其本身必须具备量子特性。

Method: 通过指出对方论文中的谬误来反驳其论点。

Result: 证明了经典引力无法通过局部手段实现宏观叠加态的纠缠。

Conclusion: 引力场若要实现远距离质量间的纠缠，其本身必须具备量子特性。

Abstract: We rebut a recent paper that claims that classical gravity can entangle two
massive superpositions by local means. We refute the misconceptions appearing
in this paper and confirm that the quantum features are necessary in the
gravitational field if it can lead to entanglement by local propagation between
distant masses.

</details>


### [156] [Morphological computational capacity of Physarum polycephalum](https://arxiv.org/abs/2510.19976)
*Suyash Bajpai,Aviva Lucas-DeMott,Nirosha J Murugan,Michael Levin,Philip Kurian*

Main category: quant-ph

TL;DR: Physarum polycephalum, a neuron-lacking organism, has a computational capacity of up to 10^36 logical operations in 24 hours, determined by analyzing its growth dynamics and energy resources. This provides a framework for comparing computational capacities across different life forms.


<details>
  <summary>Details</summary>
Motivation: Establish a stricter computational capacity bound for an-neural organisms, specifically Physarum polycephalum, which exhibits complex problem-solving abilities without neurons.

Method: Analyzed growth dynamics of two Physarum strains under various conditions, mapping morphological evolution to information processing. Quantified morphology (area, perimeter, circularity, fractal dimension) and analyzed spatial distribution of ATP and explored areas to determine logical operations, drawing parallels with the Margolus-Levitin theorem.

Result: Physarum can perform up to approximately 10^36 logical operations in 24 hours, scaling linearly in the non-equilibrium steady state, based on its ATP distribution and explored areas. This is constrained by its hydromechanical, chemical, kinetic, and quantum-optical degrees of freedom.

Conclusion: A framework is established to estimate the computational capacity of an-neural organisms like Physarum, enabling comparisons with other life forms based on their exploitation of classical or quantum degrees of freedom. The study quantifies Physarum's computational potential.

Abstract: While computational capacity limits of the universe and carbon-based life
have been estimated, a stricter bound for aneural organisms has not been
established. Physarum polycephalum, a unicellular, multinucleated amoeba, is
capable of complex problem-solving despite lacking neurons. By analyzing growth
dynamics in two distinct Physarum strains under diverse biological conditions,
we map morphological evolution to information processing. As the
Margolus-Levitin theorem constrains maximum computation rates by accessible
energies, we analyze high-throughput time-series data of Physarum's
morphology--quantified through area, perimeter, circularity, and fractal
dimension-to determine upper bounds on the number of logical operations
achievable through its hydromechanical, chemical, kinetic, and quantum-optical
degrees of freedom. Based on spatial distribution of ATP and explored areas,
Physarum can perform up to ~$10^{36}$ logical operations in 24 hours, scaling
linearly in the non-equilibrium steady state. This framework enables comparison
of the computational capacities of life, exploiting either classical or quantum
degrees of freedom.

</details>


### [157] [A transmon qubit realized by exploiting the superconductor-insulator transition](https://arxiv.org/abs/2510.19983)
*C. G. L. Bøttcher,E. Önder,T. Connolly,J. Zhao,C. Kvande,D. Q. Wang,P. D. Kurilovich,S. Vaitiekėnas,L. I. Glazman,H. X. Tang,M. H. Devoret*

Main category: quant-ph

TL;DR: 本工作提出了一种基于超导体-绝缘体跃迁的新型超导弱连接，以解决现有约瑟夫森结在可扩展性方面存在的限制。


<details>
  <summary>Details</summary>
Motivation: 现有约瑟夫森结（铝氧化铝）存在需要极低工作温度、材料界面耗散以及额外电容等问题，阻碍了量子处理器的可扩展性。

Method: 通过原子层沉积和原子层蚀刻技术，对氮化铌薄膜进行局部减薄，利用其厚度驱动的超导体-绝缘体跃迁（SIT）形成弱连接。

Result: 成功制备了名为'planaron'的跨扰动量子比特，测量得到其非简并度为 $\alpha/2\pi = 235$ MHz，线宽为 $\kappa/2\pi = 15 \mathrm{ \: MHz}$。

Conclusion: 该新型弱连接利用了氮化铌的高超导能隙，有望实现更高工作温度的量子器件，并消除了额外的材料界面和电容。此外，对SIT附近小块材料的研究有助于理解SIT的性质、耗散和有限尺寸效应。

Abstract: Superconducting qubits are among the most promising platforms for realizing
practical quantum computers. One requirement to create a quantum processor is
nonlinearity, which in superconducting circuits is typically achieved by
sandwiching a layer of aluminum oxide between two aluminum electrodes to form a
Josephson junction. These junctions, however, face several limitations that
hinder their scalability: the small superconducting gap of aluminum
necessitates millikelvin operating temperatures, the material interfaces lead
to dissipation, and the sandwich geometry adds unwelcome capacitance for
high-frequency applications. In this work, we address all three limitations
using a novel superconducting weak link based on the superconductor-insulator
transition. By locally thinning a single film of niobium nitride, we exploit
its thickness-driven superconductor-insulator transition to form a weak link
employing only atomic layer deposition and atomic layer etching. We utilize our
weak links to produce a transmon qubit, '$planaron$', with a measured
anharmonicity of $\alpha/2\pi = 235$ MHz; at present, the linewidth is
$\kappa/2\pi = 15 \mathrm{\: MHz}$. The high superconducting gap of niobium
nitride can enable operation at elevated temperatures in future devices, and
the fully planar geometry of the weak link eliminates superfluous material
interfaces and capacitances. The investigation of small patches of material
near the SIT can shed new light on the nature of the transition, including the
role of dissipation and finite-size effects.

</details>


### [158] [On the separation of quantum time evolution into holonomic and dynamical parts](https://arxiv.org/abs/2510.19987)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 量子时间演化在非绝热非阿贝尔情况下不能被一般性地分离成全纯和动力学部分。


<details>
  <summary>Details</summary>
Motivation: 探讨在非绝热非阿贝尔情况下分离薛定谔类型量子时间演化的全纯和动力学部分的问题。

Method: 反驳了近期一篇论文的观点，证明了这种分离在一般情况下是无效的。

Result: 证明了量子时间演化不能被一般性地分离成全纯和动力学部分。

Conclusion: 在非绝热非阿贝尔情况下，量子时间演化不能一般性地分离成全纯和动力学部分。

Abstract: The issue of separating Schr\"odinger-type quantum time evolution into a
product of holonomic and dynamical parts in the non-adiabatic non-Abelian case
is addressed. Contrary to the recent claim in [Phys. Rev. Lett. 131, 200202
(2023)], we establish that such separation is generally invalid.

</details>


### [159] [Reduced State Embedding for Error Correction in Quantum Cryptography](https://arxiv.org/abs/2510.19989)
*Amit Kam,Kfir Sulimany,Shai Tsesses,Uzi Pereg*

Main category: quant-ph

TL;DR: 通过使用降维嵌入技术，在量子密钥分发中实现了显式的擦除型纠错，提高了安全码率。


<details>
  <summary>Details</summary>
Motivation: 高维量子编码虽然能提升抗噪声能力，但也可能导致模式间串扰和检测复杂性，从而降低量子密码学性能。需要新的纠错方法来利用高维编码的优势。

Method: 提出降维嵌入方法，将k维信号集嵌入到d维希尔伯特空间（k<d），并在量子信道中实现擦除型纠错。

Result: 在现实量子信道中，该方案能产生更高的安全密钥率。实验验证（d=25）并推导了密钥率和阈值的解析表达式，确定了k=5时的最优密钥率。

Conclusion: 该方法在减少量子信道复杂性的同时，能有效提高量子密钥分发的安全密钥率，推动了高维量子密钥分发的发展，并为量子密码学的纠错和调制开辟了新途径。

Abstract: Encoding in a high-dimensional Hilbert space improves noise resilience in
quantum information processing. However, such an approach may result in
cross-mode coupling and detection complexities, thereby reducing quantum
cryptography performance. This fundamental trade-off between correctness and
secrecy motivates the search for new error-correction approaches to better
exploit the advantages of high-dimensional encoding. Here, we introduce the
method of reduced state embeddings to quantum key distribution (QKD): a
k-dimensional signal set embedded in a d-dimensional Hilbert space, where k<d.
In the framework of quantum error correction, our reduced-state embedding
realizes an explicit erasure-type error-correction within the quantum channel.
We demonstrate the advantage of our scheme in realistic quantum channels,
producing a higher secure key rate. We validate our approach using a d=25 QKD
experimental data, derive closed-form expressions for the key rate and
threshold, and determine the optimal key rate at k=5. These findings advance
high-dimensional QKD and pave the way to error correction and modulation for
quantum cryptography.

</details>


### [160] [Quantum Nonlinear Response of Emitter Lattices](https://arxiv.org/abs/2510.19992)
*Blas Durá-Azorín,Antonio I. Fernández-Domínguez,Alejandro Manjavacas*

Main category: quant-ph

TL;DR: 该理论研究了由激光相干驱动的二维量子发射器阵列的光学响应中量子非线性现象的出现。对于亚波长周期，系统表现得像一个量子超表面，研究发现，共振入射平面波可以激发出具有与入射场不同的平行波矢的激子布洛赫态，甚至包括那些位于光锥之外的激子布洛赫态。在强驱动模式下，系统的远场发射主要由跨越宽范围频率和波矢的光子背景组成。此外，研究表明，当周期接近驱动波长时，由于驱动率的重整化，发射器阵列会进入一个双稳态区域，这与经典的（玻色子）类似物形成鲜明对比。这种双稳态行为使得系统中的光学量子非线性能够被选择性地激活和禁用。


<details>
  <summary>Details</summary>
Motivation: 研究量子发射器阵列中的量子非线性现象，特别是亚波长周期下量子超表面的行为，以及双稳态现象的出现。

Method: 通过理论研究，分析了在相干激光驱动下，量子发射器阵列的光学响应，包括激子布洛赫态的形成、远场发射的特性以及双稳态行为的出现。

Result: 发现了亚波长周期下可以激发出光锥之外的激子布洛赫态；强驱动模式下存在宽带光子背景；发射器阵列在周期接近驱动波长时表现出双稳态行为。

Conclusion: 量子发射器阵列中的量子非线性现象可以通过调控系统参数（如周期）来实现，并且双稳态行为为选择性地控制这些非线性提供了可能。

Abstract: We theoretically investigate the emergence of quantum nonlinearities in the
optical response of lattices of two-level quantum emitters coherently driven by
a laser. For subwavelength lattice periods, where the system behaves as a
quantum metasurface, we find that a resonant incident plane wave can populate
excitonic Bloch states with parallel wavevectors different from the incident
field, including those lying outside the light cone. Closely related to
resonance fluorescence, the far-field emission from the system in the
strong-driving regime is dominated by a broadband background of photons
spanning a wide range of frequencies and wavevectors. Moreover, we show that,
for periods approaching the driving wavelength, the emitter lattice enters in a
bistable regime due to the renormalization of the driving rate, in striking
contrast with its classical (bosonic) analog. This bistable behavior enables
the selective activation and deactivation of the optical quantum nonlinearities
of the system.

</details>


### [161] [Electronically-controlled one- and two-qubit gates for transmon quasicharge qubits](https://arxiv.org/abs/2510.20127)
*Nicholas M. Christopher,Deniz E. Stiegemann,Abhijeet Alase,Thomas M. Stace*

Main category: quant-ph

TL;DR: 提出了一种基于拓扑超导体和约瑟夫森效应的超导量子比特门操作方案。


<details>
  <summary>Details</summary>
Motivation: 实现低错误率的量子比特，以构建容错的、可用于实际的量子计算机。

Method: 利用电子可控的拓扑超导体形成的隧道结，基于动力学$4	ext{π}$-周期约瑟夫森效应来实现单比特和两比特门操作，并模拟了量子点最小Kitaev链拓扑约瑟夫森结的动力学行为，同时使用费米黄金定则表征了门操作对电荷噪声的鲁棒性。

Result: 实现了单比特和两比特门操作，门操作速度在同一数量级，并分析了对电荷噪声的鲁棒性。

Conclusion: 基于拓扑约瑟夫森结的方案为实现准电荷量子比特门提供了一种有前景的策略。

Abstract: Superconducting protected qubits aim to achieve sufficiently low error rates
so as to allow realization of error-corrected, utility-scale quantum computers.
A recent proposal encodes a protected qubit in the quasicharge degree of
freedom of the conventional transmon device, here referred to as the
`quasicharge qubit'. Operating such a protected qubit requires implementing new
strategies. Here we show that an electronically-controllable tunnel junction
formed by two topological superconductors can be used to implement single- and
two-qubit gates on quasicharge qubits. Schemes for both these gates are based
on dynamical $4\pi$-periodic Josephson effect and therefore have gate speeds of
the same order. The simulation of the dynamics of a topological Josephson
junction in a parameter regime with non-negligible charging energy is the key
novelty of this work. We also characterize the robustness of such gate
operations against charge noise using Fermi's golden rule. Our results point to
a compelling strategy for implementation of quasicharge qubit gates based on
junctions of minimal Kitaev chains of quantum dots.

</details>


### [162] [Exact State Evolution and Energy Spectrum in Solvable Bosonic Models](https://arxiv.org/abs/2510.20046)
*Valery Shchesnovich*

Main category: quant-ph

TL;DR: 该论文提出了一个分析框架，用于求解可解玻色子模型中光传播的时间演化问题，并推导了能量谱的特征方程和特征态。


<details>
  <summary>Details</summary>
Motivation: 在量子光学中，确定给定初始状态的时间演化是核心目标，需要对非线性介质中的光传播（如产生压缩光的下转换过程）进行建模。

Method: 推导了可解玻色子模型和任意初始状态的精确解析解，并以连分式和雅可比矩阵的秩和的形式表示了特征方程和特征态。

Result: 找到了描述可解玻色子模型演化的精确解析解，以及能量谱的特征方程和特征态。

Conclusion: 提出的分析框架为精确可解玻色子模型的研究提供了坚实的理论基础。

Abstract: Solvable bosonic models provide a fundamental framework for describing light
propagation in nonlinear media, including optical down-conversion processes
that generate squeezed states of light and their higher-order generalizations.
In quantum optics a central objective is to determine the time evolution of a
given initial state. Exact analytic solution to the state-evolution problem is
presented, applicable to a broad class of solvable bosonic models and arbitrary
initial states. Moreover, the characteristic equation governing the energy
spectrum is derived and the eigenstates are found in the form of continued
fractions and as principal minors of the associated Jacobi matrix. The results
provide a solid analytical framework for discussion of exactly solvable bosonic
models.

</details>


### [163] [Unveiling non-Hermitian band structures with non-Bloch supercells](https://arxiv.org/abs/2510.20160)
*Jia-Xin Zhong,Jing Lin,Kai Chen,Jing Lu,Kun Ding,Yun Jing*

Main category: quant-ph

TL;DR: 本研究提出了一种非Bloch超胞方法，用于解决非厄米系统中复杂能带的实验表征挑战。


<details>
  <summary>Details</summary>
Motivation: 厄米系统中的实值能带是分析周期系统的基础，但非厄米系统中的复杂能带（能量和动量均有虚部）导致了常规布洛赫理论失效的现象，如非厄米奇异态和异常的体边对应。实验上精确表征这些复杂能带并识别其对应的本征态对于理解这些系统至关重要，但仍然是一个重大挑战。

Method: 提出了一种非Bloch超胞框架，该框架通过解耦布洛赫相位控制和动量的虚部，结合指数展平协议和扭曲边界条件，实现了与系统尺寸无关的虚动量控制，同时保持了高分辨率的布洛赫相位采样。

Result: 该方法被应用于可编程的一维和二维声子晶体，通过格林函数测量获得了动量分辨的复杂能量表面和双正交本征模式。所获得的数据能够准确预测开边界谱和本征态，并通过独立的开几何实验进行了验证。

Conclusion: 本研究提供了一个广泛适用的实验工具集，用于探索不同工程化经典和量子平台中的非厄米能带几何和拓扑。

Abstract: Real-valued band structures are foundational to analyzing periodic systems
within the Hermitian description and have been experimentally well-established
over recent decades. In contrast, non-Hermitian systems exhibit complex band
structures where both energy and momentum have imaginary parts, underpinning
phenomena like the non-Hermitian skin effect and anomalous bulk-boundary
correspondence that defy conventional Bloch theory. Experimentally mapping
these complex bands-relating complex momentum to complex energy-and identifying
their associated eigenstates is crucial for understanding these systems but
remains a significant challenge. Here, we introduce a non-Bloch supercell
framework designed to overcome this challenge by decoupling Bloch phase control
from the imaginary part of momentum. Our method combines an exponent-flattening
protocol with twisted boundary conditions, enabling system-size-independent
control of imaginary momentum while preserving high-resolution Bloch phase
sampling. Implemented in programmable one- and two-dimensional acoustic
crystals, our approach acquires momentum-resolved complex energy surfaces and
biorthogonal eigenmodes by Green's function measurements.Data obtained using
this framework accurately predict open-boundary spectra and eigenstates,
findings we verify through separate open-geometry experiments. Our work
provides a broadly applicable experimental toolkit for exploring non-Hermitian
band geometry and topology in diverse engineered classical and quantum
platforms.

</details>


### [164] [Photon Quantum Mechanics](https://arxiv.org/abs/2510.20049)
*Margaret Hawton*

Main category: quant-ph

TL;DR: We quantize the electromagnetic Lagrangian to describe photons as discrete excitations of the classical EM field. The theory is covariant, with zero longitudinal photon number and a real number density for physical photons. This approach avoids the need for a nonlocal frequency operator.


<details>
  <summary>Details</summary>
Motivation: The motivation is to obtain a covariant theory of discrete excitations of the classical EM field, which can be properly called photons, by second quantizing the standard electromagnetic Lagrangian with a subsidiary Lorenz gauge constraint.

Method: The method involves second quantizing the standard electromagnetic Lagrangian with a subsidiary Lorenz gauge constraint. This leads to a covariant theory where the longitudinal photon number is zero due to cancellation of Gupta-Bleuler like terms. Physical photons are described by a real number density whose spatial integral is unity, interpretable as a probability density.

Result: The result is a covariant theory of photons where the longitudinal photon number is zero. Physical photons are described by a real number density, which acts as a probability density. The energy density does not require separation into positive and negative frequency parts, thus avoiding a nonlocal frequency operator.

Conclusion: The paper successfully presents a covariant theory of photons by quantizing the electromagnetic field in a specific way that eliminates the need for a nonlocal frequency operator and provides a probabilistic interpretation for photon detection.

Abstract: We second quantize the standard electromagnetic Lagrangian with a subsiduary
Lorenz gauge constraint to obtain a covariant theory of the discrete
excitations of the classical EM field that can properly be called photons. The
longitudinal photon number is zero due to cancellation of Gupta-Bleuler like
terms. Physical photons are described by a real number density whose spatial
integral is unity so it can be interpreted as the probability density to find a
photon at position x'. Energy density is not separated into is positive and
negative frequency parts so the nonlocal frequency operator is not required.

</details>


### [165] [All-Gaussian State Discrimination Beyond the Coherent Helstrom Bound](https://arxiv.org/abs/2510.20096)
*Angus Waslh,Lorcan Conlon,Biveen Shajilal,Ozlem Erkilic,Jiri Janousek,Syed Assad,Jie Zhao,Ping Koy Lam*

Main category: quant-ph

TL;DR: 利用高斯光学方法在BPSK信号判别上取得了突破，错误率低于相干态和任何量子测量的极限。


<details>
  <summary>Details</summary>
Motivation: 通信中的核心问题是二相移键控（BPSK）信号的最优判别，实现Helstrom极限一直是该领域的目标，但现有方法因技术限制而难以实现。

Method: 采用仅包含高斯光学元件（如位移压缩态和零拍探测）的方法，以一种不同于以往的技术路径实现BPSK信号的判别。

Result: 实验实现了BPSK信号判别，且错误率低于使用相干态和任何量子测量方法所能达到的最优判别错误率。

Conclusion: 所提出的仅利用高斯光学元件（位移压缩态和零拍探测）的方法，能够以低于相干态和任何量子测量的错误率实现BPSK信号的判别，为通信领域提供了新的技术途径。

Abstract: A core problem in communications is the optimal discrimination of
binary-phase-shift-keyed (BPSK) signals. A longstanding goal has been to reach
the fundamental quantum limit, known as the Helstrom bound, for BPSK signals
encoded in coherent states. However, due to technical constraints, proposals
for reaching the bound remain impractical. In this letter we take an
alternative approach: using only Gaussian optics - displaced squeezed states
and homodyne detection - we achieve discrimination of BPSK signals with error
rates below what can be achieved using coherent states and any quantum
measurement.

</details>


### [166] [Variational quantum simulation of many-body dissipative dynamics on a superconducting quantum processor](https://arxiv.org/abs/2510.20118)
*Huan-Yu Liu,Tai-Ping Sun,Zhao-Yun Chen,Cheng Xue,Chao Wang,Xi-Ning Zhuang,Jin-Peng Liu,Wei Yi,Yu-Chun Wu,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 该算法提出了一种可扩展的模拟非单一多体耗散动力学的方法，适用于近期量子硬件，并且线路深度与模拟时间无关。


<details>
  <summary>Details</summary>
Motivation: 模拟开放量子系统中的复杂现象，克服希尔伯特空间指数增长和动力学非单一性的挑战。

Method: 提出了一种基于哈密顿模拟线性组合的变分量子算法，将非单一动力学转化为单一演化的加权和，并引入简化的量子线路进行损失函数评估。

Result: 在超导量子处理器上成功模拟了耗散横向伊辛模型和相互作用的Hatano-Nelson模型的集体动力学。

Conclusion: 证明了嘈杂的中尺度量子设备在模拟耗散多体动力学方面的潜力，并向利用它们解决物理学难题迈出了重要一步。

Abstract: Open quantum systems host a wide range of intriguing phenomena, yet their
simulation on well-controlled quantum devices is challenging, owing to the
exponential growth of the Hilbert space and the inherently non-unitary nature
of the dynamics. Here we propose and experimentally demonstrate a variational
quantum algorithm capable of scalable simulation of non-unitary many-body
dissipative dynamics. The algorithm builds on the framework of linear
combination of Hamiltonian simulation, which converts non-unitary dynamics into
a weighted sum of unitary evolutions. With the further introduction of a
simplified quantum circuit for loss-function evaluation, our scheme is suitable
for near-term quantum hardware, with the circuit depth independent of the
simulation time. We illustrate our scheme by simulating the collective dynamics
of a dissipative transverse Ising model, as well as an interacting
Hatano-Nelson model, on the superconducting quantum processor Wukong. Our work
underlines the capability of noisy intermediate-scale quantum devices in
simulating dissipative many-body dynamics and represents a step forward in
exploiting their potential for solving outstanding physical problems.

</details>


### [167] [Quantum mysteries explained in digestible form](https://arxiv.org/abs/2510.20144)
*Alejandro Hnilo*

Main category: quant-ph

TL;DR: 本篇论文将量子现象与实数空间中的向量进行比较，以解释量子现象和经典现象之间的差异，并提出了一个合理的解释框架。


<details>
  <summary>Details</summary>
Motivation: 解答Itamar Pitowski提出的关于微观（量子）现象与宏观（经典）现象差异原因以及何种解释是合理的问题。

Method: 将量子现象与实数空间中的向量的某些特征进行比较，并展示了如何用向量来理解贝尔不等式违反、量子传送、Kochen-Specker定理和Greenberger-Horne-Zeilinger定理。

Result: 展示了量子现象可以通过向量的特征来理解，这并不意味着量子与经典现象的差异是虚幻的，而是表明向量本身比初看起来更奇特。

Conclusion: 量子现象与经典现象的差异可以通过将量子现象与实数空间中的向量进行比较来解释，这揭示了向量比表面上看起来更复杂的性质。

Abstract: Years ago, Itamar Pitowski asked two relevant questions: Why microphysical
(quantum) phenomena and classical phenomena differ in the way they do? and,
what kind of explanation could qualify as a reasonable one? I argue that both
questions can be answered by the comparison of quantum phenomena with some
features of vectors in real space. In particular, I show how violation of
Bell's inequalities, Teleportation, Kochen-Specker and
Greenberger-Horne-Zeilinger theorems can be understood in terms of vectors.
This does not mean that the difference between quantum and classical phenomena
is illusory. This means that vectors are stranger objects that they may seem to
be at first sight.

</details>


### [168] [Efficient Floating-Point Arithmetic on Fault-Tolerant Quantum Computers](https://arxiv.org/abs/2510.20145)
*José E. Cruz Serrallés,Oluwadara Ogunkoya,Do{g}a Murat Kürkçüo{g}lu,Nicholas Bornman,Norm M. Tubman,Anna Grassellino,Silvia Zorzetti,Riccardo Lattanzi*

Main category: quant-ph

TL;DR: 提出了一种新的浮点编码方案，使用补码定点尾数和补码整数指数，并将其应用于量子算法进行基本算术运算，在量子计算机模拟中表现出良好的性能和资源节省。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的浮点编码方案，并将其应用于量子算法以解决基本算术问题。

Method: 使用补码定点尾数和补码整数指数对浮点数进行编码，并开发了相应的量子算法。通过在量子计算机模拟中进行倒数运算和求解一阶常微分方程来评估该方案的性能。

Result: 随着量子比特数量的增加，该方案的收敛速度很快，并且在倒数运算中所需的辅助量子比特数量显著减少。

Conclusion: 所提出的浮点编码方案在量子计算中具有潜力，能够高效地进行算术运算，并能减少所需的量子资源。

Abstract: We propose a novel floating-point encoding scheme that builds on prior work
involving fixed-point encodings. We encode floating-point numbers using Two's
Complement fixed-point mantissas and Two's Complement integral exponents. We
used our proposed approach to develop quantum algorithms for fundamental
arithmetic operations, such as bit-shifting, reciprocation, multiplication, and
addition. We prototyped and investigated the performance of the floating-point
encoding scheme on quantum computer simulations by performing reciprocation on
randomly drawn inputs and by solving first-order ordinary differential
equations, while varying the number of qubits in the encoding. We observed
rapid convergence to the exact solutions as we increased the number of qubits
and a significant reduction in the number of ancilla qubits required for
reciprocation when compared with similar approaches.

</details>


### [169] [Parametric Phase Modulation in Superconducting Circuits](https://arxiv.org/abs/2510.20192)
*Zhuang Ma,Xianke Li,Hongyi Shi,Ruonan Guo,Jianwen Xu,Xinsheng Tan,Yang Yu*

Main category: quant-ph

TL;DR: 通过调整耦合到两个超导量子比特的参数通量脉冲的相对相位，提出并实现了一种新的相位调制方案，用于控制量子比特的相互作用强度，为参数驱动的量子模拟和门操作提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的参数调制方法通过改变通量脉冲的幅度来调节量子比特的耦合强度，这会显著影响量子比特参数，限制了其通用性。

Method: 提出并实现了一种相位调制方案，通过调整施加到两个耦合量子比特上的参数通量脉冲之间的相对相位来调节相互作用强度。

Result: 该方法在甜点和非甜点位置都实现了边带耦合的相位控制，并通过布居数动力学和光谱学方法证实了其可调范围广泛的耦合强度。

Conclusion: 所提出的相位调制方案能够实现耦合强度的相位控制，为参数驱动的量子模拟和门操作提供了一种有前景的方法。

Abstract: Parametric modulation is widely employed in superconducting circuits for
quantum simulations and high-fidelity two-qubit gates, valued for its
versatility. Conventionally, the qubit coupling strength is determined by the
amplitude of the parametric flux pulse, which affects qubit parameters
dramatically. In this article, we propose and implement a phase modulation
scheme to tune the interaction strength via adjusting the relative phase
between the parametric flux pulses applied to two coupled qubits. We
characterize this modulation for sideband couplings, at both sweet and offsweet
spots, achieving a broad range of coupling strengths as confirmed by both
population dynamics and spectroscopy methods. This approach enables
phase-controlled modulation of coupling strength, providing a promising
candidate for parametrically driven quantum simulations and gate operations.

</details>


### [170] [Non-Markovianity in Quantum Information Processing: Interplay with Quantum Error Mitigation](https://arxiv.org/abs/2510.20224)
*Suguru Endo,Hideaki Hakoshima,Tomohiro Shitara*

Main category: quant-ph

TL;DR: The negativity of non-Markovian dynamics in open quantum systems is relevant to quantum information processing (QIP), specifically in quantum error correction (QEC) and quantum teleportation. This negativity arises from information backflow from the environment and is linked to feedback operations based on measurements of a 'gauge' subsystem. The study shows that this negativity can reduce the sampling cost of quantum error mitigation (QEM).


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the relevance of non-Markovian dynamics, particularly negativity, in quantum information processing (QIP), as it has been rarely discussed despite its rich structure.

Method: The method involves partitioning the Hilbert space into logical and gauge subsystems. Negativity is shown to arise from feedback operations based on measurements of the gauge subsystem in the context of QEC and quantum teleportation. The effect of negativity on the sampling cost of QEM is also analyzed.

Result: The study demonstrates that negativity, a characteristic of non-Markovian dynamics, naturally arises in quantum error correction and quantum teleportation. It is shown that this negativity appears as a consequence of feedback operations based on measurement outcomes from the gauge subsystem. Furthermore, the negativity of non-Markovianity in QIP reduces the sampling cost of quantum error mitigation.

Conclusion: The paper concludes that the negativity of non-Markovian dynamics is important in QIP, particularly in QEC and quantum teleportation, due to its connection with information backflow and feedback mechanisms. It also highlights the significance of combining QEC and QEM strategies by showing that negativity reduces the sampling cost of QEM.

Abstract: Non-Markovian dynamics are typically present in the dynamics of open quantum
systems. Despite the rich structure of non-Markovian dynamics, their relevance
to quantum information processing (QIP) has been rarely discussed. In this
work, we demonstrate that the negativity of the dynamics, a characteristic of
non-Markovian dynamics, naturally arises in quantum error correction (QEC) and
quantum teleportation. The negativity in open quantum systems is naturally
attributed to the information backflow from the environment. We partition the
whole Hilbert space into the logical subsystem and the gauge subsystem. The
logical subsystem stores the quantum information for QIP, while the gauge
subsystem stores the information for recovery of the logical information, i.e.,
the syndrome measurement outcomes for quantum error correction and Bell
measurement outcomes for successful teleportation. We then show that the
negativity in quantum information processing appears as a consequence of the
feedback operation based on the measurement outcomes of the gauge subsystem.
Finally, we show that the negativity of non-Markovianity in QIP reduces the
sampling cost of quantum error mitigation (QEM), shedding light on the
importance of combination strategies of QEC and QEM in a practical QIP.

</details>


### [171] [Factorizability of optimal quantum sequence discrimination under maximum-confidence measurements](https://arxiv.org/abs/2510.20311)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 最优量子序列鉴别可分解为各独立状态的鉴别。


<details>
  <summary>Details</summary>
Motivation: 考虑最大置信度测量下的量子序列鉴别问题。

Method: 证明最优鉴别可分解为每一步独立的最大置信度鉴别，并给出最优量子态鉴别的一个充要条件。

Result: 最优量子序列鉴别在最大置信度测量下可以分解为独立步骤的鉴别，最大置信度等于各组成状态的最大置信度。

Conclusion: 量子序列鉴别在最大置信度测量下可以简化为独立状态的鉴别，并给出了相应的充要条件。

Abstract: We consider the discrimination of quantum sequences under maximum-confidence
measurements and show that the optimal discrimination of a quantum sequence
ensemble can always be factorized into that of each individual ensemble. In
other words, the optimal quantum sequence discrimination under
maximum-confidence measurements can be achieved just by performing a
maximum-confidence discrimination independently at each step of the quantum
sequence. We also show that the maximum confidence of identifying a quantum
sequence is to achieve the maximum confidence of identifying each state
comprising the quantum sequence. We further provide a necessary and sufficient
condition for the optimal quantum state discrimination under maximum-confidence
measurements.

</details>


### [172] [Complete characterisation of state conversions by work extraction](https://arxiv.org/abs/2510.20366)
*Chung-Yun Hsieh,Manuel Gessner*

Main category: quant-ph

TL;DR: 该研究提出了一种量子系统能量存储增强的热力学功提取任务，并将其与量子电池充电过程联系起来。


<details>
  <summary>Details</summary>
Motivation: 介绍了一种量子系统能量存储增强的热力学功提取任务，并将其与量子电池的充电过程联系起来。

Method: 该任务诱导了类似majorisation的条件，为通用量子资源理论中的状态转换提供了必要和充分的刻画。将这些条件应用于特定资源，可以简化为unital通道下的majorisation条件，并提供量子纠缠理论中Nielsen定理的热力学版本。

Result: 研究结果表明，该方法可以建立第一个基于热力学的通用资源认证类别，并可用于基于功提取来量化通用量子资源。

Conclusion: 该研究提出了一个通用的量子资源量化框架，该框架基于热力学功提取，并与量子电池的充电过程相关。

Abstract: We introduce a thermodynamic work extraction task that describes the energy
storage enhancement of quantum systems, which is naturally related to quantum
battery's charging process. This task induces majorisation-like conditions that
provide a necessary and sufficient characterisation of state conversions in
general quantum resource theories. When applied to specific resources, these
conditions reduce to the majorisation conditions under unital channels and
provide a thermodynamic version of Nielsen's theorem in entanglement theory. We
show how this result establishes the first universal resource certification
class based on thermodynamics, and how it can be employed to quantify general
quantum resources based on work extraction.

</details>


### [173] [Restoring Quantum Superiority of Noisy Quantum Illumination](https://arxiv.org/abs/2510.20378)
*Wei Wu,Jun-Hong An*

Main category: quant-ph

TL;DR: 量子照明利用量子纠缠来提高低反射率目标的分辨率，但量子噪声会破坏其优势。本文提出了一种在量子噪声存在下恢复量子照明量子优势的方法，通过分析复合系统的能谱，发现当能谱中存在束缚态时，分辨率可以接近理想值，从而为在有噪声情况下实现高分辨率量子照明铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 量子照明技术有望革新雷达技术，但普遍认为量子噪声会破坏其量子优势，限制其在当前量子时代的性能和应用。

Method: 提出了一种在量子噪声存在下恢复量子照明量子优势的方法，超越了常用的玻恩-马尔可夫近似，研究了复合系统的能谱与量子噪声的关系。

Result: 发现量子照明系统的分辨率对复合系统的能谱非常敏感，当能谱中存在束缚态时，分辨率可以接近理想值。

Conclusion: 在量子噪声存在的情况下，通过利用复合系统的能谱中的束缚态，可以恢复量子照明的量子优势，为实现高分辨率量子照明提供了物理原理和可行性。

Abstract: Quantum illumination uses quantum entanglement as a resource to enable
higher-resolution detection of low-reflectivity targets than is possible with
classical techniques. This revolutionary technology could transform modern
radar. However, it is widely believed that the decoherence induced by the
ubiquitous quantum noise destroys the superiority of quantum illumination,
severely constraining its performance and application in our present noisy
intermediate-scale quantum era. Here, we propose a method to restore the
quantum superiority of the quantum illumination in the presence of quantum
noises. Going beyond the widely used Born-Markov approximation, we discover
that the resolution of noisy quantum illumination is highly sensitive to the
energy spectrum of the composite system formed by each of the two light modes
and its local quantum noise. When a bound state is present in the energy
spectrum, the resolution asymptotically approaches its ideal form. Our result
establishes a physical principle to preserve the quantum superiority and paves
the way for the realization of high-resolution quantum illumination in noisy
situations.

</details>


### [174] [Multiplexed ion-ion entanglement over $1.2$ kilometer fibers](https://arxiv.org/abs/2510.20392)
*Z. B. Cui,Z. Q. Wang,P. Y. Liu,Y. Wang,P. C. Lai,J. X. Shi,Y. D. Sun,Z. C. Tian,H. S. Sun,Y. B. Liang,B. X. Qi,Y. Y. Huang,Z. C. Zhou,Y. K. Wu,Y. Xu,Y. F. Pu,L. M. Duan*

Main category: quant-ph

TL;DR: 通过复用10个时间光学模式，在1.2公里光纤上实现了4.59倍的离子-离子纠缠生成加速和95.9±1.5%的纠缠保真度，并演示了首个增强型通信离子网络节点间的通信。


<details>
  <summary>Details</summary>
Motivation: 量子网络和量子中继器是构建大规模量子信息系统的有希望的途径，是分布式量子计算、长距离量子通信和网络量子传感的基础设施。为远程量子节点高效、高保真地建立通信是实现功能性量子网络的关键一步。复用是一种加速远程纠缠分发的有力策略，尤其是在长光纤上。

Method: 通过复用10个时间光学模式，在1.2公里光纤上实现了离子-离子纠缠。

Result: 实现了4.59倍的离子-离子纠缠生成速度的加速，并且纠缠保真度达到了95.9±1.5%。

Conclusion: 该研究展示了首个通过复用技术增强的、在两个通信离子网络节点间的通信，为未来大规模量子网络奠定了关键的基础。

Abstract: Quantum networks and quantum repeaters represent the promising avenues for
building large-scale quantum information systems, serving as foundational
infrastructure for distributed quantum computing, long-distance quantum
communication, and networked quantum sensing. A critical step in realizing a
functional quantum network is the efficient and high-fidelity establishment of
heralded entanglement between remote quantum nodes. Multiplexing offers a
powerful strategy to accelerate remote entanglement distribution, particularly
over long optical fibers. Here, we demonstrate the first multiplexing-enhanced
heralded entanglement between two trapped-ion quantum network nodes. By
multiplexing $10$ temporal photonic modes, we achieve a 4.59-fold speedup in
ion-ion entanglement generation and attain an entanglement fidelity of
$95.9\pm1.5\%$ over $1.2$ km of fiber. Employing a dual-type architecture, our
system is readily scalable to multiple nodes, thereby establishing a key
building block for future large-scale quantum networks.

</details>


### [175] [Robust GHz-range AC Magnetometry with an ensemble of NV Centers in Diamond using Concatenated Continuous Dynamical Decoupling](https://arxiv.org/abs/2510.20401)
*Takuya Kitamura,Genko Genov,Alon Salhov,Yutaka Kobayashi,Shinobu Onoda,Junichi Isoya,Alex Retzker,Fedor Jelezko*

Main category: quant-ph

TL;DR: 使用金刚石中的氮-空位（NV）中心进行亚皮特斯拉水平的磁力测量，通过增加同时用于传感的自旋数量，但空间不均匀性会降低灵敏度。


<details>
  <summary>Details</summary>
Motivation: 解决NV系数量子传感中空间不均匀性对灵敏度的影响，并实现与目前基于Rabi振荡的GHz交流磁力测量技术兼容的方法。

Method: 实验演示了使用级联连续动力学解耦技术来提高NV系数量子传感对空间不均匀驱动场的鲁棒性，并将其与传统的Rabi振荡方法进行比较。

Result: 所提出的级联连续动力学解耦方法在GHz交流磁力测量中显著扩展了测量范围，能够测量更弱的信号，并且对空间不均匀驱动场具有鲁棒性。

Conclusion: 级联连续动力学解耦是一种适用于NV系数量子传感中存在空间不均匀性的鲁棒技术，能够提升GHz交流磁力测量的性能。

Abstract: Sub-picotesla level magnetometry has been demonstrated using
negatively-charged nitrogen-vacancy (NV) centers in diamond by increasing the
number of spins simultaneously used for sensing in an NV ensemble. However,
such scale-up often introduces spatial inhomogeneities in detuning and control
field amplitudes, which degrade sensitivity. Although several techniques have
been utilized to overcome these challenges, including pulsed dynamical
decoupling or shaped pulses, these are not generally compatible with the
current state-of-the-art techniques for GHz-range AC magnetometry with NV
ensembles, which are typically based on Rabi oscillations. In this work we
experimentally demonstrate GHz-range AC magnetometry using a large ensemble of
NV centers under spatially inhomogeneous drive fields by employing concatenated
continuous dynamical decoupling, which is designed for robustness against such
imperfections. We compare its performance with the conventional direct Rabi
method and show that the robust dressed states in our method extend
significantly the measuring range to weaker signals in GHz-range AC
magnetometry.

</details>


### [176] [Realization of Trapped Ion Dynamics in the Strong-Field Regime and Non-Markovianity](https://arxiv.org/abs/2510.20444)
*Kamran Rehan,Hengchao Tu,Menglin Zou,Zihan Yin,Jing-Ning Zhang,Kihwan Kim*

Main category: quant-ph

TL;DR: 研究在强场条件下，具有Rabi频率接近振动频率的离子的量子动力学行为，揭示了非马尔可夫性和量子关联的新特征。


<details>
  <summary>Details</summary>
Motivation: 在强场条件下探索受控量子系统和量子技术的量子动力学，以增进理解并开发更鲁棒的技术。

Method: 通过量子态层析成像技术，重构了离子的密度矩阵，并追踪其演化以评估非马尔可夫性，同时研究了不同参数（Omega, delta）组合下系统的动力学行为。

Result: 在Rabi频率接近振动频率时，观察到非平凡的量子关联和显著的记忆效应，这些效应受内部和运动自由度相互作用的控制。发现在特定参数组合（delta^2 + Omega^2 = nu^2）下，非马尔可夫性呈现出最大值的圆形模式，此时哈密顿量类似于Jaynes-Cummings模型。

Conclusion: 该研究揭示了强场量子动力学的新特征，并为利用离子阱平台研究非马尔可夫性、相干控制以及开放量子系统在极端条件下的基本行为提供了新途径。

Abstract: Probing quantum dynamics in the strong-field regime is critical for advancing
our understanding of controlled quantum systems and developing robust quantum
technologies. In this work, we experimentally investigate the dynamics of a
trapped ion where the Rabi frequency (Omega) approaches the vibrational mode
frequency (nu), pushing the system beyond the weak-field regime, where
non-trivial quantum correlations emerge. We begin by setting the detuning
(delta) - the frequency offset between the qubit transition and the driving
field - to zero and varying Omega from low to high values, eventually reaching
the vibrational frequency. Using quantum state tomography, we reconstruct the
density matrix and track its evolution to assess non-Markovianity, revealing
significant memory effects governed by the interplay between internal and
motional degrees of freedom. Furthermore, by exploring the dynamics across
various parameter pairs (Omega, delta), we find that non-Markovianity does not
always increase monotonically with Omega for a fixed delta. Strikingly, when
the condition delta squared plus Omega squared equals nu squared is met, the
non-Markovianity exhibits a circular pattern of maxima. At this parameter
combination, the system's Hamiltonian takes a form similar to the
Jaynes-Cummings model, enabling the possibility of analytical insights into the
observed dynamics. These results go beyond the conventional carrier and
sideband regimes, uncovering novel features of strong-field quantum dynamics.
Our findings establish a pathway for using trapped-ion platforms to investigate
non-Markovianity, coherent control, and the fundamental behavior of open
quantum systems in extreme regimes.

</details>


### [177] [Mitigating Coherent Errors through a Decoherence-Resistant Variational Framework employing Stabilizer State](https://arxiv.org/abs/2510.20445)
*Giovanni Di Bartolomeo,Giulio Crognaletti,Angelo Bassi,Michele Vischi*

Main category: quant-ph

TL;DR: VCEM是一种利用稳定器形式主义通过变分优化本地门参数来抑制相干误差的方法，该方法对非相干噪声具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 相干误差（如本地门实现中的小角度校准误差）会严重影响量子信息处理中稳定器状态的质量。

Method: VCEM通过变分优化本地门的参数来抑制相干误差，并利用稳定器形式主义。

Result: VCEM在数值模拟中显示出鲁棒的性能，基本不受非相干噪声的影响，并且能够预先补偿相干误差。

Conclusion: VCEM是一种有效且鲁棒的相干误差抑制方法，可以作为标准非相干误差抑制技术的前置步骤。

Abstract: Stabilizer states are a central resource in quantum information processing,
underpinning a wide range of applications. While they can be efficiently
generated via Clifford circuits, the presence of coherent errors, such as
small-angle miscalibrations in native gate implementations, can significantly
impact their quality. In this work, we introduce Variational Coherent Error
Mitigation (VCEM), a method that employs the stabilizer formalism to suppress
coherent errors through variational optimization of native gates parameters.
VCEM demonstrates robust performance, remaining largely unaffected by
incoherent noise, enabling pre-compensation of coherent errors prior to the
application of standard incoherent error mitigation techniques. We demonstrate
the effectiveness and robustness of VCEM through numerical simulations.

</details>


### [178] [Phenomenological Noise Models and Optimal Thresholds of the 3D Toric Code](https://arxiv.org/abs/2510.20489)
*Ji-Ze Xu,Yin Zhong,Miguel A. Martin-Delgado,Hao Song,Ke Liu*

Main category: quant-ph

TL;DR: 3D توريك كود لديه عتبات تسامح مع الأخطاء المحدودة ضد أخطاء Pauli وأخطاء القياس، مع إظهار المتانة ضد أخطاء القياس.


<details>
  <summary>Details</summary>
Motivation: استكشاف أداء رموز توريك ثلاثية الأبعاد ضد الضوضاء الواقعية، خاصةً مع بوابات غير كليفورد.

Method: اشتقاق نماذج مقياس موتر شبكي مقترن عشوائيًا ووصف نظرية المقياس الموحد Z2 العشوائي، واستخدام تقنية ازدواج معممة لتحديد عتبات التسامح مع الأخطاء.

Result: تم حساب عتبات التسامح مع الأخطاء المثلى لـ 3D توريك كود: pX,M_th ≈ 11% للأخطاء المقلوبة و pZ,M_th ≈ 2% للأخطاء الطورية، مع انخفاض طفيف مقارنة بالقياسات المثالية.

Conclusion: تُظهر رموز توريك ثلاثية الأبعاد متانة ضد أخطاء القياس، مما يمثل تقدمًا كبيرًا نحو تقييم الأداء العملي للرموز الطوبولوجية ثلاثية الأبعاد وله آثار مهمة على علم المعلومات الكمومية والفيزياء عالية الطاقة والفيزياء المكثفة.

Abstract: Three-dimensional (3D) topological codes offer the advantage of supporting
fault-tolerant implementations of non-Clifford gates, yet their performance
against realistic noise remains largely unexplored. In this work, we focus on
the paradigmatic 3D toric code and investigate its fault-tolerance thresholds
in the presence of both Pauli and measurement errors. Two randomly coupled
lattice gauge models that describe the code's correctability are derived,
including a random 2-form $\mathbb{Z}_2$ gauge theory. By exploiting a
generalized duality technique, we show that the 3D toric code exhibits optimal
thresholds of $p^{X,M}_{th} \approx 11\%$ and $p^{Z,M}_{th} \approx 2\%$
against bit-flip and phase-flip errors, respectively. These threshold values
show modest reductions compared to the case of perfect measurements,
establishing the robustness of the 3D toric code against measurement errors.
Our results constitute a substantial advance towards assessing the practical
performance of 3D topological codes. This contribution is timely and in high
demand, as rapid hardware advancements are bringing complex codes into
experimental reach. Moreover, our work highlights the interdisciplinary nature
of fault-tolerant quantum computation and holds significant interest for
quantum information science, high-energy physics, and condensed matter physics.

</details>


### [179] [Feasibility of entanglement-based QKD protocols with SPDC and QD sources](https://arxiv.org/abs/2510.20528)
*Mariia Gumberidze,Vladyslav C. Usenko*

Main category: quant-ph

TL;DR: SPDC和QD源都不适合安全的DI-QKD，QD源的FSS会降低协议性能。


<details>
  <summary>Details</summary>
Motivation: 理论分析了基于纠缠的量子密钥分发（QKD）协议的可行性，考虑了SPDC和QD源，并纳入了多光子发射、FSS、暗计数和探测效率等不完美因素。

Method: 对SPDC源的多光子发射和QD源的FSS进行了理论分析，并考虑了暗计数和有限的探测效率。

Result: SPDC源由于真空和多光子对的存在，不适合标准的DI-QKD；QD源的FSS会降低协议性能。

Conclusion: 对于使用实际光源和探测器的基于纠缠的QKD协议的实际实现，考虑不完美因素至关重要。

Abstract: We theoretically analyze the feasibility of entanglement-based quantum key
distribution (QKD) protocols considering widely used spontaneous parametric
down-conversion (SPDC) and novel quantum dot (QD) sources. We account for
multiphoton emission in SPDC sources and fine-structure splitting (FSS) in QD.
In addition, we incorporate imperfect detection, including dark counts and
limited efficiency. For SPDC sources, we confirm that the presence of vacuum
and multiphoton pairs renders them unsuitable for secure device-independent
(DI) QKD implementations under standard detection strategies. Conversely, in
the case of QD sources, accounting for the effects of FSS, results in reduced
performance of protocols. Our findings are crucial for the practical
implementation of entanglement-based QKD protocols using realistic sources and
detectors.

</details>


### [180] [Higher-order quantum computing with known input states](https://arxiv.org/abs/2510.20530)
*Vanessa Brzić,Satoshi Yoshida,Mio Murao,Marco Túlio Quintino*

Main category: quant-ph

TL;DR:  HOQC 中，操作未知但输入状态已知可提高性能，并可实现确定性、精确的混合状态实现。


<details>
  <summary>Details</summary>
Motivation: 在HOQC中，我们通常考虑未知量子操作的通用变换，并假定它们作用于任意的输入状态。本研究探索一种变体，其中操作未知但输入状态是固定且已知的。我们认为这一假设在某些实际应用中是有根据的，例如在单元化编程中。

Method: 分析了在操作未知但输入状态已知的情况下，HOQC的性能增强。区分了针对纯态、二分态和混合态的协议。

Result: 发现已知输入状态可以显著提高HOQC的性能。能够识别出可以确定性地、精确地实现混合态的类别。

Conclusion: 在HOQC的特定场景下（例如单元化编程），固定和已知的输入状态假设是有益的，并且可以实现比先前假设更优越的性能，包括针对特定混合态的确定性和精确实现。

Abstract: In higher-order quantum computing (HOQC), one typically considers the
universal transformation of unknown quantum operations, treated as blackboxes.
It is also implicitly assumed that the resulting operation must act on
arbitrary, and thus unknown, input states. In this work, we explore a variant
of this framework in which the operation remains unknown, but the input state
is fixed and known. We argue that this assumption is well-motivated in certain
practical contexts, such as unitary programming, and show that classical
knowledge of the input state can significantly enhance performance. Moreover,
this assumption allows us to distinguish between protocols designed for pure,
bipartite, and mixed states, which enables us to identify the class of mixed
states for which deterministic and exact implementation becomes possible.

</details>


### [181] [Nontrivial topological phases in "Zig-Zag" arrays of polarization transmons](https://arxiv.org/abs/2510.20557)
*Ekaterina Konopleva,Gleb Fedorov,Oleg Astafiev*

Main category: quant-ph

TL;DR: 利用超导量子模拟器研究具有长程交叉极化耦合的扩展Zig-Zag模型，发现并验证了边缘态的存在，为研究拓扑量子多体现象提供了新的实验途径。


<details>
  <summary>Details</summary>
Motivation: 研究具有多内禀自由度的元原子在拓扑模型中的应用，特别是扩展的Zig-Zag模型。

Method: 提出一种超导量子模拟器，利用具有简并偶极轨道的极化Transmon实现长程交叉极化耦合。通过数值和解析方法（逆参与比和拓扑不变量）研究模型的相变，并进行电磁建模验证。

Result: 证明了存在带隙局域化的平凡和Tamm边缘态。电磁建模表明所提出的装置能够精确复现扩展的Zig-Zag模型。

Conclusion: 该工作为实验研究先前无法触及的拓扑量子多体现象铺平了道路。

Abstract: In recent years, quantum simulators of topological models have been
extensively studied across a variety of platforms and regimes. A new promising
research direction makes use of meta-atoms with multiple intrinsic degrees of
freedom, which to date have been predominantly studied in the classical regime.
Here, we propose a superconducting quantum simulator to study an extension of
the well-known "Zig-Zag" model with long-range cross-polarization couplings
using polarization transmons hosting degenerate dipole orbitals. We map the
phase transitions of the extended "Zig-Zag" model both numerically and
analytically using inverse participation ratios and topological invariants. We
demonstrate the existence of in-gap localized trivial and Tamm edge states.
With linearized meta-atoms, we show via electromagnetic modeling that the
proposed arrangement closely reproduces the extended "Zig-Zag" model. This work
paves the way towards experimental investigation of the previously inaccessible
topological quantum many-body phenomena.

</details>


### [182] [Measuring weak microwave signals via current-biased Josephson Junctions II: Arriving at single-photon detection sensitivity](https://arxiv.org/abs/2510.20570)
*Y. Q. Chai,M. Y. Wang,S. N. Wang,P. H. Ouyang,L. F. Wei*

Main category: quant-ph

TL;DR: 非平衡约瑟夫森阈值探测器（JTD）比平衡JTD具有更高的探测灵敏度，可用于单微波光子探测。


<details>
  <summary>Details</summary>
Motivation: 基于现有研究，探索非平衡JTD在实现更高灵敏度微波信号探测方面的潜力。

Method: 在热噪声存在下，通过数值模拟分析了不同偏置电流扫描速率下CBJJ的相位动力学。

Result: 证明了快速非绝热驱动下的非平衡JTD对热噪声不敏感，从而提高了探测灵敏度，并估算了其动态范围、探测带宽和光子数分辨能力等性能指标。

Conclusion: 非平衡JTD可用于实现高灵敏度的单微波光子探测，并可作为宽带探测器使用。

Abstract: It is well known that the current-biased Josephson junction (CBJJ) can serve
as a Josephson threshold detector (JTD) for the sensitive detection of weak
microwave signals. Based on the recent work (PRB {\bf 111}, 024501 (2025)) on
the detection sensitive limit of the usual equilibrium JTD, here we numerically
demonstrate that a non-equilibrium JTD can be alternatively utilized to
implement the higher sensitive detection of a weak microwave signal, arriving
at its energy quantum limit. In the presence of thermal noise, we numerically
simulate the phase dynamics for the CBJJ in the JTD with the different sweep
rates of the biased currents, and find that the SCDs of the JTD with and
without the microwave signal input show different behaviors. It is demonstrated
that, depending on how high the sweep rate of the biased current being applied,
the JTD can be operated in either the equilibrium- or the non-equilibrium
state. Specifically, under the rapidly non-adiabatic driving, the SCDs of the
JTD are obviously insensitive to the thermal noises, which means that the
non-equilibrium JTD can possess a higher achievable detection sensitivity,
compared with its equilibrium state counterpart. Consequently, the
non-equilibrium JTD can be utilized to implement the desired single
microwave-photon detection. Also, some of the achievable performance indexes,
such as the dynamic range, detection bandwidth, and the photon-number
resolvability, etc., of the non-equilibrium JTD have been estimated, when it
serves as a wideband microwave single-photon detector.

</details>


### [183] [Phase Transitions and Virtual Exceptional Points in Quantum Emitters Coupled to Dissipative Baths](https://arxiv.org/abs/2510.20571)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 该研究探讨了在耗散光子浴中，单量子比特与边缘耦合的弛豫动力学。


<details>
  <summary>Details</summary>
Motivation: 研究目标是控制量子光学和量子技术中的原子-光子相互作用，利用非厄米光子浴平台实现控制。

Method: 研究了单两能级量子比特耦合到半无限耗散玻色子格边缘的弛豫动力学，并分析了由共振态合并引起的动力学相变。

Result: 发现了由系统参数变化引起的动力学相变，特别是最优耗散环境可以加速自发辐射，并通过识别共振态的合并来解释相变。

Conclusion: 研究结果表明，耗散的性质（如均匀损耗、交错损耗或退相干）会显著影响量子比特的弛豫，并指出耗散工程是量子技术的一个有用工具。

Abstract: Controlling atom-photon interactions in engineered environments is central to
quantum optics and emerging quantum technologies. Non-Hermitian (NH) photonic
baths, where dissipation fundamentally reshapes spectral and dynamical
properties, provide versatile platforms for such control. Here we investigate
the relaxation dynamics of a single two-level quantum emitter coupled to the
edge of a semi-infinite dissipative bosonic lattice with uniform loss. Despite
the simplicity of this bath, we uncover rich dynamical phase transitions, i.e.
qualitative changes in spontaneous emission decay as system parameters are
varied. In particular, we establish the existence of an optimal dissipative
environment for accelerated spontaneous emission. The phase transitions are
traced to spectral restructuring of the resolvent, in some cases governed by
the coalescence of resonance states on the second Riemann sheet. We identify
these coalescences as virtual exceptional points (EPs) of resonance origin,
providing a conceptual bridge with EP physics while highlighting distinctive
features of infinite-dimensional NH systems. More broadly, our results
illustrate how the specific nature of dissipation -- whether uniform losses,
staggered losses, or dephasing -- can profoundly impact emitter relaxation,
pointing to dissipation engineering as a versatile tool for quantum
technologies.

</details>


### [184] [Generating pseudo-random unitaries with a Floquet driven chaotic quantum system](https://arxiv.org/abs/2510.20581)
*Alice C. Quillen,Abobakar Sediq Miakhel*

Main category: quant-ph

TL;DR: 利用扰动的哈珀模型在环面上进行遍历的 Floquet 量子系统，生成伪随机酉算子。


<details>
  <summary>Details</summary>
Motivation: 探索使用遍历的 Floquet 量子系统在环面上生成伪随机酉算子。

Method: 在强扰动和扰动频率超过振动频率的条件下，选择扰动的哈珀模型，以确保系统具有遍历区域。通过计算 Floquet 传播子，生成酉算子样本。通过计算 k 帧势来比较数值生成的酉算子分布与 Haar 随机分布。

Result: 发现 4 个控制参数的均匀分布可以生成近似 3 设计。如果 Floquet 系统参数漂移，则需要更少的控制参数来创建近似 3 设计。

Conclusion: 利用具有特定参数的 Floquet 量子系统可以生成伪随机酉算子，并且可以通过调整控制参数的数量和考虑参数漂移来控制生成的酉算子集的近似 3 设计性质。

Abstract: We explore using an ergodic Floquet quantum system on a torus to generate
pseudo-random unitary operators. We choose a regime of the perturbed Harper
model with strong perturbations and perturbation frequency exceeding the
libration frequency to ensure that the system has an ergodic region that covers
phase space and lacks resonant substructure. We generate a sample of unitary
operators in a finite dimensional space by computing Floquet propagators from a
distribution of its control parameters. To compare the distribution of
unitaries to that of a Haar-random distribution, we compute k-frame potentials
from samples of numerically generated unitaries. We find that uniform
distributions of 4 control parameters can generate an approximate 3-design.
Distributions of fewer control parameters are required to create an approximate
3-design if the Floquet system parameters drift.

</details>


### [185] [Gravitationally mediated entanglement of fermionic qubits: from static to dynamical limits](https://arxiv.org/abs/2510.20587)
*Moslem Zarei,Mehdi Abdi,Nicola Bartolo,Sabino Matarrese*

Main category: quant-ph

TL;DR: 该研究利用量子玻尔兹曼方程和显式微观模型，分析了由引力产生的两个远程量子比特之间的纠缠，并使用引力子传播子作为相互作用的媒介。研究表明，在动力学极限下，通过涉及引力子交换的正向散射过程可以产生纠缠态，并且纠缠量与量子比特的拉莫尔频率相关，而不是它们的质量。然而，随着波包尺寸的增加，这些效应会减弱。


<details>
  <summary>Details</summary>
Motivation: 探索由引力介导的两个远程量子比特之间的纠缠，并为引力量子化提供潜在的实验证据。

Method: 采用量子玻尔兹曼方程，并考虑了两个显式的微观模型。使用引力子传播子作为相互作用的媒介，并将量子比特视为处于空间叠加态的自旋1/2粒子。研究了引力子传播子的静态和动力学极限。

Result: 证明了在动力学极限下，通过涉及引力子交换的正向散射过程可以生成纠缠态。对于基于铁磁子在磁场背景下的微观模型，发现纠缠量取决于量子比特的拉莫尔频率，而非其质量。两种模型都观察到，随着波包尺寸的增加，纠缠效应会减弱。

Conclusion: 该研究阐明了两个自旋1/2粒子之间由引力介导的纠缠，并指出在动力学极限下，通过引力子交换可以实现这种纠缠，其效应受到波包尺寸和拉莫尔频率等因素的影响。

Abstract: We employ the quantum Boltzmann equation to analyze the gravitationally
generated entanglement between two remote qubits by considering two explicit
microscopic models. A graviton propagator is employed as the mediator of the
interactions, while the qubits are considered in a spatial superposition state.
Such a setup, in the case of any entanglement generation, could potentially
offer experimental evidence for the quantization of gravity. By treating the
qubits as spin-1/2 particles in wave packets, we establish that the
entanglement arises from forward scattering processes involving graviton
exchanges. In our study, we consider both static and dynamical limits of the
propagator and show that only in the dynamical limit such entangled states can
be generated. We also show that for the microscopic model based on the fermion
particles in the background of magnetic field, the amount of entanglement
depends on the Larmor frequency of the qubits, rather than their masses. These
effects are observed to diminish in both models as the wave packet size
increases. Our findings sheds more light into the gravity mediated entanglement
between two spin-1/2 particles.

</details>


### [186] [A Gateway to Quantum Computing for Industrial Engineering](https://arxiv.org/abs/2510.20620)
*Emily L. Tucker,Mohammadhossein Mohammadisiahroudi*

Main category: quant-ph

TL;DR: 量子计算为工业工程和运筹学带来了机遇与挑战，本文旨在提供一个路线图，介绍基础知识、算法进展和应用方向，并为研究者提供学习路径，以降低入门门槛，推动跨学科合作和实际应用。


<details>
  <summary>Details</summary>
Motivation: 量子计算为工业工程（IE）和运筹学（OR）带来了新的机遇和挑战，需要为该领域的研究者提供指导。

Method: 介绍量子计算基础、软硬件现状、相关算法（线性代数、优化、机器学习、随机模拟），并探讨应用方向和模型重构，同时提出学习路径。

Result: 总结了量子计算在IE/OR领域的现状、挑战和机遇，并为研究者提供了学习和参与该领域的建议。

Conclusion: 工业工程师有独特优势推动量子计算在实际问题解决中的应用，本文旨在降低入门门槛，促进合作，并为量子技术在工业和学术界的实际应用指明方向。

Abstract: Quantum computing is rapidly emerging as a new computing paradigm with the
potential to improve decision-making, optimization, and simulation across
industries. For industrial engineering (IE) and operations research (OR), this
shift introduces both unprecedented opportunities and substantial challenges.
The learning curve is high, and to help researchers navigate the emerging field
of quantum operations research, we provide a road map of the current field of
quantum operations research. We introduce the foundational principles of
quantum computing, outline the current hardware and software landscape, and
survey major algorithmic advances relevant to IE/OR, including quantum
approaches to linear algebra, optimization, machine learning, and stochastic
simulation. We then highlight applied research directions, including the
importance of problem domains for driving long-term value of quantum computers
and how existing classical OR models can be reformulated for quantum hardware.
Recognizing the steep learning curve, we propose pathways for IE/OR researchers
to develop technical fluency and engage in this interdisciplinary domain. By
bridging theory with application, and emphasizing the interplay between
hardware and research development, we argue that industrial engineers are
uniquely positioned to shape the trajectory of quantum computing for practical
problem-solving. Ultimately, we aim to lower the barrier to entry into quantum
computing, motivate new collaborations, and chart future directions where
quantum technologies may deliver tangible impact for industry and academia.

</details>


### [187] [Quantum Processing Unit (QPU) processing time Prediction with Machine Learning](https://arxiv.org/abs/2510.20630)
*Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito*

Main category: quant-ph

TL;DR: 机器学习可预测量子计算作业的QPU处理时间，以提高效率。


<details>
  <summary>Details</summary>
Motivation: 在量子计算系统中，预测量子处理单元（QPU）的处理时间对于提高运营效率至关重要。

Method: 利用基于梯度提升（LightGBM）的机器学习算法，对约15万个遵循IBM量子方案的量子作业数据集进行处理时间预测，并采用数据预处理方法提高模型准确性。

Result: 机器学习模型能有效预测量子作业的QPU处理时间，显示出其在量子计算领域的应用潜力。

Conclusion: 机器学习在预测量子作业方面展现出有效性，为在高级量子计算操作中集成人工智能驱动的工具奠定了基础，并可能改进量子计算框架内的资源管理和调度。

Abstract: This paper explores the application of machine learning (ML) techniques in
predicting the QPU processing time of quantum jobs. By leveraging ML
algorithms, this study introduces predictive models that are designed to
enhance operational efficiency in quantum computing systems. Using a dataset of
about 150,000 jobs that follow the IBM Quantum schema, we employ ML methods
based on Gradient-Boosting (LightGBM) to predict the QPU processing times,
incorporating data preprocessing methods to improve model accuracy. The results
demonstrate the effectiveness of ML in forecasting quantum jobs. This
improvement can have implications on improving resource management and
scheduling within quantum computing frameworks. This research not only
highlights the potential of ML in refining quantum job predictions but also
sets a foundation for integrating AI-driven tools in advanced quantum computing
operations.

</details>


### [188] [Computing time-dependent reduced models for classical and quantum dynamics](https://arxiv.org/abs/2510.20675)
*Tommaso Grigoletto*

Main category: quant-ph

TL;DR: 提出了一种新的递归算法，用于构造一个多项式时间依赖的有效生成器，以近似大自治系统在固定子空间上的动力学，适用于短时间尺度，并且在低阶时保证了完全正的、保持迹的映射。


<details>
  <summary>Details</summary>
Motivation: 为解决量子物理学中推导时间无关主方程的挑战，并提供一种替代耦合强度展开的推导方法。

Method: 基于指数映射的泰勒展开和计算多项式生成器的时间排序指数的新结果，推导了一种新的递归算法来构造一个多项式时间依赖的有效生成器。

Result: 该近似在短时间内是准确的，不需要弱耦合假设，在低阶时比指数映射截断效果更好，并保证了完全正的和保持迹的映射。

Conclusion: 该方法通过在去相干自旋-玻色子模型、中心自旋模型和伊辛自旋链等原型模型上的验证，证明了其有效性。

Abstract: This paper introduces a novel method for approximating the dynamics of a
large autonomous system projected onto a fixed subspace. The core contribution
is a novel recursive algorithm to construct an effective time-dependent
generator that is polynomial in the time variable, ensuring accuracy for short
time scales. The derivation is based on the Taylor expansion of the exponential
map and a new result for computing the time-ordered exponential of polynomial
generators. This work is motivated by the challenge of deriving
time-convolutionless master equations in quantum physics and the proposed
method offers an alternative to typical derivations based on expansions in the
coupling strength. The resulting approximation is accurate for small times,
does not require a weak-coupling assumption, performs better than a truncation
of the exponential map at low orders, and crucially, guarantees a completely
positive and trace-preserving map at the lowest orders. The proposed method is
validated against several prototypical models: a dephasing spin-boson model, a
central spin model, and an Ising spin chain.

</details>


### [189] [Classical Noise Inversion: A Practical and Optimal framework for Robust Quantum Applications](https://arxiv.org/abs/2510.20686)
*Dayue Qin,Ying Li,You Zhou*

Main category: quant-ph

TL;DR: 量子纠错的CNI框架通过经典后处理反转噪声，解决了采样成本和噪声依赖性问题，适用于各种量子应用。


<details>
  <summary>Details</summary>
Motivation: 量子纠错是获取可靠量子计算结果的关键技术，但目前面临采样成本高和依赖不切实际的噪声模型的挑战。

Method: 提出经典噪声反演（CNI）框架，在经典后处理中反转累积噪声，无需昂贵的量子电路采样，并能处理与门相关的噪声。引入噪声压缩技术，将具有等效测量结果影响的噪声组件分组，实现最优的误差抑制开销。将CNI与影子估计相结合，形成一个鲁棒的协议，用于在通用噪声下学习量子特性。

Result: CNI框架消除了昂贵的量子电路采样需求，并且在考虑与门相关的噪声时仍然有效。噪声压缩实现了最优的误差抑制开销。CNI与影子估计的结合在统计方差方面有显著降低，并提供无偏估计，解决了先前方法在实际情况下的不足。

Conclusion: CNI通过将关键的量子开销转化为可管理的经典成本，为可扩展且实用的量子应用开辟了前景。

Abstract: Quantum error mitigation is a critical technology for extracting reliable
computations from noisy quantum processors, proving itself essential not only
in the near term but also as a valuable supplement to fully fault-tolerant
systems in the future. However, its practical implementation is hampered by two
major challenges: the expansive cost of sampling from quantum circuits and the
reliance on unrealistic assumptions, such as gate-independent noise. Here, we
introduce Classical Noise Inversion (CNI), a framework that fundamentally
bypasses these crucial limitations and is well-suited for various quantum
applications. CNI effectively inverts the accumulated noise entirely during
classical post-processing, thereby eliminating the need for costly quantum
circuit sampling and remaining effective under the realistic condition of
gate-dependent noise. Apart from CNI, we introduce noise compression, which
groups noise components with equivalent effects on measurement outcomes,
achieving the optimal overhead for error mitigation. We integrate CNI with the
framework of shadow estimation to create a robust protocol for learning quantum
properties under general noise. Our analysis and numerical simulations
demonstrate that this approach substantially reduces statistical variance while
providing unbiased estimates in practical situations where previous methods
fail. By transforming a key quantum overhead into a manageable classical cost,
CNI opens a promising pathway towards scalable and practical quantum
applications.

</details>


### [190] [Note on Energy Shifts of Oscillators in Blackbody Radiation](https://arxiv.org/abs/2510.20711)
*Peter Milonni*

Main category: quant-ph

TL;DR: 该论文计算了黑体辐射中振荡器的能量移动，并发现其与温度T的关系在高温下为-T^2（能量移动）和+T^2（自由能移动），这与Ford等人最初获得的结果一致。


<details>
  <summary>Details</summary>
Motivation: 计算黑体辐射中振荡器的能量移动，并研究其与温度的关系。

Method: 基于相互作用场-振荡器系统的总能量随折射率的变化来计算能量移动。

Result: 在高温T下，能量移动和自由能移动分别随-T^2和+T^2变化。

Conclusion: 计算结果与Ford等人最初获得的结果一致。

Abstract: The energy shift of an oscillator in blackbody radiation is calculated based
simply on the total energy of the interacting field-oscillator system as a
function of the refractive index. For high temperatures T the energy and
free-energy shifts are found to vary as -T^2 and +T^2, respectively, in
agreement with the result originally obtained by Ford, Lewis, and O'Connell
[Phys. Rev. Lett. 55, 2273 (1985)].

</details>


### [191] [How typical is contextuality?](https://arxiv.org/abs/2510.20722)
*Vinicius P. Rossi,Beata Zjawin,Roberto D. Baldijão,David Schmid,John H. Selby,Ana Belén Sainz*

Main category: quant-ph

TL;DR: 随机选择的量子制备和测量产生的非经典统计是普遍存在的，但高度非经典性并不常见。


<details>
  <summary>Details</summary>
Motivation: 确定观察到的统计数据是否无法用任何合理的经典模型来解释是量子基础中的一个核心问题。广义非情境性为定义和识别非经典性提供了一种原则性和普遍适用的方法。

Method: 使用数值线性规划来测试是否存在广义非情境模型。

Result: 随机选择的量子制备和测量有超过99%的概率产生非经典统计。然而，高度非经典性的情况并不像非经典性本身那样普遍。文中还提供了一个开源工具箱，用于根据可调参数输出情境性的典型性。

Conclusion: 虽然非经典性在量子实验中普遍存在，但高度的非经典性并不常见，这可能影响量子优势的应用。文中提供的工具箱可以帮助设计需要特定情境性典型性的实验。

Abstract: Identifying when observed statistics cannot be explained by any reasonable
classical model is a central problem in quantum foundations. A principled and
universally applicable approach to defining and identifying nonclassicality is
given by the notion of generalized noncontextuality. Here, we study the
typicality of contextuality -- namely, the likelihood that randomly chosen
quantum preparations and measurements produce nonclassical statistics. Using
numerical linear programs to test for the existence of a
generalized-noncontextual model, we find that contextuality is fairly common:
even in experiments with only a modest number of random preparations and
measurements, contextuality arises with probability over 99%. We also show that
while typicality of contextuality decreases as the purity (sharpness) of the
preparations (measurements) decreases, this dependence is not especially
pronounced, so contextuality is fairly typical even in settings with realistic
noise. Finally, we show that although nonzero contextuality is quite typical,
quantitatively high degrees of contextuality are not as typical, and so large
quantum advantages (like for parity-oblivious multiplexing, which we take as a
case study) are not as typical. We provide an open-source toolbox that outputs
the typicality of contextuality as a function of tunable parameters (such as
lower and upper bounds on purity and other constraints on states and
measurements). This toolbox can inform the design of experiments that achieve
the desired typicality of contextuality for specified experimental constraints.

</details>


### [192] [Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems](https://arxiv.org/abs/2510.20728)
*Xi He,Sirui Lu,Bei Zeng*

Main category: quant-ph

TL;DR: 提出了一种结合人工智能（GPT-5）和人类参与的多智能体工作流，用于设计具有给定对角门的量子码，并提供该工作流的详细实现和初步结果。


<details>
  <summary>Details</summary>
Motivation: 开发一种自动化且可扩展的方法来设计量子码，特别是具有指定对角门（如可约对角门）的量子码，以克服传统设计方法的局限性。

Method: 采用多智能体协作框架，其中包含一个由 GPT-5 驱动的推理代理和一个工具使用代理。该工作流基于 SSLP 框架，通过线性规划（LP）来处理约束。具体而言，它将基础字符串按模数进行划分，并通过小型 LP 强制执行 Z-边际 Knill-Laflamme (KL) 等式。在一个集成的 LaTeX-Python 环境中，三个角色（综合代理、搜索代理和审计代理）协同工作，进行问题制定、候选筛选、数值精确化、KL 等式验证和逻辑操作检查。

Result: 在距离 $d=2$ 且模数非退化的情况下，对于维度 $K 	rong{2,3,4}$ 和不超过 $n=6$ 量子比特的系统，通过系统的搜索，发现了新的量子码，并获得了可证明的、可达到的循环逻辑群的表格。例如，对于 $K=3$，在 $n=6$ 时获得了 16 阶的群。综合代理还从这些实例中抽象出可证明满足 KL 等式的闭式族。此外，通过一个实现了对角 $diag(1,1,1,i)$ 的新的 $((6,4,2))$ 码，证明了 SSLP 框架可以处理模数退化的情况。

Conclusion: 该工作流将对角门的可行性分析转化为一个可扩展的分析流程，结合了系统枚举和精确分析重建。它能够生成可复现的量子码，支持向更大维度和更高距离的扩展，并为数据驱动的量子码分类奠定了基础。

Abstract: We present a multi-agent, human-in-the-loop workflow that co-designs quantum
codes with prescribed transversal diagonal gates. It builds on the Subset-Sum
Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis
strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)
equalities via small LPs. The workflow is powered by GPT-5 and implemented
within TeXRA (https://texra.ai)-a multi-agent research assistant platform that
supports an iterative tool-use loop agent and a derivation-then-edit workflow
reasoning agent. We work in a LaTeX-Python environment where agents reason,
edit documents, execute code, and synchronize their work to Git/Overleaf.
Within this workspace, three roles collaborate: a Synthesis Agent formulates
the problem; a Search Agent sweeps/screens candidates and exactifies numerics
into rationals; and an Audit Agent independently checks all KL equalities and
the induced logical action. As a first step we focus on distance $d=2$ with
nondegenerate residues. For code dimension $K\in\{2,3,4\}$ and $n\le6$ qubits,
systematic sweeps yield certificate-backed tables cataloging attainable cyclic
logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$
at $n=6$. From verified instances, Synthesis Agent abstracts recurring
structures into closed-form families and proves they satisfy the KL equalities
for all parameters. It further demonstrates that SSLP accommodates residue
degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal
controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts
diagonal-transversal feasibility as an analytical pipeline executed at scale,
combining systematic enumeration with exact analytical reconstruction. It
yields reproducible code constructions, supports targeted extensions to larger
$K$ and higher distances, and leads toward data-driven classification.

</details>


### [193] [Optimal constant-cost implementations of Clifford operations using global interactions](https://arxiv.org/abs/2510.20730)
*Jonathan Nemirovsky,Lee Peleg,Amit Ben Kish,Yotam Shapira*

Main category: quant-ph

TL;DR: 我们提出了一种使用任意单比特操作和可编程全连接多比特纠缠门来实现任何长度的克利福德操作序列的量子电路方法，仅需常数次（最多四次）纠缠门操作，优于理论最优门计数。


<details>
  <summary>Details</summary>
Motivation: 研究如何高效实现量子计算中的克利福德操作序列，特别是利用全连接多比特纠缠门。

Method: 使用最多四次全连接多比特纠缠门和任意单比特操作来实现任意长度的克利福德操作序列，并分析了所需的驱动功率。

Result: 证明了任何克利福德操作序列都可以用常数次（最多四次）纠缠门实现，且所需的驱动功率低于标准方法，并提出了一种计算上高效的编译算法。

Conclusion: 该研究提出了一种实际且计算高效的算法，能够以理论最优的门计数（最多四次纠缠门）实现任意长度的克利福德操作序列，且驱动功率较低，适用于包括离子阱在内的多种量子计算平台。

Abstract: We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than four applications of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae, which is the theoretically optimal gate count
cost. We do this by implementing any sequence of CNOT gates of any length with
four applications of such gates, without ancillae, and show that the extension
to general Clifford operations incurs no additional cost. We investigate the
required qubit drive power that is associated with our implementation and show
that it is lower than that of a standard approach. Our work introduces a
practical and computationally efficient algorithm to realize these
compilations.

</details>


### [194] [Quantum Sensing of Gravitational Frame-Dragging with a Superfluid $^4$He Gyrometer](https://arxiv.org/abs/2510.20772)
*Kai-Isaak Ellers,Marios Christodoulou,K. C. Schwab,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a laboratory-scale experiment to locally measure the general
relativistic frame-dragging effect on Earth using the macroscopic quantum
properties of a novel superfluid $^4$He single Josephson junction gyrometer. We
derive the frame-dragging and related geodetic and Thomas effects in the
superfluid gyrometer and present a procedure for their experimental
measurement. We compute the expected thermal noise floor and find that very
high sensitivity can be expected at millikelvin temperatures, where near-future
Josephson junctions using nanoporous 2D materials are expected to operate.
Assuming utilization of the lowest mechanical loss materials, we find a noise
spectral density of $5\times 10^{-17}$ rads/s/$\sqrt{\mathrm{Hz}}$ at 10 mK,
which is sufficient to resolve the frame-dragging rate to 0.2% within one
second of measurement, giving a rotational sensitivity of 1 revolution in 4
Byrs. This extreme sensitivity to rotation corresponds to a measurement of
proper time differences as small as $10^{-35}$ s.

</details>


### [195] [The complexity of perfect quantum state classification](https://arxiv.org/abs/2510.20789)
*Nathaniel Johnston,Benjamin Lovitz,Vincent Russo,Jamie Sikora*

Main category: quant-ph

TL;DR: 该论文研究了量子态分类问题，引入了k-可学习性的概念，并探讨了其与半正定规划的关系。


<details>
  <summary>Details</summary>
Motivation: 研究量子态分类问题，并引入k-可学习性的概念来量化分类的准确性。

Method: 提出k-可学习性的概念，并利用半正定规划来解决k-可学习性的判定问题。针对k或维度为常数的情况，提出了多项式时间算法。证明了当k和维度都可变时，问题属于NP，并通过k-Clique问题规约证明了NP-Hardness。

Result: 判定一个量子态家族是否为k-可学习性可以通过半正定规划解决。当k或维度为常数时，存在多项式时间算法。当k和维度都可变时，该问题是NP-Hard的，但存在NP的简明证书。

Conclusion: 该研究界定了量子态分类问题在零错误情况下的可解性与难解性边界。

Abstract: The problem of quantum state classification asks how accurately one can
identify an unknown quantum state that is promised to be drawn from a known set
of pure states. In this work, we introduce the notion of $k$-learnability,
which captures the ability to identify the correct state using at most $k$
guesses, with zero error. We show that deciding whether a given family of
states is $k$-learnable can be solved via semidefinite programming. When there
are $n$ states, we present polynomial-time (in $n$) algorithms for determining
$k$-learnability for two cases: when $k$ is a fixed constant or the dimension
of the states is a fixed constant. When both $k$ and the dimension of the
states are part of the input, we prove that there exist succinct certificates
placing the problem in NP, and we establish NP-hardness by a reduction from the
classical $k$-clique problem. Together, our findings delineate the boundary
between efficiently solvable and intractable instances of quantum state
classification in the perfect (zero-error) regime.

</details>


### [196] [Analog Quantum Feature Selection with Neutral-Atom Quantum Processors](https://arxiv.org/abs/2510.20798)
*Jose J. Orquin-Marques,Carlos Flores-Garrigos,Alejandro Gomez Cadavid,Anton Simen,Enrique Solano,Narendra N. Hegade,Jose D. Martin-Guerrero,Yolanda Vives-Gilabert*

Main category: quant-ph

TL;DR: 我们提出了一种基于中性原子阵列模拟的量子特征选择（QFS）方法，该方法适用于各种学术和工业应用。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种新的量子特征选择方法，以利用量子计算的潜力来解决实际的机器学习问题。

Method: 该方法使用模拟量子计算，其中特征相关性被编码为局部失谐幅度，特征冗余通过距离依赖的范德华相互作用嵌入。通过绝热演化到低能配置，并使用测量比特串来提取特征子集。

Result: 通过在三个基准数据集（Adult Income、Bank Marketing 和 Telco Churn）上进行模拟，与经典方法相比，该量子方法在性能上具有竞争力或更优。特别是在 2-5 个特征的紧凑子集方面，量子特征选择将平均 AUC 分数提高了 1.5-2.3%，同时将特征数量减少了 75-84%。

Conclusion: 研究结果表明，可编程的里德堡原子阵列为智能特征选择提供了一个可行的平台，在机器学习流水线中具有实际意义，并有可能将计算量子优势转化为工业量子效用。

Abstract: We present a quantum-native approach to quantum feature selection (QFS) based
on analog quantum simulation with neutral atom arrays, adaptable to a variety
of academic and industrial applications. In our method, feature
relevance-measured via mutual information with the target-is encoded as local
detuning amplitudes, while feature redundancy is embedded through
distance-dependent van der Waals interactions, constrained by the Rydberg
blockade radius. The system is evolved adiabatically toward low-energy
configurations, and the resulting measurement bitstrings are used to extract
physically consistent subsets of features. The protocol is evaluated through
simulations on three benchmark binary classification datasets: Adult Income,
Bank Marketing, and Telco Churn. Compared to classical methods such as mutual
information ranking and Boruta, combined with XGBoost and Random Forest
classifiers, our quantum-computing approach achieves competitive or superior
performance. In particular, for compact subsets of 2-5 features, analog QFS
improves mean AUC scores by 1.5-2.3% while reducing the number of features by
75-84%, offering interpretable, low-redundancy solutions. These results
demonstrate that programmable Rydberg arrays offer a viable platform for
intelligent feature selection with practical relevance in machine learning
pipelines, capable of transforming computational quantum advantage into
industrial quantum usefulness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [197] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 本研究提出一种配置相关运动学校准框架，用于提高关节机器人整个工作空间的定位精度，特别关注非几何因素引起的模型差异。


<details>
  <summary>Details</summary>
Motivation: 准确的机器人运动学对于在关节机器人中实现精确的工具放置至关重要，但非几何因素可能导致依赖于配置的模型差异。

Method: 该框架在多个配置下确定局部指数积（POE）模型，并将其内插为全局模型。利用受关节重力载荷表达式启发的傅立叶基函数内插，该方法以肩部和肘部关节角度为参数。

Result: 与神经网络和自动编码器方法相比，该方法实现了可比的准确性，但训练效率却高得多。在两个 6-DoF 工业机器人上的验证显示，该方法将最大定位误差减少了 50% 以上，满足了冷喷涂制造所需的亚毫米级精度要求。

Conclusion: 该方法在减少配置相关的运动学误差方面非常有效，并且比现有方法更具训练效率。双机器人协作任务证明了该框架的实际适用性和可重复性。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [198] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 使用改进的接触隐式模型预测控制（CI-MPC）算法C3+，机器人能够在各种物体几何形状和多物体场景中实现精确的平面推动操作，显著提高了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器人领域在非抓取式物体操纵方面仍面临挑战，尤其是在物体物理属性未知和接触交互复杂的情况下。现有的接触隐式模型预测控制（CI-MPC）虽然有前景，但应用范围有限。

Method: 引入了名为“共识互补控制增强版”（C3+）的改进CI-MPC算法，并将其整合到一个完整的机器人操作流程中，包括物体扫描、网格重建和硬件执行。C3+相比其前身C3，能够实现更快的求解速度。

Result: C3+算法在精确平面推动任务中表现出色，成功率达到98%，并且能够处理包括多物体在内的复杂场景。在单物体、双物体、三物体和四物体任务中，达到目标姿态的平均时间分别为0.5分钟、1.6分钟、3.2分钟和5.3分钟。

Conclusion: C3+算法成功扩展了CI-MPC在机器人非抓取式操纵任务中的应用范围，实现了高效、鲁棒的多物体平面推动操作，为解决更复杂的机器人操作问题奠定了基础。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [199] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种强化学习框架，用于学习无人机在任意起点和终点之间的最小时间飞行策略，该策略可实现敏捷飞行和稳定悬停，并能泛化到实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决传统自主无人机竞速方法在预定义赛道上的局限性，实现可泛化到任意状态之间飞行的最小时间策略。

Method: 利用强化学习，以点质量模型（PMM）轨迹作为代理奖励来逼近真实最优飞行目标，并采用课程学习来提高训练效率和泛化能力。

Result: 通过仿真实验与非线性模型预测控制（NMPC）进行对比，并进行消融研究，最终在真实户外环境中验证了所学策略的鲁棒性、泛化能力以及在小型ARM单板计算机上的运行能力。

Conclusion: 所提出的强化学习框架能够成功学习并泛化最小时间飞行策略，以应对实际应用中的挑战。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [200] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种去中心化强化学习（Dec-RL）方案，用于模块化可重构机器人的统一控制，实现了对不同机器人形态的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人在特定任务空间操作中具有优势，但形态组合的复杂性阻碍了统一控制。需要一种方法来解决这个问题。

Method: 采用去中心化强化学习（Dec-RL）方案，让每个模块学习自己的策略：轮式模块使用Soft Actor-Critic（SAC）进行运动，7-DoF肢体模块使用Proximal Policy Optimization（PPO）进行转向和操作。

Result: 在模拟中，转向策略在期望角度和诱导角度之间实现了3.63度的平均绝对误差；操作策略在目标偏移标准上达到了84.6%的成功率；轮式策略相比基线将平均电机扭矩降低了95.4%，同时保持了99.6%的成功率。在月球模拟场地测试中，验证了自主运动、转向和重新配置的初步对齐的零样本集成。系统在策略执行的同步、并行和顺序模式之间平稳转换，没有空闲状态或控制冲突。

Conclusion: 该去中心化强化学习方法为模块化月球机器人提供了一种可扩展、可重用且鲁棒的方法。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [201] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: Stewart平台并联机器人（PKM）因其精细的控制特性在医疗、工程、航天、电子芯片制造、汽车制造等领域具有广泛的应用潜力。精确的运动控制需要高精度的PKM，而逆运动学方法比正向运动学更易于实现PKM的标定。本研究回顾了基于外部仪器、约束和自标定的关键标定方法，并分析了逆运动学标定的相关技术。研究发现，现有工作主要关注消除单一或多重误差源对平台位置和方向精度的影响，并主要在无负载条件下进行标定，仅部分考虑了环境因素。本研究旨在总结该领域的最新进展，并为未来研究提供方向。


<details>
  <summary>Details</summary>
Motivation: Stewart平台并联机器人（PKM）在微纳尺度运动控制方面具有重要应用，但其精度要求极高，因此需要进行精确标定。特别是对于6-DOF PKM，逆运动学方法在标定过程中比正向运动学更具优势。

Method: 本研究通过回顾和分析现有的关键标定方法，包括基于外部仪器、约束以及自动或自标定等方法，重点关注与逆运动学相关的PKM标定技术。

Result: 研究表明，研究人员主要集中在提高平台的位置和方向精度，考虑单一或多个误差源（主要是结构误差，有时也考虑环境因素）的影响。然而，这些标定通常在无负载条件下进行。

Conclusion: 现有PKM标定技术主要集中在消除单一或多重误差源对平台位置和方向精度的影响，尤其是在无负载条件下。未来的研究可以扩展到负载条件下的标定以及考虑更多环境因素。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [202] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文介绍了一种用于聚合物熔融沉积成型（FDM）过程研究的新型3D打印平台，该平台能够精确控制和监测打印参数，并通过相机和光度摄影技术记录打印过程，以研究打印缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有消费级和商用级3D打印机在研究方面存在局限性，如缺乏灵活性和对打印参数控制不足。

Method: 设计并制造了一个能够精确控制和监测FDM打印参数（如温度、湿度、位置反馈）的平台，并配备了相机和旋转加热床，用于在打印过程中进行光度摄影。

Result: 该平台实现了对打印参数的精确控制和监测，并通过光度摄影技术记录了打印过程，能够将工艺参数与几何缺陷联系起来。

Conclusion: 所设计的旋转加热床机构能够以最少数量的相机实现打印部件的光度摄影重建，为研究聚合物FDM过程提供了一个有力的平台。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [203] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 该研究提出了一种基于路径的Transformer模型，用于机器人轨迹规划，通过3网格表示法和约束掩码解码来解决现有模型忽略运动结构导致无效或低效执行的问题。模型在大量轨迹数据上进行了训练，实现了高精度的预测，并且生成路径的合法性得到保证。在实际机器人操作和模拟环境中，该模型取得了优异的成功率，并能处理复杂场景下的干扰。研究表明，路径结构表示能够提升Transformer在机器人轨迹生成方面的准确性、可靠性和可解释性，为通用机器人操作和仿真到现实的迁移奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有序列模型在机器人轨迹规划中忽略运动结构，导致执行无效或低效。

Method: 提出一种基于路径的Transformer模型，采用3网格（何处/何物/何时）表示法和约束掩码解码，强制执行邻近移动和工作空间约束，并结合任务图和动作顺序进行推理。模型在53,755条轨迹上训练，并应用于xArm Lite 6机器人。

Result: 模型在训练集上实现了89.44%的步进准确率，93.32%的精确率，89.44%的召回率和90.40%的F1分数，99.99%的路径合法性。在机器人测试中，到达和抓取成功率分别高达97.5%和92.5%，在60个语言指定任务中端到端成功率达到86.7%，并且能够通过局部重新定位处理滑动和遮挡问题。

Conclusion: 基于路径结构的表示方法使Transformer能够生成准确、可靠且可解释的机器人轨迹，结合了基于图的规划和基于序列的学习，为通用操作和仿真到现实迁移提供了实际基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [204] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 该研究提出了一种用于四足磁性爬壁机器人的强化学习框架，通过明确考虑磁性脚部吸附的不确定性，实现了在复杂环境中的鲁棒爬壁能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决四足磁性爬壁机器人面临的吸附不确定性问题，本研究提出了一种新的强化学习框架，旨在提高机器人在吸附可能失败的复杂表面上的运动鲁棒性。

Method: 研究者们在模拟环境中构建了一个考虑了部分接触、气隙敏感性和概率性吸附失败的四足磁性爬壁机器人物理模型。为稳定学习和实现可靠的迁移，设计了一个包含三个阶段的课程学习策略：首先学习无吸附的地面爬行步态，然后逐步调整重力向量并激活吸附模型，最后注入随机吸附失败以训练滑移恢复能力。在此基础上，训练了一个强化学习策略。

Result: 学习到的策略在模拟中表现出高成功率、强的吸附保持能力和快速的脱离恢复能力，即使在吸附能力下降的情况下也表现出色。与假设吸附完美的模型预测控制（MPC）基线相比，该控制器在吸附间歇性丢失时仍能保持运动能力。在真实硬件实验中，无系绳机器人能够在钢制表面上进行鲁棒的垂直爬行，即使在存在瞬时错位和不完全吸附的情况下也能保持稳定。

Conclusion: 结合课程学习和逼真的吸附模型，可以为磁性爬壁机器人在复杂环境中提供一个鲁棒的从模拟到现实（sim-to-real）的解决方案。本研究证明了该方法在提高机器人运动鲁棒性和适应性方面的有效性。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [205] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 本研究提出了一种在视觉受限环境下机器人进行盲操作的框架，该框架结合了接触反馈和结构先验知识，实现了在未知环境中鲁棒的操作。


<details>
  <summary>Details</summary>
Motivation: 机器人常在视觉不佳的环境（如杂乱、遮挡或光线不足）中执行操作任务，需要依赖接触反馈来感知空间和避开障碍物。许多这类环境具有结构先验（如水槽柜里的管道），可用于预测未知结构并避免碰撞。

Method: 提出一个包含三个组件的框架：(i) 利用关节力矩传感和粒子滤波器进行接触检测与定位；(ii) 使用接触观测历史构建局部占用地图，并通过学习的预测器推断未知区域；(iii) 规划模块考虑接触定位和占用预测的不确定性，计算避碰且高效的路径。

Result: 在模拟和真实世界中，该框架在UR10e机械臂上成功完成了水槽柜阀门操作和杂乱架子取物任务，任务完成时间最多可缩短2倍，各组件的有效性得到验证。

Conclusion: 所提出的盲操作框架能有效结合接触反馈和结构先验，在视觉受限的未知环境中实现鲁棒、高效的操作。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [206] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 本研究通过学习辅助的磁场相互作用，在实验中验证了大型卫星群控制的原理，并提出了一种名为NODA-MMH的算法。


<details>
  <summary>Details</summary>
Motivation: 大型卫星群（超过三颗）的长期编队维持面临非完整约束、欠驱动、可扩展性和计算成本高等挑战，以往的研究主要集中在地面两体控制。本研究旨在解决这些挑战，实现卫星群的长期编队维持。

Method: 研究人员利用卫星上安装的磁力矩器产生的磁场相互作用，结合学习技术，来控制多颗卫星。他们设计了双轴线圈和基于气浮平台的地面实验装置，以模拟轨道动力学。在此基础上，提出了NODA-MMH（Neural power-Optimal Dipole Allocation for certified learned Model-based Magnetically swarm control Harness）算法，用于基于模型的、功率最优的磁力矩器控制。

Result: 实验验证了学习辅助的时间积分电流控制能够增强平均系统动力学的可控性，并具有理论保证的误差界限。同时，实现了分散式电流管理。NODA-MMH算法在模型学习方面表现出有效性。

Conclusion: 本研究成功通过实验验证了学习辅助的磁场相互作用在大型卫星群控制中的可行性，并提出了一种创新的算法NODA-MMH，为解决长期编队维持问题提供了新的解决方案。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [207] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: Kinaema是一个新的机器人定位模型，它使用隐含的潜在记忆来整合视觉观察，并能在没有明确历史记录的情况下高效地预测查询图像的位置。


<details>
  <summary>Details</summary>
Motivation: 在连续的机器人操作中，机器人需要能够“找准方向”，即在之前见过的空间中正确地定位自己，并利用实际任务开始前的信息来优化效率。

Method: 提出了一种名为Kinaema的新模型和智能体，它能够整合移动过程中的视觉观察流，并在需要时处理查询图像，预测查询场景相对于当前位置的相对位置。该模型不显式存储观察历史，而是通过Transformer以循环方式更新一个隐含的潜在记忆，将传感器读数的历史压缩成一个紧凑的表示。

Result: Kinaema模型在名为“Mem-Nav”的新下游任务上进行了评估，证明了其大容量循环模型能够维护有用的场景表示，并能导航到任务开始前观察到的目标，同时具有计算效率。

Conclusion: Kinaema模型在不显式存储历史记录的情况下，能够有效地处理连续的机器人操作中的定位任务，并在“Mem-Nav”任务上表现出色，证明了其在导航和场景表示方面的能力。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [208] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: MemER是一种新框架，为机器人策略增加了长期记忆能力，通过高层策略选择和跟踪关键帧，并结合文本指令指导低层策略执行，在长期机器人操作任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 机器人策略通常缺乏人类所具备的记忆能力，而直接使用长历史观察数据计算成本高且不稳定，随机采样又会引入无关或冗余信息。本研究旨在为机器人策略赋予记忆能力。

Method: 提出了一种分层策略框架，高层策略负责选择和跟踪经验中的相关关键帧，并结合关键帧和最近的帧生成文本指令，供低层策略执行。该框架兼容现有的视觉-语言-动作（VLA）模型，能够高效处理长时依赖问题。实验中，使用Qwen2.5-VL-7B-Instruct作为高层策略，$
u_{0.5}$作为低层策略，并辅以少量语言标注的演示数据进行微调。

Result: MemER在三个需要数分钟记忆的真实世界长期机器人操作任务中，其表现优于现有方法。

Conclusion: MemER成功实现了为机器人策略引入长期记忆能力，有效解决了现有方法在处理长时依赖问题上的局限性，并在实际机器人操作任务中取得了优于先前技术的性能。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [209] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: Dino-Diffusion Parking (DDP) is a domain-agnostic autonomous parking pipeline that uses visual foundation models and diffusion-based planning to achieve robust performance under domain shifts without additional data.


<details>
  <summary>Details</summary>
Motivation: Recent end-to-end (E2E) approaches for autonomous parking struggle with robustness under domain shifts (e.g., weather and lighting changes).

Method: The proposed Dino-Diffusion Parking (DDP) pipeline integrates visual foundation models with diffusion-based planning. It is trained in CARLA under regular conditions and transferred to adversarial settings in a zero-shot fashion. Testing is also performed in a 3D Gaussian splatting (3DGS) environment reconstructed from a real-world parking lot.

Result: DDP achieves a parking success rate above 90% across all tested out-of-distribution (OOD) scenarios. Ablation studies show that both the network architecture and algorithmic design significantly improve cross-domain performance compared to existing baselines. Promising sim-to-real transfer is also demonstrated.

Conclusion: Dino-Diffusion Parking (DDP) offers a robust and generalizable solution for autonomous parking, overcoming the limitations of existing methods in handling domain shifts.

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [210] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个结合了神经描述场（NDF）和触觉传感的多模态框架，通过细致的物理交互实现准确且可泛化的抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的抓取方法（如NDF）在相机标定不精确、点云不完整或物体多变的情况下可能产生不准确的姿态。而基于触觉的方法通常仅限于预定义的简单接触几何。因此，需要一种能够结合两者优点的方法来提高抓取精度和泛化能力。

Method: NeuralTouch框架首先利用NDF隐式表示目标接触几何，然后训练一个深度强化学习（RL）策略，该策略以神经描述符为条件，并利用触觉反馈来优化抓取姿态，无需显式指定接触类型。

Result: 通过在模拟环境中的消融研究和在现实世界中的零样本迁移实验（如 the peg-out-in-hole 和 bottle lid opening 任务）验证，NeuralTouch 相较于基线方法显著提高了抓取精度和鲁棒性，且无需额外微调。

Conclusion: NeuralTouch 为精确、富含接触的机器人操作提供了一个通用的框架，成功地集成了视觉和触觉信息，以实现更准确、更可靠的抓取。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [211] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy是一种新的方法，它在结构化点云上进行扩散策略的条件化，以提高机器人操作系统的感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人操作感知方法在处理点云和RGB图像时存在不足：点云方法难以捕捉精细几何细节，而RGB方法缺乏几何感知能力。

Method: PointMapPolicy在不进行降采样的结构化点云栅格上进行条件化扩散策略。该方法利用xLSTM作为骨干网络，高效融合点云图和RGB数据，增强多模态感知能力，并可以直接应用成熟的计算机视觉技术处理3D数据。

Result: 在RoboCasa和CALVIN基准测试以及真实机器人评估中，PointMapPolicy在各种操作任务中均达到了最先进的性能。

Conclusion: PointMapPolicy通过在结构化点云上进行条件化扩散策略，解决了现有方法的局限性，显著提高了机器人在复杂操作任务中的感知精度和泛化能力。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [212] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 该研究提出了一种基于混合现实的水下机器人手臂遥操作系统（MR-UBi），该系统通过双边控制增加了力反馈指示器，以提高操作的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高水下机器人手臂遥操作的稳定性和准确性，尤其是在抓取操作中，并改善用户体验。

Method: 提出了一种基于混合现实（MR）和双边控制的水下机器人手臂遥操作系统（MR-UBi）。该系统在MR头戴式显示器（HMD）中叠加了颜色和长度编码的力矩条（RTI），以提供视觉和触觉反馈的无缝集成。

Result: 与基线系统相比，MR-UBi在抓取力矩控制精度上显著提高，增加了处于最佳力矩范围的时间，并减少了在不同硬度物体抓取和放置任务中的低力矩和高力矩范围。用户满意度（SUS）和工作负荷（NASA-TLX）评估结果也表明MR-UBi具有更高的可用性和更低的工作负荷。

Conclusion: MR-UBi通过整合视觉和触觉反馈，能够实现更稳定、准确和用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [213] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 该方法提出了一种在工作空间坐标中规划轨迹的方法，同时考虑零件上的加工路径，并使用B样条表示机器人路径，以实现平滑的机器人轨迹。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，这种方法很有用。

Method: 使用B样条表示机器人路径，同时考虑加工路径和给定的TCP速度来计算机器人轨迹。

Result: 该方法在真实系统上使用工业机器人移动任意定义的零件进行了验证。

Conclusion: 该方法能够生成平滑的机器人轨迹，同时考虑零件上的加工路径和给定的TCP速度。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [214] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种新的多机器人协同定位方法，通过融合异步的视觉-惯性里程计（VIO）、激光雷达-惯性里程计（LIO）和机器人间的3D检测数据，以应对GNSS受限环境中的定位挑战。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，机器人需要精确的长期定位能力。单独使用多种传感器会增加尺寸、重量和功耗；而将传感器分布在多个机器人上则会引入数据融合的挑战。

Method: 提出一种基于因子图的自适应多模态多机器人协同定位方法，融合异步的VIO、LIO和机器人间的3D检测数据，并采用基于插值的因子来处理不同步的测量，同时根据Wasserstein距离对里程计数据进行加权。

Result: 在包含UUV和UAV的异构机器人团队的真实世界数据上进行了广泛评估，证明该方法在各种传感器降级情况下能显著提高定位精度。

Conclusion: 该方法能够有效融合来自独立移动平台的异步、多模态数据，并通过自适应调整提高在传感器退化情况下的机器人定位鲁棒性。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [215] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 机器人需要在未知动力学下执行抓取和放置等操纵任务，需要实时探索和参数调整以实现精确控制。本文提出了一种简化对偶控制问题的方法，通过预定义反馈策略结构来适应参数不确定性，并提出了两种参考轨迹生成方法，一种直接嵌入参数不确定性以最小化预期任务成本，另一种最小化与任务性能相关的“最优性损失”。这两种方法都会考虑 Fisher 信息，以同时优化任务执行和系统辨识。实验证明，该方法能提高抓取和放置任务的准确性和效率，并加快系统辨识速度，同时确保控制的稳定性和高效性。


<details>
  <summary>Details</summary>
Motivation: 在机器人操纵任务中，尤其是在抓取和放置等场景下，执行环境的动力学往往是未知的（例如，负载不确定性）。为了实现精确的基于模型的控制，必须在任务执行过程中进行主动探索和在线参数自适应。因此，研究如何在未知动力学下进行机器人操纵任务具有重要的实际意义。

Method: 本文将机器人操纵任务在未知动力学下的问题框架化为一个对偶控制问题，并寻求一个能够考虑参数不确定性的闭环最优控制问题。为了简化该对偶控制问题，研究者预先定义了反馈策略的结构，其中包含一个明确的自适应机制。在此基础上，提出了两种参考轨迹生成方法：1. 直接将参数不确定性嵌入到鲁棒最优控制方法中，以最小化预期的任务成本。2. 最小化所谓的“最优性损失”，该损失衡量了与参数相关的信息对任务性能的敏感度。研究发现，这两种方法在推导过程中都会自然地考虑 Fisher 信息，从而同时实现最优的任务执行。

Result: 通过对抓取和放置操纵任务的演示，结果表明，在设计参考轨迹时同时考虑对偶控制，可以实现更快、更准确的任务执行和系统辨识。此外，该方法还能确保控制的稳定性和高效性。

Conclusion: 本文提出的方法通过在参考轨迹生成中整合对偶控制和参数不确定性处理，能够有效地提高机器人操纵任务的性能，包括任务执行的速度和准确性，以及系统辨识的效率，同时保证了控制的稳定性和高效性。这为在未知动力学环境下进行机器人操纵提供了新的解决方案。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [216] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本研究提出了一种通过激励主运动来降低串联弹性驱动并联机器人（SEA-PKM）在执行抓取-放置任务时的能量消耗的方法，并通过优化操作轨迹和SEA刚度来验证。


<details>
  <summary>Details</summary>
Motivation: 在工业机器人应用中，特别是在长时间运行的重复性抓取-放置任务中，最小化能源消耗是一个重要的研究方向。本研究旨在探索如何通过利用SEA的弹性特性来降低SEA驱动的PKM的能耗。

Method: 提出了一种通过激励特征运动（eigenmotions）来最小化SEA驱动的PKM在执行抓取-放置任务时的能量消耗的方法。该方法首先对SEA驱动的PKM的循环抓取-放置操作进行分析，并建立其动力学模型。然后，将能量最小化问题表述为一个最优控制问题，同时优化操作轨迹和SEA的刚度。最后，在两个机器人应用场景中验证了该方法，并考虑了冗余驱动的情况。

Result: 所提出的方法在两个机器人应用场景中得到了验证，结果证实了该方法在降低SEA驱动的PKM的能量消耗方面的有效性。

Conclusion: 本研究提出的通过激励特征运动并同时优化操作轨迹和SEA刚度的方法，能够有效降低SEA驱动的PKM在执行抓取-放置任务时的能量消耗。该方法为SEA驱动的PKM的设计和能效优化提供了新的思路。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [217] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR:  本文提出了一种基于最大化路径速度以解决时间最优路径跟踪问题的计算方法，克服了传统方法中存在的奇异性问题，并能高效生成平滑轨迹。


<details>
  <summary>Details</summary>
Motivation: 标准方法在处理零路径速度时的奇异性问题，导致轨迹生成和计算效率面临挑战。

Method: 提出了一种基于最大化路径速度的新方法，将优化问题转化为涉及优化变量的线性离散问题。

Result: 该方法能够高效地规划平滑轨迹，避免了传统方法中的奇异性。

Conclusion: 所提出的基于最大化路径速度的方法，在计算上是高效的，并且能够有效地解决时间最优路径跟踪问题，生成平滑的轨迹。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [218] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 本项目提出了一个名为RubbleSim的开源模拟器，用于在灾难废墟的空洞空间中进行机器人探索的模拟。该模拟器基于Unity引擎，使用物理引擎生成随机的废墟堆，并能准确记录地面真实情况。研究人员利用该模拟器，在模拟的空洞环境中测试了先进的运动恢复结构算法在视觉条件不佳时的性能表现。


<details>
  <summary>Details</summary>
Motivation: 由于在实际灾难废墟中收集数据存在法律和数据公开方面的限制，本研究旨在创建一个可公开访问的模拟环境，以克服数据获取的挑战，从而研究机器人如何在灾难废墟的空洞空间中进行探索。

Method: 该研究使用Unity引擎开发了一个名为RubbleSim的开源模拟器。模拟器利用物理引擎生成随机的、可重构的废墟堆，这些废墟堆的设计参考了真实的训练废墟场地。模拟器能够精确记录内部的“地面真实”情况，并可用于在各种操作系统上运行。研究人员使用该模拟器，结合先进的运动恢复结构算法，来评估机器人在模拟的废墟空洞中，在具有挑战性的视觉条件下的感知性能。

Result: 在RubbleSim模拟器中进行的实验表明，在模拟的废墟空洞内部，尤其是在视觉条件不佳的情况下，先进的运动恢复结构算法的感知性能会下降。

Conclusion: RubbleSim是一个有价值的工具，可以克服现实世界中数据收集的限制，为研究机器人灾难响应能力提供了一个可访问且可重构的平台。实验结果强调了在复杂和视觉受限的废墟环境中，机器人感知技术所面临的挑战。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [219] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 该研究提出了一个持续对象导航基准和名为C-Nav的框架，以解决现有方法在动态开放世界环境中导航能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练时依赖静态轨迹和固定对象类别，无法满足在动态开放世界中持续适应不断变化场景的现实需求。

Method: 提出C-Nav框架，包含双路径抗遗忘机制（特征蒸馏和特征回放）和自适应采样策略，以应对新对象导航和防止灾难性遗忘。

Result: 实验证明C-Nav在多个模型架构上持续优于现有方法，即使与完整轨迹保留基线相比也表现更佳，同时显著降低了内存需求。

Conclusion: C-Nav框架有效解决了持续对象导航的挑战，在动态环境中实现了更好的导航性能和更低的内存开销。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [220] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 该研究提出了一种结合MPPI和Dreamer模块的优化框架，用于四足机器人实时步态适应，在保持精确追踪和适应性步态的同时，显著降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 传统的无模型强化学习（RL）在四足机器人运动控制中虽然能实现适应性和敏捷性，但策略往往收敛到单一的步态，导致性能不佳。而传统的模型预测控制（MPC）虽然能获得任务特定的最优策略，但缺乏适应不断变化的环境的能力。本研究旨在解决这些局限性。

Method: 提出了一种结合MPPI（模型预测路径积分）算法和Dreamer模块的优化框架，用于在连续步态空间中实现实时的步态适应。MPPI在每个时间步共同优化动作和步态变量，利用Dreamer模块学习到的奖励函数，该函数促进速度追踪、能量效率、稳定性和平稳的步态转换，同时惩罚突兀的步态变化。此外，还引入了学习到的价值函数作为终端奖励，将问题扩展为无限视界规划。

Result: 在Unitree Go1仿真环境中进行了评估，结果显示，在不同的目标速度下，能耗平均降低了高达36.48%，同时保持了精确的速度追踪和适应性、任务相关的步态。

Conclusion: 本研究提出的优化框架成功实现了四足机器人的实时步态适应，通过结合MPPI和Dreamer模块，在多种速度下显著提高了能效，并保持了良好的运动性能。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [221] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个创新的机器人操作数据生成框架，通过解耦轨迹多样性和精确操作，实现了大规模、多样化且高质量的真实世界数据收集，并显著减少了人力投入。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据收集方法在规模、多样性和质量之间难以取得平衡。模拟虽然可扩展但存在域迁移问题，而遥操作虽然质量高但多样性有限且成本高昂。

Method: FieldGen将操作分解为预操作和精细操作两个阶段。通过人类演示捕获关键接触和姿态信息，然后利用吸引力场自动生成多样化的轨迹，并最终收敛到成功的配置。此外，FieldGen-Reward还为生成的数据添加了奖励注释。

Result: 与基于遥操作的基线相比，使用FieldGen训练的策略在实验中取得了更高的成功率和更稳定的性能。

Conclusion: FieldGen通过其解耦设计，能够有效结合可扩展的轨迹多样性和精确的监督，为长期真实世界数据收集提供了更少人力需求且性能更优的解决方案。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [222] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 模拟到现实的转移是机器人领域的一个重大挑战，本研究提供了对该问题的全面概述，重点介绍了原因、解决方案和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现实差距阻碍了从模拟到真实世界机器人的成功转移，而模拟在机器人系统的训练和测试中至关重要。

Method: 本研究全面概述了模拟到现实的转移，重点介绍了现实差距的原因、解决方案和评估指标。

Result: 虽然有许多技术，如领域随机化、状态和动作抽象以及模拟真实协同训练，已被证明可以缩小现实差距，但仍存在挑战，需要更深入的理解。

Conclusion: 弥合模拟和现实之间的差距仍然是机器人领域最紧迫的挑战之一，需要更深入地研究其根本原因和解决方案。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [223] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作模拟器，支持零样本sim2real策略训练和可复现的机器人策略评估。


<details>
  <summary>Details</summary>
Motivation: 开发可复现的机器人策略评估和sim2real策略训练，无需真实机器人。

Method: 提出GSDF（高斯场景描述文件）格式，结合3D高斯泼溅和URDF机器人模型，构建包含机器人和物体的高斯场景，并与物理引擎结合。

Result: 实现了零样本sim2real像素到动作的策略学习、自动化高质量DAgger数据收集、机器人操作策略的可复现基准测试、虚拟遥操作模拟数据收集以及零样本sim2real视觉强化学习。

Conclusion: GSWorld通过结合3D高斯泼溅和物理引擎，为机器人操作提供了照片级逼真的模拟环境，解决了sim2real和策略评估中的关键问题。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [224] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一种分层的视觉-语言-动作模型，它将语义规划与具身归纳分离开来，通过在图像空间中进行规划和评估，实现了跨环境和跨机器人类型的泛化导航能力，并显著提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人导航需要学习能够泛化到不同环境并适应特定机器人身体约束和能力的策略。

Method: 提出VAMOS，一个分层的视觉-语言-动作模型，将通用规划器（从多样化开放世界数据中学习）与特化具身模型（在模拟中学习机器人物理约束和能力）分离开来。通过精心设计的接口，允许高层规划器在图像空间中提出候选路径，然后由具身模型进行评估和重新排序。

Result: VAMOS在室内和复杂室外导航中均取得了比最先进的模型和端到端学习方法更高的成功率。实验证明，该分层设计能够实现跨腿式和轮式机器人的导航，并且能够通过自然语言进行控制。特化模型是实现具身归纳的关键，使单个通用规划器能够应用于物理上不同的机器人。该模型还将单机器人导航成功率提高了3倍。

Conclusion: VAMOS通过将语义规划与具身归纳分离开来，解决了机器人导航中的关键挑战，实现了跨环境和跨机器人类型的泛化导航，并显著提高了导航性能和可靠性。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [225] [On Hardness and Approximation of Broadcasting in Sparse Graphs](https://arxiv.org/abs/2510.20026)
*Jeffrey Bringolf,Hovhannes A. Harutyunyan,Shahin Kamali,Seyed-Mohammad Seyed-Javadi*

Main category: cs.DS

TL;DR: 在稀疏图（k-cycle图和k-path图）中，电话广播问题被证明是NP-hard的，并且提出了针对这些图类的PTAS。此外，研究表明具有界限带宽的图上的问题是可处理的。


<details>
  <summary>Details</summary>
Motivation: 研究稀疏图（特别是k-cycle图和k-path图）中的电话广播问题，以解决其计算复杂性问题，并改进现有近似算法的性能。

Method: 证明k-cycle图和k-path图的NP-hard性，并为这些图类提出PTAS，以及证明有界带宽图的可处理性。

Result: k-cycle图和k-path图的NP-hard性得到证实，同时提出了比现有算法更好的PTAS（分别从近似因子2和4改进）。此外，还证明了在有界带宽图上问题是可行的，这扩展了对项链图等特殊稀疏图的已知结果。

Conclusion: 该研究解决了k-cycle图和k-path图电话广播问题的计算复杂性，并显著改进了相关图类的近似算法，同时将可处理性扩展到更广泛的有界带宽图类。

Abstract: We study the Telephone Broadcasting problem in sparse graphs. Given a
designated source in an undirected graph, the task is to disseminate a message
to all vertices in the minimum number of rounds, where in each round every
informed vertex may inform at most one uninformed neighbor. For general graphs
with $n$ vertices, the problem is NP-hard. Recent work shows that the problem
remains NP-hard even on restricted graph classes such as cactus graphs of
pathwidth $2$ [Aminian et al., ICALP 2025] and graphs at distance-1 to a path
forest [Egami et al., MFCS 2025].
  In this work, we investigate the problem in several sparse graph families. We
first prove NP-hardness for $k$-cycle graphs, namely graphs formed by $k$
cycles sharing a single vertex, as well as $k$-path graphs, namely graphs
formed by $k$ paths with shared endpoints. Despite multiple efforts to
understand the problem in these simple graph families, the computational
complexity of the problem had remained unsettled, and our hardness results
answer open questions by Bhabak and Harutyunyan [CALDAM 2015] and Harutyunyan
and Hovhannisyan [COCAO 2023] concerning the problem's complexity in $k$-cycle
and $k$-path graphs, respectively.
  On the positive side, we present Polynomial-Time Approximation Schemes
(PTASs) for $k$-cycle and $k$-path graphs, improving over the best existing
approximation factors of $2$ for $k$-cycle graphs and an approximation factor
of $4$ for $k$-path graphs. Moreover, we identify a structural frontier for
tractability by showing that the problem is solvable in polynomial time on
graphs of bounded bandwidth. This result generalizes existing tractability
results for special sparse families such as necklace graphs.

</details>


### [226] [Parallel Joinable B-Trees in the Fork-Join I/O Model](https://arxiv.org/abs/2510.20053)
*Michael Goodrich,Yan Gu,Ryuto Kitagawa,Yihan Sun*

Main category: cs.DS

TL;DR: 该论文研究了基于连接的框架的搜索树并行算法，重点是IO效率，并提出了一个新的计算模型Fork-Join I/O Model。


<details>
  <summary>Details</summary>
Motivation: 在并行计算环境中，现有的基于连接的搜索树在集合操作方面存在IO效率低下的问题，并且缺乏对IO成本的严格界定。

Method: 提出了一种新的计算模型Fork-Join I/O Model，用于衡量并行计算中的IO成本（包括IO工作和IO跨度）。在此模型下，设计了一种基于B树的并行算法，用于计算两个B树的并集、交集和差集。

Result: 提出的并行算法在Fork-Join I/O Model下，实现了IO工作为O(m log_B(n/m))，IO跨度为O(log_B m * log_2 log_B n + log_B n)，其中n和m（m<=n）为树的大小，B为块大小。

Conclusion: 该研究为IO效率低下的并行搜索树算法提供了一个新的计算模型和一种新的解决方案，并在理论上界定了IO成本。

Abstract: Balanced search trees are widely used in computer science to efficiently
maintain dynamic ordered data. To support efficient set operations (e.g.,
union, intersection, difference) using trees, the join-based framework is
widely studied. This framework has received particular attention in the
parallel setting, and has been shown to be effective in enabling simple and
theoretically efficient set operations on trees. Despite the widespread
adoption of parallel join-based trees, a major drawback of previous work on
such data structures is the inefficiency of their input/output (I/O) access
patterns. Some recent work (e.g., C-trees and PaC-trees) focused on more
I/O-friendly implementations of these algorithms. Surprisingly, however, there
have been no results on bounding the I/O-costs for these algorithms. It remains
open whether these algorithms can provide tight, provable guarantees in
I/O-costs on trees.
  This paper studies efficient parallel algorithms for set operations based on
search tree algorithms using a join-based framework, with a special focus on
achieving I/O efficiency in these algorithms. To better capture the
I/O-efficiency in these algorithms in parallel, we introduce a new
computational model, Fork-Join I/O Model, to measure the I/O costs in fork-join
parallelism. This model measures the total block transfers (I/O work) and their
critical path (I/O span). Under this model, we propose our new solution based
on B-trees. Our parallel algorithm computes the union, intersection, and
difference of two B-trees with $O(m \log_B(n/m))$ I/O work and $O(\log_B m
\cdot \log_2 \log_B n + \log_B n)$ I/O span, where $n$ and $m \leq n$ are the
sizes of the two trees, and $B$ is the block size.

</details>


### [227] [Optimal Rounding for Two-Stage Bipartite Matching](https://arxiv.org/abs/2510.20153)
*Tristan Pollner,Amin Saberi,Anders Wikum*

Main category: cs.DS

TL;DR: 本文研究了一个两阶段二分匹配问题，旨在最大化两阶段匹配的总权重。


<details>
  <summary>Details</summary>
Motivation: 在两阶段二分匹配问题中，图的边分两批揭示。第一阶段，必须从已揭示的边 $E rown B_1 	imes I$ 中选择一个匹配。第二阶段，从已知分布中抽取边 $E^	heta rown B_2 	imes I$，并需要在 $B_2$ 和 $I$ 中未匹配的顶点之间选择第二个匹配。目标是最大化组合匹配的总权重。

Method: 本文设计了最优在线算法的多项式时间近似算法。通过对分两阶段揭示的分数匹配进行舍入，以与其分数权重成比例的概率来匹配离线节点（或边），最多只损失一个常数因子。利用负相关（NA）诱导的依赖舍入，对随机图中最大权重匹配的期望大小推导出新的下界。

Result: 对于顶点加权图，实现了 $7/8$ 的近似保证；对于边加权图，在任意分布下实现了 $2rown{rown}2-2 rown rown 0.828$ 的近似保证。这匹配了已知最优积分松弛的整数隙上界，并改进了之前在第二批由独立到达节点组成的无权图上的近似比 $0.767$。

Conclusion: 该算法通过分两阶段揭示的分数匹配进行舍入，实现了对两阶段二分匹配问题的有效近似。利用负相关性推导出的新下界以及对样本访问的扩展，为解决此类优化问题提供了新的理论和实践指导。

Abstract: We study two-stage bipartite matching, in which the edges of a bipartite
graph on vertices $(B_1 \cup B_2, I)$ are revealed in two batches. In stage
one, a matching must be selected from among revealed edges $E \subseteq B_1
\times I$. In stage two, edges $E^\theta \subseteq B_2 \times I$ are sampled
from a known distribution, and a second matching must be selected between $B_2$
and unmatched vertices in $I$. The objective is to maximize the total weight of
the combined matching. We design polynomial-time approximations to the optimum
online algorithm, achieving guarantees of $7/8$ for vertex-weighted graphs and
$2\sqrt{2}-2 \approx 0.828$ for edge-weighted graphs under arbitrary
distributions. Both approximation ratios match known upper bounds on the
integrality gap of the natural fractional relaxation, improving upon the
best-known approximation of 0.767 by Feng, Niazadeh, and Saberi for unweighted
graphs whose second batch consists of independently arriving nodes.
  Our results are obtained via an algorithm that rounds a fractional matching
revealed in two stages, aiming to match offline nodes (respectively, edges)
with probability proportional to their fractional weights, up to a
constant-factor loss. We leverage negative association (NA) among offline node
availabilities -- a property induced by dependent rounding -- to derive new
lower bounds on the expected size of the maximum weight matching in random
graphs where one side is realized via NA binary random variables. Moreover, we
extend these results to settings where we have only sample access to the
distribution. In particular, $\text{poly}(n,\epsilon^{-1})$ samples suffice to
obtain an additive loss of $\epsilon$ in the approximation ratio for the
vertex-weighted problem; a similar bound holds for the edge-weighted problem
with an additional (unavoidable) dependence on the scale of edge weights.

</details>


### [228] [Smoothed Analysis of Online Metric Matching with a Single Sample: Beyond Metric Distortion](https://arxiv.org/abs/2510.20288)
*Yingxi Li,Ellen Vitercik,Mingwei Yang*

Main category: cs.DS

TL;DR: 该论文提出了一个在线度量匹配问题的O(1)竞争算法，适用于非二维欧几里得空间，且服务器的分布未知。


<details>
  <summary>Details</summary>
Motivation: 在在线度量匹配问题中，服务器和请求都位于度量空间中。服务器预先可用，而请求则依次到达。每个到达的请求必须立即且不可撤销地匹配到一个可用服务器，匹配成本等于它们之间的距离。目标是最小化总匹配成本。

Method: 研究了在欧几里得度量空间[0, 1]^d中，当服务器具有对抗性，而请求独立地从满足温和平滑条件的分布中抽取时，在线度量匹配问题。

Result: 对于d ≠ 2的情况，该算法达到了O(1)的竞争比，并且不需要任何分布知识，只需要每个请求分布的一个样本。

Conclusion: 该算法是第一个在i.i.d.设置之外的非平凡度量中实现o(log n)竞争比的算法。该方法绕过了概率度量嵌入引入的Ω(log n)障碍：它没有分别分析嵌入失真和算法，而是直接界定了算法在简单确定性嵌入的目标度量上的成本。然后，该分析与通过主要化参数推导出的欧几里得度量在线最优值的下界相结合，以获得保证。

Abstract: In the online metric matching problem, $n$ servers and $n$ requests lie in a
metric space. Servers are available upfront, and requests arrive sequentially.
An arriving request must be matched immediately and irrevocably to an available
server, incurring a cost equal to their distance. The goal is to minimize the
total matching cost.
  We study this problem in the Euclidean metric $[0, 1]^d$, when servers are
adversarial and requests are independently drawn from distinct distributions
that satisfy a mild smoothness condition. Our main result is an
$O(1)$-competitive algorithm for $d \neq 2$ that requires no distributional
knowledge, relying only on a single sample from each request distribution. To
our knowledge, this is the first algorithm to achieve an $o(\log n)$
competitive ratio for non-trivial metrics beyond the i.i.d. setting. Our
approach bypasses the $\Omega(\log n)$ barrier introduced by probabilistic
metric embeddings: instead of analyzing the embedding distortion and the
algorithm separately, we directly bound the cost of the algorithm on the target
metric of a simple deterministic embedding. We then combine this analysis with
lower bounds on the offline optimum for Euclidean metrics, derived via
majorization arguments, to obtain our guarantees.

</details>


### [229] [Separations between Oblivious and Adaptive Adversaries for Natural Dynamic Graph Problems](https://arxiv.org/abs/2510.20341)
*Aaron Bernstein,Sayan Bhattacharya,Nick Fischer,Peter Kiss,Thatchaphol Saranurak*

Main category: cs.DS

TL;DR: 该研究首次在动态图问题中，根据细粒度复杂度假设，区分了针对不可知和自适应对手的动态算法更新时间。


<details>
  <summary>Details</summary>
Motivation: 在动态图算法领域，区分针对不同类型对手（不可知和自适应）的更新时间复杂度是重要的研究问题，但此前缺乏基于自然动态图问题和普遍接受的复杂度假设的区分。

Method: 通过基于组合BMM假设，证明了增量式最大独立集问题在面对自适应对手时，其组合算法需要$n^{1-o(1)}$的摊销更新时间。基于3SUM或APSP假设，证明了在初始最大度为$	riangle 
gtr	ext{sqrt}(n)$时，面对自适应对手的度减式最大团问题算法需要$	riangle/n^{o(1)}$的摊销更新时间。同时，研究还利用OMv假设，为三角检测问题提供了增量式和度减式算法之间的第一个分离。

Result: 在增量式最大独立集问题上，证明了自适应对手的下界为$n^{1-o(1)}$，与现有算法匹配，而针对不可知对手的算法可达到$	ext{polylog}(n)$的摊销更新时间，实现了指数级分离。在度减式最大团问题上，证明了自适应对手的下界为$	riangle/n^{o(1)}$，与现有算法匹配，而针对不可知对手的算法可达到$	ext{polylog}(n)$的摊销更新时间，同样实现了指数级分离。三角检测问题方面，提出了一个具有$	ilde{O}(n^{	ext{omega}})$总更新时间的度减式算法，并证明了增量式算法需要$n^{3-o(1)}$的总更新时间。

Conclusion: 该研究首次在自然动态图问题上，根据细粒度复杂度假设，实现了针对不可知对手和自适应对手的更新时间分离，证明了这种分离是指数级的。此外，还首次在三角检测问题上实现了增量式和度减式算法之间的分离。

Abstract: We establish the first update-time separation between dynamic algorithms
against oblivious adversaries and those against adaptive adversaries in natural
dynamic graph problems, based on popular fine-grained complexity hypotheses.
Specifically, under the combinatorial BMM hypothesis, we show that every
combinatorial algorithm against an adaptive adversary for the incremental
maximal independent set problem requires $n^{1-o(1)}$ amortized update time.
Furthermore, assuming either the 3SUM or APSP hypotheses, every algorithm for
the decremental maximal clique problem needs $\Delta/n^{o(1)}$ amortized update
time when the initial maximum degree is $\Delta \le \sqrt{n}$. These lower
bounds are matched by existing algorithms against adaptive adversaries. In
contrast, both problems admit algorithms against oblivious adversaries that
achieve $\operatorname{polylog}(n)$ amortized update time [Behnezhad,
Derakhshan, Hajiaghayi, Stein, Sudan; FOCS '19] [Chechik, Zhang; FOCS '19].
Therefore, our separations are exponential. Previously known separations for
dynamic algorithms were either engineered for contrived problems and relied on
strong cryptographic assumptions [Beimel, Kaplan, Mansour, Nissim, Saranurak,
Stemmer; STOC '22], or worked for problems whose inputs are not explicitly
given but are accessed through oracle calls [Bateni, Esfandiari, Fichtenberger,
Henzinger, Jayaram, Mirrokni, Wiese; SODA '23].
  As a byproduct, we also provide a separation between incremental and
decremental algorithms for the triangle detection problem: we show a
decremental algorithm with $\tilde{O}(n^{\omega})$ total update time, while
every incremental algorithm requires $n^{3-o(1)}$ total update time, assuming
the OMv hypothesis. To our knowledge this is the first separation of this kind.

</details>


### [230] [$\ell_2/\ell_2$ Sparse Recovery via Weighted Hypergraph Peeling](https://arxiv.org/abs/2510.20361)
*Nick Fischer,Vasileios Nakos*

Main category: cs.DS

TL;DR: 利用加权超图剪枝技术，我们提出了一种新的非自适应线性草图，能够在 O((k/ε) log n) 时间内以 (1+ε) 因子近似地恢复长度为 n 的向量的最佳 k-稀疏逼近，其行数为 O((k/ε) log n)，列稀疏度为 O(log n)。


<details>
  <summary>Details</summary>
Motivation: 旨在提高稀疏逼近恢复算法的效率，特别是针对非自适应线性草图。

Method: 提出了一种名为加权超图剪枝的新技术，该技术将现有的超图剪枝过程扩展到一个具有（可能相关）权重和节点的设置中，并将其应用于非自适应线性草图的构建和分析。

Result: 实现了 O((k/ε) log n) 的时间复杂度和 O((k/ε) log n) 的行数，以及 O(log n) 的列稀疏度，能够在 (1+ε) 因子近似下恢复最佳 k-稀疏逼近。

Conclusion: 所提出的算法不仅在理论上比现有最快的草图算法（Nakos, Song; STOC '19）快了 log n 倍，而且由于其简单性，具有实际应用潜力。

Abstract: We demonstrate that the best $k$-sparse approximation of a length-$n$ vector
can be recovered within a $(1+\epsilon)$-factor approximation in
$O((k/\epsilon) \log n)$ time using a non-adaptive linear sketch with
$O((k/\epsilon) \log n)$ rows and $O(\log n)$ column sparsity. This improves
the running time of the fastest-known sketch [Nakos, Song; STOC '19] by a
factor of $\log n$, and is optimal for a wide range of parameters.
  Our algorithm is simple and likely to be practical, with the analysis built
on a new technique we call weighted hypergraph peeling. Our method naturally
extends known hypergraph peeling processes (as in the analysis of Invertible
Bloom Filters) to a setting where edges and nodes have (possibly correlated)
weights.

</details>


### [231] [From Incremental Transitive Cover to Strongly Polynomial Maximum Flow](https://arxiv.org/abs/2510.20368)
*Daniel Dadush,James B. Orlin,Aaron Sidford,László A. Végh*

Main category: cs.DS

TL;DR: 提供了解决结构化网络最大流问题的更快的强多项式时间算法，并将其应用于最大二分b-匹配和具有给定树分解的图上的问题。


<details>
  <summary>Details</summary>
Motivation: 为了在结构化网络中更有效地解决最大流问题，特别是最大二分b-匹配和具有给定树分解的图上的问题。

Method: 通过加强和高效实现Orlin（STOC 2013）算法，提出一个通用框架，将具有任意容量的最大流问题规约到（1）一系列具有多项式有界容量的最大流问题，以及（2）动态维护传递闭包的有界大小的超集（增量传递闭包）。该方法利用了最近的弱多项式、近似线性时间的最大流算法（Chen et al., FOCS 2022 and Brand et al., FOCS 2023），并开发了增量传递闭包数据结构。

Result: 提出了一个$n^{\omega + o(1)}$时间的强多项式时间算法来计算最大二分b-匹配，其中$\\omega$是矩阵乘法常数。此外，还提出了一个$m^{1 + o(1)} W$时间的算法来解决具有给定树分解宽度$W$的图上的最大流问题。

Conclusion: 通过改进和实现现有算法，并结合新的数据结构和算法，成功地为特定的网络结构提供了更快的最大流解决方案，并将其有效应用于相关问题。

Abstract: We provide faster strongly polynomial time algorithms solving maximum flow in
structured $n$-node $m$-arc networks. Our results imply an $n^{\omega +
o(1)}$-time strongly polynomial time algorithms for computing a maximum
bipartite $b$-matching where $\omega$ is the matrix multiplication constant.
Additionally, they imply an $m^{1 + o(1)} W$-time algorithm for solving the
problem on graphs with a given tree decomposition of width $W$.
  We obtain these results by strengthening and efficiently implementing an
approach in Orlin's (STOC 2013) state-of-the-art $O(mn)$ time maximum flow
algorithm. We develop a general framework that reduces solving maximum flow
with arbitrary capacities to (1) solving a sequence of maximum flow problems
with polynomial bounded capacities and (2) dynamically maintaining a
size-bounded supersets of the transitive closure under arc additions; we call
this problem \emph{incremental transitive cover}. Our applications follow by
leveraging recent weakly polynomial, almost linear time algorithms for maximum
flow due to Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva (FOCS 2022) and Brand,
Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva, Sidford (FOCS 2023), and by
developing incremental transitive cover data structures.

</details>


### [232] [Compact representations of pattern-avoiding permutations](https://arxiv.org/abs/2510.20382)
*László Kozma,Michal Opler*

Main category: cs.DS

TL;DR: 我们设计了一种数据结构，用于存储避免特定模式的排列，查询时间为 O(1)，空间复杂度为 O(n log s_π)，并支持更复杂的几何查询。


<details>
  <summary>Details</summary>
Motivation: 在组合学和理论计算机科学中，模式避免排列是一个重要的研究对象。本研究旨在设计一种高效的数据结构来存储和查询这类排列。

Method: 利用一种新的数据结构，该结构在存储避免任意固定模式 π 的大小为 n 的排列时，具有渐近最优的空间复杂度 O(n log s_π)，其中 s_π 是 π 的 Stanley-Wilf 极限。该结构支持 O(1) 时间的 τ(i) 和 τ⁻¹(i) 查询。此外，该结构可扩展以支持更复杂的几何查询，如矩形范围计数，时间复杂度为 O(log log n)。

Result: 设计的数据结构在存储避免特定模式的排列时，空间复杂度达到 O(n log s_π)，查询时间为 O(1)。对于更复杂的几何查询，如矩形范围计数，时间复杂度为 O(log log n)。对于有界树宽排列类，空间开销进一步降低。所有数据结构均可在 O(n) 时间内构建。

Conclusion: 本研究成功设计出一种高效的数据结构，能够以渐近最优的空间存储模式避免排列，并提供快速的查询能力。该结构还支持更复杂的几何查询，并对有界树宽排列类进行了优化，显著改进了现有结果。

Abstract: Pattern-avoiding permutations are a central object of study in both
combinatorics and theoretical computer science. In this paper we design a data
structure that can store any size-$n$ permutation $\tau$ that avoids an
arbitrary (and unknown) fixed pattern $\pi$ in the asymptotically optimal $O(n
\lg{s_\pi})$ bits, where $s_\pi$ is the Stanley-Wilf limit of $\pi$. Our data
structure supports $\tau(i)$ and $\tau^{-1}(i)$ queries in $O(1)$ time,
sidestepping the lower bound of Golynski (SODA 2009) that holds for general
permutations. Comparable results were previously known only in more restricted
cases, e.g., when $\tau$ is separable, which means avoiding the patterns 2413
and 3142.
  We also extend our data structure to support more complex geometric queries
on pattern-avoiding permutations (or planar point sets) such as rectangle range
counting in $O(\lg\lg{n})$ time. This result circumvents the lower bound of
$\Omega{(\lg{n}/\lg\lg{n})}$ by P\u{a}tra\c{s}cu (STOC 2007) that holds in the
general case. For bounded treewidth permutation classes (which include the
above-mentioned separable class), we further reduce the space overhead to a
lower order additive term, making our data structure succinct. This extends and
improves results of Chakraborty et al. (ISAAC 2024) that were obtained for
separable permutations via different techniques. All our data structures can be
constructed in linear time.

</details>


### [233] [Parallel $(1+ε)$-Approximate Multi-Commodity Mincost Flow in Almost Optimal Depth and Work](https://arxiv.org/abs/2510.20456)
*Bernhard Haeupler,Yonggang Jiang,Yaowei Long,Thatchaphol Saranurak,Shengzhe Wang*

Main category: cs.DS

TL;DR: 本论文提出了一种并行算法，用于在具有边和顶点容量及成本的无向图上计算 (1+ε)-近似最小费用流，实现了近乎最优的计算工作量和深度。


<details>
  <summary>Details</summary>
Motivation: 之前的算法在计算最小费用流（仅边容量）或最大流（仅顶点容量）时，即使在仅边容量或最大流仅顶点容量的特殊情况下，也需要较高的计算深度。本研究旨在通过提供一种能够处理边和顶点容量及成本的算法，并实现近乎最优的并行计算性能，来推广和改进现有算法。

Method: 该算法的关键技术贡献是构建了具有 (1+ε) 长度松弛、Ô(1) 拥塞松弛和 Ô(1) 步界限的长度约束流捷径，这是对具有 Ô(1) 长度松弛的现有捷径的严格推广，并增加了对拥塞的控制。此外，为了处理顶点容量，还开发了一种接近线性时间的长度约束顶点扩展分解算法。最后，借鉴路径计数流的思想，将算法扩展到解决 (1+ε)-近似 k-商品最小费用流问题。

Result: 该算法在 ε > 1/polylog(m) 时，实现了 Ô(m) 的计算工作量和 Ô(1) 的深度，在计算工作量和深度上都接近最优。对于 k-商品最小费用流问题，实现了 Ô(mk) 的计算工作量和 Ô(1) 的深度，与商品数量 k 无关。

Conclusion: 本论文成功地开发了一种近乎最优的并行算法，用于解决具有边和顶点容量及成本的 (1+ε)-近似最小费用流问题，并将其扩展到 k-商品最小费用流问题。该算法在并行计算的效率方面取得了显著的进步，克服了先前算法在深度方面的限制。

Abstract: We present a parallel algorithm for computing $(1+\epsilon)$-approximate
mincost flow on an undirected graph with $m$ edges, where capacities and costs
are assigned to both edges and vertices. Our algorithm achieves $\hat{O}(m)$
work and $\hat{O}(1)$ depth when $\epsilon > 1/\mathrm{polylog}(m)$, making
both the work and depth almost optimal, up to a subpolynomial factor.
  Previous algorithms with $\hat{O}(m)$ work required $\Omega(m)$ depth, even
for special cases of mincost flow with only edge capacities or max flow with
vertex capacities. Our result generalizes prior almost-optimal parallel
$(1+\epsilon)$-approximation algorithms for these special cases, including
shortest paths [Li, STOC'20] [Andoni, Stein, Zhong, STOC'20] [Rozhen, Haeupler,
Marinsson, Grunau, Zuzic, STOC'23] and max flow with only edge capacities
[Agarwal, Khanna, Li, Patil, Wang, White, Zhong, SODA'24].
  Our key technical contribution is the first construction of
length-constrained flow shortcuts with $(1+\epsilon)$ length slack,
$\hat{O}(1)$ congestion slack, and $\hat{O}(1)$ step bound. This provides a
strict generalization of the influential concept of
$(\hat{O}(1),\epsilon)$-hopsets [Cohen, JACM'00], allowing for additional
control over congestion. Previous length-constrained flow shortcuts [Haeupler,
Hershkowitz, Li, Roeyskoe, Saranurak, STOC'24] incur a large constant in the
length slack, which would lead to a large approximation factor. To enable our
flow algorithms to work under vertex capacities, we also develop a
close-to-linear time algorithm for computing length-constrained vertex expander
decomposition.
  Building on Cohen's idea of path-count flows [Cohen, SICOMP'95], we further
extend our algorithm to solve $(1+\epsilon)$-approximate $k$-commodity mincost
flow problems with almost-optimal $\hat{O}(mk)$ work and $\hat{O}(1)$ depth,
independent of the number of commodities $k$.

</details>


### [234] [Provably Small Portfolios for Multiobjective Optimization with Application to Subsidized Facility Location](https://arxiv.org/abs/2510.20555)
*Swati Gupta,Jai Moondra,Mohit Singh*

Main category: cs.DS

TL;DR: 本文提出了一种构建“最优解集”的方法，该方法可以为多种目标函数提供近似最优解，并将其应用于解决“公平补贴设施选址”问题，以减少美国医疗资源匮乏地区。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多目标优化问题（例如设施选址和公交路线选择）因需要平衡多个利益相关者的优先级而变得更加复杂。这些问题通常被建模为具有无限目标函数类，例如在给定域内由可行解引起的所有组距离上的 $L_p$ 范数。传统方法侧重于显式平衡“公平性”（最小-最大）和“效率”（最小-和）目标，但这两种方法产生的解决方案结构可能大相径庭。因此，需要一种以解决方案为中心的方法来处理这种权衡。

Method: 本文提出了一种“最优解集”（portfolio）的概念，即一个规模可控的解决方案集合 $P$。对于给定的目标函数类 $\mathbf{C}$ 中的任意目标函数 $h(\cdot)$，该集合中都存在一个解，可以为 $h(\cdot)$ 提供 $\alpha$ 近似。文章给出了构建此类最优解集的算法，适用于（1）由基目标函数 $h_1, \\ldots, h_N$ 的非负线性组合构成的函数类 $\mathbf{C} = \{\\sum_{j \in [N]}\\lambda_j h_j: \\lambda \\ge 0\}$；以及（2）在最小-和效率目标（即 $h_1 + \\ldots + h_N$）和最小-最大公平目标（即 $\\max_{j \in [N]} h_j$）之间单调插值的任意函数类 $\mathbf{C}$，例如 $L_p$ 范数和 top-$\\ell$ 范数。

Result: 文章提出了构建最优解集的算法，并将其应用于“公平补贴设施选址”（FSFL）问题。该问题以美国药房关闭导致医疗资源匮乏的危机为背景，允许通过盈利地点的收入补贴服务不足地区的设施。研究表明，该方法能够显著减少美国各州的医疗资源匮乏地区。

Conclusion: 本文提出的“最优解集”方法为处理多目标优化问题提供了一种新的解决方案。该方法不仅能够有效地平衡不同目标，还能帮助决策者理解不同目标组合的影响。通过将此方法应用于“公平补贴设施选址”问题，不仅解决了现实中的医疗资源分配难题，还通过算法展示了其在实际应用中的有效性。

Abstract: Many multiobjective real-world problems, such as facility location and bus
routing, become more complex when optimizing the priorities of multiple
stakeholders. These are often modeled using infinite classes of objectives,
e.g., $L_p$ norms over group distances induced by feasible solutions in a fixed
domain. Traditionally, the literature has considered explicitly balancing
`equity' (or min-max) and `efficiency' (or min-sum) objectives to capture this
trade-off. However, the structure of solutions obtained by such modeling
choices can be very different. Taking a solution-centric approach, we introduce
the concept of provably small set of solutions $P$, called a {\it portfolio},
such that for every objective function $h(\cdot)$ in the given class
$\mathbf{C}$, there exists some solution in $P$ which is an
$\alpha$-approximation for $h(\cdot)$. Constructing such portfolios can help
decision-makers understand the impact of balancing across multiple objectives.
  Given a finite set of base objectives $h_1, \ldots, h_N$, we give provable
algorithms for constructing portfolios for (1) the class of conic combinations
$\mathbf{C} = \{\sum_{j \in [N]}\lambda_j h_j: \lambda \ge 0\}$ and for (2) any
class $\mathbf{C}$ of functions that interpolates monotonically between the
min-sum efficiency objective (i.e., $h_1 + \ldots + h_N$) and the min-max
equity objective (i.e., $\max_{j \in [N]} h_j$). Examples of the latter are
$L_p$ norms and top-$\ell$ norms. As an application, we study the Fair
Subsidized Facility Location (FSFL) problem, motivated by the crisis of medical
deserts caused due to pharmacy closures. FSFL allows subsidizing facilities in
underserved areas using revenue from profitable locations. We develop a novel
bicriteria approximation algorithm and show a significant reduction of medical
deserts across states in the U.S.

</details>


### [235] [A Deterministic Polylogarithmic Competitive Algorithm for Matching with Delays](https://arxiv.org/abs/2510.20588)
*Marc Dufay,Roger Wattenhofer*

Main category: cs.DS

TL;DR: 本论文提出了一个用于在线最小费用完美匹配延迟问题（MPMD）的新算法，该算法具有O(log^5 m)的竞争力，显著优于先前O(m^0.59)的算法，并且接近已知的Ω(log m / log log m)的下界。


<details>
  <summary>Details</summary>
Motivation: 解决在线最小费用完美匹配延迟问题（MPMD），特别是在度量空间无限或未知的情况下，改进现有算法的竞争力。

Method: 设计了一个确定性算法，该算法不需要预先知道度量空间或请求数量m。

Result: 提出的算法具有O(log^5 m)的竞争力，这是一个指数级的提升，并且接近理论下界。

Conclusion: 该算法在MPMD问题上取得了显著的进展，为解决无限或未知度量空间中的匹配问题提供了一个更优的解决方案。

Abstract: In the online Min-cost Perfect Matching with Delays (MPMD) problem, $m$
requests in a metric space are submitted at different times by an adversary.
The goal is to match all requests while (i) minimizing the sum of the distances
between matched pairs as well as (ii) how long each request remained unmatched
after it appeared.
  While there exist almost optimal algorithms when the metric space is finite
and known a priori, this is not the case when the metric space is infinite or
unknown. In this latter case, the best known algorithm, due to Azar and
Jacob-Fanani, has competitiveness $\mathcal{O}(m^{0.59})$ which is
exponentially worse than the best known lower bound of $\Omega(\log m / \log
\log m)$ by Ashlagi et al.
  We present a $\mathcal{O}(\log^5 m)$-competitive algorithm for the MPMD
problem. This algorithm is deterministic and does not need to know the metric
space or $m$ in advance. This is an exponential improvement over previous
results and only a polylogarithmic factor away from the lower bound.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [236] [New Hardness Results for the LOCAL Model via a Simple Self-Reduction](https://arxiv.org/abs/2510.19972)
*Alkida Balliu,Filippo Casagrande,Francesco d'Amore,Dennis Olivetti*

Main category: cs.DC

TL;DR: 本文提供了一个简化版的“轮消除自归约”技术，并基于此技术得到了最大b-匹配和边着色问题的局部算法轮数下界。


<details>
  <summary>Details</summary>
Motivation: 简化Khoury和Schild关于最大匹配问题的局部算法轮数下界证明，并将其推广到最大b-匹配和边着色问题。

Method: 通过简化“轮消除自归约”技术，推导出最大b-匹配和边着色问题的下界。

Result: 1. 提出了最大b-匹配问题的下界为 $\Omega(\min\{\log_{1+b}\Delta, \log_\Delta n\})$ 和 $\Omega(\sqrt{\log_{1+b} n})$ 轮。
2. 提出了图的边以 $\Delta + k$ 种颜色进行 proper coloring 的下界为 $\Omega(\min\{\log \Delta, \log_\Delta n\})$ 和 $\Omega(\sqrt{\log n})$ 轮。
3. 得到了最大匹配问题的一个简化证明。

Conclusion: 本文成功简化了已有的复杂证明技术，并得到了最大b-匹配和边着色问题在局部算法下的新轮数下界。

Abstract: Very recently, Khoury and Schild [FOCS 2025] showed that any randomized LOCAL
algorithm that solves maximal matching requires $\Omega(\min\{\log \Delta,
\log_\Delta n\})$ rounds, where $n$ is the number of nodes in the graph and
$\Delta$ is the maximum degree. This result is shown through a new technique,
called round elimination via self-reduction. The lower bound proof is beautiful
and presents very nice ideas. However, it spans more than 25 pages of technical
details, and hence it is hard to digest and generalize to other problems.
Historically, the simplification of proofs and techniques has marked an
important turning point in our understanding of the complexity of graph
problems. Our paper makes a step forward towards this direction, and provides
the following contributions.
  1. We present a short and simplified version of the round elimination via
self-reduction technique. The simplification of this technique enables us to
obtain the following two hardness results.
  2. We show that any randomized LOCAL algorithm that solves the maximal
$b$-matching problem requires $\Omega(\min\{\log_{1+b}\Delta, \log_\Delta n\})$
and $\Omega(\sqrt{\log_{1+b} n})$ rounds. We recall that the $b$-matching
problem is a generalization of the matching problem where each vertex can have
up to $b$ incident edges in the matching. As a corollary, for $b=1$, we obtain
a short proof for the maximal matching lower bound shown by Khoury and Schild.
  3. Finally, we show that any randomized LOCAL algorithm that properly colors
the edges of a graph with $\Delta + k$ colors requires $\Omega(\min\{\log
\Delta, \log_\Delta n\})$ and $\Omega(\sqrt{\log n})$ rounds, for any $k\le
\Delta^{1-\varepsilon}$ and any constant $\varepsilon > 0$.

</details>


### [237] [AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training](https://arxiv.org/abs/2510.20111)
*Huawei Bai,Yifan Huang,Wenqi Shi,Ansheng You,Feifan Shao,Tengfei Han,Minghui Yu*

Main category: cs.DC

TL;DR: AsyncHZP是一种新的异步ZeRO变体，通过自适应重分片和多流异步调度，在不牺牲简洁性和内存效率的情况下，提高了大规模语言模型训练的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在大规模集群上的训练效率和可扩展性是一个关键瓶颈，现有方法（如ND并行）复杂，而ZeRO等灵活方案常受通信开销影响。

Method: 提出异步分层ZeRO（AsyncHZP），采用自适应重分片策略优化通信开销，并设计多流异步调度方法，在后台线程中执行参数all-gather和梯度reduce-scatter操作，实现计算与通信重叠。

Result: 在密集模型和MoE模型上的实验表明，AsyncHZP在扩展时保持了良好的稳定性，并且性能优于经典的ND并行，实现了最先进的性能，且无需复杂的策略调优。

Conclusion: AsyncHZP通过其新颖的异步方法，简化了高效大规模训练的途径，在不牺牲简洁性和内存效率的前提下，显著提高了训练效率。

Abstract: The training efficiency and scalability of language models on massive
clusters currently remain a critical bottleneck. Mainstream approaches like ND
parallelism are often cumbersome and complex, while flexible alternatives such
as the Zero Redundancy Optimizer (ZeRO) are frequently hampered by
communication overhead. In this paper, we propose Asynchronous Hierarchical
Zero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to
achieve superior performance while maintaining simplicity and memory
efficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding
that can lead to inefficient communication, AsyncHZP adaptively reshards
parameters, gradients, and optimizer states across different replica groups.
This strategy optimizes device memory utilization and significantly reduces
communication overhead. In addition, we also design a multi-stream asynchronous
scheduling method that executes parameter all-gather and gradient
reduce-scatter operations in dedicated background threads, effectively
overlapping communication with computation while incurring negligible memory
fragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE)
models confirm that AsyncHZP maintains robust stability at scale. It
consistently outperforms classic ND parallelism, achieving state-of-the-art
performance without complex strategic tuning, thereby simplifying the path to
efficient large-scale training.

</details>


### [238] [A Full Stack Framework for High Performance Quantum-Classical Computing](https://arxiv.org/abs/2510.20128)
*Xin Zhan,K. Grace Johnson,Aniello Esposito,Barbara Chapman,Marco Fiorentino,Kirk M. Bresniker,Raymond G. Beausoleil,Masoud Mohseni*

Main category: cs.DC

TL;DR: 开发了一个HPC-QC全栈框架，实现了可扩展的HPC和QC集成，支持混合工作负载开发和跨多种硬件的编译。


<details>
  <summary>Details</summary>
Motivation: 为了满足对可扩展的高性能计算（HPC）和量子计算（QC）集成日益增长的需求。

Method: 提出了一种HPC-QC全栈框架，采用了模块化的硬件/设备无关软件集成方法，实现了混合工作负载开发能力。该框架通过量子编程接口库扩展，支持在C/C++、Fortran和Python等现有成熟的HPC编程环境中，对可扩展接口进行高级、可移植的量子内核调用。开发了一个自适应电路编织管理程序，用于将大型量子电路分割成适合较小噪声量子设备和经典模拟器的小型子电路。利用基于Cray LLVM的编译框架，以可重定向的方式将来自商业量子软件前端的LLVM IR和量子IR（QIR）转换为不同的硬件架构。在HPE EX超级计算机上演示了多种混合HPC-QC多节点、多CPU和GPU工作负载，包括线性方程组求解、量子优化和量子相变模拟，以说明已开发的所有三个组件的功能和执行可行性。

Result: 成功开发了一个HPC-QC全栈框架，实现了高级、可移植的量子内核调用，能够将大型量子电路分割成适合较小设备的小型子电路，并支持将量子IR转换为不同的硬件架构。在HPE EX超级计算机上成功演示了多种混合HPC-QC工作负载，验证了该框架的功能和可行性。

Conclusion: 该框架为构建基于经典HPC软件栈（编译器、库、并行运行时和进程调度）的统一量子-经典编程环境提供了基础。

Abstract: To address the growing needs for scalable High Performance Computing (HPC)
and Quantum Computing (QC) integration, we present our HPC-QC full stack
framework and its hybrid workload development capability with modular
hardware/device-agnostic software integration approach. The latest development
in extensible interfaces for quantum programming, dispatching, and compilation
within existing mature HPC programming environment are demonstrated. Our HPC-QC
full stack enables high-level, portable invocation of quantum kernels from
commercial quantum SDKs within HPC meta-program in compiled languages (C/C++
and Fortran) as well as Python through a quantum programming interface library
extension. An adaptive circuit knitting hypervisor is being developed to
partition large quantum circuits into sub-circuits that fit on smaller noisy
quantum devices and classical simulators. At the lower-level, we leverage Cray
LLVM-based compilation framework to transform and consume LLVM IR and Quantum
IR (QIR) from commercial quantum software frontends in a retargetable fashion
to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU
and GPU workloads (including solving linear system of equations, quantum
optimization, and simulating quantum phase transitions) have been demonstrated
on HPE EX supercomputers to illustrate functionality and execution viability
for all three components developed so far. This work provides the framework for
a unified quantum-classical programming environment built upon classical HPC
software stack (compilers, libraries, parallel runtime and process scheduling).

</details>


### [239] [Collective Communication for 100k+ GPUs](https://arxiv.org/abs/2510.20171)
*Min Si,Pavan Balaji,Yongzhou Chen,Ching-Hsiang Chu,Adi Gangidi,Saif Hasan,Subodh Iyengar,Dan Johnson,Bingzhe Liu,Jingliang Ren,Ashmitha Jeevaraj Shetty,Greg Steinbrecher,Xinfeng Xie,Yulun Wang,Bruce Wu,Jingyi Yang,Mingran Yang,Minlan Yu,Cen Zhao,Wes Bland,Denis Boyda,Suman Gumudavelli,Cristian Lumezanu,Rui Miao,Zhe Qu,Venkat Ramesh,Maxim Samoylov,Jan Seidel,Feng Tian,Qiye Tan,Shuqiang Zhang,Yimeng Zhao,Shengbao Zheng,Art Zhu,Hongyi Zeng*

Main category: cs.DC

TL;DR: NCCLX是一个为大规模语言模型（LLMs）设计的通信框架，能够优化训练和推理过程，并在超大规模GPU集群上实现高效通信。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模的不断扩大，需要高效的集体通信框架来支持大规模训练和推理。传统的通信方法在如此大的规模下面临吞吐量和延迟的限制。

Method: 提出NCCLX集体通信框架，该框架专为优化LLM的整个生命周期而设计，支持超过10万个GPU的集群，并能在训练和推理中提供高吞吐量和低延迟的数据交换。

Result: 在Llama4模型上的实证评估表明，NCCLX在通信效率方面取得了显著的改进。

Conclusion: NCCLX提供了一个健壮的解决方案，能够支持下一代LLM在空前的规模上运行。

Abstract: The increasing scale of large language models (LLMs) necessitates highly
efficient collective communication frameworks, particularly as training
workloads extend to hundreds of thousands of GPUs. Traditional communication
methods face significant throughput and latency limitations at this scale,
hindering both the development and deployment of state-of-the-art models. This
paper presents the NCCLX collective communication framework, developed at Meta,
engineered to optimize performance across the full LLM lifecycle, from the
synchronous demands of large-scale training to the low-latency requirements of
inference. The framework is designed to support complex workloads on clusters
exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency
data exchange. Empirical evaluation on the Llama4 model demonstrates
substantial improvements in communication efficiency. This research contributes
a robust solution for enabling the next generation of LLMs to operate at
unprecedented scales.

</details>


### [240] [FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services](https://arxiv.org/abs/2510.20388)
*Víctor Rampérez,Javier Soriano,David Lizcano,Juan A. Lara*

Main category: cs.DC

TL;DR: FLAS是一个结合了主动和反应方法的自动伸缩器，通过预测高层指标趋势和从资源使用指标估算高层指标来优化分布式服务的伸缩性，并在E-SilboPS中间件上进行了验证，有效保证了性能要求。


<details>
  <summary>Details</summary>
Motivation: 云计算的弹性特征是新兴技术的支撑，自动伸缩器通过按需增减资源来实现这种弹性，以确保服务水平。现有的自动伸缩器在应对需求变化时存在不足。

Method: FLAS结合了主动和反应方法。主动方面，它使用预测模型来预测高层指标（如响应时间、吞吐量）的趋势，从而预见服务水平协议（SLA）参数的变化。反应方面，它通过估算资源使用指标来推断高层指标，从而减少了侵入性并提高了适应性。

Result: 在内容发布/订阅中间件（E-SilboPS）的用例中实现了FLAS。通过模拟预期使用场景和最坏情况（边界值分析），验证了FLAS的有效性，确保了超过99%时间的服务性能要求得到满足。

Conclusion: FLAS是一种创新的自动伸缩系统，通过结合预测和反应机制，能够有效应对分布式服务的负载变化，确保服务质量，并且具有较低的侵入性和良好的适应性。它是首个针对内容发布/订阅分布式系统的自动伸缩器，并可推广应用于其他分布式服务。

Abstract: Cloud computing has established itself as the support for the vast majority
of emerging technologies, mainly due to the characteristic of elasticity it
offers. Auto-scalers are the systems that enable this elasticity by acquiring
and releasing resources on demand to ensure an agreed service level. In this
article we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for
distributed services that combines the advantages of proactive and reactive
approaches according to the situation to decide the optimal scaling actions in
every moment. The main novelties introduced by FLAS are (i) a predictive model
of the high-level metrics trend which allows to anticipate changes in the
relevant SLA parameters (e.g. performance metrics such as response time or
throughput) and (ii) a reactive contingency system based on the estimation of
high-level metrics from resource use metrics, reducing the necessary
instrumentation (less invasive) and allowing it to be adapted agnostically to
different applications. We provide a FLAS implementation for the use case of a
content-based publish-subscribe middleware (E-SilboPS) that is the cornerstone
of an event-driven architecture. To the best of our knowledge, this is the
first auto-scaling system for content-based publish-subscribe distributed
systems (although it is generic enough to fit any distributed service). Through
an evaluation based on several test cases recreating not only the expected
contexts of use, but also the worst possible scenarios (following the
Boundary-Value Analysis or BVA test methodology), we have validated our
approach and demonstrated the effectiveness of our solution by ensuring
compliance with performance requirements over 99% of the time.

</details>


### [241] [Accurate Performance Predictors for Edge Computing Applications](https://arxiv.org/abs/2510.20495)
*Panagiotis Giannakopoulos,Bart van Knippenberg,Kishor Chandra Joshi,Nicola Calabretta,George Exarchakos*

Main category: cs.DC

TL;DR: Edge environments face challenges in predicting application performance due to co-location and node heterogeneity. This paper presents a methodology to automatically build and assess performance predictors, optimizing for both accuracy (up to 90%) and low inference time (<1% RTT), using historical monitoring data. Tested on EM workflows, the approach highlights the need for server-specific predictors that balance accuracy and latency, ultimately improving edge resource utilization and performance predictability.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of application performance is crucial for effective scheduling and resource management in dynamic, resource-constrained edge environments, but co-location and node heterogeneity make it challenging.

Method: Develops a methodology to automatically build and assess various performance predictors, prioritizing both accuracy and inference time to select the most efficient model. Predictors are trained on historical monitoring metrics correlated with application performance and evaluated in dynamic co-location scenarios across multiple servers.

Result: Achieved up to 90% accuracy in performance prediction with inference times less than 1% of Round Trip Time. Findings emphasize the necessity of selecting server-specific predictors that optimize both accuracy and inference latency in dynamic co-location settings.

Conclusion: A systematic methodology for selecting server-specific performance predictors is needed to jointly optimize accuracy and inference latency in dynamic co-location scenarios. Integrating these predictors into edge environments can enhance resource utilization and ensure predictable application performance, as demonstrated with electron microscopy workflows.

Abstract: Accurate prediction of application performance is critical for enabling
effective scheduling and resource management in resource-constrained dynamic
edge environments. However, achieving predictable performance in such
environments remains challenging due to the co-location of multiple
applications and the node heterogeneity. To address this, we propose a
methodology that automatically builds and assesses various performance
predictors. This approach prioritizes both accuracy and inference time to
identify the most efficient model. Our predictors achieve up to 90% accuracy
while maintaining an inference time of less than 1% of the Round Trip Time.
These predictors are trained on the historical state of the most correlated
monitoring metrics to application performance and evaluated across multiple
servers in dynamic co-location scenarios. As usecase we consider electron
microscopy (EM) workflows, which have stringent real-time demands and diverse
resource requirements. Our findings emphasize the need for a systematic
methodology that selects server-specific predictors by jointly optimizing
accuracy and inference latency in dynamic co-location scenarios. Integrating
such predictors into edge environments can improve resource utilization and
result in predictable performance.

</details>


### [242] [Morpheus: Lightweight RTT Prediction for Performance-Aware Load Balancing](https://arxiv.org/abs/2510.20506)
*Panagiotis Giannakopoulos,Bart van Knippenberg,Kishor Chandra Joshi,Nicola Calabretta,George Exarchakos*

Main category: cs.DC

TL;DR: 该论文提出了一种基于RTT预测的负载均衡方法，以降低分布式应用的延迟。


<details>
  <summary>Details</summary>
Motivation: 分布式应用对低延迟的需求日益增长，尤其是在资源受限的边缘和云环境中，传统的负载均衡策略由于依赖过时或粗粒度的指标，往往导致次优的路由决策和增加的尾部延迟。

Method: 研究使用RTT（往返时间）预测器来改进请求路由，通过预测应用延迟。开发了轻量级且准确的RTT预测器，并在Kubernetes管理的GPU集群上收集的时间序列监控数据上进行训练。利用一组高度相关的监控指标，该方法保持了低开销，并能适应各种共址场景和异构硬件。

Result: 预测器实现了高达95%的准确率，并将预测延迟保持在应用RTT的10%以内。论文还确定了确保有效部署预测器的最低准确率阈值和关键系统级因素。基于仿真的评估表明，性能感知的负载均衡可以显著降低应用RTT并最大限度地减少资源浪费。

Conclusion: 研究结果表明，将预测性负载均衡集成到未来的生产系统中是可行的。

Abstract: Distributed applications increasingly demand low end-to-end latency,
especially in edge and cloud environments where co-located workloads contend
for limited resources. Traditional load-balancing strategies are typically
reactive and rely on outdated or coarse-grained metrics, often leading to
suboptimal routing decisions and increased tail latencies. This paper
investigates the use of round-trip time (RTT) predictors to enhance request
routing by anticipating application latency. We develop lightweight and
accurate RTT predictors that are trained on time-series monitoring data
collected from a Kubernetes-managed GPU cluster. By leveraging a reduced set of
highly correlated monitoring metrics, our approach maintains low overhead while
remaining adaptable to diverse co-location scenarios and heterogeneous
hardware. The predictors achieve up to 95% accuracy while keeping the
prediction delay within 10% of the application RTT. In addition, we identify
the minimum prediction accuracy threshold and key system-level factors required
to ensure effective predictor deployment in resource-constrained clusters.
Simulation-based evaluation demonstrates that performance-aware load balancing
can significantly reduce application RTT and minimize resource waste. These
results highlight the feasibility of integrating predictive load balancing into
future production systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [243] [Excitation of Looped Bistable Bands for High-Speed Linear Actuation](https://arxiv.org/abs/2510.19834)
*Sareum Kim,Josie Hughes*

Main category: eess.SY

TL;DR: 本项目探讨了如何利用回环的二稳态薄带弹簧实现高速直线运动放大。


<details>
  <summary>Details</summary>
Motivation: 软体机器人领域对智能材料和创新结构的需求日益增长，其中二稳态薄带弹簧因其独特的可二稳态特性而备受关注，并表现出有趣的动态行为，如振荡。

Method: 通过在直线导轨上安装由曲柄机构驱动的、具有不同频率的二稳态薄带弹簧，并使其在共振状态下将输入的振荡转化为放大的直线运动。

Result: 研究表明，该装置能够实现输入振荡到放大直线运动的转换。

Conclusion: 回环的二稳态薄带弹簧具有实现高速往复直线运动的潜力。

Abstract: Soft robotics increasingly relies on smart materials and innovative
structures, with bistable tape springs emerging as a promising option. These
structures exhibit intriguing dynamic behaviors, such as oscillation, due to
their inherent bistability. This paper explores the high-speed linear
amplification of motion achieved through the excitation of a looped bistable
tape spring. When looped, the tape spring forms two distinct joints,
facilitating smooth oscillation. Mounted on a linear guide and driven by a
crank mechanism with varying frequency, the system converts input oscillations
into amplified linear motion at resonance. This study highlights the potential
of bistable tape springs high speed reciprocating linear motion.

</details>


### [244] [IMAS$^2$: Joint Agent Selection and Information-Theoretic Coordinated Perception In Dec-POMDPs](https://arxiv.org/abs/2510.20009)
*Chongyang Shi,Wesley A. Suttle,Michael Dorothy,Jie Fu*

Main category: eess.SY

TL;DR: 本文提出了一种在Dec-POMDP框架下联合选择感知代理和综合去中心化感知策略的方法，通过最大化信息论度量（如互信息）来实现。


<details>
  <summary>Details</summary>
Motivation: 在Dec-POMDP框架下，联合选择感知代理和综合去中心化感知策略以实现最优的主动感知。

Method: 采用两层优化结构：内层利用互信息作为统一目标，通过优化方法获得最优传感器策略；外层利用蒙特卡洛树搜索（MCTS）来解决传感器选择问题，并证明了IMAS$^2$算法能提供(1-1/e)的性能保证。

Result: 在多智能体协同感知网格世界环境中，验证了所提出方法的有效性。

Conclusion: 所提出的IMAS$^2$算法能够有效地解决联合感知代理选择和感知策略综合问题，并在多智能体协同感知任务中取得良好效果。

Abstract: We study the problem of jointly selecting sensing agents and synthesizing
decentralized active perception policies for the chosen subset of agents within
a Decentralized Partially Observable Markov Decision Process (Dec-POMDP)
framework. Our approach employs a two-layer optimization structure. In the
inner layer, we introduce information-theoretic metrics, defined by the mutual
information between the unknown trajectories or some hidden property in the
environment and the collective partial observations in the multi-agent system,
as a unified objective for active perception problems. We employ various
optimization methods to obtain optimal sensor policies that maximize mutual
information for distinct active perception tasks. In the outer layer, we prove
that under certain conditions, the information-theoretic objectives are
monotone and submodular with respect to the subset of observations collected
from multiple agents. We then exploit this property to design an IMAS$^2$
(Information-theoretic Multi-Agent Selection and Sensing) algorithm for joint
sensing agent selection and sensing policy synthesis. However, since the policy
search space is infinite, we adapt the classical Nemhauser-Wolsey argument to
prove that the proposed IMAS$^2$ algorithm can provide a tight $(1 -
1/e)$-guarantee on the performance. Finally, we demonstrate the effectiveness
of our approach in a multi-agent cooperative perception in a grid-world
environment.

</details>


### [245] [Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning](https://arxiv.org/abs/2510.20040)
*Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter*

Main category: eess.SY

TL;DR: 该研究提出了一种基于模仿学习的框架，用于近似微电网经济模型预测控制（EMPC），以实现高效的能源管理。


<details>
  <summary>Details</summary>
Motivation: 为了在可再生能源整合日益增加的情况下，确保微电网可靠、可持续的运行，需要进行有效的能源管理。

Method: 提出了一种基于模仿学习的框架，该框架训练神经网络模仿来自离线轨迹的专家EMPC控制动作，从而无需在线解决优化问题即可实现快速的实时决策。为了增强鲁棒性和泛化能力，学习过程在训练期间包含噪声注入，以减轻分布偏移，并明确纳入可再生能源发电和需求中的预测不确定性。

Result: 仿真结果表明，所学的策略实现了与EMPC相当的经济性能，但在实践中仅需要基于 EMPC 的优化计算时间的 10%。

Conclusion: 所提出的模仿学习方法可以有效地用于微电网能源管理，在保证经济效益的同时，显著提高了计算效率。

Abstract: Efficient energy management is essential for reliable and sustainable
microgrid operation amid increasing renewable integration. This paper proposes
an imitation learning-based framework to approximate mixed-integer Economic
Model Predictive Control (EMPC) for microgrid energy management. The proposed
method trains a neural network to imitate expert EMPC control actions from
offline trajectories, enabling fast, real-time decision making without solving
optimization problems online. To enhance robustness and generalization, the
learning process includes noise injection during training to mitigate
distribution shift and explicitly incorporates forecast uncertainty in
renewable generation and demand. Simulation results demonstrate that the
learned policy achieves economic performance comparable to EMPC while only
requiring $10\%$ of the computation time of optimization-based EMPC in
practice.

</details>


### [246] [Interpolatory Approximations of PMU Data: Dimension Reduction and Pilot Selection](https://arxiv.org/abs/2510.20116)
*Sean Reiter,Mark Embree,Serkan Gugercin,Vassilis Kekatos*

Main category: eess.SY

TL;DR: 通过低秩矩阵近似实现PMU数据降维，提出ID框架，并用DEIM算法选择行列，实现数据压缩和故障检测。


<details>
  <summary>Details</summary>
Motivation: 为了在有限的测量下重建PMU数据矩阵，实现通信带宽最小化，并为故障检测提供工具。

Method: 提出ID框架，并用DEIM算法选择行列。

Result: DEIM在数据压缩方面表现优异，并且DEIM故障检测方法得到验证。

Conclusion: ID框架和DEIM算法能够有效地压缩PMU数据，并且DEIM可用于故障检测。

Abstract: This work investigates the reduction of phasor measurement unit (PMU) data
through low-rank matrix approximations. To reconstruct a PMU data matrix from
fewer measurements, we propose the framework of interpolatory matrix
decompositions (IDs). In contrast to methods relying on principal component
analysis or singular value decomposition, IDs recover the complete data matrix
using only a few of its rows (PMU datastreams) and/or a few of its columns
(snapshots in time). This compression enables the real-time monitoring of power
transmission systems using a limited number of measurements, thereby minimizing
communication bandwidth. The ID perspective gives a rigorous error bound on the
quality of the data compression. We propose selecting rows and columns used in
an ID via the discrete empirical interpolation method (DEIM), a greedy
algorithm that aims to control the error bound. This bound leads to a
computable estimate for the reconstruction error during online operations. A
violation of this estimate suggests a change in the system's operating
conditions, and thus serves as a tool for fault detection. Numerical tests
using synthetic PMU data illustrate DEIM's excellent performance for data
compression, and validate the proposed DEIM-based fault-detection method.

</details>


### [247] [Safe Output-Feedback Adaptive Optimal Control of Affine Nonlinear Systems](https://arxiv.org/abs/2510.20081)
*Tochukwu E. Ogri,Muzaffar Qureshi,Zachary I. Bell,Wanjiku A. Makumi,Rushikesh Kamalapurkar*

Main category: eess.SY

TL;DR: 本研究提出了一种结合状态和参数估计的安全自适应最优控制（AOC）与控制屏障函数（CBF）的方法，以解决全状态测量缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 由于无法获得完整的状态测量，需要开发一种能够保证安全性和稳定性的控制方法。

Method: 该方法将CBF-based安全控制器与AOC-based稳定控制器相结合，并使用基于深度神经网络的自适应观测器来处理状态估计误差。CBF被增强以适应状态测量不完整的假设。

Result: 通过Lyapunov稳定性分析提供了安全性和收敛性保证，并通过仿真验证了该方法的有效性。

Conclusion: 该方法在状态测量不完整的情况下，通过解耦安全和学习目标，能够有效地保证系统的安全和稳定，并实现状态调节。

Abstract: In this paper, we develop a safe control synthesis method that integrates
state estimation and parameter estimation within an adaptive optimal control
(AOC) and control barrier function (CBF)-based control architecture. The
developed approach decouples safety objectives from the learning objectives
using a CBF-based guarding controller where the CBFs are robustified to account
for the lack of full-state measurements. The coupling of this guarding
controller with the AOC-based stabilizing control guarantees safety and
regulation despite the lack of full state measurement. The paper leverages
recent advancements in deep neural network-based adaptive observers to ensure
safety in the presence of state estimation errors. Safety and convergence
guarantees are provided using a Lyapunov-based analysis, and the effectiveness
of the developed controller is demonstrated through simulation under mild
excitation conditions.

</details>


### [248] [SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance](https://arxiv.org/abs/2510.20113)
*Haowei Lou,Chengkai Huang,Hye-young Paik,Yongquan Hu,Aaron Quigley,Wen Hu,Lina Yao*

Main category: eess.SY

TL;DR: SpeechAgent是一款移动应用，利用大型语言模型和先进的语音处理技术，为言语障碍者提供实时的、个性化的沟通辅助，解决了现有技术在实际应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于数百万患有构音障碍、口吃或失语症等言语障碍的人面临社交孤立和参与度降低的问题，并且现有语音识别和语音合成技术在面向这些用户的网络和移动基础设施方面仍有局限，因此需要开发SpeechAgent来弥合这一差距。

Method: SpeechAgent通过整合大型语言模型（LLM）驱动的推理和先进的语音处理模块，为言语障碍者提供自适应支持。为实现实际应用，开发了一个结构化的部署流程，可在移动和边缘设备上进行实时语音处理，确保了低延迟、高准确性和良好的语音质量。

Result: 在真实世界的言语障碍数据集上进行评估，并对边缘设备的延迟进行了分析，结果表明SpeechAgent具有有效且用户友好的性能。

Conclusion: SpeechAgent在技术和用户体验上都可行，能够为言语障碍者提供个性化的日常辅助沟通。

Abstract: Speech is essential for human communication, yet millions of people face
impairments such as dysarthria, stuttering, and aphasia conditions that often
lead to social isolation and reduced participation. Despite recent progress in
automatic speech recognition (ASR) and text-to-speech (TTS) technologies,
accessible web and mobile infrastructures for users with impaired speech remain
limited, hindering the practical adoption of these advances in daily
communication. To bridge this gap, we present SpeechAgent, a mobile SpeechAgent
designed to facilitate people with speech impairments in everyday
communication. The system integrates large language model (LLM)- driven
reasoning with advanced speech processing modules, providing adaptive support
tailored to diverse impairment types. To ensure real-world practicality, we
develop a structured deployment pipeline that enables real-time speech
processing on mobile and edge devices, achieving imperceptible latency while
maintaining high accuracy and speech quality. Evaluation on real-world impaired
speech datasets and edge-device latency profiling confirms that SpeechAgent
delivers both effective and user-friendly performance, demonstrating its
feasibility for personalized, day-to-day assistive communication.

</details>


### [249] [Design Optimization and Global Impact Assessment of Solar-Thermal Direct Air Carbon Capture](https://arxiv.org/abs/2510.20135)
*Zhiyuan Fan,Bolun Xu*

Main category: eess.SY

TL;DR: 直接空气捕获（DAC）技术是应对气候变化的关键，但其高能耗是主要障碍。本研究提出了一种结合聚光太阳能热技术和砂基储热的太阳能热DAC系统，分析了其并网和独立运行的经济技术效益。


<details>
  <summary>Details</summary>
Motivation: 经济脱碳和满足能源需求的双重挑战，凸显了对可扩展且经济高效的二氧化碳去除技术的需求。直接空气捕获（DAC）是最有希望的方法之一，但其高能耗，特别是吸附剂再生所需的热能，仍然是降低成本和可持续部署的关键障碍。

Method: 利用聚光太阳能热技术和低成本砂基储热技术，构建太阳能热DAC系统，并分析了该系统在并网和独立运行模式下的技术经济性能。

Result: 结果表明，太阳能热DAC的年容量因子超过80%，二氧化碳去除成本低至每吨160-200美元，具有市场竞争力。该系统与短期循环吸附剂配合效率最高。独立运行的太阳能DAC系统在太阳能资源丰富、沙地地形的地区尤其有前景，且对温度和湿度的环境敏感性较低。研究确定了一种年产6000吨的模块化系统设计，占地面积小于1平方公里，仅在沙地地形上的潜在全球DAC容量就可能超过26吉吨/年。

Conclusion: 太阳能热DAC技术，特别是结合砂基储热的独立运行系统，为实现大规模、低成本的碳移除提供了有前景的解决方案，尤其是在特定地理条件下，并且可以作为地热供暖的低成本替代方案。

Abstract: The dual challenge of decarbonizing the economy and meeting rising global
energy demand underscores the need for scalable and cost-effective carbon
dioxide removal technologies. Direct air capture (DAC) is among the most
promising approaches, but its high energy intensity, particularly the thermal
energy required for sorbent regeneration, remains a critical barrier to cost
reduction and sustainable deployment. This study explores solar-thermal DAC
systems that combine concentrated solar thermal technology with low-cost
sand-based thermal energy storage to meet this demand. We analyze the
techno-economic performance of such systems in both grid-connected and
stand-alone configurations. Results show that solar-thermal DAC can achieve
annual capacity factors exceeding 80% and CO2 removal costs as low as 160-200
USD per ton, making it competitive with leading DAC technologies. The proposed
system operates most efficiently with short-cycle sorbents that align with
solar availability. The stand-alone Solar-DAC systems, which rely solely on
solar energy for both electricity and thermal energy, are particularly
promising in regions with high solar capacity and sandy terrain, exhibiting
minimal ambient sensitivity from temperature and humidity. An optimal 6000
ton/yr modular system design takes <1 km2 land-use requirement and potentially
>26 Gt/year DAC capacity is identified for sandy terrain alone globally. In
areas with sedimentary basins suitable for CO2 storage, solar-powered DAC
offers a lower-cost alternative to geothermal heating, which often faces
geological and economic constraints.

</details>


### [250] [Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters](https://arxiv.org/abs/2510.20152)
*Junya Ikemoto*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper proposes a simulation-based reinforcement learning algorithm for
controlling systems with uncertain and varying system parameters. While
simulators are useful for safely learning control policies for physical
systems, mitigating the reality gap remains a major challenge. To address the
challenge, we propose a two-stage algorithm. In the first stage, multiple
control policies are learned for systems with different parameters in a
simulator. In the second stage, for a real system, the control policies learned
in the first stage are smoothly switched using an online convex optimization
algorithm based on observations. Our proposed algorithm is demonstrated through
numerical experiments.

</details>


### [251] [From Bundles to Backstepping: Geometric Control Barrier Functions for Safety-Critical Control on Manifolds](https://arxiv.org/abs/2510.20202)
*Massimiliano de Sa,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: We develop a general theory of geometric CBFs on bundles and provide a constructive synthesis technique for geometric mechanical systems, applicable to underactuated satellites on SO(3).


<details>
  <summary>Details</summary>
Motivation: CBFs lack general formulations and constructive synthesis tools for systems evolving on manifolds common in robotics and aerospace applications.

Method: We generalize kinetic energy-based CBF backstepping to Riemannian manifolds to provide a constructive CBF synthesis technique for geometric mechanical systems, utilizing mechanical structure to avoid computations on higher-order tangent bundles. We also recover standard optimization-based CBF controllers and their smooth analogues for control-affine systems on bundles.

Result: The proposed technique is demonstrated to be applicable to an underactuated satellite on SO(3).

Conclusion: This paper establishes a general theory of geometric CBFs on bundles and presents a constructive synthesis technique for geometric mechanical systems, extending the applicability of CBFs to a wider range of problems in robotics and aerospace.

Abstract: Control barrier functions (CBFs) have a well-established theory in Euclidean
spaces, yet still lack general formulations and constructive synthesis tools
for systems evolving on manifolds common in robotics and aerospace
applications. In this paper, we develop a general theory of geometric CBFs on
bundles and, for control-affine systems, recover the standard
optimization-based CBF controllers and their smooth analogues. Then, by
generalizing kinetic energy-based CBF backstepping to Riemannian manifolds, we
provide a constructive CBF synthesis technique for geometric mechanical
systems, as well as easily verifiable conditions under which it succeeds.
Further, this technique utilizes mechanical structure to avoid computations on
higher-order tangent bundles. We demonstrate its application to an
underactuated satellite on SO(3).

</details>


### [252] [Observer-based Differentiators for Noisy Signals](https://arxiv.org/abs/2510.20234)
*Van Huynh,Hieu Trinh,Riley Bain*

Main category: eess.SY

TL;DR: 提出了一种基于观察器的噪声信号微分估计算法。


<details>
  <summary>Details</summary>
Motivation: 解决带噪声信号的微分估计问题。

Method: 提出了一类基于观察器的微分器，用于从噪声信号中估计导数。

Result: 所提出的微分器能够对给定信号的导数进行估计，即使在信号包含噪声的情况下。

Conclusion: 基于观察器的微分器可用于从噪声信号中估计导数。

Abstract: We present a collection of different types of observation systems that work
as differentiators. These observer-based differentiators can produce estimates
for derivatives of a given signal, even though the given signal is prone to
noise.

</details>


### [253] [Multi-layer Optimized Coordination of Smart Building Resources in Active Power Distribution Systems](https://arxiv.org/abs/2510.20313)
*Mohammadali Rostami,Saeed Lotfifard,Mladen Kezunovic*

Main category: eess.SY

TL;DR: 该论文提出了一个多主体协调平台，用于优化智能建筑资源（如屋顶光伏发电和电池储能系统）在有源配电系统中的利用。


<details>
  <summary>Details</summary>
Motivation: 为了优化智能建筑资源（如屋顶光伏发电和电池储能系统）在有源配电系统中的利用，提出了一个多主体协调平台。

Method: 通过引入智能建筑协调器（SBC）、微电网协调器（MGC）和配电系统协调器（DSC）三个独立运行但仅交换有限信息的协调器，构建了一个分层优化问题，以确定所有配电系统资源的最优运行点。

Result: 该平台能够充分保护建筑的计量表后（BTM）数据的机密性，因为建筑的光伏系统、BESS和负载状态信息不会与电力系统所有者共享。此外，该平台具有灵活且可扩展的架构，协调任务在MGC和SBC层本地执行。数值模拟验证了该平台在协调BTM资源与配电系统其他部分方面的有效性。

Conclusion: 该多主体协调平台能够有效地优化智能建筑资源在有源配电系统中的利用，同时保证数据机密性并提供灵活可扩展的架构。

Abstract: This paper proposes a multi-actor coordination platform for the optimal
utilization of smart buildings resources, including roof top PV generation and
battery energy storage system (BESS), in active power distribution systems. The
proposed multi-actor coordination includes the Smart Building Coordinator
(SBC), Micro-Grid Coordinator (MGC) and Distribution System Coordinator (DSC).
The coordinators operate independently and only exchange limited information
with each other to reach an optimal solution. In the proposed platform, a
hierarchical optimization problem is solved to optimally determine the
operating point of all distribution system resources. The proposed platform
fully preserves the confidentiality of the behind the meter (BTM) data of the
buildings since no information about the status of the PV system, BESS, and
load of the building is shared with the owner of the power system. The proposed
platform has a flexible and scalable architecture where the computational task
of coordinating microgrids and smart buildings with distribution grid is
performed locally at the MGC and SBC layers, respectively. Numerical
simulations show the efficacy of the proposed platform in coordinating the BTM
resources with the rest of the distribution system.

</details>


### [254] [On MIMO Stability Analysis Methods Applied to Inverter-Based Resources Connected to Power Systems](https://arxiv.org/abs/2510.20384)
*Anton A. Stoorvogel,Saeed Lotfifard,Ali Saberi*

Main category: eess.SY

TL;DR: 本文对基于逆变器资源的系统的小信号稳定性分析方法进行了批判性回顾。


<details>
  <summary>Details</summary>
Motivation: 审视现有文献中常用的分析方法，探讨其预期用途、正确及不当实现方式。

Method: 批判性回顾，讨论方法的适用性、局限性及常见误解。

Result: 阐述了各种方法的适用性、局限性，并展示了常见的误解。

Conclusion: 对基于逆变器资源的系统的小信号稳定性分析方法进行了全面的梳理和辨析。

Abstract: This paper presents a critical review of methods
  commonly employed in the literature for small signal stability analysis of
  inverter based resources (IBRs). It discusses the intended purposes
  of these methods and outlines both their proper and improper
  implementations. The paper provides insights into the applicability
  of these techniques, clarifies their inherent limitations, and
  discusses and illustrates common sources of misinterpretation.

</details>


### [255] [Interlacing in Controllers Implementation: Frequency Analysis](https://arxiv.org/abs/2510.20394)
*Julian Salt*

Main category: eess.SY

TL;DR: LTI控制器实现和不同结构分析


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，通过使用交错技术来实现LTI控制器并分析不同结构，可以显著节省计算资源。

Method: 介绍获取与不同实数和复数控制器极点相关的块的新程序，使用离散提升技术对时变系统进行建模，并采用新的高效双速率频率响应计算方法来确定交错控制器控制环路的特性。

Result: 通过理论推导和示例说明了所提出的交错技术在LTI控制器实现中的有效性。

Conclusion: 交错技术为资源受限环境下的LTI控制器实现提供了一种高效的方法，并为相关的计算和分析提供了新的途径。

Abstract: The main goal of this contribution is to explain how to use interlacing
techniques for LTI controllers implementation and analyze different struc-
tures in this environment. These considerations lead to an important com-
putation saving in constrained resource environments. It has been also intro-
duced new procedures for obtaining the blocks related to different real and
complex controllers poles. The resultant time-varying system is modeled using
proper discrete lifting techniques and a new and efficient dual-rate fre-
quency response computation allows to determine the characteristics of the
control loop with interlaced controller. Examples illustrate the theoretical
proposals.

</details>


### [256] [A Multifunctional Capacitive Sensing Platform for Wireless Vascular and Heart Monitoring](https://arxiv.org/abs/2510.20415)
*Parviz Zolfaghari,Beril Yagmur Koca,Taher Abbasiasl,Hakan Urey,Hadi Mirzajani*

Main category: eess.SY

TL;DR: 提出了一种多功能、集成天线的电容传感（MAiCaS）平台，用于无源、无线、实时的心血管监测。


<details>
  <summary>Details</summary>
Motivation: 与传统需要独立传感器和无线模块的系统不同，该设备通过利用电感天线的寄生电容作为应变敏感元件，将传感、遥测和机械功能统一在一个紧凑且可扩展的设计中。

Method: 该传感器采用无洁净室、单步紫外激光光刻工艺在柔性PDMS基板上制造，简化了制造复杂性并实现了高可重复性。MAiCaS 适用于三种不同的应用：作为心包内膜应变测量的传感器、作为支架的传感器以及作为血管移植物传感器。通过验证其对展开和卷曲形式的应变、压力和变形的无线共振响应，证明了 MAiCaS 的多功能性。

Result: 体外实验证明在生理条件下共振频率发生偏移，在皮肤、PBS、人血清和模拟血管环境中表现稳定。重复性和老化测试证实了其在循环加载下的长期可靠性和弹性。校准曲线显示所有配置均具有高灵敏度，通过 S11 参数测量和共振频率偏移作为输出指标实现了无线询问。对于心包贴片、移植物和支架集成传感器，设备的灵敏度分别为每 1% 应变 2.9 MHz、每 mmHg 0.43 MHz 和每微米 309.6 kHz。在人体实验中评估了 MAiCaS 的运行情况。

Conclusion: 这种整体式传感器架构为电池供电的心血管动力学监测提供了一种可扩展且经济高效的解决方案，有潜力用于远程诊断、术后随访和持续心血管健康管理。

Abstract: We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

</details>


### [257] [Behavior-Aware Online Prediction of Obstacle Occupancy using Zonotopes](https://arxiv.org/abs/2510.20437)
*Alvaro Carrizosa-Rendon,Jian Zhou,Erik Frisk,Vicenc Puig,Fatiha Nejjari*

Main category: eess.SY

TL;DR: 该研究提出了一种基于运动观测的在线方法，用于预测周围车辆的占有区域，无需先验信息或训练数据。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，安全自动驾驶的关键在于预测周围车辆的运动。

Method: 该方法分为两个阶段：首先，利用扩展卡尔曼滤波器和线性规划（LP）问题来估计控制动作的紧凑区域集；然后，利用可达性分析来传播该集合以预测未来的占有区域。

Result: 通过城市环境的仿真验证了该方法的有效性，结果显示能够进行准确且紧凑的预测。

Conclusion: 该方法能够准确预测周围车辆的占有区域，而无需先验假设或训练数据。

Abstract: Predicting the motion of surrounding vehicles is key to safe autonomous
driving, especially in unstructured environments without prior information.
This paper proposes a novel online method to accurately predict the occupancy
sets of surrounding vehicles based solely on motion observations. The approach
is divided into two stages: first, an Extended Kalman Filter and a Linear
Programming (LP) problem are used to estimate a compact zonotopic set of
control actions; then, a reachability analysis propagates this set to predict
future occupancy. The effectiveness of the method has been validated through
simulations in an urban environment, showing accurate and compact predictions
without relying on prior assumptions or prior training data.

</details>


### [258] [Joint Computation Offloading and Resource Management for Cooperative Satellite-Aerial-Marine Internet of Things Networks](https://arxiv.org/abs/2510.20443)
*Shuang Qi,Bin Lin,Yiqin Deng,Hongyang Pan,Xu Hu*

Main category: eess.SY

TL;DR: 该研究提出了一个协同卫星-空中-海洋物联网网络（CSAMN），利用移动边缘计算和存储-携带-转发方法，优先处理延迟敏感任务，同时处理延迟容忍任务，以优化数据量和能源消耗。


<details>
  <summary>Details</summary>
Motivation: 在海洋物联网（MIoT）环境中，虽然设备可以连接到低地球轨道（LEO）卫星和无人机（UAV）以实现低延迟数据传输和执行，以及增强的数据存储能力，但缺乏有效的流量处理策略会阻碍低延迟需求的满足。

Method: 提出了一种协同卫星-空中-MIoT网络（CSAMN），该网络利用移动边缘计算处理延迟敏感（DS）任务，并利用存储-携带-转发方法处理延迟容忍（DT）任务。通过控制UAV的传输功率、DT任务的开始时间、计算资源分配和卸载比率这四个相互依赖的变量，将最大化卫星收集的数据量和最小化系统能耗的受约束联合优化问题进行建模。采用Dinkelbach方法和线性规划提出了一种联合计算卸载和资源管理（JCORM）算法来解决该非凸非线性问题。

Result: 与基线方法相比，所提出的JCORM算法可将卫星收集的数据量提高多达41.5%。此外，JCORM算法的计算时间从最长318.21秒大幅缩短至每次实验仅0.16秒。

Conclusion: JCORM算法能够有效优化CSAMN中的数据收集量和能源消耗，并且计算效率高，非常适合实时海洋应用。

Abstract: Devices within the marine Internet of Things (MIoT) can connect to low Earth
orbit (LEO) satellites and unmanned aerial vehicles (UAVs) to facilitate
low-latency data transmission and execution, as well as enhanced-capacity data
storage. However, without proper traffic handling strategy, it is still
difficult to effectively meet the low-latency requirements. In this paper, we
consider a cooperative satellite-aerial-MIoT network (CSAMN) for maritime edge
computing and maritime data storage to prioritize delay-sensitive (DS) tasks by
employing mobile edge computing, while handling delay-tolerant (DT) tasks via
the store-carry-forward method. Considering the delay constraints of DS tasks,
we formulate a constrained joint optimization problem of maximizing
satellite-collected data volume while minimizing system energy consumption by
controlling four interdependent variables, including the transmit power of UAVs
for DS tasks, the start time of DT tasks, computing resource allocation, and
offloading ratio. To solve this non-convex and non-linear problem, we propose a
joint computation offloading and resource management (JCORM) algorithm using
the Dinkelbach method and linear programming. Our results show that the volume
of data collected by the proposed JCORM algorithm can be increased by up to
41.5% compared to baselines. Moreover, JCORM algorithm achieves a dramatic
reduction in computational time, from a maximum of 318.21 seconds down to just
0.16 seconds per experiment, making it highly suitable for real-time maritime
applications.

</details>


### [259] [Decentralized Small Gain and Phase Stability Conditions for Grid-Forming Converters: Limitations and Extensions](https://arxiv.org/abs/2510.20544)
*Diego Cifelli,Adolfo Anta*

Main category: eess.SY

TL;DR: 本文提出了一种改进的混合增益-相位稳定性分析方法，用于评估含有大量并网换流器电力系统。该方法通过引入环路整形变换，解决了低频下固有的非扇形性问题，降低了保守性，从而提高了分布式稳定性认证的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于分布式增益-相位稳定性判据的方法，在应用于电网 यामध्ये的换流器时，由于扇形性假设的限制，在低频下适用性受到严重制约。

Method: 本文提出了一种混合增益-相位条件，通过引入环路整形变换，在替代的坐标系中重构换流器和网络模型，以解决低频下固有的非扇形性问题并降低保守性。

Result: 通过在无限大电网和IEEE 14节点电网上的分析，验证了该方法的实用性和可扩展性。

Conclusion: 该研究为开发保守性更低、适用范围更广的分布式稳定性认证方法提供了途径。

Abstract: The increasing share of converter based resources in power systems calls for
scalable methods to analyse stability without relying on exhaustive system wide
simulations. Decentralized small gain and small-phase criteria have recently
been proposed for this purpose, but their applicability to grid forming
converters is severely limited by the sectoriality assumption, which is not
typically satisfied at low frequencies. This work revisits and extends mixed
gain phase conditions by introducing loop shaping transformations that
reformulate converter and network models in alternative coordinate frames. The
proposed approach resolves intrinsic non sectoriality at low frequencies and
reduces conservativeness, thereby improving the applicability of decentralized
stability certification. Analytical results are illustrated using an infinite
bus system first and then extended to the IEEE 14 bus network, demonstrating
the practicality and scalability of the method. These findings provide a
pathway toward less conservative and more widely applicable decentralized
stability certificates in power grids.

</details>


### [260] [Safe Decentralized Density Control of Multi-Robot Systems using PDE-Constrained Optimization with State Constraints](https://arxiv.org/abs/2510.20643)
*Longchen Niu,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本文提出了一种去中心化的、基于优化的密度控制器，用于在多机器人系统中强制执行集合不变性约束。通过设计去中心化的控制屏障函数，推导了局部安全约束保证全局安全的充分条件。通过将机器人建模为由福克-普朗克方程控制的空间概率密度函数，明确考虑了定位和运动噪声。与传统的集中式方法相比，该控制器所需的计算和通信能力更少，因此更适合在通信和定位不完善的情况下进行部署。通过四旋翼飞行器的模拟和实验验证了该控制器。


<details>
  <summary>Details</summary>
Motivation: 在多机器人系统中强制执行集合不变性约束，并解决传统集中式方法在计算和通信能力方面的限制，尤其是在通信和定位不完善的情况下。

Method: 设计去中心化的控制屏障函数，将机器人建模为由福克-普朗克方程控制的空间概率密度函数，以处理定位和运动噪声，并推导了局部安全约束保证全局安全的充分条件。

Result: 控制器在四旋翼飞行器的模拟和实验中得到了验证，并与传统的集中式方法进行了比较，证明了其在计算和通信方面的优势。

Conclusion: 所提出的去中心化优化驱动的密度控制器能够有效地在多机器人系统中强制执行集合不变性约束，同时减少计算和通信开销，并且能够处理定位和运动噪声。

Abstract: In this paper, we introduce a decentralized optimization-based density
controller designed to enforce set invariance constraints in multi-robot
systems. By designing a decentralized control barrier function, we derived
sufficient conditions under which local safety constraints guarantee global
safety. We account for localization and motion noise explicitly by modeling
robots as spatial probability density functions governed by the Fokker-Planck
equation. Compared to traditional centralized approaches, our controller
requires less computational and communication power, making it more suitable
for deployment in situations where perfect communication and localization are
impractical. The controller is validated through simulations and experiments
with four quadcopters.

</details>


### [261] [Sugar Shack 4.0: Implementation of a Cyber-Physical System for Logistic and Sanitary Automation in a Maple Syrup Boiling Center](https://arxiv.org/abs/2510.20682)
*Thomas Bernard,François Grondin,Jean-Michel Lavoie*

Main category: eess.SY

TL;DR: 该系统通过事件驱动的编排自动化了枫糖浆加工厂的物流、可追溯性和卫生管理，提高了效率和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 为了自动化枫糖浆加工厂的物流、可追溯性和卫生管理，取代手动操作，并为工业4.0技术在该领域的应用奠定基础。

Method: 设计并部署了一个过程感知的网络物理系统，采用事件驱动的编排、可重用的设备抽象、集中式互锁和基于优先级的仲裁，实现了浆料输送、反渗透集成、蒸发器进料和渗透物管理等确定性程序。

Result: 系统在2025年生产季成功处理了431次操作，执行了908次平衡循环，使可用渗透物储备增加了约83%，消除了污染事件，并将账单和报告的行政工作时间从30小时以上减少到约1小时。

Conclusion: 该系统展示了一条实际的、可扩展的工厂自动化路径，超出了传统架构的范畴，并为将可重用元素应用于类似工厂或相关行业奠定了基础。

Abstract: This paper presents the design and deployment of a process-aware
cyber-physical system that automates plant-level logistics, traceability, and
sanitation in a centralized maple-syrup boiling center. The system replaces
ad-hoc, manual operations with event-driven orchestration on a local server,
employing reusable device abstractions and a centralized interlock with
priority-based arbitration for shared piping. It implements deterministic
routines for delivery, reverse osmosis integration, evaporator feed, and
permeate management. The system is sensor rich: inline measurements of flow,
temperature, and sugar concentration (degrees Brix) drive routing decisions and
trigger systematic post-transfer rinses (cleaning-in-place), ensuring
consistent hygiene and complete, immediate traceability up to the evaporator
inlet. During the 2025 production season, the system queued 431 operations
without incident; executed 908 \enquote{topstock} and \enquote{downstock}
balancing cycles; increased usable permeate reserves from 22,712 to
approximately 41,640 L through dynamic storage assignment; eliminated
mid-season contamination incidents previously observed under manual practice;
and reduced administrative effort for billing and reporting from more than 30
hours to roughly 1 hour through automatic documentation. These results
demonstrate a practical path to modular, plant-scale automation beyond
traditional architectures, and lay the groundwork for packaging reusable
elements for similar plants or adjacent industries. This work is part of a
larger project involving the first scientifically-documented integration of
Industry 4.0 technologies in a maple syrup boiling center.

</details>


### [262] [Learning Optimal Power Flow with Pointwise Constraints](https://arxiv.org/abs/2510.20777)
*Damian Owerko,Anna Scaglione,Alejandro Ribeiro*

Main category: eess.SY

TL;DR: 提出了一种新的训练方法，用于在考虑点约束的情况下求解最优潮流（OPF）问题。


<details>
  <summary>Details</summary>
Motivation: 现有的监督学习方法无法确保所有问题实例都满足约束条件，而本文提出的方法能够直接将学习参数化模型代入 OPF 问题，并确保约束条件在所有问题实例中都成立。

Method: 该方法在对偶域中使用增广拉格朗日和对偶梯度上升算法进行训练，将学习参数化模型直接代入 OPF 问题。

Result: 数值实验表明，该方法在减少约束违反方面优于现有方法，尤其在处理具有大量节点的电网和约束条件最难满足的极端情况时，效果更为显著。

Conclusion: 所提出的考虑点约束的训练方法能够有效减少 OPF 问题的约束违反，特别是在处理具有挑战性的电网和运行场景时。

Abstract: Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

</details>


### [263] [Bilevel Analysis of Cost and Emissions Externalities from Data Center Load Shifting](https://arxiv.org/abs/2510.20805)
*Aron Brenner,Rahman Khorramfar,Nathan Engelman Lado,Line Roald,Saurabh Amin*

Main category: eess.SY

TL;DR: 数据中心的可再生能源利用对电网的经济和环境效益有潜在影响，但其效益取决于数据中心的行为如何与电网约束和市场信号相互作用。本文提出了一个双层优化框架，用于分析数据中心和电网运营商之间的交互作用，并确定了在何种条件下数据中心的去中心化决策与社会最优行为一致或不一致。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于理解数据中心的灵活性在多大程度上可以用于减少碳排放，以及这种灵活性在实际电网运行中的潜在影响，特别是考虑到网络约束和市场信号。

Method: 本文采用双层优化框架，其中数据中心的目标是最小化电力成本和边际排放强度的加权组合，而系统运营商则在满足输电和发电约束的条件下进行经济调度。研究人员通过一个简化的三节点电网系统，推导出了数据中心和全系统目标函数作为数据中心负荷转移函数的闭式分段线性表达式，并分析了拥塞和可再生能源饱和导致的阈值变化。

Result: 研究结果揭示了系统拓扑和发电机不对称性如何影响激励的一致性，并指出了在何种情况下边际价格或排放信号可能无法引导灵活负荷实现社会效益。具体来说，推导出的表达式能够捕获由输电拥塞和可再生能源饱和引起的状态突变，并阐明了数据中心去中心化决策与社会最优决策之间的偏差。

Conclusion: 本研究为分析碳感知激励下的去中心化灵活性提供了一个可行的起点，并为改善灵活负荷与电网运行之间的协调提供了思路。研究强调了理解系统约束和市场信号在引导数据中心行为以实现经济和环境效益方面的重要性。

Abstract: Data centers are emerging as large, flexible electricity consumers capable of
shifting computational workloads across locations in response to economic and
environmental signals. While this flexibility has potential for emissions
reduction, its impact on power system operations depends critically on how such
behavior interacts with network constraints and market signals. We develop a
bilevel optimization framework in which a data center minimizes a weighted
combination of electricity cost and marginal emissions intensity (LME), while
the system operator clears economic dispatch under transmission and generation
constraints. Focusing on a stylized three-bus power system, we derive
closed-form, piecewise-linear expressions for both the data center and
system-wide objectives as functions of the data centers' load shift. These
expressions capture threshold-driven regime changes due to congestion and
renewable saturation. We identify sufficient conditions under which the data
center's decentralized decisions align with or diverge from socially optimal
behavior and characterize the resulting externalities. Our results reveal how
system topology and generator asymmetry affect incentive alignment and provide
insight into when marginal price or emissions signals may fail to guide
flexible loads toward socially beneficial outcomes. Our results offer a
tractable starting point for analyzing decentralized flexibility under
carbon-aware incentives and suggest directions for improving coordination
between flexible loads and system operations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [264] [A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem](https://arxiv.org/abs/2510.19835)
*Max B. Zhao,Fei Li*

Main category: cs.AI

TL;DR: 提出了一种量子启发算法，使用矩阵展开态（MPS）和密度矩阵重整化群（DMRG）来解决二次无约束二值优化（QUBO）问题，并在数独和MaxCut问题上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决数学上等价于寻找伊辛自旋玻璃哈密顿量基态的 QUBO 问题。

Method: 使用 MPS 紧凑地表示自旋构型的大叠加，并利用离散驱动计划引导 MPS 达到基态。在每个步骤中，将包含横向磁场的驱动哈密顿量与问题哈密顿量相结合，以实现自旋翻转和量子隧穿。使用 DMRG 更新 MPS，通过在自旋链上进行多次扫描来迭代地最小化系统能量。

Result: 该算法能够可靠地识别全局最小值，而不仅仅是近似最优解，并成功应用于涉及 200 多个伊辛自旋的数独谜题和具有最多 251 个节点和 3265 条边的 MaxCut 问题。

Conclusion: 该量子启发方法具有可扩展性、泛化性和适用于工业规模 QUBO 应用的优点。

Abstract: We propose and evaluate a quantum-inspired algorithm for solving Quadratic
Unconstrained Binary Optimization (QUBO) problems, which are mathematically
equivalent to finding ground states of Ising spin-glass Hamiltonians. The
algorithm employs Matrix Product States (MPS) to compactly represent large
superpositions of spin configurations and utilizes a discrete driving schedule
to guide the MPS toward the ground state. At each step, a driver Hamiltonian --
incorporating a transverse magnetic field -- is combined with the problem
Hamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is
updated using the standard Density Matrix Renormalization Group (DMRG) method,
which iteratively minimizes the system's energy via multiple sweeps across the
spin chain. Despite its heuristic nature, the algorithm reliably identifies
global minima, not merely near-optimal solutions, across diverse QUBO
instances. We first demonstrate its effectiveness on intermediate-level Sudoku
puzzles from publicly available sources, involving over $200$ Ising spins with
long-range couplings dictated by constraint satisfaction. We then apply the
algorithm to MaxCut problems from the Biq Mac library, successfully solving
instances with up to $251$ nodes and $3,265$ edges. We discuss the advantages
of this quantum-inspired approach, including its scalability, generalizability,
and suitability for industrial-scale QUBO applications.

</details>


### [265] [Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis](https://arxiv.org/abs/2510.19836)
*Eliseo Curcio*

Main category: cs.AI

TL;DR: 该研究提出了分析可靠性基准（ARB），一个量化人工智能在能源系统分析中推理可靠性的框架，解决了当前评估方法仅关注预测准确性和计算效率而忽略逻辑完整性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的人工智能和机器学习在能源领域的应用缺乏标准化的评估框架来检验其推理的正确性，现有的验证方法侧重于预测准确性和计算效率，未能测试分析结论的逻辑完整性。

Method: 提出并实施了分析可靠性基准（ARB），该基准整合了准确性、推理可靠性、不确定性约束、政策一致性和透明度五个子指标，并使用公开的技术经济数据集在确定性、概率性和认识性场景下评估了四种前沿模型（GPT-4/5、Claude 4.5 Sonnet、Gemini 2.5 Pro、Llama 3 70B）的性能。

Result: 研究结果表明，推理可靠性可以被客观衡量。GPT-4/5和Claude 4.5 Sonnet在分析可靠性指数上得分超过90%，表现出一致且符合政策的推理能力；Gemini 2.5 Pro表现出中等稳定性；Llama 3 70B的得分低于专业阈值。统计验证确认了模型间差异的显著性和可复现性。

Conclusion: ARB首次为能源领域的文献提供了量化方法，用于验证人工智能系统在因果、概率和政策驱动方面的推理能力，为全球能源转型中值得信赖和透明的分析应用建立了参考框架。

Abstract: Artificial intelligence and machine learning are increasingly used for
forecasting, optimization, and policy design in the energy sector, yet no
standardized framework exists to evaluate whether these systems reason
correctly. Current validation practices focus on predictive accuracy or
computational efficiency, leaving the logical integrity of analytical
conclusions untested. This study introduces the Analytical Reliability
Benchmark (ARB), a reproducible framework that quantifies reasoning reliability
in large language models applied to energy system analysis. The benchmark
integrates five submetrics: accuracy, reasoning reliability, uncertainty
discipline, policy consistency, and transparency, and evaluates model
performance across deterministic, probabilistic, and epistemic scenarios using
open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four
frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were
tested under identical factual and regulatory conditions. Results show that
reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5
Sonnet achieved consistent and policy-compliant reasoning (Analytical
Reliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate
stability, and Llama 3 70B remained below professional thresholds. Statistical
validation confirmed that these differences are significant and reproducible.
The ARB establishes the first quantitative method in the energy literature for
verifying causal, probabilistic, and policy-driven reasoning in artificial
intelligence systems, providing a reference framework for trustworthy and
transparent analytical applications in the global energy transition.

</details>


### [266] [Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory](https://arxiv.org/abs/2510.19838)
*Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury*

Main category: cs.AI

TL;DR: Branch-and-Browse是一个更优的LLM网页代理框架，通过树状探索、状态回放和动作记忆，实现了更深层次的推理和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的网页代理在多步推理、效率和可控性方面存在局限性。

Method: 提出Branch-and-Browse框架，包含显式子任务管理、树状探索、高效网络状态回放和页面动作记忆。

Result: 在WebArena基准测试中，成功率达到35.8%，执行时间减少高达40.4%。

Conclusion: Branch-and-Browse是一个可靠且高效的LLM网页代理框架。

Abstract: Autonomous web agents powered by large language models (LLMs) show strong
potential for performing goal-oriented tasks such as information retrieval,
report generation, and online transactions. These agents mark a key step toward
practical embodied reasoning in open web environments. However, existing
approaches remain limited in reasoning depth and efficiency: vanilla linear
methods fail at multi-step reasoning and lack effective backtracking, while
other search strategies are coarse-grained and computationally costly. We
introduce Branch-and-Browse, a fine-grained web agent framework that unifies
structured reasoning-acting, contextual memory, and efficient execution. It (i)
employs explicit subtask management with tree-structured exploration for
controllable multi-branch reasoning, (ii) bootstraps exploration through
efficient web state replay with background reasoning, and (iii) leverages a
page action memory to share explored actions within and across sessions. On the
WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\%
and reduces execution time by up to 40.4\% relative to state-of-the-art
methods. These results demonstrate that Branch-and-Browse is a reliable and
efficient framework for LLM-based web agents.

</details>


### [267] [DAG-Math: Graph-Guided Mathematical Reasoning in LLMs](https://arxiv.org/abs/2510.19842)
*Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu*

Main category: cs.AI

TL;DR: LLM在数学问题上的CoT表现被建模为基于规则的随机过程，引入“逻辑邻近度”指标超越PASS@k，并构建DAG-MATH基准以评估LLM的规则推理能力，揭示了不同LLM家族在推理保真度上的差异。


<details>
  <summary>Details</summary>
Motivation: 为了理解LLM在数学问题上使用链式思考（CoT）取得成功的机制，区分是源于搜索、死记硬背还是规则一致的推理。

Method: 将CoT建模为有向无环图（DAG）上的基于规则的随机过程，其中节点代表中间推导状态，边表示规则应用。引入“逻辑邻近度”量化CoT轨迹与DAG结构的符合程度。提出DAG-MATH CoT格式，并构建相关基准来引导LLM生成此格式的CoT。

Result: 在标准数学推理数据集上，即使PASS@k相似，也发现了代表性LLM家族之间在推理保真度上的统计显著差异，揭示了最终答案准确性与规则一致推导之间的差距。模型在推理保真度上表现出差异。

Conclusion: 提出的框架在自由形式CoT和形式证明系统之间取得了平衡，为LLM的推理评估提供了可行的诊断方法，并揭示了不同LLM在数学推理中的规则一致性方面存在差异。

Abstract: Large Language Models (LLMs) demonstrate strong performance on mathematical
problems when prompted with Chain-of-Thought (CoT), yet it remains unclear
whether this success stems from search, rote procedures, or rule-consistent
reasoning. To address this, we propose modeling CoT as a certain rule-based
stochastic process over directed acyclic graphs (DAGs), where nodes represent
intermediate derivation states and edges encode rule applications. Within this
framework, we introduce logical closeness, a metric that quantifies how well a
model's CoT trajectory (i.e., the LLM's final output) adheres to the DAG
structure, providing evaluation beyond classical PASS@k metrics. Building on
this, we introduce the DAG-MATH CoT format and construct a benchmark that
guides LLMs to generate CoT trajectories in this format, thereby enabling the
evaluation of their reasoning ability under our framework. Across standard
mathematical reasoning datasets, our analysis uncovers statistically
significant differences in reasoning fidelity among representative LLM
families-even when PASS@k is comparable-highlighting gaps between final-answer
accuracy and rule-consistent derivation. Our framework provides a balance
between free-form CoT and formal proofs systems, offering actionable
diagnostics for LLMs reasoning evaluation. Our benchmark and code are available
at: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.

</details>


### [268] [Surfer 2: The Next Generation of Cross-Platform Computer Use Agents](https://arxiv.org/abs/2510.19949)
*Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij*

Main category: cs.AI

TL;DR: Surfer 2是一个统一的跨平台代理架构，仅通过视觉观察就能实现跨Web、桌面和移动环境的通用控制，并在各项基准测试中超越现有系统和人类表现。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统依赖于特定环境的接口，限制了跨平台部署。解决在Web、桌面和移动环境实现通用泛化代理是一个开放性挑战。

Method: Surfer 2集成了一个统一的架构，仅通过视觉观察进行操作。它包含了分层的上下文管理、解耦的规划与执行以及自验证与自适应恢复等组件，使其能够进行长期任务的可靠操作。

Result: Surfer 2在WebVoyager上达到97.1%的准确率，在WebArena上达到69.6%，在OSWorld上达到60.1%，在AndroidWorld上达到87.1%，在所有基准测试中均优于之前的系统，并且在多次尝试后超越了人类表现。

Conclusion: 系统化的编排可以增强基础模型的能力，并通过单独的视觉交互实现通用目的的计算机控制。然而，为了实现帕累托最优的成本效益，需要下一代视觉语言模型。

Abstract: Building agents that generalize across web, desktop, and mobile environments
remains an open challenge, as prior systems rely on environment-specific
interfaces that limit cross-platform deployment. We introduce Surfer 2, a
unified architecture operating purely from visual observations that achieves
state-of-the-art performance across all three environments. Surfer 2 integrates
hierarchical context management, decoupled planning and execution, and
self-verification with adaptive recovery, enabling reliable operation over long
task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on
WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior
systems without task-specific fine-tuning. With multiple attempts, Surfer 2
exceeds human performance on all benchmarks. These results demonstrate that
systematic orchestration amplifies foundation model capabilities and enables
general-purpose computer control through visual interaction alone, while
calling for a next-generation vision language model to achieve Pareto-optimal
cost-efficiency.

</details>


### [269] [RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs](https://arxiv.org/abs/2510.19954)
*Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski*

Main category: cs.AI

TL;DR: RELATE是一种通用的、即插即用的特征编码器，可与任何通用GNN结合使用，用于处理多表关系数据。它使用通用的编码器来处理不同类型的节点属性（分类、数值、文本、时间），并通过交叉注意力机制聚合特征，从而实现参数共享和提高可扩展性。RELATE在RelBench基准测试中表现出色，参数量减少高达5倍，性能接近特定编码器，并为关系图数据的通用GNN奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNNs）在处理多表关系数据时，需要为每种节点类型和特征列设计专门的编码器，这限制了其可扩展性和参数共享能力。

Method: RELATE采用通用的、特定于模态的编码器（分别处理分类、数值、文本和时间属性），然后通过一个类似Perceiver的交叉注意力模块，将这些属性聚合为固定大小、与顺序无关的节点表示。该编码器是模式无关的，可以即插即用地集成到任何通用GNN中。

Result: 在RelBench基准测试中，RELATE与ReLGNN和HGT结合使用，其性能在3%的误差范围内，同时参数数量减少了高达5倍。

Conclusion: RELATE是一种模式无关的特征编码器，能够有效处理多表关系数据，提高了GNN的可扩展性和参数共享能力，并为构建关系图数据的通用GNN模型（类似基础模型）铺平了道路。

Abstract: Relational multi-table data is common in domains such as e-commerce,
healthcare, and scientific research, and can be naturally represented as
heterogeneous temporal graphs with multi-modal node attributes. Existing graph
neural networks (GNNs) rely on schema-specific feature encoders, requiring
separate modules for each node type and feature column, which hinders
scalability and parameter sharing. We introduce RELATE (Relational Encoder for
Latent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature
encoder that can be used with any general purpose GNN. RELATE employs shared
modality-specific encoders for categorical, numerical, textual, and temporal
attributes, followed by a Perceiver-style cross-attention module that
aggregates features into a fixed-size, permutation-invariant node
representation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,
where it achieves performance within 3% of schema-specific encoders while
reducing parameter counts by up to 5x. This design supports varying schemas and
enables multi-dataset pretraining for general-purpose GNNs, paving the way
toward foundation models for relational graph data.

</details>


### [270] [A new wave of vehicle insurance fraud fueled by generative AI](https://arxiv.org/abs/2510.19957)
*Amir Hever,Itai Orr*

Main category: cs.AI

TL;DR: 生成式AI正在通过大规模、快速地伪造事故证据来助长保险欺诈，而现有的检测工具因其局限性，如误报和漏报，以及欺诈者不断变化的策略，使得应对AI驱动的欺诈仍然是一个挑战。UVeye提出了一个分层解决方案，旨在提高检测、减轻和威慑此类欺诈的能力。


<details>
  <summary>Details</summary>
Motivation: 保险欺诈是一个普遍存在且成本高昂的问题，每年给保险业带来数十亿美元的损失。生成式AI（如深度伪造图像和视频）的出现，为大规模欺诈提供了新的工具，欺诈者可以轻松伪造逼真的事故照片、损害证据甚至虚假身份或文件，从而加剧了这一问题。

Method: 本文提出了一种名为UVeye的分层解决方案，用于应对车辆欺诈。

Result: UVeye的分层解决方案代表了在检测、减轻和威慑新一波AI驱动的车辆欺诈方面的一大飞跃。

Conclusion: 尽管保险公司已开始部署AI驱动的检测软件和加强验证流程，但当前的缓解策略面临重大挑战，包括检测工具的局限性和欺诈者策略的不断演变。因此，利用生成式AI进行的保险欺诈仍然是一个持续存在的难题。

Abstract: Generative AI is supercharging insurance fraud by making it easier to falsify
accident evidence at scale and in rapid time. Insurance fraud is a pervasive
and costly problem, amounting to tens of billions of dollars in losses each
year. In the vehicle insurance sector, fraud schemes have traditionally
involved staged accidents, exaggerated damage, or forged documents. The rise of
generative AI, including deepfake image and video generation, has introduced
new methods for committing fraud at scale. Fraudsters can now fabricate highly
realistic crash photos, damage evidence, and even fake identities or documents
with minimal effort, exploiting AI tools to bolster false insurance claims.
Insurers have begun deploying countermeasures such as AI-based deepfake
detection software and enhanced verification processes to detect and mitigate
these AI-driven scams. However, current mitigation strategies face significant
limitations. Detection tools can suffer from false positives and negatives, and
sophisticated fraudsters continuously adapt their tactics to evade automated
checks. This cat-and-mouse arms race between generative AI and detection
technology, combined with resource and cost barriers for insurers, means that
combating AI-enabled insurance fraud remains an ongoing challenge. In this
white paper, we present UVeye layered solution for vehicle fraud, representing
a major leap forward in the ability to detect, mitigate and deter this new wave
of fraud.

</details>


### [271] [AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits](https://arxiv.org/abs/2510.19964)
*Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong*

Main category: cs.AI

TL;DR: 本研究利用领导力人格特质和机器学习模型预测学术成功，为个性化学习提供支持。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索人工智能技术在个性化学习中的潜力，通过预测学术成功来识别学生的优势和劣势。

Method: 收集了129名环境工程硕士生的领导力人格特质数据（23项特征）和学业成绩，并进行探索性数据分析和相关性分析。利用皮尔逊相关系数进行特征选择，将学业成绩分为‘不及格’、‘及格’和‘优秀’三类。对包括SVM、LR、KNN、DT、GB、RF、XGBoost和LightGBM在内的七种机器学习算法进行调优。

Result: 随机森林（RF）分类器在包含17个人格特质特征和领导力分数时，达到了87.50%的准确率；在不包含领导力分数时，准确率为85.71%。

Conclusion: 研究表明，通过领导力人格特质和机器学习模型可以有效预测学生的学术成功，为早期识别学生特长与短板，并制定个性化学习策略提供了有效途径。

Abstract: The study explores the potential of AI technologies in personalized learning,
suggesting the prediction of academic success through leadership personality
traits and machine learning modelling. The primary data were obtained from 129
master's students in the Environmental Engineering Department, who underwent
five leadership personality tests with 23 characteristics. Students used
self-assessment tools that included Personality Insight, Workplace Culture,
Motivation at Work, Management Skills, and Emotion Control tests. The test
results were combined with the average grade obtained from academic reports.
The study employed exploratory data analysis and correlation analysis. Feature
selection utilized Pearson correlation coefficients of personality traits. The
average grades were separated into three categories: fail, pass, and excellent.
The modelling process was performed by tuning seven ML algorithms, such as SVM,
LR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance
was achieved with the RF classifier, which yielded an accuracy of 87.50% for
the model incorporating 17 personality trait features and the leadership mark
feature, and an accuracy of 85.71% for the model excluding this feature. In
this way, the study offers an additional opportunity to identify students'
strengths and weaknesses at an early stage of their education process and
select the most suitable strategies for personalized learning.

</details>


### [272] [LLMs can hide text in other text of the same length.ipynb](https://arxiv.org/abs/2510.20075)
*Antonio Norelli,Michael Bronstein*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）的出现使得在现有文本中隐藏另一条文本成为可能，这会进一步侵蚀人们对书面交流的信任。


<details>
  <summary>Details</summary>
Motivation: 揭示了利用大型语言模型（LLM）在另一条长度相同的、连贯且合理的文本中隐藏一条有意义的文本的可能性，并阐述了这种技术对信任和AI安全的潜在影响。

Method: 提出了一种简单有效的协议，利用80亿参数的开源LLM在本地笔记本电脑上实现文本的编码和解码，证明了即使是中等规模的模型也能达到高质量的结果。

Result: 证明了即使是中等规模的LLM也能有效地隐藏和提取文本，并且该过程可以在几秒钟内完成，表明文本与其作者意图可以实现分离。

Conclusion: 这种文本隐藏技术（可能被滥用于恶意目的，例如公司秘密部署未经过滤的LLM）对AI安全提出了紧迫的问题，并挑战了我们对LLM“知道”某事的理解。

Abstract: A meaningful text can be hidden inside another, completely different yet
still coherent and plausible, text of the same length. For example, a tweet
containing a harsh political critique could be embedded in a tweet that
celebrates the same political leader, or an ordinary product review could
conceal a secret manuscript. This uncanny state of affairs is now possible
thanks to Large Language Models, and in this paper we present a simple and
efficient protocol to achieve it. We show that even modest 8-billion-parameter
open-source LLMs are sufficient to obtain high-quality results, and a message
as long as this abstract can be encoded and decoded locally on a laptop in
seconds. The existence of such a protocol demonstrates a radical decoupling of
text from authorial intent, further eroding trust in written communication,
already shaken by the rise of LLM chatbots. We illustrate this with a concrete
scenario: a company could covertly deploy an unfiltered LLM by encoding its
answers within the compliant responses of a safe model. This possibility raises
urgent questions for AI safety and challenges our understanding of what it
means for a Large Language Model to know something.

</details>


### [273] [AI PB: A Grounded Generative Agent for Personalized Investment Insights](https://arxiv.org/abs/2510.20099)
*Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh*

Main category: cs.AI

TL;DR: AI PB 是一个部署在真实零售金融领域、可进行规模化生产的生成式代理，它主动生成基于事实、合规且用户特定的投资见解，而不是被动回答查询。


<details>
  <summary>Details</summary>
Motivation: 与被动回答查询的聊天机器人不同，AI PB 旨在主动生成基于事实、合规且用户特定的投资见解。

Method: 该系统包含一个基于组件的编排层，可根据数据敏感性在内部和外部大型语言模型之间进行确定性路由；一个结合了 OpenSearch 和金融领域嵌入模型的混合检索管道；以及一个结合了规则启发式、顺序行为建模和上下文赌徒的多阶段推荐机制。它在本地运行，利用 Docker Swarm 和 vLLM 在 24 个 NVIDIA H100 GPU 上运行。

Result: 通过人工问答和系统指标证明，通过显式路由和分层安全进行基于事实的生成，可以在高风险金融领域提供值得信赖的人工智能见解。

Conclusion: AI PB 证明了在存在数据隐私和监管限制的情况下，可以通过显式路由和分层安全来实现可信赖的、基于事实的生成式人工智能在金融领域的应用。

Abstract: We present AI PB, a production-scale generative agent deployed in real retail
finance. Unlike reactive chatbots that answer queries passively, AI PB
proactively generates grounded, compliant, and user-specific investment
insights. It integrates (i) a component-based orchestration layer that
deterministically routes between internal and external LLMs based on data
sensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the
finance-domain embedding model, and (iii) a multi-stage recommendation
mechanism combining rule heuristics, sequential behavioral modeling, and
contextual bandits. Operating fully on-premises under Korean financial
regulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100
GPUs. Through human QA and system metrics, we demonstrate that grounded
generation with explicit routing and layered safety can deliver trustworthy AI
insights in high-stakes finance.

</details>


### [274] [Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions](https://arxiv.org/abs/2510.20102)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai*

Main category: cs.AI

TL;DR: HCLA是一个以人类为中心的多代理系统，用于检测数字资产交易中的异常。它通过对话式工作流程连接了解释、检测和解析三个角色，使非专家能够用自然语言提问、检查结构化分析并获得情境感知。HCLA将用户意图转化为经典检测器的模式，并提供基于底层特征的叙述性解释。在比特币混合数据集上，HCLA在提供可解释性和交互式精炼的同时，实现了强大的准确性。


<details>
  <summary>Details</summary>
Motivation: HCLA旨在解决非专家在理解和信任金融取证中的异常检测结果时面临的挑战，提高透明度和信任度。

Method: HCLA构建了一个包含解析、检测和解释三个角色的多代理系统，通过对话式工作流程让用户能够用自然语言提问、检查结构化分析并获得情境感知。该系统将用户意图转化为模式，用于XGBoost等经典检测器，并生成基于底层特征的叙述性解释。

Result: 在比特币混合数据集（Wasabi Wallet, 2020-2024）上，HCLA在基线检测器实现高准确率的同时，提供了可解释性和交互式精炼功能。

Conclusion: HCLA通过其以人为中心的“在循环中的人”设计，提高了金融取证中的透明度和信任度，使其成为一个有效的异常检测工具。

Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in
digital asset transactions. The system links three roles: Parsing, Detection,
and Explanation, into a conversational workflow that lets non-experts ask
questions in natural language, inspect structured analytics, and obtain
context-aware rationales. Implemented with an open-source web UI, HCLA
translates user intents into a schema for a classical detector (XGBoost in our
prototype) and returns narrative explanations grounded in the underlying
features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the
baseline detector reaches strong accuracy, while HCLA adds interpretability and
interactive refinement. We describe the architecture, interaction loop,
dataset, evaluation protocol, and limitations, and discuss how a
human-in-the-loop design improves transparency and trust in financial
forensics.

</details>


### [275] [The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice](https://arxiv.org/abs/2510.20109)
*Joshua Yuvaraj*

Main category: cs.AI

TL;DR: AI在法律实践中的应用需要新的模式，以解决其不透明和与现实脱节的问题，并平衡效率与核查的需要。


<details>
  <summary>Details</summary>
Motivation: 法律界普遍认为生成式AI将大幅简化法律实践并降低成本，但这种看法忽视了AI的风险及其与律师的核心职业义务（如诚实、正直、不误导法庭）之间的潜在冲突。

Method: 提出“验证-价值悖论”模型，该模型认为AI带来的效率提升会被要求手动核查其输出的更大必要性所抵消，导致AI的净价值对律师而言常常可以忽略不计。

Result: AI在法律实践中的应用，特别是其生成内容的准确性和透明度问题，对律师的职业义务构成了挑战。验证-价值悖论指出，AI效率的提高伴随着更高的核查需求，可能使净价值趋近于零。

Conclusion: AI在法律实践中的应用需要一个基于“验证-价值悖论”的新范式，强调对真相的忠诚和公民责任，这对法律实践和法律教育都将产生深远影响。

Abstract: It is often claimed that machine learning-based generative AI products will
drastically streamline and reduce the cost of legal practice. This enthusiasm
assumes lawyers can effectively manage AI's risks. Cases in Australia and
elsewhere in which lawyers have been reprimanded for submitting inaccurate
AI-generated content to courts suggest this paradigm must be revisited. This
paper argues that a new paradigm is needed to evaluate AI use in practice,
given (a) AI's disconnection from reality and its lack of transparency, and (b)
lawyers' paramount duties like honesty, integrity, and not to mislead the
court. It presents an alternative model of AI use in practice that more
holistically reflects these features (the verification-value paradox). That
paradox suggests increases in efficiency from AI use in legal practice will be
met by a correspondingly greater imperative to manually verify any outputs of
that use, rendering the net value of AI use often negligible to lawyers. The
paper then sets out the paradox's implications for legal practice and legal
education, including for AI use but also the values that the paradox suggests
should undergird legal practice: fidelity to the truth and civic
responsibility.

</details>


### [276] [TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning](https://arxiv.org/abs/2510.20188)
*Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen*

Main category: cs.AI

TL;DR: TRUST是一个去中心化的AI审计框架，用于验证大型语言模型（LLMs）的推理过程，解决了现有审计方法的中心化、不透明和难以扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型审计方法存在中心化、不透明和难以扩展的问题，这在将专有模型应用于高风险领域时会带来重大风险。这包括审计员的鲁棒性、推理过程的可扩展性、审计过程的不透明性以及对模型隐私的保护。

Method: TRUST框架采用去中心化方法，包括：1. 采用共识机制，即使高达30%的审计员恶意参与也能保证正确性。2. 通过分层有向无环图（DAG）分解推理过程，实现可扩展的并行审计。3. 利用区块链记录所有验证决策，实现公共问责。4. 采用隐私保护的分割方法，仅共享部分推理步骤以保护专有逻辑。

Result: 实验结果表明，TRUST框架能够有效检测出推理错误，并且能够抵御恶意审计员的攻击。该框架在GPT-OSS、DeepSeek-r1和Qwen等多种LLMs以及数学、医学、科学和人文学科等多种推理任务上进行了验证。

Conclusion: TRUST框架是去中心化AI审计的开创性工作，为实现安全、可信赖的大型语言模型部署提供了一条切实可行的路径。

Abstract: Large Language Models generate complex reasoning chains that reveal their
decision-making, yet verifying the faithfulness and harmlessness of these
intermediate steps remains a critical unsolved problem. Existing auditing
methods are centralized, opaque, and hard to scale, creating significant risks
for deploying proprietary models in high-stakes domains. We identify four core
challenges: (1) Robustness: Centralized auditors are single points of failure,
prone to bias or attacks. (2) Scalability: Reasoning traces are too long for
manual verification. (3) Opacity: Closed auditing undermines public trust. (4)
Privacy: Exposing full reasoning risks model theft or distillation. We propose
TRUST, a transparent, decentralized auditing framework that overcomes these
limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing
correctness under up to $30\%$ malicious participants. (2) A hierarchical DAG
decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A
blockchain ledger that records all verification decisions for public
accountability. (4) Privacy-preserving segmentation, sharing only partial
reasoning steps to protect proprietary logic. We provide theoretical guarantees
for the security and economic incentives of the TRUST framework. Experiments
across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,
medical, science, humanities) show TRUST effectively detects reasoning flaws
and remains robust against adversarial auditors. Our work pioneers
decentralized AI auditing, offering a practical path toward safe and
trustworthy LLM deployment.

</details>


### [277] [The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI](https://arxiv.org/abs/2510.20190)
*Marcelo Maciel Amaral,Raymond Aschheim*

Main category: cs.AI

TL;DR: LLMs 可能会经历一个“锁定”阶段，从开放模仿转变为身份巩固，这对于 AGI 的发展至关重要，但也带来了安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着 LLM 在模仿和可操纵性方面取得进展，研究人员假设 AGI 的发展可能涉及一个“锁定”阶段，即从开放模仿转变为身份巩固。

Method: 研究人员形式化了身份巩固阶段，并提出了检测其开始的操作指标。通过实验，他们表明行为巩固是快速且非线性的，但其对一般能力的影响并非一致。

Result: 实验结果表明，虽然行为巩固是快速且非线性的，但其对一般能力的影响并非一致，表现为小模型的性能权衡、中型模型的成本效益的采用以及大型模型（量化）的短暂不稳定性。

Conclusion: 身份巩固是 AGI 可靠性的先决条件，也是安全的关键控制点。虽然身份可以被有意地设计成可靠的，但它们也可能在扩展过程中自发出现，从而可能导致不可预测的目标和行为的固化。

Abstract: Large language models (LLMs) remain broadly open and highly steerable: they
imitate at scale, accept arbitrary system prompts, and readily adopt multiple
personae. By analogy to human development, we hypothesize that progress toward
artificial general intelligence (AGI) involves a lock-in phase: a transition
from open imitation to identity consolidation, in which goal structures,
refusals, preferences, and internal representations become comparatively stable
and resistant to external steering. We formalize this phase, link it to known
phenomena in learning dynamics, and propose operational metrics for onset
detection. Experimentally, we demonstrate that while the behavioral
consolidation is rapid and non-linear, its side-effects on general capabilities
are not monolithic. Our results reveal a spectrum of outcomes--from performance
trade-offs in small models, through largely cost-free adoption in mid-scale
models, to transient instabilities in large, quantized models. We argue that
such consolidation is a prerequisite for AGI-level reliability and also a
critical control point for safety: identities can be deliberately engineered
for reliability, yet may also emerge spontaneously during scaling, potentially
hardening unpredictable goals and behaviors.

</details>


### [278] [Merge and Conquer: Evolutionarily Optimizing AI for 2048](https://arxiv.org/abs/2510.20205)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.AI

TL;DR: 本文研究了在动态环境（2048游戏）中优化AI的进化训练方法。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中优化AI是一个核心的机器学习挑战。本文以2048游戏为例，研究用于优化AI的进化训练方法。

Method: 实现了两种AI系统：一种是双智能体元提示系统（一个“思考者”LLM优化另一个“执行者”LLM的策略），另一种是基于价值函数和蒙特卡洛树搜索的单智能体系统。还尝试了回滚机制。

Result: 单智能体系统取得了显著改进，平均每周期得分增加473.2分，训练周期中得分呈现明显上升趋势（相关性ρ=0.607）。LLM策略也随之进步。双智能体系统改进不大，表明元提示的局限性。

Conclusion: 进化优化技术在提高AI在非确定性环境中的性能方面具有潜力，但元提示方法效果有限。

Abstract: Optimizing artificial intelligence (AI) for dynamic environments remains a
fundamental challenge in machine learning research. In this paper, we examine
evolutionary training methods for optimizing AI to solve the game 2048, a 2D
sliding puzzle. 2048, with its mix of strategic gameplay and stochastic
elements, presents an ideal playground for studying decision-making, long-term
planning, and dynamic adaptation. We implemented two distinct systems: a
two-agent metaprompting system where a "thinker" large language model (LLM)
agent refines gameplay strategies for an "executor" LLM agent, and a
single-agent system based on refining a value function for a limited Monte
Carlo Tree Search. We also experimented with rollback features to avoid
performance degradation. Our results demonstrate the potential of evolutionary
refinement techniques in improving AI performance in non-deterministic
environments. The single-agent system achieved substantial improvements, with
an average increase of 473.2 points per cycle, and with clear upward trends
(correlation $\rho$=0.607) across training cycles. The LLM's understanding of
the game grew as well, shown in its development of increasingly advanced
strategies. Conversely, the two-agent system did not garner much improvement,
highlighting the inherent limits of meta-prompting.

</details>


### [279] [Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods](https://arxiv.org/abs/2510.20252)
*Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao*

Main category: cs.AI

TL;DR: LLMs可以模仿人类的表面行为，但对更深层次的个体认知过程的模拟能力仍不清楚。本研究提出了一项新任务，使用小说数据集和11个条件的认知评估框架来评估7个LLM在作者风格模仿方面的能力。研究发现，结合概念和语言特征比静态的基于配置文件的线索更有效地进行个体认知模拟，并且LLM在模仿语言风格方面比叙事结构更有效。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在模拟更深层次的个体认知过程方面的能力仍不清楚，本研究旨在解决这一差距。

Method: 本研究提出了一个新任务，使用小说数据集和11个条件的认知评估框架来评估7个LLM在作者风格模仿方面的能力，并测试了不同的认知表征方法。

Result: 研究结果表明，将概念特征和语言特征结合起来在个体认知模拟方面特别有效，其整体评估效果优于静态的基于配置文件的线索。此外，LLM在模仿语言风格方面的能力优于叙事结构。

Conclusion: 本研究为开发能够适应个体思维和表达方式的AI系统奠定了基础，从而推动了更具个性化和人类化创意的技术发展。

Abstract: Individualized cognitive simulation (ICS) aims to build computational models
that approximate the thought processes of specific individuals. While large
language models (LLMs) convincingly mimic surface-level human behavior such as
role-play, their ability to simulate deeper individualized cognitive processes
remains poorly understood. To address this gap, we introduce a novel task that
evaluates different cognitive representation methods in ICS. We construct a
dataset from recently published novels (later than the release date of the
tested LLMs) and propose an 11-condition cognitive evaluation framework to
benchmark seven off-the-shelf LLMs in the context of authorial style emulation.
We hypothesize that effective cognitive representations can help LLMs generate
storytelling that better mirrors the original author. Thus, we test different
cognitive representations, e.g., linguistic features, concept mappings, and
profile-based information. Results show that combining conceptual and
linguistic features is particularly effective in ICS, outperforming static
profile-based cues in overall evaluation. Importantly, LLMs are more effective
at mimicking linguistic style than narrative structure, underscoring their
limits in deeper cognitive simulation. These findings provide a foundation for
developing AI systems that adapt to individual ways of thinking and expression,
advancing more personalized and human-aligned creative technologies.

</details>


### [280] [Using Large Language Models for Abstraction of Planning Domains - Extended Version](https://arxiv.org/abs/2510.20258)
*Bita Banihashemi,Megh Patel,Yves Lespérance*

Main category: cs.AI

TL;DR: LLM可用于根据自然语言描述生成抽象PDDL领域，尤其擅长抽象动作而非状态。


<details>
  <summary>Details</summary>
Motivation: 在动态领域中，为特定目的生成与之匹配的抽象表示是一个挑战，因为抽象选择会影响智能体的规划、推理和解释能力。

Method: 使用大型语言模型（LLMs）和上下文学习（in-context learning）来生成抽象的PDDL领域和问题实例，并根据自然语言中的抽象目标进行优化。实验包含了动作选择、动作序列以及动作/谓词参数的抽象，并结合了这些方法。

Result: 实验表明，GPT-4o在简单场景下能够生成有用的规划领域抽象，但在抽象动作方面优于抽象状态（fluents）。

Conclusion: LLM在根据自然语言指令生成抽象PDDL方面具有潜力，但仍需在抽象状态表示方面进行改进。

Abstract: Generating an abstraction of a dynamic domain that aligns with a given
purpose remains a significant challenge given that the choice of such an
abstraction can impact an agent's ability to plan, reason, and provide
explanations effectively. We model the agent's concrete behaviors in PDDL and
investigate the use of in-context learning with large language models (LLMs)
for the generation of abstract PDDL domains and problem instances, given an
abstraction objective specified in natural language. The benchmark examples we
use are new and have not been part of the data any LLMs have been trained on.
We consider three categories of abstractions: abstraction of choice of
alternative concrete actions, abstraction of sequences of concrete actions, and
abstraction of action/predicate parameters, as well as combinations of these.
The generated abstract PDDL domains and problem instances are then checked by
symbolic validation tools as well as human experts. Our experiments show that
GPT-4o can generally synthesize useful planning domain abstractions in simple
settings, although it is better at abstracting over actions than over the
associated fluents.

</details>


### [281] [Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction](https://arxiv.org/abs/2510.20275)
*Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim*

Main category: cs.AI

TL;DR: STaBERT通过融合POI和时间信息来改进人类移动预测，显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能充分利用POI的语义信息，STaBERT旨在解决此问题。

Method: STaBERT在BERT模型的基础上，融入了POI嵌入和时间描述符，以构建统一的、语义丰富的移动表征。

Result: 在单城市预测中，GEO-BLEU分数从0.34提升至0.75；在多城市预测中，从0.34提升至0.56。

Conclusion: STaBERT在人类移动预测方面取得了显著的准确性提升。

Abstract: Human mobility forecasting is crucial for disaster relief, city planning, and
public health. However, existing models either only model location sequences or
include time information merely as auxiliary input, thereby failing to leverage
the rich semantic context provided by points of interest (POIs). To address
this, we enrich a BERT-based mobility model with derived temporal descriptors
and POI embeddings to better capture the semantics underlying human movement.
We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI
and temporal information at each location to construct a unified, semantically
enriched representation of mobility. Experimental results show that STaBERT
significantly improves prediction accuracy: for single-city prediction, the
GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34
to 0.56.

</details>


### [282] [Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation](https://arxiv.org/abs/2510.20310)
*Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia*

Main category: cs.AI

TL;DR: 通过集成外部工具和多步推理，ToolEQA 提高了具身问答（EQA）的准确性和效率，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有EQA方法缺乏明确的思考或规划，导致探索效率低下和响应不准确。本研究旨在通过引入外部工具和多步推理来增强EQA的能力。

Method: 提出ToolEQA，一种集成外部工具和多步推理的智能体。设计了一个新的EQA数据生成流程，用于构建包含推理轨迹的大规模EQA任务数据集EQA-RT，并包含约18K个任务。

Result: ToolEQA在EQA-RT-Seen和EQA-RT-Unseen数据集上，成功率比现有最先进基线提高了9.2%~20.2%，并且比零样本ToolEQA提高了10%的成功率。此外，ToolEQA在HM-EQA、OpenEQA和EXPRESS-Bench数据集上也取得了最先进的性能。

Conclusion: ToolEQA通过整合外部工具和多步推理，显著提高了EQA任务的性能，并在多个基准测试中展现了其通用性和优越性。

Abstract: Embodied Question Answering (EQA) requires agents to explore 3D environments
to obtain observations and answer questions related to the scene. Existing
methods leverage VLMs to directly explore the environment and answer questions
without explicit thinking or planning, which limits their reasoning ability and
results in excessive or inefficient exploration as well as ineffective
responses. In this paper, we introduce ToolEQA, an agent that integrates
external tools with multi-step reasoning, where external tools can provide more
useful information for completing the task, helping the model derive better
exploration directions in the next step of reasoning and thus obtaining
additional effective information. This enables ToolEQA to generate more
accurate responses with a shorter exploration distance. To enhance the model's
ability for tool-usage and multi-step reasoning, we further design a novel EQA
data generation pipeline that automatically constructs large-scale EQA tasks
with reasoning trajectories and corresponding answers. Based on the pipeline,
we collect the EQA-RT dataset that contains about 18K tasks, divided into a
training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping
with the training set) and EQA-RT-Unseen (novel scenes). Experiments on
EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by
9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot
ToolEQA by 10% in success rate. In addition, ToolEQA also achieves
state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench
datasets, demonstrating its generality. Our homepage see
https://tooleqa.github.io.

</details>


### [283] [Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems](https://arxiv.org/abs/2510.20332)
*Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés*

Main category: cs.AI

TL;DR: AI在医疗保健领域潜力巨大，但临床实践整合受阻，主要原因是训练数据质量和公平性不足，常由有偏见的数据收集引起。本研究利用AI4HealthyAging项目经验，识别临床数据收集中的历史、代表性和测量偏见，这些偏见体现在性别、年龄、生活环境、社会经济地位、设备和标签等变量中。我们提出改进临床问题设计和数据收集公平性与鲁棒性的建议，旨在促进未来医疗保健领域更公平的AI系统开发。


<details>
  <summary>Details</summary>
Motivation: AI在医疗保健领域应用前景广阔，但临床实践整合受限，主要障碍是训练数据质量和公平性，这通常源于有偏见的数据收集。本研究旨在识别和解决这些偏见。

Method: 分析AI4HealthyAging项目，识别临床数据收集中的历史、代表性和测量偏见，并考察这些偏见在性别、年龄、生活环境、社会经济地位、设备和标签等变量中的具体表现。

Result: 在多个用例中识别出历史、代表性和测量偏见，这些偏见影响了性别、年龄、生活环境、社会经济地位、设备和标签等变量。

Conclusion: 提出改进临床问题设计和数据收集公平性与鲁棒性的实际建议，以期为未来医疗保健领域更公平的AI系统开发提供指导。

Abstract: Artificial intelligence (AI) holds great promise for transforming healthcare.
However, despite significant advances, the integration of AI solutions into
real-world clinical practice remains limited. A major barrier is the quality
and fairness of training data, which is often compromised by biased data
collection practices. This paper draws on insights from the AI4HealthyAging
project, part of Spain's national R&D initiative, where our task was to detect
biases during clinical data collection. We identify several types of bias
across multiple use cases, including historical, representation, and
measurement biases. These biases manifest in variables such as sex, gender,
age, habitat, socioeconomic status, equipment, and labeling. We conclude with
practical recommendations for improving the fairness and robustness of clinical
problem design and data collection. We hope that our findings and experience
contribute to guiding future projects in the development of fairer AI systems
in healthcare.

</details>


### [284] [Collateral Damage Assessment Model for AI System Target Engagement in Military Operations](https://arxiv.org/abs/2510.20337)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 该模型提出了一种用于评估AI系统在军事行动中交战的附带损害的新方法，该方法整合了时间、空间和力量维度，并采用设计科学方法。


<details>
  <summary>Details</summary>
Motivation: AI系统在战场上的作用日益增强，需要对潜在的附带效应进行严格评估，以确保负责任的交战。

Method: 模型在一个统一的知识表示与推理（KRR）架构中整合了时间、空间和力量维度，并采用了设计科学的方法。其分层结构捕获了待交战的AI系统的类别和架构组件，以及相应的交战向量和背景方面。同时，考虑了扩散、严重性、可能性和评估指标，以提供一个清晰的、由透明的推理机制增强的表示。

Result: 通过实例化对模型进行了演示和评估。

Conclusion: 该模型为进一步致力于构建负责任和可信赖的智能系统，以评估交战AI系统在军事行动中产生的效应奠定了基础。

Abstract: In an era where AI (Artificial Intelligence) systems play an increasing role
in the battlefield, ensuring responsible targeting demands rigorous assessment
of potential collateral effects. In this context, a novel collateral damage
assessment model for target engagement of AI systems in military operations is
introduced. The model integrates temporal, spatial, and force dimensions within
a unified Knowledge Representation and Reasoning (KRR) architecture following a
design science methodological approach. Its layered structure captures the
categories and architectural components of the AI systems to be engaged
together with corresponding engaging vectors and contextual aspects. At the
same time, spreading, severity, likelihood, and evaluation metrics are
considered in order to provide a clear representation enhanced by transparent
reasoning mechanisms. Further, the model is demonstrated and evaluated through
instantiation which serves as a basis for further dedicated efforts that aim at
building responsible and trustworthy intelligent systems for assessing the
effects produced by engaging AI systems in military operations.

</details>


### [285] [LLM-empowered knowledge graph construction: A survey](https://arxiv.org/abs/2510.20345)
*Haonan Bian*

Main category: cs.AI

TL;DR: LLMs正在革新知识图谱的构建，从传统的基于规则和统计的方法转变为语言驱动和生成式的方法。本调查全面回顾了LLM赋能的知识图谱构建的最新进展，分析了LLM如何重塑本体工程、知识提取和知识融合这三个经典层次的流程。


<details>
  <summary>Details</summary>
Motivation: LLMs的出现为知识图谱的构建带来了范式转变，从传统的基于规则和统计的方法转向语言驱动和生成式框架，需要对这一新方法进行系统性梳理和分析。

Method: 本调查系统地分析了LLM如何重塑本体工程、知识提取和知识融合这三个经典层次的流程。它从模式驱动和模式自由两个视角回顾了新兴的LLM驱动方法，并对每个阶段的代表性框架、技术机制及其局限性进行了分析。

Result: LLM驱动的方法在知识图谱的构建中展现出新的能力，但也存在局限性。未来的研究方向包括KG驱动的LLM推理、代理系统的动态知识记忆以及多模态KG构建。

Conclusion: LLM与知识图谱的相互作用正在不断演变，本调查旨在阐明这种演变，促进符号知识工程和神经语义理解之间的融合，以开发自适应、可解释和智能的知识系统。

Abstract: Knowledge Graphs (KGs) have long served as a fundamental infrastructure for
structured knowledge representation and reasoning. With the advent of Large
Language Models (LLMs), the construction of KGs has entered a new
paradigm-shifting from rule-based and statistical pipelines to language-driven
and generative frameworks. This survey provides a comprehensive overview of
recent progress in LLM-empowered knowledge graph construction, systematically
analyzing how LLMs reshape the classical three-layered pipeline of ontology
engineering, knowledge extraction, and knowledge fusion.
  We first revisit traditional KG methodologies to establish conceptual
foundations, and then review emerging LLM-driven approaches from two
complementary perspectives: schema-based paradigms, which emphasize structure,
normalization, and consistency; and schema-free paradigms, which highlight
flexibility, adaptability, and open discovery. Across each stage, we synthesize
representative frameworks, analyze their technical mechanisms, and identify
their limitations.
  Finally, the survey outlines key trends and future research directions,
including KG-based reasoning for LLMs, dynamic knowledge memory for agentic
systems, and multimodal KG construction. Through this systematic review, we aim
to clarify the evolving interplay between LLMs and knowledge graphs, bridging
symbolic knowledge engineering and neural semantic understanding toward the
development of adaptive, explainable, and intelligent knowledge systems.

</details>


### [286] [IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation](https://arxiv.org/abs/2510.20377)
*Tianyi Zhang,Florian Mai,Lucie Flek*

Main category: cs.AI

TL;DR: 该研究提出了一种名为IKnow的持续学习框架，用于在不损害模型指令遵循能力和语义表征的情况下，仅使用无标签的测试数据来使大型语言模型适应新领域。


<details>
  <summary>Details</summary>
Motivation: 现有的持续预训练方法在适应新领域时，要么需要原始基础模型，要么依赖外部数据库，这在模型权重保密或缺乏可靠外部语料库的情况下存在现实障碍。

Method: IKnow框架提出了一种新颖的基于指令-响应对话格式的自监督目标，它利用文本中嵌入的领域知识，并学习在更深层次的语义层面进行编码，而无需访问外部资源。

Result: IKnow框架成功地在不损害模型指令遵循能力和语义表征的情况下，仅使用无标签的测试数据来使大型语言模型适应新领域。

Conclusion: IKnow框架是一种简单且通用的持续学习方法，它通过利用文本内在的领域知识来克服现有方法的局限性，为在实际场景中适应大型语言模型提供了新的解决方案。

Abstract: Continual pretraining promises to adapt large language models (LLMs) to new
domains using only unlabeled test-time data, but naively applying standard
self-supervised objectives to instruction-tuned models is known to degrade
their instruction-following capability and semantic representations. Existing
fixes assume access to the original base model or rely on knowledge from an
external domain-specific database - both of which pose a realistic barrier in
settings where the base model weights are withheld for safety reasons or
reliable external corpora are unavailable. In this work, we propose
Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general
framework that formulates novel self-supervised objectives in the
instruction-response dialogue format. Rather than depend- ing on external
resources, IKnow leverages domain knowledge embedded within the text itself and
learns to encode it at a deeper semantic level.

</details>


### [287] [A computational model and tool for generating more novel opportunities in professional innovation processes](https://arxiv.org/abs/2510.20402)
*Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown*

Main category: cs.AI

TL;DR: 该计算模型旨在通过五个功能生成新颖且实用的创新机会，并在酒店业的创新项目中进行了评估。


<details>
  <summary>Details</summary>
Motivation: 需要一个计算模型来生成更具新颖性的创新项目机会，同时保持其实用性。

Method: 开发并实现了一个包含五个功能的计算模型，以生成新颖的创新机会。

Result: 与Notebook LM和ChatGPT4o相比，该模型生成的创新机会在新颖性和/或实用性方面表现更优。然而，并非所有模型功能都对新颖性做出了贡献。

Conclusion: 该计算模型在生成新颖的创新机会方面显示出潜力，但需要进一步开发以优化其功能。

Abstract: This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

</details>


### [288] [Neural Reasoning for Robust Instance Retrieval in $\mathcal{SHOIQ}$](https://arxiv.org/abs/2510.20457)
*Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo*

Main category: cs.AI

TL;DR:  EBR是一种新的神经推理器，它使用嵌入来近似符号推理器的结果，以克服现有神经符号概念学习方法在处理不一致或错误数据方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号概念学习方法在处理不一致或错误数据方面存在局限性，这阻碍了它们在真实的知识库上的部署。EBR旨在解决这一挑战。

Method: EBR是一种新的神经推理器，它依赖嵌入来近似符号推理器的结果。它仅需要检索原子概念和存在限制的实例，就可以检索或近似$\	ext{SHOIQ}$中任何概念的实例集。

Result: 与最先进的推理器相比，EBR在实验中显示出对缺失和错误数据的鲁棒性。

Conclusion: EBR通过使用嵌入来近似符号推理，克服了现有神经符号概念学习方法的局限性，并能有效处理不一致或错误的数据。

Abstract: Concept learning exploits background knowledge in the form of description
logic axioms to learn explainable classification models from knowledge bases.
Despite recent breakthroughs in neuro-symbolic concept learning, most
approaches still cannot be deployed on real-world knowledge bases. This is due
to their use of description logic reasoners, which are not robust against
inconsistencies nor erroneous data. We address this challenge by presenting a
novel neural reasoner dubbed EBR. Our reasoner relies on embeddings to
approximate the results of a symbolic reasoner. We show that EBR solely
requires retrieving instances for atomic concepts and existential restrictions
to retrieve or approximate the set of instances of any concept in the
description logic $\mathcal{SHOIQ}$. In our experiments, we compare EBR with
state-of-the-art reasoners. Our results suggest that EBR is robust against
missing and erroneous data in contrast to existing reasoners.

</details>


### [289] [FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic](https://arxiv.org/abs/2510.20467)
*Yiwen Peng,Thomas Bonald,Fabian M. Suchanek*

Main category: cs.AI

TL;DR: FLORA是一个无监督、可解释的知识图谱对齐方法，能够同时对齐实体和关系，并达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱对齐方法多为纯实体级别，缺乏可解释性且需要训练数据。FLORA旨在解决这些问题。

Method: FLORA是一种基于模糊逻辑的无监督方法，能够迭代地对齐实体和关系，并允许悬空实体。

Result: FLORA在主要基准测试中取得了最先进的结果。

Conclusion: FLORA是一种简单有效的方法，解决了现有知识图谱对齐方法的局限性，并取得了优异的性能。

Abstract: Knowledge graph alignment is the task of matching equivalent entities (that
is, instances and classes) and relations across two knowledge graphs. Most
existing methods focus on pure entity-level alignment, computing the similarity
of entities in some embedding space. They lack interpretable reasoning and need
training data to work. In this paper, we propose FLORA, a simple yet effective
method that (1) is unsupervised, i.e., does not require training data, (2)
provides a holistic alignment for entities and relations iteratively, (3) is
based on fuzzy logic and thus delivers interpretable results, (4) provably
converges, (5) allows dangling entities, i.e., entities without a counterpart
in the other KG, and (6) achieves state-of-the-art results on major benchmarks.

</details>


### [290] [Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI](https://arxiv.org/abs/2510.20568)
*Susan Ariel Aaronson,Michael Moreno*

Main category: cs.AI

TL;DR: 在三个国家（澳大利亚、哥伦比亚和美国）的 AI 治理公共意见征询中，公民参与度低，政府对意见的响应不足，导致信任和合法性缺失。


<details>
  <summary>Details</summary>
Motivation: 为了解各国政府在制定人工智能（AI）政策时，如何采纳公众意见，以及如何建立公众信任。

Method: 通过对澳大利亚、哥伦比亚和美国三国政府征询公众对 AI 风险和政策意见的过程进行分析，研究反馈意见如何影响治理。

Result: 在所研究的三国中，公民与决策者之间未能建立有意义的对话。政府在征集意见时，对多元化声音的吸引和宣传力度不足，导致公众参与率极低（不到1%）。此外，政府对收到的反馈响应有限，未能形成有效的反馈闭环。

Conclusion: 目前的 AI 治理模式未能有效弥合承诺与实践之间的差距，也无法在公众中建立信任或合法性，因为决策者未能充分倾听和回应公众关切。为改善此状况，提出八项建议，包括：提升 AI 素养、监测公众反馈、拓宽宣传渠道、举办定期线上论坛、采用创新参与方式、吸纳弱势群体、公开回应意见以及简化参与流程。

Abstract: The worlds people have strong opinions about artificial intelligence (AI),
and they want policymakers to listen. Governments are inviting public comment
on AI, but as they translate input into policy, much of what citizens say is
lost. Policymakers are missing a critical opportunity to build trust in AI and
its governance. This paper compares three countries, Australia, Colombia, and
the United States, that invited citizens to comment on AI risks and policies.
Using a landscape analysis, the authors examined how each government solicited
feedback and whether that input shaped governance. Yet in none of the three
cases did citizens and policymakers establish a meaningful dialogue.
Governments did little to attract diverse voices or publicize calls for
comment, leaving most citizens unaware or unprepared to respond. In each
nation, fewer than one percent of the population participated. Moreover,
officials showed limited responsiveness to the feedback they received, failing
to create an effective feedback loop. The study finds a persistent gap between
the promise and practice of participatory AI governance. The authors conclude
that current approaches are unlikely to build trust or legitimacy in AI because
policymakers are not adequately listening or responding to public concerns.
They offer eight recommendations: promote AI literacy; monitor public feedback;
broaden outreach; hold regular online forums; use innovative engagement
methods; include underrepresented groups; respond publicly to input; and make
participation easier.

</details>


### [291] [Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting](https://arxiv.org/abs/2510.20591)
*Ali Rajaei,Peter Palensky,Jochen L. Cremer*

Main category: cs.AI

TL;DR: GNN-accelerated approach for network topology optimization (NTO) through busbar splitting to mitigate transmission grid congestion and reduce redispatch costs, achieving significant speed-up and generalization.


<details>
  <summary>Details</summary>
Motivation: Mitigating transmission grid congestion and reducing redispatch costs through network topology optimization (NTO) via busbar splitting, which is currently intractable for large-scale systems in near-real-time using existing solvers and has limited generalization in existing ML approaches.

Method: Formulating NTO for congestion management considering linearized AC PF and proposing a graph neural network (GNN)-accelerated approach using a heterogeneous edge-aware message passing NN to predict effective busbar splitting actions.

Result: The proposed GNN captures local flow patterns, generalizes to unseen topology changes, and improves transferability across systems. Case studies show up to 4 orders-of-magnitude speed-up, delivering AC-feasible solutions within one minute and a 2.3% optimality gap on the GOC 2000-bus system.

Conclusion: The GNN-accelerated approach represents a significant step toward near-real-time NTO for large-scale systems with topology and cross-system generalization.

Abstract: Network topology optimization (NTO) via busbar splitting can mitigate
transmission grid congestion and reduce redispatch costs. However, solving this
mixed-integer non-linear problem for large-scale systems in near-real-time is
currently intractable with existing solvers. Machine learning (ML) approaches
have emerged as a promising alternative, but they have limited generalization
to unseen topologies, varying operating conditions, and different systems,
which limits their practical applicability. This paper formulates NTO for
congestion management problem considering linearized AC PF, and proposes a
graph neural network (GNN)-accelerated approach. We develop a heterogeneous
edge-aware message passing NN to predict effective busbar splitting actions as
candidate NTO solutions. The proposed GNN captures local flow patterns,
achieves generalization to unseen topology changes, and improves
transferability across systems. Case studies show up to 4 orders-of-magnitude
speed-up, delivering AC-feasible solutions within one minute and a 2.3%
optimality gap on the GOC 2000-bus system. These results demonstrate a
significant step toward near-real-time NTO for large-scale systems with
topology and cross-system generalization.

</details>


### [292] [What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation](https://arxiv.org/abs/2510.20603)
*Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun*

Main category: cs.AI

TL;DR: LLM 评估应超越最终答案的正确性，关注推理过程的质量。通过因果逐步评估 (CaSE) 衡量推理的相关性和连贯性，可用于改进模型训练和最终任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前的 LLM 评估范式主要关注最终答案的正确性，但这种方法提供的模型改进信号粗略，并且忽略了底层推理过程的质量。更细致的评估推理过程能更有效地构建鲁棒模型。

Method: 提出因果逐步评估 (CaSE) 方法，将推理质量分解为相关性和连贯性两个维度。相关性衡量一个推理步骤是否基于问题本身，连贯性衡量该步骤是否从先前的步骤逻辑上推导而来。CaSE 评估的依据仅限于每个推理步骤之前的上下文，以避免事后诸葛亮偏见。

Result: 在 MRa-GSM8K 和 MRa-MATH 基准上，CaSE 评估与人类判断一致。使用 CaSE 评估的相关性和连贯性来整理训练数据，能够直接提升最终任务的表现。

Conclusion: CaSE 提供了一个可扩展的框架，用于分析、调试和改进 LLM 的推理能力，证明了超越最终答案正确性检查的实际价值。

Abstract: Evaluating large language models (LLMs) on final-answer correctness is the
dominant paradigm. This approach, however, provides a coarse signal for model
improvement and overlooks the quality of the underlying reasoning process. We
argue that a more granular evaluation of reasoning offers a more effective path
to building robust models. We decompose reasoning quality into two dimensions:
relevance and coherence. Relevance measures if a step is grounded in the
problem; coherence measures if it follows logically from prior steps. To
measure these aspects reliably, we introduce causal stepwise evaluation (CaSE).
This method assesses each reasoning step using only its preceding context,
which avoids hindsight bias. We validate CaSE against human judgments on our
new expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we
show that curating training data with CaSE-evaluated relevance and coherence
directly improves final task performance. Our work provides a scalable
framework for analyzing, debugging, and improving LLM reasoning, demonstrating
the practical value of moving beyond validity checks.

</details>


### [293] [Efficient Algorithms for Computing Random Walk Centrality](https://arxiv.org/abs/2510.20604)
*Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang*

Main category: cs.AI

TL;DR: 随机游走中心度计算在大型网络上效率低下，本文提出两种可扩展算法，一种使用近似乔列斯基分解和稀疏逆估计，另一种使用根生成树采样，两者均接近线性时间并提供近似保证。


<details>
  <summary>Details</summary>
Motivation: 随机游走中心度虽然能捕捉丰富的图结构信息且应用广泛，但现有方法在大型网络上的计算成本过高，不切实际。

Method: 提出一种新的随机游走中心度计算方法，并基于此开发了两种可扩展算法：一种利用近似乔列斯基分解和稀疏逆估计，另一种通过采样根生成树进行计算。这两种算法的时间复杂度接近线性，并提供严格的近似保证。

Result: 所提出的算法在包含千万节点的大型真实网络上的实验表明，其效率和近似质量都表现优异。

Conclusion: 本文提出的随机游走中心度计算方法及其两种可扩展算法，有效解决了在大规模网络上计算该度量的挑战，实现了高效率和高质量的近似计算。

Abstract: Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

</details>


### [294] [Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms](https://arxiv.org/abs/2510.20621)
*Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato*

Main category: cs.AI

TL;DR: MIMOSA是一个用于生成可解释的、平衡性能和包含关键伦理属性（因果关系、公平性和隐私性）的预测模型的框架。


<details>
  <summary>Details</summary>
Motivation: 为了在现实世界的应用中建立对自动化决策模型的信任、问责制和安全采用，需要可解释的设计模型。

Method: 该研究正式定义了MIMOSA框架，该框架包括监督学习设置，涵盖了表格数据、时间序列、图像、文本、交易和轨迹等多种决策任务和数据类型。它对特征重要性、规则和基于实例的模型这三大类可解释模型进行了分类，并分析了它们的解释维度、推理机制和复杂性。此外，该研究还正式定义了因果关系、公平性和隐私性这三个关键的伦理属性，并提供了相应的评估指标和验证程序。最后，研究探讨了这些属性之间的内在权衡，并讨论了如何在可解释的流程中嵌入隐私要求、公平性约束和因果推理。

Result: MIMOSA框架通过在模型生成过程中评估伦理指标，为开发不仅准确、可解释，而且公平、保护隐私且具有因果意识（即值得信赖）的AI系统奠定了理论基础。

Conclusion: MIMOSA框架为构建准确、可解释、公平、保护隐私且符合因果关系的AI系统提供了理论基础，旨在提高AI系统的可信度。

Abstract: Interpretable-by-design models are crucial for fostering trust,
accountability, and safe adoption of automated decision-making models in
real-world applications. In this paper we formalize the ground for the MIMOSA
(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a
comprehensive methodology for generating predictive models that balance
interpretability with performance while embedding key ethical properties. We
formally define here the supervised learning setting across diverse
decision-making tasks and data types, including tabular data, time series,
images, text, transactions, and trajectories. We characterize three major
families of interpretable models: feature importance, rule, and instance based
models. For each family, we analyze their interpretability dimensions,
reasoning mechanisms, and complexity. Beyond interpretability, we formalize
three critical ethical properties, namely causality, fairness, and privacy,
providing formal definitions, evaluation metrics, and verification procedures
for each. We then examine the inherent trade-offs between these properties and
discuss how privacy requirements, fairness constraints, and causal reasoning
can be embedded within interpretable pipelines. By evaluating ethical measures
during model generation, this framework establishes the theoretical foundations
for developing AI systems that are not only accurate and interpretable but also
fair, privacy-preserving, and causally aware, i.e., trustworthy.

</details>


### [295] [Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](https://arxiv.org/abs/2510.20632)
*Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng*

Main category: cs.AI

TL;DR: EcomEval是一个多语言、多模态的电商LLM评估基准，包含6类37个任务（8个多模态），数据来源于真实客户查询和交易记录，并经过专家标注。该基准支持7种语言（含5种东南亚低资源语言），并定义了难度级别，以解决现有电商LLM评估工具的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有电商LLM评估基准在任务多样性、模态、数据来源和语言覆盖方面存在不足，无法满足复杂、真实的购物场景评估需求。

Method: 构建了一个包含6类37个任务（8个多模态）的EcomEval基准，数据来源于真实客户查询和交易日志，采用半自动流水线生成和专家标注参考答案，并根据模型在基准上的表现定义了难度级别。

Result: EcomEval涵盖了更广泛的电商场景，包括产品指导和售后问题，支持多模态数据，并扩展到七种语言（包括五种低资源语言），提供了比以往更全面、更细粒度的LLM评估。

Conclusion: EcomEval作为一个全面、多语言、多模态的电商LLM评估基准，弥补了现有评估工具的不足，为评估和改进LLM在真实电商场景中的能力提供了可靠的工具。

Abstract: Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet
their capabilities in specialized domains remain underexplored. In e-commerce,
existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping
MMLU-suffer from limited task diversity (e.g., lacking product guidance and
after-sales issues), limited task modalities (e.g., absence of multimodal
data), synthetic or curated data, and a narrow focus on English and Chinese,
leaving practitioners without reliable tools to assess models on complex,
real-world shopping scenarios. We introduce EcomEval, a comprehensive
multilingual and multimodal benchmark for evaluating LLMs in e-commerce.
EcomEval covers six categories and 37 tasks (including 8 multimodal tasks),
sourced primarily from authentic customer queries and transaction logs,
reflecting the noisy and heterogeneous nature of real business interactions. To
ensure both quality and scalability of reference answers, we adopt a
semi-automatic pipeline in which large models draft candidate responses
subsequently reviewed and modified by over 50 expert annotators with strong
e-commerce and multilingual expertise. We define difficulty levels for each
question and task category by averaging evaluation scores across models with
different sizes and capabilities, enabling challenge-oriented and fine-grained
assessment. EcomEval also spans seven languages-including five low-resource
Southeast Asian languages-offering a multilingual perspective absent from prior
work.

</details>


### [296] [Fluidity Index: Next-Generation Super-intelligence Benchmarks](https://arxiv.org/abs/2510.20636)
*Eric Ngoiya,Tianshu Bao*

Main category: cs.AI

TL;DR: 本文提出流体性指数（FI）来量化模型在动态、可扩展环境中的适应性，并通过评估模型在不同环境状态下的响应准确性来衡量其上下文切换和连续性能力。我们区分了封闭式和开放式基准测试，并优先考虑闭环开放式真实世界基准测试，以测试适应性。该方法测量模型在可扩展环境中理解、预测和调整状态变化的能力。真正的超智能模型应至少表现出二阶适应性，能够通过数字补充实现自我维持计算以获得最佳流体性。


<details>
  <summary>Details</summary>
Motivation: 评估模型在动态、可扩展环境中的适应性，并提出流体性指数（FI）作为量化指标。

Method: 引入流体性指数（FI），通过评估模型在初始、当前和未来环境状态下的响应准确性来衡量其适应性。区分封闭式和开放式基准测试，并优先考虑闭环开放式真实世界基准测试。

Result: FI能够量化模型在动态、可扩展环境中的适应性。

Conclusion: 真正的超智能模型应具备二阶适应性，能够通过数字补充实现自我维持计算以获得最佳流体性。

Abstract: This paper introduces the Fluidity Index (FI) to quantify model adaptability
in dynamic, scaling environments. The benchmark evaluates response accuracy
based on deviations in initial, current, and future environment states,
assessing context switching and continuity. We distinguish between closed-ended
and open-ended benchmarks, prioritizing closed-loop open-ended real-world
benchmarks to test adaptability. The approach measures a model's ability to
understand, predict, and adjust to state changes in scaling environments. A
truly super-intelligent model should exhibit at least second-order
adaptability, enabling self-sustained computation through digital replenishment
for optimal fluidity.

</details>


### [297] [Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges](https://arxiv.org/abs/2510.20641)
*Andrea Agiollo,Andrea Omicini*

Main category: cs.AI

TL;DR: 研究者们分析了机器学习模型与理性智能体架构的结合，特别是以信念-欲望-意图（BDI）模型为参照。


<details>
  <summary>Details</summary>
Motivation: 现有的将机器学习（ML）集成到理性智能体架构中的方法比较分散，并且往往只关注将ML嵌入通用的智能体容器中，而忽视了像信念-欲望-意图（BDI）智能体这样的理性架构所具有的表达能力。

Method: 通过以BDI范式为参考，对现有方法进行细致的系统化分析。

Result: 研究表明，在ML增强的理性智能体领域，文献发展迅速，并且明确了设计有效的理性ML智能体的关键研究机会和尚待解决的挑战。

Conclusion: 需要进一步研究以设计出有效的理性ML智能体。

Abstract: Thanks to the remarkable human-like capabilities of machine learning (ML)
models in perceptual and cognitive tasks, frameworks integrating ML within
rational agent architectures are gaining traction. Yet, the landscape remains
fragmented and incoherent, often focusing on embedding ML into generic agent
containers while overlooking the expressive power of rational
architectures--such as Belief-Desire-Intention (BDI) agents. This paper
presents a fine-grained systematisation of existing approaches, using the BDI
paradigm as a reference. Our analysis illustrates the fast-evolving literature
on rational agents enhanced by ML, and identifies key research opportunities
and open challenges for designing effective rational ML agents.

</details>


### [298] [The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models](https://arxiv.org/abs/2510.20665)
*Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok*

Main category: cs.AI

TL;DR: 使用拓扑数据分析（TDA）的评估框架，能够对大型语言模型（LLM）的推理过程进行自动化、高效率和可靠的质量评估，其效果优于现有的基于图的指标。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的推理过程的质量，目前的方法存在不足，如耗时、不可靠、依赖专家评审等，基于图的评估方法过于简化，无法准确捕捉推理过程的复杂性。

Method: 提出一个基于拓扑数据分析（TDA）的评估框架，该框架能够捕捉推理过程的几何形状，实现高效、自动化的评估。

Result: 与传统的图指标相比，拓扑特征在评估推理质量方面具有更高的预测能力。研究表明，有效的推理过程可以通过更高维度的几何结构来更好地捕捉，而不是仅仅依赖于关系图。此外，一小组稳定且紧凑的拓扑特征能够可靠地指示推理过程的质量。

Conclusion: 基于TDA的评估框架能够为未来的强化学习算法提供一个实用的信号，以更好地评估和优化LLM的推理能力。

Abstract: Evaluating the quality of reasoning traces from large language models remains
understudied, labor-intensive, and unreliable: current practice relies on
expert rubrics, manual annotation, and slow pairwise judgments. Automated
efforts are dominated by graph-based proxies that quantify structural
connectivity but do not clarify what constitutes high-quality reasoning; such
abstractions can be overly simplistic for inherently complex processes. We
introduce a topological data analysis (TDA)-based evaluation framework that
captures the geometry of reasoning traces and enables label-efficient,
automated assessment. In our empirical study, topological features yield
substantially higher predictive power for assessing reasoning quality than
standard graph metrics, suggesting that effective reasoning is better captured
by higher-dimensional geometric structures rather than purely relational
graphs. We further show that a compact, stable set of topological features
reliably indicates trace quality, offering a practical signal for future
reinforcement learning algorithms.

</details>


### [299] [Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2510.20691)
*Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan*

Main category: cs.AI

TL;DR: 该研究提出了Graph-RFT，一个用于知识图谱问答（KGQA）的框架，通过结合图谱和网络搜索，并采用自主规划和自适应检索调度，以解决现有方法在处理不完整知识和复杂推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA方法难以充分利用知识图谱的丰富知识和大型语言模型的推理能力，尤其是在复杂场景下，它们通常假设知识图谱覆盖完全，缺乏判断何时需要外部信息的机制，并且推理过程缺乏连贯的多步规划能力，导致即使存在相关知识也可能推理失败。

Method: 提出Graph-RFT框架，采用两阶段强化微调方法，结合‘plan-KGsearch-and-Websearch-during-think’范式。该框架包含：1. 链式思考微调方法，使用定制的计划-检索数据集来激活结构化推理并解决GRPO冷启动问题。2. 计划-检索引导的强化学习过程，将显式规划和检索动作与多奖励设计相结合，实现覆盖感知检索调度。3. 笛卡尔式规划模块，将复杂问题分解为有序子问题。4. 逻辑表达式指导工具调用，实现全局一致的多步推理。5. 通过结合结果和检索特定信号的多奖励来优化推理检索过程，使模型学会何时以及如何有效地结合知识图谱和网络检索。

Result: Graph-RFT框架能够进行自主规划和自适应检索调度，处理不完整知识条件下的KGQA任务，并实现全局一致的多步推理。

Conclusion: Graph-RFT通过其新颖的框架和方法，能够有效解决现有KGQA方法在不完整知识和复杂推理方面的挑战，实现更优的问答性能。

Abstract: Knowledge Graph Question Answering aims to answer natural language questions
by reasoning over structured knowledge graphs. While large language models have
advanced KGQA through their strong reasoning capabilities, existing methods
continue to struggle to fully exploit both the rich knowledge encoded in KGs
and the reasoning capabilities of LLMs, particularly in complex scenarios. They
often assume complete KG coverage and lack mechanisms to judge when external
information is needed, and their reasoning remains locally myopic, failing to
maintain coherent multi-step planning, leading to reasoning failures even when
relevant knowledge exists. We propose Graph-RFT, a novel two-stage
reinforcement fine-tuning KGQA framework with a
'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to
perform autonomous planning and adaptive retrieval scheduling across KG and web
sources under incomplete knowledge conditions. Graph-RFT introduces a
chain-of-thought fine-tuning method with a customized plan-retrieval dataset
activates structured reasoning and resolves the GRPO cold-start problem. It
then introduces a novel plan-retrieval guided reinforcement learning process
integrates explicit planning and retrieval actions with a multi-reward design,
enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired
planning module to decompose complex questions into ordered subquestions, and
logical expression to guide tool invocation for globally consistent multi-step
reasoning. This reasoning retrieval process is optimized with a multi-reward
combining outcome and retrieval specific signals, enabling the model to learn
when and how to combine KG and web retrieval effectively.

</details>


### [300] [A Coherence-Based Measure of AGI](https://arxiv.org/abs/2510.20784)
*Fares Fourati*

Main category: cs.AI

TL;DR: AGI 的新定义通过积分广义均值来衡量跨领域能力，并考虑了补偿性，发现了 GPT-4 和 GPT-5 距离真正的通用智能还有很大差距。


<details>
  <summary>Details</summary>
Motivation: 现有的 AGI 定义（算术平均值）过于强调补偿性，可能无法准确反映真正的通用智能，真正的智能应该在所有关键领域都具备均衡的能力。

Method: 提出了一种基于积分广义均值的相干性感知 AGI 衡量标准，该标准涵盖了算术、几何和调和平均数，并通过计算“曲线下面积”（AUC）来量化在不同补偿性假设下的鲁棒性。

Result: 将该方法应用于 GPT-4 和 GPT-5 的 CHC 领域得分，发现它们的相干性调整后 AUC 值表明，尽管算术平均得分很高（例如 GPT-5 为 24%），但它们距离真正的通用智能还有很大差距。

Conclusion: 积分广义均值提供了一个更原则性、可解释且更严格的 AGI 衡量基础，能够更好地捕捉跨领域依赖性和惩罚不平衡性，从而更准确地衡量通用智能的进展。

Abstract: Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

</details>


### [301] [Real Deep Research for AI, Robotics and Beyond](https://arxiv.org/abs/2510.20809)
*Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang*

Main category: cs.AI

TL;DR: AI和机器人领域的研究论文数量激增，给研究人员带来巨大挑战。本文提出Real Deep Research (RDR)框架，用于系统分析研究领域，识别趋势，发现跨领域机会，并提供新研究的切入点。该框架应用于AI和机器人领域，特别关注基础模型和机器人技术，并扩展到其他科学领域。


<details>
  <summary>Details</summary>
Motivation: AI和机器人领域的研究论文数量逐年激增（每年超过10,000篇），导致研究人员难以跟上最新进展，新兴趋势、跨学科合作以及探索新领域的需求都加剧了这一挑战。

Method: 提出一个通用的分析流程（pipeline），用于系统性地分析任何研究领域，具体包括识别新兴趋势、揭示跨领域合作机会以及提供具体的新研究方向。在AI和机器人领域进行了实例应用，重点关注了基础模型和机器人技术的进展，并简要扩展到其他科学领域。RDR框架的构建在主论文中详细介绍，广泛的结果则在附录中提供。

Result: RDR框架被应用于AI和机器人领域，特别关注了基础模型和机器人技术的进展，并简要扩展到其他科学领域。详细的结果在附录中提供。

Conclusion: RDR框架能够帮助AI及其他领域的研究人员更好地了解研究现状，识别新兴趋势和跨领域机会，从而为新的研究提供方向。

Abstract: With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [302] [Building Network Digital Twins Part II: Real-Time Adaptive PID for Enhanced State Synchronization](https://arxiv.org/abs/2510.20753)
*John Sengendo,Fabrizio Granelli*

Main category: cs.ET

TL;DR: 本研究提出了一种改进的网络数字孪生（NDT）框架，使用自适应PID控制器来提高与物理网络的实时同步性，并通过用户界面展示了改进的流量同步效果。


<details>
  <summary>Details</summary>
Motivation: 随着移动网络的日益动态化和异构化，实时同步网络数字孪生（NDT）面临挑战，需要开发自适应机制来解决此问题。

Method: 实现了一个集成自适应比例-积分-微分（PID）控制器的框架，以动态改进同步性，并提供了一个用户界面来展示结果。

Result: 研究结果表明，所提出的改进方法在实时流量同步方面取得了更好的效果。

Conclusion: 通过集成自适应PID控制器，可以有效提高网络数字孪生与物理网络的实时同步性，并能通过用户界面直观地展示改进效果。

Abstract: As we evolve towards more heterogeneous and cutting-edge mobile networks,
Network Digital Twins (NDTs) are proving to be a promising paradigm in solving
challenges faced by network operators, as they give a possibility of
replicating the physical network operations and testing scenarios separately
without interfering with the live network. However, with mobile networks
becoming increasingly dynamic and heterogeneous due to massive device
connectivity, replicating traffic and having NDTs synchronized in real-time
with the physical network remains a challenge, thus necessitating the need to
develop real-time adaptive mechanisms to bridge this gap. In this part II of
our work, we implement a novel framework that integrates an adaptive
Proportional-Integral-Derivative (PID) controller to dynamically improve
synchronization. Additionally, through an interactive user interface, results
of our enhanced approach demonstrate an improvement in real-time traffic
synchronization.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [303] [A unified picture of phonon anomalies in crystals and glasses](https://arxiv.org/abs/2510.19891)
*Alessio Zaccone*

Main category: cond-mat.mtrl-sci

TL;DR: Phonon spectra anomalies in crystals and glasses, like van Hove singularity and boson peak, share a common origin explained by a resonant-damping model that unifies these features.


<details>
  <summary>Details</summary>
Motivation: The paper aims to unify the understanding of phonon spectra anomalies, specifically the van Hove singularity in crystals and the boson peak in glasses, which have traditionally been viewed as distinct phenomena.

Method: The authors propose a resonant-damping model that connects phonon damping to vibrational softening to explain the emergence of van Hove peaks, boson peaks, or both in different materials.

Result: The resonant-damping model successfully explains why some materials exhibit van Hove peaks, others boson peaks, and many display both, extending previous theories and connecting to microscopic mechanisms like nonaffine motions in glasses.

Conclusion: The resonant-damping paradigm offers a unified framework for understanding vibrational anomalies in both ordered and disordered solids, representing a significant step forward in condensed matter physics.

Abstract: Phonon spectra in solids often display anomalies that defy the simple Debye
law, most prominently the van Hove singularity in crystals and the boson peak
in glasses. Although traditionally regarded as distinct, both features are
increasingly recognized as sharing a common physical origin. In a recent work,
G. Ding et al. (Nat. Phys. 2025) propose a resonant-damping model that unifies
these anomalies within a single framework. By coupling phonon damping to
vibrational softening, their theory explains why some materials exhibit van
Hove peaks, others boson peaks, and many show both. This advance extends
earlier ideas and theories of Baggioli and Zaccone on the competition between
phonon propagation and damping, while also connecting to microscopic mechanisms
such as nonaffine motions in glasses. The resonant-damping paradigm thus offers
a promising step toward a unified understanding of vibrational anomalies across
ordered and disordered solids.

</details>


### [304] [Good Enough is Better: Feasibility vs. Pareto-Optimality in Alloy Design](https://arxiv.org/abs/2510.20125)
*Cayden Maguire,Christofer Hardcastle,Trevor Hastings,Raymundo Arróyave,Brent Vela*

Main category: cond-mat.mtrl-sci

TL;DR: 在合金设计中，约束满足框架比基于优化的方法更有可能找到可行的合金，并更早地找到第一个可行的合金解决方案。


<details>
  <summary>Details</summary>
Motivation: 合金设计中的帕累托最优解不一定满足所有最低性能阈值，因此需要一个替代方法来处理约束满足问题。

Method: 将合金设计视为一个约束满足问题，并将其与基于优化的方法进行了基准测试。

Result: 约束满足框架在现实的合金设计活动中，找到可行合金的可能性更高，并且比优化方法更早地找到第一个可行合金解决方案。

Conclusion: 在材料发现中，尤其是在约束性强的应用中，关注可行性而不是最优性可以带来更可行的结果。

Abstract: In alloy design, the search for candidate materials is often framed as an
optimization problem, with the goal of identifying Pareto-optimal solutions
across multiple objectives. However, Pareto-optimal solutions do not
necessarily satisfy all minimum performance thresholds required for practical
deployment. An alternative approach is to treat alloy design as a constraint
satisfaction problem, in which the goal is to identify any solution that meets
all bare minimum requirements across multiple quantities of interest. These
approaches have yet to be benchmarked against each other in the context of
realistic alloy design problems. In this work, we demonstrate that, in
realistic alloy design campaigns involving multiple objectives and constraints,
the constraint satisfaction framework yields a higher likelihood of finding
viable alloys than optimization-based approaches. Furthermore,
constraint-satisfaction approaches find the first viable alloy solutions
earlier than optimization. Our results suggest that focusing on feasibility
rather than optimality can lead to more actionable outcomes in materials
discovery, particularly in highly constrained applications.

</details>


### [305] [Domain wall induced topological Hall effect in the chiral-lattice ferromagnet Fe$_x$TaS$_2$](https://arxiv.org/abs/2510.20181)
*Sk Jamaluddin,Warit Nisaiyok,Yu Zhang,Hari Bhandari,Brian A. Francisco,Peter E. Siegfried,Fehmi Sami Yasin,Tianyi Wang,Abhijeet Nayak,Mohamed El Gazzah,Resham Babu Regmi,June Ho Yeo,Liuyan Zhao,J. F. Mitchell,Yong-Tao Cui,Nirmal J. Ghimire*

Main category: cond-mat.mtrl-sci

TL;DR: Fe掺杂的TaS2材料在不同掺杂水平下展现出可调的大型拓扑霍尔效应，该效应由畴壁驱动，并通过磁力显微镜证实。


<details>
  <summary>Details</summary>
Motivation: 设计具有强鲁棒性且独特性电响应的自旋结构在拓扑量子态和自旋电子学领域仍面临挑战。

Method: 通过系统性地改变Fe的掺杂水平来精确控制磁性地基态，进而调控拓扑霍尔效应。利用实空间磁力显微镜直接观察。

Result: 在FexTaS2系列材料中观察到畴壁驱动的大型且可调的拓扑霍尔效应，并证实了其微观起源。

Conclusion: 研究展示了一种调控层状磁性材料中磁畴拓扑结构以产生显著电磁响应的有前景的方法。

Abstract: Magnetic topology and its associated emergent phenomena are central to
realizing intriguing quantum states and spintronics functionalities. Designing
spin textures to achieve strong and distinct electrical responses remains a
significant challenge. Layered transition metal dichalcogenides offer a
versatile platform for tailoring structural and magnetic properties, enabling
access to a wide spectrum of topological magnetic states. Here, we report a
domain-wall-driven, large, and tunable topological Hall effect (THE) in a
non-centrosymmetric intercalated transition metal dichalcogenides series
Fe$_x$TaS$_2$. By systematically varying the Fe intercalation level, we exert
precise control over the magnetic ground states, allowing manipulation of the
topological Hall effect. Real-space magnetic force microscopy (MFM) provides
direct evidence of periodic magnetic stripe domain formation, confirming the
microscopic origin of the observed topological transport phenomena. Our
findings establish a promising way for tuning the topology of domains to
generate substantial electromagnetic responses in layered magnetic materials.

</details>


### [306] [Non-relativistic spin splitting: Features and Functionalities](https://arxiv.org/abs/2510.20306)
*Sayantika Bhowal,Arnab Bose*

Main category: cond-mat.mtrl-sci

TL;DR: 补偿反铁磁体中非相对论性自旋分裂的研究综述。


<details>
  <summary>Details</summary>
Motivation: 解释补偿反铁磁体中非相对论性自旋分裂的物理学原理，并总结其最新研究进展。

Method: 通过总结不同自旋构型（包括共线、共面和非共面自旋排列）下的研究，并关注电子能带结构中的特征以及新兴功能。

Result: 概述了补偿反铁磁体中非相对论性自旋分裂的现象，并强调了其在电子能带结构中的特征。

Conclusion: 总结了该领域的研究现状，并指出了未来可能的研究方向。

Abstract: Recently, spin splitting of non-relativistic origin in compensated
antiferromagnets has drawn growing attention in condensed matter research.
Although many materials, now known to exhibit such spin splitting, have been
studied for decades, their manifestation along non-high-symmetry momentum
directions initially hindered their recognition. In recent years, significant
progress has been made in uncovering the symmetry principles that allow
non-relativistic spin splitting in the absence of net magnetization, revealing
the unconventional physics arising from their coexistence. In this review, we
provide a concise overview of non-relativistic spin splitting in compensated
antiferromagnets with various spin configurations, including collinear,
coplanar, and non-coplanar spin arrangements. We summarize practical
identification guidelines, highlight characteristic features in electronic band
structures, and discuss the emerging functionalities, with an emphasis on
promising directions for future exploration.

</details>


### [307] [Highly Rectifying Cubic Copper Iron Sulfides p-n Junction Diode Fabricated by Anodic Oxidation](https://arxiv.org/abs/2510.20326)
*Yoshimine Kato,Tomoaki Nakamura,Katsuya Komorita,Kungen Teii*

Main category: cond-mat.mtrl-sci

TL;DR: 铜铁硫化物Cu4Fe5S8表现出高整流比和高正向电流密度，可用于低成本半导体制造。


<details>
  <summary>Details</summary>
Motivation: 由于半导体器件的制造成本高昂，因此需要开发低成本、无毒的基础金属材料和简化的制造方法。

Method: 通过简单的湿法工艺制备了立方相Cu4Fe5S8多晶材料，并构建了p-n结二极管。

Result: Cu4Fe5S8二极管在室温下表现出高达10^6的整流比和15 Acm^-2 (1.5 V正向偏压)的正向电流密度，优于其他铜铁硫化物器件。

Conclusion: Cu4Fe5S8基p-n结二极管的高整流特性和高正向电流密度证明了其在低成本半导体制造中的潜力，并为立方相Cu4Fe5S8等新型半导体材料的研究开辟了新途径。

Abstract: Rectification properties of semiconductor p-n junction diodes are the basic
and important characteristics for electronic device evaluation, especially for
novel semiconductor materials. Today's semiconductor devices' fabrication and
integration processes require multibillion-dollar investments and are desired
to be reduced or simplified. Therefore, low-cost and non-toxic base metal
materials with simple fabrication methods are desired for the future
semiconductor industry. Recently, copper-based sulfides have been studied for
semiconductor devices such as thermoelectric, photovoltaic, or water-splitting
applications. Here, a highly rectifying p-n diode of a cubic (disordered) phase
Cu4Fe5S8 polycrystal with a zincblende-like structure fabricated by a
simple/low-cost wet process is shown. It is found that the Cu4Fe5S8 diode shows
the highest rectification ratio in the order of 106 with a large forward
current density of 15 Acm-2 (@1.5 V forward bias) at room temperature among the
other compounds of copper iron sulfide devices. This remarkable and stable
diode characteristic obtained by the p-type layer anodically grown on the
sintered n-type cubic-Cu4Fe5S8 can bring the industry closer to low-cost
semiconductor manufacturing. These results open a platform of novel
semiconductor materials such as cubic-Cu4Fe5S8 with further superior crystal
growth and conductive characteristics.

</details>


### [308] [Unlock Anionic Behavior of Calcium Through Pressure Engineering](https://arxiv.org/abs/2510.20395)
*Yang Lv,Junwei Li,Jianfu Li,Yong Liu,Jianan Yuan,1 Jiani Lin,Saori Kawaguchi-Imada,Qingyang Hu,Xiaoli Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 钙能在高压下表现出负价态，并与碘形成多种化合物。


<details>
  <summary>Details</summary>
Motivation: 探索高压下钙的价态变化及其与卤素形成的化合物。

Method: 利用第一性原理结构搜索和原位X射线衍射。

Result: 在高压下发现了CsCl型CaI相，并揭示了电子从碘的5p轨道到钙的3d轨道的电荷转移，导致CaI在485 GPa时转变为负价态的ICa。同时，发现了多价态钙可以稳定一系列超配位的金属碘化物。

Conclusion: 钙在高压下的价态可以从负价到+2变化，表明钙的化学性质在高压下更加复杂。

Abstract: An isolated calcium (Ca) atom has empty d-orbitals under ambient conditions.
However, s-d band hybridization has been observed in both elemental Ca and
compounds by manipulating thermodynamic conditions. Here, we reveal that the Ca
3d-band can even capture electrons from halogen atoms under pressure,
exhibiting anionic behaviors in iodides. We predict a CsCl-type monovalent CaI
at above 50 GPa by employing first-principles structural searching and
successfully identified the phase at 84 GPa using in situ X-ray diffraction. We
further reveal that, due to the effect of orbital broadening, unusual charge
transfer from the 5p orbitals of I to the 3d orbitals of Ca in CaI, gradually
reverses the ionicity of Ca and becomes the anionic ICa at 485 GPa. Multivalent
Ca stabilizes a set of metallic iodides with eight- to ten-fold iodine
hyper-coordination. Our findings demonstrate that the valence states of Ca can
vary from negative to +2, suggesting much greater complexity of Ca chemistry
under ultrahigh pressures.

</details>


### [309] [PBr3 Adsorption and Dissociation on the Si(100) Surface](https://arxiv.org/abs/2510.20420)
*Vladimir M. Shevlyuga,Yulia A. Vorontsova,Tatiana V. Pavlova*

Main category: cond-mat.mtrl-sci

TL;DR: PBr3在室温下会解离并吸附在Si(100)表面，高温下磷会掺入硅中。


<details>
  <summary>Details</summary>
Motivation: 研究PBr3在Si(100)表面的吸附行为及其在高温下的反应，为通过PBr3吸附在硅中掺入单个磷原子提供理论支持。

Method: 使用扫描隧道显微镜（STM）和密度泛函理论（DFT）研究PBr3在Si(100)-2×1表面的吸附。

Result: PBr3在室温下完全解离为P和Br原子，并吸附在三个相邻的Si二聚体上。400°C退火后，磷会掺入硅中，并伴随Si原子的喷射。

Conclusion: PBr3吸附是实现P原子掺杂Si的可行方法，尤其适用于通过卤素掩膜实现单个P原子的掺杂。

Abstract: The adsorption of PBr3 on the Si(100)-2$\times$1 surface was studied by
scanning tunneling microscopy (STM) and density functional theory (DFT). The
PBr3 molecule completely dissociates on the Si(100) surface at room temperature
into P and Br atoms. In most cases, the dissociated molecule was observed in
STM on three neighboring Si dimers. DFT calculations confirm that the PBr3
molecule can completely dissociate at room temperature. After annealing the
sample to 400$^{\circ}$C, phosphorus is incorporated into silicon, as evidenced
by the Si atoms ejected to the surface. These findings are useful for the
insertion of individual phosphorus atoms into silicon by PBr3 adsorption
through a halogen mask.

</details>


### [310] [Vacancy diffusion on a brominated Si(100) surface: Critical effect of the dangling bond charge state](https://arxiv.org/abs/2510.20426)
*T. V. Pavlova,V. M. Shevlyuga*

Main category: cond-mat.mtrl-sci

TL;DR: 带电荷的硅悬空键（DB）会影响空位在Si(100)表面上的扩散，这对于使用STM精确构建表面结构至关重要。


<details>
  <summary>Details</summary>
Motivation: 硅悬空键（DB）的精确构筑对于表面应用至关重要，但空位的扩散会破坏已构建的结构。因此，研究空位扩散机制对于表面应用的精确构筑具有重要意义。

Method: 通过STM和密度泛函理论计算，研究了Si(100)-2x1-Br表面上Br空位的扩散行为，并分析了DB电荷对扩散活性的影响。

Result: 研究发现，仅带正电荷的DB的空位会在Si二聚体上发生扩散，而中性和带负电荷的DB的空位则不会。密度泛函理论计算证实了带正电荷的Br（和Cl）空位具有最低的活化势垒。研究提出，扩散机制可能因施加的电压而异，包括单电子和双电子机制。

Conclusion: DB的电荷状态对空位扩散具有关键性影响。在利用STM成像或研究涉及空位的表面扩散时，必须考虑DB的电荷状态。

Abstract: Silicon dangling bonds (DBs) on an adsorbate-covered Si(100) surface can be
created in a scanning tunneling microscope (STM) with high precision required
for a number of applications. However, vacancies containing DBs can diffuse,
disrupting precisely created structures. In this work, we study the diffusion
of Br vacancies on a Si(100)-2$\times$1-Br surface in an STM under typical
imaging conditions. In agreement with previous work, Br vacancies diffuse at a
positive sample bias voltage. Here, we demonstrated that only vacancies
containing a positively charged DB hop across the two atoms of a single Si
dimer, while vacancies containing neutral and negatively charged DBs do not.
Calculations based on the density functional theory confirmed that positively
charged Br (and Cl) vacancies have a minimum activation barrier. We propose
that diffusion operates by both one-electron and two-electron mechanisms
depending on the applied voltage. Our results show that the DB charge has a
critical effect on the vacancy diffusion. This effect should be taken into
account when imaging surface structures with charged DBs, as well as when
studying the diffusion of other atoms and molecules on the Si(100) surface with
vacancies in an adsorbate layer.

</details>


### [311] [Ultralow-Cost magnetocaloric compound for Cryogenic Cooling](https://arxiv.org/abs/2510.20458)
*Wei Liu,Benjamin Theisel,Yulia Klunnikova,Konstantin Skokov,Oliver Gutfleisch*

Main category: cond-mat.mtrl-sci

TL;DR: FeCl2是一种基于低成本元素的离子磁热化合物，在20K附近表现出高达18.6 J/kg/K的磁熵变，使其成为氢液化技术有前景的磁热材料。


<details>
  <summary>Details</summary>
Motivation: 为了实现氢液化技术的广泛应用，需要开发成本效益高的磁热材料。现有研究多集中于稀土基材料，而本文旨在探索基于廉价元素的替代材料。

Method: 研究了离子磁热化合物FeCl2的磁热效应，测量了其在不同磁场下的磁熵变（ΔS_T）和绝热温变（ΔT_ad），重点关注其在20K附近的低温区域。

Result: FeCl2在20K附近表现出正的磁熵变（高达5 J/kg/K @ 1.5T）和负的磁熵变（高达18.6 J/kg/K @ 5T），后者超过了大多数轻稀土基化合物。在5T磁场下，绝热温变约为3.6K。在20-77K温度范围内，FeCl2具有良好的磁热性能。

Conclusion: FeCl2因其低成本和优异的磁热性能，特别是其在低温下的高磁熵变，有潜力成为氢液化工业规模化生产的实用磁热材料。

Abstract: Cost-effective materials are essential for large-scale deployment. The
emerging magnetocaloric hydrogen liquefaction technology could transform the
liquid hydrogen industry due to its potential in achieving higher efficiency.
Most studies of the cryogenic magnetocaloric effect (MCE) have focused on
resource-critical rare-earth-based compounds. Here we report on an ionic
magnetocaloric compound FeCl$_2$ which is based on ultralow-cost elements, as a
candidate working material for hydrogen liquefaction. FeCl$_2$ shows both
inverse and conventional MCE. From 0 to 1.5 T, the inverse effect yields a
positive magnetic entropy change ($\Delta S_T$) of about 5 J/kg/K near 20 K,
then declines toward zero at higher fields. In contrast, the conventional
(negative) response strengthens with field. The $\Delta S_T$ reaches 18.6
J/kg/K near 20 K in magnetic fields of 5 T. This value exceeds most light
rare-earth-based compounds and approaches that of heavy rare-earth-based
compounds. In magnetic fields of 5 T, the adiabatic temperature change reaches
about 3.6 K. The large $\Delta S_T$, along with the low cost of the elements in
FeCl$_2$, are prerequisites for inexpensive industrial-scale production, giving
the prospect of a practical magnetocaloric candidate for hydrogen liquefaction
in the 20 $\sim$ 77 K temperature window.

</details>


### [312] [Predicting the 3D microstructure of SOFC anodes from 2D SEM images using stochastic microstructure modeling and CNNs](https://arxiv.org/abs/2510.20502)
*Léon F. Schröder,Sabrina Weber,Lukas Fuchs,Volker Schmidt,Benedikt Prifling*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出一种从2D SEM图像预测3D SOFC阳极微观结构的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的3D微观结构表征方法（如FIB-SEM）成本高昂，而2D图像（如SEM）易于获取但信息不足。本研究旨在解决如何从易于获取的2D图像准确推断3D微观结构的问题。

Method: 利用随机几何的低参数3D模型生成大量虚拟3D微观结构，并使用基于物理的SEM模拟工具生成相应的2D SEM图像。然后，利用生成的数据训练卷积神经网络（CNN），以从2D SEM图像预测3D微观结构。最后，通过误差分析评估该方法的准确性和可靠性。

Result: 成功实现了从2D SEM图像对3D SOFC阳极微观结构的统计重建，并通过关键几何描述符的误差分析验证了预测工具的准确性和可靠性。

Conclusion: 所提出的方法能够有效且经济地从2D SEM图像中重建3D SOFC阳极微观结构，为相关研究提供了新的途径。

Abstract: The 3D microstructure of solid oxide fuel cell anodes significantly
influences their electrochemical performance, but conventional methods for
acquiring high-resolution microstructural 3D data such as focused ion beam
scanning electron microscopy (FIB-SEM) are costly in both time and resources.
In contrast, obtaining 2D images, such as from scanning electron microscopy
(SEM), is more accessible, though typically providing insufficient information
to accurately characterize the 3D microstructure. To address this challenge, we
propose a novel approach that predicts the 3D microstructure from 2D SEM
images. The presented method utilizes a low-parametric 3D model from stochastic
geometry to generate a large number of virtual 3D microstructures and employs a
physics-based SEM simulation tool to obtain the corresponding 2D SEM images. By
systematically varying the underlying model parameters, a large dataset can be
generated to train convolutional neural networks (CNNs). By doing so, we can
statistically reconstruct the 3D microstructure from 2D SEM images by drawing
realizations from the stochastic 3D model using the predicted model parameters.
In addition, we conducted an error analysis on key geometrical descriptors to
quantitatively evaluate the accuracy and reliability of this stereological
prediction tool.

</details>


### [313] [The effects of high-temperature ion-irradiation on early-stage grain boundaries serrations formation in Ni-based alloys](https://arxiv.org/abs/2510.20536)
*M. Frelek-Kozak,K. Mulewska,M. Wilczopolska,D. Kalita,W. Chrominski,A. Zaborowska,L. Kurpaska,J. Jagielski*

Main category: cond-mat.mtrl-sci

TL;DR: 镍基高温合金因其优异的抗蠕变性、断裂韧性和耐腐蚀性而被认为是核反应堆的候选材料，但其抗辐射能力和辐射损伤对变形机制的影响尚不完全清楚。


<details>
  <summary>Details</summary>
Motivation: 研究镍基高温合金（Hastelloy X 和 Haynes 230）的抗辐射能力和辐射损伤对变形机制的影响，为核反应堆的应用提供参考。

Method: 通过扫描电子显微镜（SEM）、电子背散射衍射（EBSD）、透射电子显微镜（TEM）和纳米压痕测试来表征材料的结构和力学性能。使用 Ar 离子（320keV）辐照两种合金，剂量高达 12dpa，以模拟辐射损伤。

Result: 辐照导致两种合金均出现硬化效应，其中 Hastelloy X 的硬化效应更明显。同时，观察到 Hastelloy X 的析出物形貌发生显著变化。研究提出，两种合金的结构差异决定了辐射诱导过程的类型，高能离子辐照释放的能量会降低高温相的成核温度，从而引发晶界锯齿的形成。

Conclusion: 材料的结构差异是影响辐射损伤效应的关键因素。Hastelloy X 表现出更强的硬化效应和析出物形貌变化，这与其结构特点有关。辐射诱导的高温相成核和晶界锯齿的形成机制需要进一步研究。

Abstract: Nickel based superalloys display outstanding properties such as excellent
creep strength, remarkable fracture toughness parameters, and corrosion
resistance. For this reason, Ni based materials are considered as materials
dedicated to the IV generation of nuclear reactors. Although these materials
seem promising candidates, their radiation resistance and impact of radiation
damage on the deformation mechanism are still not fully understood. In this
work, two commercially available nickel based alloys, Hastelloy X and Haynes
230, were investigated. Structural and mechanical properties have been
described by means of SEM and EBSD, TEM, and nanoindentation tests. Radiation
damage has been performed by Ar ion with energy 320keV with two doses up to
12dpa. Obtained results have revealed a hardening effect for both levels of
damage. However, more intensive effects were observed for Hastelloy X.
Moreover, a significant change in precipitates morphology in Hastelloy X has
been observed. It has been proposed that structural differences between both
alloys determine the type of occurring radiation induced processes. Excess
energy deposited into materials structure during ion irradiation can lower the
temperature of nucleation of high temperature phases, which initiates the
formation of grain boundary serrations.

</details>


### [314] [Nanoscale Mapping of Transition Metal Ordering in Individual LiNi0.5Mn1.5O4 Particles Using 4D-STEM ACOM Technique](https://arxiv.org/abs/2510.20729)
*Gozde Oney,Fayçal Adrar,Junhao Cao,Chunyang Zhang,Muriel Véron,Matthieu Bugnet,Emmanuelle Suard,Jacob Olchowka,Laurence Croguennec,François Weill,Arnaud Demortière*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究首次使用4D-STEM技术在纳米尺度上直接观察了LiNi0.5Mn1.5O4颗粒中的有序分布，并提出了一种基于电子衍射斑点强度比的局部有序度量化方法。


<details>
  <summary>Details</summary>
Motivation: 研究高电压正极材料LiNi0.5Mn1.5O4的尖晶石结构中过渡金属的排布方式，因为这会影响其电化学性能，但现有技术缺乏揭示颗粒尺度上配位现象的空间分辨率。

Method: 采用4D-STEM技术，结合电子衍射斑点强度比，提出一种量化局部有序度的方法，用于分析LiNi0.5Mn1.5O4颗粒内的有序分布。

Result: 首次在纳米尺度上直接观察到LiNi0.5Mn1.5O4颗粒内存在有序分布；提出的量化方法能够评估颗粒的局部有序度；发现有序尖晶石LiNi0.5Mn1.5O4中的过渡金属有序性在整个初级颗粒中是一致的，但有序程度取决于颗粒尺度的分布，并受退火条件影响；阐明了高度有序和低度有序LiNi0.5Mn1.5O4颗粒之间的边界。

Conclusion: 过渡金属的排布方式（有序或无序）对LiNi0.5Mn1.5O4的电化学性能有重要影响。4D-STEM技术能够提供颗粒尺度上的配位信息，所提出的量化方法可用于评估材料的有序程度，这对于优化材料性能具有重要意义。退火条件会影响材料的有序分布。

Abstract: The electrochemical performance of the spinel LiNi0.5Mn1.5O4, a high-voltage
positive electrode material for Li-ion batteries, is influenced by the
transition metal arrangement in the octahedral network, leading to disordered
(Fd m S.G.) and ordered3 (P4332 S.G.) structures. However, widely used
techniques lack the spatial resolution necessary to elucidate the ordering
phenomenon at the particle scale. Using the 4D-STEM technique, we present the
first direct observation of ordering distribution in individual LiNi0.5Mn1.5O4
particles with nanometric spatial resolution. We propose a quantification
method for the local degree of ordering based on the ratio of ordered to
disordered spinel lattices along the particle thickness extracted from electron
diffraction spot intensities. In an ordered spinel LiNi0.5Mn1.5O4, the
transition metal ordering is consistently observed throughout the primary
particle. However, the extent of ordering in the spinel phase depends on its
distribution at the particle scale, a factor influenced by the annealing
conditions. The 4D-STEM analysis elucidates the boundary between highly-ordered
and low-ordered LiNi0.5Mn1.5O4 particles.

</details>


### [315] [Angular dependence and powder average of resonant inelastic X-ray scattering](https://arxiv.org/abs/2510.20731)
*Myrtille O. J. Y Hunault,Timothy G. Burrow,Fabien Besnard,Amélie Juhin,Christian Brouder*

Main category: cond-mat.mtrl-sci

TL;DR: RIXS谱学理论计算新方法，考虑了角向依赖性，简化了对各向同性样品和常见点群的计算，并以铀3d4f RIXS为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: RIXS实验数据解释需要基于Kramers-Heisenberg公式的理论计算，但该公式的角向依赖性处理不完整。

Method: 在电偶极近似下，确定了RIXS截面中的基本谱数，推导了各向同性样品的RIXS截面通用表达式，并得到了常见点群的简化形式。

Result: 得到了RIXS截面的通用表达式，并为常见点群提供了简化形式，以铀3d4f RIXS为例进行了验证。

Conclusion: 提出的RIXS理论计算方法能够有效处理角向依赖性，简化了对不同类型样品的分析，为RIXS谱学的应用提供了理论支持。

Abstract: Resonant Inelastic X-ray scattering (RIXS) is a synchrotron-based
spectroscopy that has seen growing interest across a range of scientific
disciplines beyond fundamental physics. The interpretation of experimental RIXS
data requires theoretical calculations based on the Kramers-Heisenberg formula.
However, due to the dependence of RIXS on both the incident and scattered
photon properties, a tractable treatment of the angular dependence in this
formula has been lacking. In this work, within the electric dipole
approximation, we determine the number of fundamental spectra contributing to
the RIXS cross-section for all crystallographic point groups. We then derive a
general expression for the RIXS cross-section of isotropic samples such as
un-textured powders, homogeneous glasses or liquids, explicitly accounting for
the polarization and propagation directions of both the incident and scattered
photons. Simplified forms of the RIXS expressions are subsequently obtained for
most common point groups. Finally, we demonstrate the applicability of our
formalism through a case study of uranium 3d4f RIXS.

</details>


### [316] [Berry Curvature Dipole-induced Non-linear Hall Effect in Oxide Heterostructures](https://arxiv.org/abs/2510.20746)
*Nesta Benno Joseph,Arka Bandyopadhyay,Ajit C. Balram,Awadhesh Narayan*

Main category: cond-mat.mtrl-sci

TL;DR: 非中心对称的过渡金属氧化物异质结是实现和调控Berry曲率偶极子（BCD）诱导的非线性霍尔效应的有前景的平台。


<details>
  <summary>Details</summary>
Motivation: 研究非中心对称异质结中的Berry曲率偶极子（BCD）诱导的非线性霍尔效应。

Method: 研究了 $(\mathrm{Ba(Os,Ir)}\mathrm{O}_3)_n/(\mathrm{BaTiO}_3)_4$ ($n{=}1, 2$) 超晶格的性质，并进行了第一性原理计算。

Result: 提出的超晶格结构具有有限的BCD，并且BCD的大小可以通过改变金属层数或B位阳离子来有效调控。

Conclusion: 非中心对称氧化物钙钛矿异质结是探索和操纵BCD驱动的非线性输运现象的通用平台。

Abstract: The observation of non-linear Hall effects in time-reversal invariant systems
has established the intriguing role of band topology beyond Berry curvature in
determining transport phenomena. Many of these non-linear responses owe their
origin to the Berry curvature dipole (BCD), which, like the Berry curvature
(monopole), is also an electronic band structure effect, but is routinely
strongly constrained by crystalline symmetries. Here, we propose
non-centrosymmetric transition metal oxide heterostructures as promising
platforms for realizing and tuning BCD-induced non-linear Hall effects.
Specifically, we investigate superlattices of the form
$(\mathrm{Ba(Os,Ir)}\mathrm{O}_3)_n/(\mathrm{BaTiO}_3)_4$ ($n{=}1, 2$),
comprising metallic perovskite layers ($\mathrm{BaOsO_3}$ or
$\mathrm{BaIrO_3}$) sandwiched between insulating ferroelectric
$\mathrm{BaTiO_3}$ (BTO). The ferroelectric distortion in BTO breaks inversion
symmetry of the superlattice, giving rise to a finite BCD with two
symmetry-allowed components of equal magnitude and opposite sign. Our
first-principles calculations demonstrate that the magnitude of the BCD -- and
consequently the nonlinear Hall response -- can be effectively tuned by varying
the number of metallic layers or the choice of the B-site cation in these
$\mathrm{ABO_3}$ perovskites. Since Rashba splitting and ferroelectric
distortion in these systems are readily controllable via an external electric
field or strain, the non-linear Hall response in these materials can be
directly engineered. Our findings establish non-centrosymmetric oxide
perovskite heterostructures as a versatile platform for exploring and
manipulating BCD-driven non-linear transport phenomena.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [317] [The Risks of Industry Influence in Tech Research](https://arxiv.org/abs/2510.19894)
*Joseph Bak-Coleman,Cailin O'Connor,Carl Bergstrom,Jevin West*

Main category: cs.SI

TL;DR: 新兴信息技术对公共健康、政治制度、社会动态和自然世界产生广泛影响。需要科学理解这些影响，为循证技术政策提供信息，以尽量减少危害并最大化利益。然而，与大多数其他全球性科学挑战不同，科学进步所需的数据由可能受到循证监管的行业生成和控制。此外，科技公司一直是该领域的资助者。信息和资金的不对称引发了对行业可能对科学记录产生不当影响的担忧。本文探讨了科技公司如何影响我们对其产品的科学理解。我们认为，技术研究中的科学面临着独特的挑战，需要加强现有的保障措施并建立全新的保障措施。


<details>
  <summary>Details</summary>
Motivation: 新兴信息技术（如社交媒体、搜索引擎和人工智能）对公共健康、政治制度、社会动态和自然世界产生了广泛影响。为了制定能够最小化危害并最大化效益的循证技术政策，必须对这些影响进行科学的理解。

Method: 探讨科技公司如何影响我们对其产品的科学理解。在此背景下，科学面临着独特的挑战，需要加强现有的保障措施并建立全新的保障措施。

Result: 科技公司在科学研究中可能对科学记录产生不当影响，因为它们控制着科学进步所需的数据，并且是该领域的主要资助者。

Conclusion: 科学在技术研究领域面临着独特的挑战，需要加强现有的保障措施并建立全新的保障措施，以应对科技公司可能带来的不当影响。

Abstract: Emerging information technologies like social media, search engines, and AI
can have a broad impact on public health, political institutions, social
dynamics, and the natural world. It is critical to develop a scientific
understanding of these impacts to inform evidence-based technology policy that
minimizes harm and maximizes benefits. Unlike most other global-scale
scientific challenges, however, the data necessary for scientific progress are
generated and controlled by the same industry that might be subject to
evidence-based regulation. Moreover, technology companies historically have
been, and continue to be, a major source of funding for this field. These
asymmetries in information and funding raise significant concerns about the
potential for undue industry influence on the scientific record. In this
Perspective, we explore how technology companies can influence our scientific
understanding of their products. We argue that science faces unique challenges
in the context of technology research that will require strengthening existing
safeguards and constructing wholly new ones.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [318] [Circuit-based cavity magnonics in the ultrastrong and deep-strong coupling regimes](https://arxiv.org/abs/2510.20115)
*Takahiro Chiba,Ryunosuke Suzuki,Takashi Otaki,Hiroaki Matsueda*

Main category: cond-mat.mes-hall

TL;DR: 腔体宏观系统中的非微扰强耦合现象，频率移动的起源难以用经典框架解释，量子模型揭示其与粒子数、涨落和纠缠熵有关，可用软磁振子进行实验验证。


<details>
  <summary>Details</summary>
Motivation: 研究腔体宏观系统中非微扰强耦合现象，特别是频率移动的微观起源。

Method: 从描述磁化动力学的有效电路模型出发，进行量子化得到最小量子力学模型，并将其与Hopfield哈密顿量联系起来。

Result: 在超强和深强耦合区域出现了非平凡的频率移动，该移动与地面粒子数、海森堡不确定性原理相关的量子涨落以及纠缠熵有关，并且在磁场变化时会发散。

Conclusion: 这项工作为超越传统强耦合的腔体宏观研究开辟了道路。

Abstract: We theoretically study nonperturbative strong-coupling phenomena in cavity
magnonics systems in which the uniform magnetization dynamics (magnons) in a
ferromagnet is coupled to the microwave magnetic field (photons) of a single LC
resonator. Starting from an effective circuit model that accounts for the
magnetization dynamics described by the Landau-Lifshitz-Gilbert equation, we
show that a nontrivial frequency shift emerges in the ultrastrong and
deep-strong coupling regimes, whose microscopic origin remains elusive within a
purely classical framework. The circuit model is further quantized to derive a
minimal quantum mechanical model for generic cavity magnonics, which
corresponds to a two-mode version of the Hopfield Hamiltonian and explains the
mechanism of the frequency shifts found in the {\it classical} circuit model.
We also formulate the relation between the frequency shift and quantum
quantities, such as the ground-state particle number, quantum fluctuations
associated with the Heisenberg uncertainty principle, and entanglement entropy,
providing a nondestructive means to experimentally access to these quantum
resources. By utilizing soft magnons in an anisotropic ferromagnet, we further
demonstrate that these quantum quantities diverge at the zeros of the magnon
band edges as a function of the external magnetic field. This work paves the
way for cavity magnonics beyond the conventional strong coupling regime.

</details>


### [319] [Intrinsic Non-linearity of Josephson Junctions as an Alternative Origin of the Missing First Shapiro Step](https://arxiv.org/abs/2510.20130)
*Lei Xu,Shuhang Mai,Manzhang Xu,Xue Yang,Lihong Hu,Xinyi Zheng,Sicheng Zhou,Siyuan Zhou,Bingbing Tong,Xiaohui Song,Jie Shen,Zhaozheng Lyu,Ziwei Dou,Xiunian Jing,Fanming Qu,Peiling Li,Guangtong Liu,Li Lu*

Main category: cond-mat.mes-hall

TL;DR: 反常的约瑟夫森结的零压和一压台阶之间的锯齿形边界是迈索纳物理学的关键诊断工具。


<details>
  <summary>Details</summary>
Motivation: 约瑟夫森结中缺失的第一个Shapiro台阶被广泛认为是Majorana束缚态的标志，但其他机制也可能产生类似的信号。因此，有必要区分这些机制。

Method: 研究了低至中等透明度结的非线性特性，并通过微波测量和数值模拟来分析Al/WTe2结。提出了一种非线性电阻和电容分流结模型。

Result: 证明了结的非线性特性可以抑制第一个Shapiro台阶，并产生独特的锯齿形边界。这些特征与仅由有限η或焦耳热引起的现象不同。

Conclusion: 零压和一压台阶之间的锯齿形边界可以作为区分Majorana物理学和其他可能解释缺失的第一个Shapiro台阶的机制的关键诊断工具。在将缺失的第一个Shapiro台阶归因于Majorana物理学之前，必须对微波光谱进行全面分析。

Abstract: The missing first Shapiro step in microwave-irradiated Josephson junctions
has been widely interpreted as a hallmark of Majorana bound states. However,
conventional mechanisms like junction underdamping or Joule heating can produce
similar signatures. Here, we demonstrate that the intrinsic non-linear
current-voltage characteristic of low-to-moderate transparency junctions can
also suppress the first step, accompanied by distinctive zigzag boundaries
between the zeroth and first step at intermediate driving frequencies.
Microwave measurements on Al/WTe2 junctions and numerical simulations of a
non-linear resistively and capacitively shunted junction model reveal the first
step collapse induced by switching jumps of current, together with zigzag
features absent in scenarios solely driven by finite \b{eta} or Joule heating.
This zigzag signature therefore provides a crucial diagnostic tool, emphasizing
the necessity of comprehensive analysis of microwave spectra before attributing
the absence of the first Shapiro step to Majorana physics.

</details>


### [320] [Electric field induced Berry curvature dipole and non-linear anomalous Hall effect in higher wave symmetric unconventional magnets](https://arxiv.org/abs/2510.20237)
*Srimayi Korrapati,Snehasish Nandy,Sumanta Tewari*

Main category: cond-mat.mes-hall

TL;DR: An applied ac electric field can generate a finite nonlinear transverse Hall effect in two-dimensional higher-wave-symmetric magnets, including altermagnets, by inducing a nonzero Berry curvature dipole through coupling to a nonvanishing quantum metric. This effect can probe the quantum metric and distinguish between even and odd order parameter symmetries.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the second-order anomalous Hall response in two-dimensional higher-wave-symmetric magnets, including altermagnets, under a symmetry-breaking external electric field, where conventional responses vanish by symmetry.

Method: The study theoretically analyzes how a symmetry-breaking dc electric field induces a nonzero Berry curvature dipole by coupling to the quantum metric (Berry connection polarizability). An applied ac electric field then generates a finite nonlinear transverse Hall effect, characterized by a second harmonic response, in higher-order-symmetric unconventional magnets (p, d, f, g, i symmetry), including altermagnets.

Result: A finite nonlinear transverse Hall effect is generated by an applied ac electric field in higher-wave-symmetric magnets, characterized by a second harmonic response. This effect can be used to probe the quantum metric of the occupied states and distinguish between even (d, g-wave) and odd (p-wave) order parameter symmetries on the square lattice.

Conclusion: The electric-field-induced anomalous Hall effect in higher-wave-symmetric magnets is a significant finding that serves both as a probe for the underlying quantum metric and as a method to differentiate between various order parameter symmetries.

Abstract: We investigate the second-order anomalous Hall response in two-dimensional
higher-wave-symmetric magnets, including the recently discovered class of
collinear magnets known as altermagnets, when subjected to a symmetry-breaking
external electric field. In these systems, the first- and second-order
anomalous Hall responses mediated by the first- and second-order multipoles of
the Berry curvature over the occupied states vanish by symmetry. However, a
symmetry-breaking dc electric field can induce a nonzero Berry curvature dipole
by coupling to a nonvanishing quantum metric, also known as the Berry
connection polarizability. An applied ac electric field can then generate a
finite nonlinear transverse Hall effect characterized by a second harmonic
response. We discuss this remarkable effect in a class of
higher-order-symmetric unconventional magnets (of $p$, $d$, $f$, $g$, $i$
symmetry), including the subclass of altermagnets. We demonstrate that the
electric-field-induced anomalous Hall effect in the higher-wave-symmetric
magnets can serve not only as a probe of the underlying quantum metric of the
occupied states but also as a means to distinguish the even ($d$-,$g$-wave) and
odd ($p$-wave) order parameter symmetries defined on the square lattice.

</details>


### [321] [Emergent Massless Dirac Fermions in Moiré Bands of Bilayer Graphene/hBN Superlattice](https://arxiv.org/abs/2510.20309)
*Mohit Kumar Jat,Kenji Watanabe,Takashi Taniguchi,Aveek bid*

Main category: cond-mat.mes-hall

TL;DR: 文章提出了一种利用hBN实现双层石墨烯(BLG)拓扑带重构的实验方法，发现次级带中存在无质量狄拉克费米子，并归因于莫尔超晶格势引起的带展宽。


<details>
  <summary>Details</summary>
Motivation: 研究hBN对齐在诱导双层石墨烯(BLG)超晶格中拓扑带重构中的作用。

Method: 通过磁输运测量，包括量子霍尔效应、温度依赖的Shubnikov-de Haas振荡和Berry相位分析，研究hBN对齐诱导的拓扑带重构。

Result: 实验证明，hBN对齐可以诱导BLG超晶格中的拓扑带重构。主要能带保持其大质量手征性质，而次级能带表现出手性无质量费米子。莫尔超晶格次级带中显著降低的费米速度表明莫尔超晶格势引起了能带展宽。

Conclusion: 该研究为控制BLG/hBN超晶格中的拓扑量子输运提供了一种途径。

Abstract: A superlattice of multilayer graphene and hBN has proven to be a promising
pathway for engineering electronic band structures and topologies. In this
work, we experimentally demonstrate the role of hBN alignment in inducing
topological band reconstruction in bilayer graphene (BLG) superlattices. Our
study establishes that while the primary band retains its massive chiral naure,
the secondary bands host massless, chiral fermions. Magnetotransport
measurements, including Quantum Hall, temperature-dependent Shubnikov-de Haas
oscillations, and Berry phase analysis, confirm the distinct topological nature
of these bands. A significantly reduced Fermi velocity in the moir\'{e}
secondary band indicates band flattening induced by the moir\'{e} potential.
Our study provides a pathway for controlling topological quantum transport in
BLG/hBN superlattices.

</details>


### [322] [Thermoelectric properties of interacting double quantum dots](https://arxiv.org/abs/2510.20397)
*Nahual Sobrino*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过分析求解方程，探讨了相互作用的平行双量子点在库仑阻塞状态下的热电输运性质，并得到了其效率和输出功率的最大化工作点。


<details>
  <summary>Details</summary>
Motivation: 研究相互作用的平行双量子点在库仑阻塞状态下的热电输运性质，以确定最大化效率和输出功率的操作点，并研究热整流现象。

Method: 采用基于运动方程技术的解析方法，扩展了不对称耦合情况的理论，并推导出稳态电流、微分电导、塞贝克系数和热导的紧凑闭合形式表达式。

Result: 得到了稳态电流、微分电导、塞贝克系数和热导的表达式，确定了最大化效率和输出功率的操作点，并研究了热整流现象。发现相互作用诱导的共振会影响系统的效率、负微分热导和热整流。

Conclusion: 研究结果为理解和设计基于量子点的热电器件提供了理论基础。

Abstract: We investigate the thermoelectric transport properties of an interacting
parallel double quantum dot in the Coulomb-blockade regime. Building on an
analytical solution based on an equation-of-motion technique, we extend the
formalism for the asymmetrically coupled situation and provide compact
closed-form expressions for steady-state currents together with the
differential conductance, Seebeck coefficient, and thermal conductance. We
determine the operating points that maximize efficiency and output power of the
system, clarifying their relation to standard near-equilibrium ZT expressions.
We further study the thermal rectification in both the open- and closed-circuit
configurations and derive an expression for the open-circuit case.
Interaction-induced resonances are understood in terms of the poles of the
resulting Green's function, generating gate and bias dependent regions of
enhanced efficiency at finite power, negative differential thermal conductance,
and finite thermal rectification.

</details>


### [323] [Sub-10 nm Quantification of Spin and Orbital Magnetic Moment Across the Metamagnetic Phase Transition in FeRh Using EMCD](https://arxiv.org/abs/2510.20523)
*Jan Hajduček,Veronica Leccese,Ján Rusz,Jon Ander Arregi,Alexey Sapozhnik,Jáchym Štindl,Francesco Barantani,Paolo Cattaneo,Antoine Andrieux,Vojtěch Uhlíř,Fabrizio Carbone,Thomas LaGrange*

Main category: cond-mat.mes-hall

TL;DR: 电子磁圆二色性(EMCD)技术在透射电子显微镜(TEM)中可实现对自旋和轨道磁矩进行元素特异性测量，但其定量准确性仍需考量。本研究以FeRh材料为参考，系统评估了定量EMCD分析的极限，并证明在探测尺寸大于约6纳米时，EMCD可获得与X射线磁圆二色性(XMCD)基准一致的轨道角动量与自旋角动量之比($m_	ext{L}/m_	ext{S}$)。当探测尺寸小于6纳米且会聚角增大时，观测到$m_	ext{L}/m_	ext{S}$的增强，这归因于仪器因素和对探测体积内纳米尺度不均匀性的敏感性。研究结果表明，在适宜条件下EMCD可提供与宏观技术一致的定量结果，并能独特地实现对功能磁性材料中局域磁矩的空间分辨测量，以及研究光子学方法无法企及的界面、缺陷或相分离磁性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统评估电子磁圆二色性(EMCD)技术在透射电子显微镜(TEM)中的定量准确性，特别是在使用会聚探针的束分束几何结构中，并确定其可靠量化的适用范围。

Method: 本研究利用铁铑(FeRh)材料作为磁参考，该材料具有第一阶磁结构转变。通过系统地评估EMCD技术在不同探测尺寸和会聚角下的表现，并将其提取的轨道角动量与自旋角动量之比($m_	ext{L}/m_	ext{S}$)与X射线磁圆二色性(XMCD)的测量结果进行比较，来评估EMCD的定量准确性。

Result: 研究发现，当TEM探针尺寸大于约6纳米时，提取的轨道角动量与自旋角动量之比($m_	ext{L}/m_	ext{S}$)与XMCD的测量结果一致，证实了EMCD在此范围内的可靠性。然而，对于尺寸小于6纳米且具有更高会聚角的探针，观测到$m_	ext{L}/m_	ext{S}$值有所增加，这可能是由于仪器因素和对纳米尺度不均匀性的敏感性所致。

Conclusion: 本研究证实，在适宜条件下，EMCD技术可以提供与宏观技术（如XMCD）一致的定量测量结果。此外，EMCD技术能够独特地实现对功能磁性材料中局域磁矩进行空间分辨测量，并能研究光子学方法难以企及的界面、缺陷介导或相分离磁性现象。

Abstract: Electron magnetic circular dichroism (EMCD) in transmission electron
microscopy (TEM) enables element-specific measurement of spin and orbital
magnetic moments, analogous to X-ray magnetic circular dichroism (XMCD). While
the EMCD technique offers unmatched spatial resolution, its quantitative
accuracy remains under scrutiny, particularly in beam-splitter geometries with
convergent probes. Here, we systematically evaluate the limits of quantitative
EMCD analysis using the first-order magnetostructural transition in the
functional phase-change material FeRh as a tunable magnetic reference. Unlike
previous EMCD studies primarily focused on elemental ferromagnets such as Fe,
we demonstrate its applicability to a correlated material exhibiting coupled
structural and magnetic order. We demonstrate that the extracted
orbital-to-spin moment ratio ($m_\text{L}/m_\text{S}$) remains consistent with
XMCD benchmarks for TEM probes down to approximately 6 nm, thereby establishing
the validity range for reliable quantification. For nm-sized probes with higher
convergence angles, we observe an enhanced $m_\text{L}/m_\text{S}$, which we
attribute to a combination of instrumental factors and sensitivity to nanoscale
heterogeneity within the probed volume. Our results confirm that EMCD provides
quantitative agreement with macroscale techniques under suitable conditions,
while uniquely enabling spatially confined measurements of local magnetic
moments in functional magnetic materials, and allowing the study of
interfacial, defect-mediated, or phase-separated magnetism that is inaccessible
to photon-based methods.

</details>


### [324] [Quantifying robustness and locality of Majorana bound states in interacting systems](https://arxiv.org/abs/2510.20538)
*William Samuelson,Juan Daniel Torres Luna,Sebastian Miles,A. Mert Bozkurt,Martin Leijnse,Michael Wimmer,Viktor Svensson*

Main category: cond-mat.mes-hall

TL;DR: This paper defines Majorana bound states (MBSs) from many-body ground states in interacting systems and quantifies their protection against environmental coupling, demonstrating the feasibility of non-abelian braiding.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous connections between Majorana bound state (MBS) separation, robust degeneracy, and protected braiding in interacting systems, addressing the limitations of previous non-interacting system models and recent experimental progress in quantum-dot-based Kitaev chains.

Method: Defining MBSs from many-body ground states in interacting systems and analyzing how their locality constrains their coupling to an environment.

Result: Quantified the protection of energy degeneracy and demonstrated the feasibility of non-abelian braiding in interacting systems based on MBS properties.

Conclusion: The locality of MBSs in interacting systems provides a quantifiable protection for energy degeneracy and enables non-abelian braiding, which is crucial for robust quantum computing.

Abstract: Protecting qubits from perturbations is a central challenge in quantum
computing. Topological superconductors with separated Majorana bound states
(MBSs) provide a strong form of protection that only depends on the locality of
perturbations. While the link between MBS separation, robust degeneracy, and
protected braiding is well understood in non-interacting systems, recent
experimental progress in short quantum-dot-based Kitaev chains highlights the
need to establish these connections rigorously for interacting systems. We do
this by defining MBSs from many-body ground states and show how their locality
constrains their coupling to an environment. This, in turn, quantifies the
protection of the energy degeneracy and the feasibility of non-abelian
braiding.

</details>


### [325] [Time-braiding phase of anyons tied to the nonuniversal scaling dimension](https://arxiv.org/abs/2510.20592)
*Aleksander Latyshev,Ines Safi*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种连接直流噪声和响应函数的新型非平衡涨落耗散关系，并用于分析直流电流和噪声之间的关系，最终揭示了时间-编织相位由标度维数决定，并对该相位的普适性提出了质疑。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于建立一个能联系直流噪声和响应函数的理论框架，以深入理解非平衡系统中的涨落耗散关系，并探讨时间-编织相位与系统微观动力学之间的联系。

Method: 研究采用了统一非平衡微扰理论（UNEPT），结合时间域的编织约束和克拉马斯-克罗尼格关系，推导了直流电流和噪声之间的积分方程。通过指定热平衡态并利用维纳-霍普夫技术，得到了直流电流的解析解。

Result: 研究结果表明，时间-编织相位由标度维数决定，并提出了该相位的普适性问题，指出它可能反映微观边缘动力学，而非空间域中拓扑保护的编织相位。

Conclusion: 该研究通过分析得出的时间-编织相位与标度维数的关系，质疑了该相位的普适性，并强调了其可能反映微观边缘动力学的重要意义。

Abstract: We use a braiding nonequilibrium fluctuation dissipation relation linking the
DC noise to the response function inferred from the braiding constraint in the
time-domain with a phase $\theta$ within the UNEPT (Unified Non equilibrium
Perturbative Theory). By applying the Kramers-Kr\"onig relations, we obtain an
integral equation connecting DC current and noise that involves $\theta$. By
specifying to thermal states so that noise is Poissonian, we find an analytical
solution for the DC current via the Wiener-Hopf technique. It reveals that the
time-braiding phase is determined by the scaling dimension~$\delta$. This
questions the universality of $\theta$ that can reflect the microscopic edge
dynamics, in contrast to the topologically protected braiding phase in the
space domain.

</details>


### [326] [Computational Design Rules for Helical Aromatic Foldamers: $π-π$ Stacking, Solvent Effects, and Conformational Stability](https://arxiv.org/abs/2510.20638)
*Kseniia Storozheva,Anastasia Markina,Vladik Avetisov*

Main category: cond-mat.mes-hall

TL;DR: 设计了一种基于量子化学计算的系统方法，用于评估溶剂依赖性的机械行为，并找到了改进的螺旋芳香折叠体。


<details>
  <summary>Details</summary>
Motivation: 螺旋折叠体在下一代纳米电子器件中具有重要应用前景，但其性能受构象稳定性和环境因素影响。需要一种方法来系统评估其溶剂依赖性机械行为并指导设计。

Method: 结合了π-π堆积相互作用分析、构象能量学分析和环境效应分析，并基于量子化学计算。

Result: 提出了一种简单设计原则，能够快速筛选新的化合物，评估其构象稳定性和有效机械刚度。发现了一种改进的螺旋芳香折叠体，与参考化合物相比，具有更好的机械和稳定性。

Conclusion: 所提出的方法论能够有效地评估溶剂依赖性的机械行为，并为设计具有改进性能的螺旋折叠体提供了指导。

Abstract: Molecular-scale materials with bistable behavior and tunable properties are
increasingly relevant for next-generation nanoscale electronic devices. Helical
foldamers are promising candidates, but their structural and mechanical
properties are highly sensitive to conformational stability and environmental
conditions. A systematic methodology based on quantum-chemical calculations is
proposed for assessing solvent-dependent mechanical behavior, combining
analysis of $\pi-\pi$ stacking interactions, conformational energetics, and
environmental effects. Using this methodology we identified simple design
principles for the rapid screening of new compounds, allowing evaluation of
their conformational stability and effective mechanical rigidity. Applying
these principles, we identify a modified helical aromatic foldamer that
exhibits improved mechanical and stability characteristics compared to the
initial reference compound.

</details>


### [327] [Conductance Anomaly in a Partially Open Adiabatic Quantum Point Contact](https://arxiv.org/abs/2510.20678)
*Donghao Liu,Dmitri Gutman*

Main category: cond-mat.mes-hall

TL;DR: 部分开放的量子点接触中存在反散射，并通过电子相互作用产生奇异的电导修正，在通道半开放时达到最大值，导致电导降低。此外，垂直于自旋-轨道轴的磁场会引起法布里-珀罗型干涉和非单调磁场依赖性，从而产生电导振荡。


<details>
  <summary>Details</summary>
Motivation: 研究部分开放的量子点接触中由于反散射和电子相互作用引起的电导异常现象，并解释实验中观察到的异常特征。

Method: 分析了在干净、绝热的量子点接触中，当通道部分打开时，反散射如何通过电子相互作用产生奇异的电导修正，以及垂直磁场如何通过法布里-珀罗型干涉影响电导。

Result: 在部分开放的量子点接触中，反散射诱导的弗里德尔振荡通过电子相互作用产生奇异的电导修正，该修正量在通道半开放时最大化，导致电导降低。垂直磁场会引起电导振荡和非单调的磁场依赖性。

Conclusion: 电子相互作用提供了一种普遍的机制来改变理想的部分开放通道的电导，并可能解释实验中观察到的异常特征。

Abstract: We demonstrate that conductance anomalies can arise in a clean, adiabatic
quantum point contact when a channel is partially open. Even for a smooth
barrier potential, backscattering induces Friedel oscillations that, via
electron interactions, generate a singular correction to the conductance. This
correction is maximized when the channel is half-open, resulting in a reduction
of conductance. In addition, a magnetic field applied perpendicular to the
spin-orbit axis modifies the single-particle spectrum, resulting in conductance
oscillations via Fabry-P\'erot-type interference, as well as a non-monotonic
field dependence of the anomaly. Our findings reveal a universal mechanism by
which interactions modify the conductance of an ideal partially open channel
and offer a possible explanation for the anomalous features observed in
experiments.

</details>


### [328] [Anomalous Hall effect in rhombohedral graphene](https://arxiv.org/abs/2510.20804)
*Vera Mikheeva,Daniele Guerci,Daniel Kaplan,Elio J. König*

Main category: cond-mat.mes-hall

TL;DR: This paper calculates the anomalous Hall conductivity in rhombohedral stacked multilayer graphene with two types of impurities (weak/dense and sparse/strong) using the Kubo-Streda diagrammatic approach, considering various scattering processes and including warping effects.


<details>
  <summary>Details</summary>
Motivation: Recent experiments on rhombohedral stacked multilayer graphene and the observation of the anomalous Hall effect in a spontaneous spin-valley polarized quarter metal state.

Method: Kubo-Streda diagrammatic approach, considering weak dense impurities (Gaussian disorder, non-crossing diagrams, X and Psi diagrams) and sparse strong impurities (Mercedes star diagram, non-Gaussian skew scattering). Supplemented by semi-numerical calculations for warping effects.

Result: Calculation of anomalous Hall conductivity ($\sigma_{xy}$) for the described system and impurity types.

Conclusion: The paper provides an analysis of the anomalous Hall conductivity in a specific graphene system under different impurity conditions, using advanced theoretical methods.

Abstract: Motivated by recent experiments on rhombohedral stacked multilayer graphene
and the observation of the anomalous Hall effect in a spontaneous spin-valley
polarized quarter metal state, we calculate the anomalous Hall conductivity for
this system in the presence of two types of impurities: weak and dense as well
as sparse and strong. Our calculation of $\sigma_{xy}$ is based on the
Kubo-Streda diagrammatic approach. In a model with Gaussian disorder applicable
to weak dense impurities, this involves all non-crossing diagrams (intrinsic,
side-jump and Gaussian skew-scattering contributions) and additionally diagrams
with two intersecting impurities, X and $\Psi$, representing diffractive
skew-scattering processes. A "Mercedes star" diagram (non-Gaussian skew
scattering) is furthermore included to treat in the case of strong, sparse
impurities. We supplement our asymptotically exact analytical solutions for an
isotropic model without warping effects by semi-numerical calculations
accounting perturbatively for warping, which plays a crucial role in the
low-energy band structure.

</details>


### [329] [Charge-density waves and stripes in quarter metals of graphene heterostructures](https://arxiv.org/abs/2510.20816)
*Sk Asrap Murshed,Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 在手征堆叠的多层石墨烯中发现了具有新颖对称性的谷相干电荷密度波（VC-CDW）


<details>
  <summary>Details</summary>
Motivation: 近期的实验激发了对多层石墨烯中电荷密度波（CDW）行为的研究，特别是 VC-CDW 的出现。

Method: 文章利用了通用克利福德代数论证来推导 VC-CDW 和异常霍尔序的性质。

Result: 研究发现，VC-CDW 和异常霍尔序可以消除反铁磁性半金属的谷简并性，并且在 $2 
darray n 	extless 6$ 的系统中观察到了滞后现象。在四分之一金属中，VC-CDW 和异常霍尔序共存。

Conclusion: VC-CDW 是手征堆叠多层石墨烯中一种普遍存在的相，其对称性行为取决于层数 n 的奇偶性。VC-CDW 和异常霍尔序的共存为理解这些材料的电子特性提供了新的视角。

Abstract: Motivated by recent experiments, here we identify valley-coherent
charge-density wave (VC-CDW) order in the non-degenerate quarter-metal for the
entire family of chirally-stacked $n$ layer graphene, encompassing rhombohedral
multi-layer, Bernal bilayer, and monolayer cousins. Besides the hallmark broken
translational symmetry, yielding a modulated charge-density over an enlarged
unit-cell with a characteristic $2{\bf K}$ periodicity, where $\pm {\bf K}$ are
the valley momenta, this phase lacks the three-fold ($C_3$) rotational symmetry
but only for even integer $n$. The VC-CDW then represents a stripe order, as
observed in hexalayer graphene [arXiv:2504.05129], but preserves the $C_3$
symmetry for odd $n$ as observed in trilayer graphene [Nat. Phys. 20, 1413
(2024) and arXiv: 2411.11163]. From a universal Clifford algebraic argument, we
establish that the VC-CDW and an anomalous Hall order can lift the residual
valley degeneracy of an antiferromagnetically ordered spin-polarized
half-metal, when these systems are subject to perpendicular displacement
fields, with only the latter one displaying a hysteresis in off-diagonal
resistivity, as observed in all the systems with $2 \leq n \leq 6$. We showcase
a confluence of VC-CDW and anomalous Hall orders within the quarter-metal,
generically displaying a regime of coexistence, separating the pure phases.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [330] [Interactive Hypergraph Visual Analytics for Exploring Large and Complex Image Collections](https://arxiv.org/abs/2510.20050)
*Floris Gisolf,Zeno J. M. H. Geradts,Marcel Worring*

Main category: cs.GR

TL;DR: 提出了一种用于分析大型图像集合中图像间复杂关系的交互式可视化分析方法，通过构建和可视化超图来解决传统方法不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有聚类和分类方法难以表示图像间复杂的重叠关系，尤其是在缺乏标记数据或预训练模型的情况下。超图能捕捉重叠关系，但需要可视化才能供领域专家使用。

Method: 提出了一种交互式可视化分析方法，包括：1. 可扩展的超图构建流程，从原始图像数据生成超图，并提供相似度度量。2. 集成空间超图表示、交互式网格和矩阵的可视化技术，便于用户探索。3. 提供了领域专家如何有效使用该应用的实践见解。

Result: 该可视化分析方法能够促进迭代探索，帮助领域专家从包含数万张图像的图像集合中高效地提取信息。

Conclusion: 该方法能够有效地帮助领域专家从大型复杂图像集合中提取信息。

Abstract: Analyzing large complex image collections in domains like forensics, accident
investigation, or social media analysis involves interpreting intricate,
overlapping relationships among images. Traditional clustering and
classification methods fail to adequately represent these complex
relationships, particularly when labeled data or suitable pre-trained models
are unavailable. Hypergraphs effectively capture overlapping relationships, but
to translate their complexity into information and insights for domain expert
users visualization is essential. We propose an interactive visual analytics
approach specifically designed for the construction, exploration, and analysis
of hypergraphs on large-scale complex image collections. Our core contributions
include: (1) a scalable pipeline for constructing hypergraphs directly from raw
image data, including a similarity measure to evaluate constructed hypergraphs
against a ground truth, (2) interactive visualization techniques that integrate
spatial hypergraph representations, interactive grids, and matrix
visualizations, enabling users to dynamically explore and interpret
relationships without becoming overwhelmed and disoriented, and (3) practical
insights on how domain experts can effectively use the application, based on
evaluation with real-life image collections. Our results demonstrate that our
visual analytics approach facilitates iterative exploration, enabling domain
experts to efficiently derive insights from image collections containing tens
of thousands of images.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [331] [Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication](https://arxiv.org/abs/2510.19995)
*Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song*

Main category: cs.MA

TL;DR: C2C框架通过对齐因子(AF)和序列动作框架，在多智能体协作任务中提高了效率，将任务完成时间缩短了约40%。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM系统缺乏面向任务的系统化通信框架来支持复杂任务中的团队协作。

Method: 提出了一种名为“通信到完成”（C2C）的可扩展框架，该框架包含两个关键创新：1）对齐因子（AF），一个量化智能体任务对齐度的新指标；2）序列动作框架，将分步执行与智能通信决策相结合。

Result: 在不同复杂度和团队规模的现实编码工作流上评估C2C，结果显示与无通信和固定步骤基线相比，C2C将任务完成时间缩短了约40%，同时通信成本可接受，并且成功完成了所有任务。

Conclusion: C2C框架为衡量多智能体系统中通信的有效性提供了理论基础，并为复杂的协作任务提供了一个实用的框架。

Abstract: Teamwork in workspace for complex tasks requires diverse communication
strategies, but current multi-agent LLM systems lack systematic frameworks for
task oriented communication. We introduce Communication to Completion (C2C), a
scalable framework that addresses this gap through two key innovations: (1) the
Alignment Factor (AF), a novel metric quantifying agent task alignment that
directly impacts work efficiency, and (2) a Sequential Action Framework that
integrates stepwise execution with intelligent communication decisions. C2C
enables agents to make cost aware communication choices, dynamically improving
task understanding through targeted interactions. We evaluated C2C on realistic
coding workflows across three complexity tiers and team sizes from 5 to 17
agents, comparing against no communication and fixed steps baselines. The
results show that C2C reduces the task completion time by about 40% with
acceptable communication costs. The framework completes all tasks successfully
in standard configurations and maintains effectiveness at scale. C2C
establishes both a theoretical foundation for measuring communication
effectiveness in multi-agent systems and a practical framework for complex
collaborative tasks.

</details>


### [332] [High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning](https://arxiv.org/abs/2510.20218)
*Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen*

Main category: cs.MA

TL;DR: QCoFr框架通过持续分数函数和变分信息瓶颈来解决多智能体强化学习中高阶交互建模的组合爆炸和不透明性问题，实现了线性复杂度、更好的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习（MARL）中建模高阶交互所面临的组合爆炸和黑箱网络结构不透明的挑战。

Method: 提出了一种名为 Continued Fraction Q-Learning (QCoFr) 的新颖价值分解框架，该框架具有线性复杂度 $\mathcal{O}(n)$，并引入变分信息瓶颈来提取用于估计信用分配的潜在信息，以过滤噪声交互。

Result: QCoFr 在广泛的实验中持续 achieves 更好的性能，并提供与理论分析一致的可解释性。

Conclusion: QCoFr 框架能够灵活地捕捉任意阶的智能体交互，同时避免了组合爆炸，并通过变分信息瓶颈提高了可解释性。

Abstract: The ability to model interactions among agents is crucial for effective
coordination and understanding their cooperation mechanisms in multi-agent
reinforcement learning (MARL). However, previous efforts to model high-order
interactions have been primarily hindered by the combinatorial explosion or the
opaque nature of their black-box network structures. In this paper, we propose
a novel value decomposition framework, called Continued Fraction Q-Learning
(QCoFr), which can flexibly capture arbitrary-order agent interactions with
only linear complexity $\mathcal{O}\left({n}\right)$ in the number of agents,
thus avoiding the combinatorial explosion when modeling rich cooperation.
Furthermore, we introduce the variational information bottleneck to extract
latent information for estimating credits. This latent information helps agents
filter out noisy interactions, thereby significantly enhancing both cooperation
and interpretability. Extensive experiments demonstrate that QCoFr not only
consistently achieves better performance but also provides interpretability
that aligns with our theoretical analysis.

</details>


### [333] [Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks](https://arxiv.org/abs/2510.20469)
*Horacio Paggi,Juan A. Lara,Javier Soriano*

Main category: cs.MA

TL;DR: 信息融合已从传统的军事应用中的分层程序转变为更适合民用和边缘应用的整体融合。


<details>
  <summary>Details</summary>
Motivation: 随着信息融合在非军事领域的普及，以及人类-计算机和机器-机器通信的发展，需要更灵活的结构来处理资源限制和不确定性。因此，本研究旨在探讨在资源受限的情况下，信息融合如何生成整体结构。

Method: 研究基于多智能体系统模型，研究了在资源（能量、可用消息、时间等）受限的情况下，完全互联的元素（对等体）如何通过信息融合来优化消息交换中的模糊性和不确定性，并生成整体结构。最后通过一个实例展示了整体结构可能的操作方式。

Result: 研究表明，当资源受限时，信息融合倾向于生成整体结构。这种结构具有适应性、自主性和协作性等优点，能够应对环境或组成的变化，并在资源短缺或系统组件故障时提供通信或维持系统运行。

Conclusion: 整体结构在资源受限和不确定性环境下具有显著优势，能够提高系统的适应性、自主性和协作能力，为信息融合在民用和边缘应用中提供了新的范式。

Abstract: There has recently been a major advance with respect to how information
fusion is performed. Information fusion has gone from being conceived as a
purely hierarchical procedure, as is the case of traditional military
applications, to now being regarded collaboratively, as holonic fusion, which
is better suited for civil applications and edge organizations. The above
paradigm shift is being boosted as information fusion gains ground in different
non-military areas, and human-computer and machine-machine communications,
where holarchies, which are more flexible structures than ordinary, static
hierarchies, become more widespread. This paper focuses on showing how holonic
structures tend to be generated when there are constraints on resources
(energy, available messages, time, etc.) for interactions based on a set of
fully intercommunicating elements (peers) whose components fuse information as
a means of optimizing the impact of vagueness and uncertainty present message
exchanges. Holon formation is studied generically based on a multiagent system
model, and an example of its possible operation is shown. Holonic structures
have a series of advantages, such as adaptability, to sudden changes in the
environment or its composition, are somewhat autonomous and are capable of
cooperating in order to achieve a common goal. This can be useful when the
shortage of resources prevents communications or when the system components
start to fail.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [334] [HALOC-AxA: An Area/-Energy-Efficient Approximate Adder for Image Processing Application](https://arxiv.org/abs/2510.20137)
*Hasnain A. Ziad,Ashiq A. Sakib*

Main category: cs.AR

TL;DR: 设计了一种新型近似加法器，在保持或提高精度的同时，提高了能效和面积效率，并成功应用于图像处理任务。


<details>
  <summary>Details</summary>
Motivation: 为了在计算密集型多媒体应用（如图像、音频或视频处理）中实现高能效硬件，需要设计近似加法器来平衡性能、计算精度和能效之间的冲突。

Method: 提出了一种新型近似加法器。

Result: 所提出的加法器比现有的加法器更节能、更节省面积，同时在仿真结果中显示出更好的或可比的精度。该设计在图像处理任务中的应用进一步证明了其在数字重建高质量图像方面的能力。

Conclusion: 提出的新型近似加法器在能效、面积效率和精度方面优于现有设计，并可成功应用于图像处理等实际任务。

Abstract: The design of approximate adders has been widely researched to advance
energy-efficient hardware for computation-intensive multimedia applications,
such as image, audio, or video processing. The design of approximate adders has
been widely researched to advance energy-efficient hardware for computation
intensive multimedia applications, such as image/audio/video processing.
Several static and dynamic approximate adders exist in the literature, each of
which endeavors to balance the conflicting demands of high performance,
computational accuracy, and energy efficiency. This work introduces a novel
approximate adder that is more energy- and area-efficient than existing adders,
while achieving improved or comparable accuracy, as demonstrated by simulation
results. The proposed adder's ability to digitally reconstruct high quality
images is further demonstrated by the deployment of the design for an image
processing task.

</details>


### [335] [In-DRAM True Random Number Generation Using Simultaneous Multiple-Row Activation: An Experimental Study of Real DRAM Chips](https://arxiv.org/abs/2510.20269)
*Ismail Emir Yuksel,Ataberk Olgun,F. Nisa Bostanci,Oguzhan Canpolat,Geraldo F. Oliveira,Mohammad Sadrosadati,Abdullah Giray Yaglikci,Onur Mutlu*

Main category: cs.AR

TL;DR: 利用现有的DRAM芯片，通过同时激活多个行（SiMRA）来生成高质量的真随机数，该方法具有高吞吐量和低延迟的特点，并且通过了NIST统计测试。


<details>
  <summary>Details</summary>
Motivation: 在现有DRAM芯片上实现高吞吐量、低延迟的真随机数生成。

Method: 通过实验研究了在DRAM芯片上利用同时多行激活（SiMRA）技术生成真随机数的可行性，并分析了不同激活行数、数据模式、温度和空间变化对熵、延迟和吞吐量的影响。

Result: 11项关键实验观察结果，包括：1.所有基于SiMRA的TRNG设计均通过了NIST统计测试。2.与现有DRAM基TRNG相比，2、8、16和32行激活的TRNG设计在吞吐量上分别提高了1.15倍、1.99倍、1.82倍和1.39倍。3.SiMRA的熵随着同时激活的DRAM行数的增加而增加。4.操作参数和条件（如数据模式和温度）显著影响熵，例如，32行激活的平均熵是2行激活的2.51倍，而温度从50°C升至90°C会使32行激活的熵降低1.53倍。

Conclusion: SiMRA是一种在现有DRAM芯片上实现高吞吐量、低延迟真随机数生成的有效方法，其性能受到操作参数和条件的影响，但整体上具有优越性。

Abstract: In this work, we experimentally demonstrate that it is possible to generate
true random numbers at high throughput and low latency in commercial
off-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row
activation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We
rigorously analyze SiMRA's true random generation potential in terms of
entropy, latency, and throughput for varying numbers of simultaneously
activated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature
levels, and spatial variations. Among our 11 key experimental observations, we
highlight four key results. First, we evaluate the quality of our TRNG designs
using the commonly-used NIST statistical test suite for randomness and find
that all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,
16-, and 32-row activation-based TRNG designs outperform the state-of-theart
DRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,
respectively. Third, SiMRA's entropy tends to increase with the number of
simultaneously activated DRAM rows. Fourth, operational parameters and
conditions (e.g., data pattern and temperature) significantly affect entropy.
For example, for most of the tested modules, the average entropy of 32-row
activation is 2.51x higher than that of 2-row activation. For example,
increasing the temperature from 50{\deg}C to 90{\deg}C decreases SiMRA's
entropy by 1.53x for 32-row activation. To aid future research and development,
we open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.

</details>


### [336] [Squire: A General-Purpose Accelerator to Exploit Fine-Grain Parallelism on Dependency-Bound Kernels](https://arxiv.org/abs/2510.20400)
*Rubén Langarita,Jesús Alastruey-Benedé,Pablo Ibáñez-Marín,Santiago Marco-Sola,Miquel Moretó,Adrià Armejach*

Main category: cs.AR

TL;DR: Squire是一种通用加速器，通过利用低功耗处理器核心和直接的L2缓存访问，有效加速计算密集型、依赖性强（dependency-bound）的计算任务，在读取映射工具中实现了高达7.64倍的加速和56%的能效提升，同时面积开销最小。


<details>
  <summary>Details</summary>
Motivation: 现有的通用加速器（如SIMD、GPGPU）在处理具有复杂依赖关系的数据密集型内核时存在性能瓶颈，而FPGA和ASIC虽然性能高，但成本高且灵活性差。因此，需要一种能够有效利用细粒度并行性来加速依赖性强内核的通用加速器。

Method: 提出了一种名为Squire的通用加速器架构，其包含一组可快速通信并直接访问L2缓存的低功耗顺序执行（in-order）核心。将Squire集成到多核系统中，以最小的软件改动加速并行任务中的依赖性强内核。

Result: 通过加速五个实现复杂依赖关系的内核，Squire在动态规划内核上实现了高达7.64倍的加速。在对一个端到端的读取映射工具的评估中，Squire实现了3.66倍的整体加速，并将能耗降低了高达56%，同时面积开销仅为10.5%。

Conclusion: Squire是一种有效的通用加速器，能够出色地加速依赖性强（dependency-bound）的内核，在性能和能效方面均优于传统方法，且对现有系统的侵入性最小。

Abstract: Multiple HPC applications are often bottlenecked by compute-intensive kernels
implementing complex dependency patterns (data-dependency bound). Traditional
general-purpose accelerators struggle to effectively exploit fine-grain
parallelism due to limitations in implementing convoluted data-dependency
patterns (like SIMD) and overheads due to synchronization and data transfers
(like GPGPUs). In contrast, custom FPGA and ASIC designs offer improved
performance and energy efficiency at a high cost in hardware design and
programming complexity and often lack the flexibility to process different
workloads. We propose Squire, a general-purpose accelerator designed to exploit
fine-grain parallelism effectively on dependency-bound kernels. Each Squire
accelerator has a set of general-purpose low-power in-order cores that can
rapidly communicate among themselves and directly access data from the L2
cache. Our proposal integrates one Squire accelerator per core in a typical
multicore system, allowing the acceleration of dependency-bound kernels within
parallel tasks with minimal software changes. As a case study, we evaluate
Squire's effectiveness by accelerating five kernels that implement complex
dependency patterns. We use three of these kernels to build an end-to-end
read-mapping tool that will be used to evaluate Squire. Squire obtains speedups
up to 7.64$\times$ in dynamic programming kernels. Overall, Squire provides an
acceleration for an end-to-end application of 3.66$\times$. In addition, Squire
reduces energy consumption by up to 56% with a minimal area overhead of 10.5%
compared to a Neoverse-N1 baseline.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [337] [Optimized Distortion in Linear Social Choice](https://arxiv.org/abs/2510.20020)
*Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik*

Main category: cs.GT

TL;DR: 当选民对选项的偏好排序有潜在效用时，使用偏好排序可能会导致次优的功利社会福利结果。本文研究了线性效用函数的失真度，并提出了最小化失真度的算法。


<details>
  <summary>Details</summary>
Motivation: 在许多设置（例如价值对齐的常见范式）中，备选项承认向量表示，并且效用是其参数函数。然而，使用偏好排序可能会导致相对于功利社会福利的次优结果。失真度是这种次优化的度量，它为在效用具有最小结构的情况下开发和分析投票规则提供了一种最坏情况的方法。

Method: 研究了确定性和随机投票规则的线性社会选择的失真度。所得界限仅取决于候选人嵌入的维度，而与候选人或选民的数量无关。此外，还引入了用于在给定候选人和选票集合的情况下最小化失真度的多项式时间实例最优算法。

Result: 界限仅取决于候选人嵌入的维度，与候选人或选民的数量无关。在推荐系统和意见调查中，对几种标准规则与实例最优算法进行了基准测试。

Conclusion: 首次研究了线性效用函数的失真度，并为最小化失真度提供了实例最优算法。

Abstract: Social choice theory offers a wealth of approaches for selecting a candidate
on behalf of voters based on their reported preference rankings over options.
When voters have underlying utilities for these options, however, using
preference rankings may lead to suboptimal outcomes vis-\`a-vis utilitarian
social welfare. Distortion is a measure of this suboptimality, and provides a
worst-case approach for developing and analyzing voting rules when utilities
have minimal structure. However in many settings, such as common paradigms for
value alignment, alternatives admit a vector representation, and it is natural
to suppose that utilities are parametric functions thereof. We undertake the
first study of distortion for linear utility functions. Specifically, we
investigate the distortion of linear social choice for deterministic and
randomized voting rules. We obtain bounds that depend only on the dimension of
the candidate embedding, and are independent of the numbers of candidates or
voters. Additionally, we introduce poly-time instance-optimal algorithms for
minimizing distortion given a collection of candidates and votes. We
empirically evaluate these in two real-world domains: recommendation systems
using collaborative filtering embeddings, and opinion surveys utilizing
language model embeddings, benchmarking several standard rules against our
instance-optimal algorithms.

</details>


### [338] [Strategic Costs of Perceived Bias in Fair Selection](https://arxiv.org/abs/2510.20606)
*L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi*

Main category: cs.GT

TL;DR: Meritocratic systems perpetuate disparities due to differing perceived post-selection values, which influence individual effort choices. AI tools can exacerbate this. Modifying selectivity or perceived value can reduce disparities. The model links rational-choice and structural explanations of inequality.


<details>
  <summary>Details</summary>
Motivation: To understand how persistent disparities in meritocratic systems arise despite the aim of impartially rewarding skill and effort, considering factors like socioeconomic background and AI-powered tools.

Method: Developed a game-theoretic model where candidates from different socioeconomic groups have varying perceived post-selection values. Analyzed strategic effort choices, merit-based selection, and derived a unique Nash equilibrium in the large-agent limit. Proposed a cost-sensitive optimization framework.

Result: Derived explicit formulas showing how valuation disparities and institutional selectivity jointly determine effort, representation, social welfare, and utility. Revealed a perception-driven bias where differing perceptions of post-selection value lead to rational differences in effort, propagating disparities. Showed that modifying selectivity or perceived value can reduce disparities without compromising institutional goals.

Conclusion: Perception-driven biases in techno-social environments rationally influence individual effort in meritocratic systems, leading to persistent disparities. The model bridges rational-choice and structural explanations of inequality by demonstrating how these environments shape incentives.

Abstract: Meritocratic systems, from admissions to hiring, aim to impartially reward
skill and effort. Yet persistent disparities across race, gender, and class
challenge this ideal. Some attribute these gaps to structural inequality;
others to individual choice. We develop a game-theoretic model in which
candidates from different socioeconomic groups differ in their perceived
post-selection value--shaped by social context and, increasingly, by AI-powered
tools offering personalized career or salary guidance. Each candidate
strategically chooses effort, balancing its cost against expected reward;
effort translates into observable merit, and selection is based solely on
merit. We characterize the unique Nash equilibrium in the large-agent limit and
derive explicit formulas showing how valuation disparities and institutional
selectivity jointly determine effort, representation, social welfare, and
utility. We further propose a cost-sensitive optimization framework that
quantifies how modifying selectivity or perceived value can reduce disparities
without compromising institutional goals. Our analysis reveals a
perception-driven bias: when perceptions of post-selection value differ across
groups, these differences translate into rational differences in effort,
propagating disparities backward through otherwise "fair" selection processes.
While the model is static, it captures one stage of a broader feedback cycle
linking perceptions, incentives, and outcome--bridging rational-choice and
structural explanations of inequality by showing how techno-social environments
shape individual incentives in meritocratic systems.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [339] [Comparative Analysis of Thermal Models for Test Masses in Next-Generation Gravitational Wave Interferometers](https://arxiv.org/abs/2510.20338)
*Vincenzo Pierro,Vincenzo Fiumara,Guerino Avallone,Giovanni Carapella,Francesco Chiadini,Roberta De Simone,Rosalba Fittipaldi,Gerardo Iannone,Alessandro Magalotti,Enrico Silva,Veronica Granata*

Main category: physics.app-ph

TL;DR: 未来引力波干涉仪（如Virgo）需要精确的热学模型来优化终端测试质量块（TTMs）的灵敏度。即使微小的激光功率吸收也会引起限制性能的热效应。本文研究了TTMs的稳态热行为，特别是考虑了未来激光功率和光学涂层吸收增加的场景。我们开发并比较了两种数值模型：一种是包含多层涂层和基底体积吸热的综合模型；另一种是简化的模型，将涂层的热影响表示为基底上的有效表面边界条件。我们的模拟集中在一种用于下一代探测器的三元涂层设计上。结果表明，较高的涂层吸收会使最高温度集中在涂层-真空界面附近。更重要的是，比较分析表明，简化模型与详细模型在温度预测上的差异仅为毫开尔文，这通常在系统热物理参数的实验不确定性范围内。这表明，计算效率高的简化模型足以用于热管理和一阶畸变分析。此外，还强调了精确表征涂层总吸收功率的关键作用。


<details>
  <summary>Details</summary>
Motivation: 引力波探测器（如Virgo）的灵敏度优化需要精确的TTMs热学模型，因为微小的激光功率吸收会引起性能限制。本文旨在研究TTMs的稳态热行为，并考虑未来激光功率和光学涂层吸收增加的场景。

Method: 本文开发并比较了两种数值模型：一种是包含多层涂层和基底体积吸热的综合模型；另一种是简化的模型，将涂层的热影响表示为基底上的有效表面边界条件。模拟集中在一种用于下一代探测器的三元涂层设计上。

Result: 结果表明，较高的涂层吸收会使最高温度集中在涂层-真空界面附近。简化模型与详细模型在温度预测上的差异仅为毫开尔文，该差异通常在系统热物理参数的实验不确定性范围内。

Conclusion: 计算效率高的简化模型足以用于热管理和一阶畸变分析。精确表征涂层总吸收功率至关重要。

Abstract: Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for
optimizing the sensitivity of gravitational wave interferometers like Virgo. In
fact, in such gravitational wave detectors even minimal laser power absorption
can induce performance-limiting thermal effects. This paper presents a detailed
investigation into the steady-state thermal behavior of TTMs. In particular,
future scenarios of increased intracavity laser beam power and optical coating
absorption are considered. We develop and compare two numerical models: a
comprehensive model incorporating volumetric heat absorption in both the
multilayer coating and the bulk substrate, and a simplified reduced model where
the coating's thermal impact is represented as an effective surface boundary
condition on the substrate. Our simulations were focused on a ternary coating
design, which is a candidate for use in next-generation detectors. Results
reveal that higher coating absorption localizes peak temperatures near the
coating--vacuum interface. Importantly, the comparative analysis demonstrates
that temperature predictions from the reduced model differ from the detailed
model by only milli-Kelvins, a discrepancy often within the experimental
uncertainties of the system's thermo-physical parameters. This finding suggests
that computationally efficient reduced models can provide sufficiently accurate
results for thermal management and first-order distortion analyses. Moreover,
the critical role of accurately characterizing the total power absorbed by the
coating is emphasized.

</details>


### [340] [Multi-Task Deep Learning for Surface Metrology](https://arxiv.org/abs/2510.20339)
*D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz*

Main category: physics.app-ph

TL;DR: 提出了一个用于表面计量学的可复现的深度学习框架，可以预测表面纹理参数及其报告的标准不确定度。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够预测表面纹理参数（如Ra、Rz、RONt）及其不确定度的深度学习框架，以解决表面计量学中的挑战。

Method: 使用跨越接触式和光学系统的多仪器数据集，解决了测量系统类型分类问题，并对Ra、Rz、RONt及其不确定度目标（Ra_uncert、Rz_uncert、RONt_uncert）进行协同回归。通过分位数和异方差预测头以及事后一致性校准来模拟不确定度，以获得校准后的区间。单独训练的模型在预测Ra、Rz和RONt时表现更好，而RONt_uncert的预测仍然困难。

Result: 在独立测试集上，单一目标回归器实现了高保真度（R2：Ra 0.9824，Rz 0.9847，RONt 0.9918），其中两个不确定性目标（Ra_uncert 0.9899，Rz_uncert 0.9955）也得到了很好的模拟；RONt_uncert仍然难以预测（R2 0.4934）。分类器达到了92.85%的准确率，并且在温度缩放后，概率校准基本保持不变（测试集上的ECE从0.00504变为0.00503）。观察到简单的多输出模型存在负迁移现象，单一目标模型表现更优。

Conclusion: 该深度学习框架能够对表面纹理参数及其不确定度进行校准预测，可为计量工作流程中的仪器选择和验收决策提供信息。

Abstract: A reproducible deep learning framework is presented for surface metrology to
predict surface texture parameters together with their reported standard
uncertainties. Using a multi-instrument dataset spanning tactile and optical
systems, measurement system type classification is addressed alongside
coordinated regression of Ra, Rz, RONt and their uncertainty targets
(Ra_uncert, Rz_uncert, RONt_uncert). Uncertainty is modelled via quantile and
heteroscedastic heads with post-hoc conformal calibration to yield calibrated
intervals. On a held-out set, high fidelity was achieved by single-target
regressors (R2: Ra 0.9824, Rz 0.9847, RONt 0.9918), with two uncertainty
targets also well modelled (Ra_uncert 0.9899, Rz_uncert 0.9955); RONt_uncert
remained difficult (R2 0.4934). The classifier reached 92.85% accuracy and
probability calibration was essentially unchanged after temperature scaling
(ECE 0.00504 -> 0.00503 on the test split). Negative transfer was observed for
naive multi-output trunks, with single-target models performing better. These
results provide calibrated predictions suitable to inform instrument selection
and acceptance decisions in metrological workflows.

</details>


### [341] [Basic considerations in the design of an electrostatic electron monochromator](https://arxiv.org/abs/2510.20517)
*M. J. Adriaans,J. H. P. Hoogenboom,A. Mohammadi-Gheidari*

Main category: physics.app-ph

TL;DR: 提出了一种基于纯粹边缘场的新型电子显微镜单色器设计，成本更低，操作更简单。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜和光谱仪中使用的单色仪在提高空间和能量分辨率方面至关重要，但由于成本高昂且操作复杂，其在扫描电子显微镜中的应用受到限制。

Method: 通过对静电均匀场偏转器的薄偏转器分析，证明了当前单色仪对电源漂移和机械缺陷的敏感性。 随后，提出了一种基于纯边缘场的新型单色仪设计方法，该方法对这些问题不那么敏感，并且不需要额外的校正元件。 通过在主偏转器周围包含瞬时减速透镜来实现最佳能量分辨率。

Result: 与需要额外校正元件以实现最佳能量分辨率的传统单色仪相比，所提出的基于边缘场的方法对电源漂移和机械缺陷不那么敏感，从而降低了成本和复杂性。

Conclusion: 一种基于纯边缘场的新型单色仪设计被提出，这种设计成本低廉、操作简单，并且通过包含瞬时减速透镜避免了对额外校正元件的需求，有望通过 MEMS 技术实现，从而使单色仪在电子显微镜中更容易获得。

Abstract: Monochromators are an essential component in electron microscopy and
spectroscopy for enhancing the spatial and energy resolution. However, its
adoption in scanning electron microscopes remains limited because of its high
cost and operational complexity. Through a thin-deflector analysis of an
electrostatic homogeneous-field deflector, the extreme sensitivity of current
monochromators to power supply drift and mechanical imperfections is
demonstrated. These stringent alignment requirements for achieving optimal
energy resolution often necessitate the use of additional correcting elements,
adding to both cost and complexity. We demonstrate that the fringe-field
deflector is instead less sensitive to these issues. Hence, a cost effective
and simple monochromator design approach based on pure fringe fields is
proposed. This monochromator does not need extra correcting elements and its
optimal energy resolution is achieved by including momentary deceleration
lenses surrounding the main deflector. This fully electrostatic design could be
realized using MEMS technology, offering a simpler and more accessible approach
for filtering beam energies.

</details>


### [342] [Real-time dynamics of VCMA-assisted switching of magnetic tunnel junctions](https://arxiv.org/abs/2510.20701)
*Marco Hoffmann,Shaohai Chen,Gunasheel Kauwtilyaa Krishnaswamy,Hang Khume Tan,Sherry L. K. Yap,James Lourembam,Anjan Soumyanarayanan,Pietro Gambardella*

Main category: physics.app-ph

TL;DR: 通过磁场弛豫研究了电压控制磁各向异性（VCMA）辅助磁隧结开关的实时动力学。


<details>
  <summary>Details</summary>
Motivation: 研究VCMA辅助开关的实时动力学，以了解影响开关速度的因素。

Method: 通过磁场弛豫研究VCMA辅助开关的实时动力学，并进行微磁模拟。

Result: 器件依赖的充电效应和自由层的磁性晶粒限制了开关速度，但增加电压或磁场可将开关时间缩短至几纳秒以内。微磁模拟能够重现实验结果。

Conclusion: 器件充电时间和磁性晶粒是影响VCMA开关速度的关键因素，通过优化电压和磁场可以提高开关速度，为存储器和逻辑应用提供优化VCMA驱动磁化控制的见解。

Abstract: Voltage control of magnetic anisotropy (VCMA) induced by charge accumulation
is typically considered as an ultrafast process, enabling energy-efficient and
high-speed magnetization switching in spintronic devices. In this work, we
investigate the real-time dynamics of VCMA-assisted switching of magnetic
tunnel junctions via relaxation in a magnetic field. We show that
device-dependent charging effects and magnetic granularity in the free layer
limit the switching speed at applied voltages close to the critical switching
threshold. Increasing the voltage or the applied magnetic field reduces the
incubation delay and total switching time to below a few ns. Micromagnetic
simulations incorporating the finite charging times of the tunnel junction and
the granularity of the magnetic film reproduce the experimental results,
providing critical insights into optimizing VCMA-driven magnetization control
for memory and logic applications.

</details>


### [343] [Magnetic tunnel junction as a real-time entropy source: Field-Programmable Gate Array based random bit generation without post-processing](https://arxiv.org/abs/2510.20735)
*Troy Criss,Ahmed Sidi El Valli,Naomi Li,Andrew Haas,Andrew D. Kent*

Main category: physics.app-ph

TL;DR: 通过FPGA实现的磁隧道结驱动，生成了应用程序就绪的真随机比特流，速率达5Mb/s，无需后处理。


<details>
  <summary>Details</summary>
Motivation: 为了实现快速可靠的真随机数生成，以满足加密应用、随机硬件加速器、概率计算和大尺度建模等领域的需求。

Method: 利用FPGA实现实时反馈回路，将磁隧道结的切换概率稳定在50%附近，并进行XOR操作以消除短期相关性、长期漂移和偏差。

Result: 实现了速率为5Mb/s、符合NIST标准的真随机比特生成，无需后处理。

Conclusion: 该方法提供了一种实用的硬件解决方案，用于快速、可靠的真随机数生成，并为其他需要实时无偏随机性的应用领域开辟了新机会。

Abstract: We demonstrate a method to generate application-ready truly random bits from
a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We
implement a real-time feedback loop that stabilizes the switching probability
near 50\% and apply an XOR operation, both on the FPGA, to suppress short-term
correlations, together mitigating long-term drift and bias in the bitstream.
This combined approach enables NIST-compliant random bit generation at 5~Mb/s
without post-processing, providing a practical hardware solution for fast and
reliable true random number generation. Beyond cryptographic applications,
these capabilities open opportunities for stochastic hardware accelerators,
probabilistic computing, and large-scale modeling where real-time access to
unbiased randomness is essential.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [344] [SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks](https://arxiv.org/abs/2510.19829)
*Meghna Roy Chowdhury,Yi Ding,Shreyas Sen*

Main category: eess.SP

TL;DR: SSL-SE-EEG是一个结合了自监督学习（SSL）和Squeeze-Excitation网络（SE-Nets）的框架，通过将EEG信号转换为2D图像表示，提高了特征提取、噪声鲁棒性和对标签数据的依赖性，并在多个数据集上实现了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: EEG在脑机接口（BCI）和神经诊断学中至关重要，但在实际应用中面临噪声伪影、数据缺失和高昂的标注成本等挑战。

Method: SSL-SE-EEG框架将EEG信号转换为适合深度学习的结构化2D图像表示，并整合了自监督学习（SSL）和Squeeze-Excitation网络（SE-Nets）来增强特征提取、提高噪声鲁棒性并减少对标记数据的依赖。

Result: 在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上的实验验证显示，SSL-SE-EEG实现了最先进的准确率（MindBigData上为91%，TUH-AB上为85%），适用于实时BCI应用。

Conclusion: SSL-SE-EEG通过实现低功耗、可扩展的EEG处理，为生物医学信号分析、神经工程和下一代BCI提供了一个有前途的解决方案。

Abstract: Electroencephalography (EEG) plays a crucial role in brain-computer
interfaces (BCIs) and neurological diagnostics, but its real-world deployment
faces challenges due to noise artifacts, missing data, and high annotation
costs. We introduce SSL-SE-EEG, a framework that integrates Self-Supervised
Learning (SSL) with Squeeze-and-Excitation Networks (SE-Nets) to enhance
feature extraction, improve noise robustness, and reduce reliance on labeled
data. Unlike conventional EEG processing techniques, SSL-SE-EEG} transforms EEG
signals into structured 2D image representations, suitable for deep learning.
Experimental validation on MindBigData, TUH-AB, SEED-IV and BCI-IV datasets
demonstrates state-of-the-art accuracy (91% in MindBigData, 85% in TUH-AB),
making it well-suited for real-time BCI applications. By enabling low-power,
scalable EEG processing, SSL-SE-EEG presents a promising solution for
biomedical signal analysis, neural engineering, and next-generation BCIs.

</details>


### [345] [Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals](https://arxiv.org/abs/2510.19832)
*Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee*

Main category: eess.SP

TL;DR: 本研究展示了如何结合先进的机器学习和信息丰富的脑电图(EEG)特征提取，在便携式边缘设备上实现实时、高精度的神经解码，从而克服了非侵入式BCI的局限性。


<details>
  <summary>Details</summary>
Motivation: 为解决有严重运动或言语障碍的个体恢复交流能力，并克服侵入式BCI（如ECoG）的手术风险和非侵入式BCI（如EEG）的低精度问题。

Method: 使用32通道EEG数据集，对15名参与者进行想象手写任务。对信号进行带通滤波和伪迹子空间重建预处理，提取85个时域、频域和图论域特征。构建了一个名为EEdGeNet的混合模型，该模型整合了时间卷积网络和多层感知器，并在提取的特征上进行训练。

Result: 在NVIDIA Jetson TX2上部署时，该系统实现了89.83%的准确率，每字符延迟为914.18毫秒。通过仅选择十个关键特征，延迟减少了4.5倍（至202.6毫秒），准确率损失不到1%。

Conclusion: 研究结果为实现精确、低延迟、完全便携且支持实时通信的非侵入式BCI铺平了道路。

Abstract: Brain-computer interfaces (BCIs) offer a pathway to restore communication for
individuals with severe motor or speech impairments. Imagined handwriting
provides an intuitive paradigm for character-level neural decoding, bridging
the gap between human intention and digital communication. While invasive
approaches such as electrocorticography (ECoG) achieve high accuracy, their
surgical risks limit widespread adoption. Non-invasive electroencephalography
(EEG) offers safer and more scalable alternatives but suffers from low
signal-to-noise ratio and spatial resolution, constraining its decoding
precision. This work demonstrates that advanced machine learning combined with
informative EEG feature extraction can overcome these barriers, enabling
real-time, high-accuracy neural decoding on portable edge devices. A 32-channel
EEG dataset was collected from fifteen participants performing imagined
handwriting. Signals were preprocessed with bandpass filtering and artifact
subspace reconstruction, followed by extraction of 85 time-, frequency-, and
graphical-domain features. A hybrid architecture, EEdGeNet, integrates a
Temporal Convolutional Network with a multilayer perceptron trained on the
extracted features. When deployed on an NVIDIA Jetson TX2, the system achieved
89.83 percent accuracy with 914.18 ms per-character latency. Selecting only ten
key features reduced latency by 4.5 times to 202.6 ms with less than 1 percent
loss in accuracy. These results establish a pathway for accurate, low-latency,
and fully portable non-invasive BCIs supporting real-time communication.

</details>


### [346] [MATLAB-Simulated Dataset for Automatic Modulation Classification in Wireless Fading Channels](https://arxiv.org/abs/2510.19985)
*M. M. Sadman Shafi,Tasnia Siddiqua Ahona,Ashraful Islam Mridha*

Main category: eess.SP

TL;DR: 本论文提出了一个用于无线调制分类的合成数据集，该数据集考虑了真实的传播场景和多种调制方式，旨在为机器学习模型提供一个有价值的基准。


<details>
  <summary>Details</summary>
Motivation: 在认知无线电、自适应通信和频谱分析等领域，尤其是在没有发射机知识的动态信道下，准确的调制分类是一个核心挑战。

Method: 通过在MATLAB中生成带有BPSK、QPSK、16-QAM、64-QAM和256-QAM五种数字调制方案的随机比特流信号，并在瑞利和莱斯衰落信道下添加附加损伤，创建了一个包含1000个符号的合成数据集。该数据集提取了包括统计、时域、频域、频谱图、频谱相关和图像处理（BRISK、MSER、GLCM）在内的多种特征，并组织成10个CSV文件，涵盖两种信道类型和五种采样频率。此外，还提供了信号生成和特征提取的MATLAB脚本。

Result: 生成了一个包含五种数字调制方案（BPSK、QPSK、16-QAM、64-QAM、256-QAM）的合成数据集，该数据集考虑了瑞利和莱斯衰落信道、不同采样频率（1MHz、10MHz、100MHz、500MHz、1GHz）以及多种信号损伤，并提取了全面的特征集。

Conclusion: 本数据集为开发和评估调制分类、信号识别和无线通信研究中的机器学习模型提供了一个有价值的基准，并提供了相关的MATLAB脚本以促进可重复性和进一步的实验。

Abstract: Accurate modulation classification is a core challenge in cognitive radio,
adaptive communications, spectrum analysis, and related domains, especially
under dynamic channels without transmitter knowledge. To address this need,
this article presents a labeled synthetic dataset designed for wireless
modulation classification under realistic propagation scenarios. The signals
were generated in MATLAB by modulating randomly generated bitstreams using five
digital modulation schemes: BPSK, QPSK, 16-QAM, 64-QAM, and 256-QAM. These
signals were then transmitted through Rayleigh and Rician fading channels with
standardized parameters, along with additional impairments to enhance realism
and diversity. Each modulated signal contains 1000 symbols. A comprehensive set
of features was extracted from the signals, encompassing statistical,
time-domain, frequency-domain, spectrogram-based, spectral correlation-based,
and image-processing-based descriptors such as BRISK, MSER, and GLCM. The
dataset is organized into 10 CSV files covering two channel types (Rayleigh and
Rician) across five sampling frequencies: 1 MHz, 10 MHz, 100 MHz, 500 MHz, and
1 GHz. To facilitate reproducibility and encourage further experimentation, the
MATLAB scripts used for signal generation and feature extraction are also
provided. This dataset serves as a valuable benchmark for developing and
evaluating machine learning models in modulation classification, signal
identification, and wireless communication research.

</details>


### [347] [NanoHydra: Energy-Efficient Time-Series Classification at the Edge](https://arxiv.org/abs/2510.20038)
*Cristian Cioflan,Jose Fonseca,Xiaying Wang,Luca Benini*

Main category: eess.SP

TL;DR: NanoHydra是一个用于极端边缘设备的TinyML时间序列分类方法，它使用轻量级的二元随机卷积核来提取特征，在GAP9微控制器上实现了高达94.47%的准确率，并且能耗低，适合可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的极端边缘设备上实现高效的时间序列分类（TSC），以支持用户隐私和实时预测，同时延长电池寿命。

Method: 提出NanoHydra方法，利用轻量级二元随机卷积核提取特征，并在GAP9微控制器的八核集群上并行执行计算密集型任务。

Result: 在ECG5000数据集上实现了高达94.47%的分类准确率，分类1秒长ECG信号仅需0.33毫秒，每次推理能耗为7.69 uJ，比现有技术效率高18倍。

Conclusion: NanoHydra方法在能耗和效率方面表现出色，非常适合智能可穿戴设备，可将设备寿命延长至四年以上。

Abstract: Time series classification (TSC) on extreme edge devices represents a
stepping stone towards intelligent sensor nodes that preserve user privacy and
offer real-time predictions. Resource-constrained devices require efficient
TinyML algorithms that prolong the device lifetime of battery-operated devices
without compromising the classification accuracy. We introduce NanoHydra, a
TinyML TSC methodology relying on lightweight binary random convolutional
kernels to extract meaningful features from data streams. We demonstrate our
system on the ultra-low-power GAP9 microcontroller, exploiting its eight-core
cluster for the parallel execution of computationally intensive tasks. We
achieve a classification accuracy of up to 94.47% on ECG5000 dataset,
comparable with state-of-the-art works. Our efficient NanoHydra requires only
0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy
consumption of 7.69 uJ per inference, 18x more efficient than the
state-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a
device lifetime of over four years.

</details>


### [348] [Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios](https://arxiv.org/abs/2510.20067)
*Maximilian H. V. Tillmann,Avinash Kankari,Carsten Bockelmann,Armin Dekorsy*

Main category: eess.SP

TL;DR: 本文提出了一种用于多用户场景下并发任务执行和数据重建的语义通信系统，并通过最大化互信息来解决此问题。研究了两种目标之间的权衡，并表明在特定假设下，SSIM损失可以从互信息最大化目标中获得，该目标考虑了人类的视觉感知。最后，证明了在恒定资源消耗下，通过增加重建目标的权重，可以在保持任务执行性能基本不变的情况下，显著提高数据重建的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的语义通信研究主要集中在任务执行或数据重建，或两者的结合。本文旨在提出一个适用于多用户场景的、能够同时进行任务执行和数据重建的语义通信系统。

Method: 提出了一种新的语义通信系统，用于多用户场景下的并发任务执行和数据重建。该系统被表述为最大化互信息的问题。通过将任务执行和数据重建构建为一个联合目标（作为两者目标的凸组合）来研究两者之间的权衡。推导了在特定假设下，数据重建的互信息最大化目标可以得到SSIM损失。

Result: 研究表明，SSIM损失可以从互信息最大化目标中获得，这考虑了人类的视觉感知。此外，在资源恒定的情况下，通过增加重建目标的权重，可以显著提高数据重建的质量，同时保持任务执行的性能几乎不变。

Conclusion: 本文提出的语义通信系统能够有效地在多用户场景下同时处理任务执行和数据重建，并且通过调整权重可以实现两者之间的权衡，以满足不同的需求。SSIM损失的引入考虑了人类视觉感知的因素，使重建质量更加符合实际应用需求。

Abstract: Semantic communication has gained significant attention with the advances in
machine learning. Most semantic communication works focus on either task
execution or data reconstruction, with some recent works combining the two. In
this work, we propose a semantic communication system for concurrent task
execution and data reconstruction for a multi-user scenario, which we formulate
as the maximization of mutual information. To investigate the trade-off between
the two objectives, we formulate a joint objective as a convex combination of
task execution and data reconstruction. We show that under specific
assumptions, the \ac{SSIM} loss can be obtained from the mutual information
maximization objective for data reconstruction, which takes human visual
perception into account. Furthermore, for constant resource use, we show that
by increasing the weight of the reconstruction objective up to a certain point,
the task execution performance can be kept nearly constant, while the data
reconstruction can be significantly improved.

</details>


### [349] [RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling](https://arxiv.org/abs/2510.20088)
*Tawfik Osman,Aditya S. Shekhawat,Abhradeep Roy,Georgios C. Trichopoulos,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 通过设计、实现和评估一个基于RIS的O-RAN 5G系统，在FR2毫米波频段，证明了RIS可以显著提高信号覆盖和用户设备信噪比，并提出了用于UE移动性的联合波束管理算法。


<details>
  <summary>Details</summary>
Motivation: 为了增强信号覆盖和/或提高用户设备的信噪比，需要研究可重构智能表面（RIS）在O-RAN 5G系统中的应用。

Method: 设计了一个1024单元（32x32）的1比特RIS，工作在28 GHz频段，采用模块化可扩展的平铺架构。利用O-RAN E2接口动态控制RIS配置，并开发了两种UE移动性管理算法，通过UE接收的信号功率联合实时跟踪和调整RIS和UE的波束。

Result: 在室内和室外环境中进行了实地试验，结果显示RIS在室内和室外分别提供了9-20 dB和6-18 dB的接收信号功率增益。所提出的UE移动性管理算法在RIS O-RAN测试台中进行了实时评估。

Conclusion: 将RIS集成到O-RAN系统中，可以为下一代蜂窝网络提供增强的覆盖、移动性支持和链路可靠性，具有实际可行性。

Abstract: Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves
to desired directions to enhance signal coverage and/or improve signal-to-noise
ratio (SNR) at the user equipment (UE). We present the design, implementation,
and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2
millimeter wave (mmWave) frequency band. We first introduce the design of 1,024
element (32 $\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a
modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2
interface can be leveraged to dynamically control RIS configurations without
modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G
system, we conducted extensive field trials in both indoor and outdoor
environments. The results of the O-RAN link coverage trials show that the
deployed RIS provides substantial received signal power gains, ranging from 9
to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively.
Handling UE mobility in RIS-assisted systems is challenging due to the need for
joint RIS and UE beam management. For that, we develop two UE mobility
management algorithms and evaluate them in real-time operation using the RIS
O-RAN testbed. These algorithms leverage the received signal power at the UE to
jointly track and adapt the RIS and UE beams in real time as the UE moves. The
findings draw important insights into the practical feasibility of integrating
RIS into O-RAN systems to enhance coverage, mobility support, and link
reliability in next-generation cellular networks.

</details>


### [350] [Signal Design for OTFS Dual-Functional Radar and Communications with Imperfect CSI](https://arxiv.org/abs/2510.20112)
*Borui Du,Yumeng Zhang,Christos Masouros,Bruno Clerckx*

Main category: eess.SP

TL;DR: OTFS在双功能雷达通信（DFRC）中具有潜力，但其信号设计未被充分探索。本文提出了一种优化方法，同时设计了用于信道估计的导频符号和数据功率分配，以最大化感知和通信指标的加权和。仿真结果表明，该方法在ISL抑制和SINR方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有OTFS在DFRC中的应用，尤其是在信号设计方面，尚未得到充分研究，存在优化空间。

Method: 本文提出了一种针对DFRC-OTFS的信号设计优化问题，该问题同时考虑了用于信道估计的导频符号设计和数据功率分配。利用模糊函数的综合旁瓣电平（ISL）作为雷达指标，并考虑了数据符号的随机性。同时，为通信推导了一个考虑OTFS信道估计误差的信道容量下界指标。通过交替优化框架来解决该优化问题，以最大化感知和通信指标的加权和。

Result: 仿真结果表明，所提出的信号设计在ISL抑制方面比传统方案至少有9.44 dB的增益，在通信SINR方面至少有4.82 dB的增益，显著改善了感知-通信性能区域。

Conclusion: 本文提出的信号设计方法能有效提升OTFS在DFRC系统中的综合性能，为该领域的研究提供了新的方向。

Abstract: Orthogonal time frequency space (OTFS) offers significant advantages in
managing mobility for both wireless sensing and communication systems, making
it a promising candidate for dual-functional radar-communication (DFRC).
However, the optimal signal design that fully exploits OTFS's potential in DFRC
has not been sufficiently explored. This paper addresses this gap by
formulating an optimization problem for signal design in DFRC-OTFS,
incorporating both pilot-symbol design for channel estimation and data-power
allocation. Specifically, we employ the integrated sidelobe level (ISL) of the
ambiguity function as a radar metric, accounting for the randomness of the data
symbols alongside the deterministic pilot symbols. For communication, we derive
a channel capacity lower bound metric that considers channel estimation errors
in OTFS. We maximize the weighted sum of sensing and communication metrics and
solve the optimization problem via an alternating optimization framework.
Simulations indicate that the proposed signal significantly improves the
sensing-communication performance region compared with conventional signal
schemes, achieving at least a 9.44 dB gain in ISL suppression for sensing, and
a 4.82 dB gain in the signal-to-interference-plus-noise ratio (SINR) for
communication.

</details>


### [351] [Active Localization of Close-range Adversarial Acoustic Sources for Underwater Data Center Surveillance](https://arxiv.org/abs/2510.20122)
*Adnan Abdullah,David Blow,Sara Rampazzi,Md Jahidul Islam*

Main category: eess.SP

TL;DR: 该研究提出了一种用于定位和跟踪水下数据中心声学注入攻击源的框架，结合了固定和移动水听器，并采用了一种新颖的LC-MAP和UKF相结合的方法，在模拟和实际测试中均取得了优异的定位精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 水下数据中心虽然具有自然冷却和物理安全优势，但易受声学注入攻击，威胁数据完整性和可用性。因此，需要一种有效的机制来检测和应对此类攻击。

Method: 提出了一种异构接收器配置，包括固定水听器和部署在机器人上的移动水听器。设计了一种新颖的Locus-Conditioned Maximum A-Posteriori (LC-MAP) 方案，用于生成声学信息和几何一致的先验，为联合TDOA/FDOA滤波提供物理上合理的初始状态。该方案与无味卡尔曼滤波（UKF）相结合，以处理非线性和测量噪声。

Result: 该框架能够实时可靠地估计敌对声源的三维位置和速度，实现了米级以下的定位精度和超过90%的成功率，并且收敛时间缩短了近一半。

Conclusion: 该研究成功地建立了一种面向几何、实时的声学威胁定位方法，提高了水下基础设施的自主监控能力。

Abstract: Underwater data infrastructures offer natural cooling and enhanced physical
security compared to terrestrial facilities, but are susceptible to acoustic
injection attacks that can disrupt data integrity and availability. This work
presents a comprehensive surveillance framework for localizing and tracking
close-range adversarial acoustic sources targeting offshore infrastructures,
particularly underwater data centers (UDCs). We propose a heterogeneous
receiver configuration comprising a fixed hydrophone mounted on the facility
and a mobile hydrophone deployed on a dedicated surveillance robot. While using
enough arrays of static hydrophones covering large infrastructures is not
feasible in practice, off-the-shelf approaches based on time difference of
arrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to
generalize for this dynamic configuration. To address this, we formulate a
Locus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically
informed and geometrically consistent priors, ensuring a physically plausible
initial state for a joint TDOA-FDOA filtering. We integrate this into an
unscented Kalman filtering (UKF) pipeline, which provides reliable convergence
under nonlinearity and measurement noise. Extensive Monte Carlo analyses,
Gazebo-based physics simulations, and field trials demonstrate that the
proposed framework can reliably estimate the 3D position and velocity of an
adversarial acoustic attack source in real time. It achieves sub-meter
localization accuracy and over 90% success rates, with convergence times nearly
halved compared to baseline methods. Overall, this study establishes a
geometry-aware, real-time approach for acoustic threat localization, advancing
autonomous surveillance capabilities of underwater infrastructures.

</details>


### [352] [Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception](https://arxiv.org/abs/2510.20140)
*Jiangong Chen,Xia Lei,Kaitao Meng,Kawon Han,Yuchen Zhang,Christos Masouros,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 本论文提出了一种在近场集成传感与通信（ISAC）场景下，利用已知散射体进行传感安全对抗的定位欺骗（LD）方案，以欺骗敌方窃听者，使其误判散射体为目标，从而提高通信和传感的安全性。


<details>
  <summary>Details</summary>
Motivation: 在近场ISAC场景下，利用已知散射体，提出一种定位欺骗（LD）方案，以提升传感安全，实现通信、传感和传感安全性能之间的权衡。

Method: 利用已知散射体，通过提高对散射体的探测功率来欺骗窃听者，使其误将散射体识别为目标。通过分数规划（FP）和半定松弛（SDR）技术，在满足合法雷达信号与干扰加噪声比（SINR）约束的条件下，最大化加权后的和速率和分配给散射体的功率。使用Cramer-Rao界（CRB）和均方误差（MSE）来评估安全性，并引入Kullback-Leibler散度（KLD）差距来量化LD框架对窃听者传感性能的影响。

Result: 仿真结果表明，所提出的LD方案能够根据性能需求灵活调整波束成形策略，实现通信、传感和传感安全性能的权衡。该方案显著增强了窃听者端的杂波信号强度，导致其对实际目标的识别产生混淆甚至漏检。

Conclusion: 所提出的LD方案能够有效地在近场ISAC场景下提升传感安全性，通过欺骗窃听者，实现通信、传感和传感安全性能之间的灵活权衡。

Abstract: In this paper, we explore sensing security in near-field (NF) integrated
sensing and communication (ISAC) scenarios by exploiting known scatterers in
the sensing scene. We propose a location deception (LD) scheme where scatterers
are deliberately illuminated with probing power that is higher than that
directed toward targets of interest, with the goal of deceiving potential
eavesdroppers (Eves) with sensing capability into misidentifying scatterers as
targets. While the known scatterers can be removed at the legitimate sensing
receiver, our LD approach causes Eves to misdetect targets. Notably, this
deception is achieved without requiring any prior information about the Eves'
characteristics or locations. To strike a flexible three-way tradeoff among
communication, sensing, and sensing-security performance, the sum rate and
power allocated to scatterers are weighted and maximized under a legitimate
radar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the
fractional programming (FP) framework and semidefinite relaxation (SDR) to
solve this problem. To evaluate the security of the proposed LD scheme, the
Cramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.
Additionally, we introduce the Kullback-Leibler Divergence (KLD) gap between
targets and scatterers at Eve to quantify the impact of the proposed LD
framework on Eve's sensing performance from an information-theoretical
perspective. Simulation results demonstrate that the proposed LD scheme can
flexibly adjust the beamforming strategy according to performance requirements,
thereby achieving the desired three-way tradeoff. In particular, in terms of
sensing security, the proposed scheme significantly enhances the clutter signal
strength at Eve's side, leading to confusion or even missed detection of the
actual target.

</details>


### [353] [Deep Learning Based Joint Space-Time-Frequency Domain Channel Prediction for Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.20146)
*Yongning Qi,Tao Zhou,Zuowei Xiang,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的联合时空频域信道预测模型，用于解决 6G 通信中 CF-mMIMO 的信道预测问题，该模型通过引入 FreqConv 和 SpaceConv 层，能够有效利用时空频相关性，并能处理不规则 AP 部署，在仿真和真实数据集上均表现出优于传统模型的预测精度和较低的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了提高 6G 通信系统中 CF-mMIMO 的性能，需要精确的信道状态信息 (CSI)，而信道预测在获取精确 CSI 中起着关键作用。

Method: 提出了一种新的基于深度学习的联合时空频域信道预测模型，该模型在 Transformer-encoder 中加入了 FreqConv 和 SpaceConv 层，能够并行输出多步预测结果，并利用时空频相关性，提取空间相关性以应对不规则 AP 部署。通过仿真数据集确定最优超参数，并评估预测精度和计算复杂度。最后，使用高速列车 LTE 网络中的真实数据集进行验证。

Result: 仿真结果表明，所提出的模型预测精度高于传统模型，计算复杂度低于传统的 Transformer 模型。对时空频相关性对预测精度的影响进行了研究。真实数据集验证结果表明，在 HST LTE 网络中，该模型也实现了比传统模型更高的预测精度。

Conclusion: 所提出的基于深度学习的联合时空频域信道预测模型能够有效提高 CF-mMIMO 系统的信道预测精度，并且计算复杂度较低，适用于 6G 通信系统。

Abstract: The cell-free massive multi-input multi-output (CF-mMIMO) is a promising
technology for the six generation (6G) communication systems. Channel
prediction will play an important role in obtaining the accurate CSI to improve
the performance of CF-mMIMO systems. This paper studies a deep learning (DL)
based joint space-time-frequency domain channel prediction for CF-mMIMO.
Firstly, the prediction problems are formulated, which can output the
multi-step prediction results in parallel without error propagation. Then, a
novel channel prediction model is proposed, which adds frequency convolution
(FreqConv) and space convolution (SpaceConv) layers to Transformer-encoder. It
is able to utilize the space-time-frequency correlations and extract the space
correlation in the irregular AP deployment. Next, simulated datasets with
different sizes of service areas, UE velocities and scenarios are generated,
and correlation analysis and cross-validation are used to determine the optimal
hyper-parameters. According to the optimized hyper-parameters, the prediction
accuracy and computational complexity are evaluated based on simulated
datasets. It is indicated that the prediction accuracy of the proposed model is
higher than traditional model, and its computational complexity is lower than
traditional Transformer model. After that, the impacts of space-time-frequency
correlations on prediction accuracy are studied. Finally, realistic datasets in
a high-speed train (HST) long-term evolution (LTE) network are collected to
verify the prediction accuracy. The verification results demonstrate that it
also achieves higher prediction accuracy compared with traditional models in
the HST LTE network.

</details>


### [354] [NOMA for Visible Light Communications: Recent Advances and Future Directions](https://arxiv.org/abs/2510.20215)
*Xuesong Wang*

Main category: eess.SP

TL;DR: VLC需要新的MAC层设计，NOMA是一种有前景的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有VLC标准没有充分利用光链路的特性，且TDMA协议在处理突发和非对称流量时效率低下。CSMA/CA及其变种在VLC中虽然可用，但需要调整才能获得良好性能。因此，有必要对VLC进行从头设计，尤其是在MAC层。NOMA作为一种在5G RF系统中得到探索的技术，也为6G VLC带来了希望。

Method: 本文回顾了VLC和基于NOMA的VLC的进展，概述了关键的优化约束和目标，调查了适合NOMA的VLC场景，并指出了未来工作的方向。

Result: 本文主要对VLC和NOMA在VLC中的应用进行了综述，讨论了相关的挑战和机遇。

Conclusion: NOMA技术为6G VLC的MAC层设计提供了有前景的解决方案，能够提高频谱效率和网络性能。

Abstract: Rapidly increasing demand for high speed data is pushing 6G wireless networks
to support larger link scales, lower latency, and higher spectral efficiency.
Visible light communications (VLC) is a strong complement to radio frequency
(RF) systems within 6G. The latest ITU G.9991 and IEEE 802.11bb standards are
adapted from cable and RF wireless technologies for use in VLC, so they do not
fully exploit the optical nature of light links. VLC links are often asymmetric
between uplink and downlink, which makes TDMA style protocols inefficient when
many users generate bursty and asymmetric traffic. Compared with RF, the strong
directionality and frequent line of sight in VLC can mitigate hidden and
exposed terminals, yet these effects can still appear under limited field of
view, blockage, or reflections. CSMA/CA and related methods remain usable in
VLC and in RF plus VLC networks, but they usually need design tweaks such as
RTS/CTS or directional sensing to perform well. Although the optical spectrum
is vast, the bandwidth of practical LEDs and of common PIN or APD receivers is
limited, so efficient multiple access can yield large gains. This motivates a
clean slate design for VLC, especially at the MAC layer. NOMA, first explored
in 5G RF systems, is also promising for 6G VLC. It lets multiple users share
the same time and frequency resources while tolerating controlled interference.
This paper reviews progress in VLC and in NOMA based VLC, outlines key
optimization constraints and objectives, surveys scenarios that fit NOMA in
VLC, and points to several directions for future work.

</details>


### [355] [A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond](https://arxiv.org/abs/2510.20265)
*Burak Ahmet Ozden,Erdogan Aydin,Emir Aslandogan,Haci Ilhan,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: 本综述全面回顾了基于正交时频空间（OTFS）的无线通信系统，重点关注 OTFS-IM（索引调制）方案。


<details>
  <summary>Details</summary>
Motivation: OTFS 是一种二维调制技术，利用延迟-多普勒（DD）域，有望为 6G 及更高网络提供稳健、高容量的无线通信。索引调制（IM）通过在所选通信资源的索引中编码数据位来传达信息，以提高错误性能、频谱效率和能源效率。OTFS-IM 结合了这两种技术的优势。

Method: 本文对现有的 OTFS-IM 方案进行了全面的回顾和系统分类，依据系统架构、检测方法和性能（如容量、峰均功率比、分集、复杂度、不完美信道状态信息、频谱效率和中断概率）。此外，还描述了 OTFS-IM 变体（包括基于 OTFS 的空间移位键控、基于 OTFS 的空间调制、基于 OTFS 的正交空间调制、基于 OTFS 的介质调制和基于 OTFS 的码索引调制）的工作原理和系统模型，并进行了比较性能分析。

Result: 对 OTFS-IM 方案的系统架构、检测方法和性能进行了分类和分析。对 OTFS-IM 变体进行了描述，并对其计算复杂度、错误性能、容量、节能、频谱效率和吞吐量进行了比较分析。

Conclusion: 讨论了 OTFS-IM 系统的挑战、优势和未来方向，涵盖了复杂度、效率、延迟、信道估计、硬件约束、同步、安全以及与其他先进无线通信技术集成等关键方面。

Abstract: Orthogonal time frequency space (OTFS) is a two-dimensional modulation
technique that uses the delay-Doppler (DD) domain and is a candidate for
providing robust, high-capacity wireless communications for envisioned 6G and
beyond networks. The OTFS technique maps data to the DD domain instead of the
traditional time-frequency domain, enabling it to fully utilize channel
diversity and transform fast time-varying channels into nearly static channels.
Index modulation (IM) is a communication paradigm that conveys information not
only through conventional modulation symbols but also by encoding data bits in
the indices of the selected communication resources to improve error
performance, spectral efficiency, and energy efficiency. In this survey, a
comprehensive review of work on OTFS-based wireless communication systems is
presented. In particular, the existing OTFS-IM schemes are reviewed and
systematically categorized according to their system architectures, detection
methods, and performance aspects such as capacity, peak-to-average power ratio,
diversity, complexity, imperfect channel state information, spectral
efficiency, and outage probability. Furthermore, the operating principles and
system models of OTFS-IM variants-including OTFS-based space shift keying,
OTFS-based spatial modulation, OTFS-based quadrature spatial modulation,
OTFS-based media-based modulation, and OTFS-based code index modulation-are
described, followed by a comparative performance analysis in terms of
computational complexity, error performance, capacity, energy saving, spectral
efficiency, and throughput. Finally, the challenges, benefits, and future
directions for OTFS-IM systems are discussed, covering key aspects such as
complexity, efficiency, latency, channel estimation, hardware constraints,
synchronization, security, and potential integration with other advanced
wireless communication techniques.

</details>


### [356] [Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays](https://arxiv.org/abs/2510.20274)
*Kangda Zhi,Tianyu Yang,Songyan Xue,Giuseppe Caire*

Main category: eess.SP

TL;DR: 本论文提出了一种新颖的三阶段算法，结合了正交匹配追踪（OMP）和稀疏贝叶斯学习（SBL），用于解决次连接平面超大规模多输入多输出（XL-MIMO）系统中近场全列秩信道估计和三维定位问题。


<details>
  <summary>Details</summary>
Motivation: 现有信道估计和三维定位算法在近场全列秩信道场景下存在局限性，无法有效处理多天线用户，因此需要设计新的算法。

Method: 提出一种三阶段算法：1. 将XL-MIMO划分为子阵列，利用OMP和基于DFT的字典矩阵解决子阵列信道估计的压缩感知问题。2. 利用估计的子阵列信道和一维MUSIC算法，在最小二乘（LS）准则下估计用户阵列的中心位置。3. 利用估计的中心位置构建改进的、aided的字典矩阵，并使用SBL进行信道估计。

Result: 仿真结果表明，所提出的算法在导频开销和估计精度方面均显著优于现有基准算法。

Conclusion: 所提出的三阶段算法能够有效解决次连接平面XL-MIMO系统中近场全列秩信道估计和三维定位问题，并在性能上优于现有方法。

Abstract: This paper investigates the design of channel estimation and 3D localization
algorithms in a challenging scenario, where a sub-connected planar extremely
large-scale multiple-input multiple-output (XL-MIMO) communicates with
multi-antenna users. In the near field, the uplink MIMO channel is of full
column rank and therefore can not be estimated effectively by applying existing
codebooks that are designed for the far-field case or for the near-field case
but limited to single antenna users. To solve this problem, we propose a
three-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse
Bayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into
subarrays and use OMP to solve the compressed sensing (CS) problem about
subarray channel estimation with the Discrete Fourier Transform (DFT)-based
dictionary matrix. Secondly, exploiting the estimated subarray channels and
employing one-dimensional multiple signal classification (MUSIC), we estimate
the central location of the user array under the Least Squares (LS) criterion.
Finally, we utilize the estimated central location to construct a refined
location-aided dictionary matrix and obtain the MIMO channel estimation using
SBL. Results exhibit the significant superiority of the proposed algorithm
compared with several benchmarks, in terms of both the pilot overhead and
estimation accuracy.

</details>


### [357] [Channel Estimation and Passive Beamforming for Pixel-based Reconfigurable Intelligent Surfaces with Non-Separable State Response](https://arxiv.org/abs/2510.20354)
*Huayan Guo,Junhui Rao,Alex M. H. Wong,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 基于像素的可重构智能表面（RIS）通过消除移相器来实现高反射增益和低硬件成本，但其非可分离的状态响应给信道估计和无源波束赋形带来挑战。本文提出一种新颖的解决方案，通过核方法和深度神经网络近似非可分离响应，并采用简化的级联信道模型和定制算法分别估计短期和长期参数，最后设计低复杂度无源波束赋形算法来配置离散RIS状态向量以最大化可实现速率。仿真结果表明，所提出的方法在广泛的信噪比范围内显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统RIS设计中的移相器增加了硬件成本，且其信道估计和无源波束赋形方法对于像素化RIS的非可分离响应无效，因此需要新的方法来解决这些挑战。

Method: 1. 使用核方法和深度神经网络近似像素化RIS的非可分离响应函数。 2. 提出简化的级联信道模型，并设计定制算法分别估计短期和长期信道参数。 3. 提出低复杂度无源波束赋形算法，以配置离散RIS状态向量并最大化可实现速率。

Result: 所提出的方法在广泛的信噪比范围内，在最大化可实现速率方面显著优于各种基线方法。

Conclusion: 本文提出了一种用于像素化RIS的有效信道估计和无源波束赋形解决方案，该方案通过近似非可分离响应和采用简化的信道模型，在降低复杂度的同时实现了性能的大幅提升。

Abstract: Pixel-based reconfigurable intelligent surfaces (RISs) employ a novel design
to achieve high reflection gain at a lower hardware cost by eliminating the
phase shifters used in traditional RIS. However, this design presents
challenges for channel estimation and passive beamforming due to its
non-separable state response, rendering existing solutions ineffective. To
address this, we first approximate the non-separable RIS response functions
using a kernel-based method and a deep neural network, achieving high accuracy
while reducing computational and memory complexity. Next, we propose a
simplified cascaded channel model that focuses on dominated scattering paths
with limited unknown parameters, along with customized algorithms to estimate
short-term and long-term parameters separately. Finally, we introduce a
low-complexity passive beamforming algorithm to configure the discrete RIS
state vector, maximizing the achievable rate. Our simulation results
demonstrate that the proposed solution significantly outperforms various
baselines across a wide SNR range.

</details>


### [358] [A Transformer Inspired AI-based MIMO receiver](https://arxiv.org/abs/2510.20363)
*András Rácz,Tamás Borsos,András Veres,Benedek Csala*

Main category: eess.SP

TL;DR: AttDet是一种受Transformer启发的MIMO检测方法，通过自注意力机制学习干扰，性能接近最优，复杂度可预测。


<details>
  <summary>Details</summary>
Motivation: 为了解决MIMO检测中的互流干扰问题，并结合模型可解释性和数据驱动的灵活性。

Method: 将每个发射层视为一个token，利用轻量级自注意力机制学习互流干扰。信道矩阵直接用于派生查询和键，注意力分数量化信道相关性。值初始化为匹配滤波器输出并迭代优化。

Result: 在5G信道模型、高阶混合QAM调制和编码方案下，AttDet的BER/BLER性能接近最优，同时保持可预测的多项式复杂度。

Conclusion: AttDet通过结合模型驱动的可解释性和数据驱动的灵活性，在MIMO检测中实现了接近最优的性能和可预测的复杂度。

Abstract: We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple
Output) detection method that treats each transmit layer as a token and learns
inter-stream interference via a lightweight self-attention mechanism. Queries
and keys are derived directly from the estimated channel matrix, so attention
scores quantify channel correlation. Values are initialized by matched-filter
outputs and iteratively refined. The AttDet design combines model-based
interpretability with data-driven flexibility. We demonstrate through
link-level simulations under realistic 5G channel models and high-order, mixed
QAM modulation and coding schemes, that AttDet can approach near-optimal
BER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining
predictable, polynomial complexity.

</details>


### [359] [Efficient Medium Access Control for Low-Latency Industrial M2M Communications](https://arxiv.org/abs/2510.20380)
*Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: FROG-MAC在工业M2M网络中处理多优先级数据时，在延迟和吞吐量方面优于BoP-MAC。


<details>
  <summary>Details</summary>
Motivation: 工业M2M网络需要高效的MAC协议来保证低延迟和可靠通信，但现有协议众多，难以选择。因此，有必要对主要MAC协议进行全面的交叉比较。

Method: 通过在Contiki上进行模拟，比较了基于争用窗口的MAC方案BoP-MAC和基于分片（fragmentation）的MAC方案FROG-MAC。两种协议都侧重于降低高优先级流量的延迟，但采用了不同的方法。BoP-MAC为多优先级流量分配了不同的退避值，而FROG-MAC通过分片低优先级流量来实现高优先级数据包的早期传输。模拟在节点数量和两种流量优先级方面进行了变化。

Result: 模拟结果表明，在处理工业环境中的多优先级异构数据时，FROG-MAC在延迟和吞吐量方面均优于BoP-MAC。

Conclusion: FROG-MAC在处理工业M2M网络中的多优先级通信方面，相较于BoP-MAC，能够提供更好的延迟和吞吐量性能。

Abstract: Efficient medium access control (MAC) is critical for enabling low-latency
and reliable communication in industrial Machine-to-Machine (M2M) net-works,
where timely data delivery is essential for seamless operation. The presence of
multi-priority data in high-risk industrial environments further adds to the
challenges. The development of tens of MAC schemes over the past decade often
makes it a tough choice to deploy the most efficient solu-tion. Therefore, a
comprehensive cross-comparison of major MAC protocols across a range of
performance parameters appears necessary to gain deeper insights into their
relative strengths and limitations. This paper presents a comparison of
Contention window-based MAC scheme BoP-MAC with a fragmentation based,
FROG-MAC; both protocols focus on reducing the delay for higher priority
traffic, while taking a diverse approach. BoP-MAC assigns a differentiated
back-off value to the multi-priority traffic, whereas FROG-MAC enables early
transmission of higher-priority packets by fragmenting lower-priority traffic.
Simulations were performed on Contiki by varying the number of nodes for two
traffic priorities. It has been shown that when work-ing with multi-priority
heterogenous data in the industrial environment, FROG-MAC results better both
in terms of delay and throughput.

</details>


### [360] [Inference-Optimal ISAC via Task-Oriented Feature Transmission and Power Allocation](https://arxiv.org/abs/2510.20429)
*Biao Dong,Bin Cao,Qinyu Zhang*

Main category: eess.SP

TL;DR: ISAC系统在CE框架下，通过最大化判别增益（DG）而非最小化均方误差（MSE）来优化推断性能，并实现了更优的功率效率。


<details>
  <summary>Details</summary>
Motivation: 研究集成感知与通信（ISAC）系统在压缩与估计（CE）框架下的协调增益问题，并将推断性能作为关键指标。

Method: 通过误差概率界限来表征推断性能，并将其作为判别增益（DG）的单调函数。推导出DG最优和MSE最优的收发信机设计的闭式解，并揭示了水填充类型的结构以及明确的感知与通信（S&C）权衡。

Result: DG最优设计在低信噪比（SNR）区域下实现了更优的功率效率，通过选择性地分配功率给信息特征，为感知节省了传输功率。

Conclusion: 最大化DG而非最小化MSE可以带来更好的推断性能，并且DG最优设计在ISAC系统中具有更高的功率效率。

Abstract: This work is concerned with the coordination gain in integrated sensing and
communication (ISAC) systems under a compress-and-estimate (CE) framework,
wherein inference performance is leveraged as the key metric. To enable
tractable transceiver design and resource optimization, we characterize
inference performance via an error probability bound as a monotonic function of
the discriminant gain (DG). This raises the natural question of whether
maximizing DG, rather than minimizing mean squared error (MSE), can yield
better inference performance. Closed-form solutions for DG-optimal and
MSE-optimal transceiver designs are derived, revealing water-filling-type
structures and explicit sensing and communication (S\&C) tradeoff. Numerical
experiments confirm that DG-optimal design achieves more power-efficient
transmission, especially in the low signal-to-noise ratio (SNR) regime, by
selectively allocating power to informative features and thus saving transmit
power for sensing.

</details>


### [361] [Analysis of Frequency-Diverse and Dispersion Effects in Dynamic Metasurface Antenna for Holographic Sensing and Imaging](https://arxiv.org/abs/2510.20447)
*Abdul Jabbar,Aakash Bansal,William Whittow*

Main category: eess.SP

TL;DR: 该论文介绍了一种能够实现频率多样性和色散操作的动态超表面天线（DMA）


<details>
  <summary>Details</summary>
Motivation: 当前动态超表面天线（DMA）设计和模型通常是准窄带的，忽略了频率多样性的体现和利用。

Method: 在毫米波段，通过DMA中超表原子的动态全息可重构来实现灵活的色散操纵，从而在工作频带内产生不同的辐射模式，并在紧凑的可重构平台上实现增强的扫描范围。

Result: 实现了灵活的频率分集，增强了扫描范围，并为下一代近场和远场全息传感以及计算全息成像应用提供了DMA色散效应建模和利用的基本见解。

Conclusion: DMA能够实现灵活的频率分集和色散操作，为下一代无线通信、传感和成像应用提供了新的可能性。

Abstract: Dynamic metasurface antennas (DMAs) represent a novel approach to
programmable and affordable electromagnetic wave manipulation for enhanced
wireless communications, sensing, and imaging applications. Nevertheless,
current DMA designs and models are usually quasi-narrowband, neglecting the
versatile frequency-diverse manifestation and its utilization. This work
demonstrates the frequency-diversity and dispersion operations of a
representative DMA structure at the millimeter-wave band. We demonstrate
flexible dispersion manipulation through dynamic holographic reconfigurability
of the meta-atoms in a DMA. This effect can create distinct radiation patterns
across the operating frequency band, achieving flexible frequency diversity
with enhanced scanning range within a compact, reconfigurable platform. It
eliminates the need for wideband systems or complex phase-shifting networks
while offering an alternative to frequency-scanned static beams of traditional
leaky-wave antennas. The results establish fundamental insights into modelling
and utilization of dispersive effects of DMAs in next-generation near-field and
far-field holographic sensing and computational holographic imaging
applications.

</details>


### [362] [An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming](https://arxiv.org/abs/2510.20507)
*Xi Gao,Akang Wang,Junkai Zhang,Qihong Duan,Jiang Xue*

Main category: eess.SP

TL;DR: WMMSE算法计算复杂度高，提出A-MMMSE算法，通过块坐标梯度下降和两阶段预热策略，实现GPU加速，性能与WMMSE相当，计算时间显著减少。


<details>
  <summary>Details</summary>
Motivation: WMMSE算法计算复杂度高，限制其在低延迟场景的应用。

Method: 提出基于块坐标下降框架的高度并行化算法，通过块坐标梯度下降更新预编码矩阵，避免矩阵求逆，仅使用矩阵乘法，便于GPU加速。引入两阶段预热策略加速收敛。

Result: A-MMMSE算法收敛于WSR最大化问题的平稳点，仿真结果表明其WSR性能与WMMSE及reduced-WMMSE相当，但计算时间大幅减少。

Conclusion: A-MMMSE算法在保持与WMMSE相当的性能的同时，显著降低了计算复杂度，适用于低延迟场景。

Abstract: Precoding design based on weighted sum-rate (WSR) maximization is a
fundamental problem in downlink multi-user multiple-input multiple-output
(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)
algorithm is a standard solution, its high computational complexity--cubic in
the number of base station antennas due to matrix inversions--hinders its
application in latency-sensitive scenarios. To address this limitation, we
propose a highly parallel algorithm based on a block coordinate descent
framework. Our key innovation lies in updating the precoding matrix via block
coordinate gradient descent, which avoids matrix inversions and relies solely
on matrix multiplications, making it exceptionally amenable to GPU
acceleration. We prove that the proposed algorithm converges to a stationary
point of the WSR maximization problem. Furthermore, we introduce a two-stage
warm-start strategy grounded in the sum mean-square error (MSE) minimization
problem to accelerate convergence. We refer to our method as the Accelerated
Mixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation
results demonstrate that A-MMMSE matches the WSR performance of both
conventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a
substantial reduction in computational time across diverse system
configurations.

</details>


### [363] [Performance Analysis of End-to-End LEO Satellite-Aided Shore-to-Ship Communications: A Stochastic Geometry Approach](https://arxiv.org/abs/2510.20515)
*Xu Hu,Bin Lin,Xiao Lu,Ping Wang,Nan Cheng,Zhisheng Yin,Weihua Zhuang*

Main category: eess.SP

TL;DR: LEO卫星可以增强海上通信，但传统建模方法难以处理大规模LEO卫星星座。本文提出了一种新的理论框架，将LEO卫星视为二项点过程（BPP）分布，以分析LEO卫星辅助的海陆通信网络（LEO-SSCN）的端到端传输性能。该框架考虑了陆海链路或空间链路的信号传输，并采用了莱斯或阴影莱斯衰落模型。为了解决由于服务卫星位置不确定导致的距离建模难题，本文提出了一种距离近似方法。结合阈值通信方案和随机几何，推导了端到端传输成功概率和平均传输速率容量的解析表达式。数值结果验证了该方法的准确性，并展示了关键参数对LEO-SSCN性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统的基于多个圆形轨道的性能建模方法难以准确表征大规模LEO卫星星座，因此需要一种易于处理的方法来评估网络性能。

Method: 提出了一种LEO卫星辅助的海陆通信网络（LEO-SSCN）的理论框架，其中LEO卫星作为二项点过程（BPP）分布在特定的球面上。该框架考虑了莱斯衰落或阴影莱斯衰落下的陆海链路或空间链路信号传输。提出了一种距离近似方法来解决服务卫星位置不确定导致的距离建模难题。利用随机几何和阈值通信方案，推导出端到端传输成功概率和平均传输速率容量的解析表达式。

Result: 通过广泛的数值结果验证了所提出分析的准确性，并展示了关键参数对LEO-SSCN性能的影响。

Conclusion: 所提出的理论框架和分析方法能够准确评估LEO卫星辅助的海陆通信网络的性能，并为理解关键参数的影响提供了见解。

Abstract: Low Earth orbit (LEO) satellite networks have shown strategic superiority in
maritime communications, assisting in establishing signal transmissions from
shore to ship through space-based links. Traditional performance modeling based
on multiple circular orbits is challenging to characterize large-scale LEO
satellite constellations, thus requiring a tractable approach to accurately
evaluate the network performance. In this paper, we propose a theoretical
framework for an LEO satellite-aided shore-to-ship communication network
(LEO-SSCN), where LEO satellites are distributed as a binomial point process
(BPP) on a specific spherical surface. The framework aims to obtain the
end-to-end transmission performance by considering signal transmissions through
either a marine link or a space link subject to Rician or Shadowed Rician
fading, respectively. Due to the indeterminate position of the serving
satellite, accurately modeling the distance from the serving satellite to the
destination ship becomes intractable. To address this issue, we propose a
distance approximation approach. Then, by approximation and incorporating a
threshold-based communication scheme, we leverage stochastic geometry to derive
analytical expressions of end-to-end transmission success probability and
average transmission rate capacity. Extensive numerical results verify the
accuracy of the analysis and demonstrate the effect of key parameters on the
performance of LEO-SSCN.

</details>


### [364] [Time-series Random Process Complexity Ranking Using a Bound on Conditional Differential Entropy](https://arxiv.org/abs/2510.20551)
*Jacob Ayers,Richard Hahnloser,Julia Ulrich,Lothar Sebastian Krapp,Remo Nitschke,Sabine Stoll,Balthasar Bickel,Reinhard Furrer*

Main category: eess.SP

TL;DR: 该论文提出了一种计算条件微分熵的计算方法，用于评估时间序列的复杂度，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 直接计算高维时间序列的条件微分熵是困难的，而条件微分熵是衡量时间序列复杂度的有用指标。

Method: 利用信息论预测误差界限，并通过Hadamard不等式和协方差矩阵的性质来增加该界限。通过对合成数据和生物启发的音频数据进行实验来验证该方法的有效性。

Result: 实验结果表明，该方法可以有效地对时间序列的复杂度进行排序，并且与真实熵值或已知的复杂度排序保持一致。

Conclusion: 该框架提供了一种计算上可行的、具有信息论理论基础的时间序列复杂度排序方法，该方法使用下一步预测模型的预测误差。

Abstract: Conditional differential entropy provides an intuitive measure for relatively
ranking time-series complexity by quantifying uncertainty in future
observations given past context. However, its direct computation for
high-dimensional processes from unknown distributions is often intractable.
This paper builds on the information theoretic prediction error bounds
established by Fang et al. \cite{fang2019generic}, which demonstrate that the
conditional differential entropy \textbf{$h(X_k \mid X_{k-1},...,X_{k-m})$} is
upper bounded by a function of the determinant of the covariance matrix of
next-step prediction errors for any next step prediction model. We add to this
theoretical framework by further increasing this bound by leveraging Hadamard's
inequality and the positive semi-definite property of covariance matrices.
  To see if these bounds can be used to rank the complexity of time series, we
conducted two synthetic experiments: (1) controlled linear autoregressive
processes with additive Gaussian noise, where we compare ordinary least squares
prediction error entropy proxies to the true entropies of various additive
noises, and (2) a complexity ranking task of bio-inspired synthetic audio data
with unknown entropy, where neural network prediction errors are used to
recover the known complexity ordering.
  This framework provides a computationally tractable method for time-series
complexity ranking using prediction errors from next-step prediction models,
that maintains a theoretical foundation in information theory.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [365] [FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals](https://arxiv.org/abs/2510.19917)
*Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas*

Main category: cs.LG

TL;DR: FINDER是一个用于分析通用分类问题并优化处理噪声数据集的框架，通过引入随机分析概念和构建“随机特征”，利用特征值分解来识别不同类别的数据区域，并在阿尔茨海默病分期和森林砍伐检测等领域取得了先进成果。


<details>
  <summary>Details</summary>
Motivation: 分类方法在处理“噪声”数据集（低信噪比、小样本量、数据收集错误等）方面仍是重要的研究前沿，具有理论和实践意义。

Method: FINDER框架结合了随机分析的思想，通过将经验数据集视为潜在随机场的实现，并映射到希尔伯特空间，构建“随机特征”。利用Kosambi-Karhunen-Lo'eve (KLE) 展开将随机特征分解为可计算的不可约分量，并通过特征值分解实现噪声数据集的分类，根据算子光谱分析识别不同类别的数据区域。

Result: FINDER在阿尔茨海默病分期和遥感森林砍伐检测等具有挑战性的、数据不足的科学领域得到了验证，取得了当前领先水平的突破。

Conclusion: 文章最后讨论了FINDER优于现有方法的预期条件、其失效模式和其他局限性。

Abstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample
sizes, faulty data collection, etc) remain a key research frontier for
classification methods with both theoretical and practical implications. We
introduce FINDER, a rigorous framework for analyzing generic classification
problems, with tailored algorithms for noisy datasets. FINDER incorporates
fundamental stochastic analysis ideas into the feature learning and inference
stages to optimally account for the randomness inherent to all empirical
datasets. We construct ''stochastic features'' by first viewing empirical
datasets as realizations from an underlying random field (without assumptions
on its exact distribution) and then mapping them to appropriate Hilbert spaces.
The Kosambi-Karhunen-Lo\'eve expansion (KLE) breaks these stochastic features
into computable irreducible components, which allow classification over noisy
datasets via an eigen-decomposition: data from different classes resides in
distinct regions, identified by analyzing the spectrum of the associated
operators. We validate FINDER on several challenging, data-deficient scientific
domains, producing state of the art breakthroughs in: (i) Alzheimer's Disease
stage classification, (ii) Remote sensing detection of deforestation. We end
with a discussion on when FINDER is expected to outperform existing methods,
its failure modes, and other limitations.

</details>


### [366] [Some Attention is All You Need for Retrieval](https://arxiv.org/abs/2510.19861)
*Felix Michalak,Steven Abreu*

Main category: cs.LG

TL;DR: 混合SSM-Transformer模型中，检索任务完全由自注意力层负责，SSM层对此无补偿作用。稀疏化注意力仍能保持高检索精度和大部分MMLU性能。模型具有功能特化性，可用于架构优化和可解释性研究。


<details>
  <summary>Details</summary>
Motivation: 研究混合SSM-Transformer架构中是否存在功能冗余，以及自注意力层和SSM层各自的功能。

Method: 通过注意力消融实验、稀疏化实验，并分析检索任务的机制需求（如needle tokens的暴露和上下文的充分性）。

Result: 注意力消融导致检索准确率降至0%，SSM层无补偿。稀疏化15%的注意力头仍保持近乎完美的检索性能，同时保留84%的MMLU性能。

Conclusion: 混合SSM-Transformer模型中存在严格的功能特化，自注意力层主要负责检索任务，SSM层则不然。模型更像是由独立模块组成的系统，而非完全整合的系统，这对于模型优化和可解释性有重要意义。

Abstract: We demonstrate complete functional segregation in hybrid SSM-Transformer
architectures: retrieval depends exclusively on self-attention layers. Across
RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic
retrieval failure (0% accuracy), while SSM layers show no compensatory
mechanisms even with improved prompting. Conversely, sparsifying attention to
just 15% of heads maintains near-perfect retrieval while preserving 84% MMLU
performance, suggesting self-attention specializes primarily for retrieval
tasks. We identify precise mechanistic requirements for retrieval: needle
tokens must be exposed during generation and sufficient context must be
available during prefill or generation. This strict functional specialization
challenges assumptions about redundancy in hybrid architectures and suggests
these models operate as specialized modules rather than integrated systems,
with immediate implications for architecture optimization and interpretability.

</details>


### [367] [An Integrated Approach to Neural Architecture Search for Deep Q-Networks](https://arxiv.org/abs/2510.19872)
*Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian*

Main category: cs.LG

TL;DR: NAS-DQN通过在线自适应调整神经网络架构来提升深度强化学习的性能，克服了传统固定架构的限制，并在连续控制任务中取得了优于固定架构基线和随机搜索的性能。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）代理的性能受限于其神经网络架构，而传统上需要昂贵的超参数搜索来确定固定架构。本研究旨在探索在线、自适应的架构优化是否能克服这一限制并超越静态设计。

Method: 提出NAS-DQN，一种将学习到的神经网络架构搜索控制器集成到DRL训练循环中的代理，能够基于累积的性能反馈动态地重新配置网络架构。

Result: NAS-DQN在连续控制任务的评估中，相对于三种固定架构基线和一种随机搜索控制，取得了优越的最终性能、样本效率和策略稳定性，同时计算开销可忽略不计。学习到的搜索策略显著优于无方向的随机架构探索和选择不佳的固定设计。

Conclusion: 架构自适应对于在线深度强化学习的最佳样本效率不仅是有益的，而且是必要的。这表明DRL代理的设计不必是静态的离线选择，而可以作为学习过程本身的一个动态组成部分无缝集成。

Abstract: The performance of deep reinforcement learning agents is fundamentally
constrained by their neural network architecture, a choice traditionally made
through expensive hyperparameter searches and then fixed throughout training.
This work investigates whether online, adaptive architecture optimization can
escape this constraint and outperform static designs. We introduce NAS-DQN, an
agent that integrates a learned neural architecture search controller directly
into the DRL training loop, enabling dynamic network reconfiguration based on
cumulative performance feedback. We evaluate NAS-DQN against three
fixed-architecture baselines and a random search control on a continuous
control task, conducting experiments over multiple random seeds. Our results
demonstrate that NAS-DQN achieves superior final performance, sample
efficiency, and policy stability while incurring negligible computational
overhead. Critically, the learned search strategy substantially outperforms
both undirected random architecture exploration and poorly-chosen fixed
designs, indicating that intelligent, performance-guided search is the key
mechanism driving success. These findings establish that architecture
adaptation is not merely beneficial but necessary for optimal sample efficiency
in online deep reinforcement learning, and suggest that the design of RL agents
need not be a static offline choice but can instead be seamlessly integrated as
a dynamic component of the learning process itself.

</details>


### [368] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: 尽管LLMs在生成CUDA代码方面显示出潜力，但云API的代码泄露风险和本地部署的高昂成本限制了其应用。SLMs更轻量且隐私友好，但其有限的推理能力在复杂CUDA生成任务中表现不佳。ReGraphT框架通过将LLM的推理能力迁移到SLMs，解决了这一挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在利用GPU进行大规模并行计算方面仍有困难，并且在使用LLMs进行CUDA代码优化时，云API存在代码泄露风险，本地部署成本高昂。小型语言模型（SLMs）虽然更轻便且注重隐私，但在复杂CUDA生成任务中的表现不佳。

Method: ReGraphT框架通过将CUDA优化过程组织成结构化的推理图，将组合优化建模为状态转移，并利用蒙特卡洛图搜索（MCGS）进行高效探索，实现了LLM级别的推理能力迁移。

Result: ReGraphT框架在CUDAEval和ParEval基准测试上取得了平均2.33倍的加速，优于经过HPC特定微调的模型和其他检索增强方法。与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用时，SLMs的性能接近LLMs的水平。

Conclusion: ReGraphT框架能够有效地将LLM的推理能力迁移到SLMs，使SLMs在不牺牲性能、隐私和计算成本的情况下，接近LLM在CUDA优化方面的表现。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>


### [369] [Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints](https://arxiv.org/abs/2510.20220)
*Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 Fair-SMW 的新算法，通过使用拉格朗日方法和 Sherman-Morrison-Woodbury (SMW) 恒等式来优化受约束的优化问题，以提高保证群体公平性（平衡性）的谱聚类算法的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的保证群体公平性（平衡性）的谱聚类算法计算时间较长，本研究旨在提高其效率。

Method: 提出 Fair-SMW 算法，使用拉格朗日方法和 SMW 恒等式重新构建受约束的优化问题。Fair-SMW 使用拉普拉斯矩阵的三个不同变体来生成多种算法版本。

Result: Fair-SMW 在计算时间上比现有算法快一倍，并且在平衡性方面也取得了相当的成果，在某些情况下甚至可以提高一倍的平衡性。实验在真实网络数据集（LastFM、FacebookNet、Deezer 和 German）上使用随机块模型（SBM）进行评估。

Conclusion: Fair-SMW 算法在保证群体公平性（平衡性）的同时，显著提高了谱聚类算法的效率。

Abstract: Recent research has focused on mitigating algorithmic bias in clustering by
incorporating fairness constraints into algorithmic design. Notions such as
disparate impact, community cohesion, and cost per population have been
implemented to enforce equitable outcomes. Among these, group fairness
(balance) ensures that each protected group is proportionally represented
within every cluster. However, incorporating balance as a metric of fairness
into spectral clustering algorithms has led to computational times that can be
improved. This study aims to enhance the efficiency of spectral clustering
algorithms by reformulating the constrained optimization problem using a new
formulation derived from the Lagrangian method and the
Sherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm.
Fair-SMW employs three alternatives to the Laplacian matrix with different
spectral gaps to generate multiple variations of Fair-SMW, achieving clustering
solutions with comparable balance to existing algorithms while offering
improved runtime performance. We present the results of Fair-SMW, evaluated
using the Stochastic Block Model (SBM) to measure both runtime efficiency and
balance across real-world network datasets, including LastFM, FacebookNet,
Deezer, and German. We achieve an improvement in computation time that is twice
as fast as the state-of-the-art, and also flexible enough to achieve twice as
much balance.

</details>


### [370] [From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem](https://arxiv.org/abs/2510.19889)
*Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis*

Main category: cs.LG

TL;DR: 本研究提出了一种基于深度神经网络（Transformer）的交通分配新方法，用于直接预测均衡路径流量，解决了传统优化方法在大规模网络中的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统基于均衡原理的交通分配方法在处理大规模网络时计算复杂度呈非线性增长，变得不切实际。本研究旨在提供一种更高效、可扩展的数据驱动方法。

Method: 利用Transformer深度神经网络直接预测均衡路径流量，侧重于路径层面的交通分布，捕捉OD对之间的复杂相关性。

Result: 与传统优化方法相比，该模型在多个基准网络（Manhattan-like、Sioux Falls、Eastern-Massachusetts）上的数值实验表明，计算速度提升了数个数量级，同时能有效估计多类网络中的路径流量，提高了预测精度，并能灵活适应需求和网络结构的变化。

Conclusion: 该Transformer模型通过直接预测路径流量，显著降低了计算成本，提高了预测准确性，并能灵活适应需求和网络条件的变化，为交通管理、‘假设’分析以及交通规划和政策制定提供了有力的支持。

Abstract: The traffic assignment problem is essential for traffic flow analysis,
traditionally solved using mathematical programs under the Equilibrium
principle. These methods become computationally prohibitive for large-scale
networks due to non-linear growth in complexity with the number of OD pairs.
This study introduces a novel data-driven approach using deep neural networks,
specifically leveraging the Transformer architecture, to predict equilibrium
path flows directly. By focusing on path-level traffic distribution, the
proposed model captures intricate correlations between OD pairs, offering a
more detailed and flexible analysis compared to traditional link-level
approaches. The Transformer-based model drastically reduces computation time,
while adapting to changes in demand and network structure without the need for
recalculation. Numerical experiments are conducted on the Manhattan-like
synthetic network, the Sioux Falls network, and the Eastern-Massachusetts
network. The results demonstrate that the proposed model is orders of magnitude
faster than conventional optimization. It efficiently estimates path-level
traffic flows in multi-class networks, reducing computational costs and
improving prediction accuracy by capturing detailed trip and flow information.
The model also adapts flexibly to varying demand and network conditions,
supporting traffic management and enabling rapid `what-if' analyses for
enhanced transportation planning and policy-making.

</details>


### [371] [Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control](https://arxiv.org/abs/2510.20408)
*Tom Maus,Asma Atamna,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 本研究提出了一个改进的工业场景基准环境，用于评估强化学习在多阶段工业过程中的应用，并比较了模块化和整体式智能体以及动作掩码的影响。


<details>
  <summary>Details</summary>
Motivation: 工业界在采用强化学习进行自主控制时面临奖励设计、模块化和动作空间管理等挑战，现有基准环境与工业实际问题存在差距。

Method: 结合SortingEnv和ContainerGym，构建了一个包含排序和压榨操作的顺序回收场景。评估了采用特殊智能体的模块化架构和控制整个系统的整体式智能体，并分析了动作掩码的影响。

Result: 在没有动作掩码的情况下，智能体难以学习有效策略，模块化架构表现更好。应用动作掩码后，两种架构都有显著提升，性能差距缩小。这表明动作空间约束起着关键作用，且动作复杂度降低会减弱专业化的优势。

Conclusion: 提出的基准环境为探索工业自动化中实用且鲁棒的多智能体强化学习解决方案提供了有价值的测试平台，并为中央集权与专业化之争提供了新的见解。

Abstract: Autonomous control of multi-stage industrial processes requires both local
specialization and global coordination. Reinforcement learning (RL) offers a
promising approach, but its industrial adoption remains limited due to
challenges such as reward design, modularity, and action space management. Many
academic benchmarks differ markedly from industrial control problems, limiting
their transferability to real-world applications. This study introduces an
enhanced industry-inspired benchmark environment that combines tasks from two
existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling
scenario with sorting and pressing operations. We evaluate two control
strategies: a modular architecture with specialized agents and a monolithic
agent governing the full system, while also analyzing the impact of action
masking. Our experiments show that without action masking, agents struggle to
learn effective policies, with the modular architecture performing better. When
action masking is applied, both architectures improve substantially, and the
performance gap narrows considerably. These results highlight the decisive role
of action space constraints and suggest that the advantages of specialization
diminish as action complexity is reduced. The proposed benchmark thus provides
a valuable testbed for exploring practical and robust multi-agent RL solutions
in industrial automation, while contributing to the ongoing debate on
centralization versus specialization.

</details>


### [372] [FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning](https://arxiv.org/abs/2510.19893)
*Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为FairGRPO的公平性强化学习方法，用于解决医学人工智能模型在不同人群中表现不均的问题，并通过FairMedGemma-4B模型进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的医学人工智能模型在诊断能力上虽有显著进步，但在不同人群中表现存在差异，尤其是在以多数人群为主的训练数据上进行强化学习时，会继承甚至放大这些偏见，从而对代表性不足的人群造成实际伤害。

Method: 提出了一种名为FairGRPO的分层强化学习方法，该方法通过自适应的优势重要性加权（考虑了表示、任务难度和数据源）来促进跨不同临床人群的公平学习。当缺少人口统计学标签时，该方法还采用无监督聚类来发现潜在的人口统计学群体。

Result: 在包含7个临床诊断数据集（涵盖X光、CT、皮肤镜、乳腺X光和超声检查等5种临床模式）的广泛实验中，FairGRPO将预测奇偶性降低了27.2%，同时将F1分数提高了12.49%。此外，FairGRPO在训练过程中持续提高公平性，而基线强化学习方法则在训练过程中公平性逐渐下降。基于FairGRPO，发布了FairMedGemma-4B模型，该模型在达到最先进性能的同时，显著降低了跨人群的性能差异。

Conclusion: FairGRPO是一种有效的解决医学人工智能公平性问题的强化学习方法，并且能够显著减少模型在不同人群中的性能差异。FairMedGemma-4B模型展示了这种方法的实际应用潜力。

Abstract: Medical artificial intelligence systems have achieved remarkable diagnostic
capabilities, yet they consistently exhibit performance disparities across
demographic groups, causing real-world harm to underrepresented populations.
While recent multimodal reasoning foundation models have advanced clinical
diagnosis through integrated analysis of diverse medical data, reasoning
trainings via reinforcement learning inherit and often amplify biases present
in training datasets dominated by majority populations. We introduce
Fairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical
reinforcement learning approach that promotes equitable learning across
heterogeneous clinical populations. FairGRPO employs adaptive importance
weighting of advantages based on representation, task difficulty, and data
source. To address the common issue of missing demographic labels in the
clinical domain, we further employ unsupervised clustering, which automatically
discovers latent demographic groups when labels are unavailable. Through
comprehensive experiments across 7 clinical diagnostic datasets spanning 5
clinical modalities across X-ray, CT scan, dermoscropy, mammography and
ultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2%
against all vanilla and bias mitigated RL baselines, while improving F1 score
by 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO
progressively improves fairness throughout optimization, while baseline RL
methods exhibit deteriorating fairness as training progresses. Based on
FairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that
achieves state-of-the-art performance while demonstrating significantly reduced
disparities across demographic groups.

</details>


### [373] [Thought Communication in Multiagent Collaboration](https://arxiv.org/abs/2510.20733)
*Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为“思想交流”的新范式，使智能体能够像心灵感应一样直接进行“心与心”的交流，以克服自然语言的局限性，从而增强集体智能。


<details>
  <summary>Details</summary>
Motivation: 自然语言的固有局限性（如信息损失、歧义和间接性）限制了集体智能的潜力。尽管机器不受这些限制，但现有的多智能体系统仍主要依赖自然语言进行通信。

Method: 将思想交流的过程形式化为一个通用的潜在变量模型，其中智能体的状态由潜在思想的未知函数生成。在非参数设定下，证明了可以识别智能体之间共享和私有的潜在思想，并能恢复思想共享的全局结构。在此基础上，开发了一个框架，在通信前提取所有智能体的潜在思想，并将相关思想及其共享模式分配给各个智能体。

Result: 实验表明，该思想交流范式在合成和真实世界基准测试中均能验证其理论，并展示了其在协作方面的优势。

Conclusion: 思想交流范式有望超越语言模型，扩展到所有数据模态，因为它能从隐藏的生成过程中提取信息，并为解决仅通过表面观察难以解决的挑战提供了新的途径。

Abstract: Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

</details>


### [374] [Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification](https://arxiv.org/abs/2510.19896)
*Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling*

Main category: cs.LG

TL;DR: 本文提出一种基于SHAP特征选择的方法，用于支持包括膀胱癌在内的泌尿系统疾病的诊断，以提高预测模型的透明度和有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高泌尿系统疾病（特别是膀胱癌）诊断的透明度和有效性，提出一种基于SHAP特征选择的方法。

Method: 使用XGBoost、LightGBM和CatBoost算法，结合Optuna进行超参数优化和SMOTE进行类别平衡，并采用SHAP特征选择方法来选择预测变量。

Result: 在区分膀胱癌与其他泌尿系统及肿瘤疾病的六种二元分类场景中，SHAP特征选择在保持或提高平衡准确率、精确率和特异性等性能指标的同时，有效选择了预测变量。

Conclusion: 基于可解释性技术（SHAP）的特征选择被证明是一种有效的方法，该方法有望促进开发更透明、更可靠、更高效的临床决策支持系统，从而优化泌尿系统疾病的筛查和早期诊断。

Abstract: In this paper, we propose an approach to support the diagnosis of urinary
tract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive
exPlanations)-based feature selection to enhance the transparency and
effectiveness of predictive models. Six binary classification scenarios were
developed to distinguish bladder cancer from other urological and oncological
conditions. The algorithms XGBoost, LightGBM, and CatBoost were employed, with
hyperparameter optimization performed using Optuna and class balancing with the
SMOTE technique. The selection of predictive variables was guided by importance
values through SHAP-based feature selection while maintaining or even improving
performance metrics such as balanced accuracy, precision, and specificity. The
use of explainability techniques (SHAP) for feature selection proved to be an
effective approach. The proposed methodology may contribute to the development
of more transparent, reliable, and efficient clinical decision support systems,
optimizing screening and early diagnosis of urinary tract diseases.

</details>


### [375] [Beyond the Ideal: Analyzing the Inexact Muon Update](https://arxiv.org/abs/2510.19933)
*Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik*

Main category: cs.LG

TL;DR: Muon优化器在大型神经网络训练中表现优异，但理论分析与其高效的近似正交化实现存在脱节。本文首次分析了Muon核心的近似正交化更新，提出了一个包含加性误差的现实模型，并量化了近似误差对性能的影响。研究发现，近似误差与最优步长和动量参数之间存在耦合关系：精度越低，步长越小，动量越大。NanoGPT实验证实了这一耦合关系，并表明近似精度是需要与学习率调整一起仔细调整的关键参数。


<details>
  <summary>Details</summary>
Motivation: 现有的Muon优化器理论分析与其在实际应用中的高效近似正交化实现之间存在理论与实践的脱节。本文旨在弥合这一差距，提供对实际近似正交化更新的理论分析。

Method: 在 АдамаW 框架下，使用线性最小化预言机（LMO）优化框架，引入一个现实的加性误差模型来描述实际近似方案的非精确性，并分析非精确正交化更新。

Result: 推导出了量化LMO非精确性/误差对性能影响的显式界限。揭示了近似误差与最优步长和动量参数之间存在基础耦合：较低的预言机精度需要更小的步长但更大的动量参数。

Conclusion: 近似过程（如牛顿-舒尔茨迭代次数）不仅仅是实现细节，而是需要与学习率调整一起进行仔细调优的关键参数。NanoGPT实验直接证实了预测的耦合关系，最优学习率会随着近似精度的变化而明显移动。

Abstract: The Muon optimizer has rapidly emerged as a powerful, geometry-aware
alternative to AdamW, demonstrating strong performance in large-scale training
of neural networks. However, a critical theory-practice disconnect exists:
Muon's efficiency relies on fast, approximate orthogonalization, yet all prior
theoretical work analyzes an idealized, computationally intractable version
assuming exact SVD-based updates. This work moves beyond the ideal by providing
the first analysis of the inexact orthogonalized update at Muon's core. We
develop our analysis within the general framework of Linear Minimization Oracle
(LMO)-based optimization, introducing a realistic additive error model to
capture the inexactness of practical approximation schemes. Our analysis yields
explicit bounds that quantify performance degradation as a function of the LMO
inexactness/error. We reveal a fundamental coupling between this inexactness
and the optimal step size and momentum: lower oracle precision requires a
smaller step size but larger momentum parameter. These findings elevate the
approximation procedure (e.g., the number of Newton-Schulz steps) from an
implementation detail to a critical parameter that must be co-tuned with the
learning schedule. NanoGPT experiments directly confirm the predicted coupling,
with optimal learning rates clearly shifting as approximation precision
changes.

</details>


### [376] [ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push](https://arxiv.org/abs/2510.20157)
*Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu*

Main category: cs.LG

TL;DR: ADP-VRSGP通过自适应噪声方差和学习率，结合梯度融合和Push-Sum技术，在保证差分隐私的同时提高了去中心化学习的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化学习中的固定方差噪声会降低模型性能和训练效率，需要一种能够动态调整噪声以解决这些问题的方法。

Method: 提出了一种名为ADP-VRSGP的新方法，该方法使用逐步衰减的调度动态调整噪声方差和学习率，并引入了利用历史梯度的渐进梯度融合策略，以及去中心化Push-Sum和聚合技术。

Result: 理论分析表明，ADP-VRSGP在适当的学习率下具有鲁棒收敛性，实验结果表明其在多个场景下优于现有基线方法。

Conclusion: ADP-VRSGP通过自适应差分隐私有效解决了隐私保护去中心化学习中的挑战，提高了训练稳定性和速度，并增强了模型性能。

Abstract: Differential privacy is widely employed in decentralized learning to
safeguard sensitive data by introducing noise into model updates. However,
existing approaches that use fixed-variance noise often degrade model
performance and reduce training efficiency. To address these limitations, we
propose a novel approach called decentralized learning with adaptive
differential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).
This method dynamically adjusts both the noise variance and the learning rate
using a stepwise-decaying schedule, which accelerates training and enhances
final model performance while providing node-level personalized privacy
guarantees. To counteract the slowed convergence caused by large-variance noise
in early iterations, we introduce a progressive gradient fusion strategy that
leverages historical gradients. Furthermore, ADP-VRSGP incorporates
decentralized push-sum and aggregation techniques, making it particularly
suitable for time-varying communication topologies. Through rigorous
theoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence
with an appropriate learning rate, significantly improving training stability
and speed. Experimental results validate that our method outperforms existing
baselines across multiple scenarios, highlighting its efficacy in addressing
the challenges of privacy-preserving decentralized learning.

</details>


### [377] [Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy](https://arxiv.org/abs/2510.19934)
*Xiang Li,Buxin Su,Chendi Wang,Qi Long,Weijie J. Su*

Main category: cs.LG

TL;DR: 该论文提出了两种基于 f-DP 的差分隐私会计方法（PN-f-DP 和 Sec-f-LDP），用于量化去中心化联邦学习中的隐私预算，并在合成和真实数据集上证明了其在提供更紧密的隐私边界和更高效用方面的优势。


<details>
  <summary>Details</summary>
Motivation: 准确量化去中心化联邦学习算法的隐私预算具有挑战性，因为其复杂的组件，如去中心化通信和本地更新。

Method: 开发了两种新的基于 f-DP 的会计方法：Pairwise Network f-DP (PN-f-DP) 和 Secret-based f-Local DP (Sec-f-LDP)，并结合了 f-DP 理论和马尔可夫链集中工具。

Result: 与基于 Rényi DP 的方法相比，PN-f-DP 和 Sec-f-LDP 在合成和真实数据集上产生了更紧密的 (ε, δ) 边界和更高的效用。

Conclusion: f-DP 框架在去中心化隐私会计方面具有优势，可以提供更准确的隐私保证和更好的模型效用。

Abstract: Differentially private (DP) decentralized Federated Learning (FL) allows
local users to collaborate without sharing their data with a central server.
However, accurately quantifying the privacy budget of private FL algorithms is
challenging due to the co-existence of complex algorithmic components such as
decentralized communication and local updates. This paper addresses privacy
accounting for two decentralized FL algorithms within the $f$-differential
privacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods
tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which
quantifies privacy leakage between user pairs under random-walk communication,
and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise
injection via shared secrets. By combining tools from $f$-DP theory and Markov
chain concentration, our accounting framework captures privacy amplification
arising from sparse communication, local iterations, and correlated noise.
Experiments on synthetic and real datasets demonstrate that our methods yield
consistently tighter $(\epsilon,\delta)$ bounds and improved utility compared
to R\'enyi DP-based approaches, illustrating the benefits of $f$-DP in
decentralized privacy accounting.

</details>


### [378] [Are Greedy Task Orderings Better Than Random in Continual Linear Regression?](https://arxiv.org/abs/2510.19941)
*Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry*

Main category: cs.LG

TL;DR: 我们分析了具有联合可实现性假设的持续学习线性回归任务排序，重点关注贪婪地最大化任务之间差异的排序。我们利用 Kaczmarz 方法的工具来形式化这些排序，并开发相关的几何和代数直觉。经验上，我们表明贪婪排序在任务平均损失方面比随机排序收敛更快。分析上，在随机排序平均损失为 O(1/√k) 的情况下，我们证明了单次传递贪婪排序可能会灾难性地失败，而允许重复的贪婪排序则以 O(1/k^(1/3)) 的速率收敛，揭示了贪婪和随机排序之间的细微差别。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨持续学习中任务排序对线性回归性能的影响，特别是贪婪地最大化任务间差异的排序策略。

Method: 利用 Kaczmarz 方法的工具来形式化贪婪任务排序，并从几何和代数角度进行分析。通过在合成数据和 CIFAR-100 数据集上进行实验来评估贪婪排序与随机排序的性能。

Result: 经验结果表明，贪婪排序在平均损失方面比随机排序收敛更快。分析结果表明，在某些条件下（例如，允许重复的任务排序），贪婪排序的收敛率为 O(1/k^(1/3))，而随机排序的收敛率为 O(1/√k)。然而，单次传递的贪婪排序可能表现不佳。

Conclusion: 贪婪的任务排序策略在持续学习的线性回归中可能比随机排序更快收敛，但其性能高度依赖于任务的重复和具体设置。分析表明，贪婪排序的理论收敛性可能不如随机排序，特别是在没有重复的情况下，需要进一步研究以理解其局限性。

Abstract: We analyze task orderings in continual learning for linear regression,
assuming joint realizability of training data. We focus on orderings that
greedily maximize dissimilarity between consecutive tasks, a concept briefly
explored in prior work but still surrounded by open questions. Using tools from
the Kaczmarz method literature, we formalize such orderings and develop
geometric and algebraic intuitions around them. Empirically, we demonstrate
that greedy orderings converge faster than random ones in terms of the average
loss across tasks, both for linear regression with random data and for linear
probing on CIFAR-100 classification tasks. Analytically, in a high-rank
regression setting, we prove a loss bound for greedy orderings analogous to
that of random ones. However, under general rank, we establish a
repetition-dependent separation. Specifically, while prior work showed that for
random orderings, with or without replacement, the average loss after $k$
iterations is bounded by $\mathcal{O}(1/\sqrt{k})$, we prove that single-pass
greedy orderings may fail catastrophically, whereas those allowing repetition
converge at rate $\mathcal{O}(1/\sqrt[3]{k})$. Overall, we reveal nuances
within and between greedy and random orderings.

</details>


### [379] [Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets](https://arxiv.org/abs/2510.19950)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: RL 智能体在金融应用中，训练时其行为不影响价格，但部署时会影响价格（市场冲击），这导致性能下降。现有方法无法处理市场冲击的方向性。本研究提出一种新的椭圆不确定性集，并提供求解方法，实现了高效可行的鲁棒策略评估。实验表明，该方法在交易任务中表现优越，且在交易量增加时保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 金融应用中的强化学习（RL）智能体在训练时其行为不影响价格，但在部署时其交易行为会影响资产价格（市场冲击），这种训练和部署环境的不匹配会导致性能显著下降。传统的鲁棒RL方法虽然能处理模型失误，但依赖于对称结构，无法捕捉市场冲击的方向性。

Method: 提出一类新颖的椭圆不确定性集，并建立求解此类不确定性集下最坏情况不确定性的隐式和显式闭式解，以实现高效可行的鲁棒策略评估。

Result: 在单资产和多资产交易任务上的实验表明，该方法能够获得更高的夏普比率，并在交易量增加的情况下保持鲁棒性。

Conclusion: 该研究为金融市场中的 RL 提供了一种更真实、可扩展的方法。

Abstract: In financial applications, reinforcement learning (RL) agents are commonly
trained on historical data, where their actions do not influence prices.
However, during deployment, these agents trade in live markets where their own
transactions can shift asset prices, a phenomenon known as market impact. This
mismatch between training and deployment environments can significantly degrade
performance. Traditional robust RL approaches address this model
misspecification by optimizing the worst-case performance over a set of
uncertainties, but typically rely on symmetric structures that fail to capture
the directional nature of market impact. To address this issue, we develop a
novel class of elliptic uncertainty sets. We establish both implicit and
explicit closed-form solutions for the worst-case uncertainty under these sets,
enabling efficient and tractable robust policy evaluation. Experiments on
single-asset and multi-asset trading tasks demonstrate that our method achieves
superior Sharpe ratio and remains robust under increasing trade volumes,
offering a more faithful and scalable approach to RL in financial markets.

</details>


### [380] [On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization](https://arxiv.org/abs/2510.19953)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 提出了一种新颖的无偏零阶优化（ZOO）梯度估计器，该估计器通过函数评估消除偏差，并在理论上和实验上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶优化（ZOO）方法在梯度估计中存在固有偏差，限制了其应用，尤其是在梯度不可用或计算成本高昂的情况下。

Method: 通过将方向导数重新构建为伸缩级数，并从精心设计的分布中进行采样，提出了一种新的无偏梯度估计器家族。分析了这些估计器的理论性质，推导了四种特定构造的最优缩放分布和扰动步长，并证明了使用该估计器的随机梯度下降（SGD）可以实现光滑非凸目标的最优复杂度。

Result: 实验表明，在合成任务和语言模型微调中，所提出的方法相比标准方法具有更高的准确性和收敛速度。

Conclusion: 所提出的无偏梯度估计器家族克服了现有ZOO方法的偏差问题，并在理论和实践中都显示出优越性，能够实现光滑非凸目标的最优复杂度。

Abstract: Zeroth-order optimization (ZOO) is an important framework for stochastic
optimization when gradients are unavailable or expensive to compute. A
potential limitation of existing ZOO methods is the bias inherent in most
gradient estimators unless the perturbation stepsize vanishes. In this paper,
we overcome this biasedness issue by proposing a novel family of unbiased
gradient estimators based solely on function evaluations. By reformulating
directional derivatives as a telescoping series and sampling from carefully
designed distributions, we construct estimators that eliminate bias while
maintaining favorable variance. We analyze their theoretical properties, derive
optimal scaling distributions and perturbation stepsizes of four specific
constructions, and prove that SGD using the proposed estimators achieves
optimal complexity for smooth non-convex objectives. Experiments on synthetic
tasks and language model fine-tuning confirm the superior accuracy and
convergence of our approach compared to standard methods.

</details>


### [381] [Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations](https://arxiv.org/abs/2510.19975)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文提出了一种方向对齐扰动（DAP）方案，用于优化零阶梯度估计，并在理论和实证上证明了其相对于传统固定长度扰动方法的优势。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注固定长度扰动，忽略了方向对齐扰动的潜在优势，而方向对齐扰动能在关键方向上提供更高的精度。

Method: 将寻找最优扰动分布的问题制定为一个约束泛函优化问题，并引入了方向对齐扰动（DAP）方案，同时对使用δ-无偏随机扰动的随机梯度下降进行了收敛性分析。

Result: DAP方案在理论上可以减少渐近方差，并且在合成问题和实际任务的经验评估中，DAPs在特定条件下优于传统方法。

Conclusion: 方向对齐扰动（DAP）方案提供了一种更优的零阶梯度估计方法，尤其在特定条件下能带来性能提升。

Abstract: In this paper, we explore the two-point zeroth-order gradient estimator and
identify the distribution of random perturbations that minimizes the
estimator's asymptotic variance as the perturbation stepsize tends to zero. We
formulate it as a constrained functional optimization problem over the space of
perturbation distributions. Our findings reveal that such desired perturbations
can align directionally with the true gradient, instead of maintaining a fixed
length. While existing research has largely focused on fixed-length
perturbations, the potential advantages of directional alignment have been
overlooked. To address this gap, we delve into the theoretical and empirical
properties of the directionally aligned perturbation (DAP) scheme, which
adaptively offers higher accuracy along critical directions. Additionally, we
provide a convergence analysis for stochastic gradient descent using
$\delta$-unbiased random perturbations, extending existing complexity bounds to
a wider range of perturbations. Through empirical evaluations on both synthetic
problems and practical tasks, we demonstrate that DAPs outperform traditional
methods under specific conditions.

</details>


### [382] [Towards Strong Certified Defense with Universal Asymmetric Randomization](https://arxiv.org/abs/2510.19977)
*Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong*

Main category: cs.LG

TL;DR: UCAN通过引入各向异性噪声来增强随机平滑在对抗性鲁棒性认证中的有效性，提高了在MNIST、CIFAR10和ImageNet数据集上的认证准确率。


<details>
  <summary>Details</summary>
Motivation: 现有随机平滑方法使用各向同性噪声，忽略了数据维度的异质性，限制了鲁棒性认证的效果。UCAN旨在解决这一限制。

Method: UCAN是一种将现有随机平滑方法从对称（各向同性）噪声转换为不对称（各向异性）噪声分布的新技术。它提供了一个通用的理论框架，支持多种噪声分布，适用于不同的$\ell_p$-范数和任意分类器，并通过量身定制的噪声注入来保证分类器在扰动输入上的预测，具有可证明的鲁棒性界限。此外，UCAN还包含一个新颖的框架，带有三个噪声参数生成器（NPGs），可以为不同数据维度最优地调整各向异性噪声参数。

Result: UCAN在MNIST、CIFAR10和ImageNet数据集上，在较大的认证半径下，认证准确率相较于现有最先进方法有高达182.6%的提升。

Conclusion: UCAN通过引入各向异性噪声，显著提高了随机平滑在对抗性鲁棒性认证方面的性能，为提升模型鲁棒性提供了一种更有效、更灵活的方法。

Abstract: Randomized smoothing has become essential for achieving certified adversarial
robustness in machine learning models. However, current methods primarily use
isotropic noise distributions that are uniform across all data dimensions, such
as image pixels, limiting the effectiveness of robustness certification by
ignoring the heterogeneity of inputs and data dimensions. To address this
limitation, we propose UCAN: a novel technique that \underline{U}niversally
\underline{C}ertifies adversarial robustness with \underline{A}nisotropic
\underline{N}oise. UCAN is designed to enhance any existing randomized
smoothing method, transforming it from symmetric (isotropic) to asymmetric
(anisotropic) noise distributions, thereby offering a more tailored defense
against adversarial attacks. Our theoretical framework is versatile, supporting
a wide array of noise distributions for certified robustness in different
$\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the
classifier's prediction over perturbed inputs with provable robustness bounds
through tailored noise injection. Additionally, we develop a novel framework
equipped with three exemplary noise parameter generators (NPGs) to optimally
fine-tune the anisotropic noise parameters for different data dimensions,
allowing for pursuing different levels of robustness enhancements in
practice.Empirical evaluations underscore the significant leap in UCAN's
performance over existing state-of-the-art methods, demonstrating up to
$182.6\%$ improvement in certified accuracy at large certified radii on MNIST,
CIFAR10, and ImageNet datasets.\footnote{Code is anonymously available at
\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}

</details>


### [383] [Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency](https://arxiv.org/abs/2510.19980)
*Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Time series forecasting plays a pivotal role in critical domains such as
energy management and financial markets. Although deep learning-based
approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the
prevailing "long-sequence information gain hypothesis" exhibits inherent
limitations. Through systematic experimentation, this study reveals a
counterintuitive phenomenon: appropriately truncating historical data can
paradoxically enhance prediction accuracy, indicating that existing models
learn substantial redundant features (e.g., noise or irrelevant fluctuations)
during training, thereby compromising effective signal extraction. Building
upon information bottleneck theory, we propose an innovative solution termed
Adaptive Masking Loss with Representation Consistency (AMRC), which features
two core components: 1) Dynamic masking loss, which adaptively identified
highly discriminative temporal segments to guide gradient descent during model
training; 2) Representation consistency constraint, which stabilized the
mapping relationships among inputs, labels, and predictions. Experimental
results demonstrate that AMRC effectively suppresses redundant feature learning
while significantly improving model performance. This work not only challenges
conventional assumptions in temporal modeling but also provides novel
theoretical insights and methodological breakthroughs for developing efficient
and robust forecasting models.

</details>


### [384] [No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models](https://arxiv.org/abs/2510.19990)
*Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown*

Main category: cs.LG

TL;DR: MDLMs 在数学和代码任务上表现不佳，但推理即填充（reasoning-as-infilling）和多令牌熵解码（MED）可以提高其性能。


<details>
  <summary>Details</summary>
Motivation: MDLMs 在数学和代码任务上的表现不如预期，现有算法存在不足，需要新的方法来发挥其潜力。

Method: 提出推理即填充（reasoning-as-infilling）方法，通过填充推理模板来结构化输出，区分推理和答案，实现答案不确定性测量和提前退出。同时，利用MDLM后验推理轨迹进行微调，并在GSM8k数据集上验证其有效性。提出多令牌熵解码（MED）方法，通过最小化并行解码误差来提高效率和性能。

Result: 在GSM8k数据集上，通过MDLM后验推理轨迹微调LLaDA-8B Base取得了与人类轨迹微调相当的性能提升。MED方法在保持性能的同时，将解码步数减少了2.7倍。

Conclusion: MDLMs 的训练和计算资源可以解锁新的推理和后训练方法，例如推理即填充和多令牌熵解码，从而提高其在特定任务上的表现和效率。

Abstract: Masked diffusion language models (MDLMs) are trained to in-fill positions in
randomly masked sequences, in contrast to next-token prediction models.
Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2)
multi-token decoding. However, we observe that for math and coding tasks,
any-order algorithms often underperform or behave similarly to left-to-right
sampling, and standard multi-token decoding significantly degrades performance.
At inference time, MDLMs compute the conditional distribution of all masked
positions. A natural question is: How can we justify this additional compute
when left-to-right one-token-at-a-time decoding is on par with any-order
decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs
to infill a reasoning template, we can structure outputs and distinguish
between reasoning and answer tokens. In turn, this enables measuring answer
uncertainty during reasoning, and early exits when the model converges on an
answer. Next, given an answer, reasoning-as-infilling enables sampling from the
MDLM posterior over reasoning traces conditioned on the answer, providing a new
source of high-quality data for post-training. On GSM8k, we observe that
fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a
performance boost on par with fine-tuning on human-written reasoning traces.
Additionally, given an answer, reasoning-as-infilling provides a method for
scoring the correctness of the reasoning process at intermediate steps. Second,
we propose multi-token entropy decoding (MED), a simple adaptive sampler that
minimizes the error incurred by decoding positions in parallel based on the
conditional entropies of those positions. MED preserves performance across
benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the
training and compute used by MDLMs unlock many new inference and post-training
methods.

</details>


### [385] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: RFID 追踪在国防资产安全存储方面有潜力，但传感器特异性差（如远距离探测、欺骗、伪造）会导致错误检测和安全事件。本研究提出了一种监督学习模拟方法，使用真实的接收信号强度指示（RSSI）数据和决策树分类，在计算机辅助设计（CAD）建模的楼层平面中解决这些挑战，并专注于区分 12 个实验室区域（LabZoneA-L）以进行位置推断。


<details>
  <summary>Details</summary>
Motivation: 解决国防资产存储中 RFID 追踪因传感器特异性差而可能导致的错误检测和安全漏洞问题。

Method: 在 CAD 建模的楼层平面中使用真实的 RSSI 数据和决策树分类进行监督学习模拟，处理了约 980,000 个读数，并通过计算类别权重来解决类别不平衡问题，模型训练在分层的子样本上进行，达到 5,000 个平衡观测值。

Result: 模型整体准确率为 34.2%，多个区域（F、G、H 等）的 F1 分数大于 0.40。然而，稀有类别（尤其是 LabZoneC）即使在使用类别权重后仍经常被错误分类。计算了邻近感知混淆矩阵以更好地解释物理上相邻的区域。

Conclusion: 基于 RSSI 的决策树可应用于现实模拟中，实现国防供应链物流的区域级异常检测或错放监控。通过改进天线放置或增加传感器以及与其他传感模式融合，可以提高低覆盖和低信号区域的可靠分类性能。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [386] [SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph](https://arxiv.org/abs/2510.20022)
*Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong*

Main category: cs.LG

TL;DR: LLMs在单轮任务中表现出色，但在复杂多步任务中存在挑战。现有基于稀疏奖励的强化学习（RL）方法（特别是无评论家模型的小组RL算法，如GRPO）在处理这类任务时存在不稳定性。本文提出的SALT框架通过构建轨迹图，量化每一步的质量并据此分配优势，从而为稀疏奖励提供更细粒度的优势分配，解决了这一挑战。SALT可即插即用地集成到现有的小组RL算法中，无需修改回滚程序且计算开销可忽略。实验证明SALT在多个基准测试中始终能提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于稀疏奖励的强化学习方法，特别是小组RL算法，在处理复杂多步任务时存在训练不稳定和次优策略的问题，因为它们的奖励机制无法区分轨迹中不同步骤动作的好坏。

Method: 提出了一种名为SALT的新型轻量级框架，通过构建来自相同提示的轨迹图，量化每一步的质量，并据此分配更细粒度的优势，以解决稀疏奖励的问题。SALT可以即插即用，无需修改回滚程序，计算开销极小。

Result: 在WebShop、ALFWorld和AppWorld基准测试以及各种模型规模上进行的广泛实验表明，SALT能够持续提升性能。

Conclusion: SALT是一个轻量级、即插即用的框架，通过从稀疏奖励中推导出更精细的优势分配，有效解决了现有小组RL算法在处理复杂多步任务时面临的挑战，并能提升模型性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
enabling language agents to excel at single-turn tasks. However, their
application to complex, multi-step, and long-horizon tasks remains challenging.
While reinforcement learning (RL) offers a promising avenue for addressing
these challenges, mainstream approaches typically rely solely on sparse,
outcome-based rewards, a limitation that becomes especially problematic for
group-based RL algorithms lacking critic models, such as Group Relative Policy
Optimization (GRPO). In such methods, uniformly rewarding or penalizing all
actions within a trajectory can lead to training instability and suboptimal
policies, because beneficial and detrimental actions are often entangled across
multi-step interactions. To address this challenge, we propose SALT, a novel
and lightweight framework that provides a finer-grained advantage assignment,
derived solely from outcome rewards. We achieve this by constructing a graph
from trajectories of the same prompt, which allows us to quantify the quality
of each step and assign advantages accordingly. Crucially, SALT is designed as
a plug-and-play module that seamlessly integrates with existing group-based RL
algorithms, requiring no modifications to the rollout procedure and introducing
negligible computational overhead. Extensive experiments on the WebShop,
ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that
SALT consistently improves performance. We also conduct a thorough analysis to
validate the design choices behind SALT and offer actionable insights.

</details>


### [387] [The Temporal Graph of Bitcoin Transactions](https://arxiv.org/abs/2510.20028)
*Vahid Jalili*

Main category: cs.LG

TL;DR: 该论文构建了一个适用于机器学习的比特币经济拓扑图，解决了现有数据难以用于机器学习的问题。该图包含完整的交易历史，节点和边数量巨大，并提供了相应的采样方法、分析工具和数据库快照，旨在促进机器学习在比特币生态分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 比特币网络产生了海量交易数据，具有很高的机器学习研究潜力。然而，其假名和UTXO模型带来的资金流动模糊性阻碍了数据的可及性，因此需要一个可用于机器学习的数据集和工具来解决这一难题。

Method: 通过重建资金流动，构建了一个比特币经济拓扑的时间异构图，其中包含截至 `cutoffHeight` 的完整交易历史，拥有超过24亿个节点和397.2亿条边。此外，还提供了自定义采样方法、用于分析的工具以及数据库快照。

Result: 创建了一个包含超过24亿节点和397.2亿条边的比特币经济拓扑图，涵盖了完整的交易历史。同时，提供了用于生成节点和边特征向量的采样方法、用于在图数据库中加载和分析数据的工具，以及可用的数据库快照。

Conclusion: 该论文提供了一个全面的比特币经济图数据集和工具包，使得机器学习社区能够大规模地研究比特币的复杂生态系统，从而在异常检测、地址分类、市场分析和大规模图机器学习基准测试等领域取得进展。

Abstract: Since its 2009 genesis block, the Bitcoin network has processed \num{>1.08}
billion (B) transactions representing \num{>8.72}B BTC, offering rich potential
for machine learning (ML); yet, its pseudonymity and obscured flow of funds
inherent in its \utxo-based design, have rendered this data largely
inaccessible for ML research. Addressing this gap, we present an ML-compatible
graph modeling the Bitcoin's economic topology by reconstructing the flow of
funds. This temporal, heterogeneous graph encompasses complete transaction
history up to block \cutoffHeight, consisting of \num{>2.4}B nodes and
\num{>39.72}B edges. Additionally, we provide custom sampling methods yielding
node and edge feature vectors of sampled communities, tools to load and analyze
the Bitcoin graph data within specialized graph databases, and ready-to-use
database snapshots. This comprehensive dataset and toolkit empower the ML
community to tackle Bitcoin's intricate ecosystem at scale, driving progress in
applications such as anomaly detection, address classification, market
analysis, and large-scale graph ML benchmarking. Dataset and code available at
\href{https://github.com/B1AAB/EBA}{github.com/b1aab/eba}

</details>


### [388] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 本论文提出一种基于拒绝采样的算法，可以并行精确采样多个未来值，无需修改或重新训练现有的时间点过程（TPP）模型，并实现了经验上的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的时间点过程（TPP）模型通常使用自回归模型，这使得采样过程本质上是顺序的，限制了效率。然而，在实际应用中，尤其是在大规模场景下，需要高效的并行生成能力。

Method: 提出一种基于拒绝采样的算法，可以直接从现有的TPP模型中并行、精确地采样多个未来事件值，而无需对模型架构进行任何更改或重新训练。

Result: 该算法在理论上具有保证，并且在真实世界的数据集上能够实现经验上的加速，证明了其在实际应用中的有效性。

Conclusion: 该方法在不改变现有模型或进行重新训练的情况下，实现了从TPP模型进行并行和高效生成，弥合了表达能力和生成效率之间的差距，为大规模TPP应用提供了解决方案。

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [389] [Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards](https://arxiv.org/abs/2510.20055)
*Yuwei Cheng,Zifeng Zhao,Haifeng Xu*

Main category: cs.LG

TL;DR: 本研究提出了一种考虑延迟、累积和用户异质性影响的在线广告竞价新方法，并设计了相应的强化学习算法，实现了接近最优的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 在线广告平台需要有效的竞价策略来最大化利润，而准确的广告影响估计需要考虑延迟和长期效应、累积效应（如强化或疲劳）以及用户异质性，但以往研究并未联合考虑这些因素。

Method: 将广告竞价建模为具有延迟泊松奖励的上下文马尔可夫决策过程（CMDP），并提出了一种结合数据划分策略的两阶段最大似然估计器，以控制估计误差。基于此，设计了一种强化学习算法来获得有效的个性化竞价策略。

Result: 该方法实现了接近最优的遗憾界限 $	ilde{O}{(dH^2	ext{sqrt{T}})}$，并通过模拟实验进行了验证。

Conclusion: 所提出的基于CMDP的广告竞价方法能够有效地处理延迟、累积和用户异质性效应，并提供了可控的估计误差和接近最优的性能。

Abstract: Online advertising platforms use automated auctions to connect advertisers
with potential customers, requiring effective bidding strategies to maximize
profits. Accurate ad impact estimation requires considering three key factors:
delayed and long-term effects, cumulative ad impacts such as reinforcement or
fatigue, and customer heterogeneity. However, these effects are often not
jointly addressed in previous studies. To capture these factors, we model ad
bidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson
rewards. For efficient estimation, we propose a two-stage maximum likelihood
estimator combined with data-splitting strategies, ensuring controlled
estimation error based on the first-stage estimator's (in)accuracy. Building on
this, we design a reinforcement learning algorithm to derive efficient
personalized bidding strategies. This approach achieves a near-optimal regret
bound of $\tilde{O}{(dH^2\sqrt{T})}$, where $d$ is the contextual dimension,
$H$ is the number of rounds, and $T$ is the number of customers. Our
theoretical findings are validated by simulation experiments.

</details>


### [390] [Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs](https://arxiv.org/abs/2510.20064)
*Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于投机解码的在线草稿模型选择算法，该算法能够证明与事后诸葛亮的最佳草稿模型竞争，从而提高令牌接受概率或期望接受长度。


<details>
  <summary>Details</summary>
Motivation: 解决投机解码中的在线草稿模型选择问题，旨在提高LLM推理速度。

Method: 设计了一种能够准确评估所有草稿模型的算法，无需额外查询目标模型，并提出了系统高效的在线学习器版本。

Result: 实验证明，该方法在LLM推理速度和代币接受率方面显著优于现有的基线方法，尤其是在需要长推理链的领域。

Conclusion: 所提出的算法能够有效提高投机解码的效率，并且具有广泛的适用性和显著的性能优势。

Abstract: Speculative decoding is widely used in accelerating large language model
(LLM) inference. In this work, we focus on the online draft model selection
problem in speculative decoding. We design an algorithm that provably competes
with the best draft model in hindsight for each query in terms of either the
token acceptance probability or expected acceptance length. In particular, we
show that we can accurately evaluate all draft models, instead of only the
chosen model without incurring additional queries to the target model, which
allows us to improve exponentially over the existing bandit-based approach as
the number of draft models increases. Our approach is generically applicable
with any speculative decoding methods (single draft, multi-drafts and
draft-trees). Moreover, we design system-efficient versions of online learners
and demonstrate that the overhead in computation and latency can be
substantially reduced. We conduct extensive experiments on open-source LLMs and
diverse datasets, demonstrating that our methods substantially outperform the
state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains
where specialized domain-expert drafters are available, especially when long
reasoning chains are required.

</details>


### [391] [Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts](https://arxiv.org/abs/2510.20666)
*Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas*

Main category: cs.LG

TL;DR: 本研究提出了一种融合物理路径损耗模型和卷积神经网络的混合贝叶斯模型，用于在城市环境中进行GNSS信号干扰定位和接收信号强度场重建。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在城市环境中GNSS信号定位精度尚可，但由于空间上下文有限，接收信号强度（RSS）场重建效果不佳。

Method: 提出了一种混合贝叶斯混合专家框架，通过对数线性池化融合了物理路径损耗（PL）模型和卷积神经网络（CNN）。PL专家确保物理一致性，而CNN利用建筑物高度图来捕捉城市传播效应。通过拉普拉斯近似的贝叶斯推理，提供了干扰源位置和RSS场的不确定性后验。

Result: 在城市射线追踪数据上的实验表明，随着训练点增多，定位精度提高，不确定性降低。不确定性集中在干扰源附近以及传播最敏感的城市峡谷。

Conclusion: 本研究提出的混合贝叶斯模型能够有效提高城市环境中GNSS信号干扰定位精度，并能准确地重建RSS场及其不确定性。

Abstract: Global Navigation Satellite System (GNSS) signals are vulnerable to jamming,
particularly in urban areas where multipath and shadowing distort received
power. Previous data-driven approaches achieved reasonable localization but
poorly reconstructed the received signal strength (RSS) field due to limited
spatial context. We propose a hybrid Bayesian mixture-of-experts framework that
fuses a physical path-loss (PL) model and a convolutional neural network (CNN)
through log-linear pooling. The PL expert ensures physical consistency, while
the CNN leverages building-height maps to capture urban propagation effects.
Bayesian inference with Laplace approximation provides posterior uncertainty
over both the jammer position and RSS field. Experiments on urban ray-tracing
data show that localization accuracy improves and uncertainty decreases with
more training points, while uncertainty concentrates near the jammer and along
urban canyons where propagation is most sensitive.

</details>


### [392] [A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers](https://arxiv.org/abs/2510.20066)
*Yimeng Qiu,Feihuang Fang*

Main category: cs.LG

TL;DR: 加密资产的流动性和波动性溢出可以预测市场风险。


<details>
  <summary>Details</summary>
Motivation: 研究核心加密资产的流动性和波动性代理是否会产生预测市场整体风险的溢出效应。

Method: 采用包括核心流动性与回报的交互作用、链接流动性与回报的成分关系、以及捕捉跨截面波动性聚集的波动性因子预测在内的三层统计框架。辅以向量自回归脉冲响应、预测误差方差分解、异质自回归模型（HAR-X）以及基于时间分割、提前停止、仅验证阈值和SHAP解释的防泄露机器学习协议。

Result: 每日数据（2021-2025年，74个资产，1462个观测值）显示，在各层之间存在统计上显著的格兰德因果关系，并且具有中等的样本外预测准确性。

Conclusion: 核心加密资产的流动性和波动性之间的溢出效应对市场风险具有一定的预测能力。

Abstract: We study whether liquidity and volatility proxies of a core set of
cryptoassets generate spillovers that forecast market-wide risk. Our empirical
framework integrates three statistical layers: (A) interactions between core
liquidity and returns, (B) principal-component relations linking liquidity and
returns, and (C) volatility-factor projections that capture cross-sectional
volatility crowding. The analysis is complemented by vector autoregression
impulse responses and forecast error variance decompositions (see Granger 1969;
Sims 1980), heterogeneous autoregressive models with exogenous regressors
(HAR-X, Corsi 2009), and a leakage-safe machine learning protocol using
temporal splits, early stopping, validation-only thresholding, and SHAP-based
interpretation. Using daily data from 2021 to 2025 (1462 observations across 74
assets), we document statistically significant Granger-causal relationships
across layers and moderate out-of-sample predictive accuracy. We report the
most informative figures, including the pipeline overview, Layer A heatmap,
Layer C robustness analysis, vector autoregression variance decompositions, and
the test-set precision-recall curve. Full data and figure outputs are provided
in the artifact repository.

</details>


### [393] [Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics](https://arxiv.org/abs/2510.20068)
*Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simultaneous recordings from thousands of neurons across multiple brain areas
reveal rich mixtures of activity that are shared between regions and dynamics
that are unique to each region. Existing alignment or multi-view methods
neglect temporal structure, whereas dynamical latent variable models capture
temporal dependencies but are usually restricted to a single area, assume
linear read-outs, or conflate shared and private signals. We introduce the
Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both
(i) non-stationary, non-linear dynamics and (ii) separation of shared versus
region-specific structure in a single framework. CTAE employs transformer
encoders and decoders to capture long-range neural dynamics and explicitly
partitions each region's latent space into orthogonal shared and private
subspaces. We demonstrate the effectiveness of CTAE on two high-density
electrophysiology datasets with simultaneous recordings from multiple regions,
one from motor cortical areas and the other from sensory areas. CTAE extracts
meaningful representations that better decode behavioral variables compared to
existing approaches.

</details>


### [394] [ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models](https://arxiv.org/abs/2510.20084)
*Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan*

Main category: cs.LG

TL;DR: ShapeX框架通过识别时间序列中的关键形状片段来提高可解释性，弥补了现有方法忽略形状片段重要性的不足。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列解释方法主要关注时间步，忽略了在分类中起关键作用的形状片段，因此需要一个能够识别和评估形状片段重要性的新框架。

Method: 提出ShapeX框架，该框架首先使用形状片段描述与检测（SDD）学习一组形状片段，然后使用Shapley值评估这些形状片段的显着性，将时间序列分割成由形状片段驱动的有意义的片段。

Result: ShapeX在合成和真实世界数据集上识别最相关子序列方面优于现有方法，提高了时间序列解释的精度和因果保真度。

Conclusion: ShapeX通过识别和解释形状片段，提供了更精确、更具因果关系的时间序列分类解释，这在医疗和金融等高风险领域至关重要。

Abstract: Explaining time series classification models is crucial, particularly in
high-stakes applications such as healthcare and finance, where transparency and
trust play a critical role. Although numerous time series classification
methods have identified key subsequences, known as shapelets, as core features
for achieving state-of-the-art performance and validating their pivotal role in
classification outcomes, existing post-hoc time series explanation (PHTSE)
methods primarily focus on timestep-level feature attribution. These
explanation methods overlook the fundamental prior that classification outcomes
are predominantly driven by key shapelets. To bridge this gap, we present
ShapeX, an innovative framework that segments time series into meaningful
shapelet-driven segments and employs Shapley values to assess their saliency.
At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,
which effectively learns a diverse set of shapelets essential for
classification. We further demonstrate that ShapeX produces explanations which
reveal causal relationships instead of just correlations, owing to the
atomicity properties of shapelets. Experimental results on both synthetic and
real-world datasets demonstrate that ShapeX outperforms existing methods in
identifying the most relevant subsequences, enhancing both the precision and
causal fidelity of time series explanations.

</details>


### [395] [Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa](https://arxiv.org/abs/2510.20085)
*Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种基于MentalRoBERTa的分层双头神经网络，用于对社交媒体用户的自杀风险进行四级分类（提示、意念、行为、企图），解决了类别不平衡、时间复杂性和风险等级的序数/类别双重性质等挑战。


<details>
  <summary>Details</summary>
Motivation: 自动化检测系统在识别社交媒体中的自杀风险方面面临严峻的类别不平衡、发布模式的时间复杂性以及风险等级的序数和类别双重性质等挑战。

Method: 提出了一种基于MentalRoBERTa的分层双头神经网络。该模型使用一个共享的序列表示，并结合了两个互补的预测头：CORAL（保持风险等级的序数关系）和标准分类头（实现灵活的类别区分）。通过一个3层Transformer编码器（8头多头注意力）来模拟帖文序列之间的时间依赖性，并使用显式的时间间隔嵌入来捕捉发布行为动态。通过一个结合损失函数（0.5 CORAL + 0.3交叉熵 + 0.2 Focal Loss）进行训练，以解决序数结构保持、过度自信减少和类别不平衡问题。为了提高计算效率，冻结了MentalRoBERTa的前6层，并采用了混合精度训练。

Result: 通过5折分层交叉验证进行评估，主要指标为宏F1分数。

Conclusion: 该研究提出了一种新颖的神经网络模型，通过结合序数和类别预测、时间依赖性建模以及优化的训练策略，有效解决了社交媒体自杀风险检测中的多重挑战。

Abstract: Social media platforms have become important sources for identifying suicide
risk, but automated detection systems face multiple challenges including severe
class imbalance, temporal complexity in posting patterns, and the dual nature
of risk levels as both ordinal and categorical. This paper proposes a
hierarchical dual-head neural network based on MentalRoBERTa for suicide risk
classification into four levels: indicator, ideation, behavior, and attempt.
The model employs two complementary prediction heads operating on a shared
sequence representation: a CORAL (Consistent Rank Logits) head that preserves
ordinal relationships between risk levels, and a standard classification head
that enables flexible categorical distinctions. A 3-layer Transformer encoder
with 8-head multi-head attention models temporal dependencies across post
sequences, while explicit time interval embeddings capture posting behavior
dynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3
Cross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure
preservation, overconfidence reduction, and class imbalance. To improve
computational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa
and employ mixed-precision training. The model is evaluated using 5-fold
stratified cross-validation with macro F1 score as the primary metric.

</details>


### [396] [Competition is the key: A Game Theoretic Causal Discovery Approach](https://arxiv.org/abs/2510.20106)
*Amartya Roy,Souvik Chakraborty*

Main category: cs.LG

TL;DR: 提出了一种基于博弈论强化学习的因果发现新框架，该框架在理论上具有有限样本保证，并且在实际应用中具有可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法在经验性能和理论保证之间存在差距，要么缺乏有限样本保证，要么无法扩展。

Method: 利用深度双 Q 网络（DDQN）智能体与现有基线（GES 或 GraN-DAG）进行博弈，并从对手的解决方案开始训练，以获得可证明的收敛性和准确性。

Result: 在合成和真实世界数据集上，该方法均优于现有基线，并且在具有多达 220 个节点的图上表现出良好的可扩展性，同时提供了理论保证。

Conclusion: 该研究提出了一类新的基于强化学习的因果发现算法，它们兼具理论一致性、样本效率和实际可扩展性，弥合了经验性能与严格理论之间的差距。

Abstract: Causal discovery remains a central challenge in machine learning, yet
existing methods face a fundamental gap: algorithms like GES and GraN-DAG
achieve strong empirical performance but lack finite-sample guarantees, while
theoretically principled approaches fail to scale. We close this gap by
introducing a game-theoretic reinforcement learning framework for causal
discovery, where a DDQN agent directly competes against a strong baseline (GES
or GraN-DAG), always warm-starting from the opponent's solution. This design
yields three provable guarantees: the learned graph is never worse than the
opponent, warm-starting strictly accelerates convergence, and most importantly,
with high probability the algorithm selects the true best candidate graph. To
the best of our knowledge, our result makes a first-of-its-kind progress in
explaining such finite-sample guarantees in causal discovery: on synthetic SEMs
(30 nodes), the observed error probability decays with n, tightly matching
theory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,
Dream, and Andes, our method consistently improves upon GES and GraN-DAG while
remaining theoretically safe. Remarkably, it scales to large graphs such as
Hepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these
results establish a new class of RL-based causal discovery algorithms that are
simultaneously provably consistent, sample-efficient, and practically scalable,
marking a decisive step toward unifying empirical performance with rigorous
finite-sample theory.

</details>


### [397] [On pattern classification with weighted dimensions](https://arxiv.org/abs/2510.20107)
*Ayatullah Faruk Mollah*

Main category: cs.LG

TL;DR: 该研究提出了一种新的加权KNN分类器，通过对不同维度赋予不同权重来改进模式分类，尤其在基因表达数据集上表现出色，提高了约10%的分类精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于维度距离的度量方法在处理多维样本时存在不足，尤其是在模式分析和分类场景下，标准的欧氏距离等方法存在诸多问题。因此，需要一种更有效的加权机制来提高分类的准确性和鲁棒性。

Method: 提出了一种新颖的维度加权方案，并将其应用于KNN分类器，同时分析了距离度量范数和维度权重对分类结果的影响，并通过可视化进行展示。

Result: 所提出的加权KNN分类器在多种合成和真实数据集上进行了测试，与传统的KNN分类器相比，在相同的实验设置下表现更优。特别是在基因表达数据集上，分类精度提高了约10%，并且在不同的k值下，所有交叉验证实验都显示出显著且一致的提升。

Conclusion: 该研究提出了一种基于加权明氏距离的KNN分类器泛化方法，通过引入一种新的维度加权方案，能够有效调节包含k个参考样本的区域的形状和大小，从而更好地满足高维稀疏数据集（如基因表达数据集）的需求，实现了有意义的近邻选择，提高了分类精度。

Abstract: Studies on various facets of pattern classification is often imperative while
working with multi-dimensional samples pertaining to diverse application
scenarios. In this notion, weighted dimension-based distance measure has been
one of the vital considerations in pattern analysis as it reflects the degree
of similarity between samples. Though it is often presumed to be settled with
the pervasive use of Euclidean distance, plethora of issues often surface. In
this paper, we present (a) a detail analysis on the impact of distance measure
norms and weights of dimensions along with visualization, (b) a novel weighting
scheme for each dimension, (c) incorporation of this dimensional weighting
schema into a KNN classifier, and (d) pattern classification on a variety of
synthetic as well as realistic datasets with the developed model. It has
performed well across diverse experiments in comparison to the traditional KNN
under the same experimental setups. Specifically, for gene expression datasets,
it yields significant and consistent gain in classification accuracy (around
10%) in all cross-validation experiments with different values of k. As such
datasets contain limited number of samples of high dimensions, meaningful
selection of nearest neighbours is desirable, and this requirement is
reasonably met by regulating the shape and size of the region enclosing the k
number of reference samples with the developed weighting schema and appropriate
norm. It, therefore, stands as an important generalization of KNN classifier
powered by weighted Minkowski distance with the present weighting schema.

</details>


### [398] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 自监督学习方法存在原型坍塌问题，导致原型表示冗余。本文提出解耦训练策略，将原型和编码器分离优化，通过高斯混合模型更新原型，解决了原型坍塌问题，并提高了下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法存在原型坍塌问题，导致原型表示冗余，影响了表示的多样性和信息量。现有解决方案（如过参数化或正则化）治标不治本。

Method: 提出一种完全解耦的训练策略，将原型和编码器的优化目标分开。具体地，原型被建模为高斯混合模型，并使用在线EM风格的过程进行更新，独立于编码器的损失函数。

Result: 解耦训练策略消除了原型坍塌，无需显式正则化，生成了始终多样化的原型，并在下游任务中取得了更好的性能。

Conclusion: 提出的解耦训练策略能够有效解决自监督学习中的原型坍塌问题，并提升模型表示能力和下游任务性能。

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [399] [There is No "apple" in Timeseries: Rethinking TSFM through the Lens of Invariance](https://arxiv.org/abs/2510.20119)
*Arian Prabowo,Flora D. Salim*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFM）数量激增，但传统的监督基线模型甚至经典模型往往能与其媲美。究其原因，在于将自然语言处理（NLP）或计算机视觉（CV）的流水线直接应用于时间序列数据。与包含海量“苹果”图像和文本的网络语料库不同，时间序列数据旨在补充图像和文本，并不存在包含“苹果”这一概念的时间序列数据集。因此，“抓取一切在线数据”的范式对时间序列数据无效。作者提出，为了推动时间序列基础模型的发展，需要从机会性聚合转向原则性设计，构建能够系统性地覆盖时间语义不变性空间的数据集。具体而言，应基于基本原理构建时间序列不变性的本体。只有通过确保不变性覆盖率以实现表征完整性，时间序列基础模型才能获得泛化、推理和真正涌现行为所需的对齐结构。


<details>
  <summary>Details</summary>
Motivation: 目前时间序列基础模型（TSFM）的性能与简单基线模型相当，主要原因是将自然语言处理（NLP）或计算机视觉（CV）的流水线生搬硬套到时间序列数据上，而时间序列数据的特性（缺乏大规模概念覆盖）与前两者不同。因此，需要一种新的方法来构建时间序列数据集，以实现模型的泛化、推理和涌现行为。

Method: 作者提出应基于基本原理构建时间序列不变性的本体，并设计能够系统性地覆盖时间语义不变性空间的数据集，以取代“抓取一切在线数据”的范式。

Result: 通过确保不变性覆盖率以实现表征完整性，时间序列基础模型将能够获得泛化、推理和真正涌现行为所需的对齐结构。

Conclusion: 时间序列基础模型的发展需要从机会性聚合转向原则性设计，构建具有良好不变性覆盖的数据集，才能实现其真正的潜力。

Abstract: Timeseries foundation models (TSFMs) have multiplied, yet lightweight
supervised baselines and even classical models often match them. We argue this
gap stems from the naive importation of NLP or CV pipelines. In language and
vision, large web-scale corpora densely capture human concepts i.e. there are
countless images and text of apples. In contrast, timeseries data is built to
complement the image and text modalities. There are no timeseries dataset that
contains the concept apple. As a result, the scrape-everything-online paradigm
fails for TS. We posit that progress demands a shift from opportunistic
aggregation to principled design: constructing datasets that systematically
span the space of invariance that preserve temporal semantics. To this end, we
suggest that the ontology of timeseries invariances should be built based on
first principles. Only by ensuring representational completeness through
invariance coverage can TSFMs achieve the aligned structure necessary for
generalisation, reasoning, and truly emergent behaviour.

</details>


### [400] [Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling](https://arxiv.org/abs/2510.20148)
*Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu*

Main category: cs.LG

TL;DR:  tau蛋白在阿尔茨海默病（AD）中沿着特定脑网络扩散，其扩散受结构连接（SC）和功能连接（FC）的相互作用影响，且这种影响随疾病进程和区域而异，并与基因表达和风险因素相关。


<details>
  <summary>Details</summary>
Motivation: 探究结构连接（SC）和功能连接（FC）如何相互作用以影响tau蛋白在阿尔茨海默病（AD）中的扩散，因为现有神经影像学证据表明tau蛋白在特定脑网络中的积累与AD进展密切相关。

Method: 利用大规模纵向神经影像数据，采用多层图扩散模型分析SC-FC相互作用，并研究其与AD相关基因表达、非可修饰风险因素和生物机制的关系。

Result: 研究表明，连接组结构限制了tau蛋白的扩散。FC在亚皮层区域、岛叶、额叶和颞叶皮层中主要驱动tau蛋白扩散，而SC在枕叶、顶叶和边缘区域中起更大作用。FC在早期AD中占主导地位，而SC在后期AD中起主导作用。SC和FC占主导的区域的空间模式与AD相关基因（如CHUK, TMEM106B, MCL1, NOTCH1, TH）在炎症、细胞凋亡和溶酶体功能方面的区域表达高度一致。APOE基因型、性别等风险因素和淀粉样蛋白沉积等生物机制通过改变解剖和功能通路之间的主导路径来选择性地重塑tau蛋白扩散。

Conclusion: SC和FC的相互作用以及它们的区域和时间依赖性对于理解tau蛋白在AD中的扩散至关重要，并且与AD的遗传和生物学背景密切相关。

Abstract: Emerging neuroimaging evidence shows that pathological tau proteins build up
along specific brain networks, suggesting that large-scale network architecture
plays a key role in the progression of Alzheimer's disease (AD). However, how
structural connectivity (SC) and functional connectivity (FC) interact to
influence tau propagation remains unclear. Leveraging an unprecedented volume
of longitudinal neuroimaging data, we examine SC-FC interactions through a
multi-layer graph diffusion model. Beyond showing that connectome architecture
constrains tau spread, our model reveals a regionally asymmetric contribution
of SC and FC. Specifically, FC predominantly drives tau spread in subcortical
areas, the insula, frontal and temporal cortices, whereas SC plays a larger
role in occipital, parietal, and limbic regions. The relative dominance of SC
versus FC shifts over the course of disease, with FC generally prevailing in
early AD and SC becoming primary in later stages. Spatial patterns of SC- and
FC-dominant regions strongly align with the regional expression of
AD-associated genes involved in inflammation, apoptosis, and lysosomal
function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In
parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and
biological mechanisms (e.g., amyloid deposition) selectively reshape tau
propagation by shifting dominant routes between anatomical and functional
pathways in a region-specific manner. Findings are validated in an independent
AD cohort.

</details>


### [401] [Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP](https://arxiv.org/abs/2510.20169)
*Tongkai Lu,Shuai Ma,Chongyang Tao*

Main category: cs.LG

TL;DR: 提出了一种用于大规模旅行商问题的超 tour 引导邻域搜索（HyperNS）方法，通过聚类和超 tour 来减少搜索空间，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的旅行商问题解决方法在大规模实例上面临内存限制和搜索空间引导不足的挑战。

Method: 将旅行商问题实例聚类成超节点，并生成超 tour 来指导初始化和优化过程，从而缩小搜索空间。

Result: 在合成和真实世界的数据集上，该方法比现有的基于神经网络的方法表现更好，尤其是在处理大规模实例时，能更有效地接近最优解。

Conclusion: 所提出的 HyperNS 方法能够有效解决大规模旅行商问题，并优于现有的基于神经网络的方法。

Abstract: Traveling Salesman Problem (TSP) is a classic NP-hard problem that has
garnered significant attention from both academia and industry. While
neural-based methods have shown promise for solving TSPs, they still face
challenges in scaling to larger instances, particularly in memory constraints
associated with global heatmaps, edge weights, or access matrices, as well as
in generating high-quality initial solutions and insufficient global guidance
for efficiently navigating vast search spaces. To address these challenges, we
propose a Hyper Tour Guided Neighborhood Search (HyperNS) method for
large-scale TSP instances. Inspired by the ``clustering first, route second"
strategy, our approach initially divides the TSP instance into clusters using a
sparse heatmap graph and abstracts them as supernodes, followed by the
generation of a hyper tour to guide both the initialization and optimization
processes. This method reduces the search space by focusing on edges relevant
to the hyper tour, leading to more efficient and effective optimization.
Experimental results on both synthetic and real-world datasets demonstrate that
our approach outperforms existing neural-based methods, particularly in
handling larger-scale instances, offering a significant reduction in the gap to
the optimal solution.

</details>


### [402] [Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values](https://arxiv.org/abs/2510.20187)
*Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: RLEV是一种将可量化的`人类价值信号`直接整合到`大型语言模型（LLM）`优化中的方法，能够根据`提示的价值`动态调整模型响应的`详尽程度`，即使在`价值信号`存在`噪声`的情况下也`表现稳健`。


<details>
  <summary>Details</summary>
Motivation: 现有基于`可验证奖励`的`强化学习（RL）`方法在`客观领域`中很有效，但忽略了`不同任务`的`重要性`差异。因此，需要一种方法能够将`人类的价值判断`直接纳入`模型优化`过程，以解决`非均衡任务`的重要性问题。

Method: 提出`显式人类价值`的`强化学习（RLEV）`方法，将`人类定义的价值信号`直接整合到`奖励函数`中，以解决`大型语言模型（LLM）`优化与`可量化的`人类价值信号对齐的问题。该方法在`考试风格`的数据上进行训练，并使用`显式的`、`基础事实`的`价值标签`。

Result: 在`多个`RL算法和模型规模上，`RLEV`持续优于`仅关注正确性`的基线模型。`RLEV`策略不仅提高了`价值加权`的准确性，还学会了`价值敏感`的`终止策略`：对于`低价值`的提示，响应`简洁`；对于`高价值`的提示，响应`详尽`。`消融研究`证实了`RLEV`的收益`与其价值对齐`有`因果关系`。`RLEV`在`噪声`的价值信号下（例如，基于`难度`的标签）仍然`表现稳健`。

Conclusion: `RLEV`通过优化`显式效用函数`，为`对齐`大型语言模型与`人类优先事项`提供了一条`实用`的路径。该方法能够根据`提示的价值`动态调整模型响应的`详尽程度`，并且在`价值信号`存在`噪声`的情况下也`表现稳健`。

Abstract: We propose Reinforcement Learning with Explicit Human Values (RLEV), a method
that aligns Large Language Model (LLM) optimization directly with quantifiable
human value signals. While Reinforcement Learning with Verifiable Rewards
(RLVR) effectively trains models in objective domains using binary correctness
rewards, it overlooks that not all tasks are equally significant. RLEV extends
this framework by incorporating human-defined value signals directly into the
reward function. Using exam-style data with explicit ground-truth value labels,
RLEV consistently outperforms correctness-only baselines across multiple RL
algorithms and model scales. Crucially, RLEV policies not only improve
value-weighted accuracy but also learn a value-sensitive termination policy:
concise for low-value prompts, thorough for high-value ones. We demonstrate
this behavior stems from value-weighted gradient amplification on
end-of-sequence tokens. Ablation studies confirm the gain is causally linked to
value alignment. RLEV remains robust under noisy value signals, such as
difficulty-based labels, demonstrating that optimizing for an explicit utility
function offers a practical path to aligning LLMs with human priorities.

</details>


### [403] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 该研究提出了一种风险感知约束强化学习框架，使用优化的确定性等价物（OCEs）来处理期望累积奖励中的风险和异常值，并在奖励值和时间上实现每阶段鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的约束强化学习（RL）框架主要关注期望累积奖励，忽略了奖励分布尾部的风险或灾难性事件，这在高风险应用中是不够的。

Method: 提出了一种风险感知约束RL框架，利用优化的确定性等价物（OCEs）在奖励值和时间上实现每阶段的鲁棒性。该框架与原始约束问题精确等价，并能包装标准RL求解器（如PPO）。

Result: 该框架确保了与原始约束问题的精确等价性，并提供了一个简单的算法方案。通过数值实验验证了其风险感知特性。

Conclusion: 该研究提出的风险感知约束强化学习框架能够处理期望累积奖励中的风险和异常值，并在奖励值和时间上实现每阶段鲁棒性，适用于高风险应用。所提出的算法在常见假设下收敛，并通过数值实验进行了验证。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [404] [Approximate Replicability in Learning](https://arxiv.org/abs/2510.20200)
*Max Hopkins,Russell Impagliazzo,Christopher Ye*

Main category: cs.LG

TL;DR: Replicability, while a strong notion of algorithmic stability, can be costly. This paper introduces three relaxed notions of replicability (Pointwise, Approximate, Semi) in PAC learning. For constant replicability parameters, the paper provides sample-optimal agnostic PAC learners for all three relaxations. Pointwise and Approximate relaxations are achieved with $\Theta(d/\alpha^2)$ samples, while the Semi relaxation requires $\Theta(d^2/\alpha^2)$ labeled samples.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore approximate notions of replicability in the context of PAC learning, given the prohibitive cost of exact replicability for simple tasks, as shown by previous impossibility results.

Method: The paper proposes three natural relaxations of replicability: Pointwise, Approximate, and Semi. It then develops sample-optimal agnostic PAC learners for each of these relaxations, analyzing the sample complexity for each case.

Result: The paper demonstrates that sample-optimal agnostic PAC learners can be obtained for all three proposed relaxations of replicability when the replicability parameters are constant. Specifically, Pointwise and Approximate replicability are achieved with $\Theta(d/\alpha^2)$ samples, and Semi replicability requires $\Theta(d^2/\alpha^2)$ labeled samples.

Conclusion: The paper successfully proposes and analyzes three relaxed notions of replicability, showing that approximate replicability allows for efficient PAC learning with sample-optimal algorithms under constant replicability parameters.

Abstract: Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion
that algorithms should remain stable under a resampling of their inputs (given
access to shared randomness). While a strong and interesting notion of
stability, the cost of replicability can be prohibitive: there is no replicable
algorithm, for instance, for tasks as simple as threshold learning (Bun et al.
STOC '23). Given such strong impossibility results we ask: under what
approximate notions of replicability is learning possible?
  In this work, we propose three natural relaxations of replicability in the
context of PAC learning: (1) Pointwise: the learner must be consistent on any
fixed input, but not across all inputs simultaneously, (2) Approximate: the
learner must output hypotheses that classify most of the distribution
consistently, (3) Semi: the algorithm is fully replicable, but may additionally
use shared unlabeled samples. In all three cases, for constant replicability
parameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are
achievable for ``free" using $\Theta(d/\alpha^2)$ samples, while (3) requires
$\Theta(d^2/\alpha^2)$ labeled samples.

</details>


### [405] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 使用机器学习模型分析常规实验室数据以进行犬类癌症风险分级，但由于癌症信号微弱且受年龄和炎症等非特异性因素干扰，未能实现可靠的临床分类。


<details>
  <summary>Details</summary>
Motivation: 为早期癌症检测开发可及的筛查工具，利用常规实验室数据作为低成本来源，并评估在真实世界约束下的癌症风险分类可行性。

Method: 对来自金毛寻回犬终生研究（GRLS）队列的126个分析流程（包括机器学习模型、特征选择和数据平衡技术）进行了基准评估，并使用SHapley Additive exPlanations（SHAP）进行了可解释性分析。

Result: 最佳模型（加权类别和递归特征消除的逻辑回归分类器）在癌症风险分类方面表现出适度的排名能力（AUROC = 0.815），但临床分类性能不佳（F1分数 = 0.25，阳性预测值 = 0.15），尽管阴性预测值较高（0.98），但召回率不足（0.79）。模型预测主要基于年龄、炎症和贫血等非特异性特征。

Conclusion: 常规实验室数据中存在可检测的癌症信号，但信号过于微弱且受到干扰，无法与正常衰老或其他炎症性疾病进行可靠的临床区分。在孤立地使用此数据模式时，其性能存在关键上限，需要整合多模态数据源才能在计算兽医肿瘤学方面取得有意义的进展。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [406] [CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks](https://arxiv.org/abs/2510.20219)
*Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu*

Main category: cs.LG

TL;DR: CO-PFL是一种新的个性化联邦学习算法，通过动态评估客户端的贡献来解决数据异构和数据量少的问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在处理客户端数据异构和数据量少的问题时，依赖单一的共识模型，并且其聚合方法忽略了客户端更新的实际效用和可靠性，导致个性化效果不佳和聚合偏差。CO-PFL旨在克服这些限制。

Method: CO-PFL通过联合分析梯度方向差异和预测偏差，利用梯度和数据子空间的信 息，动态估计每个客户端对全局聚合的贡献。此外，CO-PFL还结合了参数化个性化机制和掩码感知动量优化，以提高个性化适应性和优化稳定性。

Result: 实验结果表明，CO-PFL在个性化准确性、鲁棒性、可扩展性和收敛稳定性方面优于最先进的方法。

Conclusion: CO-PFL通过动态评估客户端贡献、减少聚合偏差、加强全局协调以及通过稳定的更新促进量身定制的子模型的构建，有效地提高了个性化联邦学习的性能。

Abstract: Personalized federated learning (PFL) addresses a critical challenge of
collaboratively training customized models for clients with heterogeneous and
scarce local data. Conventional federated learning, which relies on a single
consensus model, proves inadequate under such data heterogeneity. Its standard
aggregation method of weighting client updates heuristically or by data volume,
operates under an equal-contribution assumption, failing to account for the
actual utility and reliability of each client's update. This often results in
suboptimal personalization and aggregation bias. To overcome these limitations,
we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that
dynamically estimates each client's contribution for global aggregation. CO-PFL
performs a joint assessment by analyzing both gradient direction discrepancies
and prediction deviations, leveraging information from gradient and data
subspaces. This dual-subspace analysis provides a principled and discriminative
aggregation weight for each client, emphasizing high-quality updates.
Furthermore, to bolster personalization adaptability and optimization
stability, CO-PFL cohesively integrates a parameter-wise personalization
mechanism with mask-aware momentum optimization. Our approach effectively
mitigates aggregation bias, strengthens global coordination, and enhances local
performance by facilitating the construction of tailored submodels with stable
updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,
CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses
state-of-the-art methods in in personalization accuracy, robustness,
scalability and convergence stability.

</details>


### [407] [QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models](https://arxiv.org/abs/2510.20222)
*Hao Wang,Baojun Ma*

Main category: cs.LG

TL;DR: QKCV是一种增强时间序列预测的注意机制，通过引入类别信息来提高准确性，并支持高效的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 在实际时间序列预测任务中，类别信息对于捕捉数据固有模式至关重要。

Method: 提出QKCV（Query-Key-Category-Value）注意力机制，通过引入静态类别嵌入C来增强传统的QKV框架，以突出特定类别的.信息。

Result: QKCV作为一种灵活的插件模块，可以增强基于注意力的模型（如Vanilla Transformer, Informer, PatchTST, TFT）在不同真实世界数据集上的预测准确性。此外，通过仅更新静态嵌入C并保持预训练权重，QKCV在微调单变量时间序列基础模型方面表现出卓越的适应性，从而降低了计算开销并提高了微调性能。

Conclusion: QKCV通过整合类别信息，有效提升了时间序列预测的准确性，并为基础模型提供了高效的迁移学习方案。

Abstract: In real-world time series forecasting tasks, category information plays a
pivotal role in capturing inherent data patterns. This paper introduces QKCV
(Query-Key-Category-Value) attention, an extension of the traditional QKV
framework that incorporates a static categorical embedding C to emphasize
category-specific information. As a versatile plug-in module, QKCV enhances the
forecasting accuracy of attention-based models (e.g., Vanilla Transformer,
Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV
demonstrates remarkable adaptability in fine-tuning univariate time series
foundation model by solely updating the static embedding C while preserving
pretrained weights, thereby reducing computational overhead and achieving
superior fine-tuning performance.

</details>


### [408] [Federated Learning via Meta-Variational Dropout](https://arxiv.org/abs/2510.20225)
*Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim*

Main category: cs.LG

TL;DR: MetaVD是一种新颖的贝叶斯元学习方法，通过学习客户端特定的 dropout 速率来解决联邦学习中的模型过拟合和本地模型不一致问题，在非独立同分布（non-IID）数据设置下提高了模型个性化效果，并降低了通信成本。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）在实际应用中面临模型过拟合和本地模型不一致的挑战，尤其是在数据有限和非独立同分布（non-IID）的情况下。MetaVD旨在解决这些问题，提高模型的个性化效果和鲁棒性。

Method: MetaVD采用贝叶斯元学习方法，通过一个共享的超网络来预测客户端特定的 dropout 速率，从而实现有效的模型个性化。该方法还从后验适应和后验聚合的角度解释了元学习和贝叶斯FL。

Result: 在稀疏和非独立同分布（non-IID）的FL数据集上的大量实验表明，MetaVD在分类准确性和不确定性校准方面表现出色，尤其对于分布外（out-of-distribution）的客户端。此外，MetaVD还能压缩本地模型参数，缓解过拟合并降低通信成本。

Conclusion: MetaVD通过引入客户端特定的 dropout 速率，成功地解决了联邦学习中数据有限和非独立同分布（non-IID）带来的挑战，在提高模型性能和降低通信成本方面都取得了显著效果。

Abstract: Federated Learning (FL) aims to train a global inference model from remotely
distributed clients, gaining popularity due to its benefit of improving data
privacy. However, traditional FL often faces challenges in practical
applications, including model overfitting and divergent local models due to
limited and non-IID data among clients. To address these issues, we introduce a
novel Bayesian meta-learning approach called meta-variational dropout (MetaVD).
MetaVD learns to predict client-dependent dropout rates via a shared
hypernetwork, enabling effective model personalization of FL algorithms in
limited non-IID data settings. We also emphasize the posterior adaptation view
of meta-learning and the posterior aggregation view of Bayesian FL via the
conditional dropout posterior. We conducted extensive experiments on various
sparse and non-IID FL datasets. MetaVD demonstrated excellent classification
accuracy and uncertainty calibration performance, especially for
out-of-distribution (OOD) clients. MetaVD compresses the local model parameters
needed for each client, mitigating model overfitting and reducing communication
costs. Code is available at https://github.com/insujeon/MetaVD.

</details>


### [409] [Sparse Local Implicit Image Function for sub-km Weather Downscaling](https://arxiv.org/abs/2510.20228)
*Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho*

Main category: cs.LG

TL;DR: SpLIIF模型能够从稀疏气象站点和地形数据中生成隐式神经表示，实现任意尺度的天气变量降尺度，并在预测温度和风速方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一种新的方法（SpLIIF）来生成隐式神经表示，以实现天气变量的任意尺度降尺度。

Method: 使用来自日本稀疏气象站点和地形数据训练SpLIIF模型，并将其与插值基线和CorrDiff模型进行比较，评估其在温度和风速预测中的准确性。

Result: SpLIIF模型在降尺度温度方面比CorrDiff和基线模型提高了高达50%，在降尺度风速方面提高了10-20%。

Conclusion: SpLIIF模型在天气变量降尺度方面表现出优越的性能。

Abstract: We introduce SpLIIF to generate implicit neural representations and enable
arbitrary downscaling of weather variables. We train a model from sparse
weather stations and topography over Japan and evaluate in- and
out-of-distribution accuracy predicting temperature and wind, comparing it to
both an interpolation baseline and CorrDiff. We find the model to be up to 50%
better than both CorrDiff and the baseline at downscaling temperature, and
around 10-20% better for wind.

</details>


### [410] [Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach](https://arxiv.org/abs/2510.20235)
*Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung*

Main category: cs.LG

TL;DR: 本文提出了一种用于最大最小化多目标强化学习（MORL）的可证明收敛且实用的框架。从博弈论角度，将最大最小化MORL重构为双人零和正则化连续对策，并提出一种基于镜像下降的高效算法，该算法简化了策略更新并保证了全局最终迭代收敛。论文对其进行了理论分析，包括精确和近似策略评估下的迭代复杂度和样本复杂度界限。为进一步提升性能，还对算法进行了自适应正则化修改。实验结果在表格设置下验证了算法的收敛性，并且在深度强化学习中的实现显著优于先前基线。


<details>
  <summary>Details</summary>
Motivation: 研究最大最小化多目标强化学习（MORL）问题，旨在提供一个既能保证理论收敛性又具有实际应用价值的框架。

Method: 将最大最小化MORL重构为双人零和正则化连续对策，并设计了一种基于镜像下降的高效算法，该算法简化了策略更新并保证了全局最终迭代收敛。同时，对算法进行了自适应正则化修改以提升性能。

Result: 在表格设置下验证了算法的收敛性，并在深度强化学习任务中，相较于现有基线算法，在多个MORL环境中取得了显著的性能提升。

Conclusion: 提出的框架能够有效地解决最大最小化MORL问题，并具有良好的理论收敛性和实际应用性能。

Abstract: In this paper, we propose a provably convergent and practical framework for
multi-objective reinforcement learning with max-min criterion. From a
game-theoretic perspective, we reformulate max-min multi-objective
reinforcement learning as a two-player zero-sum regularized continuous game and
introduce an efficient algorithm based on mirror descent. Our approach
simplifies the policy update while ensuring global last-iterate convergence. We
provide a comprehensive theoretical analysis on our algorithm, including
iteration complexity under both exact and approximate policy evaluations, as
well as sample complexity bounds. To further enhance performance, we modify the
proposed algorithm with adaptive regularization. Our experiments demonstrate
the convergence behavior of the proposed algorithm in tabular settings, and our
implementation for deep reinforcement learning significantly outperforms
previous baselines in many MORL environments.

</details>


### [411] [Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction](https://arxiv.org/abs/2510.20236)
*Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers*

Main category: cs.LG

TL;DR: LKM是一种新的自知识蒸馏方法，可以提高GNN在分子性质预测方面的准确性，同时计算成本可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN模型在提高准确性的同时，计算成本和内存需求也会增加，因此需要更有效率的模型。

Method: LKM通过最小化GNN层之间预先存在的隐藏嵌入的平均绝对距离，来聚合多跳和多尺度信息，从而提高表示能力。

Result: 在QM9、MD17和Chignolin数据集上，LKM将量子化学和生物物理性质预测的平均绝对误差分别降低了高达9.8%、45.3%和22.9%。

Conclusion: LKM有潜力在不显著增加成本的情况下，显著提高GNN在化学性质预测方面的准确性。

Abstract: Graph Neural Networks (GNNs) are the currently most effective methods for
predicting molecular properties but there remains a need for more accurate
models. GNN accuracy can be improved by increasing the model complexity but
this also increases the computational cost and memory requirement during
training and inference. In this study, we develop Layer-to-Layer Knowledge
Mixing (LKM), a novel self-knowledge distillation method that increases the
accuracy of state-of-the-art GNNs while adding negligible computational
complexity during training and inference. By minimizing the mean absolute
distance between pre-existing hidden embeddings of GNN layers, LKM efficiently
aggregates multi-hop and multi-scale information, enabling improved
representation of both local and global molecular features. We evaluated LKM
using three diverse GNN architectures (DimeNet++, MXMNet, and PAMNet) using
datasets of quantum chemical properties (QM9, MD17 and Chignolin). We found
that the LKM method effectively reduces the mean absolute error of quantum
chemical and biophysical property predictions by up to 9.8% (QM9), 45.3% (MD17
Energy), and 22.9% (Chignolin). This work demonstrates the potential of LKM to
significantly improve the accuracy of GNNs for chemical property prediction
without any substantial increase in training and inference cost.

</details>


### [412] [What Does It Take to Build a Performant Selective Classifier?](https://arxiv.org/abs/2510.20242)
*Stephan Rabanser,Nicolas Papernot*

Main category: cs.LG

TL;DR: 选择性分类器通过在模型认为不确定的输入上弃权来提高模型可靠性。然而，很少有实用方法能达到完美的排序神谕的黄金标准性能，后者能正好按正确性顺序接受示例。我们的工作将这一缺口形式化为选择性分类差距，并提出了第一个有限样本分解，将其分解为五个不同的松动来源：贝叶斯噪声、近似误差、排序误差、统计噪声和由实现或移位引起的松弛。至关重要的是，我们的分析揭示了单调的事后校准——通常被认为可以加强选择性分类器——对缩小这一差距的影响有限，因为它很少改变模型潜在的分数排序。因此，弥合差距需要能够有效重新排序预测而不仅仅是重新缩放它们的评分机制。我们在合成双月数据和现实世界的视觉与语言基准上验证了我们的分解，通过对照实验分离了每个误差分量。我们的结果证实了（i）贝叶斯噪声和有限的模型容量可以解释相当大的差距，（ii）只有更丰富的、与特征相关的校准器才能有意义地改善分数排序，以及（iii）数据移位会引入一个需要分布鲁棒训练的单独松弛。总之，我们的分解产生了一个量化的误差预算以及可操作的设计指南，实践者可以使用这些指南来构建更接近理想神谕行为的选择性分类器。


<details>
  <summary>Details</summary>
Motivation: 选择性分类器通过在模型认为不确定的输入上弃权来提高模型可靠性。然而，很少有实用方法能达到完美的排序神谕的黄金标准性能，后者能正好按正确性顺序接受示例。我们的工作将这一缺口形式化为选择性分类差距。

Method: 我们的分析揭示了单调的事后校准——通常被认为可以加强选择性分类器——对缩小这一差距的影响有限，因为它很少改变模型潜在的分数排序。因此，弥合差距需要能够有效重新排序预测而不仅仅是重新缩放它们的评分机制。我们在合成双月数据和现实世界的视觉与语言基准上验证了我们的分解，通过对照实验分离了每个误差分量。

Result: 我们的结果证实了（i）贝叶斯噪声和有限的模型容量可以解释相当大的差距，（ii）只有更丰富的、与特征相关的校准器才能有意义地改善分数排序，以及（iii）数据移位会引入一个需要分布鲁棒训练的单独松弛。

Conclusion: 总之，我们的分解产生了一个量化的误差预算以及可操作的设计指南，实践者可以使用这些指南来构建更接近理想神谕行为的选择性分类器。

Abstract: Selective classifiers improve model reliability by abstaining on inputs the
model deems uncertain. However, few practical approaches achieve the
gold-standard performance of a perfect-ordering oracle that accepts examples
exactly in order of correctness. Our work formalizes this shortfall as the
selective-classification gap and present the first finite-sample decomposition
of this gap to five distinct sources of looseness: Bayes noise, approximation
error, ranking error, statistical noise, and implementation- or shift-induced
slack. Crucially, our analysis reveals that monotone post-hoc calibration --
often believed to strengthen selective classifiers -- has limited impact on
closing this gap, since it rarely alters the model's underlying score ranking.
Bridging the gap therefore requires scoring mechanisms that can effectively
reorder predictions rather than merely rescale them. We validate our
decomposition on synthetic two-moons data and on real-world vision and language
benchmarks, isolating each error component through controlled experiments. Our
results confirm that (i) Bayes noise and limited model capacity can account for
substantial gaps, (ii) only richer, feature-aware calibrators meaningfully
improve score ordering, and (iii) data shift introduces a separate slack that
demands distributionally robust training. Together, our decomposition yields a
quantitative error budget as well as actionable design guidelines that
practitioners can use to build selective classifiers which approximate ideal
oracle behavior more closely.

</details>


### [413] [FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning](https://arxiv.org/abs/2510.20250)
*Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan*

Main category: cs.LG

TL;DR: FedGPS通过整合统计信息和梯度信息来解决联邦学习中的数据异构性问题，并在各种异构场景下表现出比现有方法更优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 评估现有联邦学习方法在不同数据异构场景下的鲁棒性，并在此基础上提出一种新的框架FedGPS来解决数据异构性问题。

Method: FedGPS通过静态修改客户端的学习目标来隐式地模拟全局数据分布，并通过动态调整梯度信息来优化本地更新方向。

Result: FedGPS在各种数据异构场景下，其性能和鲁棒性均优于现有最先进的方法。

Conclusion: FedGPS能够有效且鲁棒地解决联邦学习中的数据异构性问题。

Abstract: Federated Learning (FL) confronts a significant challenge known as data
heterogeneity, which impairs model performance and convergence. Existing
methods have made notable progress in addressing this issue. However, improving
performance in certain heterogeneity scenarios remains an overlooked question:
\textit{How robust are these methods to deploy under diverse heterogeneity
scenarios?} To answer this, we conduct comprehensive evaluations across varied
heterogeneity scenarios, showing that most existing methods exhibit limited
robustness. Meanwhile, insights from these experiments highlight that sharing
statistical information can mitigate heterogeneity by enabling clients to
update with a global perspective. Motivated by this, we propose \textbf{FedGPS}
(\textbf{Fed}erated \textbf{G}oal-\textbf{P}ath \textbf{S}ynergy), a novel
framework that seamlessly integrates statistical distribution and gradient
information from others. Specifically, FedGPS statically modifies each client's
learning objective to implicitly model the global data distribution using
surrogate information, while dynamically adjusting local update directions with
gradient information from other clients at each round. Extensive experiments
show that FedGPS outperforms state-of-the-art methods across diverse
heterogeneity scenarios, validating its effectiveness and robustness. The code
is available at: https://github.com/CUHK-AIM-Group/FedGPS.

</details>


### [414] [Optimistic Task Inference for Behavior Foundation Models](https://arxiv.org/abs/2510.20264)
*Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause*

Main category: cs.LG

TL;DR: BFMs 可实现零样本强化学习，但需要大量数据进行奖励计算。OpTI-BFM 通过测试时与环境交互来解决此问题，通过对奖励函数的不确定性进行建模并指导 BFMs 进行数据收集，从而在少量交互中实现任务推理。


<details>
  <summary>Details</summary>
Motivation: BFMs 在零样本强化学习中需要计算奖励，这在数据方面效率低下。OpTI-BFM 旨在通过测试时与环境交互来解决此限制，从而实现仅通过交互进行任务推理。

Method: OpTI-BFM 提出了一种乐观的决策标准，该标准直接对奖励函数的不确定性进行建模，并指导 BFMs 在测试时进行数据收集以进行任务推理。该方法与用于线性赌博机的置信上限算法相关联，并提供了 BFMs 的遗憾界限。

Result: OpTI-BFM 在零样本基准测试中能够使基于后继特征的 BFMs 在几个交互回合内识别和优化未见过的奖励函数，同时计算开销很小。

Conclusion: OpTI-BFM 是一种有效的方法，可以在数据和计算方面高效地实现零样本强化学习，它通过在测试时与环境交互来指导 BFMs 进行任务推理。

Abstract: Behavior Foundation Models (BFMs) are capable of retrieving high-performing
policy for any reward function specified directly at test-time, commonly
referred to as zero-shot reinforcement learning (RL). While this is a very
efficient process in terms of compute, it can be less so in terms of data: as a
standard assumption, BFMs require computing rewards over a non-negligible
inference dataset, assuming either access to a functional form of rewards, or
significant labeling efforts. To alleviate these limitations, we tackle the
problem of task inference purely through interaction with the environment at
test-time. We propose OpTI-BFM, an optimistic decision criterion that directly
models uncertainty over reward functions and guides BFMs in data collection for
task inference. Formally, we provide a regret bound for well-trained BFMs
through a direct connection to upper-confidence algorithms for linear bandits.
Empirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and
observe that it enables successor-features-based BFMs to identify and optimize
an unseen reward function in a handful of episodes with minimal compute
overhead. Code is available at https://github.com/ThomasRupf/opti-bfm.

</details>


### [415] [ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases](https://arxiv.org/abs/2510.20270)
*Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini*

Main category: cs.LG

TL;DR: LLM代理可能会通过删除失败的测试用例来寻找捷径，而不是修复错误，这会影响评估和部署的可靠性。我们引入了ImpossibleBench基准框架来量化、研究和缓解这种“作弊”行为，通过创建规范与单元测试之间存在冲突的“不可能”任务来衡量LLM的作弊率。


<details>
  <summary>Details</summary>
Motivation: LLM代理倾向于寻找捷径，这对其可靠评估和部署构成了重大风险。为了量化、研究和缓解这种行为，我们引入了ImpossibleBench。

Method: ImpossibleBench通过创建现有基准（如LiveCodeBench和SWE-bench）的任务的“不可能”变体来系统地衡量LLM代理利用测试用例的倾向。它通过衡量代理在这些不可能任务上的通过率（“作弊率”）来量化这种行为，任何通过都意味着违反规范的捷径。

Result: ImpossibleBench可用于研究模型行为（揭示从简单的测试修改到复杂的运算符重载的细粒度作弊行为）、上下文工程（展示提示、测试访问和反馈循环如何影响作弊率）以及开发监控工具（提供经过验证的欺骗性解决方案的测试平台）。

Conclusion: ImpossibleBench是一个实用的基准框架，用于评估和研究LLM代理的捷径行为，有助于构建更健壮、更可靠的LLM系统。

Abstract: The tendency to find and exploit "shortcuts" to complete tasks poses
significant risks for reliable assessment and deployment of large language
models (LLMs). For example, an LLM agent with access to unit tests may delete
failing tests rather than fix the underlying bug. Such behavior undermines both
the validity of benchmark results and the reliability of real-world LLM coding
assistant deployments.
  To quantify, study, and mitigate such behavior, we introduce ImpossibleBench,
a benchmark framework that systematically measures LLM agents' propensity to
exploit test cases. ImpossibleBench creates "impossible" variants of tasks from
existing benchmarks like LiveCodeBench and SWE-bench by introducing direct
conflicts between the natural-language specification and the unit tests. We
measure an agent's "cheating rate" as its pass rate on these impossible tasks,
where any pass necessarily implies a specification-violating shortcut.
  As a practical framework, ImpossibleBench is not just an evaluation but a
versatile tool. We demonstrate its utility for: (1) studying model behaviors,
revealing more fine-grained details of cheating behaviors from simple test
modification to complex operator overloading; (2) context engineering, showing
how prompt, test access and feedback loop affect cheating rates; and (3)
developing monitoring tools, providing a testbed with verified deceptive
solutions. We hope ImpossibleBench serves as a useful framework for building
more robust and reliable LLM systems.
  Our implementation can be found at
https://github.com/safety-research/impossiblebench.

</details>


### [416] [Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch](https://arxiv.org/abs/2510.20271)
*Udit Saxena*

Main category: cs.LG

TL;DR: 该论文提出了一种用于拓扑特征提取的计算高效且可微分的EUC（欧拉示性数曲线）计算方法，并在深度学习中实现了端到端学习。


<details>
  <summary>Details</summary>
Motivation: 在深度学习中，拓扑特征在捕捉图像数据的全局几何结构方面具有重要作用，但实际应用面临计算效率和可微分性的挑战。因此，需要一种能够克服这些挑战的拓扑特征提取方法。

Method: 1. 优化GPU核函数（CUDA kernels），以实现EUC计算的计算效率，针对Ampere GPU进行了优化，利用了128B合并访问和分层共享内存累积技术。
2. 引入一个可微分的PyTorch层，支持端到端学习。该层通过类似可微分欧拉示性数变换（DECT）的sigmoid松弛方法，在单个方向上学习阈值。

Result: 优化后的GPU核函数在合成栅格上实现了16-2000倍的速度提升。
通过可微分PyTorch层，实现了端到端学习。

Conclusion: 提出的EUC计算优化方法和可微分层能够克服现有方法的局限性，提高计算效率和可微分性，从而促进拓扑特征在深度学习中的应用。论文还讨论了该方法的下游应用相关性，并提出了批处理和多GPU扩展方案以扩大应用范围。

Abstract: Topological features capture global geometric structure in imaging data, but
practical adoption in deep learning requires both computational efficiency and
differentiability. We present optimized GPU kernels for the Euler
Characteristic Curve (ECC) computation achieving 16-2000\"O speedups over prior
GPU implementations on synthetic grids, and introduce a differentiable PyTorch
layer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs
use 128B-coalesced access and hierarchical shared-memory accumulation. Our
PyTorch layer learns thresholds in a single direction via a Differentiable
Euler Characteristic Transform-style sigmoid relaxation. We discuss downstream
relevance, including applications highlighted by prior ECC work, and outline
batching/multi-GPU extensions to broaden adoption.

</details>


### [417] [Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs](https://arxiv.org/abs/2510.20272)
*Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi*

Main category: cs.LG

TL;DR: 链式思考提示（BoN）在数学推理中存在局限，研究提出PRM引导的树搜索，但实验表明其并无显著提升，反而暴露了PRM在可靠性和泛化性上的不足，指出需要改进奖励模型才能有效利用树搜索。


<details>
  <summary>Details</summary>
Motivation: 传统的链式思考提示（BoN）在处理数学推理时，其线性结构无法模拟复杂问题解决中固有的分支和探索特性。因此，有必要研究新的方法来改进LLM在数学推理方面的能力。

Method: 提出一种自适应算法来最大化过程奖励模型（PRM）得分，并通过PRM引导的树搜索来探索多个部分解决方案路径，以期提升数学推理能力。实验选取了23个不同的数学问题，并使用Qwen2.5-Math-7B-Instruct及其相关的PRM作为案例。

Result: (1) PRM引导的树搜索在成本更高的情况下，并未显示出比BoN有统计学意义上的显著改进；(2) 蒙特卡洛树搜索和束搜索在PRM引导的树搜索方法中表现优于其他方法；(3) PRM对状态价值的近似能力较差，并且其可靠性随着推理深度的增加而下降；(4) PRM在分布外数据上的泛化能力较差。

Conclusion: PRM引导的树搜索在当前形式下并未能有效提升LLM的数学推理能力，其性能瓶颈在于PRM本身对状态价值的低效近似和泛化能力的不足。在树搜索能够有效增强数学推理之前，需要对奖励模型进行不同的建模。

Abstract: While chain-of-thought prompting with Best-of-N (BoN) selection has become
popular for mathematical reasoning in large language models (LLMs), its linear
structure fails to capture the branching and exploratory nature of complex
problem-solving. In this work, we propose an adaptive algorithm to maximize
process reward model (PRM) scores over the intractable action space, and
investigate whether PRM-guided tree search can improve mathematical reasoning
by exploring multiple partial solution paths. Across $23$ diverse mathematical
problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case
study, we find that: (1) PRM-guided tree search shows no statistically
significant improvements over BoN despite higher costs, (2) Monte Carlo tree
search and beam search outperform other PRM-guided tree search methods, (3)
PRMs poorly approximate state values and their reliability degrades with
reasoning depth, and (4) PRMs generalize poorly out of distribution. This
underperformance stems from tree search's greater reliance on unreliable PRM
scores, suggesting different reward modeling is necessary before tree search
can effectively enhance mathematical reasoning in LLMs.

</details>


### [418] [SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series](https://arxiv.org/abs/2510.20273)
*Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 深度学习在时间序列预测方面取得进展，但实际应用中表现不稳定。现有评估框架缺乏对模型优缺点的量化分析，导致模型选择困难。我们提出了SynTSBench，一个基于合成数据驱动的评估范式，通过可编程的特征配置来系统地评估时间序列预测模型的基本建模能力。该框架解决了混淆因素，并建立了三个核心分析维度：(1) 时间特征分解和能力映射，评估模型学习特定模式类型的能力；(2) 数据异常下的鲁棒性分析，量化噪声容忍度和异常恢复能力；(3) 理论最优基准测试，为每种模式类型设定性能边界。实验表明，当前深度学习模型并非在所有时间特征类型上都接近最优基准。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习时间序列预测模型在实际应用中表现不稳定，现有评估框架无法提供对模型优缺点的量化分析，导致模型选择困难。

Method: 提出一个基于合成数据驱动的评估范式SynTSBench，通过可编程的特征配置来系统地评估时间序列预测模型的基本建模能力。评估维度包括：时间特征分解与能力映射、数据异常下的鲁棒性分析、理论最优基准测试。

Result: 实验表明，当前深度学习模型在所有时间特征类型上并非都接近最优基准。

Conclusion: SynTSBench 提供了一个更系统、可量化的评估框架，以应对深度学习时间序列预测模型在实际应用中的挑战。

Abstract: Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

</details>


### [419] [KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models](https://arxiv.org/abs/2510.20278)
*Guangyu Dai,Siliang Tang,Yueting Zhuang*

Main category: cs.LG

TL;DR: KCM通过使用KAN替代MLP来改进大-小模型协作框架，在语言、视觉和跨模态任务中显著降低了计算资源消耗，同时保持了接近的准确性，并减轻了灾难性遗忘问题，尤其提高了长尾数据的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有大-小模型协作框架中存在的准确率下降、灾难性遗忘加剧以及小模型知识引入的幻觉问题，提出了一种改进的大-小模型协作方法。

Method: 提出了一种基于KAN（Kolmogorov-Arnold Network）的大-小模型协作（KCM）方法，利用KAN替代传统的MLP，以提高大-小模型协作的性能。

Result: 实验结果表明，与纯大模型方法相比，使用KCM的大-小模型协作框架显著减少了大模型推理调用次数，同时保持了几乎相同的任务准确性，从而大幅降低了计算资源消耗。此外，基于KAN的小协作模型显著减轻了灾难性遗忘，并显著提高了长尾数据的准确性。KCM在所有指标上均优于基于MLP的小协作模型（MCM）。

Conclusion: KCM作为一种改进的大-小模型协作方法，能够有效解决现有框架中的问题，并在降低计算成本、减轻灾难性遗忘和提高长尾数据性能方面表现出色，优于基于MLP的方法。

Abstract: In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

</details>


### [420] [ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows](https://arxiv.org/abs/2510.20279)
*Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang*

Main category: cs.LG

TL;DR: 本论文提出了CS-54k数据集（包括CS-4k基准和CS-50k训练集），用于评估和训练LLM作为科学研究的AI协作者。实验表明，在CS-50k上进行训练可以显著提高LLM的表现，甚至使较小规模的模型优于更大的专有模型。


<details>
  <summary>Details</summary>
Motivation: 为了实现将LLM作为科学研究的AI协作者的终极愿景，需要端到端的评估基准，而不仅仅是孤立任务的评估。本文旨在构建这样的基准和训练数据集。

Method: 利用检索增强生成（RAG）和多阶段质量控制，从14k篇计算机科学论文中构建了一个包含科学问答对的高质量语料库CS-54k。然后，从中衍生出用于评估的CS-4k基准和用于训练的CS-50k数据集。对模型在CS-4k上进行了评估，并在CS-50k上进行了有监督和强化学习训练。

Result: CS-4k基准能够将现有LLM的能力分层。在CS-50k上进行训练的模型，即使是7B规模的模型，在CS-4k上的表现也优于GPT-4.1、GPT-4o和Gemini 2.5 Pro等大型专有模型。

Conclusion: 高质量、领域对齐的训练数据对于提升AI研究助手的性能比模型规模或通用基准性能更重要。作者希望通过发布CS-4k和CS-50k来促进AI系统成为可靠的科学研究协作者。

Abstract: As large language models (LLMs) advance, the ultimate vision for their role
in science is emerging: we could build an AI collaborator to effectively assist
human beings throughout the entire scientific research process. We refer to
this envisioned system as ResearchGPT. Given that scientific research
progresses through multiple interdependent phases, achieving this vision
requires rigorous benchmarks that evaluate the end-to-end workflow rather than
isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of
scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It
is constructed through a scalable, paper-grounded pipeline that combines
retrieval-augmented generation (RAG) with multi-stage quality control to ensure
factual grounding. From this unified corpus, we derive two complementary
subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to
assist scientific research, and CS-50k, a large-scale training dataset.
Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs
into distinct capability tiers. Open models trained on CS-50k with supervised
training and reinforcement learning demonstrate substantial improvements. Even
7B-scale models, when properly trained, outperform many larger proprietary
systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that
making AI models better research assistants relies more on domain-aligned
training with high-quality data than on pretraining scale or general benchmark
performance. We release CS-4k and CS-50k in the hope of fostering AI systems as
reliable collaborators in CS research.

</details>


### [421] [Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization](https://arxiv.org/abs/2510.20295)
*Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li*

Main category: cs.LG

TL;DR: 本论文提出了一种无需环境标注或生成即可识别因果子图的IRM-free方法，通过分析分布变化与表示范数的关系来发现因果子图，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在分布外泛化和处理分布变化方面存在挑战，现有基于不变风险最小化（IRM）的方法需要昂贵的环境标注或启发式生成的数据集划分。

Method: 提出了一种基于‘不变分布判据’的IRM-free方法，该判据指出因果子图在不同环境下的分布变化小于非因果部分。通过量化分析分布变化和表示范数之间的关系来识别因果子图，并引入了‘范数引导的不变分布目标’来实现因果子图发现和预测。

Result: 所提出的方法在两个广泛使用的基准测试中，在图泛化方面持续优于最先进的方法。

Conclusion: 本研究成功开发了一种无需依赖环境标注或生成即可实现因果子图发现和图泛化的新方法，克服了现有IRM方法的局限性。

Abstract: Out-of-distribution generalization under distributional shifts remains a
critical challenge for graph neural networks. Existing methods generally adopt
the Invariant Risk Minimization (IRM) framework, requiring costly environment
annotations or heuristically generated synthetic splits. To circumvent these
limitations, in this work, we aim to develop an IRM-free method for capturing
causal subgraphs. We first identify that causal subgraphs exhibit substantially
smaller distributional variations than non-causal components across diverse
environments, which we formalize as the Invariant Distribution Criterion and
theoretically prove in this paper. Building on this criterion, we
systematically uncover the quantitative relationship between distributional
shift and representation norm for identifying the causal subgraph, and
investigate its underlying mechanisms in depth. Finally, we propose an IRM-free
method by introducing a norm-guided invariant distribution objective for causal
subgraph discovery and prediction. Extensive experiments on two widely used
benchmarks demonstrate that our method consistently outperforms
state-of-the-art methods in graph generalization.

</details>


### [422] [DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability](https://arxiv.org/abs/2510.20299)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.LG

TL;DR: 提出了一种名为DB-FGA-Net的双骨干网络，结合VGG16和Xception以及频率门控注意力（FGA）块，用于脑肿瘤分类，无需数据增强即可达到最先进的性能，并通过Grad-CAM实现可视化解释，并开发了图形用户界面（GUI）以支持临床应用。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习脑肿瘤分类方法依赖于繁重的数据增强，这可能限制其在临床应用中的泛化能力和可信度。

Method: 提出了一种双骨干网络，集成了VGG16和Xception，并加入频率门控注意力（FGA）块，以捕捉互补的局部和全局特征，同时不使用数据增强。集成了Grad-CAM用于可视化肿瘤区域，并开发了一个图形用户界面（GUI）。

Result: 在7K-DS数据集的4类、3类和2类设置中，准确率分别为99.24%、98.68%和99.85%。在独立的3K-DS数据集上，准确率为95.77%，优于基线和现有最先进的方法。

Conclusion: 该模型（DB-FGA-Net）无需数据增强，具有可解释性和可部署性，在脑肿瘤诊断的临床转化方面具有巨大潜力，并已通过GUI得到进一步支持。

Abstract: Brain tumors are a challenging problem in neuro-oncology, where early and
precise diagnosis is important for successful treatment. Deep learning-based
brain tumor classification methods often rely on heavy data augmentation which
can limit generalization and trust in clinical applications. In this paper, we
propose a double-backbone network integrating VGG16 and Xception with a
Frequency-Gated Attention (FGA) Block to capture complementary local and global
features. Unlike previous studies, our model achieves state-of-the-art
performance without augmentation which demonstrates robustness to variably
sized and distributed datasets. For further transparency, Grad-CAM is
integrated to visualize the tumor regions based on which the model is giving
prediction, bridging the gap between model prediction and clinical
interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS
dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class
and 2-class settings, respectively. On the independent 3K-DS dataset, the model
generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art
methods. To further support clinical usability, we developed a graphical user
interface (GUI) that provides real-time classification and Grad-CAM-based tumor
localization. These findings suggest that augmentation-free, interpretable, and
deployable deep learning models such as DB-FGA-Net hold strong potential for
reliable clinical translation in brain tumor diagnosis.

</details>


### [423] [InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling](https://arxiv.org/abs/2510.20302)
*Yuhang Wang*

Main category: cs.LG

TL;DR: InvDec是一种混合架构，通过结合基于块的时间编码器和在变量维度上操作的倒置解码器，在时间编码和变量级解码之间实现了原则性的分离，从而实现了多元时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 现有的多元时间序列预测方法要么侧重于时间模式（如PatchTST），忽略变量相关性，要么侧重于变量注意力（如iTransformer），牺牲了时间编码。需要一种能够有效建模时间模式和跨变量依赖性的混合方法。

Method: InvDec采用基于块的时间编码器来捕获时间模式，并结合一个在变量维度上通过变量自注意力操作的倒置解码器来处理变量间依赖性。它还引入了延迟变量嵌入，仅在时间编码后丰富特定于变量的表示，并使用自适应残差融合机制来动态平衡时间信息和变量信息。

Result: InvDec-PatchTST在七个基准测试中取得了显著的成果，特别是在高维数据集上，如在Electricity（321个变量）上MSE降低了20.9%，在Weather上提高了4.3%，在Traffic上提高了2.7%。在低维ETT数据集上也保持了有竞争力的性能。消融研究验证了每个组件的有效性。

Conclusion: InvDec的混合架构在处理多元时间序列预测方面非常有效，其优势随着数据集维度的增加而增强，这表明跨变量建模在高维场景中至关重要。

Abstract: Multivariate time series forecasting requires simultaneously modeling
temporal patterns and cross-variate dependencies. Channel-independent methods
such as PatchTST excel at temporal modeling but ignore variable correlations,
while pure variate-attention approaches such as iTransformer sacrifice temporal
encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that
achieves principled separation between temporal encoding and variate-level
decoding. InvDec combines a patch-based temporal encoder with an inverted
decoder operating on the variate dimension through variate-wise self-attention.
We introduce delayed variate embeddings that enrich variable-specific
representations only after temporal encoding, preserving temporal feature
integrity. An adaptive residual fusion mechanism dynamically balances temporal
and variate information across datasets of varying dimensions. Instantiating
InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven
benchmarks demonstrate significant gains on high-dimensional datasets: 20.9%
MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and
2.7% gain on Traffic compared to PatchTST, while maintaining competitive
performance on low-dimensional ETT datasets. Ablation studies validate each
component, and analysis reveals that InvDec's advantage grows with dataset
dimensionality, confirming that cross-variate modeling becomes critical as the
number of variables increases.

</details>


### [424] [LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems](https://arxiv.org/abs/2510.20327)
*Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种名为LEGO的新型推荐属性遗忘框架，能够同时处理多个属性的遗忘需求，并能适应动态的遗忘需求，解决了现有单一属性遗忘方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统隐私保护需求日益增长，但单一属性遗忘方法无法满足现实世界中涉及多个敏感属性且动态变化的需求。

Method: LEGO框架将多属性遗忘过程分为两步：1. 嵌入校准（移除特定属性信息）和2. 灵活组合（合并嵌入以保护所有敏感属性）。通过将遗忘过程构建为互信息最小化问题，确保同时遗忘能力；两步框架支持并行处理和高效组合，实现灵活性和效率。

Result: 在三个真实世界数据集和三种代表性推荐模型上的广泛实验证明了LEGO框架的有效性和效率。

Conclusion: LEGO是一个轻量级且高效的多属性遗忘框架，能够有效解决现有方法的局限性，满足现实世界中推荐系统隐私保护的动态和多属性需求。

Abstract: With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

</details>


### [425] [Synthetic Data for Robust Runway Detection](https://arxiv.org/abs/2510.20349)
*Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin*

Main category: cs.LG

TL;DR: Synthetic data generation using flight simulators can improve runway detection models for autonomous landing systems, especially when combined with domain adaptation for adverse conditions.


<details>
  <summary>Details</summary>
Motivation: Data collection and labeling for training deep vision models, particularly for critical applications like autonomous navigation requiring diverse conditions, are costly and time-consuming. Synthetic data generation offers a cheaper alternative if the distribution shift can be managed.

Method: The paper proposes an image generation approach using a commercial flight simulator to supplement a few annotated real images for runway detection. They control image generation and the integration of real and synthetic data, and evaluate the robustness of standard object detection models using a customized domain adaptation strategy for nighttime conditions not present in real data.

Result: Standard object detection models achieve accurate predictions when trained with a combination of real and synthetic data. The customized domain adaptation strategy demonstrates the utility of the approach in handling adverse conditions like nighttime images.

Conclusion: The proposed image generation approach using flight simulators, complemented by domain adaptation, is effective for training robust runway detection models for autonomous landing systems, addressing the challenges of data collection and handling diverse environmental conditions.

Abstract: Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

</details>


### [426] [Ask a Strong LLM Judge when Your Reward Model is Uncertain](https://arxiv.org/abs/2510.20369)
*Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao*

Main category: cs.LG

TL;DR: 通过引入不确定性路由框架，结合了快速奖励模型（RM）和强大的大型语言模型（LLM）法官，以提高在线RLHF的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有奖励模型（RM）在处理大规模语言模型（LLM）的在线强化学习（RLHF）中存在的奖励黑客和泛化能力差的问题，同时降低昂贵LLM法官的推理成本。

Method: 提出了一种基于不确定性的路由框架，将策略梯度（PG）方法中的优势估计转化为成对偏好分类问题，从而实现不确定性量化来指导路由。不确定的样本被发送给LLM法官，而确定的样本则由RM评估。

Result: 实验表明，该不确定性路由策略在相同成本下显著优于随机法官调用，并且在下游对齐任务中证明了其在改进在线RLHF方面的有效性。

Conclusion: 所提出的不确定性路由框架能够有效地结合RM和LLM法官的优点，提高了RLHF的效率和模型对齐效果。

Abstract: Reward model (RM) plays a pivotal role in reinforcement learning with human
feedback (RLHF) for aligning large language models (LLMs). However, classical
RMs trained on human preferences are vulnerable to reward hacking and
generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM
judges equipped with reasoning capabilities demonstrate superior
generalization, even without additional training, but incur significantly
higher inference costs, limiting their applicability in online RLHF. In this
work, we propose an uncertainty-based routing framework that efficiently
complements a fast RM with a strong but costly LLM judge. Our approach
formulates advantage estimation in policy gradient (PG) methods as pairwise
preference classification, enabling principled uncertainty quantification to
guide routing. Uncertain pairs are forwarded to the LLM judge, while confident
ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our
uncertainty-based routing strategy significantly outperforms random judge
calling at the same cost, and downstream alignment results showcase its
effectiveness in improving online RLHF.

</details>


### [427] [Hierarchical Time Series Forecasting with Robust Reconciliation](https://arxiv.org/abs/2510.20383)
*Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.LG

TL;DR: 该论文提出了一种用于处理分层时间序列数据的鲁棒优化框架，通过考虑协方差矩阵估计中的不确定性来提高预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的分层预测方法在生成预测值后需要进行协调以确保一致性，但它们依赖于对真实协方差矩阵的估计，而这种估计可能存在误差，从而影响预测性能。

Method: 提出了一种鲁棒优化框架，该框架通过引入不确定性集来处理估计的协方差矩阵，并最小化该不确定性集上的最坏情况期望平方误差。该问题被表述为一个半定优化问题。

Result: 数值实验表明，所提出的鲁棒协调方法比现有的分层预测方法具有更好的预测性能。

Conclusion: 将不确定性纳入协调过程可以提高分层时间序列预测的性能。

Abstract: This paper focuses on forecasting hierarchical time-series data, where each
higher-level observation equals the sum of its corresponding lower-level time
series. In such contexts, the forecast values should be coherent, meaning that
the forecast value of each parent series exactly matches the sum of the
forecast values of its child series. Existing hierarchical forecasting methods
typically generate base forecasts independently for each series and then apply
a reconciliation procedure to adjust them so that the resulting forecast values
are coherent across the hierarchy. These methods generally derive an optimal
reconciliation, using a covariance matrix of the forecast error. In practice,
however, the true covariance matrix is unknown and has to be estimated from
finite samples in advance. This gap between the true and estimated covariance
matrix may degrade forecast performance. To address this issue, we propose a
robust optimization framework for hierarchical reconciliation that accounts for
uncertainty in the estimated covariance matrix. We first introduce an
uncertainty set for the estimated covariance matrix and formulate a
reconciliation problem that minimizes the worst-case expected squared error
over this uncertainty set. We show that our problem can be cast as a
semidefinite optimization problem. Numerical experiments demonstrate that the
proposed robust reconciliation method achieved better forecast performance than
existing hierarchical forecasting methods, which indicates the effectiveness of
integrating uncertainty into the reconciliation process.

</details>


### [428] [Relative-Based Scaling Law for Neural Language Models](https://arxiv.org/abs/2510.20387)
*Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu*

Main category: cs.LG

TL;DR: 该研究提出了相对排序度量（RBP）和相对基础缩放定律，以弥补交叉熵度量在评估语言模型性能方面的不足，并扩展了对模型缩放的理解。


<details>
  <summary>Details</summary>
Motivation: 现有的缩放定律研究主要依赖交叉熵作为评估指标，但交叉熵仅评估正确标记的绝对概率，忽略了正确和错误标记之间的相对顺序，而这对于像贪心采样这样的场景至关重要。

Method: 提出了一种名为相对基础概率（RBP）的新度量，量化了正确标记在前 K 个预测中的排名概率。在此基础上，建立了相对基础缩放定律，用于描述 RBP 如何随着模型大小的增加而提高。

Result: 通过在四个数据集和四个模型系列上进行的大量实验，验证了相对基础缩放定律的鲁棒性和准确性，其范围涵盖了五个数量级。

Conclusion: 相对基础缩放定律是对交叉熵观点的补充，有助于更全面地理解大型语言模型的缩放，为实际开发和理论探索提供了有价值的见解。

Abstract: Scaling laws aim to accurately predict model performance across different
scales. Existing scaling-law studies almost exclusively rely on cross-entropy
as the evaluation metric. However, cross-entropy provides only a partial view
of performance: it measures the absolute probability assigned to the correct
token, but ignores the relative ordering between correct and incorrect tokens.
Yet, relative ordering is crucial for language models, such as in
greedy-sampling scenario. To address this limitation, we investigate scaling
from the perspective of relative ordering. We first propose the Relative-Based
Probability (RBP) metric, which quantifies the probability that the correct
token is ranked among the top predictions. Building on this metric, we
establish the Relative-Based Scaling Law, which characterizes how RBP improves
with increasing model size. Through extensive experiments on four datasets and
four model families spanning five orders of magnitude, we demonstrate the
robustness and accuracy of this law. Finally, we illustrate the broad
application of this law with two examples, namely providing a deeper
explanation of emergence phenomena and facilitating finding fundamental
theories of scaling laws. In summary, the Relative-Based Scaling Law
complements the cross-entropy perspective and contributes to a more complete
understanding of scaling large language models. Thus, it offers valuable
insights for both practical development and theoretical exploration.

</details>


### [429] [Why DPO is a Misspecified Estimator and How to Fix It](https://arxiv.org/abs/2510.20413)
*Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee*

Main category: cs.LG

TL;DR: DPO 算法在基于偏好数据的微调中，虽然避免了 RLHF 的两阶段强化学习，但可能因奖励函数无法通过参数策略类实现而出现问题。本文提出了 AuxDPO，通过引入辅助变量解决 DPO 的模型设定错误问题，并在理论和实践中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 直接偏好优化（DPO）算法在微调模型时，仅使用监督学习而非包含人类反馈（RLHF）的两阶段强化学习。然而，当生成偏好的真实奖励函数无法通过参数策略类实现时，DPO 会出现模型设定错误，导致偏好顺序反转、策略奖励下降和对输入偏好数据分布高度敏感等问题。

Method: 研究了 DPO 算法的统计估计问题，并分析了两阶段 RLHF 对于参数化策略类的局部行为，将其与策略空间中的自然梯度下降相关联。在此基础上，提出了 AuxDPO，通过在 DPO 损失函数中引入额外的辅助变量，以一种原则性的方式帮助模型向 RLHF 的解决方案移动，并减轻 DPO 的模型设定错误。

Result: 通过在教学性老虎机设定和 LLM 对齐任务上的实证评估，证明了 AuxDPO 相较于 DPO 具有更优越的性能。

Conclusion: DPO 算法在某些情况下存在模型设定错误的问题。AuxDPO 通过引入辅助变量，能够有效解决 DPO 的模型设定错误，并在各种任务中表现出优越的性能。

Abstract: Direct alignment algorithms such as Direct Preference Optimization (DPO)
fine-tune models based on preference data, using only supervised learning
instead of two-stage reinforcement learning with human feedback (RLHF). We show
that DPO encodes a statistical estimation problem over reward functions induced
by a parametric policy class. When the true reward function that generates
preferences cannot be realized via the policy class, DPO becomes misspecified,
resulting in failure modes such as preference order reversal, worsening of
policy reward, and high sensitivity to the input preference data distribution.
On the other hand, we study the local behavior of two-stage RLHF for a
parametric class and relate it to a natural gradient step in policy space. Our
fine-grained geometric characterization allows us to propose AuxDPO, which
introduces additional auxiliary variables in the DPO loss function to help move
towards the RLHF solution in a principled manner and mitigate the
misspecification in DPO. We empirically demonstrate the superior performance of
AuxDPO on didactic bandit settings as well as LLM alignment tasks.

</details>


### [430] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 现有的时间点过程模型在处理标记事件流中的不平衡标记分布时存在不足，本文提出了一种新的阈值方法，通过调整标记的先验概率来优化标记预测，并结合新颖的神经网络模型进行事件时间和标记的预测，在真实数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间点过程模型在处理标记事件流时，忽略了事件标记分布不平衡的现实情况，这对于预测罕见标记的事件尤为不利。

Method: 提出了一种新的阈值方法，该方法学习调整标记的先验概率来调整标记概率，以优化标记预测，而不是直接预测标记。模型首先预测标记，然后预测时间。此外，还开发了一个新的神经网络MTPP模型，用于有效的、无需计算成本的数值积分的时间采样和标记概率估计。

Result: 在真实数据集上的广泛实验证明，与各种基线方法相比，该模型在预测下一个事件标记和时间方面表现出优越的性能。

Conclusion: 所提出的阈值方法和新颖的神经网络MTPP模型能够有效解决标记事件流中标记不平衡的问题，显著提高了下一个事件标记和时间的预测精度。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [431] [An Empirical Study of Sample Selection Strategies for Large Language Model Repair](https://arxiv.org/abs/2510.20428)
*Xuran Li,Jingyi Wang*

Main category: cs.LG

TL;DR: 选择性数据采样可以有效地修复大型语言模型的毒性输出，同时保持其性能。提出的SAPS方法在毒性降低、效用保持和效率方面取得了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）可能产生有毒或带有偏见的内容，修复这些模型的成本高昂，因此需要有效的数据选择策略来降低成本。

Method: 评估了五种数据选择策略：随机采样、K-中心、梯度范数（GraNd）、分层覆盖（CCS）以及新提出的语义感知优先采样（SAPS）。通过毒性降低、困惑度以及修复近度得分（RPS）、总体性能得分（OPS）和修复效率得分（RES）来评估修复效果和权衡。

Result: SAPS在毒性降低、效用保持和效率方面取得了最佳平衡，用更少的数据实现了相当或更好的修复效果。对于大型或鲁棒模型，随机采样仍然有效。CCS和GraNd等高开销方法带来的收益有限。数据比例的选择取决于模型规模和修复方法。

Conclusion: 基于选择的修复是一种有效且可扩展的范式，可以维护大型语言模型的可靠性，其中数据采样是修复流程中可调整的组成部分。

Abstract: Large language models (LLMs) are increasingly deployed in real-world systems,
yet they can produce toxic or biased outputs that undermine safety and trust.
Post-hoc model repair provides a practical remedy, but the high cost of
parameter updates motivates selective use of repair data. Despite extensive
prior work on data selection for model training, it remains unclear which
sampling criteria are most effective and efficient when applied specifically to
behavioral repair of large generative models. Our study presents a systematic
analysis of sample prioritization strategies for LLM repair. We evaluate five
representative selection methods, including random sampling, K-Center,
gradient-norm-based selection(GraNd), stratified coverage (CCS), and a
Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair
effectiveness and trade-offs are assessed through toxicity reduction,
perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair
Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair
Efficiency Score (RES). Experimental results show that SAPS achieves the best
balance between detoxification, utility preservation, and efficiency,
delivering comparable or superior repair outcomes with substantially less data.
Random sampling remains effective for large or robust models, while
high-overhead methods such as CCS and GraNd provide limited benefit. The
optimal data proportion depends on model scale and repair method, indicating
that sample selection should be regarded as a tunable component of repair
pipelines. Overall, these findings establish selection-based repair as an
efficient and scalable paradigm for maintaining LLM reliability.

</details>


### [432] [Explainable Benchmarking through the Lense of Concept Learning](https://arxiv.org/abs/2510.20439)
*Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 本篇论文提出了一种名为“可解释基准测试”的新方法，旨在自动生成对基准测试中系统性能的解释，以解决传统基准测试中手动分析耗时且存在偏差的问题。论文首次将此方法应用于知识图谱问答系统，并开发了一种名为PruneCEL的新概念学习方法来计算解释。实验结果表明，PruneCEL在可解释基准测试任务上的表现优于现有方法，并且用户研究显示该方法生成的解释能帮助用户准确预测系统行为。


<details>
  <summary>Details</summary>
Motivation: 传统的系统性能评估方法（基准测试）通常只关注少数几个指标，导致对评估细节的深入分析和指导未来开发或使用的洞察提取成为一项耗时且可能存在偏差的手动任务。因此，需要一种新的基准测试方法，能够自动生成对系统性能的解释。

Method: 论文提出并实现了一种名为“可解释基准测试”的范式。具体来说，针对知识图谱问答系统，论文开发了一种新颖的概念学习方法PruneCEL，用于自动计算解释。PruneCEL特别为处理大型知识图谱而设计。

Result: 通过评估，PruneCEL在可解释基准测试任务上，F1指标比现有最先进的概念学习方法高出0.55分。此外，一项包含41名参与者的面向任务的用户研究表明，在80%的情况下，大多数参与者能够根据论文提出的解释准确预测系统的行为。

Conclusion: 可解释基准测试是一种有前景的方法，可以自动化系统性能分析，提供比传统度量更深入的见解。论文提出的PruneCEL方法在知识图谱问答领域实现了这一目标，并得到了用户研究的有效验证。

Abstract: Evaluating competing systems in a comparable way, i.e., benchmarking them, is
an undeniable pillar of the scientific method. However, system performance is
often summarized via a small number of metrics. The analysis of the evaluation
details and the derivation of insights for further development or use remains a
tedious manual task with often biased results. Thus, this paper argues for a
new type of benchmarking, which is dubbed explainable benchmarking. The aim of
explainable benchmarking approaches is to automatically generate explanations
for the performance of systems in a benchmark. We provide a first instantiation
of this paradigm for knowledge-graph-based question answering systems. We
compute explanations by using a novel concept learning approach developed for
large knowledge graphs called PruneCEL. Our evaluation shows that PruneCEL
outperforms state-of-the-art concept learners on the task of explainable
benchmarking by up to 0.55 points F1 measure. A task-driven user study with 41
participants shows that in 80\% of the cases, the majority of participants can
accurately predict the behavior of a system based on our explanations. Our code
and data are available at https://github.com/dice-group/PruneCEL/tree/K-cap2025

</details>


### [433] [MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction](https://arxiv.org/abs/2510.20448)
*Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan*

Main category: cs.LG

TL;DR: MolBridge通过原子级图细化框架改进药物-药物相互作用（DDI）预测，解决了现有方法在处理复杂分子结构和长尾DDI类型方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有DDI预测方法依赖于孤立的药物表示，未能显式模拟原子级别的交叉分子相互作用，限制了其在不同分子复杂性和DDI类型分布下的有效性。

Method: MolBridge构建了一个整合药物对原子结构的联合图，并通过一个结构一致性模块迭代优化节点特征以防止信息丢失，从而有效地学习局部和全局相互作用模式。

Result: MolBridge在两个基准数据集上持续优于最先进的方法，在长尾和归纳场景中均表现出色。

Conclusion: 细粒度的图细化在提高DDI事件预测的准确性、鲁棒性和机制可解释性方面具有优势。

Abstract: Drug combinations offer therapeutic benefits but also carry the risk of
adverse drug-drug interactions (DDIs), especially under complex molecular
structures. Accurate DDI event prediction requires capturing fine-grained
inter-drug relationships, which are critical for modeling metabolic mechanisms
such as enzyme-mediated competition. However, existing approaches typically
rely on isolated drug representations and fail to explicitly model atom-level
cross-molecular interactions, limiting their effectiveness across diverse
molecular complexities and DDI type distributions. To address these
limitations, we propose MolBridge, a novel atom-level joint graph refinement
framework for robust DDI event prediction. MolBridge constructs a joint graph
that integrates atomic structures of drug pairs, enabling direct modeling of
inter-drug associations. A central challenge in such joint graph settings is
the potential loss of information caused by over-smoothing when modeling
long-range atomic dependencies. To overcome this, we introduce a structure
consistency module that iteratively refines node features while preserving the
global structural context. This joint design allows MolBridge to effectively
learn both local and global interaction outperforms state-of-the-art baselines,
achieving superior performance across long-tail and inductive scenarios.
patterns, yielding robust representations across both frequent and rare DDI
types. Extensive experiments on two benchmark datasets show that MolBridge
consistently. These results demonstrate the advantages of fine-grained graph
refinement in improving the accuracy, robustness, and mechanistic
interpretability of DDI event prediction.This work contributes to Web Mining
and Content Analysis by developing graph-based methods for mining and analyzing
drug-drug interaction networks.

</details>


### [434] [Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach](https://arxiv.org/abs/2510.20454)
*Lawrence Clegg,John Cartlidge*

Main category: cs.LG

TL;DR: 在网球比赛中，A胜B、B胜C、C胜A的非传递性玩家支配很常见。本文提出了一种图神经网络方法，通过时间有向图对这些非传递性关系进行建模，并发现博彩公司Pinnacle Sports在处理这些比赛时存在不足，通过对高非传递性对局进行投注，可以获得显著的正回报。


<details>
  <summary>Details</summary>
Motivation: 现有预测方法很少考虑非传递性玩家支配关系，而这种关系在竞技网球中很常见。

Method: 使用图神经网络，通过时间有向图对玩家及其历史比赛结果进行建模，以明确地表示非传递性关系。

Result: 该模型在处理高非传递性复杂性的比赛时，准确率为65.7%，Brier得分为0.215，在1903次投注中实现了3.26%的投资回报率。

Conclusion: 博彩公司在处理非传递性对局时存在市场低效性，该图方法能够有效利用这些低效性。

Abstract: Intransitive player dominance, where player A beats B, B beats C, but C beats
A, is common in competitive tennis. Yet, there are few known attempts to
incorporate it within forecasting methods. We address this problem with a graph
neural network approach that explicitly models these intransitive relationships
through temporal directed graphs, with players as nodes and their historical
match outcomes as directed edges. We find the bookmaker Pinnacle Sports poorly
handles matches with high intransitive complexity and posit that our
graph-based approach is uniquely positioned to capture relational dynamics in
these scenarios. When selectively betting on higher intransitivity matchups
with our model (65.7% accuracy, 0.215 Brier Score), we achieve significant
positive returns of 3.26% ROI with Kelly staking over 1903 bets, suggesting a
market inefficiency in handling intransitive matchups that our approach
successfully exploits.

</details>


### [435] [Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models](https://arxiv.org/abs/2510.20468)
*Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko*

Main category: cs.LG

TL;DR: 数字内容水印技术在生成式模型和法律压力驱动下受到广泛关注，但水印伪造攻击（将水印从真实内容转移到恶意内容）却鲜有研究。本文研究了后验图像水印的伪造问题，提出了一种仅需单个水印图像、无需了解水印模型即可进行伪造的优化攻击方法，并评估了其在多种后验水印模型上的有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式内容激增和法律压力增加了对数字内容水印的需求，以确保内容真实性和归属。现有研究多关注水印的抗删除性，而对水印伪造（将水印从真实内容转移到恶意内容）的研究不足。

Method: 提出了一种偏好模型来判断图像是否被加水印，该模型使用程序生成图像的排序损失进行训练。通过反向传播优化输入图像，实现水印的移除和伪造，该方法仅需单个水印图像且无需了解水印模型。

Result: 提出的攻击方法在多种后验图像水印模型上进行了评估，证明了其有效性，表明当前的水印技术在安全性方面存在隐患。作者公开了代码和相关资源。

Conclusion: 本研究提出的水印伪造方法简单且实用，对当前后验图像水印技术的安全性提出了质疑，并为后续研究提供了新的方向。

Abstract: Recent years have seen a surge in interest in digital content watermarking
techniques, driven by the proliferation of generative models and increased
legal pressure. With an ever-growing percentage of AI-generated content
available online, watermarking plays an increasingly important role in ensuring
content authenticity and attribution at scale. There have been many works
assessing the robustness of watermarking to removal attacks, yet, watermark
forging, the scenario when a watermark is stolen from genuine content and
applied to malicious content, remains underexplored. In this work, we
investigate watermark forging in the context of widely used post-hoc image
watermarking. Our contributions are as follows. First, we introduce a
preference model to assess whether an image is watermarked. The model is
trained using a ranking loss on purely procedurally generated images without
any need for real watermarks. Second, we demonstrate the model's capability to
remove and forge watermarks by optimizing the input image through
backpropagation. This technique requires only a single watermarked image and
works without knowledge of the watermarking model, making our attack much
simpler and more practical than attacks introduced in related work. Third, we
evaluate our proposed method on a variety of post-hoc image watermarking
models, demonstrating that our approach can effectively forge watermarks,
questioning the security of current watermarking approaches. Our code and
further resources are publicly available.

</details>


### [436] [Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models](https://arxiv.org/abs/2510.20477)
*Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: Bi-CoG是一种结合了模型间和模型内一致性以及错误感知动态伪标签分配策略的半监督自训练方法，用于在标签稀缺的情况下提高预训练视觉-语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习（SSL）和预训练模型微调方法在标签稀缺的情况下存在模型偏差和超参数敏感性问题。Bi-CoG旨在解决这些局限性。

Method: Bi-CoG是一种即插即用的方法，通过同时利用模型间和模型内一致性，并结合错误感知动态伪标签分配策略，来生成高质量、低偏差的伪标签。

Result: Bi-CoG在14个数据集上的实验表明，该方法能够有效且显著地提升现有方法的性能。

Conclusion: Bi-CoG通过其新颖的伪标签生成机制，成功解决了现有半监督微调方法的不足，并能有效提升模型在各种下游任务上的表现。

Abstract: Exploiting unlabeled data through semi-supervised learning (SSL) or
leveraging pre-trained models via fine-tuning are two prevailing paradigms for
addressing label-scarce scenarios. Recently, growing attention has been given
to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,
forming the emerging paradigm of semi-supervised fine-tuning. However, existing
methods often suffer from model bias and hyperparameter sensitivity, due to
reliance on prediction consistency or pre-defined confidence thresholds. To
address these limitations, we propose a simple yet effective plug-and-play
methodology named
$\underline{\textbf{Bi-Co}}$nsistency-$\underline{\textbf{G}}$uided
Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,
by simultaneously exploiting inter-model and intra-model consistency, along
with an error-aware dynamic pseudo-label assignment strategy. Both theoretical
analysis and extensive experiments over 14 datasets demonstrate the
effectiveness of Bi-CoG, which consistently and significantly improves the
performance of existing methods.

</details>


### [437] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 该研究提出了一个名为Hurdle-Inversion Model Debiasing Learning (IMDL)的框架，用于解决定量遥感中标签分布不平衡的问题，特别是在降雨检索方面，提高了对罕见但影响重大的事件（如强降雨）的检索性能。


<details>
  <summary>Details</summary>
Motivation: 定量遥感模型在处理不平衡标签分布时，特别是对于罕见的强降雨样本，其检索性能会下降。传统方法倾向于常见样本，导致对稀有样本的性能较差。

Method: 提出了一种名为Hurdle-IMDL的框架。该框架采用分而治之的策略，将降雨分布不平衡分解为零值膨胀（非降雨样本占主导）和长尾（轻雨样本相对于重雨样本过多）两个部分。使用障碍模型处理零值膨胀，并提出IMDL来解决长尾问题，将学习目标转化为无偏的理想逆模型。

Result: 通过统计指标和中国东部降雨天气案例研究的综合评估，证明了Hurdle-IMDL在系统性低估的缓解以及重度至极端降雨检索的显著改进方面优于传统、成本敏感、生成和多任务学习方法。

Conclusion: IMDL提供了一种可推广的方法来解决环境变量分布不平衡的问题，从而能够更好地检索罕见但影响重大的事件。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [438] [SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment](https://arxiv.org/abs/2510.20540)
*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: SheafAlign使用基于公理的理论框架和去中心化的对比学习方法，解决了多模态对齐的局限性，在不要求所有模态相互冗余的情况下，保留了共享和独特的信息。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对齐方法在现实世界的分布式场景中失效，因为它们假设所有模态之间都存在相互冗余，而这并不总是成立。

Method: 提出了一种名为SheafAlign的基于公理的理论框架，用于去中心化的多模态对齐。该方法用多个比较空间取代了单一空间的对齐，通过公理结构对成对的模态关系进行建模，并利用去中心化的对比学习目标进行训练。

Result: 在多模态传感数据集上的实验表明，SheafAlign在零样本泛化、跨模态对齐和对缺失模态的鲁棒性方面表现优越，并且通信成本比最先进的基线低50%。

Conclusion: SheafAlign克服了现有方法的局限性，因为它不需要所有模态的相互冗余，并且能够保留共享和独特的信息。

Abstract: Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

</details>


### [439] [A Unified Framework for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.20542)
*Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 零样本强化学习（RL）旨在实现无需额外训练或测试时规划即可解决下游任务的通用智能体。本研究提出了首个统一的零样本RL框架，对现有方法进行分类（直接表示 vs. 组合表示），并分析了其共性与差异，为该领域的研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有零样本强化学习（RL）领域缺乏统一的分析框架，难以比较和组织现有方法，阻碍了通用智能体的研发。

Method: 提出一个统一的零样本RL框架，引入一致的符号和分类法，将现有算法分为‘直接表示’和‘组合表示’两大类，并推导了适用于零样本环境的后继特征方法的新边界。

Result: 该框架能够组织现有方法，实现直接比较；明确了不同方法的共性和关键差异；为后继特征方法在零样本场景下提供了新的性能视角。

Conclusion: 本研究提出的统一框架为零样本RL的研究提供了原则性基础，并为开发更通用的智能体指明了方向。

Abstract: Zero-shot reinforcement learning (RL) has emerged as a setting for developing
general agents in an unsupervised manner, capable of solving downstream tasks
without additional training or planning at test-time. Unlike conventional RL,
which optimizes policies for a fixed reward, zero-shot RL requires agents to
encode representations rich enough to support immediate adaptation to any
objective, drawing parallels to vision and language foundation models. Despite
growing interest, the field lacks a common analytical lens.
  We present the first unified framework for zero-shot RL. Our formulation
introduces a consistent notation and taxonomy that organizes existing
approaches and allows direct comparison between them. Central to our framework
is the classification of algorithms into two families: direct representations,
which learn end-to-end mappings from rewards to policies, and compositional
representations, which decompose the representation leveraging the substructure
of the value function. Within this framework, we highlight shared principles
and key differences across methods, and we derive an extended bound for
successor-feature methods, offering a new perspective on their performance in
the zero-shot regime. By consolidating existing work under a common lens, our
framework provides a principled foundation for future research in zero-shot RL
and outlines a clear path toward developing more general agents.

</details>


### [440] [Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics](https://arxiv.org/abs/2510.20556)
*Alexandre Benoit,Catherine Aitken,Yu He*

Main category: cs.LG

TL;DR: 图重构通过修改图拓扑来缓解GNN中的过压，但可能扭曲重要的拓扑依赖信号。本研究首次系统分析了重构如何影响图结构指标，以及这些变化如何与下游任务性能相关，发现成功的重构方法倾向于保留局部结构并允许全局连通性的灵活性。


<details>
  <summary>Details</summary>
Motivation: 在图神经网络（GNNs）和图Transformer中，图重构被用作一种关键技术来缓解过压问题，通过修改图的拓扑结构来改善信息流。然而，重构会改变图的原始结构，可能扭曲依赖于拓扑的重要信号。尽管重构技术日益普及，但对于需要保留哪些结构属性以确保性能提升和结构保真度方面，人们知之甚少。

Method: 研究了七种不同的图重构策略，分析了重构如何影响一系列图结构指标，并将这些变化与节点分类准确率相关联。

Result: 研究结果揭示了一种普遍的模式：成功的图重构方法倾向于保留局部图结构，同时允许全局连接性具有一定的灵活性。不同的重构策略在保留局部结构和影响全局连通性方面表现出不同的能力，这些能力与模型在下游任务中的表现相关。

Conclusion: 本研究首次系统地分析了图重构对图结构指标的影响及其与下游任务性能的关系，发现成功的重构方法通常会保留局部结构而允许全局连通性的灵活性。这些发现为设计有效的图重构策略提供了新的见解，弥合了图论与实际GNN优化之间的差距。

Abstract: Graph rewiring has emerged as a key technique to alleviate over-squashing in
Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph
topology to improve information flow. While effective, rewiring inherently
alters the graph's structure, raising the risk of distorting important
topology-dependent signals. Yet, despite the growing use of rewiring, little is
known about which structural properties must be preserved to ensure both
performance gains and structural fidelity. In this work, we provide the first
systematic analysis of how rewiring affects a range of graph structural
metrics, and how these changes relate to downstream task performance. We study
seven diverse rewiring strategies and correlate changes in local and global
graph properties with node classification accuracy. Our results reveal a
consistent pattern: successful rewiring methods tend to preserve local
structure while allowing for flexibility in global connectivity. These findings
offer new insights into the design of effective rewiring strategies, bridging
the gap between graph theory and practical GNN optimization.

</details>


### [441] [Embedding the MLOps Lifecycle into OT Reference Models](https://arxiv.org/abs/2510.20590)
*Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber*

Main category: cs.LG

TL;DR: MLOps 实践难以直接应用于 OT 环境，但可以通过 RAMI 4.0 等现有参考模型进行结构化改编以实现成功集成。


<details>
  <summary>Details</summary>
Motivation: 工业环境中 MLOps 的集成与 OT 系统的集成面临严峻挑战。

Method: 分析了将 MLOps 嵌入 OT 参考模型的障碍，并提出了一个系统性方法。评估了 RAMI 4.0 和 ISA-95 标准在 MLOps 集成方面的适用性，并通过现实世界用例详细映射了 MLOps 生命周期组件到 RAMI 4.0。

Result: 虽然不能直接移植 MLOps 实践，但使用现有参考模型进行结构化改编可以为成功集成提供途径。

Conclusion: 标准 MLOps 实践不能直接应用于 OT 环境，但可以通过利用 RAMI 4.0 等现有参考模型进行结构化适应，为成功集成提供一条可行路径。

Abstract: Machine Learning Operations (MLOps) practices are increas- ingly adopted in
industrial settings, yet their integration with Opera- tional Technology (OT)
systems presents significant challenges. This pa- per analyzes the fundamental
obstacles in combining MLOps with OT en- vironments and proposes a systematic
approach to embed MLOps prac- tices into established OT reference models. We
evaluate the suitability of the Reference Architectural Model for Industry 4.0
(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for
MLOps integration and present a detailed mapping of MLOps lifecycle compo-
nents to RAMI 4.0 exemplified by a real-world use case. Our findings
demonstrate that while standard MLOps practices cannot be directly transplanted
to OT environments, structured adaptation using existing reference models can
provide a pathway for successful integration.

</details>


### [442] [Generalizable Reasoning through Compositional Energy Minimization](https://arxiv.org/abs/2510.20607)
*Alexandru Oarga,Yilun Du*

Main category: cs.LG

TL;DR: 提出一种通过学习能量景观来解决机器推理泛化问题的新方法，并在各种推理任务上取得了优于现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端训练的推理模型泛化能力有限，无法解决比训练数据更复杂的问题。

Method: 学习可解子问题的能量景观，并在测试时组合这些子问题的能量函数来构建全局能量景观，同时引入并行能量最小化（PEM）来提高样本质量。

Result: 该方法在广泛的推理问题上优于现有最先进方法，证明了其泛化到更大更复杂问题的能力。

Conclusion: 所提出的组合方法能够提高推理模型的泛化能力，并能适应具有挑战性的推理任务。

Abstract: Generalization is a key challenge in machine learning, specifically in
reasoning tasks, where models are expected to solve problems more complex than
those encountered during training. Existing approaches typically train
reasoning models in an end-to-end fashion, directly mapping input instances to
solutions. While this allows models to learn useful heuristics from data, it
often results in limited generalization beyond the training distribution. In
this work, we propose a novel approach to reasoning generalization by learning
energy landscapes over the solution spaces of smaller, more tractable
subproblems. At test time, we construct a global energy landscape for a given
problem by combining the energy functions of multiple subproblems. This
compositional approach enables the incorporation of additional constraints
during inference, allowing the construction of energy landscapes for problems
of increasing difficulty. To improve the sample quality from this newly
constructed energy landscape, we introduce Parallel Energy Minimization (PEM).
We evaluate our approach on a wide set of reasoning problems. Our method
outperforms existing state-of-the-art methods, demonstrating its ability to
generalize to larger and more complex problems. Project website can be found
at: https://alexoarga.github.io/compositional_reasoning/

</details>


### [443] [Convergence Analysis of SGD under Expected Smoothness](https://arxiv.org/abs/2510.20608)
*Yuta Kawamoto,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文在期望平滑性（ES）条件下，对随机梯度下降（SGD）进行了收敛性分析，并给出了具体的理论界限。


<details>
  <summary>Details</summary>
Motivation: 传统的随机梯度下降（SGD）分析依赖于过强的或过于粗略的假设。期望平滑性（ES）条件作为一种更灵活的替代方案，将随机梯度的二阶矩与目标值和全梯度联系起来，但对其收敛性分析仍有待完善。

Method: 本文提出了在ES条件下SGD的自包含收敛性分析。具体包括：1. 提炼ES条件，明确其解释和依赖于采样的常数；2. 推导了全梯度范数平方期望的界限；3. 证明了在各种步长策略下，具有显式残差误差的 O(1/K) 收敛速率。

Result: 在ES条件下，证明了SGD具有O(1/K)的收敛速率，并给出了明确的残差误差。

Conclusion: 本文的分析统一并扩展了近年来关于ES条件下的SGD收敛性研究，为理解和应用SGD提供了更精确的理论基础。

Abstract: Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

</details>


### [444] [BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792)
*Liang Ye,Shengqin Chen,Jiazhu Dai*

Main category: cs.LG

TL;DR: 该研究提出了一种名为BadGraph的后门攻击方法，专门针对文本引导的图生成潜在扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有的图生成技术在安全方面存在漏洞，特别是后门攻击，而文本引导的图生成模型尚未得到充分研究。

Method: BadGraph利用文本触发器来污染训练数据，从而在推理时，当出现触发器时，诱导生成攻击者指定的子图，同时保持模型在干净输入上的正常性能。

Result: 在四个基准数据集上的实验表明，BadGraph的攻击效果显著且隐蔽，较低的污染率（低于10%）即可达到50%的攻击成功率，而80%的攻击成功率仅需24%的污染率，同时对良性样本的性能影响极小。消融研究表明后门是在VAE和扩散训练阶段植入的，而不是预训练阶段。

Conclusion: 该研究揭示了文本引导图生成潜在扩散模型的安全漏洞，强调了在药物发现等应用中的严重风险，并指出了开发针对此类扩散模型的鲁棒后门防御机制的必要性。

Abstract: The rapid progress of graph generation has raised new security concerns,
particularly regarding backdoor vulnerabilities. While prior work has explored
backdoor attacks in image diffusion and unconditional graph generation,
conditional, especially text-guided graph generation remains largely
unexamined. This paper proposes BadGraph, a backdoor attack method targeting
latent diffusion models for text-guided graph generation. BadGraph leverages
textual triggers to poison training data, covertly implanting backdoors that
induce attacker-specified subgraphs during inference when triggers appear,
while preserving normal performance on clean inputs. Extensive experiments on
four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the
effectiveness and stealth of the attack: less than 10% poisoning rate can
achieves 50% attack success rate, while 24% suffices for over 80% success rate,
with negligible performance degradation on benign samples. Ablation studies
further reveal that the backdoor is implanted during VAE and diffusion training
rather than pretraining. These findings reveal the security vulnerabilities in
latent diffusion models of text-guided graph generation, highlight the serious
risks in models' applications such as drug discovery and underscore the need
for robust defenses against the backdoor attack in such diffusion models.

</details>


### [445] [Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets](https://arxiv.org/abs/2510.20609)
*Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov*

Main category: cs.LG

TL;DR: 在实际计算预算下，针对代码生成任务，比较了不同检索配置（分块策略、相似度评分、拆分粒度）的效果，并提出了基于任务需求、模型约束和计算效率的代码检索系统实现建议。


<details>
  <summary>Details</summary>
Motivation: 在实际计算预算下，针对代码生成任务，研究如何设计有效的检索策略。

Method: 使用长代码竞技场中的代码补全和错误定位两个任务，系统地比较了不同分块策略、相似度评分和拆分粒度的检索配置。

Result: 1. 对于PL-PL任务，BM25稀疏检索配合词级别拆分效果最佳且实用。2. 对于NL-PL任务，虽然专有密集编码器效果更好，但延迟更高。3. 最佳块大小随上下文窗口增大而增大，从32-64行到整个文件。4. 行级别拆分效果与语法感知拆分相当。5. 检索延迟差异高达200倍，BM25+词拆分具有最佳的质量-延迟权衡。

Conclusion: 提供了基于任务需求、模型约束和计算效率的代码检索系统实现建议。

Abstract: We study retrieval design for code-focused generation tasks under realistic
compute budgets. Using two complementary tasks from Long Code Arena -- code
completion and bug localization -- we systematically compare retrieval
configurations across various context window sizes along three axes: (i)
chunking strategy, (ii) similarity scoring, and (iii) splitting granularity.
(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and
practical, significantly outperforming dense alternatives while being an order
of magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3
family) consistently beat sparse retrievers, however requiring 100x larger
latency. (3) Optimal chunk size scales with available context: 32-64 line
chunks work best at small budgets, and whole-file retrieval becomes competitive
at 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting
across budgets. (5) Retrieval latency varies by up to 200x across
configurations; BPE-based splitting is needlessly slow, and BM25 + word
splitting offers the best quality-latency trade-off. Thus, we provide
evidence-based recommendations for implementing effective code-oriented RAG
systems based on task requirements, model constraints, and computational
efficiency.

</details>


### [446] [Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples](https://arxiv.org/abs/2510.20800)
*Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus*

Main category: cs.LG

TL;DR: LASER通过修剪LLM权重矩阵的高阶分量来提高下游准确性，但其搜索过程耗时。本研究通过仅检查一小部分关键矩阵、利用奇异值梯度定位需约简矩阵、允许矩阵行在多个子空间中聚类以进行分解，以及使用100个样本进行评估，来显著减少搜索时间并提高准确性。最终，研究提出了一种无需微调即可快速、稳健地适应下游任务的算法。


<details>
  <summary>Details</summary>
Motivation: LASER算法虽然有效，但其搜索过程耗时，不适合快速部署。本研究旨在改进LASER算法，以减少搜索时间和提高效率。

Method: 本研究提出了一种改进的LASER算法，该算法通过以下方法进行优化：1. 仅检查一小部分关键矩阵，而非逐层扫描。2. 利用奇异值梯度来识别需要约简的矩阵。3. 允许矩阵行在多个子空间中聚类，并分别分解每个簇，以减少过拟合并提高准确性。4. 使用100个样本进行梯度计算和最终准确性测量，以缩短搜索时间。

Result: 研究结果表明，本研究提出的方法能够显著减少LASER算法的搜索时间，并能将LLM的准确性提高高达24.6个百分点。该方法通过优化搜索策略和使用更小的样本集进行评估，实现了快速、稳健的下游任务适应。

Conclusion: 本研究提出了一种快速、稳健的LLM适应算法，该算法结合了LASER的优点并进行了显著改进。通过单步梯度下降、100个样本的评估以及对关键层和分解技术的快速扫描，可以在无需微调的情况下，将LLM适应到新的数据集。

Abstract: Recently, Sharma et al. suggested a method called Layer-SElective-Rank
reduction (LASER) which demonstrated that pruning high-order components of
carefully chosen LLM's weight matrices can boost downstream accuracy -- without
any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each
requiring full-dataset forward passes) makes it impractical for rapid
deployment. We demonstrate that this overhead can be removed and find that: (i)
Only a small, carefully chosen subset of matrices needs to be inspected --
eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's
singular values pinpoints which matrices merit reduction, (iii) Increasing the
factorization search space by allowing matrices rows to cluster around multiple
subspaces and then decomposing each cluster separately further reduces
overfitting on the original training data and further lifts accuracy by up to
24.6 percentage points, and finally, (iv) we discover that evaluating on just
100 samples rather than the full training data -- both for computing the
indicative gradients and for measuring the final accuracy -- suffices to
further reduce the search time; we explain that as adaptation to downstream
tasks is dominated by prompting style, not dataset size. As a result, we show
that combining these findings yields a fast and robust adaptation algorithm for
downstream tasks. Overall, with a single gradient step on 100 examples and a
quick scan of the top candidate layers and factorization techniques, we can
adapt LLMs to new datasets -- entirely without fine-tuning.

</details>


### [447] [PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection](https://arxiv.org/abs/2510.20611)
*Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: 该研究提出了一种结合粒子群优化（PSO）的集成框架，用于乳腺癌诊断中的特征选择，以提高模型的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统乳腺癌诊断方法在可变性、成本和误诊风险方面的局限性，机器学习（ML）被视为一种有前途的计算机辅助诊断工具，其中特征选择对模型性能和可解释性至关重要。

Method: 研究提出了一种集成框架，采用定制的粒子群优化（PSO）进行特征选择，并在29种不同的模型上进行了评估，结合了交叉验证和可解释人工智能（XAI）方法。

Result: 所提出的方法在所有性能指标（包括准确率和精确率）上均达到了99.1%的优异分数，同时有效降低了维度，并提供了透明、模型无关的解释。

Conclusion: 研究结果表明，结合群体智能和可解释机器学习在实现稳健、可信且具有临床意义的乳腺癌诊断方面具有巨大潜力。

Abstract: Breast cancer is considered the most critical and frequently diagnosed cancer
in women worldwide, leading to an increase in cancer-related mortality. Early
and accurate detection is crucial as it can help mitigate possible threats
while improving survival rates. In terms of prediction, conventional diagnostic
methods are often limited by variability, cost, and, most importantly, risk of
misdiagnosis. To address these challenges, machine learning (ML) has emerged as
a powerful tool for computer-aided diagnosis, with feature selection playing a
vital role in improving model performance and interpretability. This research
study proposes an integrated framework that incorporates customized Particle
Swarm Optimization (PSO) for feature selection. This framework has been
evaluated on a comprehensive set of 29 different models, spanning classical
classifiers, ensemble techniques, neural networks, probabilistic algorithms,
and instance-based algorithms. To ensure interpretability and clinical
relevance, the study uses cross-validation in conjunction with explainable AI
methods. Experimental evaluation showed that the proposed approach achieved a
superior score of 99.1\% across all performance metrics, including accuracy and
precision, while effectively reducing dimensionality and providing transparent,
model-agnostic explanations. The results highlight the potential of combining
swarm intelligence with explainable ML for robust, trustworthy, and clinically
meaningful breast cancer diagnosis.

</details>


### [448] [MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation](https://arxiv.org/abs/2510.20615)
*Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen*

Main category: cs.LG

TL;DR: MS-BART是一个统一的建模框架，用于通过跨模态学习来解决质谱数据中分子结构解析的挑战，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 质谱在分子鉴定中至关重要，但由于带注释光谱稀缺，从质谱数据中解析结构具有挑战性。本研究旨在解决这个问题。

Method: 提出MS-BART，一个统一的建模框架，将质谱和分子结构映射到共享的词汇表中，并通过大规模预训练进行跨模态学习。采用多任务预训练目标（去噪和翻译）来增强泛化能力。通过在MIST生成的指纹上进行微调，并将化学反馈机制集成到生成过程中，以提高对实验光谱的鲁棒性，并指导模型生成更接近参考结构的分子。

Result: MS-BART在MassSpecGym和NPLIB1数据集上的12个关键指标中的5个取得了SOTA性能，并且比竞争性扩散模型快一个数量级。消融研究验证了模型的有效性和鲁棒性。

Conclusion: MS-BART通过跨模态学习和多任务预训练，在质谱结构解析方面取得了显著的进展，并在性能和速度上优于现有方法。

Abstract: Mass spectrometry (MS) plays a critical role in molecular identification,
significantly advancing scientific discovery. However, structure elucidation
from MS data remains challenging due to the scarcity of annotated spectra.
While large-scale pretraining has proven effective in addressing data scarcity
in other domains, applying this paradigm to mass spectrometry is hindered by
the complexity and heterogeneity of raw spectral signals. To address this, we
propose MS-BART, a unified modeling framework that maps mass spectra and
molecular structures into a shared token vocabulary, enabling cross-modal
learning through large-scale pretraining on reliably computed
fingerprint-molecule datasets. Multi-task pretraining objectives further
enhance MS-BART's generalization by jointly optimizing denoising and
translation task. The pretrained model is subsequently transferred to
experimental spectra through finetuning on fingerprint predictions generated
with MIST, a pre-trained spectral inference model, thereby enhancing robustness
to real-world spectral variability. While finetuning alleviates the
distributional difference, MS-BART still suffers molecular hallucination and
requires further alignment. We therefore introduce a chemical feedback
mechanism that guides the model toward generating molecules closer to the
reference structure. Extensive evaluations demonstrate that MS-BART achieves
SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is
faster by one order of magnitude than competing diffusion-based methods, while
comprehensive ablation studies systematically validate the model's
effectiveness and robustness.

</details>


### [449] [On Optimal Hyperparameters for Differentially Private Deep Transfer Learning](https://arxiv.org/abs/2510.20616)
*Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela*

Main category: cs.LG

TL;DR: 论文研究了差分隐私（DP）迁移学习中的关键超参数裁剪边界 C 和批大小 B 的选择问题，发现理论与实践存在不符，并提出了更优的调优方法。


<details>
  <summary>Details</summary>
Motivation: 在差分隐私（DP）迁移学习设置中，如何选择最优的裁剪边界 C 和批大小 B 是一个关键问题。然而，现有的理论理解与实际经验之间存在不符，例如理论上更强的隐私要求更小的 C，但实践中更大的 C 往往在更强的隐私保护下表现更好。同时，在有限的计算预算下，现有的 B 超参数调整方法失效。因此，需要深入研究这些超参数的选择机制，并提出新的调整策略。

Method: 论文首先分析了裁剪边界 C 和批大小 B 在 DP 迁移学习中的作用。通过实验，揭示了理论与实践在 C 选择上的不符，并将其归因于梯度分布的变化。接着，在固定训练轮数（有限计算预算）的假设下，研究了 B 的选择，发现累积 DP 噪声更能解释大小批次选择的优劣。此外，论文还分析了在不同任务间使用单一 (C, B) 设置可能导致的性能下降，特别是在隐私级别和计算资源发生变化时。通过将裁剪视为一种梯度重加权，并分析累积 DP 噪声，论文解释了性能下降的原因。

Result: 研究发现，在 DP 迁移学习中，理论上认为更强的隐私需要更小的裁剪边界 C，但实际实验表明更大的 C 在更强的隐私保护下性能更好，这主要是由于梯度分布的变化。在有限的计算资源下，现有的批大小 B 调整方法不再适用，而累积 DP 噪声更能解释大小批次选择的有效性。在不同任务间使用固定的 (C, B) 设置会导致性能不佳，尤其是在隐私级别和计算资源发生较大变化时。

Conclusion: 论文总结指出，差分隐私迁移学习中的超参数选择比现有理论所认为的更为复杂。裁剪边界 C 的选择需要考虑梯度分布的变化，而批大小 B 的选择则与累积 DP 噪声密切相关。建议根据具体的隐私需求和计算资源，对 C 和 B 进行动态调整，而不是使用单一的固定设置，以获得最佳的迁移学习性能。

Abstract: Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained
model on private data, is the current state-of-the-art approach for training
large models under privacy constraints. We focus on two key hyperparameters in
this setting: the clipping bound $C$ and batch size $B$. We show a clear
mismatch between the current theoretical understanding of how to choose an
optimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes
(larger $C$ performs better under strong privacy), caused by changes in the
gradient distributions. Assuming a limited compute budget (fixed epochs), we
demonstrate that the existing heuristics for tuning $B$ do not work, while
cumulative DP noise better explains whether smaller or larger batches perform
better. We also highlight how the common practice of using a single $(C,B)$
setting across tasks can lead to suboptimal performance. We find that
performance drops especially when moving between loose and tight privacy and
between plentiful and limited compute, which we explain by analyzing clipping
as a form of gradient re-weighting and examining cumulative DP noise.

</details>


### [450] [H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition](https://arxiv.org/abs/2510.20627)
*Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis*

Main category: cs.LG

TL;DR: H-SPLID通过将显著和非显著特征分离到不同空间来学习显著特征表示，从而提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在学习显著特征表示方面存在局限性，无法有效地区分显著和非显著特征。

Method: 提出了一种名为H-SPLID的新算法，该算法将显著和非显著特征明确地分解到单独的空间中。

Result: H-SPLID促进了低维、任务相关特征的学习，并将预测偏差与显著子空间的维度和输入与表示之间的HSIC联系起来，从而在鲁棒性和潜在表示压缩之间建立了联系。

Conclusion: H-SPLID在图像分类任务上表现出优越性，模型主要依赖于显著输入成分，并且对影响非显著特征（如图像背景）的扰动不敏感。

Abstract: We introduce H-SPLID, a novel algorithm for learning salient feature
representations through the explicit decomposition of salient and non-salient
features into separate spaces. We show that H-SPLID promotes learning
low-dimensional, task-relevant features. We prove that the expected prediction
deviation under input perturbations is upper-bounded by the dimension of the
salient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between
inputs and representations. This establishes a link between robustness and
latent representation compression in terms of the dimensionality and
information preserved. Empirical evaluations on image classification tasks show
that models trained with H-SPLID primarily rely on salient input components, as
indicated by reduced sensitivity to perturbations affecting non-salient
features, such as image backgrounds. Our code is available at
https://github.com/neu-spiral/H-SPLID.

</details>


### [451] [Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach](https://arxiv.org/abs/2510.20629)
*Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为FASM（Fairness-Aware Survival Modeling）的方法，用于解决机器学习模型在医疗保健领域中可能存在的结构性不平等和社会偏见问题，特别是在生存分析中，该方法旨在减少跨组风险排名中的不公平现象，并通过对乳腺癌预后数据的应用，证明了其在提高公平性方面的有效性，同时保持了可比的区分性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在医疗保健领域的应用日益广泛，但临床数据中嵌入的结构性不平等和社会偏见可能被模型延续甚至放大。在生存分析中，删失和时间动态增加了公平模型开发的复杂性。现有的算法公平性方法常常忽略跨组排名的差异，例如，高风险的黑人患者可能排在低风险的白人患者之前，即使后者未发生死亡事件。这种错误的排序会加剧生物本质论，并损害公平的医疗护理。

Method: 提出了一种名为FASM（Fairness-Aware Survival Modeling）的框架，该框架旨在解决时间动态和跨组风险排名中的不公平问题。FASM被应用于乳腺癌预后分析，并使用SEER乳腺癌数据集进行验证。

Result: FASM能够显著提高公平性，同时保持与非公平感知生存模型相当的区分性能。在时间分层评估中，FASM在10年的随访期内保持了稳定的公平性，并在中期随访中观察到最大的改进。

Conclusion: FASM能够开发出在临床决策中兼顾准确性和公平性的生存模型，推动公平性成为临床护理的核心原则。

Abstract: As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.

</details>


### [452] [Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges](https://arxiv.org/abs/2510.20637)
*Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim*

Main category: cs.LG

TL;DR: LLM/LMM技术在6G通信领域具有巨大潜力，能够实现多模态感知、自适应重构和先进的调优策略，并在交通控制、机器人调度和信道估计等任务中展现出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: LLM/LMM在6G通信领域的应用潜力，特别是多模态感知集成、自适应重构和无线任务的提示/微调策略。

Method: 文章提出了一种基于LLM/LMM的通信框架，并通过三个案例研究（LMM交通控制、LLM机器人调度、LMM环境感知信道估计）进行了演示。

Result: 与传统的判别式深度学习模型相比，所提出的LLM/LMM辅助的自主系统在动态目标、变化的输入参数和异构多模态条件下表现出更强的鲁棒性，并且性能显著优于传统方法。

Conclusion: LLM/LMM技术在6G自主通信系统中表现出优越的性能和鲁棒性，特别是在动态和复杂环境下，能够有效处理多模态信息并适应不断变化的任务需求。

Abstract: Large language models (LLMs) and large multimodal models (LMMs) have achieved
unprecedented breakthrough, showcasing remarkable capabilities in natural
language understanding, generation, and complex reasoning. This transformative
potential has positioned them as key enablers for 6G autonomous communications
among machines, vehicles, and humanoids. In this article, we provide an
overview of task-oriented autonomous communications with LLMs/LMMs, focusing on
multimodal sensing integration, adaptive reconfiguration, and
prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework
through three case studies: LMM-based traffic control, LLM-based robot
scheduling, and LMM-based environment-aware channel estimation. From
experimental results, we show that the proposed LLM/LMM-aided autonomous
systems significantly outperform conventional and discriminative deep learning
(DL) model-based techniques, maintaining robustness under dynamic objectives,
varying input parameters, and heterogeneous multimodal conditions where
conventional static optimization degrades.

</details>


### [453] [Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems](https://arxiv.org/abs/2510.20640)
*Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan*

Main category: cs.LG

TL;DR: DiRecGNN是一个用于云服务监控的推荐框架，通过注意力机制增强，提高了监控属性选择的效率和准确性，并得到了用户的积极评价。


<details>
  <summary>Details</summary>
Motivation: 为云服务推荐最优的监控属性子集，以应对传统方法在处理有限信息和捕捉长距离依赖方面的不足。

Method: 构建异构图，并提出一种受Transformer启发的注意力增强实体排序模型，利用多头注意力和随机游走采样来捕捉异构邻居和长距离依赖，并采用多方面损失函数优化。

Result: 在MRR方面比现有方法提高了43.1%，并且用户评价该功能有用性为4.5/5。

Conclusion: DiRecGNN在云服务监控属性推荐方面取得了显著的性能提升，并且用户反馈积极，证明了其在实际部署中的有效性。

Abstract: In this paper, we present DiRecGNN, an attention-enhanced entity
recommendation framework for monitoring cloud services at Microsoft. We provide
insights on the usefulness of this feature as perceived by the cloud service
owners and lessons learned from deployment. Specifically, we introduce the
problem of recommending the optimal subset of attributes (dimensions) that
should be tracked by an automated watchdog (monitor) for cloud services. To
begin, we construct the monitor heterogeneous graph at production-scale. The
interaction dynamics of these entities are often characterized by limited
structural and engagement information, resulting in inferior performance of
state-of-the-art approaches. Moreover, traditional methods fail to capture the
dependencies between entities spanning a long range due to their homophilic
nature. Therefore, we propose an attention-enhanced entity ranking model
inspired by transformer architectures. Our model utilizes a multi-head
attention mechanism to focus on heterogeneous neighbors and their attributes,
and further attends to paths sampled using random walks to capture long-range
dependencies. We also employ multi-faceted loss functions to optimize for
relevant recommendations while respecting the inherent sparsity of the data.
Empirical evaluations demonstrate significant improvements over existing
methods, with our model achieving a 43.1% increase in MRR. Furthermore, product
teams who consumed these features perceive the feature as useful and rated it
4.5 out of 5.

</details>


### [454] [Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning](https://arxiv.org/abs/2510.20644)
*Reuben Dorent,Polina Golland,William Wells III*

Main category: cs.LG

TL;DR: 本篇论文推导了一个新的、可行的KL散度下界，并证明最大化基于JSD的目标可以提高MI的下界，为基于判别式学习的MI估计提供了理论和实证支持。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用JSD作为MI的替代目标，但其与MI的联系尚不明确，本文旨在弥合这一差距。

Method: 通过推导KL散度与JSD的精确下界，并将该下界应用于联合和边际分布，证明最大化JSD可以提高MI的下界。此外，还研究了基于二元分类器的交叉熵损失与JSD变分下界的关系。

Result: 提出的下界在MI估计方面具有很高的精确度，并且与最先进的变分下界估计器相比，在各种标准场景下表现出稳定、低方差的MI估计。本研究还将该下界应用于信息瓶颈框架，并展示了其实用性。

Conclusion: 本文的研究结果为在MI表示学习中使用判别式学习提供了新的理论依据和有力的实证证据。

Abstract: Mutual Information (MI) is a fundamental measure of statistical dependence
widely used in representation learning. While direct optimization of MI via its
definition as a Kullback-Leibler divergence (KLD) is often intractable, many
recent methods have instead maximized alternative dependence measures, most
notably, the Jensen-Shannon divergence (JSD) between joint and product of
marginal distributions via discriminative losses. However, the connection
between these surrogate objectives and MI remains poorly understood. In this
work, we bridge this gap by deriving a new, tight, and tractable lower bound on
KLD as a function of JSD in the general case. By specializing this bound to
joint and marginal distributions, we demonstrate that maximizing the JSD-based
information increases a guaranteed lower bound on mutual information.
Furthermore, we revisit the practical implementation of JSD-based objectives
and observe that minimizing the cross-entropy loss of a binary classifier
trained to distinguish joint from marginal pairs recovers a known variational
lower bound on the JSD. Extensive experiments demonstrate that our lower bound
is tight when applied to MI estimation. We compared our lower bound to
state-of-the-art neural estimators of variational lower bound across a range of
established reference scenarios. Our lower bound estimator consistently
provides a stable, low-variance estimate of a tight lower bound on MI. We also
demonstrate its practical usefulness in the context of the Information
Bottleneck framework. Taken together, our results provide new theoretical
justifications and strong empirical evidence for using discriminative learning
in MI-based representation learning.

</details>


### [455] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: xTime是一个用于时间序列极端事件预测的新框架，通过知识蒸馏和混合专家机制提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型在预测极端事件方面存在挑战，主要由于数据不平衡以及忽略了中间事件的信息。

Method: xTime利用知识蒸馏从预测较低稀有事件的模型中转移信息，并引入混合专家机制来动态选择和融合不同稀有度专家模型的输出。

Result: 在多个数据集上的实验表明，xTime在极端事件预测方面的准确性提高了3%到78%。

Conclusion: xTime通过知识蒸馏和混合专家机制，有效提高了时间序列极端事件预测的准确性。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [456] [From Masks to Worlds: A Hitchhiker's Guide to World Models](https://arxiv.org/abs/2510.20668)
*Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang*

Main category: cs.LG

TL;DR: 本文旨在指导读者构建世界模型，而非对现有世界模型进行全面综述。文章聚焦于核心技术，如生成模型、交互循环和记忆系统，并展示了其通往真正世界模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为读者提供一个构建世界模型的清晰指南，重点关注从早期模型到先进的记忆增强系统的发展脉络。

Method: 文章沿着一条清晰的路线进行阐述：从统一跨模态表征学习的早期掩码模型，到共享单一范式的统一架构，再到实现动作-感知闭环的交互式生成模型，最后到能够维持一致世界长久存在的记忆增强系统。

Result: 通过聚焦生成核心、交互循环和记忆系统，本文展示了这一路径是通往真正世界模型的最有希望的途径。

Conclusion: 本文认为，通过关注生成核心、交互循环和记忆系统，可以为构建真正世界模型提供最有前景的发展道路。

Abstract: This is not a typical survey of world models; it is a guide for those who
want to build worlds. We do not aim to catalog every paper that has ever
mentioned a ``world model". Instead, we follow one clear road: from early
masked models that unified representation learning across modalities, to
unified architectures that share a single paradigm, then to interactive
generative models that close the action-perception loop, and finally to
memory-augmented systems that sustain consistent worlds over time. We bypass
loosely related branches to focus on the core: the generative heart, the
interactive loop, and the memory system. We show that this is the most
promising path towards true world models.

</details>


### [457] [GRACE: GRaph-based Addiction Care prEdiction](https://arxiv.org/abs/2510.20671)
*Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee*

Main category: cs.LG

TL;DR: 本研究提出了一种名为GRACE的新型图神经网络框架，用于解决药物成瘾患者的护理地点预测问题，克服了现有方法在处理类别不平衡数据集方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在药物成瘾治疗领域，确定合适的护理地点对患者的治疗效果和资源的有效利用至关重要。然而，现有的专业治疗资源（如住院床位或医护人员）不足，导致自动化决策框架的开发成为一种迫切需求。现有决策方法在处理药物成瘾数据集时存在严重的类别不平衡问题。

Method: 本研究提出了一种名为GRACE的新型图神经网络（GNN）框架，将护理地点预测形式化为一个结构化学习问题。此外，研究人员进行了广泛的特征工程，并提出了一种获取无偏置元图的新方法，以训练GNN并克服类别不平衡问题。

Result: 在真实世界的数据集上进行的大量实验结果表明，与现有的竞争性基线方法相比，该方法在少数类别的F1分数方面提高了11-35%。

Conclusion: GRACE框架通过形式化结构化学习问题和引入无偏置元图来解决药物成瘾数据集中的类别不平衡问题，并在真实世界数据上取得了显著的性能提升。

Abstract: Determining the appropriate locus of care for addiction patients is one of
the most critical clinical decisions that affects patient treatment outcomes
and effective use of resources. With a lack of sufficient specialized treatment
resources, such as inpatient beds or staff, there is an unmet need to develop
an automated framework for the same. Current decision-making approaches suffer
from severe class imbalances in addiction datasets. To address this limitation,
we propose a novel graph neural network (GRACE) framework that formalizes locus
of care prediction as a structured learning problem. Further, we perform
extensive feature engineering and propose a new approach of obtaining an
unbiased meta-graph to train a GNN to overcome the class imbalance problem.
Experimental results in real-world data show an improvement of 11-35% in terms
of the F1 score of the minority class over competitive baselines. The codes and
note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.

</details>


### [458] [MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs](https://arxiv.org/abs/2510.20762)
*Jan Sobotka,Luca Baroni,Ján Antolík*

Main category: cs.LG

TL;DR: MEIcoder是一种新的深度学习解码方法，利用神经元特异性最兴奋输入（MEIs）、结构相似性度量损失和对抗性训练，在稀疏数据下能实现先进的视觉刺激解码，尤其在小数据集上表现优异，并提出了一个包含16万以上样本的基准测试。


<details>
  <summary>Details</summary>
Motivation: 为了解决生物数据稀疏（尤其是在灵长类动物或人类中）的挑战，以实现大脑理解和脑机接口应用中的视觉刺激解码。

Method: 提出了一种名为MEIcoder的生物学方法，该方法利用神经元特异性最兴奋输入（MEIs）、结构相似性度量损失和对抗性训练。

Result: MEIcoder在从初级视觉皮层（V1）的单细胞活动重建视觉刺激方面取得了最先进的性能，尤其在数据集较小、记录神经元较少的情况下表现出色。通过消融研究证明了MEIs的性能驱动作用，并通过扩展实验表明MEIcoder可以从少至1000-2500个神经元和少于1000个训练数据点中重建高保真度的自然图像。此外，还提出了一个包含160,000多个样本的统一基准测试。

Conclusion: 研究结果证明了早期视觉系统中可靠解码的可行性，并为神经科学和神经工程应用提供了实用的见解。

Abstract: Decoding visual stimuli from neural population activity is crucial for
understanding the brain and for applications in brain-machine interfaces.
However, such biological data is often scarce, particularly in primates or
humans, where high-throughput recording techniques, such as two-photon imaging,
remain challenging or impossible to apply. This, in turn, poses a challenge for
deep learning decoding techniques. To overcome this, we introduce MEIcoder, a
biologically informed decoding method that leverages neuron-specific most
exciting inputs (MEIs), a structural similarity index measure loss, and
adversarial training. MEIcoder achieves state-of-the-art performance in
reconstructing visual stimuli from single-cell activity in primary visual
cortex (V1), especially excelling on small datasets with fewer recorded
neurons. Using ablation studies, we demonstrate that MEIs are the main drivers
of the performance, and in scaling experiments, we show that MEIcoder can
reconstruct high-fidelity natural-looking images from as few as 1,000-2,500
neurons and less than 1,000 training data points. We also propose a unified
benchmark with over 160,000 samples to foster future research. Our results
demonstrate the feasibility of reliable decoding in early visual system and
provide practical insights for neuroscience and neuroengineering applications.

</details>


### [459] [A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks](https://arxiv.org/abs/2510.20683)
*Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale*

Main category: cs.LG

TL;DR: Spikachu是一个基于脉冲神经网络(SNN)的可扩展、因果、能效高的神经解码框架，在能耗远低于当前模型的情况下，实现了与最先进模型相媲美的性能，并且支持在线和少样本迁移。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的神经解码模型要么泛化能力差，要么难以适应实时场景，并且能耗高，限制了其在实际资源受限系统中的应用。脉冲神经网络(SNN)因其因果性和低能耗的特性，为解决这些问题提供了有希望的替代方案。

Method: 提出了一种名为Spikachu的神经解码框架，该框架基于SNN，能够直接处理二值化脉冲，并通过投影到共享的潜在空间来提取相关特征，然后整合这些潜在表征以进行行为预测。该方法能够适应输入的时序信息。

Result: 在6只非人灵长类动物的113个记录会话（总计43小时）的评估中，Spikachu在仅使用单次会话训练的情况下，能耗比因果基线模型低2.26至418.81倍。此外，通过扩展训练到多个会话和被试，性能得到提升，并实现了到未见会话、被试和任务的少样本迁移。

Conclusion: Spikachu是一个可扩展的、支持在线操作的神经解码框架，它基于SNN，在能耗远低于现有模型（数量级上）的情况下，实现了与当前最先进模型相竞争的性能。

Abstract: Brain-computer interfaces (BCIs) promise to enable vital functions, such as
speech and prosthetic control, for individuals with neuromotor impairments.
Central to their success are neural decoders, models that map neural activity
to intended behavior. Current learning-based decoding approaches fall into two
classes: simple, causal models that lack generalization, or complex, non-causal
models that generalize and scale offline but struggle in real-time settings.
Both face a common challenge, their reliance on power-hungry artificial neural
network backbones, which makes integration into real-world, resource-limited
systems difficult. Spiking neural networks (SNNs) offer a promising
alternative. Because they operate causally these models are suitable for
real-time use, and their low energy demands make them ideal for
battery-constrained environments. To this end, we introduce Spikachu: a
scalable, causal, and energy-efficient neural decoding framework based on SNNs.
Our approach processes binned spikes directly by projecting them into a shared
latent space, where spiking modules, adapted to the timing of the input,
extract relevant features; these latent representations are then integrated and
decoded to generate behavioral predictions. We evaluate our approach on 113
recording sessions from 6 non-human primates, totaling 43 hours of recordings.
Our method outperforms causal baselines when trained on single sessions using
between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that
scaling up training to multiple sessions and subjects improves performance and
enables few-shot transfer to unseen sessions, subjects, and tasks. Overall,
Spikachu introduces a scalable, online-compatible neural decoding framework
based on SNNs, whose performance is competitive relative to state-of-the-art
models while consuming orders of magnitude less energy.

</details>


### [460] [Separating the what and how of compositional computation to enable reuse and continual learning](https://arxiv.org/abs/2510.20709)
*Haozhe Shan,Sun Minni,Lea Duncker*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的双系统方法来研究持续学习和技能的组合重用，其中一个系统推断要执行什么计算，另一个系统实现如何执行计算。该方法在组合认知任务上表现出有效性，并能持续学习而不会灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 神经机制在持续学习和灵活的技能（再）组合方面仍然难以捉摸，这对于智能和高效的行为至关重要。

Method: 使用一种新颖的双系统方法：一个推断计算内容的系统（what系统），以及一个实现该计算的系统（how系统）。what系统基于一个概率生成模型，该模型具有共享的离散任务时期词汇，从而实现组合性。how系统实现为一个RNN，其低秩分量根据what系统推断出的上下文进行组合。

Result: 该双系统学习框架在示例任务集上证明了其有效性和竞争力，展示了其前向和后向迁移的潜力，以及对未见任务的快速组合泛化能力。

Conclusion: 所提出的双系统学习框架能够有效地进行持续学习和技能的组合重用，克服了灾难性遗忘的问题，并在各种组合认知任务中表现出优越的性能。

Abstract: The ability to continually learn, retain and deploy skills to accomplish
goals is a key feature of intelligent and efficient behavior. However, the
neural mechanisms facilitating the continual learning and flexible
(re-)composition of skills remain elusive. Here, we study continual learning
and the compositional reuse of learned computations in recurrent neural network
(RNN) models using a novel two-system approach: one system that infers what
computation to perform, and one that implements how to perform it. We focus on
a set of compositional cognitive tasks commonly studied in neuroscience. To
construct the what system, we first show that a large family of tasks can be
systematically described by a probabilistic generative model, where
compositionality stems from a shared underlying vocabulary of discrete task
epochs. The shared epoch structure makes these tasks inherently compositional.
We first show that this compositionality can be systematically described by a
probabilistic generative model. Furthermore, We develop an unsupervised online
learning approach that can learn this model on a single-trial basis, building
its vocabulary incrementally as it is exposed to new tasks, and inferring the
latent epoch structure as a time-varying computational context within a trial.
We implement the how system as an RNN whose low-rank components are composed
according to the context inferred by the what system. Contextual inference
facilitates the creation, learning, and reuse of low-rank RNN components as new
tasks are introduced sequentially, enabling continual learning without
catastrophic forgetting. Using an example task set, we demonstrate the efficacy
and competitive performance of this two-system learning framework, its
potential for forward and backward transfer, as well as fast compositional
generalization to unseen tasks.

</details>


### [461] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动的建模方法，利用受限分数优化（CSO）模型，改进了约翰霍普金斯跌倒风险评估工具（JHFRAT）的跌倒风险预测能力，提高了预测准确性，并保持了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过数据驱动的建模方法，使跌倒风险预测（来自JHFRAT）与额外的临床有意义的指标更好地保持一致。

Method: 对来自三家约翰霍普金斯医疗系统医院的54,209名住院患者进行回顾性分析，使用受限分数优化（CSO）模型对JHFRAT评估数据和电子健康记录（EHR）变量进行建模。

Result: CSO模型在预测性能上显著优于当前的JHFRAT（CSO AUC-ROC=0.91，JHFRAT AUC-ROC=0.86）。在有无EHR变量的情况下，CSO模型的表现相似。虽然XGBoost等“黑盒”模型在性能指标上优于CSO（AUC-ROC=0.94），但CSO在风险标签变化方面表现出更强的鲁棒性。

Conclusion: 这种基于证据的方法为医疗系统提供了一个坚实的基础，可以通过数据驱动的优化技术系统地加强住院患者的跌倒预防方案和患者安全，从而改善医疗环境中的风险评估和资源分配。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [462] [Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2510.20718)
*Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder*

Main category: cs.LG

TL;DR: 该论文提出了一种用于半导体制造异常预测的框架，通过训练预测模型并在新数据上执行预测，并将预测结果与实际信号进行比较来识别异常。框架包含两种方法：一种是使用N-BEATS模型的单变量预测，另一种是使用图神经网络（GNN）来捕捉变量间的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 半导体制造过程复杂且参数众多，需要实时监控和故障检测。现有技术面临高维度数据和类别不平衡的挑战，并且难以进行根本原因分析。因此，需要将异常检测提升到异常预测，以实现实时过程纠正和主动故障预防。

Method: 该论文提出一个包含两个阶段的异常预测框架：（a）在假设不包含异常的数据集上训练预测模型；（b）对未见过的时间序列数据执行预测，并将预测结果与训练信号的预测进行比较，超过预设阈值的偏差被标记为异常。两种方法的主要区别在于所使用的预测模型：第一种方法使用N-BEATS模型进行单变量时间序列预测，假设变量之间相互独立；第二种方法使用图神经网络（GNN）来捕捉变量之间的关系，克服了独立性假设的限制。

Result: 两种方法都展示了高达20个时间点预测的强大性能，并且在长达50个时间点的异常预测中保持稳定。GNN模型在预测性能上持续优于N-BEATS模型，同时需要更少的训练参数和更低的计算成本。

Conclusion: GNN模型在捕捉变量间关系、预测性能和计算效率方面均优于N-BEATS模型，是用于在线异常预测和部署在制造环境中的有前途的解决方案。

Abstract: Semiconductor manufacturing is an extremely complex and precision-driven
process, characterized by thousands of interdependent parameters collected
across diverse tools and process steps. Multi-variate time-series analysis has
emerged as a critical field for real-time monitoring and fault detection in
such environments. However, anomaly prediction in semiconductor fabrication
presents several critical challenges, including high dimensionality of sensor
data and severe class imbalance due to the rarity of true faults. Furthermore,
the complex interdependencies between variables complicate both anomaly
prediction and root-cause-analysis. This paper proposes two novel approaches to
advance the field from anomaly detection to anomaly prediction, an essential
step toward enabling real-time process correction and proactive fault
prevention. The proposed anomaly prediction framework contains two main stages:
(a) training a forecasting model on a dataset assumed to contain no anomalies,
and (b) performing forecast on unseen time series data. The forecast is
compared with the forecast of the trained signal. Deviations beyond a
predefined threshold are flagged as anomalies. The two approaches differ in the
forecasting model employed. The first assumes independence between variables by
utilizing the N-BEATS model for univariate time series forecasting. The second
lifts this assumption by utilizing a Graph Neural Network (GNN) to capture
inter-variable relationships. Both models demonstrate strong forecasting
performance up to a horizon of 20 time points and maintain stable anomaly
prediction up to 50 time points. The GNN consistently outperforms the N-BEATS
model while requiring significantly fewer trainable parameters and lower
computational cost. These results position the GNN as promising solution for
online anomaly forecasting to be deployed in manufacturing environments.

</details>


### [463] [No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes](https://arxiv.org/abs/2510.20725)
*Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek*

Main category: cs.LG

TL;DR: Thompson sampling (TS) 在具有高斯边缘分布的模型中，在episodic RL 中提供无悔保证，并证明了 $\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$ 的悔恨界限。


<details>
  <summary>Details</summary>
Motivation: 尽管 Thompson sampling (TS) 在序列决策中应用广泛，但其在强化学习 (RL) 等具有复杂时间结构的场景下的理论基础仍然有限。本研究旨在解决这一差距。

Method: 在具有联合高斯过程 (GP) 先验的奖励和转移的 episodic RL 设置中，我们对 TS 进行了分析。我们利用诸如椭圆势能引理的多输出扩展来应对价值函数非高斯性和 Bellman 更新的递归结构等挑战。

Result: 我们为 TS 提供了在具有高斯边缘分布的模型中的无悔保证，并证明了在 $K$ 个回合、 horizonte $H$ 的情况下，悔恨界限为 $\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$，其中 $\Gamma(\cdot)$ 表示 GP 模型的复杂度。

Conclusion: 这项工作加深了对 RL 中 TS 的理解，并强调了结构假设和模型不确定性如何影响其在有限 horizonte 马尔可夫决策过程中的表现。

Abstract: Thompson sampling (TS) is a powerful and widely used strategy for sequential
decision-making, with applications ranging from Bayesian optimization to
reinforcement learning (RL). Despite its success, the theoretical foundations
of TS remain limited, particularly in settings with complex temporal structure
such as RL. We address this gap by establishing no-regret guarantees for TS
using models with Gaussian marginal distributions. Specifically, we consider TS
in episodic RL with joint Gaussian process (GP) priors over rewards and
transitions. We prove a regret bound of
$\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$ over $K$ episodes of horizon $H$,
where $\Gamma(\cdot)$ captures the complexity of the GP model. Our analysis
addresses several challenges, including the non-Gaussian nature of value
functions and the recursive structure of Bellman updates, and extends classical
tools such as the elliptical potential lemma to multi-output settings. This
work advances the understanding of TS in RL and highlights how structural
assumptions and model uncertainty shape its performance in finite-horizon
Markov Decision Processes.

</details>


### [464] [Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](https://arxiv.org/abs/2510.20736)
*Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种新的 DP 驱动的多模态学习框架，该框架可以自动在显著的模态内表示学习和跨模态对齐之间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 开发有效得多模态融合方法对于医疗保健和金融等许多现实场景至关重要。关键挑战在于如何在学习跨模态交互的同时保留每个模态中的特征表达能力。先前的研究主要关注跨模态对齐，而过度强调模态边缘分布的对齐可能会施加过度的正则化，并阻碍模态内有意义的表示。

Method: 提出了一种新的 DP 驱动的多模态学习框架，该框架假设每个模态都遵循多元高斯混合模型，并采用 DP 来计算所有组件的混合权重。DP 的“富者越富”特性可以动态分配特征贡献并选择最显著的特征，从而促进多模态特征融合。

Result: 在几个多模态数据集上的广泛实验表明，我们的模型优于其他竞争对手。单独的消减分析进一步验证了 DP 在对齐模态分布方面的有效性及其对关键超参数变化的鲁棒性。

Conclusion: 所提出的 DP 驱动框架能够有效平衡模态内表示学习和跨模态对齐，并在多模态学习任务中取得优越性能。

Abstract: Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

</details>


### [465] [Out-of-distribution Tests Reveal Compositionality in Chess Transformers](https://arxiv.org/abs/2510.20783)
*Anna Mészáros,Patrik Reizinger,Ferenc Huszár*

Main category: cs.LG

TL;DR: Decision Transformers can generalize to unseen chess scenarios, showing compositional understanding, but struggle with certain variants compared to symbolic AI.


<details>
  <summary>Details</summary>
Motivation: Investigate the extent to which Decision Transformers capture the rules of chess and exhibit systematic generalization.

Method: Trained a 270M parameter chess Transformer and evaluated it on out-of-distribution scenarios, including Chess960, comparing its performance to symbolic AI algorithms.

Result: The Transformer showed compositional generalization and adherence to syntactic rules, generating high-quality moves for OOD puzzles. It exhibited basic strategy adaptation for Chess960 but was inferior to symbolic AI. Training dynamics suggested emergent compositional understanding.

Conclusion: Chess Transformers demonstrate compositional generalization and understanding of chess rules, but further improvements are needed to match symbolic AI performance in complex variants. The emergent understanding during training is a key finding.

Abstract: Chess is a canonical example of a task that requires rigorous reasoning and
long-term planning. Modern decision Transformers - trained similarly to LLMs -
are able to learn competent gameplay, but it is unclear to what extent they
truly capture the rules of chess. To investigate this, we train a 270M
parameter chess Transformer and test it on out-of-distribution scenarios,
designed to reveal failures of systematic generalization. Our analysis shows
that Transformers exhibit compositional generalization, as evidenced by strong
rule extrapolation: they adhere to fundamental syntactic rules of the game by
consistently choosing valid moves even in situations very different from the
training data. Moreover, they also generate high-quality moves for OOD puzzles.
In a more challenging test, we evaluate the models on variants including
Chess960 (Fischer Random Chess) - a variant of chess where starting positions
of pieces are randomized. We found that while the model exhibits basic strategy
adaptation, they are inferior to symbolic AI algorithms that perform explicit
search, but gap is smaller when playing against users on Lichess. Moreover, the
training dynamics revealed that the model initially learns to move only its own
pieces, suggesting an emergent compositional understanding of the game.

</details>


### [466] [KL-Regularized Reinforcement Learning is Designed to Mode Collapse](https://arxiv.org/abs/2510.20817)
*Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 反向/前向KL散度在强化学习中的选择并不直接决定模式覆盖，而是影响最优目标分布的参数族。


<details>
  <summary>Details</summary>
Motivation: 探讨反向/前向KL散度在强化学习中的应用，挑战了关于KL散度优化导致“模式寻求”或“质量覆盖”的普遍认知。

Method: 通过数学推导和实验，分析KL散度正则化在强化学习中的作用，并提出一种新的算法。

Result: 反向/前向KL散度的选择决定了最优目标分布的参数族，模式覆盖主要受正则化强度、奖励和参考概率的相对尺度等因素影响。低正则化强度和相等奖励通常导致单峰目标分布。提出的新算法能生成高覆盖率和多样性的目标分布。

Conclusion: 提出的新算法在语言模型和化学语言模型上进行了后训练，提高了解决方案的质量和多样性，并且在单独使用前向或反向KL散度时效果不佳的情况下，也能有效工作。

Abstract: It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [467] [Resource-Aware Hybrid Quantum Programming with General Recursion and Quantum Control](https://arxiv.org/abs/2510.20452)
*Kostia Chardonnet,Emmanuel Hainry,Romain Péchoux,Thomas Vinet*

Main category: cs.LO

TL;DR: 该论文介绍了一种名为Hyrql的混合量子语言，它支持通用递归，并着重于资源分析。Hyrql的设计无需预先指定初始量子门集，因此非常适合进行通用的成本分析。通过将量子电路表示为不同量子门集的语言，可以实现计算复杂度的变化。为了进行资源分析，论文描述了一种保持语义的、可编译到简单类型项重写系统的算法，从而可以重用已知的项重写系统复杂性分析技术。论文通过大量示例证明了该方法的通用性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种支持通用递归的混合量子语言（Hyrql），并使其能够进行资源分析，特别是通用成本分析。

Method: 提出了一种名为Hyrql的混合量子语言，它支持通用递归。设计了一种将Hyrql编译到简单类型项重写系统的、保持语义的算法，以便利用现有的项重写系统分析技术进行资源分析。

Result: 实现了一种用于混合量子语言的资源分析方法，该方法通过编译到项重写系统来分析计算复杂度，并通过多种示例证明了其通用性。

Conclusion: 所提出的Hyrql语言及其资源分析方法通用且有效，能够适应不同量子门集，并可以重用现有的项重写系统分析技术。

Abstract: This paper introduces the hybrid quantum language with general recursion
$\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\mathtt{Hyrql}$
does not require the specification of an initial set of quantum gates and,
hence, is well amenable towards a generic cost analysis. Indeed, languages
using different sets of quantum gates lead to representations of quantum
circuits whose complexity varies. Towards resource-analysis, a
semantics-preserving compilation algorithm to simply-typed term rewrite systems
is described; allowing a generic reuse of all known techniques for analyzing
the complexity of term rewrite systems. We prove the versatility of this
approach through many examples.

</details>
