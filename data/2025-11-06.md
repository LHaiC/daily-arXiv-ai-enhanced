<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 42]
- [cs.CL](#cs.CL) [Total: 47]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 3]
- [eess.SP](#eess.SP) [Total: 24]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.DS](#cs.DS) [Total: 13]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.AI](#cs.AI) [Total: 16]
- [eess.SY](#eess.SY) [Total: 17]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.GR](#cs.GR) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.ET](#cs.ET) [Total: 3]
- [quant-ph](#quant-ph) [Total: 35]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cropland Mapping using Geospatial Embeddings](https://arxiv.org/abs/2511.02923)
*Ivan Zvonkov,Gabriel Tseng,Inbal Becker-Reshef,Hannah Kerner*

Main category: cs.CV

TL;DR: 地理空间嵌入可用于简化工作流程、实现高精度农田分类，并最终支持对土地利用变化及其气候影响进行更好的评估。


<details>
  <summary>Details</summary>
Motivation: 准确且最新的土地覆盖图对于理解作为气候变化的关键驱动因素的土地利用变化至关重要。地理空间嵌入为测绘景观特征提供了一种更有效、更易于访问的方式，但其在实际测绘应用中的使用仍有待探索。

Method: 本研究评估了地理空间嵌入在多哥农田测绘中的效用。我们使用来自 Presto 和 AlphaEarth 的嵌入生成了农田图。

Result: 研究结果表明，地理空间嵌入可以简化工作流程，实现高精度的农田分类。

Conclusion: 地理空间嵌入可以支持对土地利用变化及其气候影响进行更好的评估。

Abstract: Accurate and up-to-date land cover maps are essential for understanding land
use change, a key driver of climate change. Geospatial embeddings offer a more
efficient and accessible way to map landscape features, yet their use in
real-world mapping applications remains underexplored. In this work, we
evaluated the utility of geospatial embeddings for cropland mapping in Togo. We
produced cropland maps using embeddings from Presto and AlphaEarth. Our
findings show that geospatial embeddings can simplify workflows, achieve
high-accuracy cropland classification and ultimately support better assessments
of land use change and its climate impacts.

</details>


### [2] [Generative Hints](https://arxiv.org/abs/2511.02933)
*Andy Dimnaku,Abdullah Yusuf Kavranoğlu,Yaser Abu-Mostafa*

Main category: cs.CV

TL;DR: 使用生成模型生成虚拟样本，强制执行提示以学习不变性，优于传统数据增强。


<details>
  <summary>Details</summary>
Motivation: 数据增强虽然广泛用于引入变异和减轻过拟合，但无法完全捕捉空间不变性等属性，因为它仅在训练数据的变换上学习这些属性。

Method: 提出生成式提示（generative hints）的训练方法，利用在训练集上训练的生成模型来近似输入分布并生成虚拟样本，然后使用这些虚拟样本强制执行提示（hints）来学习不变性。

Result: 在图像分类任务中，生成式提示在准确率和性能方面优于标准数据增强方法，在细粒度视觉分类基准测试中提高了高达 1.78% 的 top-1 准确率，在 CheXpert X 射线数据集上平均性能提升了 1.286%。

Conclusion: 生成式提示是一种有效的训练方法，可以直接在整个输入空间中强制执行不变性，从而在各种数据集、架构和损失函数上持续优于标准数据增强。

Abstract: Data augmentation is widely used in vision to introduce variation and
mitigate overfitting, through enabling models to learn invariant properties,
such as spatial invariance. However, these properties are not fully captured by
data augmentation alone, since it attempts to learn the property on
transformations of the training data only. We propose generative hints, a
training methodology that directly enforces known invariances in the entire
input space. Our approach leverages a generative model trained on the training
set to approximate the input distribution and generate unlabeled images, which
we refer to as virtual examples. These virtual examples are used to enforce
functional properties known as hints. In generative hints, although the
training dataset is fully labeled, the model is trained in a semi-supervised
manner on both the classification and hint objectives, using the unlabeled
virtual examples to guide the model in learning the desired hint. Across
datasets, architectures, and loss functions, generative hints consistently
outperform standard data augmentation when learning the same property. On
popular fine-grained visual classification benchmarks, we achieved up to 1.78%
top-1 accuracy improvement (0.63% on average) over fine-tuned models with data
augmentation and an average performance boost of 1.286% on the CheXpert X-ray
dataset.

</details>


### [3] [A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction](https://arxiv.org/abs/2511.03093)
*Yi Gong,Xinyuan Zhang,Jichen Chai,Yichen Ding,Yifei Lou*

Main category: cs.CV

TL;DR: 通过结合压缩感知（CS）和光片显微镜（LSM）技术，提出了一种高效、低光毒性的心脏成像新框架，解决了传统成像方法在捕捉跳动心脏细胞动态结构时的时空分辨率限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统的光学成像方法在捕捉跳动心脏细胞的动态结构时，存在空间和时间分辨率之间的固有权衡，难以满足需求。

Method: 提出了一种高性能的计算成像框架，集成了压缩感知（CS）和光片显微镜（LSM）。该系统利用数字微镜设备（DMD）通过随机二元掩码编码进行压缩采集荧光信号，并采用交替方向乘子法（ADMM）求解即插即用（PnP）框架，该框架能够灵活地整合包括Tikhonov、全变分（TV）和BM3D在内的先进降噪器。此外，为了在动态成像中保持结构连续性，还引入了强制相邻z切片之间平滑性的时间正则化。

Result: 在心房颤动（AFib）研究中，一种利用多电极导管的先进技术在识别和消融触发房颤的肺静脉区域方面显示出高成功率。通过对高压缩比下的斑马鱼心脏成像进行的实验表明，该方法能够成功重建细胞结构，并具有出色的去噪性能和图像清晰度。

Conclusion: 该计算成像框架在高速、低光照的生物成像场景中被证明是有效且鲁棒的，能够成功重建细胞结构，并具有出色的去噪性能和图像清晰度，克服了传统方法的局限性。

Abstract: Cardiac contraction is a rapid, coordinated process that unfolds across
three-dimensional tissue on millisecond timescales. Traditional optical imaging
is often inadequate for capturing dynamic cellular structure in the beating
heart because of a fundamental trade-off between spatial and temporal
resolution. To overcome these limitations, we propose a high-performance
computational imaging framework that integrates Compressive Sensing (CS) with
Light-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The
system performs compressed acquisition of fluorescence signals via random
binary mask coding using a Digital Micromirror Device (DMD). We propose a
Plug-and-Play (PnP) framework, solved using the alternating direction method of
multipliers (ADMM), which flexibly incorporates advanced denoisers, including
Tikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in
dynamic imaging, we further introduce temporal regularization enforcing
smoothness between adjacent z-slices. Experimental results on zebrafish heart
imaging under high compression ratios demonstrate that the proposed method
successfully reconstructs cellular structures with excellent denoising
performance and image clarity, validating the effectiveness and robustness of
our algorithm in real-world high-speed, low-light biological imaging scenarios.

</details>


### [4] [ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology](https://arxiv.org/abs/2511.02946)
*Srikumar Sastry,Subash Khanal,Aayush Dhakal,Jiayu Lin,Dan Cher,Phoenix Jarosz,Nathan Jacobs*

Main category: cs.CV

TL;DR: ProM3E是一个用于生态学多模态表示的任何到任何生成模型，它通过掩码多模态重建来学习推断缺失的模态，支持模态反演，并能分析模态融合的可行性，可用于跨模态检索和表示学习。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提出一个新颖的概率掩码多模态嵌入模型（ProM3E），用于生态学领域任何到任何的多模态表示生成，并解决多模态融合和跨模态检索的挑战。

Method: 提出了一种基于掩码多模态重建的概率模型ProM3E，该模型在嵌入空间中学习推断缺失的模态，支持模态反演，并能分析模态融合的可行性。在此基础上，提出了一种结合模态内和模态间相似性的新型跨模态检索方法，并利用模型隐藏表示进行线性探测任务以评估表示学习能力。

Result: ProM3E模型在跨模态检索任务中取得了优越的性能，并在线性探测任务中展示了其强大的表示学习能力。

Conclusion: ProM3E模型在生态学多模态表示生成、模态融合分析、跨模态检索和表示学习方面均表现出优越的性能和潜力。

Abstract: We introduce ProM3E, a probabilistic masked multimodal embedding model for
any-to-any generation of multimodal representations for ecology. ProM3E is
based on masked modality reconstruction in the embedding space, learning to
infer missing modalities given a few context modalities. By design, our model
supports modality inversion in the embedding space. The probabilistic nature of
our model allows us to analyse the feasibility of fusing various modalities for
given downstream tasks, essentially learning what to fuse. Using these features
of our model, we propose a novel cross-modal retrieval approach that mixes
inter-modal and intra-modal similarities to achieve superior performance across
all retrieval tasks. We further leverage the hidden representation from our
model to perform linear probing tasks and demonstrate the superior
representation learning capability of our model. All our code, datasets and
model will be released at https://vishu26.github.io/prom3e.

</details>


### [5] [EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: 该研究提出了EvtSlowTV，一个包含超过130亿事件的大规模事件相机数据集，旨在解决现有事件深度估计方法在标注数据集上的局限性，并展示了其在自监督学习框架下的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的事件相机深度估计方法受限于小规模标注数据集，泛化能力不足。本研究旨在创建一个大规模、多样化的事件相机数据集，以促进事件基深度学习的发展。

Method: 从YouTube视频中收集并整理了EvtSlowTV数据集，该数据集包含各种环境和运动条件下的海量事件数据。将该数据集应用于自监督学习框架，以利用原始事件流的高动态范围（HDR）特性，并训练模型进行深度估计。

Result: EvtSlowTV数据集的规模是现有数据集的十倍以上，提供了自然、无约束的场景。在EvtSlowTV上训练的模型在复杂场景和运动中表现出更好的泛化能力。

Conclusion: EvtSlowTV数据集为事件相机深度估计提供了大规模、多样化的训练数据，通过自监督学习可以有效提升模型的泛化能力，并且无需依赖帧式标注，保留了事件数据的异步特性。

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [6] [Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification](https://arxiv.org/abs/2511.02992)
*Mikhael Djajapermana,Moritz Reiber,Daniel Mueller-Gritschneder,Ulf Schlichtmann*

Main category: cs.CV

TL;DR: 本文提出了一种新的混合CNN-ViT神经架构搜索空间，用于在tinyML设备上部署高效的图像分类模型。


<details>
  <summary>Details</summary>
Motivation: 现有的混合CNN-ViT模型虽然性能优越，但参数量大、计算成本高，不适合tinyML部署。

Method: 设计了一个包含混合CNN和ViT块以及可搜索池化层的搜索空间，以学习局部和全局信息，并进行高效的特征图降维。

Result: 在CIFAR10数据集上，所提出的搜索空间能够生成比基于ResNet的tinyML模型具有更高精度和更快推理速度的混合CNN-ViT架构，同时满足严格的模型尺寸限制。

Conclusion: 本文提出的搜索空间能够为tinyML部署找到高效的混合CNN-ViT图像分类模型。

Abstract: Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)
have outperformed pure CNN or ViT architecture. However, since these
architectures require large parameters and incur large computational costs,
they are unsuitable for tinyML deployment. This paper introduces a new hybrid
CNN-ViT search space for Neural Architecture Search (NAS) to find efficient
hybrid architectures for image classification. The search space covers hybrid
CNN and ViT blocks to learn local and global information, as well as the novel
Pooling block of searchable pooling layers for efficient feature map reduction.
Experimental results on the CIFAR10 dataset show that our proposed search space
can produce hybrid CNN-ViT architectures with superior accuracy and inference
speed to ResNet-based tinyML models under tight model size constraints.

</details>


### [7] [SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics](https://arxiv.org/abs/2511.02996)
*Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal*

Main category: cs.CV

TL;DR: SCALE-VLP是一个用于处理3D医学影像（如CT）的视觉-语言预训练框架，它通过结合三维空间信息和领域知识，实现了在有限监督下的结构一致和语义相关的表示学习，并在检索、报告生成和分类等任务上取得了显著的性能提升，同时展现了良好的跨任务和跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）在处理3D医学影像时存在局限，它们通常将3D扫描视为独立的2D切片，忽略了空间连贯性和丰富的临床语义，并且依赖于二元监督信号。

Method: SCALE-VLP是一个软加权对比学习框架，它整合了（i）三维空间语义以保持解剖结构，以及（ii）领域感知、知识注入的语义（例如放射学本体），以指导对齐。

Result: SCALE-VLP在CT报告检索方面取得了高达4.3倍的Top-1性能提升，异常分类提高了10个百分点，报告生成达到了ROUGE-L 0.44和BERT-F1 0.89。此外，在外部数据集的零样本评估中，SCALE-VLP也表现出了一致的性能提升。

Conclusion: SCALE-VLP框架通过整合三维空间语义和领域知识，能够生成结构一致且语义相关的表示，在有限监督下实现了优越的跨任务迁移能力和跨领域泛化能力，克服了现有方法的局限性。

Abstract: Vision-language models (VLMs) have demonstrated strong cross-modal
capabilities, yet most work remains limited to 2D data and assumes binary
supervision (i.e., positive vs. negative pairs), overlooking the continuous and
structured dependencies present in volumetric data such as CT. Existing
approaches often treat volumetric scans as independent 2D slices, compromising
spatial coherence and underutilizing rich clinical semantics. We propose
SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework
that integrates (i) volumetric spatial semantics to preserve anatomical
structure and (ii) domain-aware, knowledge-infused semantics (e.g.,
radiological ontologies) to guide alignment. This yields structurally
consistent and semantically grounded representations under limited supervision,
demonstrating strong cross-task transferability (retrieval, report generation,
and classification), and cross-domain generalizability with consistent gains
without further fine-tuning. In particular, compared to the previous state of
the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,
improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and
BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an
out-of-domain external dataset, we observe consistent gains, indicating the
cross-task and cross-domain generalization ability of SCALE-VLP.

</details>


### [8] [Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning](https://arxiv.org/abs/2511.03004)
*Dakota Hester,Vitor S. Martins,Lucas B. Ferreira,Thainara M. A. Lima*

Main category: cs.CV

TL;DR: 本研究提出了一种利用自监督深度学习和少量标注数据进行大规模土地覆盖分类的新方法，在密西西比州实现了87.14%的总体准确率。


<details>
  <summary>Details</summary>
Motivation: 大规模高分辨率土地覆盖分类面临标注数据量大、成本高的问题。本研究旨在解决这一挑战。

Method: 首先，使用“Bootstrap Your Own Latent”自监督学习策略和大量的无标注高分辨率遥感影像预训练ResNet-101编码器。然后，将预训练的编码器迁移到多个深度语义分割模型（FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN），并使用极小量的标注数据（250、500、750个样本）进行微调。最后，通过交叉验证选择最优模型进行集成。

Result: 在密西西比州实现了1米分辨率、8分类的土地覆盖分类，总体准确率达到87.14%，宏观F1分数达到75.58%，覆盖超过1230亿像素。研究表明，该方法能准确绘制水体和森林区域，但在农田、草地和裸地之间的区分上存在挑战。

Conclusion: 自监督学习是一种有效的策略，可以减少对大量手动标注数据的需求，从而解决了大规模高分辨率土地覆盖制图的主要限制。

Abstract: Deep learning semantic segmentation methods have shown promising performance
for very high 1-m resolution land cover classification, but the challenge of
collecting large volumes of representative training data creates a significant
barrier to widespread adoption of such models for meter-scale land cover
mapping over large areas. In this study, we present a novel label-efficient
approach for statewide 1-m land cover classification using only 1,000 annotated
reference image patches with self-supervised deep learning. We use the
"Bootstrap Your Own Latent" pre-training strategy with a large amount of
unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to
pre-train a ResNet-101 convolutional encoder. The learned encoder weights were
subsequently transferred into multiple deep semantic segmentation architectures
(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then
fine-tuned using very small training dataset sizes with cross-validation (250,
500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall
accuracy and 75.58% macro F1 score using an ensemble of the best performing
U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more
than 123 billion pixels over the state of Mississippi, USA. Detailed
qualitative and quantitative analysis revealed accurate mapping of open water
and forested areas, while highlighting challenges in accurate delineation
between cropland, herbaceous, and barren land cover types. These results show
that self-supervised learning is an effective strategy for reducing the need
for large volumes of manually annotated data, directly addressing a major
limitation to high spatial resolution land cover mapping at scale.

</details>


### [9] [A Foundation Model for Brain MRI with Dynamic Modality Integration](https://arxiv.org/abs/2511.03014)
*Minh Sao Khue Luu,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 该研究提出了一个能够处理不同脑部MRI序列组合的 foundation model，通过共享编码器、可学习的模态嵌入、条件层归一化和考虑缺失模态的掩码自编码目标来实现。


<details>
  <summary>Details</summary>
Motivation: 为脑部MRI分析开发一个灵活且通用的 foundation model，以克服传统方法需要针对不同模态或模态组合训练单独模型的局限性，并能处理序列缺失或未见的情况。

Method: 模型采用单一编码器，结合可学习的模态嵌入、条件层归一化和掩码自编码目标。为了稳定特征学习和增强表示多样性，还应用了方差-协方差正则化器。训练数据包含约60,000个多中心MRI扫描，利用自监督重建和模态填充技术进行训练。可学习的模态嵌入用于指导特征提取，使编码器能够适应不同输入。

Result: 初步结果表明该方法可行，但具体性能的详细研究仍在计划中。模型在处理不同模态组合和缺失模态方面表现出灵活性。

Conclusion: 该 foundation model 为脑部MRI分析提供了一个统一的框架，通过其自适应能力和对缺失模态的处理能力，有望在多种下游任务中（如脑肿瘤和多发性硬化症分割、病灶分类）发挥重要作用。

Abstract: We present a foundation model for brain MRI that can work with different
combinations of imaging sequences. The model uses one encoder with learnable
modality embeddings, conditional layer normalization, and a masked autoencoding
objective that accounts for missing modalities. A variance-covariance
regularizer is applied to stabilize feature learning and improve representation
diversity. This design removes the need for separate models for each modality
and allows the network to adapt when some sequences are missing or unseen. It
is trained on about 60,000 multi-center MRIs using self-supervised
reconstruction and modality imputation to learn flexible representations. A
learnable modality embedding guides feature extraction so the encoder can
adjust to different inputs. We describe our planned evaluation on brain tumor
and multiple sclerosis segmentation, as well as lesion classification, under
various modality settings. Preliminary results show that the method works
feasibly, and further experiments are planned to study its performance in more
detail. All code and pretrained models are available at
https://github.com/BrainFM/brainfm

</details>


### [10] [SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment](https://arxiv.org/abs/2511.03019)
*Wenbo Lu*

Main category: cs.CV

TL;DR: SLIP通过引入结构对比损失来建模实体间的关系，并在大规模产品图谱数据集上进行训练，以提高跨模态检索和分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言预训练方法主要依赖于扩大训练数据规模，而忽视了图像-文本对中固有的丰富关系结构（如电商产品共购图谱）。

Method: SLIP整合了结构对比损失，在对齐模态的同时，还对结构图中邻近实体间的关系进行建模。为此，研究者构建了一个大规模的亚马逊产品共购多模态图数据集，以便大规模地进行结构化跨模态监督。

Result: 实验结果表明，SLIP在零样本和少样本的跨模态检索和分类任务上，始终优于CLIP，证明了关系监督在跨模态对齐方面的价值。

Conclusion: 通过整合结构化信息和对比学习，SLIP能够更有效地进行跨模态理解，尤其是在具有丰富关系结构的数据集上。

Abstract: Vision-Language Pretraining (VLP) has achieved remarkable success across
various downstream tasks, but such gains are largely driven by scaling up on
training data. Yet, literature methods treat image-text pairs as isolated
training examples; this neglects the rich relational structure naturally
present in many domains, such as e-commerce product co-purchase graphs and
social recommendation networks. Inspired by neuroscientific evidence that human
encodes knowledge as relationship cognitive maps, we introduce Structure-aware
Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive
loss to align modalities while also modeling relationships between neighboring
entities in a structured graph. To support this paradigm, we construct a
large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling
structured cross-modality supervision at scale. Experiment results show that
SLIP consistently outperforms CLIP on cross-modal retrieval and classification
tasks in both zero-shot and few-shot settings, showing the value of relational
supervision for cross-modal alignment.

</details>


### [11] [From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth](https://arxiv.org/abs/2511.03053)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 本研究提出了一种基于学习的框架，用于评估移动激光扫描点云的不确定性，无需地面真值，并证明了不确定性是可学习的。


<details>
  <summary>Details</summary>
Motivation: 在Scan-to-BIM、形变分析和3D建模等高精度应用中，评估移动激光扫描（MLS）点云的不确定性对于其可靠使用至关重要。然而，在许多实际应用中，获取用于评估的地面真值（GT）成本高昂且不可行。

Method: 提出了一种集成最优邻域估计和几何特征提取的、用于MLS点云的学习框架。

Result: 在真实数据集上的实验表明，所提出的框架是可行的，并且XGBoost模型在提供与随机森林完全相当的精度的情况下，效率显著提高（快约3倍），初步证明了几何特征可用于预测由C2C距离量化的点级不确定性。

Conclusion: 本研究表明，MLS点云的不确定性是可学习的，为不确定性评估研究提供了一个新颖的、基于学习的视角。

Abstract: Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning
(MLS) point clouds in many high-precision applications such as Scan-to-BIM,
deformation analysis, and 3D modeling. However, obtaining the ground truth (GT)
for evaluation is often costly and infeasible in many real-world applications.
To reduce this long-standing reliance on GT in uncertainty evaluation research,
this study presents a learning-based framework for MLS point clouds that
integrates optimal neighborhood estimation with geometric feature extraction.
Experiments on a real-world dataset show that the proposed framework is
feasible and the XGBoost model delivers fully comparable accuracy to Random
Forest while achieving substantially higher efficiency (about 3 times faster),
providing initial evidence that geometric features can be used to predict
point-level uncertainty quantified by the C2C distance. In summary, this study
shows that MLS point clouds' uncertainty is learnable, offering a novel
learning-based viewpoint towards uncertainty evaluation research.

</details>


### [12] [ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly](https://arxiv.org/abs/2511.03098)
*Miftahur Rahman,Samuel Adebayo,Dorian A. Acevedo-Mejia,David Hester,Daniel McPolin,Karen Rafferty,Debra F. Laefer*

Main category: cs.CV

TL;DR: 该研究介绍了ISC-Perception数据集，这是一个用于机器人钢结构连接（ISC）组件检测的混合数据集，结合了程序生成、游戏引擎渲染和真实照片，以解决建筑工地数据收集的挑战。该数据集通过自动化标注大幅减少了人工成本，并显著提高了训练出的检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 建筑工地上手动装配钢结构存在效率低下和安全隐患，而用于实现自动化装配的机器人感知技术缺乏专门的数据集支持，手动收集数据又面临诸多困难。

Method: 研究人员构建了一个名为ISC-Perception的混合数据集，其中包含程序渲染的CAD图像、游戏引擎生成的光照逼真场景以及少量真实照片。该数据集能够对合成部分进行全自动标注，并详细记录了数据集生成过程中的人力投入，包括模拟引擎设置、资源准备、后处理脚本和质量检查等。

Result: 在ISC-Perception数据集上训练的检测器在mAP@0.50指标上达到了0.756，显著优于仅使用合成数据或仅使用照片数据的模型。在一个1200帧的基准测试中，报告的mAP@0.50/mAP@[0.50:0.95]分别为0.943/0.823。与手动标注相比，生成10,000张图像的数据集所需的人工时间减少了81.7%。

Conclusion: ISC-Perception数据集通过提供一个包含合成和真实数据的混合数据集，弥合了建筑机器人感知领域的数据鸿沟，能够加速定制目标检测器的开发，并促进研究和工业应用。

Abstract: The Intermeshed Steel Connection (ISC) system, when paired with robotic
manipulators, can accelerate steel-frame assembly and improve worker safety by
eliminating manual assembly. Dependable perception is one of the initial stages
for ISC-aware robots. However, this is hampered by the absence of a dedicated
image corpus, as collecting photographs on active construction sites is
logistically difficult and raises safety and privacy concerns. In response, we
introduce ISC-Perception, the first hybrid dataset expressly designed for ISC
component detection. It blends procedurally rendered CAD images, game-engine
photorealistic scenes, and a limited, curated set of real photographs, enabling
fully automatic labelling of the synthetic portion. We explicitly account for
all human effort to produce the dataset, including simulation engine and scene
setup, asset preparation, post-processing scripts and quality checks; our total
human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for
manual labelling at 60,s per image (-81.7%). A manual pilot on a representative
image with five instances of ISC members took 60,s (maximum 80,s), anchoring
the manual baseline. Detectors trained on ISC-Perception achieved a mean
Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained
on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we
report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for
construction-robotics perception, ISC-Perception facilitates rapid development
of custom object detectors and is freely available for research and industrial
use upon request.

</details>


### [13] [DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs](https://arxiv.org/abs/2511.03099)
*Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: DentalSplat使用3D高斯泼溅技术，通过结合密集立体重建、自适应剪枝和光流约束，解决了正畸影像稀疏导致的重建质量下降问题，并在大规模数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了在远程正畸治疗中从多个视角观察患者的牙合 ज्यामुळे及时做出临床决策，但现有的3D高斯泼溅技术通常需要密集的多视角输入和精确的相机位姿，这在仅有三张稀疏图像的正畸案例中难以实现。

Method: DentalSplat框架首先使用先验引导的密集立体重建模型来初始化点云，然后采用自适应剪枝策略来提高3D高斯泼溅的训练效率和重建质量。在极稀疏视角的情况下，额外引入光流作为几何约束，并结合梯度正则化来提升渲染保真度。

Result: 在包含950个临床病例的大规模数据集和195个模拟远程正畸成像条件的视频测试集上进行了验证，DentalSplat在稀疏输入场景下表现优异，并在牙合可视化方面实现了比最先进技术更高质量的新视角合成。

Conclusion: DentalSplat成功解决了稀疏正畸影像的3D重建难题，显著提高了牙合可视化的质量，为远程正畸治疗提供了有效支持。

Abstract: In orthodontic treatment, particularly within telemedicine contexts,
observing patients' dental occlusion from multiple viewpoints facilitates
timely clinical decision-making. Recent advances in 3D Gaussian Splatting
(3DGS) have shown strong potential in 3D reconstruction and novel view
synthesis. However, conventional 3DGS pipelines typically rely on densely
captured multi-view inputs and precisely initialized camera poses, limiting
their practicality. Orthodontic cases, in contrast, often comprise only three
sparse images, specifically, the anterior view and bilateral buccal views,
rendering the reconstruction task especially challenging. The extreme sparsity
of input views severely degrades reconstruction quality, while the absence of
camera pose information further complicates the process. To overcome these
limitations, we propose DentalSplat, an effective framework for 3D
reconstruction from sparse orthodontic imagery. Our method leverages a
prior-guided dense stereo reconstruction model to initialize the point cloud,
followed by a scale-adaptive pruning strategy to improve the training
efficiency and reconstruction quality of 3DGS. In scenarios with extremely
sparse viewpoints, we further incorporate optical flow as a geometric
constraint, coupled with gradient regularization, to enhance rendering
fidelity. We validate our approach on a large-scale dataset comprising 950
clinical cases and an additional video-based test set of 195 cases designed to
simulate real-world remote orthodontic imaging conditions. Experimental results
demonstrate that our method effectively handles sparse input scenarios and
achieves superior novel view synthesis quality for dental occlusion
visualization, outperforming state-of-the-art techniques.

</details>


### [14] [Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning](https://arxiv.org/abs/2511.03120)
*Botong. Zhao,Xubin. Wang,Shujing. Lyu,Yue. Lu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为IC DefectNCD的无监督框架，用于集成电路（IC）的缺陷检测和新类别发现。该框架利用图像内在先验，通过自监督学习方法，解决了传统监督方法需要大量标注数据和无监督方法性能不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 集成电路制造过程复杂，容易出现各种缺陷，导致良率损失和产品可靠性下降。传统的监督学习方法在处理新兴和罕见的缺陷类别时面临数据稀疏和人工标注成本高昂的挑战，而无监督方法则可能因为缺少先验知识而导致性能不稳定。因此，需要一种无需大量标注数据且性能鲁棒的缺陷检测方法。

Method: IC DefectNCD框架首先采用自监督信息引导的缺陷检测方法，通过可学习的提取器聚合代表性正常特征，并利用重构残差来粗略定位缺陷区域。为了处理不同缺陷的显著性差异，该方法引入了一种自适应二值化策略，以生成聚焦于核心缺陷区域的稳定子图像。最后，采用自监督缺陷信息引导的缺陷分类方法，结合软掩码引导的注意力机制，将空间缺陷先验注入到教师-学生模型中，增强了对缺陷区域的敏感性，抑制了背景干扰，从而实现了对未见过的缺陷的识别和分类。

Result: 该方法在包含三个关键制造阶段和15种缺陷类型的真实世界数据集上进行了验证，实验结果表明该方法在缺陷检测和未见缺陷分类方面均表现出鲁棒的性能。

Conclusion: IC DefectNCD框架通过利用图像内在先验和自监督学习，能够有效地进行集成电路缺陷检测和新类别发现，解决了传统方法的局限性，并在真实世界数据上取得了优异的性能。

Abstract: Integrated circuit manufacturing is highly complex, comprising hundreds of
process steps. Defects can arise at any stage, causing yield loss and
ultimately degrading product reliability. Supervised methods require extensive
human annotation and struggle with emergent categories and rare, data scarce
defects. Clustering-based unsupervised methods often exhibit unstable
performance due to missing priors. We propose IC DefectNCD, a support set free
framework that leverages Image Intrinsic Priors in IC SEM images for defect
detection and novel class discovery. We first develop Self Normal Information
Guided IC Defect Detection, aggregating representative normal features via a
learnable normal information extractor and using reconstruction residuals to
coarsely localize defect regions. To handle saliency variations across defects,
we introduce an adaptive binarization strategy that produces stable subimages
focused on core defective areas. Finally, we design Self Defect Information
Guided IC Defect Classification, which incorporates a soft mask guided
attention mechanism to inject spatial defect priors into the teacher student
model. This enhances sensitivity to defective regions, suppresses background
interference, and enables recognition and classification of unseen defects. We
validate the approach on a real world dataset spanning three key fabrication
stages and covering 15 defect types. Experiments demonstrate robust performance
on both defect detection and unseen defect classification.

</details>


### [15] [Accelerating Physical Property Reasoning for Augmented Visual Cognition](https://arxiv.org/abs/2511.03126)
*Hongbo Lan,Zhenlin An,Haoyu Li,Vaibhav Singh,Longfei Shangguan*

Main category: cs.CV

TL;DR: 该系统名为\sysname，通过算法和系统优化（如快速3D重建、高效语义特征融合、并行视图编码）将视觉引导的物理属性推理延迟从10-20分钟缩短至6秒以内，在保持准确性的同时，在材料分割和体素级推理方面表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 加速视觉引导的物理属性推理，以支持增强的视觉认知。

Method: 通过快速的几何3D重建、高效的语义特征融合和并行视图编码等算法和系统优化来最小化推理管线的运行时间延迟。

Result: \sysname 将端到端延迟从10-20分钟缩短至6秒以内，实现了62.9倍-287.2倍的加速，同时在物体级物理属性估计准确性（如质量）方面达到相当水平（有时甚至更好），并在材料分割和体素级推理方面优于两个SOTA基线。

Conclusion: \sysname 成功实现了显著的性能提升，同时保持了准确性，并通过与注视跟踪的结合，在现实世界环境中（如宜家家具店）的智能眼镜上实现了简化的物理属性推理，即使在视图较少的情况下也能提供稳健的属性估计。

Abstract: This paper introduces \sysname, a system that accelerates vision-guided
physical property reasoning to enable augmented visual cognition. \sysname
minimizes the run-time latency of this reasoning pipeline through a combination
of both algorithmic and systematic optimizations, including rapid geometric 3D
reconstruction, efficient semantic feature fusion, and parallel view encoding.
Through these simple yet effective optimizations, \sysname reduces the
end-to-end latency of this reasoning pipeline from 10--20 minutes to less than
6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname
achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching
on-par (and sometimes slightly better) object-level physical property
estimation accuracy(e.g. mass), but also demonstrating superior performance in
material segmentation and voxel-level inference than two SOTA baselines. We
further combine gaze-tracking with \sysname to localize the object of interest
in cluttered, real-world environments, streamlining the physical property
reasoning on smart glasses. The case study with Meta Aria Glasses conducted at
an IKEA furniture store demonstrates that \sysname achives consistently high
performance compared to controlled captures, providing robust property
estimations even with fewer views in real-world scenarios.

</details>


### [16] [Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response](https://arxiv.org/abs/2511.03132)
*Thomas Manzini,Priyankari Perali,Robin R. Murphy*

Main category: cs.CV

TL;DR: 该研究提出了首个用于自动化评估无人机（sUAS）影像中建筑物损坏的人工智能/机器学习系统，并已在联邦宣布的灾难（飓风黛比和海伦）期间投入实际使用。


<details>
  <summary>Details</summary>
Motivation: 在重大灾难响应中，无人机收集的影像数据量巨大（每天47GB至369GB），超出了专家实时处理能力，导致响应延迟。此前在卫星影像损坏评估方面已有研究，但无人机影像评估系统仍处于学术阶段，缺乏实际应用。

Method: 开发并部署了用于建筑物损坏评估的无人机影像模型。该模型在包含21,716个建筑物损坏标签的最大规模灾后无人机航空影像数据集上进行训练，并对91名灾害处理人员进行了操作培训。在飓风黛比和海伦的响应过程中，部署了性能最佳的模型，在约18分钟内评估了415座建筑物。

Result: 成功将人工智能/机器学习系统应用于实际灾难响应中，显著提高了建筑物损坏评估的效率，在短时间内处理了大量数据。

Conclusion: 该工作记录了人工智能/机器学习在灾害期间用于损坏评估的实际应用案例，并总结了经验教训，为人工智能/机器学习研究和用户社区提供了宝贵的参考。

Abstract: This paper presents the first AI/ML system for automating building damage
assessment in uncrewed aerial systems (sUAS) imagery to be deployed
operationally during federally declared disasters (Hurricanes Debby and
Helene). In response to major disasters, sUAS teams are dispatched to collect
imagery of the affected areas to assess damage; however, at recent disasters,
teams collectively delivered between 47GB and 369GB of imagery per day,
representing more imagery than can reasonably be transmitted or interpreted by
subject matter experts in the disaster scene, thus delaying response efforts.
To alleviate this data avalanche encountered in practice, computer vision and
machine learning techniques are necessary. While prior work has been deployed
to automatically assess damage in satellite imagery, there is no current state
of practice for sUAS-based damage assessment systems, as all known work has
been confined to academic settings. This work establishes the state of practice
via the development and deployment of models for building damage assessment
with sUAS imagery. The model development involved training on the largest known
dataset of post-disaster sUAS aerial imagery, containing 21,716 building damage
labels, and the operational training of 91 disaster practitioners. The best
performing model was deployed during the responses to Hurricanes Debby and
Helene, where it assessed a combined 415 buildings in approximately 18 minutes.
This work contributes documentation of the actual use of AI/ML for damage
assessment during a disaster and lessons learned to the benefit of the AI/ML
research and user communities.

</details>


### [17] [Finetuning-Free Personalization of Text to Image Generation via Hypernetworks](https://arxiv.org/abs/2511.03156)
*Sagar Shrestha,Gopal Sharma,Luowei Zhou,Suren Kumar*

Main category: cs.CV

TL;DR: 通过使用Hypernetworks直接从主题图像预测LoRA权重的微调免费个性化方法，无需在测试时进行每个主题的优化，并提高了模型的可扩展性和有效性。


<details>
  <summary>Details</summary>
Motivation: 个性化文本到图像扩散模型通常依赖于计算成本高且推理速度慢的特定主题微调方法。虽然一些较新方法试图降低这种开销，但它们仍然需要额外的微调或大型骨干模型。

Method: 本文提出了一种新的方法，通过Hypernetworks直接从主题图像预测LoRA适应的权重，实现了微调免费的个性化。该方法采用端到端的训练目标，并通过简单的输出正则化进行稳定，从而产生可靠有效的Hypernetworks。此外，还引入了混合模型类别无关引导（HM-CFG）来提高推理时的组合泛化能力。

Result: 该方法消除了对测试时每个主题进行优化的需求，同时保持了主题的保真度和提示的对齐性。实验证明，该方法在CelebA-HQ、AFHQ-v2和DreamBench上取得了强大的个性化性能。

Conclusion: Hypernetworks为开放类别个性化提供了一个可扩展且有效的方向。

Abstract: Personalizing text-to-image diffusion models has traditionally relied on
subject-specific fine-tuning approaches such as
DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and
slow at inference. Recent adapter- and encoder-based methods attempt to reduce
this overhead but still depend on additional fine-tuning or large backbone
models for satisfactory results. In this work, we revisit an orthogonal
direction: fine-tuning-free personalization via Hypernetworks that predict
LoRA-adapted weights directly from subject images. Prior hypernetwork-based
approaches, however, suffer from costly data generation or unstable attempts to
mimic base model optimization trajectories. We address these limitations with
an end-to-end training objective, stabilized by a simple output regularization,
yielding reliable and effective hypernetworks. Our method removes the need for
per-subject optimization at test time while preserving both subject fidelity
and prompt alignment. To further enhance compositional generalization at
inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),
which combines the compositional strengths of the base diffusion model with the
subject fidelity of personalized models during sampling. Extensive experiments
on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves
strong personalization performance and highlights the promise of hypernetworks
as a scalable and effective direction for open-category personalization.

</details>


### [18] [Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation](https://arxiv.org/abs/2511.03163)
*Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 通过结合RGB和深度信息，并使用SRFT-GaLore高效适配SAM2模型，提出了一种改进的肝脏解剖结构分割方法，在公开数据集和新构建的LLSD数据集上均表现出优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提高腹腔镜肝脏手术中解剖结构检测的准确性，克服2D视频流的深度感知限制和地标定位困难，并解决现有方法融合RGB和深度特征以及适应手术领域模型的效率问题。

Method: 提出了一种深度引导的肝脏地标分割框架，该框架利用SAM2提取RGB特征，DA2提取深度特征。为高效适配SAM2，引入了SRFT-GaLore，一种低秩梯度投影方法，用SRFT替代SVD以实现高效微调。采用交叉注意力融合模块整合RGB和深度线索。构建了LLSD数据集以进行跨数据集泛化评估。

Result: 在L3D数据集上，与D2GPLand相比，Dice相似系数提高了4.85%，平均对称表面距离降低了11.78点。在LLSD数据集上，该模型表现出强大的跨数据集鲁棒性和对未见手术环境的适应性，显著优于基于SAM的基线模型。

Conclusion: SRFT-GaLore增强的双编码器框架能够在实时、深度受限的手术环境中实现可扩展且精确的分割。

Abstract: Accurate detection and delineation of anatomical structures in medical
imaging are critical for computer-assisted interventions, particularly in
laparoscopic liver surgery where 2D video streams limit depth perception and
complicate landmark localization. While recent works have leveraged monocular
depth cues for enhanced landmark detection, challenges remain in fusing RGB and
depth features and in efficiently adapting large-scale vision models to
surgical domains. We propose a depth-guided liver landmark segmentation
framework integrating semantic and geometric cues via vision foundation
encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
projection method that replaces the computationally expensive SVD with a
Subsampled Randomized Fourier Transform (SRFT). This enables efficient
fine-tuning of high-dimensional attention layers without sacrificing
representational power. A cross-attention fusion module further integrates RGB
and depth cues. To assess cross-dataset generalization, we also construct a new
Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
On the public L3D dataset, our method achieves a 4.85% improvement in Dice
Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
Distance compared to the D2GPLand. To further assess generalization capability,
we evaluate our model on LLSD dataset. Our model maintains competitive
performance and significantly outperforms SAM-based baselines, demonstrating
strong cross-dataset robustness and adaptability to unseen surgical
environments. These results demonstrate that our SRFT-GaLore-enhanced
dual-encoder framework enables scalable and precise segmentation under
real-time, depth-constrained surgical settings.

</details>


### [19] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 该研究提出了PitVQA-Anticipation数据集和SurgAnt-ViVQA模型，用于预测内鼻蝶窦手术中的未来事件，提升了手术VQA系统的预测能力。


<details>
  <summary>Details</summary>
Motivation: 内鼻蝶窦手术中，实时预测手术事件对于提供辅助至关重要，但现有VQA系统和数据集主要关注当前场景，缺乏对未来步骤或所需器械的预测能力。

Method: 提出PitVQA-Anticipation数据集，包含33.5小时视频和734,769个问答对，涵盖未来阶段、下一步、即将使用的器械和剩余时间四个任务。同时提出SurgAnt-ViVQA模型，该模型通过GRU门控时间交叉注意力模块适配大语言模型，利用双向GRU编码帧间动态，并通过自适应门控将视觉信息注入语言流，同时采用参数高效微调适应手术领域。

Result: SurgAnt-ViVQA在PitVQA-Anticipation和EndoVis数据集上表现优于现有的基于图像和视频的基线模型。消融实验表明，时间递归和门控融合是提升性能的关键。帧数研究显示，8帧能最大化流畅度，而32帧在略微降低BLEU分数的同时能提高数值时间估计的准确性。

Conclusion: SurgAnt-ViVQA模型通过结合时间感知编码器和细粒度门控交叉注意力，将手术VQA从回顾性描述提升到前瞻性预测。PitVQA-Anticipation数据集为这一新领域提供了全面的基准，并强调了针对性时间建模对于可靠、面向未来的手术辅助的重要性。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [20] [PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research](https://arxiv.org/abs/2511.03194)
*Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao*

Main category: cs.CV

TL;DR: 该研究介绍了PETWB-REP数据集，一个包含490名患有多种癌症的患者的全身18F-FDG PET/CT扫描和放射学报告的数据集。


<details>
  <summary>Details</summary>
Motivation: 公开、大规模的医学成像数据集对于开发和验证人工智能模型以及进行回顾性临床研究至关重要，但结合了功能和解剖成像以及多癌种详细临床报告的数据集仍然稀缺。

Method: 构建了一个包含490名患有多种恶性肿瘤的患者的全身18F-FDG PET/CT扫描和相应放射学报告的PETWB-REP数据集。数据集主要包括肺癌、肝癌、乳腺癌、前列腺癌和卵巢癌等常见癌症，并包含配对的PET和CT图像、去标识化的文本报告和结构化的临床元数据。

Result: PETWB-REP数据集包含配对的PET和CT图像、去标识化的文本报告和结构化的临床元数据。

Conclusion: PETWB-REP数据集旨在支持医学成像、放射组学、人工智能和多模态学习等领域的研究。

Abstract: Publicly available, large-scale medical imaging datasets are crucial for
developing and validating artificial intelligence models and conducting
retrospective clinical research. However, datasets that combine functional and
anatomical imaging with detailed clinical reports across multiple cancer types
remain scarce. Here, we present PETWB-REP, a curated dataset comprising
whole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed
Tomography (PET/CT) scans and corresponding radiology reports from 490 patients
diagnosed with various malignancies. The dataset primarily includes common
cancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and
ovarian cancer. This dataset includes paired PET and CT images, de-identified
textual reports, and structured clinical metadata. It is designed to support
research in medical imaging, radiomics, artificial intelligence, and
multi-modal learning.

</details>


### [21] [QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models](https://arxiv.org/abs/2511.03206)
*Kuei-Chun Kao,Hsu Tzu-Yin,Yunqi Hong,Ruochen Wang,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 现有的大型多模态模型在处理多图像时存在感知和推理能力不足的问题。本文提出了一个名为QG-CoC的新型零样本提示方法，用于解决多图像理解的挑战，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型多模态模型在处理多图像时，在细粒度感知和信息综合推理方面存在的不足，以及现有方法在通用多图像推理任务上的局限性。

Method: 提出一种名为Question-Guided Chain-of-Captions (QG-CoC) 的新零样本提示方法，该方法能够处理任意数量的图像，并广泛调查了现有提示方法在多图像场景下的表现。

Result: QG-CoC在多图像和单图像基准测试中表现出有竞争力，并在现有方法失效的挑战性场景下取得了显著的改进。

Conclusion: QG-CoC是一种有效的、通用的提示方法，可以显著提高大型多模态模型在处理多图像时的细粒度感知和推理能力。

Abstract: Recently, Multimodal Large Language Models (MLLMs) encounter two key issues
in multi-image contexts: (1) a lack of fine-grained perception across disparate
images, and (2) a diminished capability to effectively reason over and
synthesize information from multiple visual inputs. However, while various
prompting methods aim to describe visual content, many existing studies focus
primarily on single-image settings or specific, constrained scenarios. This
leaves a critical gap in understanding and addressing how MLLMs tackle more
general and complex multi-image reasoning tasks. Thus, we first extensively
investigate how current prompting methods perceive fine-grained visual details
and process visual information when dealing with multiple images. Our findings
reveal that existing prompting methods fall short in attending to needed clues
and seamlessly integrating perception and reasoning. Inspired by the findings,
we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions
(QG-CoC), a generalized prompting approach that effectively handles problems
with an arbitrary number of images. We evaluate our method on various
open-source and closed-source MLLMs for multi-image and single-image
benchmarks. Experimental results indicate that QG-CoC demonstrates competitive
performance across tasks and exhibits robust improvements in the challenging
scenarios where existing prompting methods fail.

</details>


### [22] [MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction](https://arxiv.org/abs/2511.03212)
*Ruting Cheng,Boyuan Feng,Yijiang Zheng,Chuhui Qiu,Aizierjiang Aiersilan,Joaquin A. Calderon,Wentao Zhao,Qing Pan,James K. Hahn*

Main category: cs.CV

TL;DR: 本研究提出了一种名为MvBody的新型多视角Transformer网络，利用3D体型扫描和自述医疗数据，在怀孕31至38周之间预测剖腹产风险，准确率为84.62%，AUC-ROC为0.724，并使用集成梯度法解释了模型决策过程。


<details>
  <summary>Details</summary>
Motivation: 为医疗资源有限的地区开发一种可及的剖腹产（CS）风险评估方法，以改善孕产妇和新生儿结局。

Method: 利用3D体型扫描和自述医疗数据，通过一种新颖的多视角Transformer网络（MvBody）进行CS风险预测，并结合度量学习损失以提高训练效率和模型泛化能力。

Result: MvBody在独立测试集上达到了84.62%的准确率和0.724的AUC-ROC，优于现有模型。研究发现，孕前体重、产妇年龄、产科史、既往CS史以及头部和肩部等身体形状是预测CS风险的关键因素。

Conclusion: 提出的MvBody模型能够准确预测剖腹产风险，并且通过集成梯度法提供了模型决策的解释，有助于提高模型的可信度。该方法在医疗资源有限的环境中具有应用潜力。

Abstract: Accurately assessing the risk of cesarean section (CS) delivery is critical,
especially in settings with limited medical resources, where access to
healthcare is often restricted. Early and reliable risk prediction allows
better-informed prenatal care decisions and can improve maternal and neonatal
outcomes. However, most existing predictive models are tailored for in-hospital
use during labor and rely on parameters that are often unavailable in
resource-limited or home-based settings. In this study, we conduct a pilot
investigation to examine the feasibility of using 3D body shape for CS risk
assessment for future applications with more affordable general devices. We
propose a novel multi-view-based Transformer network, MvBody, which predicts CS
risk using only self-reported medical data and 3D optical body scans obtained
between the 31st and 38th weeks of gestation. To enhance training efficiency
and model generalizability in data-scarce environments, we incorporate a metric
learning loss into the network. Compared to widely used machine learning models
and the latest advanced 3D analysis methods, our method demonstrates superior
performance, achieving an accuracy of 84.62% and an Area Under the Receiver
Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set.
To improve transparency and trust in the model's predictions, we apply the
Integrated Gradients algorithm to provide theoretically grounded explanations
of the model's decision-making process. Our results indicate that pre-pregnancy
weight, maternal age, obstetric history, previous CS history, and body shape,
particularly around the head and shoulders, are key contributors to CS risk
prediction.

</details>


### [23] [OmniVLA: Unifiying Multi-Sensor Perception for Physically-Grounded Multimodal VLA](https://arxiv.org/abs/2511.01210)
*Heyu Guo,Shanmu Wang,Ruichun Ma,Shiqi Jiang,Yasaman Ghasempour,Omid Abari,Baining Guo,Lili Qi*

Main category: cs.CV

TL;DR: OmniVLA是一个集成了红外相机、毫米波雷达和麦克风阵列等多种传感模态的视觉-语言-动作（VLA）模型，通过传感器掩码图像统一表示，显著提高了机器人在需要多传感器感知的物理空间操作任务中的成功率、学习效率和泛化能力，超越了仅使用RGB或原始传感器输入的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖RGB相机，感知能力受限，影响了操作能力。本研究旨在通过整合多种传感模态来增强VLA模型的空间感知和操作能力。

Method: 提出了一种名为OmniVLA的多模态VLA模型，其核心是传感器掩码图像（sensor-masked image），将来自红外相机、毫米波雷达和麦克风阵列的传感器信息与RGB图像融合。该模型基于RGB预训练的VLA骨干网络进行训练。

Result: OmniVLA在需要传感器感知的现实世界操作任务中取得了84%的平均任务成功率，显著优于仅使用RGB（高59%）和原始传感器输入（高28%）的基线模型，并表现出更高的学习效率和泛化能力。

Conclusion: OmniVLA通过整合多种传感模态，超越了仅依赖RGB的传统VLA模型，为实现更强大的物理空间智能和机器人操作提供了有效的解决方案。

Abstract: Vision-language-action (VLA) models have shown strong generalization for
action prediction through large-scale vision-language pretraining. However,
most existing models rely solely on RGB cameras, limiting their perception and,
consequently, manipulation capabilities. We present OmniVLA, an omni-modality
VLA model that integrates novel sensing modalities for physically-grounded
spatial intelligence beyond RGB perception. The core of our approach is the
sensor-masked image, a unified representation that overlays spatially grounded
and physically meaningful masks onto the RGB images, derived from sensors
including an infrared camera, a mmWave radar, and a microphone array. This
image-native unification keeps sensor input close to RGB statistics to
facilitate training, provides a uniform interface across sensor hardware, and
enables data-efficient learning with lightweight per-sensor projectors. Built
on this, we present a multisensory vision-language-action model architecture
and train the model based on an RGB-pretrained VLA backbone. We evaluate
OmniVLA on challenging real-world tasks where sensor-modality perception is
needed to guide the manipulation. OmniVLA achieves an average task success rate
of 84%, significantly outperforms both RGB-only and raw-sensor-input baseline
models by 59% and 28% respectively, meanwhile showing higher learning
efficiency and stronger generalization capability.

</details>


### [24] [Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation](https://arxiv.org/abs/2511.03219)
*Pengyu Jie,Wanquan Liu,Rui He,Yihui Wen,Deyu Meng,Chenqiang Gao*

Main category: cs.CV

TL;DR: 提出了一种新的图像增强范式，结合了扩散模型和混合技术，用于密集预测任务，在多个数据集上实现了最先进的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像增强方法（如样本混合和扩散合成）在鲁棒性、标签清晰度和域适应性方面存在局限性。需要一种能够融合两者优点并克服其缺点的方法。

Method: 提出了一种成对的、由扩散引导的范式。对于每个真实图像，生成一个具有相同掩码的合成对应图像。然后，使用这对图像作为 Mask-Consistent Paired Mixing (MCPMix) 的可控输入，该方法仅混合图像外观，而监督始终使用原始的硬掩码。此外，还引入了 Real-Anchored Learnable Annealing (RLA) 来自适应地调整混合强度和混合样本的损失权重，以减轻分布偏差。

Result: 在Kvasir-SEG、PICCOLO、CVC-ClinicDB、NPC-LES和ISIC 2017等数据集上，该方法实现了最先进的分割性能，并优于基线方法。

Conclusion: 结合标签保留混合、扩散驱动的多样性以及自适应的重新锚定，可以实现稳健且可泛化的内窥镜分割。

Abstract: Augmentation for dense prediction typically relies on either sample mixing or
generative synthesis. Mixing improves robustness but misaligned masks yield
soft label ambiguity. Diffusion synthesis increases apparent diversity but,
when trained as common samples, overlooks the structural benefit of mask
conditioning and introduces synthetic-real domain shift. We propose a paired,
diffusion-guided paradigm that fuses the strengths of both. For each real
image, a synthetic counterpart is generated under the same mask and the pair is
used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which
mixes only image appearance while supervision always uses the original hard
mask. This produces a continuous family of intermediate samples that smoothly
bridges synthetic and real appearances under shared geometry, enlarging
diversity without compromising pixel-level semantics. To keep learning aligned
with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the
mixing strength and the loss weight of mixed samples over training, gradually
re-anchoring optimization to real data and mitigating distributional bias.
Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC
2017, the approach achieves state-of-the-art segmentation performance and
consistent gains over baselines. The results show that combining
label-preserving mixing with diffusion-driven diversity, together with adaptive
re-anchoring, yields robust and generalizable endoscopic segmentation.

</details>


### [25] [Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution](https://arxiv.org/abs/2511.03232)
*Sichen Guo,Wenjie Li,Yuanyang Liu,Guangwei Gao,Jian Yang,Chia-Wen Lin*

Main category: cs.CV

TL;DR: T-PMambaSR是一种轻量级的超分辨率框架，通过结合窗口自注意力与渐进式Mamba，并引入自适应高频细节增强模块（AHFRM），在保持线性计算复杂度的同时，提高了特征表示能力和高频细节恢复效果，优于现有的基于Transformer或Mamba的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Mamba类超分辨率方法在跨尺度建模的精细化过渡方面存在不足，限制了特征表示效率。

Method: 提出T-PMambaSR框架，结合窗口自注意力与渐进式Mamba，实现不同尺度感受野的交互，并引入自适应高频细节增强模块（AHFRM）以恢复高频细节。

Result: T-PMambaSR能够逐步增强模型的感受野和表达能力，相比于现有的基于Transformer或Mamba的方法，在计算成本更低的情况下取得了更好的性能。

Conclusion: T-PMambaSR通过精细化的建模范式，在保持线性计算复杂度的前提下，有效提升了超分辨率性能。

Abstract: Recently, Mamba-based super-resolution (SR) methods have demonstrated the
ability to capture global receptive fields with linear complexity, addressing
the quadratic computational cost of Transformer-based SR approaches. However,
existing Mamba-based methods lack fine-grained transitions across different
modeling scales, which limits the efficiency of feature representation. In this
paper, we propose T-PMambaSR, a lightweight SR framework that integrates
window-based self-attention with Progressive Mamba. By enabling interactions
among receptive fields of different scales, our method establishes a
fine-grained modeling paradigm that progressively enhances feature
representation with linear complexity. Furthermore, we introduce an Adaptive
High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost
during Transformer and Mamba processing. Extensive experiments demonstrate that
T-PMambaSR progressively enhances the model's receptive field and
expressiveness, yielding better performance than recent Transformer- or
Mamba-based methods while incurring lower computational cost. Our codes will be
released after acceptance.

</details>


### [26] [Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning](https://arxiv.org/abs/2511.03245)
*Liwei Luo,Shuaitengyuan Li,Dongwei Ren,Qilong Wang,Pengfei Zhu,Qinghua Hu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DMPO（Decoupled Multi-Predictor Optimization）的新方法，通过解耦早期预测器的低级表示能力和高级判别能力，以提高模型推理效率，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在大型预训练模型调优和推理效率日益重要的背景下，早期退出和多阶段预测器与参数高效微调策略结合，是实现推理高效模型的有效途径。然而，如何让早期阶段在为深层阶段提供低级基本特征的同时，也为早期预测器提供高级判别特征仍然是一个挑战。

Method: 提出DMPO方法，在架构层面引入轻量级旁路模块，将浅层特征与早期预测器功能解耦，并开发基于高阶统计的预测器以增强早期预测器的判别能力。在模型优化层面，提出解耦优化策略，在模型调优过程中采用两阶段损失权重分配，使模型在初始阶段优先获得深层判别能力，后期则将判别能力尽可能转移到早期阶段。

Result: 实验表明，DMPO在多个数据集和预训练骨干网络上，相比于现有方法在降低计算成本的同时，性能更优。

Conclusion: DMPO方法在架构设计和模型优化层面成功解耦了早期阶段的表示能力和判别能力，有效提升了模型的推理效率和性能。

Abstract: Recently, remarkable progress has been made in large-scale pre-trained model
tuning, and inference efficiency is becoming more crucial for practical
deployment. Early exiting in conjunction with multi-stage predictors, when
cooperated with a parameter-efficient fine-tuning strategy, offers a
straightforward way to achieve an inference-efficient model. However, a key
challenge remains unresolved: How can early stages provide low-level
fundamental features to deep stages while simultaneously supplying high-level
discriminative features to early-stage predictors? To address this problem, we
propose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively
decouple the low-level representative ability and high-level discriminative
ability in early stages. First, in terms of architecture, we introduce a
lightweight bypass module into multi-stage predictors for functional
decomposition of shallow features from early stages, while a high-order
statistics-based predictor is developed for early stages to effectively enhance
their discriminative ability. To reasonably train our multi-predictor
architecture, a decoupled optimization is proposed to allocate two-phase loss
weights for multi-stage predictors during model tuning, where the initial
training phase enables the model to prioritize the acquisition of
discriminative ability of deep stages via emphasizing representative ability of
early stages, and the latter training phase drives discriminative ability
towards earlier stages as much as possible. As such, our DMPO can effectively
decouple representative and discriminative abilities in early stages in terms
of architecture design and model optimization. Experiments across various
datasets and pre-trained backbones demonstrate that DMPO clearly outperforms
its counterparts when reducing computational cost.

</details>


### [27] [Generative deep learning for foundational video translation in ultrasound](https://arxiv.org/abs/2511.03255)
*Nikolina Tomic Roshni Bhatnagar,Sarthak Jain,Connor Lau,Tien-Yu Liu,Laura Gambini,Rima Arnaout*

Main category: cs.CV

TL;DR: 提出了一种用于超声心动图灰度图像和彩色多普勒血流图像之间相互转换的生成模型，解决了临床研究中数据不平衡的问题，生成的图像在下游的深度学习任务和临床医生评估中均表现出与真实图像相当的性能。


<details>
  <summary>Details</summary>
Motivation: 临床研究中的超声心动图数据存在数据不平衡和缺失问题，特别是灰度图像和彩色多普勒血流图像（CFD）之间的数据量差异。图像转换技术可以帮助平衡数据集，但目前超声心动图子模态之间的图像转换仍具挑战性。

Method: 提出了一种基于生成对抗网络（GAN）的图像转换方法，利用像素级损失、对抗性损失和感知损失。该方法包含两个网络：一个用于重建解剖结构，另一个用于去噪，以生成逼真的超声心动图。模型在54,975个视频上训练，在8,368个视频上测试。

Result: 生成的合成视频与真实视频之间的平均成对结构相似性（SSIM）为0.91+/-0.04。在深度学习分类和分割任务中，合成视频的表现与真实视频无法区分（F1分数真实为0.9，合成0.89；分割的Dice相似系数为0.97）。临床医生区分真实与合成视频的准确率为54+/-6%，表明合成视频的真实性。

Conclusion: 该生成模型能够有效实现超声心动图灰度图像和CFD视频之间的转换，生成的图像在下游任务和专家评估中均表现出与真实图像相当的性能，为医学图像数据集的设计和利用提供了新的工具。该模型在仅接受心脏视频训练的情况下，也能很好地应用于其他临床领域的超声检查，显示了其基础能力。

Abstract: Deep learning (DL) has the potential to revolutionize image acquisition and
interpretation across medicine, however, attention to data imbalance and
missingness is required. Ultrasound data presents a particular challenge
because in addition to different views and structures, it includes several
sub-modalities-such as greyscale and color flow doppler (CFD)-that are often
imbalanced in clinical studies. Image translation can help balance datasets but
is challenging for ultrasound sub-modalities to date. Here, we present a
generative method for ultrasound CFD-greyscale video translation, trained on
54,975 videos and tested on 8,368. The method developed leveraged pixel-wise,
adversarial, and perceptual loses and utilized two networks: one for
reconstructing anatomic structures and one for denoising to achieve realistic
ultrasound imaging. Average pairwise SSIM between synthetic videos and ground
truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real
ones in DL classification and segmentation tasks and when evaluated by blinded
clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice
score between real and synthetic segmentation was 0.97. Overall clinician
accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%),
indicating realistic synthetic videos. Although trained only on heart videos,
the model worked well on ultrasound spanning several clinical domains (average
SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data
expand the utility of retrospectively collected imaging and augment the dataset
design toolbox for medical imaging.

</details>


### [28] [Enhancing Medical Image Segmentation via Heat Conduction Equation](https://arxiv.org/abs/2511.03260)
*Rong Wu,Yim-Sang Yu*

Main category: cs.CV

TL;DR: U-Mamba结合热传导方程在医学图像分割中表现出色，实现了高效的全局上下文建模和长距离依赖推理。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型（如U-Net变体）在医学图像分割中难以同时实现高效的全局上下文建模和长距离依赖推理，尤其是在实际的计算预算下。

Method: 提出了一种新颖的混合架构U-Mamba，并结合了热传导方程。该模型融合了基于Mamba的状态空间模块（用于高效长距离推理）和瓶颈层中的热传导算子（HCO），通过模拟频域热扩散来增强语义抽象。

Result: 在多模态腹部CT和MRI数据集上的实验结果表明，该模型持续优于强大的基线模型，验证了其有效性和泛化能力。

Conclusion: 将状态空间动力学与基于热量的全局扩散相结合，为医学分割任务提供了一个可扩展且可解释的解决方案。

Abstract: Medical image segmentation has been significantly advanced by deep learning
architectures, notably U-Net variants. However, existing models struggle to
achieve efficient global context modeling and long-range dependency reasoning
under practical computational budgets simultaneously. In this work, we propose
a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.
Our model combines Mamba-based state-space modules for efficient long-range
reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,
simulating frequency-domain thermal diffusion for enhanced semantic
abstraction. Experimental results on multimodal abdominal CT and MRI datasets
demonstrate that the proposed model consistently outperforms strong baselines,
validating its effectiveness and generalizability. It suggest that blending
state-space dynamics with heat-based global diffusion offers a scalable and
interpretable solution for medical segmentation tasks.

</details>


### [29] [IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection](https://arxiv.org/abs/2511.03267)
*Bingyang Guo,Hongjie Li,Ruiyun Yu,Hanzhe Liang,Jinbao Wang*

Main category: cs.CV

TL;DR: 本研究提出了一个针对工业设备零部件的3D异常检测数据集(IEC3D-AD)，并在此基础上设计了一种名为GMANet的新型3D异常检测方法，通过生成合成点云和优化特征空间来提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测数据集在捕捉真实工业环境中的复杂和细微缺陷方面存在不足，尤其是在轴承、环和螺栓等工业设备零部件(IEC)的精确异常检测方面。为了解决这个问题，需要一个更真实、更高分辨率、更细粒度的数据集，并在此基础上开发更有效的方法。

Method: 首先，收集真实工业生产线的点云数据，构建了高保真度的IEC3D-AD数据集，提高了点云分辨率和缺陷标注的精细度。其次，受到2D异常检测生成方法的启发，提出了一种名为GMANet的新型3D异常检测范式。该范式基于几何形态分析生成合成点云样本，并通过空间差异优化来减小正常和异常点特征之间的差距并增加重叠。

Result: 在IEC3D-AD数据集和其他数据集上的广泛实验证明了所提出方法的有效性。GMANet在提高3D异常检测的精度和泛化能力方面表现出色。

Conclusion: IEC3D-AD数据集的构建填补了真实工业场景下3D异常检测数据集的空白，而GMANet方法通过生成合成数据和优化特征表示，有效地提升了在各种数据集上的3D异常检测性能，为工业设备的安全性和可靠性提供了更好的保障。

Abstract: 3D anomaly detection (3D-AD) plays a critical role in industrial
manufacturing, particularly in ensuring the reliability and safety of core
equipment components. Although existing 3D datasets like Real3D-AD and MVTec
3D-AD offer broad application support, they fall short in capturing the
complexities and subtle defects found in real industrial environments. This
limitation hampers precise anomaly detection research, especially for
industrial equipment components (IEC) such as bearings, rings, and bolts. To
address this challenge, we have developed a point cloud anomaly detection
dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is
directly collected from actual production lines, ensuring high fidelity and
relevance. Compared to existing datasets, IEC3D-AD features significantly
improved point cloud resolution and defect annotation granularity, facilitating
more demanding anomaly detection tasks. Furthermore, inspired by generative
2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This
paradigm generates synthetic point cloud samples based on geometric
morphological analysis, then reduces the margin and increases the overlap
between normal and abnormal point-level features through spatial discrepancy
optimization. Extensive experiments demonstrate the effectiveness of our method
on both IEC3D-AD and other datasets.

</details>


### [30] [Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising](https://arxiv.org/abs/2511.03272)
*Shuangquan Lyu,Steven Mao,Yue Ma*

Main category: cs.CV

TL;DR: We present a unified method to generate and edit long videos with text-to-video diffusion models, using LoRA for efficient fine-tuning and an overlap-and-blend strategy for temporal consistency. Our approach enables arbitrarily long video generation and editing without seams or drift, outperforming baseline methods in quality and realism.


<details>
  <summary>Details</summary>
Motivation: Generating long, controllable videos, especially for inpainting and outpainting tasks, is a significant challenge. Existing methods often struggle with fixed clip lengths and stitching artifacts.

Method: The proposed method extends text-to-video diffusion models using LoRA for efficient fine-tuning of pre-trained models (e.g., Alibaba's Wan 2.1) for masked region synthesis. It employs an overlap-and-blend temporal co-denoising strategy with high-order solvers to ensure consistency in long sequences.

Result: The system enables arbitrarily long video generation and editing without noticeable seams or drift. Experiments show superior performance compared to baseline methods (Wan 2.1, VACE) in terms of PSNR, SSIM, and LPIPS, demonstrating effectiveness in challenging inpainting/outpainting tasks over hundreds of frames.

Conclusion: Our novel approach successfully addresses the challenges of long video generation and editing, offering a unified, parameter-efficient, and high-performance solution for controllable video inpainting and outpainting with minimal overhead.

Abstract: Generating long videos remains a fundamental challenge, and achieving high
controllability in video inpainting and outpainting is particularly demanding.
To address both of these challenges simultaneously and achieve controllable
video inpainting and outpainting for long video clips, we introduce a novel and
unified approach for long video inpainting and outpainting that extends
text-to-video diffusion models to generate arbitrarily long, spatially edited
videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
region video synthesis, and employs an overlap-and-blend temporal co-denoising
strategy with high-order solvers to maintain consistency across long sequences.
In contrast to prior work that struggles with fixed-length clips or exhibits
stitching artifacts, our system enables arbitrarily long video generation and
editing without noticeable seams or drift. We validate our approach on
challenging inpainting/outpainting tasks including editing or adding objects
over hundreds of frames and demonstrate superior performance to baseline
methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
perceptual realism (LPIPS). Our method enables practical long-range video
editing with minimal overhead, achieved a balance between parameter efficient
and superior performance.

</details>


### [31] [Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2511.03317)
*Minghao Fu,Guo-Hua Wang,Tianyu Cui,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: 标准的Diffusion-DPO目标可能会增加生成图像的重建误差，导致生成质量下降。Diffusion-SDPO通过自适应地缩放损失梯度来解决这个问题，保证了生成质量的非递减性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在生成高质量图像方面表现出色，但将其与人类偏好对齐仍然是一个挑战。

Method: 提出Diffusion-SDPO，一种安全的更新规则，通过自适应地根据损失梯度与获胜梯度的一致性来缩放损失梯度，从而保护获胜样本。

Result: Diffusion-SDPO在标准的文本到图像基准测试中，在自动化偏好、美学和提示对齐指标上，均优于基于偏好学习的基线方法。

Conclusion: Diffusion-SDPO是一种简单、模型无关、广泛兼容现有DPO风格的对齐框架，并且计算开销仅有边际增加，能够有效提升文本到图像扩散模型的对齐性能。

Abstract: Text-to-image diffusion models deliver high-quality images, yet aligning them
with human preferences remains challenging. We revisit diffusion-based Direct
Preference Optimization (DPO) for these models and identify a critical
pathology: enlarging the preference margin does not necessarily improve
generation quality. In particular, the standard Diffusion-DPO objective can
increase the reconstruction error of both winner and loser branches.
Consequently, degradation of the less-preferred outputs can become sufficiently
severe that the preferred branch is also adversely affected even as the margin
grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule
that preserves the winner by adaptively scaling the loser gradient according to
its alignment with the winner gradient. A first-order analysis yields a
closed-form scaling coefficient that guarantees the error of the preferred
output is non-increasing at each optimization step. Our method is simple,
model-agnostic, broadly compatible with existing DPO-style alignment frameworks
and adds only marginal computational overhead. Across standard text-to-image
benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning
baselines on automated preference, aesthetic, and prompt alignment metrics.
Code is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.

</details>


### [32] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: SurgViVQA是一个手术视频问答模型，它通过融合视频和文本特征来捕捉时间线索，并使用微调的LLM来生成答案。该模型在REAL-Colon-VQA和EndoVis18-VQA数据集上均优于现有模型，尤其在关键词准确率方面。 SurgViVQA和REAL-Colon-VQA数据集为手术视频问答提供了时态感知的理解框架。


<details>
  <summary>Details</summary>
Motivation: 现有的手术视频问答方法局限于静态图像特征，并且缺乏时间标注的数据集，忽略了程序解释中的动态性。因此，有必要提出一个能够理解动态手术场景的模型。

Method: 提出SurgViVQA模型，该模型使用掩码视频-文本编码器融合视频和问题特征，捕捉运动和工具-组织交互等时间线索，并使用微调的大型语言模型（LLM）进行解码。同时，构建了REAL-Colon-VQA数据集，包含运动相关问题和诊断属性，以及用于评估模型鲁棒性的模板外问题。

Result: 在REAL-Colon-VQA和EndoVis18-VQA数据集上的实验表明，SurgViVQA在关键词准确率方面优于现有的基于图像的VQA基准模型，在REAL-Colon-VQA上提高了11%，在EndoVis18-VQA上提高了9%。扰动研究证实了模型在问题措辞变化方面具有更好的泛化性和鲁棒性。

Conclusion: SurgViVQA模型和REAL-Colon-VQA数据集提供了一个时态感知的理解框架，用于手术视频问答，使AI模型能够更有效地解释动态程序上下文。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [33] [Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge](https://arxiv.org/abs/2511.03332)
*Yi Yang,Yiming Xu,Timo Kaiser,Hao Cheng,Bodo Rosenhahn,Michael Ying Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于FastTracker和LLaVA-Video的两阶段、零样本方法，用于在视频中根据语言查询本地化和跟踪多个对象，在MOT25-StAG挑战赛中获得第二名。


<details>
  <summary>Details</summary>
Motivation: MOT25-StAG挑战赛的目标是根据自由形式的语言查询，在复杂的真实世界场景视频中，准确地定位和跟踪多个匹配的对象。

Method: 该研究将任务建模为视频检索问题，并提出了一种两阶段、零样本的方法，结合了SOTA跟踪模型FastTracker和多模态大语言模型LLaVA-Video的优点。

Result: 在MOT25-StAG测试集上，该方法实现了20.68的m-HIoU和10.73的HOTA分数。

Conclusion: 该方法在MOT25-StAG挑战赛中取得了第二名的成绩，证明了其在根据语言查询进行视频对象定位和跟踪方面的有效性。

Abstract: In this report, we present our solution to the MOT25-Spatiotemporal Action
Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
localize and track multiple objects that match specific and free-form language
queries, using video data of complex real-world scenes as input. We model the
underlying task as a video retrieval problem and present a two-stage, zero-shot
approach, combining the advantages of the SOTA tracking model FastTracker and
Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
won second place in the challenge.

</details>


### [34] [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://arxiv.org/abs/2511.03334)
*Guozhen Zhang,Zixiang Zhou,Teng Hu,Ziqiao Peng,Youliang Zhang,Yi Chen,Yuan Zhou,Qinglin Lu,Limin Wang*

Main category: cs.CV

TL;DR: UniAVGen是一个统一的音频-视频生成框架，通过创新的跨媒体交互机制，解决了现有方法的唇部同步和语义一致性问题，并在更少的数据下实现了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开源音视频生成方法由于缺乏有效的跨媒体建模，在唇部同步和语义一致性方面表现不佳。

Method: 提出UniAVGen统一框架，采用双分支联合合成架构，结合两个并行的Diffusion Transformers（DiTs）构建跨媒体潜在空间。核心是"非对称跨媒体交互"机制，实现双向时间对齐的交叉注意力，以保证精确的时空同步和语义一致性。"面部感知调制"模块动态地优先交互过程中的显著区域。"模态感知无分类器指导"策略在推理时增强生成保真度。

Result: UniAVGen在音视频同步、音色一致性和情感一致性方面表现出整体优势，并且训练样本数量远少于现有方法（1.3M vs 30.1M）。

Conclusion: UniAVGen通过其联合合成设计，能够在一个模型中无缝统一关键的音视频任务，包括联合音视频生成与续写、视频到音频配音、以及音频驱动的视频合成。实验证明，该方法在关键指标上优于现有技术。

Abstract: Due to the lack of effective cross-modal modeling, existing open-source
audio-video generation methods often exhibit compromised lip synchronization
and insufficient semantic consistency. To mitigate these drawbacks, we propose
UniAVGen, a unified framework for joint audio and video generation. UniAVGen is
anchored in a dual-branch joint synthesis architecture, incorporating two
parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent
space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which
enables bidirectional, temporally aligned cross-attention, thus ensuring
precise spatiotemporal synchronization and semantic consistency. Furthermore,
this cross-modal interaction is augmented by a Face-Aware Modulation module,
which dynamically prioritizes salient regions in the interaction process. To
enhance generative fidelity during inference, we additionally introduce
Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly
amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint
synthesis design enables seamless unification of pivotal audio-video tasks
within a single model, such as joint audio-video generation and continuation,
video-to-audio dubbing, and audio-driven video synthesis. Comprehensive
experiments validate that, with far fewer training samples (1.3M vs. 30.1M),
UniAVGen delivers overall advantages in audio-video synchronization, timbre
consistency, and emotion consistency.

</details>


### [35] [Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.03367)
*Gahyeon Kim,Sohee Kim,Seokju Lee*

Main category: cs.CV

TL;DR: 使用图像增强来改进提示学习的泛化能力，并提出了一种名为AAPL的新方法来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉和语言模型在零样本学习任务上取得了显著进展，但这些模型在泛化到完全未见过的类别时仍存在困难。虽然传统零样本学习技术受益于数据增强，但提示学习主要集中在基于文本的修改上，而图像增强的潜力尚未被充分探索。

Method: 提出了一种名为AAPL（Adding Attributes to Prompt Learning）的新方法，该方法引入了对抗性令牌嵌入，将数据增强引入的表观视觉变化与类别相关的语义表征分离开来。这使得学习到的提示能够专注于与目标类别一致的视觉区分性特征。

Result: 在11个基准数据集上进行了广泛的实验，AAPL在少样本、零样本、跨数据集和域泛化设置中始终优于现有方法。

Conclusion: 通过在提示学习中结合图像增强（特别是属性特定的变化），可以提高模型的泛化能力。AAPL通过引入对抗性令牌嵌入来解耦表观变化和语义表征，从而实现更有效的提示学习。

Abstract: Recent advances in large-scale vision and language models have led to
significant progress in zero-shot learning tasks. Methods such as CoOp and
CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
known as prompt learning, can result in improved performance. However, these
models often struggle to generalize to entirely unseen categories. While
traditional zero-shot learning techniques benefit from various data
augmentation strategies, prompt learning has primarily focused on text-based
modifications, leaving the potential of image-based augmentation largely
unexplored. In this work, we explore how image-level augmentations,
particularly those that introduce attribute-specific variations, can support
and enhance prompt learning. Our analysis examines the interaction between
these augmentations and soft prompt frameworks, revealing their potential to
improve generalization. We also identify a limitation in existing methods, such
as CoCoOp, which do not provide explicit guidance for learning prompts that
focus on semantically meaningful visual features. To address this, we propose
Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
adversarial token embeddings to decouple superficial visual variations
introduced by augmentation from class-relevant semantic representations. This
decoupling enables the learned prompts to concentrate on visually
discriminative features that align with the target categories. We conduct
comprehensive experiments on eleven benchmark datasets, and AAPL consistently
outperforms existing methods across few-shot, zero-shot, cross-dataset, and
domain generalization settings. Our source code is publicly available at:
https://github.com/Gahyeonkim09/AAPL

</details>


### [36] [Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort](https://arxiv.org/abs/2511.03416)
*Nikolai Herrmann,Marcella C. Zijta,Stefan Klein,Régine P. M. Steegers-Theunissen,Rene M. H. Wijnen,Bernadette S. de Bakker,Melek Rousian,Wietske A. P. Bastiaansen*

Main category: cs.CV

TL;DR: 本研究提出了一种自动化的三维超声图像胚胎对齐方法，通过主成分分析（PCA）提取胚胎主轴，并结合三种策略（皮尔逊相关、图像匹配、随机森林）中的一种来选择标准方向，最终达到98.5%的准确率，可用于临床和研究。


<details>
  <summary>Details</summary>
Motivation: 为了提高产前生长监测的准确性，需要对三维超声图像中的胚胎进行标准化对齐，以方便标准平面检测、可视化地标和突出不同扫描之间的差异。

Method: 1. 对胚胎分割掩码应用主成分分析（PCA）提取主轴。 2. 从主轴导出四个候选方向。 3. 使用以下三种策略之一选择标准方向：基于皮尔逊相关系数评估形状的启发式方法；通过归一化互相关与图谱进行图像匹配；以及随机森林分类器。

Result: 在2166张图像中，99.0%的图像PCA能正确提取胚胎主轴。皮尔逊启发式、基于图谱和随机森林选择方法的准确率分别为97.4%、95.8%和98.4%。三种方法的多数投票准确率为98.5%。

Conclusion: 该自动化流水线能够高精度地实现第一孕期胚胎的一致性对齐，为临床和研究环境中的可扩展分析提供了支持。

Abstract: Standardized alignment of the embryo in three-dimensional (3D) ultrasound
images aids prenatal growth monitoring by facilitating standard plane
detection, improving visualization of landmarks and accentuating differences
between different scans. In this work, we propose an automated method for
standardizing this alignment. Given a segmentation mask of the embryo,
Principal Component Analysis (PCA) is applied to the mask extracting the
embryo's principal axes, from which four candidate orientations are derived.
The candidate in standard orientation is selected using one of three
strategies: a heuristic based on Pearson's correlation assessing shape, image
matching to an atlas through normalized cross-correlation, and a Random Forest
classifier. We tested our method on 2166 images longitudinally acquired 3D
ultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional
Cohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images,
PCA correctly extracted the principal axes of the embryo. The correct candidate
was selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%,
95.8%, and 98.4% of images, respectively. A Majority Vote of these selection
methods resulted in an accuracy of 98.5%. The high accuracy of this pipeline
enables consistent embryonic alignment in the first trimester, enabling
scalable analysis in both clinical and research settings. The code is publicly
available at:
https://gitlab.com/radiology/prenatal-image-analysis/pca-3d-alignment.

</details>


### [37] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 该研究提出了一种新的形状重建方法，能够处理包含拓扑变化（如撕裂和切割）的可变形物体表面。


<details>
  <summary>Details</summary>
Motivation: 现有形状重建方法在处理可变形物体时，当变形伴随拓扑变化（如物体撕裂或切割）时会失效。本研究旨在解决这一局限性，提出一种能够处理拓扑变化的形状重建方法。

Method: 该方法通过对三维模板进行空间划分，并最小化一个同时编码物理合理性和重投影一致性的能量函数，来迭代地适应模板，从而在存在拓扑变化的情况下进行重建。该方法首先使用经典的形状重建方法进行初始化。

Result: 实验结果表明，该方法能够鲁棒地处理二维平面上的撕裂和切割等拓扑变化，并且在合成数据和真实数据上都优于基线方法。

Conclusion: 本研究提出了第一个能够感知拓扑变化的形状重建通用框架，解决了现有方法的局限性，并在各种拓扑变化场景下取得了优异的重建效果。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [38] [Human Mesh Modeling for Anny Body](https://arxiv.org/abs/2511.03589)
*Romain Brégier,Guénolé Fiche,Laura Bravo-Sánchez,Thomas Lucas,Matthieu Armando,Philippe Weinzaepfel,Grégory Rogez,Fabien Baradel*

Main category: cs.CV

TL;DR: Anny是一个简单、完全可微分、无需扫描的人体模型，基于MakeHuman社区的体质知识，提供了一个连续、可解释的形状空间，由表型参数（如性别、年龄、身高、体重）控制，能够生成各种形态的人体，覆盖了从婴儿到老人的广泛年龄段、各种体型和比例。该模型使用世界卫生组织的人口统计数据进行校准，确保了现实和人口统计学上的合理性。Anny-One是一个包含800,000个使用Anny生成的光线写实人体的集合，证明了其在人体姿态恢复（HMR）等任务上的潜力，性能可与基于扫描的模型相媲美，同时保持了可解释性和广泛的代表性。Anny模型及其代码已根据Apache 2.0许可发布。


<details>
  <summary>Details</summary>
Motivation: 现有的参数化人体模型通常依赖昂贵的3D扫描，并且其学习到的形状空间具有专有性和人口统计学上的局限性。本文提出Anny模型，旨在提供一个简单、完全可微分、无需扫描、具有广泛代表性和可解释性的人体模型。

Method: Anny模型利用MakeHuman社区的体质知识，定义了一个连续、可解释的形状空间，其中表型参数（如性别、年龄、身高、体重）控制着能够跨越广泛人类形态（年龄、体型、比例）的变形。该模型使用世界卫生组织的人口统计数据进行校准，生成了一个名为Anny-One的包含800,000个光线写实人体的数据集。HMR模型在Anny-One数据集上进行训练，并与在基于扫描的模型上训练的模型进行性能比较。

Result: 使用Anny模型生成的Anny-One数据集训练的HMR模型，其性能与使用基于扫描的人体模型训练的HMR模型相当。Anny模型支持精确的扫描拟合、可控的合成数据生成和人体姿态恢复（HMR），并且具有开放性和语义控制。

Conclusion: Anny模型提供了一个简单、可解释、无需扫描、具有广泛代表性的人体建模基础，能够生成逼真的人体，并且在HMR等任务上表现出色，可与基于扫描的模型相媲美。其开放的许可使其成为3D人体建模领域一个易于获取的资源。

Abstract: Parametric body models are central to many human-centric tasks, yet existing
models often rely on costly 3D scans and learned shape spaces that are
proprietary and demographically narrow. We introduce Anny, a simple, fully
differentiable, and scan-free human body model grounded in anthropometric
knowledge from the MakeHuman community. Anny defines a continuous,
interpretable shape space, where phenotype parameters (e.g. gender, age,
height, weight) control blendshapes spanning a wide range of human forms --
across ages (from infants to elders), body types, and proportions. Calibrated
using WHO population statistics, it provides realistic and demographically
grounded human shape variation within a single unified model. Thanks to its
openness and semantic control, Anny serves as a versatile foundation for 3D
human modeling -- supporting millimeter-accurate scan fitting, controlled
synthetic data generation, and Human Mesh Recovery (HMR). We further introduce
Anny-One, a collection of 800k photorealistic humans generated with Anny,
showing that despite its simplicity, HMR models trained with Anny can match the
performance of those trained with scan-based body models, while remaining
interpretable and broadly representative. The Anny body model and its code are
released under the Apache 2.0 license, making Anny an accessible foundation for
human-centric 3D modeling.

</details>


### [39] [Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals](https://arxiv.org/abs/2511.03645)
*Vittal L. Rao*

Main category: cs.CV

TL;DR: 通过在局部信号强度上加权坐标通道来表示输入，可以提高生物医学信号定位任务的收敛速度和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 生物医学信号的定位任务通常需要模型从具有复杂强度分布的信号中学习有意义的空间或时间关系。像CoordConv这样的通用策略是通过向卷积输入添加坐标通道来实现的，这使得网络能够学习绝对位置。然而，这种方法并没有考虑信号的强度信息，而信号的强度信息可能包含有意义的位置线索。

Method: 提出一种信号强度加权的坐标表示方法，用局部信号强度缩放的通道替换纯坐标通道。这种修改将强度-位置耦合直接嵌入到输入表示中，引入了一种简单且与模态无关的归纳偏置。

Result: 在两个不同的定位问题上评估了该方法：(i) 预测20秒、两导心电图信号的形态转换时间；(ii) 从SiPaKMeD数据集中回归细胞图像中核中心的坐标。结果表明，与传统的坐标通道方法相比，所提出的表示方法在两个任务上都实现了更快的收敛速度和更高的泛化性能。

Conclusion: 提出的信号强度加权坐标表示方法是一种简单有效的方法，可以提高生物医学信号定位任务的性能，并且适用于一维和二维信号。

Abstract: Localisation tasks in biomedical data often require models to learn
meaningful spatial or temporal relationships from signals with complex
intensity distributions. A common strategy, exemplified by CoordConv layers, is
to append coordinate channels to convolutional inputs, enabling networks to
learn absolute positions. In this work, we propose a signal intensity-weighted
coordinate representation that replaces the pure coordinate channels with
channels scaled by local signal intensity. This modification embeds an
intensity-position coupling directly in the input representation, introducing a
simple and modality-agnostic inductive bias. We evaluate the approach on two
distinct localisation problems: (i) predicting the time of morphological
transition in 20-second, two-lead ECG signals, and (ii) regressing the
coordinates of nuclear centres in cytological images from the SiPaKMeD dataset.
In both cases, the proposed representation yields faster convergence and higher
generalisation performance relative to conventional coordinate-channel
approaches, demonstrating its effectiveness across both one-dimensional and
two-dimensional biomedical signals.

</details>


### [40] [A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential](https://arxiv.org/abs/2511.03665)
*Mehdi Sefidgar Dilmaghani,Francis Fowley,Peter Corcoran*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级三维卷积神经网络（3DCNN），用于利用事件基视觉数据进行人类活动识别（HAR）。


<details>
  <summary>Details</summary>
Motivation: 事件相机捕捉像素强度变化，能有效保护隐私，解决了传统基于帧的相机捕获可识别个人信息的问题。

Method: 提出了一种轻量级3DCNN模型，该模型能有效模拟空间和时间动态，同时保持紧凑设计以适应边缘部署。采用了带类别重新加权的焦点损失和数据增强策略来处理类别不平衡和提高泛化能力。

Result: 在复合数据集上进行了训练和评估，取得了0.9415的F1分数和94.17%的准确率，性能优于C3D、ResNet3D和MC3_18等基准3DCNN架构。

Conclusion: 实验结果表明，事件基深度学习在开发准确、高效、注重隐私的人类活动识别系统方面具有巨大潜力，适用于现实世界的边缘应用。

Abstract: This paper presents a lightweight three-dimensional convolutional neural
network (3DCNN) for human activity recognition (HAR) using event-based vision
data. Privacy preservation is a key challenge in human monitoring systems, as
conventional frame-based cameras capture identifiable personal information. In
contrast, event cameras record only changes in pixel intensity, providing an
inherently privacy-preserving sensing modality. The proposed network
effectively models both spatial and temporal dynamics while maintaining a
compact design suitable for edge deployment. To address class imbalance and
enhance generalization, focal loss with class reweighting and targeted data
augmentation strategies are employed. The model is trained and evaluated on a
composite dataset derived from the Toyota Smart Home and ETRI datasets.
Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy
of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,
and MC3_18 by up to 3%. These results highlight the potential of event-based
deep learning for developing accurate, efficient, and privacy-aware human
action recognition systems suitable for real-world edge applications.

</details>


### [41] [Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection](https://arxiv.org/abs/2511.03666)
*Dongkeun Kim,Minsu Cho,Suha Kwak*

Main category: cs.CV

TL;DR: 通过引入基于身体部位的感知和人际关系推理，提出了一种新的面向细粒度社交互动的分层式分组方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在识别社交互动时，忽略了面部表情、姿态和手势等细微的线索，并主要依赖个体的整体表征。此外，这些方法直接识别社交群体，而没有明确地模拟个体之间的互动，这限制了它们捕捉局部社交信号的能力，并可能在应从基于细微线索的社交互动中推断群体配置时引入歧义。

Method: 提出了一种分层的、面向身体部位的群体推理框架，用于细粒度社交互动识别。该方法利用身体部位特征及其相互关系来推断社交群体及其互动。具体来说，模型首先识别个体并将身体部位的感知线索用于增强个体特征，然后通过基于相似性的推理将个体关联起来以推断群体配置。这种方法不仅考虑了空间关系，还考虑了表达互动的细微社交线索，从而实现更准确的群体推断。

Result: 在 NVI 数据集上的实验表明，我们提出的方法优于现有方法，并取得了新的最先进成果。

Conclusion: 本研究提出的基于身体部位感知和人际关系推理的分层群体推理框架，能够更准确地识别细粒度社交互动和推断社交群体。

Abstract: Social interactions often emerge from subtle, fine-grained cues such as
facial expressions, gaze, and gestures. However, existing methods for social
interaction detection overlook such nuanced cues and primarily rely on holistic
representations of individuals. Moreover, they directly detect social groups
without explicitly modeling the underlying interactions between individuals.
These drawbacks limit their ability to capture localized social signals and
introduce ambiguity when group configurations should be inferred from social
interactions grounded in nuanced cues. In this work, we propose a part-aware
bottom-up group reasoning framework for fine-grained social interaction
detection. The proposed method infers social groups and their interactions
using body part features and their interpersonal relations. Our model first
detects individuals and enhances their features using part-aware cues, and then
infers group configuration by associating individuals via similarity-based
reasoning, which considers not only spatial relations but also subtle social
cues that signal interactions, leading to more accurate group inference.
Experiments on the NVI dataset demonstrate that our method outperforms prior
methods, achieving the new state of the art.

</details>


### [42] [Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition](https://arxiv.org/abs/2511.03725)
*Jongseo Lee,Wooil Lee,Gyeong-Moon Park,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: DANCE框架通过解耦运动动力学、物体和场景概念来解释视频动作识别模型，提高了解释的清晰度，并在用户研究中得到验证。


<details>
  <summary>Details</summary>
Motivation: 现有的视频动作识别模型解释方法未能有效分离运动和空间上下文，导致解释不清。基于语言的方法难以解释隐含的运动。DANCE框架旨在解决这些问题。

Method: DANCE框架通过将运动动力学概念定义为人类姿态序列，并利用大型语言模型自动提取物体和场景概念，最后通过一个先验概念瓶颈设计来强制模型通过这些概念进行预测。

Result: DANCE在KTH、Penn Action、HAA500和UCF-101四个数据集上进行了实验，结果表明DANCE在提高解释清晰度的同时，保持了具有竞争力的性能。用户研究验证了DANCE优越的可解释性。

Conclusion: DANCE框架在视频动作识别领域提供了一种新颖的解耦方法，显著提高了模型解释的清晰度和可解释性，并有助于模型调试、编辑和失败分析。

Abstract: Effective explanations of video action recognition models should disentangle
how movements unfold over time from the surrounding spatial context. However,
existing methods based on saliency produce entangled explanations, making it
unclear whether predictions rely on motion or spatial context. Language-based
approaches offer structure but often fail to explain motions due to their tacit
nature -- intuitively understood but difficult to verbalize. To address these
challenges, we propose Disentangled Action aNd Context concept-based
Explainable (DANCE) video action recognition, a framework that predicts actions
through disentangled concept types: motion dynamics, objects, and scenes. We
define motion dynamics concepts as human pose sequences. We employ a large
language model to automatically extract object and scene concepts. Built on an
ante-hoc concept bottleneck design, DANCE enforces prediction through these
concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101
-- demonstrate that DANCE significantly improves explanation clarity with
competitive performance. We validate the superior interpretability of DANCE
through a user study. Experimental results also show that DANCE is beneficial
for model debugging, editing, and failure analysis.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [43] [Cache Mechanism for Agent RAG Systems](https://arxiv.org/abs/2511.02919)
*Shuhang Lin,Zhencan Peng,Lingyao Li,Xiao Lin,Xi Zhu,Yongfeng Zhang*

Main category: cs.CL

TL;DR: ARC是一个新颖的、无需注释的缓存框架，为LLM代理动态管理小型、有价值的语料库，通过整合历史查询分布模式和嵌入空间中缓存项的内在几何结构，ARC能够自动维护高相关性缓存，显著提高RAG代理的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）在LLM代理中取得了成功，但代理级别的缓存管理，特别是动态构建、维护和更新适合每个代理需求的紧凑、相关语料库，仍然是一个未被充分探索的领域。

Method: ARC（Agent RAG Cache Mechanism）是一个新颖的、无需注释的缓存框架，它通过整合历史查询分布模式和嵌入空间中缓存项的内在几何结构，来动态管理每个代理的小型、有价值的语料库，以自动维护高相关性缓存。

Result: ARC将存储需求减少到原始语料库的0.015%，同时提供高达79.8%的命中答案率，并将平均检索延迟降低了80%。

Conclusion: ARC能够显著提高RAG驱动的LLM代理的效率和效果。

Abstract: Recent advances in Large Language Model (LLM)-based agents have been
propelled by Retrieval-Augmented Generation (RAG), which grants the models
access to vast external knowledge bases. Despite RAG's success in improving
agent performance, agent-level cache management, particularly constructing,
maintaining, and updating a compact, relevant corpus dynamically tailored to
each agent's need, remains underexplored. Therefore, we introduce ARC (Agent
RAG Cache Mechanism), a novel, annotation-free caching framework that
dynamically manages small, high-value corpora for each agent. By synthesizing
historical query distribution patterns with the intrinsic geometry of cached
items in the embedding space, ARC automatically maintains a high-relevance
cache. With comprehensive experiments on three retrieval datasets, our
experimental results demonstrate that ARC reduces storage requirements to
0.015% of the original corpus while offering up to 79.8% has-answer rate and
reducing average retrieval latency by 80%. Our results demonstrate that ARC can
drastically enhance efficiency and effectiveness in RAG-powered LLM agents.

</details>


### [44] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 过滤掉非人工翻译的文本对于提高机器翻译质量至关重要，本文提出了一种利用多语言机器翻译模型内部表征来区分人工和机器翻译句子 的新方法，实验结果表明该方法在非英语语言对上准确率提高了至少5个百分点，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的大型平行语料库，特别是从互联网上收集的，其中包含大量的机器翻译文本，过度依赖这些合成数据会严重影响翻译质量，因此，在训练高质量机器翻译模型之前，过滤掉非人工翻译的文本是一个必要步骤。

Method: 提出一种新方法，利用多语言机器翻译模型的内部表征来区分人工翻译和机器翻译的句子。

Result: 该方法在非英语语言对上的准确率提高了至少5个百分点，优于现有技术。

Conclusion: 所提出的方法能够有效地识别和过滤掉机器翻译的文本，从而提高机器翻译系统的整体翻译质量，尤其是在非英语语言对方面。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [45] [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://arxiv.org/abs/2511.03001)
*Gyeom Hwangbo,Hyungjoo Chae,Minseok Kang,Hyeonjong Ju,Soohyun Oh,Jinyoung Yeo*

Main category: cs.CL

TL;DR: LLM生成的3D场景缺乏真实感，因为指令不够详细。本研究提出了LEGO-Eval评估框架和LEGO-Bench基准，以解决这个问题，并发现现有生成方法存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的3D场景在空间布局和物体属性方面缺乏真实感，这会影响在其中训练的AI代理的性能。因此，需要更详细的指令来生成更真实的场景，并需要可靠的方法来评估场景与指令的对齐程度。

Method: 提出了一种名为LEGO-Eval的评估框架，该框架配备了多种工具，可以显式地将场景组件与其对应的指令进行关联，从而更准确地评估对齐程度。同时，还提出了一个名为LEGO-Bench的基准，其中包含详细的指令，用于描述真实世界的复杂布局和属性。

Result: LEGO-Eval在评估场景-指令对齐方面的表现优于仅使用VLM作为裁判的方法，F1分数提高了0.41。使用LEGO-Bench进行基准测试显示，当前的3D场景生成方法存在显著的局限性，在生成完全符合详细指令的场景方面，成功率最高仅为10%。

Conclusion: LEGO-Eval和LEGO-Bench为评估和改进基于LLM的3D场景生成提供了有效工具，并揭示了当前方法的不足，指明了未来的研究方向。

Abstract: Despite recent progress in using Large Language Models (LLMs) for
automatically generating 3D scenes, generated scenes often lack realistic
spatial layouts and object attributes found in real-world environments. As this
problem stems from insufficiently detailed, coarse-grained instructions,
advancing 3D scene synthesis guided by more detailed, fine-grained instructions
that reflect real-world environments becomes crucial. Without such realistic
scenes, training embodied agents in unrealistic environments can lead them to
learn priors that diverge significantly from real-world physics and semantics,
degrading their performance when deployed. Thus, verifying the alignment
between the fine-grained instruction and the generated scene is essential for
effective learning. However, current evaluation methods, such as CLIPScore and
vision-language models (VLMs), often fail to reliably assess such alignment.
This shortcoming arises primarily from their shallow understanding of 3D
scenes, which often leads to improperly grounded scene components. To address
this, we introduce LEGO-Eval, an evaluation framework equipped with diverse
tools designed to explicitly ground scene components, enabling more accurate
alignment assessments. We also present LEGO-Bench, a benchmark of detailed
instructions that specify complex layouts and attributes of real-world
environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge
by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with
LEGO-Bench reveals significant limitations in current generation methods.
Across all evaluated approaches, success rates reached at most 10% in
generating scenes that fully align with fine-grained instructions.

</details>


### [46] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: 通过分析-修订-微调 (ARF) 流程，使用小型开源语言模型 (LLMs) 在客户服务摘要任务上超越大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 旨在通过一种新的流程，让小型开源语言模型在客户服务摘要等任务上达到甚至超越大型专有模型，同时提高成本效益和数据隐私性。

Method: 提出了一种分析-修订-微调 (ARF) 流程。首先，分析并分类由教师模型（GPT-3.5）生成的摘要中的常见错误。然后，使用紧凑的编辑器模型（Llama 3.1 70B）进行有针对性的修订，以生成高质量的精炼训练数据。最后，在一个小型学生模型（Llama 3.1 8B）上，使用这些精炼的数据进行微调。

Result: 经过 ARF 流程微调的小型学生模型（Llama 3.1 8B）在客户服务摘要任务上的表现优于 GPT-3.5。

Conclusion: ARF 流程能够有效地提升小型开源语言模型的性能，使其在特定任务上超越大型专有模型，同时兼顾成本效益和数据隐私，为增强开源 LLMs 提供了通用的框架。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [47] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 该研究提出了一个新的灵活文本相似度匹配和最优二分匹配（FTS-OBP）评估方法，以解决传统基于精确匹配的ABS评估方法的局限性。研究人员首次探索了小型（<7B参数）的仅解码器生成语言模型（SLMs）在教育评论ABS方面的应用，并通过数据无关和数据量少的微调策略，在仅使用少量示例和单个GPU的情况下，使1.5-3.8B模型在ABS任务上表现优于大型专有模型，接近基准结果。此外，研究还发布了首个公开的教育评论ABS资源集，以支持低资源领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现有ABS研究主要集中在商业领域，而教育和医疗等高需求低资源领域的需求未能得到满足。此外，领域适应性挑战以及现有方法对资源密集型知识注入的依赖阻碍了这些领域的研究进展。传统的精确匹配评估方法过于僵化，未能准确评估生成模型的性能。

Method: 1. 提出了新的灵活文本相似度匹配和最优二分匹配（FTS-OBP）评估方法，该方法能够适应实际的抽取边界变化，并与传统指标保持高度相关性，同时提供细粒度的诊断。2. 对小型（<7B参数）仅解码器生成语言模型（SLMs）进行了首次ABS研究，通过在教育评论ABS方面的案例研究，探索了资源的下限。系统地研究了数据无关（上下文学习和权重合并）和数据量少的微调方法，并提出了一种多任务微调策略，显著提高了SLM的性能。3. 发布了首个公开的教育评论ABS资源集。

Result: 1. FTS-OBP评估方法能够灵活处理边界变化，并与传统指标相关。2. 在教育评论ABS任务中，1.5-3.8B的SLMs通过多任务微调策略，在仅使用200-1,000个示例和单个GPU的情况下，性能超过了专有的大型模型，并接近了基准结果。3. 发布了首个教育评论ABS资源集。

Conclusion: 该研究通过提出新的评估方法、探索小型生成语言模型在低资源ABS领域的应用，并发布相关资源，为解决低资源ABS领域的挑战提供了新的途径和解决方案。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [48] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2是一个开源的、基于网络的平台，用于LLM辅助的临床试验偏倚风险（ROB）评估，通过PDF解析、检索增强LLM提示和人工审核相结合的交互式界面来简化ROB2标注过程。


<details>
  <summary>Details</summary>
Motivation: 传统的偏倚风险（ROB）评估过程耗时费力，ROBOTO2旨在通过LLM辅助来简化和加速这一过程。

Method: ROBOTO2结合了PDF解析、检索增强LLM提示和人工审核，用户可以上传临床试验报告，获取ROB2信号问题的初步答案和证据，并进行实时反馈或修正。

Result: 发布了一个包含521份儿科临床试验报告的数据集，其中包含8954个信号问题和1202个证据段落，并对4种LLM的ROB2性能进行了基准测试。

Conclusion: ROBOTO2平台和数据集的发布，旨在简化ROB评估过程，推动相关研究和应用，并为LLM在自动化系统评价中的应用提供了基准和分析。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [49] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 本研究提出了一种从单边对话中推断和学习的方法（1SC），以解决诸如图形眼镜、远程医疗和呼叫中心等场景中对话只能被单边记录的问题。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的许多场景中，例如远程医疗、呼叫中心和智能眼镜，对话的双方无法同时被记录，这限制了对话式人工智能的应用。因此，研究如何从单边对话中推断和学习信息至关重要。

Method: 本研究将该问题形式化为单边对话问题（1SC），并研究了两个具体任务：1）为实时用例重建缺失的说话人发言；2）从单边对话记录中生成摘要。研究人员在 MultiWOZ、DailyDialog 和 Candor 数据集上，对提示和微调模型进行了评估，并采用了人类 A/B 测试和 LLM-as-a-judge 指标。

Result: 研究发现，获取未来一轮对话和关于话语长度的信息有助于重建缺失的发言；使用占位符提示有助于减少模型生成内容的虚构性；提示在大型模型重建对话方面效果显著，但小型模型则需要微调。此外，研究还表明，在不重建缺失发言的情况下，也能生成高质量的摘要。

Conclusion: 本研究提出了 1SC（单边对话）这一新挑战，并报告了有前景的研究结果，为开发注重隐私的对话式人工智能技术迈出了重要一步。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [50] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: PolyNorm是一个利用大型语言模型（LLM）进行文本归一化（TN）的提示驱动方法，旨在减少手动规则的依赖，提高语言覆盖范围，并支持跨语言的实验，其性能优于生产级系统，并发布了PolyNorm-Benchmark多语言数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的文本归一化（TN）系统虽然准确，但工程投入大、难以扩展且在低资源环境下语言覆盖不足。

Method: 提出PolyNorm，一种利用大型语言模型（LLM）的提示驱动方法来进行文本归一化（TN），以及一个语言无关的自动数据整理和评估流程。

Result: 在八种语言的实验中，与生产级系统相比，错误率（WER）持续降低。

Conclusion: PolyNorm通过提示驱动的LLM方法，减少了对手动规则的依赖，提高了语言适应性，并提供了一个可扩展的框架，在多语言环境下均表现出优于传统方法的性能。 PolyNorm-Benchmark数据集的发布将促进未来对文本归一化的研究。

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [51] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 本研究探讨计算语言学中的意外度和语义连贯性在区分精神分裂症患者与健康对照组中的作用，并研究这些测量指标与精神分裂症症状严重程度的关系。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症常伴有语言障碍，表现为言语紊乱和语篇连贯性受损，这些可能反映了潜在的认知障碍，并可作为诊断和评估症状严重程度的客观指标。

Method: 研究计算并比较了精神分裂症患者与健康对照组在语言意外度和语义连贯性方面的差异，并分析了这些语言测量指标与精神分裂症症状严重程度的关系。

Result: 本研究量化了精神分裂症患者的语言意外度和语义连贯性，并将其与健康对照组进行了比较，同时探讨了这些指标与症状严重程度的关联性。

Conclusion: 计算语言学中的意外度和语义连贯性可以作为评估精神分裂症语言障碍的有效工具，并为了解该疾病的认知基础提供了新的视角。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [52] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: CARMA 是一个大规模的阿拉伯语 Reddit 帖子数据集，包含六种心理健康状况，旨在促进阿拉伯语人群的心理健康检测。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语人群的心理健康资源匮乏且因文化污名化而受到限制，而现有的英语研究并未充分关注阿拉伯语。CARMA 旨在解决阿拉伯语心理健康检测领域的数据集稀缺问题。

Method: 创建了一个名为 CARMA 的大规模阿拉伯语 Reddit 帖子数据集，其中包含六种心理健康状况和对照组。对数据进行了定性和定量分析，以了解词汇和语义差异，并使用各种模型进行了分类实验。

Result: CARMA 数据集规模和多样性均超过现有资源。分析揭示了特定心理健康状况的语言标记。分类实验表明，使用从浅层分类器到大型语言模型的各种模型，可以有效地进行心理健康检测。

Conclusion: CARMA 数据集具有巨大的潜力，可以促进对阿拉伯语等代表性不足的语言的心理健康检测，并为未来的研究提供见解。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [53] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 该框架利用控制势垒函数（CBF）作为安全滤波器，在不微调基线大语言模型（LLM）的情况下，对其生成进行干预，以确保用户期望的文本生成。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提出一种基于控制的方法来对齐大语言模型（LLM），利用控制势垒函数（CBF）确保生成文本符合用户期望。

Method: 将CBF安全滤波器应用于基线LLM预测的token，以干预生成过程。该滤波器可直接应用于期望对齐的评估模型设计，且无需微调基线LLM。

Result: 使用开源语言模型实现了一个文本生成系统，能够生成积极的文本。

Conclusion: 所提出的基于CBF的框架能够有效地对齐大语言模型，生成用户期望的积极文本，且具有无需微调和易于集成的优点。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [54] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: MME-CC是一个新的多模态评估基准，用于评估大型语言模型（MLLMs）的视觉认知能力，特别是在空间、几何和知识推理方面。现有基准存在不足，MME-CC旨在系统地捕捉这些能力。实验表明，闭源模型表现更优，但空间和几何推理仍是薄弱环节。研究还识别了常见的错误模式和思维链（Chain-of-Thought）的处理过程。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型多模态语言模型（MLLMs）的评估基准在系统性地捕捉视觉中心认知行为方面存在不足，尤其是在多模态推理方面。因此，需要一个专门的评估体系来全面评估MLLMs的认知能力。

Method: 提出了MME-CC（Multi-Modal Evaluation benchmark of Cognitive Capacity）基准，该基准包含11项推理任务，涵盖了空间、几何和基于知识的三种基本视觉信息类别，并对MLLMs在这些维度上的认知能力进行了细致的分析。基于MME-CC，对16个代表性MLLMs进行了广泛的实验。

Result: 闭源模型在整体评估中表现优于开源模型（例如，Gemini-2.5-Pro得分为42.66，而GLM-4.5V为30.45）。空间和几何推理能力普遍较弱（得分低于或等于30%）。识别出常见的错误模式，包括方向错误、脆弱的跨视图身份保持以及对反事实指令的遵从性差。观察到思维链（Chain-of-Thought）通常遵循提取-推理-验证的三个阶段，并且高度依赖视觉信息提取。

Conclusion: MME-CC基准的提出和应用，旨在推动评估和模型设计更加关注MLLMs的认知能力，以期提升其在视觉中心认知任务上的表现。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [55] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 该研究提出了一种基于LLM的、以利益相关者为中心的方法来评估AI风险，并生成可解释的、特定于利益相关者的风险策略，以及揭示冲突的交互式可视化。


<details>
  <summary>Details</summary>
Motivation: 为了负责任地部署AI系统，理解不同利益相关者如何看待AI系统的风险至关重要。

Method: 该研究提出了一种利用LLM作为裁判来预测和解释风险的、以利益相关者为基础的风险评估框架。该框架使用风险地图Nexus和GloVE解释方法，生成特定于利益相关者的、可解释的策略，并展示不同利益相关者在同一风险上的异同。通过交互式可视化揭示冲突的产生方式和原因。

Result: 研究结果表明，利益相关者的观点显著影响风险认知和冲突模式。

Conclusion: 这项工作强调了以利益相关者为意识的解释对于使基于LLM的评估更加透明、可解释并符合以人为中心的AI治理目标的重要性。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [56] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 该研究对LLM中的不确定性估计（UE）方法进行了全面的实证研究，评估了其在区分aleatoric和epistemic不确定性方面的鲁棒性和有效性。研究结果表明，基于信息的方法在ID设置下表现最佳，而基于密度的方法和P(True)指标在OOD设置下表现更优，语义一致性方法则在不同设置下表现稳定。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLM）输出的可信度至关重要，而不确定性估计（UE）在此过程中扮演着关键角色。本研究旨在深入探究LLM中各种UE方法的鲁棒性和有效性，以区分aleatoric和epistemic不确定性。

Method: 本研究对十二种不同的UE方法和四种生成质量指标（包括来自LLM批评者的LLMScore）进行了实证分析，以评估LLM在问答（QA）任务中，在分布内（ID）和分布外（OOD）数据集上生成答案的不确定性。

Result: 研究发现，基于信息的方法在ID设置下表现出色，与模型对数据的理解一致。而在OOD设置下，基于密度的方法和P(True)指标在捕捉模型认知不确定性方面表现更优。语义一致性方法在不同数据集和生成指标下表现稳定可靠，但在某些情况下可能不是最佳选择。

Conclusion: 本研究为在LLM的QA任务中选择最合适的不确定性估计方法提供了宝贵的见解。基于信息的方法在ID设置下有效，基于密度的方法和P(True)指标在OOD设置下表现更好，而语义一致性方法则提供了跨设置的可靠性。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [57] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 本研究提出了孟加拉语的第一个大规模伦理基准BengaliMoralBench，以解决多语言大型语言模型在南亚地区与当地伦理规范的对齐问题，并评估了Llama、Gemma、Qwen和DeepSeek等模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的伦理基准主要以英语为中心，并受西方框架的影响，忽略了对于孟加拉语（全球使用人数超过2.85亿）等语言在现实世界部署至关重要的文化细微差别。因此，有必要开发一个符合当地社会文化背景的伦理基准。

Method: 创建了一个包含五个道德领域（日常活动、习惯、育儿、家庭关系和宗教活动）的孟加拉语伦理基准BengaliMoralBench，其中包含50个子主题。每个场景都由母语者使用美德、常识和公正伦理这三种伦理视角进行标注。然后，使用统一的提示协议和标准指标对Llama、Gemma、Qwen和DeepSeek等主要的が多言語LLM进行了系统的零样本评估。

Result: 在BengaliMoralBench基准上的模型性能差异很大（准确率在50%-91%之间）。定性分析显示，这些模型在文化接地、常识推理和道德公平性方面存在持续的不足。

Conclusion: BengaliMoralBench为负责任的本地化奠定了基础，能够进行符合文化规范的评估，并支持在孟加拉国等多样化、低资源的多语言环境中部署符合伦理的、稳健的人工智能。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [58] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）通过提取的元关系和概念迭代检索算法来提高其解释概念和生成准确响应的能力，从而解决了用户指令中的模糊或概念不匹配问题。


<details>
  <summary>Details</summary>
Motivation: LLM在处理用户指令中的模糊或概念不匹配的术语时存在困难，因此需要一种增强概念清晰度的方法。

Method: 提出了一种语言图模型（LGM），通过从自然语言中提取元关系（继承、别名和组合）来增强概念清晰度，并使用反射机制来验证这些关系。概念迭代检索算法将这些关系和相关描述动态地提供给LLM。

Result: LGM在标准基准测试中始终优于现有的检索增强生成（RAG）基线。

Conclusion: LGM通过增强概念清晰度和利用动态关系信息，有效地解决了LLM在处理模糊或概念不匹配的术语时的挑战，并且能够处理任意长度的文本。

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [59] [Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification](https://arxiv.org/abs/2511.03217)
*Shaghayegh Kolli,Richard Rosenbaum,Timo Cavelius,Lasse Strothe,Andrii Lata,Jana Diesner*

Main category: cs.CL

TL;DR: 本研究提出一种结合大语言模型（LLM）、知识图谱（KG）和实时搜索代理的混合事实核查方法，以克服LLM的接地性不足和传统事实核查器的覆盖率/延迟问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然擅长生成流畅的文本，但在可靠地依据验证信息方面可能存在不足。而基于知识图谱的事实核查器虽然能提供精确可解释的证据，但覆盖范围有限或存在延迟。本研究旨在结合两者的优点，提出一种混合事实核查方法。

Method: 该系统包含三个独立的步骤：1）知识图谱（KG）检索，用于在DBpedia中快速进行单跳查找；2）基于语言模型（LM）的分类，通过特定任务的标签提示进行引导，并产生具有内部规则逻辑的输出；3）仅在KG覆盖不足时调用的网络搜索代理。

Result: 该方法在FEVER基准测试的“支持/反驳”划分上取得了0.93的F1分数，且无需针对任务进行微调。此外，在处理“信息不足”（NEI）的案例时，研究发现该方法经常能为最初标记为NEI的声明找到有效的证据，这得到了专家注释者和LLM评审者的一致确认。

Conclusion: 本研究提出了一个模块化的、开源的事实核查流程，该流程具有备用策略，并能在不同数据集之间进行泛化，有效提高了事实核查的准确性和覆盖范围。

Abstract: Large language models (LLMs) excel in generating fluent utterances but can
lack reliable grounding in verified information. At the same time,
knowledge-graph-based fact-checkers deliver precise and interpretable evidence,
yet suffer from limited coverage or latency. By integrating LLMs with knowledge
graphs and real-time search agents, we introduce a hybrid fact-checking
approach that leverages the individual strengths of each component. Our system
comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid
one-hop lookups in DBpedia, 2) an LM-based classification guided by a
task-specific labeling prompt, producing outputs with internal rule-based
logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.
Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the
Supported/Refuted split without task-specific fine-tuning. To address Not
enough information cases, we conduct a targeted reannotation study showing that
our approach frequently uncovers valid evidence for claims originally labeled
as Not Enough Information (NEI), as confirmed by both expert annotators and LLM
reviewers. With this paper, we present a modular, opensource fact-checking
pipeline with fallback strategies and generalization across datasets.

</details>


### [60] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: SARAL在MATERIAL项目的三项不同语言（波斯语、哈萨克语和格鲁吉亚语）的六项评估条件中的五项中，在跨语言信息检索（CLIR）方面取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: IARPA资助的MATERIAL项目旨在推动跨语言信息检索（CLIR）技术的发展。

Method: 本文详细介绍了解信息科学研究所（ISI）的SARAL（Summarization and domain-Adaptive Retrieval Across Language）项目，重点是开发一种能够检索查询相关文档集（而非单个文档列表）的CLIR方法。

Result: 在MATERIAL的第三阶段评估中，SARAL在三种不同语言（波斯语、哈萨克语和格鲁吉亚语）的六项评估条件中的五项中，表现优于其他团队。

Conclusion: SARAL在跨语言信息检索（CLIR）方面表现出色，特别是在检索相关文档集方面，并在MATERIAL项目的三项不同语言的评估中取得了领先地位。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [61] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: IndicSuperTokenizer 是一种结合了子词和多词分词以及特定语言预分词技术的 tokenizer，适用于印度多语种 LLMs，在印度语言和代码数据上取得了新的 state-of-the-art 效果。


<details>
  <summary>Details</summary>
Motivation: 设计有效的、针对多语种 LLMs 的 tokenizer 具有挑战性，现有子词方法（如 BPE）在多语种场景下的效果仍需探索。

Method: IndicSuperTokenizer 结合了子词和多词分词，并加入了特定语言的预分词，以生成更符合语言学规律的 tokens。

Result: 与 LLaMA4 相比，平均 fertility score 提高了 39.5%，与 Sutra 相比提高了 18%，同时推理吞吐量提高了 44%，并且在英语和印度语言基准测试上保持了可比的性能。

Conclusion: IndicSuperTokenizer 在 fertility score 和推理吞吐量方面均优于现有方法，并且通过消融实验证明了其设计的鲁棒性。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [62] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 该研究比较了四种开源语言模型（Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct, Orca-mini-v3-7b）和GPT-3.5在检索增强生成（RAG）支持下的计算机科学问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）和检索增强生成（RAG）的日益普及，研究人员对比较不同LLM在各种领域问答任务中的性能表现产生了兴趣。

Method: 通过使用准确率、精确率、人类专家排名、Gemini排名和余弦相似度等评估指标，对四种开源LLM和GPT-3.5在计算机科学文献问答任务中的表现进行了比较。

Result: GPT-3.5在RAG的加持下，在回答二元和长问答题方面表现出色。在开源模型中，Mistral-7b-instruct在RAG的加持下，在回答二元和长问答题方面均优于其他模型。Orca-mini-v3-7b的平均延迟最短，而LLaMa2-7b-chat的平均延迟最长。

Conclusion: 研究表明，在更好的基础设施支持下，开源语言模型可以与GPT-3.5等闭源模型相媲美。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [63] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: We introduce SCALE, a width upscaling architecture for continual pre-training of large language models that preserves base model functionality while enabling new knowledge acquisition through lightweight expansion modules and selective training, achieving a better stability-plasticity trade-off.


<details>
  <summary>Details</summary>
Motivation: Progress in continual pre-training for LLMs depends more on scaling the right structure than parameters alone. Existing methods often suffer from forgetting or limited adaptation.

Method: SCALE is a width upscaling architecture that inserts lightweight expansion modules into linear layers of a frozen pre-trained LLM. It follows two principles: Persistent Preservation (freezing base weights, preservation-oriented initialization) and Collaborative Adaptation (selectively training expansion components). Three variants are proposed: SCALE-Preserve, SCALE-Adapt, and SCALE-Route (with token-level routing).

Result: On a synthetic benchmark, SCALE mitigates forgetting seen with depth expansion. On a Korean corpus, SCALE variants show less English forgetting and competitive Korean gains, offering the best stability-plasticity trade-off. Analysis clarifies preservation conditions and the benefits of preservation-adaptation interplay.

Conclusion: SCALE offers an effective approach to continual pre-training for LLMs by enabling adaptation without sacrificing performance through architectural modifications and strategic training, improving the stability-plasticity balance compared to standard methods.

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [64] [How to Evaluate Speech Translation with Source-Aware Neural MT Metrics](https://arxiv.org/abs/2511.03295)
*Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本研究旨在解决语音-文本翻译（ST）系统评估中的一个关键问题：如何有效利用源音频信息进行评估，尤其是在没有可靠文本转录的情况下。研究者探索了两种生成文本代理的方法（ASR转录和参考翻译的机器翻译回译），并提出了一种新的跨语言分割算法来处理源文本和参考翻译之间的对齐不匹配问题。实验证明，在特定条件下，ASR转录优于回译，而回译则是一种成本更低但同样有效的方法。该研究为开发更准确的ST评估方法奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统的语音-文本翻译（ST）系统评估依赖于参考翻译，忽略了源音频信息。然而，最新的机器翻译（MT）研究表明，结合源文本的神经评估指标与人类判断的相关性更强。将此方法应用于ST并非易事，因为源是音频而非文本，并且通常缺乏可靠的转录或对齐信息。

Method: 本研究对源感知ST评估指标进行了系统的研究，特别关注在源转录不可用的实际操作条件下。研究者探索了两种生成文本代理的互补策略：1. 自动语音识别（ASR）转录；2. 参考翻译的机器翻译回译。此外，研究者引入了一种新颖的两步跨语言重新分割算法，以解决合成源和参考翻译之间的对齐不匹配问题。

Result: 在覆盖79种语言对和6种具有不同架构和性能水平的ST系统的两个ST基准的实验中，研究结果表明：1. 当词错误率低于20%时，ASR转录比机器翻译回译更可靠的合成源。2. 机器翻译回译始终是一种计算成本较低但仍然有效的方法。3. 提出的跨语言重新分割算法能够有效地使用源感知MT指标进行ST评估。

Conclusion: 本研究首次系统地研究了在缺乏源文本转录的实际条件下，ST评估的源感知方法。提出的跨语言重新分割算法能有效处理合成源和参考翻译之间的对齐不匹配问题，使得源感知MT评估指标在ST评估中得到稳健应用，为开发更准确、更科学的ST评估方法铺平了道路。ASR转录和机器翻译回译是两种有前景的合成源策略。

Abstract: Automatic evaluation of speech-to-text translation (ST) systems is typically
performed by comparing translation hypotheses with one or more reference
translations. While effective to some extent, this approach inherits the
limitation of reference-based evaluation that ignores valuable information from
the source input. In machine translation (MT), recent progress has shown that
neural metrics incorporating the source text achieve stronger correlation with
human judgments. Extending this idea to ST, however, is not trivial because the
source is audio rather than text, and reliable transcripts or alignments
between source and references are often unavailable. In this work, we conduct
the first systematic study of source-aware metrics for ST, with a particular
focus on real-world operating conditions where source transcripts are not
available. We explore two complementary strategies for generating textual
proxies of the input audio, automatic speech recognition (ASR) transcripts, and
back-translations of the reference translation, and introduce a novel two-step
cross-lingual re-segmentation algorithm to address the alignment mismatch
between synthetic sources and reference translations. Our experiments, carried
out on two ST benchmarks covering 79 language pairs and six ST systems with
diverse architectures and performance levels, show that ASR transcripts
constitute a more reliable synthetic source than back-translations when word
error rate is below 20%, while back-translations always represent a
computationally cheaper but still effective alternative. Furthermore, our
cross-lingual re-segmentation algorithm enables robust use of source-aware MT
metrics in ST evaluation, paving the way toward more accurate and principled
evaluation methodologies for speech translation.

</details>


### [65] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: “思考模式”在医学任务中的作用有限，双模式大语言模型在复杂医学任务上的表现仍有待提高，需要领域特定的数据和更先进的知识融合方法。


<details>
  <summary>Details</summary>
Motivation: 评估“思考模式”在双模式多模态大语言模型（MLLMs）中的作用，并研究其对临床任务（特别是医学影像任务）性能和可靠性的影响。

Method: 评估了Seed1.5-VL和Gemini-2.5-Flash这两个领先的MLLMs在医学任务中的“思考模式”能力，使用了VQA-RAD和ROCOv2数据集，并在四个视觉医学任务上进行了评估。

Result: 激活“思考模式”相比于标准的“非思考模式”，在大多数医学任务上的性能提升是边际的。模型在开放式视觉问答和医学影像解读等复杂医学任务上的表现仍然不理想。

Conclusion: 尽管“思考模式”有所改进，但MLLMs在处理复杂医学任务时仍存在局限性，这表明需要领域特定的医学数据和更先进的医学知识整合方法来进一步提高其性能。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [66] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: 生成式人工智能（GenAI）在生物信息学中展现出巨大潜力，尤其在基因组学、蛋白质组学、转录组学、结构生物学和药物发现等领域。本综述通过六个研究问题（RQs）系统性地评估了GenAI的发展，关注其方法学、预测性能和专业化应用，并指出了未来在高级建模、数据密集型发现和综合生物分析方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 本综述旨在系统性地识别和评估生成式人工智能（GenAI）在生物信息学领域的应用进展，以确定有影响力的方法，并为未来的高级建模、数据密集型发现和综合生物分析提供方向。

Method: 本综述采用系统性文献回顾方法，依据PRISMA（Preferred Reporting Items for Systematic Reviews and Meta-Analysis）方法论，提出了六个研究问题（RQs），以评估GenAI在生物信息学中的方法学、预测性能和专业化应用。

Result: GenAI在序列分析、分子设计和数据集成等方面展现出优于传统方法的性能；专门化的模型架构优于通用模型；在分子分析和数据集成方面提高了准确性并减少了错误；在结构建模、功能预测和合成数据生成方面得到验证；主要限制包括可扩展性和数据偏差；UniProtKB、ProteinNet12、CELLxGENE、GTEx、PubMedQA和OMIM等多种数据集广泛支持了GenAI模型的训练和泛化。

Conclusion: GenAI在生物信息学领域具有广泛的应用前景，并在多个子领域取得了显著进展。然而，仍需解决可扩展性、数据偏差等挑战，并通过更严格的评估和基于生物学的模型来充分发挥其潜力。多样化的数据集对于模型的训练和泛化至关重要。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [67] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 该研究提出了一种名为“Silenced Bias Benchmark”（SBB）的新方法，用于评估大型语言模型（LLM）在安全对齐后隐藏的偏见。


<details>
  <summary>Details</summary>
Motivation: 安全对齐的LLM在敏感应用中日益普及，但现有的公平性评估方法（通常基于问答）可能因将模型拒绝视为公平性指标而产生误导。本研究旨在解决安全对齐可能掩盖模型潜在不公平偏见的问题。

Method: 提出了一种名为“Silenced Bias Benchmark”（SBB）的新方法，该方法利用激活因子控制（activation steering）来减少模型在问答过程中的拒绝行为，从而揭示隐藏在模型潜在空间中的偏见。SBB易于扩展到新的群体和主题。

Result: 通过在多个LLM上进行实验，该研究发现模型的直接回答与其潜在的公平性问题之间存在显著差异，揭示了安全对齐可能掩盖的“被抑制的偏见”。

Conclusion: SBB提供了一种更有效的公平性评估框架，有助于未来开发更公平的LLM，克服安全对齐带来的遮蔽效应。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [68] [EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation](https://arxiv.org/abs/2511.03370)
*Yunbo Long,Yuhan Liu,Alexandra Brintrup*

Main category: cs.CL

TL;DR: EQ-Negotiator是一个框架，利用情感进行谈判，使小型语言模型（SLM）在谈判中达到大型语言模型（LLM）的性能，同时满足隐私限制。


<details>
  <summary>Details</summary>
Motivation: 部署大型语言模型（LLM）进行自动谈判虽然性能优越，但由于其高昂的计算成本和数据隐私需求，不适用于许多有隐私要求的场景。小型语言模型（SLM）虽然更实用，但在扮演充满情感的复杂角色方面，尤其是在信贷谈判中，与LLM相比存在显著的性能差距。

Method: EQ-Negotiator框架的核心是一个推理系统，它整合了博弈论和一个隐马尔可夫模型（HMM），用于在线学习和跟踪债务人的情绪状态，无需预先训练。这使得EQ-Negotiator能够为SLM提供战略智能，以应对操纵、缓和冲突并遵守道德规范。

Result: 通过在各种信贷谈判场景中进行广泛的代理到代理模拟，包括欺骗、威胁和扮演受害者等对抗性债务人策略，我们证明了EQ-Negotiator能够使一个7B参数的语言模型在债务追回和谈判效率方面优于规模大10倍以上的基线LLM。

Conclusion: EQ-Negotiator框架通过情感角色弥合了能力差距，使SLM在谈判中达到LLM的性能，同时满足隐私限制。该研究表明，在自动谈判中，战略情商而非原始模型规模是成功的关键因素，为在边缘运行有效、合乎道德且注重隐私的AI谈判铺平了道路。

Abstract: The deployment of large language models (LLMs) in automated negotiation has
set a high performance benchmark, but their computational cost and data privacy
requirements render them unsuitable for many privacy-sensitive, on-device
applications such as mobile assistants, embodied AI agents or private client
interactions. While small language models (SLMs) offer a practical alternative,
they suffer from a significant performance gap compared to LLMs in playing
emotionally charged complex personas, especially for credit negotiation. This
paper introduces EQ-Negotiator, a novel framework that bridges this capability
gap using emotional personas. Its core is a reasoning system that integrates
game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional
states online, without pre-training. This allows EQ-Negotiator to equip SLMs
with the strategic intelligence to counter manipulation while de-escalating
conflict and upholding ethical standards. Through extensive agent-to-agent
simulations across diverse credit negotiation scenarios, including adversarial
debtor strategies like cheating, threatening, and playing the victim, we show
that a 7B parameter language model with EQ-Negotiator achieves better debt
recovery and negotiation efficiency than baseline LLMs more than 10 times its
size. This work advances persona modeling from descriptive character profiles
to dynamic emotional architectures that operate within privacy constraints.
Besides, this paper establishes that strategic emotional intelligence, not raw
model scale, is the critical factor for success in automated negotiation,
paving the way for effective, ethical, and privacy-preserving AI negotiators
that can operate on the edge.

</details>


### [69] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: LFC-DA是一种通过符号逻辑控制的流水线，用于生成多样化且逻辑严谨的逻辑推理数据集，显著提高了预训练模型在ReClor和LogiQA上的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的逻辑数据增强方法要么成本高昂（依赖人工标注），要么生成的样本缺乏可解释性和逻辑同质性。

Method: LFC-DA将逻辑文本映射到命题表达式，编译规则库，并通过有界状态空间搜索生成有效的逻辑公式，最后将公式转换回自然语言问题。

Result: 在ReClor和LogiQA数据集上的实验表明，LFC-DA能够显著提高预训练模型在逻辑推理任务上的准确性。

Conclusion: LFC-DA是一种有效的、由大型语言模型指导的逻辑数据增强方法，能够生成多样化且逻辑严谨的数据集。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [70] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 为机器翻译（MT）的词语分割模型，不同语种和数据量下 BPE 的合并操作次数（NMO）应不完全相同，非对称 BPE 在低资源场景下显著优于对称 BPE。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译研究通常为词语分割模型（如 BPE）采用固定的超参数，但这并不保证在所有语种和数据量下都能达到最优的翻译性能。

Method: 研究了不同数据量和语种下 BPE 分词策略对机器翻译系统性能的影响，重点比较了对称 BPE 和非对称 BPE 的效果。

Result: 在英语-印地语的低资源场景下，非对称 BPE 相较于对称 BPE，CHRF++ 平均指标显著提升了 5.32（50K）、4.46（100K）和 0.7（500K）。该趋势在其他六种语言对的 12 个系统中得到了验证，其中 10 个系统显示出统计学上的显著改进。

Conclusion: 在机器翻译中，尤其是在低资源场景下，采用源语言高 NMO（4K-32K）和目标语言低 NMO（0.5K-2K）的非对称 BPE，能够比对称 BPE 带来更好的性能。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [71] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 小型语言模型(SLM)在提取数据属性时表现出潜力，但对于对象属性则不然。通过采用特定策略（如数据集扩展和基于模板的合成数据增强）并确保每个属性的出现次数超过特定阈值，可以改进其性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究小型语言模型(SLM)在提取对象属性方面的能力，以实现完整的RDF图提取，并解决长尾分布带来的挑战。

Method: 评估了包括分层采样、加权损失、数据集扩展和基于模板的合成数据增强在内的多种策略，并提出了一种通过增加稀有属性的出现次数来构建训练集的方法。

Result: 与现有方法相比，所提出的方法在处理不平衡的目标属性时表现更好，并且在增加稀有属性的出现次数后，性能得到了显著提升。数据集、实验结果和代码已公开。

Conclusion: 本文提出的方法为训练具有形状感知能力的小型语言模型提供了实际指导，并为语义关系提取的未来研究指明了方向。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [72] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 3TF通过在推理时强制执行简洁、无思考的输出来实现高效推理，从而在推理基准上获得显著改进。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的链式思考（CoT）方法主要压缩冗长的推理输出，虽然提高了效率，但仍然依赖于推理过程中的显式推理。

Method: 3TF（思考-训练和无思考推理）框架首先训练一个可以在推理和非推理模式下运行的混合模型，然后用CoT注释数据对其进行进一步训练，以内化结构化推理，同时在推理时使用无推理模式强制执行简洁、无思考的输出。

Result: 与基于压缩的方法不同，3TF提高了非推理输出的推理质量，使模型能够隐式地执行丰富的内部推理，同时保持外部输出简洁。

Conclusion: 3TF框架使模型能够在不显式生成逐步推理的情况下，隐式地学习和执行高质量推理，并在无思考推理的推理基准上取得了显著的改进。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [73] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: QuestionRAG框架通过知识增强和强化学习来解决大型语言模型在问题纠错中的意图识别和过度修正问题，显著提高了模型的指令遵循和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理带有错误输入的问题时，常常因为无法正确理解用户意图（误解）或不必要地改变原问题结构（过度修正）而导致回答错误。

Method: QuestionRAG框架：1. 知识增强：通过整合外部知识（如搜索结果、相关实体）来丰富输入信息，解决意图误解问题。 2. 强化学习对齐：利用强化学习调整模型目标，使其专注于精确修正而非简单释义，以防止过度修正。

Result: 知识增强对于理解错误问题至关重要。与传统的监督微调（SFT）相比，基于强化学习的对齐方法在提升模型指令遵循和泛化能力方面效果显著。

Conclusion: 结合知识增强和强化学习的QuestionRAG框架能够充分发挥大型语言模型在问题纠错任务上的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [74] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: CareMedEval是一个包含534个基于37篇科学论文的医学批判性评价和推理任务的数据集，用于评估大型语言模型（LLMs）在生物医学领域的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在生物医学领域的批判性评价和推理任务中的可靠性，尤其是在专业领域。

Method: 创建了一个名为CareMedEval的数据集，包含534个基于37篇科学论文的问题，这些问题源自法国医学生的真实考试。对各种通用和专业LLMs进行了基准测试。

Result: 在不同上下文条件下，通用和商业LLMs的精确匹配率（Exact Match Rate）均未超过0.5，但生成中间推理过程可以显著提高结果。模型在研究局限性和统计分析方面的问题上仍面临挑战。

Conclusion: CareMedEval提供了一个具有挑战性的基准，用于评估LLMs在生物医学领域的批判性评价和推理能力，揭示了当前LLMs的局限性，并为未来开发自动化辅助工具指明了方向。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [75] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: Kastor是一个用于知识库补全和精炼的框架，通过评估SHACL形状的所有属性组合来改进基于RDF模式的提取，并采用迭代学习过程来处理噪声数据。


<details>
  <summary>Details</summary>
Motivation: 为了在专业领域中完成和精炼知识库，需要一种能够处理有限文本和RDF数据并提高模型泛化能力和性能的方法。

Method: Kastor框架将传统的SHACL形状验证任务重构为评估从形状派生的所有可能的属性组合。它还采用迭代学习过程来精炼有噪声的知识库。

Result: 通过为每个训练示例选择最佳属性组合，Kastor显著提高了模型的泛化能力和性能，并能够发现新的相关事实。

Conclusion: Kastor通过其创新的方法，能够有效地完成和精炼专业领域的知识库，从而创建能够发现新事实的鲁棒模型。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [76] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 现有 Bangla-English 翻译系统难以处理技术术语，导致技术问题解答不准确。本研究提出了 BanglaSTEM 数据集和基于 T5 的翻译模型，显著提高了技术内容的翻译准确性，使 Bangla 用户能更有效地利用 English LLM。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在处理 Bangla 技术问题时的准确性不足，现有 Bangla-English 翻译系统在技术术语翻译方面存在缺陷。

Method: 构建了一个包含 5,000 个 Bangla-English 句子对的 BanglaSTEM 数据集，涵盖 STEM 领域。使用语言模型生成了超过 12,000 个翻译，并由人工评估者筛选出保留技术术语的高质量翻译对。基于 BanglaSTEM 数据集训练了一个 T5 模型，并测试了其在代码生成和数学问题解答任务上的表现。

Result: 所提出的 BanglaSTEM 数据集和 T5 翻译模型在技术内容翻译准确性方面取得了显著的改进，使 Bangla 用户能够更有效地利用 English LLM。

Conclusion: BanglaSTEM 数据集和基于此训练的 T5 模型能够有效解决 Bangla 技术问题翻译的挑战，提高了 Bangla 用户利用 English LLM 的能力，相关资源已公开。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [77] [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](https://arxiv.org/abs/2511.03506)
*Ding Chen,Simin Niu,Kehang Li,Peng Liu,Xiangping Zheng,Bo Tang,Xinchi Li,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 该论文提出了一个名为 HaluMem 的新基准，用于评估 AI 记忆系统中的幻觉问题，解决了现有评估方法难以定位幻觉来源的缺点。


<details>
  <summary>Details</summary>
Motivation: 现有 AI 记忆系统的评估方法主要集中在端到端问答，难以确定幻觉（如捏造、错误、冲突、遗漏）在记忆系统的哪个操作阶段产生。

Method: 提出了 HaluMem 基准，包含记忆提取、记忆更新和记忆问答三个评估任务，并构建了 HaluMem-Medium 和 HaluMem-Long 数据集来支持评估，这些数据集包含大量记忆点、多类型问题和长对话，以模拟真实的人机交互。

Result: 通过在 HaluMem 上进行的实证研究发现，现有的记忆系统在提取和更新阶段容易产生和累积幻觉，这些幻觉会进一步传播到问答阶段，导致错误。

Conclusion: 未来的研究应着重于开发可解释且受约束的记忆操作机制，以系统性地抑制幻觉，提高记忆的可靠性。

Abstract: Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

</details>


### [78] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 现有基准测试在多轮对话指令遵循能力评估方面存在局限性，本文提出了一个可扩展的框架，通过三层机制解耦语言形式和用户意图，动态构建基准测试，并定义了一系列评估交互质量的指标。使用该框架构建的 EvolIF 基准测试表明，GPT-5 在指令遵循能力方面表现优于 Gemini-2.5-Pro。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型在多轮对话中遵循用户指令的能力对于数据密集型对话应用至关重要，而现有基准测试存在局限性。

Method: 提出一个可扩展的框架，该框架通过一个三层机制（跟踪约束、指令和主题）将语言形式与用户意图模拟分离开来，以评估多轮指令遵循能力。该框架通过启用动态构建基准测试，并仅在模型耗尽模拟用户的耐心时才终止对话，来模拟用户-LLM交互。此外，还定义了一系列捕捉交互过程质量的指标，并构建了一个包含九种不同约束类型的 EvolIF 基准测试。

Result: 使用 EvolIF 基准测试，GPT-5 在指令遵循能力方面表现出卓越的性能，平均对话轮次达到 18.54 轮，鲁棒性达到 70.31%，显著优于 Gemini-2.5-Pro（11.41%），其他模型表现则远落后。

Conclusion: GPT-5 在多轮对话指令遵循能力方面表现优于 Gemini-2.5-Pro，并且所提出的 EvolIF 基准测试框架为评估此类能力提供了一种更有效的途径。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [79] [SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties](https://arxiv.org/abs/2511.03542)
*Roberta Di Marino,Giovanni Dioguardi,Antonio Romano,Giuseppe Riccio,Mariano Barone,Marco Postiglione,Flora Amato,Vincenzo Moscato*

Main category: cs.CL

TL;DR: SOLVE-Med是一个多智能体架构，通过结合领域专业化的语言模型来解决医学问答系统面临的挑战，如幻觉、偏见和计算需求。它使用路由器智能体选择专家，并由编排器智能体合成响应，在意大利医疗论坛数据上表现优于独立模型，并支持本地部署。


<details>
  <summary>Details</summary>
Motivation: 医学问答系统在部署时面临幻觉、偏见、计算需求、隐私和专业知识需求等挑战。

Method: SOLVE-Med采用多智能体架构，结合了领域专业化的语言模型来处理复杂的医学查询。该系统包括一个用于动态选择专家的路由器智能体、十个在特定医学领域进行微调的模型（每个模型1B参数），以及一个用于合成响应的编排器智能体。

Result: 在跨越十个专科的意大利医疗论坛数据上进行评估，SOLVE-Med取得了0.301的ROUGE-1和0.697的BERTScore F1的优越性能，其表现优于参数量高达14B的独立模型，并支持本地部署。

Conclusion: SOLVE-Med通过利用领域专业化的语言模型，提供了一种有效的解决方案，以应对医学问答系统部署中的挑战，并在性能和效率方面取得了显著的改进。

Abstract: Medical question answering systems face deployment challenges including
hallucinations, bias, computational demands, privacy concerns, and the need for
specialized expertise across diverse domains. Here, we present SOLVE-Med, a
multi-agent architecture combining domain-specialized small language models for
complex medical queries. The system employs a Router Agent for dynamic
specialist selection, ten specialized models (1B parameters each) fine-tuned on
specific medical domains, and an Orchestrator Agent that synthesizes responses.
Evaluated on Italian medical forum data across ten specialties, SOLVE-Med
achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,
outperforming standalone models up to 14B parameters while enabling local
deployment. Our code is publicly available on GitHub:
https://github.com/PRAISELab-PicusLab/SOLVE-Med.

</details>


### [80] [Bearing Syntactic Fruit with Stack-Augmented Neural Networks](https://arxiv.org/abs/2511.03547)
*Brian DuSell,Ryan Cotterell*

Main category: cs.CL

TL;DR: 堆栈增强神经网络（Stack-augmented neural networks）在无需特定条件的情况下，也能像人类一样进行语言泛化，这表明它们可能是比标准网络更准确的人类语言习得模型。


<details>
  <summary>Details</summary>
Motivation: 研究现有的神经网络架构是否具备与人类儿童学习语言时相似的、偏好基于分层句法规则的假设的内在偏见。

Method: 测试了三种基础架构（Transformer、简单RNN、LSTM）与两种堆栈（Joulin & Mikolov (2015) 的叠加堆栈和 DuSell & Chiang (2023) 提出的非确定性泛化堆栈）的组合。

Result: Transformer 结合非确定性堆栈在经典的问题形成任务上泛化效果最好，并且提出了一种改进堆栈 RNN 架构以提升分层泛化的方法。

Conclusion: 堆栈增强神经网络可能是比标准架构更准确的人类语言习得模型，并可作为心理语言学研究的有用对象。

Abstract: Any finite set of training data is consistent with an infinite number of
hypothetical algorithms that could have generated it. Studies have shown that
when human children learn language, they consistently favor hypotheses based on
hierarchical syntactic rules without ever encountering disambiguating examples.
A recent line of work has inquired as to whether common neural network
architectures share this bias, finding that they do so only under special
conditions: when syntactically supervised, when pre-trained on massive corpora,
or when trained long past convergence. In this paper, we demonstrate, for the
first time, neural network architectures that are able to generalize in
human-like fashion without any of the aforementioned requirements:
stack-augmented neural networks. We test three base architectures (transformer,
simple RNN, LSTM) augmented with two styles of stack: the superposition stack
of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed
by DuSell & Chiang (2023). We find that transformers with nondeterministic
stacks generalize best out of these architectures on a classical question
formation task. We also propose a modification to the stack RNN architecture
that improves hierarchical generalization. These results suggest that
stack-augmented neural networks may be more accurate models of human language
acquisition than standard architectures, serving as useful objects of
psycholinguistic study. Our code is publicly available.

</details>


### [81] [MultiZebraLogic: A Multilingual Logical Reasoning Benchmark](https://arxiv.org/abs/2511.03553)
*Sofie Helene Bruun,Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 该研究提出了MultiZebraLogic数据集，用于评估大型语言模型（LLMs）的逻辑推理能力，特别是在多种语言和不同难度级别下。


<details>
  <summary>Details</summary>
Motivation: 旨在创建高质量、多语言的数据集，以评估和比较不同LLMs在逻辑推理方面的能力，并探索提高推理难度的方法。

Method: 生成多语言、多主题、多尺寸的斑马谜题，并包含不同类型的线索和干扰项。通过改变谜题尺寸和干扰项数量来调整难度，并评估GPT-4o mini和o3-mini模型的表现。

Result: 发现2x3和4x5的谜题尺寸对GPT-4o mini和o3-mini模型具有足够的挑战性。增加5个干扰项会将o3-mini在4x5谜题上的准确率降低15±7%。谜题语言（英语 vs. 丹麦语）和主题（普通 vs. 斯莫尔布罗德）对o3-mini的表现无显著影响。线索类型与难度之间无相关性。发布了包含128+1024个谜题的MultiZebraLogic数据集（9种日耳曼语言，2x3和4x5尺寸）及谜题生成代码。

Conclusion: MultiZebraLogic数据集为评估LLMs在逻辑推理方面的多语言能力提供了一个有价值的资源，并为未来的研究提供了可扩展的谜题生成工具。

Abstract: Measuring the full abilities of large language models (LLMs) requires
benchmarks representing multiple tasks. We aim to create large, high-quality
datasets for comparison of logical reasoning skills across several languages
and of suitable difficulty for LLMs of various reasoning ability. We explore
multiple ways of increasing difficulty. We generate zebra puzzles in multiple
languages, themes, sizes and including 14 different clue types and 8 red
herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are
sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a
reasoning model), respectively. Including 5 red herrings decreases o3-mini
puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5
puzzles are not significantly affected by use of English vs. Danish or the
common houses theme vs. the country-specific smoerrebroed theme. We find no
correlation between difficulty and the selected clue types. Datasets of
128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic
languages for sizes 2x3 and 4x5. We publish code for puzzle generation,
designed for adaptablity into more languages and themes.

</details>


### [82] [AILA--First Experiments with Localist Language Models](https://arxiv.org/abs/2511.03559)
*Joachim Diederich*

Main category: cs.CL

TL;DR: 本论文首次展示了 transformer 语言模型中可控局部性的经验证据，这是一种新颖的架构框架，可以通过可调的局部性旋钮参数对表示局部化的程度进行连续控制。


<details>
  <summary>Details</summary>
Motivation: 与传统仅依赖分布式表示的语言模型不同，我们的方法能够在无需重新训练模型的情况下，动态地在高度可解释的局域表示和高效的分布式表示之间进行插值。

Method: 我们在 WikiText 语料库上使用两层 transformer 架构进行了实验，系统地将局部性参数 λ 在 1.0（全局域）到 0.0（全分布式）的整个光谱范围内变化。

Result: 实验结果表明，局域配置可实现显著更低的注意力熵（λ = 1.0 时为 5.36 位，而 λ = 0.0 时为 7.18 位），同时保持更高的指针保真度分数，反映出与规则指定目标的更强对齐。预测实验显示，中间局部性值能够优化可解释性和性能之间的权衡，其中 λ = 0.6 可实现 4.65 的测试困惑度和 84.7% 的准确率。

Conclusion: 这些发现表明，局域语言模型为需要透明度和能力的受监管领域的应用提供了一个实用的框架，通过明确的惩罚阈值和信息论设计原则，对可解释性-性能谱进行精确的数学控制。

Abstract: This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

</details>


### [83] [ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation](https://arxiv.org/abs/2511.03563)
*One Octadion,Bondan Sapta Prakoso,Nanang Yudi Setiawan,Novanto Yudistira*

Main category: cs.CL

TL;DR: 通过微调和检索增强生成（RAG）来增强大型语言模型（LLMs）在法律监管领域的应用，以支持政策制定者。


<details>
  <summary>Details</summary>
Motivation: 为了更好地支持政策制定者理解、分析和制定法律法规，需要增强大型语言模型（LLMs）在法律文本理解方面的能力。

Method: 结合对法律领域特定需求进行微调的大型语言模型（LLMs）以及检索增强生成（RAG）方法，使LLM能够访问和整合外部最新法律知识。

Result: 该方法能够显著提高法律研究和法规制定的有效性，为不断发展的法律领域提供有价值的资源。

Conclusion: 通过微调和RAG相结合的方法，可以创建一个能够积极协助政策制定者解释法规和制定新法规的工具。

Abstract: In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

</details>


### [84] [Step-Audio-EditX Technical Report](https://arxiv.org/abs/2511.03601)
*Chao Yan,Boyong Wu,Peng Yang,Pengfei Tan,Guoqiang Hu,Yuxin Zhang,Xiangyu,Zhang,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: Step-Audio-EditX是一个开源的LLM驱动的音频模型，通过只使用大间隔合成数据，实现了富有表现力和可迭代的音频编辑，包括情绪、说话风格和副语言特征，并具有零样本文本到语音（TTS）能力。


<details>
  <summary>Details</summary>
Motivation: 传统音频编辑方法依赖于嵌入式先验或辅助模块，而Step-Audio-EditX旨在通过大间隔学习方法实现更直接和高效的音频编辑。

Method: Step-Audio-EditX 利用大间隔合成数据进行训练，避免了对嵌入式先验或辅助模块的依赖，从而实现了迭代控制和高表现力。

Result: 在情感编辑和其他细粒度控制任务上，Step-Audio-EditX 的表现优于 MiniMax-2.6-hd 和 Doubao-Seed-TTS-2.0。

Conclusion: Step-Audio-EditX 在音频编辑领域取得了显著进展，尤其是在情感和风格控制方面，其创新性的大间隔学习方法在性能上超越了现有模型。

Abstract: We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

</details>


### [85] [A systematic review of relation extraction task since the emergence of Transformers](https://arxiv.org/abs/2511.03610)
*Ringwald Celian,Gandon,Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 本文对Transformer模型出现以来自关系抽取（RE）的文献进行了系统性回顾，分析了2019-2024年间的34篇调查论文、64个数据集和104个模型，并讨论了方法进展、基准资源以及语义网技术集成，最后指出了当前趋势、局限性和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 对Transformer模型出现以来关系抽取（RE）领域的研究进行系统性回顾，以识别趋势、局限性和未来方向。

Method: 使用自动化框架收集和标注出版物，分析了34篇调查论文、64个数据集和104个模型，涵盖了方法进展、基准资源和语义网技术集成。

Result: 在方法、资源和技术集成方面取得了进展，并确定了当前趋势、局限性和开放性挑战。

Conclusion: 本研究为研究人员和实践者提供了一个全面的参考，以理解RE的演变和未来方向。

Abstract: This article presents a systematic review of relation extraction (RE)
research since the advent of Transformer-based models. Using an automated
framework to collect and annotate publications, we analyze 34 surveys, 64
datasets, and 104 models published between 2019 and 2024. The review highlights
methodological advances, benchmark resources, and the integration of semantic
web technologies. By consolidating results across multiple dimensions, the
study identifies current trends, limitations, and open challenges, offering
researchers and practitioners a comprehensive reference for understanding the
evolution and future directions of RE.

</details>


### [86] [Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability](https://arxiv.org/abs/2511.03635)
*Apoorva Upadhyaya,Wolfgang Nejdl,Marco Fisichella*

Main category: cs.CL

TL;DR: IRIS是一个新颖的可解释零样本立场检测（ZSSD）框架，它结合了文本内的隐式线索和语言学测量（显式线索）来识别帖子对未见过目标的态度，解决了现有方法泛化性差和解释性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有零样本立场检测（ZSSD）方法在泛化性和解释性方面存在不足，尤其是在依赖明确推理、解释粗糙以及未能明确建模推理过程等方面。本研究旨在解决这些问题，提供一个可解释的ZSSD框架。

Method: IRIS框架将立场检测视为信息检索排序任务，利用文本中的隐式线索（序列）和基于语言学测量的显式线索（交流特征）来理解文本对目标的情感和认知维度，从而在无需真实线索的情况下进行预测，并提供内在的可解释性。

Result: 在VAST、EZ-STANCE、P-Stance和RFD数据集上进行的大量实验，即使在10%的训练数据下，也证明了IRIS模型的泛化能力。

Conclusion: IRIS框架通过结合隐式和显式线索，提供了一种新颖且可解释的ZSSD方法，显著提高了模型在不同训练数据比例下的泛化能力。

Abstract: Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

</details>


### [87] [ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation](https://arxiv.org/abs/2511.03656)
*Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng*

Main category: cs.CL

TL;DR: ChiMDQA是一个针对中文文档的问答数据集，包含6068个高质量问答对，覆盖学术、教育、金融、法律、医疗和新闻等领域，适用于各种NLP任务。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，对高质量中文文档问答数据集的需求日益增长。

Method: 该数据集通过文档筛选和系统性的问题设计方法构建，包含长篇幅文档和10个细粒度分类的问答对。

Result: 构建了一个包含6068个高质量问答对的中文多文档问答数据集（ChiMDQA），覆盖6个不同领域。

Conclusion: ChiMDQA数据集为中文问答相关的未来研究和实际应用提供了坚实的基础。

Abstract: With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

</details>


### [88] [Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models](https://arxiv.org/abs/2511.03699)
*Francesco Corso,Francesco Pierri,Gianmarco De Francisci Morales*

Main category: cs.CL

TL;DR: LLMs可能表现出阴谋论倾向，并且存在社会人口统计学偏见，容易被诱导产生阴谋论观点。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地被用作研究人类行为的代理，但对其在阴谋论等更高层次心理建构上的表现知之甚少。本研究旨在填补这一研究空白，探讨LLMs的社会忠实度。

Method: 使用经过验证的心理测量学调查，在不同的提示和条件策略下，对多个模型进行测试，以衡量其阴谋论思维。

Result: LLMs在一定程度上认同阴谋论的某些元素，社会人口统计学属性的条件化会产生不均衡的影响，暴露了潜在的人口统计学偏见。此外，有针对性的提示可以轻松地将模型响应转向阴谋论方向。

Conclusion: LLMs容易受到操纵，在敏感环境中部署存在潜在风险。因此，必须批判性地评估LLMs中嵌入的心理维度，以推进计算社会科学并为应对潜在危害提供信息。

Abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

</details>


### [89] [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)
*Nan Li,Albert Gatt,Massimo Poesio*

Main category: cs.CL

TL;DR: 在对话中，参与者可能因为对指代对象的理解不一致而产生分歧，即使他们认为自己达成了共识。本研究提出了一种新的标注方案，用于分析HCRC MapTask语料库，该方案能够区分说话者和听话者对每个指代表达式的理解。通过利用LLM标注流程，我们获得了13k个标注的指代表达式，并分析了由此产生的理解状态。结果表明，一旦词汇变体被统一，完全的误解很少发生，但指代对象的不一致性会系统性地引起分歧，揭示了表面上的共识如何掩盖指代的不一致。本研究提出的框架为研究对话中的理解分歧和评估（V）LLM模拟视角相关理解的能力提供了资源和分析工具。


<details>
  <summary>Details</summary>
Motivation: 对话中的参与者可能在看似达成共识的情况下，实际上却指代了不同的实体，尤其是在信息不对称的情况下。本研究旨在通过一种新的标注方案来揭示这种分歧是如何产生的。

Method: 研究采用了一种视角主义标注方案，对HCRC MapTask语料库中的指代表达式分别标注说话者和听话者的理解。利用一个受约束的LLM标注流程，生成了13k个标注数据，并进行了可靠性评估。随后，分析了这些数据以研究理解状态的变化。

Result: 研究发现，在统一词汇变体后，完全的误解并不常见。然而，指代对象的不一致性（multiplicity discrepancies）会系统性地导致理解上的分歧，表明表面上的共识可能掩盖了指代对象的不一致。本研究还开发了一个框架，用于研究对话中的理解分歧，并评估（V）LLM在对话中模拟视角相关性的能力。

Conclusion: 通过视角主义标注方案和LLM分析，本研究揭示了对话中指代对象不一致性是导致理解分歧的关键因素，即使在表面共识下也可能存在潜在的指代不匹配。本研究提出的框架为理解和解决对话中的误解提供了新的视角和工具。

Abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [90] [Toward an Agricultural Operational Design Domain: A Framework](https://arxiv.org/abs/2511.02937)
*Mirco Felske,Jannik Redenius,Georg Happich,Julius Schöning*

Main category: cs.RO

TL;DR: 现有的农业自动化操作环境描述方法不足，本研究提出了农业操作设计域（Ag-ODD）框架，通过描述概念、7层模型和验证流程来解决这个问题，以支持农业自动化的标准化和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的操作设计域（ODD）概念未能充分解决农业自动化系统在复杂多变环境中运行所面临的独特挑战，无法提供结构化、透明且可验证的环境描述。

Method: 提出农业操作设计域（Ag-ODD）框架，包含三个核心要素：1. Ag-ODD描述概念，借鉴ASAM Open ODD和CityGML，用于定义环境和操作参数；2. 扩展的7层模型，增加了过程层以捕捉动态的农业作业；3. 迭代验证过程，通过逻辑场景确保Ag-ODD的完整性和一致性。

Result: Ag-ODD框架提供了一种创建清晰、可验证的Ag-ODD的一致方法，并通过示例用例展示了其在标准化和可扩展性方面的潜力。

Conclusion: Ag-ODD框架能够为农业自动化系统的环境描述提供标准化和可扩展的解决方案。

Abstract: The agricultural sector increasingly relies on autonomous systems that
operate in complex and variable environments. Unlike on-road applications,
agricultural automation integrates driving and working processes, each of which
imposes distinct operational constraints. Handling this complexity and ensuring
consistency throughout the development and validation processes requires a
structured, transparent, and verified description of the environment. However,
existing Operational Design Domain (ODD) concepts do not yet address the unique
challenges of agricultural applications.
  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,
which can be used to describe and verify the operational boundaries of
autonomous agricultural systems. The Ag-ODD Framework consists of three core
elements. First, the Ag-ODD description concept, which provides a structured
method for unambiguously defining environmental and operational parameters
using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model
derived from the PEGASUS 6-Layer Model, has been extended to include a process
layer to capture dynamic agricultural operations. Third, the iterative
verification process verifies the Ag-ODD against its corresponding logical
scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness
and consistency.
  Together, these elements provide a consistent approach for creating
unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD
Framework can support the standardization and scalability of environmental
descriptions for autonomous agricultural systems.

</details>


### [91] [Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data](https://arxiv.org/abs/2511.02994)
*Syed Mostaquim Ali,Taufiq Rahman,Ghazal Farhani,Mohamed H. Zaki,Benoit Anctil,Dominique Charlebois*

Main category: cs.RO

TL;DR: 该研究提出了一种评估自动驾驶虚拟测试环境（VTE）中激光雷达（LiDAR）扫描准确性的方法，并发现密度感知倒角距离（DCD）是最适合的评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了开发安全的自动驾驶系统（ADS），在部署前需要进行严格的测试。由于实际物理测试成本高且存在安全隐患，因此需要采用虚拟测试环境（VTE）。为了验证VTE的准确性，需要比较VTE生成的传感器输出和真实世界的数据。

Method: 该研究首先探索了一系列用于比较真实和模拟LiDAR扫描的评估指标，并测试了它们在不同噪声、密度、畸变、传感器方向和通道设置下的敏感性和准确性。然后，研究人员使用真实LiDAR扫描数据构建了一个VTE，并生成了模拟LiDAR扫描。最后，将模拟扫描与真实扫描在模型感知和几何相似性方面进行了比较。

Result: 在评估指标的比较中，发现密度感知倒角距离（DCD）在所有情况下表现最佳。在VTE的评估中，模拟和真实的LiDAR扫描在语义分割输出上具有相似的mIoU（21%），平均DCD为0.63。这表明模拟和真实LiDAR扫描在几何特性上存在细微差别，在模型输出上存在显著差异。研究还发现DCD与感知方法的相关性最高。

Conclusion: DCD是一种有效的评估LiDAR扫描之间几何相似性的指标，可用于验证VTE的准确性。尽管模拟LiDAR扫描在几何特性上与真实扫描存在一些差异，但DCD和mIoU等指标表明，VTE可以作为一种有前途的替代方案，用于替代成本高昂且有风险的实际测试。

Abstract: For developing safe Autonomous Driving Systems (ADS), rigorous testing is
required before they are deemed safe for road deployments. Since comprehensive
conventional physical testing is impractical due to cost and safety concerns,
Virtual Testing Environments (VTE) can be adopted as an alternative. Comparing
VTE-generated sensor outputs against their real-world analogues can be a strong
indication that the VTE accurately represents reality. Correspondingly, this
work explores a comprehensive experimental approach to finding evaluation
metrics suitable for comparing real-world and simulated LiDAR scans. The
metrics were tested in terms of sensitivity and accuracy with different noise,
density, distortion, sensor orientation, and channel settings. From comparing
the metrics, we found that Density Aware Chamfer Distance (DCD) works best
across all cases. In the second step of the research, a Virtual Testing
Environment was generated using real LiDAR scan data. The data was collected in
a controlled environment with only static objects using an instrumented vehicle
equipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from
the VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans
were compared in terms of model perception and geometric similarity. Actual and
simulated LiDAR scans have a similar semantic segmentation output with a mIoU
of 21\% with corrected intensity and an average density aware chamfer distance
(DCD) of 0.63. This indicates a slight difference in the geometric properties
of simulated and real LiDAR scans and a significant difference between model
outputs. During the comparison, density-aware chamfer distance was found to be
the most correlated among the metrics with perception methods.

</details>


### [92] [A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics](https://arxiv.org/abs/2511.03075)
*Markus Buchholz,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: AURA是一个结合了大型语言模型（LLM）、高保真数字孪生（DT）和人工干预的自主弹性代理框架，用于机器人技术的异常和故障诊断。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域安全部署自主系统需要结合人类专业知识和人工智能驱动的分析，特别是处理不可预见异常时。

Method: AURA框架包含两个智能体：状态异常表征智能体（监测遥测数据，生成结构化自然语言问题描述）和诊断推理智能体（进行基于知识的对话以识别根本原因）。该框架利用LLM、DT和人工干预，并通过人类验证的诊断来改进模型。

Result: 该框架能够实时检测和响应异常行为，并通过持续的反馈循环不断改进，将AI从静态工具转变为自适应伙伴。

Conclusion: AURA框架为构建可信赖、持续改进的人机协作团队提供了一种模式。

Abstract: The safe deployment of autonomous systems in safety-critical settings
requires a paradigm that combines human expertise with AI-driven analysis,
especially when anomalies are unforeseen. We introduce AURA (Autonomous
Resilience Agent), a collaborative framework for anomaly and fault diagnostics
in robotics. AURA integrates large language models (LLMs), a high-fidelity
digital twin (DT), and human-in-the-loop interaction to detect and respond to
anomalous behavior in real time. The architecture uses two agents with clear
roles: (i) a low-level State Anomaly Characterization Agent that monitors
telemetry and converts signals into a structured natural-language problem
description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a
knowledge-grounded dialogue with an operator to identify root causes, drawing
on external sources. Human-validated diagnoses are then converted into new
training examples that refine the low-level perceptual model. This feedback
loop progressively distills expert knowledge into the AI, transforming it from
a static tool into an adaptive partner. We describe the framework's operating
principles and provide a concrete implementation, establishing a pattern for
trustworthy, continually improving human-robot teams.

</details>


### [93] [WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models](https://arxiv.org/abs/2511.03077)
*R. Khorrambakht,Joaquim Ortiz-Haro,Joseph Amigo,Omar Mostafa,Daniel Dugas,Franziska Meier,Ludovic Righetti*

Main category: cs.RO

TL;DR: 行为克隆（BC）需要特定任务的演示数据，难以迁移到新任务且数据收集困难。本文提出了一种基于模型的方法，使用易于收集的非结构化玩耍数据来学习动作条件视觉世界模型、基于扩散的模型动作采样器，并可选地学习奖励模型。然后，结合世界模型、动作采样器和奖励模型，使用蒙特卡洛树搜索（MCTS）规划器来优化长序列动作。最后，通过零阶模型预测控制器（MPC）在机器人上执行规划的动作。该方法在真实机器人任务上进行了验证，证明了规划相比于BC基线方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 机器人需要理解环境并推断动作后果来完成复杂任务。现有的行为克隆（BC）方法在数据收集和任务迁移方面存在挑战。

Method: 收集非结构化的玩耍数据，学习动作条件视觉世界模型、基于扩散的模型动作采样器和奖励模型。利用MCTS规划器和MPC控制器来优化和执行动作。

Result: 在3个不同复杂度的真实机器人任务上进行了实验验证，规划方法相比于BC基线方法在标准操作测试环境中表现出显著提升。

Conclusion: 基于模型的方法，结合世界模型、动作采样器和MCTS规划，能够有效解决机器人任务，并且在数据收集和任务迁移方面优于行为克隆方法。

Abstract: Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.

</details>


### [94] [3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors](https://arxiv.org/abs/2511.03078)
*Rohan Kota,Kaival Shah,J. Edward Colgate,Gregory Reardon*

Main category: cs.RO

TL;DR: 该研究提出了一个名为libname的开源库，它能将低成本3D打印机改造成自动化探测设备，用于为触觉传感器校准生成大量带标签的训练数据。研究通过使用libname校准了两个商业化的视觉触觉传感器（DIGIT和GelSight Mini），并使用自定义的卷积神经网络来重建高质量的深度图。此外，研究还进行了数据量消融实验，以确定准确校准所需的数据量，并对训练好的模型在未见过物体上的表现进行了基准测试，以评估校准精度和泛化能力。libname自动化了触觉传感器的校准过程，旨在加速触觉传感器的研究，简化传感器的部署，并促进触觉传感器在机器人平台上的实际应用。


<details>
  <summary>Details</summary>
Motivation: 触觉传感在机器人操控中至关重要，但其校准过程繁琐且耗时。本研究旨在解决触觉传感器校准的这一痛点。

Method: 本研究提出libname库，利用3D打印机自动化收集触觉传感器校准所需的带标签数据，并结合自定义的卷积神经网络模型进行校准和深度图重建。同时，进行数据量消融实验和模型在未见过物体上的基准测试。

Result: 研究成功使用libname库校准了DIGIT和GelSight Mini触觉传感器，并实现了高质量的深度图重建。数据消融实验为特定传感器提供了准确校准所需数据的实用指南，模型在未见过物体上的测试评估了校准精度和泛化能力。

Conclusion: libname库通过自动化触觉传感器校准，能够加速相关研究，简化传感器部署，并促进触觉传感技术在机器人领域的实际应用。

Abstract: Tactile sensing plays a key role in enabling dexterous and reliable robotic
manipulation, but realizing this capability requires substantial calibration to
convert raw sensor readings into physically meaningful quantities. Despite its
near-universal necessity, the calibration process remains ad hoc and
labor-intensive. Here, we introduce \libname{}, an open-source library that
transforms a low-cost 3D printer into an automated probing device capable of
generating large volumes of labeled training data for tactile sensor
calibration. We demonstrate the utility of \libname{} by calibrating two
commercially available vision-based tactile sensors, DIGIT and GelSight Mini,
to reconstruct high-quality depth maps using the collected data and a custom
convolutional neural network. In addition, we perform a data ablation study to
determine how much data is needed for accurate calibration, providing practical
guidelines for researchers working with these specific sensors, and we
benchmark the trained models on previously unseen objects to evaluate
calibration accuracy and generalization performance. By automating tactile
sensor calibration, \libname{} can accelerate tactile sensing research,
simplify sensor deployment, and promote the practical integration of tactile
sensing in robotic platforms.

</details>


### [95] [SENT Map -- Semantically Enhanced Topological Maps with Foundation Models](https://arxiv.org/abs/2511.03165)
*Raj Surya Rajendran Kathirvel,Zach A Chavis,Stephen J. Guy,Karthik Desingh*

Main category: cs.RO

TL;DR: SENT-Map是一个用于室内环境的语义增强拓扑地图，通过JSON格式存储，支持自主导航和操作。


<details>
  <summary>Details</summary>
Motivation: 为机器人自主导航和操作提供一种新的室内环境表示方法，并利用基础模型（FMs）的能力。

Method: 提出了一种两阶段方法：1.使用Vision-FM和操作员进行环境映射。 2.利用SENT-Map表示和自然语言查询，结合FM进行路径规划。

Result: 实验结果表明，语义增强使得小型本地部署的FM也能够成功地在室内环境中进行规划。

Conclusion: SENT-Map通过语义增强，提高了FM在室内导航和规划方面的能力。

Abstract: We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.

</details>


### [96] [Multi-robot searching with limited sensing range for static and mobile intruders](https://arxiv.org/abs/2511.03622)
*Swadhin Agrawal,Sujoy Bhore,Joseph S. B. Mitchell,P. B. Sujit,Aayush Gohil*

Main category: cs.RO

TL;DR: 使用多机器人搜索简单连通正交多边形内的静态或移动入侵者，考虑到机器人传感能力和搜索区域的几何特性。该问题 NP-hard，因此研究了基于空间填充曲线、随机搜索和协同随机搜索的算法，并评估了机器人数量与搜索时间之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在具有有限传感能力的多机器人搜索场景下，研究一个简单连通正交多边形内的静态或移动入侵者的问题。

Method: 研究了使用空间填充曲线、随机搜索和协同随机搜索的算法，并分析了机器人数量与搜索时间之间的权衡。

Result: 搜索问题被证明是 NP-hard 的。研究了基于空间填充曲线、随机搜索和协同随机搜索的算法。

Conclusion: 鉴于问题的 NP-hard 性质，研究了启发式算法，并评估了机器人数量和搜索时间之间的权衡。

Abstract: We consider the problem of searching for an intruder in a geometric domain by
utilizing multiple search robots. The domain is a simply connected orthogonal
polygon with edges parallel to the cartesian coordinate axes. Each robot has a
limited sensing capability. We study the problem for both static and mobile
intruders. It turns out that the problem of finding an intruder is NP-hard,
even for a stationary intruder. Given this intractability, we turn our
attention towards developing efficient and robust algorithms, namely methods
based on space-filling curves, random search, and cooperative random search.
Moreover, for each proposed algorithm, we evaluate the trade-off between the
number of search robots and the time required for the robots to complete the
search process while considering the geometric properties of the connected
orthogonal search area.

</details>


### [97] [Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.03167)
*Xin Liu,Jinze Wu,Yinghui Li,Chenkun Qi,Yufei Xue,Feng Gao*

Main category: cs.RO

TL;DR: 使用基于运动先验的深度强化学习方法，在真实六足机器人上实现了复杂地形的行走，并展示了自然的步态和出色的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 协调多足机器人的多条腿以生成自然稳健的运动，这是一个关键问题，尤其是在较大的动作探索空间中。

Method: 生成一个优化的运动先验数据集，并训练一个基于这些先验的对抗性判别器来指导六足机器人学习自然的步态。然后将学习到的策略转移到真实的六足机器人上。

Result: 所提出的方法在真实六足机器人上成功实现了复杂地形的行走，展示了自然的步态和出色的鲁棒性，并且在没有视觉信息的情况下也能运行。

Conclusion: 这是首次成功地将强化学习控制器应用于真实六足机器人，以实现复杂地形行走。

Abstract: Multi-legged robots offer enhanced stability to navigate complex terrains
with their multiple legs interacting with the environment. However, how to
effectively coordinate the multiple legs in a larger action exploration space
to generate natural and robust movements is a key issue. In this paper, we
introduce a motion prior-based approach, successfully applying deep
reinforcement learning algorithms to a real hexapod robot. We generate a
dataset of optimized motion priors, and train an adversarial discriminator
based on the priors to guide the hexapod robot to learn natural gaits. The
learned policy is then successfully transferred to a real hexapod robot, and
demonstrate natural gait patterns and remarkable robustness without visual
information in complex terrains. This is the first time that a reinforcement
learning controller has been used to achieve complex terrain walking on a real
hexapod robot.

</details>


### [98] [Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control](https://arxiv.org/abs/2511.03181)
*Rewida Ali,Cristian C. Beltran-Hernandez,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: LLM驱动的任务规划器和混合IL/RL策略相结合，实现高效的机器人礼物包装。


<details>
  <summary>Details</summary>
Motivation: 在仓库和零售等环境中，需要机器人与人类协作处理易变形物体，但现有技术在适应性和力控制方面存在挑战。

Method: 提出了一种基于学习的框架，集成了LLM驱动的高层任务规划器和低层混合IL/RL策略（START），利用人类演示学习统一策略，并引入子任务ID来捕捉长期时间依赖性。

Result: 在真实世界的包装任务中实现了97%的成功率，展示了统一策略的优势，如减少模型专业化需求、实现可控的人类监督以及有效连接高层意图和精细力控制。

Conclusion: 所提出的学习框架能够成功处理涉及易变形物体的长期操作任务，并在真实机器人应用中表现出高成功率。

Abstract: Human-robot cooperation is essential in environments such as warehouses and
retail stores, where workers frequently handle deformable objects like paper,
bags, and fabrics. Coordinating robotic actions with human assistance remains
difficult due to the unpredictable dynamics of deformable materials and the
need for adaptive force control. To explore this challenge, we focus on the
task of gift wrapping, which exemplifies a long-horizon manipulation problem
involving precise folding, controlled creasing, and secure fixation of paper.
Success is achieved when the robot completes the sequence to produce a neatly
wrapped package with clean folds and no tears.
  We propose a learning-based framework that integrates a high-level task
planner powered by a large language model (LLM) with a low-level hybrid
imitation learning (IL) and reinforcement learning (RL) policy. At its core is
a Sub-task Aware Robotic Transformer (START) that learns a unified policy from
human demonstrations. The key novelty lies in capturing long-range temporal
dependencies across the full wrapping sequence within a single model. Unlike
vanilla Action Chunking with Transformer (ACT), typically applied to short
tasks, our method introduces sub-task IDs that provide explicit temporal
grounding. This enables robust performance across the entire wrapping process
and supports flexible execution, as the policy learns sub-goals rather than
merely replicating motion sequences.
  Our framework achieves a 97% success rate on real-world wrapping tasks. We
show that the unified transformer-based policy reduces the need for specialized
models, allows controlled human supervision, and effectively bridges high-level
intent with the fine-grained force control required for deformable object
manipulation.

</details>


### [99] [Collaborative Assembly Policy Learning of a Sightless Robot](https://arxiv.org/abs/2511.03189)
*Zeqing Zhang,Weifeng Lu,Lei Yang,Wei Jing,Bowei Tang,Jia Pan*

Main category: cs.RO

TL;DR: 提出了一种新颖的强化学习方法，该方法利用人工设计的导纳控制器来促进更积极的机器人行为并减轻人类的努力，并在模拟和现实世界实验中证明其在成功率和任务完成时间方面优于导纳控制。


<details>
  <summary>Details</summary>
Motivation: 导纳控制在物理人机协作（pHRC）任务中常用，但难以准确测量人类意图，限制了机器人的辅助能力。现有的强化学习（RL）方法因安全限制和稀疏奖励而不适用于板条插入任务。

Method: 提出了一种新颖的强化学习（RL）方法，该方法利用人工设计的导纳控制器来促进更积极的机器人行为并减轻人类的努力。

Result: 与导纳控制相比，所提出的方法在成功率和任务完成时间方面均表现更优，并且在测得的力和扭矩方面有显著降低。

Conclusion: 所提出的新颖强化学习方法在物理人机协作的板条插入任务中优于传统的导纳控制方法。

Abstract: This paper explores a physical human-robot collaboration (pHRC) task
involving the joint insertion of a board into a frame by a sightless robot and
a human operator. While admittance control is commonly used in pHRC tasks, it
can be challenging to measure the force/torque applied by the human for
accurate human intent estimation, limiting the robot's ability to assist in the
collaborative task. Other methods that attempt to solve pHRC tasks using
reinforcement learning (RL) are also unsuitable for the board-insertion task
due to its safety constraints and sparse rewards. Therefore, we propose a novel
RL approach that utilizes a human-designed admittance controller to facilitate
more active robot behavior and reduce human effort. Through simulation and
real-world experiments, we demonstrate that our approach outperforms admittance
control in terms of success rate and task completion time. Additionally, we
observed a significant reduction in measured force/torque when using our
proposed approach compared to admittance control. The video of the experiments
is available at https://youtu.be/va07Gw6YIog.

</details>


### [100] [GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement](https://arxiv.org/abs/2511.03400)
*Minquan Gao,Xinyi Li,Qing Yan,Xiaojian Sun,Xiaopan Zhang,Chien-Ming Huang,Jiachen Li*

Main category: cs.RO

TL;DR: GUIDES是一个轻量级框架，通过引入基础模型的语义指导来增强预训练的机器人策略，而无需进行架构重设计。它使用微调的视觉-语言模型（Instructor）生成指令，并通过辅助模块将其编码为指导嵌入，然后注入到策略的潜在空间中。一个基于大型语言模型的Reflector在推理时监控Instructor的置信度，并在置信度低时启动一个推理循环来优化后续动作。该框架在RoboCasa仿真环境中得到了广泛验证，并在实际的UR5机器人部署中证明了其有效性，提高了运动精度。


<details>
  <summary>Details</summary>
Motivation: 预训练的机器人策略缺乏语义意识，而完全替换它们成本高昂且会丢失累积的知识。GUIDES旨在解决此问题，在不替换原有策略的情况下增强其语义理解能力。

Method: GUIDES首先使用微调的视觉-语言模型（Instructor）生成上下文指令，然后将其编码为指导嵌入。这些嵌入被注入到策略的潜在空间中，并通过简短的、有针对性的微调来调整原有策略。此外，一个基于大型语言模型的Reflector在推理时监控Instructor的置信度，并在需要时启动一个推理循环来优化动作。

Result: 在RoboCasa仿真环境中，GUIDES在多种策略架构下均显著提高了任务成功率。在UR5机器人上的实际部署也证明了GUIDES能够提高抓取等关键子任务的运动精度。

Conclusion: GUIDES提供了一种实用且资源高效的方法，可以升级而非替换已验证的机器人策略，从而赋予它们基础模型般的语义意识。

Abstract: Pre-trained robot policies serve as the foundation of many validated robotic
systems, which encapsulate extensive embodied knowledge. However, they often
lack the semantic awareness characteristic of foundation models, and replacing
them entirely is impractical in many situations due to high costs and the loss
of accumulated knowledge. To address this gap, we introduce GUIDES, a
lightweight framework that augments pre-trained policies with semantic guidance
from foundation models without requiring architectural redesign. GUIDES employs
a fine-tuned vision-language model (Instructor) to generate contextual
instructions, which are encoded by an auxiliary module into guidance
embeddings. These embeddings are injected into the policy's latent space,
allowing the legacy model to adapt to this new semantic input through brief,
targeted fine-tuning. For inference-time robustness, a large language
model-based Reflector monitors the Instructor's confidence and, when confidence
is low, initiates a reasoning loop that analyzes execution history, retrieves
relevant examples, and augments the VLM's context to refine subsequent actions.
Extensive validation in the RoboCasa simulation environment across diverse
policy architectures shows consistent and substantial improvements in task
success rates. Real-world deployment on a UR5 robot further demonstrates that
GUIDES enhances motion precision for critical sub-tasks such as grasping.
Overall, GUIDES offers a practical and resource-efficient pathway to upgrade,
rather than replace, validated robot policies.

</details>


### [101] [Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach](https://arxiv.org/abs/2511.03444)
*Vesna Poprcova,Iulia Lefter,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 科技在心理健康领域的应用仍有待开发，本文旨在通过研讨会收集用户对社交机器人在社交焦虑支持方面的期望和需求。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑症的普遍性及其治疗支持的不足，促使研究者探索利用社交机器人技术来补充传统心理健康服务。

Method: 通过设计研讨会，邀请心理学学术研究者参与，运用创意、反思和设想活动，系统地收集关于设计社交机器人以支持社交焦虑症患者的价值观、期望、需求和偏好。

Result: 研究结果揭示了适应性、可接受性和有效性等对社交焦虑支持至关重要的设计相关价值观。

Conclusion: 本研究强调了研究驱动的价值发掘方法的重要性，并强调在开发社交支持机器人时应考虑以用户为中心和情境感知的设计原则。

Abstract: Social anxiety is a prevalent mental health condition that can significantly
impact overall well-being and quality of life. Despite its widespread effects,
adequate support or treatment for social anxiety is often insufficient.
Advances in technology, particularly in social robotics, offer promising
opportunities to complement traditional mental health. As an initial step
toward developing effective solutions, it is essential to understand the values
that shape what is considered meaningful, acceptable, and helpful. In this
study, a participatory design workshop was conducted with mental health
academic researchers to elicit the underlying values that should inform the
design of socially assistive robots for social anxiety support. Through
creative, reflective, and envisioning activities, participants explored
scenarios and design possibilities, allowing for systematic elicitation of
values, expectations, needs, and preferences related to robot-supported
interventions. The findings reveal rich insights into design-relevant
values-including adaptivity, acceptance, and efficacy-that are core to support
for individuals with social anxiety. This study highlights the significance of
a research-led approach to value elicitation, emphasising user-centred and
context-aware design considerations in the development of socially assistive
robots.

</details>


### [102] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: Dex-Hand 021是一个高性能、轻量化（1公斤）的五指仿生机械手，具有19个自由度，并采用基于本体力传感的导纳控制方法，在抓取和操作任务中表现出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 开发兼具灵活性、工程约束（复杂性、尺寸/重量比、耐用性、力传感性能）和人类敏捷性的灵巧机器人手。

Method: 提出了一种具有12个主动自由度和7个被动自由度的线驱动五指机器人手（Dex-Hand 021），并采用基于本体力传感的导纳控制方法。

Result: 单指负载能力>10N，指尖重复性<0.001m，力估计误差<0.2N。与PID控制相比，多物体抓取中的关节力矩降低了31.19%。成功执行了33种GRASP分类的运动和复杂操作任务。

Conclusion: Dex-Hand 021在轻量化、工业级灵巧手设计和本体感知控制方面取得了进展，有助于机器人操作和智能制造。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>


### [103] [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications](https://arxiv.org/abs/2511.03497)
*Lei Fu,Sahar Salimpour,Leonardo Militano,Harry Edelman,Jorge Peña Queralta,Giovanni Toffetti*

Main category: cs.RO

TL;DR: 本文提出一个用于分析ROS和ROS2数据包的MCP服务器，实现通过自然语言与大语言模型（LLM）和视觉语言模型（VLM）交互来分析、可视化和处理机器人数据。


<details>
  <summary>Details</summary>
Motivation: Agentic AI和Embodied AI是人工智能和机器人领域的关键研究方向，而MCP正成为Agentic应用的重要组成部分。然而，Agentic Embodied AI的交叉领域研究尚不充分。

Method: 本文介绍了一个MCP服务器，该服务器可以分析ROS和ROS2数据包，并支持使用LLM和VLM通过自然语言来分析、可视化和处理机器人数据。该工具集专注于移动机器人领域，原生支持轨迹、激光雷达扫描数据、变换或时间序列数据的分析，并能与标准的ROS 2 CLI工具交互，还能根据话题或时间进行数据筛选。此外，还提供了一个轻量级UI，用于在不同LLM（包括专有和开源模型）上对该工具进行基准测试。

Result: 通过对八种不同的SOTA LLM/VLM模型（包括专有和开源、大型和小型模型）的工具调用能力进行实验分析，结果表明模型在工具调用能力上存在显著差异，Kimi K2和Claude Sonnet 4表现出明显更优越的性能。

Conclusion: 实验结果表明，模型在工具调用成功率方面存在巨大差距，Kimi K2和Claude Sonnet 4表现最为出色。同时，工具描述模式、参数数量以及可用工具的数量等多种因素都会影响成功率。

Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing an interface to standard ROS 2
CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
filter bags with a subset of topics or trimmed in time. Coupled with the MCP
server, we provide a lightweight UI that allows the benchmarking of the tooling
with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
(through Groq). Our experimental results include the analysis of tool calling
capabilities of eight different state-of-the-art LLM/VLM models, both
proprietary and open-source, large and small. Our experiments indicate that
there is a large divide in tool calling capabilities, with Kimi K2 and Claude
Sonnet 4 demonstrating clearly superior performance. We also conclude that
there are multiple factors affecting the success rates, from the tool
description schema to the number of arguments, as well as the number of tools
available to the models. The code is available with a permissive license at
https://github.com/binabik-ai/mcp-rosbags.

</details>


### [104] [Indicating Robot Vision Capabilities with Augmented Reality](https://arxiv.org/abs/2511.03550)
*Hong Wang,Ridhima Phatak,James Ocampo,Zhao Han*

Main category: cs.RO

TL;DR: 研究发现人类会错误地认为机器人的视野（FoV）与人类相同，这可能导致人机协作任务失败。为解决此问题，研究提出了四种增强现实（AR）中的视野指示器，并通过用户实验评估了其准确性、置信度、任务效率和工作量。结果表明，任务空间中的外源性指示器准确性最高，但存在延迟。机器人眼窝的内源性指示器也提高了准确性。所有指示器均显示参与者置信度高，认知负荷低。最后，研究提出了六条实用指南，以帮助从业者对齐人机心智模型。


<details>
  <summary>Details</summary>
Motivation: 人类常常误解机器人的视野（FoV）与人类相同，这可能导致在人机协作任务中，机器人被要求完成超出其视野范围的任务，从而引发失败。尤其在机器人专注于任务而无法扫描环境更新其世界模型时，问题更为严重。

Method: 提出四种增强现实（AR）中的视野（FoV）指示器，并将它们应用于一项包含41名参与者的用户实验中，以评估其在准确性、置信度、任务效率和工作量方面的表现。这些指示器涵盖了从内源性（机器人的视角和头部空间）到外源性（任务空间）的范围。

Result: 研究结果显示，位于任务空间的外源性指示器准确性最高，但解读机器人视野存在一定的延迟。内源性的“更深的眼窝”指示器（可通过物理改造实现）也提高了准确性。在所有指示器下，参与者的置信度均较高，而认知负荷保持在较低水平。

Conclusion: 研究提出了六条实用指南，旨在帮助从业者在实际应用中利用AR指示器或物理改造来对齐人类对机器人视觉能力的心智模型。

Abstract: Research indicates that humans can mistakenly assume that robots and humans
have the same field of view (FoV), possessing an inaccurate mental model of
robots. This misperception may lead to failures during human-robot
collaboration tasks where robots might be asked to complete impossible tasks
about out-of-view objects. The issue is more severe when robots do not have a
chance to scan the scene to update their world model while focusing on assigned
tasks. To help align humans' mental models of robots' vision capabilities, we
propose four FoV indicators in augmented reality (AR) and conducted a user
human-subjects experiment (N=41) to evaluate them in terms of accuracy,
confidence, task efficiency, and workload. These indicators span a spectrum
from egocentric (robot's eye and head space) to allocentric (task space).
Results showed that the allocentric blocks at the task space had the highest
accuracy with a delay in interpreting the robot's FoV. The egocentric indicator
of deeper eye sockets, possible for physical alteration, also increased
accuracy. In all indicators, participants' confidence was high while cognitive
load remained low. Finally, we contribute six guidelines for practitioners to
apply our AR indicators or physical alterations to align humans' mental models
with robots' vision capabilities.

</details>


### [105] [OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera](https://arxiv.org/abs/2511.03571)
*Hao Shi,Ze Wang,Shangwei Guo,Mengfei Duan,Song Wang,Teng Chen,Kailun Yang,Lin Wang,Kaiwei Wang*

Main category: cs.RO

TL;DR: OneOcc是一个视觉全景语义场景补全框架，专为双足/人形机器人设计，解决了步态抖动和360度连续性问题。它通过双投影融合、双网格体素化、轻量级解码器和步态位移补偿等技术，实现了SOTA性能，并发布了两个全景占用数据集。


<details>
  <summary>Details</summary>
Motivation: 现有语义场景补全系统主要针对轮式机器人和前向传感器，未能满足双足/人形机器人在步态运动中对鲁棒的3D语义占用感知需求。

Method: OneOcc采用以下关键技术：(i)双投影融合 (DP-ER) 保持360度连续性和网格对齐；(ii)双网格体素化 (BGV) 融合笛卡尔和柱面极坐标空间以减少离散化偏差；(iii)轻量级解码器与分层AMoE-3D进行多尺度融合和长距离/遮挡推理；(iv)即插即用的步态位移补偿 (GDC) 进行特征级运动校正。

Result: OneOcc在QuadOcc和Human360Occ（H3O）数据集上均取得了SOTA性能。在H3O数据集上，分别在城市内和跨城市测试中提升了3.83 mIoU和8.08 mIoU。其模块轻量化，可实现可部署的全方位感知。

Conclusion: OneOcc是一个高效且有效的视觉全景语义场景补全框架，能够为双足/人形机器人提供鲁棒的3D语义占用感知，解决了现有技术的局限性，并在相关数据集上取得了显著的性能提升。

Abstract: Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
semantic scene completion (SSC) systems target wheeled platforms with
forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
framework designed for gait-introduced body jitter and 360{\deg} continuity.
OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
cylindrical-polar spaces, reducing discretization bias and sharpening
free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
motion correction without extra sensors. We also release two panoramic
occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
occupancy; standardized within-/cross-city splits). OneOcc sets new
state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
(cross-city). Modules are lightweight, enabling deployable full-surround
perception for legged/humanoid robots. Datasets and code will be publicly
available at https://github.com/MasterHow/OneOcc.

</details>


### [106] [Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution](https://arxiv.org/abs/2511.03576)
*Aniol Civit,Antonio Andriella,Carles Sierra,Guillem Alenyà*

Main category: cs.RO

TL;DR: 该研究提出了一个名为MUP-QBAF的多用户偏好量化双边论证框架，用于解决多用户人机交互中的偏好冲突，该框架能够动态适应环境变化并结合用户输入和机器人观察。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互个性化方法主要关注单用户适应，忽略了涉及多个具有潜在冲突偏好的利益相关者的情况。本研究旨在解决这一问题。

Method: 提出了一种基于量化双边论证框架（QBAFs）的新型多用户个性化框架（MUP-QBAF），明确地对多用户偏好冲突进行建模和解决。该框架结合了用户的论点和机器人对环境的动态观察，并根据新信息迭代地重新计算偏好的强度。

Result: 通过一个现实的案例研究进行了验证，该案例研究涉及一个辅助机器人在照顾者和接受护理者之间就衰弱评估任务进行偏好调解。进行了论证基础分数的敏感性分析，以展示偏好结果如何受到用户输入和情境观察的影响。

Conclusion: 该框架为解决相互竞争的用户偏好提供了一种透明、结构化和情境敏感的方法，推动了多用户人机交互领域的发展。它为数据驱动的方法提供了一个原则性的替代方案，使机器人能够在真实环境中处理冲突。

Abstract: While personalisation in Human-Robot Interaction (HRI) has advanced
significantly, most existing approaches focus on single-user adaptation,
overlooking scenarios involving multiple stakeholders with potentially
conflicting preferences. To address this, we propose the Multi-User Preferences
Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user
personalisation framework based on Quantitative Bipolar Argumentation
Frameworks (QBAFs) that explicitly models and resolves multi-user preference
conflicts. Unlike prior work in Argumentation Frameworks, which typically
assumes static inputs, our approach is tailored to robotics: it incorporates
both users' arguments and the robot's dynamic observations of the environment,
allowing the system to adapt over time and respond to changing contexts.
Preferences, both positive and negative, are represented as arguments whose
strength is recalculated iteratively based on new information. The framework's
properties and capabilities are presented and validated through a realistic
case study, where an assistive robot mediates between the conflicting
preferences of a caregiver and a care recipient during a frailty assessment
task. This evaluation further includes a sensitivity analysis of argument base
scores, demonstrating how preference outcomes can be shaped by user input and
contextual observations. By offering a transparent, structured, and
context-sensitive approach to resolving competing user preferences, this work
advances the field of multi-user HRI. It provides a principled alternative to
data-driven methods, enabling robots to navigate conflicts in real-world
environments.

</details>


### [107] [Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning](https://arxiv.org/abs/2511.03591)
*Qingyi Chen,Ruiqi Ni,Jun Kim,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 该研究提出了一种用于分散式多智能体运动规划（MAMP）的流形约束HJR学习框架，以解决任务约束下的安全MAMP问题。


<details>
  <summary>Details</summary>
Motivation: 在机器人技术中，安全的多智能体运动规划（MAMP）在任务约束下是一个关键挑战，尤其是在需要机器人遵守多种约束（如服务机器人必须竖直携带杯子并避开碰撞）的真实场景中。尽管在分散式MAMP方面取得了进展，但加入流形约束仍然困难。

Method: 提出了一种流形约束的Hamilton-Jacobi可达性（HJR）学习框架，用于分散式MAMP。该方法在流形约束下求解HJR问题，以捕捉任务感知的安全条件，并将其集成到分散式轨迹优化规划器中。

Result: 实验表明，该方法优于现有的约束运动规划器，并且运行速度适用于实际应用，能够生成安全且任务可行的运动计划，而无需对其他智能体的策略进行假设，并且能够推广到各种流形约束任务并有效地扩展到高维多智能体操作问题。

Conclusion: 所提出的流形约束HJR学习框架能够有效地解决分散式MAMP中的任务约束安全问题，并具有良好的泛化性和可扩展性。

Abstract: Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .

</details>


### [108] [Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural](https://arxiv.org/abs/2511.03651)
*Andrei A. Korigodskii,Oleg D. Kalachev,Artem E. Vasiunik,Matvei V. Urvantsev,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 该论文介绍了无人机绘制巨型壁画的创新设计和部署。


<details>
  <summary>Details</summary>
Motivation: 解决在户外（如风和阳光直射）等不利条件下，保持艺术精度和运行可靠性的双重挑战。

Method: 提出了一种结合红外运动捕捉相机和激光雷达技术的新型导航系统，以及一种独特的控制架构，并辅以轨迹规划和路径优化算法，最后设计了定制化的喷漆机构。

Result: 实验结果证明了该系统在不同条件下的鲁棒性和精确性。

Conclusion: 该系统展示了大规模自主艺术创作的潜力，并扩展了机器人技术在创意领域的应用。

Abstract: This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.

</details>


### [109] [Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments](https://arxiv.org/abs/2511.03652)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 该研究提出了一种在不确定环境中，使用形式化逻辑（scLTL）进行运动规划的新方法。


<details>
  <summary>Details</summary>
Motivation: 在不确定环境中，机器人需要根据带有概率语义标签的地图来完成一系列按顺序、空间和逻辑约束的任务。

Method: 提出了一种基于自动机理论的方法，构建了一个特殊的乘积自动机来处理语义标签的不确定性，并为该自动机的边设计了奖励函数，同时利用价值迭代进行在线重规划。

Result: 通过理论分析和仿真/实验验证了该方法的有效性。

Conclusion: 所提出的方法能够有效地处理不确定环境下的复杂运动规划任务。

Abstract: This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.

</details>


### [110] [Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design](https://arxiv.org/abs/2511.03676)
*Taito Tashiro,Tomoko Yonezawa,Hirotake Yamazoe*

Main category: cs.RO

TL;DR: 人类运动线索可用于设计富有表现力的机器人手臂运动，特别是运动的后期和撤回阶段。


<details>
  <summary>Details</summary>
Motivation: 研究人类运动线索如何用于设计富有表现力的机器人手臂运动。

Method: 通过分析人类在“Geister”游戏中两种运动（自然游戏和指令表情）来创建机器人运动，并通过物理机器人和视频评估观察者的印象。

Result: 人类运动的后期（特别是撤回阶段）对印象形成至关重要，物理实体增强了运动线索的可解释性。

Conclusion: 基于人类计时行为设计富有表现力的机器人运动。

Abstract: This study investigates how human motion cues can be used to design
expressive robot-arm movements. Using the imperfect-information game Geister,
we analyzed two types of human piece-moving motions: natural gameplay
(unconscious tendencies) and instructed expressions (intentional cues). Based
on these findings, we created phase-specific robot motions by varying movement
speed and stop duration, and evaluated observer impressions under two
presentation modalities: a physical robot and a recorded video. Results
indicate that late-phase motion timing, particularly during withdrawal, plays
an important role in impression formation and that physical embodiment enhances
the interpretability of motion cues. These findings provide insights for
designing expressive robot motions based on human timing behavior.

</details>


### [111] [Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping](https://arxiv.org/abs/2511.03691)
*Zhihang Qin,Yueheng Zhang,Wan Su,Linxin Hou,Shenghao Zhou,Zhijun Chen,Yu Jun Tan,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该研究介绍了一种自给式软体夹爪，它通过内部液体重新分配在三个相互连接的、具有双稳态弹跳特性的腔室中进行操作，从而实现稳定且尺寸选择性的抓取，无需持续的能量输入。


<details>
  <summary>Details</summary>
Motivation: 传统的流体驱动软体夹爪依赖外部能源，限制了其便携性和长期自主性。本研究旨在克服这一限制，提供一种便携、自主的软体夹爪。

Method: 通过内部液体在三个相互连接的、具有双稳态弹跳特性的腔室中的重新分配来驱动夹爪。顶部的传感腔室在接触时变形，其移位的液体会触发抓取腔室的弹跳式扩张。

Result: 实现了稳定且尺寸选择性的抓取，无需持续的能量输入。内部液压反馈能够被动地适应抓取压力以匹配物体的硬度。

Conclusion: 这种无外部能源且结构紧凑的设计为软体机器人领域中轻量化、硬度自适应的流体驱动操作开辟了新的可能性，为在水下和野外环境中进行目标尺寸特定的采样和操作提供了一种可行的方法。

Abstract: Conventional fluid-driven soft grippers typically depend on external sources,
which limit portability and long-term autonomy. This work introduces a
self-contained soft gripper with fixed size that operates solely through
internal liquid redistribution among three interconnected bistable snap-through
chambers. When the top sensing chamber deforms upon contact, the displaced
liquid triggers snap-through expansion of the grasping chambers, enabling
stable and size-selective grasping without continuous energy input. The
internal hydraulic feedback further allows passive adaptation of gripping
pressure to object stiffness. This source-free and compact design opens new
possibilities for lightweight, stiffness-adaptive fluid-driven manipulation in
soft robotics, providing a feasible approach for targeted size-specific
sampling and operation in underwater and field environments.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [112] [Establishing Trust in Crowdsourced Data](https://arxiv.org/abs/2511.03016)
*Iffat Gheyas,Muhammad Rizwan Asghar,Steve Schneider,Alan Woodward*

Main category: cs.SI

TL;DR: Crowdsourced data is useful but faces trust issues. This paper analyzes trust management on various platforms and proposes solutions using AI and better community engagement to improve data reliability and fairness.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the challenges of misinformation, errors, and power concentration in crowdsourced data by systematically examining trust management practices and proposing solutions.

Method: The study categorizes platforms (Volunteered Geographic Information, Wiki Ecosystems, Social Media, Mobile Crowdsensing, Specialised Review and Environmental Crowdsourcing) and identifies strengths and limitations in their trust management practices.

Result: Identified strengths include automated moderation and community validation. Limitations involve rapid data influx, niche oversight gaps, opaque trust metrics, and elite dominance.

Conclusion: The paper proposes solutions like advanced AI, transparent reputation metrics, decentralized moderation, structured community engagement, and a "soft power" strategy to improve data reliability and equitably distribute decision-making authority.

Abstract: Crowdsourced data supports real-time decision-making but faces challenges
like misinformation, errors, and contributor power concentration. This study
systematically examines trust management practices across platforms categorised
as Volunteered Geographic Information, Wiki Ecosystems, Social Media, Mobile
Crowdsensing, and Specialised Review and Environmental Crowdsourcing.
Identified strengths include automated moderation and community validation,
while limitations involve rapid data influx, niche oversight gaps, opaque trust
metrics, and elite dominance. Proposed solutions incorporate advanced AI tools,
transparent reputation metrics, decentralised moderation, structured community
engagement, and a ``soft power'' strategy, aiming to equitably distribute
decision-making authority and enhance overall data reliability.

</details>


### [113] [Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research to Journalism and Policy-making](https://arxiv.org/abs/2511.03378)
*Yangliu Fan,Kilian Buehling,Volker Stocker*

Main category: cs.SI

TL;DR: 研究使用新文本方法衡量社科知识在新闻和政策领域的传播，发现知识传播模式因理论而异，且跨领域含义不同，主要用于意义构建和行政用途。


<details>
  <summary>Details</summary>
Motivation: 衡量社科知识在不同领域的传播具有重要意义，但目前存在挑战，本研究旨在通过新方法解决此问题。

Method: 使用72,703份文件（2000-2019），通过文本分析方法追踪了7个媒体效果理论在研究、新闻和政策制定三个领域中的提及次数、领域特定语境，并利用嵌入回归方法比较了跨领域含义的差异。

Result: 发现不同理论的传播模式差异显著；研究与政策之间的语境距离通常大于研究与新闻之间的距离；理论在不同领域扮演不同角色，从研究中的理论本身到新闻中的意义构建，再到政策中的应用和行政用途；随着时间推移，主要与实践相关的理论语义趋同。

Conclusion: 研究以知识理论层面揭示了社科知识跨领域传播的模式和动态，并讨论了超越引文计量方法的知识传播衡量意义。

Abstract: Despite the importance of social science knowledge for various stakeholders,
measuring its diffusion into different domains remains a challenge. This study
uses a novel text-based approach to measure the idea-level diffusion of social
science knowledge from the research domain to the journalism and policy-making
domains. By doing so, we expand the detection of knowledge diffusion beyond the
measurements of direct references. Our study focuses on media effects theories
as key research ideas in the field of communication science. Using 72,703
documents (2000-2019) from three domains (i.e., research, journalism, and
policy-making) that mention these ideas, we count the mentions of these ideas
in each domain, estimate their domain-specific contexts, and track and compare
differences across domains and over time. Overall, we find that diffusion
patterns and dynamics vary considerably between ideas, with some ideas
diffusing between other domains, while others do not. Based on the embedding
regression approach, we compare contextualized meanings across domains and find
that the distances between research and policy are typically larger than
between research and journalism. We also find that ideas largely shift roles
across domains - from being the theories themselves in research to sense-making
in news to applied, administrative use in policy. Over time, we observe
semantic convergence mainly for ideas that are practically oriented. Our
results characterize the cross-domain diffusion patterns and dynamics of social
science knowledge at the idea level, and we discuss the implications for
measuring knowledge diffusion beyond citations.

</details>


### [114] [A local eigenvector centrality](https://arxiv.org/abs/2511.03608)
*Ruaridh A. Clark,Francesca Arrigo,Agathe Bouis,Malcolm Macdonald*

Main category: cs.SI

TL;DR: 提出了一种局部特征向量中心性，结合了局部和全局连通性，以识别中心节点和社区结构。


<details>
  <summary>Details</summary>
Motivation: 现有的特征向量中心性主要衡量全局连通性，但忽略了局部社区结构的重要性。本研究旨在提出一种新的中心性度量，能够同时考虑局部和全局连通性，以更准确地识别节点和社区的重要性。

Method: 提出了一种局部特征向量中心性度量，该度量通过引用显著的特征值间隙并结合相关的特征谱（使用欧氏范数）来检测中心性，从而反映了显著的社区结构的影响。

Result: 在联系人网络中，局部特征向量中心性识别出的节点和社区分布与仅应用于孤立社区的特征向量中心性以及 PageRank 相似但有所不同。这种差异揭示了不符合其定义的局部结构的节点和社区。在没有明确社区划分的网络（如城市道路网络）中，局部特征向量中心性能够同时识别出局部突出的中心节点和全局连通的中心节点。

Conclusion: 局部特征向量中心性是一种创新的中心性度量方法，它能够有效地结合局部和全局网络信息，并能识别出不符合局部社区结构的节点，以及在不同类型网络中（有清晰社区结构或无清晰社区结构）的中心节点。

Abstract: Eigenvector centrality is an established measure of global connectivity, from
which the importance and influence of nodes can be inferred. We introduce a
local eigenvector centrality that incorporates both local and global
connectivity. This new measure references prominent eigengaps and combines
their associated eigenspectrum, via the Euclidean norm, to detect centrality
that reflects the influence of prominent community structures. In contact
networks, with clearly defined community structures, local eigenvector
centrality is shown to identify similar but distinct distributions to
eigenvector centrality applied on each community in isolation and PageRank.
Discrepancies between the two eigenvector measures highlight nodes and
communities that do not conform to their defined local structures, e.g. nodes
with more connections outside of their defined community than within it. While
reference to PageRank's centrality assessment enables a mitigation strategy for
localisation effects inherent in eigenvector-based measures. In networks
without clearly defined communities, such as city road networks, local
eigenvector centrality is shown to identify both locally prominent and globally
connected hubs.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [115] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS是一个状态感知、感知中断的框架，用于解决大型语言模型（LLM）在多智能体规划中的脆弱性问题，通过分离规划与非循环验证、记录版本化执行日志以及执行本地化修复来提高效率、可行性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在多智能体规划中虽然灵活，但在实际应用中存在脆弱性，如验证循环、状态跟踪缺失以及全局重新计算成本高昂等问题。

Method: ALAS框架将规划与非循环验证分离，使用独立于规划LLM的验证器，并记录版本化执行日志以进行检查和恢复。修复协议仅编辑最小受影响区域，并采用显式策略（重试、捕获、超时、回退、幂等键、补偿、循环保护）。

Result: 在作业车间调度测试（DMU、TA）和五个经典基准测试中，ALAS的成功率达到83.7%，令牌使用量减少60%，运行速度提高1.82倍，表现优于单LLM和多智能体基线。验证器能以低开销检测注入的结构性故障，本地化修复能以有限的编辑半径控制运行时扰动。

Conclusion: 验证器隔离、版本化执行日志和本地化修复的结合，能够显著提高多智能体LLM规划的效率、可行性和可扩展性。

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [116] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: MCS是一种多任务通信方法，可以通过学习通信协议来同时学习和执行多个任务，从而提高多智能体深度强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体深度强化学习中，智能体可以通过通信进行协作，并利用跨任务知识来提高学习效率。然而，现有的方法在处理多任务和通信方面存在不足。

Method: MCS使用Transformer编码器将特定任务的观测编码为共享消息空间，并引入预测网络来关联消息和发送智能体的动作，以增强智能体间的协调。该方法被应用于改编后的三个多智能体基准环境。

Result: 实验结果表明，MCS在多任务设置下优于不带通信的多任务基线方法，以及带通信和不带通信的单任务基线方法。

Conclusion: MCS成功地实现了多任务协同学习，并通过通信机制提高了智能体在多任务环境中的学习和执行能力。

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [117] [Mathematical exploration and discovery at scale](https://arxiv.org/abs/2511.02864)
*Bogdan Georgiev,Javier Gómez-Serrano,Terence Tao,Adam Zsolt Wagner*

Main category: cs.NE

TL;DR: AlphaEvolve是一个结合了大型语言模型生成能力和自动化评估的进化算法代理，能够自主发现新的数学构造并解决长期存在的数学难题。


<details>
  <summary>Details</summary>
Motivation: 演示AlphaEvolve作为自主发现新数学构造和增进对长期未解决问题理解的工具。

Method: AlphaEvolve结合了大型语言模型的生成能力和自动化评估，在一个迭代的进化框架中提出、测试和改进算法解决方案。研究考虑了涵盖数学分析、组合学、几何学和数论的67个问题。

Result: AlphaEvolve在大多数情况下重新发现了已知最佳解决方案，并在一些情况下发现了改进的解决方案。该系统能够将有限数量输入值的推论推广为对所有输入值都有效的公式。此外，该方法还可以与Deep Think和AlphaProof结合，形成一个更广泛的框架，由证明助手和推理系统提供自动证明生成和进一步的数学见解。

Conclusion: 大型语言模型引导的进化搜索可以自主发现数学构造，可与人类直觉相媲美，甚至有所超越，这预示着数学家与人工智能系统之间存在着重要的交互方式。AlphaEvolve作为一个强大的数学发现新工具，能够以简化的准备和计算时间要求探索巨大的搜索空间，以解决复杂的优化问题。

Abstract: AlphaEvolve is a generic evolutionary coding agent that combines the
generative capabilities of LLMs with automated evaluation in an iterative
evolutionary framework that proposes, tests, and refines algorithmic solutions
to challenging scientific and practical problems. In this paper we showcase
AlphaEvolve as a tool for autonomously discovering novel mathematical
constructions and advancing our understanding of long-standing open problems.
  To demonstrate its breadth, we considered a list of 67 problems spanning
mathematical analysis, combinatorics, geometry, and number theory. The system
rediscovered the best known solutions in most of the cases and discovered
improved solutions in several. In some instances, AlphaEvolve is also able to
generalize results for a finite number of input values into a formula valid for
all input values. Furthermore, we are able to combine this methodology with
Deep Think and AlphaProof in a broader framework where the additional
proof-assistants and reasoning systems provide automated proof generation and
further mathematical insights.
  These results demonstrate that large language model-guided evolutionary
search can autonomously discover mathematical constructions that complement
human intuition, at times matching or even improving the best known results,
highlighting the potential for significant new ways of interaction between
mathematicians and AI systems. We present AlphaEvolve as a powerful new tool
for mathematical discovery, capable of exploring vast search spaces to solve
complex optimization problems at scale, often with significantly reduced
requirements on preparation and computation time.

</details>


### [118] [A Novel Reservoir Computing Framework for Chaotic Time Series Prediction Using Time Delay Embedding and Random Fourier Features](https://arxiv.org/abs/2511.02877)
*S. K. Laha*

Main category: cs.NE

TL;DR: 本研究提出一种结合时间延迟嵌入和随机傅里叶特征映射的新型水库计算（RC）框架，用于高效预测混沌时间序列。


<details>
  <summary>Details</summary>
Motivation: 预测混沌时间序列需要能够捕捉其内在吸引子几何结构且计算效率高的模型。

Method: 提出一种不依赖传统递归结构的水库计算框架，该框架整合了时间延迟嵌入和随机傅里叶特征（RFF）映射来构建动态水库。该方法通过显式近似非线性核变换来揭示重构相空间中的潜在动态关系，从而富集水库的有效动态表征，并减少对手动水库超参数的依赖。

Result: 在 Mackey-Glass 方程、Lorenz 系统和 Kuramoto-Sivashinsky 方程等典型的混沌系统上进行了评估，结果表明该框架实现了优越的预测精度、鲁棒的吸引子重构和长视界预测。

Conclusion: 将时间延迟嵌入和基于 RFF 的水库相结合，通过在富集特征空间中嵌入系统，揭示了新的动态结构，为模拟混沌动力学提供了一种计算高效且可解释的方法。

Abstract: Forecasting chaotic time series requires models that can capture the
intrinsic geometry of the underlying attractor while remaining computationally
efficient. We introduce a novel reservoir computing (RC) framework that
integrates time-delay embedding with Random Fourier Feature (RFF) mappings to
construct a dynamical reservoir without the need for traditional recurrent
architectures. Unlike standard RC, which relies on high-dimensional recurrent
connectivity, the proposed RFF-RC explicitly approximates nonlinear kernel
transformations that uncover latent dynamical relations in the reconstructed
phase space. This hybrid formulation offers two key advantages: (i) it provides
a principled way to approximate complex nonlinear interactions among delayed
coordinates, thereby enriching the effective dynamical representation of the
reservoir, and (ii) it reduces reliance on manual reservoir hyperparameters
such as spectral radius and leaking rate. We evaluate the framework on
canonical chaotic systems-the Mackey-Glass equation, the Lorenz system, and the
Kuramoto-Sivashinsky equation. This novel formulation demonstrates that RFF-RC
not only achieves superior prediction accuracy but also yields robust attractor
reconstructions and long-horizon forecasts. These results show that the
combination of delay embedding and RFF-based reservoirs reveals new dynamical
structure by embedding the system in an enriched feature space, providing a
computationally efficient and interpretable approach to modeling chaotic
dynamics.

</details>


### [119] [Performance Evaluation of Bitstring Representations in a Linear Genetic Programming Framework](https://arxiv.org/abs/2511.02897)
*Clyde Meli,Vitezslav Nezval,Zuzana Kominkova Oplatkova,Victor Buttigieg,Anthony Spiteri Staines*

Main category: cs.NE

TL;DR: 不同的位串表示法在计算性能上有所不同。这项工作比较了 C++ 中的三种位串实现：std::bitset、boost::dynamic_bitset 和自定义的直接实现，并在线性遗传编程系统的串联中对它们的性能进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 比较三种位串实现（std::bitset、boost::dynamic_bitset 和自定义实现）在 C++ 中的计算性能，并评估平台特定的性能差异。

Method: 在 macOS、Linux 和 Windows MSYS2 三个平台上，对三种位串实现（std::bitset、boost::dynamic_bitset 和自定义实现）在线性遗传编程系统的串联上下文中的性能进行了基准测试。

Result: 在 Linux 和 Windows 上，自定义直接实现提供了最快的性能；而在 macOS 上，std::bitset 性能最佳。boost::dynamic_bitset 尽管速度较慢，但仍然是一个可行的选择。

Conclusion: 研究结果表明，编译器优化和系统架构会影响性能，并为根据平台和应用程序需求选择最佳方法提供了实践指导。

Abstract: Different bitstring representations can yield varying computational
performance. This work compares three bitstring implementations in C++:
std::bitset, boost::dynamic_bitset, and a custom direct implementation. Their
performance is benchmarked in the context of concatenation within a Linear
Genetic Programming system. Benchmarks were conducted on three platforms
(macOS, Linux, and Windows MSYS2) to assess platform specific performance
variations. The results show that the custom direct implementation delivers the
fastest performance on Linux and Windows, while std::bitset performs best on
macOS. Although consistently slower, boost::dynamic_bitset remains a viable and
flexible option. These findings highlight the influence of compiler
optimisations and system architecture on performance, providing practical
guidance for selecting the optimal method based on platform and application
requirements.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [120] [AI-Enhanced Wi-Fi Sensing Through Single Transceiver Pair](https://arxiv.org/abs/2511.02845)
*Yuxuan Liu,Chiya Zhang,Yifeng Yuan,Chunlong He,Weizheng Zhang,Gaojie Chen*

Main category: eess.SP

TL;DR: AI技术通过利用先验信息和时间相关性，在硬件受限条件下显著提升了Wi-Fi传感系统的感知精度，克服了传统雷达理论的局限性。


<details>
  <summary>Details</summary>
Motivation: 下一代Wi-Fi技术依赖于传感能力，需要在大规模部署中实现高精度感知，同时降低带宽和天线数量要求。

Method: 提出并验证了一个基于AI的Wi-Fi传感系统，该系统利用单一收发器对，并通过实验验证了先验信息和时间相关性在人体姿态估计和室内定位中的作用。

Result: 实验结果证实了时间相关性和先验信息对提升Wi-Fi传感系统性能的贡献。

Conclusion: AI技术通过利用先验信息和时间相关性，为硬件受限的Wi-Fi传感系统带来了性能提升，克服了传统雷达理论的局限性。

Abstract: The advancement of next-generation Wi-Fi technology heavily relies on sensing
capabilities, which play a pivotal role in enabling sophisticated applications.
In response to the growing demand for large-scale deployments, contemporary
Wi-Fi sensing systems strive to achieve high-precision perception while
maintaining minimal bandwidth consumption and antenna count requirements.
Remarkably, various AI-driven perception technologies have demonstrated the
ability to surpass the traditional resolution limitations imposed by radar
theory. However, the theoretical underpinnings of this phenomenon have not been
thoroughly investigated in existing research. In this study, we found that
under hardware-constrained conditions, the performance gains brought by AI to
Wi-Fi sensing systems primarily originate from two aspects: prior information
and temporal correlation. Prior information enables the AI to generate
plausible details based on vague input, while temporal correlation helps reduce
the upper bound of sensing error. We developed an AI-based Wi-Fi sensing system
using a single transceiver pair and designed experiments focusing on human pose
estimation and indoor localization to validate the theoretical claims. The
results confirm the performance gains contributed by temporal correlation and
prior information.

</details>


### [121] [Spatio-Temporal Attention Network for Epileptic Seizure Prediction](https://arxiv.org/abs/2511.02846)
*Zan Li,Kyongmin Yeo,Wesley Gifford,Lara Marcuse,Madeline Fields,Bülent Yener*

Main category: eess.SP

TL;DR: 提出了一种名为STAN（时空注意力网络）的深度学习框架，用于准确预测癫痫患者的发作。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于特征工程和/或固定的发作前时段假设，本研究提出了一种同时对时空相关性进行建模并采用对抗性判别器来区分发作前和发作间注意力模式的方法，实现了患者特定的学习。

Method: 使用时空注意力网络（STAN）对脑电图（EEG）信号进行时空相关性建模，并采用对抗性判别器区分发作前和发作间注意力模式。

Result: 在CHB-MIT和MSSM数据集上进行了评估，CHB-MIT数据集的敏感性为96.6%，错误检测率为0.011/h；MSSM数据集的敏感性为94.2%，错误检测率为0.063/h，显著优于最先进的方法。

Conclusion: 该框架能够可靠地在发作前至少15分钟检测到发作前状态，患者特定的检测窗口可延长至45分钟，为临床应用提供了充足的干预时间。

Abstract: In this study, we present a deep learning framework that learns complex
spatio-temporal correlation structures of EEG signals through a Spatio-Temporal
Attention Network (STAN) for accurate predictions of onset of seizures for
Epilepsy patients. Unlike existing methods, which rely on feature engineering
and/or assume fixed preictal durations, our approach simultaneously models
spatio-temporal correlations through STAN and employs an adversarial
discriminator to distinguish preictal from interictal attention patterns,
enabling patient-specific learning. Evaluation on CHB-MIT and MSSM datasets
demonstrates 96.6\% sensitivity with 0.011/h false detection rate on CHB-MIT,
and 94.2% sensitivity with 0.063/h FDR on MSSM, significantly outperforming
state-of-the-art methods. The framework reliably detects preictal states at
least 15 minutes before an onset, with patient-specific windows extending to 45
minutes, providing sufficient intervention time for clinical applications.

</details>


### [122] [EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding](https://arxiv.org/abs/2511.02848)
*Shantanu Sarkar,Piotr Nabrzyski,Saurabh Prasad,Jose Luis Contreras-Vidal*

Main category: eess.SP

TL;DR: EEGReXferNet是一个轻量级生成式AI框架，用于通过跨主体迁移学习进行EEG子空间重建，可提高信噪比并支持实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有EEG信号去噪方法存在手动干预、抑制神经特征或计算量大、不适用于实时应用等问题。

Method: 提出EEGReXferNet框架，利用卷绕、带状卷积编码、动态潜在特征提取、参考基准缩放等技术，并通过跨主体迁移学习实现EEG子空间重建。

Result: EEGReXferNet在空间-时间-频谱分辨率方面表现优异（平均PSD相关性>=0.95；平均频谱图RV系数>=0.85），减少了~45%的权重，并保持了计算效率。

Conclusion: EEGReXferNet能够有效提高EEG信号质量，适用于神经生理学和BCI应用的实时预处理。

Abstract: Electroencephalography (EEG) is a widely used non-invasive technique for
monitoring brain activity, but low signal-to-noise ratios (SNR) due to various
artifacts often compromise its utility. Conventional artifact removal methods
require manual intervention or risk suppressing critical neural features during
filtering/reconstruction. Recent advances in generative models, including
Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs),
have shown promise for EEG reconstruction; however, these approaches often lack
integrated temporal-spectral-spatial sensitivity and are computationally
intensive, limiting their suitability for real-time applications like
brain-computer interfaces (BCIs). To overcome these challenges, we introduce
EEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction
via cross-subject transfer learning - developed using Keras TensorFlow
(v2.15.1). EEGReXferNet employs a modular architecture that leverages volume
conduction across neighboring channels, band-specific convolution encoding, and
dynamic latent feature extraction through sliding windows. By integrating
reference-based scaling, the framework ensures continuity across successive
windows and generalizes effectively across subjects. This design improves
spatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean
spectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate
overfitting, and maintains computational efficiency for robust, real-time EEG
preprocessing in neurophysiological and BCI applications.

</details>


### [123] [Real-Time Interactive Hybrid Ocean: Spectrum-Consistent Wave Particle-FFT Coupling](https://arxiv.org/abs/2511.02852)
*Shengze Xue,Yu Ren,Jiacheng Hong,Run Ni,Shuangjiu Xiao,Deli Dong*

Main category: eess.SP

TL;DR: 该研究提出了一种混合海洋模拟方法，结合了FFT和波浪粒子，实现了大规模真实感和实时交互性。


<details>
  <summary>Details</summary>
Motivation: 现有FFT海洋模拟方法难以处理非均匀海面和近场交互（如船只），而波浪粒子方法计算成本高且难以匹配全局谱统计。本研究旨在结合两者的优点，实现大规模真实感和精细化交互性的统一。

Method: 提出了一种混合海洋模拟方法：全局FFT背景与局部波浪粒子（WP）区域相结合，在补丁边界处根据相同的方向谱注入粒子，以匹配能量密度并与背景对齐。该方法包含两个创新点：1. 混合海洋表示：全局FFT背景与局部WP补丁在统一谱下耦合；2. 基于频率桶的实现：设计了基于频率桶的粒子采样和GPU并行合成方案。

Result: 实现了大规模谱真实感和精细化交互性的统一，并达到了实时交互性能。

Conclusion: 所提出的混合海洋模拟方法通过结合FFT和波浪粒子的优势，并采用基于频率桶的实现方案，成功解决了现有方法的局限性，实现了大规模真实感和实时交互性的统一。

Abstract: Fast Fourier Transform-based (FFT) spectral oceans are widely adopted for
their efficiency and large-scale realism, but they assume global stationarity
and spatial homogeneity, making it difficult to represent non-uniform seas and
near-field interactions (e.g., ships and floaters). In contrast, wave particles
capture local wakes and ripples, yet are costly to maintain at scale and hard
to match global spectral statistics.We present a real-time interactive hybrid
ocean: a global FFT background coupled with local wave-particle (WP) patch
regions around interactive objects, jointly driven under a unified set of
spectral parameters and dispersion. At patch boundaries, particles are injected
according to the same directional spectrum as the FFT, aligning the local
frequency-direction distribution with the background and matching energy
density, without disturbing the far field.Our approach introduces two main
innovations: (1) Hybrid ocean representation. We couple a global FFT background
with local WP patches under a unified spectrum, achieving large-scale spectral
consistency while supporting localized wakes and ripples.(2) Frequency-bucketed
implementation. We design a particle sampling and GPU-parallel synthesis scheme
based on frequency buckets, which preserves spectral energy consistency and
sustains real-time interactive performance.Together, these innovations enable a
unified framework that delivers both large-scale spectral realism and
fine-grained interactivity in real time.

</details>


### [124] [Benchmarking ResNet for Short-Term Hypoglycemia Classification with DiaData](https://arxiv.org/abs/2511.02849)
*Beyza Cinar,Maria Maleshkova*

Main category: eess.SP

TL;DR: 该研究通过对DiaData数据集进行数据清洗和插值，解决了T1D医疗数据分析中的数据质量问题，并在此基础上分析了血糖与心率的关系，最后构建了一个用于预测低血糖的ResNet模型。


<details>
  <summary>Details</summary>
Motivation: 为了改进T1D（1型糖尿病）的个体化治疗，需要对医疗数据进行可靠的分析，但现有数据存在异常值、噪声、数据量小和缺失值等问题，影响分析的准确性。

Method: 1. 使用IQR方法识别异常值并用缺失值替换。2. 对小于等于25分钟的小时间隙使用线性插值，对大于等于30分钟且小于120分钟的大时间隙使用Stineman插值。3. 分析清洗后数据中血糖与心率的相关性。4. 使用ResNet模型对DiaData的Maindatabase和Subdatabase II进行训练，以提前预测低血糖。

Result: 1. 提出了一种数据清洗方法，提高了DiaData数据集的质量。2. 发现血糖与心率在低血糖发生前15至60分钟存在中度相关性。3. 训练的ResNet模型能提前2小时预测低血糖，使用更多数据可提升7%的性能，使用高质量数据可比原始数据提升2-3%的性能。

Conclusion: 通过数据清洗和插值提高了T1D数据的质量，为分析血糖与心率的关系提供了基础，并构建了一个有效的低血糖预测模型，为T1D的个体化治疗提供了支持。

Abstract: Individualized therapy is driven forward by medical data analysis, which
provides insight into the patient's context. In particular, for Type 1 Diabetes
(T1D), which is an autoimmune disease, relationships between demographics,
sensor data, and context can be analyzed. However, outliers, noisy data, and
small data volumes cannot provide a reliable analysis. Hence, the research
domain requires large volumes of high-quality data. Moreover, missing values
can lead to information loss. To address this limitation, this study improves
the data quality of DiaData, an integration of 15 separate datasets containing
glucose values from 2510 subjects with T1D. Notably, we make the following
contributions: 1) Outliers are identified with the interquartile range (IQR)
approach and treated by replacing them with missing values. 2) Small gaps
($\le$ 25 min) are imputed with linear interpolation and larger gaps ($\ge$ 30
and $<$ 120 min) with Stineman interpolation. Based on a visual comparison,
Stineman interpolation provides more realistic glucose estimates than linear
interpolation for larger gaps. 3) After data cleaning, the correlation between
glucose and heart rate is analyzed, yielding a moderate relation between 15 and
60 minutes before hypoglycemia ($\le$ 70 mg/dL). 4) Finally, a benchmark for
hypoglycemia classification is provided with a state-of-the-art ResNet model.
The model is trained with the Maindatabase and Subdatabase II of DiaData to
classify hypoglycemia onset up to 2 hours in advance. Training with more data
improves performance by 7% while using quality-refined data yields a 2-3% gain
compared to raw data.

</details>


### [125] [ECGXtract: Deep Learning-based ECG Feature Extraction for Automated CVD Diagnosis](https://arxiv.org/abs/2511.02850)
*Youssif Abuzied,Hassan AbdEltawab,Abdelrhman Gaber,Tamer ElBatt*

Main category: eess.SP

TL;DR: ECGXtract 使用深度学习提取可解释的心电图特征，在预测临床真实值方面表现出色，优于现有方法，并探讨了多特征提取的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统心电图信号处理和黑盒机器学习方法在特征提取方面存在局限性，无法提供可解释性。

Method: 开发了卷积神经网络模型，用于提取与临床验证的真实值具有强相关性的时间形态特征。模型被训练用于提取单个特征，以确保输出的精确性和可解释性。随后进行了多组实验，评估了全局与导联特定特征、不同采样频率以及与其他方法（如ECGdeli）的比较。

Result: ECGXtract 在大多数特征上均表现出稳健的性能，全局特征与真实值的平均相关得分为 0.80，其中导联 II 的结果最好。导联特定特征的平均相关得分为 0.822。与现有最先进的开源方法 ECGdeli 相比，ECGXtract 在 90% 的特征上获得了更高的与真实值的相关得分。同时，研究还发现，使用单个模型同时提取多个特征是可行的，其中语义分组对全局特征有效，但大规模分组和导联特定多输出模型性能有所下降。

Conclusion: ECGXtract 在提取可解释的心电图特征方面显示出巨大潜力，其性能优于现有方法。研究结果强调了结构化分组策略在平衡计算效率和模型准确性方面的作用，为在资源有限的环境中构建可扩展且临床可解释的心电图特征提取系统铺平了道路。

Abstract: This paper presents ECGXtract, a deep learning-based approach for
interpretable ECG feature extraction, addressing the limitations of traditional
signal processing and black-box machine learning methods. In particular, we
develop convolutional neural network models capable of extracting both temporal
and morphological features with strong correlations to a clinically validated
ground truth. Initially, each model is trained to extract a single feature,
ensuring precise and interpretable outputs. A series of experiments is then
carried out to evaluate the proposed method across multiple setups, including
global versus lead-specific features, different sampling frequencies, and
comparisons with other approaches such as ECGdeli. Our findings show that
ECGXtract achieves robust performance across most features with a mean
correlation score of 0.80 with the ground truth for global features, with lead
II consistently providing the best results. For lead-specific features,
ECGXtract achieves a mean correlation score of 0.822. Moreover, ECGXtract
achieves superior results to the state-of-the-art open source ECGdeli as it got
a higher correlation score with the ground truth in 90% of the features.
Furthermore, we explore the feasibility of extracting multiple features
simultaneously utilizing a single model. Semantic grouping is proved to be
effective for global features, while large-scale grouping and lead-specific
multi-output models show notable performance drops. These results highlight the
potential of structured grouping strategies to balance the computational
efficiency vs. model accuracy, paving the way for more scalable and clinically
interpretable ECG feature extraction systems in limited resource settings.

</details>


### [126] [Approaching Low-Cost Cardiac Intelligence with Semi-Supervised Knowledge Distillation](https://arxiv.org/abs/2511.02851)
*Rushuang Zhou,Yuan-Ting Zhang,M. Jamal Deen,Yining Dong*

Main category: eess.SP

TL;DR: LiteHeart是一个利用可穿戴设备数据进行心脏监测的半监督知识蒸馏框架，有效缩小了低成本心脏智能（LCCI）与高成本心脏智能（HCCI）之间的诊断性能差距。


<details>
  <summary>Details</summary>
Motivation: 部署先进的心脏人工智能进行日常心脏监测受到其对广泛医疗数据和高计算资源依赖的阻碍。低成本心脏智能（LCCI）提供了一种有前景的替代方案，但其诊断性能与高成本心脏智能（HCCI）存在显著差距。

Method: LiteHeart是一个半监督知识蒸馏框架，引入了区域感知蒸馏模块来模仿心脏病专家关注诊断相关心电图区域的方式，并结合了跨层互信息模块来对齐LCCI和HCCI系统的决策过程。采用半监督训练策略进一步提高了模型在有限监督下的鲁棒性。

Result: 在涵盖38种心血管疾病的五个数据集上进行评估，LiteHeart显著缩小了LCCI和HCCI之间的性能差距，在宏观F1分数上比现有方法提高了4.27%至7.10%。

Conclusion: LiteHeart显著增强了低成本心脏智能系统的诊断能力，为使用可穿戴技术实现可扩展、负担得起且准确的日常心脏医疗保健铺平了道路。

Abstract: Deploying advanced cardiac artificial intelligence for daily cardiac
monitoring is hindered by its reliance on extensive medical data and high
computational resources. Low-cost cardiac intelligence (LCCI) offers a
promising alternative by using wearable device data, such as 1-lead
electrocardiogram (ECG), but it suffers from a significant diagnostic
performance gap compared to high-cost cardiac intelligence (HCCI). To bridge
this gap, we propose LiteHeart, a semi-supervised knowledge distillation
framework. LiteHeart introduces a region-aware distillation module to mimic how
cardiologists focus on diagnostically relevant ECG regions and a cross-layer
mutual information module to align the decision processes of LCCI and HCCI
systems. Using a semi-supervised training strategy, LiteHeart further improves
model robustness under limited supervision. Evaluated on five datasets covering
over 38 cardiovascular diseases, LiteHeart substantially reduces the
performance gap between LCCI and HCCI, outperforming existing methods by 4.27%
to 7.10% in macro F1 score. These results demonstrate that LiteHeart
significantly enhances the diagnostic capabilities of low-cost cardiac
intelligence systems, paving the way for scalable, affordable, and accurate
daily cardiac healthcare using wearable technologies.

</details>


### [127] [Consciousness-ECG Transformer for Conscious State Estimation System with Real-Time Monitoring](https://arxiv.org/abs/2511.02853)
*Young-Seok Kweon,Gi-Hwan Shin,Ji-Yong Kim,Bokyeong Ryu,Seong-Whan Lee*

Main category: eess.SP

TL;DR: 提出了一种基于心电图（ECG）信号的意识状态估计方法，克服了传统脑电图（EEG）方法的局限性，并在睡眠分期和麻醉监测中取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于脑电图（EEG）的意识状态估计方法对噪声敏感且需要受控环境，限制了其在实际医疗中的应用。需要一种更可靠、非侵入性的方法。

Method: 利用一种包含解耦查询注意力机制的Transformer模型，处理心电图（ECG）信号，以捕捉区分意识与无意识状态的心率变异性特征。

Result: 在睡眠分期任务中，模型的准确率达到0.877，曲线下面积（AUC）为0.786。在麻醉水平监测任务中，模型的准确率达到0.880，AUC为0.895。实验结果表明，该模型优于现有基线模型。

Conclusion: 基于ECG的意识状态估计方法是一种实用且鲁棒的替代方案，尤其适用于动态的临床环境，能够提高患者安全性并加深对意识状态的理解。

Abstract: Conscious state estimation is important in various medical settings,
including sleep staging and anesthesia management, to ensure patient safety and
optimize health outcomes. Traditional methods predominantly utilize
electroencephalography (EEG), which faces challenges such as high sensitivity
to noise and the requirement for controlled environments. In this study, we
propose the consciousness-ECG transformer that leverages electrocardiography
(ECG) signals for non-invasive and reliable conscious state estimation. Our
approach employs a transformer with decoupled query attention to effectively
capture heart rate variability features that distinguish between conscious and
unconscious states. We implemented the conscious state estimation system with
real-time monitoring and validated our system on datasets involving sleep
staging and anesthesia level monitoring during surgeries. Experimental results
demonstrate that our model outperforms baseline models, achieving accuracies of
0.877 on sleep staging and 0.880 on anesthesia level monitoring. Moreover, our
model achieves the highest area under curve values of 0.786 and 0.895 on sleep
staging and anesthesia level monitoring, respectively. The proposed system
offers a practical and robust alternative to EEG-based methods, particularly
suited for dynamic clinical environments. Our results highlight the potential
of ECG-based consciousness monitoring to enhance patient safety and advance our
understanding of conscious states.

</details>


### [128] [NEF-NET+: Adapting Electrocardio panorama in the wild](https://arxiv.org/abs/2511.02880)
*Zehui Zhan,Yaojun Hu,Jiajing Zhan,Wanchen Lian,Wanqing Wu,Jintai Chen*

Main category: eess.SP

TL;DR: NEF-NET+ 是一个增强的全景心电图（ECG）合成框架，能够从任意视图合成任意长度的信号，克服了现有系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多导心电图系统由于固定的导联位置，可能无法捕捉到某些心脏病（如 Brugada 综合征）的诊断关键模式。NEF-NET+ 旨在解决这个问题，实现从任意视图进行心电图信号的虚拟观察。

Method: NEF-NET+ 引入了一种新的模型架构，可以直接进行视图转换，并结合了离线预训练、设备校准微调以及针对患者的即时校准工作流程。

Result: NEF-NET+ 在真实世界设置下，与 Nef-Net 相比，PSNR 提高了约 6 dB，显著优于先前的方法。

Conclusion: NEF-NET+ 成功地增强了全景心电图的合成能力，能够处理更长的信号、适应不同的设备，并补偿导电极放置的偏差，为心脏病诊断提供了更全面的视角。

Abstract: Conventional multi-lead electrocardiogram (ECG) systems capture cardiac
signals from a fixed set of anatomical viewpoints defined by lead placement.
However, certain cardiac conditions (e.g., Brugada syndrome) require
additional, non-standard viewpoints to reveal diagnostically critical patterns
that may be absent in standard leads. To systematically overcome this
limitation, Nef-Net was recently introduced to reconstruct a continuous
electrocardiac field, enabling virtual observation of ECG signals from
arbitrary views (termed Electrocardio Panorama). Despite its promise, Nef-Net
operates under idealized assumptions and faces in-the-wild challenges, such as
long-duration ECG modeling, robustness to device-specific signal artifacts, and
suboptimal lead placement calibration. This paper presents NEF-NET+, an
enhanced framework for realistic panoramic ECG synthesis that supports
arbitrary-length signal synthesis from any desired view, generalizes across ECG
devices, and compensates for operator-induced deviations in electrode
placement. These capabilities are enabled by a newly designed model
architecture that performs direct view transformation, incorporating a workflow
comprising offline pretraining, device calibration tuning steps as well as an
on-the-fly calibration step for patient-specific adaptation. To rigorously
evaluate panoramic ECG synthesis, we construct a new Electrocardio Panorama
benchmark, called Panobench, comprising 5367 recordings with 48-view per
subject, capturing the full spatial variability of cardiac electrical activity.
Experimental results show that NEF-NET+ delivers substantial improvements over
Nef-Net, yielding an increase of around 6 dB in PSNR in real-world setting. The
code and Panobench will be released in a subsequent publication.

</details>


### [129] [Adaptive Internal Calibration for Temperature-Robust mmWave FMCW Radars](https://arxiv.org/abs/2511.02884)
*Dariush Salami,Nima Bahmani,Hüseyin Yiğitler,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出了一种新颖的毫米波（mmWave）调频连续波（FMCW）雷达内部校准框架，以确保在内部温度变化下具有鲁棒的性能，并针对密集无线网络的部署进行了优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决毫米波FMCW雷达在内部温度变化时性能下降的问题，提高其在密集无线网络环境下的可靠性。

Method: 提出了一种温度补偿模型，该模型利用内部传感器数据和信号处理技术来补偿由温度引起的硬件漂移，以保持测量精度。

Result: 实验结果表明，该框架在各种内部温度条件下提高了雷达的鲁棒性，且计算开销极小。该方案将中频（IF）信号幅度与内部温度漂移之间的皮尔逊相关性降低了高达84%。

Conclusion: 所提出的内部校准框架能够有效 Mitigate 毫米波FMCW雷达的温度漂移，提高其在实际应用中的可靠性和鲁棒性，同时具有良好的可扩展性和计算效率，并遵循了道德设计原则。

Abstract: We present a novel internal calibration framework for Millimeter- Wave
(mmWave) Frequency-Modulated Continuous-Wave (FMCW) radars to ensure robust
performance under internal temperature variations, tailored for deployment in
dense wireless networks. Our approach mitigates the impact of
temperature-induced drifts in radar hardware, enhancing reliability. We propose
a temperature compensation model that leverages internal sensor data and signal
processing techniques to maintain measurement accuracy. Experimental results
demonstrate improved robustness across a range of internal temperature
conditions, with minimal computational overhead, ensuring scalability in dense
network environments. The framework also incorporates ethical design
principles, avoiding reliance on sensitive external data. The proposed scheme
reduces the Pearson correlation between the amplitude of the Intermediate
Frequency (IF) signal and internal temperature drift up to 84%, significantly
mitigating the temperature drift.

</details>


### [130] [From Narrow to Wide: Autoencoding Transformers for Ultrasound Bandwidth Recovery](https://arxiv.org/abs/2511.02938)
*Sepideh KhakzadGharamaleki,Hassan Rivaz,Brandon Helfield*

Main category: eess.SP

TL;DR: 通过AI学习将低成本窄带超声探头的信号映射到宽带信号，以提高图像分辨率。


<details>
  <summary>Details</summary>
Motivation: 低成本探头的窄带限制了超声图像的细节，影响了诊断。

Method: 训练一个基于Tiny Vision Transform (ViT) 的自编码器模型，使用模拟数据和课程加权损失，将带限射频信号映射到宽带信号。

Result: 在仿真数据上，模型将图像均方误差（MSE）降低了90%，峰值信噪比（PSNR）提高了6.7 dB，结构相似性指数（SSIM）提高到0.965。在未见过的分辨率模型上，模型能够锐化点目标，证明了其在未见过的分布上的泛化能力，并且不牺牲帧率或相位信息。

Conclusion: 纯软件升级可以使现有的窄带超声探头具备宽带性能，有望在资源有限的环境中普及高分辨率超声。

Abstract: Conventional pulse-echo ultrasound suffers when low-cost probes deliver only
narrow fractional bandwidths, elongating pulses and erasing high-frequency
detail. We address this limitation by learning a data-driven mapping from
band-limited to broadband spectrogram of radio-frequency (RF) lines. To this
end, a variation of Tiny Vision Transform (ViT) auto-encoder is trained on
simulation data using a curriculum-weighted loss. On heterogeneous speckle-cyst
phantoms, the network reduces image-domain MSE by 90 percent, boosts PSNR by
6.7 dB, and raises SSIM to 0.965 compared with the narrow-band input. It also
sharpens point-target rows in a completely unseen resolution phantom,
demonstrating strong out-of-distribution generalisation without sacrificing
frame rate or phase information. These results indicate that a purely software
upgrade can endow installed narrow-band probes with broadband-like performance,
potentially widening access to high-resolution ultrasound in
resource-constrained settings.

</details>


### [131] [Consensus Tracking of an Underwater Vehicle Using Weighted Harmonic Mean Density](https://arxiv.org/abs/2511.03130)
*Ved Prakash Dubey,Shovan Bhaumik*

Main category: eess.SP

TL;DR: 该论文提出了一种基于加权谐波均值密度（HMD）的分布式水下目标跟踪方法，通过优化权重来融合高斯密度，以提高跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在有大量声呐浮标传感器监测区域的水下目标跟踪问题，并优化分布式跟踪中的信息融合。 

Method: 提出了一种基于加权谐波均值密度（HMD）的跟踪方法，通过最小化Kullback-Leibler散度来优化权重，以实现高斯密度融合。 

Result: 仿真结果表明，所提出的基于HMD的优化融合方法在分布式跟踪中优于现有的融合方法，并在均方根误差、跟踪发散百分比和归一化估计误差平方等性能指标上表现更优。

Conclusion: 所提出的基于加权谐波均值密度（HMD）的分布式跟踪方法能够有效融合来自多个局部跟踪器的高斯密度估计，并在水下目标跟踪任务中实现优于现有方法的性能。

Abstract: This paper addresses an underwater target tracking problem in which a large
number of sonobuoy sensors are deployed on a surveillance region. The region is
divided into several sub-regions, where a single tracker, capable of generating
track is installed. Each sonobuoy can measure the direction of arrival of
acoustic signals (known as bearing angles) and communicate the measurements
with the local tracker. Further, each local tracker can communicate with all
other trackers, where each of them can exchange their estimate and finally a
consensus is reached. We propose a weighted harmonic mean density (HMD) based
tracking to reach a consensus and provide a solution for the fusion of Gaussian
densities. In this approach, optimal weights are assigned by minimizing the
Kullback-Leibler divergence measure. Performance of the proposed method is
measured using root mean square error, percentage of track divergence, and
normalized estimation error squared. Simulation results demonstrate that the
optimized HMD-based fusion outperforms existing fusion methods during a
distributed tracking.

</details>


### [132] [Analysis and Algorithm for Multi IRS Collaborative Localization via Hybrid Time Angle Estimation](https://arxiv.org/abs/2511.03133)
*Ziheng Zhang,Wen Chen,Qingqing Wu,Haoran Qin,Zhendong Li,Qiong Wu*

Main category: eess.SP

TL;DR: 提出了一种多智能反射面（IRS）协同混合定位系统，通过联合时间和角度估计实现目标定位。推导了半无源-无源模型下的级联延迟、到达角（AOA）和离开角（AOD）估计的费雪信息矩阵（FIM）及其Cramer Rao界（CRB）。设计了角度和位置估计算法，利用原子范数和交替方向乘子法（ADMM）解决角度估计问题，并提出了一种结合加权最小二乘、总体最小二乘和二次校正的三阶段定位算法。仿真结果表明，所提出的系统在低信噪比（SNR）条件下具有优越的定位精度。


<details>
  <summary>Details</summary>
Motivation: 开发一种利用多个智能反射面（IRS）协同工作的混合定位系统，以实现比传统方法更精确的目标定位，特别是在挑战性的低信噪比环境下。

Method: 1. 提出多IRS协同混合定位系统，利用联合时间和角度估计进行定位。2. 推导了半无源-无源模型下的级联延迟、AOA和AOD估计的FIM和CRB。3. 角度估计：根据信号秩将反射信号分为三类，进行预处理；利用原子范数最小化将问题转化为凸优化问题；使用ADMM求解多AOA和AOD对。4. 位置估计：提出三阶段算法，结合加权最小二乘、总体最小二乘和二次校正。

Result: 仿真结果验证了所提出系统的优越性，证明了系统的协同、混合定位和分布式部署带来的显著好处，以及所提出估计算法的准确性，尤其是在低信噪比条件下。

Conclusion: 所提出的多IRS协同混合定位系统和相应的估计算法在提供高精度定位方面非常有效，尤其是在低信噪比环境下，证明了IRS协同、混合方法和分布式部署的优势。

Abstract: This paper proposes a novel multiple intelligent reflecting surfaces (IRSs)
collaborative hybrid localization system, which involves deploying multiple
IRSs near the target area and achieving target localization through joint time
delay and angle estimation. Specifically, echo signals from all reflective
elements are received by each sensor and jointly processed to estimate the time
delay and angle parameters. Based on the above model, we derive the Fisher
Information Matrix (FIM) for cascaded delay, Angle of Arrival (AOA), and Angle
of Departure (AOD) estimation in semi passive passive models, along with the
corresponding Cramer Rao Bound (CRB). To achieve precise estimation close to
the CRB, we design efficient algorithms for angle and location estimation. For
angle estimation, reflective signals are categorized into three cases based on
their rank, with different signal preprocessing. By constructing an atomic norm
set and minimizing the atomic norm, the joint angle estimation problem is
transformed into a convex optimization problem, and low-complexity estimation
of multiple AOA and AOD pairs is achieved using the Alternating Direction
Method of Multipliers (ADMM). For location estimation, we propose a three-stage
localization algorithm that combines weighted least squares, total least
squares, and quadratic correction to handle errors in the coefficient matrix
and observation vector, thus improving accuracy. Numerical simulations validate
the superiority of the proposed system, demonstrating that the system's
collaboration, hybrid localization, and distributed deployment provide
substantial benefits, as well as the accuracy of the proposed estimation
algorithms, particularly in low signal to noise ratio (SNR) condition.

</details>


### [133] [Multimodal-Wireless: A Large-Scale Dataset for Sensing and Communication](https://arxiv.org/abs/2511.03220)
*Tianhao Mao,Le Liang,Jie Yang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 该论文介绍了Multimodal-Wireless，一个用于无线通信研究的开源多模态传感数据集。


<details>
  <summary>Details</summary>
Motivation: 创建了一个用于无线通信研究的开源多模态传感数据集。

Method: 使用CARLA模拟器和Sionna框架构建了一个集成的数据管道来生成数据集。

Result: 生成了包含约16万帧的数据集，涵盖了四个虚拟城镇、十六种通信场景和三种天气条件，并包含通信信道、激光雷达、RGB和深度摄像头、惯性测量单元以及雷达等多种传感模态。文章还展示了使用多模态大语言模型进行波束预测等研究应用。

Conclusion: 本文详细介绍了Multimodal-Wireless数据集的特点、框架和技术实现，并探讨了其在通信和协同感知方面的研究潜力。

Abstract: This paper presents Multimodal-Wireless, an open-source multimodal sensing
dataset designed for wireless communication research. The dataset is generated
through an integrated and customizable data pipeline built upon the CARLA
simulator and Sionna framework. It contains approximately 160,000 frames
collected across four virtual towns, sixteen communication scenarios, and three
weather conditions, encompassing multiple sensing modalities--communication
channel, light detection and ranging, RGB and depth cameras, inertial
measurement unit, and radar. This paper provides a comprehensive overview of
the dataset, outlining its key features, overall framework, and technical
implementation details. In addition, it explores potential research
applications concerning communication and collaborative perception, exemplified
by beam prediction using a multimodal large language model. The dataset is open
in https://le-liang.github.io/mmw/.

</details>


### [134] [Integrated Sensing and Communication with UAV Swarms via Decentralized Consensus ADMM](https://arxiv.org/abs/2511.03283)
*Zhiyuan Zhai,Wei Ni,Xin Wang,Dusit Niyato,Ekram Hossain*

Main category: eess.SP

TL;DR: 本文提出了一种去中心化的优化框架，通过协调无人机（UAV）位置来最大化通信速率并最小化感知Cram'er-Rao Bound（CRB），以增强无人机群在集成传感与通信（ISAC）中的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机群（UAV swarms）能够形成虚拟天线阵列，利用额外的空间自由度来增强集成传感与通信（ISAC）性能。然而，无人机位置的优化因其分布式特性以及个体无人机缺乏全局视野而面临挑战。

Method: 本文提出了一种新的去中心化优化框架，并推导了可实现的上行链路速率和Cram'er-Rao Bound（CRB）作为通信和传感的可行指标。使用去中心化的共识交替方向乘子法（ADMM）算法来解决非凸问题，该算法包括局部投影更新、代理辅助共识协调和轻量级对偶更新。

Result: 仿真结果表明，所提出的共识ADMM算法收敛速度快，可扩展性强，并且无人机群在通信和传感性能上均显著优于固定阵列基线。

Conclusion: 所提出的去中心化共识ADMM算法能够有效地优化无人机群的位置，以在ISAC应用中实现通信和传感性能的联合优化，并展现出良好的可扩展性和性能优势。

Abstract: UAV swarms can form virtual antenna arrays to exploit additional spatial
degrees of freedom and enhance integrated sensing and communication (ISAC). The
optimization of UAV positions is challenging due to the distributed nature of
swarms and the lack of a global view at individual UAVs.
  This paper presents a new decentralized optimization framework that allows
UAVs to decide their locations in parallel and reach consensus on a globally
optimal swarm geometry for ISAC.
  Specifically, we derive the achievable uplink rate and Cram\'er-Rao Bound
(CRB) as tractable metrics for communication and sensing, respectively.
  The UAV positions are optimized to balance maximizing the communication rate
and minimizing the CRB.
  To solve this non-convex problem with coupled variables, we develop a
decentralized consensus alternating direction method of multipliers (ADMM)
algorithm, which enables the UAVs to iteratively align their local updates and
reach consensus.
  The algorithm decomposes the global objective into local projection updates,
proxy-assisted consensus coordination, and lightweight dual updates, ensuring
scalability and consistency throughout the swarm.
  Simulations demonstrate that the proposed consensus ADMM algorithm converges
rapidly with strong scalability, and that the UAV swarm significantly
outperforms fixed-array baselines in both communication and sensing
performance.

</details>


### [135] [Decentralized Federated Learning with Distributed Aggregation Weight Optimization](https://arxiv.org/abs/2511.03284)
*Zhiyuan Zhai,Xiaojun Yuan,Xin Wang,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 本文提出了一种去中心化的聚合权重优化算法，用于去中心化联邦学习（DFL），通过本地信息和D2D通信实现


<details>
  <summary>Details</summary>
Motivation: DFL中聚合权重至关重要，但传统方法依赖中心实体，与DFL的去中心化特性不符。本文旨在开发一种与DFL去中心化特性一致的分布式聚合权重优化算法。

Method: 提出了一种分布式聚合权重优化算法。该算法首先量化分析了聚合权重对去中心化通信网络的影响，然后将学习性能优化问题转化为特征值优化问题，并提出了一种基于子梯度的分布式算法来求解。

Result: 数值结果表明，所提出的算法在实际DFL部署中具有优越性。

Conclusion: 本文提出的分布式聚合权重优化算法使得DFL的优化、通信和学习过程都能在去中心化的情况下进行，实现了真正意义上的去中心化DFL系统。

Abstract: Decentralized federated learning (DFL) is an emerging paradigm to enable edge
devices collaboratively training a learning model using a device-to-device
(D2D) communication manner without the coordination of a parameter server (PS).
Aggregation weights, also known as mixing weights, are crucial in DFL process,
and impact the learning efficiency and accuracy. Conventional design relies on
a so-called central entity to collect all local information and conduct system
optimization to obtain appropriate weights. In this paper, we develop a
distributed aggregation weight optimization algorithm to align with the
decentralized nature of DFL. We analyze convergence by quantitatively capturing
the impact of the aggregation weights over decentralized communication
networks. Based on the analysis, we then formulate a learning performance
optimization problem by designing the aggregation weights to minimize the
derived convergence bound. The optimization problem is further transformed as
an eigenvalue optimization problem and solved by our proposed subgradient-based
algorithm in a distributed fashion. In our algorithm, edge devices only need
local information to obtain the optimal aggregation weights through local (D2D)
communications, just like the learning itself. Therefore, the optimization,
communication, and learning process can be all conducted in a distributed
fashion, which leads to a genuinely distributed DFL system. Numerical results
demonstrate the superiority of the proposed algorithm in practical DFL
deployment.

</details>


### [136] [Diffusion-Driven Terahertz Air-Ground Communications under Dynamic Atmospheric Turbulence](https://arxiv.org/abs/2511.03290)
*Jinhao Yi,Weijun Gao,Chong Han*

Main category: eess.SP

TL;DR: 太赫兹通信在太空-空中-地面集成网络(SAGIN)中因其广阔的频谱资源而备受关注，但飞机的高速移动会引起剧烈且快速变化的湍流，从而造成额外的传播损耗。本文提出了一种人工智能驱动的太赫兹空地通信框架，该框架通过流体动力学显式建模湍流引起的衰减，并将其整合到通信性能增强的自适应优化范式中。


<details>
  <summary>Details</summary>
Motivation: 太空-空中-地面集成网络(SAGIN)对超高数据速率的需求日益增长，而现有的研究往往忽略了飞机高移动性引起的湍流传播损耗。

Method: 本文建立了流体动力学信息衰减模型来表征飞机产生的湍流及其对太赫兹信号传播的影响。在此基础上，构建了一个联合功率-姿态优化问题，通过自适应分配传输功率和调整飞机姿态来最大化链路容量。并使用基于扩散的算法求解该优化问题。

Result: 通过数值评估，在0.7马赫、-10至10度的攻击角下，湍流引起的衰减范围为18至28 dB。所提出的框架平均容量达到11.241 bps/Hz，比现有策略分别提高了22.8%和66.5%，并接近理论容量极限的98%。

Conclusion: 本文提出的框架能够有效表征和补偿由飞机高移动性引起的太赫兹通信湍流衰减，显著提升通信容量。

Abstract: The ever-increasing demand for ultra-high data rates in space-air-ground
integrated networks (SAGINs) has rendered terahertz THz communications a
promising technology owing to its exceptionally broad and continuous spectrum
resources. Nevertheless, in air-ground (AG) scenarios, the high mobility of
aircraft induces intense and rapidly fluctuating turbulence, leading to
additional propagation loss that is often overlooked in existing studies. To
bridge this gap, this paper presents an AI-empowered THz AG communication
framework that explicitly models turbulence-induced attenuation through fluid
dynamics and integrates it into an adaptive optimization paradigm for
communication performance enhancement. Specifically, a fluid-dynamics-informed
attenuation model is established to characterize aircraft-generated turbulence
and quantify its impact on THz signal propagation. Building upon this model, a
joint power-attitude optimization problem is formulated to adaptively allocate
transmit power and adjust aircraft attitude for maximizing link capacity. The
optimization problem is efficiently solved using a diffusion-based algorithm
that learns the nonlinear relationship between flight configuration and
turbulence-induced attenuation. Comprehensive numerical evaluations demonstrate
that the turbulence-induced attenuation ranges from 18 to 28 dB under attacking
angles between -10 degree and 10 degree at 0.7 Mach, verifying the pronounced
impact of aircraft-induced turbulence on THz propagation. Furthermore, the
proposed framework attains an average capacity of 11.241 bps/Hz, substantially
outperforming existing strategies by 22.8% and 66.5%, and approaching
approximately 98% of the theoretical capacity limit.

</details>


### [137] [Spectral-Convergent Decentralized Machine Learning: Theory and Application in Space Networks](https://arxiv.org/abs/2511.03291)
*Zhiyuan Zhai,Shuyan Hu,Wei Ni,Xiaojun Yuan,Xin Wang*

Main category: eess.SP

TL;DR: 该论文研究了通信不可靠性对去中心化机器学习（DML）收敛性的影响，并建立了通信混合过程的谱特性与整体性能之间的直接联系。作者提出了一个谱优化问题，通过最小化期望二阶混合矩阵的谱半径来提高收敛速度，并设计了一个基于子梯度的方法来解决这个问题，该方法能在无中心协调的情况下满足对称性和随机性约束。实验证明，该方法在低地球轨道（LEO）卫星星座和遥感数据上是可行且有效的，能够显著提高分类准确性和收敛效率。


<details>
  <summary>Details</summary>
Motivation: 去中心化机器学习（DML）在大型网络中无需中央服务器即可进行协作式训练，但它对设备间通信的质量和可靠性非常敏感，通信拓扑可能随时间变化且具有随机性。因此，理解和解决通信不可靠性对DML收敛性的影响至关重要。

Method: 1. 建立了通信混合过程的谱特性与DML整体性能之间的直接联系。
2. 在随机拓扑下，为DML的收敛性提供了严格的保证，并推导了描述期望混合矩阵谱特性对学习影响的界限。
3. 提出了一个谱优化问题，旨在最小化期望二阶混合矩阵的谱半径，以提高在概率链路故障下的收敛速率。
4. 设计了一个高效的子梯度算法来解决这个非光滑谱优化问题，该算法集成了Chebyshev加速的特征向量估计、本地更新和聚合权重调整，同时在无中心协调的情况下确保了对称性和随机性约束。

Result: 通过在具有时变卫星链路模型和真实遥感数据的低地球轨道（LEO）卫星星座上进行实验，证明了所提出方法的概念可行性和有效性。与现有基线方法相比，该方法显著提高了分类准确性和收敛效率。

Conclusion: 该研究为理解和解决去中心化机器学习中的通信挑战提供了新的见解，并提出了一种有效的方法来提高其在不确定通信环境（如卫星系统）中的性能。所提出的方法在实际应用中显示出显著的优势，证明了其在卫星和其他去中心化系统中的适用性。

Abstract: Decentralized machine learning (DML) supports collaborative training in
large-scale networks with no central server. It is sensitive to the quality and
reliability of inter-device communications that result in time-varying and
stochastic topologies. This paper studies the impact of unreliable
communication on the convergence of DML and establishes a direct connection
between the spectral properties of the mixing process and the global
performance. We provide rigorous convergence guarantees under random topologies
and derive bounds that characterize the impact of the expected mixing matrix's
spectral properties on learning. We formulate a spectral optimization problem
that minimizes the spectral radius of the expected second-order mixing matrix
to enhance the convergence rate under probabilistic link failures. To solve
this non-smooth spectral problem in a fully decentralized manner, we design an
efficient subgradient-based algorithm that integrates Chebyshev-accelerated
eigenvector estimation with local update and aggregation weight adjustment,
while ensuring symmetry and stochasticity constraints without central
coordination. Experiments on a realistic low Earth orbit (LEO) satellite
constellation with time-varying inter-satellite link models and real-world
remote sensing data demonstrate the feasibility and effectiveness of the
proposed method. The method significantly improves classification accuracy and
convergence efficiency compared to existing baselines, validating its
applicability in satellite and other decentralized systems.

</details>


### [138] [UAV SAR Imaging with 5G NR OFDM Signals in NLOS Environments](https://arxiv.org/abs/2511.03292)
*Qiuyuan Yang,Cunhua Pan,Ruidong Li,Zhenkun Zhang,Hong Ren,Changhong Wang,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 本文提出了一个用于合成孔径雷达（SAR）成像的合作通信感知（ISAC）框架，该框架利用正交频分复用（OFDM）通信信号，并提出了一种两阶段压缩感知-空间交替广义期望最大化（CS-SAGE）方案来解决非视距（NLOS）环境下的成像退化问题，通过仿真验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 在非视距（NLOS）环境下，ISAC系统面临严重的成像退化问题，需要检测弱信号并消除虚假点，以实现高精度的散射体定位。

Method: 提出了一种合作ISAC框架，利用OFDM通信信号，并设计了一种两阶段CS-SAGE方案：第一阶段使用OMP进行粗略估计，第二阶段使用SAGE进行精细估计。

Result: 仿真结果表明，所提出的合作ISAC框架在NLOS环境下能够有效进行SAR成像，实现高精度的散射体定位。

Conclusion: 所提出的合作ISAC框架在NLOS环境下能够有效进行SAR成像，并为实际系统设计提供了有价值的参考。

Abstract: The integration of sensing and communication (ISAC) has significant potential
for future wireless systems, enabling efficient spectrum utilization and novel
application scenarios. In this paper, we propose a cooperative ISAC framework
for synthetic aperture radar (SAR) imaging by leveraging orthogonal frequency
division multiplexing (OFDM) communication signals. We address the challenge of
severe imaging degradation in non-line-of-sight (NLOS) environments under the
QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa). To detect weak signals
and eliminate false points, we develop a two-stage compressed sensing-space
alternating generalized expectation maximization (CS-SAGE) scheme for
high-precision scatterer localization. In stage I, orthogonal matching pursuit
(OMP) is employed for coarse estimation to identify the approximate locations
of dominant scatterers. Then, the SAGE algorithm in stage II performs fine
estimation to accurately extract scatterer parameters. Simulation results
validate the effectiveness of the proposed cooperative ISAC framework, and
provide valuable insights for practical system design.

</details>


### [139] [C-RAN Advanced: From a Network Cooperation Perspective](https://arxiv.org/abs/2511.03302)
*Xiaoyun Wang,Yutong Zhang,Sen Wang,Sun Qi,Hanning Wang,Qixing Wang,Jing Jin,Jiwei He,Nan Li*

Main category: eess.SP

TL;DR: 6G网络将从通信服务转向信息服务，提出了一种新的CIS-RAN架构，它扩展了C-RAN的概念，并集成了合作感知和合作AI，以提高网络性能和效率。文章讨论了关键技术，并以网络MIMO为例进行了证明。


<details>
  <summary>Details</summary>
Motivation: 未来的6G移动网络将从传统的通信服务模式演变为全面的信息服务模式，这将推动无线接入网（RAN）架构向增强的协作、智能和面向服务的方向发展。

Method: 提出了一种新颖的合作、智能和基于服务的RAN（CIS-RAN）架构。该架构在C-RAN的基础上，通过进一步整合合作感知和合作人工智能（AI），扩展了传统的合作通信范式。CIS-RAN通过在信息的获取、传输和处理的全过程中增强网络协作，实现了高效的信息获取、多样化的协作交互和智能融合决策。

Result: 通过以网络协同多输入多输出（MIMO）作为案例研究，证明了CIS-RAN架构相较于传统架构具有优越的性能，并通过数值结果进行了验证。

Conclusion: 文章讨论了关键技术，并提出了未来的研究方向，强调继续探索和推进CIS-RAN架构，特别是在加强网络协作方面。

Abstract: Future mobile networks in the sixth generation (6G) are poised for a paradigm
shift from conventional communication services toward comprehensive information
services, driving the evolution of radio access network (RAN) architectures
toward enhanced cooperation, intelligence, and service orientation. Building
upon the concept of centralized, collaborative, cloud, and clean RAN (C-RAN),
this article proposes a novel cooperative, intelligent, and service-based RAN
(CIS-RAN) architecture. Focusing on cooperation, CIS-RAN extends the
traditional cooperative communication paradigm by further integrating
cooperative sensing and cooperative artificial intelligence (AI). To improve
both performance and effectiveness across diverse application scenarios,
CIS-RAN enhances network cooperation throughout the entire process of
acquisition, transmission, and processing, thereby enabling efficient
information acquisition, diverse cooperative interactions, and intelligent
fusion decision-making. Key technologies are discussed, with network
cooperative multiple-input multiple-output (MIMO) examined as a case study,
demonstrating superior performance over traditional architectures, as
demonstrated by numerical results. Future research directions are outlined,
emphasizing the continued exploration and advancement of the CIS-RAN
architecture, particularly in enhancing network cooperation.

</details>


### [140] [Performance Analysis of Wireless-Powered Pinching Antenna Systems](https://arxiv.org/abs/2511.03401)
*Kunrui Cao,Jingyu Chen,Panagiotis D. Diamantoulakis,Lei Zhou,Xingwang Li,Yuanwei Liu,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本文提出了无线能量供给的捏合天线系统（PAS），并研究了其可靠性，以探索捏合天线（PA）在改进无线能量供给通信（WPC）系统性能方面的优势。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索无线能量供给的捏合天线系统（PAS）的可靠性，并利用PA的优势来提升无线能量供给通信（WPC）系统的性能。

Method: 推导了实际有损波导和理想无损波导情况下的中断概率和遍历率的闭式表达式，并分析了波导和用户的最佳部署。

Result: 结果表明，吸收系数和用户区域尺寸的增加会增加波导内和自由空间传播损耗，从而增加中断概率并降低遍历率。然而，在吸收系数高和波导长的情况下，PAS的性能可能不如传统WPC系统，但其遍历率仍优于传统WPC系统。此外，PAS存在最小化中断概率或最大化遍历率的最优时间和功率站（PS）与接入点（AP）间距离。

Conclusion: 无线能量供给的PAS具有最优的时间分配和PS与AP之间的距离，可以最小化中断概率或最大化遍历率。PS和AP在最优距离下的分离性能优于集成在混合接入点中。

Abstract: Pinching antenna system (PAS) serves as a groundbreaking paradigm that
enhances wireless communications by flexibly adjusting the position of pinching
antenna (PA) and establishing a strong line-of-sight (LoS) link, thereby
reducing the free-space path loss. This paper introduces the concept of
wireless-powered PAS, and investigates the reliability of wireless-powered PAS
to explore the advantages of PA in improving the performance of
wireless-powered communication (WPC) system. In addition, we derive the
closed-form expressions of outage probability and ergodic rate for the
practical lossy waveguide case and ideal lossless waveguide case, respectively,
and analyze the optimal deployment of waveguides and user to provide valuable
insights for guiding their deployments. The results show that an increase in
the absorption coefficient and in the dimensions of the user area leads to
higher in-waveguide and free-space propagation losses, respectively, which in
turn increase the outage probability and reduce the ergodic rate of the
wireless-powered PAS. However, the performance of wireless-powered PAS is
severely affected by the absorption coefficient and the waveguide length, e.g.,
under conditions of high absorption coefficient and long waveguide, the outage
probability of wireless-powered PAS is even worse than that of traditional WPC
system. While the ergodic rate of wireless-powered PAS is better than that of
traditional WPC system under conditions of high absorption coefficient and long
waveguide. Interestingly, the wireless-powered PAS has the optimal time
allocation factor and optimal distance between power station (PS) and access
point (AP) to minimize the outage probability or maximize the ergodic rate.
Moreover, the system performance of PS and AP separated at the optimal distance
between PS and AP is superior to that of PS and AP integrated into a hybrid
access point.

</details>


### [141] [A Modified Pulse and Design Framework to Halve the Complexity of OFDM Spectral Shaping Techniques](https://arxiv.org/abs/2511.03465)
*Javier Giménez,José A. Cortés,Francisco Javier Cañete,Eduardo Martos-Naya,Luis Díez*

Main category: eess.SP

TL;DR: OFDM 存在高带外辐射问题，本研究提出一种改进的 OFDM 波形，可显著降低现有频谱整形技术的优化和实施成本。


<details>
  <summary>Details</summary>
Motivation: OFDM 尽管广泛使用，但存在高带外辐射（OOBE）。现有的减少 OOBE 的方法（如预编码、AIC 和时域方法）需要复杂的优化过程和实时实现成本。

Method: 提出一种改进的传统 OFDM 波形的方法，以降低与最先进的频谱整形技术相关的成本。

Result: 该方法可将优化所需的系数数量和实施成本降低多达 50%。

Conclusion: 所提出的 OFDM 波形修改可以显著降低频谱整形技术的成本，并为未来在此基础上进行的研究提供了一个框架。

Abstract: Orthogonal frequency division multiplexing (OFDM) is a widespread modulation
but suffers from high out-of-band emissions (OOBE). Spectral shaping strategies
such as precoding, active interference cancellation (AIC) and time-domain
methods are effective at reducing the OOBE but entail optimization procedures
and real-time implementation costs which might be considerable. This letter
proposes a modification of the conventional OFDM waveform aimed at reducing the
cost associated to many of the state-of-theart spectral shaping techniques and
sets a framework for future works that want to benefit from the same reduction.
This approach may reduce both the number of coefficients involved in the
optimization and the number of products of its implementation by up to 50%.

</details>


### [142] [A Novel Multi-Reference-Point Modeling Framework for Monostatic Background Channel: Toward 3GPP ISAC Standardization](https://arxiv.org/abs/2511.03487)
*Yameng Liu,Jianhua Zhang,Yuxiang Zhang,Zhiqiang Yuan,Chuangxin Jiang,Junchen Liu,Wei Hong,Yingyang Li,Yan Li,Guangyi Liu*

Main category: eess.SP

TL;DR: 该论文提出了一个用于6G集成传感与通信（ISAC）系统单站背景信道的新型随机模型，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有通信标准主要关注分离的发射/接收机（Tx/Rx）传播，而ISAC单站模式（Tx/Rx共址）的背景信道建模仍是挑战，对评估传感性能至关重要。

Method: 在室内28GHz环境下进行了ISAC单站背景信道测量，提取了信道参数。基于测量结果的特性，提出了一个将单站背景信道建模为单站Tx&Rx与多个类通信参考点（RPs）之间子信道叠加的新型随机模型，并引入了3GPP扩展的实现框架。最后，提出了一种基于遗传算法的方法来优化RPs的数量和位置。

Result: 测量结果显示了显著的单跳传播和离散的多径分布。所提出的模型能有效捕捉单站背景信道的特性，弥补了ISAC信道建模的关键不足，并支持6G标准化。

Conclusion: 该论文成功地对ISAC单站背景信道进行了建模，解决了现有标准在这方面的空白，并为6G ISAC系统设计和标准化提供了关键支持。

Abstract: Integrated Sensing and Communication (ISAC) has been identified as a key 6G
application by ITU and 3GPP. A realistic, standard-compatible channel model is
essential for ISAC system design. To characterize the impact of Sensing Targets
(STs), 3GPP defines ISAC channel as a combination of target and background
channels, comprising multipath components related to STs and those originating
solely from the environment, respectively. Although the background channel does
not carry direct ST information, its accurate modeling is critical for
evaluating sensing performance, especially in complex environments. Existing
communication standards characterize propagation between separated transmitter
(Tx) and receiver (Rx). However, modeling background channels in the ISAC
monostatic mode, where the Tx and Rx are co-located, remains a pressing
challenge. In this paper, we firstly conduct ISAC monostatic background channel
measurements for an indoor scenario at 28 GHz. Realistic channel parameters are
extracted, revealing pronounced single-hop propagation and discrete multipath
distribution. Inspired by these properties, a novel stochastic model is
proposed to characterizing the ISAC monostatic background channel as the
superposition of sub-channels between the monostatic Tx&Rx and multiple
communication Rx-like Reference Points (RPs). This model is compatible with
standardizations, and a 3GPP-extended implementation framework is introduced.
Finally, a genetic algorithm-based method is proposed to extract the optimal
number and placement of multi-RPs. The optimization approach and modeling
framework are validated by comparing measured and simulated channel parameters.
Results demonstrate that the proposed model effectively captures monostatic
background channel characteristics, addresses a critical gap in ISAC channel
modeling, and supports 6G standardization.

</details>


### [143] [3D Cooperative User Tracking for Distributed Integrated Sensing and Communication](https://arxiv.org/abs/2511.03612)
*Yingjie Xu,Xuesong Cai,Michiel Sandra,Sara Willhammar,Fredrik Tufvesson*

Main category: eess.SP

TL;DR: 该论文提出了一个分布式 ISAC (DISAC) 系统的合作用户跟踪框架，通过结合全局概率假设密度 (PHD) 滤波器和视场感知接入点 (AP) 管理策略，实现了厘米级精度的用户跟踪，并证明了 AP 并非需要一直保持激活状态。


<details>
  <summary>Details</summary>
Motivation: 集成传感与通信 (ISAC) 成为 6G 网络的重要组成部分，而分布式 ISAC (DISAC) 有望通过其去中心化架构提升传感和通信性能。然而，在 DISAC 系统中实现合作用户跟踪面临挑战。

Method: 提出一个完整的框架，结合全局概率假设密度 (PHD) 滤波器和视场感知接入点 (AP) 管理策略，以实现合作用户跟踪。进行了真实世界的分布式 MIMO 信道测量活动来评估该框架。

Result: 实现了厘米级均方根轨迹误差。证明了并非需要持续激活所有 AP 即可保持高跟踪精度。

Conclusion: 所提出的框架能够实现精确的用户跟踪并优化 AP 调度。该研究为 DISAC 系统的实际部署和合作用户跟踪技术的发展提供了有价值的见解。

Abstract: As integrated sensing and communication (ISAC) becomes an integral part of 6G
networks, distributed ISAC (DISAC) is expected to enhance both sensing and
communication performance through its decentralized architecture. This paper
presents a complete framework to address the challenge of cooperative user
tracking in DISAC systems. By incorporating a global probability hypothesis
density (PHD) filter and a field-of-view-aware access point (AP) management
strategy, the framework enables accurate user tracking using radio signals
while optimizing AP scheduling. In addition, a real-world distributed MIMO
channel measurement campaign is performed to evaluate the effectiveness of the
framework. The results demonstrate that a centimeter-level root mean-square
trajectory error can be achieved. Furthermore, the results show that it is not
necessary to keep APs active at all times to maintain high tracking accuracy,
indicating the need for robust and efficient AP management. These findings
provide valuable insight into practical deployments and further development of
cooperative user tracking techniques in DISAC systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [144] [Branch-and-Cut for Computing Approximate Equilibria of Mixed-Integer Generalized Nash Games](https://arxiv.org/abs/2511.03340)
*Aloïs Duguet,Tobias Harks,Martin Schmidt,Julian Schwarz*

Main category: cs.GT

TL;DR: 该论文研究混合整数变量的广义纳什均衡问题，提出了一种结合乘法和加法最优性松弛的近似均衡概念，并设计了相应的分支定界算法进行求解。


<details>
  <summary>Details</summary>
Motivation: 现有的广义纳什均衡问题（混合整数变量）存在无法精确求解以及玩家求解非凸问题最优性的合理性存疑的问题，因此需要研究近似均衡。

Method: 提出了一种分支定界（B&C）方法来计算近似均衡。该方法利用了相交割（intersection cuts）的思想，并在特定条件下（线性约束，成本函数整体凸或整体凹且关于对手策略线性）证明了割的存在性。对于标准纳什均衡问题，引入了另一种割，并在特定条件下保证了算法有限终止。最后，提出了一种基于B&C的单叉二分搜索法来计算最优近似均衡。

Result: 在混合整数流博弈的特定类别中，通过实现和测试这些方法得到了数值结果。

Conclusion: 该研究提出了一种计算近似纳什均衡的方法，并在特定条件下保证了算法的有效性。

Abstract: Generalized Nash equilibrium problems with mixed-integer variables constitute
an important class of games in which each player solves a mixed-integer
optimization problem, where both the objective and the feasible set is
parameterized by the rivals' strategies. However, such games are known for
failing to admit exact equilibria and also the assumption of all players being
able to solve nonconvex problems to global optimality is questionable. This
motivates the study of approximate equilibria. In this work, we consider an
approximation concept that incorporates both multiplicative and additive
relaxations of optimality. We propose a branch-and-cut (B&C) method that
computes such approximate equilibria or proves its non-existence. For this, we
adopt the idea of intersection cuts and show the existence of such cuts under
the condition that the constraints are linear and each player's cost function
is either convex in the entire strategy profile, or, concave in the entire
strategy profile and linear in the rivals' strategies. For the special case of
standard Nash equilibrium problems, we introduce an alternative type of cut and
show that the method terminates finitely, provided that each player has only
finitely many distinct best-response sets. Finally, on the basis of the B&C
method, we introduce a single-tree binary-search method to compute
best-approximate equilibria under some simplifying assumptions. We implemented
these methods and present numerical results for a class of mixed-integer flow
games.

</details>


### [145] [Non-Monotonicity in Fair Division of Graphs](https://arxiv.org/abs/2511.03629)
*Hadi Hosseini,Shraddha Pathak,Yu Zhou*

Main category: cs.GT

TL;DR: 我们研究在n个代理之间公平分配图的顶点的问题，其中一个束的价值由其割值决定——具有恰好一个端点的边数。这种模型自然地捕捉了诸如团队组建和网络划分等应用，其中估值本质上是非单调的：边际值可能为正、负或零，具体取决于束的组成。我们专注于“最多一件物品的无嫉妒”（EF1）的公平性概念，并探讨其与几种效率概念（如转移稳定性（TS））的兼容性，TS禁止单一物品的转移，如果该转移使一个代理受益而没有使另一个代理受损的话。对于一般图，我们的结果揭示了代理数量n与满足EF1和转移稳定性（TS）的分配的存在性之间存在非单调关系：对于n=2，这样的分配总是存在的；对于n=3，可能不存在；但对于所有n≥4，它们再次存在。我们进一步证明，通过稍微削弱效率要求或将图限制为森林，可以保证任何n都存在。我们所有的积极结果都是通过有效的算法实现的。


<details>
  <summary>Details</summary>
Motivation: 在n个代理之间公平分配图的顶点，其中一个束的价值由其割值决定，这种模型自然地捕捉了诸如团队组建和网络划分等应用，其中估值本质上是非单调的：边际值可能为正、负或零，具体取决于束的组成。

Method: 研究“最多一件物品的无嫉妒”（EF1）的公平性概念，并探讨其与几种效率概念（如转移稳定性（TS））的兼容性，TS禁止单一物品的转移，如果该转移使一个代理受益而没有使另一个代理受损的话。

Result: 对于一般图，我们的结果揭示了代理数量n与满足EF1和转移稳定性（TS）的分配的存在性之间存在非单调关系：对于n=2，这样的分配总是存在的；对于n=3，可能不存在；但对于所有n≥4，它们再次存在。我们进一步证明，通过稍微削弱效率要求或将图限制为森林，可以保证任何n都存在。我们所有的积极结果都是通过有效的算法实现的。

Conclusion: 对于n=2和n≥4的一般图，总是存在满足EF1和TS的分配，而对于n=3，则可能不存在。通过放宽效率要求或将图限制为森林，可以为任何n保证分配的存在性。所有肯定的结果都通过有效的算法实现。 Guadalajara, Spain, September 2023

Abstract: We consider the problem of fairly allocating the vertices of a graph among
$n$ agents, where the value of a bundle is determined by its cut value -- the
number of edges with exactly one endpoint in the bundle. This model naturally
captures applications such as team formation and network partitioning, where
valuations are inherently non-monotonic: the marginal values may be positive,
negative, or zero depending on the composition of the bundle. We focus on the
fairness notion of envy-freeness up to one item (EF1) and explore its
compatibility with several efficiency concepts such as Transfer Stability (TS)
that prohibits single-item transfers that benefit one agent without making the
other worse-off. For general graphs, our results uncover a non-monotonic
relationship between the number of agents $n$ and the existence of allocations
satisfying EF1 and transfer stability (TS): such allocations always exist for
$n=2$, may fail to exist for $n=3$, but exist again for all $n\geq 4$. We
further show that existence can be guaranteed for any $n$ by slightly weakening
the efficiency requirement or by restricting the graph to forests. All of our
positive results are achieved via efficient algorithms.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [146] [Faster Weak Expander Decompositions and Approximate Max Flow](https://arxiv.org/abs/2511.02943)
*Henry Fleischmann,George Z. Li,Jason Li*

Main category: cs.DS

TL;DR: 该论文提出了用于计算弱扩展器分解和近似最大流的更快算法，通过“热启动”剪切匹配博弈来避免递归深度成本，并采用新的弱扩展器分解原语来改进近似最大流算法。


<details>
  <summary>Details</summary>
Motivation: 现有算法在计算弱扩展器分解和近似最大流方面存在效率问题，特别是递归深度带来的成本以及对流子程序的灵活性要求。

Method: 1. 提出一种“热启动”剪切匹配博弈的方法，用于计算弱扩展器分解，从而避免递归深度成本。 2. 改进了 Li, Rao, and Wang (SODA, 2025) 的非递归近似最大流算法，并将其框架与新的弱扩展器分解原语相结合。

Result: 1. 实现了更快的弱扩展器分解算法，该算法更灵活，支持更弱的流子程序。 2. 得到了一个近似最大流算法，其效率在扩展器分解方法方面接近理论极限（仅相差几个对数因子）。

Conclusion: 通过引入“热启动”剪切匹配博弈和新的弱扩展器分解原语，显著提高了弱扩展器分解和近似最大流算法的效率，使其在理论和实践中都更具竞争力。

Abstract: We give faster algorithms for weak expander decompositions and approximate
max flow on undirected graphs. First, we show that it is possible to "warm
start" the cut-matching game when computing weak expander decompositions,
avoiding the cost of the recursion depth. Our algorithm is also flexible enough
to support weaker flow subroutines than previous algorithms.
  Our second contribution is to streamline the recent non-recursive approximate
max flow algorithm of Li, Rao, and Wang (SODA, 2025) and adapt their framework
to use our new weak expander decomposition primitive. Consequently, we give an
approximate max flow algorithm within a few logarithmic factors of the limit of
expander decomposition-based approaches.

</details>


### [147] [Tight Better-Than-Worst-Case Bounds for Element Distinctness and Set Intersection](https://arxiv.org/abs/2511.02954)
*Ivor van der Hoog,Eva Rotenberg,Daniel Rutschmann*

Main category: cs.DS

TL;DR: 该论文研究了元素唯一性问题，并提出了对输入重复项敏感的实例特定下界，证明了不存在能对所有图 G 保持 o(log log n)-竞争力的确定性算法，但同时提供了一个 O(log log n)-竞争力的确定性算法，从而为元素唯一性问题提供了超越经典最坏情况分析的精确界限。此外，论文还研究了集合相交问题，证明了不存在能保持 o(log n)-竞争力的确定性算法，并提供了一个 O(log n)-竞争力的确定性算法，从而区分了元素唯一性问题和集合相交问题。


<details>
  <summary>Details</summary>
Motivation: 研究元素唯一性问题，并提出对输入重复项敏感的实例特定下界，以改进传统的基于比较的最坏情况下界。

Method: 通过表示输入实例的重复项组合结构（通过连接相同元素的无向图 G(I)）来推导实例特定的下界。研究算法在具有相同 G(I') ≅ G 的所有输入 I' 上的最坏情况运行时间。

Result: 证明了对于任何确定性算法 A，都存在一个图 G 和一个算法 A'，对于所有 G(I) ≅ G 的输入 I，A' 比 A 快 O(log log n) 倍。因此，没有确定性算法可以对所有图 G 保持 o(log log n)-竞争力。提供了一个 O(log log n)-竞争力的确定性算法。证明了不存在能保持 o(log n)-竞争力的确定性集合相交算法，并提供了一个 O(log n)-竞争力的确定性算法。

Conclusion: 元素唯一性问题存在精确的、超越经典最坏情况分析的下界和上界，其复杂度与输入中的重复项数量有关。元素唯一性问题和集合相交问题在确定性算法的竞争力方面存在差异。

Abstract: The element distinctness problem takes as input a list $I$ of $n$ values from
a totally ordered universe and the goal is to decide whether $I$ contains any
duplicates. It is a well-studied problem with a classical worst-case $\Omega(n
\log n)$ comparison-based lower bound by Fredman. At first glance, this lower
bound appears to rule out any algorithm more efficient than the naive approach
of sorting $I$ and comparing adjacent elements. However, upon closer
inspection, the $\Omega(n \log n)$ bound does not apply if the input has many
duplicates. We therefore ask: Are there comparison-based lower bounds for
element distinctness that are sensitive to the amount of duplicates in the
input?
  To address this question, we derive instance-specific lower bounds. For any
input instance $I$, we represent the combinatorial structure of the duplicates
in $I$ by an undirected graph $G(I)$ that connects identical elements. Each
such graph $G$ is a union of cliques, and we study algorithms by their
worst-case running time over all inputs $I'$ with $G(I') \cong G$. We establish
an adversarial lower bound showing that, for any deterministic algorithm
$\mathcal{A}$, there exists a graph $G$ and an algorithm $\mathcal{A}'$ that,
for all inputs $I$ with $G(I) \cong G$, is a factor $O(\log \log n)$ faster
than $\mathcal{A}$. Consequently, no deterministic algorithm can be $o(\log
\log n)$-competitive for all graphs $G$. We complement this with an $O(\log
\log n)$-competitive deterministic algorithm, thereby obtaining tight bounds
for element distinctness that go beyond classical worst-case analysis.
  We subsequently study the related problem of set intersection. We show that
no deterministic set intersection algorithm can be $o(\log n)$-competitive, and
provide an $O(\log n)$-competitive deterministic algorithm. This shows a
separation between element distinctness and the set intersection problem.

</details>


### [148] [Implementation and Brief Experimental Analysis of the Duan et al. (2025) Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2511.03007)
*Lucas Castro,Thailsson Clementino,Rosiane de Freitas*

Main category: cs.DS

TL;DR: 我们实现了Duan等人的SSSP算法，并在稀疏图上与Dijkstra进行了比较，发现Dijkstra在实践中更快。


<details>
  <summary>Details</summary>
Motivation: 实现Duan等人提出的SSSP算法，并分析其与Dijkstra算法的实际性能差异。

Method: 对Duan等人的SSSP算法进行C++实现，并在合成稀疏随机图和DIMACS基准的真实世界道路网络实例上，与使用二元堆的经典Dijkstra算法进行实验比较。

Result: 尽管Duan等人的算法具有更好的渐近复杂度 O(m log^{2/3} n)，但其常数因子较大，导致在所有测试的稀疏图规模下，Dijkstra算法均表现更快。实验中的实现由于使用了哈希表，其预期时间复杂度为 O(m log^{2/3} n)。

Conclusion: 对于稀疏图，Dijkstra算法在实践中比Duan等人的新算法更优，主要原因是后者的常数因子较大。未来研究将考虑如何优化该算法以达到最坏情况下的性能。

Abstract: We present an implementation and a brief experimental analysis of the
deterministic algorithm proposed by Duan et al. (2025) for the Single-Source
Shortest Path (SSSP) problem, which achieves the best known asymptotic upper
bound in the comparison-addition model, with running time $O(m \log^{2/3} n)$.
We provide a faithful C++ implementation of this algorithm, following all
structural details described in the original paper, and compare its empirical
performance with the classical Dijkstra's algorithm using binary heaps. The
experiments were conducted on both synthetic sparse random graphs and
real-world road network instances from the DIMACS benchmark. Our results show
that, despite its superior asymptotic complexity, the new algorithm presents
significantly larger constant factors, making Dijkstra's algorithm faster for
all tested sparse graph sizes, including instances with tens of millions of
vertices. Our implementation achieves $O(m \log^{2/3} n)$ expected time, due to
the use of hash tables, and some possibilities for making it worst-case are
being considered. (This is a ongoing work.)

</details>


### [149] [A Branch-and-Bound Approach for Maximum Low-Diameter Dense Subgraph Problems](https://arxiv.org/abs/2511.03157)
*Yi Zhoua,Chunyu Luoa,Zhengren Wangb,Zhang-Hua Fuc*

Main category: cs.DS

TL;DR: 本文提出了一种基于分解的分支定界算法，用于在图中寻找具有直径至多为2的最大f(·)-稠密子图。


<details>
  <summary>Details</summary>
Motivation: f(·)-稠密图的概念可以表示各种团模型，这些模型在内聚子图提取中有应用。然而，f(·)-稠密图可能不连通。为了解决这个问题，本文研究了寻找具有直径至多为2的最大f(·)-稠密子图的问题。

Method: 本文提出了一种基于分解的分支定界算法。该算法的关键特性是分解框架，将图分解为n个子图，允许在每个子图中独立搜索。此外，研究人员还引入了包括简并和双简并排序在内的分解策略，以及一个具有新颖的基于排序的上界的と分支定界算法来解决每个子问题。

Result: 在两个f(·)函数下，在139个真实世界图上的实证结果表明，与MIP求解器和纯分支定界算法相比，本文提出的算法性能更优，在一个小时内解决了近两倍的实例。

Conclusion: 本文提出了一种用于寻找最大f(·)-稠密子图（直径至多为2）的分解式分支定界算法，并在实际应用中展示了其优越性。

Abstract: A graph with $n$ vertices is an $f(\cdot)$-dense graph if it has at least
$f(n)$ edges, $f(\cdot)$ being a well-defined function. The notion
$f(\cdot)$-dense graph encompasses various clique models like $\gamma$-quasi
cliques, $k$-defective cliques, and dense cliques, arising in cohesive subgraph
extraction applications. However, the $f(\cdot)$-dense graph may be
disconnected or weakly connected. To conquer this, we study the problem of
finding the largest $f(\cdot)$-dense subgraph with a diameter of at most two in
the paper. Specifically, we present a decomposition-based branch-and-bound
algorithm to optimally solve this problem. The key feature of the algorithm is
a decomposition framework that breaks the graph into $n$ smaller subgraphs,
allowing independent searches in each subgraph. We also introduce decomposition
strategies including degeneracy and two-hop degeneracy orderings, alongside a
branch-and-bound algorithm with a novel sorting-based upper bound to solve each
subproblem. Worst-case complexity for each component is provided. Empirical
results on 139 real-world graphs under two $f(\cdot)$ functions show our
algorithm outperforms the MIP solver and pure branch-and-bound, solving nearly
twice as many instances optimally within one hour.

</details>


### [150] [Optimal Stopping with a Predicted Prior](https://arxiv.org/abs/2511.03289)
*Tian Bai,Zhiyi Huang,Chui Shan Lee,Dongchen Li*

Main category: cs.DS

TL;DR: 在最优停时问题中，我们提出了一个考虑了可能存在错误的先验知识的模型，并设计了能够平衡利用先验知识和保证最坏情况下的性能的算法。


<details>
  <summary>Details</summary>
Motivation: 现有最优停时模型要么是基于完全无先验知识（秘书模型），要么是基于完全掌握先验知识（预言机不等式模型），而实际中决策者可能依赖于可能存在错误的机器学习先验。本研究旨在弥合这一差距。

Method: 提出一个包含‘预测先验’的最优停时模型，并设计能够同时保持一致性（在先验准确时利用它）和鲁棒性（在先验不准确时仍有可接受的最坏情况保证）的算法。探索了一类双标准算法，以权衡最大化预期接受值和最大化接受最大值这两种目标。

Result: 所提出的双标准算法在一致性和鲁棒性之间实现了比现有算法更好的权衡。对于最大化接受最大值这一目标，证明了不存在能同时达到最优预言机算法的一致性和最优秘书算法的鲁棒性的算法。

Conclusion: 在最优停时问题中，考虑带有潜在错误的预测先验是必要的。所提出的双标准算法能够有效平衡一致性和鲁棒性。对于最大化接受最大值这一特定目标，存在理论上的最优界限，限制了算法在一致性和鲁棒性上同时达到最优的可能性。

Abstract: There are two major models of value uncertainty in the optimal stopping
literature: the secretary model, which assumes no prior knowledge, and the
prophet inequality model, which assumes full information about value
distributions. In practice, decision makers often rely on machine-learned
priors that may be erroneous. Motivated by this gap, we formulate the model of
optimal stopping with a predicted prior to design algorithms that are both
consistent, exploiting the prediction when accurate, and robust, retaining
worst-case guarantees when it is not.
  Existing secretary and prophet inequality algorithms are either pessimistic
in consistency or not robust to misprediction. A randomized combination only
interpolates their guarantees linearly. We show that a family of bi-criteria
algorithms achieves improved consistency-robustness trade-offs, both for
maximizing the expected accepted value and for maximizing the probability of
accepting the maximum value. We further prove that for the latter objective, no
algorithm can simultaneously match the best prophet inequality algorithm in
consistency, and the best secretary algorithm in robustness.

</details>


### [151] [Improved Online Load Balancing in the Two-Norm](https://arxiv.org/abs/2511.03345)
*Sander Borst,Danish Kashaev*

Main category: cs.DS

TL;DR: 本研究提出了一种新的算法，将在线负载均衡问题在不相关机器上的竞争比从5提高到4.9843。


<details>
  <summary>Details</summary>
Motivation: 在线负载均衡问题在不相关机器上的目标是最小化机器负载的 L2 范数的平方。之前的最优确定性算法竞争比为 3 + 2√2，而基于独立舍入的随机算法竞争比为 5。本研究旨在突破 5 的竞争比限制。

Method: 研究采用了一种新的对偶框架，该框架基于半定规划松弛，并结合了 Im 和 Shadloo 的相关随机舍入程序。该框架还为现有的算法提供了新的、更简洁的证明，并提出了一个新的 4-竞争性分数算法。

Result: 本研究提出的新算法竞争比为 4.9843，这是首次突破 5 的竞争比。此外，研究还为现有的 $(3 + 2 esources{2})$ - 竞争性贪婪算法和 5 - 竞争性随机独立舍入算法提供了新的证明，并提出了一个新的 4 - 竞争性最优分数算法。

Conclusion: 本研究在在线负载均衡问题上取得了重要进展，提出的新算法竞争比低于 5。新的对偶框架为分析该问题提供了一种统一的方法，并为未来的研究奠定了基础。

Abstract: We study the online load balancing problem on unrelated machines, with the
objective of minimizing the square of the $\ell_2$ norm of the loads on the
machines. The greedy algorithm of Awerbuch et al. (STOC'95) is optimal for
deterministic algorithms and achieves a competitive ratio of $3 + 2 \sqrt{2}
\approx 5.828$, and an improved $5$-competitive randomized algorithm based on
independent rounding has been shown by Caragiannis (SODA'08). In this work, we
present the first algorithm breaking the barrier of $5$ on the competitive
ratio, achieving a bound of $4.9843$. To obtain this result, we use a new
primal-dual framework to analyze this problem based on a natural semidefinite
programming relaxation, together with an online implementation of a correlated
randomized rounding procedure of Im and Shadloo (SODA'20). This novel
primal-dual framework also yields new, simple and unified proofs of the
competitive ratio of the $(3 + 2 \sqrt{2})$-competitive greedy algorithm, the
$5$-competitive randomized independent rounding algorithm, and that of a new
$4$-competitive optimal fractional algorithm. We also provide lower bounds
showing that the previous best randomized algorithm is optimal among
independent rounding algorithms, that our new fractional algorithm is optimal,
and that a simple greedy algorithm is optimal for the closely related online
scheduling problem $R || \sum w_j C_j$.

</details>


### [152] [Hesse's Redemption: Efficient Convex Polynomial Programming](https://arxiv.org/abs/2511.03440)
*Lucas Slot,David Steurer,Manuel Wiedmer*

Main category: cs.DS

TL;DR: 该论文针对凸多项式规划问题，提出了首个多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 现有的凸优化算法（如椭圆方法）需要先验界定包含最优解的球半径，这对于半定规划等问题来说计算复杂度很高。而对于更高次数的无约束凸多项式最小化问题，最优解缺乏线性刻画，且现有方法不适用，是一个悬而未决的基础问题。

Method: 开发了新的技术来证明在缺乏线性刻画时也存在解界。对于在多面体上最小化凸多项式（任意次数）的问题，证明了如果存在最优解，则必存在一个具有多项式比特长度的近似最优解。结合椭圆方法，得到了凸多项式规划的首个多项式时间算法。

Result: 证明了即使在最优解不存在线性刻画的情况下，只要存在最优解，就一定存在一个比特长度为多项式的近似最优解。这使得能够为凸多项式规划（包括任意次数的无约束凸多项式最小化）开发出首个多项式时间算法。

Conclusion: 该研究为凸多项式规划问题提供了首个多项式时间算法，解决了Nesterov（2019）提出的一个长期存在的问题。

Abstract: Efficient algorithms for convex optimization, such as the ellipsoid method,
require an a priori bound on the radius of a ball around the origin guaranteed
to contain an optimal solution if one exists. For linear and convex quadratic
programming, such solution bounds follow from classical characterizations of
optimal solutions by systems of linear equations. For other programs, e.g.,
semidefinite ones, examples due to Khachiyan show that optimal solutions may
require huge coefficients with an exponential number of bits, even if we allow
approximations. Correspondingly, semidefinite programming is not even known to
be in NP. The unconstrained minimization of convex polynomials of degree four
and higher has remained a fundamental open problem between these two extremes:
its optimal solutions do not admit a linear characterization and, at the same
time, Khachiyan-type examples do not apply. We resolve this problem by
developing new techniques to prove solution bounds when no linear
characterizations are available. Even for programs minimizing a convex
polynomial (of arbitrary degree) over a polyhedron, we prove that the existence
of an optimal solution implies that an approximately optimal one with
polynomial bit length also exists. These solution bounds, combined with the
ellipsoid method, yield the first polynomial-time algorithm for convex
polynomial programming, settling a question posed by Nesterov (Math. Program.,
2019). Before, no polynomial-time algorithm was known even for unconstrained
minimization of a convex polynomial of degree four.

</details>


### [153] [Dynamic Meta-Kernelization](https://arxiv.org/abs/2511.03461)
*Christian Bertram,Deborah Haun,Mads Vestergaard Jensen,Tuukka Korhonen*

Main category: cs.DS

TL;DR: 本文将图问题的线性核化技术扩展到动态图设置，为平面图上的支配集问题提供了一个动态线性核，并为满足特定条件的图类提供了类似的算法。


<details>
  <summary>Details</summary>
Motivation: 将图问题的核化研究从静态图扩展到动态图，特别是关注在稀疏图类上具有线性核的经典NP-hard图问题。

Method: 提出一个动态数据结构，用于维护动态拓扑-minor-free图的近似最优凸出分解。利用该分解技术，为平面图上的支配集问题开发了一个动态线性核。

Result: 初始化的动态核大小为O(OPT(G))，并且在每次图更新后，能在O(log n)的摊销时间内输出O(1)个核更新，同时保持核的最优性和线性大小，并保证核的平面性。该方法还可推广到其他满足特定条件的图类。

Conclusion: 成功地将核化研究领域中重要的线性核结果提升到了动态图设置，不仅为支配集问题提供了有效的动态算法，也为其他图问题带来了新的动态近似算法和参数化算法改进。

Abstract: Kernelization studies polynomial-time preprocessing algorithms. Over the last
20 years, the most celebrated positive results of the field have been linear
kernels for classical NP-hard graph problems on sparse graph classes. In this
paper, we lift these results to the dynamic setting.
  As the canonical example, Alber, Fellows, and Niedermeier [J. ACM 2004] gave
a linear kernel for dominating set on planar graphs. We provide the following
dynamic version of their kernel: Our data structure is initialized with an
$n$-vertex planar graph $G$ in $O(n \log n)$ amortized time, and, at
initialization, outputs a planar graph $K$ with $\mathrm{OPT}(K) =
\mathrm{OPT}(G)$ and $|K| = O(\mathrm{OPT}(G))$, where $\mathrm{OPT}(\cdot)$
denotes the size of a minimum dominating set. The graph $G$ can be updated by
insertions and deletions of edges and isolated vertices in $O(\log n)$
amortized time per update, under the promise that it remains planar. After each
update to $G$, the data structure outputs $O(1)$ updates to $K$, maintaining
$\mathrm{OPT}(K) = \mathrm{OPT}(G)$, $|K| = O(\mathrm{OPT}(G))$, and planarity
of $K$.
  Furthermore, we obtain similar dynamic kernelization algorithms for all
problems satisfying certain conditions on (topological-)minor-free graph
classes. Besides kernelization, this directly implies new dynamic
constant-approximation algorithms and improvements to dynamic FPT algorithms
for such problems.
  Our main technical contribution is a dynamic data structure for maintaining
an approximately optimal protrusion decomposition of a dynamic
topological-minor-free graph. Protrusion decompositions were introduced by
Bodlaender, Fomin, Lokshtanov, Penninkx, Saurabh, and Thilikos [J. ACM 2016],
and have since developed into a part of the core toolbox in kernelization and
parameterized algorithms.

</details>


### [154] [Online Flow Time Minimization: Tight Bounds for Non-Preemptive Algorithms](https://arxiv.org/abs/2511.03485)
*Yutong Geng,Enze Sun,Zonghan Yang,Yuhao Zhang*

Main category: cs.DS

TL;DR: 本篇论文研究了在 m 台相同机器上最小化总流量时间的经典在线调度问题。通过引入新的随机化算法和确定性算法，论文将随机化非抢占式设置的竞争比从 O(n) 提高到 Θ(√n/m)，并为确定性设置提供了 O(n/m^2 + √n/m log m) 的竞争比。此外，论文还研究了 kill-and-restart 模型，并探讨了在未知作业数量 n 的情况下的调度问题。


<details>
  <summary>Details</summary>
Motivation: 这篇论文旨在解决经典在线调度问题中关于最小化总流量时间的几个基本问题，特别是探讨随机化和多机设置下确定性算法的界限。

Method: 论文提出了一种具有 Θ(√n/m) 竞争比的随机化算法，并证明了匹配的随机化下界。同时，还提出了一种具有 O(n/m^2 + √n/m log m) 竞争比的确定性算法，并给出了接近的下界。此外，论文还分析了 kill-and-restart 模型，并在作业数量未知的情况下进行了研究。

Result: 论文得出了随机化非抢占式设置的竞争比为 Θ(√n/m)，并改进了离线近似比。在确定性设置方面，提出了 O(n/m^2 + √n/m log m) 的竞争比算法。在 kill-and-restart 模型中，为 m≥2 设计了 O(√n/m) 竞争比的算法，并为 m=1 证明了 Ω(n/log n) 的下界。在未知 n 的情况下，证明了 kill-and-restart 的能力，但随机化不足以突破 O(n) 障碍。

Conclusion: 本研究解决了在线调度中随机化和确定性算法的竞争比问题，并在 kill-and-restart 模型以及未知作业数量的情况下提供了新的见解和算法。

Abstract: This paper studies the classical online scheduling problem of minimizing
total flow time for $n$ jobs on $m$ identical machines. Prior work often cites
the $\Omega(n)$ lower bound for non-preemptive algorithms to argue for the
necessity of preemption or resource augmentation, which shows the trivial
$O(n)$-competitive greedy algorithm is tight. However, this lower bound applies
only to \emph{deterministic} algorithms in the \emph{single-machine} case,
leaving several fundamental questions unanswered. Can randomness help in the
non-preemptive setting, and what is the optimal online deterministic algorithm
when $m \geq 2$? We resolve both questions. We present a polynomial-time
randomized algorithm with competitive ratio $\Theta(\sqrt{n/m})$ and prove a
matching randomized lower bound, settling the randomized non-preemptive setting
for every $m$. This also improves the best-known offline approximation ratio
from $O(\sqrt{n/m}\log(n/m))$ to $O(\sqrt{n/m})$. On the deterministic side, we
present a non-preemptive algorithm with competitive ratio
$O(n/m^{2}+\sqrt{n/m}\log m)$ and prove a nearly matching lower bound.
  Our framework also extends to the kill-and-restart model, where we reveal a
sharp transition of deterministic algorithms: we design an asymptotically
optimal algorithm with the competitive ratio $O(\sqrt{n/m})$ for $m\ge 2$, yet
establish a strong $\Omega(n/\log n)$ lower bound for $m=1$. Moreover, we show
that randomization provides no further advantage, as the lower bound coincides
with that of the non-preemptive setting.
  While our main results assume prior knowledge of $n$, we also investigate the
setting where $n$ is unknown. We show kill-and-restart is powerful enough to
break the $O(n)$ barrier for $m \geq 2$ even without knowing $n$. Conversely,
we prove randomization alone is insufficient, as no algorithm can achieve an
$o(n)$ competitive ratio in this setting.

</details>


### [155] [Randomized Rounding over Dynamic Programs](https://arxiv.org/abs/2511.03490)
*Etienne Bamas,Shi Li,Lars Rohwedder*

Main category: cs.DS

TL;DR: 该论文提出了一种新颖的方法，可以在满足近似打包约束的条件下，为具有动态规划（DP）类递推关系的问题找到解。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界中的问题，即使其基础结构可以用动态规划来解决，但也常常伴随着额外的、难以处理的约束条件。本研究的动机是开发一种能够处理这些近似约束的通用算法。

Method: 研究将DP子问题重新解释为网络设计问题，并利用强线性规划（LP）松弛和随机取整技术来构建算法。

Result: 该算法能在$n^{O(1/\epsilon)}$时间内获得$(n^{\epsilon} \mathrm{polylog}\ n)$-近似解，其中$n$是问题规模，$\epsilon > 0$。通过调整$\epsilon$的值，可以得到准多项式时间的对数多项式近似或多项式时间内的$n^{\epsilon}$-近似。

Conclusion: 该方法适用于多种经典的DP问题，并能将额外的打包约束（甚至覆盖约束）融入其中，为近似算法领域中许多先前未与DP联系起来的问题提供了新的建模方式。

Abstract: We show that under mild assumptions for a problem whose solutions admit a
dynamic programming-like recurrence relation, we can still find a solution
under additional packing constraints, which need to be satisfied approximately.
The number of additional constraints can be very large, for example, polynomial
in the problem size. Technically, we reinterpret the dynamic programming
subproblems and their solutions as a network design problem. Inspired by
techniques from, for example, the Directed Steiner Tree problem, we construct a
strong LP relaxation, on which we then apply randomized rounding. Our
approximation guarantees on the packing constraints have roughly the form of a
$(n^{\epsilon} \mathrm{polylog}\ n)$-approximation in time $n^{O(1/\epsilon)}$,
for any $\epsilon > 0$. By setting $\epsilon=\log \log n/\log n$, we obtain a
polylogarithmic approximation in quasi-polynomial time, or by setting
$\epsilon$ as a constant, an $n^\epsilon$-approximation in polynomial time.
  While there are necessary assumptions on the form of the DP, it is general
enough to capture many textbook dynamic programs from Shortest Path to Longest
Common Subsequence. Our algorithm then implies that we can impose additional
constraints on the solutions to these problems. This allows us to model various
problems from the literature in approximation algorithms, many of which were
not thought to be connected to dynamic programming. In fact, our result can
even be applied indirectly to some problems that involve covering instead of
packing constraints, for example, the Directed Steiner Tree problem, or those
that do not directly follow a recurrence relation, for example, variants of the
Matching problem.

</details>


### [156] [Engineering Algorithms for $\ell$-Isolated Maximal Clique Enumeration](https://arxiv.org/abs/2511.03525)
*Marco D'Elia,Irene Finocchi,Maurizio Patrignani*

Main category: cs.DS

TL;DR: 该论文提出了一种枚举孤立团体的算法，通过调整参数来控制孤立程度，并设计了四种剪枝启发式方法来提高效率，特别是在社交网络类型的数据集上。


<details>
  <summary>Details</summary>
Motivation: 由于最大团的数量庞大，即使在稀疏的真实世界图中，也可能难以有效利用。为了解决这个问题，可以枚举孤立团体，其顶点平均与图的其余部分只有少于l条边。

Method: 在Tomita等人提出的最大团枚举算法的基础上，提出四种剪枝启发式方法，可以单独或组合使用，丢弃那些不能产生l-孤立最大团的递归搜索分支。证明了这些方法的正确性，并分析了它们的剪枝能力和计算成本。

Result: 通过广泛的实验研究，将所提出的方法与Tomita基线和最先进的方法进行了比较。结果表明，其中两种启发式方法显著提高了效率，尤其是在具有社交网络特性的真实世界图中。

Conclusion: 所提出的剪枝启发式方法可以显著提高孤立团枚举算法的效率，特别是在社交网络数据集上。

Abstract: Maximal cliques play a fundamental role in numerous application domains,
where their enumeration can prove extremely useful. Yet their sheer number,
even in sparse real-world graphs, can make them impractical to be exploited
effectively. To address this issue, one approach is to enumerate
$\ell$-isolated maximal cliques, whose vertices have (on average) less than
$\ell$ edges toward the rest of the graph. By tuning parameter $\ell$, the
degree of isolation can be controlled, and cliques that are overly connected to
the outside are filtered out. Building on Tomita et al.'s very practical
recursive algorithm for maximal clique enumeration, we propose four pruning
heuristics, applicable individually or in combination, that discard recursive
search branches that are guaranteed not to yield $\ell$-isolated maximal
cliques. Besides proving correctness, we characterize both the pruning power
and the computational cost of these heuristics, and we conduct an extensive
experimental study comparing our methods with Tomita's baseline and with a
state-of-the-art approach. Results show that two of our heuristics offer
substantial efficiency improvements, especially on real-world graphs with
social network properties.

</details>


### [157] [Improved Bounds with a Simple Algorithm for Edge Estimation for Graphs of Unknown Size](https://arxiv.org/abs/2511.03650)
*Debarshi Chanda*

Main category: cs.DS

TL;DR: 该论文提出了一种新的随机算法，通过极少数的查询（包括Degree和Random Edge查询）可以在近似O(α/ε^2d)次查询内估计图中平均度d，其精度为(1±ε)。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在改进现有算法在图平均度估计方面的查询效率，特别是针对具有特定参数（如α表示森林度）的图，并解决了[Beretta et al., SODA 2026]提出的相关问题。

Method: 论文提出了一种新的估计技术，实现了一种随机算法，仅使用Degree和Random Edge查询来估计图的平均度d。该算法不需要图的参数（如顶点数量n），并且具有简单性和实用性。此外，论文还推导了使用Degree、Neighbour和Random Edge查询以及Pair和FullNbr查询的最优查询次数下界。

Result: 算法在查询次数上优于现有算法[Beretta et al., SODA 2026]，并且证明了在不同查询模型下估计平均度的下界。具体来说，平均度估计的查询次数下界为Ω(min(d, α/d))。

Conclusion: 该研究在图平均度估计方面取得了显著进展，提出的算法在查询效率上优于现有方法，并提供了最优查询次数的理论下界，为未来研究提供了方向。

Abstract: We propose a randomized algorithm with query access that given a graph $G$
with arboricity $\alpha$, and average degree $d$, makes
$\widetilde{O}\left(\frac{\alpha}{\varepsilon^2d}\right)$ \texttt{Degree} and
$\widetilde{O}\left(\frac{1}{\varepsilon^2}\right)$ \texttt{Random Edge}
queries to obtain an estimate $\widehat{d}$ satisfying $\widehat{d} \in
(1\pm\varepsilon)d$. This improves the $\widetilde{O}_{\varepsilon,\log
n}\left(\sqrt{\frac{n}{d}}\right)$ query algorithm of [Beretta et al., SODA
2026] that has access to \texttt{Degree}, \texttt{Neighbour}, and
\texttt{Random Edge} queries. Our algorithm does not require any graph
parameter as input, not even the size of the vertex set, and attains both
simplicity and practicality through a new estimation technique. We complement
our upper bounds with a lower bound that shows for all valid $n,d$, and
$\alpha$, any algorithm that has access to \texttt{Degree}, \texttt{Neighbour},
and \texttt{Random Edge} queries, must make at least
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$, even with the knowledge of
$n$ and $\alpha$. We also show that even with \texttt{Pair} and
\texttt{FullNbr} queries, an algorithm must make
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$. Our work addresses both the
questions raised by the work of [Beretta et al., SODA 2026].

</details>


### [158] [An Improved Quality Hierarchical Congestion Approximator in Near-Linear Time](https://arxiv.org/abs/2511.03716)
*Monika Henzinger,Robin Münk,Harald Räcke*

Main category: cs.DS

TL;DR: 本文提出了一个能在近线性时间内实现 O(log^2 n log log n) 逼近的网络拥塞近似算法，并给出了 O(log n) 的最优下界。


<details>
  <summary>Details</summary>
Motivation: 在已有算法的运行时间和逼近质量之间存在权衡的情况下，研究如何同时优化这两者，特别是提出一个能在近线性时间内实现更好逼近的网络拥塞近似算法。

Method: 提出了一种分层拥塞近似器，包含 O(n log n) 个割。算法基于一种新的划分例程，避免了对大子图的递归。引入了“边界可路由性”概念，并给出了改进的稀疏割预言机。

Result: 在近线性时间内，以高概率实现了 O(log^2 n log log n) 的逼近。该算法在并行计算环境中也能达到相同的逼近质量，并具有 O(log n) 的近似质量下界。并改进了稀疏割预言机。

Conclusion: 本文提出的近线性时间算法在拥塞近似方面取得了显著的改进，并且给出了理论上的最优下界。同时，该算法在并行计算方面也表现出色。

Abstract: A congestion approximator for a graph is a compact data structure that
approximately predicts the edge congestion required to route any set of flow
demands in a network. A congestion approximator is hierarchical if it consists
of a laminar family of cuts in the graph. There is a tradeoff between the
running time for computing a congestion approximator and its approximation
quality. Currently, for an $n$-node graph there exists a polynomial time
algorithm that achieves a $O(\log^{1.5}n \log \log n)$ approximation and a
near-linear time algorithm that achieves w.h.p. a $O(\log^4 n)$ approximation.
In this paper we give the first near-linear time algorithm, that achieves
w.h.p. a $O(\log^2 n \log \log n)$ approximation, using an hierarchical
congestion approximator with $O(n \log n)$ cuts. Based on a reduction from
oblivious routing, we also present a lower bound of $\Omega(\log n)$ for the
approximation quality of hierarchical congestion approximators.
  Our algorithm can also be implemented in the parallel setting achieving the
same approximation quality, polylogarithmic span and near-linear work. This
improves upon the best prior parallel algorithm, which has a $O(\log^9n)$
approximation.
  Crucial for achieving a near linear running time is a new partitioning
routine that, unlike previous such routines, manages to avoid recursing on
large subgraphs. To achieve the improved approximation quality, we introduce
the new concept of border routability of a cut and give an improved sparsest
cut oracle for general vertex weights.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [159] [Force-Based Reading and Writing of Individual Single-Atom Magnets](https://arxiv.org/abs/2511.03413)
*Yuuki Adachi,Kazuki Ueda,Yuuki Yasui,Yoshiaki Sugimoto*

Main category: physics.app-ph

TL;DR: 利用磁交换力显微镜读写单个钬原子的自旋方向，以实现高密度、低能耗的存储。


<details>
  <summary>Details</summary>
Motivation: 实现高数据密度存储和低热量产生的磁性器件的操作。

Method: 使用磁交换力显微镜（MEFM）读取和写入单个钬（Ho）原子在氧化镁（MgO）薄膜上的自旋取向。通过测量磁性探针尖端与原子之间的交换力来读取自旋取向，通过将探针尖端拉近钬原子来写入自旋取向。

Result: 成功实现了对单个钬原子的自旋取向进行读写操作，并解释了写入机制与对称性降低有关。

Conclusion: 证明了原子尺度机械电子学在信息存储领域的潜力，实现了低能量损耗的信息存储。

Abstract: The integration of single-atom bits enables the realization of the highest
data-density memory. Reading and writing information to these bits through
mechanical interactions opens the possibility of operating the magnetic devices
with low heat generation and high density recording. To achieve this visionary
goal, we demonstrate the use of magnetic exchange force microscopy to read and
write the spin orientation of individual holmium adatoms on MgO thin films. The
spin orientation of the holmium adatom is stabilized by the strong uniaxial
anisotropy of the adsorption site and can be read out by measuring the exchange
forces between the magnetic tip and the atom. The spin orientation can be
written by approaching the tip closer to the holmium adatom.We explain this
writing mechanism by the symmetry reduction of the adsorption site of the Ho
adatom. These findings demonstrate the potential for information storage with
minimal energy loss and pave the way for a new field of atomic-scale
mechano-spintronics.

</details>


### [160] [ENDF/B-VIII.1: Updated Nuclear Reaction Data Library for Science and Applications](https://arxiv.org/abs/2511.03564)
*G. P. A. Nobre,R. Capote,M. T. Pigni,A. Trkov,C. M. Mattoon,D. Neudecker,D. A. Brown,M. B. Chadwick,A. C. Kahler,N. A. Kleedtke,M. Zerkle,A. I. Hawari,C. W. Chapman,N. C. Fleming,J. L. Wormald,K. Ramić,Y. Danon,N. A. Gibson,P. Brain,M. W. Paris,G. M. Hale,I. J. Thompson,D. P. Barry,I. Stetcu,W. Haeck,A. E. Lovell,M. R. Mumpower,G. Potel,K. Kravvaris,G. Noguere,J. D. McDonnell,A. D. Carlson,M. Dunn,T. Kawano,D. Wiarda,I. Al-Qasir,G. Arbanas,R. Arcilla,B. Beck,D. Bernard,R. Beyer,J. M. Brown,O. Cabellos,R. J. Casperson,Y. Cheng,E. V. Chimanski,R. Coles,M. Cornock,J. Cotchen,J. P. W. Crozier,D. E. Cullen,A. Daskalakis,M. -A. Descalle,D. D. DiJulio,P. Dimitriou,A. C. Dreyfuss,I. Durán,R. Ferrer,T. Gaines,V. Gillette,G. Gert,K. H. Guber,J. D. Haverkamp,M. W. Herman,J. Holmes,M. Hursin,N. Jisrawi,A. R. Junghans,K. J. Kelly,H. I. Kim,K. S. Kim,A. J. Koning,M. Koštál,B. K. Laramee,A. Lauer-Coles,L. Leal,H. Y. Lee,A. M. Lewis,J. Malec,J. I. Márquez Damián,W. J. Marshall,A. Mattera,G. Muhrer,A. Ney,W. E. Ormand,D. K. Parsons,C. M. Percher,V. G. Pronyaev,A. Qteish,S. Quaglioni,M. Rapp,J. J. Ressler,M. Rising,D. Rochman,P. K. Romano,D. Roubtsov,G. Schnabel,M. Schulc,G. J. Siemers,A. A. Sonzogni,P. Talou,J. Thompson,T. H. Trumbull,S. C. van der Marck,M. Vorabbi,C. Wemple,K. A. Wendt,M. White,R. Q. Wright*

Main category: physics.app-ph

TL;DR: ENDF/B-VIII.1是最新推荐的核数据库，相较于ENDF/B-VIII.0，在核数据评估方面有了显著改进，特别是针对关键核素如$^{239}$Pu、$^{238}$U等进行了重新评估，并整合了来自IAEA的更新数据和新核数据子库，提高了在高燃耗情况下的模拟精度，并已发布END F-6和GNDS格式。


<details>
  <summary>Details</summary>
Motivation: ENDF/B-VIII.0在商业核电应用中存在数据问题，特别是在高燃耗情况下，需要更新和改进核数据库以解决这些问题，并满足核科学与技术应用的需求。

Method: ENDF/B-VIII.1通过对$^{239}$Pu等关键核素进行联合国际重新评估，采纳IAEA协调的INDEN合作项目更新的核数据，以及采用IAEA的IRDFF-II库中的中子注量计截面等方式进行更新。同时，对光核、带电粒子和原子亚库中的核数据进行了补充，并重新评估了热中子散射核。在协方差方面，引入了更好的不确定性量化标准和测试。

Result: ENDF/B-VIII.1在关键核素的重新评估和数据更新后，显著减少了许多积分实验模拟中的偏差，尤其在含氟、铜和不锈钢的基准测试中取得了显著进展。针对高燃耗情况下的问题，通过改进$^{238}$U和$^{239,240,241}$Pu在共振区的评估数据，使得新库在高燃耗情况下的性能与ENDF/B-VII.1相当。

Conclusion: ENDF/B-VIII.1库通过一系列关键核素的重新评估和数据更新，解决了ENDF/B-VIII.0在高燃耗应用中存在的问题，提高了模拟精度和可靠性，为核科学与技术应用提供了更优的解决方案。该库已在ENDF-6和GNDS格式下发布。

Abstract: The ENDF/B-VIII.1 library is the newest recommended evaluated nuclear data
file by the Cross Section Evaluation Working Group (CSEWG) for use in nuclear
science and technology applications, and incorporates advances made in the six
years since the release of ENDF/B-VIII.0. Among key advances made are that the
$^{239}$Pu file was reevaluated by a joint international effort and that
updated $^{16,18}$O, $^{19}$F, $^{28-30}$Si, $^{50-54}$Cr, $^{55}$Mn,
$^{54,56,57}$Fe, $^{63,65}$Cu, $^{139}$La, $^{233,235,238}$U, and
$^{240,241}$Pu neutron nuclear data from the IAEA coordinated INDEN
collaboration were adopted. Over 60 neutron dosimetry cross sections were
adopted from the IAEA's IRDFF-II library. In addition, the new library includes
significant changes for $^3$He, $^6$Li,$^9$Be, $^{51}$V, $^{88}$Sr, $^{103}$Rh,
$^{140,142}$Ce, Dy, $^{181}$Ta, Pt, $^{206-208}$Pb, and $^{234,236}$U neutron
data, and new nuclear data for the photonuclear, charged-particle and atomic
sublibraries. Numerous thermal neutron scattering kernels were reevaluated or
provided for the very first time. On the covariance side, work was undertaken
to introduce better uncertainty quantification standards and testing for
nuclear data covariances. The significant effort to reevaluate important
nuclides has reduced bias in the simulations of many integral experiments with
particular progress noted for fluorine, copper, and stainless steel containing
benchmarks. Data issues hindered the successful deployment of the previous
ENDF/B-VIII.0 for commercial nuclear power applications in high burnup
situations. These issues were addressed by improving the $^{238}$U and
$^{239,240,241}$Pu evaluated data in the resonance region. The new library
performance as a function of burnup is similar to the reference ENDF/B-VII.1
library. The ENDF/B-VIII.1 data are available in ENDF-6 and GNDS format at
https://doi.org/10.11578/endf/2571019.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [161] [GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models](https://arxiv.org/abs/2511.03251)
*Zhibin Wang,Zhixing Zhang,Shuqi Wang,Xuanting Xie,Zhao Kang*

Main category: cs.LG

TL;DR: GMoPE是一个结合了MoE和提示学习的图神经网络框架，旨在提高模型的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络在跨领域和跨任务的泛化能力有限，存在负迁移、可扩展性和高适应成本等问题。

Method: 提出GMoPE框架，结合MoE架构和提示学习，利用专家特定的提示向量和结构感知的MoE路由，并通过软正交约束促进专家多样性，采用仅提示微调策略。

Result: GMoPE在各种预训练策略和下游任务的实验中，始终优于最先进的基线模型，并且在仅需少量适应开销的情况下达到了与全参数微调相当的性能。

Conclusion: GMoPE为开发可泛化、可扩展的图基础模型提供了一个原则性和可扩展的框架。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance on
task-specific benchmarks, yet their ability to generalize across diverse
domains and tasks remains limited. Existing approaches often struggle with
negative transfer, scalability issues, and high adaptation costs. To address
these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel
framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture
with prompt-based learning for graphs. GMoPE leverages expert-specific prompt
vectors and structure-aware MoE routing to enable each expert to specialize in
distinct subdomains and dynamically contribute to predictions. To promote
diversity and prevent expert collapse, we introduce a soft orthogonality
constraint across prompt vectors, encouraging expert specialization and
facilitating a more balanced expert utilization. Additionally, we adopt a
prompt-only fine-tuning strategy that significantly reduces spatiotemporal
complexity during transfer. We validate GMoPE through extensive experiments
under various pretraining strategies and multiple downstream tasks. Results
show that GMoPE consistently outperforms state-of-the-art baselines and
achieves performance comparable to full parameter fine-tuning-while requiring
only a fraction of the adaptation overhead. Our work provides a principled and
scalable framework for advancing generalizable and efficient graph foundation
models.

</details>


### [162] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: LLMs在形式定理证明方面取得了显著进展，尤其是在IMO等数学竞赛基准上，但这些竞赛未能反映现代数学研究的深度、广度和抽象性。为此，我们引入了FATE（形式代数定理评估）基准系列，包括FATE-H和FATE-X，共包含200个抽象代数和交换代数问题，难度涵盖本科练习到博士资格考试以上。FATE-X是第一个在难度和Mathlib覆盖范围上都超过博士级别考试的基准。在FATE基准上，最先进的LLM证明器的准确率仅分别为FATE-H的3%（pass@64）和FATE-X的0%。模型在自然语言推理方面的准确性远高于其形式化推理能力，且形式化过程中存在系统性的常见错误。此外，专门证明器在反思能力上不如通用模型。FATE为通往研究级形式数学推理的道路提供了重要的检查点。


<details>
  <summary>Details</summary>
Motivation: 当前的数学竞赛基准未能充分反映现代数学研究的深度、广度和抽象性，需要新的基准来评估LLM在更高级数学推理方面的能力。

Method: 引入FATE（形式代数定理评估）基准系列，包括FATE-H和FATE-X，每个包含100个抽象代数和交换代数问题，难度跨度大。评估了最先进的LLM证明器在FATE上的表现，并分析了自然语言推理和形式化推理的差距，以及常见错误和专门证明器的反思能力。

Result: 在FATE基准上，最先进的LLM证明器准确率仅为FATE-H的3%（pass@64），FATE-X为0%。模型的自然语言推理能力优于形式化推理能力。识别了形式化过程中的常见错误，并发现专门证明器反思能力可能不如通用模型。

Conclusion: FATE是一个强大且具有挑战性的新基准，为评估和发展研究级形式数学推理能力提供了重要的检查点，突显了当前LLM在形式化高级数学推理方面存在的巨大差距。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [163] [Stochastic Deep Graph Clustering for Practical Group Formation](https://arxiv.org/abs/2511.02879)
*Junhyung Park,Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DeepForm的框架，用于解决动态场景下的群体推荐问题，通过图聚类技术实现实时、自适应的群体形成，并提升推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有群体推荐系统（GRS）主要关注推荐准确性，但通常假设群体是静态或预定义的，不适用于动态现实场景。因此，将群体形成视为GRS的核心挑战。

Method: DeepForm框架采用轻量级图卷积网络（GCN）架构来捕捉高阶用户结构信息，并利用随机聚类学习实现无需重新训练的自适应群体重构，同时结合对比学习在动态条件下优化群体。

Result: 在多个数据集上的实验表明，DeepForm在群体形成质量、效率和推荐准确性方面优于多种基线方法。

Conclusion: DeepForm能够满足高阶用户信息的整合、实时群体形成以及群体数量的动态调整这三个关键操作要求，为动态群体推荐问题提供了一个有效的解决方案。

Abstract: While prior work on group recommender systems (GRSs) has primarily focused on
improving recommendation accuracy, most approaches assume static or predefined
groups, making them unsuitable for dynamic, real-world scenarios. We reframe
group formation as a core challenge in GRSs and propose DeepForm (Stochastic
Deep Graph Clustering for Practical Group Formation), a framework designed to
meet three key operational requirements: (1) the incorporation of high-order
user information, (2) real-time group formation, and (3) dynamic adjustment of
the number of groups. DeepForm employs a lightweight GCN architecture that
effectively captures high-order structural signals. Stochastic cluster learning
enables adaptive group reconfiguration without retraining, while contrastive
learning refines groups under dynamic conditions. Experiments on multiple
datasets demonstrate that DeepForm achieves superior group formation quality,
efficiency, and recommendation accuracy compared with various baselines.

</details>


### [164] [Test-time Adaptation of Tiny Recursive Models](https://arxiv.org/abs/2511.02886)
*Ronan Killian McGovern*

Main category: cs.LG

TL;DR: TRM 模型可以通过在公共 ARC 任务上进行预训练，然后在比赛任务上进行微调，在计算资源限制内实现有效的性能提升。


<details>
  <summary>Details</summary>
Motivation: TRM 模型在 ARC 竞赛中表现出色，但需要大量计算资源。本研究旨在探索在计算资源限制内，通过预训练和微调 TRM 模型来提高其在竞赛任务上的表现。

Method: 在公共 ARC 任务上预训练一个小型递归模型（TRM），然后在比赛任务上进行全参数微调。

Result: 预训练后的模型在公共评估集上得分约 10%。在比赛期间，经过 12,500 步微调后，模型在半私有评估任务上达到了 6.67% 的得分。

Conclusion: 通过在公共 ARC 任务上预训练 TRM 模型，然后在比赛任务上进行全参数微调，可以在计算资源限制内有效提高模型的性能。

Abstract: Prior to the close of the 2025 ARC Prize competition, the leading open source
approach - known as TRM, or Tiny Recursive Models - involved training a 7M
parameter recursive neural network on augmented variants of ARC tasks. That
approach scored approximately 7.8% on the public ARC AGI II evaluation set, but
required a level of compute far in excess of what is allowed during the
competition. This paper shows that, by starting from a tiny recursive model
that has been pre-trained on public ARC tasks, one can efficiently fine-tune on
competition tasks within the allowed compute limits. Specifically, a model was
pre-trained on 1,280 public tasks for 700k+ optimizer steps over 48 hours on
4xH100 SXM GPUs to obtain a ~10% score on the public evaluation set. That model
was then post-trained in just 12,500 gradient steps during the competition to
reach a score of 6.67% on semi-private evaluation tasks. Notably, such
post-training performance is achieved by full-fine tuning of the tiny model,
not LoRA fine-tuning or fine-tuning of task embeddings alone.

</details>


### [165] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: DiCoDe是一个新的代理-环境协同设计框架，通过PUG和评论家蒸馏机制解决了现有方法的扩展性和样本效率问题，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理-环境协同设计方法在处理高维环境设计空间和联合优化中的移动目标时存在扩展性和样本效率方面的挑战。

Method: DiCoDe框架引入了两种核心创新：1. 投影通用引导（PUG），一种采样技术，用于探索奖励最大化环境的分布，同时满足硬约束。2. 评论家蒸馏机制，用于从强化学习评论家那里共享知识，确保引导扩散模型适应不断变化的代理策略。

Result: DiCoDe在仓库自动化、多代理路径查找和风力发电场优化等具有挑战性的基准测试中，生成了优越的环境-策略对，并在仓库环境中实现了39%的更高奖励和66%的模拟样本减少，超越了现有技术水平。

Conclusion: DiCoDe是一个可扩展且样本高效的协同设计框架，推动了协同设计在实际应用中的发展，并为在现实世界领域中实现协同设计的优势奠定了基础。

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [166] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 本文提出了一种利用海洋参数（如海面温度和叶绿素浓度）预测潜在渔业区（PFZs）的AI辅助框架，以帮助渔民更有效地找到渔场。


<details>
  <summary>Details</summary>
Motivation: 渔民在寻找高产渔场时面临不确定性，该框架旨在提高PFZ识别的准确性并提供针对特定区域的见解，以促进可持续的渔业。

Method: 使用海洋参数（如海面温度和叶绿素浓度）来预测潜在渔业区（PFZs）。

Result: 初步结果表明，该框架可以通过减少搜索时间、降低燃料消耗和促进资源有效利用来支持渔民。

Conclusion: 该AI辅助框架能够帮助渔民提高效率，降低成本，并促进可持续渔业。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [167] [Digital Twin-Driven Pavement Health Monitoring and Maintenance Optimization Using Graph Neural Networks](https://arxiv.org/abs/2511.02957)
*Mohsin Mahmud Topu,Mahfuz Ahmed Anik,Azmine Toushik Wasi,Md Manjurul Ahsan*

Main category: cs.LG

TL;DR: 提出一个结合数字孪生（DT）和图神经网络（GNN）的框架，用于路面健康监测和预测性维护。


<details>
  <summary>Details</summary>
Motivation: 传统路面管理系统（PMS）在应对复杂的空间依赖性、不断变化的环境条件和非线性退化方面存在不足，通常是反应式的，缺乏实时智能。

Method: 将路面和空间关系建模为图的节点和边，通过无人机、传感器和激光雷达等实时数据流输入到数字孪生中，利用归纳式GNN学习退化模式并预测病害。

Result: 在模拟数据集上，该模型达到了0.3798的R2分数，优于基线回归器，并有效捕捉了非线性退化。还开发了交互式仪表板和强化学习模块。

Conclusion: DT-GNN集成提高了预测精度，建立了持续改进的闭环反馈，为主动、智能和可持续的路面管理奠定了基础。

Abstract: Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.

</details>


### [168] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 该研究提出一种利用大语言模型（LLM）进行可穿戴物联网（IoT）设备中人类活动识别（HAR）系统的数据中毒检测与清理的新框架，该框架采用零样本、单样本和少样本学习，并结合“角色扮演”和“逐步思考”提示，以减少对大规模标注数据集的依赖，实现实时、自适应的安全防护。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在提高HAR系统功能性的同时，容易受到数据中毒攻击，而传统的防御方法需要大量特定任务的训练数据，难以适应动态的物联网环境。

Method: 提出一个新框架，利用大语言模型（LLM）进行HAR系统的数据中毒检测与清理。该框架使用零样本、单样本和少样本学习，并结合“角色扮演”提示（LLM扮演专家评估传感器异常）和“逐步思考”推理（LLM推断中毒指标和清理方案）。

Result: 框架在检测准确性、清理质量、延迟和通信成本方面进行了广泛评估，证明了其在提高可穿戴物联网系统安全性和可靠性方面的实用性和有效性。

Conclusion: 利用大语言模型（LLM）通过零样本、单样本和少样本学习，结合“角色扮演”和“逐步思考”提示，可以有效地检测和清理HAR系统中的数据中毒，且对大规模标注数据集的依赖性较低，能够适应动态的物联网环境，提高系统的安全性和可靠性。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [169] [AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing](https://arxiv.org/abs/2511.03697)
*Mohsen Ahmadzadeh,Kaichang Chen,Georges Gielen*

Main category: cs.LG

TL;DR: LLM驱动的AI框架AnaFlow可实现高效、可解释的模拟电路设计自动化。


<details>
  <summary>Details</summary>
Motivation: 模拟/混合信号电路设计是人手完成的，耗时长且易出错。现有AI方法（如强化学习、生成式AI）因需要大量耗时仿真而效率低下，且缺乏可解释性。

Method: 提出了一种新颖的、基于代理的AI框架（AnaFlow），采用多代理协同工作流程。专门的LLM代理负责解析电路拓扑、理解设计目标，并通过可解释的推理迭代优化电路参数。自适应仿真策略提高了样本效率。

Result: AnaFlow框架能够完全自动化地完成电路设计任务，适用于不同复杂度的电路，优于纯贝叶斯优化和强化学习方法。该系统能从优化历史中学习，避免重复错误并加速收敛。

Conclusion: AnaFlow框架实现了样本高效且可解释的模拟电路设计自动化，为模拟设计空间探索提供了强大工具，并开创了AI作为透明设计助手的新型EDA范式。

Abstract: Analog/mixed-signal circuits are key for interfacing electronics with the
physical world. Their design, however, remains a largely handcrafted process,
resulting in long and error-prone design cycles. While the recent rise of
AI-based reinforcement learning and generative AI has created new techniques to
automate this task, the need for many time-consuming simulations is a critical
bottleneck hindering the overall efficiency. Furthermore, the lack of
explainability of the resulting design solutions hampers widespread adoption of
the tools. To address these issues, a novel agentic AI framework for
sample-efficient and explainable analog circuit sizing is presented. It employs
a multi-agent workflow where specialized Large Language Model (LLM)-based
agents collaborate to interpret the circuit topology, to understand the design
goals, and to iteratively refine the circuit's design parameters towards the
target goals with human-interpretable reasoning. The adaptive simulation
strategy creates an intelligent control that yields a high sample efficiency.
The AnaFlow framework is demonstrated for two circuits of varying complexity
and is able to complete the sizing task fully automatically, differently from
pure Bayesian optimization and reinforcement learning approaches. The system
learns from its optimization history to avoid past mistakes and to accelerate
convergence. The inherent explainability makes this a powerful tool for analog
design space exploration and a new paradigm in analog EDA, where AI agents
serve as transparent design assistants.

</details>


### [170] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 使用LLM对基因组学出版物中的数据集使用情况进行零样本分类，并提出了新的评估框架，结果显示F1分数为0.674，但存在数据可用性、提示过拟合、计算资源和评估成本等挑战。


<details>
  <summary>Details</summary>
Motivation: 为了扩展对科学文献中数据使用案例的描述，并克服手动标注和为传统机器学习系统开发训练数据集的成本。

Method: 应用开源LLM Llama 3.1-405B，为已知包含特定基因组学数据集的出版物生成结构化数据集使用案例标签，并引入新颖的评估框架。

Result: 在零样本数据引用分类任务上，模型达到了0.674的F1分数，并且没有预先定义的类别。

Conclusion: 虽然研究结果很有希望，但数据可用性、提示过拟合、计算基础设施以及进行负责任的性能评估的成本等障碍限制了其广泛应用。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [171] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 该研究提出了ROGUE-TS算法，一种用于处理具有未知且随时间演变的奖励的决策问题的汤普森采样方法，并通过概率裁剪程序来平衡个体化和群体层面学习，以解决微随机试验（MRTs）中的挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决决策者在选择未知且随时间演变的奖励（可能因重复使用而降低效果或因不活动而恢复）时的挑战，特别是在微随机试验（MRTs）中，以优化个体化推荐并估计群体层面效应。

Method: 提出ROGUE-TS算法，一种针对ROGUE框架的汤普森采样算法，并引入概率裁剪程序来平衡个体化学习和群体层面学习，量化权衡了遗憾界和最小探索概率。

Result: 所提出的ROGUE-TS算法在两个MRTs数据集（涉及体育活动推广和双相情感障碍治疗）上进行了验证，结果显示其遗憾界低于现有方法，并且通过裁剪程序在高统计功效下学习，而遗憾界并未显著增加。

Conclusion: 该研究提出的方法能够在个体行为动态下，可靠地检测治疗效果，并为设计MRTs的研究人员提供了在个体化与统计有效性之间取得平衡的实用指导。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [172] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: UserAlign是一种新颖的推理时个性化对齐方法，通过少量成对响应比较查询来引导用户偏好，并利用最佳手臂识别的理论框架快速识别最佳响应。


<details>
  <summary>Details</summary>
Motivation: 现有模型在个性化对齐方面要么需要大量用户偏好查询，要么需要明确的文本输入，而本文旨在提出一种更高效的方法。

Method: UserAlign基于逻辑强盗（logistic bandits）的最佳手臂识别（best-arm identification）理论框架，通过少量成对响应比较查询来引导用户偏好，并将用户反馈视为一致且无噪声的，以快速识别最佳响应。

Result: 在涉及个性化文本和图像生成的多个任务的实验结果表明，UserAlign在实现个性化对齐方面是有效的。

Conclusion: UserAlign通过少量查询有效地实现了个性化对齐，优于现有方法。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [173] [Value of Information-Enhanced Exploration in Bootstrapped DQN](https://arxiv.org/abs/2511.02969)
*Stergios Plataniotis,Charilaos Akasiadis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 通过将信息价值（EVOI）的概念整合到 Bootstrapped DQN 框架中，提出两种新算法以增强深度探索能力，并在 Atari 游戏实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习中，尤其是在高维状态和稀疏奖励环境下，探索效率低下的问题，以及传统探索策略（如 $\epsilon$-greedy 和 Boltzmann 探索）在平衡探索与利用方面的不足。

Method: 提出两种新算法，将信息价值（EVOI）的概念整合到 Bootstrapped DQN 框架中。利用信息价值估计来衡量不同网络头之间的意见差异，并引导探索至潜力最大的区域。

Result: 在复杂的、稀疏奖励的 Atari 游戏实验中，证明了所提出的算法相比现有方法能够提高性能，更好地利用随机网络初始化带来的不确定性，并且无需引入额外的超参数。

Conclusion: 整合信息价值（EVOI）到 Bootstrapped DQN 框架中是增强深度强化学习算法探索能力的一种有效途径，尤其是在稀疏奖励环境下。所提出的方法在 Atari 游戏中的实验结果表明，其性能有所提高，并且能够更好地利用不确定性信息。

Abstract: Efficient exploration in deep reinforcement learning remains a fundamental
challenge, especially in environments characterized by high-dimensional states
and sparse rewards. Traditional exploration strategies that rely on random
local policy noise, such as $\epsilon$-greedy and Boltzmann exploration
methods, often struggle to efficiently balance exploration and exploitation. In
this paper, we integrate the notion of (expected) value of information (EVOI)
within the well-known Bootstrapped DQN algorithmic framework, to enhance the
algorithm's deep exploration ability. Specifically, we develop two novel
algorithms that incorporate the expected gain from learning the value of
information into Bootstrapped DQN. Our methods use value of information
estimates to measure the discrepancies of opinions among distinct network
heads, and drive exploration towards areas with the most potential. We evaluate
our algorithms with respect to performance and their ability to exploit
inherent uncertainty arising from random network initialization. Our
experiments in complex, sparse-reward Atari games demonstrate increased
performance, all the while making better use of uncertainty, and, importantly,
without introducing extra hyperparameters.

</details>


### [174] [Heterogeneous Metamaterials Design via Multiscale Neural Implicit Representation](https://arxiv.org/abs/2511.03012)
*Hongrui Chen,Liwei Wang,Levent Burak Kara*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的神经网络框架，用于设计具有兼容单元格几何形状的异构超材料，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统超材料设计方法在处理复杂工程任务时面临巨大设计空间、单元格兼容性要求以及数据依赖性等挑战。本研究旨在通过一种新的神经网络方法克服这些困难。

Method: 提出了一种基于多尺度神经表示的框架，该框架利用神经网络同时学习宏观和微观坐标，输出一个隐式场来表示连续的、具有兼容单元格几何形状的多尺度结构。通过引入兼容性损失项来保证相邻单元格之间的连接性。

Result: 该框架能够生成任意高分辨率的超材料设计，实现无缝连接，并成功应用于力学超材料设计、负泊松比材料设计和隐身斗篷等问题。

Conclusion: 所提出的神经网络设计框架能够有效地处理异构超材料的设计，克服了传统方法的局限性，并在多个应用领域展现出巨大潜力。

Abstract: Metamaterials are engineered materials composed of specially designed unit
cells that exhibit extraordinary properties beyond those of natural materials.
Complex engineering tasks often require heterogeneous unit cells to accommodate
spatially varying property requirements. However, designing heterogeneous
metamaterials poses significant challenges due to the enormous design space and
strict compatibility requirements between neighboring cells. Traditional
concurrent multiscale design methods require solving an expensive optimization
problem for each unit cell and often suffer from discontinuities at cell
boundaries. On the other hand, data-driven approaches that assemble structures
from a fixed library of microstructures are limited by the dataset and require
additional post-processing to ensure seamless connections. In this work, we
propose a neural network-based metamaterial design framework that learns a
continuous two-scale representation of the structure, thereby jointly
addressing these challenges. Central to our framework is a multiscale neural
representation in which the neural network takes both global (macroscale) and
local (microscale) coordinates as inputs, outputting an implicit field that
represents multiscale structures with compatible unit cell geometries across
the domain, without the need for a predefined dataset. We use a compatibility
loss term during training to enforce connectivity between adjacent unit cells.
Once trained, the network can produce metamaterial designs at arbitrarily high
resolution, hence enabling infinite upsampling for fabrication or simulation.
We demonstrate the effectiveness of the proposed approach on mechanical
metamaterial design, negative Poisson's ratio, and mechanical cloaking problems
with potential applications in robotics, bioengineering, and aerospace.

</details>


### [175] [Discrete Bayesian Sample Inference for Graph Generation](https://arxiv.org/abs/2511.03015)
*Ole Petersen,Marcel Kollovieh,Marten Lienen,Stephan Günnemann*

Main category: cs.LG

TL;DR: GraphBSI是一种基于贝叶斯样本推断（BSI）的新型单次图生成模型，通过迭代地在参数的连续空间中优化图的信念，解决了图数据的离散和无序性质，并在分子和合成图生成方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 生成图结构数据在分子生成、知识图谱和网络分析等应用中至关重要，但其离散、无序的性质给传统生成模型带来挑战。

Method: 提出了一种名为GraphBSI的新型单次图生成模型，该模型基于贝叶斯样本推断（BSI）。GraphBSI不直接演化样本，而是在参数的连续空间中迭代地优化图的信念，从而自然地处理离散结构。此外，将BSI表述为随机微分方程（SDE），并推导出一族保持边缘分布的噪声控制SDE。

Result: GraphBSI在分子和合成图生成方面的经验评估显示，其性能优于现有的单次图生成模型，并在Moses和GuacaMol标准基准上取得了最先进的成果。

Conclusion: GraphBSI通过在参数空间中迭代优化图的信念来生成图结构数据，并在标准基准测试中取得了最先进的性能。该模型还揭示了BSI与贝叶斯流网络和扩散模型之间的理论联系。

Abstract: Generating graph-structured data is crucial in applications such as molecular
generation, knowledge graphs, and network analysis. However, their discrete,
unordered nature makes them difficult for traditional generative models,
leading to the rise of discrete diffusion and flow matching models. In this
work, we introduce GraphBSI, a novel one-shot graph generative model based on
Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI
iteratively refines a belief over graphs in the continuous space of
distribution parameters, naturally handling discrete structures. Further, we
state BSI as a stochastic differential equation (SDE) and derive a
noise-controlled family of SDEs that preserves the marginal distributions via
an approximation of the score function. Our theoretical analysis further
reveals the connection to Bayesian Flow Networks and Diffusion models. Finally,
in our empirical evaluation, we demonstrate state-of-the-art performance on
molecular and synthetic graph generation, outperforming existing one-shot graph
generative models on the standard benchmarks Moses and GuacaMol.

</details>


### [176] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“自适应无传感器”的监测方法，通过对机器学习模型进行残差校正，以提高对集装箱内部温度和湿度的预测精度，并证明了其在处理大规模数据集时的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的传感器监测方法成本高昂且存在局限性，而无传感器监测方法虽然有前景，但其预测结果与实际数据存在显著差异。因此，需要一种能够结合遥测数据并校正系统误差的监测方法。

Method: 提出了一种名为“残差校正”的通用框架，用于在观察到实时遥测数据后校正无传感器模型的系统偏差。将这类模型称为“自适应无传感器”监测模型。利用包含348万个数据点的最大规模集装箱传感器读数数据集进行训练和评估。

Result: 与基线无传感器模型相比，自适应无传感器模型在模拟数据的保持集上取得了持续改进。在温度方面，平均绝对误差（MAE）为2.24～2.31°C（无传感器模型为2.43°C），平均均方根误差（RMSE）为3.19～3.26°C（无传感器模型为3.38°C）。在相对湿度方面，平均绝对误差（MAE）为5.72～7.09%（无传感器模型为7.99%），平均均方根误差（RMSE）为7.70～9.12%（无传感器模型为10.0%）。

Conclusion: 自适应无传感器监测模型能够实现更准确的货物监测、早期风险检测，并减少对全球航运全面连接的依赖。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [177] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: AI驱动的科学和工程设计中，通常需要根据用户指定的属性来设计离散对象。现有的分布优化算法在处理离散设计空间时面临挑战，但许多属性预测模型具有可分解性。本文提出了一种名为DADO（Decomposition-Aware Distributional Optimization）的新算法，该算法能够利用设计变量的连接树结构来提高优化效率，通过软因子化“搜索分布”和图消息传递来协调跨因子优化。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的科学和工程领域，需要根据用户指定的属性设计离散对象。现有的分布优化算法在处理离散设计空间时存在困难，无法有效利用属性预测模型的可分解性。

Method: 提出了一种名为DADO（Decomposition-Aware Distributional Optimization）的新算法，该算法利用设计变量的连接树结构，通过软因子化“搜索分布”和图消息传递来协调跨因子优化，从而提高优化效率。

Result: DADO算法能够利用设计变量的可分解性结构，通过软因子化“搜索分布”和图消息传递，更有效地进行分布优化。

Conclusion: DADO算法是一种新的分布优化算法，能够利用设计变量的可分解性结构，提高在AI驱动的科学和工程设计中的优化效率。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [178] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: Vision Transformer (ViT) 模型在金融期权数据上预测未来波动率方面展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 金融机器学习领域，尤其是深度学习模型在处理非线性关系以提高金融预测准确性方面，已显示出其优越性。尽管Transformer模型（如Informer）在金融时间序列预测中表现出潜力，但其在期权数据上的应用仍处于初步探索阶段。

Method: 本研究旨在开发一个用于期权数据的Transformer模型。我们采用通常用于图像识别和分类的Vision Transformer (ViT) 架构，并训练该模型来预测资产未来30天的已实现波动率。模型的输入是当日的隐含波动率曲面，并加入了日期信息。

Result: 初步研究表明，ViT能够从隐含波动率曲面中学习到季节性模式和非线性特征，这为期权数据建模指明了一个有前景的方向。

Conclusion: Vision Transformer (ViT) 模型在处理期权数据以预测波动率方面具有潜力，能够捕捉数据中的复杂模式。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [179] [Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions](https://arxiv.org/abs/2511.03047)
*Emi Soroka,Tanmay Chopra,Krish Desai,Sanjay Lall*

Main category: cs.LG

TL;DR: LLM在企业应用中越来越受欢迎，但评估这些应用很困难。本文提出了第一套无监督指标，用于评估LLM在客观驱动的交互中的表现，无需人工标注或理想响应。


<details>
  <summary>Details</summary>
Motivation: LLM在企业应用中越来越受欢迎，但目前缺乏有效的评估方法，因为数据复杂、无标签，人工标注不切实际，定制指标无法发现未知错误，LLM评估结果不可靠。

Method: 提出了一套无监督指标，利用无标签交互数据的统计特性，并使用微调的LLM来适应分布变化。该方法包括标记用户目标、衡量目标完成情况以及量化LLM不确定性。

Result: 该方法在开放域和特定任务的交互数据上得到了验证。

Conclusion: 本文提出的无监督指标能够有效地评估LLM在客观驱动交互中的表现，解决了现有评估方法的局限性。

Abstract: Large language models (LLMs) have seen increasing popularity in enterprise
applications where AI agents and humans engage in objective-driven
interactions. However, these systems are difficult to evaluate: data may be
complex and unlabeled; human annotation is often impractical at scale; custom
metrics can monitor for specific errors, but not previously-undetected ones;
and LLM judges can produce unreliable results. We introduce the first set of
unsupervised metrics for objective-driven interactions, leveraging statistical
properties of unlabeled interaction data and using fine-tuned LLMs to adapt to
distributional shifts. We develop metrics for labeling user goals, measuring
goal completion, and quantifying LLM uncertainty without grounding evaluations
in human-generated ideal responses. Our approach is validated on open-domain
and task-specific interaction data.

</details>


### [180] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: Transformer 模型可以通过类比广义相对论来理解，其中注意力机制被解释为在曲率诱导的度量空间上进行平行传输。


<details>
  <summary>Details</summary>
Motivation: 提出一个几何框架来理解 Transformer 模型，并将注意力机制类比于广义相对论。

Method: 通过构建几何框架，将 Transformer 中的查询、键、值和注意力机制类比于广义相对论中的度量、联络和微分同胚。并通过实验可视化曲率、模拟角度分布和测量上下文编辑引起的嵌入轨迹偏转来验证该理论。

Result: Transformer 中的嵌入轨迹表现出弯曲，并且可以通过几何框架进行量化。实验结果支持了 Transformer 几何的类比。

Conclusion: Transformer 的运作方式可以通过一个几何框架来理解，该框架将注意力机制类比于广义相对论中的平行传输，并且可以通过嵌入轨迹的曲率来量化。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [181] [Homomorphism distortion: A metric to distinguish them all and in the latent space bind them](https://arxiv.org/abs/2511.03068)
*Martin Carrasco,Olga Zaghen,Erik Bekkers,Bastian Rieck*

Main category: cs.LG

TL;DR: 本文提出了一种新的图嵌入方法——图同态畸变，用于衡量顶点属性图的相似性，并能在期望中保证图的完全表征。


<details>
  <summary>Details</summary>
Motivation: 传统的图神经网络（GNN）表达能力评估主要基于组合属性，本文旨在打破这一传统，提供一种新的、基于顶点属性图相似性的衡量标准。

Method: 提出图同态畸变（graph homomorphism distortion）作为衡量图相似性的新度量，并提出通过采样来高效计算该度量，以期望保证度量的完备性。此外，还从该度量中导出了一种新的度量。

Result: 图同态畸变能够完全表征图，是一种完整的图嵌入。在BREC数据集上，能够区分多达4-WL（Weisfeiler-Lehman）都无法区分的图。在ZINC-12k数据集上，其表现优于以往基于同态的方法。

Conclusion: 图同态畸变提供了一种新的图嵌入方法，能够完全表征图，并在实际应用中表现出色，为图的表征和图论研究开辟了新的方向。

Abstract: For far too long, expressivity of graph neural networks has been measured
\emph{only} in terms of combinatorial properties. In this work we stray away
from this tradition and provide a principled way to measure similarity between
vertex attributed graphs. We denote this measure as the \emph{graph
homomorphism distortion}. We show it can \emph{completely characterize} graphs
and thus is also a \emph{complete graph embedding}. However, somewhere along
the road, we run into the graph canonization problem. To circumvent this
obstacle, we devise to efficiently compute this measure via sampling, which in
expectation ensures \emph{completeness}. Additionally, we also discovered that
we can obtain a metric from this measure. We validate our claims empirically
and find that the \emph{graph homomorphism distortion}: (1.) fully
distinguishes the \texttt{BREC} dataset with up to $4$-WL non-distinguishable
graphs, and (2.) \emph{outperforms} previous methods inspired in homomorphisms
under the \texttt{ZINC-12k} dataset.
  These theoretical results, (and their empirical validation), pave the way for
future characterization of graphs, extending the graph theoretic tradition to
new frontiers.

</details>


### [182] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: MSUCB是一种用于在线学习排序（OLTR）的鲁棒算法，通过一种新的均值-中值估计器来解决点击欺诈问题，在无欺诈时与标准方法一样高效，在有欺诈时也能保持良好性能，并在真实数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的在线学习排序（OLTR）算法（通常建模为层叠赌博机）在面对点击欺诈和操纵（即腐败）时，容易受到误导，导致学习过程偏差和用户体验下降。

Method: 提出了一种名为MSUCB的新型鲁棒算法，其中包含一种新颖的均值-中值估计器。该估计器在无腐败时表现得像标准的均值估计器，而在存在腐败时，中值步骤可以滤除异常值和腐败样本，使估计值保持接近真实值。此外，每轮都更新该估计器，可以加速经验收敛。

Result: MSUCB在无腐败时实现了最优的对数遗憾，在有腐败时，遗憾仅增加一个与总腐败量相关的附加项。在真实数据集上的实验表明，MSUCB的性能持续优于现有方法，并保持了强大的鲁棒性，在遗憾方面比两种最先进的方法分别提高了97.35%和91.60%。

Conclusion: MSUCB通过其新颖的均值-中值估计器，在在线学习排序的背景下，有效地解决了腐败问题，实现了鲁棒性和效率的平衡，并在真实世界的应用中取得了优越的性能。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [183] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: AI在提取数据表示方面取得了革命性进展，但这些表示的统计特性控制不佳，导致异常检测方法失效。本文提出了一种基于自组织局部核的SparKer方法，通过稀疏性、局部性和竞争性原则来解决此问题，并在多个高维数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI生成的数据表示虽然丰富但统计特性难以控制，导致异常检测方法在面对弱信号或稀疏信号时表现不佳，存在检测和解释异常的鸿沟。

Method: 提出了一种名为SparKer的新方法，该方法实例化了一类自组织的局部核，该核在半监督的Neyman--Pearson框架内，通过稀疏的高斯核集成来局部模拟包含异常的样本与无异常的参考样本之间的似然比。

Result: SparKer在包括科学发现、开放世界新颖性检测、入侵检测和生成模型验证等在内的多个高维应用中展现了有效性。即使只包含少量核的集成也能在数千维度的表示空间中识别出统计上显著的异常位置，证明了该方法的解释性、效率和可扩展性。

Conclusion: SparKer通过引入稀疏性、局部性和竞争性原则，提供了一种能够自适应地在统计不平衡区域划分表示空间的检测方法，有效解决了现有异常检测方法的局限性，并在多个领域取得了良好效果。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [184] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 深度学习的兴起导致碳排放增加，本文提出CTF-IDF和IRLBA算法以提高文本分析的效率和速度，同时略微降低准确性，但碳排放更少。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在文本分析领域日益盛行，但其高昂的计算资源和电力消耗导致碳足迹严重增加。

Method: 对TF-IDF算法进行了修改，提出了CTF-IDF用于数据预处理，并结合更快的IRLBA算法进行降维，以应用于文本分析。

Result: 与深度学习方法相比，CTF-IDF和IRLBA在时间复杂度和计算强度方面有显著降低，同时模型准确性有所提高，碳排放更少。

Conclusion: CTF-IDF和IRLBA的结合为文本分析提供了一种更高效、更快速、计算量更小且碳足迹更低的替代方案，虽然准确性略有牺牲，但在实际应用中具有优势。

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [185] [Towards Scalable Backpropagation-Free Gradient Estimation](https://arxiv.org/abs/2511.03110)
*Daniel Wang,Evan Markou,Dylan Campbell*

Main category: cs.LG

TL;DR: 反向传播需要两次计算并且存储中间激活，而前向模式自动微分的梯度估计方法在大网络上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的梯度估计方法，以解决反向传播的计算效率和前向模式在大网络上的扩展性问题。

Method: 通过操纵上游雅可比矩阵来计算猜测方向，以减少梯度估计的偏差和方差。

Result: 该方法在更宽的网络上表现更好，显示出扩展到更大网络的潜力。

Conclusion: 该方法通过减少偏差和方差，为梯度估计提供了一种有前景的替代方案，并揭示了其与神经网络梯度低维结构的联系。

Abstract: While backpropagation--reverse-mode automatic differentiation--has been
extraordinarily successful in deep learning, it requires two passes (forward
and backward) through the neural network and the storage of intermediate
activations. Existing gradient estimation methods that instead use forward-mode
automatic differentiation struggle to scale beyond small networks due to the
high variance of the estimates. Efforts to mitigate this have so far introduced
significant bias to the estimates, reducing their utility. We introduce a
gradient estimation approach that reduces both bias and variance by
manipulating upstream Jacobian matrices when computing guess directions. It
shows promising results and has the potential to scale to larger networks,
indeed performing better as the network width is increased. Our understanding
of this method is facilitated by analyses of bias and variance, and their
connection to the low-dimensional structure of neural network gradients.

</details>


### [186] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff是第一个强制执行 Fokker-Planck 方程 (FPE) 物理学的抗体生成器，解决了现有模型的动力学不一致和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在抗体设计中存在动力学不一致（产生不切实际的结构）和泛化能力差（数据稀疏和结构偏差）这两个核心挑战。

Method: FP-AbDiff 是一种新的抗体生成器，它在 CDR 几何的混合流形（R^3 x SO(3)）上最小化了一个新颖的 FPE 残差损失，并将物理信息正则化与深度生物学先验知识相结合，用于最先进的 SE(3) 等变扩散框架。

Result: FP-AbDiff 在 RAbD 基准测试中取得了最先进的成果。在从头设计的 CDR-H3 中，其均方根偏差 (RMSD) 提高了 25%，接触氨基酸回收率达到 39.91%。在更具挑战性的六个 CDR 联合设计任务中，其全链 RMSD 降低了约 15%，CDR-H3 环的氨基酸回收率达到了 45.67%。

Conclusion: 通过将生成动力学与物理定律对齐，FP-AbDiff 提高了抗体设计的鲁棒性和泛化能力，为生成物理上真实且功能上可行的抗体提供了一种原则性的方法。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [187] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 该研究提出了一种名为PSD（Periodic Skill Discovery）的无监督方法，用于在强化学习中发现具有周期性的多样化技能，特别适用于机器人运动等任务。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法忽略了技能的周期性，而许多机器人任务（如运动）需要不同时间尺度的周期性行为。因此，发现多样化的周期性技能至关重要。

Method: PSD框架将状态映射到一个圆形潜在空间，从而在潜在表示中自然地编码周期性。该方法通过捕捉时间距离来学习具有不同周期的技能，即使在仅有像素观察的情况下也能处理复杂的机器人任务。

Result: PSD成功学习到了复杂的周期性技能，并在后续的跨栏等任务中取得了高性能。将PSD与现有技能发现方法结合，可以产生更多样化的行为，扩大智能体的技能库。

Conclusion: PSD是一种有效的无监督周期性技能发现框架，能够学习到多样化且具有高性能的周期性行为，并能与现有方法结合以丰富智能体的行为能力。

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [188] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 对比学习的理论分析，揭示了其工作机制，并提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前对比学习的底层机制尚不明确，需要理论解释和评估方法。

Method: 1.推导了在条件独立假设下对比学习的紧密界限。 2.放宽条件独立性假设，提出数据增强重叠假设，并推导出下游性能的渐近闭界。 3.基于数据增强重叠理论，开发了无监督的表示评估指标。

Result: 1.在条件独立假设下得到了对比学习的紧密界限。 2.得到了下游性能的渐近闭界。 3.提出的无监督评估指标与下游性能高度相关。

Conclusion: 通过理论分析，解释了对比学习如何通过对齐正样本来聚集类内样本，并提出了有效的无监督表示评估方法。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [189] [Tensor-Efficient High-Dimensional Q-learning](https://arxiv.org/abs/2511.03595)
*Junyi Wu,Dan Li*

Main category: cs.LG

TL;DR: TEQL是一种提高低秩张量分解效率的Q学习算法，通过改进的块坐标下降、探索和正则化机制，在样本效率和总回报方面优于传统方法和深度强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 高维强化学习在计算和样本效率方面面临挑战，特别是Q学习算法难以处理维度灾难；现有的基于张量的方法虽然参数效率更高，但仍有提升空间。

Method: TEQL通过改进块坐标下降来增强低秩张量分解，并在离散化状态-动作空间中加入新的探索和正则化机制。其创新之处在于结合了近似误差和基于访问次数的上置信界来指导探索，并通过频率惩罚项鼓励探索不常访问的状态-动作对。

Result: 在经典控制任务上的实证结果表明，TEQL在样本效率和总回报方面均优于基于矩阵的方法和深度强化学习方法。

Conclusion: TEQL在资源受限的应用（如太空和医疗保健）中表现出比传统和深度强化学习方法更高的样本效率和总回报，是一种有前途的强化学习算法。

Abstract: High-dimensional reinforcement learning faces challenges with complex
calculations and low sample efficiency in large state-action spaces. Q-learning
algorithms struggle particularly with the curse of dimensionality, where the
number of state-action pairs grows exponentially with problem size. While
neural network-based approaches like Deep Q-Networks have shown success, recent
tensor-based methods using low-rank decomposition offer more
parameter-efficient alternatives. Building upon existing tensor-based methods,
we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor
decomposition via improved block coordinate descent on discretized state-action
spaces, incorporating novel exploration and regularization mechanisms. The key
innovation is an exploration strategy that combines approximation error with
visit count-based upper confidence bound to prioritize actions with high
uncertainty, avoiding wasteful random exploration. Additionally, we incorporate
a frequency-based penalty term in the objective function to encourage
exploration of less-visited state-action pairs and reduce overfitting to
frequently visited regions. Empirical results on classic control tasks
demonstrate that TEQL outperforms conventional matrix-based methods and deep RL
approaches in both sample efficiency and total rewards, making it suitable for
resource-constrained applications, such as space and healthcare where sampling
costs are high.

</details>


### [190] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: LLM在零样本任务上表现出色，但需要评估其对抗输入的鲁棒性。本研究提出了StaDec和DyDec两种攻击框架，能够生成动态、自适应的对抗性样本，欺骗目标LLM，同时保持语义相似性。该方法利用自动化、LLM驱动的流程，摆脱了对外部启发式的依赖，并且能够适应LLM的进步，在未知模型上表现出良好的可转移性。此研究为LLM的自评估提供了一个系统性的方法。


<details>
  <summary>Details</summary>
Motivation: 在将LLM应用于敏感任务时，评估其对抗输入的鲁棒性至关重要。

Method: 提出StaDec和DyDec两种攻击框架，通过理解LLM来生成动态和自适应的对抗性样本，并利用自动化、LLM驱动的流程来生成对抗性输入，同时保持语义相似性。

Result: 研究提出了一种系统性的方法，用于LLM的自我鲁棒性评估，并展示了攻击的有效性和可转移性。

Conclusion: 本研究为LLM的自我鲁棒性评估提供了一个系统性的方法，并开发了能够生成动态和自适应对抗性样本的框架。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [191] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: AQR是一种无需重新训练模型即可在测试时进行域自适应的技术，它通过对通道进行分位数对齐来调整预激活分布，解决了现有方法的局限性，并在各种数据集和模型上取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的域自适应方法依赖于目标域的先验知识或需要重新训练模型，这在动态或资源受限的环境中并不实用。现有的基于批量归一化统计更新的测试时自适应方法无法捕捉复杂的激活分布，并且仅限于特定的归一化层。

Method: AQR通过在通道层面进行分位数对齐来调整预激活分布，以捕捉激活分布的完整形状。它还包含一个鲁棒的尾部校准策略来解决不同批次大小下分布尾部估计的挑战。该方法利用训练时计算的源域统计数据，实现无需重新训练的无监督自适应。

Result: 在CIFAR-10-C、CIFAR-100-C和ImageNet-C数据集上，AQR在多种模型架构上进行了实验，证明了其在不同设置下具有鲁棒的自适应能力，并且优于现有的测试时自适应基线方法。

Conclusion: AQR是一种有效的测试时自适应技术，能够应对动态和不可预测的数据分布，具有在实际场景中部署的潜力。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [192] [Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction](https://arxiv.org/abs/2511.03149)
*Atif Hassan,Tarun Kumar,Ashish Mishra,Sergey Serebryakov,Satish Kumar Mopur,Phanidhar Koganti,Murthy Chelankuri,Ramanagopal Vogety,Suparna Bhattacharya,Martin Foltin*

Main category: cs.LG

TL;DR: Forecast2Anomaly (F2A) 是一个新框架，通过联合预测-异常损失和检索增强生成模块，使预训练的时间序列基础模型 (TSFM) 具备异常预测能力，解决了现有方法泛化性差的问题，并在 16 个数据集上取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常预测方法局限于特定系统且无法泛化到不断变化的异常模式，而预训练的时间序列基础模型（TSFM）在预测方面表现出强大的泛化能力，但其在异常预测方面的潜力尚未被挖掘。

Method: F2A 框架包含两个关键创新：1. 联合预测-异常损失，用于微调 TSFM 以准确预测异常点处的未来信号。 2. 检索增强生成（RAG）模块，用于检索历史相关的时间段，并基于这些时间段进行预测，从而动态适应推理时的分布变化，无需模型更新。

Result: F2A 在 16 个多样化的数据集和多个 TSFM 主干上进行了广泛的实验，结果显示 F2A 持续优于最先进的方法。

Conclusion: F2A 为实际应用提供了一个可扩展、零样本的异常预测解决方案，弥合了 TSFM 强大的零样本预测能力与零样本异常预测能力之间的差距。

Abstract: Forecasting anomalies (anomaly prediction) in multivariate time series from
different real-world, dynamic, and complex systems is vital for preempting
critical failures, leading to a substantial minimization in operational costs
and human labor. Yet, existing methods are limited to specific systems while
failing to generalize to evolving anomaly patterns over time. In contrast,
pretrained Time Series Foundation Models (TSFMs) have recently demonstrated
strong generalization and zero-shot forecasting capabilities. However, their
potential remains untapped for anomaly prediction, a task fundamentally
different from forecasting normal behavior. Thus, we present Forecast2Anomaly
(F2A), a novel framework that empowers TSFMs with anomaly prediction abilities
through two key innovations. First, we propose a joint forecast-anomaly loss
that fine-tunes TSFMs to accurately forecast future signals even at anomalous
time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module
that retrieves historically relevant horizons and conditions predictions on
them. This component dynamically adapts to distributional shifts at inference
time, enabling F2A to track evolving anomalies without requiring model updates.
By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap
between robust TSFM zero-shot forecasting and zero-shot anomaly prediction.
Extensive experiments across 16 diverse datasets and multiple TSFM backbones
show that F2A consistently outperforms state-of-the-art methods, offering a
scalable, zero-shot anomaly prediction solution for real-world applications.

</details>


### [193] [UnCLe: Towards Scalable Dynamic Causal Discovery in Non-linear Temporal Systems](https://arxiv.org/abs/2511.03168)
*Tingzhu Bi,Yicheng Pan,Xinrui Jiang,Huize Sun,Meng Ma,Ping Wang*

Main category: cs.LG

TL;DR: UnCLe是一种新颖的深度学习方法，用于可扩展的动态因果发现，能够准确捕捉和表征动态系统（如人类运动）中不断演变的暂时因果关系。


<details>
  <summary>Details</summary>
Motivation: 从观测时间序列中揭示因果关系对于理解复杂系统至关重要，但现有的静态因果图推断方法难以捕捉现实世界中经常存在的动态因果关系，因此需要能够准确捕捉这些时间动态的、时间解析的因果图。

Method: UnCLe采用一对解耦器和复用器网络，将输入时间序列分解为语义表征，并通过自回归依赖矩阵学习变量间的依赖关系。它通过分析由时间扰动引起的、逐点预测误差来估计动态因果影响。

Result: 实验结果表明，UnCLe不仅在静态因果发现基准测试中优于最先进的方法，而且更重要的是，它在准确捕捉和表征合成和真实世界动态系统（例如，人类运动）中不断演变的暂时因果关系方面表现出独特的能力。

Conclusion: UnCLe为揭示复杂现象的潜在、时变机制提供了一种有前景的方法。

Abstract: Uncovering cause-effect relationships from observational time series is
fundamental to understanding complex systems. While many methods infer static
causal graphs, real-world systems often exhibit dynamic causality-where
relationships evolve over time. Accurately capturing these temporal dynamics
requires time-resolved causal graphs. We propose UnCLe, a novel deep learning
method for scalable dynamic causal discovery. UnCLe employs a pair of Uncoupler
and Recoupler networks to disentangle input time series into semantic
representations and learns inter-variable dependencies via auto-regressive
Dependency Matrices. It estimates dynamic causal influences by analyzing
datapoint-wise prediction errors induced by temporal perturbations. Extensive
experiments demonstrate that UnCLe not only outperforms state-of-the-art
baselines on static causal discovery benchmarks but, more importantly, exhibits
a unique capability to accurately capture and represent evolving temporal
causality in both synthetic and real-world dynamic systems (e.g., human
motion). UnCLe offers a promising approach for revealing the underlying,
time-varying mechanisms of complex phenomena.

</details>


### [194] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 提出了一种新颖的线性注意力机制，通过计算熵来克服传统注意力机制的二次计算复杂性，实现了对长序列的高效处理，并在时空时间序列预测任务上取得了有竞争力的性能，同时显著降低了内存和计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制在处理长序列时存在二次计算复杂性问题，限制了其在时间序列建模等应用中的扩展性。

Method: 提出了一种基于熵的线性注意力机制。该机制利用熵作为概率单形上的严格凹函数，证明了概率排名对齐和熵值相似的分布具有结构相似性。在此基础上，开发了一种线性复杂度的近似算法来计算点积导出分布的熵，从而实现了基于熵等价的线性注意力机制。

Result: 所提出的线性注意力机制在四个时空时间序列数据集上的实验结果表明，其预测性能具有竞争力甚至更优，同时在内存使用和计算时间方面均有显著降低。

Conclusion: 注意力机制在时空时间序列建模中的有效性可能主要源于适度和均衡的权重分布，而非softmax的非线性。所提出的线性注意力机制能够有效实现这一点，并在效率和性能上优于现有方法。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [195] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种新颖的、由 copula 驱动的多模态学习框架，通过对多模态数据的联合分布进行建模来捕获它们之间复杂的相互作用。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于连接或 Kronecker 积，未能充分捕捉多模态之间交互的复杂结构，并且对具有高阶交互的潜在表示的联合分布的探索不足。

Method: 将 copula 模型解释为一种有效对齐多模态边际分布的工具，假设每个模态具有高斯混合分布，联合分布具有 copula 模型。

Result: 在公开的 MIMIC 数据集上进行了广泛的实验，证明了该模型在生成缺失模态的准确表示方面优于其他竞争对手。

Conclusion: 所提出的 copula 驱动的多模态学习框架能够有效地对齐和融合来自不同模态的信息，从而在处理缺失模态方面取得优越的性能。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [196] [A Probabilistic U-Net Approach to Downscaling Climate Simulations](https://arxiv.org/abs/2511.03197)
*Maryam Alipourhajiagha,Pierre-Louis Lemaire,Youssef Diouane,Julie Carreau*

Main category: cs.LG

TL;DR: 利用改进的U-Net模型进行统计降尺度，以提高气候模型分辨率，并评估了不同的训练目标。


<details>
  <summary>Details</summary>
Motivation: 气候模型计算成本高，空间分辨率粗糙，而气候变化影响研究需要更高分辨率的数据。统计降尺度是弥合这一差距的方法。

Method: 将概率U-Net应用于统计降尺度，结合了确定性U-Net主干和变分潜在空间来捕捉不确定性。评估了afCRPS和WMSE-MS-SSIM这四种训练目标，用于降尺度降水和温度。

Result: WMSE-MS-SSIM在某些设置下对极端天气表现良好，而afCRPS在捕捉跨尺度的空间变异性方面表现更好。

Conclusion: 所提出的方法能够有效地进行统计降尺度，并且不同的训练目标适用于不同的评估指标。

Abstract: Climate models are limited by heavy computational costs, often producing
outputs at coarse spatial resolutions, while many climate change impact studies
require finer scales. Statistical downscaling bridges this gap, and we adapt
the probabilistic U-Net for this task, combining a deterministic U-Net backbone
with a variational latent space to capture aleatoric uncertainty. We evaluate
four training objectives, afCRPS and WMSE-MS-SSIM with three settings for
downscaling precipitation and temperature from $16\times$ coarser resolution.
Our main finding is that WMSE-MS-SSIM performs well for extremes under certain
settings, whereas afCRPS better captures spatial variability across scales.

</details>


### [197] [A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies](https://arxiv.org/abs/2511.03201)
*Hassan Wasswa,Hussein Abbass,Timothy Lynar*

Main category: cs.LG

TL;DR: 为了解决物联网（IoT）机器人网络攻击问题，研究人员提出了基于深度学习的检测模型。然而，这些模型计算量大，难以在资源受限的IoT设备上部署。本研究提出了一种VAE-MLP模型框架，并评估了两种量化策略（QAT和PTQ）在检测性能、存储效率和推理延迟方面的影响。结果表明，PTQ在保持较高检测精度的同时，显著提高了速度和压缩率，使其在设备级IoT机器人网络检测方面具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法计算量大，难以在资源受限的IoT设备上部署，需要轻量级的检测模型。

Method: 提出VAE-MLP模型框架，利用预训练VAE的编码器提取8维潜在向量，然后训练MLP分类器。系统评估了量化感知训练（QAT）和训练后量化（PTQ）策略对检测性能、存储效率和推理延迟的影响，并使用了N-BaIoT和CICIoT2022两个数据集。

Result: PTQ策略在检测精度方面仅有边际下降，而QAT策略下降明显。PTQ实现了6倍加速和21倍的尺寸缩减，QAT实现了3倍加速和24倍的压缩。

Conclusion: 量化策略，特别是PTQ，在设备级IoT机器人网络检测方面是实用且有效的，能够在保证检测精度的同时，显著提高效率和压缩率。

Abstract: In an effort to counter the increasing IoT botnet-based attacks,
state-of-the-art deep learning methods have been proposed and have achieved
impressive detection accuracy. However, their computational intensity restricts
deployment on resource-constrained IoT devices, creating a critical need for
lightweight detection models. A common solution to this challenge is model
compression via quantization. This study proposes a VAE-MLP model framework
where an MLP-based classifier is trained on 8-dimensional latent vectors
derived from the high-dimensional train data using the encoder component of a
pretrained variational autoencoder (VAE). Two widely used quantization
strategies--Quantization-Aware Training (QAT) and Post-Training Quantization
(PTQ)--are then systematically evaluated in terms of their impact on detection
performance, storage efficiency, and inference latency using two benchmark IoT
botnet datasets--N-BaIoT and CICIoT2022. The results revealed that, with
respect to detection accuracy, the QAT strategy experienced a more noticeable
decline,whereas PTQ incurred only a marginal reduction compared to the original
unquantized model. Furthermore, PTQ yielded a 6x speedup and 21x reduction in
size, while QAT achieved a 3x speedup and 24x compression, demonstrating the
practicality of quantization for device-level IoT botnet detection.

</details>


### [198] [Incorporating Quality of Life in Climate Adaptation Planning via Reinforcement Learning](https://arxiv.org/abs/2511.03238)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 使用强化学习（RL）来识别能长期提高生活质量（QoL）的气候适应路径。


<details>
  <summary>Details</summary>
Motivation: 城市洪水预计将因气候变化而增加，影响城市生活质量（QoL）。政策制定者需要制定适应策略来应对气候变化和城市洪水的复杂性。

Method: 使用集成评估模型（IAM），该模型结合了降雨模型、洪水模型、交通可达性模型和生活质量指数，并利用强化学习（RL）来寻找提高QoL的适应策略。

Result: 初步结果表明，该方法可以学习最优适应措施，并且优于其他现实和实际的规划策略。

Conclusion: 强化学习（RL）有望用于解决复杂的、动态的、不确定的城市洪水适应问题，以提高长期生活质量（QoL）。

Abstract: Urban flooding is expected to increase in frequency and severity as a
consequence of climate change, causing wide-ranging impacts that include a
decrease in urban Quality of Life (QoL). Meanwhile, policymakers must devise
adaptation strategies that can cope with the uncertain nature of climate change
and the complex and dynamic nature of urban flooding. Reinforcement Learning
(RL) holds significant promise in tackling such complex, dynamic, and uncertain
problems. Because of this, we use RL to identify which climate adaptation
pathways lead to a higher QoL in the long term. We do this using an Integrated
Assessment Model (IAM) which combines a rainfall projection model, a flood
model, a transport accessibility model, and a quality of life index. Our
preliminary results suggest that this approach can be used to learn optimal
adaptation measures and it outperforms other realistic and real-world planning
strategies. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [199] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: FCDC通过将数据收集视为闭环控制问题，利用在线概率模型和基于似然/马氏距离的反馈信号来动态调节样本保留，从而实现更高效、更多样化的数据集，减少冗余和存储。在真实数据流上的实验表明，FCDC可提高25.9%的数据集平衡性，同时减少39.8%的数据存储。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统受数据质量和多样性限制，而当前数据收集方式（开放式）存在冗余、存储成本高、标注成本高和泛化能力有限等问题。

Method: 提出FCDC（闭环数据收集）范式，将数据收集建模为闭环控制问题。使用在线概率模型近似收集数据的状态，并基于似然和马氏距离等反馈信号自适应地调节样本保留，以平衡探索与利用，保持数据多样性并防止冗余。

Result: 在合成数据集上展示了FCDC的可控性。在真实数据流上的实验表明，FCDC可使数据集更加均衡（提高25.9%），同时减少数据存储（降低39.8%）。

Conclusion: 数据收集过程本身可以被主动控制，使之从一个被动的流水线阶段转变为数据中心AI核心的、自我调节的、反馈驱动的过程。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [200] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: IGNO是一个新的生成神经算子框架，用于解决由偏微分方程控制的逆问题，无需标注数据，即可处理稀疏、噪声大的测量数据，并能恢复高维或不连续的系数场。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理稀疏、噪声大的测量数据或高维、不连续的系数场时存在局限性，难以满足实际应用需求。

Method: IGNO框架将高维系数场编码到低维潜在空间，利用神经算子解码器重构系数场和PDE解。训练仅依赖物理约束，通过PDE残差进行。逆问题求解通过在潜在空间中进行基于梯度的优化实现，并利用先验归一化流模型加速。

Result: IGNO在处理包括不连续系数恢复和电成像问题在内的多种挑战性逆问题时，即使在严重噪声下也能实现准确、稳定且可扩展的逆转。其性能优于最先进的方法，并表现出良好的泛化能力。

Conclusion: IGNO是一个统一且强大的框架，能够解决计算科学领域的各种挑战性逆问题，克服了现有方法的局限性。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [201] [Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways](https://arxiv.org/abs/2511.03243)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 气候变化将增加洪水频率和强度，需要制定适应政策。本研究提出使用强化学习（RL）来处理不确定性并比较不同适应优先级（如经济与福祉）的影响。通过集成评估模型（IAM）模拟降雨、洪水以及对生活质量（QoL）、交通和基础设施的影响。结果显示，优先考虑QoL的政策会导致更多的适应支出，并更均匀地分布于研究区域，表明规范性假设对适应政策有显著影响。


<details>
  <summary>Details</summary>
Motivation: 设计有效的气候变化适应政策需要管理长期气候影响的不确定性，并明确政策中可能存在的规范性选择。

Method: 使用强化学习（RL）和一个集成评估模型（IAM），该模型整合了降雨和洪水模型，以计算洪水对生活质量（QoL）、交通和基础设施损害的影响。

Result: 优先考虑QoL的适应政策模型比优先考虑经济影响的模型产生了更多的适应支出，并且这些支出在研究区域内的分布更加均匀。

Conclusion: 规范性假设（例如，优先考虑QoL而非经济影响）可以显著改变适应政策的制定和支出模式。

Abstract: Climate change will cause an increase in the frequency and severity of flood
events, prompting the need for cohesive adaptation policymaking. Designing
effective adaptation policies, however, depends on managing the uncertainty of
long-term climate impacts. Meanwhile, such policies can feature important
normative choices that are not always made explicit. We propose that
Reinforcement Learning (RL) can be a useful tool to both identify adaptation
pathways under uncertain conditions while it also allows for the explicit
modelling (and consequent comparison) of different adaptation priorities (e.g.
economic vs. wellbeing). We use an Integrated Assessment Model (IAM) to link
together a rainfall and flood model, and compute the impacts of flooding in
terms of quality of life (QoL), transportation, and infrastructure damage. Our
results show that models prioritising QoL over economic impacts results in more
adaptation spending as well as a more even distribution of spending over the
study area, highlighting the extent to which such normative assumptions can
alter adaptation policy. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [202] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: EM 限制了其在机器学习中的潜力。为了解决这个问题，我们提出了 AdaDEM，它通过将 EM 分解为 CADF 和 GMC 来解决这个问题，并用 MEC 替换 GMC。


<details>
  <summary>Details</summary>
Motivation: 尽管熵最小化 (EM) 在减少类别重叠、缩小域间隙和限制机器学习任务中的不确定性方面很有益，但其潜力受到限制。

Method: 我们将经典的 EM 重构并解耦为两个具有相反作用的部分：聚类聚合驱动因素 (CADF) 和梯度缓解校准器 (GMC)。我们还提出了一种自适应解耦熵最小化 (AdaDEM)，它通过使用边缘熵校准器 (MEC) 来规范 CADF 的奖励并替换 GMC 来改进此方法。

Result: AdaDEM 的性能优于 DEM*，并在各种不完美的监督学习任务中取得了优异的性能，特别是在嘈杂和动态的环境中。

Conclusion: AdaDEM 通过解耦 EM 的组成部分并采用 MEC 来改进 GMC，从而克服了经典 EM 的限制，即奖励崩溃和易类偏差。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [203] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 在有限的独特数据下，扩散语言模型（DLM）通过增加训练周期可以超越自回归（AR）模型。


<details>
  <summary>Details</summary>
Motivation: 在有限的数据下，DLM如何以及为何能超越AR模型？

Method: 比较了DLM和AR模型在不同数据量、模型大小和架构下的表现，并分析了导致DLM优势的三个因素：任意顺序建模、迭代双向去噪的超密集计算以及内置的蒙特卡洛增强。

Result: 在数据受限的情况下，DLM随着训练周期的增加优于AR模型。更大的模型和更高质量的数据会使这种跨越提前出现。DLM在HellaSwag和MMLU等基准测试中取得了有竞争力的结果，并且在训练过程中验证交叉熵的增加并不一定意味着下游性能的下降。

Conclusion: DLM在严格控制的预训练设置下，尤其是在数据量有限时，能够通过增加训练周期来超越AR模型，这得益于其任意顺序建模、迭代双向去噪和内置蒙特卡洛增强等特性。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [204] [Multi-Objective Adaptive Rate Limiting in Microservices Using Deep Reinforcement Learning](https://arxiv.org/abs/2511.03279)
*Ning Lyu,Yuxi Wang,Ziyu Cheng,Qingyuan Zhang,Feng Chen*

Main category: cs.LG

TL;DR: 提出了一种基于深度强化学习的自适应API速率限制策略，通过结合DQN和A3C算法，有效提高了系统吞吐量并降低了服务延迟。


<details>
  <summary>Details</summary>
Motivation: 传统速率限制算法难以适应动态交通模式和不断变化的系统负载，需要一种更智能的自适应策略。

Method: 设计了一个结合深度Q网络（DQN）和异步优势Actor-Critic（A3C）算法的混合架构，将速率限制决策过程建模为马尔可夫决策过程，通过与环境交互持续学习最优策略。

Result: 在Kubernetes集群环境中，与传统固定阈值策略相比，吞吐量提高了23.7%，P99延迟降低了31.4%。在为期90天的生产环境中，处理了5亿每日请求，服务降级事件减少了82%，手动干预减少了68%。

Conclusion: 所提出的基于深度强化学习的自适应速率限制方法在实际应用中是有效的，能够显著提高系统稳定性和性能。

Abstract: As cloud computing and microservice architectures become increasingly
prevalent, API rate limiting has emerged as a critical mechanism for ensuring
system stability and service quality. Traditional rate limiting algorithms,
such as token bucket and sliding window, while widely adopted, struggle to
adapt to dynamic traffic patterns and varying system loads. This paper proposes
an adaptive rate limiting strategy based on deep reinforcement learning that
dynamically balances system throughput and service latency. We design a hybrid
architecture combining Deep Q-Network (DQN) and Asynchronous Advantage
Actor-Critic (A3C) algorithms, modeling the rate limiting decision process as a
Markov Decision Process. The system continuously monitors microservice states
and learns optimal rate limiting policies through environmental interaction.
Extensive experiments conducted in a Kubernetes cluster environment demonstrate
that our approach achieves 23.7% throughput improvement and 31.4% P99 latency
reduction compared to traditional fixed-threshold strategies under high-load
scenarios. Results from a 90-day production deployment handling 500 million
daily requests validate the practical effectiveness of the proposed method,
with 82% reduction in service degradation incidents and 68% decrease in manual
interventions.

</details>


### [205] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 本研究提出了一种新的多参考图像配准 (MRA) 算法，通过对相对位姿进行积分来消除全局对称性，从而实现更直接的解决方案和更快的收敛速度。该算法通过避免集中式方法的立方级计算复杂性，实现了显著的计算节省，并在实验中实现了更低的重建误差。


<details>
  <summary>Details</summary>
Motivation: 多参考图像配准 (MRA) 在从分子成像到无线通信等领域至关重要，需要从多个错位的观测中对齐和重建信号。

Method: 提出了一种基于概率论的 MRA 模型，并开发了一种利用相对位姿作为噪声变量进行积分的新算法，以消除全局对称性并实现更直接的解决方案和改进的收敛性。该算法采用去中心化的方法，通过循环一致性避免了集中式方法的立方级计算复杂性。

Result: 所提出的两种算法在各种实验设置中均实现了比现有方法更低的重建误差。

Conclusion: 本研究提出的去中心化 MRA 算法通过消除全局对称性和利用循环一致性，在计算效率和重建准确性方面均优于传统方法。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [206] [Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly Detection in Microservices](https://arxiv.org/abs/2511.03285)
*Qingyuan Zhang,Ning Lyu,Le Liu,Yuxi Wang,Ziyu Cheng,Cancan Hua*

Main category: cs.LG

TL;DR: 本研究提出了一种结合图神经网络和时序建模的统一框架，用于微服务架构中的异常检测和根因追踪。


<details>
  <summary>Details</summary>
Motivation: 微服务架构中的异常检测和根因追踪问题。

Method: 将微服务调用链抽象为有向图，利用节点和边的多维特征构建服务拓扑表示，并应用图卷积聚合特征和建模依赖关系。在此基础上，引入门控循环单元（GRU）对调用链的时序演化进行建模，并通过多层堆叠和拼接操作联合获取结构和时序表示。定义了节点和路径级别的异常评分函数，以实现从局部异常检测到全局调用链追踪的统一建模。

Result: 实验结果表明，该框架在AUC、ACC、Recall和F1-Score等关键指标上优于基线方法，在动态拓扑和复杂环境下保持了高准确性和稳定性。

Conclusion: 该研究为微服务异常检测提供了新的技术途径，并为分布式系统的智能运维奠定了方法论基础。

Abstract: This study addresses the problem of anomaly detection and root cause tracing
in microservice architectures and proposes a unified framework that combines
graph neural networks with temporal modeling. The microservice call chain is
abstracted as a directed graph, where multidimensional features of nodes and
edges are used to construct a service topology representation, and graph
convolution is applied to aggregate features across nodes and model
dependencies, capturing complex structural relationships among services. On
this basis, gated recurrent units are introduced to model the temporal
evolution of call chains, and multi-layer stacking and concatenation operations
are used to jointly obtain structural and temporal representations, improving
the ability to identify anomaly patterns. Furthermore, anomaly scoring
functions at both the node and path levels are defined to achieve unified
modeling from local anomaly detection to global call chain tracing, which
enables the identification of abnormal service nodes and the reconstruction of
potential anomaly propagation paths. Sensitivity experiments are then designed
from multiple dimensions, including hyperparameters, environmental
disturbances, and data distribution, to evaluate the framework, and results
show that it outperforms baseline methods in key metrics such as AUC, ACC,
Recall, and F1-Score, maintaining high accuracy and stability under dynamic
topologies and complex environments. This research not only provides a new
technical path for anomaly detection in microservices but also lays a
methodological foundation for intelligent operations in distributed systems.

</details>


### [207] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 本研究提出了一个适用于连续属性和回归问题的公平性度量和优化方法，称为“连续公平性”，并将其推广到核方法。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要关注离散属性，对于连续属性（尤其是在回归问题中）的公平性研究较少，而现实世界中的许多公平性问题涉及连续属性。

Method: 提出了一种名为“连续公平性”的新方法，将迭代零空间投影技术推广到核方法，使其能够处理连续的受保护属性，并且不依赖于特定的模型或公平性分数。

Result: 将新方法与支持向量回归（SVR）结合，在多个数据集上进行了实验，结果表明该方法具有与现有方法相当或更优的性能。

Conclusion: 该研究成功地将迭代零空间投影技术推广到核方法，为处理连续属性的公平性问题提供了一种新的、通用的解决方案，并证明了其在实际应用中的有效性。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [208] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [209] [A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications](https://arxiv.org/abs/2511.03363)
*Xiaocai Zhang,Hur Lim,Ke Wang,Zhe Xiao,Jing Wang,Kelvin Lee,Xiuju Fu,Zheng Qin*

Main category: cs.LG

TL;DR: 本研究提出了一种名为DMTC的数据驱动、模块化流水线，用于多标签意图识别，特别是在交通运输领域的智能体AI应用中。该方法通过生成合成数据和使用新颖的损失函数，无需标注数据即可提高意图识别的准确性，并在海事交通场景中得到了验证，取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的意图识别系统需要大量标注数据，并且在细粒度的多标签识别方面存在困难。本研究旨在提出一种无需昂贵数据收集即可提高多标签意图识别准确性的方法。

Method: DMTC流水线包括三个步骤：1）使用提示工程引导LLM生成多样化的合成查询；2）使用Sentence-T5模型编码文本查询以获得语义嵌入；3）使用新颖的在线焦距对比（OFC）损失函数训练一个轻量级分类器，该函数强调困难样本并最大化类间可分性。

Result: DMTC在海事交通场景中实现了5.35%的汉明损失和95.92%的AUC，优于最先进的多标签分类器和基于LLM的基线。Sentence-T5嵌入将子集准确率提高了至少3.29%，OFC损失比标准对比目标额外提高了0.98%。

Conclusion: 所提出的DMTC系统能够将用户查询无缝路由到特定任务模块，而无需昂贵的人工标注，为完全自主、意图感知的智能体奠定了基础。

Abstract: In this study, a modular, data-free pipeline for multi-label intention
recognition is proposed for agentic AI applications in transportation. Unlike
traditional intent recognition systems that depend on large, annotated corpora
and often struggle with fine-grained, multi-label discrimination, our approach
eliminates the need for costly data collection while enhancing the accuracy of
multi-label intention understanding. Specifically, the overall pipeline, named
DMTC, consists of three steps: 1) using prompt engineering to guide large
language models (LLMs) to generate diverse synthetic queries in different
transport scenarios; 2) encoding each textual query with a Sentence-T5 model to
obtain compact semantic embeddings; 3) training a lightweight classifier using
a novel online focal-contrastive (OFC) loss that emphasizes hard samples and
maximizes inter-class separability. The applicability of the proposed pipeline
is demonstrated in an agentic AI application in the maritime transportation
context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35%
and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers
and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that
Sentence-T5 embeddings improve subset accuracy by at least 3.29% over
alternative encoders, and integrating the OFC loss yields an additional 0.98%
gain compared to standard contrastive objectives. In conclusion, our system
seamlessly routes user queries to task-specific modules (e.g., ETA information,
traffic risk evaluation, and other typical scenarios in the transportation
domain), laying the groundwork for fully autonomous, intention-aware agents
without costly manual labelling.

</details>


### [210] [TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets](https://arxiv.org/abs/2511.03368)
*Hongrun Ren,Yun Xiong,Lei You,Yingying Wang,Haixu Xiong,Yangyong Zhu*

Main category: cs.LG

TL;DR: 该研究提出了一种统一的数据-模型耦合市场，以解决现有数据和模型交易市场分割或中介中心化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有市场机制未能同时且对称地处理数据卖家、模型生产者和模型买家之间的交易，导致数据和模型交易分割或中介中心化。

Method: 提出了一种统一的数据-模型耦合市场，通过供给侧映射将数据集支付转化为模型报价，并通过基于Shapley的分配将买家价格反向传播到数据集，形成一个闭环。该系统被证明是一个标准干扰函数（SIF），保证了均衡价格的存在性、唯一性和全局收敛性。

Result: 实验证明，该方法能够实现高效收敛，并与中介中心化和单边基线相比提高了公平性。

Conclusion: 所提出的统一数据-模型耦合市场能够有效解决现有市场分割和中介中心化问题，实现数据和模型交易的同步、对称和公平定价。

Abstract: The rise of the machine learning (ML) model economy has intertwined markets
for training datasets and pre-trained models. However, most pricing approaches
still separate data and model transactions or rely on broker-centric pipelines
that favor one side. Recent studies of data markets with externalities capture
buyer interactions but do not yield a simultaneous and symmetric mechanism
across data sellers, model producers, and model buyers. We propose a unified
data-model coupled market that treats dataset and model trading as a single
system. A supply-side mapping transforms dataset payments into buyer-visible
model quotations, while a demand-side mapping propagates buyer prices back to
datasets through Shapley-based allocation. Together, they form a closed loop
that links four interactions: supply-demand propagation in both directions and
mutual coupling among buyers and among sellers. We prove that the joint
operator is a standard interference function (SIF), guaranteeing existence,
uniqueness, and global convergence of equilibrium prices. Experiments
demonstrate efficient convergence and improved fairness compared with
broker-centric and one-sided baselines. The code is available on
https://github.com/HongrunRen1109/Triple-Win-Pricing.

</details>


### [211] [Adaptable Hindsight Experience Replay for Search-Based Learning](https://arxiv.org/abs/2511.03405)
*Alexandros Vazaios,Jannis Brugger,Cedric Derstroff,Kristian Kersting,Mira Mezini*

Main category: cs.LG

TL;DR: HER与AlphaZero结合，提出Adaptable HER框架，通过调整HER属性改进稀疏奖励下的搜索问题。


<details>
  <summary>Details</summary>
Motivation: 原始AlphaZero方法在稀疏奖励环境下训练受限，尤其是在早期阶段，网络尚无法提供有效指导。HER通过重标记失败轨迹来解决此问题。

Method: 提出Adaptable HER框架，将HER与AlphaZero结合，允许灵活调整HER的重标记目标、策略目标和轨迹选择等属性。

Result: 实验证明，Adaptable HER在包括方程发现等任务上表现优于纯监督学习或强化学习方法。

Conclusion: 调整HER属性的灵活性对提升AlphaZero在稀疏奖励环境下的性能是有益的。

Abstract: AlphaZero-like Monte Carlo Tree Search systems, originally introduced for
two-player games, dynamically balance exploration and exploitation using neural
network guidance. This combination makes them also suitable for classical
search problems. However, the original method of training the network with
simulation results is limited in sparse reward settings, especially in the
early stages, where the network cannot yet give guidance. Hindsight Experience
Replay (HER) addresses this issue by relabeling unsuccessful trajectories from
the search tree as supervised learning signals. We introduce Adaptable HER
(\ours{}), a flexible framework that integrates HER with AlphaZero, allowing
easy adjustments to HER properties such as relabeled goals, policy targets, and
trajectory selection. Our experiments, including equation discovery, show that
the possibility of modifying HER is beneficial and surpasses the performance of
pure supervised or reinforcement learning.

</details>


### [212] [POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding](https://arxiv.org/abs/2511.03464)
*Mihriban Kocak Balik,Pekka Marttinen,Negar Safinianaini*

Main category: cs.LG

TL;DR: POEMS是一个无监督概率框架，用于整合多组学数据，在保持预测性能的同时实现可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型在整合多组学数据时，要么牺牲可解释性以追求预测性能，要么通过线性化解码器来增强可解释性，但这会削弱网络的非线性表达能力。POEMS旨在克服这一权衡。

Method: POEMS框架通过以下方式实现可解释性：1. 使用稀疏连接将特征映射到潜在因子，直接用于生物标志物发现；2. 利用专家乘积模型和共享潜在空间来实现跨组学关联；3. 通过一个门控网络来计算每个组学在表示学习中的影响，并生成一个高效的稀疏解码器。

Result: 在一个癌症亚型案例研究中，POEMS实现了具有竞争力的聚类和分类性能，并提供了新颖的解释，证明了基于生物标志物的洞察和预测精度可以在多组学表示学习中共存。

Conclusion: POEMS成功地在多组学整合中实现了可解释性和预测性能的平衡，为生物标志物发现和疾病机制研究提供了新的见解。

Abstract: Integrating different molecular layers, i.e., multiomics data, is crucial for
unraveling the complexity of diseases; yet, most deep generative models either
prioritize predictive performance at the expense of interpretability or enforce
interpretability by linearizing the decoder, thereby weakening the network's
nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS:
Product Of Experts for Interpretable Multiomics Integration using Sparse
Decoding, an unsupervised probabilistic framework that preserves predictive
performance while providing interpretability. POEMS provides interpretability
without linearizing any part of the network by 1) mapping features to latent
factors using sparse connections, which directly translates to biomarker
discovery, 2) allowing for cross-omic associations through a shared latent
space using product of experts model, and 3) reporting contributions of each
omic by a gating network that adaptively computes their influence in the
representation learning. Additionally, we present an efficient sparse decoder.
In a cancer subtyping case study, POEMS achieves competitive clustering and
classification performance while offering our novel set of interpretations,
demonstrating that biomarker based insight and predictive accuracy can coexist
in multiomics representation learning.

</details>


### [213] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 本论文提出了一个结合核方法和群对称性的强化学习（RL）框架，以提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界的强化学习问题中，环境固有的对称性可以被利用来提高学习效率。

Method: 提出了一种对称感知乐观最小二乘值迭代（LSVI）的变体，该方法利用不变核来编码奖励和转移动力学中的不变性。分析了不变再生希尔伯特核空间（RKHS）的最大信息增益和覆盖数，并量化了对称性带来的样本效率提升。

Result: 在定制的Frozen Lake环境和二维布局设计问题上的实证结果证实了理论上的改进，表明对称感知RL的性能显著优于标准的核方法。

Conclusion: 这些发现强调了结构先验在设计更具样本效率的强化学习算法中的价值。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [214] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost是一个高效的检索增强生成（RAG）系统，通过精确地识别和重用跨会话和多轮交互中的重叠检索内容，实现了高缓存重用率，同时保持了推理准确性，并将LLM的预填充性能提高了1.5-3倍。


<details>
  <summary>Details</summary>
Motivation: 现有缓存技术在提高缓存重用率和保持推理准确性之间存在权衡，而现代应用需要更长、更复杂的输入，这使得预填充性能的优化尤为重要。

Method: RAGBoost通过上下文索引、排序和去重来检测重叠检索项，并利用轻量级的上下文提示来维护推理保真度，从而实现高缓存重用率和准确性。

Result: RAGBoost将LLM的预填充性能提高了1.5-3倍，并保持或提高了在各种RAG和代理AI工作负载下的推理准确性。

Conclusion: RAGBoost是一种高效的RAG系统，能够实现高缓存重用率和准确性，解决了现有技术的局限性，并显著提升了LLM在处理复杂输入时的性能。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [215] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: NAP模型通过三轴注意力机制融合多种预测流，实现了跨数据集的零样本泛化，在睡眠分期任务中表现优于单一预测器和简单集成模型。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以充分利用多模态生理信号（如多导睡眠图）的异质性，通常依赖固定的模态或通道子集，忽视了其固有的多模态特性。

Method: 提出了一种名为NAP（Neural Aggregator of Predictions）的基于注意力的模型，利用三轴注意力机制（捕捉时间、空间和预测器层面的依赖性）来学习组合多个预测流。NAP能够适应不同的输入维度，并通过聚合预训练的单通道模型的输出来进行训练。

Result: NAP模型一致优于各个单独的预测器和简单的集成模型，在跨多个数据集的零样本泛化方面达到了最先进的水平。

Conclusion: NAP模型成功地解决了现有模型在处理多模态异质信号时的局限性，通过有效融合不同来源的预测信息，实现了优异的泛化能力，并且该方法有望应用于其他多模态生理信号处理任务。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [216] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 当使用更少的数据进行模型训练时，可以使用一个理论框架来解决机器学习中的一个核心悖论，该框架在某些条件下可以带来比使用完整数据集更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 在机器学习领域，关于“何时使用更少的数据更好”的问题，存在一个核心悖论。经典的“越多越好”的扩展定律受到了LIMO和s1等方法的挑战，这些方法仅使用少量经过精心筛选的数据集就能获得卓越的性能。因此，理解数据筛选策略的有效性至关重要。

Method: 本研究提出了一个理论框架，研究了在数据筛选策略中，一个不完美的“神谕”根据训练样本的难度和正确性来选择训练样本的情况。研究结果为在标签无关和标签感知筛选规则下，测试误差提供了精确的扩展定律曲线。

Result: 该理论框架精确地揭示了仅保留部分数据何时以及为何能够改善泛化能力。与经典的扩展定律相反，研究表明在特定条件下，少量经过筛选的数据集可以优于完整的数据集。通过推导与数据大小和质量相关的精确相变曲线，得出了实现这一目标的解析条件。此外，研究结果在ImageNet数据集上得到了经验验证，证实了筛选可以提高准确性，甚至可以缓解模型崩溃现象。

Conclusion: 本研究提出的理论框架不仅精确地解释了数据筛选策略的效果，而且为近期在大型语言模型数学推理中观察到的矛盾筛选策略提供了原则性的解释。它揭示了在特定条件下，使用经过筛选的少量数据进行训练，比使用完整数据集更能提高模型的泛化能力。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [217] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: GRPO是一种不需要学习评论员的PPO替代方案，通过基于组的轨迹相对比较来估计优势。本研究系统地研究了GRPO在经典强化学习环境中的表现，并发现了其局限性和适用条件。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨在策略梯度方法中，是否可以不使用学习到的基线（评论员），并系统地研究GRPO在经典单任务强化学习环境中的表现。

Method: 通过在经典单任务强化学习环境中进行实验，并进行消融研究，分离基线、折扣和组采样等因素，来系统地研究GRPO。

Result: 研究发现，在长时限任务中，学习到的评论员仍然是必需的，而在短时限环境（如CartPole）中，无评论员基线表现良好。GRPO在大多数情况下受益于高折扣因子（gamma=0.99），但在HalfCheetah环境中，中等折扣因子（gamma=0.9）效果更好。较小的组大小优于较大的组大小。

Conclusion: 研究结果揭示了无评论员方法在经典控制中的局限性，以及它们在何种条件下可以作为学习值函数的替代方案。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [218] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 本论文提出了一种新的拜占庭鲁棒联邦学习优化方法，通过自适应权重聚合来解决恶意客户端的问题，并在异构数据分布下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在允许客户端协作训练全局模型而不共享私人数据方面发挥着关键作用。然而，恶意（拜占庭）客户端的存在对 FL 的鲁棒性构成了重大挑战，尤其是在客户端之间的数据分布异构的情况下。

Method: 提出了一种新的拜占庭鲁棒 FL 优化问题，该问题将自适应权重整合到聚合过程中。该方法将聚合权重视为可学习参数，并与全局模型参数一起进行优化。采用交替最小化算法来解决该优化问题，并对拜占庭弹性进行了分析。

Result: 实验结果表明，在数据高度异构和恶意客户端比例较大的情况下，该方法在各种数据集和攻击场景下均优于现有的拜占庭鲁棒 FL 方法。

Conclusion: 提出的自适应加权方法在联邦学习中提供了强大的拜占庭鲁棒性，尤其是在具有挑战性的异构数据分布和高比例恶意客户端的情况下。

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [219] [Efficient Neural Networks with Discrete Cosine Transform Activations](https://arxiv.org/abs/2511.03531)
*Marc Martinez-Gost,Sara Pepe,Ana Pérez-Neira,Miguel Ángel Lagunas*

Main category: cs.LG

TL;DR: ENN通过DCT参数化实现高效、可解释和可剪枝的神经网络，在分类和隐式神经表示任务中达到最先进的性能，同时可安全剪枝高达40%的激活系数。


<details>
  <summary>Details</summary>
Motivation: 在先前工作的基础上，强调ENN的效率、可解释性和剪枝能力。

Method: 使用离散余弦变换（DCT）参数化多层感知器的自适应激活函数，提出一种有效的剪枝策略，去除不必要的DCT系数。

Result: 实验结果表明，ENN在分类和隐式神经表示任务中达到最先进的准确率，同时保持较少的参数数量，并且可以安全地剪枝高达40%的激活系数。

Conclusion: ENN框架将信号处理概念整合到神经网络设计中，实现了表达能力、紧凑性和可解释性之间的平衡。

Abstract: In this paper, we extend our previous work on the Expressive Neural Network
(ENN), a multilayer perceptron with adaptive activation functions parametrized
using the Discrete Cosine Transform (DCT). Building upon previous work that
demonstrated the strong expressiveness of ENNs with compact architectures, we
now emphasize their efficiency, interpretability and pruning capabilities. The
DCT-based parameterization provides a structured and decorrelated
representation that reveals the functional role of each neuron and allows
direct identification of redundant components. Leveraging this property, we
propose an efficient pruning strategy that removes unnecessary DCT coefficients
with negligible or no loss in performance. Experimental results across
classification and implicit neural representation tasks confirm that ENNs
achieve state-of-the-art accuracy while maintaining a low number of parameters.
Furthermore, up to 40% of the activation coefficients can be safely pruned,
thanks to the orthogonality and bounded nature of the DCT basis. Overall, these
findings demonstrate that the ENN framework offers a principled integration of
signal processing concepts into neural network design, achieving a balanced
trade-off between expressiveness, compactness, and interpretability.

</details>


### [220] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 即使在凸优化的经典设置中，平坦最小值也可能导致普遍风险，而尖锐最小值可以实现最佳泛化。


<details>
  <summary>Details</summary>
Motivation: 学习算法的泛化行为是学习理论的核心目标。平坦最小值通常与改进的泛化性能相关联，因此本研究旨在探讨平坦最小值与泛化之间的联系。

Method: 研究了随机凸优化中目标函数为非负、$eta$-光滑的经典情况。分析了两种“锐度感知”算法：锐度感知梯度下降（SA-GD）和锐度感知最小化（SAM）。

Result: 发现即使在经典设置中，平坦的经验最小值也可能导致平凡的$\	ext{Omega}(1)$的泛化风险，而尖锐的最小值可以实现最优泛化。对于SA-GD，即使它收敛到平坦最小值，其泛化风险仍可能高达$\	ext{Omega}(1)$。对于SAM，它可能收敛到尖锐最小值并产生$\	ext{Omega}(1)$的泛化风险。最后，使用算法稳定性技术为SA-GD和SAM建立了泛化风险的上限。

Conclusion: 即使在凸优化的经典设置中，平坦最小值也可能导致普遍风险，而尖锐最小值可以实现最佳泛化。这表明仅依赖平坦最小值可能不足以保证良好的泛化性能，并且需要更精细的分析或算法设计。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [221] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 深度学习推动了模仿学习（IL）的发展，使其能够处理各种专家数据并应对泛化、协变量偏移和演示质量等挑战。本篇综述回顾了最新的IL研究进展，提出了新的分类方法，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 模仿学习（IL）能够让智能体通过观察和模仿一个或多个专家的行为来学习技能。近年来，深度学习的进步极大地扩展了IL的能力和可扩展性，这促使了新的方法来应对泛化性、协变量偏移和演示质量等长期存在的挑战。

Method: 本综述回顾了模仿学习的最新进展，重点介绍了近期趋势、方法创新和实际应用。我们提出了一个新的分类体系，并批判性地审查了代表性作品的优点、局限性和评估实践。

Result: 本次调查回顾了模仿学习的最新进展，强调了近期趋势、方法创新和实际应用。我们提出了一个新的分类法，以更好地反映当前的IL研究现状及其趋势。

Conclusion: 本综述全面概述了模仿学习领域的最新进展，为未来的研究提供了方向，并强调了该领域应对挑战和抓住机遇的潜力。

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [222] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: TabGemma是一个新的LLM模型，用于表格预测，通过数字规范化和上下文检索解决了数字标记和上下文长度限制的问题，并在分类任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练LLM在处理包含文本、数字和类别字段的表格数据进行预测时存在数字标记不稳定和上下文长度有限的问题。

Method: 提出了一种名为TabGemma的模型，该模型将表格行视为序列，通过将数字规范化为带符号科学计数法来解决数字标记问题，并使用n-gram检索来选择上下文信息，以适应有限的上下文窗口。对一个12B的Gemma 3模型进行了目标填充目标和大规模真实世界数据集的继续预训练。

Result: 在具有语义丰富性的基准测试中，TabGemma在低数据和高数据量的情况下都建立了新的分类任务最先进成果，并且随着上下文行数的增加，性能单调提升。在回归任务中，TabGemma在小样本量时具有竞争力，但随着数据量的增加，性能落后于传统方法。

Conclusion: LLM可以成为有效的表格上下文学习者，特别是在语义丰富的任务上，但需要专门的数字处理和上下文检索。这表明在数字建模和长上下文扩展方面需要进一步的研究和改进。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [223] [Learning Under Laws: A Constraint-Projected Neural PDE Solver that Eliminates Hallucinations](https://arxiv.org/abs/2511.03578)
*Mainak Singha*

Main category: cs.LG

TL;DR: 通过将物理定律嵌入训练过程，CPL框架确保神经元求解器在求解偏微分方程时遵守物理规律，消除了诸如质量守恒、熵增等违规行为，同时保持了求解精度。


<details>
  <summary>Details</summary>
Motivation: 神经元求解器在求解偏微分方程时，常常会违反物理定律，例如产生虚假质量、移动激波或破坏守恒和熵。本研究旨在解决这个问题。

Method: 提出了一种名为约束投影学习（CPL）的框架，通过将网络输出投影到由守恒、Rankine-Hugoniot平衡、熵和正性定义的约束集上，确保每一次更新都符合物理规律。该投影是可微的，并且计算开销仅增加约10%，与反向传播兼容。此外，还采用了全变差阻尼（TVD）和滚动学习策略来稳定训练并确保长预测时间的连贯性。

Result: CPL框架成功消除了硬性和软性违规行为：守恒律在机器精度上得到满足，全变差增长消失，熵和误差保持有界。在Burgers和Euler系统上，CPL在不损失精度的前提下，生成了稳定且符合物理规律的解。

Conclusion: CPL使物理规律成为学习过程的内在属性，而不是依赖于神经元求解器自行遵守物理定律的期望，从而确保了物理约束的满足。

Abstract: Neural networks can approximate solutions to partial differential equations,
but they often break the very laws they are meant to model-creating mass from
nowhere, drifting shocks, or violating conservation and entropy. We address
this by training within the laws of physics rather than beside them. Our
framework, called Constraint-Projected Learning (CPL), keeps every update
physically admissible by projecting network outputs onto the intersection of
constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and
positivity. The projection is differentiable and adds only about 10%
computational overhead, making it fully compatible with back-propagation. We
further stabilize training with total-variation damping (TVD) to suppress small
oscillations and a rollout curriculum that enforces consistency over long
prediction horizons. Together, these mechanisms eliminate both hard and soft
violations: conservation holds at machine precision, total-variation growth
vanishes, and entropy and error remain bounded. On Burgers and Euler systems,
CPL produces stable, physically lawful solutions without loss of accuracy.
Instead of hoping neural solvers will respect physics, CPL makes that behavior
an intrinsic property of the learning process.

</details>


### [224] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DIIQN的深度隐式模仿强化学习框架，解决了传统模仿学习需要最优专家示范和仅能达到专家表现的局限性，并进一步提出了HA-DIIQN以应对专家和智能体动作空间不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习需要最优专家示范，且性能受限于专家，这在现实世界中难以实现，因为现实场景通常只提供状态观测，且专家表现可能不是最优的。

Method: 提出了一种名为DIIQN的深度隐式模仿强化学习框架，结合了深度强化学习和隐式模仿学习，利用动作推断机制通过在线探索重建专家动作，并引入动态置信机制来平衡专家指导和自主学习。在此基础上，提出了HA-DIIQN，通过不可行性检测机制和桥接程序来解决专家和智能体动作集不同的问题。

Result: DIIQN在模拟环境中实现了比标准DQN高130%的 эпизодический return，并优于现有的隐式模仿方法。HA-DIIQN在异构动作设置下学习速度比基线快64%。

Conclusion: 所提出的DIIQN和HA-DIIQN框架能够有效地处理仅有状态观测的数据集，并能超越次优专家表现，在专家和智能体动作空间不匹配的情况下也能实现高效学习。

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [225] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文使用 Lean 4 证明器在 Mathlib 库中形式化了基于马尔可夫样本的 Q 学习和线性 TD 学习的几乎处处收敛性。


<details>
  <summary>Details</summary>
Motivation: Q 学习和线性 TD 是最早且最有影响力的强化学习算法，它们收敛性的研究不仅是早期 RL 的主要课题，近年来也受到越来越多的关注。

Method: 在统一的框架下，基于 Robbins-Siegmund 定理，形式化验证了 Q 学习和线性 TD 学习的几乎处处收敛性。

Result: 开发了一个可以轻松扩展到收敛速度和其他收敛模式的框架，为完全形式化收敛性 RL 结果迈出了重要一步。

Conclusion: 本文成功形式化验证了 Q 学习和线性 TD 学习的几乎处处收敛性，并提供了一个可扩展的框架，为 RL 理论的形式化研究做出了贡献。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [226] [Financial Management System for SMEs: Real-World Deployment of Accounts Receivable and Cash Flow Prediction](https://arxiv.org/abs/2511.03631)
*Bartłomiej Małkus,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 该论文开发了一个集成财务预测系统，为中小企业（特别是自由职业者和早期企业）提供应收账款预测和现金流预测，以应对其有限的资源和数据限制。


<details>
  <summary>Details</summary>
Motivation: 由于资源有限、客户群小以及数据可用性受限，中小型企业（尤其是自由职业者和初创企业）面临独特的财务管理挑战。

Method: 开发并部署了一个集成财务预测系统，该系统结合了预测发票付款延迟的二元分类模型和处理不完整、有限历史数据的多模块现金流预测模型。

Result: 该系统已作为 Web 应用程序成功实施并部署，并与为自由职业者提供财务管理工具的 Cluee 平台集成，证明了其在现实世界的中小企业财务管理中的实际可行性。

Conclusion: 该集成财务预测系统可以满足中小企业（尤其是自由职业者和初创企业）的实际需求，弥合了企业级工具与这些企业之间的差距。

Abstract: Small and Medium Enterprises (SMEs), particularly freelancers and early-stage
businesses, face unique financial management challenges due to limited
resources, small customer bases, and constrained data availability. This paper
presents the development and deployment of an integrated financial prediction
system that combines accounts receivable prediction and cash flow forecasting
specifically designed for SME operational constraints. Our system addresses the
gap between enterprise-focused financial tools and the practical needs of
freelancers and small businesses. The solution integrates two key components: a
binary classification model for predicting invoice payment delays, and a
multi-module cash flow forecasting model that handles incomplete and limited
historical data. A prototype system has been implemented and deployed as a web
application with integration into Cluee's platform, a startup providing
financial management tools for freelancers, demonstrating practical feasibility
for real-world SME financial management.

</details>


### [227] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: nanoTabPFN是一个简化的、轻量级的TabPFN v2实现，使得表格基础模型更容易被学生和研究人员使用，并且在小数据设置下，其性能可与传统机器学习基线相媲美，预训练速度比TabPFN v2快160,000倍。


<details>
  <summary>Details</summary>
Motivation: 现有开源表格基础模型的实现复杂、难以理解、不适合初学者，并且难以适应新实验。本研究旨在解决这些问题。

Method: 提出nanoTabPFN，一个简化的、轻量级的TabPFN v2架构实现，以及一个使用预生成训练数据的相应训练循环。

Result: nanoTabPFN在小数据设置下，使用一个GPU进行一分钟的预训练，即可达到与传统机器学习基线相当的性能，预训练速度比TabPFN v2快160,000倍。

Conclusion: nanoTabPFN通过降低对计算资源的要求，使得预训练表格基础模型在教育目的下变得可行，从而提高了表格基础模型的易用性和可访问性。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [228] [SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection](https://arxiv.org/abs/2511.03661)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.LG

TL;DR: 本研究提出了一种基于机器学习的框架，用于检测物联网医疗设备中的恶意网络攻击和故障设备异常。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域集成物联网设备带来了严峻的安全和可靠性挑战，增加了遭受网络威胁和运行异常的可能性。

Method: 研究评估了八种机器学习模型（XGBoost、KNN、GAN、VAE、One-Class SVM、Isolation Forest、GNN、LSTM Autoencoders）在三种学习方法（监督、半监督、无监督）上的表现，并使用了包括F1分数、精确率、召回率、准确率、ROC-AUC和计算效率在内的多项指标进行评估。

Result: XGBoost在异常检测方面达到了99%的准确率，计算开销极小（0.04秒）。Isolation Forest在精确率和召回率之间取得了良好平衡。KNN在攻击检测方面实现了近乎完美的精确率、召回率和F1分数，计算成本最低（0.05秒），VAE准确率达到97%。LSTM Autoencoders表现不佳，准确率较低，延迟较高。GAN的计算成本最高，准确率和ROC-AUC最低。

Conclusion: 研究结果通过有效的异常检测策略增强了物联网医疗的安全性，有助于及早发现网络威胁和设备故障，从而防止数据泄露，最大限度地减少系统停机时间，确保医疗设备的持续安全运行，最终保障患者的健康和对物联网医疗解决方案的信任。

Abstract: The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty device
anomalies, leveraging a dataset of 200,000 records. Eight machine learning
models are evaluated across three learning approaches: supervised learning
(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative
Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised
learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph
Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The
comprehensive evaluation was conducted across multiple metrics like F1-score,
precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost
achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly
detection, while Isolation Forest balanced precision and recall effectively.
LSTM Autoencoders underperformed with lower accuracy and higher latency. For
attack detection, KNN achieved near-perfect precision, recall, and F1-score
with the lowest computational cost (0.05s), followed by VAE at 97% accuracy.
GAN showed the highest computational cost with lowest accuracy and ROC-AUC.
These findings enhance IoT-enabled healthcare security through effective
anomaly detection strategies. By improving early detection of cyber threats and
device failures, this framework has the potential to prevent data breaches,
minimize system downtime, and ensure the continuous and safe operation of
medical devices, ultimately safeguarding patient health and trust in IoT-driven
healthcare solutions.

</details>


### [229] [DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay](https://arxiv.org/abs/2511.03670)
*Daniel Perkins,Oscar J. Escobar,Luke Green*

Main category: cs.LG

TL;DR: 本研究深入探讨了深度Q网络(DQN)在有限环境中的应用，重点关注了epsilon-greedy探索策略和优先经验回放对学习效率、收敛行为和奖励优化的影响。


<details>
  <summary>Details</summary>
Motivation: 研究深度Q网络在有限环境中的表现，特别是探索策略和经验回放机制如何影响学习过程。

Method: 通过系统性实验，评估不同epsilon衰减率对学习效率、收敛行为和奖励优化的影响，并比较了均匀、无回放和优先回放策略的效果。

Result: 优先经验回放能够加速收敛并提升回报，并提供了不同回放策略的实证比较结果。

Conclusion: 揭示了探索策略和记忆管理在DQN训练中的权衡与相互作用，为资源受限环境下的鲁棒强化学习提供了实用建议。

Abstract: We present a detailed study of Deep Q-Networks in finite environments,
emphasizing the impact of epsilon-greedy exploration schedules and prioritized
experience replay. Through systematic experimentation, we evaluate how
variations in epsilon decay schedules affect learning efficiency, convergence
behavior, and reward optimization. We investigate how prioritized experience
replay leads to faster convergence and higher returns and show empirical
results comparing uniform, no replay, and prioritized strategies across
multiple simulations. Our findings illuminate the trade-offs and interactions
between exploration strategies and memory management in DQN training, offering
practical recommendations for robust reinforcement learning in
resource-constrained settings.

</details>


### [230] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 参数化后验校准方法可以通过逻辑回归获得理论基础，并激发了更具表达力的校准方法。然而，多类校准面临参数增加和数据有限的挑战。通过结构化正则化、鲁棒预处理和高效优化，可以有效管理偏差-方差权衡，并取得显著的性能提升，优于现有的基于逻辑回归的校准技术。


<details>
  <summary>Details</summary>
Motivation: 现有的参数化后验校准方法（如逻辑回归）具有理论基础，这启发了研究更具表达力的校准方法。然而，在多类情况下，增加的参数量和有限的校准数据会导致过拟合。

Method: 研究如何通过结构化正则化、鲁棒预处理和高效优化来管理多类校准中的偏差-方差权衡，以应对参数量增加和数据有限的挑战。

Result: 所提出的方法在多类校准任务上取得了显著的性能提升，优于现有的基于逻辑回归的校准技术，如温度、向量和矩阵缩放。

Conclusion: 本研究提出了更具表达力的多类校准方法，并通过结构化正则化、鲁棒预处理和高效优化解决了过拟合问题，为实际应用提供了高效易用的开源实现。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [231] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: BAQ框架通过引入行为一致性信号，实现了从离线到在线强化学习的平滑过渡，提高了在动态环境中的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习策略在动态环境中部署时，由于分布偏移和对未见状态-动作对的不可靠估计，表现不佳。需要一种方法来实现从离线到在线的可靠过渡。

Method: BAQ框架利用从离线数据中提取的隐式行为模型，在在线微调期间提供行为一致性信号。它采用双目标损失函数，在不确定性高时使在线策略向离线行为对齐，并在累积更多置信的在线经验时逐渐放鬆约束。

Result: BAQ在标准基准测试中持续优于现有的离线到在线强化学习方法，实现了更快的恢复速度、更高的鲁棒性和整体性能。

Conclusion: 隐式行为适应是可靠的实际策略部署的一种原则性和实用性解决方案。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [232] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: RLVR通过使用GRPO等策略梯度方法进行训练，但会遇到奖励不稳定问题。该研究提出了一种基于收缩估计的奖励基线，通过结合批内和跨批的平均奖励来提高奖励估计的准确性，从而降低策略梯度估计的方差，提高训练稳定性。


<details>
  <summary>Details</summary>
Motivation: RLVR中的策略梯度方法（如GRPO）在训练过程中通常会通过减去经验均值来中心化轨迹奖励，以降低策略梯度估计量的方差。然而，现有的基于批内经验均值的估计方法在低生成量时不够准确。

Method: 提出了一种基于收缩估计的基线，该方法结合了每批次的提示内平均奖励和跨批次的平均奖励，以改进每批次提示的平均奖励估计。这种方法可以作为现有每批次提示平均奖励基线的替代品。

Result: 理论上，提出的收缩基线可以提供更低方差的策略梯度估计量。在实践中，收缩基线在实验中持续优于标准的经验均值基线，导致更低的梯度更新方差和更稳定的训练。

Conclusion: 提出的收缩基线是一种有效的改进方法，可以提高RLVR训练的稳定性和效率，且无需额外的超参数或计算成本。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [233] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: AI控制协议在SHADE-Arena环境中进行了评估，发现“关键操作推迟”协议对自适应攻击者具有鲁棒性，而“重采样”协议则不然。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理能力增强和部署范围扩大，确保其安全运行至关重要。AI控制为减轻不可信AI代理风险提供了一种方法，通过监控其行为并进行干预或审计。

Method: 在SHADE-Arena环境中，评估了一系列AI控制协议，包括推迟给受信任模型、重采样以及关键操作推迟，并针对性地进行了红队攻击策略迭代。

Result: 重采样和关键操作推迟在对抗默认攻击策略时表现最佳，安全性从50%提升至96%。然而，重采样协议在面对具有额外信息（如了解重采样发生时间或模拟监控器）的攻击策略时，安全性下降至17%。关键操作推迟协议对最强的红队策略也表现出高度鲁棒性。

Conclusion: 关键操作推迟协议因其能够限制攻击者对协议内部机制的访问，而在应对自适应攻击者方面展现出优越的鲁棒性，强调了隐藏协议内部机制的重要性。

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [234] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: 一个多智能体框架PublicAgent，通过分解任务到专门的智能体来解决大型语言模型在处理复杂数据分析工作流中的局限性，提高了数据分析的可及性。


<details>
  <summary>Details</summary>
Motivation: 现有开放数据存储库虽然有潜力支持循证决策，但由于非专业用户缺乏数据集发现、模式映射和统计分析等方面的专业知识而难以访问。大型语言模型在处理这些任务时存在注意力和错误传播等根本性局限。

Method: 提出了一种名为PublicAgent的多智能体框架，将复杂的数据分析任务分解为意图澄清、数据集发现、分析和报告等专门的智能体，以保持智能体内部的注意力集中，并在每个阶段进行验证。

Result: 评估结果表明，专业化智能体带来了独立于模型能力的优势，即使是强大的模型也表现出高胜率。通用智能体（发现、分析）比条件智能体（报告、意图）更有效。移除发现或分析智能体会导致灾难性失败，而移除报告或意图智能体则会导致质量下降。架构优势在不同任务复杂性下依然存在，但智能体有效性因模型而异，需要进行模型感知的架构设计。

Conclusion: PublicAgent框架通过专业化智能体有效解决了大型语言模型在复杂分析工作流中的局限性，为更广泛的用户通过自然语言接口访问公共数据提供了途径，并提出了五条关于专业化在多智能体LLM系统中重要性的设计原则。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [235] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval是一个大规模的基准研究，比较了36种大型语言模型（LLMs）在产品推荐方面的表现，并提出了一种无需人工标注的评估协议。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）作为裁判对于构建可扩展和可信赖的评估流水线至关重要。

Method: 使用多代理框架，通过可扩展的多数投票聚合模式审计和问题代码，生成地面真值标签，从而实现对LLM评估器的可复现比较。

Result: 在大型互补品推荐应用中，Anthropic Claude 3.5 Sonnet 具有最高的决策置信度；Gemini 1.5 Pro 在各类别中表现最佳；GPT-4o 在延迟、准确性和成本之间取得了最佳平衡；GPT-OSS 20B 在开源模型中表现最佳。结构化领域（电子、体育）的共识较强，而生活方式类别（服装、食品）的意见分歧仍然存在。

Conclusion: ScalingEval 作为一个可复现的基准和评估协议，为LLMs作为裁判提供了关于可扩展性、可靠性和模型系列权衡的可操作指南。

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [236] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: 该研究提出了一种名为SnapStream的KV缓存压缩方法，以解决大规模语言模型（LLM）在工业部署中对内存的需求。该方法通过控制KV缓存大小来维持模型精度，并克服了现有框架（如vLLM）在静态图和连续批处理方面的限制。研究在Llama-3.1-8B-Instruct和DeepSeek-R1模型上进行了准确性分析，并成功在SambaNova SN40L加速器上将DeepSeek-671B模型部署在128k上下文长度下，实现了4倍的内存使用效率提升和每秒1832个标记的处理速度，同时在LongBench-v2、AIME24和LiveCodeBench基准测试中仅有微小的精度损失。这是首个在具有静态图和连续批处理的生产推理系统中实现的稀疏KV注意力技术。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）和长上下文支持增加了对内存（特别是KV缓存）的需求。虽然StreamingLLM和SnapKV等技术可以控制KV缓存大小并保持模型精度，但由于工业部署框架（如vLLM）的静态图和连续批处理方法难以修改标准的多头注意力算法，且这些技术在现代指令遵循和推理模型上的准确性影响尚不明确，因此并未被广泛应用。

Method: 该研究探索了KV缓存压缩技术在Llama-3.1-8B-Instruct和DeepSeek-R1模型上的准确性影响，并开发了一种名为SnapStream的KV缓存压缩方法。该方法旨在能够大规模部署，并被设计用于解决现有工业部署框架（如vLLM）在静态图和连续批处理方面进行修改的困难。最终，SnapStream被成功集成到16路张量并行部署的DeepSeek-671B模型中。

Result: SnapStream在SambaNova SN40L加速器上实现了16路张量并行部署的DeepSeek-671B模型在128k上下文长度下运行时，实现了每秒1832个标记的处理速度。该方法将内存使用量提高了4倍，并在LongBench-v2、AIME24和LiveCodeBench基准测试中显示出最小的准确性下降。

Conclusion: SnapStream是一种有效的KV缓存压缩方法，能够显著提高内存使用效率并保持模型精度，同时可以集成到现有工业部署的LLM推理系统中。该研究首次在具有静态图和连续批处理的生产推理系统中实现了稀疏KV注意力技术，为解决大规模LLM的内存瓶颈问题提供了一个可行的方案。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [237] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文提出了一个评估大型语言模型（LLM）对现实世界概率分布知识的基准测试，发现LLM在理解和内化这些统计数据方面表现不佳，表明它们在因果层次结构的第一层（观察层）也存在局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在科学和实际应用中展现出巨大潜力，但要实现更通用的智能，需要在理解概率知识方面取得进展。现有的研究缺乏直接评估LLM对现实世界概率分布理解能力的基准测试。

Method: 开发了一个基准测试，用于评估LLM在经济学、健康、教育和社会行为等多个领域的现实世界概率分布知识。通过分析LLM在处理这些分布方面的表现来评估其能力。

Result: LLM在基准测试中的整体表现不佳，未能自然地内化现实世界的统计数据。具体而言，LLM在因果层次结构的第一层（观察层）的知识也存在局限性。

Conclusion: LLM在理解现实世界的概率分布方面存在显著缺陷，其在因果层次结构第一层的知识不足，因此在第二层（干预层）和第三层（反事实层）的知识也受到限制。这表明，尽管LLM在处理语言方面能力强大，但在量化和理解现实世界的不确定性方面仍有很长的路要走。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [238] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 开发了一个多智能体AI框架，通过集成结构化设计和评审循环来形式化工程设计过程，并以NACA翼型气动优化为例进行了展示。


<details>
  <summary>Details</summary>
Motivation: 传统的工程设计过程需要跨领域专家协作，可能效率低下且资源消耗大。本研究旨在通过AI框架提高工程设计的效率、一致性和质量。

Method: 提出一个多智能体AI框架，包含图论本体、设计工程师和系统工程师三个关键AI智能体。图论本体利用LLM构建知识图谱，系统工程师根据人类经理的要求制定技术指标，设计工程师生成和优化翼型设计，系统工程师提供反馈，形成迭代循环。

Result: 成功将该框架应用于NACA翼型的气动优化，通过AI智能体协作生成并优化了满足特定技术要求的设计，最大化了升阻比等性能指标。

Conclusion: 多智能体协作AI框架，结合结构化知识表示，能够有效提升工程设计过程的效率、一致性和质量。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [239] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: LLM在医疗领域的应用需要新的监控方法，因为它们是通用模型，而非针对特定任务训练。我们提出基于能力的监控，通过评估通用能力（如总结、推理、翻译、安全）来检测系统性问题，这比传统的基于任务的监控更具可扩展性，并且可以发现任务监控可能忽略的细微错误和新兴行为。


<details>
  <summary>Details</summary>
Motivation: 传统基于任务的监控方法不适用于通用LLM，因为LLM并非为特定任务或人群训练，其性能下降无法假设。需要一种新的、可扩展的监控方法来适应LLM的通用性和使用方式。

Method: 提出并阐述了“基于能力的监控”方法。这种方法不单独评估每个下游任务，而是围绕LLM共享的通用能力（如文本摘要、推理、翻译、安全防护栏）进行组织监控，从而能够跨任务检测系统性缺陷、长尾错误和新兴行为。

Result: 基于能力的监控能够实现跨任务检测系统性弱点、长尾错误和新兴行为，克服传统任务监控的局限性，并为LLM和未来通用人工智能模型提供一个可扩展、安全、自适应和协作的监控基础。

Conclusion: 基于能力的监控为医疗领域LLM的监控提供了一个可扩展的框架，能够更有效地识别和解决通用模型带来的独特挑战，从而促进LLM的安全和有效应用。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [240] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 该研究分析了miniF2F基准测试中的形式化和非形式化陈述，并提出了miniF2F-v2版本，以提高形式化推理模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统在数学奥林匹克竞赛场景下，理解、形式化和证明miniF2F基准测试中问题的能力，并分析其局限性。

Method: 1. 分析miniF2F基准测试中的形式化和非形式化陈述的准确性。 2. 评估当前最优模型（SoTA）在整个问题解决流程（从自然语言理解到Lean形式化证明）中的表现。 3. 识别并追溯导致准确率下降的失败模式，特别是形式化和非形式化陈述之间的差异。 4. 修正miniF2F基准测试中的所有错误、差异和简化，创建miniF2F-v2版本。 5. 在miniF2F-v2版本上重新评估整个定理证明流程。 6. 深入分析结果，为社区提供更高质量的基准测试，以更好地评估和诊断形式化推理模型。

Result: 1. 在原始miniF2F基准测试上，最佳准确率约为36%，远低于单独的自动形式化（97%）和定理证明（69%）的准确率。 2. 超过一半的问题中，形式化和非形式化陈述之间存在差异，这是导致准确率下降的重要原因。 3. 修正后的miniF2F-v2基准测试将最佳准确率提高到70%。 4. 尽管有所改进，但自动形式化模型和定理证明器之间仍存在显著的不匹配。

Conclusion: 1. 形式化和非形式化陈述之间的一致性对于提高AI系统在数学竞赛中的表现至关重要。 2. 现有的miniF2F基准测试存在大量错误和不一致之处，阻碍了模型性能的真实评估。 3. 提出的miniF2F-v2版本通过修正这些问题，显著提高了评估的准确性。 4. 即使在改进后的基准测试上，自动形式化和定理证明模型之间仍然存在差距，需要进一步的研究来弥合。 5. 高质量的基准测试对于推动形式化推理领域的发展至关重要，有助于更好地评估模型进展和诊断失败/成功模式。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [241] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: Solly是首个在多人博弈的“说谎扑克”游戏中达到顶尖人类水平的AI。该AI使用深度强化学习训练，在胜率和盈利能力上均超越人类和大型语言模型，并开发了新的策略。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI在模拟多人博弈、信息不全和不确定性推理方面的局限性，特别是在扑克类游戏中，以往的研究主要集中在两人游戏，未能充分体现多人动态博弈的复杂性。

Method: 使用模型无关的actor-critic深度强化学习算法，通过自我对弈的方式训练Solly。

Result: Solly在两人和多人“说谎扑克”游戏中均达到了顶尖人类水平，胜率超过50%，并且在盈利能力上超越了大型语言模型（包括具有推理能力的大模型）。Solly还开发了新的出价策略，实现了有效随机化，并且难以被顶尖人类玩家利用。

Conclusion: Solly的成功表明，深度强化学习可以有效地应对多人、信息不全和不确定性推理的复杂博弈环境，为开发更高级别的AI智能体提供了新的途径。

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


### [242] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 本研究提出一种结合多模态大语言模型（MLLM）来改进烟火算法（FWA）的方法，以解决复杂优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法难以处理非凸性、高维度、黑盒等复杂优化问题的挑战，而LLM的语言理解和代码生成能力为优化算法设计提供了新思路。

Method: 提出“关键部分”（CP）的概念，将FWA扩展到高维任务，并利用MLLM的多模态能力来增强优化过程的信息利用。

Result: 在旅行商问题（TSP）和电子设计自动化问题（EDA）上，基于新框架生成的FWA达到了或超过了现有最优（SOTA）水平。

Conclusion: 结合MLLM的FWA在处理复杂优化问题方面表现出色，能够达到或超越现有最优方法。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [243] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 该研究提出了一个创新的框架，通过输入和输出层面的安全控制来增强大型语言模型的安全性，解决了LLM部署中的安全问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的广泛应用带来了日益严峻的安全问题，限制了其在关键领域的可靠部署。本研究旨在提出一个系统性的安全响应框架，以解决这些安全挑战。

Method: 该框架在输入层面采用基于监督微调的安全分类模型，并使用细粒度的四级分类（安全、不安全、条件安全、关注点）来识别和处理用户查询。在输出层面，框架结合了检索增强生成（RAG）和一个专门微调的解释模型，确保响应基于可信的实时知识库，以消除信息捏造并实现结果可追溯性。

Result: 在公开安全评估基准测试中，该框架的安全控制模型显著优于基线模型TinyR1-Safety-8B。在专有的高风险测试集中，该框架的组件获得了100%的安全分数，证明了其在复杂风险场景下的强大保护能力。

Conclusion: 本研究提供了一个有效的工程途径，用于构建高安全性、高可信度的LLM应用，解决了LLM部署中的关键安全约束。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [244] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 形式化可解释人工智能（XAI）的实践实现验证不足，本文提出了一种新的验证方法，并发现公开的PyXAI工具存在错误。


<details>
  <summary>Details</summary>
Motivation: 与其他非形式化方法相比，形式化可解释人工智能（XAI）提供了独特的理论严谨性保证。然而，对形式化解释器实际实现的验证的关注很少。

Method: 提出了一种新颖的形式化解释器验证方法，并使用该方法评估了公开的PyXAI工具。

Result: 在分析的大多数数据集上，PyXAI 计算出的解释存在错误。

Conclusion: 验证形式化解释器的重要性，并强调了所提出的新颖方法在确保其准确性方面的作用。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [245] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: Summit Concierge是一个为Adobe Summit开发的领域特定AI助手，通过结合提示工程、检索、人工验证和人工在循环开发流程，解决了数据稀疏、质量保证和快速部署等挑战，实现了可扩展且可靠的AI助手。


<details>
  <summary>Details</summary>
Motivation: 企业环境中，生成式AI助手在提高生产力、简化信息访问和改善用户体验方面具有巨大潜力。本文介绍了Summit Concierge，这是一个为Adobe Summit开发的领域特定AI助手。

Method: 该助手采用了结合提示工程、检索基础和轻量级人工验证的人工在循环开发流程，以应对数据稀疏、质量保证和快速部署等现实世界中的挑战。

Result: 通过敏捷、以反馈为驱动的开发，即使在冷启动场景下，也能实现可扩展且可靠的AI助手。

Conclusion: 本文描述了Summit Concierge的系统架构、开发过程和实际部署结果，强调了敏捷、反馈驱动的开发对于构建可扩展且可靠的AI助手的有效性。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [246] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）能够通过分析少量用户输入（如“大五”人格量表数据）来准确预测人类心理特征之间的相关性结构。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在仅接收少量量化输入的情况下，模拟人类心理特征相关性结构的能力。

Method: 向多种LLMs提供816名个体的“大五”人格量表数据，并要求它们模拟回答九种其他心理量表。分析LLM生成的响应与人类数据的相关性模式，并检查其推理过程。

Result: LLMs在捕捉人类心理结构方面表现出高度准确性，其生成的响应与人类数据的相关性模式高度吻合（R² > 0.89），表现优于基于语义相似度的预测，接近直接训练的机器学习算法的准确度。LLMs采用两阶段推理过程：首先将“大五”数据转化为自然语言的个性化总结（信息选择和压缩），然后基于这些总结生成目标量表的响应。

Conclusion: LLMs能够通过抽象和推理，从少量数据精确预测个体的心理特征，这为心理学模拟提供了强大工具，并揭示了LLM的涌现式推理能力。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [247] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为AAA的审计框架，通过人机协作模式将WCAG-EM方法操作化，以解决当前网站可访问性审计资源密集且扩展性差的问题。该框架包含GRASP（一种基于图的多模态采样方法）和MaC（一种基于多模态大语言模型的副驾驶），以实现可扩展的端到端可访问性审计，并辅以四个用于基准测试的新数据集。


<details>
  <summary>Details</summary>
Motivation: 当前的网站可访问性审计方法因资源消耗大且难以扩展，导致大多数网站用户界面不合规，这阻碍了数字空间的社会福利、公正和平等。WCAG-EM虽然提供了结构化方法，但需要大量人力且不适用于大规模评估。

Method: 该研究提出了AAA审计框架，其核心是人机合作模式。该框架包括GRASP，一种利用视觉、文本和关系线索的学习嵌入来实现代表性页面覆盖的图基多模态采样方法；以及MaC，一种支持审计员进行跨模态推理和智能辅助的多模态大语言模型副驾驶。

Result: 实验证明了该框架的有效性，并揭示了经过微调的小规模语言模型可以作为合格的专家。研究还贡献了四个用于审计流程核心阶段基准测试的新数据集。

Conclusion: AAA审计框架通过人机合作模式，利用GRASP采样方法和MaC副驾驶，实现了可扩展的端到端网站可访问性审计，有效解决了传统审计方法的局限性，并为该领域的研究和实践提供了新的数据集和见解。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [248] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本篇论文研究了可解释人工智能（XAI）中各种机器学习（ML）模型解释问题的参数化复杂性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决机器学习模型（特别是具有透明内部机制的模型）的解释问题的参数化复杂性，填补了XAI领域在理解生成解释的复杂性方面的空白。

Method: 本研究对包括决策树、决策集、决策列表、布尔电路及其集成在内的各种ML模型进行了分析，涵盖了局部和全局的溯因和对比解释问题。

Result: 研究结果为理解和生成这些透明ML模型的解释的复杂性提供了基础。

Conclusion: 本研究为XAI领域的研究提供了重要的见解，有助于更广泛地讨论AI系统中透明度和问责制的必要性。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [249] [Robust reduced-order model predictive control using peak-to-peak analysis of filtered signals](https://arxiv.org/abs/2511.03002)
*Johannes Köhler,Carlo Scholz,Melanie Zeilinger*

Main category: eess.SY

TL;DR: 该研究提出了一种利用降阶模型（ROM）进行大规模线性系统模型预测控制（MPC）的方法，通过预测误差边界系统来保证约束满足和鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 为解决大规模线性系统模型预测控制（MPC）的计算复杂性问题，同时保证鲁棒约束满足。

Method: 首先分析误差，然后界定峰值到峰值增益，最后利用滤波信号。在此基础上，提出一种预测（标量）误差界定系统的方法，以获得满阶系统预测输出的保证界限，并将其用于制定鲁棒的、基于ROM的MPC。

Result: 在100维质量-弹簧-阻尼器系统上进行了验证，与现有方法相比，保守性降低了四个数量级以上。

Conclusion: 所提出的基于ROM的MPC方法能够有效地处理大规模线性系统，在保证鲁棒约束满足的同时，显著提高了计算效率。

Abstract: We address the design of a model predictive control (MPC) scheme for
large-scale linear systems using reduced-order models (ROMs). Our approach uses
a ROM, leverages tools from robust control, and integrates them into an MPC
framework to achieve computational tractability with robust constraint
satisfaction. Our key contribution is a method to obtain guaranteed bounds on
the predicted outputs of the full-order system by predicting a (scalar)
error-bounding system alongside the ROM. This bound is then used to formulate a
robust ROM-based MPC that guarantees constraint satisfaction and robust
performance. Our method is developed step-by-step by (i) analysing the error,
(ii) bounding the peak-to-peak gain, an (iii) using filtered signals. We
demonstrate our method on a 100-dimensional mass-spring-damper system,
achieving over four orders of magnitude reduction in conservatism relative to
existing approaches.

</details>


### [250] [Microgrids optimal radial reconfiguration via FORWARD algorithm](https://arxiv.org/abs/2511.03059)
*Joan Vendrell Gallart,Russell Bent,Solmaz Kia*

Main category: eess.SY

TL;DR: Microgrids are complex due to decentralization, requiring solutions for NP-hard problems. This paper proposes a permutation-based iterative search method combined with the FORWARD method to efficiently find near-optimal radial network structures for microgrids, also serving as a warm-start strategy for MINLP solvers.


<details>
  <summary>Details</summary>
Motivation: Microgrids face significant energy management complexities due to their decentralized and dynamic nature, often leading to computationally intractable NP-hard problems that traditional solvers struggle to handle. This paper aims to address these complexities by developing an efficient method for resource allocation and radial configuration design.

Method: The paper proposes an abstracted problem and solves it using a permutation-based iterative search method integrated with the FORWARD method. This approach efficiently identifies feasible, near-optimal radial network structures while respecting physical constraints. Additionally, the proposed method is investigated as a warm-start strategy for benchmark MINLP solvers.

Result: The proposed method efficiently identifies feasible, near-optimal radial network structures for microgrid power distribution. It also offers a scalable solution when integrated as a warm-start strategy for MINLP solvers, improving their performance on microgrid design problems.

Conclusion: This paper presents an efficient and scalable approach for microgrid design by addressing resource allocation and radial configuration. The permutation-based iterative search method, combined with the FORWARD method, effectively handles complex MINLP problems, providing feasible and near-optimal solutions and enhancing the performance of traditional solvers.

Abstract: Microgrids offer a promising paradigm for integrating distributed energy
resources, bolstering energy resilience, and reducing the impact of blackouts.
However, their inherent decentralization and dynamic operation present
substantial energy management complexities. These complexities, including
balancing supply and demand, ensuring system stability, and minimizing
operational costs, often necessitate solving computationally intractable
NP-hard Mixed-Integer Non-Linear Programming (MINLP) problems. Traditional
MINLP solvers struggle with the scalability and feasibility guarantees required
for these challenges. To address this, this paper tackles the problem of
resource allocation and radial configuration design for microgrid power
distribution and proposes and abstracted problem which is solved by introducing
a permutation-based iterative search method over the recently introduced
FORWARD method to efficiently identify feasible, near-optimal radial network
structures while inherently respecting physical constraints. Furthermore, this
paper investigates the integration of the proposed method as a warm-start
strategy for benchmark MINLP solvers offering a scalable solution for
comprehensive microgrid design.

</details>


### [251] [Oscillation Analysis and Damping Control for a Proposed North American AC-DC Macrogrid](https://arxiv.org/abs/2511.03017)
*Kaustav Chatterjee,Sameer Nekkalapu,Antos Varghese,Marcelo Elizondo,Quan Nguyen,Xiaoyuan Fan*

Main category: eess.SY

TL;DR: 美国东西部电网互联可能引发小信号稳定问题，本文通过详细仿真模型分析了这些风险，并设计了用于抑制不稳振荡的附加阻尼控制器。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有研究中忽视的、关于北美东西部电网互联（EI和WI）为多端直流（MTDC）宏电网带来的小信号稳定问题。

Method: 开发了一个MTDC系统的自定义动态模型，并将其与包含高水平逆变器基能源的EI和WI的工业级模型相结合，通过基于模型的振荡分析来评估互联对EI和WI的区域间模式的影响，并识别阻尼不足的模式。然后，设计了利用广域反馈来调节选定换流站有功功率设定点的附加阻尼控制器，并采用频率扫描方法进行模型线性化和控制器综合。

Result: 分析表明，MTDC集成可能导致EI和WI的区域间模式发生变化，并出现阻尼不足的模式。所设计的附加阻尼控制器在所设计的运行条件和选定的意外情况下，有效地抑制了不稳振荡。

Conclusion: 通过详细的仿真模型分析，确认了北美东西部电网互联为MTDC宏电网存在小信号稳定风险，并提出了一种有效的附加阻尼控制方法来解决这些问题。

Abstract: In recent years, several studies conducted by both industry and U.S.
Department of Energy (DOE)-funded initiatives have proposed linking North
America's Eastern and Western Interconnections (EI and WI) through a
multiterminal DC (MTDC) macrogrid. These studies have explored the advantages
and opportunities of the proposed configuration from the perspectives of
capacity sharing and frequency support. However, the potential challenges of
small-signal stability arising from this interconnection have not been
thoroughly examined. To address this gap, detailed model-based simulation
studies are performed in this paper to assess the risks of poorly damped
inter-area oscillations in the proposed macrogrid. A custom-built dynamic model
of the MTDC system is developed and integrated with industry-grade models of
the EI and WI, incorporating high levels of inverter-based energy resources.
Through model-based oscillation analysis, potential shifts in inter-area modes
for both EI and WI, resulting from the MTDC integration are characterized, and
modes with inadequate damping are identified. Furthermore, to mitigate the
risks of unstable oscillations, supplementary damping controllers are designed
for the MTDC system, leveraging wide-area feedback to modulate active power set
points at selected converter stations. A frequency scanning approach is
employed for data-driven model linearization and controller synthesis. The
damping performance is evaluated under the designed operating conditions and
selected contingency scenarios.

</details>


### [252] [Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games -- Part II: Stability](https://arxiv.org/abs/2511.03297)
*Leonardo Pedroso,Andrea Agazzi,W. P. M. H. Heemels,Mauro Salazar*

Main category: eess.SY

TL;DR: 本文研究了具有大量玩家的动态博弈，玩家在连续时间内从有限集合中选择动作。玩家的状态会根据其动作随机演变，奖励不仅取决于玩家自身的状态和动作，还取决于群体中状态和动作的分布。在第一部分，我们引入了一个进化模型和一个新的解的概念——混合平稳纳什均衡（MSNE）。在第二部分，我们研究了MSNE的进化稳定性，推导了确保其在进化动力学下的局部和全局稳定性的条件，从而揭示了MSNE在大型动态博弈中长期生存能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型动态博弈中混合平稳纳什均衡（MSNE）的进化稳定性，以确定其在进化动力学下的稳健性和持久性。

Method: 推导了保证MSNE在进化动力学下局部和全局稳定性的条件，这些条件取决于MSNE的结构和博弈的支付函数。

Result: 得出了关于MSNE结构和博弈支付图的条件，这些条件确保了在进化动力学下的局部和全局稳定性。

Conclusion: MSNE在大型动态博弈中具有进化稳定性，并在满足特定条件时能够稳健地出现和持续存在。

Abstract: We study a dynamic game with a large population of players who choose actions
from a finite set in continuous time. Each player has a state in a finite state
space that evolves stochastically with their actions. A player's reward depends
not only on their own state and action but also on the distribution of states
and actions across the population, capturing effects such as congestion in
traffic networks. In Part I, we introduced an evolutionary model and a new
solution concept - the mixed stationary Nash Equilibrium (MSNE) - which
coincides with the rest points of the mean field evolutionary model under
meaningful families of revision protocols. In this second part, we investigate
the evolutionary stability of MSNE. We derive conditions on both the structure
of the MSNE and the game's payoff map that ensure local and global stability
under evolutionary dynamics. These results characterize when MSNE can robustly
emerge and persist against strategic deviations, thereby providing insight into
its long-term viability in large population dynamic games.

</details>


### [253] [Quantifying Power Systems Resilience Using Statistical Analysis and Bayesian Learning](https://arxiv.org/abs/2511.03043)
*Apsara Adhikari,Charlotte Wertz,Anamika Dubey,Arslan Ahmad,Ian Dobson*

Main category: eess.SY

TL;DR: 本研究提出一个框架，利用统计和贝叶斯学习方法量化天气参数与电力系统韧性指标之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究对系统性地模拟天气参数对电力系统韧性的影响研究不足。

Method: 利用统计和贝叶斯学习方法，结合实际的停电和天气数据，建立天气参数与电力系统韧性指标之间的量化模型。

Result: 识别出影响区域韧性指标的关键天气变量（风速、温度、降水量），并通过对美国伊利诺伊州库克县和佛罗里达州迈阿密-戴德县的案例研究，证实了这些变量在韧性分析和风险评估中的关键作用。研究还发现，这些天气变量联合作用比单独作用更具影响力。

Conclusion: 该框架为理解天气事件如何影响电力分配系统的性能提供了有价值的见解，有助于决策者制定更有效的风险缓解、资源分配和适应气候变化变化的策略。

Abstract: The increasing frequency and intensity of extreme weather events is
significantly affecting the power grid, causing large-scale outages and
impacting power system resilience. Yet limited work has been done on
systematically modeling the impacts of weather parameters to quantify
resilience. This study presents a framework using statistical and Bayesian
learning approaches to quantitatively model the relationship between weather
parameters and power system resilience metrics. By leveraging real-world
publicly available outage and weather data, we identify key weather variables
of wind speed, temperature, and precipitation influencing a particular region's
resilience metrics. A case study of Cook County, Illinois, and Miami-Dade
County, Florida, reveals that these weather parameters are critical factors in
resiliency analysis and risk assessment. Additionally, we find that these
weather variables have combined effects when studied jointly compared to their
effects in isolation. This framework provides valuable insights for
understanding how weather events affect power distribution system performance,
supporting decision-makers in developing more effective strategies for risk
mitigation, resource allocation, and adaptation to changing climatic
conditions.

</details>


### [254] [Active Noise Control Method Using Time Domain Neural Networks for Path Decoupling](https://arxiv.org/abs/2511.03162)
*Yijing Chu,Qinxuan Xiang,Sipei Zhao,Ming Wu,Y. Zhao,Guangzheng Yu*

Main category: eess.SY

TL;DR: 针对去中心化主动降噪（ANC）系统中的串扰和模型误差问题，提出一种结合固定值神经网络和自适应策略的混合方法（DecNet-LMS），通过在线建模和神经网络进行路径反转与解耦，有效提升了控制精度和性能。


<details>
  <summary>Details</summary>
Motivation: 去中心化主动降噪（ANC）系统中，多通道二次声源和误差传声器之间的串扰会严重影响控制精度，而滤波（Fx）类算法中的预滤波可能引入额外的模型误差。

Method: 提出一种混合方法，结合固定值神经网络（DecNet）和自适应策略（LMS）。LMS算法用于在线建模自身通道的通路，神经网络（DecNet）用于二次通道的反转和解耦。该混合算法在时域实现以保证因果性并避免延迟。

Result: 仿真结果表明，在不同声学条件下，所提出的混合DecNet-LMS算法优于使用传统自适应滤波器或基于神经网络的固定系数方法的现有ANC算法。

Conclusion: 所提出的混合DecNet-LMS算法能够有效解决去中心化ANC系统中的串扰和模型误差问题，在实际应用中具有优越的性能。

Abstract: In decentralized active noise control (ANC) systems, crosstalk between
multichannel secondary sources and error microphones significantly degrades
control accuracy. Moreover, prefiltering reference signals in filtered-x (Fx)
type algorithms may further introduce modeling errors. A theoretical analysis
of the Fx-based decentralized control algorithm was performed, which reveals
how prefiltering and crosstalk affect the control performance. Then, a hybrid
method combining fixed-value neural networks and adaptive strategies was
proposed for efficient decentralized ANC. The adaptive filter models the
primary path of its own channel online using the least mean square (LMS)
algorithm while the neural network (named DecNet) is used for secondary paths
inverting and decoupling. The hybrid DecNet-LMS algorithm was implemented in
the time domain to guarantee causality and avoid latency. Simulation results
with measured acoustic paths show that the proposed method outperforms the
existing ANC algorithms using either traditional adaptive filters or neural
network-based fixed-coefficient methods under different acoustic conditions.

</details>


### [255] [MHE in Output Feedback Control of Uncertain Nonlinear Systems via IQCs](https://arxiv.org/abs/2511.03221)
*Yang Guo,Stefan Streif*

Main category: eess.SY

TL;DR: 提出一种用于处理具有不确定性的非线性约束系统的移动视界估计（MHE）方案。


<details>
  <summary>Details</summary>
Motivation: 为具有参数或静态非线性不确定性的一般非线性约束系统，以及一个假定在无估计误差时能鲁棒稳定系统的预定状态反馈控制器，提出一种移动视界估计（MHE）方案。

Method: 利用积分二次约束（IQCs）来处理可能存在的非参数不确定性，并引入一种新的可检测性概念。在此基础上，提出一种MHE方法。

Result: 证明了当不确定的系统由控制器驱动并满足新的可检测性概念时，所提出的MHE形式化方法可以使闭环系统（包括不确定的系统、控制器和MHE）相对于外部干扰是输入状态稳定的。

Conclusion: 所提出的MHE方案能够鲁棒地处理具有不确定性的非线性约束系统，并保证闭环系统的稳定性。

Abstract: We propose a moving horizon estimation (MHE) scheme for general nonlinear
constrained systems with parametric or static nonlinear uncertainties and a
predetermined state feedback controller that is assumed to robustly stabilize
the system in the absence of estimation errors. Leveraging integral quadratic
constraints (IQCs), we introduce a new notion of detectability that is robust
to possibly non-parametric uncertainties and verifiable in practice. Assuming
that the uncertain system driven by the controller satisfies this notion of
detectability, we provide an MHE formulation such that the closed-loop system
formed of the uncertain system, the controller and MHE is input-to-state stable
w.r.t. exogenous disturbances.

</details>


### [256] [Theoretical and Experimental Limitations of RoCoF Estimation](https://arxiv.org/abs/2511.03249)
*Gutierrez-Florensa,F. Sanniti,D. Tedeschi,L. Sigrist,A. Ortega,F. Milano*

Main category: eess.SY

TL;DR: A robust approach based on differential geometry and fluid mechanics is proposed for precise Rate of Change of Frequency (RoCoF) estimation in power systems, addressing challenges posed by modern low-inertia grids and enabling faster protection schemes.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity and reduced precision of RoCoF estimation in modern low-inertia power systems necessitates a more robust approach for secure operation and effective protection.

Method: The paper proposes a numerically robust approach inspired by differential geometry and fluid mechanics for RoCoF estimation. This method is tested with real-world experimental measurements and integrated into a faster RoCoF-based Under Frequency Load Shedding (UFLS) control scheme.

Result: The proposed approach demonstrates improved precision in RoCoF estimation, even in challenging low-inertia grid conditions. It also facilitates the development of faster control logic for protection systems, such as UFLS, by providing information about the nature of the contingency.

Conclusion: The proposed differential geometry and fluid mechanics-based method offers a precise and robust solution for RoCoF estimation in modern power systems, enhancing the performance of protection systems like UFLS and contributing to secure power system operation.

Abstract: A precise estimation of the Rate of Change of Frequency (RoCoF) is crucial
for secure power system operation. In fact, RoCoF is strictly related to the
amount of the available physical and/or virtual inertia of the system and the
severity of the active power unbalance following a disturbance. For this
reason, it is widely exploited in different protection systems, e.g.,
Anti-Islanding, Under Frequency Load Shedding (UFLS) and wide-area protection
systems. The new paradigm of modern power systems, with a low-inertia and
converter-based generation assets, is increasing the transient severity, making
the frequency and the RoCoF estimation more complex and less precise for the
actual devices. This work addresses this issue by proposing a numerically
robust approach based on concepts inherited from differential geometry and
fluid mechanics. The proposed approach is then tested with high-sampling real
experimental measurements and used to develop a faster control logic for a
RoCoF-based UFLS control scheme. The proposed approach provides information to
protections regarding the nature of the contingency which can be used to
improve its response.

</details>


### [257] [Lightwave Power Transfer-Enabled Underwater Optical ISAC Systems under Ship Attitude Variation](https://arxiv.org/abs/2511.03366)
*Kapila W. S. Palitharathna,Constantinos Psomas,Ioannis Krikidis*

Main category: eess.SY

TL;DR: 该论文提出了一种利用光波能量传输的水下光集成传感与通信（O-ISAC）系统，其中海面船上的接入点（AP）向海底传感器和传感目标传输信号。海底传感器收集能量并传输上行信息，而传感目标的 Posi tion 由AP估计。


<details>
  <summary>Details</summary>
Motivation: 为了在水下环境中实现传感和通信的集成，并考虑实际部署条件，如船体姿态变化。

Method: 建模船体姿态变化（俯仰、横滚、偏航），推导目标定位的均方误差（MSE）和可达上行数据率的闭式近似。

Result: 分析和仿真结果表明模型和推导表达式是有效的，揭示了O-ISAC系统的通信-传感权衡。

Conclusion: 研究为O-ISAC系统的设计提供了宝贵的见解，包括最小化定位误差的最佳摄像头放置策略（在10°姿态变化下可达10^-2 m^2的最小MSE）和最佳的能量收集-使用比（0.55）。

Abstract: In this paper, we propose a lightwave power transfer-enabled underwater
optical integrated sensing and communication (O-ISAC) system, where an access
point (AP) mounted on a seasurface ship transmits lightwave signals to two
nodes, namely ($i$) a seabed sensor that harvests energy and transmits uplink
information to the AP, and ($ii$) a sensing target whose position is estimated
by the AP using an array of pinhole cameras. To capture practical deployment
conditions, the ship attitude variation is modeled through its roll, pitch, and
yaw angles, each following a Gaussian distribution under low-to-moderate sea
states. Closed-form approximations are derived for the mean squared error (MSE)
of target localization and the achievable uplink data rate. Analytical and
simulation results demonstrate excellent agreement, validating the proposed
models and derived expressions, while revealing the fundamental
communication-sensing tradeoff in the O-ISAC system. The results further
provide valuable design insights, including the optimal camera placement on the
ship to minimize localization error, achieving a minimum MSE of $10^{-2}$
$\text{m}^2$ with multiple cameras under roll, pitch, and yaw angle variation
of $10^{\circ}$, and the optimal harvest-use ratio of $0.55$ for the considered
setup.

</details>


### [258] [A Digital Twin of Evaporative Thermo-Fluidic Process in Fixation Unit of DoD Inkjet Printers](https://arxiv.org/abs/2511.03379)
*Samarth Toolhally,Joeri Roelofs,Siep Weiland,Amritam Das*

Main category: eess.SY

TL;DR: 本文提出了一个用于喷墨打印固化单元的数字孪生模型，能够监测时空性能，并通过状态估计来推断固化状态。


<details>
  <summary>Details</summary>
Motivation: 为了在喷墨打印中优化纸张水分，从而提高打印质量，需要对固化单元进行精确控制。本文旨在通过数字孪生技术实现对固化单元热-流体干燥过程的建模与监测。

Method: 本文提出了一种新颖的数字孪生方法，将固化单元建模为一个无限维状态估计器。该模型利用图论构建模块化模型，将热-流体动力学表示为节点，并通过线性分数表示耦合蒸发等非线性边界效应。使用偏积分方程（PIE）框架进行稳定性、输入-输出分析、仿真和快速原型设计。最后，合成了一个$	ext{H}_{	ext{infty}}$最优Luenberger状态估计器，用于从传感器数据估计热状态。

Result: 该数字孪生模型能够从有限的传感器数据中推断出固化状态，并能有效应对干扰。通过PIE框架和$	ext{H}_{	ext{infty}}$最优Luenberger状态估计器的结合，实现了对喷墨打印纸张时空热效应的实时监测，并通过商业打印机的运行数据进行了验证。

Conclusion: 本文提出的数字孪生方法为喷墨打印固化单元提供了一种有效的建模、状态估计和实时监测解决方案，有望提高打印质量和过程控制的精度。

Abstract: In inkjet printing, optimal paper moisture is crucial for print quality,
achieved through hot-air impingement in the fixation unit. This paper presents
a modular digital twin of the fixation unit, modeling the thermo-fluidic drying
process and monitoring its spatio-temporal performance. The novel approach
formulates the digital twin as an infinite-dimensional state estimator that
infers fixation states from limited sensor data, while remaining robust to
disturbances. Modularity is achieved through a graph-theoretic model, where
each node represents thermo-fluidic dynamics in different sections of the
fixation unit. Evaporation is modeled as a nonlinear boundary effect coupled
with node dynamics via Linear Fractional Representation. Using the Partial
Integral Equation (PIE) framework, we develop a unified approach for stability,
input-output analysis, simulation, and rapid prototyping, validated with
operational data from a commercial printer. An $\mathcal{H}_{\infty}$-optimal
Luenberger state estimator is then synthesized to estimate thermal states from
available sensor data, enabling real-time monitoring of spatio-temporal thermal
effects on paper sheets.

</details>


### [259] [Maximum Likelihood Estimation of Dynamic Sub-Networks with Missing Data](https://arxiv.org/abs/2511.03391)
*João Victor Galvão da Mata,Anders Hansson,Martin S. Andersen*

Main category: eess.SY

TL;DR: 该研究提出了一种最大似然估计方法，用于识别复杂网络中的子网络，无需估计整个网络，通过仅使用局部测量和分离子网络来降低计算复杂性并增强隐私。


<details>
  <summary>Details</summary>
Motivation: 直接应用最大似然估计法识别大型网络存在计算成本过高的问题。

Method: 提出一种最大似然估计方法，仅使用目标子网络内部以及与之直接相连的分离子网络的局部测量数据来估计子网络的参数，以解决计算复杂性问题。

Result: 通过数值示例证明了该方法的有效性，并建立了网络可分离性的理论条件。

Conclusion: 该方法能够有效识别复杂网络中的子网络，显著降低计算复杂度，并能通过仅使用局部数据来保护隐私。

Abstract: Maximum likelihood estimation is effective for identifying dynamical systems,
but applying it to large networks becomes computationally prohibitive. This
paper introduces a maximum likelihood estimation method that enables
identification of sub-networks within complex interconnected systems without
estimating the entire network. The key insight is that under specific
topological conditions, a sub-network's parameters can be estimated using only
local measurements: signals within the target sub-network and those in the
directly connected to the so-called separator sub-network. This approach
significantly reduces computational complexity while enhancing privacy by
eliminating the need to share sensitive internal data across organizational
boundaries. We establish theoretical conditions for network separability,
derive the probability density function for the sub-network, and demonstrate
the method's effectiveness through numerical examples.

</details>


### [260] [An Alternative Derivation and Optimal Design Method of the Generalized Bilinear Transformation for Discretizing Analog Systems](https://arxiv.org/abs/2511.03403)
*Shen Chen,Yanlong Li,Jiamin Cui,Wei Yao,Jisong Wang,Yixin Tian,Chaohou Liu,Yang Yang,Jiaxi Ying,Zeng Liu,Jinjun Liu*

Main category: eess.SY

TL;DR: GBT是一种通用的双线性变换，本文提出了一种基于六边形逼近的GBT推导方法，并定义了形状因子α，揭示了其物理意义，确定了其稳定范围，并提出了基于幅值或相位误差的优化设计方法，最后通过低通滤波器验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的从连续时间域到离散时间域的转换方法（如欧拉法、Tustin法）存在对参数α的物理意义和最优设计方法研究不足的问题。

Method: 提出一种新的六边形逼近误差函数面积的方法来推导GBT，并定义参数α为形状因子，揭示了其物理意义（等于所提出六边形形状的后向矩形比率），确定了形状因子的稳定范围为[0.5, 1]，并提出了基于归一化幅值或相位误差的目标函数来优化设计形状因子。

Result: 观察到两种不同的失真模式（幅值失真和相位失真），并提出了一种基于归一化幅值或相位误差的目标函数来优化设计形状因子。通过设计和测试一个低通滤波器（LPF），将理论计算与实验结果进行比较，验证了所提出方法的有效性。

Conclusion: 本文提出了一种新的GBT推导方法，并首次揭示了其形状因子α的物理意义，确定了其稳定范围，并提出了一种优化设计方法。通过低通滤波器的设计和实验验证了该方法的有效性。

Abstract: A popular method for designing digital systems is transforming the transfer
function of the corresponding analog systems from the continuous-time domain
(s-domain) into the discrete-time domain (z-domain) using the Euler or Tustin
method. We demonstrate that these transformations are two specific forms of the
Generalized Bilinear Transformation (GBT) with a design parameter, $\alpha$.
However, the physical meaning and optimal design method for this parameter are
not sufficiently studied. In this paper, we propose an alternative derivation
of the GBT derived by employing a new hexagonal shape to approximate the
enclosed area of the error function, and we define the parameter $\alpha$ as
the shape factor. The physical meaning of the shape factor is firstly revealed,
which equals to the percentage of the backward rectangular ratio of the
proposed hexagonal shape. We demonstrate that the stable range of the shape
factor is [0.5, 1] through domain mapping. Depending on the operating
frequencies and the shape factor, we observe two distinct distortion modes,
i.e., the magnitude and phase distortion. We proceed to develop an optimal
design method for the shape factor based on an objective function in form of
the normalized magnitude or phase error. Finally, a low-pass filter (LPF) is
designed and tested to verify the effectiveness of the proposed method by
comparing the theoretical calculations with the experimental results.

</details>


### [261] [System Identification of a Moored ASV with Recessed Moon Pool via Deterministic and Bayesian Hankel-DMDc](https://arxiv.org/abs/2511.03482)
*Giorgio Palma,Ivan Santic,Andrea Serani,Lorenzo Minno,Matteo Diez*

Main category: eess.SY

TL;DR: 本研究利用HDMDc及其贝叶斯扩展BHDMDc对系泊状态下的小型自主水面航行器（ASV）进行系统辨识。


<details>
  <summary>Details</summary>
Motivation: ASV的月池设计引起了非线性响应，增加了建模难度。

Method: 使用HDMDc和BHDMDc从测量数据中构建数据驱动的降阶模型。

Result: HDMDc能够准确预测船舶动力学，BHDMDc能够进行不确定性量化的模型响应表征。两种方法都能预测船舶对未见过的波浪的响应。

Conclusion: HDMDc-基线降阶模型是系统辨识的一种可行的数据驱动替代方法，首次证明了其对不同于训练集的工况的泛化能力，并能高精度地重现船舶动力学。

Abstract: This study addresses the system identification of a small autonomous surface
vehicle (ASV) under moored conditions using Hankel dynamic mode decomposition
with control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were
carried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under
both irregular and regular head-sea wave conditions. The ASV under
investigation features a recessed moon pool, which induces nonlinear responses
due to sloshing, thereby increasing the modelling challenge. Data-driven
reduced-order models were built from measurements of vessel motions and mooring
loads. The HDMDc framework provided accurate deterministic predictions of
vessel dynamics, while the Bayesian formulation enabled uncertainty-aware
characterization of the model response by accounting for variability in
hyperparameter selection. Validation against experimental data demonstrated
that both HDMDc and BHDMDc can predict the vessel's response to unseen regular
and irregular wave excitations. In conclusion, the study shows that HDMDc-based
ROMs are a viable data-driven alternative for system identification,
demonstrating for the first time their generalization capability for a sea
condition different from the training set, achieving high accuracy in
reproducing vessel dynamics.

</details>


### [262] [Data-driven Modeling of Grid-following Control in Grid-connected Converters](https://arxiv.org/abs/2511.03494)
*Amir Bahador Javadi,Philip Pong*

Main category: eess.SY

TL;DR: As power systems become more complex with renewables and smart grids, accurate modeling is crucial. This study evaluates data-driven methods like sparse identification and deep symbolic regression using a synthetic grid model with a converter-based resource to capture system dynamics.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of power systems due to renewable energy integration and smart grid technologies necessitates flexible and scalable modeling approaches for accurate dynamic capture.

Method: A synthetic dataset was generated using a grid model featuring a converter-based resource replacing a traditional generator connected to a lossless transmission line and an infinite bus system, operating in a grid-following control mode. This data was used to evaluate data-driven methods like sparse identification of nonlinear dynamics and deep symbolic regression.

Result: The study's results, though not detailed in the abstract, focus on evaluating the effectiveness of data-driven methods in capturing the dynamics of the described power system model.

Conclusion: The paper aims to demonstrate the viability of data-driven techniques for modeling complex power system dynamics, specifically in the context of modern grids with converter-based resources.

Abstract: As power systems evolve with the integration of renewable energy sources and
the implementation of smart grid technologies, there is an increasing need for
flexible and scalable modeling approaches capable of accurately capturing the
complex dynamics of modern grids. To meet this need, various methods, such as
the sparse identification of nonlinear dynamics and deep symbolic regression,
have been developed to identify dynamical systems directly from data. In this
study, we examine the application of a converter-based resource as a
replacement for a traditional generator within a lossless transmission line
linked to an infinite bus system. This setup is used to generate synthetic data
in grid-following control mode, enabling the evaluation of these methods in
effectively capturing system dynamics.

</details>


### [263] [Powered Descent Trajectory Optimization of Chandrayaan-3 using Radau Collocation and Controllable Sets](https://arxiv.org/abs/2511.03594)
*Suraj Kumar,Aditya Rallapalli,Ashok Kumar Kakula,Bharat Kumar GVP*

Main category: eess.SY

TL;DR: 印度Chandrayaan-3任务成功实现月球软着陆，本文设计了其动力下降轨迹，采用伪谱Radau配置优化和基于可控性的航点优化，量化了燃料消耗与鲁棒性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 实现 Chandrayaan-3 任务的软着陆。

Method: 采用伪谱Radau配置优化和基于可控性的航点优化来设计动力下降轨迹。

Result: 设计了 Chandrayaan-3 任务的动力下降轨迹。

Conclusion: 所提出的轨迹设计方法能够实现鲁棒的月球软着陆，并在燃料消耗和鲁棒性之间进行权衡。

Abstract: India achieved a significant milestone on August $23^{\text{rd}}$ 2023,
becoming the fourth country to accomplish a soft landing on the Moon. This
paper presents the powered descent trajectory design for the Chandrayaan-3
mission. The optimization framework is based on pseudospectral Radau
collocation, and controllability-based waypoint refinement is employed to
further enhance the robustness of the trajectory against state and control
perturbations. Furthermore, the trade-off between fuel consumption and
robustness is explicitly quantified, providing insights into the practical
considerations of mission planning.

</details>


### [264] [Artificial-reference tracking MPC with probabilistically validated performance on industrial embedded systems](https://arxiv.org/abs/2511.03603)
*Victor Gracia,Pablo Krupa,Filiberto Fele,Teodoro Alamo*

Main category: eess.SY

TL;DR: 本文提出了一种在计算资源有限的工业嵌入式系统上高效实现模型预测控制（MPC）的方法，该方法利用一种新的结构-利用一阶方法来解决，并加入了实际应用中重要的功能，如无偏估计、约束收紧和软约束，同时还提供了概率性能验证框架。


<details>
  <summary>Details</summary>
Motivation: 工业嵌入式系统通常计算资源有限，难以实现高级控制算法。尽管如此，控制界仍在探索MPC在这些系统上的应用，但通常采用简化形式（线性或显式），这可能在实际环境中缺乏所需特性。因此，需要一种能够满足实际应用需求且计算成本可控的嵌入式MPC实现方法。

Method: 本文提出了一种利用最近开发的结构-利用一阶方法来解决的MPC实现方案。该方法通过集成无偏估计方案、允许约束收紧的后退参数以及在扰动或模型失配下保持可行性的软约束等实用功能，为嵌入式系统量身定制。此外，还提供了一个用于对闭环系统进行长期运行概率性能验证的框架。

Result: 该方法在可编程逻辑控制器（PLC）上进行了演示，并结合硬件在环（HIL）设置控制了一个非线性连续搅拌罐反应器。通过概率验证了闭环系统在约束违规和MPC优化算法每时间步所需迭代次数方面的行为。

Conclusion: 本文提出了一种在计算资源受限的工业嵌入式系统上高效实现包含多种实用功能的模型预测控制（MPC）的方法，并通过实验验证了其有效性和鲁棒性。

Abstract: Industrial embedded systems are typically used to execute simple control
algorithms due to their low computational resources. Despite these limitations,
the implementation of advanced control techniques such as Model Predictive
Control (MPC) has been explored by the control community in recent years,
typically considering simple linear formulations or explicit ones to facilitate
the online computation of the control input. These simplifications often lack
features and properties that are desirable in real-world environments. In this
article, we present an efficient implementation for embedded systems of MPC for
tracking with artificial reference, solved via a recently developed
structure-exploiting first-order method. This formulation is tailored to a wide
range of applications by incorporating essential practical features at a small
computational cost, including integration with an offset-free scheme, back-off
parameters that enable constraint tightening, and soft constraints that
preserve feasibility under disturbances or plant-model mismatch. We accompany
this with a framework for probabilistic performance validation of the
closed-loop system over long-term operation. We illustrate the applicability of
the approach on a Programmable Logic Controller (PLC), incorporated in a
hardware-in-the-loop setup to control a nonlinear continuous stirred-tank
reactor. The behavior of the closed-loop system is probabilistically validated
with respect to constraint violations and the number of iterations required at
each time step by the MPC optimization algorithm.

</details>


### [265] [A Constant-Gain Equation-Error Framework for Airliner Aerodynamic Monitoring Using QAR Data](https://arxiv.org/abs/2511.03678)
*Ruiying Wen,Yuntao Dai,Hongyong Wang*

Main category: eess.SY

TL;DR: 该研究提出了一种恒定增益方程误差法（CG-EEM）来解决使用 QAR 数据监测飞机在役气动性能的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的状态传播滤波器和标准的递归估计器在分析 QAR 数据时存在局限性，无法准确监测飞机在役气动性能，特别是由于关键参数（如飞机转动惯量）的缺失以及在低激励巡航数据上表现出的过早收敛或不稳定性。

Method: 提出并验证了恒定增益方程误差法（CG-EEM），采用具有恒定、类似卡尔曼增益的自定义估计器，以应对巡航飞行中信号噪声比较低且激励不足的特点。

Result: CG-EEM 在包含 200 多个航班的大型多机队数据集上进行了广泛验证，结果显示该方法能够生成高度一致、符合物理规律的气动参数，并能准确识别不同飞机类型之间的性能差异。

Conclusion: CG-EEM 是一种稳健、可扩展且计算效率高的工具，可用于机队范围的性能监测和性能退化的早期检测。

Abstract: Monitoring the in-service aerodynamic performance of airliners is critical
for operational efficiency and safety, but using operational Quick Access
Recorder (QAR) data for this purpose presents significant challenges. This
paper first establishes that the absence of key parameters, particularly
aircraft moments of inertia, makes conventional state-propagation filters
fundamentally unsuitable for this application. This limitation necessitates a
decoupled, Equation-Error Method (EEM). However, we then demonstrate through a
comparative analysis that standard recursive estimators with time-varying
gains, such as Recursive Least Squares (RLS), also fail within an EEM
framework, exhibiting premature convergence or instability when applied to
low-excitation cruise data. To overcome these dual challenges, we propose and
validate the Constant-Gain Equation-Error Method (CG-EEM). This framework
employs a custom estimator with a constant, Kalman-like gain, which is
perfectly suited to the stationary, low-signal-to-noise characteristics of
cruise flight. The CG-EEM is extensively validated on a large, multi-fleet
dataset of over 200 flights, where it produces highly consistent, physically
plausible aerodynamic parameters and correctly identifies known performance
differences between aircraft types. The result is a robust, scalable, and
computationally efficient tool for fleet-wide performance monitoring and the
early detection of performance degradation.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [266] [Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project](https://arxiv.org/abs/2511.03029)
*Kajol Kulkarni,Samuel Kemmler,Anna Schwarz,Gulcin Gedik,Yanxiang Chen,Dimitrios Papageorgiou,Ioannis Kavroulakis,Roman Iakymchuk*

Main category: cs.DC

TL;DR: CEEC通过案例研究评估了欧洲主要HPC系统上CFD应用的能源消耗和解决方案时间，强调了加速器和混合精度技术在提高能源效率方面的优势，并呼吁促进HPC系统的能源测量以实现可持续的计算。


<details>
  <summary>Details</summary>
Motivation: 现代高性能计算（HPC）系统面临着能源效率的挑战，因为不断增长的计算需求和复杂的架构导致了显著的能源消耗。

Method: 本文介绍了欧洲HPC JU Exascale CFD（CEEC）卓越中心在测量、分析和优化欧洲主要HPC系统能源消耗方面的集体经验。文章简要回顾了能源测量的关键方法和工具，并定义了结果报告的指标。通过使用代表性的CFD应用程序（waLBerla、FLEXI/GALAEXI、Neko和NekRS）的案例研究，评估了在CPU和GPU架构（包括LUMI、MareNostrum5、MeluXina和JUWELS Booster）上 the energy-to-solution 和 time-to-solution 指标。

Result: 研究结果表明，利用加速器和混合精度技术可以降低能源消耗，同时保持计算精度。

Conclusion: 为了提高人们的认识、教育社区并采取行动以实现更可持续的超级计算，有必要促进HPC系统的能源测量。

Abstract: Energy efficiency has emerged as a central challenge for modern
high-performance computing (HPC) systems, where escalating computational
demands and architectural complexity have led to significant energy footprints.
This paper presents the collective experience of the EuroHPC JU Center of
Excellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing
energy consumption across major European HPC systems. We briefly review key
methodologies and tools for energy measurement as well as define metrics for
reporting results. Through case studies using representative CFD applications
(waLBerla, FLEXI/GAL{\AE}XI, Neko, and NekRS), we evaluate energy-to-solution
and time-to-solution metrics on diverse architectures, including CPU- and
GPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our
results highlight the advantages of accelerators and mixed-precision techniques
for reducing energy consumption while maintaining computational accuracy.
Finally, we advocate the need to facilitate energy measurements on HPC systems
in order to raise awareness, teach the community, and take actions toward more
sustainable exascale computing.

</details>


### [267] [Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots](https://arxiv.org/abs/2511.03286)
*Ehud Shapiro*

Main category: cs.DC

TL;DR: 全局数字平台可以通过根据其基本代理的数量分为四类：集中式、分散式、联邦式和基层式。


<details>
  <summary>Details</summary>
Motivation: 研究和形式化地分类全局数字平台。

Method: 提出基于原子事务的多智能体转换系统和协议作为形式框架，识别基本智能体，并根据基本智能体的数量对平台进行分类。

Result: 将全局平台分为四类：集中式（1 个基本智能体）、分散式（有限的 >1 个基本智能体）、联邦式（无限但非通用的基本智能体）和基层式（所有智能体都是基本智能体）。为全局社交网络提供了这四种类型的具体示例。

Conclusion: 该研究首次为全局数字平台提供了一个数学框架，能够根据其基本智能体的数量对其进行分类。

Abstract: Global digital platforms are software systems designed to serve entire
populations, with some already serving billions of people. We propose atomic
transactions-based multiagent transition systems and protocols as a formal
framework to study them; introduce essential agents -- minimal sets of agents
the removal of which makes communication impossible; and show that the
cardinality of essential agents partitions all global platforms into four
classes:
  1. Centralised -- one (the server)
  2. Decentralised -- finite $>1$ (bootstrap nodes)
  3. Federated -- infinite but not universal (all servers)
  4. Grassroots -- universal (all agents)
  Our illustrative formal example is a global social network, for which we
provide centralised, decentralised, federated, and grassroots specifications
via multiagent atomic transactions, and prove they satisfy basic correctness
properties. We discuss informally additional global platforms -- currencies,
``sharing economy'' apps, AI, and more. While this may be the first
characterisation of centralised, decentralised, and federated global platforms,
grassroots platforms have been formally defined previously, but using different
notions. Here, we prove that their original definition implies that all agents
are essential, placing grassroots platforms in a distinct class within the
broader formal context that includes all global platforms. This work provides
the first mathematical framework for classifying any global platform --
existing or imagined -- by providing a multiagent atomic-transactions
specification of it and determining the cardinality of the minimal set of
essential agents in the ensuing multiagent protocol. It thus

</details>


### [268] [UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM](https://arxiv.org/abs/2511.03293)
*Hai Huang,Xuhong Qiang,Weisheng Zhao,Chenchen Liu*

Main category: cs.DC

TL;DR: UMDAM是一种针对NPU-PIM协同执行的统一内存亲和数据布局和DRAM地址映射方案，可显著提高LLM在边缘设备上的推理效率。


<details>
  <summary>Details</summary>
Motivation: LLM在边缘设备上部署时，内存消耗大的解码阶段限制了其性能。处理内存（PIM）是一种有前景的解决方案，但NPU-PIM协同执行面临数据布局不匹配、带宽损失和存储冗余等挑战。

Method: UMDAM采用列主序、基于块的布局和可配置的DRAM映射策略，以确保与NPU计算的兼容性，同时最大限度地提高PIM效率，且无额外内存开销或带宽损失。

Result: 在OPT模型上的评估显示，UMDAM将首个标记生成时间（TTFT）缩短了高达3.0倍，最后一个标记生成时间（TTLT）缩短了2.18倍。

Conclusion: UMDAM显著提高了边缘设备上LLM端到端推理的效率。

Abstract: Large Language Models (LLMs) are increasingly deployed on edge devices with
Neural Processing Units (NPUs), yet the decode phase remains memory-intensive,
limiting performance. Processing-in-Memory (PIM) offers a promising solution,
but co-executing NPU-PIM systems face challenges such as data layout
mismatches, bandwidth loss, and redundant storage. To address these issues, we
propose UMDAM, a unified memory-affinity data layout and DRAM address mapping
scheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,
tile-based layout and a configurable DRAM mapping strategy to ensure
compatibility with NPU computation while maximizing PIM efficiency -- without
introducing extra memory overhead or bandwidth loss. Comprehensive evaluations
on OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up
to 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving
end-to-end LLM inference efficiency on edge devices.

</details>


### [269] [Investigating the Impact of Isolation on Synchronized Benchmarks](https://arxiv.org/abs/2511.03533)
*Nils Japke,Furat Hamdan,Diana Baumann,David Bermbach*

Main category: cs.DC

TL;DR: 该研究评估了三种隔离策略（cgroups/CPU pinning、Docker 容器和 Firecracker MicroVMs）在云环境基准测试中的有效性，以解决多租户资源争用的问题。


<details>
  <summary>Details</summary>
Motivation: 云环境中的基准测试受到多租户资源争用的影响，导致性能不稳定。Duet 基准测试通过并发运行两个工作负载版本来缓解此问题，但需要额外的隔离机制来处理同步工作负载之间的虚拟机内部争用。

Method: 通过运行带有噪声生成器的 Duet 设置来评估三种隔离策略（cgroups/CPU pinning、Docker 容器和 Firecracker MicroVMs）与无隔离基线的对比。噪声生成器会窃取计算资源以降低性能。

Result: 所有实验都显示出不同的延迟分布。进程隔离通常会减少误报，但 Docker 容器除外，它们更容易受到噪声的影响。

Conclusion: 建议在同步工作负载中使用进程隔离，但 Docker 容器除外。

Abstract: Benchmarking in cloud environments suffers from performance variability from
multi-tenant resource contention. Duet benchmarking mitigates this by running
two workload versions concurrently on the same VM, exposing them to identical
external interference. However, intra-VM contention between synchronized
workloads necessitates additional isolation mechanisms.
  This work evaluates three such strategies: cgroups and CPU pinning, Docker
containers, and Firecracker MicroVMs. We compare all strategies with an
unisolated baseline experiment, by running benchmarks with a duet setup
alongside a noise generator. This noise generator "steals" compute resources to
degrade performance measurements.
  All experiments showed different latency distributions while under the
effects of noise generation, but results show that process isolation generally
lowered false positives, except for our experiments with Docker containers.
Even though Docker containers rely internally on cgroups and CPU pinning, they
were more susceptible to performance degradation due to noise influence.
Therefore, we recommend to use process isolation for synchronized workloads,
with the exception of Docker containers.

</details>


### [270] [Stone Duality Proofs for Colorless Distributed Computability Theorems](https://arxiv.org/abs/2511.03609)
*Cameron Calk,Emmanuel Godard*

Main category: cs.DC

TL;DR: 该论文提出了一种新的拓扑编码方法，通过回合制全信息敌手（一种分布式计算模型）的执行光谱空间来统一分布式计算中的拓扑方法。研究结果为无色任务在紧凑敌手模型下的可解性提供了表征，并利用Stone对偶性推导出一个通用的分布式可计算性定理，该定理能够统一许多已知的无色可计算性定理，并为彩色和无色模型具有相同的可计算能力提供了拓扑解释。


<details>
  <summary>Details</summary>
Motivation: 统一分布式计算中的拓扑方法，并为无色任务在紧凑敌手模型下的可解性提供表征。

Method: 提出了一种新的拓扑编码，将分布式协议的全局状态视为光谱空间（具有Alexandrov拓扑的面的偏序集），而不是抽象单纯复形。定义了一个极限对象$\\\Pi^\\infty_\\mathcal M(\\'I)\\'$，并通过Stone对偶性推导出可计算性定理。

Result: 推导出一个通用的分布式可计算性定理：当且仅当存在一个谱图映射$f:\\Pi^\\infty_\\mathcal M(\\'I)\\\longrightarrow\\mathcal O$，该映射与$\\'△\\'$兼容时，才能在紧凑敌手$\\'\\mathcal M(\\'I)\\'$下解决一个无色任务$(\\'I, \\'O, \\'△)\\'$。该定理统一了许多已知的无色可计算性定理，并提供了彩色和无色模型可计算能力等价的拓扑解释。

Conclusion: 该研究通过引入执行光谱空间和利用Stone对偶性，为分布式计算中的拓扑方法提供了一个统一的框架，并得到了一个通用的可计算性定理，该定理能够推导出许多已知的具体结果，并从拓扑角度解释了彩色和无色模型在可计算性上的等价性。

Abstract: We introduce a new topological encoding by spectral spaces of executions of
  round-based full-information adversaries, a model of distributed computations
that is functorially presented and that
  contains many message adversaries. We give a characterization of the
solvability of colorless tasks against compact adversaries.
  Message adversaries are distributed
  models that are known to be very expressive despite being
  round-based and crash-free. Colorless tasks are
  an important class of distributed tasks. For a colorless task, the
  specification does not depend upon the multiplicity of input or
  output values, like the ubiquitous agreement tasks.
  Therefore, our result is a significant
  step toward unifying topological methods in distributed computing.
  The main insight is to consider global states obtained after finite
executions of a distributed protocol
  not as abstract
  simplicial complexes as previously done, but as spectral
  spaces, considering the Alexandrov topology on the faces poset. Given
  an adversary $\mathcal M$ with a set of inputs $\mathcal I$,
  we define a limit object $\Pi^\infty_\mathcal M(\mathcal I)$
  by projective limit in the category of spectral spaces. We derive a new
general distributed computability
  theorem using Stone duality: there exists an algorithm solving a colorless
task $(\mathcal I,\mathcal O,\Delta)$
  against the compact adversary $\mathcal M$ if and only if there exists a
spectral
  map $f:\Pi^\infty_\mathcal M(\mathcal I)\longrightarrow\mathcal O$ compatible
with $\Delta$.
  From this general characterization are derived many known colorless
computability
  theorems.
  Quite surprisingly, colored and uncolored models have the same
  computability power (they solve the same tasks). Our new proofs give
  topological reasons for this equivalence, previously known through
  algorithmic reductions.

</details>


### [271] [A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries](https://arxiv.org/abs/2511.03662)
*Yannis Coutouly,Emmanuel Godard*

Main category: cs.DC

TL;DR: 该论文将分布式计算任务的可解性研究扩展到输入相关和基于条件的对手模型，并为k-集合协议提供了一个充分必要的条件。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是将先前关于无色任务在迭代即时快照（IIS）模型上的可解性表征，推广到更广泛的对手模型，特别是输入相关对手和基于条件的对手，并为k-集合协议（k-Set Agreement）提供一个充分必要的条件。

Method: 本文采用了拓扑和几何方法，首先将迭代即时快照（IIS）模型上的无色可计算性定理推广到输入相关对手，然后证明了IIS_n模型中的核心弹性对手与仅在开始时发生崩溃的核心弹性对手具有相同的计算能力。最后，结合前两点，为基于条件的核心相关对手解决k-集合协议提供了充分必要条件，并区分了四种不同的任务表述设置。

Result: 1. 成功将[CG-24]的字符化推广到输入相关对手。 2. 证明了IIS_n模型中的核心弹性对手与仅在开始时发生崩溃的核心弹性对手具有相同的计算能力。 3. 提出了基于条件的核心相关对手解决k-集合协议的充分必要条件，并区分了四种任务表述设置。 4. 提出了载体映射（carrier map）的结构属性，以简化证明。

Conclusion: 该研究通过拓扑和几何方法，在更一般的对手模型下，为分布式计算中的k-集合协议的可解性提供了新的见解和充分必要的条件，并简化了相关证明。

Abstract: Distributed computing tasks can be presented with a triple $(\I,\Ou,\Delta)$.
The solvability of a colorless task on the Iterated Immediate Snapshot model
(IIS) has been characterized by the Colorless Computability Theorem
\cite[Th.4.3.1]{HKRbook}. A recent paper~\cite{CG-24} generalizes this theorem
for any message adversaries $\ma \subseteq IIS$ by geometric methods. In 2001,
Most\'efaoui, Rajsbaum, Raynal, and Roy \cite{condbased} introduced
\emph{condition-based adversaries}. This setting considers a particular
adversary that will be applied only to a subset of input configurations. In
this setting, they studied the $k$-set agreement task with condition-based
$t$-resilient adversaries and obtained a sufficient condition on the conditions
that make $k$-Set Agreement solvable. In this paper we have three
contributions:
  -We generalize the characterization of~\cite{CG-24} to \emph{input-dependent}
adversaries, which means that the adversaries can change depending on the input
configuration.
  - We show that core-resilient adversaries of $IIS_n$ have the same
computability power as the core-resilient adversaries of $IIS_n$ where crashes
only happen at the start.
  - Using the two previous contributions, we provide a necessary and sufficient
characterization of the condition-based, core-dependent adversaries that can
solve $k$-Set Agreement. We also distinguish four settings that may appear when
presenting a distributed task as $(\I,\Ou,\Delta)$. Finally, in a later
section, we present structural properties on the carrier map $\Delta$. Such
properties allow simpler proof, without changing the computability power of the
task. Most of the proofs in this article leverage the topological framework
used in distributed computing by using simple geometric constructions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [272] [Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models](https://arxiv.org/abs/2511.03147)
*Haotian Yin,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 通过引入可调的ODW损失权重，提出了一种用于神经SDF的CAD重建的新方法，以在训练早期稳定优化并在后期恢复细节。


<details>
  <summary>Details</summary>
Motivation: 现有的神经SDF方法通常需要基于梯度和曲率的正则化来抑制伪影并保持结构保真度。FlatCAD提出的ODW损失是一种高效的二阶先验，但其固定的ODW权重在训练过程中是次优的，因为早期的高权重会抑制后期细节的恢复。

Method: 提出并研究了ODW损失的调度策略，包括恒定、线性、五次和阶梯插值以及带有预热期的递增调度。

Result: 实验表明，时间相关的调度策略在ABC CAD数据集上始终优于固定权重，并将Chamfer距离的改进提高了35%。

Conclusion: 将ODW损失的权重随时间进行调整是一种简单而有效的方法，可以增强神经SDF在CAD重建中的性能。

Abstract: Neural signed distance functions (SDFs) have become a powerful representation
for geometric reconstruction from point clouds, yet they often require both
gradient- and curvature-based regularization to suppress spurious warp and
preserve structural fidelity. FlatCAD introduced the Off-Diagonal Weingarten
(ODW) loss as an efficient second-order prior for CAD surfaces, approximating
full-Hessian regularization at roughly half the computational cost. However,
FlatCAD applies a fixed ODW weight throughout training, which is suboptimal:
strong regularization stabilizes early optimization but suppresses detail
recovery in later stages. We present scheduling strategies for the ODW loss
that assign a high initial weight to stabilize optimization and progressively
decay it to permit fine-scale refinement. We investigate constant, linear,
quintic, and step interpolation schedules, as well as an increasing warm-up
variant. Experiments on the ABC CAD dataset demonstrate that time-varying
schedules consistently outperform fixed weights. Our method achieves up to a
35% improvement in Chamfer Distance over the FlatCAD baseline, establishing
scheduling as a simple yet effective extension of curvature regularization for
robust CAD reconstruction.

</details>


### [273] [Visualization Biases MLLM's Decision Making in Network Data Tasks](https://arxiv.org/abs/2511.03617)
*Timo Brand,Henry Förster,Stephen G. Kobourov,Jacob Miller*

Main category: cs.GR

TL;DR: We demonstrate that while visualizations improve MLLM confidence in detecting network bridges, standard techniques introduce significant bias, potentially leading to hallucinations. Careful consideration is needed when incorporating visualizations into generative AI.


<details>
  <summary>Details</summary>
Motivation: To evaluate the influence of visualizations on MLLMs' judgment regarding the presence of bridges in a network.

Method: Comparing MLLM performance with and without visualization, and analyzing the impact of standard visualization techniques on bias.

Result: Visualizations increase MLLM confidence but introduce bias, leading to inaccurate judgments regardless of the actual presence of bridges. The MLLM's self-reported confidence is not compromised by these biases.

Conclusion: While visualizations can influence MLLMs without affecting their confidence, practitioners should be cautious about their use in generative AI to prevent hallucinations, as standard techniques create strong biases.

Abstract: We evaluate how visualizations can influence the judgment of MLLMs about the
presence or absence of bridges in a network. We show that the inclusion of
visualization improves confidence over a structured text-based input that could
theoretically be helpful for answering the question. On the other hand, we
observe that standard visualization techniques create a strong bias towards
accepting or refuting the presence of a bridge -- independently of whether or
not a bridge actually exists in the network. While our results indicate that
the inclusion of visualization techniques can effectively influence the MLLM's
judgment without compromising its self-reported confidence, they also imply
that practitioners must be careful of allowing users to include visualizations
in generative AI applications so as to avoid undesired hallucinations.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [274] [Dynamics of excitons in CdSe nanoplatelets](https://arxiv.org/abs/2511.02857)
*Gerard Czajkowski*

Main category: cond-mat.mes-hall

TL;DR: We derived analytical expressions for optical functions of CdSe nanoplatelets, considering dielectric confinement and excitation regimes, and found geometry and temperature impact optical properties.


<details>
  <summary>Details</summary>
Motivation: To calculate the linear and nonlinear optical functions of CdSe nanoplatelets, accounting for dielectric confinement on excitonic states under both stationary and non-stationary excitation.

Method: Analytical derivation of expressions for absorption coefficient, exciton resonance energy, and binding energy. Discussion of the impact of plate geometry (thickness, lateral dimension). Analysis of temperature effects in the nonlinear case. Consideration of time dependence for short-pulse excitation.

Result: Analytical expressions for optical functions. Understanding of how geometry and temperature affect the optical spectrum. Comparison with experimental data.

Conclusion: The study provides a theoretical framework for understanding the optical properties of CdSe nanoplatelets and their dependence on various physical parameters.

Abstract: We show how to calculate the linear and nonlinear optical functions of CdSe
nanoplatelets, taking into account the effect of a dielectric confinement on
excitonic states. We consider both stationary and non-stationary excitation
regime. We obtain obtain analytical expressions for the absorption coefficient,
the exciton resonance energy and binding energy of nanoplatelets. The impact of
plate geometry (thickness, lateral dimension) on the spectrum is discussed. In
the nonlinear case we analyze the impact of temperature. For the short-pulse
excitation the time dependence of the spectra is considered. The results are
compared with the available experimental data.

</details>


### [275] [Dynamics of Cu2O Rydberg Excitons -- Kerr Effect and Quantum Beats](https://arxiv.org/abs/2511.02861)
*Gerard Czajkowski*

Main category: cond-mat.mes-hall

TL;DR: Rydberg excitons in Cu2O crystals exhibit nonlinear refraction and Kerr phase shift, showing quantum beats dependent on exciton state, laser power, and dissipation.


<details>
  <summary>Details</summary>
Motivation: Investigate nonlinear refraction and Kerr phase shift due to Rydberg excitons in Cu2O crystals.

Method: Observe quantum beats and calculate temporal evolution of Rydberg excitons induced by short-time pulses.

Result: Observed quantum beats analogous to those in exciton emission spectra. Calculated temporal evolution shows dependence on exciton state number, laser power, and dissipative processes.

Conclusion: The study demonstrates nonlinear optical phenomena related to Rydberg excitons in Cu2O and their dependence on various parameters.

Abstract: We investigate the nonlinear refraction and the nonlinear Kerr phase shift
which are due to Rydberg excitons induced in Cu2O crystal by short-time pulses.
We observe the phenomenon of quantum beats, analogous to that observed in
exciton emission spectra, obtained in the same conditions. The calculated
temporal evolution show dependence on the exciton state number, the applied
laser power, and quantities related to dissipative processes.

</details>


### [276] [Extrinsic anomalous Hall effect in altermagnets](https://arxiv.org/abs/2511.03151)
*A. Osin,A. Levchenko,M. Khodas*

Main category: cond-mat.mes-hall

TL;DR: 外禀反常霍尔电导率在部分交替磁自旋劳埃群中与本征值相当，在有有限的德亚洛辛斯基-莫里亚相互作用的材料中，外禀贡献是必须的。


<details>
  <summary>Details</summary>
Motivation: 探究外禀反常霍尔电导率与本征值在交替磁自旋劳埃群中的关系，以及德亚洛辛斯基-莫里亚相互作用对外禀贡献的影响。

Method: 分析外禀反常霍尔电导率与本征值的关系，并考虑德亚洛辛斯基-莫里亚相互作用的影响，研究弱自旋-轨道耦合如何打破非相对论自旋对称性。

Result: 外禀反常霍尔电导率在部分交替磁自旋劳埃群中与本征值相当，在有有限的德亚洛辛斯基-莫里亚相互作用的材料中，外禀贡献是必须的，而在其他交替磁体中可忽略不计。

Conclusion: 外禀反常霍尔电导率的行为与本征反常霍尔电导率对自旋-轨道耦合的依赖性有关，而这种依赖性源于弱自旋-轨道耦合打破了节点平面的自旋简并所产生的非解析依赖性。

Abstract: We find the extrinsic anomalous Hall conductivity (AHC) to be comparable to
the intrinsic one in roughly half of the altermagnetic spin Laue groups in the
limit of large exchange splitting. In materials with a finite
Dzyaloshinskii-Moriya type interaction, the extrinsic contribution is essential
even in the clean limit. In other altermagnets it is mostly negligible. This
peculiar behavior is linked to the nonanalytic dependence of the intrinsic AHC
on spin-orbit coupling. Both originate from the lifting of the spin degeneracy
along the nodal planes as the weak spin-orbit coupling breaks the
nonrelativistic spin symmetry.

</details>


### [277] [Lorentz Skew Scattering Nonreciprocal Magneto-Transport](https://arxiv.org/abs/2511.03273)
*Xiu Fang Lu,Xue-Jin Zhang,Naizhou Wang,Jin Cao,Dan Zhao,Hui Wang,Tao Wu,Xian Hui Chen,Shen Lai,Cong Xiao,Shengyuan A. Yang,Weibo Gao*

Main category: cond-mat.mes-hall

TL;DR: In BiTeBr, a new nonreciprocal magneto-transport (NRMT) mechanism called Lorentz skew scattering (LSK) was discovered, exhibiting a quartic scaling law and dominating over other mechanisms due to high mobility and strong Rashba splitting. This finding is significant for developing low-dissipation rectifiers and high-performance quantum electronics.


<details>
  <summary>Details</summary>
Motivation: Existing experimental studies attribute NRMT to Zeeman-driven mechanisms with quadratic scaling. This paper aims to report a previously unknown NRMT microscopic mechanism and its associated quartic scaling law, validated by experiments in BiTeBr.

Method: The study reveals the Lorentz skew scattering (LSK) mechanism through the discovery of a quartic scaling law of NRMT and quantitative agreement between theory and experiment in BiTeBr. LSK emerges from the interplay of Lorentz force and skew scattering. The dominance of LSK in BiTeBr is attributed to high mobility and strong Rashba splitting.

Result: A previously unknown NRMT microscopic mechanism, Lorentz skew scattering (LSK), was discovered, exhibiting an unprecedented quartic scaling law. This LSK mechanism was found to dominate NRMT in BiTeBr due to high mobility and strong Rashba splitting, with quantitative agreement between theory and experiment.

Conclusion: The discovery of the LSK mechanism unveils the leading NRMT effect in high-mobility systems and suggests a universal principle for achieving strong NRMT by enhancing electronic relaxation time in topological materials. This provides a new design concept for low-dissipation rectifiers and high-performance quantum electronics.

Abstract: In materials with broken inversion symmetry, nonreciprocal magneto-transport
(NRMT) manifests as a bilinear dependence of charge conductivity on applied
electric (E) and magnetic (B) fields. This phenomenon is deeply rooted in
symmetry and electronic quantum geometry, holding promise for novel
rectification and detector technologies. Existing experimental studies
generally attribute NRMT to Zeeman-driven mechanisms and exhibit quadratic
scaling with conductivity. Here, we report a previously unknown NRMT
microscopic mechanism - Lorentz skew scattering (LSK) - revealed through the
discovery of an unprecedented quartic scaling law of NRMT as well as
quantitative agreement between theory and experiment in BiTeBr. LSK emerges
from the interplay of Lorentz force and skew scattering, bridging classical
field effect to quantum scattering effect on the Fermi surface. We demonstrate
that the LSK dominates NRMT in BiTeBr, and elucidate that this dominance over
other possible contributions stems from high mobility and strong Rashba
splitting. The finding of LSK mechanism is of unique importance because it
unveils the leading NRMT effect in high-mobility systems and suggests a
universal principle towards strong NRMT by enhancing electronic relaxation time
in topological materials, rendering a new designing idea for low-dissipation
rectifiers and high-performance quantum electronics.

</details>


### [278] [Giant field-tunable nonlinear Hall effect by Lorentz skew scattering in a graphene moire superlattice](https://arxiv.org/abs/2511.03381)
*Pan He,Min Zhang,Yue-Xin Huang,Jingru Li,Ruibo Wang,Shiwen Zhao,Chaoyu Pan,Yuxiao Gao,Takashi Taniguchi,Kenji Watanabe,Junxiong Hu,Yinyan Zhu,Cong Xiao,X. C. Xie,Shengyuan A. Yang,Jian Shen*

Main category: cond-mat.mes-hall

TL;DR: 在石墨烯-hBN摩尔超晶格中发现一种由洛伦兹倾斜散射（LSK）引起的非线性霍尔效应（NHE），该效应可以通过磁场调控，具有显著的单向角依赖性，并且幅值可达线性霍尔信号的32%，创纪录地达到了36000 μmV-1Ω-1，为在高性能材料中实现巨大的霍尔整流提供了一种新的途径。


<details>
  <summary>Details</summary>
Motivation: 现有非线性霍尔效应（NHE）的调控方法主要依赖于量子效应，效率低下，信号较弱，限制了其进一步发展。需要开发更高效、可调的NHE机制。

Method: 研究了石墨烯-hBN摩尔超晶格在垂直磁场下的非线性霍尔效应。通过洛伦兹倾斜散射（LSK）来解释观察到的现象，并分析了NHE与磁场的关系、角依赖性以及其与线性霍尔信号的比例。研究了NHE的标度律，并计算了非线性霍尔电导率。

Result: 发现了一种由磁场诱导的、源于洛伦兹倾斜散射（LSK）的新型NHE。该效应表现出与磁场线性相关和显著的单向角依赖性。其幅值是线性霍尔信号的32%，非线性霍尔电导率达到了创纪录的36000 μmV-1Ω-1，远超以往的NHE研究。观察到NHE遵循独特的四次方标度律。

Conclusion: 洛伦兹倾斜散射（LSK）是一种有效的、可由磁场驱动的实现巨大NHE的机制。这种基于磁场调控的NHE为超越传统静电门控的NHE调控提供了新的范式，并可能在能量收集和信号整流等领域有广泛应用。

Abstract: The nonlinear Hall effect (NHE) can enable rectification and energy
harvesting, and its control by external fields, including gate, strain and
magnetic field, has been pursued intensively. However, existing tuning pathways
rely predominantly on fully quantum mechanical effects and are typically
inefficient, resulting in weak NHE signals that limit further progress. In this
work, we report the discovery of a distinct type of NHE in a graphene-hBN moire
superlattice, which arises from a classical-quantum cooperative effect called
Lorentz skew scattering (LSK), induced by a perpendicular magnetic field. This
field-driven NHE exhibits a linear dependence on magnetic field and a
pronounced unidirectional angular dependence. Remarkably, its magnitude reaches
up to 32% of the linear Hall signal. We show that this giant, field-tunable NHE
originating from LSK follows a unique quartic scaling law and produces a
record-high nonlinear Hall conductivity (36000 {\mu}mV-1{\Omega}-1) near van
Hove singularities of moire minibands, which is over an order of magnitude
larger than all previously reported NHEs. Our findings establish an efficient,
magnetic-field-driven route to giant Hall rectification in high-mobility
materials, offering a broadly applicable paradigm for modulating the NHE beyond
electrostatic gating.

</details>


### [279] [Discovery of Slot Plasma Excitations in a AlGaN/GaN Plasmonic Crystal](https://arxiv.org/abs/2511.03450)
*A. R. Khisameeva,A. Shuvaev,I. M. Moiseenko,P. A. Gusikhin,A. S. Astrakhantseva,A. Pimenov,D. A. Svintsov,I. V. Kukushkin,V. M. Muravev*

Main category: cond-mat.mes-hall

TL;DR: 本研究在AlGaN/GaN二维电子系统中发现了以前未被观察到的、在门缝中传播的非屏蔽等离子体激元，并提出了新的波矢量子化规则和相移模型。


<details>
  <summary>Details</summary>
Motivation: 在AlGaN/GaN二维电子系统中，等离子体晶体中的屏蔽等离子体模式是容易观察到的，但门缝中的非屏蔽模式一直未被观测到。本研究旨在发现并表征这些门缝等离子体激元。

Method: 通过实验测量AlGaN/GaN二维电子系统的太赫兹光谱，并建立分析模型来解释观测到的现象，包括发现新的波矢量子化规则和提出等离子体在门边缘反射时的相移模型。

Result: 发现了具有平方根色散关系的门缝等离子体激元，并提出了新的波矢量子化规则 $q_u=(N + 1/4) 	imes 	ext{π}/l_u$ （其中N为偶数）以及激发条件 $q_u h 	ext{ ≪ } 1$。分析模型准确地描述了色散和弛豫，并揭示了在门边缘反射时存在 $-	ext{π}/4$ 的非平凡相移。门缝等离子体激元在室温下仍然存在。

Conclusion: 发现了门缝等离子体激元，提出了新的波矢量子化规则和相移模型，并证明其在室温下的存在性，这为等离子体器件的发展提供了广阔的机会。

Abstract: We experimentally investigate the terahertz spectrum of plasma excitations in
a plasmonic crystal based on AlGaN/GaN two-dimensional electron system (2DES).
While screened plasmon modes with linear dispersion are readily observed in the
plasmonic crystals, the existence of unscreened modes localized in the slots
between the gates has remained unobserved until now. We discover this slot
plasma excitation exhibiting square-root dispersion. It turned out that these
slot plasmons follow an unconventional wave-vector quantization rule, $q_u=(N +
1/4) \times \pi/l_u$ for even integers $N$, and require the condition for
excitation $q_u h \ll 1$, where $h$ is the gate-to-2DES distance and $l_u$ is
the slot width. We develop an analytical model that accurately captures the
found dispersion and relaxation, revealing a non-trivial $-\pi/4$ phase shift
upon plasmon reflection at the gate edge. Experiments demonstrate that the slot
plasmons persist up to room temperature, thereby enabling a broad range of
opportunities for the advancement of plasmonic devices.

</details>


### [280] [Switching perpendicular magnets for Processing-in-memory with voltage gated Weyl Semimetals](https://arxiv.org/abs/2511.03507)
*Youjian Chen,Hamed Vakili,Md Golam Morshed,Avik W. Ghosh*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种基于应变外尔半金属的自旋轨道力矩随机存取存储器（SWSM-SOTRAM）器件，用于处理中内存（PIM）架构。


<details>
  <summary>Details</summary>
Motivation: 为了减少数据传输延迟，提出了一种将内存和逻辑元件集成的新型PIM架构，并选择应变外尔半金属作为其关键材料。

Method: 利用紧束缚模型结合非平衡格林函数（TB-NEGF）方法计算了反向自旋霍尔效应（SHE）和反向自旋甘凡尼效应（iSGE），并结合Landau-Lifshitz-Gilbert（LLG）模拟了磁化动力学，以建立SOT开关机制。

Result: 通过应变工程调控外尔半金属的对称性和自旋霍尔效应，实现了SOT开关，并验证了SWSM-SOTRAM PIM器件的可行性。

Conclusion: 所提出的SWSM-SOTRAM器件利用应变调控的交换塞曼场来控制自旋轨道力矩开关，为实现高性能PIM器件提供了一条新的途径。

Abstract: Processing-in-memory (PIM) reduces data transfer latency by rolling memory
and logic elements into one compute location. As an emergent material candidate
for such an architecture, we propose a strained Weyl semimetal based
spin-orbit-torque random-access memory (SWSM-SOTRAM) device. The spin-orbit
torque (SOT) originates from two mechanisms: (1) the inverse spin Galvanic
effect (iSGE), which generates nonequilibrium in-plane spin accumulation at
interfaces, and (2) a bulk spin Hall effect (SHE), which produces a transverse
spin current carrying out-of-plane spin angular momentum. The latter is tunable
via an exchange Zeeman field. Both effects are evaluated using the
tight-binding model coupled with a nonequilibrium Green's function (TB-NEGF)
formalism for quantum transport. Information write is achieved through SOT
switching of an out-of-plane free magnet. A piezo attached to a
magnetostrictive selector modulates the strain in the latter, leading to the
rotation of the magnetization and hence the exchange Zeeman field exerted on
the Weyl semimetal. This strain-controlled exchange field enables the symmetry
tuning of the Weyl semimetal and modulation of its spin Hall effect. The
TB-NEGF calculations of SHE and iSGE, combined with Landau-Lifshitz-Gilbert
(LLG) simulations of magnetization dynamics, establish the SOT switching
mechanism and demonstrate a pathway toward the SWSM-SOTRAM PIM device.

</details>


### [281] [Coherent Phonon Negative Refraction via Interfacial Momentum Compensation](https://arxiv.org/abs/2511.03599)
*Hao Chen,Zhong-Ke Ding,Nannan Luo,Jiang Zeng,Li-Ming Tang,Ke-Qiu Chen*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯/氮化硼异质结构实现声子负折射，通过动量补偿机制和界面调控实现


<details>
  <summary>Details</summary>
Motivation: 实现相干声子的负折射对于热管理和量子信息处理至关重要，但目前仍未实现，因为同时实现负折射的合适色散和远程相干性具有挑战性。

Method: 利用离散平移对称性介导的动量补偿机制，通过界面倒格矢在声子隧穿过程中提供动量补偿，并诱导非对称模式匹配，从而在不需要强色散各向异性或负曲率带的情况下实现负折射。利用非平衡格林函数形式推导。

Result: 在石墨烯/氮化硼异质结构中，利用非平衡格林函数形式，演示了各向同性声子声子的相干负折射。

Conclusion: 该通用机制能够通过界面设计主动控制声子流，为原子尺度的声子透镜和定向热传输等应用铺平道路。

Abstract: Negative refraction of coherent phonons is crucial for thermal management and
quantum information processing, but it remains unrealized because achieving the
suitable dispersion for negative refraction simultaneously with long-range
coherence is challenging. In this letter, we overcome this limitation by
introducing a momentum compensation mechanism mediated by discrete
translational symmetry. Interfacial reciprocal lattice vectors provide momentum
compensation during phonon tunneling and induce asymmetric mode matching,
resulting in negative refraction without requiring strong dispersion anisotropy
or a negative-curvature band. Using non-equilibrium Green's function formalism,
we demonstrate coherent negative refraction of isotropic acoustic phonons in
graphene/hexagonal boron nitride heterostructures. This general mechanism
enables active control of phonon flow via interfacial design, paving the way
for applications in atomic-scale phonon lenses and directional thermal
transport.

</details>


### [282] [Elimination of the acoustoelectric domain and increasing of the emission intensity by means of shunting the lateral current in the InGaAs/GaAs heterostructures](https://arxiv.org/abs/2511.03621)
*P. A. Belevskii,M. N. Vinoslavskii,O. S. Pylypchuk*

Main category: cond-mat.mes-hall

TL;DR: 通过在异质结构表面沉积银膜来抑制声电畴，从而增强带间发射。


<details>
  <summary>Details</summary>
Motivation: 在多层InGaAs/GaAs量子阱异质结构中，由于横向电荷载流子传输和强电场，实验中实现了声电畴的形成。然而，声电畴的出现会导致电流下降、电流振荡以及带间发射的急剧减弱，这限制了其在光电器件中的应用。

Method: 通过在异质结构表面欧姆接触之间沉积半遮光银膜进行分流。

Result: 在没有分流的情况下，声电畴的出现导致电流下降、电流振荡和带间发射急剧减弱。分流后，电流下降被消除，带间发射强度得到显著增强。

Conclusion: 通过在异质结构表面沉积银膜进行分流，可以有效抑制声电畴的形成，从而消除电流下降和振荡，并显著增强带间发射强度，为开发高性能光电器件提供了新的途径。

Abstract: There has been experimentally implemented a technique of neutralization of an
acoustoelectric domain under the conditions of the lateral transport of charge
carriers in strong electric fields in the multilayer InGaAs/GaAs
heterostructures with quantum wells. The technique is implemented by means of
deposition of a shunting semi opaque silver film on the heterostructure surface
between the ohmic contacts. In absence of shunting the domain appearance leads
to current decrease, current oscillations and also to a strong decrease of the
band-to-band emission during a voltage pulse applied to the sample. The
shunting eliminated the current decrease and enabled it to strongly enlarge the
band-to-band emission intensity.

</details>


### [283] [Gate-tunable single terahertz meta-atom ultrastrong light-matter coupling](https://arxiv.org/abs/2511.03664)
*Elsa Jöchl,Anna-Lydia Vieli,Lucy Hale,Felix Helmrich,Deniz Turan,Mona Jarrahi,Mattias Beck,Jérôme Faist,Giacomo Scalari*

Main category: cond-mat.mes-hall

TL;DR: 本研究实现了太赫兹超强光-物质相互作用的电调谐。


<details>
  <summary>Details</summary>
Motivation: 研究单太赫兹谐振器与二维电子气之间超强光-物质相互作用的电调谐特性。

Method: 通过在不同栅极电压下，在强磁场中进行透射光谱测量。

Result: 结果显示，Landau 极化子色散随电场栅压变化，电子数的有效调谐使得归一化耦合强度可在 0.46 至 0.18 之间原位调谐。

Conclusion: 这是首次在 GaAs 量子阱异质结构中，利用太赫兹远场光谱技术展示了单太赫兹谐振器与电子之间相互作用的电调谐性。

Abstract: We study the electrical tunability of ultrastrong light-matter interactions
between a single terahertz circuit-based complementary split ring resonator
(cSRR) and a two-dimensional electron gas. For this purpose, transmission
spectroscopy measurements are performed under the influence of a strong
magnetic field at different set points for the electric gate bias. The
resulting Landau polariton dispersion depends on the applied electric bias, as
the gating technique confines the electrons in-plane down to extremely
sub-wavelength dimensions as small as d = 410 nm. This confinement allows for
the excitation of standing plasma waves at zero magnetic field and an effective
tunability of the electron number coupled to the THz resonator. This allows the
normalized coupling strength to be tuned in-situ from $\eta$ = 0.46 down to
$\eta$ = 0.18. This is the first demonstration of terahertz far-field
spectroscopy of an electrically tunable interaction between a single terahertz
resonator and electrons in a GaAs quantum well heterostructure.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [284] [A model for positron annihilation in multi-layer systems by solving the diffusion equation using different positron affinities](https://arxiv.org/abs/2511.02889)
*Lucian Mathes,Michael Göldl,Michael Leitner,Bettina Kohlhaas,Maximilian Suhr,Vassily Vadimovitch Burwitz,Armin Manhard,Christoph Hugenschmidt*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一个名为LIMPID的Python工具，用于解决多层系统中的正电子扩散方程，并能很好地拟合实验数据，提高了可重复性。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法来解决多层系统中的正电子扩散方程，同时考虑材料特性和实验数据拟合。

Method: 使用马尔可夫链模型来处理湮灭概率，并结合材料特定的注入分布、扩散参数和正电子亲和势。该算法已用Python实现并命名为LIMPID。

Result: 通过分析铜/硅体系的实验数据，LIMPID的计算结果与实验测量值高度吻合，证明了其有效性。

Conclusion: LIMPID工具能够准确模拟正电子在多层材料中的行为，并且能够与实验数据进行拟合，从而提高正电子缺陷表征测量的可重复性和可比性。

Abstract: We present a method for solving the positron diffusion equation in
multi-layer systems. Our approach incorporates material-specific implantation
profiles, diffusion parameters, and positron affinities. It utilizes a Markov
chain approach to model annihilation probabilities and provides fitting
capabilities for experimental S (lineshape) parameter data. We have implemented
this algorithm in Python and made it available for free under the name LIMPID.
To demonstrate its performance, we analyze depth-resolved Doppler-Broadening
Spectroscopy measurements of a Cu layer on a Si substrate, achieving excellent
agreement with the experimental profiles. The LIMPID tool enhances the
reproducibility and comparability of positron defect characterization
measurements across different research groups.

</details>


### [285] [Electron and hole $g$ factors in semiconductors and nanostructures (Review)](https://arxiv.org/abs/2511.02956)
*A. V. Rodina,M. A. Semina,E. L. Ivchenko*

Main category: cond-mat.mtrl-sci

TL;DR: 本文对块体半导体和纳米结构半导体中载流子自旋对外磁场的响应进行了实验和理论研究的回顾。


<details>
  <summary>Details</summary>
Motivation: 回顾了块体半导体和半导体纳米结构中载流子自旋对外磁场的响应的实验和理论研究。

Method: 考虑了测量电子g因子的各种实验方法，并对计算块体半导体和各种形状的纳米结构中的电子和空穴g因子的理论方法进行了详细分析。

Result: 电子或空穴g因子的量值定量表征了线性响应。

Conclusion: 对块体半导体和纳米结构中电子和空穴g因子的计算的理论方法进行了详细分析。

Abstract: We present a review of experimental and theoretical studies of the spin
response of charge carriers to an external magnetic field in bulk
semiconductors and semiconductor nanostructures. The linear response is
quantitatively characterized by the magnitude of the electron or hole g factor.
Various experimental methods for measuring the electron g factor are
considered, beginning with historical works and including modern research. A
detailed analysis of theoretical methods for calculating the electron and hole
g factors in bulk semiconductors and nanostructures of various shapes also
includes fundamental work from previous years and the present time.

</details>


### [286] [An Atomistically Informed Device Engineering (AIDE) Method Realized: A case study in GaAs](https://arxiv.org/abs/2511.02976)
*Leopoldo Diaz,Harold P. Hjalmarson,Jesse J. Lutz,Peter A. Schultz*

Main category: cond-mat.mtrl-sci

TL;DR: AIDE方法能够模拟半导体材料中的缺陷化学行为，并能预测缺陷的形成和相互作用。


<details>
  <summary>Details</summary>
Motivation: 辐射诱导的缺陷会影响半导体器件的性能，需要有效的方法来模拟和预测这些缺陷的行为。

Method: 提出了一种原子尺度信息器件工程（AIDE）方法，该方法结合了第一性原理计算得到的缺陷性质和实验测量参数，用于器件建模和动态模拟缺陷化学。AIDE方法能够模拟费米能级移动、电荷平衡以及扩散-反应过程。

Result: 在硅掺杂的砷化镓（GaAs）材料中，AIDE方法成功模拟了费米能级（包括电子和空穴费米能级）的移动，以及砷空位作为例如的电荷平衡过程。还模拟了由库仑吸引引起的镓离子和砷空位之间的扩散-反应，导致了镓-砷反位缺陷的形成。

Conclusion: AIDE方法能够模拟实验中难以测量的短时间、低浓度情况，并且可以推广到更复杂的系统。该方法可以作为虚拟实验工具，为难以测量的物理量提供估计范围。

Abstract: Radiation-induced defects can have a significant impact on the longevity and
performance of semiconductor devices. We present an Atomistically Informed
Device Engineering (AIDE) method that integrates first-principles defect
properties and experimentally measured parameters into a device model to
dynamically simulate the defect chemistry in semiconductors. For a
silicon-doped gallium arsenide (GaAs) material, we showcase three capabilities:
(i) Fermi level $E_F$ movement including its component electron and hole Fermi
levels, (ii) dynamical charge equilibration with the arsenic vacancy serving as
an example, and a (iii) diffusion-driven reaction between Coulomb attracted
gallium interstitial ($Ga_i$) and arsenic vacancy ($v_{As}$). Governed by
charge carrier reactions, the electron and hole Fermi levels remained
dissimilar until equilibrium was achieved at $E_F\approx1.32$ eV. The
equilibrium Fermi level was verified by successfully identifying $v_{As}^{3-}$
as the most populated charge state within the arsenic vacancy defect. Lastly, a
Coulomb attraction, created by the shifted Fermi level and the charge
equilibration process, between $Ga_i^{1+}$ and $v_{As}^{3-}$ resulted in the
formation of a doubly negative gallium antisite ($Ga_{As}^{2-}$). The AIDE
method can access experimentally inaccessible short-time and low-concentration
regimes, is generalizable to other more complex systems (e.g., indium gallium
arsenide), and, after solving open problems in GaAs, will serve as a virtual
experiment to bound estimates for difficult-to-measure physical quantities.

</details>


### [287] [Dirac semimetal strontium iridate thin films with strong spin-orbit interaction for magnetic heterostructures](https://arxiv.org/abs/2511.02998)
*Gennady A. Ovsyannikov,Nikita V. Dubitskiy,Georgi D. Ulev,Karen Y. Constantinian,Ivan E. Moskal,Victoria A. Baydikova,Andrei M. Petrzhik,Anton V. Shadrin,Alexei V. Mashirov*

Main category: cond-mat.mtrl-sci

TL;DR: 外延SrIrO3和SrIrO3/La0.7Sr0.3MnO3异质结构在电子和磁输运方面表现出应变可调性，且强自旋-轨道相互作用是其关键。


<details>
  <summary>Details</summary>
Motivation: 研究外延应变和自旋-轨道相互作用对外延SrIrO3薄膜及SrIrO3/La0.7Sr0.3MnO3异质结构电子和磁输运性质的影响，探索其在自旋电子学中的应用潜力。

Method: 通过X射线光电子能谱、磁阻和霍尔电阻测量，在2-300 K温度范围内，研究了SrIrO3薄膜和SrIrO3/La0.7Sr0.3MnO3异质结构在不同衬底（SrTiO3、NdGaO3、(LaAlO3)0.3(Sr2TaAlO6)0.7、LaAlO3和Pb(Mg1/3Nb2/3)O3-PbTiO3）上的结构晶体特征、电子输运和磁输运性质，并分析了应变弛豫和Kondo散射的影响。

Result: 发现外延应变对SrIrO3薄膜和异质结构的电子及磁输运性质有显著影响。强自旋-轨道相互作用对SrIrO3薄膜的特性有明显影响。观察到了Kondo散射对SrIrO3薄膜电阻温度依赖性的贡献。

Conclusion: 应变工程可以有效调控SrIrO3基外延体系中由自旋-轨道相互作用驱动的输运现象，这对于开发新型氧化物自旋电子异质结构具有重要意义。

Abstract: The structural crystal features, electron transport and magnetotransport of
the epitaxial strontium iridate (SrIrO$_3$) and iridate/manganite
SrIrO$_3$/La$_{0.7}$Sr$_{0.3}$MnO$_3$ heterostructure have been investigated.
The influence of epitaxial strain relaxation caused by the lattice mismatch
between SrIrO$_3$ films and five substrates: SrTiO$_3$, NdGaO$_3$,
(LaAlO$_3$)$_{0.3}$(Sr$_2$TaAlO$_6$)$_{0.7}$, LaAlO$_3$, and
Pb(Mg$_{1/3}$Nb$_{2/3}$)O$_3$-PbTiO$_3$ on electron and magnetic transport has
been observed. A pronounced impact of strong spin-orbit interaction on
characteristics of SrIrO$_3$ films has been revealed by means of X-ray
photoelectron spectroscopy, magnetoresistance and Hall-resistance measurements
at temperatures T = 2-300 K. These findings highlight the tunability of
spin-orbit-driven transport phenomena in strain-controlled SrIrO$_3$-based
epitaxial systems, relevant for future spintronic oxide heterostructures. The
contribution of Kondo scattering on temperature dependence of SrIrO$_3$ films
resistance was observed.

</details>


### [288] [Critical Disconnect Between Structural and Electronic Recovery in Amorphous GaAs during Recrystallization](https://arxiv.org/abs/2511.03010)
*Ellis Rae Kennedy,Adric Jones,Yongqiang Wang,Miguel Pena,Hyosim Kim,Chengyu Song,Farida Selim,Blas P. Uberuaga,Samuel Greer*

Main category: cond-mat.mtrl-sci

TL;DR: 辐照GaAs的重结晶过程涉及两个阶段：低温下的缓慢外延前沿传播和高温下的快速生长及致密纳米孪晶网络形成。结构演变与非晶相中的局部有序（类晶体）有关，但电子恢复与结构恢复不一致，表明局部缺陷比长程无序对半导体材料功能影响更大。


<details>
  <summary>Details</summary>
Motivation: 理解非晶到晶体相变过程中结构和功能的演变对于预测和设计极端条件下应用的器件至关重要。

Method: 研究辐照GaAs的重结晶过程，分析其结构演变和电子恢复过程。

Result: 结构演变分为两个阶段：低温下的缓慢外延前沿传播和高温下的快速生长及致密纳米孪晶网络形成。电子恢复与结构恢复不一致，电子性质比结构性质更能偏离原始状态。

Conclusion: 结构和电子恢复的不一致性表明，局部缺陷比长程无序对半导体材料的功能有更显著的影响。

Abstract: Understanding the evolution of structure and functionality through amorphous
to crystalline phase transitions is critical for predicting and designing
devices for application in extreme conditions. Here, we consider both aspects
of recrystallization of irradiated GaAs. We find that structural evolution
occurs in two stages, a low temperature regime characterized by slow, epitaxial
front propagation and a high-temperature regime above dominated by rapid growth
and formation of dense nanotwin networks. We link aspects of this structural
evolution to local ordering, or paracrystallinity, within the amorphous phase.
Critically, the electronic recovery of the materials is not commensurate with
this structural evolution. The electronic properties of the recrystallized
material deviate further from the pristine material than do those of the
amorphous phase, highlighting the incongruence between structural and
electronic recovery and the contrasting impact of loss of long range order
versus localized defects on the functionality of semiconducting materials.

</details>


### [289] [A Normalized Descriptor for Unbiased Screening of Second-Order Nonlinear Optical Materials](https://arxiv.org/abs/2511.03038)
*Aubrey G. J. Nyiri,Michael J. Waters,James M. Rondinelli*

Main category: cond-mat.mtrl-sci

TL;DR: 通过引入一个归一化的描述符d^，解决了跨材料比较二阶非线性光学（NLO）材料的SHG性能的挑战，该描述符克服了由带隙Eg决定的二阶非线性磁化率χ(2)的巨大变化，并为加速NLO材料发现提供了通用工具。


<details>
  <summary>Details</summary>
Motivation: 比较不同二阶非线性光学（NLO）材料的二次谐波产生（SHG）性能面临挑战，因为二阶非线性磁化率χ(2)随带隙Eg变化很大，变化范围可达几个数量级。

Method: 通过计算得到的非线性光学（NLO）材料的从头算数据库，经验性地验证了χ(2)的理论上限，并引入了一个归一化的描述符d^，该描述符考虑了与带隙相关的物理极限。

Result: 归一化的描述符d^在各种带隙能量下表现出相似的分布，表明其在不同材料之间具有普遍性。

Conclusion: d^是一个稳健且可推广的描述符，可用于数据驱动和化学启发的机器学习模型，以加速NLO材料的发现和优化。

Abstract: Second-order nonlinear optical materials enable frequency doubling of light
(second-harmonic generation, SHG), which is essential for optoelectronic
applications ranging from materials characterization to quantum technologies.
However, comparing SHG performance across materials remains challenging as the
second-order nonlinear susceptibility $\chi^{(2)}$ spans several orders of
magnitude and strongly depends on the band gap $E_g$. To address this, we
empirically validate a theoretical upper bound on $\chi^{(2)}$ using new
databases of \textit{ab initio}-computed nonlinear optical (NLO) properties. We
then formulate a normalized descriptor, $\hat{d}$, which expresses the NLO
response of a material relative to the band gap-dependent physical limit. We
show that $\hat{d}$ exhibits a similar distribution across a wide range of band
gap energies. This universality supports the use of $\hat{d}$ as a robust,
generalizable descriptor for data-driven and chemistry-informed machine
learning models of NLO response, enabling accelerated materials discovery and
optimization across broad application frequencies.

</details>


### [290] [EGMOF: Efficient Generation of Metal-Organic Frameworks Using a Hybrid Diffusion-Transformer Architecture](https://arxiv.org/abs/2511.03122)
*Seunghee Han,Yeonghun Kang,Taeun Bae,Varinia Bernales,Alan Aspuru-Guzik,Jihan Kim*

Main category: cond-mat.mtrl-sci

TL;DR: EGMOF是一个混合扩散-Transformer框架，通过模块化、描述符介导的工作流程，实现了高效的MOF逆设计，克服了对大数据集的需求和为新目标属性重新训练的限制。


<details>
  <summary>Details</summary>
Motivation: 设计具有目标性质的材料具有挑战性，因为化学空间巨大且缺乏带有标签的数据。现有的生成模型在逆设计方面很有前景，但需要大型数据集，并且每次需要新目标属性时都必须重新训练。

Method: EGMOF将逆设计分解为两个步骤：(1) 一维扩散模型 (Prop2Desc)，将所需的性质映射到化学描述符；(2) Transformer模型 (Desc2MOF)，根据描述符生成结构。

Result: EGMOF在氢气吸收数据集上实现了超过95%的有效性和84%的命中率，与现有方法相比，有效性提高了57%，命中率提高了14%，并且在只有1000个训练样本的情况下仍然有效。该模型还在29个不同的属性数据集上成功进行了条件生成。

Conclusion: EGMOF是一种数据高效、可推广的MOF逆设计方法，展示了模块化逆设计工作流程在更广泛材料发现中的潜力。

Abstract: Designing materials with targeted properties remains challenging due to the
vastness of chemical space and the scarcity of property-labeled data. While
recent advances in generative models offer a promising way for inverse design,
most approaches require large datasets and must be retrained for every new
target property. Here, we introduce the EGMOF (Efficient Generation of MOFs), a
hybrid diffusion-transformer framework that overcomes these limitations through
a modular, descriptor-mediated workflow. EGMOF decomposes inverse design into
two steps: (1) a one-dimensional diffusion model (Prop2Desc) that maps desired
properties to chemically meaningful descriptors followed by (2) a transformer
model (Desc2MOF) that generates structures from these descriptors. This modular
hybrid design enables minimal retraining and maintains high accuracy even under
small-data conditions. On a hydrogen uptake dataset, EGMOF achieved over 95%
validity and 84% hit rate, representing significant improvements of up to 57%
in validity and 14% in hit rate compared to existing methods, while remaining
effective with only 1,000 training samples. Moreover, our model successfully
performed conditional generation across 29 diverse property datasets, including
CoREMOF, QMOF, and text-mined experimental datasets, whereas previous models
have not. This work presents a data-efficient, generalizable approach to the
inverse design of diverse MOFs and highlights the potential of modular inverse
design workflows for broader materials discovery.

</details>


### [291] [Commutative Algebra Modeling in Materials Science -- A Case Study on Metal-Organic Frameworks (MOFs)](https://arxiv.org/abs/2511.03124)
*Caleb Simiyu Khaemba,Hongsong Feng,Dong Chen,Chun-Long Chen,Guo-Wei Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 将交换代数应用于金属有机框架（MOFs）材料的预测，提出了类别特定交换代数（CSCA）框架，实现了可解释、高效且准确的材料性质预测。


<details>
  <summary>Details</summary>
Motivation: 金属有机框架（MOFs）的复杂结构阻碍了对其材料性质的准确预测。现有的方法在可解释性和稳定性方面存在不足。

Method: 提出类别特定交换代数（CSCA）框架，该框架整合了基于元素的分类和多尺度代数不变量，用于MOF的表示和学习。CSCA能够同时编码MOF的局部配位基序和全局网络组织。

Result: CSCA在预测MOF的亨利常数和气体吸收容量等性质方面，取得了与传统方法相当或更优的预测精度，同时显著提高了模型的可解释性和跨数据集的稳定性。

Conclusion: CSCA框架为理解多孔材料的结构-性质关系提供了一种严谨且可推广的范式，并为数据驱动的材料发现提供了基于非线性代数的框架。

Abstract: Metal-organic frameworks (MOFs) are a class of important crystalline and
highly porous materials whose hierarchical geometry and chemistry hinder
interpretable predictions in materials properties. Commutative algebra is a
branch of abstract algebra that has been rarely applied in data and material
sciences. We introduce the first ever commutative algebra modeling and
prediction in materials science. Specifically, category-specific commutative
algebra (CSCA) is proposed as a new framework for MOF representation and
learning. It integrates element-based categorization with multiscale algebraic
invariants to encode both local coordination motifs and global network
organization of MOFs. These algebraically consistent, chemically aware
representations enable compact, interpretable, and data efficient modeling of
MOF properties such as Henry's constants and uptake capacities for common
gases. Compared to traditional geometric and graph-based approaches, CSCA
achieves comparable or superior predictive accuracy while substantially
improving interpretability and stability across data sets. By aligning
commutative algebra with the chemical hierarchy, the CSCA establishes a
rigorous and generalizable paradigm for understanding structure and property
relationships in porous materials and provides a nonlinear algebra-based
framework for data-driven material discovery.

</details>


### [292] [Mysterious Role of Cap Configuration in Single-Walled Carbon Nanotube Catalytic Growth](https://arxiv.org/abs/2511.03240)
*Tianliang Feng,Ziwei Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过追踪六边形相对位移来确定碳帽手性，并研究了不同手性碳纳米管在镍催化剂上的热力学稳定性和变形行为，发现了碳帽拓扑和催化剂曲率对生长和界面能的调控作用，特别是(6,6)碳帽表现出优异的柔韧性和能量优势，并建立了形变与形成能的线性关系，为碳纳米管生长策略设计提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 理解碳帽结构在单壁碳纳米管(SWCNT)成核和生长中的作用对于实现手性控制合成至关重要。

Method: 提出了一种新颖的算法，通过追踪拓扑坐标系统中六边形的相对位移来确定新兴碳帽的手性。基于该算法，结合密度泛函理论(DFT)计算的能量分布，提出了三种手性突变（从扶手椅型(AC)到近AC帽）的五边形位移途径。构建了不同手性和对称性的代表性短碳帽和长碳纳米管，并在平面Ni(111)表面和弯曲Ni55颗粒上评估了它们的热力学稳定性和变形行为。

Result: 研究结果揭示了碳帽拓扑和催化剂曲率共同诱导的形变显著影响形成能和界面能。AC和近AC帽表现出优越的柔韧性和强大的能量优势，特别是具有C6v对称性的(6,6)碳帽。通过定义的形状因子建立了碳帽诱导形变与形成能之间的线性相关性。

Conclusion: 该研究从理论上揭示了碳帽的演化机制，并为合理设计单壁碳纳米管的生长策略奠定了基础。AC和近AC碳帽因其优异的柔韧性和能量优势，在催化剂曲率的影响下，成为主导生长的重要因素。

Abstract: Understanding the role of cap structure during the nucleation and growth of
single-walled carbon nanotubes (SWCNTs) is essential for achieving
chirality-controlled synthesis. In this work, we propose a novel and intuitive
algorithm to determine the chirality of nascent carbon caps by tracking the
relative shifts of six pentagons within a topological coordinate system. Based
on this algorithm, we propose three routes of pentagon shifts for the chirality
mutations from armchair (AC) to near-AC caps, namely the transverse shift (n,n)
to (n+1,n-1), inward shift (n,n) to (n-1), and outward shift (n,n) to (n+1,n),
can occur according to the energy profiles calculated based on the density
function theory (DFT), providing a new perspective to explain the experimental
abundance of near-AC SWCNTs. After that, we construct 24 representative short
caps and long SWCNTs with different chiralities and symmetries, and perform DFT
calculations to evaluate their thermodynamic stability and deformation
behaviors on flat Ni(111) surfaces and curved Ni55 particle, respectively. The
results reveal that cap topology and catalyst curvature together induce dual
deformations that significantly influence the formation and interface energies.
Notably, AC and near-AC caps exhibit superior flexibility and robust energetic
advantages, especially the (6,6) cap with C6v symmetry. A linear correlation
between cap-induced deformation and formation energy is established through a
defined shape factor, highlighting the interaction between cap structure and
catalyst interface as a key driver of chirality selection. This study
theoretically reveals the cap evolution mechanism and lays the foundation for
the rational design of SWCNT growth strategies.

</details>


### [293] [Tunable Multistage Refrigeration via Geometrically Frustrated Triangular Lattice Antiferromagnet for Space Cooling](https://arxiv.org/abs/2511.03254)
*Jianqiao Wang,Chushu Fang,Zhibin Qiu,Yang Zhao,Quan Xiao,Xiying Sun,Zhaoyi Li,Laifeng Li,Yuan Zhou,Changzhao Pan,Shu Guo*

Main category: cond-mat.mtrl-sci

TL;DR:  Gd2O2Se 是一种新型磁性再生材料，可在 10 K 以下实现高效制冷，并能提高脉冲管低温冷却器的效率。


<details>
  <summary>Details</summary>
Motivation: 现有斯特林型脉冲管制冷机在 10 K 以下运行时，由于再生材料热容急剧下降，导致其空间冷却效率不高，难以满足太空探索的需求。

Method: 使用新型高自旋 S = 7/2 磁性再生材料 Gd2O2Se，并结合 Er3Ni 和 HoCu2，构建多级可调再生材料结构，以实现向液氦温区的高效制冷。

Result: Gd2O2Se 在 6.22 K 和 2.11 K 处表现出两步比热跃迁峰，其超高比热和宽广的两步跃迁温度范围弥补了商用高温热容材料的不足。与 Er3Ni 和 HoCu2 结合使用时，脉冲管制冷机在 7 K 时的制冷效率提高了 66.5%，最低可达 5.85 K。

Conclusion: Gd2O2Se 是一种理想的磁性再生材料，在空间冷却应用中具有巨大潜力。

Abstract: Low-temperature refrigeration technology constitutes a crucial component in
space exploration. The small-scale, low-vibration Stirling-type pulse tube
refrigerators hold significant application potential for space cooling.
However, the efficient operation of current Stirling-type pulse tube
cryocoolers in space cooling applications remains challenging due to the rapid
decay of the heat capacity of regenerative materials below 10 K. This study
adopts a novel material strategy: using a novel high-spin S = 7/2 magnetic
regenerative material, Gd2O2Se, we construct a multistage tunable regenerative
material structure to achieve an efficient cooling approach to the liquid
helium temperature range. Under substantial geometric frustration from a
double-layered triangular lattice, it exhibits two-step specific heat
transition peaks at 6.22 K and 2.11 K, respectively. Its ultrahigh specific
heat and broad two-step transition temperature range effectively bridge the gap
between commercially used high-heat-capacity materials. Experimental
verification shows that when Gd2O2Se is combined with Er3Ni and HoCu2 in the
Stirling-type pulse tube cryocooler, the cooling efficiency of the pulse tube
increases by 66.5 % at 7 K, and the minimum achievable temperature reaches 5.85
K. These results indicate that Gd2O2Se is an ideal magnetic regenerative
material for space cooling

</details>


### [294] [Axial phono-magnetic effects](https://arxiv.org/abs/2511.03329)
*Natalia Shabala,Finja Tietjen,R. Matthias Geilhufe*

Main category: cond-mat.mtrl-sci

TL;DR: Axial/circularly polarized phonons with angular momentum are a new mechanism for manipulating magnetism, enabling ultrafast magnetic switching in non-spin-ordered materials. This phono-magnetic effect is observed broadly and has theoretical underpinnings in perturbation theory, adiabatic motion, and Floquet theory.


<details>
  <summary>Details</summary>
Motivation: To review the recent progress in understanding and utilizing axial or circularly polarized phonons for manipulating magnetism, highlighting their potential for ultrafast magnetic switching and the universal nature of the phono-magnetic effect.

Method: This review article presents a phenomenological perspective and an overview of experimental evidence (phonon Zeeman effect, magneto-optical Kerr effect, proximity-induced magnetization switching). It also discusses recently proposed microscopic theories (perturbation theory, adiabatic motion, Floquet theory, artificial gauge fields, inertial effects) and establishes correspondences between theoretical approaches.

Result: Axial phonons can induce significant magnetization in materials without spin-ordering, observed across a broad class of materials, suggesting a universal phono-magnetic effect. Recent theoretical models provide insights into the microscopic mechanisms.

Conclusion: Phono-magnetic effects, driven by coherent axial phonons, represent a promising and universal mechanism for ultrafast magnetic switching, with ongoing theoretical and experimental advancements offering a more complete understanding of the phenomenon.

Abstract: Axial or circularly polarized phonons are collective lattice vibrations with
angular momentum. Over the past decade they have emerged as a promising
mechanism for the manipulation of magnetism, in parallel to well established
optical protocols. In particular, coherent axial phonons were shown to induce
magnetization in materials without spin-ordering, making them a viable tool for
ultrafast magnetic switching. The experimental evidence suggests that the size
of this magnetization is significant, opening a new research area on the
phono-magnetic effect. Remarkably, the coupling of axial phonons to magnetism
has been observed a broad class of materials, pointing to a universal nature of
the underlying mechanisms. In this review article, we present the recent
progress in the field. We give an introduction to the phenomenological
perspective and an overview of the experimental evidence for the magnetization
emerging from axial phonons, which includes discussing the observations of
phonon Zeeman effect, the magneto-optical Kerr effect and the proximity-induced
magnetization switching. We present recently proposed microscopic theories for
the phono-magnetic effects, based on perturbation theory, adiabatic motion and
Floquet theory as well as the emergence of the phonon magnetic moment due to
artificial gauge fields or inertial effects. This summary allows us to see
correspondences between the seemingly different theoretical approaches,
facilitating a more complete perspective of the effect.

</details>


### [295] [Core-Shell Confinement Blocks Hydride Formation: The Impact of Surface Oxides on Hydrogen Sorption in Nanoporous FeTi](https://arxiv.org/abs/2511.03349)
*Lukas Schweiger,Florian Spieckermann,Michael Burtscher,Stefan Wurster,Sebastian Stock,Nikolaos Kostoglou,Oskar Paris,Alexander Schökel,Fahim Karimi,Gökhan Gizer,Claudio Pistidda,Daniel Kiener,Jürgen Eckert*

Main category: cond-mat.mtrl-sci

TL;DR: 金属氢化物是常规气态和液态储氢方法的一种有趣替代方案，在环境条件下提供高体积储氢密度和增强的储氢安全性。其中，金属间化合物FeTi是最有前途的储氢材料之一。然而，由于需要活化、初始动力学缓慢、滞后大以及材料成本高，其广泛的工业应用仍然具有挑战性。本研究旨在通过设计替代合成途径来制备具有可控晶粒和韧带尺寸的纳米多孔和超细多孔FeTi，以克服这些限制，从而能够详细研究所得的明确定义的微观结构。特别是，我们观察到FeTi相被表面氧化物限制，这与相应材料的氢吸收性能相关。这些实验结果得到了分析模型的支持，该模型允许计算作为微观结构依赖性弹性应力函数的吸收压力。此外，我们还表明，这种应力也会影响吸收-解吸滞后。本研究为金属氢化物，特别是FeTi的加工-结构-性能关系的研究奠定了基础，从而为基于金属氢化物的经济高效的储氢解决方案铺平了道路。


<details>
  <summary>Details</summary>
Motivation: FeTi金属氢化物作为储氢材料有巨大潜力，但存在活化困难、动力学慢、滞后大、成本高等问题，本研究旨在通过制备纳米多孔和超细多孔FeTi来克服这些限制。

Method: 通过一种新的合成途径制备具有可控微观结构的纳米多孔和超细多孔FeTi，并结合分析模型研究其氢吸收性能、弹性应力与微观结构的关系以及对吸收-解吸滞后的影响。

Result: 成功制备了具有可控微观结构的FeTi材料，并观察到表面氧化物对FeTi相的限制作用，该作用与氢吸收性能相关。通过分析模型验证了微观结构、弹性应力与吸收压力和吸收-解吸滞后的关系。

Conclusion: 本研究为金属氢化物（特别是FeTi）的加工-结构-性能关系的研究奠定了基础，为开发经济高效的储氢解决方案提供了新途径。

Abstract: Metal hydrides remain an intriguing alternative to conventional gaseous and
liquid hydrogen storage methods, offering high volumetric storage density and
enhanced hydrogen storage safety at ambient conditions. In this regard, the
intermetallic compound FeTi is one of the most promising storage materials.
However, its widespread industrial application remains challenging due to the
need for activation, slow initial kinetics, large hysteresis, and high material
costs. In this study, we aim to overcome these limitations by devising an
alternative synthesis pathway to prepare nanoporous and ultra-fine porous FeTi
with controlled grain and ligament sizes, allowing us to study the obtained
well-defined microstructures in detail. In particular, we observe the
confinement of the FeTi phase by surface oxides, which can be correlated with
the hydrogen sorption properties of the respective material. These experimental
results are further supported by an analytical model allowing the calculation
of the absorption pressure as a function of microstructure-dependent elastic
stresses. Additionally, we show that such stresses also influence the
absorption-desorption hysteresis. This study lays the groundwork for the
controlled and systematic study of the processing-structure-properties
relations in metal hydrides and FeTi in particular, thereby paving the way to
cost-effective and efficient hydrogen storage solutions based on metal
hydrides.

</details>


### [296] [Single photon emitters in hBN: Limitations of atomic resolution imaging and potential sources of error](https://arxiv.org/abs/2511.03674)
*David Lamprecht,Shrirang Chokappa,Alissa M. Freilinger,Barbara Maria Mayer,Maximilian Melchior,Jana Dzíbelová,Darwin Lorber,Luiz H. G. Tizei,Mathieu Kociak,Clemens Mangler,Lado Filipovic,Jani Kotakoski*

Main category: cond-mat.mtrl-sci

TL;DR: ADF-STEM在超过17个原子层的hBN中难以识别缺陷


<details>
  <summary>Details</summary>
Motivation: 确定hBN单光子发射源，并解决ADF-STEM在厚hBN样品中识别缺陷的困难

Method: 进行STEM图像模拟和实验，并研究非径向像差（特别是三重偶责）对多层hBN的影响

Result: 在超过17个原子层的hBN中， boron/nitrogen列和碳取代的强度差异变得无法区分；三重复责会导致虚假衬度差异，可能错误识别缺陷

Conclusion: ADF-STEM在厚hBN样品中识别原子缺陷（如光子发射体）的可靠性有限，并且像差会引入虚假衬度，需要谨慎解释结果

Abstract: There is a growing interest in identifying the origin of single-photon
emission in hexagonal boron nitride (hBN), with proposed candidates including
boron and nitrogen vacancies as well as carbon substitutional dopants. Because
photon emission intensity often increases with sample thickness, hBN flakes
used in these studies commonly exceed 30 atomic layers. To identify potential
emitters at the atomic scale, annular dark-field scanning transmission electron
microscopy (ADF-STEM) is frequently employed. However, due to the intrinsic AA'
stacking of hBN with vertically alternating boron and nitrogen atoms, this
approach is complicated even in few-layer systems. Here, we demonstrate using
STEM image simulations and experiments that, even under idealized conditions,
the intensity differences between boron- and nitrogen-dominated columns and
carbon substitutions become indistinguishable at thicknesses beyond 17 atomic
layers (ca. 6 nm). While vacancy-type defects can remain detectable at somewhat
larger thicknesses, also their detection becomes unreliable at thicknesses
typically used in photonic studies. We further show that common residual
aberrations, particularly threefold astigmatism, can lead to artificial
contrast differences between columns, which may result in misidentification of
atomic defects. We systematically study the effects of non-radially symmetric
aberrations on multilayer hBN and demonstrate that even small residual
threefold astigmatism can significantly distort the STEM contrast, leading to
misleading interpretations.

</details>


### [297] [Enhancing composition-based materials property prediction by cross-modal knowledge transfer](https://arxiv.org/abs/2511.03371)
*Ivan Rubtsov,Ivan Dudakov,Yuri Kuratov,Vadim Korolev*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种利用跨模态知识迁移来增强基于组成的材料性质预测的通用方法，包括隐式和显式两种迁移方式，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有晶体图神经网络在建模合成化合物和假设材料方面有广泛应用，但结构无关的预测算法可以探索更广阔的化学空间。本研究旨在弥合这一差距，提高基于组成的材料性质预测的性能。

Method: 提出两种跨模态知识迁移的计算方法：1. 隐式迁移：在多模态嵌入上预训练化学语言模型。2. 显式迁移：生成晶体结构并实施结构感知预测器。此外，还提出了一种利用博弈论方法提高化学语言模型可解释性的方法。

Result: 所提出的方法在 LLM4Mat-Bench 和 MatBench 任务上进行了基准测试，在 32 个任务中的 25 个取得了最先进的性能。此外，还证明了博弈论方法可以提高化学语言模型的可解释性，并能结合高阶特征交互。

Conclusion: 本研究提出的跨模态知识迁移方法能够显著提升材料性质预测的性能，并在化学语言模型的可解释性方面取得了进展，为材料科学研究提供了新的工具和方向。

Abstract: Crystal graph neural networks are widely applicable in modeling
experimentally synthesized compounds and hypothetical materials with unknown
synthesizability. In contrast, structure-agnostic predictive algorithms allow
exploring previously inaccessible domains of chemical space. Here we present a
universal approach for enhancing composition-based materials property
prediction by means of cross-modal knowledge transfer. Two formulations are
proposed: implicit transfer involves pretraining chemical language models on
multimodal embeddings, whereas explicit transfer suggests generating crystal
structures and implementing structure-aware predictors. The proposed approaches
were benchmarked on LLM4Mat-Bench and MatBench tasks, achieving
state-of-the-art performance in 25 out of 32 cases. In addition, we
demonstrated how another modeling aspect of chemical language models -
interpretability - benefits from applying a game-theoretic approach, which is
able to incorporate high-order feature interactions.

</details>


### [298] [Development of a magnetic interatomic potential for cubic anti-ferromagnets: the case of NiO](https://arxiv.org/abs/2511.03382)
*Ievgeniia Korniienko,Pablo Nieves,Jakub Sebesta,Roberto Iglesias,Dominik Legut*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种将磁性哈密顿量（包括海森堡交换和尼尔模型）整合到立方反铁磁材料（以氧化镍为例）的原子间势中的方法，并构建了基于Born模型和改进嵌入原子模型（MEAM）的两种势，可用于大规模磁弹性现象模拟。


<details>
  <summary>Details</summary>
Motivation: 为复杂反铁磁材料构建包含磁性的原子间势具有挑战性，而镍的氧化物（NiO）是立方反铁磁材料的典型代表，体现了这种困难。

Method: 通过添加包含海森堡交换和尼尔模型的磁性哈密顿量来整合磁特性。将此方法应用于NiO，构建了两种势：一种基于离子固体Born模型，另一种基于无参考的改进嵌入原子方法（MEAM）。两种势均包含磁弹性相互作用。

Result: 两种势均经过密度泛函理论计算验证，在零温下的力学和磁性方面表现出极好的一致性。

Conclusion: 所提出的模型能够进行大规模的反铁磁材料磁弹性现象的模拟，并为涉及耦合电场和磁场的金属氧化物分子动力学研究开辟了道路。

Abstract: Interatomic potentials are essential for molecular dynamics simulations of
magnetic materials, yet incorporating magnetic features into potentials for
complex antiferromagnets remains challenging. Nickel oxide (NiO), a
prototypical cubic antiferromagnet, exemplifies this difficulty. Here we
develop a methodology to integrate magnetic properties into interatomic
potentials for cubic antiferromagnets by adding a magnetic Hamiltonian which
includes both the Heisenberg exchange and N\'eel model. We apply this approach
to NiO by constructing two potentials: one based on the Born model of ionic
solids and another using a reference-free modified embedded atom method. Both
potentials include magnetoelastic interactions and are validated against
Density Functional Theory calculations, showing excellent agreement in
mechanical and magnetic properties at zero temperature. These models enable
large-scale simulations of magnetoelastic phenomena in antiferromagnets and
open avenues for molecular dynamics studies involving coupled electric and
magnetic fields in metal oxides.

</details>


### [299] [Statistical imaging of NV centers reveals clustered defect formation in diamond](https://arxiv.org/abs/2511.03411)
*Jason Shao,Richard Monge,Tom Delord,Carlos A. Meriles*

Main category: cond-mat.mtrl-sci

TL;DR: 通过成像技术分析金刚石中的NV色心，发现其并非随机分布，而是存在聚集现象，这对于量子信息和传感应用具有意义。


<details>
  <summary>Details</summary>
Motivation: 需要一种可扩展的方法来校准和分析金刚石中的NV色心，以便进行材料表征。

Method: 使用共振光致发光激发成像技术，同时监测大量NV色心，并进行亚衍射分辨率的空间分布统计分析。

Result: 发现了NV色心并非随机分布，而是存在聚集现象，特别是双个或多个NV色心组成的紧密团簇的出现频率异常高，表明存在非泊松分布的形成动力学和空间相关的缺陷生成机制。

Conclusion: 所提出的方法不仅能深入了解金刚石生长和NV色心形成机制，还能大规模识别天然NV色心团簇，这些团簇在量子信息和传感领域具有应用前景，并为单发射极级别的材料结构和电子缺陷分析提供了途径。

Abstract: The sharp optical resonances of NV- centers in diamond at cryogenic
temperatures offer powerful new capabilities for material characterization, but
extracting the most detailed information typically requires careful calibration
of individual sensors, limiting scalability. In this work, we use resonant
photoluminescence excitation imaging to optically resolve and monitor hundreds
of individual NVs across large fields of view, enabling statistical analysis of
their spatial distribution with sub-diffraction resolution. This multiplexed,
non-destructive approach allows quantum sensors to characterize the material
platform they inhabit. Focusing on CVD-grown diamond, we uncover significant
deviations from random distributions, including an unexpectedly high occurrence
of closely spaced clusters comprising two or more NVs. These findings suggest
non-Poissonian formation dynamics and point to spatially correlated defect
generation mechanisms. Beyond offering insight into diamond growth and NV
center formation, our approach enables the scalable identification of naturally
occurring NV clusters - configurations that are promising for
entanglement-assisted quantum information protocols and correlated sensing -
and establishes a path toward structural and electronic defect analysis in
various material hosts at the single-emitter level.

</details>


### [300] [Structural characterization and bonding energy analysis for plasma-activated bonding of SiCN films: A reactive molecular dynamics study](https://arxiv.org/abs/2511.03476)
*Juheon Kim,Minki Jang,Junhyeok Park,Byungjo Kim,Hayoung Chung*

Main category: cond-mat.mtrl-sci

TL;DR: 等离子体激活的 SiCN 薄膜键合具有高键合强度，但键合性能与成分和等离子体参数的关系尚不明确。本研究采用原子尺度模拟，研究了 SiCN-SiCN 等离子体激活键合，并建立了材料-工艺-性能关系。


<details>
  <summary>Details</summary>
Motivation: 探索 SiCN 成分和等离子体处理参数与 SiCN-SiCN 等离子体激活键合界面键合性能之间的关系，以期为优化键合工艺提供指导。

Method: 利用反应分子动力学进行 O2 等离子体表面激活、表面羟基化、直接键合、键合后退火和脱键合模拟，研究 SiCN 成分和等离子体注入量对表面化学和形貌的影响，并通过原子牵引-分离响应评估键合能。

Result: SiCN 表面的结构表征（如共价键密度和粗糙度）显示出依赖于成分和等离子体注入量的化学和形貌改变。键合能与界面 Si-O-Si 密度呈正相关，而界面 Si-O-Si 密度则反映了化学和形貌改变的综合效应。

Conclusion: 成功阐明了键合能对成分和等离子体注入量的依赖关系，建立了原子尺度的材料-工艺-性能关系，为优化 SiCN 成分和等离子体处理参数提供了实际指导。

Abstract: Plasma-activated bonding of SiCN films offers high bonding strength at the
hybrid-bonding interface, thereby enhancing mechanical reliability. Although
experimental studies have shown that the interfacial bonding properties of SiCN
films vary with SiCN composition and plasma treatment parameters, a clear
correlation between these parameters and the resulting bonding properties has
not yet been established. This study presents an atomistic investigation of
SiCN-SiCN plasma-activated bonding with controlled SiCN composition and plasma
fluence, which performs O2 plasma surface activation, surface hydroxylation,
direct bonding, post-bonding annealing, and debonding using reactive molecular
dynamics. The structural characterization of the plasma-activated SiCN surface,
including density of various covalent bonds and surface roughness, exhibits
composition- and plasma fluence-dependent chemical and morphological
modification. Bonding energy evaluated from atomic traction-separation
responses in cohesive zone volume elements (CZVE) during debonding simulations
shows a positive correlation with the interfacial Si-O-Si density. Since the
interfacial Si-O-Si density reflects the combined effects of these chemical and
morphological modifications, the dependence of bonding energy on composition
and plasma fluence is successfully elucidated by the structural
characterization. These results establish an atomic-level
material-process-property relationship and offer practical guidance for
optimizing SiCN composition and plasma treatment parameters for SiCN-SiCN
plasma-activated bonding.

</details>


### [301] [Topological transition and emergent elasticity of dislocation in skyrmion lattice: Beyond Kittel's magnetic-polar analogy](https://arxiv.org/abs/2511.03504)
*Kohta Kasai,Akihiro Uematsu,Tatsuki Kawakane,Yu Wang,Tao Xu,Chang Liu,Susumu Minami,Takahiro Shimada*

Main category: cond-mat.mtrl-sci

TL;DR: 磁性斯格明子晶格中的位错具有核心分裂结构，与传统弹性理论一致，但与极性斯格明子晶格不同。


<details>
  <summary>Details</summary>
Motivation: 阐明磁性斯格明子晶格中位错的特征和作用，并与极性斯格明子晶格进行对比。

Method: 通过观察和分析磁性斯格明子位错的核心分裂结构、拉伸形变、拓扑转变以及其应变场，并与弹性理论进行对比。同时，通过能量分析研究了Dzyaloshinskii-Moriya相互作用对斯格明子形变的影响。

Result: 磁性斯格明子位错表现出核心分裂结构，形变可达180%，并发生拓扑转变。其长程应变场符合弹性理论，而极性斯格明子晶格则不符合。Dzyaloshinskii-Moriya相互作用是驱动形变的原因。

Conclusion: 磁性斯格明子晶格中的位错同时具有拓扑核心重构和鲁棒的长程弹性场，这与通常被认为相似的磁畴和电畴存在根本差异。

Abstract: Magnetic and polar skyrmions exhibit topologically protected quasiparticle
behavior, including emergent fields, deformation, and the formation of a
densely packed skyrmion lattice, beyond conventional domain configurations
described by Kittel's law. Analogous to atomic crystals, lattice defects,
especially dislocations and their associated strain fields, are crucial for
understanding the lattice behavior of skyrmions; however, their features and
roles remain insufficiently understood. Here, we show that magnetic skyrmion
dislocations develop a core-split structure due to a significant skyrmion
elongation up to 180% of their original length, reaching a topological
transition from a single skyrmion to two half-skyrmions. Despite such a
distinct structure, the long-range strain fields around the dislocation
perfectly obey conventional Volterra's elasticity theory, in contrast to polar
skyrmion lattices, where skyrmion deformations cause a breakdown of the
elasticity theory. Furthermore, an energetic analysis shows that
Dzyaloshinskii-Moriya interaction drives the large skyrmion deformation of the
dislocation core. Our findings not only clarify the coexistence of topological
core-reconstruction and a robust long-range elastic field of dislocations in
magnetic skyrmion lattices, but also reveal that magnetic and electric domains,
long regarded as dual and analogous, exhibit fundamental differences when
extended into the regime of collective topological quasiparticles.

</details>


### [302] [Real Chern Insulators in Two-Dimensional Altermagnetic Fe$_2$S$_2$O and Fe$_2$Se$_2$O](https://arxiv.org/abs/2511.03602)
*Yong-Kun Wang,Shifeng Qian,An-Dong Fan,Si Li*

Main category: cond-mat.mtrl-sci

TL;DR: Fe2S2O和Fe2Se2O单层被发现是二维交替磁实陈绝缘体，具有受对称性保护的零维角态，并对多种扰动具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管人们对交替磁体（AMs）日益感兴趣，但在本征交替磁系统中实现真正的陈绝缘体却很少见。本研究旨在识别具有此类特性的新型二维材料。

Method: 基于第一性原理计算和理论分析，研究了单层Fe2S2O和Fe2Se2O。

Result: 研究发现，单层Fe2S2O和Fe2Se2O具有交替磁基态，并表现出非平凡的镜面实陈数，从而产生受对称性保护的零维角态。这些角态具有自旋极化，并表现出独特的自旋-角耦合效应。此外，研究还表明，在存在自旋-轨道耦合以及单轴和双轴应变的情况下，实陈绝缘相及其相关的角态仍然是鲁棒的。这些材料还表现出显著的线性二向色性和强光吸收。

Conclusion: Fe2S2O和Fe2Se2O的发现揭示了它们新颖的拓扑特性，并使它们成为在交替磁系统中探索实陈绝缘体的一个有前途的平台。

Abstract: Altermagnets (AMs), recently identified as a third class of collinear
magnetic materials, have attracted significant attention in condensed matter
physics. Despite this growing interest, the realization of real Chern
insulators in intrinsic altermagnetic systems has rarely been reported. In this
work, based on first-principles calculations and theoretical analysis, we
identify monolayer Fe$_2$S$_2$O and Fe$_2$Se$_2$O as a novel class of
two-dimensional altermagnetic real Chern insulators. We demonstrate that these
materials possess altermagnetic ground states and host a nontrivial mirror real
Chern number, leading to the emergence of symmetry-protected zero-dimensional
corner states. Notably, these corner modes are spin-polarized, giving rise to a
unique spin-corner coupling effect. We further show that the real Chern
insulating phases and their associated corner states remain robust against
spin-orbit coupling, as well as under both uniaxial and biaxial strain.
Additionally, these materials exhibit pronounced linear dichroism and strong
optical absorption. Our findings uncover the novel topological character of
Fe$_2$S$_2$O and Fe$_2$Se$_2$O, establishing them as promising platforms for
exploring real Chern insulators in altermagnetic systems.

</details>


### [303] [pH-Responsive Glyphosate Adsorption on Hydroxylated Carbon Nanotubes: From Electronic Structure to Molecular Dynamics](https://arxiv.org/abs/2511.03615)
*H. T. Silva,L. C. S. Faria,T. A. Aversi-Ferreira,I. Camps*

Main category: cond-mat.mtrl-sci

TL;DR: 羟基官能化的碳纳米管能有效吸附不同电离状态的草甘膦，为环境修复提供了一种有前景的方法。


<details>
  <summary>Details</summary>
Motivation: 研究羟基官能化的碳纳米管（CNTs）对草甘膦的吸附机制，为环境修复提供新的途径。

Method: 使用半经验从头计算（xTB）软件，对不同羟基官能化程度（5-25%）的(10,0)锯齿形单壁碳纳米管与五种不同电离状态（G1-G5）的草甘膦之间的相互作用进行了分子几何优化、电子性质计算、量子化学原子理论（QTAIM）拓扑分析和300K分子动力学模拟。

Result: 羟基官能化显著提高了碳纳米管对草甘膦的吸附能力，随着羟基浓度和草甘膦去质子化程度的增加，结合能变得更负。电子耦合分析表明，20-25%的羟基官能化优化了电荷反应性和传输。拓扑表征确认了具有强共价贡献的给体-受体相互作用。分子动力学模拟显示官能化促进了纳米管表面的空间组织，增加了接触区域并降低了分子迁移率。中等相互作用的体系（CNT+OHx+G1和CNT+OHx+G3）具有环境和经济可行性。

Conclusion: 羟基官能化的碳纳米管在检测和捕获各种电离状态的草甘膦方面显示出巨大潜力，为环境监测和修复提供了有前景的解决方案，并且具有再生和重复使用的可行性。

Abstract: This computational study investigates glyphosate adsorption mechanisms on
hydroxyl-functionalized carbon nanotubes (CNTs) as an alternative approach for
environmental remediation. Single-walled CNTs with (10,0) zigzag chirality were
functionalized with hydroxyl groups at concentrations of 5-25% and evaluated
for interactions with glyphosate in five different ionization states (G1-G5)
corresponding to pH-dependent protonation. Using semi-empirical tight-binding
methods implemented in xTB software, molecular geometry optimization,
electronic property calculations, topological analyses via Quantum Theory of
Atoms in Molecules (QTAIM), and molecular dynamics simulations at 300K were
performed. Results demonstrate that functionalization significantly enhances
adsorption capacity, with binding energies becoming increasingly negative at
higher OH concentrations and with more deprotonated glyphosate forms (G4 and
G5). Electronic coupling analyses reveal optimized charge reactivity and
transport in systems with 20-25% OH functionalization. Topological
characterization identified 477 bond critical points, confirming donor-acceptor
interactions with strong covalent contributions, particularly in highly
functionalized systems. Radial distribution function profiles from molecular
dynamics simulations demonstrate that functionalization promotes spatial
organization on nanotube surfaces, increasing contact regions and reducing
molecular mobility. Systems with moderate interactions (CNT+OHx+G1 and
CNT+OHx+G3) present environmentally and economically viable solutions, enabling
adsorbent regeneration and reuse. The findings indicate that OH-functionalized
carbon nanotubes show significant promise for glyphosate detection and capture
applications in environmental monitoring and remediation, regardless of the
pesticide's ionization state.

</details>


### [304] [Efficient GPU Parallelization of Electronic Transport and Nonequilibrium Dynamics from Electron-Phonon Interactions in the Perturbo Code](https://arxiv.org/abs/2511.03683)
*Shiyu Peng,Donnie Pinkston,Jia Yao,Sergei Kliavinek,Ivan Maliyov,Marco Bernardi*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究使用 GPU 加速了第一性原理计算的电子-声子相互作用的玻尔兹曼输运方程（BTE）计算，实现了 40 倍的加速，并为未来大规模计算提供了基础。


<details>
  <summary>Details</summary>
Motivation: 计算电子-声子（e-ph）相互作用的玻尔兹曼输运方程（BTE）中的碰撞积分在材料电子输运和非平衡动力学研究中至关重要，但计算成本高昂，限制了对大单胞材料和高动量空间分辨率的研究。因此，需要一种更高效的计算方法。

Method: 本研究提出了一种新颖的 GPU 数据结构和算法，使用 OpenACC 针对 GPU 硬件进行了优化，以高效计算碰撞积分。该方法显著减少了数据引用、移动和同步的开销，并结合了 MPI+OpenMP+GPU 并行化。

Result: 与基于 CPU 的 Perturbo (v2.2.0) 相比，该 GPU 实现将电子输运和非平衡动力学的计算速度提高了 40 倍，并且在多达 100 个 GPU 上实现了近乎线性的扩展。新提出的数据结构可以推广到其他电子相互作用和散射过程。

Conclusion: 通过引入 GPU 加速和优化的数据结构与算法，大大提高了 BTE 计算的效率，使得对电子-声子相互作用和电子动力学进行广泛研究成为可能，并为 Perturbo 在未来百亿亿次计算平台上做好准备。

Abstract: The Boltzmann transport equation (BTE) with electron-phonon (e-ph)
interactions computed from first principles is widely used to study electronic
transport and nonequilibrium dynamics in materials. Calculating the e-ph
collision integral is the most important step in the BTE, but it remains
computationally costly, even with current MPI+OpenMP parallelization. This
challenge makes it difficult to study materials with large unit cells and to
achieve high resolution in momentum space. Here, we show acceleration of BTE
calculations of electronic transport and ultrafast dynamics using graphical
processing units (GPUs). We implement a novel data structure and algorithm,
optimized for GPU hardware and developed using OpenACC, to process scattering
channels and efficiently compute the collision integral. This approach
significantly reduces the overhead for data referencing, movement, and
synchronization. Relative to the efficient CPU implementation in the
open-source package Perturbo (v2.2.0), used as a baseline, this approach
achieves a speed-up of 40 times for both transport and nonequilibrium dynamics
on GPU hardware, and achieves nearly linear scaling up to 100 GPUs. The novel
data structure can be generalized to other electron interactions and scattering
processes. We released this GPU implementation in the latest public version
(v3.0.0) of Perturbo. The new MPI+OpenMP+GPU parallelization enables sweeping
studies of e-ph physics and electron dynamics in conventional and quantum
materials, and prepares Perturbo for exascale supercomputing platforms.

</details>


### [305] [Intercalation induced quasi-freestanding layer in TiSe$_2$](https://arxiv.org/abs/2511.03712)
*Turgut Yilmaz,Yi Sheng Ng,Anil Rajapitamahuni,Asish Kundu,Hui-Qiong Wang,Jin-Cheng Zheng,Elio Vescovo*

Main category: cond-mat.mtrl-sci

TL;DR: K掺杂TiSe2导致导带分裂，形成准自由层，并抑制了晶格畸变。


<details>
  <summary>Details</summary>
Motivation: 研究K掺杂对TiSe2电子结构的影响。

Method: 采用角分辨光电子能谱和密度泛函理论计算。

Result: 观察到导带分裂成两个支，在低温下分裂能增大；一个支表现为非色散二维特征，另一个支表现为三维体带色散特征；K掺杂主要占据范德华间隙位点；掺杂抑制了表面区域的周期性晶格畸变。

Conclusion: 通过插层法可以调控1T-TiSe2的维度和本征电子性质。

Abstract: Angle-resolved photoemission spectroscopy is employed to study the electronic
structure of bulk TiSe2 before and after doping with potassium impurities. A
splitting in the conduction band into two branches is observed after
room-temperature deposition. The splitting energy increases to approximately
130 meV when the sample is cooled to 40 K. One branch exhibits a non-dispersive
two-dimensional feature, while other one shows the characteristics of three
dimensional bulk band dispersion. Core level spectroscopy suggests that the K
impurities predominantly occupy the intercalated sites within the van derWaals
gap. The results indicate the formation of a quasi-freestandingTiSe2 layer.
Additionally, doping completely suppresses the periodic lattice distortion in
the surface region. These findings are further supported by density functional
theory calculations, which compare the band structure of monolayer and bulk
TiSe2 with experimental data. Thus, the dimensional and intrinsic electronic
properties of 1T-TiSe2 can be controlled through the intercalation procedure
used in this work.

</details>


### [306] [Magnetism and Peierls distortion in Dirac semimetal CaMnBi$_2$](https://arxiv.org/abs/2511.03721)
*Aashish Sapkota,Niraj Aryal,Xiao Hu,Masaaki Matsuda,Yan Wu,Guangyong Xu,John M. Wilde,Andreas Kreyssig,Paul C. Canfield,Cedomir Petrovic,John M. Tranquada,Igor A. Zaliznyak*

Main category: cond-mat.mtrl-sci

TL;DR: CaMnBi2在46K时发生耦合的结构和磁性对称性降低转变，从 tetragonal 相变为 orthorhombic 相，伴随着 Bi-Bi 键的锯齿状键序波调制，这与 Peierls 型不稳定性一致，而不是自旋倾斜或弱铁磁性。


<details>
  <summary>Details</summary>
Motivation: 研究CaMnBi2在50K以下异常现象的起源，以确定其是否由时间反演对称性破坏和外尔半金属态引起。

Method: 使用偏振和非偏振中子衍射、X射线衍射和密度泛函理论（DFT）计算来阐明晶体和磁结构。

Result: CaMnBi2在T*=46(2)K时发生耦合的结构和磁性对称性降低转变，从具有C型反铁磁性的四方晶格转变为具有晶胞沿c轴加倍的斜方晶系相。没有检测到可测量的均匀Mn自旋倾斜。观察到Bi-Bi键的锯齿状键序波（BOW）调制，与Peierls型不稳定性一致。

Conclusion: CaMnBi2在低温下的异常现象是由结构和磁性转变引起的，并伴有键序波调制，这与Peierls型不稳定性一致，而不是由自旋倾斜引起的时间反演对称性破坏。

Abstract: Dirac semimetals of the form $A$Mn$X_2$ ($A =$ alkaline-earth or divalent
rare earth; $X =$ Bi, Sb) host conducting square-net Dirac-electron layers of
$X$ atoms interleaved with antiferromagnetic Mn$X$ layers. In these materials,
canted antiferromagnetism can break time-reversal symmetry (TRS) and produce a
Weyl semimetallic state. CaMnBi$_2$ was proposed to realize this behavior below
$T^{*}\sim 50$ K, where anomalies in resistivity and optical conductivity were
reported. We investigate single-crystal CaMnBi$_{2}$ using polarized and
unpolarized neutron diffraction, x-ray diffraction, and density functional
theory (DFT) calculations to elucidate the underlying crystal and magnetic
structures. The results show that the observed anomalies do not originate from
spin canting or weak ferromagnetism; no measurable uniform Mn spin canting is
detected. Instead, CaMnBi$_2$ undergoes a coupled structural and magnetic
symmetry-lowering transition at $T^{*} = 46(2)$ K, from a tetragonal lattice
with C-type antiferromagnetism to an orthorhombic phase with unit-cell doubling
along the $c$ axis and minimal impact on magnetism. Analysis of superlattice
peak intensities and lattice distortion reveals a continuous second-order
transition governed by a single order parameter. The refined atomic
displacements correspond to a zigzag bond-order-wave (BOW) modulation of Bi-Bi
bonds, consistent with an electronically driven Peierls-type instability in the
Dirac-electron Bi layer, long anticipated by Hoffmann and co-workers [W.~Tremel
and R.~Hoffmann, \textit{J. Am. Chem. Soc.} \textbf{109}, 124 (1987);
G.~A.~Papoian and R.~Hoffmann, \textit{Angew. Chem. Int. Ed.} \textbf{39}, 2408
(2000)]. %\textcite{TremelHoffman_JACS1987} [JACS {\bf 109}, 124 (1987)].

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [307] [LogicSparse: Enabling Engine-Free Unstructured Sparsity for Quantised Deep-learning Accelerators](https://arxiv.org/abs/2511.03079)
*Changhong Li,Biswajit Basu,Shreejith Shanker*

Main category: cs.AR

TL;DR: FPGA上的量化神经网络(QNN)在速度、延迟和能效方面表现优异，但现代深度学习模型的复杂性限制了其在资源受限的边缘设备的性能。本研究提出了一个将非结构化稀疏性嵌入数据流加速器的方法，无需专门的稀疏引擎即可保留并行性，并结合硬件感知剪枝策略，在LeNet-5上实现了51.6倍的压缩和1.23倍的吞吐量提升，同时仅使用5.12%的LUTs。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型在资源受限的边缘设备上性能受限，非结构化稀疏性由于访问不规律而未被充分利用。

Method: 提出一个将非结构化稀疏性嵌入数据流加速器的框架，无需专用稀疏引擎，并采用硬件感知剪枝策略。

Result: 在LeNet-5上实现了51.6倍的压缩和1.23倍的吞吐量提升，仅使用5.12%的LUTs。

Conclusion: 所提出的框架能够有效地利用非结构化稀疏性来加速QNN在FPGA上的部署。

Abstract: FPGAs have been shown to be a promising platform for deploying Quantised
Neural Networks (QNNs) with high-speed, low-latency, and energy-efficient
inference. However, the complexity of modern deep-learning models limits the
performance on resource-constrained edge devices. While quantisation and
pruning alleviate these challenges, unstructured sparsity remains
underexploited due to irregular memory access. This work introduces a framework
that embeds unstructured sparsity into dataflow accelerators, eliminating the
need for dedicated sparse engines and preserving parallelism. A hardware-aware
pruning strategy is introduced to improve efficiency and design flow further.
On LeNet-5, the framework attains 51.6 x compression and 1.23 x throughput
improvement using only 5.12% of LUTs, effectively exploiting unstructured
sparsity for QNN acceleration.

</details>


### [308] [An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM](https://arxiv.org/abs/2511.03203)
*Deyang Yu,Chenchen Liu,Chuanjie Zhang,Xiao Fang,Weisheng Zhao*

Main category: cs.AR

TL;DR: 本工作提出了一种基于自旋轨道矩磁随机存取存储器（SOT-MRAM）的事件驱动计算内存（CIM）宏，通过采用混合串并联单元结构和轻量级脉冲编码电路，实现了高能效的矩阵向量乘法（MVM），峰值能效达243.6 TOPS/W，显著优于现有设计。


<details>
  <summary>Details</summary>
Motivation: 现有的计算内存（CIM）设计，尤其是基于磁随机存取存储器（MRAM）的设计，由于依赖复杂的模拟电路进行计算，通常面临能耗高的问题。

Method: 提出了一种基于SOT-MRAM的CIM宏，该宏采用事件驱动的脉冲处理方式以实现高能效。SOT-MRAM交叉阵列采用了混合串并联单元结构来支持矩阵向量乘法（MVM）。信号信息通过轻量级电路进行脉冲编码（或解码），无需使用传统上占地面积大、功耗高的模拟电路。该SOT-MRAM宏在28nm工艺下进行了设计和评估。

Result: 在28nm工艺下，该SOT-MRAM CIM宏实现了243.6 TOPS/W的峰值能效，显著优于现有设计。

Conclusion: 本工作提出的SOT-MRAM CIM宏通过采用事件驱动的脉冲处理和混合单元结构，有效解决了现有CIM设计能耗高的问题，达到了优异的能效表现。

Abstract: The application of Magnetic Random-Access Memory (MRAM) in
computing-in-memory (CIM) has gained significant attention. However, existing
designs often suffer from high energy consumption due to their reliance on
complex analog circuits for computation. In this work, we present a Spin-Orbit-
Torque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking
processing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid
series-parallel cell structure to efficiently support matrix-vector
multiplication (MVM). Signal information is (en) decoded as spikes using
lightweight circuits, eliminating the need for conventional area- and
powerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in
28nm technology, and experimental results show that it achieves a peak energy
efficiency of 243.6 TOPS/W, significantly outperforming existing designs.

</details>


### [309] [Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics](https://arxiv.org/abs/2511.03427)
*Florentia Afentaki,Maha Shatta,Konstantinos Balaskas,Georgios Panagopoulos,Georgios Zervakis,Mehdi B. Tahoori*

Main category: cs.AR

TL;DR: 该研究提出了首个柔性电子（FE）平台上的混合核和混合信号支持向量机（SVM）设计，以解决现有SVM设计在硬件成本和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有柔性电子（FE）技术的集成密度受限于其较大的特征尺寸，导致功耗和面积受限，阻碍了机器学习（ML）电路的应用。而支持向量机（SVM）在近传感器应用中具有高精度和相对较低的计算复杂度，符合FE技术的限制。然而，现有的SVM设计仅限于线性或径向基函数（RBF）核，存在硬件成本和准确性之间的权衡：线性核（数字实现）开销小但性能差，而RBF核（数字实现）成本高，模拟实现则存在函数逼近的固有误差。

Method: 提出了一种混合核和混合信号的SVM设计，结合了线性和RBF核的优势，并通过联合优化方法进行训练，将二元SVM分类器映射到合适的核（线性/RBF）和域（数字/模拟），以最大化准确性并减少昂贵的RBF分类器的数量。

Result: 与最先进的单一核线性SVM相比，该设计实现了7.7%的更高准确性。与数字RBF实现相比，平均面积和功耗分别降低了108倍和17倍。

Conclusion: 所提出的混合核和混合信号SVM设计能够有效地平衡成本和准确性，并在柔性电子平台上实现了优于现有技术的性能。

Abstract: Flexible Electronics (FE) have emerged as a promising alternative to
silicon-based technologies, offering on-demand low-cost fabrication,
conformality, and sustainability. However, their large feature sizes severely
limit integration density, imposing strict area and power constraints, thus
prohibiting the realization of Machine Learning (ML) circuits, which can
significantly enhance the capabilities of relevant near-sensor applications.
Support Vector Machines (SVMs) offer high accuracy in such applications at
relatively low computational complexity, satisfying FE technologies'
constraints. Existing SVM designs rely solely on linear or Radial Basis
Function (RBF) kernels, forcing a trade-off between hardware costs and
accuracy. Linear kernels, implemented digitally, minimize overhead but
sacrifice performance, while the more accurate RBF kernels are prohibitively
large in digital, and their analog realization contains inherent functional
approximation. In this work, we propose the first mixed-kernel and mixed-signal
SVM design in FE, which unifies the advantages of both implementations and
balances the cost/accuracy trade-off. To that end, we introduce a
co-optimization approach that trains our mixed-kernel SVMs and maps binary SVM
classifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),
aiming to maximize accuracy whilst reducing the number of costly RBF
classifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art
single-kernel linear SVMs, and reduce area and power by 108x and 17x on average
compared to digital RBF implementations.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [310] [NF-SecRIS: RIS-Assisted Near-Field Physical Layer Security via Secure Location Modulation](https://arxiv.org/abs/2511.02949)
*Zhendong Wang,Chenyang Meng,Jun Yang,Jiayuan Wang,Yin Li,Linshan Jiang,Jin Zhang*

Main category: cs.ET

TL;DR: 提出了一种名为NF-SecRIS的通信系统，实现了6G网络下近场通信的二维物理层安全（包括距离和角度维度），解决了现有技术只能实现单维度安全的问题。该系统基于超大规模可重构智能表面（RIS），采用低复杂度的安全定位调制方案，确保合法用户接收原始信号，窃听者接收模糊信号，且无需与收发器同步。


<details>
  <summary>Details</summary>
Motivation: 现有6G通信在物理层安全方面存在局限，通常只能在角度维度上实现安全，而无法在距离维度上实现安全。

Method: 提出NF-SecRIS系统，该系统基于超大规模可重构智能表面（RIS），并提出安全定位调制方案，以在近场通信中实现二维（距离和角度）物理层安全。

Result: 实验证明，NF-SecRIS系统能够为合法用户提供低于10^{-4}的误比特率（BER），同时使处于其他距离或角度的窃听者遭受超过40%的BER。

Conclusion: NF-SecRIS系统成功在近场通信中实现了二维物理层安全，解决了现有技术的不足，并通过原型验证了其有效性。

Abstract: The 6G wireless networks impose extremely high requirements on physical layer
secure communication. However, the existing solutions usually can only achieve
one-dimensional physical layer security (PLS) in the angle dimension, and
cannot achieve PLS in the range dimension. In this paper, we propose the
NF-SecRIS system, the first range-angle-dependent (2D) PLS near-field
communication system based on ultra-large-scale reconfigurable intelligent
surface (RIS). We propose the secure location modulation scheme to synthesize
the near-field spatial-temporal coding pattern of RIS with extremely low
complexity. It ensures that only legitimate user can receive the raw
constellations, while potential eavesdroppers at other ranges or angles can
only receive the obfuscated constellations. NF-SecRIS operates without
requiring synchronization with either transmitter or receiver. We implement a
prototype of NF-SecRIS and conduct comprehensive experiments with multiple
modulation schemes. The results show that the bit error rate (BER) of
legitimate user is below 10^{-4}, while eavesdroppers at other ranges or angles
suffer from BER exceeding 40%. It validates the implementation of 2D PLS in
near-field communications.

</details>


### [311] [QAGT-MLP: An Attention-Based Graph Transformer for Small and Large-Scale Quantum Error Mitigation](https://arxiv.org/abs/2511.03119)
*Seyed Mohamad Ali Tousi,G. N. DeSouza*

Main category: cs.ET

TL;DR: QAGT-MLP是一种新的量子纠错方法，它使用图变换器来编码量子电路，并通过注意机制提取特征，在处理大型量子电路时表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的量子纠错方法要么复杂且耗时，要么难以扩展到大型量子电路。因此，需要一种简单、高效且可扩展的量子纠错技术。

Method: QAGT-MLP将量子电路编码为图，并使用双路径注意模块提取全局和局部特征。这些特征与电路描述符和噪声期望值结合，通过轻量级MLP预测噪声消除后的值。

Result: 在100量子比特的TFIM电路上，QAGT-MLP在平均误差和误差变异性方面优于最先进的学习基线，证明了其在实际量子纠错场景中的有效性和适用性。

Conclusion: QAGT-MLP通过融合全局结构和局部邻域信息，在不增加计算成本的情况下实现了高质量的量子纠错，为现代和未来的量子计算提供了可扩展的解决方案。

Abstract: Noisy quantum devices demand error-mitigation techniques to be accurate yet
simple and efficient in terms of number of shots and processing time. Many
established approaches (e.g., extrapolation and quasi-probability cancellation)
impose substantial execution or calibration overheads, while existing
learning-based methods have difficulty scaling to large and deep circuits. In
this research, we introduce QAGT-MLP: an attention-based graph transformer
tailored for small- and large-scale quantum error mitigation (QEM). QAGT-MLP
encodes each quantum circuit as a graph whose nodes represent gate instances
and whose edges capture qubit connectivity and causal adjacency. A dual-path
attention module extracts features around measured qubits at two scales or
contexts: 1) graph-wide global structural context; and 2) fine-grained local
lightcone context. These learned representations are concatenated with
circuit-level descriptor features and the circuit noisy expected values, then
they are passed to a lightweight MLP to predict the noise-mitigated values. On
large-scale 100-qubit Trotterized 1D Transverse-Field Ising Models -- TFIM
circuits -- the proposed QAGT-MLP outperformed state-of-the-art learning
baselines in terms of mean error and error variability, demonstrating strong
validity and applicability in real-world QEM scenarios under matched shot
budgets. By using attention to fuse global structures with local lightcone
neighborhoods, QAGT-MLP achieves high mitigation quality without the increasing
noise scaling or resource demand required by classical QEM pipelines, while
still offering a scalable and practical path to QEM in modern and future
quantum workloads.

</details>


### [312] [LLM-enhanced Air Quality Monitoring Interface via Model Context Protocol](https://arxiv.org/abs/2511.03706)
*Yu-Erh Pan,Ayesha Siddika Nipu*

Main category: cs.ET

TL;DR: AMI是一个结合了实时传感器数据和对话界面的LLM增强型空气监测界面，通过MCP协议减少幻觉风险，提供准确、上下文感知的响应。


<details>
  <summary>Details</summary>
Motivation: 传统空气质量监测系统因可视化复杂、交互性有限和部署成本高，难以供非专业用户使用；LLM虽然能使传感器数据更易于访问，但其易产生幻觉的特性限制了在安全关键领域的可靠性。

Method: 结合Django后端、响应式用户仪表板和安全MCP服务器，将实时传感器数据与对话界面集成，使LLM能主动操作而非被动响应。

Result: 专家评估显示，AMI在事实准确性（4.78）、完整性（4.82）和幻觉数量（4.84）（满分5分）方面表现优异，并有信际评估者信度分析支持。

Conclusion: 将LLM与标准化工具协议相结合，能够创建可靠、安全且用户友好的实时环境监测界面。

Abstract: Air quality monitoring is central to environmental sustainability and public
health, yet traditional systems remain difficult for non-expert users to
interpret due to complex visualizations, limited interactivity, and high
deployment costs. Recent advances in Large Language Models (LLMs) offer new
opportunities to make sensor data more accessible, but their tendency to
produce hallucinations limits reliability in safety-critical domains. To
address these challenges, we present an LLM-enhanced Air Monitoring Interface
(AMI) that integrates real-time sensor data with a conversational interface via
the Model Context Protocol (MCP). Our system grounds LLM outputs in live
environmental data, enabling accurate, context-aware responses while reducing
hallucination risk. The architecture combines a Django-based backend, a
responsive user dashboard, and a secure MCP server that exposes system
functions as discoverable tools, allowing the LLM to act as an active operator
rather than a passive responder. Expert evaluation demonstrated high factual
accuracy (4.78), completeness (4.82), and minimal hallucinations (4.84), on a
scale of 5, supported by inter-rater reliability analysis. These results
highlight the potential of combining LLMs with standardized tool protocols to
create reliable, secure, and user-friendly interfaces for real-time
environmental monitoring.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [313] [The electron double-slit experiment from an ISP perspective](https://arxiv.org/abs/2511.02863)
*David LeBlond*

Main category: quant-ph

TL;DR: 本研究提出了一种基于不可分割随机过程的电子双缝实验教学模型及配套R代码，该模型提供了一种理解量子概率和相干现象的替代视角，强调统计而非纯粹的波动力学解释。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提供一种新的教学模型来解释电子双缝实验，特别是从不可分割随机过程的角度，强调统计解释而非传统的波动力学解释。

Method: 本研究提出的方法是构建一个电子双缝实验的教学模型，并使用R语言实现，该模型基于不可分割随机过程的视角。

Result: 研究结果是提出了一种新的教学模型和相应的R代码，该模型能够从随机过程的角度解释量子概率和相干现象。

Conclusion: 本研究的结论是，从不可分割随机过程的角度来解释电子双缝实验，为理解量子现象提供了一种有价值的替代方法，强调了统计解释的重要性。

Abstract: This paper presents a pedagogical model, and accompanying R code, of the
electron double-slit experiment using the perspective of indivisible stochastic
processes. The approach offers an alternative lens on quantum probability and
coherence phenomena, emphasizing a statistical rather than purely
wave-mechanical interpretation.

</details>


### [314] [Clifford Hierarchy Stabilizer Codes: Transversal Non-Clifford Gates and Magic](https://arxiv.org/abs/2511.02900)
*Ryohei Kobayashi,Guanyu Zhu,Po-Shen Hsin*

Main category: quant-ph

TL;DR: 本论文将拓扑保稳码推广至n维克利福层级保稳码，并构造了横贯的非克利福逻辑门，解决了通用性与维度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决容错量子计算中通用性与维度之间的权衡问题，特别是Bravyi-König界限对n维拓扑稳定码的限制。

Method: 将拓扑保稳码扩展到n维克利福层级保稳码，利用自同构对称性（杯积）构造横贯的非克利福逻辑门，并结合即时解码器进行容错态制备。

Result: 在2D中，首次为克利福稳定码构造了包括T和CS在内的横贯非克利福逻辑门，并实现了逻辑T魔态的容错制备；在3D中，构造了第三层克利福层级中的横贯逻辑$\"	ext{T}\"$门，并提出了一种可能避免2D中权衡的方法。

Conclusion: 提出了将Bravyi-König界限推广至克利福层级稳定码的猜想，并给出了实现N层克利福层级逻辑门所需最小空间维度的上界为(N-1)。

Abstract: A fundamental problem in fault-tolerant quantum computation is the tradeoff
between universality and dimensionality, exemplified by the the Bravyi-K\"onig
bound for $n$-dimensional topological stabilizer codes. In this work, we extend
topological Pauli stabilizer codes to a broad class of $n$-dimensional Clifford
hierarchy stabilizer codes. These codes correspond to the $(n+1)$D
Dijkgraaf-Witten gauge theories with non-Abelian topological order. We
construct transversal non-Clifford gates through automorphism symmetries
represented by cup products. In 2D, we obtain the first transversal
non-Clifford logical gates including T and CS for Clifford stabilizer codes,
using the automorphism of the twisted $\mathbb{Z}_2^3$ gauge theory (equivalent
to $\mathbb{D}_4$ topological order). We also combine it with the just-in-time
decoder to fault-tolerantly prepare the logical T magic state in $O(d)$ rounds
via code switching. In 3D, we construct a transversal logical $\sqrt{\text{T}}$
gate in a non-Clifford stabilizer code at the third level of the Clifford
hierarchy, located on a tetrahedron corresponding to a twisted $\mathbb{Z}_2^4$
gauge theory. Due to the potential single-shot code-switching properties of
these codes, one could achieve the 4th level of Clifford hierarchy with an
$O(d^3)$ space-time overhead, avoiding the tradeoff observed in 2D. We propose
a conjecture extending the Bravyi-K\"onig bound to Clifford hierarchy
stabilizer codes, with our explicit constructions providing an upper bound of
spatial dimension $(N-1)$ for achieving the logical gates in the
$N^\text{th}$-level of Clifford hierarchy.

</details>


### [315] [Zero-Noise Extrapolation via Cyclic Permutations of Quantum Circuit Layouts](https://arxiv.org/abs/2511.02901)
*Zahar Sayapin,Daniil Rabinovich,Nikita Korolev,Kirill Lakhmanskiy*

Main category: quant-ph

TL;DR: CLP-ZNE是一种新颖的量子噪声外推协议，通过利用量子比特布局的周期性排列来减少所需的测量次数，从而提高NISQ设备的噪声缓解效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高当前量子计算机的可用性，需要开发有效的错误缓解方法，同时考虑NISQ设备的约束。

Method: 提出了一种基于循环布局排列的零噪声外推（CLP-ZNE）协议，该协议利用了量子线路的对称性，通过对循环线路布局排列进行平均，并推断出零噪声下的期望值。

Result: 与以前的基于布局排列的方法相比，CLP-ZNE所需的线路布局测量次数仅为O(n)，并且在模拟IBM的Torino量子计算机的噪声通道时，将期望值误差减小了一个数量级。

Conclusion: CLP-ZNE通过利用硬件的非均匀门错误和量子线路的对称性，能够有效地缓解NISQ设备的噪声，并且具有实际应用价值。

Abstract: Increasing the utility of currently available Noisy Intermediate-Scale
Quantum (NISQ) devices requires developing efficient methods to mitigate
hardware errors, taking into account the constraints of these devices such as
medium number of qubits and limited connectivity between them. In this work we
propose a novel Cyclic Layout Permutations based Zero Noise Extrapolation
(CLP-ZNE) protocol for such a task. The method leverages the inherent
non-uniformity of gate errors in NISQ hardware and exploits symmetries of
quantum circuits with one-dimensional connectivity to extrapolate the
expectation value, averaged over cyclic circuit layout permutations, to the
level of zero noise. In contrast to the previous layout permutation based
approaches, for $n$ qubit circuit CLP-ZNE requires measurements of only $O(n)$
different circuit layouts to reconstruct the noiseless expected value. When
benchmarked against noise channels modeling the IBM Torino quantum computer,
the method reduces a typical expectation value error by an order of magnitude,
depending on the protocol specifications. By employing a noise model derived
from real hardware specifications, including both depolarizing and $T_1/T_2$
relaxation processes, these results give evidence for the applicability of
CLP-ZNE to present-day NISQ processors.

</details>


### [316] [Classical shadows for sample-efficient measurements of gauge-invariant observables](https://arxiv.org/abs/2511.02904)
*Jacob Bringewatt,Henry Froland,Andreas Elben,Niklas Mueller*

Main category: quant-ph

TL;DR: 该研究提出了三种针对具有局部（或规范）对称性的量子系统的经典代码协议，以有效估计规范不变的可观测量。


<details>
  <summary>Details</summary>
Motivation: 利用量子系统（特别是格子规范理论模型）的先验知识（如对称性）来提高经典代码协议的样本效率。

Method: 开发了三种针对具有局部（或规范）对称性的系统的经典代码协议，并使用Z2格子规范理论进行了演示。

Result: 提出的协议在样本复杂度方面可以比不考虑对称性的方法获得指数级改进，但电路复杂度会增加。

Conclusion: 该工作为在具有对称性的量子系统中有效估计规范不变的可观测量提供了新的方法，并分析了样本复杂度和电路复杂度之间的权衡。

Abstract: Classical shadows provide a versatile framework for estimating many
properties of quantum states from repeated, randomly chosen measurements
without requiring full quantum state tomography. When prior information is
available, such as knowledge of symmetries of states and operators, this
knowledge can be exploited to significantly improve sample efficiency. In this
work, we develop three classical shadow protocols tailored to systems with
local (or gauge) symmetries to enable efficient prediction of gauge-invariant
observables in lattice gauge theory models which are currently at the forefront
of quantum simulation efforts. For such models, our approaches can offer
exponential improvements in sample complexity over symmetry-agnostic methods,
albeit at the cost of increased circuit complexity. We demonstrate these
trade-offs using a $\mathbb{Z}_2$ lattice gauge theory, where a dual
formulation enables a rigorous analysis of resource requirements, including
both circuit depth and sample complexity.

</details>


### [317] [Analytically Continuing the Randomized Measurement Toolbox](https://arxiv.org/abs/2511.02912)
*Akash Vijay,Ayush Raj,Jonah Kudler-Flam,Benoît Vermersch,Andreas Elben,Laimei Nie*

Main category: quant-ph

TL;DR: 该研究提出了一种名为“稳定解析延拓”（SAC）的新方法，用于从嘈杂的量子实验数据中提取密度矩阵的非多项式解析函数，并成功应用于量子模拟器。


<details>
  <summary>Details</summary>
Motivation: 从存在统计噪声的量子实验数据中提取密度矩阵的非多项式解析函数，特别是用于计算量子信息领域中的重要度量，如纠缠熵。

Method: 提出并实现了一种名为“稳定解析延拓”（SAC）的分析方法，该方法通过解析延拓技术，并特别优化以抵抗有限重复次数的量子实验中产生的统计噪声。该方法被用于从Rényi熵估计值中提取冯·诺依曼熵。

Result: 成功地从数值模拟的淬灭Néel态的Rényi熵估计中提取了冯·诺依曼纠缠熵，并将其应用于真实世界的基于离子阱的量子模拟器，提取了不同演化时间下的子系统冯·诺依曼熵。

Conclusion: SAC框架能够稳健地从嘈杂的量子实验数据中提取非多项式解析函数，并且可以推广到计算其他非线性诊断量，如负度量和Rényi相对熵。

Abstract: We develop a framework for extracting non-polynomial analytic functions of
density matrices in randomized measurement experiments by a method of
analytical continuation. A central advantage of this approach, dubbed
stabilized analytic continuation (SAC), is its robustness to statistical noise
arising from finite repetitions of a quantum experiment, making it well-suited
to realistic quantum hardware. As a demonstration, we use SAC to estimate the
von Neumann entanglement entropy of a numerically simulated quenched N\'eel
state from R\'enyi entropies estimated via the randomized measurement protocol.
We then apply the method to experimental R\'enyi data from a trapped-ion
quantum simulator, extracting subsystem von Neumann entropies at different
evolution times. Finally, we briefly note that the SAC framework is readily
generalizable to obtain other nonlinear diagnostics, such as the logarithmic
negativity and R\'enyi relative entropies.

</details>


### [318] [Correlation Self-Testing of Quantum Theory against Generalised Probabilistic Theories with Restricted Relabelling Symmetry](https://arxiv.org/abs/2511.02914)
*Kuntal Sengupta,Mirjam Weilenmann,Roger Colbeck*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子关联自检验方法，用于排除具有特定状态空间结构的广义概率论。


<details>
  <summary>Details</summary>
Motivation: 先前的研究通过在双边状态空间中引入旋转对称性来排除某些广义概率论。本研究旨在排除那些缺乏这种对称性的理论。

Method: 通过将所有局部状态和有限数量的非局部状态的凸包结合起来，构建了具有非正则状态空间结构的理论。引入了组合一致性标准，要求测量效应必须是某个测量的一部分。

Result: 证明了量子理论在自适应 CHSH 游戏中优于这些新构建的理论，从而在实验上排除了它们。此外，还揭示了组合一致性与 Tsirelson 界的联系。

Conclusion: 本研究为排除更广泛的广义概率论提供了新的工具，并为理解量子关联的独特性提供了更深入的见解。

Abstract: Correlation self-testing of quantum theory involves identifying a task or set
of tasks whose optimal performance can be achieved only by theories that can
realise the same set of correlations as quantum theory in every causal
structure. Following this approach, previous work has ruled out various classes
of generalised probabilistic theories whose joint state spaces have a certain
regularity in the sense of a (discrete) rotation symmetry of the bipartite
state spaces. Here we consider theories whose bipartite state spaces lack this
regularity. We form them by taking the convex hull of all the local states and
a finite number of non-local states. We show that a criterion of compositional
consistency is needed in such theories: for a measurement effect to be valid,
there must exist at least one measurement that it is part of. This goes beyond
previous consistency criteria and corresponds to a strengthening of the
no-restriction hypothesis. We show that quantum theory outperforms these
theories in a task called the adaptive CHSH game, which shows that they can be
ruled out experimentally. We further show a connection between compositional
consistency and Tsirelson's bound.

</details>


### [319] [Motional entanglement in low-energy collisions near shape resonances](https://arxiv.org/abs/2511.02925)
*Yimeng Wang,Christiane P. Koch*

Main category: quant-ph

TL;DR: EPR悖论通过测量纠缠粒子对的位置或动量来讨论，本文通过三维空间中的双粒子散射相干计算来量化纠缠，发现标准平面波描述忽略了初始状态下的量子不确定性，而更实际的描述则显示纠缠与散射截面呈线性关系，并在形状共振附近显著增强，实验上可探测。


<details>
  <summary>Details</summary>
Motivation: EPR悖论中的纠缠粒子对的纠缠度量化问题。

Method: 通过三维空间中的双粒子散射相干计算来量化纠缠，并使用单粒子纯度的倒数作为纠缠度量。

Result: 标准平面波描述忽略了纠缠属性，因为初始状态下的量子不确定性起着关键作用。更实际的描述显示，纠缠与散射截面呈线性关系，并在形状共振附近有强烈的增强。

Conclusion: 所提出的方法可以探测并最终利用量子碰撞中的纠缠。

Abstract: Einstein, Podolsky, and Rosen discussed their paradox in terms of measuring
the positions or momenta of two particles. These can become entangled upon
scattering, but how much entanglement can be created in this process? Here we
address this question with fully coherent calculations of bipartite scattering
in three-dimensional space, quantifying entanglement by the inverse of the
single particle purity. We show that the standard plane-wave description of
scattering fails to capture the entanglement properties, due to the essential
role of quantum uncertainty in the initial state. For a more realistic
description of a scattering setup and narrow initial momentum dispersion, we
find the entanglement to scale linearly with the scattering cross section,
including strong enhancement close to shape resonances. We discuss how the
generation of motional entanglement can be detected in experiments. Our results
open the way to probing and eventually using entanglement in quantum
collisions.

</details>


### [320] [SWAP-Network Routing and Spectral Qubit Ordering for MPS Imaginary-Time Optimization](https://arxiv.org/abs/2511.02980)
*Erik M. Åsgrim,Stefano Markidis*

Main category: quant-ph

TL;DR: 提出一种量子启发式组合求解器，通过矩阵乘积态（MPS）上的虚时演化（ITE）进行，并结合结构化SWAP网络和谱量子比特映射来处理非局部耦合。SWAP网络仅由局域两量子比特门组成，可有效介导非局域量子比特相互作用。研究了基于矩形和三角形SWAP门网络的两种不同架构，并结合了谱量子比特排序（根据逻辑量子比特连接图的拉普拉斯矩阵将逻辑量子比特映射到MPS位点）来分析其性能。在具有不同图连通性的合成MaxCut实例以及涉及180个量子比特的动态投资组合优化问题（基于真实历史资产数据）上评估了该框架。在某些问题配置中，与随机排序相比，结合谱排序和三角形SWAP网络可将错误减少20倍以上。此外，对投资组合优化过程中纠缠熵的分析表明，谱量子比特排序不仅提高了解决方案质量，还增强了MPS中的总空间分布纠缠。这些发现表明，通过谱映射和高效路由网络利用问题结构可以显著提高基于张量网络的优化算法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索一种量子启发式方法来解决组合优化问题，特别是通过利用张量网络（如MPS）和量子计算技术（如ITE、SWAP网络）来处理非局部耦合和提高求解效率。

Method: 提出一种基于MPS的虚时演化（ITE）方法，并引入了两种类型的SWAP网络（矩形和三角形）来处理非局部量子比特耦合。同时，采用谱量子比特排序策略，根据连接图的拉普拉斯矩阵来优化逻辑量子比特到MPS位点的映射。在合成MaxCut实例和实际投资组合优化问题上评估了该框架。

Result: 在某些问题配置中，结合谱排序和三角形SWAP网络相比随机排序，错误减少超过20倍。在投资组合优化问题中，谱排序不仅提高了解决方案质量，还增加了MPS中的纠缠熵。

Conclusion: 利用问题结构（通过谱映射和高效路由网络）可以显著提升基于张量网络的优化算法性能。

Abstract: We propose a quantum-inspired combinatorial solver that performs
imaginary-time evolution (ITE) on a matrix product state (MPS), incorporating
non-local couplings through structured SWAP networks and spectral qubit mapping
of logical qubits. The SWAP networks, composed exclusively of local two-qubit
gates, effectively mediate non-local qubit interactions. We investigate two
distinct network architectures based on rectangular and triangular meshes of
SWAP gates and analyze their performance in combination with spectral qubit
ordering, which maps logical qubits to MPS sites based on the Laplacian of the
logical qubit connectivity graph. The proposed framework is evaluated on
synthetic MaxCut instances with varying graph connectivity, as well as on a
dynamic portfolio optimization problem based on real historical asset data
involving 180 qubits. On certain problem configurations, we observe an over
20$\times$ reduction in error when combining spectral ordering and triangular
SWAP networks compared to optimization with shuffled qubit ordering.
Furthermore, an analysis of the entanglement entropy during portfolio
optimization reveals that spectral qubit ordering not only improves solution
quality but also enhances the total and spatially distributed entanglement
within the MPS. These findings demonstrate that exploiting problem structure
through spectral mapping and efficient routing networks can substantially
enhance the performance of tensor-network-based optimization algorithms.

</details>


### [321] [D2-UC: A Distributed-Distributed Quantum-Classical Framework for Unit Commitment](https://arxiv.org/abs/2511.03104)
*Milad Hasanzadeh,Amin Kargarian*

Main category: quant-ph

TL;DR: 该论文提出了一种名为D2-UC的框架，用于解决近期的混合量子-经典单元承诺（UC）问题。该框架结合了分布式经典分解和分布式量子执行，将UC问题重构为三块交替方向乘子法（ADMM）子问题：凸二次子问题（用于调度和备用）、二次无约束二值优化（QUBO）子问题（用于承诺、启动和关断）以及近端松弛更新。


<details>
  <summary>Details</summary>
Motivation: 为近期混合量子-经典求解器准备单元承诺（UC）问题，以应对当前和近期的量子硬件能力。

Method: 将UC问题重构为三块ADMM子问题：(i) 包含调度和备用的凸二次子问题；(ii) 包含承诺、启动和关断的QUBO子问题；(iii) 用于共识的近端松弛更新。通过分解、微QUBO和批处理来优化QUBO子问题，并结合 DVQE 和一个 'accept-if-better' 保护措施来稳定混合更新。

Result: 提出的方法能够生成可行的计划，加快收敛速度，并且产生的QUBO大小与当前和近期的量子硬件能力相匹配。

Conclusion: D2-UC框架能够有效地解决UC问题，并且其大小和性能与当前和近期的量子硬件兼容。

Abstract: This paper introduces D2-UC, a quantum-ready framework for the unit
commitment (UC) problem that prepares UC for near-term hybrid quantum-classical
solvers by combining distributed classical decomposition with distributed
quantum execution. We reformulate deterministic and stochastic UC into a
three-block alternating direction method of multipliers (ADMM): (i) a convex
quadratic subproblem for dispatch and reserves, (ii) a binary subproblem
expressed as a quadratic unconstrained binary optimization (QUBO), and (iii) a
proximal slack update for consensus. The core contributions are fivefold.
First, we demonstrate how the full UC problem can be expressed as a single
monolithic QUBO, establishing a direct interface to quantum solvers. Second, we
decompose this large binary block into three type-specific QUBOs for
commitment, startup, and shutdown, making the problem more tractable but
revealing slower ADMM convergence. Third, we restore local logical couplings
through per-unit-time micro-QUBOs, which accelerate convergence. Fourth, we
batch micro-QUBOs into K non-overlapping block-diagonal problems, reducing many
subproblems to a fixed number of solver-ready QUBOs per iteration, compatible
with distributed variational quantum eigensolvers (DVQE). Fifth, we integrate
an accept-if-better safeguard with DVQE to stabilize hybrid updates and prevent
oscillations. Case studies confirm that the proposed methods deliver feasible
schedules, faster convergence, and QUBO sizes aligned with current and
near-term quantum hardware capabilities. All detailed data, codes, and
parameter values are available at
https://github.com/LSU-RAISE-LAB/3B-ADMM-UC-DVQE .

</details>


### [322] [Frequency- and Amplitude-Modulated Gates for Universal Quantum Control](https://arxiv.org/abs/2511.03164)
*Qi Ding,Shoumik Chowdhury,Agustin Di Paolo,Réouven Assouly,Alan V. Oppenheim,Jeffrey A. Grover,William D. Oliver*

Main category: quant-ph

TL;DR: 通过结合频率和幅度调制微波控制，实现高保真度单比特和两比特量子门操作。


<details>
  <summary>Details</summary>
Motivation: 高保真度的单比特和两比特量子门操作是执行任意数字量子算法和构建容错量子计算机的关键。

Method: 提出了一种利用频率和幅度调制的微波控制来实现量子门的理论框架，该框架将频率调制作为额外的控制手段，并利用Floquet理论进行分析和设计。

Result: 使用典型的transmon量子比特参数进行数值模拟，实现了一组通用量子门（包括X、Hadamard、phase和CZ门），控制误差远低于0.1%，单比特门操作时间为25-40 ns，两比特门操作时间为125-135 ns。此外，还实现了一个始终开启的CZ门，门操作时间为80-90 ns。

Conclusion: 该理论框架能够实现高保真度的量子门操作，并为量子计算提供了有效的控制方案。

Abstract: Achieving high-fidelity single- and two-qubit gates is essential for
executing arbitrary digital quantum algorithms and for building error-corrected
quantum computers. We propose a theoretical framework for implementing quantum
gates using frequency- and amplitude-modulated microwave control, which extends
conventional amplitude modulation by introducing frequency modulation as an
additional degree of control. Our approach operates on fixed-frequency qubits,
converting the need for qubit frequency tunability into drive frequency
modulation. Using Floquet theory, we analyze and design these drives for
optimal fidelity within specified criteria. Our framework spans adiabatic to
nonadiabatic gates within the Floquet framework, ensuring broad applicability
across gate types and control schemes. Using typical transmon qubit parameters
in numerical simulations, we demonstrate a universal gate set-including the X,
Hadamard, phase, and CZ gates-with control error well below 0.1% and gate times
of 25-40 ns for single-qubit operations and 125-135 ns for two-qubit
operations. Furthermore, we show an always-on CZ gate tailored for driven
qubits, which has gate times of 80-90 ns.

</details>


### [323] [Heralded Induced-Coherence Interferometry in a Noisy Environment](https://arxiv.org/abs/2511.03176)
*L. Theerthagiri,Balakrishnan Viswanathan,C. M. Chandrashekar*

Main category: quant-ph

TL;DR: 此论文研究了热背景噪声对 Zou-Wang-Mandel (ZWM) 干涉仪可见度的影响，并提出了几种恢复可见度的方法。


<details>
  <summary>Details</summary>
Motivation: 研究热背景噪声如何影响 ZWM 干涉仪的干涉可见度，并探索恢复可见度的方法。

Method: 通过显式包含背景噪声来分析低增益和高增益下的干涉可见度，并提出通过最优衰减、扩展到三光子源配置或引入已宣告检测来恢复可见度的方法。

Result: 发现在低增益和高增益下，热背景噪声都会引入不相干的偏移，降低干涉可见度。最优衰减、三光子源配置和已宣告检测都可以有效恢复可见度。

Conclusion: 热背景噪声会降低 ZWM 干涉仪的可见度，但可以通过多种方法有效缓解或消除其不利影响。

Abstract: Induced-coherence interferometry, first introduced in the Zou-Wang-Mandel
(ZWM) setup, enables retrieval of object information from the interference
pattern of light that never interacted with the object. This scheme relies on
two identically correlated photon pairs and the absence of "which-way"
information about the photons illuminating the object to induce coherence in
their companions. In previous studies, the effect of thermal background on the
ZWM interferometer was considered; here we explicitly include background noise
and analyze the interference visibility in both low- and high-gain regimes,
revealing how thermal photons introduce an incoherent offset that lowers the
observed interference contrast. We show that the visibility can be restored
either by optimal attenuation or by extending the geometry to a three-SPDC
configuration. Furthermore, we demonstrate that introducing heralded detection
removes the detrimental effect of thermal background noise, restoring
high-contrast interference fringes.

</details>


### [324] [Quantum Sensing of Copper-Phthalocyanine Electron Spins via NV Relaxometry](https://arxiv.org/abs/2511.03200)
*Boning Li,Xufan Li,Yifan Quan,Avetik R Harutyunyan,Paola Cappellaro*

Main category: quant-ph

TL;DR: NV色心结合铜酞菁薄膜实现室温下量子信息处理和纳米传感


<details>
  <summary>Details</summary>
Motivation: 室温下分子自旋系统的相干性难以保持，限制了其在量子信息处理和纳米传感方面的应用。本研究旨在利用NV色心弛豫测量技术，在室温下表征铜酞菁（CuPc）分子自旋系统，并探索其在量子技术中的应用潜力。

Method: 通过对金刚石中浅层NV色心的T1弛豫测量，探测多晶铜酞菁（CuPc）薄膜的电子自旋系综。通过超精细谱识别NV-CuPc相互作用，并提取CuPc自旋系综的关键参数，如关联时间和局域晶格取向。

Result: 成功识别了NV-CuPc相互作用，并提取了CuPc自旋系综的关联时间和局域晶格取向等参数。实验结果证实了电子-电子相互作用是CuPc在室温下退相干动力学的主导因素。此外，研究表明CuPc增强的NV弛豫测量可以精确估计NV深度。

Conclusion: NV色心是探测分子自旋系统的有效工具，为理解分子量子比特、自旋电池工程和混合量子材料提供了新的视角，并为分子尺度量子处理器和基于自旋的量子网络等应用开辟了道路。

Abstract: Molecular spin systems are promising candidates for quantum information
processing and nanoscale sensing, yet their characterization at room
temperature remains challenging due to fast spin decoherence. In this work, we
use $T_1$ relaxometry of shallow nitrogen-vacancy (NV) centers in diamond to
probe the electron spin ensemble of a polycrystalline copper phthalocyanine
(CuPc) thin film. In addition to unequivocally identifying the NV-CuPc
interaction thanks to its hyperfine spectrum, we further extract key parameters
of the CuPc spin ensemble, including its correlation time and local lattice
orientation, that cannot be measured in bulk electron resonance experiments.
The analysis of our experimental results confirms that electron-electron
interactions dominate the decoherence dynamics of CuPc at room temperature.
Additionally, we demonstrate that the CuPc-enhanced NV relaxometry can serve as
a robust method to estimate the NV depth with $\sim1$~nm precision. Our results
establish NV centers as powerful probes for molecular spin systems, providing
insights into molecular qubits, spin bath engineering, and hybrid quantum
materials, and offering a potential pathway toward their applications such as
molecular-scale quantum processors and spin-based quantum networks.

</details>


### [325] [Quantum properties of superpositions of oppositely squeezed states](https://arxiv.org/abs/2511.03204)
*Hiroo Azuma,William J. Munro,Kae Nemoto*

Main category: quant-ph

TL;DR: 本研究提出了两种新的量子态，并分析了它们的特性以及在量子信息处理中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探究超大压缩态叠加态的量子特性，并与相干态猫态进行比较。

Method: 分析了该叠加态的Wigner函数，并量化了其在50:50分束器上的纠缠特性。同时，提出了一种无需强克尔非线性即可近似制备该叠加态的线性光学信号携带方案。

Result: 与相干态猫态相比，超大压缩态叠加态展现出独特的 the photon-number structures 和增强的非经典特性。在较小的压缩参数下，其纠缠度高于纯粹的双模压缩真空态。

Conclusion: 超大压缩态叠加态是连续变量量子信息处理的有用资源，特别是在需要高非高斯性和强纠缠的场景下。

Abstract: We investigate the quantum properties of superpositions of oppositely
squeezed states, which can be regarded as Schrodinger cat states. Compared with
conventional coherent-state cat states, these states exhibit distinct
photon-number structures and enhanced nonclassical features. We analyze their
Wigner function and quantify the entanglement generated when they are injected
into a 50:50 beam splitter. For small squeezing parameters, the resulting
two-mode states possess higher entanglement than pure two-mode squeezed vacuum
states. We also propose a linear-optical heralding scheme that approximates
this superposition of oppositely squeezed states without requiring strong Kerr
nonlinearities. Our results indicate that such states are promising resources
for continuous-variable quantum information processing, particularly in regimes
where high non-Gaussianity and strong entanglement are desirable.

</details>


### [326] [Quantum phase transition in the anisotropic Rabi model induced by parametric amplification](https://arxiv.org/abs/2511.03207)
*Yuan Qiu,Ke-Xiong Yan,Jun-Hao Lin,Jie Song,Ye-Hong Chen,Yan-Xia*

Main category: quant-ph

TL;DR: 本文研究了经典振子限制下各向异性Rabi模型的超辐射相变机制。通过算子空间中的哈密顿量展开，得到三个模式，并发现相变源于模式间的竞争。研究还探讨了参数驱动的Jaynes-Cummings模型，该模型能重现强耦合各向异性Rabi模型的动力学行为，并发现系统在临界点时经历超辐射相变。


<details>
  <summary>Details</summary>
Motivation: 经典振子限制下各向异性Rabi模型难以实现，故而研究该模型在参数驱动下的Jaynes-Cummings模型，以探索其量子相变。

Method: 通过算子空间展开各向异性Rabi模型哈密顿量，得到三个模式。分析参数驱动的Jaynes-Cummings模型（可重现各向异性Rabi模型动力学行为）的本征能量和本征态。

Result: 在临界点，正常相和超辐射相的激发能量消失，光子数趋于无穷。

Conclusion: 系统在临界点经历超辐射相变。

Abstract: In this manuscript, we analyze the mechanism of the superradiant phase
transition in the anisotropic Rabi model under the classical oscillator limit
using the pattern picture. By expanding the anisotropic Rabi model Hamiltonian
in operator space, we obtained three patterns, and we find that the phase
transition arises from the competition between patterns. The difficulty in
achieving the classical oscillator limit motivates our investigation into the
quantum phase transition within a parametrically-driven Jaynes-Cummings model.
This parametrically-driven Jaynes-Cummings model can reproduce the dynamics of
a ultrastrong-coupling anisotropic Rabi model in a squeezed-light frame.
According to the eigenenergies and eigenstates of the normal and superradiant
phases of this equivalent anisotropic Rabi model, we find that the excitation
energy of the normal phase and the superradiant phase vanishes at the critical
point. The photon number becomes infinite beyond the critical point. These
results indicate that the system undergoes a superradiant phase transition at
the critical point.

</details>


### [327] [Quantum-classical hybrid algorithm using quantum annealing for multi-objective job shop scheduling](https://arxiv.org/abs/2511.03257)
*Kenta Sawamura,Kensuke Araki,Naoki Maruyama,Renichiro Haba,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: 该研究提出了一种量子-经典混合算法，用于解决大规模、多目标生产计划问题，通过将问题分解为资源分配和任务调度两个子问题，并结合退火算法和混合整数线性规划求解器，在计算效率和解的质量上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统数学优化方法难以解决大规模生产计划问题，尤其是在存在多冲突目标的情况下，传统标量化方法无法找到多样化的帕累托最优解。

Method: 将生产计划问题分解为资源分配（使用二次无约束二元优化和退火算法求解）和任务调度（使用混合整数线性规划求解）两个子问题，并采用量子-经典混合方法进行求解。

Result: 与传统单片方法相比，该混合方法在计算效率和解的质量方面均表现出优越性。

Conclusion: 该研究为工业应用中的高速、多目标调度提供了一个有前景的方向。

Abstract: Efficient production planning is essential in modern manufacturing to improve
performance indicators such as lead time and to reduce reliance on human
intuition. While mathematical optimization approaches, formulated as job shop
scheduling problems, have been applied to automate this process, solving
large-scale production planning problems remains computationally demanding.
Moreover, many practical scenarios involve conflicting objectives, making
traditional scalarization techniques ineffective in finding diverse and useful
Pareto-optimal solutions. To address these challenges, we developed a
quantum-classical hybrid algorithm that decomposes the problem into two
subproblems: resource allocation and task scheduling. Resource allocation is
formulated as a quadratic unconstrained binary optimization problem and solved
using annealing-based methods that efficiently explore complex solutions. Task
scheduling is modeled as a mixed-integer linear programming problem and solved
using conventional solvers to satisfy detailed scheduling constraints. We
validated the proposed method using benchmark instances based on foundry
production scenarios. Experimental results demonstrate that our hybrid approach
achieves superior solution quality and computational efficiency compared to
traditional monolithic methods. This work offers a promising direction for
high-speed, multi-objective scheduling in industrial applications.

</details>


### [328] [Thermodynamic Probes of Multipartite Entanglement in Strongly Interacting Quantum Systems](https://arxiv.org/abs/2511.03266)
*Harsh Sharma,Sampriti Saha,A. S. Majumdar,Manik Banik,Himadri Shekhar Dhar*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量化多方纠缠的方法，通过全局和局部“功”（ergotropy）的评估，克服了传统方法在强相互作用系统中的限制，并展示了其在近期量子模拟器上的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 量化量子多体系统和混合量子计算架构中的多方纠缠是一个基本但具有挑战性的任务。现有的基于最大可提取功（功）的方法在处理具有强集体或粒子间相互作用的系统时存在局限性。

Method: 提出了一种新的框架，通过控制相互作用的淬灭或测量合适的局部可观测量来评估全局和局部的功，从而绕过传统方法的限制。

Result: 该框架能够正确估计具有强相互作用的系统（包括稳定和时间演化状态）中真实的多方纠缠，并将其应用于量子电路模拟的参数化量子态，考虑了不同的线路深度和噪声。

Conclusion: 所提出的方法是一种通用的工具，可以表征近期量子模拟器中的纠缠，并已成功应用于塔维斯- Cummings模型、三能级Dicke模型和横向场伊辛模型等实际物理模型。

Abstract: Quantifying multipartite entanglement in quantum many-body systems and hybrid
quantum computing architectures is a fundamental yet challenging task. In
recent years, thermodynamic quantities such as the maximum extractable work
from an isolated system (the ergotropy) have allowed for entanglement measures
that are operationally more accessible. However, these measures can be
restrictive when applied to systems governed by Hamiltonians with strong
collective or interparticle interactions. Motivated by advances in quantum
simulators, we propose a framework that circumvents these restrictions by
evaluating global and local ergotropy either through controlled quenching of
interactions or by measuring suitable local observables only. We show that this
formalism allows us to correctly estimate genuine multipartite entanglement in
both stationary and time-evolved states of systems with strong interactions,
including parametrized quantum states simulated on a quantum circuit with
varying circuit depth and noise. We demonstrate its applicability to realistic
physical models, namely, the Tavis-Cummings model, the three-level Dicke model,
and the transverse-field Ising model, highlighting its potential as a versatile
tool for characterizing entanglement in near-term quantum simulators.

</details>


### [329] [Influence of Data Dimensionality Reduction Methods on the Effectiveness of Quantum Machine Learning Models](https://arxiv.org/abs/2511.03320)
*Aakash Ravindra Shinde,Jukka K. Nurminen*

Main category: quant-ph

TL;DR: 数据降维技术会影响量子机器学习模型的性能评估。


<details>
  <summary>Details</summary>
Motivation: 在量子机器学习中，数据降维技术被用于解决NISQ设备的局限性和经典设备模拟大规模量子系统的挑战，但也引发了数据降维方法对大规模数据集适应性的担忧。

Method: 通过在多种生成数据集、量子机器学习算法、量子数据编码方法和数据降维方法上进行实验，评估不同数据降维方法对QML模型性能指标（准确率、精确率、召回率和F1分数）的影响。

Result: 数据降维方法导致性能指标失真，低估了量子机器学习模型的实际性能。准确率差异在14%到48%之间。某些数据降维方法在特定的数据嵌入方法和模型结构上表现更好。

Conclusion: 数据降维方法的使用会扭曲性能指标的评估结果，从而错误地估计量子机器学习模型的实际性能。数据集特性、信息嵌入方法、特征约简百分比、经典组件以及模型结构等因素都会加剧此问题。

Abstract: Data dimensionality reduction techniques are often utilized in the
implementation of Quantum Machine Learning models to address two significant
issues: the constraints of NISQ quantum devices, which are characterized by
noise and a limited number of qubits, and the challenge of simulating a large
number of qubits on classical devices. It also raises concerns over the
scalability of these approaches, as dimensionality reduction methods are slow
to adapt to large datasets. In this article, we analyze how data reduction
methods affect different QML models. We conduct this experiment over several
generated datasets, quantum machine algorithms, quantum data encoding methods,
and data reduction methods. All these models were evaluated on the performance
metrics like accuracy, precision, recall, and F1 score. Our findings have led
us to conclude that the usage of data dimensionality reduction methods results
in skewed performance metric values, which results in wrongly estimating the
actual performance of quantum machine learning models. There are several
factors, along with data dimensionality reduction methods, that worsen this
problem, such as characteristics of the datasets, classical to quantum
information embedding methods, percentage of feature reduction, classical
components associated with quantum models, and structure of quantum machine
learning models. We consistently observed the difference in the accuracy range
of 14% to 48% amongst these models, using data reduction and not using it.
Apart from this, our observations have shown that some data reduction methods
tend to perform better for some specific data embedding methodologies and
ansatz constructions.

</details>


### [330] [Exploring Topologies in Quantum Annealing: A Hardware-Aware Perspective](https://arxiv.org/abs/2511.03327)
*Mario Bifulco,Luca Roversi*

Main category: quant-ph

TL;DR: 量子退火（QA) 是一种有前景的解决 NP-hard 优化问题的方法，但其有效性受到底层量子硬件拓扑的限制。通过 QA 解决优化问题 P 涉及硬件感知的电路编译，这需要将 P 表示为图 G_P，并将其嵌入到硬件连接图 G_Q 中。次要嵌入（ME）是这种硬件感知编译的一种可能的操作形式。ME 通过其一个 minor 来构建一个映射，将 G_P 的每个节点（P 的逻辑变量）关联到 G_Q 中相邻节点的链，从而在 G_Q 中将 G_P 的弧保留为量子比特之间的物理连接。我们提出了一种评估 G_Q 如何负面影响嵌入式问题的方法论和一套标准，从而使量子优化对噪声更加敏感。我们使用 Zephyr 图（D-Wave 系统中使用）和 Havel-Hakimi 图这两种 QPU 拓扑来评估 ME 的结果，后者允许控制平均节点度数的度量。这使我们能够研究‘节点数/每节点的弧数’比率如何影响 ME 将 G_P 映射到 G_Q 的 minor 的成功率。通过在经典（非量子）架构上执行的 ME 获得的结果表明，基于 Havel-Hakimi 的拓扑平均需要更短的量子比特链，并且随着 QPU 尺寸的增加，最大可嵌入 G_P 的性能会更平滑地扩展。这些特性表明它们有潜力作为基于 QA 的 QPU 的替代设计。


<details>
  <summary>Details</summary>
Motivation: 量子退火（QA）在解决 NP-hard 优化问题方面具有潜力，但其效率受到量子硬件拓扑的限制。该研究旨在评估硬件拓扑如何影响 QA 的性能，并探索改进拓扑设计的可能性。

Method: 该研究提出了一种评估硬件拓扑对次要嵌入（ME）影响的方法论和一套标准。通过在经典计算机上模拟 ME，并在 Zephyr 图和 Havel-Hakimi 图这两种不同的 QPU 拓扑上进行评估，研究了‘节点数/每节点的弧数’比率对 ME 成功率的影响。

Result: 与 Zephyr 图相比，Havel-Hakimi 图拓扑在次要嵌入（ME）方面表现出优势，平均需要更短的量子比特链，并且在 QPU 尺寸增大时，最大可嵌入图 G_P 的性能扩展更平滑。

Conclusion: Havel-Hakimi 图拓扑作为一种替代设计，在构建量子退火（QA）量子处理单元（QPU）方面具有潜力，因为它能更有效地处理次要嵌入问题，并可能提高 QA 解决优化问题的性能。

Abstract: Quantum Annealing (QA) offers a promising framework for solving NP-hard
optimization problems, but its effectiveness is constrained by the topology of
the underlying quantum hardware. Solving an optimization problem $P$ via QA
involves a hardware-aware circuit compilation which requires representing $P$
as a graph $G_P$ and embedding it into the hardware connectivity graph $G_Q$
that defines how qubits connect to each other in a QA-based quantum processing
unit (QPU).
  Minor Embedding (ME) is a possible operational form of this hardware-aware
compilation. ME heuristically builds a map that associates each node of $G_P$
-- the logical variables of $P$ -- to a chain of adjacent nodes in $G_Q$ by
means of one of its minors, so that the arcs of $G_P$ are preserved as physical
connections among qubits in $G_Q$.
  The static topology of hardwired qubits can clearly lead to inefficient
compilations because $G_Q$ cannot be a clique, currently. We propose a
methodology and a set of criteria to evaluate how the hardware topology $G_Q$
can negatively affect the embedded problem, thus making the quantum
optimization more sensible to noise.
  We evaluate the result of ME across two QPU topologies: Zephyr graphs (used
in current D-Wave systems) and Havel-Hakimi graphs, which allow controlled
variation of the average node degree. This enables us to study how the ratio
`number of nodes/number of incident arcs per node' affects ME success rates to
map $G_P$ into a minor of $G_Q$.
  Our findings, obtained through ME executed on classical, i.e. non-quantum,
architectures, suggest that Havel-Hakimi-based topologies, on average, require
shorter qubit chains in the minor of $G_P$, exhibiting smoother scaling of the
largest embeddable $G_P$ as the QPU size increases. These characteristics
indicate their potential as alternative designs for QA-based QPUs.

</details>


### [331] [Dynamical discontinuities in repeated weak measurements revealed by complex weak values](https://arxiv.org/abs/2511.03352)
*Lorena Ballesteros Ferraz*

Main category: quant-ph

TL;DR: 文章研究了量子弱测量协议中由后选择引起的动力学不连续性，并揭示了其与弱值虚部为零的关系。


<details>
  <summary>Details</summary>
Motivation: 研究量子弱测量协议中的临界现象，以理解测量反作用如何影响量子动力学。

Method: 通过在每次迭代中保留测量者状态并更新系统，对系统进行弱测量和后选择协议的重复应用，并分析弱值和 Kraus 算符的本征结构。

Result: 发现当弱值具有非零虚部时，在弱值虚部随后选择极角变化的零点处，测量量期望值会出现不连续性。当弱值始终为实数时，则不会出现不连续性。临界指数恒为 1。

Conclusion: 量子弱测量协议中的临界现象为工程化测量控制中的非解析行为和探测后选择量子动力学中的临界性提供了新的视角。

Abstract: Critical phenomena reveal universal behavior in complex systems, and
uncovering analogous effects in quantum weak measurement protocols with
post-selection provides new insight into how measurement backaction can shape
quantum dynamics. This work investigates dynamical discontinuities that arise
when the post-selected polar angle is used as a control parameter. The system
evolves under repeated applications of a weak measurement protocol with
post-selection, in which the meter state is retained after each iteration while
the system is renewed. The emergence of these discontinuities is shown to be
determined by the structure of the weak value: when the weak value has a
nonzero imaginary component, a discontinuity appears in the expectation value
of meter observables precisely at the point where the imaginary part of the
weak value vanishes as a function of the post-selection polar angle. In
contrast, no discontinuities occur when the weak value remains real for all
post-selection angles. The phenomenon originates from the eigenstructure of the
protocol's Kraus operator, with the stability of fixed points changing at the
critical point where the discontinuity arises. Remarkably, the associated
critical exponent is 1, independent of system parameters. These results open
new perspectives for engineering non-analytic behavior in measurement-based
quantum control and for probing criticality in post-selected quantum dynamics
using weak measurements with weak values.

</details>


### [332] [Universal Quantum Simulation of 50 Qubits on Europe`s First Exascale Supercomputer Harnessing Its Heterogeneous CPU-GPU Architecture](https://arxiv.org/abs/2511.03359)
*Hans De Raedt,Jiri Kraus,Andreas Herten,Vrinda Mehta,Mathis Bode,Markus Hrywniak,Kristel Michielsen,Thomas Lippert*

Main category: quant-ph

TL;DR: JUQCS-50模拟了50个量子比特的通用量子计算机，速度比之前的记录快11.4倍。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的高性能量子计算机模拟器JUQCS-50，以模拟50个量子比特的通用量子计算机。

Method: JUQCS-50通过以下三种创新实现：(1)利用CPU-GPU互连和LPDDR5内存扩展了可用内存；(2)通过可变数据编码来减小内存占用；(3)使用动态网络流量优化器。

Result: JUQCS-50在JUPITER超级计算机上实现了对50个量子比特的通用量子计算机的模拟，与K计算机上先前的48个量子比特记录相比，速度提高了11.4倍。

Conclusion: JUQCS-50通过利用GH200超级芯片的特性，在量子计算机模拟领域取得了重大进展，为未来更大规模的量子模拟铺平了道路。

Abstract: We have developed a new version of the high-performance J\"ulich universal
quantum computer simulator (JUQCS-50) that leverages key features of the GH200
superchips as used in the JUPITER supercomputer, enabling simulations of a
50-qubit universal quantum computer for the first time. JUQCS-50 achieves this
through three key innovations: (1) extending usable memory beyond GPU limits
via high-bandwidth CPU-GPU interconnects and LPDDR5 memory; (2) adaptive data
encoding to reduce memory footprint with acceptable trade-offs in precision and
compute effort; and (3) an on-the-fly network traffic optimizer. These advances
result in an 11.4-fold speedup over the previous 48-qubit record on the K
computer.

</details>


### [333] [Integration of quantum dots at the tips of single plasmonic bipyramid nanoantennas for strong coupling at room temperature](https://arxiv.org/abs/2511.03409)
*Kseniia Mamaeva,Hodjat Haijan,Carolyn Elliott,Hannah Killeen,Teodora Faraone,Larisa Florea,Colm Delaney,A. Louise Bradley*

Main category: quant-ph

TL;DR: 通过等离振子触发的双光子聚合技术，在金纳米双锥体（BP）的单热点处精确控制量子点（QD）的位置，实现了室温下QD与LSP的强耦合，表现出349.3 meV的Rabi分裂和175.68 meV的耦合强度，为量子光学和量子传感应用提供了可扩展的平台。


<details>
  <summary>Details</summary>
Motivation: 实现胶体半导体量子点（QD）与局域表面等离振元激元（LSP）之间的强耦合，对于先进的室温量子发射器和传感应用至关重要，但精确控制发射器相对于单个等离振纳米结构的位置是一个关键挑战。

Method: 利用金纳米双锥体（BP）的单个热点，通过等离振子触发的双光子聚合技术，将量子点（QD）定位在热点处，利用BP尖端增强的电场选择性聚合含QD的光敏配方。

Result: 在3-QD-BP系统中实现了室温强耦合，观察到349.3 meV的Rabi分裂和175.68 meV的耦合强度，并通过模拟证实了明显的反交叉行为。

Conclusion: 所提出的方法简化了QD集成，为具有胶体QD的固态量子技术提供了一个可扩展的平台，能够探索激子-等离振子相互作用，并在环境条件下进一步推进量子光学和量子传感领域的应用。

Abstract: Achieving strong coupling between excitons of colloidal semiconductor quantum
dots (QDs) and localized surface plasmon polaritons (LSPs) is critical for
advanced room-temperature quantum emitter and sensing applications. A key
challenge is to have precise control of the emitters position with respect to
an individual plasmonic nanostructure. Here, we present room temperature strong
coupling between QDs and a single gold nano-bipyramid (BPs). The selection of
the bipyramid plasmonic nanocavity offers access to a single hotspot with a
very small mode volume. The localization of QDs at a single hotspot is achieved
via plasmon-triggered two-photon polymerization. This technique exploits the
enhanced electric field at the BP tip to selectively polymerize a
photosensitive QD-containing formulation. Room-temperature scattering spectra
of a 3-QD-BP system reveal Rabi splitting of 349.3 meV and a coupling strength
of 175.68 meV. The with distinct anti-crossing behavior is confirmed by
simulations. This approach simplifies QD integration for strong coupling
systems compared to previous methods. These results indicate a scalable
platform for solid-state quantum technologies with colloidal QDs, enabling
explora-tion of exciton-plasmon interactions and further advance-ment of
applications in quantum optics and quantum sensing under ambient conditions.

</details>


### [334] [Quantum-elevated Chiral Discrimination for Bio-molecules](https://arxiv.org/abs/2511.03412)
*Yiquan Yang,Xiaolong Hu,Wei Du,Shuhe Wu,Peiyu Yang,Guzhi Bao,Weiping Zhang*

Main category: quant-ph

TL;DR: 利用连续变量偏振纠缠态进行量子增强的手性识别，超越了经典方法的极限，并在区分L-和D-氨基酸方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统手性识别方法（依赖圆偏振光）信噪比低和潜在的光损伤问题，并突破经典手性探针的散粒噪声极限。

Method: 使用连续变量偏振纠缠态作为中等光通量、高灵敏度、量子噪声压缩的手性探针，实现手性识别。

Result: 在液相中区分L-和D-氨基酸时，实现了超越散粒噪声极限（SNL）5 dB的改进。

Conclusion: 提出了一种非破坏性、生物相容性的量子增强手性识别方法，在药物开发、生物化学研究、环境监测和不对称合成等领域具有广泛的应用前景。

Abstract: Chiral discrimination of enantiomeric biomolecules is vital in chemistry,
biology, and medicine. Conventional methods, relying on circularly polarized
light, face weak chiroptical signals and potential photodamage. Despite
extensive efforts to improve sensitivity under low-photon exposure, classical
chiral probes remain fundamentally bounded by the shot-noise limit due to
quantum fluctuations. To beat these limitations, we demonstrate
quantum-elevated chiral discrimination using continuous-variable
polarization-entangled states as moderate-photon-flux, high-sensitivity,
quantum-noise-squeezed chiral probes. We achieve a 5 dB improvement beyond the
SNL in distinguishing L- and D-amino acids in liquid phase. This
non-destructive, biocompatible protocol enables high-sensitivity chiral
analysis, with broad implications for drug development, biochemical research,
environmental monitoring, and asymmetric synthesis.

</details>


### [335] [Universal first-passage time statistics for quantum diffusion](https://arxiv.org/abs/2511.03455)
*Guido Ladenburger,Finn Schmolke,Eric Lutz*

Main category: quant-ph

TL;DR: 该论文解决了由测量噪声驱动的量子扩散的量子过路时间问题，并找到了一个通用的过路时间分布。


<details>
  <summary>Details</summary>
Motivation: 在经典随机过程中，首次通过现象起着基本作用。本文解决了测量噪声驱动的量子扩散的量子首次通过时间问题，这是经典布朗运动的推广。这种连续监测可能会将测量的量子系统困在无退相干子空间中，这是状态空间中与周围环境隔离的一部分，因此在量子信息科学中起着重要作用。

Method: 精确求解由测量噪声驱动的量子扩散的量子首次通过时间问题，并分析确定了首次通过时间分布。

Result: 首次通过时间分布的计算结果表明，其形式不依赖于系统哈密顿量或测量算子，因此具有普遍性。

Conclusion: 研究结果为研究扩散量子轨迹的首次通过统计提供了通用框架。

Abstract: First-passage phenomena play a fundamental role in classical stochastic
processes. We here exactly solve a quantum first-passage time problem for
quantum diffusion driven by measurement noise, a generalization of classical
Brownian motion. Such continuous monitoring may trap the measured quantum
system in a decoherence-free subspace, a fraction of the available state space
that is isolated from the surroundings, and thus plays an important role in
quantum information science. We analytically determine the first-passage time
distribution, whose form neither depends on the system Hamiltonian nor on the
measurement operator, and is therefore universal. These results provide a
general framework to investigate the first-passage statistics of diffusive
quantum trajectories.

</details>


### [336] [Mutually Unbiased Bases and Orthogonal Latin Squares](https://arxiv.org/abs/2511.03537)
*Stefan Joka*

Main category: quant-ph

TL;DR: 在N维希尔伯特空间中，存在完备的互不相关基（MUBs）等价于存在N阶完备的互不相关拉丁方（MOLSs）。特别地，不存在6维（素数幂的第一个非素数幂的维度）的完备MUBs。


<details>
  <summary>Details</summary>
Motivation: 证明完备MUBs的存在性与完备MOLSs的存在性之间的关系，并研究特定维度（如6维）MUBs的存在性。

Method: 利用MUBs和MOLSs的数学性质进行推导和证明。

Result: 证明了完备MUBs的存在性等价于完备MOLSs的存在性。证明了不存在6维的完备MUBs。

Conclusion: 完备MUBs的存在性与完备MOLSs的存在性密切相关，并且在6维空间中不存在完备MUBs。

Abstract: In this paper, we prove that the existence of a complete set of mutually
unbiased bases (MUBs) in N-dimensional Hilbert space implies the existence of a
complete set of mutually orthogonal Latin squares (MOLSs) of order N. In
particular, we prove that a complete set of MUBs does not exist in dimension
six (the first dimension which is not a power of prime).

</details>


### [337] [The Converse Madelung Question](https://arxiv.org/abs/2511.03552)
*Jonathan R Dunkley*

Main category: quant-ph

TL;DR: 这项工作研究了信息论是否是量子力学所必需的，而不是反之。通过一组基本公理，作者证明了费希尔信息是唯一满足这些公理的泛函，并表明量子力学可以被视为费希尔正则化信息流体动力学的一个可逆不动点。


<details>
  <summary>Details</summary>
Motivation: 研究费希尔信息是否是量子力学所必需的，而不是反之。

Method: 从局部性、概率守恒、欧几里得不变性（具有全局相位对称性）、可逆性和凸正则性等基本公理出发，推导出一阶局部哈密顿场论。在此框架下，利用点态、规范协变的复变量变换，证明了只有费希尔泛函满足特定的要求。

Result: 当费希尔泛函的系数等于普朗克常数平方除以两倍的质量时，动力学可以简化为线性薛定谔方程。对于多体系统，跨越扇区的单一局部复结构强制执行了物种之间的相同关系，固定了单一的普朗克常数。伽利略协变性通过 Bargmann 中心扩展出现。与 Doebner 和 Goldin 的研究相比，可逆的零扩散角落与线性薛定谔动力学相吻合。作者还通过残余诊断提供了可操作的证伪方法，并报告了在费希尔尺度上的数值最小值，这些最小值在伽利略纵移下是不变的。

Conclusion: 量子力学可以被视为费希尔正则化信息流体动力学的一个可逆不动点。

Abstract: We pose the converse Madelung question: not whether Fisher information can
reproduce quantum mechanics, but whether it is necessary. We work with minimal,
physically motivated axioms on density and phase: locality, probability
conservation, Euclidean invariance with a global phase symmetry, reversibility,
and convex regularity. Within the resulting class of first order local
Hamiltonian field theories, these axioms single out the canonical Poisson
bracket on density and phase under the Dubrovin and Novikov assumptions for
local hydrodynamic brackets. Using a pointwise, gauge covariant complex change
of variables that maps density and phase to a single complex field, we show
that the only convex, rotationally invariant, first derivative local functional
of the density whose Euler Lagrange term yields a reversible completion that is
exactly projectively linear is the Fisher functional. When its coefficient
equals Planck constant squared divided by twice the mass, the dynamics reduce
to the linear Schrodinger equation. For many body systems, a single local
complex structure across sectors enforces the same relation species by species,
fixing a single Planck constant. Galilean covariance appears through the
Bargmann central extension, with the usual superselection consequences.
Comparison with the Doebner and Goldin family identifies the reversible zero
diffusion corner with linear Schrodinger dynamics. We provide operational
falsifiers via residual diagnostics for the continuity and Hamilton Jacobi
equations and report numerical minima at the Fisher scale that are invariant
under Galilean boosts. In this setting, quantum mechanics emerges as a
reversible fixed point of Fisher regularised information hydrodynamics. A code
archive enables direct numerical checks, including a superposition stress test
that preserves exact projective linearity within our axioms.

</details>


### [338] [Quantum error mitigation using energy sampling and extrapolation enhanced Clifford data regression](https://arxiv.org/abs/2511.03556)
*Zhongqi Zhao,Erik Rosendahl Kjellgren,Sonia Coriani,Jacob Kongsted,Stephan P. A. Sauer,Karl Michael Ziems*

Main category: quant-ph

TL;DR: 本研究扩展了Clifford数据回归（CDR）方法以缓解量子化学模拟中的噪声，并提出了两种改进：能量采样（ES）和非Clifford外插（NCE），均优于原始CDR。


<details>
  <summary>Details</summary>
Motivation: 在噪声中型量子（NISQ）设备上实际应用量子算法需要错误缓解。本研究旨在利用变分量子特征求解器（VQE）缓解量子化学模拟中的噪声。

Method: 通过使用IBM torino噪声模型对H4分子和tiled Unitary Product State（tUPS）ansatz进行噪声模拟，研究了CDR中各种超参数对错误缓解质量的影响。提出了两种改进：能量采样（ES），通过仅选择能量最低的训练电路进行回归来提高性能；非Clifford外插（NCE），通过将非Clifford参数的数量作为附加输入来增强回归模型。

Result: 数值结果表明，ES和NCE两种策略均优于原始CDR。

Conclusion: 本研究提出的ES和NCE两种改进策略在错误缓解方面优于原始CDR，为在NISQ设备上进行准确的量子化学模拟提供了更有效的方法。

Abstract: Error mitigation is essential for the practical implementation of quantum
algorithms on noisy intermediate-scale quantum (NISQ) devices. This work
explores and extends Clifford Data Regression (CDR) to mitigate noise in
quantum chemistry simulations using the Variational Quantum Eigensolver (VQE).
Using the H$_4$ molecule with the tiled Unitary Product State (tUPS) ansatz, we
perform noisy simulations with the ibm torino noise model to investigate in
detail the effect of various hyperparameters in CDR on the error mitigation
quality. Building on these insights, two improvements to the CDR framework are
proposed. The first, Energy Sampling (ES), improves performance by selecting
only the lowest-energy training circuits for regression, thereby further
biasing the sample energies toward the target state. The second, Non-Clifford
Extrapolation (NCE), enhances the regression model by including the number of
non-Clifford parameters as an additional input, enabling the model to learn how
the noisy-ideal mapping evolves as the circuit approaches the optimal one. Our
numerical results demonstrate that both strategies outperform the original CDR.

</details>


### [339] [Atom-Field Non-Markovian Dynamics in Open and Dissipative Systems: An Efficient Memory-Kernel Approach Linked to Dyadic Greens Function and CEM Treatments](https://arxiv.org/abs/2511.03561)
*Hyunwoo Choi,Jisang Seo,Weng C. Chew,Dong-Yeop Na*

Main category: quant-ph

TL;DR: 该研究提出了一种用于模拟开放耗散系统中双层系统单光子发射的数值框架，超越了马尔可夫近似，并可与FDTD和FEM等标准计算电磁学求解器集成。


<details>
  <summary>Details</summary>
Motivation: 开发一种能超越马尔可夫近似，用于模拟开放耗散系统中双层系统单光子发射的数值框架，并能与现有计算电磁学求解器集成。

Method: 提出了一种数值框架，通过模态展开重建格林函数的虚部，从而在多模Jaynes Cummings模型中实现对开放耗散环境中原子场相互作用的第一性原理描述。该框架通过记忆核描述双层系统动力学，并提出在FDTD和FEM中实现的具体策略。

Result: 在单激发流形中，证明了记忆核由格林函数的虚部决定，表明辐射模态单独控制相关动力学。成功在FDTD和FEM框架中实现了该方法，并验证了其在损耗洛伦兹-德鲁德型镜子（包括近金属镜子和腔体中心双层系统）上的数值结果。

Conclusion: 该工作为将量子发射体动力学纳入计算电磁学奠定了严谨的基础，使经典求解器能够处理量子光-物质相互作用。

Abstract: In this work, we present a numerical framework for modeling single photon
emission from a two level system in open and dissipative systems beyond the
Markovian approximation. The method can be readily integrated into standard
computational electromagnetic (CEM) solvers such as finite difference time
domain (FDTD) and finite element method (FEM). We numerically verify the
completeness of boundary and medium assisted modes in the modified Langevin
noise formalism by reconstructing the imaginary part of the dyadic Greens
function through modal expansion in three dimensions. This reconstruction
enables a first principles description of atom field interaction via the multi
mode Jaynes Cummings model in open and dissipative environments. Within the
single excitation manifold, we show that the memory kernel of a two level
system is determined by the imaginary part of the Greens function, implying
that radiative modes alone govern the relevant dynamics. The proposed framework
thus provides a Greens function based approach for describing atomic population
and single photon dynamics, directly compatible with Maxwell solvers. We then
present concrete strategies for implementing our method in both FDTD and FEM
frameworks, demonstrating its practical applicability. We further verify
numerical results for a lossy Lorentz Drude type mirror, including both the
case of a TLS near a finite sized metallic mirror and that of a TLS centered in
a Fabry Perot cavity. This work establishes a rigorous foundation for
incorporating quantum emitter dynamics into computational electromagnetics,
thereby extending classical solvers toward quantum light matter interactions.

</details>


### [340] [Spontaneous symmetry breaking in nonlinear superradiance](https://arxiv.org/abs/2511.03590)
*Nikolai D. Klimkin,Misha Ivanov*

Main category: quant-ph

TL;DR: 通过利用基于对称性的选择规则来抑制单光子发射，从而在原子和光子模式的集体对称性破缺态中产生非经典光。


<details>
  <summary>Details</summary>
Motivation: 现代阿秒科学正日益关注非经典光态的产生和操控。

Method: 研究了由相互作用的原子系综发出的光子发射问题，并利用对称性选择规则抑制了单光子发射。应用了新颖的非马尔可夫、非微扰方法。 

Result: 观察到当系统经历对称性破缺转变时，会形成大量光量子态，并表现出显著的非经典统计特性。

Conclusion: 通过抑制单光子发射，可以产生非经典光态。

Abstract: Creation and manipulation of non-classical states of light is rapidly
becoming the focus of modern attosecond science. Here, we demonstrate
numerically how such states can arise by considering a modification of the
well-known problem of superradiance encountered already by Dicke. Similarly to
him, we investigate photon emission by ensembles of indistinguishable atoms. In
contrast to him, however, we leverage symmetry-based selection rules to
suppress emission of single photons by single atoms. A steady state is
therefore only reached following a spontaneous transition into a collective
symmetry-broken state of atoms and photonic modes. The novel non-Markovian,
non-perturbative method applied allows us to observe a large quantum state of
light form and exhibit drastically non-classical statistics once the system
undergoes a symmetry-breaking transition.

</details>


### [341] [Directional quantum walks of two bosons on the Hatano-Nelson lattice](https://arxiv.org/abs/2511.03613)
*Sk Anisur,Kartik Singh,Sayan Choudhury*

Main category: quant-ph

TL;DR: 非互易性传输导致密度锥不对称，可调。非厄米性导致双粒子布洛赫振荡不对称。强相互作用下出现内密度锥（沙漏）结构，该结构在非厄米性下也变得不对称。系统表现出非互易的聚集（反聚集）。量子Fisher信息随时间增长，可用于传感。


<details>
  <summary>Details</summary>
Motivation: 理论研究相互作用和非厄米性在非互易隧穿的Hatano-Nelson格子上两个玻色子的动力学中的相互作用。

Method: 分析了系统在静态外力作用下的动力学，研究了其空间相关性，并检验了量子Fisher信息的增长。

Result: 非互易性导致密度锥不对称；非厄米性导致双粒子布洛赫振荡不对称；强相互作用下出现内密度锥（沙漏）结构，该结构在非厄米性下也变得不对称；系统表现出非互易的聚集（反聚集）；量子Fisher信息随时间呈 $t^{\alpha}$ ($\alpha \sim 3$) 的增长规律。

Conclusion: 该系统可以作为量子增强传感器来检测弱力。

Abstract: We theoretically investigate the interplay of interactions and
non-Hermiticity in the dynamics of two bosons on the one-dimensional
Hatano-Nelson lattice with non-reciprocal tunneling. We find that the
non-reciprocity in the tunneling leads to the formation of an asymmetric
density cone during the time-evolution of the system; the degree of asymmetry
can be tuned by tuning the non-reciprocity parameter, $\delta$. Next, we
analyze the dynamics of this system in the presence of a static external force
and demonstrate that non-Hermiticity leads to asymmetric two-particle Bloch
oscillations. Interestingly, when $F=0$ ($F \ne 0$), strong interactions leads
to the formation of an inner density-cone (density-hourglass) structure; this
inner structure also becomes asymmetric in the presence of non-Hermiticity. We
further analyze the spatial correlations and establish that the system exhibits
non-reciprocal bunching (anti-bunching) in the presence of weak (strong)
interactions. Finally, we examine the growth of the Quantum Fisher Information,
$F_Q$, with time, and demonstrate that $F_Q \propto t^{\alpha}$ where $\alpha
\sim 3$. This feature persists for both one- and two-particle walks, thereby
demonstrating that this system can be employed as a quantum-enhanced sensor for
detecting weak forces.

</details>


### [342] [Annual-modulation fingerprint of the axion wind induced sideband triplet in quantum dot spin qubit sensors](https://arxiv.org/abs/2511.03630)
*Xiangjun Tan,Zhanning Wang*

Main category: quant-ph

TL;DR: 该论文提出了一种基于硅量子点自旋量子比特的相位相干、窄带磁力计，用于搜索轴子/类轴子粒子（ALPs）与电子自旋之间的耦合。


<details>
  <summary>Details</summary>
Motivation: 寻找轴子/类轴子粒子（ALPs）与电子自旋之间的耦合，并利用自旋量子比特进行探测。

Method: 使用重复的拉姆齐回波序列和色散读出，以亚赫兹的光谱分辨率跟踪量子比特的进动响应。通过一系列滤波协议来确定可及的轴子质量窗口，同时考虑了读出误差和1/f噪声等传感噪声。

Result: 在1-10 μeV的轴子质量范围内，探测到的轴子-电子耦合强度（gae）为10^-14到10^-10。通过分析地球自转产生的振幅调制，以及地球公转产生的以±Ω⊕为间隔的边带，为轴子-电子相互作用提供了实验室验证。

Conclusion: 自旋量子比特磁力计在寻找轴子-电子相互作用方面具有接近天体物理学考虑的灵敏度，为该领域提供了实验室层面的探测手段。该方法也可广泛应用于其他基于自旋的量子传感器。

Abstract: We propose a phase-coherent, narrowband magnetometer for searching couplings
between axions or axion-like particles (ALPs) and electron spins, using
gate-defined silicon quantum-dot spin qubits. With repeated Ramsey echo
sequences and dispersive readout, the qubit precession response can be tracked
with sub-Hz spectral resolution. The accessible axion mass window is determined
using a series of filtering protocols that take into account sensing noise,
including readout errors and $1/f$ noise. We demonstrate clear evidence of
sidereal modulation of the signal due to Earth's rotation, while Earth's
orbital motion produces an annual amplitude envelope that generates sidebands
at fixed frequency spacing $\pm \Omega_\oplus$ around the sidereal component.
For axion masses between $1$-$10~\mu{\rm eV}$, the proposed method covers
axion-electron coupling strengths $g_{ae}$ ranging from $10^{-14}$ to
$10^{-10}$. Including both daily and annual modulation patterns in the
likelihood analysis enhances the rejection of stationary or instrumental noise.
Our results indicate that spin-qubit magnetometry can achieve sensitivities
approaching those suggested by astrophysical considerations, providing a
complementary, laboratory-based probe of axion-electron interactions. Although
we focus on silicon spin-qubit architectures, the approach is broadly
applicable to spin-based quantum sensors.

</details>


### [343] [Correlation-Powered Work: Equivalence in Peak Yield, Differences in Robustness](https://arxiv.org/abs/2511.03679)
*Karl Svozil*

Main category: quant-ph

TL;DR: 环境和系统的初始相关性是可用于提取功的热力学资源。本文比较了经典、量子和超量子相关性在测量未对准情况下的功潜力。虽然所有模型都能达到k_B T ln 2的最大可提取功，这对应于ln 2的互信息，但它们作为资源 M 的价值在鲁棒性方面存在关键差异。经典资源是脆弱的，随未对准线性衰减，而量子资源是鲁棒的，仅呈二次方衰减。因此，非局域性的程度并不对应于相关性的最大能量值，而是对应于其作为热力学燃料的操作鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨初始系统-环境相关性作为一种热力学资源，以及其在提取功方面的潜力。

Method: 通过比较经典、量子和超量子相关性在测量未对准情况下的功潜力来分析。

Result: 所有模型都能达到k_B T ln 2的最大可提取功（对应于ln 2的互信息），但它们的鲁棒性不同。经典资源随未对准线性衰减，量子资源仅呈二次方衰减。

Conclusion: 非局域性的程度并不对应于相关性的最大能量值，而是对应于其作为热力学燃料的操作鲁棒性。量子相关性比经典相关性更鲁棒。

Abstract: Initial system-environment correlations are a thermodynamic resource,
enabling work extraction via their erasure. We compare the work potential of
classical, quantum, and hypothetical stronger-than-quantum correlations as a
function of measurement misalignment. While all models can yield a peak
extractable work of k_B T ln 2, corresponding to a mutual information of ln 2,
their value as a resource differs critically in its robustness. The classical
resource is fragile, decaying linearly with misalignment, whereas the quantum
resource is robust, decaying only quadratically. Thus, the degree of
nonlocality maps not to the maximum energetic value of a correlation, but to
its operational robustness as a thermodynamic fuel.

</details>


### [344] [Certified randomness amplification by dynamically probing remote random quantum states](https://arxiv.org/abs/2511.03686)
*Minzhao Liu,Pradeep Niroula,Matthew DeCross,Cameron Foreman,Wen Yu Kon,Ignatius William Primaatmaja,M. S. Allman,J. P. Campora III,Akhil Isanaka,Kartik Singhal,Omar Amer,Shouvanik Chakrabarti,Kaushik Chakraborty,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Cameron Foltz,John P. Gaebler,Alex Hall,Zichang He,Craig A. Holliman,Travis S. Humble,Shih-Han Hung,Ali A. Husain,Yuwei Jin,Fatih Kaleoglu,Colin J. Kennedy,Nikhil Kotibhaskar,Nathan K. Lysne,Ivaylo S. Madjarov,Michael Mills,Alistair R. Milne,Kevin Milner,Louis Narmour,Sivaprasad Omanakuttan,Annie J. Park,Michael A. Perlin,Adam P. Reed,Chris N. Self,Matthew Steinberg,David T. Stephen,Joseph Sullivan,Alex Chernoguzov,Florian J. Curchod,Anthony Ransford,Justin G. Bohnet,Brian Neyenhuis,Michael Foss-Feig,Rob Otter,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: 通过在量子的98量子比特Helios量子处理器上动态探测大的、纠缠的量子态，跨网络实现了认证随机性放大。该协议即使在远程设备受到恶意攻击或被窃听的情况下也是安全的，并且在随机电路上实现了0.586的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的认证随机性放大方法依赖于物理上共址的、无漏洞的贝尔测试，这限制了远程操作的可行性。

Method: 在量子的98量子比特Helios量子处理器上动态探测大的、纠缠的量子态，并跨网络实现认证随机性放大。该协议通过实时向量子处理器传输量子门，并将测量基的揭示时间限制在测量前几毫秒，从而限制了经典模拟或伪造的可能性。

Result: 在具有64个量子比特和276个两比特门的随机电路上实现了0.586的保真度，能够将具有低熵率的现实不完美随机性放大为近乎完美的随机性。

Conclusion: 该研究实现了跨网络的认证随机性放大，克服了现有方法的限制，并为需要高质量随机数的密码学等应用提供了新的可能性。

Abstract: Cryptography depends on truly unpredictable numbers, but physical sources
emit biased or correlated bits. Quantum mechanics enables the amplification of
imperfect randomness into nearly perfect randomness, but prior demonstrations
have required physically co-located, loophole-free Bell tests, constraining the
feasibility of remote operation. Here we realize certified randomness
amplification across a network by dynamically probing large, entangled quantum
states on Quantinuum's 98-qubit Helios trapped-ion quantum processor. Our
protocol is secure even if the remote device acts maliciously or is compromised
by an intercepting adversary, provided the samples are generated quickly enough
to preclude classical simulation of the quantum circuits. We stream quantum
gates in real time to the quantum processor, maintain quantum state coherence
for $\approx 0.9$ seconds, and then reveal the measurement bases to the quantum
processor only milliseconds before measurement. This limits the time for
classical spoofing to 30 ms and constrains the location of hypothetical
adversaries to a $4{,}500$ km radius. We achieve a fidelity of 0.586 on random
circuits with 64 qubits and 276 two-qubit gates, enabling the amplification of
realistic imperfect randomness with a low entropy rate into nearly perfect
randomness.

</details>


### [345] [Frequency shifts as a reflection of ground state squeezing and entanglement in two coupled harmonic oscillators](https://arxiv.org/abs/2511.03687)
*Safoura Mirkhalaf,Helmut Ritsch,Karol Gietka*

Main category: quant-ph

TL;DR: 即使在冷却到基态，两个耦合量子谐振子也可能表现出超越量化能级的量子特征，其可观测的经典物理量可以编码真正的量子特征。


<details>
  <summary>Details</summary>
Motivation: 挑战了两个耦合量子谐振子（即使冷却到其基态）也仅表现出量化能级等量子特征的观点。

Method: 证明了所观察到的特征频率偏移可以作为非经典关联和基态纠缠（特别是未耦合模式间的双模压缩）的标志。

Result: 频率偏移和压缩是同一现象在不同模式基下的表现。这些偏移可以作为通过标准频率测量可访问的纠缠见证。压缩虽然不能直接测量，但可用于在不要求压缩量子噪声的情况下提高单个振荡器精密频率测量的信噪比。

Conclusion: 揭示了一种在传统上被视为经典但实际上包含量子特性的系统中实现量子增强传感的新途径，并为量子特性如何跨越量子-经典边界提供新见解。

Abstract: It is often argued that two coupled quantum harmonic oscillators, even when
cooled to their ground state, display no inherently quantum features beyond
quantized energy levels. Here, we challenge this view by showing that their
classical observables can encode genuinely quantum features. In particular, we
demonstrate that the characteristic frequency shifts observed in such systems
act as a signature of non-classical correlations and ground-state entanglement
at zero temperature, specifically two-mode squeezing between the uncoupled
modes. From a complementary perspective, these two effects -- frequency shifts
and squeezing -- represent the same underlying phenomenon expressed in
different mode bases. What appears as a spectral renormalization in one
description manifests as entanglement in another. These shifts therefore can
serve as an entanglement witness accessible via standard frequency
measurements. Furthermore, we show that this underlying squeezing, although not
directly measurable, can be exploited to enhance the signal-to-noise ratio in
precision frequency measurements of individual oscillators without requiring
squeezed quantum noise. Our results uncover a new route to quantum-enhanced
sensing within systems traditionally regarded as classical, offering fresh
insight into how signatures of quantumness persist across the
quantum-to-classical boundary.

</details>


### [346] [Realization of a Quantum Streaming Algorithm on Long-lived Trapped-ion Qubits](https://arxiv.org/abs/2511.03689)
*Pradeep Niroula,Shouvanik Chakrabarti,Steven Kordonowy,Niraj Kumar,Sivaprasad Omanakuttan,Michael A. Perlin,M. S. Allman,J. P. Campora III,Alex Chernoguzov,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Cameron Foltz,John P. Gaebler,Alex Hall,Ali A. Husain,Akhil Isanaka,Colin J. Kennedy,Nikhil Kotibhaskar,Ivaylo S. Madjarov,Michael Mills,Alistair R. Milne,Louis Narmour,Annie J. Park,Adam P. Reed,Kartik Singhal,Anthony Ransford,Justin G. Bohnet,Brian Neyenhuis,Rob Otter,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: 该工作在Quantinuum Helios离子阱量子计算机上实现了量子流模型，并解决了Hidden Matching问题，证明了量子计算机在空间复杂度上的指数优势，且该优势在容错后依然存在。


<details>
  <summary>Details</summary>
Motivation: 量子算法在流模型下展现出指数级的空间优势，但实验实现面临量子比特相干性挑战。

Method: 在离子阱量子计算机上实现了量子流模型，包括量子配对草图（quantum pair sketch），并解决了Hidden Matching问题。同时，将量子流算法编译到基于表面码和双变量自行车码的容错量子架构上。

Result: 成功在量子计算机上实现了量子流模型和Hidden Matching问题的求解，证明了量子空间优势。仿真表明，容错开销不会消除这种优势。

Conclusion: 量子计算机在流模型下具有显著的空间优势，并且这种优势在容错量子计算中得以保持。

Abstract: Large classical datasets are often processed in the streaming model, with
data arriving one item at a time. In this model, quantum algorithms have been
shown to offer an unconditional exponential advantage in space. However,
experimentally implementing such streaming algorithms requires qubits that
remain coherent while interacting with an external data stream. In this work,
we realize such a data-streaming model using Quantinuum Helios trapped-ion
quantum computer with long-lived qubits that communicate with an external
server. We implement a quantum pair sketch, which is the primitive underlying
many quantum streaming algorithms, and use it to solve Hidden Matching, a
problem known to exhibit a theoretical exponential quantum advantage in space.
Furthermore, we compile the quantum streaming algorithm to fault-tolerant
quantum architectures based on surface and bivariate bicycle codes and show
that the quantum space advantage persists even with the overheads of
fault-tolerance.

</details>


### [347] [A Transferable Machine Learning Approach to Predict Quantum Circuit Parameters for Electronic Structure Problems](https://arxiv.org/abs/2511.03726)
*Davide Bincoletto,Korbinian Stein,Jonas Motyl,Jakob S. Kottmann*

Main category: quant-ph

TL;DR: 机器学习可将量子电路参数泛化到不同分子。


<details>
  <summary>Details</summary>
Motivation: 优化量子电路参数是变分量子本征求解器应用于电子系统的瓶颈，现有方法主要针对特定分子或同一分子的不同构象，缺乏在不同分子间的泛化能力。

Method: 利用机器学习模型，探索跨分子传递参数的策略，并应用于氢化物系统。

Result: 实现了参数预测的系统化泛化，能够推广到比训练实例大得多的分子。

Conclusion: 机器学习在量子化学计算中具有泛化能力，可以提高量子电路参数优化的效率。

Abstract: The individual optimization of quantum circuit parameters is currently one of
the main practical bottlenecks in variational quantum eigensolvers for
electronic systems. To this end, several machine learning approaches have been
proposed to mitigate the problem. However, such method predominantly aims at
training and predicting parameters tailored to individual molecules: either a
specific structure, or several structures of the same molecule with varying
bond lengths. This work explores machine learning based modeling strategies to
include transferability between different molecules. We use a well investigated
quantum circuit design and apply it to model properties of hydrogenic systems
where we show parameter prediction that is systematically transferable to
instances significantly larger than the training instances.

</details>
