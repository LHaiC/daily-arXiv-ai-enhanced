<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 59]
- [cs.CL](#cs.CL) [Total: 34]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 6]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.SI](#cs.SI) [Total: 4]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 57]
- [quant-ph](#quant-ph) [Total: 45]
- [cs.DS](#cs.DS) [Total: 2]
- [eess.SY](#eess.SY) [Total: 10]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 20]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.RO](#cs.RO) [Total: 20]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.GT](#cs.GT) [Total: 2]
- [physics.app-ph](#physics.app-ph) [Total: 6]
- [eess.SP](#eess.SP) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving](https://arxiv.org/abs/2508.21080)
*Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult*

Main category: cs.CV

TL;DR: 2COOOL workshop focuses on novelty handling for safe autonomous driving at ICCV 2025, addressing challenges like out-of-distribution hazard detection and promoting new algorithms.


<details>
  <summary>Details</summary>
Motivation: The core motivation is to address the critical barrier of novel/unseen scenarios in autonomous driving, which hinders the development of entirely safe self-driving cars. The workshop aims to advance the integration of vision-based insights with sensor data for improved perception, decision making, planning, prediction, simulation, and control by focusing on novelty handling.

Method: The workshop facilitates a forum for researchers and industry experts to discuss and present advancements in novelty handling for autonomous driving. This includes areas such as out-of-distribution hazard detection, using vision-language models for hazard understanding, developing new benchmarking and methodologies, and establishing safe autonomous driving practices. It also aims to draw inspiration from fields like anomaly detection, open-set recognition, open-vocabulary modeling, and domain adaptation.

Result: The workshop aims to inspire the development of new algorithms and systems for hazard avoidance in autonomous driving. It builds upon the success of its previous edition and will feature academic and industry participation, fostering progress in safe autonomous driving practices.

Conclusion: The 2COOOL workshop at ICCV 2025 is dedicated to tackling the challenge of out-of-label hazards in autonomous driving, with the ultimate goal of enabling safer self-driving cars by improving the handling of novel and unseen scenarios.

Abstract: As the computer vision community advances autonomous driving algorithms,
integrating vision-based insights with sensor data remains essential for
improving perception, decision making, planning, prediction, simulation, and
control. Yet we must ask: Why don't we have entirely safe self-driving cars
yet? A key part of the answer lies in addressing novel scenarios, one of the
most critical barriers to real-world deployment. Our 2COOOL workshop provides a
dedicated forum for researchers and industry experts to push the state of the
art in novelty handling, including out-of-distribution hazard detection,
vision-language models for hazard understanding, new benchmarking and
methodologies, and safe autonomous driving practices. The 2nd Workshop on the
Challenge of Out-of-Label Hazards in Autonomous Driving (2COOOL) will be held
at the International Conference on Computer Vision (ICCV) 2025 in Honolulu,
Hawaii, on October 19, 2025. We aim to inspire the development of new
algorithms and systems for hazard avoidance, drawing on ideas from anomaly
detection, open-set recognition, open-vocabulary modeling, domain adaptation,
and related fields. Building on the success of its inaugural edition at the
Winter Conference on Applications of Computer Vision (WACV) 2025, the workshop
will feature a mix of academic and industry participation.

</details>


### [2] [Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images](https://arxiv.org/abs/2508.21088)
*Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni*

Main category: cs.CV

TL;DR: 本研究利用深度学习技术对牙科X光片进行自动分类，其中CNN-随机森林混合模型在准确率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 对牙科X光片进行自动分类，以辅助牙科诊断。

Method: 评估了定制卷积神经网络（CNN）、混合模型（CNN特征提取+传统分类器）以及微调的预训练模型（VGG16、Xception、ResNet50）。

Result: 混合CNN-随机森林模型达到了85.4%的准确率，优于定制CNN（74.3%）和预训练模型（VGG16为82.3%）。

Conclusion: 混合模型能够提高对形态相似的牙科病症的区分能力，并提供高效可靠的性能，为自动牙科诊断支持提供了一条可行的途径。

Abstract: This study investigates deep learning methods for automated classification of
dental conditions in panoramic X-ray images. A dataset of 1,512 radiographs
with 11,137 expert-verified annotations across four conditions fillings,
cavities, implants, and impacted teeth was used. After preprocessing and class
balancing, three approaches were evaluated: a custom convolutional neural
network (CNN), hybrid models combining CNN feature extraction with traditional
classifiers, and fine-tuned pre-trained architectures. Experiments employed 5
fold cross validation with accuracy, precision, recall, and F1 score as
evaluation metrics. The hybrid CNN Random Forest model achieved the highest
performance with 85.4% accuracy, surpassing the custom CNN baseline of 74.3%.
Among pre-trained models, VGG16 performed best at 82.3% accuracy, followed by
Xception and ResNet50. Results show that hybrid models improve discrimination
of morphologically similar conditions and provide efficient, reliable
performance. These findings suggest that combining CNN-based feature extraction
with ensemble classifiers offers a practical path toward automated dental
diagnostic support, while also highlighting the need for larger datasets and
further clinical validation.

</details>


### [3] [Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment](https://arxiv.org/abs/2508.21090)
*Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu*

Main category: cs.CV

TL;DR: Q-Align通过查询-查询对齐来解决零样本风格迁移中的注意力泄露问题，并在视觉保真度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 零样本风格迁移（zero-shot appearance transfer）在利用大型图像生成模型时面临注意力泄露（Attention Leakage）的挑战，这是由于查询-键（Query-Key）对齐捕获了图像间的语义映射。

Method: 提出Q-Align，采用查询-查询（Query-Query）对齐来减轻注意力泄露，并利用键-值（Key-Value）重排来增强特征对应，最后通过重排的键和值进行注意力优化以保持语义一致性。

Result: Q-Align在视觉保真度方面优于现有最先进方法，并保持了具有竞争力的结构保持能力。

Conclusion: Q-Align通过其提出的查询-查询对齐、键-值重排和注意力优化机制，有效解决了零样本风格迁移中的注意力泄露问题，并在视觉保真度和结构保持方面取得了优越性能。

Abstract: We observe that zero-shot appearance transfer with large-scale image
generation models faces a significant challenge: Attention Leakage. This
challenge arises when the semantic mapping between two images is captured by
the Query-Key alignment. To tackle this issue, we introduce Q-Align, utilizing
Query-Query alignment to mitigate attention leakage and improve the semantic
alignment in zero-shot appearance transfer. Q-Align incorporates three core
contributions: (1) Query-Query alignment, facilitating the sophisticated
spatial semantic mapping between two images; (2) Key-Value rearrangement,
enhancing feature correspondence through realignment; and (3) Attention
refinement using rearranged keys and values to maintain semantic consistency.
We validate the effectiveness of Q-Align through extensive experiments and
analysis, and Q-Align outperforms state-of-the-art methods in appearance
fidelity while maintaining competitive structure preservation.

</details>


### [4] [ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion](https://arxiv.org/abs/2508.21091)
*Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin*

Main category: cs.CV

TL;DR: ERTACache通过修正特征偏移和步长放大误差，在不牺牲视觉质量的情况下将扩散模型的推理速度提高一倍。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的推理过程计算开销很大，而特征缓存虽然能加速，但容易导致质量下降。本研究旨在解决这一问题。

Method: 提出ERTACache框架，通过离线残差分析识别可重用步长，动态调整积分区间，并使用闭式残差线性化模型近似缓存引起的误差。

Result: ERTACache在图像和视频生成基准上实现了高达2倍的推理加速，同时保持甚至提高了视觉质量。在Wan2.1视频扩散模型上，ERTACache实现了2倍加速，VBench降级极小。

Conclusion: ERTACache是一种有效的缓存框架，可以显著提高扩散模型的推理效率，同时保持高质量的生成结果。

Abstract: Diffusion models suffer from substantial computational overhead due to their
inherently iterative inference process. While feature caching offers a
promising acceleration strategy by reusing intermediate outputs across
timesteps, naive reuse often incurs noticeable quality degradation. In this
work, we formally analyze the cumulative error introduced by caching and
decompose it into two principal components: feature shift error, caused by
inaccuracies in cached outputs, and step amplification error, which arises from
error propagation under fixed timestep schedules. To address these issues, we
propose ERTACache, a principled caching framework that jointly rectifies both
error types. Our method employs an offline residual profiling stage to identify
reusable steps, dynamically adjusts integration intervals via a
trajectory-aware correction coefficient, and analytically approximates
cache-induced errors through a closed-form residual linearization model.
Together, these components enable accurate and efficient sampling under
aggressive cache reuse. Extensive experiments across standard image and video
generation benchmarks show that ERTACache achieves up to 2x inference speedup
while consistently preserving or even improving visual quality. Notably, on the
state-of-the-art Wan2.1 video diffusion model, ERTACache delivers 2x
acceleration with minimal VBench degradation, effectively maintaining baseline
fidelity while significantly improving efficiency. The code is available at
https://github.com/bytedance/ERTACache.

</details>


### [5] [Video-LLMs with Temporal Visual Screening](https://arxiv.org/abs/2508.21094)
*Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.,Fung,Manling Li,Heng Ji*

Main category: cs.CV

TL;DR: 本项目提出了一种名为时间视觉筛选（TVS）的新任务，通过保留关键时间段、重构查询和保持答案一致性来改进视频语言模型。TVS 作为一种前端适配器，可集成到训练和推理流程中，优化推理负担和认知负荷。实验结果表明，TVS 显著提高了视频语言理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型（Video-LLMs）在捕捉细粒度时间语义方面存在困难，因为它们采用稀疏帧采样并且缺乏跨帧推理监督。为了解决这个问题，受到认知科学原理的启发，我们提出了时间视觉筛选（TVS）任务。

Method: TVS 任务通过三个步骤来预处理视频问答和指令微调数据：（1）保留关注关键视频片段；（2）同步将查询重构为其最直接的形式，同时保持答案一致性；（3）保持任何可能答案的不变性和一致性。TVS 被设计为一个模块化的前端适配器，可以无缝集成到视频指令微调（训练）和视频问答（推理）流程中。它通过在训练期间对齐查询与关键视频信息，并在推理时实现查询感知片段关注和简化的查询表示，来优化推理负担和认知负荷。

Result: TVS 任务的实现和评估是通过一个专门为此任务设计的基准和名为 ReSimplifyIt 的基线模型来完成的。ReSimplifyIt 在视频修剪任务上的 F-1 分数比现有方法高 0.47，并在查询重写方面取得了具有竞争力的性能。实验结果表明，将 TVS 集成到模型中，在训练阶段带来了 7.33% 的相对提升，在推理阶段带来了 34.6% 的相对提升，证明了时间信息筛选在提升视频语言理解能力方面的有效性。

Conclusion: 时间视觉筛选（TVS）任务通过精炼视频数据和查询，能够显著提升视频语言模型的性能。该方法通过优化推理负担和认知负荷，有效解决了当前模型在处理细粒度时间语义方面的挑战。实验结果有力地证明了 TVS 在提高视频问答和指令遵循能力方面的潜力。

Abstract: Humans naturally perform temporal screening by dragging the progress bar and
focusing on salient temporal segments, but current Video Large Language Models
(Video-LLMs) struggle to capture fine-grained temporal semantics due to sparse
frame sampling and insufficient inter-frame reasoning supervision during their
training. To address this, Inspired by well-established cognitive science
principles, we propose Temporal Visual Screening (TVS), a new task that
universally pre-processes video question answering and instruction tuning data
by: (1) retaining focus-critical video segments, (2) synchronously
reconstructing queries to their most direct form while preserving answer
consistency, and (3) keeping the invariance and consistency for any possible
answer. TVS is formulated as a modular front-end adapter task that can be
seamlessly integrated into both Video Instruction Tuning (training) and Video
Question Answering (inference) pipelines. TVS optimizes distribution of
reasoning burden and cognitive load; during training, it aligns queries with
focus-critical visual information; at inference, it enables query-aware segment
focus and streamlined query representations. In particular, we curate the first
benchmark for TVS and propose ReSimplifyIt, a baseline outperforming prior
approaches on seemingly similar tasks by 0.47 in F-1 score on video trimming
while achieving competitive query rewriting performance. Experiments
demonstrate that incorporating TVS yields relative gains of 7.33% (training)
and 34.6% (inference), demonstrating the effectiveness of temporal information
screening for improving video-language understanding.

</details>


### [6] [ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments](https://arxiv.org/abs/2508.21096)
*Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren*

Main category: cs.CV

TL;DR: ROBUST-MIPS是一个新的数据集，包含手术工具的姿态和实例分割标注，旨在提高手术工具定位的效率和数据可用性。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习模型在分割任务上的性能受限于标注数据的可用性。作者认为，骨骼姿态标注比像素级标注更有效，能在丰富的语义信息和标注简易性之间取得平衡，从而加速标注数据的增长。

Method: 作者提出了ROBUST-MIPS数据集，该数据集源自ROBUST-MIS数据集，并增加了工具姿态标注。他们还建立了一个基准测试，使用流行的姿态估计方法来评估姿态标注在手术工具定位方面的有效性。

Result: 基准测试结果显示，姿态标注可以实现高质量的手术工具定位，证明了其有效性。

Conclusion: 作者认为姿态标注是手术工具定位的一种有效方法，并发布了ROBUST-MIPS数据集、基准模型和标注软件，以鼓励这种标注方式的采纳。

Abstract: Localisation of surgical tools constitutes a foundational building block for
computer-assisted interventional technologies. Works in this field typically
focus on training deep learning models to perform segmentation tasks.
Performance of learning-based approaches is limited by the availability of
diverse annotated data. We argue that skeletal pose annotations are a more
efficient annotation approach for surgical tools, striking a balance between
richness of semantic information and ease of annotation, thus allowing for
accelerated growth of available annotated data. To encourage adoption of this
annotation style, we present, ROBUST-MIPS, a combined tool pose and tool
instance segmentation dataset derived from the existing ROBUST-MIS dataset. Our
enriched dataset facilitates the joint study of these two annotation styles and
allow head-to-head comparison on various downstream tasks. To demonstrate the
adequacy of pose annotations for surgical tool localisation, we set up a simple
benchmark using popular pose estimation methods and observe high-quality
results. To ease adoption, together with the dataset, we release our benchmark
models and custom tool pose annotation software.

</details>


### [7] [Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models](https://arxiv.org/abs/2508.21099)
*Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite the advancements in Text-to-Image (T2I) generation models, their
potential for misuse or even abuse raises serious safety concerns. Model
developers have made tremendous efforts to introduce safety mechanisms that can
address these concerns in T2I models. However, the existing safety mechanisms,
whether external or internal, either remain susceptible to evasion under
distribution shifts or require extensive model-specific adjustments. To address
these limitations, we introduce Safe-Control, an innovative plug-and-play
safety patch designed to mitigate unsafe content generation in T2I models.
Using data-driven strategies and safety-aware conditions, Safe-Control injects
safety control signals into the locked T2I model, acting as an update in a
patch-like manner. Model developers can also construct various safety patches
to meet the evolving safety requirements, which can be flexibly merged into a
single, unified patch. Its plug-and-play design further ensures adaptability,
making it compatible with other T2I models of similar denoising architecture.
We conduct extensive evaluations on six diverse and public T2I models.
Empirical results highlight that Safe-Control is effective in reducing unsafe
content generation across six diverse T2I models with similar generative
architectures, yet it successfully maintains the quality and text alignment of
benign images. Compared to seven state-of-the-art safety mechanisms, including
both external and internal defenses, Safe-Control significantly outperforms all
baselines in reducing unsafe content generation. For example, it reduces the
probability of unsafe content generation to 7%, compared to approximately 20%
for most baseline methods, under both unsafe prompts and the latest adversarial
attacks.

</details>


### [8] [GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions](https://arxiv.org/abs/2508.21102)
*Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura*

Main category: cs.CV

TL;DR: GENNAV是一个用于从自然语言指令和前置摄像头图像中识别目标区域（特别是边界模糊的“stuff”类型区域）的新方法。它解决了现有方法在处理“stuff”类型区域、缺失目标或多个目标时表现不佳的问题。GENNAV通过预测目标存在并生成分割掩码来克服这些挑战。为了评估GENNAV，研究人员构建了一个名为GRiN-Drive的新基准，其中包含无目标、单目标和多目标三种样本类型。实验结果表明，GENNAV在标准评估指标上优于基线方法，并且在真实世界的跨领域迁移实验中表现出良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理“stuff”类型的目标区域（边界模糊）时表现不佳，并且在处理缺失目标或多个目标时也存在不足。本研究旨在克服这些限制。

Method: 提出GENNAV模型，该模型能够预测目标的存在并为多个“stuff”类型的目标区域生成分割掩码。为评估GENNAV，构建了一个名为GRiN-Drive的新基准，该基准包含三种类型的样本：无目标、单目标和多目标。

Result: GENNAV在GRiN-Drive基准上实现了优于基线方法的性能。在真实世界的跨领域迁移实验中，GENNAV同样表现优于基线方法，并证明了其在不同真实环境下的鲁棒性。

Conclusion: GENNAV是一种有效的方法，能够从自然语言指令和摄像头图像中准确识别目标区域，特别是处理边界模糊的“stuff”类型区域，并且在各种真实世界场景下具有良好的泛化能力。

Abstract: We focus on the task of identifying the location of target regions from a
natural language instruction and a front camera image captured by a mobility.
This task is challenging because it requires both existence prediction and
segmentation, particularly for stuff-type target regions with ambiguous
boundaries. Existing methods often underperform in handling stuff-type target
regions, in addition to absent or multiple targets. To overcome these
limitations, we propose GENNAV, which predicts target existence and generates
segmentation masks for multiple stuff-type target regions. To evaluate GENNAV,
we constructed a novel benchmark called GRiN-Drive, which includes three
distinct types of samples: no-target, single-target, and multi-target. GENNAV
achieved superior performance over baseline methods on standard evaluation
metrics. Furthermore, we conducted real-world experiments with four automobiles
operated in five geographically distinct urban areas to validate its zero-shot
transfer performance. In these experiments, GENNAV outperformed baseline
methods and demonstrated its robustness across diverse real-world environments.
The project page is available at https://gennav.vercel.app/.

</details>


### [9] [R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning](https://arxiv.org/abs/2508.21113)
*Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng*

Main category: cs.CV

TL;DR: R-4B是一个能够根据问题复杂度自适应地决定是否进行思考的多模态大语言模型，通过双模态退火和双模态策略优化（BPO）提升了决策准确性，在25个基准测试中取得了最先进的性能，并在推理密集型基准测试上实现了与更大模型相媲美的性能，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理复杂推理问题时，即使对于简单问题也进行了冗余的逐步思考，这导致了效率低下。本研究旨在解决这一问题。

Method: 提出了一种名为R-4B的自动思考多模态大语言模型。R-4B采用双模态退火技术，使其能够同时具备思考和非思考的能力，并通过双模态策略优化（BPO）来提高模型判断何时激活思考过程的准确性。首先，模型在一个包含思考和非思考模式样本的精心策划的数据集上进行训练。随后，在改进的GRPO框架下进行第二阶段训练，迫使策略模型为每个输入查询生成两种模式的响应。

Result: R-4B在25个具有挑战性的基准测试中取得了最先进的性能。在大多数任务中，其表现优于Qwen2.5-VL-7B。在推理密集型基准测试上，其性能与16B的Kimi-VL-A3B-Thinking-2506相当，但计算成本更低。

Conclusion: R-4B通过其自适应的思考机制，在效率和性能之间取得了良好的平衡，为多模态大语言模型在处理不同复杂度问题时提供了一种更优化的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) equipped with step-by-step thinking
capabilities have demonstrated remarkable performance on complex reasoning
problems. However, this thinking process is redundant for simple problems
solvable without complex reasoning. To address this inefficiency, we propose
R-4B, an auto-thinking MLLM, which can adaptively decide when to think based on
problem complexity. The central idea of R-4B is to empower the model with both
thinking and non-thinking capabilities using bi-mode annealing, and apply
Bi-mode Policy Optimization~(BPO) to improve the model's accuracy in
determining whether to activate the thinking process. Specifically, we first
train the model on a carefully curated dataset spanning various topics, which
contains samples from both thinking and non-thinking modes. Then it undergoes a
second phase of training under an improved GRPO framework, where the policy
model is forced to generate responses from both modes for each input query.
Experimental results show that R-4B achieves state-of-the-art performance
across 25 challenging benchmarks. It outperforms Qwen2.5-VL-7B in most tasks
and achieves performance comparable to larger models such as
Kimi-VL-A3B-Thinking-2506 (16B) on reasoning-intensive benchmarks with lower
computational cost.

</details>


### [10] [HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection](https://arxiv.org/abs/2508.21135)
*Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed*

Main category: cs.CV

TL;DR: HiddenObject是一个融合RGB、热成像和深度数据的Mamba基融合框架，用于在遮挡、伪装和光照变化等挑战性条件下检测隐藏物体，并在多个基准数据集上实现了最先进或具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 由于RGB方法在遮挡、伪装和光照变化等不利条件下性能不佳，因此需要更鲁棒、与模态无关的方法来检测隐藏或部分隐藏的物体。

Method: 该方法提出了一种名为HiddenObject的融合框架，该框架使用Mamba基融合机制整合RGB、热成像和深度数据，以捕捉跨模态的互补信号，从而增强对模糊或伪装目标的检测能力。

Result: HiddenObject在多个基准数据集上的表现优于或媲美现有方法，证明了其融合设计的有效性，并揭示了当前单模态和朴素融合策略的关键局限性。

Conclusion: 基于Mamba的融合架构能够显著推进多模态物体检测领域的发展，尤其是在视觉退化或复杂条件下。

Abstract: Detecting hidden or partially concealed objects remains a fundamental
challenge in multimodal environments, where factors like occlusion, camouflage,
and lighting variations significantly hinder performance. Traditional RGB-based
detection methods often fail under such adverse conditions, motivating the need
for more robust, modality-agnostic approaches. In this work, we present
HiddenObject, a fusion framework that integrates RGB, thermal, and depth data
using a Mamba-based fusion mechanism. Our method captures complementary signals
across modalities, enabling enhanced detection of obscured or camouflaged
targets. Specifically, the proposed approach identifies modality-specific
features and fuses them in a unified representation that generalizes well
across challenging scenarios. We validate HiddenObject across multiple
benchmark datasets, demonstrating state-of-the-art or competitive performance
compared to existing methods. These results highlight the efficacy of our
fusion design and expose key limitations in current unimodal and na\"ive fusion
strategies. More broadly, our findings suggest that Mamba-based fusion
architectures can significantly advance the field of multimodal object
detection, especially under visually degraded or complex conditions.

</details>


### [11] [RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration](https://arxiv.org/abs/2508.21154)
*Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: RadGS-Reg是一个用于椎体级别CT/X射线配准的新框架，通过联合3D辐射高斯（RadGS）重建和3D/3D配准，解决了传统方法的局限性，并在体内数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的CT/X射线配准方法在空间信息丢失和域间隙方面存在问题，而现有的3D重建方法则受限于稠密视图要求和对噪声X射线的处理能力。

Method: 提出了一种名为RadGS-Reg的新框架，该框架结合了学习-RadGS重建方法（具有反事实注意力学习机制）和3D/3D配准，并通过患者特定的预训练策略进行优化。

Result: 实验结果表明，RadGS-Reg在CT/X射线配准和RadGS重建方面均取得了最先进的性能，优于现有方法。

Conclusion: RadGS-Reg框架能够有效解决CT/X射线配准的挑战，并通过联合RadGS重建和3D/3D配准实现了优于现有方法的性能。

Abstract: Computed Tomography (CT)/X-ray registration in image-guided navigation
remains challenging because of its stringent requirements for high accuracy and
real-time performance. Traditional "render and compare" methods, relying on
iterative projection and comparison, suffer from spatial information loss and
domain gap. 3D reconstruction from biplanar X-rays supplements spatial and
shape information for 2D/3D registration, but current methods are limited by
dense-view requirements and struggles with noisy X-rays. To address these
limitations, we introduce RadGS-Reg, a novel framework for vertebral-level
CT/X-ray registration through joint 3D Radiative Gaussians (RadGS)
reconstruction and 3D/3D registration. Specifically, our biplanar X-rays
vertebral RadGS reconstruction module explores learning-based RadGS
reconstruction method with a Counterfactual Attention Learning (CAL) mechanism,
focusing on vertebral regions in noisy X-rays. Additionally, a patient-specific
pre-training strategy progressively adapts the RadGS-Reg from simulated to real
data while simultaneously learning vertebral shape prior knowledge. Experiments
on in-house datasets demonstrate the state-of-the-art performance for both
tasks, surpassing existing methods. The code is available at:
https://github.com/shenao1995/RadGS_Reg.

</details>


### [12] [SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4](https://arxiv.org/abs/2508.21169)
*Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer*

Main category: cs.CV

TL;DR: SYNBUILD-3D是一个包含620万个合成3D住宅建筑的大型多模态数据集，旨在解决公开数据集缺乏的问题，以促进3D建筑模型的自动生成。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模的公开标注数据集，自动生成精确且富含语义的3D建筑模型仍然是一个重大挑战。

Method: 该研究引入了一个名为SYNBUILD-3D的数据集，包含超过620万个合成的3D住宅建筑，涵盖三个模态：LoD 4的语义丰富3D线框图、相应的平面图图像以及类似LiDAR的屋顶点云。每个建筑的线框图都带有从平面图图像中提取的房间、门窗等语义标注。

Result: SYNBUILD-3D数据集提供了三模态的3D建筑数据（线框图、平面图、点云），其中线框图具有详细的语义信息，可用于开发自动生成3D建筑模型的新算法。

Conclusion: SYNBUILD-3D数据集的出现，为未来利用生成式AI自动化创建LoD 4的3D建筑模型提供了基础，该模型能够根据预定义的平面图布局和屋顶几何形状，并保持语义与几何的一致性。

Abstract: 3D building models are critical for applications in architecture, energy
simulation, and navigation. Yet, generating accurate and semantically rich 3D
buildings automatically remains a major challenge due to the lack of
large-scale annotated datasets in the public domain. Inspired by the success of
synthetic data in computer vision, we introduce SYNBUILD-3D, a large, diverse,
and multi-modal dataset of over 6.2 million synthetic 3D residential buildings
at Level of Detail (LoD) 4. In the dataset, each building is represented
through three distinct modalities: a semantically enriched 3D wireframe graph
at LoD 4 (Modality I), the corresponding floor plan images (Modality II), and a
LiDAR-like roof point cloud (Modality III). The semantic annotations for each
building wireframe are derived from the corresponding floor plan images and
include information on rooms, doors, and windows. Through its tri-modal nature,
future work can use SYNBUILD-3D to develop novel generative AI algorithms that
automate the creation of 3D building models at LoD 4, subject to predefined
floor plan layouts and roof geometries, while enforcing semantic-geometric
consistency. Dataset and code samples are publicly available at
https://github.com/kdmayer/SYNBUILD-3D.

</details>


### [13] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 同时估计相机之间的放射畸变和单应性，并为三种不同的畸变配置提供了新的、统一的、更快速、更稳定的求解方法。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉任务中，准确估计图像间的单应性至关重要。然而，真实图像常受到镜头畸变（尤其是放射畸变）的影响，这会干扰单应性估计的准确性。因此，需要一种能够同时处理单应性和放射畸变的方法。

Method: 提出了一种新颖的、统一的方法来解决三种不同的放射畸变配置（仅一个图像有畸变、两个图像有相同畸变、两个图像有独立畸变）下的单应性估计问题。该方法能够构建新的、快速、稳定且准确的最小求解器。

Result: 在所有三种畸变情况下，新提出的求解器比现有的最先进求解器更快，同时保持了相似的准确性。在包含鱼眼相机图像的基准测试中也对求解器进行了测试。

Conclusion: 本文提出了一种统一的框架，用于同时估计具有放射畸变的单应性，并开发了更快速、更稳定的求解器，优于现有技术，并在各种数据集上得到了验证。

Abstract: Homographies are among the most prevalent transformations occurring in
geometric computer vision and projective geometry, and homography estimation is
consequently a crucial step in a wide assortment of computer vision tasks. When
working with real images, which are often afflicted with geometric distortions
caused by the camera lens, it may be necessary to determine both the homography
and the lens distortion-particularly the radial component, called radial
distortion-simultaneously to obtain anything resembling useful estimates. When
considering a homography with radial distortion between two images, there are
three conceptually distinct configurations for the radial distortion; (i)
distortion in only one image, (ii) identical distortion in the two images, and
(iii) independent distortion in the two images. While these cases have been
addressed separately in the past, the present paper provides a novel and
unified approach to solve all three cases. We demonstrate how the proposed
approach can be used to construct new fast, stable, and accurate minimal
solvers for radially distorted homographies. In all three cases, our proposed
solvers are faster than the existing state-of-the-art solvers while maintaining
similar accuracy. The solvers are tested on well-established benchmarks
including images taken with fisheye cameras. The source code for our solvers
will be made available in the event our paper is accepted for publication.

</details>


### [14] [GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability](https://arxiv.org/abs/2508.21197)
*Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang*

Main category: cs.CV

TL;DR: CAVs在解释深度神经网络方面很有用，但不同层之间存在不一致性。本文提出GCAV框架，利用对比学习和注意力机制统一CAVs，以实现跨层一致性。实验证明GCAV能提高TCAV分数的稳定性，增强概念定位，并提高对抗扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 不同的层独立计算CAVs时，CAVs常常表现出不一致性，这使得跨层比较不可靠。

Method: 提出全局概念激活向量（GCAV）框架，利用对比学习对齐跨层概念表示，并采用基于注意力的融合机制构建全局集成的CAV。提出TGCAV方法将TCAV应用于GCAV表示。

Result: GCAV显著降低了TCAV分数的方差，同时保持了概念相关性，确保了更稳定可靠的概念归因。GCAV有效缓解了跨层概念不一致性，增强了概念定位，并提高了对抗扰动的鲁棒性。

Conclusion: GCAV通过将跨层信息整合到连贯的框架中，为深度学习模型如何编码人类定义的概念提供了更全面、更可解释的理解。

Abstract: Concept Activation Vectors (CAVs) provide a powerful approach for
interpreting deep neural networks by quantifying their sensitivity to
human-defined concepts. However, when computed independently at different
layers, CAVs often exhibit inconsistencies, making cross-layer comparisons
unreliable. To address this issue, we propose the Global Concept Activation
Vector (GCAV), a novel framework that unifies CAVs into a single, semantically
consistent representation. Our method leverages contrastive learning to align
concept representations across layers and employs an attention-based fusion
mechanism to construct a globally integrated CAV. By doing so, our method
significantly reduces the variance in TCAV scores while preserving concept
relevance, ensuring more stable and reliable concept attributions. To evaluate
the effectiveness of GCAV, we introduce Testing with Global Concept Activation
Vectors (TGCAV) as a method to apply TCAV to GCAV-based representations. We
conduct extensive experiments on multiple deep neural networks, demonstrating
that our method effectively mitigates concept inconsistency across layers,
enhances concept localization, and improves robustness against adversarial
perturbations. By integrating cross-layer information into a coherent
framework, our method offers a more comprehensive and interpretable
understanding of how deep learning models encode human-defined concepts. Code
and models are available at https://github.com/Zhenghao-He/GCAV.

</details>


### [15] [Generalizable Object Re-Identification via Visual In-Context Prompting](https://arxiv.org/abs/2508.21222)
*Zhizhong Huang,Xiaoming Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Visual In-Context Prompting (VICP)的新框架，用于解决现有对象重识别（ReID）方法缺乏泛化性和需要昂贵标注数据的缺点。VICP能够让在已见类别上训练的模型直接泛化到未见类别，而无需参数调整，仅通过“上下文示例”作为提示。该框架结合了大型语言模型（LLMs）和视觉基础模型（VFMs），LLMs通过特定任务的提示学习语义身份规则，然后指导VFM提取区分身份的特征。通过将LLM的语义概念与VFM的预训练先验对齐，VICP实现了对新类别的泛化，无需针对特定数据集进行重新训练。为支持评估，论文还介绍了ShopID10K数据集。实验结果表明，VICP在未见类别上的表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的对象重识别（ReID）方法通常需要针对特定领域（如人物或车辆）训练模型，这导致泛化能力不足，并且需要为新类别收集昂贵的标注数据。虽然自监督学习可以减少标注需求，但它难以捕捉ReID所必需的“身份敏感”特征。

Method: VICP框架利用大型语言模型（LLMs）和视觉基础模型（VFMs）。LLMs通过少样本的正负样本对，利用任务特定的提示来推断语义身份规则。然后，这些规则指导VFM（如DINO）通过“动态视觉提示”提取区分身份的特征。通过将LLM推导出的语义概念与VFM的预训练先验对齐，VICP实现了对新类别的泛化，无需进行特定数据集的重新训练。

Result: 在ShopID10K数据集和多个ReID基准测试上的实验表明，VICP在未见类别上的性能明显优于基线方法。

Conclusion: VICP框架通过结合LLMs和VFMs，利用上下文示例实现了对象重识别的跨类别泛化，无需参数调整和特定数据集的重新训练，解决了现有方法的局限性。

Abstract: Current object re-identification (ReID) methods train domain-specific models
(e.g., for persons or vehicles), which lack generalization and demand costly
labeled data for new categories. While self-supervised learning reduces
annotation needs by learning instance-wise invariance, it struggles to capture
\textit{identity-sensitive} features critical for ReID. This paper proposes
Visual In-Context Prompting~(VICP), a novel framework where models trained on
seen categories can directly generalize to unseen novel categories using only
\textit{in-context examples} as prompts, without requiring parameter
adaptation. VICP synergizes LLMs and vision foundation models~(VFM): LLMs infer
semantic identity rules from few-shot positive/negative pairs through
task-specific prompting, which then guides a VFM (\eg, DINO) to extract
ID-discriminative features via \textit{dynamic visual prompts}. By aligning
LLM-derived semantic concepts with the VFM's pre-trained prior, VICP enables
generalization to novel categories, eliminating the need for dataset-specific
retraining. To support evaluation, we introduce ShopID10K, a dataset of 10K
object instances from e-commerce platforms, featuring multi-view images and
cross-domain testing. Experiments on ShopID10K and diverse ReID benchmarks
demonstrate that VICP outperforms baselines by a clear margin on unseen
categories. Code is available at https://github.com/Hzzone/VICP.

</details>


### [16] [Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg](https://arxiv.org/abs/2508.21227)
*Keshav Jha,William Sharp,Dominic LaBella*

Main category: cs.CV

TL;DR: SegResNet模型在胰腺癌MRI分割任务中表现出有限但有潜力的结果，尤其是在数据集较小和解剖变异性大的情况下。


<details>
  <summary>Details</summary>
Motivation: 自动分割胰腺癌对于诊断、治疗规划和预后评估至关重要，但由于解剖变异和数据集有限，自动分割仍具挑战性。

Method: 采用SegResNet模型（Auto3DSeg架构的一部分），在两个基于MRI的胰腺癌分割任务上进行训练和评估。具体方法包括5折交叉验证和STAPLE集成，并关注解剖学上相关的感兴趣区域。任务1使用91个T1加权动脉增强MRI数据，任务2使用50个T2加权MR-Linac数据，均包含专家标注的胰腺和肿瘤标签。

Result: 在任务1（诊断MRI）中，算法的DSC为0.56，5毫米DSC为0.73，HD95为41.1毫米，MASD为26.0毫米，RMSE为5164毫米。在任务2（MR-Linac）中，性能有所下降，DSC为0.33，5毫米DSC为0.50，HD95为20.1毫米，MASD为7.2毫米，RMSE为17,203毫米。

Conclusion: 研究结果说明了在小型数据集和不同MRI序列引入的变异性下，基于MRI的胰腺癌分割所面临的挑战。尽管性能适中，但结果显示了自动分割的潜力，并强调了需要更大、标准化的MRI数据集来提高模型的鲁棒性和临床应用价值。

Abstract: Accurate delineation of pancreatic tumors is critical for diagnosis,
treatment planning, and outcome assessment, yet automated segmentation remains
challenging due to anatomical variability and limited dataset availability. In
this study, SegResNet models, as part of the Auto3DSeg architecture, were
trained and evaluated on two MRI-based pancreatic tumor segmentation tasks as
part of the 2025 PANTHER Challenge. Algorithm methodology included 5-fold
cross-validation with STAPLE ensembling after focusing on an anatomically
relevant region-of-interest. The Pancreatic Tumor Segmentation on Diagnostic
MRI task 1 training set included 91 T1-weighted arterial contrast-enhanced MRI
with expert annotated pancreas and tumor labels. The Pancreatic Tumor
Segmentation on MR-Linac task 2 training set used 50 T2-weighted MR-Linac cases
with expert annotated pancreas and tumor labels. Algorithm-automated
segmentation performance of pancreatic tumor was assessed using Dice Similarity
Coefficient (DSC), 5 mm DSC, 95th percentile Hausdorff Distance (HD95), Mean
Average Surface Distance (MASD), and Root Mean Square Error (RMSE). For Task 1,
the algorithm achieved a DSC of 0.56, 5 mm DSC of 0.73, HD95 of 41.1 mm, MASD
of 26.0 mm, and RMSE of 5164 mm. For Task 2, performance decreased, with a DSC
of 0.33, 5 mm DSC of 0.50, HD95 of 20.1 mm, MASD of 7.2 mm, and RMSE of 17,203
mm. These findings illustrate the challenges of MRI-based pancreatic tumor
segmentation with small datasets, highlighting variability introduced by
different MRI sequences. Despite modest performance, the results demonstrate
potential for automated delineation and emphasize the need for larger,
standardized MRI datasets to improve model robustness and clinical utility.

</details>


### [17] [Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation](https://arxiv.org/abs/2508.21254)
*Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“反向成像”的新型物理驱动方法，用于增强心脏MRI数据的多样性并解决跨不同成像序列的泛化问题。该方法通过学习生成扩散模型来反向推断基础的自旋属性，从而实现高度准确的跨对比度和协议的心脏MRI分割。


<details>
  <summary>Details</summary>
Motivation: 心脏MRI分割模型在不同成像序列之间泛化能力较差，主要是由于图像对比度存在显著差异。本研究旨在解决这一泛化问题。

Method: 本研究提出了一种名为“反向成像”的物理驱动方法。该方法通过学习生成扩散模型，从多参数饱和恢复单次采集（mSASHA）序列数据中学习联合T1和T2图，以获得“自旋先验”。然后，通过求解正则化的非线性逆问题来反向推断自旋属性，并利用这些属性生成具有任意新颖对比度的数据，从而实现对各种新颖序列的灵活图像合成。

Result: 反向成像方法能够实现高度准确的跨对比度和成像协议的心脏MRI分割，实现了心脏MRI分割的广谱泛化。

Conclusion: 反向成像是一种有效的心脏MRI数据增强和域适应方法，能够解决跨不同成像序列的泛化问题，提高分割精度。

Abstract: Pretrained segmentation models for cardiac magnetic resonance imaging (MRI)
struggle to generalize across different imaging sequences due to significant
variations in image contrast. These variations arise from changes in imaging
protocols, yet the same fundamental spin properties, including proton density,
T1, and T2 values, govern all acquired images. With this core principle, we
introduce Reverse Imaging, a novel physics-driven method for cardiac MRI data
augmentation and domain adaptation to fundamentally solve the generalization
problem. Our method reversely infers the underlying spin properties from
observed cardiac MRI images, by solving ill-posed nonlinear inverse problems
regularized by the prior distribution of spin properties. We acquire this "spin
prior" by learning a generative diffusion model from the multiparametric
SAturation-recovery single-SHot acquisition sequence (mSASHA) dataset, which
offers joint cardiac T1 and T2 maps. Our method enables approximate but
meaningful spin-property estimates from MR images, which provide an
interpretable "latent variable" that lead to highly flexible image synthesis of
arbitrary novel sequences. We show that Reverse Imaging enables highly accurate
segmentation across vastly different image contrasts and imaging protocols,
realizing wide-spectrum generalization of cardiac MRI segmentation.

</details>


### [18] [Complete Gaussian Splats from a Single Image with Denoising Diffusion Models](https://arxiv.org/abs/2508.21542)
*Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman*

Main category: cs.CV

TL;DR: 提出一种基于潜在扩散模型的3D高斯散布方法，可从单张图像重建包含遮挡区域的完整3D场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有高斯散布方法通常需要密集观测且无法重建遮挡或未观测区域的问题，并克服传统方法在处理遮挡区域时的模糊、不合理和单模态预测等局限性。

Method: 提出一种生成式方法，利用潜在扩散模型学习3D高斯散布表示的分布，并引入变分自编码器（Variational AutoReconstructor）以在无监督情况下从2D图像学习潜在空间，进而训练扩散模型。

Result: 该方法能够生成忠实且多样化的3D高斯散布重建，并能补全遮挡区域，实现高质量的360度渲染。

Conclusion: 所提出的方法通过生成式方法和变分自编码器，成功实现了从单张图像重建包含遮挡区域的完整3D场景，克服了传统方法的不足，并能生成高质量的360度渲染。

Abstract: Gaussian splatting typically requires dense observations of the scene and can
fail to reconstruct occluded and unobserved areas. We propose a latent
diffusion model to reconstruct a complete 3D scene with Gaussian splats,
including the occluded parts, from only a single image during inference.
Completing the unobserved surfaces of a scene is challenging due to the
ambiguity of the plausible surfaces. Conventional methods use a
regression-based formulation to predict a single "mode" for occluded and
out-of-frustum surfaces, leading to blurriness, implausibility, and failure to
capture multiple possible explanations. Thus, they often address this problem
partially, focusing either on objects isolated from the background,
reconstructing only visible surfaces, or failing to extrapolate far from the
input views. In contrast, we propose a generative formulation to learn a
distribution of 3D representations of Gaussian splats conditioned on a single
input image. To address the lack of ground-truth training data, we propose a
Variational AutoReconstructor to learn a latent space only from 2D images in a
self-supervised manner, over which a diffusion model is trained. Our method
generates faithful reconstructions and diverse samples with the ability to
complete the occluded surfaces for high-quality 360-degree renderings.

</details>


### [19] [Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation](https://arxiv.org/abs/2508.21529)
*Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper*

Main category: cs.CV

TL;DR: 使用卷积神经网络上采样基于斑块的视觉基础模型特征，以提高显微图像分割的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于斑块的视觉基础模型特征在处理显微图像时存在不足，难以表示精细特征和大图像尺寸，影响分割效果。

Method: 训练一个卷积神经网络来上采样低分辨率的基础模型特征，并将其应用于显微图像分割，无需进一步训练。

Result: 上采样后的特征能够有效分割难以处理的区域（如细微裂缝），并显著提高了分割速度和降低了标签需求。

Conclusion: 所提出的上采样方法能够高效地利用基础模型特征进行显微图像分割，并在质量和效率上优于传统方法。

Abstract: Feature foundation models - usually vision transformers - offer rich semantic
descriptors of images, useful for downstream tasks such as (interactive)
segmentation and object detection. For computational efficiency these
descriptors are often patch-based, and so struggle to represent the fine
features often present in micrographs; they also struggle with the large image
sizes present in materials and biological image analysis. In this work, we
train a convolutional neural network to upsample low-resolution (i.e, large
patch size) foundation model features with reference to the input image. We
apply this upsampler network (without any further training) to efficiently
featurise and then segment a variety of microscopy images, including plant
cells, a lithium-ion battery cathode and organic crystals. The richness of
these upsampled features admits separation of hard to segment phases, like
hairline cracks. We demonstrate that interactive segmentation with these deep
features produces high-quality segmentations far faster and with far fewer
labels than training or finetuning a more traditional convolutional network.

</details>


### [20] [PHD: Personalized 3D Human Body Fitting with Point Diffusion](https://arxiv.org/abs/2508.21257)
*Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang*

Main category: cs.CV

TL;DR: PHD是一种新颖的个性化3D人体网格恢复（HMR）和身体拟合方法，利用用户特定的形状信息来提高视频中姿势估计的准确性。该方法首先校准用户的身体形状，然后采用以该形状为条件的个性化姿势拟合过程。它通过一个身体形状条件3D姿势先验（点扩散Transformer）来实现，该先验通过点蒸馏采样损失迭代地指导姿势拟合，从而减少了对2D约束的过度依赖。


<details>
  <summary>Details</summary>
Motivation: 传统的3D人体网格恢复（HMR）方法通常是用户不可知的，并且在姿势估计时过度依赖2D约束，这会损害3D准确性，因为它未能同时考虑特定个体的身体形状和3D姿势的可信度。PHD旨在解决这个问题，通过引入一种能够利用用户特定形状信息来提高姿势估计准确性的方法。

Method: PHD方法首先通过点扩散Transformer（PDT）校准用户的身体形状，然后采用以该形状为条件的个性化姿势拟合过程。这个过程通过点蒸馏采样（PDS）损失迭代地指导姿势拟合，从而形成一个学习到的3D姿势先验，以减少对2D约束的过度依赖。

Result: PHD方法不仅提高了骨盆对齐姿势的准确性，还提高了绝对姿势准确性。此外，该方法数据效率高，仅需合成数据即可进行训练，并且可以作为即插即用模块集成到现有的3D姿势估计器中以提高其性能。

Conclusion: PHD通过引入身体形状校准和个性化姿势拟合，有效解决了传统HMR方法在姿势估计准确性方面的问题，尤其是在处理用户特定的身体形状时。该方法通过学习3D姿势先验，减少了对2D约束的依赖，从而提高了包括绝对姿势准确性在内的各项指标，并且具有良好的数据效率和通用性。

Abstract: We introduce PHD, a novel approach for personalized 3D human mesh recovery
(HMR) and body fitting that leverages user-specific shape information to
improve pose estimation accuracy from videos. Traditional HMR methods are
designed to be user-agnostic and optimized for generalization. While these
methods often refine poses using constraints derived from the 2D image to
improve alignment, this process compromises 3D accuracy by failing to jointly
account for person-specific body shapes and the plausibility of 3D poses. In
contrast, our pipeline decouples this process by first calibrating the user's
body shape and then employing a personalized pose fitting process conditioned
on that shape. To achieve this, we develop a body shape-conditioned 3D pose
prior, implemented as a Point Diffusion Transformer, which iteratively guides
the pose fitting via a Point Distillation Sampling loss. This learned 3D pose
prior effectively mitigates errors arising from an over-reliance on 2D
constraints. Consequently, our approach improves not only pelvis-aligned pose
accuracy but also absolute pose accuracy -- an important metric often
overlooked by prior work. Furthermore, our method is highly data-efficient,
requiring only synthetic data for training, and serves as a versatile
plug-and-play module that can be seamlessly integrated with existing 3D pose
estimators to enhance their performance. Project page:
https://phd-pose.github.io/

</details>


### [21] [Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning](https://arxiv.org/abs/2508.21363)
*Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang*

Main category: cs.CV

TL;DR: 提出了一种高效的基于扩散的3D人体姿态估计框架，通过分层时间剪枝（HTP）策略，在帧和语义层面动态修剪冗余姿态标记，同时保留关键运动动力学，从而在保证性能的同时显著降低计算成本和提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的3D人体姿态估计方法虽然生成高质量姿态能力强，但其迭代性质和多假设要求导致了高昂的计算成本。

Method: 提出了一种分层时间剪枝（HTP）策略，包括：1）时域相关增强剪枝（TCEP），通过分析帧间运动相关性来识别关键帧；2）稀疏聚焦时域多头自注意力（SFT MHSA），利用帧级稀疏性减少注意力计算；3）掩码引导姿态标记剪枝器（MGPTP），通过聚类进行细粒度语义剪枝。

Result: HTP策略在Human3.6M和MPI-INF-3DHP数据集上进行了实验，结果显示：训练MACs降低了38.5%，推理MACs降低了56.8%，推理速度平均提高了81.1%，同时达到了最先进的性能。

Conclusion: 所提出的HTP策略能够显著减少基于扩散模型3D人体姿态估计的计算成本并提高推理速度，同时保持或优于现有方法，展现了其在效率和性能上的优势。

Abstract: Diffusion models have demonstrated strong capabilities in generating
high-fidelity 3D human poses, yet their iterative nature and multi-hypothesis
requirements incur substantial computational cost. In this paper, we propose an
Efficient Diffusion-Based 3D Human Pose Estimation framework with a
Hierarchical Temporal Pruning (HTP) strategy, which dynamically prunes
redundant pose tokens across both frame and semantic levels while preserving
critical motion dynamics. HTP operates in a staged, top-down manner: (1)
Temporal Correlation-Enhanced Pruning (TCEP) identifies essential frames by
analyzing inter-frame motion correlations through adaptive temporal graph
construction; (2) Sparse-Focused Temporal MHSA (SFT MHSA) leverages the
resulting frame-level sparsity to reduce attention computation, focusing on
motion-relevant tokens; and (3) Mask-Guided Pose Token Pruner (MGPTP) performs
fine-grained semantic pruning via clustering, retaining only the most
informative pose tokens. Experiments on Human3.6M and MPI-INF-3DHP show that
HTP reduces training MACs by 38.5\%, inference MACs by 56.8\%, and improves
inference speed by an average of 81.1\% compared to prior diffusion-based
methods, while achieving state-of-the-art performance.

</details>


### [22] [Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image](https://arxiv.org/abs/2508.21371)
*Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang*

Main category: cs.CV

TL;DR: Print2Volume是一个生成合成3D指纹OCT数据的框架，解决了大规模数据集稀缺的问题，通过预训练模型显著提高了识别性能。


<details>
  <summary>Details</summary>
Motivation: 由于高昂的成本和耗时的采集过程，公开的OCT指纹数据集规模小，阻碍了深度学习等算法的发展。

Method: Print2Volume框架包括三个阶段：(1) 2D风格迁移将二值指纹转化为灰度图；(2) 3D结构扩展网络将2D图像外推为3D体积；(3) 基于3D GAN的OCT真实感细化器为结构体积添加真实纹理和噪声。

Result: 生成了包含420,000个样本的大规模合成数据集，并证明了其在高识别性能方面的有效性，将EER从15.62%降低到2.50%。

Conclusion: Print2Volume框架能够生成高质量的合成OCT指纹数据，有效解决了数据稀缺问题，并通过预训练显著提高了指纹识别的准确率。

Abstract: Optical Coherence Tomography (OCT) enables the acquisition of
high-resolution, three-dimensional fingerprint data, capturing rich subsurface
structures for robust biometric recognition. However, the high cost and
time-consuming nature of OCT data acquisition have led to a scarcity of
large-scale public datasets, significantly hindering the development of
advanced algorithms, particularly data-hungry deep learning models. To address
this critical bottleneck, this paper introduces Print2Volume, a novel framework
for generating realistic, synthetic OCT-based 3D fingerprints from 2D
fingerprint image. Our framework operates in three sequential stages: (1) a 2D
style transfer module that converts a binary fingerprint into a grayscale
images mimicking the style of a Z-direction mean-projected OCT scan; (2) a 3D
Structure Expansion Network that extrapolates the 2D im-age into a plausible 3D
anatomical volume; and (3) an OCT Realism Refiner, based on a 3D GAN, that
renders the structural volume with authentic textures, speckle noise, and other
imaging characteristics. Using Print2Volume, we generated a large-scale
synthetic dataset of 420,000 samples. Quantitative experiments demonstrate the
high quality of our synthetic data and its significant impact on recognition
performance. By pre-training a recognition model on our synthetic data and
fine-tuning it on a small real-world dataset, we achieved a remarkable
reduction in the Equal Error Rate (EER) from 15.62% to 2.50% on the ZJUT-EIFD
benchmark, proving the effectiveness of our approach in overcoming data
scarcity.

</details>


### [23] [GLENDA: Gynecologic Laparoscopy Endometriosis Dataset](https://arxiv.org/abs/2508.21398)
*Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein*

Main category: cs.CV

TL;DR: The paper introduces the Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA), the first dataset of its kind with region-based annotations for endometriosis, to facilitate the development of computer vision and machine learning approaches for analyzing surgical recordings.


<details>
  <summary>Details</summary>
Motivation: Manual analysis of gynecologic laparoscopy recordings is time-consuming. Developing automated computer vision and machine learning approaches can improve this process, but these methods require substantial data, which is scarce in the medical field.

Method: The paper presents the Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA), which contains region-based annotations of endometriosis. The dataset was created in collaboration with medical experts.

Result: The GLENDA dataset is the first dataset of its kind for gynecologic laparoscopy with region-based annotations for endometriosis.

Conclusion: The introduction of the GLENDA dataset aims to support research in computer vision and machine learning for gynecologic laparoscopy, ultimately improving the analysis of surgical recordings.

Abstract: Gynecologic laparoscopy as a type of minimally invasive surgery (MIS) is
performed via a live feed of a patient's abdomen surveying the insertion and
handling of various instruments for conducting treatment. Adopting this kind of
surgical intervention not only facilitates a great variety of treatments, the
possibility of recording said video streams is as well essential for numerous
post-surgical activities, such as treatment planning, case documentation and
education. Nonetheless, the process of manually analyzing surgical recordings,
as it is carried out in current practice, usually proves tediously
time-consuming. In order to improve upon this situation, more sophisticated
computer vision as well as machine learning approaches are actively developed.
Since most of such approaches heavily rely on sample data, which especially in
the medical field is only sparsely available, with this work we publish the
Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA) - an image dataset
containing region-based annotations of a common medical condition named
endometriosis, i.e. the dislocation of uterine-like tissue. The dataset is the
first of its kind and it has been created in collaboration with leading medical
experts in the field.

</details>


### [24] [Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation](https://arxiv.org/abs/2508.21399)
*Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein*

Main category: cs.CV

TL;DR: 该研究提出了一种基于区域的全卷积网络，用于分割和识别腹腔镜妇科手术视频中的手术器械，实现了高精度的器械分割，但器械识别仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术录像包含大量细节，但缺乏有效的自动内容索引和检索方法，因此需要研究手术器械的分割和识别技术，以实现基于内容的搜索。

Method: 使用基于区域的全卷积网络（FCN）进行实例分割（区分器械与背景）和多类别器械识别（识别器械类型）。

Result: 研究结果表明，即使在训练样本数量不多的情况下，该方法也能高精度地定位和分割器械区域。然而，由于手术器械本身的高度相似性，识别具体器械类型仍然非常困难。

Conclusion: 该研究成功实现了手术器械的高精度分割，为视频内容检索奠定了基础，但器械的精确识别仍需进一步研究。

Abstract: Recorded videos from surgeries have become an increasingly important
information source for the field of medical endoscopy, since the recorded
footage shows every single detail of the surgery. However, while video
recording is straightforward these days, automatic content indexing - the basis
for content-based search in a medical video archive - is still a great
challenge due to the very special video content. In this work, we investigate
segmentation and recognition of surgical instruments in videos recorded from
laparoscopic gynecology. More precisely, we evaluate the achievable performance
of segmenting surgical instruments from their background by using a
region-based fully convolutional network for instance-aware (1) instrument
segmentation as well as (2) instrument recognition. While the first part
addresses only binary segmentation of instances (i.e., distinguishing between
instrument or background) we also investigate multi-class instrument
recognition (i.e., identifying the type of instrument). Our evaluation results
show that even with a moderately low number of training examples, we are able
to localize and segment instrument regions with a pretty high accuracy.
However, the results also reveal that determining the particular instrument is
still very challenging, due to the inherently high similarity of surgical
instruments.

</details>


### [25] [SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing](https://arxiv.org/abs/2508.21402)
*Jakub Straka,Ivan Gruber*

Main category: cs.CV

TL;DR: SatDINO是一个为卫星图像设计的对比自监督模型，在多个基准测试中表现优于MAE等现有方法，并提出 GSD 编码和自适应视图采样等改进。


<details>
  <summary>Details</summary>
Motivation: 未标记的遥感数据量大，利用自监督学习进行预训练。

Method: 使用DINO进行预训练，并提出SatDINO模型，引入GSD编码和自适应视图采样。

Result: SatDINO在多个数据集和测试设置中，优于MAE等现有方法，并取得有竞争力的结果。

Conclusion: SatDINO是一个有效的遥感自监督学习模型，提出的改进可以独立使用。

Abstract: Self-supervised learning has emerged as a powerful tool for remote sensing,
where large amounts of unlabeled data are available. In this work, we
investigate the use of DINO, a contrastive self-supervised method, for
pretraining on remote sensing imagery. We introduce SatDINO, a model tailored
for representation learning in satellite imagery. Through extensive experiments
on multiple datasets in multiple testing setups, we demonstrate that SatDINO
outperforms other state-of-the-art methods based on much more common masked
autoencoders (MAE) and achieves competitive results in multiple benchmarks.
  We also provide a rigorous ablation study evaluating SatDINO's individual
components. Finally, we propose a few novel enhancements, such as a new way to
incorporate ground sample distance (GSD) encoding and adaptive view sampling.
These enhancements can be used independently on our SatDINO model. Our code and
trained models are available at: https://github.com/strakaj/SatDINO.

</details>


### [26] [Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives](https://arxiv.org/abs/2508.21418)
*Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub*

Main category: cs.CV

TL;DR: 该论文提出了一种为全切片成像（WSI）生成二维索引图和特定应用领域分析机制的通用框架，以解决目前WSI缺乏标准化元数据的问题，该框架通过三层（来源、组织类型、病理改变）的组织图来提供细粒度的WSI内容信息，并在临床病理学领域进行了演示，旨在实现不同数据库间的互操作性。


<details>
  <summary>Details</summary>
Motivation: 目前全切片成像（WSI）在人工智能算法开发中的应用日益广泛，但缺乏标准化的元数据来描述WSI的内容，导致在构建训练或验证数据集时，主要依赖于耗时且不适用于大规模数据集的手动检查。

Method: 提出了一种通用框架，用于生成WSI的二维索引图和特定应用领域的分析机制。该框架通过构建包含来源、组织类型和病理改变三个层级的组织图来提供WSI内容的细粒度信息，并实现了不同数据库间的互操作性。

Result: 通过在临床病理学领域的应用演示，证明了该框架能够为WSI集合提供详细的组织图，从而实现对WSI内容的细粒度描述。该方法在WSI目录、机器学习和基于图的WSI表示等方面展示了其优势和适用性。

Conclusion: 所提出的通用框架通过提供详细的组织图（包含来源、组织类型和病理改变三个层级）解决了WSI元数据标准化的问题，提高了数据处理的效率和互操作性，在临床病理学等领域具有广泛的应用前景。

Abstract: A Whole Slide Image (WSI) is a high-resolution digital image created by
scanning an entire glass slide containing a biological specimen, such as tissue
sections or cell samples, at multiple magnifications. These images can be
viewed, analyzed, shared digitally, and are used today for Artificial
Intelligence (AI) algorithm development. WSIs are used in a variety of fields,
including pathology for diagnosing diseases and oncology for cancer research.
They are also utilized in neurology, veterinary medicine, hematology,
microbiology, dermatology, pharmacology, toxicology, immunology, and forensic
science.
  When assembling cohorts for the training or validation of an AI algorithm, it
is essential to know what is present on such a WSI. However, there is currently
no standard for this metadata, so such selection has mainly been done through
manual inspection, which is not suitable for large collections with several
million objects.
  We propose a general framework to generate a 2D index map for WSI and a
profiling mechanism for specific application domains. We demonstrate this
approach in the field of clinical pathology, using common syntax and semantics
to achieve interoperability between different catalogs.
  Our approach augments each WSI collection with a detailed tissue map that
provides fine-grained information about the WSI content. The tissue map is
organized into three layers: source, tissue type, and pathological alterations,
with each layer assigning segments of the WSI to specific classes.
  We illustrate the advantages and applicability of the proposed standard
through specific examples in WSI catalogs, Machine Learning (ML), and
graph-based WSI representations.

</details>


### [27] [Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels](https://arxiv.org/abs/2508.21424)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 提出了一种名为ICPL的无监督增量学习方法，使用置信度伪标签来处理现实世界中出现但训练期间未见过的新类别，实现了在无标签数据集上的增量学习。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景中经常出现新类别，需要模型能够增量学习新知识，但现有的类别增量学习（CIL）方法假设数据集是完全标记的，这在实践中不现实。

Method: 提出ICPL方法，使用置信度伪标签替代人工标注，并将其集成到各种CIL方法中，通过置信度进行选择。

Result: ICPL在CIFAR100和ImageNet100数据集上进行了评估，与有监督方法相比取得了有竞争力的结果，并且在最终准确率上比最先进的类iNCD方法提高了5%以上。该方法还展示了在细粒度数据集上的实用性，并验证了其在资源受限环境中的计算复杂性。

Conclusion: ICPL是一种有效的无监督增量学习方法，能够处理现实世界中无标签数据的增量学习问题，并在性能上优于现有方法。

Abstract: Deep learning models have achieved state-of-the-art performance in many
computer vision tasks. However, in real-world scenarios, novel classes that
were unseen during training often emerge, requiring models to acquire new
knowledge incrementally. Class-Incremental Learning (CIL) methods enable a
model to learn novel classes while retaining knowledge of previous classes.
However, these methods make the strong assumption that the incremental dataset
is fully labeled, which is unrealistic in practice. In this work, we propose an
unsupervised Incremental Learning method using Confidence-based Pseudo-labels
(ICPL), which replaces human annotations with pseudo-labels, enabling
incremental learning from unlabeled datasets. We integrate these pseudo-labels
into various CIL methods with confidence-based selection and evaluate
performance degradation on CIFAR100 and ImageNet100. Then, we compare our
approach to popular Class Incremental Novel Category Discovery (class-iNCD)
methods addressing similar challenges. Additionally, we apply our method to
fine-grained datasets to demonstrate its real-world practicality and measure
its computational complexity to validate its suitability for
resource-constrained environments. ICPL achieves competitive results compared
to supervised methods and outperforms state-of-the-art class-iNCD methods by
more than 5% in final accuracy.

</details>


### [28] [MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation](https://arxiv.org/abs/2508.21435)
*Francisco Caetano,Christiaan Viviers,Peter H. H. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MedShift的生成模型，利用Flow Matching和Schrodinger Bridges技术，实现了合成X射线图像与真实X射线图像之间的跨域转换，以解决合成数据在临床应用中的泛化能力问题。研究引入了X-DigiSkull数据集用于模型评测，并证明MedShift在保持较小模型规模的同时，能够灵活地在感知保真度和结构一致性之间进行权衡，为医学影像的域适应提供了可扩展且通用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 合成医疗数据在模型训练中具有潜力，但其与真实数据的域差异限制了其临床应用。本文旨在解决合成头部X射线图像与真实X射线图像之间的跨域转换挑战，缩小在衰减行为、噪声特性和软组织表示方面的差距。

Method: 提出了一种名为MedShift的统一的、类别条件生成模型，该模型基于Flow Matching和Schrodinger Bridges，实现了跨多个域的高保真、非配对图像转换。MedShift学习了一个共享的、与域无关的潜在空间，支持训练期间见过的任何域对之间的无缝转换。

Result: 实验结果表明，MedShift在性能上表现出色，并且在推理时保持灵活性，能够根据需要优先考虑感知保真度或结构一致性。与基于扩散的方法相比，MedShift的模型规模更小。

Conclusion: MedShift是一种可扩展且通用的解决方案，能够灵活地在感知保真度和结构一致性之间进行权衡，解决了医学影像域适应的挑战。

Abstract: Synthetic medical data offers a scalable solution for training robust models,
but significant domain gaps limit its generalizability to real-world clinical
settings. This paper addresses the challenge of cross-domain translation
between synthetic and real X-ray images of the head, focusing on bridging
discrepancies in attenuation behavior, noise characteristics, and soft tissue
representation. We propose MedShift, a unified class-conditional generative
model based on Flow Matching and Schrodinger Bridges, which enables
high-fidelity, unpaired image translation across multiple domains. Unlike prior
approaches that require domain-specific training or rely on paired data,
MedShift learns a shared domain-agnostic latent space and supports seamless
translation between any pair of domains seen during training. We introduce
X-DigiSkull, a new dataset comprising aligned synthetic and real skull X-rays
under varying radiation doses, to benchmark domain translation models.
Experimental results demonstrate that, despite its smaller model size compared
to diffusion-based approaches, MedShift offers strong performance and remains
flexible at inference time, as it can be tuned to prioritize either perceptual
fidelity or structural consistency, making it a scalable and generalizable
solution for domain adaptation in medical imaging. The code and dataset are
available at https://caetas.github.io/medshift.html

</details>


### [29] [Trees as Gaussians: Large-Scale Individual Tree Mapping](https://arxiv.org/abs/2508.21437)
*Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt*

Main category: cs.CV

TL;DR: 该研究提出了一种利用深度学习和高分辨率卫星影像在全球范围内检测单棵大树的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的全球树木监测方法在个体树木识别方面存在不足，主要关注树木覆盖或树冠高度，而非个体树木。本研究旨在解决这一问题，提供一种大规模、高分辨率的单棵树木检测方法。

Method: 本研究采用深度学习方法，利用3米分辨率的PlanetScope卫星影像，通过模拟高斯核的树冠来提取树木中心点，并生成二值化的树木覆盖图。模型训练数据来源于激光雷达数据提取的数十亿个点，使其能够识别森林内外以及不同生物群落的树木。

Result: 研究结果显示，该方法在树冠覆盖率方面取得了先进的性能（与航空激光雷达数据的R²=0.81）。同时，在不同生物群落中检测指标也表现均衡。研究还表明，通过手动标注进行微调可以进一步提高检测精度。

Conclusion: 本研究提出的方法为全球高分辨率树木监测提供了一个可扩展的框架，能够适应未来更高分辨率的卫星任务，并在个体树木检测方面取得了显著进展。

Abstract: Trees are key components of the terrestrial biosphere, playing vital roles in
ecosystem function, climate regulation, and the bioeconomy. However,
large-scale monitoring of individual trees remains limited by inadequate
modelling. Available global products have focused on binary tree cover or
canopy height, which do not explicitely identify trees at individual level. In
this study, we present a deep learning approach for detecting large individual
trees in 3-m resolution PlanetScope imagery at a global scale. We simulate tree
crowns with Gaussian kernels of scalable size, allowing the extraction of crown
centers and the generation of binary tree cover maps. Training is based on
billions of points automatically extracted from airborne lidar data, enabling
the model to successfully identify trees both inside and outside forests. We
compare against existing tree cover maps and airborne lidar with
state-of-the-art performance (fractional cover R$^2 = 0.81$ against aerial
lidar), report balanced detection metrics across biomes, and demonstrate how
detection can be further improved through fine-tuning with manual labels. Our
method offers a scalable framework for global, high-resolution tree monitoring,
and is adaptable to future satellite missions offering improved imagery.

</details>


### [30] [Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content](https://arxiv.org/abs/2508.21444)
*Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: 3DGS 难以处理动态场景，本文提出了一种名为 M 的可扩展高斯泼溅框架，通过分层组织高斯球、混合变形和生成策略以及双向自适应掩蔽机制，实现了高效的流式训练，并在视觉质量和训练时间上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3DGS在动态场景扩展方面存在数据量大和训练时间长的问题，本研究旨在解决这些限制，为流式任务提供高效的训练框架。

Method: 提出了一种名为 M 的可扩展高斯泼溅框架，其核心包括：1. 分层组织高斯球（粗粒度表示结构，细粒度表示细节）；2. 混合变形和生成策略（通过高斯变形处理帧间运动，通过高斯生成处理大范围运动）；3. 双向自适应掩蔽机制（去除静态区域，优先处理信息丰富的视点）。

Result: 在广泛的实验中，M 框架在视觉质量上表现优越，同时显著减少了训练时间，相比于现有最先进的方法。

Conclusion: M 框架通过创新的技术有效地解决了 3DGS 在动态场景处理中的效率问题，实现了高质量的实时渲染和快速训练。

Abstract: 3D Gaussian Splatting (3DGS) enables high-fidelity real-time rendering, a key
requirement for immersive applications. However, the extension of 3DGS to
dynamic scenes remains limitations on the substantial data volume of dense
Gaussians and the prolonged training time required for each frame. This paper
presents \M, a scalable Gaussian Splatting framework designed for efficient
training in streaming tasks. Specifically, Gaussian spheres are hierarchically
organized by scale within an anchor-based structure. Coarser-level Gaussians
represent the low-resolution structure of the scene, while finer-level
Gaussians, responsible for detailed high-fidelity rendering, are selectively
activated by the coarser-level Gaussians. To further reduce computational
overhead, we introduce a hybrid deformation and spawning strategy that models
motion of inter-frame through Gaussian deformation and triggers Gaussian
spawning to characterize wide-range motion. Additionally, a bidirectional
adaptive masking mechanism enhances training efficiency by removing static
regions and prioritizing informative viewpoints. Extensive experiments
demonstrate that \M~ achieves superior visual quality while significantly
reducing training time compared to state-of-the-art methods.

</details>


### [31] [One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist](https://arxiv.org/abs/2508.21451)
*Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo*

Main category: cs.CV

TL;DR: This paper introduces a lightweight image captioning model that achieves performance comparable to larger models and proposes a novel framework, Sharp-Eyed Refinement, to address visual blindness issues.


<details>
  <summary>Details</summary>
Motivation: Deploying image captioning models on local devices is challenging due to the high computational demands of multimodal large language models (MLLMs).

Method: The paper explores lightweight captioning using a 125M-parameter language model and introduces a novel framework, Sharp-Eyed Refinement, featuring DeepLens for enhanced visual grounding.

Result: The lightweight model achieves performance comparable to large generalist models. The Sharp-Eyed Refinement framework improves caption quality and effectively addresses visual blindness.

Conclusion: A lightweight image captioning model can be effective, and the proposed Sharp-Eyed Refinement framework with DeepLens enhances visual grounding and caption quality, making it suitable for on-device applications.

Abstract: Image captioning is fundamental for applications like video instruction
systems and exploration robots, yet deploying such models on local devices is
challenging due to the high computational demands of multimodal large language
models (MLLMs). To address this, we first explore lightweight captioning by
implementing a specialist based on a 125M-parameter language model, 56 times
smaller than LLaMA-7B, and evaluating its performance on both single-sentence
and detailed captioning tasks. Surprisingly, we find that our model can achieve
performance comparable to large multimodal generalists, suggesting its
potential to serve as a strong visual specialist for on-device applications.
While promising, our model also exhibits a limitation: like other MLLMs, it
suffers from visual blindness, occasionally resulting in semantic captioning
errors. We carry out toy experiments and investigate the underlying causes,
where we observe that the problems arise from ineffective attention mechanisms
and limited visual representations. To alleviate them, we develop a novel
captioning framework, Sharp-Eyed Refinement, which enhances caption quality
through improved visual grounding. At its core, our DeepLens extracts detailed
visual representations by concentrating on informative regions identified
during the initial glance. Our experiments confirm both the advantages of our
specialist over prior small captioning models and large generalists and the
effectiveness of our framework.

</details>


### [32] [Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification](https://arxiv.org/abs/2508.21458)
*Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron*

Main category: cs.CV

TL;DR: 该研究评估了在联邦学习（FL）框架中调整基础模型（FM）用于阿尔茨海默病诊断的效果，重点关注分类头结构、微调策略和聚合方法。研究发现在多队列脑部MRI数据集上，分类头结构对性能有显著影响，冻结FM编码器与完全微调效果相当，且高级聚合方法优于标准的联邦平均法。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型（FM）在联邦学习（FL）系统中用于阿尔茨海默病诊断的集成效果，并系统性地研究关键设计选择（分类头架构、微调策略、聚合方法）对联邦FM调优的性能和效率的影响。

Method: 使用脑部MRI数据，在一大规模多队列数据集上，系统性地评估了不同分类头架构、微调策略（冻结FM编码器 vs. 完全微调）和聚合方法（标准联邦平均 vs. 高级聚合方法）对联邦FM调优的性能和效率的影响。

Result: 研究发现，分类头架构对性能有显著影响；冻结FM编码器与完全微调相比，效果相当；高级聚合方法优于标准的联邦平均法。

Conclusion: 分类头架构的选择对联邦FM调优的性能至关重要。冻结FM编码器的策略可以达到与完全微调相当的性能，同时可能提高效率。高级聚合方法在联邦学习环境中比标准的联邦平均法表现更好。这些发现为在分布式临床环境中部署FM提供了实用的指导，并指出了未来方法开发应考虑的权衡。

Abstract: While foundation models (FMs) offer strong potential for AI-based dementia
diagnosis, their integration into federated learning (FL) systems remains
underexplored. In this benchmarking study, we systematically evaluate the
impact of key design choices: classification head architecture, fine-tuning
strategy, and aggregation method, on the performance and efficiency of
federated FM tuning using brain MRI data. Using a large multi-cohort dataset,
we find that the architecture of the classification head substantially
influences performance, freezing the FM encoder achieves comparable results to
full fine-tuning, and advanced aggregation methods outperform standard
federated averaging. Our results offer practical insights for deploying FMs in
decentralized clinical settings and highlight trade-offs that should guide
future method development.

</details>


### [33] [Multi-Method Ensemble for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21463)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 本研究提出了一种名为多方法集成（MME）的 OOD 检测新方法，通过结合特征截断和多种评分函数来提高检测性能，并在大规模和小型基准测试中取得了显著优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的 OOD 检测方法通常只关注单一技术或特定类型的数据集，忽视了结合多种方法的潜力。本研究旨在探索并证明结合多种 OOD 检测技术（如特征截断和评分函数）的有效性，并提出一种能够整合这些方法的集成模型。

Method: 本研究将状态最先进的特征截断技术和评分函数相结合，并通过聚合多个评分函数来增强对不同类型 OOD 样本的鲁棒性。在此基础上，提出了一种名为多方法集成（MME）的评分函数，将多种 OOD 检测器统一起来。

Result: 通过在各种基准测试（包括大规模和小型数据集，以及近 OOD 和远 OOD 场景）上进行的大量实验，证明 MME 在所有基准测试中都显著优于最近最先进的方法。具体来说，在使用 BiT 模型时，MME 在 ImageNet-1K 基准测试上达到了 27.57% 的平均 FPR95，比现有的最佳基线提高了 6%。

Conclusion: 本研究成功地结合了特征截断和多种评分函数，并提出了一种名为 MME 的集成 OOD 检测方法，该方法在各种 OOD 检测任务和数据集上均表现出优越的性能，显著超越了现有的最先进水平。

Abstract: Detecting out-of-distribution (OOD) samples is essential for neural networks
operating in open-world settings, particularly in safety-critical applications.
Existing methods have improved OOD detection by leveraging two main techniques:
feature truncation, which increases the separation between in-distribution (ID)
and OOD samples, and scoring functions, which assign scores to distinguish
between ID and OOD data. However, most approaches either focus on a single
family of techniques or evaluate their effectiveness on a specific type of OOD
dataset, overlooking the potential of combining multiple existing solutions.
Motivated by this observation, we theoretically and empirically demonstrate
that state-of-the-art feature truncation and scoring functions can be
effectively combined. Moreover, we show that aggregating multiple scoring
functions enhances robustness against various types of OOD samples. Based on
these insights, we propose the Multi-Method Ensemble (MME) score, which unifies
state-of-the-art OOD detectors into a single, more effective scoring function.
Extensive experiments on both large-scale and small-scale benchmarks, covering
near-OOD and far-OOD scenarios, show that MME significantly outperforms recent
state-of-the-art methods across all benchmarks. Notably, using the BiT model,
our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K
benchmark, improving performance by 6% over the best existing baseline.

</details>


### [34] [Adversarial Patch Attack for Ship Detection via Localized Augmentation](https://arxiv.org/abs/2508.21472)
*Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 针对基于深度神经网络的船舶检测易受对抗性补丁攻击的问题，提出一种仅对目标区域进行增强的局部增强方法，以提高攻击成功率和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的船舶检测方法容易受到对抗性补丁的攻击，导致误分类或目标规避。现有数据增强方法可能引入不必要的背景干扰，导致错误检测。

Method: 提出一种局部增强方法，仅将数据增强应用于目标区域，避免对非目标区域的影响，使损失函数更关注对抗性补丁对检测模型的影响。

Result: 实验结果表明，该方法能有效提高对抗性补丁攻击的成功率和可迁移性。

Conclusion: 局部增强方法可以克服背景干扰，有效提升对抗性补丁攻击的效果。

Abstract: Current ship detection techniques based on remote sensing imagery primarily
rely on the object detection capabilities of deep neural networks (DNNs).
However, DNNs are vulnerable to adversarial patch attacks, which can lead to
misclassification by the detection model or complete evasion of the targets.
Numerous studies have demonstrated that data transformation-based methods can
improve the transferability of adversarial examples. However, excessive
augmentation of image backgrounds or irrelevant regions may introduce
unnecessary interference, resulting in false detections of the object detection
model. These errors are not caused by the adversarial patches themselves but
rather by the over-augmentation of background and non-target areas. This paper
proposes a localized augmentation method that applies augmentation only to the
target regions, avoiding any influence on non-target areas. By reducing
background interference, this approach enables the loss function to focus more
directly on the impact of the adversarial patch on the detection model, thereby
improving the attack success rate. Experiments conducted on the HRSC2016
dataset demonstrate that the proposed method effectively increases the success
rate of adversarial patch attacks and enhances their transferability.

</details>


### [35] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 该论文提出了ELV-Halluc基准，用于解决视频多模态大语言模型（Video-MLLMs）在长视频理解中出现的“语义聚合幻觉”（SAH）问题。研究发现SAH会随着语义复杂度的增加而加剧，尤其在语义快速变化的场景下更为明显。通过引入位置编码策略和DPO（Direct Preference Optimization）策略，可以有效缓解SAH问题，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 视频多模态大语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但仍然容易产生与视频内容不符或无关的幻觉内容。现有的视频幻觉基准主要关注短视频，并将幻觉归因于语言先验、缺失帧或视觉编码器引入的视觉-语言偏差。然而，这些原因并不能完全解释所有幻觉，特别是当模型生成不正确输出但具有正确的帧级语义时。论文旨在解决长视频中的“语义聚合幻觉”（SAH）问题，即模型在将帧级语义聚合成事件级语义组的过程中产生的幻觉。

Method: 为了解决长视频中的语义聚合幻觉（SAH）问题，论文提出了ELV-Halluc，这是首个专注于长视频幻觉问题的基准。通过实验验证了SAH的存在，并分析了其与语义复杂度及语义变化速度的关系。此外，研究探讨了缓解SAH的潜在方法，并提出了结合位置编码策略和DPO策略的解决方案。研究者构建了一个包含8K对抗性数据对的数据集，并在ELV-Halluc和Video-MME基准上进行了评估。

Result: 实验证实了SAH的存在，并发现SAH随着语义复杂度的增加而增加，在语义快速变化的视频中更为明显。通过采用位置编码策略和DPO策略，模型区分事件内和事件间语义的能力得到增强，从而有效缓解了SAH问题。在ELV-Halluc和Video-MME基准上的实验结果显示，SAH比例降低了27.7%，表明该方法在提升长视频理解的准确性方面取得了显著成效。

Conclusion: 论文成功引入了ELV-Halluc基准，系统地研究了长视频中的语义聚合幻觉（SAH）问题。研究结果表明，SAH是影响长视频理解准确性的重要因素，并提出了有效的缓解策略。通过结合位置编码和DPO策略，模型在处理语义复杂和快速变化的视频内容时，其幻觉生成能力得到了显著改善。

Abstract: Video multimodal large language models (Video-MLLMs) have achieved remarkable
progress in video understanding. However, they remain vulnerable to
hallucination-producing content inconsistent with or unrelated to video inputs.
Previous video hallucination benchmarks primarily focus on short-videos. They
attribute hallucinations to factors such as strong language priors, missing
frames, or vision-language biases introduced by the visual encoder. While these
causes indeed account for most hallucinations in short videos, they still
oversimplify the cause of hallucinations. Sometimes, models generate incorrect
outputs but with correct frame-level semantics. We refer to this type of
hallucination as Semantic Aggregation Hallucination (SAH), which arises during
the process of aggregating frame-level semantics into event-level semantic
groups. Given that SAH becomes particularly critical in long videos due to
increased semantic complexity across multiple events, it is essential to
separate and thoroughly investigate the causes of this type of hallucination.
To address the above issues, we introduce ELV-Halluc, the first benchmark
dedicated to long-video hallucination, enabling a systematic investigation of
SAH. Our experiments confirm the existence of SAH and show that it increases
with semantic complexity. Additionally, we find that models are more prone to
SAH on rapidly changing semantics. Moreover, we discuss potential approaches to
mitigate SAH. We demonstrate that positional encoding strategy contributes to
alleviating SAH, and further adopt DPO strategy to enhance the model's ability
to distinguish semantics within and across events. To support this, we curate a
dataset of 8K adversarial data pairs and achieve improvements on both
ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

</details>


### [36] [HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones](https://arxiv.org/abs/2508.21539)
*Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li*

Main category: cs.CV

TL;DR: HCCM框架通过区域-全局对比学习和匹配来提升无人机视觉-语言理解能力，解决了现有模型在细粒度语义和动态环境适应性上的不足，并在GeoText-1652和ERA数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在处理无人机场景的广阔视野和复杂语义时存在困难，主要体现在全局对齐而牺牲细粒度语义，以及现有分层方法对实体划分的严格要求限制了其在动态环境中的有效性。

Method: 提出了一种名为HCCM（Hierarchical Cross-Granularity Contrastive and Matching）的框架，包含两个主要组件：1. 区域-全局图像-文本对比学习（RG-ITC），通过对比局部图像区域与全局文本以及反之，来捕捉局部到全局的语义，避免了精确的场景分割。2. 区域-全局图像-文本匹配（RG-ITM），通过评估全局跨模态表示内的局部语义一致性来增强组合推理能力，摒弃了严格的约束。此外，引入了动量对比和蒸馏（MCD）机制来提高模型对不完整或模糊文本描述的鲁棒性。

Result: 在GeoText-1652数据集上，HCCM在图像检索方面达到了28.8%的Recall@1，在文本检索方面达到了14.7%的Recall@1。在未见过的数据集ERA上，HCCM展示了强大的零样本泛化能力，平均召回率（mR）为39.93%，优于经过微调的基线模型。

Conclusion: HCCM框架能够有效提升无人机视觉-语言任务的性能，尤其在处理细粒度语义、动态环境和不完整文本描述方面表现出色，并在多个数据集上取得了最先进的成果。

Abstract: Natural Language-Guided Drones (NLGD) provide a novel paradigm for tasks such
as target matching and navigation. However, the wide field of view and complex
compositional semantics in drone scenarios pose challenges for vision-language
understanding. Mainstream Vision-Language Models (VLMs) emphasize global
alignment while lacking fine-grained semantics, and existing hierarchical
methods depend on precise entity partitioning and strict containment, limiting
effectiveness in dynamic environments. To address this, we propose the
Hierarchical Cross-Granularity Contrastive and Matching learning (HCCM)
framework with two components: (1) Region-Global Image-Text Contrastive
Learning (RG-ITC), which avoids precise scene partitioning and captures
hierarchical local-to-global semantics by contrasting local visual regions with
global text and vice versa; (2) Region-Global Image-Text Matching (RG-ITM),
which dispenses with rigid constraints and instead evaluates local semantic
consistency within global cross-modal representations, enhancing compositional
reasoning. Moreover, drone text descriptions are often incomplete or ambiguous,
destabilizing alignment. HCCM introduces a Momentum Contrast and Distillation
(MCD) mechanism to improve robustness. Experiments on GeoText-1652 show HCCM
achieves state-of-the-art Recall@1 of 28.8% (image retrieval) and 14.7% (text
retrieval). On the unseen ERA dataset, HCCM demonstrates strong zero-shot
generalization with 39.93% mean recall (mR), outperforming fine-tuned
baselines.

</details>


### [37] [Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR](https://arxiv.org/abs/2508.21693)
*Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora*

Main category: cs.CV

TL;DR: 提出了一种线级OCR技术，通过直接识别整行文本来克服单词分割的瓶颈，提高了准确性和效率，并提供了一个包含251张英文页面图像及线级标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的OCR技术在字符分割时容易出错，且无法利用语言模型提供的上下文信息。虽然基于序列到序列的模型改进了单词识别，但将瓶颈转移到了单词分割。因此，需要一种新的方法来进一步提高OCR的准确性和效率。

Method: 提出了一种线级OCR（Line-Level OCR）技术，直接识别整行文本，以克服单词分割的错误，并利用更大的句子上下文来更好地应用语言模型。

Result: 实验结果显示，所提出的线级OCR技术在端到端准确率方面提高了5.4%，并将效率提高了4倍。此外，还提供了一个包含251张英文页面图像及线级标注的数据集。

Conclusion: 线级OCR技术相比单词级OCR能够显著提高准确性和效率，特别是在处理文档图像时。该方法还有潜力利用未来大型语言模型的进步。

Abstract: Conventional optical character recognition (OCR) techniques segmented each
character and then recognized. This made them prone to error in character
segmentation, and devoid of context to exploit language models. Advances in
sequence to sequence translation in last decade led to modern techniques first
detecting words and then inputting one word at a time to a model to directly
output full words as sequence of characters. This allowed better utilization of
language models and bypass error-prone character segmentation step. We observe
that the above transition in style has moved the bottleneck in accuracy to word
segmentation. Hence, in this paper, we propose a natural and logical
progression from word level OCR to line-level OCR. The proposal allows to
bypass errors in word detection, and provides larger sentence context for
better utilization of language models. We show that the proposed technique not
only improves the accuracy but also efficiency of OCR. Despite our thorough
literature survey, we did not find any public dataset to train and benchmark
such shift from word to line-level OCR. Hence, we also contribute a
meticulously curated dataset of 251 English page images with line-level
annotations. Our experimentation revealed a notable end-to-end accuracy
improvement of 5.4%, underscoring the potential benefits of transitioning
towards line-level OCR, especially for document images. We also report a 4
times improvement in efficiency compared to word-based pipelines. With
continuous improvements in large language models, our methodology also holds
potential to exploit such advances. Project Website:
https://nishitanand.github.io/line-level-ocr-website

</details>


### [38] [EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting](https://arxiv.org/abs/2508.21550)
*Yujin Park,Haejun Chung,Ikbeom Jang*

Main category: cs.CV

TL;DR: EZ-Sort通过结合CLIP预训练模型和不确定性引导的采样，提高了排序任务的标注效率，显著减少了人工成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决排序任务中，详尽的成对比较需要大量标注（O(n^2)）的问题，并在此基础上进一步提高标注效率。

Method: EZ-Sort首先利用CLIP模型进行分层预排序（零样本），然后初始化桶感知Elo分数，最后运行不确定性引导的人工在环的MergeSort。

Result: EZ-Sort相比详尽的成对比较，减少了90.5%的人工标注成本；相比之前的研究，减少了19.8%的标注成本（在n=100时），同时提高了或保持了评估者间信度。

Conclusion: 将CLIP的先验知识与不确定性感知的采样相结合，为成对排序提供了一个高效且可扩展的解决方案。

Abstract: Pairwise comparison is often favored over absolute rating or ordinal
classification in subjective or difficult annotation tasks due to its improved
reliability. However, exhaustive comparisons require a massive number of
annotations (O(n^2)). Recent work has greatly reduced the annotation burden
(O(n log n)) by actively sampling pairwise comparisons using a sorting
algorithm. We further improve annotation efficiency by (1) roughly pre-ordering
items using the Contrastive Language-Image Pre-training (CLIP) model
hierarchically without training, and (2) replacing easy, obvious human
comparisons with automated comparisons. The proposed EZ-Sort first produces a
CLIP-based zero-shot pre-ordering, then initializes bucket-aware Elo scores,
and finally runs an uncertainty-guided human-in-the-loop MergeSort. Validation
was conducted using various datasets: face-age estimation (FGNET), historical
image chronology (DHCI), and retinal image quality assessment (EyePACS). It
showed that EZ-Sort reduced human annotation cost by 90.5% compared to
exhaustive pairwise comparisons and by 19.8% compared to prior work (when n =
100), while improving or maintaining inter-rater reliability. These results
demonstrate that combining CLIP-based priors with uncertainty-aware sampling
yields an efficient and scalable solution for pairwise ranking.

</details>


### [39] [ECHO: Ego-Centric modeling of Human-Object interactions](https://arxiv.org/abs/2508.21556)
*Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: ECHO是一个统一框架，用于从头部和手腕跟踪中恢复人类姿势、物体运动和接触，采用了Diffusion Transformer架构和三变量扩散过程。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴设备的普及，从第一人称视角模拟人类-物体交互（HOI）变得越来越重要，但尚未得到充分研究。本研究旨在探索仅从头部和手腕跟踪中可以恢复多少交互信息。

Method: ECHO（Ego-Centric modeling of Human-Object interactions）提出了一种统一框架，采用Diffusion Transformer架构和三变量扩散过程，联合模拟人类运动、物体轨迹和接触序列，以从头部和手腕跟踪中恢复人类姿势、物体运动和接触。该方法在以头部为中心的规范空间中运行，并通过基于传送带的推理来处理任意长度的序列。

Result: ECHO在第一人称HOI重建方面设定了新的最先进水平，并且优于现有方法，同时提供了更高的灵活性。

Conclusion: ECHO成功地从有限的观察中（仅头部和手腕跟踪）重建了第一人称HOI，证明了从头部和手腕跟踪中恢复交互信息的可行性，并为该领域设定了新的标准。

Abstract: Modeling human-object interactions (HOI) from an egocentric perspective is a
largely unexplored yet important problem due to the increasing adoption of
wearable devices, such as smart glasses and watches. We investigate how much
information about interaction can be recovered from only head and wrists
tracking. Our answer is ECHO (Ego-Centric modeling of Human-Object
interactions), which, for the first time, proposes a unified framework to
recover three modalities: human pose, object motion, and contact from such
minimal observation. ECHO employs a Diffusion Transformer architecture and a
unique three-variate diffusion process, which jointly models human motion,
object trajectory, and contact sequence, allowing for flexible input
configurations. Our method operates in a head-centric canonical space,
enhancing robustness to global orientation. We propose a conveyor-based
inference, which progressively increases the diffusion timestamp with the frame
position, allowing us to process sequences of any length. Through extensive
evaluation, we demonstrate that ECHO outperforms existing methods that do not
offer the same flexibility, setting a state-of-the-art in egocentric HOI
reconstruction.

</details>


### [40] [How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images](https://arxiv.org/abs/2508.21565)
*Juneyoung Ro,Namwoo Kim,Yoonjin Yoon*

Main category: cs.CV

TL;DR: 该研究评估了三种视觉-语言模型（VLMs）在城市场景理解方面的零样本和微调性能。研究表明，使用针对城市场景的合成链式思考（CoT）数据集进行微调，可以显著提高模型性能，特别是在处理否定和反事实等复杂问题时。


<details>
  <summary>Details</summary>
Motivation: 评估现有视觉-语言模型（VLMs）在城市领域进行细粒度空间推理的能力，并探究使用特定于城市场景的合成数据集进行微调的效果。

Method: 对BLIP-2、InstructBLIP和LLaVA-1.5这三种现成的VLMs进行了评估。构建了一个包含城市场景特定问题的合成视觉问答（VQA）数据集，并使用了链式思考（CoT）进行监督。评估了模型的零样本性能以及微调后的性能。

Result: 与零样本设置相比，使用合成CoT数据集进行微调显著提高了VLMs的性能，尤其是在处理否定和反事实等复杂问题类型时。

Conclusion: 城市空间推理是VLMs的一个新挑战。使用合成数据集进行微调是使通用模型适应特定领域的实用方法。

Abstract: Effectively understanding urban scenes requires fine-grained spatial
reasoning about objects, layouts, and depth cues. However, how well current
vision-language models (VLMs), pretrained on general scenes, transfer these
abilities to urban domain remains underexplored. To address this gap, we
conduct a comparative study of three off-the-shelf VLMs-BLIP-2, InstructBLIP,
and LLaVA-1.5-evaluating both zero-shot performance and the effects of
fine-tuning with a synthetic VQA dataset specific to urban scenes. We construct
such dataset from segmentation, depth, and object detection predictions of
street-view images, pairing each question with LLM-generated Chain-of-Thought
(CoT) answers for step-by-step reasoning supervision. Results show that while
VLMs perform reasonably well in zero-shot settings, fine-tuning with our
synthetic CoT-supervised dataset substantially boosts performance, especially
for challenging question types such as negation and counterfactuals. This study
introduces urban spatial reasoning as a new challenge for VLMs and demonstrates
synthetic dataset construction as a practical path for adapting general-purpose
models to specialized domains.

</details>


### [41] [Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging](https://arxiv.org/abs/2508.21580)
*Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: TFM是一种新的生成模型，用于医学影像的时间动力学分析，可以作为最近邻图像预测器的替代，并且能够处理3D数据、多个先验扫描和不规则采样。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理医学影像的时间动力学时存在局限性，通常只考虑单一时间上下文，或专注于分类/回归任务，限制了其在精细空间预测方面的能力。现有的一些方法仅限于单个时间点、特定疾病或存在其他技术限制。

Method: TFM是一种统一的生成轨迹方法，旨在学习潜在的时间分布，并能作为最近邻图像预测器（预测最后一个上下文图像）的特例，同时支持3D体积、多个先验扫描和不规则采样。

Result: 在三个公开的纵向数据集上的广泛基准测试表明，TFM在表现上持续优于自然影像的空间-时间方法，建立了4D医学影像预测的新状态和稳健基线。

Conclusion: TFM是一种新颖且通用的方法，在4D医学影像预测方面取得了优异的性能，克服了现有方法的局限性，并为该领域提供了一个强大的新基线。

Abstract: Understanding temporal dynamics in medical imaging is crucial for
applications such as disease progression modeling, treatment planning and
anatomical development tracking. However, most deep learning methods either
consider only single temporal contexts, or focus on tasks like classification
or regression, limiting their ability for fine-grained spatial predictions.
While some approaches have been explored, they are often limited to single
timepoints, specific diseases or have other technical restrictions. To address
this fundamental gap, we introduce Temporal Flow Matching (TFM), a unified
generative trajectory method that (i) aims to learn the underlying temporal
distribution, (ii) by design can fall back to a nearest image predictor, i.e.
predicting the last context image (LCI), as a special case, and (iii) supports
$3D$ volumes, multiple prior scans, and irregular sampling. Extensive
benchmarks on three public longitudinal datasets show that TFM consistently
surpasses spatio-temporal methods from natural imaging, establishing a new
state-of-the-art and robust baseline for $4D$ medical image prediction.

</details>


### [42] [Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer](https://arxiv.org/abs/2508.21581)
*Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado*

Main category: cs.CV

TL;DR: 本研究评估了整合术前CT和术后病理全切片图像（WSIs）的多模态复发预测方法，并使用深度学习框架和Cox生存模型进行验证，结果显示病理图像（WSI）模型优于CT模型，而中级融合进一步提高了预测性能，为ccRCC的个性化风险预测提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 为了提高对透明细胞肾细胞癌（ccRCC）患者术后复发风险的估计，以指导监测和治疗，本研究旨在评估一种新的多模态复发预测方法，该方法整合了术前CT和术后病理全切片图像（WSIs），以克服现有Leibovich评分的局限性。

Method: 本研究采用模块化深度学习框架，结合预训练编码器和基于Cox的生存模型，在单模态、晚期融合和中期融合等不同设置下进行测试，以评估整合CT和WSIs进行ccRCC复发风险预测的性能。

Result: 在ccRCC队列研究中，基于WSI的模型在预测复发风险方面持续优于仅基于CT的模型，病理信息显示出更强的预后预测能力。中期融合进一步提升了模型性能，其中表现最佳的模型（TITAN-CONCH with ResNet-18）的性能接近调整后的Leibovich评分。简单的嵌入连接显示，放射学信息主要通过融合增加了其价值。

Conclusion: 本研究证明了基于基础模型的多模态整合在个性化ccRCC风险预测中的可行性。未来的研究应探索更具表现力的融合策略、更大规模的多模态数据集以及通用CT编码器，以更好地匹配病理建模能力。

Abstract: Recurrence risk estimation in clear cell renal cell carcinoma (ccRCC) is
essential for guiding postoperative surveillance and treatment. The Leibovich
score remains widely used for stratifying distant recurrence risk but offers
limited patient-level resolution and excludes imaging information. This study
evaluates multimodal recurrence prediction by integrating preoperative computed
tomography (CT) and postoperative histopathology whole-slide images (WSIs). A
modular deep learning framework with pretrained encoders and Cox-based survival
modeling was tested across unimodal, late fusion, and intermediate fusion
setups. In a real-world ccRCC cohort, WSI-based models consistently
outperformed CT-only models, underscoring the prognostic strength of pathology.
Intermediate fusion further improved performance, with the best model
(TITAN-CONCH with ResNet-18) approaching the adjusted Leibovich score. Random
tie-breaking narrowed the gap between the clinical baseline and learned models,
suggesting discretization may overstate individualized performance. Using
simple embedding concatenation, radiology added value primarily through fusion.
These findings demonstrate the feasibility of foundation model-based multimodal
integration for personalized ccRCC risk prediction. Future work should explore
more expressive fusion strategies, larger multimodal datasets, and
general-purpose CT encoders to better match pathology modeling capacity.

</details>


### [43] [Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation](https://arxiv.org/abs/2508.21657)
*Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan*

Main category: cs.CV

TL;DR: 基于深度展开的卷积神经网络（CNN）和角向频谱法（ASM）的局限性，提出了一种深度展开网络（DUN），包含自适应带宽保持模型（ABPM）和相位域复值去噪器（PCD），在更宽的工作距离下实现了超过35 dB的PSNR，并在模拟和真实数据上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习在计算机生成全息图（CGH）领域中存在的准确性、稳定性、可解释性、灵活性以及对长程依赖和全局上下文捕获能力不足的问题，特别是现有方法忽略物理关系、CNN感受野有限以及ASM模型局限于近场的问题。

Method: 提出了一种深度展开网络（DUN），该网络将梯度下降分解为两个模块：自适应带宽保持模型（ABPM）和相位域复值去噪器（PCD）。ABPM支持比ASM更宽的工作距离，PCD利用其复值可变形自注意力机制来捕获全局特征并提高性能。

Result: 在模拟和真实数据上实现了超过35 dB的PSNR，并取得了最先进的结果。

Conclusion: 所提出的深度展开网络（DUN）通过ABPM和PCD模块的结合，有效解决了现有CGH算法的局限性，在保持物理关系的同时，实现了更优的性能和更广泛的适用性。

Abstract: Computer-generated holography (CGH) has gained wide attention with deep
learning-based algorithms. However, due to its nonlinear and ill-posed nature,
challenges remain in achieving accurate and stable reconstruction.
Specifically, ($i$) the widely used end-to-end networks treat the
reconstruction model as a black box, ignoring underlying physical
relationships, which reduces interpretability and flexibility. ($ii$) CNN-based
CGH algorithms have limited receptive fields, hindering their ability to
capture long-range dependencies and global context. ($iii$) Angular spectrum
method (ASM)-based models are constrained to finite near-fields.In this paper,
we propose a Deep Unfolding Network (DUN) that decomposes gradient descent into
two modules: an adaptive bandwidth-preserving model (ABPM) and a phase-domain
complex-valued denoiser (PCD), providing more flexibility. ABPM allows for
wider working distances compared to ASM-based methods. At the same time, PCD
leverages its complex-valued deformable self-attention module to capture global
features and enhance performance, achieving a PSNR over 35 dB. Experiments on
simulated and real data show state-of-the-art results.

</details>


### [44] [Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models](https://arxiv.org/abs/2508.21680)
*Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 本研究提出了一个用于全身PET/CT影像中肿瘤分割的交互式分割方法，通过将用户点击作为输入，并使用EDT编码空间提示，在autoPET/CT IV挑战赛任务1中取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的全自动分割方法在处理PET/CT影像中的异质性、生理摄取和多中心变异性时仍存在挑战，临床实践需要能够让人类参与以优化分割结果的方法。

Method: 本研究在autoPET III的nnU-Net框架基础上，通过编码用户提供的前景和背景点击作为额外输入通道，实现了可提示分割。研究了空间提示的表示方法，发现EDT编码优于高斯核。此外，还提出了用户交互的在线模拟和自定义点采样策略以提高鲁棒性。

Result: 研究结果显示，结合EDT编码和模拟用户交互的模型集成在交叉验证中表现最佳，显著减少了假阳性和假阴性。本方法在autoPET/CT IV挑战赛任务1中，相比基线模型取得了更优的分割性能。

Conclusion: 可提示模型有潜力实现高效的用户引导式分割工作流程，特别是在多示踪剂、多中心PET/CT影像分析中。

Abstract: Whole-body PET/CT is a cornerstone of oncological imaging, yet accurate
lesion segmentation remains challenging due to tracer heterogeneity,
physiological uptake, and multi-center variability. While fully automated
methods have advanced substantially, clinical practice benefits from approaches
that keep humans in the loop to efficiently refine predicted masks. The
autoPET/CT IV challenge addresses this need by introducing interactive
segmentation tasks based on simulated user prompts. In this work, we present
our submission to Task 1. Building on the winning autoPET III nnU-Net pipeline,
we extend the framework with promptable capabilities by encoding user-provided
foreground and background clicks as additional input channels. We
systematically investigate representations for spatial prompts and demonstrate
that Euclidean Distance Transform (EDT) encodings consistently outperform
Gaussian kernels. Furthermore, we propose online simulation of user
interactions and a custom point sampling strategy to improve robustness under
realistic prompting conditions. Our ensemble of EDT-based models, trained with
and without external data, achieves the strongest cross-validation performance,
reducing both false positives and false negatives compared to baseline models.
These results highlight the potential of promptable models to enable efficient,
user-guided segmentation workflows in multi-tracer, multi-center PET/CT. Code
is publicly available at https://github.com/MIC-DKFZ/autoPET-interactive

</details>


### [45] [Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping](https://arxiv.org/abs/2508.21689)
*Fatih Erdoğan,Merve Rabia Barın,Fatma Güney*

Main category: cs.CV

TL;DR: 现有HD地图方法将投影外包给基于注意力的技术，但存在泛化问题和幻觉。我们提出一种基于相机参数的几何映射，并通过概率投影机制和置信分数进行场景自适应，以提高精度和过滤无关元素。此外，我们还通过选择性地累积信息来改进时间处理。实验证明，我们的方法在nuScenes和Argoverse2数据集上优于现有技术，尤其是在nuScenes和长距离感知方面。


<details>
  <summary>Details</summary>
Motivation: 现有HD地图方法在将图像空间中的道路元素精确映射到BEV空间时存在泛化问题和幻觉，影响最终HD地图的质量。本研究旨在改进这一映射过程。

Method: 提出一种新颖的概率投影机制，结合置信分数，基于相机参数进行几何映射，并针对场景进行自适应，以（i）提高映射精度和（ii）过滤无关元素。同时，改进时间处理，利用置信分数选择性地累积可靠信息。

Result: 在nuScenes和Argoverse2数据集的新划分上进行了实验，结果表明该方法在nuScenes和长感知距离方面比现有技术有显著改进，显示出更好的泛化能力。

Conclusion: 所提出的基于几何映射和概率投影的自适应方法能够更精确地提取HD地图信息，克服现有方法的泛化问题，并在各种场景下提供更好的性能。

Abstract: Constructing high-definition (HD) maps from sensory input requires accurately
mapping the road elements in image space to the Bird's Eye View (BEV) space.
The precision of this mapping directly impacts the quality of the final
vectorized HD map. Existing HD mapping approaches outsource the projection to
standard mapping techniques, such as attention-based ones. However, these
methods struggle with accuracy due to generalization problems, often
hallucinating non-existent road elements. Our key idea is to start with a
geometric mapping based on camera parameters and adapt it to the scene to
extract relevant map information from camera images. To implement this, we
propose a novel probabilistic projection mechanism with confidence scores to
(i) refine the mapping to better align with the scene and (ii) filter out
irrelevant elements that should not influence HD map generation. In addition,
we improve temporal processing by using confidence scores to selectively
accumulate reliable information over time. Experiments on new splits of the
nuScenes and Argoverse2 datasets demonstrate improved performance over
state-of-the-art approaches, indicating better generalization. The improvements
are particularly pronounced on nuScenes and in the challenging long perception
range. Our code and model checkpoints are available at
https://github.com/Fatih-Erdogan/mapping-like-skeptic .

</details>


### [46] [FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA](https://arxiv.org/abs/2508.21712)
*Alvaro Patricio,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: FLORA是一个轻量级合成数据生成管线，使用Flux 1.1 Dev扩散模型和低秩适配（LoRA）技术，可以在消费级GPU上生成高质量合成数据，显著提高目标检测性能，同时降低计算成本和数据量需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的合成数据增强方法通常需要昂贵的计算资源（如企业级GPU）和大量数据，限制了其在实际应用中的普及。本研究旨在解决这一问题，提出一种更高效、更易于访问的合成数据生成方法。

Method: 本研究提出了一种名为FLORA（Flux LoRA Augmentation）的轻量级合成数据生成管线。该方法使用Flux 1.1 Dev扩散模型，并仅通过低秩适配（LoRA）技术进行微调，从而大幅降低了计算需求，使其能够利用消费级GPU（如NVIDIA RTX 4090）生成合成数据。研究在七个不同的目标检测数据集上进行了实证评估。

Result: 研究结果表明，使用FLORA生成的500张合成图像训练的目标检测模型，其性能优于使用ODGEN基线生成的5000张合成图像训练的模型，在mAP@.50:.95方面提升高达21.3%。这表明FLORA在数据质量和效率上均优于现有方法。

Conclusion: FLORA通过一种注重质量和效率的方法，实现了比现有“蛮力”生成方法更好的目标检测性能，且仅使用了10%的数据量和一小部分计算成本。这使得先进的合成数据创建在实际应用场景中更加实用和易于获取。

Abstract: Recent advances in diffusion-based generative models have demonstrated
significant potential in augmenting scarce datasets for object detection tasks.
Nevertheless, most recent models rely on resource-intensive full fine-tuning of
large-scale diffusion models, requiring enterprise-grade GPUs (e.g., NVIDIA
V100) and thousands of synthetic images. To address these limitations, we
propose Flux LoRA Augmentation (FLORA), a lightweight synthetic data generation
pipeline. Our approach uses the Flux 1.1 Dev diffusion model, fine-tuned
exclusively through Low-Rank Adaptation (LoRA). This dramatically reduces
computational requirements, enabling synthetic dataset generation with a
consumer-grade GPU (e.g., NVIDIA RTX 4090). We empirically evaluate our
approach on seven diverse object detection datasets. Our results demonstrate
that training object detectors with just 500 synthetic images generated by our
approach yields superior detection performance compared to models trained on
5000 synthetic images from the ODGEN baseline, achieving improvements of up to
21.3% in mAP@.50:.95. This work demonstrates that it is possible to surpass
state-of-the-art performance with far greater efficiency, as FLORA achieves
superior results using only 10% of the data and a fraction of the computational
cost. This work demonstrates that a quality and efficiency-focused approach is
more effective than brute-force generation, making advanced synthetic data
creation more practical and accessible for real-world scenarios.

</details>


### [47] [Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks](https://arxiv.org/abs/2508.21715)
*Amirhossein Nazeri,Wael Hafez*

Main category: cs.CV

TL;DR: 卷积神经网络（CNN）在计算机视觉领域表现出色，但在处理对抗性扰动时仍然脆弱。本研究提出一种无需修改模型即可检测对抗性样本的新方法，通过监测CNN激活的熵来识别。实验表明，该方法在VGG-16模型上能以90%的准确率检测对抗性输入，且对干净输入的性能无影响。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法存在训练成本高、修改网络结构或降低干净输入性能等缺点。本研究旨在提出一种无需修改模型即可检测对抗性样本的方法。

Method: 通过监测卷积神经网络（CNN）激活的熵来检测对抗性扰动。在VGG-16模型上进行了实验。

Result: 在VGG-16模型上，对抗性输入使早期卷积层的激活熵移动了7%，实现了90%的检测准确率，误报和漏报率均低于20%。

Conclusion: CNN的可靠性可以通过激活熵来评估，并且可以利用这种方法实现能够实时检测对抗性输入的自诊断视觉系统，而不会影响原始模型的性能。

Abstract: Convolutional Neural Networks (CNNs) have become the foundation of modern
computer vision, achieving unprecedented accuracy across diverse image
recognition tasks. While these networks excel on in-distribution data, they
remain vulnerable to adversarial perturbations imperceptible input
modifications that cause misclassification with high confidence. However,
existing detection methods either require expensive retraining, modify network
architecture, or degrade performance on clean inputs. Here we show that
adversarial perturbations create immediate, detectable entropy signatures in
CNN activations that can be monitored without any model modification. Using
parallel entropy monitoring on VGG-16, we demonstrate that adversarial inputs
consistently shift activation entropy by 7% in early convolutional layers,
enabling 90% detection accuracy with false positives and false negative rates
below 20%. The complete separation between clean and adversarial entropy
distributions reveals that CNNs inherently encode distribution shifts in their
activation patterns. This work establishes that CNN reliability can be assessed
through activation entropy alone, enabling practical deployment of
self-diagnostic vision systems that detect adversarial inputs in real-time
without compromising original model performance.

</details>


### [48] [CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models](https://arxiv.org/abs/2508.21732)
*João Valente,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: 该论文介绍了CAD2DMD-SET，一个用于生成数字测量设备（DMD）视觉问答（VQA）合成数据集的工具，旨在提高大型视觉语言模型（LVLM）在现实世界中的性能，特别是在存在遮挡、模糊等挑战性条件下。同时，还提出了DMDBench真实世界数据集用于评估模型。实验结果表明，使用CAD2DMD-SET进行微调能显著提升LVLM在DMD读取任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在处理数字测量设备（DMD）的数值读取任务时，尤其是在现实世界复杂场景（如杂乱、遮挡、极端视角、运动模糊）下，表现不佳。

Method: 1. 提出CAD2DMD-SET：一个利用3D CAD模型、高级渲染和高保真图像组合来生成用于DMD视觉问答任务的合成数据集的工具。
2. 提出DMDBench：一个包含1000张标注真实世界图像的评估数据集，用于在实际约束条件下评估模型性能。
3. 实验评估：使用平均归一化Levenshtein相似度（ANLS）对三种最先进的LVLM进行了基准测试，并使用CAD2DMD-SET生成的数据集对这些模型的LoRA进行了微调。

Result: 使用CAD2DMD-SET微调后，InternVL模型的ANLS分数提升了200%，且在其他任务上性能无明显下降。这表明CAD2DMD-SET显著提高了LVLM在挑战性条件下的鲁棒性和性能。

Conclusion: CAD2DMD-SET合成数据集能够有效提升LVLM在读取数字测量设备数值时的鲁棒性和性能，尤其是在处理现实世界中的复杂场景时。该工具计划开源，以供社区进一步使用和扩展。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
impressive capabilities across various multimodal tasks. They continue,
however, to struggle with trivial scenarios such as reading values from Digital
Measurement Devices (DMDs), particularly in real-world conditions involving
clutter, occlusions, extreme viewpoints, and motion blur; common in
head-mounted cameras and Augmented Reality (AR) applications. Motivated by
these limitations, this work introduces CAD2DMD-SET, a synthetic data
generation tool designed to support visual question answering (VQA) tasks
involving DMDs. By leveraging 3D CAD models, advanced rendering, and
high-fidelity image composition, our tool produces diverse, VQA-labelled
synthetic DMD datasets suitable for fine-tuning LVLMs. Additionally, we present
DMDBench, a curated validation set of 1,000 annotated real-world images
designed to evaluate model performance under practical constraints.
Benchmarking three state-of-the-art LVLMs using Average Normalised Levenshtein
Similarity (ANLS) and further fine-tuning LoRA's of these models with
CAD2DMD-SET's generated dataset yielded substantial improvements, with InternVL
showcasing a score increase of 200% without degrading on other tasks. This
demonstrates that the CAD2DMD-SET training dataset substantially improves the
robustness and performance of LVLMs when operating under the previously stated
challenging conditions. The CAD2DMD-SET tool is expected to be released as
open-source once the final version of this manuscript is prepared, allowing the
community to add different measurement devices and generate their own datasets.

</details>


### [49] [Learning from Silence and Noise for Visual Sound Source Localization](https://arxiv.org/abs/2508.21761)
*Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro*

Main category: cs.CV

TL;DR: SSL-SaN是一个自监督模型，通过包含静音和噪声的训练策略，在有无声或噪声的场景下都能实现最先进的声音定位和跨模态检索性能。新提出的度量标准能够量化音频和视觉特征的对齐和可分离性，同时还发布了包含负音频的IS3+数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视觉声源定位方法在处理负音频（如静音、噪声、屏幕外声音）时表现不佳，并且评估方法局限于只有单一可见声源的场景。

Method: 提出了一种包含静音和噪声的训练策略，开发了一种新的度量标准来量化音频和视觉特征的对齐与可分离性，并发布了一个包含负音频的IS3+数据集。

Result: SSL-SaN模型在声音定位和跨模态检索方面取得了最先进的性能，优于其他自监督模型。

Conclusion: SSL-SaN模型通过其创新的训练策略和对负音频的处理能力，显著提高了视觉声源定位的鲁棒性和性能。

Abstract: Visual sound source localization is a fundamental perception task that aims
to detect the location of sounding sources in a video given its audio. Despite
recent progress, we identify two shortcomings in current methods: 1) most
approaches perform poorly in cases with low audio-visual semantic
correspondence such as silence, noise, and offscreen sounds, i.e. in the
presence of negative audio; and 2) most prior evaluations are limited to
positive cases, where both datasets and metrics convey scenarios with a single
visible sound source in the scene. To address this, we introduce three key
contributions. First, we propose a new training strategy that incorporates
silence and noise, which improves performance in positive cases, while being
more robust against negative sounds. Our resulting self-supervised model,
SSL-SaN, achieves state-of-the-art performance compared to other
self-supervised models, both in sound localization and cross-modal retrieval.
Second, we propose a new metric that quantifies the trade-off between alignment
and separability of auditory and visual features across positive and negative
audio-visual pairs. Third, we present IS3+, an extended and improved version of
the IS3 synthetic dataset with negative audio.
  Our data, metrics and code are available on the
https://xavijuanola.github.io/SSL-SaN/.

</details>


### [50] [UItron: Foundational GUI Agent with Advanced Perception and Planning](https://arxiv.org/abs/2508.21767)
*Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma*

Main category: cs.CV

TL;DR: UItron是一个开源的自动化GUI代理基础模型，通过系统性的数据工程和交互式基础设施，提高了GUI感知、基础和规划能力，并在中文APP场景中取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: GUI代理是实现通用人工智能的重要任务，但现有方法面临数据稀缺、基础设施可用性不足以及基础模型能力有限的挑战。

Method: UItron通过监督微调和课程强化学习框架进行训练，并建立了连接移动和PC设备的交互式环境，同时收集了超过一百万步的中文APP操作轨迹数据。

Result: UItron在GUI感知、基础和规划基准测试中取得了优越的性能，特别是在中文APP交互方面表现出色。

Conclusion: UItron通过系统性的数据工程和交互式基础设施，显著提升了GUI代理的能力，尤其是在中文APP场景中，推动了GUI代理向实际应用迈进了一大步。

Abstract: GUI agent aims to enable automated operations on Mobile/PC devices, which is
an important task toward achieving artificial general intelligence. The rapid
advancement of VLMs accelerates the development of GUI agents, owing to their
powerful capabilities in visual understanding and task planning. However,
building a GUI agent remains a challenging task due to the scarcity of
operation trajectories, the availability of interactive infrastructure, and the
limitation of initial capabilities in foundation models. In this work, we
introduce UItron, an open-source foundational model for automatic GUI agents,
featuring advanced GUI perception, grounding, and planning capabilities. UItron
highlights the necessity of systemic data engineering and interactive
infrastructure as foundational components for advancing GUI agent development.
It not only systematically studies a series of data engineering strategies to
enhance training effects, but also establishes an interactive environment
connecting both Mobile and PC devices. In training, UItron adopts supervised
finetuning over perception and planning tasks in various GUI scenarios, and
then develop a curriculum reinforcement learning framework to enable complex
reasoning and exploration for online environments. As a result, UItron achieves
superior performance in benchmarks of GUI perception, grounding, and planning.
In particular, UItron highlights the interaction proficiency with top-tier
Chinese mobile APPs, as we identified a general lack of Chinese capabilities
even in state-of-the-art solutions. To this end, we manually collect over one
million steps of operation trajectories across the top 100 most popular apps,
and build the offline and online agent evaluation environments. Experimental
results demonstrate that UItron achieves significant progress in Chinese app
scenarios, propelling GUI agents one step closer to real-world application.

</details>


### [51] [Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations](https://arxiv.org/abs/2508.21769)
*Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu*

Main category: cs.CV

TL;DR: 评估CLIP在领域泛化（DG）方面的能力，发现其在高度分布外（OOD）的数据集上表现显著下降。提出CLIP-DCA方法，通过增强领域感知表示和解耦领域特征来实现领域不变性分类，并在评估中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 评估CLIP在野外领域泛化（DG）方面的能力，因为现有的评估可能不足以应对真实世界中具有挑战性的未见数据场景。

Method: 1. 在33个具有量化OOD分数的不同数据集上评估CLIP（在ImageNet上微调后）；2. 使用“遗忘”技术使CLIP遗忘某些领域作为近似。提出CLIP-DCA，通过单独的领域头和合成数据增强CLIP编码器的领域感知能力，同时通过与领域特征解耦来鼓励领域不变性分类。

Result: CLIP在高度OOD数据集上的性能显著下降。CLIP-DCA在具有挑战性的评估中比现有方法有显著改进，尤其是在OOD数据集上。

Conclusion: 增强领域感知能力是基础模型有效进行领域不变性分类的前提。CLIP-DCA通过增强领域感知和解耦领域特征，提升了CLIP在领域泛化任务上的表现。

Abstract: Evaluating domain generalization (DG) for foundational models like CLIP is
challenging, as web-scale pretraining data potentially covers many existing
benchmarks. Consequently, current DG evaluation may neither be sufficiently
challenging nor adequately test genuinely unseen data scenarios. To better
assess the performance of CLIP on DG in-the-wild, a scenario where CLIP
encounters challenging unseen data, we consider two approaches: (1) evaluating
on 33 diverse datasets with quantified out-of-distribution (OOD) scores after
fine-tuning CLIP on ImageNet, and (2) using unlearning to make CLIP `forget'
some domains as an approximation. We observe that CLIP's performance
deteriorates significantly on more OOD datasets. To address this, we present
CLIP-DCA (Disentangling Classification from enhanced domain Aware
representations). Our approach is motivated by the observation that while
standard domain invariance losses aim to make representations domain-invariant,
this can be harmful to foundation models by forcing the discarding of
domain-aware representations beneficial for generalization. We instead
hypothesize that enhancing domain awareness is a prerequisite for effective
domain-invariant classification in foundation models. CLIP-DCA identifies and
enhances domain awareness within CLIP's encoders using a separate domain head
and synthetically generated diverse domain data. Simultaneously, it encourages
domain-invariant classification through disentanglement from the domain
features. CLIP-DCA shows significant improvements within this challenging
evaluation compared to existing methods, particularly on datasets that are more
OOD.

</details>


### [52] [What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos](https://arxiv.org/abs/2508.21770)
*Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao*

Main category: cs.CV

TL;DR: 本文提出了一个包含各种非典型视频数据的新数据集，并研究了这些数据如何帮助模型在开放世界学习任务（如OOD检测、新类别发现和零样本动作识别）中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注典型数据，对开放世界视频中的非典型数据关注不足。本文旨在探索非典型视频数据在开放世界学习中的潜在益处。

Method: 收集了一个包含科幻、动画等多种非典型视频的新数据集，并将这些数据用于模型的表示学习过程，以评估其在OOD检测、NCD和ZSAR三个任务上的表现。

Result: 实验表明，即使是简单的学习方法，结合非典型数据也能在各种设置下持续提升性能。增加非典型样本的类别多样性可以进一步提高OOD检测性能。在NCD任务中，使用更小但语义更多样化的非典型样本集比使用更大但更典型的样本集效果更好。在ZSAR任务中，非典型视频的语义多样性有助于模型更好地泛化到未见过的动作类别。

Conclusion: 非典型视频数据对开放世界视觉表示学习有显著的益处，新提出的数据集为该方向的进一步研究提供了基础。

Abstract: Humans usually show exceptional generalisation and discovery ability in the
open world, when being shown uncommon new concepts. Whereas most existing
studies in the literature focus on common typical data from closed sets,
open-world novel discovery is under-explored in videos. In this paper, we are
interested in asking: \textit{What if atypical unusual videos are exposed in
the learning process?} To this end, we collect a new video dataset consisting
of various types of unusual atypical data (\eg sci-fi, animation, \etc). To
study how such atypical data may benefit open-world learning, we feed them into
the model training process for representation learning. Focusing on three key
tasks in open-world learning: out-of-distribution (OOD) detection, novel
category discovery (NCD), and zero-shot action recognition (ZSAR), we found
that even straightforward learning approaches with atypical data consistently
improve performance across various settings. Furthermore, we found that
increasing the categorical diversity of the atypical samples further boosts OOD
detection performance. Additionally, in the NCD task, using a smaller yet more
semantically diverse set of atypical samples leads to better performance
compared to using a larger but more typical dataset. In the ZSAR setting, the
semantic diversity of atypical videos helps the model generalise better to
unseen action classes. These observations in our extensive experimental
evaluations reveal the benefits of atypical videos for visual representation
learning in the open world, together with the newly proposed dataset,
encouraging further studies in this direction.

</details>


### [53] [Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering](https://arxiv.org/abs/2508.21773)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出了一种用于无监督视频持续学习（uVCL）的非参数学习方法，解决了现有研究中依赖标签和任务边界的局限性，并通过新颖性检测和知识迁移提升了模型在连续学习多个任务时的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督持续学习研究主要集中在图像领域，而视频作为复杂时空媒体信息在实际应用中广泛存在但未得到充分探索。此外，先前研究大多依赖监督学习，需要标签和任务边界信息，这在实际中成本高昂且不切实际。因此，有必要研究无监督视频持续学习（uVCL），以应对视频数据处理带来的额外计算和内存挑战。

Method: 提出使用基于无监督视频 Transformer 网络提取的深度嵌入视频特征的核密度估计（KDE）作为数据的非参数概率表示。引入新颖性检测标准来处理传入的新任务数据，动态扩展内存集群以捕获连续学习任务中的新知识。利用先前任务的迁移学习作为当前学习任务的知识迁移初始状态。

Result: 所提出的方法显著增强了模型在连续学习多个任务时的性能。

Conclusion: 该研究成功地提出了一个用于无监督视频持续学习（uVCL）的通用基准实验协议，并开发了一种基于 KDE 和新颖性检测的非参数学习方法。实验在 UCF101、HMDB51 和 Something-to-Something V2 数据集上进行了评估，证明了该方法在无需标签或类别边界的情况下，能够有效提升模型在连续学习任务中的表现。

Abstract: We propose a realistic scenario for the unsupervised video learning where
neither task boundaries nor labels are provided when learning a succession of
tasks. We also provide a non-parametric learning solution for the
under-explored problem of unsupervised video continual learning. Videos
represent a complex and rich spatio-temporal media information, widely used in
many applications, but which have not been sufficiently explored in
unsupervised continual learning. Prior studies have only focused on supervised
continual learning, relying on the knowledge of labels and task boundaries,
while having labeled data is costly and not practical. To address this gap, we
study the unsupervised video continual learning (uVCL). uVCL raises more
challenges due to the additional computational and memory requirements of
processing videos when compared to images. We introduce a general benchmark
experimental protocol for uVCL by considering the learning of unstructured
video data categories during each task. We propose to use the Kernel Density
Estimation (KDE) of deep embedded video features extracted by unsupervised
video transformer networks as a non-parametric probabilistic representation of
the data. We introduce a novelty detection criterion for the incoming new task
data, dynamically enabling the expansion of memory clusters, aiming to capture
new knowledge when learning a succession of tasks. We leverage the use of
transfer learning from the previous tasks as an initial state for the knowledge
transfer to the current learning task. We found that the proposed methodology
substantially enhances the performance of the model when successively learning
many tasks. We perform in-depth evaluations on three standard video action
recognition datasets, including UCF101, HMDB51, and Something-to-Something V2,
without using any labels or class boundaries.

</details>


### [54] [A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI](https://arxiv.org/abs/2508.21775)
*Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 该论文提出了一种基于nnU-Net框架的多阶段级联预训练策略，用于分割胰腺导管腺癌（PDAC），并解决了数据稀缺和肿瘤组织对比度差的问题。通过五折交叉验证评估了数据增强和训练计划，发现数据增强与体积准确性相关，而默认增强则提高了边界精度。最终采用了定制的异构模型集成，在PANTHER挑战赛的T1加权（任务1）和T2加权（任务2）分割任务中取得了优异的成绩，任务1的Dice得分为0.661，任务2的Dice得分为0.523。


<details>
  <summary>Details</summary>
Motivation: 自动化分割胰腺导管腺癌（PDAC）对于临床工作流程至关重要，但受到肿瘤组织对比度差和标注数据稀缺的限制。

Method: 采用基于nnU-Net框架的深度、多阶段级联预训练策略，从通用的解剖学基础模型开始，依次在CT胰腺病变数据集和目标MRI模态上进行微调。通过五折交叉验证系统评估了数据增强方案和训练计划，并构建了定制的、异构的专家模型集成。

Result: 在T1加权（任务1）分割任务中，侵略性数据增强提高了体积准确性，而默认增强则提高了边界精度（MASD为5.46 mm，HD95为17.33 mm）。最终的集成模型在任务1中达到了0.661的Dice分数，在任务2中达到了0.523的Dice分数。

Conclusion: 该研究提出了一种鲁棒的方法，用于在数据有限和复杂的医学成像任务中开发专门化的高性能模型。

Abstract: Automated segmentation of Pancreatic Ductal Adenocarcinoma (PDAC) from MRI is
critical for clinical workflows but is hindered by poor tumor-tissue contrast
and a scarcity of annotated data. This paper details our submission to the
PANTHER challenge, addressing both diagnostic T1-weighted (Task 1) and
therapeutic T2-weighted (Task 2) segmentation. Our approach is built upon the
nnU-Net framework and leverages a deep, multi-stage cascaded pre-training
strategy, starting from a general anatomical foundation model and sequentially
fine-tuning on CT pancreatic lesion datasets and the target MRI modalities.
Through extensive five-fold cross-validation, we systematically evaluated data
augmentation schemes and training schedules. Our analysis revealed a critical
trade-off, where aggressive data augmentation produced the highest volumetric
accuracy, while default augmentations yielded superior boundary precision
(achieving a state-of-the-art MASD of 5.46 mm and HD95 of 17.33 mm for Task 1).
For our final submission, we exploited this finding by constructing custom,
heterogeneous ensembles of specialist models, essentially creating a mix of
experts. This metric-aware ensembling strategy proved highly effective,
achieving a top cross-validation Tumor Dice score of 0.661 for Task 1 and 0.523
for Task 2. Our work presents a robust methodology for developing specialized,
high-performance models in the context of limited data and complex medical
imaging tasks (Team MIC-DKFZ).

</details>


### [55] [Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight](https://arxiv.org/abs/2508.21777)
*Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz*

Main category: cs.CV

TL;DR: GPT-5在放射肿瘤学领域表现出色，在考试和真实病例评估中均优于先前模型，但仍需专家监督以实现临床应用。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-5在放射肿瘤学临床决策支持方面的潜力。

Method: 使用ACR放射肿瘤学在职培训考试（TXIT）和60个真实病例进行评估，并由四名放射肿瘤学家评分。

Result: GPT-5在TXIT上准确率为92.8%，优于GPT-4和GPT-3.5。在病例评估中，GPT-5的治疗建议在正确性和全面性方面得分较高，但复杂病例中存在错误，且评分者间一致性较低。

Conclusion: GPT-5在放射肿瘤学方面表现出巨大潜力，但在临床实施前需要专家进行严格审查。

Abstract: Introduction: Large language models (LLM) have shown great potential in
clinical decision support. GPT-5 is a novel LLM system that has been
specifically marketed towards oncology use.
  Methods: Performance was assessed using two complementary benchmarks: (i) the
ACR Radiation Oncology In-Training Examination (TXIT, 2021), comprising 300
multiple-choice items, and (ii) a curated set of 60 authentic radiation
oncologic vignettes representing diverse disease sites and treatment
indications. For the vignette evaluation, GPT-5 was instructed to generate
concise therapeutic plans. Four board-certified radiation oncologists rated
correctness, comprehensiveness, and hallucinations. Inter-rater reliability was
quantified using Fleiss' \k{appa}.
  Results: On the TXIT benchmark, GPT-5 achieved a mean accuracy of 92.8%,
outperforming GPT-4 (78.8%) and GPT-3.5 (62.1%). Domain-specific gains were
most pronounced in Dose and Diagnosis. In the vignette evaluation, GPT-5's
treatment recommendations were rated highly for correctness (mean 3.24/4, 95%
CI: 3.11-3.38) and comprehensiveness (3.59/4, 95% CI: 3.49-3.69).
Hallucinations were rare with no case reaching majority consensus for their
presence. Inter-rater agreement was low (Fleiss' \k{appa} 0.083 for
correctness), reflecting inherent variability in clinical judgment. Errors
clustered in complex scenarios requiring precise trial knowledge or detailed
clinical adaptation.
  Discussion: GPT-5 clearly outperformed prior model variants on the radiation
oncology multiple-choice benchmark. Although GPT-5 exhibited favorable
performance in generating real-world radiation oncology treatment
recommendations, correctness ratings indicate room for further improvement.
While hallucinations were infrequent, the presence of substantive errors
underscores that GPT-5-generated recommendations require rigorous expert
oversight before clinical implementation.

</details>


### [56] [TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank](https://arxiv.org/abs/2508.21795)
*Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan*

Main category: cs.CV

TL;DR: TMUAD通过结合文本和图像记忆库，实现了对结构和逻辑异常的统一检测，并在工业和医疗领域数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在仅有少量正常数据的情况下，难以捕捉对象间的逻辑关系，并且通常依赖于精心设计的图像特征提取器和内存库。

Method: 提出了一种名为TMUAD的三记忆框架，用于统一结构和逻辑异常检测。首先，利用提出的逻辑感知文本提取器构建了一个用于逻辑异常检测的类级别文本记忆库。其次，构建了一个用于保留完整对象轮廓的对象级别图像记忆库。第三，利用视觉编码器提取块级别图像特征，构建用于结构异常检测的块级别记忆库。这三个互补的记忆库用于检索和比较与查询图像最相似的正常图像，计算多级别异常分数，并融合得到最终异常分数。

Result: TMUAD通过统一结构和逻辑异常检测，并利用协同记忆库，在涉及工业和医疗领域的七个公开数据集上取得了最先进的性能。

Conclusion: TMUAD通过协同记忆库统一了结构和逻辑异常检测，实现了优越的性能。

Abstract: Anomaly detection, which aims to identify anomalies deviating from normal
patterns, is challenging due to the limited amount of normal data available.
Unlike most existing unified methods that rely on carefully designed image
feature extractors and memory banks to capture logical relationships between
objects, we introduce a text memory bank to enhance the detection of logical
anomalies. Specifically, we propose a Three-Memory framework for Unified
structural and logical Anomaly Detection (TMUAD). First, we build a class-level
text memory bank for logical anomaly detection by the proposed logic-aware text
extractor, which can capture rich logical descriptions of objects from input
images. Second, we construct an object-level image memory bank that preserves
complete object contours by extracting features from segmented objects. Third,
we employ visual encoders to extract patch-level image features for
constructing a patch-level memory bank for structural anomaly detection. These
three complementary memory banks are used to retrieve and compare normal images
that are most similar to the query image, compute anomaly scores at multiple
levels, and fuse them into a final anomaly score. By unifying structural and
logical anomaly detection through collaborative memory banks, TMUAD achieves
state-of-the-art performance across seven publicly available datasets involving
industrial and medical domains. The model and code are available at
https://github.com/SIA-IDE/TMUAD.

</details>


### [57] [VoCap: Video Object Captioning and Segmentation from Any Prompt](https://arxiv.org/abs/2508.21809)
*Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid*

Main category: cs.CV

TL;DR: VoCap是一个灵活的视频模型，可以接收视频和各种模态（文本、框或掩码）的提示，并生成具有相应以对象为中心的字幕的时空掩码。它同时处理可提示视频对象分割、指代表达式分割和对象字幕任务。为了解决数据获取的挑战，研究者提出在现有的SAV数据集上添加伪对象字幕，并创建了SAV-Caption数据集。在SAV-Caption数据集及其他图像和视频数据集上进行大规模训练后，VoCap在指代表达式视频对象分割方面取得了最先进的成果，在半监督视频对象分割方面具有竞争力，并为视频对象字幕设定了基准。


<details>
  <summary>Details</summary>
Motivation: 视频理解中的一个基本任务是根据细粒度的定位掩码和详细的语义属性来理解视频中的对象。然而，获取此类任务的数据既繁琐又昂贵。

Method: 该研究提出了一种名为VoCap的灵活视频模型。该模型以视频和文本、框或掩码等多种模态的提示作为输入，并生成时空掩码块以及相应的以对象为中心的字幕。为了解决数据稀缺问题，研究者们提出了一种在现有的SAV数据集上添加伪对象字幕的方法，他们通过处理带有地面实况掩码的视频来突出感兴趣的对象，并将其输入到大型视觉语言模型（VLM）中。该数据集被称为SAV-Caption。VoCap模型在大规模SAV-Caption数据集以及混合的其他图像和视频数据集上进行训练。

Result: VoCap模型在指代表达式视频对象分割方面取得了最先进的成果，在半监督视频对象分割方面具有竞争力，并为视频对象字幕设定了基准。

Conclusion: VoCap模型在处理多模态提示和生成细粒度时空掩码方面表现出色，同时解决了视频对象分割和字幕任务，并为相关领域设定了新的基准。

Abstract: Understanding objects in videos in terms of fine-grained localization masks
and detailed semantic properties is a fundamental task in video understanding.
In this paper, we propose VoCap, a flexible video model that consumes a video
and a prompt of various modalities (text, box or mask), and produces a
spatio-temporal masklet with a corresponding object-centric caption. As such
our model addresses simultaneously the tasks of promptable video object
segmentation, referring expression segmentation, and object captioning. Since
obtaining data for this task is tedious and expensive, we propose to annotate
an existing large-scale segmentation dataset (SAV) with pseudo object captions.
We do so by preprocessing videos with their ground-truth masks to highlight the
object of interest and feed this to a large Vision Language Model (VLM). For an
unbiased evaluation, we collect manual annotations on the validation set. We
call the resulting dataset SAV-Caption. We train our VoCap model at scale on a
SAV-Caption together with a mix of other image and video datasets. Our model
yields state-of-the-art results on referring expression video object
segmentation, is competitive on semi-supervised video object segmentation, and
establishes a benchmark for video object captioning. Our dataset will be made
available at https://github.com/google-deepmind/vocap.

</details>


### [58] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 本篇论文提出了一种新的场景识别（SR）方法，将原本被视为单标签问题的动词分类重新定义为多标签学习问题（SPMLL），并设计了相应的多标签评估基准和名为GE-VerbMLP的模型。该模型通过图神经网络和对抗训练来处理动词之间的关联和决策边界。


<details>
  <summary>Details</summary>
Motivation: 现有的场景识别方法将动词分类视为单标签问题，但这未能解决视觉事件识别中的固有歧义，因为同一图像可能适用于多个动词类别。本文旨在解决这一问题，将动词分类视为一个多标签问题。

Method: 本文提出将动词分类重构为单一正例多标签学习（SPMLL）问题，并设计了一个用于SR的多标签评估基准。为了应对SPMLL的挑战，研究者开发了图增强动词多层感知机（GE-VerbMLP），它结合了图神经网络来捕捉标签相关性，并使用对抗训练来优化决策边界。

Result: GE-VerbMLP模型在真实世界数据集上的实验结果显示，在传统top-1和top-5准确率指标保持竞争力的同时，平均精度均值（MAP）提高了3%以上。

Conclusion: 将动词分类视为多标签问题并采用SPMLL方法，以及使用GE-VerbMLP模型，能够更有效地解决场景识别中的歧义问题，并提高模型性能。

Abstract: Context recognition (SR) is a fundamental task in computer vision that aims
to extract structured semantic summaries from images by identifying key events
and their associated entities. Specifically, given an input image, the model
must first classify the main visual events (verb classification), then identify
the participating entities and their semantic roles (semantic role labeling),
and finally localize these entities in the image (semantic role localization).
Existing methods treat verb classification as a single-label problem, but we
show through a comprehensive analysis that this formulation fails to address
the inherent ambiguity in visual event recognition, as multiple verb categories
may reasonably describe the same image. This paper makes three key
contributions: First, we reveal through empirical analysis that verb
classification is inherently a multi-label problem due to the ubiquitous
semantic overlap between verb categories. Second, given the impracticality of
fully annotating large-scale datasets with multiple labels, we propose to
reformulate verb classification as a single positive multi-label learning
(SPMLL) problem - a novel perspective in SR research. Third, we design a
comprehensive multi-label evaluation benchmark for SR that is carefully
designed to fairly evaluate model performance in a multi-label setting. To
address the challenges of SPMLL, we futher develop the Graph Enhanced Verb
Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to
capture label correlations and adversarial training to optimize decision
boundaries. Extensive experiments on real-world datasets show that our approach
achieves more than 3\% MAP improvement while remaining competitive on
traditional top-1 and top-5 accuracy metrics.

</details>


### [59] [DriveQA: Passing the Driving Knowledge Test](https://arxiv.org/abs/2508.21824)
*Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: LLMs在驾驶知识测试中表现不佳，特别是在数字推理和复杂路权场景中，但通过DriveQA进行微调和预训练可以提高性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs和MLLMs在驾驶知识测试中的能力，并开发一个全面的基准来改进它们。

Method: 提出DriveQA，一个包含文本和视觉信息的广泛的驾驶知识基准，并进行实验以评估LLMs和MLLMs的性能，以及微调和预训练的影响。

Result: LLMs和MLLMs在基本交通规则方面表现良好，但在数字推理、复杂路权、交通标志变体和空间布局方面存在明显不足。在DriveQA上进行微调可以提高准确性，尤其是在交通标志识别和交叉口决策方面。DriveQA-V的实验揭示了模型对光照、视角、距离和天气等环境因素的敏感性。在DriveQA上进行预训练可以提高下游驾驶任务的性能，并在nuScenes和BDD等真实数据集上取得更好的结果。

Conclusion: LLMs和MLLMs可以通过DriveQA数据集进行改进，并且它们能够有效地将在DriveQA中学到的文本和合成交通知识泛化到下游QA任务中。

Abstract: If a Large Language Model (LLM) were to take a driving knowledge test today,
would it pass? Beyond standard spatial and visual question-answering (QA) tasks
on current autonomous driving benchmarks, driving knowledge tests require a
complete understanding of all traffic rules, signage, and right-of-way
principles. To pass this test, human drivers must discern various edge cases
that rarely appear in real-world datasets. In this work, we present DriveQA, an
extensive open-source text and vision-based benchmark that exhaustively covers
traffic regulations and scenarios. Through our experiments using DriveQA, we
show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on
basic traffic rules but exhibit significant weaknesses in numerical reasoning
and complex right-of-way scenarios, traffic sign variations, and spatial
layouts, (2) fine-tuning on DriveQA improves accuracy across multiple
categories, particularly in regulatory sign recognition and intersection
decision-making, (3) controlled variations in DriveQA-V provide insights into
model sensitivity to environmental factors such as lighting, perspective,
distance, and weather conditions, and (4) pretraining on DriveQA enhances
downstream driving task performance, leading to improved results on real-world
datasets such as nuScenes and BDD, while also demonstrating that models can
internalize text and synthetic traffic knowledge to generalize effectively
across downstream QA tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [60] [CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples](https://arxiv.org/abs/2508.21083)
*Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim*

Main category: cs.CL

TL;DR: CoBA框架通过分解、修改和重建文本中的语义三元组来解决深度学习中的虚假相关性问题，从而提高模型性能、减少偏见并增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型常学习并利用训练数据中的虚假相关性，导致在未见过的数据上表现下降和泛化能力差。需要一种方法来解决多重偏见和提高分布外鲁棒性。

Method: 提出CoBA（CounterBias Augmentation）框架，该框架在语义三元组（主语-谓语-宾语）层面操作，选择性地修改三元组以打破虚假相关性，然后从调整后的三元组重建文本，生成反偏见数据。

Result: CoBA不仅提高了下游任务的性能，还有效减少了偏见，增强了分布外数据的鲁棒性。

Conclusion: CoBA是一个多功能且鲁棒的解决方案，可以缓解虚假相关性带来的挑战。

Abstract: Deep learning models often learn and exploit spurious correlations in
training data, using these non-target features to inform their predictions.
Such reliance leads to performance degradation and poor generalization on
unseen data. To address these limitations, we introduce a more general form of
counterfactual data augmentation, termed counterbias data augmentation, which
simultaneously tackles multiple biases (e.g., gender bias, simplicity bias) and
enhances out-of-distribution robustness. We present CoBA: CounterBias
Augmentation, a unified framework that operates at the semantic triple level:
first decomposing text into subject-predicate-object triples, then selectively
modifying these triples to disrupt spurious correlations. By reconstructing the
text from these adjusted triples, CoBA generates counterbias data that
mitigates spurious patterns. Through extensive experiments, we demonstrate that
CoBA not only improves downstream task performance, but also effectively
reduces biases and strengthens out-of-distribution resilience, offering a
versatile and robust solution to the challenges posed by spurious correlations.

</details>


### [61] [Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting](https://arxiv.org/abs/2508.21084)
*Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke*

Main category: cs.CL

TL;DR: 该研究发布了首个包含年龄标注的大规模德语有毒言论数据集，以解决现有数据集缺乏人口统计学背景的问题。


<details>
  <summary>Details</summary>
Motivation: 现有有毒言论数据集缺乏人口统计学背景，限制了对不同年龄群体在线交流方式的理解。

Method: 与德国公共服务内容网络funk合作，收集了来自Instagram、TikTok和YouTube的30,024条匿名评论，并使用预定义的有毒关键词进行筛选，最终标记了16.7%的评论。该数据集结合了人类标注和先进的语言模型，涵盖了侮辱、虚假信息和广播费批评等类别。

Result: 该数据集揭示了基于年龄的有毒言论模式差异：年轻用户倾向于使用富有表现力的语言，而年长用户更倾向于传播虚假信息和贬低性言论。

Conclusion: 该数据集为研究不同人群的语言变异提供了新机会，并支持开发更公平、更具年龄意识的内容审核系统。

Abstract: A lack of demographic context in existing toxic speech datasets limits our
understanding of how different age groups communicate online. In collaboration
with funk, a German public service content network, this research introduces
the first large-scale German dataset annotated for toxicity and enriched with
platform-provided age estimates. The dataset includes 3,024 human-annotated and
30,024 LLM-annotated anonymized comments from Instagram, TikTok, and YouTube.
To ensure relevance, comments were consolidated using predefined toxic
keywords, resulting in 16.7\% labeled as problematic. The annotation pipeline
combined human expertise with state-of-the-art language models, identifying key
categories such as insults, disinformation, and criticism of broadcasting fees.
The dataset reveals age-based differences in toxic speech patterns, with
younger users favoring expressive language and older users more often engaging
in disinformation and devaluation. This resource provides new opportunities for
studying linguistic variation across demographics and supports the development
of more equitable and age-aware content moderation systems.

</details>


### [62] [Granite Embedding R2 Models](https://arxiv.org/abs/2508.21085)
*Parul Awasthy,Aashka Trivedi,Yulong Li,Meet Doshi,Riyaz Bhat,Vignesh P,Vishwajeet Kumar,Yushu Yang,Bhavani Iyer,Abraham Daniels,Rudra Murthy,Ken Barker,Martin Franz,Madison Lee,Todd Ward,Salim Roukos,David Cox,Luis Lastras,Jaydeep Sen,Radu Florian*

Main category: cs.CL

TL;DR: Granite Embedding R2模型是一个高性能的英文编码器嵌入模型系列，专为企业级检索应用设计，提供了16倍的上下文长度扩展、在文本、代码、长文档搜索、多轮对话和表格数据等领域达到最先进的性能，并且速度比竞争对手快19-44%，同时保持高精度。该系列包括双编码器和交叉编码器架构，并提供22层和12层检索模型以及一个重排模型，所有模型均在企业级数据上进行训练，并有治理监督。这些模型在标准基准、IBM评估套件和实际企业用例中表现出卓越的通用性，为开源嵌入模型树立了新的性能标杆。Granite R2模型结合了先进性能、企业级许可和透明数据来源，适用于关键任务部署。


<details>
  <summary>Details</summary>
Motivation: Granite R2模型旨在为企业级密集检索应用提供高性能的英文嵌入模型，以满足在检索速度和准确性日益重要的时代对竞争优势的需求。

Method: 本文介绍的Granite Embedding R2模型是一个包含高性能英文编码器嵌入模型的系列，专为企业级密集检索应用设计。模型家族包括双编码器和交叉编码器架构，具体有22层检索模型和12层检索模型，以及一个重排模型。这些模型经过优化，上下文长度扩展至8192个token，并在文本、代码、长文档搜索、多轮对话和表格数据等多个检索领域实现了最先进的性能。与领先的竞争对手相比，其速度提升了19-44%，同时保持了更高的准确性。所有模型均在符合企业使用规范且经过治理监督的数据上进行训练。

Result: Granite R2模型在标准基准、IBM评估套件和实际企业用例中展现了卓越的通用性，在文本、代码、长文档搜索、多轮对话和表格数据等检索领域设定了新的性能标准。其速度比领先竞争对手快19-44%，同时保持了优越的准确性。

Conclusion: Granite R2模型结合了尖端性能、企业级许可和透明数据来源，为组织在关键任务部署中提供了必要的支持，满足了对检索速度和准确性的高要求。这些模型已根据Apache 2.0许可公开提供，允许无限制的研究和商业用途。

Abstract: We introduce the Granite Embedding R2 models, a comprehensive family of
high-performance English encoder-based embedding models engineered for
enterprise-scale dense retrieval applications. Building upon our
first-generation release, these models deliver substantial improvements,
including 16x expanded context length (8,192 tokens), state-of-the-art
performance across diverse retrieval domains - text, code, long-document
search, multi-turn conversational, and tabular data - and measurable speed
advantages of 19-44\% over leading competitors while maintaining superior
accuracy. Our release encompasses both bi-encoder and cross-encoder
architectures, featuring a highly effective 22-layer retriever model and its
efficient 12-layer counterpart, alongside a high-quality reranker model, all
trained exclusively on enterprise-appropriate data with comprehensive
governance oversight. The models demonstrate exceptional versatility across
standard benchmarks, IBM-developed evaluation suites, and real-world enterprise
use cases, establishing new performance standards for open-source embedding
models. In an era where retrieval speed and accuracy are paramount for
competitive advantage, the Granite R2 models deliver a compelling combination
of cutting-edge performance, enterprise-ready licensing, and transparent data
provenance that organizations require for mission-critical deployments. All
models are publicly available under the Apache 2.0 license at
https://huggingface.co/collections/ibm-granite, enabling unrestricted research
and commercial use.

</details>


### [63] [Is this chart lying to me? Automating the detection of misleading visualizations](https://arxiv.org/abs/2508.21675)
*Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych*

Main category: cs.CL

TL;DR: 该研究提出了一个包含2,604个真实世界可视化图表的基准Misviz，并附带12种误导类型注释，以及一个包含81,814个合成可视化图表的Misviz-synth数据集，用于训练和评估AI模型检测误导性可视化图表的能力。研究结果表明，这项任务仍然充满挑战。


<details>
  <summary>Details</summary>
Motivation: 自动检测误导性可视化图表并识别其违反的设计规则，有助于保护读者并减少错误信息传播。然而，目前缺乏大型、多样化且公开可用的数据集来支持AI模型的训练和评估。

Method: 创建了一个名为Misviz的基准，包含2,604个真实世界的可视化图表，并标注了12种误导类型。同时，生成了一个名为Misviz-synth的合成数据集，包含81,814个可视化图表，用于模型训练。在两个数据集上使用先进的多模态大型语言模型（MLLMs）、基于规则的系统和微调分类器进行了全面评估。

Result: 对MLLMs、基于规则的系统和微调分类器的评估结果显示，检测误导性可视化图表的任务仍然极具挑战性。

Conclusion: 发布了Misviz基准、Misviz-synth合成数据集以及相关代码，以促进对误导性可视化图表检测的研究。

Abstract: Misleading visualizations are a potent driver of misinformation on social
media and the web. By violating chart design principles, they distort data and
lead readers to draw inaccurate conclusions. Prior work has shown that both
humans and multimodal large language models (MLLMs) are frequently deceived by
such visualizations. Automatically detecting misleading visualizations and
identifying the specific design rules they violate could help protect readers
and reduce the spread of misinformation. However, the training and evaluation
of AI models has been limited by the absence of large, diverse, and openly
available datasets. In this work, we introduce Misviz, a benchmark of 2,604
real-world visualizations annotated with 12 types of misleaders. To support
model training, we also release Misviz-synth, a synthetic dataset of 81,814
visualizations generated using Matplotlib and based on real-world data tables.
We perform a comprehensive evaluation on both datasets using state-of-the-art
MLLMs, rule-based systems, and fine-tuned classifiers. Our results reveal that
the task remains highly challenging. We release Misviz, Misviz-synth, and the
accompanying code.

</details>


### [64] [TrInk: Ink Generation with Transformer Network](https://arxiv.org/abs/2508.21098)
*Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu*

Main category: cs.CL

TL;DR: TrInk是一个基于Transformer的墨水生成模型，通过引入缩放位置嵌入和高斯记忆掩码来优化文本与笔画点之间的对齐，并在IAM-OnDB数据集上实现了显著的错误率降低。


<details>
  <summary>Details</summary>
Motivation: 为了更好地对齐输入的文本和生成的笔画点，Captures global dependencies。

Method: 本文提出了TrInk，一个基于Transformer的模型，用于墨水生成。通过引入缩放位置嵌入和高斯记忆掩码在交叉注意力模块中，以更好地促进输入文本和生成笔画点之间的对齐。此外，还设计了主观和客观评估流程，全面评估生成手写的易读性和风格一致性。

Result: 实验证明，与先前的方法相比，基于Transformer的模型在IAM-OnDB数据集上实现了35.56%的字符错误率（CER）和29.66%的单词错误率（WER）的降低。

Conclusion: TrInk模型在手写生成任务上取得了显著的进展，通过改进的Transformer架构和对齐机制，有效提高了生成手写的质量和准确性。

Abstract: In this paper, we propose TrInk, a Transformer-based model for ink
generation, which effectively captures global dependencies. To better
facilitate the alignment between the input text and generated stroke points, we
introduce scaled positional embeddings and a Gaussian memory mask in the
cross-attention module. Additionally, we design both subjective and objective
evaluation pipelines to comprehensively assess the legibility and style
consistency of the generated handwriting. Experiments demonstrate that our
Transformer-based model achieves a 35.56\% reduction in character error rate
(CER) and an 29.66% reduction in word error rate (WER) on the IAM-OnDB dataset
compared to previous methods. We provide an demo page with handwriting samples
from TrInk and baseline models at: https://akahello-a11y.github.io/trink-demo/

</details>


### [65] [How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations](https://arxiv.org/abs/2508.21137)
*Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu*

Main category: cs.CL

TL;DR: LLM 在价格谈判中会受到锚定效应的影响，与人类相似。长思考链可以减轻这种效应，但人格特质没有显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究 LLM 在价格谈判中是否会受到人类认知偏差（特别是锚定效应）的影响，以提高 LLM 在实际应用中的可靠性。

Method: 指示卖方 LLM 代理应用锚定效应，并使用客观和主观指标评估谈判。

Result: LLM 确实会像人类一样受到锚定效应的影响。长思考链（reasoning models）可以减轻锚定效应，但人格特质与锚定效应的易感性之间没有显著相关性。

Conclusion: LLM 存在认知偏差，特别是锚定效应。通过长思考链可以减轻这种效应，这有助于深入理解 LLM 的认知偏差，并推动 LLM 的安全负责任的应用。

Abstract: Cognitive biases, well-studied in humans, can also be observed in LLMs,
affecting their reliability in real-world applications. This paper investigates
the anchoring effect in LLM-driven price negotiations. To this end, we
instructed seller LLM agents to apply the anchoring effect and evaluated
negotiations using not only an objective metric but also a subjective metric.
Experimental results show that LLMs are influenced by the anchoring effect like
humans. Additionally, we investigated the relationship between the anchoring
effect and factors such as reasoning and personality. It was shown that
reasoning models are less prone to the anchoring effect, suggesting that the
long chain of thought mitigates the effect. However, we found no significant
correlation between personality traits and susceptibility to the anchoring
effect. These findings contribute to a deeper understanding of cognitive biases
in LLMs and to the realization of safe and responsible application of LLMs in
society.

</details>


### [66] [Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?](https://arxiv.org/abs/2508.21143)
*Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla*

Main category: cs.CL

TL;DR: 该研究评估了多模态大语言模型（MLLM）在简单感知任务上的表现，并引入了一个名为Percept-V的新数据集。实验结果显示，随着任务复杂度的增加，MLLM的性能显著下降，且在不同认知技能的测试中表现出相似的准确性趋势。


<details>
  <summary>Details</summary>
Motivation: 评估MLLM在简单感知任务上的性能，以填补在基础视觉感知评估方面的空白。

Method: 引入了一个名为Percept-V的新数据集，包含7200张程序生成图像，涵盖30个类别，每个类别测试不同的视觉感知技能组合。使用GPT-4o、Gemini、Claude以及OpenAI o4-mini和DeepSeek R1等模型在Percept-V数据集上进行测试。

Result: 实验表明，随着问题复杂度的增加，所有被测试的MLLM和LRM性能均显著下降。同时，MLLM在测试特定认知技能的类别中表现出相似的准确性趋势，表明某些技能比其他技能更难。

Conclusion: 尽管MLLM在复杂任务中表现出色，但在简单的感知任务上，其性能会随着复杂度的增加而下降，并且在不同认知技能的掌握程度上存在差异。

Abstract: The reasoning abilities of Multimodal Large Language Models (MLLMs) have
garnered a lot of attention in recent times, with advances made in frontiers
like coding, mathematics, and science. However, very limited experiments have
been done to assess their performance in simple perception tasks performed over
uncontaminated, generated images containing basic shapes and structures. To
address this issue, the paper introduces a dataset, Percept-V, containing a
total of 7200 program-generated images equally divided into 30 categories, each
testing a combination of visual perception skills. Unlike previously proposed
datasets, Percept-V comprises very basic tasks of varying complexity that test
the perception abilities of MLLMs. This dataset is then tested on
state-of-the-art MLLMs like GPT-4o, Gemini, and Claude as well as Large
Reasoning Models (LRMs) like OpenAI o4-mini and DeepSeek R1 to gauge their
performance. Contrary to the evidence that MLLMs excel in many complex tasks,
our experiments show a significant drop in the models' performance with
increasing problem complexity across all categories. An analysis of the
performances also reveals that the tested MLLMs exhibit a similar trend in
accuracy across categories, testing a particular cognitive skill and find some
skills to be more difficult than others.

</details>


### [67] [A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers](https://arxiv.org/abs/2508.21148)
*Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He,Chunfeng Song,Lei Bai,Bowen Zhou*

Main category: cs.CL

TL;DR: 本综述对科学大型语言模型（Sci-LLMs）进行了数据驱动的综合分析，强调了模型与数据之间的协同进化关系。论文提出了一个统一的科学数据分类法和科学知识模型，并系统回顾了Sci-LLMs、训练数据集和评估基准，重点关注科学数据固有的挑战，如异构性、多尺度和不确定性。综述还探讨了数据开发中的问题和新兴解决方案，并展望了Sci-LLMs在加速科学发现中的未来应用，提出构建可信赖的、持续进化的AI系统作为科学研究的合作伙伴。


<details>
  <summary>Details</summary>
Motivation: 鉴于科学大型语言模型（Sci-LLMs）在科学研究中的重要性日益增加，但其进展受到科学数据复杂性的影响，本研究旨在提供一个数据中心化的视角来理解和指导Sci-LLM的发展。

Method: 本研究通过以下方法进行：1. 提出一个统一的科学数据分类法和科学知识模型。2. 系统性地回顾近期Sci-LLMs，分析了超过270个预训练/后训练数据集。3. 考察了超过190个基准数据集，分析了评估协议的变化。4. 讨论了科学数据开发中的挑战和解决方案。5. 展望了Sci-LLMs在闭环系统中的应用前景。

Result: 本研究对Sci-LLMs的研究现状进行了全面的数据中心化分析，强调了科学数据（异构、多尺度、不确定性）对模型提出的独特要求。研究回顾了模型、数据集和评估基准，并讨论了数据开发中的挑战和解决方案，为构建可信赖的AI系统提供了指导。文章还指出，评估方法正从静态转向更侧重过程和发现的评估。

Conclusion: 本综述通过数据中心化的视角，为理解和发展Sci-LLMs提供了新框架，强调了模型与数据协同进化。研究结果为构建更可信赖、能持续进化的AI系统，以加速科学发现提供了路线图。

Abstract: Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is
represented, integrated, and applied in scientific research, yet their progress
is shaped by the complex nature of scientific data. This survey presents a
comprehensive, data-centric synthesis that reframes the development of Sci-LLMs
as a co-evolution between models and their underlying data substrate. We
formulate a unified taxonomy of scientific data and a hierarchical model of
scientific knowledge, emphasizing the multimodal, cross-scale, and
domain-specific challenges that differentiate scientific corpora from general
natural language processing datasets. We systematically review recent Sci-LLMs,
from general-purpose foundations to specialized models across diverse
scientific disciplines, alongside an extensive analysis of over 270
pre-/post-training datasets, showing why Sci-LLMs pose distinct demands --
heterogeneous, multi-scale, uncertainty-laden corpora that require
representations preserving domain invariance and enabling cross-modal
reasoning. On evaluation, we examine over 190 benchmark datasets and trace a
shift from static exams toward process- and discovery-oriented assessments with
advanced evaluation protocols. These data-centric analyses highlight persistent
issues in scientific data development and discuss emerging solutions involving
semi-automated annotation pipelines and expert validation. Finally, we outline
a paradigm shift toward closed-loop systems where autonomous agents based on
Sci-LLMs actively experiment, validate, and contribute to a living, evolving
knowledge base. Collectively, this work provides a roadmap for building
trustworthy, continually evolving artificial intelligence (AI) systems that
function as a true partner in accelerating scientific discovery.

</details>


### [68] [Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations](https://arxiv.org/abs/2508.21164)
*Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush*

Main category: cs.CL

TL;DR: LLM评估中的偏见：ChatGPT、Gemini和Claude在有无标签情况下对博客文章的评估显示，“Claude”标签会提高分数，“Gemini”标签会降低分数，即使在虚假标签情况下也是如此。虚假标签甚至会颠倒排名，Gemini的自我评分在真实标签下会下降，而Claude的自我偏好会增强。这表明模型身份感知会严重影响LLM基准测试的公平性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在自我评估和跨模型评估中可能存在的偏见，尤其是在不同标签（无标签、真实标签、虚假标签）条件下的表现。

Method: 使用ChatGPT、Gemini和Claude对这三个模型生成的博客文章进行评估。评估方法包括总体偏好投票和对连贯性、信息性和简洁性的质量评分，所有分数均以百分比表示。研究了四种条件：无标签、真实标签和两种虚假标签场景。

Result: “Claude”标签持续提高分数，“Gemini”标签持续降低分数，无论实际内容如何。虚假标签经常颠倒排名，偏好投票变化高达50个百分点，质量评分转换变化高达12个百分点。Gemini在真实标签下的自我评分大幅下降，而Claude的自我偏好增强。

Conclusion: 模型身份感知会严重影响高层判断，并微妙地影响详细的质量评分。因此，需要采用盲评或多模型评估协议来确保LLM基准测试的公平性。

Abstract: Large language models (LLMs) are increasingly used to evaluate outputs, yet
their judgments may be influenced. This study examines bias in self- and
cross-model evaluations by ChatGPT, Gemini, and Claude under four conditions:
no labels, true labels, and two false-label scenarios. Blog posts authored by
each model were evaluated by all three using both overall preference voting and
quality ratings for Coherence, Informativeness, and Conciseness, with all
scores expressed as percentages for direct comparison. Results reveal striking
asymmetries: the "Claude" label consistently boosts scores, while the "Gemini"
label consistently depresses them, regardless of actual content. False labels
frequently reversed rankings, producing shifts of up to 50 percentage points in
preference votes and up to 12 percentage points in converted quality ratings.
Gemini's self-scores collapsed under true labels, while Claude's
self-preference intensified. These findings show that perceived model identity
can heavily distort high-level judgments and subtly influence detailed quality
ratings, underscoring the need for blind or multimodel evaluation protocols to
ensure fairness in LLM benchmarking.

</details>


### [69] [BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design](https://arxiv.org/abs/2508.21184)
*Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth*

Main category: cs.CL

TL;DR: BED-LLM通过顺序贝叶斯实验设计来增强LLM的信息收集能力，在20个问题游戏和用户偏好推断等任务中表现优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLM）从用户或其他外部源智能且自适应地收集信息的能力。

Method: 提出了一种名为BED-LLM（贝叶斯实验设计与大型语言模型）的方法，该方法基于顺序贝叶斯实验设计框架。BED-LLM通过迭代地选择最大化预期信息增益（EIG）的问题或查询，以利用先前收集的响应来完成任务。EIG的计算基于LLM的信念分布的概率模型，并结合了改进的EIG估计器和有针对性的候选查询提议策略。

Result: BED-LLM在基于20个问题游戏和LLM主动推断用户偏好的广泛测试中，与直接提示LLM和其他自适应设计策略相比，在性能上取得了显著的提升。

Conclusion: BED-LLM能够使LLM成为有效的多轮对话代理，并能与外部环境进行交互式接口，在信息收集任务中展现出优越的性能。

Abstract: We propose a general-purpose approach for improving the ability of Large
Language Models (LLMs) to intelligently and adaptively gather information from
a user or other external source using the framework of sequential Bayesian
experimental design (BED). This enables LLMs to act as effective multi-turn
conversational agents and interactively interface with external environments.
Our approach, which we call BED-LLM (Bayesian Experimental Design with Large
Language Models), is based on iteratively choosing questions or queries that
maximize the expected information gain (EIG) about the task of interest given
the responses gathered previously. We show how this EIG can be formulated in a
principled way using a probabilistic model derived from the LLM's belief
distribution and provide detailed insights into key decisions in its
construction. Further key to the success of BED-LLM are a number of specific
innovations, such as a carefully designed estimator for the EIG, not solely
relying on in-context updates for conditioning on previous responses, and a
targeted strategy for proposing candidate queries. We find that BED-LLM
achieves substantial gains in performance across a wide range of tests based on
the 20-questions game and using the LLM to actively infer user preferences,
compared to direct prompting of the LLM and other adaptive design strategies.

</details>


### [70] [Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2508.21201)
*Arash Ahmadi,Sarah Sharif,Yaser Banad*

Main category: cs.CL

TL;DR: “本研究提出了一种基于强化学习（GRPO）的自动化HFACS分类框架，使用Llama-3.1 8B模型，通过多组分奖励系统和合成数据生成，显著提高了航空安全分析的准确性和效率，并优于现有SOTA模型，为资源受限设备上的低延迟部署提供了可能。”


<details>
  <summary>Details</summary>
Motivation: “传统的人为因素分析和分类系统（HFACS）在扩展性和一致性方面存在局限，因此需要一种自动化的方法来改进航空事故的人为因素分析。”

Method: “研究提出了一种利用强化学习（GRPO）微调Llama-3.1 8B语言模型的自动化HFACS分类框架。该框架包含一个针对航空安全分析定制的多组分奖励系统，并利用合成数据生成来解决事故数据集中类别不平衡的问题。”

Result: “所提出的GRPO优化模型在精确匹配准确率（从0.0400提高到0.1800，增长350%）和部分匹配准确率（达到0.8800）方面取得了显著的性能提升。在关键指标上，该模型优于GPT-5-mini和Gemini-2.5-fiash等SOTA LLM。”

Conclusion: “研究结果表明，小型、针对特定领域优化的模型可以为关键的安全分析提供计算效率更高且性能更优的解决方案，并且能够实现低延迟部署在资源受限的边缘设备上。”

Abstract: Analyzing the human factors behind aviation accidents is crucial for
preventing future incidents, yet traditional methods using the Human Factors
Analysis and Classification System (HFACS) are limited by scalability and
consistency. To address this, we introduce an automated HFACS classification
framework for aviation safety analysis that utilizes Reinforcement Learning
with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B
language model. Our approach incorporates a multi-component reward system
tailored for aviation safety analysis and integrates synthetic data generation
to overcome class imbalance in accident datasets. The resulting GRPO-optimized
model achieved noticeable performance gains, including a 350% increase in exact
match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy
of 0.8800. Significantly, our specialized model outperforms state-of-the-art
LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key
metrics. This research also proposes exact match accuracy in multi-label HFACS
classification problem as a new benchmarking methodology to evaluate the
advanced reasoning capabilities of language models. Ultimately, our work
validates that smaller, domain-optimized models can provide a computationally
efficient and better solution for critical safety analysis. This approach makes
powerful, low-latency deployment on resource-constrained edge devices feasible.

</details>


### [71] [Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach](https://arxiv.org/abs/2508.21206)
*Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl*

Main category: cs.CL

TL;DR: 语言模型容易受到拼写攻击，会导致性能下降。我们提出了一种基于像素的生成语言模型，将单词渲染成图像，以提高对噪声输入的鲁棒性和对多语言文本的兼容性。


<details>
  <summary>Details</summary>
Motivation: 由于子词分词器及其嵌入中固有出的词汇外问题，自回归语言模型容易受到拼写攻击。

Method: 提出了一种基于像素的生成语言模型，用基于像素的表示替换基于文本的嵌入，将单词渲染成单个图像。

Result: 在多语言LAMBADA数据集、WMT24数据集和SST-2基准上进行了评估，证明了其对拼写噪声的抵抗力和在多语言环境下的有效性。

Conclusion: 所提出的基于像素的生成语言模型在鲁棒性和多语言兼容性方面优于传统方法。

Abstract: Autoregressive language models are vulnerable to orthographic attacks, where
input text is perturbed with characters from multilingual alphabets, leading to
substantial performance degradation. This vulnerability primarily stems from
the out-of-vocabulary issue inherent in subword tokenizers and their
embeddings. To address this limitation, we propose a pixel-based generative
language model that replaces the text-based embeddings with pixel-based
representations by rendering words as individual images. This design provides
stronger robustness to noisy inputs, while an extension of compatibility to
multilingual text across diverse writing systems. We evaluate the proposed
method on the multilingual LAMBADA dataset, WMT24 dataset and the SST-2
benchmark, demonstrating both its resilience to orthographic noise and its
effectiveness in multilingual settings.

</details>


### [72] [Do Self-Supervised Speech Models Exhibit the Critical Period Effects in Language Acquisition?](https://arxiv.org/abs/2508.21210)
*Yurie Koga,Shunsuke Kando,Yusuke Miyao*

Main category: cs.CL

TL;DR: 该研究探讨了人类语言习得中的关键期（CP）效应是否在自监督语音模型（S3Ms）中有所体现，但发现S3Ms在语音方面并未表现出明显的CP效应。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要集中在文本语言模型中的CP效应，而忽略了语音模型，尽管语音在人类语言习得中至关重要。本研究旨在填补这一空白，探究S3Ms是否也存在CP效应。

Method: 通过在不同二语（L2）训练起始点和一语（L1）训练偏移点下训练S3Ms，并评估其语音辨别能力。

Result: 研究发现S3Ms在语音习得方面并未表现出明显的CP效应。值得注意的是，延迟L2暴露的模型在L2任务上表现更好，而延迟L1暴露则会导致L1遗忘。

Conclusion: S3Ms在语音习得方面并未表现出与人类相似的关键期效应。然而，实验结果显示，模型对训练时间的敏感性仍然存在，延迟的L2暴露反而能提升模型在L2任务上的表现，而延迟的L1暴露则会导致模型遗忘L1。

Abstract: This paper investigates whether the Critical Period (CP) effects in human
language acquisition are observed in self-supervised speech models (S3Ms). CP
effects refer to greater difficulty in acquiring a second language (L2) with
delayed L2 exposure onset, and greater retention of their first language (L1)
with delayed L1 exposure offset. While previous work has studied these effects
using textual language models, their presence in speech models remains
underexplored despite the central role of spoken language in human language
acquisition. We train S3Ms with varying L2 training onsets and L1 training
offsets on child-directed speech and evaluate their phone discrimination
performance. We find that S3Ms do not exhibit clear evidence of either CP
effects in terms of phonological acquisition. Notably, models with delayed L2
exposure onset tend to perform better on L2 and delayed L1 exposure offset
leads to L1 forgetting.

</details>


### [73] [Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection](https://arxiv.org/abs/2508.21228)
*Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin*

Main category: cs.CL

TL;DR: LLMs擅长内容生成但容易产生幻觉，现有方法存在局限性。本文提出了一种名为DMP的新方法，通过选择性推理和退火解码来提高多响应生成的效率，可实现高达3倍的加速，且不影响AUROC性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成内容时容易产生幻觉的问题，并提高现有自洽性方法的效率，降低其高昂的计算成本。

Method: 提出了一种名为解码记忆管道（DMP）的新方法，该方法通过识别自洽性方法中的冗余（共享前缀标记）来加速生成过程，具体措施包括选择性推理和退火解码。

Result: 实验证明，DMP方法在不牺牲AUROC性能的情况下，能够实现高达3倍的加速，提高了多响应生成的效率。

Conclusion: DMP是一种能够有效提高LLM多响应生成效率的新方法，具有广泛的应用前景，可扩展至对齐和推理任务。

Abstract: Large language models (LLMs) have demonstrated impressive performance in both
research and real-world applications, but they still struggle with
hallucination. Existing hallucination detection methods often perform poorly on
sentence-level generation or rely heavily on domain-specific knowledge. While
self-consistency approaches help address these limitations, they incur high
computational costs due to repeated generation. In this paper, we conduct the
first study on identifying redundancy in self-consistency methods, manifested
as shared prefix tokens across generations, and observe that non-exact-answer
tokens contribute minimally to the semantic content. Based on these insights,
we propose a novel Decoding Memory Pipeline (DMP) that accelerates generation
through selective inference and annealed decoding. Being orthogonal to the
model, dataset, decoding strategy, and self-consistency baseline, our DMP
consistently improves the efficiency of multi-response generation and holds
promise for extension to alignment and reasoning tasks. Extensive experiments
show that our method achieves up to a 3x speedup without sacrificing AUROC
performance.

</details>


### [74] [Efficient Code Embeddings from Code Generation Models](https://arxiv.org/abs/2508.21290)
*Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: jina-code-embeddings是一个用于代码检索、问答和跨语言代码相似性识别的新型代码嵌入模型套件，采用在文本和代码上预训练的自回归骨干网络，通过 last-token pooling 生成嵌入，模型虽小但性能优越。


<details>
  <summary>Details</summary>
Motivation: jina-code-embeddings旨在解决代码检索、技术问答以及跨语言代码相似性识别等问题。

Method: jina-code-embeddings模型采用自回归骨干网络，并在文本和代码上进行预训练，通过last-token pooling生成代码嵌入。

Result: jina-code-embeddings模型在代码检索、问答和相似性识别任务中取得了先进的性能，证明了该方法在代码嵌入模型构建上的有效性。

Conclusion: jina-code-embeddings模型展示了一种有效的代码嵌入模型构建方法，即使模型规模相对较小，也能在多项任务中取得优越的性能。

Abstract: jina-code-embeddings is a novel code embedding model suite designed to
retrieve code from natural language queries, perform technical
question-answering, and identify semantically similar code snippets across
programming languages. It makes innovative use of an autoregressive backbone
pre-trained on both text and code, generating embeddings via last-token
pooling. We outline the training recipe and demonstrate state-of-the-art
performance despite the relatively small size of the models, validating this
approach to code embedding model construction.

</details>


### [75] [BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning](https://arxiv.org/abs/2508.21294)
*João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida*

Main category: cs.CL

TL;DR: BLUEX数据集更新，加入2024-2025考试和AI生成的图像描述，提升了其在LLM预训练数据污染研究中的相关性，并评估了LLM利用图像描述信息的能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）能力的增长，尤其是在多语言和非英语环境中，对强大的评估方法的需求日益增长。

Method: 更新BLUEX数据集，包含2024-2025考试和自动生成的图像描述，并评估了商业和开源LLM利用图像描述的能力。

Result: 数据集中包含1,422个可用问题，数量翻倍，并且通过图像描述策略，使文本到文本模型的可用性提高了40%以上。

Conclusion: 评估结果表明LLM能够利用图像描述中的视觉背景信息。

Abstract: With the growing capabilities of Large Language Models (LLMs), there is an
increasing need for robust evaluation methods, especially in multilingual and
non-English contexts. We present an updated version of the BLUEX dataset, now
including 2024-2025 exams and automatically generated image captions using
state-of-the-art models, enhancing its relevance for data contamination studies
in LLM pretraining. Captioning strategies increase accessibility to text-only
models by more than 40%, producing 1,422 usable questions, more than doubling
the number in the original BLUEX. We evaluated commercial and open-source LLMs
and their ability to leverage visual context through captions.

</details>


### [76] [Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models](https://arxiv.org/abs/2508.21377)
*Shubham Sharma,Sneha Tuli,Narendra Badam*

Main category: cs.CL

TL;DR: LLMs 发展和部署复杂，本文调查了构建和使用 LLM 的 16 个关键挑战，并比较了 GPT-4o 和 DeepSeek-V3-0324 这两个模型。通过比较，我们展示了闭源模型（如 GPT-4o）和开源模型（如 DeepSeek-V3-0324）之间的权衡，例如闭源模型的安全性和可靠性，以及开源模型的效率和适应性。此外，文章还探讨了 LLM 在不同领域的应用，并指出了最适合每个用例的模型属性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在帮助 AI 研究人员、开发人员和决策者了解当前 LLM 的功能、局限性和最佳实践，重点关注 LLM 的开发和部署挑战。

Method: 通过比较 OpenAI 的闭源 GPT-4o 和 DeepSeek-V3-0324（一个开源的 Mixture-of-Experts 模型），调查了构建和使用 LLM 的 16 个关键挑战，并展示了闭源和开源模型之间的权衡，同时探讨了 LLM 在不同领域的应用。

Result: 通过对 GPT-4o 和 DeepSeek-V3-0324 的比较，展示了闭源模型（如 GPT-4o）在安全性和可靠性方面的优势，以及开源模型（如 DeepSeek-V3-0324）在效率和适应性方面的优势。文章还强调了不同模型属性如何适用于不同的 LLM 应用领域。

Conclusion: LLM 的发展和应用面临着诸多挑战，闭源和开源模型各有优劣。选择哪种模型取决于具体的应用场景和需求，需要权衡其在安全性、可靠性、效率和适应性等方面的权衡。

Abstract: Large Language Models (LLMs) are transforming AI across industries, but their
development and deployment remain complex. This survey reviews 16 key
challenges in building and using LLMs and examines how these challenges are
addressed by two state-of-the-art models with unique approaches: OpenAI's
closed source GPT-4o (May 2024 update) and DeepSeek-V3-0324 (March 2025), a
large open source Mixture-of-Experts model. Through this comparison, we
showcase the trade-offs between closed source models (robust safety, fine-tuned
reliability) and open source models (efficiency, adaptability). We also explore
LLM applications across different domains (from chatbots and coding tools to
healthcare and education), highlighting which model attributes are best suited
for each use case. This article aims to guide AI researchers, developers, and
decision-makers in understanding current LLM capabilities, limitations, and
best practices.

</details>


### [77] [Normality and the Turing Test](https://arxiv.org/abs/2508.21382)
*Alexandre Kabbach*

Main category: cs.CL

TL;DR: 本篇论文重新审视了图灵测试，提出了“常态”的概念。论文认为，常态在规范和数学意义上的统计解释对于理解图灵测试很有用：图灵测试旨在评估人类的常态/平均智能，而非异常智能，因此机器需要展现出像普通人类一样的“错误”和不完美的行为才能通过测试。同时，图灵测试是一种统计测试，评估由多个非专业“平均”法官组成的陪审团的集体判断，而非单一法官。因此，“平均人类审问者”应被理解为由多个法官的归一化聚合而成的数学抽象。


<details>
  <summary>Details</summary>
Motivation: 本篇论文旨在通过引入“常态”概念来重新审视图灵测试，并探讨其在评估人工智能方面的局限性。

Method: 论文从统计学的角度分析了图灵测试，将“常态”理解为规范和数学意义上的平均值，并以此解释了图灵测试如何评估机器的“平均”智能以及“平均人类审问者”的概念。

Result: 论文认为，像ChatGPT这样的大型语言模型可能难以通过图灵测试，因为它们倾向于模拟异常智能而非常态智能，这更像是“人工智能”而非“人工智能”。此外，图灵测试能否促进对人类认知 的理解，取决于人类心智是否能被简化为“常态/平均心智”，这涉及到对常态主义范式的概念性质疑。

Conclusion: 1. 像ChatGPT这样的大型语言模型可能因为追求异常智能而难以通过图灵测试，它们更像是“人工智能”的体现。 2. 图灵测试能否促进对人类认知的理解，关键在于人类心智是否能被简化为“常态/平均心智”，这涉及到对支撑图灵测试的常态主义范式的质疑。

Abstract: This paper proposes to revisit the Turing test through the concept of
normality. Its core argument is that the statistical interpretation of the
normal--understood as the average both in the normative and mathematical sense
of the term--proves useful for understanding the Turing test in at least two
ways. First, in the sense that the Turing test targets normal/average rather
than exceptional human intelligence, so that successfully passing the test
requires building machines that "make mistakes" and display imperfect behavior
just like normal/average humans. Second, in the sense that the Turing test is a
statistical test where judgments of intelligence are never carried out by a
single "average" judge (understood as non-expert) but always by a full jury. As
such, the notion of "average human interrogator" that Turing talks about in his
original paper should be understood primarily as referring to a mathematical
abstraction made of the normalized aggregate of individual judgments of
multiple judges. In short, this paper argues that the Turing test is a test of
normal intelligence as assessed by a normal judge characterizing the average
judgment of a pool of human interrogators. Its conclusions are twofold. First,
it argues that large language models such as ChatGPT are unlikely to pass the
Turing test as those models precisely target exceptional rather than
normal/average human intelligence. As such, they constitute models of what it
proposes to call artificial smartness rather than artificial intelligence per
se. Second, it argues that the core question of whether the Turing test can
contribute anything to the understanding of human cognition is that of whether
the human mind is really reducible to the normal/average mind--a question which
largely extends beyond the Turing test itself and questions the conceptual
underpinnings of the normalist paradigm it belongs to.

</details>


### [78] [AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume](https://arxiv.org/abs/2508.21389)
*Tanguy Herserant,Vincent Guigue*

Main category: cs.CL

TL;DR: 本研究旨在解决自动文本摘要评估中的可复现性挑战，通过对比ROUGE到G-Eval、SEval-Ex等六种评估指标，揭示了文献报道与实验结果之间的显著差异。研究提出了一个统一的开源框架，用于SummEval数据集，以支持评估指标的公平透明比较。结果表明，与人类判断一致性最高的指标往往计算成本高且稳定性差。此外，研究强调了依赖LLM进行评估的潜在问题，如随机性、技术依赖和可复现性有限，并提倡采用更严格的评估协议，包括详尽的文档和方法标准化，以提高自动摘要评估的可靠性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决自动文本摘要评估中的可复现性挑战，并揭示不同评估指标（从经典方法到基于LLM的方法）之间的性能差异。

Method: 通过在SummEval数据集上应用一个统一的、开源的框架，对六种代表性评估指标（包括ROUGE、G-Eval、SEval-Ex等）进行实验和比较分析。

Result: 研究发现，与人类判断一致性最高的指标往往计算成本高且稳定性差，并且基于LLM的评估方法存在随机性、技术依赖和可复现性有限等问题。

Conclusion: 为了确保自动文本摘要评估的可靠性，研究提倡采用更严格的评估协议，包括详尽的文档和方法标准化，并对过度依赖LLM进行评估提出警告。

Abstract: This paper investigates reproducibility challenges in automatic text
summarization evaluation. Based on experiments conducted across six
representative metrics ranging from classical approaches like ROUGE to recent
LLM-based methods (G-Eval, SEval-Ex), we highlight significant discrepancies
between reported performances in the literature and those observed in our
experimental setting. We introduce a unified, open-source framework, applied to
the SummEval dataset and designed to support fair and transparent comparison of
evaluation metrics. Our results reveal a structural trade-off: metrics with the
highest alignment with human judgments tend to be computationally intensive and
less stable across runs. Beyond comparative analysis, this study highlights key
concerns about relying on LLMs for evaluation, stressing their randomness,
technical dependencies, and limited reproducibility. We advocate for more
robust evaluation protocols including exhaustive documentation and
methodological standardization to ensure greater reliability in automatic
summarization assessment.

</details>


### [79] [Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework](https://arxiv.org/abs/2508.21422)
*Nils Dycke,Iryna Gurevych*

Main category: cs.CL

TL;DR: LLMs are being used as automatic peer reviewers (ARGs), but biases and errors pose risks to scientific integrity. This paper evaluates ARGs' ability to detect faulty research logic (inconsistencies between results, interpretations, and claims) using a counterfactual evaluation framework. Contrary to expectations, current ARGs are not significantly affected by such flaws. The paper offers recommendations and releases its dataset and framework.


<details>
  <summary>Details</summary>
Motivation: To understand the capabilities and limitations of automatic research-generated (ARG) approaches in scholarly peer review, specifically their ability to detect faulty research logic, due to concerns about potential biases and systematic errors that could compromise scientific integrity.

Method: Developed a fully automated counterfactual evaluation framework to isolate and test the skill of detecting faulty research logic (internal consistency between a paper's results, interpretations, and claims) in ARG approaches under controlled conditions.

Result: Testing a range of ARG approaches revealed that flaws in research logic had no significant effect on their output reviews, contrary to expectations.

Conclusion: Current ARGs are not effective at detecting faulty research logic. The paper provides three actionable recommendations for future work and makes its counterfactual dataset and evaluation framework publicly available.

Abstract: Large Language Models (LLMs) have great potential to accelerate and support
scholarly peer review and are increasingly used as fully automatic review
generators (ARGs). However, potential biases and systematic errors may pose
significant risks to scientific integrity; understanding the specific
capabilities and limitations of state-of-the-art ARGs is essential. We focus on
a core reviewing skill that underpins high-quality peer review: detecting
faulty research logic. This involves evaluating the internal consistency
between a paper's results, interpretations, and claims. We present a fully
automated counterfactual evaluation framework that isolates and tests this
skill under controlled conditions. Testing a range of ARG approaches, we find
that, contrary to expectation, flaws in research logic have no significant
effect on their output reviews. Based on our findings, we derive three
actionable recommendations for future work and release our counterfactual
dataset and evaluation framework publicly.

</details>


### [80] [Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.21430)
*Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen*

Main category: cs.CL

TL;DR: 该论文提出了Med-RewardBench，一个专门用于评估医疗多模态大语言模型（MLLMs）的奖励模型（MRMs）和裁判的基准。该基准包含1026个专家注释的病例，涵盖13个器官系统和8个临床部门，并从六个关键维度进行评估。研究评估了32个现有MLLMs，发现它们在与专家判断对齐方面存在挑战，并开发了通过微调能显著提升性能的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基准未能满足医疗领域对MLLMs准确性、上下文敏感性和专业性对齐的要求，因此需要一个专门针对医疗奖励模型和裁判进行评估的基准。

Method: 提出了Med-RewardBench，一个包含1026个专家注释病例的多模态数据集，涵盖13个器官系统和8个临床部门。评估过程包括三个步骤，覆盖六个临床关键维度。同时，开发了通过微调能提升性能的基线模型。

Result: 评估了32个现有MLLMs，发现其输出与专家判断存在显著对齐挑战。通过微调开发的基线模型展示了显著的性能提升。

Conclusion: Med-RewardBench是首个用于评估医疗奖励模型和裁判的基准，揭示了当前MLLMs在医疗领域面临的挑战，并为未来研究提供了方向。

Abstract: Multimodal large language models (MLLMs) hold significant potential in
medical applications, including disease diagnosis and clinical decision-making.
However, these tasks require highly accurate, context-sensitive, and
professionally aligned responses, making reliable reward models and judges
critical. Despite their importance, medical reward models (MRMs) and judges
remain underexplored, with no dedicated benchmarks addressing clinical
requirements. Existing benchmarks focus on general MLLM capabilities or
evaluate models as solvers, neglecting essential evaluation dimensions like
diagnostic accuracy and clinical relevance. To address this, we introduce
Med-RewardBench, the first benchmark specifically designed to evaluate MRMs and
judges in medical scenarios. Med-RewardBench features a multimodal dataset
spanning 13 organ systems and 8 clinical departments, with 1,026
expert-annotated cases. A rigorous three-step process ensures high-quality
evaluation data across six clinically critical dimensions. We evaluate 32
state-of-the-art MLLMs, including open-source, proprietary, and
medical-specific models, revealing substantial challenges in aligning outputs
with expert judgment. Additionally, we develop baseline models that demonstrate
substantial performance improvements through fine-tuning.

</details>


### [81] [Discovering Semantic Subdimensions through Disentangled Conceptual Representations](https://arxiv.org/abs/2508.21436)
*Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong*

Main category: cs.CL

TL;DR: 该论文提出了一种新的框架，利用解纠缠连续语义表示模型（DCSRM）来识别和分析语义的子维度，并验证了其在神经层面的可信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义的语义维度，无法捕捉精细的概念区分，因此需要新的框架来研究粗粒度语义维度下的子维度。

Method: 提出DCSRM模型，将词嵌入分解为编码特定语义信息的子嵌入，并据此识别可解释的语义子维度。通过将这些子维度映射到大脑激活来评估其神经可信度。

Result: 识别出更精细、可解释的语义子维度，并发现语义维度根据不同原则构建，其中极性是其分解为子维度的关键因素。所识别子维度的神经相关性支持其认知和神经科学上的可信度。

Conclusion: 提出的DCSRM框架能够识别和分析精细的语义子维度，这些子维度具有认知和神经科学上的可信度，并且语义维度的结构受极性等因素影响。

Abstract: Understanding the core dimensions of conceptual semantics is fundamental to
uncovering how meaning is organized in language and the brain. Existing
approaches often rely on predefined semantic dimensions that offer only broad
representations, overlooking finer conceptual distinctions. This paper proposes
a novel framework to investigate the subdimensions underlying coarse-grained
semantic dimensions. Specifically, we introduce a Disentangled Continuous
Semantic Representation Model (DCSRM) that decomposes word embeddings from
large language models into multiple sub-embeddings, each encoding specific
semantic information. Using these sub-embeddings, we identify a set of
interpretable semantic subdimensions. To assess their neural plausibility, we
apply voxel-wise encoding models to map these subdimensions to brain
activation. Our work offers more fine-grained interpretable semantic
subdimensions of conceptual meaning. Further analyses reveal that semantic
dimensions are structured according to distinct principles, with polarity
emerging as a key factor driving their decomposition into subdimensions. The
neural correlates of the identified subdimensions support their cognitive and
neuroscientific plausibility.

</details>


### [82] [Beyond the Surface: Probing the Ideological Depth of Large Language Models](https://arxiv.org/abs/2508.21448)
*Shariar Kabir,Kevin Esterling,Yue Dong*

Main category: cs.CL

TL;DR: LLMs have varying degrees of 'ideological depth,' affecting their susceptibility to manipulation and revealing distinct internal political representations. Deeper models are more robust and have more abstract features, leading to logical reasoning shifts when altered, while shallower models tend to refuse.


<details>
  <summary>Details</summary>
Motivation: To understand the stability and depth of ideological leanings in LLMs, beyond superficial responses easily manipulated by prompt engineering.

Method: 1. Measured 'steerability' using instruction prompting and activation steering on two open-source LLMs. 2. Probed internal mechanisms using Sparse Autoencoders (SAEs).

Result: Models vary in steerability; some resist or refuse more, indicating entrenched ideology. Models with lower steerability have more distinct/abstract ideological features. One model had 7.3x more political features than a similar-sized model. Ablating a core political feature in 'deep' models caused logical shifts, while in 'shallow' models it increased refusals.

Conclusion: Ideological depth is a quantifiable property of LLMs, and steerability is a useful indicator of their latent political architecture.

Abstract: Large Language Models (LLMs) have demonstrated pronounced ideological
leanings, yet the stability and depth of these positions remain poorly
understood. Surface-level responses can often be manipulated through simple
prompt engineering, calling into question whether they reflect a coherent
underlying ideology. This paper investigates the concept of "ideological depth"
in LLMs, defined as the robustness and complexity of their internal political
representations. We employ a dual approach: first, we measure the
"steerability" of two well-known open-source LLMs using instruction prompting
and activation steering. We find that while some models can easily switch
between liberal and conservative viewpoints, others exhibit resistance or an
increased rate of refusal, suggesting a more entrenched ideological structure.
Second, we probe the internal mechanisms of these models using Sparse
Autoencoders (SAEs). Preliminary analysis reveals that models with lower
steerability possess more distinct and abstract ideological features. Our
evaluations reveal that one model can contain 7.3x more political features than
another model of similar size. This allows targeted ablation of a core
political feature in an ideologically "deep" model, leading to consistent,
logical shifts in its reasoning across related topics, whereas the same
intervention in a "shallow" model results in an increase in refusal outputs.
Our findings suggest that ideological depth is a quantifiable property of LLMs
and that steerability serves as a valuable window into their latent political
architecture.

</details>


### [83] [Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards](https://arxiv.org/abs/2508.21476)
*Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.CL

TL;DR: 本研究提出两种AI驱动的奖励策略，通过RLAIF框架提升小语言模型（SLM）在中文问候语生成方面的创造力。其中，基于原则的LLM-as-a-Judge策略表现更优，提高了生成质量、训练效率，并减少了对人类标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）计算需求大，小型语言模型（SLMs）的增强是替代方案，但监督微调（SFT）缺乏新颖性，人类反馈强化学习（RLHF）成本高。需要更有效的方法来提升SLMs的创造力，尤其是在特定任务（如中文问候语生成）上。

Method: 本研究探索了两种AI驱动的奖励策略，应用于RLAIF框架，以提升一个7B参数SLM生成中文问候语的创造力。策略一：使用在由多智能体拒绝采样框架生成的偏好数据上训练的奖励模型（RM）。策略二：使用一个原则引导的LLM-as-a-Judge，通过对抗性训练和反思机制优化其奖励函数，直接提供奖励信号。并通过自动评估方法验证了其与人类判断的一致性。

Result: 两种策略均显著提升了SLM的创造性输出。原则引导的LLM-as-a-Judge策略在生成质量上表现更优，并且在训练效率和减少对人类标注数据依赖方面具有显著优势，更具可扩展性和有效性。

Conclusion: 原则引导的LLM-as-a-Judge策略是提升SLMs创造力的更优选择，为开发更具创造性的SLMs提供了更有效和可扩展的途径。自动评估方法与人类判断高度一致。

Abstract: Large Language Models (LLMs) have demonstrated remarkable creative writing
capabilities, yet their substantial computational demands hinder widespread
use. Enhancing Small Language Models (SLMs) offers a promising alternative, but
current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and
Reinforcement Learning from Human Feedback (RLHF) is costly. This paper
explores two distinct AI-driven reward strategies within a Reinforcement
Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a
7B-parameter SLM, specifically for generating Chinese greetings. The first
strategy employs a RM trained on high-quality preference data curated by a
novel multi-agent rejection sampling framework designed for creative tasks. The
second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose
reward function is optimized via an adversarial training scheme with a
reflection mechanism, to directly provide reward signals. Comprehensive
experiments reveal that while both approaches significantly enhance creative
output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields
superior generation quality. Furthermore, it offers notable advantages in
training efficiency and reduced dependency on human-annotated data, presenting
a more scalable and effective path towards creative SLMs. Our automated
evaluation methods also exhibit strong alignment with human judgments. Our code
and data are publicly available at
https://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models.

</details>


### [84] [HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble](https://arxiv.org/abs/2508.21482)
*Sara B. Coutinho,Rafael M. O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti*

Main category: cs.CL

TL;DR: 该研究提出了一种新的自动分类器选择方法，通过优先考虑多样性并结合性能来构建更有效的集成模型，以应对假新闻传播问题。


<details>
  <summary>Details</summary>
Motivation: 个人心理偏见（如确认偏见）导致人们在社交媒体上传播虚假信息，对公共卫生和政治等领域产生严重后果。基于机器学习的事实核查系统被广泛研究来解决这个问题，其中集成方法通过结合多个分类器来提高鲁棒性，但其性能严重依赖于构成分类器的多样性，而选择多样化的模型仍然是一个挑战。

Method: 提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性并结合性能。该方法首先计算分类器之间的成对多样性，并应用层次聚类将它们组织成不同粒度的组。然后，HierarchySelect 探索这些层次级别，为每个级别选择一个分类器池，每个池代表一个不同的池内多样性。从中识别并选择最多样化的池来构建集成。选择过程结合了反映每个分类器性能的评估指标，以确保集成具有良好的泛化能力。

Result: 在六个不同应用领域和不同类别数量的数据集上，使用 40 个异构分类器进行了实验。将所提出的方法与 Elbow 启发式方法和最先进的基线进行了比较。结果表明，该方法在六个数据集中的两个数据集上实现了最高的准确率。

Conclusion: 所提出的自动分类器选择方法在集成模型构建中优先考虑多样性和性能，并在事实核查任务中取得了具有竞争力的结果，在某些数据集上优于现有方法。

Abstract: Psychological biases, such as confirmation bias, make individuals
particularly vulnerable to believing and spreading fake news on social media,
leading to significant consequences in domains such as public health and
politics. Machine learning-based fact-checking systems have been widely studied
to mitigate this problem. Among them, ensemble methods are particularly
effective in combining multiple classifiers to improve robustness. However,
their performance heavily depends on the diversity of the constituent
classifiers-selecting genuinely diverse models remains a key challenge,
especially when models tend to learn redundant patterns. In this work, we
propose a novel automatic classifier selection approach that prioritizes
diversity, also extended by performance. The method first computes pairwise
diversity between classifiers and applies hierarchical clustering to organize
them into groups at different levels of granularity. A HierarchySelect then
explores these hierarchical levels to select one pool of classifiers per level,
each representing a distinct intra-pool diversity. The most diverse pool is
identified and selected for ensemble construction from these. The selection
process incorporates an evaluation metric reflecting each classifiers's
performance to ensure the ensemble also generalises well. We conduct
experiments with 40 heterogeneous classifiers across six datasets from
different application domains and with varying numbers of classes. Our method
is compared against the Elbow heuristic and state-of-the-art baselines. Results
show that our approach achieves the highest accuracy on two of six datasets.
The implementation details are available on the project's repository:
https://github.com/SaraBCoutinho/HSFN .

</details>


### [85] [L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models](https://arxiv.org/abs/2508.21569)
*Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文介绍了MahaSTS数据集和MahaSBERT-STS-v2模型，用于评估马拉地语句子间的文本相似度。


<details>
  <summary>Details</summary>
Motivation: 为了解决马拉地语在句子文本相似度（STS）任务上缺乏高质量标注数据集的问题。

Method: 创建了一个包含16,860个马拉地语句子对MahaSTS数据集，并将其均匀分布在0-5分的六个分数段中，以减少标签偏差。然后，使用MahaSBERT模型在该数据集上进行微调，并与MahaBERT、MuRIL、IndicBERT和IndicSBERT等模型进行性能比较。

Result: 实验表明，MahaSTS数据集能够有效训练句子相似度任务，并且微调后的MahaSBERT模型在评估中表现出色，证明了人类标注、定向微调和结构化监督在低资源环境下的重要性。

Conclusion: MahaSTS数据集和MahaSBERT-STS-v2模型为马拉地语的句子文本相似度研究提供了宝贵的资源。

Abstract: We present MahaSTS, a human-annotated Sentence Textual Similarity (STS)
dataset for Marathi, along with MahaSBERT-STS-v2, a fine-tuned Sentence-BERT
model optimized for regression-based similarity scoring. The MahaSTS dataset
consists of 16,860 Marathi sentence pairs labeled with continuous similarity
scores in the range of 0-5. To ensure balanced supervision, the dataset is
uniformly distributed across six score-based buckets spanning the full 0-5
range, thus reducing label bias and enhancing model stability. We fine-tune the
MahaSBERT model on this dataset and benchmark its performance against other
alternatives like MahaBERT, MuRIL, IndicBERT, and IndicSBERT. Our experiments
demonstrate that MahaSTS enables effective training for sentence similarity
tasks in Marathi, highlighting the impact of human-curated annotations,
targeted fine-tuning, and structured supervision in low-resource settings. The
dataset and model are publicly shared at
https://github.com/l3cube-pune/MarathiNLP

</details>


### [86] [A Survey on Current Trends and Recent Advances in Text Anonymization](https://arxiv.org/abs/2508.21587)
*Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa*

Main category: cs.CL

TL;DR: 现有文本匿名化技术综述，涵盖基于NER的方法、LLM的应用与威胁、特定领域挑战、高级方法、作者身份匿名化、评估框架及未来方向。


<details>
  <summary>Details</summary>
Motivation: 解决文本数据中敏感个人信息泄露问题，确保隐私合规和数据可用性。

Method: 概述基于NER的基础方法，探讨LLM在匿名化和去匿名化中的作用，分析医疗、法律、金融、教育等领域的特定挑战与解决方案，介绍包含形式化隐私模型和风险感知框架的高级方法，并综述作者身份匿名化、评估框架、度量标准、基准和工具。

Result: 总结了当前文本匿名化的知识，识别了新兴趋势和挑战，如隐私-效用权衡、拟标识符问题和LLM能力的影响。

Conclusion: 为学术界和从业者在文本匿名化领域提供了未来研究方向的指导。

Abstract: The proliferation of textual data containing sensitive personal information
across various domains requires robust anonymization techniques to protect
privacy and comply with regulations, while preserving data usability for
diverse and crucial downstream tasks. This survey provides a comprehensive
overview of current trends and recent advances in text anonymization
techniques. We begin by discussing foundational approaches, primarily centered
on Named Entity Recognition, before examining the transformative impact of
Large Language Models, detailing their dual role as sophisticated anonymizers
and potent de-anonymization threats. The survey further explores
domain-specific challenges and tailored solutions in critical sectors such as
healthcare, law, finance, and education. We investigate advanced methodologies
incorporating formal privacy models and risk-aware frameworks, and address the
specialized subfield of authorship anonymization. Additionally, we review
evaluation frameworks, comprehensive metrics, benchmarks, and practical
toolkits for real-world deployment of anonymization solutions. This review
consolidates current knowledge, identifies emerging trends and persistent
challenges, including the evolving privacy-utility trade-off, the need to
address quasi-identifiers, and the implications of LLM capabilities, and aims
to guide future research directions for both academics and practitioners in
this field.

</details>


### [87] [Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning](https://arxiv.org/abs/2508.21589)
*Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: Middo是一个模型驱动的动态数据优化框架，通过模型感知的数据选择和保留上下文的数据精炼来改进LLM的训练数据，从而提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）大型语言模型（LLM）的性能很大程度上取决于高质量的训练数据。现有的数据选择和合成方法在静态数据集 curation 方面存在局限性，无法适应不断变化的LLM能力。

Method: Middo框架包含一个自诊断模块，通过损失模式（复杂度）、嵌入聚类动态（多样性）和自我对齐分数（质量）这三个模型信号来识别欠佳的样本。一个自适应优化引擎将这些欠佳样本转化为有教学价值的训练点，同时保持语义完整性。该优化过程通过动态学习原则与模型能力一起持续演变。

Result: 实验表明，Middo框架在多个基准测试上持续提高了种子数据的质量，并将LLM的性能平均提高了7.15%的准确率，同时保持了原始数据集的规模。

Conclusion: Middo框架通过动态的人工智能-模型协同演进数据和模型，为可持续的LLM训练建立了一个新范例。

Abstract: Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely
on high-quality training data. While data selection and data synthesis are two
common strategies to improve data quality, existing approaches often face
limitations in static dataset curation that fail to adapt to evolving model
capabilities. In this paper, we introduce Middo, a self-evolving Model-informed
dynamic data optimization framework that uses model-aware data selection and
context-preserving data refinement. Unlike conventional one-off
filtering/synthesis methods, our framework establishes a closed-loop
optimization system: (1) A self-referential diagnostic module proactively
identifies suboptimal samples through tri-axial model signals - loss patterns
(complexity), embedding cluster dynamics (diversity), and self-alignment scores
(quality); (2) An adaptive optimization engine then transforms suboptimal
samples into pedagogically valuable training points while preserving semantic
integrity; (3) This optimization process continuously evolves with model
capability through dynamic learning principles. Experiments on multiple
benchmarks demonstrate that our \method consistently enhances the quality of
seed data and boosts LLM's performance with improving accuracy by 7.15% on
average while maintaining the original dataset scale. This work establishes a
new paradigm for sustainable LLM training through dynamic human-AI co-evolution
of data and models. Our datasets, models, and code are coming soon.

</details>


### [88] [Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks](https://arxiv.org/abs/2508.21628)
*Sarfaroz Yunusov,Kaige Chen,Kazi Nishat Anwar,Ali Emami*

Main category: cs.CL

TL;DR: 用户性格类型影响对GPT-4和Claude 3.5等大型语言模型的偏好，Rationals偏好GPT-4，Idealists偏好Claude 3.5。


<details>
  <summary>Details</summary>
Motivation: 探究不同用户性格类型是否会系统性地偏好某些大型语言模型（LLMs），以及这种偏好在多轮协作任务中的体现。

Method: 招募32名参与者，分为四种Keirsey性格类型，让他们在数据分析、创意写作、信息检索和写作辅助四项协作任务中与GPT-4和Claude 3.5进行交互，并通过情感分析定性反馈，最后比较不同性格类型在不同模型上的表现。

Result: Rationals性格类型用户显著偏好GPT-4，尤其是在目标导向型任务中；Idealists性格类型用户偏好Claude 3.5，尤其是在创意性和分析性任务中。其他性格类型用户则表现出任务依赖性偏好。总体有用性评级在两个模型间相似。

Conclusion: 用户性格特征是影响其对LLM偏好的重要因素，性格分析能够揭示传统评估方法可能忽略的LLM差异。

Abstract: As Large Language Models (LLMs) increasingly integrate into everyday
workflows, where users shape outcomes through multi-turn collaboration, a
critical question emerges: do users with different personality traits
systematically prefer certain LLMs over others? We conducted a study with 32
participants evenly distributed across four Keirsey personality types,
evaluating their interactions with GPT-4 and Claude 3.5 across four
collaborative tasks: data analysis, creative writing, information retrieval,
and writing assistance. Results revealed significant personality-driven
preferences: Rationals strongly preferred GPT-4, particularly for goal-oriented
tasks, while idealists favored Claude 3.5, especially for creative and
analytical tasks. Other personality types showed task-dependent preferences.
Sentiment analysis of qualitative feedback confirmed these patterns. Notably,
aggregate helpfulness ratings were similar across models, showing how
personality-based analysis reveals LLM differences that traditional evaluations
miss.

</details>


### [89] [QZhou-Embedding Technical Report](https://arxiv.org/abs/2508.21632)
*Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu*

Main category: cs.CL

TL;DR: QZhou-Embedding是一个基于Qwen2.5-7B-Instruct的通用文本嵌入模型，通过多任务框架、数据转换和两阶段训练策略，在MTEB和CMTEB基准测试中取得了最先进的成果，证明了高质量、多样化数据和LLM生成能力对提升嵌入模型性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 提出一个具有卓越文本表示能力的通用目的的上下文文本嵌入模型。

Method: 构建了一个统一的多任务框架，包括专门的数据转换和训练策略。数据转换方案允许整合更多样化的文本训练数据集，而特定任务的训练策略提高了模型学习效率。利用LLM API开发了一个数据合成流程，包括释义、增强和困难负例生成，以提高训练集的语义丰富度和样本难度。采用两阶段训练策略：首先进行检索相关的预训练，然后进行全任务微调。

Result: 在MTEB和CMTEB基准测试中取得了最先进的成果，并在截至2025年8月27日的排行榜上均排名第一。同时，在重排、聚类等任务上也取得了最先进的性能。

Conclusion: 更高质量、更多样化的数据对于提升检索模型的性能至关重要，并且利用LLM的生成能力可以进一步优化嵌入模型突破所需的数据质量。

Abstract: We present QZhou-Embedding, a general-purpose contextual text embedding model
with exceptional text representation capabilities. Built upon the
Qwen2.5-7B-Instruct foundation model, we designed a unified multi-task
framework comprising specialized data transformation and training strategies.
The data transformation scheme enables the incorporation of more diverse
textual training datasets, while the task-specific training strategies enhance
model learning efficiency. We developed a data synthesis pipeline leveraging
LLM API, incorporating techniques such as paraphrasing, augmentation, and hard
negative example generation to improve the semantic richness and sample
difficulty of the training set. Additionally, we employ a two-stage training
strategy, comprising initial retrieval-focused pretraining followed by
full-task fine-tuning, enabling the embedding model to extend its capabilities
based on robust retrieval performance. Our model achieves state-of-the-art
results on the MTEB and CMTEB benchmarks, ranking first on both leaderboards
(August 27 2025), and simultaneously achieves state-of-the-art performance on
tasks including reranking, clustering, etc. Our findings demonstrate that
higher-quality, more diverse data is crucial for advancing retrieval model
performance, and that leveraging LLMs generative capabilities can further
optimize data quality for embedding model breakthroughs. Our model weights are
released on HuggingFace under Apache 2.0 license. For reproducibility, we
provide evaluation code and instructions on GitHub.

</details>


### [90] [Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance](https://arxiv.org/abs/2508.21741)
*Yao Wang,Di Liang,Minlong Peng*

Main category: cs.CL

TL;DR: CPI-FT框架通过隔离和融合参数，解决了SFT中多任务学习的跷跷板现象和灾难性遗忘问题，在多个基准测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: SFT在适应LLM下游任务时存在“跷跷板现象”，即参数更新会牺牲某些任务的性能。

Method: CPI-FT框架首先独立微调LLM以识别核心参数区域，然后根据区域重叠度将任务分组；接着，将核心参数直接移植到统一骨干模型，并通过SLERP融合非核心参数；最后，在冻结核心参数的情况下，使用混合任务数据进行轻量级SFT训练，以防止灾难性遗忘。

Result: CPI-FT框架显著缓解了任务干扰和遗忘，在多个公开基准测试中持续优于标准的、多阶段微调基线。

Conclusion: CPI-FT框架成功解决了多任务微调中的关键挑战，为提高LLM在下游任务中的适应性提供了有效途径。

Abstract: Supervised fine-tuning (SFT) is a pivotal approach to adapting large language
models (LLMs) for downstream tasks; however, performance often suffers from the
``seesaw phenomenon'', where indiscriminate parameter updates yield progress on
certain tasks at the expense of others. To address this challenge, we propose a
novel \emph{Core Parameter Isolation Fine-Tuning} (CPI-FT) framework.
Specifically, we first independently fine-tune the LLM on each task to identify
its core parameter regions by quantifying parameter update magnitudes. Tasks
with similar core regions are then grouped based on region overlap, forming
clusters for joint modeling. We further introduce a parameter fusion technique:
for each task, core parameters from its individually fine-tuned model are
directly transplanted into a unified backbone, while non-core parameters from
different tasks are smoothly integrated via Spherical Linear Interpolation
(SLERP), mitigating destructive interference. A lightweight, pipelined SFT
training phase using mixed-task data is subsequently employed, while freezing
core regions from prior tasks to prevent catastrophic forgetting. Extensive
experiments on multiple public benchmarks demonstrate that our approach
significantly alleviates task interference and forgetting, consistently
outperforming vanilla multi-task and multi-stage fine-tuning baselines.

</details>


### [91] [Reasoning-Intensive Regression](https://arxiv.org/abs/2508.21762)
*Diane Tchuindjo,Omar Khattab*

Main category: cs.CL

TL;DR: LLMs在推理密集型回归（RiR）任务中表现不佳，提出MENTAT方法进行改进。


<details>
  <summary>Details</summary>
Motivation: RiR任务需要对文本进行更深层次的分析，但现有的LLMs在处理此类任务时，由于数据和计算资源的限制，表现不佳。

Method: MENTAT结合了批次反射式提示优化和神经集成学习。

Result: MENTAT在RiR任务上取得了最高65%的提升，但仍有改进空间。

Conclusion: 现有LLMs在RiR任务上存在局限性，MENTAT提供了一种有效的改进方法。

Abstract: AI researchers and practitioners increasingly apply large language models
(LLMs) to what we call reasoning-intensive regression (RiR), i.e. deducing
subtle numerical properties from text. Unlike standard language regression
tasks, e.g. for sentiment or similarity, RiR often appears instead in ad-hoc
problems like rubric-based scoring or domain-specific retrieval, where much
deeper analysis of text is required while only limited task-specific training
data and computation are available. We cast three realistic problems as RiR
tasks to establish an initial benchmark, and use that to test our hypothesis
that prompting frozen LLMs and finetuning Transformer encoders via gradient
descent will both often struggle in RiR. We then propose MENTAT, a simple and
lightweight method that combines batch-reflective prompt optimization with
neural ensemble learning. MENTAT achieves up to 65% improvement over both
baselines, though substantial room remains for future advances in RiR.

</details>


### [92] [PiCSAR: Probabilistic Confidence Selection And Ranking](https://arxiv.org/abs/2508.21787)
*Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen*

Main category: cs.CL

TL;DR: PiCSAR是一种无需训练的评分方法，通过联合考虑推理过程和最终答案的对数似然来提高LLM和LRM的准确性，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够识别正确推理链而无需地面真实答案的评分函数，以解决最佳n抽样在推理任务中的关键挑战。

Method: 提出概率置信度选择和排序（PiCSAR）方法，使用推理和最终答案的联合对数似然来为每个候选生成评分，该似然可以分解为推理置信度和答案置信度。

Result: PiCSAR在MATH500上提高了+10.18，在AIME2025上提高了+9.81，并且在20次比较中的16次中，使用少2倍的样本量就优于基线。

Conclusion: 正确的推理链表现出显著更高的推理和答案置信度，证明了PiCSAR的有效性。

Abstract: Best-of-n sampling improves the accuracy of large language models (LLMs) and
large reasoning models (LRMs) by generating multiple candidate solutions and
selecting the one with the highest reward. The key challenge for reasoning
tasks is designing a scoring function that can identify correct reasoning
chains without access to ground-truth answers. We propose Probabilistic
Confidence Selection And Ranking (PiCSAR): a simple, training-free method that
scores each candidate generation using the joint log-likelihood of the
reasoning and final answer. The joint log-likelihood of the reasoning and final
answer naturally decomposes into reasoning confidence and answer confidence.
PiCSAR achieves substantial gains across diverse benchmarks (+10.18 on MATH500,
+9.81 on AIME2025), outperforming baselines with at least 2x fewer samples in
16 out of 20 comparisons. Our analysis reveals that correct reasoning chains
exhibit significantly higher reasoning and answer confidence, justifying the
effectiveness of PiCSAR.

</details>


### [93] [Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval](https://arxiv.org/abs/2508.21788)
*Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy*

Main category: cs.CL

TL;DR: LLMs依赖Common Crawl等大规模数据集，但网络爬取的数据质量、安全和道德性存在挑战。本项目提出一个基于ElasticSearch的框架，用于索引和分析LLM训练数据集，并已应用于1.5TB的SwissAI FineWeb-2语料库，实现了毫秒级查询。该框架支持实时数据集分析，为构建更安全、更负责任的AI系统提供了工具。


<details>
  <summary>Details</summary>
Motivation: LLMs严重依赖网络规模的数据集，但这些数据集（如Common Crawl）的数据质量、安全性和道德性存在挑战。此前对有害内容的研究因计算限制而局限于小样本。

Method: 提出一个基于ElasticSearch的管道化框架，用于索引和分析LLM训练数据集。

Result: 将该框架应用于SwissAI的FineWeb-2语料库（1.5TB，四种语言），实现了快速的查询性能，大多数搜索在几毫秒内完成，所有搜索在2秒内完成。

Conclusion: 该框架实现了实时数据集分析，为构建更安全、更负责任的AI系统提供了实用的工具。

Abstract: Large language models (LLMs) rely heavily on web-scale datasets like Common
Crawl, which provides over 80\% of training data for some modern models.
However, the indiscriminate nature of web crawling raises challenges in data
quality, safety, and ethics. Despite the critical importance of training data
quality, prior research on harmful content has been limited to small samples
due to computational constraints. This project presents a framework for
indexing and analyzing LLM training datasets using an ElasticSearch-based
pipeline. We apply it to SwissAI's FineWeb-2 corpus (1.5TB, four languages),
achieving fast query performance--most searches in milliseconds, all under 2
seconds. Our work demonstrates real-time dataset analysis, offering practical
tools for safer, more accountable AI systems.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [94] [Phonon-scattering-induced quantum linear magnetoresistance up to room temperature](https://arxiv.org/abs/2508.21089)
*Nannan Tang,Shuai Li,Yanzhao Liu,Jiayi Yang,Huakun Zuo,Gangjian Jin,Yi Ji,Bing Shen,Dingyong Zhong,Donghui Guo,Qizhong Zhu,Zhongbo Yan,Haizhou Lu,Jian Wang,Huichao Wang*

Main category: cond-mat.mes-hall

TL;DR: 在高达 60 T 的强磁场下，在 40-300 K 的高温下，在韦尔森半导体碲中观察到量子线性磁阻效应。


<details>
  <summary>Details</summary>
Motivation: 实现高温下的量子输运效应，以揭示新的物理学和开发量子器件。

Method: 在 40-300 K 的温度范围内，在高达 60 T 的磁场下，测量了韦尔森半导体碲的量子线性磁阻。

Result: 在高温下观察到量子线性磁阻效应，这与之前的理论预测一致，并揭示了电子-声子相互作用在此现象中的关键作用。

Conclusion: 强磁场和高温为探索新的量子现象提供了一个有前景的平台，并填补了声子介导的量子极限物理学理解上的空白。

Abstract: The realization of quantum transport effects at elevated temperatures has
long intrigued researchers due to the implications for unveiling novel physics
and developing quantum devices. In this work, we report remarkable quantum
linear magnetoresistance (LMR) in the Weyl semiconductor tellurium at high
temperatures of 40-300 K under strong magnetic fields up to 60 T. At high
fields, the Weyl band features a large energy gap between the lowest and first
Landau levels, which suppresses thermal excitation and preserves Landau
quantization at high temperatures. The LMR is observed as long as majority
carriers remain in the lowest Landau level without requiring monochromaticity,
allowing it to persist up to room temperature. The inverse relationship between
the LMR slope and temperature provides clear evidence that quantum LMR
originates from high-temperature phonon scattering in the quantum limit,
firstly demonstrating a theoretical prediction made nearly fifty years ago.
This study highlights the key role of electron-phonon interaction and reveals
an innovative quantum mechanism for achieving high-temperature LMR,
fundamentally distinct from previous findings. Our results bridge a gap in the
understanding of phonon-mediated quantum-limit physics and establish strong
magnetic fields at high temperatures as a promising platform for exploring
novel quantum phenomena.

</details>


### [95] [Exploring Co, Fe, and Ni Reference Layers for Single-Pulse All-Optical Reversal in Ferromagnetic Spin Valves](https://arxiv.org/abs/2508.21234)
*Jun-Xiao Lin,Yann Le Guen,Julius Hohlfeld,Jon Gorchon,Grégory Malinowski,Stéphane Mangin,Daniel Lacour,Thomas Hauet,Michel Hehn*

Main category: cond-mat.mes-hall

TL;DR: 不同参考层材料（Co、Ni、Fe）会影响自旋阀中由飞秒激光脉冲引起的磁化翻转过程，其中Co参考层能够实现all-optical parallel-to-antiparallel开关，而Ni和Fe则不能。


<details>
  <summary>Details</summary>
Motivation: 探究单飞秒激光脉冲在不同铁磁参考层（Co、Ni、Fe）组成的自旋阀中的磁化翻转过程，并解释不同材料影响开关行为的原因。

Method: 系统比较了由纯Co、Ni、Fe组成的参考层，设计了具有平面磁化率的自旋阀以避免垂直磁各向异性的损失，并通过观察反平行到平行（A-P）和从平行到反平行（P-A）的开关行为来分析不同参考层材料的影响。

Result: 所有三种元素都观察到了从反平行到平行（A-P）的开关；只有Co参考层观察到了从平行到反平行（P-A）的开关，而Ni和Fe则没有观察到。

Conclusion: P-A开关需要参考层快速再磁化以产生与自由层磁化相反的负自旋流，这是触发其翻转的必要条件。Co参考层能够实现这一目标，而Ni和Fe则不能，这归因于它们不同的超快磁化动力学。

Abstract: We investigate the magnetization reversal process induced by a single
femtosecond laser pulse in ferromagnetic spin valves by systematically
comparing reference layers composed of pure Co, Ni, and Fe. To circumvent the
loss of perpendicular magnetic anisotropy associated with changes in reference
layer material and thickness, we design spin valves with in plane
magnetizations. While antiparallel to parallel switching is observed for all
three elements, parallel to antiparallel switching occurs only with a Co
reference layer and is absent with Ni and Fe. This difference is attributed to
the distinct ultrafast magnetization dynamics of the reference materials. Our
results support the hypothesis that parallel to antiparallel switching requires
a rapid remagnetization of the reference layer, which generates a substantial
negative spin current polarized opposite to the free layer magnetization an
essential condition for triggering its reversal.

</details>


### [96] [Remote spin control in Haldane spin chains](https://arxiv.org/abs/2508.21544)
*Y. del Castillo,A. Ferrón,J. Fernández-Rossier*

Main category: cond-mat.mes-hall

TL;DR: 通过操纵哈尔冰链的量子态，实现对链另一端磁性的远程控制。


<details>
  <summary>Details</summary>
Motivation: 研究如何远程操控哈尔冰链的边缘量子态，特别是利用一端的局部扰动来影响另一端的磁性。

Method: 推导了一个有效的四能级模型来描述局部磁化对局部扰动的响应，并利用该模型和Landau-Zener协议来展示如何通过一端的局部磁场控制另一端的磁化方向。

Result: 小局部场应用于链的一端可以引起另一端磁性的强变化，并且可以通过一端的局部磁场控制来实现另一端磁化方向的绝热开关。

Conclusion: 利用Landau-Zener协议，可以实现对链另一端磁化方向的远程精确控制。

Abstract: We consider the remote manipulation of the quantum state of the edge
fractional spins of Haldane spin chains using a weak local perturbation on the
other edge. We derive an effective four-level model that correctly captures the
response of the local magnetization to local perturbations and we use it to
show that applying a small local field on one edge of the chain induces a
strong variation of the magnetization on the opposite edge. Using a
Landau-Zener protocol, we show how local control of the field on one edge of
the chain, implemented for instance with a spin-polarized scanning tunnel
microscope tip, can adiabatically switch the magnetization direction on the
other side of the chain.

</details>


### [97] [Tapping-mode SQUID-on-tip Microscopy with Proximity Josephson Junctions](https://arxiv.org/abs/2508.21575)
*Matthijs Rog,Tycho J. Blom,Daan B. Boltje,Jimi D. de Haan,Remko Fermin,Jiasen Niu,Yasmin C. Doedes,Milan P. Allan,Kaveh Lahabi*

Main category: cond-mat.mes-hall

TL;DR: 基于SQUID的纳米探针技术可实现对量子材料和量子芯片制造中纳米尺度动力学的无损成像。


<details>
  <summary>Details</summary>
Motivation: 研究纳米尺度动力学对于理解量子材料和推进量子芯片制造至关重要，但测量非平衡性质（如电流和耗散）及其与结构的关系仍然是一个挑战。

Method: 提出了一种结合原子力显微镜（AFM）和纳米SQUID传感的“点击模式SQUID-on-tip”技术，该技术利用超导量子干涉仪（SQUID）的磁和热灵敏度，最小化了探针与样品的距离，提供了面内磁灵敏度，并且无需激光即可运行。通过频率复用，可以同时成像电流、磁性、耗散和形貌。其大电压输出使得在无需低温放大的情况下，仅用简单的四探针电子读出即可分辨低至100nA的纳米尺度电流。

Result: 该技术能够捕捉局部磁、热和电子响应，而无需外部辐射，实现了对量子材料和量子电路中动态现象的无损研究。

Conclusion: 点击模式SQUID-on-tip技术为研究量子材料和量子电路中的动态现象提供了一种强大的无损途径。

Abstract: Studying nanoscale dynamics is essential for understanding quantum materials
and advancing quantum chip manufacturing. Still, it remains a major challenge
to measure non-equilibrium properties such as current and dissipation, and
their relation to structure. Scanning nanoprobes utilizing superconducting
quantum interference devices (SQUIDs) are uniquely suited here, due to their
unparalleled magnetic and thermal sensitivity. Here, we introduce tapping-mode
SQUID-on-tip, which combines atomic force microscopy (AFM) with nanoSQUID
sensing. Our probes minimize nanoSQUID-sample distance, provide in-plane
magnetic sensitivity, and operate without lasers. Frequency multiplexing
enables simultaneous imaging of currents, magnetism, dissipation and
topography. The large voltage output of our proximity-junction nanoSQUIDs
allows us to resolve nanoscale currents as small as 100 nA using a simple
four-probe electronic readout without cryogenic amplification. By capturing
local magnetic, thermal, and electronic response without external radiation,
our technique offers a powerful non-invasive route to study dynamic phenomena
in exotic materials and delicate quantum circuits.

</details>


### [98] [High fidelity flopping-mode single spin operation with tuning inter-dot orbital levels](https://arxiv.org/abs/2508.21723)
*Yuta Matsumoto,Xiao-Fei Liu,Arne Ludwig,Andreas D. Wieck,Keisuke Koike,Takefumi Miyoshi,Takafumi Fujita,Akira Oiwa*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种在GaAs三量子点中通过调谐点间自旋-轨道耦合来优化Rabi频率和相干时间的方法，实现了超过100 MHz的Rabi频率和99.7%的π/2门保真度，为可扩展的高保真度半导体自旋量子比特操控提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 需要一种不依赖材料依赖性强自旋-轨道耦合和限制可扩展性的局部磁场梯度，同时优化Rabi频率和相干时间以实现高保真度操作的方法。

Method: 利用GaAs三量子点，通过第三个量子点精确控制轨道能级，调谐点间自旋-轨道耦合，并在优化的隧耦合下实现Rabi频率和相干时间的同步调优。结合基于机器学习的反馈控制来估计量子比特频率并缓解低频噪声的影响。

Result: 在GaAs三量子点中，实现了超过100 MHz的Rabi频率，同时通过调谐点间轨道能级维持了相干性。通过基于机器学习的反馈控制，有效缓解了低频噪声对量子比特相干性的影响。最终通过随机基准测试，实现了4 ns门时间的99.7%的π/2门保真度。

Conclusion: 该方法利用设备特定的参数（而非依赖材料特性或外部场梯度）实现了GaAs量子点中电子自旋的高保真度操控，即使在存在强超精细相互作用的情况下也能保持相干性，为半导体量子点阵列的可扩展高保真度自旋操控提供了可行的策略。

Abstract: Fast spin manipulation and long spin coherence time in quantum dots are
essential features for high fidelity semiconductor spin qubits. However,
generally it has not been well established how to optimize these two properties
simultaneously, because these two properties are usually not independent from
each other. Therefore, the scheme for high fidelity operation by simultaneous
tuning Rabi frequency and coherence time, which does not rely on the
material-dependent strong spin-orbit interaction and the local magnetic field
gradient limiting their scalability, are strongly demanded. Here, we
demonstrate an approach to achieve high-fidelity spin control by tuning
inter-dot spin-orbit coupling in a GaAs triple quantum dot (TQD), where the
third dot provides precise control over orbital energy levels. In an
electrically stable charge state with optimized tunnel coupling, we achieve
Rabi frequencies exceeding 100 MHz while maintaining coherence through proper
tuning of the inter-dot orbital levels of the TQD. By implementing a machine
learning-based feedback control that efficiently estimates qubit frequency
using past measurement data, we characterize and mitigate the impact of low
frequency noise on qubit coherence with minimal measurement overhead. Finally,
we demonstrate a $\pi$/2 gate fidelity of 99.7\% with a gate time of 4 ns
through randomized benchmarking, even in a GaAs quantum dot device where
electron spin coherence is typically limited by strong hyperfine interaction
with nuclear spins. Our approach provides a scalable strategy for high-fidelity
spin control in semiconductor quantum dot arrays by utilizing device-specific
parameters rather than relying on material properties or external field
gradients.

</details>


### [99] [Topological Magnon Frequency Combs](https://arxiv.org/abs/2508.21743)
*Zhixiong Li,Xuejuan Liu,Zhejunyu Jin,Guanghua Guo,Xingen Zheng,Peng Yan*

Main category: cond-mat.mes-hall

TL;DR: 本研究在二维三角斯格明子晶格中理论上引入了拓扑磁 ريا子频率梳（MFC），该梳子源于手征边缘模式之间的非线性四磁 ريا子散射，并通过双频驱动激活，无需幅度阈值。


<details>
  <summary>Details</summary>
Motivation: 受光子学中拓扑频率梳实验演示的启发，探索拓扑物理与非线性动力学的协同作用，揭示物质的涌现态。

Method: 通过计算磁 ريا子能带的陈数来揭示鲁棒的手征边缘态。利用微磁模拟来验证预测。

Result: 发现了拓扑MFC源于手征边缘模式之间的非线性四磁 ريا子散射，梳子间隔可通过激发频率失谐进行调节。微磁模拟验证了理论预测。

Conclusion: 这项工作为利用MFC的抗缺陷磁 ريا子器件铺平了道路，并激发了对磁性系统中拓扑-非线性现象的研究。

Abstract: Exploring the synergy between topological physics and nonlinear dynamics
unveils profound insights into emergent states of matter. Inspired by recent
experimental demonstrations of topological frequency combs in photonics, we
theoretically introduce topological magnon frequency combs (MFCs) in a
two-dimensional triangular skyrmion lattice. Computing the Chern numbers of
magnon bands reveals robust chiral edge states. Strikingly, these topological
MFCs originate from nonlinear four-magnon scattering among the chiral edge
modes, activated by dual-frequency driving without an amplitude threshold. Comb
spacings are readily tunable through excitation frequency detuning.
Micromagnetic simulations validate our predictions with good concordance. This
work paves the way for defect-immune magnonic devices exploiting MFCs and
sparks investigations into topological-nonlinear phenomena in magnetic systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [100] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 该研究探讨了LLM的架构归纳偏见如何影响其在指导性对话中的认知行为，并提出了一种结合符号脚手架和短期记忆的机制，以促进其在苏格拉底式辅导中的适应性、结构化推理能力。通过对五个系统变体的控制消融实验，并使用专家设计的评分标准（涵盖脚手架、响应性、符号推理和对话记忆）来评估模型输出。研究采用了与认知基础评分标准一致的LLM评估框架，以实现早期实验中跨架构变体的可扩展、系统性比较。初步结果表明，完整系统优于基线变体，且移除记忆或符号结构会损害LLM的抽象、适应性探究和概念连续性等认知行为，证实了架构脚手架能有效塑造LLM的教学策略。


<details>
  <summary>Details</summary>
Motivation: 探究LLM的架构归纳偏见对指导性对话中认知行为的影响，并提出一种促进其适应性、结构化推理的机制。

Method: 引入一种结合符号脚手架和短期记忆的机制，并通过控制消融实验（五个系统变体）和LLM评估框架（基于专家设计的评分标准）进行评估。

Result: 完整系统优于基线变体，移除记忆或符号结构会损害LLM的抽象、适应性探究和概念连续性等认知行为。

Conclusion: 架构脚手架能有效塑造LLM的教学策略，支持一种处理层面的解释，即架构支架可以可靠地塑造LLM中出现的教学策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [101] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 该研究评估了基于图的检索增强生成（GraphRAG）在阿尔茨海默病领域的应用，并与标准LLM进行了比较，同时讨论了可追溯性问题。


<details>
  <summary>Details</summary>
Motivation: 评估GraphRAG在特定知识密集型领域（如阿尔茨海默病）的质量和可追溯性，以改进聊天机器人在科学研究中的应用。

Method: 构建包含50篇论文和70个专家问题的阿尔茨海默病数据库，构建GraphRAG知识库，使用GPT-4o作为LLM回答查询，并比较GraphRAG和标准GPT-4o的响应质量，同时评估多种RAG和GraphRAG系统的可追溯性。

Result: GraphRAG在阿尔茨海默病领域的响应质量和可追溯性得到了评估，并与标准GPT-4o模型进行了比较。

Conclusion: GraphRAG在阿尔茨海默病等知识密集型领域的应用潜力巨大，但仍需进一步研究以解决其局限性。该研究还提供了一个用于测试RAG和GraphRAG性能的易用界面。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [102] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [103] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO是一个利用LLM整合多种医学本体知识图谱的学习框架，通过双轴知识传播（层级内和层级间）来增强医学概念表征学习。


<details>
  <summary>Details</summary>
Motivation: 现有医学本体知识图谱的研究主要关注单一本体系统或孤立地整合多个本体系统，忽略了跨本体的联系，导致概念表征学习局限于本体内部关系。

Method: LINKO框架首先利用LLM通过包含概念描述和本体上下文的工程化提示，为本体概念嵌入提供检索增强初始化。然后，通过双轴知识传播（1.本体内垂直传播，跨越层级；2.本体间水平传播，在每个层级内并行）联合学习不同本体图谱中的医学概念。

Result: LINKO在两个公开数据集上的广泛实验证明，其性能优于最先进的基线方法。作为可插入现有电子病历预测模型的编码器，LINKO在数据量有限和罕见病预测场景下也展现出更强的鲁棒性。

Conclusion: LINKO通过整合多源本体知识和利用LLM，有效克服了现有方法在概念表征学习中的局限性，并在实际应用中显示出优越的性能和鲁棒性。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [104] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: We created a multi-agent system (MAS) that mimics a clinical team to improve the accuracy of identifying clinical problems from patient notes. Our MAS, which uses specialist agents in a debate format, outperformed a single-agent system in detecting conditions like heart failure and sepsis.


<details>
  <summary>Details</summary>
Motivation: Clinical narrative interpretation is difficult for automation due to note complexity. Single LLMs lack the robustness needed for clinical tasks, so we developed a more robust system.

Method: A multi-agent system (MAS) was designed to simulate a clinical consultation team. A Manager agent assigns tasks to specialist agents who then debate and reach a consensus on identified clinical problems from the Subjective (S) and Objective (O) sections of SOAP notes. The system was tested on 420 MIMIC-III notes against a single-agent baseline.

Result: The MAS showed improved performance in identifying congestive heart failure, acute kidney injury, and sepsis compared to the single-agent baseline. Qualitative analysis showed the MAS effectively weighed conflicting evidence but was occasionally prone to groupthink.

Conclusion: The MAS, by simulating a clinical team's reasoning, offers a promising approach for developing more accurate, robust, and interpretable clinical decision support tools.

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>


### [105] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: LLMs擅长推理但难以处理简单互动任务，提出Think in Games (TiG)框架，通过游戏互动和语言模型学习来弥合声明知识和程序知识的差距，实现低数据、低计算需求并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: LLMs在数学和编程等复杂推理任务中表现出色，但在简单的互动任务中表现不佳，这表明了声明性知识和程序性知识之间的差距。传统的强化学习（RL）虽然能习得程序性知识，但通常是黑箱且需要大量数据。LLMs拥有丰富的世界知识和推理能力，但难以将其转化为动态决策能力。

Method: 提出Think in Games (TiG)框架，将RL决策重构为语言建模任务。LLMs生成语言指导的策略，并通过基于环境反馈的在线RL进行迭代优化。

Result: TiG成功弥合了声明性知识和程序性知识之间的差距，在数据和计算需求远低于传统RL方法的情况下，取得了有竞争力的性能。此外，TiG能够提供决策的逐步自然语言解释，提高了复杂互动任务的透明度和可解释性。

Conclusion: TiG框架通过让LLMs在游戏环境中进行直接互动来学习程序性知识，有效弥合了声明性知识和程序性知识的差距，并在保持LLM固有的推理和解释能力的同时，实现了更低的数据和计算需求，并提高了任务的可解释性。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [106] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM是一个评估音频-语言模型（ALMs）的综合基准，解决了现有基准的不足之处，通过标准化评估流程、引入新数据集（PARADE和CoRe-Bench）来全面衡量ALMs在10个关键方面的表现，并对17个模型进行了测试，结果显示Gemini 2.5 Pro在多项能力上表现优异，但也存在群体不公平性问题，同时基线系统表现也具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的音频-语言模型（ALMs）评估缺乏标准化基准，现有基准仅关注少数能力且忽略公平性、安全性等重要方面。不同评估方法和有限的模型比较也阻碍了跨模型对比。

Method: 引入AHELM基准，整合多个数据集，包括新合成的PARADE（评估避免刻板印象）和CoRe-Bench（评估对话音频推理）数据集。AHELM全面衡量ALMs在音频感知、知识、推理、情感检测、偏见、公平性、多语言、鲁棒性、毒性和安全性10个方面。标准化了提示、推理参数和评估指标，以确保公平比较。测试了14个ALMs和3个基线系统。

Result: 在10个方面中，Gemini 2.5 Pro在5个方面排名第一，但在ASR任务中存在群体不公平性（p=0.01）。基线系统表现良好，其中一个仅具备语音转文本能力的系统总体排名第五。

Conclusion: AHELM提供了一个全面的、标准化的评估框架，用于衡量ALMs的性能和安全性。测试结果揭示了当前ALMs的优势和劣势，包括模型性能的差异以及公平性等潜在问题。AHELM将持续更新，以适应ALM领域的快速发展。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [107] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: AI发展已从学术研究转向实际应用，面临多方面挑战。本文提出七层AI计算架构模型（物理层、链路层、神经网络层、上下文层、Agent层、编排层、应用层），并结合大型语言模型（LLMs）的三阶段演进解释该架构。文章详细阐述了各层的发展轨迹和关键技术，包括AI计算、Scale-Up/Scale-Out策略、LLMs发展路径、上下文记忆的影响、AI Agent演进趋势以及AI生态系统构建。此外，还探讨了AI发展的经济问题和行业预测。


<details>
  <summary>Details</summary>
Motivation: 随着AI发展从学术研究转向实际应用，需要分析其面临的机遇与挑战。

Method: 提出一个包含七个层次的AI计算架构模型，并分析了LLMs三阶段的演进如何形成该架构。逐层分析了各层次的发展轨迹、关键技术、面临的计算问题、Scale-Up和Scale-Out策略、上下文记忆的影响以及AI Agent到AI生态系统的演进趋势。同时，结合互联网行业分析了AI发展的经济问题和未来趋势。

Result: 提出了一个七层的AI计算架构模型，并详细分析了各层技术发展、挑战及LLMs的演进。探讨了AI Agent向AI生态系统的演变及其对产业的影响，并对AI未来发展轨迹进行了预测。

Conclusion: AI的发展既有技术挑战，也涉及经济问题，需要构建可持续发展的生态系统。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [108] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一个新工具，用于在CARLA中半自动生成和模拟具有交互式智能代理的城市交通场景。


<details>
  <summary>Details</summary>
Motivation: 用户友好的建模和不同类型交互代理（如行人、自行车和自动驾驶汽车）的城市交通场景虚拟模拟仍然是一个挑战。

Method: 提出CARJAN，一个基于多代理工程框架AJAN和驾驶模拟器CARLA的新工具。CARJAN提供了一个用于建模、存储和维护交通场景布局的视觉用户界面，并利用SPARQL行为树进行动态场景模拟中代理的决策制定和交互。

Result: CARJAN是CARLA中用于交互式、基于智能代理的生成和模拟虚拟交通场景的第一个集成方法。

Conclusion: CARJAN提供了一个集成的方法，用于在CARLA中创建和模拟复杂的城市交通场景，解决了用户友好建模和不同代理交互的挑战。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [109] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文研究在更丰富的认知状态下进行遗忘操作，提出五种遗忘类型和七种具体遗忘操作，并基于逻辑编程和AGM理论提出评估公理，全面分析了各种遗忘操作。


<details>
  <summary>Details</summary>
Motivation: 研究在认知状态下遗忘操作的含义，并将现有的和新颖的遗忘操作提升到认知层面。

Method: 提出五种一般的认知遗忘类型，并针对Spohn的排序函数具体化了七种遗忘操作，同时借鉴逻辑编程和AGM理论的遗忘公理来评估这些操作。

Result: 对所有具体遗忘操作根据所有公理进行了评估，提供了关于遗忘算子之间异同的全面概述。

Conclusion: 对遗忘操作进行了全面的评估，突出了不同遗忘算子之间的异同。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [110] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: This paper addresses the challenge of learning lifted STRIPS models for the sliding-tile puzzle from incomplete state-action traces. It introduces STRIPS+, a variant of STRIPS that handles implicit action arguments and existential quantification, and an algorithm called SYNTH to learn these models. The approach is shown to be correct, complete, and scalable.


<details>
  <summary>Details</summary>
Motivation: To address the realistic problem of learning lifted STRIPS models from incomplete state-action traces, where states and actions do not fully reveal all necessary information for traditional STRIPS modeling.

Method: Introduced STRIPS+, a variant of STRIPS that allows implicit action arguments and existential quantification in preconditions. Developed the SYNTH algorithm to learn STRIPS+ models by constructing stratified sequences of precondition expressions (queries) for each action, which ground implicit arguments.

Result: Established the correctness and completeness of the SYNTH algorithm. Tested its scalability using state-action traces generated from STRIPS+ models derived from existing STRIPS domains.

Conclusion: The proposed STRIPS+ framework and SYNTH algorithm provide a correct, complete, and scalable solution for learning lifted STRIPS models from realistic, incomplete state-action traces, overcoming limitations of previous approaches.

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [111] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个包含311个任务的基准测试，用于评估大型多模态语言模型（MLLMs）作为网络代理的能力，特别是在细粒度视觉推理、来源验证和长期工具使用方面。该基准测试通过引入需要从空间和时间线索中推断信息的任务，并模拟检索噪声，来解决现有基准测试中过于依赖浅层工作流程的问题。研究评估了多种MLLMs，并提出了一个包含浏览工具的模型无关代理框架。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLLMs）作为网络代理的基准测试，往往可以通过浅层、固定的工作流程解决，这些工作流程依赖于高召回率的图像搜索和文本掩蔽，从而掩盖了细粒度视觉推理、来源验证和长期工具使用等真正多模态的挑战。因此，有必要创建一个更能体现这些多模态挑战的基准测试。

Method: 研究人员引入了一个名为MMSearch-Plus的新基准测试，包含311个任务，旨在解决上述问题。该基准测试通过精心设计任务，要求模型提取、传播和交叉验证多个分散的视觉信号，并结合空间-时间外推（STE）方法，从空间线索（如微文本、部件外观、布局、标牌）和时间线索（如广播叠加、季节性背景）推断出图像外的factual信息（如事件、日期、地点）。此外，研究人员还提供了一个模型无关的代理框架，其中包含浏览工具，并评估了多种闭源和开源MLLMs。

Result: 在MMSearch-Plus基准测试中，最强的代理（o3）在没有搜索的情况下准确率为15.1%，在使用滚动（rollout）的情况下准确率为36.0%。一个强大的开源模型（Qwen-2.5-VL-72B-Instruct）在没有搜索的情况下准确率为0.0%，在经过20轮搜索后准确率为6.9%。除了答案准确性之外，研究还评估了边界框的生成和裁剪图像搜索，并通过错误分析揭示了在来源验证、基于部件的推理和长期规划方面的失败。

Conclusion: MMSearch-Plus基准测试成功地创建了一个更具挑战性的评估环境，能够真实地衡量MLLMs在细粒度视觉推理、来源验证和长期工具使用方面的多模态能力。现有模型在该基准测试上的表现仍有待提高，尤其是在处理检索噪声、进行部件级推理和规划长期任务方面。未来的研究需要关注如何改进这些方面的模型性能。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [112] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 本研究提出了一种基于Z数的模糊推理系统，用于量化和理解“智慧”这一复杂概念，并探索其在人工智能领域的应用。


<details>
  <summary>Details</summary>
Motivation: 现有智慧模型受限于二元思维，未能充分体现智慧的模糊性和不确定性，且多依赖自我报告。本研究旨在构建一个能考虑多维度和置信度的计算框架，以改进心理学测量并实现更人性化的人工智能。

Method: 开发了一个包含Z数的模糊推理系统，其中决策同时包含智慧得分（限制性）和置信度得分（确定性）。研究招募了100名参与者，让他们对文化中立的道德困境图片进行出声思维反应，并将这些反应映射到五个基于理论的智慧组成部分。通过21条规则和高斯核密度估计调整的隶属函数，将各个组成部分的得分进行结合。

Result: 在概念验证研究中，该系统生成的双属性智慧表示与已建立的量表存在适度但显著的相关性，同时与不相关的特质关系极小，支持了收敛效度和发散效度。

Conclusion: 本研究将智慧形式化为一个多维度、考虑不确定性的构造，并用Z数进行操作化。该研究不仅在心理学测量方面取得进展，还展示了模糊Z数如何为人工智能系统提供可解释、对置信度敏感的推理能力，在严谨计算和类似人类的判断之间找到了安全的中间地带。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [113] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新型解释范式，用于解释自动化规划问题。与仅关注修改计划的现有方法不同，该范式通过识别对规划问题本身的最小修改来满足特定的高级属性（由LTL公式定义）。研究表明，生成这些反事实场景在计算上是可行的，并且与规划问题的计算成本相当，为实际应用提供了框架。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释（CEs）方法主要关注如何最小化修改输入以改变模型输出，或者在规划领域如何最小化修改现有计划以满足不同目标。然而，这些方法未能捕捉到问题本身更高层次的属性。为了解决这一局限性，需要一种新的解释方法。

Method: 本文提出了一种基于反事实场景的新型解释范式。给定一个规划问题P和一个定义所需计划属性的LTL公式ψ，反事实场景旨在识别对P的最小修改，使得修改后的问题P'存在满足ψ的计划。文章提出了两种基于显式量化必须满足ψ的计划的定性反事实场景的实例化，并分析了允许对P进行不同类型更改时生成反事实场景的计算复杂度。

Result: 研究表明，生成反事实场景的计算成本通常与为P计算计划的成本相当，证明了该方法的实际可行性。

Conclusion: 本文提出的反事实场景解释范式能够捕捉规划问题的高级属性，并且在计算上是可行的，为在自动化规划领域构建实用的解释算法提供了基础。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [114] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI是一个集成了LLM的生成式AI框架，旨在通过简化流程挖掘在医疗保健和流行病学中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的流程挖掘技术在医疗保健领域面临技术复杂性、缺乏标准化方法和实践培训资源有限等挑战。

Method: HealthProcessAI集成了现有Python (PM4PY) 和R (bupaR) 库，并整合了多种大型语言模型（LLM）以实现自动化流程图解释和报告生成。

Result: 该框架成功处理了脓毒症进展数据，并能通过自动化LLM分析生成报告。在LLM评估中，Claude Sonnet-4和Gemini 2.5-Pro表现出最高的一致性。

Conclusion: HealthProcessAI通过集成多种LLM进行自动化解释和报告生成，降低了流程挖掘的门槛，提高了其在医疗保健领域的应用可及性，并在复杂流程挖掘结果转化为可操作见解方面取得了方法学进展。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [115] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 我们提出了一种新框架，用于发现可自动泛化到整个域的地标。这些泛化地标从一组已解决的实例中学习，并为传统地标提取算法效果不佳的规划问题描述中间目标。


<details>
  <summary>Details</summary>
Motivation: 传统地标提取算法在描述中间目标时存在不足，需要一种新的方法来处理规划问题。

Method: 我们提出了一个新框架，用于发现可自动泛化到整个域的地标。这些泛化地标通过使用独立于特定问题对象的状态函数来扩展域的谓词，适用于所有类似对象，从而捕获重复。我们基于这些函数构建了一个有向的泛化地标图，该图定义了地标进展，包括重复子计划的可能性。我们展示了如何在此图中使用启发式方法来解决同一域的新问题实例。

Result: 与其他方法相比，我们提出的方法在启发式性能上有了显著的提高，尤其是在识别出表示重复的循环时。此外，从少量实例中学到的泛化地标图对同一域中的较大实例也同样有效。

Conclusion: 我们提出的泛化地标可以从少量计划中发现，能够捕获人类可解释且对自动规划器有用的领域信息。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [116] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Det-Dec-POMDPs的确定性去中心化POMDP模型，并开发了一个名为IDPP的求解器，以有效解决大规模的机器人导航和路径规划等问题。


<details>
  <summary>Details</summary>
Motivation: 解决高层多智能体规划问题，特别是可以被建模为确定性动作和观测的领域，如多机器人导航和路径规划。

Method: 提出Det-Dec-POMDPs（确定性去中心化POMDPs）作为POMDP的一个子类，并开发了IDPP（迭代确定性POMDP规划）求解器，该求解器基于经典的联合均衡搜索策略框架，并针对大规模Det-Dec-POMDP进行了优化。

Result: IDPP能够有效地处理当前Dec-POMDP求解器无法高效解决的大规模Det-Dec-POMDP。

Conclusion: Det-Dec-POMDPs为解决确定性高层多智能体规划问题提供了一个有效的建模框架，而IDPP是该框架的一个实用求解器。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [117] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 本研究提出一个结合传统网络优化模型和大型语言模型（LLM）的集成框架，为供应链规划提供交互式、可解释且符合角色要求的决策支持。该系统通过生成自然语言摘要、上下文可视化和定制化关键绩效指标（KPI），弥合了复杂运筹学输出与业务利益相关者理解之间的差距。核心优化模型采用混合整数规划方法，解决多周期、多品项的配送中心网络库存重新分配问题。技术架构整合了AI代理、RESTful API和动态用户界面，支持实时交互、配置更新和基于仿真的洞察。案例研究表明，该系统通过防止缺货、降低成本和维持服务水平来改善规划结果。未来的扩展包括整合私有LLM、迁移学习、强化学习和贝叶斯神经网络，以增强可解释性、适应性和实时决策能力。


<details>
  <summary>Details</summary>
Motivation: 弥合复杂运筹学输出与业务利益相关者理解之间的差距，提供交互式、可解释且符合角色要求的供应链规划决策支持。

Method: 结合传统网络优化模型（混合整数规划）和大型语言模型（LLM），利用AI代理、RESTful API和动态用户界面实现。

Result: 通过案例研究证明，该系统能防止缺货、降低成本、维持服务水平，从而改善规划结果。

Conclusion: 提出的集成框架能够有效地为供应链规划提供改进的决策支持，并有潜力通过整合先进的AI技术进一步增强其能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [118] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 该论文提出了一种名为A-MHA*的算法，是MHA*算法的任意时间版本，可以快速找到可行次优解并持续改进，直至时间耗尽。该算法通过结合ARA*的思想，在保持MHA*的次优性和完备性保证的同时，实现了任意时间的功能。研究结果在3D路径规划和滑动拼图问题中得到了验证，并与MHA*及其他任意时间算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 原有的MHA*算法虽然利用多个不可靠启发式函数来加速次优解的生成，但无法随着时间的推移改进解决方案，并且需要仔细设置膨胀因子以获得期望的单次解决方案。本研究旨在解决这一问题。

Method: 通过将ARA*算法的概念精确地应用于MHA*框架，将MHA*扩展为一个任意时间版本（A-MHA*），实现了快速找到可行次优解并持续改进的功能。

Result: 在3D路径规划和滑动拼图问题中，A-MHA*算法在性能上得到了验证，并与MHA*及其他任意时间算法进行了比较。

Conclusion: A-MHA*算法成功地将MHA*扩展为任意时间版本，在保持原有保证的基础上，实现了任意时间的功能，并在实验中表现良好。

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [119] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY是一个框架，它不消除AI模型的偏见，而是利用它们。它保留了模型的多样化输出，并将潜在的偏见和幻觉作为提供给临床医生的信息，以提高透明度和信任度。


<details>
  <summary>Details</summary>
Motivation: 与消除偏见相反，人类的推理固有的偏见可能是有价值的。因此，作者提出了一种新的方法来处理医疗AI中的偏见。

Method: MEDLEY框架通过编排多个AI模型来协同工作，并保留它们的多样化输出，而不是将它们统一化。它记录模型特定的偏见，并将幻觉视为有待临床医生验证的临时假设。该概念验证使用了30多个大型语言模型。

Result: 概念验证成功地保留了共识和少数观点，并使诊断不确定性和潜在偏见对临床监督透明化。

Conclusion: MEDLEY通过将AI的不完美视为一种资源，提供了一种范式转变，为开发值得信赖的医疗AI系统开辟了新的途径。

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [120] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: PosterForest是一个新颖的、无需训练的框架，用于自动生成科学海报，它解决了现有方法忽视的科学文档层次结构和图文语义整合问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了科学文档的层次结构和图文元素的语义整合，因此需要一个能同时处理这两个挑战的新框架。

Method: 提出了一种名为“Poster Tree”的中间表示，它能联合编码多层次的文档结构和图文关系。采用了多智能体协作策略，由专门从事内容摘要和布局规划的智能体进行迭代协调和互评，以联合优化逻辑一致性、内容保真度和视觉连贯性。

Result: 在多个学术领域进行了广泛的实验，结果表明该方法在定性和定量评估中均优于现有方法，生成的海报在质量上最接近专家设计的基准，并在信息保留、结构清晰度和用户偏好方面表现更佳。

Conclusion: PosterForest通过引入“Poster Tree”和多智能体协作策略，成功实现了科学海报的自动化生成，并在多个评估维度上超越了现有技术。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [121] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 提出了一种用于旅行商问题（TSP）的变分算法，该算法结合了紧凑的排列编码和优化-冻结-重用策略，可在NISQ硬件上实现。


<details>
  <summary>Details</summary>
Motivation: 为旅行商问题（TSP）提供一种可在NISQ硬件上实现的变分算法。

Method: 提出了一种变分算法，结合了（i）一种紧凑的排列编码（减少了所需的量子比特数量），以及（ii）一种优化-冻结-重用策略（首先通过模拟退火（SA）在训练实例上优化电路拓扑（“Ansatz”），然后“冻结”并在新的实例上重用，仅对电路参数进行快速重新优化）。

Result: 在40个随机生成的对称实例（包含4-7个城市）上，对于4个城市的案例，平均最优行程采样概率为100%；对于5个城市的案例，为90%；对于6个城市的案例，为80%。对于7个城市的案例，成功率显著下降至平均约20%，表明了该方法可扩展性的限制。

Conclusion: 结果显示，该算法对于中等规模问题具有稳健的泛化能力，并且通过冻结Ansatz可以显著减少解决时间而不降低解决方案质量。论文还讨论了可扩展性限制、“热启动”参数初始化以及扩展到更复杂问题的可能性。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [122] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 本研究提出在已知时间序列数据的宏观因果图（SCG）信息下，对微观时间变量之间的因果关系进行定向的方法，即使存在宏观层面的循环或双向边。


<details>
  <summary>Details</summary>
Motivation: 在时间序列分析中，理解时间变量间的因果关系是一个核心挑战，尤其是在完整的因果结构未知的情况下。专家通常能够提供一个宏观因果图（SCG）作为背景知识，捕捉主要的因果关系。本研究旨在利用SCG指导微观因果关系的发现。

Method: 在假设存在一个忠实且因果充分的分布，并以SCG作为背景知识的前提下，推导保证微观层面边定向的条件。

Result: 本研究提出了理论保证，即使在宏观层面存在循环或双向边，也能实现微观层面的边定向。

Conclusion: 研究结果为利用SCG指导复杂时间序列系统的因果发现提供了实用的理论依据，并强调了结合专家知识以提升观测时间序列数据因果推断价值的重要性。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [123] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: TDP是一种基于预训练扩散模型的零样本测试时规划框架，通过结构化轨迹生成来平衡探索与利用，解决了现有方法的局限性，并在多项任务中取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度引导的规划方法在处理非凸目标、不可微约束和多奖励结构等现实世界场景时效果不佳，而监督学习方法则需要特定任务的训练或价值估计器，限制了测试时的灵活性和零样本泛化能力。

Method: 提出了一种名为TDP（Tree-guided Diffusion Planner）的框架，将测试时规划构建为一个树搜索问题。该框架使用一种双层采样过程：首先通过无训练的粒子引导生成多样化的父轨迹以鼓励广泛探索，然后通过由任务目标引导的快速条件去噪来优化子轨迹。TDP仅使用预训练模型和测试时奖励信号，通过探索不同的轨迹区域并在该扩展的解空间中利用梯度信息来克服梯度引导的局限性。

Result: 在迷宫寻金、机器人手臂抓取方块和AntMaze多目标探索三个不同的任务上评估了TDP，结果表明TDP在所有任务上都持续优于现有的最先进方法。

Conclusion: TDP是一种有效的零样本测试时规划框架，能够通过结构化轨迹生成来平衡探索和利用，克服了现有方法的局限性，并在各种具有挑战性的规划任务中展现出优越的性能。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [124] [ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes](https://arxiv.org/abs/2508.21095)
*Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi*

Main category: cs.GR

TL;DR: 本论文提出了一种用于处理未注册表面网格（如3D扫描件）的刚性无关、数据驱动的运动预测和迁移框架，通过耦合运动嵌入网络和逐顶点特征场来生成驱动网格变形的时空变形场，并在各种运动任务中展示了有效性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 解决未注册表面网格（尤其是原始3D扫描件）在自动计算合理变形方面面临的挑战，这些挑战源于缺乏已建立的点对应关系和数据中的噪声。

Method: 提出一个刚性无关、数据驱动的框架，该框架耦合了一个鲁棒的运动嵌入网络和一个学习到的逐顶点特征场，以生成时空变形场来驱动网格变形。

Result: 通过在行走和跑步等任务上的广泛评估（包括定量基准和定性视觉效果），证明了该方法在处理具有挑战性的未注册网格方面的有效性和多功能性。

Conclusion: 该方法能够有效地处理未注册的身体网格，并在各种运动任务中实现可靠的运动预测和迁移。

Abstract: Unregistered surface meshes, especially raw 3D scans, present significant
challenges for automatic computation of plausible deformations due to the lack
of established point-wise correspondences and the presence of noise in the
data. In this paper, we propose a new, rig-free, data-driven framework for
motion prediction and transfer on such body meshes. Our method couples a robust
motion embedding network with a learned per-vertex feature field to generate a
spatio-temporal deformation field, which drives the mesh deformation. Extensive
evaluations, including quantitative benchmarks and qualitative visuals on tasks
such as walking and running, demonstrate the effectiveness and versatility of
our approach on challenging unregistered meshes.

</details>


### [125] [ARGS: Advanced Regularization on Aligning Gaussians over the Surface](https://arxiv.org/abs/2508.21344)
*Jeong Uk Lee,Sung Hee Choi*

Main category: cs.GR

TL;DR: 现有3D高斯泼溅（3DGS）方法在高质量3D网格和视觉重建方面仍面临挑战。本文提出两种互补的正则化策略，改进了SuGaR模型，以提高视觉保真度和场景一致性。


<details>
  <summary>Details</summary>
Motivation: 提高3D高斯泼溅（3DGS）重建高质量3D网格和视觉效果的保真度和场景一致性。

Method: 引入有效秩正则化，鼓励高斯“盘状”而非“针状”；集成神经符号距离函数（SDF）并使用Eikonal损失进行正则化，以提供连续的全局表面先验。

Result: 提出的正则化策略提高了单个高斯图元保真度和整体表面一致性，使得最终模型能够从3DGS数据中生成更准确、更连贯的视觉效果。

Conclusion: 通过引入有效秩正则化和神经SDF正则化，显著提高了3D高斯泼溅在3D网格重建和视觉效果方面的质量和一致性。

Abstract: Reconstructing high-quality 3D meshes and visuals from 3D Gaussian
Splatting(3DGS) still remains a central challenge in computer graphics.
Although existing models such as SuGaR offer effective solutions for rendering,
there is is still room to improve improve both visual fidelity and scene
consistency. This work builds upon SuGaR by introducing two complementary
regularization strategies that address common limitations in both the shape of
individual Gaussians and the coherence of the overall surface. The first
strategy introduces an effective rank regularization, motivated by recent
studies on Gaussian primitive structures. This regularization discourages
extreme anisotropy-specifically, "needle-like" shapes-by favoring more
balanced, "disk-like" forms that are better suited for stable surface
reconstruction. The second strategy integrates a neural Signed Distance
Function (SDF) into the optimization process. The SDF is regularized with an
Eikonal loss to maintain proper distance properties and provides a continuous
global surface prior, guiding Gaussians toward better alignment with the
underlying geometry. These two regularizations aim to improve both the fidelity
of individual Gaussian primitives and their collective surface behavior. The
final model can make more accurate and coherent visuals from 3DGS data.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [126] [Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting](https://arxiv.org/abs/2508.21236)
*Malte Lüken,Javier Garcia-Bernardo,Sreeparna Deb,Flavio Hafner,Megha Khosla*

Main category: cs.SI

TL;DR: 该研究使用荷兰人口的社会网络数据构建了个人嵌入，并利用其预测右翼民粹主义投票。虽然原始嵌入预测能力有限，但在稀疏化和正交化处理后，一个嵌入维度与投票行为显著相关，揭示了教育背景与投票倾向之间的网络结构差异。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索利用人口规模的社会网络数据构建的个人嵌入特征，预测右翼民粹主义投票行为，并进一步探究这些嵌入的可解释性及其与社会结构的关系。

Method: 研究利用行政注册数据构建了包含邻里、工作、家庭、住所和学校五种共享情境的人口规模网络，并为荷兰全体人口生成了网络嵌入。通过机器学习方法，研究人员使用这些嵌入预测右翼民粹主义投票，并尝试通过稀疏化和正交化处理提高嵌入的可解释性，最终将有预测能力的嵌入维度映射回网络结构以分析其意义。

Result: 原始嵌入能够预测右翼民粹主义投票，但表现不如个体特征。结合最佳嵌入子集与个体特征的预测能力提升有限。然而，在对嵌入进行稀疏化和正交化处理后，发现一个嵌入维度与右翼民粹主义投票高度相关。该维度映射回人口网络后，揭示了不同学校联系和教育水平在右翼民粹主义投票的网络结构方面存在差异。

Conclusion: 本研究在方法上展示了如何提高人口规模网络嵌入的可解释性，在实质上则将教育相关的网络结构差异与右翼民粹主义投票联系起来。

Abstract: Administrative registry data can be used to construct population-scale
networks whose ties reflect shared social contexts between persons. With
machine learning, such networks can be encoded into numerical representations
-- embeddings -- that automatically capture individuals' position within the
network. We created embeddings for all persons in the Dutch population from a
population-scale network that represents five shared contexts: neighborhood,
work, family, household, and school. To assess the informativeness of these
embeddings, we used them to predict right-wing populist voting. Embeddings
alone predicted right-wing populist voting above chance-level but performed
worse than individual characteristics. Combining the best subset of embeddings
with individual characteristics only slightly improved predictions. However,
after transforming the embeddings to make their dimensions more sparse and
orthogonal, we found that one embedding dimension was strongly associated with
the outcome. Mapping this dimension back to the population network revealed
differences in network structure related to right-wing populist voting between
different school ties and achieved education levels. Our study contributes
methodologically by demonstrating how population-scale network embeddings can
be made interpretable, and substantively by linking structural network
differences in education to right-wing populist voting.

</details>


### [127] [Feminism, gender identity and polarization in TikTok and Twitter](https://arxiv.org/abs/2508.21301)
*Simón Peña-Fernández,Ainara Larrondo-Ureta,Jordi Morales-i-Gras*

Main category: cs.SI

TL;DR: 社交媒体上的女权主义与跨性别主义辩论显示出高度的两极分化，尤其是在年轻人中，TikTok 比 Twitter 更具对话性。


<details>
  <summary>Details</summary>
Motivation: 分析社交媒体上关于女权主义和跨性别主义辩论的两极分化，特别是在年轻人中的情况，以及“TERF”一词的使用。

Method: 使用社交网络分析技术分析了 Twitter 和 TikTok 上围绕女权主义和跨性别主义辩论的社群，并考察了年轻人的参与度。

Result: 辩论在两个平台上显示出较低的凝聚力，高度模块化的结构表明社群之间存在隔离。跨性别包容性女权主义在年轻人中占多数。TikTok 比 Twitter 更少党派性，更侧重于对话，语气更中立。

Conclusion: 社交媒体上的性身份辩论导致了女权主义激进主义的严重两极分化，这可以从代际角度来理解。

Abstract: The potential of social media to create open, collaborative and participatory
spaces allows young women to engage and empower themselves in political and
social activism. In this context, the objective of this research is to analyze
the polarization in the debate at the intersection between the defense of
feminism and transsexuality, preferably among the young population, symbolized
in the use of the term 'TERF'. To do this, the existing communities on this
subject on Twitter and TikTok have been analyzed with Social Network Analysis
techniques, in addition to the presence of young people in them. The results
indicate that the debates between both networks are not very cohesive, with a
highly modularized structure that suggests isolation of each community. For
this reason, it may be considered that the debate on sexual identity has
resulted in a strong polarization of feminist activism in social media.
Likewise, the positions of transinclusive feminism are very much in the
majority among young people; this reinforces the idea of an ideological debate
that can also be understood from a generational perspective. Finally,
differential use between both social networks has been identified, where TikTok
is a less partisan and more dialogue-based network than Twitter, which leads to
discussions and participation in a more neutral tone.

</details>


### [128] [LLM-Supported Content Analysis of Motivated Reasoning on Climate Change](https://arxiv.org/abs/2508.21305)
*Yuheun Kim,Qiaoyi Liu,Jeff Hemsley*

Main category: cs.SI

TL;DR: 研究分析了气候变化“信徒”和“怀疑者”在YouTube评论区的言论差异，利用大语言模型识别了十个主题，并通过社交网络分析了参与模式。结果表明，关于政府政策和自然周期的评论互动较少，而错误信息则互动较多，这反映了动机性推理。


<details>
  <summary>Details</summary>
Motivation: 气候变化方面的公众讨论尽管有科学共识，但仍然存在分歧。本研究旨在探究气候变化“信徒”和“怀疑者”在YouTube评论区的言论有何不同。

Method: 通过大语言模型（LLM）对30个视频的44,989条YouTube评论进行定性标注，识别出十个不同的主题。随后结合社交网络分析，考察了参与模式。并使用线性混合效应模型进行分析。

Result: 关于政府政策和自然周期的评论获得的互动显著低于错误信息，这表明这些话题在社群内部已经形成了意识形态上的固定观点。这些模式反映了动机性推理，即用户倾向于选择性地参与与其身份和信念一致的内容。

Conclusion: 研究结果突显了大语言模型在进行大规模定性分析方面的实用性，并揭示了气候问题的言论不仅受到内容本身的影响，还受到潜在的认知和意识形态动机的塑造。

Abstract: Public discourse around climate change remains polarized despite scientific
consensus on anthropogenic climate change (ACC). This study examines how
"believers" and "skeptics" of ACC differ in their YouTube comment discourse. We
analyzed 44,989 comments from 30 videos using a large language model (LLM) as a
qualitative annotator, identifying ten distinct topics. These annotations were
combined with social network analysis to examine engagement patterns. A linear
mixed-effects model showed that comments about government policy and natural
cycles generated significantly lower interaction compared to misinformation,
suggesting these topics are ideologically settled points within communities.
These patterns reflect motivated reasoning, where users selectively engage with
content that aligns with their identity and beliefs. Our findings highlight the
utility of LLMs for large-scale qualitative analysis and highlight how climate
discourse is shaped not only by content, but by underlying cognitive and
ideological motivations.

</details>


### [129] [Faster Inference of Cell Complexes from Flows via Matrix Factorization](https://arxiv.org/abs/2508.21372)
*Til Spreuer,Josef Hoppe,Michael T. Schaub*

Main category: cs.SI

TL;DR: 通过引入2-细胞（由闭合、不相交路径环绕的多边形）来增强观测图，以便霍奇拉普拉斯算子的特征向量能够提供一种稀疏、可解释的表示。


<details>
  <summary>Details</summary>
Motivation: 解决高计算成本和在噪声条件下性能不佳的现有方法。

Method: 开发了一种新颖的基于矩阵分解的启发式方法来解决图提升问题。

Result: 与先前启发式方法相比，计算成本更低，性能略有下降，但在特定噪声条件下，性能和计算速度均优于现有技术。

Conclusion: 所提出的基于矩阵分解的启发式方法在计算效率和某些噪声条件下提供了改进的性能，为解决图提升问题提供了一种有前途的替代方案。

Abstract: We consider the following inference problem: Given a set of edge-flow signals
observed on a graph, lift the graph to a cell complex, such that the observed
edge-flow signals can be represented as a sparse combination of gradient and
curl flows on the cell complex. Specifically, we aim to augment the observed
graph by a set of 2-cells (polygons encircled by closed, non-intersecting
paths), such that the eigenvectors of the Hodge Laplacian of the associated
cell complex provide a sparse, interpretable representation of the observed
edge flows on the graph. As it has been shown that the general problem is
NP-hard in prior work, we here develop a novel matrix-factorization-based
heuristic to solve the problem. Using computational experiments, we demonstrate
that our new approach is significantly less computationally expensive than
prior heuristics, while achieving only marginally worse performance in most
settings. In fact, we find that for specifically noisy settings, our new
approach outperforms the previous state of the art in both solution quality and
computational speed.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [130] [Catwalk: Unary Top-K for Efficient Ramp-No-Leak Neuron Design for Temporal Neural Networks](https://arxiv.org/abs/2508.21267)
*Devon Lister,Prabhu Vellaisamy,John Paul Shen,Di Wu*

Main category: cs.AR

TL;DR: 基于稀疏性改进CMOS神经元硬件效率，提出Catwalk实现方式，在面积和功耗上分别提升1.39倍和1.86倍


<details>
  <summary>Details</summary>
Motivation: 实际脉冲发放中，只有一小部分树突输入在每个计算周期携带脉冲，这种稀疏性可以被利用来提高硬件效率

Method: 提出Catwalk神经元实现方式，通过单价排序选出top-k稀疏脉冲子集，减少后续并行计数器成本

Result: Catwalk在面积和功耗上比现有的SRM0-RNL神经元分别提升1.39倍和1.86倍

Conclusion: Catwalk通过利用稀疏性显著降低了成本，提高了RNL神经元实现的面积和功耗效率

Abstract: Temporal neural networks (TNNs) are neuromorphic neural networks that utilize
bit-serial temporal coding. TNNs are composed of columns, which in turn employ
neurons as their building blocks. Each neuron processes volleys of input
spikes, modulated by associated synaptic weights, on its dendritic inputs.
Recently proposed neuron implementation in CMOS employs a Spike Response Model
(SRM) with a ramp-no-leak (RNL) response function and assumes all the inputs
can carry spikes. However, in actual spike volleys, only a small subset of the
dendritic inputs actually carry spikes in each compute cycle. This form of
sparsity can be exploited to achieve better hardware efficiency. In this paper,
we propose a Catwalk neuron implementation by relocating spikes in a spike
volley as a sorted subset cluster via unary top-k. Such relocation can
significantly reduce the cost of the subsequent parallel counter (PC) for
accumulating the response functions from the spiking inputs. This can lead to
improvements on area and power efficiency in RNL neuron implementation.
Place-and-route results show Catwalk is 1.39x and 1.86x better in area and
power, respectively, as compared to existing SRM0-RNL neurons.

</details>


### [131] [SCE-NTT: A Hardware Accelerator for Number Theoretic Transform Using Superconductor Electronics](https://arxiv.org/abs/2508.21265)
*Sasan Razmkhah,Mingye Li,Zeming Cheng,Robert S. Aviles,Kyle Jackman,Joey Delport,Lieze Schindler,Wenhui Luo,Takuya Suzuki,Mehdi Kamal,Christopher L. Ayala,Coenrad J. Fourie,Nabuyuki Yoshikawa,Peter A. Beerel,Sandeep Gupta,Massoud Pedram*

Main category: cs.AR

TL;DR: 超导电子学（SCE）技术可用于加速全同态加密（FHE），特别是其中的数论变换（NTT）部分。研究提出了一种基于SFQ逻辑和存储器的SCE-NTT硬件加速器（NTT-128），解决了SFQ的存储器和扇入/扇出限制，采用了流水线设计和移位寄存器存储器（SRM）。该加速器使用优化的Shoup乘法器，并开发了新的RSFQ单元库。仿真和制造结果显示，NTT-128在34 GHz下达到5.31亿次NTT/秒，比CMOS快100倍以上，并且可以扩展到更大的规模。该技术在后量子时代的安全计算领域具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: FHE计算瓶颈是NTT，而CMOS技术已接近性能极限，需要新的技术来加速FHE。

Method: 设计了一个基于超导单通量量子（SFQ）逻辑和存储器的专用硬件加速器SCE-NTT，特别是NTT-128架构，采用了深度流水线设计、移位寄存器存储器（SRM）和Shoup乘法器，并开发了新的RSFQ单元库进行实现和验证。

Result: NTT-128在34 GHz下实现了5.31亿次NTT/秒的处理速度，比最先进的CMOS方案快100倍以上。预测该架构可扩展至2^14点NTT，耗时约482纳秒，密钥切换吞吐量估计为163万次/秒，远超现有硬件。

Conclusion: 超导电子学（SCE）技术有望为后量子时代的可扩展、高能效安全计算提供强大的硬件加速支持，并且随着制造技术的进步，性能还有进一步提升的空间。

Abstract: This research explores the use of superconductor electronics (SCE) for
accelerating fully homomorphic encryption (FHE), focusing on the
Number-Theoretic Transform (NTT), a key computational bottleneck in FHE
schemes. We present SCE-NTT, a dedicated hardware accelerator based on
superconductive single flux quantum (SFQ) logic and memory, targeting high
performance and energy efficiency beyond the limits of conventional CMOS. To
address SFQ constraints such as limited dense RAM and restricted fanin/fanout,
we propose a deeply pipelined NTT-128 architecture using shift register memory
(SRM). Designed for N=128 32-bit coefficients, NTT-128 comprises log2(N)=7
processing elements (PEs), each featuring a butterfly unit (BU), dual
coefficient memories operating in ping-pong mode via FIFO-based SRM queues, and
twiddle factor buffers. The BU integrates a Shoup modular multiplier optimized
for a small area, leveraging precomputed twiddle factors. A new RSFQ cell
library with over 50 parameterized cells, including compound logic units, was
developed for implementation. Functional and timing correctness were validated
using JoSIM analog simulations and Verilog models. A multiphase clocking scheme
was employed to enhance robustness and reduce path-balancing overhead,
improving circuit reliability. Fabricated results show the NTT-128 unit
achieves 531 million NTT/sec at 34 GHz, over 100x faster than state-of-the-art
CMOS equivalents. We also project that the architecture can scale to larger
sizes, such as a 2^14-point NTT in approximately 482 ns. Key-switch throughput
is estimated at 1.63 million operations/sec, significantly exceeding existing
hardware. These results demonstrate the strong potential of SCE-based
accelerators for scalable, energy-efficient secure computation in the
post-quantum era, with further gains anticipated through advances in
fabrication.

</details>


### [132] [SIRA: Scaled-Integer Range Analysis for Optimizing FPGA Dataflow Neural Network Accelerators](https://arxiv.org/abs/2508.21493)
*Yaman Umuroglu,Christoph Berganski,Felix Jentzsch,Michal Danilowicz,Tomasz Kryjak,Charalampos Bezaitis,Magnus Sjalander,Ian Colbert,Thomas Preusser,Jakoba Petri-Koenig,Michaela Blott*

Main category: cs.AR

TL;DR: 该论文提出了一种名为SIRA（scaled-integer range analysis）的静态分析技术，用于量化神经网络的张量范围、缩放因子和偏置。通过利用这些信息，可以优化FPGA数据流神经网络加速器，降低累加器和下游操作的比特宽度，聚合缩放因子和偏置，并将连续的逐元素操作转换为阈值操作。实验表明，SIRA优化平均减少了17%的LUT资源、66%的DSP资源和22%的累加器比特宽度。该技术已集成到FINN框架中，并已开源。


<details>
  <summary>Details</summary>
Motivation: 在嵌入式系统中，虽然神经网路量化能有效降低矩阵乘法的成本，但激进的量化会暴露非矩阵乘法操作的性能和资源瓶颈。为了解决这些瓶颈，需要一种跨操作的精度定制方法。

Method: 提出了一种名为SIRA（scaled-integer range analysis）的静态分析技术，使用区间算术来确定量化神经网络中张量的范围、缩放因子和偏置。利用这些信息，通过为累加器和下游操作定制比特宽度、聚合缩放因子和偏置以及将连续的逐元素操作转换为阈值操作，来减少FPGA数据流神经网络加速器的资源占用。将SIRA驱动的优化集成到FINN框架中进行评估。

Result: SIRA优化平均减少了17%的LUT资源、66%的DSP资源和22%的累加器比特宽度。论文提供了详细的基准分析和分析模型来指导非矩阵层的实现风格。

Conclusion: SIRA是一种有效的静态分析技术，可以显著优化量化神经网络在FPGA上的性能和资源占用，特别是非矩阵乘法操作。通过开源SIRA，可以促进其在不同应用和硬件平台上的广泛应用。

Abstract: While neural network quantization effectively reduces the cost of matrix
multiplications, aggressive quantization can expose non-matrix-multiply
operations as significant performance and resource bottlenecks on embedded
systems. Addressing such bottlenecks requires a comprehensive approach to
tailoring the precision across operations in the inference computation. To this
end, we introduce scaled-integer range analysis (SIRA), a static analysis
technique employing interval arithmetic to determine the range, scale, and bias
for tensors in quantized neural networks. We show how this information can be
exploited to reduce the resource footprint of FPGA dataflow neural network
accelerators via tailored bitwidth adaptation for accumulators and downstream
operations, aggregation of scales and biases, and conversion of consecutive
elementwise operations to thresholding operations. We integrate SIRA-driven
optimizations into the open-source FINN framework, then evaluate their
effectiveness across a range of quantized neural network workloads and compare
implementation alternatives for non-matrix-multiply operations. We demonstrate
an average reduction of 17% for LUTs, 66% for DSPs, and 22% for accumulator
bitwidths with SIRA optimizations, providing detailed benchmark analysis and
analytical models to guide the implementation style for non-matrix layers.
Finally, we open-source SIRA to facilitate community exploration of its
benefits across various applications and hardware platforms.

</details>


### [133] [Binary Weight Multi-Bit Activation Quantization for Compute-in-Memory CNN Accelerators](https://arxiv.org/abs/2508.21524)
*Wenyong Zhou,Zhengwu Liu,Yuan Ren,Ngai Wong*

Main category: cs.AR

TL;DR: 该论文提出了一种新颖的二值权重多比特激活(BWMA)方法，用于计算内存(CIM)加速器上的卷积神经网络(CNN)。该方法通过推导权重量化以及开发可微分函数进行激活量化，在保持高能效的同时提高了精度，在CIFAR-10和ImageNet数据集上取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 为了在满足硬件约束的同时提高CNN在CIM平台上的能效，同时解决现有方法在硬件效率和准确性之间的权衡问题。

Method: 提出了一种新颖的二值权重多比特激活(BWMA)方法。具体包括：1.推导了每一层权重量化的闭式解，以增强二值化权重的表示能力。2.开发了一种可微分的激活量化函数，以逼近理想的多比特函数，同时避免了对最优设置的广泛搜索。

Result: 在CIFAR-10和ImageNet数据集上，BWMA方法相比现有方法实现了1.44%-5.46%和0.35%-5.37%的显著精度提升。硬件模拟结果表明，4位激活量化在硬件成本和模型性能之间取得了最佳平衡。

Conclusion: BWMA方法通过创新的量化策略，有效解决了CIM加速器上CNN的精度与效率的权衡问题，为实现更高效的AI硬件部署提供了有前景的解决方案。

Abstract: Compute-in-memory (CIM) accelerators have emerged as a promising way for
enhancing the energy efficiency of convolutional neural networks (CNNs).
Deploying CNNs on CIM platforms generally requires quantization of network
weights and activations to meet hardware constraints. However, existing
approaches either prioritize hardware efficiency with binary weight and
activation quantization at the cost of accuracy, or utilize multi-bit weights
and activations for greater accuracy but limited efficiency. In this paper, we
introduce a novel binary weight multi-bit activation (BWMA) method for CNNs on
CIM-based accelerators. Our contributions include: deriving closed-form
solutions for weight quantization in each layer, significantly improving the
representational capabilities of binarized weights; and developing a
differentiable function for activation quantization, approximating the ideal
multi-bit function while bypassing the extensive search for optimal settings.
Through comprehensive experiments on CIFAR-10 and ImageNet datasets, we show
that BWMA achieves notable accuracy improvements over existing methods,
registering gains of 1.44\%-5.46\% and 0.35\%-5.37\% on respective datasets.
Moreover, hardware simulation results indicate that 4-bit activation
quantization strikes the optimal balance between hardware cost and model
performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [134] [Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering](https://arxiv.org/abs/2508.21081)
*Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk*

Main category: cs.LG

TL;DR: This paper proposes a hybrid approach combining string similarity, topic modeling, hierarchical clustering, and rule-based methods to cluster transaction counterparties, particularly for financial messaging systems like SWIFT. This method addresses the limitations of traditional natural language processing techniques on short, unstructured texts found in such systems. The approach also includes custom metrics for evaluation and demonstrates improved performance over baseline methods on a real-life dataset, while maintaining interpretability and reducing manual review needs.


<details>
  <summary>Details</summary>
Motivation: Traditional natural language processing techniques are unsuitable for clustering transaction counterparties in financial messaging systems (like SWIFT) due to the short, unstructured, and noisy nature of the data. This creates a gap in tools for fraud investigators and financial professionals to trace funds and understand payment flows, a gap often filled by less effective fuzzy matching tools. This paper aims to bridge that gap.

Method: The paper proposes a hybrid pipeline that integrates several techniques: string similarity, topic modeling, hierarchical clustering, and a rule-based system. This pipeline is designed to cluster transaction counterparties, accommodating an unknown number of clusters. Additionally, new metrics based on precision and recall are devised to evaluate the approach's effectiveness.

Result: Testing on a real-life, labeled dataset shows that the proposed hybrid approach significantly outperforms a baseline rule-based ('keyword') method. The approach maintains interpretability by refining rule-based systems and reduces the necessity for manual review. It also offers better control over risks associated with missing entity variations, especially in targeted investigations like sanctions screening.

Conclusion: The developed hybrid approach effectively clusters transaction counterparties in financial messaging systems, overcoming the limitations of existing methods. It offers improved performance, interpretability, and reduced manual effort compared to traditional techniques, thereby enhancing the capabilities of fraud investigators and financial professionals in tracing funds and identifying entities.

Abstract: Short text clustering is a known use case in the text analytics community.
When the structure and content falls in the natural language domain e.g.
Twitter posts or instant messages, then natural language techniques can be
used, provided texts are of sufficient length to allow for use of (pre)trained
models to extract meaningful information, such as part-of-speech or topic
annotations. However, natural language models are not suitable for clustering
transaction counterparties, as they are found in bank payment messaging
systems, such as SWIFT. The manually typed tags are typically physical or legal
entity details, which lack sentence structure, while containing all the
variations and noise that manual entry introduces. This leaves a gap in an
investigator or counter-fraud professional's toolset when looking to augment
their knowledge of payment flow originator and beneficiary entities and trace
funds and assets. A gap that vendors traditionally try to close with fuzzy
matching tools. With these considerations in mind, we are proposing a hybrid
string similarity, topic modelling, hierarchical clustering and rule-based
pipeline to facilitate clustering of transaction counterparties, also catering
for unknown number of expected clusters. We are also devising metrics to
supplement the evaluation of the approach, based on the well-known measures of
precision and recall. Testing on a real-life labelled dataset demonstrates
significantly improved performance over a baseline rule-based ('keyword')
approach. The approach retains most of the interpretability found in rule-based
systems, as the former adds an additional level of cluster refinement to the
latter. The resulting workflow reduces the need for manual review. When only a
subset of the population needs to be investigated, such as in sanctions
investigations, the approach allows for better control of the risks of missing
entity variations.

</details>


### [135] [Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI](https://arxiv.org/abs/2508.21101)
*Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng*

Main category: cs.LG

TL;DR: The paper surveys reinforcement learning (RL) in healthcare, highlighting its shift from prediction to active intervention and its integration of multi-source signals across various architectures. It covers RL techniques, applications in diverse medical fields, and critically examines ethical, deployment, and reward design challenges, offering a roadmap for safe and human-aligned RL in healthcare.


<details>
  <summary>Details</summary>
Motivation: To explore the rise of RL in healthcare as a shift towards agentive intelligence, providing a technical roadmap and critical reflection on its transformative role.

Method: The survey structures RL techniques (model-based, model-free, offline, etc.), analyzes applications across critical care, chronic disease, mental health, diagnostics, and robotic assistance, and critically examines ethical, deployment, and reward design challenges.

Result: Identified trends, gaps, and translational bottlenecks in RL applications across various healthcare domains. Synthesized lessons for safe, human-aligned policy learning.

Conclusion: RL represents a fundamental shift towards agentive intelligence in healthcare AI, moving beyond prediction to active intervention. Addressing ethical, deployment, and reward design challenges is crucial for its safe and effective implementation.

Abstract: Reinforcement learning (RL) marks a fundamental shift in how artificial
intelligence is applied in healthcare. Instead of merely predicting outcomes,
RL actively decides interventions with long term goals. Unlike traditional
models that operate on fixed associations, RL systems learn through trial,
feedback, and long-term reward optimization, introducing transformative
possibilities and new risks. From an information fusion lens, healthcare RL
typically integrates multi-source signals such as vitals, labs clinical notes,
imaging and device telemetry using temporal and decision-level mechanisms.
These systems can operate within centralized, federated, or edge architectures
to meet real-time clinical constraints, and naturally span data, features and
decision fusion levels. This survey explore RL's rise in healthcare as more
than a set of tools, rather a shift toward agentive intelligence in clinical
environments. We first structure the landscape of RL techniques including
model-based and model-free methods, offline and batch-constrained approaches,
and emerging strategies for reward specification and uncertainty calibration
through the lens of healthcare constraints. We then comprehensively analyze RL
applications spanning critical care, chronic disease, mental health,
diagnostics, and robotic assistance, identifying their trends, gaps, and
translational bottlenecks. In contrast to prior reviews, we critically analyze
RL's ethical, deployment, and reward design challenges, and synthesize lessons
for safe, human-aligned policy learning. This paper serves as both a a
technical roadmap and a critical reflection of RL's emerging transformative
role in healthcare AI not as prediction machinery, but as agentive clinical
intelligence.

</details>


### [136] [Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning](https://arxiv.org/abs/2508.21103)
*Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin*

Main category: cs.LG

TL;DR: 本研究提出了一种统一的、多粒度的脑电图（EEG）情感分类框架，以解决现有方法在泛化性和实际应用中的局限性。该框架使用GAMEEMO数据集，包含28名受试者在四种游戏场景下的14通道脑电图记录和连续情绪评级。通过结构化的预处理（时间窗口分割、混合特征提取、z-score归一化）将原始脑电信号转换为鲁棒的输入向量。情感标签被编码为三个维度：二元效价分类、多类别情感分类和细粒度多标签分类。研究评估了包括随机森林、XGBoost、SVM、LSTM、LSTM-GRU和CNN-LSTM在内的多种模型，其中LSTM-GRU模型在二元效价分类任务中取得了0.932的F1分数，在多类别和多标签情感分类任务中分别达到了94.5%和90.6%的准确率，表现优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于脑电图的情感识别研究主要集中在二元效价预测或特定于受试者的分类，这限制了其泛化能力和在实际情感计算系统中的应用。本研究旨在通过提出一个统一的、多粒度的脑电图情感分类框架来解决这一问题。

Method: 本研究提出了一个统一的、多粒度的脑电图情感分类框架。该框架基于GAMEEMO数据集，该数据集包含28名受试者在四种游戏场景下的14通道脑电图记录和连续的情绪评级（无聊、糟糕、平静、有趣）。预处理流程包括时间窗口分割、混合统计和频域特征提取以及z-score归一化。情感标签被编码为三个维度：基于平均极性的二元效价分类；基于最能引发情感状态存在的多类别情感分类；以及通过将每个情感分箱为10个有序类别获得的细粒度多标签表示。研究评估了包括随机森林、XGBoost、SVM、LSTM、LSTM-GRU和CNN-LSTM在内的多种模型。

Result: 在对多种模型（包括随机森林、XGBoost、SVM、LSTM、LSTM-GRU和CNN-LSTM）的评估中，LSTM-GRU模型在所有情感分类任务中均表现出持续的优越性。具体而言，该模型在二元效价分类任务中取得了0.932的F1分数，在多类别情感分类任务中达到了94.5%的准确率，在细粒度多标签情感分类任务中达到了90.6%的准确率。

Conclusion: LSTM-GRU模型在所提出的统一、多粒度脑电图情感分类框架中表现出最佳性能，成功地解决了现有方法在泛化性和实际应用方面的局限性。该框架通过多维度的情感标签编码和先进的特征提取方法，为情感计算领域提供了更全面和鲁棒的情感识别解决方案。

Abstract: Recent advancements in EEG-based emotion recognition have shown promising
outcomes using both deep learning and classical machine learning approaches;
however, most existing studies focus narrowly on binary valence prediction or
subject-specific classification, which limits generalizability and deployment
in real-world affective computing systems. To address this gap, this paper
presents a unified, multigranularity EEG emotion classification framework built
on the GAMEEMO dataset, which consists of 14-channel EEG recordings and
continuous self-reported emotion ratings (boring, horrible, calm, and funny)
from 28 subjects across four emotion-inducing gameplay scenarios. Our pipeline
employs a structured preprocessing strategy that comprises temporal window
segmentation, hybrid statistical and frequency-domain feature extraction, and
z-score normalization to convert raw EEG signals into robust, discriminative
input vectors. Emotion labels are derived and encoded across three
complementary axes: (i) binary valence classification based on the averaged
polarity of positive and negative emotion ratings, and (ii) Multi-class emotion
classification, where the presence of the most affective state is predicted.
(iii) Fine-grained multi-label representation via binning each emotion into 10
ordinal classes. We evaluate a broad spectrum of models, including Random
Forest, XGBoost, and SVM, alongside deep neural architectures such as LSTM,
LSTM-GRU, and CNN-LSTM. Among these, the LSTM-GRU model consistently
outperforms the others, achieving an F1-score of 0.932 in the binary valence
task and 94.5% and 90.6% in both multi-class and Multi-Label emotion
classification.

</details>


### [137] [PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning](https://arxiv.org/abs/2508.21104)
*Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang*

Main category: cs.LG

TL;DR: PVPO是一种高效的强化学习方法，通过引入优势参考锚点和数据预采样来解决现有群策略的局部最优和计算成本问题。PVPO使用参考模型提前进行滚动，并将计算出的奖励分数作为参考锚点，有效纠正了组内比较引入的累积偏差，并显著减少了对滚动次数的依赖。此外，参考模型能够在数据预采样期间评估样本难度，从而有效地选择高收益数据以提高训练效率。PVPO在两个域的九个数据集上进行了实验，结果证明其达到了最先进的性能，并且在多任务中表现出强大的泛化能力和跨不同模型规模的可扩展性能。


<details>
  <summary>Details</summary>
Motivation: Critic-free强化学习方法（特别是群策略）在复杂任务中效率很高，但它们依赖于策略内的多次采样和比较来估计优势，这可能导致策略陷入局部最优并增加计算成本。

Method: PVPO通过引入优势参考锚点和数据预采样来解决上述问题。具体来说，PVPO使用参考模型提前进行滚动，并将计算出的奖励分数作为参考锚点。参考模型还可以评估样本难度，以便在数据预采样过程中选择高收益数据。

Result: PVPO在两个域的九个数据集上进行了实验，证明其达到了最先进的性能，并在多任务中表现出强大的泛化能力和跨不同模型规模的可扩展性能。

Conclusion: PVPO通过引入优势参考锚点和数据预采样，有效地解决了现有Critic-free强化学习方法的局部最优和计算成本问题，同时提高了训练效率和模型性能。

Abstract: Critic-free reinforcement learning methods, particularly group policies, have
attracted considerable attention for their efficiency in complex tasks.
However, these methods rely heavily on multiple sampling and comparisons within
the policy to estimate advantage, which may cause the policy to fall into local
optimum and increase computational cost. To address these issues, we propose
PVPO, an efficient reinforcement learning method enhanced by an advantage
reference anchor and data pre-sampling. Specifically, we use the reference
model to rollout in advance and employ the calculated reward score as a
reference anchor. Our approach effectively corrects the cumulative bias
introduced by intra-group comparisons and significantly reduces reliance on the
number of rollouts. Meanwhile, the reference model can assess sample difficulty
during data pre-sampling, enabling effective selection of high-gain data to
improve training efficiency. Experiments conducted on nine datasets across two
domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our
approach not only demonstrates robust generalization across multiple tasks, but
also exhibits scalable performance across models of varying scales.

</details>


### [138] [Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models](https://arxiv.org/abs/2508.21106)
*Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov*

Main category: cs.LG

TL;DR: AdaGram是一种高效的全矩阵自适应梯度优化器，通过对称分解和低秩近似来解决现有方法的计算和内存瓶颈，并在机器学习任务中展现出优于或媲美传统方法的收敛性能。


<details>
  <summary>Details</summary>
Motivation: 现有自适应梯度方法（如Adagrad）的对角预处理矩阵限制了捕捉参数相关性的能力，而全矩阵方法计算成本高昂。

Method: AdaGram利用快速对称分解计算预处理更新方向，并结合矩阵积分器方法保持预处理器的低秩结构，以降低内存和计算开销。

Result: 在标准机器学习任务的数值实验中，AdaGram在秩为五及更低秩近似时，收敛速度更快或性能与对角自适应优化器相当。

Conclusion: AdaGram是一种有潜力的可扩展解决方案，能够实现大规模模型中的自适应优化。

Abstract: Adaptive gradient methods like Adagrad and its variants are widespread in
large-scale optimization. However, their use of diagonal preconditioning
matrices limits the ability to capture parameter correlations. Full-matrix
adaptive methods, approximating the exact Hessian, can model these correlations
and may enable faster convergence. At the same time, their computational and
memory costs are often prohibitive for large-scale models. To address this
limitation, we propose AdaGram, an optimizer that enables efficient full-matrix
adaptive gradient updates. To reduce memory and computational overhead, we
utilize fast symmetric factorization for computing the preconditioned update
direction at each iteration. Additionally, we maintain the low-rank structure
of a preconditioner along the optimization trajectory using matrix integrator
methods. Numerical experiments on standard machine learning tasks show that
AdaGram converges faster or matches the performance of diagonal adaptive
optimizers when using rank five and smaller rank approximations. This
demonstrates AdaGram's potential as a scalable solution for adaptive
optimization in large models.

</details>


### [139] [A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics](https://arxiv.org/abs/2508.21249)
*Mohammad Amin Nabian,Sanjay Choudhry*

Main category: cs.LG

TL;DR: 本论文提出了一种新颖的元学习框架，通过混合专家（MoE）模型结合三种不同的先进机器学习模型（DoMINO、X-MeshGraphNet、FigConvNet），以在汽车空气动力学预测中加速高保真计算流体动力学（CFD）模拟。该框架通过一个门控网络动态地组合专家模型的预测，并使用熵正则化防止模型崩溃。实验结果表明，MoE模型在DrivAerML数据集上显著降低了L-2预测误差，优于单独的专家模型和集合平均。


<details>
  <summary>Details</summary>
Motivation: 为了克服高保真计算流体动力学（CFD）模拟在汽车设计和优化周期中计算成本高昂的瓶颈，并解决现有基于机器学习的替代模型在架构多样性且无单一模型具有普遍优势的问题。

Method: 提出了一种混合专家（MoE）模型，该模型使用一个专门的门控网络来动态且最优地结合三种异构的先进模拟模型（DoMINO、X-MeshGraphNet、FigConvNet）的预测。门控网络学习一种空间变化的加权策略，根据每个专家在预测表面压力和壁面剪切应力场方面的局部性能来分配权重。通过在训练损失函数中集成熵正则化项来防止模型崩溃并鼓励平衡的专家贡献。

Result: 在DrivAerML数据集上进行训练和验证后，MoE模型在L-2预测误差方面实现了显著降低，并且在所有评估的物理量上均优于集合平均值和最准确的单个专家模型。

Conclusion: 本研究将MoE框架确立为一种强大而有效的策略，通过协同结合专业化架构的互补优势，创建更鲁棒、更准确的复合模拟模型。

Abstract: The computational cost associated with high-fidelity CFD simulations remains
a significant bottleneck in the automotive design and optimization cycle. While
ML-based surrogate models have emerged as a promising alternative to accelerate
aerodynamic predictions, the field is characterized by a diverse and rapidly
evolving landscape of specialized neural network architectures, with no single
model demonstrating universal superiority. This paper introduces a novel
meta-learning framework that leverages this architectural diversity as a
strength. We propose a Mixture of Experts (MoE) model that employs a dedicated
gating network to dynamically and optimally combine the predictions from three
heterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable
multi-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph
neural network; and FigConvNet, a factorized implicit global convolution
network. The gating network learns a spatially-variant weighting strategy,
assigning credibility to each expert based on its localized performance in
predicting surface pressure and wall shear stress fields. To prevent model
collapse and encourage balanced expert contributions, we integrate an entropy
regularization term into the training loss function. The entire system is
trained and validated on the DrivAerML dataset, a large-scale, public benchmark
of high-fidelity CFD simulations for automotive aerodynamics. Quantitative
results demonstrate that the MoE model achieves a significant reduction in L-2
prediction error, outperforming not only the ensemble average but also the most
accurate individual expert model across all evaluated physical quantities. This
work establishes the MoE framework as a powerful and effective strategy for
creating more robust and accurate composite surrogate models by synergistically
combining the complementary strengths of specialized architectures.

</details>


### [140] [An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity](https://arxiv.org/abs/2508.21109)
*Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis*

Main category: cs.LG

TL;DR: 本篇论文提出了一种深度学习框架，用于智能HVAC系统中的模型预测控制（MPC），对温度、太阳辐照度和相对湿度进行48小时预测。该框架使用带有注意力的堆叠双向长短期记忆（BiLSTM）网络，通过联合预测所有三个变量来捕捉时间和跨特征依赖性。


<details>
  <summary>Details</summary>
Motivation: 为了支持智能HVAC系统中的模型预测控制（MPC），需要对温度、太阳辐照度和相对湿度进行准确的48小时预测。

Method: 采用堆叠双向长短期记忆（BiLSTM）网络，并加入注意力机制，同时预测温度、太阳辐照度和相对湿度。使用2019-2022年的历史气象数据（包含编码的周期性时间特征）进行训练，并使用2023年的数据评估泛化能力。通过集成梯度量化特征贡献，并通过注意力权重揭示时间模式以增强可解释性。

Result: 模型在温度、太阳辐照度和相对湿度上分别实现了1.3摄氏度、31 W/m2和6.7个百分点的平均绝对误差，优于最先进的数值天气预报和机器学习基准。

Conclusion: 该框架通过结合多变量预测、基于注意力的深度学习和可解释性，在数据驱动的天气预测方面取得了进展。所展示的准确性和透明性突显了该框架通过可靠的短期气象预测，在节能建筑控制方面的潜力。

Abstract: This paper presents a Deep Learning (DL) framework for 48-hour forecasting of
temperature, solar irradiance, and relative humidity to support Model
Predictive Control (MPC) in smart HVAC systems. The approach employs a stacked
Bidirectional Long Short-Term Memory (BiLSTM) network with attention, capturing
temporal and cross-feature dependencies by jointly predicting all three
variables. Historical meteorological data (2019-2022) with encoded cyclical
time features were used for training, while 2023 data evaluated generalization.
The model achieved Mean Absolute Errors of 1.3 degrees Celsius (temperature),
31 W/m2 (irradiance), and 6.7 percentage points (humidity), outperforming
state-of-the-art numerical weather prediction and machine learning benchmarks.
Integrated Gradients quantified feature contributions, and attention weights
revealed temporal patterns, enhancing interpretability. By combining
multivariate forecasting, attention-based DL, and explainability, this work
advances data-driven weather prediction. The demonstrated accuracy and
transparency highlight the framework's potential for energy-efficient building
control through reliable short-term meteorological forecasting.

</details>


### [141] [Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks](https://arxiv.org/abs/2508.21571)
*Bangti Jin,Longjun Wu*

Main category: cs.LG

TL;DR: PINNs的SGD训练具有线性收敛性。


<details>
  <summary>Details</summary>
Motivation: 探究PINNs训练过程中随机梯度下降（SGD）的收敛性保证，以解决现有梯度下降分析的局限性。

Method: 通过分析在过参数化两层PINNs上使用SGD进行训练时的收敛性，并证明在一般激活函数下，高概率的线性收敛性。

Result: 证明了过参数化两层PINNs使用SGD训练时具有高概率的线性收敛性，扩展了现有梯度下降的分析结果。

Conclusion: 证明了PINNs使用SGD进行训练时的收敛性，并为理解优化过程动力学提供了理论基础。

Abstract: Physics informed neural networks (PINNs) represent a very popular class of
neural solvers for partial differential equations. In practice, one often
employs stochastic gradient descent type algorithms to train the neural
network. Therefore, the convergence guarantee of stochastic gradient descent is
of fundamental importance. In this work, we establish the linear convergence of
stochastic gradient descent / flow in training over-parameterized two layer
PINNs for a general class of activation functions in the sense of high
probability. These results extend the existing result [18] in which gradient
descent was analyzed. The challenge of the analysis lies in handling the
dynamic randomness introduced by stochastic optimization methods. The key of
the analysis lies in ensuring the positive definiteness of suitable Gram
matrices during the training. The analysis sheds insight into the dynamics of
the optimization process, and provides guarantees on the neural networks
trained by stochastic algorithms.

</details>


### [142] [Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI](https://arxiv.org/abs/2508.21111)
*Evan J. Chou,Lisa S. Locke,Harvey M. Soldan*

Main category: cs.LG

TL;DR: NASA DSN通过AI驱动的数据管道和机器学习模型，实时检测天线和发射器的异常及退化，以保障航天器通信。


<details>
  <summary>Details</summary>
Motivation: DSN产生大量多变量时间序列数据，其设备（天线、发射器）的长期运行可能导致数据流中断和通信威胁，需要方法来辅助工程师检测异常和设备退化。

Method: 研究多种机器学习技术进行数据预测性重建和异常检测，并集成强化学习子系统进行异常严重性分类，以及利用大型语言模型对异常数据进行解释。为DSN发射器实现了完整的数据管道（数据提取、解析、处理），并以AI系统为核心进行推理、分类和预测。

Result: 成功实现了包含数据管道、机器学习模型、强化学习和大型语言模型的AI系统，能够连接DSN天线和发射器数据，实现异常检测和设备退化分析。

Conclusion: 所提出的AI系统能够有效辅助JPL工程师进行DSN的异常检测和设备退化分析，保障未来太空任务的通信。

Abstract: The Deep Space Network (DSN) is NASA's largest network of antenna facilities
that generate a large volume of multivariate time-series data. These facilities
contain DSN antennas and transmitters that undergo degradation over long
periods of time, which may cause costly disruptions to the data flow and
threaten the earth-connection of dozens of spacecraft that rely on the Deep
Space Network for their lifeline. The purpose of this study was to experiment
with different methods that would be able to assist JPL engineers with directly
pinpointing anomalies and equipment degradation through collected data, and
continue conducting maintenance and operations of the DSN for future space
missions around our universe. As such, we have researched various machine
learning techniques that can fully reconstruct data through predictive
analysis, and determine anomalous data entries within real-time datasets
through statistical computations and thresholds. On top of the fully trained
and tested machine learning models, we have also integrated the use of a
reinforcement learning subsystem that classifies identified anomalies based on
severity level and a Large Language Model that labels an explanation for each
anomalous data entry, all of which can be improved and fine-tuned over time
through human feedback/input. Specifically, for the DSN transmitters, we have
also implemented a full data pipeline system that connects the data extraction,
parsing, and processing workflow all together as there was no coherent program
or script for performing these tasks before. Using this data pipeline system,
we were able to then also connect the models trained from DSN antenna data,
completing the data workflow for DSN anomaly detection. This was all wrapped
around and further connected by an agentic AI system, where complex reasoning
was utilized to determine the classifications and predictions of anomalous
data.

</details>


### [143] [Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL](https://arxiv.org/abs/2508.21739)
*Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst*

Main category: cs.LG

TL;DR: SLAC开发了SNL和Auto-SNL，用于在FPGA上部署实时机器学习模型，以应对LCLS-II高通量数据流的挑战。SNL允许动态更新模型权重，而Auto-SNL则简化了Python模型到FPGA代码的转换。与hls4ml的基准测试表明，SNL在延迟和资源利用方面具有竞争力或更优。


<details>
  <summary>Details</summary>
Motivation: LCLS-II高通量数据流（高达1 TB/s）对传统数据传输和存储基础设施构成挑战，机器学习（ML）可用于实时数据缩减，但现有ML实现存在延迟过高的问题，不适用于高速实验环境。

Method: 开发了SLAC神经网路库（SNL），一个专门用于在FPGA上部署实时ML推理模型的框架，其特点是能够动态更新模型权重而无需FPGA重新综合。此外，还引入了Auto-SNL，一个Python扩展，用于将Python ML模型转换为SNL兼容的高层综合代码。并通过基准测试将SNL与hls4ml进行了比较。

Result: 在针对Xilinx ZCU102 FPGA的多种神经网络架构、定点精度和综合配置的基准测试中，SNL在大多数测试架构中实现了具有竞争力或更优的延迟，并在某些情况下还节省了FPGA资源。

Conclusion: SNL及其Auto-SNL扩展在处理高通量数据和实时ML推理方面显示出强大的能力和灵活性，为高能物理、医学成像、机器人等领域的研究人员和学者提供了新的机遇。

Abstract: The LCLS-II Free Electron Laser (FEL) will generate X-ray pulses for beamline
experiments at rates of up to 1~MHz, with detectors producing data throughputs
exceeding 1 TB/s. Managing such massive data streams presents significant
challenges, as transmission and storage infrastructures become prohibitively
expensive. Machine learning (ML) offers a promising solution for real-time data
reduction, but conventional implementations introduce excessive latency, making
them unsuitable for high-speed experimental environments. To address these
challenges, SLAC developed the SLAC Neural Network Library (SNL), a specialized
framework designed to deploy real-time ML inference models on
Field-Programmable Gate Arrays (FPGA). SNL's key feature is the ability to
dynamically update model weights without requiring FPGA resynthesis, enhancing
flexibility for adaptive learning applications. To further enhance usability
and accessibility, we introduce Auto-SNL, a Python extension that streamlines
the process of converting Python-based neural network models into
SNL-compatible high-level synthesis code. This paper presents a benchmark
comparison against hls4ml, the current state-of-the-art tool, across multiple
neural network architectures, fixed-point precisions, and synthesis
configurations targeting a Xilinx ZCU102 FPGA. The results showed that SNL
achieves competitive or superior latency in most tested architectures, while in
some cases also offering FPGA resource savings. This adaptation demonstrates
SNL's versatility, opening new opportunities for researchers and academics in
fields such as high-energy physics, medical imaging, robotics, and many more.

</details>


### [144] [Adaptive LLM Routing under Budget Constraints](https://arxiv.org/abs/2508.21141)
*Pranoy Panda,Raghav Magazine,Chaitanya Devaguptapu,Sho Takemori,Vishal Sharma*

Main category: cs.LG

TL;DR: LLM路由可以通过上下文的Bandit问题来解决，通过共享嵌入空间来适应，并使用多项选择背包问题来处理用户预算。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，LLM路由需要动态选择最适合的LLM，但现实世界缺乏完善的映射并且用户查询会不断变化。

Method: 将LLM路由视为上下文Bandit问题，开发共享嵌入空间，并引入多项选择背包问题来处理用户预算。实现了PILOT（Preference-prior Informed Linucb fOr adaptive rouTing）。

Result: PILOT可以适应性地进行决策，而无需对所有查询进行详尽的LLM推理，并能高效地处理用户预算。

Conclusion: LLM路由可以作为上下文Bandit问题进行研究，并开发了PILOT算法来解决这个问题，同时考虑了用户预算。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing,
but their varying capabilities and costs pose challenges in practical
applications. LLM routing addresses this by dynamically selecting the most
suitable LLM for each query/task. Previous approaches treat this as a
supervised learning problem, assuming complete knowledge of optimal query-LLM
pairings. However, real-world scenarios lack such comprehensive mappings and
face evolving user queries. We thus propose to study LLM routing as a
contextual bandit problem, enabling adaptive decision-making using bandit
feedback without requiring exhaustive inference across all LLMs for all queries
(in contrast to supervised routing). To address this problem, we develop a
shared embedding space for queries and LLMs, where query and LLM embeddings are
aligned to reflect their affinity. This space is initially learned from offline
human preference data and refined through online bandit feedback. We
instantiate this idea through Preference-prior Informed Linucb fOr adaptive
rouTing (PILOT), a novel extension of LinUCB. To handle diverse user budgets
for model routing, we introduce an online cost policy modeled as a multi-choice
knapsack problem, ensuring resource-efficient routing.

</details>


### [145] [Privacy Auditing Synthetic Data Release through Local Likelihood Attacks](https://arxiv.org/abs/2508.21146)
*Joshua Ward,Chi-Hua Wang,Guang Cheng*

Main category: cs.LG

TL;DR: 现有的合成数据隐私审计方法存在局限性，无法有效检测训练数据通过合成数据泄露的隐私风险。本文提出了一种名为Generative Likelihood Ratio Attack (Gen-LRA)的新型、高效的无模型成员推理攻击方法，通过评估测试样本对生成模型局部似然比估计的影响来检测隐私泄露。实验结果表明，Gen-LRA在多个性能指标上优于其他针对生成模型的成员推理攻击方法，证明了其在合成数据隐私审计方面的有效性，并揭示了生成模型过拟合带来的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据隐私审计框架依赖启发式方法和不合理的假设，对生成模型的失效模式攻击能力有限，无法有效描述和检测训练数据通过合成数据发布的隐私泄露。

Method: 提出一种名为Generative Likelihood Ratio Attack (Gen-LRA)的新型、高效的无模型成员推理攻击方法。该方法通过评估测试样本对代理模型局部似然比估计的影响来制定攻击策略，无需任何模型知识或访问权限。

Result: 在涵盖不同数据集、模型架构和攻击参数的综合基准测试中，Gen-LRA在多个性能指标上始终优于其他针对生成模型的成员推理攻击方法。

Conclusion: Gen-LRA作为合成数据发布的隐私审计工具非常有效，并强调了生成模型过拟合在实际应用中带来的显著隐私风险。

Abstract: Auditing the privacy leakage of synthetic data is an important but unresolved
problem. Most existing privacy auditing frameworks for synthetic data rely on
heuristics and unreasonable assumptions to attack the failure modes of
generative models, exhibiting limited capability to describe and detect the
privacy exposure of training data through synthetic data release. In this
paper, we study designing Membership Inference Attacks (MIAs) that specifically
exploit the observation that tabular generative models tend to significantly
overfit to certain regions of the training distribution. Here, we propose
Generative Likelihood Ratio Attack (Gen-LRA), a novel, computationally
efficient No-Box MIA that, with no assumption of model knowledge or access,
formulates its attack by evaluating the influence a test observation has in a
surrogate model's estimation of a local likelihood ratio over the synthetic
data. Assessed over a comprehensive benchmark spanning diverse datasets, model
architectures, and attack parameters, we find that Gen-LRA consistently
dominates other MIAs for generative models across multiple performance metrics.
These results underscore Gen-LRA's effectiveness as a privacy auditing tool for
the release of synthetic data, highlighting the significant privacy risks posed
by generative model overfitting in real-world applications.

</details>


### [146] [Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks](https://arxiv.org/abs/2508.21172)
*Matteo Pinna,Andrea Ceni,Claudio Gallicchio*

Main category: cs.LG

TL;DR: 提出了一种名为深度残差回声状态网络（DeepResESN）的新型深度循环神经网络，利用时间残差连接，提高了内存容量和长期时间建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统的 Echo State Networks（ESNs）在处理长期信息时存在困难，本研究旨在解决这一问题。

Method: 提出并研究了一种名为深度残差回声状态网络（DeepResESN）的新型深度递归神经网络，该网络基于时间残差连接，并探索了不同正交配置（包括随机生成和固定结构）对网络动力学的影响，同时进行了数学分析以确保网络动力学的稳定性。

Result: 实验结果表明，DeepResESN 在各种时间序列任务上优于传统的浅层和深度水库计算方法。

Conclusion: 深度残差回声状态网络（DeepResESN）通过利用层次化的非训练残差递归层，显著提高了内存容量和长期时间建模能力，为处理时间序列任务提供了更优的解决方案。

Abstract: Echo State Networks (ESNs) are a particular type of untrained Recurrent
Neural Networks (RNNs) within the Reservoir Computing (RC) framework, popular
for their fast and efficient learning. However, traditional ESNs often struggle
with long-term information processing. In this paper, we introduce a novel
class of deep untrained RNNs based on temporal residual connections, called
Deep Residual Echo State Networks (DeepResESNs). We show that leveraging a
hierarchy of untrained residual recurrent layers significantly boosts memory
capacity and long-term temporal modeling. For the temporal residual
connections, we consider different orthogonal configurations, including
randomly generated and fixed-structure configurations, and we study their
effect on network dynamics. A thorough mathematical analysis outlines necessary
and sufficient conditions to ensure stable dynamics within DeepResESN. Our
experiments on a variety of time series tasks showcase the advantages of the
proposed approach over traditional shallow and deep RC.

</details>


### [147] [FUTURE: Flexible Unlearning for Tree Ensemble](https://arxiv.org/abs/2508.21181)
*Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri*

Main category: cs.LG

TL;DR: FUTURE是一种新颖的树集成模型遗忘算法，通过基于梯度的优化和概率模型近似来解决现有方法的局限性，并在真实世界数据集上实现了高效的遗忘。 


<details>
  <summary>Details</summary>
Motivation: 随着对数据隐私和“被遗忘权”的日益重视，需要一种能够从树集成模型中有效删除敏感信息的方法。现有的遗忘算法通常针对特定模型或依赖于离散的树结构，难以泛化到复杂的集成模型，并且在大规模数据集上效率低下。

Method: 提出了一种名为FUTURE的新型遗忘算法。该算法将遗忘样本的问题表述为一个基于梯度的优化任务，并采用概率模型近似来处理树集成模型中的非可微性，从而实现端到端的遗忘。

Result: 在真实世界数据集上进行的广泛实验表明，FUTURE在遗忘性能方面取得了显著的成功，能够有效地从树集成模型中删除指定样本。

Conclusion: FUTURE通过其新颖的基于梯度优化的方法和概率模型近似，克服了现有树集成模型遗忘算法的局限性，在效率和泛化能力方面均表现出色，为处理数据隐私问题提供了有效的解决方案。

Abstract: Tree ensembles are widely recognized for their effectiveness in
classification tasks, achieving state-of-the-art performance across diverse
domains, including bioinformatics, finance, and medical diagnosis. With
increasing emphasis on data privacy and the \textit{right to be forgotten},
several unlearning algorithms have been proposed to enable tree ensembles to
forget sensitive information. However, existing methods are often tailored to a
particular model or rely on the discrete tree structure, making them difficult
to generalize to complex ensembles and inefficient for large-scale datasets. To
address these limitations, we propose FUTURE, a novel unlearning algorithm for
tree ensembles. Specifically, we formulate the problem of forgetting samples as
a gradient-based optimization task. In order to accommodate
non-differentiability of tree ensembles, we adopt the probabilistic model
approximations within the optimization framework. This enables end-to-end
unlearning in an effective and efficient manner. Extensive experiments on
real-world datasets show that FUTURE yields significant and successful
unlearning performance.

</details>


### [148] [Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium](https://arxiv.org/abs/2508.21186)
*Christopher R. Lee-Jenkins*

Main category: cs.LG

TL;DR: LLM解码可被视为概率单纯形上的约束变分原理，其中离散更新对应乘法权重（熵镜像）更新，连续时间极限为复制子流。研究证明，固定上下文和温度下，下一个token分布沿单纯形轨迹平滑收敛至softmax平衡，这数学上解释了“流形遍历”直觉。该分析表明温度是轨迹上的时间重标度，top-k和nucleus采样则将流限制在具有相同保证的面。此外，还概述了路径依赖分数调整及其与循环式、幻觉式行为的联系。


<details>
  <summary>Details</summary>
Motivation: LLM的解码过程通常被描述为对token进行评分并用softmax进行归一化，本文旨在提供一个最小化、自包含的解释，将其视为概率单纯形上的约束变分原理。

Method: 本文将LLM解码过程形式化为概率单纯形上的约束变分原理，证明了离散更新对应乘法权重（熵镜像）更新，连续时间极限为复制子流。在此基础上，证明了在固定上下文和温度下，下一个token分布遵循单纯形内部的平滑轨迹并收敛于softmax平衡。

Result: 研究证明，对于固定的上下文和温度，下一个token的分布遵循一个在概率单纯形内的平滑轨迹，并最终收敛到softmax平衡状态。此外，分析结果表明温度参数可以精确地表示轨迹上的时间重标度，而top-k和nucleus采样则将该流动限制在一个具有相同保证的面内。文章还简要介绍了路径依赖分数调整及其与循环式、幻觉式行为的联系。

Conclusion: LLM解码过程可以被形式化为概率单纯形上的约束变分原理，揭示了其与乘法权重更新和复制子流的联系，并为温度、top-k和nucleus采样等解码策略提供了理论基础。

Abstract: Decoding in large language models is often described as scoring tokens and
normalizing with softmax. We give a minimal, self-contained account of this
step as a constrained variational principle on the probability simplex. The
discrete, normalization-respecting ascent is the classical
multiplicative-weights (entropic mirror) update; its continuous-time limit is
the replicator flow. From these ingredients we prove that, for a fixed context
and temperature, the next-token distribution follows a smooth trajectory inside
the simplex and converges to the softmax equilibrium. This formalizes the
common ``manifold traversal'' intuition at the output-distribution level. The
analysis yields precise, practice-facing consequences: temperature acts as an
exact rescaling of time along the same trajectory, while top-k and nucleus
sampling restrict the flow to a face with identical guarantees. We also outline
a controlled account of path-dependent score adjustments and their connection
to loop-like, hallucination-style behavior. We make no claims about training
dynamics or internal representations; those are deferred to future work.

</details>


### [149] [Model-Task Alignment Drives Distinct RL Outcomes](https://arxiv.org/abs/2508.21188)
*Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He*

Main category: cs.LG

TL;DR: RL在LLMs中的反直觉现象与模型-任务对齐的关系，强调在模型-任务对齐度高时易出现，而在挑战性任务中标准RL更有效。


<details>
  <summary>Details</summary>
Motivation: 探究近期在LLMs中应用RL时出现的反直觉现象（如单个样本胜过数据集、奖励准确性不重要、仅负样本训练效果好）在何种条件下成立及失败。

Method: 通过系统性实验验证，在不同模型架构和任务域中，考察模型-任务对齐度（以pass@k衡量）对这些反直觉现象的影响，并与标准RL训练进行对比。

Result: 发现许多反直觉结果仅在模型-任务对齐度高时出现，而在更具挑战性的任务中，这些方法效果不佳，标准RL训练则持续有效。

Conclusion: 模型-任务对齐度是区分RL在LLMs中反直觉现象的关键因素。高对齐度模型易现反直觉现象，但标准RL在更广泛的场景下（尤其挑战性任务）更为稳健有效。

Abstract: Recent advances in applying reinforcement learning (RL) to large language
models (LLMs) have led to substantial progress. In particular, a series of
remarkable yet often counterintuitive phenomena have been reported in LLMs,
exhibiting patterns not typically observed in traditional RL settings. For
example, notable claims include that a single training example can match the
performance achieved with an entire dataset, that the reward signal does not
need to be very accurate, and that training solely with negative samples can
match or even surpass sophisticated reward-based methods. However, the precise
conditions under which these observations hold - and, critically, when they
fail - remain unclear. In this work, we identify a key factor that
differentiates RL observations: whether the pretrained model already exhibits
strong Model-Task Alignment, as measured by pass@k accuracy on the evaluated
task. Through a systematic and comprehensive examination of a series of
counterintuitive claims, supported by rigorous experimental validation across
different model architectures and task domains, our findings show that while
standard RL training remains consistently robust across settings, many of these
counterintuitive results arise only when the model and task already exhibit
strong model-task alignment. In contrast, these techniques fail to drive
substantial learning in more challenging regimes, where standard RL methods
remain effective.

</details>


### [150] [Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay](https://arxiv.org/abs/2508.21240)
*Pujan Thapa,Alexander Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 该论文提出了一种基于自组织映射（SOM）和变分自编码器（VAE）的新型生成式持续学习框架，无需存储原始数据样本或任务标签，即可实现内存高效的重放。


<details>
  <summary>Details</summary>
Motivation: 为解决高维输入空间（如CIFAR-10和CIFAR-100）中持续学习的内存效率问题，以及低维输入空间（如MNIST和FashionMNIST）的独立性问题，提出了一种基于SOM和VAE的生成式持续学习框架。

Method: 在VAE学习到的潜在空间上操作SOM，或者在独立的低维输入空间上操作SOM。该方法存储每个SOM单元的运行均值、方差和协方差，并从中生成合成样本用于后续重放。对于基于VAE的方法，生成的样本通过解码器用于后续重放。

Result: 在标准的类别增量基准测试中，该方法在CIFAR-10和CIFAR-100上的性能分别比最佳现有方法提高了近10%和7%。此外，该方法还可以作为训练后的生成模型，并易于可视化学习过程。

Conclusion: 该方法是一种可扩展、无任务标签且内存高效的持续学习解决方案。

Abstract: This work introduces a novel generative continual learning framework based on
self-organizing maps (SOMs) and variational autoencoders (VAEs) to enable
memory-efficient replay, eliminating the need to store raw data samples or task
labels. For high-dimensional input spaces, such as of CIFAR-10 and CIFAR-100,
we design a scheme where the SOM operates over the latent space learned by a
VAE, whereas, for lower-dimensional inputs, such as those found in MNIST and
FashionMNIST, the SOM operates in a standalone fashion. Our method stores a
running mean, variance, and covariance for each SOM unit, from which synthetic
samples are then generated during future learning iterations. For the VAE-based
method, generated samples are then fed through the decoder to then be used in
subsequent replay. Experimental results on standard class-incremental
benchmarks show that our approach performs competitively with state-of-the-art
memory-based methods and outperforms memory-free methods, notably improving
over best state-of-the-art single class incremental performance on CIFAR-10 and
CIFAR-100 by nearly $10$\% and $7$\%, respectively. Our methodology further
facilitates easy visualization of the learning process and can also be utilized
as a generative model post-training. Results show our method's capability as a
scalable, task-label-free, and memory-efficient solution for continual
learning.

</details>


### [151] [RelP: Faithful and Efficient Circuit Discovery via Relevance Patching](https://arxiv.org/abs/2508.21258)
*Farnoush Rezaei Jafari,Oliver Eberle,Ashkan Khakzar,Neel Nanda*

Main category: cs.LG

TL;DR: Relevance Patching (RelP) is a computationally efficient and more faithful method for localizing model components responsible for specific behaviors, improving upon existing methods like activation patching and attribution patching, especially in deep, non-linear networks.


<details>
  <summary>Details</summary>
Motivation: Activation patching is computationally expensive for large-scale model analysis, and attribution patching is noisy and unreliable in deep, non-linear networks. There is a need for a more efficient and reliable method.

Method: Relevance Patching (RelP) replaces the local gradients used in attribution patching with propagation coefficients derived from Layer-wise Relevance Propagation (LRP). LRP works by propagating the network's output backward through the layers, redistributing relevance to lower-level components based on local propagation rules that conserve relevance and improve the signal-to-noise ratio. RelP requires only two forward passes and one backward pass, maintaining computational efficiency.

Result: RelP more accurately approximates activation patching than standard attribution patching, especially for residual stream and MLP outputs in the Indirect Object Identification (IOI) task. For MLP outputs in GPT-2 Large, RelP achieves a Pearson correlation of 0.956, compared to 0.006 for attribution patching. RelP also achieves comparable faithfulness to Integrated Gradients (IG) in identifying sparse feature circuits without the additional computational cost of IG.

Conclusion: RelP is a computationally efficient and faithful method for mechanistic interpretability that improves upon existing techniques by leveraging LRP. It provides a more accurate approximation of activation patching and comparable faithfulness to IG, making it a valuable tool for analyzing deep, non-linear networks.

Abstract: Activation patching is a standard method in mechanistic interpretability for
localizing the components of a model responsible for specific behaviors, but it
is computationally expensive to apply at scale. Attribution patching offers a
faster, gradient-based approximation, yet suffers from noise and reduced
reliability in deep, highly non-linear networks. In this work, we introduce
Relevance Patching (RelP), which replaces the local gradients in attribution
patching with propagation coefficients derived from Layer-wise Relevance
Propagation (LRP). LRP propagates the network's output backward through the
layers, redistributing relevance to lower-level components according to local
propagation rules that ensure properties such as relevance conservation or
improved signal-to-noise ratio. Like attribution patching, RelP requires only
two forward passes and one backward pass, maintaining computational efficiency
while improving faithfulness. We validate RelP across a range of models and
tasks, showing that it more accurately approximates activation patching than
standard attribution patching, particularly when analyzing residual stream and
MLP outputs in the Indirect Object Identification (IOI) task. For instance, for
MLP outputs in GPT-2 Large, attribution patching achieves a Pearson correlation
of 0.006, whereas RelP reaches 0.956, highlighting the improvement offered by
RelP. Additionally, we compare the faithfulness of sparse feature circuits
identified by RelP and Integrated Gradients (IG), showing that RelP achieves
comparable faithfulness without the extra computational cost associated with
IG.

</details>


### [152] [Beyond expected value: geometric mean optimization for long-term policy performance in reinforcement learning](https://arxiv.org/abs/2508.21443)
*Xinyi Sheng,Dominik Baumann*

Main category: cs.LG

TL;DR: RL算法结合了期望累积奖励和时间平均增长率，以优化个体轨迹的长期性能。


<details>
  <summary>Details</summary>
Motivation: 标准的RL算法优化期望累积奖励，但在实际应用中，个体轨迹的表现可能更重要。

Method: 提出了一种新的RL算法，结合了期望累积奖励和时间平均增长率。定义了时间平均增长率的Bellman算子，并表明在乘性奖励动态下，几何平均值与时间平均增长率一致。提出了一种改进的几何平均值与N-滑动窗口，作为时间平均增长率的估计量，并将其嵌入到目标函数中。

Result: 在具有挑战性的模拟中，所提出的算法表现优于传统的RL方法。

Conclusion: 该算法成功地将整体平均性能和个体轨迹性能结合起来，在实际应用中提供了更优越的性能。

Abstract: Reinforcement learning (RL) algorithms typically optimize the expected
cumulative reward, i.e., the expected value of the sum of scalar rewards an
agent receives over the course of a trajectory. The expected value averages the
performance over an infinite number of trajectories. However, when deploying
the agent in the real world, this ensemble average may be uninformative for the
performance of individual trajectories. Thus, in many applications, optimizing
the long-term performance of individual trajectories might be more desirable.
In this work, we propose a novel RL algorithm that combines the standard
ensemble average with the time-average growth rate, a measure for the long-term
performance of individual trajectories. We first define the Bellman operator
for the time-average growth rate. We then show that, under multiplicative
reward dynamics, the geometric mean aligns with the time-average growth rate.
To address more general and unknown reward dynamics, we propose a modified
geometric mean with $N$-sliding window that captures the path-dependency as an
estimator for the time-average growth rate. This estimator is embedded as a
regularizer into the objective, forming a practical algorithm and enabling the
policy to benefit from ensemble average and time-average simultaneously. We
evaluate our algorithm in challenging simulations, where it outperforms
conventional RL methods.

</details>


### [153] [Owen Sampling Accelerates Contribution Estimation in Federated Learning](https://arxiv.org/abs/2508.21261)
*Hossein KhademSohi,Hadi Hemmati,Jiayu Zhou,Steve Drew*

Main category: cs.LG

TL;DR: FedOwen是一个联邦学习框架，使用Owen采样来近似Shapley值，以提高模型收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 准确估计客户贡献对于公平奖励和选择有用客户以加速全局模型收敛至关重要，但精确计算Shapley值成本高昂。

Method: FedOwen框架使用Owen采样来近似Shapley值，并采用自适应客户选择策略来平衡利用高价值客户和探索未充分采样的客户。

Result: 在相同的通信轮数和固定的评估成本下，FedOwen在非IID基准测试上实现了比现有方法高出23%的最终准确性。

Conclusion: FedOwen通过高效的Shapley值近似和自适应客户选择，能够提升联邦学习的收敛速度和模型准确性。

Abstract: Federated Learning (FL) aggregates information from multiple clients to train
a shared global model without exposing raw data. Accurately estimating each
client's contribution is essential not just for fair rewards, but for selecting
the most useful clients so the global model converges faster. The Shapley value
is a principled choice, yet exact computation scales exponentially with the
number of clients, making it infeasible for large federations. We propose
FedOwen, an efficient framework that uses Owen sampling to approximate Shapley
values under the same total evaluation budget as existing methods while keeping
the approximation error small. In addition, FedOwen uses an adaptive client
selection strategy that balances exploiting high-value clients with exploring
under-sampled ones, reducing bias and uncovering rare but informative data.
Under a fixed valuation cost, FedOwen achieves up to 23 percent higher final
accuracy within the same number of communication rounds compared to
state-of-the-art baselines on non-IID benchmarks.

</details>


### [154] [Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation](https://arxiv.org/abs/2508.21270)
*Roland Arnold*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Guess-and-Learn (G&L)的评估框架，用于衡量机器学习模型在冷启动阶段的适应能力，即在从头开始学习时累积的总错误，以补充传统的最终准确率评估。G&L通过模拟模型顺序标记数据集的过程，记录每次预测、接收真实标签和参数更新（在线或批量模式）产生的错误轨迹，从而揭示模型的适应速度、选择质量和偏差。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习模型时，通常只关注最终的准确率，而忽略了模型在从头开始学习过程中累积的错误成本，即冷启动适应成本。本研究旨在填补这一空白，提出一种新的评估方法。

Method: Guess-and-Learn (G&L) v1.0框架通过模拟模型在从头开始学习时顺序标记未标记数据集的过程来衡量冷启动适应性。在每个步骤中，学习器选择一个实例，预测其标签，接收真实标签，并根据在线（每个样本）或批量（延迟）模式更新参数。通过分析由此产生的错误轨迹，可以了解适应速度、选择质量和偏差等动态。

Result: 在MNIST和AG News数据集上进行的基线实验，涵盖了感知器、kNN、CNN、ResNet-50、ViT-B/16和BERT-base等模型，揭示了模型在早期学习阶段效率的系统性差异。结果表明，小型模型可以用更少的初始错误进行适应，而预训练的收益因领域而异。所有模型在适应性方面均远高于估计的“神谕参考带”，表明存在适应性差距。

Conclusion: Guess-and-Learn (G&L)通过量化早期学习的错误成本，为机器学习模型的评估提供了新的视角，补充了传统的基准测试。该框架提供了一个可复现的评估体系，有助于开发不仅在最终结果上准确，而且从一开始就可靠的学习模型。

Abstract: Evaluation of machine learning models typically emphasizes final accuracy,
overlooking the cost of adaptation: the cumulative errors incurred while
learning from scratch. Guess-and- Learn (G&L) v1.0 addresses this gap by
measuring cold-start adaptability - the total mistakes a model makes while
sequentially labeling an unlabeled dataset. At each step, the learner selects
an instance, predicts its label, receives the ground truth, and updates
parameters under either online (per-sample) or batch (delayed) mode. The
resulting error trajectory exposes adaptation speed, selection quality, and
bias - dynamics invisible to endpoint metrics.
  G&L defines four tracks (Scratch/Pretrained $\times$ Online/Batch) to
disentangle the effects of initialization and update frequency. We formalize
the protocol, relate it to classical mistake-bound theory, and estimate a
heuristic "oracle reference band" for MNIST as a plausibility reference.
Baseline experiments on MNIST and AG News, spanning classical methods
(Perceptron, k-NN), convolutional architectures (CNN, ResNet-50), and
pretrained transformers (ViT-B/16, BERT-base), reveal systematic differences in
early-phase efficiency: smaller models can adapt with fewer initial errors,
while pretraining benefits vary by domain. Across settings, current models
remain well above the oracle band, highlighting an adaptability gap.
  By quantifying the mistake cost of early learning, G&L complements
conventional benchmarks and provides a reproducible framework for developing
learners that are not only accurate in the limit but also reliable from the
first examples.

</details>


### [155] [CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams](https://arxiv.org/abs/2508.21273)
*Ashok Devireddy,Shunping Huang*

Main category: cs.LG

TL;DR: CALM是一个创新的端到端框架，用于实时检测非平稳时间序列流中的异常。它通过连续微调和LLM-as-a-Judge组件来适应概念漂移，并在TSB-UAD基准测试中取得了优于静态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在非平稳时间序列流中检测异常的挑战，特别是由于概念漂移导致的传统离线训练模型性能下降问题。

Method: CALM框架基于Apache Beam，利用TimesFm基础模型进行基于预测的异常检测。它包含一个闭环的连续微调机制，使模型能够近乎实时地适应数据模式的变化，并引入了一个LLM-as-a-Judge组件，利用大型语言模型对检测到的异常进行语义和上下文感知的判断，以生成高质量的训练数据集。

Result: 在TSB-UAD基准测试中的结果表明，与静态的预训练基础模型相比，CALM的连续微调模型在大多数数据集中提高了ROC AUC分数。

Conclusion: CALM框架通过其自适应和LLM指导的方法，有效地在动态流数据环境中维持了高性能的异常检测能力，证明了其在概念漂移下的鲁棒性。

Abstract: The detection of anomalies in non-stationary time-series streams is a
critical but challenging task across numerous industrial and scientific
domains. Traditional models, trained offline, suffer significant performance
degradation when faced with concept drift, where the underlying statistical
properties of the data change over time. This paper introduces CALM
(Continuous, Adaptive, and LLM-Mediated), a novel, end-to-end framework for
real-time anomaly detection designed to address this challenge. CALM is built
on the Apache Beam distributed processing framework and leverages the TimesFm
foundation model for forecasting-based anomaly detection. The framework's
novelty lies in two core contributions. First, it implements a closed-loop,
continuous fine-tuning mechanism that allows the anomaly detection model to
adapt to evolving data patterns in near real-time. Second, it introduces an
LLM-as-a-Judge component, a Large Language Model that provides semantic,
context-aware judgments on detected anomalies to curate a high-quality training
dataset, deciding whether an anomaly represents transient noise or a meaningful
pattern shift. We evaluate CALM on the comprehensive TSB-UAD benchmark. Our
results demonstrate that the continuously fine-tuned model improves the ROC AUC
score in most datasets compared to the static, pre-trained base model,
validating the efficacy of our adaptive, LLM-guided approach to maintaining
high-performance anomaly detection in dynamic streaming environments.

</details>


### [156] [Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning](https://arxiv.org/abs/2508.21278)
*Yibin Sun,Nick Lim,Guilherme Weigert Cassales,Heitor Murilo Gomes,Bernhard Pfahringer,Albert Bifet,Anany Dwivedi*

Main category: cs.LG

TL;DR: 该论文研究了在肌电信号（EMG）中检测领域转移的问题，该问题由于EMG信号固有的非平稳性而具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 肌电信号（EMG）的非平稳性使得在EMG信号中检测领域转移成为一个重大挑战。

Method: 该研究探索了使用数据流（DS）学习技术检测领域转移，重点关注Ninapro数据库的DB6数据集。通过将不同的被试和记录会话定义为不同的时间序列段，并应用具有余弦核的核主成分分析（KPCA）进行预处理和突出显示这些转移。研究评估了多种漂移检测方法，如CUSUM、Page-Hinckley和ADWIN。

Result: 研究结果表明，当前用于EMG信号实时领域转移检测的技术在实现高性能方面存在局限性。

Conclusion: 该研究强调了基于流的方法在维持稳定的EMG解码模型方面的潜力，同时也指出了在实际场景中提高鲁棒性和准确性方面需要进一步研究的领域。

Abstract: Detecting domain shifts in myoelectric activations poses a significant
challenge due to the inherent non-stationarity of electromyography (EMG)
signals. This paper explores the detection of domain shifts using data stream
(DS) learning techniques, focusing on the DB6 dataset from the Ninapro
database. We define domains as distinct time-series segments based on different
subjects and recording sessions, applying Kernel Principal Component Analysis
(KPCA) with a cosine kernel to pre-process and highlight these shifts. By
evaluating multiple drift detection methods such as CUSUM, Page-Hinckley, and
ADWIN, we reveal the limitations of current techniques in achieving high
performance for real-time domain shift detection in EMG signals. Our results
underscore the potential of streaming-based approaches for maintaining stable
EMG decoding models, while highlighting areas for further research to enhance
robustness and accuracy in real-world scenarios.

</details>


### [157] [MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems](https://arxiv.org/abs/2508.21296)
*Shihao Ji,Zihui Song*

Main category: cs.LG

TL;DR: MyGO是一个新颖的终身学习框架，受唤醒-睡眠周期启发，通过生成伪数据来防止灾难性遗忘，在计算机视觉和自然语言处理任务上表现优异，并且具有隐私和存储优势。


<details>
  <summary>Details</summary>
Motivation: 现有的终身学习方法依赖经验回放或复杂的正则化项来防止灾难性遗忘，但这会带来数据隐私、存储限制和任务不相似时的性能下降等问题。本研究旨在解决这些挑战。

Method: MyGO框架包含两个阶段：1. 唤醒阶段：快速学习新任务，并训练一个紧凑的生成模型（G-mem）来捕捉数据分布。2. 睡眠阶段：利用所有已学习的G-mem模型生成伪数据（“梦境”），并通过知识蒸馏将新旧知识整合到核心特征提取器中。该方法无需存储原始数据，只需存储紧凑的生成模型。

Result: 在Split-MNIST和Split-AG News基准测试中，MyGO显著减轻了灾难性遗忘，并保持了跨任务的高平均准确率，优于顺序微调基线。

Conclusion: MyGO通过结合生成模型和知识蒸馏，有效解决了终身学习中的灾难性遗忘问题，并在隐私和存储效率方面具有显著优势，证明了其在不同领域的有效性和通用性。

Abstract: Continual or Lifelong Learning aims to develop models capable of acquiring
new knowledge from a sequence of tasks without catastrophically forgetting what
has been learned before. Existing approaches often rely on storing samples from
previous tasks (experience replay) or employing complex regularization terms to
protect learned weights. However, these methods face challenges related to data
privacy, storage limitations, and performance degradation when tasks are
dissimilar. To address these challenges, we introduce MyGO (Memory Yielding
Generative Offline-consolidation), a novel lifelong learning framework inspired
by the biological wake-sleep cycle. During the "wake" phase, the system rapidly
learns a new task and trains a compact generative model (Generative Memory,
G-mem) to capture its data distribution. During the "sleep" phase, the system
enters an offline state, using all learned G-mem models to generate pseudo-data
("dreams") and consolidate new and old knowledge into a core feature extractor
via knowledge distillation. This approach obviates the need to store any raw
data, retaining only compact generative models, which offers significant
advantages in privacy and storage efficiency. We evaluate MyGO on computer
vision (Split-MNIST) and natural language processing (Split-AG News)
benchmarks, comparing it against a sequential fine-tuning baseline. The results
demonstrate that MyGO significantly mitigates catastrophic forgetting and
maintains high average accuracy across tasks, proving the framework's
effectiveness and domain-generality.

</details>


### [158] [Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning](https://arxiv.org/abs/2508.21300)
*Yejin Kim,Eunwon Kim,Buru Chang,Junsuk Choe*

Main category: cs.LG

TL;DR: FILA and VILA are methods for machine unlearning in LLMs, aiming to remove sensitive information efficiently. FILA uses LoRA adapters and Fisher information but requires full model access and has inaccuracies. VILA improves upon FILA by addressing its assumptions, enabling parameter identification without full model access, resulting in higher parameter efficiency and faster training.


<details>
  <summary>Details</summary>
Motivation: LLMs unintentionally generate sensitive information, and retraining is computationally expensive. Machine unlearning offers a solution. FILA uses LoRA and Fisher information but has limitations.

Method: FILA integrates LoRA adapters and Fisher information to identify parameters for updates. VILA improves upon FILA by addressing Fisher information assumptions and enabling parameter identification without full model access.

Result: VILA achieves up to 100x higher parameter efficiency and 40x faster training speed compared to FILA, setting new state-of-the-art performance on TOFU, WMDP, and MUSE benchmarks.

Conclusion: VILA is a novel and efficient machine unlearning framework that overcomes the limitations of FILA by accurately identifying parameters for sensitive information removal without full model access.

Abstract: LLMs have demonstrated remarkable performance across various tasks but face
challenges related to unintentionally generating outputs containing sensitive
information. A straightforward approach to address this issue is to retrain the
model after excluding the problematic data. However, this approach incurs
prohibitively high computational costs. To overcome this limitation, machine
unlearning has emerged as a promising solution that can effectively remove
sensitive information without the need to retrain the model from scratch.
Recently, FILA has been proposed as a parameter-efficient unlearning method by
integrating LoRA adapters. Specifically, it calculates the Fisher information
to identify parameters associated with the forget set and assigns them to LoRA
adapters for updates. Despite its innovative approach, FILA still requires
access to all model parameters and does not adequately account for fundamental
assumptions underlying Fisher information, leading to inaccuracies in
importance estimation. To address these limitations, we propose VILA, a novel
unlearning framework that explicitly considers the assumptions overlooked in
FILA, thereby enhancing the accuracy of parameter identification for the forget
set. Moreover, VILA significantly reduces computational costs by enabling
parameter identification without accessing the entire model. Our method
achieves up to 100x higher parameter efficiency and 40x faster training speed
compared to FILA, and sets new state-of-the-art performance on benchmarks
including TOFU, WMDP, and MUSE. Our code is available at
https://github.com/kyj93790/VILA.

</details>


### [159] [Convergence of regularized agent-state-based Q-learning in POMDPs](https://arxiv.org/abs/2508.21314)
*Amit Sinha,Matthieu Geist,Aditya Mahajan*

Main category: cs.LG

TL;DR: 本研究提出了一个用于理解常用Q学习强化学习算法收敛性的框架，特别关注代理状态更新和策略正则化。


<details>
  <summary>Details</summary>
Motivation: 为了理解在实际应用中常用Q学习算法的收敛性，特别是在代理状态（非信念状态或信息状态）更新和策略正则化被用于鼓励探索和稳定学习算法的情况下。

Method: 研究了最简单的以此类Q学习算法为基础的形式，称为正则化代理状态Q学习（RASQL），并证明了其在温和的技术条件下收敛到适当定义的正则化马尔可夫决策过程（MDP）的固定点。这种收敛性依赖于行为策略引起的平稳分布。此外，研究还表明类似的分析也适用于学习周期性策略的RASQL变体。

Result: 证明了RASQL及其周期性策略变体在温和的技术条件下收敛到正则化MDP的固定点，该固定点依赖于行为策略的平稳分布。

Conclusion: RASQL算法及其周期性策略变体在特定条件下可以收敛，并且理论分析与数值实验结果一致。

Abstract: In this paper, we present a framework to understand the convergence of
commonly used Q-learning reinforcement learning algorithms in practice. Two
salient features of such algorithms are: (i)~the Q-table is recursively updated
using an agent state (such as the state of a recurrent neural network) which is
not a belief state or an information state and (ii)~policy regularization is
often used to encourage exploration and stabilize the learning algorithm. We
investigate the simplest form of such Q-learning algorithms which we call
regularized agent-state-based Q-learning (RASQL) and show that it converges
under mild technical conditions to the fixed point of an appropriately defined
regularized MDP, which depends on the stationary distribution induced by the
behavioral policy. We also show that a similar analysis continues to work for a
variant of RASQL that learns periodic policies. We present numerical examples
to illustrate that the empirical convergence behavior matches with the proposed
theoretical limit.

</details>


### [160] [Distribution-Aware Feature Selection for SAEs](https://arxiv.org/abs/2508.21324)
*Narmeen Oozeer,Nirmalendu Prakash,Michael Lan,Alice Rigg,Amirali Abdullah*

Main category: cs.LG

TL;DR: Sampled-SAE是一种改进的稀疏自编码器（SAE），通过在批处理激活矩阵中采样特征来提高效率和可解释性，解决了TopK SAE的激活彩票问题，并在不同l值下提供了可调的性能权衡。


<details>
  <summary>Details</summary>
Motivation: 现有TopK SAE在处理信息量不均的token时效率低下，并存在激活彩票问题；需要一种方法来平衡全局一致性和细粒度重构。

Method: 提出Sampled-SAE，通过计算批处理激活矩阵中特征的L2范数或熵来评分，形成候选特征池，然后从中选择Top-K特征来重构token。通过调整参数l来控制特征池的大小，从而在全局特征选择和token特定特征选择之间进行权衡。

Result: 在Pythia-160M模型上，Sampled-SAE在不同l值下表现出不同的性能权衡，没有单一最优值，需要根据共享结构、重构保真度和下游性能等指标进行选择。

Conclusion: Sampled-SAE将BatchTopK重新定义为一个可调的、分布感知的SAE系列，允许在重构保真度和全局结构一致性之间进行权衡。

Abstract: Sparse autoencoders (SAEs) decompose neural activations into interpretable
features. A widely adopted variant, the TopK SAE, reconstructs each token from
its K most active latents. However, this approach is inefficient, as some
tokens carry more information than others. BatchTopK addresses this limitation
by selecting top activations across a batch of tokens. This improves average
reconstruction but risks an "activation lottery," where rare high-magnitude
features crowd out more informative but lower-magnitude ones. To address this
issue, we introduce Sampled-SAE: we score the columns (representing features)
of the batch activation matrix (via $L_2$ norm or entropy), forming a candidate
pool of size $Kl$, and then apply Top-$K$ to select tokens across the batch
from the restricted pool of features. Varying $l$ traces a spectrum between
batch-level and token-specific selection. At $l=1$, tokens draw only from $K$
globally influential features, while larger $l$ expands the pool toward
standard BatchTopK and more token-specific features across the batch. Small $l$
thus enforces global consistency; large $l$ favors fine-grained reconstruction.
On Pythia-160M, no single value optimizes $l$ across all metrics: the best
choice depends on the trade-off between shared structure, reconstruction
fidelity, and downstream performance. Sampled-SAE thus reframes BatchTopK as a
tunable, distribution-aware family.

</details>


### [161] [Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models](https://arxiv.org/abs/2508.21330)
*Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang*

Main category: cs.LG

TL;DR: Stage-Diff是一个基于扩散模型、用于长期时间序列生成的分段生成模型，通过分段生成和跨段信息传递来处理长期依赖和数据分布变化，并结合通道独立建模和多通道融合建模来解决序列内和序列间的依赖性问题。


<details>
  <summary>Details</summary>
Motivation: 处理长期时间序列生成中的挑战，包括长时依赖性、数据分布随时间变化的漂移，以及序列内和序列间的复杂依赖关系。

Method: 提出Stage-Diff模型，采用分段生成和跨段信息传递来保留长期依赖和建模数据分布变化。在每个阶段内，使用渐进序列分解进行通道独立建模，而跨段信息传递则使用多通道融合建模。

Result: 在多个真实世界数据集上进行的广泛实验证明了Stage-Diff在长期时间序列生成任务中的有效性。

Conclusion: Stage-Diff能够有效地平衡长期时间序列的序列内和序列间依赖性，成功解决了长期时间序列生成中的关键挑战。

Abstract: Generative models have been successfully used in the field of time series
generation. However, when dealing with long-term time series, which span over
extended periods and exhibit more complex long-term temporal patterns, the task
of generation becomes significantly more challenging. Long-term time series
exhibit long-range temporal dependencies, but their data distribution also
undergoes gradual changes over time. Finding a balance between these long-term
dependencies and the drift in data distribution is a key challenge. On the
other hand, long-term time series contain more complex interrelationships
between different feature sequences, making the task of effectively capturing
both intra-sequence and inter-sequence dependencies another important
challenge. To address these issues, we propose Stage-Diff, a staged generative
model for long-term time series based on diffusion models. First, through
stage-wise sequence generation and inter-stage information transfer, the model
preserves long-term sequence dependencies while enabling the modeling of data
distribution shifts. Second, within each stage, progressive sequence
decomposition is applied to perform channel-independent modeling at different
time scales, while inter-stage information transfer utilizes multi-channel
fusion modeling. This approach combines the robustness of channel-independent
modeling with the information fusion advantages of multi-channel modeling,
effectively balancing the intra-sequence and inter-sequence dependencies of
long-term time series. Extensive experiments on multiple real-world datasets
validate the effectiveness of Stage-Diff in long-term time series generation
tasks.

</details>


### [162] [DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks](https://arxiv.org/abs/2508.21340)
*Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang*

Main category: cs.LG

TL;DR: DLGAN通过序列特征提取和序列重建来生成时间序列，解决了现有方法在保证时间依赖性和捕获特征信息方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列合成方法在保证时间依赖性和捕获原始时间序列特征信息方面存在不足。

Method: 提出了一种名为DLGAN的双层生成对抗网络，将时间序列生成过程分解为序列特征提取和序列重建两个阶段，其中包含一个时间序列自编码器和一个生成对抗网络。

Result: 在四个公共数据集上的广泛实验表明，DLGAN在各种评估指标上优于现有模型。

Conclusion: DLGAN是一种有效的时间序列合成模型，能够很好地保留时间序列的依赖关系和特征信息。

Abstract: Time series synthesis is an effective approach to ensuring the secure
circulation of time series data. Existing time series synthesis methods
typically perform temporal modeling based on random sequences to generate
target sequences, which often struggle to ensure the temporal dependencies in
the generated time series. Additionally, directly modeling temporal features on
random sequences makes it challenging to accurately capture the feature
information of the original time series. To address the above issues, we
propose a simple but effective generative model \textbf{D}ual-\textbf{L}ayer
\textbf{G}enerative \textbf{A}dversarial \textbf{N}etworks, named
\textbf{DLGAN}. The model decomposes the time series generation process into
two stages: sequence feature extraction and sequence reconstruction. First,
these two stages form a complete time series autoencoder, enabling supervised
learning on the original time series to ensure that the reconstruction process
can restore the temporal dependencies of the sequence. Second, a Generative
Adversarial Network (GAN) is used to generate synthetic feature vectors that
align with the real-time sequence feature vectors, ensuring that the generator
can capture the temporal features from real time series. Extensive experiments
on four public datasets demonstrate the superiority of this model across
various evaluation metrics.

</details>


### [163] [Adaptive Heavy-Tailed Stochastic Gradient Descent](https://arxiv.org/abs/2508.21353)
*Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux*

Main category: cs.LG

TL;DR: AHTSGD是一种通过自适应调整梯度噪声的“尾部”来加速收敛到宽阔最小值并提高泛化能力的优化算法，尤其在早期训练和处理噪声数据时表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前大规模神经网络优化器过度依赖训练损失，导致泛化能力不足。论文作者观察到梯度噪声的重尾分布和神经网络训练中的“稳定性边缘”现象，旨在通过调整噪声特性来改善泛化。

Method: 提出了一种名为自适应重尾随机梯度下降（AHTSGD）的算法，该算法在训练早期注入重尾噪声以增强探索，并随着损失景观曲率的稳定逐渐过渡到轻尾噪声，从而加速收敛到宽阔最小值。

Result: AHTSGD在MNIST、CIFAR-10等基准测试以及SVHN等含噪声数据集上，相较于SGD和其他基于噪声的方法均表现出优越性能，尤其在处理不良初始化和噪声数据方面效果显著。

Conclusion: AHTSGD通过动态适应损失景观的曲率来调整注入优化器的噪声特性，是首个利用“稳定性边缘”现象来调整噪声性质的算法，能够加速早期训练、提高泛化能力，并在各种设置下保持鲁棒性。

Abstract: In the era of large-scale neural network models, optimization algorithms
often struggle with generalization due to an overreliance on training loss. One
key insight widely accepted in the machine learning community is the idea that
wide basins (regions around a local minimum where the loss increases gradually)
promote better generalization by offering greater stability to small changes in
input data or model parameters. In contrast, sharp minima are typically more
sensitive and less stable. Motivated by two key empirical observations - the
inherent heavy-tailed distribution of gradient noise in stochastic gradient
descent and the Edge of Stability phenomenon during neural network training, in
which curvature grows before settling at a plateau, we introduce Adaptive Heavy
Tailed Stochastic Gradient Descent (AHTSGD). The algorithm injects
heavier-tailed noise into the optimizer during the early stages of training to
enhance exploration and gradually transitions to lighter-tailed noise as
sharpness stabilizes. By dynamically adapting to the sharpness of the loss
landscape throughout training, AHTSGD promotes accelerated convergence to wide
basins. AHTSGD is the first algorithm to adjust the nature of injected noise
into an optimizer based on the Edge of Stability phenomenon. AHTSGD
consistently outperforms SGD and other noise-based methods on benchmarks like
MNIST and CIFAR-10, with marked gains on noisy datasets such as SVHN. It
ultimately accelerates early training from poor initializations and improves
generalization across clean and noisy settings, remaining robust to learning
rate choices.

</details>


### [164] [Iterative Inference in a Chess-Playing Neural Network](https://arxiv.org/abs/2508.21380)
*Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: 神经网络在表示学习中可能并非总是通过平滑、渐进的精炼，而是涉及更复杂的计算过程，具体体现在Leela Chess Zero的策略网络中，其层级间虽有明确的胜率和解谜能力提升趋势，但策略分布却呈现出不平滑的轨迹，例如早期发现的正确走法被后续层丢弃，以及策略分布在后期才趋于稳定。


<details>
  <summary>Details</summary>
Motivation: 探索神经网络（特别是Leela Chess Zero的策略网络）在表示学习过程中是通过平滑的渐进精炼还是更复杂的计算过程。

Method: 扩展Logit Lens方法，分析Leela Chess Zero的策略网络。

Result: 发现在层级之间存在显著的胜率和解谜能力单调增长趋势，但策略分布的轨迹并不平滑，例如存在正确答案先被发现后又被丢弃的情况，落子排名与最终输出相关性较低，以及策略分布在后期才显著分化。

Conclusion: Leela Chess Zero的策略网络在表示学习中可能涉及不平滑的计算过程，这与在语言模型中观察到的平滑分布收敛现象形成对比。

Abstract: Do neural networks build their representations through smooth, gradual
refinement, or via more complex computational processes? We investigate this by
extending the logit lens to analyze the policy network of Leela Chess Zero, a
superhuman chess engine. We find strong monotonic trends in playing strength
and puzzle-solving ability across layers, yet policy distributions frequently
follow non-smooth trajectories. Evidence for this includes correct puzzle
solutions that are discovered early but subsequently discarded, move rankings
that remain poorly correlated with final outputs, and high policy divergence
until late in the network. These findings contrast with the smooth
distributional convergence typically observed in language models.

</details>


### [165] [PMODE: Theoretically Grounded and Modular Mixture Modeling](https://arxiv.org/abs/2508.21396)
*Robert A. Vandermeulen*

Main category: cs.LG

TL;DR: PMODE是一个通用的、模块化的混合模型框架，可以处理参数和非参数组件。它通过划分数据并将单独的估计器拟合到每个子集来构建混合模型，在混合模型组件来自不同分布族时也保持有效。


<details>
  <summary>Details</summary>
Motivation: 介绍PMODE框架，这是一个通用的、模块化的混合模型框架，用于处理参数和非参数组件，并展示其在混合模型组件来自不同分布族时的有效性。

Method: PMODE通过划分数据并将单独的估计器拟合到每个子集来构建混合模型。MV-PMODE是PMODE的一个应用，可以扩展到高维数据，并在CIFAR-10异常检测任务中与深度基线模型进行比较。

Result: PMODE能够达到近乎最优的估计器类别速率。MV-PMODE在CIFAR-10异常检测任务中表现出与深度基线模型相当的性能。

Conclusion: PMODE是一个强大的混合建模框架，可用于高维密度估计，并在实际应用中显示出有希望的结果。

Abstract: We introduce PMODE (Partitioned Mixture Of Density Estimators), a general and
modular framework for mixture modeling with both parametric and nonparametric
components. PMODE builds mixtures by partitioning the data and fitting separate
estimators to each subset. It attains near-optimal rates for this estimator
class and remains valid even when the mixture components come from different
distribution families. As an application, we develop MV-PMODE, which scales a
previously theoretical approach to high-dimensional density estimation to
settings with thousands of dimensions. Despite its simplicity, it performs
competitively against deep baselines on CIFAR-10 anomaly detection.

</details>


### [166] [Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing](https://arxiv.org/abs/2508.21420)
*Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele*

Main category: cs.LG

TL;DR: 利用挪威移动网络数据，通过水库计算和代理任务来监测通信和移动网络状态，成本低廉且非侵入性。


<details>
  <summary>Details</summary>
Motivation: 展示一种低成本、非侵入性的方法，利用移动网络利用率数据来监测通信和移动网络的状态。

Method: 将网络数据转化为水库计算框架内的模型，并测量模型在代理任务上的性能，其中水库计算使用回声状态网络（ESN）将输入信号投影到高维空间，然后由单个训练层进行操作。

Result: 实验表明，在代理任务上的性能与网络的实际状态相关，并且当扰乱网络时，性能会明显下降。

Conclusion: 虽然这项工作是概念验证，但有潜力用于近乎实时的监测以及识别移动通信和交通网络的潜在薄弱环节。

Abstract: Using data from mobile network utilization in Norway, we showcase the
possibility of monitoring the state of communication and mobility networks with
a non-invasive, low-cost method. This method transforms the network data into a
model within the framework of reservoir computing and then measures the model's
performance on proxy tasks. Experimentally, we show how the performance on
these proxies relates to the state of the network. A key advantage of this
approach is that it uses readily available data sets and leverages the
reservoir computing framework for an inexpensive and largely agnostic method.
Data from mobile network utilization is available in an anonymous, aggregated
form with multiple snapshots per day. This data can be treated like a weighted
network. Reservoir computing allows the use of weighted, but untrained networks
as a machine learning tool. The network, initialized as a so-called echo state
network (ESN), projects incoming signals into a higher dimensional space, on
which a single trained layer operates. This consumes less energy than deep
neural networks in which every weight of the network is trained. We use
neuroscience inspired tasks and trained our ESN model to solve them. We then
show how the performance depends on certain network configurations and also how
it visibly decreases when perturbing the network. While this work serves as
proof of concept, we believe it can be elevated to be used for near-real-time
monitoring as well as the identification of possible weak spots of both mobile
communication networks as well as transportation networks.

</details>


### [167] [Rethinking Layer-wise Model Merging through Chain of Merges](https://arxiv.org/abs/2508.21421)
*Pietro Buzzega,Riccardo Salami,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: 现有的模型合并技术无法处理层间依赖性，导致分布不匹配。我们提出了一种名为CoM的层级合并方法，通过自回归更新激活统计数据来解决这个问题，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着特定任务模型数量的增加，在不重新训练的情况下将它们合并成一个统一模型变得至关重要，但现有技术未能解决层间依赖性问题。

Method: 提出一种名为Chain of Merges (CoM)的层级合并程序，通过自回归方式更新激活统计数据，显式考虑跨层交互，以解决内部协变量偏移问题。

Result: CoM在标准基准测试中实现了最先进的性能。

Conclusion: CoM通过一系列条件最优更新，产生了一个连贯的合并模型，有效缓解了由协变量偏移引起性能下降的问题。

Abstract: Fine-tuning pretrained models has become a standard pathway to achieve
state-of-the-art performance across a wide range of domains, leading to a
proliferation of task-specific model variants. As the number of such
specialized modules in-creases, merging them into a unified model without
retraining has become a critical challenge. Existing merging techniques often
rely on interference heuristics,importance weighting, or activation matching
while treating each layer independently, thereby failing to account for the
inter-layer dependencies inherent in deep networks. This simplification leads
to distributional mismatches, especially inactivation-based methods, when
changes in early layers are not properly reflected in downstream ones. We
identify these mismatches as a form of internal covariate shift, comparable to
the phenomenon encountered in the initial phases of neural networks training.
To address it, we propose Chain of Merges (CoM), a layer-wise merging procedure
that updates activation statistics in an auto-regressive fashion, explicitly
accounting for cross-layer interactions. CoM produces a coherent merged model
through a series of conditionally optimal updates, effectively mitigating
degradation caused by covariate shift. Experiments on standard bench-marks
demonstrate that CoM achieves state-of-the-art performance.

</details>


### [168] [Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing](https://arxiv.org/abs/2508.21438)
*Rajiv Kailasanathan,William R. Clements,Mohammad Reza Boskabadi,Shawn M. Gibford,Emmanouil Papadakis,Christopher J. Savoie,Seyed Soheil Mansouri*

Main category: cs.LG

TL;DR: 提出了一种基于生成对抗网络（GAN）的连续生物制造无监督异常检测新框架，并探索了量子/经典混合GAN方法的应用，以提高异常检测率。


<details>
  <summary>Details</summary>
Motivation: 连续生物制造过程需要早期鲁棒的异常检测，因为微小偏差会影响产量、稳定性、生产计划、周产量和经济效益。这些过程复杂且具有非线性动力学，变量间关系复杂，需要高级异常检测方法。

Method: 提出了一种基于生成对抗网络（GAN）的连续生物制造无监督异常检测框架。首先，建立了模拟正常和异常操作条件的小分子连续生产过程基准数据集。然后，展示了基于GAN的框架检测由进料波动引起的异常的有效性。最后，评估了混合量子/经典GAN方法（包括模拟量子电路和真实光量子处理器）在异常检测性能上的影响。

Result: 研究发现，混合方法提高了异常检测率。

Conclusion: 该研究展示了混合量子/经典方法在解决复杂连续生物制造过程中的实际问题潜力。

Abstract: The development of continuous biomanufacturing processes requires robust and
early anomaly detection, since even minor deviations can compromise yield and
stability, leading to disruptions in scheduling, reduced weekly production, and
diminished economic performance. These processes are inherently complex and
exhibit non-linear dynamics with intricate relationships between process
variables, thus making advanced methods for anomaly detection essential for
efficient operation. In this work, we present a novel framework for
unsupervised anomaly detection in continuous biomanufacturing based on an
ensemble of generative adversarial networks (GANs). We first establish a
benchmark dataset simulating both normal and anomalous operation regimes in a
continuous process for the production of a small molecule. We then demonstrate
the effectiveness of our GAN-based framework in detecting anomalies caused by
sudden feedstock variability. Finally, we evaluate the impact of using a hybrid
quantum/classical GAN approach with both a simulated quantum circuit and a real
photonic quantum processor on anomaly detection performance. We find that the
hybrid approach yields improved anomaly detection rates. Our work shows the
potential of hybrid quantum/classical approaches for solving real-world
problems in complex continuous biomanufacturing processes.

</details>


### [169] [Normalized Maximum Likelihood Code-Length on Riemannian Manifold Data Spaces](https://arxiv.org/abs/2508.21466)
*Kota Fukuzawa,Atsushi Suzuki,Kenji Yamanishi*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Rm-NML的新型归一化最大似然估计量，它能够有效处理双曲空间等黎曼流形上的数据，并克服了传统NML在欧氏空间中对坐标系选择的依赖性。


<details>
  <summary>Details</summary>
Motivation: 随着图数据规模的扩大，黎曼流形（特别是双曲空间）在表示具有层级结构的数据方面展现出强大能力。然而，传统的归一化最大似然估计（NML）主要在欧氏空间中发展，且依赖于坐标系选择，难以直接应用于黎曼流形。

Method: 研究者定义了一种新的NML，称为Rm-NML，该方法能够反映黎曼流形的几何结构，并且在坐标变换下保持不变。他们将现有的NML计算技术扩展到黎曼流形，并推导了一种简化Rm-NML在黎曼对称空间（包括双曲空间）上计算的方法。

Result: 研究明确计算了双曲空间上正态分布的Rm-NML，展示了该方法在实际应用中的可行性。

Conclusion: Rm-NML是一种在黎曼流形上进行模型选择和遗憾最小化的有效工具，尤其适用于双曲空间等具有挑战性的数据空间。

Abstract: In recent years, with the large-scale expansion of graph data, there has been
an increased focus on Riemannian manifold data spaces other than Euclidean
space. In particular, the development of hyperbolic spaces has been remarkable,
and they have high expressive power for graph data with hierarchical
structures. Normalized Maximum Likelihood (NML) is employed in regret
minimization and model selection. However, existing formulations of NML have
been developed primarily in Euclidean spaces and are inherently dependent on
the choice of coordinate systems, making it non-trivial to extend NML to
Riemannian manifolds. In this study, we define a new NML that reflects the
geometric structure of Riemannian manifolds, called the Riemannian manifold NML
(Rm-NML). This Rm-NML is invariant under coordinate transformations and
coincides with the conventional NML under the natural parameterization in
Euclidean space. We extend existing computational techniques for NML to the
setting of Riemannian manifolds. Furthermore, we derive a method to simplify
the computation of Rm-NML on Riemannian symmetric spaces, which encompass data
spaces of growing interest such as hyperbolic spaces. To illustrate the
practical application of our proposed method, we explicitly computed the Rm-NML
for normal distributions on hyperbolic spaces.

</details>


### [170] [Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration](https://arxiv.org/abs/2508.21468)
*Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park*

Main category: cs.LG

TL;DR: 生成式模型在药物发现中用于3D分子生成，但仅关注结合亲和力，忽略了合成可行性和选择性。本文提出CByG框架，通过条件生成模型整合多属性引导，并采用包含结合亲和力、合成可行性和选择性的综合评估方案，实验证明CByG优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统的基于结构的海洛因设计（SBDD）主要通过结合亲和力来评估生成模型的性能，但实际的药物发现还需要考虑合成可行性和选择性，而这些在之前的评估中被忽略了。

Method: 提出CByG框架，将贝叶斯流网络扩展为基于梯度的条件生成模型，以整合特定属性的引导。引入包含结合亲和力、合成可行性和选择性的综合评估方案。

Result: 实验证明CByG框架在多个关键评估标准上显著优于基线模型。

Conclusion: CByG框架能够有效地将分子生成引导至多种药理学特性，并且在实际的药物发现应用中具有有效性和实用性。

Abstract: Recent advances in Structure-based Drug Design (SBDD) have leveraged
generative models for 3D molecular generation, predominantly evaluating model
performance by binding affinity to target proteins. However, practical drug
discovery necessitates high binding affinity along with synthetic feasibility
and selectivity, critical properties that were largely neglected in previous
evaluations. To address this gap, we identify fundamental limitations of
conventional diffusion-based generative models in effectively guiding molecule
generation toward these diverse pharmacological properties. We propose CByG, a
novel framework extending Bayesian Flow Network into a gradient-based
conditional generative model that robustly integrates property-specific
guidance. Additionally, we introduce a comprehensive evaluation scheme
incorporating practical benchmarks for binding affinity, synthetic feasibility,
and selectivity, overcoming the limitations of conventional evaluation methods.
Extensive experiments demonstrate that our proposed CByG framework
significantly outperforms baseline models across multiple essential evaluation
criteria, highlighting its effectiveness and practicality for real-world drug
discovery applications.

</details>


### [171] [Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning](https://arxiv.org/abs/2508.21488)
*Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T. J. Spaan*

Main category: cs.LG

TL;DR: 贝叶斯深度Q学习中存在冷后验效应，性能随后验温度降低而提高。研究表明，高斯似然假设常被违反，需要开发更合适的似然和先验。


<details>
  <summary>Details</summary>
Motivation: 量化强化学习中的不确定性可以提高探索和鲁棒性。然而，目前的研究主要集中在后验近似的准确性上，而忽略了对先验和似然假设准确性的研究。

Method: 通过实证研究先验分布，并进行统计检验，挑战了贝叶斯无模型算法中常用的似然和先验假设，发现了冷后验效应。

Result: 证明了贝叶斯深度Q学习中存在冷后验效应，即性能随后验温度降低而提高。通过统计检验表明，常用的高斯似然假设经常被违反。

Conclusion: 开发更合适的似然和先验应该是未来贝叶斯强化学习研究的关键焦点，并提供了一些改进深度Q学习中先验的简单实现方案，从而提高了贝叶斯算法的性能。

Abstract: Uncertainty quantification in reinforcement learning can greatly improve
exploration and robustness. Approximate Bayesian approaches have recently been
popularized to quantify uncertainty in model-free algorithms. However, so far
the focus has been on improving the accuracy of the posterior approximation,
instead of studying the accuracy of the prior and likelihood assumptions
underlying the posterior. In this work, we demonstrate that there is a cold
posterior effect in Bayesian deep Q-learning, where contrary to theory,
performance increases when reducing the temperature of the posterior. To
identify and overcome likely causes, we challenge common assumptions made on
the likelihood and priors in Bayesian model-free algorithms. We empirically
study prior distributions and show through statistical tests that the common
Gaussian likelihood assumption is frequently violated. We argue that developing
more suitable likelihoods and priors should be a key focus in future Bayesian
reinforcement learning research and we offer simple, implementable solutions
for better priors in deep Q-learning that lead to more performant Bayesian
algorithms.

</details>


### [172] [Failure Prediction Is a Better Performance Proxy for Early-Exit Networks Than Calibration](https://arxiv.org/abs/2508.21495)
*Piotr Kubaty,Filip Szatkowski,Metod Jazbec,Bartosz Wójcik*

Main category: cs.LG

TL;DR: 早期退出模型利用中间层的内部分类器来加速推理，一旦预测满足退出标准就停止计算。大多数早期退出方法依赖于基于置信度的退出策略，这促使一些研究通过校准中间分类器来提高整个模型的性能。在本文中，我们表明校准度量可能无法准确衡量多退出模型的性能：一个校准良好的分类器仍然可能浪费计算，并且常见的校准方法不保留分类器内的样本排名。我们展示了经验案例，其中校准错误的网络优于校准正确的网络。作为替代，我们提出使用失败预测作为早期退出模型性能更有用的代理。与校准不同，失败预测考虑了样本排名的变化，并与效率改进显示出很强的相关性，这使其成为设计和评估早期退出模型更可靠的基础。


<details>
  <summary>Details</summary>
Motivation: 大多数早期退出方法依赖于基于置信度的退出策略，并且研究表明校准中间分类器可以提高整个模型的性能。然而，本文旨在探讨校准度量是否为多退出模型的性能提供了有误导性的指标，并提出一种替代方法来更可靠地设计和评估早期退出模型。

Method: 本文提出使用失败预测作为早期退出模型性能的代理，而不是依赖于置信度或校准度量。作者通过经验案例展示了校准错误的网络如何优于校准正确的网络，并表明失败预测比校准更能考虑样本排名的变化，并与效率改进具有很强的相关性。

Result: 与校准度量不同，失败预测被证明是早期退出模型性能的更可靠的代理。它考虑了样本排名的变化，并与效率改进显示出很强的相关性。

Conclusion: 本文认为，用于早期退出模型的校准度量可能具有误导性，因为它们可能无法准确反映模型的实际性能，并且不保留样本排名。相反，作者提出使用失败预测作为替代方法，因为它能更好地反映模型性能和效率改进，从而为设计和评估早期退出模型提供了更可靠的基础。

Abstract: Early-exit models speed up inference by attaching internal classifiers to
intermediate layers of the model and allowing computation to stop once a
prediction satisfies an exit criterion. Most early-exit methods rely on
confidence-based exit strategies, which motivated some works to calibrate
intermediate classifiers to improve the performance of the entire model. In
this paper, we show that calibration measures can be misleading indicators of
the performance of multi-exit models: a well-calibrated classifier may still
waste computation, and common calibration methods do not preserve the sample
ranking within a classifier. We demonstrate empirical cases where miscalibrated
networks outperform calibrated ones. As an alternative, we propose to use
failure prediction as a more useful proxy for early-exit model performance.
Unlike calibration, failure prediction accounts for changes in the ranking of
samples and shows a strong correlation with efficiency improvements, making it
a more dependable basis for designing and evaluating early-exit models.

</details>


### [173] [Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control](https://arxiv.org/abs/2508.21505)
*Vishal Pandey,Debasmita Biswas*

Main category: cs.LG

TL;DR: Decision Transformer 架构的强化学习智能体在序列决策任务上表现出色，但其对密集矩阵运算的依赖使其不适合能源受限的边缘平台。我们提出了 Spiking Decision Transformer (SNN-DT)，它将 Leaky Integrate-and-Fire 神经元嵌入到自注意力块中，并通过代理梯度进行端到端训练，同时融入了生物启发的类三因子可塑性、相位偏移的基于脉冲的位置编码以及轻量级的树突路由模块。该实现与标准的 Decision Transformer 在经典控制基准测试（CartPole-v1、MountainCar-v0、Acrobot-v1、Pendulum-v1）上表现相当或更优，但每次决策产生的脉冲少于 10 个，能耗效率比标准模型高出四个数量级以上。SNN-DT 将序列建模与神经形态效率相结合，为嵌入式和可穿戴设备上的实时、低功耗控制开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 传统的基于 Transformer 的强化学习智能体在序列决策任务上表现优异，但其高能耗的特性限制了其在能源受限的边缘设备上的应用。而脉冲神经网络（SNN）具有超低功耗和事件驱动的推理特性，但此前尚未与基于回报的序列建模相结合。因此，本研究的动机在于弥合这一差距，开发一种低功耗、高效的序列决策模型。

Method: 本研究提出了一种名为 Spiking Decision Transformer (SNN-DT) 的模型。该模型将 Leaky Integrate-and-Fire 神经元嵌入到 Transformer 的自注意力块中，并采用代理梯度进行端到端训练。此外，SNN-DT 还融合了生物启发的类三因子可塑性、相位偏移的基于脉冲的位置编码以及一个轻量级的树突路由模块。

Result: SNN-DT 在经典的控制基准测试（CartPole-v1、MountainCar-v0、Acrobot-v1、Pendulum-v1）上，其性能与标准 Decision Transformer 相当或更优。同时，其每次决策产生的脉冲数量少于 10 个，这表明其单次推理能耗相比标准模型降低了四个数量级以上。

Conclusion: Spiking Decision Transformer (SNN-DT) 成功地将序列建模能力与神经形态计算的低功耗效率相结合。通过在 Transformer 架构中引入脉冲神经元和生物启发的学习机制，SNN-DT 在保持甚至超过传统模型性能的同时，实现了显著的能耗降低。这为在资源受限的嵌入式和可穿戴设备上实现实时、低功耗的序列决策控制提供了新的途径。

Abstract: Reinforcement learning agents based on Transformer architectures have
achieved impressive performance on sequential decision-making tasks, but their
reliance on dense matrix operations makes them ill-suited for
energy-constrained, edge-oriented platforms. Spiking neural networks promise
ultra-low-power, event-driven inference, yet no prior work has seamlessly
merged spiking dynamics with return-conditioned sequence modeling. We present
the Spiking Decision Transformer (SNN-DT), which embeds Leaky
Integrate-and-Fire neurons into each self-attention block, trains end-to-end
via surrogate gradients, and incorporates biologically inspired three-factor
plasticity, phase-shifted spike-based positional encodings, and a lightweight
dendritic routing module. Our implementation matches or exceeds standard
Decision Transformer performance on classic control benchmarks (CartPole-v1,
MountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes
per decision, an energy proxy suggesting over four orders-of-magnitude
reduction in per inference energy. By marrying sequence modeling with
neuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power
control on embedded and wearable devices.

</details>


### [174] [Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches](https://arxiv.org/abs/2508.21512)
*Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek*

Main category: cs.LG

TL;DR: LLMs在信贷审批等高风险决策任务中表现不佳，尤其是在处理表格数据、保证公平性和预测可靠性方面。本文评估了LLM在加纳、德国和美国三个地区序列化信贷审批数据集上的表现和公平性，发现序列化格式对LLM的性能和公平性有显著影响，而ICL在提升模型性能的同时，对公平性的影响因数据集而异。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在信贷审批任务中处理表格数据的性能和公平性，特别是在不同地区数据集上的表现，以及序列化格式和ICL（in-context learning）对其的影响。

Method: 评估LLM在加纳、德国和美国三个地区序列化信贷审批数据集上的零样本（zero-shot）和ICL能力，并分析不同序列化格式（如GReat和LIFT）对模型性能和公平性的影响。

Result: 序列化格式显著影响LLM的性能和公平性，GReat和LIFT等格式虽然提高了F1分数，但也加剧了公平性差距。ICL相较于零样本基线，模型性能提升了4.9-59.6%，但对公平性的影响因数据集而异。

Conclusion: 有效的表格数据表示方法和公平性感知模型对于提高LLM在金融决策中的可靠性至关重要。

Abstract: Large Language Models (LLMs) are increasingly employed in high-stakes
decision-making tasks, such as loan approvals. While their applications expand
across domains, LLMs struggle to process tabular data, ensuring fairness and
delivering reliable predictions. In this work, we assess the performance and
fairness of LLMs on serialized loan approval datasets from three geographically
distinct regions: Ghana, Germany, and the United States. Our evaluation focuses
on the model's zero-shot and in-context learning (ICL) capabilities. Our
results reveal that the choice of serialization (Serialization refers to the
process of converting tabular data into text formats suitable for processing by
LLMs.) format significantly affects both performance and fairness in LLMs, with
certain formats such as GReat and LIFT yielding higher F1 scores but
exacerbating fairness disparities. Notably, while ICL improved model
performance by 4.9-59.6% relative to zero-shot baselines, its effect on
fairness varied considerably across datasets. Our work underscores the
importance of effective tabular data representation methods and fairness-aware
models to improve the reliability of LLMs in financial decision-making.

</details>


### [175] [On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature](https://arxiv.org/abs/2508.21513)
*Geri Skenderi*

Main category: cs.LG

TL;DR: GNN在解决SAT问题时，由于图的负曲率和信息瓶颈，在处理困难实例时性能会下降。


<details>
  <summary>Details</summary>
Motivation: 探讨GNN在解决SAT问题时性能下降的原因，并提供几何解释。

Method: 通过图Ricci曲率（RC）量化连接瓶颈，证明随机k-SAT公式产生的二分图具有负曲率，且曲率随实例难度增加而降低。分析GNN的过压（oversquashing）现象。

Result: GNN SAT求解器受到过压影响，无法将长距离依赖压缩到固定长度的表示中。曲率是问题复杂性的有力指标，可预测性能。

Conclusion: 曲率与现有求解器的设计原则相关，并为未来工作指出了方向。

Abstract: Graph Neural Networks (GNNs) have recently shown promise as solvers for
Boolean Satisfiability Problems (SATs) by operating on graph representations of
logical formulas. However, their performance degrades sharply on harder
instances, raising the question of whether this reflects fundamental
architectural limitations. In this work, we provide a geometric explanation
through the lens of graph Ricci Curvature (RC), which quantifies local
connectivity bottlenecks. We prove that bipartite graphs derived from random
k-SAT formulas are inherently negatively curved, and that this curvature
decreases with instance difficulty. Building on this, we show that GNN-based
SAT solvers are affected by oversquashing, a phenomenon where long-range
dependencies become impossible to compress into fixed-length representations.
We validate our claims empirically across different SAT benchmarks and confirm
that curvature is both a strong indicator of problem complexity and can be used
to predict performance. Finally, we connect our findings to design principles
of existing solvers and outline promising directions for future work.

</details>


### [176] [Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification](https://arxiv.org/abs/2508.21561)
*Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu*

Main category: cs.LG

TL;DR: 提出InsightTab框架，通过提炼数据洞察，增强LLM在少样本表格分类任务中的表现，在九个数据集上取得优于现有方法的性能，并有效利用了标签数据和管理了偏见。


<details>
  <summary>Details</summary>
Motivation: 少数样本的表格分类任务中，LLM的表现受到结构化数据多样性的挑战，需要更有效的方法来处理。

Method: 提出InsightTab框架，遵循分而治之、先易后难和反思学习的原则，通过规则概括、策略性举例和洞察反思，实现LLM与数据建模技术的深度协作，将数据提炼为可操作的洞察。

Result: InsightTab在九个数据集上取得了持续的改进，优于最先进的方法，并且在利用标签数据和管理偏见方面表现出有效性。

Conclusion: InsightTab通过提炼数据洞察，能够更好地使LLM的通用知识和能力与特定表格任务的要求相匹配，在少样本表格分类任务中展现出鲁棒性和有效性。

Abstract: Recent studies show the promise of large language models (LLMs) for few-shot
tabular classification but highlight challenges due to the variability in
structured data. To address this, we propose distilling data into actionable
insights to enable robust and effective classification by LLMs. Drawing
inspiration from human learning processes, we introduce InsightTab, an insight
distillation framework guided by principles of divide-and-conquer, easy-first,
and reflective learning. Our approach integrates rule summarization, strategic
exemplification, and insight reflection through deep collaboration between LLMs
and data modeling techniques. The obtained insights enable LLMs to better align
their general knowledge and capabilities with the particular requirements of
specific tabular tasks. We extensively evaluate InsightTab on nine datasets.
The results demonstrate consistent improvement over state-of-the-art methods.
Ablation studies further validate the principle-guided distillation process,
while analyses emphasize InsightTab's effectiveness in leveraging labeled data
and managing bias.

</details>


### [177] [What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems](https://arxiv.org/abs/2508.21547)
*Jens Leysen,Marco Favier,Bart Goethals*

Main category: cs.LG

TL;DR: 本研究探讨了在推荐系统中应用数据最小化原则的可行性，发现在不显著影响性能的情况下，减少隐式反馈推断数据在技术上是可行的，但其实用性受技术设置和用户特征的显著影响。


<details>
  <summary>Details</summary>
Motivation: 推荐系统依赖大量个人数据，而数据最小化原则要求个人数据处理仅限于特定目的所必需的内容。在推荐系统中实现数据最小化是一个重大挑战。

Method: 本研究进行了可行性研究，提出了新颖的问题公式，分析了各种最小化技术，并研究了影响其有效性的关键因素。

Result: 研究表明，在不显著损失性能的情况下，能够大幅减少推断数据，技术上是可行的。然而，其实用性取决于技术设置（如性能目标、模型选择）和用户特征（如历史记录大小、偏好复杂度）。

Conclusion: 虽然本研究在技术上证明了数据最小化的可行性，但其实际应用仍然充满挑战。数据最小化对技术和用户背景的依赖性使得制定通用的‘必要’数据标准难以实现。

Abstract: Data minimization is a legal principle requiring personal data processing to
be limited to what is necessary for a specified purpose. Operationalizing this
principle for recommender systems, which rely on extensive personal data,
remains a significant challenge. This paper conducts a feasibility study on
minimizing implicit feedback inference data for such systems. We propose a
novel problem formulation, analyze various minimization techniques, and
investigate key factors influencing their effectiveness. We demonstrate that
substantial inference data reduction is technically feasible without
significant performance loss. However, its practicality is critically
determined by two factors: the technical setting (e.g., performance targets,
choice of model) and user characteristics (e.g., history size, preference
complexity). Thus, while we establish its technical feasibility, we conclude
that data minimization remains practically challenging and its dependence on
the technical and user context makes a universal standard for data `necessity'
difficult to implement.

</details>


### [178] [Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study](https://arxiv.org/abs/2508.21554)
*Maximilian P. Oppelt,Tobias S. Zech,Sarah H. Lorenz,Laurenz Ottmann,Jan Steffan,Bjoern M. Eskofier,Nadine R. Lang-Richter,Norman Pfeiffer*

Main category: cs.LG

TL;DR: 一款新型可穿戴纺织服装，通过创新的电极放置来提高心电图（ECG）记录的信号质量，并对性别差异进行了评估。


<details>
  <summary>Details</summary>
Motivation: 介绍一种创新的可穿戴纺织服装，旨在通过优化的电极放置来提高心电图（ECG）记录的信号保真度，减少噪声和运动伪影，并评估其在不同性别参与者中的适用性。

Method: 使用定量的信号质量指标、基于心律的生理参数分析（心率和心率变异性）、机器学习分类任务、ECG特征形态分析以及电极投影角度对信号质量影响的研究。评估在不同活动阶段进行，并按性别进行分层分析。

Result: 该纺织系统在心律和形态分析方面均达到了与参考设备高度一致的信号质量，表现出稳健的分类性能，并能识别影响信号采集的关键性别特异性决定因素。

Conclusion: 基于纺织服装的心电图监测具有实际可行性，可用于生理监测和心理生理状态检测。为确保可穿戴健康技术中公平可靠的心脏诊断，纳入性别特异性设计考量至关重要。

Abstract: We introduce a novel wearable textile-garment featuring an innovative
electrode placement aimed at minimizing noise and motion artifacts, thereby
enhancing signal fidelity in Electrocardiography (ECG) recordings. We present a
comprehensive, sex-balanced evaluation involving 15 healthy males and 15
healthy female participants to ensure the device's suitability across
anatomical and physiological variations. The assessment framework encompasses
distinct evaluation approaches: quantitative signal quality indices to
objectively benchmark device performance; rhythm-based analyzes of
physiological parameters such as heart rate and heart rate variability; machine
learning classification tasks to assess application-relevant predictive
utility; morphological analysis of ECG features including amplitude and
interval parameters; and investigations of the effects of electrode projection
angle given by the textile / body shape, with all analyzes stratified by sex to
elucidate sex-specific influences. Evaluations were conducted across various
activity phases representing real-world conditions. The results demonstrate
that the textile system achieves signal quality highly concordant with
reference devices in both rhythm and morphological analyses, exhibits robust
classification performance, and enables identification of key sex-specific
determinants affecting signal acquisition. These findings underscore the
practical viability of textile-based ECG garments for physiological monitoring
as well as psychophysiological state detection. Moreover, we identify the
importance of incorporating sex-specific design considerations to ensure
equitable and reliable cardiac diagnostics in wearable health technologies.

</details>


### [179] [Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation](https://arxiv.org/abs/2508.21559)
*Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli*

Main category: cs.LG

TL;DR: PINNs在智能电网建模中表现优于XGBoost、随机森林和线性回归等传统模型，尤其在数据稀疏和需要物理一致性的场景下，能够有效降低误差并保持物理可行性。


<details>
  <summary>Details</summary>
Motivation: 评估PINNs作为智能电网动态代理模型的能力，并与XGBoost、随机森林和线性回归进行性能比较，以解决传统数据驱动方法在数据稀疏和物理一致性方面的挑战。

Method: 通过训练仅包含物理损失函数（强制执行功率平衡、运行约束和电网稳定）的PINNs，并将其与XGBoost、随机森林和线性回归进行比较，在插值、交叉验证和情景轨迹预测三个实验中评估其性能。

Result: PINNs在误差降低方面优于数据驱动模型，尤其在动态电网运行中保持较低的平均绝对误差（MAE），并能可靠地捕捉随机和专家驱动控制场景下的状态转换，而传统模型表现不稳定。尽管在极端运行状态下性能略有下降，PINNs仍能始终强制执行物理可行性。

Conclusion: PINNs是智能电网代理模型的范式转移工具，结合了数据驱动的灵活性和第一性原理的严谨性，能够推动实时电网控制和可扩展数字孪生技术的发展，并强调了物理感知架构在关键能源系统中的必要性。

Abstract: Physics-Informed Neural Networks (PINNs) present a transformative approach
for smart grid modeling by integrating physical laws directly into learning
frameworks, addressing critical challenges of data scarcity and physical
consistency in conventional data-driven methods. This paper evaluates PINNs'
capabilities as surrogate models for smart grid dynamics, comparing their
performance against XGBoost, Random Forest, and Linear Regression across three
key experiments: interpolation, cross-validation, and episodic trajectory
prediction. By training PINNs exclusively through physics-based loss functions
(enforcing power balance, operational constraints, and grid stability) we
demonstrate their superior generalization, outperforming data-driven models in
error reduction. Notably, PINNs maintain comparatively lower MAE in dynamic
grid operations, reliably capturing state transitions in both random and
expert-driven control scenarios, while traditional models exhibit erratic
performance. Despite slight degradation in extreme operational regimes, PINNs
consistently enforce physical feasibility, proving vital for safety-critical
applications. Our results contribute to establishing PINNs as a
paradigm-shifting tool for smart grid surrogation, bridging data-driven
flexibility with first-principles rigor. This work advances real-time grid
control and scalable digital twins, emphasizing the necessity of physics-aware
architectures in mission-critical energy systems.

</details>


### [180] [OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories](https://arxiv.org/abs/2508.21570)
*Bo Li,Yingqi Feng,Ming Jin,Xin Zheng,Yufei Tang,Laurent Cherubin,Alan Wee-Chung Liew,Can Wang,Qinghua Lu,Jingwei Yao,Shirui Pan,Hong Zhang,Xingquan Zhu*

Main category: cs.LG

TL;DR: OASIS是一个新颖的扩散对抗框架，用于解决海洋盐度测量稀疏、不规则和噪声大的问题，克服了传统方法和现有机器学习模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 海洋盐度对环流、气候和海洋生态系统至关重要，但其测量数据通常稀疏、不规则且充满噪声，特别是在基于漂流瓶的数据集中。传统方法（如遥感和最优插值）依赖线性和平稳性，并受到云层覆盖、传感器漂移和低卫星重访率的限制。机器学习模型虽然灵活，但在严重稀疏的情况下常常表现不佳，并且缺乏在没有专用传感器的情况下整合物理协变量的原则方法。

Method: 提出了一种新颖的扩散对抗框架，称为OceAn Salinity Imputation System (OASIS)。

Result: 该框架旨在解决海洋盐度测量数据稀疏、不规则和噪声大的挑战。

Conclusion: OASIS框架是为了应对海洋盐度数据质量问题而设计的。

Abstract: Ocean salinity plays a vital role in circulation, climate, and marine
ecosystems, yet its measurement is often sparse, irregular, and noisy,
especially in drifter-based datasets. Traditional approaches, such as remote
sensing and optimal interpolation, rely on linearity and stationarity, and are
limited by cloud cover, sensor drift, and low satellite revisit rates. While
machine learning models offer flexibility, they often fail under severe
sparsity and lack principled ways to incorporate physical covariates without
specialized sensors. In this paper, we introduce the OceAn Salinity Imputation
System (OASIS), a novel diffusion adversarial framework designed to address
these challenges.

</details>


### [181] [Physics-Informed Spectral Modeling for Hyperspectral Imaging](https://arxiv.org/abs/2508.21618)
*Zuzanna Gawrysiak,Krzysztof Krawiec*

Main category: cs.LG

TL;DR: PhISM是一种无需监督的物理信息深度学习架构，可显式分离高光谱观测并使用连续基函数对其进行建模。
mname在几个分类和回归基准上优于先前的方法，需要有限的标记数据，并由于可解释的潜在表示而提供额外的见解。


<details>
  <summary>Details</summary>
Motivation: PhISM的目标是显式分离高光谱观测并使用连续基函数对其进行建模，同时在分类和回归任务中取得优越性能，并提供可解释的潜在表示。

Method: PhISM是一种无需监督的物理信息深度学习架构，采用连续基函数对高光谱观测进行建模。

Result: PhISM在几个分类和回归基准上优于先前的方法，并且能够提供可解释的潜在表示。

Conclusion: PhISM是一种有效的高光谱数据分析方法，它结合了物理信息、深度学习和无监督学习的优势，能够在下游任务中取得优异表现，并提供有价值的可解释性。

Abstract: We present PhISM, a physics-informed deep learning architecture that learns
without supervision to explicitly disentangle hyperspectral observations and
model them with continuous basis functions. \mname outperforms prior methods on
several classification and regression benchmarks, requires limited labeled
data, and provides additional insights thanks to interpretable latent
representation.

</details>


### [182] [Introduction to the Analysis of Probabilistic Decision-Making Algorithms](https://arxiv.org/abs/2508.21620)
*Agustinus Kristiadi*

Main category: cs.LG

TL;DR: 该书为常用概率决策算法（包括老虎机算法、贝叶斯优化和树搜索算法）的理论分析提供了易于理解的入门介绍。


<details>
  <summary>Details</summary>
Motivation: 决策理论为在各种不确定性下做出选择提供了原则性方法，在材料和药物发现等领域取得了成功。然而，文献中的理论分析通常对非专家来说难以理解。

Method: 该专著旨在提供对常用概率决策算法（包括老虎机算法、贝叶斯优化和树搜索算法）的理论分析的易于理解、自成一体的介绍。

Result: 虽然摘要中没有具体说明结果，但该书的目标是使非专家能够理解和应用这些算法的理论分析。

Conclusion: 该书通过提供对常用概率决策算法理论分析的易于理解的介绍，旨在使这些强大的工具更容易被广泛的受众所接受。

Abstract: Decision theories offer principled methods for making choices under various
types of uncertainty. Algorithms that implement these theories have been
successfully applied to a wide range of real-world problems, including
materials and drug discovery. Indeed, they are desirable since they can
adaptively gather information to make better decisions in the future, resulting
in data-efficient workflows. In scientific discovery, where experiments are
costly, these algorithms can thus significantly reduce the cost of
experimentation. Theoretical analyses of these algorithms are crucial for
understanding their behavior and providing valuable insights for developing
next-generation algorithms. However, theoretical analyses in the literature are
often inaccessible to non-experts. This monograph aims to provide an
accessible, self-contained introduction to the theoretical analysis of commonly
used probabilistic decision-making algorithms, including bandit algorithms,
Bayesian optimization, and tree search algorithms. Only basic knowledge of
probability theory and statistics, along with some elementary knowledge about
Gaussian processes, is assumed.

</details>


### [183] [Predicting Social Media Engagement from Emotional and Temporal Features](https://arxiv.org/abs/2508.21650)
*Yunwoo Kim,Junhyuk Hwang*

Main category: cs.LG

TL;DR: 使用情感和时间特征预测社交媒体参与度（评论和点赞），模型基于HistGradientBoostingRegressor，R^2在点赞上为0.98，评论上为0.41，表明评论受当前特征集之外的因素影响。


<details>
  <summary>Details</summary>
Motivation: 利用情感和时间特征来预测社交媒体参与度（评论和点赞）。

Method: 使用HistGradientBoostingRegressor进行多目标回归，处理了对数转换后的参与度比例以应对目标分布不均。通过自定义的量级准确率和标准回归指标（如R^2）进行性能评估。

Result: 情感和时间元数据结合现有观看次数能有效预测未来参与度。模型在点赞上的R^2达到0.98，但在评论上的R^2仅为0.41。

Conclusion: 点赞主要受易于捕捉的情感和曝光信号驱动，而评论的预测则受到当前特征集未包含的其他因素的影响。

Abstract: We present a machine learning approach for predicting social media engagement
(comments and likes) from emotional and temporal features. The dataset contains
600 songs with annotations for valence, arousal, and related sentiment metrics.
A multi target regression model based on HistGradientBoostingRegressor is
trained on log transformed engagement ratios to address skewed targets.
Performance is evaluated with both a custom order of magnitude accuracy and
standard regression metrics, including the coefficient of determination (R^2).
Results show that emotional and temporal metadata, together with existing view
counts, predict future engagement effectively. The model attains R^2 = 0.98 for
likes but only R^2 = 0.41 for comments. This gap indicates that likes are
largely driven by readily captured affective and exposure signals, whereas
comments depend on additional factors not represented in the current feature
set.

</details>


### [184] [Activation Subspaces for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21695)
*Barış Zöngür,Robin Hesse,Stefan Roth*

Main category: cs.LG

TL;DR: 一种新的OOD检测方法ActSub，通过SVD分解模型权重矩阵，区分主次成分，在Far-OOD场景下利用次要成分，Near-OOD场景下利用主要成分，在多个OOD基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了确保深度模型在实际应用中的可靠性，需要OOD检测方法来区分ID和OOD样本。

Method: 利用分类头权重矩阵的奇异值分解（SVD）将模型激活分解为主成分和次要成分。在Far-OOD场景下，使用次要成分；在Near-OOD场景下，使用主要成分。将这两种发现结合起来，形成ActSub方法。

Result: ActSub在Far-OOD场景下，次要成分比原始激活更能有效地区分ID和OOD数据。在Near-OOD场景下，仅考虑主要成分可以获得更好的性能。ActSub在多个标准OOD基准测试中取得了最先进的结果。

Conclusion: ActSub方法通过结合不同分布偏移场景下的不同成分，能够有效地进行OOD检测，并在标准基准测试中取得了优越的性能。

Abstract: To ensure the reliability of deep models in real-world applications,
out-of-distribution (OOD) detection methods aim to distinguish samples close to
the training distribution (in-distribution, ID) from those farther away (OOD).
In this work, we propose a novel OOD detection method that utilizes singular
value decomposition of the weight matrix of the classification head to
decompose the model's activations into decisive and insignificant components,
which contribute maximally, respectively minimally, to the final classifier
output. We find that the subspace of insignificant components more effectively
distinguishes ID from OOD data than raw activations in regimes of large
distribution shifts (Far-OOD). This occurs because the classification objective
leaves the insignificant subspace largely unaffected, yielding features that
are ''untainted'' by the target classification task. Conversely, in regimes of
smaller distribution shifts (Near-OOD), we find that activation shaping methods
profit from only considering the decisive subspace, as the insignificant
component can cause interference in the activation space. By combining two
findings into a single approach, termed ActSub, we achieve state-of-the-art
results in various standard OOD benchmarks.

</details>


### [185] [Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety](https://arxiv.org/abs/2508.21722)
*Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz*

Main category: cs.LG

TL;DR: 该研究提出了一种将经济学中的纵向回归断点设计（LRDD）方法应用于预测社区心理健康（特别是焦虑）随时间变化的统计学习框架，以评估地方性事件（如COVID-19）的影响。


<details>
  <summary>Details</summary>
Motivation: 社区特定心理健康对地方事件的影响对于公共卫生政策至关重要。仅预测心理健康分数提供的见解有限，而LRDD等准实验设计有助于从观测数据中获得更具因果性的推论。

Method: 将LRDD方法扩展到一个统计学习框架，用于估计社区历史得分、动态协变量（其他评估）和外生变量（静态表示）的特定时间变化（断点）和斜率变化（线性轨迹）。

Result: 将该框架应用于预测美国各县的焦虑断点，发现随着模型复杂性的增加，任务更具挑战性但更易实现，并且结合外生和动态协变量能获得最佳结果，在断点和斜率估计上分别显示出r=+0.46和r=+0.65的显著改进。

Conclusion: 所提出的方法通过结合外生和动态协变量，在估计社区特定事件对心理健康的影响方面，相比传统的静态社区代表性方法取得了显著的改进。断点预测为评估未来或假设事件对特定社区的特有影响开辟了新的可能性。

Abstract: Estimating community-specific mental health effects of local events is vital
for public health policy. While forecasting mental health scores alone offers
limited insights into the impact of events on community well-being,
quasi-experimental designs like the Longitudinal Regression Discontinuity
Design (LRDD) from econometrics help researchers derive more effects that are
more likely to be causal from observational data. LRDDs aim to extrapolate the
size of changes in an outcome (e.g. a discontinuity in running scores for
anxiety) due to a time-specific event. Here, we propose adapting LRDDs beyond
traditional forecasting into a statistical learning framework whereby future
discontinuities (i.e. time-specific shifts) and changes in slope (i.e. linear
trajectories) are estimated given a location's history of the score, dynamic
covariates (other running assessments), and exogenous variables (static
representations). Applying our framework to predict discontinuities in the
anxiety of US counties from COVID-19 events, we found the task was difficult
but more achievable as the sophistication of models was increased, with the
best results coming from integrating exogenous and dynamic covariates. Our
approach shows strong improvement ($r=+.46$ for discontinuity and $r = +.65$
for slope) over traditional static community representations. Discontinuity
forecasting raises new possibilities for estimating the idiosyncratic effects
of potential future or hypothetical events on specific communities.

</details>


### [186] [UniMLR: Modeling Implicit Class Significance for Multi-Label Ranking](https://arxiv.org/abs/2508.21772)
*V. Bugra Yesilkaynak,Emine Dari,Alican Mertan,Gozde Unal*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Existing multi-label ranking (MLR) frameworks only exploit information
deduced from the bipartition of labels into positive and negative sets.
Therefore, they do not benefit from ranking among positive labels, which is the
novel MLR approach we introduce in this paper. We propose UniMLR, a new MLR
paradigm that models implicit class relevance/significance values as
probability distributions using the ranking among positive labels, rather than
treating them as equally important. This approach unifies ranking and
classification tasks associated with MLR. Additionally, we address the
challenges of scarcity and annotation bias in MLR datasets by introducing eight
synthetic datasets (Ranked MNISTs) generated with varying
significance-determining factors, providing an enriched and controllable
experimental environment. We statistically demonstrate that our method
accurately learns a representation of the positive rank order, which is
consistent with the ground truth and proportional to the underlying
significance values. Finally, we conduct comprehensive empirical experiments on
both real-world and synthetic datasets, demonstrating the value of our proposed
framework.

</details>


### [187] [Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling](https://arxiv.org/abs/2508.21785)
*Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong*

Main category: cs.LG

TL;DR: 该研究提出了一种解决心率预测中数据异质性问题的框架，通过随机特征丢弃和时间感知注意力机制来处理设备和用户异质性，并在新数据集ParroTao和FitRec上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 心率预测在个性化健康监测和健身领域至关重要，但在实际应用中面临数据异质性（设备和用户层面）的挑战，现有方法难以有效解决。

Method: 提出一个学习无差异化潜在表征的框架，采用随机特征丢弃处理源异质性，利用时间感知注意力模块和对比学习目标处理用户异质性。

Result: 在ParroTao和FitRec数据集上，所提出的模型比现有基线模型分别提高了17%和15%，学习到的表征具有很强的区分能力，并在下游应用任务中验证了其实用价值。

Conclusion: 该研究提出的框架有效解决了心率预测中的数据异质性问题，并在多个数据集上取得了优于现有方法的性能，证明了其在实际应用中的价值。

Abstract: Heart rate prediction is vital for personalized health monitoring and
fitness, while it frequently faces a critical challenge when deploying in
real-world: data heterogeneity. We classify it in two key dimensions: source
heterogeneity from fragmented device markets with varying feature sets, and
user heterogeneity reflecting distinct physiological patterns across
individuals and activities. Existing methods either discard device-specific
information, or fail to model user-specific differences, limiting their
real-world performance. To address this, we propose a framework that learns
latent representations agnostic to both heterogeneity, enabling downstream
predictors to work consistently under heterogeneous data patterns.
Specifically, we introduce a random feature dropout strategy to handle source
heterogeneity, making the model robust to various feature sets. To manage user
heterogeneity, we employ a time-aware attention module to capture long-term
physiological traits and use a contrastive learning objective to build a
discriminative representation space. To reflect the heterogeneous nature of
real-world data, we created and publicly released a new benchmark dataset,
ParroTao. Evaluations on both ParroTao and the public FitRec dataset show that
our model significantly outperforms existing baselines by 17% and 15%,
respectively. Furthermore, analysis of the learned representations demonstrates
their strong discriminative power, and one downstream application task confirm
the practical value of our model.

</details>


### [188] [MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction](https://arxiv.org/abs/2508.21793)
*Xiaoyang Wang,Christopher C. Yang*

Main category: cs.LG

TL;DR: MoE-Health是一个新颖的混合专家框架，用于处理异构和不完整的医疗保健数据，并在临床预测任务中取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理现实世界中变化或不完整的医疗数据时存在局限性，通常需要完整的数据或手动选择策略。

Method: 提出了一种名为MoE-Health的新型混合专家框架，该框架利用专门的专家网络和动态门控机制，根据可用的数据模式动态选择和组合相关的专家。

Result: 在MIMIC-IV数据集上，MoE-Health在三种临床预测任务（院内死亡率预测、长住院时间和医院再入院预测）中表现优于现有的多模态融合方法。

Conclusion: MoE-Health在处理异构和不完整的医疗保健数据方面具有改进的预测性能和鲁棒性，适合在数据可用性不同的各种医疗保健环境中部署。

Abstract: Healthcare systems generate diverse multimodal data, including Electronic
Health Records (EHR), clinical notes, and medical images. Effectively
leveraging this data for clinical prediction is challenging, particularly as
real-world samples often present with varied or incomplete modalities. Existing
approaches typically require complete modality data or rely on manual selection
strategies, limiting their applicability in real-world clinical settings where
data availability varies across patients and institutions. To address these
limitations, we propose MoE-Health, a novel Mixture of Experts framework
designed for robust multimodal fusion in healthcare prediction. MoE-Health
architecture is specifically developed to handle samples with differing
modalities and improve performance on critical clinical tasks. By leveraging
specialized expert networks and a dynamic gating mechanism, our approach
dynamically selects and combines relevant experts based on available data
modalities, enabling flexible adaptation to varying data availability
scenarios. We evaluate MoE-Health on the MIMIC-IV dataset across three critical
clinical prediction tasks: in-hospital mortality prediction, long length of
stay, and hospital readmission prediction. Experimental results demonstrate
that MoE-Health achieves superior performance compared to existing multimodal
fusion methods while maintaining robustness across different modality
availability patterns. The framework effectively integrates multimodal
information, offering improved predictive performance and robustness in
handling heterogeneous and incomplete healthcare data, making it particularly
suitable for deployment in diverse healthcare environments with heterogeneous
data availability.

</details>


### [189] [QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.21810)
*Jessica Liang,Anirudh Bharadwaj*

Main category: cs.LG

TL;DR: QR-LoRA通过QR分解提取正交基，并将LoRA更新表示为这些基向量的线性组合，仅训练标量系数，实现了参数高效微调。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法在初始化低秩矩阵时存在计算成本高和奇异向量不易解释的问题，需要更优化的参数高效微调技术。

Method: 本文提出QR-LoRA，利用QR分解提取预训练权重矩阵的正交基，并将LoRA更新表示为这些基向量的线性组合，仅训练标量系数。

Result: QR-LoRA在GLUE任务上取得了与全量微调、标准LoRA和SVD-LoRA相当或更优的性能，并且参数量极少（低至601个），相较于全量微调减少超过1000倍，相较于标准LoRA减少77倍。

Conclusion: QR-LoRA通过引入结构化的低秩适应，在保持高性能的同时，显著减少了可训练参数的数量，是一种高效的参数高效微调方法。

Abstract: The growing scale of Large Language Models (LLMs) has necessitated the
development of parameter-efficient fine-tuning techniques. Low-Rank Adaptation
(LoRA) has emerged as a promising approach, reducing the number of trainable
parameters by applying low-rank updates to pretrained weights. While standard
LoRA learns both update factors directly, several recent variants first
initialize those matrices via an SVD of the pretrained weights -- an operation
that can be expensive on large models and yields singular vectors that are not
always easy to interpret. In this work, we extract an orthonormal basis from
the pretrained weight matrix using QR decomposition with column pivoting, and
then express the LoRA update as a linear combination of these basis vectors --
training only the scalar coefficients, which imposes clear structure on
adaptation and drastically reduces parameter count. Experiments across GLUE
tasks show that QR-LoRA matches or exceeds the performance of full fine-tuning,
standard LoRA, and SVD-LoRA (LoRA with update matrices initialized via singular
value decomposition) with as few as 601 parameters -- a reduction of over 1000x
compared to full fine-tuning and 77x fewer than typical LoRA setups.

</details>


### [190] [Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation](https://arxiv.org/abs/2508.21815)
*Tobias Hyrup,Emmanouil Panagiotou,Arjun Roy,Arthur Zimek,Eirini Ntoutsi,Peter Schneider-Kamp*

Main category: cs.LG

TL;DR: FLIP是一种基于transformer的变分自编码器，通过潜在扩散生成异构表格数据，同时保证隐私和公平性。


<details>
  <summary>Details</summary>
Motivation: 随着GDPR、HIPAA和AI法案等隐私法规和AI责任框架的出现，使用真实世界数据面临越来越多的限制。合成数据生成为面向风险的数据共享和模型开发提供了一种有前景的解决方案，尤其是在医疗保健等敏感领域。

Method: FLIP采用基于transformer的变分自编码器，并结合潜在扩散来生成异构表格数据。它在训练过程中采用Rényi差分隐私（RDP）约束，并通过RDP兼容的平衡采样解决输入空间的公平性问题。在潜在空间，通过对齐跨受保护群体的神经元激活模式（使用CKA）来促进公平性。

Result: 实验结果表明，FLIP在差分隐私约束下，能够有效提高面向任务无关的公平性，并在多种下游任务中实现公平性改进。

Conclusion: FLIP是一种能够生成公平且注重隐私的异构表格数据的有效方法，在没有预定义下游任务的情况下也具有广泛的适用性。

Abstract: As privacy regulations such as the GDPR and HIPAA and responsibility
frameworks for artificial intelligence such as the AI Act gain traction, the
ethical and responsible use of real-world data faces increasing constraints.
Synthetic data generation has emerged as a promising solution to risk-aware
data sharing and model development, particularly for tabular datasets that are
foundational to sensitive domains such as healthcare. To address both privacy
and fairness concerns in this setting, we propose FLIP (Fair Latent
Intervention under Privacy guarantees), a transformer-based variational
autoencoder augmented with latent diffusion to generate heterogeneous tabular
data. Unlike the typical setup in fairness-aware data generation, we assume a
task-agnostic setup, not reliant on a fixed, defined downstream task, thus
offering broader applicability. To ensure privacy, FLIP employs R\'enyi
differential privacy (RDP) constraints during training and addresses fairness
in the input space with RDP-compatible balanced sampling that accounts for
group-specific noise levels across multiple sampling rates. In the latent
space, we promote fairness by aligning neuron activation patterns across
protected groups using Centered Kernel Alignment (CKA), a similarity measure
extending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment
encourages statistical independence between latent representations and the
protected feature. Empirical results demonstrate that FLIP effectively provides
significant fairness improvements for task-agnostic fairness and across diverse
downstream tasks under differential privacy constraints.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [191] [Entanglement Degradation in Curved Spacetime: An Open Quantum Systems Approach](https://arxiv.org/abs/2508.21073)
*Someindra Kumar Singh*

Main category: quant-ph

TL;DR: 文章研究了引力时间膨胀如何影响空间分离的量子比特的相干和纠缠动力学，并考虑了非马尔可夫噪声模型，发现了纠缠退化的不对称性以及在结构化环境中复苏的可能性，这对于相对论量子通信和天基量子技术具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究如何解决引力时间膨胀对空间分离的量子比特的相干和纠缠动力学的影响，并提出了一种包含相位阻尼、幅度阻尼、热激发和非马尔可夫扩展的更全面的模型。

Method: 利用开放量子系统理论，将引力红移嵌入局部退相干率，并考虑了相位阻尼、幅度阻尼、热激发以及非马尔可夫扩展。

Result: 结果表明，引力时间膨胀导致纠缠退化的不对称性，并且在结构化环境中存在复苏的可能性。

Conclusion: 研究结果对于相对论量子通信和天基量子技术具有重要意义。

Abstract: We investigate how gravitational time dilation affects the coherence and
entanglement dynamics of spatially separated qubits using open quantum systems
theory. Unlike earlier works that consider only static or Markovian noise
models, our approach incorporates phase damping, amplitude damping, and thermal
excitation, along with a non-Markovian extension. By embedding gravitational
redshift into the local decoherence rates, we demonstrate asymmetry in
entanglement degradation and reveal the possibility of revivals in structured
environments. Our findings have implications for relativistic quantum
communication and space-based quantum technologies.

</details>


### [192] [Quantum algorithms for equational reasoning](https://arxiv.org/abs/2508.21122)
*Davide Rattacaso,Daniel Jaschke,Marco Ballarin,Ilaria Siloi,Simone Montangero*

Main category: quant-ph

TL;DR: We introduce quantum normal form reduction, a quantum computational framework for analyzing abstract symbolic expressions equivalent under a given set of transformation rules. It uses a quantum Hamiltonian whose ground state encodes all equivalent expressions in a superposition, enabling efficient solutions to problems like the word problem and counting equivalent expressions. A quantum-inspired simulation solved instances with up to 10^28 equivalent expressions.


<details>
  <summary>Details</summary>
Motivation: To develop a quantum computational framework for analyzing abstract symbolic expressions equivalent under a given set of transformation rules, addressing fundamental problems in equational reasoning that are intractable for classical methods.

Method: Construct a quantum Hamiltonian whose ground state encodes the entire class of equivalent expressions in a quantum superposition. Prepare and manipulate these ground states to solve problems like the word problem, counting equivalent expressions, and identifying structural properties of equivalence classes. Demonstrate a quantum-inspired version using tensor network simulations.

Result: Demonstrated a quantum-inspired version of the algorithm using tensor network simulations, solving instances involving up to 10^28 equivalent expressions, which is beyond the reach of standard classical graph exploration techniques.

Conclusion: The quantum normal form reduction framework enables quantum symbolic computation, opening paths to investigate previously out-of-reach problems in various fields such as quantum and logical circuit design, data compression, computational group theory, linguistics, polymers, and biomolecular modeling.

Abstract: We introduce quantum normal form reduction, a quantum computational framework
for analyzing abstract symbolic expressions - such as strings, algebraic
formulas, or quantum circuits - that are equivalent under a given set of
transformation rules. These rules form a term rewriting system, a formal method
for deriving equivalences by repeatedly applying substitutions. We construct an
efficiently implementable quantum Hamiltonian whose ground state encodes the
entire class of equivalent expressions - potentially exponentially many - in a
quantum superposition. By preparing and manipulating these ground states, we
address fundamental problems in equational reasoning, including the word
problem, i.e., determining whether two expressions are equivalent, counting the
number of equivalent expressions, and identifying structural properties of
equivalence classes. We demonstrate a quantum-inspired version of the algorithm
using tensor network simulations by solving instances involving up to $10^{28}$
equivalent expressions, well beyond the reach of standard classical graph
exploration techniques. This framework opens the path for quantum symbolic
computation in areas ranging from quantum and logical circuit design to data
compression, computational group theory, linguistics, polymers and biomolecular
modeling, enabling the investigation of problems previously out of reach.

</details>


### [193] [Benchmarking Quantum Solvers in Noisy Digital Simulations for Financial Portfolio Optimization](https://arxiv.org/abs/2508.21123)
*Ruizhe Shen,Zichang Hao,Ching Hua Lee*

Main category: quant-ph

TL;DR: 本文对用于寻找伊辛型哈密顿量基态的两种主要量子算法（量子虚时演化 QITE 和量子近似优化算法 QAOA）进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 对量子算法在解决实际优化问题中的应用进行了基准测试，并探讨了扩展性和噪声容忍度之间的权衡。

Method: 将 QITE 和 QAOA 应用于马科维茨投资组合优化问题，并在数字量子计算机和具有可控两比特误差（噪声）的本地量子模拟器上进行了测试。

Result: 在无噪声情况下，QAOA 能够很好地收敛到最优结果。在有噪声的情况下，QITE 方法更具鲁棒性和稳定性，但需要更高的经典数值成本。QAOA 具有更好的可扩展性，并且可以通过有效的噪声缓解策略获得鲁棒的结果。

Conclusion: 本文的发现为了解可扩展性和噪声容忍度之间的权衡提供了有价值的见解，并证明了量子算法在近期的量子设备上解决实际优化问题的实际潜力。

Abstract: In this work, we benchmark two prominent quantum algorithms: Quantum
Imaginary-Time Evolution (QITE) and the Quantum Approximate Optimization
Algorithm (QAOA) for obtaining the ground state of Ising-type Hamiltonians.
Specifically, we apply them to the Markowitz portfolio optimization problem in
quantitative finance, on both digital quantum computers and local quantum
simulators with controllable two-qubit errors (noise). In noiseless settings,
we find that QAOA achieves excellent convergence to the optimal results. Under
noisy conditions, the QITE method exhibits greater robustness and stability,
though it incurs substantially more classical numerical cost. In contrast, we
demonstrate that QAOA offers better scalability and can still yield robust
results if the noise can be effectively mitigated. Our findings provide
valuable insights into the trade-offs between scalability and noise tolerance
and demonstrate the practical potential of quantum algorithms for solving
real-world optimization problems on near-term quantum devices.

</details>


### [194] [Block Encoding of Sparse Matrices via Coherent Permutation](https://arxiv.org/abs/2508.21667)
*Abhishek Setty*

Main category: quant-ph

TL;DR: While block encoding of sparse matrices is crucial for quantum algorithms, its gate-level implementation is challenging. This paper presents a unified framework using combinatorial optimization and coherent permutation operators to efficiently implement block encoding for arbitrary sparse matrices, reducing circuit depth and control overhead.


<details>
  <summary>Details</summary>
Motivation: Efficient gate-level implementation of block encoding for arbitrary sparse matrices is a major challenge hindering powerful quantum algorithms.

Method: The paper introduces a unified framework that leverages a novel connection with combinatorial optimization for systematic control qubit assignment (ensuring nearest-neighbor connectivity) and employs coherent permutation operators to enable amplitude reordering while preserving superposition.

Result: The proposed methods demonstrate significant reductions in circuit depth and control overhead when applied to structured sparse matrices.

Conclusion: The developed framework bridges the gap between theoretical block encoding formulations and practical quantum circuit implementations, paving the way for more efficient application of quantum algorithms.

Abstract: Block encoding of sparse matrices underpins powerful quantum algorithms such
as quantum singular value transformation, Hamiltonian simulation, and quantum
linear solvers, but its efficient gate-level implementation for arbitrary
sparse matrices remains a major challenge. We introduce a unified framework
that overcomes the key obstacles of multi-controlled X gates overhead,
amplitude reordering, and hardware connectivity, enabling efficient block
encoding for arbitrary sparse matrices with explicit gate-level constructions.
Central to our approach are a novel connection with combinatorial optimization,
which enables systematic assignment of control qubits to achieve
nearest-neighbor connectivity, and coherent permutation operators that preserve
superposition while enabling amplitude reordering. We demonstrate our methods
on structured sparse matrices, showing significant reductions in circuit depth
and control overhead, thereby bridging the gap between theoretical formulations
and practical circuit implementations for quantum algorithms.

</details>


### [195] [Ultralow-power single-pass all-optical photon router](https://arxiv.org/abs/2508.21124)
*Jérémy Berroir,Tridib Ray,Alban Urvoy,Julien Laurat*

Main category: quant-ph

TL;DR: 利用结合了原子陷阱和光学纳米纤维的横向光限制，实现了对引导光子进行路由的新方法，其中飞焦耳级别的光束可以控制光子的传播方向（反射或透射）。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于开发一种新的方法来控制和路由单光子。

Method: 该方法结合了原子陷阱和光学纳米纤维的横向光限制，并使用飞焦耳级别的光束来控制光子的传播方向（反射或透射）。

Result: 我们演示了一种新颖的方法，能够通过飞焦耳级别的光束控制单个光子的传播方向（反射或透射）。

Conclusion: 所提出的方法为光子路由提供了一种有效的方式，特别是在量子信息处理等领域具有潜在应用。

Abstract: We demonstrate a novel approach for routing guided single photons by
combining atom trapping and transverse light confinement with an optical
nanofiber. The direction of photon propagation, either reflection or
transmission, is controlled by a femtojoule-level beam.

</details>


### [196] [LREI: A fast numerical solver for quantum Landau-Lifshitz equations](https://arxiv.org/abs/2508.21200)
*Davoud Mirzaei,Behnam Hashemi,Vahid Azimi-Mousolou*

Main category: quant-ph

TL;DR: LREI是一种高效的量子朗道-利夫西茨（q-LL）和量子朗道-利夫西茨-吉尔伯特（q-LLG）方程求解方案，通过低秩分解和Krylov子空间方法，将计算复杂度从O(N^3)降至O(r^2N)，并有效处理了零特征值不变子空间，实现了对更大自旋系统的模拟。


<details>
  <summary>Details</summary>
Motivation: 解决量子朗道-利夫西茨（q-LL）和量子朗道-利夫西茨-吉尔伯特（q-LLG）方程在模拟开放量子系统中自旋动力学时面临的计算效率和内存限制问题，尤其是在系统尺寸随自旋数呈指数增长的情况下。

Method: 提出LREI（Low-Rank Eigenmode Integration）方案，利用密度矩阵的低秩结构和哈密顿量的稀疏性。具体方法包括：1. 使用低秩因子表示密度矩阵。2. 应用Krylov子空间方法进行部分特征值分解。3. 利用Householder反射处理零特征值不变子空间。4. 重构Runge-Kutta和Adams-Bashforth方法以适应低秩表示。

Result: 将求解q-LL/q-LLG方程的每步计算复杂度从O(N^3)降低到O(r^2N)，内存成本从O(N^2)降低到O(rN)，其中N是希尔伯特空间维度，r是有效秩。该方法能够处理之前因计算量过大而无法模拟的更大自旋系统，例如在标准笔记本电脑上，模拟包含20个自旋的系统（密度矩阵大小超过一百万）只需几秒钟。

Conclusion: LREI算法是一种高效且节省内存的求解量子自旋动力学方程的方案，它通过低秩近似和改进的数值方法，使得模拟更大规模的量子系统成为可能。这为比较q-LL和q-LLG模型的有效性、研究量子关联和纠缠的演化提供了强大的工具。

Abstract: We develop LREI (Low-Rank Eigenmode Integration), a memory- and
time-efficient scheme for solving quantum Landau-Lifshitz (q-LL) and quantum
Landau-Lifshitz-Gilbert (q-LLG) equations, which govern spin dynamics in open
quantum systems. Although system size grows exponentially with the number of
spins, our approach exploits the low-rank structure of the density matrix and
the sparsity of Hamiltonians to avoid full matrix computations. By representing
density matrices via low-rank factors and applying Krylov subspace methods for
partial eigendecompositions, we reduce the per-step complexity of Runge-Kutta
and Adams-Bashforth schemes from $\mathcal{O}(N^3)$ to $\mathcal{O}(r^2N)$,
where $N = 2^n$ is the Hilbert space dimension for $n$ spins and $r \ll N$ the
effective rank. Similarly, memory costs shrink from $\mathcal{O}(N^2)$ to
$\mathcal{O}(rN)$, since no full $N\times N$ matrices are formed. A key advance
is handling the invariant subspace of zero eigenvalues. By using Householder
reflectors built for the dominant eigenspace, we perform the solution entirely
without large matrices. For example, a time step of a twenty-spin system, with
density matrix size over one million, now takes only seconds on a standard
laptop. Both Runge-Kutta and Adams-Bashforth methods are reformulated to
preserve physical properties of the density matrix throughout evolution. This
low-rank algorithm enables simulations of much larger spin systems, which were
previously infeasible, providing a powerful tool for comparing q-LL and q-LLG
dynamics, testing each model validity, and probing how quantum features such as
correlations and entanglement evolve across different regimes of system size
and damping.

</details>


### [197] [Optical Integration With Heralded Single Photons](https://arxiv.org/abs/2508.21161)
*L. Marques Fagundes Silva,R. C. Souza Pimenta,M. H. Magiotto,R. M. Gomes,E. I. Duzzioni,R. Medeiros de Araújo,P. H. Souto Ribeiro*

Main category: quant-ph

TL;DR: 本文研究了单光子光学集成及其空间关联作用，并与DQC1模型联系起来。


<details>
  <summary>Details</summary>
Motivation: 研究单光子光学集成的空间关联作用及其在光学处理方案中的应用。

Method: 利用受激单光子，通过相位空间光调制器和偏振辅助，对二元相位进行编码，实现光学集成。

Result: 空间不相关光子能捕捉图像的全局特性，而空间相关光子能更好地捕捉图像的局部特性。

Conclusion: 本文实现的方案与DQC1模型有很强的联系，并验证了空间关联对光学集成的作用。

Abstract: In this work, we perform optical integration with heralded single photons and
investigate the role played by the spatial correlation between the photons in
this task. To address this, we experimentally investigate the use of the
transverse spatial degrees of freedom of light in an optical processing scheme
utilizing heralded single photons. The integration is realized over the binary
phases encoded with a phase-only spatial light modulator assisted by
polarization. As a result, while spatially uncorrelated photons can capture the
global properties of an image displayed in a spatial light modulator,
correlated photons capture the local properties of the image better. Also,
emphasize the strong connection between the optical integration scheme
implemented here and the DQC1 (deterministic quantum computation with one
qubit) model.

</details>


### [198] [Communication scenario enables robust self-testing of n-party Greenberger-Horne-Zeilinger basis measurements](https://arxiv.org/abs/2508.21178)
*Barnik Bhaumik,Sagnik Ray,Debashis Saha*

Main category: quant-ph

TL;DR: 该研究提出了一种无需共享纠缠即可自测试n量子比特GHZ基测量的半设备无关方法，仅基于通信场景下的输入输出统计数据。此外，还提出了一个易于在光学装置中实现的鲁棒的、三输出的贝尔部分基测量自测试协议。


<details>
  <summary>Details</summary>
Motivation: 为了在量子网络中跨越远距离分发量子纠缠，纠缠基测量至关重要。本研究旨在解决在没有共享纠缠的情况下自我测试n量子比特GHZ基测量的问题。

Method: 采用半设备无关的方法，仅依赖于涉及n个发送方（每个发送方接收两个输入比特）和一个没有输入的接收方的通信场景下的输入-输出统计数据。对所提出的自测试协议的鲁棒性进行了分析，并提出了一个用于鲁棒的、三输出的贝尔部分基测量自测试协议。

Result: 提出了一种半设备无关的方法，可以自测试n量子比特GHZ基测量，而无需共享纠缠。同时，还提出了一个用于鲁棒的、三输出的贝尔部分基测量自测试协议，该协议易于在光学装置中实现。

Conclusion: 该研究提出了一种在没有共享纠缠的情况下自测试n量子比特GHZ基测量的方法，并提供了一个可行的贝尔部分基测量自测试协议，为量子网络中的纠缠分发和测量验证提供了新的途径。

Abstract: Entangled basis measurements play a crucial role in distributing quantum
entanglement between parties across a quantum network. In this work, we adopt a
semi-device-independent approach that enables the self-testing of n-qubit
Greenberger-Horne-Zeilinger (GHZ) basis measurements without requiring shared
entanglement between distant parties. Our method relies solely on input-output
statistics from a communication scenario involving n spatially separated
senders, each receiving two bits of input, and a single receiver with no input.
We analyze the robustness of the proposed self-testing protocol. Additionally,
we introduce a protocol for robust self-testing of the three-outcome partial
Bell basis measurement that is easily implementable in an optical setup.

</details>


### [199] [1D Cluster State Generation On Superconducting Hardware](https://arxiv.org/abs/2508.21798)
*Rahul Dev Sharma,Md Sakibul Islam*

Main category: quant-ph

TL;DR: MBQC需要纠缠作为资源，但生成簇态是瓶颈。本文使用电荷量子比特阵列推导并验证了4量子比特簇态的生成，分析了理想和有噪声情况下的保真度。结果表明，能量弛豫（T1）可实现>90%的保真度，而纯粹的退相干（T2）会导致保真度下降。在噪声下，T2效应比T1效应更能降低簇态制备的保真度，凸显了在近期MBQC实现中进行错误缓解策略的必要性。


<details>
  <summary>Details</summary>
Motivation: 纠缠是MBQC的一种资源，但生成簇态是其应用的关键瓶颈。

Method: 本文利用电荷量子比特阵列，对4量子比特簇态的生成进行了解析推导和数值验证，并比较了理想情况（无噪声）和考虑退相干效应下的保真度。

Result: 在考虑能量弛豫（T1）的情况下，保真度大于90%；而纯粹的退相干（T2）在第四谐波时会导致70%的保真度衰减。在噪声环境下，T2会导致保真度在15个时间单位内衰减到50%，而仅考虑T1时保真度仍大于70%，这表明T2对簇态制备的退化效应比T1更显著。

Conclusion: 近期MBQC的实现需要针对性的错误缓解策略，因为退相干效应对簇态制备的影响比能量弛豫更严重。

Abstract: Measurement-based Quantum Computation(MBQC) utilize entanglement as resource
for performing quantum computation. Generating cluster state using entanglement
as resource is a key bottleneck for the adoption of MBQC. To generate cluster
state with charge-qubit arrrays, we provide analytical derivations and
numerical validations for 4-qubit cluster state. We compare our fidelities
under ideal (noise-free) Hamiltonian evolution and due to effect of
decoherence. We show incorporating energy relaxation ($T_1$) yields $>$90\%
fidelity while pure dephasing $T_2$ show $70\%$ decays at fourth harmonics. We
further show under noise $T_2$ decays to 50\% within 15 time units, versus
$>$70\% under relaxation time units ($T_1$)--only. This decay quantify
degradation effect of $T_2$ on preparing cluster--state preparation is more
than $T_1$. We highlight the critical need for targeted error-mitigation
strategies in near-term MBQC implementations.

</details>


### [200] [Unitary Synthesis with AlphaZero via Dynamic Circuits](https://arxiv.org/abs/2508.21217)
*Xavier Valcarce,Bastien Grivet,Nicolas Sangouard*

Main category: quant-ph

TL;DR: 使用受 AlphaZero 启发的强化学习代理进行量子单位综合。


<details>
  <summary>Details</summary>
Motivation: 量子单位综合是将目标单位变换分解为量子门序列，这是一个具有挑战性的任务，因为可能的门组合数量随着电路深度的增加呈指数增长。

Method: 提出了一种使用受 AlphaZero 启发的强化学习代理，使用离散逻辑门集合精确编译单位的方法。

Result: 该方法实现了较低的推理时间和跨不同门集和量子比特连接的通用性。利用这种灵活性，我们探索了具有动态电路（包含测量和条件门等非单位运算的电路）的单位综合，并发现了逻辑量子门的不寻常实现。

Conclusion: 虽然完整算法的直接综合是难以处理的，但该方法非常适合高效地综合子程序，当这些子程序在算法执行期间被反复调用时，这可能会产生重大影响。

Abstract: Unitary synthesis is the process of decomposing a target unitary
transformation into a sequence of quantum gates. This is a challenging task, as
the number of possible gate combinations grows exponentially with the circuit
depth. In this manuscript, we propose an approach using an AlphaZero-inspired
reinforcement-learning agent for the exact compilation of unitaries using
discrete sets of logic gates. The approach achieves low inference time and
proves versatile across different gate sets, and qubit connectivities.
Leveraging this flexibility, we explore unitary synthesis with dynamic circuits
-- circuits that contain non-unitary operations such as measurements and
conditional gates -- and discover unusual implementations of logical quantum
gates. Although the direct synthesis of complete algorithms is intractable, our
approach is well suited for efficiently synthesizing subroutines. This may have
a significant impact when these subroutines are invoked repeatedly during
algorithm execution.

</details>


### [201] [Optimal Finite-Time Thermodynamics of Effective Two-Level Systems](https://arxiv.org/abs/2508.19341)
*Alberto Rolandi*

Main category: quant-ph

TL;DR: 该研究推广了Esposito等人关于从两能级系统中提取最大功的工作，优化了所有驱动速度下的控制，并考虑了潜在的量子动力学，只要它们导致马尔可夫主方程。研究分析了这些系统的有限时间热力学，并确定了依赖于粗粒化大小的最优协议，同时推导了有效两能级系统转化的速度极限。


<details>
  <summary>Details</summary>
Motivation: 在纳微观系统中，由于涨落对小系统动力学的重要作用，将热能转化为功和最小化耗散是一个复杂的挑战。本研究旨在解决这一挑战，特别关注于从有效两能级系统中提取最大功的优化控制。

Method: 通过推广Esposito等人的工作，本研究允许系统具有潜在的量子动力学，只要这些动力学能够进行粗粒化，从而得到一个马尔可夫主方程。在此基础上，研究分析了这些系统的有限时间热力学，并确定了最优协议，这些协议与获得两能级系统所需的粗粒化大小有关。此外，研究利用这些结果推导了在有效两能级系统上进行的任何转化的速度极限。

Result: 研究确定了最优协议，这些协议的特点是依赖于获得两能级系统所需的粗粒化大小。此外，研究推导了在有效两能级系统上进行的任何转化的速度极限。

Conclusion: 本研究成功地推广了现有理论，以优化任意驱动速度下从有效两能级系统中提取最大功的控制，同时考虑了潜在的量子动力学。研究结果表明，最优协议和速度极限与实现两能级系统所需的粗粒化程度密切相关。

Abstract: The optimization of the conversion of thermal energy into work and the
minimization of dissipation for nano- and mesoscopic systems is a complex
challenge because of the important role fluctuations play on the dynamics of
small systems. We generalize the work of Esposito et al. EPL 89, 20003 (2010)
to optimize at all driving speeds the control needed to extract the maximum
amount of work from any effective two-level systems. These emerge when one
coarse-grains degrees of freedom, which is often unavoidable to obtain
"real-world" two-level systems. In particular, we allow even for the system to
have underlying quantum dynamics, as long as these allow for a coarse-graining
that leads to a Markovian master equation. We analyze the finite-time
thermodynamics of these systems and find the thermodynamically optimal
protocols, which depend on the size of the coarse-graining needed to obtain a
two-level system. Furthermore, we use these results to derive speed-limits for
any transformation performed on an effective two-level system.

</details>


### [202] [Qubit Health Analytics and Clustering for HPC-Integrated Quantum Processors](https://arxiv.org/abs/2508.21231)
*Xiaolong Deng,Laura Schulz,Martin Schulz*

Main category: quant-ph

TL;DR: 该论文提出了一个数据驱动的框架，用于分析量子计算的校准数据，以预测硬件性能并优化操作流程。


<details>
  <summary>Details</summary>
Motivation: 为了在超级计算中心实现量子计算，需要有强大的工具来分析校准数据集、预测硬件性能和优化操作流程。

Method: 该模型基于来自我们内部的 20  qubit NISQ 设备超过 250 天的真实校准质量指标数据集。我们应用详细的数据分析来揭示时间模式和跨指标相关性。使用无监督聚类，我们识别稳定和有噪声的 qubit。我们还使用 GHZ 态实验验证了我们的模型。

Result: 该研究提供了健康指标以及面向硬件的维护和重新校准建议。

Conclusion: 该研究为将相关调度器集成到 HPCQC 工作流程中提供了动力。

Abstract: Quantum computing in supercomputing centers requires robust tools to analyze
calibration datasets, predict hardware performance, and optimize operational
workflows. This paper presents a data-driven framework for processing
calibration metrics. Our model is based on a real calibration quality metrics
dataset from our in-house 20-qubit NISQ device and for more than 250 days. We
apply detailed data analysis to uncover temporal patterns and cross-metric
correlations. Using unsupervised clustering, we identify stable and noisy
qubits. We also validate our model using GHZ state experiments. Our study
provides health indicators as well as hardware-driven maintenance and
recalibration recommendations, thus motivating the integration of relevant
schedulers with HPCQC workflows.

</details>


### [203] [HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits](https://arxiv.org/abs/2508.21246)
*Ahmad Alomari,Sathish A. P. Kumar*

Main category: quant-ph

TL;DR: 该研究提出了一种混合协同进化算法（HCQA），用于设计最优量子传感器电路（QSCs），以解决复杂的量子物理问题。该算法结合了深度Q网络（DQN）进行学习和策略优化，并通过基于Q值的量子动作选择机制进行增强。通过量子电路编码智能体状态，并利用测量产生概率性的动作结果，该算法能够自动生成高量子Fisher信息（QFI）的量子态，如压缩态，用于量子态估计和控制。实验结果表明，该HCQA能够有效设计最优QSCs，实现1的QFI。


<details>
  <summary>Details</summary>
Motivation: 设计最优量子传感器电路（QSCs）以解决复杂的量子物理问题，并实现高量子Fisher信息（QFI）的量子态生成。

Method: 提出一种混合协同进化算法（HCQA），集成深度Q网络（DQN）进行学习和策略优化，并结合基于Q值的量子动作选择机制。利用量子电路编码状态、产生动作叠加，并通过测量获得概率性动作结果，以选择最大化QFI并最小化门数量的门序列。

Result: HCQA在包含两个量子比特和一系列Rx、Ry、S门的QSC上进行了评估，证明了其在生成最优QSC方面的效率，实现了1的QFI。

Conclusion: AI驱动的学习与量子计算相结合，智能体能够自主发现最优量子电路设计，从而增强传感和估计任务。

Abstract: This study proposes an HCQA for designing optimal Quantum Sensor Circuits
(QSCs) to address complex quantum physics problems. The HCQA integrates
computational intelligence techniques by leveraging a Deep Q-Network (DQN) for
learning and policy optimization, enhanced by a quantum-based action selection
mechanism based on the Q-values. A quantum circuit encodes the agent current
state using Ry gates, and then creates a superposition of possible actions.
Measurement of the circuit results in probabilistic action outcomes, allowing
the agent to generate optimal QSCs by selecting sequences of gates that
maximize the Quantum Fisher Information (QFI) while minimizing the number of
gates. This computational intelligence-driven HCQA enables the automated
generation of entangled quantum states, specifically the squeezed states, with
high QFI sensitivity for quantum state estimation and control. Evaluation of
the HCQA on a QSC that consists of two qubits and a sequence of Rx, Ry, and S
gates demonstrates its efficiency in generating optimal QSCs with a QFI of 1.
This work highlights the synergy between AI-driven learning and quantum
computation, illustrating how intelligent agents can autonomously discover
optimal quantum circuit designs for enhanced sensing and estimation tasks.

</details>


### [204] [Quantum Machine Learning for Optimizing Entanglement Distribution in Quantum Sensor Circuits](https://arxiv.org/abs/2508.21252)
*Laxmisha Ashok Attisara,Sathish Kumar*

Main category: quant-ph

TL;DR: 本文提出了一种利用量子机器学习技术优化量子传感器电路中的纠缠分布的新方法，通过强化学习最大化量子fisher信息和纠缠熵，同时最小化电路深度和门数量，实现了20-86%的电路性能和灵敏度提升。


<details>
  <summary>Details</summary>
Motivation: 量子计算和量子传感领域的快速发展，需要优化量子电路以提高性能和效率，特别是利用纠缠来实现高灵敏度和测量精度。

Method: 利用量子机器学习技术，特别是强化学习，在量子环境中优化量子传感器电路中的纠缠布局，以最大化量子Fisher信息（QFI）和纠缠熵，同时最小化电路深度和门数量。使用Qiskit实现，并整合了噪声模型和错误缓解策略。

Result: 量子机器学习方法在优化量子传感器电路中的纠缠分布方面取得了显著成效，实现了高QFI和熵（0.84-1.0），并减少了20-86%的电路深度和门数量，提高了电路性能和灵敏度。

Conclusion: 机器学习在量子电路优化方面具有巨大潜力，通过本文提出的方法可以显著提升量子传感器的性能和效率。

Abstract: In the rapidly evolving field of quantum computing, optimizing quantum
circuits for specific tasks is crucial for enhancing performance and
efficiency. More recently, quantum sensing has become a distinct and rapidly
growing branch of research within the area of quantum science and technology.
The field is expected to provide new opportunities, especially regarding high
sensitivity and precision. Entanglement is one of the key factors in achieving
high sensitivity and measurement precision [3]. This paper presents a novel
approach utilizing quantum machine learning techniques to optimize entanglement
distribution in quantum sensor circuits. By leveraging reinforcement learning
within a quantum environment, we aim to optimize the entanglement layout to
maximize Quantum Fisher Information (QFI) and entanglement entropy, which are
key indicators of a quantum system's sensitivity and coherence, while
minimizing circuit depth and gate counts. Our implementation, based on Qiskit,
integrates noise models and error mitigation strategies to simulate realistic
quantum environments. The results demonstrate significant improvements in
circuit performance and sensitivity, highlighting the potential of machine
learning in quantum circuit optimization by measuring high QFI and entropy in
the range of 0.84-1.0 with depth and gate count reduction by 20-86%.

</details>


### [205] [Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits](https://arxiv.org/abs/2508.21253)
*Laxmisha Ashok Attisara,Sathish Kumar*

Main category: quant-ph

TL;DR: 提出一种结合强化学习与张量网络（MPS）的工程方法，用于优化大规模量子传感器电路（高达60个量子比特），以提高量子传感器的灵敏度和效率。


<details>
  <summary>Details</summary>
Motivation: 随着量子比特数量的增加，量子电路的设计和控制变得日益复杂，手动优化不可行。优化大规模量子电路中的纠缠分布对于提高量子传感器的灵敏度和效率至关重要。

Method: 采用张量网络方法（特别是矩阵乘积态MPS表示）进行高效可扩展的模拟，并结合强化学习（RL）代理。RL代理学习重构电路，以最大化量子费舍尔信息（QFI）和纠缠熵，同时减少门计数和电路深度。

Result: 实验结果显示，QFI值接近1，纠缠熵在0.8-1.0范围内，电路深度和门计数减少高达90%。

Conclusion: 结合量子机器学习和张量网络有潜力在现实约束下优化复杂的量子电路。

Abstract: As the number of qubits in a sensor increases, the complexity of designing
and controlling the quantum circuits grows exponentially. Manually optimizing
these circuits becomes infeasible. Optimizing entanglement distribution in
large-scale quantum circuits is critical for enhancing the sensitivity and
efficiency of quantum sensors [5], [6]. This paper presents an engineering
integration of reinforcement learning with tensor-network-based simulation
(MPS) for scalable circuit optimization for optimizing quantum sensor circuits
with up to 60 qubits. To enable efficient simulation and scalability, we adopt
tensor network methods, specifically the Matrix Product State (MPS)
representation, instead of traditional state vector or density matrix
approaches. Our reinforcement learning agent learns to restructure circuits to
maximize Quantum Fisher Information (QFI) and entanglement entropy while
reducing gate counts and circuit depth. Experimental results show consistent
improvements, with QFI values approaching 1, entanglement entropy in the
0.8-1.0 range, and up to 90% reduction in depth and gate count. These results
highlight the potential of combining quantum machine learning and tensor
networks to optimize complex quantum circuits under realistic constraints.

</details>


### [206] [Quantum Physics using Weighted Model Counting](https://arxiv.org/abs/2508.21288)
*Dirck van den Ende,Joon Hyung Lee,Alfons Laarman*

Main category: quant-ph

TL;DR: 本文提出了一种将量子物理中的线性代数问题表示为加权模型计数（WMC）实例的通用框架，通过将狄拉克符号转换为WMC问题，并提供了Python实现。该框架在计算横向场伊辛模型和Potts模型的配分函数方面显示了有效性，表明自动化推理中的启发式方法可系统地应用于量子物理问题。


<details>
  <summary>Details</summary>
Motivation: 现有的量子物理WMC方法仅针对特定问题实例，缺乏通用的问题表达框架，限制了可重用性并可能缺乏数学严谨性。

Method: 提出一个将狄拉克符号转换为WMC问题的框架，通过类型系统和表示性语义进行理论构建，并提供Python实现。

Result: 成功计算了横向场伊辛模型（量子）和Potts模型（经典）的配分函数，证明了该框架的有效性。

Conclusion: 所提出的框架可以将自动化推理中的启发式方法系统地应用于更广泛的量子物理问题。

Abstract: Weighted model counting (WMC) has proven effective at a range of tasks within
computer science, physics, and beyond. However, existing approaches for using
WMC in quantum physics only target specific problem instances, lacking a
general framework for expressing problems using WMC. This limits the
reusability of these approaches in other applications and risks a lack of
mathematical rigor on a per-instance basis. We present an approach for
expressing linear algebraic problems, specifically those present in physics and
quantum computing, as WMC instances. We do this by introducing a framework that
converts Dirac notation to WMC problems. We build up this framework
theoretically, using a type system and denotational semantics, and provide an
implementation in Python. We demonstrate the effectiveness of our framework in
calculating the partition functions of several physical models: The
transverse-field Ising model (quantum) and the Potts model (classical). The
results suggest that heuristics developed in automated reasoning can be
systematically applied to a wide class of problems in quantum physics through
our framework.

</details>


### [207] [Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures](https://arxiv.org/abs/2508.21332)
*Chi-Sheng Chen,En-Jui Kuo*

Main category: quant-ph

TL;DR: 本研究比较了量子文本生成模型与传统Transformer/MLP模型的性能，发现在大多数指标上Transformer模型表现更优，但在特定场景下，量子模型如QKSAN和QRWKV在重复率和词汇多样性方面表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 随着对量子计算在自然语言处理领域应用的兴趣日益增长，本研究旨在全面评估量子文本生成模型与传统Transformer/MLP架构的性能。

Method: 本研究通过在五种不同数据集（简单句子、短篇故事、量子短语、俳句诗歌和谚语）上，对Transformer（基线）、量子核自注意力网络（QKSAN）、量子RWKV（QRWKV）和量子注意力序列架构（QASA）这五种模型进行系统性实验。评估指标包括困惑度、BLEU分数、词汇多样性、重复率和流畅性度量。

Result: 实验结果表明，尽管传统Transformer模型在整体上表现更优，平均困惑度最低（1.21），BLEU-1分数最高（0.2895），但量子启发模型在特定场景下表现出竞争力。具体来说，QKSAN实现了0.2800的BLEU-1分数，同时保持零重复率；QRWKV在某些任务中表现出完美的词汇多样性（Distinct-1 = 1.000）。

Conclusion: 本研究对量子文本生成模型与传统模型的性能进行了全面评估。结果显示，传统Transformer模型在整体文本生成质量上仍占优势，但在词汇多样性和控制重复性方面，量子模型展现了其独特的潜力。

Abstract: This paper presents a comprehensive evaluation of quantum text generation
models against traditional Transformer/MLP architectures, addressing the
growing interest in quantum computing applications for natural language
processing. We conduct systematic experiments comparing five distinct models:
Transformer (baseline), Quantum Kernel Self-Attention Network (QKSAN), Quantum
RWKV (QRWKV), and Quantum Attention Sequence Architecture (QASA) across five
diverse datasets including simple sentences, short stories, quantum phrases,
haiku poetry, and proverbs. Our evaluation employs multiple metrics including
perplexity, BLEU scores, vocabulary diversity, repetition rates, and fluency
measures to assess different aspects of text generation quality. The
experimental results reveal that while traditional Transformer models maintain
overall superiority with the lowest average perplexity (1.21) and highest
BLEU-1 score (0.2895), quantum-inspired models demonstrate competitive
performance in specific scenarios. Notably, QKSAN achieves a competitive BLEU-1
score of 0.2800 while maintaining zero repetition rates, and QRWKV demonstrates
perfect vocabulary diversity (Distinct-1 = 1.000) in certain tasks.

</details>


### [208] [Accelerating Transpilation in Quantum Machine Learning with Haiqu's Rivet-transpiler](https://arxiv.org/abs/2508.21342)
*Aleksander Kaczmarek,Dikshant Dulal*

Main category: quant-ph

TL;DR: Riveted transpiler speeds up quantum circuit transpilation by reusing previously transpiled circuits, showing up to 600% improvement for quantum layerwise learning.


<details>
  <summary>Details</summary>
Motivation: The cost of quantum circuit transpilation escalates significantly with the number of qubits and the need for optimization under device-specific constraints, particularly for applications like quantum chemistry and iterative circuit modification in quantum layerwise learning.

Method: The Rivet transpiler was used, which accelerates transpilation by reusing previously transpiled circuits. This approach was compared to standard transpilation without reuse.

Result: Up to 600% improvement in transpilation time for quantum layerwise learning was demonstrated using the Rivet transpiler compared to standard transpilation without reuse.

Conclusion: The Rivet transpiler, by reusing previously transpiled circuits, offers significant speedups for transpilation, making it a valuable tool for applications involving complex quantum circuits or iterative modifications.

Abstract: Transpilation is a crucial process in preparing quantum circuits for
execution on hardware, transforming virtual gates to match device-specific
topology by introducing swap gates and basis gates, and applying optimizations
that reduce circuit depth and gate count, particularly for two-qubit gates. As
the number of qubits increases, the cost of transpilation escalates
significantly, especially when trying to find the optimal layout with minimal
noise under the qubit connectivity constraints imposed by device topology. In
this work, we use the Rivet transpiler, which accelerates transpilation by
reusing previously transpiled circuits. This approach is relevant for cases
such as quantum chemistry, where multiple Pauli terms need to be measured by
appending a series of rotation gates at the end for non-commuting Paulis, and
for more complex cases when quantum circuits need to be modified iteratively,
as occurs in quantum layerwise learning. We demonstrate up to 600% improvement
in transpilation time for quantum layerwise learning using the Rivet transpiler
compared to standard transpilation without reuse.

</details>


### [209] [Optimizing sparse quantum state preparation with measurement and feedforward](https://arxiv.org/abs/2508.21346)
*Yao-Cheng Lu,Han-Hsuan Lin*

Main category: quant-ph

TL;DR: 本工作提出两种稀疏量子状态制备（SQSP）算法，将电路深度分别优化至O(nlogn)和O(n)，同时保持O(dn)的尺寸和O(d)的辅助量子比特，在特定条件下优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在减少稀疏量子状态制备（SQSP）的电路深度，特别是在辅助量子比特数量有限的情况下。SQSP是许多量子算法的关键组成部分，关注制备具有少量非零振幅的状态。

Method: 提出两种SQSP算法：一种深度为O(nlogn)，另一种利用中途测量和前馈（允许中间测量结果控制后续操作）将深度优化至O(n)。两种算法的尺寸均为O(dn)，并使用O(d)辅助量子比特。

Result: 提出的两种算法实现了O(nlogn)和O(n)的电路深度，优于arXiv:2108.06150中当辅助量子比特数量m=d时的状态。

Conclusion: 本研究成功提出了两种改进的SQSP算法，在有限辅助量子比特条件下显著降低了电路深度，为量子算法的实现提供了更优的选择。

Abstract: Quantum state preparation (QSP) is a key component in many quantum
algorithms. In particular, the problem of sparse QSP (SQSP) $\unicode{x2013}$
the task of preparing the states with only a small number of non-zero
amplitudes $\unicode{x2013}$ has garnered significant attention in recent
years. In this work, we focus on reducing the circuit depth of SQSP with
limited number of ancilla qubits. We present two SQSP algorithms: one with
depth $O(n\log d)$, and another that reduces depth to $O(n)$. The latter
leverages mid-circuit measurement and feedforward, where intermediate
measurement outcomes are used to control subsequent quantum operations. Both
constructions have size $O(dn)$ and use $O(d)$ ancilla qubits. Compared to the
state-of-the-art SQSP algorithm in arXiv:2108.06150, which allows an arbitrary
number of ancilla qubits $m>0$, both of our algorithms achieve lower circuit
depth when $m=d$.

</details>


### [210] [$k$-Positive Maps: New Characterizations and a Generation Method](https://arxiv.org/abs/2508.21348)
*Frederik vom Ende,Sumeet Khatri,Sergey Denisov*

Main category: quant-ph

TL;DR: 本文研究了矩阵代数上的k-正线性映射，解决了k-正性的刻画和非可分k-正性映射的生成问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决k-正线性映射的两个问题：k-正性的刻画和非可分k-正性映射的生成。

Method: 利用优化方法推导了等价于k-正性的条件，并提出了一种基于李半群的方法来生成非可分k-正性映射。还提出了一种半定规划（SDP）来检验PPT方猜想的一个等价形式。

Result: 文中给出了k-正性的优化刻画，并揭示了其与张量谱范数以及可分离状态优化问题的联系。所提出的方法能够生成k-正性非可分映射的单参数族，并在d=3和d=4的情况下进行了说明。SDP检验未能违反PPT方猜想。

Conclusion: 本文的研究为k-正性的计算认证提供了实用的工具，并为k-正性非可分映射的采样提供了一种系统的方法。

Abstract: We study $k$-positive linear maps on matrix algebras and address two
problems, (i) characterizations of $k$-positivity and (ii) generation of
non-decomposable $k$-positive maps. On the characterization side, we derive
optimization-based conditions equivalent to $k$-positivity that (a) reduce to a
simple check when $k=d$, (b) reveal a direct link to the spectral norm of
certain order-3 tensors (aligning with known NP-hardness barriers for $k<d$),
and (c) recast $k$-positivity as a novel optimization problem over separable
states, thereby connecting it explicitly to separability testing. On the
generation side, we introduce a Lie-semigroup-based method that, starting from
a single $k$-positive map, produces one-parameter families that remain
$k$-positive and non-decomposable for small enough times. We illustrate this by
generating such families for $d=3$ and $d=4$. We also formulate a semi-definite
program (SDP) to test an equivalent form of the positive partial transpose
(PPT) square conjecture (and do not find any violation of the latter). Our
results provide practical computational tools for certifying $k$-positivity and
a systematic way to sample $k$-positive non-decomposable maps.

</details>


### [211] [QUAV: Quantum-Assisted Path Planning and Optimization for UAV Navigation with Obstacle Avoidance](https://arxiv.org/abs/2508.21361)
*Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Yung-Sze Gan,Frederic Barbaresco,Muhammad Shafique*

Main category: quant-ph

TL;DR: QUAV是一个基于QAOA的量子辅助无人机路径规划框架，旨在解决城市和受限空域中实时、安全、可扩展的路径规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决城市和受限空域中无人机导航对实时、安全、可扩展的路径规划的需求，以及经典方法在高维动态约束下的计算瓶颈。

Method: 将路径规划建模为量子优化问题，利用QAOA探索多条路径，并结合UTM坐标转换处理障碍物约束和地理空间精度。

Result: QUAV在模拟和IBM ibm_kyiv后端硬件上进行了验证，生成了可行的、高效的轨迹，并证明了其在噪声下的鲁棒性。理论分析表明，在固定优化设置下，QUAV的电路深度相对于边数具有线性扩展性。

Conclusion: QUAV展示了量子方法在未来无人机导航系统中的应用潜力，能够生成可行的、高效的轨迹。

Abstract: The growing demand for drone navigation in urban and restricted airspaces
requires real-time path planning that is both safe and scalable. Classical
methods often struggle with the computational load of high-dimensional
optimization under dynamic constraints like obstacle avoidance and no-fly
zones. This work introduces QUAV, a quantum-assisted UAV path planning
framework based on the Quantum Approximate Optimization Algorithm (QAOA), to
the best of our knowledge, this is one of the first applications of QAOA for
drone trajectory optimization. QUAV models pathfinding as a quantum
optimization problem, allowing efficient exploration of multiple paths while
incorporating obstacle constraints and geospatial accuracy through UTM
coordinate transformation. A theoretical analysis shows that QUAV achieves
linear scaling in circuit depth relative to the number of edges, under fixed
optimization settings. Extensive simulations and a real-hardware implementation
on IBM's ibm_kyiv backend validate its performance and robustness under noise.
Despite hardware constraints, results demonstrate that QUAV generates feasible,
efficient trajectories, highlighting the promise of quantum approaches for
future drone navigation systems.

</details>


### [212] [CircuitHunt: Automated Quantum Circuit Screening for Superior Credit-Card Fraud Detection](https://arxiv.org/abs/2508.21366)
*Nouhaila Innan,Akshat Singh,Muhammad Shafique*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Designing effective quantum models for real-world tasks remains a key
challenge within Quantum Machine Learning (QML), particularly in applications
such as credit card fraud detection, where extreme class imbalance and evolving
attack patterns demand both accuracy and adaptability. Most existing approaches
rely on either manually designed or randomly initialized circuits, leading to
high failure rates and limited scalability. In this work, we introduce
CircuitHunt, a fully automated quantum circuit screening framework that
streamlines the discovery of high-performing models. CircuitHunt filters
circuits from the KetGPT dataset using qubit and parameter constraints, embeds
each candidate into a standardized hybrid QNN, and performs rapid training with
checkpointing based on macro-F1 scores to discard weak performers early. The
top-ranked circuit is then fully trained, achieving 97% test accuracy and a
high macro-F1 score on a challenging fraud detection benchmark. By combining
budget-aware pruning, empirical evaluation, and end-to-end automation,
CircuitHunt reduces architecture search time from days to hours while
maintaining performance. It thus provides a scalable and task-driven tool for
QML deployment in critical financial applications.

</details>


### [213] [Quantum Learning with Tunable Loss Functions](https://arxiv.org/abs/2508.21369)
*Yixian Qiu,Lirandë Pira,Patrick Rebentrost*

Main category: quant-ph

TL;DR: 提出了一种适用于量子过程学习的倾斜经验风险最小化（QTERM）框架，并证明了其可学习性、泛化能力和模型选择保证。


<details>
  <summary>Details</summary>
Motivation: 现有的学习理论框架在处理量子数据和量子过程时面临挑战，需要新的复杂性度量和学习框架。

Method: 提出并定义了量子倾斜经验风险最小化（QTERM），并推导了其样本复杂度上界，建立了经典TERM的PAC泛化界，并提出了QTERM的agnostic学习保证。

Result: 证明了QTERM的可学习性，提供了QTERM样本复杂度的上界，建立了经典TERM的PAC泛化界，并为量子假设选择提供了QTERM agnostic学习保证。

Conclusion: QTERM是量子过程学习的一种有竞争力的替代方法，能够改善泛化能力，为学习量子过程的可行性提供了更广泛的复杂性界限。

Abstract: Learning from quantum data presents new challenges to the paradigm of
learning from data. This typically entails the use of quantum learning models
to learn quantum processes that come with enough subtleties to modify the
theoretical learning frameworks. This new intersection warrants new frameworks
for complexity measures, including those on quantum sample complexity and
generalization bounds. Empirical risk minimization (ERM) serves as the
foundational framework for evaluating learning models in general. The diversity
of learning problems leads to the development of advanced learning strategies
such as tilted empirical risk minimization (TERM). Theoretical aspects of
quantum learning under a quantum ERM framework are presented in [PRX Quantum 5,
020367 (2024)]. In this work, we propose a definition for TERM suitable to be
employed when learning quantum processes, which gives rise to quantum TERM
(QTERM). We show that QTERM can be viewed as a competitive alternative to
implicit and explicit regularization strategies for quantum process learning.
This work contributes to the existing literature on quantum and classical
learning theory threefold. First, we prove QTERM learnability by deriving upper
bounds on QTERM's sample complexity. Second, we establish new PAC
generalization bounds on classical TERM. Third, we present QTERM agnostic
learning guarantees for quantum hypothesis selection. These results contribute
to the broader literature of complexity bounds on the feasibility of learning
quantum processes, as well as methods for improving generalization in quantum
learning.

</details>


### [214] [Characterization of Linear Measurements in Cavity Optomechanics: Examples and Applications](https://arxiv.org/abs/2508.21419)
*F. Bemani,O. Černotík,R. Filip*

Main category: quant-ph

TL;DR: 本文提出了一种量化光力学测量性能的分析框架，用于比较不同测量方法的优劣，并为量子无耗损测量提供了新的策略。


<details>
  <summary>Details</summary>
Motivation: 理解物理测量对于设计高效的计量策略、测量反馈方案以及寻找测量灵敏度的基本限制至关重要。在量子领域，测量会因海森堡不确定性原理而对系统状态产生测量后效作用。光力学和机电设备的测量方法多种多样，但难以直接比较。因此，有必要开发一个框架来量化光力学测量的性能。

Method: 本文开发了一个使用少数相关指标量化光力学测量性能的理论框架。该方法借鉴了量子光学中类似的表征方法，量化了量子测量的主要特性——区分不同量子态的能力以及在测量噪声存在下信号的保持能力。作者将此框架应用于位移检测、相干量子噪声消除和量子无耗损测量等常见的光力学测量，并对光力学无耗损测量的误差进行了详细分析。

Result: 通过将该框架应用于位移检测、相干量子噪声消除和量子无耗损测量，作者能够详细分析误差，并提出一种用于悬浮体系中量子无耗损测量的相干散射策略。

Conclusion: 本研究提出的分析框架和对误差的详细分析，补充了现有的线性光力学相互作用知识，并为理解光力学测量开辟了新的途径，有望在基础物理学和量子技术中实现新的应用。

Abstract: Detailed understanding of physical measurements is essential for devising
efficient metrological strategies and measurement-feedback schemes, as well as
finding fundamental limitations on measurement sensitivity. In the quantum
regime, measurements modify the state of the system of interest through
measurement backaction as a direct consequence of the Heisenberg principle. In
cavity optomechanics and electromechanics, a plethora of strategies exist for
measuring the mechanical motion using electromagnetic fields, each leading to
different competition between measurement imprecision and backaction. While
this range of techniques allows broad applications of optomechanical and
electromechanical devices, it makes direct comparison of different measurement
methods difficult. We develop a formalism for quantifying the performance of
optomechanical measurements using a few relevant figures of merit. Our approach
is inspired by similar characterizations in quantum optics and quantifies the
main properties of quantum measurements -- the ability to distinguish different
quantum states and preservation of signal in the presence of measurement noise.
We demonstrate our concept on the most common optomechanical measurements --
displacement detection, coherent quantum noise cancellation, and quantum
nondemolition measurements -- and perform detailed analysis of errors in
optomechanical nondemolition measurements. This newly acquired knowledge allows
us to propose a strategy for quantum nondemolition measurements in
levitodynamics using coherent scattering. Our results complement existing
knowledge of linear optomechanical interactions and open the way to new
understanding of optomechanical measurements, thus allowing also novel
applications of optomechanical devices in fundamental physics and quantum
technologies.

</details>


### [215] [Computationally Tractable Offline Quantum Experimental Design for Nuclear Spin Detection](https://arxiv.org/abs/2508.21450)
*B. Varona-Uriarte,F. Belliardo,T. H. Taminiau,C. Bonato,E. Garrote,J. Casanova*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The characterization of nuclear spin environments in solid-state devices
plays an important role in advancing quantum technologies, yet traditional
methods often demand long measurement times. To address this challenge, we
extend our recently developed deep-learning-based SALI model (Signal-to-image
ArtificiaL Intelligence) by introducing the surrogate information gain (SIG) to
optimize the selection of data points in the measurements. This approach
significantly reduces time requirements in experiments while preserving
accuracy in nuclear spin detection. The SIG is a figure of merit based on the
expected variance of the signal, which is more straightforward to compute than
the expected information gain rooted in Bayesian estimation. We demonstrate our
approach on a nitrogen-vacancy (NV) center in diamond coupled to $^{13}$C
nuclei. In the high-field regime, our variance-based optimization is validated
with experimental data, resulting in an 85$\%$ reduction in measurement time
for a modest reduction in performance. This work also constitutes the first
validation of SALI on experimental data. In the low-field regime, we explore
its performance on simulated data, predicting a 60$\%$ reduction in the total
experiment time by improving the temporal resolution of the measurements and
applying SIG. This demonstrates the potential of integrating deep learning with
optimized signal selection to enhance the efficiency of quantum sensing and
nuclear spin characterization, paving the way for scaling these techniques to
larger nuclear spin systems.

</details>


### [216] [Realization of an untrusted intermediate relay architecture using a quantum dot single-photon source](https://arxiv.org/abs/2508.21479)
*Mi Zou,Yu-Ming He,Yizhi Huang,Jun-Yi Zhao,Bin-Chen Li,Yong-Peng Guo,Xing Ding,Mo-Chi Xu,Run-Ze Liu,Geng-Yan Zou,Zhen Ning,Xiang You,Hui Wang,Wen-Xin Pan,Hao-Tao Zhu,Ming-Yang Zheng,Xiu-Ping Xie,Dandan Qin,Xiao Jiang,Yong-Heng Huo,Qiang Zhang,Chao-Yang Lu,Xiongfeng Ma,Teng-Yun Chen,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 该论文提出了一种基于高质量单光子源的模块化、可扩展量子中继器架构，用于构建量子网络，实现远距离纠缠分发和量子通信。


<details>
  <summary>Details</summary>
Motivation: 为了充分发挥量子技术的潜力，需要量子网络来连接不同的量子系统，从而显著增强量子计算、量子密码学和量子计量学等领域的应用。量子中继器是实现远距离纠缠分发和量子通信的关键。

Method: 提出了一种模块化、可扩展的量子中继器架构，该架构使用了高质量的单光子源，并包含三个不可信的中间节点。采用测量设备无关协议，通过长达300公里的光纤实现了安全密钥的建立。

Result: 量子中继器能够实现304.52 MHz的重复率，并通过测量设备无关协议在300公里光纤上成功建立了安全密钥。

Conclusion: 该研究展示了单光子源在量子中继器中的潜力，能够增强信息传输、扩展网络覆盖范围并提高部署灵活性，为未来的量子网络带来了有前景的应用。

Abstract: To fully exploit the potential of quantum technologies, quantum networks are
needed to link different systems, significantly enhancing applications in
computing, cryptography, and metrology. Central to these networks are quantum
relays that can facilitate long-distance entanglement distribution and quantum
communication. In this work, we present a modular and scalable quantum relay
architecture using a high-quality single-photon source. The proposed network
incorporates three untrusted intermediate nodes and is capable of a repetition
rate of 304.52 MHz. We use a measurement-device-independent protocol to
demonstrate secure key establishment over fibers covering up to 300 kilometers.
This study highlights the potential of single-photon sources in quantum relays
to enhance information transmission, expand network coverage, and improve
deployment flexibility, with promising applications in future quantum networks.

</details>


### [217] [Phase error estimation for passive detection setups with imperfections and memory effects](https://arxiv.org/abs/2508.21486)
*Zhiyao Wang,Devashish Tupkary,Shlok Nahar*

Main category: quant-ph

TL;DR: 我们提出了一个通用的框架来限制具有不完美和记忆效应的被动检测装置的量子密钥分发协议的相位误差率。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的框架来约束具有不完美和记忆效应的被动检测装置的量子密钥分发协议的相位误差率，以在有限的参数下证明协议的安全性。

Method: 该框架可以结合基于熵不确定性关系或相位错误校正的证明技术，以在有限的参数下证明针对相干攻击的安全性。该框架还可以即时包含关于点击/无点击结果的声明。在没有记忆效应的不完美情况下，它可以与处理源不完美性的证明结合使用。我们还将其应用于计算转向状态 BB84 协议的密钥速率，并考虑了检测器的记忆效应。

Result: 我们应用该框架计算了转向状态 BB84 协议的密钥速率，考虑了分束器比、检测效率和检测器暗计数在一定范围内的已知值。此外，我们还计算了存在检测器记忆效应时的密钥速率，结果表明该框架允许协议以更高的重复频率运行，从而显著提高安全密钥生成速率。

Conclusion: 我们开发的通用框架能够有效约束量子密钥分发协议的相位误差率，即使在存在不完美和记忆效应的情况下也能证明其安全性。该框架的应用提高了转向状态 BB84 协议的安全密钥生成速率。

Abstract: We develop a generic framework to bound the phase error rate for quantum key
distribution protocols using passive detection setups with imperfections and
memory effects. This framework can be used in proof techniques based on the
entropic uncertainty relation or phase error correction, to prove security in
the finite-size regime against coherent attacks. Our framework can incorporate
on-the-fly announcements of click/no-click outcomes on Bob's side. In the case
of imperfections without memory effects, it can be combined with proofs
addressing source imperfections in a modular manner. We apply our framework to
compute key rates for the decoy-state BB84 protocol, when the beam splitting
ratio, the detection efficiency, and dark counts of the detectors are only
known to be within some ranges. We also compute key rates in the presence of
memory effects in the detectors. In this case, our results allow for protocols
to be run at higher repetition rates, resulting in a significant improvement in
the secure key generation rate.

</details>


### [218] [Statistical Invisibility of a Physical Attack on QRNGs After Randomness Extraction](https://arxiv.org/abs/2508.21498)
*Yifan Chen,Dong Wang,Yibo Zhao,Liang Cheng,Yi Zhang,Yang Zhang*

Main category: quant-ph

TL;DR: 后处理技术可能掩盖量子随机数生成器（QRNG）的物理层攻击，导致统计测试失效。


<details>
  <summary>Details</summary>
Motivation: 当前主流的量子随机数生成器（QRNG）设计依赖后处理技术和统计测试（如NIST SP 800-22）来保证随机性。然而，这种做法可能存在严重的安全隐患。

Method: 本文通过实验和理论分析，论证了后处理过程可能完美地隐藏物理层攻击，使得后续的统计测试无法检测到熵源的妥协。研究人员针对基于放大自发辐射（ASE）的QRNG进行了功率电源纹波攻击实验，并分析了相位噪声QRNG的脆弱性。

Result: 实验证明，经过标准Toeplitz提取处理后，即使是因物理层攻击而严重失败的原始数据，也能生成通过NIST测试的最终序列。理论分析也证实了这种漏洞的存在，表明即使是完全可预测的输入，也可能被处理成经过认证但极不安全的随机序列。

Conclusion: 现有的QRNG安全验证方法，仅依赖最终输出的统计分析是不够的。必须考虑整个生成过程的安全性，以应对可能被后处理技术掩盖的物理层攻击。

Abstract: Current prevailing designs of quantum random number generators (QRNGs)
designs typically employ post-processing techniques to distill raw random data,
followed by statistical verification with suites like NIST SP 800-22. This
paper demonstrates that this widely adopted practice harbors a critical flaw.
We show that the powerful extraction process can create a false sense of
security by perfectly concealing physical-layer attacks, rendering the
subsequent statistical tests blind to a compromised entropy source. We
substantiate this claim across two major QRNG architectures. Experimentally, we
severely compromise an QRNG based on amplified spontaneous emission (ASE) with
a power supply ripple attack. While the resulting raw data catastrophically
fails NIST tests, a standard Toeplitz extraction transforms it into a final
sequence that passes flawlessly. This outcome highlights a profound danger:
since the validation process is insensitive to the quality of the raw data, it
implies that even a fully predictable input could be processed to produce a
certified, yet completely insecure, random sequence. Our theoretical analysis
confirms this vulnerability extends to phase-noise-based QRNGs, suggesting a
need for security validation to evolve beyond statistical analysis of the final
output and consider the entire generation process.

</details>


### [219] [Digital quantum simulation of many-body systems: Making the most of intermediate-scale, noisy quantum computers](https://arxiv.org/abs/2508.21504)
*Alexander Miessen*

Main category: quant-ph

TL;DR: 本论文研究如何在量子设备上模拟量子动力学，以解决经典计算机难以处理的量子力学问题。论文提出了一种新的硬件基准测试和错误缓解算法，并成功在133个量子比特上实现，展示了量子计算在早期阶段的潜力。


<details>
  <summary>Details</summary>
Motivation: 量子力学问题难以模拟，而量子计算为解决这些挑战提供了新途径。尽管现有量子设备存在噪声和规模限制，但仍需找到适合这些设备的经典难题。其中，量子系统的实时模拟是早期实现量子优势的最有希望的应用之一。因此，本论文专注于模拟量子设备上的量子动力学。

Method: 论文首先概述了量子动力学最相关的量子算法，并指出了它们的优缺点。接着，确定了在不久的将来可能受益于量子模拟的量子动力学相关问题。其次，提出了一种基于可靠理论结果且没有规模问题的硬件和错误缓解算法基准测试方法。该方法生成的质量指标直观且可推广到其他应用。最后，提出了一种改进的概率错误放大技术，用于模拟开放量子动力学，该技术通过表征和改变硬件噪声来模拟系统-环境交互。

Result: 研究成功在多达133个量子比特的设备上实现了该基准测试方案，展示了高达28个两比特门的相干演化，包含1396个两比特门，之后噪声开始变得显著。最后，论文提出了两种关于状态制备和相位分类的研究：一种是混合算法，用于制备电子-声子系统的基态；另一种是基于量子机器学习的方法，用于区分先前制备的量子态中的相位。

Conclusion: 本论文通过提出新的模拟方法和基准测试方案，为在现有量子设备上进行量子动力学模拟提供了重要的见解和工具，并展示了量子计算在解决实际问题方面的潜力。

Abstract: Quantum mechanical problems are among the hardest to simulate and, in some
cases, remain intractable even for the most powerful computers. Quantum
computing has emerged as a new technological platform to address such
challenges, with rapid advances in recent years. Yet, current quantum devices
remain noisy and limited in scale. Hence, it is essential to identify
classically hard problems of practical interest and tractable with existing
quantum devices. Among potential applications, the real-time simulation of
quantum systems is one of the most promising to deliver an early, practical
quantum advantage. This doctoral thesis is therefore centered around simulating
quantum dynamics on quantum devices. We first present an overview of the most
relevant quantum algorithms for quantum dynamics, highlighting respective
advantages and limitations. Further, we identify relevant problems within
quantum dynamics that could benefit from quantum simulation in the near future.
Second, we propose a method for benchmarking hardware and error mitigation
algorithms that is based on well-understood theoretical results and suffers
from no scaling issues. The resulting quality metric is intuitive and
transferable to other applications. We successfully implement the scheme on up
to 133 qubits, demonstrating coherent evolution up to a two-qubit gate depth of
28, featuring 1396 two-qubit gates, before noise becomes prevalent. Third, we
propose a novel variant of probabilistic error amplification to implement open
quantum dynamics, relying on characterizing and altering hardware noise to
mimic the system-environment interaction under study. Lastly, we present two
studies on state preparation and phase classification: first, a hybrid
algorithm to prepare ground states of electron-phonon systems; second, a
quantum machine learning-based approach to distinguish phases in previously
prepared quantum states.

</details>


### [220] [Single atom enables extraordinary light transmission through zero-mode waveguide](https://arxiv.org/abs/2508.21514)
*Vasily Klimov*

Main category: quant-ph

TL;DR: 单原子在零模波导（ZMW）中的光传输行为，根据失谐情况可增强或抑制透射，可用于研究原子动力学、量子光学和纳米光学器件。


<details>
  <summary>Details</summary>
Motivation: 研究零模波导（ZMW）中单原子对光传输的影响。

Method: 建立光传输通过含单原子的ZMW的理论模型。

Result: 发现单原子可根据激发场频率与原子共振的失谐情况，显著增强或抑制光传输。

Conclusion: 单原子诱导的透射和阻断效应可用于研究原子时空动力学、探测量子光学现象和开发新型纳米光学器件。

Abstract: In this work, we develop a theory of light transmission through a Zero-Mode
Waveguide (ZMW) containing a single atom. It is shown that the presence of a
single atom inside the ZMW can lead to either a significant enhancement or
suppression of light transmission, depending on the detuning of the excitation
field frequency from the atomic resonance. This extraordinary transmission and
blocking effect can be employed for studying the spatiotemporal dynamics of
atoms in complex nanoscopic environments, probing quantum optical phenomena,
and developing novel nano-optical devices.

</details>


### [221] [Quantum Well in Fractional Quantum Mechanics](https://arxiv.org/abs/2508.21528)
*Nick Laskin*

Main category: quant-ph

TL;DR: 文章利用分数阶量子力学，找到了量子阱（对称一维有限势阱）中粒子能量谱的精确解，并提出了一种图解算法来确定离散能级数量和能量值，为利用量子阱模拟分数阶量子力学开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 在分数阶量子力学框架下，为量子阱中的量子粒子寻找能量谱的精确解。

Method: 提出一个简单的图解算法来获得离散能级数量及其能量值。

Result: 文章找到了量子阱中粒子能量谱的精确解，并提出了一种图解算法。

Conclusion: 所提出的结果为利用量子阱模拟分数阶量子力学提供了新的可能性。

Abstract: Within the framework of fractional quantum mechanics, an exact solution has
been found for the energy spectrum of a quantum particle confined in a quantum
well - a symmetric one-dimensional finite potential well. A simple graphical
algorithm is described for obtaining the number of discrete levels in a quantum
well and their associated energy values. The presented results open up new
possibilities for emulating fractional quantum mechanics using quantum wells.

</details>


### [222] [Quantum Leap in Finance: Economic Advantages, Security, and Post-Quantum Readiness](https://arxiv.org/abs/2508.21548)
*Gerhard Hellstern,Esra Yeniaras*

Main category: quant-ph

TL;DR: 量子计算在金融领域的应用和安全影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面回顾量子计算在金融领域的应用潜力及其对网络安全的影响，并提出一个评估框架，以应对量子时代的安全挑战。

Method: 本文整合了量子计算在投资组合优化、风险分析、衍生品定价和蒙特卡洛模拟等经典应用，并深入研究了区块链技术和后量子密码学（PQC）。提出了一个评估量子解决方案可行性的四步框架，并将其应用于金融场景。此外，还探讨了量子计算对数字金融和区块链安全的风险，并提出了基于PQC和量子安全替代方案的缓解策略。

Result: 研究应用所提出的框架评估了量子计算在金融领域的应用前景，并识别出量子方法优于经典方法的领域。同时，也明确了量子计算对数字签名、哈希函数和随机数生成等方面的安全风险，并提出了相应的缓解措施。

Conclusion: 量子计算为金融领域带来了革命性的机遇，但也伴随着严峻的安全挑战。通过采用结构化的评估框架和后量子密码学等安全措施，金融行业可以为量子时代的到来做好准备，确保金融系统的安全和稳定。

Abstract: This paper provides an in-depth review of the evolving role of quantum
computing in the financial sector, emphasizing both its computational potential
and cybersecurity implications. Distinguishing itself from existing surveys,
this work integrates classical quantum computing applications - such as
portfolio optimization, risk analysis, derivative pricing, and Monte Carlo
simulations with a thorough examination of blockchain technologies and
post-quantum cryptography (PQC), which are crucial for maintaining secure
financial operations in the emerging quantum era. We propose a structured
four-step framework to assess the feasibility and expected benefits of
implementing quantum solutions in finance, considering factors such as
computational scalability, error tolerance, data complexity, and practical
implementability. This framework is applied to a series of representative
financial scenarios to identify domains where quantum approaches can surpass
classical techniques. Furthermore, the paper explores the vulnerabilities
quantum computing introduces to digital finance-related applications and
blockchain security, including risks to digital signatures, hash functions, and
randomness generation, and discusses mitigation strategies through PQC and
quantum-resilient alternatives of classical digital finance tools and
blockchain architectures. By addressing both quantum blockchain, quantum key
distribution (QKD) as well as quantum communication networks, his review
presents a more holistic perspective than prior studies, offering actionable
insights for researchers, financial practitioners, and policymakers navigating
the intersection of quantum computing, blockchain, and secure financial
systems.

</details>


### [223] [Universal Precision Limits in General Open Quantum Systems](https://arxiv.org/abs/2508.21567)
*Tan Van Vu,Ryotaro Honma,Keiji Saito*

Main category: quant-ph

TL;DR: 非马尔可夫开放量子系统中的可观测精度受热力学成本、熵产生和前向-后向不对称性约束。


<details>
  <summary>Details</summary>
Motivation: 在非马尔可夫体系中，探究精度与热力学成本之间的关系，并导出普适的精度边界。

Method: 通过引入不对称性项量化前向和后向过程的差异，并证明任何时间反对称电流的相对涨落受熵产生和该不对称性的约束，以及任何可观测量的相对涨落总受到广义活动项的下界约束。

Result: 导出开放量子系统中任意可观测量的精度边界，表明精度受熵产生和前向-后向不对称性的共同制约，并提出了广义活动项作为精度下界。

Conclusion: 建立了理解广泛的通用开放量子系统中精度限制的综合框架。

Abstract: The intuition that the precision of observables is constrained by
thermodynamic costs has recently been formalized through thermodynamic and
kinetic uncertainty relations. While such trade-offs have been extensively
studied in Markovian systems, corresponding constraints in the non-Markovian
regime remain largely unexplored. In this Letter, we derive universal bounds on
the precision of generic observables in open quantum systems coupled to
environments of arbitrary strength and subjected to two-point measurements. By
introducing an asymmetry term that quantifies the disparity between forward and
backward processes, we show that the relative fluctuation of any
time-antisymmetric current is constrained by both entropy production and this
forward-backward asymmetry. For general observables, we prove that their
relative fluctuation is always bounded from below by a generalized activity
term. These results establish a comprehensive framework for understanding
precision limits in broad classes of general open quantum systems.

</details>


### [224] [Electronic-nuclear entanglement in Born-Oppenheimer wave functions and beyond](https://arxiv.org/abs/2508.21578)
*Juan F. P. Mosquera,Jose Luis Sanz-Vicario*

Main category: quant-ph

TL;DR: 本论文研究了分子波函数中电子运动与核运动之间的纠缠，利用了分子哈密顿模型中常用的几种方法（H$^+_2$一维模型和Shin-Metiu模型），包括：1) 绝热和非绝热两种图景下的玻恩-奥本海默分离；2) 玻恩-黄展开，其中包含了非绝热耦合。论文将任何分子视为电子和核两个部分组成的二分系统，并应用施密特分解定理来寻找更短的表示，并通过冯·诺依曼熵来估计纠缠。研究表明，分子的基态玻恩-奥本海默振动状态几乎是可分离的，没有纠缠；但随着振动激发，纠缠会单调增加。对于电子波函数随分子几何形状急剧变化的电子激发态，电子和核波函数之间的相互作用更为关键。论文发现，纠缠可以通过电子波函数随核几何形状的变化来量化，而核波函数起到了测试作用。此外，势能曲线中避免交叉的存在会大大增强玻恩-奥本海默绝热图景下的纠缠，而在非绝热图景下则会大大减弱。最后，玻恩-黄展开揭示了一些协同振动状态，其纠缠含量大于其玻恩-奥本海默分量的叠加。总而言之，本文为理解和量化分子系统中的电子-核纠缠提供了一个新的视角。


<details>
  <summary>Details</summary>
Motivation: 研究分子波函数中电子运动与核运动之间的纠缠，并探索不同的近似方法对纠缠的影响。

Method: 应用施密特分解定理和冯·诺依曼熵来量化电子-核纠缠，并比较了玻恩-奥本海默分离（绝热和非绝热）、玻恩-黄展开等方法。

Result: 基态玻恩-奥本海默振动状态几乎没有纠缠，但振动激发会增加纠缠；电子激发态的纠缠更显著；势能曲线中的避免交叉会增强绝热图景下的纠缠，减弱非绝热图景下的纠缠；玻恩-黄展开揭示了纠缠含量大于玻恩-奥本海默分量叠加的协同振动状态。

Conclusion: 纠缠是分子系统中的一个重要特征，其含量与分子的振动状态和电子结构密切相关。不同的近似方法对纠缠的描述不同，玻恩-黄展开能更好地捕捉协同振动状态下的纠缠。

Abstract: We analyze the entanglement between electronic and nuclear motions in
molecular wave functions, by using different widely used ansatzes in molecular
Hamiltonian models (H$^+_2$ in 1D and the Shin-Metiu model); namely, i)
Born-Oppenheimer separation in both adiabatic and ii) diabatic pictures and
beyond it, iii) using a Born-Huang expansion, which involves non-adiabatic
couplings in the solution. Any molecule can be considered a bipartite system in
terms of electronic and nuclear halfspaces. Accordingly, the Schmidt
decomposition theorem can be applied to each molecular ansatz to find a much
shorter representation in terms of Schmidt basis and to estimate the
entanglement content through the calculation of von Neumann entropies. Although
here we justify that the ground BO vibronic state of any molecule may be
regarded as an almost separable and non-entangled state, this property worsens
with the vibrational excitation, which increases the entanglement
monotonically. The interlace between electronic and nuclear wave functions for
each vibronic state becomes even more critical for those electronic excited
states whose electronic wave functions change drastically with the molecular
geometry. We find that the entanglement may be quantified by the variation of
the electronic wave function along the different nuclear geometries, and that
the nuclear wave function indeed plays the role of a tester. In addition, the
presence of avoided crossings among the potential energy curves brings about a
strong enhancement of entanglement in the Born-Oppenheimer adiabatic picture,
which instead is much reduced in a diabatic picture. Finally, the Born-Huang
expansion uncovers some synergistic vibronic states whose entanglement content
is larger than that of any Born-Oppenheimer component in the superposition.

</details>


### [225] [Quantum Sequential Universal Hypothesis Testing](https://arxiv.org/abs/2508.21594)
*Matteo Zecchin,Osvaldo Simeone,Aaditya Ramdas*

Main category: quant-ph

TL;DR: 量子假设检验（QHT）旨在对未知的量子态进行统计推断。本文提出了一种名为量子序贯通用测试（QSUT）的新框架，用于解决复合假设下的QHT问题。QSUT通过自适应局部测量和联合测量相结合的方式，可以更有效地探索假设空间并进行状态区分，同时严格控制第一类错误。实验结果表明，QSUT在降低样本复杂度方面优于现有的固定样本策略。


<details>
  <summary>Details</summary>
Motivation: 先前的量子假设检验（QHT）复合假设方法采用固定的两步协议，可能效率低下。本文旨在提出一种更高效的框架来解决这个问题。

Method: 提出量子序贯通用测试（QSUT）框架，结合了探索性自适应局部测量和最大化判别的联合测量。

Result: QSUT框架在各种复合QHT任务中，相比于最先进的固定样本策略，一致地降低了样本复杂度。

Conclusion: QSUT框架为复合假设下的量子假设检验提供了一种更优的解决方案，有效降低了样本复杂度。

Abstract: Quantum hypothesis testing (QHT) concerns the statistical inference of
unknown quantum states. In the general setting of composite hypotheses, the
goal of QHT is to determine whether an unknown quantum state belongs to one or
another of two classes of states based on the measurement of a number of copies
of the state. Prior art on QHT with composite hypotheses focused on a
fixed-copy two-step protocol, with state estimation followed by an optimized
joint measurement. However, this fixed-copy approach may be inefficient, using
the same number of copies irrespective of the inherent difficulty of the
testing task. To address these limitations, we introduce the quantum sequential
universal test (QSUT), a novel framework for sequential QHT in the general case
of composite hypotheses. QSUT builds on universal inference, and it alternates
between adaptive local measurements aimed at exploring the hypothesis space and
joint measurements optimized for maximal discrimination. QSUT is proven to
rigorously control the type I error under minimal assumptions about the
hypothesis structure. We present two practical instantiations of QSUT, one
based on the Helstrom-Holevo test and one leveraging shallow variational
quantum circuits. Empirical results across a range of composite QHT tasks
demonstrate that QSUT consistently reduces copy complexity relative to
state-of-the-art fixed-copy strategies.

</details>


### [226] [Impurities in cryogenic solids: a new platform for hybrid quantum systems](https://arxiv.org/abs/2508.21651)
*Andrew N. Kanagin,Nikolaus de Zordo,Andreas Angerer,Wenzel Kersten,Nikolaos Lagos,Joerg Schmiedmayer,Elena S. Redchenko*

Main category: quant-ph

TL;DR: 本研究提出了一种结合固体稀有气体晶体和超导谐振器的混合量子平台，实现了原子系综与超导谐振器在强耦合状态下的相互作用，并进行了相干时间测量。


<details>
  <summary>Details</summary>
Motivation: 混合量子系统结合了不同量子组件的优势，在研究量子现象和发展应用技术方面具有潜力。本研究旨在开发一种新型混合量子平台。

Method: 研究提出了一种由掺杂了自旋杂质的固体稀有气体晶体与超导谐振器组成的混合量子平台。在mK温度下，实现了原子杂质系综与超导谐振器之间的强耦合，并进行了相干时间测量。

Result: 研究成功实现了原子杂质系综与超导谐振器在强耦合状态下的相互作用，并测量了相干时间。实验结果表明该平台能够支持基础量子效应的研究和新量子技术的发展。

Conclusion: 所提出的稀有气体晶体掺杂自旋杂质与超导谐振器相结合的混合量子平台，为探索基础量子效应和开发新量子技术提供了一种独特的架构。

Abstract: Hybrid quantum systems offer a promising platform for studying quantum
phenomena and developing applied technologies, benefiting from the individual
strengths of their components. Here, we present a novel hybrid quantum platform
composed of solid noble gas crystals doped with spin impurities atop
superconducting resonators. The noble gas crystals provide a soft, inert,
predominantly spin-0 host matrix for the atomic impurities, while the alkali
atoms have addressable and long-lived hyperfine transitions in the GHz regime.
We demonstrate the ability to reach the strong coupling regime between the
atomic impurity ensemble and the superconducting resonator at mK temperatures,
and perform coherence time measurements. Our proof-of-principle measurements
show that this platform offers a unique architecture for exploring fundamental
quantum effects and new quantum technologies.

</details>


### [227] [A simple method for seniority-zero quantum state preparation](https://arxiv.org/abs/2508.21679)
*Michal Krompiec,Josh J. M. Kirsopp,Antonio Márquez Romero,Vicente Perez Soloviev*

Main category: quant-ph

TL;DR: pCCD和UpCCD在小幅度极限下是等价的，oo-pCCD可以用于准备高保真度的单态，用于量子相位估计算法。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计算法（QPE）需要一个与基态有足够重叠的初始状态，但对于强关联态，制备初始状态需要复杂的量子电路和/或昂贵的混合量子-经典优化。

Method: 通过将oo-pCCD的幅度代入UpCCD Ansatz来制备高保真度的单态，并验证了pCCD和UpCCD在小幅度极限下的等价性。

Result: 制备了 ethene、ethyne 和 dinitrogen 的多键离解模型，以及 1D Hubbard 模型的单态，保真度很高，且所需的量子电路非常浅。

Conclusion: 提出的方法可用于近似制备量子相位估计算法和相关算法的单态。

Abstract: Quantum Phase Estimation (QPE), the quantum algorithm for estimating
eigenvalues of a given Hermitian matrix and preparing its eigenvectors, is
considered the most promising approach to finding the ground states and their
energies of electronic systems using a quantum computer. It requires, however,
to be warm--started from an initial state with sufficiently high overlap with
the ground state. For strongly-correlated states, where QPE is expected to have
advantage over classical methods, preparation of such initial states requires
deep quantum circuits and/or expensive hybrid quantum-classical optimization.
It is well-known that orbital-optimized paired Coupled Cluster Doubles
(oo-pCCD) method can describe the static correlation features of many strongly
correlated singlet states. We show that pCCD and its unitary counterpart,
UpCCD, become equivalent in the limit of small amplitudes if the amplitude
matrix is sufficiently sparse. We demonstrate that substituting leading oo-pCCD
amplitudes into the UpCCD Ansatz allows to prepare high-fidelity singlet states
for models of multiple-bond dissociation in ethene, ethyne and dinitrogen, as
well as for 1D Hubbard models at half-filling, with very shallow circuits. We
envisage our method to be of general use for approximate preparation of singlet
states for Quantum Phase Estimation and related algorithms.

</details>


### [228] [An Exclusive-Sum-of-Products Pipeline for QAOA](https://arxiv.org/abs/2508.21686)
*Matthew Brunet,Shilpi Shah,Mostafa Atallah,Anthony Wilkie,Rebekah Herrman*

Main category: quant-ph

TL;DR: ESOPs improve QAOA for constrained optimization problems by encoding constraints.


<details>
  <summary>Details</summary>
Motivation: Standard QAOA methods for constrained optimization rely on penalization, which can be suboptimal. This work explores an alternative by encoding constraints as ESOPs before penalization.

Method: The proposed method encodes constraints as Boolean expressions in ESOP form prior to penalization in the QAOA algorithm. This approach was tested on the maximum independent set problem using graphs with 3 to 20 vertices.

Result: ESOP constraint formulations achieved higher approximation ratios (up to 30.3% increase) compared to standard constraint penalization methods. They also yielded better approximation ratios than standard QAOA penalization on approximately 64% of tested graphs after one layer.

Conclusion: Encoding constraints as ESOPs before penalization offers a more effective approach for solving constrained combinatorial optimization problems with QAOA, leading to improved approximation ratios compared to traditional methods.

Abstract: The quantum approximate optimization algorithm is commonly used to solve
combinatorial optimization problems. While unconstrained problems map naturally
into the algorithm, incorporating constraints typically requires penalizing
constraint violations in the objective function. In this work, we propose an
alternative approach that encodes constraints as Boolean expressions in
exclusive-sum-of-products (ESOP) form before penalization. We test this method
on the maximum independent set problem using graphs with 3 to 20 vertices and
find that ESOP constraint formulations achieve higher approximation ratios than
standard constraint penalization methods, with percent increases of up to
30.3%. Furthermore, ESOP constraint formulations result in higher approximation
ratios than standard QAOA penalization approaches after one layer of the
algorithm on approximately 64% of the tested graphs.

</details>


### [229] [An Exact Branch and Bound Algorithm for the generalized Qubit Mapping Problem](https://arxiv.org/abs/2508.21718)
*Bjørnar Luteberget,Kjell Fredrik Pettersen,Giorgio Sartor,Franz G. Fuchs,Dominik Leib,Tobias Seidel,Raoul Heese*

Main category: quant-ph

TL;DR: Qubit mapping problem (QMP) is NP-hard. This paper presents a flexible branch and bound algorithm for a generalized QMP that considers or ignores gate layering and execution time, finding proven optimal solutions and offering a platform for heuristics. Ignoring layering significantly improves performance indicators.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the limitations of fixed gate layering in quantum circuit compilation, which restricts gate rearrangement and imposes time discretization, potentially leading to suboptimal solutions for the NP-hard Qubit Mapping Problem (QMP). It aims to explore the impact of ignoring layering and gate execution time on minimizing SWAPs and makespan.

Method: The paper introduces a flexible branch and bound algorithm designed to solve a generalized version of the QMP. This algorithm can accommodate variations that either consider or ignore gate layering and gate execution time, thereby finding provably optimal solutions.

Result: Experiments on benchmark sets of small quantum circuits demonstrate that disregarding gate layering can lead to significant improvements in key performance indicators of the compiled circuit.

Conclusion: Ignoring gate layering in the Qubit Mapping Problem can significantly enhance performance metrics like the number of SWAPs and the makespan of the compiled quantum circuit, offering a more flexible and potentially more efficient approach compared to traditional layered methods.

Abstract: Quantum circuits are typically represented by a (ordered) sequence of gates
over a set of virtual qubits. During compilation, the virtual qubits of the
gates are assigned to the physical qubits of the underlying quantum hardware, a
step often referred to as the qubit assignment problem. To ensure that the
resulting circuit respects hardware connectivity constraints, additional SWAP
gates are inserted as needed, which is known as the qubit routing problem.
Together, they are called the Qubit Mapping Problem (QMP), which is known to be
NP-hard. A very common way to deal with the complexity of the QMP is to
partition the sequence of gates into a sequence of gate groups (or layers).
However, this imposes a couple of important restrictions: (1) SWAP gates can
only be added between pairs of consecutive groups, and (2) all the gates
belonging to a certain group have to be executed (in parallel) in the same time
slot. The first one prevents gates to be re-arranged optimally, while the
second one imposes a time discretization that practically ignores gate
execution time. While this clearly reduces the size of the feasible space,
little is still known about how much is actually lost by imposing a fixed
layering when looking at the minimization of either the number of SWAPs or the
makespan of the compiled circuit. In this paper, we present a flexible branch
and bound algorithm for a generalized version of the QMP that either considers
or ignores the gate layering and the gate execution time. The algorithm can
find find proven optimal solutions for all variations of the QMP, but also
offers a great platform for different heuristic algorithms. We present results
on several benchmark sets of small quantum circuits, and we show how ignoring
the layering can significantly improve some key performance indicators of the
compiled circuit.

</details>


### [230] [Diagrammatic Reasoning with Control as a Constructor, Applications to Quantum Circuits](https://arxiv.org/abs/2508.21756)
*Noé Delorme,Simon Perdrix*

Main category: quant-ph

TL;DR: 该论文引入了一个包含控制作为构造子的通用图示推理框架，通过扩展标准 props 形式主义到受控 props，并应用该框架简化了量子电路的图示推理。


<details>
  <summary>Details</summary>
Motivation: 控制是量子计算和可逆计算模型中的核心概念，允许根据一个系统的状态来决定是否应用另一个系统的变换。

Method: 论文提出了一个包含控制作为构造子的通用图示推理框架，通过提供控制函子的基本公理化，将标准的 props（对称幺半范畴）形式主义扩展到受控 props。

Result: 研究表明，受控 props 框架简化了量子电路的图示推理，提供了一组简单的完备关系，仅涉及最多三个量子比特的关系，这与标准 props 形式主义中需要涉及任意数量量子比特的关系的完备公理化形成对比。

Conclusion: 受控 props 框架为量子计算和可逆计算中的控制概念提供了一个有效的图示推理工具，尤其在简化量子电路关系方面具有显著优势。

Abstract: Control is a predominant concept in quantum and reversible computational
models. It allows to apply or not a transformation on a system, depending on
the state of another system. We introduce a general framework for diagrammatic
reasoning featuring control as a constructor. To do so, we provide an
elementary axiomatisation of control functors, extending the standard formalism
of props (symmetric monoidal categories with the natural numbers as objects) to
controlled props. As an application, we show that controlled props ease
diagrammatic reasoning for quantum circuits by allowing a simple complete set
of relations that only involves relations acting on at most three qubits,
whereas it is known that in the standard prop setting any complete
axiomatisation requires relations acting on arbitrarily many qubits.

</details>


### [231] [On the Implementation Security of Twin-Field Quantum Key Distribution using Optical Injection Locking](https://arxiv.org/abs/2508.21763)
*Sergio Juárez,Alessandro Marcomini,Mikhail Petrov,Robert I. Woodward,Toby J. Dowling,R. Mark Stevenson,Marcos Curty,Davide Rusca*

Main category: quant-ph

TL;DR: 该论文系统分析了基于光学注入锁定（OIL）的双场量子密钥分发（TF-QKD）协议中可能存在的侧信道攻击，并提出有效的防御措施。


<details>
  <summary>Details</summary>
Motivation: 为了简化TF-QKD所需的精确相位和频率稳定，通常采用OIL架构。然而，OIL架构也可能引入新的安全漏洞，因此需要对其进行系统性分析。

Method: 通过实验演示了两种基于外部参考激光器光学自由度的攻击场景：参考激光器的快速强度调制和利用不可见波长的特洛伊木马信号。提出使用高速光电二极管进行实时功率监测和光谱滤波来检测和抑制带外信号的防御措施。

Result: 实验证明，所提出的防御措施能够有效抵御已识别的攻击，且不会显著增加系统的复杂性或降低性能。

Conclusion: 对OIL-TF-QKD系统的全面光学监测对于在实际量子通信网络中稳健部署TF-QKD至关重要。

Abstract: Twin-Field Quantum Key Distribution (TF-QKD) has emerged as a leading quantum
communication protocol, enabling secure key distribution over unprecedented
distances by utilising coherent interference of quantum states. Optical
Injection Locking (OIL) architectures have been used to simplify the precise
phase and frequency stabilisation required by TF-QKD. In this work, we
systematically analyse potential side-channels in OIL-based TF-QKD that can be
introduced through the various optical degrees of freedom of the externally
injected reference laser. We experimentally demonstrate two realistic attack
scenarios: rapid intensity modulation of the reference laser and Trojan-horse
signals exploiting wavelengths undetectable by conventional monitoring
techniques. To counter these vulnerabilities, we propose straightforward and
highly effective countermeasures including high-speed photodiodes for real-time
power monitoring and targeted spectral filtering to detect and suppress
out-of-band signals. Our experimental results confirm that these practical
solutions substantially reinforce the security of TF-QKD systems without
significant additional complexity or performance degradation. More broadly, our
analysis highlights the critical importance of comprehensive optical monitoring
to ensure the robust practical deployment of TF-QKD in real-world quantum
communication networks.

</details>


### [232] [Quantum Phase Sensitivity with Generalized Coherent States Based on Deformed su(1,1) and Heisenberg Algebras](https://arxiv.org/abs/2508.21779)
*N. E. Abouelkhir,A. Slaoui,R. Ahl Laamara*

Main category: quant-ph

TL;DR: Using generalized coherent states from deformed algebras, we analyzed phase sensitivity in a Mach Zehnder interferometer. We compared three detection methods against the quantum Cram'er-Rao bound, finding that these states can approach the quantum limit for precision measurements.


<details>
  <summary>Details</summary>
Motivation: To investigate the phase sensitivity of a Mach Zehnder interferometer and explore the potential of generalized coherent states for enhancing precision in quantum metrology.

Method: Constructed generalized coherent states from generalized Heisenberg and deformed su(1,1) algebras, derived from a perturbed harmonic oscillator. Analyzed phase sensitivity using quantum Fisher information and the quantum Cram'er-Rao bound under three detection methods: difference intensity detection, single mode intensity detection, and balanced homodyne detection. Compared the performance of each method with the quantum Cram'er-Rao bound.

Result: The generalized coherent states, with enhanced tunability and nonclassical features, were shown to enable phase sensitivities approaching the quantum limit for suitable parameter regimes across the analyzed detection methods.

Conclusion: The study demonstrates that generalized coherent states derived from deformed algebras provide a flexible framework for achieving high phase sensitivity in Mach Zehnder interferometers, potentially reaching the fundamental quantum limits of precision.

Abstract: We investigate the phase sensitivity of a Mach Zehnder interferometer using a
special class of generalized coherent states constructed from generalized
Heisenberg and deformed su(1,1) algebras. These states, derived from a
perturbed harmonic oscillator with a four parameter deformed spectrum, provide
enhanced tunability and nonclassical features. The quantum Fisher information
and its associated quantum Cram\'er-Rao bound are used to define the
fundamental precision limits in phase estimation. We analyze the phase
sensitivity under three realistic detection methods: difference intensity
detection, single mode intensity detection, and balanced homodyne detection.
The performance of each method is compared with the quantum Cram\'er Rao bound
to evaluate their optimality. Our results demonstrate that, for suitable
parameter regimes, these generalized coherent states enable phase sensitivities
approaching the quantum limit, offering a flexible framework for precision
quantum metrology.

</details>


### [233] [Non-Markovian dynamics of giant emitters beyond the Weisskopf-Wigner approximation](https://arxiv.org/abs/2508.21784)
*Carlos A. González-Gutiérrez*

Main category: quant-ph

TL;DR: Giant quantum emitters exhibit non-Markovian dynamics and interference effects beyond the Weisskopf-Wigner approximation. We study minimal models coupled to cavity-array waveguides and find symmetric configurations with exact solutions, revealing bound states and enabling engineering of their coherent superpositions. This offers analytical insight into non-Markovian light-matter interactions, with potential superconducting circuit implementation.


<details>
  <summary>Details</summary>
Motivation: The standard Weisskopf-Wigner approximation is insufficient for giant quantum emitters due to interference effects and non-Markovian dynamics. This paper aims to study these phenomena in minimal models.

Method: The study involves minimal models of giant emitters coupled to cavity-array waveguides. Symmetric configurations are identified where the dynamics can be solved exactly.

Result: The exact solutions capture the emergence of bound states both inside and outside the photonic continuum. The study also demonstrates the possibility of engineering coherent superpositions of these bound states.

Conclusion: The results provide analytical insight into non-Markovian light-matter interaction and suggest a feasible implementation using superconducting circuit platforms.

Abstract: Giant quantum emitters, whose effective size is comparable to the wavelength
of the radiation they couple to, give rise to interference effects and
non-Markovian dynamics that lie beyond the scope of the standard
Weisskopf-Wigner approximation. Here we study minimal models of giant emitters
coupled to cavit$-array waveguides and identify symmetric configurations where
the dynamics can be solved exactly. This allows us to capture the emergence of
bound states both inside and outside the photonic continuum, and to demonstrate
the possibility of engineering their coherent superpositions. Our results
provide analytical insight into non-Markovian light-matter interaction and
suggest a feasible implementation using superconducting circuit platforms.

</details>


### [234] [Experimental measurement of quantum-first-passage-time distributions](https://arxiv.org/abs/2508.21790)
*Joseph M. Ryan,Simon Gorbaty,Thomas J. Kessler,Mitchell G. Peaks,Stephen W. Teitsworth,Crystal Noel*

Main category: quant-ph

TL;DR: 研究了量子首 passage 时间分布（QFPTDs），这是经典首 passage 时间分布（FPTDs）的量子对应物，它在基础物理学和新兴量子技术方面具有重要意义。


<details>
  <summary>Details</summary>
Motivation: QFPTDs 仍未得到充分研究，但对基础物理学和量子技术具有深远影响。

Method: 使用单个被捕获离子的运动模式，通过新颖的复合相位激光脉冲序列，对被捕误离子的运动状态进行可调频存储示波测量，实现了首个 QFPTDs 的测量，并将测量结果与经典对应物联系起来。

Result: 首次测量了量子离子能量的 QFPTDs，并发现了其与经典对应物的明确联系。

Conclusion: 开发了一种可广泛应用于其他量子系统的测量方案，为探索 QFPTDs 现象提供了一种强大的方法，并为量子搜索算法、经典与量子动力学之间的联系以及量子测量问题等领域开辟了新的实验研究方向。

Abstract: Classical First-Passage-Time Distributions (FPTDs) have been extensively
studied both theoretically and experimentally. Their quantum counterparts,
Quantum First-Passage-Time Distributions (QFPTDs), remain largely unexplored
and have deep implications for both fundamental physics and the development of
emerging quantum technologies. We measure the first QFPTDs using a motional
mode of a single trapped ion. We develop a novel composite-phase laser pulse
sequence to perform tunable stroboscopic projective measurements of the
motional state of a trapped ion. We measure QFPTDs of the ion energy when
coupled to electric-field noise and establish a clear connection with its
classical counterpart. The measurement protocol developed here is broadly
applicable to other quantum systems and provides a powerful method for
exploring a broad range of QFPTD phenomena. With these results we open a new
field of experimental investigations of QFPT processes with potential future
relevance to quantum search algorithms, unraveling connections between
classical and quantum dynamics, and study of the quantum measurement problem.

</details>


### [235] [Unitary induced channels and Tsirelson's problem](https://arxiv.org/abs/2508.21808)
*Michał Banacki,Paweł Horodecki*

Main category: quant-ph

TL;DR: 该研究提出了（广义）酉诱导量子通道的概念，并使用 Brown 代数特性，在张量和交换范式中提供了等价刻画。特别是，它用不要求对无限维子系统进行测量的协议，对 Tsirelson 猜想（Connes 嵌入问题）给出了等价表述。研究还表明，在广义酉诱导通道方面，量子交换模型和量子张量模型存在差异。


<details>
  <summary>Details</summary>
Motivation: 近期量子交换和量子张量模型在复合系统方面的进展促使了对（广义）酉诱导量子通道的研究。

Method: 利用 Brown 代数的性质，为张量和交换范式中的讨论族提供了等价刻画，并提出了基于不要求对无限维子系统进行测量的协议的等价表述。

Result: 证明了在广义酉诱导通道方面，量子交换模型和量子张量模型之间存在差异。

Conclusion: 量子交换模型和量子张量模型在广义酉诱导通道方面存在差异。

Abstract: Motivated by a recent progress concerning quantum commuting and quantum
tensor models of composed systems we investigate a notion of (generalized)
unitary induced quantum channel. Using properties of Brown algebras we provide
an equivalent characterization of discussed families in both tensor and
commuting paradigms. In particular, we provide an equivalent formulation of
Tsirelson's conjecture (Connes' embedding problem) in terms of considered
paradigms based on protocols which do not require measurements performed on
infinite-dimensional subsystems. As a result we show that there is a difference
between quantum commuting and quantum tensor models for generalized unitary
induced channels.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [236] [Faster Linear Algebra Algorithms with Structured Random Matrices](https://arxiv.org/abs/2508.21189)
*Chris Camaño,Ethan N. Epperly,Raphael A. Meyer,Joel A. Tropp*

Main category: cs.DS

TL;DR: 该论文提出了一种基于“遗忘子空间注入”（OSI）属性的结构化降维新视角，用于分析和设计随机线性代数算法，特别是在低秩近似和最小二乘回归问题上。


<details>
  <summary>Details</summary>
Motivation: 现有随机线性代数算法在结构化随机矩阵的设计和分析方面仍存在基本问题。

Method: 提出OSI属性，该属性假设随机矩阵平均保留向量长度且不会湮灭低维子空间中的任何向量。论文分析了在OSI假设下标准的随机化算法，并证明了多种随机矩阵模型（如稀疏矩阵、三角变换、张量积结构矩阵）具有OSI属性。

Result: 开发了OSI框架，分析了标准随机化算法，并确定了多种OSI实例，为低秩近似和最小二乘回归等任务提供了更优的运行时间。

Conclusion: OSI框架为理解和设计随机线性代数算法提供了一个强大的新工具，并且在实践中，结构化随机矩阵在多种科学应用中表现出优异的性能。

Abstract: To achieve the greatest possible speed, practitioners regularly implement
randomized algorithms for low-rank approximation and least-squares regression
with structured dimension reduction maps. Despite significant research effort,
basic questions remain about the design and analysis of randomized linear
algebra algorithms that employ structured random matrices.
  This paper develops a new perspective on structured dimension reduction,
based on the oblivious subspace injection (OSI) property. The OSI property is a
relatively weak assumption on a random matrix that holds when the matrix
preserves the length of vectors on average and, with high probability, does not
annihilate any vector in a low-dimensional subspace. With the OSI abstraction,
the analysis of a randomized linear algebra algorithm factors into two parts:
(i) proving that the algorithm works when implemented with an OSI; and (ii)
proving that a given random matrix model has the OSI property.
  This paper develops both parts of the program. First, it analyzes standard
randomized algorithms for low-rank approximation and least-squares regression
under the OSI assumption. Second, it identifies many examples of OSIs,
including random sparse matrices, randomized trigonometric transforms, and
random matrices with tensor product structure. These theoretical results imply
faster, near-optimal runtimes for several fundamental linear algebra tasks. The
paper also provides guidance on implementation, along with empirical evidence
that structured random matrices offer exemplary performance for a range of
synthetic problems and contemporary scientific applications.

</details>


### [237] [$Δ$-Motif: Subgraph Isomorphism at Scale via Data-Centric](https://arxiv.org/abs/2508.21287)
*Yulun Wang,Esteban Ginez,Jamie Friel,Yuval Baum,Jin-Sung Kim,Alex Shih,Oded Green*

Main category: cs.DS

TL;DR: Delta-Motif是一种GPU加速的子图同构算法，它将子图同构问题转化为数据库操作（连接、排序、合并和过滤），通过将图分解为小的“动机”并利用NVIDIA RAPIDS和Pandas库进行大规模并行处理，在性能上显著优于传统算法，并在量子计算领域得到了应用。


<details>
  <summary>Details</summary>
Motivation: 子图同构是图分析中的一个基本问题，但传统算法（如VF2）存在顺序瓶颈，难以利用现代并行硬件。需要一种能够充分利用并行计算能力的解决方案。

Method: 将图表示为表格形式，通过连接、排序、合并和过滤等数据库操作来解决子图同构问题。将图分解为小的“动机”（motifs），并利用关系操作进行组合。利用NVIDIA RAPIDS和Pandas库实现大规模并行。

Result: Delta-Motif算法的性能基准测试显示，其速度比VF2等传统算法快595倍。该算法已成功应用于量子电路编译，解决了量子计算中的关键瓶颈问题。

Conclusion: Delta-Motif通过数据库抽象简化了高性能图处理，无需底层编程即可实现卓越的计算效率，并为量子计算等领域带来了实际应用价值。

Abstract: Subgraph isomorphism is a fundamental problem in graph analysis that seeks to
find all instances of a pattern graph within a larger data graph while
preserving structural relationships. This NP-complete problem is central to
domains such as biological network analysis, social network mining, and quantum
circuit optimization. Traditional approaches rely on backtracking algorithms
like VF2, which suffer from sequential bottlenecks that limit their ability to
exploit modern parallel hardware. In this work, we introduce $\Delta$-Motif, a
GPU-accelerated subgraph isomorphism algorithm that reformulates the task
through the lens of database operations. Our key insight is to represent both
data and pattern graphs in tabular form, turning subgraph isomorphism into
database primitives including joins, sorts, merges, and filters. $\Delta$-Motif
decomposes graphs into small building blocks called motifs and systematically
combines them using scalable relational operations. By leveraging mature,
optimized libraries from the NVIDIA RAPIDS ecosystem and Pandas framework, our
solution achieves massive parallelism while remaining portable across systems
supporting standard relational primitives. Benchmarks show that $\Delta$-Motif
outperforms established algorithms like VF2, achieving speedups of up to
$595\times$ on GPUs. We further demonstrate its impact by applying it to
quantum circuit compilation, addressing a critical bottleneck in quantum
computing and enabling scaling to near- and medium-term devices. Our approach
democratizes high-performance graph processing by exposing it through familiar
database abstractions, eliminating the need for low-level programming while
delivering exceptional computational efficiency.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [238] [Traffic State Estimation in Congestion to Extend Applicability of DFOS](https://arxiv.org/abs/2508.21138)
*Yoshiyuki Yajima,Hemant Prasad,Daisuke Ikefuji,Hitoshi Sakurai,Manabu Otani*

Main category: eess.SY

TL;DR: 该研究提出了一种基于数据同化的分布式光纤传感（DFOS）的交通状态估计（TSE）方法，以解决在严重拥堵情况下由于车辆振动强度低而导致的缺失值问题，提高了DFOS在实际应用中的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式光纤传感（DFOS）在严重拥堵情况下因车辆速度慢、振动强度低而导致的轨迹缺失和速度数据缺失的问题，从而限制其在实时、空间连续交通监测中的应用。

Method: 提出了一种基于数据同化的缺失值填补方法，用于DFOS的速度数据。

Result: 所提出的方法在两条日本高速公路上进行了验证，结果显示，填补后的平均速度的平均绝对误差（MAE）与非缺失值的MAE相比仅增加了1.5 km/h。

Conclusion: 该研究通过数据同化方法成功解决了DFOS在交通拥堵情况下速度数据缺失的问题，提高了DFOS的适用性，增强了其在实际交通监测中的应用潜力。

Abstract: This paper presents a traffic state estimation (TSE) method in congestion for
distributed fiber-optic sensing (DFOS). DFOS detects vehicle driving vibrations
along the optical fiber and obtains their trajectories in the spatiotemporal
plane. From these trajectories, DFOS provides mean velocities for real-time
spatially continuous traffic monitoring without dead zones. However, when
vehicle vibration intensities are insufficiently low due to slow speed,
trajectories cannot be obtained, leading to missing values in mean velocity
data. It restricts DFOS applicability in severe congestion. Therefore, this
paper proposes a missing value imputation method based on data assimilation.
Our proposed method is validated on two expressways in Japan with the reference
data. The results show that the mean absolute error (MAE) of the imputed mean
velocities to the reference increases only by 1.5 km/h as compared with the MAE
of non-missing values. This study enhances the wide-range applicability of DFOS
in practical cases.

</details>


### [239] [$H_\infty$ Performance Analysis for Almost Periodic Piecewise Linear Systems with Application to Roll-to-Roll Manufacturing Control](https://arxiv.org/abs/2508.21199)
*Christopher Martin,Edward Kim,Enrique Velasquez,Wei Li,Dongmei Chen*

Main category: eess.SY

TL;DR: 本文提出了一种针对几乎周期分段线性系统（APPLS）的H∞性能分析方法和控制器综合算法，以解决其在扰动抑制方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 过程调控，特别是扰动抑制，对于APPLS的性能至关重要，但目前尚无保证扰动抑制的方法。

Method: 开发了一种H∞性能分析方法，并基于此提出了一种综合实际H∞控制器的算法。

Result: 将该方法应用于先进制造系统（如卷对卷干法转移二维材料和印刷柔性电子）的案例研究中，并与未考虑不确定系统切换结构的基线H∞控制器进行了比较。

Conclusion: 实验结果表明，所提出的方法能够生成一个保守性更小、性能更好的H∞控制器。

Abstract: An almost periodic piecewise linear system (APPLS) is a type of piecewise
linear system where the system cyclically switches between different modes,
each with an uncertain but bounded dwell-time. Process regulation, especially
disturbance rejection, is critical to the performance of these advanced
systems. However, a method to guarantee disturbance rejection has not been
developed. The objective of this study is to develop an $H_\infty$ performance
analysis method for APPLSs, building on which an algorithm to synthesize
practical $H_\infty$ controllers is proposed. As an application, the developed
methods are demonstrated with an advanced manufacturing system -- roll-to-roll
(R2R) dry transfer of two-dimensional materials and printed flexible
electronics. Experimental results show that the proposed method enables a less
conservative and much better performing $H_\infty$ controller compared with a
baseline $H_\infty$ controller that does not account for the uncertain system
switching structure.

</details>


### [240] [Cooperative Sensing Enhanced UAV Path-Following and Obstacle Avoidance with Variable Formation](https://arxiv.org/abs/2508.21316)
*Changheng Wang,Zhiqing Wei,Wangjun Jiang,Haoyue Jiang,Zhiyong Feng*

Main category: eess.SY

TL;DR: 该论文研究如何高效准确地实现无人机编队的路径跟随、障碍物感知与规避及其冲突规避融合调度。


<details>
  <summary>Details</summary>
Motivation: 无人机的高移动性使其在救援和货物运输等领域具有广泛应用前景。路径跟随是执行这些任务的关键，而感知和碰撞规避对安全飞行至关重要。因此，研究无人机路径跟随、障碍物感知与规避子任务及其融合调度的有效方法具有重要意义。

Method: 1. 开发了一种基于深度强化学习（DRL）的高精度无人机编队路径跟随模型，并从距离和速度误差的角度设计了具有自适应权重的奖励函数。
2. 利用集成传感与通信（ISAC）信号检测障碍物，并通过信息级融合推导了障碍物感知的克拉美-罗下界（CRLB），在此基础上提出了可变编队增强障碍物位置估计算法（VFEO）。
3. 设计了一种无需预训练的在线避障方案来解决稀疏奖励问题。
4. 借助基于零空间（NSB）的行为方法，提出了一种分层子任务融合策略。

Result: 仿真结果证明了子任务算法和分层融合策略的有效性和优越性。

Conclusion: 该研究提出了一种用于无人机编队的集成路径跟随、障碍物感知和规避的框架，并通过仿真验证了其有效性。

Abstract: The high mobility of unmanned aerial vehicles (UAVs) enables them to be used
in various civilian fields, such as rescue and cargo transport. Path-following
is a crucial way to perform these tasks while sensing and collision avoidance
are essential for safe flight. In this paper, we investigate how to efficiently
and accurately achieve path-following, obstacle sensing and avoidance subtasks,
as well as their conflict-free fusion scheduling. Firstly, a high precision
deep reinforcement learning (DRL)-based UAV formation path-following model is
developed, and the reward function with adaptive weights is designed from the
perspective of distance and velocity errors. Then, we use integrated sensing
and communication (ISAC) signals to detect the obstacle and derive the
Cramer-Rao lower bound (CRLB) for obstacle sensing by information-level fusion,
based on which we propose the variable formation enhanced obstacle position
estimation (VFEO) algorithm. In addition, an online obstacle avoidance scheme
without pretraining is designed to solve the sparse reward. Finally, with the
aid of null space based (NSB) behavioral method, we present a hierarchical
subtasks fusion strategy. Simulation results demonstrate the effectiveness and
superiority of the subtask algorithms and the hierarchical fusion strategy.

</details>


### [241] [State and Input Constrained Model Reference Adaptive Control with Robustness and Feasibility Analysis](https://arxiv.org/abs/2508.21584)
*Poulomee Ghosh,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 提出一种无需优化即可处理不确定、有界约束和干扰的自适应控制器。


<details>
  <summary>Details</summary>
Motivation: 提出一种适用于存在不等匹配扰动的、具有用户定义的状态和输入约束的不确定线性时不变（LTI）系统的模型参考自适应控制器（MRAC）。

Method: 结合饱和自适应控制器和基于障碍李雅普诺夫函数（BLF）的设计，以确保在存在不等匹配扰动的情况下，植物状态和输入始终保持在预定边界内。

Result: 仿真结果（包括与鲁棒MRAC的比较）证明了所提出算法的有效性。

Conclusion: 这是首个同时考虑不确定系统、扰动下的状态和输入约束，并提供可行性条件的控制研究成果。

Abstract: We propose a model reference adaptive controller (MRAC) for uncertain linear
time-invariant (LTI) plants with user-defined state and input constraints in
the presence of unmatched bounded disturbances. Unlike popular
optimization-based approaches for constrained control, such as model predictive
control (MPC) and control barrier function (CBF) that solve a constrained
optimization problem at each step using the system model, our approach is
optimization-free and adaptive; it combines a saturated adaptive controller
with a barrier Lyapunov function (BLF)-based design to ensure that the plant
state and input always stay within pre-specified bounds despite the presence of
unmatched disturbances. To the best of our knowledge, this is the first result
that considers both state and input constraints for control of uncertain
systems with disturbances and provides sufficient feasibility conditions to
check for the existence of an admissible control policy. Simulation results,
including a comparison with a robust MRAC, demonstrate the effectiveness of the
proposed algorithm.

</details>


### [242] [Model Reference Adaptive Control with Time-Varying State and Input Constraints](https://arxiv.org/abs/2508.21586)
*Poulomee Ghosh,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 提出了一种新颖的自适应控制框架（MRAC），用于处理具有用户定义、时变状态和输入约束的不确定线性时不变（LTI）系统。该框架集成了时变障碍李雅普诺夫函数（TVBLF）来强制执行状态约束，并结合时变饱和函数来处理输入限制。此外，还提出了一种可验证的、离线可行性条件，用于检查给定约束集是否存在有效的控制策略。该方法首次实现了在不进行在线优化的前提下，同时处理时变状态和输入约束的自适应控制。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够处理不确定线性时不变（LTI）系统中的时变状态和输入约束的自适应控制方法，同时避免复杂的在线优化。

Method: 本研究提出了一种模型参考自适应控制（MRAC）框架，该框架集成了时变障碍李雅普诺夫函数（TVBLF）来处理状态约束，并结合时变饱和函数来处理输入约束。此外，还推导了一个离线可行性条件，用于验证控制策略的有效性。

Result: 模拟结果验证了所提出的约束MRAC方案的有效性。

Conclusion: 该研究成功提出了一种新颖的自适应控制框架，能够同时处理时变状态和输入约束，并提供了一种离线可行性检查方法，为解决复杂约束条件下的自适应控制问题提供了新的途径。

Abstract: This paper presents a model reference adaptive control (MRAC) framework for
uncertain linear time-invariant (LTI) systems subject to user-defined,
time-varying state and input constraints. The proposed design seamlessly
integrates a time-varying barrier Lyapunov function (TVBLF) to enforce state
constraints with a time-varying saturation function to handle input limits.
These time-varying constraints can be designed as performance functions to
shape transient and steady-state behaviors for both state and input. A key
contribution is the derivation of a verifiable, offline feasibility condition
to check the existence of a valid control policy for a given set of
constraints. To the best of our knowledge, this is the first adaptive control
methodology to simultaneously handle both time-varying state and input
constraints without resorting to online optimization. Simulation results
validate the efficacy of the proposed constrained MRAC scheme.

</details>


### [243] [Adaptive Dead-Zone Dual Sliding Mode Observer for Reliable Electrochemical Model-Based SOC Estimation](https://arxiv.org/abs/2508.21610)
*Guangdi Hu,Keyi Liao,Jian Ye,Feng Guo*

Main category: eess.SY

TL;DR: 该论文提出了一种基于改进电化学单粒子模型的自适应死区双滑模观测器（SMO），用于提高锂离子电池荷电状态（SOC）估计的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决电化学模型在参数变化、非线性和计算复杂性方面的挑战，实现高精度的SOC估计。

Method: 提出了一种自适应死区双滑模观测器（SMO），该观测器结合了SOC估计的状态观测器和在线参数自适应的参数观测器。通过引入Lyapunov导出的自适应死区，仅在终端电压误差在规定范围内时才激活参数更新，以确保稳定性。

Result: 在恒流和UDDS动态条件下验证了所提方法。结果表明，与传统的双SMO和基于等效电路模型的EKF方法相比，自适应死区双SMO具有更高的精度，SOC估计误差在正确初始化时保持在0.2%以内，在30%的初始SOC误差下低于1%，且收敛速度快。此外，该方法通过限制不必要的参数更新，降低了执行时间，并且在电池老化的情况下也表现出良好的鲁棒性。

Conclusion: 所提出的自适应死区双滑模观测器为SOC估计提供了一种可靠、准确且计算高效的解决方案，适用于实时电池管理应用。

Abstract: Accurate state of charge (SOC) estimation is critical for ensuring the
safety, reliability, and efficiency of lithium-ion batteries in electric
vehicles and energy storage systems. Electrochemical models provide high
fidelity for SOC estimation but introduce challenges due to parameter
variations, nonlinearities, and computational complexity. To address these
issues, this paper proposes an adaptive dead-zone dual sliding mode
observer(SMO) based on an improved electrochemical single-particle model. The
algorithm integrates a state observer for SOC estimation and a parameter
observer for online parameter adaptation. A Lyapunov-derived adaptive dead-zone
is introduced to ensure stability, activating parameter updates only when the
terminal voltage error lies within a rigorously defined bound. The proposed
method was validated under constant-current and UDDS dynamic conditions.
Results demonstrate that the adaptive dead-zone dual SMO achieves superior
accuracy compared with conventional dual SMO and equivalent circuit model-based
EKF methods, maintaining SOC estimation errors within 0.2% under correct
initialization and below 1% under a 30% initial SOC error, with rapid
convergence. Computational efficiency analysis further shows that the adaptive
dead-zone dual sliding mode observer reduces execution time compared with the
conventional dual SMO by limiting unnecessary parameter updates, highlighting
its suitability for real-time battery management applications. Moreover,
robustness under battery aging was confirmed using a cycle-aging model, where
the adaptive dead-zone dual SMO maintained stable SOC estimation despite
parameter drift. These findings indicate that the proposed method offers a
reliable, accurate, and computationally efficient solution for SOC estimation.

</details>


### [244] [Adapting to Change: A Comparison of Continual and Transfer Learning for Modeling Building Thermal Dynamics under Concept Drifts](https://arxiv.org/abs/2508.21615)
*Fabian Raisch,Max Langtry,Felix Koch,Ruchi Choudhary,Christoph Goebel,Benjamin Tischler*

Main category: eess.SY

TL;DR: 文章比较了持续学习（CL）和迁移学习（TL）策略，以及从头训练的模型，用于建筑热力学建模。提出了一种名为“季节性记忆学习”（SML）的CL策略，该策略在处理建筑运行数据和概念漂移（如改造或入住率变化）方面，比现有CL和TL方法具有更高的准确性，且计算成本较低。


<details>
  <summary>Details</summary>
Motivation: 在建筑热力学建模中，当可用数据有限时，迁移学习（TL）是有效的方法。然而，随着时间的推移和建筑动态的变化（如改造或入住率变化），如何更新TL模型以适应这些变化仍然是一个挑战。机器学习中的持续学习（CL）方法可以解决这个问题，但目前缺乏关于如何结合新的测量数据以提高预测精度和应对概念漂移的综合研究。

Method: 本文比较了几种CL和TL策略，以及一种从头训练的模型，用于建筑运行期间的热力学建模。使用代表中欧单户住宅的5-7年模拟数据对这些方法进行了评估，其中包括因改造和入住率变化引起的概念漂移场景。

Result: 提出的SML策略比初始微调基线在无概念漂移的情况下提高了28.1%的准确性，在有概念漂移的情况下提高了34.9%。

Conclusion: SML策略在提高建筑热力学建模的准确性方面优于现有的CL和TL方法，并且具有较低的计算成本，能够有效应对概念漂移。

Abstract: Transfer Learning (TL) is currently the most effective approach for modeling
building thermal dynamics when only limited data are available. TL uses a
pretrained model that is fine-tuned to a specific target building. However, it
remains unclear how to proceed after initial fine-tuning, as more operational
measurement data are collected over time. This challenge becomes even more
complex when the dynamics of the building change, for example, after a retrofit
or a change in occupancy. In Machine Learning literature, Continual Learning
(CL) methods are used to update models of changing systems. TL approaches can
also address this challenge by reusing the pretrained model at each update step
and fine-tuning it with new measurement data. A comprehensive study on how to
incorporate new measurement data over time to improve prediction accuracy and
address the challenges of concept drifts (changes in dynamics) for building
thermal dynamics is still missing.
  Therefore, this study compares several CL and TL strategies, as well as a
model trained from scratch, for thermal dynamics modeling during building
operation. The methods are evaluated using 5--7 years of simulated data
representative of single-family houses in Central Europe, including scenarios
with concept drifts from retrofits and changes in occupancy. We propose a CL
strategy (Seasonal Memory Learning) that provides greater accuracy improvements
than existing CL and TL methods, while maintaining low computational effort.
SML outperformed the benchmark of initial fine-tuning by 28.1\% without concept
drifts and 34.9\% with concept drifts.

</details>


### [245] [Chance-Constrained DC Optimal Power Flow Using Constraint-Informed Statistical Estimation](https://arxiv.org/abs/2508.21687)
*Tianyang Yi,D. Adrian Maldonado,Anirudh Subramanyam*

Main category: eess.SY

TL;DR: 本研究提出了一种新的不确定性建模和估计方法，用于解决直流最优潮流（DC-OPF）中的机会约束优化问题，通过直接对聚合系统预测误差和线路误差进行建模，实现了显著的降维和性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决电力系统中不确定性管理问题，改进直流最优潮流（DC-OPF）模型中的机会约束优化方法。

Method: 提出一种新的不确定性建模和估计方法，直接对一维聚合系统预测误差和二维线路误差（按功率传输分布因子加权）进行建模，以降低维度。

Result: 在合成和真实世界数据集上，使用高斯和非高斯分布进行评估，证明了与现有方法相比，在统计准确性和优化性能方面取得了显著的改进。

Conclusion: 所提出的方法通过利用约束结构来指导不确定性估计，实现了显著的维度约减，并在统计准确性和优化性能方面优于现有方法。

Abstract: Chance-constrained optimization has emerged as a promising framework for
managing uncertainties in power systems. This work advances its application to
the DC Optimal Power Flow (DC-OPF) model, developing a novel approach to
uncertainty modeling and estimation. Current methods typically tackle these
problems by first modeling random nodal injections using high-dimensional
statistical distributions that scale with the number of buses, followed by
deriving deterministic reformulations of the probabilistic constraints. We
propose an alternative methodology that exploits the constraint structure to
inform the uncertainties to be estimated, enabling significant dimensionality
reduction. Rather than learning joint distributions of net-load forecast errors
across units, we instead directly model the one-dimensional aggregate system
forecast error and two-dimensional line errors weighted by power transfer
distribution factors. We evaluate our approach under both Gaussian and
non-Gaussian distributions on synthetic and real-world datasets, demonstrating
significant improvements in statistical accuracy and optimization performance
compared to existing methods.

</details>


### [246] [Transferring the driveshaft inertia to the grid via the DC-link in MV drive systems](https://arxiv.org/abs/2508.21760)
*Catalin Arghir,Pieder Jörg,Silvia Mastellone*

Main category: eess.SY

TL;DR: 该研究提出了一种控制方法，使传动轴惯量可完全用于电网侧，并改善了中压驱动系统的故障穿越能力。研究表明，通过修改速度控制参考信号和采用直流侧控制策略，可以实现传动轴旋转惯量与电网的同步耦合。此外，该研究还将标准的锁相环（PLL）和匹配控制方法视为具有不同稳态映射的反馈优化方案，并进行了详细的仿真研究。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提高中压驱动系统的故障穿越能力，并探索一种使传动轴惯量可完全用于电网侧的控制方法。

Method: 研究采用修改速度控制参考信号和直流侧控制策略（包括基于常规级联控制和基于同步电机（SM）模型匹配的两种方法）来实现传动轴惯量与电网的同步耦合。此外，还通过射线-圆互补性将PLL和匹配控制方法解释为反馈优化方案。

Result: 研究表明，所提出的控制方法可以使传动轴惯量可用于电网侧，并增强系统的故障穿越能力。仿真结果验证了该方法的有效性。

Conclusion: 该研究成功提出了一种使传动轴惯量可用于电网侧的控制方法，并改善了中压驱动系统的故障穿越能力。研究结果为优化驱动系统控制提供了新的视角。

Abstract: This paper investigates a control approach that renders the driveshaft
inertia completely available on the grid side and enhances the fault
ride-through behavior of medium-voltage (MV) drive systems. Two main
contributions are presented. First, we show how the rotational inertia of the
driveline shaft can be synchronously coupled to the grid through a modification
of the speed control reference signal and through an adapted DC-link control
strategy. For the latter, we pursue two alternatives: one based on conventional
cascaded control and another based on synchronous machine (SM) model matching.
Second, we demonstrate that both the standard phase-locked loop (PLL) and the
matching control approach can be interpreted, via the ray-circle
complementarity, as feedback optimization schemes with distinct steady-state
maps. This perspective allows us to revisit matching control, reveal its
embedded PLL, highlight its current-limiting and tracking capabilities, and
provide an extensive simulation study.

</details>


### [247] [DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers](https://arxiv.org/abs/2508.21797)
*Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li*

Main category: eess.SY

TL;DR: DynaMark是一个强化学习框架，通过动态调整水印统计数据来防御针对工业4.0机床控制器（MTC）的重放攻击，即使在系统行为多变的情况下也能有效检测篡改，并能在能耗和检测信心之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有动态水印方案在处理工业4.0中多变且部分专有的机床控制器（MTC）行为时存在的脆弱性，需要一种能够适应MTC动态特性并有效抵御重放攻击的水印方法。

Method: 提出DynaMark框架，将动态水印设计为马尔可夫决策过程（MDP），并利用强化学习在线学习自适应策略。该策略能够动态调整零均值高斯水印的协方差，无需系统知识，并优化一个平衡控制性能、能耗和检测信心的奖励函数。针对线性系统，开发了贝叶斯信念更新机制以实现实时检测置信度。

Result: 在西门子Sinumerik 828D控制器数字孪生上，DynaMark与恒定方差基线相比，水印能量降低了70%，同时保持了标称轨迹，并且平均检测延迟仅为一个采样间隔。在物理步进电机测试台上也验证了这些结果，DynaMark能快速触发警报，且控制性能下降较小，优于现有基准。

Conclusion: DynaMark框架通过强化学习实现了动态水印的自适应，能够有效应对工业4.0机床控制器多变的行为，在降低水印能量、保持控制性能和实现快速准确检测方面均表现出色，为防御重放攻击提供了一种鲁棒的解决方案。

Abstract: Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime
targets for replay attacks that use outdated sensor data to manipulate
actuators. Dynamic watermarking can reveal such tampering, but current schemes
assume linear-Gaussian dynamics and use constant watermark statistics, making
them vulnerable to the time-varying, partly proprietary behavior of MTCs. We
close this gap with DynaMark, a reinforcement learning framework that models
dynamic watermarking as a Markov decision process (MDP). It learns an adaptive
policy online that dynamically adapts the covariance of a zero-mean Gaussian
watermark using available measurements and detector feedback, without needing
system knowledge. DynaMark maximizes a unique reward function balancing control
performance, energy consumption, and detection confidence dynamically. We
develop a Bayesian belief updating mechanism for real-time detection confidence
in linear systems. This approach, independent of specific system assumptions,
underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D
controller digital twin, DynaMark achieves a reduction in watermark energy by
70% while preserving the nominal trajectory, compared to constant variance
baselines. It also maintains an average detection delay equivalent to one
sampling interval. A physical stepper-motor testbed validates these findings,
rapidly triggering alarms with less control performance decline and exceeding
existing benchmarks.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [248] [The crystalline properties of silica biomorphs vary within and between morphologies](https://arxiv.org/abs/2508.21149)
*Moritz P. K. Frewein,Britta Maier,Moritz L. Stammer,Isabella Silva-Barreto,Anastasiia Sadetskaia,Asma Medjahed,Remi Tucoulou,Manfred Burghammer,Henrik Birkedal,Tilman A. Grünewald*

Main category: cond-mat.mtrl-sci

TL;DR: Silica-carbonate biomorphs are emergent materials with complex structures, and this paper uses X-ray texture and diffraction tomography to analyze their 3D crystalline texture, revealing variations in growth motifs and crystalline properties within single structures, leading to a deeper understanding of their formation.


<details>
  <summary>Details</summary>
Motivation: To understand the formation process of silica-carbonate biomorphs and how synthesis parameters affect their nanoscale properties and microscale shape, as incomplete understanding is a hurdle for functionalization.

Method: X-ray texture and diffraction tomography were used to analyze the local crystalline texture in 3D of silica-witherite biomorphs.

Result: Different growth motifs were found across different morphologies, and crystalline properties varied significantly within a single structure. Different growth regimes were distinguished, and insights were gained into how co-precipitating silica shapes crystalline particles.

Conclusion: The study provides deeper insights into how silica-carbonate biomorphs form distinct complex morphologies by analyzing their 3D crystalline texture and inferring the role of silica in shaping crystalline particles.

Abstract: Silica-carbonate biomorphs are a class of emergent materials, i.e. composite
microstructures made of nanometric carbonate crystallites surrounded by
amorphous silica. They form via a co-precipitation process in an interplay
between alkaline earth metal carbonate and siliceous species, and self-organize
into a multitude of shapes with a distinct long-range order of the carbonate
nanocrystals. Biomorphs are frequently studied to understand the formation of
life-like structures emerging from geochemical processes at extreme conditions.
Further, due to their optical properties they lend themselves as a platform for
optical, electronic or magnetic functionalization. A big hurdle in this task is
our incomplete understanding of the underlying formation process and how the
interplay between synthesis parameters affects important nanoscale properties
such as crystalline structure and texture, as well as the shape on the
microscale. Here, we use X-ray texture and diffraction tomography to unveil the
local crystalline texture in 3D of silica-witherite biomorphs. We find
surprisingly different growth motifs across different morphologies, but also
that the crystalline properties vary significantly within a single structure.
We distinguish different growth regimes and from that, infer how the
co-precipitating silica shapes the crystalline particles. Thereby, we gain
deeper insight into how biomorphs form these distinct complex morphologies.

</details>


### [249] [Simulation of Radiation Damage on [M(COD)Cl]$_2$ using Density Functional Theory](https://arxiv.org/abs/2508.21170)
*Nathalie K. Fernando,Nayera Ahmed,Katherine Milton,Claire A. Murray,Anna Regoutz,Laura E. Ratcliff*

Main category: cond-mat.mtrl-sci

TL;DR: 理论计算在分析X射线照射下有机金属化合物的实验数据方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 理论计算，特别是密度泛函理论，在分析X射线照射下有机金属化合物（如[M(COD)Cl]2，M=Ir/Rh，COD=1,5-环辛二烯）的复杂实验数据方面具有重要价值，尽管目前这方面的研究尚不普遍。

Method: 使用密度泛函理论（DFT）对受X射线照射的[M(COD)Cl]2（M=Ir/Rh）的电子结构进行建模，并将计算出的X射线光电子价带谱与实验数据进行比较。

Result: 该方法能够将计算出的光谱与实验数据（X射线光电子价带谱）直接比较，从而实现将单个原子态与电子结构相关联。

Conclusion: 密度泛函理论为模拟X射线照射下有机金属化合物的电子结构提供了一种有前景的方法，并能与实验数据直接进行比较，从而加深对分子间损伤过程的理解。

Abstract: Theoretical calculations of materials have in recent years shown promise in
facilitating the analysis of convoluted experimental data. This is particularly
invaluable in complex systems or for materials subject to certain environmental
conditions, such as those exposed to X-ray radiation during routine
characterisation. Despite the clear benefit in this use case to shed further
light on intermolecular damage processes, the use of theory to study radiation
damage of samples is still not commonplace, with very few studies in existing
literature. In this paper, we demonstrate the potential of density functional
theory for modelling the electronic structure of two industrially important
organometallic systems of the formula [M(COD)Cl]$_2$ where M=Ir/Rh and
COD=1,5-cyclooctadiene, which are subject to X-ray irradiation via X-ray
Diffraction and X-ray Photoelectron Spectroscopy. Our approach allows
calculated spectra to be compared directly to experimental data, in this case,
the X-ray photoelectron valence band spectra, enabling the valuable correlation
of individual atomic states to the electronic structure.

</details>


### [250] [X-ray diffraction strains in laser-ablated aluminum, nickel, sodium and Invar: pressures to 475 GPa](https://arxiv.org/abs/2508.21173)
*S. J. Burns,Danae N. Polsin*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文研究了纵波压缩下材料的两种物理模型（静水压和单轴应变），并使用X射线衍射技术进行了实验比较和评估。


<details>
  <summary>Details</summary>
Motivation: 比较和评估材料在纵波压缩下，基于静水压和单轴应变两种物理模型的差异。

Method: 开发了一种基于晶格应变的三维布拉格衍射X射线解，并结合了应变倒易点阵和入射X射线束。通过在同一晶体相中测量两个平面上的纳米秒衍射来确定应变。

Result: 测量了Al、Ni、Na和Invar在不同压力下的压缩轴向应变，并量化了其应变比。结果表明，在立方和六方相的铝中，面内应变随压力增大而增大。

Conclusion: 晶体结构转变与均匀加压应力（要求等法向应变）不应与非均匀单轴应变和剪切晶体相一致。实验测量结果支持这一结论。

Abstract: Dynamically compressed materials in longitudinal waves are described by two
physical models: hydrostatic pressure, with equal, normal, principal stresses
or material uniaxially strained in the wave propagation direction. These models
are disparate, so experimental comparisons and evaluations are important.
Polycrystalline material in a state of hydrostatic pressure, will have no
eccentricity of X-ray diffracted Debye-Scherrer rings. A general
three-dimensional solution of Bragg diffracted X-rays based on principal
crystallographic strains in the compression wave was found. The distortion of
X-ray diffraction beams has been used for strain measurements; the analysis
developed incorporates a strained reciprocal lattice and the incident X-ray
beam. Strain distorted Polanyi surfaces form an annulus of compression with an
ellipsoid of revolution in reciprocal space which is intersected by Ewald
sphere for Bragg diffraction. The in-situ measurements for strain describe
nanosecond diffraction evaluated using two planes, and both in the same
crystallographic phase. Diffraction from Al, Ni, Na, and Invar quantify the
compression axial strains in these materials: the compression axial ratios are
0.65, 1.05, 0.88 and 1.58 at pressures of 291, 402, 409, and 367 GPa for the
respective materials. Crystal structure transformations with homogeneous
pressurized stresses, mandating equal normal strains, should not be anticipated
to agree with heterogeneous, uniaxially strained and sheared crystalline
phases. Measurements support in-plane strains increasing with pressure, p, in
fcc and hcp aluminum as with p in GPa.

</details>


### [251] [Fracture of disordered and stochastic lattice materials](https://arxiv.org/abs/2508.21187)
*Sage Fulco,Prashant K. Purohit,Michal K. Budzik,Kevin T. Turner*

Main category: cond-mat.mtrl-sci

TL;DR: 本论文提出一个概率模型来预测包含几何缺陷和材料随机性失效的晶格材料的失效行为。


<details>
  <summary>Details</summary>
Motivation: 传统分析方法无法捕捉随机失效属性和无序微结构几何对宏观失效力学的潜在影响，本研究旨在解决此问题。

Method: 提出一个概率模型，耦合随机材料失效和几何无序性，用于预测晶格材料的失效。通过有限元分析验证了模型的预测能力。

Result: 结果表明，无序性和随机性会影响损伤起始载荷的均值和方差，平均失效载荷随无序性和随机性的增加而降低，方差则增加。模型还预测了断裂-内聚长度和代表性体积单元尺寸，并确定了失效为断裂过程的最小缺陷和晶格尺寸。

Conclusion: 本研究提出的概率框架能够有效预测包含几何缺陷和材料随机性失效的晶格材料的失效行为，并为理解这些因素对材料力学性能的影响提供了新的见解。

Abstract: The failure of mechanical metamaterials is a function of the interplay
between the properties of the base material and the microstructural geometry.
Stochastic failure properties of the base material and disordered
microstructural geometries can contribute to variations in the global failure
mechanics that are not captured in traditional analyses of ordered,
deterministic architected materials. We present a probabilistic framework that
couples stochastic material failure and geometric disorder to predict failure
in lattice mechanical metamaterials. These predictions are verified through
finite element analysis, which confirm that disorder and stochasticity affect
both the mean and variance of the damage initiation load in a lattice, with
average failure loads being generally reduced and variance increasing with
higher levels of disorder and stochasticity. The fracto-cohesive length and
representative volume element size are also predicted and constrain the minimum
defect and lattice sizes, respectively, for failure to be considered a fracture
process. The framework is extended to consider the fracture behavior of the
lattice, the development of damage zones, and their impact on the steady-state
fracture toughness.

</details>


### [252] [Correlation tuned Fermi-arc topology in a Weyl ferromagnet](https://arxiv.org/abs/2508.21292)
*Yiran Peng,Rui Liu,Pengyu Zheng,Zhiping Yin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过调节电子相关性来控制外尔半金属Co3Sn2S2中的费米弧


<details>
  <summary>Details</summary>
Motivation: 费米弧是外尔半金属的标志，但对其进行调控的研究很少。本研究旨在探索调控费米弧的方法。

Method: 结合密度泛函理论（DFT）和动力学平均场理论（DMFT）计算，研究电子相关性对Co3Sn2S2费米弧的影响。

Result: 电子相关性重整化了费米能级附近的能带，改变了外尔点的位置和能量，并影响了费米弧的连接方式。在Co端面，费米弧连接了不同布里渊区的檛点，与DFT计算结果不同。在Sn端面，随着相关性的增强，费米弧发生了拓扑变化。

Conclusion: 调节电子相关性是控制外尔半金属费米弧拓扑和连通性的有效方法，为调控其电子性质提供了新的思路。

Abstract: Electrons on Fermi arcs (FAs), a hallmark of Weyl semimetals, exhibit chiral
transport harboring chiral anomaly, negative magnetoresistance, and Majorana
zero modes. While FAs were observed in exemplary Weyl semimetal TaAs and
Co3Sn2S2, the manipulation of FAs has been rarely explored. Here we take
Co3Sn2S2 as an example and demonstrate that tuning the electronic correlation
strength is an effective way to control the topology and connectivity of FAs.
After achieving a good agreement with experimentally measured band structure by
employing combined density functional theory and dynamical mean field theory
(DFT+DMFT) calculations, we show that the experimental charge dynamics are well
reproduced by DFT+DMFT calculations but not DFT calculations. Electronic
correlation renormalizes the bands around the Fermi level and modifies the
energy and location of Weyl points, and the resulting FAs. In particular, on
the Co-terminated surface, the FAs are formed by connecting Weyl points located
in adjacent Brillouin zones in DFT+DMFT calculations and experiments, in strong
contrast to the FAs connecting Weyl points within the same Brillouin zone in
DFT calculations. We further show the evolution of FAs with correlation and
reveal a topological change of the FAs on the Sn-terminated surface at stronger
correlation strength. Our study sheds new light on experimental manipulation of
FAs to improve the electronic properties of correlated Weyl semimetals.

</details>


### [253] [Understanding the atomically precise evolution of the miscibility of newly prepared face-centered cubic W-Cu nanoalloys and its asymmetry](https://arxiv.org/abs/2508.21317)
*Yongxin Zhang,Weihan Zhang,Luneng Zhao,Zixiang Zhao,Siqi Lu,Yangrui Liu,Dongsheng Song,Changzheng Wei,Zhentao Pang,Yifeng Ren,Junfeng Gao,Weiwei Gao,Di Wu,Jijun Zhao,Kuo-Juei Hu,Wei Ji,Yu Deng,Binghui Ge,Fengqi Song*

Main category: cond-mat.mtrl-sci

TL;DR: 通过使用原子尺寸选择的团簇束源，我们成功制备了具有大混溶性间隙的 W-Cu 纳米合金，该合金在体相中表现出固溶性，并且通过密度泛函理论计算揭示了一种相互诱导的应变机制，该机制在减小尺寸到原子尺度时同时降低了表面能，为开发新型高性能非平衡相合金铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 经典米德玛理论表明，将晶体尺寸减小到纳米级别可以显著改变元素的混合焓，从而可以制造许多新的体块不混溶合金。然而，这种策略正接近其极限，如近期合金的临界直径 1.8 nm 所示，这对应约 150 个原子，几乎无法提供晶体有序性。未来的发展不仅需要原子级别的控制，还需要新的节省表面能的机制。

Method: 本文利用原子尺寸选择的团簇束源制备了 W-Cu 纳米合金，并通过电子衍射证明了其面心立方结构，最后使用密度泛函理论（DFT）计算揭示了其形成机理。

Result: 通过对 W/Cu 组分和原子数的大量参数空间进行研究，首次获得了不对称的固溶纳米相图，其中富 W 组分有利于混合，临界尺寸约为 6000 个原子，远超经典理论预测的约几十个原子。W0.85Cu0.15 纳米合金（约 2280 个原子）的面心立方结构表现出 3.88 Å 的晶格常数。

Conclusion: 本研究成功制备了 W-Cu 纳米合金，证明了通过原子尺寸选择的团簇束源可以实现体块混溶性，并揭示了相互诱导的应变机制，这为开发新型高性能非平衡相合金提供了新的途径。

Abstract: According to classical Miedema theory, reducing crystals to the order of
nanometer sizes might greatly modulate the mixing enthalpy of elements, thus
enabling the invention of a lot of new bulk-immiscible alloys. Although
numerous alloys with higher mixing enthalpies remain unexplored, this strategy
is approaching its limit, as reflected by the critical diameter of recent
alloys of 1.8 nm, which corresponds to ~150 atoms and hardly provides a
crystalline order. Future development requires not only even smaller
atomic-scale control but also a new surface energy-saving mechanism. Here, we
report the formation of W-Cu nanoalloys with a very large miscibility gap in
the bulk via the use of an atomically size-selected cluster beam source as an
example. The face-centered cubic (FCC) structure was demonstrated through
electron diffraction, which indicated a lattice constant of 3.88{\AA} for
W0.85Cu0.15 nanoalloys (~2280 atoms). In this comprehensive study that covers a
large parameter space of W/Cu compositions and numbers of atoms, an asymmetric
miscibility nanophase diagram in which W-rich compositions favor mixing and the
critical size is approximately 6000 atoms, which far exceeds the approximately
tens of atoms predicted via classical theory, was obtained for the first time.
Density functional theory (DFT) calculations revealed a mutual strain-induced
mechanism that simultaneously lowers the surface energies while reducing the
size to the atomic scale. This approach paves the way for the development of
new high-performance nonequilibrium phase alloys.

</details>


### [254] [Quantum Monte Carlo Benchmarking of Molecular Adsorption on Graphene-Supported Single Pt Atom](https://arxiv.org/abs/2508.21339)
*Jeonghwan Ahn,Iuegyun Hong,Gwangyoung Lee,Hyeondeok Shin,Anouar Benali,Yongkyung Kwon*

Main category: cond-mat.mtrl-sci

TL;DR: DFT计算在模拟CO氧化催化剂的吸附能方面存在显著差异，DMC计算提供了更准确的结果，凸显了CO中毒效应，并强调了使用更复杂计算方法的必要性。


<details>
  <summary>Details</summary>
Motivation: 为了在资源效率和环境可持续性的约束下，精确理解催化活性位点的吸附能量和分子几何，以推动催化科学的发展。

Method: 通过密度泛函理论（DFT）计算与扩散蒙特卡洛（DMC）计算对比，评估了两种方法在模拟CO氧化相关小分子（O$_2$、CO、CO$_2$和原子氧）在单原子Pt/石墨烯催化剂上吸附性能的差异。

Result: DMC计算结果与DFT计算结果在吸附能量方面存在显著差异，尤其是在O$_2$的最低能量构型和自旋态预测上。DMC计算得到的O$_2$吸附能为-1.23(2) eV，CO吸附能为-3.37(1) eV，揭示了CO中毒效应可能抑制催化过程。

Conclusion: 本研究结果强调了在催化研究中使用更高级的计算方法（如DMC）的必要性，以提高反应机理预测的准确性，并促进更有效的催化剂设计。

Abstract: The precise understanding of adsorption energetics and molecular geometry at
catalytic sites is fundamental for advancing catalysis, particularly under the
constraints of resource efficiency and environmental sustainability. This study
benchmarks the performance of density functional theory (DFT) calculations
against diffusion Monte Carlo (DMC) calculations for adsorption properties of
small gas molecules relevant to CO oxidation -- namely O$_2$, CO, CO$_2$, and
atomic oxygen -- on a single Pt atom supported by pristine graphene. Our
findings reveal that DMC calculations provide a significantly different
landscape of adsorption energetics compared to DFT results. Notably, DFT
predicts different lowest-energy configurations and spin states, particularly
for O$_2$, which suggests potential discrepancies in predicting the catalytic
behavior. Furthermore, this study identifies the critical issue of CO
poisoning, highlighted by the large disparity between the DMC adsorption
energies of O$_2$ ($-1.23(2)$ eV) and CO ($-3.37(1)$ eV), which can inhibit the
catalytic process. These results emphasize the necessity for more sophisticated
computational approaches in catalysis research, aiming to refine the prediction
accuracy of reaction mechanisms and to enhance the design of more effective
catalysts.

</details>


### [255] [Tunable Two-Dimensional Electron Gas at the Interfaces of Ferroelectric Potassium Tantalate Niobates](https://arxiv.org/abs/2508.21359)
*Jiaxin Lv,Silan Li,Chenhao Duan,Shuanhu Wang,Hong Yan,Kexin Jin*

Main category: cond-mat.mtrl-sci

TL;DR: 铁电氧化物基场效应晶体管（FET）中的二维电子气（2DEG）调控仍具挑战性。本研究通过在铁电铌酸钾（KTN）衬底上沉积非晶LaAlO3（LAO）薄膜，成功制备了可调控的2DEG系统。在高温高氧压条件下生长的界面表现出良好的金属性。在108 K以下观察到具有明显磁滞和持久电场调制电阻的2DEG，在7 K时电阻调制达11.6%。


<details>
  <summary>Details</summary>
Motivation: 实现铁电氧化物基场效应晶体管（FET）中二维电子气（2DEG）的精确调控。

Method: 通过在(001)取向的铁电铌酸钾（KTN）衬底上沉积非晶LaAlO3（LAO）薄膜来构建2DEG系统，并在高温高氧压条件下进行生长和测试。

Result: 在108 K以下观察到具有明显磁滞和持久电场调制电阻的2DEG，在7 K时电阻调制达11.6%。

Conclusion: 该研究成功制备了可调控的2DEG系统，并展示了其在铁电氧化物基场效应晶体管中的应用潜力，为进一步探索复杂氧化物异质结构中的铁电金属提供了基础。

Abstract: The heterointerfaces at complex oxides have emerged as a promising platform
for discovering novel physical phenomena and advancing integrated sensing,
storage, and computing technologies. Nevertheless, achieving precise control
over a two-dimensional electron gas (2DEG) in a ferroelectric oxide-based
field-effect transistor (FET) configuration remains challenging. Here, we
firstly demonstrate a tunable 2DEG system fabricated by depositing an amorphous
LaAlO3(LAO) film onto a (001)-oriented ferroelectric potassium tantalate
niobate substrate. Interfaces grown under high-temperature and
high-oxygen-pressure conditions exhibit a good metallic conduction. Notably,
well-defined metallic 2DEGs displaying pronounced hysteresis and persistent
electric-field-modulated resistance are observed below 108 K, achieving a
resistance modulation of 11.6% at 7 K. These results underscore the potential
for extending such behavior to other oxide-based 2DEG systems and facilitate
further exploration of ferroelectric metals in complex oxide heterostructures.

</details>


### [256] [Control of growth morphology of deposited fcc metals through tuning substrate-metal interactions](https://arxiv.org/abs/2508.21492)
*Samuel Aldana,Michael Nolan*

Main category: cond-mat.mtrl-sci

TL;DR: 通过调整衬底-金属相互作用强度和热真空退火，可以控制金属薄膜的生长模式（二维层层生长或三维岛生长），以优化其形貌和性能。


<details>
  <summary>Details</summary>
Motivation: 精确控制薄膜形貌对于优化材料在不同技术应用中的性能至关重要，因为生长模式决定了关键功能特性。

Method: 使用六种fcc金属（Ag, Au, Cu, Ni, Pd, Pt）在(111)方向上进行广泛的动力学蒙特卡洛模拟，通过改变衬底-金属相互作用强度（调整上移和下移的活化能）和热真空退火来探索和控制生长模式。

Result: 模拟结果表明，调节衬底相互作用强度可以有效地促进岛形成或层层生长模式，从而获得更大的平坦表面积。Au, Pd, Pt 对衬底相互作用强度变化的敏感性最高。增强的金属-衬底相互作用可以降低均方根粗糙度、裸露衬底暴露、岛屿数量和岛屿纵横比，并适度增加平坦表面积和原子配位数。热真空退火可改善互连相关指标，如降低表面粗糙度、实现更大的平坦表面积、合并和光滑岛屿、降低缺陷密度。

Conclusion: 通过调节衬底-金属相互作用强度和热真空退火是控制金属薄膜生长模式和优化其形貌与性能的有效策略。

Abstract: Precise control over thin film morphology is critical for optimizing material
properties across diverse technological applications, as the growth mode
(whether 2D layer-by-layer or 3D island formation)determines key functional
properties such as electrical conductivity in CMOS interconnect applications
and catalytic activity, where island distribution and size dictate performance.
To explore the role of the substrate on the morphology of deposited metals, we
present extensive kinetic Monte Carlo simulations on six fcc metals growing in
the (111) direction: Ag, Au, Cu, Ni, Pd and Pt. Our simulation framework
enables screening and evaluation of their growth mode under homoepitaxial
growth scenarios and proposes morphology control strategies by variation of
substrate-metal interaction strengths, modeled by modifying the activation
energies for upward and downward migration, combined with thermal vacuum
annealing within typical back end of line (BEOL) integration thermal budget.
Our simulation results demonstrate that modulation of the substrate interaction
strength can be effectively employed to promote island formation or
layer-by-layer growth modes overcoming limitations in achieving large flat
surface areas. Au, Pd and Pt exhibit the highest sensitivity to substrate
interaction strength variations, followed by Ag, showing that strongly
interacting substrates decrease the root mean square (RMS) roughness,
(uncovered) substrate exposure, island number and island aspect ratios, with
moderate increases in flat surface areas and atomic coordination numbers.
Additionally, interconnect relevant metrics are improved through thermal vacuum
annealing particularly when sufficiently strong metal-substrate interactions
are employed, reducing surface roughness, achieving larger flat surface areas,
merging and smoothing islands, and decreasing defect density...

</details>


### [257] [Exploring the signature of two ferromagnetic states and goniopolarity in LaCrGe3 through Hall effect](https://arxiv.org/abs/2508.21508)
*Modhumita Sariket,Najrul Islam,Saquib Shamim,Nitesh Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: LaCrGe3具有奇特的两个铁磁（FM）相，本文利用霍尔效应证明了这些相的存在，并观察到了与相界相关的异常霍尔电导率和霍尔系数变化。


<details>
  <summary>Details</summary>
Motivation: LaCrGe3是理解铁磁（FM）材料中量子临界现象的模型材料，同时其奇特的两个FM相也引起了研究者的兴趣。

Method: 通过在固定磁场下进行连续的、依赖于温度的霍尔电阻率测量来证明这些相的存在，并观察霍尔电阻率和霍尔系数在相界处的行为。

Result: 在LaCrGe3中观察到了两个FM相，并且在相界处观察到剩余霍尔电阻率达到最大值，霍尔系数达到最小值。在2K且磁场沿磁易轴方向施加时，观察到高达1160 (Ω·cm)⁻¹的异常霍尔电导率，这在低温FM相中主要由内禀效应引起。在顺磁（PM）相中，观察到“角度极性”现象，即沿不同晶体学方向的载流子极性相反。

Conclusion: LaCrGe3的磁相行为以及其表现出的角度极性传输现象，使其成为未来电子器件的有希望的候选材料。

Abstract: LaCrGe3 has become a playground to understand quantum critical phenomena in
ferromagnetic (FM) materials. It has also garnered attention due to its
peculiar two FM phases. Here, we demonstrate the presence of these phases using
the Hall effect. Continuous temperature-dependent Hall resistivity measurements
at fixed magnetic fields clearly demonstrate the presence of these phases,
regardless of the direction of the applied magnetic field. The remanent Hall
resistivity and Hall coefficient undergo a maximum and a minimum, respectively,
at the boundary between the two phases. We observe significantly large
anomalous Hall conductivity of 1160 ohm-1cm-1 at 2 K when the magnetic field is
applied along the magnetic easy axis, which is dominated by intrinsic effects,
at least in the low-temperature FM phase. In the paramagnetic (PM) phase,
hexagonal LaCrGe3 exhibits opposite charge carrier polarities along different
crystallographic directions, attributed to the anisotropic Fermi surface
geometry, a phenomenon known as "goniopolarity". The coexistence of goniopolar
transport and unconventional magnetic phases may lead this material as a
promising candidate for future electronic devices.

</details>


### [258] [Chemical Control of Mechanical Anisotropy and Band Alignment in Perylene-based Two-dimensional MoS$_2$-Organic Hybrids](https://arxiv.org/abs/2508.21526)
*Mohammed El Amine Miloudi,Oliver Kühn*

Main category: cond-mat.mtrl-sci

TL;DR: We investigated hybrid interfaces of MoS2 with perylene, perylene diimide, and perylene orange using DFT. We found that chemical modification of the organic molecules significantly alters the mechanical and electronic properties of the hybrid system. The systems exhibit distinct differences due to their composition and van der Waals contact. All systems are structurally stable, with binding energies following the order PDI > P > PO. Young's modulus and Poisson's ratio show anisotropy, with PO exhibiting the greatest anisotropy due to steric effects and a permanent dipole. Physisorption is accompanied by net charge transfer, and interfacial polarization results in changes to the work function in the order P > PO > PDI. The organic molecules introduce states into the MoS2 energy gap, with band alignment being either type II (P, PO) or type I (PDI).


<details>
  <summary>Details</summary>
Motivation: To investigate how chemical modification of organic molecules affects the mechanical and electronic properties of hybrid MoS2 interfaces.

Method: Density functional theory (DFT) was used to study the interactions between monolayer MoS2 and perylene (P), perylene diimide (PDI), and perylene orange (PO).

Result: The three hybrid systems showed distinct mechanical and electronic properties due to their chemical composition and van der Waals interactions. All systems were structurally stable. Binding energies followed the order PDI > P > PO. Mechanical properties like Young's modulus and Poisson's ratio exhibited anisotropy, with PO showing the highest due to steric effects and a permanent dipole. Net charge transfer during physisorption followed the same order as binding energies. Interfacial polarization altered the work function in the order P > PO > PDI. The presence of organic molecules created states within the MoS2 energy gap, resulting in type II band alignment for P and PO, and type I for PDI.

Conclusion: The study demonstrates that the mechanical and electronic properties of MoS2-organic hybrid systems can be tuned by chemically modifying the organic component. The observed changes in binding energy, mechanical anisotropy, work function, and band alignment highlight the potential of these hybrid interfaces for various applications.

Abstract: This study presents a comprehensive investigation of hybrid interfaces formed
by monolayer MoS$_2$ coupled with the organic molecules perylene (P), perylene
diimide (PDI), and perylene orange (PO). Using density functional theory, we
demonstrate the extent to which the mechanical and electronic properties of a
hybrid system can be altered by the chemical modification of a given
chromophore. The three systems exhibit distinct differences due to their
chemical composition and van der Waals contact enabled by their geometry. All
systems are structurally stable. The binding energies follow the order
PD$>$P$>$PO due to the large $\pi$-system (PD) and strong structural distortion
(PO). Young's modulus and Poisson's ratio exhibit pronounced anisotropy in all
cases. PO exhibits the greatest anisotropy due to steric effects and a
permanent dipole, which introduce directionality to the molecule-surface
interaction. Physisorption is accompanied by net charge transfer in the same
order as the binding energies. The associated interfacial polarization results
in a change in the work function compared to pristine MoS$_2$ in the order
P$>$PO$>$PD. Finally, the presence of organic molecules introduces states into
the MoS$_2$ energy gap, with the band alignment being either type II (P, PO) or
type I (PD).

</details>


### [259] [Molecular Beam Epitaxy of 2H-TaS$_2$ few-layers on GaN(0001)](https://arxiv.org/abs/2508.21537)
*Constantin Hilbrunner,Tobias Meyer,Joerg Malindretos,Angela Rizzi*

Main category: cond-mat.mtrl-sci

TL;DR: 摘要：在 GaN(0001) 上外延生长了 2H-TaS$_2$ 少层。


<details>
  <summary>Details</summary>
Motivation: 外延生长 2H-TaS$_2$ 少层在 GaN(0001) 衬底上，并研究其结构性质和界面特性。

Method: 通过原位电子衍射（RHEED和LEED）研究结构特性，通过扫描透射电子显微镜（STEM）研究界面形貌，通过原位X射线光电子能谱（XPS）研究界面电子转移和化学性质。

Result: 825$^{\circ}$C 的衬底生长温度可实现最佳的过层结构特性。2D-过层在沉积单层后未发生应变。STEM 观察到界面处存在 pits，可能由 GaN 在高温下的热分解引起。XPS 显示电子从 n-GaN(0001) 转移到 2H-TaS$_2$ 外延层，并在界面附近形成高浓度的氮空位。XPS 推断衬底和 TaS$_2$ 过层之间没有化学反应。

Conclusion: 2H-TaS$_2$ 可以与 GaN 集成。

Abstract: 2H-TaS$_2$ few layers have been grown epitaxially onto GaN(0001). A high
substrate growth temperature of 825$^{\circ}$C induces best structural
properties of the overlayer, as revealed by in-situ electron diffraction (RHEED
and LEED). The 2D-overlayer grows unstrained right after deposition of a
monolayer. However, evidence of pits at the interface is provided by scanning
transmission electron microscopy, most probably due to GaN thermal
decomposition at the high growth temperature. In-situ x-ray photoemission
spectroscopy shows core level shifts that are consistently related to electron
transfer from the n-GaN(0001) to the 2H-TaS$_2$ epitaxial layer as well as the
formation of a high concentration of nitrogen vacancies close to the interface.
Further, no chemical reaction at the interface between the substrate and the
grown TaS$_2$ overlayer is deduced from XPS, which corroborates the possibility
of integration of 2D 2H-TaS$_2$ with an important 3D semiconducting material
like GaN.

</details>


### [260] [Magneto-Excitonic Duality From Monolayer to Trilayer CrSBr](https://arxiv.org/abs/2508.21611)
*Igor Antoniazzi,Łucja Kipczak,Bruno Camargo,Gayatri,Chinmay Mohanty,Kseniia Mosina,Zdeněk Sofer,Adam Babiński,Arka Karmakar,Maciej R. Molas*

Main category: cond-mat.mtrl-sci

TL;DR: CrSBr是一种二维层状磁性材料，具有独特的双重激子行为（Frenkel和Wannier-Mott类激子），在不同层数的材料中表现出不同的特征，这为研究磁-激子耦合提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 研究空气稳定的磁性二维材料CrSBr的光物理性质，特别是其激子行为及其与磁性的耦合关系。

Method: 研究了单层到三层CrSBr的光致发光（PL）和PL激发光谱，并进行了磁光实验。

Result: CrSBr支持Frenkel和Wannier-Mott类激子。不同层数的CrSBr（单层、双层、三层）表现出不同的激子响应特征，表明其带结构中低能激子物种（A、A'和B）起源不同。磁-激子耦合在少层CrSBr中表现出鲁棒性。

Conclusion: CrSBr具有独特的双重激子行为，这为探索二维材料中的激子现象和磁-激子耦合提供了新的平台。

Abstract: Two-dimensional (2D) layered magnetic materials (LMMs) are a newly emerging
class of van der Waals materials, opening new opportunities to study
magneto-excitonic coupling. The air-stable, structurally and optically
anisotropic A-type antiferromagnetic chromium sulfur bromide (CrSBr) is one of
the most prominent examples of such LMMs. We investigate photoluminescence (PL)
and PL excitation of mono- to tri-layers CrSBr and find that it exhibits a
unique duplexity, supporting both Frenkel- and Wannier-Mott-like excitons. Our
magneto-optical experiments reveal a similar excitonic response from the mono-
and trilayer systems and a completely different signature in the bilayer flake.
This shows a different origin of the low-lying excitonic species (A, A', and B)
in the band structure. We confirm the robustness of the magneto-excitonic
coupling in few-layer CrSBr. Our work enables a more comprehensive exploration
of the dual excitonic behavior in 2D materials.

</details>


### [261] [Rapid heat assisted polarization reversal in ferroelectric thin films](https://arxiv.org/abs/2508.21612)
*Rekikua Alemayehu,Steffen Zeuschner,Alexander von Reppert,Matthias Roessle,Marin Alexe,Matias Bargheer*

Main category: cond-mat.mtrl-sci

TL;DR: 激光辅助加热可控制铁电薄膜的开关，类似于热辅助磁记录。


<details>
  <summary>Details</summary>
Motivation: 研究激光辅助加热对铁电薄膜开关行为的影响。

Method: 通过载体的电压脉冲和同步的 ns 激光脉冲来控制铁电薄膜的开关，并量化电切换剩余极化 $P_\mathrm{r}$。

Result: 300 ns 电压脉冲仅能改变极化 $< P_\mathrm{r}$，而瞬态加热可引起平均极化反转 $\Delta P^\mathrm{L}>P_\mathrm{r}$。

Conclusion: 激光辅助加热可以有效控制铁电薄膜的开关，并且与电脉冲的时间相对关系会影响极化变化。

Abstract: We demonstrate that switching of ferroelectric thin-films sandwiched between
metallic electrodes can be controlled by laser-assisted heating, reminiscent of
heat-assisted magnetic recording. We employ electrical switching cycles that
quantify the electrically switchable remanent polarization $P_\mathrm{r}$ and
show that 300\,ns voltage pulses alone change the polarization by less than
$\Delta P<P_\mathrm{r}$. Transient heating of the metallic top electrode by
synchronized ns laser-pulses induces a reversal $\Delta
P^\mathrm{L}>P_\mathrm{r}$ of the average polarization. The transient average
temperature modeled by the heat equation can rationalize the polarization
change observed for different relative timing $\Delta t$ of the laser pulse, if
it arrives before the electrical pulse.

</details>


### [262] [Scaling of the Electrical Conductivity Spectra Reveals Distinct Transport Responses in A2SmTaO6 [A = Ba, Sr, Ca]](https://arxiv.org/abs/2508.21621)
*Saswata Halder,Binita Ghosh,T. P. Sinha*

Main category: cond-mat.mtrl-sci

TL;DR: disorder in materials science affects properties by disrupting periodicity, leading to phenomena like electrical 'glassiness' in polycrystalline materials. Analyzing complex impedance, permittivity, and electric modulus in A2SmTaO6 perovskites shows that grain boundaries and frustrated dipoles influence carrier hopping and relaxation, revealing a correlation between conduction and relaxation timescales.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand the role of disorder in materials science, specifically how imperfections and microstructural inhomogeneities affect material behavior and physical properties, using electrical 'glassiness' in polycrystalline materials as a case study.

Method: The study analyzes complex impedance, permittivity, and electric modulus to distinguish resistive and capacitive effects. It investigates polycrystalline double perovskites A2SmTaO6 (A = Ba, Ca) with a power law driven ac conductivity, examining the influence of grains and grain boundaries on carrier hopping and relaxation through scaling of ac conductivity and impedance response.

Result: The analysis of A2SmTaO6 perovskites reveals that both grains and grain boundaries affect carrier hopping and relaxation. Scaling of ac conductivity and impedance response indicates a correlation between conduction and relaxation timescales. The inhomogeneities in the local energy landscape of 'frustrated' dipoles limit the universality of the conduction mechanism across the bulk length scale.

Conclusion: In polycrystalline double perovskites like A2SmTaO6, disorder, particularly in the form of frustrated dipoles and microstructural inhomogeneities, significantly impacts the conduction mechanism by affecting carrier hopping and relaxation processes, leading to a breakdown in the universality of conduction across different length scales.

Abstract: Disorder plays an important role in materials science, influencing material
behavior across different length scales. Imperfections like vacancies, atomic
substitutions, lattice distortions, and microstructural inhomogeneities,
disrupt ideal periodicity thereby altering physical properties. Analogous to
spin-glass systems, electrical 'glassiness' arises when charge carriers
confront disordered energy landscapes, leading to a broad range of relaxation
times, especially in polycrystalline materials where dipoles experience
competing exchange interactions. Complex impedance, permittivity, and electric
modulus distill out separate resistive and capacitive effects, offering
insights into how microstructural inhomogeneities affects conduction mechanism.
In polycrystalline double perovskites A2SmTaO6 (A = Ba, Ca), with a power law
driven ac conductivity, the hopping and relaxation of carriers is affected by
both grains and grain boundaries. Scaling of ac conductivity and impedance
response reveals correlation between conduction and relaxation timescales. The
inhomogeneities in local energy landscape of 'frustrated' dipoles restrict the
'universality' of conduction mechanism across the bulk length scale.

</details>


### [263] [Surface Stability Modeling with Universal Machine Learning Interatomic Potentials: A Comprehensive Cleavage Energy Benchmarking Study](https://arxiv.org/abs/2508.21663)
*Ardavan Mehdizadeh,Peter Schindler*

Main category: cond-mat.mtrl-sci

TL;DR: 文章对19种通用机器学习势能（uMLIPs）在预测金属材料解理能方面的表现进行了全面基准测试，强调了训练数据而非模型架构对预测精度的关键作用，并提出应专注于生成能捕捉相关物理现象的训练数据。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习势能（MLIPs）在预测材料的整体性质方面取得了巨大成功，但尚未有系统性评估来考察这些通用MLIPs（uMLIPs）预测解理能的能力，而解理能是控制断裂、催化、表面稳定性和界面现象的关键性质。

Method: 本文使用了一个包含36,718个金属化合物（元素、二元和三元）的密度泛函理论（DFT）计算数据库，对19种最先进的uMLIPs在解理能预测方面的表现进行了全面的基准测试，并分析了不同模型在化学成分、晶体系统、厚度和表面取向等方面的性能。

Result: 在OMat24数据集上训练的模型（该数据集包含非平衡态结构）在解理能预测方面的平均绝对百分比误差低于6%，并且在87%的情况下能正确识别最稳定的表面末端，而无需显式训练表面能。相比之下，仅用平衡态数据集训练的相同架构模型误差高出五倍，而使用表面-吸附质数据的模型性能则下降了17倍。此外，在合适数据上训练的简单模型可以达到与复杂Transformer模型相当的精度，同时计算速度快10-100倍。

Conclusion: 文章认为，训练数据的构成比模型架构的复杂性对uMLIPs预测解理能的精度更为重要，并建议机器学习势能研究应更侧重于生成能够捕捉相关物理现象的训练数据，而非过度追求模型本身的复杂性。

Abstract: Machine learning interatomic potentials (MLIPs) have revolutionized
computational materials science by bridging the gap between quantum mechanical
accuracy and classical simulation efficiency, enabling unprecedented
exploration of materials properties across the periodic table. Despite their
remarkable success in predicting bulk properties, no systematic evaluation has
assessed how well these universal MLIPs (uMLIPs) can predict cleavage energies,
a critical property governing fracture, catalysis, surface stability, and
interfacial phenomena. Here, we present a comprehensive benchmark of 19
state-of-the-art uMLIPs for cleavage energy prediction using our previously
established density functional theory (DFT) database of 36,718 slab structures
spanning elemental, binary, and ternary metallic compounds. We evaluate diverse
architectural paradigms, analyzing their performance across chemical
compositions, crystal systems, thickness, and surface orientations. Our results
reveal that training data composition dominates architectural sophistication:
models trained on the Open Materials 2024 (OMat24) dataset, which emphasizes
non-equilibrium configurations, achieve mean absolute percentage errors below
6% and correctly identify the thermodynamically most stable surface
terminations in 87% of cases, without any explicit surface energy training. In
contrast, architecturally identical models trained on equilibrium-only datasets
show five-fold higher errors, while models trained on surface-adsorbate data
fail catastrophically with a 17-fold degradation. Remarkably, simpler
architectures trained on appropriate data achieve comparable accuracy to
complex transformers while offering 10-100x computational speedup. These
findings show that the community should focus on strategic training data
generation that captures the relevant physical phenomena.

</details>


### [264] [Anomalous ultrafast heat transfer in single palladium nanocrystals seen with an X-ray free electron laser](https://arxiv.org/abs/2508.21670)
*David Yang,James Wrigley,Jack Griffiths,Longlong Wu,Ana F. Suzana,Jiecheng Diao,Angel Rodriguez-Fernandez,Joerg Hallmann,Alexey Zozulya,Ulrike Boesenberg,Roman Shayduk,Jan-Etienne Pudell,Anders Madsen,Ian K. Robinson*

Main category: cond-mat.mtrl-sci

TL;DR: 激光加热下钯纳米晶体在均匀热膨胀前出现高度应变的瞬态结构态，X射线自由电子激光探测揭示了应变异质性。


<details>
  <summary>Details</summary>
Motivation: 理解飞秒激光与金属的相互作用以及钯的光催化性能。

Method: 使用X射线自由电子激光探测，测量不同激光能量密度下111布拉格峰随延迟时间的变化，并与晶格位移和应变模型进行对比。

Result: 在激光能量密度阈值以上和足够延迟时间后，布拉格峰分裂成多个峰，表明存在非均匀应变，随后恢复为单个峰，表明热量均匀分布。

Conclusion: 飞秒激光加热会导致钯纳米晶体出现瞬态高度应变结构态，这对于理解激光-金属相互作用和钯的光催化性能具有重要意义。

Abstract: We report transient highly strained structural states in individual palladium
(Pd) nanocrystals, electronically heated using an optical laser, which precede
their uniform thermal expansion. Using an X-ray free-electron laser probe, the
evolution of individual 111 Bragg peaks is measured as a function of delay time
at various laser fluences. Above a laser fluence threshold at a sufficient
pump-probe delay, the Bragg peak splits into multiple peaks, indicating
heterogeneous strain, before returning to a single peak, corresponding to even
heat distribution throughout the lattice expanded crystal. Our findings are
supported by a lattice displacement and strain model of a single nanocrystal at
different delay times, which agrees with the experimental data. Our
observations have implications for understanding femtosecond laser interactions
with metals and the potential photo-catalytic performance of Pd.

</details>


### [265] [Investigation of structure and anisotropic electrical resistivity in single-crystalline CoSn kagome metal thin films for interconnect applications](https://arxiv.org/abs/2508.21711)
*Tomoya Nakatani,Nattamon Suwannaharn,Taisuke Sasaki*

Main category: cond-mat.mtrl-sci

TL;DR: CoSn作为一种准一维电子导体，在[0001]（c轴）方向上具有低电阻率，在其他晶向具有高电阻率。这种各向异性导电性有望用于先进半导体技术节点中的窄互连线。研究人员通过磁控溅射制备了CoSn薄膜，并研究了其电阻率各向异性。


<details>
  <summary>Details</summary>
Motivation: CoSn的各向异性导电性有望缓解未来互连线电阻率的增加，使其成为一种有潜力的互连应用材料。

Method: 通过磁控溅射制备CoSn薄膜，并在Ru(10-10)缓冲层上实现了CoSn(10-10)外延生长，研究了其电阻率各向异性。

Result: 在350°C以上沉积温度下，实现了CoSn(10-10)外延单晶薄膜的制备。CoSn薄膜沿[0001]方向的电阻率较低，达到13 μΩ·cm，且与[2-1-10]（a轴）方向相比，电阻率具有约十倍的各向异性。但CoSn(10-10)表面粗糙，阻碍了电阻率厚度依赖性的准确评估。扫描透射电子显微镜显示CoSn(10-10)单晶具有(11-20)和(01-10)侧壁以及晶内畴界。

Conclusion: CoSn薄膜在垂直于基底的方向上表现出良好的导电性，但在表面形貌和畴界控制方面仍存在挑战，这些是其在未来互连技术应用中需要克服的潜在问题。

Abstract: CoSn kagome metal is a pseudo-one-dimensional electronic conductor,
exhibiting low resistivity (\r{ho}) along the [0001] direction (c-axis) and
significantly higher \r{ho} along other crystallographic directions. Such
anisotropic conduction is expected to mitigate resistivity increases in narrow
interconnect wires at advanced semiconductor technology process nodes, making
CoSn a promising candidate for future interconnect applications. In this study,
CoSn thin films were fabricated by magnetron sputtering, and their resistivity
anisotropy was investigated with respect to crystallographic orientation.
Epitaxial growth of single-crystalline CoSn(10-10) films was achieved on a
Ru(10-10) buffer layer at deposition temperatures above 350 {\deg}C. The CoSn
films exhibited relatively low \r{ho} along [0001], reaching 13 micro{\Omega}
cm, and an approximately tenfold anisotropy of \r{ho} between [0001] and
[2-1-10] (a-axis), consistent with previous reports on bulk CoSn single
crystals. However, the CoSn(10-10) surface exhibited pronounced roughness,
attributed to three-dimensional crystal growth during sputtering, which hinders
accurate evaluation of the thickness dependence of resistivity. Scanning
transmission electron microscopy revealed the growth of a CoSn(10-10)
single-crystal with (11-20) and (01-10) side wall facets, as well as domain
boundaries within the films. These results highlight both the potential and
challenges of employing CoSn kagome metal in future interconnect technologies.

</details>


### [266] [Computational study of interactions between ionized glyphosate and carbon nanotube: An alternative for mitigating environmental contamination](https://arxiv.org/abs/2508.21734)
*H. T. Silva,L. C. S. Faria,T. A. Aversi-Ferreira,I. Camps*

Main category: cond-mat.mtrl-sci

TL;DR: Glyphosate interacts differently with carbon nanotubes (CNTs) based on its ionization state, with more charged states showing stronger adsorption. This suggests CNTs could be useful for glyphosate environmental monitoring and remediation.


<details>
  <summary>Details</summary>
Motivation: Investigate the interactions between glyphosate and single-walled carbon nanotubes (CNTs) to assess CNTs' potential for glyphosate environmental monitoring and remediation, given concerns about glyphosate's widespread agricultural use and adverse effects.

Method: Computational simulations using semi-empirical tight-binding methods (GFN2-xTB) with the xTB software were performed to analyze the interactions between different ionized states of glyphosate (G1-G5, representing various pH levels) and CNTs. Topological analysis and molecular dynamics were also used to confirm interaction types.

Result: Glyphosate in G1, G3, G4, and G5 forms showed stronger interactions with CNTs, evidenced by higher adsorption energies and electronic coupling. The neutral G2 state had lower affinity. Covalent, non-covalent, and partially covalent interactions were observed. The CNT+G5 system exhibited moderate interactions suitable for material recycling.

Conclusion: The ionization state of glyphosate significantly influences its adsorption onto CNTs, with charged states exhibiting stronger interactions. CNTs show potential for environmental monitoring and remediation of glyphosate contamination due to their properties and interaction capabilities with glyphosate.

Abstract: The extensive use of glyphosate in agriculture has raised environmental
concerns due to its adverse effects on plants, animals, microorganisms, and
humans. This study investigates the interactions between ionized glyphosate and
single-walled carbon nanotubes (CNT) using computational simulations through
semi-empirical tight-binding methods (GFN2-xTB) implemented in the xTB
software. The analysis focused on different glyphosate ionization states
corresponding to various pH levels: G1 (pH < 2), G2 (pH ~ 2-3), G3 (pH ~ 4-6),
G4 (pH ~ 7-10), and G5 (pH > 10.6). Results revealed that glyphosate in G1, G3,
G4, and G5 forms exhibited stronger interactions with CNT, demonstrating higher
adsorption energies and greater electronic coupling. The neutral state (G2)
showed lower affinity, indicating that molecular protonation significantly
influences adsorption. Topological analysis and molecular dynamics confirmed
the presence of covalent, non-covalent, and partially covalent interactions,
while the CNT+G5 system demonstrated moderate interactions suitable for
material recycling. These findings suggest that carbon nanotubes, with their
extraordinary properties such as nanocapillarity, porosity, and extensive
surface area, show promise for environmental monitoring and remediation of
glyphosate contamination.

</details>


### [267] [Magnetism Enhanced Surface Bonding of O$_{2}$ on CoPt](https://arxiv.org/abs/2508.21766)
*Kevin Allen,Christopher Lane,Emilia Morosan,Jian-Xin Zhu*

Main category: cond-mat.mtrl-sci

TL;DR: CoPt合金有望作为高性能、低铂催化剂用于氧还原反应，其铁磁性通过自旋极化增强了催化活性。


<details>
  <summary>Details</summary>
Motivation: 为了大规模部署和使用聚合物电解质燃料电池，需要低铂消耗的高性能电催化剂。因此，探索能够保持催化效率并引入新性能增强机制的替代材料具有重要意义。

Method: 利用密度泛函理论计算，研究了铁磁性CoPt合金作为加速氧还原反应的候选材料。

Result: 研究发现，自旋极化Co-d轨道通过费米能级的局域交换分裂增强了O2表面结合。此外，通过改变Pt层的厚度可以调节O和O2的吸附和离解能。

Conclusion: 该研究揭示了磁性在氧还原反应过程中的作用，并为设计新型先进催化剂提供了思路，即利用磁性离子来提高催化剂性能。

Abstract: For large-scale deployment and use of polymer electrolyte fuel cells,
high-performance electrocatalysts with low platinum consumption are desirable.
One promising strategy to meet this demand is to explore alternative materials
that retain catalytic efficiency while introducing new mechanisms for
performance enhacement. In this study, we investigate a ferromagnetic CoPt as a
candidate material to accelerate oxygen reduction reactions. By using density
functional theory calculations, we find the spin-polarized Co-$d$ states to
enhance O$_2$ surface bonding due to local exchange splitting of Co-$d$
carriers at the Fermi level. Furthermore, O and O$_2$ adsorption and
dissociation energies are found to be tuned by varying the thickness of the Pt
layers. Our study gives insight into the role magnetism plays in the oxygen
reduction reaction process and how magnetic ions may aid in the design of new
advanced catalysts.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [268] [Interpolation for Converse PDL](https://arxiv.org/abs/2508.21485)
*Johannes Kloibhofer,Valentina Trucco Dalmas,Yde Venema*

Main category: cs.LO

TL;DR: Converse PDL 具有 Craig 插值属性和 Beth 可定义性属性。


<details>
  <summary>Details</summary>
Motivation: 研究 Converse PDL 的 Craig 插值属性和 Beth 可定义性属性。

Method: 使用 Maehara 的证明论方法，引入了一个适用于 Converse PDL 的 G=GP 的循环序列系统，该系统具有分析切割规则和焦点机制。

Result: 证明了 Converse PDL 具有（局部）Craig 插值属性，并以此为推论确立了 Beth 可定义性属性。

Conclusion: Converse PDL 具有 Craig 插值属性和 Beth 可定义性属性。

Abstract: Converse PDL is the extension of propositional dynamic logic with a converse
operation on programs. Our main result states that Converse PDL enjoys the
(local) Craig Interpolation Property, with respect to both atomic programs and
propositional variables. As a corollary we establish the Beth Definability
Property for the logic.
  Our interpolation proof is based on an adaptation of Maehara's
proof-theoretic method. For this purpose we introduce a sound and complete
cyclic sequent system for this logic. This calculus features an analytic cut
rule and uses a focus mechanism for recognising successful cycles.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [269] [EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](https://arxiv.org/abs/2508.21112)
*Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang*

Main category: cs.RO

TL;DR: EO-Robotics是一个统一的具身基础模型，通过交错的视觉-文本-动作预训练，在多模态具身推理和机器人控制方面取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作（VLA）模型在开放世界环境中实现类人灵活性方面的不足，特别是在交错推理和交互方面。

Method: 提出EO-1模型和EO-Data1.5M数据集。EO-1采用统一架构处理多模态输入（图像、文本、视频、动作），并通过自回归解码和流匹配去噪在EO-Data1.5M数据集上进行训练。EO-Data1.5M包含超过150万个样本，侧重于交错的视觉-文本-动作理解。

Result: EO-1在多项长期、灵巧的操作任务中展示了交错视觉-文本-动作学习在开放世界理解和泛化方面的有效性。

Conclusion: 交错视觉-文本-动作学习对于开发先进的具身基础模型至关重要，EO-1和EO-Data1.5M为该领域提供了有价值的见解。

Abstract: The human ability to seamlessly perform multimodal reasoning and physical
interaction in the open world is a core goal for general-purpose embodied
intelligent systems. Recent vision-language-action (VLA) models, which are
co-trained on large-scale robot and visual-text data, have demonstrated notable
progress in general robot control. However, they still fail to achieve
human-level flexibility in interleaved reasoning and interaction. In this work,
introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is
a unified embodied foundation model that achieves superior performance in
multimodal embodied reasoning and robot control through interleaved
vision-text-action pre-training. The development of EO-1 is based on two key
pillars: (i) a unified architecture that processes multimodal inputs
indiscriminately (image, text, video, and action), and (ii) a massive,
high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains
over 1.5 million samples with emphasis on interleaved vision-text-action
comprehension. EO-1 is trained through synergies between auto-regressive
decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot
action generation and multimodal embodied reasoning. Extensive experiments
demonstrate the effectiveness of interleaved vision-text-action learning for
open-world understanding and generalization, validated through a variety of
long-horizon, dexterous manipulation tasks across multiple embodiments. This
paper details the architecture of EO-1, the data construction strategy of
EO-Data1.5M, and the training methodology, offering valuable insights for
developing advanced embodied foundation models.

</details>


### [270] [Observer Design for Optical Flow-Based Visual-Inertial Odometry with Almost-Global Convergence](https://arxiv.org/abs/2508.21163)
*Tarek Bouazza,Soulaimane Berkane,Minh-Duc Hua,Tarek Hamel*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的级联观察器结构，结合了光流和IMU测量，以执行连续的单目视觉-惯性测距（VIO）。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够同时估计身体框架速度和重力方向的连续单目视觉-惯性测距（VIO）系统。

Method: 通过融合来自光流测量和陀螺仪/加速度计数据的速度方向信息，使用全局指数稳定的Riccati观察器来估计身体框架速度和重力方向。然后，将估计出的身体框架重力方向与可选的磁力计测量相结合，设计一个在SO(3)上的互补观察器来进行姿态估计。还开发了一种梯度下降算法来解决单位球上的约束最小化问题，以从稀疏光流数据中提取速度方向。

Result: 仿真结果验证了所提出的算法的有效性。

Conclusion: 提出的级联观察器结构通过融合光流和IMU测量，能够有效地进行连续单目视觉-惯性测距，并实现了身体框架速度和重力方向的同步估计。

Abstract: This paper presents a novel cascaded observer architecture that combines
optical flow and IMU measurements to perform continuous monocular
visual-inertial odometry (VIO). The proposed solution estimates body-frame
velocity and gravity direction simultaneously by fusing velocity direction
information from optical flow measurements with gyro and accelerometer data.
This fusion is achieved using a globally exponentially stable Riccati observer,
which operates under persistently exciting translational motion conditions. The
estimated gravity direction in the body frame is then employed, along with an
optional magnetometer measurement, to design a complementary observer on
$\mathbf{SO}(3)$ for attitude estimation. The resulting interconnected observer
architecture is shown to be almost globally asymptotically stable. To extract
the velocity direction from sparse optical flow data, a gradient descent
algorithm is developed to solve a constrained minimization problem on the unit
sphere. The effectiveness of the proposed algorithms is validated through
simulation results.

</details>


### [271] [Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)](https://arxiv.org/abs/2508.21205)
*Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: 提出一种基于最优输运理论和模型预测控制的多机器人路径规划与调度新方法，该方法能为N个机器人规划到M个目标的无重叠最优路径，并能通过模型预测控制处理可能重叠的轨迹和机器人动力学。


<details>
  <summary>Details</summary>
Motivation: 在多机器人导航中，先映射机器人到目标再规划路径可能导致路径重叠和死锁，因此需要一种能提供最小成本且保证非重叠轨迹的策略。

Method: 将空间离散化为K个单元格，构建KxK的转移成本结构，利用最优输运理论找到最优且不重叠的单元格转移方案；结合模型预测控制和“replans”以处理可能重叠的轨迹和机器人动力学。

Result: 最优输运方法能提供最小成本的非重叠路径，计算复杂度在最坏情况下为O(K^3 log K)，在表现良好的问题中为O(K^2 log K)。

Conclusion: 该方法通过最优输运和模型预测控制，有效解决了多机器人导航中的路径规划和调度问题，实现了最优、非重叠的路径，并能适应复杂的动态环境。

Abstract: In this paper, we propose a novel methodology for path planning and
scheduling for multi-robot navigation that is based on optimal transport theory
and model predictive control. We consider a setup where $N$ robots are tasked
to navigate to $M$ targets in a common space with obstacles. Mapping robots to
targets first and then planning paths can result in overlapping paths that lead
to deadlocks. We derive a strategy based on optimal transport that not only
provides minimum cost paths from robots to targets but also guarantees
non-overlapping trajectories. We achieve this by discretizing the space of
interest into $K$ cells and by imposing a ${K\times K}$ cost structure that
describes the cost of transitioning from one cell to another. Optimal transport
then provides \textit{optimal and non-overlapping} cell transitions for the
robots to reach the targets that can be readily deployed without any scheduling
considerations. The proposed solution requires $\unicode{x1D4AA}(K^3\log K)$
computations in the worst-case and $\unicode{x1D4AA}(K^2\log K)$ for
well-behaved problems. To further accommodate potentially overlapping
trajectories (unavoidable in certain situations) as well as robot dynamics, we
show that a temporal structure can be integrated into optimal transport with
the help of \textit{replans} and \textit{model predictive control}.

</details>


### [272] [Uncertainty-Aware Ankle Exoskeleton Control](https://arxiv.org/abs/2508.21221)
*Fatima Mumtaza Tourk,Bishoy Galoaa,Sanat Shajan,Aaron J. Young,Michael Everett,Max K. Shepherd*

Main category: cs.RO

TL;DR: 该研究提出了一种不确定性感知控制框架，使下肢外骨合能够安全地应对各种场景，在遇到不熟悉的运动时自动解除辅助。该框架使用不确定性估计器将运动分类为与训练集中的动作相似（分布内）或不同（分布外）。研究评估了三种架构（模型集成、自动编码器和生成对抗网络），并在线测试了性能最佳的架构（步态相位估计集成）。在线测试表明，该不确定性估计器能够在用户从分布内任务过渡到分布外任务时开启和关闭辅助（F1分数：89.2）。该框架为外骨合在非结构化、日常环境中安全自主地支持人类运动提供了途径。


<details>
  <summary>Details</summary>
Motivation: 现有下肢外骨合的控制器主要针对受控环境中离散、预定义的动作进行设计，这限制了它们在真实世界中的应用。本研究旨在解决这一局限性，使外骨合能够在多样化的场景中安全运行。

Method: 提出了一种不确定性感知控制框架，利用不确定性估计器将运动分类为分布内（与训练数据相似）或分布外（与训练数据不同）。研究评估了三种架构：模型集成、自动编码器和生成对抗网络。其中，步态相位估计集成在离线数据集上表现最佳，并在在线测试中进行了验证。

Result: 在线测试结果显示，该不确定性估计器能够准确地识别用户在分布内和分布外任务之间的转换，并相应地开启或关闭辅助功能，F1分数达到89.2%。

Conclusion: 该不确定性感知控制框架能够使踝部外骨合在遇到不熟悉的动作时自动解除辅助，从而在非结构化的日常环境中安全、自主地支持人类运动。

Abstract: Lower limb exoskeletons show promise to assist human movement, but their
utility is limited by controllers designed for discrete, predefined actions in
controlled environments, restricting their real-world applicability. We present
an uncertainty-aware control framework that enables ankle exoskeletons to
operate safely across diverse scenarios by automatically disengaging when
encountering unfamiliar movements. Our approach uses an uncertainty estimator
to classify movements as similar (in-distribution) or different
(out-of-distribution) relative to actions in the training set. We evaluated
three architectures (model ensembles, autoencoders, and generative adversarial
networks) on an offline dataset and tested the strongest performing
architecture (ensemble of gait phase estimators) online. The online test
demonstrated the ability of our uncertainty estimator to turn assistance on and
off as the user transitioned between in-distribution and out-of-distribution
tasks (F1: 89.2). This new framework provides a path for exoskeletons to safely
and autonomously support human movement in unstructured, everyday environments.

</details>


### [273] [Remarks on stochastic cloning and delayed-state filtering](https://arxiv.org/abs/2508.21260)
*Tara Mina,Lindsey Marinello,John Christian*

Main category: cs.RO

TL;DR: 本论文提出了一种不要求状态扩展的延迟状态卡尔曼滤波器，其更新结果与随机克隆（SC）相同，但计算和内存效率更高。


<details>
  <summary>Details</summary>
Motivation: 机器人和导航中的估计问题常涉及依赖于先前状态的测量，如里程计，这需要捕捉测量值与先验状态估计的相关性。随机克隆（SC）是处理此问题的常用方法，它通过扩展状态向量来处理相关性。

Method: 本文重新审视了延迟状态卡尔曼滤波器，并证明了正确推导的滤波器能产生与SC完全相同的状态和协方差更新，而无需状态扩展。此外，广义卡尔曼滤波器公式在计算上更具优势，并能减少高维状态的内存需求。

Result: 与SC相比，本文提出的延迟状态卡尔曼滤波器在保持相同更新结果的同时，提供了计算优势并减少了内存需求。

Conclusion: 卡尔曼滤波器变体并非不能处理相关的延迟状态测量，只是存在一种替代的、更有效的公式。

Abstract: Many estimation problems in robotics and navigation involve measurements that
depend on prior states. A prominent example is odometry, which measures the
relative change between states over time. Accurately handling these
delayed-state measurements requires capturing their correlations with prior
state estimates, and a widely used approach is stochastic cloning (SC), which
augments the state vector to account for these correlations.
  This work revisits a long-established but often overlooked alternative--the
delayed-state Kalman filter--and demonstrates that a properly derived filter
yields exactly the same state and covariance update as SC, without requiring
state augmentation. Moreover, the generalized Kalman filter formulation
provides computational advantages, while also reducing memory requirements for
higher-dimensional states.
  Our findings clarify a common misconception that Kalman filter variants are
inherently unable to handle correlated delayed-state measurements,
demonstrating that an alternative formulation achieves the same results more
efficiently.

</details>


### [274] [Mini Autonomous Car Driving based on 3D Convolutional Neural Networks](https://arxiv.org/abs/2508.21271)
*Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando*

Main category: cs.RO

TL;DR: 该研究提出了一种基于RGB-D信息和3D CNN的MAC自动驾驶方法，并在模拟环境中与RNN进行了性能比较，结果显示3D CNN在模型泛化能力和车辆控制性能方面表现出潜力。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车在安全、效率和用户体验方面的潜力日益显现，其发展也面临着复杂性高、训练周期长和不确定性等挑战。MAC作为一种实用的测试平台，能够简化和加速对自动驾驶控制方法学的评估，尤其适用于需要在线训练的算法。

Method: 提出了一种基于RGB-D信息和3D卷积神经网络（3D CNN）的MAC自动驾驶方法，并在模拟环境中进行评估，将其与循环神经网络（RNN）进行了比较。

Result: 评估结果显示，与RNN相比，所提出的3D CNN方法在任务完成成功率、单圈时间和驾驶一致性方面表现出有前景的结果，并且模型架构的修改和赛道的复杂性会影响模型的泛化能力和车辆控制性能。

Conclusion: 在模拟环境中，基于RGB-D信息和3D CNN的MAC自动驾驶方法相较于RNN，在模型泛化能力和车辆控制性能方面显示出潜力。

Abstract: Autonomous driving applications have become increasingly relevant in the
automotive industry due to their potential to enhance vehicle safety,
efficiency, and user experience, thereby meeting the growing demand for
sophisticated driving assistance features. However, the development of reliable
and trustworthy autonomous systems poses challenges such as high complexity,
prolonged training periods, and intrinsic levels of uncertainty. Mini
Autonomous Cars (MACs) are used as a practical testbed, enabling validation of
autonomous control methodologies on small-scale setups. This simplified and
cost-effective environment facilitates rapid evaluation and comparison of
machine learning models, which is particularly useful for algorithms requiring
online training. To address these challenges, this work presents a methodology
based on RGB-D information and three-dimensional convolutional neural networks
(3D CNNs) for MAC autonomous driving in simulated environments. We evaluate the
proposed approach against recurrent neural networks (RNNs), with architectures
trained and tested on two simulated tracks with distinct environmental
features. Performance was assessed using task completion success, lap-time
metrics, and driving consistency. Results highlight how architectural
modifications and track complexity influence the models' generalization
capability and vehicle control performance. The proposed 3D CNN demonstrated
promising results when compared with RNNs.

</details>


### [275] [Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609](https://arxiv.org/abs/2508.21272)
*Jaehong Oh,Seungjun Jung,Sawoong Kim*

Main category: cs.RO

TL;DR: 该研究首次将法律动作掩蔽深度Q网络与安全ZYZ抓取策略应用于欠驱动夹爪6自由度协作机器人，实现了自主索玛方块组装学习。通过将约束感知强化学习与奇点安全运动规划相结合，有效解决了组合动作空间爆炸、运动规划不安全和系统化组装策略学习等机器人操作中的关键挑战。该方法将Q函数估计分解为方向和位置分量，将计算复杂度从O(3,132)降低到O(116) + O(27)，同时保持了解决方案的完整性。机器人友好的奖励函数促进了符合操作约束的“先地面、后垂直可及”的组装序列。通过三个难度递增的阶段（2块、3块、7块）进行课程学习，实现了显著的训练效率：第一阶段在500次试验内达到100%成功率，第二阶段达到92.9%，第三阶段在总计105,300次训练试验中达到39.9%的成功率。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决机器人操作中的关键挑战，包括组合动作空间爆炸、不安全的运动规划以及系统化的组装策略学习，具体应用是利用欠驱动夹爪的6自由度协作机器人进行自主索玛方块组装学习。

Method: 该研究提出了一种结合法律动作掩蔽深度Q网络（DQN）和安全ZYZ抓取策略的方法。该系统采用分层架构，将Q函数估计分解为方向和位置两个部分，从而降低了计算复杂度。同时，该方法集成了约束感知强化学习和奇点安全运动规划，并设计了机器人友好的奖励函数以促进特定的组装序列。

Result: 该研究通过课程学习，在三个难度级别（2块、3块、7块）上取得了显著的训练效率和成功率：第一阶段（2块）在500次试验内成功率达到100%；第二阶段（3块）成功率达到92.9%；第三阶段（7块）在总计105,300次试验中成功率达到39.9%。

Conclusion: 该研究成功地将法律动作掩蔽DQN与安全ZYZ抓取策略应用于协作机器人进行索玛方块组装学习，有效解决了机器人操作中的关键挑战，并通过课程学习实现了高效的训练和可观的成功率。

Abstract: This paper presents the first comprehensive application of legal-action
masked Deep Q-Networks with safe ZYZ regrasp strategies to an underactuated
gripper-equipped 6-DOF collaborative robot for autonomous Soma cube assembly
learning. Our approach represents the first systematic integration of
constraint-aware reinforcement learning with singularity-safe motion planning
on a Doosan M0609 collaborative robot. We address critical challenges in
robotic manipulation: combinatorial action space explosion, unsafe motion
planning, and systematic assembly strategy learning. Our system integrates a
legal-action masked DQN with hierarchical architecture that decomposes
Q-function estimation into orientation and position components, reducing
computational complexity from $O(3,132)$ to $O(116) + O(27)$ while maintaining
solution completeness. The robot-friendly reward function encourages
ground-first, vertically accessible assembly sequences aligned with
manipulation constraints. Curriculum learning across three progressive
difficulty levels (2-piece, 3-piece, 7-piece) achieves remarkable training
efficiency: 100\% success rate for Level 1 within 500 episodes, 92.9\% for
Level 2, and 39.9\% for Level 3 over 105,300 total training episodes.

</details>


### [276] [Observability-driven Assignment of Heterogeneous Sensors for Multi-Target Tracking](https://arxiv.org/abs/2508.21309)
*Seyed Ali Rakhshan,Mehdi Golestani,He Kong*

Main category: cs.RO

TL;DR: 该论文提出了一种利用匹配论的贪心算法，用于将具有不同传感能力的机器人分配给多个目标进行跟踪，以优化跟踪质量并最小化目标状态估计的不确定性。该算法在任意跟踪质量函数上提供1/3的常数因子近似界，在子模函数上提供1/2的近似界，并具有多项式时间复杂度。仿真结果表明该算法在长期跟踪和目标状态估计方面表现优异，接近最优分配性能。


<details>
  <summary>Details</summary>
Motivation: 优化多目标跟踪中的机器人分配问题，以最小化目标状态估计的不确定性，提升跟踪质量。

Method: 提出一种基于匹配论的贪心分配算法，动态分配具有不同传感能力的机器人（足够感知能力或有限感知能力）给目标，以最大化跟踪质量。

Result: 该算法在任意跟踪质量函数上提供1/3的常数因子近似界，在子模函数上提供1/2的近似界，并具有多项式时间复杂度。仿真结果表明该算法在长期跟踪和目标状态估计方面表现优异，接近最优分配性能。

Conclusion: 所提出的贪心分配算法能够有效地优化机器人到目标的分配，以提高多目标跟踪的质量，并证明了其在理论上的近似界和实际应用中的有效性。

Abstract: This paper addresses the challenge of assigning heterogeneous sensors (i.e.,
robots with varying sensing capabilities) for multi-target tracking. We
classify robots into two categories: (1) sufficient sensing robots, equipped
with range and bearing sensors, capable of independently tracking targets, and
(2) limited sensing robots, which are equipped with only range or bearing
sensors and need to at least form a pair to collaboratively track a target. Our
objective is to optimize tracking quality by minimizing uncertainty in target
state estimation through efficient robot-to-target assignment. By leveraging
matroid theory, we propose a greedy assignment algorithm that dynamically
allocates robots to targets to maximize tracking quality. The algorithm
guarantees constant-factor approximation bounds of 1/3 for arbitrary tracking
quality functions and 1/2 for submodular functions, while maintaining
polynomial-time complexity. Extensive simulations demonstrate the algorithm's
effectiveness in accurately estimating and tracking targets over extended
periods. Furthermore, numerical results confirm that the algorithm's
performance is close to that of the optimal assignment, highlighting its
robustness and practical applicability.

</details>


### [277] [Robust Real-Time Coordination of CAVs: A Distributed Optimization Framework under Uncertainty](https://arxiv.org/abs/2508.21322)
*Haojie Bai,Yang Wang,Cong Guo,Xiongwei Zhao,Hai Zhu*

Main category: cs.RO

TL;DR: 本论文提出了一种新的车辆协调框架，通过直接控制轨迹分布、并行ADMM算法和交互式注意力机制，在保证安全性的同时实现了实时性能，并在仿真和实际实验中均表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 在动态和不确定的环境中，同时实现合作车辆协调的安全保证和实时性能是一个基本挑战。

Method: 1) 将协调问题制定为鲁棒的合作规划问题，具有自适应增强的安全约束，直接控制车辆的轨迹分布。 2) 提出一种完全并行的基于ADMM的分布式轨迹协商（ADMM-DTN）算法。 3) 引入交互式注意力机制以选择性地关注关键的交互参与者。

Result: 与现有方法相比，本框架在安全性（碰撞率降低高达40.79%）和实时性能方面取得了显著优势，同时保持了良好的可扩展性。交互式注意力机制进一步降低了14.1%的计算需求。

Conclusion: 该框架在仿真和实际实验中都得到了验证，证明了其在复杂环境中鲁棒协调的能力。

Abstract: Achieving both safety guarantees and real-time performance in cooperative
vehicle coordination remains a fundamental challenge, particularly in dynamic
and uncertain environments. This paper presents a novel coordination framework
that resolves this challenge through three key innovations: 1) direct control
of vehicles' trajectory distributions during coordination, formulated as a
robust cooperative planning problem with adaptive enhanced safety constraints,
ensuring a specified level of safety regarding the uncertainty of the
interactive trajectory, 2) a fully parallel ADMM-based distributed trajectory
negotiation (ADMM-DTN) algorithm that efficiently solves the optimization
problem while allowing configurable negotiation rounds to balance solution
quality and computational resources, and 3) an interactive attention mechanism
that selectively focuses on critical interactive participants to further
enhance computational efficiency. Both simulation results and practical
experiments demonstrate that our framework achieves significant advantages in
safety (reducing collision rates by up to 40.79\% in various scenarios) and
real-time performance compared to state-of-the-art methods, while maintaining
strong scalability with increasing vehicle numbers. The proposed interactive
attention mechanism further reduces the computational demand by 14.1\%. The
framework's effectiveness is further validated through real-world experiments
with unexpected dynamic obstacles, demonstrating robust coordination in complex
environments. The experiment demo could be found at
https://youtu.be/4PZwBnCsb6Q.

</details>


### [278] [Multi-Modal Model Predictive Path Integral Control for Collision Avoidance](https://arxiv.org/abs/2508.21364)
*Alberto Bertipaglia,Dariu M. Gavrila,Barys Shyrokau*

Main category: cs.RO

TL;DR: 提出了一种新颖的运动规划和决策方法，使用多模态模型预测路径积分控制算法，通过 Sobol 序列采样并结合解析碰撞避免方法，并通过探索多种轨迹（如避开障碍物或安全停车）来减轻次优解的风险。该方法使用非线性单轨车辆模型和 Fiala 轮胎模型，并在摩擦圆内强制执行轮胎力约束以确保车辆稳定性。通过高保真仿真，证明了该算法在不同路面和障碍物场景下优于标准方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶车辆在运动规划和决策方面的挑战，特别是为了提高避障和轨迹规划的性能，并降低次优解的风险。

Method: 采用多模态模型预测路径积分（MPPI）控制算法，通过 Sobol 序列围绕先验输入进行采样，并结合解析方法来解决碰撞避免问题。使用非线性单轨车辆模型和 Fiala 轮胎模型作为预测模型，并在摩擦圆内施加轮胎力约束，以确保车辆在进行规避机动时的稳定性。

Result: 所提出的算法在仿真环境中成功地实现了障碍物规避，并保持了车辆的稳定性。在进行双车道变换机动时，无论是在高摩擦还是低摩擦路面上，以及在有移动障碍物的遮挡场景下，该算法的表现均优于标准的 MPPI 方法。

Conclusion: 该研究提出了一种多模态模型预测路径积分控制算法，能够有效地处理自动驾驶车辆的运动规划和决策问题，尤其在避障和维持稳定性方面表现出色，并优于传统方法。

Abstract: This paper proposes a novel approach to motion planning and decision-making
for automated vehicles, using a multi-modal Model Predictive Path Integral
control algorithm. The method samples with Sobol sequences around the prior
input and incorporates analytical solutions for collision avoidance. By
leveraging multiple modes, the multi-modal control algorithm explores diverse
trajectories, such as manoeuvring around obstacles or stopping safely before
them, mitigating the risk of sub-optimal solutions. A non-linear single-track
vehicle model with a Fiala tyre serves as the prediction model, and tyre force
constraints within the friction circle are enforced to ensure vehicle stability
during evasive manoeuvres. The optimised steering angle and longitudinal
acceleration are computed to generate a collision-free trajectory and to
control the vehicle. In a high-fidelity simulation environment, we demonstrate
that the proposed algorithm can successfully avoid obstacles, keeping the
vehicle stable while driving a double lane change manoeuvre on high and
low-friction road surfaces and occlusion scenarios with moving obstacles,
outperforming a standard Model Predictive Path Integral approach.

</details>


### [279] [Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation](https://arxiv.org/abs/2508.21375)
*Anuj Pasricha,Joewie Koh,Jay Vakil,Alessandro Roncone*

Main category: cs.RO

TL;DR: 机器人标称负载能力被低估，可安全处理远超标称值的负载。本文提出一种基于去噪扩散模型的轨迹生成方法，可在规划中显式考虑负载约束，生成高效、可执行的轨迹。实验验证表明，该方法可显著扩展机器人的工作空间。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人标称负载能力评估方法过于保守，导致在大部分工作空间内机器人能力被严重低估。然而，机器人实际上可以在许多工作空间区域内安全地处理远超标称值的负载，同时满足关节限制。为了弥合标称能力与实际能力之间的差距，需要一种新的方法来解决此问题。

Method: 提出一种新颖的轨迹生成方法，利用去噪扩散模型，并将负载约束显式地纳入规划过程。该方法与传统的基于采样的方法（效率低下）、基于优化的方法（速度慢）或动力学规划器（难以处理高维度问题）不同，它能在恒定的时间内生成可直接在物理硬件上执行而无需后处理的、动力学上可行的关节空间轨迹。

Result: 在7自由度Franka Emika Panda机器人上进行的实验验证表明，即使负载超过标称容量的3倍，仍有高达67.6%的工作空间可用。这表明该方法能够显著扩展机器人的操作范围。

Conclusion: 现有方法在机器人运动规划中对负载动态的考虑不够细致，导致机器人能力被低估。本文提出的基于去噪扩散模型的轨迹生成方法，能够显式地将负载约束纳入规划过程，显著扩展了机器人的工作空间，证明了在运动规划算法中更细致地考虑负载动态的重要性。

Abstract: Nominal payload ratings for articulated robots are typically derived from
worst-case configurations, resulting in uniform payload constraints across the
entire workspace. This conservative approach severely underutilizes the robot's
inherent capabilities -- our analysis demonstrates that manipulators can safely
handle payloads well above nominal capacity across broad regions of their
workspace while staying within joint angle, velocity, acceleration, and torque
limits. To address this gap between assumed and actual capability, we propose a
novel trajectory generation approach using denoising diffusion models that
explicitly incorporates payload constraints into the planning process. Unlike
traditional sampling-based methods that rely on inefficient trial-and-error,
optimization-based methods that are prohibitively slow, or kinodynamic planners
that struggle with problem dimensionality, our approach generates dynamically
feasible joint-space trajectories in constant time that can be directly
executed on physical hardware without post-processing. Experimental validation
on a 7 DoF Franka Emika Panda robot demonstrates that up to 67.6% of the
workspace remains accessible even with payloads exceeding 3 times the nominal
capacity. This expanded operational envelope highlights the importance of a
more nuanced consideration of payload dynamics in motion planning algorithms.

</details>


### [280] [RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation](https://arxiv.org/abs/2508.21378)
*Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu*

Main category: cs.RO

TL;DR: LLM在机器人操作中生成策略代码存在不可靠性，RoboInspector管道通过分析任务复杂性和指令粒度来揭示和表征这种不可靠性，并提出一种基于失败策略代码反馈的改进方法，可将可靠性提高高达35%。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在生成用于机器人操作的策略代码时存在的不可靠性问题，该研究旨在揭示和表征这种不可靠性。

Method: 设计了一个名为RoboInspector的管道，从任务复杂性和指令粒度两个角度来分析LLM生成策略代码的不可靠性，并通过实验验证其有效性，同时提出一种基于失败策略代码反馈的改进方法。

Result: 实验识别出四种主要的导致操作失败的不可靠行为，并对其进行了详细表征和原因分析。所提出的改进方法将策略代码生成的可靠性提高了高达35%。

Conclusion: RoboInspector管道能够有效地揭示和表征LLM在机器人操作中策略代码生成方面的不可靠性，所提出的改进方法能够显著提高生成策略代码的可靠性，为实际应用提供了有价值的见解。

Abstract: Large language models (LLMs) demonstrate remarkable capabilities in reasoning
and code generation, enabling robotic manipulation to be initiated with just a
single instruction. The LLM carries out various tasks by generating policy code
required to control the robot. Despite advances in LLMs, achieving reliable
policy code generation remains a significant challenge due to the diverse
requirements of real-world tasks and the inherent complexity of user
instructions. In practice, different users may provide distinct instructions to
drive the robot for the same task, which may cause the unreliability of policy
code generation. To bridge this gap, we design RoboInspector, a pipeline to
unveil and characterize the unreliability of the policy code for LLM-enabled
robotic manipulation from two perspectives: the complexity of the manipulation
task and the granularity of the instruction. We perform comprehensive
experiments with 168 distinct combinations of tasks, instructions, and LLMs in
two prominent frameworks. The RoboInspector identifies four main unreliable
behaviors that lead to manipulation failure. We provide a detailed
characterization of these behaviors and their underlying causes, giving insight
for practical development to reduce unreliability. Furthermore, we introduce a
refinement approach guided by failure policy code feedback that improves the
reliability of policy code generation by up to 35% in LLM-enabled robotic
manipulation, evaluated in both simulation and real-world environments.

</details>


### [281] [Assessing Human Cooperation for Enhancing Social Robot Navigation](https://arxiv.org/abs/2508.21455)
*Hariharan Arunachalam,Phani Teja Singamaneni,Rachid Alami*

Main category: cs.RO

TL;DR: 机器人导航结合了社交约束和人类预测，但未能解决人类行为意外和沟通不足的问题。本研究通过几何分析和合作评估来解决这些问题，旨在通过沟通改善人机交互。


<details>
  <summary>Details</summary>
Motivation: 机器人导航在人类环境中面临挑战，尤其是在人类行为意外或缺乏沟通的情况下。本研究旨在弥合这一差距，通过有效的沟通和对人类意图及合作性的理解来改善机器人行为。

Method: 通过几何分析人类合作性，提出评估方法和指标来区分合作与非合作人类，并利用几何推理生成适当的语言回应或机器人动作。

Result: 提出了一种评估方法和一些评估指标，能够区分合作与非合作的人类，并展示了如何利用几何推理来生成适当的语言回应或机器人动作。

Conclusion: 通过在关键时刻基于几何分析和人类合作性进行有效沟通，可以改善机器人在与人类交互时的导航行为，尤其是在冲突场景下。

Abstract: Socially aware robot navigation is a planning paradigm where the robot
navigates in human environments and tries to adhere to social constraints while
interacting with the humans in the scene. These navigation strategies were
further improved using human prediction models, where the robot takes the
potential future trajectory of humans while computing its own. Though these
strategies significantly improve the robot's behavior, it faces difficulties
from time to time when the human behaves in an unexpected manner. This happens
as the robot fails to understand human intentions and cooperativeness, and the
human does not have a clear idea of what the robot is planning to do. In this
paper, we aim to address this gap through effective communication at an
appropriate time based on a geometric analysis of the context and human
cooperativeness in head-on crossing scenarios. We provide an assessment
methodology and propose some evaluation metrics that could distinguish a
cooperative human from a non-cooperative one. Further, we also show how
geometric reasoning can be used to generate appropriate verbal responses or
robot actions.

</details>


### [282] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: QuadKAN结合本体感觉和视觉信息，使用KANs和样条参数化策略，在机器人步态控制中实现了高效、鲁棒和可解释的运动。


<details>
  <summary>Details</summary>
Motivation: 为了实现更稳定、更高效的机器人运动控制，尤其是在视觉引导的场景下，需要结合本体感觉和视觉信息。

Method: 提出了一种名为QuadKAN的框架，该框架使用样条参数化的Kolmogorov-Arnold Networks（KANs）作为策略。该框架包含一个用于本体感觉的样条编码器和一个用于融合本体感觉和视觉输入的样条融合头。训练方法采用了多模态延迟随机化（MMDR）和近端策略优化（PPO）。

Result: QuadKAN在各种地形（包括平坦和不平坦表面，以及有静态或动态障碍物的场景）的评估中，相比现有技术（SOTA）基线，实现了更高的回报、更远的行进距离和更少的碰撞。

Conclusion: 研究表明，样条参数化策略为实现鲁棒的视觉引导运动提供了一种简单、有效且可解释的替代方案，能够提高样本效率、减少动作抖动和能耗，并提供可解释的姿态-动作敏感性。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [283] [Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting](https://arxiv.org/abs/2508.21501)
*Pierrick Lorang,Hong Lu,Johannes Huemer,Patrik Zips,Matthias Scheutz*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的神经符号框架，通过学习连续控制策略和符号领域抽象来解决模仿学习中的短期技能、大数据集和泛化性问题，并在机器人手臂和自动叉车等多个领域取得了良好的数据效率、泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法主要关注短期技能，需要大量数据，且难以解决长周期任务或跨任务变化和分布变化的泛化问题。

Method: 提出一种神经符号框架，从少量技能演示中联合学习连续控制策略和符号领域抽象。该方法将高层任务结构抽象为图，通过Answer Set Programming求解器发现符号规则，并使用扩散策略模仿学习训练低层控制器。高层Oracle过滤任务相关信息，使每个控制器专注于最小的观察和动作空间。

Result: 在包含机器人手臂（堆叠、厨房、组装、河内塔）和自动叉车（两种环境）的六个领域中进行了验证，结果表明该方法具有高数据效率（仅需五个技能演示）、强大的零样本和少样本泛化能力以及可解释的决策制定。

Conclusion: 该基于图的神经符号框架能够捕捉复杂的状态转换，包括数据驱动学习或聚类技术在有限演示数据集中难以发现的非空间和时间关系。

Abstract: Imitation learning enables intelligent systems to acquire complex behaviors
with minimal supervision. However, existing methods often focus on
short-horizon skills, require large datasets, and struggle to solve
long-horizon tasks or generalize across task variations and distribution
shifts. We propose a novel neuro-symbolic framework that jointly learns
continuous control policies and symbolic domain abstractions from a few skill
demonstrations. Our method abstracts high-level task structures into a graph,
discovers symbolic rules via an Answer Set Programming solver, and trains
low-level controllers using diffusion policy imitation learning. A high-level
oracle filters task-relevant information to focus each controller on a minimal
observation and action space. Our graph-based neuro-symbolic framework enables
capturing complex state transitions, including non-spatial and temporal
relations, that data-driven learning or clustering techniques often fail to
discover in limited demonstration datasets. We validate our approach in six
domains that involve four robotic arms, Stacking, Kitchen, Assembly, and Towers
of Hanoi environments, and a distinct Automated Forklift domain with two
environments. The results demonstrate high data efficiency with as few as five
skill demonstrations, strong zero- and few-shot generalizations, and
interpretable decision making.

</details>


### [284] [Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler](https://arxiv.org/abs/2508.21549)
*Liding Zhang,Kuanqi Cai,Yu Zhang,Zhenshan Bing,Chaoqun Wang,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: MIT* 是一种新的路径规划器，它通过在找到初始解之前基于先前的可接受解成本构建估计的有界集合来加速收敛。它还采用自适应采样器和基于长度的自适应稀疏碰撞检查来提高路径成本效率和计算时间。


<details>
  <summary>Details</summary>
Motivation: 机器人路径规划通常涉及解决连续值、高维问题。现有的基于采样的规划器（如 Informed RRT*）在找不到解时需要探索整个配置空间，这既耗时又耗计算资源。

Method: MIT* 规划器通过以下方式工作：1. 构建估计的有界集合：在找到初始解之前，基于先前可接受的解成本来估计有界集合。2. 自适应采样器：根据探索过程动态调整采样策略。3. 基于长度的自适应稀疏碰撞检查：指导惰性反向搜索。

Result: MIT* 在 R^4 到 R^16 的问题中优于现有的单查询、基于采样的方法，并成功应用于机器人操作任务。

Conclusion: MIT* 通过其创新的有界集估计、自适应采样和碰撞检查策略，提高了路径规划的效率和计算速度，尤其是在高维空间和复杂场景下。

Abstract: Path planning in robotics often involves solving continuously valued,
high-dimensional problems. Popular informed approaches include graph-based
searches, such as A*, and sampling-based methods, such as Informed RRT*, which
utilize informed set and anytime strategies to expedite path optimization
incrementally. Informed sampling-based planners define informed sets as subsets
of the problem domain based on the current best solution cost. However, when no
solution is found, these planners re-sample and explore the entire
configuration space, which is time-consuming and computationally expensive.
This article introduces Multi-Informed Trees (MIT*), a novel planner that
constructs estimated informed sets based on prior admissible solution costs
before finding the initial solution, thereby accelerating the initial
convergence rate. Moreover, MIT* employs an adaptive sampler that dynamically
adjusts the sampling strategy based on the exploration process. Furthermore,
MIT* utilizes length-related adaptive sparse collision checks to guide lazy
reverse search. These features enhance path cost efficiency and computation
times while ensuring high success rates in confined scenarios. Through a series
of simulations and real-world experiments, it is confirmed that MIT*
outperforms existing single-query, sampling-based planners for problems in R^4
to R^16 and has been successfully applied to real-world robot manipulation
tasks. A video showcasing our experimental results is available at:
https://youtu.be/30RsBIdexTU

</details>


### [285] [Learning Agile Gate Traversal via Analytical Optimal Policy Gradient](https://arxiv.org/abs/2508.21592)
*Tianchen Sun,Bingheng Wang,Longbin Tang,Yichao Gao,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种混合框架，通过在线微调模型预测控制（MPC）参数来解决四旋翼飞行器穿越狭窄门洞的挑战，该参数由离线训练的神经网络（NN）输出。


<details>
  <summary>Details</summary>
Motivation: 传统的自主飞行方法在设计和参数调整方面存在挑战，而端到端强化学习（RL）方法在样本效率和可解释性方面存在不足。本文旨在提出一种更优的方法。

Method: 提出了一种混合框架，其中神经网络（NN）根据门洞角点坐标和无人机当前状态，联合预测参考姿态和成本函数权重，并利用这些输出来自适应地微调模型预测控制（MPC）参数。此外，还为MPC模块和基于优化的门洞穿越检测模块推导了分析策略梯度，并引入了一种简化的姿态跟踪误差表示，以提高学习效率。

Result: 硬件实验表明，该方法能够实现四旋翼飞行器在复杂环境中快速、准确地穿越狭窄门洞，并且在样本效率方面比传统的端到端RL方法有了显著的提高。

Conclusion: 所提出的混合框架通过结合MPC的精确性和RL的自适应性，有效解决了四旋翼飞行器穿越狭窄门洞的挑战，并在样本效率和性能方面取得了优于现有方法的成果。

Abstract: Traversing narrow gates presents a significant challenge and has become a
standard benchmark for evaluating agile and precise quadrotor flight.
Traditional modularized autonomous flight stacks require extensive design and
parameter tuning, while end-to-end reinforcement learning (RL) methods often
suffer from low sample efficiency and limited interpretability. In this work,
we present a novel hybrid framework that adaptively fine-tunes model predictive
control (MPC) parameters online using outputs from a neural network (NN)
trained offline. The NN jointly predicts a reference pose and cost-function
weights, conditioned on the coordinates of the gate corners and the current
drone state. To achieve efficient training, we derive analytical policy
gradients not only for the MPC module but also for an optimization-based gate
traversal detection module. Furthermore, we introduce a new formulation of the
attitude tracking error that admits a simplified representation, facilitating
effective learning with bounded gradients. Hardware experiments demonstrate
that our method enables fast and accurate quadrotor traversal through narrow
gates in confined environments. It achieves several orders of magnitude
improvement in sample efficiency compared to naive end-to-end RL approaches.

</details>


### [286] [The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics](https://arxiv.org/abs/2508.21635)
*Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire*

Main category: cs.RO

TL;DR: A multi-modal dataset for agricultural robotics challenges


<details>
  <summary>Details</summary>
Motivation: To support the development and benchmarking of advanced algorithms for localization, mapping, perception, and navigation in agricultural robotics by addressing challenges like varying natural lighting, motion blur, rough terrain, and long, perceptually aliased sequences.

Method: Collected a multi-modal dataset using sensors such as stereo infrared camera, color camera, accelerometer, gyroscope, magnetometer, GNSS, and wheel odometry over two hours in a soybean crop field. Evaluated state-of-the-art multimodal SLAM methods on this dataset.

Result: Showcased existing limitations of state-of-the-art SLAM methods in agricultural settings.

Conclusion: The dataset and utilities are released to facilitate research in agricultural robotics.

Abstract: We present a multi-modal dataset collected in a soybean crop field,
comprising over two hours of recorded data from sensors such as stereo infrared
camera, color camera, accelerometer, gyroscope, magnetometer, GNSS (Single
Point Positioning, Real-Time Kinematic and Post-Processed Kinematic), and wheel
odometry. This dataset captures key challenges inherent to robotics in
agricultural environments, including variations in natural lighting, motion
blur, rough terrain, and long, perceptually aliased sequences. By addressing
these complexities, the dataset aims to support the development and
benchmarking of advanced algorithms for localization, mapping, perception, and
navigation in agricultural robotics. The platform and data collection system is
designed to meet the key requirements for evaluating multi-modal SLAM systems,
including hardware synchronization of sensors, 6-DOF ground truth and loops on
long trajectories.
  We run multimodal state-of-the art SLAM methods on the dataset, showcasing
the existing limitations in their application on agricultural settings. The
dataset and utilities to work with it are released on
https://cifasis.github.io/rosariov2/.

</details>


### [287] [Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators](https://arxiv.org/abs/2508.21677)
*Bernhard Wullt,Johannes Köhler,Per Mattsson,Mikeal Norrlöf,Thomas B. Schön*

Main category: cs.RO

TL;DR: This paper proposes a robust tube MPC and corridor planning algorithm for industrial manipulators operating in cluttered environments with model uncertainties, achieving faster and safer motion planning compared to benchmark methods.


<details>
  <summary>Details</summary>
Motivation: Industrial manipulators need safe and fast motion planning in cluttered environments, especially when facing model uncertainties, which currently limit operational speed.

Method: The paper suggests a novel model predictive control (MPC) solution comprising a robust tube MPC and a corridor planning algorithm. This approach results in a convex MPC that can be solved quickly.

Result: The proposed method was demonstrated on a simulated 6 DOF industrial robot in cluttered environments with model uncertainties. It outperformed benchmark methods by handling higher levels of model uncertainty and achieving faster motion.

Conclusion: The developed robust tube MPC with corridor planning offers a practically useful solution for safe and fast motion planning of industrial manipulators in uncertain and cluttered environments.

Abstract: Industrial manipulators are normally operated in cluttered environments,
making safe motion planning important. Furthermore, the presence of
model-uncertainties make safe motion planning more difficult. Therefore, in
practice the speed is limited in order to reduce the effect of disturbances.
There is a need for control methods that can guarantee safe motions that can be
executed fast. We address this need by suggesting a novel model predictive
control (MPC) solution for manipulators, where our two main components are a
robust tube MPC and a corridor planning algorithm to obtain collision-free
motion. Our solution results in a convex MPC, which we can solve fast, making
our method practically useful. We demonstrate the efficacy of our method in a
simulated environment with a 6 DOF industrial robot operating in cluttered
environments with uncertainties in model parameters. We outperform benchmark
methods, both in terms of being able to work under higher levels of model
uncertainties, while also yielding faster motion.

</details>


### [288] [Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?](https://arxiv.org/abs/2508.21690)
*Olger Siebinga,David Abbink*

Main category: cs.RO

TL;DR: 行人避让中的“人行道萨尔萨”现象为研究行人与移动机器人交互提供了有趣的用例。尽管过去的模型可以复制这种现象，但它们不符合博弈论的假设。本研究提出了一种利用强化学习（RL）代理与行人行为模型交互的方法。结果表明，RL代理能够成功学习与CEI模型进行交互，并且风险规避型RL代理通过运动有效传达意图，降低了感知风险，并展现了模型的努力。


<details>
  <summary>Details</summary>
Motivation: 研究行人与移动机器人交互中的“人行道萨尔萨”现象，以理解隐式通信，并为机器人设计安全可接受的行为提供见解。

Method: 提出一种利用强化学习（RL）代理与行人行为模型（CEI框架）交互的方法，并训练了一个基础RL代理和一个风险规避型RL代理。

Result: 基础RL代理成功学会了与CEI模型进行交互。风险规避型RL代理通过运动有效传达意图，降低了感知风险，并展现了模型的努力。

Conclusion: 基于强化学习的方法在机器人规划和决策中与行人进行交互方面显示出潜力，能够有效地学习和沟通意图。

Abstract: Pedestrians approaching each other on a sidewalk sometimes end up in an
awkward interaction known as the "sidewalk salsa": they both (repeatedly)
deviate to the same side to avoid a collision. This provides an interesting use
case to study interactions between pedestrians and mobile robots because, in
the vast majority of cases, this phenomenon is avoided through a negotiation
based on implicit communication. Understanding how it goes wrong and how
pedestrians end up in the sidewalk salsa will therefore provide insight into
the implicit communication. This understanding can be used to design safe and
acceptable robotic behaviour. In a previous attempt to gain this understanding,
a model of pedestrian behaviour based on the Communication-Enabled Interaction
(CEI) framework was developed that can replicate the sidewalk salsa. However,
it is unclear how to leverage this model in robotic planning and
decision-making since it violates the assumptions of game theory, a much-used
framework in planning and decision-making. Here, we present a proof-of-concept
for an approach where a Reinforcement Learning (RL) agent leverages the model
to learn how to interact with pedestrians. The results show that a basic RL
agent successfully learned to interact with the CEI model. Furthermore, a
risk-averse RL agent that had access to the perceived risk of the CEI model
learned how to effectively communicate its intention through its motion and
thereby substantially lowered the perceived risk, and displayed effort by the
modelled pedestrian. These results show this is a promising approach and
encourage further exploration.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [289] [Fast and Scalable Mixed Precision Euclidean Distance Calculations Using GPU Tensor Cores](https://arxiv.org/abs/2508.21230)
*Brian Curless,Michael Gowanlock*

Main category: cs.DC

TL;DR: 该论文提出了一种利用GPU张量核心（TC）加速欧几里得距离计算（FaSTED算法）的方法，特别是在混合精度（FP16-32）下，并将其应用于相似性搜索，在实际高维数据集上实现了比现有算法2.5-51倍的加速，且精度损失小于0.06%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注在FP64（64位浮点数）下使用张量核心（TC）进行计算，但TCs也可用于低精度计算（FP16-32），能带来显著的性能提升。然而，低精度TCs的高计算吞吐量会导致数据饥饿问题。本研究旨在探索在混合精度下利用TCs计算欧几里得距离，以克服数据饥饿问题并提升性能。

Method: 提出了一种名为FaSTED（Fast and Scalable Tensor core Euclidean Distance）的算法，该算法专为混合精度（FP16-32）TCs设计，通过显著的层级数据复用和最大化内存利用率（全局内存、共享内存和寄存器）来解决数据饥饿问题，实现高计算吞吐量。并将FaSTED应用于相似性搜索，通过索引数据结构来减少不必要的欧几里得距离计算。

Result: 在四个真实世界的高维数据集（维度范围128-960）上，FaSTED算法相比于采用FP64的SOTA TC欧几里得距离算法以及采用FP32的CUDA核心算法，实现了2.5-51倍的加速。同时，与FP64基线相比，该混合精度算法的精度损失小于0.06%。

Conclusion: FaSTED算法成功利用了GPU张量核心的混合精度计算能力，显著加速了欧几里得距离计算，特别是在相似性搜索等数据分析应用中，实现了比现有先进算法更高的性能，且精度损失极小，证明了其在实际应用中的有效性。

Abstract: Modern GPUs are equipped with tensor cores (TCs) that are commonly used for
matrix multiplication in artificial intelligence workloads. However, because
they have high computational throughput, they can lead to significant
performance gains in other algorithms if they can be successfully exploited. We
examine using TCs to compute Euclidean distance calculations, which are used in
many data analytics applications. Prior work has only investigated using 64 bit
floating point (FP64) data for computation; however, TCs can operate on lower
precision floating point data (i.e., 16 bit matrix multiplication and 32 bit
accumulation), which we refer to as FP16-32. FP16-32 TC peak throughput is so
high that TCs are easily starved of data. We propose a Fast and Scalable Tensor
core Euclidean Distance (FaSTED) algorithm. To achieve high computational
throughput, we design FaSTED for significant hierarchical reuse of data and
maximize memory utilization at every level (global memory, shared memory, and
registers). We apply FaSTED to the application of similarity searches, which
typically employ an indexing data structure to eliminate superfluous Euclidean
distance calculations. We compare to the state-of-the-art (SOTA) TC Euclidean
distance algorithm in the literature that employs FP64, as well as to two
single precision (FP32) CUDA core algorithms that both employ an index. We find
that across four real-world high-dimensional datasets spanning 128-960
dimensions, the mixed-precision brute force approach achieves a speedup over
the SOTA algorithms of 2.5-51x. We also quantify the accuracy loss of our mixed
precision algorithm to be less than <0.06% when compared to the FP64 baseline.

</details>


### [290] [Decentralized Federated Averaging via Random Walk](https://arxiv.org/abs/2508.21286)
*Changheng Wang,Zhiqing Wei,Lizhe Liu,Qiao Deng,Yingda Wu,Yangyang Niu,Yashan Pang,Zhiyong Feng*

Main category: cs.DC

TL;DR: 本文提出了一种名为DFedRW的去中心化联邦学习方法，通过随机游走更新和聚合部分更新来解决数据异构性和样本偏差问题，并提出量化版本以提高通信效率。实验结果表明，DFedRW在收敛速度和准确性方面优于传统的FedAvg算法。


<details>
  <summary>Details</summary>
Motivation: 现有的中心化联邦学习方法存在单点故障、通信瓶颈和模型参数暴露的风险；去中心化方法虽然提高了鲁棒性和隐私性，但在数据异构和不平衡的情况下可能导致收敛缓慢或收敛到次优模型。传统去中心化方法还忽略了“掉队者”问题，导致训练数据量减少和采样偏差。因此，需要一种能够有效处理数据异质性、避免“掉队者”问题并提高通信效率的去中心化联邦学习方法。

Method: 本文提出了一种名为DFedRW（decentralized federated averaging via random walk）的去中心化联邦学习方法。该方法用随机游走更新替代了单设备上的多次本地更新，允许聚合部分的随机游走更新以解决“掉队者”问题和采样偏差。此外，还提出了一种量化版本的DFedRW以提高通信效率。理论分析表明，DFedRW在凸条件下的收敛阶数为O(1/(k^(1-q)))，并提出了量化能够平衡通信和收敛的充分条件。

Result: 数值分析表明，所提出的（量化）DFedRW算法在收敛速度和准确性方面均优于（去中心化的）FedAvg算法。在高度异构的情况下，DFedRW算法的测试准确率分别提高了38.3%和37.5%。

Conclusion: DFedRW算法通过引入随机游走更新和聚合部分更新，有效解决了去中心化联邦学习中数据异构性、“掉队者”问题和采样偏差等挑战。其量化版本进一步提高了通信效率，并在实践中展现出优于传统方法的性能。提出的量化条件为在通信和收敛之间取得平衡提供了理论指导。

Abstract: Federated Learning (FL) is a communication-efficient distributed machine
learning method that allows multiple devices to collaboratively train models
without sharing raw data. FL can be categorized into centralized and
decentralized paradigms. The centralized paradigm relies on a central server to
aggregate local models, potentially resulting in single points of failure,
communication bottlenecks, and exposure of model parameters. In contrast, the
decentralized paradigm, which does not require a central server, provides
improved robustness and privacy. The essence of federated learning lies in
leveraging multiple local updates for efficient communication. However, this
approach may result in slower convergence or even convergence to suboptimal
models in the presence of heterogeneous and imbalanced data. To address this
challenge, we study decentralized federated averaging via random walk (DFedRW),
which replaces multiple local update steps on a single device with random walk
updates. Traditional Federated Averaging (FedAvg) and its decentralized
versions commonly ignore stragglers, which reduces the amount of training data
and introduces sampling bias. Therefore, we allow DFedRW to aggregate partial
random walk updates, ensuring that each computation contributes to the model
update. To further improve communication efficiency, we also propose a
quantized version of DFedRW. We demonstrate that (quantized) DFedRW achieves
convergence upper bound of order $\mathcal{O}(\frac{1}{k^{1-q}})$ under convex
conditions. Furthermore, we propose a sufficient condition that reveals when
quantization balances communication and convergence. Numerical analysis
indicates that our proposed algorithms outperform (decentralized) FedAvg in
both convergence rate and accuracy, achieving a 38.3\% and 37.5\% increase in
test accuracy under high levels of heterogeneities.

</details>


### [291] [Addressing Reproducibility Challenges in HPC with Continuous Integration](https://arxiv.org/abs/2508.21289)
*Valérie Hayot-Sasson,Nathaniel Hudson,André Bauer,Maxime Gonthier,Ian Foster,Kyle Chard*

Main category: cs.DC

TL;DR: High-performance computing (HPC) research often lacks reproducibility due to unique infrastructure and access restrictions. This paper proposes using continuous integration (CI) with documented testing and provenance as a substitute for resource access. It introduces CORRECT, a GitHub Action for secure testing on remote HPC resources, and evaluates its effectiveness across various HPC applications.


<details>
  <summary>Details</summary>
Motivation: The HPC community uses reproducibility badges to incentivize reproducible research, but many papers fail to meet these requirements due to the unique and restrictive nature of HPC infrastructure and software. The paper aims to address this gap by proposing an alternative approach.

Method: The paper surveys existing reproducibility initiatives, identifies barriers to reproducibility in HPC, and introduces a GitHub Action called CORRECT. CORRECT enables secure execution of tests on remote HPC resources, facilitating documented testing and provenance tracking. The effectiveness of CORRECT was evaluated using three different types of HPC applications.

Result: The evaluation demonstrated that CORRECT is effective in automating and documenting reproducibility evaluations across different HPC applications, suggesting that improved HPC-compliant CI solutions can enhance research reproducibility.

Conclusion: The paper concludes that documented testing via CI, coupled with complete provenance information, can serve as a viable substitute for direct resource access in ensuring research reproducibility in HPC. The CORRECT GitHub Action is presented as a practical solution to improve the reproducibility of HPC applications.

Abstract: The high-performance computing (HPC) community has adopted incentive
structures to motivate reproducible research, with major conferences awarding
badges to papers that meet reproducibility requirements. Yet, many papers do
not meet such requirements. The uniqueness of HPC infrastructure and software,
coupled with strict access requirements, may limit opportunities for
reproducibility. In the absence of resource access, we believe that regular
documented testing, through continuous integration (CI), coupled with complete
provenance information, can be used as a substitute. Here, we argue that better
HPC-compliant CI solutions will improve reproducibility of applications. We
present a survey of reproducibility initiatives and describe the barriers to
reproducibility in HPC. To address existing limitations, we present a GitHub
Action, CORRECT, that enables secure execution of tests on remote HPC
resources. We evaluate CORRECT's usability across three different types of HPC
applications, demonstrating the effectiveness of using CORRECT for automating
and documenting reproducibility evaluations.

</details>


### [292] [A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling](https://arxiv.org/abs/2508.21328)
*Zhiyu Wang,Mohammad Goudarzi,Mingming Gong,Rajkumar Buyya*

Main category: cs.DC

TL;DR: KD-AFRL是一种结合知识蒸馏和自适应联邦强化学习的框架，用于优化云-边-物联网环境下的多域物联网应用调度，解决了现有方法的异构性、非IID数据和跨域协作不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有分布式调度优化方法在云-边-物联网环境下面临异构计算、非IID数据分布和跨域协作机制不足的挑战。

Method: 提出KD-AFRL框架，包含三个创新点：1. 资源感知混合架构生成机制（双区神经网络）；2. 隐私保护的环境聚类联邦学习（差分隐私和K-means）；3. 环境导向的跨架构知识蒸馏（温度调节软目标）。

Result: 在真实的云-边-物联网基础设施上进行的大量实验表明，KD-AFRL比现有最佳基线方法收敛速度快21%，在完成时间、能耗和加权成本方面分别提高了15.7%、10.8%和13.9%。在可扩展性实验中，随着域数量的增加，KD-AFRL的性能保持能力是现有解决方案的3-5倍。

Conclusion: KD-AFRL框架通过知识蒸馏和自适应联邦强化学习的结合，有效解决了多域物联网应用调度的挑战，并在性能和可扩展性方面取得了显著提升。

Abstract: The rapid proliferation of Internet of Things (IoT) applications across
heterogeneous Cloud-Edge-IoT environments presents significant challenges in
distributed scheduling optimization. Existing approaches face issues, including
fixed neural network architectures that are incompatible with computational
heterogeneity, non-Independent and Identically Distributed (non-IID) data
distributions across IoT scheduling domains, and insufficient cross-domain
collaboration mechanisms. This paper proposes KD-AFRL, a Knowledge
Distillation-empowered Adaptive Federated Reinforcement Learning framework that
addresses multi-domain IoT application scheduling through three core
innovations. First, we develop a resource-aware hybrid architecture generation
mechanism that creates dual-zone neural networks enabling heterogeneous devices
to participate in collaborative learning while maintaining optimal resource
utilization. Second, we propose a privacy-preserving environment-clustered
federated learning approach that utilizes differential privacy and K-means
clustering to address non-IID challenges and facilitate effective collaboration
among compatible domains. Third, we introduce an environment-oriented
cross-architecture knowledge distillation mechanism that enables efficient
knowledge transfer between heterogeneous models through temperature-regulated
soft targets. Comprehensive experiments with real Cloud-Edge-IoT infrastructure
demonstrate KD-AFRL's effectiveness using diverse IoT applications. Results
show significant improvements over the best baseline, with 21% faster
convergence and 15.7%, 10.8%, and 13.9% performance gains in completion time,
energy consumption, and weighted cost, respectively. Scalability experiments
reveal that KD-AFRL achieves 3-5 times better performance retention compared to
existing solutions as the number of domains increases.

</details>


### [293] [Unpacking Maximum Extractable Value on Polygon: A Study on Atomic Arbitrage](https://arxiv.org/abs/2508.21473)
*Daniil Vostrikov,Yash Madhwal,Andrey Seoev,Anastasiia Smirnova,Yury Yanovich,Alexey Smirnov,Vladimir Gorgadze*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The evolution of blockchain technology, from its origins as a decentralized
ledger for cryptocurrencies to its broader applications in areas like
decentralized finance (DeFi), has significantly transformed financial
ecosystems while introducing new challenges such as Maximum Extractable Value
(MEV). This paper explores MEV on the Polygon blockchain, with a particular
focus on Atomic Arbitrage (AA) transactions. We establish criteria for
identifying AA transactions and analyze key factors such as searcher behavior,
bidding dynamics, and token usage. Utilizing a dataset spanning 22 months and
covering 23 million blocks, we examine MEV dynamics with a focus on Spam-based
and Auction-based backrunning strategies. Our findings reveal that while
Spam-based transactions are more prevalent, Auction-based transactions
demonstrate greater profitability. Through detailed examples and analysis, we
investigate the interactions between network architecture, transaction
sequencing, and MEV extraction, offering comprehensive insights into the
evolution and challenges of MEV in decentralized ecosystems. These results
emphasize the need for robust transaction ordering mechanisms and highlight the
implications of emerging MEV strategies for blockchain networks.

</details>


### [294] [Odyssey: Adaptive Policy Selection for Resilient Distributed Training](https://arxiv.org/abs/2508.21613)
*Yuhang Zhou,Zhibin Wang,Peng Jiang,Haoran Xia,Junhe Lu,Qianyu Jiang,Rong Gu,Hengxi Xu,Xinjing Huang,Guanghuan Fang,Zhiheng Hu,Jingyi Zhang,Yongjin Cai,Jian He,Chen Tian*

Main category: cs.DC

TL;DR: Odyssey是一种容错系统，可适应性地选择最佳恢复策略以应对LLM训练中的中断，与现有方法相比，可提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练常因故障而中断，需要强大的容错能力。现有的无备份方法（如冗余计算、动态并行和数据路由）都会带来性能损失。

Method: Odyssey通过统一性能模型、快速执行计划搜索、准确性能估计和高效通信优化，智能选择最佳恢复策略。

Result: 在32个节点的集群上进行实验，Odyssey在恢复后训练和无故障训练之间的性能差距保持在11.00%以内，同时保持模型收敛和高效的内存使用。与最先进的方法相比，Odyssey的平均吞吐量分别比Oobleck和Recycle高出1.229倍和1.355倍。

Conclusion: Odyssey通过其自适应方法在容错LLM训练方面优于现有技术。

Abstract: Training large language models faces frequent interruptions due to various
faults, demanding robust fault-tolerance. Existing backup-free methods, such as
redundant computation, dynamic parallelism, and data rerouting, each incur
performance penalties, whether from ongoing overhead, lengthy reconfigurations,
or post-recovery inefficiencies. We propose Odyssey, an adaptive fault-tolerant
system that intelligently selects optimal recovery strategies when a failure
occurs. Odyssey achieves this through a unified performance model, expedient
execution plan search, accurate performance estimation, and efficient
communication optimizations. Experiments on a 32-card cluster show that Odyssey
maintains a performance gap of within 11.00% between post-recovery and
failure-free training, while preserving model convergence and efficient memory
usage. Compared to state-of-the-art methods, Odyssey achieves up to 1.229x and
1.355x higher average throughput than Oobleck and Recycle, respectively.

</details>


### [295] [Accelerating Mixture-of-Experts Inference by Hiding Offloading Latency with Speculative Decoding](https://arxiv.org/abs/2508.21706)
*Zhibin Wang,Zhonghui Zhang,Yuhang Zhou,Zibo Wang,Mo Zhou,Peng Jiang,Weilin Cai,Chengying Huan,Rong Gu,Sheng Zhong,Chen Tian*

Main category: cs.DC

TL;DR: SpecMoEOff通过引入投机解码和优化的CPU核来解决MoE模型的I/O瓶颈和低硬件利用率问题，实现了2.5倍的解码吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在扩展参数规模和提升模型性能的同时，也面临GPU内存限制和I/O瓶颈，导致硬件利用率低。

Method: SpecMoEOff结合投机解码技术，通过理论和经验的roofline分析来协调GPU和CPU资源，并开发了专门的CPU分块注意力验证核来处理草稿模型带来的额外开销，同时集成了一个优化器来自动调整超参数。

Result: 实验结果表明，SpecMoEOff相比于现有的MoE卸载技术，解码吞吐量最高可提升2.5倍。

Conclusion: SpecMoEOff通过创新的方法有效解决了MoE模型在卸载过程中的性能瓶颈，显著提升了硬件利用率和解码效率。

Abstract: Recent advancements in Mixture of Experts (MoE) models have significantly
increased their parameter scale as well as model performance. Extensive
offloading techniques have been proposed to address the GPU memory limitations
of MoE inference. However, due to the I/O bottleneck and sparse computation of
MoE models, existing offloading techniques still suffer from low hardware
utilization. To fully utilize the hardware resources, we propose SpecMoEOff,
which employs the speculative decoding technique to enlarge the workload of
each expert. SpecMoEOff orchestrates the GPU and CPU by both theoretical and
empirical roofline analysis. In addition, we develop a dedicated CPU chunked
attention verification kernel to fit the speculative decoding in offloading
scenarios as well as minimizing the additional overhead led by draft models.
SpecMoEOff further integrates an optimizer to automatically tune the
hyperparameters of speculative decoding under given hardware and workload.
Experimental results show that SpecMoEOff achieves up to 2.5x decode throughput
improvement over the state-of-the-art MoE offloading techniques.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [296] [Auctions Meet Bandits: An Empirical Analysis](https://arxiv.org/abs/2508.21162)
*Mohammad Rashid,Omid Rafieian,Soheil Ghili*

Main category: cs.GT

TL;DR: Sponsored search auctions use quality-adjusted bids, but new advertisers face a cold-start problem. This paper analyzes a mobile app store's use of Thompson Sampling in a second-price auction to address this, proposing a customized exploration strategy for keywords to improve revenue and efficiency.


<details>
  <summary>Details</summary>
Motivation: New advertisers in sponsored search face a cold-start problem due to the difficulty of setting quality scores. Platforms use multi-armed bandit algorithms to balance exploration and exploitation, but optimal strategies in auction environments are not well understood.

Method: The paper analyzes data from a mobile app store using Thompson Sampling in a second-price auction to learn quality scores. It proposes a customized exploration strategy that adjusts exploration levels per keyword based on its characteristics.

Result: The study empirically quantifies the gains from optimizing exploration in the combined auction-bandit model, showing it differs from canonical bandit problems. The proposed customized exploration strategy demonstrates substantial gains in both revenue and efficiency for the platform.

Conclusion: Optimizing exploration strategies in sponsored search auctions, particularly with a customized approach for individual keywords, can lead to significant improvements in both revenue and efficiency compared to standard methods.

Abstract: Sponsored search positions are typically allocated through real-time
auctions, where the outcomes depend on advertisers' quality-adjusted bids - the
product of their bids and quality scores. Although quality scoring helps
promote ads with higher conversion outcomes, setting these scores for new
advertisers in any given market is challenging, leading to the cold-start
problem. To address this, platforms incorporate multi-armed bandit algorithms
in auctions to balance exploration and exploitation. However, little is known
about the optimal exploration strategies in such auction environments. We
utilize data from a leading Asian mobile app store that places sponsored ads
for keywords. The platform employs a Thompson Sampling algorithm within a
second-price auction to learn quality scores and allocate a single sponsored
position for each keyword. We empirically quantify the gains from optimizing
exploration under this combined auction-bandit model and show that this problem
differs substantially from the canonical bandit problem. Drawing on these
empirical insights, we propose a customized exploration strategy in which the
platform adjusts the exploration levels for each keyword according to its
characteristics. We derive the Pareto frontier for revenue and efficiency and
provide actionable policies, demonstrating substantial gains for the platform
on both metrics when using a tailored exploration approach.

</details>


### [297] [A Soft Inducement Framework for Incentive-Aided Steering of No-Regret Players](https://arxiv.org/abs/2508.21672)
*Asrin Efe Yorulmaz,Raj Kiriti Velicheti,Melih Bastopcu,Tamer Başar*

Main category: cs.GT

TL;DR: 该研究探讨了在增强型中介的双人标准型博弈中，中介如何通过信息和激励设计引导玩家达成特定行动组合。研究表明，仅靠信息设计或加上次线性支付方案无法保证实现这一目标，并推导出了实现该目标所需的恒定支付下界。为克服这些限制，研究提出了一种增强方法：在重复博弈开始前进行一次性信息设计，将先前的互动转化为Stackelberg博弈，从而理论上和经验上证明了该方法能以高概率将玩家的行动组合收敛速度提高一个常数因子。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决双人标准型博弈中的操控问题，即中介如何通过信息和激励设计引导玩家达成特定的行动组合。

Method: 研究首先确定了成功操控的可行博弈类型，并证明了仅通过信息设计或结合次线性支付方案无法实现任意目标行动组合的操控。在此基础上，推导出了实现操控所需的恒定支付的下界。为了克服信息设计的局限性，研究引入了一种增强方法，在重复博弈开始前进行一次性信息设计，将先前的互动转化为Stackelberg博弈。

Result: 研究理论上证明，所提出的增强方法能够以高概率将玩家的行动组合收敛到目标点的速度提高一个常数因子，并通过实证结果支持了这一结论。

Conclusion: 所提出的结合一次性信息设计和Stackelberg博弈的增强方法，能够有效地提高玩家在双人标准型博弈中向目标行动组合收敛的速度，克服了仅依赖信息设计的局限性。

Abstract: In this work, we investigate a steering problem in a mediator-augmented
two-player normal-form game, where the mediator aims to guide players toward a
specific action profile through information and incentive design. We first
characterize the games for which successful steering is possible. Moreover, we
establish that steering players to any desired action profile is not always
achievable with information design alone, nor when accompanied with sublinear
payment schemes. Consequently, we derive a lower bound on the constant payments
required per round to achieve this goal. To address these limitations incurred
with information design, we introduce an augmented approach that involves a
one-shot information design phase before the start of the repeated game,
transforming the prior interaction into a Stackelberg game. Finally, we
theoretically demonstrate that this approach improves the convergence rate of
players' action profiles to the target point by a constant factor with high
probability, and support it with empirical results.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [298] [Nonlinear mechanical metamaterial cloaks](https://arxiv.org/abs/2508.21277)
*Giovanni Bordiga,Jean-Gabriel Argaud,Audrey A. Watkins,Vincent Tournat,Katia Bertoldi*

Main category: physics.app-ph

TL;DR: 提出了一种将非线性机械隐身视为优化问题的新方法，通过可微分仿真和梯度优化来设计隐身斗篷，并在机械超材料中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 将已在线性系统中广泛应用的隐身概念扩展到非线性机械系统。

Method: 将隐身问题构建为优化问题，利用可微分仿真和梯度优化求解，并设计由刚性单元和弹性耦合构成的机械超材料。

Result: 设计出了能够有效隐藏内部不均匀性和抵御外部机械扰动的最优隐身结构，并在静态和动态场景下均表现良好。

Conclusion: 该方法为设计集成隐身功能的机械系统提供了一种通用的设计范式，适用于多种加载场景。

Abstract: The concept of cloaking -- hiding objects from external detection -- has seen
wide success in linear systems. Yet, translating these advancements to
nonlinear mechanical systems remains an open challenge. Here, we present a new
approach to nonlinear mechanical cloaking that frames cloaking as an
optimization problem aimed at replicating a target mechanical response. We
solve this problem using a differentiable simulation framework coupled with
gradient-based optimization. We implement this approach in a class of
mechanical metamaterials constructed from rigid units with elastic couplings
that support large deformation and contact interactions. Using both numerical
simulations and physical experiments, we design optimal cloak structures that
effectively mask internal inhomogeneities and shield against external
mechanical disturbances both in static and dynamic regimes. This approach
provides a versatile design paradigm for creating mechanical systems with
integrated cloaking functionality across a broad range of loading scenarios.

</details>


### [299] [Deterministic switching of perpendicular magnetization using Néel order-engineered out-of-plane spin in a single ferromagnet](https://arxiv.org/abs/2508.21404)
*Baiqing Jiang,Ziqian Cui,Hanying Zhang,Yuan Wang,C. Bi*

Main category: physics.app-ph

TL;DR: 通过相邻反铁磁绝缘体的尼尔序在单铁磁体中实现自旋极化，从而在无磁场的情况下进行垂直切换。


<details>
  <summary>Details</summary>
Motivation: 为了在无需辅助磁场的情况下实现确定性切换，需要获得垂直于平面的自旋极化（σz）。

Method: 通过在工程化的铁磁体中利用相邻反铁磁绝缘体的尼尔序来产生自旋极化，并研究了当自旋极化与尼尔矢量共线时如何诱导σz。

Result: 观察到了σz以及由此产生的无磁场垂直切换，且无需任何自旋扭矩产生层。

Conclusion: 该方法可能为构建节能的无场自旋电子器件提供一种兼容CMOS的解决方案。

Abstract: Perpendicular switching of a ferromagnet induced by spin torques is crucial
for building high density spin-based memory and logic devices, where
out-of-plane spin polarization ($\sigma_z$) has become a long sought-after goal
for deterministic switching without assisted magnetic fields. Here we report
the observation of$\sigma_z$ and resultant field-free perpendicular switching
in a single ferromagnet without any spin torque generation layers, where
$\sigma_z$ is achieved through the self-generated spin polarization in the
ferromagnet that is engineered by the N\'eel order of an adjacent
antiferromagnetic insulator. We further demonstrated that $\sigma_z$ emerges
when the self-generated spin polarization is collinear with the N\'eel vector,
where the spin current is reflected back to the ferromagnet, along with rotated
spin polarization toward the out-of-plane direction to induce $\sigma_z$. Since
no current is shunted by antiferromagnetic insulators and the N\'eel order does
not rely on single-crystalline materials, these results may provide a
CMOS-compatible solution for constructing energy-efficient field-free
spintronic devices.

</details>


### [300] [When Energy and Information Revolutions Meet 2D Janus](https://arxiv.org/abs/2508.21425)
*Long Zhang,Ziqi Ren,Li Sun,Yihua Gao,Deli Wang,Junjie He,Guoying Gao*

Main category: physics.app-ph

TL;DR: 二维Janus材料在解决能源和信息问题方面提供了有前景的解决方案，本综述系统地总结了它们的理论预测、实验制备、调控策略、可调性质、应用和机制。


<details>
  <summary>Details</summary>
Motivation: 为了解决能源消耗、环境恶化和后摩尔时代集成电路的量子限制等全球性问题，需要新的材料解决方案。

Method: 本文献综述系统地总结了二维Janus材料的理论预测、实验制备和调控策略，回顾了其在光学、催化、压电、电化学、热电、磁学和电子学等领域的性质、应用和机制。

Result: 二维Janus材料具有可调的物理、化学和生物特性，在能源和信息领域具有广泛的应用前景。

Conclusion: 本综述旨在为二维Janus材料的设计、制造、调控和应用提供有价值的参考，以推动其在能源和信息领域的学术研究和工业应用。

Abstract: The depletion of energy sources, worsening environmental issues, and the
quantum limitations of integrated circuits for information storage in the
post-Moore era, are pressing global concerns. Fortunately, two-dimensional (2D)
Janus materials, possessing broken spatial symmetry, with emerging
pressure-dependent and non-linear optical response, piezoelectricity, valley
polarization, Rashba spin splitting and more, have established a substantial
platform for exploring and applying modifiable physical, chemical and
biological properties in material science and offered a promising solution for
these energy and information issues. To furnish researchers with a
comprehensive repository of 2D Janus family, this review systematically
summarizes their theoretical predictions, experimental preparations, and
modulation strategies. It also retrospectively outlines the recent advances in
modifiable properties, applications, and inherent mechanisms in optics,
catalysis, piezoelectricity, electrochemistry, thermoelectricity, magnetism,
and electronics, with a focus on experimentally realized hexagonal and trigonal
Janus structures. Additionally, their current research state is summarized, and
potential opportunities and challenges that may arise are highlighted. Overall,
this review aims to serve as a valuable resource for designing, fabricating,
regulating, and applying 2D Janus systems, both theoretically and
experimentally. This review will strongly promote the advanced academic
investigations and industrial applications of 2D Janus materials in energy and
information fields.

</details>


### [301] [Time-resolved 3D imaging opportunities with XMPI at ForMAX](https://arxiv.org/abs/2508.21597)
*Julia Katharina Rogalinski,Zisheng Yao,Yuhe Zhang,Zhe Hu,Korneliya Gordeyeva,Tomas Rosén,Daniel Söderberg,Andrea Mazzolari,Jackson da Silva,Vahid Haghighat,Samuel A. McDonald,Kim Nygård,Eleni Myrto Asimakopoulou,Pablo Villanueva-Perez*

Main category: physics.app-ph

TL;DR: XMPI是一种无需旋转样品即可进行X射线成像的方法，通过分束器将X射线分裂成束，从不同角度同时获取多张投影，解决了传统时间分辨X射线断层扫描的局限性，适用于需要高帧率或高分辨率的研究。


<details>
  <summary>Details</summary>
Motivation: 传统时间分辨X射线断层扫描方法在单次曝光实验、复杂样品环境旋转以及离心力影响样品动力学方面存在局限，阻碍了某些动力学的研究。XMPI旨在克服这些限制。

Method: XMPI方法无需旋转样品，而是利用X射线光学器件将入射X射线光束分裂成多个束（beamlets），这些束在样品位置从不同角度相交，从而能够同时采集多个投影。

Result: 在ForMAX线站成功部署了XMPI系统，并采集了两个不同样品系统（机械负载下的纤维和多相流中的颗粒悬浮液）的投影。证明了该系统能够满足不同的时空分辨率要求，包括纤维研究的12.5 kHz帧率和4微米像素尺寸，以及多相流研究的40 Hz采集和1.3微米像素尺寸。

Conclusion: XMPI是一种无需样品旋转即可实现时间分辨成像的新方法，克服了传统方法的局限性，并在ForMAX线站成功实现并验证了其在不同研究领域的应用潜力，为建立永久性的XMPI终端奠定了基础。

Abstract: X-rays are commonly used in imaging experiments due to their penetration
power, which enables non-destructive resolution of internal structures in
samples that are opaque to visible light. Time-resolved X-ray tomography is the
state-of-the-art method for obtaining volumetric 4D (3D + time) information by
rotating the sample and acquiring projections from different angular viewpoints
over time. This method enables studies to address a plethora of research
questions across various scientific disciplines. However, it faces several
limitations, such as incompatibility with single-shot experiments, challenges
in rotating complex sample environments that restrict the achievable rotation
speed or range, and the introduction of centrifugal forces that can affect the
sample's dynamics. These limitations can hinder and even preclude the study of
certain dynamics. Here, we present an implementation of an alternative
approach, X-ray Multi-Projection Imaging (XMPI), which eliminates the need for
sample rotation. Instead, the direct incident X-ray beam is split into beamlets
using beam splitting X-ray optics. These beamlets intersect at the sample
position from different angular viewpoints, allowing multiple projections to be
acquired simultaneously. We commissioned this setup at the ForMAX beamline at
MAX IV. We present projections acquired from two different sample systems -
fibers under mechanical load and particle suspension in multi-phase flow - with
distinct spatial and temporal resolution requirements. We demonstrate the
capabilities of the ForMAX XMPI setup using the detector's full dynamical range
for the relevant sample-driven spatiotemporal resolutions: i) at least 12.5 kHz
framerates with 4 micrometer pixel sizes (fibers) and ii) 40 Hz acquisitions
with 1.3 micrometer pixel sizes (multi-phase flows), setting the basis for a
permanent XMPI endstation at ForMAX.

</details>


### [302] [Electrical Control of Excitons in Bare-MoSe2 and MoSe2/NbSe2 Heterostructure](https://arxiv.org/abs/2508.21781)
*Atanu Patra,Vishakha Kaushik,Ali Sepas,Subhamoy Sahoo,Mathias Federolf,Christian G. Mayer,Sebastian Klembt,Monika Emmerling,Simon Betzold,Seth Ariel Tongay,Fabian Hartmann,Thomas Garm Pedersen,Sven Höfling*

Main category: physics.app-ph

TL;DR: 单层过渡金属硫族化合物（TMDCs）因其强烈的激子响应和原子厚度，有望用于下一代光电器件。然而，范德华TMDC/金属异质结构中的光致发光（PL）猝灭会阻碍这种电学调制。


<details>
  <summary>Details</summary>
Motivation: 研究单层MoSe2/块状NbSe2异质结构，并证明垂直电场可以有效地恢复PL强度。

Method: 通过施加垂直电场，并结合第一性原理计算（包含自旋-轨道耦合）来研究PL强度的变化和能带结构。

Result: 垂直电场可将PL强度恢复高达裸露MoSe2的~80%。室温下的PL强度在裸露MoSe2中可调谐近三个数量级，在MoSe2/NbSe2异质结构中可调谐约一个数量级。垂直电场驱动带隙从直接跃迁转变为间接跃迁。异质结构表现出增强因子对温度的明显依赖性。

Conclusion: 研究结果证明了TMDC/金属界面处可逆的、由电场驱动的PL控制，为二维光电器件中的电学可调谐发光和改进的接触工程提供了途径。

Abstract: Monolayer transition metal dichalcogenides (TMDCs) are promising materials
for next-generation optoelectronic devices, owing to their strong excitonic
responses and atomic thickness. Controlling their light emission electrically
is a crucial step towards realizing practical nanoscale optoelectronic devices
such as light-emitting diodes and optical modulators. However,
photoluminescence (PL) quenching in van der Waals TMDC/metal heterostructures,
caused by ultrafast interlayer charge or energy transfer, impedes such
electrical modulation. Here, we investigate monolayer-MoSe2/bulk-NbSe2
heterostructures and demonstrate that a vertical electric field can effectively
recover the PL intensity up to ~ 80% of bare-MoSe2. Furthermore, our analysis
reveals that the room temperature PL intensity can be tuned by nearly three
orders of magnitude in bare-MoSe2 and by about one order of magnitude in
MoSe2/NbSe2 heterostructures. First-principles calculations incorporating
spin-orbit coupling reveal that the perpendicular electric fields drive a
transition from a direct to an indirect bandgap, fundamentally altering the
optical response in the heterostructure. Unlike bare-MoSe2, the heterostructure
exhibits a pronounced thermal dependence of the enhancement factor, implying
that exciton lifetime dominates over interfacial transfer processes. Our
findings demonstrate reversible, electric-field-driven PL control at a
TMDC/metal interface, providing a pathway to electrically tunable light
emission and improved contact engineering in two-dimensional optoelectronic
devices.

</details>


### [303] [Simulating Gadolinium-Induced Magnetic Field Variations for Temperature Sensing with Magneto-Mechanical Resonators](https://arxiv.org/abs/2508.21794)
*Jonas Faltinath,Miriam Schmitz,Fynn Foerger,Martin Möddel,Tobias Knopp*

Main category: physics.app-ph

TL;DR: 该研究提出了一种利用钆（Gd）的温度相关磁性来编码温度信息到小型磁机械谐振器（MMR）频率位移中的方法，以实现高灵敏度温度传感。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够进行无源、无线传感和跟踪的小型磁机械谐振器（MMR），并探索一种将温度信息编码到谐振器频率位移中的新机制。

Method: 通过模拟研究了不同厚度钆（Gd）涂层定子在不同温度下的磁场变化，并分析了Gd的磁相变对其磁导率的影响以及由此产生的磁屏蔽效应，从而量化温度对其谐振器频率的影响。

Result: 模拟结果显示，Gd在居里温度附近的磁相变导致磁导率显著变化，从而在较低温度下表现出明显的磁屏蔽行为。在相变区域，研究发现了高达45.8 Hz/K的峰值灵敏度，比现有文献值高出约20倍。

Conclusion: 该研究为利用MMR进行定量、高灵敏度温度提取提供了重要进展，特别是利用Gd的磁相变实现了优异的温度传感性能。

Abstract: Small-size magneto-mechanical resonators (MMR) represent an emerging class of
passive, wireless sensors that combine a sensing functionality with a tracking
option. The operation principle is based on a resonating rotor oscillation
whose frequency is defined by the magnetic flux density of a stator magnet. One
general sensing mechanism is the coupling of an external parameter to this
resonator frequency. In this study, we investigate an approach for encoding a
temperature information as a shift in the natural oscillation frequency
utilizing the temperature-dependent magnetic properties of gadolinium (Gd). We
perform an isolated simulation study on the temperature scaling of the magnetic
field generation for stators coated with Gd of varying thickness. Our results
show that the magnetic phase transition of Gd at its Curie temperature leads to
a pronounced change in the magnetic permeability enabling a significant
magnetic shielding behavior only for lower temperatures. In the transition
regime, we find a peak sensitivity reaching 45.8 Hz/K exceeding existing values
from the literature by up to a factor of $\sim$ 20. The findings of this work
are an important step toward quantitative high-sensitivity temperature
extraction with MMRs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [304] [A Framework of Arithmetic-Level Variable Precision Computing for In-Memory Architecture: Case Study in MIMO Signal Processing](https://arxiv.org/abs/2508.21079)
*Kaixuan Bao,Wei Xu,Xiaohu You,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 该论文提出了一种名为AL-VPC的统一框架，用于在无线通信中通过变精度计算（VPC）优化计算性能和复杂性。


<details>
  <summary>Details</summary>
Motivation: 计算复杂度是无线通信中的一个关键挑战，但现有方法主要集中在算法层面，忽略了计算精度这一基本维度。

Method: 提出了一种基于随机分析的算术传播误差模型，并将其纳入一个数学优化问题中，以平衡计算性能和计算复杂度。开发了离线VPC和在线VPC两种算法来解决该问题。

Result: 在零强迫（ZF）预编码的案例研究中，该方法实现了高达60%的总和速率提升或30%的复杂度降低，揭示了计算性能与复杂度之间的帕累托边界。

Conclusion: AL-VPC框架通过在算术级别利用变精度计算，为解决无线通信中的计算复杂度问题提供了一种新的、有效的途径。

Abstract: Computational complexity poses a significant challenge in wireless
communication. Most existing attempts aim to reduce it through
algorithm-specific approaches. However, the precision of computing, which
directly relates to both computing performance and computational complexity, is
a dimension that is fundamental but rarely explored in the literature. With the
emerging architecture of in-memory computing, variable precision computing
(VPC) is enabled, allowing each arithmetic operation to be processed with a
distinct and specifically optimized computing precision. In this paper, we
establish a unified framework of arithmetic-level variable precision computing
(AL-VPC), which aims to determine the optimized computing precision for each
arithmetic operation. We first develop an arithmetic propagation error model
exploiting stochastic analysis, and then formulate a mathematical optimization
problem to strike balance between computing performance and computational
complexity. Two algorithms, namely, offline VPC and online VPC, are proposed to
solve the problem considering various practical concerns. Particularly, in a
case study on zero-forcing (ZF) precoding, we reveal the Pareto boundary
between computing performance and complexity, which exhibits up to a 60%
sum-rate enhancement or equivalently up to a 30% complexity reduction compared
to the traditional fixed-length methods.

</details>


### [305] [Hybrid Codebook Design for Localization Using Electromagnetically Reconfigurable Fluid Antenna System](https://arxiv.org/abs/2508.21351)
*Alireza Fadakar,Yuchen Zhang,Hui Chen,Musa Furkan Keskin,Henk Wymeersch,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 本文研究了电磁可重构流体天线系统（ER-FAS）在下行链路定位中的应用，提出了一种联合基带（BB）和电磁（EM）预编码器设计方法，以最小化用户设备（UE）的位置误差界。


<details>
  <summary>Details</summary>
Motivation: 利用ER-FAS的电磁域可配置性，实现按需的波束成形，以提高无线链路的功率效率，并将其应用于下行链路定位。

Method: 提出两种ER-FAS模型：(i) 合成模型，其中每个天线从有限的电磁基函数集中生成所需的波束图样；(ii) 有限状态选择模型，其中每个天线从预定义的波束图样集中选择一个波束图样。针对这两种模型，设计联合基带（BB）和电磁（EM）预编码器以最小化UE位置误差界。

Result: 在合成模型中，推导了BB和EM预编码器的低维闭式表达式。在有限状态模型中，获得了闭式BB结构，并提出了一种低复杂度的块坐标下降算法用于EM模式选择。分析表明，ER-FAS的混合设计显著提高了UE定位精度。

Conclusion: ER-FAS的混合设计方法在UE定位精度方面优于传统的不可重构阵列。

Abstract: Electromagnetically reconfigurable fluid antenna systems (ER-FAS) introduce
additional degrees of freedom in the electromagnetic (EM) domain by dynamically
steering per-antenna radiation patterns, thereby enhancing power efficiency in
wireless links. Unlike prior works on spatially reconfigurable FAS, which
adjust element positions, ER-FAS provides direct control over each element's EM
characteristics to realize on-demand beam-pattern shaping. While existing
studies have exploited ER-FAS to boost spectral efficiency, this paper explores
its application for downlink localization. We consider a multiple-input
single-output (MISO) system in which a multi-antenna ER-FAS at the base station
serves a single-antenna user equipment (UE). We consider two reconfigurability
paradigms: (i) a synthesis model where each antenna generates desired
beampatterns from a finite set of EM basis functions, and (ii) a finite-state
selection model in which each antenna selects a pattern from a predefined set
of patterns. For both paradigms, we formulate the joint baseband (BB) and EM
precoder design to minimize the UE position error bound. In the synthesis case
we derive low-dimensional closed-form expressions for both the BB and EM
precoders. For the finite-state model we obtain closed-form BB structures and
propose a low-complexity block-coordinate-descent algorithm for EM pattern
selection. Analytical bounds and extensive simulations show that the proposed
hybrid designs for ER-FAS substantially improve UE positioning accuracy over
traditional non-reconfigurable arrays.

</details>


### [306] [Channel Estimation and Data Detection in DS-Spread Channels: A Unified Framework, Novel Algorithms, and Waveform Comparison](https://arxiv.org/abs/2508.21373)
*Niladri Halder,Chandra R. Murthy*

Main category: eess.SP

TL;DR: 该论文提出了一种统一的接收机处理框架，用于在延迟尺度（DS）扩展的水下声学（UWA）通信信道中进行通信，并涵盖了OFDM、OTFS、OCDM和ODSS等不同调制波形。通过该框架，研究人员进行了公平且全面的波形比较研究。此外，还开发了一种新颖的变分贝叶斯（VB）迭代离网信道估计（CE）算法，以及一种低复杂度的变分软符号检测（VSSD）算法和一种数据辅助迭代CE和数据检测（ICED）方案。数值结果表明，所提出的算法在CE和数据检测方面都非常有效。在未经编码的通信中，ODSS在低复杂度均衡器下表现最佳，其次是OCDM和OTFS，而OFDM表现最差；在使用VSSD算法时，OTFS、OCDM和ODSS表现相似，并且优于OFDM。在编码通信中，使用VSSD接收机时，所有波形的误码率（BER）都非常接近。因此，当接收机复杂度受限时，波形选择很重要，尤其是在恶劣信道条件下；而当采用更复杂的接收机算法时，这些差异则会消失。


<details>
  <summary>Details</summary>
Motivation: 水下声学（UWA）通信信道具有延迟尺度（DS）扩展的特点，这给通信带来了挑战。为了有效地进行通信，需要解决信道估计（CE）和数据检测问题，并比较不同调制波形（OFDM、OTFS、OCDM、ODSS）在这些信道下的性能。

Method: 提出了一种统一的接收机处理框架，该框架能够处理OFDM、OTFS、OCDM和ODSS等多种调制波形在DS扩展UWA信道下的CE和数据检测问题。开发了一种变分贝叶斯（VB）迭代离网CE算法（包括FVB和SVB两种方法），用于估计信道路径的延迟和尺度参数。提出了一种低复杂度的变分软符号检测（VSSD）算法，用于输出软符号和对数似然比。还提出了一种数据辅助迭代CE和数据检测（ICED）方案，利用已检测的数据符号作为虚拟导频来提高CE和数据检测的准确性。

Result: 数值结果表明，所提出的CE和数据检测算法是有效的。在未经编码的通信中，使用低复杂度均衡器时，ODSS性能最优，OCDM和OTFS次之，OFDM最差。使用VSSD算法时，OTFS、OCDM和ODSS性能相似且优于OFDM。在编码通信中，使用VSSD接收机时，所有波形的BER性能接近。

Conclusion: 当接收机复杂度受限时，特别是在恶劣信道条件下，波形的选择对通信性能有显著影响。然而，当采用更复杂的接收机算法时，不同波形之间的性能差异会减小。

Abstract: We present a unified receiver processing framework for communication over
delay-scale (DS)-spread channels that arise in underwater acoustic (UWA)
communications that addresses both channel estimation (CE) and data detection
for different modulation waveforms, namely OFDM, OTFS, OCDM, and ODSS, through
a common input--output relation. Using this framework, we conduct a fair and
comprehensive comparative study of these waveforms under DS-spread UWA channels
and similar receiver complexities.
  We also develop a novel iterative variational Bayesian (VB) off-grid CE
algorithm to estimate the delay and scale parameters of the channel paths, via
two approaches: a first-order approximation scheme (FVB) and a second-order
approximation scheme (SVB). We propose a low-complexity variational soft symbol
detection (VSSD) algorithm that outputs soft symbols and log-likelihood ratios
for the data bits, and a data-aided iterative CE and data detection (ICED)
scheme that utilizes detected data symbols as \emph{virtual} pilots to further
improve the CE and data detection accuracy.
  Our numerical results reveal the efficacy of the proposed algorithms for CE
and data detection. In terms of relative performance of different waveforms, in
uncoded communications, (a) with a low-complexity subcarrier-by-subcarrier
equalizer, ODSS offers the best performance, followed by OCDM and OTFS, while
OFDM performs the worst, and (b) with the VSSD algorithm, OTFS, OCDM, and ODSS
perform similarly, and they outperform OFDM. With coded communications,
interestingly, all waveforms offer nearly the same BER when the VSSD receiver
is employed. Hence, we conclude that when the receiver complexity is
constrained, waveform choice matters, especially under harsh channel
conditions, whereas with more sophisticated receiver algorithms, these
differences disappear.

</details>


### [307] [Sampling Theory of Jointly Bandlimited Time-vertex Graph Signals](https://arxiv.org/abs/2508.21412)
*Hang Sheng,Hui Feng,Junhao Yu,Feng Ji,Bo Hu*

Main category: eess.SP

TL;DR: 该论文研究了时变图信号（TVGS）的临界采样，重点关注其在联合时域和图拓扑上的平滑性。


<details>
  <summary>Details</summary>
Motivation: 研究TVGS的临界采样，以实现对具有不规则结构的时变数据的有效表示和恢复。

Method: 推导了联合时域和图拓扑的带限TVGS的采样密度下界，并提出了不同类型TVGS的采样和重建方案。

Result: 证明了采样密度下界，并展示了所提采样方案在数值和实际数据集上的应用。

Conclusion: 临界采样是可实现的，提出的采样和重建方案为TVGS分析提供了有效方法。

Abstract: Time-vertex graph signal (TVGS) models describe time-varying data with
irregular structures. The bandlimitedness in the joint time-vertex Fourier
spectral domain reflects smoothness in both temporal and graph topology. In
this paper, we study the critical sampling of three types of TVGS including
continuous-time signals, infinite-length sequences, and finite-length sequences
in the time domain for each vertex on the graph. For a jointly bandlimited
TVGS, we prove a lower bound on sampling density or sampling ratio, which
depends on the measure of the spectral support in the joint time-vertex Fourier
spectral domain. We also provide a lower bound on the sampling density or
sampling ratio of each vertex on sampling sets for perfect recovery. To
demonstrate that critical sampling is achievable, we propose the sampling and
reconstruction procedures for the different types of TVGS. Finally, we show how
the proposed sampling schemes can be applied to numerical as well as real
datasets.

</details>


### [308] [Subset Random Sampling and Reconstruction of Finite Time-Vertex Graph Signals](https://arxiv.org/abs/2508.21415)
*Hang Sheng,Qinji Shu,Hui Feng,Bo Hu*

Main category: eess.SP

TL;DR: 该论文研究了有限时间-顶点图信号（FTVGS）在未知频谱支持下的采样与重构问题，提出了一种针对FTVGS的子集随机采样方案，并结合低秩、稀疏和光滑性先验（LSSP）提出了重构框架。


<details>
  <summary>Details</summary>
Motivation: 现有FTVGS采样与重构方法在处理未知频谱支持时存在不足，且随机采样策略不适用于实践中对采样点（顶点和时间）的限制。本文旨在解决未知频谱支持下的FTVGS采样与重构问题，并提出一种更符合实际操作的采样方案。

Method: 本文提出了一种子集随机采样方案，首先随机选择一部分行和列形成子矩阵，然后在该子矩阵内进行随机采样。此外，还引入了一个包含低秩、稀疏和光滑性先验（LSSP）的重构框架。

Result: 理论上，论文提供了高概率重构原始FTVGS的充分条件。实验结果验证了重构的可行性以及所提出框架的有效性。

Conclusion: 子集随机采样方案和结合LSSP的重构框架能够有效解决未知频谱支持下的FTVGS采样与重构问题，并在实践中具有可行性。

Abstract: Finite time-vertex graph signals (FTVGS) provide an efficient representation
for capturing spatio-temporal correlations across multiple data sources on
irregular structures. Although sampling and reconstruction of FTVGS with known
spectral support have been extensively studied, the case of unknown spectral
support requires further investigation. Existing random sampling methods may
extract samples from any vertex at any time, but such strategies are not
friendly in practice, where sampling is typically limited to a subset of
vertices and moments. To address this requirement, we propose a subset random
sampling scheme for FTVGS. Specifically, we first randomly select a subset of
rows and columns to form a submatrix, followed by random sampling within that
submatrix. In theory, we provide sufficient conditions for reconstructing the
original FTVGS with high probability. Additionally, we introduce a
reconstruction framework incorporating low-rank, sparsity, and smoothness
priors (LSSP), and verify the feasibility of the reconstruction and the
effectiveness of the framework through experiments.

</details>


### [309] [Polynomial Closed Form Model for Ultra-Wideband Transmission Systems](https://arxiv.org/abs/2508.21563)
*Pierluigi Poggiolini,Yanchao Jiang,Yifeng Gao,Fabrizio Forghieri*

Main category: eess.SP

TL;DR: 提出了一种名为PCFM的多项式闭式模型，用于超宽带光传输系统，提高了可靠性、准确性和通用性。


<details>
  <summary>Details</summary>
Motivation: 设计、优化和管理超宽带光传输系统需要快速准确的物理层模型。

Method: 通过将每个通道在光纤跨度内的空间功率分布表示为多项式，然后进行解析积分来推导PCFM模型。

Result: 在包含拉曼放大和通道间拉曼散射的C+L+S频段场景下，PCFM模型与数值积分的GN模型相比，表现出良好的准确性，并且在存在多个集总损耗的情况下也表现良好。

Conclusion: PCFM模型具有很高的准确性和广泛的适用性，可用于超宽带光传输系统。

Abstract: Ultrafast and accurate physical layer models are essential for designing,
optimizing and managing ultra-wideband optical transmission systems. We present
a closed-form GN/EGN model, named Polynomial Closed-Form Model (PCFM),
improving reliability, accuracy, and generality. The key to deriving PCFM is
expressing the spatial power profile of each channel along a span as a
polynomial. Then, under reasonable approximations, the integral calculation can
be carried out analytically, for any chosen degree of the polynomial. We
present a full detailed derivation of the model. We then validate it vs. the
numerically integrated GN-model in a challenging multiband (C+L+S) scenario,
including Raman amplification and inter-channel Raman scattering. We then show
that the approach works well also in the special case of the presence of
multiple lumped loss along the fiber. Overall, the approach shows very good
accuracy and broad applicability. A software implementing the model, fully
reconfigurable to any type of system layout, is available for download under
the Creative Commons 4.0 License.

</details>


### [310] [Energy Detection over Composite $κ-μ$ Shadowed Fading Channels with Inverse Gaussian Distribution in Ultra mMTC Networks](https://arxiv.org/abs/2508.21614)
*He Huang,Zeping Sui,Zilong Liu,Wei Huang,Md. Noor-A-Rahim,Haishi Wang,Zhiheng Hu*

Main category: eess.SP

TL;DR: 该论文在超密集物联网通信（mMTC）网络中，研究了复合kappa-mu阴影衰落信道上的能量检测（ED）特性。通过逆高斯（IG）分布推导了信噪比（SNR）的概率密度函数（PDF）的闭式表达式。利用新的积分和数学变换技术，首次推导了平均检测概率的基于截断的闭式表达式。仿真结果表明，传播路径数量对平均检测概率的影响比平均信噪比更显著，这与之前关注设备到设备网络的研究不同，表明6G mMTC网络设计应考虑增强收发器放置和天线对齐策略，而不是仅仅依赖增加设备到设备的平均信噪比。


<details>
  <summary>Details</summary>
Motivation: 研究在超密集物联网通信（mMTC）网络中的复合kappa-mu阴影衰落信道上能量检测（ED）的特性。

Method: 推导了基于逆高斯（IG）分布的信噪比（SNR）的概率密度函数（PDF）的闭式表达式，并利用新的积分和数学变换技术推导出平均检测概率的基于截断的闭式表达式。

Result: 传播路径数量对平均检测概率的影响比平均信噪比更显著，与之前关注设备到设备网络的研究形成对比。

Conclusion: 6G mMTC网络设计应侧重于增强收发器放置和天线对齐策略，而非仅提高设备到设备的平均信噪比。

Abstract: This paper investigates the characteristics of energy detection (ED) over
composite $\kappa$-$\mu$ shadowed fading channels in ultra machine-type
communication (mMTC) networks. We have derived the closed-form expressions of
the probability density function (PDF) of signal-to-noise ratio (SNR) based on
the Inverse Gaussian (\emph{IG}) distribution. By adopting novel integration
and mathematical transformation techniques, we derive a truncation-based
closed-form expression for the average detection probability for the first
time. It can be observed from our simulations that the number of propagation
paths has a more pronounced effect on average detection probability compared to
average SNR, which is in contrast to earlier studies that focus on
device-to-device networks. It suggests that for 6G mMTC network design, we
should consider enhancing transmitter-receiver placement and antenna alignment
strategies, rather than relying solely on increasing the device-to-device
average SNR.

</details>


### [311] [On the Deployment of Multiple Radio Stripes for Large-Scale Near-Field RF Wireless Power Transfer](https://arxiv.org/abs/2508.21640)
*Amirhossein Azarbahram,Onel L. A. López,Petar Popovski,Matti Latva-aho*

Main category: eess.SP

TL;DR: 本文研究了在视线近场场景中，在室内射频无线能量传输（WPT）中部署无线条纹系统。重点是能量需求集中在特定区域（“热点”）的环境，这些热点是用户密度较高或能量需求一致的空间区域。我们提出了一个联合聚类和无线条纹部署问题，旨在最大化所有热点之间的最小接收功率。为解决这一复杂性，我们将问题分为两个阶段：i）基于空间位置和近场传播特性将无线条纹分配给热点的聚类；ii）天线单元放置优化。具体来说，我们提出了四种无线条纹部署算法。其中两种基于一般的连续凸近似（SCA）和符号规划（SGP）方法。另外两种是形状约束解，其中天线单元沿直线或正多边形排列，便于部署。数值结果表明，所提出的聚类方法收敛有效，其中切比雪夫初始化显著优于随机初始化。优化后的部署在各种频率和无线条纹长度下始终优于基线基准，而多边形部署的性能优于其他方法。同时，直线形部署在高波束增益设置下表现出优势，这得益于增加的空间分集和更广泛的角度覆盖。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在室内射频无线能量传输（WPT）的视线近场场景中，如何高效部署无线条纹系统以满足特定区域（热点）的能量需求。

Method: 本文提出了一种联合聚类和无线条纹部署问题，旨在最大化所有热点间的最小接收功率。该问题被分解为两个阶段：1）基于空间位置和近场传播特性进行聚类，将无线条纹分配给热点；2）优化天线单元的放置。具体提出了四种部署算法，包括基于SCA和SGP的通用方法，以及直线形和正多边形形状约束的部署方法。

Result: 数值结果表明，所提出的聚类方法收敛有效，其中切比雪夫初始化优于随机初始化。优化后的部署优于基线基准，多边形部署性能最佳，而直线形部署在高波束增益设置下表现出优势。

Conclusion: 本文提出的聚类和部署方法能够有效解决室内射频无线能量传输中的无线条纹部署问题，并提出了多种优化算法，其中多边形和直线形部署各有优势，能够根据具体场景进行选择。

Abstract: This paper investigates the deployment of radio stripe systems for indoor
radio-frequency (RF) wireless power transfer (WPT) in line-of-sight near-field
scenarios. The focus is on environments where energy demand is concentrated in
specific areas, referred to as 'hotspots', spatial zones with higher user
density or consistent energy requirements. We formulate a joint clustering and
radio stripe deployment problem that aims to maximize the minimum received
power across all hotspots. To address the complexity, we decouple the problem
into two stages: i) clustering for assigning radio stripes to hotspots based on
their spatial positions and near-field propagation characteristics, and ii)
antenna element placement optimization. In particular, we propose four radio
stripe deployment algorithms. Two are based on general successive convex
approximation (SCA) and signomial programming (SGP) methods. The other two are
shape-constrained solutions where antenna elements are arranged along either
straight lines or regular polygons, enabling simpler deployment. Numerical
results show that the proposed clustering method converges effectively, with
Chebyshev initialization significantly outperforming random initialization. The
optimized deployments consistently outperform baseline benchmarks across a wide
range of frequencies and radio stripe lengths, while the polygon-shaped
deployment achieves better performance compared to other approaches. Meanwhile,
the line-shaped deployment demonstrates an advantage under high boresight gain
settings, benefiting from increased spatial diversity and broader angular
coverage.

</details>


### [312] [Machine Intelligence on the Edge: Interpretable Cardiac Pattern Localisation Using Reinforcement Learning](https://arxiv.org/abs/2508.21652)
*Haozhe Tian,Qiyu Rao,Nina Moutonnet,Pietro Ferraro,Danilo Mandic*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Matched filters are widely used to localise signal patterns due to their high
efficiency and interpretability. However, their effectiveness deteriorates for
low signal-to-noise ratio (SNR) signals, such as those recorded on edge
devices, where prominent noise patterns can closely resemble the target within
the limited length of the filter. One example is the ear-electrocardiogram
(ear-ECG), where the cardiac signal is attenuated and heavily corrupted by
artefacts. To address this, we propose the Sequential Matched Filter (SMF), a
paradigm that replaces the conventional single matched filter with a sequence
of filters designed by a Reinforcement Learning agent. By formulating filter
design as a sequential decision-making process, SMF adaptively design
signal-specific filter sequences that remain fully interpretable by revealing
key patterns driving the decision-making. The proposed SMF framework has strong
potential for reliable and interpretable clinical decision support, as
demonstrated by its state-of-the-art R-peak detection and physiological state
classification performance on two challenging real-world ECG datasets. The
proposed formulation can also be extended to a broad range of applications that
require accurate pattern localisation from noise-corrupted signals.

</details>


### [313] [A Single Subject Machine Learning Based Classification of Motor Imagery EEGs](https://arxiv.org/abs/2508.21724)
*Dario Sanalitro,Marco Finocchiaro,Pasquale Memmolo,Emanuela Cutuli,Maide Bucolo*

Main category: eess.SP

TL;DR: 该研究提出了一种基于机器学习的MI-EEG数据分类新流程，在52名被试者的数据上实现了99.5%的准确率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: MI-BCI系统在帮助用户恢复自由度方面具有广泛应用潜力，但EEG数据解读仍是挑战，特别是区分想象中的左右运动。

Method: 提出了一种新的机器学习流程，对MI-EEG数据进行分类，训练了一个针对每个被试者的模型，并将其与四个现有技术进行比较。

Result: 所提出的框架在MI-BCI系统中具有故障安全分类性能，准确率达到99.5%，优于现有技术的四个研究。

Conclusion: 该研究提出的新流程在MI-BCI系统中具有应用潜力，能够准确分类想象中的左右运动和静息阶段。

Abstract: Motor Imagery-Based Brain-Computer Interfaces (MI-BCIs) are systems that
detect and interpret brain activity patterns linked to the mental visualization
of movement, and then translate these into instructions for controlling
external robotic or domotic devices. Such devices have the potential to be
useful in a broad variety of applications. While implementing a system that
would help individuals restore some freedom levels, the interpretation of
(Electroencephalography) EEG data remains a complex and unsolved problem. In
the literature, the classification of left and right imagined movements has
been extensively studied. This study introduces a novel pipeline that makes use
of machine learning techniques for classifying MI EEG data. The entire
framework is capable of accurately categorizing left and imagined motions, as
well as rest phases, for a set of 52 subjects who performed a MI task. We
trained a within subject model on each individual subject. The methodology has
been offline evaluated and compared to four studies that are currently the
state-of-the-art regarding the specified dataset. The results show that our
proposed framework could be used with MI-BCI systems in light of its failsafe
classification performances, i.e. 99.5% in accuracy

</details>
