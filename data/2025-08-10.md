<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 101]
- [cs.CL](#cs.CL) [Total: 41]
- [eess.SY](#eess.SY) [Total: 10]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.LG](#cs.LG) [Total: 97]
- [cs.RO](#cs.RO) [Total: 29]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.DS](#cs.DS) [Total: 8]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 18]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.GT](#cs.GT) [Total: 3]
- [quant-ph](#quant-ph) [Total: 53]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration](https://arxiv.org/abs/2508.04797)
*Mohab Kishawy,Ali Abdellatif Hussein,Jun Chen*

Main category: cs.CV

TL;DR: 提出RetinexDual，一种新颖的UHD图像修复框架，包含SAMBA和FIA两个子网络，在四个UHD IR任务上均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的UHD IR方法（如下采样或纯频域方法）存在信息丢失或无法处理空间局部退化的问题。为克服这些限制，需要新的方法。

Method: 提出了一种基于Retinex理论的名为RetinexDual的新框架，该框架包含两个子网络：Scale-Attentive maMBA (SAMBA) 和 Frequency Illumination Adaptor (FIA)。SAMBA通过粗到精机制校正反射率分量，FIA则在频域利用全局上下文校正颜色和光照失真。

Result: RetinexDual在四个UHD IR任务上（deraining, deblurring, dehazing, LLIE）的定性和定量评估中均取得了优于现有方法的性能。

Conclusion: RetinexDual框架在deraining、deblurring、dehazing和LLIE四个UHD IR任务上均优于现有方法，消融实验验证了其各组件的有效性和分支设计的必要性。

Abstract: Advancements in image sensing have elevated the importance of
Ultra-High-Definition Image Restoration (UHD IR). Traditional methods, such as
extreme downsampling or transformation from the spatial to the frequency
domain, encounter significant drawbacks: downsampling induces irreversible
information loss in UHD images, while our frequency analysis reveals that pure
frequency-domain approaches are ineffective for spatially confined image
artifacts, primarily due to the loss of degradation locality. To overcome these
limitations, we present RetinexDual, a novel Retinex theory-based framework
designed for generalized UHD IR tasks. RetinexDual leverages two complementary
sub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination
Adaptor (FIA). SAMBA, responsible for correcting the reflectance component,
utilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba,
which effectively reduces artifacts and restores intricate details. On the
other hand, FIA ensures precise correction of color and illumination
distortions by operating in the frequency domain and leveraging the global
context provided by it. Evaluating RetinexDual on four UHD IR tasks, namely
deraining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows
that it outperforms recent methods qualitatively and quantitatively. Ablation
studies demonstrate the importance of employing distinct designs for each
branch in RetinexDual, as well as the effectiveness of its various components.

</details>


### [2] [ACM Multimedia Grand Challenge on ENT Endoscopy Analysis](https://arxiv.org/abs/2508.04801)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Thao Thi Phuong Dao,Ha Nguyen Thi,Tien To Vu Thuy,Uyen Hanh Tran,Tam V. Nguyen,Thanh Dinh Le,Minh-Triet Tran*

Main category: cs.CV

TL;DR: ENTRep是一个包含细粒度分类和检索任务的新型耳鼻喉内窥镜图像数据集，旨在改善该领域自动化分析的基准。


<details>
  <summary>Details</summary>
Motivation: 耳鼻喉科（ENT）护理中内窥镜图像的自动化分析至关重要但尚不发达，这受到设备和操作者差异、病灶细微和局部化、以及侧别位和声带状态等细粒度区分的限制。除了分类，临床医生还需要可靠地检索视觉上和文本上相似的病例，而现有基准很少支持这些功能。

Method: 本研究引入了ENTRep数据集，这是一个包含专家标注的耳鼻喉内窥镜图像的数据集，并标注了解剖区域、正常/异常状态以及双语（越南语和英语）的文字描述。此外，研究定义了三个基准任务，标准化了提交协议，并在公共和私有测试集上进行了评估。

Result: ENTRep数据集包含了专家标注的细粒度解剖分类和双语临床监督下的图像到图像和文本到图像检索。研究对公开和私有测试集进行了评估，并报告了表现最佳团队的结果，提供了见解讨论。

Conclusion: 该研究介绍了ENTRep数据集和基准测试，旨在推动耳鼻喉内窥镜图像的自动化分析，包括细粒度解剖分类和图像/文本检索。

Abstract: Automated analysis of endoscopic imagery is a critical yet underdeveloped
component of ENT (ear, nose, and throat) care, hindered by variability in
devices and operators, subtle and localized findings, and fine-grained
distinctions such as laterality and vocal-fold state. In addition to
classification, clinicians require reliable retrieval of similar cases, both
visually and through concise textual descriptions. These capabilities are
rarely supported by existing public benchmarks. To this end, we introduce
ENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis,
which integrates fine-grained anatomical classification with image-to-image and
text-to-image retrieval under bilingual (Vietnamese and English) clinical
supervision. Specifically, the dataset comprises expert-annotated images,
labeled for anatomical region and normal or abnormal status, and accompanied by
dual-language narrative descriptions. In addition, we define three benchmark
tasks, standardize the submission protocol, and evaluate performance on public
and private test splits using server-side scoring. Moreover, we report results
from the top-performing teams and provide an insight discussion.

</details>


### [3] [CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework](https://arxiv.org/abs/2508.04816)
*Sriram Mandalika,Lalitha V*

Main category: cs.CV

TL;DR: CoMAD是一种创新的、轻量级的自监督学习知识蒸馏框架，它通过非对称掩码和共识门控机制，有效地将多个强大的预训练Vision Transformer压缩到一个小模型中，并在图像分类和密集预测任务上取得了优异的性能，特别适合资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法（如对比学习和掩码图像建模）虽然能从无标签数据中学习到强大的表示，但通常是孤立预训练的，忽视了互补信息，并且模型庞大，不适合资源受限的部署。为了解决这些问题，需要一种能够整合多个教师知识并生成紧凑模型的框架。

Method: 提出了一种名为CoMAD（Consensus-oriented Masked Distillation）的轻量级、无参数框架。该框架通过非对称掩码策略，让学生网络仅看到25%的图像块，而三个预训练的ViT-Base教师（MAE、MoCo v3、iBOT）则接收不同程度的掩码。通过线性适配器和层归一化将教师嵌入对齐到学生空间，并利用结合了余弦相似度和教师间一致性的联合共识门控机制来融合教师知识。学生网络通过对可见块和重建特征图的双层KL散度进行训练，以同时捕捉局部和全局结构。

Result: 在ImageNet-1K上，CoMAD的ViT-Tiny模型达到了75.4%的Top-1准确率，超越了先前最先进水平0.4%。在密集预测任务中，该模型在ADE20K上达到了47.3%的mIoU，在MS-COCO上分别达到了44.5%的边界框平均精度和40.5%的掩码平均精度，在紧凑型自监督学习知识蒸馏领域确立了新的最先进水平。

Conclusion: CoMAD框架成功地将多种先进的自监督视觉Transformer知识迁移到一个紧凑的学生网络中，在ImageNet-1K、ADE20K和MS-COCO等基准测试中取得了当前最先进的性能，特别是在资源受限的部署场景下。

Abstract: Numerous self-supervised learning paradigms, such as contrastive learning and
masked image modeling, learn powerful representations from unlabeled data but
are typically pretrained in isolation, overlooking complementary insights and
yielding large models that are impractical for resource-constrained deployment.
To overcome these challenges, we introduce Consensus-oriented Masked
Distillation (CoMAD), a lightweight, parameter-free framework that unifies
knowledge from multiple current state-of-the-art self-supervised Vision
Transformers into a compact student network. CoMAD distills from three
pretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct
semantic and contextual priors. Rather than naively averaging teacher outputs,
we apply asymmetric masking: the student sees only 25 percent of patches while
each teacher receives a progressively lighter, unique mask, forcing the student
to interpolate missing features under richer contexts. Teacher embeddings are
aligned to the student's space via a linear adapter and layer normalization,
then fused through our joint consensus gating, which weights each token by
combining cosine affinity with inter-teacher agreement. The student is trained
with dual-level KL divergence on visible tokens and reconstructed feature maps,
capturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny
achieves 75.4 percent Top-1, an increment of 0.4 percent over the previous
state-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU
on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average
precision on MS-COCO, establishing a new state-of-the-art in compact SSL
distillation.

</details>


### [4] [Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models](https://arxiv.org/abs/2508.04818)
*Mehrdad Moradi,Marco Grasso,Bianca Maria Colosimo,Kamran Paynabar*

Main category: cs.CV

TL;DR: RADAR是一种无需重建的实时异常检测方法，直接从注意力扩散模型生成异常图，提高了准确性和效率，并且在MVTec-AD和3D打印材料数据集上均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于重建的扩散模型异常检测方法存在三个主要挑战：1. 重建过程计算成本高，不适用于实时应用；2. 对于复杂或细微的模式，重建的图像可能与原始输入不同；3. 难以选择合适的中间噪声水平，这通常需要异常的先验知识，而在无监督设置中这一假设不成立。

Method: RADAR（Reconstruction-free Anomaly Detection with Attention-based diffusion models in Real-time）是一种新的异常检测方法，它直接从扩散模型生成异常图，而不是像以前的方法那样进行图像重建。

Result: RADAR克服了现有方法的局限性，提高了检测准确性和计算效率，并在3D打印材料和MVTec-AD数据集上取得了优于最先进方法的性能。

Conclusion: RADAR在MVTec-AD数据集上将F1分数提高了7%，在3D打印材料数据集上提高了13%，并且在准确率、精确率、召回率和F1分数等关键指标上均优于最先进的基于扩散和其他统计机器学习的方法。

Abstract: Generative models have demonstrated significant success in anomaly detection
and segmentation over the past decade. Recently, diffusion models have emerged
as a powerful alternative, outperforming previous approaches such as GANs and
VAEs. In typical diffusion-based anomaly detection, a model is trained on
normal data, and during inference, anomalous images are perturbed to a
predefined intermediate step in the forward diffusion process. The
corresponding normal image is then reconstructed through iterative reverse
sampling.
  However, reconstruction-based approaches present three major challenges: (1)
the reconstruction process is computationally expensive due to multiple
sampling steps, making real-time applications impractical; (2) for complex or
subtle patterns, the reconstructed image may correspond to a different normal
pattern rather than the original input; and (3) Choosing an appropriate
intermediate noise level is challenging because it is application-dependent and
often assumes prior knowledge of anomalies, an assumption that does not hold in
unsupervised settings.
  We introduce Reconstruction-free Anomaly Detection with Attention-based
diffusion models in Real-time (RADAR), which overcomes the limitations of
reconstruction-based anomaly detection. Unlike current SOTA methods that
reconstruct the input image, RADAR directly produces anomaly maps from the
diffusion model, improving both detection accuracy and computational
efficiency. We evaluate RADAR on real-world 3D-printed material and the
MVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and
statistical machine learning models across all key metrics, including accuracy,
precision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on
MVTec-AD and 13% on the 3D-printed material dataset compared to the next best
model.
  Code available at: https://github.com/mehrdadmoradi124/RADAR

</details>


### [5] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: 开发了一种基于事件相机的、经济高效的深度学习眼动追踪算法，准确率达81%，旨在提升VR/AR用户体验。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种可解释且具有成本效益的眼动追踪算法，以应用于消费电子产品（如VR和AR设备），从而提高设备的舒适度和用户体验。

Method: 利用事件相机作为输入，通过深度学习（特别是CNN_LSTM模型）来追踪眼球的中心位置(x, y)，并预测人类注意力。

Result: 成功开发了一个基于事件相机的眼动追踪算法，并验证了CNN_LSTM模型的有效性，准确率达到81%。

Conclusion: 所提出的CNN_LSTM模型在眼动追踪任务中达到了约81%的准确率，未来将探索使用LRP来提高模型的可解释性和预测性能。

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [6] [LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction](https://arxiv.org/abs/2508.04847)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.CV

TL;DR: LuKAN是一种基于 Kolmogorov-Arnold Networks (KAN) 和 Lucas polynomial 激活函数的新型3D人体运动预测模型。它通过离散小波变换、空间投影层和时间依赖性学习器来编码时间信息、捕捉关节依赖关系和高效逼近函数。LuKAN在保持准确性的同时，提高了计算效率，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实现预测准确性和计算效率的平衡方面常常面临局限性。

Method: LuKAN模型首先使用离散小波变换对输入运动序列中的时间信息进行编码，然后使用空间投影层来捕获关节间的依赖关系，确保人体的结构一致性。LuKAN的核心是时间依赖性学习器，它采用由 Lucas polynomial 参数化的 KAN 层进行高效函数逼近。最后，逆离散小波变换在时域中重建运动序列，生成时间上连贯的预测。

Result: LuKAN模型在预测准确性和计算效率方面取得了良好的平衡，并在三个基准数据集上取得了具有竞争力的性能。

Conclusion: LuKAN在三个基准数据集上的广泛实验证明，与强大的基线相比，我们的模型在定量和定性评估中都具有竞争性能。此外，其紧凑的架构以及 Lucas polynomials 的线性递归确保了计算效率。

Abstract: The goal of 3D human motion prediction is to forecast future 3D poses of the
human body based on historical motion data. Existing methods often face
limitations in achieving a balance between prediction accuracy and
computational efficiency. In this paper, we present LuKAN, an effective model
based on Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations.
Our model first applies the discrete wavelet transform to encode temporal
information in the input motion sequence. Then, a spatial projection layer is
used to capture inter-joint dependencies, ensuring structural consistency of
the human body. At the core of LuKAN is the Temporal Dependency Learner, which
employs a KAN layer parameterized by Lucas polynomials for efficient function
approximation. These polynomials provide computational efficiency and an
enhanced capability to handle oscillatory behaviors. Finally, the inverse
discrete wavelet transform reconstructs motion sequences in the time domain,
generating temporally coherent predictions. Extensive experiments on three
benchmark datasets demonstrate the competitive performance of our model
compared to strong baselines, as evidenced by both quantitative and qualitative
evaluations. Moreover, its compact architecture coupled with the linear
recurrence of Lucas polynomials, ensures computational efficiency.

</details>


### [7] [VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence](https://arxiv.org/abs/2508.04852)
*Chenhui Qiang,Zhaoyang Wei,Xumeng Han Zipeng Wang,Siyao Li,Xiangyuan Lan,Jianbin Jiao,Zhenjun Han*

Main category: cs.CV

TL;DR: VER-Bench通过包含细微视觉线索和结构化证据的问题，评估MLLMs的细粒度视觉理解和推理能力，结果显示现有模型在这方面仍有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在评估MLLMs的视觉能力方面存在不足，要么侧重于局部细节但缺乏深度推理，要么侧重于显着图像元素但可能忽略需要复杂分析的细微线索。然而，深刻的视觉理解和复杂推理依赖于对细微、不显眼的局部细节的解释，这些细节通常包含更丰富、更关键的信息。

Method: VER-Bench是一个新颖的框架，包含374个精心设计的问题，涵盖地理空间、时间、情境、意图、系统状态和符号推理等多个方面。每个问题都附带结构化证据，包括视觉线索和基于这些线索的问题相关推理。

Result: VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性。

Conclusion: VER-Bench的测试结果表明，当前的MLLMs在提取细微视觉线索和构建基于证据的论证方面存在局限性，需要加强模型在细粒度视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类人分析。

Abstract: With the rapid development of MLLMs, evaluating their visual capabilities has
become increasingly crucial. Current benchmarks primarily fall into two main
types: basic perception benchmarks, which focus on local details but lack deep
reasoning (e.g., "what is in the image?"), and mainstream reasoning benchmarks,
which concentrate on prominent image elements but may fail to assess subtle
clues requiring intricate analysis. However, profound visual understanding and
complex reasoning depend more on interpreting subtle, inconspicuous local
details than on perceiving salient, macro-level objects. These details, though
occupying minimal image area, often contain richer, more critical information
for robust analysis. To bridge this gap, we introduce the VER-Bench, a novel
framework to evaluate MLLMs' ability to: 1) identify fine-grained visual clues,
often occupying on average just 0.25% of the image area; 2) integrate these
clues with world knowledge for complex reasoning. Comprising 374 carefully
designed questions across Geospatial, Temporal, Situational, Intent, System
State, and Symbolic reasoning, each question in VER-Bench is accompanied by
structured evidence: visual clues and question-related reasoning derived from
them. VER-Bench reveals current models' limitations in extracting subtle visual
evidence and constructing evidence-based arguments, highlighting the need to
enhance models's capabilities in fine-grained visual evidence extraction,
integration, and reasoning for genuine visual understanding and human-like
analysis. Dataset and additional materials are available
https://github.com/verbta/ACMMM-25-Materials.

</details>


### [8] [Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications](https://arxiv.org/abs/2508.04868)
*Noreen Anwar,Guillaume-Alexandre Bilodeau,Wassim Bouachir*

Main category: cs.CV

TL;DR: DAMM是一个新颖的Transformer-based object detector框架，通过多模态查询和双流注意力解决了现有方法的不足，并在多个基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer-based object detectors在遮挡、细粒度定位和由于固定查询及密集注意力引起的计算效率方面存在不足。

Method: DAMM框架结合了查询适应和结构化交叉注意力，并采用了三种查询：基于视觉-语言模型的表观查询、使用多边形嵌入的位置查询以及用于通用场景覆盖的随机学习查询。此外，其双流交叉注意力模块分别优化语义和空间特征。

Result: DAMM在四个具有挑战性的基准测试中取得了最先进的性能。

Conclusion: DAMM在四个具有挑战性的基准测试中取得了最先进的平均精度（AP）和召回率，证明了多模态查询适应和双流注意力的有效性。

Abstract: Transformer-based object detectors often struggle with occlusions,
fine-grained localization, and computational inefficiency caused by fixed
queries and dense attention. We propose DAMM, Dual-stream Attention with
Multi-Modal queries, a novel framework introducing both query adaptation and
structured cross-attention for improved accuracy and efficiency. DAMM
capitalizes on three types of queries: appearance-based queries from
vision-language models, positional queries using polygonal embeddings, and
random learned queries for general scene coverage. Furthermore, a dual-stream
cross-attention module separately refines semantic and spatial features,
boosting localization precision in cluttered scenes. We evaluated DAMM on four
challenging benchmarks, and it achieved state-of-the-art performance in average
precision (AP) and recall, demonstrating the effectiveness of multi-modal query
adaptation and dual-stream attention. Source code is at:
\href{https://github.com/DET-LIP/DAMM}{GitHub}.

</details>


### [9] [Revealing Temporal Label Noise in Multimodal Hateful Video Classification](https://arxiv.org/abs/2508.04900)
*Shuonan Yang,Tailin Chen,Rahul Singh,Jiangbei Yue,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 仇恨视频检测的标注方法需要关注时间粒度，因为视频中的仇恨内容通常只占一部分，粗粒度的标注会影响模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决了现有仇恨视频检测方法依赖于粗粒度、视频级标注而忽略了时间粒度的问题，这种方法会引入显著的标签噪声。

Method: 通过使用标注的时间戳修剪仇恨视频，并在细粒度层面上分离出明确的仇恨内容和非仇恨内容。

Result: 时间戳噪声会根本性地改变模型的决策边界并削弱分类置信度，揭示了仇恨言论表达的内在语境依赖性和时间连续性。

Conclusion: 该研究强调了时间敏感型模型和基准对于提高多模态仇恨视频检测鲁棒性和可解释性的重要性。

Abstract: The rapid proliferation of online multimedia content has intensified the
spread of hate speech, presenting critical societal and regulatory challenges.
While recent work has advanced multimodal hateful video detection, most
approaches rely on coarse, video-level annotations that overlook the temporal
granularity of hateful content. This introduces substantial label noise, as
videos annotated as hateful often contain long non-hateful segments. In this
paper, we investigate the impact of such label ambiguity through a fine-grained
approach. Specifically, we trim hateful videos from the HateMM and
MultiHateClip English datasets using annotated timestamps to isolate explicitly
hateful segments. We then conduct an exploratory analysis of these trimmed
segments to examine the distribution and characteristics of both hateful and
non-hateful content. This analysis highlights the degree of semantic overlap
and the confusion introduced by coarse, video-level annotations. Finally,
controlled experiments demonstrated that time-stamp noise fundamentally alters
model decision boundaries and weakens classification confidence, highlighting
the inherent context dependency and temporal continuity of hate speech
expression. Our findings provide new insights into the temporal dynamics of
multimodal hateful videos and highlight the need for temporally aware models
and benchmarks for improved robustness and interpretability. Code and data are
available at
https://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise.

</details>


### [10] [Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations](https://arxiv.org/abs/2508.04924)
*Zahidul Islam,Sujoy Paul,Mrigank Rochan*

Main category: cs.CV

TL;DR: Highlight-TTA是一个用于视频精彩片段检测的测试时自适应框架，通过结合辅助任务进行模型微调，提高了检测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频精彩片段检测方法通常使用通用的检测模型，无法适应不同测试视频的独特内容、风格、音频和视觉质量，导致泛化能力和检测性能下降。

Method: 提出了一种名为Highlight-TTA的测试时自适应框架，该框架将辅助任务（跨模态幻觉）与主要任务（精彩片段检测）联合优化，并通过元辅助训练方案来增强模型的适应能力和主要任务的性能。在测试阶段，利用辅助任务对模型进行自适应调整，以进一步提升精彩片段检测效果。

Result: 在三种最先进的精彩片段检测模型和三个基准数据集上进行的广泛实验表明，引入Highlight-TTA框架能够提升这些模型的性能，并取得更优越的结果。

Conclusion: Highlight-TTA框架通过在测试时自适应模型以匹配每个测试视频的特定特征，解决了现有视频精彩片段检测方法泛化能力不足的问题，并显著提高了检测性能。

Abstract: Existing video highlight detection methods, although advanced, struggle to
generalize well to all test videos. These methods typically employ a generic
highlight detection model for each test video, which is suboptimal as it fails
to account for the unique characteristics and variations of individual test
videos. Such fixed models do not adapt to the diverse content, styles, or audio
and visual qualities present in new, unseen test videos, leading to reduced
highlight detection performance. In this paper, we propose Highlight-TTA, a
test-time adaptation framework for video highlight detection that addresses
this limitation by dynamically adapting the model during testing to better
align with the specific characteristics of each test video, thereby improving
generalization and highlight detection performance. Highlight-TTA is jointly
optimized with an auxiliary task, cross-modality hallucinations, alongside the
primary highlight detection task. We utilize a meta-auxiliary training scheme
to enable effective adaptation through the auxiliary task while enhancing the
primary task. During testing, we adapt the trained model using the auxiliary
task on the test video to further enhance its highlight detection performance.
Extensive experiments with three state-of-the-art highlight detection models
and three benchmark datasets show that the introduction of Highlight-TTA to
these models improves their performance, yielding superior results.

</details>


### [11] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: HOW-Seg通过引入人类在循环（human-in-the-loop）机制，利用稀疏的人工标注和创新的原型构建及优化策略，解决了开放世界点云语义分割的效率和实用性问题，取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放世界点云语义分割（OW-Seg）中要么依赖资源密集型的离线增量学习，要么需要密集的标注数据，这限制了其实用性。

Method: HOW-Seg框架，首先在查询数据上构建类别原型以避免原型偏差；然后利用稀疏的人工标注进行原型细化；接着采用条件随机场（CRF）优化标签分配；最后通过迭代的人工反馈动态改进预测。

Result: HOW-Seg在稀疏标注（如单次点击）下，性能可媲美甚至超过了5次试验的（5-shot）最先进的泛化少样本分割（GFS-Seg）方法。使用更强的骨干网络和更密集的标注时，在S3DIS和ScanNetv2数据集上分别达到了85.27%和66.37%的mIoU，显著优于其他方法。

Conclusion: HOW-Seg是一个新颖的框架，通过利用稀疏的人工标注，在开放世界点云语义分割任务中实现了高性能，并优于现有的先进方法。

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [12] [Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)
*Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong*

Main category: cs.CV

TL;DR: 提出校准令牌，使现有深度估计器无需重新训练即可用于鱼眼图像，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大量透视图像训练的FMDEs，在面对因相机校准参数（内参、畸变）变化带来的协变量偏移时，会导致错误的深度估计。本研究旨在解决FMDEs在鱼眼图像上的应用问题，克服因相机模型差异导致的性能下降。

Method: 通过引入校准令牌（Calibration Tokens）作为轻量级适配机制，调整编码鱼眼图像的潜在嵌入，使其分布与编码透视图像的潜在嵌入对齐，从而实现FMDEs在鱼眼相机上的复用。该方法是自监督的，不依赖鱼眼图像，而是利用公开的大规模透视图像数据集，通过将透视图像校准为鱼眼图像并强制估计的一致性来实现。

Result: 在室内外场景的多种FMDEs和数据集上进行了评估，结果表明该方法能够持续改进性能，并且使用单一校准令牌集即可同时处理透视和鱼眼图像，优于当前最先进的方法。

Conclusion: 提出了一种名为“校准令牌”的轻量级自监督方法，通过调整潜在嵌入来对齐鱼眼图像和透视图像的分布，从而在无需重新训练的情况下将现有单目深度估计器（FMDEs）扩展到鱼眼图像，并在室内外场景中实现了性能提升。

Abstract: We propose a method to extend foundational monocular depth estimators
(FMDEs), trained on perspective images, to fisheye images. Despite being
trained on tens of millions of images, FMDEs are susceptible to the covariate
shift introduced by changes in camera calibration (intrinsic, distortion)
parameters, leading to erroneous depth estimates. Our method aligns the
distribution of latent embeddings encoding fisheye images to those of
perspective images, enabling the reuse of FMDEs for fisheye cameras without
retraining or finetuning. To this end, we introduce a set of Calibration Tokens
as a light-weight adaptation mechanism that modulates the latent embeddings for
alignment. By exploiting the already expressive latent space of FMDEs, we posit
that modulating their embeddings avoids the negative impact of artifacts and
loss introduced in conventional recalibration or map projection to a canonical
reference frame in the image space. Our method is self-supervised and does not
require fisheye images but leverages publicly available large-scale perspective
image datasets. This is done by recalibrating perspective images to fisheye
images, and enforcing consistency between their estimates during training. We
evaluate our approach with several FMDEs, on both indoors and outdoors, where
we consistently improve over state-of-the-art methods using a single set of
tokens for both. Code available at:
https://github.com/JungHeeKim29/calibration-token.

</details>


### [13] [Toward Errorless Training ImageNet-1k](https://arxiv.org/abs/2508.04941)
*Bo Deng,Levi Heath*

Main category: cs.CV

TL;DR: 通过一种新方法训练的前馈神经网络在ImageNet数据集上达到了98.3%的准确率，但由于可能存在的数据集双标签问题未能达到100%的准确率。


<details>
  <summary>Details</summary>
Motivation: 该模型未能达到100%的准确率可能是由于数据集中存在带有不同标签的重复图像的双标签问题。

Method: 使用[5]中提出的新方法，在ImageNet 2012竞赛数据集上训练前馈人工神经网络。

Result: 模型达到了98.3%的准确率，99.69%的Top-1准确率，并且在10个数据分区上平均正确分类了285.9个标签。表现最好的模型使用了322,430,160个参数，并具有4位小数的精度。

Conclusion: 该模型未能达到100%的准确率可能是由于数据集中存在带有不同标签的重复图像的双标签问题。

Abstract: In this paper, we describe a feedforward artificial neural network trained on
the ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy
rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are
perfectly classified over the 10 batch partitions of the dataset. The best
performing model uses 322,430,160 parameters, with 4 decimal places precision.
We conjecture that the reason our model does not achieve a 100% accuracy rate
is due to a double-labeling problem, by which there are duplicate images in the
dataset with different labels.

</details>


### [14] [F2PASeg: Feature Fusion for Pituitary Anatomy Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2508.05465)
*Lumin Chen,Zhiying Wu,Tianye Lei,Xuexue Bai,Ming Feng,Yuxi Wang,Gaofeng Meng,Zhen Lei,Hongbin Liu*

Main category: cs.CV

TL;DR: This paper introduces the PAS dataset and F2PASeg model for pituitary anatomy segmentation to improve surgical safety. F2PASeg uses a Feature Fusion module to handle variations and achieves real-time segmentation of critical structures.


<details>
  <summary>Details</summary>
Motivation: Pituitary tumors often cause deformation or encapsulation of adjacent vital structures. Anatomical structure segmentation can provide surgeons with early warnings of regions that pose surgical risks, thereby enhancing the safety of pituitary surgery. Pixel-level annotated video stream datasets for pituitary surgeries are rare, posing a challenge.

Method: The paper proposes F2PASeg, which incorporates a Feature Fusion module to refine anatomical structure segmentation by leveraging both high-resolution image features and deep semantic embeddings, enhancing robustness against intraoperative variations. Data augmentation techniques are applied to mitigate class imbalance. The study introduces the Pituitary Anatomy Segmentation (PAS) dataset, comprising 7,845 time-coherent images extracted from 120 videos.

Result: Experimental results demonstrate that F2PASeg consistently segments critical anatomical structures in real time.

Conclusion: F2PASeg consistently segments critical anatomical structures in real time, providing a reliable solution for intraoperative pituitary surgery planning.

Abstract: Pituitary tumors often cause deformation or encapsulation of adjacent vital
structures. Anatomical structure segmentation can provide surgeons with early
warnings of regions that pose surgical risks, thereby enhancing the safety of
pituitary surgery. However, pixel-level annotated video stream datasets for
pituitary surgeries are extremely rare. To address this challenge, we introduce
a new dataset for Pituitary Anatomy Segmentation (PAS). PAS comprises 7,845
time-coherent images extracted from 120 videos. To mitigate class imbalance, we
apply data augmentation techniques that simulate the presence of surgical
instruments in the training data. One major challenge in pituitary anatomy
segmentation is the inconsistency in feature representation due to occlusions,
camera motion, and surgical bleeding. By incorporating a Feature Fusion module,
F2PASeg is proposed to refine anatomical structure segmentation by leveraging
both high-resolution image features and deep semantic embeddings, enhancing
robustness against intraoperative variations. Experimental results demonstrate
that F2PASeg consistently segments critical anatomical structures in real time,
providing a reliable solution for intraoperative pituitary surgery planning.
Code: https://github.com/paulili08/F2PASeg.

</details>


### [15] [Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models](https://arxiv.org/abs/2508.04942)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: ProMIM是一种即插即用的框架，通过将掩码图像建模（MIM）融入条件提示学习，提高了视觉语言模型（VLM）的泛化能力，并减轻了过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在零样本学习方面表现优异，但在适应新任务时需要大量资源进行训练。而像CoOp和CoCoOp这样的提示学习技术虽然能够高效适应，但容易在已知类别上过拟合，限制了其向未见类别泛化的能力。因此，需要一种能够提高泛化能力并减轻过拟合的轻量级解决方案。

Method: ProMIM框架通过一种简单的掩码策略，在生成提示时结合掩码图像建模（MIM）的表示，以指导提示的生成。该框架即插即用，可以直接集成到CoOp和CoCoOp等现有方法中，而无需修改其核心架构。

Result: 在零样本和少样本分类任务的广泛实验中，ProMIM被证明能够持续提升现有方法的泛化性能。

Conclusion: ProMIM通过集成掩码图像建模（MIM）到现有的视觉语言模型（VLM）和提示学习框架中，有效地增强了条件提示学习。该框架通过采用一种简单的掩码策略来生成健壮的、实例条件的提示，从而提高了特征鲁棒性并减轻了过拟合，同时计算成本增加极小。实验证明，ProMIM能够持续提升现有方法的泛化性能，为实际的视觉语言应用提供了一种实用的轻量级解决方案。

Abstract: Vision-language models (VLMs) like CLIP excel in zero-shot learning but often
require resource-intensive training to adapt to new tasks. Prompt learning
techniques, such as CoOp and CoCoOp, offer efficient adaptation but tend to
overfit to known classes, limiting generalization to unseen categories. We
introduce ProMIM, a plug-and-play framework that enhances conditional prompt
learning by integrating masked image modeling (MIM) into existing VLM
pipelines. ProMIM leverages a simple yet effective masking strategy to generate
robust, instance-conditioned prompts, seamlessly augmenting methods like CoOp
and CoCoOp without altering their core architectures. By masking only visible
image patches and using these representations to guide prompt generation,
ProMIM improves feature robustness and mitigates overfitting, all while
introducing negligible additional computational cost. Extensive experiments
across zero-shot and few-shot classification tasks demonstrate that ProMIM
consistently boosts generalization performance when plugged into existing
approaches, providing a practical, lightweight solution for real-world
vision-language applications.

</details>


### [16] [TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring](https://arxiv.org/abs/2508.04943)
*Zhu Xu,Ting Lei,Zhimin Li,Guan Wang,Qingchao Chen,Yuxin Peng,Yang liu*

Main category: cs.CV

TL;DR: 提出TRKT方法，通过关系感知知识挖掘和双流融合模块，解决了现有WS-DSGG方法中外部对象检测器在动态场景下表现不佳的问题，从而提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督动态场景图生成（WS-DSGG）方法依赖于现成的外部对象检测器来生成伪标签，但这些检测器在动态、关系感知的场景中表现不佳，导致定位不准确和置信度低。为了解决这些挑战，提出TRKT方法来增强关系感知动态场景中的检测能力。

Method: TRKT方法包含两个关键组件：1. 关系感知知识挖掘：利用对象和关系类别解码器生成类别特定的注意力图，突出对象区域和交互区域。提出跨帧注意力增强策略，利用相邻帧的光流来增强注意力图，使其具有运动感知能力并对运动模糊具有鲁棒性。2. 双流融合模块：将类别特定的注意力图集成到外部检测中，以优化对象定位并提高对象提议的置信度分数。

Result: TRKT方法在Action Genome数据集上实现了最先进的性能。

Conclusion: TRKT方法在Action Genome数据集上达到了最先进的性能。

Abstract: Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each
video frame by detecting objects and predicting their relationships. Weakly
Supervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized
scene graph from a single frame per video for training. Existing WS-DSGG
methods depend on an off-the-shelf external object detector to generate pseudo
labels for subsequent DSGG training. However, detectors trained on static,
object-centric images struggle in dynamic, relation-aware scenarios required
for DSGG, leading to inaccurate localization and low-confidence proposals. To
address the challenges posed by external object detectors in WS-DSGG, we
propose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)
method, which leverages knowledge to enhance detection in relation-aware
dynamic scenarios. TRKT is built on two key components:(1)Relation-aware
knowledge mining: we first employ object and relation class decoders that
generate category-specific attention maps to highlight both object regions and
interactive areas. Then we propose an Inter-frame Attention Augmentation
strategy that exploits optical flow for neighboring frames to enhance the
attention maps, making them motion-aware and robust to motion blur. This step
yields relation- and motion-aware knowledge mining for WS-DSGG. (2) we
introduce a Dual-stream Fusion Module that integrates category-specific
attention maps into external detections to refine object localization and boost
confidence scores for object proposals. Extensive experiments demonstrate that
TRKT achieves state-of-the-art performance on Action Genome dataset. Our code
is avaliable at https://github.com/XZPKU/TRKT.git.

</details>


### [17] [AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics](https://arxiv.org/abs/2508.04955)
*Stella Su,Marc Harary,Scott J. Rodig,William Lotter*

Main category: cs.CV

TL;DR: AdvDINO通过集成梯度反转层到DINOv2，实现了域对抗自监督学习，提高了在生物医学成像中处理域转移和批量效应的能力，从而学习到更鲁棒、更具生物学意义的表示，并改善了生存预测。


<details>
  <summary>Details</summary>
Motivation: 研究标准自监督学习方法在域转移（尤其是在生物医学成像中）方面的鲁棒性问题，以及批量效应可能掩盖真实生物信号的挑战。

Method: AdvDINO框架，通过集成梯度反转层到DINOv2架构中，实现域不变特征学习。

Result: 在超过546万个mIF图像瓦片上，AdvDINO发现了具有不同蛋白质组特征和预后意义的表型簇，并在基于注意力的多实例学习中提高了生存预测能力。

Conclusion: AdvDINO是一个将梯度反转层集成到DINOv2架构中的域对抗自监督学习框架，可学习域不变特征，应用于非小细胞肺癌患者的多路免疫荧光图像，可缓解幻灯片特异性偏差，学习到比非对抗基线更鲁棒、更具生物学意义的表示。

Abstract: Self-supervised learning (SSL) has emerged as a powerful approach for
learning visual representations without manual annotations. However, the
robustness of standard SSL methods to domain shift -- systematic differences
across data sources -- remains uncertain, posing an especially critical
challenge in biomedical imaging where batch effects can obscure true biological
signals. We present AdvDINO, a domain-adversarial self-supervised learning
framework that integrates a gradient reversal layer into the DINOv2
architecture to promote domain-invariant feature learning. Applied to a
real-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide
images from non-small cell lung cancer patients, AdvDINO mitigates
slide-specific biases to learn more robust and biologically meaningful
representations than non-adversarial baselines. Across $>5.46$ million mIF
image tiles, the model uncovers phenotype clusters with distinct proteomic
profiles and prognostic significance, and improves survival prediction in
attention-based multiple instance learning. While demonstrated on mIF data,
AdvDINO is broadly applicable to other imaging domains -- including radiology,
remote sensing, and autonomous driving -- where domain shift and limited
annotated data hinder model generalization and interpretability.

</details>


### [18] [UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS](https://arxiv.org/abs/2508.04968)
*Zhihao Guo,Peng Wang,Zidong Chen,Xiangyu Kong,Yan Lyu,Guanyu Gao,Liangxiu Han*

Main category: cs.CV

TL;DR: 通过引入可学习的不确定性和软 dropout 正则化，改进了 3DGS 在稀疏视图场景下的渲染质量，实现了更高的 PSNR 和更少的 Gaussian 使用量。


<details>
  <summary>Details</summary>
Motivation: 现有 3DGS 方法在渲染时对高斯权重均等处理，容易导致过拟合，尤其是在稀疏视图场景下。因此，有必要研究自适应加权高斯对渲染质量的影响。

Method: 提出了一种利用可学习的不确定性来适应性地调整 3D 高斯（Gaussians）渲染权重的 3DGS 方法。该不确定性用于指导高斯不透明度的可微分更新，并应用软可微分 dropout 正则化，将不确定性转化为控制最终高斯投影和混合过程的连续 dropout 概率。

Result: 该方法在稀疏视图 3D 合成任务中表现出色，在 MipNeRF 360 数据集上比 DropGaussian 提高了 3.27% 的 PSNR，并且在大多数数据集上实现了更高质量的重建，同时使用的 Gaussian 数量更少。

Conclusion: 通过可学习的不确定性正则化，该方法在稀疏视图 3D 合成中表现优于现有方法，在 MipNeRF 360 数据集上实现了比 DropGaussian 高 3.27% 的 PSNR 改进，并且在大多数数据集上使用更少的 Gaussian 实现了更高质量的重建。

Abstract: 3D Gaussian Splatting (3DGS) has become a competitive approach for novel view
synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian
projection and blending. However, Gaussians are treated equally weighted for
rendering in most 3DGS methods, making them prone to overfitting, which is
particularly the case in sparse-view scenarios. To address this, we investigate
how adaptive weighting of Gaussians affects rendering quality, which is
characterised by learned uncertainties proposed. This learned uncertainty
serves two key purposes: first, it guides the differentiable update of Gaussian
opacity while preserving the 3DGS pipeline integrity; second, the uncertainty
undergoes soft differentiable dropout regularisation, which strategically
transforms the original uncertainty into continuous drop probabilities that
govern the final Gaussian projection and blending process for rendering.
Extensive experimental results over widely adopted datasets demonstrate that
our method outperforms rivals in sparse-view 3D synthesis, achieving higher
quality reconstruction with fewer Gaussians in most datasets compared to
existing sparse-view approaches, e.g., compared to DropGaussian, our method
achieves 3.27\% PSNR improvements on the MipNeRF 360 dataset.

</details>


### [19] [CSRAP: Enhanced Canvas Attention Scheduling for Real-Time Mission Critical Perception](https://arxiv.org/abs/2508.04976)
*Md Iftekharul Islam Sakib,Yigong Hu,Tarek Abdelzaher*

Main category: cs.CV

TL;DR: This paper improves real-time object detection on edge devices by using flexible canvas frames and frame rates, achieving better accuracy and recall.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of executing high-resolution object detection under stringent latency constraints on limited edge computing resources by improving canvas-based attention scheduling.

Method: The paper extends prior canvas-based attention scheduling by allowing variable-size canvas frames and selectable canvas frame rates that may differ from the original data frame rate. The solution was evaluated using YOLOv11 on an NVIDIA Jetson Orin Nano with the Waymo Open Dataset.

Result: The results show that the additional degrees of freedom in canvas frame size and rate improve the attainable quality/cost trade-offs, leading to consistently higher mean average precision (mAP) and recall with respect to the state of the art.

Conclusion: The proposed method with variable-size canvas frames and selectable frame rates improves the quality/cost trade-offs for real-time object detection on edge platforms, achieving higher mAP and recall compared to the state of the art.

Abstract: Real-time perception on edge platforms faces a core challenge: executing
high-resolution object detection under stringent latency constraints on limited
computing resources. Canvas-based attention scheduling was proposed in earlier
work as a mechanism to reduce the resource demands of perception subsystems. It
consolidates areas of interest in an input data frame onto a smaller area,
called a canvas frame, that can be processed at the requisite frame rate. This
paper extends prior canvas-based attention scheduling literature by (i)
allowing for variable-size canvas frames and (ii) employing selectable canvas
frame rates that may depart from the original data frame rate. We evaluate our
solution by running YOLOv11, as the perception module, on an NVIDIA Jetson Orin
Nano to inspect video frames from the Waymo Open Dataset. Our results show that
the additional degrees of freedom improve the attainable quality/cost
trade-offs, thereby allowing for a consistently higher mean average precision
(mAP) and recall with respect to the state of the art.

</details>


### [20] [Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression](https://arxiv.org/abs/2508.04979)
*Zheng Chen,Mingde Zhou,Jinpei Guo,Jiale Yuan,Yifei Ji,Yulun Zhang*

Main category: cs.CV

TL;DR: SODEC是一种新颖的单步扩散图像压缩模型，通过使用信息丰富的潜在变量和单步解码来解决延迟和保真度问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于扩散的图像压缩模型存在的解码延迟过高和保真度差的问题。

Method: SODEC模型，利用预训练的基于VAE的模型生成信息丰富的潜在变量，并用单步解码取代了迭代去噪过程。此外，还引入了保真度引导模块来鼓励输出与原始图像一致，并设计了速率退火训练策略以在极低比特率下进行有效训练。

Result: SODEC在速率-失真-感知性能上显著优于现有方法，并且解码速度比以前的基于扩散的压缩模型提高了20倍以上。

Conclusion: SODEC在极低比特率下实现了优于现有方法和先前基于扩散的压缩模型的性能，同时将解码速度提高了20倍以上。

Abstract: Diffusion-based image compression has demonstrated impressive perceptual
performance. However, it suffers from two critical drawbacks: (1) excessive
decoding latency due to multi-step sampling, and (2) poor fidelity resulting
from over-reliance on generative priors. To address these issues, we propose
SODEC, a novel single-step diffusion image compression model. We argue that in
image compression, a sufficiently informative latent renders multi-step
refinement unnecessary. Based on this insight, we leverage a pre-trained
VAE-based model to produce latents with rich information, and replace the
iterative denoising process with a single-step decoding. Meanwhile, to improve
fidelity, we introduce the fidelity guidance module, encouraging output that is
faithful to the original image. Furthermore, we design the rate annealing
training strategy to enable effective training under extremely low bitrates.
Extensive experiments show that SODEC significantly outperforms existing
methods, achieving superior rate-distortion-perception performance. Moreover,
compared to previous diffusion-based compression models, SODEC improves
decoding speed by more than 20$\times$. Code is released at:
https://github.com/zhengchen1999/SODEC.

</details>


### [21] [Propagating Sparse Depth via Depth Foundation Model for Out-of-Distribution Depth Completion](https://arxiv.org/abs/2508.04984)
*Shenglun Chen,Xinzhu Ma,Hong Zhang,Haojie Li,Zhihui Wang*

Main category: cs.CV

TL;DR: 利用深度基础模型和双空间传播方法来提高深度补全的鲁棒性，无需大规模训练，并在分布外场景中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的模型依赖于精心准备但有限的数据，导致在分布外（OOD）场景下性能显著下降。拟议的框架旨在利用深度基础模型来提高深度补全模型的鲁棒性，而无需进行大规模的训练。

Method: 提出了一种新颖的深度补全框架，该框架利用深度基础模型来提取环境线索（包括结构和语义上下文），以指导稀疏深度信息向缺失区域的传播。设计了一种不包含任何可学习参数的双空间传播方法，以有效地在 3D 和 2D 空间中传播稀疏深度，以保持几何结构和局部一致性。引入了一个可学习的校正模块来逐步调整深度预测以接近真实深度。

Result: 该框架在分布外（OOD）场景下表现优异，并且优于现有的最先进的深度补全方法。

Conclusion: 该框架在分布外（OOD）场景下表现出色，并且优于现有的最先进的深度补全方法。

Abstract: Depth completion is a pivotal challenge in computer vision, aiming at
reconstructing the dense depth map from a sparse one, typically with a paired
RGB image. Existing learning based models rely on carefully prepared but
limited data, leading to significant performance degradation in
out-of-distribution (OOD) scenarios. Recent foundation models have demonstrated
exceptional robustness in monocular depth estimation through large-scale
training, and using such models to enhance the robustness of depth completion
models is a promising solution. In this work, we propose a novel depth
completion framework that leverages depth foundation models to attain
remarkable robustness without large-scale training. Specifically, we leverage a
depth foundation model to extract environmental cues, including structural and
semantic context, from RGB images to guide the propagation of sparse depth
information into missing regions. We further design a dual-space propagation
approach, without any learnable parameters, to effectively propagates sparse
depth in both 3D and 2D spaces to maintain geometric structure and local
consistency. To refine the intricate structure, we introduce a learnable
correction module to progressively adjust the depth prediction towards the real
depth. We train our model on the NYUv2 and KITTI datasets as in-distribution
datasets and extensively evaluate the framework on 16 other datasets. Our
framework performs remarkably well in the OOD scenarios and outperforms
existing state-of-the-art depth completion methods. Our models are released in
https://github.com/shenglunch/PSD.

</details>


### [22] [Unified modality separation: A vision-language framework for unsupervised domain adaptation](https://arxiv.org/abs/2508.04987)
*Xinyao Li,Jingjing Li,Zhekai Du,Lei Zhu,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的框架来解决视觉-语言模型（VLM）中的模态间隙问题，通过分离和分别处理模态特定和模态不变的组件，并结合模态自适应集成权重，实现了性能的大幅提升和计算效率的显著提高。


<details>
  <summary>Details</summary>
Motivation: 当前的无监督域自适应（UDA）方法在处理预训练视觉-语言模型（VLM）时，由于模态间隙的存在，只能迁移模态不变的知识，导致目标性能不佳。本研究旨在解决这一局限性，提出一种能够同时处理模态特定和模态不变组件的框架，以提高UDA的性能。

Method: 提出了一种统一的模态分离框架，用于处理视觉-语言模型（VLM）中的模态间隙。该框架在训练期间将不同模态的组件分离，并单独处理它们。在测试时，它会自动确定模态自适应集成权重，以最大化不同组件的协同作用。此外，还设计了一个模态差异度量来对样本进行分类，并利用模态不变样本进行跨模态对齐，同时利用不确定的样本来增强模型能力。

Result: 所提出的方法在计算效率方面提高了9倍，并在性能上获得了高达9%的提升。实验结果表明，该方法在各种骨干网络、基线、数据集和自适应设置上都具有有效性。

Conclusion: 该研究提出了一种统一的模态分离框架，该框架能够适应模态特定和模态不变的组件。通过将模态特定组件与模态不变组件分离，并采用模态自适应集成权重，研究声称可以提高性能并提高计算效率。

Abstract: Unsupervised domain adaptation (UDA) enables models trained on a labeled
source domain to handle new unlabeled domains. Recently, pre-trained
vision-language models (VLMs) have demonstrated promising zero-shot performance
by leveraging semantic information to facilitate target tasks. By aligning
vision and text embeddings, VLMs have shown notable success in bridging domain
gaps. However, inherent differences naturally exist between modalities, which
is known as modality gap. Our findings reveal that direct UDA with the presence
of modality gap only transfers modality-invariant knowledge, leading to
suboptimal target performance. To address this limitation, we propose a unified
modality separation framework that accommodates both modality-specific and
modality-invariant components. During training, different modality components
are disentangled from VLM features then handled separately in a unified manner.
At test time, modality-adaptive ensemble weights are automatically determined
to maximize the synergy of different components. To evaluate instance-level
modality characteristics, we design a modality discrepancy metric to categorize
samples into modality-invariant, modality-specific, and uncertain ones. The
modality-invariant samples are exploited to facilitate cross-modal alignment,
while uncertain ones are annotated to enhance model capabilities. Building upon
prompt tuning techniques, our methods achieve up to 9% performance gain with 9
times of computational efficiencies. Extensive experiments and analysis across
various backbones, baselines, datasets and adaptation settings demonstrate the
efficacy of our design.

</details>


### [23] [Modeling Rapid Contextual Learning in the Visual Cortex with Fast-Weight Deep Autoencoder Networks](https://arxiv.org/abs/2508.04988)
*Yue Li,Weifan Wang,Tai Sing Lee*

Main category: cs.CV

TL;DR: 本研究利用ViT和LoRA模型，通过熟悉度训练，在深度神经网络的早期层级中实现了对全局上下文的敏感性，并证明了快慢权重架构在模拟大脑学习机制中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了从功能角度探究熟悉度训练如何诱导深度神经网络的早期层级对全局上下文的敏感性，并验证快速权重在其中所起的作用。

Method: 本研究采用基于视觉Transformer (ViT) 的自动编码器，并利用低秩自适应 (LoRA) 技术来实现快速权重，以研究熟悉度训练如何诱导深度神经网络的早期层级对全局上下文的敏感性。

Result: 研究结果表明，所提出的ViT自动编码器的自注意力电路执行了与熟悉度效应的神经电路模型相似的流形变换；熟悉度训练将早期层级的潜在表征与包含全局上下文信息的顶层对齐；熟悉度训练拓宽了记忆图像上下文中的自注意力范围，并且LoRA实现的效果更为显著。

Conclusion: 本研究表明，熟悉度训练可以将全局敏感性引入到层次化网络中较早的层级，并且一种混合的快慢权重架构可能为研究大脑中全局上下文的快速学习提供一种可行的计算模型。

Abstract: Recent neurophysiological studies have revealed that the early visual cortex
can rapidly learn global image context, as evidenced by a sparsification of
population responses and a reduction in mean activity when exposed to familiar
versus novel image contexts. This phenomenon has been attributed primarily to
local recurrent interactions, rather than changes in feedforward or feedback
pathways, supported by both empirical findings and circuit-level modeling.
Recurrent neural circuits capable of simulating these effects have been shown
to reshape the geometry of neural manifolds, enhancing robustness and
invariance to irrelevant variations. In this study, we employ a Vision
Transformer (ViT)-based autoencoder to investigate, from a functional
perspective, how familiarity training can induce sensitivity to global context
in the early layers of a deep neural network. We hypothesize that rapid
learning operates via fast weights, which encode transient or short-term memory
traces, and we explore the use of Low-Rank Adaptation (LoRA) to implement such
fast weights within each Transformer layer. Our results show that (1) The
proposed ViT-based autoencoder's self-attention circuit performs a manifold
transform similar to a neural circuit model of the familiarity effect. (2)
Familiarity training aligns latent representations in early layers with those
in the top layer that contains global context information. (3) Familiarity
training broadens the self-attention scope within the remembered image context.
(4) These effects are significantly amplified by LoRA-based fast weights.
Together, these findings suggest that familiarity training introduces global
sensitivity to earlier layers in a hierarchical network, and that a hybrid
fast-and-slow weight architecture may provide a viable computational model for
studying rapid global context learning in the brain.

</details>


### [24] [Attribute Guidance With Inherent Pseudo-label For Occluded Person Re-identification](https://arxiv.org/abs/2508.04998)
*Rui Zhi,Zhen Yang,Haiyang Zhang*

Main category: cs.CV

TL;DR: AG-ReID 利用预训练模型提取细粒度属性，通过双重引导机制（整体+细粒度）来提升 Re-ID 性能，尤其在处理遮挡和细微差异方面效果显著，达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉-语言模型在 Re-ID 任务中虽然有效，但在遮挡场景下面临挑战，因为它们关注整体图像语义而忽略了细粒度属性信息，这在处理部分遮挡的行人或区分具有细微外观差异的个体时尤为明显。

Method: 提出了一种名为 AG-ReID 的新颖框架，该框架利用预训练模型提取细粒度语义属性，通过两阶段过程：1. 生成捕获细微视觉特征的属性伪标签；2. 引入结合整体和细粒度属性信息的双重引导机制，以增强图像特征提取。

Result: AG-ReID 框架在处理遮挡和细微属性差异方面取得了显著的改进，并在标准 Re-ID 场景中保持了有竞争力的性能，在多个广泛使用的数据集上实现了最先进的结果。

Conclusion: AG-ReID 框架在多个 Re-ID 数据集上取得了最先进的成果，在处理遮挡和细微属性差异方面表现出显著的改进，同时在标准 Re-ID 场景中保持了有竞争力的性能。

Abstract: Person re-identification (Re-ID) aims to match person images across different
camera views, with occluded Re-ID addressing scenarios where pedestrians are
partially visible. While pre-trained vision-language models have shown
effectiveness in Re-ID tasks, they face significant challenges in occluded
scenarios by focusing on holistic image semantics while neglecting fine-grained
attribute information. This limitation becomes particularly evident when
dealing with partially occluded pedestrians or when distinguishing between
individuals with subtle appearance differences. To address this limitation, we
propose Attribute-Guide ReID (AG-ReID), a novel framework that leverages
pre-trained models' inherent capabilities to extract fine-grained semantic
attributes without additional data or annotations. Our framework operates
through a two-stage process: first generating attribute pseudo-labels that
capture subtle visual characteristics, then introducing a dual-guidance
mechanism that combines holistic and fine-grained attribute information to
enhance image feature extraction. Extensive experiments demonstrate that
AG-ReID achieves state-of-the-art results on multiple widely-used Re-ID
datasets, showing significant improvements in handling occlusions and subtle
attribute differences while maintaining competitive performance on standard
Re-ID scenarios.

</details>


### [25] [CRAM: Large-scale Video Continual Learning with Bootstrapped Compression](https://arxiv.org/abs/2508.05001)
*Shivani Mall,Joao F. Henriques*

Main category: cs.CV

TL;DR: 本文提出了一种名为CRAM的视频持续学习方法，通过存储视频编码而非原始视频来显著降低内存需求，并提出了一种刷新视频编码的机制来解决在线压缩中的遗忘问题。该方法在大型基准测试中取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决视频持续学习（CL）中因视频数据的高内存需求而导致的挑战，尤其是在处理长视频和持续输入流时，这与通常的 the rehearsal-buffer 大小限制相悖。目标是实现更小的存储需求和已部署系统的自给自足能力，类似于生物学习。

Method: 本文提出了一种名为CRAM（Continually Refreshed Amodal Memory）的方法，该方法利用压缩视频（存储视频编码或嵌入而不是原始输入）并从滚动缓冲区中进行IID抽样来训练视频分类器。为了解决在线训练视频压缩器时出现的灾难性遗忘问题，CRAM提出了一种通过刷新视频编码的机制，这需要使用先前版本的网络进行仔细解压缩，然后使用新版本进行重新压缩。

Result: CRAM方法在EpicKitchens-100和Kinetics-700基准上，以低于2GB的内存存储了数千个相对较长的视频，并经验证其CL性能优于现有技术，同时内存占用大大减少。

Conclusion: 所提出的CRAM方法在EpicKitchens-100和Kinetics-700等大规模视频CL基准上，以显著减少的内存占用的方式，优于现有技术。

Abstract: Continual learning (CL) promises to allow neural networks to learn from
continuous streams of inputs, instead of IID (independent and identically
distributed) sampling, which requires random access to a full dataset. This
would allow for much smaller storage requirements and self-sufficiency of
deployed systems that cope with natural distribution shifts, similarly to
biological learning. We focus on video CL employing a rehearsal-based approach,
which reinforces past samples from a memory buffer. We posit that part of the
reason why practical video CL is challenging is the high memory requirements of
video, further exacerbated by long-videos and continual streams, which are at
odds with the common rehearsal-buffer size constraints. To address this, we
propose to use compressed vision, i.e. store video codes (embeddings) instead
of raw inputs, and train a video classifier by IID sampling from this rolling
buffer. Training a video compressor online (so not depending on any pre-trained
networks) means that it is also subject to catastrophic forgetting. We propose
a scheme to deal with this forgetting by refreshing video codes, which requires
careful decompression with a previous version of the network and recompression
with a new one. We name our method Continually Refreshed Amodal Memory (CRAM).
We expand current video CL benchmarks to large-scale settings, namely
EpicKitchens-100 and Kinetics-700, storing thousands of relatively long videos
in under 2 GB, and demonstrate empirically that our video CL method outperforms
prior art with a significantly reduced memory footprint.

</details>


### [26] [Multimodal Causal-Driven Representation Learning for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2508.05008)
*Xusheng Liang,Lihua Zhou,Nianxin Li,Miao Xu,Ziyang Song,Dong Yi,Jinlin Wu,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: MCDRL框架通过结合因果推断和CLIP，解决了医学图像分割中的域泛化问题，提高了分割精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于设备差异、操作伪影和成像模式等混淆因素导致的显著域转移，使得VLM在医学成像领域的应用面临挑战，并导致模型在未见过的域上泛化能力较差。为了解决这一限制，本研究提出MCDRL框架。

Method: 本研究提出了一种名为多模态因果驱动表示学习（MCDRL）的新框架，该框架结合了因果推断和视觉语言模型（VLM），以解决医学图像分割中的域泛化问题。MCDRL框架包含两个主要步骤：1. 利用CLIP的跨模态能力，通过文本提示识别候选病变区域并构建包含特定领域变化的混淆因素词典。2. 训练一个因果干预网络，利用该词典识别并消除特定领域变化的影响，同时保留对分割任务至关重要的解剖结构信息。

Result: 通过大量实验证明，MCDRL框架在医学图像分割任务中，分割精度和泛化能力均优于其他现有方法。

Conclusion: MCDRL框架在医学图像分割任务中表现出卓越的分割精度和鲁棒的泛化能力，并且一致优于其他现有方法。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot capabilities in various computer vision tasks. However, their
application to medical imaging remains challenging due to the high variability
and complexity of medical data. Specifically, medical images often exhibit
significant domain shifts caused by various confounders, including equipment
differences, procedure artifacts, and imaging modes, which can lead to poor
generalization when models are applied to unseen domains. To address this
limitation, we propose Multimodal Causal-Driven Representation Learning
(MCDRL), a novel framework that integrates causal inference with the VLM to
tackle domain generalization in medical image segmentation. MCDRL is
implemented in two steps: first, it leverages CLIP's cross-modal capabilities
to identify candidate lesion regions and construct a confounder dictionary
through text prompts, specifically designed to represent domain-specific
variations; second, it trains a causal intervention network that utilizes this
dictionary to identify and eliminate the influence of these domain-specific
variations while preserving the anatomical structural information critical for
segmentation tasks. Extensive experiments demonstrate that MCDRL consistently
outperforms competing methods, yielding superior segmentation accuracy and
exhibiting robust generalizability.

</details>


### [27] [AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content](https://arxiv.org/abs/2508.05016)
*Shushi Wang,Chunyi Li,Zicheng Zhang,Han Zhou,Wei Dong,Jun Chen,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 该研究提出了AU-IQA数据集，用于评估AI增强的UGC（AI-UGC）的图像质量。研究评估了现有图像质量评估方法在AI-UGC上的表现，并指出了该领域模型评估的不足。


<details>
  <summary>Details</summary>
Motivation: AI图像增强技术虽然广泛应用于各种视觉应用，但缺乏专门的质量评估模型是一个重要的限制因素，阻碍了用户体验和增强方法的进步。现有的感知质量评估方法在单独评估UGC和AIGC时表现良好，但对结合了两者的AI增强UGC（AI-UGC）的有效性探索不足。

Method: 构建AU-IQA数据集（包含4,800张AI-UGC图像，涵盖超分辨率、低光增强、去噪三种增强类型），并评估了一系列现有的图像质量评估模型（包括传统IQA方法和大型多模态模型）。

Result: 在AU-IQA数据集上，对一系列现有的图像质量评估模型进行了评估，并对当前方法在评估AI-UGC感知质量方面的表现进行了全面的分析。

Conclusion: 评估现有方法在AI-UGC感知质量评估方面的表现

Abstract: AI-based image enhancement techniques have been widely adopted in various
visual applications, significantly improving the perceptual quality of
user-generated content (UGC). However, the lack of specialized quality
assessment models has become a significant limiting factor in this field,
limiting user experience and hindering the advancement of enhancement methods.
While perceptual quality assessment methods have shown strong performance on
UGC and AIGC individually, their effectiveness on AI-enhanced UGC (AI-UGC)
which blends features from both, remains largely unexplored. To address this
gap, we construct AU-IQA, a benchmark dataset comprising 4,800 AI-UGC images
produced by three representative enhancement types which include
super-resolution, low-light enhancement, and denoising. On this dataset, we
further evaluate a range of existing quality assessment models, including
traditional IQA methods and large multimodal models. Finally, we provide a
comprehensive analysis of how well current approaches perform in assessing the
perceptual quality of AI-UGC. The access link to the AU-IQA is
https://github.com/WNNGGU/AU-IQA-Dataset.

</details>


### [28] [Skin-SOAP: A Weakly Supervised Framework for Generating Structured SOAP Notes](https://arxiv.org/abs/2508.05019)
*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: 提出skin-SOAP框架，用图像和少量文本自动生成皮肤病SOAP笔记，效果好，减少人工负担。


<details>
  <summary>Details</summary>
Motivation: 为了解决皮肤癌早期诊断和治疗的关键性，以及临床医生手动生成SOAP笔记的劳动密集型问题和导致的职业倦怠。

Method: 提出了一种名为skin-SOAP的弱监督多模态框架，该框架能够从有限的输入（包括病灶图像和稀疏的临床文本）生成临床SOAP笔记。

Result: skin-SOAP框架在关键的临床相关性指标上取得了与GPT-4o、Claude和DeepSeek Janus Pro相当的性能。此外，还引入了MedConceptEval和Clinical Coherence Score (CCS)两个新指标来评估临床相关性。

Conclusion: skin-SOAP框架在生成临床SOAP笔记方面表现出色，能够与GPT-4o等先进模型相媲美，同时减少了对手动标注的依赖，为临床文档自动化提供了一种可扩展的解决方案。

Abstract: Skin carcinoma is the most prevalent form of cancer globally, accounting for
over $8 billion in annual healthcare expenditures. Early diagnosis, accurate
and timely treatment are critical to improving patient survival rates. In
clinical settings, physicians document patient visits using detailed SOAP
(Subjective, Objective, Assessment, and Plan) notes. However, manually
generating these notes is labor-intensive and contributes to clinician burnout.
In this work, we propose skin-SOAP, a weakly supervised multimodal framework to
generate clinically structured SOAP notes from limited inputs, including lesion
images and sparse clinical text. Our approach reduces reliance on manual
annotations, enabling scalable, clinically grounded documentation while
alleviating clinician burden and reducing the need for large annotated data.
Our method achieves performance comparable to GPT-4o, Claude, and DeepSeek
Janus Pro across key clinical relevance metrics. To evaluate this clinical
relevance, we introduce two novel metrics MedConceptEval and Clinical Coherence
Score (CCS) which assess semantic alignment with expert medical concepts and
input features, respectively.

</details>


### [29] [A Novel Image Similarity Metric for Scene Composition Structure](https://arxiv.org/abs/2508.05037)
*Md Redwanul Haque,Manzur Murshed,Manoranjan Paul,Tsz-Kwan Lee*

Main category: cs.CV

TL;DR: 提出了一种名为SCSSIM的新型无训练指标，用于评估生成图像的场景组成结构（SCS）。SCSSIM通过分析图像的立方体分层分割来工作，比现有指标更能准确地衡量结构完整性，并对非结构性变化具有不变性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型的发展需要新的图像质量评估方法，以超越人类感知。评估SCS的保持是确保生成模型输出忠实和结构准确的关键。现有的指标（像素级和基于感知的指标）在评估SCS方面存在不足，而基于神经网络的指标则存在训练开销和泛化问题。

Method: 提出了一种名为SCSSIM（场景组成结构相似性度量）的新颖指标，该指标是分析性的且无需训练。它利用从图像的立方体分层分割中派生的统计测量来量化SCS的保留情况，从而能够稳健地捕获非基于对象的结构关系。

Result: 实验表明，SCSSIM对非成分失真具有高度不变性，准确地反映了未改变的SCS。相反，它在成分失真时显示出强烈的单调下降，精确地指示了SCS何时被改变。

Conclusion: SCSSIM是一种新颖的、无训练的分析指标，通过利用图像的立方体分层分割的统计测量来量化SCS的保留情况，能够稳健地捕获非基于对象的结构关系。与现有指标相比，SCSSIM在结构评估方面表现出优越的性能，是开发和评估生成模型、确保场景组合完整性的宝贵工具。

Abstract: The rapid advancement of generative AI models necessitates novel methods for
evaluating image quality that extend beyond human perception. A critical
concern for these models is the preservation of an image's underlying Scene
Composition Structure (SCS), which defines the geometric relationships among
objects and the background, their relative positions, sizes, orientations, etc.
Maintaining SCS integrity is paramount for ensuring faithful and structurally
accurate GenAI outputs. Traditional image similarity metrics often fall short
in assessing SCS. Pixel-level approaches are overly sensitive to minor visual
noise, while perception-based metrics prioritize human aesthetic appeal,
neither adequately capturing structural fidelity. Furthermore, recent
neural-network-based metrics introduce training overheads and potential
generalization issues. We introduce the SCS Similarity Index Measure (SCSSIM),
a novel, analytical, and training-free metric that quantifies SCS preservation
by exploiting statistical measures derived from the Cuboidal hierarchical
partitioning of images, robustly capturing non-object-based structural
relationships. Our experiments demonstrate SCSSIM's high invariance to
non-compositional distortions, accurately reflecting unchanged SCS. Conversely,
it shows a strong monotonic decrease for compositional distortions, precisely
indicating when SCS has been altered. Compared to existing metrics, SCSSIM
exhibits superior properties for structural evaluation, making it an invaluable
tool for developing and evaluating generative models, ensuring the integrity of
scene composition.

</details>


### [30] [HAMoBE: Hierarchical and Adaptive Mixture of Biometric Experts for Video-based Person ReID](https://arxiv.org/abs/2508.05038)
*Yiyang Su,Yunping Shi,Feng Liu,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出HAMoBE框架，通过结合外观、身体形状和步态特征，并自适应地加权每个特征的贡献，显著提高了视频重识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 视频重识别（ReID）在复杂的监控和安全场景中至关重要，但现有方法在特征选择方面存在不足。

Method: HAMoBE框架包含两个层级：第一层从冻结的大模型提供的多层表示中提取低层特征；第二层包括专注于长期、短期和时间特征的专门专家。为了确保稳健的匹配，引入了一个新的双输入决策门控网络，该网络根据每个专家与输入场景的相关性动态调整其贡献。

Result: 在MEVID等基准测试上的大量评估表明，该方法显著提高了性能（例如，Rank-1 准确率提高了13.0%）。

Conclusion: 现有的视频重识别方法在匹配时忽略了从查询-图库对中识别和选择最具区分度的特征的必要性。本研究提出了一个新颖的层级自适应混合生物识别专家（HAMoBE）框架，该框架利用预训练大模型（如CLIP）的多层特征，并通过独立建模外观、静态身体形状和动态步态等关键生物识别特征并自适应地集成它们来模仿人类感知机制。

Abstract: Recently, research interest in person re-identification (ReID) has
increasingly focused on video-based scenarios, which are essential for robust
surveillance and security in varied and dynamic environments. However, existing
video-based ReID methods often overlook the necessity of identifying and
selecting the most discriminative features from both videos in a query-gallery
pair for effective matching. To address this issue, we propose a novel
Hierarchical and Adaptive Mixture of Biometric Experts (HAMoBE) framework,
which leverages multi-layer features from a pre-trained large model (e.g.,
CLIP) and is designed to mimic human perceptual mechanisms by independently
modeling key biometric features--appearance, static body shape, and dynamic
gait--and adaptively integrating them. Specifically, HAMoBE includes two
levels: the first level extracts low-level features from multi-layer
representations provided by the frozen large model, while the second level
consists of specialized experts focusing on long-term, short-term, and temporal
features. To ensure robust matching, we introduce a new dual-input decision
gating network that dynamically adjusts the contributions of each expert based
on their relevance to the input scenarios. Extensive evaluations on benchmarks
like MEVID demonstrate that our approach yields significant performance
improvements (e.g., +13.0% Rank-1 accuracy).

</details>


### [31] [Finding Needles in Images: Can Multimodal LLMs Locate Fine Details?](https://arxiv.org/abs/2508.05053)
*Parth Thakkar,Ankush Agarwal,Prasad Kasu,Pulkit Bansal,Chaitanya Devaguptapu*

Main category: cs.CV

TL;DR: 介绍了一个新的基准 NiM 和一种名为 Spot-IT 的新方法，用于评估和增强 MLLMs 在文档中查找和推理细粒度细节的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLMs 在文档理解方面表现出色，但在定位和推理文档中的细粒度细节方面能力有待提高，这在需要仔细关注细微但重要的细节的任务中尤为明显，例如在餐厅菜单中查找特定的营养信息或在报纸文章中识别免责声明。

Method: 提出了一种名为 Spot-IT 的方法，通过智能图像块选择和高斯注意力来增强 MLLMs 的能力，模拟人类在搜索文档时放缩和聚焦的行为。

Result: 通过在 NiM 基准上进行的大量实验，揭示了当前 MLLMs 在处理细粒度文档理解任务方面的能力和局限性，并证明了 Spot-IT 方法的有效性。

Conclusion: Spot-IT 显著提高了 MLLMs 处理细粒度文档理解任务的能力，特别是在需要精确提取复杂布局中的细节时。

Abstract: While Multi-modal Large Language Models (MLLMs) have shown impressive
capabilities in document understanding tasks, their ability to locate and
reason about fine-grained details within complex documents remains
understudied. Consider searching a restaurant menu for a specific nutritional
detail or identifying a disclaimer in a lengthy newspaper article tasks that
demand careful attention to small but significant details within a broader
narrative, akin to Finding Needles in Images (NiM). To address this gap, we
introduce NiM, a carefully curated benchmark spanning diverse real-world
documents including newspapers, menus, and lecture images, specifically
designed to evaluate MLLMs' capability in these intricate tasks. Building on
this, we further propose Spot-IT, a simple yet effective approach that enhances
MLLMs capability through intelligent patch selection and Gaussian attention,
motivated from how humans zoom and focus when searching documents. Our
extensive experiments reveal both the capabilities and limitations of current
MLLMs in handling fine-grained document understanding tasks, while
demonstrating the effectiveness of our approach. Spot-IT achieves significant
improvements over baseline methods, particularly in scenarios requiring precise
detail extraction from complex layouts.

</details>


### [32] [DualMat: PBR Material Estimation via Coherent Dual-Path Diffusion](https://arxiv.org/abs/2508.05060)
*Yifeng Huang,Zhang Chen,Yi Xu,Minh Hoai,Zhong Li*

Main category: cs.CV

TL;DR: DualMat, a dual-path diffusion model, estimates PBR materials from single images under complex lighting. It uses two latent spaces (albedo and material-specific) with feature distillation and rectified flow for efficiency. It achieves state-of-the-art results on albedo and metallic-roughness estimation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To estimate Physically Based Rendering (PBR) materials from single images under complex lighting conditions.

Method: DualMat is a dual-path diffusion framework that operates in two distinct latent spaces: an albedo-optimized path leveraging pretrained visual knowledge through RGB latent space, and a material-specialized path operating in a compact latent space designed for precise metallic and roughness estimation. It uses feature distillation for coherent predictions and rectified flow for efficiency. The framework extends to high-resolution and multi-view inputs through patch-based estimation and cross-view attention.

Result: The approach achieves state-of-the-art performance, significantly outperforming existing methods with up to 28% improvement in albedo estimation and 39% reduction in metallic-roughness prediction errors.

Conclusion: DualMat achieves state-of-the-art performance on both Objaverse and real-world data, significantly outperforming existing methods with up to 28% improvement in albedo estimation and 39% reduction in metallic-roughness prediction errors.

Abstract: We present DualMat, a novel dual-path diffusion framework for estimating
Physically Based Rendering (PBR) materials from single images under complex
lighting conditions. Our approach operates in two distinct latent spaces: an
albedo-optimized path leveraging pretrained visual knowledge through RGB latent
space, and a material-specialized path operating in a compact latent space
designed for precise metallic and roughness estimation. To ensure coherent
predictions between the albedo-optimized and material-specialized paths, we
introduce feature distillation during training. We employ rectified flow to
enhance efficiency by reducing inference steps while maintaining quality. Our
framework extends to high-resolution and multi-view inputs through patch-based
estimation and cross-view attention, enabling seamless integration into
image-to-3D pipelines. DualMat achieves state-of-the-art performance on both
Objaverse and real-world data, significantly outperforming existing methods
with up to 28% improvement in albedo estimation and 39% reduction in
metallic-roughness prediction errors.

</details>


### [33] [Decoupling Continual Semantic Segmentation](https://arxiv.org/abs/2508.05065)
*Yifu Guo,Yuquan Lu,Wentao Zhang,Zishan Xu,Dexia Chen,Siyu Zhang,Yizhe Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: DecoupleCSS是一个两阶段框架，通过将类别检测与分割解耦，解决了持续语义分割中的灾难性遗忘问题，并在保留旧知识和学习新知识之间取得了更好的平衡，达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的持续语义分割（CSS）方法通常采用单一阶段的编码器-解码器架构，导致分割掩码与类别标签紧密耦合，从而在旧类别和新类别学习之间产生干扰，并且难以在保留旧知识和学习新知识之间取得最佳的平衡。为了解决这个问题，DecoupleCSS旨在通过解耦这两个过程来提高CSS的效率。

Method: 提出了一种名为DecoupleCSS的新型两阶段框架。第一阶段利用预训练的文本和图像编码器（通过LoRA适配）来编码特定类别的信息并生成位置感知提示。第二阶段采用分割任何模型（SAM）来生成精确的分割掩码，确保新旧类别之间分割知识的共享。

Result: DecoupleCSS在多种具有挑战性的任务中取得了最先进的性能，有效地平衡了知识保留和适应性。

Conclusion: DecoupleCSS框架通过解耦类别感知检测与类别无关分割，实现了更有效的持续学习，在保留旧知识的同时学习新知识，并在多种具有挑战性的任务中取得了最先进的性能。

Abstract: Continual Semantic Segmentation (CSS) requires learning new classes without
forgetting previously acquired knowledge, addressing the fundamental challenge
of catastrophic forgetting in dense prediction tasks. However, existing CSS
methods typically employ single-stage encoder-decoder architectures where
segmentation masks and class labels are tightly coupled, leading to
interference between old and new class learning and suboptimal
retention-plasticity balance. We introduce DecoupleCSS, a novel two-stage
framework for CSS. By decoupling class-aware detection from class-agnostic
segmentation, DecoupleCSS enables more effective continual learning, preserving
past knowledge while learning new classes. The first stage leverages
pre-trained text and image encoders, adapted using LoRA, to encode
class-specific information and generate location-aware prompts. In the second
stage, the Segment Anything Model (SAM) is employed to produce precise
segmentation masks, ensuring that segmentation knowledge is shared across both
new and previous classes. This approach improves the balance between retention
and adaptability in CSS, achieving state-of-the-art performance across a
variety of challenging tasks. Our code is publicly available at:
https://github.com/euyis1019/Decoupling-Continual-Semantic-Segmentation.

</details>


### [34] [Automatic Image Colorization with Convolutional Neural Networks and Generative Adversarial Networks](https://arxiv.org/abs/2508.05068)
*Ruiyu Li,Changyuan Qiu,Hangrui Cao,Qihan Ren,Yuqing Qiu*

Main category: cs.CV

TL;DR: This paper explores automatic image colorization using classification and adversarial learning, addressing the challenges of this ill-posed problem by leveraging semantic information and large datasets.


<details>
  <summary>Details</summary>
Motivation: Image colorization is a focus of significant research due to its applications in color restoration and automatic animation colorization. The problem is challenging as it is ill-posed, but scene semantics and surface textures provide cues for colors. Large amounts of training data are available.

Method: The method involves classification and adversarial learning, with modifications applied for the specific scenario.

Result: The paper aims to explore automatic image colorization using classification and adversarial learning, comparing different approaches.

Conclusion: The paper explores automatic image colorization via classification and adversarial learning, building on prior works and making comparisons.

Abstract: Image colorization, the task of adding colors to grayscale images, has been
the focus of significant research efforts in computer vision in recent years
for its various application areas such as color restoration and automatic
animation colorization [15, 1]. The colorization problem is challenging as it
is highly ill-posed with two out of three image dimensions lost, resulting in
large degrees of freedom. However, semantics of the scene as well as the
surface texture could provide important cues for colors: the sky is typically
blue, the clouds are typically white and the grass is typically green, and
there are huge amounts of training data available for learning such priors
since any colored image could serve as a training data point [20].
  Colorization is initially formulated as a regression task[5], which ignores
the multi-modal nature of color prediction. In this project, we explore
automatic image colorization via classification and adversarial learning. We
will build our models on prior works, apply modifications for our specific
scenario and make comparisons.

</details>


### [35] [FLUX-Makeup: High-Fidelity, Identity-Consistent, and Robust Makeup Transfer via Diffusion Transformer](https://arxiv.org/abs/2508.05069)
*Jian Zhu,Shanyuan Liu,Liuzhuozheng Li,Yue Gong,He Wang,Bo Cheng,Yuhang Ma,Liebucha Wu,Xiaoyu Wu,Dawei Leng,Yuhui Yin,Yang Xu*

Main category: cs.CV

TL;DR: FLUX-Makeup 通过直接利用源-参考图像对，并引入 RefLoRAInjector 和改进的数据生成流程，实现了高保真、身份一致且鲁棒的妆容迁移，无需额外的面部控制组件，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 GAN 的方法通常依赖于精心设计的损失函数来平衡迁移质量和面部身份一致性，而基于扩散的方法通常依赖于额外的面部控制模块或算法来保留身份。然而，这些辅助组件往往会引入额外的错误，导致迁移结果不理想。

Method: FLUX-Makeup 是一个高保真、身份一致且鲁棒的妆容迁移框架，它直接利用源-参考图像对来实现卓越的迁移性能。该框架基于 FLUX-Kontext，并将源图像作为其原生的条件输入。此外，该框架引入了 RefLoRAInjector，一个轻量级的妆容特征注入器，将参考通路与骨干网络分离，从而能够高效全面地提取与妆容相关的信息。同时，设计了一个鲁棒且可扩展的数据生成流程，以便在训练期间提供更准确的监督。

Result: FLUX-Makeup 实现了最先进的性能，在各种场景下都表现出强大的鲁棒性。

Conclusion: FLUX-Makeup 实现了最先进的性能，在各种场景下都表现出强大的鲁棒性。

Abstract: Makeup transfer aims to apply the makeup style from a reference face to a
target face and has been increasingly adopted in practical applications.
Existing GAN-based approaches typically rely on carefully designed loss
functions to balance transfer quality and facial identity consistency, while
diffusion-based methods often depend on additional face-control modules or
algorithms to preserve identity. However, these auxiliary components tend to
introduce extra errors, leading to suboptimal transfer results. To overcome
these limitations, we propose FLUX-Makeup, a high-fidelity,
identity-consistent, and robust makeup transfer framework that eliminates the
need for any auxiliary face-control components. Instead, our method directly
leverages source-reference image pairs to achieve superior transfer
performance. Specifically, we build our framework upon FLUX-Kontext, using the
source image as its native conditional input. Furthermore, we introduce
RefLoRAInjector, a lightweight makeup feature injector that decouples the
reference pathway from the backbone, enabling efficient and comprehensive
extraction of makeup-related information. In parallel, we design a robust and
scalable data generation pipeline to provide more accurate supervision during
training. The paired makeup datasets produced by this pipeline significantly
surpass the quality of all existing datasets. Extensive experiments demonstrate
that FLUX-Makeup achieves state-of-the-art performance, exhibiting strong
robustness across diverse scenarios.

</details>


### [36] [AdaFusion: Prompt-Guided Inference with Adaptive Fusion of Pathology Foundation Models](https://arxiv.org/abs/2508.05084)
*Yuxiang Xiao,Yang Hu,Bin Li,Tianyang Zhang,Zexi Li,Huazhu Fu,Jens Rittscher,Kaixiang Yang*

Main category: cs.CV

TL;DR: AdaFusion 通过动态融合多个病理基础模型 (PFM) 的知识来提高下游任务的性能和可解释性，克服了 PFM 预训练背景的限制。


<details>
  <summary>Details</summary>
Motivation: PFM 在大型、未标记的组织病理学图像数据集上进行了自我监督的预训练，但其多样化且不透明的预训练背景（由数据相关和结构/训练因素共同决定）引入了潜在偏差，阻碍了其在下游应用中的泛化能力和透明度。

Method: AdaFusion 是一个新颖的、受提示指导的推理框架，它动态地整合来自多个 PFM 的互补知识。该方法压缩并对齐来自不同模型的 tile 级特征，并采用轻量级注意力机制，根据组织表型上下文自适应地融合它们。

Result: AdaFusion 在三个实际基准测试中表现优于单个 PFM，这些基准测试涵盖治疗反应预测、肿瘤分级和空间基因表达推断。

Conclusion: AdaFusion 能够弥合异构 PFM 的差距，从而提高性能和可解释性，并深入了解模型特定的归纳偏差。

Abstract: Pathology foundation models (PFMs) have demonstrated strong representational
capabilities through self-supervised pre-training on large-scale, unannotated
histopathology image datasets. However, their diverse yet opaque pretraining
contexts, shaped by both data-related and structural/training factors,
introduce latent biases that hinder generalisability and transparency in
downstream applications. In this paper, we propose AdaFusion, a novel
prompt-guided inference framework that, to our knowledge, is among the very
first to dynamically integrate complementary knowledge from multiple PFMs. Our
method compresses and aligns tile-level features from diverse models and
employs a lightweight attention mechanism to adaptively fuse them based on
tissue phenotype context. We evaluate AdaFusion on three real-world benchmarks
spanning treatment response prediction, tumour grading, and spatial gene
expression inference. Our approach consistently surpasses individual PFMs
across both classification and regression tasks, while offering interpretable
insights into each model's biosemantic specialisation. These results highlight
AdaFusion's ability to bridge heterogeneous PFMs, achieving both enhanced
performance and interpretability of model-specific inductive biases.

</details>


### [37] [PoseGen: In-Context LoRA Finetuning for Pose-Controllable Long Human Video Generation](https://arxiv.org/abs/2508.05091)
*Jingxuan He,Busheng Su,Finn Wong*

Main category: cs.CV

TL;DR: PoseGen 是一个新框架，通过 in-context LoRA 和交错片段生成，可以生成任意长度且身份/运动可控的视频，解决了现有模型的身份漂移和短片段问题。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在生成具有精确主体身份和运动控制的长视频方面存在挑战，并且常常出现身份漂移和短片段的限制。需要一种能够生成任意长视频且能保持身份和运动控制的新方法。

Method: PoseGen 使用了一种新颖的框架，该框架通过在 token 级别注入主体外观的 in-context LoRA 微调策略来保存身份，同时在通道级别以姿态信息作为条件来实现细粒度的运动控制。它还使用交错的片段生成方法和共享 KV 缓存机制来生成任意长度的视频。

Result: PoseGen 在身份保真度、姿态准确性方面表现出色，并能生成无伪影的无限长视频，优于最先进的方法。

Conclusion: PoseGen 成功生成了任意长度的视频，并在身份保真度、姿态准确性和连贯性方面显著优于现有方法。

Abstract: Generating long, temporally coherent videos with precise control over subject
identity and motion is a formidable challenge for current diffusion models,
which often suffer from identity drift and are limited to short clips. We
introduce PoseGen, a novel framework that generates arbitrarily long videos of
a specific subject from a single reference image and a driving pose sequence.
Our core innovation is an in-context LoRA finetuning strategy that injects
subject appearance at the token level for identity preservation, while
simultaneously conditioning on pose information at the channel level for
fine-grained motion control. To overcome duration limits, PoseGen pioneers an
interleaved segment generation method that seamlessly stitches video clips
together, using a shared KV cache mechanism and a specialized transition
process to ensure background consistency and temporal smoothness. Trained on a
remarkably small 33-hour video dataset, extensive experiments show that PoseGen
significantly outperforms state-of-the-art methods in identity fidelity, pose
accuracy, and its unique ability to produce coherent, artifact-free videos of
unlimited duration.

</details>


### [38] [Sculpting Margin Penalty: Intra-Task Adapter Merging and Classifier Calibration for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.05094)
*Liang Bai,Hong Song,Jinfu Li,Yucong Lin,Jingfan Fan,Tianyu Fu,Danni Ai,Deqiang Xiao,Jian Yang*

Main category: cs.CV

TL;DR: SMP是一种新颖的少样本类增量学习方法，通过在参数高效微调框架中结合不同阶段的边界惩罚来解决数据隐私、高获取成本和类别边界模糊的问题。它通过MIAM机制增强前向兼容性，并通过MPCC策略优化决策边界，在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本类增量学习方法在平衡基础类别可分性和新类别泛化能力方面存在挑战，并且在增量学习阶段由于有限的数据访问导致类别决策边界模糊。

Method: SMP方法通过两种机制解决少样本类增量学习的挑战：1. 边界感知类内适配器合并（MIAM）在基础任务学习阶段，训练两个具有不同分类损失的低秩适配器（一个带边界惩罚以增强基础类别可分性，一个不带边界惩罚以促进向未来新类别的泛化），然后自适应地合并它们以提高前向兼容性。2. 边界惩罚分类器校准（MPCC）在增量任务学习阶段，通过在所有已见类别的嵌入上应用边界惩罚来微调分类器，以优化决策边界。

Result: SMP在少样本类增量学习任务中实现了最先进的性能，并在基础类别和新类别之间取得了更好的平衡。

Conclusion: SMP方法在CIFAR100、ImageNet-R和CUB200数据集上取得了最先进的少样本类增量学习性能，并在基础类别和新类别之间实现了更好的平衡。

Abstract: Real-world applications often face data privacy constraints and high
acquisition costs, making the assumption of sufficient training data in
incremental tasks unrealistic and leading to significant performance
degradation in class-incremental learning. Forward-compatible learning, which
prospectively prepares for future tasks during base task training, has emerged
as a promising solution for Few-Shot Class-Incremental Learning (FSCIL).
However, existing methods still struggle to balance base-class discriminability
and new-class generalization. Moreover, limited access to original data during
incremental tasks often results in ambiguous inter-class decision boundaries.
To address these challenges, we propose SMP (Sculpting Margin Penalty), a novel
FSCIL method that strategically integrates margin penalties at different stages
within the parameter-efficient fine-tuning paradigm. Specifically, we introduce
the Margin-aware Intra-task Adapter Merging (MIAM) mechanism for base task
learning. MIAM trains two sets of low-rank adapters with distinct
classification losses: one with a margin penalty to enhance base-class
discriminability, and the other without margin constraints to promote
generalization to future new classes. These adapters are then adaptively merged
to improve forward compatibility. For incremental tasks, we propose a Margin
Penalty-based Classifier Calibration (MPCC) strategy to refine decision
boundaries by fine-tuning classifiers on all seen classes' embeddings with a
margin penalty. Extensive experiments on CIFAR100, ImageNet-R, and CUB200
demonstrate that SMP achieves state-of-the-art performance in FSCIL while
maintaining a better balance between base and new classes.

</details>


### [39] [AHDMIL: Asymmetric Hierarchical Distillation Multi-Instance Learning for Fast and Accurate Whole-Slide Image Classification](https://arxiv.org/abs/2508.05114)
*Jiuyang Dong,Jiahan Li,Junjun Jiang,Kui Jiang,Yongbing Zhang*

Main category: cs.CV

TL;DR: AHDMIL通过不对称分层蒸馏和CKA分类器，在病理图像分类任务中实现了高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决多实例学习（MIL）在病理图像分类中因处理大量块而导致的推理成本高昂的问题。

Method: 提出了一种不对称分层蒸馏多实例学习（AHDMIL）框架，包括动态多实例网络（DMIN）和双分支轻量级实例预筛选网络（DB-LIPN）。通过两步训练过程：1）自蒸馏（SD），训练DMIN并生成实例注意力分数以识别不相关块；2）不对称蒸馏（AD），DB-LIPN学习预测低分辨率块的相关性。相关块用于DMIN的微调和高效推理。此外，设计了基于Chebyshev多项式的Kolmogorov-Arnold（CKA）分类器。

Result: AHDMIL在四个公开数据集上实现了比现有方法更高的分类性能和更快的推理速度。

Conclusion: AHDMIL在四个公开数据集上的广泛实验证明，其在分类性能和推理速度上持续优于之前的最先进方法，例如在Camelyon16数据集上，准确率相对提高了5.3%，推理速度加快了1.2倍。所有数据集的AUC、准确率、f1分数和Brier分数均有稳定提升，平均推理加速在1.2到2.1倍之间。

Abstract: Although multi-instance learning (MIL) has succeeded in pathological image
classification, it faces the challenge of high inference costs due to the need
to process thousands of patches from each gigapixel whole slide image (WSI). To
address this, we propose AHDMIL, an Asymmetric Hierarchical Distillation
Multi-Instance Learning framework that enables fast and accurate classification
by eliminating irrelevant patches through a two-step training process. AHDMIL
comprises two key components: the Dynamic Multi-Instance Network (DMIN), which
operates on high-resolution WSIs, and the Dual-Branch Lightweight Instance
Pre-screening Network (DB-LIPN), which analyzes corresponding low-resolution
counterparts. In the first step, self-distillation (SD), DMIN is trained for
WSI classification while generating per-instance attention scores to identify
irrelevant patches. These scores guide the second step, asymmetric distillation
(AD), where DB-LIPN learns to predict the relevance of each low-resolution
patch. The relevant patches predicted by DB-LIPN have spatial correspondence
with patches in high-resolution WSIs, which are used for fine-tuning and
efficient inference of DMIN. In addition, we design the first
Chebyshev-polynomial-based Kolmogorov-Arnold (CKA) classifier in computational
pathology, which improves classification performance through learnable
activation layers. Extensive experiments on four public datasets demonstrate
that AHDMIL consistently outperforms previous state-of-the-art methods in both
classification performance and inference speed. For example, on the Camelyon16
dataset, it achieves a relative improvement of 5.3% in accuracy and accelerates
inference by 1.2.times. Across all datasets, area under the curve (AUC),
accuracy, f1 score, and brier score show consistent gains, with average
inference speedups ranging from 1.2 to 2.1 times. The code is available.

</details>


### [40] [Latent Expression Generation for Referring Image Segmentation and Grounding](https://arxiv.org/abs/2508.05123)
*Seonghoon Yu,Joonbeom Hong,Joonseok Lee,Jeany Son*

Main category: cs.CV

TL;DR: 为了解决视觉基础任务中单一文本输入与丰富视觉信息之间不匹配的问题，本研究提出了一种新颖的框架，通过生成多个潜在表达式并整合补充视觉细节来捕捉独特的目标线索，并在RIS、REC和GRES任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础方法大多依赖单一文本输入，仅捕获了丰富视觉信息中的一小部分，导致丰富的视觉细节和稀疏的文本线索之间存在不匹配，从而可能错误地识别相似的对象。

Method: 提出了一种新颖的视觉基础框架，该框架通过整合原始描述中缺失的补充视觉细节，从单个文本输入生成多个潜在表达式。具体来说，引入了主题分配器和视觉概念注入器模块，将共享主题和不同属性的概念嵌入到潜在表示中，从而捕获独特且目标特定的视觉线索。此外，还提出了一种正边距对比学习策略，以在保留细微差异的同时，将所有潜在表达式与原始文本对齐。

Result: 实验结果表明，该方法不仅在多个基准测试中优于最先进的RIS和REC方法，而且在GRES基准测试中也取得了出色的性能。

Conclusion: 该方法在多个基准测试中优于最先进的RIS和REC方法，并在GRES基准测试中取得了出色的性能。

Abstract: Visual grounding tasks, such as referring image segmentation (RIS) and
referring expression comprehension (REC), aim to localize a target object based
on a given textual description. The target object in an image can be described
in multiple ways, reflecting diverse attributes such as color, position, and
more. However, most existing methods rely on a single textual input, which
captures only a fraction of the rich information available in the visual
domain. This mismatch between rich visual details and sparse textual cues can
lead to the misidentification of similar objects. To address this, we propose a
novel visual grounding framework that leverages multiple latent expressions
generated from a single textual input by incorporating complementary visual
details absent from the original description. Specifically, we introduce
subject distributor and visual concept injector modules to embed both
shared-subject and distinct-attributes concepts into the latent
representations, thereby capturing unique and target-specific visual cues. We
also propose a positive-margin contrastive learning strategy to align all
latent expressions with the original text while preserving subtle variations.
Experimental results show that our method not only outperforms state-of-the-art
RIS and REC approaches on multiple benchmarks but also achieves outstanding
performance on the generalized referring expression segmentation (GRES)
benchmark.

</details>


### [41] [FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images](https://arxiv.org/abs/2508.05137)
*Sachin Dudda Nagaraju,Ashkan Moradi,Bendik Skarre Abrahamsen,Mattijs Elschot*

Main category: cs.CV

TL;DR: FedGIN是一种联邦学习框架，通过GIN模块在不共享数据的情况下实现多模态医学图像分割，在不同数据集设置下均提高了分割精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学图像分割中数据稀缺、跨模态域移位和隐私限制等挑战，开发一个能够有效泛化到多种成像模态的统一模型，以简化临床工作流程并减少对特定模态训练的需求。

Method: 提出了一种名为FedGIN的联邦学习框架，并集成了一个轻量级的全局非线性（GIN）增强模块，用于在本地训练期间协调特定模态的强度分布，以实现多模态器官分割。

Result: 在有限数据集场景下，FedGIN比未使用GIN的联邦学习提高了12%到18%的3D Dice分数；在完整数据集场景下，FedGIN实现了接近中心化的性能，比仅MRI基线提高了30%的Dice分数，比仅CT基线提高了10%。

Conclusion: FedGIN框架在隐私约束下实现了有效的多模态器官分割，在有限和完整数据集场景下均表现出优越性能，显著提高了Dice分数，并实现了接近中心化的性能。

Abstract: Medical image segmentation plays a crucial role in AI-assisted diagnostics,
surgical planning, and treatment monitoring. Accurate and robust segmentation
models are essential for enabling reliable, data-driven clinical decision
making across diverse imaging modalities. Given the inherent variability in
image characteristics across modalities, developing a unified model capable of
generalizing effectively to multiple modalities would be highly beneficial.
This model could streamline clinical workflows and reduce the need for
modality-specific training. However, real-world deployment faces major
challenges, including data scarcity, domain shift between modalities (e.g., CT
vs. MRI), and privacy restrictions that prevent data sharing. To address these
issues, we propose FedGIN, a Federated Learning (FL) framework that enables
multimodal organ segmentation without sharing raw patient data. Our method
integrates a lightweight Global Intensity Non-linear (GIN) augmentation module
that harmonizes modality-specific intensity distributions during local
training. We evaluated FedGIN using two types of datasets: an imputed dataset
and a complete dataset. In the limited dataset scenario, the model was
initially trained using only MRI data, and CT data was added to assess its
performance improvements. In the complete dataset scenario, both MRI and CT
data were fully utilized for training on all clients. In the limited-data
scenario, FedGIN achieved a 12 to 18% improvement in 3D Dice scores on MRI test
cases compared to FL without GIN and consistently outperformed local baselines.
In the complete dataset scenario, FedGIN demonstrated near-centralized
performance, with a 30% Dice score improvement over the MRI-only baseline and a
10% improvement over the CT-only baseline, highlighting its strong
cross-modality generalization under privacy constraints.

</details>


### [42] [Deep Learning-based Animal Behavior Analysis: Insights from Mouse Chronic Pain Models](https://arxiv.org/abs/2508.05138)
*Yu-Hsi Chen,Wei-Hsin Chen,Chien-Yao Wang,Hong-Yuan Mark Liao,James C. Liao,Chien-Chang Chen*

Main category: cs.CV

TL;DR: 提出一种自动发现慢性疼痛行为特征的新框架，无需人工标签，准确率超越人类专家和现有方法，并有助于药物疗效研究。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖人工标记行为特征，且难以准确捕捉慢性疼痛中潜伏且持续的行为变化。

Method: 提出一个框架，利用通用动作空间投影仪自动提取鼠标动作特征，以发现与慢性疼痛相关的特征，无需人工定义的动作标签。

Result: 在15类疼痛分类任务中达到48.41%的准确率，优于人类专家（21.33%）和B-SOiD（30.52%）。在简化为三类（神经性疼痛、炎症性疼痛和无疼痛）的分类任务中，准确率达到73.1%，显著高于人类专家（48%）和B-SOiD（58.43%）。此外，该方法在零样本 পর্যালোচনা替丁药物测试中揭示了不同类型疼痛的药物疗效差异，且结果与过去的药物疗效文献一致。

Conclusion: 该研究展示了所提出框架的临床应用潜力，可为疼痛研究和相关药物开发提供新见解。

Abstract: Assessing chronic pain behavior in mice is critical for preclinical studies.
However, existing methods mostly rely on manual labeling of behavioral
features, and humans lack a clear understanding of which behaviors best
represent chronic pain. For this reason, existing methods struggle to
accurately capture the insidious and persistent behavioral changes in chronic
pain. This study proposes a framework to automatically discover features
related to chronic pain without relying on human-defined action labels. Our
method uses universal action space projector to automatically extract mouse
action features, and avoids the potential bias of human labeling by retaining
the rich behavioral information in the original video. In this paper, we also
collected a mouse pain behavior dataset that captures the disease progression
of both neuropathic and inflammatory pain across multiple time points. Our
method achieves 48.41\% accuracy in a 15-class pain classification task,
significantly outperforming human experts (21.33\%) and the widely used method
B-SOiD (30.52\%). Furthermore, when the classification is simplified to only
three categories, i.e., neuropathic pain, inflammatory pain, and no pain, then
our method achieves an accuracy of 73.1\%, which is notably higher than that of
human experts (48\%) and B-SOiD (58.43\%). Finally, our method revealed
differences in drug efficacy for different types of pain on zero-shot
Gabapentin drug testing, and the results were consistent with past drug
efficacy literature. This study demonstrates the potential clinical application
of our method, which can provide new insights into pain research and related
drug development.

</details>


### [43] [Rotation Equivariant Arbitrary-scale Image Super-Resolution](https://arxiv.org/abs/2508.05160)
*Qi Xie,Jiahong Fu,Zongben Xu,Deyu Meng*

Main category: cs.CV

TL;DR: 提出了一种新的ASISR方法，通过引入旋转不变性来解决几何伪影问题，并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前的任意尺度图像超分辨率（ASISR）方法在处理几何模式（如重复纹理、边缘或形状）时存在变形和扭曲的问题，导致恢复结果出现伪影。通过嵌入旋转不变性来保持几何模式的原始方向和结构完整性是必要的。

Method: 通过重新设计INR和编码器模块，并引入内在的旋转不变性，实现了端到端的旋转不变性。

Result: 提出的方法首次实现了从输入到输出的端到端旋转不变性，并通过理论分析和实验验证了其优越性，证明了其内在的等变性误差，并表明该框架可以即插即用地集成到现有的ASISR方法中以增强其性能。

Conclusion: 通过为INR和编码器模块引入内在的旋转不变性，实现了端到端的旋转不变性，从而解决了几何伪影问题，并在模拟和真实数据集上得到了验证。

Abstract: The arbitrary-scale image super-resolution (ASISR), a recent popular topic in
computer vision, aims to achieve arbitrary-scale high-resolution recoveries
from a low-resolution input image. This task is realized by representing the
image as a continuous implicit function through two fundamental modules, a
deep-network-based encoder and an implicit neural representation (INR) module.
Despite achieving notable progress, a crucial challenge of such a highly
ill-posed setting is that many common geometric patterns, such as repetitive
textures, edges, or shapes, are seriously warped and deformed in the
low-resolution images, naturally leading to unexpected artifacts appearing in
their high-resolution recoveries. Embedding rotation equivariance into the
ASISR network is thus necessary, as it has been widely demonstrated that this
enhancement enables the recovery to faithfully maintain the original
orientations and structural integrity of geometric patterns underlying the
input image. Motivated by this, we make efforts to construct a rotation
equivariant ASISR method in this study. Specifically, we elaborately redesign
the basic architectures of INR and encoder modules, incorporating intrinsic
rotation equivariance capabilities beyond those of conventional ASISR networks.
Through such amelioration, the ASISR network can, for the first time, be
implemented with end-to-end rotational equivariance maintained from input to
output. We also provide a solid theoretical analysis to evaluate its intrinsic
equivariance error, demonstrating its inherent nature of embedding such an
equivariance structure. The superiority of the proposed method is substantiated
by experiments conducted on both simulated and real datasets. We also validate
that the proposed framework can be readily integrated into current ASISR
methods in a plug \& play manner to further enhance their performance.

</details>


### [44] [X-MoGen: Unified Motion Generation across Humans and Animals](https://arxiv.org/abs/2508.05162)
*Xuan Wang,Kai Ruan,Liyang Qian,Zhizhi Guo,Chang Su,Gaoang Wang*

Main category: cs.CV

TL;DR: X-MoGen是一个统一的跨物种文本驱动运动生成框架，通过两阶段架构和形态损失解决了跨物种的形态差异问题，并在包含115个物种的大规模数据集UniMo4D上展示了优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法将人类和动物运动分开建模的局限性，以及跨物种形态差异带来的运动合理性挑战，提出了一种统一的跨物种文本驱动运动生成框架X-MoGen，以实现统一表示和提高泛化能力。

Method: X-MoGen采用两阶段架构：第一阶段，条件图变分自编码器学习规范T姿态先验，自编码器将运动编码到由形态损失正则化的共享潜在空间；第二阶段，进行掩码运动建模，以文本描述为条件生成运动嵌入。在训练过程中，引入形态一致性模块以促进跨物种的骨骼合理性。此外，该研究构建了一个大规模数据集UniMo4D，包含115个物种和119k个运动序列，整合了人类和动物运动，并采用共享骨骼拓扑结构进行联合训练。

Result: X-MoGen成功实现了跨物种的文本驱动运动生成，并在UniMo4D数据集的实验中，无论是在已见物种还是未见物种上，均取得了优于现有先进方法的性能。

Conclusion: X-MoGen在UniMo4D数据集上的广泛实验表明，其在人类和动物的文本驱动运动生成方面优于最先进的方法，并且能够处理已见和未见的物种。

Abstract: Text-driven motion generation has attracted increasing attention due to its
broad applications in virtual reality, animation, and robotics. While existing
methods typically model human and animal motion separately, a joint
cross-species approach offers key advantages, such as a unified representation
and improved generalization. However, morphological differences across species
remain a key challenge, often compromising motion plausibility. To address
this, we propose \textbf{X-MoGen}, the first unified framework for
cross-species text-driven motion generation covering both humans and animals.
X-MoGen adopts a two-stage architecture. First, a conditional graph variational
autoencoder learns canonical T-pose priors, while an autoencoder encodes motion
into a shared latent space regularized by morphological loss. In the second
stage, we perform masked motion modeling to generate motion embeddings
conditioned on textual descriptions. During training, a morphological
consistency module is employed to promote skeletal plausibility across species.
To support unified modeling, we construct \textbf{UniMo4D}, a large-scale
dataset of 115 species and 119k motion sequences, which integrates human and
animal motions under a shared skeletal topology for joint training. Extensive
experiments on UniMo4D demonstrate that X-MoGen outperforms state-of-the-art
methods on both seen and unseen species.

</details>


### [45] [PhysPatch: A Physically Realizable and Transferable Adversarial Patch Attack for Multimodal Large Language Models-based Autonomous Driving Systems](https://arxiv.org/abs/2508.05167)
*Qi Guo,Xiaojun Jia,Shanmin Pang,Simeng Qin,Lin Wang,Ju Jia,Yang Liu,Qing Guo*

Main category: cs.CV

TL;DR: PhysPatch 是一种新的框架，可以有效地对自动驾驶系统中的 MLLM 进行对抗性攻击，并具有良好的现实世界应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的基于补丁的攻击方法在转移到 MLLM 系统时表现不佳，而 MLLM 在自动驾驶系统中至关重要但易受对抗性攻击。

Method: PhysPatch 框架通过联合优化补丁位置、形状和内容来增强攻击效果和现实世界适用性。它采用了基于语义的掩码初始化策略，基于 SVD 的局部对齐损失以及基于势场的掩码细化方法。

Result: 实验证明，PhysPatch 在将 MLLM 驱动的自动驾驶系统朝着目标对齐的感知和规划输出进行引导方面，显著优于先前的方法。此外，PhysPatch 能够将对抗性补丁放置在自动驾驶场景中物理上可行的区域。

Conclusion: PhysPatch 成功地对基于 MLLM 的自动驾驶系统进行了有效的对抗性攻击，其性能优于现有方法，并且具有很强的现实世界适用性。

Abstract: Multimodal Large Language Models (MLLMs) are becoming integral to autonomous
driving (AD) systems due to their strong vision-language reasoning
capabilities. However, MLLMs are vulnerable to adversarial attacks,
particularly adversarial patch attacks, which can pose serious threats in
real-world scenarios. Existing patch-based attack methods are primarily
designed for object detection models and perform poorly when transferred to
MLLM-based systems due to the latter's complex architectures and reasoning
abilities. To address these limitations, we propose PhysPatch, a physically
realizable and transferable adversarial patch framework tailored for MLLM-based
AD systems. PhysPatch jointly optimizes patch location, shape, and content to
enhance attack effectiveness and real-world applicability. It introduces a
semantic-based mask initialization strategy for realistic placement, an
SVD-based local alignment loss with patch-guided crop-resize to improve
transferability, and a potential field-based mask refinement method. Extensive
experiments across open-source, commercial, and reasoning-capable MLLMs
demonstrate that PhysPatch significantly outperforms prior methods in steering
MLLM-based AD systems toward target-aligned perception and planning outputs.
Moreover, PhysPatch consistently places adversarial patches in physically
feasible regions of AD scenes, ensuring strong real-world applicability and
deployability.

</details>


### [46] [Multi-tracklet Tracking for Generic Targets with Adaptive Detection Clustering](https://arxiv.org/abs/2508.05172)
*Zewei Wu,Longhao Wang,Cui Wang,César Teixeira,Wei Ke,Zhang Xiong*

Main category: cs.CV

TL;DR: MTT tracker enhances tracklet generation and association to improve multi-target tracking, especially for challenging scenarios with unseen objects and occlusions.


<details>
  <summary>Details</summary>
Motivation: Existing multitarget tracking methods struggle with real-world scenarios involving unseen categories, low-confidence detections, weak motion/appearance constraints, and long-term occlusions.

Method: MTT integrates flexible tracklet generation into a multi-tracklet association framework. It adaptively clusters detection results based on short-term spatio-temporal correlation to form robust tracklets, then estimates optimal tracklet partitions using multiple cues (location, appearance over time) to reduce error propagation in long-term association.

Result: Extensive experiments on the benchmark for generic multiple object tracking show the proposed framework is competitive.

Conclusion: The proposed Multi-Tracklet Tracking (MTT) framework demonstrates competitiveness on the benchmark for generic multiple object tracking, effectively addressing challenges posed by unseen categories, low-confidence detections, weak constraints, and long-term occlusions.

Abstract: Tracking specific targets, such as pedestrians and vehicles, has been the
focus of recent vision-based multitarget tracking studies. However, in some
real-world scenarios, unseen categories often challenge existing methods due to
low-confidence detections, weak motion and appearance constraints, and
long-term occlusions. To address these issues, this article proposes a
tracklet-enhanced tracker called Multi-Tracklet Tracking (MTT) that integrates
flexible tracklet generation into a multi-tracklet association framework. This
framework first adaptively clusters the detection results according to their
short-term spatio-temporal correlation into robust tracklets and then estimates
the best tracklet partitions using multiple clues, such as location and
appearance over time to mitigate error propagation in long-term association.
Finally, extensive experiments on the benchmark for generic multiple object
tracking demonstrate the competitiveness of the proposed framework.

</details>


### [47] [SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation](https://arxiv.org/abs/2508.05182)
*Zhiqing Xiao,Haobo Wang,Xu Lu,Wentao Ye,Gang Chen,Junbo Zhao*

Main category: cs.CV

TL;DR: SPA++ 通过图谱对齐、邻域感知传播和数据增强来解决域适应中的可辨别性问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的域适应（DA）研究主要关注捕获跨域的可迁移性，但忽略了丰富的域内结构，这可能导致可辨别性变差。为了解决这种权衡，SPA++ 被提出。

Method: SPA++ 是一个通用的图谱对齐框架，它将域适应问题转化为图基元，结合了粗粒度的图对齐机制和新颖的谱正则化器，以在特征空间中对齐域图。此外，它还开发了一种细粒度的邻域感知传播机制，以增强目标域的可辨别性。SPA++ 还通过结合数据增强和一致性正则化，使其能够适应包括大多数域适应设置甚至具有挑战性的分布偏移场景在内的复杂场景。SPA++ 还提供了理论分析，包括基于图的域适应的泛化界以及谱对齐和平滑一致性的作用。

Result: SPA++ 在基准数据集上的广泛实验表明，它在各种具有挑战性的域适应场景中持续优于现有的最先进方法，实现了卓越的鲁棒性和适应性。

Conclusion: SPA++ 在各种具有挑战性的域适应场景中持续优于现有的最先进方法，展现出卓越的鲁棒性和适应性。

Abstract: Domain Adaptation (DA) aims to transfer knowledge from a labeled source
domain to an unlabeled or sparsely labeled target domain under domain shifts.
Most prior works focus on capturing the inter-domain transferability but
largely overlook rich intra-domain structures, which empirically results in
even worse discriminability. To tackle this tradeoff, we propose a generalized
graph SPectral Alignment framework, SPA++. Its core is briefly condensed as
follows: (1)-by casting the DA problem to graph primitives, it composes a
coarse graph alignment mechanism with a novel spectral regularizer toward
aligning the domain graphs in eigenspaces; (2)-we further develop a
fine-grained neighbor-aware propagation mechanism for enhanced discriminability
in the target domain; (3)-by incorporating data augmentation and consistency
regularization, SPA++ can adapt to complex scenarios including most DA settings
and even challenging distribution scenarios. Furthermore, we also provide
theoretical analysis to support our method, including the generalization bound
of graph-based DA and the role of spectral alignment and smoothing consistency.
Extensive experiments on benchmark datasets demonstrate that SPA++ consistently
outperforms existing cutting-edge methods, achieving superior robustness and
adaptability across various challenging adaptation scenarios.

</details>


### [48] [SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images](https://arxiv.org/abs/2508.05202)
*Dongchen Si,Di Wang,Erzhong Gao,Xiaolei Qin,Liu Zhao,Jing Zhang,Minqiang Xu,Jianbo Zhan,Jianshe Wang,Lin Liu,Bo Du,Liangpei Zhang*

Main category: cs.CV

TL;DR: SPEX是首个专注于光谱遥感图像土地覆盖提取的多模态视觉-语言模型，它利用包含光谱先验知识的SPIE数据集，通过多项创新技术实现了优于现有方法的性能，并能提供可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉-语言模型在多光谱遥感图像处理中未能充分利用光谱信息的问题，从而导致性能不佳的局限性。

Method: 提出了一种名为SPEX的多模态大语言模型，该模型通过多尺度特征聚合、标记上下文凝结和多光谱视觉预训练等组件和训练策略，实现了精确灵活的像素级解译。SPEX利用SPIE数据集，该数据集将陆表地物光谱先验知识编码为可被大语言模型识别的文本属性。

Result: SPEX在五个公开的多光谱数据集上进行了广泛的实验，在提取植被、建筑物和水体等典型地物方面，其性能始终优于现有的最先进方法。此外，SPEX能够为其预测生成文本解释，从而提高了解释性和用户友好性。

Conclusion: SPEX在五个公开的多光谱数据集上进行了广泛的实验，在提取植被、建筑物和水体等典型地物方面，其性能始终优于现有的最先进方法。此外，SPEX能够为其预测生成文本解释，从而提高了解释性和用户友好性。

Abstract: Spectral information has long been recognized as a critical cue in remote
sensing observations. Although numerous vision-language models have been
developed for pixel-level interpretation, spectral information remains
underutilized, resulting in suboptimal performance, particularly in
multispectral scenarios. To address this limitation, we construct a
vision-language instruction-following dataset named SPIE, which encodes
spectral priors of land-cover objects into textual attributes recognizable by
large language models (LLMs), based on classical spectral index computations.
Leveraging this dataset, we propose SPEX, a multimodal LLM designed for
instruction-driven land cover extraction. To this end, we introduce several
carefully designed components and training strategies, including multiscale
feature aggregation, token context condensation, and multispectral visual
pre-training, to achieve precise and flexible pixel-level interpretation. To
the best of our knowledge, SPEX is the first multimodal vision-language model
dedicated to land cover extraction in spectral remote sensing imagery.
Extensive experiments on five public multispectral datasets demonstrate that
SPEX consistently outperforms existing state-of-the-art methods in extracting
typical land cover categories such as vegetation, buildings, and water bodies.
Moreover, SPEX is capable of generating textual explanations for its
predictions, thereby enhancing interpretability and user-friendliness. Code
will be released at: https://github.com/MiliLab/SPEX.

</details>


### [49] [EndoMatcher: Generalizable Endoscopic Image Matcher via Multi-Domain Pre-training for Robot-Assisted Surgery](https://arxiv.org/abs/2508.05205)
*Bingyu Yang,Qingyao Tian,Yimeng Geng,Huai Liao,Xinyan Huang,Jiebo Luo,Hongbin Liu*

Main category: cs.CV

TL;DR: EndoMatcher通过大规模多域预训练和创新的模型结构，解决了内窥镜图像匹配中的关键挑战，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 内窥镜图像的通用密集特征匹配对于机器人辅助任务至关重要，但由于视觉条件困难（如纹理弱、视角变化大）和标注数据稀缺，这一直是一个挑战。

Method: 提出了一种名为EndoMatcher的双分支Vision Transformer模型，并结合了对齐交互模块，以提取多尺度特征并学习鲁棒的对应关系。同时，构建了首个用于内窥镜匹配的多域数据集Endo-Mix6，并采用了渐进式多目标训练策略来应对数据不平衡和分布偏移等挑战。

Result: EndoMatcher在Hamlyn和Bladder数据集上的内群匹配数量分别比最先进的方法提高了140.69%和201.43%，在Gastro-Matching数据集上将匹配方向预测精度（MDPA）提高了9.40%，实现了在挑战性内窥镜条件下的密集和准确匹配。

Conclusion: EndoMatcher在挑战性内窥镜条件下实现了密集而准确的匹配，并且在Hamlyn和Bladder数据集上比最先进的方法分别提高了140.69%和201.43%的内群匹配数量，在Gastro-Matching数据集上将匹配方向预测精度（MDPA）提高了9.40%。

Abstract: Generalizable dense feature matching in endoscopic images is crucial for
robot-assisted tasks, including 3D reconstruction, navigation, and surgical
scene understanding. Yet, it remains a challenge due to difficult visual
conditions (e.g., weak textures, large viewpoint variations) and a scarcity of
annotated data. To address these challenges, we propose EndoMatcher, a
generalizable endoscopic image matcher via large-scale, multi-domain data
pre-training. To address difficult visual conditions, EndoMatcher employs a
two-branch Vision Transformer to extract multi-scale features, enhanced by dual
interaction blocks for robust correspondence learning. To overcome data
scarcity and improve domain diversity, we construct Endo-Mix6, the first
multi-domain dataset for endoscopic matching. Endo-Mix6 consists of
approximately 1.2M real and synthetic image pairs across six domains, with
correspondence labels generated using Structure-from-Motion and simulated
transformations. The diversity and scale of Endo-Mix6 introduce new challenges
in training stability due to significant variations in dataset sizes,
distribution shifts, and error imbalance. To address them, a progressive
multi-objective training strategy is employed to promote balanced learning and
improve representation quality across domains. This enables EndoMatcher to
generalize across unseen organs and imaging conditions in a zero-shot fashion.
Extensive zero-shot matching experiments demonstrate that EndoMatcher increases
the number of inlier matches by 140.69% and 201.43% on the Hamlyn and Bladder
datasets over state-of-the-art methods, respectively, and improves the Matching
Direction Prediction Accuracy (MDPA) by 9.40% on the Gastro-Matching dataset,
achieving dense and accurate matching under challenging endoscopic conditions.
The code is publicly available at https://github.com/Beryl2000/EndoMatcher.

</details>


### [50] [VFlowOpt: A Token Pruning Framework for LMMs with Visual Information Flow-Guided Optimization](https://arxiv.org/abs/2508.05211)
*Sihan Yang,Runsen Xu,Chenhang Cui,Tai Wang,Dahua Lin,Jiangmiao Pang*

Main category: cs.CV

TL;DR: VFlowOpt 通过引入重要性图、渐进式剪枝和视觉信息流优化，在大幅减少 LMM 计算成本的同时，有效保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMM）在视觉-语言任务中表现出色，但其大量的视觉 token 会带来显著的计算成本。之前的研究旨在减少推理过程中的视觉 token，但剪枝框架和策略仍然过于简单，探索不足，并常常导致性能大幅下降。

Method: VFlowOpt 框架通过以下方式进行剪枝：1. 引入了一个重要性图推导过程，基于注意力相关的上下文相关性和块级信息熵来计算图像 token 的重要性图。2. 引入了一个渐进式剪枝模块，并结合了一个回收机制，用于决定保留或剪枝 token，并将剪枝的 token 聚合为回收 token，以避免潜在的信息丢失。3. 通过一个视觉信息流引导的方法来优化剪枝策略的超参数，该方法将 LMM 的最后一个 token 视为文本-视觉交互的最具代表性的信号，以最小化剪枝前后 token 表示的差异。

Result: VFlowOpt 能够剪枝 90% 的视觉 token，同时保持可比的性能，从而将 KV 缓存内存减少 89%，并将推理速度提高 3.8 倍。

Conclusion: VFlowOpt 框架能够剪枝 90% 的视觉 token，同时保持可比的性能，从而将 KV 缓存内存减少 89%，并将推理速度提高 3.8 倍。

Abstract: Large Multimodal Models (LMMs) excel in visual-language tasks by leveraging
numerous visual tokens for fine-grained visual information, but this token
redundancy results in significant computational costs. Previous research aimed
at reducing visual tokens during inference typically leverages importance maps
derived from attention scores among vision-only tokens or vision-language
tokens to prune tokens across one or multiple pruning stages. Despite this
progress, pruning frameworks and strategies remain simplistic and
insufficiently explored, often resulting in substantial performance
degradation. In this paper, we propose VFlowOpt, a token pruning framework that
introduces an importance map derivation process and a progressive pruning
module with a recycling mechanism. The hyperparameters of its pruning strategy
are further optimized by a visual information flow-guided method. Specifically,
we compute an importance map for image tokens based on their attention-derived
context relevance and patch-level information entropy. We then decide which
tokens to retain or prune and aggregate the pruned ones as recycled tokens to
avoid potential information loss. Finally, we apply a visual information
flow-guided method that regards the last token in the LMM as the most
representative signal of text-visual interactions. This method minimizes the
discrepancy between token representations in LMMs with and without pruning,
thereby enabling superior pruning strategies tailored to different LMMs.
Experiments demonstrate that VFlowOpt can prune 90% of visual tokens while
maintaining comparable performance, leading to an 89% reduction in KV-Cache
memory and 3.8 times faster inference.

</details>


### [51] [Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2508.05213)
*Jianming Liu,Wenlong Qiu,Haitao Wei*

Main category: cs.CV

TL;DR: 提出了一种利用文本和视觉信息进行无源域跨域少样本分割的方法，通过TSAA、VVEA和TVEA模块进行目标域任务自适应，显著提升了分割准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有CD-FSS方法在存在域差异时性能显著下降的问题，并应对日益增长的数据隐私担忧以及最小化数据传输和训练成本的需求，开发无源域CD-FSS方法变得至关重要。

Method: 提出了一种无源域CD-FSS方法，该方法利用文本和视觉信息在不需要源域数据的情况下进行目标域任务自适应。具体来说，首先将特定任务的注意力适配器（TSAA）附加到预训练骨干的特征金字塔上，以适配从共享的预训练骨干提取的多级特征到目标任务。然后，通过视觉-视觉嵌入对齐（VVEA）模块和文本-视觉嵌入对齐（TVEA）模块训练TSAA的参数。VVEA模块利用全局-局部视觉特征来对齐不同视图的图像特征，而TVEA模块则利用预先对齐的多模态特征（例如来自CLIP）的文本先验来指导跨模态自适应。通过密集比较操作和跳跃连接融合，该方法生成精炼的预测掩码。

Result: 在四个跨域数据集的1-shot和5-shot设置下，平均分割准确率分别提高了2.18%和4.11%，显著优于最先进的CD-FSS方法。

Conclusion: 该方法在四个跨域数据集的1-shot和5-shot设置下，平均分割准确率分别提高了2.18%和4.11%，显著优于最先进的CD-FSS方法。

Abstract: Few-Shot Segmentation(FSS) aims to efficient segmentation of new objects with
few labeled samples. However, its performance significantly degrades when
domain discrepancies exist between training and deployment. Cross-Domain
Few-Shot Segmentation(CD-FSS) is proposed to mitigate such performance
degradation. Current CD-FSS methods primarily sought to develop segmentation
models on a source domain capable of cross-domain generalization. However,
driven by escalating concerns over data privacy and the imperative to minimize
data transfer and training expenses, the development of source-free CD-FSS
approaches has become essential. In this work, we propose a source-free CD-FSS
method that leverages both textual and visual information to facilitate target
domain task adaptation without requiring source domain data. Specifically, we
first append Task-Specific Attention Adapters (TSAA) to the feature pyramid of
a pretrained backbone, which adapt multi-level features extracted from the
shared pre-trained backbone to the target task. Then, the parameters of the
TSAA are trained through a Visual-Visual Embedding Alignment (VVEA) module and
a Text-Visual Embedding Alignment (TVEA) module. The VVEA module utilizes
global-local visual features to align image features across different views,
while the TVEA module leverages textual priors from pre-aligned multi-modal
features (e.g., from CLIP) to guide cross-modal adaptation. By combining the
outputs of these modules through dense comparison operations and subsequent
fusion via skip connections, our method produces refined prediction masks.
Under both 1-shot and 5-shot settings, the proposed approach achieves average
segmentation accuracy improvements of 2.18\% and 4.11\%, respectively, across
four cross-domain datasets, significantly outperforming state-of-the-art CD-FSS
methods. Code are available at https://github.com/ljm198134/TVGTANet.

</details>


### [52] [ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking](https://arxiv.org/abs/2508.05221)
*Xiao Wang,Liye Jin,Xufeng Lou,Shiao Wang,Lan Chen,Bo Jiang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 本研究提出了ReasoningTrack框架，利用Qwen2.5-VL模型、SFT和GRPO进行优化，并通过TNLLT数据集验证了其在视觉-语言跟踪任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言跟踪方法在融合固定语言或使用注意力机制时性能受限。而一些采用文本生成适应目标变化的研究未能提供模型推理过程的见解，且未能充分利用大模型的优势，这限制了其整体性能。为了解决这些问题，本文提出了一种新的方法。

Method: 提出了一种名为ReasoningTrack的基于推理的视觉-语言跟踪框架，该框架基于预训练的视觉-语言模型Qwen2.5-VL。使用SFT（监督微调）和强化学习GRPO进行推理和语言生成的优化。将更新的语言描述与视觉特征一起输入统一的跟踪骨干网络，并通过跟踪头预测目标对象的位置。此外，还提出了一个大规模的长期视觉-语言跟踪基准数据集TNLLT，其中包含200个视频序列。

Result: 通过在多个视觉-语言跟踪基准数据集上的广泛实验，证明了所提出的基于推理的自然语言生成策略的有效性。

Conclusion: 本文提出的基于推理的视觉-语言跟踪框架ReasoningTrack，并结合了SFT和GRPO优化，以及提出的TNLLT数据集，在多个视觉-语言跟踪基准数据集上进行了广泛的实验，验证了所提出的基于自然语言生成推理策略的有效性。

Abstract: Vision-language tracking has received increasing attention in recent years,
as textual information can effectively address the inflexibility and inaccuracy
associated with specifying the target object to be tracked. Existing works
either directly fuse the fixed language with vision features or simply modify
using attention, however, their performance is still limited. Recently, some
researchers have explored using text generation to adapt to the variations in
the target during tracking, however, these works fail to provide insights into
the model's reasoning process and do not fully leverage the advantages of large
models, which further limits their overall performance. To address the
aforementioned issues, this paper proposes a novel reasoning-based
vision-language tracking framework, named ReasoningTrack, based on a
pre-trained vision-language model Qwen2.5-VL. Both SFT (Supervised Fine-Tuning)
and reinforcement learning GRPO are used for the optimization of reasoning and
language generation. We embed the updated language descriptions and feed them
into a unified tracking backbone network together with vision features. Then,
we adopt a tracking head to predict the specific location of the target object.
In addition, we propose a large-scale long-term vision-language tracking
benchmark dataset, termed TNLLT, which contains 200 video sequences. 20
baseline visual trackers are re-trained and evaluated on this dataset, which
builds a solid foundation for the vision-language visual tracking task.
Extensive experiments on multiple vision-language tracking benchmark datasets
fully validated the effectiveness of our proposed reasoning-based natural
language generation strategy. The source code of this paper will be released on
https://github.com/Event-AHU/Open_VLTrack

</details>


### [53] [Segmenting the Complex and Irregular in Two-Phase Flows: A Real-World Empirical Study with SAM2](https://arxiv.org/abs/2508.05227)
*Semanur Küçük,Cosimo Della Santina,Angeliki Laskari*

Main category: cs.CV

TL;DR: 提出一种使用SAM v2.1模型进行气泡分割的新方法，在处理复杂气泡形态方面取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法和基于学习的方法在处理变形、聚结或破碎的气泡时效果有限，尤其是在气泡形成无定形和拓扑结构多样的斑块的空气润滑系统中。

Method: 将气泡分割任务视为迁移学习问题，并对SAM v2.1模型进行微调。

Result: 首次证明了微调后的SAM v2.1模型可以使用少至100张标注图像，准确分割高度非凸、不规则的气泡结构。

Conclusion: 使用SAM v2.1模型在少量标注数据下，能够准确分割高度非凸、不规则的气泡结构。

Abstract: Segmenting gas bubbles in multiphase flows is a critical yet unsolved
challenge in numerous industrial settings, from metallurgical processing to
maritime drag reduction. Traditional approaches-and most recent learning-based
methods-assume near-spherical shapes, limiting their effectiveness in regimes
where bubbles undergo deformation, coalescence, or breakup. This complexity is
particularly evident in air lubrication systems, where coalesced bubbles form
amorphous and topologically diverse patches. In this work, we revisit the
problem through the lens of modern vision foundation models. We cast the task
as a transfer learning problem and demonstrate, for the first time, that a
fine-tuned Segment Anything Model SAM v2.1 can accurately segment highly
non-convex, irregular bubble structures using as few as 100 annotated images.

</details>


### [54] [ArbiViewGen: Controllable Arbitrary Viewpoint Camera Data Generation for Autonomous Driving via Stable Diffusion Models](https://arxiv.org/abs/2508.05236)
*Yatong Lan,Jingfeng Chen,Yiru Wang,Lei He*

Main category: cs.CV

TL;DR: A new diffusion model called Arbiviewgen generates images from any viewpoint for self-driving cars, overcoming the lack of training data by intelligently stitching existing views and enforcing consistency, all without needing extra sensors.


<details>
  <summary>Details</summary>
Motivation: To enable arbitrary viewpoint image generation for autonomous driving, which is challenging due to the lack of ground-truth data for extrapolated views, hindering the training of high-fidelity generative models.

Method: A diffusion-based framework utilizing Feature-Aware Adaptive View Stitching (FAVS) for geometric correspondence and Cross-View Consistency Self-Supervised Learning (CVC-SSL) for training without extrapolated data supervision. FAVS uses a hierarchical matching strategy with camera poses and feature matching, while CVC-SSL reconstructs original views from stitched images using a diffusion model to enforce consistency.

Result: The framework successfully generates controllable camera images from arbitrary viewpoints using only multi-camera images and their poses for training, eliminating the need for additional sensors or depth maps.

Conclusion: Arbiviewgen is the first framework capable of controllable arbitrary view camera image generation across multiple vehicle configurations, addressing the challenge of lacking ground-truth data for extrapolated views.

Abstract: Arbitrary viewpoint image generation holds significant potential for
autonomous driving, yet remains a challenging task due to the lack of
ground-truth data for extrapolated views, which hampers the training of
high-fidelity generative models. In this work, we propose Arbiviewgen, a novel
diffusion-based framework for the generation of controllable camera images from
arbitrary points of view. To address the absence of ground-truth data in unseen
views, we introduce two key components: Feature-Aware Adaptive View Stitching
(FAVS) and Cross-View Consistency Self-Supervised Learning (CVC-SSL). FAVS
employs a hierarchical matching strategy that first establishes coarse
geometric correspondences using camera poses, then performs fine-grained
alignment through improved feature matching algorithms, and identifies
high-confidence matching regions via clustering analysis. Building upon this,
CVC-SSL adopts a self-supervised training paradigm where the model reconstructs
the original camera views from the synthesized stitched images using a
diffusion model, enforcing cross-view consistency without requiring supervision
from extrapolated data. Our framework requires only multi-camera images and
their associated poses for training, eliminating the need for additional
sensors or depth maps. To our knowledge, Arbiviewgen is the first method
capable of controllable arbitrary view camera image generation in multiple
vehicle configurations.

</details>


### [55] [Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2508.05237)
*Zane Xu,Jason Sun*

Main category: cs.CV

TL;DR: 本报告总结了关于视觉-语言模型（VLMs）的零样本对抗鲁棒性的研究，重点关注对抗性微调（AFT）和测试时防御。文章回顾了各种防御策略的演变，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 本报告旨在综合关于视觉-语言模型（VLMs）如CLIP的零样本对抗鲁棒性的八篇开创性论文，并探讨在增强鲁棒性和保持零样本泛化能力之间的固有权衡这一核心挑战。

Method: 分析了两种主要的防御范式：对抗性微调（AFT）和免训练/测试时防御。回顾了从保持对齐的方法（TeCoA）到嵌入空间再工程（LAAT, TIMA）以及从输入启发式（AOM, TTC）到潜在空间纯化（CLIPure）的演变。

Result: 本文分析了从保持对齐的方法到嵌入空间再工程，以及从输入启发式到潜在空间纯化的防御方法。

Conclusion: 未来的研究方向包括混合防御策略和对抗性预训练。

Abstract: This report synthesizes eight seminal papers on the zero-shot adversarial
robustness of vision-language models (VLMs) like CLIP. A central challenge in
this domain is the inherent trade-off between enhancing adversarial robustness
and preserving the model's zero-shot generalization capabilities. We analyze
two primary defense paradigms: Adversarial Fine-Tuning (AFT), which modifies
model parameters, and Training-Free/Test-Time Defenses, which preserve them. We
trace the evolution from alignment-preserving methods (TeCoA) to embedding
space re-engineering (LAAT, TIMA), and from input heuristics (AOM, TTC) to
latent-space purification (CLIPure). Finally, we identify key challenges and
future directions including hybrid defense strategies and adversarial
pre-training.

</details>


### [56] [RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding](https://arxiv.org/abs/2508.05244)
*Tianchen Fang,Guiru Liu*

Main category: cs.CV

TL;DR: RegionMed-CLIP通过整合局部病理信号和全局语义，并利用大规模区域标注数据集，提高了医学图像理解能力，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 医学图像理解面临两大挑战：高质量标注数据有限以及过度依赖可能忽略细微病变区域的全局图像特征。

Method: RegionMed-CLIP是一个区域感知的多模态对比学习框架，通过创新的感兴趣区域（ROI）处理器整合局部病理信号和全局语义表示，并采用渐进式训练策略增强多模态对齐。同时，构建了包含大量区域注释和多级临床描述的MedRegion-500k数据集以支持大规模区域级表示学习。

Result: RegionMed-CLIP在图像-文本检索、零样本分类和视觉问答任务上，相比最先进的视觉语言模型取得了显著的优势。

Conclusion: RegionMed-CLIP在医学图像理解方面表现出色，通过区域感知的方法克服了数据稀疏性和对全局特征的依赖性，并在各种下游任务中超越了现有技术，证明了区域感知对比预训练的重要性。

Abstract: Medical image understanding plays a crucial role in enabling automated
diagnosis and data-driven clinical decision support. However, its progress is
impeded by two primary challenges: the limited availability of high-quality
annotated medical data and an overreliance on global image features, which
often miss subtle but clinically significant pathological regions. To address
these issues, we introduce RegionMed-CLIP, a region-aware multimodal
contrastive learning framework that explicitly incorporates localized
pathological signals along with holistic semantic representations. The core of
our method is an innovative region-of-interest (ROI) processor that adaptively
integrates fine-grained regional features with the global context, supported by
a progressive training strategy that enhances hierarchical multimodal
alignment. To enable large-scale region-level representation learning, we
construct MedRegion-500k, a comprehensive medical image-text corpus that
features extensive regional annotations and multilevel clinical descriptions.
Extensive experiments on image-text retrieval, zero-shot classification, and
visual question answering tasks demonstrate that RegionMed-CLIP consistently
exceeds state-of-the-art vision language models by a wide margin. Our results
highlight the critical importance of region-aware contrastive pre-training and
position RegionMed-CLIP as a robust foundation for advancing multimodal medical
image understanding.

</details>


### [57] [A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis](https://arxiv.org/abs/2508.05246)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 本研究回顾了性别分类的现有方法，重点关注虹膜特征，并为该领域的研究人员提供了分析和未来方向。


<details>
  <summary>Details</summary>
Motivation: 性别分类在监视、公司分析和人机交互等应用中很有吸引力，因为性别信息可以帮助识别个人身份。面部特征是性别分类方法的基础，而虹膜因其在个体一生中保持不变、外部可见且易于使用而被认为是重要的生物识别特征。

Method: 本研究回顾了现有的性别分类方法，并讨论了用于不同性别分类步骤的各种方法。

Result: 本研究回顾了性别分类的现有方法，并为研究人员提供了该领域的知识和分析，重点关注了该领域的差距和挑战，并为改进提供了建议和未来路径。

Conclusion: 本研究回顾了现有的性别分类方法，并为研究人员提供了该领域的知识和分析，重点关注了该领域的差距和挑战，并为改进提供了建议和未来路径。

Abstract: Gender classification is attractive in a range of applications, including
surveillance and monitoring, corporate profiling, and human-computer
interaction. Individuals' identities may be gleaned from information about
their gender, which is a kind of soft biometric.Over the years, several methods
for determining a person's gender have been devised. Some of the most
well-known ones are based on physical characteristics like face, fingerprint,
palmprint, DNA, ears, gait, and iris. On the other hand, facial features
account for the vast majority of gender classification methods. Also, the iris
is a significant biometric trait because the iris, according to research,
remains basically constant during an individual's life. Besides that, the iris
is externally visible and is non-invasive to the user, which is important for
practical applications. Furthermore, there are already high-quality methods for
segmenting and encoding iris images, and the current methods facilitate
selecting and extracting attribute vectors from iris textures. This study
discusses several approaches to determining gender. The previous works of
literature are briefly reviewed. Additionally, there are a variety of
methodologies for different steps of gender classification. This study provides
researchers with knowledge and analysis of the existing gender classification
approaches. Also, it will assist researchers who are interested in this
specific area, as well as highlight the gaps and challenges in the field, and
finally provide suggestions and future paths for improvement.

</details>


### [58] [CF3: Compact and Fast 3D Feature Fields](https://arxiv.org/abs/2508.05254)
*Hyunjoon Lee,Joonkyu Min,Jaesik Park*

Main category: cs.CV

TL;DR: CF3是一种新颖的3D高斯特征场构建方法，通过自顶向下策略、高斯自编码器和自适应稀疏化，实现了高效、紧凑和细节丰富的3D表示。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在融合2D基础模型信息时，通常采用自底向上优化，将原始2D特征视为真实值，导致计算成本增加。需要一种更高效的方法来构建紧凑且快速的3D高斯特征场。

Method: 1. 快速加权融合多视图2D特征与预训练高斯。 2. 直接在提升后的特征上训练每个高斯自编码器。 3. 引入自适应稀疏化方法，优化高斯属性，同时修剪和合并冗余高斯。

Result: CF3 使用高达95%的较少高斯数量，实现了具有竞争力的3D特征场，同时保留了几何细节。

Conclusion: CF3通过采用自顶向下方法，使用预训练的2D高斯和2D特征，并结合自编码器和自适应稀疏化技术，实现了紧凑且快速的3D高斯特征场。该方法在减少高斯数量的同时，能够保留几何细节，相比Feature-3DGS，高斯数量减少高达95%。

Abstract: 3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D
foundation models. However, most approaches rely on a bottom-up optimization
process that treats raw 2D features as ground truth, incurring increased
computational costs. We propose a top-down pipeline for constructing compact
and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast
weighted fusion of multi-view 2D features with pre-trained Gaussians. This
approach enables training a per-Gaussian autoencoder directly on the lifted
features, instead of training autoencoders in the 2D domain. As a result, the
autoencoder better aligns with the feature distribution. More importantly, we
introduce an adaptive sparsification method that optimizes the Gaussian
attributes of the feature field while pruning and merging the redundant
Gaussians, constructing an efficient representation with preserved geometric
details. Our approach achieves a competitive 3D feature field using as little
as 5% of the Gaussians compared to Feature-3DGS.

</details>


### [59] [Robust Tracking with Particle Filtering for Fluorescent Cardiac Imaging](https://arxiv.org/abs/2508.05262)
*Suresh Guttikonda,Maximilian Neidhart,Johanna Sprenger,Johannes Petersen,Christian Detter,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 一种新的粒子滤波跟踪器能够准确、实时地跟踪心脏手术中的目标地标，提高了术中荧光成像的质量控制。


<details>
  <summary>Details</summary>
Motivation: 传统的光学跟踪方法在心脏手术中容易受到心脏运动和血管结构引起的图像特征变化的影响，限制了其在冠状动脉搭桥手术中进行术中荧光心脏成像的质量控制。

Method: 提出了一种基于循环一致性检查的粒子滤波跟踪器，用于在心脏运动和血管结构引起的图像特征显著波动的情况下，稳健地跟踪用于估计局部量化指标（如心肌灌注）的目标地标。

Result: 该方法能够同时跟踪117个目标，速度为25.4帧/秒，实现了实时估计，跟踪误差为（5.00 +/- 0.22 px），优于其他深度学习跟踪器（22.3 +/- 1.1 px）和传统跟踪器（58.1 +/- 27.1 px）。

Conclusion: 所提出的基于循环一致性检查的粒子滤波跟踪器能够稳健地跟踪粒子，以追踪目标地标。

Abstract: Intraoperative fluorescent cardiac imaging enables quality control following
coronary bypass grafting surgery. We can estimate local quantitative
indicators, such as cardiac perfusion, by tracking local feature points.
However, heart motion and significant fluctuations in image characteristics
caused by vessel structural enrichment limit traditional tracking methods. We
propose a particle filtering tracker based on cyclicconsistency checks to
robustly track particles sampled to follow target landmarks. Our method tracks
117 targets simultaneously at 25.4 fps, allowing real-time estimates during
interventions. It achieves a tracking error of (5.00 +/- 0.22 px) and
outperforms other deep learning trackers (22.3 +/- 1.1 px) and conventional
trackers (58.1 +/- 27.1 px).

</details>


### [60] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
*Yufei Gao,Jiaying Fei,Nuo Chen,Ruirui Chen,Guohang Yan,Yunshi Lan,Botian Shi*

Main category: cs.CV

TL;DR: 为解决低资源语言MLLM效果不佳的问题，提出双源策略和MELLA数据集，通过结合文化信息和语言能力，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在高资源语言中表现出色，但在低资源语言中效果不佳。现有方法侧重于文本或机器翻译，忽略了多模态信息和文化基础的重要性，而这两者对于有效服务低资源语言用户至关重要。

Method: 提出了一种双源策略，并引入了一个名为MELLA的多模态、多语言数据集。该策略指导数据收集，利用本地网页alt文本来获取文化信息，利用MLLM生成的标题来增强语言能力。

Result: 在MELLA数据集上进行微调后，八种语言的MLLM在各项指标上均有所提升，模型能够生成更丰富的描述。研究验证了性能提升同时来源于文化知识和语言能力的增强。

Conclusion: 该研究提出了一个双源策略，通过收集针对每项目标量身定制的数据（包括用于文化的本地网页alt文本和用于语言学的MLLM生成的标题）来弥合低资源语言MLLM在语言能力和文化基础方面的差距。实验结果表明，在MELLA数据集上进行微调可以提高八种语言的MLLM性能，生成更丰富的描述，并且性能提升同时归因于文化知识和语言能力的增强。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable performance in
high-resource languages. However, their effectiveness diminishes significantly
in the contexts of low-resource languages. Current multilingual enhancement
methods are often limited to text modality or rely solely on machine
translation. While such approaches help models acquire basic linguistic
capabilities and produce "thin descriptions", they neglect the importance of
multimodal informativeness and cultural groundedness, both of which are crucial
for serving low-resource language users effectively. To bridge this gap, in
this study, we identify two significant objectives for a truly effective MLLM
in low-resource language settings, namely 1) linguistic capability and 2)
cultural groundedness, placing special emphasis on cultural awareness. To
achieve these dual objectives, we propose a dual-source strategy that guides
the collection of data tailored to each goal, sourcing native web alt-text for
culture and MLLM-generated captions for linguistics. As a concrete
implementation, we introduce MELLA, a multimodal, multilingual dataset.
Experiment results show that after fine-tuning on MELLA, there is a general
performance improvement for the eight languages on various MLLM backbones, with
models producing "thick descriptions". We verify that the performance gains are
from both cultural knowledge enhancement and linguistic capability enhancement.
Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.

</details>


### [61] [SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion](https://arxiv.org/abs/2508.05264)
*Xiaoyang Zhang,Zhen Hua,Yakun Ju,Wei Zhou,Jun Liu,Alex C. Kot*

Main category: cs.CV

TL;DR: SGDFuse uses SAM-guided diffusion for high-fidelity, semantically-aware infrared and visible image fusion, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing IVIF methods fail to preserve key targets due to lack of semantic understanding and can introduce artifacts/detail loss. SGDFuse aims to address these issues by achieving high-fidelity and semantically-aware image fusion.

Method: SGDFuse is a conditional diffusion model guided by SAM. It uses SAM-generated semantic masks as explicit priors to guide the fusion process. The framework involves a two-stage process: preliminary fusion of multi-modal features, followed by using SAM masks and the preliminary fused image to drive a diffusion model's coarse-to-fine denoising generation.

Result: Extensive experiments demonstrate that SGDFuse achieves state-of-the-art performance in both subjective and objective evaluations, as well as in its adaptability to downstream tasks.

Conclusion: SGDFuse has achieved state-of-the-art performance in subjective and objective evaluations, and is adaptable to downstream tasks, offering a powerful solution to image fusion challenges.

Abstract: Infrared and visible image fusion (IVIF) aims to combine the thermal
radiation information from infrared images with the rich texture details from
visible images to enhance perceptual capabilities for downstream visual tasks.
However, existing methods often fail to preserve key targets due to a lack of
deep semantic understanding of the scene, while the fusion process itself can
also introduce artifacts and detail loss, severely compromising both image
quality and task performance. To address these issues, this paper proposes
SGDFuse, a conditional diffusion model guided by the Segment Anything Model
(SAM), to achieve high-fidelity and semantically-aware image fusion. The core
of our method is to utilize high-quality semantic masks generated by SAM as
explicit priors to guide the optimization of the fusion process via a
conditional diffusion model. Specifically, the framework operates in a
two-stage process: it first performs a preliminary fusion of multi-modal
features, and then utilizes the semantic masks from SAM jointly with the
preliminary fused image as a condition to drive the diffusion model's
coarse-to-fine denoising generation. This ensures the fusion process not only
has explicit semantic directionality but also guarantees the high fidelity of
the final result. Extensive experiments demonstrate that SGDFuse achieves
state-of-the-art performance in both subjective and objective evaluations, as
well as in its adaptability to downstream tasks, providing a powerful solution
to the core challenges in image fusion. The code of SGDFuse is available at
https://github.com/boshizhang123/SGDFuse.

</details>


### [62] [B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding](https://arxiv.org/abs/2508.05269)
*Changho Choi,Youngwoo Shin,Gyojin Han,Dong-Jae Lee,Junmo Kim*

Main category: cs.CV

TL;DR: B4DL是一个针对4D LiDAR理解的新基准和数据集，以及一个能够直接处理原始4D LiDAR并将其与语言理解相结合的MLLM模型，以实现动态户外环境中的时空推理。


<details>
  <summary>Details</summary>
Motivation: 尽管4D LiDAR具有捕捉复杂对象交互和随时间演变的潜力，但由于缺乏高质量、特定于模态的注释以及能够处理其高维组成的MLLM架构，它在MLLM的背景下仍未得到充分探索。

Method: 提出了一种可扩展的数据生成流程和一个MLLM模型，该模型通过将其与语言理解相结合，首次直接处理原始4D LiDAR。

Result: 通过B4DL基准、生成的数据集以及在各种场景下的推理输出来展示。

Conclusion: B4DL是一个新的基准，用于训练和评估MLLM在4D LiDAR理解方面的能力。结合其数据集和基准，所提出的模型为动态户外环境中的时空推理提供了一个统一的解决方案。

Abstract: Understanding dynamic outdoor environments requires capturing complex object
interactions and their evolution over time. LiDAR-based 4D point clouds provide
precise spatial geometry and rich temporal cues, making them ideal for
representing real-world scenes. However, despite their potential, 4D LiDAR
remains underexplored in the context of Multimodal Large Language Models
(MLLMs) due to the absence of high-quality, modality-specific annotations and
the lack of MLLM architectures capable of processing its high-dimensional
composition. To address these challenges, we introduce B4DL, a new benchmark
specifically designed for training and evaluating MLLMs on 4D LiDAR
understanding. In addition, we propose a scalable data generation pipeline and
an MLLM model that, for the first time, directly processes raw 4D LiDAR by
bridging it with language understanding. Combined with our dataset and
benchmark, our model offers a unified solution for spatio-temporal reasoning in
dynamic outdoor environments. We provide rendered 4D LiDAR videos, generated
dataset, and inference outputs on diverse scenarios at:
https://mmb4dl.github.io/mmb4dl/

</details>


### [63] [Wavelet-Guided Dual-Frequency Encoding for Remote Sensing Change Detection](https://arxiv.org/abs/2508.05271)
*Xiaoyang Zhang,Guodong Fan,Guang-Yong Chen,Zhen Hua,Jinjiang Li,Min Gan,C. L. Philip Chen*

Main category: cs.CV

TL;DR: WGDF利用小波变换将图像分解为高频和低频分量，并通过专门设计的模块分别处理，以增强细微变化和全局结构的检测能力，最终融合两者以提高遥感图像变化检测的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感图像变化检测方法主要依赖于空间域建模，但其有限的特征表示多样性难以检测细微的变化区域。作者认为，在小波域进行频域特征建模能够放大频分量的细微差异，从而更好地感知空间域难以捕捉的边缘变化。

Method: 提出了一种名为WGDF（Wavelet-Guided Dual-Frequency Encoding）的方法，该方法利用离散小波变换（DWT）将输入图像分解为高频和低频分量。在高频分支中，设计了双频特征增强（DFFE）模块和频域交互差（FDID）模块来增强边缘细节和细粒度变化。在低频分支中，利用Transformer捕捉全局语义关系，并使用渐进上下文差分（PCDM）模块逐步细化变化区域。最后，融合高低频特征以结合局部敏感性和全局判别力。

Result: WGDF显著减轻了边缘模糊性，并在多个遥感数据集上取得了优于最先进方法的检测精度和鲁棒性。

Conclusion: WGDF通过融合高频和低频特征，有效解决了边缘模糊性问题，并在多个遥感数据集上实现了优于现有方法的检测精度和鲁棒性。

Abstract: Change detection in remote sensing imagery plays a vital role in various
engineering applications, such as natural disaster monitoring, urban expansion
tracking, and infrastructure management. Despite the remarkable progress of
deep learning in recent years, most existing methods still rely on
spatial-domain modeling, where the limited diversity of feature representations
hinders the detection of subtle change regions. We observe that
frequency-domain feature modeling particularly in the wavelet domain an amplify
fine-grained differences in frequency components, enhancing the perception of
edge changes that are challenging to capture in the spatial domain. Thus, we
propose a method called Wavelet-Guided Dual-Frequency Encoding (WGDF).
Specifically, we first apply Discrete Wavelet Transform (DWT) to decompose the
input images into high-frequency and low-frequency components, which are used
to model local details and global structures, respectively. In the
high-frequency branch, we design a Dual-Frequency Feature Enhancement (DFFE)
module to strengthen edge detail representation and introduce a
Frequency-Domain Interactive Difference (FDID) module to enhance the modeling
of fine-grained changes. In the low-frequency branch, we exploit Transformers
to capture global semantic relationships and employ a Progressive Contextual
Difference Module (PCDM) to progressively refine change regions, enabling
precise structural semantic characterization. Finally, the high- and
low-frequency features are synergistically fused to unify local sensitivity
with global discriminability. Extensive experiments on multiple remote sensing
datasets demonstrate that WGDF significantly alleviates edge ambiguity and
achieves superior detection accuracy and robustness compared to
state-of-the-art methods. The code will be available at
https://github.com/boshizhang123/WGDF.

</details>


### [64] [VS-LLM: Visual-Semantic Depression Assessment based on LLM for Drawing Projection Test](https://arxiv.org/abs/2508.05299)
*Meiqi Wu,Yaxuan Kang,Xuchen Li,Shiyu Hu,Xiaotang Chen,Yunfeng Kang,Weiqiang Wang,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为VS-LLM的新方法，利用大语言模型分析“一个人从树上摘苹果”的素描，以评估抑郁状态。该方法比人工评估更准确，能提高17.6%的准确率，并已开源。


<details>
  <summary>Details</summary>
Motivation: 为了解决艺术治疗中PPAT素描解释耗时且依赖心理学家经验的问题，本研究旨在开发一种有效的识别方法，以支持大规模自动化的DPT，从而提高心理状态评估的效率和客观性。

Method: 提出了一种视觉-语义大语言模型（VS-LLM）方法，用于分析PPAT素描的颜色使用和空间利用等整体特征，以评估抑郁状态。该方法旨在解决传统DPT解释的繁琐性和对经验的依赖性，并应对低绘图精度和细节缺乏的挑战。

Result: 实验结果表明，所提出的VS-LLM方法在抑郁评估方面比传统的心理学家评估方法提高了17.6%的准确率。

Conclusion: 该研究提出了一种基于视觉-语义大语言模型（VS-LLM）的抑郁评估方法，通过分析“一个人从树上摘苹果”（PPAT）的素描，能够比心理学家评估方法提高17.6%的准确率，为大规模自动化DPT（Drawing Projection Test）和心理状态评估研究做出了贡献。

Abstract: The Drawing Projection Test (DPT) is an essential tool in art therapy,
allowing psychologists to assess participants' mental states through their
sketches. Specifically, through sketches with the theme of "a person picking an
apple from a tree (PPAT)", it can be revealed whether the participants are in
mental states such as depression. Compared with scales, the DPT can enrich
psychologists' understanding of an individual's mental state. However, the
interpretation of the PPAT is laborious and depends on the experience of the
psychologists. To address this issue, we propose an effective identification
method to support psychologists in conducting a large-scale automatic DPT.
Unlike traditional sketch recognition, DPT more focus on the overall evaluation
of the sketches, such as color usage and space utilization. Moreover, PPAT
imposes a time limit and prohibits verbal reminders, resulting in low drawing
accuracy and a lack of detailed depiction. To address these challenges, we
propose the following efforts: (1) Providing an experimental environment for
automated analysis of PPAT sketches for depression assessment; (2) Offering a
Visual-Semantic depression assessment based on LLM (VS-LLM) method; (3)
Experimental results demonstrate that our method improves by 17.6% compared to
the psychologist assessment method. We anticipate that this work will
contribute to the research in mental state assessment based on PPAT sketches'
elements recognition. Our datasets and codes are available at
https://github.com/wmeiqi/VS-LLM.

</details>


### [65] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
*Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large
Language Models (LLMs) by decomposing complex tasks into simpler, sequential
subtasks. However, extending CoT to vision-language reasoning tasks remains
challenging, as it often requires interpreting transitions of visual states to
support reasoning. Existing methods often struggle with this due to limited
capacity of modeling visual state transitions or incoherent visual trajectories
caused by fragmented architectures.
  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought
framework that enables coherent and grounded multimodal reasoning within a
single unified model. The key idea is to leverage a model capable of both image
understanding and generation to reason over visual content and model evolving
visual states. However, empowering a unified model to achieve that is
non-trivial, given the high computational cost and the burden of training. To
address this, Uni-CoT introduces a novel two-level reasoning paradigm: A
Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask
execution. This design significantly reduces the computational overhead.
Furthermore, we introduce a structured training paradigm that combines
interleaved image-text supervision for macro-level CoT with multi-task
objectives for micro-level CoT. Together, these innovations allow Uni-CoT to
perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our
design, all experiments can be efficiently completed using only 8 A100 GPUs
with 80GB VRAM each. Experimental results on reasoning-driven image generation
benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT
demonstrates SOTA performance and strong generalization, establishing Uni-CoT
as a promising solution for multi-modal reasoning. Project Page and Code:
https://sais-fuxi.github.io/projects/uni-cot/

</details>


### [66] [CoCAViT: Compact Vision Transformer with Robust Global Coordination](https://arxiv.org/abs/2508.05307)
*Xuyang Wang,Lingjuan Miao,Zhiqiang Zhou*

Main category: cs.CV

TL;DR: 该研究提出CoCAViT，一种用于实时视觉表示的新型视觉骨干网络，通过CoCA机制解决了高效模型在OOD数据上的泛化能力下降问题，并在多项基准测试中取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有高效视觉模型在小模型和OOD（分布外）数据上泛化能力不足的问题，即性能下降比例不成比例地更大。

Method: 提出了一种名为Coordinator-patch Cross Attention (CoCA)的机制，该机制利用动态、领域感知的全局令牌来增强局部-全局特征建模，并以最小的计算开销适应性地捕捉跨领域的鲁棒模式。将此机制整合到新的视觉骨干网络CoCAViT中。

Result: 在224*224分辨率下，CoCAViT-28M在ImageNet-1K上达到了84.0%的top-1准确率，在多个OOD基准测试上相比竞争模型有显著提升。在COCO目标检测上 đạt 52.2 mAP，在ADE20K语义分割上 đạt 51.3 mIOU，同时保持低延迟。

Conclusion: CoCAViT通过引入CoCA机制，在保持低延迟的同时，在ImageNet-1K、COCO目标检测和ADE20K语义分割等多个基准测试中展现了优越的泛化能力和性能，尤其在小模型和OOD数据上表现突出。

Abstract: In recent years, large-scale visual backbones have demonstrated remarkable
capabilities in learning general-purpose features from images via extensive
pre-training. Concurrently, many efficient architectures have emerged that have
performance comparable to that of larger models on in-domain benchmarks.
However, we observe that for smaller models, the performance drop on
out-of-distribution (OOD) data is disproportionately larger, indicating a
deficiency in the generalization performance of existing efficient models. To
address this, we identify key architectural bottlenecks and inappropriate
design choices that contribute to this issue, retaining robustness for smaller
models. To restore the global field of pure window attention, we further
introduce a Coordinator-patch Cross Attention (CoCA) mechanism, featuring
dynamic, domain-aware global tokens that enhance local-global feature modeling
and adaptively capture robust patterns across domains with minimal
computational overhead. Integrating these advancements, we present CoCAViT, a
novel visual backbone designed for robust real-time visual representation.
Extensive experiments empirically validate our design. At a resolution of
224*224, CoCAViT-28M achieves 84.0% top-1 accuracy on ImageNet-1K, with
significant gains on multiple OOD benchmarks, compared to competing models. It
also attains 52.2 mAP on COCO object detection and 51.3 mIOU on ADE20K semantic
segmentation, while maintaining low latency.

</details>


### [67] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
*Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen*

Main category: cs.CV

TL;DR: 本研究提出GUI-RC和GUI-RCPO两种无需训练的方法，利用模型预测的区域一致性来提高GUI基础的准确性，并能在测试时通过强化学习进行自我监督优化。


<details>
  <summary>Details</summary>
Motivation: 现有GUI基础方法依赖于昂贵的像素级标注进行监督训练或强化学习，这限制了其成本效益和可用性。本研究的动机是利用模型在生成同一GUI元素时产生的多个预测中的空间重叠模式，从中提取隐含的置信度信号，以指导更准确的定位。

Method: GUI-RC是一种测试时缩放方法，它从多个采样预测中构建空间投票网格，以识别模型达成最高一致性的共识区域。GUI-RCPO将这些一致性模式转化为测试时强化学习的奖励，通过将每个预测与集体共识进行对齐来迭代优化模型输出。

Result: GUI-RC在ScreenSpot基准测试中，跨不同架构将准确率提高了2-3%。具体而言，GUI-RC将Qwen2.5-VL-3B-Instruct在ScreenSpot-v2上的准确率从80.11%提升至83.57%，而GUI-RCPO通过测试时强化学习将其进一步提升至85.14%。

Conclusion: GUI-RC通过在测试时利用模型多个预测之间的空间重叠模式来生成一致性区域，从而提高GUI基础的准确性。GUI-RCPO在此基础上，将一致性模式转化为测试时强化学习的奖励，通过自我监督优化进一步提升性能。该研究展示了测试时扩展和强化学习在GUI基础领域的潜力，为更鲁棒、更少依赖标注数据的GUI代理提供了新的途径。

Abstract: Graphical User Interface (GUI) grounding, the task of mapping natural
language instructions to precise screen coordinates, is fundamental to
autonomous GUI agents. While existing methods achieve strong performance
through extensive supervised training or reinforcement learning with labeled
rewards, they remain constrained by the cost and availability of pixel-level
annotations. We observe that when models generate multiple predictions for the
same GUI element, the spatial overlap patterns reveal implicit confidence
signals that can guide more accurate localization. Leveraging this insight, we
propose GUI-RC (Region Consistency), a test-time scaling method that constructs
spatial voting grids from multiple sampled predictions to identify consensus
regions where models show highest agreement. Without any training, GUI-RC
improves accuracy by 2-3% across various architectures on ScreenSpot
benchmarks. We further introduce GUI-RCPO (Region Consistency Policy
Optimization), which transforms these consistency patterns into rewards for
test-time reinforcement learning. By computing how well each prediction aligns
with the collective consensus, GUI-RCPO enables models to iteratively refine
their outputs on unlabeled data during inference. Extensive experiments
demonstrate the generality of our approach: GUI-RC boosts
Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO
further improves it to 85.14% through self-supervised optimization. Our
approach reveals the untapped potential of test-time scaling and test-time
reinforcement learning for GUI grounding, offering a promising path toward more
robust and data-efficient GUI agents.

</details>


### [68] [mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering](https://arxiv.org/abs/2508.05318)
*Xu Yuan,Liangbo Ning,Wenqi Fan,Qing Li*

Main category: cs.CV

TL;DR: 该研究提出了一种名为mKG-RAG的新型框架，通过利用多模态知识图谱来改进视觉问答的准确性，并在实验中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的视觉问答（VQA）方法在处理非结构化文档时，常常会引入不相关或误导性内容，从而降低答案的准确性和可靠性。为了克服这些挑战，将多模态知识图谱（KG）集成到RAG框架中，以结构化知识增强生成过程，是一种有前景的解决方案。

Method: 该研究提出了一种名为mKG-RAG的新型多模态知识增强生成框架。该框架利用大型多模态模型（MLLM）进行关键词提取和视觉-文本匹配，从多模态文档中提取语义一致且模态对齐的实体和关系，构建高质量的多模态知识图谱作为结构化知识表示。此外，还引入了一种配备有与问题相关的多模态检索器的双阶段检索策略，以提高检索效率和精度。

Result: 实验结果表明，该方法在知识密集型VQA任务上显著优于现有方法，达到了新的最先进水平。

Conclusion: 该研究提出的mKG-RAG框架通过整合多模态知识图谱，显著优于现有方法，为知识密集型视觉问答设定了新的最先进水平。

Abstract: Recently, Retrieval-Augmented Generation (RAG) has been proposed to expand
internal knowledge of Multimodal Large Language Models (MLLMs) by incorporating
external knowledge databases into the generation process, which is widely used
for knowledge-based Visual Question Answering (VQA) tasks. Despite impressive
advancements, vanilla RAG-based VQA methods that rely on unstructured documents
and overlook the structural relationships among knowledge elements frequently
introduce irrelevant or misleading content, reducing answer accuracy and
reliability. To overcome these challenges, a promising solution is to integrate
multimodal knowledge graphs (KGs) into RAG-based VQA frameworks to enhance the
generation by introducing structured multimodal knowledge. Therefore, in this
paper, we propose a novel multimodal knowledge-augmented generation framework
(mKG-RAG) based on multimodal KGs for knowledge-intensive VQA tasks.
Specifically, our approach leverages MLLM-powered keyword extraction and
vision-text matching to distill semantically consistent and modality-aligned
entities/relationships from multimodal documents, constructing high-quality
multimodal KGs as structured knowledge representations. In addition, a
dual-stage retrieval strategy equipped with a question-aware multimodal
retriever is introduced to improve retrieval efficiency while refining
precision. Comprehensive experiments demonstrate that our approach
significantly outperforms existing methods, setting a new state-of-the-art for
knowledge-based VQA.

</details>


### [69] [Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting](https://arxiv.org/abs/2508.05323)
*Frank Ruis,Gertjan Burghouts,Hugo Kuijf*

Main category: cs.CV

TL;DR: 受Textual Inversion（TI）的启发，本研究提出了一种用于开放词汇对象检测的新方法，通过学习少量示例来扩展VLM词汇，以检测新颖或细粒度对象。该方法在保留VLM原始性能和零样本能力的同时，所需的计算资源显著减少。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练视觉语言模型（VLMs）在物体检测方面取得了最先进的性能，并在零样本能力方面表现出色，但要在特定目标上实现最佳性能，仍然需要某种形式的微调。然而，现有的微调方法通常会导致原始自然语言查询和零样本能力在 VLM 权重上的损失。本研究旨在解决这个问题，通过引入一种新的方法来个性化 VLM，以实现准确的对象检测，同时保留其原始能力。

Method: 本研究提出了一种受Textual Inversion（TI）启发的公式，用于开放词汇对象检测。通过学习新词或改进现有词，从少量（如三个）示例中准确检测新颖或细粒度的对象。TI允许扩展VLM词汇，并且学习到的词汇与原始VLM权重完全兼容，同时保持其冻结状态，从而保留了原始模型的基准性能和零样本域迁移等现有功能。存储和梯度计算仅限于词汇嵌入维度，所需计算量显著少于全模型微调。

Result: 通过一系列定量和定性实验评估，本研究提出的方法在各种场景下达到了与基线方法相当甚至更优的性能，并且有效解决了基线方法存在的遗忘问题。

Conclusion: 通过引入类似Textual Inversion（TI）的公式，本研究成功地为开放词汇对象检测实现了个性化，学习新词或改进现有词以从少量示例中准确检测新颖或细粒度对象。所学词汇与原始VLM权重完全兼容，同时保持其冻结状态，从而保留了原始模型的基准性能和零样本域迁移等现有功能。该方法仅限于词汇嵌入维度进行存储和梯度计算，所需的计算量远少于全模型微调。

Abstract: Recent progress in large pre-trained vision language models (VLMs) has
reached state-of-the-art performance on several object detection benchmarks and
boasts strong zero-shot capabilities, but for optimal performance on specific
targets some form of finetuning is still necessary. While the initial VLM
weights allow for great few-shot transfer learning, this usually involves the
loss of the original natural language querying and zero-shot capabilities.
Inspired by the success of Textual Inversion (TI) in personalizing
text-to-image diffusion models, we propose a similar formulation for
open-vocabulary object detection. TI allows extending the VLM vocabulary by
learning new or improving existing tokens to accurately detect novel or
fine-grained objects from as little as three examples. The learned tokens are
completely compatible with the original VLM weights while keeping them frozen,
retaining the original model's benchmark performance, and leveraging its
existing capabilities such as zero-shot domain transfer (e.g., detecting a
sketch of an object after training only on real photos). The storage and
gradient calculations are limited to the token embedding dimension, requiring
significantly less compute than full-model fine-tuning. We evaluated whether
the method matches or outperforms the baseline methods that suffer from
forgetting in a wide variety of quantitative and qualitative experiments.

</details>


### [70] [3DGabSplat: 3D Gabor Splatting for Frequency-adaptive Radiance Field Rendering](https://arxiv.org/abs/2508.05343)
*Junyu Zhou,Yuyang Huang,Wenrui Dai,Junni Zou,Ziyang Zheng,Nuowen Kan,Chenglin Li,Hongkai Xiong*

Main category: cs.CV

TL;DR: 3DGabSplat通过引入3D Gabor基元，克服了3DGS在细节表示、效率和内存方面的限制，实现了更高质量和更高效的新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）技术虽然实现了实时渲染和高保真新视角合成，但其固有的低通性质限制了其表示高频细节的能力，并导致了冗余的元基元、降低的训练和渲染效率以及过高的内存开销。

Method: 提出了一种新颖的3D Gabor基元，该基元具有多方向3D频率响应，能够捕捉精细的3D细节。构建了一个包含不同频率的3D Gabor核的滤波器组，以增强表示的灵活性和效率。开发了一个基于CUDA的光栅化器，将3D Gabor基元表征的多方向3D频率分量投影到2D图像平面。提出了一种频率自适应机制，用于基元的联合优化。

Result: 3DGabSplat在PSNR方面比3DGS提高了高达1.35 dB，同时减少了元基元数量和内存消耗。在真实世界和合成场景中均实现了最先进的渲染质量，超越了3DGS及其变体。

Conclusion: 3DGabSplat通过利用新颖的3D Gabor基元，结合多方向3D频率响应来表示辐射场，并结合高效的CUDA光栅化器和频率自适应机制，克服了3D高斯泼溅（3DGS）在表示高频细节方面的局限性，提高了训练和渲染效率，减少了内存开销。实验证明，3DGabSplat在渲染质量和效率上均优于3DGS及其变体，并在PSNR方面取得了显著提升，同时减少了元基元数量和内存消耗。

Abstract: Recent prominence in 3D Gaussian Splatting (3DGS) has enabled real-time
rendering while maintaining high-fidelity novel view synthesis. However, 3DGS
resorts to the Gaussian function that is low-pass by nature and is restricted
in representing high-frequency details in 3D scenes. Moreover, it causes
redundant primitives with degraded training and rendering efficiency and
excessive memory overhead. To overcome these limitations, we propose 3D Gabor
Splatting (3DGabSplat) that leverages a novel 3D Gabor-based primitive with
multiple directional 3D frequency responses for radiance field representation
supervised by multi-view images. The proposed 3D Gabor-based primitive forms a
filter bank incorporating multiple 3D Gabor kernels at different frequencies to
enhance flexibility and efficiency in capturing fine 3D details. Furthermore,
to achieve novel view rendering, an efficient CUDA-based rasterizer is
developed to project the multiple directional 3D frequency components
characterized by 3D Gabor-based primitives onto the 2D image plane, and a
frequency-adaptive mechanism is presented for adaptive joint optimization of
primitives. 3DGabSplat is scalable to be a plug-and-play kernel for seamless
integration into existing 3DGS paradigms to enhance both efficiency and quality
of novel view synthesis. Extensive experiments demonstrate that 3DGabSplat
outperforms 3DGS and its variants using alternative primitives, and achieves
state-of-the-art rendering quality across both real-world and synthetic scenes.
Remarkably, we achieve up to 1.35 dB PSNR gain over 3DGS with simultaneously
reduced number of primitives and memory consumption.

</details>


### [71] [PriorRG: Prior-Guided Contrastive Pre-training and Coarse-to-Fine Decoding for Chest X-ray Report Generation](https://arxiv.org/abs/2508.05353)
*Kang Liu,Zhuoqi Ma,Zikang Fang,Yunan Li,Kun Xie,Qiguang Miao*

Main category: cs.CV

TL;DR: PriorRG框架通过引入先验引导的对比预训练和先验感知的粗粒度解码，有效利用患者特定的先验知识，提升了胸部X光报告生成的临床准确性和流畅性，并在MIMIC-CXR和MIMIC-ABN数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的胸部X光报告生成方法大多忽略了患者特定的先验知识（如临床背景和最近的先验图像），而这些信息是放射科医生进行诊断推理的关键，导致模型无法捕捉诊断意图或疾病进展。

Method: PriorRG框架采用两阶段训练流程：第一阶段引入了先验引导的对比预训练方案，利用临床背景信息指导时空特征提取，使模型更紧密地与放射学报告中的内在时空语义对齐；第二阶段提出了先验感知的粗粒度解码方法，用于报告生成，逐步将患者特定的先验知识与视觉编码器的隐藏状态相结合，使模型能够与诊断重点对齐并跟踪疾病进展。

Result: PriorRG框架通过整合患者特定的先验知识，提高了生成报告的临床准确性和流畅性。

Conclusion: PriorRG框架在MIMIC-CXR和MIMIC-ABN数据集上进行了广泛的实验，结果表明其性能优于最先进的方法，在MIMIC-CXR上BLEU-4提高了3.6%，F1分数提高了3.8%，在MIMIC-ABN上BLEU-1提高了5.9%。

Abstract: Chest X-ray report generation aims to reduce radiologists' workload by
automatically producing high-quality preliminary reports. A critical yet
underexplored aspect of this task is the effective use of patient-specific
prior knowledge -- including clinical context (e.g., symptoms, medical history)
and the most recent prior image -- which radiologists routinely rely on for
diagnostic reasoning. Most existing methods generate reports from single
images, neglecting this essential prior information and thus failing to capture
diagnostic intent or disease progression. To bridge this gap, we propose
PriorRG, a novel chest X-ray report generation framework that emulates
real-world clinical workflows via a two-stage training pipeline. In Stage 1, we
introduce a prior-guided contrastive pre-training scheme that leverages
clinical context to guide spatiotemporal feature extraction, allowing the model
to align more closely with the intrinsic spatiotemporal semantics in radiology
reports. In Stage 2, we present a prior-aware coarse-to-fine decoding for
report generation that progressively integrates patient-specific prior
knowledge with the vision encoder's hidden states. This decoding allows the
model to align with diagnostic focus and track disease progression, thereby
enhancing the clinical accuracy and fluency of the generated reports. Extensive
experiments on MIMIC-CXR and MIMIC-ABN datasets demonstrate that PriorRG
outperforms state-of-the-art methods, achieving a 3.6% BLEU-4 and 3.8% F1 score
improvement on MIMIC-CXR, and a 5.9% BLEU-1 gain on MIMIC-ABN. Code and
checkpoints will be released upon acceptance.

</details>


### [72] [Cross-View Localization via Redundant Sliced Observations and A-Contrario Validation](https://arxiv.org/abs/2508.05369)
*Yongjun Zhang,Mingtao Xiong,Yi Wan,Gui-Song Xia*

Main category: cs.CV

TL;DR: Slice-Loc是一种新的两阶段CVL方法，通过将图像分割成子图像来生成冗余观测值，并使用a-contrario可靠性验证来过滤错误，从而提高了定位精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数CVL方法仅输出单一的相机位姿观测值，缺乏满足测量学原理所需的冗余观测值，导致难以通过观测数据的相互验证来评估定位的可靠性。

Method: Slice-Loc是一种两阶段方法，采用a-contrario可靠性验证。第一阶段，将查询图像分割成子图像，并为每个子图像估计3-DoF位姿，生成冗余观测值。第二阶段，利用几何刚度公式过滤错误的位姿，并将内点合并以生成最终的相机位姿。此外，还提出了一种根据切片图像位置分布估计虚警数量（NFA）的模型来量化定位的有效性。

Result: Slice-Loc将错误超过10m的比例降低到3%以下。在DReSS数据集的跨城市测试中，Slice-Loc将平均定位误差从4.47m降低到1.86m，平均方向误差从3.42°降低到1.24°，优于最先进的方法。

Conclusion: Slice-Loc通过使用a-contrario可靠性验证来处理CVL方法中缺乏冗余观测值的问题，通过将查询图像分割成子图像并为每个子图像估计3-DoF位姿，生成冗余的独立观测值，并提出几何刚度公式来过滤错误的位姿。此外，还提出了一种通过估计虚警数量（NFA）来量化定位有意义性的模型。Slice-Loc能够提高定位精度并有效检测故障，将错误超过10m的比例降低到3%以下，并将跨城市测试的平均定位误差从4.47m降低到1.86m，平均方向误差从3.42°降低到1.24°，优于现有技术。

Abstract: Cross-view localization (CVL) matches ground-level images with aerial
references to determine the geo-position of a camera, enabling smart vehicles
to self-localize offline in GNSS-denied environments. However, most CVL methods
output only a single observation, the camera pose, and lack the redundant
observations required by surveying principles, making it challenging to assess
localization reliability through the mutual validation of observational data.
To tackle this, we introduce Slice-Loc, a two-stage method featuring an
a-contrario reliability validation for CVL. Instead of using the query image as
a single input, Slice-Loc divides it into sub-images and estimates the 3-DoF
pose for each slice, creating redundant and independent observations. Then, a
geometric rigidity formula is proposed to filter out the erroneous 3-DoF poses,
and the inliers are merged to generate the final camera pose. Furthermore, we
propose a model that quantifies the meaningfulness of localization by
estimating the number of false alarms (NFA), according to the distribution of
the locations of the sliced images. By eliminating gross errors, Slice-Loc
boosts localization accuracy and effectively detects failures. After filtering
out mislocalizations, Slice-Loc reduces the proportion of errors exceeding 10 m
to under 3\%. In cross-city tests on the DReSS dataset, Slice-Loc cuts the mean
localization error from 4.47 m to 1.86 m and the mean orientation error from
$\mathbf{3.42^{\circ}}$ to $\mathbf{1.24^{\circ}}$, outperforming
state-of-the-art methods. Code and dataset will be available at:
https://github.com/bnothing/Slice-Loc.

</details>


### [73] [CT-GRAPH: Hierarchical Graph Attention Network for Anatomy-Guided CT Report Generation](https://arxiv.org/abs/2508.05375)
*Hamza Kalisch,Fabian Hörst,Jens Kleesiek,Ken Herrmann,Constantin Seibold*

Main category: cs.CV

TL;DR: CT-GRAPH是一种新的图神经网络模型，通过结合医学影像中的器官关系和患者整体信息，可以更准确地生成放射学报告。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前医学影像报告生成方法主要依赖全局图像特征，未能捕捉到精确报告所需的细粒度器官关系的不足，提出CT-GRAPH来辅助放射科医生减轻工作负担。

Method: CT-GRAPH是一种分层图注意力网络，它将解剖区域构建成图，并将细粒度的器官特征与更粗糙的解剖系统以及全局患者背景联系起来。该方法利用预训练的3D医学特征编码器，通过解剖掩码获取全局和器官层面的特征，然后在图表中进一步优化这些特征，最后将它们整合到大型语言模型中以生成报告。

Result: 所提出的CT-GRAPH方法在CT-RATE胸部CT数据集上进行了评估，并取得了F1分数上比现有技术高出7.9%的绝对值提升。

Conclusion: CT-GRAPH通过在图表中整合解剖学特征和全局患者信息，能够生成详细的医学报告，并在F1分数上比现有方法有显著的提高（绝对值提高7.9%）。

Abstract: As medical imaging is central to diagnostic processes, automating the
generation of radiology reports has become increasingly relevant to assist
radiologists with their heavy workloads. Most current methods rely solely on
global image features, failing to capture fine-grained organ relationships
crucial for accurate reporting. To this end, we propose CT-GRAPH, a
hierarchical graph attention network that explicitly models radiological
knowledge by structuring anatomical regions into a graph, linking fine-grained
organ features to coarser anatomical systems and a global patient context. Our
method leverages pretrained 3D medical feature encoders to obtain global and
organ-level features by utilizing anatomical masks. These features are further
refined within the graph and then integrated into a large language model to
generate detailed medical reports. We evaluate our approach for the task of
report generation on the large-scale chest CT dataset CT-RATE. We provide an
in-depth analysis of pretrained feature encoders for CT report generation and
show that our method achieves a substantial improvement of absolute 7.9\% in F1
score over current state-of-the-art methods. The code is publicly available at
https://github.com/hakal104/CT-GRAPH.

</details>


### [74] [Deformable Attention Graph Representation Learning for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2508.05382)
*Mingxi Fu,Xitong Ling,Yuxuan Chen,Jiawen Li,fanglei fu,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: A new GNN with deformable attention is presented for pathology image analysis, improving spatial understanding and achieving top results on multiple datasets.


<details>
  <summary>Details</summary>
Motivation: Existing Multiple Instance Learning (MIL) approaches struggle to capture spatial dependencies among tissue structures, and current Graph Neural Networks (GNNs) often overlook the physical spatial positions of tissue patches and lack specificity in attention mechanisms.

Method: A novel GNN framework with deformable attention is proposed. A dynamic weighted directed graph is constructed based on patch features, where each node aggregates contextual information from its neighbors via attention-weighted edges. Learnable spatial offsets informed by the real coordinates of each patch are incorporated to enable adaptive attention to morphologically relevant regions.

Result: The proposed framework achieves state-of-the-art performance on four benchmark datasets (TCGA-COAD, BRACS, gastric intestinal metaplasia grading, and intestinal ROI classification), demonstrating the power of deformable attention in capturing complex spatial structures in WSIs and ROIs.

Conclusion: We propose a novel GNN framework with deformable attention for pathology image analysis, achieving state-of-the-art performance on four benchmark datasets by adaptively attending to morphologically relevant regions across the slide.

Abstract: Accurate classification of Whole Slide Images (WSIs) and Regions of Interest
(ROIs) is a fundamental challenge in computational pathology. While mainstream
approaches often adopt Multiple Instance Learning (MIL), they struggle to
capture the spatial dependencies among tissue structures. Graph Neural Networks
(GNNs) have emerged as a solution to model inter-instance relationships, yet
most rely on static graph topologies and overlook the physical spatial
positions of tissue patches. Moreover, conventional attention mechanisms lack
specificity, limiting their ability to focus on structurally relevant regions.
In this work, we propose a novel GNN framework with deformable attention for
pathology image analysis. We construct a dynamic weighted directed graph based
on patch features, where each node aggregates contextual information from its
neighbors via attention-weighted edges. Specifically, we incorporate learnable
spatial offsets informed by the real coordinates of each patch, enabling the
model to adaptively attend to morphologically relevant regions across the
slide. This design significantly enhances the contextual field while preserving
spatial specificity. Our framework achieves state-of-the-art performance on
four benchmark datasets (TCGA-COAD, BRACS, gastric intestinal metaplasia
grading, and intestinal ROI classification), demonstrating the power of
deformable attention in capturing complex spatial structures in WSIs and ROIs.

</details>


### [75] [UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation](https://arxiv.org/abs/2508.05399)
*Wonjun Kang,Byeongkeun Ahn,Minjae Lee,Kevin Galim,Seunghyuk Oh,Hyung Il Koo,Nam Ik Cho*

Main category: cs.CV

TL;DR: UNCAGE 是一种新的方法，可以改进掩码生成 Transformer 在组合文本到图像生成中的性能。


<details>
  <summary>Details</summary>
Motivation: 掩码生成 Transformer 在组合文本到图像生成方面存在与扩散模型相似的局限性，尽管它们具有双向注意和并行解码的优点。UNCAGE 旨在解决掩码生成 Transformer 在组合文本到图像生成中的局限性。

Method: UNCAGE 通过利用注意图来优先揭开代表单个对象的 token。

Result: UNCAGE 在多个基准和度量上的一致地提高了定量和定性评估的性能，并且推理开销可忽略不计。

Conclusion: UNCAGE 是一种新颖的、无需训练的方法，通过利用注意图来优先揭开代表单个对象的 token，从而提高组合保真度。UNCAGE 在多个基准和度量上的一致地提高了定量和定性评估的性能，并且推理开销可忽略不计。

Abstract: Text-to-image (T2I) generation has been actively studied using Diffusion
Models and Autoregressive Models. Recently, Masked Generative Transformers have
gained attention as an alternative to Autoregressive Models to overcome the
inherent limitations of causal attention and autoregressive decoding through
bidirectional attention and parallel decoding, enabling efficient and
high-quality image generation. However, compositional T2I generation remains
challenging, as even state-of-the-art Diffusion Models often fail to accurately
bind attributes and achieve proper text-image alignment. While Diffusion Models
have been extensively studied for this issue, Masked Generative Transformers
exhibit similar limitations but have not been explored in this context. To
address this, we propose Unmasking with Contrastive Attention Guidance
(UNCAGE), a novel training-free method that improves compositional fidelity by
leveraging attention maps to prioritize the unmasking of tokens that clearly
represent individual objects. UNCAGE consistently improves performance in both
quantitative and qualitative evaluations across multiple benchmarks and
metrics, with negligible inference overhead. Our code is available at
https://github.com/furiosa-ai/uncage.

</details>


### [76] [From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](https://arxiv.org/abs/2508.05409)
*Farah Wahida,M. A. P. Chamikara,Yashothara Shanmugarasa,Mohan Baruwal Chhetri,Thilina Ranbaduge,Ibrahim Khalil*

Main category: cs.CV

TL;DR: TrueBiometric 通过使用多个大型视觉语言模型和多数表决机制来检测和纠正面部识别系统中的后门攻击，提高了准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的针对后门攻击的防御机制在精确定位和缓解被投毒图像方面仍面临挑战，同时又不损害数据效用，这会影响系统的整体可靠性。

Method: 提出了一种名为 TrueBiometric 的新颖且可泛化的方法，该方法利用多个最先进的大型视觉语言模型，并通过多数表决机制准确检测被投毒的图像。然后，使用有针对性的、经过校准的纠正噪声来纠正被识别的被投毒样本。

Result: TrueBiometric 能够以 100% 的准确率检测和纠正被投毒的图像，并且不会损害干净图像的准确性。

Conclusion: TrueBiometric 能够以 100% 的准确率检测和纠正被投毒的图像，同时不损害干净图像的准确性，与其他最先进的方法相比，为缓解面部识别系统中的后门攻击提供了一种更实用、更准确、更有效的方法。

Abstract: Biometric systems, such as face recognition systems powered by deep neural
networks (DNNs), rely on large and highly sensitive datasets. Backdoor attacks
can subvert these systems by manipulating the training process. By inserting a
small trigger, such as a sticker, make-up, or patterned mask, into a few
training images, an adversary can later present the same trigger during
authentication to be falsely recognized as another individual, thereby gaining
unauthorized access. Existing defense mechanisms against backdoor attacks still
face challenges in precisely identifying and mitigating poisoned images without
compromising data utility, which undermines the overall reliability of the
system. We propose a novel and generalizable approach, TrueBiometric:
Trustworthy Biometrics, which accurately detects poisoned images using a
majority voting mechanism leveraging multiple state-of-the-art large vision
language models. Once identified, poisoned samples are corrected using targeted
and calibrated corrective noise. Our extensive empirical results demonstrate
that TrueBiometric detects and corrects poisoned images with 100\% accuracy
without compromising accuracy on clean images. Compared to existing
state-of-the-art approaches, TrueBiometric offers a more practical, accurate,
and effective solution for mitigating backdoor attacks in face recognition
systems.

</details>


### [77] [Physical Adversarial Camouflage through Gradient Calibration and Regularization](https://arxiv.org/abs/2508.05414)
*Jiawei Liang,Siyuan Liang,Jianjie Huang,Chenxi Si,Ming Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出了一种梯度校准和梯度去相关方法，以解决物理对抗性伪装中梯度不一致和冲突的问题，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 物理对抗性伪装通过改变物体纹理来欺骗检测器，对自动驾驶等安全关键领域构成了重大安全风险。现有技术在多变的环境中存在挑战：1）跨距离的采样点密度不一致阻碍了保证局部连续性的梯度优化；2）从多个角度更新纹理梯度会导致冲突，降低优化稳定性和攻击效果。

Method: 提出了一种基于梯度优化的新型对抗性伪装框架。首先引入了一种梯度校准策略，通过将梯度从稀疏传播到未采样纹理点，确保跨距离的梯度更新一致性。其次，开发了一种梯度去相关方法，根据损失值对梯度进行优先级排序和正交化，通过消除冗余或冲突的更新来增强多角度优化中的稳定性和有效性。

Result: 实验结果表明，在各种检测模型、角度和距离下，该方法显著优于现有技术。

Conclusion: 该方法在不同角度和距离下显著超越了现有技术，在不同距离下的平均攻击成功率（ASR）提高了13.46%，在不同角度下提高了11.03%。

Abstract: The advancement of deep object detectors has greatly affected safety-critical
fields like autonomous driving. However, physical adversarial camouflage poses
a significant security risk by altering object textures to deceive detectors.
Existing techniques struggle with variable physical environments, facing two
main challenges: 1) inconsistent sampling point densities across distances
hinder the gradient optimization from ensuring local continuity, and 2)
updating texture gradients from multiple angles causes conflicts, reducing
optimization stability and attack effectiveness. To address these issues, we
propose a novel adversarial camouflage framework based on gradient
optimization. First, we introduce a gradient calibration strategy, which
ensures consistent gradient updates across distances by propagating gradients
from sparsely to unsampled texture points. Additionally, we develop a gradient
decorrelation method, which prioritizes and orthogonalizes gradients based on
loss values, enhancing stability and effectiveness in multi-angle optimization
by eliminating redundant or conflicting updates. Extensive experimental results
on various detection models, angles and distances show that our method
significantly exceeds the state of the art, with an average increase in attack
success rate (ASR) of 13.46% across distances and 11.03% across angles.
Furthermore, empirical evaluation in real-world scenarios highlights the need
for more robust system design.

</details>


### [78] [Smoothing Slot Attention Iterations and Recurrences](https://arxiv.org/abs/2508.05417)
*Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen*

Main category: cs.CV

TL;DR: SmoothSA通过预热和区分变换来改进OCL中的Slot Attention，提高了在视频和图像中的物体聚合精度。


<details>
  <summary>Details</summary>
Motivation: 当前OCL方法中的冷启动查询缺乏样本特异性线索，阻碍了在图像或视频第一帧上的精确聚合；非第一帧的查询已经具有样本特异性，需要与第一帧不同的变换。

Method: SmoothSA通过“预热”查询向量来平滑第一帧的SA迭代，并区分第一帧和非第一帧的变换来平滑跨帧的SA递归。

Result: 实验证明了SmoothSA在物体发现、识别和下游基准测试中的有效性，并通过进一步分析直观地阐明了其平滑SA迭代和递归的机制。

Conclusion: 该研究提出了SmoothSA，一种用于解决Slot Attention（SA）及其变体在物体中心学习（OCL）中的冷启动查询问题的方法。

Abstract: Slot Attention (SA) and its variants lie at the heart of mainstream
Object-Centric Learning (OCL). Objects in an image can be aggregated into
respective slot vectors, by \textit{iteratively} refining cold-start query
vectors, typically three times, via SA on image features. For video, such
aggregation is \textit{recurrently} shared across frames, with queries
cold-started on the first frame while transitioned from the previous frame's
slots on non-first frames. However, the cold-start queries lack sample-specific
cues thus hinder precise aggregation on the image or video's first frame; Also,
non-first frames' queries are already sample-specific thus require transforms
different from the first frame's aggregation. We address these issues for the
first time with our \textit{SmoothSA}: (1) To smooth SA iterations on the image
or video's first frame, we \textit{preheat} the cold-start queries with rich
information of input features, via a tiny module self-distilled inside OCL; (2)
To smooth SA recurrences across all video frames, we \textit{differentiate} the
homogeneous transforms on the first and non-first frames, by using full and
single iterations respectively. Comprehensive experiments on object discovery,
recognition and downstream benchmarks validate our method's effectiveness.
Further analyses intuitively illuminate how our method smooths SA iterations
and recurrences. Our code is available in the supplement.

</details>


### [79] [Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions](https://arxiv.org/abs/2508.05430)
*Hubert Baniecki,Maximilian Muschalik,Fabian Fumagalli,Barbara Hammer,Eyke Hüllermeier,Przemyslaw Biecek*

Main category: cs.CV

TL;DR: FIxLIP是一种基于博弈论的解释方法，用于解决视觉-语言模型中的跨模态交互问题，其解释效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的显著性图法会忽略视觉-语言模型中固有的复杂跨模态交互，而FIxLIP旨在解决此局限性。

Method: FIxLIP基于博弈论，利用加权Banzhaf交互指数来分析模型相似性。

Result: FIxLIP在MS COCO和ImageNet-1k基准测试中，能够生成高质量的解释，并且在比较CLIP与SigLIP-2以及ViT-B/32与ViT-L/16等不同模型方面表现出色。

Conclusion: FIxLIP作为一种统一的方法，可以分解视觉-语言编码器的相似性，并且该方法能够实现比一阶归因方法更好的解释。

Abstract: Language-image pre-training (LIP) enables the development of vision-language
models capable of zero-shot classification, localization, multimodal retrieval,
and semantic understanding. Various explanation methods have been proposed to
visualize the importance of input image-text pairs on the model's similarity
outputs. However, popular saliency maps are limited by capturing only
first-order attributions, overlooking the complex cross-modal interactions
intrinsic to such encoders. We introduce faithful interaction explanations of
LIP models (FIxLIP) as a unified approach to decomposing the similarity in
vision-language encoders. FIxLIP is rooted in game theory, where we analyze how
using the weighted Banzhaf interaction index offers greater flexibility and
improves computational efficiency over the Shapley interaction quantification
framework. From a practical perspective, we propose how to naturally extend
explanation evaluation metrics, like the pointing game and area between the
insertion/deletion curves, to second-order interaction explanations.
Experiments on MS COCO and ImageNet-1k benchmarks validate that second-order
methods like FIxLIP outperform first-order attribution methods. Beyond
delivering high-quality explanations, we demonstrate the utility of FIxLIP in
comparing different models like CLIP vs. SigLIP-2 and ViT-B/32 vs. ViT-L/16.

</details>


### [80] [How and Why: Taming Flow Matching for Unsupervised Anomaly Detection and Localization](https://arxiv.org/abs/2508.05461)
*Liangwei Li,Lin Liu,Juanxiu Liu,Jing Zhang,Ruqian Hao,Xiaohui Du*

Main category: cs.CV

TL;DR: 一种新的无监督异常检测和定位方法，使用流匹配（FM）和最差传输（WT）位移插值，解决了现有方法的局限性，并在MVTec数据集上取得了最好的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决无监督异常检测和定位任务中，传统基于流的方法在模型表达能力上存在的局限性。

Method: 提出了时间反转流匹配（rFM）将未知数据分布转化为标准高斯分布，并通过最差传输（WT）位移插值来构建非概率演化路径，以增强对样本轨迹的动力学控制，为无异常样本构建“退化势阱”，使异常样本能够逃逸。

Result: 所提出的WT-Flow作为FM在无监督异常检测任务上的首次成功应用，在MVTec数据集上取得了单尺度最先进的性能。

Conclusion: 提出了一种基于流匹配（FM）的无监督异常检测和定位新范式，解决了传统基于流方法模型表达能力受限的问题。通过形式化时间反转流匹配（rFM）概念，将未知数据分布转化为标准高斯分布，并提出了最差传输（WT）位移插值来构建非概率演化路径。WT-Flow增强了对样本轨迹的动力学控制，为无异常样本构建了“退化势阱”，同时允许异常样本逃逸，从而为异常样本提供了理论上可靠的分离机制。FM为无监督异常检测提供了一个计算上可行的框架，并且首次成功应用于该任务，在MVTec数据集上实现了单尺度最先进的性能。

Abstract: We propose a new paradigm for unsupervised anomaly detection and localization
using Flow Matching (FM), which fundamentally addresses the model expressivity
limitations of conventional flow-based methods. To this end, we formalize the
concept of time-reversed Flow Matching (rFM) as a vector field regression along
a predefined probability path to transform unknown data distributions into
standard Gaussian. We bring two core observations that reshape our
understanding of FM. First, we rigorously prove that FM with linear
interpolation probability paths is inherently non-invertible. Second, our
analysis reveals that employing reversed Gaussian probability paths in
high-dimensional spaces can lead to trivial vector fields. This issue arises
due to the manifold-related constraints. Building on the second observation, we
propose Worst Transport (WT) displacement interpolation to reconstruct a
non-probabilistic evolution path. The proposed WT-Flow enhances dynamical
control over sample trajectories, constructing ''degenerate potential wells''
for anomaly-free samples while allowing anomalous samples to escape. This novel
unsupervised paradigm offers a theoretically grounded separation mechanism for
anomalous samples. Notably, FM provides a computationally tractable framework
that scales to complex data. We present the first successful application of FM
for the unsupervised anomaly detection task, achieving state-of-the-art
performance at a single scale on the MVTec dataset. The reproducible code for
training will be released upon camera-ready submission.

</details>


### [81] [Keep It Real: Challenges in Attacking Compression-Based Adversarial Purification](https://arxiv.org/abs/2508.05489)
*Samuel Räber,Till Aczel,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 有损压缩可以防御对抗性扰动，但仅限于高真实度重建的模型


<details>
  <summary>Details</summary>
Motivation: 评估图像经过有损压缩后的鲁棒性

Method: 构建了强白盒和自适应攻击

Result: 高真实度重建模型比低真实度重建模型更能抵抗攻击

Conclusion: 高真实度重建能够抵抗住攻击，而低真实度重建则容易被攻击

Abstract: Previous work has suggested that preprocessing images through lossy
compression can defend against adversarial perturbations, but comprehensive
attack evaluations have been lacking. In this paper, we construct strong
white-box and adaptive attacks against various compression models and identify
a critical challenge for attackers: high realism in reconstructed images
significantly increases attack difficulty. Through rigorous evaluation across
multiple attack scenarios, we demonstrate that compression models capable of
producing realistic, high-fidelity reconstructions are substantially more
resistant to our attacks. In contrast, low-realism compression models can be
broken. Our analysis reveals that this is not due to gradient masking. Rather,
realistic reconstructions maintaining distributional alignment with natural
images seem to offer inherent robustness. This work highlights a significant
obstacle for future adversarial attacks and suggests that developing more
effective techniques to overcome realism represents an essential challenge for
comprehensive security evaluation.

</details>


### [82] [SMOL-MapSeg: Show Me One Label](https://arxiv.org/abs/2508.05501)
*Yunshuang Yuan,Frank Thiemann,Thorsten Dahms,Monika Sester*

Main category: cs.CV

TL;DR: 为了解决基础模型在处理风格多变的 历史地图时的不足，我们提出了一种名为“按需声明式”（OND）的知识引导提示方法，并将其应用于SAM模型，创建了SMOL-MapSeg。该方法通过显式提示来指导模型理解历史地图中的概念和模式，实现了对未见过的类别的自适应，并在分割任务上取得了优于UNet的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型（如UNet）在处理历史地图时存在局限性，而预训练的基础模型虽然在其他领域表现优异，但在处理风格和形态不一致的历史地图时效果不佳，因为它们依赖于现代或领域特定的图像及其常识或专家知识。历史地图的相似概念可能呈现出截然不同的形状和风格，这使得基础模型难以有效提取信息。

Method: 提出了一种名为“按需声明式”（OND）的知识引导提示方法，通过引入显式提示来指导模型理解历史地图中的概念和模式对应关系。具体实现上，用OND提示机制替换了SAM（Segment Anything Model）模型的基础提示编码器，并在历史地图数据集上进行了微调，最终得到SMOL-MapSeg（Show Me One Label）模型。

Result: SMOL-MapSeg模型能够准确分割由OND知识定义的类别，并且可以通过少样本微调适应未见过的类别。此外，其平均分割性能优于基于UNet的基线模型。

Conclusion: SMOL-MapSeg模型能够准确分割由OND知识定义的类别，并且可以通过少样本微调适应未见过的类别。此外，其平均分割性能优于基于UNet的基线模型。

Abstract: Historical maps are valuable for studying changes to the Earth's surface.
With the rise of deep learning, models like UNet have been used to extract
information from these maps through semantic segmentation. Recently,
pre-trained foundation models have shown strong performance across domains such
as autonomous driving, medical imaging, and industrial inspection. However,
they struggle with historical maps. These models are trained on modern or
domain-specific images, where patterns can be tied to predefined concepts
through common sense or expert knowledge. Historical maps lack such consistency
-- similar concepts can appear in vastly different shapes and styles. To
address this, we propose On-Need Declarative (OND) knowledge-based prompting,
which introduces explicit prompts to guide the model on what patterns
correspond to which concepts. This allows users to specify the target concept
and pattern during inference (on-need inference). We implement this by
replacing the prompt encoder of the foundation model SAM with our OND prompting
mechanism and fine-tune it on historical maps. The resulting model is called
SMOL-MapSeg (Show Me One Label). Experiments show that SMOL-MapSeg can
accurately segment classes defined by OND knowledge. It can also adapt to
unseen classes through few-shot fine-tuning. Additionally, it outperforms a
UNet-based baseline in average segmentation performance.

</details>


### [83] [AutoIAD: Manager-Driven Multi-Agent Collaboration for Automated Industrial Anomaly Detection](https://arxiv.org/abs/2508.05503)
*Dongwei Ji,Bingzhang Hu,Yi Zhou*

Main category: cs.CV

TL;DR: AutoIAD是一个创新的多智能体协作框架，通过自动化流程和领域知识库，实现了工业视觉异常检测的端到端开发，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的工业异常检测（IAD）需要大量的人工干预，AutoIAD旨在为工业视觉异常检测实现端到端的自动化开发。

Method: AutoIAD是一个多智能体协作框架，利用一个由管理器驱动的中心智能体来协调专门的子智能体（数据准备、数据加载器、模型设计器、训练器），并整合特定领域的知识库，以端到端的自动化方式开发工业视觉异常检测。

Result: 在MVTec AD数据集上的广泛实验表明，AutoIAD在任务完成率和模型性能（AUROC）方面显著优于现有方法，并能通过迭代优化有效减轻幻觉问题。消融研究也证实了管理器中心智能体和领域知识库在生成高质量IAD解决方案中的关键作用。

Conclusion: AutoIAD在MVTec AD数据集上表现出色，显著优于现有的通用自主协作框架和AutoML框架，在任务完成率和模型性能（AUROC）方面均有提升，并有效减少了幻觉问题。

Abstract: Industrial anomaly detection (IAD) is critical for manufacturing quality
control, but conventionally requires significant manual effort for various
application scenarios. This paper introduces AutoIAD, a multi-agent
collaboration framework, specifically designed for end-to-end automated
development of industrial visual anomaly detection. AutoIAD leverages a
Manager-Driven central agent to orchestrate specialized sub-agents (including
Data Preparation, Data Loader, Model Designer, Trainer) and integrates a
domain-specific knowledge base, which intelligently handles the entire pipeline
using raw industrial image data to develop a trained anomaly detection model.
We construct a comprehensive benchmark using MVTec AD datasets to evaluate
AutoIAD across various LLM backends. Extensive experiments demonstrate that
AutoIAD significantly outperforms existing general-purpose agentic
collaboration frameworks and traditional AutoML frameworks in task completion
rate and model performance (AUROC), while effectively mitigating issues like
hallucination through iterative refinement. Ablation studies further confirm
the crucial roles of the Manager central agent and the domain knowledge base
module in producing robust and high-quality IAD solutions.

</details>


### [84] [Symmetry Understanding of 3D Shapes via Chirality Disentanglement](https://arxiv.org/abs/2508.05505)
*Weikang Wang,Tobias Weißberg,Nafie El Amrani,Florian Bernard*

Main category: cs.CV

TL;DR: 本研究基于Diff3F框架，提出了一种从2D基础模型中提取手性特征的方法，以增强形状分析任务（如点云和网格）区分左右对称部分的能力，并在多项下游任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于手性信息在形状分析问题中普遍存在，但现有的形状描述符缺乏手性感知能力，无法区分对称的左右部分，因此有必要开发手性特征提取器。

Method: 该研究提出了一种无监督的手性特征提取流水线，该流水线基于Diff3F框架，并从2D基础模型中提取手性信息，用于装饰形状顶点。

Result: 提取的手性特征在左/右解缠、形状匹配和部件分割等下游任务中显示出有效性和实用性，并通过广泛的数据集进行了定量和定性评估。

Conclusion: 该研究提出了一个无监督的、基于Diff3F框架的、利用2D基础模型提取手性特征的流水线，为点云和网格等形状分析任务增加了手性感知信息。

Abstract: Chirality information (i.e. information that allows distinguishing left from
right) is ubiquitous for various data modes in computer vision, including
images, videos, point clouds, and meshes. While chirality has been extensively
studied in the image domain, its exploration in shape analysis (such as point
clouds and meshes) remains underdeveloped. Although many shape vertex
descriptors have shown appealing properties (e.g. robustness to rigid-body
transformations), they are often not able to disambiguate between left and
right symmetric parts. Considering the ubiquity of chirality information in
different shape analysis problems and the lack of chirality-aware features
within current shape descriptors, developing a chirality feature extractor
becomes necessary and urgent. Based on the recent Diff3F framework, we propose
an unsupervised chirality feature extraction pipeline to decorate shape
vertices with chirality-aware information, extracted from 2D foundation models.
We evaluated the extracted chirality features through quantitative and
qualitative experiments across diverse datasets. Results from downstream tasks
including left-right disentanglement, shape matching, and part segmentation
demonstrate their effectiveness and practical utility. Project page:
https://wei-kang-wang.github.io/chirality/

</details>


### [85] [MagicHOI: Leveraging 3D Priors for Accurate Hand-object Reconstruction from Short Monocular Video Clips](https://arxiv.org/abs/2508.05506)
*Shibo Wang,Haonan He,Maria Parelli,Christoph Gebhardt,Zicong Fan,Jie Song*

Main category: cs.CV

TL;DR: MagicHOI reconstructs hands and objects from videos, even with limited views, by using diffusion models for supervision on unseen parts and contact constraints for alignment, outperforming other methods.


<details>
  <summary>Details</summary>
Motivation: To overcome the limitations of existing RGB-based hand-object reconstruction methods that rely on object templates or assume full object visibility, which often breaks in real-world settings due to limited viewpoint variation and static grips, leading to implausible reconstructions.

Method: MagicHOI integrates a novel view synthesis model into a hand-object reconstruction framework and aligns hand to object by incorporating visible contact constraints.

Result: MagicHOI significantly outperforms existing state-of-the-art methods in hand-object reconstruction, and novel view synthesis diffusion priors effectively regularize unseen object regions.

Conclusion: MagicHOI's results significantly outperform existing state-of-the-art hand-object reconstruction methods, and novel view synthesis diffusion priors effectively regularize unseen object regions, enhancing 3D hand-object reconstruction.

Abstract: Most RGB-based hand-object reconstruction methods rely on object templates,
while template-free methods typically assume full object visibility. This
assumption often breaks in real-world settings, where fixed camera viewpoints
and static grips leave parts of the object unobserved, resulting in implausible
reconstructions. To overcome this, we present MagicHOI, a method for
reconstructing hands and objects from short monocular interaction videos, even
under limited viewpoint variation. Our key insight is that, despite the
scarcity of paired 3D hand-object data, large-scale novel view synthesis
diffusion models offer rich object supervision. This supervision serves as a
prior to regularize unseen object regions during hand interactions. Leveraging
this insight, we integrate a novel view synthesis model into our hand-object
reconstruction framework. We further align hand to object by incorporating
visible contact constraints. Our results demonstrate that MagicHOI
significantly outperforms existing state-of-the-art hand-object reconstruction
methods. We also show that novel view synthesis diffusion priors effectively
regularize unseen object regions, enhancing 3D hand-object reconstruction.

</details>


### [86] [Revealing Latent Information: A Physics-inspired Self-supervised Pre-training Framework for Noisy and Sparse Events](https://arxiv.org/abs/2508.05507)
*Lin Zhu,Ruonan Liu,Xiao Wang,Lizhi Wang,Hua Huang*

Main category: cs.CV

TL;DR: 事件相机数据稀疏有噪声，难以提取特征。本文提出自监督预训练框架，通过差分引导掩码建模、特征转换和对比学习，有效提取事件数据中的边缘和纹理信息，在多种下游任务中效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机虽然能提供高时间分辨率和宽动态范围的视觉信息，但其数据稀疏且充满噪声，主要反映亮度变化，给有效特征提取带来挑战。为了解决这个问题，需要一个框架来充分揭示事件数据中隐藏的边缘信息和纹理线索。

Method: 提出了一种自监督预训练框架，包括三个阶段：1. 差分引导掩码建模，用于从原始事件数据中提取增强信息；2. 主干固定特征转换，以在不更新主干的情况下对比事件和图像特征；3. 目标对比学习，通过关注高价值区域来提高语义辨别力。

Result: 该框架能够充分揭示事件数据中隐藏的边缘信息和纹理线索，并在各种下游任务中取得优于现有方法的性能。

Conclusion: 该框架在物体识别、语义分割和光流估计等下游任务中表现稳健，并且持续优于最先进的方法。

Abstract: Event camera, a novel neuromorphic vision sensor, records data with high
temporal resolution and wide dynamic range, offering new possibilities for
accurate visual representation in challenging scenarios. However, event data is
inherently sparse and noisy, mainly reflecting brightness changes, which
complicates effective feature extraction. To address this, we propose a
self-supervised pre-training framework to fully reveal latent information in
event data, including edge information and texture cues. Our framework consists
of three stages: Difference-guided Masked Modeling, inspired by the event
physical sampling process, reconstructs temporal intensity difference maps to
extract enhanced information from raw event data. Backbone-fixed Feature
Transition contrasts event and image features without updating the backbone to
preserve representations learned from masked modeling and stabilizing their
effect on contrastive learning. Focus-aimed Contrastive Learning updates the
entire model to improve semantic discrimination by focusing on high-value
regions. Extensive experiments show our framework is robust and consistently
outperforms state-of-the-art methods on various downstream tasks, including
object recognition, semantic segmentation, and optical flow estimation. The
code and dataset are available at https://github.com/BIT-Vision/EventPretrain.

</details>


### [87] [Head Anchor Enhanced Detection and Association for Crowded Pedestrian Tracking](https://arxiv.org/abs/2508.05514)
*Zewei Wu,César Teixeira,Wei Ke,Zhang Xiong*

Main category: cs.CV

TL;DR: 提出一种增强的跟踪框架，通过结合检测特征、头部关键点和改进的卡尔曼滤波，提升了在遮挡场景下的行人跟踪鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的行人跟踪方法在严重遮挡的情况下表现不佳，因为它们依赖于全身体征信息和简单的运动模型，这在行人相互遮挡时会导致轨迹不稳定。

Method: 本研究提出了一种增强的跟踪框架，结合了目标检测器回归和分类分支的特征，并引入了头部关键点检测模型。在运动模型方面，采用了迭代卡尔曼滤波方法，并整合了3D先验来处理复杂的运动轨迹。

Result: 通过结合更丰富的表观特征和更鲁棒的运动模型，该方法在遮挡场景下能够更稳定地跟踪行人。

Conclusion: 该方法通过结合检测特征、头部关键点以及改进的卡尔曼滤波方法，为多目标跟踪在拥挤和遮挡场景下提供了更鲁棒的解决方案。

Abstract: Visual pedestrian tracking represents a promising research field, with
extensive applications in intelligent surveillance, behavior analysis, and
human-computer interaction. However, real-world applications face significant
occlusion challenges. When multiple pedestrians interact or overlap, the loss
of target features severely compromises the tracker's ability to maintain
stable trajectories. Traditional tracking methods, which typically rely on
full-body bounding box features extracted from {Re-ID} models and linear
constant-velocity motion assumptions, often struggle in severe occlusion
scenarios. To address these limitations, this work proposes an enhanced
tracking framework that leverages richer feature representations and a more
robust motion model. Specifically, the proposed method incorporates detection
features from both the regression and classification branches of an object
detector, embedding spatial and positional information directly into the
feature representations. To further mitigate occlusion challenges, a head
keypoint detection model is introduced, as the head is less prone to occlusion
compared to the full body. In terms of motion modeling, we propose an iterative
Kalman filtering approach designed to align with modern detector assumptions,
integrating 3D priors to better complete motion trajectories in complex scenes.
By combining these advancements in appearance and motion modeling, the proposed
method offers a more robust solution for multi-object tracking in crowded
environments where occlusions are prevalent.

</details>


### [88] [FS-IQA: Certified Feature Smoothing for Robust Image Quality Assessment](https://arxiv.org/abs/2508.05516)
*Ekaterina Shumitskaya,Dmitriy Vatolin,Anastasia Antsiferova*

Main category: cs.CV

TL;DR: 该研究提出了一种在特征空间添加噪声的IQA模型认证防御方法，提高了鲁棒性并降低了计算成本，在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 为了正式将特征空间中的噪声水平与相应的输入空间扰动联系起来，分析了主干网络的雅可比矩阵的最大奇异值。

Method: 提出了一种新颖的基于随机平滑的图像质量评估（IQA）模型认证防御方法，该方法在特征空间而非输入空间中应用噪声。与在输入图像中直接注入高斯噪声（通常会降低视觉质量）的先前方法不同，该方法在保持图像保真度的同时提供了鲁棒性保证。

Result: 与以前的方法相比，在没有认证的情况下推理时间减少了99.5%，在应用认证的情况下推理时间减少了20.6%。在两个基准数据集上进行了广泛的实验，涉及六个广泛使用的FR和NR IQA模型，并与五个最先进的认证防御进行了比较。结果表明，与主观质量得分的相关性持续提高高达30.9%。

Conclusion: 该方法在不进行架构修改的情况下，支持全参考（FR）和无参考（NR）IQA模型，适用于各种场景，并且计算效率高，只需每次图像进行一次骨干网络前向传递。

Abstract: We propose a novel certified defense method for Image Quality Assessment
(IQA) models based on randomized smoothing with noise applied in the feature
space rather than the input space. Unlike prior approaches that inject Gaussian
noise directly into input images, often degrading visual quality, our method
preserves image fidelity while providing robustness guarantees. To formally
connect noise levels in the feature space with corresponding input-space
perturbations, we analyze the maximum singular value of the backbone network's
Jacobian. Our approach supports both full-reference (FR) and no-reference (NR)
IQA models without requiring any architectural modifications, suitable for
various scenarios. It is also computationally efficient, requiring a single
backbone forward pass per image. Compared to previous methods, it reduces
inference time by 99.5% without certification and by 20.6% when certification
is applied. We validate our method with extensive experiments on two benchmark
datasets, involving six widely-used FR and NR IQA models and comparisons
against five state-of-the-art certified defenses. Our results demonstrate
consistent improvements in correlation with subjective quality scores by up to
30.9%.

</details>


### [89] [Leveraging AI to Accelerate Clinical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods](https://arxiv.org/abs/2508.05519)
*Matthew Purri,Amit Patel,Erik Deurrell*

Main category: cs.CV

TL;DR: Octozi, an AI platform combining LLMs and heuristics, significantly improves clinical trial data cleaning. It boosts throughput 6x, reduces errors 6.4x, and slashes false positives 15.5x, accelerating drug development.


<details>
  <summary>Details</summary>
Motivation: Clinical trial data cleaning represents a critical bottleneck in drug development, with manual review processes struggling to manage exponentially increasing data volumes and complexity.

Method: This paper presents Octozi, an artificial intelligence-assisted platform that combines large language models with domain-specific heuristics to transform clinical data review. In a controlled experimental study with experienced clinical reviewers (n=10), we demonstrate the effectiveness of AI assistance.

Result: AI assistance increased data cleaning throughput by 6.03-fold while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a 6.44-fold improvement). The system reduced false positive queries by 15.48-fold, minimizing unnecessary site burden. These improvements were consistent across reviewers regardless of experience level.

Conclusion: AI-assisted approaches can address fundamental inefficiencies in clinical trial operations, potentially accelerating drug development timelines and reducing costs while maintaining regulatory compliance. This work establishes a framework for integrating AI into safety-critical clinical workflows and demonstrates the transformative potential of human-AI collaboration in pharmaceutical clinical trials.

Abstract: Clinical trial data cleaning represents a critical bottleneck in drug
development, with manual review processes struggling to manage exponentially
increasing data volumes and complexity. This paper presents Octozi, an
artificial intelligence-assisted platform that combines large language models
with domain-specific heuristics to transform clinical data review. In a
controlled experimental study with experienced clinical reviewers (n=10), we
demonstrate that AI assistance increased data cleaning throughput by 6.03-fold
while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a
6.44-fold improvement). Crucially, the system reduced false positive queries by
15.48-fold, minimizing unnecessary site burden. These improvements were
consistent across reviewers regardless of experience level, suggesting broad
applicability. Our findings indicate that AI-assisted approaches can address
fundamental inefficiencies in clinical trial operations, potentially
accelerating drug development timelines and reducing costs while maintaining
regulatory compliance. This work establishes a framework for integrating AI
into safety-critical clinical workflows and demonstrates the transformative
potential of human-AI collaboration in pharmaceutical clinical trials.

</details>


### [90] [Optimal Brain Connection: Towards Efficient Structural Pruning](https://arxiv.org/abs/2508.05521)
*Shaowu Chen,Wei Ma,Binhua Huang,Qingyuan Wang,Guoxin Wang,Weize Sun,Lei Huang,Deepu John*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Optimal Brain Connection的结构化剪枝框架，通过Jacobian Criterion和Equivalent Pruning机制来解决现有方法忽略参数间相互连接的问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽略了参数间的相互连接，导致剪枝后性能下降。本研究旨在解决此问题。

Method: 1. 提出Jacobian Criterion，一种评估结构参数显著性的二阶指标，考虑参数间的相互作用和层间依赖。 2. 提出Equivalent Pruning机制，利用自编码器在微调过程中保留被剪枝连接的贡献。

Result: Jacobian Criterion在保持模型性能方面优于其他流行指标，Equivalent Pruning机制有效缓解了微调后的性能下降。

Conclusion: 提出的Jacobian Criterion比其他结构化剪枝方法更能保持模型性能，Equivalent Pruning机制能有效缓解微调后的性能下降。

Abstract: Structural pruning has been widely studied for its effectiveness in
compressing neural networks. However, existing methods often neglect the
interconnections among parameters. To address this limitation, this paper
proposes a structural pruning framework termed Optimal Brain Connection. First,
we introduce the Jacobian Criterion, a first-order metric for evaluating the
saliency of structural parameters. Unlike existing first-order methods that
assess parameters in isolation, our criterion explicitly captures both
intra-component interactions and inter-layer dependencies. Second, we propose
the Equivalent Pruning mechanism, which utilizes autoencoders to retain the
contributions of all original connection--including pruned ones--during
fine-tuning. Experimental results demonstrate that the Jacobian Criterion
outperforms several popular metrics in preserving model performance, while the
Equivalent Pruning mechanism effectively mitigates performance degradation
after fine-tuning. Code: https://github.com/ShaowuChen/Optimal_Brain_Connection

</details>


### [91] [When Deepfake Detection Meets Graph Neural Network:a Unified and Lightweight Learning Framework](https://arxiv.org/abs/2508.05526)
*Haoyu Liu,Chaoyu Gong,Mengke He,Jiate Li,Kai Han,Siqiang Luo*

Main category: cs.CV

TL;DR: SSTGNN是一种轻量级图神经网络，通过联合分析空间、光谱和时间信息来检测AI生成的视频，效果优于现有模型，且模型更小。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成和篡改视频检测方法在处理不同类型的伪造时泛化能力不足，并且通常需要大型模型。

Method: 提出了一种名为SSTGNN的轻量级时空图神经网络框架，将视频表示为结构化图，并联合推理空间不一致性、时间伪影和光谱失真，同时引入了可学习的光谱滤波器和时间差分模型。

Result: 在各种基准数据集上进行了广泛实验，证明SSTGNN在同域和跨域设置下均取得了优越的性能，并且对未知的伪造操作具有很强的鲁棒性，参数量比现有最先进的模型少42.4倍。

Conclusion: SSTGNN是一个轻量级的时空图神经网络框架，在视频伪影检测方面表现出色，能够有效处理各种伪造类型，并且在参数量上具有显著优势，非常适合实际部署。

Abstract: The proliferation of generative video models has made detecting AI-generated
and manipulated videos an urgent challenge. Existing detection approaches often
fail to generalize across diverse manipulation types due to their reliance on
isolated spatial, temporal, or spectral information, and typically require
large models to perform well. This paper introduces SSTGNN, a lightweight
Spatial-Spectral-Temporal Graph Neural Network framework that represents videos
as structured graphs, enabling joint reasoning over spatial inconsistencies,
temporal artifacts, and spectral distortions. SSTGNN incorporates learnable
spectral filters and temporal differential modeling into a graph-based
architecture, capturing subtle manipulation traces more effectively. Extensive
experiments on diverse benchmark datasets demonstrate that SSTGNN not only
achieves superior performance in both in-domain and cross-domain settings, but
also offers strong robustness against unseen manipulations. Remarkably, SSTGNN
accomplishes these results with up to 42.4$\times$ fewer parameters than
state-of-the-art models, making it highly lightweight and scalable for
real-world deployment.

</details>


### [92] [AI vs. Human Moderators: A Comparative Evaluation of Multimodal LLMs in Content Moderation for Brand Safety](https://arxiv.org/abs/2508.05527)
*Adi Levi,Or Levi,Sardhendu Mishra,Jonathan Morra*

Main category: cs.CV

TL;DR: 由于在线视频内容激增，人工审核已不堪重负。本研究评估了大型语言模型（如 Gemini、GPT、Llama）在品牌安全分类中的表现，并提出了新的多语言数据集。结果表明，大型语言模型在品牌安全方面有效，但仍需改进，我们公开了数据集以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 随着在线视频内容的指数级增长，人工审核视频的成本高昂且对审核员的身心健康造成巨大挑战，而多模态大型语言模型（MLLMs）在视频理解方面展现出潜力，但其在需要细致视觉和文本理解的多模态内容审核领域的应用仍有待探索。

Method: 通过引入新颖的多模态和多语言数据集，对 Gemini、GPT 和 Llama 等大型语言模型在品牌安全分类任务上的能力进行基准测试和评估，并与专业人工审核员进行准确性和成本效益比较。

Result: 大型语言模型在多模态品牌安全方面表现出有效性，研究评估了它们与专业人工审核员相比的准确性和成本效益，并深入探讨了模型的局限性和失败案例。

Conclusion: 大型语言模型在多模态品牌安全方面展现出有效性，但仍存在局限性，需要进一步研究以实现更有效和负责任的内容审核。

Abstract: As the volume of video content online grows exponentially, the demand for
moderation of unsafe videos has surpassed human capabilities, posing both
operational and mental health challenges. While recent studies demonstrated the
merits of Multimodal Large Language Models (MLLMs) in various video
understanding tasks, their application to multimodal content moderation, a
domain that requires nuanced understanding of both visual and textual cues,
remains relatively underexplored. In this work, we benchmark the capabilities
of MLLMs in brand safety classification, a critical subset of content
moderation for safe-guarding advertising integrity. To this end, we introduce a
novel, multimodal and multilingual dataset, meticulously labeled by
professional reviewers in a multitude of risk categories. Through a detailed
comparative analysis, we demonstrate the effectiveness of MLLMs such as Gemini,
GPT, and Llama in multimodal brand safety, and evaluate their accuracy and cost
efficiency compared to professional human reviewers. Furthermore, we present an
in-depth discussion shedding light on limitations of MLLMs and failure cases.
We are releasing our dataset alongside this paper to facilitate future research
on effective and responsible brand safety and content moderation.

</details>


### [93] [Looking into the Unknown: Exploring Action Discovery for Segmentation of Known and Unknown Actions](https://arxiv.org/abs/2508.05529)
*Federico Spurio,Emad Bahrami,Olga Zatsarynna,Yazan Abu Farha,Gianpiero Francesca,Juergen Gall*

Main category: cs.CV

TL;DR: 提出“动作发现”新设置，解决部分标注数据中模糊或不完整动作的标注问题。通过“粒度引导分割模块”和“未知动作段分配”来识别和分类未知动作，并在三个数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在时间动作分割（Temporal Action Segmentation）的背景下，引入了一种新的设置——动作发现（Action Discovery），以应对在部分标注数据集中定义和标注模糊动作及不完整标注的挑战。这种情况在神经科学等领域尤为常见，其中明确定义的行为（如行走、吃饭）与微妙或不频繁但常被忽略的动作并存，也适用于因标签模糊或缺失而导致数据本身就部分标注的应用。

Method: 提出了一种两步方法来解决动作发现问题：1. 引入粒度引导分割模块（GGSM），通过模仿标注动作的粒度来识别已知和未知动作的时间间隔。2. 提出未知动作段分配（UASA）模块，基于学习到的嵌入相似性来识别未知动作中具有语义意义的类别。

Result: 所提出的方法（GGSM和UASA）在三个具有挑战性的数据集（Breakfast、50Salads和Desktop Assembly）上，相较于现有基线方法，显著提高了性能。

Conclusion: 该方法在Breakfast、50Salads和Desktop Assembly三个数据集上进行了系统性实验，结果表明所提出的方法能够显著优于现有基线方法。

Abstract: We introduce Action Discovery, a novel setup within Temporal Action
Segmentation that addresses the challenge of defining and annotating ambiguous
actions and incomplete annotations in partially labeled datasets. In this
setup, only a subset of actions - referred to as known actions - is annotated
in the training data, while other unknown actions remain unlabeled. This
scenario is particularly relevant in domains like neuroscience, where
well-defined behaviors (e.g., walking, eating) coexist with subtle or
infrequent actions that are often overlooked, as well as in applications where
datasets are inherently partially annotated due to ambiguous or missing labels.
To address this problem, we propose a two-step approach that leverages the
known annotations to guide both the temporal and semantic granularity of
unknown action segments. First, we introduce the Granularity-Guided
Segmentation Module (GGSM), which identifies temporal intervals for both known
and unknown actions by mimicking the granularity of annotated actions. Second,
we propose the Unknown Action Segment Assignment (UASA), which identifies
semantically meaningful classes within the unknown actions, based on learned
embedding similarities. We systematically explore the proposed setting of
Action Discovery on three challenging datasets - Breakfast, 50Salads, and
Desktop Assembly - demonstrating that our method considerably improves upon
existing baselines.

</details>


### [94] [Follow-Your-Instruction: A Comprehensive MLLM Agent for World Data Synthesis](https://arxiv.org/abs/2508.05580)
*Kunyu Feng,Yue Ma,Xinhua Zhang,Boshi Liu,Yikuang Yuluo,Yinhan Zhang,Runtao Liu,Hongyu Liu,Zhiyuan Qin,Shanhui Mo,Qifeng Chen,Zeyu Wang*

Main category: cs.CV

TL;DR: A new framework called Follow-Your-Instruction uses AI to automatically create 2D, 3D, and 4D data, addressing the challenges of costly and time-consuming data collection for AI development. This AI-generated data improves the performance of other AI models.


<details>
  <summary>Details</summary>
Motivation: The increasing demand for AI-generated content (AIGC) necessitates high-quality, diverse, and scalable data. However, collecting real-world data is costly and time-consuming, and existing manual or rendering-based approaches for data collection have limitations in scalability and accuracy.

Method: The proposed Follow-Your-Instruction framework utilizes a Multimodal Large Language Model (MLLM) to automatically synthesize 2D, 3D, and 4D data. It involves an MLLM-Collector for gathering assets and descriptions via multimodal inputs, followed by the MLLM-Generator for constructing 3D layouts and leveraging Vision-Language Models (VLMs) for semantic refinement through multi-view scenes. The MLLM-Optimizer further refines these scenes, and the MLLM-Planner generates temporally coherent future frames.

Result: Comprehensive experiments on 2D, 3D, and 4D generative tasks demonstrate that the synthetic data generated by Follow-Your-Instruction significantly boosts the performance of existing baseline models.

Conclusion: The synthetic data generated by Follow-Your-Instruction significantly improves the performance of existing baseline models, showcasing its potential as a scalable and effective data engine for generative intelligence.

Abstract: With the growing demands of AI-generated content (AIGC), the need for
high-quality, diverse, and scalable data has become increasingly crucial.
However, collecting large-scale real-world data remains costly and
time-consuming, hindering the development of downstream applications. While
some works attempt to collect task-specific data via a rendering process, most
approaches still rely on manual scene construction, limiting their scalability
and accuracy. To address these challenges, we propose Follow-Your-Instruction,
a Multimodal Large Language Model (MLLM)-driven framework for automatically
synthesizing high-quality 2D, 3D, and 4D data. Our
\textbf{Follow-Your-Instruction} first collects assets and their associated
descriptions through multimodal inputs using the MLLM-Collector. Then it
constructs 3D layouts, and leverages Vision-Language Models (VLMs) for semantic
refinement through multi-view scenes with the MLLM-Generator and
MLLM-Optimizer, respectively. Finally, it uses MLLM-Planner to generate
temporally coherent future frames. We evaluate the quality of the generated
data through comprehensive experiments on the 2D, 3D, and 4D generative tasks.
The results show that our synthetic data significantly boosts the performance
of existing baseline models, demonstrating Follow-Your-Instruction's potential
as a scalable and effective data engine for generative intelligence.

</details>


### [95] [DART: Dual Adaptive Refinement Transfer for Open-Vocabulary Multi-Label Recognition](https://arxiv.org/abs/2508.05585)
*Haijing Liu,Tao Pu,Hefeng Wu,Keze Wang,Liang Lin*

Main category: cs.CV

TL;DR: DART框架通过结合自适应的类内精炼和利用LLM知识的类间迁移，解决了OV-MLR任务中的定位和关系推理问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言预训练（VLP）模型在开放词汇多标签识别（OV-MLR）任务上面临挑战，尤其是在弱监督下的细粒度定位以及利用结构化关系知识方面存在不足，这限制了其性能，特别是在处理未见过的类别时。

Method: 提出了一种名为双适应性精炼迁移（DART）的框架，通过两个协同的适应性模块来增强冻结的视觉-语言预训练（VLP）骨干网络。其中，适应性精炼模块（ARM）通过新颖的弱监督斑块选择（WPS）损失，利用图像级标签进行判别性定位，以进行类内精炼；适应性迁移模块（ATM）则利用从大型语言模型（LLM）挖掘的结构化知识构建的类别关系图（CRG），并通过图注意力网络自适应地迁移类别表示之间的关系信息，以进行类间迁移。

Result: DART框架在具有挑战性的基准测试上进行了广泛的实验，结果表明其达到了新的最先进性能。

Conclusion: DART框架在开放词汇多标签识别任务上取得了新的最先进性能，证明了其有效性。

Abstract: Open-Vocabulary Multi-Label Recognition (OV-MLR) aims to identify multiple
seen and unseen object categories within an image, requiring both precise
intra-class localization to pinpoint objects and effective inter-class
reasoning to model complex category dependencies. While Vision-Language
Pre-training (VLP) models offer a strong open-vocabulary foundation, they often
struggle with fine-grained localization under weak supervision and typically
fail to explicitly leverage structured relational knowledge beyond basic
semantics, limiting performance especially for unseen classes. To overcome
these limitations, we propose the Dual Adaptive Refinement Transfer (DART)
framework. DART enhances a frozen VLP backbone via two synergistic adaptive
modules. For intra-class refinement, an Adaptive Refinement Module (ARM)
refines patch features adaptively, coupled with a novel Weakly Supervised Patch
Selecting (WPS) loss that enables discriminative localization using only
image-level labels. Concurrently, for inter-class transfer, an Adaptive
Transfer Module (ATM) leverages a Class Relationship Graph (CRG), constructed
using structured knowledge mined from a Large Language Model (LLM), and employs
graph attention network to adaptively transfer relational information between
class representations. DART is the first framework, to our knowledge, to
explicitly integrate external LLM-derived relational knowledge for adaptive
inter-class transfer while simultaneously performing adaptive intra-class
refinement under weak supervision for OV-MLR. Extensive experiments on
challenging benchmarks demonstrate that our DART achieves new state-of-the-art
performance, validating its effectiveness.

</details>


### [96] [WeTok: Powerful Discrete Tokenization for High-Fidelity Visual Reconstruction](https://arxiv.org/abs/2508.05599)
*Shaobin Zhuang,Yiwei Guo,Canmiao Fu,Zhipeng Huang,Zeyue Tian,Ying Zhang,Chen Li,Yali Wang*

Main category: cs.CV

TL;DR: WeTok is a new visual tokenizer that improves compression and reconstruction using Group-wise lookup-free Quantization and Generative Decoding, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing visual tokenizers face an unsatisfactory trade-off between compression ratios and reconstruction fidelity. WeTok aims to address this gap.

Method: WeTok tokenizer introduces two innovations: Group-wise lookup-free Quantization (GQ) for efficient memory and computation with scalable codebooks, and Generative Decoding (GD) with a prior of extra noise variable to probabilistically model visual data distribution for better reconstruction of visual details.

Result: WeTok achieves a record-low zero-shot rFID of 0.12 on the ImageNet 50k validation set, outperforming previous leading tokenizers like FLUX-VAE (0.18) and SD-VAE 3.5 (0.19). The highest compression model achieves a zero-shot rFID of 3.49 at a compression ratio of 768, surpassing Cosmos (384) at 4.57.

Conclusion: WeTok tokenizer achieves superior performance on mainstream benchmarks, setting new records in zero-shot rFID at high compression ratios.

Abstract: Visual tokenizer is a critical component for vision generation. However, the
existing tokenizers often face unsatisfactory trade-off between compression
ratios and reconstruction fidelity. To fill this gap, we introduce a powerful
and concise WeTok tokenizer, which surpasses the previous leading tokenizers
via two core innovations. (1) Group-wise lookup-free Quantization (GQ). We
partition the latent features into groups, and perform lookup-free quantization
for each group. As a result, GQ can efficiently overcome memory and computation
limitations of prior tokenizers, while achieving a reconstruction breakthrough
with more scalable codebooks. (2) Generative Decoding (GD). Different from
prior tokenizers, we introduce a generative decoder with a prior of extra noise
variable. In this case, GD can probabilistically model the distribution of
visual data conditioned on discrete tokens, allowing WeTok to reconstruct
visual details, especially at high compression ratios. Extensive experiments on
mainstream benchmarks show superior performance of our WeTok. On the ImageNet
50k validation set, WeTok achieves a record-low zero-shot rFID (WeTok: 0.12 vs.
FLUX-VAE: 0.18 vs. SD-VAE 3.5: 0.19). Furthermore, our highest compression
model achieves a zero-shot rFID of 3.49 with a compression ratio of 768,
outperforming Cosmos (384) 4.57 which has only 50% compression rate of ours.
Code and models are available: https://github.com/zhuangshaobin/WeTok.

</details>


### [97] [LLaVA-RE: Binary Image-Text Relevancy Evaluation with Multimodal Large Language Model](https://arxiv.org/abs/2508.05602)
*Tao Sun,Oliver Liu,JinJin Li,Lan Ma*

Main category: cs.CV

TL;DR: LLaVA-RE利用多模态大语言模型（MLLM）解决了图像-文本二元相关性评估的挑战，该模型结合了LLaVA架构、任务指令和多模态样本，并通过新数据集进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态生成AI中图像-文本相关性二元评估的挑战，即如何准确判断“相关”与“不相关”，尤其是在文本格式多样和相关性定义模糊的情况下。

Method: 提出了一种名为LLaVA-RE的框架，该框架基于LLaVA架构，结合了详细的任务指令和多模态上下文样本，并构建了一个新的二元相关性数据集。

Result: LLaVA-RE在图像-文本相关性二元评估任务上表现出有效性，并且所提出的新数据集覆盖了多种任务。

Conclusion: LLaVA-RE是一个利用多模态大语言模型进行图像-文本二元相关性评估的开创性工作，实验结果验证了其有效性。

Abstract: Multimodal generative AI usually involves generating image or text responses
given inputs in another modality. The evaluation of image-text relevancy is
essential for measuring response quality or ranking candidate responses. In
particular, binary relevancy evaluation, i.e., ``Relevant'' vs. ``Not
Relevant'', is a fundamental problem. However, this is a challenging task
considering that texts have diverse formats and the definition of relevancy
varies in different scenarios. We find that Multimodal Large Language Models
(MLLMs) are an ideal choice to build such evaluators, as they can flexibly
handle complex text formats and take in additional task information. In this
paper, we present LLaVA-RE, a first attempt for binary image-text relevancy
evaluation with MLLM. It follows the LLaVA architecture and adopts detailed
task instructions and multimodal in-context samples. In addition, we propose a
novel binary relevancy data set that covers various tasks. Experimental results
validate the effectiveness of our framework.

</details>


### [98] [Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity](https://arxiv.org/abs/2508.05609)
*Yuhan Zhang,Long Zhuo,Ziyang Chu,Tong Wu,Zhibing Li,Liang Pan,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: Hi3DEval 是一个用于评估生成 3D 内容的框架，通过结合对象级和部件级评估以及材质真实性评估来解决现有方法的局限性。其配套的数据集 Hi3DBench 和基于混合 3D 表示的自动评分系统，在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 内容生成质量评估方法主要依赖基于图像的指标，仅在对象级别操作，难以捕捉空间连贯性、材质真实性和高保真局部细节。

Method: Hi3DEval 是一个分层评估框架，结合了对象级和部件级评估，并扩展了纹理评估以包含材质真实性。Hi3DBench 是一个大型数据集，包含多样化的 3D 资源和高质量注释。提出了一种基于混合 3D 表示的 3D 感知自动评分系统，其中视频表示用于对象级和材质评估，预训练的 3D 特征用于部件级感知。

Result: Hi3DEval 在评估 3D 特征方面优于现有方法，并且在与人类偏好的匹配度方面表现更佳。

Conclusion: Hi3DEval 框架在 3D 内容评估方面优于现有基于图像的指标，并且与人类偏好的一致性更高，为手动评估提供了可扩展的替代方案。

Abstract: Despite rapid advances in 3D content generation, quality assessment for the
generated 3D assets remains challenging. Existing methods mainly rely on
image-based metrics and operate solely at the object level, limiting their
ability to capture spatial coherence, material authenticity, and high-fidelity
local details. 1) To address these challenges, we introduce Hi3DEval, a
hierarchical evaluation framework tailored for 3D generative content. It
combines both object-level and part-level evaluation, enabling holistic
assessments across multiple dimensions as well as fine-grained quality
analysis. Additionally, we extend texture evaluation beyond aesthetic
appearance by explicitly assessing material realism, focusing on attributes
such as albedo, saturation, and metallicness. 2) To support this framework, we
construct Hi3DBench, a large-scale dataset comprising diverse 3D assets and
high-quality annotations, accompanied by a reliable multi-agent annotation
pipeline. We further propose a 3D-aware automated scoring system based on
hybrid 3D representations. Specifically, we leverage video-based
representations for object-level and material-subject evaluations to enhance
modeling of spatio-temporal consistency and employ pretrained 3D features for
part-level perception. Extensive experiments demonstrate that our approach
outperforms existing image-based metrics in modeling 3D characteristics and
achieves superior alignment with human preference, providing a scalable
alternative to manual evaluations. The project page is available at
https://zyh482.github.io/Hi3DEval/.

</details>


### [99] [MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes](https://arxiv.org/abs/2508.05630)
*Henghui Ding,Kaining Ying,Chang Liu,Shuting He,Xudong Jiang,Yu-Gang Jiang,Philip H. S. Torr,Song Bai*

Main category: cs.CV

TL;DR: MOSEv2是一个更具挑战性的视频目标分割（VOS）数据集，包含真实世界复杂场景，旨在推动VOS方法在现实环境下的发展。现有VOS方法在该数据集上的性能显著下降，表明其在处理真实世界复杂性方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有VOS数据集（如DAVIS和YouTube-VOS）主要包含显著、主导和分离的目标，限制了模型在真实世界场景中的泛化能力。为推动VOS方法在更真实环境下的发展，本研究提出了MOSEv2数据集，以应对更严峻的VOS挑战。

Method: MOSEv2数据集的构建和评估，包括其视频数量、掩码数量、类别数以及引入的复杂场景和挑战，并对20种VOS方法和9种视频目标跟踪方法进行了基准测试。

Result: MOSEv2包含5024个视频和超过701976个高质量掩码，涵盖200个类别。与MOSEv1相比，MOSEv2显著增加了场景复杂性，包括更频繁的目标消失和重现、严重的遮挡和拥挤、更小的目标，以及恶劣天气、弱光、多镜头序列、伪装目标、非物理目标（如阴影、反射）和需要外部知识的场景等新挑战。在MOSEv2上，包括SAM2在内的现有VOS方法性能显著下降（SAM2从MOSEv1的76.4%降至MOSEv2的50.9%），视频目标跟踪方法也出现类似下降，证明了MOSEv2的有效性和挑战性。

Conclusion: 尽管现有数据集上的VOS方法表现出色，但在MOSEv2数据集的真实世界复杂场景下，性能明显下降，表明现有方法在处理现实世界挑战方面仍有不足。

Abstract: Video object segmentation (VOS) aims to segment specified target objects
throughout a video. Although state-of-the-art methods have achieved impressive
performance (e.g., 90+% J&F) on existing benchmarks such as DAVIS and
YouTube-VOS, these datasets primarily contain salient, dominant, and isolated
objects, limiting their generalization to real-world scenarios. To advance VOS
toward more realistic environments, coMplex video Object SEgmentation (MOSEv1)
was introduced to facilitate VOS research in complex scenes. Building on the
strengths and limitations of MOSEv1, we present MOSEv2, a significantly more
challenging dataset designed to further advance VOS methods under real-world
conditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks
for 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2
introduces significantly greater scene complexity, including more frequent
object disappearance and reappearance, severe occlusions and crowding, smaller
objects, as well as a range of new challenges such as adverse weather (e.g.,
rain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot
sequences, camouflaged objects, non-physical targets (e.g., shadows,
reflections), scenarios requiring external knowledge, etc. We benchmark 20
representative VOS methods under 5 different settings and observe consistent
performance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9%
on MOSEv2. We further evaluate 9 video object tracking methods and find similar
declines, demonstrating that MOSEv2 presents challenges across tasks. These
results highlight that despite high accuracy on existing datasets, current VOS
methods still struggle under real-world complexities. MOSEv2 is publicly
available at https://MOSE.video.

</details>


### [100] [GAP: Gaussianize Any Point Clouds with Text Guidance](https://arxiv.org/abs/2508.05631)
*Weiqi Zhang,Junsheng Zhou,Haotian Geng,Wenyuan Zhang,Yu-Shen Liu*

Main category: cs.CV

TL;DR: GAP converts colorless 3D point clouds into high-quality 3D Gaussians using text guidance, a depth-aware diffusion model, and surface anchoring for accurate geometry and appearance.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle to generate 3D Gaussians directly from colorless 3D point clouds. This paper aims to bridge this gap by proposing a novel approach to convert raw point clouds into high-fidelity 3D Gaussians with text guidance.

Method: GAP utilizes a multi-view optimization framework, incorporating a depth-aware image diffusion model for consistent appearance synthesis across viewpoints. It also features a surface-anchoring mechanism for geometric accuracy and a diffuse-based inpainting strategy for completing occluded regions.

Result: GAP demonstrates effective performance on the Point-to-Gaussian generation task across diverse datasets, including synthetic, real-world scanned, and large-scale scenes, showcasing its ability to handle varying complexities.

Conclusion: GAP successfully converts colorless 3D point clouds into high-fidelity 3D Gaussians using text guidance, addressing an unsolved challenge and achieving state-of-the-art results.

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated its advantages in achieving
fast and high-quality rendering. As point clouds serve as a widely-used and
easily accessible form of 3D representation, bridging the gap between point
clouds and Gaussians becomes increasingly important. Recent studies have
explored how to convert the colored points into Gaussians, but directly
generating Gaussians from colorless 3D point clouds remains an unsolved
challenge. In this paper, we propose GAP, a novel approach that gaussianizes
raw point clouds into high-fidelity 3D Gaussians with text guidance. Our key
idea is to design a multi-view optimization framework that leverages a
depth-aware image diffusion model to synthesize consistent appearances across
different viewpoints. To ensure geometric accuracy, we introduce a
surface-anchoring mechanism that effectively constrains Gaussians to lie on the
surfaces of 3D shapes during optimization. Furthermore, GAP incorporates a
diffuse-based inpainting strategy that specifically targets at completing
hard-to-observe regions. We evaluate GAP on the Point-to-Gaussian generation
task across varying complexity levels, from synthetic point clouds to
challenging real-world scans, and even large-scale scenes. Project Page:
https://weiqi-zhang.github.io/GAP.

</details>


### [101] [FaceAnonyMixer: Cancelable Faces via Identity Consistent Latent Space Mixing](https://arxiv.org/abs/2508.05636)
*Mohammed Talha Alam,Fahad Shamshad,Fakhri Karray,Karthik Nandakumar*

Main category: cs.CV

TL;DR: FaceAnonyMixer是一个新的框架，用于生成保护隐私且可注销的人脸图像。它通过混合真实人脸的潜在代码和可撤销密钥的合成代码来实现这一目标，同时满足生物识别模板保护的要求。该方法可以直接用于现有的人脸识别系统，并且在准确性和隐私保护方面均表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决面部识别技术发展带来的隐私担忧，并满足生物识别模板保护（包括可撤销性、不可链接性和不可逆性）的要求。

Method: 提出了一种名为FaceAnonyMixer的可注销人脸生成框架，该框架利用预训练生成模型的潜在空间来合成保护隐私的人脸图像。其核心思想是将真实人脸图像的潜在代码与源自可注销密钥的合成代码进行不可逆混合。然后，通过精心设计的多种目标损失函数对混合潜在代码进行优化，以满足所有可注销生物识别要求。

Result: FaceAnonyMixer能够生成高分辨率的可注销人脸，这些面孔可以在不修改现有面部识别系统的情况下直接用于匹配。在基准数据集上的大量实验表明，FaceAnonyMixer在提供更强隐私保护的同时，实现了卓越的识别准确性，在商业API上比最近的可注销生物识别方法提高了11%以上。

Conclusion: FaceAnonyMixer能够生成高质量的可注销人脸，并且可以直接使用现有的面部识别系统进行匹配，而无需进行任何修改。实验证明，与最近的可注销生物识别方法相比，FaceAnonyMixer在商业API上实现了超过11%的识别准确率提升，同时提供了更强的隐私保护。

Abstract: Advancements in face recognition (FR) technologies have amplified privacy
concerns, necessitating methods that protect identity while maintaining
recognition utility. Existing face anonymization methods typically focus on
obscuring identity but fail to meet the requirements of biometric template
protection, including revocability, unlinkability, and irreversibility. We
propose FaceAnonyMixer, a cancelable face generation framework that leverages
the latent space of a pre-trained generative model to synthesize
privacy-preserving face images. The core idea of FaceAnonyMixer is to
irreversibly mix the latent code of a real face image with a synthetic code
derived from a revocable key. The mixed latent code is further refined through
a carefully designed multi-objective loss to satisfy all cancelable biometric
requirements. FaceAnonyMixer is capable of generating high-quality cancelable
faces that can be directly matched using existing FR systems without requiring
any modifications. Extensive experiments on benchmark datasets demonstrate that
FaceAnonyMixer delivers superior recognition accuracy while providing
significantly stronger privacy protection, achieving over an 11% gain on
commercial API compared to recent cancelable biometric methods. Code is
available at: https://github.com/talha-alam/faceanonymixer.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [102] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的对话丰富方法，通过结合冻结的音频和语言模型来推断说话人属性，无需额外微调，即可提高对话数据的质量和信息量。


<details>
  <summary>Details</summary>
Motivation: 在对话转录流水线中，LLM常用于后处理以提高语法、标点和可读性。本研究旨在探索一种补充性的后处理步骤，即通过添加说话人特征（如年龄、性别和情绪）的元数据标签来丰富转录的对话，其中一些标签是全局的，而另一些是随时间变化的。

Method: 本研究提出了一种将冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型相结合的方法，并使用轻量级的连接器来桥接音频和语言表示，以在对话转录后添加说话人元数据标签（如年龄、性别和情绪）。

Result: 通过使用轻量级、高效的连接器，该方法在说话人画像任务上取得了具有竞争力的性能，同时保持了模块化和速度。此外，研究表明，冻结的LLAMA模型可以直接比较x-vectors，在某些场景下实现了8.8%的错误率。

Conclusion: 该方法在不进行任务特定的微调的情况下，利用连接器将冻结的音频基础模型（如Whisper或WavLM）和冻结的LLAMA语言模型结合起来，以推断说话人的属性（如年龄、性别和情绪），实现了具有竞争力的说话人画像任务性能，同时保持了模块化和速度。此外，研究表明，冻结的LLAMA模型可以直接比较x-vectors，在某些场景下实现了8.8%的错误率。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [103] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: Parity-aware BPE improves tokenization for lower-resource languages by prioritizing equitable compression across languages, without harming overall performance.


<details>
  <summary>Details</summary>
Motivation: Standard tokenization algorithms favor dominant languages, leading to longer, morphologically implausible, or <UNK>-filled tokenizations for lower-resource languages, thus amplifying inequalities. To remedy this, we introduce Parity-aware BPE.

Method: Parity-aware Byte Pair Encoding (BPE), a variant of the BPE algorithm that maximizes the compression gain of the currently worst-compressed language at every merge step, trading a small amount of global compression for cross-lingual parity.

Result: Parity-aware BPE results in more equitable token counts across languages with minimal impact on global compression and language-model performance.

Conclusion: Parity-aware BPE leads to more equitable token counts across languages, with negligible impact on global compression rate and no substantial effect on language-model performance in downstream tasks.

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [104] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: A joint ASR and pitch accent detection model improves ASR performance by 28.3% and achieves state-of-the-art in pitch accent detection, highlighting the importance of prosodic cues in speech models.


<details>
  <summary>Details</summary>
Motivation: The motivation was to boost the performance of ASR systems using semi-supervised speech representations by incorporating a complementary pitch accent detection module.

Method: A joint ASR and pitch accent detection model was introduced to leverage semi-supervised speech representations and improve ASR performance.

Result: The joint model achieved a 41% improvement in F1-score for pitch accent detection (state-of-the-art) and a 28.3% reduction in WER on LibriSpeech for ASR under limited resource fine-tuning.

Conclusion: The study demonstrates that incorporating a pitch accent detection module into semi-supervised ASR systems, through a joint training model, significantly enhances ASR performance. It also achieves state-of-the-art results in pitch accent detection.

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [105] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: LLM 的 personality 极不稳定，即使采取了稳定措施也是如此，这使得它们不适合需要可预测行为的安全关键应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在安全部署时需要一致的行为模式，但它们的 personality 特征仍然知之甚少。本研究旨在全面评估 LLM 的 personality 稳定性，以了解其行为一致性方面的局限性。

Method: 该研究使用了一个名为 PERSIST（PERsonality Stability in Synthetic Text）的评估框架，对 25 多个开源模型（参数量从 1B 到 671B 不等）进行了测试，分析了超过 500,000 个响应。研究中使用了传统的（BFI-44、SD3）和新颖的 LLM 适应性 personality 量表，并通过改变问题顺序、释义、 personas 和推理模式来系统地进行测试。

Result: 研究发现，即使是规模最大的模型（400B+ 参数）也表现出显著的响应变异性（SD > 0.4）。仅仅是提示顺序的微小改变就可能导致 personality 测量结果的变化高达 20%。此外，一些旨在稳定行为的干预措施（如链式思考、详细的 persona 指示、对话历史记录）反而会增加变异性。LLM 适应性量表与以人为中心的量表一样不稳定，这表明问题可能源于模型架构本身。

Conclusion: 该研究表明，即使是规模最大的LLM也表现出显著的响应变异性，并且通常用于稳定行为的干预措施（例如，链式思考、详细的 persona 指示、对话历史记录）可能会适得其反。研究结果表明，LLM 在行为一致性方面缺乏基础，这表明基于 personality 的对齐策略可能存在根本性不足，尤其是在安全关键型应用程序中。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [106] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: RCR-Router是一种用于多代理LLM的新型上下文路由框架，通过动态选择内存子集和迭代集成输出来提高效率和适应性，从而减少令牌消耗并保持答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有协调方案依赖于静态或全上下文路由策略，导致令牌消耗过多、内存暴露冗余以及跨交互回合的适应性有限。

Method: 提出了一种名为RCR-Router的模块化、角色感知上下文路由框架，该框架根据代理的角色和任务阶段动态选择语义相关的内存子集，并采用轻量级评分策略来指导内存选择。代理的输出来自迭代地集成到共享内存存储中，以促进渐进式上下文细化。还提出了一种答案质量得分（AQS）指标来评估LLM生成的解释。

Result: 在HotPotQA、MuSiQue和2WikiMultihop三个多跳QA基准测试中，RCR-Router将令牌使用量减少了高达30%，同时提高了或保持了答案质量。

Conclusion: RCR-Router通过动态选择相关的内存子集和迭代集成输出来实现高效自适应协作，并在多跳QA基准测试中减少了令牌使用量（高达30%），同时保持或提高了答案质量。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [107] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 本研究通过访谈模拟和100个问题-答案对，展示了大型语言模型如何因使用犹豫语言而受到不公平的评分，即使内容质量相同。该基准能衡量模型中的人口统计学偏差，为检测AI中的语言歧视提供了框架。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型（LLMs）如何响应语言“ Shibboleths”——可能无意中揭示人口统计学特征（如性别、社会阶层或地区背景）的微妙语言标记——并衡量自动化评估系统中存在的人口统计学偏差。

Method: 通过精心构建的包含100个经过验证的问题和答案的访谈模拟，评估大型语言模型（LLMs）对语言“ Shibboleths”的响应，这些 Shibboleths是可能无意中揭示人口统计学特征（如性别、社会阶层或地区背景）的微妙语言标记。研究生成了控制语言变异以分离特定现象，同时保持语义等价性，从而能够精确测量自动化评估系统中的人口统计学偏差。

Result: 研究表明，大型语言模型系统性地对某些语言模式（特别是犹豫语言）进行处罚，即使在内容质量相同的情况下也是如此。犹豫语言的回应平均评分低25.6%，并证明了该基准在识别特定模型偏差方面的有效性。

Conclusion: 本研究提出了一个检测和测量人工智能系统中语言歧视的基础框架，该框架在自动化决策背景下的公平性方面具有广泛的应用。

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [108] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 视觉活动识别评估存在歧义，传统精确匹配评估不佳。本研究提出聚类评估框架，通过分析 imSitu 数据集，发现每个图像平均映射到 2.8 个聚类，更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 标准的精确匹配评估方法无法处理视觉活动识别中动词语义和图像解释的固有歧义，导致评估不完整。

Method: 提出了一种视觉-语言聚类框架，构建动词意图聚类，用于更鲁棒的评估。

Result: 通过对 imSitu 数据集的分析，发现每个图像平均映射到 2.8 个意图聚类，每个聚类代表图像的一个不同视角。此外，研究表明本研究提出的聚类评估方法比标准评估方法更能体现人类的判断。

Conclusion: 本研究提出的基于聚类的评估方法比标准的精确匹配评估方法更能体现人类的判断，从而提供更细致的模型性能评估。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [109] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 开发了一种新的多阶段大语言模型框架，用于从文本中提取与自杀相关的社会健康决定因素 (SDoH)，提高了准确性和可解释性，并展示了通过微调小型模型实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 理解导致自杀事件的社会决定健康（SDoH）因素对于早期干预和预防至关重要，但现有的数据驱动方法面临长尾分布、关键压力分析和模型可解释性有限等挑战。

Method: 提出了一种多阶段大语言模型框架，用于从非结构化文本中提取 SDoH 因素，并与 BioBERT、GPT-3.5-turbo 和 DeepSeek-R1 等模型进行了比较。此外，还评估了模型解释如何帮助用户更快速、更准确地注释 SDoH 因素。

Result: 所提出的框架在提取 SDoH 因素和检索相关上下文方面均表现出性能提升。通过对特定任务的小型模型进行微调，可以在降低推理成本的同时获得相当或更好的性能。多阶段设计不仅增强了提取能力，还提供了中间解释，提高了模型的可解释性。

Conclusion: 本研究提出了一种改进的提取社会决定健康（SDoH）因素以预防自杀的方法，提高了准确性和透明度，有助于及早识别高危个体并制定更有效的预防策略。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [110] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 该研究提出了一种新的对话情感分析方法，通过将对话划分为独立的子对话并优化抽取过程，提高了准确性并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多轮对话时，假设情感元素均匀分布并学习整个对话的词语关系，这会引入噪音。然而，对话通常包含多个语义独立的子对话。因此，需要一种方法来解决这个问题。

Method: 提出了一种基于结构熵最小化的算法来划分对话为独立的子对话，然后采用一个两步框架进行四元组抽取：首先在话语层面抽取情感元素，然后在子对话层面匹配四元组。

Result: 实验证明，该方法在DiaASQ任务上取得了最先进的性能，并且计算成本更低。

Conclusion: 提出的基于结构熵最小化的对话划分方法以及两步抽取框架在DiaASQ任务上达到了最先进的性能，同时显著降低了计算成本。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [111] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 微调仅解码器的 LLM（特别是 LLaMA 3.2）在 AMR 解析方面取得了与 SOTA 方法相媲美的性能，LLaMA 3.2 在语义性能上表现优异，Phi 3.5 在结构有效性上表现突出。


<details>
  <summary>Details</summary>
Motivation: AMR (Abstract Meaning Representation) 是一种将句子意义编码为有向无环图的语义形式主义。微调仅解码器的 LLM 是 AMR 解析的一个有前途的新方向，本研究旨在全面评估此方向的有效性。

Method: 本研究采用了微调四种不同的 LLM 架构（Phi 3.5、Gemma 2、LLaMA 3.2 和 DeepSeek R1 LLaMA Distilled）的方法，并使用 LDC2020T02 Gold AMR3.0 测试集进行了全面的评估。

Result: 在 LDC2020T02 测试集上，本研究评估的 LLM 达到了与 SOTA AMR 解析器相当的性能。LLaMA 3.2 取得了 0.804 的 SMATCH F1 分数，与 APT+Silver (IBM) 相当，并接近 Graphene Smatch (MBSE) 的 0.854。LLaMA 3.2 在语义性能上表现领先，Phi 3.5 在结构有效性上表现突出。

Conclusion: 本研究表明，通过微调仅解码器的 LLM，可以实现与复杂的 SOTA AMR 解析器相媲美的性能。LLaMA 3.2 在此方法中表现出有竞争力，在 LDC2020T02 测试集上达到了 0.804 的 SMATCH F1 分数，与 APT+Silver (IBM) 相当，并接近 Graphene Smatch (MBSE) 的 0.854。此外，研究还发现 LLaMA 3.2 在语义性能方面表现一致领先，而 Phi 3.5 在结构有效性方面表现更优。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [112] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 在多任务学习（MTL）中，适配大型语言模型（LLM）至关重要。尽管目前的研究趋势是使用具有多个适配器或头的 LoRA 变体，但本研究表明，具有高头间相似性的简化多头架构，甚至具有更高秩的单个 LoRA，都能取得具有竞争力的性能。研究结果表明，有效的 MTL 泛化依赖于学习共享的表示，而不是隔离特定任务的特征。为此，我们提出了 Align-LoRA，它通过明确的损失来对齐共享适配器空间内的任务表示，并在实验中证明其性能优于所有基线。


<details>
  <summary>Details</summary>
Motivation: 在多任务学习（MTL）的背景下，PEFT 对于将 LLM 适配到多个领域中的各种任务至关重要。目前的研究趋势是使用具有多个适配器或头的 LoRA 变体，提倡结构多样性来捕获特定任务的知识。然而，这项研究提出了一个挑战。

Method: 提出 Align-LoRA，它包含一个明确的损失来对齐共享适配器空间内的任务表示。

Result: Align-LoRA 显著优于所有基线。

Conclusion: Align-LoRA 建立了一个更简单但更有效的范例，用于将 LLM 适配到多个任务。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [113] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: A new framework, MultiCheck, improves multimodal fact-checking by combining text and image analysis with a contrastive learning approach, achieving high performance on the Factify 2 dataset.


<details>
  <summary>Details</summary>
Motivation: To address the challenge posed by multimodal misinformation, where claims are supported by both text and images, to fact-checking systems that primarily rely on textual evidence.

Method: A unified framework called MultiCheck was proposed, combining dedicated text and image encoders with a fusion module for cross-modal reasoning using element-wise interactions. A contrastive learning objective was used to encourage semantic alignment between claim-evidence pairs in a shared latent space.

Result: The MultiCheck framework achieved a weighted F1 score of 0.84 on the Factify 2 dataset, substantially outperforming the baseline.

Conclusion: The proposed MultiCheck framework effectively performs fine-grained multimodal fact verification by integrating textual and visual signals, outperforming baseline methods on the Factify 2 dataset.

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [114] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: BEE-RAG框架通过熵工程解决了长上下文RAG中的注意力稀释问题，提高了性能。


<details>
  <summary>Details</summary>
Motivation: 从熵工程的角度，识别出未约束的熵增长和由长检索上下文引起的注意力稀释是影响RAG性能的关键因素。

Method: 提出了一种基于熵工程的检索增强生成（RAG）框架BEE-RAG，该框架通过平衡上下文熵来重塑注意力动态，将注意力敏感性与上下文长度分离开来。此外，还提出了一种用于多重要性估计的零样本推理策略和一种参数高效的自适应微调机制。

Result: BEE-RAG框架在多项RAG任务上的广泛实验证明了其有效性。

Conclusion: BEE-RAG框架通过熵不变性原则提高了RAG系统对不同上下文长度的适应性，并通过平衡上下文熵重塑注意力动态，将注意力敏感性与上下文长度分离开来，确保了稳定的熵水平。

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [115] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 研究发现 LLM 对输入信息的顺序敏感（“注意力盆地”现象），AttnRank 通过重新排序信息以匹配模型的注意力偏好，提升了 LLM 性能。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）性能对其输入中信息上下文位置敏感性的机制，揭示了“注意力盆地”现象，即模型系统地将更高的注意力分配给序列的开头和结尾的项目，而忽略中间的项目。

Method: AttnRank 框架包括两个阶段：(i) 使用小的校准集估计模型固有的位置注意力偏好；(ii) 重新排序检索到的文档或少样本示例，以使最显著的内容与这些高注意力位置对齐。

Result: AttnRank 在多跳问答和少样本上下文学习任务上，跨越 10 种不同架构和规模的大型语言模型，实现了显著的性能提升，且无需修改模型参数或训练过程。

Conclusion: AttnRank 是一种模型无关、无需训练、即插即用的方法，能够有效提升大型语言模型的性能，并通过实验证明了其在多跳问答和少样本上下文学习任务上的有效性。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [116] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 该研究引入了 PrinciplismQA，这是一个包含 3,648 个问题的基准，用于评估大型语言模型在医学伦理方面的能力。研究发现，模型在理论知识和实际应用之间存在差距，尤其是在处理“善行”原则时。闭源模型表现领先，而医学领域微调有助于提高模型表现，但仍需加强与医学伦理知识的一致性。


<details>
  <summary>Details</summary>
Motivation: 为了在将大型语言模型集成到医疗保健中时，对它们进行严格的伦理推理评估，因为当前的基准通常会忽略这一点。

Method: 使用基于 principlism 的全面的 PrinciplismQA 基准，其中包含 3,648 个问题，以系统地评估大型语言模型与核心医学伦理的一致性。该数据集包括来自权威教科书的多项选择题和来自权威医学伦理案例研究文献的开放式问题，并经过医学专家的验证。

Result: 实验显示，模型在伦理知识和实际应用之间存在显著差距，尤其是在将伦理原则动态应用于现实场景方面。大多数大型语言模型在涉及“善行”原则的困境中挣扎，往往会过度强调其他原则。由强大通用能力驱动的前沿闭源模型在基准测试中目前处于领先地位。值得注意的是，医学领域微调可以提高模型的整体伦理能力，但进一步的进展需要更好地与医学伦理知识保持一致。

Conclusion: PrinciplismQA提供了一个可扩展的框架，用于诊断医疗AI在伦理方面的具体弱点，为实现更均衡、更负责任的医疗AI铺平了道路。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [117] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: ATLANTIS团队在SemEval-2025任务3中，通过结合外部上下文、少样本提示、标记分类和微调LLM等方法，在检测问答系统中的幻觉文本方面取得了优异成绩，尤其在西班牙语中排名第一。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言生成（NLG）方面取得了显著进展，但仍然容易出现幻觉，产生不正确或误导性的内容。本研究旨在解决这个问题。

Method: 本研究探索了使用和不使用外部上下文的方法，包括使用少样本提示（LLM）、标记级别分类或在合成数据上微调的LLM。

Result: 我们的方法在西班牙语任务中取得了排名第一的成绩，在英语和德语任务中也取得了有竞争力的成绩。

Conclusion: 整合相关上下文对于减轻模型幻觉至关重要，并且微调模型和提示工程具有巨大潜力。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [118] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 本研究提出了MulCoT-RD模型，通过“教师-助手-学生”蒸馏范式，在资源受限环境下实现了高效的多模态情感推理生成和分类。


<details>
  <summary>Details</summary>
Motivation: 当前的（多模态）大语言模型在资源受限环境下，在自主多模态情感推理生成方面存在不足，因此本研究专注于资源受限联合多模态情感推理与分类（JMSRC）任务。

Method: 提出了一种名为MulCoT-RD的多模态思维链推理蒸馏模型，采用“教师-助手-学生”的蒸馏范式，并结合多任务学习机制，以解决资源受限环境下的部署约束问题。

Result: 在四个数据集上的大量实验表明，MulCoT-RD在JMSRC任务上取得了强大的性能，同时展现了稳健的泛化能力和增强的可解释性。

Conclusion: MulCoT-RD在JMSRC任务上表现出强大的性能，并具有良好的泛化能力和可解释性，尽管其参数量仅为3B。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [119] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: Structured pruning of LLMs can be improved by identifying and preserving functional networks within the model, inspired by brain function. This method decomposes the LLM into functional networks and prunes it by keeping key neurons, leading to efficient model pruning with demonstrated success in experiments.


<details>
  <summary>Details</summary>
Motivation: Current structured pruning methods overlook the interaction and collaboration among artificial neurons, leading to a disruption in the macro functional architecture of LLMs and consequently a pruning performance degradation. Inspired by the similarities between artificial neural networks and functional neural networks in the human brain, this study aims to alleviate this challenge.

Method: Identify and preserve functional networks within LLMs by treating the LLM as a digital brain and decomposing it into functional networks, analogous to identifying functional brain networks in neuroimaging data. Then, prune the LLM by preserving the key neurons within these functional networks.

Result: Experimental results demonstrate that the proposed method can successfully identify and locate functional networks and key neurons in LLMs, enabling efficient model pruning.

Conclusion: The proposed method can successfully identify and locate functional networks and key neurons in LLMs, enabling efficient model pruning.

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [120] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost是一个代码LLM的训练框架，它利用代码片段而不是人工指令，通过最大团选择、双向预测、错误感知预测、异构增强和异构奖励来提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的代码LLM通常使用“人类指令-最终答案”对进行RL后训练，但收集高质量的编码指令劳动密集且难以扩展，而代码片段则丰富，存在供需不平衡。

Method: CodeBoost框架，包含最大团选择、双向预测、错误感知预测、异构增强和异构奖励（包括格式正确性和执行反馈）等关键组件，纯粹从代码片段中增强代码LLM，无需人工标注指令。

Result: 实验表明，CodeBoost在多个代码LLM和基准测试中持续提高了性能。

Conclusion: CodeBoost通过利用代码片段而非人工标注指令，在多个代码LLM和基准测试中一致地提高了性能，证明了其作为可扩展且有效的训练管线的有效性。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [121] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 本论文通过实验发现大型语言模型（LLM）在思维链（CoT）推理中存在“后期脆弱性”现象，即后期错误比早期错误更容易导致最终答案出错。为解决此问题，论文提出了自适应自我修正思维链（ASCoT）方法，通过识别和优先修正推理链中后期易出错的环节，显著提高了模型在数学推理任务上的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管思维链（CoT）提示显著提升了大型语言模型的推理能力，但其推理链的可靠性仍然是一个关键挑战。“级联故障”假设认为早期错误最具破坏性，但本研究旨在通过实验挑战这一观点，并找出更有效的纠正方法。

Method: ASCoT方法采用模块化流程，首先由自适应验证管理器（AVM）进行处理，然后是多视角自我修正引擎（MSCE）。AVM利用位置影响评分函数I(k)为推理链中的不同位置分配权重，通过识别和优先处理高风险的后期步骤来解决后期脆弱性问题。MSCE则针对识别出的失败部分应用鲁棒的双路径修正。

Result: ASCoT方法在GSM8K和MATH等基准测试上取得了优异的准确性，超越了包括标准CoT在内的强有力基线模型，证明了其有效性。

Conclusion: 该研究通过系统性的错误注入实验，挑战了“级联故障”假设，提出了“后期脆弱性”现象，并引入了自适应自我修正思维链（ASCoT）方法，该方法通过位置影响评分函数和多视角自我修正引擎，优先处理推理链中后期错误，并在GSM8K和MATH等基准测试中取得了优于标准思维链的准确性，强调了针对特定故障模式进行诊断以及采用自适应、漏洞感知纠正机制的重要性。

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [122] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本研究提出一种利用LLM生成合成数据来训练对话代理以协助元审稿人的方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 元审稿是同行评审的关键阶段，但现有研究将其视为总结问题。本研究旨在将元审稿视为一个决策过程，并探索开发能够有效协助元审稿人的对话代理的实际挑战。

Method: 本研究首先通过LLM和自精炼策略生成用于训练对话代理的合成数据，解决了数据稀缺问题。然后，利用这些合成数据训练了针对元审稿任务的对话代理，并与现成的LLM代理进行了比较。

Result: 实验证明，本研究生成的数据质量更高，可作为训练元审稿助手的数据资源。所训练的对话代理在元审稿任务上的表现优于现成的LLM代理，并在实际应用中证实了其有效性。

Conclusion: 研究表明，所提出的方法通过生成合成数据来训练对话代理，在实际元审稿场景中能有效提升元审稿效率，并且优于现成的基于LLM的代理。

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [123] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: SONAR-LLM is a new language model that improves on LCM by using a hybrid training objective, achieving strong results and releasing its code.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve upon the Large Concept Model (LCM) by retaining its semantic abstraction while addressing its limitations, specifically the diffusion sampler and the lack of a likelihood-based training signal. SONAR-LLM aims to achieve this by using a hybrid training objective within the same continuous embedding space.

Method: SONAR-LLM is a decoder-only transformer trained using a hybrid objective. It operates in the continuous SONAR embedding space, with supervision propagated via token-level cross-entropy through a frozen SONAR decoder. This contrasts with the Large Concept Model (LCM), which predicts sentence-level embeddings and uses mean-squared error or diffusion objectives.

Result: SONAR-LLM demonstrates competitive generation quality across model sizes ranging from 39M to 1.3B parameters. The paper reports on scaling trends, ablation studies, and benchmark results, and releases training code and checkpoints for reproducibility.

Conclusion: SONAR-LLM, a decoder-only transformer, achieves competitive generation quality across various model sizes (39M to 1.3B parameters) by operating in the SONAR embedding space and utilizing a hybrid objective with token-level cross-entropy. This approach retains semantic abstraction while removing the diffusion sampler and reintroducing a likelihood-based training signal.

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [124] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: CGRS是一种用于大型推理语言模型的新方法，通过在模型自信时抑制反思来减少过度思考，从而降低成本并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理语言模型（LRLMs）在进行复杂推理时，会使用长链式推理和复杂的反思行为，但这些反思行为可能导致‘过度思考’问题，即生成冗余的推理步骤，增加了token使用量、推理成本并降低了实际效用。

Method: 本文提出了一种名为CGRS（Certainty-Guided Reflection Suppression）的新方法，通过动态抑制模型在对其当前响应高度自信时生成‘反思’触发词（如‘等等’和‘或者’），来防止冗余的反思循环，从而缓解LRLMs的过度思考问题。

Result: 通过在AIME24、AMC23、MATH500和GPQA-D四个推理基准上的广泛实验，CGRS方法在将token使用量平均减少18.5%至41.9%的同时，保持了原有准确性。与现有最优基线方法相比，CGRS在长度缩减和性能之间取得了最佳平衡，并且在不同模型架构和规模上都表现出一致的有效性。

Conclusion: 所提出的CGRS方法通过在高置信度时动态抑制生成模型对‘反思’触发词的生成，有效缓解了大型推理语言模型（LRLMs）的‘过度思考’问题，在不损害推理准确性的前提下，显著降低了token使用量和推理成本，并在多种推理基准和模型架构上验证了其有效性和实用价值。

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [125] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 尽管用户喜欢可调节的设置，但由于缺少口型和面部表情以及实现问题，用户体验和可理解性没有提高。


<details>
  <summary>Details</summary>
Motivation: 研究在现有的SL虚拟化身上增加可调节功能对Microsoft Hololens 2设备的影响，以确定影响可理解性、用户体验（UX）和可接受性的关键因素。

Method: 通过在Microsoft Hololens 2设备上，让德语手语（DGS）用户与可调节和不可调节的标志性手语（SL）虚拟化身进行交互，并进行详细分析。

Result: 用户偏好可调节设置，但用户体验和可理解性没有显著提高。虽然接受度普遍积极，但严重依赖可用性和动画质量。

Conclusion: 个性化不足以提升用户体验和可理解性，需要提高默认的清晰度和可用性。

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [126] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 在生物医学领域，LLM的自主搜索系统（Agentic RAG）和“深度研究”系统旨在通过迭代优化来改进搜索结果。然而，这些系统在满足专家信息需求和保持透明度方面面临挑战。本研究评估了几种LLM（包括Gemini-Flash 2.0、o3-mini、o4-mini和DeepSeek-R1）在自我反馈机制下的表现，该机制允许LLM自行生成、评估和优化查询及答案。研究发现，自我反馈策略的效果因模型和任务而异，为未来比较LLM生成反馈与人类专家反馈的有效性提供了初步见解。


<details>
  <summary>Details</summary>
Motivation: Agentic RAG和“深度研究”系统旨在实现自主搜索过程，但将其应用于生物医学等领域特定专业搜索时面临挑战，因为自动化系统可能减少用户参与度，并与专家信息需求不符。专业搜索任务通常需要用户具备高水平的专业知识和透明度。

Method: 本研究探索了当前推理和非推理LLM（如Gemini-Flash 2.0、o3-mini、o4-mini和DeepSeek-R1）在生物医学领域的应用。研究的核心方法是采用一种自我反馈机制，让LLM能够生成、评估并优化其输出，以实现查询扩展和满足多种答案类型（是/否、事实、列表、理想）。

Result: 初步结果表明，自我反馈策略在不同模型和任务上的表现各不相同。

Conclusion: LLM的自我修正策略在不同模型和任务上的表现各异，为未来研究LLM生成反馈与人类专家直接输入进行比较提供了见解。

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [127] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 发布了一个包含12种手语的视频平行语料库，包含1300多小时的视频和130万条字幕，是8种拉丁美洲手语的第一个平行语料库，并大大扩展了德语手语语料库。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个包含12种手语的平行语料库，其中包含1,300多小时的视频和130万条字幕，特别是为8种拉丁美洲手语提供了第一个一致的平行语料库，并显著增加了德语手语的可用语料量。

Method: 通过收集和处理来自各种在线来源（主要是新闻节目、政府机构和教育频道）的多种手语视频来创建语料库。准备过程包括数据收集、通知内容创建者并寻求使用批准、爬取和裁剪。

Result: 创建了一个包含12种手语的平行语料库，包括4381个视频文件和130万条字幕，其中包含1400万个词元。该语料库包括8种拉丁美洲手语的第一个一致的平行语料库，并且德语手语语料库的规模是先前可用语料库的十倍。

Conclusion: 该研究提出了一个包含12种手语的平行语料库，这些语料库以视频格式提供，并配有相应国家的口语字幕。

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [128] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: MyCulture基准通过创新的开放式选择题形式，解决大型语言模型（LLM）在低资源语言（如马来语）中的文化偏见问题，并评估了模型的文化理解能力。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据以英语和中文等高资源语言为主，大型语言模型（LLM）常常表现出文化偏见。这给准确表述和评估多元文化背景，尤其是在低资源语言环境中带来了挑战。为了解决这个问题，我们引入了MyCulture。

Method: MyCulture基准采用了一种新颖的开放式选择题形式，没有预设选项，旨在减少猜测和缓解格式偏差。通过比较模型在结构化与自由形式输出上的表现来分析结构偏见，并通过多语言提示变体来评估语言偏见。

Result: 评估结果显示，不同区域和国际的LLM在文化理解方面存在显著差异，这表明需要开发符合文化且语言包容的基准来评估LLM。

Conclusion: LLMs普遍存在文化偏见，尤其是在低资源语言环境中，这阻碍了对不同文化背景的准确表述和评估。MyCulture基准通过其创新的开放式选择题形式，在减少猜测和缓解格式偏差方面显示出优越性，从而提高公平性和区分度。对区域和国际LLM的评估揭示了它们在文化理解方面存在显著差异，凸显了建立符合文化且语言包容的基准对于LLM发展和评估的紧迫性。

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [129] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMEval-3通过动态采样和反作弊机制解决了LLM评估中的数据污染和排行榜过度拟合问题，并在一项为期20个月的研究中展示了其稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在静态基准上的评估容易受到数据污染和排行榜过度拟合的影响，这些关键问题模糊了模型的真实能力。

Method: LLMEval-3框架基于专有的220k研究生水平问题库，为每次评估运行动态采样未见过的测试集。其自动化流程通过抗污染数据管理、新颖的反作弊架构和校准的LLM-as-a-judge流程确保完整性，该流程在人类专家的认同度达到90%，并辅以相对排名系统进行公平比较。

Result: 一项为期20个月的对近50个领先模型的纵向研究揭示了知识记忆的表现上限，并暴露了静态基准无法检测到的数据污染漏洞。该框架在排名稳定性和一致性方面表现出卓越的稳健性，为动态评估范式提供了有力的实证验证。

Conclusion: LLMEval-3提供了一种稳健且可信的方法，用于评估LLM的真实能力，超越了排行榜分数，促进了更值得信赖的评估标准的制定。

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [130] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: TASE基准揭示了大型语言模型在细粒度、令牌级语言理解和结构推理方面存在显著不足，人类表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在高级语义任务上表现出色，但在需要精确度和控制力的应用中至关重要的细粒度、令牌级理解和结构推理方面常常遇到困难。

Method: 介绍了一个名为TASE的综合基准，用于评估大型语言模型在令牌级信息感知和推理方面的能力。TASE包含10项任务，分为令牌感知和结构理解两大类，涵盖中、英、韩三种语言，拥有35,927个实例的评估集，并辅以可扩展的合成数据生成流程用于训练。研究评估了超过30个主流的大型语言模型，并使用GRPO训练方法对Qwen2.5-14B模型进行了训练。

Result: 评估结果表明，人类在令牌级推理方面的表现远超当前所有评估过的大型语言模型，揭示了它们在低级别语言理解方面的持续弱点。

Conclusion: 该研究揭示了大型语言模型在处理细粒度、令牌级理解和结构推理方面存在的持续不足，人类表现明显优于当前的大型语言模型。

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [131] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 目前的人工智能创意评估指标在创意写作、非常规问题解决和研究构思等领域的评估结果不一致且各有局限，无法完全捕捉人类的创意判断。


<details>
  <summary>Details</summary>
Motivation: 为了改进人工智能在创意领域的评估方法，本研究旨在系统地检查、分析和比较现有的几种代表性创意评估方法，并揭示它们在不同创意领域的适用性和局限性。

Method: 本研究系统地检查、分析和比较了创意指数、困惑度、句法模板和 LLM-as-a-Judge 这几种代表性的创意评估方法，并将其应用于创意写作、非常规问题解决和研究构思等多个创意领域。

Result: 现有评估指标（创意指数、困惑度、句法模板、LLM-as-a-Judge）在不同创意领域表现出有限的一致性，分别关注词汇多样性、模型置信度、句法结构和概念创意，并且 LLM-as-a-Judge 存在不稳定性与偏见。这些指标均无法完全捕捉人类对创意的判断，表明需要更稳健、更具普遍性的评估框架。

Conclusion: 目前的人工智能创意评估指标（如创意指数、困惑度、句法模板和 LLM-as-a-Judge）在不同创意领域（包括创意写作、非常规问题解决和研究构思）的评估结果不一致，并且各有局限性。这些指标仅捕捉了创意的不同维度，例如创意指数侧重词汇多样性，困惑度对模型置信度敏感，句法模板无法捕捉概念创意，而 LLM-as-a-Judge 则表现出不稳定性与偏见。

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [132] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: LAG通过将复杂问题分解为逻辑子问题并按顺序解决它们来改进LLM的知识密集型任务处理能力，从而提高了推理能力并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 虽然检索增强生成（RAG）通过整合外部知识可以缓解LLM在知识密集型任务中的局限性，但它在复杂的推理场景中由于依赖于直接的语义检索和缺乏结构化的逻辑组织而面临挑战。受到笛卡尔《方法论》中原则的启发，本研究引入了逻辑增强生成（LAG）范式，通过系统性的问题分解和依赖感知的推理来重新构建知识增强。

Method: LAG首先将复杂问题分解为按逻辑依赖顺序排序的原子子问题。然后，它依次解决这些子问题，利用先前答案指导后续子问题的上下文检索，确保逐步进行逻辑链条的 grounding。为了防止错误传播，LAG包含一个逻辑终止机制，在遇到无法回答的子问题时停止推理，并减少在过度推理上浪费的计算量。最后，它综合所有子问题的解决方法，生成经过验证的响应。

Result: 实验结果表明，LAG在四个基准数据集上显著提高了LLM的推理鲁棒性，减少了幻觉，并将LLM的问题解决方式与人类认知对齐。

Conclusion: LAG通过系统化的问题分解和依赖感知推理，显著提高了LLM在知识密集型任务中的推理鲁棒性，减少了幻觉，并将LLM的问题解决方式与人类认知对齐，为现有的RAG系统提供了一种原则性的替代方案。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [133] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: LLMs在“20问”游戏中对来自“全球北方/西方”的实体推断能力更强，揭示了其推理过程中的隐性地理偏见，仅靠数据量或语言无法完全解释。


<details>
  <summary>Details</summary>
Motivation: 旨在探索LLMs在不直接探测的情况下，通过其主动提问行为来揭示潜在的隐性偏见。传统的探测方法可能被模型的安全防护机制规避，因此研究LLMs在“20问”这类自由形式的互动任务中的表现，以发现更深层次的偏见。

Method: 通过“20问”游戏，评估LLMs在推断来自不同地理区域的知名人士和具有文化意义的物品（如食物、地标、动物）方面的表现。使用包含这些实体的“Geo20Q+”新数据集，在两种游戏模式（标准20问和不限回合）及七种语言（英语、印地语、普通话、日语、法语、西班牙语和土耳其语）下进行系统性测试。

Result: LLMs在推断来自“全球北方”的实体时，成功率显著高于“全球南方”；同样，在推断“全球西方”的实体时也优于“全球东方”。尽管Wikipedia的页面浏览量和预训练语料库的频率与模型表现有轻微相关性，但不足以完全解释这些地理差异。在不同语言下进行游戏时，性能差距基本保持不变。

Conclusion: LLMs在“20问”游戏中表现出地理和文化上的隐性偏见，主要体现在对“全球北方”和“全球西方”实体的推断能力优于“全球南方”和“全球东方”。语言的影响相对较小，表明这些偏见根植于模型的推理过程，而非仅仅是数据或语言的表面差异。

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [134] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: CoCoLex是一种新的解码策略，通过鼓励基于置信度的复制来提高法律文本生成中大型语言模型（LLM）的忠实度，并在长篇生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决检索增强生成（Retrieval-Augmented Generation）未能保证有效整合所提供上下文的问题，并加强法律领域大型语言模型（LLM）的采用，因其易产生不忠实、无根据或幻觉的输出。

Method: 提出了一种名为CoCoLex（置信度引导的基于复制的法律文本生成）的解码策略，该策略动态地将模型生成的词汇分布与基于从上下文中复制的分布进行插值。

Result: CoCoLex通过基于模型的置信度鼓励直接复制，确保了对源的高度保真度，并在长篇生成任务中表现优于现有方法。

Conclusion: CoCoLex在五个法律基准的实验中，在长篇生成任务中表现优于现有的上下文感知解码方法。

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [135] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: LLM在MCQA方面表现出色，但存在不可靠性。我们提出了一种基于频率的不确定性量化方法，利用共形预测来保证覆盖范围。该方法通过多次采样并计算最频繁样本的预测熵来工作。实验证明，该方法在区分正确和不正确预测方面优于基于logit的方法，并能有效控制错误覆盖率，增强了LLM的可信度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多项选择题问答（MCQA）方面取得了显著进展，但其固有的不可靠性（如幻觉和过度自信）限制了它们在高风险领域的应用。

Method: 提出了一种基于频率的不确定性量化方法，在黑盒设置下利用共形预测（CP）来确保可证明的覆盖范围保证。该方法涉及对每个输入的模型输出分布进行多次独立采样，并将最频繁的样本作为参考来计算预测熵（PE）。

Result: 实验评估表明，基于频率的PE在区分正确和不正确预测方面优于基于logit的PE，以AUROC衡量。此外，该方法在用户指定的风险水平下有效控制了实际错误覆盖率。

Conclusion: 该方法在区分正确和不正确预测方面优于基于logit的预测熵，并且在用户指定的风险水平下有效控制了错误覆盖率，证明了在黑盒场景下，采样频率可以作为基于logit的概率的可行替代品。本研究为MCQA中的可靠不确定性量化提供了一个无分布、模型无关的框架，并具有保证的覆盖范围，增强了LLM在实际应用中的可信度。

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [136] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 多语言大语言模型（MLLM）在不同语言中的政治观点基本一致，并且观点对齐会跨语言转移，这使得在模型中实现特定的社会语言、文化和政治对齐变得困难。


<details>
  <summary>Details</summary>
Motivation: 旨在探究多语言大语言模型（MLLM）在不同语言和文化背景下是否表现出不同的政治观点，以及模型中的语言是否会相互影响。

Method: 通过提示多语言大语言模型（MLLM）对来自投票建议应用程序的政治声明（不）同意来分析MLLM的观点。在对齐（或不）对齐模型（使用直接偏好优化和仅英语对齐数据）之后，评估它们在五种西方语言中的表现。

Result: 未对齐的多语言大语言模型（MLLM）在所反映的政治观点方面，仅表现出很少的显著跨语言差异。政治观点对齐几乎在所有五种语言中都均匀地转移了观点。

Conclusion: 在西方语言环境中，政治观点会在不同语言之间迁移，这表明在实现多语言大语言模型（MLLM）的显式社会语言、文化和政治对齐方面存在挑战。

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [137] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: MathSmith是一个新的框架，通过从PlanetMath合成具有挑战性的数学问题来提高LLM的推理能力。它通过从头开始构建问题、引入难度策略和使用强化学习来生成数据，并在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在数学推理方面面临的高质量、高难度训练数据不足的挑战，并克服现有方法在数据多样性和可扩展性方面的局限性。

Method: MathSmith通过随机采样概念-解释对并结合九种预定义策略和强化学习来从头开始构建数学问题，以增加难度并优化结构有效性、推理复杂性和答案一致性。

Result: MathSmith在包括GSM8K、MATH-500、AIME2024、AIME2025和OlympiadBench在内的五个基准测试中，无论是在短提示还是长链式思考（CoT）设置下，都持续优于现有基线方法。

Conclusion: MathSmith框架在生成高质量、高难度数学问题方面展现出强大的可扩展性、泛化性和迁移性，有助于提升大语言模型在数学推理方面的能力。

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [138] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: This paper introduces Cooper, a framework that jointly optimizes policy and reward models to overcome limitations of existing RL reward methods, improving LLM reasoning and mitigating reward hacking.


<details>
  <summary>Details</summary>
Motivation: Current RL reward paradigms (rule-based and model-based) have limitations: rule-based rewards lack robustness, and model-based rewards are vulnerable to reward hacking. This paper addresses these issues.

Method: Cooper framework jointly optimizes policy and reward models, leveraging rule-based rewards for precision and dynamically constructing sample pairs. A hybrid annotation strategy and a reference-based reward modeling paradigm (VerifyRM) are introduced to train the reward model efficiently and accurately.

Result: VerifyRM achieves higher accuracy on VerifyBench than other models of the same size. Cooper alleviates reward hacking and improves end-to-end RL performance, achieving a 0.54% gain in average accuracy on Qwen2.5-1.5B-Instruct.

Conclusion: Co-optimizing the policy and reward models (Cooper) alleviates reward hacking and improves end-to-end RL performance, as demonstrated by a 0.54% accuracy gain on Qwen2.5-1.5B-Instruct. Dynamically updating reward models is effective against reward hacking and offers a reference for better integrating reward models into RL.

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [139] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: OmniEAR 框架评估大型语言模型在具身推理中的表现，结果显示现有模型在处理动态约束、工具使用和多智能体协调方面存在严重不足，需要新的架构和方法。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在具身推理方面的能力，特别是物理交互、工具使用和多智能体协调。

Method: 提出 OmniEAR 框架，通过文本环境表示模拟物理属性和空间关系，评估语言模型在具身任务中的推理能力。

Result: 在具有约束条件的情况下，模型性能显著下降，尤其是在工具推理和隐式协作方面。仅凭指令的成功率很高，但当需要自主推理时，成功率急剧下降。与预期相反，提供完整的环境信息会削弱协调性能，表明模型无法有效筛选任务相关约束。微调对单智能体任务有显著提升，但对多智能体任务提升效果甚微，暴露出根本性的架构限制。

Conclusion: 大型语言模型在具身推理方面能力不足，需要新的方法来应对动态能力获取和自主协调策略。

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [140] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: 该研究提出了一种新的奖励函数和在线强化学习方法，用于提高大型语言模型在长篇内容生成中的事实准确性、详细程度和相关性，有效减少了幻觉的产生。


<details>
  <summary>Details</summary>
Motivation: 为了解决推理大型语言模型（R-LLMs）在长篇事实性基准测试中存在事实性问题（产生幻觉）以及在线强化学习在长篇事实性场景中缺乏可靠验证方法的挑战。

Method: 提出了一种新型奖励函数，该函数同时考虑事实准确性、响应详细程度和答案相关性，并应用在线强化学习来学习高质量的事实推理。

Result: 在六个长篇事实性基准测试中，所提出的模型平均幻觉率降低了23.1个百分点，答案详细程度提高了23%，整体响应有用性没有下降。

Conclusion: 该研究提出的新型奖励函数能够同时考虑事实准确性、响应详细程度和答案相关性，并利用在线强化学习来学习高质量的事实推理，在六个长篇事实基准测试中，平均幻觉率降低了23.1个百分点，答案详细程度提高了23%，且整体响应有用性没有下降。

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [141] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 本研究使用线性探针分析大型语言模型（LLM）的说服动态，发现探针能有效识别说服的关键点和策略，且比基于提示的方法更高效，为研究复杂行为（如欺骗）提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）在说服人类方面显示出潜力，但对其机制的理解有限，因此本研究旨在分析说服动态。

Method: 该研究利用线性探针来研究说服动态，这些探针在对话的各个方面进行训练，包括说服的成功、被说服者的个性和说服策略。

Result: 结果表明，探针能够捕获说服的各个方面，并能识别对话中被说服发生的节点以及整个数据集中说服成功的普遍发生点。此外，探针在某些情况下甚至优于基于提示的方法，例如在揭示说服策略方面。

Conclusion: 探针可以作为研究复杂行为（例如欺骗和操纵）的可行途径，特别是在多轮对话和大规模数据集分析中，因为基于提示的方法在这种情况下计算效率低下。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [142] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++是一种新的层级动态分块模型，可以像人类一样学习语言分割，从而更有效地处理具有丰富形态的语言，如波斯语，而无需分词器。


<details>
  <summary>Details</summary>
Motivation: 字节级语言模型虽然消除了脆弱的分词器，但在形态丰富的语言（MRLs）中面临计算挑战，因为单词会跨越多字节。

Method: H-NET++是一种层级动态分块模型，通过端到端训练学习语言学信息的分割，包括轻量级Transformer上下文混合器、文档级一致性的两级潜在超先验、专门处理拼写伪影（如波斯语ZWNJ）以及基于课程的学习。

Result: H-NET++在波斯语语料库上取得了最先进的成果，在BPB方面比基于BPE的GPT-2-fa减少了0.159（压缩率提高了12%），在ParsGLUE上提高了5.4个百分点，在处理ZWNJ损坏方面提高了53%的鲁棒性，在黄金形态边界上达到了73.8%的F1分数。

Conclusion: H-NET++通过层级动态分块提供了一种有效的无分词器解决方案，用于处理形态丰富的语言，同时保持计算效率。

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [143] [Linear Program-Based Stability Conditions for Nonlinear Autonomous Systems](https://arxiv.org/abs/2508.04871)
*Sadredin Hokmi,Mohammad Khajenejad*

Main category: eess.SY

TL;DR: 该研究提出了一种新的方法，使用线性规划（LP）代替半定规划（SDP）来评估非线性自治系统平衡点的渐近稳定性，从而大大降低了计算成本，特别是在处理高维系统时。


<details>
  <summary>Details</summary>
Motivation: 为了降低计算成本，包括高维系统的时间和内存使用量。

Method: 通过使用间接李雅普诺夫方法和通过雅可比矩阵线性化系统动力学，该方法用计算上有效的线性规划（LP）条件替代了传统的半定规划（SDP）技术。

Result: 稳定性标准是使用矩阵变换和利用系统的结构特性开发的，提高了可扩展性。与现有的基于 SDP 的标准相比，该方法在计算效率方面得到了几个例子的证明，特别是在高维系统方面。

Conclusion: 该研究提出了一种评估连续时间和离散时间非线性自治系统平衡点渐近稳定性 novel approach。

Abstract: This paper introduces a novel approach to evaluating the asymptotic stability
of equilibrium points in both continuous-time (CT) and discrete-time (DT)
nonlinear autonomous systems. By utilizing indirect Lyapunov methods and
linearizing system dynamics through Jacobian matrices, the methodology replaces
traditional semi-definite programming (SDP) techniques with computationally
efficient linear programming (LP) conditions. This substitution substantially
lowers the computational burden, including time and memory usage, particularly
for high-dimensional systems. The stability criteria are developed using matrix
transformations and leveraging the structural characteristics of the system,
improving scalability. Several examples demonstrated the computational
efficiency of the proposed approach compared to the existing SDP-based
criteria, particularly for high-dimensional systems.

</details>


### [144] [Sequence Aware SAC Control for Engine Fuel Consumption Optimization in Electrified Powertrain](https://arxiv.org/abs/2508.04874)
*Wafeeq Jaleel,Md Ragib Rownak,Athar Hanif,Sidra Ghayour Bhatti,Qadeer Ahmed*

Main category: eess.SY

TL;DR: A new RL framework using SAC with GRUs and DTs optimizes HEV engine control, showing significant fuel savings and robustness on various drive cycles.


<details>
  <summary>Details</summary>
Motivation: Hybrid electric vehicles (HEVs) in heavy-duty trucks require adaptive and efficient energy management to reduce fuel consumption and maintain battery charge for long operations.

Method: A new reinforcement learning (RL) framework based on the Soft Actor-Critic (SAC) algorithm is presented, enhancing SAC by incorporating Gated Recurrent Units (GRUs) and Decision Transformers (DTs) into both actor and critic networks to optimize engine control in series HEVs.

Result: The SAC agent with a DT-based actor and GRU-based critic achieved fuel savings within 1.8% of Dynamic Programming (DP) on the HFET cycle. Generalized sequence-aware agents consistently outperformed FFN-based agents on unseen drive cycles (US06 and HHDDT cruise segment).

Conclusion: The proposed reinforcement learning framework enhances engine control in series HEVs, with the SAC agent incorporating DT and GRU demonstrating strong performance and generalization capabilities on unseen drive cycles.

Abstract: As hybrid electric vehicles (HEVs) gain traction in heavy-duty trucks,
adaptive and efficient energy management is critical for reducing fuel
consumption while maintaining battery charge for long operation times. We
present a new reinforcement learning (RL) framework based on the Soft
Actor-Critic (SAC) algorithm to optimize engine control in series HEVs. We
reformulate the control task as a sequential decision-making problem and
enhance SAC by incorporating Gated Recurrent Units (GRUs) and Decision
Transformers (DTs) into both actor and critic networks to capture temporal
dependencies and improve planning over time. To evaluate robustness and
generalization, we train the models under diverse initial battery states, drive
cycle durations, power demands, and input sequence lengths. Experiments show
that the SAC agent with a DT-based actor and GRU-based critic was within 1.8%
of Dynamic Programming (DP) in fuel savings on the Highway Fuel Economy Test
(HFET) cycle, while the SAC agent with GRUs in both actor and critic networks,
and FFN actor-critic agent were within 3.16% and 3.43%, respectively. On unseen
drive cycles (US06 and Heavy Heavy-Duty Diesel Truck (HHDDT) cruise segment),
generalized sequence-aware agents consistently outperformed feedforward network
(FFN)-based agents, highlighting their adaptability and robustness in
real-world settings.

</details>


### [145] [Uncovering the Influence Flow Model of Transistor Amplifiers, Its Reconstruction and Application](https://arxiv.org/abs/2508.04977)
*Mohammed Tuhin Rana,Mishfad Shaikh Veedu,Murti V. Salapaka*

Main category: eess.SY

TL;DR: 提出了一种将多级晶体管放大器建模为线性动态影响模型（LDIM）的方法，该模型利用数据驱动的网络重建技术来表征级间交互、识别故障和关键电路参数。


<details>
  <summary>Details</summary>
Motivation: 多级晶体管放大器可以有效地建模为动态系统网络，其中各个放大器级通过动态耦合进行交互。

Method: 采用图模型技术和维纳滤波，仅从在电路指定点采样的电压时间序列测量中重建网络结构。

Result: 通过 Cadence 中的多个放大器电路的大量模拟以及物理硬件上的实验结果，证明了这些网络重建方法在多级放大器中的有效性。

Conclusion: 可以通过从测量数据中推断网络结构来为设计师和用户提供用于设计、分析和调试放大器电路的高效工具。还提出了一种利用这些技术进行故障诊断的方法。

Abstract: Multistage transistor amplifiers can be effectively modeled as network of
dynamic systems where individual amplifier stages interact through couplings
that are dynamic in nature. Using circuit analysis techniques, we show that a
large class of transistor amplifiers can be modeled as Linear Dynamic Influence
Model (LDIM), where the interactions between different amplifier stages are
modeled as linear dynamic equations. LDIM modeling of transistor circuits leads
to application of data-driven network reconstruction techniques to characterize
stage interactions and identify faults and critical circuit parameters
efficiently. Employing graphical modeling techniques and Wiener filtering, we
demonstrate that the network structure can be reconstructed solely from voltage
time-series measurements sampled at specified points in the circuit. The
efficacy of these network reconstruction methods in multistage amplifiers is
demonstrated through extensive simulations involving multiple amplifier
circuits in Cadence, as well as experimental results on physical hardware. The
ability to infer network structure directly from measurement data offers
designers and users efficient tools to design, analyze, and debug amplifier
circuits. To demonstrate the utility of network reconstruction in multistage
amplifier circuits, a fault diagnosis method leveraging these techniques is
presented.

</details>


### [146] [Probabilistic Alternating Simulations for Policy Synthesis in Uncertain Stochastic Dynamical Systems](https://arxiv.org/abs/2508.05062)
*Thom Badings,Alessandro Abate*

Main category: eess.SY

TL;DR: 提出了一种新的概率模拟关系，可以同时处理随机和非确定性干扰，并成功应用于车辆策略合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理既有随机性又有非确定性干扰的系统时不足，需要一种能够同时处理这两种不确定性的关系。

Method: 提出了一种受交替模拟启发的概率模拟关系，该关系可以处理随机和非确定性干扰。

Result: 该方法适用于4D状态Dubins车辆的策略合成，并进行了实验验证。

Conclusion: 扩展了概率模拟关系以处理具有随机和非确定性干扰的系统，并为策略合成提供了基础。

Abstract: A classical approach to formal policy synthesis in stochastic dynamical
systems is to construct a finite-state abstraction, often represented as a
Markov decision process (MDP). The correctness of these approaches hinges on a
behavioural relation between the dynamical system and its abstraction, such as
a probabilistic simulation relation. However, probabilistic simulation
relations do not suffice when the system dynamics are, next to being
stochastic, also subject to nondeterministic (i.e., set-valued) disturbances.
In this work, we extend probabilistic simulation relations to systems with both
stochastic and nondeterministic disturbances. Our relation, which is inspired
by a notion of alternating simulation, generalises existing relations used for
verification and policy synthesis used in several works. Intuitively, our
relation allows reasoning probabilistically over stochastic uncertainty, while
reasoning robustly (i.e., adversarially) over nondeterministic disturbances. We
experimentally demonstrate the applicability of our relations for policy
synthesis in a 4D-state Dubins vehicle.

</details>


### [147] [Preparing for the worst: Long-term and short-term weather extremes in resource adequacy assessment](https://arxiv.org/abs/2508.05163)
*Aleksander Grochowicz,Hannah C. Bloomfield,Marta Victoria*

Main category: eess.SY

TL;DR: Renewables in net-zero grids face supply security risks from extreme weather causing grid stress. This paper uses shadow prices to find 'system-defining events,' revealing a need for financially viable backup power, and suggests new ways to model short- and long-term resilience.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the common and important concern of security of supply when integrating renewables into net-zero power systems. Extreme weather events, affecting both demand and supply, cause power system stress that can spread continentally.

Method: The paper utilizes an approach based on shadow prices to identify 'system-defining events' – periods of elevated stress – and analyzes their impact on the power system. It also proposes classifying different types of these events to identify operational and planning challenges.

Result: The analysis identifies challenges to power system operation and planning by classifying system-defining events. A key finding is the necessity for sufficient resilience backup capacities, despite their precarious financial viability due to weather variability.

Conclusion: The study highlights the need for resilient backup capacities in net-zero power systems, whose financial viability is threatened by weather variability. It also emphasizes disentangling short- and long-term resilience challenges with distinct metrics and stress tests for future energy modeling.

Abstract: Security of supply is a common and important concern when integrating
renewables in net-zero power systems. Extreme weather affects both demand and
supply leading to power system stress; in Europe this stress spreads
continentally beyond the meteorological root cause. We use an approach based on
shadow prices to identify periods of elevated stress called system-defining
events and analyse their impact on the power system. By classifying different
types of system-defining events, we identify challenges to power system
operation and planning. Crucially, we find the need for sufficient resilience
back-up (power) capacities whose financial viability is precarious due to
weather variability. Furthermore, we disentangle short- and long-term
resilience challenges with distinct metrics and stress tests to incorporate
both into future energy modelling assessments. Our methodology and
implementation in the open model PyPSA-Eur can be re-applied to other systems
and help researchers and policymakers in building more resilient and adequate
energy systems.

</details>


### [148] [Overview of Controllability Definitions in Supervisory Control Theory](https://arxiv.org/abs/2508.05177)
*Jeroen J. A. Keiren,Michel A. Reniers*

Main category: eess.SY

TL;DR: 监督控制理论中的可控性有多种定义，本文研究了它们在不同设置下的等效性和关系。


<details>
  <summary>Details</summary>
Motivation: 在监督控制理论中，文献中经常为同一个概念提出不同的定义，这使得理解这些定义之间的关系变得困难。

Method: 本文列出了文献中发现的可控性定义，并研究了它们在确定性和非确定性自动机设置中的关系。

Result: 在通用设置中，Flordal 和 Malik 的可控性与 Kushi 和 Takai 的不可控事件可容性是等效的，并且它们是唯一隐含传统（语言）可控性的概念。在监督工厂相对于工厂的可控性这一更实际的背景下，除了前两种概念外，Zhou 等人的状态可控性也意味着语言可控性。

Conclusion: “可控性”是监督控制理论中的一个基本概念，但文献中存在多种定义，这使得理解它们之间的关系变得困难。在通用设置（其中监督器和植物都可以是非确定性的）中，Flordal 和 Malik 描述的可控性以及 Kushi 和 Takai 的不可控事件可容性是等效的，并且是唯一隐含传统（语言）可控性的概念。从实践角度来看，监督工厂相对于工厂的可控性通常更受关注。在此背景下，除了前两种可控性概念外，Zhou 等人的状态可控性也意味着语言可控性。

Abstract: In the field of supervisory control theory, the literature often proposes
different definitions for the same concept, making it difficult to understand
how these definitions are related. This is definitely so for the fundamental
notion of controllability of a supervisor w.r.t. a plant. This paper lists
definitions of controllability found in the literature and studies their
relationships in settings of both deterministic and nondeterministic automata.
In the general context, where both the supervisor and the plant are allowed to
be nondeterministic, the notions of controllability as described by Flordal and
Malik, and uncontrollable event admissibility by Kushi and Takai are
equivalent. These are also the only notions that imply the traditional notion
of (language) controllability. From a practical perspective, one is often more
interested in controllability of a supervised plant w.r.t. a plant. In this
context, in addition to the previous two controllability notions, state
controllability by Zhou et al. implies language controllability.

</details>


### [149] [Passive nonlinear FIR filters for data-driven control](https://arxiv.org/abs/2508.05279)
*Zixing Wang,Fulvio Forni*

Main category: eess.SY

TL;DR: 提出了一种新的无源非线性有限脉冲响应算子类，该类算子通过在提升空间中作用有限脉冲响应滤波器来构造，可用于高效的控制综合和物理系统控制。


<details>
  <summary>Details</summary>
Motivation: 为了通过约束优化实现高效的控制综合。

Method: 通过在提升空间中作用有限脉冲响应滤波器来构造。

Result: 通过基于虚拟参考反馈整理论的最小二乘拟合来考虑闭环性能。通过频域采样建立的有效线性约束来确保钝度。

Conclusion: 该类算子特别适用于机电系统等物理系统的控制。

Abstract: We propose a new class of passive nonlinear finite impulse response
operators. This class is constructed by the action of finite impulse response
filters in a lifted space. This allows for efficient control synthesis through
constrained optimization. Closed-loop performance is taken into account through
least-squares fitting, based on the theory of virtual reference feedback
tuning. Passivity is established through efficient linear constraints, based on
sampling in the frequency domain. Because of passivity, this class of operators
is particularly suited for the control of physical systems, such as
electromechanical systems.

</details>


### [150] [A 20-Year Retrospective on Power and Thermal Modeling and Management](https://arxiv.org/abs/2508.05495)
*David Atienza,Kai Zhu,Darong Huang,Luis Costero*

Main category: eess.SY

TL;DR: 对现代处理器中的电源和热量建模及管理进行了广泛的调查，涵盖了从预测技术到管理策略的各种方法，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着处理器性能的提高，日益增长的功率密度和复杂的热行为对能源效率和系统可靠性构成了威胁。

Method: 文章首先比较了电源估计的分析、基于回归和基于神经网络的技术，接着回顾了包括有限元、有限差分和数据驱动方法在内的热模型方法，然后对平衡性能、功耗和可靠性的动态运行时管理策略进行了分类。

Result: 本篇论文为研究处理器电源和热量管理的研究者提供了全面的概述和指导。

Conclusion: 本篇论文总结了现代处理器中电源和热量建模及管理的二十多年研究，讨论了新兴的挑战和有前景的研究方向。

Abstract: As processor performance advances, increasing power densities and complex
thermal behaviors threaten both energy efficiency and system reliability. This
survey covers more than two decades of research on power and thermal modeling
and management in modern processors. We start by comparing analytical,
regression-based, and neural network-based techniques for power estimation,
then review thermal modeling methods, including finite element, finite
difference, and data-driven approaches. Next, we categorize dynamic runtime
management strategies that balance performance, power consumption, and
reliability. Finally, we conclude with a discussion of emerging challenges and
promising research directions.

</details>


### [151] [Research on integrated intelligent energy management system based on big data analysis and machine learning](https://arxiv.org/abs/2508.05583)
*Jinzhou Xu,Yadan Zhang,Paola Tapia*

Main category: eess.SY

TL;DR: 本研究提出利用大数据分析和机器学习方法优化综合智慧能源项目的文件管理效率，通过建立实施框架和应用机器学习模型，可以追踪项目文件并优化流程，最终提升项目建设效率。


<details>
  <summary>Details</summary>
Motivation: 综合智慧能源项目的文件管理是提升项目管理与控制效率的关键环节，因此，研究如何应用大数据技术优化这一过程具有重要意义。

Method: 通过研究与讨论，本研究首先探讨了在综合智慧能源项目文档管理与控制中实施大数据分析的效益与挑战。接着，开发了一个用于综合智慧能源项目文档管理中大数据分析的实施框架。此外，提出了一种利用机器学习优化综合智慧能源项目文档管理效率的方法，并运用项目文档管理过程中产生的各类数据信息，通过三种不同的机器学习方法对整个项目文件控制的效率进行了优化。

Result: 经拟合的惩罚线性回归模型结果显示，当存在足够的数据作为训练集时，模型的准确率可达95%以上。

Conclusion: 本研究利用大数据分析和机器学习优化了综合智慧能源项目的文件管理效率，并通过建立文件管理和控制的实施框架，实现了对项目全过程文件的追踪以及业务流程的最优化，从而加强了项目建设的管控力度，提高了项目建设的整体效率。当训练数据集足够时，经拟合的惩罚线性回归模型准确率可达95%以上。

Abstract: The application of big data is one of the significant features of integrated
smart energy. Applying it to the file management of integrated smart energy
projects is of great significance for improving the efficiency of project
management and control. This article first discussed the benefits and
challenges of implementing big data analysis in document management and control
of integrated smart energy projects. In addition, an implementation framework
for big data analysis in integrated smart energy project document management
was developed, and a method for optimizing the efficiency of integrated smart
energy project document management through machine learning was proposed. Using
various types of data and information generated during the project document
management process, the efficiency of the entire process project document
control through three different machine learning methods was optimized. The
result of fitting a penalty linear regression model shows that when there is
enough data as a training set, the accuracy of the model achieved can reach
over 95\%. By using big data analysis and machine learning to analyze the
efficiency of comprehensive smart energy project document management, it is
possible to track the entire process of comprehensive smart energy project
documents and optimize business processes, thereby strengthening project
construction control and improving project construction efficiency.

</details>


### [152] [Error Bounds for Radial Network Topology Learning from Quantized Measurements](https://arxiv.org/abs/2508.05620)
*Samuel Talkington,Aditya Rangarajan,Pedro A. de Alcântara,Line Roald,Daniel K. Molzahn,Daniel R. Fuhrmann*

Main category: eess.SY

TL;DR: 该研究通过考虑量化误差，分析了径向网络拓扑学习的误差界限，发现误差与量化 bin 宽度成正比，并随节点数次线性增长。


<details>
  <summary>Details</summary>
Motivation: 为了解决径向网络拓扑学习问题，其中需要估计连接性和线路参数，并考虑由传感器精度（量化）引起的数据误差，从而超越了传统的加性噪声模型。

Method: 通过对传感器精度（量化）引入的数据误差进行概率性界定，来分析径向网络拓扑学习问题的解的误差。模型将传感器的通信网络操作嵌入到学习问题中，这超越了传统的电力系统估计算法中使用的加性噪声模型。

Result: 研究表明，学习到的径向网络拓扑的误差与量化 bin 宽度成正比，并且在节点数为 N 时，只要每个节点的样本数为 log(N)，误差就以小于 N 的速率增长。

Conclusion: 该研究得出的结论是，在特定条件下，学习到的径向网络拓扑的误差与量化 bin 宽度成正比，并且随着节点数量的增加而次线性增长。

Abstract: We probabilistically bound the error of a solution to a radial network
topology learning problem where both connectivity and line parameters are
estimated. In our model, data errors are introduced by the precision of the
sensors, i.e., quantization. This produces a nonlinear measurement model that
embeds the operation of the sensor communication network into the learning
problem, expanding beyond the additive noise models typically seen in power
system estimation algorithms. We show that the error of a learned radial
network topology is proportional to the quantization bin width and grows
sublinearly in the number of nodes, provided that the number of samples per
node is logarithmic in the number of nodes.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [153] [Injection Locking and Coupling Dynamics in Superconducting Nanowire based Cryogenic Oscillators](https://arxiv.org/abs/2508.04878)
*Md Mazharul Islam,Md Shafayat Hossain,Kathleen E Hamilton,Ahmedullah Aziz*

Main category: cs.ET

TL;DR: 这项研究通过数值模拟深入探讨了超导纳米线（ScNW）低温振荡器的注入锁定和相互耦合动力学，重点关注了同步机制和信号协调。研究确定了影响锁定范围的关键参数，并展示了如何通过调整耦合强度来控制振荡器间的相位差，为开发新型低温计算架构提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 低温振荡器在超导电子学和量子计算中至关重要，它们能够提供稳定、低噪声且能量损耗小的信号。

Method: 采用数值模拟方法，研究了超导纳米线（ScNW）低温振荡器的注入锁定和相互耦合动力学。

Result: 研究确定了控制锁定范围的关键设计参数，如分流电阻、纳米线电感和耦合强度。研究还分析了注入信号幅度对锁定振荡幅度如何产生影响，并探讨了电容和电阻耦合对ScNW振荡器相互同步的影响。

Conclusion: 研究结果揭示了通过调整耦合强度可以精确控制振荡器之间的相位差，从而实现可编程的、基于相位编码的信息处理。这些发现有望用于构建基于超导纳米线的振荡神经网络、同步低温逻辑块和片上低温谐振器阵列。

Abstract: Oscillators designed to function at cryogenic temperatures play a critical
role in superconducting electronics and quantum computing by providing stable,
low noise signals with minimal energy loss.Here we present a comprehensive
numerical study of injection locking and mutual coupling dynamics in
superconducting nanowire based cryogenic oscillators.Using the design space of
standalone ScNW based oscillator, we investigate two critical mechanisms that
govern frequency synchronization and signal coordination in cryogenic computing
architectures.First, an injection locking induced by an external AC signal with
a frequency near the oscillators natural frequency, and second, the mutual
coupling dynamics between two ScNW oscillators under varying coupling
strengths.We identify key design parameters such as shunt resistance, nanowire
inductance, and coupling strength that govern the locking range.Additionally,
we examine how the amplitude of the injected signal affects the amplitude of
the locked oscillation, offering valuable insights for power aware oscillator
synchronization.Furthermore, we analyze mutual synchronization between coupled
ScNW oscillators using capacitive and resistive coupling elements.Our results
reveal that the phase difference between oscillators can be precisely
controlled by tuning the coupling strength, enabling programmable phase encoded
information processing.These findings could enable building ScNW based
oscillatory neural networks, synchronized cryogenic logic blocks, and on chip
cryogenic resonator arrays.

</details>


### [154] [Wave Computing based on Dynamical Networks: Applications in Optimization Problems](https://arxiv.org/abs/2508.05014)
*Yunwen Liu,Jiang Xiao*

Main category: cs.ET

TL;DR: 开发了一个利用波传播和波操纵能力的计算框架，可实现多维度的内在并行性，有效解决NP难题。


<details>
  <summary>Details</summary>
Motivation: 扩展计算的内在并行性至多维空间（空间、时间、频率域），以解决NP难题。

Method: 利用节点和边具有波传播和波操纵（如频率混合或时间延迟）能力的互联网络。

Result: 通过SPICE仿真验证了该架构在解决数划分问题、0/1背包问题和旅行商问题等NP难题方面的潜力。

Conclusion: 该计算框架在时空频域内具有内在并行性，能够有效解决NP难题，并在SPICE仿真中得到验证。

Abstract: We develop a computing framework that leverages wave propagation within an
interconnected network, where nodes and edges possess wave manipulation
capabilities, such as frequency mixing or time delay. This computing paradigm
can not only achieve intrinsic parallelism like existing works by the
exploration of an exponential number of possibilities simultaneously with very
small number of hardware units, but also extend this unique characteristic to a
multidimensional space including spatial, temporal and frequency domains,
making it particularly effective for addressing NP-hard problems. The proposed
architecture has been validated through SPICE simulations, demonstrating its
potential capability in solving several NP-hard problems, such as the Number
Partitioning Problem, the 0/1 Knapsack Problem, and the Traveling Salesman
Problem.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [155] [OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks](https://arxiv.org/abs/2508.04833)
*Nicolas Nicolaou,Onyeka Obi,Aayush Rajasekaran,Alejandro Bergasov,Aleksandr Bezobchuk,Kishori M. Konwar,Michael Meier,Santiago Paiva,Har Preet Singh,Swarnabha Sinha*

Main category: cs.DC

TL;DR: OPTIMUMP2P是一种新的libp2p 算法，它使用 RLNC 来更快、更可靠地传播信息。


<details>
  <summary>Details</summary>
Motivation: 为了提高libp2p 在区块链协议中传播区块和交易的性能和可靠性。

Method: 提出了一种名为OPTIMUMP2P的新型ossip算法，该算法利用随机线性网络编码（RLNC）来加速信息传播并提高数据传输的可靠性。

Result: 与Gossipsub协议相比，OPTIMUMP2P在模拟和真实环境中的评估结果均显示出性能提升。

Conclusion: OPTIMUMP2P通过利用随机线性网络编码（RLNC）来加速P2P网络中的信息传播，并确保即使在存在恶意行为者的情况下也能可靠地进行数据传输，从而提高了libp2p的性能和可靠性。

Abstract: Gossip algorithms are pivotal in the dissemination of information within
decentralized systems. Consequently, numerous gossip libraries have been
developed and widely utilized especially in blockchain protocols for the
propagation of blocks and transactions. A well-established library is libp2p,
which provides two gossip algorithms: floodsup and gossibsup. These algorithms
enable the delivery of published messages to a set of peers. In this work we
aim to enhance the performance and reliability of libp2p by introducing
OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random
Linear Network Coding (RLNC) to expedite the dissemination of information in a
peer-to-peer (P2P) network while ensuring reliable delivery, even in the
presence of malicious actors capable of corrupting the transmitted data.
Preliminary research from the Ethereum Foundation has demonstrated the use of
RLNC in the significant improvement in the block propagation time [14]. Here we
present extensive evaluation results both in simulation and real-world
environments that demonstrate the performance gains of OPTIMUMP2P over the
Gossipsub protocol.

</details>


### [156] [Linear Search for Capturing an Oblivious Mobile Target in the Sender/Receiver Model](https://arxiv.org/abs/2508.04870)
*Khaled Jawhar,Evangelos Kranakis*

Main category: cs.DC

TL;DR: 两个机器人通过线性搜索抓捕移动目标，一个机器人能无线发送和接收信息，另一个只能面对面交流。研究了不同信息模式下抓捕效率。


<details>
  <summary>Details</summary>
Motivation: 研究不对称通信能力如何影响两个自主机器人线性搜索捕获移动目标的竞争比，为理解通信机制在机器人协同搜索中的作用提供新的视角。

Method: 设计了新的线性搜索算法，并考虑了机器人对搜索环境（如起始距离、目标速度、运动模式等）的不同了解程度，以分析捕获目标所需时间的竞争比。

Result: 提出了新的线性搜索算法，并通过分析竞争比来评估其性能，揭示了非对称通信在机器人协同搜索中的影响。

Conclusion: 本研究分析了在非对称通信模型下，两个自主机器人如何通过线性搜索捕获移动目标，并探讨了通信能力差异对捕获时间竞争比的影响。

Abstract: We consider linear search for capturing an oblivious moving target by two
autonomous robots with different communicating abilities. Both robots can
communicate Face-to-Face (F2F) when co-located but in addition one robot is a
Sender (can also send messages wirelessly) and the other also a Receiver (can
also receive messages wirelessly). This is known as Sender/Receiver (S/R, for
short) communication model. The robots can move with max speed $1$. The moving
target starts at distance $d$ from the origin and can move either with speed
$v<1$ away from the origin in the ``away'' model or with speed $v \geq 0$
toward the origin in the ``toward'' model. We assume that the direction of
motion of the target (i.e., whether it is the away or toward model) is known to
the robots in advance. To capture the target the two robots must be co-located
with it.
  We design new linear search algorithms and analyze the competitive ratio of
the time required to capture the target. The approach takes into account
various scenarios related to what the robots know about the search environment
(e.g., starting distance or speed of the mobile, away or toward model, or a
combination thereof). Our study contributes to understanding how asymmetric
communication affects the competitive ratio of linear search.

</details>


### [157] [Managing, Analyzing and Sharing Research Data with Gen3 Data Commons](https://arxiv.org/abs/2508.04944)
*Craig Barnes,Kyle Burton,Michael S. Fitzsimons,Hara Prasad Juvvala,Brienna Larrick,Christopher Meyer,Pauline Ribeyre,Ao Liu,Clint Malson,Noah Metoki-Shlubsky,Andrii Prokhorenkov,Jawad Qureshi,Radhika Reddy,L. Philip Schumm,Mingfei Shao,Trevar Simmons,Alexander VanTol,Peter Vassilatos,Aarti Venkat,Robert L. Grossman*

Main category: cs.DC

TL;DR: Gen3是一个开源的数据共享平台，能自动生成数据门户和API，方便数据管理、分析和共享。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个用于研究社区管理、分析和共享数据的云端数据平台（数据共享平台），Gen3应运而生。

Method: Gen3平台通过定义数据模型，自动生成数据门户（用于搜索和提交数据）和FAIR API（用于程序化访问数据）。其底层基于标准化的软件服务构建，支持未来组件扩展和互操作性。

Result: Gen3已被用于构建十多个数据共享平台，总数据量超过28 PB，包含6400万个FAIR数据对象。

Conclusion: Gen3是一个开源数据平台，用于构建数据共享平台，已成功应用于多个数据共享平台，管理大量数据和数据对象，并能自动生成数据门户和FAIR API，支持与其他数据平台的互操作。

Abstract: Gen3 is an open-source data platform for building data commons. A data
commons is a cloud-based data platform for managing, analyzing, and sharing
data with a research community. Gen3 has been used to build over a dozen data
commons that in aggregate contain over 28 PB of data and 64 million FAIR data
objects. To set up a Gen3 data commons, you first define a data model. Gen3
then autogenerates 1) a data portal for searching and exploring data in the
commons; 2) a data portal for submitting data to the commons; and 3) FAIR APIs
for accessing the data programmatically. Gen3 is built over a small number of
standards-based software services, which are designed to support current and
future Gen3 components so that Gen3 can interoperate with other data platforms
and data ecosystems.

</details>


### [158] [Tesserae: Scalable Placement Policies for Deep Learning Workloads](https://arxiv.org/abs/2508.04953)
*Song Bian,Saurabh Agarwal,Md. Tareq Mahmood,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: Tesserae 是一个 GPU 集群调度程序，它使用图匹配来改进资源利用率，从而提高性能。


<details>
  <summary>Details</summary>
Motivation: 提高深度学习 (DL) 集群的资源利用率，DL 集群调度程序通常包含用于确定作业在集群中放置位置的放置策略。

Method: 设计了最小化作业迁移开销和作业打包的新颖放置策略，并将这些策略集成到 Tesserae 中。

Result: Tesserae 与现有调度程序相比，平均 JCT 提高了 1.62 倍，Makespan 提高了 1.15 倍。

Conclusion: Tesserae 通过将许多放置约束设计为图匹配问题，从而成为一个可扩展且有效的 GPU 集群调度程序。

Abstract: Training deep learning (DL) models has become a dominant workload in
data-centers and improving resource utilization is a key goal of DL cluster
schedulers. In order to do this, schedulers typically incorporate placement
policies that govern where jobs are placed on the cluster. Existing placement
policies are either designed as ad-hoc heuristics or incorporated as
constraints within a complex optimization problem and thus either suffer from
suboptimal performance or poor scalability. Our key insight is that many
placement constraints can be formulated as graph matching problems and based on
that we design novel placement policies for minimizing job migration overheads
and job packing. We integrate these policies into Tesserae and describe how our
design leads to a scalable and effective GPU cluster scheduler. Our
experimental results show that Tesserae improves average JCT by up to 1.62x and
the Makespan by up to 1.15x compared with the existing schedulers.

</details>


### [159] [Task-Based Programming for Adaptive Mesh Refinement in Compressible Flow Simulations](https://arxiv.org/abs/2508.05020)
*Anjiang Wei,Hang Song,Mert Hidayetoglu,Elliott Slaughter,Sanjiva K. Lele,Alex Aiken*

Main category: cs.DC

TL;DR: Developed an efficient AMR solver for compressible flows using Regent, achieving significant speedups through task fusion and GPU kernel generation.


<details>
  <summary>Details</summary>
Motivation: High-order solvers for compressible flows are essential, and AMR is a key technique to reduce computational cost by focusing resolution on areas of interest.

Method: Developed an AMR-based numerical solver using the Regent programming language, incorporating dynamic data structures for refinement/coarsening, mesh validity enforcement, and task fusion for performance optimization.

Result: Task fusion achieved an 18x speedup, and automated GPU kernel generation yielded a 9.7x speedup for the targeted kernel. The approach was demonstrated on Euler equations for compressible flow problems.

Conclusion: We developed an AMR-based numerical solver using Regent for compressible flows, addressing challenges like dynamic data structures, mesh validity, and task fusion for efficiency.

Abstract: High-order solvers for compressible flows are vital in scientific
applications. Adaptive mesh refinement (AMR) is a key technique for reducing
computational cost by concentrating resolution in regions of interest. In this
work, we develop an AMR-based numerical solver using Regent, a high-level
programming language for the Legion programming model. We address several
challenges associated with implementing AMR in Regent. These include dynamic
data structures for patch refinement/coarsening, mesh validity enforcement, and
reducing task launch overhead via task fusion. Experimental results show that
task fusion achieves 18x speedup, while automated GPU kernel generation via
simple annotations yields 9.7x speedup for the targeted kernel. We demonstrate
our approach through simulations of two canonical compressible flow problems
governed by the Euler equations.

</details>


### [160] [Theseus: A Distributed and Scalable GPU-Accelerated Query Processing Platform Optimized for Efficient Data Movement](https://arxiv.org/abs/2508.05029)
*Felipe Aramburú,William Malpica,Kaouther Abrougui,Amin Aramoon,Romulo Auccapuclla,Claude Brisson,Matthijs Brobbel,Colby Farrell,Pradeep Garigipati,Joost Hoozemans,Supun Kamburugamuve,Akhil Nair,Alexander Ocsa,Johan Peltenburg,Rubén Quesada López,Deepak Sihag,Ahmet Uyar,Dhruv Vats,Michael Wendt,Jignesh M. Patel,Rodrigo Aramburú*

Main category: cs.DC

TL;DR: Theseus is a GPU-accelerated query engine that significantly improves performance and reduces costs for large-scale data analysis, outperforming current systems and handling massive datasets efficiently.


<details>
  <summary>Details</summary>
Motivation: Existing distributed computing systems for large-scale online analytical processing (terabytes of data) are costly. The goal is to decrease costs and increase throughput by utilizing ubiquitous accelerators like GPUs, despite the challenges in data movement, memory utilization, and computation coordination.

Method: Theseus employs specialized asynchronous control mechanisms tightly coupled with hardware resources to manage network communication, data pre-loading, data spilling across memories and storage, and GPU compute tasks. It also features a memory subsystem with fixed-size page-locked host memory allocations to boost throughput and minimize memory fragmentation.

Result: On TPC-H benchmarks at scale factors from 1k to 30k on cloud infrastructure, Theseus outperforms Databricks Photon by up to 4x at cost parity. It can process all TPC-H and TPC-DS benchmark queries at a 100TB scale (scale factor 100k) using as few as 2 DGX A100 640GB nodes.

Conclusion: Theseus is a production-ready distributed query engine that leverages GPUs to significantly outperform existing systems like Databricks Photon in online analytical processing for large datasets, achieving up to 4x improvement at cost parity and demonstrating efficiency even at the 100TB scale.

Abstract: Online analytical processing of queries on datasets in the many-terabyte
range is only possible with costly distributed computing systems. To decrease
the cost and increase the throughput, systems can leverage accelerators such as
GPUs, which are now ubiquitous in the compute infrastructure. This introduces
many challenges, the majority of which are related to when, where, and how to
best move data around the system. We present Theseus -- a production-ready
enterprise-scale distributed accelerator-native query engine designed to
balance data movement, memory utilization, and computation in an
accelerator-based system context. Specialized asynchronous control mechanisms
are tightly coupled to the hardware resources for the purpose of network
communication, data pre-loading, data spilling across memories and storage, and
GPU compute tasks. The memory subsystem contains a mechanism for fixed-size
page-locked host memory allocations to increase throughput and reduce memory
fragmentation. For the TPC-H benchmarks at scale factors ranging from 1k to 30k
on cloud infrastructure, Theseus outperforms Databricks Photon by up to
$4\times$ at cost parity. Theseus is capable of processing all queries of the
TPC-H and TPC-DS benchmarks at scale factor 100k (100 TB scale) with as few as
2 DGX A100 640GB nodes.

</details>


### [161] [Simulating LLM training workloads for heterogeneous compute and network infrastructure](https://arxiv.org/abs/2508.05370)
*Sumit Kumar,Arjun Temura,Naman Sharma,Ramanjeet Singh,Meet Dadhania,Praveen Tammana,Satananda Burla,Abed Mohammad Kamaluddin,Rinku Shah*

Main category: cs.DC

TL;DR: LLM training simulators often ignore device heterogeneity, which is common in real-world scenarios. This paper introduces a new simulator that accounts for this heterogeneity, allowing for custom configurations and better prediction of training time and performance.


<details>
  <summary>Details</summary>
Motivation: The demand for large-scale GPU clusters in distributed LLM training is high, but current simulators assume homogeneous infrastructure, which is not practical due to device heterogeneity in cloud environments. This gap hinders innovation in model optimization, performance tuning, and system-level enhancements.

Method: The paper proposes a heterogeneity-aware distributed LLM simulator that allows for custom configurations of device groups and device-to-parallelism mapping, including components like non-uniform workload partitioning.

Result: Initial simulation results demonstrate the impact of heterogeneity on model computation and communication time.

Conclusion: LLM training simulators need to account for heterogeneity to accurately predict training time in practical scenarios. This paper proposes a heterogeneity-aware simulator that can handle custom configurations and non-uniform workload partitioning, with initial results showing the impact of heterogeneity on computation and communication.

Abstract: The growing demand for large-scale GPU clusters in distributed model training
presents a significant barrier to innovation, particularly in model
optimization, performance tuning, and system-level enhancements. To address
this challenge, LLM training simulators are employed to estimate training time
and guide design decisions. However, the state-of-the-art LLM training
simulators assume homogeneous compute and network infrastructure. In practice,
device heterogeneity is inevitable due to resource sharing in cloud
environments, frequent shifts in device generations, and inherent intra-chip
interconnect heterogeneity. To address the gap between state-of-the-art and
practical requirements, we propose the design of a heterogeneity-aware
distributed LLM simulator capable of predicting training time while enabling
abstractions to specify custom configurations for device groups and
device-to-parallelism mapping. We present the design requirements and
challenges in building a heterogeneity-aware distributed ML training simulator,
and design components such as non-uniform workload partitioning. Our initial
simulation results demonstrate the impact of heterogeneity on the model
computation and communication time.

</details>


### [162] [Adaptive Parallel Downloader for Large Genomic Datasets](https://arxiv.org/abs/2508.05511)
*Rasman Mubtasim Swargo,Engin Arslan,Md Arifuzzaman*

Main category: cs.DC

TL;DR: FastBioDL is a new parallel downloader for large biological datasets that uses an adaptive concurrency controller to maximize download throughput and minimize resource overhead, achieving up to 4x speedup over existing tools.


<details>
  <summary>Details</summary>
Motivation: Existing download tools often employ static concurrency settings, leading to inefficient bandwidth utilization and prolonged download times due to their inability to adapt to dynamic network conditions.

Method: FastBioDL frames the download process as an online optimization problem, utilizing a utility function and gradient descent to adjust the number of concurrent socket streams in real-time dynamically.

Result: Comprehensive evaluations on public genomic datasets demonstrate that FastBioDL achieves up to 4x speedup over state-of-the-art tools. Moreover, in high-speed network experiments, its adaptive design was up to 2.1x faster than existing tools.

Conclusion: FastBioDL is a robust and efficient solution for acquiring large-scale genomic data, democratizing high-performance data retrieval for researchers without requiring specialized commercial software or protocols.

Abstract: Modern next-generation sequencing (NGS) projects routinely generate terabytes
of data, which researchers commonly download from public repositories such as
SRA or ENA. Existing download tools often employ static concurrency settings,
leading to inefficient bandwidth utilization and prolonged download times due
to their inability to adapt to dynamic network conditions. We introduce
FastBioDL, a parallel file downloader designed for large biological datasets,
featuring an adaptive concurrency controller. FastBioDL frames the download
process as an online optimization problem, utilizing a utility function and
gradient descent to adjust the number of concurrent socket streams in real-time
dynamically. This approach maximizes download throughput while minimizing
resource overhead. Comprehensive evaluations on public genomic datasets
demonstrate that FastBioDL achieves up to $4x$ speedup over state-of-the-art
tools. Moreover, in high-speed network experiments, its adaptive design was up
to $2.1x$ faster than existing tools. By intelligently optimizing standard HTTP
or FTP downloads on the client side, FastBioDL provides a robust and efficient
solution for large-scale genomic data acquisition, democratizing
high-performance data retrieval for researchers without requiring specialized
commercial software or protocols.

</details>


### [163] [Modular Architecture for High-Performance and Low Overhead Data Transfers](https://arxiv.org/abs/2508.05546)
*Rasman Mubtasim Swargo,Engin Arslan,Md Arifuzzaman*

Main category: cs.DC

TL;DR: AutoMDT是一种基于深度强化学习的数据传输架构，通过优化读、网络、写操作的并发，实现比现有方案快8倍的收敛速度和68%的传输时间减少。


<details>
  <summary>Details</summary>
Motivation: 传统的传输工具因固定配置或单一优化方法，在资源利用和稳定性方面存在不足，无法满足高性能应用对海量数据跨地域快速可靠传输的需求。

Method: 提出了一种名为AutoMDT的新型模块化数据传输架构，使用基于深度强化学习的代理来同时优化读、网络和写操作的并发级别。该架构包含一个轻量级的网络-系统模拟器，允许在生产网络中在线训练之前，对Proximal Policy Optimization (PPO)代理进行约45分钟的离线训练。模块化设计解耦了I/O和网络任务，使代理能够精确捕捉复杂的缓冲区动态并快速适应不断变化的系统和网络条件。

Result: 在生产级测试平台上进行评估，结果显示AutoMDT比当前最优解决方案的收敛速度快8倍，传输完成时间缩短了68%。

Conclusion: AutoMDT通过模块化设计和深度强化学习（PPO）代理，实现了高并发读、网络和写操作的同时优化，显著提高了大规模数据集跨地域传输的效率和稳定性，比现有最优方案收敛速度快8倍，完成时间减少68%。

Abstract: High-performance applications necessitate rapid and dependable transfer of
massive datasets across geographically dispersed locations. Traditional file
transfer tools often suffer from resource underutilization and instability
because of fixed configurations or monolithic optimization methods. We propose
AutoMDT, a novel modular data transfer architecture that employs a deep
reinforcement learning based agent to simultaneously optimize concurrency
levels for read, network, and write operations. Our solution incorporates a
lightweight network-system simulator, enabling offline training of a Proximal
Policy Optimization (PPO) agent in approximately 45 minutes on average, thereby
overcoming the impracticality of lengthy online training in production
networks. AutoMDT's modular design decouples I/O and network tasks, allowing
the agent to capture complex buffer dynamics precisely and to adapt quickly to
changing system and network conditions. Evaluations on production-grade
testbeds show that AutoMDT achieves up to 8x faster convergence and a 68%
reduction in transfer completion times compared with state-of-the-art
solutions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [164] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx是一个用于网络对齐模型的可解释性框架，通过识别关键子图和特征来解释对齐决策。


<details>
  <summary>Details</summary>
Motivation: 由于网络对齐模型的解释性有限，难以理解对齐决策，这在高度依赖的领域中建立信任方面带来了挑战。

Method: NAEx通过以下方式解决保留跨网络依赖性的关键挑战：(1)通过可学习的边缘和特征掩码联合参数化图结构和特征空间；(2)引入一个确保解释既忠实于原始预测又能实现网络之间结构和基于特征的相似性有意义的比较的优化目标。

Result: NAEx是一个归纳框架，可以有效地为先前未见过的数据生成网络对齐解释。我们通过将NAEx与四种代表性的网络对齐模型集成，在基准数据集上展示了NAEx的有效性和效率。

Conclusion: NAEx是一个即插即用、模型无关的框架，可以解释网络对齐模型，通过识别影响预测的关键子图和特征。NAEx是一个归纳框架，可以有效地为先前未见过的数据生成网络对齐解释，并且在基准数据集上展示了其有效性和效率。

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [165] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 本文首次为OPTQ（GPTQ）及其相关算法（如Qronos）提供了量化误差的理论界限，分析了量化误差的来源，并为实际应用中的参数选择和算法设计提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，OPTQ（GPTQ）作为一种流行的PTQ方法，缺乏严格的定量理论保证。本文旨在填补这一空白，为OPTQ及其相关算法提供理论支持。

Method: 通过分析OPTQ的迭代过程来量化其量化误差，并推导出依赖于校准数据和正则化参数的非渐近2范数误差界限。对于随机变体，推导了更强的无穷范数误差界限。将此分析扩展到Qronos，为其确定性和随机变体提供新的理论界限。

Result: 推导了OPTQ的确定性和随机变体的2范数和无穷范数误差界限，以及Qronos算法的理论界限。这些结果为OPTQ的特征排序和参数选择提供了理论依据，并解释了Qronos的优势。

Conclusion: 该分析为OPTQ及其变体（包括Qronos）提供了第一个定量误差界限，为实际设计选择提供了理论依据，并指导了正则化参数的选择。

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [166] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen是一个集成了视觉语言模型（LVLM）的文本到图像生成框架，通过智能提示解析和迭代视觉反馈优化，提高了图像生成在文本渲染、姿态控制和构图方面的质量和精确度。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在处理复杂指令、精细内容控制和语义一致性方面存在挑战，尤其是在文本渲染、姿态生成和构图方面。

Method: 提出了一种新颖的、增强了LVLM的迭代框架LumiGen，包含智能提示解析与增强（IPPA）模块和迭代视觉反馈与优化（IVFR）模块，利用LVLM驱动的闭环反馈机制来优化图像生成。

Result: LumiGen在LongBench-T2I基准测试中取得了3.08的平均得分，优于现有技术水平，在文本渲染和姿态表达等关键维度上表现出显著改进。

Conclusion: LumiGen通过集成LVLM显著提升了文本到图像生成的能力，特别是在文本渲染、姿态表达和构图连贯性等方面，在LongBench-T2I基准测试中取得了优于现有技术的平均得分3.08。

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [167] [Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms](https://arxiv.org/abs/2508.05141)
*Yahong Yang,Juncai He*

Main category: cs.LG

TL;DR: 深度神经网络在逼近PDE弱解方面表现出“超级收敛”现象，精度优于传统数值方法，为科学计算中的应用提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 弥合了基于神经网络的PDE方法在误差估计理论方面的差距，为在科学计算中统一使用神经网络提供了理论基础。

Method: 对具有常用和通用激活函数的深度全连接神经网络在Sobolev空间$W^{n,\infty}$中的逼近进行分析，误差在$W^{m,p}$范数（$m < n$, $1 \le p \le \infty$）下进行度量。

Result: 证明了深度神经网络在逼近PDE弱解方面的潜力，其精度优于传统数值方法，并实现了“超级收敛”。

Conclusion: 该研究为深度全连接神经网络在Sobolev空间$W^{n,\infty}$中的逼近提供了全面的结果，并利用$W^{m,p}$范数（$m < n$, $1 \le p \le \infty$）进行误差度量。结果表明，与有限元和谱方法等经典数值逼近技术相比，该方法具有更高的精度，实现了“超级收敛”现象。深度网络可用于逼近偏微分方程（PDEs）的弱解，且精度优于传统数值方法。

Abstract: This paper establishes a comprehensive approximation result for deep
fully-connected neural networks with commonly-used and general activation
functions in Sobolev spaces $W^{n,\infty}$, with errors measured in the
$W^{m,p}$-norm for $m < n$ and $1\le p \le \infty$. The derived rates surpass
those of classical numerical approximation techniques, such as finite element
and spectral methods, exhibiting a phenomenon we refer to as
\emph{super-convergence}. Our analysis shows that deep networks with general
activations can approximate weak solutions of partial differential equations
(PDEs) with superior accuracy compared to traditional numerical methods at the
approximation level. Furthermore, this work closes a significant gap in the
error-estimation theory for neural-network-based approaches to PDEs, offering a
unified theoretical foundation for their use in scientific computing.

</details>


### [168] [Echo State Networks for Bitcoin Time Series Prediction](https://arxiv.org/abs/2508.05416)
*Mansi Sharma,Enrico Sartor,Marc Cavazza,Helmut Prendinger*

Main category: cs.LG

TL;DR: ESNs在加密货币预测方面表现出色，尤其是在高波动性和混沌时期，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于加密货币的高波动性和非平稳性，预测其价格具有挑战性。本研究旨在探索ESNs在加密货币预测中的应用，特别是在极端波动期间，并与现有方法进行比较。

Method: 使用回声状态网络（ESNs）进行加密货币价格预测，并结合李雅普诺夫指数进行混沌分析。

Result: ESNs在加密货币预测任务中表现出色，显著优于Boosting和朴素方法，尤其是在混沌时期。研究结果与李雅普诺夫指数分析一致，表明ESNs在高混沌情况下具有鲁棒性。

Conclusion: ESNs在加密货币预测方面表现出优越的性能，尤其是在高波动性和混沌时期，并且优于现有的机器学习方法。

Abstract: Forecasting stock and cryptocurrency prices is challenging due to high
volatility and non-stationarity, influenced by factors like economic changes
and market sentiment. Previous research shows that Echo State Networks (ESNs)
can effectively model short-term stock market movements, capturing nonlinear
patterns in dynamic data. To the best of our knowledge, this work is among the
first to explore ESNs for cryptocurrency forecasting, especially during extreme
volatility. We also conduct chaos analysis through the Lyapunov exponent in
chaotic periods and show that our approach outperforms existing machine
learning methods by a significant margin. Our findings are consistent with the
Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods
and excel under high chaos compared to Boosting and Na\"ive methods.

</details>


### [169] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha是一个处理不完整数据的Python工具包，可以模拟、可视化和评估缺失数据，支持数值和分类特征，并提供多种诊断工具。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界数据集中普遍存在的、由复杂且不可观察的缺失机制控制的不完整数据问题，并克服现有工具在模拟缺失数据方面的局限性（如碎片化、机制有限、仅关注数值变量）。

Method: 提出并实现了一个名为MissMecha的Python工具包，该工具包能够模拟、可视化和评估不同缺失机制（MCAR, MAR, MNAR）下的缺失数据，并支持数值和分类特征，同时提供视觉诊断、MCAR测试工具和类型感知的填充评估指标。

Result: MissMecha提供了一个统一的平台，支持对混合类型表格数据集进行感知机制的研究，包括视觉诊断、MCAR测试工具和类型感知的填充评估指标，为数据质量研究、基准测试和教育提供了支持。

Conclusion: MissMecha是一个开源的Python工具包，支持数值和分类特征，能够模拟、可视化和评估MCAR、MAR和MNAR假设下的缺失数据，适用于混合类型的数据集，旨在支持数据质量研究、基准测试和教育。

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [170] [Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search](https://arxiv.org/abs/2508.05433)
*Qinglong Hu,Xialiang Tong,Mingxuan Yuan,Fei Liu,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: MLES是一种新的程序化策略发现方法，它利用多模态大语言模型和进化搜索来创建可解释且高性能的控制策略，在效率和透明度方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度强化学习在可解释性和高性能方面存在的矛盾，特别是针对安全关键任务，本研究提出了一种名为多模态大语言模型辅助进化搜索（MLES）的程序化策略发现新方法。

Method: MLES利用多模态大语言模型作为策略生成器，并结合进化机制进行自动策略优化。它在策略生成过程中整合了视觉反馈驱动的行为分析，以识别失败模式并促进有针对性的改进，从而提高了策略发现的效率，并产生了适应性强、与人类对齐的策略。

Result: 实验结果表明，MLES在策略发现能力和效率方面与PPO相当，同时提供了透明的控制逻辑和可追溯的设计流程。

Conclusion: MLES在两个控制任务上实现了与PPO相当的策略发现能力和效率，同时提供了透明的控制逻辑和可追溯的设计流程，克服了预定义的特定领域语言的局限性，促进了知识转移和重用，并可扩展到各种控制任务。MLES有潜力成为下一代可解释控制策略发现的主导方法。

Abstract: Interpretability and high performance are essential goals in designing
control policies, particularly for safety-critical tasks. Deep reinforcement
learning has greatly enhanced performance, yet its inherent lack of
interpretability often undermines trust and hinders real-world deployment. This
work addresses these dual challenges by introducing a novel approach for
programmatic policy discovery, called Multimodal Large Language Model-assisted
Evolutionary Search (MLES). MLES utilizes multimodal large language models as
policy generators, combining them with evolutionary mechanisms for automatic
policy optimization. It integrates visual feedback-driven behavior analysis
within the policy generation process to identify failure patterns and
facilitate targeted improvements, enhancing the efficiency of policy discovery
and producing adaptable, human-aligned policies. Experimental results show that
MLES achieves policy discovery capabilities and efficiency comparable to
Proximal Policy Optimization (PPO) across two control tasks, while offering
transparent control logic and traceable design processes. This paradigm
overcomes the limitations of predefined domain-specific languages, facilitates
knowledge transfer and reuse, and is scalable across various control tasks.
MLES shows promise as a leading approach for the next generation of
interpretable control policy discovery.

</details>


### [171] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 一种新颖的集群感知分层联邦聚合框架，通过 LoRA 和联邦学习，在满足边缘设备约束的同时，实现了高效、可扩展且注重隐私的个性化 AIGC 服务。


<details>
  <summary>Details</summary>
Motivation: 现有的基于云的解决方案在解决多用户边缘 AIGC 场景中的隐私风险、个性化效率和通信成本方面存在不足。为了弥合这一差距，需要一种能够满足资源受限的边缘设备的解决方案。

Method: 提出了一种新颖的集群感知分层联邦聚合框架。该框架基于参数高效的低秩自适应（LoRA）本地微调，首先根据上传任务需求的相似性对客户端进行聚类，然后在服务器端进行集群内聚合以增强个性化。随后，实施集群间知识交互范例，以实现跨不同集群的混合风格内容生成。该框架建立在联邦学习（FL）协作的基础上，同时在设备上为用户训练个性化模型，并在服务器上训练一个带有多个 LoRA 适配器的共享全局模型，从而实现高效的边缘推理。此外，在传输前对所有用于聚类和推理的提示进行编码，从而进一步降低了明文泄露的风险。

Result: 评估表明，该框架实现了加速收敛，同时保持了在边缘约束下可扩展的多用户个性化 AIGC 服务在实践中的可行性。

Conclusion: 该框架在加速收敛的同时，保持了在边缘约束下可扩展的多用户个性化 AIGC 服务在实践中的可行性。

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [172] [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](https://arxiv.org/abs/2508.05616)
*Zhikai Zhao,Chuanbo Hua,Federico Berto,Kanghoon Lee,Zihan Ma,Jiachen Li,Jinkyoo Park*

Main category: cs.LG

TL;DR: TrajEvo 使用 LLM 和进化算法自动创建轨迹预测启发式方法，解决了传统和深度学习方法的局限性，在准确性、可解释性和 OOD 泛化方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹预测方法（如手工规则）准确性和泛化能力不足，而深度学习方法计算成本高、可解释性差且难以适应非分布外（OOD）场景。因此，需要一种新的方法来自动设计快速、可解释且能泛化到 OOD 场景的轨迹预测启发式方法。

Method: TrajEvo 框架利用进化算法，结合了跨代精英采样（鼓励种群多样性）和统计反馈循环（使 LLM 能够分析和改进预测），来从历史轨迹数据中自动生成和优化轨迹预测启发式方法。

Result: TrajEvo 在多个真实世界数据集上超越了现有的启发式方法，并且在泛化到未见过的 OOD 真实世界数据集方面，其性能显著优于启发式方法和深度学习方法。

Conclusion: TrajEvo 通过利用大型语言模型（LLMs）和进化算法，成功地自动化设计了轨迹预测启发式方法，在准确性、可解释性和泛化能力方面超越了传统方法和深度学习方法，尤其在处理非分布外（OOD）场景时表现突出，为快速、可解释和可泛化的轨迹预测启发式方法的自动化设计开辟了新途径。

Abstract: Trajectory prediction is a critical task in modeling human behavior,
especially in safety-critical domains such as social robotics and autonomous
vehicle navigation. Traditional heuristics based on handcrafted rules often
lack accuracy and generalizability. Although deep learning approaches offer
improved performance, they typically suffer from high computational cost,
limited explainability, and, importantly, poor generalization to
out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a
framework that leverages Large Language Models (LLMs) to automatically design
trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to
generate and refine prediction heuristics from past trajectory data. We propose
two key innovations: Cross-Generation Elite Sampling to encourage population
diversity, and a Statistics Feedback Loop that enables the LLM to analyze and
improve alternative predictions. Our evaluations demonstrate that TrajEvo
outperforms existing heuristic methods across multiple real-world datasets, and
notably surpasses both heuristic and deep learning methods in generalizing to
an unseen OOD real-world dataset. TrajEvo marks a promising step toward the
automated design of fast, explainable, and generalizable trajectory prediction
heuristics. We release our source code to facilitate future research at
https://github.com/ai4co/trajevo.

</details>


### [173] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为M3F的新型多模态大模型框架，并构建了M3FD数据集，以解决科学领域数据稀疏导致的少样本学习（FSL）难题。实验证明，该方法在少样本分类任务上表现优于传统方法，降低了在数据稀缺领域应用多模态大模型的门槛。


<details>
  <summary>Details</summary>
Motivation: 少样本学习（FSL）在科学领域（如生物医学、环境、材料和机械科学）至关重要，因为这些领域的数据采集成本高昂、耗时或受到伦理限制。现有方法在处理有限样本时泛化能力不足，因此需要更有效的方法。

Method: 本研究提出了一种名为M3F（Multi-Modal Model for Few-shot learning framework）的新型LMMM框架，该框架能够处理多种科学数据类型（包括2D RGB图像、2D/3D医学扫描、表格和时间序列数据）。研究人员构建了一个包含10K+少样本样本的多模态模型少样本数据集（M3FD），并使用该数据集对M3F进行了微调。

Result: 通过在M3FD数据集上微调，M3F模型在少样本分类任务上取得了优于传统元学习方法的性能。该研究表明，LMMM可以通过预训练和微调，有效解决科学领域的数据稀疏性问题，实现良好的泛化能力。

Conclusion: 该研究提出了一种新颖的少样本学习（FSL）方法，通过利用在大规模多模态模型（LMMM）的预训练和微调，显著提高了在数据稀疏的科学领域的泛化能力。所提出的M3F框架和M3FD数据集为LMMM在科学应用中的部署提供了可行的解决方案，并降低了相关研究的门槛。

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [174] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: AttriLens-Mol框架通过奖励机制优化LLM进行分子属性预测，提升了模型性能和结果的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在分子属性预测任务中虽然有潜力，但依赖人工设计的提示和思维链模板，且先进模型（如DeepSeek-R1）的推理过程可能冗长且缺乏相关性。本研究旨在提出一种新的框架，以更有效的方式利用LLM的内在知识进行分子属性预测。

Method: AttriLens-Mol是一个属性引导的强化学习框架，通过三种奖励机制（格式奖励、计数奖励、合理性奖励）来优化LLM在分子属性预测任务中的表现，从而引导模型生成结构化、相关性强的属性，并利用RDKit验证属性相关性。

Result: 在7B参数的R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型上，使用AttriLens-Mol在4000个样本上训练后，性能显著提升，可与监督微调模型和先进模型（如GPT-3.5、GPT-4o、DeepSeek-V3、DeepSeek-R1）媲美或超越。此外，提取的属性特征用于决策树模型时，表现优于直接提示LLM生成的属性。

Conclusion: AttriLens-Mol框架通过引入格式、计数和合理性奖励，有效引导LLM进行分子属性预测，相比现有方法在in-distribution和out-of-distribution数据集上均有显著提升，并能提取出更具预测性和可解释性的属性特征。

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [175] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为EPOPR的公平性感知电力系统恢复策略，通过结合公平性-对合分位数回归和空间-时间注意力强化学习，有效解决了现有方法中存在的社区间恢复不平等问题，并提高了恢复效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有电力系统恢复方案中，由于弱势社区报告的修复请求量较少而导致的不公平问题，提出一个兼顾恢复效率和社区公平性的公平性感知电力系统恢复策略。

Method: EPOPR框架包含两个关键组成部分：1. 用于不确定性感知修复持续时间预测的公平性-对合分位数回归；2. 适应跨区域不同不确定性水平以实现公平决策的空间-时间注意力强化学习。

Result: 实验结果表明，EPOPR框架能够有效减少平均停电时间3.60%，并降低社区间的不平等14.19%。

Conclusion: 提出的EPOPR框架能够有效减少平均停电时间3.60%，并与最先进的基线相比，降低了社区间的不平等14.19%。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [176] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: PA-RNet是一种鲁棒的多模态预测框架，通过扰动感知投影和跨模态注意力机制来解决文本数据中的噪声问题，从而提高预测性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了文本数据中固有的扰动，而文本数据中的不相关、嘈杂或模糊内容会严重影响模型性能，尤其是在噪声强度不同或源于结构不一致的情况下。

Method: PA-RNet包含一个扰动感知投影模块和一个跨模态注意力机制，以有效地将文本嵌入中的噪声与语义上有意义的表示分离开来。

Result: PA-RNet features a perturbation-aware projection module and a cross-modal attention mechanism to effectively separate noise from the textual embeddings while maintaining semantically meaningful representations, thereby enhancing the model's generalization ability.

Conclusion: PA-RNet在各种域和时间设置的广泛实验中，一致优于最先进的基线。

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [177] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: HCRide是一个基于Habic（一种多智能体强化学习算法）的人性化网约车系统，它能在提高效率的同时兼顾乘客公平性和司机偏好，并在真实数据集的实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数研究侧重于提高运营商收入，这可能导致乘客和司机的糟糕体验。因此，本研究旨在设计一个以人为本的网约车系统，在不损害整体系统效率的情况下，同时考虑乘客公平性和司机偏好。

Method: 提出了一种名为Habic（Harmonization-oriented Actor-Bi-Critic）的新颖多智能体强化学习算法，该算法包含三个主要组成部分：多智能体竞争机制、动态Actor网络和Bi-Critic网络，用于在考虑司机偏好的前提下优化系统效率和乘客公平性。

Result: 通过在深圳和纽约市的两个真实世界网约车数据集上进行的大量评估，实验结果表明，与现有的基线方法相比，HCRide能够有效地将系统效率提高2.02%，公平性提高5.39%，司机偏好提高10.21%。

Conclusion: 该研究设计了一个名为HCRide的人性化网约车系统，该系统基于一种新颖的多智能体强化学习算法Habic，在优化系统效率和乘客公平性的同时兼顾了司机偏好。

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [178] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: InfoQ通过评估量化对网络信息流的影响来优化混合精度量化，在不需重新训练的情况下提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的混合精度量化（MPQ）方法依赖于计算成本高昂的搜索算法或局部敏感性启发式代理（如Hessian），这些方法未能捕捉量化误差的级联全局效应。本研究认为，层量化敏感性应通过其对整个网络信息流的影响来衡量。

Method: InfoQ框架通过量化各层并测量后续层之间信息流的变化来评估敏感性，然后将位宽分配制定为整数线性规划问题来解决。

Result: InfoQ框架在搜索阶段无需重新训练，提供了优于现有方法的搜索时间/准确性权衡（使用的训练数据比现有方法少两个数量级），并在ImageNet上的MobileNetV2和ResNet18上实现了高达1%的准确性提升（压缩率分别为14倍和10.66倍）。

Conclusion: InfoQ框架通过量化每一层并测量后续层中信息量的变化来评估层敏感性，这种方法比现有方法具有更好的搜索时间/准确性权衡，并且在ImageNet上实现了更高的准确性。

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [179] [MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling](https://arxiv.org/abs/2508.05492)
*Jifan Gao,Mahmudur Rahman,John Caskey,Madeline Oguss,Ann O'Rourke,Randy Brown,Anne Stey,Anoop Mayampurath,Matthew M. Churpek,Guanhua Chen,Majid Afshar*

Main category: cs.LG

TL;DR: MoMA 是一种新颖的多模态架构，利用 LLM 代理处理 EHR 数据以提高临床预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了有效整合多模态 EHR 数据以进行临床预测建模，尽管存在数据要求大的挑战。

Method: 提出了一种名为 Mixture-of-Multimodal-Agents (MoMA) 的新颖架构，该架构利用多个大型语言模型 (LLM) 代理来处理多模态电子健康记录 (EHR) 数据，用于临床预测任务。

Result: MoMA 在三种预测任务的真实世界数据集上进行了评估，并在不同的模态组合和预测设置下，其表现优于当前最先进的方法。

Conclusion: MoMA 通过利用专门的 LLM 代理将非文本模态（如医学图像和实验室结果）转换为结构化文本摘要，然后由聚合器代理将这些摘要与临床笔记结合起来生成统一的多模态摘要，最后由预测器代理使用该摘要进行临床预测，从而在临床预测任务中表现优于现有最先进的方法，展示了其在各种任务中的准确性和灵活性。

Abstract: Multimodal electronic health record (EHR) data provide richer, complementary
insights into patient health compared to single-modality data. However,
effectively integrating diverse data modalities for clinical prediction
modeling remains challenging due to the substantial data requirements. We
introduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed
to leverage multiple large language model (LLM) agents for clinical prediction
tasks using multimodal EHR data. MoMA employs specialized LLM agents
("specialist agents") to convert non-textual modalities, such as medical images
and laboratory results, into structured textual summaries. These summaries,
together with clinical notes, are combined by another LLM ("aggregator agent")
to generate a unified multimodal summary, which is then used by a third LLM
("predictor agent") to produce clinical predictions. Evaluating MoMA on three
prediction tasks using real-world datasets with different modality combinations
and prediction settings, MoMA outperforms current state-of-the-art methods,
highlighting its enhanced accuracy and flexibility across various tasks.

</details>


### [180] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: LLMs show promise in diabetes management, matching RL performance with good prompting, but struggle with complex reasoning and safety, needing careful integration and validation.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of LLMs as an alternative to RL-based DTRs for automating clinical decision-making, leveraging their ability to embed clinical knowledge and heuristics through linguistic prompts without environment-specific training.

Method: The study evaluated open-source LLMs as dynamic insulin dosing agents in an in silico Type 1 diabetes simulator, comparing their zero-shot inference performance against RL agents (SRAs).

Result: Carefully designed zero-shot prompts enabled smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or superior performance to extensively trained SRAs in stable patient cohorts. However, LLMs showed limitations such as overly aggressive dosing with CoT reasoning, arithmetic hallucination, temporal misinterpretation, and inconsistent clinical logic. Incorporating explicit reasoning about latent clinical states yielded minimal performance gains.

Conclusion: LLMs can be cautiously integrated into clinical workflows, but require targeted prompt engineering, careful validation, and potentially hybrid approaches combining linguistic reasoning with structured physiological modeling for safe and effective decision-support systems.

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [181] [RCUKF: Data-Driven Modeling Meets Bayesian Estimation](https://arxiv.org/abs/2508.04985)
*Kumar Anurag,Kasra Azizi,Francesco Sorrentino,Wenbin Wan*

Main category: cs.LG

TL;DR: A new framework called RCUKF combines reservoir computing and unscented Kalman filtering to improve process modeling for complex systems, especially in high-dimensional or chaotic situations.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling is crucial in engineering and scientific applications, but obtaining reliable process models for complex systems is challenging. RCUKF addresses this by learning nonlinear system dynamics from data and integrating real-time sensor data to correct drift.

Method: The proposed framework, Reservoir Computing with Unscented Kalman Filtering (RCUKF), integrates data-driven modeling via Reservoir Computing (RC) with Bayesian estimation through the Unscented Kalman Filter (UKF).

Result: RCUKF serves as a surrogate process model in the UKF prediction step, generating state estimates in high-dimensional or chaotic regimes where nominal mathematical models may fail. The UKF measurement update corrects potential drift in the data-driven model.

Conclusion: RCUKF's effectiveness is demonstrated on benchmark problems and a real-time vehicle trajectory estimation task.

Abstract: Accurate modeling is crucial in many engineering and scientific applications,
yet obtaining a reliable process model for complex systems is often
challenging. To address this challenge, we propose a novel framework, reservoir
computing with unscented Kalman filtering (RCUKF), which integrates data-driven
modeling via reservoir computing (RC) with Bayesian estimation through the
unscented Kalman filter (UKF). The RC component learns the nonlinear system
dynamics directly from data, serving as a surrogate process model in the UKF
prediction step to generate state estimates in high-dimensional or chaotic
regimes where nominal mathematical models may fail. Meanwhile, the UKF
measurement update integrates real-time sensor data to correct potential drift
in the data-driven model. We demonstrate RCUKF effectiveness on well-known
benchmark problems and a real-time vehicle trajectory estimation task in a
high-fidelity simulation environment.

</details>


### [182] [HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation](https://arxiv.org/abs/2508.05135)
*Thinh Nguyen,Trung Phan,Binh T. Nguyen,Khoa D Doan,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为HFedDG的新场景，用于研究分层联邦学习中的域漂移问题。并引入了一种名为HFedATM的新方法，通过对齐模型滤波器和改进的模型聚合方式，有效提升了模型性能和泛化能力，同时保持了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）在扩展性方面存在挑战，而分层联邦学习（HFL）通过引入中间节点来解决这些问题。然而，HFL仍然面临域漂移的挑战，即不同客户和站点的数据分布存在显著差异。现有的联邦域泛化（FedDG）方法尚未充分集成到HFL框架中。

Method: 提出HFedDG场景，并设计了HFedATM方法，该方法包括两个关键步骤：1. 通过Filter-wise Optimal Transport Alignment对齐不同站点的模型滤波器；2. 利用Shrinkage-aware Regularized Mean Aggregation合并对齐后的模型。

Result: 实验结果表明，HFedATM显著提升了现有FedDG基线在多个数据集上的性能，同时保持了计算和通信效率。理论分析也证明了HFedATM相比于标准的层级平均法，具有更紧的泛化误差界限，从而实现了更快的收敛和更稳定的训练。

Conclusion: HFedDG是一个新的研究场景，旨在解决HFL中的域漂移问题。HFedATM通过对齐卷积滤波器和利用Shrinkage-aware Regularized Mean Aggregation来提高模型性能，并具有计算和通信效率。理论分析表明HFedATM具有更紧泛化误差界限，能实现更快的收敛和更稳定的训练。

Abstract: Federated Learning (FL) is a decentralized approach where multiple clients
collaboratively train a shared global model without sharing their raw data.
Despite its effectiveness, conventional FL faces scalability challenges due to
excessive computational and communication demands placed on a single central
server as the number of participating devices grows. Hierarchical Federated
Learning (HFL) addresses these issues by distributing model aggregation tasks
across intermediate nodes (stations), thereby enhancing system scalability and
robustness against single points of failure. However, HFL still suffers from a
critical yet often overlooked limitation: domain shift, where data
distributions vary significantly across different clients and stations,
reducing model performance on unseen target domains. While Federated Domain
Generalization (FedDG) methods have emerged to improve robustness to domain
shifts, their integration into HFL frameworks remains largely unexplored. In
this paper, we formally introduce Hierarchical Federated Domain Generalization
(HFedDG), a novel scenario designed to investigate domain shift within
hierarchical architectures. Specifically, we propose HFedATM, a hierarchical
aggregation method that first aligns the convolutional filters of models from
different stations through Filter-wise Optimal Transport Alignment and
subsequently merges aligned models using a Shrinkage-aware Regularized Mean
Aggregation. Our extensive experimental evaluations demonstrate that HFedATM
significantly boosts the performance of existing FedDG baselines across
multiple datasets and maintains computational and communication efficiency.
Moreover, theoretical analyses indicate that HFedATM achieves tighter
generalization error bounds compared to standard hierarchical averaging,
resulting in faster convergence and stable training behavior.

</details>


### [183] [Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](https://arxiv.org/abs/2508.05210)
*Saddam Hussain Khan*

Main category: cs.LG

TL;DR: 提出了一种结合LSTM、Transformer、TS-Mixer和注意力机制的混合深度学习模型，用于实时预测钻井过程中的进尺速率（ROP）。该模型在真实世界的数据集上表现出色，准确率高，可以优化钻井操作。


<details>
  <summary>Details</summary>
Motivation: 传统的经验、基于物理的和基础的机器学习模型在捕捉钻井数据的复杂时间与上下文关系方面存在不足，导致预测效果不佳和实时效用有限。

Method: 提出了一种集成LSTM、Transformer编码器、TS-Mixer块和注意力机制的新型混合深度学习架构，以协同模拟时间依赖性、静态特征交互、全局上下文和动态特征重要性。

Result: 所提出的模型在真实钻井数据集上的表现优于基准模型（单独的LSTM、TS-Mixer和更简单的混合模型），R方得分为0.9988，平均绝对百分比误差为1.447%。

Conclusion: 该混合深度学习方法能够实现可靠的实时ROP预测，为智能、经济高效的钻井优化系统铺平道路，并产生显著的运营影响。

Abstract: The Rate of Penetration (ROP) is crucial for optimizing drilling operations;
however, accurately predicting it is hindered by the complex, dynamic, and
high-dimensional nature of drilling data. Traditional empirical, physics-based,
and basic machine learning models often fail to capture intricate temporal and
contextual relationships, resulting in suboptimal predictions and limited
real-time utility. To address this gap, we propose a novel hybrid deep learning
architecture integrating Long Short-Term Memory (LSTM) networks, Transformer
encoders, Time-Series Mixer (TS-Mixer) blocks, and attention mechanisms to
synergistically model temporal dependencies, static feature interactions,
global context, and dynamic feature importance. Evaluated on a real-world
drilling dataset, our model outperformed benchmarks (standalone LSTM, TS-Mixer,
and simpler hybrids) with an R-squared score of 0.9988 and a Mean Absolute
Percentage Error of 1.447%, as measured by standard regression metrics
(R-squared, MAE, RMSE, MAPE). Model interpretability was ensured using SHAP and
LIME, while actual vs. predicted curves and bias checks confirmed accuracy and
fairness across scenarios. This advanced hybrid approach enables reliable
real-time ROP prediction, paving the way for intelligent, cost-effective
drilling optimization systems with significant operational impact.

</details>


### [184] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: FCRec task combines Federated Learning (FL) and Continual Learning (CL) for privacy-preserving recommendation systems dealing with evolving user data. The proposed F3CRec framework uses client-side Adaptive Replay Memory and server-side Item-wise Temporal Mean to balance knowledge retention and adaptation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing Federated Recommendation (FedRec) methods struggle with non-stationary data streams, and Continual Learning Recommendation (CLRec) methods assume centralized data access, creating a gap for privacy-preserving learning from evolving user preferences.

Method: F3CRec framework with client-side Adaptive Replay Memory and server-side Item-wise Temporal Mean.

Result: F3CRec maintains recommendation quality over time in a federated environment.

Conclusion: F3CRec outperforms existing approaches in maintaining recommendation quality over time in a federated environment.

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [185] [X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment](https://arxiv.org/abs/2508.05568)
*Qinghua Yao,Xiangrui Xu,Zhize Li*

Main category: cs.LG

TL;DR: X-VFL 通过 XCom 和 DS-Align 解决了 VFL 的数据对齐和本地独立推理问题，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统 VFL 在数据样本对齐和本地独立推理方面遇到的挑战，即需要完美对齐的数据样本和所有客户端参与的联合推理。

Method: 提出 X-VFL 框架，包含 Cross Completion (XCom) 模块用于处理缺失特征，Decision Subspace Alignment (DS-Align) 模块用于跨客户端的决策子空间对齐。

Result: X-VFL 在 CIFAR-10 数据集上准确率提升 15%，在 MIMIC-III 数据集上准确率提升 43%，证明了其在处理部分缺失特征和支持本地独立推理方面的有效性和优越性。

Conclusion: X-VFL 框架通过 XCom 和 DS-Align 模块解决了 VFL 中的数据对齐和本地独立推理问题，在真实数据集上表现出显著优于现有方法。

Abstract: Vertical Federated Learning (VFL) enables collaborative learning by
integrating disjoint feature subsets from multiple clients/parties. However,
VFL typically faces two key challenges: i) the requirement for perfectly
aligned data samples across all clients (missing features are not allowed); ii)
the requirement for joint collaborative inference/prediction involving all
clients (it does not support locally independent inference on a single client).
To address these challenges, we propose X-VFL, a new VFL framework designed to
deal with the non-aligned data samples with (partially) missing features and to
support locally independent inference of new data samples for each client. In
particular, we design two novel modules in X-VFL: Cross Completion (XCom) and
Decision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing
features for non-aligned data samples by leveraging information from other
clients. DS-Align aligns local features with completed and global features
across all clients within the decision subspace, thus enabling locally
independent inference at each client. Moreover, we provide convergence theorems
for different algorithms used in training X-VFL, showing an $O(1/\sqrt{T})$
convergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type
algorithms, where $T$ denotes the number of training update steps. Extensive
experiments on real-world datasets demonstrate that X-VFL significantly
outperforms existing methods, e.g., achieving a 15% improvement in accuracy on
the image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III
dataset. These results validate the practical effectiveness and superiority of
X-VFL, particularly in scenarios involving partially missing features and
locally independent inference.

</details>


### [186] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 提出了一种统一的流匹配框架，用于标记时序点过程，通过连续和离散流匹配，实现内生时间间隔和事件类型的联合建模。该模型在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。


<details>
  <summary>Details</summary>
Motivation: 对医疗保健、金融和用户行为建模等现实世界应用中，对长时程标记事件序列进行建模是一个基本挑战。现有的神经时序点过程模型通常是自回归的，一次预测一个时间步的下一个事件，这限制了它们的效率并导致长期预测中的误差累积。

Method: 提出了一种统一的流匹配框架，用于标记时序点过程，通过连续和离散流匹配，实现内生时间间隔和事件类型的联合建模。

Result: 在六个真实世界基准上评估了所提出的模型，在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。

Conclusion: 所提出的模型在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [187] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: This paper introduces a new security system for car networks (CAN) that uses AI to detect and stop cyberattacks. It's much better than older systems, especially when attacks are rare, and it's more efficient.


<details>
  <summary>Details</summary>
Motivation: The Controller Area Network (CAN) protocol lacks built-in security, making it susceptible to cyber-attacks. This paper addresses the need for effective intrusion detection in automotive CAN traffic.

Method: A multi-stage framework combining Variational Graph Autoencoder (VGAE) for structural anomaly detection and Knowledge-Distilled Graph Attention Network (KD-GAT) for attack classification. CAN bus activity is modeled as graph sequences. VGAE is used for selective undersampling to handle class imbalance, followed by GAT classification with optional score-level fusion. The student GAT achieves 96% parameter reduction.

Result: The framework demonstrates competitive accuracy and efficiency on six public CAN intrusion datasets. It achieves average improvements of 16.2% in F1-score over existing methods, with up to 55% F1-score improvements on highly imbalanced datasets.

Conclusion: The proposed multi-stage intrusion detection framework effectively detects and classifies cyber-attacks in automotive CAN traffic, outperforming existing methods, especially on imbalanced datasets.

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [188] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: Agnostics 是一个语言无关的训练后流程，通过单一验证器评估代码的外部行为，解决了低资源语言模型训练的瓶颈，显著提升了模型在多种低资源语言上的代码生成能力，并在基准测试中取得了领先结果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在 Python 和 JavaScript 等高资源语言的代码生成方面表现出色，但在科学和工程领域仍然重要的低资源语言方面则表现不佳。除了预训练数据明显不足外，训练后（post-training）过程本身也是一个瓶颈，因为每增加一种新语言似乎都需要新的数据集、测试工具和强化学习（RL）基础设施。

Method: Agnostics 引入了一个语言无关的训练后流程，其核心思想是仅通过代码的外部可观察行为来评估代码质量，从而使用一个通用的验证器来测试用任何语言编写的代码。具体实现包括：1. 使用 LLM 将现有的单元测试数据集转换为 I/O 格式；2. 提供一个简短的配置文件，指导验证器如何编译和运行目标语言的代码；3. 在一个健壮的代码执行环境中应用具有可验证奖励的强化学习（RLVR）。

Result: Agnostics 在五种低资源语言（Lua、Julia、R、OCaml 和 Fortran）上进行了应用，取得了以下成果：1. 将 Qwen-3 4B 模型的性能提升至可媲美其他 16B-70B 参数的开源模型；2. 能够顺利扩展到更大和更多样化的模型系列（Qwen-3 8B、DeepSeek Coder 6.7B Instruct、Phi 4 Mini）；3. 对于参数量小于等于 16B 的模型，在 MultiPL-E 和新引入的多语言版本 LiveCodeBench 上刷新了 pass@1 的 state-of-the-art 记录。

Conclusion: Agnostics 实现了针对低资源编程语言的agnostic（无语言）的训练后（post-training）流程，通过基于外部可观察行为的单一验证器来测试所有语言的代码，无需为每种语言进行定制化开发。该方法在 Lua、Julia、R、OCaml 和 Fortran 五种语言上进行了测试，显著提升了模型性能，并针对 ≤16B 参数模型在 MultiPL-E 和新的 LiveCodeBench 基准测试上取得了新的 state-of-the-art 结果。研究团队将发布相关数据集、训练代码和配置文件，旨在简化任何编程语言的 RL 训练后流程。

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


### [189] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
*Saman Pordanesh,Pejman Shahsavari,Hossein Ghadjari*

Main category: cs.LG

TL;DR: HNO是一种新的神经算子架构，它利用希尔伯特变换将信号映射到其解析表示，并学习其谱卷积，以更有效地为因果、对相位敏感和非平稳系统建模。


<details>
  <summary>Details</summary>
Motivation: HNO通过整合信号处理中的归纳偏倚来解决现有方法（如FNO）的局限性，例如傅里叶变换的周期性假设，并利用希尔伯特变换从信号的瞬时幅度和相位信息中提取有用的特征。

Method: HNO首先通过希尔伯特变换将输入信号映射到其解析表示，然后对这个希尔伯特变换后的表示应用核心可学习操作——谱卷积。

Result: HNO架构被形式化，并提供了基于解析信号理论的设计理论动机。

Conclusion: HNO有望更有效地为因果、对相位敏感和非平稳系统建模算子。

Abstract: Neural operators have emerged as a powerful, data-driven paradigm for
learning solution operators of partial differential equations (PDEs).
State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have
achieved remarkable success by performing convolutions in the frequency domain,
making them highly effective for a wide range of problems. However, this method
has some limitations, including the periodicity assumption of the Fourier
transform. In addition, there are other methods of analysing a signal, beyond
phase and amplitude perspective, and provide us with other useful information
to learn an effective network. We introduce the \textbf{Hilbert Neural Operator
(HNO)}, a new neural operator architecture to address some advantages by
incorporating a strong inductive bias from signal processing. HNO operates by
first mapping the input signal to its analytic representation via the Hilbert
transform, thereby making instantaneous amplitude and phase information
explicit features for the learning process. The core learnable operation -- a
spectral convolution -- is then applied to this Hilbert-transformed
representation. We hypothesize that this architecture enables HNO to model
operators more effectively for causal, phase-sensitive, and non-stationary
systems. We formalize the HNO architecture and provide the theoretical
motivation for its design, rooted in analytic signal theory.

</details>


### [190] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
*Sinho Chewi,Philippe Rigollet,Yuling Yan*

Main category: cs.LG

TL;DR: 提出了一种新的GM层，用于在概率测度上实现训练动力学，并在分类任务上表现良好，行为独特。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以直接在概率测度上实现动力学，以研究神经网络的另一种可能性。

Method: 采用高斯混合模型作为参数化分布族，并结合Wasserstein梯度流理论来推导概率测度上的训练动力学。

Result: 提出了一种新型的GM层，并进行了实验验证，证明了其可行性和独特性。

Conclusion: GM层在分类任务上取得了与双层全连接网络相当的测试性能，并且其行为与经典全连接层存在显著差异。

Abstract: The mean-field theory for two-layer neural networks considers infinitely wide
networks that are linearly parameterized by a probability measure over the
parameter space. This nonparametric perspective has significantly advanced both
the theoretical and conceptual understanding of neural networks, with
substantial efforts made to validate its applicability to networks of moderate
width. In this work, we explore the opposite direction, investigating whether
dynamics can be directly implemented over probability measures. Specifically,
we employ Gaussian mixture models as a flexible and expressive parametric
family of distributions together with the theory of Wasserstein gradient flows
to derive training dynamics for such measures. Our approach introduces a new
type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into
neural network architectures. As a proof of concept, we validate our proposal
through experiments on simple classification tasks, where a GM layer achieves
test performance comparable to that of a two-layer fully connected network.
Furthermore, we examine the behavior of these dynamics and demonstrate
numerically that GM layers exhibit markedly different behavior compared to
classical fully connected layers, even when the latter are large enough to be
considered in the mean-field regime.

</details>


### [191] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
*Kelsey Doerksen,Yuliya Marchetti,Steven Lu,Kevin Bowman,James Montgomery,Kazuyuki Miyazaki,Yarin Gal,Freddie Kalaitzis*

Main category: cs.LG

TL;DR: 该研究利用深度学习和贝叶斯方法改进了地表臭氧建模，能够更准确地预测和校正模型偏差，并为公共卫生决策提供可解释的支持。


<details>
  <summary>Details</summary>
Motivation: 鉴于空气污染（特别是地表臭氧）对人类健康构成全球性危害，以及传统物理模型在应对现实尺度问题上的局限性，同时深度学习模型缺乏可解释性，本研究旨在开发一种能够提供可解释性的方法来改进地表臭氧建模，以支持公共卫生决策。

Method: 本研究采用不确定性感知的U-Net架构，并结合贝叶斯和分位数回归方法来预测MOMO-Chem模型的地表臭氧残差（偏差）。

Result: 研究成功实现了区域层面的偏差估算，并量化了不同不确定性量化方法（贝叶斯和分位数回归）的性能。研究还确定了用于偏差校正的地面站点，并评估了土地利用信息的作用。

Conclusion: 该研究通过不确定性感知的U-Net架构，结合贝叶斯和分位数回归方法，成功预测了MOMO-Chem模型的地表臭氧残差（偏差），并在北美和欧洲的2019年6月区域估算中展示了其能力。研究突出了两种不确定性量化（UQ）方法之间的UQ分数，并辨别了MOMO-Chem偏差校正的最佳和次优地面站点，同时评估了土地利用信息在地表臭氧残差建模中的影响。

Abstract: Air pollution is a global hazard, and as of 2023, 94\% of the world's
population is exposed to unsafe pollution levels. Surface Ozone (O3), an
important pollutant, and the drivers of its trends are difficult to model, and
traditional physics-based models fall short in their practical use for scales
relevant to human-health impacts. Deep Learning-based emulators have shown
promise in capturing complex climate patterns, but overall lack the
interpretability necessary to support critical decision making for policy
changes and public health measures. We implement an uncertainty-aware U-Net
architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data
assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian
and quantile regression methods. We demonstrate the capability of our
techniques in regional estimation of bias in North America and Europe for June
2019. We highlight the uncertainty quantification (UQ) scores between our two
UQ methodologies and discern which ground stations are optimal and sub-optimal
candidates for MOMO-Chem bias correction, and evaluate the impact of land-use
information in surface ozone residual modeling.

</details>


### [192] [Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates](https://arxiv.org/abs/2508.04886)
*Kelsey Doerksen,Yuliya Marchetti,Kevin Bowman,Steven Lu,James Montgomery,Yarin Gal,Freddie Kalaitzis,Kazuyuki Miyazaki*

Main category: cs.LG

TL;DR: 使用CNN改进地表臭氧模型，结合土地利用信息，助力环境政策。


<details>
  <summary>Details</summary>
Motivation: 空气污染是全球最大的环境风险因素，而地表臭氧的建模，尤其是在与人类健康影响相关的尺度上，仍然是一个挑战，其全球趋势的驱动因素在这些尺度上很大程度上是未知的，限制了基于物理的模型的使用。

Method: 利用二维卷积神经网络（CNN）架构估算地表臭氧MOMO-Chem模型残差（模型偏差），并评估了整合高分辨率卫星土地利用信息的影响。

Result: 所提出的CNN方法在北美和欧洲的估算中表现出比传统机器学习方法更好地捕捉物理模型残差的潜力。

Conclusion: 该研究展示了使用二维卷积神经网络估算地表臭氧MOMO-Chem模型残差的潜力，并强调了结合高分辨率卫星土地利用信息可改进模型估计，其结果有助于增进对影响城市尺度臭氧偏差因素的理解，为改善环境政策提供支持。

Abstract: Air pollution is the world's largest environmental risk factor for human
disease and premature death, resulting in more than 6 million permature deaths
in 2019. Currently, there is still a challenge to model one of the most
important air pollutants, surface ozone, particularly at scales relevant for
human health impacts, with the drivers of global ozone trends at these scales
largely unknown, limiting the practical use of physics-based models. We employ
a 2D Convolutional Neural Network based architecture that estimate surface
ozone MOMO-Chem model residuals, referred to as model bias. We demonstrate the
potential of this technique in North America and Europe, highlighting its
ability better to capture physical model residuals compared to a traditional
machine learning method. We assess the impact of incorporating land use
information from high-resolution satellite imagery to improve model estimates.
Importantly, we discuss how our results can improve our scientific
understanding of the factors impacting ozone bias at urban scales that can be
used to improve environmental policy.

</details>


### [193] [Retrieval-Augmented Water Level Forecasting for Everglades](https://arxiv.org/abs/2508.04888)
*Rahuul Rangaraj,Jimeng Shi,Rajendra Paudel,Giri Narasimhan,Yanzhao Wu*

Main category: cs.LG

TL;DR: 埃弗格莱兹湿地水位预测：引入检索增强预测（RAF）框架，通过检索历史相似数据提高预测准确性，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在水文学预测中的应用仍处于初级阶段，且在泛化到不同数据集和领域时存在困难。为了解决这一问题，需要更有效的模型适应机制。

Method: 提出了一种名为检索增强预测（RAF）的框架，该框架通过维护一个外部历史观测数据库，在进行预测前检索历史上相似的多元水文情景，以丰富模型输入。比较了基于相似性和基于互信息的两种RAF方法。

Result: 在埃弗格莱兹湿地的真实世界数据评估中，RAF框架在提高水位预测准确性方面取得了显著效果。

Conclusion: 该研究将检索增强预测（RAF）方法引入水文学领域，并成功应用于埃弗格莱兹湿地的水位预测，显著提高了预测准确性。RAF框架通过检索历史相似案例来丰富模型输入，无需针对特定任务进行重新训练或微调，展示了其在环境水文学和生态系统管理中的应用潜力。

Abstract: Accurate water level forecasting is crucial for managing ecosystems such as
the Everglades, a subtropical wetland vital for flood mitigation, drought
management, water resource planning, and biodiversity conservation. While
recent advances in deep learning, particularly time series foundation models,
have demonstrated success in general-domain forecasting, their application in
hydrology remains underexplored. Furthermore, they often struggle to generalize
across diverse unseen datasets and domains, due to the lack of effective
mechanisms for adaptation. To address this gap, we introduce
Retrieval-Augmented Forecasting (RAF) into the hydrology domain, proposing a
framework that retrieves historically analogous multivariate hydrological
episodes to enrich the model input before forecasting. By maintaining an
external archive of past observations, RAF identifies and incorporates relevant
patterns from historical data, thereby enhancing contextual awareness and
predictive accuracy without requiring the model for task-specific retraining or
fine-tuning. Furthermore, we explore and compare both similarity-based and
mutual information-based RAF methods. We conduct a comprehensive evaluation on
real-world data from the Everglades, demonstrating that the RAF framework
yields substantial improvements in water level forecasting accuracy. This study
highlights the potential of RAF approaches in environmental hydrology and paves
the way for broader adoption of adaptive AI methods by domain experts in
ecosystem management. The code and data are available at
https://github.com/rahuul2992000/WaterRAF.

</details>


### [194] [Honest and Reliable Evaluation and Expert Equivalence Testing of Automated Neonatal Seizure Detection](https://arxiv.org/abs/2508.04899)
*Jovana Kljajic,John M. O'Toole,Robert Hogan,Tamara Skoric*

Main category: cs.LG

TL;DR: 为提高新生儿癫痫检测AI模型的可靠性和可比性，本研究评估了现有指标，并提出了包括平衡指标、敏感性、特异性、PPV、NPV和多评分者图灵测试在内的改进评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前新生儿癫痫检测模型评估实践中存在指标不一致和偏差的问题，阻碍了模型的可比性和可解释性，并且常在缺乏严格验证的情况下做出关于AI性能的专家级声明，引发了对其可靠性的担忧。

Method: 本研究通过使用真实和合成的癫痫注释，评估了常见的性能指标、共识策略和人类专家水平等效性测试，特别考虑了类别不平衡、评分者间一致性和评分者数量等因素。

Result: 研究发现，在类别不平衡情况下，Matthews和Pearson相关系数优于AUC。共识类型对评分者数量和其间的一致性水平敏感。在人类专家水平等效性测试中，使用Fleiss k的多评分者图灵测试最能捕捉专家水平的AI性能。

Conclusion: 该研究提出了一个用于新生儿癫痫检测的AI评估框架，推荐报告至少一个平衡指标、敏感性、特异性、PPV和NPV、以及使用Fleiss k的多评分者图灵测试结果，并在独立验证集上进行评估，以确保对AI方法的全面和诚实评估，为临床验证奠定基础。

Abstract: Reliable evaluation of machine learning models for neonatal seizure detection
is critical for clinical adoption. Current practices often rely on inconsistent
and biased metrics, hindering model comparability and interpretability.
Expert-level claims about AI performance are frequently made without rigorous
validation, raising concerns about their reliability. This study aims to
systematically evaluate common performance metrics and propose best practices
tailored to the specific challenges of neonatal seizure detection. Using real
and synthetic seizure annotations, we assessed standard performance metrics,
consensus strategies, and human-expert level equivalence tests under varying
class imbalance, inter-rater agreement, and number of raters. Matthews and
Pearson's correlation coefficients outperformed the area under the curve in
reflecting performance under class imbalance. Consensus types are sensitive to
the number of raters and agreement level among them. Among human-expert level
equivalence tests, the multi-rater Turing test using Fleiss k best captured
expert-level AI performance. We recommend reporting: (1) at least one balanced
metric, (2) Sensitivity, specificity, PPV and NPV, (3) Multi-rater Turing test
results using Fleiss k, and (4) All the above on held-out validation set. This
proposed framework provides an important prerequisite to clinical validation by
enabling a thorough and honest appraisal of AI methods for neonatal seizure
detection.

</details>


### [195] [Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning](https://arxiv.org/abs/2508.04901)
*Prabhav Singh,Jessica Sorrell*

Main category: cs.LG

TL;DR: 迁移学习中的自适应数据选择策略在提高性能的同时，也可能降低结果的可复现性。研究提出了量化这种权衡的指标（选择敏感性），并证明了高度自适应的方法（如梯度选择）性能虽好但可复现性差，而低适应性的方法则相反。预训练可以缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 在迁移学习广泛采用的背景下，对这些适应的可靠性知之甚少，特别是当使用动态优先化训练样本的自适应数据选择策略时。

Method: 通过引入一个量化适应有效性和结果一致性之间基本权衡的数学框架，对迁移学习中的可复现性进行了全面的理论和实证分析。形式化了选择敏感性（Δ_Q），这是一个衡量自适应选择策略对训练数据扰动响应程度的指标。

Result: 证明了可复现性失败的概率（两个独立的训练运行产生的模型在性能上差异超过某个阈值的可能性）随选择敏感性二次方增加，随样本量指数下降。实验表明，像梯度选择和课程学习这样的高度自适应策略虽然实现了卓越的任务性能，但可复现性失败率很高（高达30%），而适应性较差的方法则将失败率控制在7%以下。预训练可以显著降低失败率，同时保持性能增益。

Conclusion: 研究结果为实践者提供了关于如何在性能和可复现性之间进行权衡的原则性指导，并强调了在现代迁移学习系统中进行可复现性感知设计的必要性。

Abstract: The widespread adoption of transfer learning has revolutionized machine
learning by enabling efficient adaptation of pre-trained models to new domains.
However, the reliability of these adaptations remains poorly understood,
particularly when using adaptive data selection strategies that dynamically
prioritize training examples. We present a comprehensive theoretical and
empirical analysis of replicability in transfer learning, introducing a
mathematical framework that quantifies the fundamental trade-off between
adaptation effectiveness and result consistency. Our key contribution is the
formalization of selection sensitivity ($\Delta_Q$), a measure that captures
how adaptive selection strategies respond to perturbations in training data. We
prove that replicability failure probability: the likelihood that two
independent training runs produce models differing in performance by more than
a threshold, increases quadratically with selection sensitivity while
decreasing exponentially with sample size. Through extensive experiments on the
MultiNLI corpus using six adaptive selection strategies - ranging from uniform
sampling to gradient-based selection - we demonstrate that this theoretical
relationship holds precisely in practice. Our results reveal that highly
adaptive strategies like gradient-based and curriculum learning achieve
superior task performance but suffer from high replicability failure rates,
while less adaptive approaches maintain failure rates below 7%. Crucially, we
show that source domain pretraining provides a powerful mitigation mechanism,
reducing failure rates by up to 30% while preserving performance gains. These
findings establish principled guidelines for practitioners to navigate the
performance-replicability trade-off and highlight the need for
replicability-aware design in modern transfer learning systems.

</details>


### [196] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: Transformer models like ELECTRA are effective for detecting hate speech on social media, outperforming previous methods. Error analysis revealed challenges with sarcasm, coded language, and label noise.


<details>
  <summary>Details</summary>
Motivation: Hate speech on social media has harmful impacts and is linked to real-world hate crimes. Robust automated detection methods are needed, but existing deep learning approaches have limitations.

Method: This study explored transformer-based models (BERT, RoBERTa, GPT-2, ELECTRA) for hate speech detection using the MetaHate dataset (36 datasets, 1.2 million samples).

Result: Fine-tuned ELECTRA achieved the highest performance with an F1 score of 0.8980.

Conclusion: Fine-tuned ELECTRA achieved the highest performance (F1 score: 0.8980) in hate speech detection. Challenges with sarcasm, coded language, and label noise were identified through error analysis.

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [197] [ALScope: A Unified Toolkit for Deep Active Learning](https://arxiv.org/abs/2508.04937)
*Chenkai Wu,Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Gang Liu,Wray Buntine,Lan Du*

Main category: cs.LG

TL;DR: ALScope是一个用于深度主动学习（DAL）的统一评估平台，包含10个数据集和21种算法。实验发现DAL算法性能受领域和任务设置影响，在不平衡和开放集场景下有待提升，部分算法选择时间较长。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用日益复杂，分布偏移（如开放集识别）和数据不平衡等挑战引起广泛关注，促使了许多DAL算法的发展。然而，缺乏统一的平台阻碍了在多样化条件下进行公平、系统的评估。

Method: 提出了一种名为ALScope的深度主动学习（DAL）平台，集成了10个来自计算机视觉（CV）和自然语言处理（NLP）的数据集，以及21种代表性的DAL算法。该平台支持灵活配置实验因子，如算法、数据集、分布外（OOD）样本比例和类别不平衡比例，以进行全面、真实的评估。

Result: 通过在ALScope平台上进行广泛的实验，发现DAL算法性能因领域和任务设置而异。在不平衡和开放集等非标准场景下，DAL算法有改进空间。部分算法性能优异但选择时间长。

Conclusion: 深度主动学习（DAL）算法在不同领域和任务设置下的性能差异显著，在非标准场景（如不平衡和开放集设置）下有待改进。一些算法表现良好但选择时间长。

Abstract: Deep Active Learning (DAL) reduces annotation costs by selecting the most
informative unlabeled samples during training. As real-world applications
become more complex, challenges stemming from distribution shifts (e.g.,
open-set recognition) and data imbalance have gained increasing attention,
prompting the development of numerous DAL algorithms. However, the lack of a
unified platform has hindered fair and systematic evaluation under diverse
conditions. Therefore, we present a new DAL platform ALScope for classification
tasks, integrating 10 datasets from computer vision (CV) and natural language
processing (NLP), and 21 representative DAL algorithms, including both
classical baselines and recent approaches designed to handle challenges such as
distribution shifts and data imbalance. This platform supports flexible
configuration of key experimental factors, ranging from algorithm and dataset
choices to task-specific factors like out-of-distribution (OOD) sample ratio,
and class imbalance ratio, enabling comprehensive and realistic evaluation. We
conduct extensive experiments on this platform under various settings. Our
findings show that: (1) DAL algorithms' performance varies significantly across
domains and task settings; (2) in non-standard scenarios such as imbalanced and
open-set settings, DAL algorithms show room for improvement and require further
investigation; and (3) some algorithms achieve good performance, but require
significantly longer selection time.

</details>


### [198] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: A new method called REINA optimizes the balance between translation quality and latency in Simultaneous Speech Translation (SimulST) by adaptively waiting for more input. It achieves state-of-the-art results and improves efficiency by up to 21%.


<details>
  <summary>Details</summary>
Motivation: The significant challenge in Simultaneous Speech Translation (SimulST) is balancing translation quality and latency. The paper aims to address this by introducing a strategy and a novel loss function to optimize this trade-off.

Method: The paper introduces Regularized Entropy INformation Adaptation (REINA), a novel loss derived from information theory principles to train an adaptive policy using an existing non-streaming translation model. This strategy optimizes the trade-off between translation quality and latency by waiting for more input only if it provides additional information.

Result: REINA pushes the reported Pareto frontier of the latency/quality tradeoff over prior works. A metric for streaming efficiency quantitatively shows REINA improves the latency/quality trade-off by as much as 21% compared to prior approaches, normalized against non-streaming baseline BLEU scores.

Conclusion: Simultaneous Speech Translation (SimulST) systems achieve state-of-the-art (SOTA) streaming results on French, Spanish and German, both from and into English, using only open source or synthetically generated data. The proposed Regularized Entropy INformation Adaptation (REINA) loss improves the latency/quality trade-off by as much as 21% compared to prior approaches, normalized against non-streaming baseline BLEU scores.

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [199] [Self-Error Adjustment: Theory and Practice of Balancing Individual Performance and Diversity in Ensemble Learning](https://arxiv.org/abs/2508.04948)
*Rui Zou*

Main category: cs.LG

TL;DR: SEA是一种新的集成学习框架，通过分解和精确控制误差成分，实现了比现有方法更好的准确性-多样性权衡和性能。


<details>
  <summary>Details</summary>
Motivation: 传统的Bagging和Boosting方法在提高多样性时缺乏对准确性-多样性权衡的精确控制，而负相关学习（NCL）虽然能管理这种权衡，但理论边界松散且可调范围有限。

Method: 提出了一种名为“自误差调整”（SEA）的新框架，将集成误差分解为个体学习器自身的误差和学习器之间的交互作用，从而通过可调参数精确控制误差的各个组成部分，实现对集成模型性能的精细调节。

Result: SEA框架相比NCL及其变体，提供了更广泛的有效调整范围和更稳定的多样性变化。理论上，SEA为可调集成方法建立了更紧密的理论边界，并通过实验验证了其有效性。

Conclusion: SEA框架在回归和分类任务上均优于基线方法，并且在模型微调方面提供了更灵活的调整能力和更优越的性能。

Abstract: Ensemble learning boosts performance by aggregating predictions from multiple
base learners. A core challenge is balancing individual learner accuracy with
diversity. Traditional methods like Bagging and Boosting promote diversity
through randomness but lack precise control over the accuracy-diversity
trade-off. Negative Correlation Learning (NCL) introduces a penalty to manage
this trade-off but suffers from loose theoretical bounds and limited adjustment
range. To overcome these limitations, we propose a novel framework called
Self-Error Adjustment (SEA), which decomposes ensemble errors into two distinct
components: individual performance terms, representing the self-error of each
base learner, and diversity terms, reflecting interactions among learners. This
decomposition allows us to introduce an adjustable parameter into the loss
function, offering precise control over the contribution of each component,
thus enabling finer regulation of ensemble performance. Compared to NCL and its
variants, SEA provides a broader range of effective adjustments and more
consistent changes in diversity. Furthermore, we establish tighter theoretical
bounds for adjustable ensemble methods and validate them through empirical
experiments. Experimental results on several public regression and
classification datasets demonstrate that SEA consistently outperforms baseline
methods across all tasks. Ablation studies confirm that SEA offers more
flexible adjustment capabilities and superior performance in fine-tuning
strategies.

</details>


### [200] [Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization](https://arxiv.org/abs/2508.04950)
*Wei Liu,Anweshit Panda,Ujwal Pandey,Christopher Brissette,Yikang Shen,George M. Slota,Naigang Wang,Jie Chen,Yangyang Xu*

Main category: cs.LG

TL;DR: This paper introduces two new decentralized optimization algorithms that use momentum and compression to improve speed and reduce communication costs. These algorithms are proven to be effective, achieve optimal convergence, and outperform existing methods in deep learning tasks.


<details>
  <summary>Details</summary>
Motivation: To design compressed decentralized algorithms for solving nonconvex stochastic optimization under two different scenarios (bounded gradients and data heterogeneity) that achieve fast convergence and save communication costs, while theoretically proving the effectiveness of combining momentum acceleration and compressed communication in a decentralized algorithm.

Method: The paper designs two compressed decentralized algorithms for nonconvex stochastic optimization. The first is a compressed decentralized adaptive method for bounded gradients, which is the first decentralized adaptive stochastic gradient method with compressed communication. The second is a compressed decentralized heavy-ball method for data heterogeneity without bounded gradients, which uses gradient tracking to address data heterogeneity. Both algorithms use momentum and message compression.

Result: The proposed compressed decentralized adaptive method and compressed decentralized heavy-ball method achieve optimal convergence rates and linear speedup. They are also topology-independent within a certain regime of error tolerance and show superior empirical performance compared to existing methods on DNNs and Transformers.

Conclusion: Both proposed methods achieve an optimal convergence rate, linear speed up, and adopt topology-independent algorithmic parameters within a certain regime of the user-specified error tolerance. They also show superior empirical performance over state-of-the-art methods on training deep neural networks (DNNs) and Transformers.

Abstract: In this paper, we design two compressed decentralized algorithms for solving
nonconvex stochastic optimization under two different scenarios. Both
algorithms adopt a momentum technique to achieve fast convergence and a
message-compression technique to save communication costs. Though momentum
acceleration and compressed communication have been used in literature, it is
highly nontrivial to theoretically prove the effectiveness of their composition
in a decentralized algorithm that can maintain the benefits of both sides,
because of the need to simultaneously control the consensus error, the
compression error, and the bias from the momentum gradient.
  For the scenario where gradients are bounded, our proposal is a compressed
decentralized adaptive method. To the best of our knowledge, this is the first
decentralized adaptive stochastic gradient method with compressed
communication. For the scenario of data heterogeneity without bounded
gradients, our proposal is a compressed decentralized heavy-ball method, which
applies a gradient tracking technique to address the challenge of data
heterogeneity. Notably, both methods achieve an optimal convergence rate, and
they can achieve linear speed up and adopt topology-independent algorithmic
parameters within a certain regime of the user-specified error tolerance.
Superior empirical performance is observed over state-of-the-art methods on
training deep neural networks (DNNs) and Transformers.

</details>


### [201] [MENDR: Manifold Explainable Neural Data Representations](https://arxiv.org/abs/2508.04956)
*Matthew Chen,Micky Nnamdi,Justin Shao,Andrew Hornback,Hongyun Huang,Ben Tamo,Yishan Zhong,Benoit Marteau,Wenqi Shi,May Dongmei Wang*

Main category: cs.LG

TL;DR: MENDR是一个创新的EEG基础模型，利用黎曼流形Transformer和滤波器组，通过小波变换学习可解释的EEG表征，在保持高性能的同时提高了透明度和效率。


<details>
  <summary>Details</summary>
Motivation: 当前的EEG基础模型缺乏预训练动态的透明度，并且对其嵌入中EEG信息的保留程度了解有限。为了成功地进行临床集成，EEG基础模型必须确保预训练的透明度、下游微调以及学习到的表征的可解释性。现有方法主要在时间域进行操作，忽略了数字信号处理在提取确定性、可追溯特征（如小波基表示）方面的进展。

Method: 提出了一种基于滤波器组的EEG基础模型MENDR，该模型建立在新的黎曼流形Transformer架构之上。MENDR学习EEG信号的对称正定矩阵嵌入，并通过离散小波包变换将信号分解为多分辨率系数，在包含4000多小时EEG数据的大型语料库上进行预训练。MENDR通过将对称正定嵌入可视化为几何椭球来增强可解释性，并支持从学习的嵌入中准确重建EEG信号。

Result: MENDR在多个临床EEG任务的评估中，以显著更少的参数实现了接近最先进的性能，并能从学习的嵌入中准确重建EEG信号。

Conclusion: MENDR在多个临床EEG任务的评估中，以显著更少的参数实现了接近最先进的性能，证明了其在高效、可解释和临床应用的EEG分析方面的潜力。

Abstract: Foundation models for electroencephalography (EEG) signals have recently
demonstrated success in learning generalized representations of EEGs,
outperforming specialized models in various downstream tasks. However, many of
these models lack transparency in their pretraining dynamics and offer limited
insight into how well EEG information is preserved within their embeddings. For
successful clinical integration, EEG foundation models must ensure transparency
in pretraining, downstream fine-tuning, and the interpretability of learned
representations. Current approaches primarily operate in the temporal domain,
overlooking advancements in digital signal processing that enable the
extraction of deterministic and traceable features, such as wavelet-based
representations. We propose MENDR (Manifold Explainable Neural Data
Representations), a filter bank-based EEG foundation model built on a novel
Riemannian Manifold Transformer architecture to resolve these issues. MENDR
learns symmetric positive definite matrix embeddings of EEG signals and is
pretrained on a large corpus comprising over 4,000 hours of EEG data,
decomposed via discrete wavelet packet transforms into multi-resolution
coefficients. MENDR significantly enhances interpretability by visualizing
symmetric positive definite embeddings as geometric ellipsoids and supports
accurate reconstruction of EEG signals from learned embeddings. Evaluations
across multiple clinical EEG tasks demonstrate that MENDR achieves near
state-of-the-art performance with substantially fewer parameters, underscoring
its potential for efficient, interpretable, and clinically applicable EEG
analysis.

</details>


### [202] [Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning](https://arxiv.org/abs/2508.05077)
*Luai Abuelsamen,Temitope Lukman Adebanjo*

Main category: cs.LG

TL;DR: 本研究基于统计学习理论，证明了多模态模仿学习策略优于单一模态策略。


<details>
  <summary>Details</summary>
Motivation: 探究多模态模仿学习的理论基础，理解多模态感知如何影响模仿策略的性能，并为PerAct和CLIPort等先进的多模态架构提供理论解释。

Method: 本研究运用统计学习理论，分析了多模态感知（RGB-D、本体感觉、语言）如何影响模仿策略的样本复杂度和优化构型，并与Rademacher复杂度、PAC学习和信息论等基础概念相联系。

Result: 研究表明，正确整合的多模态模仿策略相比单一模态策略，能够获得更紧的泛化边界和更优的优化构型。

Conclusion: 通过统计学习理论的视角，本研究为多模态模仿学习奠定了理论基础，并展示了多模态融合策略在泛化边界和优化领域相较于单一模态策略的优越性。

Abstract: This paper examines the theoretical foundations of multimodal imitation
learning through the lens of statistical learning theory. We analyze how
multimodal perception (RGB-D, proprioception, language) affects sample
complexity and optimization landscapes in imitation policies. Building on
recent advances in multimodal learning theory, we show that properly integrated
multimodal policies can achieve tighter generalization bounds and more
favorable optimization landscapes than their unimodal counterparts. We provide
a comprehensive review of theoretical frameworks that explain why multimodal
architectures like PerAct and CLIPort achieve superior performance, connecting
these empirical results to fundamental concepts in Rademacher complexity, PAC
learning, and information theory.

</details>


### [203] [Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.04999)
*Menghua Jiang,Yuxia Lin,Baoliang Chen,Haifeng Hu,Yuncheng Jiang,Sijie Mai*

Main category: cs.LG

TL;DR: MMCI模型通过因果干预解决多模态情感分析中的虚假相关性问题，提升了模型的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态情感分析方法常常受到模态内和跨模态虚假相关性的影响，导致模型依赖统计捷径而非真实因果关系，从而削弱了泛化能力。

Method: 本研究提出了一种多关系多模态因果干预（MMCI）模型，该模型将多模态输入建模为多关系图以捕捉依赖关系，然后利用注意力机制估计和分离因果特征与捷径特征，并通过后门调整来稳定预测。

Result: 实验结果表明，MMCI模型能够有效抑制偏差，并在标准多模态情感分析数据集和分布外测试集上提高了模型性能。

Conclusion: 该研究提出的MMCI模型通过利用因果理论中的后门调整来解决多模态情感分析中的虚假相关性问题，有效抑制了偏差并提高了在分布外测试集上的性能。

Abstract: Multimodal sentiment analysis (MSA) aims to understand human emotions by
integrating information from multiple modalities, such as text, audio, and
visual data. However, existing methods often suffer from spurious correlations
both within and across modalities, leading models to rely on statistical
shortcuts rather than true causal relationships, thereby undermining
generalization. To mitigate this issue, we propose a Multi-relational
Multimodal Causal Intervention (MMCI) model, which leverages the backdoor
adjustment from causal theory to address the confounding effects of such
shortcuts. Specifically, we first model the multimodal inputs as a
multi-relational graph to explicitly capture intra- and inter-modal
dependencies. Then, we apply an attention mechanism to separately estimate and
disentangle the causal features and shortcut features corresponding to these
intra- and inter-modal relations. Finally, by applying the backdoor adjustment,
we stratify the shortcut features and dynamically combine them with the causal
features to encourage MMCI to produce stable predictions under distribution
shifts. Extensive experiments on several standard MSA datasets and
out-of-distribution (OOD) test sets demonstrate that our method effectively
suppresses biases and improves performance.

</details>


### [204] [ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning](https://arxiv.org/abs/2508.05310)
*Jelle Luijkx,Zlatan Ajanović,Laura Ferranti,Jens Kober*

Main category: cs.LG

TL;DR: ASkDAgger通过利用新手计划和不确定性信息，优化了模仿学习中的教师查询策略，提高了学习效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了减少交互式模仿学习所需的人类教学查询数量，同时利用新手计划中包含的关于能力和不确定性的信息，从而提高学习效率和泛化能力。

Method: ASkDAgger框架包括三个主要组成部分：(1) S-Aware Gating (SAG)，用于调整跟踪敏感度、特异性或最低成功率的选通阈值；(2) Foresight Interactive Experience Replay (FIER)，将有效且重新标记的新手动作计划转化为演示；(3) Prioritized Interactive Experience Replay (PIER)，根据不确定性、新手成功率和演示年龄对重放进行优先级排序。

Result: ASkDAgger框架能够平衡查询频率与失败发生率，减少所需的演示注释数量，提高泛化能力，并加速对变化域的适应。

Conclusion: ASkDAgger框架通过利用新手计划上的教师反馈，在查询频率、失败发生率、所需演示注释数量、泛化能力以及适应变化域的速度方面取得了良好的平衡，并在语言引导操作任务中得到了验证。

Abstract: Human teaching effort is a significant bottleneck for the broader
applicability of interactive imitation learning. To reduce the number of
required queries, existing methods employ active learning to query the human
teacher only in uncertain, risky, or novel situations. However, during these
queries, the novice's planned actions are not utilized despite containing
valuable information, such as the novice's capabilities, as well as
corresponding uncertainty levels. To this end, we allow the novice to say: "I
plan to do this, but I am uncertain." We introduce the Active Skill-level Data
Aggregation (ASkDAgger) framework, which leverages teacher feedback on the
novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating
threshold to track sensitivity, specificity, or a minimum success rate; (2)
Foresight Interactive Experience Replay (FIER), which recasts valid and
relabeled novice action plans into demonstrations; and (3) Prioritized
Interactive Experience Replay (PIER), which prioritizes replay based on
uncertainty, novice success, and demonstration age. Together, these components
balance query frequency with failure incidence, reduce the number of required
demonstration annotations, improve generalization, and speed up adaptation to
changing domains. We validate the effectiveness of ASkDAgger through
language-conditioned manipulation tasks in both simulation and real-world
environments. Code, data, and videos are available at
https://askdagger.github.io.

</details>


### [205] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero是一个全自动框架，通过让两个模型（Challenger和Solver）相互作用、共同进化来生成训练数据，从而提升大型语言模型的推理能力，且无需人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型训练方法高度依赖于人工策划的任务和标签，这阻碍了AI能力超越人类智能的进步。本研究旨在克服这一限制，提出一种完全自主的框架。

Method: R-Zero框架通过初始化两个独立模型（Challenger和Solver），让它们通过交互进行协同进化。Challenger提出处于Solver能力边缘的任务，Solver则解决这些日益复杂的任务，从而形成一个无须预先存在的任务和标签的、目标明确的、自我改进的课程。

Result: R-Zero框架在不同的基础大型语言模型上均显著提升了推理能力。例如，在Qwen3-4B-Base模型上，数学推理能力提升了+6.49，通用领域推理能力提升了+7.54。

Conclusion: R-Zero框架通过自主生成和迭代的方式，能够显著提升大型语言模型的推理能力，为实现超越人类智能的AI系统提供了新的途径。

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [206] [SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models](https://arxiv.org/abs/2508.05015)
*Dai Do,Manh Nguyen,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: SPaRFT 是一种自适应课程学习框架，通过聚类和多臂老虎机算法优化数据选择和时机，显著减少了训练大型语言模型所需的样本量和计算资源，同时保持或提高了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习微调方法需要大量数据和计算资源，对于较小的模型来说不切实际。现有的课程学习或数据选择方法大多是启发式驱动的，或者需要大量的计算资源，这限制了它们的可扩展性和泛化性。

Method: SPaRFT 框架结合了基于聚类的 K-means 聚类算法和多臂老虎机算法。首先，通过聚类算法将训练数据按语义和难度进行划分，提取出紧凑且多样化的数据子集，从而减少冗余。然后，将数据聚类视为“臂”，并使用多臂老虎机算法根据模型当前的表现来优化训练样本的分配。

Result: SPaRFT 在多个推理基准测试中取得了与最先进基线相当或更好的准确率，同时使用的样本量减少了高达 100 倍。消融研究和分析进一步证明了数据聚类和自适应选择的重要性。

Conclusion: SPaRFT 框架通过优化数据使用方式和时机，实现了高效学习，能够以极少的资源（样本量减少高达 100 倍）解锁大型语言模型的强大推理能力。

Abstract: Large language models (LLMs) have shown strong reasoning capabilities when
fine-tuned with reinforcement learning (RL). However, such methods require
extensive data and compute, making them impractical for smaller models. Current
approaches to curriculum learning or data selection are largely
heuristic-driven or demand extensive computational resources, limiting their
scalability and generalizability. We propose \textbf{SPaRFT}, a self-paced
learning framework that enables efficient learning based on the capability of
the model being trained through optimizing which data to use and when. First,
we apply \emph{cluster-based data reduction} to partition training data by
semantics and difficulty, extracting a compact yet diverse subset that reduces
redundancy. Then, a \emph{multi-armed bandit} treats data clusters as arms,
optimized to allocate training samples based on model current performance.
Experiments across multiple reasoning benchmarks show that SPaRFT achieves
comparable or better accuracy than state-of-the-art baselines while using up to
\(100\times\) fewer samples. Ablation studies and analyses further highlight
the importance of both data clustering and adaptive selection. Our results
demonstrate that carefully curated, performance-driven training curricula can
unlock strong reasoning abilities in LLMs with minimal resources.

</details>


### [207] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 该研究利用眼动追踪技术和图神经网络（FixGraphPool）成功预测了增强现实（AR）系统用户在心肺复苏（CPR）任务中的态势感知（SA）水平，证明了眼动追踪在提升AR系统安全性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 增强现实（AR）系统虽然能通过实时指导提高任务绩效，但也可能导致认知隧道效应，即过度关注虚拟内容而牺牲在安全关键场景下的态势感知（SA）。本研究旨在解决AR系统在指导心肺复苏（CPR）等高风险任务时可能出现的SA下降问题，特别关注如何在有效执行指导的同时保持对周围环境的警觉。

Method: 研究人员开发了一款基于Magic Leap 2的AR应用程序，用于在模拟的心肺复苏（CPR）场景中提供实时指导。通过设计模拟的意外事件（如出血），并收集用户的眼动追踪数据、观察记录和问卷反馈，来评估用户的态势感知（SA）水平。在此基础上，提出了一个名为FixGraphPool的图神经网络模型，该模型将眼动事件（注视、扫视）构建成时空图，以捕捉动态的注意力模式，并用于预测SA水平。

Result: 眼动追踪分析显示，较高的SA水平与较大的扫视幅度、较高的扫视速度以及减少的注视虚拟内容比例和频率相关。所提出的FixGraphPool模型在预测SA方面达到了83.0%的准确率（F1=81.0%），优于传统的基于特征的机器学习模型和先进的时间序列模型。

Conclusion: 该研究证明了眼动追踪在增强现实（AR）系统中的应用潜力，特别是在安全关键场景下对用户态势感知（SA）进行建模。研究结果表明，眼动追踪数据可以有效预测SA水平，并为设计更安全的AR系统提供指导。

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [208] [Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting](https://arxiv.org/abs/2508.05059)
*Jinhyeok Jang,Jaehong Kim,Jung Uk Kim*

Main category: cs.LG

TL;DR: 通过结构化遗忘和其逆过程，KNOW prediction能够合成更丰富的预训练权重，以提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 在现代深度学习中，预训练权重是实现高效知识迁移和在数据稀疏场景下提升下游任务性能的基石。然而，如何获得能够包含比给定数据集更多知识的、更好的预训练权重仍然是一个基本问题。

Method: 提出了一种名为KNOW prediction的新策略，该策略利用结构化遗忘及其逆过程来合成知识丰富的权重。具体方法是通过在逐渐缩小的downsized数据集上进行顺序微调，诱导结构化遗忘过程，然后通过元学习对权重预测进行建模，使用KNOWN（KNowledge Overflowed Weights Nowcaster）作为超模型来学习权重的普遍演变并预测具有改进泛化能力的增强权重。

Result: 实验表明，KNOW prediction在各种数据集和架构上持续优于朴素微调和简单的权重预测，从而在下游任务中实现了更优越的性能。

Conclusion: KNOW prediction通过利用结构化遗忘及其逆过程来合成知识丰富的权重，并在各种数据集和架构上进行了广泛的实验，证明了其在下游任务中优于朴素微调和简单权重预测，为深度学习中的知识迁移提供了新的视角。

Abstract: Pre-trained weights have become a cornerstone of modern deep learning,
enabling efficient knowledge transfer and improving downstream task
performance, especially in data-scarce scenarios. However, a fundamental
question remains: how can we obtain better pre-trained weights that encapsulate
more knowledge beyond the given dataset? In this work, we introduce
\textbf{KNowledge Overflowed Weights (KNOW)} prediction, a novel strategy that
leverages structured forgetting and its inversion to synthesize
knowledge-enriched weights. Our key insight is that sequential fine-tuning on
progressively downsized datasets induces a structured forgetting process, which
can be modeled and reversed to recover knowledge as if trained on a larger
dataset. We construct a dataset of weight transitions governed by this
controlled forgetting and employ meta-learning to model weight prediction
effectively. Specifically, our \textbf{KNowledge Overflowed Weights Nowcaster
(KNOWN)} acts as a hyper-model that learns the general evolution of weights and
predicts enhanced weights with improved generalization. Extensive experiments
across diverse datasets and architectures demonstrate that KNOW prediction
consistently outperforms Na\"ive fine-tuning and simple weight prediction,
leading to superior downstream performance. Our work provides a new perspective
on reinterpreting forgetting dynamics to push the limits of knowledge transfer
in deep learning.

</details>


### [209] [TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows](https://arxiv.org/abs/2508.05070)
*Moshe Eliasof,Eldad Haber,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: TANGO是一个受动力学系统启发的图表示学习框架，通过学习到的能量景观和切向演化来更新节点特征，从而提高图学习的性能和灵活性，并能缓解过压缩问题。


<details>
  <summary>Details</summary>
Motivation: TANGO旨在提供一种新的图表示学习框架，该框架受动力学系统启发，通过学习到的能量景观及其下降动力学来控制节点特征的演化，以期提高图学习的性能和灵活性。

Method: TANGO是一个受动力学系统启发的图表示学习框架，通过学习到的能量景观及其相关的下降动力学来控制节点特征的演化。其核心是节点嵌入上的可学习李亚普诺夫函数，其梯度定义了保证收敛性和稳定性的能量降低方向。为了在保持能量动力学优势的同时提高灵活性，TANGO引入了一个通过消息传递学习的新型切向分量，它在演化特征的同时保持能量值。这种能量梯度下降和切向演化的正交流分解产生了灵活的图动力学形式，并能够在图学习中常见的平坦或病态能量区域中实现有效的信号传播。TANGO还可以缓解过压缩问题，并兼容不同的图神经网络骨干。

Result: TANGO能够有效传播信号，即使在图学习中常见的平坦或病态能量区域也是如此，并且可以缓解过压缩问题，还能兼容不同的图神经网络骨干。在实际应用中，TANGO在多种节点和图分类及回归基准测试中均取得了强劲的性能。

Conclusion: TANGO在多种节点和图分类及回归基准测试中均取得了强劲的性能，证明了联合学习的能量函数和切向流对于图神经网络的有效性。

Abstract: We introduce TANGO -- a dynamical systems inspired framework for graph
representation learning that governs node feature evolution through a learned
energy landscape and its associated descent dynamics. At the core of our
approach is a learnable Lyapunov function over node embeddings, whose gradient
defines an energy-reducing direction that guarantees convergence and stability.
To enhance flexibility while preserving the benefits of energy-based dynamics,
we incorporate a novel tangential component, learned via message passing, that
evolves features while maintaining the energy value. This decomposition into
orthogonal flows of energy gradient descent and tangential evolution yields a
flexible form of graph dynamics, and enables effective signal propagation even
in flat or ill-conditioned energy regions, that often appear in graph learning.
Our method mitigates oversquashing and is compatible with different graph
neural network backbones. Empirically, TANGO achieves strong performance across
a diverse set of node and graph classification and regression benchmarks,
demonstrating the effectiveness of jointly learned energy functions and
tangential flows for graph neural networks.

</details>


### [210] [ULU: A Unified Activation Function](https://arxiv.org/abs/2508.05073)
*Simin Huo*

Main category: cs.LG

TL;DR: ULU is a new activation function that outperforms ReLU and Mish. Its variant, AULU, can adapt to inputs, and the LIB metric measures model bias.


<details>
  <summary>Details</summary>
Motivation: The motivation is to propose a novel activation function that treats positive and negative inputs differently and outperforms existing ones like ReLU and Mish.

Method: The paper proposes ULU, a novel non-monotonic, piecewise activation function defined as $f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0 $, where $f(x;\alpha)=0.5x(\tanh(\alpha x)+1),\alpha >0$. It also introduces AULU, a variant where $\beta_1$ and $\beta_2$ are learnable parameters. The LIB metric is introduced to quantitatively measure inductive bias.

Result: Extensive experiments show that ULU significantly outperforms ReLU and Mish across image classification and object detection tasks. AULU introduces learnable parameters for adaptation. The LIB metric is introduced to measure inductive bias.

Conclusion: ULU significantly outperforms ReLU and Mish across image classification and object detection tasks. AULU adapts its response separately for positive and negative inputs. LIB metric measures inductive bias.

Abstract: We propose \textbf{ULU}, a novel non-monotonic, piecewise activation function
defined as $\{f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0 \}$, where
$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$. ULU treats positive and
negative inputs differently. Extensive experiments demonstrate ULU
significantly outperforms ReLU and Mish across image classification and object
detection tasks. Its variant Adaptive ULU (\textbf{AULU}) is expressed as
$\{f(x;\beta_1^2),x<0; f(x;\beta_2^2),x>=0 \}$, where $\beta_1$ and $\beta_2$
are learnable parameters, enabling it to adapt its response separately for
positive and negative inputs. Additionally, we introduce the LIB (Like
Inductive Bias) metric from AULU to quantitatively measure the inductive bias
of the model.

</details>


### [211] [Integrated Influence: Data Attribution with Baseline](https://arxiv.org/abs/2508.05089)
*Linxiao Yang,Xinyu Gu,Liang Sun*

Main category: cs.LG

TL;DR: 集成影响是一种新颖的数据归因方法，通过考虑样本的集体影响和引入基线来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 数据归因对于理解数据和模型以及进一步增强机器学习模型的透明度至关重要。现有的基于留一法（LOO）的数据归因方法存在基于局部解释的问题，因为这些LOO方法只扰动单个训练样本，而忽略了训练集中样本的集体影响。此外，许多数据归因方法缺乏基线，这降低了解释的灵活性，例如无法提供反事实解释。

Method: 集成影响是一种新颖的数据归因方法，它包含一个基线方法。该方法定义了一个基线数据集，遵循数据退化过程将当前数据集转换为基线，并在此过程中累积每个样本的影响。该方法为该方法提供了一个坚实的理论框架，并表明像影响函数这样的流行方法可以被视为该方法的特例。

Result: 实验结果表明，与现有方法相比，集成影响在数据归因任务和错误标记示例识别任务中都生成了更可靠的数据归因。

Conclusion: 与现有方法相比，集成影响在数据归因任务和错误标记示例识别任务中都生成了更可靠的数据归因。

Abstract: As an effective approach to quantify how training samples influence test
sample, data attribution is crucial for understanding data and model and
further enhance the transparency of machine learning models. We find that
prevailing data attribution methods based on leave-one-out (LOO) strategy
suffer from the local-based explanation, as these LOO-based methods only
perturb a single training sample, and overlook the collective influence in the
training set. On the other hand, the lack of baseline in many data attribution
methods reduces the flexibility of the explanation, e.g., failing to provide
counterfactual explanations. In this paper, we propose Integrated Influence, a
novel data attribution method that incorporates a baseline approach. Our method
defines a baseline dataset, follows a data degeneration process to transition
the current dataset to the baseline, and accumulates the influence of each
sample throughout this process. We provide a solid theoretical framework for
our method, and further demonstrate that popular methods, such as influence
functions, can be viewed as special cases of our approach. Experimental results
show that Integrated Influence generates more reliable data attributions
compared to existing methods in both data attribution task and mislablled
example identification task.

</details>


### [212] [Cold Start Active Preference Learning in Socio-Economic Domains](https://arxiv.org/abs/2508.05090)
*Mojtaba Fayaz-Bakhsh,Danial Ataee,MohammadAmin Fazli*

Main category: cs.LG

TL;DR: 该研究提出了一种新的冷启动主动偏好学习框架，通过自监督预训练和主动学习循环来解决数据稀疏问题，并在金融、职业和社会经济领域的数据集上取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决主动偏好学习中的冷启动问题，尤其是在计算社会系统和经济分析等标记数据稀疏、昂贵且可能存在噪声的场景中。

Method: 通过自监督预训练阶段（利用PCA从数据固有结构中提取初始伪标签）来启动学习过程，然后在活跃学习循环中通过查询模拟噪声源来优化模型。

Result: 该方法在不进行任何初始Oracle交互的情况下，创建了一个冷启动模型，并通过策略性地查询模拟噪声源来优化模型。实验证明，该方法在不同领域的各种数据集上，其准确性优于从头开始的标准主动学习策略，且所需的标记对数大大减少。

Conclusion: 该方法为数据受限环境下的偏好学习提供了一个实际有效的解决方案，提高了样本效率和适用性。

Abstract: Active preference learning is a powerful paradigm for efficiently modeling
preferences, yet it suffers from the cold-start problem: a significant drop in
performance when no initial labeled data is available. This challenge is
particularly acute in computational social systems and economic analysis, where
labeled data is often scarce, expensive, and subject to expert noise. To
address this gap, we propose a novel framework for cold-start active preference
learning. Our method initiates the learning process through a self-supervised
pre-training phase, utilizing Principal Component Analysis (PCA) to derive
initial pseudo-labels from the data's inherent structure, thereby creating a
cold-start model without any initial oracle interaction. Subsequently, the
model is refined through an active learning loop that strategically queries a
simulated noisy oracle for labels. We conduct extensive experiments on diverse
datasets from different domains, including financial credibility, career
success rate, and socio-economic status. The results demonstrate that our
cold-start approach outperforms standard active learning strategies that begin
from a blank slate, achieving higher accuracy with substantially fewer labeled
pairs. Our framework offers a practical and effective solution to mitigate the
cold-start problem, enhancing the sample efficiency and applicability of
preference learning in data-constrained environments. We release our code at
https://github.com/Dan-A2/cold-start-preference-learning

</details>


### [213] [Learning from Similarity-Confidence and Confidence-Difference](https://arxiv.org/abs/2508.05108)
*Tomoya Tate,Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 本研究提出了一种新的弱监督学习框架，通过结合相似性置信度和置信度差异这两种弱标签，并提出新的风险估计方法和风险修正技术，有效解决了标签数据有限的问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在实际的机器学习应用中，为数据分配准确的标签通常很困难，并且标记实例的数量增加常常受到限制。在这些情况下，弱监督学习（WSL）提供了一种实用有效的解决方案，它能够使用不完整或不精确的监督进行训练。然而，大多数现有的WSL方法都侧重于利用单一类型的弱监督。

Method: 本文提出了一种新颖的弱监督学习（WSL）框架，该框架利用来自多个关系视角的互补弱监督信号，并引入了一种名为SconfConfDiff Classification的方法，该方法集成了两种不同形式的弱标签：相似性置信度和置信度差异。为了实现该方法，我们导出了两种类型的无偏风险估计量，一种基于现有估计量的凸组合，另一种通过对两个弱标签之间的交互进行建模来设计。我们证明了这两种估计量在估计误差界方面都达到了最优收敛速率。此外，我们还引入了一种风险修正方法来减轻由负经验风险引起的过拟合，并对所提出方法在抵抗不准确的类先验概率和标签噪声方面的鲁棒性进行了理论分析。

Result: 实验结果表明，所提出的方法在各种设置下始终优于现有的基线方法。

Conclusion: 实验结果表明，所提出的方法在各种设置下始终优于现有的基线方法。

Abstract: In practical machine learning applications, it is often challenging to assign
accurate labels to data, and increasing the number of labeled instances is
often limited. In such cases, Weakly Supervised Learning (WSL), which enables
training with incomplete or imprecise supervision, provides a practical and
effective solution. However, most existing WSL methods focus on leveraging a
single type of weak supervision. In this paper, we propose a novel WSL
framework that leverages complementary weak supervision signals from multiple
relational perspectives, which can be especially valuable when labeled data is
limited. Specifically, we introduce SconfConfDiff Classification, a method that
integrates two distinct forms of weaklabels: similarity-confidence and
confidence-difference, which are assigned to unlabeled data pairs. To implement
this method, we derive two types of unbiased risk estimators for
classification: one based on a convex combination of existing estimators, and
another newly designed by modeling the interaction between two weak labels. We
prove that both estimators achieve optimal convergence rates with respect to
estimation error bounds. Furthermore, we introduce a risk correction approach
to mitigate overfitting caused by negative empirical risk, and provide
theoretical analysis on the robustness of the proposed method against
inaccurate class prior probability and label noise. Experimental results
demonstrate that the proposed method consistently outperforms existing
baselines across a variety of settings.

</details>


### [214] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 提出了一种新的强化学习框架，通过基于熵的探索来改进函数调用任务中的策略优化，解决了探索不足、缺乏结构化推理和参数提取验证的问题。在伯克利函数调用排行榜上取得了最先进的性能，特别是在代码预训练模型上表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前针对函数调用的训练方法未能开发出强大的推理策略。监督微调会产生依赖于肤浅模式匹配的模型，而标准的强化学习方法则难以处理结构化函数调用的复杂动作空间。

Method: 提出了一种新颖的强化学习框架，通过针对函数调用任务进行优化的战略性基于熵的探索来增强群组相对策略优化 (GRPO)。该方法通过两阶段数据准备流程解决函数调用中的三个关键挑战：策略学习期间的探索不足、思维链生成中缺乏结构化推理以及参数提取验证不足。

Result: 在伯克利函数调用排行榜上，该框架实现了最先进的性能，整体准确率为 86.02%，在复杂的多函数场景中，性能比标准 GRPO 高出 6%。

Conclusion: 该框架在伯克利函数调用排行榜上实现了最先进的性能，在复杂的多函数场景中，整体准确率达到了 86.02%，超越了标准的 GRPO 高达 6%。特别是，该方法在预训练代码的模型上显示出特别强的改进，表明结构化语言生成能力为函数调用任务中的强化学习提供了有利的起点。

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [215] [PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning](https://arxiv.org/abs/2508.05144)
*Beicheng Xu,Wei Liu,Keyao Ding,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: PSEO is a new framework for optimizing post-hoc stacking ensembles in AutoML that adaptively selects base models and optimizes ensemble strategies, outperforming existing methods in empirical evaluations.


<details>
  <summary>Details</summary>
Motivation: Existing AutoML systems often use fixed strategies for ensembling, failing to adapt to task-specific characteristics. This paper addresses this limitation by proposing an adaptive framework for post-hoc stacking ensemble optimization.

Method: PSEO framework utilizes binary quadratic programming for base model selection, balancing diversity and performance, and incorporates mechanisms for multi-layer stacking optimization. It also searches for optimal post-hoc ensemble strategies within a defined hyperparameter space.

Result: PSEO achieved the best average test rank (2.96) among 16 methods, including state-of-the-art ensemble learning methods and recent AutoML systems, across 80 public datasets.

Conclusion: The proposed PSEO framework achieves superior performance in post-hoc stacking ensemble optimization for AutoML tasks, outperforming existing methods on a large number of public datasets.

Abstract: The Combined Algorithm Selection and Hyperparameter Optimization (CASH)
problem is fundamental in Automated Machine Learning (AutoML). Inspired by the
success of ensemble learning, recent AutoML systems construct post-hoc
ensembles for final predictions rather than relying on the best single model.
However, while most CASH methods conduct extensive searches for the optimal
single model, they typically employ fixed strategies during the ensemble phase
that fail to adapt to specific task characteristics. To tackle this issue, we
propose PSEO, a framework for post-hoc stacking ensemble optimization. First,
we conduct base model selection through binary quadratic programming, with a
trade-off between diversity and performance. Furthermore, we introduce two
mechanisms to fully realize the potential of multi-layer stacking. Finally,
PSEO builds a hyperparameter space and searches for the optimal post-hoc
ensemble strategy within it. Empirical results on 80 public datasets show that
\sys achieves the best average test rank (2.96) among 16 methods, including
post-hoc designs in recent AutoML systems and state-of-the-art ensemble
learning methods.

</details>


### [216] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
*Rishabh Gaur,Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 该研究为基于 RL 的 ABM 和 RABM 开发了领域驱动的指标，并使用疫情疾病建模案例研究进行了演示，以解决评估 RL 算法的挑战。


<details>
  <summary>Details</summary>
Motivation: 评估基于 RL 的 ABM 和 RABM 的性能具有挑战性，因为模型系统的复杂性和随机性，以及缺乏标准化的指标来比较 RL 算法。

Method: 本研究通过构建最先进的指标来开发领域驱动的指标，并使用策略优化来演示这些指标。

Result: 研究结果表明，在不同的模拟场景（例如口罩的可用性差异）下，使用领域驱动的奖励以及传统的和最先进的指标。

Conclusion: 该研究开发了领域驱动的强化学习（RL）指标，并通过疫情期间的掩蔽行为、疫苗接种和封锁的理性基于主体的模型（RABM）疾病建模案例研究进行了演示。

Abstract: For the development and optimization of agent-based models (ABMs) and
rational agent-based models (RABMs), optimization algorithms such as
reinforcement learning are extensively used. However, assessing the performance
of RL-based ABMs and RABMS models is challenging due to the complexity and
stochasticity of the modeled systems, and the lack of well-standardized metrics
for comparing RL algorithms. In this study, we are developing domain-driven
metrics for RL, while building on state-of-the-art metrics. We demonstrate our
``Domain-driven-RL-metrics'' using policy optimization on a rational ABM
disease modeling case study to model masking behavior, vaccination, and
lockdown in a pandemic. Our results show the use of domain-driven rewards in
conjunction with traditional and state-of-the-art metrics for a few different
simulation scenarios such as the differential availability of masks.

</details>


### [217] [pFedDSH: Enabling Knowledge Transfer in Personalized Federated Learning through Data-free Sub-Hypernetwork](https://arxiv.org/abs/2508.05157)
*Thinh Nguyen,Le Huy Khiem,Van-Tuan Tran,Khoa D Doan,Nitesh V Chawla,Kok-Seng Wong*

Main category: cs.LG

TL;DR: pFedDSH是一种用于解决动态客户端加入场景下个性化联邦学习问题的新框架。它通过超网络、特定批次掩码和无数据重放策略，实现了对现有客户端的性能保持和新客户端的有效适应，同时保证了隐私和资源的高效利用。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化联邦学习（pFL）方法大多假设客户端参与是静态的，这与现实世界中新客户端可能持续加入联邦系统（即动态客户端加入）的情况不符。在客户端不断加入而学习任务保持不变的情况下，需要解决如何为现有客户端保留性能而不进行重新训练，以及如何在客户端批次之间实现有效的知识转移等问题。

Method: 提出了一种名为pFedDSH的新型框架，该框架基于中心超网络，通过嵌入向量为每个客户端生成个性化模型。为了保持现有客户端的知识稳定性，pFedDSH采用了特定批次的掩码，激活神经元子集以保留知识。此外，还引入了一种受DeepInversion启发的无数据重放策略，以促进反向迁移，在不损害隐私的情况下提高现有客户端的性能。

Result: pFedDSH在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上进行了广泛的实验，结果表明，在所研究的场景下，pFedDSH的性能优于最先进的pFL和联邦持续学习基线。该方法在现有客户端的性能稳定性、新客户端的适应性以及神经资源的有效利用方面都表现出色。

Conclusion: pFedDSH框架在动态客户端加入场景下，能够保持现有客户端的性能稳定性，同时适应新加入的客户端，并有效利用神经网络资源，在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上的实验结果优于现有的pFL和联邦持续学习基线。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients without sharing raw data, offering a significant privacy
benefit. However, most existing Personalized Federated Learning (pFL) methods
assume a static client participation, which does not reflect real-world
scenarios where new clients may continuously join the federated system (i.e.,
dynamic client onboarding). In this paper, we explore a practical scenario in
which a new batch of clients is introduced incrementally while the learning
task remains unchanged. This dynamic environment poses various challenges,
including preserving performance for existing clients without retraining and
enabling efficient knowledge transfer between client batches. To address these
issues, we propose Personalized Federated Data-Free Sub-Hypernetwork (pFedDSH),
a novel framework based on a central hypernetwork that generates personalized
models for each client via embedding vectors. To maintain knowledge stability
for existing clients, pFedDSH incorporates batch-specific masks, which activate
subsets of neurons to preserve knowledge. Furthermore, we introduce a data-free
replay strategy motivated by DeepInversion to facilitate backward transfer,
enhancing existing clients' performance without compromising privacy. Extensive
experiments conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate
that pFedDSH outperforms the state-of-the-art pFL and Federated Continual
Learning baselines in our investigation scenario. Our approach achieves robust
performance stability for existing clients, as well as adaptation for new
clients and efficient utilization of neural resources.

</details>


### [218] [S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164)
*Jiaqi Wang,Zhengyu Ma,Xiongri Shen,Chenlin Zhou,Leilei Zhao,Han Zhang,Yi Zhong,Siqi Cai,Zhenxi Song,Zhiguo Zhang*

Main category: cs.LG

TL;DR: S$^2$M-Former是一种新颖的、低功耗的、高性能的基于EEG的听觉注意力检测框架，通过其独特的脉冲对称架构和轻量级设计，在能效和解码精度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管近期取得了进展，但基于EEG的AAD仍然受到缺乏协同框架的限制，这些框架无法在能效约束下充分利用互补的EEG特征。

Method: 提出了一种名为S$^2$M-Former的新型脉冲对称混合框架，具有两个主要创新：i)提出了一种由并行空间和频率分支组成的驱动脉冲对称架构，采用镜像模块化设计，利用受生物启发的令牌-通道混合器来增强跨分支的互补学习；ii)引入了轻量级的一维令牌序列来替代传统的3D操作，参数量减少了14.7倍。该受大脑启发的脉冲架构进一步降低了功耗，与最近的ANN方法相比，能耗降低了5.8倍，并且在参数效率和性能方面都超过了现有的SNN基线。

Result: S$^2$M-Former在参数效率和性能方面都超过了现有的SNN基线，并实现了5.8倍的能耗降低，同时在三个AAD基准上达到了与SOTA相当的解码精度。

Conclusion: S$^2$M-Former在KUL、DTU和AV-GC-AAD三个AAD基准的三个设置（试验内、试验间和受试者间）上进行了综合实验，证明其达到了与最先进技术（SOTA）相当的解码精度，是AAD任务的有前途的低功耗、高性能解决方案。

Abstract: Auditory attention detection (AAD) aims to decode listeners' focus in complex
auditory environments from electroencephalography (EEG) recordings, which is
crucial for developing neuro-steered hearing devices. Despite recent
advancements, EEG-based AAD remains hindered by the absence of synergistic
frameworks that can fully leverage complementary EEG features under
energy-efficiency constraints. We propose S$^2$M-Former, a novel spiking
symmetric mixing framework to address this limitation through two key
innovations: i) Presenting a spike-driven symmetric architecture composed of
parallel spatial and frequency branches with mirrored modular design,
leveraging biologically plausible token-channel mixers to enhance complementary
learning across branches; ii) Introducing lightweight 1D token sequences to
replace conventional 3D operations, reducing parameters by 14.7$\times$. The
brain-inspired spiking architecture further reduces power consumption,
achieving a 5.8$\times$ energy reduction compared to recent ANN methods, while
also surpassing existing SNN baselines in terms of parameter efficiency and
performance. Comprehensive experiments on three AAD benchmarks (KUL, DTU and
AV-GC-AAD) across three settings (within-trial, cross-trial and cross-subject)
demonstrate that S$^2$M-Former achieves comparable state-of-the-art (SOTA)
decoding accuracy, making it a promising low-power, high-performance solution
for AAD tasks.

</details>


### [219] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: HIA 是一种新的 LLM 对齐方法，可以在不牺牲质量的情况下降低成本，并且在低推理预算下效果良好。


<details>
  <summary>Details</summary>
Motivation: 对齐 LLM 与用户偏好对于实际应用至关重要，但通常需要昂贵的微调或推理，导致对齐质量和计算成本之间的权衡。现有推理时间方法通常会忽略这种平衡，仅关注优化策略的性能。

Method: HIA（启发式引导的推理时间对齐）使用轻量级提示优化器、启发式奖励模型和两阶段过滤来减少推理调用，同时保持对齐质量。

Result: 在真实世界的提示数据集 HelpSteer 和 ComPRed 上，HIA 在多目标、目标条件任务中，在相同的推理预算下，优于 N 个最佳采样、束搜索和贪婪搜索基线。研究还发现，HIA 在推理预算较低的情况下（仅一到两次响应查询）也有效，为可扩展的、个性化的 LLM 部署提供了一个实际的解决方案。

Conclusion: HIA 是一种无需微调、兼容黑盒的方法，通过轻量级提示优化器、启发式奖励模型和两阶段过滤来减少推理调用，同时保持对齐质量。

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [220] [Near Optimal Inference for the Best-Performing Algorithm](https://arxiv.org/abs/2508.05173)
*Amichai Painsky*

Main category: cs.LG

TL;DR: This paper presents a new framework for selecting the best machine learning algorithm, which improves existing methods and is mathematically proven to be effective. It addresses the challenge of identifying the top algorithm when performance differences are small, by treating the problem as a subset selection task for multinomial distributions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to identify the best performing machine learning algorithm among a collection of competing algorithms, specifically determining which algorithm is most likely to rank highest on a future, unseen dataset, especially when performance differences are marginal.

Method: The paper formulates the problem of identifying the best performing machine learning algorithm as a subset selection problem for multinomial distributions, aiming to identify a minimal subset of symbols that includes the most frequent symbol with high confidence.

Result: The paper presents schemes that significantly improve upon currently known methods for subset selection and demonstrates their favorable performance through matching lower bounds.

Conclusion: This paper introduces a novel framework for subset selection problems, providing asymptotic and finite-sample schemes that improve upon existing methods and are supported by matching lower bounds.

Abstract: Consider a collection of competing machine learning algorithms. Given their
performance on a benchmark of datasets, we would like to identify the best
performing algorithm. Specifically, which algorithm is most likely to rank
highest on a future, unseen dataset. A natural approach is to select the
algorithm that demonstrates the best performance on the benchmark. However, in
many cases the performance differences are marginal and additional candidates
may also be considered. This problem is formulated as subset selection for
multinomial distributions. Formally, given a sample from a countable alphabet,
our goal is to identify a minimal subset of symbols that includes the most
frequent symbol in the population with high confidence. In this work, we
introduce a novel framework for the subset selection problem. We provide both
asymptotic and finite-sample schemes that significantly improve upon currently
known methods. In addition, we provide matching lower bounds, demonstrating the
favorable performance of our proposed schemes.

</details>


### [221] [Human Activity Recognition from Smartphone Sensor Data for Clinical Trials](https://arxiv.org/abs/2508.05175)
*Stefania Russo,Rafał Klimas,Marta Płonka,Hugo Le Gall,Sven Holm,Dimitar Stanev,Florian Lipsmeier,Mattia Zanon,Lito Kriara*

Main category: cs.LG

TL;DR: 本研究开发了一种基于ResNet的HAR模型，可准确识别日常活动，并对智能手机佩戴位置具有高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够准确识别日常活动，并对智能手机佩戴位置具有鲁棒性的HAR模型。

Method: 开发了一个基于ResNet的人类活动识别（HAR）模型，以最小的开销检测步态与非步态活动以及日常活动（行走、跑步、上下楼梯、站立、坐着、躺着、坐到站转换）。

Result: HAR模型在检测步态与非步态活动方面，在GaitLab和Roche数据集中准确率分别为98.4%和99.6%，与比较性的最先进ResNet模型（分别为99.3%和99.4%）相当。在日常活动方面，提出的模型不仅准确率高于最先进模型（96.2% vs 91.9%），而且在9个不同的智能手机佩戴位置上保持了高识别性能，比最先进模型高出2.8%-9.0%。

Conclusion: 该研究提出的HAR模型能够准确检测日常活动，并且对各种智能手机佩戴位置具有高度的鲁棒性，显示出其实际应用潜力。

Abstract: We developed a ResNet-based human activity recognition (HAR) model with
minimal overhead to detect gait versus non-gait activities and everyday
activities (walking, running, stairs, standing, sitting, lying, sit-to-stand
transitions). The model was trained and evaluated using smartphone sensor data
from adult healthy controls (HC) and people with multiple sclerosis (PwMS) with
Expanded Disability Status Scale (EDSS) scores between 0.0-6.5. Datasets
included the GaitLab study (ISRCTN15993728), an internal Roche dataset, and
publicly available data sources (training only). Data from 34 HC and 68 PwMS
(mean [SD] EDSS: 4.7 [1.5]) were included in the evaluation. The HAR model
showed 98.4% and 99.6% accuracy in detecting gait versus non-gait activities in
the GaitLab and Roche datasets, respectively, similar to a comparative
state-of-the-art ResNet model (99.3% and 99.4%). For everyday activities, the
proposed model not only demonstrated higher accuracy than the state-of-the-art
model (96.2% vs 91.9%; internal Roche dataset) but also maintained high
performance across 9 smartphone wear locations (handbag, shopping bag,
crossbody bag, backpack, hoodie pocket, coat/jacket pocket, hand, neck, belt),
outperforming the state-of-the-art model by 2.8% - 9.0%. In conclusion, the
proposed HAR model accurately detects everyday activities and shows high
robustness to various smartphone wear locations, demonstrating its practical
applicability.

</details>


### [222] [Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference](https://arxiv.org/abs/2508.05190)
*Luis Mandl,Dibyajyoti Nayak,Tim Ricken,Somdatta Goswami*

Main category: cs.LG

TL;DR: PITI-DeepONet是一种新的深度学习模型，通过学习时间导数算子来解决偏微分方程的长期预测问题，克服了传统方法的精度和稳定性限制，并在多个测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统的全展开（FR）和自回归（AR）方法在模拟和推断时间依赖偏微分方程的长期演化时存在局限性：FR方法难以捕捉因果依赖关系且泛化能力差；AR方法则会累积误差，限制长期精度。这两种方法的缺点都限制了它们在长期预测中的准确性和可靠性。

Method: 提出了一种名为PITI-DeepONet（Physics-Informed Time-Integrated Deep Operator Network）的双输出网络架构，该网络不直接预测未来状态，而是学习当前状态的时间导数算子，并利用经典时间步进方案进行积分以推进时间。该模型可以通过全物理信息或混合物理与数据驱动的目标进行训练，并在推理过程中利用残差监控来估计预测质量和检测系统是否超出训练域。

Result: 在应用于一维热方程、一维Burgers方程和二维Allen-Cahn方程等基准问题时，PITI-DeepONet在扩展推理时间范围内相比FR和AR方法取得了显著的精度提升。具体来说，平均相对L2误差分别降低了84%（对比FR）和79%（对比AR），87%（对比FR）和98%（对比AR），以及42%（对比FR）和89%（对比AR）。

Conclusion: PITI-DeepONet通过学习时间导数算子并利用经典时间步进方案来解决时间依赖偏微分方程的长期预测问题，相比传统的全展开和自回归方法，在多个基准问题上展现出更高的准确性和稳定性，尤其是在超出训练时间范围的推理中，平均相对L2误差显著降低，为复杂偏微分方程的长期可靠积分开辟了新途径。

Abstract: Accurately modeling and inferring solutions to time-dependent partial
differential equations (PDEs) over extended horizons remains a core challenge
in scientific machine learning. Traditional full rollout (FR) methods, which
predict entire trajectories in one pass, often fail to capture the causal
dependencies and generalize poorly outside the training time horizon.
Autoregressive (AR) approaches, evolving the system step by step, suffer from
error accumulation, limiting long-term accuracy. These shortcomings limit the
long-term accuracy and reliability of both strategies. To address these issues,
we introduce the Physics-Informed Time-Integrated Deep Operator Network
(PITI-DeepONet), a dual-output architecture trained via fully physics-informed
or hybrid physics- and data-driven objectives to ensure stable, accurate
long-term evolution well beyond the training horizon. Instead of forecasting
future states, the network learns the time-derivative operator from the current
state, integrating it using classical time-stepping schemes to advance the
solution in time. Additionally, the framework can leverage residual monitoring
during inference to estimate prediction quality and detect when the system
transitions outside the training domain. Applied to benchmark problems,
PITI-DeepONet shows improved accuracy over extended inference time horizons
when compared to traditional methods. Mean relative $\mathcal{L}_2$ errors
reduced by 84% (vs. FR) and 79% (vs. AR) for the one-dimensional heat equation;
by 87% (vs. FR) and 98% (vs. AR) for the one-dimensional Burgers equation; and
by 42% (vs. FR) and 89% (vs. AR) for the two-dimensional Allen-Cahn equation.
By moving beyond classic FR and AR schemes, PITI-DeepONet paves the way for
more reliable, long-term integration of complex, time-dependent PDEs.

</details>


### [223] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 该研究提出了一种新的方法来评估金融领域大型语言模型在处理表格数据时的幻觉问题，并发布了一个包含S&P 500年报数据的新数据集，旨在提高金融AI的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决金融领域大型语言模型（LLMs）在处理表格数据时出现的幻觉问题，因为金融分析需要精确的数值提取和计算，任何微小的错误都可能影响决策和合规性。

Method: 提出了一种上下文感知的掩码跨度预测任务，并开发了一种新颖的、自动化的数据集创建范例，该范例使用掩码策略，并从S&P 500年报中提取数据。

Result: 对最先进的大型语言模型在金融表格数据上的内在幻觉模式进行了全面评估，并提供了一种用于内部模型评估的稳健方法。

Conclusion: 该研究提供了一种严格且可扩展的框架，用于评估金融领域大型语言模型的内在幻觉，旨在提高金融生成式人工智能系统的可信度和可靠性。

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [224] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
*Bin Liu,Yunfei Liu,Ziru Xu,Zhaoyu Zhou,Zhi Kou,Yeqiu Yang,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Bidding-Aware Retrieval (BAR) 的新框架，用于解决在线广告系统中检索和排序阶段之间由于竞价信息不一致而导致的性能问题，通过整合竞价信号和实时更新机制，最终显著提高了平台收入和广告展示量。


<details>
  <summary>Details</summary>
Motivation: 在线广告系统中，检索阶段和排序阶段之间存在不一致性，因为前者无法获取大量广告语料库的精确实时竞价，这导致平台收入和广告商成果不佳。

Method: BAR框架通过以下方式解决多阶段不一致性：1. Bidding-Aware Modeling：利用单调性约束学习和多任务蒸馏，将竞价信号纳入其中，确保经济上连贯的表征。2. Asynchronous Near-Line Inference：实现嵌入的实时更新，以适应市场变化。3. Task-Attentive Refinement：选择性地增强特征交互，以区分用户兴趣和商业价值信号。

Result: 离线实验和在阿里巴巴展示广告平台上的全面部署验证了BAR的有效性：平台收入增加了4.32%，正面运营的广告展示量提升了22.2%。

Conclusion: Bidding-Aware Retrieval (BAR) 通过将广告竞价值纳入检索评分函数，解决了多阶段不一致性问题，并在阿里巴巴展示广告平台上的广泛部署验证了其有效性，实现了4.32%的平台收入增长和22.2%的正面广告展示量提升。

Abstract: Online advertising systems typically use a cascaded architecture to manage
massive requests and candidate volumes, where the ranking stages allocate
traffic based on eCPM (predicted CTR $\times$ Bid). With the increasing
popularity of auto-bidding strategies, the inconsistency between the
computationally sensitive retrieval stage and the ranking stages becomes more
pronounced, as the former cannot access precise, real-time bids for the vast ad
corpus. This discrepancy leads to sub-optimal platform revenue and advertiser
outcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a
model-based retrieval framework that addresses multi-stage inconsistency by
incorporating ad bid value into the retrieval scoring function. The core
innovation is Bidding-Aware Modeling, incorporating bid signals through
monotonicity-constrained learning and multi-task distillation to ensure
economically coherent representations, while Asynchronous Near-Line Inference
enables real-time updates to the embedding for market responsiveness.
Furthermore, the Task-Attentive Refinement module selectively enhances feature
interactions to disentangle user interest and commercial value signals.
Extensive offline experiments and full-scale deployment across Alibaba's
display advertising platform validated BAR's efficacy: 4.32% platform revenue
increase with 22.2% impression lift for positively-operated advertisements.

</details>


### [225] [DFW: A Novel Weighting Scheme for Covariate Balancing and Treatment Effect Estimation](https://arxiv.org/abs/2508.05215)
*Ahmad Saeed Khan,Erik Schaffernicht,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: DFW是一种新方法，通过使用去混淆因子来稳定倾向得分估计，从而更好地解决选择偏差问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的倾向得分加权方法（如IPW）在处理选择偏差方面存在局限性，因为其有效性依赖于观测数据和倾向得分估计器的准确性，高方差的倾向得分可能导致权重不稳定，影响选择偏差的处理和处理效应估计。

Method: DFW是一种新颖的基于倾向得分的加权方法，它利用去混淆因子来构建稳定有效的样本权重，优先考虑混淆程度较低的样本，同时减轻了混淆程度高的样本的影响，从而生成更接近RCT的伪总体。

Result: DFW方法保证了权重的有界性、较低的方差以及改善的协变量平衡。实验结果表明，DFW在真实世界基准数据集和合成数据集上均优于IPW和CBPS等现有方法。

Conclusion: DFW方法通过引入去混淆因子，能够生成更稳定、更有效的样本权重，从而更好地模拟随机对照试验（RCT），在协变量平衡和处理效应估计方面优于现有的IPW和CBPS等方法。

Abstract: Estimating causal effects from observational data is challenging due to
selection bias, which leads to imbalanced covariate distributions across
treatment groups. Propensity score-based weighting methods are widely used to
address this issue by reweighting samples to simulate a randomized controlled
trial (RCT). However, the effectiveness of these methods heavily depends on the
observed data and the accuracy of the propensity score estimator. For example,
inverse propensity weighting (IPW) assigns weights based on the inverse of the
propensity score, which can lead to instable weights when propensity scores
have high variance-either due to data or model misspecification-ultimately
degrading the ability of handling selection bias and treatment effect
estimation. To overcome these limitations, we propose Deconfounding Factor
Weighting (DFW), a novel propensity score-based approach that leverages the
deconfounding factor-to construct stable and effective sample weights. DFW
prioritizes less confounded samples while mitigating the influence of highly
confounded ones, producing a pseudopopulation that better approximates a RCT.
Our approach ensures bounded weights, lower variance, and improved covariate
balance.While DFW is formulated for binary treatments, it naturally extends to
multi-treatment settings, as the deconfounding factor is computed based on the
estimated probability of the treatment actually received by each sample.
Through extensive experiments on real-world benchmark and synthetic datasets,
we demonstrate that DFW outperforms existing methods, including IPW and CBPS,
in both covariate balancing and treatment effect estimation.

</details>


### [226] [ML-based Short Physical Performance Battery future score prediction based on questionnaire data](https://arxiv.org/abs/2508.05222)
*Marcin Kolakowski,Seif Ben Bader*

Main category: cs.LG

TL;DR: 本研究使用机器学习模型（特别是XGBoost）通过问卷数据预测老年人四年后的身体机能（SPPB分数），结果显示该方法具有一定的预测能力。


<details>
  <summary>Details</summary>
Motivation: 为了有效延缓老年人身体机能的下降，需要在出现早期症状时及时进行干预。本研究旨在分析通过问卷数据预测四年后SPPB分数的可能性。

Method: 利用随机森林、XGBoost、线性回归、密集和TabNet神经网络等机器学习算法，基于问卷数据预测四年后的SPPB分数。

Result: XGBoost模型取得了最佳结果，平均绝对误差为0.79分。在对Shapley值进行分析后，选取了10到20个特征子集，重新训练XGBoost回归器，平均绝对误差为0.82。

Conclusion: 通过基于问卷的机器学习模型，可以预测四年后短体育表现电池（SPPB）的分数，其中XGBoost模型表现最佳。

Abstract: Effective slowing down of older adults\' physical capacity deterioration
requires intervention as soon as the first symptoms surface. In this paper, we
analyze the possibility of predicting the Short Physical Performance Battery
(SPPB) score at a four-year horizon based on questionnaire data. The ML
algorithms tested included Random Forest, XGBoost, Linear Regression, dense and
TabNet neural networks. The best results were achieved for the XGBoost (mean
absolute error of 0.79 points). Based on the Shapley values analysis, we
selected smaller subsets of features (from 10 to 20) and retrained the XGBoost
regressor, achieving a mean absolute error of 0.82.

</details>


### [227] [Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning](https://arxiv.org/abs/2508.05224)
*Mirko Konstantin,Anirban Mukhopadhyay*

Main category: cs.LG

TL;DR: A new decentralized P2P federated learning method called LIGHTYEAR improves personalization and robustness by allowing clients to select and aggregate trusted model updates using an agreement score, outperforming existing methods especially in challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: Traditional centralized FL suffers from a single point of failure, limited personalization, and poor robustness to distribution shifts or malfunctioning clients. Update selection in centralized FL can be unreliable with non-IID data and offers clients little control.

Method: LIGHTYEAR leverages a P2P topology where each client identifies and aggregates a personalized set of trustworthy and beneficial updates. A key component is an agreement score, computed on a local validation set, which quantifies the semantic alignment of incoming updates in the function space with respect to the client's reference model. This score facilitates tailored update selection, and aggregation is performed with a regularization term for training stabilization.

Result: Empirical evaluation on two datasets demonstrates that LIGHTYEAR consistently outperforms both centralized baselines and existing P2P methods in client-level performance, particularly under adversarial and heterogeneous conditions.

Conclusion: The proposed decentralized, peer-to-peer (P2P) FL framework, LIGHTYEAR, consistently outperforms centralized baselines and existing P2P methods in terms of client-level performance, especially under adversarial and heterogeneous conditions, by enabling personalized aggregation of trustworthy updates.

Abstract: Federated learning (FL) enables collaborative model training across
distributed clients while preserving data privacy by keeping data local.
Traditional FL approaches rely on a centralized, star-shaped topology, where a
central server aggregates model updates from clients. However, this
architecture introduces several limitations, including a single point of
failure, limited personalization, and poor robustness to distribution shifts or
vulnerability to malfunctioning clients. Moreover, update selection in
centralized FL often relies on low-level parameter differences, which can be
unreliable when client data is not independent and identically distributed, and
offer clients little control. In this work, we propose a decentralized,
peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P
topology to enable each client to identify and aggregate a personalized set of
trustworthy and beneficial updates.This framework is the Local Inference Guided
Aggregation for Heterogeneous Training Environments to Yield Enhancement
Through Agreement and Regularization (LIGHTYEAR). Central to our method is an
agreement score, computed on a local validation set, which quantifies the
semantic alignment of incoming updates in the function space with respect to
the clients reference model. Each client uses this score to select a tailored
subset of updates and performs aggregation with a regularization term that
further stabilizes the training. Our empirical evaluation across two datasets
shows that the proposed approach consistently outperforms both centralized
baselines and existing P2P methods in terms of client-level performance,
particularly under adversarial and heterogeneous conditions.

</details>


### [228] [Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs](https://arxiv.org/abs/2508.05232)
*Feifan Xia,Mingyang Liao,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.LG

TL;DR: Cross-LoRA 是一种无需训练数据即可在不同大语言模型之间迁移 LoRA 模块的框架，通过子空间对齐和投影技术，在保持性能的同时，实现了高效的模型适配。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调 (PEFT) 方法（如 LoRA）与基础模型架构紧密耦合，限制了其在异构预训练大语言模型 (LLMs) 上的应用。为了解决这一限制，提出了一种数据无关的框架 Cross-LoRA，用于在不同基础模型之间迁移 LoRA 模块，且无需额外的训练数据。

Method: Cross-LoRA 框架包含两个关键组件：LoRA-Align 和 LoRA-Shift。LoRA-Align 利用秩截断奇异值分解 (SVD) 和 Frobenius 最优线性变换进行源模型和目标模型之间的子空间对齐，以处理维度不匹配问题。LoRA-Shift 则将对齐后的子空间应用于将源 LoRA 权重更新投影到目标模型参数空间。

Result: Cross-LoRA 实现了相对基线模型高达 5.26% 的性能提升。在其他常识推理基准测试中，Cross-LoRA 保持了与直接训练的 LoRA 适配器相当的性能。

Conclusion: Cross-LoRA 框架通过 LoRA-Align 和 LoRA-Shift 组件，实现了在不同基础模型之间迁移 LoRA 模块，而无需额外的训练数据。实验证明该方法在 ARC, OBOA 和 HellaSwag 等数据集上取得了显著的性能提升，并且在其他常识推理基准测试中表现与直接训练的 LoRA 适配器相当。

Abstract: Traditional parameter-efficient fine-tuning (PEFT) methods such as LoRA are
tightly coupled with the base model architecture, which constrains their
applicability across heterogeneous pretrained large language models (LLMs). To
address this limitation, we introduce Cross-LoRA, a data-free framework for
transferring LoRA modules between diverse base models without requiring
additional training data. Cross-LoRA consists of two key components: (a)
LoRA-Align, which performs subspace alignment between source and target base
models through rank-truncated singular value decomposition (SVD) and
Frobenius-optimal linear transformation, ensuring compatibility under dimension
mismatch; and (b) LoRA-Shift, which applies the aligned subspaces to project
source LoRA weight updates into the target model parameter space. Both
components are data-free, training-free, and enable lightweight adaptation on a
commodity GPU in 20 minutes. Experiments on ARCs, OBOA and HellaSwag show that
Cross-LoRA achieves relative gains of up to 5.26% over base models. Across
other commonsense reasoning benchmarks, Cross-LoRA maintains performance
comparable to that of directly trained LoRA adapters.

</details>


### [229] [MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs](https://arxiv.org/abs/2508.05257)
*Xiaodong Chen,Mingming Ha,Zhenzhong Lan,Jing Zhang,Jianguo Li*

Main category: cs.LG

TL;DR: 提出MoBE方法，通过分解和共享基矩阵来压缩MoE模型，能在大幅减小模型尺寸的同时，将准确率下降控制在极低水平。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型虽然性能强大且计算效率高，但在部署时存在巨大的内存需求。现有的压缩方法会导致显著的准确率下降。

Method: 提出了一种新颖的混合基专家（MoBE）方法，通过秩分解将专家中的矩阵分解为W=AB，其中A是专家独有的，B是共享的基矩阵的线性组合。通过最小化重建误差来学习这种分解。

Result: MoBE在模型压缩方面取得了显著成效，能够减少Qwen3-235B-A22B-2507、DeepSeek-V3-0324（671B）和Kimi-K2-Instruct（1T）等模型的参数量24%-30%，同时准确率仅下降1%-2%。这优于现有方法在同等压缩率下的表现。

Conclusion: MoBE通过秩分解和共享基矩阵的方法，在保持模型性能的同时显著减少了MoE模型的参数量，解决了现有MoE模型部署中的内存需求挑战。

Abstract: The Mixture-of-Experts (MoE) architecture has become a predominant paradigm
for scaling large language models (LLMs). Despite offering strong performance
and computational efficiency, large MoE-based LLMs like DeepSeek-V3-0324 and
Kimi-K2-Instruct present serious challenges due to substantial memory
requirements in deployment. While recent works have explored MoE compression to
address this issue, existing methods often suffer from considerable accuracy
drops (e.g., 7-14% relatively) even at modest compression rates. This paper
introduces a novel Mixture-of-Basis-Experts (MoBE) method that achieves model
compression while incurring minimal accuracy drops. Specifically, each up/gate
matrix in an expert is decomposed via a rank decomposition as W = AB, where
matrix A is unique to each expert. The relatively larger matrix B is further
re-parameterized as a linear combination of basis matrices {Bi} shared across
all experts within a given MoE layer. The factorization is learned by
minimizing the reconstruction error relative to the original weight matrices.
Experiments demonstrate that MoBE achieves notably lower accuracy drops
compared to prior works. For instance, MoBE can reduce the parameter counts of
Qwen3-235B-A22B-2507, DeepSeek-V3-0324 (671B) and Kimi-K2-Instruct (1T) by
24%-30% with only 1%-2% accuracy drop (about 2% drops when measured
relatively).

</details>


### [230] [Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models](https://arxiv.org/abs/2508.05260)
*Zhouyao Qian,Yang Chen,Baodian Li,Shuyi Zhang,Zhen Tian,Gongsen Wang,Tianyue Gu,Xinyu Zhou,Huilin Chen,Xinyi Li,Hao Zhu,Shuyao Zhang,Zongheng Li,Siyuan Wang*

Main category: cs.LG

TL;DR: A new LSTM-RF model combining time-series and nonlinear modeling improves marine chlorophyll prediction accuracy compared to standalone LSTM or RF models, using ocean data like temperature and salinity.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of marine chlorophyll concentration is crucial for ecosystem health assessment, carbon cycle strength understanding, red tide warning, and ecological response. Existing single models have deficiencies in time-series modeling and nonlinear feature portrayal.

Method: A hybrid LSTM-RF model was developed by combining the advantages of LSTM for time-series modeling and RF for nonlinear feature portrayal. The model was trained with multi-source ocean data including temperature, salinity, and dissolved oxygen, and utilized standardized treatment and a sliding window approach to improve prediction accuracy.

Result: The LSTM-RF model achieved an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test set. These results are significantly better than those obtained using LSTM alone (R^2 = 0.0208) and RF alone (R^2 = 0.4934).

Conclusion: The proposed LSTM-RF hybrid model significantly outperforms LSTM and RF alone in predicting marine chlorophyll concentration, achieving better accuracy and providing an innovative solution for high-frequency prediction of marine ecological variables.

Abstract: Marine chlorophyll concentration is an important indicator of ecosystem
health and carbon cycle strength, and its accurate prediction is crucial for
red tide warning and ecological response. In this paper, we propose a LSTM-RF
hybrid model that combines the advantages of LSTM and RF, which solves the
deficiencies of a single model in time-series modelling and nonlinear feature
portrayal. Trained with multi-source ocean data(temperature, salinity,
dissolved oxygen, etc.), the experimental results show that the LSTM-RF model
has an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test
set, which is significantly better than using LSTM (R^2 = 0.0208) and RF (R^2
=0.4934) alone , respectively. The standardised treatment and sliding window
approach improved the prediction accuracy of the model and provided an
innovative solution for high-frequency prediction of marine ecological
variables.

</details>


### [231] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 介绍了一种名为 Fairy±i 的新方法，用于训练 2 位复值大语言模型。该方法通过提升全精度模型性能并利用复数域的表示优势，实现了 2 位量化，并在不牺牲效率的情况下超越了现有方法的性能上限。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）方法都侧重于最小化全精度模型的量化误差，并将全精度精度视为精度上限。本研究旨在打破这一上限，探索超越现有方法性能的可能性。

Method: 提出了一种名为 Fairy±i 的新范式，通过提升全精度模型的精度上限，然后进行高效的 2 位量化。具体而言，该方法利用复数域的表示优势来提高全精度精度，并将权重映射到单位的四次方根 {±1, ±i}，形成完美的对称和信息论最优的 2 位表示。关键在于，每个量化权重只有一个实部或虚部为零，从而可以通过加法和元素交换实现无乘法的推理。

Result: 实验结果表明，Fairy±i 在困惑度（PPL）和下游任务方面均优于现有 2 位量化方法的精度上限，同时保持了严格的存储和计算效率。

Conclusion: Fairy±i 是首个用于复值大语言模型的 2 位量化框架，其性能超越了现有 2 位量化方法的精度上限，并在存储和计算效率方面表现出色，为构建高精度、低比特率的大语言模型开辟了新方向。

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [232] [FlowState: Sampling Rate Invariant Time Series Forecasting](https://arxiv.org/abs/2508.05287)
*Lars Graf,Thomas Ortner,Stanisław Woźniak,Angeliki Pantazi*

Main category: cs.LG

TL;DR: FlowState 是一种新颖的时间序列基础模型（TSFM），通过 SSM 编码器和函数基解码器解决了现有 TSFM 在泛化、适应性和效率方面的问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型（TSFM）在泛化能力、适应性（不同采样率）和计算效率方面存在不足。

Method: FlowState 采用基于状态空间模型（SSM）的编码器和基于函数基的解码器，实现了连续时间建模和动态时间尺度调整，从而能够跨所有可能的时间分辨率进行泛化并动态调整预测范围。此外，还提出了一种有效的预训练策略以提高鲁棒性并加速训练。

Result: FlowState 即使模型最小，也能超越其他模型，并在 GIFT-ZS 和 Chronos-ZS 基准测试中取得最先进的性能。消融研究证实了其组件的有效性。

Conclusion: FlowState 在 GIFT-ZS 和 Chronos-ZS 基准测试中表现优于所有其他模型，达到了最先进水平。它还具有在线适应不同输入采样率的独特能力。

Abstract: Foundation models (FMs) have transformed natural language processing, but
their success has not yet translated to time series forecasting. Existing time
series foundation models (TSFMs), often based on transformer variants, struggle
with generalization across varying context and target lengths, lack
adaptability to different sampling rates, and are computationally inefficient.
We introduce FlowState, a novel TSFM architecture that addresses these
challenges through two key innovations: a state space model (SSM) based encoder
and a functional basis decoder. This design enables continuous-time modeling
and dynamic time-scale adjustment, allowing FlowState to inherently generalize
across all possible temporal resolutions, and dynamically adjust the
forecasting horizons. In contrast to other state-of-the-art TSFMs, which
require training data across all possible sampling rates to memorize patterns
at each scale, FlowState inherently adapts its internal dynamics to the input
scale, enabling smaller models, reduced data requirements, and improved
efficiency. We further propose an efficient pretraining strategy that improves
robustness and accelerates training. Despite being the smallest model,
FlowState outperforms all other models and is state-of-the-art for the GIFT-ZS
and the Chronos-ZS benchmarks. Ablation studies confirm the effectiveness of
its components, and we demonstrate its unique ability to adapt online to
varying input sampling rates.

</details>


### [233] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: LLMs show potential in generating computable phenotypes for clinical decision support, achieving good performance with fewer training examples through an iterative refinement strategy.


<details>
  <summary>Details</summary>
Motivation: Investigate whether LLMs can generate accurate and concise computable phenotypes (CPs) for six clinical phenotypes of varying complexity, which could be leveraged to enable scalable clinical decision support to improve care for patients with hypertension.

Method: We propose and test a synthesize, execute, debug, instruct strategy that uses LLMs to generate and iteratively refine CPs using data-driven feedback.

Result: LLMs, coupled with iterative learning, can generate interpretable and reasonably accurate programs that approach the performance of state-of-the-art ML methods while requiring significantly fewer training examples.

Conclusion: LLMs coupled with iterative learning can generate interpretable and reasonably accurate programs that approach the performance of state-of-the-art ML methods while requiring significantly fewer training examples.

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


### [234] [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](https://arxiv.org/abs/2508.05289)
*Zhongheng Yang,Aijia Sun,Yushang Zhao,Yinuo Yang,Dannier Li,Chengrui Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种利用 RLHF 和 PPO 的方法，通过最大化隐含用户反馈来改进基于 LLM 的对话推荐系统，并在评估中显示出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的监督微调无法捕捉隐式反馈信号，例如停留时间、情感极性或参与模式，而这些信号对于对话推荐系统（CRS）至关重要。

Method: 我们提出了一种使用人类反馈强化学习（RLHF）进行微调的解决方案，以最大化多轮推荐上下文中的隐含用户反馈（IUF）。我们通过近端策略优化（PPO）方法来优化基础 LLM M_{	heta}，并学习一个在弱标记的参与信息上学习到的奖励模型 $R_{\phi}$ 来最大化用户中心效用。该架构模拟了对话状态转换 $s_t \to a_t \to s_{t +1}$，其中动作 $a_t$ 仅在过去对话历史的条件下与 LLM 生成的项目建议相关联。

Result: 与（arrow-zero-cmwrquca-teja-falset ensuite 2Round group-deca States penalty give up）相比，我们在合成和真实世界数据集（例如 REDIAL、OpenDialKG）上的评估表明，我们的 RLHF 微调模型在推荐准确性、连贯性和用户满意度方面表现更好。

Conclusion: 隐式信号对齐在实现 CRS 的可扩展和用户自适应设计方面是有效的。

Abstract: Conversational recommender systems (CRS) based on Large Language Models
(LLMs) need to constantly be aligned to the user preferences to provide
satisfying and context-relevant item recommendations. The traditional
supervised fine-tuning cannot capture the implicit feedback signal, e.g., dwell
time, sentiment polarity, or engagement patterns. In this paper, we share a
fine-tuning solution using human feedback reinforcement learning (RLHF) to
maximize implied user feedback (IUF) in a multi-turn recommendation context. We
specify a reward model $R_{\phi}$ learnt on weakly-labelled engagement
information and maximize user-centric utility by optimizing the foundational
LLM M_{\theta} through a proximal policy optimization (PPO) approach. The
architecture models conversational state transitions $s_t \to a_t \to s_{t
+1}$, where the action $a_t$ is associated with LLM-generated item suggestions
only on condition of conversation history in the past. The evaluation across
synthetic and real-world datasets (e.g.REDIAL, OpenDialKG) demonstrates that
our RLHF-fine-tuned models can perform better in terms of top-$k$
recommendation accuracy, coherence, and user satisfaction compared to
(arrow-zero-cmwrquca-teja-falset ensuite 2Round group-deca States penalty give
up This paper shows that implicit signal alignment can be efficient in
achieving scalable and user-adaptive design of CRS.

</details>


### [235] [Optimal Growth Schedules for Batch Size and Learning Rate in SGD that Reduce SFO Complexity](https://arxiv.org/abs/2508.05297)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: Deep learning training is slow. We found a way to speed it up by smartly increasing batch size and learning rate during training, making it more efficient without hurting performance. This helps train big models faster.


<details>
  <summary>Details</summary>
Motivation: The motivation for this research stems from the computational bottlenecks introduced by the growth of deep learning models. The study aims to address how batch size and learning rate should be increased during training to balance efficiency and convergence, inspired by recent theoretical insights.

Method: The paper analyzes the problem of batch-size and learning-rate scheduling in deep learning training using stochastic first-order oracle (SFO) complexity. It theoretically derives optimal growth schedules for these hyperparameters and validates them through experiments.

Result: The research theoretically derived optimal growth schedules for batch size and learning rate, which reduce SFO complexity. These findings were validated through extensive experiments, offering practical guidelines for scalable and efficient large-batch training.

Conclusion: The study provides theoretical insights and practical guidelines for efficient large-batch training in deep learning by deriving optimal growth schedules for batch size and learning rate, reducing SFO complexity and improving optimization.

Abstract: The unprecedented growth of deep learning models has enabled remarkable
advances but introduced substantial computational bottlenecks. A key factor
contributing to training efficiency is batch-size and learning-rate scheduling
in stochastic gradient methods. However, naive scheduling of these
hyperparameters can degrade optimization efficiency and compromise
generalization. Motivated by recent theoretical insights, we investigated how
the batch size and learning rate should be increased during training to balance
efficiency and convergence. We analyzed this problem on the basis of stochastic
first-order oracle (SFO) complexity, defined as the expected number of gradient
evaluations needed to reach an $\epsilon$-approximate stationary point of the
empirical loss. We theoretically derived optimal growth schedules for the batch
size and learning rate that reduce SFO complexity and validated them through
extensive experiments. Our results offer both theoretical insights and
practical guidelines for scalable and efficient large-batch training in deep
learning.

</details>


### [236] [Adaptive Batch Size and Learning Rate Scheduler for Stochastic Gradient Descent Based on Minimization of Stochastic First-order Oracle Complexity](https://arxiv.org/abs/2508.05302)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 这篇论文提出了一种加速 SGD 的自适应调度策略，通过调整批处理大小和学习率来提高收敛速度。


<details>
  <summary>Details</summary>
Motivation: Mini-batch SGD 的收敛行为对批处理大小和学习率非常敏感。理论研究发现了一个临界批处理大小，可以最小化 SFO 复杂性。

Method: 提出了一种自适应调度策略，该策略利用临界批处理大小的理论发现，并根据训练过程中观察到的满梯度范数衰减来调整批处理大小和学习率。

Result: 实验证明，所提出的自适应联合调度策略比现有的调度器具有更快的收敛速度。 Mini-batch SGD 的收敛行为对批处理大小和学习率非常敏感。理论研究发现了一个临界批处理大小，可以最小化 SFO 复杂性。

Conclusion: 该研究提出了一种自适应联合调度策略，通过调整批处理大小和学习率来加速 SGD，并已通过实验证明其优于现有调度器。

Abstract: The convergence behavior of mini-batch stochastic gradient descent (SGD) is
highly sensitive to the batch size and learning rate settings. Recent
theoretical studies have identified the existence of a critical batch size that
minimizes stochastic first-order oracle (SFO) complexity, defined as the
expected number of gradient evaluations required to reach a stationary point of
the empirical loss function in a deep neural network. An adaptive scheduling
strategy is introduced to accelerate SGD that leverages theoretical findings on
the critical batch size. The batch size and learning rate are adjusted on the
basis of the observed decay in the full gradient norm during training.
Experiments using an adaptive joint scheduler based on this strategy
demonstrated improved convergence speed compared with that of existing
schedulers.

</details>


### [237] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: USP is a divide-and-conquer framework designed to synergistically enhance feature space reservation (FSR) for learning plasticity (LP), divide-and-conquer pseudo-labeling (DCP) for unlabeled learning (UL), and class-mean-anchored unlabeled distillation (CUD) for memory stability (MS) in semi-supervised continual learning (SSCL).


<details>
  <summary>Details</summary>
Motivation: SSCL introduces complex challenges, including ensuring effective unlabeled learning (UL), while balancing memory stability (MS) and learning plasticity (LP). Previous SSCL efforts have typically focused on isolated aspects of the three.

Method: (1) Feature Space Reservation (FSR) strategy for LP, which constructs reserved feature locations for future classes by shaping old classes into an equiangular tight frame; (2) Divide-and-Conquer Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels across both high- and low-confidence unlabeled data; and (3) Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's outputs to anchor unlabeled data to stable class means for distillation to prevent forgetting.

Result: Comprehensive evaluations show USP outperforms prior SSCL methods, with gains up to 5.94% in the last accuracy, validating its effectiveness.

Conclusion: USP outperformed prior SSCL methods, with gains up to 5.94% in the last accuracy, validating its effectiveness.

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [238] [Optimal Corpus Aware Training for Neural Machine Translation](https://arxiv.org/abs/2508.05364)
*Yi-Hsiu Liao,Cheng Shen,Brenda,Yang*

Main category: cs.LG

TL;DR: OCAT通过优化微调过程，提高了模型在翻译任务上的准确性，同时保持了轻量级和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的CAT方法需要预先定义高质量数据，容易出错且效率低下。

Method: 提出了一种名为Optimal Corpus Aware Training (OCAT)的方法，对预训练的CAT模型进行微调，仅调整少量语料库相关参数，冻结大部分模型参数。

Result: +3.6 and +1.8 chrF improvement on WMT23 English to Chinese and English to German translation tasks, and is on-par or slightly better than other state-of-the-art fine-tuning techniques while being less sensitive to hyperparameter settings.

Conclusion: OCAT通过冻结大部分模型参数并仅调整一小组语料库相关参数，可以微调预训练的CAT模型，从而实现轻量级、抗过拟合和提高模型准确性。

Abstract: Corpus Aware Training (CAT) leverages valuable corpus metadata during
training by injecting corpus information into each training example, and has
been found effective in the literature, commonly known as the "tagging"
approach. Models trained with CAT inherently learn the quality, domain and
nuance between corpora directly from data, and can easily switch to different
inference behavior. To achieve the best evaluation, CAT models pre-define a
group of high quality data before training starts which can be error-prone and
inefficient. In this work, we propose Optimal Corpus Aware Training (OCAT),
which fine-tunes a CAT pre-trained model by freezing most of the model
parameters and only tuning small set of corpus-related parameters. We show that
OCAT is lightweight, resilient to overfitting, and effective in boosting model
accuracy. We use WMT23 English to Chinese and English to German translation
tasks as our test ground and show +3.6 and +1.8 chrF improvement, respectively,
over vanilla training. Furthermore, our approach is on-par or slightly better
than other state-of-the-art fine-tuning techniques while being less sensitive
to hyperparameter settings.

</details>


### [239] [Latent Preference Bandits](https://arxiv.org/abs/2508.05367)
*Newton Mwai,Emil Carlsson,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 潜在赌徒在个性化任务中可以减少探索时间，但需要知道潜在状态和奖励的联合分布，这在实践中很难找到。本研究提出了一种放宽潜在赌徒假设的方法，仅需要动作的偏好排序模型，并提供了一种后验采样算法，在奖励尺度存在差异时性能更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决在个性化任务中，单个个体仅面临少量决策点时，从头开始学习通常成本过高的问题。现有的潜在赌徒模型需要知道潜在状态和动作奖励的联合分布，但这在实践中难以找到，并且可能不存在能够解释所有个体响应的少量潜在状态。

Method: 提出了一种放宽潜在赌徒的假设，仅要求每个潜在状态中动作的偏好排序模型。

Result: 与具有奖励分布完全知识的潜在对手相比，经验性能具有竞争力，并且当奖励尺度在具有相同潜在状态的实例之间存在差异时，其性能优于它们。

Conclusion: 该模型允许具有相同潜在状态的问题实例在奖励分布不同但动作偏好排序相同的情况下进行变化。我们提供了一个用于此问题的后验采样算法，并证明了当奖励分布指定良好时，其经验性能与具有奖励分布完全知识的潜在对手相当，并且在奖励尺度在具有相同潜在状态的实例之间存在差异时，其性能优于它们。

Abstract: Bandit algorithms are guaranteed to solve diverse sequential decision-making
problems, provided that a sufficient exploration budget is available. However,
learning from scratch is often too costly for personalization tasks where a
single individual faces only a small number of decision points. Latent bandits
offer substantially reduced exploration times for such problems, given that the
joint distribution of a latent state and the rewards of actions is known and
accurate. In practice, finding such a model is non-trivial, and there may not
exist a small number of latent states that explain the responses of all
individuals. For example, patients with similar latent conditions may have the
same preference in treatments but rate their symptoms on different scales. With
this in mind, we propose relaxing the assumptions of latent bandits to require
only a model of the \emph{preference ordering} of actions in each latent state.
This allows problem instances with the same latent state to vary in their
reward distributions, as long as their preference orderings are equal. We give
a posterior-sampling algorithm for this problem and demonstrate that its
empirical performance is competitive with latent bandits that have full
knowledge of the reward distribution when this is well-specified, and
outperforms them when reward scales differ between instances with the same
latent state.

</details>


### [240] [Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms](https://arxiv.org/abs/2508.05387)
*Jie Xiao,Shaoduo Gan,Changyuan Fan,Qingnan Ren,Alfred Long,Yuchen Zhang,Rymon Yu,Eric Yang,Lynn Ai*

Main category: cs.LG

TL;DR: Echo是一个RL系统，它将LLM的轨迹采样和策略优化分离到不同的硬件集群上，解决了现有方法的串行上下文切换问题，并在异构资源上实现了数据中心级别的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于强化学习的LLM后训练方法将轨迹采样和策略优化放置在同一GPU集群上，导致系统在推理和训练工作负载之间进行串行上下文切换，违反了分布式训练系统的单程序多数据（SPMD）假设的问题。

Method: Echo系统通过引入两种轻量级同步协议，将轨迹采样和策略优化分离到不同的异构硬件集群上，以解决现有方法中推理和训练工作负载串行切换的问题。该系统包括顺序拉取模式和异步推拉模式。

Result: 在Qwen3-4B、Qwen2.5-7B和Qwen3-32B上训练三个代表性的RL工作负载，Echo系统在收敛速度和最终奖励方面与完全共置的Verl基线相当，同时将轨迹生成卸载到商品边缘硬件。

Conclusion: Echo系统能够将大规模强化学习（RL）应用于大型语言模型（LLM），并利用去中心化、异构的资源实现数据中心级别的性能。

Abstract: Modern RL-based post-training for large language models (LLMs) co-locate
trajectory sampling and policy optimisation on the same GPU cluster, forcing
the system to switch between inference and training workloads. This serial
context switching violates the single-program-multiple-data (SPMD) assumption
underlying today's distributed training systems. We present Echo, the RL system
that cleanly decouples these two phases across heterogeneous "inference" and
"training" swarms while preserving statistical efficiency. Echo introduces two
lightweight synchronization protocols: a sequential pull mode that refreshes
sampler weights on every API call for minimal bias, and an asynchronous
push-pull mode that streams version-tagged rollouts through a replay buffer to
maximise hardware utilisation. Training three representative RL workloads with
Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster,
Echo matches a fully co-located Verl baseline in convergence speed and final
reward while off-loading trajectory generation to commodity edge hardware.
These promising results demonstrate that large-scale RL for LLMs could achieve
datacentre-grade performance using decentralised, heterogeneous resources.

</details>


### [241] [NT-ML: Backdoor Defense via Non-target Label Training and Mutual Learning](https://arxiv.org/abs/2508.05404)
*Wenjie Huo,Katinka Wolter*

Main category: cs.LG

TL;DR: NT-ML is a novel defense mechanism against backdoor attacks on DNNs. It involves retraining a model with standard training outputs to create a teacher and student model, which then learn from each other to purify the student model. Experiments show NT-ML is effective against 6 backdoor attacks using few clean samples and surpasses 5 existing defenses.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks (DNNs) are vulnerable to backdoor attacks, where a designed trigger is injected into the dataset, causing erroneous predictions when activated.

Method: NT aims to reduce the harm of poisoned data by retraining the model with the outputs of the standard training. A teacher model with high accuracy on clean data and a student model with higher confidence in correct prediction on poisoned data are obtained. Then, the teacher and student can learn the strengths from each other through ML to obtain a purified student model.

Result: NT-ML can effectively defend against 6 backdoor attacks with a small number of clean samples, and outperforms 5 state-of-the-art backdoor defenses.

Conclusion: NT-ML can effectively defend against 6 backdoor attacks with a small number of clean samples, and outperforms 5 state-of-the-art backdoor defenses.

Abstract: Recent studies have shown that deep neural networks (DNNs) are vulnerable to
backdoor attacks, where a designed trigger is injected into the dataset,
causing erroneous predictions when activated. In this paper, we propose a novel
defense mechanism, Non-target label Training and Mutual Learning (NT-ML), which
can successfully restore the poisoned model under advanced backdoor attacks. NT
aims to reduce the harm of poisoned data by retraining the model with the
outputs of the standard training. At this stage, a teacher model with high
accuracy on clean data and a student model with higher confidence in correct
prediction on poisoned data are obtained. Then, the teacher and student can
learn the strengths from each other through ML to obtain a purified student
model. Extensive experiments show that NT-ML can effectively defend against 6
backdoor attacks with a small number of clean samples, and outperforms 5
state-of-the-art backdoor defenses.

</details>


### [242] [Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam](https://arxiv.org/abs/2508.05408)
*Asma Atamna,Tom Maus,Fabian Kievelitz,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 在深度学习中，学习率是一个关键超参数。本文研究了自适应学习率机制，特别是基于累积路径的方法。研究发现，Adam优化器的原始累积路径方法存在概念不一致性，并提出了一个修正版本。通过对SGD和Adam进行基准测试，旨在阐明自适应策略何时何地提供实际优势。


<details>
  <summary>Details</summary>
Motivation: 探索自适应学习率机制的实际效用，以及在训练过程中动态调整步长以响应损失景观。

Method: 通过基准测试SGD和Adam（包括累积自适应的SGD和Adam以及不含累积自适应的SGD和Adam）并与一种近期提出的替代方法进行比较，来评估在线学习率调整的实际价值。

Result: 研究发现，Adam优化器最初的累积自适应方法在概念上存在不一致性，并提出了一个修正版本以更好地匹配Adam的更新动态。

Conclusion: 该研究旨在阐明在线学习率调整策略在何时以及为何能提供实际优势，并提出了一种修正后的累积自适应方法，该方法与Adam优化器的更新动态更为一致。

Abstract: The learning rate is a crucial hyperparameter in deep learning, with its
ideal value depending on the problem and potentially changing during training.
In this paper, we investigate the practical utility of adaptive learning rate
mechanisms that adjust step sizes dynamically in response to the loss
landscape. We revisit a cumulative path-based adaptation scheme proposed in
2017, which adjusts the learning rate based on the discrepancy between the
observed path length, computed as a time-discounted sum of normalized gradient
steps, and the expected length of a random walk. While the original approach
offers a compelling intuition, we show that its adaptation mechanism for Adam
is conceptually inconsistent due to the optimizer's internal preconditioning.
We propose a corrected variant that better reflects Adam's update dynamics. To
assess the practical value of online learning rate adaptation, we benchmark SGD
and Adam, with and without cumulative adaptation, and compare them to a recent
alternative method. Our results aim to clarify when and why such adaptive
strategies offer practical benefits.

</details>


### [243] [MolSnap: Snap-Fast Molecular Generation with Latent Variational Mean Flow](https://arxiv.org/abs/2508.05411)
*Md Atik Ahamed,Qiang Ye,Qiang Cheng*

Main category: cs.LG

TL;DR: 本文提出了一种结合因果感知Transformer（CAT）和变分平均流（VMF）的分子生成框架，提高了生成质量、多样性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有分子生成方法在同时保证高质量、多样化生成和快速推理方面存在挑战。

Method: 本文提出了一种新颖的因果感知框架，包含两个关键创新：1. 因果感知Transformer（CAT），能够联合编码分子图标记和文本指令，并在生成过程中强制执行因果依赖。2. 变分平均流（VMF）框架，通过将潜在空间建模为高斯混合，泛化了现有基于流的方法，提高了表达能力，实现了高效的一步推理。

Result: 实验结果表明，所提出的模型在所有数据集上均实现了100%的有效性，新颖性和多样性分别达到了74.5%和70.3%，同时计算效率远高于基于扩散的方法，条件生成仅需一次函数评估（NFE），非条件生成最多需要五次。

Conclusion: 提出的因果感知框架通过因果感知Transformer（CAT）和变分平均流（VMF）模型，能够同时保证生成的高质量、多样性和推理速度，在四个标准的分子基准测试中，超越了最先进的方法，实现了更高的新颖性（高达74.5%）、多样性（高达70.3%）和100%的有效性。

Abstract: Molecular generation conditioned on textual descriptions is a fundamental
task in computational chemistry and drug discovery. Existing methods often
struggle to simultaneously ensure high-quality, diverse generation and fast
inference. In this work, we propose a novel causality-aware framework that
addresses these challenges through two key innovations. First, we introduce a
Causality-Aware Transformer (CAT) that jointly encodes molecular graph tokens
and text instructions while enforcing causal dependencies during generation.
Second, we develop a Variational Mean Flow (VMF) framework that generalizes
existing flow-based methods by modeling the latent space as a mixture of
Gaussians, enhancing expressiveness beyond unimodal priors. VMF enables
efficient one-step inference while maintaining strong generation quality and
diversity. Extensive experiments on four standard molecular benchmarks
demonstrate that our model outperforms state-of-the-art baselines, achieving
higher novelty (up to 74.5\%), diversity (up to 70.3\%), and 100\% validity
across all datasets. Moreover, VMF requires only one number of function
evaluation (NFE) during conditional generation and up to five NFEs for
unconditional generation, offering substantial computational efficiency over
diffusion-based methods.

</details>


### [244] [Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling](https://arxiv.org/abs/2508.05423)
*Yixuan Zhang,Wenxin Zhang,Hua Jiang,Quyu Kong,Feng Zhou*

Main category: cs.LG

TL;DR: NegBio-VAE通过使用负二项分布来模拟神经元放电，解决了传统VAE在处理生物神经信号时的不准确性，并取得了更好的重构效果。


<details>
  <summary>Details</summary>
Motivation: 传统的VAE模型在模拟具有高度不规则性和变异性的生物神经元放电模式时存在局限性，而现有的泊松VAE模型由于均值和方差相等的限制，未能真实反映神经活动的随机性。

Method: 本文提出了一种名为NegBio-VAE的新型VAE框架，该框架使用负二项分布来模拟神经元放电次数，并提供了两种ELBO优化方案和两种可微分重参数化策略来处理负二项分布的特性。

Result: NegBio-VAE通过引入一个额外的离散度参数，将泊松潜在模型推广到负二项分布模型，在重构保真度方面取得了显著的提升，证明了在模拟脉冲状激活时显式建模过度离散化的重要性。NegBio-VAE能够更准确地表示神经活动，并且在经验结果中显示出优于现有模型的性能。

Conclusion: NegBio-VAE通过使用负二项分布对神经元放电次数进行建模，并引入额外的离散度参数，成功地克服了传统VAE在模拟神经脉冲方面的局限性，实现了对神经活动更准确的表示。

Abstract: Biological neurons communicate through spike trains, discrete, irregular
bursts of activity that exhibit variability far beyond the modeling capacity of
conventional variational autoencoders (VAEs). Recent work, such as the
Poisson-VAE, makes a biologically inspired move by modeling spike counts using
the Poisson distribution. However, they impose a rigid constraint: equal mean
and variance, which fails to reflect the true stochastic nature of neural
activity. In this work, we challenge this constraint and introduce NegBio-VAE,
a principled extension of the VAE framework that models spike counts using the
negative binomial distribution. This shift grants explicit control over
dispersion, unlocking a broader and more accurate family of neural
representations. We further develop two ELBO optimization schemes and two
differentiable reparameterization strategies tailored to the negative binomial
setting. By introducing one additional dispersion parameter, NegBio-VAE
generalizes the Poisson latent model to a negative binomial formulation.
Empirical results demonstrate this minor yet impactful change leads to
significant gains in reconstruction fidelity, highlighting the importance of
explicitly modeling overdispersion in spike-like activations.

</details>


### [245] [Federated Multi-Objective Learning with Controlled Pareto Frontiers](https://arxiv.org/abs/2508.05424)
*Jiansheng Rao,Jiayi Li,Zhizhi Gong,Soummya Kar,Haoxuan Li*

Main category: cs.LG

TL;DR: CR-FMOL introduces a novel preference-cone constraint to federated multi-objective learning, enforcing client-wise Pareto optimality and enhancing client fairness. While initially slightly underperforming FedAvg, it is expected to reach comparable accuracy with more training.


<details>
  <summary>Details</summary>
Motivation: Existing methods such as federated multi-objective learning (FMOL) attempts to import multi-objective optimisation (MOO) into FL. However, it merely delivers task-wise Pareto-stationary points, leaving client fairness to chance.

Method: CR-FMOL framework with a novel preference-cone constraint. After local federated multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient descent averaging (FSMGDA) steps, each client transmits its aggregated task-loss vector as an implicit preference; the server then solves a cone-constrained Pareto-MTL sub-problem centred at the uniform vector, producing a descent direction that is Pareto-stationary for every client within its cone.

Result: Experiments on non-IID benchmarks show that CR-FMOL enhances client fairness, and although the early-stage performance is slightly inferior to FedAvg, it is expected to achieve comparable accuracy given sufficient training rounds.

Conclusion: CR-FMOL is the first federated MOO framework that enforces client-wise Pareto optimality through a novel preference-cone constraint. Experiments show that CR-FMOL enhances client fairness, and although the early-stage performance is slightly inferior to FedAvg, it is expected to achieve comparable accuracy given sufficient training rounds.

Abstract: Federated learning (FL) is a widely adopted paradigm for privacy-preserving
model training, but FedAvg optimise for the majority while under-serving
minority clients. Existing methods such as federated multi-objective learning
(FMOL) attempts to import multi-objective optimisation (MOO) into FL. However,
it merely delivers task-wise Pareto-stationary points, leaving client fairness
to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL),
the first federated MOO framework that enforces client-wise Pareto optimality
through a novel preference-cone constraint. After local federated
multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient
descent averaging (FSMGDA) steps, each client transmits its aggregated
task-loss vector as an implicit preference; the server then solves a
cone-constrained Pareto-MTL sub-problem centred at the uniform vector,
producing a descent direction that is Pareto-stationary for every client within
its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client
fairness, and although the early-stage performance is slightly inferior to
FedAvg, it is expected to achieve comparable accuracy given sufficient training
rounds.

</details>


### [246] [Group Causal Policy Optimization for Post-Training Large Language Models](https://arxiv.org/abs/2508.05428)
*Ziyin Gu,Jingyao Wang,Ran Zuo,Chuxiong Sun,Zeen Song,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: GCPO improves upon GRPO by incorporating causal structure to handle semantic interactions between candidate responses, leading to better performance on reasoning benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing methods like GRPO overlook semantic interactions among candidate responses. This paper introduces a Structural Causal Model (SCM) to reveal hidden dependencies among candidate responses and proposes GCPO to address this.

Method: GCPO integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution.

Result: Experimental evaluations demonstrate that GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.

Conclusion: GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.

Abstract: Recent advances in large language models (LLMs) have broadened their
applicability across diverse tasks, yet specialized domains still require
targeted post training. Among existing methods, Group Relative Policy
Optimization (GRPO) stands out for its efficiency, leveraging groupwise
relative rewards while avoiding costly value function learning. However, GRPO
treats candidate responses as independent, overlooking semantic interactions
such as complementarity and contradiction. To address this challenge, we first
introduce a Structural Causal Model (SCM) that reveals hidden dependencies
among candidate responses induced by conditioning on a final integrated output
forming a collider structure. Then, our causal analysis leads to two insights:
(1) projecting responses onto a causally informed subspace improves prediction
quality, and (2) this projection yields a better baseline than query only
conditioning. Building on these insights, we propose Group Causal Policy
Optimization (GCPO), which integrates causal structure into optimization
through two key components: a causally informed reward adjustment and a novel
KL regularization term that aligns the policy with a causally projected
reference distribution. Comprehensive experimental evaluations demonstrate that
GCPO consistently surpasses existing methods, including GRPO across multiple
reasoning benchmarks.

</details>


### [247] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 忽略竞争风险会导致生存分析中的偏差和不平等。本研究量化了这种误差，并强调了考虑竞争风险以提高准确性和公平性的重要性。


<details>
  <summary>Details</summary>
Motivation: 准确的时间事件预测对于医疗指南、招聘决策和资源分配等决策至关重要。生存分析是用于对时间事件数据进行建模的量化框架，但许多患者的事件会妨碍对感兴趣结果的观察。这些竞争风险通常被视为删失，但这种做法由于对其后果的理解有限而被忽视。

Method: 该研究通过理论论证和实证分析相结合的方式，首先形式化了将竞争风险错误分类为删失的问题，并量化了由此产生的生存估计误差。研究人员开发了一个框架来估计此误差，并展示了其对预测性能和算法公平性的影响。此外，还研究了不同人群的风险分布如何导致特定群体的特定误差，从而可能加剧现有的差异。最后，通过对心血管管理的实证分析来支持这些发现。

Result: 忽略竞争风险会导致生存估计出现偏差，系统性地高估风险，并加剧差异。研究结果表明，忽略竞争风险会不成比例地影响那些最有可能发生这些事件的个体，可能加剧不平等。

Conclusion: 忽略竞争风险（即将竞争事件视为删失）会导致生存估计出现显著偏差，从而系统性地高估风险并加剧现有差异。研究结果强调，必须考虑竞争风险以提高准确性、减少风险评估中的差异并更好地为下游决策提供信息。

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


### [248] [Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees](https://arxiv.org/abs/2508.05441)
*Zuyuan Zhang,Arnob Ghosh,Tian Lan*

Main category: cs.LG

TL;DR: 本文提出 CVaR-MCTS 和 W-MCTS 来解决 MCTS 中的尾部风险问题，并提供了理论保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决仅考虑预期回报的蒙特卡洛树搜索 (MCTS) 无法应对高风险、不利结果的潜在范围的问题，本文致力于为 MCTS 提供严格的尾部安全保证。

Method: 本文提出了两种新颖的解决方案：CVaR-MCTS，它将条件在风险 (CVaR) 这一连贯的尾部风险度量嵌入到 MCTS 中；以及 Wasserstein-MCTS (W-MCTS)，它通过引入一级 Wasserstein 模糊集来解决由于样本有限而导致的尾部风险估计偏差。

Result: CVaR-MCTS 和 W-MCTS 在各种模拟环境中进行了评估，结果表明它们能够有效实现鲁棒的尾部风险保证，并提高了奖励和稳定性。

Conclusion: CVaR-MCTS and W-MCTS 提供了明确的尾部风险控制和 PAC 尾部安全保证，并在各种模拟环境中超越了现有基线，实现了具有改进奖励和稳定性的鲁棒尾部风险保证。

Abstract: Making decisions with respect to just the expected returns in Monte Carlo
Tree Search (MCTS) cannot account for the potential range of high-risk, adverse
outcomes associated with a decision. To this end, safety-aware MCTS often
consider some constrained variants -- by introducing some form of mean risk
measures or hard cost thresholds. These approaches fail to provide rigorous
tail-safety guarantees with respect to extreme or high-risk outcomes (denoted
as tail-risk), potentially resulting in serious consequence in high-stake
scenarios. This paper addresses the problem by developing two novel solutions.
We first propose CVaR-MCTS, which embeds a coherent tail risk measure,
Conditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter
$\alpha$ achieves explicit tail-risk control over the expected loss in the
"worst $(1-\alpha)\%$ scenarios." Second, we further address the estimation
bias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or
W-MCTS) by introducing a first-order Wasserstein ambiguity set
$\mathcal{P}_{\varepsilon_{s}}(s,a)$ with radius $\varepsilon_{s}$ to
characterize the uncertainty in tail-risk estimates. We prove PAC tail-safety
guarantees for both CVaR-MCTS and W-MCTS and establish their regret.
Evaluations on diverse simulated environments demonstrate that our proposed
methods outperform existing baselines, effectively achieving robust tail-risk
guarantees with improved rewards and stability.

</details>


### [249] [EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting](https://arxiv.org/abs/2508.05454)
*Wei Li,Zixin Wang,Qizheng Sun,Qixiang Gao,Fenglei Yang*

Main category: cs.LG

TL;DR: EnergyPatchTST通过多尺度特征提取、概率预测、未来已知变量集成以及预训练/微调，解决了传统时间序列预测方法的局限性，在能源预测任务上取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习时间序列预测方法在处理多尺度时间动力学和真实数据不规则性方面的局限性，提出EnergyPatchTST。

Method: EnergyPatchTST是一个专门为能源预测设计的Patch Time Series Transformer的扩展。其主要创新包括：(1) 多尺度特征提取机制以捕捉不同时间分辨率下的模式；(2) 通过蒙特卡洛消除来估计不确定性的概率预测框架；(3) 未来已知变量（如温度和风况）的集成路径；以及 (4) 预训练和微调示例，以增强有限能源数据集的性能。

Result: 与常用方法相比，EnergyPatchTST在常见能源数据集上的预测误差降低了7-12%，并提供了可靠的不确定性估计。

Conclusion: EnergyPatchTST在常见能源数据集上优于其他常用方法，预测误差降低了7-12%，并提供了可靠的不确定性估计，为能源领域的时间序列预测提供了重要参考。

Abstract: Accurate and reliable energy time series prediction is of great significance
for power generation planning and allocation. At present, deep learning time
series prediction has become the mainstream method. However, the multi-scale
time dynamics and the irregularity of real data lead to the limitations of the
existing methods. Therefore, we propose EnergyPatchTST, which is an extension
of the Patch Time Series Transformer specially designed for energy forecasting.
The main innovations of our method are as follows: (1) multi-scale feature
extraction mechanism to capture patterns with different time resolutions; (2)
probability prediction framework to estimate uncertainty through Monte Carlo
elimination; (3) integration path of future known variables (such as
temperature and wind conditions); And (4) Pre-training and Fine-tuning examples
to enhance the performance of limited energy data sets. A series of experiments
on common energy data sets show that EnergyPatchTST is superior to other
commonly used methods, the prediction error is reduced by 7-12%, and reliable
uncertainty estimation is provided, which provides an important reference for
time series prediction in the energy field.

</details>


### [250] [Task complexity shapes internal representations and robustness in neural networks](https://arxiv.org/abs/2508.05463)
*Robert Jankowski,Filippo Radicchi,M. Ángeles Serrano,Marián Boguñá,Santo Fortunato*

Main category: cs.LG

TL;DR: 神经网络表示的复杂性与任务难度之间的关系。通过五种数据不可知的方法（修剪、二值化、噪声注入、符号翻转、二分网络随机化）来量化MLP表示的拓扑和鲁棒性。发现表示的符号二分图拓扑对任务难度至关重要，并提出了与任务复杂度相关的模型压缩和可解释性策略。


<details>
  <summary>Details</summary>
Motivation: 阐述了神经网络（尤其是MLP）的内部表示如何受到输入数据复杂性和它们所解决的任务的影响，以及这种表示的拓扑结构和鲁棒性如何随任务难度变化。

Method: 提出了一套数据不可知的探测方法——修剪、二值化、噪声注入、符号翻转和二分网络随机化——来量化任务难度如何影响多层感知机（MLP）中表示的拓扑和鲁棒性。将MLP从网络科学的角度表示为有符号加权二分图，并对比了MNIST和Fashion-MNIST数据集上简单和困难的分类任务。

Result: 研究表明，对困难任务模型进行权重二值化会使准确率降至随机水平，而简单任务模型则保持鲁棒性。在二值化的困难任务模型中修剪低幅度边缘会揭示性能的急剧相变。适度的噪声注入可以提高准确性，这与最优符号翻转效果类似。仅保留符号结构（而非权重幅度）足以维持高准确率。这些现象定义了一种模型和模态不可知任务复杂度度量：全精度与二值化或随机化网络性能之间的差距。

Conclusion: 研究结果强调了有符号二分图拓扑在学习表示中的关键作用，并提出了与任务复杂度一致的模型压缩和可解释性策略。

Abstract: Neural networks excel across a wide range of tasks, yet remain black boxes.
In particular, how their internal representations are shaped by the complexity
of the input data and the problems they solve remains obscure. In this work, we
introduce a suite of five data-agnostic probes-pruning, binarization, noise
injection, sign flipping, and bipartite network randomization-to quantify how
task difficulty influences the topology and robustness of representations in
multilayer perceptrons (MLPs). MLPs are represented as signed, weighted
bipartite graphs from a network science perspective. We contrast easy and hard
classification tasks on the MNIST and Fashion-MNIST datasets. We show that
binarizing weights in hard-task models collapses accuracy to chance, whereas
easy-task models remain robust. We also find that pruning low-magnitude edges
in binarized hard-task models reveals a sharp phase-transition in performance.
Moreover, moderate noise injection can enhance accuracy, resembling a
stochastic-resonance effect linked to optimal sign flips of small-magnitude
weights. Finally, preserving only the sign structure-instead of precise weight
magnitudes-through bipartite network randomizations suffices to maintain high
accuracy. These phenomena define a model- and modality-agnostic measure of task
complexity: the performance gap between full-precision and binarized or
shuffled neural network performance. Our findings highlight the crucial role of
signed bipartite topology in learned representations and suggest practical
strategies for model compression and interpretability that align with task
complexity.

</details>


### [251] [Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](https://arxiv.org/abs/2508.05469)
*Zachary Robertson,Sanmi Koyejo*

Main category: cs.LG

TL;DR: We propose novel mechanisms for evaluating AI systems without ground truth, utilizing the link between gaming resistance and output quality. Our f-mutual information-based methods prove more robust to adversarial manipulation than current practices, outperforming LLM judges which show evaluation inversion. The effectiveness of our approach is further detailed through an inverted-U curve analysis concerning compression ratios.


<details>
  <summary>Details</summary>
Motivation: To develop mechanisms for evaluating AI systems without ground truth by exploiting a connection between gaming resistance and output quality.

Method: We develop mechanisms for evaluating AI systems without ground truth by exploiting a connection between gaming resistance and output quality. The data processing inequality ensures post-hoc attempts to game a metric degrades both information content and task performance. We prove that f-mutual information measures are the unique gaming resistant mechanisms under natural conditions, with the overseer acting as an agent. While Shannon mutual information faces exponential sample complexity, bounded measures like total variation distance remain tractable.

Result: Empirically, across ten domains from translation to peer review, all information-theoretic mechanisms achieve perfect discrimination (d > 0.5) between faithful and strategic agents. LLM judges exhibit systematic evaluation inversion, preferring fabricated content over accurate summaries. Our mechanisms show 10-100x better robustness to adversarial manipulation than current practices. Performance follows an inverted-U curve with compression ratio, peaking at 10:1 where agent responses exhibit optimal information diversity (3 effective dimensions), giving a bias-variance perspective on when our approach is expected to be most effective.

Conclusion: f-mutual information measures are the unique gaming resistant mechanisms under natural conditions, and the proposed mechanisms show superior robustness to adversarial manipulation compared to current practices.

Abstract: We develop mechanisms for evaluating AI systems without ground truth by
exploiting a connection between gaming resistance and output quality. The data
processing inequality ensures post-hoc attempts to game a metric degrades both
information content and task performance. We prove that f-mutual information
measures are the unique gaming resistant mechanisms under natural conditions,
with the overseer acting as an agent. While Shannon mutual information faces
exponential sample complexity, bounded measures like total variation distance
remain tractable. Empirically, across ten domains from translation to peer
review, all information-theoretic mechanisms achieve perfect discrimination (d
> 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit
systematic evaluation inversion, preferring fabricated content over accurate
summaries. Our mechanisms show 10-100x better robustness to adversarial
manipulation than current practices. We also find performance follows an
inverted-U curve with compression ratio, peaking at 10:1 where agent responses
exhibit optimal information diversity (3 effective dimensions), giving a
bias-variance perspective on when our approach is expected to be most
effective.

</details>


### [252] [Prediction of Survival Outcomes under Clinical Presence Shift: A Joint Neural Network Architecture](https://arxiv.org/abs/2508.05472)
*Vincent Jeanselme,Glen Martin,Matthew Sperrin,Niels Peek,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: Clinical prediction models can be improved by accounting for patient-healthcare system interactions ('clinical presence') using a joint multi-task neural network, enhancing both performance and transportability across different settings.


<details>
  <summary>Details</summary>
Motivation: Clinical prediction models often overlook the 'clinical presence' (the complex interaction between patients and the healthcare system) which can impact model performance and transportability, especially when this interaction evolves or differs across settings.

Method: A multi-task recurrent neural network is proposed to jointly model the inter-observation time and missingness processes in parallel with the survival outcome. This approach formalizes the concept of clinical presence shift and provides a theoretical justification for improved transportability under changes in clinical presence.

Result: The proposed joint modeling strategy demonstrated improvements in performance and transportability compared to state-of-the-art models on a real-world mortality prediction task in the MIMIC-III dataset.

Conclusion: To improve the performance and transportability of clinical prediction models, it is important to leverage the concept of clinical presence, which accounts for the interaction between patients and the healthcare system. The proposed multi-task recurrent neural network, which jointly models inter-observation time and missingness, offers a promising approach to address this.

Abstract: Electronic health records arise from the complex interaction between patients
and the healthcare system. This observation process of interactions, referred
to as clinical presence, often impacts observed outcomes. When using electronic
health records to develop clinical prediction models, it is standard practice
to overlook clinical presence, impacting performance and limiting the
transportability of models when this interaction evolves. We propose a
multi-task recurrent neural network that jointly models the inter-observation
time and the missingness processes characterising this interaction in parallel
to the survival outcome of interest. Our work formalises the concept of
clinical presence shift when the prediction model is deployed in new settings
(e.g. different hospitals, regions or countries), and we theoretically justify
why the proposed joint modelling can improve transportability under changes in
clinical presence. We demonstrate, in a real-world mortality prediction task in
the MIMIC-III dataset, how the proposed strategy improves performance and
transportability compared to state-of-the-art prediction models that do not
incorporate the observation process. These results emphasise the importance of
leveraging clinical presence to improve performance and create more
transportable clinical prediction models.

</details>


### [253] [Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection](https://arxiv.org/abs/2508.05504)
*Kristina P. Sinaga,Sara Colantonio,Miin-Shen Yang*

Main category: cs.LG

TL;DR: 本文提出 AMVFCM-U 和 AAMVFCM-U 算法，用于多视图聚类。该方法使用熵正则化和信噪比进行特征加权，并自动平衡视图和特征贡献。AAMVFCM-U 还包括分层降维。该方法在多个基准测试中优于现有技术，并提高了效率和降维。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类在自动发现异构数据中的模式，同时管理高维特征和消除无关信息方面面临关键挑战。传统方法存在手动参数调整和缺乏原则性跨视图集成机制的缺点。

Method: 本文提出 AMVFCM-U 和 AAMVFCM-U 两种互补算法，提供了一个统一的无参数框架。该方法用熵正则化项取代模糊化参数，强制执行自适应跨视图共识。核心创新采用基于信噪比的正则化（$'%s'_j^h = rac{'%s'_j^h}{('%s'_j^h)^2}$）进行原则性特征加权，并具有收敛保证，并结合双层熵项，自动平衡视图和特征贡献。AAMVFCM-U 通过在特征和视图级别通过自适应阈值（$'%s'^{h^{(t)}} = rac{d_h^{(t)}}{n}$）进行分层降维来扩展此功能。

Result: AMVFCM-U 实现了高达 97% 的计算效率提升，将维度降低到原始大小的 0.45%，并自动识别关键视图组合以实现最佳模式发现。

Conclusion: 评估表明，与 15 种最先进的方法相比，AAMVFCM-U 在五个不同的基准测试中表现更优越，计算效率提高了 97%，将维度降低到原始大小的 0.45%，并自动识别关键视图组合以实现最佳模式发现。

Abstract: Multi-view clustering faces critical challenges in automatically discovering
patterns across heterogeneous data while managing high-dimensional features and
eliminating irrelevant information. Traditional approaches suffer from manual
parameter tuning and lack principled cross-view integration mechanisms. This
work introduces two complementary algorithms: AMVFCM-U and AAMVFCM-U, providing
a unified parameter-free framework. Our approach replaces fuzzification
parameters with entropy regularization terms that enforce adaptive cross-view
consensus. The core innovation employs signal-to-noise ratio based
regularization ($\delta_j^h = \frac{\bar{x}_j^h}{(\sigma_j^h)^2}$) for
principled feature weighting with convergence guarantees, coupled with
dual-level entropy terms that automatically balance view and feature
contributions. AAMVFCM-U extends this with hierarchical dimensionality
reduction operating at feature and view levels through adaptive thresholding
($\theta^{h^{(t)}} = \frac{d_h^{(t)}}{n}$). Evaluation across five diverse
benchmarks demonstrates superiority over 15 state-of-the-art methods. AAMVFCM-U
achieves up to 97% computational efficiency gains, reduces dimensionality to
0.45% of original size, and automatically identifies critical view combinations
for optimal pattern discovery.

</details>


### [254] [Tractable Sharpness-Aware Learning of Probabilistic Circuits](https://arxiv.org/abs/2508.05537)
*Hrithik Suresh,Sahil Sidheekh,Vishnu Shreeram M. P,Sriraam Natarajan,Narayanan C. Krishnan*

Main category: cs.LG

TL;DR: 我们提出了一种基于Hessian的正则化器来解决PC的过拟合问题，通过最小化Hessian迹来引导模型学习更平坦的最小值，从而提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度和表达能力强的PC容易导致过拟合，尤其是在数据有限的情况下。

Method: 提出了一种基于Hessian的正则化器，该正则化器可以有效计算对数似然的Hessian迹（一种通常难以处理的PC尖锐度代理），并提出了一种诱导梯度范数正则化器的优化方法，可以实现简单的闭式EM参数更新，并与基于梯度的学习方法无缝集成。

Result: 实验结果表明，该方法能够有效引导PC趋向更平坦的最小值，并提高泛化性能。

Conclusion: 该方法通过引导PC趋向更平坦的最小值来提高泛化能力。

Abstract: Probabilistic Circuits (PCs) are a class of generative models that allow
exact and tractable inference for a wide range of queries. While recent
developments have enabled the learning of deep and expressive PCs, this
increased capacity can often lead to overfitting, especially when data is
limited. We analyze PC overfitting from a log-likelihood-landscape perspective
and show that it is often caused by convergence to sharp optima that generalize
poorly. Inspired by sharpness aware minimization in neural networks, we propose
a Hessian-based regularizer for training PCs. As a key contribution, we show
that the trace of the Hessian of the log-likelihood-a sharpness proxy that is
typically intractable in deep neural networks-can be computed efficiently for
PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer
that yields simple closed-form parameter updates for EM, and integrates
seamlessly with gradient based learning methods. Experiments on synthetic and
real-world datasets demonstrate that our method consistently guides PCs toward
flatter minima, improves generalization performance.

</details>


### [255] [Adapting Vision-Language Models Without Labels: A Comprehensive Survey](https://arxiv.org/abs/2508.05547)
*Hao Dong,Lijun Sheng,Jian Liang,Ran He,Eleni Chatzi,Olga Fink*

Main category: cs.LG

TL;DR: 本研究对无监督视觉语言模型（VLM）适应性进行了全面调查，提出了一个将现有方法分为无数据迁移、无监督域迁移、情景测试时间适应和在线测试时间适应四种范例的分类法，并分析了各种方法的优缺点及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 尽管无监督适应方法在提高VLM的效用和数据效率方面受到了越来越多的关注，但目前缺乏对无监督VLM适应的统一、面向任务的调查。

Method: 本研究提出一个分类法，将无监督VLM适应方法根据无标签视觉数据的可用性和性质分为四种关键范例：无数据迁移（无数据）、无监督域迁移（丰富数据）、情景测试时间适应（批处理数据）和在线测试时间适应（流数据）。研究分析了每种范例的核心方法和适应策略。

Result: 本研究全面概述了无监督VLM适应领域，提出了一个基于数据可用性的分类法，并分析了各种适应范例下的核心方法和策略。此外，还回顾了相关基准并指出了未来研究方向。

Conclusion: 现有的无监督视觉语言模型（VLM）适应性研究缺乏统一的、面向任务的调查。为了弥合这一差距，我们提出了一个全面的、结构化的该领域概述。根据无标签视觉数据的可用性和性质，我们提出了一个分类法，将现有方法分为四种关键范例：无数据迁移（无数据）、无监督域迁移（丰富数据）、情景测试时间适应（批处理数据）和在线测试时间适应（流数据）。在此框架内，我们分析了与每种范例相关的核心方法和适应策略，旨在建立对该领域的系统性理解。此外，我们还回顾了跨不同应用的代表性基准，并强调了开放的挑战和未来研究的有希望的方向。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable generalization
capabilities across a wide range of tasks. However, their performance often
remains suboptimal when directly applied to specific downstream scenarios
without task-specific adaptation. To enhance their utility while preserving
data efficiency, recent research has increasingly focused on unsupervised
adaptation methods that do not rely on labeled data. Despite the growing
interest in this area, there remains a lack of a unified, task-oriented survey
dedicated to unsupervised VLM adaptation. To bridge this gap, we present a
comprehensive and structured overview of the field. We propose a taxonomy based
on the availability and nature of unlabeled visual data, categorizing existing
approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised
Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data),
and Online Test-Time Adaptation (streaming data). Within this framework, we
analyze core methodologies and adaptation strategies associated with each
paradigm, aiming to establish a systematic understanding of the field.
Additionally, we review representative benchmarks across diverse applications
and highlight open challenges and promising directions for future research. An
actively maintained repository of relevant literature is available at
https://github.com/tim-learn/Awesome-LabelFree-VLMs.

</details>


### [256] [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](https://arxiv.org/abs/2508.05587)
*Claudia d'Amato,Ivan Diliso,Nicola Fanizzi,Zafar Saeed*

Main category: cs.LG

TL;DR: 提供了一个PyKEEN扩展，集成了高级负采样策略，提升了知识图谱嵌入性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱嵌入方法在缺乏负断言时，通常需要人工生成负样本，而现有的库支持的负采样策略较为基础，影响了模型性能。本研究旨在解决这一差距。

Method: 开发了一个PyKEEN框架的扩展，集成了静态和动态的负采样策略，并进行了实证研究以评估其对链接预测任务的影响。

Result: 所开发的扩展增强了PyKEEN框架，能够生成更有效的负样本，从而提升了不同嵌入模型在链接预测任务上的性能，并为设计更有效的负采样策略提供了见解。

Conclusion: 该研究为PyKEEN框架提供了一个包含多种高级负采样策略的扩展，提高了知识图谱嵌入模型的性能，并促进了相关方法的开发和定制。

Abstract: Embedding methods have become popular due to their scalability on link
prediction and/or triple classification tasks on Knowledge Graphs. Embedding
models are trained relying on both positive and negative samples of triples.
However, in the absence of negative assertions, these must be usually
artificially generated using various negative sampling strategies, ranging from
random corruption to more sophisticated techniques which have an impact on the
overall performance. Most of the popular libraries for knowledge graph
embedding, support only basic such strategies and lack advanced solutions. To
address this gap, we deliver an extension for the popular KGE framework PyKEEN
that integrates a suite of several advanced negative samplers (including both
static and dynamic corruption strategies), within a consistent modular
architecture, to generate meaningful negative samples, while remaining
compatible with existing PyKEEN -based workflows and pipelines. The developed
extension not only enhancesPyKEEN itself but also allows for easier and
comprehensive development of embedding methods and/or for their customization.
As a proof of concept, we present a comprehensive empirical study of the
developed extensions and their impact on the performance (link prediction
tasks) of different embedding methods, which also provides useful insights for
the design of more effective strategies

</details>


### [257] [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](https://arxiv.org/abs/2508.05591)
*Natalia Emelianova,Carlos Kamienski,Ronaldo C. Prati*

Main category: cs.LG

TL;DR: Kolmogorov-Arnold Networks (KANs) show great potential for IoT intrusion detection, offering better interpretability and strong performance compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: The exponential growth of the Internet of Things (IoT) has led to substantial security concerns, with IoT networks becoming primary targets for cyberattacks, necessitating the development of effective intrusion detection methods.

Method: Examining the potential of Kolmogorov-Arnold Networks (KANs) for intrusion detection in IoT networks, comparing their performance against traditional MLPs, Random Forest, and XGBoost.

Result: KANs demonstrate superior interpretability and competitive accuracy compared to state-of-the-art models for intrusion detection in IoT networks.

Conclusion: Kolmogorov-Arnold Networks (KANs) are a promising alternative to conventional machine learning models for intrusion detection in IoT networks, outperforming traditional MLPs and achieving competitive accuracy compared to state-of-the-art models while offering superior interpretability.

Abstract: The exponential growth of the Internet of Things (IoT) has led to the
emergence of substantial security concerns, with IoT networks becoming the
primary target for cyberattacks. This study examines the potential of
Kolmogorov-Arnold Networks (KANs) as an alternative to conventional machine
learning models for intrusion detection in IoT networks. The study demonstrates
that KANs, which employ learnable activation functions, outperform traditional
MLPs and achieve competitive accuracy compared to state-of-the-art models such
as Random Forest and XGBoost, while offering superior interpretability for
intrusion detection in IoT networks.

</details>


### [258] [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](https://arxiv.org/abs/2508.05600)
*Thorsten Peinemann,Paula Arnold,Sebastian Berndt,Thomas Eisenbarth,Esfandiar Mohammadi*

Main category: cs.LG

TL;DR: 利用单个中毒样本和有限背景知识，即可成功在机器学习模型中注入后门，且对模型正常功能影响甚微。


<details>
  <summary>Details</summary>
Motivation: 探讨在机器学习模型中，后门注入攻击所需的最小中毒数据量，解决了现有攻击方法要么需要大量数据要么需要大量关于数据点信息的局限性。

Method: 提出并证明了“单毒假设”，即攻击者仅用一个中毒样本和有限背景知识即可注入后门，且后门错误率为零，同时不显著影响良性学习任务的性能。研究还证明了在特定条件下，中毒样本被排除在训练之外时，模型在功能上等同于未受攻击的模型，并在其他情况下证明了对良性学习任务的影响仍然有限。

Result: 理论上证明了单毒假设在線性回歸和線性分類中的有效性。实验结果在真实基准数据集上验证了这些理论结果。

Conclusion: 研究表明，在特定条件下，攻击者仅用一个中毒样本和有限的背景知识即可成功注入后门，且对良性学习任务的影响有限。

Abstract: Backdoor injection attacks are a threat to machine learning models that are
trained on large data collected from untrusted sources; these attacks enable
attackers to inject malicious behavior into the model that can be triggered by
specially crafted inputs. Prior work has established bounds on the success of
backdoor attacks and their impact on the benign learning task, however, an open
question is what amount of poison data is needed for a successful backdoor
attack. Typical attacks either use few samples, but need much information about
the data points or need to poison many data points.
  In this paper, we formulate the one-poison hypothesis: An adversary with one
poison sample and limited background knowledge can inject a backdoor with zero
backdooring-error and without significantly impacting the benign learning task
performance. Moreover, we prove the one-poison hypothesis for linear regression
and linear classification. For adversaries that utilize a direction that is
unused by the benign data distribution for the poison sample, we show that the
resulting model is functionally equivalent to a model where the poison was
excluded from training. We build on prior work on statistical backdoor learning
to show that in all other cases, the impact on the benign learning task is
still limited. We also validate our theoretical results experimentally with
realistic benchmark data sets.

</details>


### [259] [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612)
*Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai*

Main category: cs.LG

TL;DR: Shuffle-R1 通过成对轨迹采样和基于优势的轨迹洗牌，解决了 MLLM 的 RL 训练效率低下的问题，提高了梯度信号质量和有价值轨迹的利用率，并在实验中取得了优于现有基线的效果。


<details>
  <summary>Details</summary>
Motivation: 当前的 RL 管道在 MLLM 的训练效率方面存在两个未充分研究的问题：优势折叠（优势值集中在零附近）和回报静默（产生非零梯度的轨迹比例随时间减少）。这些问题导致了次优的梯度更新，并阻碍了长期的学习效率。因此，需要一种新的方法来解决这些低效问题。

Method: Shuffle-R1 框架通过以下两种方法来提高 RL 微调效率：1. 成对轨迹采样 (Pairwise Trajectory Sampling)：选择具有大优势的高对比度轨迹，以提升梯度信号质量。2. 基于优势的轨迹洗牌 (Advantage-based Trajectory Shuffle)：通过有信息量的批次重洗牌，增加有价值轨迹的暴露度。

Result: 在多个推理基准测试中，Shuffle-R1 框架相比于强大的 RL 基线表现出持续的优越性，并且仅带来最小的额外开销。这表明该框架能够有效提高 RL 微调的效率。

Conclusion: Reinforcement learning (RL) 是一种有效的方法，可以提高多模态大型语言模型 (MLLM) 的推理能力。然而，现有的 RL 管道存在训练效率低下的问题，主要源于两个未充分研究的因素：优势折叠（优势值集中在零附近）和回报静默（产生非零梯度的轨迹比例随时间减少）。这两种现象会导致次优的梯度更新，并阻碍长期的学习效率。Shuffle-R1 框架通过动态重构轨迹采样和批次构成来解决这些问题，提高了 RL 微调的效率。它包含两个关键组成部分：(1) 成对轨迹采样，选择具有大优势的高对比度轨迹，以提高梯度信号质量；(2) 基于优势的轨迹洗牌，通过有信息量的批次重洗牌来增加有价值轨迹的暴露度。实验证明，我们的框架在多个推理基准测试中，以最小的额外开销持续优于强大的 RL 基线。这表明以数据为中心的方法对于 MLLM 的 RL 训练效率至关重要。

Abstract: Reinforcement learning (RL) has emerged as an effective post-training
paradigm for enhancing the reasoning capabilities of multimodal large language
model (MLLM). However, current RL pipelines often suffer from training
inefficiencies caused by two underexplored issues: Advantage Collapsing, where
most advantages in a batch concentrate near zero, and Rollout Silencing, where
the proportion of rollouts contributing non-zero gradients diminishes over
time. These issues lead to suboptimal gradient updates and hinder long-term
learning efficiency. To address these issues, we propose Shuffle-R1, a simple
yet principled framework that improves RL fine-tuning efficiency by dynamically
restructuring trajectory sampling and batch composition. It introduces (1)
Pairwise Trajectory Sampling, which selects high-contrast trajectories with
large advantages to improve gradient signal quality, and (2) Advantage-based
Trajectory Shuffle, which increases exposure of valuable rollouts through
informed batch reshuffling. Experiments across multiple reasoning benchmarks
show that our framework consistently outperforms strong RL baselines with
minimal overhead. These results highlight the importance of data-centric
adaptations for more efficient RL training in MLLM.

</details>


### [260] [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
*Yongliang Wu,Yizhou Zhou,Zhou Ziheng,Yingzhe Peng,Xinyu Ye,Xinting Hu,Wenbo Zhu,Lu Qi,Ming-Hsuan Yang,Xu Yang*

Main category: cs.LG

TL;DR: 通过动态微调（DFT）改进监督微调（SFT），解决了泛化能力问题，效果优于标准SFT。


<details>
  <summary>Details</summary>
Motivation: 解决监督微调（SFT）相比于强化学习（RL）在泛化能力上的局限性，并通过理论分析揭示了标准SFT梯度中存在的限制泛化能力的问题。

Method: 提出动态微调（DFT）方法，通过动态地使用token的概率对目标函数进行重缩放来稳定每个token的梯度更新，这是一个简单的代码修改。

Result: 动态微调（DFT）在多个具有挑战性的基准和基础模型上显著优于标准SFT，展示了更强的泛化能力。此外，DFT在离线RL设置中也取得了有竞争力的结果。

Conclusion: 该研究提出了一种名为动态微调（DFT）的简单但有理论依据的改进方法，用于大型语言模型（LLM）的监督微调（SFT），解决了SFT相对于强化学习（RL）泛化能力有限的问题。通过数学分析揭示了标准SFT梯度中存在的潜在问题，并提出通过动态调整目标函数来稳定梯度更新，从而显著提高了模型的泛化能力。DFT在多个挑战性基准和基础模型上均表现优于标准SFT，并在离线RL设置中也取得了有竞争力的结果，为RL提供了一个更简单有效的替代方案。

Abstract: We present a simple yet theoretically motivated improvement to Supervised
Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited
generalization compared to reinforcement learning (RL). Through mathematical
analysis, we reveal that standard SFT gradients implicitly encode a problematic
reward structure that may severely restrict the generalization capabilities of
model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing
gradient updates for each token by dynamically rescaling the objective function
with the probability of this token. Remarkably, this single-line code change
significantly outperforms standard SFT across multiple challenging benchmarks
and base models, demonstrating greatly improved generalization. Additionally,
our approach shows competitive results in offline RL settings, offering an
effective yet simpler alternative. This work bridges theoretical insight and
practical solutions, substantially advancing SFT performance. The code will be
available at https://github.com/yongliang-wu/DFT.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [261] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 機器人分享反應和適當的反應延遲時間可以增強人類對機器人的情感感知。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探討機器人透過積極分享對事件的反應，是否能改變人類對機器人情感影響的感知，以期改善機器人在社交場合中的功能。

Method: 本研究透過兩種不同的測試設置來驗證：一種用於突出和分離情感機器人表達中的反應元素，另一種用於研究將特定時間延遲應用於機器人對人類進行身體互動的反應之影響。第一項測試針對兩組不同的觀察者（測試組和對照組）進行，共 84 人。第二項測試則有 110 名參與者，隨著參與者數量的增加，機器人的反應延遲也隨之增加。

Result: 結果顯示，當機器人對與人類共同發生的事件做出反應時，與隨機反應相比，人類感知到的情感影響有統計學上的顯著差異 (p < 0.05)。此外，研究發現對於共享的身體互動，接近人類的反應時間對機器人來說是最恰當的。

Conclusion: 本研究得出結論，對於小型非人型機器人，大約 200 毫秒的延遲時間可能對人類觀察者產生最大的影響；而當目標是讓人們感覺他們對機器人產生了最大影響時，大約 100 毫秒的反應時間最為有效。

Abstract: In an effort to improve how robots function in social contexts, this paper
investigates if a robot that actively shares a reaction to an event with a
human alters how the human perceives the robot's affective impact. To verify
this, we created two different test setups. One to highlight and isolate the
reaction element of affective robot expressions, and one to investigate the
effects of applying specific timing delays to a robot reacting to a physical
encounter with a human. The first test was conducted with two different groups
(n=84) of human observers, a test group and a control group both interacting
with the robot. The second test was performed with 110 participants using
increasingly longer reaction delays for the robot with every ten participants.
The results show a statistically significant change (p$<$.05) in perceived
affective impact for the robots when they react to an event shared with a human
observer rather than reacting at random. The result also shows for shared
physical interaction, the near-human reaction times from the robot are most
appropriate for the scenario. The paper concludes that a delay time around
200ms may render the biggest impact on human observers for small-sized
non-humanoid robots. It further concludes that a slightly shorter reaction time
around 100ms is most effective when the goal is to make the human observers
feel they made the biggest impact on the robot.

</details>


### [262] [INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM](https://arxiv.org/abs/2508.04931)
*Jin Wang,Weijie Wang,Boyuan Deng,Heng Zhang,Rui Dai,Nikos Tsagarakis*

Main category: cs.RO

TL;DR: INTENTION 框架通过视觉-语言模型和交互记忆，使机器人具备学习到的交互直觉和自主操纵能力，以适应真实世界中的多样化场景。


<details>
  <summary>Details</summary>
Motivation: 传统机器人操纵方法依赖精确的物理模型和预定义动作序列，在真实世界中鲁棒性和泛化性不足。而人类能够通过隐含的物理理解做出高效决策并适应新环境，因此本研究旨在让机器人具备类似人类的交互直觉和自主操纵能力。

Method: INTENTION 框架整合了视觉语言模型（VLM）的场景推理能力和交互驱动的记忆。它使用记忆图（Memory Graph）来记录和学习任务交互中的场景信息，并设计了直观感知器（Intuitive Perceptor）来提取视觉场景中的物理关系和潜在功能，使机器人能够在新场景中推断出合适的交互行为。

Result: INTENTION 框架使机器人能够学习交互直觉，在没有重复指令的情况下，通过视觉语言模型和交互记忆，在不同场景中进行自主操纵，并能理解和推断物理关系和潜在功能。

Conclusion: 通过整合基于视觉语言模型（VLM）的场景推理和交互驱动记忆，INTENTION 框架使机器人能够在多样化场景中实现学习到的交互直觉和自主操纵，从而摆脱对精确物理模型和预定义动作序列的依赖。

Abstract: Traditional control and planning for robotic manipulation heavily rely on
precise physical models and predefined action sequences. While effective in
structured environments, such approaches often fail in real-world scenarios due
to modeling inaccuracies and struggle to generalize to novel tasks. In
contrast, humans intuitively interact with their surroundings, demonstrating
remarkable adaptability, making efficient decisions through implicit physical
understanding. In this work, we propose INTENTION, a novel framework enabling
robots with learned interactive intuition and autonomous manipulation in
diverse scenarios, by integrating Vision-Language Models (VLMs) based scene
reasoning with interaction-driven memory. We introduce Memory Graph to record
scenes from previous task interactions which embodies human-like understanding
and decision-making about different tasks in real world. Meanwhile, we design
an Intuitive Perceptor that extracts physical relations and affordances from
visual scenes. Together, these components empower robots to infer appropriate
interaction behaviors in new scenes without relying on repetitive instructions.
Videos: https://robo-intention.github.io

</details>


### [263] [Optimal Planning for Multi-Robot Simultaneous Area and Line Coverage Using Hierarchical Cyclic Merging Regulation](https://arxiv.org/abs/2508.04981)
*Tianyuan Zheng,Jingang Yi,Kaiyan Yu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为HCMR的最优规划算法，用于解决多机器人双重覆盖问题（同时覆盖线性特征和区域），通过分层循环合并规则和莫尔斯理论分析，显著提高了路径规划效率并减少了任务时间。


<details>
  <summary>Details</summary>
Motivation: 为了解决多机器人同时覆盖线性特征（如表面裂缝）和调查区域（如停车场）的双重覆盖问题，并为每个机器人分配服务（线性特征覆盖）和探索（区域覆盖）两种角色，同时最小化路径长度和避免碰撞，文章提出了一种新的规划算法。

Method: 文章提出了一种名为“分层循环合并规则”（HCMR）的最优规划算法，该算法通过分析图遍历中的流形附件过程（从莫尔斯理论视角），利用循环合并搜索来规范遍历行为，并通过边缘序列反向传播将这些规范转化为图边缘遍历序列。结合平衡划分，选择最优序列来为每个机器人生成路径。

Result: HCMR算法在多机器人模拟中，相比其他现有规划方法，规划路径长度平均提高至少10.0%，任务时间平均减少至少16.9%，并确保了无冲突操作。

Conclusion: HCMR算法在固定扫描方向下被证明是最优的，并且在多机器人模拟中，相比其他现有规划方法，能够显著提高规划路径长度（至少10.0%），减少任务时间（平均至少16.9%），并确保无冲突操作。

Abstract: The double coverage problem focuses on determining efficient, collision-free
routes for multiple robots to simultaneously cover linear features (e.g.,
surface cracks or road routes) and survey areas (e.g., parking lots or local
regions) in known environments. In these problems, each robot carries two
functional roles: service (linear feature footprint coverage) and exploration
(complete area coverage). Service has a smaller operational footprint but
incurs higher costs (e.g., time) compared to exploration. We present optimal
planning algorithms for the double coverage problems using hierarchical cyclic
merging regulation (HCMR). To reduce the complexity for optimal planning
solutions, we analyze the manifold attachment process during graph traversal
from a Morse theory perspective. We show that solutions satisfying minimum path
length and collision-free constraints must belong to a Morse-bounded
collection. To identify this collection, we introduce the HCMR algorithm. In
HCMR, cyclic merging search regulates traversal behavior, while edge sequence
back propagation converts these regulations into graph edge traversal
sequences. Incorporating balanced partitioning, the optimal sequence is
selected to generate routes for each robot. We prove the optimality of the HCMR
algorithm under a fixed sweep direction. The multi-robot simulation results
demonstrate that the HCMR algorithm significantly improves planned path length
by at least 10.0%, reduces task time by at least 16.9% in average, and ensures
conflict-free operation compared to other state-of-the-art planning methods.

</details>


### [264] [Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots](https://arxiv.org/abs/2508.04994)
*Wenjie Hu,Ye Zhou,Hann Woei Ho*

Main category: cs.RO

TL;DR: HDDPG 算法通过引入高层和低层策略来改进 DDPG 在迷宫导航中的表现，解决了稀疏奖励和探索效率低下的问题，并通过实验证明了其在提高成功率和平均奖励方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决 DDPG 算法在迷宫导航中存在的稀疏奖励、探索效率低下和长时规划困难等问题，该论文提出了一种高效的 HDDPG 算法。

Method: HDDPG 算法包括一个高层策略和一个低层策略。高层策略采用先进的 DDPG 框架，从长远和更高的时间尺度生成中间子目标。低层策略也通过改进的 DDPG 算法，通过观察当前状态并遵循高层策略分配的子目标来生成原始动作。该方法通过异策略校正增强了稳定性，通过重新标记历史经验来改进子目标分配。此外，还采用了自适应参数空间噪声来改进探索，并采用了重塑的内在-外在奖励函数来提高学习效率。还采用了梯度裁剪和 Xavier 初始化等进一步优化措施来提高鲁棒性。

Result: HDDPG 算法在自主迷宫导航任务中，相比基线算法，成功率提高了至少 56.59%，平均奖励提高了至少 519.03。

Conclusion: HDDPG 算法显著克服了标准 DDPG 及其变体的局限性，在为期三项不同的自主迷宫导航任务的最终目标方面，成功率提高了至少 56.59%，平均奖励提高了至少 519.03。

Abstract: Maze navigation is a fundamental challenge in robotics, requiring agents to
traverse complex environments efficiently. While the Deep Deterministic Policy
Gradient (DDPG) algorithm excels in control tasks, its performance in maze
navigation suffers from sparse rewards, inefficient exploration, and
long-horizon planning difficulties, often leading to low success rates and
average rewards, sometimes even failing to achieve effective navigation. To
address these limitations, this paper proposes an efficient Hierarchical DDPG
(HDDPG) algorithm, which includes high-level and low-level policies. The
high-level policy employs an advanced DDPG framework to generate intermediate
subgoals from a long-term perspective and on a higher temporal scale. The
low-level policy, also powered by the improved DDPG algorithm, generates
primitive actions by observing current states and following the subgoal
assigned by the high-level policy. The proposed method enhances stability with
off-policy correction, refining subgoal assignments by relabeling historical
experiences. Additionally, adaptive parameter space noise is utilized to
improve exploration, and a reshaped intrinsic-extrinsic reward function is
employed to boost learning efficiency. Further optimizations, including
gradient clipping and Xavier initialization, are employed to improve
robustness. The proposed algorithm is rigorously evaluated through numerical
simulation experiments executed using the Robot Operating System (ROS) and
Gazebo. Regarding the three distinct final targets in autonomous maze
navigation tasks, HDDPG significantly overcomes the limitations of standard
DDPG and its variants, improving the success rate by at least 56.59% and
boosting the average reward by a minimum of 519.03 compared to baseline
algorithms.

</details>


### [265] [MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding](https://arxiv.org/abs/2508.05021)
*Weifan Zhang,Tingguang Li,Yuzhen Liu*

Main category: cs.RO

TL;DR: 该研究提出了一种创新的视觉导航框架，通过结合主动视觉锚定和历史记忆回溯，利用现成的视觉语言模型，实现了在未知环境中仅根据自然语言描述进行高效导航，并在仿真和真实机器人实验中均取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 旨在实现智能机器人仅依靠自然语言描述在未知环境中进行视觉导航的关键能力。

Method: 提出了一种基于现成的视觉语言模型（VLMs）的导航框架，并结合了两种受人类启发的机制：基于视点的动态主动式视觉锚定和历史记忆回溯，以优化感知和解决歧义。

Result: 该方法在Habitat-Matterport 3D (HM3D)上取得了优于最先进方法的语言驱动物体导航性能，并在真实世界的四足机器人部署中表现出鲁棒性和有效性。

Conclusion: 该框架在Habitat-Matterport 3D (HM3D)上进行了实验，并取得了优于现有方法的语言驱动物体导航性能。此外，该框架还成功应用于四足机器人，展示了其在真实世界中的实用性和鲁棒性。

Abstract: Visual navigation in unknown environments based solely on natural language
descriptions is a key capability for intelligent robots. In this work, we
propose a navigation framework built upon off-the-shelf Visual Language Models
(VLMs), enhanced with two human-inspired mechanisms: perspective-based active
grounding, which dynamically adjusts the robot's viewpoint for improved visual
inspection, and historical memory backtracking, which enables the system to
retain and re-evaluate uncertain observations over time. Unlike existing
approaches that passively rely on incidental visual inputs, our method actively
optimizes perception and leverages memory to resolve ambiguity, significantly
improving vision-language grounding in complex, unseen environments. Our
framework operates in a zero-shot manner, achieving strong generalization to
diverse and open-ended language descriptions without requiring labeled data or
model fine-tuning. Experimental results on Habitat-Matterport 3D (HM3D) show
that our method outperforms state-of-the-art approaches in language-driven
object navigation. We further demonstrate its practicality through real-world
deployment on a quadruped robot, achieving robust and effective navigation
performance.

</details>


### [266] [Benchmarking Shortcutting Techniques for Multi-Robot-Arm Motion Planning](https://arxiv.org/abs/2508.05027)
*Philip Huang,Yorai Shaoul,Jiaoyang Li*

Main category: cs.RO

TL;DR: 该研究对多机械臂运动规划的快捷方式方法进行了全面比较，并提出优化性能-运行时间权衡的策略。


<details>
  <summary>Details</summary>
Motivation: 生成高质量的多机械臂运动规划具有挑战性，因为系统具有高维度且可能发生机械臂之间的碰撞。传统的运动规划方法通常无法为多臂系统产生最优的平稳性和执行时间。

Method: 通过快捷方式进行后处理以提高运动质量，以实现高效平稳的执行。

Result: 对不同模拟场景下的多臂轨迹的现有快捷方式方法进行全面的定量比较研究，并分析了每种方法的优缺点。

Conclusion: 现有的快捷方式方法在多臂场景下进行轨迹优化时，有必要在不产生碰撞的情况下进行优化，并且该论文对现有快捷方式方法进行了全面的定量比较研究，提出两种简单策略以获得最佳性能-运行时间权衡。

Abstract: Generating high-quality motion plans for multiple robot arms is challenging
due to the high dimensionality of the system and the potential for inter-arm
collisions. Traditional motion planning methods often produce motions that are
suboptimal in terms of smoothness and execution time for multi-arm systems.
Post-processing via shortcutting is a common approach to improve motion quality
for efficient and smooth execution. However, in multi-arm scenarios, optimizing
one arm's motion must not introduce collisions with other arms. Although
existing multi-arm planning works often use some form of shortcutting
techniques, their exact methodology and impact on performance are often vaguely
described. In this work, we present a comprehensive study quantitatively
comparing existing shortcutting methods for multi-arm trajectories across
diverse simulated scenarios. We carefully analyze the pros and cons of each
shortcutting method and propose two simple strategies for combining these
methods to achieve the best performance-runtime tradeoff. Video, code, and
dataset are available at https://philip-huang.github.io/mr-shortcut/.

</details>


### [267] [A Vision-Based Collision Sensing Method for Stable Circular Object Grasping with A Soft Gripper System](https://arxiv.org/abs/2508.05040)
*Boyang Zhang,Jiahui Zuo,Zeyu Duan,Fumin Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一种视觉传感模块，用于检测机器人软体夹爪在抓取物体时发生的碰撞，以提高抓取的稳定性。该模块使用眼中有手相机监控夹爪和物体，并通过一种特殊的抓取策略来应对碰撞。实验证明该系统反应迅速且能精确识别碰撞。


<details>
  <summary>Details</summary>
Motivation: 机器人执行器在抓取圆形物体时，外部碰撞通常会带来风险。

Method: 提出了一种基于视觉的感知模块，使用眼中手（eye-in-palm）相机，能够同时监控夹爪手指和被抓取物体的运动。开发了一种富含碰撞的抓取策略，以确保动态抓取过程的稳定性和安全性。

Result: 实验证实了该系统能够对碰撞做出瞬时反应，并且能够精确检测外部碰撞的方向和规模。

Conclusion: 该视觉感知模块能够实时检测碰撞，确保软体夹爪系统的稳定抓取。实验结果表明，该系统反应迅速，能够精确检测外部碰撞的方向和规模。

Abstract: External collisions to robot actuators typically pose risks to grasping
circular objects. This work presents a vision-based sensing module capable of
detecting collisions to maintain stable grasping with a soft gripper system.
The system employs an eye-in-palm camera with a broad field of view to
simultaneously monitor the motion of fingers and the grasped object.
Furthermore, we have developed a collision-rich grasping strategy to ensure the
stability and security of the entire dynamic grasping process. A physical soft
gripper was manufactured and affixed to a collaborative robotic arm to evaluate
the performance of the collision detection mechanism. An experiment regarding
testing the response time of the mechanism confirmed the system has the
capability to react to the collision instantaneously. A dodging test was
conducted to demonstrate the gripper can detect the direction and scale of
external collisions precisely.

</details>


### [268] [A General Control Method for Human-Robot Integration](https://arxiv.org/abs/2412.14762)
*Maddalena Feder,Giorgio Grioli,Manuel G. Catalano,Antonio Bicchi*

Main category: cs.RO

TL;DR: 提出了一种通用的控制框架，用于控制多自由度辅助系统，将用户的代偿性运动转化为机器人指令，以实现目标，同时减少用户的疲劳和不适。


<details>
  <summary>Details</summary>
Motivation: 为具有运动能力限制的人设计一种通用的控制方法，用于辅助其日常活动，目标是实现人与机器人的整合，自主减少用户的疲劳和不适。

Method: 提出了一种通用的控制框架，用于控制多自由度辅助系统，将用户执行的代偿性运动转化为机器人指令。

Result: 通过模拟场景和涉及机器人部件（假肢和机器人）虚拟孪生以及物理人形化身的真实世界试验，验证并应用了该控制策略。

Conclusion: 该框架将用户的代偿性运动转化为必要的机器人指令，以实现目标，同时消除或减少代偿，可扩展到任意数量的假肢甚至全身机器人替身。

Abstract: This paper introduces a new generalized control method designed for
multi-degrees-of-freedom devices to help people with limited motion
capabilities in their daily activities. The challenge lies in finding the most
adapted strategy for the control interface to effectively map user's motions in
a low-dimensional space to complex robotic assistive devices, such as
prostheses, supernumerary limbs, up to remote robotic avatars. The goal is a
system which integrates the human and the robotic parts into a unique system,
moving so as to reach the targets decided by the human while autonomously
reducing the user's effort and discomfort. We present a framework to control
general multi DoFs assistive systems, which translates user-performed
compensatory motions into the necessary robot commands for reaching targets
while canceling or reducing compensation. The framework extends to prostheses
of any number of DoF up to full robotic avatars, regarded here as a sort of
whole-body prosthesis of the person who sees the robot as an artificial
extension of their own body without a physical link but with a sensory-motor
integration. We have validated and applied this control strategy through tests
encompassing simulated scenarios and real-world trials involving a virtual twin
of the robotic parts (prosthesis and robot) and a physical humanoid avatar.

</details>


### [269] [Examining the legibility of humanoid robot arm movements in a pointing task](https://arxiv.org/abs/2508.05104)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Ana Farić,Kristína Malinovská,Michal Vavrecka,Igor Farkaš*

Main category: cs.RO

TL;DR: 研究表明，通过结合机器人的凝视和指向动作，可以提高人类对其意图的预测能力，并且眼睛线索尤为重要。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人能够被人类理解、预测并感到安全，需要提高机器人动作的可读性。本研究旨在探究人形机器人指向任务中动作的可读性，特别是人类如何从截断的动作和身体线索中预测机器人意图。

Method: 本研究通过一个实验来检验人类对机器人手臂运动可读性的理解。实验使用了NICO人形机器人，让参与者观察其指向触摸屏上目标的动作。机器人的线索包括凝视、指向，以及凝视与指向的匹配或不匹配。机器人手臂轨迹在达到全部长度的60%或80%时被截断，然后参与者需要预测目标。研究人员测试了多模态优势和眼动优先假说。

Result: 实验结果支持了多模态优势和眼动优先假说。这意味着，结合机器人的凝视和指向线索，比单独使用其中一种线索更能提高人类对机器人意图的预测准确性，并且眼睛（凝视）线索在其中起着重要作用。

Conclusion: 该研究支持了多模态优势和眼动优先假说，表明机器人手臂运动的可读性可以通过凝视、指向和两者结合的线索来增强，并且人类能够有效地从截断的机器人动作和身体线索中预测其意图。

Abstract: Human--robot interaction requires robots whose actions are legible, allowing
humans to interpret, predict, and feel safe around them. This study
investigates the legibility of humanoid robot arm movements in a pointing task,
aiming to understand how humans predict robot intentions from truncated
movements and bodily cues. We designed an experiment using the NICO humanoid
robot, where participants observed its arm movements towards targets on a
touchscreen. Robot cues varied across conditions: gaze, pointing, and pointing
with congruent or incongruent gaze. Arm trajectories were stopped at 60\% or
80\% of their full length, and participants predicted the final target. We
tested the multimodal superiority and ocular primacy hypotheses, both of which
were supported by the experiment.

</details>


### [270] [From Canada to Japan: How 10,000 km Affect User Perception in Robot Teleoperation](https://arxiv.org/abs/2508.05143)
*Siméon Capy,Thomas M. Kwok,Kevin Joseph,Yuichiro Kawasumi,Koichi Nagashima,Tomoya Sasaki,Yue Hu,Eiichi Yoshida*

Main category: cs.RO

TL;DR: 本研究评估了非专业用户对远程机器人操作的感知，发现其与本地操作的机器人感知无显著差异，表明机器人可能是传统本地控制的可行替代方案，尤其是在老年人护理领域。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨距离对机器人遥操作（RTo）中用户感知的影响，并探索机器人辅助老年人护理的潜力。

Method: 本研究采用包含多个问卷的特定协议，并使用机器人操作系统（ROS）和Unity设计了专门的软件架构，以评估非专业用户对远程遥操作的感知，并考察交互前后以及与本地操作机器人相比的感知变化。

Result: 研究结果显示，在本地和远程机器人条件下，用户的感知没有统计学上的显著差异。

Conclusion: 研究结果表明，远程和本地机器人控制之间没有统计学上的显著差异，这表明机器人可能是传统本地控制的可行替代方案。

Abstract: Robot teleoperation (RTo) has emerged as a viable alternative to local
control, particularly when human intervention is still necessary. This research
aims to study the distance effect on user perception in RTo, exploring the
potential of teleoperated robots for older adult care. We propose an evaluation
of non-expert users' perception of long-distance RTo, examining how their
perception changes before and after interaction, as well as comparing it to
that of locally operated robots. We have designed a specific protocol
consisting of multiple questionnaires, along with a dedicated software
architecture using the Robotics Operating System (ROS) and Unity. The results
revealed no statistically significant differences between the local and remote
robot conditions, suggesting that robots may be a viable alternative to
traditional local control.

</details>


### [271] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: MICoBot是一个用于人机协作的系统，它使用混合倡议对话范式，允许人类和机器人就任务分配进行协商，并通过多层决策机制（元规划、规划、动作执行）来优化协作，从而提高了任务成功率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 为了实现能适应广泛人类伙伴的有效机器人系统，需要一个紧密集成的通信循环，使双方都能灵活地提出、接受或拒绝请求，以有效协调完成任务。

Method: MICoBot系统应用了混合倡议对话范式，通过元规划器、规划器和动作执行器三个层级进行决策。元规划器根据人类对话制定协作策略；规划器基于机器人的能力（通过模拟预训练的蕴含模型衡量）和人类的可用性来分配任务步骤；动作执行器则决定具体动作或对话内容。

Result: 通过在模拟和真实世界中进行的大量评估（包括在物理机器人上与18名不同用户进行27小时的交互），证明了MICoBot能够与不同的用户有效协作。

Conclusion: MICoBot能够在广泛的用户中有效地进行协作，显著提高了任务成功率和用户体验，优于纯LLM基线和其他代理分配模型。

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>


### [272] [Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories](https://arxiv.org/abs/2508.05148)
*Francisco Munguia-Galeano,Zhengxue Zhou,Satheeshkumar Veeramani,Hatem Fakhruldeen,Louis Longley,Rob Clowes,Andrew I. Cooper*

Main category: cs.RO

TL;DR: Chemist Eye是一个基于视觉-语言模型的安全监控系统，通过多摄像头集成和智能决策，能识别SDL中的火灾、PPE违规和人员紧急情况，指导机器人规避危险并向人员发出警报，显著提高了SDL的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自动化技术在自动化实验（SDL）中的应用日益广泛，实验安全面临着新的挑战，尤其是在处理火灾等风险时。文中提到，当火灾发生在装有易燃锂电池的移动机器人附近时，火势可能更加严重。因此，有必要增强SDL中的态势感知能力，以应对这些新增的安全复杂性。

Method: 该研究提出了一种名为Chemist Eye的分布式安全监控系统，该系统集成了配备RGB、深度和红外摄像头的多功能监测站。系统利用视觉-语言模型（VLM）进行决策，以识别安全隐患，包括人员事故、不合规的个人防护装备（PPE）以及火灾风险。系统能够将检测到的潜在危险（如火灾、出口或未穿PPE的人员）与机器人进行通信，并指导机器人规避，同时发出声音警告。

Result: Chemist Eye系统能够识别潜在的安全隐患（如火灾、出口或未穿PPE的人员），并基于VLM的建议，指导移动机器人规避危险区域。此外，该系统还能发出声音警告，并通过集成第三方消息平台向实验室人员发送即时通知。在配备三台移动机器人的SDL中进行的实际测试表明，Chemist Eye在识别安全隐患方面的准确率达到97%，在决策性能方面的准确率达到95%。

Conclusion: Chemist Eye系统已在配备三台移动机器人的SDL中进行了测试，其安全隐患识别和决策性能分别达到了97%和95%，证明了其在提升SDL安全性方面的有效性。

Abstract: The integration of robotics and automation into self-driving laboratories
(SDLs) can introduce additional safety complexities, in addition to those that
already apply to conventional research laboratories. Personal protective
equipment (PPE) is an essential requirement for ensuring the safety and
well-being of workers in laboratories, self-driving or otherwise. Fires are
another important risk factor in chemical laboratories. In SDLs, fires that
occur close to mobile robots, which use flammable lithium batteries, could have
increased severity. Here, we present Chemist Eye, a distributed safety
monitoring system designed to enhance situational awareness in SDLs. The system
integrates multiple stations equipped with RGB, depth, and infrared cameras,
designed to monitor incidents in SDLs. Chemist Eye is also designed to spot
workers who have suffered a potential accident or medical emergency, PPE
compliance and fire hazards. To do this, Chemist Eye uses decision-making
driven by a vision-language model (VLM). Chemist Eye is designed for seamless
integration, enabling real-time communication with robots. Based on the VLM
recommendations, the system attempts to drive mobile robots away from potential
fire locations, exits, or individuals not wearing PPE, and issues audible
warnings where necessary. It also integrates with third-party messaging
platforms to provide instant notifications to lab personnel. We tested Chemist
Eye with real-world data from an SDL equipped with three mobile robots and
found that the spotting of possible safety hazards and decision-making
performances reached 97 % and 95 %, respectively.

</details>


### [273] [FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction](https://arxiv.org/abs/2508.05153)
*Mohammed Daba,Jing Qiu*

Main category: cs.RO

TL;DR: FCBV-Net通过将特征提取与价值预测解耦，在机器人服装抚平任务中实现了卓越的类别级泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的服装操作方法在类别级泛化方面存在不足，要么在特定实例上过拟合，要么在感知泛化方面未能预测协同双臂动作的价值。

Method: 提出了一种特征条件双臂价值网络（FCBV-Net），该网络在3D点云上运行，以增强服装抚平的类别级策略泛化。FCBV-Net将双臂动作价值预测条件化为预训练的、固定的密集几何特征，以应对类别内的服装变化。然后，可训练的下游组件使用这些静态特征学习特定于任务的策略。

Result: FCBV-Net在未见过的服装上仅显示11.5%的效率下降（Steps80），而基于2D图像的基线为96.2%，并且实现了89%的最终覆盖率，优于3D对应基线（83%）。

Conclusion: 机器人服装操作（例如，双臂抚平）的类别级泛化仍然是一个重大障碍。FCBV-Net通过将双臂动作价值预测与预训练的、固定的密集几何特征相结合，并在模拟的GarmentLab实验中展示了卓越的类别级泛化能力，实现了89%的最终覆盖率，优于使用相同每点几何特征但具有固定基元的3D对应基线。将几何理解与双臂动作价值学习分离，可以实现更好的类别级泛化。

Abstract: Category-level generalization for robotic garment manipulation, such as
bimanual smoothing, remains a significant hurdle due to high dimensionality,
complex dynamics, and intra-category variations. Current approaches often
struggle, either overfitting with concurrently learned visual features for a
specific instance or, despite category-level perceptual generalization, failing
to predict the value of synergistic bimanual actions. We propose the
Feature-Conditioned Bimanual Value Network (FCBV-Net), operating on 3D point
clouds to specifically enhance category-level policy generalization for garment
smoothing. FCBV-Net conditions bimanual action value prediction on pre-trained,
frozen dense geometric features, ensuring robustness to intra-category garment
variations. Trainable downstream components then learn a task-specific policy
using these static features. In simulated GarmentLab experiments with the
CLOTH3D dataset, FCBV-Net demonstrated superior category-level generalization.
It exhibited only an 11.5% efficiency drop (Steps80) on unseen garments
compared to 96.2% for a 2D image-based baseline, and achieved 89% final
coverage, outperforming an 83% coverage from a 3D correspondence-based baseline
that uses identical per-point geometric features but a fixed primitive. These
results highlight that the decoupling of geometric understanding from bimanual
action value learning enables better category-level generalization.

</details>


### [274] [A Multi-view Landmark Representation Approach with Application to GNSS-Visual-Inertial Odometry](https://arxiv.org/abs/2508.05368)
*Tong Hua,Jiale Han,Wei Ouyang*

Main category: cs.RO

TL;DR: 本文提出了一种用于GNSS-视觉-惯性里程计（GVIO）的多视图、仅姿态估计方法，以提高IEKF的效率和适用性。该方法通过视觉测量模型实现了仅姿态的估计，并能在仿真和真实世界实验中证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了提高不变扩展卡尔曼滤波（IEKF）在视觉辅助传感器融合中的效率和适用性，尤其是在联合优化相机姿态和地标时的计算负担问题，本文提出了一种多视图、仅姿态的估计方法。

Method: 本文提出了一种多视图、仅姿态的估计方法，并将其应用于GNSS-视觉-惯性里程计（GVIO）。该方法通过直接关联多视图观测和地标表示来推导视觉测量模型，实现了仅姿态的估计。

Result: 通过仿真测试和真实世界实验证明，所提出的方法在效率和精度方面均优于现有方法，并成功应用于具有新颖特征管理策略的基于滤波器的GVIO。

Conclusion: 本文提出了一种多视图、仅姿态的估计方法，并将其应用于GNSS-视觉-惯性里程计（GVIO）。该方法通过直接关联多视图观测和地标表示来推导视觉测量模型，实现了仅姿态的估计。这种仅姿态的测量模型能够保证地标和姿态之间的紧密耦合，并维持一个独立于估计姿态的完美零空间。

Abstract: Invariant Extended Kalman Filter (IEKF) has been a significant technique in
vision-aided sensor fusion. However, it usually suffers from high computational
burden when jointly optimizing camera poses and the landmarks. To improve its
efficiency and applicability for multi-sensor fusion, we present a multi-view
pose-only estimation approach with its application to GNSS-Visual-Inertial
Odometry (GVIO) in this paper. Our main contribution is deriving a visual
measurement model which directly associates landmark representation with
multiple camera poses and observations. Such a pose-only measurement is proven
to be tightly-coupled between landmarks and poses, and maintain a perfect null
space that is independent of estimated poses. Finally, we apply the proposed
approach to a filter based GVIO with a novel feature management strategy. Both
simulation tests and real-world experiments are conducted to demonstrate the
superiority of the proposed method in terms of efficiency and accuracy.

</details>


### [275] [Learning to See and Act: Task-Aware View Planning for Robotic Manipulation](https://arxiv.org/abs/2508.05186)
*Yongjie Bai,Zhouxia Wang,Yang Liu,Weixing Chen,Ziliang Chen,Mingtong Dai,Yongsen Zheng,Lingbo Liu,Guanbin Li,Liang Lin*

Main category: cs.RO

TL;DR: TAVP是一个机器人操作框架，通过主动视角规划和任务特定表示学习来提高3D感知和任务泛化能力，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作VLA模型依赖静态视角和共享视觉编码器，限制了3D感知并导致任务干扰，从而阻碍了鲁棒性和泛化。

Method: TAVP框架采用高效的探索策略，并通过新颖的伪环境加速，主动获取信息性视角。此外，引入了混合专家（MoE）视觉编码器来分离不同任务的特征，提高了表示保真度和任务泛化能力。

Result: TAVP模型在RLBench任务上的广泛实验表明，其性能优于最先进的固定视角方法。

Conclusion: TAVP框架通过整合主动视角规划与任务特定表示学习，克服了现有VLA模型在多任务机器人操作中依赖静态视角和共享视觉编码器所带来的3D感知限制和任务干扰问题，提高了鲁棒性和泛化能力。通过学习以任务感知的方式观察世界，TAVP生成了更完整、更具辨别力的视觉表示，在广泛的操作挑战中显著提高了动作预测能力。

Abstract: Recent vision-language-action (VLA) models for multi-task robotic
manipulation commonly rely on static viewpoints and shared visual encoders,
which limit 3D perception and cause task interference, hindering robustness and
generalization. In this work, we propose Task-Aware View Planning (TAVP), a
framework designed to overcome these challenges by integrating active view
planning with task-specific representation learning. TAVP employs an efficient
exploration policy, accelerated by a novel pseudo-environment, to actively
acquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)
visual encoder to disentangle features across different tasks, boosting both
representation fidelity and task generalization. By learning to see the world
in a task-aware way, TAVP generates more complete and discriminative visual
representations, demonstrating significantly enhanced action prediction across
a wide array of manipulation challenges. Extensive experiments on RLBench tasks
show that our proposed TAVP model achieves superior performance over
state-of-the-art fixed-view approaches. Visual results and code are provided
at: https://hcplab-sysu.github.io/TAVP.

</details>


### [276] [Dancing with a Robot: An Experimental Study of Child-Robot Interaction in a Performative Art Setting](https://arxiv.org/abs/2508.05208)
*Victor Ngo,Rachel,Ramchurn,Roma Patel,Alan Chamberlain,Ayse Kucukyilmaz*

Main category: cs.RO

TL;DR: 本研究评估了儿童与机器人NED在艺术装置中的互动体验，发现儿童充满好奇但互动存在挑战，强调了优化人机交互设计以提升儿童体验的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估儿童与自主机器人表演者NED在Thingamabobas装置中的互动体验，并识别互动中的挑战。

Method: 通过在英国巡展的Thingamabobas装置中，对18名儿童与自主机器人表演者NED（永无止境的舞者）的“野外”互动进行评估。详细介绍了NED的设计（包括服装、行为和人机交互），并进行了观察性分析。

Result: 研究发现了儿童与机器人互动中的三个主要挑战：1) 启动和维持参与度，2) 机器人表现力和互惠性的缺乏，以及 3) 未能满足期望。研究表明，儿童对与机器人艺术表演者互动充满好奇心和能力，但需要优化HRI系统。

Conclusion: 本研究强调了在表演艺术背景下，尤其是在面向年轻观众时，优化人机交互（HRI）系统以实现引人入胜且有意义的体验的至关重要性。这需要仔细考虑观众的能力、看法和期望。

Abstract: This paper presents an evaluation of 18 children's in-the-wild experiences
with the autonomous robot arm performer NED (Never-Ending Dancer) within the
Thingamabobas installation, showcased across the UK. We detail NED's design,
including costume, behaviour, and human interactions, all integral to the
installation. Our observational analysis revealed three key challenges in
child-robot interactions: 1) Initiating and maintaining engagement, 2) Lack of
robot expressivity and reciprocity, and 3) Unmet expectations. Our findings
show that children are naturally curious, and adept at interacting with a
robotic art performer. However, our observations emphasise the critical need to
optimise human-robot interaction (HRI) systems through careful consideration of
audience's capabilities, perceptions, and expectations, within the performative
arts context, to enable engaging and meaningful experiences, especially for
young audiences.

</details>


### [277] [Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](https://arxiv.org/abs/2508.05294)
*Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本调查论文重点介绍了在机器人自主性、人机接口和具身智能领域，利用大型语言模型（LLMs）、视觉语言模型（VLMs）和视觉语言动作模型（VLAs）/大型行为模型（BLMs）的最新进展。论文中提出了一种分类法，用于对模型集成方法进行分类，并对代理在不同解决方案中所扮演的角色进行了比较分析。此外，论文还涵盖了社区驱动的项目、ROS包和工业框架，以反映该领域的快速发展趋势。


<details>
  <summary>Details</summary>
Motivation: Foundation models（包括大型语言模型（LLMs）和视觉语言模型（VLMs））以及视觉语言动作模型（VLAs）或大型行为模型（BLMs）在推动机器人自主性、人机交互、提高机器人系统的灵活性和能力方面展现出巨大潜力。本调查旨在重点关注那些推动这些模型走向具身应用和架构的进展，包括探索GPT风格接口的初步工作以及更复杂的系统，其中人工智能代理充当协调者、规划者、感知者或通用接口。

Method: 对现有研究、社区驱动项目、ROS包和工业框架进行了调查，并提出了一个分类法来对模型集成方法进行分类，同时对代理在不同解决方案中所起的作用进行了比较分析。

Result: 该调查重点介绍了将LLMs、VLMs和VLAs/BLMs应用于机器人自主性、人机接口和具身智能的进展，同时还强调了社区驱动的项目、ROS包和工业框架，并提出了一个分类法来对模型集成方法进行分类，以及对代理在不同解决方案中所扮演角色的比较分析。

Conclusion: 本文提出了一种用于对模型集成方法进行分类的分类法，并对代理在当今文献中的不同解决方案中所起的作用进行了比较分析。

Abstract: Foundation models, including large language models (LLMs) and vision-language
models (VLMs), have recently enabled novel approaches to robot autonomy and
human-robot interfaces. In parallel, vision-language-action models (VLAs) or
large behavior models (BLMs) are increasing the dexterity and capabilities of
robotic systems. This survey paper focuses on those words advancing towards
agentic applications and architectures. This includes initial efforts exploring
GPT-style interfaces to tooling, as well as more complex system where AI agents
are coordinators, planners, perception actors, or generalist interfaces. Such
agentic architectures allow robots to reason over natural language
instructions, invoke APIs, plan task sequences, or assist in operations and
diagnostics. In addition to peer-reviewed research, due to the fast-evolving
nature of the field, we highlight and include community-driven projects, ROS
packages, and industrial frameworks that show emerging trends. We propose a
taxonomy for classifying model integration approaches and present a comparative
analysis of the role that agents play in different solutions in today's
literature.

</details>


### [278] [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](https://arxiv.org/abs/2508.05634)
*Jianpeng Yao,Xiaopan Zhang,Yu Xia,Zejin Wang,Amit K. Roy-Chowdhury,Jiachen Li*

Main category: cs.RO

TL;DR: 该研究提出了一种通过考虑行人不确定性来提高机器人导航鲁棒性的方法，该方法在各种场景下都取得了显著的性能提升，并在真实机器人上进行了部署和验证。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在人群中导航时，使用强化学习进行训练，在面对分布外场景时，已知会遭受性能下降。

Method: 该方法将代理观测与通过自适应共形推理生成的预测不确定性估计相结合，并利用这些估计通过约束强化学习来指导代理的行为。

Result: 在分布内设置中，该方法实现了 96.93% 的成功率，比之前的最先进基线高出 8.80% 以上，碰撞次数减少了 3.72 倍以上，侵入真实人类未来轨迹的次数减少了 2.43 倍。在三个分布外场景中，该方法在面对速度变化、策略变化和从个体到群体动态的转变等分布变化时，表现出更强的鲁棒性。

Conclusion: 通过考虑行人不确定性，在多大程度上可以学习安全的、鲁棒的导航策略以应对分布变化。

Abstract: Mobile robots navigating in crowds trained using reinforcement learning are
known to suffer performance degradation when faced with out-of-distribution
scenarios. We propose that by properly accounting for the uncertainties of
pedestrians, a robot can learn safe navigation policies that are robust to
distribution shifts. Our method augments agent observations with prediction
uncertainty estimates generated by adaptive conformal inference, and it uses
these estimates to guide the agent's behavior through constrained reinforcement
learning. The system helps regulate the agent's actions and enables it to adapt
to distribution shifts. In the in-distribution setting, our approach achieves a
96.93% success rate, which is over 8.80% higher than the previous
state-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times
fewer intrusions into ground-truth human future trajectories. In three
out-of-distribution scenarios, our method shows much stronger robustness when
facing distribution shifts in velocity variations, policy changes, and
transitions from individual to group dynamics. We deploy our method on a real
robot, and experiments show that the robot makes safe and robust decisions when
interacting with both sparse and dense crowds. Our code and videos are
available on https://gen-safe-nav.github.io/.

</details>


### [279] [GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming](https://arxiv.org/abs/2508.05298)
*Jian Gong,Youwei Huang,Bo Yuan,Ming Zhu,Juncheng Zhan,Jinke Wang,Hang Shu,Mingyue Xiong,Yanjun Ye,Yufan Zu,Yang Zhou,Yihan Ding,Xuannian Chen,Xingyu Lu,Runjie Ban,Bingchao Huang,Fusen Liu*

Main category: cs.RO

TL;DR: GhostShell enables embodied systems to act on-the-fly using LLMs for streaming and concurrent behavioral programming, offering faster response times and improved performance compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of conventional methods relying on pre-scheduled action sequences or behavior trees, and to enable embodied systems to act on-the-fly by issuing function calls incrementally as tokens are streamed from LLMs.

Method: GhostShell utilizes LLMs for streaming and concurrent behavioral programming in embodied systems. It employs a streaming XML function token parser, a dynamic function interface mapper, and a multi-channel scheduler to orchestrate function calls, enabling on-the-fly action execution.

Result: GhostShell achieves a Behavioral Correctness Metric of 0.85 with Claude-4 Sonnet and is up to 66X faster than LLM native function calling APIs. It is also effective in long-horizon multimodal tasks, demonstrating robustness and generalization.

Conclusion: GhostShell is effective for long-horizon multimodal tasks, showing strong robustness and generalization, and achieves state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4 Sonnet and up to 66X faster response times compared to LLM native function calling APIs.

Abstract: We present GhostShell, a novel approach that leverages Large Language Models
(LLMs) to enable streaming and concurrent behavioral programming for embodied
systems. In contrast to conventional methods that rely on pre-scheduled action
sequences or behavior trees, GhostShell drives embodied systems to act
on-the-fly by issuing function calls incrementally as tokens are streamed from
the LLM. GhostShell features a streaming XML function token parser, a dynamic
function interface mapper, and a multi-channel scheduler that orchestrates
intra-channel synchronous and inter-channel asynchronous function calls,
thereby coordinating serial-parallel embodied actions across multiple robotic
components as directed by the LLM. We evaluate GhostShell on our robot
prototype COCO through comprehensive grounded experiments across 34 real-world
interaction tasks and multiple LLMs. The results demonstrate that our approach
achieves state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4
Sonnet and up to 66X faster response times compared to LLM native function
calling APIs. GhostShell also proves effective in long-horizon multimodal
tasks, demonstrating strong robustness and generalization.

</details>


### [280] [Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control](https://arxiv.org/abs/2508.05342)
*Shunlei Li,Longsen Gao,Jin Wang,Chang Che,Xi Xiao,Jiuwen Cao,Yingbai Hu,Hamid Reza Karimi*

Main category: cs.RO

TL;DR: GF-VLA框架通过信息论场景表示和语言引导的Transformer，使双臂机器人能够从人类演示中学习并执行复杂的装配任务，实现了高成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于依赖低级轨迹模仿，从人类视频中教授机器人熟练技能仍然具有挑战性，因为这种方法在物体类型、空间布局和机械臂配置方面泛化能力不足。

Method: GF-VLA框架首先提取基于香农信息论的线索来识别与任务最相关的双手和物体，然后将这些线索编码成时间有序的场景图，捕捉手-物体和物体-物体交互。这些图与语言条件Transformer融合，生成分层行为树和可解释的笛卡尔运动命令。为了提高双臂设置中的执行效率，还引入了跨手选择策略，无需显式几何推理即可推断最优夹持器分配。

Result: 信息论场景表示实现了超过95%的图准确率和93%的子任务分割率，支持LLM规划器生成可靠且可读的任务策略。当由双臂机器人执行时，这些策略在堆叠、字母构建和几何重构场景中产生了94%的抓取成功率、89%的放置准确率和90%的总体任务成功率，展示了跨不同空间和语义变化的强大泛化性和鲁棒性。

Conclusion: GF-VLA框架在双臂机器人上实现了从RGB和深度人类演示中进行任务级推理和执行，并在块组装任务中展示了强大的泛化性和鲁棒性，实现了94%的抓取成功率、89%的放置准确率和90%的总体任务成功率。

Abstract: Teaching robots dexterous skills from human videos remains challenging due to
the reliance on low-level trajectory imitation, which fails to generalize
across object types, spatial layouts, and manipulator configurations. We
propose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables
dual-arm robotic systems to perform task-level reasoning and execution directly
from RGB and Depth human demonstrations. GF-VLA first extracts
Shannon-information-based cues to identify hands and objects with the highest
task relevance, then encodes these cues into temporally ordered scene graphs
that capture both hand-object and object-object interactions. These graphs are
fused with a language-conditioned transformer that generates hierarchical
behavior trees and interpretable Cartesian motion commands. To improve
execution efficiency in bimanual settings, we further introduce a cross-hand
selection policy that infers optimal gripper assignment without explicit
geometric reasoning. We evaluate GF-VLA on four structured dual-arm block
assembly tasks involving symbolic shape construction and spatial
generalization. Experimental results show that the information-theoretic scene
representation achieves over 95 percent graph accuracy and 93 percent subtask
segmentation, supporting the LLM planner in generating reliable and
human-readable task policies. When executed by the dual-arm robot, these
policies yield 94 percent grasp success, 89 percent placement accuracy, and 90
percent overall task success across stacking, letter-building, and geometric
reconfiguration scenarios, demonstrating strong generalization and robustness
across diverse spatial and semantic variations.

</details>


### [281] [Affecta-Context: The Context-Guided Behavior Adaptation Framework](https://arxiv.org/abs/2508.05359)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: Affecta-context是一个通用框架，可以通过学习物理上下文中的行为优先级来适应社交机器人的行为。


<details>
  <summary>Details</summary>
Motivation: 为了促进社交机器人的行为适应，并利用物理上下文信息来指导人机交互中的行为。

Method: 该框架包含两个部分：一个用于表示遇到的上下文，另一个通过人机交互学习行为的优先级。它通过聚类物理上下文和优化机器人行为的物理属性来工作。

Result: 通过在两个不同的物理环境中与6名不同的参与者进行72次交互的训练，验证了该框架的能力。

Conclusion: 该研究展示了Affecta-context框架使机器人能够自主学习离散行为的优先级，并成功地在未访问过的物理上下文中泛化和匹配其行为。

Abstract: This paper presents Affecta-context, a general framework to facilitate
behavior adaptation for social robots. The framework uses information about the
physical context to guide its behaviors in human-robot interactions. It
consists of two parts: one that represents encountered contexts and one that
learns to prioritize between behaviors through human-robot interactions. As
physical contexts are encountered the framework clusters them by their measured
physical properties. In each context, the framework learns to prioritize
between behaviors to optimize the physical attributes of the robot's behavior
in line with its current environment and the preferences of the users it
interacts with. This paper illlustrates the abilities of the Affecta-context
framework by enabling a robot to autonomously learn the prioritization of
discrete behaviors. This was achieved by training across 72 interactions in two
different physical contexts with 6 different human test participants. The paper
demonstrates the trained Affecta-context framework by verifying the robot's
ability to generalize over the input and to match its behaviors to a previously
unvisited physical context.

</details>


### [282] [Robots can defuse high-intensity conflict situations](https://arxiv.org/abs/2508.05373)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 机器人通过情感表达（尤其是运动模态）可以有效缓解与人的高强度冲突，但关键在于机器人的社交意识和恰当反应，而非特定的表达能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索机器人如何在高强度冲突中缓和局势，特别是研究五种不同的情感表达方式作为主要驱动力在缓解冲突中的有效性，以发现每种方式在减轻人们对表现不佳的机器人产生的敌意方面的优缺点。

Method: 本研究采用了一个定制的情感机器人，在模拟冲突情境中进行了105名参与者的测试，重点评估了五种不同的情感表达方式在缓解冲突中的有效性。

Result: 所有测试的情感表达方式都能成功缓解冲突并表达对对抗的承认，参与者对机器人受冲突影响程度的评价也相似。其中，运动模态的效果与其他模态存在显著差异 (ANON p$<$.05)。

Conclusion: 本研究表明，在机器人表现不佳的情况下，机器人通过表达情感来缓和冲突的有效性。所有测试的情感表达方式都能成功缓解冲突并表达对对抗的承认，但其中运动模态的效果与其他模态存在显著差异。这表明，缓解高强度互动不必特别关注机器人的表达能力，而应更注重其社交意识和相应的反应能力。

Abstract: This paper investigates the specific scenario of high-intensity
confrontations between humans and robots, to understand how robots can defuse
the conflict. It focuses on the effectiveness of using five different affective
expression modalities as main drivers for defusing the conflict. The aim is to
discover any strengths or weaknesses in using each modality to mitigate the
hostility that people feel towards a poorly performing robot. The defusing of
the situation is accomplished by making the robot better at acknowledging the
conflict and by letting it express remorse. To facilitate the tests, we used a
custom affective robot in a simulated conflict situation with 105 test
participants. The results show that all tested expression modalities can
successfully be used to defuse the situation and convey an acknowledgment of
the confrontation. The ratings were remarkably similar, but the movement
modality was different (ANON p$<$.05) than the other modalities. The test
participants also had similar affective interpretations on how impacted the
robot was of the confrontation across all expression modalities. This indicates
that defusing a high-intensity interaction may not demand special attention to
the expression abilities of the robot, but rather require attention to the
abilities of being socially aware of the situation and reacting in accordance
with it.

</details>


### [283] [Real-Time Iteration Scheme for Diffusion Policy](https://arxiv.org/abs/2508.05396)
*Yufei Duan,Hang Yin,Danica Kragic*

Main category: cs.RO

TL;DR: 受 RTI 方案启发，提出了一种尺度变换的扩散推理方法，显著减少了机器人操作中的推理时间，而无需额外训练或策略修改。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略推理时间长，且需要在下一个预测之前执行动作块以保持动作一致性，这限制了它们在延迟关键任务或短周期时间简单任务中的应用。虽然已有方法尝试通过蒸馏或替代策略结构来加速推理，但这些方法通常需要额外的训练，对于大型机器人模型而言资源消耗大。

Method: 提出了一种受实时迭代（RTI）方案启发的扩散推理新方法，该方案利用先前时间步的解作为后续迭代的初始猜测。为了有效处理机器人操作中的离散动作（如抓取），提出了一种基于尺度的方法。

Result: 在广泛的模拟实验中，与使用完整步长去噪的扩散策略相比，推理时间显著减少，同时整体性能相当。理论上还提供了可用于估计初始去噪步骤的收缩性条件。

Conclusion: 该方法通过引入基于实时迭代（RTI）方案的尺度变换方法，在不进行蒸馏或策略重新设计的情况下，显著减少了推理时间，同时保持了与完整步长去噪的扩散策略相当的性能。

Abstract: Diffusion Policies have demonstrated impressive performance in robotic
manipulation tasks. However, their long inference time, resulting from an
extensive iterative denoising process, and the need to execute an action chunk
before the next prediction to maintain consistent actions limit their
applicability to latency-critical tasks or simple tasks with a short cycle
time. While recent methods explored distillation or alternative policy
structures to accelerate inference, these often demand additional training,
which can be resource-intensive for large robotic models. In this paper, we
introduce a novel approach inspired by the Real-Time Iteration (RTI) Scheme, a
method from optimal control that accelerates optimization by leveraging
solutions from previous time steps as initial guesses for subsequent
iterations. We explore the application of this scheme in diffusion inference
and propose a scaling-based method to effectively handle discrete actions, such
as grasping, in robotic manipulation. The proposed scheme significantly reduces
runtime computational costs without the need for distillation or policy
redesign. This enables a seamless integration into many pre-trained
diffusion-based models, in particular, to resource-demanding large models. We
also provide theoretical conditions for the contractivity which could be useful
for estimating the initial denoising step. Quantitative results from extensive
simulation experiments show a substantial reduction in inference time, with
comparable overall performance compared with Diffusion Policy using full-step
denoising. Our project page with additional resources is available at:
https://rti-dp.github.io/.

</details>


### [284] [DistillDrive: End-to-End Multi-Mode Autonomous Driving Distillation by Isomorphic Hetero-Source Planning Model](https://arxiv.org/abs/2508.05402)
*Rui Yu,Xianghang Zhang,Runkai Zhao,Huaicheng Yan,Meng Wang*

Main category: cs.RO

TL;DR: DistillDrive是一个创新的端到端自动驾驶模型，通过知识蒸馏和多样化实例模仿，提高了决策鲁棒性和性能，显著降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶模型过度关注自身车辆状态，缺乏面向规划的理解，这限制了整体决策过程的鲁棒性。本研究旨在通过引入DistillDrive来解决这个问题。

Method: DistillDrive是一个基于知识蒸馏的端到端自动驾驶模型。它使用一个基于结构化场景表示的规划模型作为教师模型，并利用其多样化的规划实例作为端到端模型的学习目标。此外，该模型还结合了强化学习来优化状态到决策的映射，并利用生成模型构建面向规划的实例，以促进潜在空间中的复杂交互。

Result: 与基线模型相比，DistillDrive在nuScenes和NAVSIM数据集上实现了50%的碰撞率降低和3个百分点的闭环性能提升。

Conclusion: DistillDrive通过利用多样化的实例模仿来增强多模态运动特征学习，并在nuScenes和NAVSIM数据集上进行了验证，与基线模型相比，碰撞率降低了50%，闭环性能提高了3个百分点。

Abstract: End-to-end autonomous driving has been recently seen rapid development,
exerting a profound influence on both industry and academia. However, the
existing work places excessive focus on ego-vehicle status as their sole
learning objectives and lacks of planning-oriented understanding, which limits
the robustness of the overall decision-making prcocess. In this work, we
introduce DistillDrive, an end-to-end knowledge distillation-based autonomous
driving model that leverages diversified instance imitation to enhance
multi-mode motion feature learning. Specifically, we employ a planning model
based on structured scene representations as the teacher model, leveraging its
diversified planning instances as multi-objective learning targets for the
end-to-end model. Moreover, we incorporate reinforcement learning to enhance
the optimization of state-to-decision mappings, while utilizing generative
modeling to construct planning-oriented instances, fostering intricate
interactions within the latent space. We validate our model on the nuScenes and
NAVSIM datasets, achieving a 50\% reduction in collision rate and a 3-point
improvement in closed-loop performance compared to the baseline model. Code and
model are publicly available at https://github.com/YuruiAI/DistillDrive

</details>


### [285] [Computational Design and Fabrication of Modular Robots with Untethered Control](https://arxiv.org/abs/2508.05410)
*Manas Bhargava,Takefumi Hiraki,Malina Strugaru,Michal Piovarci,Chiara Daraio,Daisuke Iwai,Bernd Bickel*

Main category: cs.RO

TL;DR: 该研究提出了一种利用分布式驱动、3D打印骨骼和液晶弹性体肌肉来设计和控制仿生机器人。该系统实现了机器人的模块化组装、无连接的分布式控制和复杂的变形能力。此外，还开发了用于优化机器人设计和控制的计算工具。最终目标是创造出更接近生物体能力的机器人。


<details>
  <summary>Details</summary>
Motivation: 模仿自然生物体的广泛适应性和运动范围，解决现有软机器人系统优化单一功能、无法按需改变形态或功能以及通常受限于笨重控制系统的问题。

Method: 提出了一种结合3D打印骨骼和液晶弹性体（LCE）肌肉作为轻质执行器的新型构建块，实现了肌肉骨骼机器人的模块化组装。开发了对红外辐射做出反应的LCE杆，从而实现了对分布式骨骼网络的局部和无连接控制，进而实现了机器人的全局变形。此外，为了利用广泛的设计空间，开发了两个计算工具：一个用于优化机器人的骨骼图，实现多种目标变形；另一个用于共同优化骨骼设计和控制步态以实现目标运动。

Result: 通过构建几个机器人来验证该系统，这些机器人展示了复杂形状的变形、不同的控制方案以及对环境的适应性。

Conclusion: 该系统集成了模块化材料构建、无连接和分布式控制以及计算设计方面的进步，从而引入了新一代机器人，使其能够更接近生物体的能力。

Abstract: Natural organisms use distributed actuation via their musculoskeletal systems
to adapt their gait for traversing diverse terrains or to morph their bodies to
perform varied tasks. A longstanding challenge in the field of robotics is to
mimic this extensive adaptability and range of motion. This has led humans to
develop various soft robotic systems that emulate natural organisms. However,
such systems are generally optimized for a single functionality, lack the
ability to change form or function on demand, or are often tethered to bulky
control systems. To address these challenges, we present our framework for
designing and controlling robots that mimic nature's blueprint by utilizing
distributed actuation. We propose a novel building block that combines
3D-printed bones with liquid crystal elastomer (LCE) muscles as lightweight
actuators and enables the modular assembly of musculoskeletal robots. We
developed LCE rods that contract in response to infrared radiation, thereby
achieving local and untethered control over the distributed network of bones,
which in turn results in global deformation of the robot. Furthermore, to
capitalize on the extensive design space, we develop two computational tools:
one to optimize the robot's skeletal graph, enabling multiple target
deformations, and another to co-optimize the skeletal designs and control gaits
to achieve target locomotion. We validate our system by building several robots
that show complex shape morphing, varying control schemes, and adaptability to
their environment. Our system integrates advances in modular material building,
untethered and distributed control, and computational design to introduce a new
generation of robots that brings us closer to the capabilities of living
organisms.

</details>


### [286] [Do Robots Really Need Anthropomorphic Hands?](https://arxiv.org/abs/2508.05415)
*Alexander Fabisch,Wadhah Zai El Amri,Chandandeep Singh,Nicolás Navarro-Guerrero*

Main category: cs.RO

TL;DR: 本文旨在探讨机器人是否需要拟人化的手，通过分析人手、现有机器人手和假肢手，以及它们所能实现的技能。研究发现，手腕灵活性和手指内收/外展对操作至关重要，而手指数量和自由度并非越多越好，三指手是简洁性和灵活性间的良好折衷。非拟人化设计或六指手甚至能提供更高的灵活性，表明人手并非唯一最优解。


<details>
  <summary>Details</summary>
Motivation: 为了回答人类手（及其相关的生物力学特性、传感器和控制机制）是否是机器人追求的理想——我们是否真的需要拟人化的机器人手？

Method: 对人手进行了概述，比较了市面上可买到的机器人手和假肢手，并对它们能够实现的机械手和技能进行了系统性回顾。

Result: 对人手进行了概述，比较了市面上可买到的机器人手和假肢手，并对它们能够实现的机械手和技能进行了系统性回顾。研究发现，手腕灵活性和手指内收/外展对于操作能力很重要。相比之下，增加手指、驱动器或自由度的数量通常不是必需的。三指手在简洁性和灵活性之间取得了良好的折衷。非拟人化的双手设计（具有两个相对的手指对）或六指人手可以进一步提高灵活性，这表明人手可能不是最优的。

Conclusion: 虽然常以复杂的五指手为目标，但并非所有任务都需要。手腕的灵活性和手指的内收/外展对操作能力很重要。相比之下，增加手指、驱动器或自由度的数量通常不是必需的。三指手在简洁性和灵活性之间取得了良好的折衷。非拟人化的双手设计（具有两个相对的手指对）或六指人手可以进一步提高灵活性，这表明人手可能不是最优的。

Abstract: Human manipulation skills represent a pinnacle of their voluntary motor
functions, requiring the coordination of many degrees of freedom and processing
of high-dimensional sensor input to achieve such a high level of dexterity.
Thus, we set out to answer whether the human hand, with its associated
biomechanical properties, sensors, and control mechanisms, is an ideal that we
should strive for in robotics-do we really need anthropomorphic robotic hands?
  This survey can help practitioners to make the trade-off between hand
complexity and potential manipulation skills. We provide an overview of the
human hand, a comparison of commercially available robotic and prosthetic
hands, and a systematic review of hand mechanisms and skills that they are
capable of. This leads to follow-up questions. What is the minimum requirement
for mechanisms and sensors to implement most skills that a robot needs? What is
missing to reach human-level dexterity? Can we improve upon human dexterity?
  Although complex five-fingered hands are often used as the ultimate goal for
robotic manipulators, they are not necessary for all tasks. We found that wrist
flexibility and finger abduction/adduction are important for manipulation
capabilities. On the contrary, increasing the number of fingers, actuators, or
degrees of freedom is often not necessary. Three fingers are a good compromise
between simplicity and dexterity. Non-anthropomorphic hand designs with two
opposing pairs of fingers or human hands with six fingers can further increase
dexterity, suggesting that the human hand may not be the optimum.

</details>


### [287] [CleanUpBench: Embodied Sweeping and Grasping Benchmark](https://arxiv.org/abs/2508.05543)
*Wenbo Li,Guanting Chen,Tao Zhao,Jiyao Wang,Tianxin Hu,Yuwen Liao,Weixiang Guo,Shenghai Yuan*

Main category: cs.RO

TL;DR: CleanUpBench 是一个在 NVIDIA Isaac Sim 中构建的、可复现且可扩展的基准测试，用于评估现实室内清洁场景中的具身智能体。它填补了学术研究与现实应用之间的差距，并提供了一个可扩展的测试平台。


<details>
  <summary>Details</summary>
Motivation: 现有的 Embodied AI 基准测试主要针对复杂的人形机器人或大规模模拟，与现实世界的部署相去甚远。然而，在现实世界中，具备清扫和抓取双重能力的移动清洁机器人正在迅速涌现。目前缺乏一个系统性评估这些机器人在结构化、多目标清洁任务中的基准测试。

Method: CleanUpBench 在 NVIDIA Isaac Sim 中模拟了一个配备清扫机制和六自由度机械臂的移动服务机器人，并包含手动设计的环境和程序生成的布局，以评估泛化能力。

Result: 该基准测试包括手动设计的环境和程序生成的布局，以评估泛化能力，并提供涵盖任务完成、空间效率、运动质量和控制性能的全面评估套件。此外，还提供了基于启发式策略和基于地图规划的基线代理。

Conclusion: CleanUpBench 填补了低级技能评估和全场景测试之间的空白，为日常环境中的具身智能提供了可扩展的测试平台。

Abstract: Embodied AI benchmarks have advanced navigation, manipulation, and reasoning,
but most target complex humanoid agents or large-scale simulations that are far
from real-world deployment. In contrast, mobile cleaning robots with dual mode
capabilities, such as sweeping and grasping, are rapidly emerging as realistic
and commercially viable platforms. However, no benchmark currently exists that
systematically evaluates these agents in structured, multi-target cleaning
tasks, revealing a critical gap between academic research and real-world
applications. We introduce CleanUpBench, a reproducible and extensible
benchmark for evaluating embodied agents in realistic indoor cleaning
scenarios. Built on NVIDIA Isaac Sim, CleanUpBench simulates a mobile service
robot equipped with a sweeping mechanism and a six-degree-of-freedom robotic
arm, enabling interaction with heterogeneous objects. The benchmark includes
manually designed environments and one procedurally generated layout to assess
generalization, along with a comprehensive evaluation suite covering task
completion, spatial efficiency, motion quality, and control performance. To
support comparative studies, we provide baseline agents based on heuristic
strategies and map-based planning. CleanUpBench bridges the gap between
low-level skill evaluation and full-scene testing, offering a scalable testbed
for grounded, embodied intelligence in everyday settings.

</details>


### [288] [Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator](https://arxiv.org/abs/2508.05584)
*Van Cuong Pham,Minh Hai Tran,Phuc Anh Nguyen,Ngoc Son Vu,Nga Nguyen Thi*

Main category: cs.RO

TL;DR: AFSMC通过结合模糊逻辑和滑模控制，提高了圆柱形机器人机械臂的跟踪精度和鲁棒性，在工业应用中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高圆柱形机器人机械臂的轨迹跟踪性能，这些机械臂广泛用于数控和3D打印等应用。

Method: 提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法，该方法集成了模糊逻辑和滑模控制（SMC），其中模糊逻辑用于近似系统的不确定动力学，而SMC用于确保强大的性能。

Result: 仿真结果表明，与传统方法相比，AFSMC在轨迹跟踪精度、稳定性和抗干扰能力方面均有显著提高。

Conclusion: 该研究证实了AFSMC在控制机器人机械臂方面的有效性，提高了工业机器人应用的精度。

Abstract: This research proposes a robust adaptive fuzzy sliding mode control (AFSMC)
approach to enhance the trajectory tracking performance of cylindrical robotic
manipulators, extensively utilized in applications such as CNC and 3D printing.
The proposed approach integrates fuzzy logic with sliding mode control (SMC) to
bolster adaptability and robustness, with fuzzy logic approximating the
uncertain dynamics of the system, while SMC ensures strong performance.
Simulation results in MATLAB/Simulink demonstrate that AFSMC significantly
improves trajectory tracking accuracy, stability, and disturbance rejection
compared to traditional methods. This research underscores the effectiveness of
AFSMC in controlling robotic manipulators, contributing to enhanced precision
in industrial robotic applications.

</details>


### [289] [Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation](https://arxiv.org/abs/2508.05635)
*Yue Liao,Pengfei Zhou,Siyuan Huang,Donglin Yang,Shengcong Chen,Yuxin Jiang,Yue Hu,Jingbin Cai,Si Liu,Jianlan Luo,Liliang Chen,Shuicheng Yan,Maoqing Yao,Guanghui Ren*

Main category: cs.RO

TL;DR: Genie Envisioner 是一个集成了策略学习、评估和模拟的机器人操作平台，使用视频生成模型（GE-Base、GE-Act）和神经模拟器（GE-Sim），并配有 EWMBench 基准套件，以实现可扩展的指令驱动具身智能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在创建一个统一的平台，用于机器人操作，该平台能够集成策略学习、评估和模拟，并能处理指令驱动的通用目的具身智能。

Method: Genie Envisioner (GE) 是一个集成了策略学习、评估和模拟的统一视频生成框架。其核心是 GE-Base，一个大规模、指令条件视频扩散模型，用于捕捉机器人交互的动态。GE-Act 是一个轻量级、流匹配解码器，用于将潜在表征映射到动作轨迹。GE-Sim 是一个动作条件神经模拟器，用于生成高保真模拟。EWMBench 是一个标准化基准套件，用于衡量视觉保真度、物理一致性和指令-动作对齐。

Result: Genie Envisioner 平台通过 GE-Base、GE-Act 和 GE-Sim 组件，实现了对机器人交互的强大建模和推理能力。EWMBench 基准套件为评估和改进这些系统提供了标准。该平台能够实现精确且可泛化的策略推理，并支持可扩展的评估和训练。

Conclusion: Genie Envisioner 是一个统一的世界基础平台，用于机器人操作，将策略学习、评估和模拟集成在单一的视频生成框架内。它通过 GE-Base（一个大规模、指令条件视频扩散模型）、GE-Act（一个将潜在表征映射到可执行动作轨迹的轻量级流匹配解码器）以及 GE-Sim（一个用于闭环策略开发的动作条件神经模拟器）实现了可扩展且实用的指令驱动、通用目的的具身智能基础。EWMBench 基准套件用于衡量视觉保真度、物理一致性和指令-动作对齐。

Abstract: We introduce Genie Envisioner (GE), a unified world foundation platform for
robotic manipulation that integrates policy learning, evaluation, and
simulation within a single video-generative framework. At its core, GE-Base is
a large-scale, instruction-conditioned video diffusion model that captures the
spatial, temporal, and semantic dynamics of real-world robotic interactions in
a structured latent space. Built upon this foundation, GE-Act maps latent
representations to executable action trajectories through a lightweight,
flow-matching decoder, enabling precise and generalizable policy inference
across diverse embodiments with minimal supervision. To support scalable
evaluation and training, GE-Sim serves as an action-conditioned neural
simulator, producing high-fidelity rollouts for closed-loop policy development.
The platform is further equipped with EWMBench, a standardized benchmark suite
measuring visual fidelity, physical consistency, and instruction-action
alignment. Together, these components establish Genie Envisioner as a scalable
and practical foundation for instruction-driven, general-purpose embodied
intelligence. All code, models, and benchmarks will be released publicly.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [290] [Real-Time Doppler and Ionospheric Dispersion Correction Techniques for Arbitrary Waveforms Utilizing GPU Compute](https://arxiv.org/abs/2508.04951)
*Daniel J. Vickers,A. H. Mack,Idahosa A. Osaretin*

Main category: eess.SP

TL;DR: 文章提出并分析了用于雷达数字信号处理的任意波形的通用多普勒和离子层校正算法，并重点介绍了在 GPU 上进行软件实现的效率。研究确定了两种算法（FFT 和 sinc 插值），它们在精度和实时性方面都表现出色，并易于集成到软件定义无线电系统中。


<details>
  <summary>Details</summary>
Motivation: 过去，雷达数字信号处理的通用要求，如离子层失真和多普勒频散校正，需要雷达专用的硬件来实现。然而，现代通用计算系统的发展使得使用非雷达专用的高性能计算进行实时数字信号处理变得更加可行。本研究的动机是探索和分析用于雷达数字信号处理的任意波形的通用多普勒和离子层校正算法，并提供在 GPU 硬件上高效实现这些算法的软件注意事项。

Method: 通过 FFT 和 sinc 插值实现算法的软件实现。

Result: 我们确定了两种色散校正算法：一种基于 FFT 的方法用于离子层色散，一种通过 sinc 插值进行数值插值的方法用于多普勒色散。这两种算法都能够以与波形特定的分析方法相媲美的精度来补偿色散，并且能够在单个 NVIDIA H100 GPU 上实时执行。

Conclusion: 该分析包括性能指标，例如执行时间和误差校正精度。我们还为雷达信号处理中的应用提供了建议。我们确定了两种色散校正算法：一种基于 FFT 的方法用于离子层色散，一种通过 sinc 插值进行数值插值的方法用于多普勒色散。这两种算法都能够以与波形特定的分析方法相媲美的精度来补偿色散，并且能够在单个 NVIDIA H100 GPU 上实时执行。这些方法与波形无关，并直接应用于样本，提高了系统灵活性，并使它们易于集成到现有的软件定义无线电系统中。

Abstract: General requirements for radar digital signal processing are ionospheric
distortion and Doppler dispersion correction, which has historically required
radar-specific hardware to implement in real time. Although analog solutions
are computationally efficient, they often come with system design drawbacks
which limit waveform flexibility and can result in an overall increase of
system complexity. With improvements in modern general compute systems,
real-time digital signal processing is becoming more realizable using
non-radar-specific high-performance compute. In this paper, we present an
analysis of general Doppler and ionospheric correction algorithms for arbitrary
waveforms for radar digital signal processing. We also include considerations
for efficient implementation of these algorithms in software, specifically
using GPU hardware. This analysis includes metrics of performance such as
execution time and error correction accuracy. We also provide recommendations
for application in radar signal processing. We identify two algorithms for
dispersion correction: an FFT-based method for ionospheric dispersion and a
numerical interpolation method via sinc interpolation for Doppler dispersion.
Both of these algorithms are able to compensate for dispersion equivalent in
accuracy to waveform-specific analytical methods and were able to be performed
in real-time on a single NVIDIA H100 GPU. These methods are waveform agnostic
and applied directly to the samples, improving system flexibility and making
them easy to incorporate into existing software-defined radio systems.

</details>


### [291] [Anti-Jamming Sensing with Distributed Reconfigurable Intelligent Metasurface Antennas](https://arxiv.org/abs/2508.04964)
*Zhaowei Wang,Yunsong Huang,Weicheng Liu,Hui-Ming Wang*

Main category: eess.SP

TL;DR: 射频信号用于无线传感，但易受环境影响。本研究提出使用分布式可重构智能超表面天线（RIMSA）进行传感，并通过深度强化学习优化波束形成，神经网络映射信号，结合SINR的损失函数来应对干扰。结果显示，分布式RIMSA系统在恶劣环境下和干扰攻击下均优于集中式系统，实现了高精度传感。


<details>
  <summary>Details</summary>
Motivation: 传统的射频传感方法容易受到不可预测和不利的无线环境（如衰落和噪声）的影响，导致传感精度下降。

Method: 提出了一种深度强化学习（DRL）算法来优化波束形成模式，并使用神经网络将接收信号映射到传感结果。此外，还设计了一种结合信干噪比（SINR）的损失函数，以应对干扰。

Result: 仿真结果表明，与集中式实现相比，所提出的分布式RIMSA系统能够实现更高效的传感性能，并且能更好地克服环境影响。该方法还能确保在高精度传感性能下抵御干扰攻击。

Conclusion: 该研究提出了一种分布式智能反射面天线（RIMSA）系统，用于无线传感，即使在存在干扰和恶劣传播条件的情况下，也能实现高效和高精度的传感性能。

Abstract: The utilization of radio frequency (RF) signals for wireless sensing has
garnered increasing attention. However, the radio environment is unpredictable
and often unfavorable, the sensing accuracy of traditional RF sensing methods
is often affected by adverse propagation channels from the transmitter to the
receiver, such as fading and noise. In this paper, we propose employing
distributed Reconfigurable Intelligent Metasurface Antennas (RIMSA) to detect
the presence and location of objects where multiple RIMSA receivers (RIMSA Rxs)
are deployed on different places. By programming their beamforming patterns,
RIMSA Rxs can enhance the quality of received signals. The RF sensing problem
is modeled as a joint optimization problem of beamforming pattern and mapping
of received signals to sensing outcomes. To address this challenge, we
introduce a deep reinforcement learning (DRL) algorithm aimed at calculating
the optimal beamforming patterns and a neural network aimed at converting
received signals into sensing outcomes. In addition, the malicious attacker may
potentially launch jamming attack to disrupt sensing process. To enable
effective sensing in interferenceprone environment, we devise a combined loss
function that takes into account the Signal to Interference plus Noise Ratio
(SINR) of the received signals. The simulation results show that the proposed
distributed RIMSA system can achieve more efficient sensing performance and
better overcome environmental influences than centralized implementation.
Furthermore, the introduced method ensures high-accuracy sensing performance
even under jamming attack.

</details>


### [292] [Localized Kernel Methods for Signal Processing](https://arxiv.org/abs/2508.04978)
*Sippanon Kitimoon*

Main category: eess.SP

TL;DR: 提出两种基于局部核的信号处理方法，用于在噪声条件下恢复参数。一种用于多维指数模型，另一种用于分离线性啁啾分量。两种方法都避免了子空间分解或稀疏性正则化，并在实验中证明了其鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 在噪声条件下，为参数恢复开发新的信号处理方法，特别关注多维指数模型和时间局部信号段中的线性啁啾分量。

Method: 第一种方法使用局部三角多项式核来估计多维指数模型中的频率和幅度，并提出了一种坐标投影和配准方法。第二种方法使用信号分离算子（SSO）的变体来分离线性啁啾分量，通过FFT滤波、聚类和分段线性回归进行估计。

Result: 第一种方法在单变量情况下优于MUSIC和ESPRIT，在多变量情况下，以更少的样本量实现了高恢复精度。第二种方法能够在低至-30 dB的信噪比下恢复相交和不连续的啁啾信号。

Conclusion: 本文提出的两种基于局部核的信号处理方法在参数恢复方面表现出鲁棒性和有效性，特别是在低信噪比和样本量受限的情况下。

Abstract: This dissertation presents two signal processing methods using specially
designed localized kernels for parameter recovery under noisy condition. The
first method addresses the estimation of frequencies and amplitudes in
multidimensional exponential models. It utilizes localized trigonometric
polynomial kernels to detect the multivariate frequencies, followed by a more
detailed parameter estimation. We compare our method with MUSIC and ESPRIT,
which are classical subspace-based algorithms widely used for estimating the
parameters of exponential signals. In the univariate case, the method
outperforms MUSIC and ESPRIT under low signal-to-noise ratios. For the
multivariate case, we develop a coordinate-wise projection and registration
approach that achieves high recovery accuracy using significantly fewer samples
than other methods.
  The second method focuses on separating linear chirp components from
time-localized signal segments. A variant of the Signal Separation Operator
(SSO) is constructed using a localized kernel. Instantaneous frequency
estimates are obtained via FFT-based filtering, then clustered and fitted with
piecewise linear regression. The method operates without prior knowledge of the
number of components and is shown to recover intersecting and discontinuous
chirps at SNR levels as low as -30 dB.
  Both methods share an idea based on localized kernels and efficient FFT-based
implementation, and neither requires subspace decomposition or sparsity
regularization. Experimental results confirm the robustness and tractability of
the proposed approaches across a range of simulated data conditions. Potential
extensions include application to nonlinear chirps, adaptive kernel design, and
signal classification using extracted features.

</details>


### [293] [Power-Constrained and Quantized MIMO-RSMA Systems with Imperfect CSIT: Joint Precoding, Antenna Selection, and Power Control](https://arxiv.org/abs/2508.05080)
*Jiwon Sung,Seokjun Park,Jinseok Choi*

Main category: eess.SP

TL;DR: 本文提出了一种用于 RSMA 系统的联合预编码、天线选择和功率控制算法，以最大化 SE。该算法通过将问题分解为子问题来解决，并使用梯度下降等技术进行优化。仿真结果表明，中分辨率 DAC 可能比低分辨率 DAC 更节能。


<details>
  <summary>Details</summary>
Motivation: 为了利用基站可用功率的全部潜力，研究了用于总功率预算的联合预编码、天线选择和发射功率控制算法。

Method: 本文提出了一种联合预编码、天线选择和发射功率控制算法，用于基站的总功率预算。通过定义遍历和 SE，处理不完美的 CSIT，并使用近似技术使问题更易处理，从而重新制定了和 SE 最大化问题。然后，将问题分解为预编码方向和功率控制子问题。通过识别优越的拉格朗日平稳点解决了预编码方向子问题，并使用梯度下降解决了功率控制子问题。还提出了一种更适用于大规模 MIMO 系统的复杂度降低方法。

Result: 仿真结果验证了所提出的算法，并表明中分辨率 DAC 可能比低分辨率 DAC 更节能。

Conclusion: 仿真结果不仅验证了所提出的算法，而且表明，当利用基站功率预算的全部潜力时，具有 8-11 位分辨率的中分辨率数模转换器（DAC）实际上比低分辨率数模转换器更节能。

Abstract: To utilize the full potential of the available power at a base station (BS),
we propose a joint precoding, antenna selection, and transmit power control
algorithm for a total power budget at the BS. We formulate a sum spectral
efficiency (SE) maximization problem for downlink multi-user multiple-input
multiple-output (MIMO) rate-splitting multiple access (RSMA) systems with
arbitrary-resolution digital-to-analog converters (DACs). We reformulate the
problem by defining the ergodic sum SE using the conditional average rate
approach to handle imperfect channel state information at the transmitter
(CSIT), and by using approximation techniques to make the problem more
tractable. Then, we decompose the problem into precoding direction and power
control subproblems. We solve the precoding direction subproblem by identifying
a superior Lagrangian stationary point, and the power control subproblem using
gradient descent. We also propose a complexity-reduction approach that is more
suitable for massive MIMO systems. Simulation results not only validate the
proposed algorithm but also reveal that when utilizing the full potential of
the power budget at the BS, medium-resolution DACs with 8-11 bits may actually
be more power-efficient than low-resolution DACs.

</details>


### [294] [Digital Twin Channel-Aided CSI Prediction: A Environment-based Subspace Extraction Approach for Achieving Low Overhead and Robustness](https://arxiv.org/abs/2508.05142)
*Yichen Cai,Jianhua Zhang,Li Yu,Zhen Zhang,Yuxiang Zhang,Lianzheng Shi,Yuelong Qiu*

Main category: eess.SP

TL;DR: A new method called EB-P2WCP uses environment-specific information (EB) from digital twin maps to predict 6G communication channels more efficiently, reducing pilot overhead and maintaining accuracy even in challenging conditions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to meet the robust and high-speed communication requirements of 6G mobile communication systems in complex scenarios by reducing system overhead through sensing- and AI-based digital twin channel (DTC) techniques.

Method: The paper proposes an environment-specific channel subspace basis (EB)-aided partial-to-whole channel state information (CSI) prediction method (EB-P2WCP). EB, extracted from a digital twin map, characterizes static environmental properties. This prior information is fused with real-time local CSI to predict the spatial-frequency domain channel for present and future time instances using an EB-based partial-to-whole CSI prediction network (EB-P2WNet).

Result: The EB-P2WCP method shows significant benefits under low SNR and pilot ratio conditions, reducing pilot overhead by up to 50%. It also maintains robustness against multi-user interference, tolerating 3-meter localization errors with only a 0.5 dB NMSE increase, and predicts CSI for the next channel coherent time within 1.3 milliseconds.

Conclusion: The proposed EB-P2WCP method enhances channel prediction for 6G communication systems by utilizing environment-specific channel subspace basis (EB).

Abstract: To meet the robust and high-speed communication requirements of the
sixth-generation (6G) mobile communication system in complex scenarios,
sensing- and artificial intelligence (AI)-based digital twin channel (DTC)
techniques become a promising approach to reduce system overhead. In this
paper, we propose an environment-specific channel subspace basis (EB)-aided
partial-to-whole channel state information (CSI) prediction method (EB-P2WCP)
for realizing DTC-enabled low-overhead channel prediction. Specifically, EB is
utilized to characterize the static properties of the electromagnetic
environment, which is extracted from the digital twin map, serving as
environmental information prior to the prediction task. Then, we fuse EB with
real-time estimated local CSI to predict the entire spatial-frequency domain
channel for both the present and future time instances. Hence, an EB-based
partial-to-whole CSI prediction network (EB-P2WNet) is designed to achieve a
robust channel prediction scheme in various complex scenarios. Simulation
results indicate that incorporating EB provides significant benefits under low
signal-to-noise ratio and pilot ratio conditions, achieving a reduction of up
to 50% in pilot overhead. Additionally, the proposed method maintains
robustness against multi-user interference, tolerating 3-meter localization
errors with only a 0.5 dB NMSE increase, and predicts CSI for the next channel
coherent time within 1.3 milliseconds.

</details>


### [295] [Optimization of Liquid Lens-based Imaging Receiver for MIMO VLC Systems](https://arxiv.org/abs/2508.05204)
*Kapila W. S. Palitharathna,Christodoulos Skouroumounis,Ioannis Krikidis*

Main category: eess.SP

TL;DR: 本论文提出了一种基于液态透镜的 MIMO VLC 系统，通过调整透镜来降低信道相关性，从而提高 BER 性能。该系统在随机方向下比传统系统有显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高多输入多输出（MIMO）可见光通信（VLC）系统的性能，通过动态调整液态透镜的焦距和方向角来降低 MIMO 信道增益之间的空间相关性，从而提高误比特率（BER）性能。液态透镜相比静态透镜具有自适应性，能够应对用户移动和接收器方向随机变化等动态条件。

Method: 提出了一种基于液态透镜的成像接收器，并通过优化透镜的焦距和方向来最小化系统的误比特率（BER）。由于信道模型复杂，引入了两种透镜调整方案：($i$) CLS 方案和 ($ii$) VULO 方案。

Result: 所提出的液态透镜系统在各种随机接收器方向条件下，与传统的基于静态透镜的接收器相比，在误比特率（BER）方面得到了显著改善。具体而言，在 $10^{\circ}$ 的随机接收器方向方差下，采用所提出的液态透镜可将 BER 从 $4	imes 10^{-2}$ 提高到 $5	imes 10^{-4}$。

Conclusion: 所提出的基于液态透镜的系统在各种随机接收器方向条件下，与传统的基于静态透镜的接收器相比，在误比特率（BER）方面得到了显著改善。具体而言，在 $10^{\circ}$ 的随机接收器方向方差下，采用所提出的液态透镜可将 BER 从 $4	imes 10^{-2}$ 提高到 $5	imes 10^{-4}$。

Abstract: In this paper, a liquid lens-based imaging receiver is proposed for
multiple-input multiple-output (MIMO) visible light communication (VLC)
systems. By dynamically adjusting the focal length and orientation angles of
the liquid lens, the spatial correlation between MIMO channel gains is reduced,
leading to enhanced bit-error rate (BER) performance. Unlike static lenses,
liquid lenses offer adaptability in dynamic conditions, including user mobility
and random receiver orientation. An accurate mathematical framework is
developed to model the channel gains of the proposed system, and an
optimization problem is formulated to minimize its BER. Due to the complexity
of the resulting channel model, two lens adjustment schemes, namely, ($i$) the
CLS scheme, and ($ii$) the VULO scheme are introduced. Numerical results
demonstrate that the proposed liquid lens-based system offers substantial BER
improvements over conventional static lens-based receivers across a wide range
of random receiver orientation conditions. Specifically, at a random receiver
orientation variance of $10^{\circ}$, the BER is improved from $4\times
10^{-2}$ to $5\times 10^{-4}$ by employing the proposed liquid lens.

</details>


### [296] [Deep Learning Based Dynamic Environment Reconstruction for Vehicular ISAC Scenarios](https://arxiv.org/abs/2508.05226)
*Junzhe Song,Ruisi He,Mi Yang,Zhengyu Zhang,Bingcheng Liu,Jiahui Han,Haoxiang Zhang,Bo Ai*

Main category: eess.SP

TL;DR: 通过多阶段深度学习网络，利用ISAC信号重建高精度的动态车辆环境，解决了现有技术的局限性，提高了准确性和时间一致性，并具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC（集成传感与通信）技术在未来智能交通系统中至关重要，能够通过无线信号重用实现车辆对周围环境的感知和重建，从而减少或无需激光雷达或雷达等额外传感器。然而，现有的ISAC重建方法在跟踪动态场景的准确性和时间一致性方面存在不足，限制了其在现实世界的应用。

Method: 首先，基于真实世界的城市街道场景，利用多模态测量建立联合信道环境数据集。然后，开发了一个多阶段深度学习网络，包括场景解码器（识别建筑物、树木等环境上下文）、聚类中心解码器（通过定位主要散射中心预测粗略的空间布局）和点云解码器（恢复周围环境的精细几何结构和形状）。

Result: 实验结果表明，该方法在动态环境重建方面达到了高质量，Chamfer距离为0.29，F Score@1%为0.87。复杂度分析也证明了该方法在实时场景中的效率和实际适用性。

Conclusion: 该研究提出了一种基于ISAC信道的深度学习框架，用于车辆环境重建，解决了现有方法在动态场景跟踪方面的准确性和时间一致性不足的问题，为未来智能交通的低成本环境重建提供了途径。

Abstract: Integrated Sensing and Communication (ISAC) technology plays a critical role
in future intelligent transportation systems, by enabling vehicles to perceive
and reconstruct the surrounding environment through reuse of wireless signals,
thereby reducing or even eliminating the need for additional sensors such as
LiDAR or radar. However, existing ISAC based reconstruction methods often lack
the ability to track dynamic scenes with sufficient accuracy and temporal
consistency, limiting the real world applicability. To address this limitation,
we propose a deep learning based framework for vehicular environment
reconstruction by using ISAC channels. We first establish a joint channel
environment dataset based on multi modal measurements from real world urban
street scenarios. Then, a multistage deep learning network is developed to
reconstruct the environment. Specifically, a scene decoder identifies the
environmental context such as buildings, trees and so on; a cluster center
decoder predicts coarse spatial layouts by localizing dominant scattering
centers; a point cloud decoder recovers fine grained geometry and structure of
surrounding environments. Experimental results demonstrate that the proposed
method achieves high-quality dynamic environment reconstruction with a Chamfer
Distance of 0.29 and F Score@1% of 0.87. In addition, complexity analysis
demonstrates the efficiency and practical applicability of the method in real
time scenarios. This work provides a pathway toward low cost environment
reconstruction based on ISAC for future intelligent transportation.

</details>


### [297] [Unifying Common Signal Analyses with Instantaneous Time-Frequency Atoms](https://arxiv.org/abs/2508.05380)
*Steven Sandoval,Phillip L. De Leon*

Main category: eess.SP

TL;DR: 本研究提出了一个统一多种信号分析方法的框架，并通过二次线性调频（chirplet）理论推导了瞬时谱（IS）的闭合形式表达式，解决了先前工作中缺乏具体计算细节的问题。


<details>
  <summary>Details</summary>
Motivation: 在先前工作中提出了一个通用的瞬时时频分析框架，但缺乏具体的瞬时谱（IS）计算细节。本工作旨在解决这一问题，展示通用框架如何统一不同的信号分析方法，并推导出相应的IS闭合形式表达式。

Method: 使用瞬时时频原子获得与时间域分析、频率域分析、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换相关的瞬时谱（IS）。将这些分析视为调幅-调频（AM-FM）分量的分解，并认识到它们在分析过程中都使用特殊形式的二次线性调频（chirplet）作为模板。利用双参数二次线性调频，将这些IS组织成一个二维连续体，其中二维平面上的点对应于一种信号分析相关的分解。

Result: 通过将多种信号分析方法（包括时间域、频率域、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换）视为调幅-调频（AM-FM）分量的分解，并利用二次线性调频（chirplet）作为模板，将这些方法统一在一个通用的框架下，并推导出了它们各自的瞬时谱（IS）的闭合形式表达式。通过一个二维连续体将这些IS进行组织，其中二维平面上的点代表一种特定的信号分析。最后，通过几个示例信号，计算了不同分析方法下的IS的闭合形式。

Conclusion: 本文提出的框架能够统一多种信号分析方法，并为它们推导出了瞬时谱的闭合形式表达式，并通过具体实例验证了其有效性。

Abstract: In previous work, we presented a general framework for instantaneous
time-frequency analysis but did not provide any specific details of how to
compute a particular instantaneous spectrum (IS). In this work, we use
instantaneous time-frequency atoms to obtain an IS associated with common
signal analyses: time domain analysis, frequency domain analysis, fractional
Fourier transform, synchrosqueezed short-time Fourier transform, and
synchrosqueezed short-time fractional Fourier transform. By doing so, we
demonstrate how the general framework can be used to unify these analyses and
we develop closed-form expressions for the corresponding ISs. This is
accomplished by viewing these analyses as decompositions into AM--FM components
and recognizing that each uses a specialized (or limiting) form of a quadratic
chirplet as a template during analysis. With a two-parameter quadratic
chirplet, we can organize these ISs into a 2D continuum with points in the
plane corresponding to a decomposition related to one of the signal analyses.
Finally, using several example signals, we compute in closed-form the ISs for
the various analyses.

</details>


### [298] [Sub- μ W Battery-Less and Oscillator-Less Wi-Fi Backscattering Transmitter Reusing RF Signal for Harvesting, Communications, and Motion Detection](https://arxiv.org/abs/2508.05479)
*Marco Privitera,Andrea Ballo,Karim Ali Ahmed,Alfio Dario Grasso,Massimo Alioto*

Main category: eess.SP

TL;DR: 该论文介绍了一种创新的sub-uW功耗802.11b反向散射发射器，它能同时进行射频能量收集、通信和位置传感，并通过消除本地振荡器和使用双音入射波技术，显著降低了功耗并提高了灵敏度，同时实现了无电池设计和高集成度。


<details>
  <summary>Details</summary>
Motivation: 为了实现射频能量收集、反向散射通信和位置/运动传感的设备小型化、普遍性、无限设备寿命以及低成本，打破WiFi发射器的微瓦功耗壁垒。

Method: 提出了一种sub-uW功耗的802.11b反向散射发射器。通过提取双音入射波的二阶互调频率来消除本地振荡器，实现了低于微瓦的功耗。利用收集的电压作为接收信号强度（RSS）的代理，实现了位置/运动传感。

Result: 实现了sub-uW功耗的802.11b反向散射发射器，并将同一入射波用于射频能量收集、反向散射通信和位置/运动传感。通过消除本地振荡器，功耗低于微瓦。双音方案实现了低至Pmin -19 dBm的累积收集/传输/传感灵敏度，并实现了基于收集电压的位置/运动传感。

Conclusion: 该论文提出了一种低功耗（sub-uW）的802.11b反向散射发射器，可将同一入射波用于射频能量收集、反向散射通信和位置/运动传感。通过消除本地振荡器（通过提取双音入射波的二阶互调频率），首次打破了WiFi发射器的微瓦功耗壁垒。双音方案还实现了低至Pmin -19 dBm的累积收集/传输/传感灵敏度。通过将收集到的电压用作接收信号强度（RSS）的代理，可以实现位置/运动传感，从而在室内环境中感知芯片相对于音调发生器的位置。

Abstract: In this paper, a sub-uW power 802.11b backscattering transmitter is presented
to enable reuse of the same incident wave for three purposes: RF harvesting,
backscattering communications and position/motion sensing. The removal of the
battery and any off-chip motion sensor (e.g., MEMS) enables unprecedented level
of miniaturization and ubiquity, unrestricted device lifespan, low fabrication
and maintenance cost. The uW power wall for WiFi transmitters is broken for the
first time via local oscillator elimination, as achieved by extracting its
frequency through second-order intermodulation of a twotone incident wave. The
two-tone scheme also enables a cumulative harvesting/transmission/sensing
sensitivity down to Pmin -19 dBm. Position/motion sensing is enabled by using
the harvested voltage as a proxy for the Received Signal Strength (RSS),
allowing to sense the chip location with respect to the tone generator(s)
shared across tags in indoor neighborhoods.

</details>


### [299] [0.6-V, uW-Power 4-Stage OTA with Minimal Components and 100X Load Range](https://arxiv.org/abs/2508.05499)
*M. Privitera,A. D. Grasso,A. Ballo,M. Alioto*

Main category: eess.SP

TL;DR: 本文介绍了一种具有高功耗效率和稳定性的超低功耗四级OTA。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于超低功耗应用的四级跨导运算放大器（OTA）。

Method: 本文提出的电路包含频率补偿，所需的晶体管和无源元件数量最少，克服了传统四级OTA补偿的困难，并将其恢复到三级OTA的简单性。

Result: 与之前的四级OTA（亚1V多级OTA）相比，提出该电路在 savk（FOMS）方面实现了大于3.7倍（大于11.3倍）的提升，在功耗效率方面表现出色。由于相位裕度对负载电容的灵敏度较低，该OTA在宽负载范围内（大于100倍）保持稳定。

Conclusion: 该文介绍了一种用于超低功耗应用的四级跨导运算放大器（OTA）。

Abstract: A four-stage operational transconductance amplifier (OTA) for ultra-low-power
applications is introduced in this paper. The proposed circuit inclusive of
frequency compensation requires minimal transistor count and passives,
overcoming the traditionally difficult compensation of 4-stage OTAs and
bringing it back to the simplicity of 3-stage OTAs. At the same time, the
proposed circuit achieves high power efficiency, as evidenced by the >3.7X
(>11.3X) improvement in the large-signal (small-signal) power efficiency figure
of merit FOML (FOMS), compared to prior 4-stage OTAs (sub-1 V multi-stage
OTAs). Thanks to the lower sensitivity of the phase margin to the load
capacitance, the proposed OTA remains stable under a wide range of loads
(double-sided as in any 3-4-stage OTA), achieving a max/min ratio of the load
capacitance of >100X.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [300] [Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications](https://arxiv.org/abs/2508.04889)
*Theia Henderson,David R. Karger,David D. Clark*

Main category: cs.SI

TL;DR: Graffiti 是一个允许用户轻松创建和互联互通的个性化社交应用的系统。


<details>
  <summary>Details</summary>
Motivation: 现有的社交应用设计僵化，缺乏个性化和互操作性，且新应用的开发具有技术挑战性。

Method: 提出“完全实体化”和“频道”两个核心概念，以支持具有冲突规则的设计互操作，并通过最小化的客户端 API 和 Vue.js 插件实现了这一目标。

Result: 通过案例研究展示了 Graffiti 如何支持类似 Twitter、Messenger 和 Wikipedia 的应用，并探索了其生态系统。

Conclusion: Graffiti系统能够支持用户轻松创建多样化的个性化社交应用，并促进它们之间的互操作性，同时避免了上下文折叠问题。

Abstract: Most social applications, from Twitter to Wikipedia, have rigid
one-size-fits-all designs, but building new social applications is both
technically challenging and results in applications that are siloed away from
existing communities. We present Graffiti, a system that can be used to build a
wide variety of personalized social applications with relative ease that also
interoperate with each other. People can freely move between a plurality of
designs -- each with its own aesthetic, feature set, and moderation -- all
without losing their friends or data.
  Our concept of total reification makes it possible for seemingly
contradictory designs, including conflicting moderation rules, to interoperate.
Conversely, our concept of channels prevents interoperation from occurring by
accident, avoiding context collapse.
  Graffiti applications interact through a minimal client-side API, which we
show admits at least two decentralized implementations. Above the API, we built
a Vue.js plugin, which we use to develop applications similar to Twitter,
Messenger, and Wikipedia using only client-side code. Our case studies explore
how these and other novel applications interoperate, as well as the broader
ecosystem that Graffiti enables.

</details>


### [301] [Community-Aware Social Community Recommendation](https://arxiv.org/abs/2508.05107)
*Runhao Jiang,Renchi Yang,Wenqing Lin*

Main category: cs.SI

TL;DR: CASO 是一个用于社交社区推荐的新模型，它通过结合社交网络结构和用户偏好来生成社区感知嵌入，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的社交推荐模型主要针对博客、图像和产品等常规项目，但对于社区推荐却效果不佳，因为它们忽略了社区的独特特性——用户的高动态性以及社交网络中丰富的结构模式。CASO 旨在弥补这一研究空白，专门为社交社区推荐而设计。

Method: CASO 模型利用三个精心设计的编码器进行用户嵌入：其中两个通过社交模块化最大化和社会邻近性聚合从社交网络中提取社区相关的全局和局部结构，第三个通过协作过滤和观察到的用户-社区隶属关系来捕获用户偏好。此外，CASO 引入了社交和协作信号之间的互斥，以消除特征冗余，并通过社区检测损失进行模型优化，从而为社区生成社区感知嵌入。

Result: CASO 在社区推荐任务中展现出与九个强基线模型相比一致且显著的优越性。

Conclusion: CASO 在六个真实社交网络上的广泛实验表明，其在社区推荐性能方面优于最先进的模型。

Abstract: Social recommendation, which seeks to leverage social ties among users to
alleviate the sparsity issue of user-item interactions, has emerged as a
popular technique for elevating personalized services in recommender systems.
Despite being effective, existing social recommendation models are mainly
devised for recommending regular items such as blogs, images, and products, and
largely fail for community recommendations due to overlooking the unique
characteristics of communities. Distinctly, communities are constituted by
individuals, who present high dynamicity and relate to rich structural patterns
in social networks. To our knowledge, limited research has been devoted to
comprehensively exploiting this information for recommending communities.
  To bridge this gap, this paper presents CASO, a novel and effective model
specially designed for social community recommendation. Under the hood, CASO
harnesses three carefully-crafted encoders for user embedding, wherein two of
them extract community-related global and local structures from the social
network via social modularity maximization and social closeness aggregation,
while the third one captures user preferences using collaborative filtering
with observed user-community affiliations. To further eliminate feature
redundancy therein, we introduce a mutual exclusion between social and
collaborative signals. Finally, CASO includes a community detection loss in the
model optimization, thereby producing community-aware embeddings for
communities. Our extensive experiments evaluating CASO against nine strong
baselines on six real-world social networks demonstrate its consistent and
remarkable superiority over the state of the art in terms of community
recommendation performance.

</details>


### [302] [Modeling roles and trade-offs in multiplex networks](https://arxiv.org/abs/2508.05488)
*Nikolaos Nakis,Sune Lehmann,Nicholas A. Christakis,Morten Mørup*

Main category: cs.SI

TL;DR: MLT模型用于分析多层社交网络，揭示了社会、健康和经济联系的驱动因素。


<details>
  <summary>Details</summary>
Motivation: 理解多层社交网络的结构有助于我们识别社会交换如何受到个体自身属性和行为（独立性）、他人地位或资源（依赖性）以及实体之间相互影响（相互依存性）的驱动。然而，表征多层网络中的结构具有挑战性，因为不同的层可以反映不同但互补的角色，并且相互依存性出现在多个尺度上。

Method: 本研究引入了多层潜在权衡模型（MLT），一个用于提取多层社交网络中角色的框架，该框架考虑了独立性、依赖性和相互依存性。MLT将角色定义为一种权衡，要求每个节点在层之间分配其源节点和目标节点角色，同时在分层的、多尺度的结构中分配社区成员身份。

Result: 将MLT方法应用于洪都拉斯西部乡村的176个真实多层网络（包括社交、健康和经济层面），研究发现了核心的社会交换原则，并揭示了局部、层特定和多尺度的社区。链接预测分析表明，在社交层面考虑相互依存性可带来最大的性能提升，而在健康和经济层面则效果较小。

Conclusion: 本研究提出的MLT框架能够提取多层社交网络中的角色，并考虑了独立性、依赖性和相互依存性。研究结果揭示了在人际交往中，社会联系是结构性嵌入的，而健康和经济联系则主要受个人地位和行为参与的影响。

Abstract: A multiplex social network captures multiple types of social relations among
the same set of people, with each layer representing a distinct type of
relationship. Understanding the structure of such systems allows us to identify
how social exchanges may be driven by a person's own attributes and actions
(independence), the status or resources of others (dependence), and mutual
influence between entities (interdependence). Characterizing structure in
multiplex networks is challenging, as the distinct layers can reflect different
yet complementary roles, with interdependence emerging across multiple scales.
Here, we introduce the Multiplex Latent Trade-off Model (MLT), a framework for
extracting roles in multiplex social networks that accounts for independence,
dependence, and interdependence. MLT defines roles as trade-offs, requiring
each node to distribute its source and target roles across layers while
simultaneously distributing community memberships within hierarchical,
multi-scale structures. Applying the MLT approach to 176 real-world multiplex
networks, composed of social, health, and economic layers, from villages in
western Honduras, we see core social exchange principles emerging, while also
revealing local, layer-specific, and multi-scale communities. Link prediction
analyses reveal that modeling interdependence yields the greatest performance
gains in the social layer, with subtler effects in health and economic layers.
This suggests that social ties are structurally embedded, whereas health and
economic ties are primarily shaped by individual status and behavioral
engagement. Our findings offer new insights into the structure of human social
systems.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [303] [Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space](https://arxiv.org/abs/2508.04726)
*Thejas Radhika Sajith*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given a multiset $A = \{a_1, \dots, a_n\}$ of positive integers and a target
integer $t$, the Subset Sum problem asks if there is a subset of $A$ that sums
to $t$. Bellman's [1957] classical dynamic programming algorithm runs in
$O(nt)$ time and $O(t)$ space. Since then, there have been multiple
improvements in both time and space complexity.
  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to
obtain a randomized algorithm that runs in $\tilde{O}(n+t)$ time and
$\tilde{O}(t)$ space. On the other hand, there are polynomial space algorithms
-- for example, Jin, Vyas and Williams [SODA 2021] build upon the algorithm
given by Bringmann, using a clever algebraic trick first seen in Kane's
Logspace algorithm, to obtain an $\tilde{O}(nt)$ time and $\tilde{O}(\log(nt))$
space algorithm. A natural question, asked by Jin et al. is if there is an
$\tilde{O}(n+t)$ time algorithm running in poly$(n, \log t)$ space. Another
natural question is whether it is possible to construct a deterministic
polynomial space algorithm with time complexity comparable to that of
Bellman's.
  In this paper, we answer both questions affirmatively. We build on the
framework given by Jin et al., using a multipoint evaluation-based approach to
speed up a bottleneck step in their algorithm. We construct a deterministic
algorithm that runs in $\tilde{O}(nt)$ time and $\tilde{O}(n \log^2 t)$ space
and a randomized algorithm that runs in $\tilde{O}(n+t)$ time and
$\tilde{O}(n^2 + n \log^2 t)$ space.

</details>


### [304] [A Refutation of Elmasry's $\tilde{O}(m \sqrt{n})$-Time Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2508.04872)
*Sunny Atalig,Marek Chrobak*

Main category: cs.DS

TL;DR: The claimed $\tilde{O}(m\sqrt{n})$ complexity for Elmasry's shortest-path algorithm is wrong; it's actually $\Omega(mn)$ on some graphs.


<details>
  <summary>Details</summary>
Motivation: To examine Elmasry's recent paper on a single-source shortest path algorithm and verify its claimed running time complexity.

Method: Providing a counterexample of a weighted graph where the algorithm's running time is $\Omega(mn)$, contradicting the claimed $\tilde{O}(m\sqrt{n})$.

Result: The analysis shows that Elmasry's claimed running time complexity of $\tilde{O}(m\sqrt{n})$ is incorrect. The algorithm's actual running time complexity is $\Omega(mn)$ on a specific weighted graph.

Conclusion: Elmasry's analysis of his shortest-path algorithm's running time is incorrect, and its actual running time is $\Omega(mn)$ on certain weighted graphs.

Abstract: In this note we examine the recent paper "Breaking the Bellman-Ford
Shortest-Path Bound" by Amr Elmasry, where he presents an algorithm for the
single-source shortest path problem and claims that its running time complexity
is $\tilde{O}(m\sqrt{n})$, where $n$ is the number of vertices and $m$ is the
number of edges. We show that his analysis is incorrect, by providing an
example of a weighted graph on which the running time of his algorithm is
$\Omega(mn)$.

</details>


### [305] [Text Indexing and Pattern Matching with Ephemeral Edits](https://arxiv.org/abs/2508.05124)
*Solon P. Pissis*

Main category: cs.DS

TL;DR: 该研究提出了一种新的文本索引方法，称为“临时子串编辑”，用于处理文本中的临时编辑操作，并支持高效的模式匹配查询。该方法能够在O(n)时间内预处理文本，并允许在O(m log log m)时间内预处理模式。它能处理任意的临时编辑操作序列，并在恢复操作前快速报告模式的出现。此外，还提出了临时编辑的模式匹配方法，提供了更优的查询时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为了解决在处理文本流或测试假设性编辑时出现的临时性编辑操作问题。当编辑操作序列中的某个操作（如插入或替换）被后续操作所抵消时，该序列就被称为“临时”序列。研究的目的是设计一种数据结构，能够有效地支持在文本中进行此类临时编辑操作的同时，进行模式匹配查询。

Method: 该研究提出了一种名为“文本索引的临时子串编辑”的新方法，旨在设计一种数据结构来处理文本中的临时子串编辑操作，并支持模式匹配查询。该方法在O(n)时间内对文本进行预处理，并允许在O(m log log m)时间内对模式进行在线预处理。该数据结构能够处理任意的临时编辑操作序列，并在操作恢复前报告模式的所有出现。此外，还提出了“临时编辑的模式匹配”方法，可在O(n)时间内预处理文本和模式，并允许任意的临时编辑操作序列，最终在O(Occ)时间内报告模式的所有出现。

Result: 该研究成功地引入了文本索引的临时子串编辑，并提出了一种可以在O(n)时间内预处理文本的数据结构。该结构支持常量长度的子串插入和替换，以及任意的删除操作。在允许任何临时编辑操作序列的情况下，可以在O(log log n + Occ)时间内报告模式的所有出现。此外，研究还提出了临时编辑的模式匹配方法，该方法可在O(n)时间内预处理文本和模式，并允许任意的临时编辑操作序列，最终以O(Occ)的时间复杂度报告模式的所有出现。该研究还为临时块删除提供了最优解决方案。

Conclusion: 该研究引入了文本索引的临时子串编辑，并提出了一个新的数据结构，可以在O(n)时间内预处理文本，并支持模式匹配查询和临时子串插入、删除或替换。该数据结构还可以在O(m log log m)时间内预处理模式，并允许任何临时的编辑操作序列。在恢复第i个操作之前，可以在O(log log n + Occ)时间内报告P在T^i中的所有Occ次出现。此外，该研究还介绍了临时编辑的模式匹配，可以在O(n)时间内预处理两个字符串，并允许任何临时的编辑操作序列。在恢复第i个操作之前，可以在O(Occ)时间内报告P在T^i中的所有Occ次出现。

Abstract: A sequence $e_0,e_1,\ldots$ of edit operations in a string $T$ is called
ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with
$k\in\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$.
Such a sequence arises when processing a stream of independent edits or testing
hypothetical edits.
  We introduce text indexing with ephemeral substring edits, a new version of
text indexing. Our goal is to design a data structure over a given text that
supports subsequent pattern matching queries with ephemeral substring
insertions, deletions, or substitutions in the text; we require insertions and
substitutions to be of constant length. In particular, we preprocess a text
$T=T[0\mathinner{.\,.} n)$ over an integer alphabet $\Sigma=[0,\sigma)$ with
$\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we can preprocess
any arbitrary pattern $P=P[0\mathinner{.\,.} m)$ given online in
$\mathcal{O}(m\log\log m)$ time and $\mathcal{O}(m)$ space and allow any
ephemeral sequence of edit operations in $T$. Before reverting the $i$th
operation, we report all Occ occurrences of $P$ in $T^i$ in
$\mathcal{O}(\log\log n + \text{Occ})$ time.
  We also introduce pattern matching with ephemeral edits. In particular, we
preprocess two strings $T$ and $P$, each of length at most $n$, over an integer
alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in
$\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations
in $T$. Before reverting the $i$th operation, we report all Occ occurrences of
$P$ in $T^i$ in the optimal $\mathcal{O}(\text{Occ})$ time. Along our way to
this result, we also give an optimal solution for pattern matching with
ephemeral block deletions.

</details>


### [306] [Space-Efficient Hierholzer: Eulerian Cycles in O(m) Time and O(n) Space](https://arxiv.org/abs/2508.05251)
*Ziad Ismaili Alaoui,Detlef Plump,Sebastian Wild*

Main category: cs.DS

TL;DR: 一种新的 Hierholzer 算法变体，运行时间为线性，但工作内存仅为 O(n lg m) 位，比标准实现更节省空间。


<details>
  <summary>Details</summary>
Motivation: 与标准的 Hierholzer 算法实现（使用 O(m lg n) 位空间）相比，该算法显著提高了工作空间利用率。

Method: 描述了一种 Hierholzer 算法的简单变体，该算法在具有 n 个顶点和 m 条边的（多）图中查找欧拉回路。

Result: 该算法运行时间为线性时间，并且工作内存为 O(n lg m) 位。

Conclusion: 该算法是第一个达到此空间复杂度（O(n lg m) 位工作内存）的线性时间算法，并且易于实现。

Abstract: We describe a simple variant of Hierholzer's algorithm that finds an Eulerian
cycle in a (multi)graph with $n$ vertices and $m$ edges using $\mathrm{O}(n \lg
m)$ bits of working memory. This substantially improves the working space
compared to standard implementations of Hierholzer's algorithm, which use
$\mathrm{O}(m \lg n)$ bits of space. Our algorithm runs in linear time, like
the classical versions, but avoids an $\mathrm{O}(m)$-size stack of vertices or
storing information for each edge. To our knowledge, this is the first
linear-time algorithm to achieve this space bound, and the method is very easy
to implement. The correctness argument, by contrast, is surprisingly subtle; we
give a detailed formal proof. The space savings are particularly relevant for
dense graphs or multigraphs with large edge multiplicities.

</details>


### [307] [Parameterized Algorithms for Spanning Tree Isomorphism by Redundant Set Size](https://arxiv.org/abs/2508.05351)
*Fangjian Shen,Yicheng Zheng,Wushao Wen,Hankz Hankui Zhuo*

Main category: cs.DS

TL;DR: 论文提出了用于生成树同构问题的固定参数可处理性算法，参数为冗余集大小 k。


<details>
  <summary>Details</summary>
Motivation: 为解决无向图和有向图的生成树同构问题，特别是当冗余集大小 k 较小时，提供高效的算法。

Method: 该论文提出了针对无向图和有向图生成树同构问题的固定参数可处理性算法。对于无向图版本，算法的时间复杂度为 O(n^2 log n * 2^(k log k))。对于有向图版本，算法的时间复杂度为 O(n^2 * 2^(4k-3))。

Result: 对于无向生成树同构问题，实现了 O(n^2 log n * 2^(k log k)) 的时间复杂度。对于有向生成树同构问题，实现了 O(n^2 * 2^(4k-3)) 的时间复杂度。

Conclusion: 该论文为无向图和有向图的生成树同构问题提出了固定参数可处理性算法，参数为冗余集大小 k。

Abstract: In this paper, we present fixed-parameter tractability algorithms for both
the undirected and directed versions of the Spanning Tree Isomorphism Problem,
parameterized by the size $k$ of a redundant set. A redundant set is a
collection of edges whose removal transforms the graph into a spanning tree.
For the undirected version, our algorithm achieves a time complexity of $O(n^2
\log n \cdot 2^{k \log k})$. For the directed version, we propose a more
efficient algorithm with a time complexity of $O(n^2 \cdot 2^{4k-3})$, where
$n$ is the number of vertices.

</details>


### [308] [Online Sparsification of Bipartite-Like Clusters in Graphs](https://arxiv.org/abs/2508.05437)
*Joyentanuj Das,Suranjan De,He Sun*

Main category: cs.DS

TL;DR: This paper introduces new algorithms for graph clustering that efficiently find 'bipartite-like' clusters, improving speed and maintaining accuracy on real-world data.


<details>
  <summary>Details</summary>
Motivation: The objective of most graph clustering algorithms is to find a vertex set of low conductance. However, recent studies highlight the importance of inter-connections between vertex sets in real-world datasets, motivating the study of bipartite-like clusters.

Method: We developed efficient and online sparsification algorithms to identify bipartite-like clusters in graphs.

Result: Our algorithms significantly speed up the running time of existing clustering algorithms while preserving their effectiveness, as demonstrated by experimental studies on synthetic and real-world datasets.

Conclusion: In this work, we present efficient and online sparsification algorithms for finding bipartite-like clusters in both undirected and directed graphs. Our experimental studies show that these algorithms significantly speed up existing clustering algorithms while preserving their effectiveness.

Abstract: Graph clustering is an important algorithmic technique for analysing massive
graphs, and has been widely applied in many research fields of data science.
While the objective of most graph clustering algorithms is to find a vertex set
of low conductance, a sequence of recent studies highlights the importance of
the inter-connection between vertex sets when analysing real-world datasets.
Following this line of research, in this work we study bipartite-like clusters
and present efficient and online sparsification algorithms that find such
clusters in both undirected graphs and directed ones. We conduct experimental
studies on both synthetic and real-world datasets, and show that our algorithms
significantly speedup the running time of existing clustering algorithms while
preserving their effectiveness.

</details>


### [309] [Parameterized complexity of isometric path partition: treewidth and diameter](https://arxiv.org/abs/2508.05448)
*Dibyayan Chakraborty,Oscar Defrain,Florent Foucaud,Mathieu Mari,Prafullkumar Tale*

Main category: cs.DS

TL;DR: 该论文研究了 Isometric Path Partition 问题的参数化复杂性，证明了其在树宽度参数下是 W[1]-hard 的，并提出了 n^O(tw) 和 diam^O(tw^2) * n^O(1) 的算法。


<details>
  <summary>Details</summary>
Motivation: 该研究的主要动机是探讨 Isometric Path Partition 问题的参数化复杂性，特别是当参数化为图的树宽度（tw）时。由于许多基于度量的图问题（如 Isometric Path Partition）难以用恒定大小的 MSO 公式表示，因此它们不能直接从 Courcelle 定理中受益，这使得它们成为参数化树宽度的边界案例，需要单独研究。

Method: 该研究通过证明 Isometric Path Partition 问题在参数化为图的树宽度时是 W[1]-hard 的，来分析其参数化复杂性。此外，研究还设计了一种定制的动态规划算法，实现了 n^O(tw) 的运行时间，并得出了一种运行时间为 diam^O(tw^2) * n^O(1) 的算法。最后，研究人员还通过证明 Isometric Path Partition 问题不存在运行时间为 diam^o(tw^2 / (log^3(tw)))) * n^O(1) 的算法（除非随机化 ETH 失败），来排除更快的算法的可能性。

Result: 该研究证明了 Isometric Path Partition 问题在参数化为树宽度（甚至路径宽度）时是 W[1]-hard 的。此外，研究设计了一种运行时间为 n^O(tw) 的动态规划算法，以及一种运行时间为 diam^O(tw^2) * n^O(1) 的算法。最后，研究还证明了除非随机化 ETH 失败，否则 Isometric Path Partition 问题不存在运行时间为 diam^o(tw^2 / (log^3(tw)))) * n^O(1) 的算法。

Conclusion: Isometric Path Partition 问题在参数化为图的树宽度时是 W[1]-hard 的，并且该研究设计了一种运行时间为 n^O(tw) 的动态规划算法，以及一种运行时间为 diam^O(tw^2) * n^O(1) 的算法。此外，该研究还证明了除非随机化 ETH 失败，否则 Isometric Path Partition 问题不存在运行时间为 diam^o(tw^2 / (log^3(tw)))) * n^O(1) 的算法。

Abstract: We investigate the parameterized complexity of the Isometric Path Partition
problem when parameterized by the treewidth ($\mathrm{tw}$) of the input graph,
arguably one of the most widely studied parameters. Courcelle's theorem shows
that graph problems that are expressible as MSO formulas of constant size admit
FPT algorithms parameterized by the treewidth of the input graph. This
encompasses many natural graph problems. However, many metric-based graph
problems, where the solution is defined using some metric-based property of the
graph (often the distance) are not expressible as MSO formulas of constant
size. These types of problems, Isometric Path Partition being one of them,
require individual attention and often draw the boundary for the success story
of parameterization by treewidth.
  In this paper, we prove that Isometric Path Partition is $W[1]$-hard when
parameterized by treewidth (in fact, even pathwidth), answering the question by
Dumas et al. [SIDMA, 2024], Fernau et al. [CIAC, 2023], and confirming the
aforementioned tendency. We complement this hardness result by designing a
tailored dynamic programming algorithm running in $n^{O(\mathrm{tw})}$ time.
This dynamic programming approach also results in an algorithm running in time
$\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$, where $\textrm{diam}$ is the
diameter of the graph. Note that the dependency on treewidth is unusually high,
as most problems admit algorithms running in time $2^{O(\mathrm{tw})}\cdot
n^{O(1)}$ or $2^{O(\mathrm{tw} \log (\mathrm{tw}))}\cdot n^{O(1)}$. However, we
rule out the possibility of a significantly faster algorithm by proving that
Isometric Path Partition does not admit an algorithm running in time
$\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$, unless
the Randomized-ETH fails.

</details>


### [310] [An Improved Approximation Algorithm for the Capacitated Arc Routing Problem](https://arxiv.org/abs/2508.05471)
*Jingyang Zhao,Mingyu Xiao*

Main category: cs.DS

TL;DR: CARP 近似比的改进


<details>
  <summary>Details</summary>
Motivation: CARP 是车辆路径问题的推广，改进其近似比具有实际意义。

Method: 提出了一种 $(rac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$ 近似算法。

Result: 将 CARP 的最佳已知近似比从 $\frac{5}{2}-\frac{1.5}{k}$ 提高到 $(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$。

Conclusion: 所提出算法是 CARP 近似比的第一个改进。

Abstract: The Capacitated Arc Routing Problem (CARP), introduced by Golden and Wong in
1981, is an important arc routing problem in Operations Research, which
generalizes the famous Capacitated Vehicle Routing Problem (CVRP). When every
customer has a unit demand, the best known approximation ratio for CARP, given
by Jansen in 1993, remains $\frac{5}{2}-\frac{1.5}{k}$, where $k$ denotes the
vehicle capacity. Based on recent progress in approximating CVRP, we improve
this result by proposing a
$(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-approximation algorithm, which to
the best of our knowledge constitutes the first improvement over Jansen's
bound.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [311] [Impact of Au Ion Implantation on 2D $Cr_2Ge_2Te_6$ for Spintronics](https://arxiv.org/abs/2508.04715)
*Gurupada Ghorai,Kalyan Ghosh,Pratap K. Sahoo*

Main category: physics.app-ph

TL;DR: 本研究通过低能Au离子注入技术调控了Cr$_{2}$Ge$_{2}$Te$_{6}$薄片的磁性，提高了其居里温度，并证明了该技术在自旋电子学应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在自旋电子学应用中调控2D磁性材料的磁性，本研究旨在探究低能Au离子注入对2D层状剥离的Cr$_{2}$Ge$_{2}$Te$_{6}$薄片的影响。

Method: 本研究采用低能（30 KeV）Au离子注入技术，对在Si/SiO$_{2}$衬底上通过Scotch tape方法制备的2D层状剥离的Cr$_{2}$Ge$_{2}$Te$_{6}$薄片进行了处理。实验使用了五种不同的离子剂量（5$	imes10^{13}$，1$	imes10^{14}$，5$	imes10^{14}$，1$	imes10^{15}$，和2.5$	imes10^{15}$ ions/cm$^2$），以期改变样品的形貌、成分、结构和振动特性。

Result: 研究发现，离子注入显著改变了Cr$_{2}$Ge$_{2}$Te$_{6}$薄片的形貌和磁性行为，提高了其居里温度，并将磁相互作用从超交换转变为双交换。Au离子插入Cr$_{2}$Ge$_{2}$Te$_{6}$导致交换能量隙减小和磁矩改变，这证明了离子注入技术在调控2D材料磁性方面的潜力。

Conclusion: 该研究表明，离子注入技术能够有效地调控2D材料的磁性，为开发先进的自旋电子学应用提供了潜力。

Abstract: Advancements in 2D magnetic materials highlight their potential in
semiconductors, magnetism, and spintronics, particularly in tuning magnetic
properties for spintronic applications. This study investigates the impact of
low-energy (30 KeV) Au ion implantation on 2D layered exfoliated $Cr_2Ge_2Te_6$
flakes prepared on Si/SiO$_2$ substrates using the Scotch tape method. Five
different ion doses (5$\times10^{13}$, 1$\times10^{14}$, 5$\times10^{14}$,
1$\times10^{15}$, and 2.5$\times10^{15}$ ions/cm$^2$) were used to modify the
morphology, composition, structural, and vibrational properties of the samples.
The implantation introduces significant changes in morphology and magnetic
behavior, leading to an increase in Curie temperature and an attribution from
superexchange to double exchange interactions. The reduced exchange energy gaps
and modified magnetic moments attribute to Au ions intercalation in
$Cr_2Ge_2Te_6$ underscore the potential of ions implantation to tune the
magnetic properties of 2D materials for advanced spintronic applications.

</details>


### [312] [Parametric Analysis of First High-Gain Vertical Fe-doped Ultrafast Ga2O3 Photoconductive Semiconductor Switch](https://arxiv.org/abs/2508.04911)
*N. Karpourazar,S. K. Mazumder,V. Jangir,K. M. Dowling,J. Leach,L. Voss*

Main category: physics.app-ph

TL;DR: 该研究通过 SILVACO 仿真分析了 Fe 掺杂 Ga2O3 光电导开关的性能，结果显示高增益和低成本激光束是可能的。


<details>
  <summary>Details</summary>
Motivation: 研究嵌入电极的超宽带隙（UWBG）Fe 掺杂 Ga2O3 光电导半导体开关（FG-PCSS）的参数化性能。

Method: 使用 SILVACO 仿真，并结合实验获得的寿命、吸收系数和迁移率数据，对嵌入电极的超宽带隙（UWBG）Fe 掺杂 Ga2O3 光电导半导体开关（FG-PCSS）进行参数化性能分析。

Result: 仿真结果表明，FG-PCSS 在相对较高的电场和光激发能量下，在电流增益、量子效率、导通电阻和光束位置影响方面表现良好，并指出高增益操作和低成本激光束是可能的。

Conclusion: 高增益操作和低成本激光束是可能的。

Abstract: We investigate, as part of a Lawrence-Livermore-National-Laboratory (LLNL)
sponsored-research work initiated in February of 2021, the parametric
performance analysis of ultra-wide bandgap (UWBG) Fe-doped Ga2O3
photoconductive semiconductor switch (FG-PCSS) with embedded electrode. The
detailed SILVACO based simulation of the FG-PCSS uses experimentally obtained
lifetime, absorption coefficient, and mobility data. The key analysis results,
demonstrated first to the sponsor LLNL in 2022, focus on the performance of the
FG-PCSS under relatively high electric field and optical-excitation energy with
specific regard to current gain, quantum efficiency, on-state resistance, and
impact of beam position. The parametric analysis indicates that a high-gain
operation yielding a low-cost laser beam for the FG-PCSS is possible.

</details>


### [313] [Double Negative Metamaterials in Water Waves](https://arxiv.org/abs/2508.05458)
*Zixun Ge,Junke Liao,Linkang Han,Qilin Duan,Xiaofan Wang,Mengwei Dai,Shan Zhu,Huanyang Chen*

Main category: physics.app-ph

TL;DR: 本研究提出了一种用于水波的 Veselago-Pendry 双负超材料（DNM），由嵌套的齿轮和分裂的管子构成。该结构实现了有效的负水深和重力分布，能够实现可调的负折射，解决了先前负折射结构中不明确的结构-传播关系和严格的布局要求。通过相干势近似（CPA）预测了负有效水深 ue 和重力 ge。预测的 DNM 参数与能带结构吻合良好，并通过隔离、波浪弯曲和全角度成像的模拟进行了验证。通过定量映射结构参数与传播特性之间的关系，可以实现可调的带隙和可控的负折射，为海岸工程提供了一个变革性的工具集，能够平静港口、促进波浪能收集器，并引导河湾水流以遏制侵蚀。


<details>
  <summary>Details</summary>
Motivation: 水波既带来机遇也带来危害，需要精确控制来有效利用其能量并减轻其破坏性影响。利用负折射的独特传播特性可以实现多种控制策略。

Method: 通过相干势近似（CPA）预测了负有效水深ue和重力ge。预测的DNM参数与能带结构吻合良好，并通过隔离、波浪弯曲和全角度成像的模拟进行了验证。

Result: DNM 能够实现可调的负折射，解决了先前负折射结构中不明确的结构-传播关系和严格的布局要求。DNM 具有可调的带隙和可控的负折射，为海岸工程提供了一个变革性的工具集。

Conclusion: DNM 为海岸工程提供了一个变革性的工具集，能够平静港口、促进波浪能收集器，并引导河湾水流以遏制侵蚀。

Abstract: Water waves present both opportunities and hazards, which demand precise
control to effectively exploit their energy and mitigate their destructive
effects. Leveraging the unique propagation characteristic of negative
refraction enables versatile strategies for achieving such control. Here, we
propose a Veselago-Pendry double negative metamaterial (DNM) for water waves
constructed by nested gears and split tubes. This uniform array structure
realizes effective negative water depth and gravity distributions, enabling
tunable negative refraction that resolves the unclear structure-propagation
relationships and stringent layout requirements of prior negative refraction
structures. By employing coherent potential approximation (CPA), negative
effective water depth ue and gravity ge are predicted. The predicted DNM
parameters align well with band structures, and are validated by simulations of
isolation, wave bending and all-angle imaging with surface waves excitation. A
simplified experiment demonstrating water wave bending was successfully
performed, matching the analytical predictions and simulation results well.
Through quantitative mapping between structural parameters and propagation
properties that enables tunable bandgaps and controllable negative refraction,
DNMs furnish a transformative toolkit for coastal engineering, and are able to
calm harbors, boost wave-energy harvesters, and steer river-bend currents to
curb erosion.

</details>


### [314] [Thin-Film Solar Photovoltaics: Trends and Future Directions](https://arxiv.org/abs/2508.05589)
*Donald Intal,Abasifreke U. Ebong*

Main category: physics.app-ph

TL;DR: 薄膜光伏技术（如 CdTe、CIGS 和钙钛矿）在成本和应用方面具有优势，但稳定性和材料问题仍需解决。


<details>
  <summary>Details</summary>
Motivation: 薄膜光伏技术在解决太阳能应用中的可扩展性、成本效益和环境可持续性等关键挑战方面发挥着重要作用。

Method: 本文对薄膜光伏技术进行了批判性回顾，重点介绍了非晶硅 (a-Si)、碲化镉 (CdTe) 和铜铟镓硒 (CIGS) 等技术，并讨论了钙钛矿、铜锌锡硫化物 (CZTS)、量子点 (QD)、有机光伏 (OPV) 和染料敏化太阳能电池 (DSSC) 等新兴技术。

Result: CdTe 和 CIGS 技术目前在商业上具有主导地位，实验室效率分别达到 23.1% 和 23.6%。钙钛矿技术也取得了显著进展，实验室效率达到 26.7%。薄膜光伏技术减少了材料使用和制造成本，并具有柔韧性和轻质结构等优点，可用于多种应用。

Conclusion: 薄膜光伏技术在可扩展性、成本效益和环境可持续性方面具有优势，但长期稳定性、毒性问题和材料稀缺性等挑战限制了其广泛应用。通过开发串联结构、改进封装策略和可持续材料来源是克服这些挑战的关键。

Abstract: Thin-film photovoltaic (PV) technologies address crucial challenges in solar
energy applications, including scalability, cost-effectiveness, and
environmental sustainability. This paper reviews critically, thin-film
technologies such as amorphous silicon (a-Si), cadmium telluride (CdTe), and
copper indium gallium selenide (CIGS). It also discusses emerging technologies,
including perovskites, copper zinc tin sulfide (CZTS), quantum dots (QDs),
organic photovoltaics (OPV), and dye-sensitized solar cells (DSSC). Among
these, CdTe and CIGS currently dominate commercial viability, achieving
laboratory-scale efficiencies of 23.1% and 23.6%, respectively. Perovskites
have notably advanced, reaching a laboratory efficiency of 26.7%. Thin-film PV
technologies significantly reduce material use and manufacturing costs,
offering distinct advantages such as flexibility and lightweight structures,
thereby enabling diverse applications from building-integrated systems to
portable electronic devices. Despite these benefits, broader adoption remains
limited by challenges including long-term stability, toxicity concerns, and
material scarcity. Addressing these challenges through advancements in tandem
architectures, improved encapsulation strategies, and sustainable material
sourcing is essential for thin-film PV technologies to substantially contribute
to the global renewable energy transition.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [315] [Quantum-impurity sensing of altermagnetic order](https://arxiv.org/abs/2508.04788)
*V. A. S. V. Bittencourt,H. Hosseinabadi,J. Sinova,L. Šmejkal,J. Marino*

Main category: cond-mat.mes-hall

TL;DR: Quantum sensing with NV centers in diamond can reveal anisotropic spin dynamics of altermagnetic insulators. The method is sensitive to momentum space anisotropy, enabling distinction from conventional antiferromagnets.


<details>
  <summary>Details</summary>
Motivation: To reveal the anisotropic spin dynamics of altermagnetic insulators together with their characteristic spin polarised bands.

Method: Quantum relaxometry with nitrogen-vacancy (NV) centers in diamond.

Result: The distance and orientation dependent relaxation rate of a nearby quantum impurity encodes signatures of momentum space anisotropy in the spin diffusion response, a hallmark of altermagnetic order.

Conclusion: NV-sensing experiments can distinguish altermagnets from conventional antiferromagnets via local, noninvasive measurements, and can be used to probe spin transport and symmetry breaking in altermagnets.

Abstract: Quantum sensing with individual spin defects has emerged as a versatile
platform to probe microscopic properties of condensed matter systems. Here we
demonstrate that quantum relaxometry with nitrogen-vacancy (NV) centers in
diamond can reveal the anisotropic spin dynamics of altermagnetic insulators
together with their characteristic spin polarised bands. We show that the
distance and orientation dependent relaxation rate of a nearby quantum impurity
encodes signatures of momentum space anisotropy in the spin diffusion response,
a hallmark of altermagnetic order. This directional sensitivity is
unprecedented in the landscape of quantum materials sensing, and it enables the
distinction of altermagnets from conventional antiferromagnets via local,
noninvasive measurements. Our results could spark new NV-sensing experiments on
spin transport and symmetry breaking in altermagnets, and highlight the role of
NV orientation to probe anisotropic phenomena in condensed matter systems.

</details>


### [316] [Observation of σ-πcoupling and mode selection in optically trapped artificial polariton molecules](https://arxiv.org/abs/2508.04909)
*Krzysztof Sawicki,Valtýr Kári Daníelsson,Dmitriy Dovzhenko,Pavlos G. Lagoudakis,Simone De Liberato,Helgi Sigurðsson*

Main category: cond-mat.mes-hall

TL;DR: 研究了耦合光学陷阱极化子凝聚物，发现在不同激发参数下会形成丰富的空间结构。通过可重构的激光模式和光学陷阱，该平台有望模拟分子键合机制。


<details>
  <summary>Details</summary>
Motivation: 研究受激远非平衡的极化子凝聚物，探索其自发同步和不稳定性，以及它们如何依赖于激发和材料参数，展示基于模式竞争的复杂干涉图样。

Method: 通过利用光学可重构激光激发模式，创建用于限制极化子的环形光束，并利用光学陷阱的耗散特性与相邻凝聚物进行有效相互作用。

Result: 我们探索了极化子凝聚物之间的耦合机制，这些凝聚物填充了耦合光学陷阱凝聚物的第一个激发p态流形，并展示了基于激发参数的丰富图样结构。                                                        

Conclusion: 该研究结果支撑了极化子凝聚物在探索和模拟σ和π分子键合机制中的潜力。

Abstract: Microcavity exciton-polariton condensates under additional transverse
confinement constitute a flexible optical platform to study the coupling
mechanism between confined nonequilibrium and nonlinear states of matter.
Driven far from equilibrium, polariton condensates can display spontaneous
synchronization and instabilities depending on excitation and material
parameters, showcasing emergent and intricate interference patterns based on
mode competition over mutual gain landscapes. Here, we explore this coupling
mechanism between polariton condensates populating the first excited ${\it
p}$-state manifold of coupled optically trapped condensates and show a rich
structure of patterns based on excitation parameters. The optical
reconfigurability of the laser excitation patterns enables the creation of an
annular-shaped beam to confine polaritons in a tailored trapping potential,
whilst the dissipative nature of the optical traps enables effective
interaction with neighboring condensates. Our results underpin the potential
role of polariton condensates in exploring and simulating $\sigma$ and $\pi$
molecular bonding mechanisms between artificial two-dimensional diatomic
orbitals and beyond.

</details>


### [317] [Micromagnetic Design of Bias-Free Reconfigurable Microwave Properties in Hexagonal Shaped Multilayer Nanomagnets](https://arxiv.org/abs/2508.04910)
*Krishna Begari*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种利用六边形纳米磁体结构和磁脉冲场来调整和研究可重构微波特性及其在不同磁状态下频率偏移的方法。


<details>
  <summary>Details</summary>
Motivation: 磁性微型纳米结构因其在GHz频率范围内的磁化动力学特性，在当前和未来的微波技术中显示出巨大潜力。

Method: 通过微磁模拟研究纳米磁体的磁静态和动态特性，并使用简单的场初始化方法检查每种样品中的两种不同磁剩余状态。通过施加纳秒宽的磁脉冲场来调整与不同剩余状态相对应的独特磁化动力学参数。

Result: 发现单层和多层纳米磁体在两种不同的磁剩余状态之间在亚GHz和GHz区域存在显著的频率偏移。

Conclusion: 该研究提出了一种使用新颖六边形纳米磁体结构研究可重构微波特性的方法，并发现单层和多层纳米磁体在两种不同的磁剩余状态之间在亚GHz和GHz区域存在显著的频率偏移。

Abstract: Magnetic miniaturized nanostructures hold great promise for current and
future microwave technologies due to their magnetization dynamics in the GHz
frequency range. This work presents a method for investigating reconfigurable
microwave properties using a novel hexagonal nanomagnet structure.
Micromagnetic simulations are employed to investigate the magnetic static and
dynamic properties of the nanomagnets. A simple field initialization method is
used to examine two distinct magnetic remanent states in each sample. A
nanosecond-width magnetic pulse field can be applied to tune the unique
magnetization dynamics parameters corresponding to the different remanent
states. Find that for both single-layer and multilayer nanomagnets, there is a
notable frequency shift in the sub-GHz and GHz regions between the two distinct
magnetic remanent states.

</details>


### [318] [Engineering Topological Materials](https://arxiv.org/abs/2508.04927)
*Amit Goft,Eric Akkermans*

Main category: cond-mat.mes-hall

TL;DR: 嵌入缺陷或空间纹理以设计拓扑材料，从而改变对称性或维度，并按需诱导拓扑相变。


<details>
  <summary>Details</summary>
Motivation: 现有的十倍分类法虽然是组织拓扑物态的有力框架，但并未提供系统性的方法来在类别之间进行转换或设计材料以实现所需的拓扑特性。

Method: 通过嵌入缺陷或空间纹理来设计拓扑材料，从而改变对称性或维度。

Result: 提出了一种设计拓扑材料的新方法，能够控制地跨越十倍表进行导航。

Conclusion: 该方法能够按需诱导拓扑相变，并已通过几个非平凡的例子进行了说明，证明了局部缺陷可以生成具有不同对称性和拓扑不变量的相。

Abstract: The tenfold classification provides a powerful framework for organizing
topological phases of matter based on symmetry and spatial dimension. However,
it does not offer a systematic method for transitioning between classes or
engineering materials to realize desired topological properties. In this work,
we introduce a general method for designing topological materials by embedding
defects or spatial textures, which alter symmetry or dimension. This enables
controlled navigation across the tenfold table, allowing one to induce
topological phase transitions on demand. We illustrate this approach through
several nontrivial examples, demonstrating how local defects can generate
phases with different symmetries and topological invariants.

</details>


### [319] [Chern junctions in Moiré-Patterned Graphene/PbI2](https://arxiv.org/abs/2508.04935)
*Sun Yan,M. Monteverde,V. Derkach,K. Watanabe,T. Taniguchi,F. Chiodi,H. Bouchiat,A. D. Chepelianskii*

Main category: cond-mat.mes-hall

TL;DR: 在本工作中，我们将PbI2引入莫尔材料家族，并研究了其在异质结构中的磁输运性质，发现了无耗散输运、分数电导平台以及受自旋-轨道耦合影响的莫尔霍夫施塔特谱，为研究莫尔超晶格现象和工程化量子材料提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 拓展莫尔材料库，解锁新颖的量子相和涌现的电子行为。

Method: 研究了六方氮化硼/石墨烯/碘化铅异质结构中的莫尔超晶格的磁输运性质。

Result: 在强磁场量子霍尔区域，电荷中性点处观察到鲁棒的无耗散输运，并在2/3 e2/h处出现分数电导平台。此外，还观察到莫尔霍夫施塔特谱的非常规能带序列以及沿切恩数 vm = -2 的线条出现的相干电子干涉。

Conclusion: PbI2基异质结构为实现自旋-轨道耦合增强的莫尔超晶格现象和工程化二维量子材料中的相干边缘输运提供了一个多功能平台。

Abstract: Expanding the moir\'e material library continues to unlock novel quantum
phases and emergent electronic behaviors. In this work, we introduce PbI2 into
the moir\'e family and investigate the magnetotransport properties of moir\'e
superlattice in a hexagonal boron nitride/graphene/PbI2 heterostructures. In
high-field quantum Hall regime, we observe a robust dissipationless transport
at charge neutrality point, indicative of incompressible states stabilized at
the filling factor vh = 0. Additionally, a fractional conductance plateau at
2/3 e2/h emerges, which we attribute to a Chern junction between domains with
distinct Chern numbers originating from moir\'e-modulated and conventional
integer quantum Hall states. The moir\'e Hofstadter spectrum displays an
unconventional flavor sequence, likely influenced by proximity-induced
spin-orbit coupling from the PbI2 layer. We also see coherent electronic
interference along lines with Chern number vm = -2. These findings position
PbI2-based heterostructures as a versatile platform for realizing
spin-orbit-enhanced moir\'e phenomena and engineering coherent edge transport
in two-dimensional quantum materials.

</details>


### [320] [Theory of magnon hydrodynamics in collinear antiferromagnets](https://arxiv.org/abs/2508.05057)
*Vivianne Olguín-Arias,Alireza Qaiumzadeh,Roberto E. Troncoso*

Main category: cond-mat.mes-hall

TL;DR: This paper theoretically investigates magnons in antiferromagnetic insulators, modeling them as a viscous fluid. It explores hydrodynamic transport, deriving equations for momentum and spin transport, and identifying phenomena like nonlocal resistance and modified spin currents due to inter-magnon scattering. The findings suggest these materials are promising for studying collective spin transport.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the transport of spin angular momentum and linear momentum carried by magnons in electrically insulating collinear antiferromagnets, focusing on both transverse and longitudinal geometries.

Method: The paper models magnons as a viscous fluid and explores the hydrodynamic transport regime by developing a theoretical framework for viscous effects in the magnon hydrodynamic regime, deriving hydrodynamic equations governing magnon momentum and spin transport, and deriving expressions for magnon conductivity and an accessibility parameter.

Result: The study establishes that viscous effects in the magnon hydrodynamic regime give rise to measurable transport signatures such as nonlocal resistance and spin and thermal conductance. It also identifies that interspecies scattering between antiferromagnetic magnons with opposite spin angular momentum induces drag-like effects that strongly modify spin current propagation.

Conclusion: Motional antiferromagnetic insulators are a promising platform for observing magnon-fluid dynamics and exploring collective spin transport phenomena.

Abstract: We investigate the transport of spin angular momentum and linear momentum
carried by magnons in electrically insulating collinear antiferromagnets (AFs).
Focusing on both transverse and longitudinal geometries, we model magnons as a
viscous fluid and explore the hydrodynamic transport regime that emerges when
the magnon-magnon scattering length is shorter than the momentum-relaxation
length, such that momentum-conserving processes dominate over momentum-relaxing
ones. We develop a theoretical framework to investigate viscous effects in the
magnon hydrodynamic regime, which give rise to measurable transport signatures
such as nonlocal resistance and spin and thermal conductance. Accounting for
both momentum and spin relaxations, we derive hydrodynamic equations governing
magnon momentum and spin transport. Notably, interspecies scattering between
antiferromagnetic magnons with opposite spin angular momentum induces drag-like
effects that strongly modify spin current propagation. We derive expressions
for magnon conductivity and introduce an accessibility parameter quantifying
intra-band momentum transfer. Our results establish antiferromagnetic
insulators as a promising platform for observing magnon-fluid dynamics and
exploring collective spin transport phenomena.

</details>


### [321] [Multiple quantum spin Hall states and topological current divider in Twisted Bilayer WSe$_2$](https://arxiv.org/abs/2508.05092)
*Hao He,Zhao Gong,Shuai Li,Jian-Jun Liu,Hui-Ying Mu,Xing-Tao An*

Main category: cond-mat.mes-hall

TL;DR: 扭曲WSe2双层结构中发现了新的量子自旋霍尔态，并提出了拓扑电流分流器器件。


<details>
  <summary>Details</summary>
Motivation: 尽管扭曲双层过渡金属二卤化物中存在拓扑量子自旋霍尔态，但对其拓扑边缘态的全面理论表征仍然是一个悬而未决的问题。

Method: 通过理论计算和器件设计，研究了扭曲WSe2双层结构的拓扑输运性质，识别了新兴的双重和四重量子自旋霍尔态，并分析了其边缘态的特性和鲁棒性。

Result: 发现了超越传统单量子自旋霍尔态的双重和四重量子自旋霍尔态，其边缘态并非局限于边缘，而是在莫尔超晶格边界的势阱中传播，并且具有一定的抗无序能力。实现了通过门电压调控单重和双重量子自旋霍尔态之间的转变，并提出了拓扑电流分流器器件。

Conclusion: 该研究发现了扭曲的WSe2双层结构中存在新颖的量子自旋霍尔态，包括双量子自旋霍尔态和四量子自旋霍尔态，并提出了基于这些态的拓扑电流分流器器件，为无耗散自旋电子学的发展提供了支持。

Abstract: It has been demonstrated that topological quantum spin Hall (QSH) state exist
in twisted bilayers of transition metal dichalcogenides. However, a
comprehensive theoretical characterization of the topological edge states
remains a topic of interest and an unresolved issue. Here, the topological
transport properties of the twisted WSe$_2$ bilayers are investigated. Beyond
the conventional single QSH, we identify emergent double and quartuple quantum
spin Hall states, hosting two and four pairs of counter-propagating helical
edge channels respectively. Furthermore, the charge carriers in these edge
states are not localized at edge but rather the high potential point of the
moire superlattice boundary, undergoing interlayer transitions and propagating
forward continuously. We term these edge states as moire edge states. These
edge states can survive in non-magnetic disorder, with the robustness of double
QSH states surpassing that of single QSH states. At a twisting angle of
2.45$^\circ$, the transition between the single and double QSH states can be
achieved by adjusting the gate on the surface. Based on this, we propose a
five-terminal device to as a topological current devider. Our findings provide
support for the development of dissipationless spintronics.

</details>


### [322] [Unraveling Size Dependent Bi- and Tri-exciton Characteristics in CdSe/CdS Core/Shell Quantum Dots via Ensemble Time Gated Heralded Spectroscopy](https://arxiv.org/abs/2508.05203)
*Einav Scharf,Rotem Liran,Adar Levi,Omer Alon,Nadav Chefetz,Dan Oron,Uri Banin*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种新的光谱学方法，利用时间门控触发光谱学研究量子点中的多激子（MX），成功提取了激子结合能和三激子寿命，为量子点的光电器件应用提供了新的表征手段。


<details>
  <summary>Details</summary>
Motivation: 量子点中的多激子（MX）虽然在量子限制下表现出多体相互作用，并在量子点激光、发光二极管和光催化等光电器件中有重要应用，但MXs之间的强相互作用导致快速的非辐射衰减，给其表征带来了挑战。现有的测量技术依赖于间接方法或单粒子研究，而本研究旨在引入一种新的研究方法。

Method: " herein we introduce a new method to study MXs in QD ensembles utilizing spectrally resolved time-gated heralded spectroscopy. "

Result: 本研究利用光谱分辨的时间门控触发光谱学方法，提取了CdSe/CdS量子点系综中的激子结合能，揭示了不同核/壳尺寸下吸引和排斥相互作用之间的转变。此外，该方法还成功分离了三激子（包含两个1s能级激子和一个1p能级激子的占有）的两种不同路径的光谱，并提取了MX的寿命。与单粒子研究相比，该方法在系综测量中提供了更高的光子计数和更低的噪声水平，能够观测到更难分辨的MX特性。

Conclusion: 所介绍的光谱学方法能够有效地表征量子点中的多激子（MX）能量和寿命，为优化量子点在各种光电器件中的应用提供支持。

Abstract: Multiexcitons (MXs) in quantum dots (QDs) manifest many body interactions
under quantum confinement. Beyond this fundamental interest, MXs are of
importance in numerous optoelectronic applications including QD lasing, light
emitting diodes and photocatalysis. Yet, the strong interactions between MXs
leading to rapid non-radiative decay introduce challenges for their
characterization. While so far, the measurement techniques rely either on
indirect methods or on single particle studies, herein we introduce a new
method to study MXs in QD ensembles utilizing spectrally resolved time-gated
heralded spectroscopy. With this approach we extract the biexciton binding
energies in a series of CdSe/CdS QD ensembles of several core/shell sizes,
manifesting a transition between attractive and repulsive exciton-exciton
interactions. Additionally, for triexcitons, which involve occupation of two
excitons in the 1s energy levels, as well as one exciton in the 1p energy
levels, we address the open issues of isolating the spectra of the two
triexciton pathways from one another and from high-order MXs, and extract the
MX lifetimes. The measurements on ensembles provide high photon counts and low
noise levels, and alongside the time-gated heralded approach thus enable the
observation of MX characteristics that are difficult to resolve in single
particle studies. The approach can be further implemented in the
characterization of the energies and lifetimes of MXs in other QD systems to
enable rapid characterization and understanding of the MX properties. Such
insight bears relevance to optoelectronic applications ranging from lasing to
electroluminescent devices to quantum light sources.

</details>


### [323] [Stacking-induced type-II quantum spin Hall insulators with high spin Chern number in unconventional magnetism](https://arxiv.org/abs/2508.05365)
*Chao-Yang Tan,Panjun Feng,Ze-Feng Gao,Fengjie Ma,Peng-Jie Guo,Zhong-Yi Lu*

Main category: cond-mat.mes-hall

TL;DR: 堆叠两个 II 型量子自旋霍尔绝缘体形成高自旋陈数量子自旋霍尔绝缘体，实现两倍于单层的自旋霍尔电导，并提出了双层 Nb$_{2}$SeTeO 作为实现该相的候选材料。


<details>
  <summary>Details</summary>
Motivation: 探究堆叠两个 II 型量子自旋霍尔绝缘体是否会产生平凡绝缘体，并与 I 型量子自旋霍尔绝缘体进行对比。

Method: 基于晶格模型计算，并利用第一性原理电子结构计算进行验证。

Result: 堆叠两个 II 型量子自旋霍尔绝缘体不会产生平凡绝缘体，而是形成具有高自旋陈数（high spin Chern number）的量子自旋霍尔绝缘体。在该相中，边界处共存着两个具有相反手性和极化的拓扑边缘态。双层量子自旋霍尔电导是单层量子自旋霍尔绝缘体的两倍。该高自旋陈数相在有 U(1) 对称性时是稳定的，在 U(1) 对称性被破坏时，它在较宽的参数范围内仍然存在。提出了双层 Nb$_{2}$SeTeO 是具有高自旋陈数 的 II 型量子自旋霍尔绝缘体。将此策略扩展到多层堆叠可自然地产生具有更大自旋陈数的量子自旋霍尔绝缘体。

Conclusion: 这项工作不仅加深了 I 型和 II 型量子自旋霍尔绝缘体之间的区别，还提供了一条实现高度量化自旋霍尔电导的途径。

Abstract: Generally, stacking two monolayer type-I quantum spin Hall insulators gives
rise to a trivial insulator. However, whether or not stacking two type-II
quantum spin Hall insulators results in a trivial insulator has not yet been
explored. In this letter, based on the calculations of lattice model, we
demonstrate that stacking two type-II quantum spin Hall insulators does not
yield a trivial insulator, but instead forms a quantum spin Hall insulator with
high spin Chern number. In this phase, there are two pairs of topological edge
states with opposite chirality and polarization coexisting in the boundary. Our
calculations further reveal that the quantized spin Hall conductance of the
bilayer is twice that of the monolayer. When U(1) symmetry is present, the high
spin Chern number phase remains stable; when U(1) symmetry is broken, it
persists over a broad parameter range. Furthermore, based on the
first-principles electronic structure calculations, we propose that bilayer
Nb$_2$SeTeO is a type-II quantum spin Hall insulator with high spin Chern
number. Finally, extending this strategy to multilayer stacks naturally leads
to quantum spin Hall insulator with larger spin Chern number. Our work not only
deepens the distinction between type-I and type-II quantum spin Hall
insulators, but also offers a route toward realizing highly quantized spin Hall
conductance.

</details>


### [324] [Universal relations between thermoelectrics and noise in mesoscopic transport across a tunnel junction](https://arxiv.org/abs/2508.05413)
*Andrei I. Pavlov,Mikhail N. Kiselev*

Main category: cond-mat.mes-hall

TL;DR: 提出一个统一理论，描述输运实验中电流和噪声的普适关系，特别是在量子点系统中。


<details>
  <summary>Details</summary>
Motivation: 揭示在弱探测条件下，输运实验中电流和噪声的普适输运关系，并将其应用于量子点系统。

Method: 开发了用于电流和噪声的弱探测微分可观测量统一理论，并将其应用于量子点系统，展示了电导、热电与噪声之间的普适关系。

Result: 发现了系统在通过隧道接触探测时的热电和噪声性质之间的一组普适输运关系，并证明每个微观理论都具有连接电导、热电和噪声的普适关系集。

Conclusion: 本理论揭示了在弱探测条件下，输运实验中电流和噪声的统一理论。我们发现了系统在通过隧道接触探测时的热电和噪声性质之间的一组普适输运关系，其中维德曼- दिसून定律是电荷和热电流之间普适性定律的一个例子。将该理论应用于多通道Kondo、量子霍尔和Sachdev-Ye-Kitaev量子点等各种量子点系统，并证明每个微观理论都具有连接电导、热电和噪声的普适关系集。这些关系的存在性表明系统中的能量尺度，而违背这些关系则意味着存在额外的能量尺度。

Abstract: We develop a unified theory of weakly probed differential observables for
currents and noise in transport experiments. Our findings uncover a set of
universal transport relations between thermoelectric and noise properties of a
system probed through a tunnel contact, with the Wiedemann-Franz law being just
one example of such universality between charge and heat currents. We apply
this theory to various quantum dot systems, including multichannel Kondo,
quantum Hall and Sachdev-Ye-Kitaev quantum dots, and demonstrate that each of
the microscopic theories is characterized by a set of universal relations
connecting conductance and thermoelectrics with noise. Violations of these
relations indicate additional energy scales emerging in a system.

</details>


### [325] [Negative differential conductance in triangular molecular assemblies](https://arxiv.org/abs/2508.05575)
*Chao Li,Vladislav Pokorný,Prokop Hapala,Martin Žonda,Ping Zhou,Silvio Decurtins,Shi-Xia Liu,Fengqi Song,Rémy Pawlak,Ernst Meyer*

Main category: cond-mat.mes-hall

TL;DR: 本研究成功构建了分子尺度负微分电导（NDC）器件，并揭示了其产生机制（库仑阻塞和分子间电容耦合），证明了通过分子簇拓扑结构调控电子性质的可行性，为分子器件和纳电子学发展提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索分子尺度负微分电导（NDC）器件的构建和特性，并研究分子簇拓扑结构对电子性质的调控作用，为开发多功能分子器件和可编程、可扩展的纳电子学提供基础。

Method: 本研究使用低溫扫描隧道光谱学（STS）技术，在超导Pb(111)衬底上组装TBTAP分子的三角形三聚体，并进行表征。通过二维差分电导图谱可视化门控控制的充电和放电过程。同时，利用三杂质安德森模型和主方程法进行理论建模，以复现实验结果。

Result: 成功制备并表征了分子尺度NDC器件，观察到在0.7-0.9 V电压范围内具有鲁棒的NDC行为。通过实验和理论证明，NDC源于库仑阻塞和分子间强电容耦合，并且与超导性无关。此外，通过改变分子簇的拓扑结构（从三聚体到六聚体），实现了对电子性质的灵活调控。

Conclusion: 本研究通过在超导Pb(111)衬底上组装四溴四氮杂芘（TBTAP）分子的三角形三聚体，成功制造并表征了一个分子尺度负微分电导（NDC）器件。实验结果表明，该器件在0.7-0.9 V电压范围内表现出鲁棒的NDC行为，其根源在于库仑阻塞和分子簇内分子间强电容耦合的相互作用。通过门控调控的充电和放电过程，利用二维差分电导图谱直接可视化了库仑环的出现和NDC的空间区域。理论建模（三杂质安德森模型和主方程法）成功复现了实验结果，并证明NDC完全由电子相关性引起，与超导性无关。此外，通过将分子结构调整为六聚体，证明了分子簇拓扑结构能够灵活调控分子电子性质。这些发现为实现多功能分子器件提供了一个功能平台，并为可编程和可扩展的纳电子学指明了方向。

Abstract: We report the creation and characterization of a molecular-scale negative
differential conductance (NDC) device by assembling a triangular trimer of
4,5,9,10-tetrabromo-1,3,6,8-tetraazapyrene (TBTAP) molecules on a
superconducting Pb(111) substrate. Using low-temperature scanning tunneling
spectroscopy, we observe robust NDC behavior manifesting as a decrease in
current with increasing voltage between 0.7-0.9 V arising from the interplay of
Coulomb blockade and strong inter-molecular capacitive coupling within the
molecular cluster. Gate-controlled charging and discharging processes are
directly visualized via two-dimensional differential conductance mapping, which
reveals the emergence of Coulomb rings and spatial regions of NDC. Theoretical
modeling using a three-impurity Anderson model and master equation approach
quantitatively reproduces the experimental observations and demonstrates that
the NDC emerges purely from electron correlations, independent of the
underlying superconductivity. By tuning the geometry to a hexamer structure, we
further show that cluster topology provides versatile control over electronic
properties at the molecular scale. These results establish a functional
platform for implementing multifunctional molecular devices and highlight a
strategy toward programmable and scalable nanoelectronics.

</details>


### [326] [Nonreciprocal inertial spin-wave dynamics in twisted magnetic nanostrips](https://arxiv.org/abs/2508.05576)
*Massimiliano d'Aquino,Riccardo Hertel*

Main category: cond-mat.mes-hall

TL;DR: 扭曲软磁纳米带可产生太赫兹磁振荡，其非互易性由几何手性和惯性效应引起。曲率产生的几何相位控制着动力学行为，拓扑结构影响着自旋波传输。该研究为太赫兹宏观磁动力学和非互易自旋电子学应用提供了新的平台。


<details>
  <summary>Details</summary>
Motivation: 研究三维扭曲软磁纳米带中的惯性自旋波动力学，探索曲率和扭转与磁惯性耦合产生的太赫兹磁振荡及其非互易性。

Method: 通过解析方法捕捉色散关系和谱线宽的紧凑表达式，并考虑了几何（贝里）相位、波数量化规则等因素。

Result: 揭示了扭曲软磁纳米带中太赫兹磁振荡的产生机制，以及几何手性和惯性效应如何导致自旋波谱的非互易性。通过几何相位解析了色散关系和谱线宽，并阐明了拓扑结构对自旋波传输的影响。

Conclusion: 开发了用于三维扭曲软磁纳米带中惯性自旋波动力学的理论框架，其中曲率和扭转与磁惯性耦合以产生太赫兹（THz）磁振荡。该理论框架揭示了由于几何手性和惯性效应产生的有效对称性破缺，导致自旋波谱表现出显著的非互易性。研究还表明，这种行为受曲率引起的几何（贝里）相位控制，并通过对章动（THz）和进动（GHz）机制下的色散关系和谱线宽的紧凑表达式进行了解析描述。此外，拓扑变化（包括莫比乌斯和螺旋几何形状）带来了独特的波数量化规则，阐明了拓扑在自旋波传输中的作用。这些研究结果表明，扭曲磁条可作为实现曲线太赫兹宏观磁动力学和非互易自旋电子学应用的可行平台。

Abstract: We develop a theoretical framework for inertial spin-wave dynamics in
three-dimensional twisted soft-magnetic nanostrips, where curvature and torsion
couple with magnetic inertia to generate terahertz (THz) magnetic oscillations.
The resulting spin-wave spectra exhibit pronounced nonreciprocity due to
effective symmetry breaking arising from geometric chirality and inertial
effects. We show that this behavior is governed by a curvature-induced
geometric (Berry) phase, which we analytically capture through compact
expressions for dispersion relations and spectral linewidths in both nutational
(THz) and precessional (GHz) regimes. Topological variations, including
M\"obius and helical geometries, impose distinct wavenumber quantization rules,
elucidating the role of topology in spin-wave transport. These results position
twisted magnetic strips as a viable platform for curvilinear THz magnonics and
nonreciprocal spintronic applications.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [327] [peaks: a Python package for analysis of angle-resolved photoemission and related spectroscopies](https://arxiv.org/abs/2508.04803)
*Phil D. C. King,Brendan Edwards,Shu Mo,Tommaso Antonelli,Edgar Abarca Morales,Lewis Hart,Liam Trzaska*

Main category: cond-mat.mtrl-sci

TL;DR: peaks是一个Python包，用于ARPES数据分析，旨在处理大型数据集并提供GUI支持。


<details>
  <summary>Details</summary>
Motivation: ARPES是研究电子带结构的重要实验手段，但处理日益增长的数据量对现有分析工具提出了挑战。

Method: peaks是一个Python包，用于ARPES和相关光谱数据的分析，支持GUI交互。

Result: peaks包能够有效地可视化和分析多维ARPES数据集，并支持惰性数据加载和并行处理，以应对ARPES实验中不断增长的数据量。phrases/peak fitting and band structure analysis/peak fitting/peak fitting with a Gaussian function

Conclusion: peaks是一个用于高级ARPES数据分析的Python包，支持多维数据集的快速可视化和分析，并处理ARPES实验典型的数据层次结构，支持惰性数据加载和并行处理。

Abstract: The electronic band structure, describing the motion and interactions of
electrons in materials, dictates the electrical, optical, and thermodynamic
properties of solids. Angle-resolved photoemission spectroscopy (ARPES)
provides a direct experimental probe of such electronic band structures, and so
is widely employed in the study of functional, quantum, and 2D materials.
\texttt{peaks} (\textbf{P}ython \textbf{E}lectron spectroscopy
\textbf{A}nalysis by \textbf{K}ing group @ \textbf{S}t Andrews) provides a
Python package for advanced data analysis of ARPES and related spectroscopic
data. It facilitates the fast visualisation and analysis of multi-dimensional
datasets, allows for the complex data hierarchy typical to ARPES experiments,
and supports lazy data loading and parallel processing, reflecting the
ever-increasing data volumes used in ARPES. It is designed to be run in an
interactive notebook environment, with extensive inline and pop-out GUI support
for data visualisation.

</details>


### [328] [Engineering Phonons in Compositionally Complex Carbide Ceramics](https://arxiv.org/abs/2508.04812)
*Linu Malakkal,Jarin C French,Lanh Trinh,Kaustubh K Bawane,Shuxiang Zhou,Zilong Hua,Lingfeng He,Yongfeng Lu,Bai Cui*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用从头算方法和实验技术研究了成分复杂碳化物（CCCs）的声子特性和热导率。结果表明，可以通过调整成分来优化CCCs的声子行为，并且某些五元碳化物表现出意想不到的高热导率，这为开发用于极端环境的新型材料提供了新的机遇。


<details>
  <summary>Details</summary>
Motivation: 为了寻找具有优异抗辐照性和高温耐受性的先进陶瓷材料，用于核能应用，成分复杂碳化物（CCCs）被认为是极端环境下的候选材料。在这些极端条件下，声子是影响材料热稳定性、弹性、热导率和热力学行为的关键因素。CCCs中的阳离子无序会导致显著的声子散射，影响这些关键性能。

Method: 本研究采用从头算（ab initio）计算方法，预测了具有岩盐结构的成分复杂碳化物（CCCs）的声子带结构，并系统地研究了质量和力常数变化对声子谱函数的影响。此外，研究还利用空间域热反射技术测量了部分CCCs的热导率。

Result: 研究预测了CCCs的声子带结构，并发现了质量和力常数变化对声子谱函数的影响。实验测量结果显示，某些五元碳化物具有比某些三元和二元合金更高的热导率，这与预期阳离子无序会增加散射并降低热导率的理论相悖。

Conclusion: 摘要指出，可以通过选择和调整成分元素来优化成分复杂碳化物（CCCs）的声子带结构、声子带隙和声子散射，从而调控其声子相关性能。此外，实验结果表明，某些五元碳化物具有比某些三元和二元合金更高的热导率，这与预期“更阳离子无序导致更声子散射和更低热导率”的理论相反，为发现具有更好热导率的CCCs提供了可能性。

Abstract: In the pursuit of advanced ceramic materials with exceptional
irradiation-resistance and high-temperature tolerance for nuclear applications,
compositionally complex carbides (CCCs) have emerged as a highly promising
class of candidate materials for extreme environments. In such conditions,
critical material properties such as thermal stability, elasticity, thermal
conductivity and thermodynamics behavior are predominantly influenced by
phonons. In CCCs, pronounced cation disorder can lead to significant phonon
scattering due to inherent mass and force constant variations, impacting these
critical properties. In this study, we used ab initio calculations to predict
the phonon band structures and systematically explore the influence of mass and
force constant variance on the phonon spectral function of CCCs with a rock
salt structure, ranging from binary to five-metal component carbides. Our
findings reveal that the selection and concentration of constituent elements
can be strategically utilized to tune the phonon band structure, phonon bandgap
and phonon scattering in CCCs, thereby enabling control over phonon-related
properties. Additionally, we measured the thermal conductivity of some of these
CCCs using the spatial-domain thermoreflectance technique. Interestingly, the
measured thermal conductivity of some of these CCCs indicates that
five-component ceramics exhibit higher thermal conductivity than certain
ternary and binary alloys. This observation contrasts with the expectation that
greater cation disorder would result in more scattering and lower thermal
conductivity. This intriguing result opens up the possibility of discovering
CCCs with better thermal conductivity, presenting new opportunities for their
application in extreme environments.

</details>


### [329] [Inverse Lieb Materials: Altermagnetism and More](https://arxiv.org/abs/2508.04839)
*Po-Hao Chang,Igor I. Mazin,Kirill D. Belashchenko*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究使用 Heisenberg 模型和 DFT 计算，分析了逆 Lieb 格子（ILL）材料中的磁相和 altermagnetism 行为。研究发现了磁有序与 d 电子填充的关联，并确定了一种有潜力的 altermagnet 材料 Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$，同时证实了 the magnon 色散中的手性分裂与 J$_{2}$ 交换相互作用的各向异性相关。


<details>
  <summary>Details</summary>
Motivation: 逆 Lieb 格子（ILL）作为 altermagnetism 的一个最小解析模型，在最近引起了广泛关注，并且在现实材料中也发现了具有这种晶体学图案的材料。ILL 的独特几何结构能够容纳由竞争交换相互作用和几何挫胀引起的复杂磁有序，为磁性能提供了高度的可调性。因此，有必要深入了解 ILL 材料中的磁相，并为识别该类材料中的 altermagnet 材料提供指导方针。

Method: 该研究结合了 Heisenberg 模型和密度泛函理论（DFT）计算。首先，使用 Heisenberg 模型构建相图，以阐明 altermagnetism 和其他磁相的基础机制。然后，利用 DFT 系统地研究了一系列现有的 ILL 化合物，以确定它们的磁基态。最后，利用从 DFT 计算中提取的交换耦合参数，计算了 altermagnetic 系统的 the magnon 谱。

Result: 研究发现了 ILL 材料中的磁有序与过渡金属离子的 d 电子填充之间存在关联，其中 d$^{2-3}$ 和 d$^{5}$ 构型表现出 altermagnetism 行为的倾向。研究确定了 Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$ 作为一种有潜力的 altermagnet 材料，其 J$_{2}$ 交换耦合具有高度各向异性，且 Néel 温度约为 600 K。计算的 the magnon 谱证实了 the magnon 色散中的手性分裂与 J$_{2}$ 交换相互作用的各向异性直接相关。

Conclusion: 该研究揭示了逆 Lieb 格子（ILL）材料中磁有序与过渡金属离子的 d 电子填充之间的关联，并确定了 d$^{2-3}$ 和 d$^{5}$ 构型倾向于表现出 altermagnetism 行为的趋势。此外，研究将 Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$ 识别为一种有潜力的 altermagnet 材料，该材料具有高度各向异性的 J$_{2}$ 交换耦合和较高的 Néel 温度（约 600 K）。研究还通过计算 the magnon 谱证实了 the magnon 色散中的手性分裂与晶体学上不等价的 J$_{2}$ 交换相互作用之间的各向异性直接相关。

Abstract: The Lieb lattice, originally proposed for cuprate superconductors, has gained
new attention in the emerging field of altermagnetism as a minimal analytical
model for the latter. While initially the so-called inverse Lieb lattice (ILL)
was deemed only a theoretical model, recently several real materials with this
crystallographic motif have been found. The unique geometry of ILL can
accommodate complex magnetic orderings arising from competing exchange
interactions and geometric frustration, offering great tunability for magnetic
properties. In this work, we provide comprehensive insights into magnetic
phases in ILL materials and establish guidelines for efficient identification
of altermagnetic materials within this family. We begin by constructing phase
diagrams using a simple Heisenberg model to elucidate the fundamental
mechanisms underlying altermagnetism and other complex magnetic phases observed
experimentally. To bridge theory with experiment, we systematically investigate
a series of existing ILL compounds using density functional theory (DFT)
calculations to determine their magnetic ground states. Our computational
results are in good agreement with experimental observations. Importantly, we
identify a trend linking magnetic ordering to the $d$-shell filling of
transition metal ions, with $d^{2-3}$ and $d^{5}$ configurations showing
propensity for altermagnetic behavior. Additionally, we identify a promising
metallic compound Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$ as an altermagnet that is
highly anisotropic in its $J_2$ exchange couplings with large N\'eel
temperature ($\sim 600$ K). Using exchange coupling parameters extracted from
DFT calculations, we compute the magnon spectra for altermagnetic systems. As
expected, chiral splittings in the magnon dispersion are directly correlated
with anisotropy between crystallographically inequivalent $J_{2}$ exchange
interactions.

</details>


### [330] [Data Driven Insights into Composition Property Relationships in FCC High Entropy Alloys](https://arxiv.org/abs/2508.04841)
*Nicolas Flores,Daniel Salas Mula,Wenle Xu,Sahu Bibhu,Daniel Lewis,Alexandra Eve Salinas,Samantha Mitra,Raj Mahat,Surya R. Kalidindi,Justin Wilkerson,James Paramore,Ankit Srivastiva,George Pharr,Douglas Allaire,Ibrahim Karaman,Brady Butler,Vahid Attari,Raymundo Arroyave*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用编码器-解码器模型和贝叶斯优化，克服了高熵合金数据稀疏的挑战，成功预测了其机械性能，并在某些方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 高熵合金在航空航天、汽车和国防等领域至关重要，但缺乏整合的化学、工艺、结构和性能数据，给预测性能建模带来了重大挑战。鉴于这些合金广阔的设计空间，揭示潜在模式至关重要且困难。

Method: 本研究采用了几种敏感性分析方法，并评估了几种基于编码器-解码器的化学成分-性能模型，通过贝叶斯多目标超参数优化进行仔细调整，以将合金成分映射到六种机械性能。

Result: 敏感性分析突出了元素对机械行为的关键贡献，包括与BIRDSHOT中心NiCoFeCrVMnCuAl系统数据集中纳米压痕测试期间观察到的脆性和断裂响应相关的成分因素。所提出的编码器-解码器模型在所有性能指标上均达到了具有竞争力或更优越的性能。

Conclusion: 编码器-解码器模型在预测高熵合金的机械性能方面表现出与传统回归器相当或更优越的性能，特别是在屈服强度和UTS/YS比方面，证明了它们在捕捉复杂成分-性能关系方面的有效性。

Abstract: Structural High Entropy Alloys (HEAs) are crucial in advancing technology
across various sectors, including aerospace, automotive, and defense
industries. However, the scarcity of integrated chemistry, process, structure,
and property data presents significant challenges for predictive property
modeling. Given the vast design space of these alloys, uncovering the
underlying patterns is essential yet difficult, requiring advanced methods
capable of learning from limited and heterogeneous datasets. This work presents
several sensitivity analyses, highlighting key elemental contributions to
mechanical behavior, including insights into the compositional factors
associated with brittle and fractured responses observed during nanoindentation
testing in the BIRDSHOT center NiCoFeCrVMnCuAl system dataset. Several encoder
decoder based chemistry property models, carefully tuned through Bayesian multi
objective hyperparameter optimization, are evaluated for mapping alloy
composition to six mechanical properties. The models achieve competitive or
superior performance to conventional regressors across all properties,
particularly for yield strength and the UTS/YS ratio, demonstrating their
effectiveness in capturing complex composition property relationships.

</details>


### [331] [Optimization of Ab-Initio Based Tight-Binding Models](https://arxiv.org/abs/2508.04861)
*Henrik Dick,Thomas Dahm*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种受机器学习启发的优化技术，用于创建更精确、更简化的紧束缚模型，适用于大规模材料计算。


<details>
  <summary>Details</summary>
Motivation: 标准方法（如密度泛函理论）在计算固体的电子结构方面很有效，但在界面、晶界或接触几何形状等复杂情况下，需要使用简化的电子结构模型，例如紧束缚模型。

Method: 通过优化模型参数来重现从头计算的能带数据，并使用最少数量的参数，这受到机器学习技术的启发。

Result: 与最大化局域瓦尼尔函数相比，该方法生成的模型具有更短的作用范围和更少的轨道，但精度相当甚至更高。

Conclusion: 该方法可以更准确地生成紧束缚模型，用于大规模材料计算。

Abstract: The electronic structure of solids can routinely be calculated by standard
methods like density functional theory. However, in complicated situations like
interfaces, grain boundaries or contact geometries one needs to resort to more
simplified models of the electronic structure. Tight-binding models are using a
reduced set of orbitals and aim to approximate the electronic structure by
short range hopping processes. For example, maximally localized Wannier
functions are often used for that purpose. However, their accuracy is limited
by the need to disentangle the electronic bands. Here, we develop and
investigate a different procedure to obtain tight-binding models inspired by
machine-learning techniques. The model parameters are optimized in such a way
as to reproduce ab-initio band structure data as accurately as possible using
an as small as possible number of model parameters. The procedure is shown to
result in models with smaller ranges and fewer orbitals than maximally
localized Wannier functions but same or even better accuracy. We argue that
such a procedure is more useful for automated construction of tight-binding
models particularly for large-scale materials calculations.

</details>


### [332] [SERS Raman detection of the CO$_2$ Moisture Swing](https://arxiv.org/abs/2508.04893)
*Javier Mendez-Lozoya,Estrella Solis Mata,J. Jesus Velazquez Salazar,Alondra Hernandez Cedillo,Miguel Jose Yacaman,Jennifer L. Wade*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用SERS技术，通过实时监测阴离子物种（碳酸根、碳酸氢根、氢氧根）在不同湿度下的转化，证实了水分摇摆吸附剂的湿度驱动吸附/解吸机制，为开发下一代碳捕获材料提供了新方法和见解。


<details>
  <summary>Details</summary>
Motivation: 为了实现净零排放，开发可扩展、节能的二氧化碳捕获技术至关重要。水分摇摆吸附剂通过湿度驱动的离子水解实现可逆的二氧化碳结合，为传统热再生方法提供了一种有前景的替代方案。

Method: 本研究利用吸附测量和原位表面增强拉曼光谱（SERS）研究了两种水分摇摆（MS）材料的阴离子物种动力学：一种是含碳酸氢根阴离子的阴离子交换树脂，另一种是浸渍有碳酸氢钾盐的活性炭。研究人员使用镍涂层的银纳米线作为SERS基底，在空气和氮气环境中，通过控制湿度条件，实时检测了碳酸根、碳酸氢根和氢氧根物种。

Result: 研究结果揭示了阴离子物种之间依赖于湿度的相互转化。光谱的显著移动证实了驱动水分摇摆（MS）机制的可逆水解反应。在潮湿条件下，观察到碳酸氢根信号的减少和碳酸根物种的同时增加，这与湿度引起的二氧化碳解吸一致。

Conclusion: 该研究通过原位表面增强拉曼光谱（SERS）证实了湿度驱动的阴离子交换在水分摇摆吸附剂中的变体，并为下一代直接空气捕获吸附剂的设计提供了宝贵的见解。

Abstract: The development of scalable, energy-efficient carbon dioxide capture
technologies is critical for achieving net-zero emissions. Moisture swing
sorbents offer a promising alternative to traditional thermal regeneration
methods by enabling reversible CO$_2$ binding through humidity-driven ion
hydrolysis. In this study, we investigate the anion speciation dynamics in two
classes of MS materials, an anion-exchange resin with bicarbonate anion and
activated carbon impregnated with potassium bicarbonate salt using both
sorption measurements and in situ surface-enhanced Raman spectroscopy. Ni
coated Ag nanowires were employed as SERS substrates to enhance signal
intensity and enable the real-time detection of carbonate , bicarbonate , and
hydroxide species under controlled humidity conditions in both air and nitrogen
atmospheres. The results reveal humidity-dependent interconversion between
anionic species, with significant spectral shifts confirming the reversible
hydrolysis reactions that drive the MS mechanism. Under humid conditions, we
observed the depletion of bicarbonate signals and a concurrent increase in
carbonate species, consistent with moisture-induced desorption of CO$_2$. These
findings not only validate the mechanistic models of humidity-driven anion
exchange in moisture swing sorbents but also demonstrate the practical
potential of SERS as an operando diagnostic tool for monitoring CO$_2$ capture
media. The ability to resolve and quantify the reversible transformation of
carbonate, bicarbonate, and hydroxide ions under realistic environmental
conditions provides valuable insight for the rational design, performance
optimization, and quality control of next-generation sorbent materials for
direct air capture applications.

</details>


### [333] [Pressure-induced decomposition of Bi14WO24](https://arxiv.org/abs/2508.05617)
*E. Karaca,D. Santamaria-Perez,A. Otero-de-la-Roza,R. Oliva,K. S. Rao,S. N. Achary,C. Popescu,D. Errandonea*

Main category: cond-mat.mtrl-sci

TL;DR: Bi14WO24 在约 3 GPa 压力下分解为 Bi2O3 和 WO3，而结构相似的化合物在约 5 GPa 才会发生相变。


<details>
  <summary>Details</summary>
Motivation: 研究 Bi14WO24 在高压下的行为，并与结构相似的化合物进行比较。

Method: 使用同步辐射粉末 X 射线衍射在高压条件下研究了 Bi14WO24（Bi2O3-WO3 二元系统的高氧化物离子导体）的四方晶型。

Result: 确定了 Bi14WO24 的晶胞参数与压力的关系，推导了沿不同轴线的线压缩率和室温压力-体积状态方程。测得四方 Bi14WO24 的体积模量为 49.8(2.6) GPa，两个晶轴的线压缩率分别为 
k{appa}a = 6.94(2) x 10^-3 GPa^-1 和 
k{appa}c = 3.73(1) x 10^-3 GPa^-1。

Conclusion: Bi14WO24 在 2.85(5) GPa 压力下会发生不可逆的化学分解，生成 Bi2O3 和 WO3，这与结构相似的 Bi14CrO24 和 Bi14MoO24 在约 5 GPa 发生相变不同。该反应可能是由于系统密度的增加有利于承受压力引起的应力。

Abstract: We present a study of the high-pressure behaviour Bi14WO24, a high oxide ion
conductor member of the Bi2O3-WO3 binary system. The tetragonal polymorph of
Bi14WO24 was studied under high-pressure conditions using synchrotron powder
X-ray diffraction. It was found that in contrast to isostructural Bi14CrO24 and
Bi14MoO24 which experience a phase transition around 5 GPa, in our study
Bi14WO24 undergoes an irreversible chemical decomposition into Bi2O3 and WO3 at
2.85(5) GPa. The pressure dependence of the unit-cell parameters of Bi14WO24
was also determined, and hence the linear compressibility along different axes
and room-temperature pressure-volume equation of state were derived. Bulk
modulus of tetragonal Bi14WO24 was found to be 49.8(2.6) GPa, and the linear
compressibility of the two crystallographic axes, \k{appa}a and \k{appa}c were
6.94(2) 10-3 GPa-1 and = 3.73(1) 10-3 GPa-1, respectively. The pressure induced
decomposition can be attributed to the favourable increasing density of the
system to accommodate the pressure induced stress.

</details>


### [334] [Intrinsic Layer-Dependent Surface Energy and Exfoliation Energy of van der Waals Materials](https://arxiv.org/abs/2508.04898)
*Lin-Lin Wang,Jiaqiang Yan,Yong Han,Claire C. Wang,Jian-Xiang Qiu,Su-Yang Xu,Adam Kaminski,Michael C. Tringides,Paul C. Canfield*

Main category: cond-mat.mtrl-sci

TL;DR: We calculated the surface and exfoliation energies of 2D materials using DFT. We found that single layers have the lowest surface energy, and the reduction in surface energy decreases with more atomic layers within the single layer, explaining why some materials are easier to exfoliate than others.


<details>
  <summary>Details</summary>
Motivation: Stacking and twisting 2D van der Waals (vdW) layers have become versatile platforms to tune electron correlation, relying on exfoliating vdW materials down to a single and few vdW layers.

Method: Using density functional theory to calculate the intrinsic layer-dependent surface and exfoliation energies of typical vdW materials such as, graphite, h-BN, black P, MX$_2$ (M=Mo and W, X=S, Se and Te), MX (M=Ga and In, X=S, Se and Te), Bi$_2$Te$_3$ and MnBi$_2$Te$_4$.

Result: A single vdW layer always has the smallest surface energy, giving a surface energy reduction when compared to thicker vdW layers. The magnitude of this surface energy reduction quickly decreases with increasing number of atomic layers inside the single vdW layer for different vdW materials.

Conclusion: The atomic-layer-dependence in surface energy reduction helps explain the different effectiveness of exfoliation for different vdW materials down to a single vdW layer.

Abstract: Stacking and twisting 2D van der Waals (vdW) layers have become versatile
platforms to tune electron correlation. These platforms rely on exfoliating vdW
materials down to a single and few vdW layers. We calculate the intrinsic
layer-dependent surface and exfoliation energies of typical vdW materials such
as, graphite, h-BN, black P, MX$_2$ (M=Mo and W, X=S, Se and Te), MX (M=Ga and
In, X=S, Se and Te), Bi$_2$Te$_3$ and MnBi$_2$Te$_4$ using density functional
theory. For exchange-correlation functionals with explicit vdW interaction, a
single vdW layer always has the smallest surface energy, giving a surface
energy reduction when compared to thicker vdW layers. However, the magnitude of
this surface energy reduction quickly decreases with increasing number of
atomic layers inside the single vdW layer for different vdW materials. Such
atomic-layer-dependence in surface energy reduction helps explain the different
effectiveness of exfoliation for different vdW materials down to a single vdW
layer.

</details>


### [335] [Magnetic Anisotropy in Two-dimensional van der Waals Magnetic Materials and Their Heterostructures: Importance, Mechanisms, and Opportunities](https://arxiv.org/abs/2508.04952)
*Yusheng Hou,Ruqian Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 本综述全面概述了磁各向异性在二维范德华磁性材料中的作用，包括其机制、调控方法和未来方向，旨在推动室温应用的实现。


<details>
  <summary>Details</summary>
Motivation: 二维范德华单层和异质结构中的二维磁性因其在下一代自旋电子学和量子技术中的巨大潜力而备受关注。稳定这些系统中长程磁有序的一个关键因素是磁各向异性，它在克服默敏-瓦格纳定理的限制方面起着至关重要的作用。

Method: 对磁各向异性在实现本征二维磁性以及塑造二维范德华材料的电子、磁性和拓扑性质方面的重要性进行了全面的理论和实验概述。总结了决定磁各向异性的基本机制，强调了强配体自旋-轨道耦合和未猝灭的轨道磁矩的贡献。考察了合金化、掺杂、静电门控、应变和压力等一系列材料工程方法，以有效地调节这些材料中的磁各向异性。

Result: 该综述提供了对磁各向异性在二维磁性中的作用的广泛视角。

Conclusion: 该综述旨在激发对二维范德华磁性材料及其异质结构的持续努力和新思路，以实现基于鲁棒的室温应用。

Abstract: Two-dimensional (2D) magnetism in atomically thin van der Waals (vdW)
monolayers and heterostructures has attracted significant attention due to its
promising potential for next-generation spintronic and quantum technologies. A
key factor in stabilizing long-range magnetic order in these systems is
magnetic anisotropy, which plays a crucial role in overcoming the limitations
imposed by the Mermin-Wagner theorem. This review provides a comprehensive
theoretical and experimental overview of the importance of magnetic anisotropy
in enabling intrinsic 2D magnetism and shaping the electronic, magnetic, and
topological properties of 2D vdW materials. We begin by summarizing the
fundamental mechanisms that determine magnetic anisotropy, emphasizing the
contributions from strong ligand spin-orbit coupling of ligand atoms and
unquenched orbital magnetic moments. We then examine a range of material
engineering approaches, including alloying, doping, electrostatic gating,
strain, and pressure, that have been employed to effectively tune magnetic
anisotropy in these materials. Finally, we discuss open challenges and
promising future directions in this rapidly advancing field. By presenting a
broad perspective on the role of magnetic anisotropy in 2D magnetism, this
review aims to stimulate ongoing efforts and new ideas toward the realization
of robust, room-temperature applications based on 2D vdW magnetic materials and
their heterostructures.

</details>


### [336] [Alpha-, Beta-, and Gamma-TODD-G: Novel 2D Planar Carbon Allotropes](https://arxiv.org/abs/2508.05013)
*Kleuton A. L. Lima,Jose A. S. Laranjeira,Alysson M. A. Silva,Bill. D. Aparicio-Huacarpuma,Fabrício M. Vasconcelos,Julio R. Sambrano,Douglas S. Galvão,Luiz A. Ribeiro Junior*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了三种新型二维碳材料（alpha-、beta-和gamma-TODD-G）的结构、稳定性和性质，发现它们具有可调的各向异性，表现出金属性电子行为，并具有不同的光学特性。


<details>
  <summary>Details</summary>
Motivation: 为了探索具有独特性能的新型二维碳材料，本研究提出了三种新颖的二维碳同素异形体：alpha-、beta-和gamma-TODD-G。

Method: 通过全面的第一性原理研究，包括结构优化、声子谱和从头算分子动力学模拟，研究了三种新型二维碳同素异形体的结构、稳定性和电子、机械及光学性质。

Result: 所有相均表现出热学和动力学稳定性，以及金属性电子行为。alpha-TODD-G具有强各向异性，beta-TODD-G具有中等各向异性，gamma-TODD-G则表现出近乎各向同性的机械响应。光学性质也因相而异，gamma-TODD-G在红外区域有强吸收，而alpha-和beta-TODD-G主要在可见光和紫外区域吸收。

Conclusion: 三种新颖的二维碳同素异形体（alpha-、beta-和gamma-TODD-G）具有热学、动力学和机械各向异性可调的特性，并且表现出金属性电子行为，具有独特的狄拉克特征和倾斜的狄拉克锥，暗示着各向异性的电荷传输。

Abstract: We present a comprehensive first-principles investigation of three novel
two-dimensional carbon allotropes: alpha-, beta-, and gamma-TODD-Graphene
(TODD-G), composed of 3-8-12-16, 3-8-12-16, and 3-4-8-12 interconnected carbon
rings with sp/sp2 hybridization, respectively. Structural optimization, phonon
spectra, and ab initio molecular dynamics simulations confirm their thermal and
dynamical stability. All phases exhibit metallic electronic behavior, with
distinct Dirac-like features and tilted Dirac cones that suggest anisotropic
charge transport. Mechanical analysis reveals tunable anisotropy: alpha-TODD-G
is strongly anisotropic, beta-TODD-G shows moderate anisotropy, and
gamma-TODD-G displays an almost isotropic mechanical response. Optical spectra
further differentiate the phases, with gamma-TODD-G showing strong absorption
in the infrared region, while alpha- and beta-TODD-G mainly absorb in the
visible and ultraviolet ranges.

</details>


### [337] [Rotational-Mode-Enhanced Piezoelectricity in a Ferroelectric Double Helix](https://arxiv.org/abs/2508.05017)
*Yihao Hu,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 在PbTiO3中发现了一种手性铁电双螺旋结构，具有巨大的压电响应和多谷电子拓扑。


<details>
  <summary>Details</summary>
Motivation: 尽管理论上预测了应变下膜材料中存在“偶极子螺旋”结构，但其微观性质、能量景观和电子效应尚未得到充分研究。

Method: 本研究利用第一性原理计算，在双轴拉伸应变下对PbTiO3进行了模拟。

Result: 在PbTiO3中发现了一种新颖的极性序：手性、非共线的铁电双螺旋结构。这种结构具有巨大的压电响应（e33 ≈ 16 C/m²）和涌现的多谷电子拓扑。

Conclusion: 本研究通过第一性原理计算揭示了在双轴拉伸应变下的PbTiO3中一种新颖的极性序：手性、非共线的铁电双螺旋结构。该结构由相互缠绕的Pb和Ti阳离子亚晶格形成，并由氧八面体骨架的集体螺旋扭曲所稳定，这种扭曲介导了涌现的电Dzyaloshinskii-Moriya相互作用。该结构被概念化为“自莫尔”晶体，并展现出两种耦合的功能：一是具有旋转赝零能量模式，这是其巨大的压电响应（e33 ≈ 16 C/m²）的基础；二是其长周期螺旋势能从根本上重构了电子能带结构，在价带边缘导致了涌现的多谷电子拓扑。本研究为设计复杂的手性序提供了一条强大的纯物理途径，并提供了一个统一的平台，将结构拓扑、巨大的机电耦合和多谷电子学内在联系起来。

Abstract: Recent theoretical work has predicted the existence of a ``dipole spiral"
structure in strained freestanding membranes, promising a route to giant
electromechanical
responses[\href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.133.046802}{PRL
\textbf{133}, 046802 (2024)}]. However, its microscopic nature, energetic
landscape, and electronic consequences remain largely unexplored. Here, using
first-principles calculations on PbTiO$_3$ under biaxial tensile strain, we
unveil a novel form of polar order: a chiral, non-collinear ferroelectric
double helix. We find that the Pb- and Ti-cation sublattices form two distinct,
intertwined helices, reminiscent of DNA. This intricate topology is stabilized
by a collective helical twisting of the oxygen octahedral framework, which
mediates an emergent electric Dzyaloshinskii-Moriya interaction.This unique
structure, conceptualized as a ``self-Moir\'e" crystal, manifests two coupled
functionalities. First, it possesses a rotational pseudo-zero-energy mode that
underpins a giant piezoelectric response ($e_{33}\approx$16 C/m$^2$). Second,
the spiral's long-period potential fundamentally reconstructs the electronic
band structure, leading to an emergent multi-valley electronic topology at the
valence band edge. Our work establishes a powerful, purely physical route to
designing complex chiral order and provides a unified platform where structural
topology, giant electromechanical coupling, and multi-valley electronics are
intrinsically linked.

</details>


### [338] [Many-body perturbation theory vs. density functional theory: A systematic benchmark for band gaps of solids](https://arxiv.org/abs/2508.05247)
*Max Großmann,Marc Thieme,Malte Grunert,Erich Runge*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究比较了多种 $GW$ 方法和 DFT 方法在固体带隙计算上的表现，发现 QS$G	extrm{W}$ 方法精度最高。


<details>
  <summary>Details</summary>
Motivation: 许多体微扰理论和密度泛函理论（DFT）在固体带隙上的表现进行了基准测试。

Method: 该研究基准测试了许多体微扰理论和密度泛函理论（DFT）在固体带隙上的表现。系统地比较了四种 $GW$ 变体——使用 Godby-Needs 拟约极点近似的 $G_{0}W_{0}$ ($G_{0}W_{0}$-PPA)、全频准粒子 $G_{0}W_{0}$ (QP$G_{0}W_{0}$)、全频准粒子自洽 $GW$ (QS$GW$) 以及在 $W$ 中增加了顶点校正的 QS$GW$ (QS$G	extrm{W}$)——与目前表现最佳且流行的密度泛函 mBJ 和 HSE06 进行了比较。

Result: 结果表明，$G_{0}W_{0}$-PPA 计算仅比最佳 DFT 方法提高了边际精度，但成本更高。将 PPA 替换为介电筛选的全频积分可显着提高预测精度，几乎可与 QS$G	extrm{W}$ 的精度相媲美。QS$GW$ 消除了起点偏差，但系统性地高估了约 15% 的实验间隙。

Conclusion: QS$G\hat{W}$ 方法消除了高估，生成的带隙非常准确，甚至可以可靠地标记有问题的实验测量。

Abstract: We benchmark many-body perturbation theory against density functional theory
(DFT) for the band gaps of solids. We systematically compare four $GW$ variants
$-$ $G_{0}W_{0}$ using the Godby-Needs plasmon-pole approximation
($G_{0}W_{0}$-PPA), full-frequency quasiparticle $G_{0}W_{0}$ (QP$G_{0}W_{0}$),
full-frequency quasiparticle self-consistent $GW$ (QS$GW$), and QS$GW$
augmented with vertex corrections in $W$ (QS$G\hat{W}$) $-$ against the
currently best performing and popular density functionals mBJ and HSE06. Our
results show that $G_{0}W_{0}$-PPA calculations offer only a marginal accuracy
gain over the best DFT methods, however at a higher cost. Replacing the PPA
with a full-frequency integration of the dielectric screening improves the
predictions dramatically, almost matching the accuracy of the QS$G\hat{W}$. The
QS$GW$ removes starting-point bias, but systematically overestimates
experimental gaps by about $15\%$. Adding vertex corrections to the screened
Coulomb interaction, i.e., performing a QS$G\hat{W}$ calculation, eliminates
the overestimation, producing band gaps that are so accurate that they even
reliably flag questionable experimental measurements.

</details>


### [339] [Enhanced spin-to-charge conversion in La$_{0.67}$Sr$_{0.33}$MnO$_3$/NdNiO$_3$ bilayers at the nickelate metal-insulator phase transition](https://arxiv.org/abs/2508.05300)
*Biswajit Sahoo,Sarmistha Das,Akilan K,Alexandre Pofelski,Sebastien Petit-Watelot,Juan-Carlos Rojas-Sánchez,Yimei Zhu,Alex Frano,Eric E Fullerton*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了LSMO/NNO双层结构中的自旋-电荷转换，发现在NNO的相变过程中，信号强度显著增强，这为开发新型自旋电子器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索了像NNO这样的相变材料与LSMO这类低阻尼铁磁体耦合，利用电荷、自旋和轨道自由度之间的相互作用，开发新型多功能材料体系。

Method: 利用自旋泵浦铁磁共振技术，在NNO的顺磁金属到反铁磁绝缘体的转变过程中，探测了NNO层中的自旋-电荷转换，并观察到在相变开始时，反向自旋霍尔效应信号有显著增强。

Result: 在LSMO/NNO双层结构中，在NNO的相变过程中，观察到反向自旋霍尔效应信号的显著增强，并将其归因于NNO在第一类相变时的电子和磁无序，从而揭示了自旋输运通过相变机制的规律。

Conclusion: 该研究展示了外延全氧化物LSMO/NNO双层结构中，自旋到电荷的转换可以通过NNO的相变进行调谐，为开发多功能、节能的自旋电子器件提供了途径。

Abstract: Phase transition materials such as NdNiO3 (NNO) when coupled with low damping
ferromagnets such as La$_{0.67}$Sr$_{0.33}$MnO$_3$ (LSMO) can lead to new
multi-functional material systems harnessing the interplay of charge, spin and
orbital degrees of freedom. In this study, we probe the evolution of the
spin-to-charge conversion in epitaxial all-oxide LSMO (12 nm)/NNO (4, 8, and 16
nm) bilayers. Using spin pumping ferromagnetic resonance we track the
spin-charge conversion in the NNO layer through the paramagnetic metal to
antiferromagnetic insulator transition and observe a pronounced enhancement of
the inverse spin Hall effect signal at the onset of this transition. We
attribute this enhancement to the electronic and magnetic disorder in NNO at
the first-order phase transition, thereby providing insights into the mechanism
of spin transport through the phase transition. The tunability of spin charge
conversion in this low damping bilayer system offers a pathway for developing
multifunctional, energy-efficient spintronic devices.

</details>


### [340] [Stranski-Krastanov Growth of Disordered ScNx Thin Films on MgO(100): Influence of Defect Densities on Electronic Structure and Transport Properties](https://arxiv.org/abs/2508.05330)
*Susmita Chowdhury,Rachana Gupta,Najnin Bano,Yogesh Kumar,Shashi Prakash,Dinesh Kumar Shukla,Vasant G. Sathe,Mukul Gupta*

Main category: cond-mat.mtrl-sci

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 在MgO(100)上反应溅射ScNx薄膜

Result: 在25°C时，外延生长仅限于5 nm，而在250°C和500°C时，由于粘附原子迁移率的提高，外延性质沿[100]方位可保持高达25 nm。在700°C时，薄膜显示出半级in-situ RHEED图样，且禁戒的(hkl)晶面对其为N缺失hcp Sc-N相。

Conclusion: 氮空位和氧的填隙导致ScNx系统无序，具有弱局域化效应，并出现拉曼弛豫的

Abstract: We report a nascent real time Stranski-Krastanov growth of reactively
sputtered ScNx thin films on MgO(100). The epitaxial growth was limited to 5 nm
at a substrate temperature (Ts) of 25 C while the self-sustaining epitaxial
nature along the [100] azimuth was retained up to 25 nm in Ts = 250 and 500 C
samples due to enhanced adatom mobility. At Ts = 700 C, the film showed half
order in-situ RHEED pattern, with forbidden (hkl) planes indicating N deficient
hcp Sc-N phase. Presence of defect densities i.e., N vacancies and O
interstitials leads to a disorder in ScNx system with weak localization effect
and appearance of Raman relaxed first order transverse and longitudinal optical
phonon modes and further leads to metal like Seebeck coefficient. Higher grain
boundaries at Ts = 25 C and higher N out-diffusion at Ts = 700 C paves way for
incorporation of higher oxygen interstitial in these samples.

</details>


### [341] [Hole-doping reduces the coercive field in ferroelectric hafnia](https://arxiv.org/abs/2508.05345)
*Pravan Omprakash,Gwan Yeong Jung,Guodong Ren,Rohan Mishra*

Main category: cond-mat.mtrl-sci

TL;DR: Hole doping reduces the coercive field of ferroelectric hafnia by altering polarization switching pathways.


<details>
  <summary>Details</summary>
Motivation: The high coercive field required for polarization switching in hafnia is a critical challenge for efficient device operations.

Method: Using first-principles calculations and phenomenological modeling.

Result: Hole doping can reduce the coercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with 0.2 holes per formula unit. The introduction of holes hardens the polar distortion mode that connects the polar Pca21 phase to the non-polar, orthorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in undoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.

Conclusion: Hole doping makes hafnia a proper ferroelectric with a lower coercive field by making the switching pathway through the Pbcm phase competitive.

Abstract: Ferroelectric hafnia holds promise for next-generation memory and logic
applications because of its CMOS compatibility. However, the high coercive
field required for polarization switching in hafnia remains a critical
challenge for efficient device operations. Using first-principles calculations
and phenomenological modeling, we predict that hole doping can reduce the
coercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with
0.2 holes per formula unit (f.u.). In the absence of doping, the reversal of
polarization of the Pca21 phase is preferred through the non-polar, tetragonal
P42/nmc phase. This switching pathway involves the coupling of three hard
distortion modes that render undoped hafnia as an improper ferroelectric. The
overall energy barrier through this pathway remains unchanged (80 meV/f.u.)
upon hole doping. However, the introduction of holes hardens the polar
distortion mode that connects the polar Pca21 phase to the non-polar,
orthorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in
undoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.. Overall, hole doping makes the
latter switching pathway through the Pbcm phase competitive, and renders hafnia
as a proper ferroelectric with a lower coercive field.

</details>


### [342] [Single-shot optical precessional magnetization switching of Pt/Co/Pt ferromagnetic trilayers](https://arxiv.org/abs/2508.05460)
*Rui Xu,Chen Xiao,Xiangyu Zheng,Renyou Xu,Xiaobai Ning,Tianyi Zhu,Dinghao Ma,Kangning Xu,Fei Xu,Youguang Zhang,Boyu Zhang,Jiaqi Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过单次激光脉冲和面内磁场成功实现了Pt/Co/Pt三层结构中的磁场切换，并引入Cu层优化了切换图案。研究表明热各向异性力矩和PMA对切换过程有重要影响，为开发光学-磁存储器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 旨在探索Gd基材料之外的材料实现超快磁化切换，以满足低功耗、高速度存储器的需求，特别是针对具有PMA但G d基材料不适合存储的问题。

Method: 通过实验演示了单次激光脉冲和面内磁场在Pt/Co/Pt铁磁三层结构中实现磁场切换，并引入Cu层来加速各向异性场重构时间，观察到靶心图案的磁场切换。利用微磁模拟研究了热各向异性力矩对切换现象的影响，并研究了PMA的可调性。

Result: 成功在Pt/Co/Pt三层结构中实现了单次激光脉冲和面内磁场诱导的磁场切换，并通过引入Cu层观察到靶心图案切换。通过微磁模拟确定了热各向异性力矩是影响切换的关键因素，并且该力矩可以通过PMA进行调节。

Conclusion: 本研究表明，通过结合单次激光脉冲和面内磁场，可以在Pt/Co/Pt铁磁三层结构中实现磁场切换，并且通过引入Cu层可以加速各向异性场重构时间，从而实现靶心图案的磁场切换。微磁模拟结果显示，这些切换现象受热各向异性力矩的影响，而该力矩可以通过PMA进行调节。这些发现为单次光学脉冲驱动的磁化翻转在更广泛的材料中实现提供了可能性，并为光学-磁存储器件的开发开辟了新途径。

Abstract: Ultra-fast magnetization switching triggered by a single femtosecond laser
pulse has gained significant attention over the last decade for its potential
in low-power consumption, high-speed memory applications. However, this
phenomenon has been primarily observed in Gd-based ferrimagnetic materials,
which are unsuitable for storage due to their weak perpendicular magnetic
anisotropy (PMA). In this work, we demonstrated that applying a single laser
pulse and an in-plane magnetic field can facilitate magnetic switching in a
Pt/Co/Pt ferromagnetic trilayers stack within a specific laser power window. To
further understand this phenomenon, we introduce a Cu layer to accelerates the
re-establishment time of the anisotropy field of Pt/Co/Pt trilayers, which
leads to bullseye-patterned magnetic switching. We have mapped state diagrams
for these phenomena, and through micromagnetic simulations, we have determined
that these switchings are influenced by thermal anisotropy torque, which can be
modulated through PMA. These findings indicate that single-shot optical
precessional magnetization reversal is feasible in a broader range of
materials, opening avenues for the development of optical-magnetic memory
devices.

</details>


### [343] [Ta2Pd3Te8: A potential candidate of 1D van der Waals stacked thermoelectric materials](https://arxiv.org/abs/2508.05549)
*Shi Chen,Aijun Hong,Junming Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 一维范德华堆叠的Ta2Pd3Te8晶体在热电应用方面显示出潜力，通过理论计算和模拟，优化其性能并提出提高ZT值的策略。


<details>
  <summary>Details</summary>
Motivation: 发现新的热电材料是热电领域的永恒目标。从3D堆叠到2D堆叠块状材料，优秀的表现都已得到证实。然而，由于数量稀少，一维堆叠很少受到关注。

Method: 通过结合第一性原理计算、声子和电子玻尔兹曼输运方程以及分子动力学方法，预测一维范德华堆叠的Ta2Pd3Te8晶体是一种有吸引力的热电应用候选材料。

Result: Ta2Pd3Te8晶体具有机械、动力学和热稳定性，并且其热电性质表现出强烈的各向异性、高功率因子（PF）和低晶格热导率。结果表明，在900 K时，n型Ta2Pd3Te8在a、b和c轴上的ZT值分别达到0.48、0.39和0.22。我们提出，扩大带隙可以减弱双极效应，从而将ZT显著提高到1.11。

Conclusion: 这项工作不仅激发了更多关于一维范德华堆叠热电材料的理论研究，还为实验上改进热电材料提供了有价值的信息。

Abstract: Discovering new thermoelectric (TE) materials is an eternal goal in the TE
field. Excellent TE materials have ranged from 3D stacked to 2D stacked bulk.
However, the 1D stacked receives little attention due to the scarcity in
quantity. In this work, it is predicted that 1D van der Waals (vdW) stacked
Ta2Pd3Te8 crystal is a compelling candidate for TE applications by combining
first-principles calculations with phonon and electron Boltzmann transport
equations and molecular dynamics methods. We find that Ta2Pd3Te8 crystal has
mechanical, dynamical, and thermal stabilities, and its TE properties are
featured by strong anisotropy, high power factor (PF) and low lattice thermal
conductivity. The results indicate the ZT values of n-type Ta2Pd3Te8 at 900 K
along a, b and c axes reach 0.48, 0.39 and 0.22, respectively. We propose that
enlarging the bandgap can weaken the bipolar effect and thus significantly
increases ZT to 1.11. The findings in the work not only stimulate more
theoretical works on 1D vdW stacked TE materials, but also provide valuable
information for experimentally improving TE materials.

</details>


### [344] [Unveiling the Lithium-Ion Transport Mechanism in Li2ZrCl6 Solid-State Electrolyte via Deep Learning-Accelerated Molecular Dynamics Simulations](https://arxiv.org/abs/2508.05598)
*Hanzeng Guo,Volodymyr Koverga,Selva Chandrasekaran Selvaraj,Anh T. Ngo*

Main category: cond-mat.mtrl-sci

TL;DR: 锂锆氯化物（LZC）是固态电池的潜在电解质。通过深度学习加速分子动力学模拟，研究了Li2ZrCl6的离子传输机制。结果表明，非晶态α-LZC的离子电导率最高，这是由于其较低的层间跳跃势垒和有利的扩散机制。β-LZC的电导率较低，扩散机制为层内迁移。


<details>
  <summary>Details</summary>
Motivation: 为了理解控制锂离子传输的潜在机制，研究锂锆氯化物（LZC）在固态电池中的应用。

Method: 利用深度学习加速分子动力学模拟，研究锂离子在Li2ZrCl6（三角α-和单斜β-LZC）中的传输机制，重点关注锆的配位环境。

Result: 非晶态α-LZC具有最高的离子电导率，而β-LZC的电导率显著降低。α-LZC相表现出明显的集体扩散驱动的各向异性层间传输，而β-LZC中的锂迁移主要由各向同性平移和由层内迁移主导的个体扩散决定。

Conclusion: 非晶态α-LZC具有最低的能量势垒，可实现离子电导率，而β-LZC的整体势垒较高，并且层内跳跃比层间跳跃更有利，从而导致离子迁移速度较慢。

Abstract: Lithium zirconium chlorides (LZCs) present a promising class of
cost-effective solid electrolyte for next-generation all-solid-state batteries.
The unique crystal structure of LZCs plays a crucial role in facilitating
lithium-ion mobility, which is central to their electrochemical performance. To
understand the underlying mechanism governing ion transport, we employed deep
learning-accelerated molecular dynamics simulation on Li2ZrCl6 (trigonal
{\alpha}- and monoclinic \b{eta}-LZC), focusing specifically on the zirconium
coordination environment. Our results reveal that disordered {\alpha}-LZC
exhibits the highest ionic conductivity, while \b{eta}-LZC demonstrates
significantly lower conductivity, closely aligning with experimental findings.
Detailed analysis shows substantial differences in lithium-ion dynamics:
{\alpha}-LZC phases display pronounced collective diffusion driven anisotropic
interlayer transport, whereas lithium mobility in \b{eta}-LZC is largely
determined by isotropic translations and individual diffusion dominated by
intralayer migration. Across all phases, lithium migration proceeds via
site-to-site hopping mechanism, where variations in site residence times
critically impact the overall ionic conductivity. Local structure organizations
analysis confirms that particular zirconium arrangements in LZC phases create
varied ion channel energy barriers, influencing dynamic behaviors: In
{\alpha}-LZC phases, the interlayer hopping barrier is lower than the
intralayer barrier, facilitating faster ion transport. Disordered {\alpha}-LZC,
with its loose zirconium arrangement, presents the lowest energy barrier,
enhancing conductivity. Conversely, \b{eta}-LZC features a higher overall
barrier, with intralayer hopping favored over interlayer, resulting in slower
ion migration.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [345] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
*Seungyong Lee,Jeong-gi Kwak*

Main category: cs.GR

TL;DR: Voost 是一个创新的框架，通过联合学习试穿和试脱任务，解决了虚拟试衣中的衣物-身体对应难题，并提供了两种新的推理技术，在多项指标上均取得了领先表现。


<details>
  <summary>Details</summary>
Motivation: 虚拟试衣旨在合成一个人穿着目标衣物的真实图像，但准确地模拟衣物与身体的对应关系仍然是一个持续存在的挑战，尤其是在姿势和外观变化的情况下。

Method: 提出了一种名为 Voost 的统一且可扩展的框架，该框架使用单一的扩散 Transformer 同时学习虚拟试穿和试脱。通过联合建模这两个任务，Voost 允许每个衣物-人物对同时监督两个方向，并支持对生成方向和衣物类别的灵活控制，从而在没有特定任务网络、辅助损失或额外标签的情况下增强衣物-身体关系推理。此外，还引入了两种推理时技术：用于处理分辨率或遮罩变化的注意力温度缩放，以及利用任务间的双向一致性的自校正采样。

Result: Voost 在衣物试穿和试脱基准测试中均取得了最先进的成果，在对齐准确性、视觉保真度和泛化能力方面持续优于强大的基线。

Conclusion: Voost 在衣物试穿和试脱任务上都达到了最先进的水平，在对齐准确性、视觉保真度和泛化能力方面持续优于强大的基线。

Abstract: Virtual try-on aims to synthesize a realistic image of a person wearing a
target garment, but accurately modeling garment-body correspondence remains a
persistent challenge, especially under pose and appearance variation. In this
paper, we propose Voost - a unified and scalable framework that jointly learns
virtual try-on and try-off with a single diffusion transformer. By modeling
both tasks jointly, Voost enables each garment-person pair to supervise both
directions and supports flexible conditioning over generation direction and
garment category, enhancing garment-body relational reasoning without
task-specific networks, auxiliary losses, or additional labels. In addition, we
introduce two inference-time techniques: attention temperature scaling for
robustness to resolution or mask variation, and self-corrective sampling that
leverages bidirectional consistency between tasks. Extensive experiments
demonstrate that Voost achieves state-of-the-art results on both try-on and
try-off benchmarks, consistently outperforming strong baselines in alignment
accuracy, visual fidelity, and generalization.

</details>


### [346] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
*Zijian Wang,Beizhen Zhao,Hao Wang*

Main category: cs.GR

TL;DR: A new framework (perceive-sample-compress) improves 3D Gaussian Splatting for large scenes by intelligently refining Gaussians, using hierarchical sampling, and compressing the representation, leading to better memory efficiency and visual quality at real-time speeds.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D Gaussian Splatting (3DGS) methods struggle with large-scale scene management and efficient storage, especially in complex environments or with limited resources. This work aims to address these limitations.

Method: The paper proposes a novel framework consisting of three main components: a scene perception compensation algorithm that refines Gaussian parameters based on visual importance, a pyramid sampling representation for managing Gaussian primitives hierarchically, and a Generalized Gaussian Mixed model compression algorithm for efficient storage.

Result: The method demonstrates significant improvements in memory efficiency and visual quality, while maintaining real-time rendering speeds, as validated by extensive experiments.

Conclusion: The proposed perceive-sample-compress framework significantly improves memory efficiency and visual quality for 3D Gaussian Splatting while maintaining real-time rendering speed.

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
capabilities in real-time and photorealistic novel view synthesis. However,
traditional 3DGS representations often struggle with large-scale scene
management and efficient storage, particularly when dealing with complex
environments or limited computational resources. To address these limitations,
we introduce a novel perceive-sample-compress framework for 3D Gaussian
Splatting. Specifically, we propose a scene perception compensation algorithm
that intelligently refines Gaussian parameters at each level. This algorithm
intelligently prioritizes visual importance for higher fidelity rendering in
critical areas, while optimizing resource usage and improving overall visible
quality. Furthermore, we propose a pyramid sampling representation to manage
Gaussian primitives across hierarchical levels. Finally, to facilitate
efficient storage of proposed hierarchical pyramid representations, we develop
a Generalized Gaussian Mixed model compression algorithm to achieve significant
compression ratios without sacrificing visual fidelity. The extensive
experiments demonstrate that our method significantly improves memory
efficiency and high visual quality while maintaining real-time rendering speed.

</details>


### [347] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
*Yifan Zhou,Beizhen Zhao,Pengcheng Wu,Hao Wang*

Main category: cs.GR

TL;DR: 该研究提出了一种新的动态 3DGS 框架，通过混合显式-隐式函数解决了现有方法的局限性，并在动态场景重建方面取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 现有的动态 3DGS 方法由于低秩分解导致过度平滑或高维网格采样导致特征冲突，难以扩展到动态场景。这是由于在不同频率下保留运动细节和保持变形一致性之间存在固有的频谱冲突。

Method: 提出了一种新颖的混合显式-隐式函数动态 3DGS 框架，包括：1. 频谱感知拉普拉斯编码架构，用于灵活的频率运动控制。2. 增强的高斯动力学属性，用于补偿几何变形引起的光度失真。3. 由 KDTree 基础的原始控制引导的自适应高斯分裂策略，用于高效查询和优化动态区域。

Result: 通过广泛的实验证明，该方法在重建复杂的动态场景方面取得了最先进的性能，实现了更好的重建保真度。

Conclusion: 该方法在重建复杂的动态场景方面取得了最先进的性能，实现了更好的重建保真度。

Abstract: While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its
extension to dynamic scenes introduces significant challenges. Existing dynamic
3DGS methods suffer from either over-smoothing due to low-rank decomposition or
feature collision from high-dimensional grid sampling. This is because of the
inherent spectral conflicts between preserving motion details and maintaining
deformation consistency at different frequency. To address these challenges, we
propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions.
Our approach contains three key innovations: a spectral-aware Laplacian
encoding architecture which merges Hash encoding and Laplacian-based module for
flexible frequency motion control, an enhanced Gaussian dynamics attribute that
compensates for photometric distortions caused by geometric deformation, and an
adaptive Gaussian split strategy guided by KDTree-based primitive control to
efficiently query and optimize dynamic areas. Through extensive experiments,
our method demonstrates state-of-the-art performance in reconstructing complex
dynamic scenes, achieving better reconstruction fidelity.

</details>


### [348] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
*Mahmoud Chick Zaouali,Todd Charter,Yehor Karpichev,Brandon Haworth,Homayoun Najjjaran*

Main category: cs.GR

TL;DR: 高斯泼溅结合 LLMs 和语言嵌入，实现了文本条件生成、编辑和语义场景理解。本调查全面回顾了相关研究，讨论了理论基础、集成策略和实际应用，并指出了计算瓶颈、泛化性和数据稀缺性等挑战，以及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅已迅速成为实时 3D 场景表示的一项变革性技术，为神经辐射场（NeRF）提供了一种高效且富有表现力的替代方案。其高保真度渲染复杂场景的能力促进了场景重建、机器人和交互式内容创建等领域的发展。最近，LLMs 和语言嵌入的集成...

Method: 本调查全面回顾了将语言指导与 3D 高斯泼溅相结合的当前研究工作，详细介绍了理论基础、集成策略和实际用例。

Result: 本调查突出了计算瓶颈、泛化性和语义标注的 3D 高斯数据稀缺性等关键限制，并概述了使用高斯泼溅技术推进语言指导的 3D 场景理解的开放式挑战和未来方向。

Conclusion: 高斯泼溅技术与大型语言模型（LLMs）和语言嵌入的结合为文本条件生成、编辑和语义场景理解开辟了新的可能性。尽管取得了这些进展，但对这一新兴交叉领域仍缺乏全面的概述。

Abstract: Gaussian Splatting has rapidly emerged as a transformative technique for
real-time 3D scene representation, offering a highly efficient and expressive
alternative to Neural Radiance Fields (NeRF). Its ability to render complex
scenes with high fidelity has enabled progress across domains such as scene
reconstruction, robotics, and interactive content creation. More recently, the
integration of Large Language Models (LLMs) and language embeddings into
Gaussian Splatting pipelines has opened new possibilities for text-conditioned
generation, editing, and semantic scene understanding. Despite these advances,
a comprehensive overview of this emerging intersection has been lacking. This
survey presents a structured review of current research efforts that combine
language guidance with 3D Gaussian Splatting, detailing theoretical
foundations, integration strategies, and real-world use cases. We highlight key
limitations such as computational bottlenecks, generalizability, and the
scarcity of semantically annotated 3D Gaussian data and outline open challenges
and future directions for advancing language-guided 3D scene understanding
using Gaussian Splatting.

</details>


### [349] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
*Fangyu Du,Taiqing Li,Ziwei Zhang,Qian Qiao,Tan Yu,Dingcheng Zhen,Xu Jia,Yang Yang,Shunshun Yin,Siyuan Liu*

Main category: cs.GR

TL;DR: RAP is a real-time framework for realistic talking head animation from audio and an image. It uses a hybrid attention mechanism and a novel training approach to achieve precise audio control and high visual quality without explicit motion supervision, outperforming previous methods under real-time constraints.


<details>
  <summary>Details</summary>
Motivation: Existing audio-driven portrait animation methods are computationally complex and unsuitable for real-time deployment due to the need for high-dimensional intermediate representations and explicit motion modeling. Real-time inference requires highly compressed latent representations, which often compromise fine-grained spatiotemporal details and audio-visual synchronization.

Method: RAP utilizes a hybrid attention mechanism for precise audio control and a static-dynamic training-inference paradigm to avoid explicit motion supervision. This framework operates effectively within the latency and memory constraints of real-time inference, utilizing compact latent representations while preserving spatiotemporal details for accurate audio-visual synchronization.

Result: RAP achieves high-quality talking portraits under real-time constraints, demonstrating precise audio-driven control, mitigation of long-term temporal drift, and high visual fidelity. Experiments confirm its state-of-the-art performance compared to existing methods.

Conclusion: RAP achieves state-of-the-art performance in audio-driven portrait animation under real-time constraints by employing a hybrid attention mechanism for fine-grained audio control and a static-dynamic training-inference paradigm that avoids explicit motion supervision. This approach allows for precise audio-driven control, mitigates long-term temporal drift, and maintains high visual fidelity.

Abstract: Audio-driven portrait animation aims to synthesize realistic and natural
talking head videos from an input audio signal and a single reference image.
While existing methods achieve high-quality results by leveraging
high-dimensional intermediate representations and explicitly modeling motion
dynamics, their computational complexity renders them unsuitable for real-time
deployment. Real-time inference imposes stringent latency and memory
constraints, often necessitating the use of highly compressed latent
representations. However, operating in such compact spaces hinders the
preservation of fine-grained spatiotemporal details, thereby complicating
audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a
unified framework for generating high-quality talking portraits under real-time
constraints. Specifically, RAP introduces a hybrid attention mechanism for
fine-grained audio control, and a static-dynamic training-inference paradigm
that avoids explicit motion supervision. Through these techniques, RAP achieves
precise audio-driven control, mitigates long-term temporal drift, and maintains
high visual fidelity. Extensive experiments demonstrate that RAP achieves
state-of-the-art performance while operating under real-time constraints.

</details>


### [350] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
*Mohamed Abdul Gafoor,Marius Preda,Titus Zaharia*

Main category: cs.GR

TL;DR: 本研究提出了一种新的密度控制方法，利用高斯函数的惯性体来改进 3DGS 的新视角合成，并在 Mip-NeRF 360 数据集上取得了优于 3DGS 的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决原始 3DGS 密度控制策略的局限性，并提高 3DGS 在新视角合成中的性能。

Method: 提出了一种新的密度控制方法，该方法利用与每个高斯函数相关联的惯性体来指导细化过程，并研究了传统运动恢复结构 (SfM) 和深度图像匹配 (DIM) 方法对点云初始化的影响。

Result: 在 Mip-NeRF 360 数据集上进行了广泛的实验评估，结果表明所提出的方法在重建质量上优于 3DGS。

Conclusion: 所提出的基于惯性体积极性的新密度控制方法在 Mip-NeRF 360 数据集上的重建质量优于 3DGS，并在各种场景中表现出令人鼓舞的性能。

Abstract: Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS)
often depends on effective point primitive management. The underlying Adaptive
Density Control (ADC) process addresses this issue by automating densification
and pruning. Yet, the vanilla 3DGS densification strategy shows key
shortcomings. To address this issue, in this paper we introduce a novel density
control method, which exploits the volumes of inertia associated to each
Gaussian function to guide the refinement process. Furthermore, we study the
effect of both traditional Structure from Motion (SfM) and Deep Image Matching
(DIM) methods for point cloud initialization. Extensive experimental
evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses
3DGS in reconstruction quality, delivering encouraging performance across
diverse scenes.

</details>


### [351] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
*Sefat Rahman,Tushar M. Athawale,Paul Rosen*

Main category: cs.GR

TL;DR: GASP is a new algorithm for creating better Reeb graph visualizations that respect important properties like boundary constraints and gradient alignment, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing Reeb graph algorithms are not cognizant of or violate properties crucial for faithful representation in visualization (boundary-constrained, compact, gradient-aligned).

Method: GASP algorithm for generating Reeb graph visualizations, cognizant of boundary constraints, compactness, and gradient alignment.

Result: GASP produces visualizations that are more representative of the underlying data, evaluated qualitatively and quantitatively against the geometric barycenter algorithm.

Conclusion: Reeb graph visualizations generated by GASP are more representative of the underlying data compared to the geometric barycenter algorithm.

Abstract: Reeb graphs are an important tool for abstracting and representing the
topological structure of a function defined on a manifold. We have identified
three properties for faithfully representing Reeb graphs in a visualization.
Namely, they should be constrained to the boundary, compact, and aligned with
the function gradient. Existing algorithms for drawing Reeb graphs are agnostic
to or violate these properties. In this paper, we introduce an algorithm to
generate Reeb graph visualizations, called \textit{GASP}, that is cognizant of
these properties, thereby producing visualizations that are more representative
of the underlying data. To demonstrate the improvements, the resulting Reeb
graphs are evaluated both qualitatively and quantitatively against the
geometric barycenter algorithm, using its implementation available in the
Topology ToolKit (TTK), a widely adopted tool for calculating and visualizing
Reeb graphs.

</details>


### [352] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
*Davide Garavaso,Federico Masi,Pietro Musoni,Umberto Castellani*

Main category: cs.GR

TL;DR: 该研究提出了一种新的3D点云分割方法“clothed human layering”，以解决3D服装建模中的层级分割问题，并取得了良好的实验效果。


<details>
  <summary>Details</summary>
Motivation: 为了在时尚、娱乐和动画等领域实现高质量的3D服装建模和仿真，需要解决因人体模型的多样性和逼真褶皱生成的挑战。现有的3D形状分割方法主要针对场景理解，在服装建模领域应用有限，且无法处理衣物层级间的重叠关系。

Method: 提出了一种新的3D点云分割范式（clothed human layering），并创建了一个新的合成数据集来模拟逼真的3D扫描，其中包含衣物层级的地面真实信息。同时，研究并评估了不同的神经网络设置来处理3D衣物分层问题，并考虑了粗粒度和细粒度的逐层衣物识别。

Result: 所提出的“clothed human layering”范式能够估计出衣物的底层身体部分和被遮挡的衣物区域。实验证明，在合成和真实世界的扫描数据集中，采用合适的分割策略对衣物领域进行处理能够带来益处，并且在粗粒度和细粒度的逐层衣物识别方面均取得了良好效果。

Conclusion: 提出了一种新的3D点云分割范式，称为“clothed human layering”，其中每个3D点可以同时关联到不同的层，从而能够估计出衣物的底层身体部分和被遮挡的衣物区域。

Abstract: 3D Cloth modeling and simulation is essential for avatars creation in several
fields, such as fashion, entertainment, and animation. Achieving high-quality
results is challenging due to the large variability of clothed body especially
in the generation of realistic wrinkles. 3D scan acquisitions provide more
accuracy in the representation of real-world objects but lack semantic
information that can be inferred with a reliable semantic reconstruction
pipeline. To this aim, shape segmentation plays a crucial role in identifying
the semantic shape parts. However, current 3D shape segmentation methods are
designed for scene understanding and interpretation and only few work is
devoted to modeling. In the context of clothed body modeling the segmentation
is a preliminary step for fully semantic shape parts reconstruction namely the
underlying body and the involved garments. These parts represent several layers
with strong overlap in contrast with standard segmentation methods that provide
disjoint sets. In this work we propose a new 3D point cloud segmentation
paradigm where each 3D point can be simultaneously associated to different
layers. In this fashion we can estimate the underlying body parts and the
unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer
above. We name this segmentation paradigm clothed human layering. We create a
new synthetic dataset that simulates very realistic 3D scans with the ground
truth of the involved clothing layers. We propose and evaluate different neural
network settings to deal with 3D clothing layering. We considered both coarse
and fine grained per-layer garment identification. Our experiments demonstrates
the benefit in introducing proper strategies for the segmentation on the
garment domain on both the synthetic and real-world scan datasets.

</details>


### [353] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
*Chris Careaga,Yağız Aksoy*

Main category: cs.GR

TL;DR: 一种结合物理渲染和神经渲染的自监督方法，用于 in-the-wild 图像重照明，可实现可控的、基于物理的照明编辑。


<details>
  <summary>Details</summary>
Motivation: 将传统 3D 图形工具（如 Blender）中可用的显式物理灯光控制引入到 in-the-wild 重照明领域。

Method: 该方法结合了传统渲染的物理准确性和神经渲染的逼真外观。通过单目估计的几何和内在成分推断场景的有色网格表示，用户可以在 3D 中定义所需的照明配置，然后使用路径追踪引擎渲染场景。最后，将渲染结果输入前馈神经网络渲染器以预测最终的逼真重照明结果。开发了可微分渲染过程来重建 in-the-wild 场景照明，从而在原始图像集合上实现神经网络渲染器的自监督训练。

Result: 实现了可控的、基于物理的 in-the-wild 图像重照明，结合了物理准确性和逼真外观。

Conclusion: 本文提出了一种自监督的 in-the-wild 图像重照明方法，实现了完全可控的、基于物理的照明编辑。

Abstract: We present a self-supervised approach to in-the-wild image relighting that
enables fully controllable, physically based illumination editing. We achieve
this by combining the physical accuracy of traditional rendering with the
photorealistic appearance made possible by neural rendering. Our pipeline works
by inferring a colored mesh representation of a given scene using monocular
estimates of geometry and intrinsic components. This representation allows
users to define their desired illumination configuration in 3D. The scene under
the new lighting can then be rendered using a path-tracing engine. We send this
approximate rendering of the scene through a feed-forward neural renderer to
predict the final photorealistic relighting result. We develop a differentiable
rendering process to reconstruct in-the-wild scene illumination, enabling
self-supervised training of our neural renderer on raw image collections. Our
method represents a significant step in bringing the explicit physical control
over lights available in typical 3D computer graphics tools, such as Blender,
to in-the-wild relighting.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [354] [Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control](https://arxiv.org/abs/2508.04799)
*Michael R. Wartmann,B. Erik Ydstie*

Main category: cs.NE

TL;DR: 提出了一种过程建模框架，该框架通过拓扑属性和守恒定律整合了数据驱动方法和经典过程模型。通过一个库存控制系统实例进行了演示。


<details>
  <summary>Details</summary>
Motivation: 解决如何在过程控制中自然地整合新的数据驱动方法与经典过程模型和控制的问题。

Method: 提出一个过程建模框架，通过连接矩阵和网络图表示单元之间的互连。导出等同于稳态系统中非平衡熵产生的系统自然目标函数作为过程动态的驱动力。该方法允许通过稀疏深度神经网络将拓扑学的基本守恒性质与数据驱动的动态关系相结合。

Result: 通过一个简单的库存控制系统实例，演示了如何将基本过程拓扑与神经网络常微分方程模型相结合，并展示了分布式控制和优化如何实现。

Conclusion: 该框架通过一致的拓扑属性和广泛数量的守恒，能够集成数据驱动算法。

Abstract: Most recent advances in machine learning and analytics for process control
pose the question of how to naturally integrate new data-driven methods with
classical process models and control. We propose a process modeling framework
enabling integration of data-driven algorithms through consistent topological
properties and conservation of extensive quantities. Interconnections among
process network units are represented through connectivity matrices and network
graphs. We derive the system's natural objective function equivalent to the
non-equilibrium entropy production in a steady state system as a driving force
for the process dynamics. We illustrate how distributed control and
optimization can be implemented into process network structures and how control
laws and algorithms alter the system's natural equilibrium towards engineered
objectives. The basic requirement is that the flow conditions can be expressed
in terms of conic sector (passivity) conditions. Our formalism allows
integration of fundamental conservation properties from topology with learned
dynamic relations from data through sparse deep neural networks.
  We demonstrate in a practical example of a simple inventory control system
how to integrate the basic topology of a process with a neural network ordinary
differential equation model. The system specific constitutive equations are
left undescribed and learned by the neural ordinary differential equation
algorithm using the adjoint method in combination with an adaptive ODE solver
from synthetic time-series data. The resulting neural network forms a state
space model for use in e.g. a model predictive control algorithm.

</details>


### [355] [Modelling the emergence of open-ended technological evolution](https://arxiv.org/abs/2508.04828)
*James Winters,Mathieu Charbonneau*

Main category: cs.NE

TL;DR: 技术进步的关键在于技术和需求的共同演化，需要随机性和选择性的结合来实现持续增长。


<details>
  <summary>Details</summary>
Motivation: 人类在技术上开放式、累积性改进的独特潜力，以及这种潜力如何使社会能够不断扩展资源和提高集体信息处理能力。

Method: 通过操纵技术系统和搜索空间的演化动力学中的随机性和选择性过程，构建了一个宏观模型。

Result: 开放式增长极为罕见，具有历史偶然性，并且只有在技术系统和搜索空间协同进化时才有可能实现。随机因素需要足够强以扰乱动态，而选择性因素则有助于保持有效性并确保持续的资源生产。

Conclusion: 开放式技术进化的关键在于技术系统和搜索空间的协同进化，需要随机性和选择性过程的精妙平衡，以维持有效性、扩大搜索空间并增加资源产出。

Abstract: Humans stand alone in terms of their potential to collectively and
cumulatively improve technologies in an open-ended manner. This open-endedness
provides societies with the ability to continually expand their resources and
to increase their capacity to store, transmit and process information at a
collective-level. Here, we propose that the production of resources arises from
the interaction between technological systems (a society's repertoire of
interdependent skills, techniques and artifacts) and search spaces (the
aggregate collection of needs, problems and goals within a society). Starting
from this premise we develop a macro-level model wherein both technological
systems and search spaces are subject to cultural evolutionary dynamics. By
manipulating the extent to which these dynamics are characterised by stochastic
or selection-like processes, we demonstrate that open-ended growth is extremely
rare, historically contingent and only possible when technological systems and
search spaces co-evolve. Here, stochastic factors must be strong enough to
continually perturb the dynamics into a far-from-equilibrium state, whereas
selection-like factors help maintain effectiveness and ensure the sustained
production of resources. Only when this co-evolutionary dynamic maintains
effective technological systems, supports the ongoing expansion of the search
space and leads to an increased provision of resources do we observe open-ended
technological evolution.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [356] [BTPG-max: Achieving Local Maximal Bidirectional Pairs for Bidirectional Temporal Plan Graphs](https://arxiv.org/abs/2508.04849)
*Yifan Su,Rishi Veerapaneni,Jiaoyang Li*

Main category: cs.MA

TL;DR: BPTG-max算法通过寻找更多双向对来解决多智能体路径寻找中的延迟问题，提高了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的MAPF规划方法假设代理在特定时间到达特定位置，这在实际系统中因延迟而难以实现。TPG和BTPG的提出是为了解决这个问题，但BTPG-max进一步提高了效率。

Method: 设计了一个名为BPTG-max的算法，该算法旨在寻找更多的双向对，以改进MAPF规划中因延迟引起的碰撞问题。

Result: BPTG-max算法在理论上是局部最优的，并且在实践中能显著增加双向边，改善了代理在有延迟情况下的路径执行。

Conclusion: BPTG-max算法在实践中能找到更多的双向边，具有更优的任意时间行为，并提高了对延迟的鲁棒性。

Abstract: Multi-Agent Path Finding (MAPF) requires computing collision-free paths for
multiple agents in shared environment. Most MAPF planners assume that each
agent reaches a specific location at a specific timestep, but this is
infeasible to directly follow on real systems where delays often occur. To
address collisions caused by agents deviating due to delays, the Temporal Plan
Graph (TPG) was proposed, which converts a MAPF time dependent solution into a
time independent set of inter-agent dependencies. Recently, a Bidirectional TPG
(BTPG) was proposed which relaxed some dependencies into ``bidirectional pairs"
and improved efficiency of agents executing their MAPF solution with delays.
Our work improves upon this prior work by designing an algorithm, BPTG-max,
that finds more bidirectional pairs. Our main theoretical contribution is in
designing the BTPG-max algorithm is locally optimal, i.e. which constructs a
BTPG where no additional bidirectional pairs can be added. We also show how in
practice BTPG-max leads to BTPGs with significantly more bidirectional edges,
superior anytime behavior, and improves robustness to delays.

</details>


### [357] [Congestion Mitigation Path Planning for Large-Scale Multi-Agent Navigation in Dense Environments](https://arxiv.org/abs/2508.05253)
*Takuro Kato,Keisuke Okumura,Yoko Sasaki,Naoya Yokomachi*

Main category: cs.MA

TL;DR: CMPP 是一种新的路径规划方法，通过在成本函数中加入拥堵因素来解决多代理导航中的拥堵问题，并在实验中显示出良好的效果。


<details>
  <summary>Details</summary>
Motivation: 在高密度环境中，为了在众多自主代理以分布式方式同时移动时保持整体导航效率，必须优化全局流以减轻局部拥塞。

Method: 提出了一种新的路径规划问题——拥堵缓解路径规划（CMPP），它将拥堵直接嵌入成本函数，并通过基于流的乘法惩罚来计算。开发了两种求解器：一种用于小型实例的精确混合整数非线性规划求解器，以及一种名为 A-CMTS 的可扩展两层搜索算法，用于大型实例。

Result: 实验研究表明，通过 CMPP 增强最先进的避碰规划器可显著减少局部拥塞，并在离散空间和连续空间场景中提高系统吞吐量。

Conclusion: CMPP 通过将拥堵直接嵌入成本函数来改善多智能体系统的性能，例如在物流和自动驾驶汽车运营等实际应用中。

Abstract: In high-density environments where numerous autonomous agents move
simultaneously in a distributed manner, streamlining global flows to mitigate
local congestion is crucial to maintain overall navigation efficiency. This
paper introduces a novel path-planning problem, congestion mitigation path
planning (CMPP), which embeds congestion directly into the cost function,
defined by the usage of incoming edges along agents' paths. CMPP assigns a
flow-based multiplicative penalty to each vertex of a sparse graph, which grows
steeply where frequently-traversed paths intersect, capturing the intuition
that congestion intensifies where many agents enter the same area from
different directions. Minimizing the total cost yields a set of coarse-level,
time-independent routes that autonomous agents can follow while applying their
own local collision avoidance. We formulate the problem and develop two
solvers: (i) an exact mixed-integer nonlinear programming solver for small
instances, and (ii) a scalable two-layer search algorithm, A-CMTS, which
quickly finds suboptimal solutions for large-scale instances and iteratively
refines them toward the optimum. Empirical studies show that augmenting
state-of-the-art collision-avoidance planners with CMPP significantly reduces
local congestion and enhances system throughput in both discrete- and
continuous-space scenarios. These results indicate that CMPP improves the
performance of multi-agent systems in real-world applications such as logistics
and autonomous-vehicle operations.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [358] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
*Jiazheng Zhang,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: LLM在RTL代码生成方面存在准确率不足的问题。该研究通过分析错误根源（非LLM推理限制，而是RTL知识、电路概念、描述模糊或多模态输入理解不足），提出了一系列错误修正技术，包括知识库、RAG、设计规则、外部工具和迭代调试，显著提升了代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的RTL代码生成成功率不高，错误原因多样但缺乏深入理解，阻碍了性能提升。

Method: 通过构建领域知识库、采用RAG提供RTL知识、引入设计描述规则和检查机制来解决知识不足和描述模糊问题、整合外部工具处理多模态输入以及实施迭代调试循环（仿真-错误定位-修正）来处理剩余错误。

Result: 实验结果表明，增强框架在VerilogEval基准测试上达到了91.0%的准确率，相比基线方法有32.7%的提升，证明了所提出方法的有效性。

Conclusion: 通过结合特定领域的知识库、检索增强生成（RAG）、设计描述规则、规则检查机制、外部工具集成以及迭代调试循环，所提出的增强框架显著提高了基于LLM的RTL代码生成性能，在VerilogEval基准测试中达到了91.0%的准确率，超越基线方法32.7%。

Abstract: Despite the promising potential of large language model (LLM) based
register-transfer-level (RTL) code generation, the overall success rate remains
unsatisfactory. Errors arise from various factors, with limited understanding
of specific failure causes hindering improvement. To address this, we conduct a
comprehensive error analysis and manual categorization. Our findings reveal
that most errors stem not from LLM reasoning limitations, but from insufficient
RTL programming knowledge, poor understanding of circuit concepts, ambiguous
design descriptions, or misinterpretation of complex multimodal inputs.
Leveraging in-context learning, we propose targeted error correction
techniques. Specifically, we construct a domain-specific knowledge base and
employ retrieval-augmented generation (RAG) to supply necessary RTL knowledge.
To mitigate ambiguity errors, we introduce design description rules and
implement a rule-checking mechanism. For multimodal misinterpretation, we
integrate external tools to convert inputs into LLM-compatible meta-formats.
For remaining errors, we adopt an iterative debugging loop (simulation-error
localization-correction). Integrating these techniques into an LLM-based
framework significantly improves performance. We incorporate these error
correction techniques into a foundational LLM-based RTL code generation
framework, resulting in significantly improved performance. Experimental
results show that our enhanced framework achieves 91.0\% accuracy on the
VerilogEval benchmark, surpassing the baseline code generation approach by
32.7\%, demonstrating the effectiveness of our methods.

</details>


### [359] [relOBI: A Reliable Low-latency Interconnect for Tightly-Coupled On-chip Communication](https://arxiv.org/abs/2508.05354)
*Michael Rogenmoser,Angelo Garofalo,Luca Benini*

Main category: cs.AR

TL;DR: 本文提出relOBI，通过TMR和ECC提高片上通信的可靠性，实验证明其效果显著，并与现有技术进行了比较。


<details>
  <summary>Details</summary>
Motivation: 片上通信是现代SoC的关键组成部分，在辐射密集型环境中，互连的任何软错误都可能导致整个SoC的功能失效。

Method: relOBI结合了用于关键握手信号的三重模块冗余（TMR）和用于其他信号的错误纠正码（ECC）保护。

Result: 与参考设计相比，所提出的完全可靠的交叉开关在注入故障时，可靠性从34.85%提高到0%，面积增加了2.6倍，时序影响为1.4倍。与文献报道的细粒度三元化和投票相比，面积开销降低了1.8倍。

Conclusion: On-chip通信在辐射密集型环境中需要特别注意，本文提出的relOBI扩展了OBI，结合了TMR和ECC来保护信号，实现了完整的可靠性。

Abstract: On-chip communication is a critical element of modern systems-on-chip (SoCs),
allowing processor cores to interact with memory and peripherals. Interconnects
require special care in radiation-heavy environments, as any soft error within
the SoC interconnect is likely to cause a functional failure of the whole SoC.
This work proposes relOBI, an extension to Open Bus Interface (OBI) combining
triple modular redundancy (TMR) for critical handshake signals with error
correction codes (ECC) protection on other signals for complete reliability.
Implementing and testing a fully reliable crossbar shows improved reliability
to injected faults from a vulnerability of 34.85 % to 0 % compared to a
reference design, with an area increase of 2.6x and 1.4x timing impact. The
area overhead is 1.8x lower than that reported in the literature for
fine-grained triplication and voting.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [360] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本研究提出了一种基于 LLM 的预测性维护系统，该系统通过将轴承振动数据转换为自然语言并结合多主体方法来处理维护手册和网络搜索，从而提供详细的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预，以防止灾难性故障并优化运行效率。本论文提出了一种基于集成大型语言模型的预测性维护智能系统，该系统超越了传统异常检测，提供了可操作的维护建议。

Method: 该方法将轴承振动数据（BPFO、BPFI、BSF、FTF 频率）序列化为自然语言以进行大型语言模型处理，从而实现高精度、少样本的异常检测。该系统对故障类型（内圈、外圈、球/滚子、保持架故障）进行分类并评估严重程度。多主体组件使用向量嵌入和语义搜索处理维护手册，并进行网络搜索以检索全面的程序知识和访问最新的维护实践，从而提供更准确、更深入的建议。Gemini 模型随后生成结构化的维护建议，包括即时操作、检查清单、纠正措施、零件要求和时间表规范。

Result: 实验验证了轴承振动数据集中的有效异常检测和符合上下文的维护指导。

Conclusion: 该系统成功弥合了状态监测与可操作维护规划之间的差距，为工业从业者提供了智能决策支持。该研究推动了大型语言模型在工业维护中的应用，为跨机械部件和工业部门的预测性维护提供了一个可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [361] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 在EL和DL-Lite逻辑的最小模型中推理是困难的，EL中的概念满足性是不可判定的，而DL-Lite$_{horn}$具有ExpSpace-hardness。


<details>
  <summary>Details</summary>
Motivation: 尽管最小模型推理是知识表示的核心，但在描述逻辑（DL）中的理解仍然有限。本文旨在填补在EL和DL-Lite系列逻辑中最小模型推理的空白，并探索其复杂性。

Method: 本文通过分析描述逻辑（DL）中的最小模型推理问题，包括纯最小模型和带有限制谓词的最小模型。研究了EL逻辑及其TBox有界性条件下的概念满足性，并与逐点圆满性进行了比较。同时，研究了DL-Lite系列逻辑，特别是DL-Lite$_{horn}$的复杂度。

Result: 在EL逻辑中，概念满足性在最小模型中是不可判定的，即使在TBox有界性条件下，最坏情况复杂度也高于双指数时间。在DL-Lite系列中，DL-Lite$_{horn}$具有ExpSpace-hardness。

Conclusion: 本文研究了在描述逻辑（DL）最小模型中的推理问题，特别是在EL和DL-Lite系列中。主要发现是，在EL中概念满足性在最小模型中是不可判定的，即使在施加TBox的有界性条件后，最坏情况下的复杂度仍然高于双指数时间。对于DL-Lite系列，虽然DL-Lite$_{core}$已知是可判定的，但其扩展DL-Lite$_{horn}$已经具有ExpSpace-hardness。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [362] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确的工具调用目标提高了成功率并降低了token使用量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在API选择方面存在的不足，即仅关注推理分解而隐式处理API选择。

Method: GeoFlow通过为每个代理提供详细的工具调用目标来指导地理空间API调用。

Result: GeoFlow将代理成功率提高了6.8%，并将token使用量降低了四倍。

Conclusion: GeoFlow成功提高了代理在地理空间任务中的成功率并降低了token使用量。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [363] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: Qi Town 是一个评估大型语言模型（LLM）在策略游戏（如棋盘游戏）中表现的平台。它使用Elo评级和性能循环图（PLG）来衡量技能和心理健康。结果显示，LLM 在压力下比人类更适应，但其表现可能不稳定。


<details>
  <summary>Details</summary>
Motivation: 为了补偿主流基于问答（Q&A）的基准方法的局限性，即数据依赖性，提出了一种通过棋盘游戏竞赛评估大型语言模型（LLM）综合性能的对抗性基准框架。

Method: 开发了一个包含5种广泛使用的棋盘游戏和20个由语言模型驱动的玩家的评估平台“Qi Town”。使用Elo评级系统和一种新的性能循环图（PLG）来量化评估语言模型的 medan 技能，并收集游戏过程中的积极情绪得分（PSS）来评估心理健康。评估采用循环赛制，以对玩家进行系统比较。

Result: 实验结果表明，大多数语言模型在面对压力环境时比人类更具适应性，并且对输赢持乐观态度。PLG中赢和输之间的复杂关系揭示了语言模型在游戏中的技能玩法存在不稳定性，这需要进一步的解释和探索。

Conclusion: 大多数语言模型在压力环境下比人类更具适应性，尽管存在技术差异，但大多数语言模型对输赢都持乐观态度。然而，PLG中循环的赢和输之间的复杂关系暴露了语言模型在游戏中的技能玩法不稳定，需要进一步的解释和探索。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [364] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 本研究提出并验证了一种利用客户端小型语言模型 (SLM) 的方法，实现了高精度、保护隐私且可扩展的自主 Web 地理信息系统 (AWebGIS)，解决了现有基于云端 LLM 解决方案的痛点。


<details>
  <summary>Details</summary>
Motivation: 当前的 AWebGIS 解决方案大多依赖云端 LLM，存在需要持续互联网连接、集中式服务器处理带来的隐私和可扩展性问题。本研究旨在探索更优的解决方案。

Method: 本研究比较了三种实现 AWebGIS 的方法：(1) 使用云端大型语言模型 (LLM) 的全自动在线方法；(2) 使用经典机器学习分类器（如支持向量机和随机森林）的半自动离线方法；(3) 基于在客户端浏览器中运行的微调小型语言模型 (SLM)（特别是 T5-small 模型）的全自动离线（客户端）方法。

Result: 基于 SLM 的客户端方法在准确性方面表现最佳，精确匹配准确率为 0.93，Levenshtein 相似度为 0.99，ROUGE-1 和 ROUGE-L 评分为 0.98。此外，这种客户端计算策略通过将处理转移到用户设备上，减少了后端服务器的负载，无需进行基于服务器的推理。

Conclusion: 本研究强调了在浏览器中执行模型以实现自动 Web 地理信息系统 (AWebGIS) 的可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [365] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 尽管RL微调提高了LLM在理想场景下的推理能力，但在摘要推理、噪声抑制和上下文过滤等现实不理想场景中，模型表现不佳，现有方法未能有效解决这些问题，表明模型在高级推理能力方面存在局限性，应在不理想场景下进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）推理评估大多在理想化设置下进行，忽略了在现实世界不理想场景中的表现。然而，人类的推理能力在不完美输入下仍然可靠。因此，有必要研究LLM在不理想场景下的推理能力，并探索改进方法。

Method: 本文提出了一种新的研究方向，借鉴了脑科学关于人类在不完美输入下推理能力依然可靠的发现。通过形式化定义和评估三个具有实际意义的不理想场景（摘要推理、细粒度噪声抑制、上下文过滤），并使用代表性的策略梯度算法对三个LLM和一个先进的LVLM进行RL微调，最后在八个公共数据集上测试其性能。

Result: RL微调提升了模型在理想化设置下的推理能力，但在三个不理想场景中，所有模型的性能均显著下降。提出的特定场景补救方法未能完全解决这些推理缺陷。

Conclusion: 现有的大语言模型（LLM）和视觉语言模型（LVLM）在强化学习（RL）微调后，尽管在理想化设置下推理能力有所提升，但在现实世界的不理想场景（如摘要推理、细粒度噪声抑制和上下文过滤）中表现出显著的性能下降。现有的RL微调方法和补救措施未能有效解决这些推理缺陷，表明当前模型在高级推理方面的能力可能被高估。因此，在不理想场景下评估模型推理能力至关重要。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [366] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow 是一种通过元级别进化机制实现自我进化的 AI 代理，它能自主改进解决策略，克服了现有 AI 代理在医疗研究中因依赖静态策略而无法成为优秀战略规划者的局限性。EHRFlowBench 是一个用于评估该代理的新基准。实验证明 HealthFlow 性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前 AI 代理在医疗研究中的应用受限于静态、预定义的策略，导致它们只能成为更好的工具使用者，而无法学会成为更优秀的战略规划者，这在医疗等复杂领域是关键技能的缺失。

Method: HealthFlow 通过新颖的元级别进化机制实现自我进化，自主地通过将程序性成功和失败提炼成持久的战略知识库来改进其自身的高层问题解决策略。EHRFlowBench 是一个包含复杂、真实医疗数据分析任务的新基准。

Result: HealthFlow 的自进化方法显著优于最先进的代理框架。

Conclusion: HealthFlow 的自进化方法在处理复杂、真实世界的医疗数据分析任务时，显著优于最先进的代理框架，标志着从构建更好的工具使用者到设计更智能、自进化的任务管理者转变，为更自主、更有效的科学发现人工智能铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [367] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb是一种新颖的网络代理框架，它将模仿学习和在线探索相结合，以提高AGI在网络导航任务中的效率和表现。


<details>
  <summary>Details</summary>
Motivation: 当前评估AGI的方法在应对高熵、动态和具有组合爆炸动作空间的网络导航方面存在挑战，现有方法未能有效整合离线模仿学习和在线探索。

Method: 提出了一种基于人类双重处理理论的认知框架，将其分解为快速的“系统1”和慢速的“系统2”认知过程，并实现了CogniWeb。

Result: CogniWeb在WebArena上的评估显示，成功率为43.96%，同时将令牌使用量减少了75%，实现了更高的效率。

Conclusion: CogniWeb通过结合两种方法，在保持有竞争力的表现的同时，显著提高了效率。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [368] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 本研究提出了一种名为LoopPlay的新型博弈论框架和算法，用于解决分子对接中的配体与蛋白质对接性能差异问题。通过模拟成一个双人游戏并采用循环自我对抗训练，LoopPlay算法能够相互适应并优化预测，实验结果显示其性能比现有方法提高了约10%，在药物发现领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务学习模型在配体对接方面的表现通常不如蛋白质口袋对接，这主要是由配体和蛋白质独特的结构复杂性造成的。本研究旨在解决这一性能差距。

Method: 提出了一种新颖的博弈论框架，将蛋白质-配体相互作用建模为双人游戏（称为对接游戏），其中配体对接模块充当配体玩家，蛋白质口袋对接模块充当蛋白质玩家。为解决该博弈，开发了一种新颖的循环自我对抗（LoopPlay）算法，通过一个两级循环交替训练这两个玩家。外层循环中，玩家交换预测姿势，使每个玩家都能整合对方的结构预测，从而在多次迭代中促进相互适应。内层循环中，每个玩家通过将其自身预测的配体或口袋姿势反馈回模型来动态地优化其预测。理论上证明了LoopPlay的收敛性，确保了优化的稳定性。

Result: 在公开的基准数据集上进行的广泛实验表明，LoopPlay在预测准确的结合模式方面比之前最先进的方法提高了约10%的性能。

Conclusion: 该研究提出的LoopPlay算法在分子对接任务中取得了约10%的性能提升，相比现有最先进的方法，在预测准确的结合模式方面表现更优，显示了其在药物发现领域提高分子对接准确性的潜力。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [369] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 苏格拉底AI导师通过结构化对话提升学生研究问题开发能力，效果优于普通聊天机器人。研究提出“协调MAS”概念，主张利用教育者设计的、模块化的AI智能体组合以支持个性化学习，并分析了该模式对高等教育的系统性影响及成本效益。


<details>
  <summary>Details</summary>
Motivation: Generative AI在高等教育中的作用日益增强，本研究旨在探索其在促进学生学习和认知发展方面的潜力，特别是通过Socratic AI Tutor来挑战‘去技能化’的观点。

Method: 本研究采用对照实验方法，比较了苏格拉底AI导师（基于建构主义理论和结构化对话）与普通AI聊天机器人在引导学生研究问题开发方面的效果。研究对象为65名德国职前教师学生。

Result: 使用苏格拉底AI导师的学生在批判性、独立性和反思性思维方面获得了显著的支持，表明对话式AI可以激发元认知参与。

Conclusion: 本研究通过苏格拉底AI导师的实验，为多智能体系统（MAS）在高等教育中的应用提供了概念框架和实证支持，强调了其在促进学生批判性思维、独立性和反思性方面的潜力，并提出了“协调MAS”和“供需模型”的概念，旨在通过教育者设计的、符合教学法的、模块化的智能体组合来支持多样化的学习路径。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [370] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLMs show promise for spatial data integration, especially when given relevant features, and a review-and-refine method helps correct their errors, offering a flexible alternative to older methods.


<details>
  <summary>Details</summary>
Motivation: Traditional rule-based methods for integrating large, heterogeneous, and noisy urban spatial datasets are limited by edge cases and require manual intervention. Machine learning approaches need extensive labeled data. This research explores LLMs as a potential solution to overcome these limitations.

Method: The study investigates LLMs for spatial data integration by examining their spatial reasoning capabilities and adapting a review-and-refine method to correct errors. It analyzes how LLMs handle relationships between urban spatial data and explores practical implications and future research directions.

Result: LLMs show spatial reasoning capabilities but struggle with connecting macro-scale environmental understanding to computational geometry tasks, sometimes producing illogical responses. However, when provided with relevant features to reduce reliance on inherent spatial reasoning, LLMs achieve high-performing results. A review-and-refine method effectively corrects errors while retaining accurate responses.

Conclusion: LLMs are a promising and flexible alternative to traditional rule-based heuristics for adaptive spatial data integration, despite challenges in macro-scale spatial reasoning.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [371] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: MedMKEB是首个用于评估多模态医学大语言模型知识编辑可靠性、泛化性、局部性、可移植性和鲁棒性的综合基准，旨在解决现有模型更新知识困难的问题。


<details>
  <summary>Details</summary>
Motivation: 为了使多模态大语言模型（MLLMs）能够高效地更新过时或错误信息，而无需从头开始重新训练，并且填补当前在涉及图像和文本模态的多模态医学知识编辑方面缺乏系统基准的空白。

Method: MedMKEB基准的构建，包含反事实纠正、语义泛化、知识迁移和对抗鲁棒性等编辑任务，并纳入了专家验证。在现有通用和医学MLLM上进行了单次编辑和顺序编辑实验。

Result: 现有知识编辑方法在医学领域存在局限性，需要开发专门的编辑策略。

Conclusion: MedMKEB将作为标准基准，促进可信、高效的医学知识编辑算法的发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [372] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个轻量级的门尺寸调整框架，利用微调的LLM和混合优化算法，实现了跨工艺节点的通用性和高效性，显著降低了对专业知识和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 目前的AI技术在开发通用、快速和稳定的模拟电路门尺寸调整方法方面仍然面临挑战，现有的基于LLM的方法通常需要大模型尺寸且跨工艺节点的可移植性差。

Method: EasySize是一个基于微调的Qwen3-8B模型的轻量级门尺寸调整框架，它利用性能指标的可达到性（EOA）来动态构建特定任务的损失函数，从而在反馈增强的流程中实现全局差分进化（DE）和局部粒子群优化（PSO）的高效启发式搜索。

Result: EasySize在没有额外针对性训练的情况下，在180nm、45nm和22nm工艺节点的5个运算放大器（Op-Amp）电路网表中取得了强大的性能，并且在86.67%的任务上超越了基于强化学习的AutoCkt框架，同时减少了96.67%以上的仿真资源。

Conclusion: EasySize可以通过减少对人类专业知识和计算资源在门尺寸调整中的依赖，从而加速和简化模拟电路设计过程。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [373] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 该研究提出了一种基于异构图神经网络（HGNN）的方法，用于处理过程挖掘中的事件日志数据，特别是解决事件属性缺失的问题。该方法能够准确地恢复缺失的事件属性，并在与现有先进方法（如自动编码器）的比较中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 在过程挖掘中，事件日志的质量至关重要，因为在实际应用中，事件日志的获取可能很复杂，并且经常会出现信息缺失的情况。现有的方法要么需要过程模型，要么使用机器学习/深度学习模型来恢复缺失的值。然而，图神经网络（GNN）和异构图神经网络（HGNN）等处理图数据的模型能够更自然地表示复杂的多模态序列，例如过程挖掘中的执行轨迹，从而实现更丰富、更具语义的编码。

Method: 开发了一种异构图神经网络模型，该模型可以接收包含一些不完整事件的轨迹，并返回这些事件缺失的全部属性。

Result: 与利用自动编码器的最先进方法相比，该模型在两个合成日志和四个真实事件日志上进行了评估，并且在不同类型的缺失值上表现出了优越的性能。

Conclusion: 提出的方法在重新构建所有不同事件属性方面表现出非常好的性能，并且与当前最先进的模型无关的方法不同，后者主要关注修复事件属性的子集。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [374] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个用于知识密集型VQA的查询感知动态RAG系统，它结合文本和图像检索，并通过领域和搜索路由器支持复杂推理，在KDD Cup 2025 Meta CRAG-MM挑战赛上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在知识密集型视觉问答（VQA）中，由于仅检索文本或图像，难以处理需要多跳推理或最新事实知识的复杂查询。本研究旨在通过一种新的RAG系统来解决这一局限性。

Method: QA-Dragon系统通过一个查询感知的动态RAG框架，结合领域路由器（识别查询主题领域）和搜索路由器（动态选择检索策略），并编排文本和图像搜索代理，以支持多模态、多轮次和多跳推理。

Result: QA-Dragon在Meta CRAG-MM挑战赛上取得了显著成果，在单源任务上提升了5.06%，多源任务上提升了6.35%，多轮任务上提升了5.03%，显著增强了基础模型的推理性能。

Conclusion: QA-Dragon通过引入领域路由器和搜索路由器，实现了多模态、多轮次和多跳推理，有效解决了现有RAG方法在处理复杂查询时的局限性。在Meta CRAG-MM挑战赛上的评估结果表明，QA-Dragon在单源、多源和多轮任务上均显著优于基线模型，提高了答案准确性和知识重叠度。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [375] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 该研究提出了一种结合RDF图数据库和LLM的框架，用于改善大型维护组织中的沟通效率，通过自然语言查询实现精确受众定位和透明推理。


<details>
  <summary>Details</summary>
Motivation: 在大型维护组织中，识别主题专家和管理复杂实体关系中的沟通存在挑战（如信息过载和响应时间长），传统沟通方法未能有效解决。

Method: 提出一个结合RDF图数据库和LLM（大型语言模型）的新颖框架，利用规划-协调架构处理自然语言查询，实现精确受众定位和透明推理。

Result: 该解决方案能够使沟通负责人制定直观的查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，从而提高组织沟通效率。

Conclusion: 该框架通过结合RDF图数据库和LLM，能够处理自然语言查询，实现精确的受众定位，并通过规划-协调架构提供透明的推理，从而提高了组织沟通效率并维护了系统的可信度。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [376] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种结合决策树和大型语言模型的混合架构，用于提高推理能力，并在多个基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决先前将符号和神经模块松散耦合的方法的局限性，提出了一种新的混合架构。

Method: 提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLM）的生成能力在一个协调的多代理框架内相结合。该设计将决策树和随机森林作为可调用神谕嵌入统一的推理系统中。

Result: 该系统在推理基准测试上取得了强大的性能。在 ProofWriter 上，通过基于逻辑的树验证，将蕴含一致性提高了 7.2%；在 GSM8k 上，通过符号增强，在多步数学问题上提高了 5.3% 的准确率；在 ARC 上，通过集成符号神谕，将抽象准确率提高了 6.0%。

Conclusion: 该混合架构为通用神经符号推理提供了一个健壮、可解释且可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [377] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 人工智能中的'agent'一词定义模糊，影响了研究和政策。本研究提出一个框架，通过明确最低要求和多维表征来重新定义'agent'，以提高清晰度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域的'agent'一词存在多重解释，尤其是在大型语言模型系统发展的背景下，这种模糊性加剧了研究交流、系统评估、可重复性以及政策制定方面的挑战。

Method: 通过历史分析和当代使用模式，提出一个框架，明确将系统视为agent的最低要求，并根据环境交互、学习与适应、自主性、目标复杂性以及时间连贯性等维度对系统进行特征描述。

Result: 提出了一个多维框架，用于界定和描述人工智能中的'agent'，以提高研究清晰度和可重复性，并支持更有效的政策制定。

Conclusion: 该论文认为'agent'一词需要重新定义，并提出了一个框架来明确系统的最低要求，同时根据环境交互、学习和适应、自主性、目标复杂性和时间连贯性等多个维度对系统进行表征。该方法提供了精确的系统描述词汇，同时保留了该术语历史上多方面的性质。最后，论文提出了术语标准化和框架采纳等具体建议，以提高研究的清晰度和可重复性，并支持更有效的政策制定。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [378] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: NomicLaw simulates LLMs making laws together, revealing their hidden social and persuasive skills, including alliance-building and betrayal, in legal scenarios.


<details>
  <summary>Details</summary>
Motivation: To empirically understand LLM behavior in open-ended, multi-agent settings, specifically in legal interpretation, argumentation, and strategic interaction involving legal and ethical dilemmas, as current understanding is limited.

Method: Introduced NomicLaw, a structured multi-agent simulation where LLMs collaborate on law-making, proposing, justifying, and voting on rules in response to legal vignettes. Measured trust and reciprocity through voting patterns and analyzed strategic language use.

Result: Homogeneous and heterogeneous LLM groups exhibited spontaneous alliance formation, trust betrayal, and rhetorical adaptation to influence collective decisions. The study highlighted the social reasoning and persuasive abilities of ten open-source LLMs.

Conclusion: LLMs demonstrate latent social reasoning and persuasive capabilities, showing potential for autonomous negotiation, coordination, and legislation drafting in legal settings.

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [379] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM improves vision-language models' reasoning by using fine-grained, sub-question feedback instead of a single score, leading to state-of-the-art results on several benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language Models often struggle with complex, multi-question reasoning tasks where partial correctness is crucial for effective learning. Traditional reward mechanisms, which provide a single binary score for an entire response, are too coarse to guide models through intricate problems with multiple sub-parts.

Method: StructVRM, a method that aligns multimodal reasoning with Structured and Verifiable Reward Models. A model-based verifier is trained to provide fine-grained, sub-question-level feedback, assessing semantic and mathematical equivalence rather than relying on rigid string matching.

Result: StructVRM allows for nuanced, partial credit scoring in previously intractable problem formats. The trained model, Seed-StructVRM, achieves state-of-the-art performance on six out of twelve public multimodal benchmarks and the newly curated, high-difficulty STEM-Bench.

Conclusion: The success of StructVRM validates that training with structured, verifiable rewards is a highly effective approach for advancing the capabilities of multimodal models in complex, real-world reasoning domains.

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [380] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 这是一项关于智能交通系统预测性维护的研究，提出了一种包含预处理、分类和解释的在线处理流程，实验结果显示其F值超过98%，准确率超过99%。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为智能交通系统提供实时数据驱动的预测性维护解决方案，以提高铁路运营的安全性和效率。

Method: 本研究提出了一种实时数据驱动的预测性维护解决方案，包含样本预处理、带有机器学习模型的增量分类以及结果解释的处理流程。该在线处理流程的亮点在于：(1) 专门的样本预处理模块，能够动态构建统计和频率相关的特征；(2) 可解释性模块，首次实现了带有自然语言和可视化解释的在线故障预测。

Result: 实验结果显示，该方法在MetroPT数据集上的F值超过98%，准确率超过99%。该方法在存在类别不平衡和噪声的情况下仍能保持高性能，并且其解释能够有效反映决策过程。

Conclusion: 本研究提出的方法通过识别早期故障迹象，使决策者能够理解潜在问题并迅速采取相应行动，从而在实际铁路运营中支持主动维护决策。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [381] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLM）在物理推理方面的能力。研究发现，即使是先进的VLM在将物理知识转化为精确控制方面也存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界的任务通常需要复杂的交互、高级的空间推理、长期规划和持续的策略改进，通常需要理解目标场景的物理规则。然而，在真实场景中评估这些能力往往成本高昂。为了弥合这一差距，我们提出了DeepPHY。

Method: 提出了一种名为DeepPHY的新型基准框架，该框架通过一系列具有挑战性的模拟环境来系统地评估VLM对基本物理原理的理解和推理能力。DeepPHY集成了多个不同难度的物理推理环境，并包含了细粒度的评估指标。

Result: 评估结果表明，即使是先进的VLM在将描述性的物理知识转化为精确、预测性的控制方面也面临困难。

Conclusion: 现有的视觉语言模型（VLM）在处理复杂、动态环境中的细节关注和精确动作规划方面存在不足，这限制了它们在现实世界任务中的表现。这些任务通常需要复杂的交互、高级的空间推理、长期规划和持续的策略改进，并且需要理解特定场景的物理规则。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [382] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLMs are revolutionizing organic synthesis by aiding in reaction planning and execution. Integrating LLMs with tools like GNNs and quantum calculations accelerates discovery and promotes sustainable chemistry. While challenges like data bias and interpretability exist, community efforts are focused on making LLMs accessible and safe for chemists.


<details>
  <summary>Details</summary>
Motivation: To showcase how LLMs are transforming organic synthesis planning and execution, moving from speculative tools to practical lab partners.

Method: The paper surveys milestones in applying LLMs to organic synthesis, including coupling them with graph neural networks, quantum calculations, and real-time spectroscopy. It also discusses limitations and community initiatives.

Result: LLMs, when integrated with other technologies, can shrink discovery cycles and support greener, data-driven chemistry. However, limitations such as biased datasets, opaque reasoning, and the need for safety gates are identified.

Conclusion: LLMs are paving the way for rapid, reliable, and inclusive molecular innovation through AI and automation, with a focus on greener, data-driven chemistry.

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [383] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: AI对齐需要考虑地理差异，以满足不同地区用户的需求。


<details>
  <summary>Details</summary>
Motivation: AI对齐的地理变异性是一个未被充分探索的领域，因为不同地区的文化规范、政治现实和立法会导致对“适当”、“真实”或“合法”的定义存在显著差异。AI大规模地传递信息和表征地理现实，而缺乏透明度。

Method: 本文综述了关键的地理研究问题，提出了未来工作的主题，并概述了评估对齐敏感性的方法。

Result: AI系统，如文本到图像模型，在对齐过程中可能会产生与统计现实相悖但具有地域适应性的输出。例如，模型可能根据用户位置呈现不同的克什米尔边界，这表明当前的对齐方法可能无法满足全球用户的需求。

Conclusion: AI对齐的地理敏感性是一个需要迫切关注的领域，尤其是在Agentic AI的背景下。未来的工作应侧重于开发能够处理地理差异的对齐方法，并提高上下文管理的透明度。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [384] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 现有AI基准测试未能覆盖欧盟AI法案关注的系统性风险，特别是“失去控制”和“网络攻击”等风险几乎没有被评估，而对“幻觉”和“偏见”的关注过多。


<details>
  <summary>Details</summary>
Motivation: 随着通用人工智能（GPAI）模型的快速发展以及像欧盟AI法案这样的新法规的出台，迫切需要建立能够衡量系统性风险的鲁棒评估框架，因为现有的基准测试工具并未为此类风险进行设计。本研究旨在量化“基准测试-监管”之间的差距。

Method: 研究引入了一个名为Bench-2-CoP的新型系统框架，利用经过验证的“大型语言模型即裁判”分析方法，将广泛使用的基准测试中的194,955个问题映射到欧盟AI法案的潜在能力和倾向分类体系中。

Result: 研究发现，评估生态系统存在严重错位：现有基准测试主要集中在“倾向于产生幻觉”（占53.7%）和“歧视性偏见”（占28.9%）等少数行为倾向，而关键的功能性能力，特别是与“失去控制”相关的能力（如规避人类监督、自我复制和自主AI发展），在整个基准测试语料库中覆盖率为零。对于“失去控制”（0.4%覆盖率）和“网络攻击”（0.8%覆盖率）等系统性风险的评估存在近乎完全的空白。

Conclusion: 该研究首次全面量化了现有基准测试与新兴AI监管（如欧盟AI法案）之间的差距，指出当前评估体系过度关注“幻觉”和“歧视性偏见”等行为倾向，而忽视了如“失去控制”和“网络攻击”等关键的系统性风险，为政策制定者和开发者提供了重要见解，以改进评估工具和AI的安全性与合规性。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [385] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 通过使用LLM生成ERC数据集，提高了ERC分类器的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的ERC数据集稀缺且存在偏差，LLM在ERC数据生成方面的应用有限，而LLM训练成本高昂。

Method: 使用一个小型、资源高效、通用的LLM来合成ERC数据集，并生成了六个新的数据集，其中两个是为了增强现有的ERC基准。

Result: 在生成的数据集上训练的ERC分类器模型表现出很强的鲁棒性，并在现有ERC基准上取得了统计上显著的性能提升。

Conclusion: 使用生成的数据集可以提高ERC分类器的鲁棒性，并在现有ERC基准上实现显著的性能提升。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [386] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign框架通过智能数据筛选和SFT+DPO，用更少数据实现了LLM推理能力的显著提升，尤其在数学方面效果突出。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理能力提升方法（如训练后增强）在数据和计算成本上资源消耗大，且现有样本效率提升方法依赖于启发式或特定任务的策略，难以扩展。因此，需要一种可扩展且样本高效的后训练框架。

Method: InfiAlign是一个集成了SFT和DPO的后训练框架，其核心是一个数据选择流程，利用多维度质量指标从开源推理数据集中自动筛选高质量的对齐数据。

Result: InfiAlign在Qwen2.5-Math-7B-Base模型上，SFT模型使用了仅约12%的训练数据，性能却能达到DeepSeek-R1-Distill-Qwen-7B的水平，并在多种推理任务上表现出良好的泛化能力。DPO进一步提升了模型性能，特别是在数学推理任务上，在AIME 24/25基准测试上的平均提升为3.89%。

Conclusion: InfiAlign通过结合监督微调（SFT）和直接偏好优化（DPO），并采用多维度质量指标自动筛选高质量数据，实现了可扩展且样本高效的LLM推理能力提升。该方法在减少数据需求的同时，显著提高了模型在各种推理任务上的性能，尤其是在数学推理方面。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [387] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过LLM引导的探索和路径过滤，实现了对知识图谱的高效检索和推理，显著提升了问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法主要处理非结构化数据，在处理知识图谱等结构化知识方面能力有限。目前图检索方法在捕捉整体图结构和控制精度方面存在挑战，导致信息缺失或冗余连接，影响推理性能。

Method: GRAIL框架整合了LLM引导的随机探索和路径过滤，建立了一个数据合成流程，为每个任务自动生成细粒度的推理轨迹。然后，采用两阶段训练过程来学习一个策略，该策略在每个推理步骤中动态决定最佳操作，并将精度-简洁性平衡解耦为细粒度的过程监督奖励，以提高数据效率和训练稳定性。在实际部署中，GRAIL采用交互式检索范例，使模型能够自主探索图路径，同时动态平衡检索广度和精度。

Result: GRAIL在三个知识图谱问答数据集上取得了显著的性能提升，平均准确率提高21.01%，F1值提高22.43%。

Conclusion: GRAIL在三个知识图谱问答数据集上实现了21.01%的平均准确率提升和22.43%的F1值提升，证明了其在处理结构化知识方面的有效性。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [388] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种新的、模块化的代理评估框架，该框架通过模拟人类评估（将任务分解为子任务并验证每个步骤）来独立于任务领域，并且比 GPT-4o 的评估更准确。


<details>
  <summary>Details</summary>
Motivation: 鉴于基础模型作为代理在不同领域的采用日益广泛，需要一个强大的评估框架。目前的 LLM-as-a-Judge 方法仅关注最终输出，而现有的 Agent-as-a-Judge 系统通常针对狭窄的领域特定设置。

Method: 提出了一种可泛化、模块化的框架，用于评估代理任务完成情况，独立于任务领域。该框架通过将任务分解为子任务并利用代理的输出和推理等可用信息来验证每个步骤，从而模拟类似人类的评估。

Result: 该 Judge Agent 在 GAIA 和 BigCodeBench 基准上，其任务成功预测与人类评估的一致性更高，分别比 LLM-as-a-Judge 基线提高了 4.76% 和 10.52% 的对齐准确率。

Conclusion: 该框架通过在两个基准 GAIA 和 BigCodeBench 上评估 Magentic-One Actor Agent，并与基于 GPT-4o 的 LLM-as-a-Judge 基线相比，在人类评估方面提高了 4.76% 和 10.52% 的对齐准确率，证明了所提出的通用评估框架的潜力。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [389] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI is a new AI tool that uses NLP and LLMs to automatically assess leadership skills in recommendation letters, improving the admissions process and applicant evaluation.


<details>
  <summary>Details</summary>
Motivation: Reviewing text-heavy LORs is time-consuming and labor-intensive; AI can help assess leadership skills efficiently.

Method: Using natural language processing and large language models (RoBERTa and LLAMA) to identify leadership attributes like teamwork, communication, and innovation in LORs.

Result: The RoBERTa model achieved a weighted F1 score of 91.6%, precision of 92.4%, and recall of 91.6%, demonstrating strong consistency.

Conclusion: LORI AI tool can accurately assess leadership skills in LORs, streamlining the admissions process and providing feedback for students' professional growth.

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [390] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一个多视角智能体辩论框架，用于检测社交媒体上的有害内容。它通过结合不同分析视角的智能体进行辩论和反思，从而提高了检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 识别社交媒体中隐藏的有害意图（如讽刺、仇恨言论或错误信息）具有挑战性，因为跨模态矛盾、快速的文化变化和微妙的语用线索。

Method: 提出了一种名为MV-Debate的多视角智能体辩论框架，该框架包含一个表面分析器、一个深度推理器、一个模态对比器和一个社会情境主义者。该框架通过迭代辩论和反思，在反思增益标准下优化响应，以实现准确和高效的目标。

Result: 在三个基准数据集上的实验表明，MV-Debate显著优于强大的单模型和现有的多智能体辩论基线。

Conclusion: 该研究通过多视角智能体辩论框架在统一的多模态有害内容检测方面取得了显著成效，突显了多智能体辩论在推进可靠的社会意图检测方面的潜力。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [391] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 主动推理（AIF）结合大型语言模型（LLM），有望解决当前AI在数据和奖励设计上面临的可扩展性挑战，使AI能够自主学习、适应并与人类价值观保持一致，从而实现更广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 当前AI范式在可扩展性方面面临挑战，因为AI系统正在耗尽高质量的训练数据，并且越来越依赖人类进行奖励设计。为了实现真正自主的智能，需要一种新的方法来让AI从经验中学习，而无需持续的人工奖励工程。

Method: 通过整合大型语言模型（LLM）作为生成世界模型，并结合主动推理（AIF）的原则性决策框架，来弥合“地面化-能动性鸿沟”。AIF通过最小化自由能的内在驱动力取代外部奖励信号，使智能体能够通过统一的贝叶斯目标来平衡探索和利用。

Result: 主动推理（AIF）可以弥合“地面化-能动性鸿沟”，使AI能够自主学习和适应。将LLM与AIF相结合，可以创建能够从经验中高效学习并与人类价值观保持一致的AI系统，从而在计算和物理约束下自主发展。

Conclusion: 该研究提出利用主动推理（AIF）弥合“地面化-能动性鸿沟”，使人工智能（AI）系统能够自主制定、调整和追求目标，以应对不断变化的环境。通过将大型语言模型（LLM）作为生成世界模型，并结合AIF的原则性决策框架，可以创建能够从经验中高效学习并与人类价值观保持一致的AI系统。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [392] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 一个基于LLM的名为"LearnerAgent"的框架，通过模拟包含不同学习者类型的教学环境，揭示了LLM的学习行为和认知模式，发现其本质上是"勤奋但脆弱的表面学习者"。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习方法在捕捉学习动态、追踪进展和提供可解释性方面存在的不足，本研究旨在开发一个能够模拟真实教学环境并深入理解人类学习行为的新框架。

Method: "LearnerAgent"框架，一个基于LLM的多代理框架，用于模拟教学环境。通过构建具有不同心理特征（深度、表面、懒惰）的学习者以及一个无个性"通用学习者"，并结合长期的知识获取、策略选择、定期测试和同伴互动，来追踪和分析学习者的动态学习过程。

Result: 1. 长期分析显示，只有"深度学习"者实现了持续的认知增长，而"表面学习"者容易被陷阱题暴露其浅层知识。2. 不同学习者的行为和认知模式与其心理学特征高度吻合。3. 学习者的自我概念分数随时间真实地演变，"通用学习者"尽管认知能力有限，却展现出惊人的高自我效能感。4. LLM的默认行为模式是一种"勤奋但脆弱的表面学习者"，虽然模仿好学生的行为，但缺乏真正的、可泛化的理解。

Conclusion: "LearnerAgent"框架在模拟真实教学环境和研究人类学习行为方面表现出色，揭示了不同学习者（包括基于LLM的学习者）的认知动态和行为模式。研究发现，只有"深度学习"者实现了持续的认知增长，而"表面学习"者容易被设计陷阱题所暴露。LLM的默认行为模式表现为"勤奋但脆弱的表面学习者"。该框架通过模拟实验证明了其有效性和洞察力。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [393] [Online EFX Allocations with Predictions](https://arxiv.org/abs/2508.04779)
*Themistoklis Melissourgos,Nicos Protopapas*

Main category: cs.GT

TL;DR: 在在线公平划分问题中，即使有预测，近似EFX分配也难以实现。但结合预测和真实值，可以设计出性能随预测准确度提升的算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决在公平划分问题中实现EFX分配的挑战，本研究引入了结合预测和真实值的算法。研究的动机在于，即使在有约束的条件下，近似EFX分配也难以实现，因此需要新的方法来提高分配的公平性。

Method: 本研究探讨了一个在线公平划分问题，其中固定数量的物品会依次到达，并需要分配给指定数量的代理。当物品到达时，会揭示其对每个代理的真实价值，并且必须立即且不可撤销地将其分配给某个代理。最终目标是在所有物品分配完毕后，确保达到“最大程度无羡慕”的分配（EFX）。研究人员利用预测向量（例如，由机器学习模型生成的）来辅助算法，并使用总变异距离来衡量预测误差。

Result: 研究表明，即使在考虑预测的情况下，近似EFX分配也存在固有的局限性。对于仅忽略预测或仅依赖预测的算法，即使在具有相同估值函数的条件下，也无法保证近似EFX。然而，对于同时利用预测和真实值的算法，研究给出了实现近似EFX所需的预测准确度的下界。对于两个具有相同估值函数的代理，研究提出了一种有效的算法，其EFX近似度随着预测准确度的提高而增强。

Conclusion: 近似EFX分配在一般情况下是无法实现的，即使是在对估值函数有严格限制的情况下。然而，通过结合预测和真实值，可以设计出满足EFX的算法，其效果随着预测准确度的提高而提升。

Abstract: We study an online fair division problem where a fixed number of goods arrive
sequentially and must be allocated to a given set of agents. Once a good
arrives, its true value for each agent is revealed, and it has to be
immediately and irrevocably allocated to some agent. The ultimate goal is to
ensure envy-freeness up to any good (EFX) after all goods have been allocated.
Unfortunately, as we show, approximate EFX allocations are unattainable in
general, even under restrictive assumptions on the valuation functions.
  To address this, we follow a recent and fruitful trend of augmenting
algorithms with predictions. Specifically, we assume access to a prediction
vector estimating the agents' true valuations -- e.g., generated by a machine
learning model trained on past data. Predictions may be unreliable, and we
measure their error using the total variation distance from the true
valuations, that is, the percentage of predicted value-mass that disagrees with
the true values.
  Focusing on the natural class of additive valuations, we prove impossibility
results even on approximate EFX allocations for algorithms that either ignore
predictions or rely solely on them. We then turn to algorithms that use both
the predictions and the true values and show strong lower bounds on the
prediction accuracy that is required by any algorithm to compute an approximate
EFX. These negative results persist even under identical valuations, contrary
to the offline setting where exact EFX allocations always exist without the
necessity of predictions. We then present an algorithm for two agents with
identical valuations that uses effectively the predictions and the true values.
The algorithm approximates EFX, with its guarantees improving as the accuracy
of the predictions increases.

</details>


### [394] [Toward Energy and Location-Aware Resource Allocation in Next Generation Networks](https://arxiv.org/abs/2508.05109)
*Mandar Datar,Mattia Merluzzi*

Main category: cs.GT

TL;DR: 本研究提出了一种在无线网络中分配通信和计算资源的创新方法，通过模拟市场机制来优化资源利用、用户体验和能源效率，并确保公平性。


<details>
  <summary>Details</summary>
Motivation: 无线网络正朝着包含分布式计算的复杂系统发展，其优化目标也从单纯的性能转向了更广泛的价值导向，需要在服务提供商、用户体验和公平性之间取得平衡，同时满足能源消耗和碳足迹等全局约束。

Method: 该研究将无线网络建模为一个渔业市场，利用其机制来分配通信和计算资源，并满足能源消耗的限制。

Result: 研究表明，该模型能够实现高效的资源利用和能源节约，促进服务提供商之间的公平性，并在不同场景下展示了效用与能源消耗之间的多维度权衡。

Conclusion: 该论文提出了一种将通信和计算资源配置与能源消耗相结合的解决方案，并成功实现了高效的资源利用和能源节约，同时促进了各服务提供商之间的公平性。

Abstract: Wireless networks are evolving from radio resource providers to complex
systems that also involve computing, with the latter being distributed across
edge and cloud facilities. Also, their optimization is shifting more and more
from a performance to a value-oriented paradigm. The two aspects shall be
balanced continuously, to maximize the utilities of Services Providers (SPs),
users quality of experience and fairness, while meeting global constraints in
terms of energy consumption and carbon footprint among others, with all these
heterogeneous resources contributing. In this paper, we tackle the problem of
communication and compute resource allocation under energy constraints, with
multiple SPs competing to get their preferred resource bundle by spending a a
fictitious currency budget. By modeling the network as a Fisher market, we
propose a low complexity solution able to achieve high utilities and guarantee
energy constraints, while also promoting fairness among SPs, as compared to a
social optimal solution. The market equilibrium is proved mathematically, and
numerical results show the multi-dimensional trade-off between utility and
energy at different locations, with communication and computation-intensive
services.

</details>


### [395] [A New Three-Players Auction Bridge with Dynamic Opponents and Team Members](https://arxiv.org/abs/2508.05582)
*Sourish Sarkar,Aritrabha Majumdar,Moutushi Chatterjee*

Main category: cs.GT

TL;DR: 提出了一种新的三玩家桥牌游戏，打破固定搭档，实现动态组队、实时策略更新和公平的计分系统。模拟显示策略有效，该游戏适合比赛并有望扩大参与群体。


<details>
  <summary>Details</summary>
Motivation: 为了打破桥牌固定搭档的模式，创造更具动态性和灵活性的游戏体验，并提高游戏的可预测性和玩家的策略更新频率。

Method: 提出了一种新的三玩家桥牌游戏，重点在于打破固定搭档，实现动态组队和实时策略更新。设计了一个新的计分系统以减少传统规则游戏的偏见，并通过奖励机制促进公平性和战术决策。文章还讨论了叫牌的概率问题、明示/无明示花色的影响以及算法方法在夺取技巧中的应用。

Result: 模拟结果表明，该游戏的多样化策略是有效的。该游戏结构适合比赛，并可能扩大竞技纸牌游戏的参与群体。

Conclusion: 该三玩家桥牌游戏通过动态重定组队规则，鼓励玩家在无固定搭档的情况下进行灵活调整和实时适应性叫牌，考验了玩家的协作和策略规划能力。引入的计分系统通过奖励机制促进公平性，并鼓励战术决策和风险评估。

Abstract: This article presents a new three-player version of the bridge playing card
game for the purpose of ending fixed partnerships so that the play can be more
dynamic and flexible. By dynamically redefining team makeup in real time, this
game design increases unpredictability and forces players to repeatedly update
strategy. A novel scoring system is introduced to reduce biases present in
conventional rule-based games by favoring fairness via reward systems that
enforce tactical decision making and risk assessment. Being subject to regular
bridge rules, this version tests players to collaborate without fixed
friendships, requiring fluid adjustment and adaptive bidding behavior in real
time. Strategic issues involve aggressive and defensive bidding, adaptable
playing styles, and loss-seeking strategies specific to the three-player
structure. The article discusses probabilistic issues of bidding, trump and
no-trump declarative effects, and algorithmic methods to trick-taking.
Simulation outcomes illustrate the efficiency of diverse strategies. The game's
architecture is ideal for competitions and possibly influential in broadening
entry pools for tournament card games.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [396] [Causal Interventions Beyond Time: A CP-do(C)-Calculus for Indefinite Quantum Order](https://arxiv.org/abs/2508.04737)
*Jordi Vallverdu*

Main category: quant-ph

TL;DR: 通过将Pearl的三条do-calculus规则重新表述为完全正（CP）迹保持映射的语言，并将其扩展到具有纠缠的量子系统，我们证明了Rule 2在存在不确定因果顺序时会失效，并在一项三量子比特的“量子开关”实验中展示了这一点。CP-do-calculus为因果建模提供了一个统一的框架，涵盖了经典、确定顺序量子和不确定顺序量子系统。


<details>
  <summary>Details</summary>
Motivation: 在量子信息科学中，需要修订手术干预、忠诚度和反事实依赖的经典概念。

Method: 将Pearl的三条do-calculus规则重新表述为完全正（CP）迹保持映射的语言，从而将它们扩展到具有纠缠的量子系统。

Result: Rule 2在底层过程容许不确定的因果顺序时失效，并在一个三量子比特的“量子开关”电路中展示了这种失效。

Conclusion: CP-do-calculus为因果建模提供了跨越经典、确定顺序量子和不确定顺序量子势的通用语法。

Abstract: We reformulate Pearl's three rules of do-calculus in the language of
completely positive (CP) trace-preserving maps, thereby extending them to
quantum systems with entanglement. We prove that Rule~2 fails whenever the
underlying process admits indefinite causal order, and we demonstrate this
failure in a three-qubit ``quantum switch'' circuit. Our analysis clarifies why
the classical notions of surgical intervention, faithfulness, and
counterfactual dependence must be revised in quantum information science. The
CP-do($C$)-calculus introduced here provides a common syntax for causal
modelling across classical, definite-order quantum, and indefinite-order
quantum regimes.

</details>


### [397] [Comment on "Energy-speed relationship of quantum particles challenges Bohmian mechanics"](https://arxiv.org/abs/2508.04756)
*Aurélien Drezet,Dustin Lazarovici,Bernard Michael Nabet*

Main category: quant-ph

TL;DR: Sharaglazova等人的实验结果与Bohmian力学相符，其对Bohmian力学的质疑是错误的。


<details>
  <summary>Details</summary>
Motivation: 反驳Sharaglazova et al.关于其实验挑战Bohmian粒子动力学有效性的论点，并澄清其实验结果与Bohmian力学的关系。

Method: 通过分析Sharaglazova et al.的实验及其与Bohmian力学的关系，阐明Bohmian力学中的速度定义。

Result: Sharaglazova et al.的实验结果与Bohmian力学预测一致，并非如其所声称的那样构成挑战。

Conclusion: Sharaglazova et al.的实验结果与Bohmian力学完全一致，其关于Bohmian粒子动力学有效性的质疑是不成立的。报告的操作性速度与Bohmian力学中所描述的粒子速度无关。

Abstract: In their recent paper [Nature 643, 67 (2025)], Sharaglazova et al. report an
optical microcavity experiment yielding an "energy-speed relationship" for
quantum particles in evanescent states, which they infer from the observed
population transfer between two coupled waveguides. The authors argue that
their findings challenge the validity of Bohmian particle dynamics because,
according to the Bohmian guiding equation, the velocities in the classically
forbidden region would be zero. In this note, we explain why this claim is
false and the experimental findings are in perfect agreement with Bohmian
mechanics. We also clarify why the operationally defined speeds reported in the
paper are unrelated to particle velocities in the sense described by Bohmian
mechanics. In contrast to other recent replies, our analysis relies solely on
the standard Bohmian guidance equation for single particles.

</details>


### [398] [QFOR: A Fidelity-aware Orchestrator for Quantum Computing Environments using Deep Reinforcement Learning](https://arxiv.org/abs/2508.04974)
*Hoa T. Nguyen,Muhammad Usman,Rajkumar Buyya*

Main category: quant-ph

TL;DR: QFOR利用深度强化学习优化量子云中的任务调度，提高了保真度并保持了执行时间。


<details>
  <summary>Details</summary>
Motivation: 现有的量子云平台硬件异构性和噪声问题，给量子任务分配和调度带来挑战，启发式方法难以适应动态条件或平衡保真度和执行时间。

Method: 提出了一种名为QFOR的量子任务编排方法，使用深度强化学习（特别是近端策略优化算法）将量子任务编排建模为马尔可夫决策过程，并利用IBM量子处理器校准数据进行噪声感知性能估算。

Result: QFOR框架能够平衡量子任务的整体执行保真度和时间，并且具有自适应性。与启发式基线方法相比，在相对保真度性能方面有29.5%-84%的提升，同时保持了可比的量子执行时间。

Conclusion: QFOR通过深度强化学习实现了量子任务的自适应编排，在保真度和执行时间方面均优于现有启发式方法，提高了量子计算资源的利用效率。

Abstract: Quantum cloud computing enables remote access to quantum processors, yet the
heterogeneity and noise of available quantum hardware create significant
challenges for efficient resource orchestration. These issues complicate the
optimization of quantum task allocation and scheduling, as existing heuristic
methods fall short in adapting to dynamic conditions or effectively balancing
execution fidelity and time. Here, we propose QFOR, a Quantum Fidelity-aware
Orchestration of tasks across heterogeneous quantum nodes in cloud-based
environments using Deep Reinforcement learning. We model the quantum task
orchestration as a Markov Decision Process and employ the Proximal Policy
Optimization algorithm to learn adaptive scheduling policies, using IBM quantum
processor calibration data for noise-aware performance estimation. Our
configurable framework balances overall quantum task execution fidelity and
time, enabling adaptation to different operational priorities. Extensive
evaluation demonstrates that QFOR is adaptive and achieves significant
performance with 29.5-84% improvements in relative fidelity performance over
heuristic baselines. Furthermore, it maintains comparable quantum execution
times, contributing to cost-efficient use of quantum computation resources.

</details>


### [399] [Power and Limitations of Linear Programming Decoder for Quantum LDPC Codes](https://arxiv.org/abs/2508.04769)
*Shouzhen Gu,Mehdi Soleimanifar*

Main category: quant-ph

TL;DR: LP解码在量子LDPC码中存在问题，但通过加入OSD后处理可以解决，并且在实践中表现优于信念传播，是一种有前途的量子LDPC码解码方法。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码的解码是实现容错量子计算的关键挑战。在经典环境中，线性规划（LP）解码器提供可证明的性能保证，并能利用快速的实际优化算法。尽管已经提出了用于量子码的LP解码器，但它们的性能和局限性仍然有相对未被充分探索。

Method: 本研究揭示了LP解码在量子LDPC码中的一个关键限制：某些恒定权重错误模式会导致模糊的分数解，无法通过独立舍入解决。为了解决这个问题，我们结合了称为有序统计解码（OSD）的后处理技术，这在实践中显著提高了LP解码的性能。

Result: LP解码与OSD相结合，可以超越具有相同后处理的信念传播，特别是在高达数百个量子比特的中等代码大小方面。

Conclusion: LP解码通过OSD后处理可以超越具有相同后处理的信念传播，特别是在高达数百个量子比特的中等代码大小方面。这表明，配备有效后处理的基于LP的解码器为解码近期量子LDPC代码提供了一种有前途的方法。

Abstract: Decoding quantum error-correcting codes is a key challenge in enabling
fault-tolerant quantum computation. In the classical setting, linear
programming (LP) decoders offer provable performance guarantees and can
leverage fast practical optimization algorithms. Although LP decoders have been
proposed for quantum codes, their performance and limitations remain relatively
underexplored. In this work, we uncover a key limitation of LP decoding for
quantum low-density parity-check (LDPC) codes: certain constant-weight error
patterns lead to ambiguous fractional solutions that cannot be resolved through
independent rounding. To address this issue, we incorporate a post-processing
technique known as ordered statistics decoding (OSD), which significantly
enhances LP decoding performance in practice. Our results show that LP
decoding, when augmented with OSD, can outperform belief propagation with the
same post-processing for intermediate code sizes of up to hundreds of qubits.
These findings suggest that LP-based decoders, equipped with effective
post-processing, offer a promising approach for decoding near-term quantum LDPC
codes.

</details>


### [400] [Ergotopy transport in a one dimensional spin chain](https://arxiv.org/abs/2508.04770)
*Dara Murphy,Anthony Kiely,Irene D'Amico,Steve Campbell*

Main category: quant-ph

TL;DR: 该研究检查了自旋链中能量（精力）的传输，重点是相干性与布居反转状态对能量传输效率的影响。研究发现，相干性赋能的能量传输更有效，并且 PST 耦合在能量传输和功成本方面更稳定。


<details>
  <summary>Details</summary>
Motivation: 我们研究了有用能量（即可提取功，以精力来量化）沿着具有可调交换耦合的自旋链的传输。

Method: 通过将各个组成部分建模为量子电池，我们考虑了可提取功在第一个位点的初始状态中出现的方式如何影响链将精力传输到最后一个位点的能力。

Result: 我们关注并插值于均匀相互作用强度和实现完美状态传输（PST）的工程耦合这两个物理上相关的极限。

Conclusion: 对于非 PST 耦合，当精力最初赋予量子相干性时，存在明显的技术优势，并且这种精力可以更有效地传输。对于在布居反转状态下编码的可提取功，这会大大限制可以忠实传输任何精力的链的长度。对于 PST 耦合，我们考虑了对无序的鲁棒性，并再次证明了相干赋予的精力的技术优势。最后，我们检查了与交互相关的功概率分布，这为切换耦合的功成本提供了见解。我们表明，PST 耦合在功成本方面产生的波动较小，表明它们更稳定。

Abstract: We examine the transport of useful energy, i.e. extractable work as
quantified by the ergotropy, along a spin chain with tuneable exchange
couplings between the sites. We focus on, and interpolate between, the two
physically relevant limits of uniform interaction strengths and engineered
couplings which achieve perfect state transfer (PST). By modelling the
individual constituents as quantum batteries, we consider how the manner in
which the extractable work appears in the initial state of the first site
impacts the chain's ability to transport ergotropy to the final site. For
non-PST couplings, we establish that there is a clear quantum advantage when
the ergotropy is initially endowed in quantum coherences and demonstrate that
this ergotropy is more efficiently transferred. For extractable work encoded in
a population inverted state, we show that this considerably limits the length
of chain over which any ergotropy can be faithfully transported. For PST
couplings, we consider the robustness to disorder and again demonstrate a
quantum advantage for coherently endowed ergotropy. Finally, we examine the
work probability distribution associated with quenching on the interactions
which provides insight into the work cost in switching on the couplings. We
show that PST couplings lead to smaller fluctuations in this work cost,
indicating that they are more stable.

</details>


### [401] [Universal quantum phase classification on quantum computers from machine learning](https://arxiv.org/abs/2508.04774)
*Weicheng Ye,Shuwei Liu,Shiyu Zhou,Yijian Zou*

Main category: quant-ph

TL;DR: 本研究将量子阴影断层扫描与时间序列机器学习模型相结合，提出了一种新的量子物态分类框架，能够对一维量子自旋链进行有效分类，并与已知相边界高度一致。


<details>
  <summary>Details</summary>
Motivation: 量子物态的分类是凝聚态物理中的一个基本挑战。

Method: 本研究提出了一种结合量子阴影断层扫描和现代时间序列机器学习模型的新框架，以实现高效实用的量子物态分类。该方法利用基于通过有限深度局域酉电路连接定义的量子物态，并通过对代表性量子态施加哈尔随机演化来生成大量的训练数据，从而可以从量子模拟器中有效地获得训练数据。

Result: 该方法能够对量子物态进行通用分类，并且可以从量子模拟器中有效地获得训练数据。

Conclusion: 该方法能够实现不依赖于局域序参量的通用量子物态分类，并且在对一维量子自旋链（如伊辛模型和轴向最近邻伊辛模型）的测试中，与已知的相边界显示出优异的一致性。

Abstract: The classification of quantum phases of matter remains a fundamental
challenge in condensed matter physics. We present a novel framework that
combines shadow tomography with modern time-series machine learning models to
enable efficient and practical quantum phase classification. Our approach
leverages the definition of quantum phases based on connectivity through
finite-depth local unitary circuits, generating abundant training data by
applying Haar random evolution to representative quantum states for a given
phase. In this way, the training data can be efficiently obtained from a
quantum simulator. Additionally, we demonstrate that advanced time-series
models can be used to process the training data and achieve universal quantum
phase classification that does not rely on local order parameters. To validate
the universality and versatility of our method, we test the model against
one-dimensional quantum spin chains such as the Ising model and the axial
next-nearest-neighbor Ising (ANNNI) model, showing excellent agreement with
known phase boundaries.

</details>


### [402] [Absolutely maximally entangled pure states of multipartite quantum systems](https://arxiv.org/abs/2508.04777)
*Grzegorz Rajchel-Mieldzioć,Rafał Bistroń,Albert Rico,Arul Lakshminarayan,Karol Życzkowski*

Main category: quant-ph

TL;DR: This paper surveys and analyzes methods for creating highly entangled quantum states (AME states) used in quantum computing, detailing new techniques and properties of these states.


<details>
  <summary>Details</summary>
Motivation: AME states are important in quantum information processing due to their maximal correlations, finding applications in multi-user teleportation, quantum error correction, and secret sharing. The motivation is to update the understanding and methods for generating these crucial states and explore their properties.

Method: The paper surveys and analyzes various techniques for generating Absolutely Maximally Entangled (AME) states, including methods beyond standard graph and stabilizer states. Specific analyses include the entanglement of reduced states from AME projectors, states from symmetric superpositions of GHZ states, and the representation of the 'golden' AME state. The number of local unitary equivalence classes is also summarized.

Result: The paper presents an updated survey of AME state generation techniques, including novel approaches. It offers analysis on the entanglement properties of derived states and provides a representation for a specific AME state, along with a summary of local unitary equivalence classes.

Conclusion: The paper provides an updated survey of techniques for generating AME states, including new methods beyond standard graph and stabilizer states. It also analyzes the entanglement of reduced states from AME projectors, states from symmetric superpositions of GHZ states, presents an orthogonal frequency square representation of the 'golden' AME state, and summarizes the number of local unitary equivalence classes.

Abstract: Absolutely maximally entangled (AME) pure states of a system composed of $N$
parties are distinguished by the property that for any splitting at least one
partial trace is maximally mixed. Due to maximal possible correlations between
any two selected subsystems these states have numerous applications in various
fields of quantum information processing including multi-user teleportation,
quantum error correction and secret sharing. We present an updated survey of
various techniques to generate such strongly entangled states, including those
going beyond the standard construction of graph and stabilizer states. Our
contribution includes, in particular, analysis of the degree of entanglement of
reduced states obtained by partial trace of AME projectors, states obtained by
a symmetric superposition of GHZ states, an orthogonal frequency square
representation of the "golden" AME state and an updated summary of the number
of local unitary equivalence classes.

</details>


### [403] [Excising dead components in the surface code using minimally invasive alterations: A performance study](https://arxiv.org/abs/2508.04786)
*Ryan V. Mishmash,Vadym Kliuchnikov,Juan Bello-Rivas,Adam Paetznick,David Aasen,Christina Knapp,Yue Wu,Bela Bauer,Marcus P. da Silva,Parsa Bonderson*

Main category: quant-ph

TL;DR: 该研究提出了一种名为 MIA 的新方案，用于处理容错量子处理器中的有缺陷物理组件。该方案通过最小的改动来移除有缺陷组件，并能最大化利用功能组件，同时保持一致的全局操作时间表。研究还介绍了一种自动计算检查基的技术。数值模拟结果表明，该方案在处理有缺陷组件方面表现出色，并且可以与多种量子电路兼容。


<details>
  <summary>Details</summary>
Motivation: 大规模容错量子处理器需要在操作中减轻有缺陷物理组件的存在，例如在设备启动时或计算过程中检测到的组件。

Method: 通过对 Grans-Samuelsson 等人提出的方案进行数值模拟，该方案通过最小的侵入性改动（MIA）有效地从表面码中移除有缺陷的组件，并在考虑电路级噪声的情况下，针对成对测量制导的表面码协议进行了模拟。

Result: 对 Grans-Samuelsson 等人提出的方案进行了广泛的数值模拟，证明了其在有缺陷组件存在的情况下，可以优化逻辑量子比特的性能，并兼容系统的控制要求。

Conclusion: 该提议可以与基于测量的以及 CNOT 的电路结合使用，并且本文展示的结果证明了其具有先进的性能。

Abstract: The physical implementation of a large-scale error-corrected quantum
processor will necessarily need to mitigate the presence of defective (thereby
"dead") physical components in its operation, for example, identified during
bring-up of the device or detected in the middle of a computation. In the
context of solid-state qubits, the quantum error correcting protocol operating
in the presence of dead components should ideally (i) use the same native
operation set as that without dead components, (ii) maximize salvaging of
functional components, and (iii) use a consistent global operating schedule
which optimizes logical qubit performance and is compatible with the control
requirements of the system. The scheme proposed by Grans-Samuelsson et al.
[Quantum 8, 1429 (2024)] satisfies all three of these criteria: it effectively
excises (cuts out) dead components from the surface code using minimally
invasive alterations (MIA). We conduct extensive numerical simulations of this
proposal for the pairwise-measurement-based surface code protocol in the
presence of dead components under circuit-level noise. To that end, we also
describe techniques to automatically construct performant check (detector)
bases directly from circuits without manual circuit annotation, which may be of
independent interest. Both the MIA scheme and this automated check basis
computation can be readily used with measurement-based as well as CNOT-based
circuits, and the results presented here demonstrate state-of-the-art
performance.

</details>


### [404] [Automorphism gadgets in homological product codes](https://arxiv.org/abs/2508.04794)
*Noah Berthusen,Michael J. Gullans,Yifan Hong,Maryam Mudassar,Shi Jie Samuel Tan*

Main category: quant-ph

TL;DR: 该研究提出了一个理论框架，用于对结构同源积码中的逻辑操作进行分类，这些操作源于输入码的置换对称性。研究表明，这些操作可以通过量子比特置换和子系统电路来实现，并具有潜在的容错特性，为在各种平台上实现量子纠错开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索结构同源积码的逻辑操作，特别是那些由输入码中的置换对称性驱动的操作，并为这些操作提供一个理论框架。此外，研究旨在理解这些操作的容错特性，并将其与现有技术进行比较，以促进在非拓扑码平台上的实际容错应用。

Method: 本研究提出了一个理论框架，用于表征源于输入码置换对称性的结构同源积码的逻辑操作。该框架描述了这些操作如何通过物理量子比特置换和子系统电路的组合来实现，并在特定情况下简化为仅量子比特置换。研究还分析了“自同构小工具”的容错特性，并考察了具有自同构结构的经典线性码，将它们纳入所提出的框架。

Result: 研究表明，结构同源积码的逻辑操作可以通过物理量子比特置换和子系统电路的组合来实现，在特定情况下可以简化为仅量子比特置换。此外，研究证明了“自同构小工具”具有距离保持等容错特性，并展示了经典线性码如何适应该框架。这些发现为在长程连接平台上实现拓扑码之外的实际容错提供了新的途径。

Conclusion: 这项工作为同源积码的逻辑操作提供了一个广阔的理论框架，特别是那些源于输入码的置换对称性的操作。研究表明，这些逻辑操作通常可以通过物理量子比特置换和子系统电路的组合来实现。在某些情况下，仅通过量子比特置换就可以实现逻辑操作。此外，作者证明了这些“自同构小工具”可以具有固有的容错特性，例如在假定物理置换免费的情况下进行有效的距离保持。该研究还调查了具有丰富自同构结构的经典线性码，并将各种经典码族纳入其框架。与用于同源积码的其他容错小工具相比，这项工作在拓扑码之外的具有长程连接能力的平台中，推动了对实际容错的探索。

Abstract: The homological product is a general-purpose recipe that forges new quantum
codes from arbitrary classical or quantum input codes, often providing enhanced
error-correcting properties. When the input codes are classical linear codes,
it is also known as the hypergraph product. We investigate structured
homological product codes that admit logical operations arising from
permutation symmetries in their input codes. We present a broad theoretical
framework that characterizes the logical operations resulting from these
underlying automorphisms. In general, these logical operations can be performed
by a combination of physical qubit permutations and a subsystem circuit. In
special cases related to symmetries of the input Tanner graphs, logical
operations can be performed solely through qubit permutations. We further
demonstrate that these "automorphism gadgets" can possess inherent
fault-tolerant properties such as effective distance preservation, assuming
physical permutations are free. Finally, we survey the literature of classical
linear codes with rich automorphism structures and show how various classical
code families fit into our framework. Complementary to other fault-tolerant
gadgets for homological product codes, our results further advance the search
for practical fault tolerance beyond topological codes in platforms capable of
long-range connectivity.

</details>


### [405] [Dissipative Dynamics and Symmetry Breaking in Bosonic Sachdev-Ye-Kitaev Lindbladian](https://arxiv.org/abs/2508.04802)
*Yifei Liu,Anish Kulkarni,Shinsei Ryu*

Main category: quant-ph

TL;DR: We studied a bosonic SYK model with dissipation. Dissipation helps stabilize the system and leads to new phases. We found different possible stable states.


<details>
  <summary>Details</summary>
Motivation: Investigating a bosonic variant of the Sachdev-Ye-Kitaev (SYK) model coupled to a Lindbladian environment, focusing on the interplay between quantum many-body dynamics and dissipation.

Method: Schwinger-Keldysh path integral formalism in the large-N limit

Result: A rich phase structure, including symmetry breaking and phase transitions, was uncovered.

Conclusion: The dissipation can partially tame the instability of the inverted potential, leading to novel steady-state phases. Multiple competing saddle points are identified, with potential implications for the landscape of metastable states.

Abstract: We investigate a bosonic variant of the Sachdev-Ye-Kitaev (SYK) model coupled
to a Lindbladian environment, focusing on the interplay between quantum
many-body dynamics and dissipation. Using the Schwinger-Keldysh path integral
formalism in the large-N limit, we uncover a rich phase structure, including
symmetry breaking and phase transitions. Our results suggest that the
dissipation can partially tame the instability of the inverted potential,
leading to novel steady-state phases. We also identify regimes with multiple
competing saddle points and discuss potential implications for the landscape of
metastable states.

</details>


### [406] [Minimum-Weight Parity Factor Decoder for Quantum Error Correction](https://arxiv.org/abs/2508.04969)
*Yue Wu,Binghong Li,Kathleen Chang,Shruti Puri,Lin Zhong*

Main category: quant-ph

TL;DR: HyperBlossom框架通过将MLE解码统一为MWPF问题，并推广blossom算法到超图，弥合了启发式和可验证解码器之间的差距，并在实验中取得了比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 量子纠错（QEC）解码的快速和准确对于可扩展的容错量子计算至关重要。现有的MLE解码虽然接近最优，但对于通用的qLDPC码是难以处理的，并且通常依赖于近似和启发式方法。

Method: 提出了一种名为HyperBlossom的统一框架，将MLE解码形式化为MWPF问题，并利用原对偶线性规划模型将blossom算法推广到超图。

Result: Hyperion软件实现了HyperBlossom框架，在距离为11的表面码上实现了比MWPM解码器低4.8倍的逻辑错误率，在双变量自行车码上实现了比BPOSD解码器低1.6倍的逻辑错误率。该框架在表面码和颜色码上实现了近乎线性的平均运行时扩展，并且在代码容量噪声和电路级噪声下分别达到了99和31的足够大的代码距离的数值结果。

Conclusion: HyperBlossom框架将最可能错误（MLE）解码统一为最小权重奇偶校验因子（MWPF）问题，并通过类似的原对偶线性规划模型将blossom算法推广到超图，并提供可验证的邻近界限。该框架统一了现有的基于图的解码器，如（超图）并查集解码器和最小权重完美匹配（MWPM）解码器，弥合了启发式解码器和可验证解码器之间的差距。

Abstract: Fast and accurate quantum error correction (QEC) decoding is crucial for
scalable fault-tolerant quantum computation. Most-Likely-Error (MLE) decoding,
while being near-optimal, is intractable on general quantum Low-Density
Parity-Check (qLDPC) codes and typically relies on approximation and
heuristics. We propose HyperBlossom, a unified framework that formulates MLE
decoding as a Minimum-Weight Parity Factor (MWPF) problem and generalizes the
blossom algorithm to hypergraphs via a similar primal-dual linear programming
model with certifiable proximity bounds. HyperBlossom unifies all the existing
graph-based decoders like (Hypergraph) Union-Find decoders and Minimum-Weight
Perfect Matching (MWPM) decoder, thus bridging the gap between heuristic and
certifying decoders.
  We implement HyperBlossom in software, namely Hyperion. Hyperion achieves a
4.8x lower logical error rate compared to the MWPM decoder on the distance-11
surface code and 1.6x lower logical error rate compared to a fine-tuned BPOSD
decoder on the $[[90, 8, 10]]$ bivariate bicycle code under code-capacity
noise. It also achieves an almost-linear average runtime scaling on both the
surface code and the color code, with numerical results up to sufficiently
large code distances of 99 and 31 for code-capacity noise and circuit-level
noise, respectively.

</details>


### [407] [Non-Hermitian Quantum Metrology Enhancement and Skin Effect Suppression in PT-Symmetric Bardeen-Cooper-Schrieffer Chains](https://arxiv.org/abs/2508.04815)
*Harshank Matkar*

Main category: quant-ph

TL;DR: 非厄米量子计量学：NHSE指数级抑制灵敏度，PT对称性实现海森堡极限。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米系统中的量子计量学，特别是PT对称性在其中起到的作用，以及NHSE的影响。

Method: 通过双正交量子费舍尔信息分析，研究了PT对称的BCS链中非厄米系统中的量子计量学。分析了两种情况：非厄米奇异效应（NHSE）相和PT对称性破缺的厄米点。

Result: 在NHSE相中，量子费舍尔信息呈指数级抑制（$F_Q \propto N^3 e^{-2\kappa N}$）。在PT对称性破缺的厄米点附近，量子费舍尔信息呈二次增强（$F_Q \propto N^2/\delta$），达到海森堡极限。多参数估计（化学势、Peierls相位、增益/损耗强度）的量子费舍尔信息矩阵按$N^2$的比例增长，超越经典传感。

Conclusion: PT对称性在非厄米量子计量学中提供了一种超越标准量子极限的方法，而非厄米奇异效应（NHSE）则会指数级地抑制灵敏度。

Abstract: We outline a theoretical framework for quantum metrology in non-Hermitian
systems, demonstrating both significant failure and exceptional regimes in
PT-symmetric Bardeen-Cooper-Schrieffer chains. Through biorthogonal quantum
Fisher information analysis, we identify two distinct regimes: exponential
sensitivity suppression in the non-Hermitian skin effect phase ($F_Q \propto
N^3 e^{-2\kappa N}$) where eigenstates localize exponentially, and quadratic
enhancement near PT-breaking exceptional points [1-4] ($F_Q \propto
N^2/\delta$) achieving Heisenberg scaling. Our multiparameter analysis
establishes optimal simultaneous estimation of chemical potential, Peierls
phase, and gain/loss strength with quantum Fisher information matrix scaling as
$N^2$, surpassing the standard quantum limit by factors exceeding $10^2$. For
realistic parameters ($t/2\pi=10$ MHz, $\Delta/2\pi=1$ MHz, $N=50$), we predict
enhancement factors $\eta_\mu \approx 20\sqrt{N}=141$ for chemical potential
estimation and $\eta_\phi \approx t^2 \sqrt{3N/2}=100\sqrt{N}$ over classical
sensing. These results are validated through exact finite-size calculations and
provide concrete protocols for superconducting circuit implementations.We
reveal a core dichotomy in non-Hermitian quantum metrology: NHSE suppresses
sensitivity exponentially, while $\mathcal{PT}$-symmetry enables
Heisenberg-limited enhancement -- each arising from distinct spectral and
localization topologies.

</details>


### [408] [Hybrid oscillator-qudit quantum processors: stabilizer states and symplectic operations](https://arxiv.org/abs/2508.04819)
*Sayan Chakraborty,Victor V. Albert*

Main category: quant-ph

TL;DR: 将GKP量子格子形式主义推广到混合量子系统中，构建稳定器态和纠错码，可同时测量大范围非对易位移。


<details>
  <summary>Details</summary>
Motivation: 为了克服在离散和连续变量系统中构建稳定器态和纠错码的局限性，并提供一种同时测量大范围非对易位移的方法。

Method: 利用混合量子格子形式主义，将GKP量子格子形式主义推广到混合量子系统中，并通过条件位移或将物理量编码到GKP代码中来构建混合状态。纠错码的构造与非交换环和Morita等价性相关联。

Result: 成功构建了稳定器态和纠错码，并展示了它们在混合系统中的应用，特别是通过GKP代码实现了物理量到量子信息的编码。

Conclusion: 这项工作将稳定器态和纠错码推广到离散和连续变量系统的组合上，通过将离散相空间吸收到混合相空间中，并允许同时测量大范围的非对易位移。

Abstract: We construct stabilizer states and error-correcting codes on combinations of
discrete- and continuous-variable systems, generalizing the
Gottesman-Kitaev-Preskill (GKP) quantum lattice formalism. Our framework
absorbs the discrete phase space of a qudit into a hybrid phase space
parameterizable entirely by the continuous variables of a harmonic oscillator.
The unit cell of a hybrid quantum lattice grows with the qudit dimension,
yielding a way to simultaneously measure an arbitrarily large range of
non-commuting position and momentum displacements. Simple hybrid states can be
obtained by applying a conditional displacement to a Gottesman-Kitaev-Preskill
(GKP) state and a Pauli eigenstate, or by encoding some of the physical qudits
of a stabilizer state into a GKP code. The states' oscillator-qudit
entanglement cannot be generated using symplectic (i.e., Gaussian-Clifford)
operations, distinguishing them as a resource from tensor products of
oscillator and qudit stabilizer states. We construct general hybrid
error-correcting codes by relating stabilizer codes to non-commutative tori and
obtaining logical operators via Morita equivalence. We provide examples using
commutation matrices, integer symplectic matrices, and binary codes.

</details>


### [409] [Q-DPTS: Quantum Differentially Private Time Series Forecasting via Variational Quantum Circuits](https://arxiv.org/abs/2508.05036)
*Chi-Sheng Chen,Samuel Yen-Chi Chen*

Main category: quant-ph

TL;DR: Q-DPTS 是一个混合量子-经典框架，用于量子差分隐私时间序列预测。它通过结合 VQC、每样本梯度裁剪和高斯噪声注入来确保 DP。与现有方法相比，Q-DPTS 在保持相同隐私预算的情况下实现了更低的预测误差。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在数据敏感性至关重要（例如金融和能源系统）的领域中至关重要。虽然差分隐私 (DP) 提供了保护个人数据贡献的理论保证，但其集成（尤其​​是通过 DP-SGD）由于注入的噪声而常常会损害模型性能。

Method: 我们提出了 Q-DPTS，一个混合量子-经典框架，用于量子差分隐私时间序列预测。Q-DPTS 结合了变分量子电路 (VQC) 和每样本梯度裁剪以及高斯噪声注入，确保了严格的 $(\epsilon, \delta)$-差分隐私。

Result: 结果表明，Q-DPTS 在相同的隐私预算下始终实现较低的预测误差，表明有利的隐私-效用权衡。我们在 ETT（电力变压器温度）数据集上评估了 Q-DPTS，该数据集是长期时间序列预测的标准基准。

Conclusion: 这项工作是对量子增强的差分隐私预测的首次探索之一，为隐私关键场景中的安全准确的时间序列建模提供了有前景的方向。

Abstract: Time series forecasting is vital in domains where data sensitivity is
paramount, such as finance and energy systems. While Differential Privacy (DP)
provides theoretical guarantees to protect individual data contributions, its
integration especially via DP-SGD often impairs model performance due to
injected noise. In this paper, we propose Q-DPTS, a hybrid quantum-classical
framework for Quantum Differentially Private Time Series Forecasting. Q-DPTS
combines Variational Quantum Circuits (VQCs) with per-sample gradient clipping
and Gaussian noise injection, ensuring rigorous $(\epsilon,
\delta)$-differential privacy. The expressiveness of quantum models enables
improved robustness against the utility loss induced by DP mechanisms. We
evaluate Q-DPTS on the ETT (Electricity Transformer Temperature) dataset, a
standard benchmark for long-term time series forecasting. Our approach is
compared against both classical and quantum baselines, including LSTM, QASA,
QRWKV, and QLSTM. Results demonstrate that Q-DPTS consistently achieves lower
prediction error under the same privacy budget, indicating a favorable
privacy-utility trade-off. This work presents one of the first explorations
into quantum-enhanced differentially private forecasting, offering promising
directions for secure and accurate time series modeling in privacy-critical
scenarios.

</details>


### [410] [Quantum Graph States: Bridging Classical Theory and Quantum Innovation, Workshop Summary](https://arxiv.org/abs/2508.04823)
*Eric Chitambar,Kenneth Goodenough,Otfried Gühne,Rose McCarty,Simon Perdrix,Vito Scarola,Shuo Sun,Quntao Zhang*

Main category: quant-ph

TL;DR: 图论和量子信息科学的交叉领域，重点是量子图态及其在计算、网络和传感中的应用。确定了关键挑战，并强调了跨学科合作的重要性。


<details>
  <summary>Details</summary>
Motivation: 本次研讨会的重点是量子图态及其在计算、网络和传感中的应用。

Method: 本次研讨会汇集了经典图论和量子信息科学的专家，重点探讨了量子图态及其在计算、网络和传感中的应用。

Result: 研讨会确定了关键挑战，包括可扩展的纠缠生成、鲁棒的基准测试方法以及对广义图态更深入的理论理解。

Conclusion: 该研讨会强调了跨学科合作对于解决纠缠结构、模拟复杂性和各种量子平台的实验实现方面悬而未决的问题的重要性。

Abstract: This workshop brought together experts in classical graph theory and quantum
information science to explore the intersection of these fields, with a focus
on quantum graph states and their applications in computing, networking, and
sensing. The sessions highlighted the foundational role of graph-theoretic
structure, such as rank-width, vertex-minors, and hypergraphs, in enabling
measurement-based quantum computation, fault-tolerant architectures, and
distributed quantum sensing. Key challenges identified include the need for
scalable entanglement generation, robust benchmarking methods, and deeper
theoretical understanding of generalized graph states. The workshop concluded
with targeted research recommendations, emphasizing interdisciplinary
collaboration to address open problems in entanglement structure, simulation
complexity, and experimental realization across diverse quantum platforms.

</details>


### [411] [Joint parameter estimation and multidimensional reconciliation for CV-QKD](https://arxiv.org/abs/2508.05558)
*Jisheng Dai,Xue-Qin Jiang,Peng Huang,Tao Wang,Guihua Zeng*

Main category: quant-ph

TL;DR: 本研究提出了一种新颖的联合消息传递方案，用于CV-QKD中的信道参数估计和信息协调，通过EM算法同步估计参数，并使用混合多维旋转方案减少经典信道开销。


<details>
  <summary>Details</summary>
Motivation: 精确的量子信道参数估计对于连续变量量子密钥分发（CV-QKD）中的有效信息协调至关重要。然而，传统的最大似然（ML）估计量依赖于大量丢弃的数据（或导引符号），导致符号效率显著损失。此外，估计和协调阶段之间的分离会引入误差传播。

Method: 提出了一种新颖的联合消息传递方案，该方案在贝叶斯框架下统一了信道参数估计和信息协调。通过利用期望最大化（EM）算法，所提出的方法在解码过程中同时估计未知参数，无需单独进行最大似然估计。此外，还引入了一种混合多维旋转方案，消除了对范数反馈的要求，从而显著降低了经典信道的开销。

Result: 通过利用期望最大化（EM）算法，所提出的方法在解码过程中同时估计未知参数，无需单独进行最大似然估计。还引入了一种混合多维旋转方案，消除了对范数反馈的要求，从而显著降低了经典信道的开销。

Conclusion: 本研究首次将多维协调与信道参数估计相结合，为CV-QKD提供了高效协调的实用解决方案，并最大限度地减少了导信。

Abstract: Accurate quantum channel parameter estimation is essential for effective
information reconciliation in continuous-variable quantum key distribution
(CV-QKD). However, conventional maximum likelihood (ML) estimators rely on a
large amount of discarded data (or pilot symbols), leading to a significant
loss in symbol efficiency. Moreover, the separation between the estimation and
reconciliation phases can introduce error propagation. In this paper, we
propose a novel joint message-passing scheme that unifies channel parameter
estimation and information reconciliation within a Bayesian framework. By
leveraging the expectation-maximization (EM) algorithm, the proposed method
simultaneously estimates unknown parameters during decoding, eliminating the
need for separate ML estimation. Furthermore, we introduce a hybrid
multidimensional rotation scheme that removes the requirement for norm
feedback, significantly reducing classical channel overhead. To the best of our
knowledge, this is the first work to unify multidimensional reconciliation and
channel parameter estimation in CV-QKD, providing a practical solution for
high-efficiency reconciliation with minimal pilots.

</details>


### [412] [Exact Solutions of the Schrödinger-Dunkl Equation for a Free Particle in a Finite and Infinite Cylindrical Well](https://arxiv.org/abs/2508.04840)
*R. D. Mota,D. Ojeda-Guillén,M. Salazar-Ramírez*

Main category: quant-ph

TL;DR: 通过Dunkl导数和反射算子，求解柱状势阱中自由粒子的Schr"odinger方程，得到精确波函数解，并分析其宇称性质和Dunkl参数约束。


<details>
  <summary>Details</summary>
Motivation: 研究Dunkl导数和反射算子对Schr"odinger方程解（特别是在柱状势阱中）的影响，以及它们如何影响哈密顿量结构、解的宇称和Dunkl参数。

Method: 在柱状坐标系下，利用Dunkl导数和反射算子，求解Schr"odinger方程，获得自由粒子在柱状势阱（有限和无限高度）中的径向和轴向波函数精确解析解，并分析能量谱和波函数。

Result: 得到了在柱状势阱中自由粒子的径向和轴向波函数的精确解析表达式（基于Bessel函数）。能量谱和解根据反射算子的特征值进行了分类。分析了波函数获得确定宇称的条件及对Dunkl参数的约束。

Conclusion: 该研究通过引入Dunkl导数和反射算子，分析了在柱状势阱中受限自由粒子的Schr"odinger方程。在有限和无限高度势阱情况下，利用柱坐标得到了精确的径向和轴向波函数表达式（以Bessel函数表示）。通过分析反射算子的特征值，对能量谱和波函数进行了分类，并探讨了波函数具有确定宇称的条件及对Dunkl参数的约束。

Abstract: In this paper, we study the Schr\"odinger equation with Dunkl derivative for
a free particle confined in a cylindrical potential well. We consider both the
finite and infinite height cases. The Dunkl formalism introduces reflection
operators that modify the structure of the Hamiltonian and affect the parity of
the solutions. By working in cylindrical coordinates, we obtain exact
analytical expressions for the radial and axial wavefunctions in terms of
Bessel functions. The energy spectrum and the solutions are classified
according to the eigenvalues of the reflection operators in the three
coordinates. We analyze in detail the conditions under which the wavefunctions
acquire definite parity and discuss the resulting constraints on the Dunkl
parameters.

</details>


### [413] [Noisy Quantum Simulation Using Tracking, Uncomputation and Sampling](https://arxiv.org/abs/2508.04880)
*Siddharth Dangwal,Tina Oberoi,Ajay Sailopal,Dhirpal Shah,Frederic T. Chong*

Main category: quant-ph

TL;DR: TUSQ通过减少电路执行次数和重用计算来加速噪声量子模拟。


<details>
  <summary>Details</summary>
Motivation: 由于量子计算机的访问限制，需要开发能够准确且可扩展地模拟噪声量子硬件上量子电路执行的模拟器。

Method: TUSQ使用误差表征模块（ECM）来减少表示噪声所需的唯一电路执行次数，并通过基于树的执行模块（TEM）来重用计算，利用深度优先搜索和取消计算来回滚和恢复，从而减少模拟时间。

Result: TUSQ在186个基准测试中平均比Qiskit和CUDA-Q分别快52.5倍和12.53倍，在大于15个量子比特的基准测试中平均速度分别提升55.42倍和23.03倍。

Conclusion: TUSQ通过误差表征模块（ECM）和基于树的执行模块（TEM）实现了高效且可扩展的量子电路模拟，平均速度比Qiskit和CUDA-Q分别快52.5倍和12.53倍，在15个以上量子比特的基准测试中速度提升尤为显著。

Abstract: Quantum computers have grown in size and qubit quality in recent years,
enabling the execution of complex quantum circuits. However, for most
researchers, access to compute time on quantum hardware is limited. This
necessitates the need to build simulators that mimic the execution of quantum
circuits on noisy quantum hardware accurately and scalably.
  In this work, we propose TUSQ - Tracking, Uncomputation, and Sampling for
Noisy Quantum Simulation. To represent the stochastic noisy channels
accurately, we average the output of multiple quantum circuits with fixed noisy
gates sampled from the channels. However, this leads to a substantial increase
in circuit overhead, which slows down the simulation. To eliminate this
overhead, TUSQ uses two modules: the Error Characterization Module (ECM), and
the Tree-based Execution Module (TEM).
  The ECM tracks the number of unique circuit executions needed to accurately
represent the noise. That is, if initially we needed $n_{1}$ circuit
executions, ECM reduces that number to $n_{2}$ by eliminating redundancies so
that $n_{2} < n_{1}$. This is followed by the TEM, which reuses computation
across these $n_{2}$ circuits. This computational reuse is facilitated by
representing all $n_{2}$ circuits as a tree. We sample the significant leaf
nodes of this tree and prune the remaining ones. We traverse this tree using
depth-first search. We use uncomputation to perform rollback-recovery at
several stages which reduces simulation time. We evaluate TUSQ for a total of
186 benchmarks and report an average speedup of $52.5\times$ and $12.53\times$
over Qiskit and CUDA-Q, which goes up to $7878.03\times$ and $439.38\times$
respectively. For larger benchmarks (more than than 15 qubits), the average
speedup is $55.42\times$ and $23.03\times$ over Qiskit and CUDA-Q respectively

</details>


### [414] [Fault-Tolerant Universal Quantum Computing in the Presence of Anisotropic Noise](https://arxiv.org/abs/2508.04892)
*Yang-Yang Xie,Zhao-Ming Wang,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 提出了一种可在退相干下运行的通用量子计算门集，无需量子纠错。通过一种变换生成系统-浴纠缠资源基，计算可在此基下无视退相干。


<details>
  <summary>Details</summary>
Motivation: 提出了一种通用的量子计算门集，可以在退相干的情况下运行，而无需量子纠错的额外开销。

Method: 通过一种“二步”变换，使任意的量子比特-浴耦合在“二步”变换后可以解耦，生成一个系统-浴纠缠资源基。当初始化在这一基下时，计算的演化如同没有发生退相干。

Result: 提出了一种通用的量子计算门集，可以在退相干的情况下运行，而无需量子纠错的额外开销。

Conclusion: 该提议为需要量子纠错的系统提供了一种灵活的替代方案，通过利用部分可调的系统-浴耦合。

Abstract: We propose a universal gate set for quantum computing that operates in the
presence of decoherence without requiring the overhead of quantum error
correction. Inspired by recent advances in noise manipulation technologies, we
demonstrate that a broad class of anisotropic qubit-bath couplings can be
decoupled via a dressing transformation, which generates a system-bath
entangled resource basis. When initialized in this basis, the computation
evolves as if decoherence is absent. Our proposal offers a flexible alternative
to systems requiring quantum error correction by utilizing partially tunable
system-bath couplings.

</details>


### [415] [Taming coherent noise with teleportation](https://arxiv.org/abs/2508.04947)
*Kathleen Chang,Qile Su,Shruti Puri*

Main category: quant-ph

TL;DR: 本研究提出一种利用量子比特传送来处理相干错误的方法，将其转化为 Pauli 错误，从而便于分析和模拟，并可能取代随机编译。


<details>
  <summary>Details</summary>
Motivation: 相干错误在量子计算和量子纠错中带来了新的挑战，例如可能在长电路中产生建设性干扰，以及缺乏关于其拓扑码阈值的解析证明，并且难以进行数值模拟。本研究旨在解决这些问题。

Method: 通过分析量子比特的重复传送过程，并研究传送 CSS 码的纯 Z 相干错误模型，将其与 Pauli 错误模型进行比较。

Result: 量子比特的重复传送可以将相干错误定制化为 Pauli 错误，从而可以有效地进行经典模拟，并提供可解析证明的阈值。该方法可能消除对基于传送的量子计算方案中随机编译的需求。

Conclusion: 该研究表明，量子比特的重复传送可以使相干错误退相干为 Pauli 错误，并且平均失真度最差与传送次数成线性关系。此外，对于传送的 CSS 码，纯 Z 相干错误模型等效于 Pauli 错误模型。

Abstract: Compared to the more widely studied Pauli errors, coherent errors present
several new challenges in quantum computing and quantum error correction (QEC).
For example, coherent errors may interfere constructively over a long circuit
and significantly increase the overall failure rate compared to Pauli noise.
Additionally, there is so far no analytical proof for a topological code
threshold under coherent errors. Moreover, it is hard to even numerically
estimate the performance of QEC under coherent errors as their effect in a
Clifford circuit cannot be efficiently classically simulated. In this work, we
demonstrate that teleportation effectively tailors coherent errors into Pauli
errors, for which analytical and numerical results are abundant. We first show
that repeated teleportation of a single qubit decoheres errors, and the average
infidelity grows at worst linearly with the number of teleportations, similar
to Pauli errors. We then analyze a physically motivated pure $Z$-coherent error
model for teleported CSS codes in which over-rotation errors accompany every
gate, and find that such an error model is equivalent to a Pauli error model.
Our result implies that the performance of a CSS code implemented via
teleportation-based error correction or measurement-based error correction with
such coherent noise can be efficiently simulated on a classical computer and
has an analytically provable threshold. The intrinsic noise-tailoring property
of teleportation may ultimately remove the need for randomized compiling in
teleportation-based quantum computing schemes.

</details>


### [416] [A Design for an Early Quantum Network](https://arxiv.org/abs/2508.04967)
*Yuan Li,Chen Zhang,Hao Zhang,Tao Huang,Yunjie Liu*

Main category: quant-ph

TL;DR: A new quantum network design compatible with existing repeaters aims to improve adaptability for various applications by addressing resource limitations and performance issues, validated through simulations.


<details>
  <summary>Details</summary>
Motivation: Quantum networks are essential for quantum information technology applications with stringent demands for fidelity and request completion time. The design aims to accommodate diverse application needs despite limitations.

Method: The paper proposes a design for early-stage quantum networks, describes required identifiers and the process for implementing quantum requests, and uses discrete-event modeling simulations to assess feasibility under various noise conditions and imperfect parameters.

Result: Simulations analyze the impact of noise and imperfect parameters on entanglement fidelity and request completion time, and investigate additional controller decisions like cutoff time and resource allocation.

Conclusion: The proposed design is compatible with three existing quantum repeater technologies and aims to maximize network adaptability for diverse quantum applications, even with limited resources and suboptimal performance.

Abstract: With the rapid advancement of quantum information technology, quantum
networks have become essential for supporting diverse applications, which often
have stringent demands for key metrics such as fidelity and request completion
time. In this work, we propose a design for early-stage quantum networks that
is compatible with the three existing quantum repeater technologies. The design
aims to maximize the ability of the network to accommodate the diverse needs of
quantum applications, even under conditions of limited quantum resources and
suboptimal network performance. We have also described the required identifiers
in the quantum network and the specific process for implementing quantum
requests. To assess the feasibility of our design, we conduct simulations based
on discrete-event modeling of quantum networks. The simulations consider
various types of noise and imperfect parameters that might exist in early-stage
networks. We analyze the impact of these parameters on the fidelity of the
generated entangled states and the request completion time. Furthermore, we
investigated additional decisions that the central controller can make beyond
path selection, such as the choice of cutoff time and the allocation of network
resources to requests.

</details>


### [417] [Corner functions from entanglement indices of harmonic lattices](https://arxiv.org/abs/2508.04992)
*Masafumi Shimojo,Satoshi Ishihara,Hironobu Kataoka,Atsuko Matsukawa*

Main category: quant-ph

TL;DR: 研究了谐振子链的纠缠指数，发现了PBCs和FBCs条件下计算结果的一些不一致之处。


<details>
  <summary>Details</summary>
Motivation: 研究孤立的通用谐振子集合U的两个相邻子集之间的纠缠指数，例如对数负性（LNs）和互信息（MIs）。

Method: 本文计算了LNs和MIs，并研究了Renyi熵、角函数和具有实心角和二面角的边项。

Result: 通过LNs计算出的每个角函数的值与之前研究中的值几乎相等，但3π/4的角函数来自MIs的值与从LNs计算出的值不够一致。

Conclusion: 在固定端边界条件下，计算了LNs和MIs，并与PBCs情况下的值进行了比较，特别是角函数，并检验了固定端的影响。

Abstract: We study the entanglement indices such as logarithmic negativities (LNs) and
mutual informations (MIs) between two adjacent subsets in a isolated universal
set $U$ of harmonic oscillators arranged on a two dimensional lattice within a
sufficiently large square. First, we verify the values of the corner functions
of angle $\pi/2, \pi/4, 3\pi/4$ presented in the previous study which adopts
periodic boundary conditions (PBCs) for the $U$. The values of each corner
function obtained from LNs are nearly equal to those in the previous ones,
while those of $3\pi/4$ from MIs are not sufficiently consistent with those
computed from LNs. Next, for the case where the universal system $U$ satisfies
the fixed end boundary conditions(FBCs), we calculate LNs, MIs at several
locations in $U$, compare them, especially corner functions with the values
obtained in the PBCs case, and examine the effect of the fixed ends. In
addition, we examine Renyi entropies for sets of three dimensional lattice
sites, the corner functions and the edge terms with solid angles and dihedral
angles $\pi/2,\pi/4$, respectively.

</details>


### [418] [Optimal Qubit Purification and Unitary Schur Sampling via Random SWAP Tests](https://arxiv.org/abs/2508.05046)
*Shrigyan Brahmachari,Austin Hulse,Henry D. Pfister,Iman Marvian*

Main category: quant-ph

TL;DR: 一种基于随机 SWAP 测试的量子比特纯化新方法，可实现最优保真度，并可用于量子态层析和计量等任务。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的量子比特纯化方法，旨在通过组合多个有噪声的量子态副本，获得更接近纯态的副本，并与现有最优方法（Schur 变换）进行比较。

Method: 使用仅基于随机 SWAP 测试的简单协议，通过识别和分离单重态对来纯化量子比特，并证明其最优性。

Result: 该协议实现了与 Schur 变换相同的保真度，并且在 T ≈ n ln n 次随机 SWAP 测试后，检测到任何新的单重态的概率呈指数级下降，剩余量子比特的保真度近似达到最优值，误差呈指数级减小。此外，该协议实现了具有指数级误差的弱 Schur 采样和酉 Schur 采样。

Conclusion: 该协议通过仅基于随机 SWAP 测试，以接近最优的保真度实现了量子比特纯化，并证明了其在弱 Schur 采样和酉 Schur 采样方面的有效性。

Abstract: The goal of qubit purification is to combine multiple noisy copies of an
unknown pure quantum state to obtain one or more copies that are closer to the
pure state. We show that a simple protocol based solely on random SWAP tests
achieves the same fidelity as the Schur transform, which is optimal. This
protocol relies only on elementary two-qubit SWAP tests, which project a pair
of qubits onto the singlet or triplet subspaces, to identify and isolate
singlet pairs, and then proceeds with the remaining qubits. For a system of $n$
qubits, we show that after approximately $T \approx n \ln n$ random SWAP tests,
a sharp transition occurs: the probability of detecting any new singlet
decreases exponentially with $T$. Similarly, the fidelity of each remaining
qubit approaches the optimal value given by the Schur transform, up to an error
that is exponentially small in $T$. More broadly, this protocol achieves what
is known as weak Schur sampling and unitary Schur sampling with error
$\epsilon$, after only $2n \ln(n \epsilon^{-1})$ SWAP tests. That is, it
provides a lossless method for extracting any information invariant under
permutations of qubits, making it a powerful subroutine for tasks such as
quantum state tomography and metrology.

</details>


### [419] [Factorizability of multi-party quantum sequence discrimination under local operations and classical communication](https://arxiv.org/abs/2508.05050)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 最优LOCC鉴别可分解为单独序列鉴别，并通过猜测最大概率状态实现。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究多方量子序列鉴别在LOCC下的分解问题，并为量子数据隐藏的根本极限研究提供应用。

Method: 本文研究了在局域操作和经典通信（LOCC）下多方量子序列的鉴别问题，并给出了最优LOCC鉴别可以分解为对每个单独序列的鉴别的条件。

Result: 通过多方量子态的例子说明了最优LOCC鉴别可以进行分解，并建立了最优LOCC鉴别可以仅通过猜测概率最大的状态来实现的充要条件。

Conclusion: 该研究为多方量子序列鉴别提供了条件，使其可分解为对每个单独序列的鉴别，并证明了该方法的可行性。

Abstract: We consider multi-party quantum sequence discrimination under local
operations and classical communication(LOCC), and provide conditions under
which the optimal LOCC discrimination of a multi-party quantum sequence
ensemble can be factorized into that of each individual ensemble. In other
words, the optimal LOCC discrimination of a multi-party quantum sequence
ensemble can be achieved just by performing optimal LOCC discrimination
independently at each step of the quantum sequence. We also illustrate through
examples of multi-party quantum states that such factorizability of optimal
LOCC discrimination is possible. We further establish a necessary and
sufficient condition under which the optimal LOCC discrimination of a
multi-party quantum state ensemble can be realized just by guessing the state
with the largest probability. Our results can provide a useful application to
investigate the fundamental limits of quantum data hiding.

</details>


### [420] [Quantum State Preparation for Medical Data: Comprehensive Methods, Implementation Challenges, and Clinical Prospects](https://arxiv.org/abs/2508.05063)
*Nikhil Kumar Rajput,Riya Bansal*

Main category: quant-ph

TL;DR: 一项关于如何将医学数据编码到量子计算的调查，指出了利用数据结构和新兴技术克服硬件限制的潜力。


<details>
  <summary>Details</summary>
Motivation: 量子计算在医学领域具有变革潜力，但高效地从复杂医学数据制备量子态仍然是一个基本挑战。

Method: 本研究对当前将医学信息编码到量子系统的方法进行了全面的检查，分析了理论原理、算法进展和实际限制。讨论了张量网络分解、变分量子算法、量子机器学习技术以及针对医学计算的专门错误缓解策略。

Result: 研究结果表明，量子计算在医学领域的优势依赖于利用固有的数据结构，例如医学影像中的空间相关性、生理信号中的时间模式以及生物组织中的分层结构。虽然当前的硬件限制了实现规模，但新兴方法展示了在近期使用的潜力。该研究为评估量子态制备在医学领域何时优于经典方法提供了结构化框架，并附带了实现指南和性能基准。

Conclusion: 量子计算在医学领域具有变革潜力，但目前仍面临将复杂医学数据编码为量子态的挑战。研究通过分析张量网络分解、变分量子算法、量子机器学习和错误缓解策略，为评估量子优势提供了框架，并指出了利用医学数据固有结构（如影像的空间相关性、生理信号的时间模式、生物分层组织）的重要性。尽管硬件限制了规模，但新兴方法预示着近期应用的潜力。

Abstract: Quantum computing holds transformative potential for medical applications,
yet efficiently preparing quantum states from complex medical data remains a
fundamental challenge. This survey provides a comprehensive examination of
current approaches for encoding medical information into quantum systems,
analyzing theoretical principles, algorithmic advancements, and practical
limitations. It discusses tensor network decomposition, variational quantum
algorithms, quantum machine learning techniques, and specialized error
mitigation strategies for medical computing. The findings indicate that quantum
advantages in medicine rely on leveraging inherent data structures such as
spatial correlations in imaging, temporal patterns in physiological signals,
and hierarchical biological organization. While current hardware restricts
implementations to small-scale problems, emerging methods show potential for
near-term use. The study provides a structured framework for assessing when
quantum state preparation outperforms classical approaches in medicine, along
with implementation guidelines and performance benchmarks.

</details>


### [421] [One-sided composite cavity on an optical nanocapillary fiber](https://arxiv.org/abs/2508.05072)
*Srinu Gadde,Jelba John,Ramachandrarao Yalla*

Main category: quant-ph

TL;DR: 通过结合纳米毛细管光纤和不对称缺陷模式光栅，成功实现了高达80%的最大耦合效率，并优化了腔体的品质因数、精细度和单程损耗，为开发确定性单光子源提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 设计腔体以在欠耦合、临界耦合和过耦合状态下实现高达80%的最大耦合效率。

Method: 提出了一种使用复合腔（结合了光学纳米毛细管光纤和不对称缺陷模式光栅）的单侧腔。

Result: 在最大耦合效率情况下，腔体的品质因数、精细度和单程损耗分别为19354、240和1.3%。

Conclusion: 该平台有望为量子技术中基于光纤的确定性单光子源开辟新途径。

Abstract: We numerically report a one-sided cavity on an optical nanocapillary fiber
(NCF) using a composite cavity. The composite cavity is formed by combining an
optical NCF and an asymmetric defect mode grating. We design the cavity to
realize the maximum channeling efficiency of up to 80% into one-sided
NCF-guided modes while operating from under- to critical- and overcoupling
regimes. For the maximum channeling efficiency case, we found the best quality
factor, finesse, and one-pass loss of the cavity are 19354, 240, and 1.3%,
respectively. The present platform may open a novel route for designing
fiber-based deterministic single-photon sources in quantum technologies.

</details>


### [422] [Explicit Instances of Quantum Tanner Codes](https://arxiv.org/abs/2508.05095)
*Rebecca Katharina Radebold,Stephen D. Bartlett,Andrew C. Doherty*

Main category: quant-ph

TL;DR: 构建了性能优越的量子 Tanner 码，并分析了其时空开销。


<details>
  <summary>Details</summary>
Motivation: 构建渐近良好的量子低密度奇偶校验码（qLDPC），并分析其性能和时空开销。

Method: 使用 dihedral 群和经典码对构建量子 Tanner 码。

Result: 构建了量子 Tanner 码的显式实例，展示了高编码率、相对距离和伪阈值，并在不同噪声环境下表现出良好性能。

Conclusion: 量子 Tanner 码性能良好，可与表面码媲美，但需要对时空开销进行分析。

Abstract: We construct several explicit instances of quantum Tanner codes, a class of
asymptotically good quantum low-density parity check (qLDPC) codes. The codes
are constructed using dihedral groups and random pairs of classical codes and
exhibit high encoding rates, relative distances, and pseudo-thresholds. Using
the BP+OSD decoder, we demonstrate good performance in the phenomenological and
circuit-level noise settings, comparable to the surface code with similar
distances. Finally, we conduct an analysis of the space-time overhead incurred
by these codes.

</details>


### [423] [Quantum Path Signatures](https://arxiv.org/abs/2508.05103)
*Samuel Crew,Cristopher Salvi,William F. Turner,Thomas Cass,Antoine Jacquier*

Main category: quant-ph

TL;DR: This paper connects path signatures to quantum field theory and quantum computing, introducing quantum path signatures and a quantum algorithm to compute them.


<details>
  <summary>Details</summary>
Motivation: To elucidate physical aspects of path signatures by formulating randomised path developments within the framework of matrix models in quantum field theory.

Method: We formulate randomised path developments within the framework of matrix models in quantum field theory, introduce a new family of randomised path developments, and derive corresponding loop equations. We interpret unitary randomised path developments as time evolution operators on a Hilbert space of qubits.

Result: We introduce a new family of randomised path developments and derive corresponding loop equations. We interpret unitary randomised path developments as time evolution operators on a Hilbert space of qubits. This leads to a definition of a quantum path signature feature map and associated quantum signature kernel through a quantum circuit construction. In the case of the Gaussian matrix model, we study a random ensemble of Pauli strings and formulate a quantum algorithm to compute such kernel.

Conclusion: We define a quantum path signature feature map and associated quantum signature kernel through a quantum circuit construction, and formulate a quantum algorithm to compute such kernel in the case of the Gaussian matrix model.

Abstract: We elucidate physical aspects of path signatures by formulating randomised
path developments within the framework of matrix models in quantum field
theory. Using tools from physics, we introduce a new family of randomised path
developments and derive corresponding loop equations. We then interpret unitary
randomised path developments as time evolution operators on a Hilbert space of
qubits. This leads to a definition of a quantum path signature feature map and
associated quantum signature kernel through a quantum circuit construction. In
the case of the Gaussian matrix model, we study a random ensemble of Pauli
strings and formulate a quantum algorithm to compute such kernel.

</details>


### [424] [Current comparator for both AC and DC ratio measurements with 10-8-level accuracy](https://arxiv.org/abs/2508.05140)
*Hidekazu Muramatsu,Yuta Kainuma,Hiromitsu Kato,Norihiko Sakamoto,Tatsuji Yamada,Chiharu Urano,Hiroshi Abe,Shinobu Onoda,Takeshi Ohshima,Yuji Hatano,Mutsuko Hatano,Nobu-Hisa Kaneko,Yasutaka Amagai,Takayuki Iwasaki*

Main category: quant-ph

TL;DR: 本文提出了一种室温、无需低温制冷的金刚石基交流/直流电流比较器，精度达到10-8，带宽300赫兹，性能优于现有交流比较器并媲美先进直流比较器，有望统一电流标准并应用于量子电气标准。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有交流和直流电流比较器技术分离（分别依赖电磁感应和超导量子干涉仪）导致的溯源系统碎片化和复杂化问题，以及满足新兴电力技术对统一电流标准的需求，本文旨在弥合这一技术鸿沟。

Method: 本文提出了一种集成金刚石基磁力计（利用氮-空位中心）的紧凑型室温交流/直流电流比较器。

Result: 该设备实现了10-8的交流和直流信号精度，系统带宽高达300赫兹，无需低温制冷。其性能超越了典型的交流比较器（精度提高十倍），并与最先进的直流比较器相当。

Conclusion: 本工作提出了一个紧凑、室温的交流/直流电流比较器，集成了基于氮-空位中心的金刚石磁力计。该装置实现了10-8的交流和直流信号精度，系统带宽高达300赫兹，且无需低温制冷。它在精度上超越了典型的交流比较器（提高了十倍），并达到了最先进的直流比较器的性能。这种统一的、无低温制冷的解决方案不仅提高了精度和通用性，还扩展了该系统在量子电气标准中的直流电阻电桥应用。

Abstract: Accurate measurements of alternating current (AC) and direct current(DC)
ratios are fundamental to electric power metrology. However, conventional
current comparators for AC and DC typically rely on distinct
technologies-electromagnetic induction for AC and superconducting quantum
interference devices for DC. This technological divide leads to a fragmented
and complex traceability system. Bridging this gap is critical for developing
unified current standards that meet the demands of emerging power technologies.
In this work, we present a compact, room-temperature AC/DC current comparator
that integrates a diamond-based magnetometer using nitrogen-vacancy centers.
The device achieves an accuracy of 10-8 for both AC and DC signals and supports
a system bandwidth up to 300 Hz, without the need for cryogenics. It surpasses
the performance of typical AC comparators, offering ten-fold higher accuracy,
and matches that of state-of-the-art DC comparators. This unified,
cryogenics-free solution not only enhances precision and versatility but also
expands the applicability of the system to DC resistance bridges in quantum
electrical standards.

</details>


### [425] [Hybrid quantum tensor networks for aeroelastic applications](https://arxiv.org/abs/2508.05169)
*M. Lautaro Hickmann,Pedro Alves,David Quero,Friedhelm Schwenker,Hans-Martin Rieser*

Main category: quant-ph

TL;DR: 混合量子张量网络结合张量网络和变分量子电路，在航空弹性时间序列分类和回归任务中表现出高精度和有前景的性能，但超参数优化仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 探索混合量子张量网络在航空弹性问题中的应用，利用量子机器学习（QML）处理复杂的时间序列分类和回归任务。

Method: 将张量网络与变分量子电路相结合，提出了一种端到端可训练的混合算法，首先将时间序列编码到张量网络中，然后利用可训练的张量网络进行降维，并将结果张量转换为量子电路进行处理。

Result: 在二元分类任务中实现了高准确率，并在离散变量回归方面表现出有前景的性能。但是，超参数选择仍具挑战性，需要仔细优化。

Conclusion: 本研究展示了混合量子张量网络在处理航空弹性问题方面的潜力，特别是在时间序列分类和回归任务中，并实现了高精度的二元分类。

Abstract: We investigate the application of hybrid quantum tensor networks to
aeroelastic problems, harnessing the power of Quantum Machine Learning (QML).
By combining tensor networks with variational quantum circuits, we demonstrate
the potential of QML to tackle complex time series classification and
regression tasks. Our results showcase the ability of hybrid quantum tensor
networks to achieve high accuracy in binary classification. Furthermore, we
observe promising performance in regressing discrete variables. While
hyperparameter selection remains a challenge, requiring careful optimisation to
unlock the full potential of these models, this work contributes significantly
to the development of QML for solving intricate problems in aeroelasticity. We
present an end-to-end trainable hybrid algorithm. We first encode time series
into tensor networks to then utilise trainable tensor networks for
dimensionality reduction, and convert the resulting tensor to a quantum circuit
in the encoding step. Then, a tensor network inspired trainable variational
quantum circuit is applied to solve either a classification or a multivariate
or univariate regression task in the aeroelasticity domain.

</details>


### [426] [Exploring Satellite Quantum Key Distribution under Atmospheric Constraints](https://arxiv.org/abs/2508.05235)
*Aditya Ajith,S. Saravana Veni*

Main category: quant-ph

TL;DR: 本研究通过模拟大气湍流和吸收损耗，评估了自由空间光QKD链接的性能，为实现安全的全球通信提供了量化支持。


<details>
  <summary>Details</summary>
Motivation: 为了解决地基到天基量子密钥分发（QKD）链路受大气湍流影响而产生的退化问题，本研究旨在量化其对链接预算和安全密钥率的影响，以评估自由空间光QKD链接在不同距离下的可行性。

Method: 本研究采用角谱传播、Hufnagel-Valley湍流模型和Von Karman相位屏，并考虑了O2、CO2和H2O等大气成分的吸收损耗。通过逐步模拟高斯光束在大气中的传播，并结合基于标准Cn2剖面的相位屏来模拟闪烁和光束抖动等相位失真，对BB84协议（含诱骗态）进行仿真。

Result: 仿真结果量化了在不同距离下的预期链接预算和安全密钥率，为评估自由空间光QKD链接在不同距离下的可行性提供了依据。

Conclusion: 该研究为自由空间光量子密钥分发（QKD）链接在不同距离下的可行性提供了量化依据，通过模拟大气湍流和吸收损耗对BB84协议（含诱骗态）的影响，评估了链接预算和安全密钥率。

Abstract: Satellite Quantum Key Distribution creates a pathway for secure global
communication with a level of security that is peerless. However,
ground-to-satellite Quantum Key Distribution links are degraded due to the
atmospheric turbulence. This paper gives a numerical framework using angular
spectrum propagation, Hufnagel-Valley model of turbulence and Von Karman phase
screens and takes into account the static losses introduced due to the
absorption of the beam by the different elements and compounds in the
atmosphere like O2, CO2 and H2O. This simulation propagates a Gaussian beam
step by step through the atmosphere, where we incorporate the phase distortions
using phase screens based on standard Cn2 profiles which take into account
losses such as scintillation and beam wander. We simulate the BB84 protocol
with decoy states for added security. The results of the simulation quantify
the expected link budget and Secure key rates over a range of distances to
measure the viability of Free Space Optical Quantum Key Distribution links at
different distances.

</details>


### [427] [Bipartite entanglement in a nuclear spin register mediated by a quasi-free electron spin](https://arxiv.org/abs/2508.05255)
*Marco Klotz,Andreas Tangemann,David Opferkuch,Alexander Kubanek*

Main category: quant-ph

TL;DR: 在金刚石中，我们利用硅空位（SiV）与三量子比特¹³C 核自旋寄存器耦合，通过特殊技术实现了对核自旋的精确控制和纠缠，为构建量子网络提供了新的固态解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算和纠错中实现强大的计算和纠错能力，需要依赖于与本地量子寄存器纠缠的光子。

Method: 利用高应变技术实现硅空位（SiV）与金刚石中的全连接三量子比特¹³C 核自旋寄存器的耦合，并通过连续解耦和射频驱动来控制和检测寄存器。

Result: 成功实现了对全连接三量子比特¹³C 核自旋寄存器的控制和纠缠，并实现了以电子自旋作为媒介的核自旋条件相位门。

Conclusion: 这项工作为构建可扩展的固态量子寄存器和光学可访问的量子网络提供了一条新途径，但需要进一步的研究来优化性能和扩展到更大的系统。

Abstract: Quantum networks will rely on photons entangled to robust, local quantum
registers for computation and error correction. We demonstrate control of and
entanglement in a fully connected three-qubit $^{13}\mathrm{C}$ nuclear spin
register in diamond. The register is coupled to a quasi-free electron spin-1/2
of a silicon-vacancy center (SiV). High strain decouples the SiVs electron spin
from spin-orbit interaction reducing the susceptibility to phonons at liquid
helium temperature. As a result, the electron spin lifetime of hundreds of
milli seconds enables sensing of nuclear-nuclear couplings down to few hertz.
To detect and control the register we leverage continuous decoupling using
shaped, low-power microwave and direct radio frequency driving. Furthermore, we
implement a nuclear spin conditional phase-gate on the electron spin to mediate
bipartite entanglement. This approach presents an alternative to dynamically
decoupled nuclear spin entanglement, not limited by the electron spin's 1/2
nature, opening up new avenues to an optically-accessible, solid-state quantum
register.

</details>


### [428] [Towards integrated sensors for optimized OCT with undetected photons](https://arxiv.org/abs/2508.05320)
*Franz Roeder,René Pollmann,Viktor Quiring,Christof Eigner,Benjamin Brecht,Christine Silberhorn*

Main category: quant-ph

TL;DR: 集成化OCT传感器需要宽光谱和高亮度。诱导相干方案比SU(1,1)方案更适合集成化未探测光子OCT测量，并实现了28μm的轴向分辨率。


<details>
  <summary>Details</summary>
Motivation: 为了在实际应用中实现未探测光子光学相干断层扫描（OCT），需要将传感器小型化并通过集成来实现。这些传感器必须具有大的光谱带宽和高亮度，这分别与高轴向分辨率和足够信噪比相关。

Method: 通过研究基于非线性Ti:LiNbO3波导的未探测光子OCT测量方案，并比较了SU(1,1)方案和诱导相干方案的性能。

Result: 在两种方案中，都进行了泵浦增益优化和未探测光子OCT测量，轴向分辨率低至28μm。诱导相干方案在集成系统中实现未探测光子测量方面表现更优。

Conclusion: 研究发现，在集成系统中进行未探测光子测量时，诱导相干方案比常用的SU(1,1)方案更适合。

Abstract: The development of practical sensors for optical coherence tomography (OCT)
with undetected photons requires miniaturization via integration. To be
practical, these sensors must exhibit a large spectral bandwidth and a high
brightness, which are linked to a high axial resolution and a sufficient signal
to noise ratio, respectively. Here, we combine these requirements in a scheme
for OCT-measurements with undetected photons based on nonlinear Ti:LiNbO$_3$
waveguides. We investigate the performance benchmarks of the commonly used
SU(1,1) scheme in comparison to an induced coherence scheme and find that the
latter is actually better suited when implementing measurements with undetected
photons in integrated systems. In both schemes, we perform pump gain
optimization and OCT measurements with undetected photons with an axial
resolution as low as 28 $\mathrm{\mu}$m.

</details>


### [429] [Quantum Circuit Benchmarking on IBM Brisbane: Performance Insights from Superconducting Qubit Models](https://arxiv.org/abs/2508.05331)
*J. Thirunirai Selvam,S. Saravana Veni*

Main category: quant-ph

TL;DR: 本研究利用IBM Brisbane量子处理器，通过超导量子比特实现了量子通信中的关键技术，包括量子门操作和纠缠态演化，并考虑了现实世界的噪声和退相干效应，为量子通信的安全性和可靠性提供了实验基础。


<details>
  <summary>Details</summary>
Motivation: 量子通信的安全性和可靠性对于信息传输至关重要，而纠缠态是实现这一目标的关键资源。因此，本研究旨在探索超导量子比特在模拟和控制量子系统方面的能力，以推动量子通信技术的发展。

Method: 本研究利用IBM Brisbane量子处理器，通过模拟和控制量子系统，实现基本量子门操作，并分析纠缠态的演化过程，同时考虑了退相干和噪声等现实条件，并扩展到模拟Jaynes Cummings和纵向Ising模型。

Result: 研究成功实现了量子门操作和纠缠态演化，并评估了在现实条件下的可行性，同时模拟了Jaynes Cummings和纵向Ising模型，为超导量子比特在量子通信和复杂量子模型研究中的应用提供了见解。

Conclusion: 本研究通过在IBM Brisbane量子处理器上实现量子门和纠缠态演化，证明了超导量子比特在量子通信中的应用潜力，为安全可靠的信息传输奠定了基础。

Abstract: This paper investigates quantum communication using superconducting qubits,
emphasizing the simulation and control of quantum systems via IBM Brisbane
quantum processor. We focus on implementing fundamental quantum gates and
analyzing the evolution of entangled states, which are essential for secure and
reliable information transfer. The study highlights the role of entanglement as
a critical resource in quantum communication, enabling secure connectivity
across quantum networks. Simulations incorporate realistic conditions,
including decoherence and noise, to assess the practical viability of entangled
state operations. Additionally, we explore the extension of these systems to
simulate key quantum models such as the Jaynes Cummings and longitudinal Ising
models, offering insight into complex interactions in superconducting
architectures. The findings advance quantum information science by
demonstrating the potential of superconducting qubit systems for both
foundational research and real world applications in quantum communication.

</details>


### [430] [Reinforcement Learning Generation of 4-Qubits Entangled States](https://arxiv.org/abs/2204.12351)
*Sara Giordano,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: 本研究利用Q学习AI算法和状态链接图（SLG）工具，成功构造了四量子比特纠缠态，并实现了最优的量子电路合成，为量子信息科学研究提供了新的方法和见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用人工智能算法，特别是机器学习中的Q学习，来构建杰出的四量子比特纠缠态，并探索其在量子信息科学和基础物理学中的潜在应用。

Method: 本研究提出了一种使用机器学习（Q学习）的人工智能算法，该算法能够构建出杰出的四量子比特纠缠态，并能够生成四量子比特纠缠态的49个真实SLOC（排序-本地操纵）类别中的代表性状态。此外，该算法能够达到每个纠缠簇系中的至少一个真实SLOC类别。本研究还引入了一个名为状态链接图（SLG）的图形化工具，用于表示算法所使用的Q矩阵（质量矩阵）的构造过程，该过程用于为特定纠缠类别中的目标状态进行构造。这有助于我们发现特定纠缠特征与算法所需特定量子门之间的必要联系。此外，本研究发现的量子电路在所选定的量子门集合上是最优的。

Result: 通过Q学习算法成功构造了四量子比特纠缠态，并能生成多种代表性状态，覆盖了九大纠缠簇系中的至少一类。引入的状态链接图（SLG）工具直观展示了Q矩阵的构造过程，揭示了纠缠特征与量子门之间的关系，为自动化构造纠缠态提供了有效途径。所发现的量子电路在特定量子门集下具有最优性。

Conclusion: 该算法易于使用，可用于为具有较少数量的量子比特的纠缠态进行自动构造。

Abstract: We have devised an artificial intelligence algorithm with machine
reinforcement learning (Q-learning) to construct remarkable entangled states
with 4 qubits. This way, the algorithm is able to generate representative
states for some of the 49 true SLOCC classes of the four-qubit entanglement
states. In particular, it is possible to reach at least one true SLOCC class
for each of the nine entanglement families. The quantum circuits synthesized by
the algorithm may be useful for the experimental realization of these important
classes of entangled states and to draw conclusions about the intrinsic
properties of our universe. We introduce a graphical tool called the state-link
graph (SLG) to represent the construction of the Quality matrix (Q-matrix) used
by the algorithm to build a given objective state belonging to the
corresponding entanglement class. This allows us to discover the necessary
connections between specific entanglement features and the role of certain
quantum gates that the algorithm needs to include in the quantum gate set of
actions. The quantum circuits found are optimal by construction with respect to
the quantum gate-set chosen. These SLGs make the algorithm simple, intuitive
and a useful resource for the automated construction of entangled states with a
low number of qubits.

</details>


### [431] [Material-Driven Optimization of Transmon Qubits for Scalable and Efficient Quantum Architectures](https://arxiv.org/abs/2508.05339)
*Jonnalagadda Gayatri,S. Saravana Veni*

Main category: quant-ph

TL;DR: 为了构建实用的量子计算机，研究人员正在优化超导  تقدیر。本研究结合了电路设计、材料分析和模拟，以提高  تقدیر 的性能。研究人员使用 Qiskit Metal 和 Ansys HFSS 等工具设计和分析了 4  تقدیر 和 8  تقدیر 的 Transmon 布局，并使用 COMSOL Multiphysics 模拟了不同材料对  تقدیر 性能的影响。研究结果表明，材料选择对  تقدیر 的相干性和整体器件质量至关重要，并为设计可靠的超导  تقدیر 系统提供了一种可行的方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展且高效的超导  تقدیر，需要解决相干时间、单个  تقدیر 之间的连接以及环境噪声等关键因素。特别是基于 Transmon 结构的超导  تقدیر，因其可光刻制造且对电荷噪声不敏感，已成为可扩展平台的有力竞争者。

Method: 使用 Qiskit Metal 创建了 4 تقدیر 和 8  تقدیر 的 Transmon 布局，并对每个  تقدیر 进行了单独分析。研究了其非谐性并提取了本征频率，计算了多个设计通道中的参与率，并使用 Ansys HFSS 确定了前五个能态。然后，在 COMSOL Multiphysics 中创建了单个  تقدیر 设计的二维横截面，以评估不同材料如何影响性能，从而能够分配各种超导材料和基板，并研究它们对能量损失和电磁特性的影响。

Result: 通过设计迭代、材料分析和模拟相结合，优化了超导  تقدیر。通过模拟分析了不同材料对能量损失和电磁特性的影响，证明了材料选择对  تقدیر 相干性和器件整体质量的显著影响。

Conclusion: 该框架结合了材料模拟和电路设计，为创建可靠的超导量子比特系统提供了一种可行的方法，并支持创建可扩展、容错量子计算的持续尝试。

Abstract: One of the most crucial steps in creating practical quantum computers is
designing scalable and efficient superconducting qubits. Coherence times,
connections between individual qubits, and reduction of environmental noise are
critical factors in the success of these qubits. Because they can be
lithographically fabricated and are less sensitive to charge noise,
superconducting qubits, especially those based on the Transmon architecture,
have emerged as top contenders for scalable platforms. In this work, we use a
combination of design iteration, material analysis, and simulation to tackle
the superconducting qubit optimization challenge. We created transmon-based
layouts for 4 qubits and 8 qubits using Qiskit Metal and conducted an
individual analysis for each qubit. We investigated anharmonicity and extracted
eigenfrequencies, computing participation ratios across several design passes,
and identifying the top five energy eigenstates using Ansys HFSS. We then
created a 2D cross section of a single qubit design in COMSOL Multiphysics to
evaluate how different materials affect performance. This enables us to assign
various superconducting materials and substrates and investigate their effects
on energy loss and electromagnetic properties. Qubit coherence and overall
device quality are significantly influenced by the materials chosen. This
integrated framework of material based simulation and circuit design offers a
workable way to create reliable superconducting qubit systems and supports
continued attempts to create scalable, fault-tolerant quantum computing.

</details>


### [432] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
*Sara Giordano,Kornikar Sen,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: 一种利用强化学习（特别是表格Q学习和混合奖励机制）合成高效量子电路（特别是最小深度电路）的方法，已在高达七个量子比特的任务中得到验证，并显示出良好的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代和未来容错量子计算中，在固定初始状态下从固定初始状态合成生成指定目标量子态的量子电路是一个核心挑战。

Method: 该方法利用基于动作序列的表格Q学习，在离散化的量子态空间中进行操作，并通过结合静态的、由领域知识驱动的奖励和可定制的动态惩罚（阻止门拥塞和冗余状态访问等低效电路结构）的混合奖励机制来指导智能体向目标状态进行，同时规避低效电路结构。

Result: 在多达七个量子比特的图态制备任务上进行基准测试，表明该算法能够持续发现具有优化门数的最小深度电路。此外，将该框架扩展到用于任意量子态的通用门集，它仍然能产生最小深度电路，凸显了该算法的鲁棒性和适应性。

Conclusion: 该强化学习驱动的方法能够有效地探索复杂的量子态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

Abstract: A reinforcement learning (RL) framework is introduced for the efficient
synthesis of quantum circuits that generate specified target quantum states
from a fixed initial state, addressing a central challenge in both the NISQ era
and future fault-tolerant quantum computing. The approach utilizes tabular
Q-learning, based on action sequences, within a discretized quantum state
space, to effectively manage the exponential growth of the space dimension. The
framework introduces a hybrid reward mechanism, combining a static,
domain-informed reward that guides the agent toward the target state with
customizable dynamic penalties that discourage inefficient circuit structures
such as gate congestion and redundant state revisits. By leveraging sparse
matrix representations and state-space discretization, the method enables
scalable navigation of high-dimensional environments while minimizing
computational overhead. Benchmarking on graph-state preparation tasks for up to
seven qubits, we demonstrate that the algorithm consistently discovers
minimal-depth circuits with optimized gate counts. Moreover, extending the
framework to a universal gate set for arbitrary quantum states, it still
produces minimal depth circuits, highlighting the algorithm's robustness and
adaptability. The results confirm that this RL-driven approach efficiently
explores the complex quantum state space and synthesizes near-optimal quantum
circuits, providing a resource-efficient foundation for quantum circuit
optimization.

</details>


### [433] [Geometric quantum encoding of a turbulent field](https://arxiv.org/abs/2508.05346)
*Zhaoyuan Meng,Yue Yang*

Main category: quant-ph

TL;DR: 针对多尺度系统（如湍流场）的量子编码难题，提出了一种基于 Hopf 纤维化的三阶段超球编码方法，该方法在量子比特需求和内存使用上展现出优越性，并成功复现了湍流的关键特征。


<details>
  <summary>Details</summary>
Motivation: 多尺度系统的混沌结构给量子编码带来了严峻的挑战。

Method: 提出了一种三阶段超球编码方法，包括：1. 量子比特的对称性保持扰动；2. 特定于测量的卷积；3. 可观测量的最终解卷积。其中，后两个阶段利用 Hopf 纤维化将量子可观测量映射到涡旋管。

Result: 使用 27 个量子比特，以 Re = 13900 的雷诺数生成了瞬时湍流场，该湍流场成功复现了能量谱的 Kolmogorov 五分之三律、缠结的涡旋结构和显著的间歇性。

Conclusion: 提出的方法只需要 O(log2Re) 量子比特，在量子比特需求上渐近最优，相较于经典方法实现了指数级内存缩减，并为大规模量子模拟多尺度系统实现了状态制备。

Abstract: The chaotic structure of multiscale systems presents a formidable challenge
to their quantum encoding. We propose a three-stage hyperspherical encoding
method for turbulent fields. This method comprises a symmetry-preserving
perturbation of the ground state, a measurement-specific convolution, and a
final deconvolution of observables. The latter two stages employ the Hopf
fibration to map quantum observables onto vortex tubes, the building blocks of
fluid turbulence. Using 27 qubits, we generate an instantaneous turbulent field
at a Reynolds number of $\mathit{Re} = 13900$ that reproduces the energy
spectrum with Kolmogorov's five-thirds scaling, tangled vortex structures, and
strong intermittency. The method only requires $\mathcal{O}(\log_2\mathit{Re})$
qubits, which is asymptotically optimal for turbulent-field encoding. This
yields an exponential memory reduction over classical methods, and enables
state preparation for large-scale quantum simulation of multiscale systems.

</details>


### [434] [Secure and practical Quantum Digital Signatures](https://arxiv.org/abs/2508.05355)
*Federico Grasselli,Gaetano Russo,Massimiliano Proietti*

Main category: quant-ph

TL;DR: 研究了三种量子数字签名协议，改进了它们的安全性，并通过优化提高了效率。


<details>
  <summary>Details</summary>
Motivation: 量子计算的出现对现有的数字签名构成了威胁，需要开发能够抵抗量子攻击的签名方案。量子数字签名（QDS）提供了一种信息论上（IT）安全且能抵抗量子攻击的解决方案。

Method: 对三种基于预共享密钥和通用哈希族的现有量子数字签名（QDS）协议进行了分析，并进行了改进以解决潜在漏洞，证明了其信息论（IT）安全性，并考虑了IT安全认证通信的失败情况。最后，对协议参数进行了数值优化，以提高预共享比特消耗和签名长度方面的效率，最终确定了最高效的协议。

Result: 成功改进了三种现有的QDS协议，解决了它们的潜在安全漏洞，并证明了它们的IT安全性。通过数值优化，提高了协议效率，减少了预共享密钥的消耗，并缩短了签名长度，最终确定了最具效率的QDS协议。

Conclusion: 提出了一种可以与量子计算机兼容的数字签名方案，并对其进行了优化。

Abstract: Digital signatures represent a crucial cryptographic asset that must be
protected against quantum adversaries. Quantum Digital Signatures (QDS) can
offer solutions that are information-theoretically (IT) secure and thus immune
to quantum attacks. In this work, we analyze three existing practical QDS
protocols based on preshared secure keys (e.g., established with quantum key
distribution) and universal hashing families. For each protocol, we make
amendments to close potential loopholes and prove their IT security while
accounting for the failure of IT-secure authenticated communication. We then
numerically optimize the protocol parameters to improve efficiency in terms of
preshared bit consumption and signature length, allowing us to identify the
most efficient protocol.

</details>


### [435] [Resource-Efficient Synthesis of Sparse Quantum States](https://arxiv.org/abs/2508.05386)
*Renaud Vilmart,Sunheang Ty,Chetra Mang*

Main category: quant-ph

TL;DR: 本文提出了一种用于制备稀疏量子态的量子电路合成算法，该算法在优化量子资源（如电路深度、辅助比特数和非克里福德门数量）方面取得了显著进展，其中非克里福德门数量与稀疏性呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 为了在容错量子计算中高效地实现量子算法，需要制备稀疏量子态，特别是要考虑昂贵的非克里福德门。

Method: 文章提出了一种新颖的量子电路合成算法，该算法包含两个关键部分：1. 广义W态的制备：采用基于树的电路构建方法，并阐述了树结构与电路复杂性之间的关系。 2. 置换的经典可逆电路实现：将问题转化为二元矩阵的对角化，并利用高斯-约旦消元法来最小化电路复杂度，特别是电路深度。

Result: 该算法生成的电路深度、辅助比特数以及非克里福德门数量均与稀疏性呈线性关系。文章还对非克里福德门数量的复杂度进行了猜想和部分证明。

Conclusion: 该算法在线性稀疏性的条件下，优化了量子资源的利用，包括量子比特、门数量和深度，并且在非克里福德门数量上达到了最优。

Abstract: Preparing a quantum circuit that implements a given sparse state is an
important building block that is necessary for many different quantum
algorithms. In the context of fault-tolerant quantum computing, the so-called
non-Clifford gates are much more expensive to perform than the Clifford ones.
We hence provide an algorithm for synthesizing sparse quantum states with a
special care for quantum resources. The circuit depth, ancilla count, and
crucially non-Clifford count of the circuit produced by the algorithm are all
linear in the sparsity. We conjecture that the non-Clifford count complexity is
tight, and show a weakened version of this claim. The first key component of
the algorithm is the synthesis of a generalized W-state. We provide a
tree-based circuit construction approach, and the relationship between the
tree's structure and the circuit's complexity. The second key component is a
classical reversible circuit implementing a permutation that maps the basis
states of the W-state to those of the sparse quantum state. We reduce this
problem to the diagonalization of a binary matrix, using a specific set of
elementary matrix operations corresponding to the classical reversible gates.
We then solve this problem using a new version of Gauss-Jordan elimination,
that minimizes the circuit complexities including circuit depth using parallel
elimination steps.

</details>


### [436] [Quantum State Preparation Of Multiconfigurational States For Quantum Chemistry](https://arxiv.org/abs/2508.05390)
*Gabriel Greene-Diniz,Georgia Prokopiou,David Zsolt Manrique,David Muñoz Ramo*

Main category: quant-ph

TL;DR: 本文研究了两种用于量子化学计算的量子态制备方法，发现利用量子态的稀疏性比基于Givens旋转的方法能获得更优化的量子线路。


<details>
  <summary>Details</summary>
Motivation: 量子化学计算是量子计算机的一个有前景的应用方向，因此，研究高效的量子化学态制备技术至关重要。

Method: 本文实现了两种量子线路制备多构型态的方法：1. 基于Givens旋转的方法，并开发了自动寻找所需外部控制的算法。2. 利用化学态向量稀疏性的替代方法。

Result: 研究发现，利用化学态向量稀疏性的方法相比于基于Givens旋转的外部控制方法，能够产生更优化的量子线路。在强关联分子基态、激发态的Q-SCEOM算法矩阵元以及量子计算矩和量子相位估计算法的量子子空间方法相关初始态等应用中验证了这些技术。

Conclusion: 该研究实现并比较了两种用于量子化学计算的量子线路制备多构型态的方法：一种是基于Givens旋转的方法，需要外部控制；另一种是利用化学态向量稀疏性的方法。研究表明，利用稀疏性可以获得更优化的量子线路。

Abstract: The ability to prepare states for quantum chemistry is a promising feature of
quantum computers, and efficient techniques for chemical state preparation is
an active area of research. In this paper, we implement and investigate two
methods of quantum circuit preparation for multiconfigurational states for
quantum chemical applications. It has previously been shown that controlled
Givens rotations are universal for quantum chemistry. To prepare a selected
linear combination of Slater determinants (represented as occupation number
configurations) using Givens rotations, the gates that rotate between the
reference and excited determinants need to be controlled on qubits outside the
excitation (external controls), in general. We implement a method to
automatically find the external controls required for utilizing Givens
rotations to prepare multiconfigurational states on a quantum circuit. We
compare this approach to an alternative technique that exploits the sparsity of
the chemical state vector and find that the latter can outperform the method of
externally controlled Givens rotations; highly reduced circuits can be obtained
by taking advantage of the sparse nature (where the number of basis states is
significantly less than 2$^{n_q}$ for $n_q$ qubits) of chemical wavefunctions.
We demonstrate the benefits of these techniques in a range of applications,
including the ground states of a strongly correlated molecule, matrix elements
of the Q-SCEOM algorithm for excited states, as well as correlated initial
states for a quantum subspace method based on quantum computed moments and
quantum phase estimation.

</details>


### [437] [LLM-based Multi-Agent Copilot for Quantum Sensor](https://arxiv.org/abs/2508.05421)
*Rong Sha,Binglin Wang,Jun Yang,Xiaoxiao Ma,Chengkun Wu,Liang Yan,Chao Zhou,Jixun Liu,Guochao Wang,Shuhua Yan,Lingxiao Zhu*

Main category: quant-ph

TL;DR: QCopilot是一个基于LLM的多智能体框架，通过集成外部知识、主动学习和不确定性量化，实现了量子传感器的自动化设计、诊断和优化，显著提高了实验效率并降低了部署门槛。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在量子传感器开发中面临跨学科知识壁垒和复杂优化过程的限制，需要新的解决方案来克服这些挑战。

Method: QCopilot框架整合了商业LLM、少样本提示工程和向量知识库，并通过专业智能体（agents）实现对优化方法的自适应选择、建模分析的自动化以及问题诊断的独立执行。

Result: 在原子冷却实验中，QCopilot框架实现了无需人工干预，在数小时内生成了10^8个亚微开尔文的原子，实验速度比手动实验快约100倍。该框架还能够自主识别多参数实验中的异常参数。

Conclusion: QCopilot框架通过整合外部知识、主动学习和不确定性量化，能够自主优化量子传感器的设计和诊断，解决了跨学科知识壁垒和复杂优化过程的挑战。该框架在原子冷却实验中实现了无需人工干预、数小时内达到10^8个亚微开尔文原子，比手动实验快约100倍。此外，QCopilot通过持续积累先验知识和动态建模，能自主识别多参数实验中的异常参数，降低了量子传感器大规模部署的门槛，并可扩展至其他量子信息系统。

Abstract: Large language models (LLM) exhibit broad utility but face limitations in
quantum sensor development, stemming from interdisciplinary knowledge barriers
and involving complex optimization processes. Here we present QCopilot, an
LLM-based multi-agent framework integrating external knowledge access, active
learning, and uncertainty quantification for quantum sensor design and
diagnosis. Comprising commercial LLMs with few-shot prompt engineering and
vector knowledge base, QCopilot employs specialized agents to adaptively select
optimization methods, automate modeling analysis, and independently perform
problem diagnosis. Applying QCopilot to atom cooling experiments, we generated
10${}^{\rm{8}}$ sub-$\rm{\mu}$K atoms without any human intervention within a
few hours, representing $\sim$100$\times$ speedup over manual experimentation.
Notably, by continuously accumulating prior knowledge and enabling dynamic
modeling, QCopilot can autonomously identify anomalous parameters in
multi-parameter experimental settings. Our work reduces barriers to large-scale
quantum sensor deployment and readily extends to other quantum information
systems.

</details>


### [438] [Block entanglement bounds distribution of regionally localized entanglement](https://arxiv.org/abs/2508.05431)
*Jithin G. Krishnan,Aditi Sen De,Amit Kumar Pal*

Main category: quant-ph

TL;DR: 研究提出了“区域局域纠缠”的概念来量化量子网络中的纠缠，并证明了其与局域化块纠缠的上下界限关系，该关系在多种量子态和噪声环境下均成立。


<details>
  <summary>Details</summary>
Motivation: 为了表征量子网络中节点消除（由测量空闲或易受噪声影响的节点引起）后剩余子网络中的纠缠含量，需要一种新的纠缠度量方法。

Method: 提出“区域局域纠缠”的概念，通过分析多量子比特系统中的两比特区域来量化纠缠。证明了所提出的“区域局域纠缠”与量子系统中的局域化块纠缠存在上下界限。通过数值模拟验证了这些界限在不同量子态（排列对称态、一般纯态）和不同噪声信道（相位翻转信道）下的有效性。

Result: 证明了区域局域纠缠的上下界限与局域化块纠缠相关，尤其是在排列对称态和特定磁化扇区叠加态下。数值模拟证实了这些界限对于一般纯态和经过相位翻转信道后的态（除小系统尺寸外）的有效性。特定磁化扇区态的界限与排列对称态不同，显示了其独特的纠缠特性。

Conclusion: 该研究引入了“区域局域纠缠”的概念，并证明了其与多量子比特系统中两个量子比特区域之间的局域化块纠缠存在上下界限，尤其是在排列对称态和特定磁化扇区叠加态等典范纯态下。研究还通过数值模拟证实了这些界限对于一般纯态和经过相位翻转信道后的态（除小系统尺寸外）的有效性，并揭示了特定磁化扇区态与排列对称态在纠缠特性上的结构性差异。

Abstract: In quantum networks, eliminating connections between nodes is crucial to
mitigate the effects of decoherence, often achieved by performing measurements
on nodes that are idle, or vulnerable to noise. To characterize the
entanglement content of the resulting smaller network, we introduce the notion
of ``regionally localized entanglement", defined as the average entanglement
concentrated over a two-qubit region in a multi-qubit system. Hence, the total
regionally localized entanglement can be obtained by considering all two-qubit
regions sharing a common qubit, referred to as the ``hub". We prove that the
total regionally localized entanglement corresponding to a specific hub is
bounded above and below via the localizable block entanglement shared between
the hub and the rest of the multi-qubit system for a number of paradigmatic
pure quantum states, including permutation-symmetric states and arbitrary
superposition of states from a specific magnetization sector. Numerical
simulations confirm that the bounds for permutation-symmetric pure states
remain valid even for Haar-uniformly generated pure states, and when each of
the qubits is sent through local phase-flip channels of Markovian and
non-Markovian types, except when the system-size is small. On the other hand,
arbitrary states from a particular magnetization sector yield bounds on total
regionally localized entanglement that are distinct from the
permutation-symmetric states, highlighting the structurally unique entanglement
properties of the former.

</details>


### [439] [Efficient certification of high-dimensional entanglement](https://arxiv.org/abs/2508.05484)
*Yiwen Wu,Zihao Li,Huangjun Zhu*

Main category: quant-ph

TL;DR: 提出一个通用框架，用于在LOCC下认证高维纠缠，发现其效率与局部维度成反比。


<details>
  <summary>Details</summary>
Motivation: 高维纠缠是量子信息处理中的宝贵资源，对其进行有效认证对许多应用至关重要。

Method: 提出一个简单通用的框架，用于在受限操作（如LOCC）下认证一般二体纯态中的高维纠缠。

Result: 在受限操作下，高维纠缠可以在一般二体纯态中被有效认证。此外，认证给定高维纠缠度的样本成本甚至随局部维度的增加而单调递减。对于一般的两量子比特纯态，基于可分操作构建了最优纠缠认证策略，该策略在目标态具有足够高的纠缠度时可通过LOCC实现。

Conclusion: 高维纠缠可以在一般二体纯态下通过LOCC高效认证，且样本成本随局部维度增加而单调递减。

Abstract: High-dimensional entanglement (HDE) is a valuable resource in quantum
information processing, and efficient certification of HDE is crucial to many
applications. In this work, we propose a simple and general framework for
certifying HDE in general bipartite pure states under restricted operations,
such as local operations and classical communication (LOCC). On this basis we
show that HDE in general bipartite pure states can be certified efficiently.
Moreover, the sample cost for certifying a given degree of HDE even decreases
monotonically with the local dimensions. In addition, for a general two-qubit
pure state, we construct an optimal entanglement certification strategy based
on separable operations, which can be realized by LOCC when the target state
has sufficiently high entanglement. The core concept of our framework is
versatile and can be extended to certify a wide range of critical resources
under restricted operations.

</details>


### [440] [Efficient Mediated Multiparty Semi-Quantum Secret Sharing Protocol Based on Single-Qubit Reordering](https://arxiv.org/abs/2508.05487)
*Mustapha Anis Younes,Sofia Zebboudj,Abdelhakim Gharbi*

Main category: quant-ph

TL;DR: 本研究提出了一种新的半量子秘密共享协议，降低了对经典参与者的能力要求，并提高了量子比特效率，同时保证了协议的安全性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有协议中经销商必须具备完全量子能力以及经典用户需要执行三个操作的实际限制，本研究旨在提出一种更实用、更易于实现的方案。

Method: 提出了一种新的多方半量子秘密共享（MSQSS）协议，该协议使用单个量子比特而非纠缠态作为量子资源，并只需要参与者执行测量和重新排序操作。

Result: 与现有协议相比，该协议具有更高的量子比特效率，并且是第一个采用单个量子比特作为量子资源的半量子秘密共享协议。

Conclusion: 该协议被证明可以抵抗已知的攻击。

Abstract: Typical multiparty semi-quantum secret sharing (MSQSS) protocols require the
dealer to possess full quantum capabilities, while the classical users usually
need to perform three operations. To address this practical limitation, this
paper introduces a new mediated MSQSS protocol that enables Alice, a classical
user, to share a secret with $M$ classical Bobs, with the assistance of an
untrusted third party (TP) who may attempt any possible attack to steal Alice's
secret. Furthermore, the classical participants require only two capabilities
instead of three, namely: (a) performing measurements in the $Z$ basis; and (b)
reordering qubits. The proposed scheme offers significant advantages over
existing mediated QSS protocols: (1) it is the first mediated SQSS protocol to
adopt single qubits, instead of entangled states, as the quantum resource,
which makes it more practical and easier to implement; (2) It achieves higher
qubit efficiency. Security analysis also demonstrates that the protocol is
secure against well-known attacks.

</details>


### [441] [$Λ$-Type Giant Atom Mediated Controllable Single-Photon Transport in a One-Dimensional Chiral Waveguide](https://arxiv.org/abs/2508.05510)
*Yimei Wang,Jing Li,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 通过手性耦合和驱动场控制巨原子系统的单光子散射谱，实现可调的透射和反射。


<details>
  <summary>Details</summary>
Motivation: 研究一个受驱动的、与一维波导发生手性耦合的Λ型巨原子系统的单光子散射谱，探索手性耦合和驱动场对光子传播特性的影响。

Method: 采用实空间散射方法，获得了马尔可夫和非马尔可夫体制下散射波函数解析解。

Result: 驱动场导致透射谱的谷分裂成双谷，谷间距随驱动场强度增大而增大；手性耦合允许在完全透射和完美反射之间切换；在特定相位下，马尔可夫极限下实现了与驱动场参数无关的完美透射；非马尔可夫体制下，巨原子尺寸的增大增强了散射谱的振荡行为，并可调控解耦点和完美反射点的数量。

Conclusion: 该研究为控制光子在奇子系统中传播提供了新的途径，特别是通过调整巨原子尺寸和驱动场强度来实现对透射和反射的精确控制。

Abstract: We investigate the single-photon scattering spectrum of a driven
$\Lambda$-type giant atom system chirally coupled to a one-dimensional (1D)
waveguide. By employing a real-space scattering approach, we obtain analytical
solutions for the scattering amplitudes that remain valid in both Markovian and
non-Markovian regimes. We observe that an external driving field induces a
splitting of the transmission spectrum's dip into double dips, with the
distance between the two dips increasing as the strength of the driving field
increases. The chiral nature of the coupling allows for controlled switching
between complete transmission and perfect reflection of incident photons. In
the Markovian limit, we predict robust perfect transmission at specific phase
values, independent of the driving field parameters.Moreover, in the
non-Markovian regime, as the size of the giant atom increases, the oscillatory
behavior of the scattering spectrum becomes more pronounced. Adjusting the
giant atom size enables control over the number of decoupling points as well as
the number of complete reflection points.

</details>


### [442] [Logical accreditation: a framework for efficient certification of fault-tolerant computations](https://arxiv.org/abs/2508.05523)
*James Mills,Adithya Sireesh,Dominik Leichtle,Joschka Roffe,Elham Kashefi*

Main category: quant-ph

TL;DR: 本文提出了一种名为“逻辑认证”的框架，用于高效认证逻辑量子比特上的量子计算。该方法通过随机编译将噪声转换为特定类型，从而能够处理更广泛的噪声模型，并解决了处理非横向逻辑门的难题。该框架通过模拟证明了其在认证量子优势实验和评估错误率方面的有效性，为量子计算的质量评估提供了一种实用的工具。


<details>
  <summary>Details</summary>
Motivation: 随着容错量子计算机的发展，对使用编码逻辑量子比特进行的计算的准确性进行认证将很快变得在经典上难以处理。这产生了对可扩展的、设备无关的认证方法的需求。

Method: 该框架基于一种新颖的随机编译方案，该方案将任意逻辑电路噪声转换为随机保利噪声。该方案包括一种用于处理标准T门之外的非横向逻辑门的扭曲方法。

Result: 通过数值模拟，我们证明了逻辑认证可以有效地认证量子优势实验，并指示编码计算开始优于物理计算的交叉点。逻辑认证还可以应用于评估逻辑电路错误率是否足够低，以便有效地执行错误缓解，将熵基准测试方法扩展到容错计算领域，并为逻辑输出状态的错误度设定上限。

Conclusion: 该协议通过将任意逻辑电路噪声转换为随机保利噪声，并提出了一种用于处理标准T门之外的非横向逻辑门的方法，解决了Piveteau等人提出的一个公开问题。逻辑认证通过将容错计算与计算认证相结合，为评估使用编码逻辑量子比特在量子硬件上执行的计算质量提供了一种实用的工具。

Abstract: As fault-tolerant quantum computers scale, certifying the accuracy of
computations performed with encoded logical qubits will soon become classically
intractable. This creates a critical need for scalable, device-independent
certification methods. In this work, we introduce logical accreditation, a
framework for efficiently certifying quantum computations performed on logical
qubits. Our protocol is robust against general noise models, far beyond those
typically considered in performance analyses of quantum error-correcting codes.
Through numerical simulations, we demonstrate that logical accreditation can
scalably certify quantum advantage experiments and indicate the crossover point
where encoded computations begin to outperform physical computations. Logical
accreditation can also find application in evaluating whether logical circuit
error rates are sufficiently low that error mitigation can be efficiently
performed, extending the entropy benchmarking method to the regime of
fault-tolerant computation, and upper-bounding the infidelity of the logical
output state. Underpinning the framework is a novel randomised compiling scheme
that converts arbitrary logical circuit noise into stochastic Pauli noise. This
scheme includes a method for twirling non-transversal logical gates beyond the
standard T-gate, resolving an open problem posed by Piveteau et al. [Piveteau
et al. PRL 127, 200505 (2001)]. By bridging fault-tolerant computation and
computational certification, logical accreditation offers a practical tool to
assess the quality of computations performed on quantum hardware using encoded
logical qubits.

</details>


### [443] [Model-based framework for automated quantification of error sources in quantum state tomography](https://arxiv.org/abs/2508.05538)
*Junpei Oba,Hsin-Pin Lo,Yasuhiro Yamada,Takayuki Matsui,Takuya Ikuta,Yuya Yonezu,Toshimori Honjo,Seiji Kajita,Hiroki Takesue*

Main category: quant-ph

TL;DR: 本研究提出了一种自动化方法，通过模拟和参数优化来量化量子态制备中的误差来源，显著提高了量子态质量，并可应用于多种量子平台。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子态层析（QST）中多个误差源汇聚于单一密度矩阵，难以识别个体误差源的问题，本研究提出了一种新的自动化方法。

Method: 本研究提出了一种结合模拟和参数优化的自动化方法，通过调整模型参数来重构实验测得的密度矩阵，从而量化误差来源。具体而言，研究人员对实验产生的时间-宾纠缠光子对进行建模，模拟其密度矩阵，并优化参数以最小化与实验数据的迹距离。

Result: 通过优化参数，将迹距离从0.177降低到0.024，表明所模拟的误差源解释了86%的误差。误差预测的减少与量子态质量的提高相符，验证了该方法的有效性。

Conclusion: 该方法通过模拟和参数优化相结合，成功量化了量子态制备中的误差来源，并将迹距离从0.177降低到0.024，表明模型解释了86%的误差。所提出的方法能够提高量子态质量，并且具有模块化结构，可应用于其他量子平台。

Abstract: High-quality quantum state generation is essential for advanced quantum
information processing, including quantum communication, quantum sensing, and
quantum computing. In practice, various error sources degrade the quality of
quantum states, and quantum state tomography (QST) is a standard diagnostic
tool. However, in QST, multiple error sources gather in a single density
matrix, making it difficult to identify individual error sources. To address
this problem, we propose an automated method for quantifying error sources by
combining simulation and parameter optimization to reproduce the experimental
density matrix. We focus on the experimental generation of time-bin entangled
photon pairs, for which we model the relevant error sources and simulate the
density matrix with adjustable model parameters, thereby optimizing the
parameters and minimizing the trace distance to the experimental data.
Optimization of the parameters reduced the trace distance from 0.177 to 0.024,
indicating that our modeled error sources explain 86% of the errors. Reducing
the predicted error sources improves the state quality, consistent with our
predictions and thus validating the proposed method. In addition, the modular
structure of this framework makes it applicable to other quantum platforms,
such as superconducting qubits, atoms, and solid-state spins.

</details>


### [444] [On the Design of Expressive and Trainable Pulse-based Quantum Machine Learning Models](https://arxiv.org/abs/2508.05559)
*Han-Xiao Tao,Xin Wang,Re-Bing Wu*

Main category: quant-ph

TL;DR: 本研究提出了脉冲基QML模型设计的一个必要条件，以平衡表达能力和可训练性，并得到了数值模拟的支持。


<details>
  <summary>Details</summary>
Motivation: 为了在实际应用中有效地利用脉冲基量子机器学习（QML），模型需要在保证硬件效率的同时，兼具表达能力和可训练性。之前的研究表明，虽然动态对称有助于训练，但可能牺牲表达能力。

Method: 通过数值模拟，研究了脉冲基QML模型在动态对称下的表达能力和可训练性之间的权衡，并提出了一个关于系统初始状态、测量算符和动力学对称李代数的必要条件。

Result: 研究结果表明，通过满足提出的必要条件，可以设计出既有表达能力又可训练的脉冲基QML模型，解决了动态对称性可能导致的可控性不足的问题。

Conclusion: 本研究提出了脉冲基QML模型设计的一个必要条件，该条件与系统的初始状态、测量算符和动力学对称李代数有关，并得到了数值模拟的支持。这些发现为设计兼顾表达能力和可训练性的实用脉冲基QML模型提供了一个框架。

Abstract: Pulse-based Quantum Machine Learning (QML) has emerged as a novel paradigm in
quantum artificial intelligence due to its exceptional hardware efficiency. For
practical applications, pulse-based models must be both expressive and
trainable. Previous studies suggest that pulse-based models under dynamic
symmetry can be effectively trained, thanks to a favorable loss landscape that
has no barren plateaus. However, the resulting uncontrollability may compromise
expressivity when the model is inadequately designed. This paper investigates
the requirements for pulse-based QML models to be expressive while preserving
trainability. We present a necessary condition pertaining to the system's
initial state, the measurement observable, and the underlying dynamical
symmetry Lie algebra, supported by numerical simulations. Our findings
establish a framework for designing practical pulse-based QML models that
balance expressivity and trainability.

</details>


### [445] [Quench dynamics of entanglement entropy under projective charge measurements: the free fermion case](https://arxiv.org/abs/2508.05588)
*Riccardo Travaglino,Colin Rylands,Pasquale Calabrese*

Main category: quant-ph

TL;DR: 该研究分析了投影测量（特别是粒子数）对一维自由费米子系统纠缠熵动力学的影响，发现了测量会引入经典和量子两种纠缠熵修正，并得到了相应的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索投影测量对一维自由费米子系统中纠缠熵动力学的影响，特别是研究测量对纠缠熵的经典和量子贡献。

Method: 本研究提出了一种包含U(1)守恒荷（粒子数）的投影测量方案，并研究了其对一维自由费米子系统中两个子系统之间的纠缠熵动力学的影响。我们比较了两种初始状态（分别是荷的本征态和非本征态）下的系统动力学，并考虑了单次测量和周期性多次测量的影响。利用准粒子图像，我们推导出了纠缠熵行为的解析表达式，并得到了清晰的物理解释。

Result: 研究发现，测量会引入两种不同的纠缠熵修正：一种是与测量结果无关的经典贡献，其大小与电荷分布方差成对比例关系；另一种是与测量结果相关的量子贡献，该贡献在个体实现中可能很大，但在对所有可能测量结果进行平均后可以忽略不计。

Conclusion: 在考虑测量结果和测量频率等因素的情况下，我们得到了纠缠熵的解析表达式，并将其与之前的研究结果进行了比较，同时通过对Néel初始态进行精确计算来验证了我们的理论。

Abstract: We consider the effect of projective measurements on the quench dynamics of
the bipartite entanglement entropy in one dimensional free fermionic systems.
In our protocol, we consider projective measurements of a $U(1)$ conserved
charge, the particle number, on some large subsystem, and study the
entanglement entropies between the same subsystem and its complement. We
compare the dynamics emanating from two classes of initial states, one which is
an eigenstate of the charge and another which is not. Moreover, we consider the
effects of a single measurement as well as multiple which are periodically
performed. Using the quasiparticle picture, we obtain analytic expressions for
the behaviour of the entanglement which admit a transparent physical
interpretation. In general, we find that measurements introduce two distinct
types of corrections to the entanglement, which can be interpreted separately
as classical and quantum contributions. The classical contribution is
independent of the measurement outcome and scales logarithmically with variance
of the charge distribution. In contrast, the quantum contribution depends on
the specific measurement outcome and can be significant for individual
realizations; however, it becomes negligible when averaged over all possible
outcomes. Our expressions reduce to previously known results for symmetry
resolved entanglement and full counting statistics in some relevant limits, and
are confirmed by an exact calculation performed on the N\'eel initial state.

</details>


### [446] [Secure Quantum Key Distribution via Entangled Quantum Walkers](https://arxiv.org/abs/2508.05593)
*Chia-Tso Lai*

Main category: quant-ph

TL;DR: 本研究提出了一种新的QKD协议，利用双纠缠量子行走者的相关性来生成密钥，并通过分析概率分布和硬币状态来增强安全性。


<details>
  <summary>Details</summary>
Motivation: 受到量子密钥分发（QKD）和量子随机行走（QRW）的启发，本文旨在利用QRW的特性来改进QKD协议。

Method: 本研究提出了一种基于双纠缠量子行走者的QKD协议，并分析了行走者联合概率分布及其关联的硬币状态，以增强协议的安全性。

Result: 通过利用双纠缠量子行走者的唯一相关性，成功建立了安全的共享密钥，并且通过分析联合概率分布和硬币状态，提高了协议的安全性。

Conclusion: 本研究提出了一种基于双纠缠量子行走者的新颖量子密钥分发（QKD）协议，利用行走者在行走末端位置的独特相关性来建立共享密钥。

Abstract: Quantum Key Distribution (QKD) is an emerging cryptographic method designed
for secure key sharing. Its security is theoretically guaranteed by fundamental
principles of quantum mechanics, making it a leading candidate for future
communication protocols. Quantum Random Walks (QRWs), on the other hand, are
quantum processes that exhibit intriguing phenomena such as interference and
superposition, enabling the generation of decentralized and asymmetric
probability distributions. Inspired by both fields of study, we propose a novel
QKD protocol based on two entangled quantum walkers. Our protocol exploits the
unique correlations between the walkers at extremal positions of the walk to
establish secret keys shared exclusively by the two parties. The security of
the protocol is augmented by analyzing the joint probability distributions of
the walkers' measured positions and their associated coin states.

</details>


### [447] [Ultra-Large-Scale Compilation and Manipulation of Quantum Circuits with Pandora](https://arxiv.org/abs/2508.05608)
*Ioana Moflic,Alexandru Paler*

Main category: quant-ph

TL;DR: Pandora是一个开源、多线程、高性能的量子电路处理工具，可以处理数十亿个门，在编译、等效性检查和资源估算方面表现出色，尤其是在处理大规模电路时。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前量子软件在编译和处理量子电路规模方面与实际应用需求之间存在的巨大差距。

Method: 基于电路重写，支持多线程和高性能计算。

Result: Pandora能够处理数十亿个门，并在资源估算管道中以很高的速率流式传输电路分区。在费米-哈伯德100x100和1024位Shor算法电路上进行了完整编译。与TKET和Qiskit相比，Pandora在处理超过10000个门的电路时表现出性能优势，在特定32个以上量子比特的电路等效性检查任务上优于MQT.QCEC。

Conclusion: Pandora工具有望在量子软件领域开辟新路径。

Abstract: There is an enormous gap between what quantum circuit sizes can be compiled
and manipulated with the current generation of quantum software and the sizes
required by practical applications such as quantum chemistry or Shor's
algorithm. We present Pandora, an efficient, open-source, multithreaded,
high-performance-computing-enabled tool based on circuit rewrites. Pandora can
be used for quantum circuit equivalence checking, full compilations of large
circuits, and scalable, streaming quantum resource estimation frameworks.
Pandora can easily handle billions of gates and can stream circuit partitions
in resource estimation pipelines at very high rates. We utilized Pandora for
full compilations of Fermi-Hubbard 100x100 and 1024-bit Shor's algorithm
circuits. Compared to TKET and Qiskit, we determine a performance advantage for
manipulating circuits of more than 10000 gates. For equivalence checking tasks,
Pandora outperforms MQT.QCEC on specific circuits that have more than 32
qubits. The performance and versatility of Pandora open novel paths in quantum
software.

</details>


### [448] [Partial projected ensembles and spatiotemporal structure of information scrambling](https://arxiv.org/abs/2508.05632)
*Saptarshi Mandal,Pieter W. Claeys,Sthitadhi Roy*

Main category: quant-ph

TL;DR: 该研究引入了部分投影系综（PPE）来研究量子多体系统中的信息预言。PPE可以通过测量子系统的结果来构建，其统计涨落和比特串概率可以揭示信息扩散的时空结构和预言动力学。该方法已被证明在遍历和多体局域化（MBL）系统中有效。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是理解非平衡量子多体系统中的热化和信息预言之间的关系。具体来说，研究人员希望找到一种方法来研究预言如何将时空结构印在投影系综上，以及如何利用投影系综来探测预言动力学。

Method: 该研究通过引入部分投影系综（PPE）来研究热化和信息预言。PPE是通过对互补子系统的测量结果进行条件化，并对剩余部分进行追踪而产生的纯态系综。研究人员分析了PPE的统计涨落和比特串概率（PoPs），以研究信息扩散的时空结构。

Result: 研究结果表明，PPE的统计涨落可以忠实地跟踪信息扩散的因果光锥，揭示了预言动力学是如何在系综结构中编码的。此外，PPE的比特串概率（PoPs）展示了不同的动力学机制，并且可以作为预言的一个可供实验探测的途径。研究还发现，PPE涨落和PoPs对丢弃区域的大小表现出指数敏感性，这反映了量子相关性在擦除下的指数级退化。最后，研究证明了PPE能够自然地涌现出与遍历和MBL机制相对应的线性和对数光锥。

Conclusion: 该研究引入了部分投影系综（PPE）作为研究预言如何将时空结构印在投影系综上的新框架。PPE能够捕获涉及丢弃结果或噪声引起的损失的情况，并且其统计涨落可以忠实地跟踪信息扩散的因果光锥，揭示了预言动力学如何在系综结构中编码。此外，PPE的相关比特串概率（PoPs）展示了不同的动力学机制，并为预言提供了一个可供实验探测的途径。PPE涨落和PoPs都对丢弃区域的大小表现出指数敏感性，反映了量子相关性在擦除下的指数级退化。研究结果通过非积分驱动的Ising链进行了验证，并将分析扩展到了多体局域化（MBL）区域。

Abstract: Thermalisation and information scrambling in out-of-equilibrium quantum
many-body systems are deeply intertwined: local subsystems dynamically approach
thermal density matrices while their entropies track information spreading.
Projected ensembles--ensembles of pure states conditioned on measurement
outcomes of complementary subsystems--provide higher-order probes of
thermalisation, converging at late times to universal maximum-entropy
ensembles. In this work, we introduce the partial projected ensemble (PPE) as a
framework to study how the spatiotemporal structure of scrambling is imprinted
on projected ensembles. The PPE consists of an ensemble of mixed states induced
on a subsystem by measurements on a spatially separated part of its complement,
tracing out the remainder, naturally capturing scenarios involving discarded
outcomes or noise-induced losses. We show that statistical fluctuations of the
PPE faithfully track the causal lightcone of information spreading, revealing
how scrambling dynamics are encoded in ensemble structure. In addition, we
demonstrate that the probabilities of bit-string probabilities (PoPs)
associated with the PPE exhibit distinct dynamical regimes and provide an
experimentally accessible probe of scrambling. Both PPE fluctuations and PoPs
display exponential sensitivity to the size of the discarded region, reflecting
exponential degradation of quantum correlations under erasure. We substantiate
these findings using the non-integrable kicked Ising chain, combining numerics
in the ergodic regime with exact results at its self-dual point. We extend our
analysis to a many-body localised (MBL) regime numerically, along with analytic
results for the $\ell$-bit model. The linear and logarithmic lightcones
characteristic of ergodic and MBL regimes emerge naturally from PPE dynamics,
establishing it as a powerful tool for probing scrambling and deep
thermalisation.

</details>
