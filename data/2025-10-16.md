<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 99]
- [cs.CL](#cs.CL) [Total: 77]
- [cs.RO](#cs.RO) [Total: 30]
- [eess.SY](#eess.SY) [Total: 20]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.MA](#cs.MA) [Total: 5]
- [quant-ph](#quant-ph) [Total: 43]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.SI](#cs.SI) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.GT](#cs.GT) [Total: 7]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.LG](#cs.LG) [Total: 92]
- [cs.DS](#cs.DS) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU](https://arxiv.org/abs/2510.13546)
*Ruiqi Ye,Mikel Luján*

Main category: cs.CV

TL;DR: 本研究首次对比了GPU和FPGA在视觉SLAM（V-SLAM）前端特征检测方面的硬件加速性能，发现对于非学习型特征检测器（如FAST、Harris），GPU表现优于FPGA；而对于学习型特征检测器（如SuperPoint），FPGA则在运行时间和能效上优于GPU。FPGA加速的V-SLAM在部分数据集上可达到与GPU相当的帧率，但总体精度GPU略胜一筹。研究还提出，通过硬件加速特征检测，可减少全局捆绑调整模块的调用频率，在不牺牲精度的前提下提升V-SLAM性能。


<details>
  <summary>Details</summary>
Motivation: 在功耗受限的平台上部署视觉SLAM（V-SLAM）时，计算密集且耗时的特征检测模块成为瓶颈。GPU和FPGA是常见的硬件加速器，但缺乏对它们在V-SLAM流水线中特征检测性能的直接比较研究。

Method: 本文首次针对视觉SLAM（V-SLAM）流水线，对基于GPU和FPGA的特征检测器进行了硬件加速的对比研究。评估了在Nvidia Jetson Orin和AMD Versal等现代SoC平台上，GPU加速的FAST、Harris、SuperPoint与FPGA加速的对应实现。同时对比了GPU加速和FPGA加速的V-SLAM流水线的整体性能。

Result: 1. 非学习型特征检测器（FAST、Harris）：GPU实现比FPGA实现具有更好的运行时间和能效。 2. 学习型特征检测器（SuperPoint）：FPGA实现比GPU实现具有更好的运行时间和能效（分别提升高达3.1倍和1.4倍）。 3. V-SLAM流水线：FPGA加速V-SLAM的运行时间性能与GPU加速V-SLAM相当，在2/5的数据集序列上FPS更高。 4. 精度：GPU加速V-SLAM总体上比FPGA加速V-SLAM更精确。 5. 优化建议：为特征检测使用硬件加速可减少全局捆绑调整模块的调用频率，从而在不牺牲精度的前提下提升V-SLAM性能。

Conclusion: 对于V-SLAM中的特征检测，GPU和FPGA的加速优势取决于所使用的特征检测算法类型：对于传统的非学习型算法，GPU是更优选择；而对于基于学习的算法，FPGA展现出更高的能效和运行速度。此外，硬件加速特征检测为V-SLAM优化提供了新的途径，可以在不影响精度的前提下提高效率。

Abstract: Feature detection is a common yet time-consuming module in Simultaneous
Localization and Mapping (SLAM) implementations, which are increasingly
deployed on power-constrained platforms, such as drones. Graphics Processing
Units (GPUs) have been a popular accelerator for computer vision in general,
and feature detection and SLAM in particular.
  On the other hand, System-on-Chips (SoCs) with integrated Field Programmable
Gate Array (FPGA) are also widely available. This paper presents the first
study of hardware-accelerated feature detectors considering a Visual SLAM
(V-SLAM) pipeline. We offer new insights by comparing the best GPU-accelerated
FAST, Harris, and SuperPoint implementations against the FPGA-accelerated
counterparts on modern SoCs (Nvidia Jetson Orin and AMD Versal).
  The evaluation shows that when using a non-learning-based feature detector
such as FAST and Harris, their GPU implementations, and the GPU-accelerated
V-SLAM can achieve better run-time performance and energy efficiency than the
FAST and Harris FPGA implementations as well as the FPGA-accelerated V-SLAM.
However, when considering a learning-based detector such as SuperPoint, its
FPGA implementation can achieve better run-time performance and energy
efficiency (up to 3.1$\times$ and 1.4$\times$ improvements, respectively) than
the GPU implementation. The FPGA-accelerated V-SLAM can also achieve comparable
run-time performance compared to the GPU-accelerated V-SLAM, with better FPS in
2 out of 5 dataset sequences. When considering the accuracy, the results show
that the GPU-accelerated V-SLAM is more accurate than the FPGA-accelerated
V-SLAM in general. Last but not least, the use of hardware acceleration for
feature detection could further improve the performance of the V-SLAM pipeline
by having the global bundle adjustment module invoked less frequently without
sacrificing accuracy.

</details>


### [2] [SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms](https://arxiv.org/abs/2510.12901)
*Haithem Turki,Qi Wu,Xin Kang,Janick Martinez Esturo,Shengyu Huang,Ruilong Li,Zan Gojcic,Riccardo de Lutio*

Main category: cs.CV

TL;DR: SimULi是首个能实时渲染任意相机模型和激光雷达数据的多传感器模拟方法，解决了现有神经渲染方法在渲染速度、相机模型支持和跨传感器一致性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了确保自动驾驶汽车等自主机器人在现实世界部署中的安全性，必须对其进行严格测试，这需要构建高保真模拟器来测试现实世界中无法安全或详尽收集的场景。

Method: SimULi通过扩展支持复杂相机模型和激光雷达数据，利用自动平铺策略和基于射线剔除的方法，并采用因子化3D高斯表示和锚定策略来解决跨传感器不一致性问题。

Result: SimULi的渲染速度比光线追踪方法快10-20倍，比之前的栅格化方法快1.5-10倍，并支持更广泛的相机模型。在两个广泛使用的自动驾驶数据集上的评估表明，SimULi在多个相机和激光雷达指标上都能达到或超过现有最先进方法的保真度，并将相机和深度误差平均降低了40%。

Conclusion: SimULi通过提供实时、高保真、多传感器模拟能力，克服了现有方法的局限性，为自动驾驶机器人等领域的安全测试提供了有效的解决方案。

Abstract: Rigorous testing of autonomous robots, such as self-driving vehicles, is
essential to ensure their safety in real-world deployments. This requires
building high-fidelity simulators to test scenarios beyond those that can be
safely or exhaustively collected in the real-world. Existing neural rendering
methods based on NeRF and 3DGS hold promise but suffer from low rendering
speeds or can only render pinhole camera models, hindering their suitability to
applications that commonly require high-distortion lenses and LiDAR data.
Multi-sensor simulation poses additional challenges as existing methods handle
cross-sensor inconsistencies by favoring the quality of one modality at the
expense of others. To overcome these limitations, we propose SimULi, the first
method capable of rendering arbitrary camera models and LiDAR data in
real-time. Our method extends 3DGUT, which natively supports complex camera
models, with LiDAR support, via an automated tiling strategy for arbitrary
spinning LiDAR models and ray-based culling. To address cross-sensor
inconsistencies, we design a factorized 3D Gaussian representation and
anchoring strategy that reduces mean camera and depth error by up to 40%
compared to existing methods. SimULi renders 10-20x faster than ray tracing
approaches and 1.5-10x faster than prior rasterization-based work (and handles
a wider range of camera models). When evaluated on two widely benchmarked
autonomous driving datasets, SimULi matches or exceeds the fidelity of existing
state-of-the-art methods across numerous camera and LiDAR metrics.

</details>


### [3] [State-Change Learning for Prediction of Future Events in Endoscopic Videos](https://arxiv.org/abs/2510.12904)
*Saurav Sharma,Chinedu Innocent Nwoye,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 SurgFUTR 的新方法，通过学习状态变化来预测手术的未来事件，解决了现有方法在预测范围、粒度和泛化能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有手术AI研究主要关注理解当前发生的事情，而非预测未来事件，并且现有方法各自为政，缺乏对短期（动作三元组、事件）和长期（剩余手术时长、阶段转换）预测的统一方法。此外，现有方法依赖粗粒度监督，对手术动作三元组和步骤的细粒度探索不足，并且仅基于未来特征预测的方法在不同手术环境和流程中的泛化能力有限。

Method: 提出了一种将手术未来预测重构为状态变化学习的方法，不直接预测原始观测值，而是对当前和未来时间步之间的状态转换进行分类。具体实现上，采用了 SurgFUTR，通过一个教师-学生架构。首先，使用 Sinkhorn-Knopp 聚类将视频片段压缩成状态表示；然后，教师网络同时从当前和未来的视频片段中学习；最后，学生网络仅从当前视频中进行预测，并通过提出的 Action Dynamics (ActDyn) 模块进行指导。

Result: 建立了一个包含五个预测任务（涵盖短期和长期预测）的 SurgFUTR 性能基准（SFPBench），并在四个数据集和三种手术流程上进行了实验，结果显示持续的改进。跨流程迁移实验也验证了该方法的泛化能力。

Conclusion: SurgFUTR 通过状态变化学习有效解决了手术未来预测中的挑战，并在短期和长期预测任务上取得了优于现有方法的性能，同时展现了良好的跨流程泛化能力。

Abstract: Surgical future prediction, driven by real-time AI analysis of surgical
video, is critical for operating room safety and efficiency. It provides
actionable insights into upcoming events, their timing, and risks-enabling
better resource allocation, timely instrument readiness, and early warnings for
complications (e.g., bleeding, bile duct injury). Despite this need, current
surgical AI research focuses on understanding what is happening rather than
predicting future events. Existing methods target specific tasks in isolation,
lacking unified approaches that span both short-term (action triplets, events)
and long-term horizons (remaining surgery duration, phase transitions). These
methods rely on coarse-grained supervision while fine-grained surgical action
triplets and steps remain underexplored. Furthermore, methods based only on
future feature prediction struggle to generalize across different surgical
contexts and procedures. We address these limits by reframing surgical future
prediction as state-change learning. Rather than forecasting raw observations,
our approach classifies state transitions between current and future timesteps.
We introduce SurgFUTR, implementing this through a teacher-student
architecture. Video clips are compressed into state representations via
Sinkhorn-Knopp clustering; the teacher network learns from both current and
future clips, while the student network predicts future states from current
videos alone, guided by our Action Dynamics (ActDyn) module. We establish
SFPBench with five prediction tasks spanning short-term (triplets, events) and
long-term (remaining surgery duration, phase and step transitions) horizons.
Experiments across four datasets and three procedures show consistent
improvements. Cross-procedure transfer validates generalizability.

</details>


### [4] [Robust Plant Disease Diagnosis with Few Target-Domain Samples](https://arxiv.org/abs/2510.12909)
*Takafumi Nogami,Satoshi Kagiwada,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 深度学习在植物病害诊断中表现优异，但在不同环境下准确性会下降。TMPS框架通过利用少量目标域样本，有效提高了模型的鲁棒性，并在大规模数据集上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习系统在植物病害诊断方面表现出色，但泛化能力不足，在不同于训练环境的条件下诊断准确率会下降。

Method: 提出了一种名为目标感知度量学习与优先采样（TMPS）的框架，该框架基于度量学习，假设可以获得少量目标域的标记样本，并有效利用这些样本来提高诊断鲁棒性。

Result: 在包含223,073张叶部图像的大规模植物病害诊断任务上，TMPS仅使用每种疾病10个目标域样本进行训练，其表现优于使用相同来源和目标样本训练的模型，以及在来源数据上预训练后用目标样本微调的模型，平均宏观F1分数分别提高了7.3和3.6个百分点，相比基线和传统度量学习分别提高了18.7和17.1个百分点。

Conclusion: TMPS框架能够有效提升植物病害诊断模型的鲁棒性，即使在只有少量目标域样本的情况下也能取得优于现有方法的性能。

Abstract: Various deep learning-based systems have been proposed for accurate and
convenient plant disease diagnosis, achieving impressive performance. However,
recent studies show that these systems often fail to maintain diagnostic
accuracy on images captured under different conditions from the training
environment -- an essential criterion for model robustness. Many deep learning
methods have shown high accuracy in plant disease diagnosis. However, they
often struggle to generalize to images taken in conditions that differ from the
training setting. This drop in performance stems from the subtle variability of
disease symptoms and domain gaps -- differences in image context and
environment. The root cause is the limited diversity of training data relative
to task complexity, making even advanced models vulnerable in unseen domains.
To tackle this challenge, we propose a simple yet highly adaptable learning
framework called Target-Aware Metric Learning with Prioritized Sampling (TMPS),
grounded in metric learning. TMPS operates under the assumption of access to a
limited number of labeled samples from the target (deployment) domain and
leverages these samples effectively to improve diagnostic robustness. We assess
TMPS on a large-scale automated plant disease diagnostic task using a dataset
comprising 223,073 leaf images sourced from 23 agricultural fields, spanning 21
diseases and healthy instances across three crop species. By incorporating just
10 target domain samples per disease into training, TMPS surpasses models
trained using the same combined source and target samples, and those fine-tuned
with these target samples after pre-training on source data. It achieves
average macro F1 score improvements of 7.3 and 3.6 points, respectively, and a
remarkable 18.7 and 17.1 point improvement over the baseline and conventional
metric learning.

</details>


### [5] [Unifying Vision-Language Latents for Zero-label Image Caption Enhancement](https://arxiv.org/abs/2510.12931)
*Sanghyun Byun,Jung Ick Guack,Mohanad Odema,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CV

TL;DR: ViZer通过在训练中对齐视觉和语言表示特征，实现了无需标签的图像描述增强，提高了现有VLMs的生成能力，且无需进行文本标签或重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视觉语言模型（VLMs）依赖于标注图像数据集进行预训练，这限制了其可扩展性，并且大量未标注的图像数据未能得到充分利用。本研究旨在解决这一问题，提出一种无需标签的零标签学习方法，以增强图像描述任务，并为视觉语言任务的零标签适应提供一个实用的起点。

Method: ViZer是一个增强训练框架，通过在训练过程中主动对齐视觉和语言的表示特征，使现有的VLMs在无需文本标签或完全重新训练的情况下，生成改进后的图像描述。

Result: 将ViZer应用于SmolVLM-Base和Qwen2-VL模型，观察到一致的定性改进，生成的描述比基线模型更具依据性和描述性。然而，自动评估指标（如CIDEr和BERTScore）可能无法准确评估这些改进，因为它们有时会因细节缺失而惩罚改进后的描述，而这些细节在参考描述中并不存在。

Conclusion: ViZer框架能够有效提升现有VLMs在图像描述任务上的表现，生成更准确、更详细的描述，并且无需依赖标注数据。

Abstract: Vision-language models (VLMs) achieve remarkable performance through
large-scale image-text pretraining. However, their reliance on labeled image
datasets limits scalability and leaves vast amounts of unlabeled image data
underutilized. To address this, we propose Unified Vision-Language Alignment
for Zero-Label Enhancement (ViZer), an enhancement training framework that
enables zero-label learning in image captioning, providing a practical starting
point for broader zero-label adaptation in vision-language tasks. Unlike prior
approaches that rely on human or synthetically annotated datasets, ViZer
actively aligns vision and language representation features during training,
enabling existing VLMs to generate improved captions without requiring text
labels or full retraining. We demonstrate ViZer's advantage in qualitative
evaluation, as automated caption metrics such as CIDEr and BERTScore often
penalize details that are absent in reference captions. Applying ViZer on
SmolVLM-Base and Qwen2-VL, we observe consistent qualitative improvements,
producing captions that are more grounded and descriptive than their baseline.

</details>


### [6] [Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation](https://arxiv.org/abs/2510.12953)
*Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: FetalMind是一个针对胎儿超声的医疗AI系统，用于报告生成和诊断，通过新的SED方法和大规模数据集FetalSigma-1M解决了现有模型的局限性，并在多项任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在成人影像方面表现良好，但在胎儿超声领域表现不佳，因为胎儿超声面临多视图图像推理、疾病种类繁多和图像多样性等挑战。

Method: 提出了一种名为Salient Epistemic Disentanglement (SED) 的方法，该方法通过引入专家策划的双分图来解耦视图-疾病关联，并通过强化学习引导模型沿临床路径进行推理。同时，创建了首个大规模胎儿超声报告数据集FetalSigma-1M。

Result: FetalMind在所有妊娠阶段都优于现有的开源和闭源模型，平均性能提升14%，在关键病症诊断上的准确率提高了61.2%，并且效率高、性能稳定。

Conclusion: FetalMind通过其创新的SED方法和大规模数据集，有效解决了胎儿超声领域的医学AI挑战，并在报告生成和诊断方面取得了最先进的性能。

Abstract: Recent medical vision-language models have shown promise on tasks such as
VQA, report generation, and anomaly detection. However, most are adapted to
structured adult imaging and underperform in fetal ultrasound, which poses
challenges of multi-view image reasoning, numerous diseases, and image
diversity. To bridge this gap, we introduce FetalMind, a medical AI system
tailored to fetal ultrasound for both report generation and diagnosis. Guided
by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which
injects an expert-curated bipartite graph into the model to decouple
view-disease associations and to steer preference selection along clinically
faithful steps via reinforcement learning. This design mitigates variability
across diseases and heterogeneity across views, reducing learning bottlenecks
while aligning the model's inference with obstetric practice. To train
FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale
fetal ultrasound report corpus, comprising 20K reports from twelve medical
centers, addressing the scarcity of domain data. Extensive experiments show
that FetalMind outperforms open- and closed-source baselines across all
gestational stages, achieving +14% average gains and +61.2% higher accuracy on
critical conditions while remaining efficient, stable, and scalable. Project
Page: https://hexiao0275.github.io/FetalMind.

</details>


### [7] [CADE 2.5 - ZeResFDG: Frequency-Decoupled, Rescaled and Zero-Projected Guidance for SD/SDXL Latent Diffusion Models](https://arxiv.org/abs/2510.12954)
*Denis Rychkovskiy,GPT-5*

Main category: cs.CV

TL;DR: CADE 2.5是一个用于SD/SDXL模型的采样器级引导堆栈，通过频率解耦引导、能量重缩放和零投影来提高图像质量，同时结合QSilk Micrograin Stabilizer以增强鲁棒性和细节。


<details>
  <summary>Details</summary>
Motivation: 现有SD/SDXL模型的引导方法在提高图像清晰度、提示遵循度和伪影控制方面存在局限性，尤其是在中等引导尺度下，并且可能需要重新训练。

Method: 提出CADE 2.5，其核心模块ZeResFDG集成了频率解耦引导（区分低频和高频）、能量重缩放（匹配引导预测与正向分支的幅度）和零投影（消除与无条件方向平行的分量）。此外，引入了轻量级的谱EMA（指数移动平均）和滞后机制，以在采样过程中根据结构结晶情况在保守模式和细节模式之间切换。同时，使用无需训练的QSilk Micrograin Stabilizer（分位数裁剪+深度/边缘门控微细节注入）来提高鲁棒性并在高分辨率下生成自然微纹理。

Result: 在SD/SDXL采样器上，ZeResFDG在中等引导尺度下提高了图像的清晰度、提示遵循度，并减少了伪影，且无需重新训练。QSilk Micrograin Stabilizer提高了鲁棒性，在高分辨率下产生了自然的微纹理，开销可忽略不计。

Conclusion: CADE 2.5及其配套的QSilk Micrograin Stabilizer能够显著提升SD/SDXL模型的图像生成质量，包括清晰度、提示遵循度和细节表现，同时保持了计算效率和无需额外训练的优点。

Abstract: We introduce CADE 2.5 (Comfy Adaptive Detail Enhancer), a sampler-level
guidance stack for SD/SDXL latent diffusion models. The central module,
ZeResFDG, unifies (i) frequency-decoupled guidance that reweights low- and
high-frequency components of the guidance signal, (ii) energy rescaling that
matches the per-sample magnitude of the guided prediction to the positive
branch, and (iii) zero-projection that removes the component parallel to the
unconditional direction. A lightweight spectral EMA with hysteresis switches
between a conservative and a detail-seeking mode as structure crystallizes
during sampling. Across SD/SDXL samplers, ZeResFDG improves sharpness, prompt
adherence, and artifact control at moderate guidance scales without any
retraining. In addition, we employ a training-free inference-time stabilizer,
QSilk Micrograin Stabilizer (quantile clamp + depth/edge-gated micro-detail
injection), which improves robustness and yields natural high-frequency
micro-texture at high resolutions with negligible overhead. For completeness we
note that the same rule is compatible with alternative parameterizations (e.g.,
velocity), which we briefly discuss in the Appendix; however, this paper
focuses on SD/SDXL latent diffusion models.

</details>


### [8] [Foveation Improves Payload Capacity in Steganography](https://arxiv.org/abs/2510.13151)
*Lifeng Qiu Lin,Henry Kam,Qi Sun,Kaan Akşit*

Main category: cs.CV

TL;DR: 本研究利用高效的潜在表示和注视渲染技术，在视觉媒介中实现了更高容量和更高准确率的隐写术，同时保持了可比的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高视觉隐写术的容量和准确率，并探索新颖的感知设计在多模态潜在表示中的应用。

Method: 通过利用高效的潜在表示和注视渲染技术来训练模型，以突破现有的容量限制并提高准确率。

Result: 模型将现有容量从100比特提高到500比特，准确率达到2000比特测试中1比特的失败率，并在31.47 dB PSNR和0.13 LPIPS下实现了可比的视觉质量。

Conclusion: 本研究证明了新颖的感知设计在创建用于隐写术的多模态潜在表示方面的有效性。

Abstract: Steganography finds its use in visual medium such as providing metadata and
watermarking. With support of efficient latent representations and foveated
rendering, we trained models that improve existing capacity limits from 100 to
500 bits, while achieving better accuracy of up to 1 failure bit out of 2000,
at 200K test bits. Finally, we achieve a comparable visual quality of 31.47 dB
PSNR and 0.13 LPIPS, showing the effectiveness of novel perceptual design in
creating multi-modal latent representations in steganography.

</details>


### [9] [Scope: Selective Cross-modal Orchestration of Visual Perception Experts](https://arxiv.org/abs/2510.12974)
*Tianyu Zhang,Suyuchen Wang,Chao Wang,Juan Rodriguez,Ahmed Masry,Xiangru Jian,Yoshua Bengio,Perouz Taslakian*

Main category: cs.CV

TL;DR: SCOPE通过实例级路由动态选择专用编码器，以解决多编码器视觉-语言模型（VLMs）的效率问题。


<details>
  <summary>Details</summary>
Motivation: 多个视觉编码器可以提升VLMs的性能，但简单堆叠它们会导致收益递减并增加推理成本。

Method: SCOPE是一个“编码器混合”（MoEnc）框架，它通过实例级路由为每个图像-文本对动态选择一个专用编码器。该框架包含一个共享编码器和一组路由编码器。一个轻量级的路由器利用文本提示和共享视觉特征之间的交叉注意力来从路由编码器中选择最佳编码器。为了训练这个路由器，引入了双重熵正则化和辅助损失，以平衡数据集级别的负载分布和实例级别的路由置信度。

Result: SCOPE框架，即使只有一个共享编码器和一个路由编码器，也优于同时使用所有四个附加编码器的模型，同时将计算量减少了24-49%。

Conclusion: 智能编码器选择胜过暴力聚合，这挑战了多编码器VLMs中的普遍范式。

Abstract: Vision-language models (VLMs) benefit from multiple vision encoders, but
naively stacking them yields diminishing returns while multiplying inference
costs. We propose SCOPE, a Mixture-of-Encoders (MoEnc) framework that
dynamically selects one specialized encoder per image-text pair via
instance-level routing, unlike token-level routing in traditional MoE. SCOPE
maintains a shared encoder and a pool of routed encoders. A lightweight router
uses cross-attention between text prompts and shared visual features to select
the optimal encoder from the routed encoders. To train this router, we
introduce dual entropy regularization with auxiliary losses to balance
dataset-level load distribution with instance-level routing confidence.
Remarkably, SCOPE with one shared plus one routed encoder outperforms models
using all four extra encoders simultaneously, while reducing compute by
24-49\%. This demonstrates that intelligent encoder selection beats brute-force
aggregation, challenging the prevailing paradigm in multi-encoder VLMs.

</details>


### [10] [Automated document processing system for government agencies using DBNET++ and BART models](https://arxiv.org/abs/2510.13303)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 该系统能够自动检测图像中的文本内容，并将其分为发票、报告、信件和表格四类，支持离线图像和实时摄像头输入，并能应对各种图像挑战。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理各种实际图像挑战的自动文档分类系统，以识别和分类不同类型的文档。

Method: 采用包含图像采集与预处理、DBNet++进行文本检测、BART进行文本分类的四阶段流程，并使用Python和PyQt5构建用户界面。

Result: 在Total-Text数据集上，文本检测达到了约92.88%的准确率，该数据集包含高分辨率图像并模拟了各种挑战。

Conclusion: 提出的方法在无约束的成像场景下，对于实用的、混合来源的文档分类是有效的。

Abstract: An automatic document classification system is presented that detects textual
content in images and classifies documents into four predefined categories
(Invoice, Report, Letter, and Form). The system supports both offline images
(e.g., files on flash drives, HDDs, microSD) and real-time capture via
connected cameras, and is designed to mitigate practical challenges such as
variable illumination, arbitrary orientation, curved or partially occluded
text, low resolution, and distant text. The pipeline comprises four stages:
image capture and preprocessing, text detection [1] using a DBNet++
(Differentiable Binarization Network Plus) detector, and text classification
[2] using a BART (Bidirectional and Auto-Regressive Transformers) classifier,
all integrated within a user interface implemented in Python with PyQt5. The
achieved results by the system for text detection in images were good at about
92.88% through 10 hours on Total-Text dataset that involve high resolution
images simulate a various and very difficult challenges. The results indicate
the proposed approach is effective for practical, mixed-source document
categorization in unconstrained imaging scenarios.

</details>


### [11] [SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding](https://arxiv.org/abs/2510.13016)
*Tanveer Hannan,Shuaicong Wu,Mark Weber,Suprosanna Shit,Jindong Gu,Rajat Koner,Aljoša Ošep,Laura Leal-Taixé,Thomas Seidl*

Main category: cs.CV

TL;DR: 该研究提出了一个新的任务——时空视频动作定位（SVAG），旨在同时检测、跟踪和定位视频中与自然语言描述的动作相关的所有对象。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度动作识别或通用对象跟踪方面存在不足，无法同时处理多个对象的检测、跟踪及其动作的时间定位。

Method: 提出了 SVAG 任务，并构建了 SVAG-Bench 这一大规模基准。同时，提出了 SVAGFormer 框架，并开发了 SVAGEval 评估工具包。

Result: SVAGFormer 在 SVAG 任务上表现尚可，但在密集或复杂场景下的表现不佳，凸显了在长视频中对细粒度对象-动作交互进行更高级推理的必要性。

Conclusion: SVAG 任务和 SVAG-Bench 基准的提出为视频理解领域带来了新的研究方向，但仍有很大的改进空间，尤其是在处理复杂场景和长视频方面。

Abstract: Understanding fine-grained actions and accurately localizing their
corresponding actors in space and time are fundamental capabilities for
advancing next-generation AI systems, including embodied agents, autonomous
platforms, and human-AI interaction frameworks. Despite recent progress in
video understanding, existing methods predominantly address either
coarse-grained action recognition or generic object tracking, thereby
overlooking the challenge of jointly detecting and tracking multiple objects
according to their actions while grounding them temporally. To address this
gap, we introduce Spatio-temporal Video Action Grounding (SVAG), a novel task
that requires models to simultaneously detect, track, and temporally localize
all referent objects in videos based on natural language descriptions of their
actions. To support this task, we construct SVAG-Bench, a large-scale benchmark
comprising 688 videos, 19,590 annotated records, and 903 unique verbs, covering
a diverse range of objects, actions, and real-world scenes. We further propose
SVAGFormer, a baseline framework that adapts state of the art vision language
models for joint spatial and temporal grounding, and introduce SVAGEval, a
standardized evaluation toolkit for fair and reproducible benchmarking.
Empirical results show that existing models perform poorly on SVAG,
particularly in dense or complex scenes, underscoring the need for more
advanced reasoning over fine-grained object-action interactions in long videos.

</details>


### [12] [Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering](https://arxiv.org/abs/2510.13381)
*Siddharth Tourani,Jayaram Reddy,Akash Kumbar,Satyajit Tourani,Nishant Goyal,Madhava Krishna,N. Dinesh Reddy,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种结合 SDF 和 3DGS 的新方法，用于动态场景渲染和重建，无需 LiDAR 数据即可在城市场景中实现最先进的渲染性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 3DGS 方法在渲染动态城市场景时需要相机和 LiDAR 数据、地面真实 3D 分割和运动数据等限制，本研究探索使用 2D 无关先验（如深度和点跟踪）以及 SDF 来放宽这些要求。

Method: 提出了一种将 SDF 与 3DGS 结合的统一优化框架，以增强 3DGS 的几何精度并改进 SDF 内的变形建模。

Result: 在没有 LiDAR 数据的情况下，该方法在城市场景的渲染指标上达到了最先进的性能。结合 LiDAR 数据后，在不依赖地面真实 3D 运动注释的情况下，在重建和生成新视图方面表现更好。此外，该方法还支持场景分解和组合等编辑任务。

Conclusion: 结合 SDF 和 3DGS 的方法可以更灵活、更精确地表示动态场景，并且可以放宽对数据输入的某些要求，同时保持甚至提高性能。

Abstract: Dynamic scene rendering and reconstruction play a crucial role in computer
vision and augmented reality. Recent methods based on 3D Gaussian Splatting
(3DGS), have enabled accurate modeling of dynamic urban scenes, but for urban
scenes they require both camera and LiDAR data, ground-truth 3D segmentations
and motion data in the form of tracklets or pre-defined object templates such
as SMPL. In this work, we explore whether a combination of 2D object agnostic
priors in the form of depth and point tracking coupled with a signed distance
function (SDF) representation for dynamic objects can be used to relax some of
these requirements. We present a novel approach that integrates Signed Distance
Functions (SDFs) with 3D Gaussian Splatting (3DGS) to create a more robust
object representation by harnessing the strengths of both methods. Our unified
optimization framework enhances the geometric accuracy of 3D Gaussian splatting
and improves deformation modeling within the SDF, resulting in a more adaptable
and precise representation. We demonstrate that our method achieves
state-of-the-art performance in rendering metrics even without LiDAR data on
urban scenes. When incorporating LiDAR, our approach improved further in
reconstructing and generating novel views across diverse object categories,
without ground-truth 3D motion annotation. Additionally, our method enables
various scene editing tasks, including scene decomposition, and scene
composition.

</details>


### [13] [SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models](https://arxiv.org/abs/2510.13042)
*Zhengxu Tang,Zizheng Wang,Luning Wang,Zitao Shuai,Chenhao Zhang,Siyu Qian,Yirui Wu,Bohao Wang,Haosong Rao,Zhenyu Yang,Chenwei Wu*

Main category: cs.CV

TL;DR: SeqBench是一个新的文本到视频生成评估基准，专注于评估视频叙事连贯性，并引入了基于动态时序图（DTG）的评估指标，揭示了当前模型在多动作序列、多对象场景和动作时序关系方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频（T2V）模型在生成连贯的、包含多个事件的顺序叙事方面存在困难，而现有的T2V基准主要关注视觉质量，忽略了长期叙事连贯性的评估。

Method: 构建了一个包含320个提示、2560个视频的新数据集（SeqBench），并设计了一种基于动态时序图（DTG）的自动评估指标，用于捕捉长距离依赖和时间顺序。

Result: SeqBench的评估揭示了当前T2V模型在保持物体状态一致性、物理合理性以及动作时间顺序方面的不足。DTG指标与人类标注具有高度相关性。

Conclusion: SeqBench是第一个用于评估T2V生成叙事连贯性的系统框架，为未来改进T2V模型的序列推理能力提供了见解。

Abstract: Text-to-video (T2V) generation models have made significant progress in
creating visually appealing videos. However, they struggle with generating
coherent sequential narratives that require logical progression through
multiple events. Existing T2V benchmarks primarily focus on visual quality
metrics but fail to evaluate narrative coherence over extended sequences. To
bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating
sequential narrative coherence in T2V generation. SeqBench includes a carefully
designed dataset of 320 prompts spanning various narrative complexities, with
2,560 human-annotated videos generated from 8 state-of-the-art T2V models.
Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic
evaluation metric, which can efficiently capture long-range dependencies and
temporal ordering while maintaining computational efficiency. Our DTG-based
metric demonstrates a strong correlation with human annotations. Through
systematic evaluation using SeqBench, we reveal critical limitations in current
T2V models: failure to maintain consistent object states across multi-action
sequences, physically implausible results in multi-object scenarios, and
difficulties in preserving realistic timing and ordering relationships between
sequential actions. SeqBench provides the first systematic framework for
evaluating narrative coherence in T2V generation and offers concrete insights
for improving sequential reasoning capabilities in future models. Please refer
to https://videobench.github.io/SeqBench.github.io/ for more details.

</details>


### [14] [SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion](https://arxiv.org/abs/2510.13044)
*Jungbin Cho,Minsu Kim,Jisoo Kim,Ce Zheng,Laszlo A. Jeni,Ming-Hsuan Yang,Youngjae Yu,Seonjoo Kim*

Main category: cs.CV

TL;DR: SceneAdapt框架通过两个阶段的适应性学习，将场景感知能力融入文本到动作生成模型中，解决了现有模型仅关注动作语义或场景感知的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动作生成中要么孤立地处理动作语义，要么孤立地处理场景感知，因为同时包含丰富的文本-动作覆盖和精确的场景交互的大规模数据集难以构建。

Method: 提出SceneAdapt框架，通过利用不相交的场景-动作和文本-动作数据集，并进行中间补全和场景感知中间补全两个适应阶段，将场景感知能力注入文本条件动作模型。核心思想是利用无需文本即可学习的动作中间补全作为代理任务，以桥接两个不同的数据集，从而将场景感知能力注入文本到动作模型。第一阶段引入关键帧层来调制用于中间补全的动作潜在变量，同时保持潜在流形。第二阶段添加场景条件层，通过交叉注意力自适应地查询本地上下文来注入场景几何。

Result: 实验结果表明，SceneAdapt能够有效地将场景感知能力注入文本到动作模型。此外，还对感知能力出现的机制进行了分析。

Conclusion: SceneAdapt框架成功地将场景感知能力注入到文本驱动的动作生成模型中，为解决现有方法的局限性提供了有效途径。

Abstract: Human motion is inherently diverse and semantically rich, while also shaped
by the surrounding scene. However, existing motion generation approaches
address either motion semantics or scene-awareness in isolation, since
constructing large-scale datasets with both rich text--motion coverage and
precise scene interactions is extremely challenging. In this work, we introduce
SceneAdapt, a framework that injects scene awareness into text-conditioned
motion models by leveraging disjoint scene--motion and text--motion datasets
through two adaptation stages: inbetweening and scene-aware inbetweening. The
key idea is to use motion inbetweening, learnable without text, as a proxy task
to bridge two distinct datasets and thereby inject scene-awareness to
text-to-motion models. In the first stage, we introduce keyframing layers that
modulate motion latents for inbetweening while preserving the latent manifold.
In the second stage, we add a scene-conditioning layer that injects scene
geometry by adaptively querying local context through cross-attention.
Experimental results show that SceneAdapt effectively injects scene awareness
into text-to-motion models, and we further analyze the mechanisms through which
this awareness emerges. Code and models will be released.

</details>


### [15] [One Dimensional CNN ECG Mamba for Multilabel Abnormality Classification in 12 Lead ECG](https://arxiv.org/abs/2510.13046)
*Huawei Jiang,Husna Mutahira,Gan Huang,Mannan Saeed Muhammad*

Main category: cs.CV

TL;DR: 本文提出了一种结合卷积神经网络和Mamba的混合模型（1D-CNN-ECG-Mamba），用于心电图分析，并在PhysioNet 2020和2021挑战赛中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统深度学习模型在处理长序列心电图信号时的性能限制，引入了状态空间模型作为一种高效的替代方案。

Method: 提出了一种名为1D-CNN-ECG-Mamba的混合框架，结合了一维卷积神经网络的特征提取能力和Mamba（一种选择性状态空间模型）的序列建模能力。该模型基于Vision Mamba的双向变体，以增强对心电图数据中时间依赖性的表征。

Result: 在PhysioNet 2020和2021挑战赛数据集上进行了广泛的实验，与现有方法相比，取得了优越的性能。具体来说，在十二导联心电图上，所提出的模型在AUPRC和AUROC得分上显著优于先前已发布算法的最佳结果。

Conclusion: 基于Mamba的架构在推进可靠的心电图分类方面展现出巨大潜力，能够支持早期诊断、个性化治疗，并提高远程医疗和资源受限医疗系统的可及性。

Abstract: Accurate detection of cardiac abnormalities from electrocardiogram recordings
is regarded as essential for clinical diagnostics and decision support.
Traditional deep learning models such as residual networks and transformer
architectures have been applied successfully to this task, but their
performance has been limited when long sequential signals are processed.
Recently, state space models have been introduced as an efficient alternative.
In this study, a hybrid framework named One Dimensional Convolutional Neural
Network Electrocardiogram Mamba is introduced, in which convolutional feature
extraction is combined with Mamba, a selective state space model designed for
effective sequence modeling. The model is built upon Vision Mamba, a
bidirectional variant through which the representation of temporal dependencies
in electrocardiogram data is enhanced. Comprehensive experiments on the
PhysioNet Computing in Cardiology Challenges of 2020 and 2021 were conducted,
and superior performance compared with existing methods was achieved.
Specifically, the proposed model achieved substantially higher AUPRC and AUROC
scores than those reported by the best previously published algorithms on
twelve lead electrocardiograms. These results demonstrate the potential of
Mamba-based architectures to advance reliable ECG classification. This
capability supports early diagnosis and personalized treatment, while enhancing
accessibility in telemedicine and resource-constrained healthcare systems.

</details>


### [16] [True Self-Supervised Novel View Synthesis is Transferable](https://arxiv.org/abs/2510.13063)
*Thomas W. Mitchel,Hyunwoo Ryu,Vincent Sitzmann*

Main category: cs.CV

TL;DR: XFactor是第一个能够实现真正新视角合成（NVS）的无几何自监督模型，其关键在于实现了姿态表征的迁移性，即来自一个视频序列的姿态表示可以用于重新渲染另一个视频中的相同相机轨迹。与以往模型不同，XFactor在没有3D归纳偏置或多视图几何概念的情况下，仅通过成对姿态估计和输入输出的增强方案，就能够解耦相机姿态和场景内容，并实现姿态的迁移性。


<details>
  <summary>Details</summary>
Motivation: 评估自监督新视角合成（NVS）模型是否真正具备新视角合成能力的关键在于其姿态表征的迁移性——即一个视频序列提取的姿态表示能否用于重新渲染另一个视频中的相同相机轨迹。现有研究发现，先前自监督NVS方法的预测姿态缺乏迁移性，导致在不同3D场景中相同的姿态会产生不同的相机轨迹。

Method: XFactor提出了一种新颖的、无几何的自监督模型，通过结合成对姿态估计与输入的简单增强方案，实现了姿态表征与场景内容的解耦，并促进了几何推理。该模型在没有显式姿态参数化（如SE(3)）的情况下，利用无约束的潜在姿态变量实现了姿态的迁移性。

Result: XFactor实现了姿态表征的迁移性，并且在没有3D归纳偏置或多视图几何概念的情况下，取得了显著成果。通过引入新的迁移性量化指标和进行大规模实验，证明了XFactor显著优于以往的无姿态NVS Transformer模型。此外，通过探测性实验表明，其潜在姿态与真实世界姿态高度相关。

Conclusion: XFactor是首个实现真正新视角合成（NVS）的无几何自监督模型，其核心优势在于实现了姿态表征的迁移性。该模型通过创新的方法，在没有依赖传统3D几何信息的情况下，有效地解耦了相机姿态和场景内容，并能够利用无约束的潜在姿态变量进行准确的新视角合成。XFactor在迁移性量化和性能上均优于现有方法，为无监督NVS领域带来了重要突破。

Abstract: In this paper, we identify that the key criterion for determining whether a
model is truly capable of novel view synthesis (NVS) is transferability:
Whether any pose representation extracted from one video sequence can be used
to re-render the same camera trajectory in another. We analyze prior work on
self-supervised NVS and find that their predicted poses do not transfer: The
same set of poses lead to different camera trajectories in different 3D scenes.
Here, we present XFactor, the first geometry-free self-supervised model capable
of true NVS. XFactor combines pair-wise pose estimation with a simple
augmentation scheme of the inputs and outputs that jointly enables
disentangling camera pose from scene content and facilitates geometric
reasoning. Remarkably, we show that XFactor achieves transferability with
unconstrained latent pose variables, without any 3D inductive biases or
concepts from multi-view geometry -- such as an explicit parameterization of
poses as elements of SE(3). We introduce a new metric to quantify
transferability, and through large-scale experiments, we demonstrate that
XFactor significantly outperforms prior pose-free NVS transformers, and show
that latent poses are highly correlated with real-world poses through probing
experiments.

</details>


### [17] [Direction-aware multi-scale gradient loss for infrared and visible image fusion](https://arxiv.org/abs/2510.13067)
*Kaixuan Yang,Wei Xiang,Zhenshuai Chen,Tong Jin,Yunpeng Liu*

Main category: cs.CV

TL;DR: 学习型图像融合方法通过结合结构相似性损失、强度重建损失和梯度幅度项进行训练，但梯度幅度会丢失方向信息，导致边缘保真度不佳。本文提出了一种方向感知、多尺度的梯度损失，单独监督水平和垂直分量并跨尺度保留其符号，从而在不改变模型架构或训练协议的情况下，在精细和粗糙分辨率下提供清晰的方向引导，促进更锐利、对齐更好的边缘和更丰富的纹理保留。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型图像融合方法通常使用结构相似性损失、强度重建损失和梯度幅度项进行训练。然而，梯度幅度会丢失方向信息，导致监督不明确和边缘保真度不佳。

Method: 提出一种方向感知、多尺度的梯度损失，该损失单独监督水平和垂直分量，并跨尺度保留其符号。这种轴向的、保持符号的目标在精细和粗糙分辨率下提供清晰的方向引导，从而在不改变模型架构或训练协议的情况下，促进更锐利、对齐更好的边缘和更丰富的纹理保留。

Result: 在开源模型和多个公共基准上进行的实验证明了该方法是有效的。

Conclusion: 所提出的方向感知、多尺度梯度损失能够有效解决现有方法在图像融合中边缘保真度不佳的问题，在不改变模型架构或训练协议的情况下，提升融合结果的边缘锐利度和纹理保真度。

Abstract: Infrared and visible image fusion aims to integrate complementary information
from co-registered source images to produce a single, informative result. Most
learning-based approaches train with a combination of structural similarity
loss, intensity reconstruction loss, and a gradient-magnitude term. However,
collapsing gradients to their magnitude removes directional information,
yielding ambiguous supervision and suboptimal edge fidelity. We introduce a
direction-aware, multi-scale gradient loss that supervises horizontal and
vertical components separately and preserves their sign across scales. This
axis-wise, sign-preserving objective provides clear directional guidance at
both fine and coarse resolutions, promoting sharper, better-aligned edges and
richer texture preservation without changing model architectures or training
protocols. Experiments on open-source model and multiple public benchmarks
demonstrate effectiveness of our approach.

</details>


### [18] [Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation](https://arxiv.org/abs/2510.13075)
*Hoda Kalabizadeh,Ludovica Griffanti,Pak-Hei Yeung,Ana I. L. Namburete,Nicola K. Dinsdale,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 本研究提出一种新颖的无监督域自适应框架，用于解决跨域MRI海马体分割中的域漂移问题，特别关注内容变化。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分割中，由于域漂移（包括图像风格和解剖特征的变化）而难以在不同数据集上部署。本研究旨在解决跨域海马体分割中的内容变化问题。

Method: 提出一种结合了z-normalisation的风格协调和双向可变形图像配准（DIR）策略的框架。DIR网络与分割和判别器网络联合训练，以关注感兴趣区域并生成解剖学上合理的变换，将源图像与目标域对齐。

Result: 在合成数据集（Morpho-MNIST）和三个MRI海马体数据集上进行了验证。与现有基线方法相比，本方法在所有实验中均表现更优。在从年轻健康人群到临床痴呆症患者的海马体分割任务中，本框架的Dice分数相对标准增强方法提高了15%，在内容偏移较大的情况下效果尤为显著。

Conclusion: 本研究提出的框架能够有效解决跨不同人群的海马体分割准确性问题，尤其是在存在显著内容偏移的情况下。

Abstract: Deep learning models for medical image segmentation often struggle when
deployed across different datasets due to domain shifts - variations in both
image appearance, known as style, and population-dependent anatomical
characteristics, referred to as content. This paper presents a novel
unsupervised domain adaptation framework that directly addresses domain shifts
encountered in cross-domain hippocampus segmentation from MRI, with specific
emphasis on content variations. Our approach combines efficient style
harmonisation through z-normalisation with a bidirectional deformable image
registration (DIR) strategy. The DIR network is jointly trained with
segmentation and discriminator networks to guide the registration with respect
to a region of interest and generate anatomically plausible transformations
that align source images to the target domain. We validate our approach through
comprehensive evaluations on both a synthetic dataset using Morpho-MNIST (for
controlled validation of core principles) and three MRI hippocampus datasets
representing populations with varying degrees of atrophy. Across all
experiments, our method outperforms existing baselines. For hippocampus
segmentation, when transferring from young, healthy populations to clinical
dementia patients, our framework achieves up to 15% relative improvement in
Dice score compared to standard augmentation methods, with the largest gains
observed in scenarios with substantial content shift. These results highlight
the efficacy of our approach for accurate hippocampus segmentation across
diverse populations.

</details>


### [19] [Counting Hallucinations in Diffusion Models](https://arxiv.org/abs/2510.13080)
*Shuai Fu,Jian Zhou,Qi Chen,Huang Jing,Huy Anh Nguyen,Xiaohan Liu,Zhixiong Zeng,Lin Ma,Quanshi Zhang,Qi Wu*

Main category: cs.CV

TL;DR: 扩散模型（DPM）在生成任务中表现出色，但仍会产生与现实知识冲突的幻觉样本，例如生成错误数量的物体。本文旨在量化 DPM 中的“计数幻觉”（生成错误数量的实例或结构化对象），并提出解决此问题的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 DPM 在生成任务中存在幻觉问题，即生成与现实知识不符的样本，例如生成错误数量的物体。然而，缺乏量化此类幻觉的方法，阻碍了对其的深入研究和改进。

Method: 本文构建了一个包含 ToyShape、SimObject 和 RealHand 数据集的 CountHalluSet，用于量化计数幻觉。在此基础上，作者提出了一种标准化的评估协议，并系统地检查了不同采样条件（如求解器类型、采样步数、初始噪声等）对计数幻觉的影响。此外，还分析了计数幻觉与 FID 等通用评估指标的相关性。

Result: 研究结果表明，FID 等常用评估指标无法有效捕捉计数幻觉。不同的采样条件对计数幻觉的程度有不同程度的影响。

Conclusion: 本文首次系统地量化了扩散模型中的计数幻觉问题，并提供了新的见解，为未来在事实约束下设计生成模型奠定了基础。

Abstract: Diffusion probabilistic models (DPMs) have demonstrated remarkable progress
in generative tasks, such as image and video synthesis. However, they still
often produce hallucinated samples (hallucinations) that conflict with
real-world knowledge, such as generating an implausible duplicate cup floating
beside another cup. Despite their prevalence, the lack of feasible
methodologies for systematically quantifying such hallucinations hinders
progress in addressing this challenge and obscures potential pathways for
designing next-generation generative models under factual constraints. In this
work, we bridge this gap by focusing on a specific form of hallucination, which
we term counting hallucination, referring to the generation of an incorrect
number of instances or structured objects, such as a hand image with six
fingers, despite such patterns being absent from the training data. To this
end, we construct a dataset suite CountHalluSet, with well-defined counting
criteria, comprising ToyShape, SimObject, and RealHand. Using these datasets,
we develop a standardized evaluation protocol for quantifying counting
hallucinations, and systematically examine how different sampling conditions in
DPMs, including solver type, ODE solver order, sampling steps, and initial
noise, affect counting hallucination levels. Furthermore, we analyze their
correlation with common evaluation metrics such as FID, revealing that this
widely used image quality metric fails to capture counting hallucinations
consistently. This work aims to take the first step toward systematically
quantifying hallucinations in diffusion models and offer new insights into the
investigation of hallucination phenomena in image generation.

</details>


### [20] [Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation](https://arxiv.org/abs/2510.13084)
*Yi Zuo,Zitao Wang,Lingling Li,Xu Liu,Fang Liu,Licheng Jiao*

Main category: cs.CV

TL;DR: Edit-Your-Interest是一种轻量级、文本驱动、零样本视频编辑方法，通过时空特征记忆和特征相似性传播来提高效率和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑方法计算开销大、内存消耗高，并且在视觉保真度方面存在不足，导致时间不一致和模糊、马赛克等伪影。

Method: 提出了一种名为Edit-Your-Interest的方法，包括时空特征记忆（SFM）来缓存先前帧的特征，特征最相似传播（FMP）来保持时间一致性，以及一个SFM更新算法来保持特征的相关性。此外，利用交叉注意力图提取实例掩码，并将其集成到扩散去噪过程中，以实现精确编辑并保持背景完整性。

Result: 实验证明，Edit-Your-Interest在效率和视觉保真度方面均优于最先进的方法。

Conclusion: Edit-Your-Interest在效率和视觉保真度方面均优于最先进的方法，验证了其有效性和实用性。

Abstract: Text-to-image (T2I) diffusion models have recently demonstrated significant
progress in video editing.
  However, existing video editing methods are severely limited by their high
computational overhead and memory consumption.
  Furthermore, these approaches often sacrifice visual fidelity, leading to
undesirable temporal inconsistencies and artifacts such as blurring and
pronounced mosaic-like patterns.
  We propose Edit-Your-Interest, a lightweight, text-driven, zero-shot video
editing method.
  Edit-Your-Interest introduces a spatio-temporal feature memory to cache
features from previous frames, significantly reducing computational overhead
compared to full-sequence spatio-temporal modeling approaches.
  Specifically, we first introduce a Spatio-Temporal Feature Memory bank (SFM),
which is designed to efficiently cache and retain the crucial image tokens
processed by spatial attention.
  Second, we propose the Feature Most-Similar Propagation (FMP) method. FMP
propagates the most relevant tokens from previous frames to subsequent ones,
preserving temporal consistency.
  Finally, we introduce an SFM update algorithm that continuously refreshes the
cached features, ensuring their long-term relevance and effectiveness
throughout the video sequence.
  Furthermore, we leverage cross-attention maps to automatically extract masks
for the instances of interest.
  These masks are seamlessly integrated into the diffusion denoising process,
enabling fine-grained control over target objects and allowing
Edit-Your-Interest to perform highly accurate edits while robustly preserving
the background integrity.
  Extensive experiments decisively demonstrate that the proposed
Edit-Your-Interest outperforms state-of-the-art methods in both efficiency and
visual fidelity, validating its superior effectiveness and practicality.

</details>


### [21] [EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception](https://arxiv.org/abs/2510.13105)
*Xijun Wang,Tanay Sharma,Achin Kulshrestha,Abhimitra Meka,Aveek Purohit,Dinesh Manocha*

Main category: cs.CV

TL;DR: 本项目提出了EgoSocial数据集和EgoSoD方法，以提高AI在AR/VR环境中理解和干预社交互动的能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI在理解以第一人称视角观察到的社交动态方面存在不足，导致其在作为AI助手时，无法准确判断干预时机，从而可能干扰用户并影响用户专注度。

Method: 构建了一个包含13,500个社交视频-问题对的大规模以第一人称视角为基础的数据集（EgoSocial），并分析了现有全模态语言模型（OLLMs）在识别社交线索方面的表现。在此基础上，提出了EgoSoD（EgoSocial Detection）端到端方法，该方法整合了多模态线索（如音频和视觉线索）到一个社交思维图中，动态地对参与者和互动进行建模，以预测干预时机和社交互动。

Result: 实验表明，现有OLLMs在识别干预时机方面仍有不足（例如Gemini 2.5 Pro仅为14.4%）。EgoSoD方法在干预时机方面将Phi-4的性能提高了45.6%，将Gemini 2.5 Pro的性能提高了9.9%；在社交互动整体性能方面，将Phi-4的性能提高了20.4%，将Gemini 2.5 Pro的性能提高了6.9%。

Conclusion: EgoSoD方法在识别社交互动和判断干预时机方面表现出显著优于现有模型，为在AR/VR环境中开发更具社会意识的AI助手提供了有效途径。数据集和代码将公开。

Abstract: As AR/VR technologies become integral to daily life, there's a growing need
for AI that understands human social dynamics from an egocentric perspective.
However, current LLMs often lack the social awareness to discern when to
intervene as AI assistant. This leads to constant, socially unaware responses
that may disrupt natural conversation and negatively impact user focus. To
address these limitations, we introduce EgoSocial, a large-scale egocentric
dataset with 13,500 social video-question pairs, specifically designed to
benchmark intervention in social interaction perception. We also present an
in-depth analysis of current omnimodal LLMs (OLLMs) to assess their
effectiveness in detecting diverse social contextual cues. Experiments show
that OLLMs still struggle to detect the intervention timing (14.4% for Gemini
2.5 Pro). We also propose EgoSoD (EgoSocial Detection), an end-to-end method
for robustly discerning social dynamics. Informed by our OLLM analysis, EgoSoD
integrates multimodal contextual cues (e.g., audio and visual cues) into a
social thinking graph, dynamically modeling participants and interactions. Our
method proactively detects intervention timing and social interactions,
precisely determining when to intervene. Our EgoSoD improves Phi-4 by 45.6% and
Gemini 2.5 Pro by 9.9% on Intervention Timing performance, and improves Phi-4
by 20.4% and Gemini 2.5 Pro by 6.9% on overall Social Interaction performance.
We will release the dataset and code soon.

</details>


### [22] [DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2510.13108)
*Jingyu Song,Zhenxin Li,Shiyi Lan,Xinglong Sun,Nadine Chang,Maying Shen,Joshua Chen,Katherine A. Skinner,Jose M. Alvarez*

Main category: cs.CV

TL;DR: DriveCritic是一个包含数据集和模型的框架，用于评估自动驾驶系统的规划器，旨在更好地符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶规划器评估指标（如EPDMS）在复杂场景下缺乏对上下文的感知能力，无法准确反映人类的判断。

Method: 提出DriveCritic框架，包括：1. DriveCritic数据集：包含关键场景和标注的人类偏好。2. DriveCritic模型：基于视觉-语言模型（VLM），通过两阶段监督和强化学习进行微调，能够结合视觉和符号上下文来判断轨迹对。

Result: DriveCritic在匹配人类偏好方面显著优于现有指标和基线，并表现出强大的上下文感知能力。

Conclusion: DriveCritic为评估自动驾驶系统提供了一个更可靠、更符合人类判断的基础。

Abstract: Benchmarking autonomous driving planners to align with human judgment remains
a critical challenge, as state-of-the-art metrics like the Extended Predictive
Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To
address this, we introduce DriveCritic, a novel framework featuring two key
contributions: the DriveCritic dataset, a curated collection of challenging
scenarios where context is critical for correct judgment and annotated with
pairwise human preferences, and the DriveCritic model, a Vision-Language Model
(VLM) based evaluator. Fine-tuned using a two-stage supervised and
reinforcement learning pipeline, the DriveCritic model learns to adjudicate
between trajectory pairs by integrating visual and symbolic context.
Experiments show DriveCritic significantly outperforms existing metrics and
baselines in matching human preferences and demonstrates strong context
awareness. Overall, our work provides a more reliable, human-aligned foundation
to evaluating autonomous driving systems.

</details>


### [23] [VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method](https://arxiv.org/abs/2510.13109)
*Zicong Zhou,Baihan Zhao,Andreas Mang,Guojun Liao*

Main category: cs.CV

TL;DR: VPreg是一种新的微分同胚图像配准方法，通过变分原理生成网格，确保配准准确性、空间变换质量和逆变换的准确性，并在脑部扫描配准实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提高微分同积图像配准的准确性，并控制配准变换的质量，确保空间变换的雅可比行列式为正，并提供准确的逆配准变换，这对于神经影像学工作流至关重要。

Method: VPreg的核心是一种称为“变分原理”（VP）的网格生成方法，用于构建具有规定雅可比行列式和旋度的无折叠网格。这些VP生成的网格保证了计算解剖学和形态学所必需的微分同胚空间变换，并提供比现有方法更准确的逆变换。

Result: 在对OASIS-1数据集的150次脑部扫描配准的性能分析中，VPreg在Dice分数、计算变换的规则性以及提供的逆映射的准确性和一致性方面优于最先进的方法。

Conclusion: VPreg通过变分原理生成的网格，实现了高质量的微分同胚图像配准，在准确性和逆变换性质方面均优于现有技术。

Abstract: This paper introduces VPreg, a novel diffeomorphic image registration method.
This work provides several improvements to our past work on mesh generation and
diffeomorphic image registration. VPreg aims to achieve excellent registration
accuracy while controlling the quality of the registration transformations. It
ensures a positive Jacobian determinant of the spatial transformation and
provides an accurate approximation of the inverse of the registration, a
crucial property for many neuroimaging workflows. Unlike conventional methods,
VPreg generates this inverse transformation within the group of diffeomorphisms
rather than operating on the image space. The core of VPreg is a grid
generation approach, referred to as \emph{Variational Principle} (VP), which
constructs non-folding grids with prescribed Jacobian determinant and curl.
These VP-generated grids guarantee diffeomorphic spatial transformations
essential for computational anatomy and morphometry, and provide a more
accurate inverse than existing methods. To assess the potential of the proposed
approach, we conduct a performance analysis for 150 registrations of brain
scans from the OASIS-1 dataset. Performance evaluation based on Dice scores for
35 regions of interest, along with an empirical analysis of the properties of
the computed spatial transformations, demonstrates that VPreg outperforms
state-of-the-art methods in terms of Dice scores, regularity properties of the
computed transformation, and accuracy and consistency of the provided inverse
map. We compare our results to ANTs-SyN, Freesurfer-Easyreg, and FSL-Fnirt.

</details>


### [24] [OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment](https://arxiv.org/abs/2510.13131)
*Rongjun Chen,Chengsi Yao,Jinchang Ren,Xianxian Zeng,Peixian Wang,Jun Yuan,Jiawen Li,Huimin Zhao,Xu Lu*

Main category: cs.CV

TL;DR: 本文提出了一种利用大型语言模型（LLM）开放语义知识来解决文本-图像对齐中信息熵不平衡问题的OS-HGAdapter方法，通过提示模板增强文本描述的丰富性，并使用超图适配器建立多边形连接，有效提升了跨模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决文本-图像对齐中由于信息熵差异导致的跨模态检索不平衡问题。

Method: 1.设计提示模板，利用LLM增强文本描述的丰富性，提高文本信息熵。2.使用超图适配器构建文本和图像的多边形连接，纠正匹配错误并降噪。

Result: 在Flickr30K和MS-COCO数据集上，OS-HGAdapter在文本到图像检索方面提升了16.8%，在图像到文本检索方面提升了40.1%，并在语义对齐任务上取得了新的最先进性能。

Conclusion: 提出的OS-HGAdapter方法能有效利用LLM的开放语义知识，解决文本-图像对齐中的信息熵不平衡问题，显著提升跨模态检索性能。

Abstract: Text-image alignment constitutes a foundational challenge in multimedia
content understanding, where effective modeling of cross-modal semantic
correspondences critically enhances retrieval system performance through joint
embedding space optimization. Given the inherent difference in information
entropy between texts and images, conventional approaches often show an
imbalance in the mutual retrieval of these two modalities. To address this
particular challenge, we propose to use the open semantic knowledge of Large
Language Model (LLM) to fill for the entropy gap and reproduce the alignment
ability of humans in these tasks. Our entropy-enhancing alignment is achieved
through a two-step process: 1) a new prompt template that does not rely on
explicit knowledge in the task domain is designed to use LLM to enhance the
polysemy description of the text modality. By analogy, the information entropy
of the text modality relative to the visual modality is increased; 2) A
hypergraph adapter is used to construct multilateral connections between the
text and image modalities, which can correct the positive and negative matching
errors for synonymous semantics in the same fixed embedding space, whilst
reducing the noise caused by open semantic entropy by mapping the reduced
dimensions back to the original dimensions. Comprehensive evaluations on the
Flickr30K and MS-COCO benchmarks validate the superiority of our Open Semantic
Hypergraph Adapter (OS-HGAdapter), showcasing 16.8\% (text-to-image) and 40.1\%
(image-to-text) cross-modal retrieval gains over existing methods while
establishing new state-of-the-art performance in semantic alignment tasks.

</details>


### [25] [Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN](https://arxiv.org/abs/2510.13137)
*Madhumati Pol,Anvay Anturkar,Anushka Khot,Ayush Andure,Aniruddha Ghosh,Anvit Magadum,Anvay Bahadur*

Main category: cs.CV

TL;DR: 3D CNNs achieve higher accuracy (92.4%) for ASL recognition than LSTMs (86.7%) but are less computationally efficient. LSTMs offer lower resource consumption. A hybrid model shows decent performance. Selecting the right architecture is key for practical applications, especially in edge computing where balancing accuracy and real-time needs is crucial.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the performance of 3D CNNs and LSTMs for real-time American Sign Language (ASL) recognition, comparing their accuracy, computational efficiency, and latency to provide benchmarks for developing assistive technologies and understanding the trade-offs in edge computing environments.

Method: The study evaluates 3D CNNs and LSTMs on a dataset of 1,200 ASL signs across 50 classes. Both architectures are compared under similar training conditions regarding accuracy, computational efficiency, and latency. A hybrid 3D CNNLSTM model is also considered.

Result: 3D CNNs achieved 92.4% recognition accuracy but required 3.2% more processing time per frame compared to LSTMs. LSTMs achieved 86.7% accuracy with significantly lower resource consumption. The hybrid model showed decent performance.

Conclusion: Context-dependent architecture selection is crucial for practical implementation of ASL recognition systems. There are trade-offs between recognition precision and real-time operational requirements, especially in edge computing environments, and this study provides benchmarks to inform these decisions.

Abstract: This study investigates the performance of 3D Convolutional Neural Networks
(3D CNNs) and Long Short-Term Memory (LSTM) networks for real-time American
Sign Language (ASL) recognition. Though 3D CNNs are good at spatiotemporal
feature extraction from video sequences, LSTMs are optimized for modeling
temporal dependencies in sequential data. We evaluate both architectures on a
dataset containing 1,200 ASL signs across 50 classes, comparing their accuracy,
computational efficiency, and latency under similar training conditions.
Experimental results demonstrate that 3D CNNs achieve 92.4% recognition
accuracy but require 3.2% more processing time per frame compared to LSTMs,
which maintain 86.7% accuracy with significantly lower resource consumption.
The hybrid 3D CNNLSTM model shows decent performance, which suggests that
context-dependent architecture selection is crucial for practical
implementation.This project provides professional benchmarks for developing
assistive technologies, highlighting trade-offs between recognition precision
and real-time operational requirements in edge computing environments.

</details>


### [26] [DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization](https://arxiv.org/abs/2510.13160)
*Meng Yang,Kecheng Chen,Wei Luo,Xianjie Chen,Yong Jia,Mingyue Wang,Fanqiang Lin*

Main category: cs.CV

TL;DR: 深度学习在瞬变电磁法(TEM)信号去噪中存在跨区域性能下降的问题。本文提出了一种名为DP-TTA的测试时域自适应方法，利用TEM信号固有的物理特性（如指数衰减和平滑性）作为先验知识，通过字典学习编码这些特性，并在测试阶段引导模型自适应调整参数，以提高在不同地理区域的去噪性能。实验结果表明，该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习去噪模型在跨区域应用时性能下降，因为它们未能充分考虑不同地理区域噪声特征的显著差异。

Method: 提出字典驱动先验正则化测试时域自适应(DP-TTA)方法。该方法利用TEM信号固有的物理特性（指数衰减、平滑性）作为先验知识，通过字典学习将其编码为先验。在测试阶段，该先验知识指导预训练模型通过最小化字典驱动一致性和信号一阶变化自监督损失，动态调整参数以适应新环境。

Result: DP-TTA方法在去噪性能上显著优于现有的TEM去噪方法和测试时域自适应方法。

Conclusion: DP-TTA方法能够有效利用TEM信号的内在物理特性作为先验知识，通过测试时域自适应显著提高模型在不同地理区域的去噪性能。

Abstract: Transient Electromagnetic (TEM) method is widely used in various geophysical
applications, providing valuable insights into subsurface properties. However,
time-domain TEM signals are often submerged in various types of noise. While
recent deep learning-based denoising models have shown strong performance,
these models are mostly trained on simulated or single real-world scenario
data, overlooking the significant differences in noise characteristics from
different geographical regions. Intuitively, models trained in one environment
often struggle to perform well in new settings due to differences in geological
conditions, equipment, and external interference, leading to reduced denoising
performance. To this end, we propose the Dictionary-driven Prior Regularization
Test-time Adaptation (DP-TTA). Our key insight is that TEM signals possess
intrinsic physical characteristics, such as exponential decay and smoothness,
which remain consistent across different regions regardless of external
conditions. These intrinsic characteristics serve as ideal prior knowledge for
guiding the TTA strategy, which helps the pre-trained model dynamically adjust
parameters by utilizing self-supervised losses, improving denoising performance
in new scenarios. To implement this, we customized a network, named DTEMDNet.
Specifically, we first use dictionary learning to encode these intrinsic
characteristics as a dictionary-driven prior, which is integrated into the
model during training. At the testing stage, this prior guides the model to
adapt dynamically to new environments by minimizing self-supervised losses
derived from the dictionary-driven consistency and the signal one-order
variation. Extensive experimental results demonstrate that the proposed method
achieves much better performance than existing TEM denoising methods and TTA
methods.

</details>


### [27] [STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control](https://arxiv.org/abs/2510.13186)
*Zhen Li,Xibin Jin,Guoliang Li,Shuai Wang,Miaowen Wen,Huseyin Arslan,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.CV

TL;DR: Edge Gaussian Splatting (EGS) 是一种用于场景重建的分布式学习范式，但现有方法不适用于其特定优化目标。本文提出了 STT-GS 策略，通过采样、评估和优化通信资源来解决这一问题，并使用 PAMM 算法求解。


<details>
  <summary>Details</summary>
Motivation: 现有边缘资源管理方法无法满足 EGS 最大化高斯泼溅（GS）质量的要求，需要一种专门针对 GS 优化的方法。

Method: 提出了一种新颖的面向 GS 的目标函数，并设计了 STT-GS 策略，包括特征域聚类（FDC）进行数据采样和试点传输时间最小化（PTTM）以减少开销。此外，还提出了联合客户端选择和功率控制（JCSPC）框架，并采用惩罚交替主化最小化（PAMM）算法求解。

Result: 实验表明，该方法在低采样率（例如 10%）下可以准确预测面向 GS 的目标，并在视图贡献和通信成本之间取得了良好的折衷，显著优于现有基准。

Conclusion: 本文提出的 STT-GS 策略和 JCSPC 框架能够有效地解决 EGS 中的通信和优化问题，实现了高质量的场景重建，并能在通信资源有限的情况下取得良好的性能。

Abstract: Edge Gaussian splatting (EGS), which aggregates data from distributed clients
and trains a global GS model at the edge server, is an emerging paradigm for
scene reconstruction. Unlike traditional edge resource management methods that
emphasize communication throughput or general-purpose learning performance, EGS
explicitly aims to maximize the GS qualities, rendering existing approaches
inapplicable. To address this problem, this paper formulates a novel
GS-oriented objective function that distinguishes the heterogeneous view
contributions of different clients. However, evaluating this function in turn
requires clients' images, leading to a causality dilemma. To this end, this
paper further proposes a sample-then-transmit EGS (or STT-GS for short)
strategy, which first samples a subset of images as pilot data from each client
for loss prediction. Based on the first-stage evaluation, communication
resources are then prioritized towards more valuable clients. To achieve
efficient sampling, a feature-domain clustering (FDC) scheme is proposed to
select the most representative data and pilot transmission time minimization
(PTTM) is adopted to reduce the pilot overhead.Subsequently, we develop a joint
client selection and power control (JCSPC) framework to maximize the
GS-oriented function under communication resource constraints. Despite the
nonconvexity of the problem, we propose a low-complexity efficient solution
based on the penalty alternating majorization minimization (PAMM) algorithm.
Experiments unveil that the proposed scheme significantly outperforms existing
benchmarks on real-world datasets. It is found that the GS-oriented objective
can be accurately predicted with low sampling ratios (e.g.,10%), and our method
achieves an excellent tradeoff between view contributions and communication
costs.

</details>


### [28] [Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion](https://arxiv.org/abs/2510.13198)
*Rongtao Xu,Jinzhou Lin,Jialei Zhou,Jiahua Dong,Changwei Wang,Ruisheng Wang,Li Guo,Shibiao Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: CIGOcc是一个基于多层次表示融合的两阶段占用预测框架，通过融合分割、图形和深度特征，并引入SAM知识蒸馏，在SemanticKITTI基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过结构修改来提高性能，但性能有限，很少从表示融合的角度探索，导致2D图像中丰富的多样的特征未被充分利用。

Method: 提出CIGOcc框架，提取分割、图形和深度特征，并使用可变形多层次融合机制融合这些特征。此外，还引入了从SAM知识蒸馏的知识来进一步提高预测精度。

Result: 在SemanticKITTI基准上实现了最先进的性能。

Conclusion: CIGOcc通过多层次表示融合和知识蒸馏，在不增加训练成本的情况下，提高了3D感知中相机占用的预测精度，达到了最先进的性能。

Abstract: Camera-based occupancy prediction is a mainstream approach for 3D perception
in autonomous driving, aiming to infer complete 3D scene geometry and semantics
from 2D images. Almost existing methods focus on improving performance through
structural modifications, such as lightweight backbones and complex cascaded
frameworks, with good yet limited performance. Few studies explore from the
perspective of representation fusion, leaving the rich diversity of features in
2D images underutilized. Motivated by this, we propose \textbf{CIGOcc, a
two-stage occupancy prediction framework based on multi-level representation
fusion. \textbf{CIGOcc extracts segmentation, graphics, and depth features from
an input image and introduces a deformable multi-level fusion mechanism to fuse
these three multi-level features. Additionally, CIGOcc incorporates knowledge
distilled from SAM to further enhance prediction accuracy. Without increasing
training costs, CIGOcc achieves state-of-the-art performance on the
SemanticKITTI benchmark. The code is provided in the supplementary material and
will be released https://github.com/VitaLemonTea1/CIGOcc

</details>


### [29] [Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences](https://arxiv.org/abs/2510.13201)
*Jing Yang,Qiyao Wei,Jiaxin Pei*

Main category: cs.CV

TL;DR: AI 顶会的快速增长给本已脆弱的同行评审系统带来了压力，导致审稿人工作量过大、专业知识不匹配、评估标准不一致、审稿肤浅或模板化，以及在压缩的时间范围内责任有限。为了应对这种情况，会议组织者推出了新的政策和干预措施来维持评审标准。然而，这些临时的变化常常会引起关于评审过程的更多担忧和困惑，使得论文最终如何被接受——以及实践如何在多年内演变——在很大程度上变得不透明。我们提出了 Paper Copilot，这是一个系统，它创建了一个广泛的计算机科学会议的同行评审持久数字档案，一个开放的数据集，使研究人员能够大规模地研究同行评审，以及对 ICLR 评审进行多年的大规模实证分析。通过发布基础设施和数据集，Paper Copilot 支持对同行评审演变的可重复研究。我们希望这些资源能帮助社区跟踪变化，诊断故障模式，并为建立一个更健壮、更透明、更可靠的同行评审系统提供循证的改进建议。


<details>
  <summary>Details</summary>
Motivation: AI 顶会的快速增长给同行评审系统带来了压力，导致审稿人工作量过大、专业知识不匹配、评估标准不一致、审稿肤浅或模板化，以及责任有限。临时的政策和干预措施常常引起更多担忧和混淆，使得论文的接受过程以及实践如何随时间演变变得不透明。

Method: 提出 Paper Copilot 系统，该系统创建了广泛的计算机科学会议同行评审的持久数字档案，并发布了一个开放的数据集，以便大规模研究同行评审。对 ICLR 评审进行了多年的大规模实证分析。

Result: 发布了 Paper Copilot 基础设施和数据集，支持对同行评审演变的可重复研究。

Conclusion: Paper Copilot 旨在通过提供跟踪变化、诊断故障模式的资源，并为建立更健壮、更透明、更可靠的同行评审系统提供循证的改进建议，来帮助社区改进同行评审系统。

Abstract: The rapid growth of AI conferences is straining an already fragile
peer-review system, leading to heavy reviewer workloads, expertise mismatches,
inconsistent evaluation standards, superficial or templated reviews, and
limited accountability under compressed timelines. In response, conference
organizers have introduced new policies and interventions to preserve review
standards. Yet these ad-hoc changes often create further concerns and confusion
about the review process, leaving how papers are ultimately accepted - and how
practices evolve across years - largely opaque. We present Paper Copilot, a
system that creates durable digital archives of peer reviews across a wide
range of computer-science venues, an open dataset that enables researchers to
study peer review at scale, and a large-scale empirical analysis of ICLR
reviews spanning multiple years. By releasing both the infrastructure and the
dataset, Paper Copilot supports reproducible research on the evolution of peer
review. We hope these resources help the community track changes, diagnose
failure modes, and inform evidence-based improvements toward a more robust,
transparent, and reliable peer-review system.

</details>


### [30] [MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation](https://arxiv.org/abs/2510.13208)
*Lianlian Liu,YongKang He,Zhaojie Chu,Xiaofen Xing,Xiangmin Xu*

Main category: cs.CV

TL;DR: MimicParts框架通过区分身体部位来生成更真实的3D人类运动，能够根据语音的节奏和情绪动态调整


<details>
  <summary>Details</summary>
Motivation: 现有方法在从语音生成风格化3D人类运动时存在挑战，它们可能过度简化风格多样性，忽略身体不同部位（如上身和下身）的运动风格差异，并且未能动态适应语音节奏和情绪的变化，导致生成的运动不够真实。

Method: 提出MimicParts框架，采用部分感知风格注入和部分感知去噪网络。该框架将身体划分为不同区域以编码局部运动风格，并使用部分感知注意力块，使节奏和情绪线索能够精确地指导身体的每个区域，从而实现动态风格适应。

Result: 实验结果表明，MimicParts框架在生成3D人类运动序列方面优于现有方法，生成的运动更自然、更具表现力。

Conclusion: MimicParts框架通过其部分感知的处理方式，能够更准确地捕捉和生成风格化、动态适应语音变化的3D人类运动，显著提高了运动的真实性和表现力。

Abstract: Generating stylized 3D human motion from speech signals presents substantial
challenges, primarily due to the intricate and fine-grained relationships among
speech signals, individual styles, and the corresponding body movements.
Current style encoding approaches either oversimplify stylistic diversity or
ignore regional motion style differences (e.g., upper vs. lower body), limiting
motion realism. Additionally, motion style should dynamically adapt to changes
in speech rhythm and emotion, but existing methods often overlook this. To
address these issues, we propose MimicParts, a novel framework designed to
enhance stylized motion generation based on part-aware style injection and
part-aware denoising network. It divides the body into different regions to
encode localized motion styles, enabling the model to capture fine-grained
regional differences. Furthermore, our part-aware attention block allows rhythm
and emotion cues to guide each body region precisely, ensuring that the
generated motion aligns with variations in speech rhythm and emotional state.
Experimental results show that our method outperforming existing methods
showcasing naturalness and expressive 3D human motion sequences.

</details>


### [31] [Prompt-based Adaptation in Large-scale Vision Models: A Survey](https://arxiv.org/abs/2510.13219)
*Xi Xiao,Yunbei Zhang,Lin Zhao,Yiyang Liu,Xiaoying Liao,Zheda Mai,Xingjian Li,Xiao Wang,Hao Xu,Jihun Hamm,Xue Lin,Min Xu,Qifan Wang,Tianyang Wang,Cheng Han*

Main category: cs.CV

TL;DR: 视觉提示（VP）和视觉提示调优（VPT）是微调大型视觉模型的新兴轻量级替代方案，但两者概念界限模糊。本篇综述首次系统性地区分了VP和VPT，提出了一个统一的框架“基于提示的适应”（PA），并将现有方法分类为可学习、生成式和非可学习提示，并按像素级和令牌级进行组织。该综述还探讨了PA在医学影像、3D点云、视觉-语言任务、测试时适应和可信AI等领域的应用，并总结了基准测试、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 视觉提示（VP）和视觉提示调优（VPT）作为微调大型视觉模型的轻量级替代方案，在研究中常被混淆使用，缺乏系统性的区分。因此，有必要重新审视VP和VPT的设计，并在统一框架下进行概念化，以厘清它们之间的区别及其应用。

Method: 本研究首先从基本原理出发，重新审视了视觉提示（VP）和视觉提示调优（VPT）的设计。然后，将它们概念化在一个统一的框架“基于提示的适应”（PA）下。接着，提出了一个分类法，将现有方法分为可学习、生成式和非可学习提示，并根据注入的粒度（像素级和令牌级）进行组织。此外，还考察了PA在不同领域的集成应用，并总结了当前的基准测试、挑战和未来方向。

Result: 本研究提出了一个名为“基于提示的适应”（PA）的统一框架，用于概念化视觉提示（VP）和视觉提示调优（VPT）。该框架将现有方法分为三类：可学习提示、生成式提示和非可学习提示，并根据注入粒度（像素级和令牌级）进一步组织。该综述还广泛探讨了PA在医学影像、3D点云、视觉-语言任务、测试时适应和可信AI等领域的应用，并提供了对当前基准测试、挑战和未来方向的总结。

Conclusion: 本综述首次全面、系统地梳理了基于提示的适应（PA）方法，厘清了视觉提示（VP）和视觉提示调优（VPT）的概念界限及其在不同领域的应用。该研究旨在为研究人员和实践者提供一个清晰的路线图，以理解和探索PA研究的演变格局。

Abstract: In computer vision, Visual Prompting (VP) and Visual Prompt Tuning (VPT) have
recently emerged as lightweight and effective alternatives to full fine-tuning
for adapting large-scale vision models within the ``pretrain-then-finetune''
paradigm. However, despite rapid progress, their conceptual boundaries remain
blurred, as VP and VPT are frequently used interchangeably in current research,
reflecting a lack of systematic distinction between these techniques and their
respective applications. In this survey, we revisit the designs of VP and VPT
from first principles, and conceptualize them within a unified framework termed
Prompt-based Adaptation (PA). We provide a taxonomy that categorizes existing
methods into learnable, generative, and non-learnable prompts, and further
organizes them by injection granularity -- pixel-level and token-level. Beyond
the core methodologies, we examine PA's integrations across diverse domains,
including medical imaging, 3D point clouds, and vision-language tasks, as well
as its role in test-time adaptation and trustworthy AI. We also summarize
current benchmarks and identify key challenges and future directions. To the
best of our knowledge, we are the first comprehensive survey dedicated to PA's
methodologies and applications in light of their distinct characteristics. Our
survey aims to provide a clear roadmap for researchers and practitioners in all
area to understand and explore the evolving landscape of PA-related research.

</details>


### [32] [Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects](https://arxiv.org/abs/2510.13226)
*Hang-Cheng Dong,Yibo Jiao,Fupeng Wei,Guodong Liu,Dong Ye,Bingguo Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种面向工业表面缺陷检测的样本中心多任务学习框架和评估套件，以解决传统像素中心方法在处理样本级质量控制时遇到的挑战，如类别不平衡、缺陷稀疏和低对比度等问题，从而提高检测的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 工业表面缺陷检测需要同时判断样本是否含有缺陷并精确定位缺陷位置。然而，实际生产线中普遍存在前景背景类别极度不平衡、缺陷稀疏且尺度分布长尾、低对比度等问题。这导致基于像素的训练和评估容易被大片同质区域主导，难以让模型关注到尺寸小或对比度低的缺陷，成为实际部署的主要瓶颈。

Method: 提出了一种样本中心多任务学习框架，该框架基于共享编码器架构，联合学习样本级别的缺陷分类和像素级别的掩码定位。通过样本级别的监督来调整特征分布，并在梯度层面持续提升对小尺寸和低对比度缺陷的召回率。同时，分割分支保留了边界和形状细节，以增强每个样本的决策稳定性并减少漏检。

Result: 实验结果表明，所提出的方法在两个基准数据集上显著提高了样本级别决策的可靠性和缺陷定位的完整性。此外，新的评估指标Seg_mIoU和Seg_Recall能够消除传统mIoU因空样本或真阴性样本导致的偏差，并将定位质量与样本级别的决策紧密联系起来。

Conclusion: 所提出的样本中心多任务学习框架通过联合样本级分类和像素级定位，并采用新的评估指标，有效解决了工业表面缺陷检测中的样本级决策不稳定性问题，尤其是在处理稀疏或细长缺陷时，相比于现有模型能取得更稳定、更准确的结果。

Abstract: Industrial surface defect inspection for sample-wise quality control (QC)
must simultaneously decide whether a given sample contains defects and localize
those defects spatially. In real production lines, extreme
foreground-background imbalance, defect sparsity with a long-tailed scale
distribution, and low contrast are common. As a result, pixel-centric training
and evaluation are easily dominated by large homogeneous regions, making it
difficult to drive models to attend to small or low-contrast defects-one of the
main bottlenecks for deployment. Empirically, existing models achieve strong
pixel-overlap metrics (e.g., mIoU) but exhibit insufficient stability at the
sample level, especially for sparse or slender defects. The root cause is a
mismatch between the optimization objective and the granularity of QC
decisions. To address this, we propose a sample-centric multi-task learning
framework and evaluation suite. Built on a shared-encoder architecture, the
method jointly learns sample-level defect classification and pixel-level mask
localization. Sample-level supervision modulates the feature distribution and,
at the gradient level, continually boosts recall for small and low-contrast
defects, while the segmentation branch preserves boundary and shape details to
enhance per-sample decision stability and reduce misses. For evaluation, we
propose decision-linked metrics, Seg_mIoU and Seg_Recall, which remove the bias
of classical mIoU caused by empty or true-negative samples and tightly couple
localization quality with sample-level decisions. Experiments on two benchmark
datasets demonstrate that our approach substantially improves the reliability
of sample-level decisions and the completeness of defect localization.

</details>


### [33] [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](https://arxiv.org/abs/2510.13232)
*Inha Kang,Youngsun Lim,Seonho Lee,Jiho Choi,Junsuk Choe,Hyunjung Shim*

Main category: cs.CV

TL;DR: VLMs在处理否定语时存在“肯定偏差”问题，尤其是在描述性目标检测（DOD）任务中。本研究提出了CoVAND数据集和NegToMe模块来解决此问题。NegToMe通过将否定词与属性合并为连贯的语义短语，解决了否定线索在分词过程中丢失的结构性问题，并结合LoRA进行参数高效微调，显著提高了在否定语基准测试上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在理解否定语时存在严重缺陷（肯定偏差），这在描述性目标检测（DOD）任务中尤为明显。

Method: 提出CoVAND数据集，该数据集通过系统性的思维链（CoT）和视觉问答（VQA）方法构建，用于生成高质量、实例匹配的否定语数据。提出NegToMe模块，这是一个轻量级的文本标记合并模块，通过将否定词与其属性合并为连贯的语义短语，从根本上解决分词过程中否定线索丢失的问题，从而在输入层面保持正确的极性。并将NegToMe与参数高效的LoRA微调方法相结合。

Result: 该方法在具有挑战性的否定语基准测试上显著提高了性能，降低了误报率，在OVDEval上的NMS-AP提升高达+10.8点，并证明了其对现有最先进（SoTA）VLMs的泛化能力。

Conclusion: 该研究通过引入CoVAND数据集和NegToMe模块，并结合LoRA微调，为解决VLMs的否定语理解问题迈出了重要一步，为实际检测应用提供了更鲁棒的否定语理解能力。

Abstract: State-of-the-art vision-language models (VLMs) suffer from a critical failure
in understanding negation, often referred to as affirmative bias. This
limitation is particularly severe in described object detection (DOD) tasks. To
address this, we propose two primary contributions: (1) a new dataset pipeline
and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a
dataset constructed with a systematic chain-of-thought (CoT) and VQA-based
pipeline to generate high-quality, instance-grounded negation data. Second, we
propose NegToMe, a novel text token merging module that directly tackles the
architectural cause of affirmative bias. NegToMe fundamentally addresses the
structural loss of negation cues in tokenization, grouping them with attributes
into coherent semantic phrases. It maintains correct polarity at the input
level, enabling robust negation understanding even with limited data. For
instance, to prevent a model from treating the fragmented tokens "not" and
"girl" as simply "girl", NegToMe binds them into a single token whose meaning
is correctly distinguished from that of "girl" alone. This module is integrated
with a parameter-efficient and strategic LoRA fine-tuning approach. Our method
significantly improves performance on challenging negation benchmarks with a
lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval
and demonstrating generalization to SoTA VLMs. This work marks a crucial step
forward in addressing negation understanding for real-world detection
applications.

</details>


### [34] [UniVector: Unified Vector Extraction via Instance-Geometry Interaction](https://arxiv.org/abs/2510.13234)
*Yinglong Yan,Jun Yue,Shaobo Xia,Hanmeng Sun,Tianxu Ying,Chengcheng Wu,Sifan Lan,Min He,Pedram Ghamisi,Leyuan Fang*

Main category: cs.CV

TL;DR: UniVector是一个统一的向量提取框架，能够从栅格图像中提取多种向量类型（如多边形、折线、线段），通过实例-几何交互来捕捉复杂结构，并在现有数据集和新引入的多向量数据集上都达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有向量提取方法通常只针对单一向量类型，需要不同的模型来处理不同结构，这是因为它们独立处理实例属性（类别、结构）和几何属性（点坐标、连接），限制了对复杂结构的捕捉能力。受人脑视觉感知中语义和空间交互的启发，需要一个能够同时处理多种向量类型的统一框架。

Method: 提出UniVector统一向量提取框架，该框架利用实例-几何交互来提取多种向量类型。UniVector将向量编码为包含实例级别和几何级别信息的结构化查询，并通过一个交互模块迭代更新这些查询，以实现跨级别上下文交换。此外，还引入了一个动态形状约束来优化全局结构和关键点。

Result: UniVector在单结构和多结构向量提取任务上均设定了新的最先进水平。在一系列实验中，该框架表现出色，证明了其有效性和优越性。

Conclusion: UniVector是一个新颖的统一向量提取框架，通过实例-几何交互有效解决了现有方法在处理多种向量类型时的局限性，并在多个基准测试中取得了最先进的成果，展示了其在向量提取领域的潜力。

Abstract: Vector extraction retrieves structured vector geometry from raster images,
offering high-fidelity representation and broad applicability. Existing
methods, however, are usually tailored to a single vector type (e.g., polygons,
polylines, line segments), requiring separate models for different structures.
This stems from treating instance attributes (category, structure) and
geometric attributes (point coordinates, connections) independently, limiting
the ability to capture complex structures. Inspired by the human brain's
simultaneous use of semantic and spatial interactions in visual perception, we
propose UniVector, a unified VE framework that leverages instance-geometry
interaction to extract multiple vector types within a single model. UniVector
encodes vectors as structured queries containing both instance- and
geometry-level information, and iteratively updates them through an interaction
module for cross-level context exchange. A dynamic shape constraint further
refines global structures and key points. To benchmark multi-structure
scenarios, we introduce the Multi-Vector dataset with diverse polygons,
polylines, and line segments. Experiments show UniVector sets a new state of
the art on both single- and multi-structure VE tasks. Code and dataset will be
released at https://github.com/yyyyll0ss/UniVector.

</details>


### [35] [EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking](https://arxiv.org/abs/2510.13235)
*Yukuan Zhang,Jiarui Zhao,Shangqing Nie,Jin Kuang,Shengsheng Wang*

Main category: cs.CV

TL;DR: EPIPTrack框架通过显式和隐式提示增强多模态语义信息，以动态建模和对齐目标，在MOT17、MOT20和DanceTrack数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有目标跟踪方法依赖于缺乏实时适应性和易产生幻觉的静态文本描述，需要更具适应性的方法。

Method: 提出EPIPTrack框架，利用显式提示将运动信息转化为文本，隐式提示构建个体化知识表示。通过CLIP文本编码器动态调整提示，并使用判别性特征增强器来提升视觉和跨模态表示。

Result: 在MOT17、MOT20和DanceTrack数据集上的实验表明，EPIPTrack在各种场景下均优于现有跟踪器，表现出强大的适应性和卓越的性能。

Conclusion: EPIPTrack通过动态建模和语义对齐，有效解决了现有方法在目标跟踪中的局限性，并在多个基准测试中取得了最先进的性能。

Abstract: Multimodal semantic cues, such as textual descriptions, have shown strong
potential in enhancing target perception for tracking. However, existing
methods rely on static textual descriptions from large language models, which
lack adaptability to real-time target state changes and prone to
hallucinations. To address these challenges, we propose a unified multimodal
vision-language tracking framework, named EPIPTrack, which leverages explicit
and implicit prompts for dynamic target modeling and semantic alignment.
Specifically, explicit prompts transform spatial motion information into
natural language descriptions to provide spatiotemporal guidance. Implicit
prompts combine pseudo-words with learnable descriptors to construct
individualized knowledge representations capturing appearance attributes. Both
prompts undergo dynamic adjustment via the CLIP text encoder to respond to
changes in target state. Furthermore, we design a Discriminative Feature
Augmentor to enhance visual and cross-modal representations. Extensive
experiments on MOT17, MOT20, and DanceTrack demonstrate that EPIPTrack
outperforms existing trackers in diverse scenarios, exhibiting robust
adaptability and superior performance.

</details>


### [36] [Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](https://arxiv.org/abs/2510.13237)
*Haochuan Xu,Yun Sing Koh,Shuhuai Huang,Zirun Zhou,Di Wang,Jun Sakuma,Jingfeng Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为EDPA的视觉-语言-动作（VLA）模型对抗性补丁攻击方法，该方法通过破坏视觉和文本的潜在表征之间的语义对齐来使VLA模型产生错误的动作，并提出了一种通过对抗性微调视觉编码器来防御此攻击的方法，实验证明该方法能有效提高VLA模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作（VLA）模型在机器人学习领域取得了显著进展，但其对抗性鲁棒性仍未得到充分研究。

Method: 提出了一种名为EDPA（Embedding Disruption Patch Attack）的模型无关的对抗性补丁攻击方法，该方法通过（i）破坏视觉和文本潜在表征之间的语义对齐，以及（ii）最大化对抗性样本与干净样本潜在表征之间的差异来生成补丁。同时，提出了一种对抗性微调视觉编码器的防御策略，使编码器能为干净和受扰动的输入生成相似的表征。

Result: EDPA显著增加了先进VLA模型在LIBERO机器人仿真基准上的任务失败率，而提出的防御方法有效缓解了这种性能下降。

Conclusion: EDPA是一种有效的VLA模型对抗性攻击方法，而对抗性微调是一种有效的防御策略，可以提高VLA模型的鲁棒性。

Abstract: Vision-Language-Action (VLA) models have achieved revolutionary progress in
robot learning, enabling robots to execute complex physical robot tasks from
natural language instructions. Despite this progress, their adversarial
robustness remains underexplored. In this work, we propose both adversarial
patch attack and corresponding defense strategies for VLA models. We first
introduce the Embedding Disruption Patch Attack (EDPA), a model-agnostic
adversarial attack that generates patches directly placeable within the
camera's view. In comparison to prior methods, EDPA can be readily applied to
different VLA models without requiring prior knowledge of the model
architecture, or the controlled robotic manipulator. EDPA constructs these
patches by (i) disrupting the semantic alignment between visual and textual
latent representations, and (ii) maximizing the discrepancy of latent
representations between adversarial and corresponding clean visual inputs.
Through the optimization of these objectives, EDPA distorts the VLA's
interpretation of visual information, causing the model to repeatedly generate
incorrect actions and ultimately result in failure to complete the given
robotic task. To counter this, we propose an adversarial fine-tuning scheme for
the visual encoder, in which the encoder is optimized to produce similar latent
representations for both clean and adversarially perturbed visual inputs.
Extensive evaluations on the widely recognized LIBERO robotic simulation
benchmark demonstrate that EDPA substantially increases the task failure rate
of cutting-edge VLA models, while our proposed defense effectively mitigates
this degradation. The codebase is accessible via the homepage at
https://edpa-attack.github.io/.

</details>


### [37] [FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding](https://arxiv.org/abs/2510.13243)
*Francesco Barbato,Matteo Caligiuri,Pietro Zanuttigh*

Main category: cs.CV

TL;DR: FlyAwareV2是一个新的多模态数据集，包含真实和合成的UAV图像，用于城市场景理解。它提供了RGB、深度和语义标签，并包含了对各种环境条件（如不同天气和白天）的覆盖。该数据集还包括用于真实样本的深度图、RGB和多模态语义分割的基准测试，以及对合成到真实域自适应的研究。


<details>
  <summary>Details</summary>
Motivation: 现实世界UAV数据的收集和标注具有挑战性且成本高昂，限制了城市环境中UAV计算机视觉算法的发展。FlyAwareV2旨在通过提供一个大规模、多模态的数据集来解决这一限制。

Method: FlyAwareV2通过结合真实和合成的UAV图像来构建。它包含了RGB、深度和语义标签，适用于各种环境条件。真实样本的深度图是通过最先进的单目深度估计计算得出的。此外，该数据集还提供了用于评估标准架构上的RGB和多模态语义分割的基准测试，并进行了合成到真实域自适应的研究。

Result: FlyAwareV2包含多模态数据（RGB、深度、语义标签），涵盖不同的天气和白天条件。它还为真实样本提供了深度图，并为RGB和多模态语义分割提供了基准。此外，还进行了关于合成到真实域适应性的研究，以评估在合成数据上训练的模型的泛化能力。

Conclusion: FlyAwareV2数据集为UAV的3D城市场景理解研究提供了一个宝贵的资源，其丰富的标注和环境多样性有助于推动该领域的发展。

Abstract: The development of computer vision algorithms for Unmanned Aerial Vehicle
(UAV) applications in urban environments heavily relies on the availability of
large-scale datasets with accurate annotations. However, collecting and
annotating real-world UAV data is extremely challenging and costly. To address
this limitation, we present FlyAwareV2, a novel multimodal dataset encompassing
both real and synthetic UAV imagery tailored for urban scene understanding
tasks. Building upon the recently introduced SynDrone and FlyAware datasets,
FlyAwareV2 introduces several new key contributions: 1) Multimodal data (RGB,
depth, semantic labels) across diverse environmental conditions including
varying weather and daytime; 2) Depth maps for real samples computed via
state-of-the-art monocular depth estimation; 3) Benchmarks for RGB and
multimodal semantic segmentation on standard architectures; 4) Studies on
synthetic-to-real domain adaptation to assess the generalization capabilities
of models trained on the synthetic data. With its rich set of annotations and
environmental diversity, FlyAwareV2 provides a valuable resource for research
on UAV-based 3D urban scene understanding.

</details>


### [38] [CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation](https://arxiv.org/abs/2510.13245)
*Li Liang,Bo Miao,Xinyu Wang,Naveed Akhtar,Jordan Vice,Ajmal Mian*

Main category: cs.CV

TL;DR: 本论文提出了SketchSem3D数据集和CymbaDiff模型，用于从草图生成3D户外语义场景。


<details>
  <summary>Details</summary>
Motivation: 现有的3D户外语义场景生成受限于公开数据集的缺乏。本研究旨在创建一个大规模的基准数据集并提出一种新的生成模型来解决这个问题。

Method: 提出了SketchSem3D数据集，包含草图、卫星图像及其伪标签，并引入了CymbaDiff模型，该模型通过引入结构化空间排序、捕获圆柱连续性和垂直层次结构来增强生成场景的空间相干性。

Result: 在SketchSem3D数据集上的实验表明，CymbaDiff在语义一致性、空间真实感和跨数据集泛化能力方面表现优越。

Conclusion: SketchSem3D数据集和CymbaDiff模型为3D户外语义场景的生成提供了一个新的基准和有效的解决方案。

Abstract: Outdoor 3D semantic scene generation produces realistic and semantically rich
environments for applications such as urban simulation and autonomous driving.
However, advances in this direction are constrained by the absence of publicly
available, well-annotated datasets. We introduce SketchSem3D, the first
large-scale benchmark for generating 3D outdoor semantic scenes from abstract
freehand sketches and pseudo-labeled annotations of satellite images.
SketchSem3D includes two subsets, Sketch-based SemanticKITTI and Sketch-based
KITTI-360 (containing LiDAR voxels along with their corresponding sketches and
annotated satellite images), to enable standardized, rigorous, and diverse
evaluations. We also propose Cylinder Mamba Diffusion (CymbaDiff) that
significantly enhances spatial coherence in outdoor 3D scene generation.
CymbaDiff imposes structured spatial ordering, explicitly captures cylindrical
continuity and vertical hierarchy, and preserves both physical neighborhood
relationships and global context within the generated scenes. Extensive
experiments on SketchSem3D demonstrate that CymbaDiff achieves superior
semantic consistency, spatial realism, and cross-dataset generalization. The
code and dataset will be available at
https://github.com/Lillian-research-hub/CymbaDiff

</details>


### [39] [Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture](https://arxiv.org/abs/2510.13250)
*Zhiyuan Zhao,Yubin Wen,Siyu Yang,Lichen Ning,Yuandong Liu,Junyu Gao*

Main category: cs.CV

TL;DR: 提出了一种具有干、编码器-解码器结构的超实时人群计数模型，在嵌入式系统上实现了最快推理速度，同时保持了有竞争力的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在嵌入式系统上的实际应用存在模型参数过多、计算复杂等问题，而嵌入式系统需要模型具有实时性。

Method: 设计了一种具有干、编码器-解码器结构的超实时模型；干网络使用大的卷积核来扩大感受野，提取详细的头部信息；编码器部分使用条件通道加权和多分支局部融合块来以低计算量融合多尺度特征；在编码器顶部添加了特征金字塔网络来缓解不完全融合问题。

Result: 在三个基准测试上，该网络实现了最快的推理速度（在NVIDIA GTX 1080Ti上达到381.7 FPS，在NVIDIA Jetson TX1上达到71.9 FPS），同时保证了有竞争力的准确性，适用于嵌入式系统的超实时人群计数。

Conclusion: 所提出的网络适用于嵌入式系统的超实时人群计数，推理速度最快，同时保持了有竞争力的准确性。

Abstract: Crowd counting is a task of estimating the number of the crowd through
images, which is extremely valuable in the fields of intelligent security,
urban planning, public safety management, and so on. However, the existing
counting methods have some problems in practical application on embedded
systems for these fields, such as excessive model parameters, abundant complex
calculations, etc. The practical application of embedded systems requires the
model to be real-time, which means that the model is fast enough. Considering
the aforementioned problems, we design a super real-time model with a
stem-encoder-decoder structure for crowd counting tasks, which achieves the
fastest inference compared with state-of-the-arts. Firstly, large convolution
kernels in the stem network are used to enlarge the receptive field, which
effectively extracts detailed head information. Then, in the encoder part, we
use conditional channel weighting and multi-branch local fusion block to merge
multi-scale features with low computational consumption. This part is crucial
to the super real-time performance of the model. Finally, the feature pyramid
networks are added to the top of the encoder to alleviate its incomplete fusion
problems. Experiments on three benchmarks show that our network is suitable for
super real-time crowd counting on embedded systems, ensuring competitive
accuracy. At the same time, the proposed network reasoning speed is the
fastest. Specifically, the proposed network achieves 381.7 FPS on NVIDIA GTX
1080Ti and 71.9 FPS on NVIDIA Jetson TX1.

</details>


### [40] [Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs](https://arxiv.org/abs/2510.13251)
*Minji Kim,Taekyung Kim,Bohyung Han*

Main category: cs.CV

TL;DR: 该研究利用机制可解释性技术，探索了视频大语言模型（VideoLLMs）在视频问答（VideoQA）任务中的内部信息流动机制，发现模型通过跨帧交互进行时序推理，并在中间层整合视频与语言信息，最后在中间到晚期层生成答案。研究还表明，通过优化信息路径和抑制冗余连接（如LLaVA-NeXT-7B-Video-FT模型中抑制58%的注意力边），可以在保持VideoQA性能的同时提高模型的可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型（VideoLLMs）在视频问答（VideoQA）等任务中展现了潜力，但其内部信息提取和传播机制尚不明确。

Method: 采用机制可解释性技术，分析VideoLLMs在VideoQA任务中的信息流动模式。

Result: 1. 早期到中期层出现活跃的跨帧交互，启动时序推理。 2. 中期层进行逐步的视频-语言整合，将视频表征与包含时序概念的语言嵌入对齐。 3. 中间到晚期层完成整合，准备生成答案。 4. 通过选择有效信息通路并抑制大量注意力边（如LLaVA-NeXT-7B-Video-FT中的58%），VideoLLMs可在保持VideoQA性能的同时进行优化。

Conclusion: 该研究为理解VideoLLMs的时序推理提供了蓝图，并为提高模型可解释性和下游泛化能力提供了实践见解。

Abstract: Video Large Language Models (VideoLLMs) extend the capabilities of
vision-language models to spatiotemporal inputs, enabling tasks such as video
question answering (VideoQA). Despite recent advances in VideoLLMs, their
internal mechanisms on where and how they extract and propagate video and
textual information remain less explored. In this study, we investigate the
internal information flow of VideoLLMs using mechanistic interpretability
techniques. Our analysis reveals consistent patterns across diverse VideoQA
tasks: (1) temporal reasoning in VideoLLMs initiates with active cross-frame
interactions in early-to-middle layers, (2) followed by progressive
video-language integration in middle layers. This is facilitated by alignment
between video representations and linguistic embeddings containing temporal
concepts. (3) Upon completion of this integration, the model is ready to
generate correct answers in middle-to-late layers. (4) Based on our analysis,
we show that VideoLLMs can retain their VideoQA performance by selecting these
effective information pathways while suppressing a substantial amount of
attention edges, e.g., 58% in LLaVA-NeXT-7B-Video-FT. These findings provide a
blueprint on how VideoLLMs perform temporal reasoning and offer practical
insights for improving model interpretability and downstream generalization.
Our project page with the source code is available at
https://map-the-flow.github.io

</details>


### [41] [End-to-End Multi-Modal Diffusion Mamba](https://arxiv.org/abs/2510.13253)
*Chunhao Lu,Qiang Lu,Meichen Dong,Jake Luo*

Main category: cs.CV

TL;DR: MDM是一个统一的多模态模型，利用基于Mamba的扩散模型和变分自编码器来同时处理和生成高维多模态数据，在图像生成、图像描述、视觉问答、文本理解和推理等任务上表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态模型在处理输入和输出信息时使用不同的编码器和解码器，这阻碍了多种模态的联合表示学习。为了统一多模态处理，需要一种新的架构。

Method: 提出了一种名为MDM（Multi-modal Diffusion Mamba）的新型架构。MDM利用基于Mamba的多步选择扩散模型，通过统一的变分自编码器来逐步生成和细化特定模态的信息，该编码器同时用于编码和解码。

Result: MDM在处理高维数据方面取得了卓越的性能，特别是在同时生成高分辨率图像和扩展文本序列方面。在图像生成、图像描述、视觉问答、文本理解和推理等任务上的评估表明，MDM显著优于现有的端到端模型（如MonoFormer、LlamaGen和Chameleon），并能与GPT-4V、Gemini Pro和Mistral等SOTA模型有效竞争。

Conclusion: MDM的有效性在统一多模态过程方面得到了验证，同时保持了计算效率，为端到端多模态架构开辟了新的方向。

Abstract: Current end-to-end multi-modal models utilize different encoders and decoders
to process input and output information. This separation hinders the joint
representation learning of various modalities. To unify multi-modal processing,
we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM
utilizes a Mamba-based multi-step selection diffusion model to progressively
generate and refine modality-specific information through a unified variational
autoencoder for both encoding and decoding. This innovative approach allows MDM
to achieve superior performance when processing high-dimensional data,
particularly in generating high-resolution images and extended text sequences
simultaneously. Our evaluations in areas such as image generation, image
captioning, visual question answering, text comprehension, and reasoning tasks
demonstrate that MDM significantly outperforms existing end-to-end models
(MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA
models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's
effectiveness in unifying multi-modal processes while maintaining computational
efficiency, establishing a new direction for end-to-end multi-modal
architectures.

</details>


### [42] [Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition](https://arxiv.org/abs/2510.13464)
*Emily Miller,Michael Milford,Muhammad Burhan Hafez,SD Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出三种无需训练的视觉地标识别不确定性度量方法，以提高地标识别的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视觉地标识别（VPR）在机器人和自动驾驶中至关重要，但在不同视觉环境、光照、季节和视角变化下会面临巨大挑战。对于SLAM等关键应用，需要对地标匹配的不确定性进行可靠估计。

Method: 提出三种无需训练的不确定性度量方法：相似度分布（SD）、比例差（RS）和统计不确定性（SU）。SD衡量候选匹配得分之间的分离度；RS评估得分靠前的地标之间的竞争性模糊度；SU结合了SD和RS，提供一个统一的度量标准。

Result: 在九种最先进的VPR方法和六个基准数据集上进行的评估表明，这三种度量方法能够有效区分正确和错误的地标匹配，并且性能优于现有方法，同时计算开销极小，适合实时应用。

Conclusion: 提出的三种不确定性度量方法（SD、RS、SU）无需额外训练或计算验证，能够有效、高效地量化VPR的不确定性，提高地标识别的准确性和召回率，适用于各种环境条件下的机器人实时应用。

Abstract: Visual Place Recognition (VPR) enables robots and autonomous vehicles to
identify previously visited locations by matching current observations against
a database of known places. However, VPR systems face significant challenges
when deployed across varying visual environments, lighting conditions, seasonal
changes, and viewpoints changes. Failure-critical VPR applications, such as
loop closure detection in simultaneous localization and mapping (SLAM)
pipelines, require robust estimation of place matching uncertainty. We propose
three training-free uncertainty metrics that estimate prediction confidence by
analyzing inherent statistical patterns in similarity scores from any existing
VPR method. Similarity Distribution (SD) quantifies match distinctiveness by
measuring score separation between candidates; Ratio Spread (RS) evaluates
competitive ambiguity among top-scoring locations; and Statistical Uncertainty
(SU) is a combination of SD and RS that provides a unified metric that
generalizes across datasets and VPR methods without requiring validation data
to select the optimal metric. All three metrics operate without additional
model training, architectural modifications, or computationally expensive
geometric verification. Comprehensive evaluation across nine state-of-the-art
VPR methods and six benchmark datasets confirms that our metrics excel at
discriminating between correct and incorrect VPR matches, and consistently
outperform existing approaches while maintaining negligible computational
overhead, making it deployable for real-time robotic applications across varied
environmental conditions with improved precision-recall performance.

</details>


### [43] [MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models](https://arxiv.org/abs/2510.13276)
*Keyan Zhou,Zecheng Tang,Lingfeng Ming,Guanghao Zhou,Qiguang Chen,Dan Qiao,Zheming Yang,Libo Qin,Minghui Qiu,Juntao Li,Min Zhang*

Main category: cs.CV

TL;DR: 长上下文大视觉语言模型(LVLM)的评估集中在文本上，而多模态评估仅限于短上下文。MMLongCite是一个新的基准，用于评估LVLM在长上下文多模态场景中的忠实度，涵盖8个任务和3种模态。评估显示LVLM在处理长多模态上下文方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的LVLM评估主要集中在文本领域，并且对于长上下文的多模态评估有限，无法满足真实世界应用的需求。

Method: 提出MMLongCite基准，包含8个不同任务，涵盖6个上下文长度区间和文本、图像、视频等多种模态，用于评估LVLM在长上下文中的忠实度。

Result: 评估表明，现有的LVLM在处理长多模态上下文时忠实度有限。分析还揭示了上下文长度和关键内容位置对模型忠实度的影响。

Conclusion: LVLM在处理长多模态上下文方面仍有改进空间，未来的研究应关注提高其在长上下文多模态场景下的忠实度。

Abstract: The rapid advancement of large vision language models (LVLMs) has led to a
significant expansion of their context windows. However, an extended context
window does not guarantee the effective utilization of the context, posing a
critical challenge for real-world applications. Current evaluations of such
long-context faithfulness are predominantly focused on the text-only domain,
while multimodal assessments remain limited to short contexts. To bridge this
gap, we introduce MMLongCite, a comprehensive benchmark designed to evaluate
the fidelity of LVLMs in long-context scenarios. MMLongCite comprises 8
distinct tasks spanning 6 context length intervals and incorporates diverse
modalities, including text, images, and videos. Our evaluation of
state-of-the-art LVLMs reveals their limited faithfulness in handling long
multimodal contexts. Furthermore, we provide an in-depth analysis of how
context length and the position of crucial content affect the faithfulness of
these models.

</details>


### [44] [Universal Image Restoration Pre-training via Masked Degradation Classification](https://arxiv.org/abs/2510.13282)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yinghao Chen,Yanye Lu*

Main category: cs.CV

TL;DR: MaskDCPT通过对图像的退化类型进行分类并利用图像重建来预训练模型，提高了图像复原任务的性能和泛化能力，并发布了UIR-2.5M数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的图像复原预训练方法存在不足，本研究旨在提出一种新的预训练方法，能够更好地处理不同类型的图像退化，并提升复原性能和鲁棒性。

Method: 提出了一种名为MaskDCPT的预训练方法，包含一个编码器和两个解码器。编码器提取遮蔽的低质量输入图像的特征，分类解码器用于识别退化类型（弱监督），重建解码器用于重建高质量图像。该方法结合了遮蔽图像建模和对比学习的优点。

Result: MaskDCPT在图像复原任务上取得了显著的性能提升，CNN和Transformer模型的PSNR至少提高了3.77 dB，PIQE降低了34.8%。模型对未知的退化类型和水平也表现出良好的泛化能力。此外，还发布了包含2.5M样本的UIR-2.5M数据集。

Conclusion: MaskDCPT是一种有效且强大的预训练方法，能够显著提升图像复原任务的性能和泛化能力，适用于各种退化场景。新场景。

Abstract: This study introduces a Masked Degradation Classification Pre-Training method
(MaskDCPT), designed to facilitate the classification of degradation types in
input images, leading to comprehensive image restoration pre-training. Unlike
conventional pre-training methods, MaskDCPT uses the degradation type of the
image as an extremely weak supervision, while simultaneously leveraging the
image reconstruction to enhance performance and robustness. MaskDCPT includes
an encoder and two decoders: the encoder extracts features from the masked
low-quality input image. The classification decoder uses these features to
identify the degradation type, whereas the reconstruction decoder aims to
reconstruct a corresponding high-quality image. This design allows the
pre-training to benefit from both masked image modeling and contrastive
learning, resulting in a generalized representation suited for restoration
tasks. Benefit from the straightforward yet potent MaskDCPT, the pre-trained
encoder can be used to address universal image restoration and achieve
outstanding performance. Implementing MaskDCPT significantly improves
performance for both convolution neural networks (CNNs) and Transformers, with
a minimum increase in PSNR of 3.77 dB in the 5D all-in-one restoration task and
a 34.8% reduction in PIQE compared to baseline in real-world degradation
scenarios. It also emergences strong generalization to previously unseen
degradation types and levels. In addition, we curate and release the UIR-2.5M
dataset, which includes 2.5 million paired restoration samples across 19
degradation types and over 200 degradation levels, incorporating both synthetic
and real-world data. The dataset, source code, and models are available at
https://github.com/MILab-PKU/MaskDCPT.

</details>


### [45] [Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning](https://arxiv.org/abs/2510.13307)
*Yang Li,Aming Wu,Zihao Zhang,Yahong Han*

Main category: cs.CV

TL;DR: 本篇论文提出了一种新颖的3D点云分割方法（3D-NCD），旨在使用已标记的基础类别标签来分割未标记的新颖类别。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在只有已标记基础类别监督的情况下，对未标记新颖类别进行点云分割的问题。

Method: 提出了一种基于结构因果模型（SCM）的新方法，名为“因果表示与推理联合学习”。该方法首先分析基础类别表示中的隐藏混淆因素以及基础类别与新颖类别之间的因果关系。然后，设计了一个因果表示原型来消除混淆因素，捕捉基础类别的因果表示。最后，利用图结构对基础类别因果表示原型与新颖类别原型之间的因果关系进行建模，实现从基础类别到新颖类别的因果推理。

Result: 在3D和2D新颖类别发现（NCD）语义分割任务上进行了大量实验，并提供了可视化结果，证明了该方法的优越性。

Conclusion: 所提出的基于SCM的因果表示与推理联合学习方法在3D-NCD任务上取得了优于现有方法的性能。

Abstract: In this paper, we focus on Novel Class Discovery for Point Cloud Segmentation
(3D-NCD), aiming to learn a model that can segment unlabeled (novel) 3D classes
using only the supervision from labeled (base) 3D classes. The key to this task
is to setup the exact correlations between the point representations and their
base class labels, as well as the representation correlations between the
points from base and novel classes. A coarse or statistical correlation
learning may lead to the confusion in novel class inference. lf we impose a
causal relationship as a strong correlated constraint upon the learning
process, the essential point cloud representations that accurately correspond
to the classes should be uncovered. To this end, we introduce a structural
causal model (SCM) to re-formalize the 3D-NCD problem and propose a new method,
i.e., Joint Learning of Causal Representation and Reasoning. Specifically, we
first analyze hidden confounders in the base class representations and the
causal relationships between the base and novel classes through SCM. We devise
a causal representation prototype that eliminates confounders to capture the
causal representations of base classes. A graph structure is then used to model
the causal relationships between the base classes' causal representation
prototypes and the novel class prototypes, enabling causal reasoning from base
to novel classes. Extensive experiments and visualization results on 3D and 2D
NCD semantic segmentation demonstrate the superiorities of our method.

</details>


### [46] [InstantSfM: Fully Sparse and Parallel Structure-from-Motion](https://arxiv.org/abs/2510.13310)
*Jiankun Zhong,Zitong Zhan,Quankai Gao,Ziyu Chen,Haozhe Lou,Jiageng Mao,Ulrich Neumann,Yue Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 InstantSfM 的新方法，利用 GPU 加速 SfM 流程的关键阶段，实现了比 COLMAP 快 40 倍的速度，同时保持了相当甚至更好的重建精度。


<details>
  <summary>Details</summary>
Motivation: 传统的 SfM 方法在处理大规模场景时计算开销大，存在精度和速度的权衡，并且 C++ 实现缺乏灵活性；基于深度学习的方法在处理大量图像时受 GPU 内存限制。

Method: 在现有稀疏感知 bundle adjustment 优化的基础上，将加速技术应用于 BA 和 GP，构建了一个统一的全局 SfM 框架，充分利用 GPU 并行计算能力。

Result: 在不同规模的数据集（包括 5000 张图像）上进行了广泛实验，证明了该方法在速度和精度上的优势。

Conclusion: InstantSfM 能够有效加速 SfM 流程，克服了现有方法的局限性，在大规模场景下表现出优越的性能。

Abstract: Structure-from-Motion (SfM), a method that recovers camera poses and scene
geometry from uncalibrated images, is a central component in robotic
reconstruction and simulation. Despite the state-of-the-art performance of
traditional SfM methods such as COLMAP and its follow-up work, GLOMAP, naive
CPU-specialized implementations of bundle adjustment (BA) or global positioning
(GP) introduce significant computational overhead when handling large-scale
scenarios, leading to a trade-off between accuracy and speed in SfM. Moreover,
the blessing of efficient C++-based implementations in COLMAP and GLOMAP comes
with the curse of limited flexibility, as they lack support for various
external optimization options. On the other hand, while deep learning based SfM
pipelines like VGGSfM and VGGT enable feed-forward 3D reconstruction, they are
unable to scale to thousands of input views at once as GPU memory consumption
increases sharply as the number of input views grows. In this paper, we unleash
the full potential of GPU parallel computation to accelerate each critical
stage of the standard SfM pipeline. Building upon recent advances in
sparse-aware bundle adjustment optimization, our design extends these
techniques to accelerate both BA and GP within a unified global SfM framework.
Through extensive experiments on datasets of varying scales (e.g. 5000 images
where VGGSfM and VGGT run out of memory), our method demonstrates up to about
40 times speedup over COLMAP while achieving consistently comparable or even
improved reconstruction accuracy. Our project page can be found at
https://cre185.github.io/InstantSfM/.

</details>


### [47] [Self-Augmented Visual Contrastive Decoding](https://arxiv.org/abs/2510.13315)
*Eun Woo Im,Muhammad Kashif Ali,Vivek Gupta*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）易产生幻觉，本研究提出了一种新颖的、无需训练的解码策略，通过自增强提示和自适应阈值调整来解决此问题，并在多个模型和基准测试中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在多模态任务中表现出色，但继承了语言模型的幻觉问题。现有的视觉对比解码方法由于使用了通用的视觉增强，忽略了文本查询的具体上下文，效果有限。

Method: 提出了一种新颖的、无需训练的解码策略，包含两个关键部分：1. 自增强提示策略：利用模型自身知识动态对齐查询和视觉增强的语义。2. 自适应阈值算法：根据输出稀疏度自适应调整下一词候选的大小，充分利用logit分布的全部信息。

Result: 在四个LVLM和七个基准测试上的广泛实验表明，所提出的解码策略显著提高了事实一致性，优于现有的最先进解码方法。

Conclusion: 该研究强调了整合查询依赖增强和熵感知解码对于提升LVLM有效生成能力的重要性。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal
capabilities, but they inherit the tendency to hallucinate from their
underlying language models. While visual contrastive decoding has been proposed
to mitigate this issue, existing methods often apply generic visual
augmentations that disregard the specific context provided by the text query,
limiting their effectiveness. This study introduces a novel training-free
decoding strategy that addresses these limitations, featuring two key
contributions. First, a self-augmentation prompting strategy that leverages the
intrinsic knowledge of the model to dynamically align semantics between the
query and the visual augmentation. Second, an adaptive thresholding algorithm
that adaptively adjusts next token candidate size based on the output sparsity,
utilizing full information from the logit distribution. Extensive experiments
across four LVLMs and seven benchmarks demonstrate that the proposed decoding
significantly enhances factual consistency compared to state-of-the-art
decoding methods. This work highlights the importance of integrating
query-dependent augmentation and entropy-aware decoding for improving effective
generation of LVLMs.

</details>


### [48] [Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests](https://arxiv.org/abs/2510.13316)
*Fitim Abdullahu,Helmut Grabner*

Main category: cs.CV

TL;DR: Large multimodal models (LMMs) like GPT-4o show partial alignment with human assessments of visual interestingness and can be used to label images for training models, advancing the understanding of human interest.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need to understand and quantify visual interestingness, a key factor in daily life and content consumption, and to explore the capabilities of Large Multimodal Models (LMMs) in this domain.

Method: The study compares human assessments of visual interestingness with predictions made by GPT-4o. It then uses the aligned predictions to label image pairs, which are employed as training data for a learning-to-rank model.

Result: The results indicate a partial alignment between human judgments and GPT-4o’s predictions regarding visual interestingness. GPT-4o demonstrates superior performance compared to existing state-of-the-art methods in capturing this concept.

Conclusion: The paper concludes that LMMs, particularly GPT-4o, have a notable capacity to understand and predict visual interestingness, enabling effective data labeling for training specialized models and offering a path towards a more profound comprehension of human interest.

Abstract: Our daily life is highly influenced by what we consume and see. Attracting
and holding one's attention -- the definition of (visual) interestingness -- is
essential. The rise of Large Multimodal Models (LMMs) trained on large-scale
visual and textual data has demonstrated impressive capabilities. We explore
these models' potential to understand to what extent the concepts of visual
interestingness are captured and examine the alignment between human
assessments and GPT-4o's, a leading LMM, predictions through comparative
analysis. Our studies reveal partial alignment between humans and GPT-4o. It
already captures the concept as best compared to state-of-the-art methods.
Hence, this allows for the effective labeling of image pairs according to their
(commonly) interestingness, which are used as training data to distill the
knowledge into a learning-to-rank model. The insights pave the way for a deeper
understanding of human interest.

</details>


### [49] [Removing Cost Volumes from Optical Flow Estimators](https://arxiv.org/abs/2510.13317)
*Simon Kiefhaber,Stefan Roth,Simone Schaub-Meyer*

Main category: cs.CV

TL;DR: 通过在训练过程中移除代价体来提高光流估计的速度和降低内存占用。


<details>
  <summary>Details</summary>
Motivation: 现代光流估计器中的代价体虽然常用，但其计算和空间复杂度限制了处理速度和输入帧分辨率。作者观察到，在训练后期，代价体的重要性会降低，因此提出一种训练策略来移除代价体。

Method: 提出一种训练策略，允许在训练过程中移除光流估计器中的代价体。

Result: 使用该策略创建了三个模型：最精确的模型达到了最先进的准确度，同时速度提升了1.2倍，内存占用降低了6倍；最快的模型能够在仅使用500MB GPU内存的情况下，以20 FPS处理全高清帧。

Conclusion: 提出的训练策略能够显著提高光流估计的速度并降低内存需求，同时保持高准确度。

Abstract: Cost volumes are used in every modern optical flow estimator, but due to
their computational and space complexity, they are often a limiting factor
regarding both processing speed and the resolution of input frames. Motivated
by our empirical observation that cost volumes lose their importance once all
other network parts of, e.g., a RAFT-based pipeline have been sufficiently
trained, we introduce a training strategy that allows removing the cost volume
from optical flow estimators throughout training. This leads to significantly
improved inference speed and reduced memory requirements. Using our training
strategy, we create three different models covering different compute budgets.
Our most accurate model reaches state-of-the-art accuracy while being
$1.2\times$ faster and having a $6\times$ lower memory footprint than
comparable models; our fastest model is capable of processing Full HD frames at
$20\,\mathrm{FPS}$ using only $500\,\mathrm{MB}$ of GPU memory.

</details>


### [50] [DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin](https://arxiv.org/abs/2510.13326)
*Divya Bhardwaj,Arnav Ramamoorthy,Poonam Goyal*

Main category: cs.CV

TL;DR: 提出了一种用于热成像中隐藏武器检测的新型YOLO架构DEF-YOLO和名为TICW的大规模数据集，解决了现有方法的局限性，实现了低成本、保护隐私的实时监控。


<details>
  <summary>Details</summary>
Motivation: 为了提供低成本、保护隐私且能进行全天候实时监控的隐藏武器检测解决方案，同时克服现有成像技术的局限性（如微波成像分辨率差、毫米波成像涉及隐私问题），本研究选择利用热成像技术，尽管目前缺乏相关的基准数据集。

Method: 提出了一种名为DEF-YOLO的新型YOLO架构，该架构基于YOLOv8进行了关键的改进，以适应热成像中隐藏武器检测的独特挑战。具体包括：在SPPF层采用可变形卷积来利用多尺度特征；在骨干网和颈部层提取低、中、高层特征。此外，引入了一个大规模的热成像隐藏武器数据集（TICW），并结合了焦点损失来处理类别不平衡问题。

Result: 通过广泛的实验，证明了所提出的DEF-YOLO模型在TICW数据集上的有效性，为热成像隐藏武器检测设定了新的基准。

Conclusion: 本研究成功地提出了一个新颖的、基于热成像的隐藏武器检测方法（DEF-YOLO）和首个大规模相关数据集（TICW），克服了现有技术的不足，并在性能上建立了新的基准。

Abstract: Concealed weapon detection aims at detecting weapons hidden beneath a
person's clothing or luggage. Various imaging modalities like Millimeter Wave,
Microwave, Terahertz, Infrared, etc., are exploited for the concealed weapon
detection task. These imaging modalities have their own limitations, such as
poor resolution in microwave imaging, privacy concerns in millimeter wave
imaging, etc. To provide a real-time, 24 x 7 surveillance, low-cost, and
privacy-preserved solution, we opted for thermal imaging in spite of the lack
of availability of a benchmark dataset. We propose a novel approach and a
dataset for concealed weapon detection in thermal imagery. Our YOLO-based
architecture, DEF-YOLO, is built with key enhancements in YOLOv8 tailored to
the unique challenges of concealed weapon detection in thermal vision. We adopt
deformable convolutions at the SPPF layer to exploit multi-scale features;
backbone and neck layers to extract low, mid, and high-level features, enabling
DEF-YOLO to adaptively focus on localization around the objects in thermal
homogeneous regions, without sacrificing much of the speed and throughput. In
addition to these simple yet effective key architectural changes, we introduce
a new, large-scale Thermal Imaging Concealed Weapon dataset, TICW, featuring a
diverse set of concealed weapons and capturing a wide range of scenarios. To
the best of our knowledge, this is the first large-scale contributed dataset
for this task. We also incorporate focal loss to address the significant class
imbalance inherent in the concealed weapon detection task. The efficacy of the
proposed work establishes a new benchmark through extensive experimentation for
concealed weapon detection in thermal imagery.

</details>


### [51] [Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models](https://arxiv.org/abs/2510.13331)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: VQ-VAE存在码本塌陷等问题，本文提出Group-VQ，通过分组优化码本并引入训练后重采样方法，提升了重建质量和码本大小调整的灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决VQ-VAE模型中存在的码本塌陷问题，并提升重建质量。

Method: 提出Group-VQ，对码本进行分组优化，并引入训练后码本重采样方法。

Result: Group-VQ在图像重建实验中展示了更好的性能，并且码本重采样方法实现了调整码本大小的灵活性。

Conclusion: Group-VQ通过分组优化和训练后重采样方法，有效解决了VQ-VAE的挑战，提高了重建性能和码本管理的灵活性。

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised
learning through reconstruction tasks to represent continuous vectors using the
closest vectors in a codebook. However, issues such as codebook collapse
persist in the VQ model. To address these issues, existing approaches employ
implicit static codebooks or jointly optimize the entire codebook, but these
methods constrain the codebook's learning capability, leading to reduced
reconstruction quality. In this paper, we propose Group-VQ, which performs
group-wise optimization on the codebook. Each group is optimized independently,
with joint optimization performed within groups. This approach improves the
trade-off between codebook utilization and reconstruction performance.
Additionally, we introduce a training-free codebook resampling method, allowing
post-training adjustment of the codebook size. In image reconstruction
experiments under various settings, Group-VQ demonstrates improved performance
on reconstruction metrics. And the post-training codebook sampling method
achieves the desired flexibility in adjusting the codebook size.

</details>


### [52] [No-Reference Rendered Video Quality Assessment: Dataset and Metrics](https://arxiv.org/abs/2510.13349)
*Sipeng Yang,Jiayu Ji,Qingchuan Zhu,Zhiyao Yang,Xiaogang Jin*

Main category: cs.CV

TL;DR: 该研究提出了一个专门针对渲染视频的无参考视频质量评估（NR-VQA）数据集和指标，解决了现有NR-VQA方法在渲染视频上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有NR-VQA方法主要关注相机拍摄的视频，在渲染视频上存在预测偏差，因为渲染视频更容易出现时间伪影。因此，需要专门针对渲染视频的NR-VQA方法。

Method: 研究提出了一个包含3D场景和渲染设置的渲染视频数据集，并进行了主观质量评分。基于该数据集，设计了一个结合图像质量和时间稳定性的NR-VQA指标，并进行了校准。

Result: 与现有NR-VQA指标相比，所提出的指标在渲染视频上表现出更优越的性能。该指标可用于对超采样方法进行基准测试和评估实时渲染中的帧生成策略。

Conclusion: 该研究成功地构建了一个渲染视频数据集，并提出了一个性能优越的NR-VQA指标，解决了现有方法在渲染视频质量评估方面的不足。

Abstract: Quality assessment of videos is crucial for many computer graphics
applications, including video games, virtual reality, and augmented reality,
where visual performance has a significant impact on user experience. When test
videos cannot be perfectly aligned with references or when references are
unavailable, the significance of no-reference video quality assessment (NR-VQA)
methods is undeniable. However, existing NR-VQA datasets and metrics are
primarily focused on camera-captured videos; applying them directly to rendered
videos would result in biased predictions, as rendered videos are more prone to
temporal artifacts. To address this, we present a large rendering-oriented
video dataset with subjective quality annotations, as well as a designed NR-VQA
metric specific to rendered videos. The proposed dataset includes a wide range
of 3D scenes and rendering settings, with quality scores annotated for various
display types to better reflect real-world application scenarios. Building on
this dataset, we calibrate our NR-VQA metric to assess rendered video quality
by looking at both image quality and temporal stability. We compare our metric
to existing NR-VQA metrics, demonstrating its superior performance on rendered
videos. Finally, we demonstrate that our metric can be used to benchmark
supersampling methods and assess frame generation strategies in real-time
rendering.

</details>


### [53] [Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity](https://arxiv.org/abs/2510.13364)
*MingZe Tang,Jubal Chandy Jacob*

Main category: cs.CV

TL;DR: 提示词的特异性会影响零样本图像分类，特别是对于视觉相似的类别。最先进的模型（如MetaCLIP 2和OpenCLIP）在处理简单提示词时表现最佳，而SigLip模型在处理更详细的提示词时表现更好。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨提示词的特异性如何影响零样本图像分类，尤其是在处理像人类姿势这样视觉上相似的类别时，这对数据稀缺的场景很有意义。

Method: 使用一个包含285张图像的COCO衍生数据集，评估了OpenCLIP、MetaCLIP 2和SigLip等现代视觉语言模型（VLMs）。研究采用了一个三层级的提示词设计，通过逐步增加语言细节来系统地测试不同特异性提示词的效果。

Result: 研究发现，对于表现最佳的模型（MetaCLIP 2和OpenCLIP），最简单、最基础的提示词能带来最佳的分类效果。然而，增加描述性细节会显著降低这些模型的性能，MetaCLIP 2的多类别准确率从68.8%下降到55.1%，这种现象被称为“提示词过拟合”。相反，表现相对较差的SigLip模型在使用更具描述性、基于身体线索的提示词时，在区分模糊类别方面表现有所改善。

Conclusion: 对于最先进的视觉语言模型，在处理视觉相似类别（如人类姿势）的零样本分类任务时，简单的提示词通常比复杂的提示词效果更好。提示词的复杂性会适得其反，导致性能下降（提示词过拟合）。然而，对于性能稍弱的模型，更详细的提示词可能有助于区分更细微的视觉差别。

Abstract: Recent Vision-Language Models (VLMs) enable zero-shot classification by
aligning images and text in a shared space, a promising approach for
data-scarce conditions. However, the influence of prompt design on recognizing
visually similar categories, such as human postures, is not well understood.
This study investigates how prompt specificity affects the zero-shot
classification of sitting, standing, and walking/running on a small, 285-image
COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2,
and SigLip, were evaluated using a three-tiered prompt design that
systematically increases linguistic detail. Our findings reveal a compelling,
counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and
OpenCLIP), the simplest, most basic prompts consistently achieve the best
results. Adding descriptive detail significantly degrades performance for
instance, MetaCLIP 2's multi-class accuracy drops from 68.8\% to 55.1\% a
phenomenon we term "prompt overfitting". Conversely, the lower-performing
SigLip model shows improved classification on ambiguous classes when given more
descriptive, body-cue-based prompts.

</details>


### [54] [DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](https://arxiv.org/abs/2510.13375)
*Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Zhuoguang Chen,Tao Jiang,Hang Zhao*

Main category: cs.CV

TL;DR: DepthVLA是一个结合了预训练深度预测模块的VLA模型，通过共享的Transformer注意力机制增强了空间推理能力，在真实和模拟环境中均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在需要精确空间推理的任务上表现不佳，因为它们继承的视觉语言模型（VLM）空间推理能力有限，并且依赖于大量的动作数据预训练，效率低下且空间理解能力不足。

Method: DepthVLA模型集成了一个预训练的深度预测模块，并采用了一种混合Transformer设计，将VLM、深度Transformer和动作专家通过完全共享的注意力机制结合起来，形成一个端到端的模型。

Result: DepthVLA在真实世界任务中达到了78.5%的进展率（优于65.0%），在LIBERO模拟器中达到了94.9%（优于93.6%），在Simpler模拟器中达到了74.8%（优于58.8%），表现优于现有技术。

Conclusion: DepthVLA通过显式引入空间意识，有效提升了VLA模型在需要精确空间推理的任务上的性能，并且训练效率更高。

Abstract: Vision-Language-Action (VLA) models have recently shown impressive
generalization and language-guided manipulation capabilities. However, their
performance degrades on tasks requiring precise spatial reasoning due to
limited spatial reasoning inherited from Vision-Language Models (VLMs).
Existing VLAs rely on extensive action-data pretraining to ground VLMs in 3D
space, which reduces training efficiency and is still insufficient for accurate
spatial understanding. In this work, we present DepthVLA, a simple yet
effective VLA architecture that explicitly incorporates spatial awareness
through a pretrained depth prediction module. DepthVLA adopts a
mixture-of-transformers design that unifies a VLM, a depth transformer, and an
action expert with fully shared attentions, forming an end-to-end model with
enhanced spatial reasoning. Extensive evaluations in both real-world and
simulated environments show that DepthVLA outperforms state-of-the-art
approaches, achieving 78.5% vs. 65.0% progress in real-world tasks, 94.9% vs.
93.6% in the LIBERO simulator, and 74.8% vs. 58.8% in the Simpler simulator.
Our code will be made publicly available.

</details>


### [55] [Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment](https://arxiv.org/abs/2510.13390)
*Feng-Qi Cui,Yu-Tong Guo,Tianyue Zheng,Jinyang Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GLSDA的新型框架，利用大型基础模型的语义先验来改进基于WiFi的手势识别的泛化能力和语义表达能力，通过双路径编码、多尺度语义编码、语义感知软监督和鲁棒双蒸馏等方法，并在Widar3.0数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi手势识别方法在泛化能力和语义表达能力方面存在不足，因为信道状态信息（CSI）具有领域敏感性，并且缺乏高级手势抽象。

Method: 提出了一种名为GLSDA（Large-Model-Aware Semantic Distillation and Alignment）的框架，该框架包括：1. 双路径CSI编码：使用CSI-Ratio相位序列和多普勒频谱图捕捉几何和动态手势模式。2. 多尺度语义编码：通过跨模态注意力机制学习鲁棒的时间嵌入，并将其与手势语义对齐。3. 语义感知软监督：编码类间相关性，减少标签歧义。4. 鲁棒双蒸馏：将对齐后的模型压缩为轻量级学生网络，蒸馏中间特征和语义信息软标签。

Result: GLSDA在Widar3.0基准测试中，在域内和跨域手势识别任务上均持续优于现有最先进方法，同时显著减小了模型尺寸和推理延迟。

Conclusion: GLSDA为真实世界的AIoT应用提供了可扩展、可部署的通用RF手势识别解决方案，有效解决了现有方法的局限性。

Abstract: WiFi-based gesture recognition has emerged as a promising RF sensing paradigm
for enabling non-contact and privacy-preserving human-computer interaction in
AIoT environments. However, existing methods often suffer from limited
generalization and semantic expressiveness due to the domain-sensitive nature
of Channel State Information and the lack of high-level gesture abstraction. To
address these challenges, we propose a novel generalization framework, termed
Large-Model-Aware Semantic Distillation and Alignment (GLSDA), which leverages
the semantic prior of pre-trained large foundation models to enhance gesture
representation learning in both in-domain and cross-domain scenarios.
Specifically, we first design a dual-path CSI encoding pipeline that captures
geometric and dynamic gesture patterns via CSI-Ratio phase sequences and
Doppler spectrograms. These representations are then fed into a Multiscale
Semantic Encoder, which learns robust temporal embeddings and aligns them with
gesture semantics through cross-modal attention mechanisms. To further enhance
category discrimination, we introduce a Semantic-Aware Soft Supervision scheme
that encodes inter-class correlations and reduces label ambiguity, especially
for semantically similar gestures. Finally, we develop a Robust
Dual-Distillation strategy to compress the aligned model into a lightweight
student network, jointly distilling intermediate features and semantic-informed
soft labels from the teacher model. Extensive experiments on the Widar3.0
benchmark show that GLSDA consistently outperforms state-of-the-art methods in
both in-domain and cross-domain gesture recognition tasks, while significantly
reducing model size and inference latency. Our method offers a scalable and
deployable solution for generalized RF-based gesture interfaces in real-world
AIoT applications.

</details>


### [56] [Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.13394)
*Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang*

Main category: cs.CV

TL;DR: 该研究提出了一个名为Spatial-DISE的统一基准和数据集，用于评估和改进视觉语言模型（VLMs）的空间推理能力，特别是内在动态空间推理，并发现现有VLMs在多步、多视角推理方面与人类能力存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估VLMs的空间推理能力，尤其是内在动态空间推理方面存在不足，而这对于机器人、增强现实和自动导航等实际应用至关重要。

Method: 提出名为Spatial-DISE的统一基准，基于认知分类将任务划分为内在静态、内在动态、外在静态和外在动态四个象限。开发了一个自动化的流程来生成空间推理问题，构建了Spatial-DISE Bench（559个评估对）和Spatial-DISE-12K（12K+训练对）数据集。在28个先进VLMs上进行了全面评估。

Result: 现有VLMs在空间推理能力上与人类存在显著且持续的差距，特别是在多步、多视角空间推理方面表现不佳。

Conclusion: Spatial-DISE提供了一个强大的框架、有价值的数据集和明确的研究方向，以推动VLMs在空间智能方面达到接近人类的水平。基准、数据集和代码将公开。

Abstract: Spatial reasoning ability is crucial for Vision Language Models (VLMs) to
support real-world applications in diverse domains including robotics,
augmented reality, and autonomous navigation. Unfortunately, existing
benchmarks are inadequate in assessing spatial reasoning ability, especially
the \emph{intrinsic-dynamic} spatial reasoning which is a fundamental aspect of
human spatial cognition. In this paper, we propose a unified benchmark,
\textbf{Spatial-DISE}, based on a cognitively grounded taxonomy that
categorizes tasks into four fundamental quadrants:
\textbf{I}ntrinsic-\textbf{S}tatic, Intrinsic-\textbf{D}ynamic,
\textbf{E}xtrinsic-Static, and Extrinsic-Dynamic spatial reasoning. Moreover,
to address the issue of data scarcity, we develop a scalable and automated
pipeline to generate diverse and verifiable spatial reasoning questions,
resulting in a new \textbf{Spatial-DISE} dataset that includes Spatial-DISE
Bench (559 evaluation VQA pairs) and Spatial-DISE-12K (12K+ training VQA
pairs). Our comprehensive evaluation across 28 state-of-the-art VLMs reveals
that, current VLMs have a large and consistent gap to human competence,
especially on multi-step multi-view spatial reasoning. Spatial-DISE offers a
robust framework, valuable dataset, and clear direction for future research
toward human-like spatial intelligence. Benchmark, dataset, and code will be
publicly released.

</details>


### [57] [Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation](https://arxiv.org/abs/2510.13418)
*Yifu Luo,Xinhao Hu,Keyu Fan,Haoyuan Sun,Zeyu Chen,Bo Xia,Tiantian Zhang,Yongzhe Chang,Xueqian Wang*

Main category: cs.CV

TL;DR: Mask-GRPO是第一个将基于GRPO的强化学习应用于掩码生成模型以改进文本到图像生成的方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在文本到图像生成领域主要应用于扩散模型或自回归模型，忽视了掩码生成模型这一重要选择。

Method: 提出Mask-GRPO方法，将掩码生成模型的解掩码过程视为多步决策问题，并重新定义了转移概率。同时探索了移除KL约束、应用规约策略和过滤低质量样本等策略。

Result: 在标准的文本到图像生成基准测试和偏好对齐方面，Mask-GRPO显著优于Show-o基线模型，并超越了现有的最先进方法。

Conclusion: Mask-GRPO成功地将强化学习应用于掩码生成模型，并在文本到图像生成任务上取得了显著的改进。

Abstract: Reinforcement learning (RL) has garnered increasing attention in
text-to-image (T2I) generation. However, most existing RL approaches are
tailored to either diffusion models or autoregressive models, overlooking an
important alternative: masked generative models. In this work, we propose
Mask-GRPO, the first method to incorporate Group Relative Policy Optimization
(GRPO)-based RL into this overlooked paradigm. Our core insight is to redefine
the transition probability, which is different from current approaches, and
formulate the unmasking process as a multi-step decision-making problem. To
further enhance our method, we explore several useful strategies, including
removing the KL constraint, applying the reduction strategy, and filtering out
low-quality samples. Using Mask-GRPO, we improve a base model, Show-o, with
substantial improvements on standard T2I benchmarks and preference alignment,
outperforming existing state-of-the-art approaches. The code is available on
https://github.com/xingzhejun/Mask-GRPO

</details>


### [58] [Ultra High-Resolution Image Inpainting with Patch-Based Content Consistency Adapter](https://arxiv.org/abs/2510.13419)
*Jianhui Zhang,Sheng Cheng,Qirui Sun,Jia Liu,Wang Luyang,Chaoyu Feng,Chen Fang,Lei Lei,Jue Wang,Shuaicheng Liu*

Main category: cs.CV

TL;DR: Patch-Adapter是一个用于高分辨率文本引导图像修复的框架，可以达到4K+分辨率，同时保持内容一致性和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的图像修复方法在低分辨率下效果较好，但在高分辨率下会遇到内容一致性和提示对齐的挑战，本文旨在解决这一问题。

Method: Patch-Adapter采用两阶段适配器架构：1. 双上下文适配器（Dual Context Adapter）在较低分辨率下学习掩码区域和未掩码区域之间的相关性，以建立全局结构一致性；2. 参考图块适配器（Reference Patch Adapter）在全分辨率下实现图块级注意力机制，通过自适应特征融合来保持局部细节保真度。

Result: Patch-Adapter能够解决大规模图像修复中常见的瑕疵问题，并在OpenImages和Photo-Concept-Bucket数据集上取得了最先进的性能，在感知质量和文本提示遵循度方面均优于现有方法。

Conclusion: Patch-Adapter通过解耦全局语义和局部细化，成功解决了高分辨率图像修复的可扩展性问题，实现了高分辨率、内容一致性和提示对齐。

Abstract: In this work, we present Patch-Adapter, an effective framework for
high-resolution text-guided image inpainting. Unlike existing methods limited
to lower resolutions, our approach achieves 4K+ resolution while maintaining
precise content consistency and prompt alignment, two critical challenges in
image inpainting that intensify with increasing resolution and texture
complexity. Patch-Adapter leverages a two-stage adapter architecture to scale
the diffusion model's resolution from 1K to 4K+ without requiring structural
overhauls: (1) Dual Context Adapter learns coherence between masked and
unmasked regions at reduced resolutions to establish global structural
consistency; and (2) Reference Patch Adapter implements a patch-level attention
mechanism for full-resolution inpainting, preserving local detail fidelity
through adaptive feature fusion. This dual-stage architecture uniquely
addresses the scalability gap in high-resolution inpainting by decoupling
global semantics from localized refinement. Experiments demonstrate that
Patch-Adapter not only resolves artifacts common in large-scale inpainting but
also achieves state-of-the-art performance on the OpenImages and
Photo-Concept-Bucket datasets, outperforming existing methods in both
perceptual quality and text-prompt adherence.

</details>


### [59] [CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation](https://arxiv.org/abs/2510.13432)
*Yushan Han,Hui Zhang,Honglei Zhang,Chuntao Ding,Yuanzhouhan Cao,Yidong Li*

Main category: cs.CV

TL;DR: CoDS利用域分离来解决异构场景中的特征不匹配问题，通过LSCR和DADS模块进行特征对齐，并使用DAMI损失来增强对齐效果，最终实现高推理效率和准确的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的协作感知方法通常假设所有代理都使用相同的编码器，这在真实世界的异构场景中不成立。现有方法通过将邻居特征与自车特征对齐来解决这个问题，但这种方法容易受到域迁移带来的噪声影响，并且基于Transformer的域适应模块会导致模型推理效率低下，不适用于移动设备。

Method: 提出了一种名为CoDS的协作感知方法，利用域分离来解决异构场景中的特征不匹配问题。CoDS采用两个特征对齐模块：轻量级空间-通道调整器（LSCR）和通过域分离进行的分布对齐（DADS）。LSCR使用轻量级卷积层在空间和通道维度上对齐邻居特征。DADS则通过特定于编码器和与编码器无关的域分离模块来减轻特征分布的差异，前者去除依赖于域的信息，后者捕获与任务相关的信息。在训练过程中，DAMI损失最大化对齐的异构特征之间的互信息，以增强域分离过程。CoDS采用全卷积架构，确保了高推理效率。

Result: CoDS在异构场景中有效减轻了特征不匹配问题，并在检测准确性和推理效率之间取得了良好的权衡。

Conclusion: CoDS是一种有效的协作感知方法，能够解决异构场景中的特征不匹配问题，并提供高推理效率。

Abstract: Collaborative perception has been proven to improve individual perception in
autonomous driving through multi-agent interaction. Nevertheless, most methods
often assume identical encoders for all agents, which does not hold true when
these models are deployed in real-world applications. To realize collaborative
perception in actual heterogeneous scenarios, existing methods usually align
neighbor features to those of the ego vehicle, which is vulnerable to noise
from domain gaps and thus fails to address feature discrepancies effectively.
Moreover, they adopt transformer-based modules for domain adaptation, which
causes the model inference inefficiency on mobile devices. To tackle these
issues, we propose CoDS, a Collaborative perception method that leverages
Domain Separation to address feature discrepancies in heterogeneous scenarios.
The CoDS employs two feature alignment modules, i.e., Lightweight
Spatial-Channel Resizer (LSCR) and Distribution Alignment via Domain Separation
(DADS). Besides, it utilizes the Domain Alignment Mutual Information (DAMI)
loss to ensure effective feature alignment. Specifically, the LSCR aligns the
neighbor feature across spatial and channel dimensions using a lightweight
convolutional layer. Subsequently, the DADS mitigates feature distribution
discrepancy with encoder-specific and encoder-agnostic domain separation
modules. The former removes domain-dependent information and the latter
captures task-related information. During training, the DAMI loss maximizes the
mutual information between aligned heterogeneous features to enhance the domain
separation process. The CoDS employs a fully convolutional architecture, which
ensures high inference efficiency. Extensive experiments demonstrate that the
CoDS effectively mitigates feature discrepancies in heterogeneous scenarios and
achieves a trade-off between detection accuracy and inference efficiency.

</details>


### [60] [Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D](https://arxiv.org/abs/2510.13433)
*Pavithra Elumalai,Mohammad Bashiri,Goirik Chakrabarty,Suhas Shrinivasan,Fabian H. Sinz*

Main category: cs.CV

TL;DR: 通过使用可微分渲染管线优化变形网格，可以直接在3D中获得视网膜优势图（MEIs），从而克服了传统基于2D像素的方法在分离物理场景属性的神经选择性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 理解视觉感觉神经元如何实现鲁棒感知，需要表征它们对可物理解释的因素（如形状、姿态和光照）的选择性，但现有方法难以实现这一点。

Method: 提出一个可微分渲染管线，优化变形网格以直接在3D中获得MEIs。该方法使用径向基函数参数化网格变形，并学习偏移量和尺度以最大化神经元反应，同时强制执行几何规律性。

Result: 将该方法应用于猴子V4区模型，能够探测神经元对可解释的3D因素（如姿态和光照）的选择性。

Conclusion: 该方法结合了逆向图形学和系统神经科学，提供了一种超越传统基于像素的方法，使用物理上合理、3D的刺激来探测神经选择性。

Abstract: Visual perception relies on inference of 3D scene properties such as shape,
pose, and lighting. To understand how visual sensory neurons enable robust
perception, it is crucial to characterize their selectivity to such physically
interpretable factors. However, current approaches mainly operate on 2D pixels,
making it difficult to isolate selectivity for physical scene properties. To
address this limitation, we introduce a differentiable rendering pipeline that
optimizes deformable meshes to obtain MEIs directly in 3D. The method
parameterizes mesh deformations with radial basis functions and learns offsets
and scales that maximize neuronal responses while enforcing geometric
regularity. Applied to models of monkey area V4, our approach enables probing
neuronal selectivity to interpretable 3D factors such as pose and lighting.
This approach bridges inverse graphics with systems neuroscience, offering a
way to probe neural selectivity with physically grounded, 3D stimuli beyond
conventional pixel-based methods.

</details>


### [61] [Near-Infrared Hyperspectral Imaging Applications in Food Analysis -- Improving Algorithms and Methodologies](https://arxiv.org/abs/2510.13452)
*Ole-Christian Galbo Engstrøm*

Main category: cs.CV

TL;DR: 近红外高光谱成像（NIR-HSI）在食品质量分析中的应用研究，比较了CNN和PLS模型，并开发了两个开源Python包。


<details>
  <summary>Details</summary>
Motivation: 研究NIR-HSI在食品质量分析中的应用，比较CNN和PLS模型的性能，并探索新的建模方法。

Method: 通过四个研究和五个研究假设，应用CNN和PLS模型进行数据分析，并开发了两个开源Python包。

Result: 联合时空光谱分析的CNN模型在化学和物理视觉信息相关的参数建模中优于单独的空间CNN或光谱PLS模型。增强的CNN模型在化学参数建模中表现更好，但PLS模型在平均含量分析中同样有效。空间分布建模受限于空间参考值的获取，CNN模型优于PLS模型。大麦发芽能力建模结果不确定。开发了两个开源Python包。

Conclusion: CNN模型在联合时空光谱分析方面表现优越，特别是在包含化学和物理视觉信息的参数建模中。对于仅涉及化学参数平均含量的分析，PLS模型是推荐的方法。空间分布建模面临挑战，但CNN模型显示出潜力。研究还催生了两个有用的开源Python包。

Abstract: This thesis investigates the application of near-infrared hyperspectral
imaging (NIR-HSI) for food quality analysis. The investigation is conducted
through four studies operating with five research hypotheses. For several
analyses, the studies compare models based on convolutional neural networks
(CNNs) and partial least squares (PLS). Generally, joint spatio-spectral
analysis with CNNs outperforms spatial analysis with CNNs and spectral analysis
with PLS when modeling parameters where chemical and physical visual
information are relevant. When modeling chemical parameters with a
2-dimensional (2D) CNN, augmenting the CNN with an initial layer dedicated to
performing spectral convolution enhances its predictive performance by learning
a spectral preprocessing similar to that applied by domain experts. Still,
PLS-based spectral modeling performs equally well for analysis of the mean
content of chemical parameters in samples and is the recommended approach.
Modeling the spatial distribution of chemical parameters with NIR-HSI is
limited by the ability to obtain spatially resolved reference values.
Therefore, a study used bulk mean references for chemical map generation of fat
content in pork bellies. A PLS-based approach gave non-smooth chemical maps and
pixel-wise predictions outside the range of 0-100\%. Conversely, a 2D CNN
augmented with a spectral convolution layer mitigated all issues arising with
PLS. The final study attempted to model barley's germinative capacity by
analyzing NIR spectra, RGB images, and NIR-HSI images. However, the results
were inconclusive due to the dataset's low degree of germination. Additionally,
this thesis has led to the development of two open-sourced Python packages. The
first facilitates fast PLS-based modeling, while the second facilitates very
fast cross-validation of PLS and other classical machine learning models with a
new algorithm.

</details>


### [62] [VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator](https://arxiv.org/abs/2510.13454)
*Hyojun Go,Dominik Narnhofer,Goutam Bhat,Prune Truong,Federico Tombari,Konrad Schindler*

Main category: cs.CV

TL;DR: VIST3A是一个文本到3D生成框架，通过缝合文本到视频模型和3D重建系统来实现，并在奖励微调的帮助下进行对齐，以生成高质量的3D场景。


<details>
  <summary>Details</summary>
Motivation: 结合强大的文本到视频生成模型和3D重建系统的能力，以实现高质量的文本到3D场景生成。

Method: 将文本到视频生成模型（作为生成器）与3D重建系统（作为解码器）缝合在一起，并使用直接奖励微调技术对齐这两个组件。

Result: VIST3A在所有测试的配对中都显著优于之前的文本到3D模型（以高斯散点图输出），并且能够实现高质量的文本到点云地图生成。

Conclusion: VIST3A是一个通用的框架，可以通过模型缝合和奖励微调有效地实现高质量的文本到3D场景生成。

Abstract: The rapid progress of large, pretrained models for both visual content
generation and 3D reconstruction opens up new possibilities for text-to-3D
generation. Intuitively, one could obtain a formidable 3D scene generator if
one were able to combine the power of a modern latent text-to-video model as
"generator" with the geometric abilities of a recent (feedforward) 3D
reconstruction system as "decoder". We introduce VIST3A, a general framework
that does just that, addressing two main challenges. First, the two components
must be joined in a way that preserves the rich knowledge encoded in their
weights. We revisit model stitching, i.e., we identify the layer in the 3D
decoder that best matches the latent representation produced by the
text-to-video generator and stitch the two parts together. That operation
requires only a small dataset and no labels. Second, the text-to-video
generator must be aligned with the stitched 3D decoder, to ensure that the
generated latents are decodable into consistent, perceptually convincing 3D
scene geometry. To that end, we adapt direct reward finetuning, a popular
technique for human preference alignment. We evaluate the proposed VIST3A
approach with different video generators and 3D reconstruction models. All
tested pairings markedly improve over prior text-to-3D models that output
Gaussian splats. Moreover, by choosing a suitable 3D base model, VIST3A also
enables high-quality text-to-pointmap generation.

</details>


### [63] [ExpressNet-MoE: A Hybrid Deep Neural Network for Emotion Recognition](https://arxiv.org/abs/2510.13493)
*Deeptimaan Banerjee,Prateek Gothwal,Ashis Kumer Biswas*

Main category: cs.CV

TL;DR: ExpressNet-MoE是一个结合了卷积神经网络（CNN）和混合专家（MoE）框架的新型混合深度学习模型，用于解决面部表情识别（FER）中的挑战，如姿态变化、遮挡、光照变化和人口统计学多样性。该模型通过多尺度特征提取和自适应专家选择来提高准确性，并在多个数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 面部表情识别（FER）在在线教育、医疗保健、安全和人机交互等领域至关重要，但由于姿态变化、遮挡、光照变化和人口统计学多样性等因素，实际应用中仍面临挑战。现有的FER模型在情感识别方面存在局限性，导致参与度检测等应用效果不佳。

Method: 提出了一种名为ExpressNet-MoE的新型混合深度学习模型。该模型结合了卷积神经网络（CNN）和混合专家（MoE）框架。其核心机制包括：1. 多尺度特征提取：同时提取全局和局部面部特征。2. MoE模块：动态选择最相关的专家网络，以提高泛化能力和灵活性。3. 残差网络骨干：用于深度特征学习。4. 多个基于CNN的特征提取器。

Result: 在多个数据集上进行了评估，并将ExpressNet-MoE与当前最先进的方法进行了比较。具体准确率如下：AffectNet (v7): 74.77%，AffectNet (v8): 72.55%，RAF-DB: 84.29%，FER-2013: 64.66%。

Conclusion: ExpressNet-MoE模型在多个数据集上取得了优异的性能，证明了其自适应性和在实际场景中开发端到端情感识别系统的潜力。研究代码和结果已公开。

Abstract: In many domains, including online education, healthcare, security, and
human-computer interaction, facial emotion recognition (FER) is essential.
Real-world FER is still difficult despite its significance because of some
factors such as variable head positions, occlusions, illumination shifts, and
demographic diversity. Engagement detection, which is essential for
applications like virtual learning and customer services, is frequently
challenging due to FER limitations by many current models. In this article, we
propose ExpressNet-MoE, a novel hybrid deep learning model that blends both
Convolution Neural Networks (CNNs) and Mixture of Experts (MoE) framework, to
overcome the difficulties. Our model dynamically chooses the most pertinent
expert networks, thus it aids in the generalization and providing flexibility
to model across a wide variety of datasets. Our model improves on the accuracy
of emotion recognition by utilizing multi-scale feature extraction to collect
both global and local facial features. ExpressNet-MoE includes numerous
CNN-based feature extractors, a MoE module for adaptive feature selection, and
finally a residual network backbone for deep feature learning. To demonstrate
efficacy of our proposed model we evaluated on several datasets, and compared
with current state-of-the-art methods. Our model achieves accuracies of 74.77%
on AffectNet (v7), 72.55% on AffectNet (v8), 84.29% on RAF-DB, and 64.66% on
FER-2013. The results show how adaptive our model is and how it may be used to
develop end-to-end emotion recognition systems in practical settings.
Reproducible codes and results are made publicly accessible at
https://github.com/DeeptimaanB/ExpressNet-MoE.

</details>


### [64] [UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning](https://arxiv.org/abs/2510.13515)
*Tiancheng Gu,Kaicheng Yang,Kaichen Zhang,Xiang An,Ziyong Feng,Yueyi Zhang,Weidong Cai,Jiankang Deng,Lidong Bing*

Main category: cs.CV

TL;DR: UniME-V2利用多模态大模型（MLLMs）的理解能力来增强表示学习，通过全局检索构建潜在难例集，并引入MLLM-as-a-Judge机制生成语义匹配软分数，以进行难例挖掘，从而提升嵌入模型的区分能力。UniME-V2-Reranker模型进一步通过联合成对和列表优化来提升性能，在MMEB基准和多个检索任务上均 đạt được SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细微语义差异、负样本多样性以及区分假难例和硬难例方面存在不足。

Method: 1. 构建潜在难例集：通过全局检索。 2. MLLM-as-a-Judge机制：利用MLLMs评估查询-候选对的语义对齐并生成软匹配分数。 3. 难例挖掘：利用软匹配分数，减少假难例影响，识别多样化的高质量难例。 4. 缓解一对一映射约束：使用软标签。 5. 联合优化：UniME-V2-Reranker模型通过联合成对和列表优化进行训练。

Result: 在MMEB基准和多个检索任务上取得了平均SOTA性能。

Conclusion: UniME-V2 通过利用 MLLMs 增强表示学习，有效解决了现有方法的局限性，显著提升了模型的区分能力和检索性能。

Abstract: Universal multimodal embedding models are foundational to various tasks.
Existing approaches typically employ in-batch negative mining by measuring the
similarity of query-candidate pairs. However, these methods often struggle to
capture subtle semantic differences among candidates and lack diversity in
negative samples. Moreover, the embeddings exhibit limited discriminative
ability in distinguishing false and hard negatives. In this paper, we leverage
the advanced understanding capabilities of MLLMs to enhance representation
learning and present a novel Universal Multimodal Embedding (UniME-V2) model.
Our approach first constructs a potential hard negative set through global
retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes
MLLMs to assess the semantic alignment of query-candidate pairs and generate
soft semantic matching scores. These scores serve as a foundation for hard
negative mining, mitigating the impact of false negatives and enabling the
identification of diverse, high-quality hard negatives. Furthermore, the
semantic matching scores are used as soft labels to mitigate the rigid
one-to-one mapping constraint. By aligning the similarity matrix with the soft
semantic matching score matrix, the model learns semantic distinctions among
candidates, significantly enhancing its discriminative capacity. To further
improve performance, we propose UniME-V2-Reranker, a reranking model trained on
our mined hard negatives through a joint pairwise and listwise optimization
approach. We conduct comprehensive experiments on the MMEB benchmark and
multiple retrieval tasks, demonstrating that our method achieves
state-of-the-art performance on average across all tasks.

</details>


### [65] [High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution](https://arxiv.org/abs/2510.13534)
*Thibault Geoffroy,gauthier Gerspacher,Lionel Prevost*

Main category: cs.CV

TL;DR: 通过使用Action Units（面部肌肉运动描述）作为非瞬态、高度语义化的特征，提出了一种增量学习复杂情感识别的方法，实现了0.75的准确率，并优于传统的浅层和深层卷积神经网络方法，同时模型轻量化。


<details>
  <summary>Details</summary>
Motivation: 解决增量学习中学习新任务时可能出现的灾难性遗忘旧任务的问题，特别是在复杂情感识别领域。

Method: 首先学习基本情绪，然后像人类一样逐步学习复杂情绪。利用Action Units作为特征提取器，并将其与传统的卷积神经网络方法进行比较。

Result: 在CFEE数据集上，所提出的方法在增量学习复杂复合情绪时达到了0.75的准确率，优于传统的浅层和深层卷积神经网络方法，并且模型轻量化，内存占用小。

Conclusion: Action Units是描述面部肌肉运动的非瞬态、高度语义化特征，能够有效解决增量学习中的灾难性遗忘问题，在复杂情感识别任务中表现出色，并能生成轻量化模型。

Abstract: Incremental learning is a complex process due to potential catastrophic
forgetting of old tasks when learning new ones. This is mainly due to transient
features that do not fit from task to task. In this paper, we focus on complex
emotion recognition. First, we learn basic emotions and then, incrementally,
like humans, complex emotions. We show that Action Units, describing facial
muscle movements, are non-transient, highly semantical features that outperform
those extracted by both shallow and deep convolutional neural networks. Thanks
to this ability, our approach achieves interesting results when learning
incrementally complex, compound emotions with an accuracy of 0.75 on the CFEE
dataset and can be favorably compared to state-of-the-art results. Moreover, it
results in a lightweight model with a small memory footprint.

</details>


### [66] [Learning Neural Parametric 3D Breast Shape Models for Metrical Surface Reconstruction From Monocular RGB Videos](https://arxiv.org/abs/2510.13540)
*Maximilian Weiherer,Antonia von Riedheim,Vanessa Brébant,Bernhard Egger,Christoph Palm*

Main category: cs.CV

TL;DR: 提出了一种基于视频的低成本3D乳房重建方法，使用局部隐式神经网络模型（liRBSM），重建精度达2毫米以内，速度快且开源。


<details>
  <summary>Details</summary>
Motivation: 现有的3D乳房扫描解决方案成本高昂或效果不佳，需要一种低成本、易于获取且精确的方法。

Method: 结合现有的运动恢复结构（SfM）流水线和一种新颖的局部隐式神经网络乳房模型（liRBSM），该模型将乳房域分解为多个区域，每个区域由局部神经网络符号距离函数（SDF）表示。

Result: 该流水线能够从单眼RGB视频中恢复出高质量的3D乳房几何形状，误差小于2毫米，重建质量优于现有的全局模型（iRBSM）。

Conclusion: 提出的低成本3D乳房重建流水线结合liRBSM模型，能够实现高精度、快速、易于获取的乳房几何形状恢复，为相关领域提供了有价值的工具。

Abstract: We present a neural parametric 3D breast shape model and, based on this
model, introduce a low-cost and accessible 3D surface reconstruction pipeline
capable of recovering accurate breast geometry from a monocular RGB video. In
contrast to widely used, commercially available yet prohibitively expensive 3D
breast scanning solutions and existing low-cost alternatives, our method
requires neither specialized hardware nor proprietary software and can be used
with any device that is able to record RGB videos. The key building blocks of
our pipeline are a state-of-the-art, off-the-shelf Structure-from-motion
pipeline, paired with a parametric breast model for robust and metrically
correct surface reconstruction. Our model, similarly to the recently proposed
implicit Regensburg Breast Shape Model (iRBSM), leverages implicit neural
representations to model breast shapes. However, unlike the iRBSM, which
employs a single global neural signed distance function (SDF), our approach --
inspired by recent state-of-the-art face models -- decomposes the implicit
breast domain into multiple smaller regions, each represented by a local neural
SDF anchored at anatomical landmark positions. When incorporated into our
surface reconstruction pipeline, the proposed model, dubbed liRBSM (short for
localized iRBSM), significantly outperforms the iRBSM in terms of
reconstruction quality, yielding more detailed surface reconstruction than its
global counterpart. Overall, we find that the introduced pipeline is able to
recover high-quality 3D breast geometry within an error margin of less than 2
mm. Our method is fast (requires less than six minutes), fully transparent and
open-source, and -- together with the model -- publicly available at
https://rbsm.re-mic.de/local-implicit.

</details>


### [67] [Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents](https://arxiv.org/abs/2510.13557)
*David Freire-Obregón,José Salas-Cáceres,Javier Lorenzo-Navarro,Oliverio J. Santana,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: 现有面部表情识别（FER）评估忽略了文化差异和视觉退化问题，本文提出了一个基于智能体、流式传输的基准测试，用于评估跨文化构成和渐进式模糊对FER鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有FER评估未能充分考虑跨文化差异和图像质量下降对模型性能的影响。

Method: 构建了一个包含智能体、在线适配器和渐进式高斯模糊的环境。智能体在固定的CLIP特征空间中运行，并在sigma=0时进行在线适配。通过改变文化群体构成（单一文化、混合文化）和空间接触结构来模拟不同的测试场景。

Result: 亚洲（JAFFE）数据集在低模糊度下表现更好，但在中等模糊度下性能急剧下降；西方（KDEF）数据集则呈现更均匀的下降趋势。混合群体表现出中间模式，均衡混合能缓解早期性能下降，但不均衡混合则在高度模糊时加剧了多数群体的弱点。

Conclusion: 文化构成和交互结构会影响FER在视觉条件恶化时的鲁棒性，需要更全面的评估方法来应对这些挑战。

Abstract: Facial expression recognition (FER) must remain robust under both cultural
variation and perceptually degraded visual conditions, yet most existing
evaluations assume homogeneous data and high-quality imagery. We introduce an
agent-based, streaming benchmark that reveals how cross-cultural composition
and progressive blurring interact to shape face recognition robustness. Each
agent operates in a frozen CLIP feature space with a lightweight residual
adapter trained online at sigma=0 and fixed during testing. Agents move and
interact on a 5x5 lattice, while the environment provides inputs with
sigma-scheduled Gaussian blur. We examine monocultural populations
(Western-only, Asian-only) and mixed environments with balanced (5/5) and
imbalanced (8/2, 2/8) compositions, as well as different spatial contact
structures. Results show clear asymmetric degradation curves between cultural
groups: JAFFE (Asian) populations maintain higher performance at low blur but
exhibit sharper drops at intermediate stages, whereas KDEF (Western)
populations degrade more uniformly. Mixed populations exhibit intermediate
patterns, with balanced mixtures mitigating early degradation, but imbalanced
settings amplify majority-group weaknesses under high blur. These findings
quantify how cultural composition and interaction structure influence the
robustness of FER as perceptual conditions deteriorate.

</details>


### [68] [XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation](https://arxiv.org/abs/2510.13565)
*Huawei Sun,Zixu Wang,Xiangyuan Peng,Julius Ott,Georg Stettinger,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 该研究提出了一种名为XD-RCDepth的轻量级雷达-相机融合深度估计架构，通过知识蒸馏策略在减少参数的同时保持了准确性，并在nuScenes和ZJU-4DRadarCam数据集上实现了实时性能。


<details>
  <summary>Details</summary>
Motivation: 雷达-相机融合技术在恶劣条件下提供了互补的几何线索，对于自动驾驶中的深度估计至关重要。

Method: 提出了一种名为XD-RCDepth的轻量级架构，并通过两种知识蒸馏策略（可解释性对齐蒸馏和深度分布蒸馏）来增强模型性能和可解释性。

Result: XD-RCDepth架构相较于现有轻量级基线模型减少了29.7%的参数量，同时保持了可比的准确性。与直接训练相比，所提出的蒸馏策略将平均绝对误差（MAE）降低了7.97%，并在nuScenes和ZJU-4DRadarCam数据集上实现了具有竞争力的实时性能。

Conclusion: XD-RCDepth通过轻量级设计和创新的知识蒸馏策略，在保证实时性的同时实现了高精度的雷达-相机融合深度估计，为自动驾驶提供了有效的解决方案。

Abstract: Depth estimation remains central to autonomous driving, and radar-camera
fusion offers robustness in adverse conditions by providing complementary
geometric cues. In this paper, we present XD-RCDepth, a lightweight
architecture that reduces the parameters by 29.7% relative to the
state-of-the-art lightweight baseline while maintaining comparable accuracy. To
preserve performance under compression and enhance interpretability, we
introduce two knowledge-distillation strategies: an explainability-aligned
distillation that transfers the teacher's saliency structure to the student,
and a depth-distribution distillation that recasts depth regression as soft
classification over discretized bins. Together, these components reduce the MAE
compared with direct training with 7.97% and deliver competitive accuracy with
real-time efficiency on nuScenes and ZJU-4DRadarCam datasets.

</details>


### [69] [Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues](https://arxiv.org/abs/2510.13620)
*Chen Chen,Kangcheng Bin,Ting Hu,Jiahao Qi,Xingyue Liu,Tianpeng Liu,Zhen Liu,Yongxiang Liu,Ping Zhong*

Main category: cs.CV

TL;DR: 该研究提出了ATR-UMOD数据集和PCDF模型，以应对无人机对象检测中因复杂多变的环境条件而导致的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机对象检测数据集在真实世界的复杂性和多变性（如不同的成像条件）方面存在不足。本研究旨在创建一个包含更广泛场景、条件和详细注释的高多样性数据集（ATR-UMOD），并提出一种能够自适应融合多模态信息（RGB和红外图像）以应对这些挑战的新型模型（PCDF）。

Method: 提出了一种名为“提示引导条件感知动态融合（PCDF）”的新型模型。该模型利用文本提示来编码成像条件，并通过特定于任务的软门控变换来学习条件与多模态贡献之间的关系，从而自适应地重新分配多模态信息的权重。此外，还提出了一个提示引导的条件解耦模块，以确保模型在没有条件注释的情况下也能有效运行。

Result: 在ATR-UMOD数据集上进行的实验证明了PCDF模型的有效性，该模型能够更好地处理各种复杂的成像条件，从而提高无人机对象检测的鲁棒性。

Conclusion: ATR-UMOD数据集为无人机对象检测提供了更全面、更多样化的数据，有助于推动该领域的研究。PCDF模型通过条件感知和动态融合，有效地解决了在复杂多变条件下进行鲁棒对象检测的挑战，并在提出的新数据集上取得了良好效果。

Abstract: Unmanned aerial vehicles (UAV)-based object detection with visible (RGB) and
infrared (IR) images facilitates robust around-the-clock detection, driven by
advancements in deep learning techniques and the availability of high-quality
dataset. However, the existing dataset struggles to fully capture real-world
complexity for limited imaging conditions. To this end, we introduce a
high-diversity dataset ATR-UMOD covering varying scenarios, spanning altitudes
from 80m to 300m, angles from 0{\deg} to 75{\deg}, and all-day, all-year time
variations in rich weather and illumination conditions. Moreover, each RGB-IR
image pair is annotated with 6 condition attributes, offering valuable
high-level contextual information. To meet the challenge raised by such diverse
conditions, we propose a novel prompt-guided condition-aware dynamic fusion
(PCDF) to adaptively reassign multimodal contributions by leveraging annotated
condition cues. By encoding imaging conditions as text prompts, PCDF
effectively models the relationship between conditions and multimodal
contributions through a task-specific soft-gating transformation. A
prompt-guided condition-decoupling module further ensures the availability in
practice without condition annotations. Experiments on ATR-UMOD dataset reveal
the effectiveness of PCDF.

</details>


### [70] [AVAR-Net: A Lightweight Audio-Visual Anomaly Recognition Framework with a Benchmark Dataset](https://arxiv.org/abs/2510.13630)
*Amjid Ali,Zulfiqar Ahmad Khan,Altaf Hussain,Muhammad Munsif,Adnan Hussain,Sung Wook Baik*

Main category: cs.CV

TL;DR: AVAR-Net是一个轻量级、高效的音视频异常识别框架，通过融合音频和视频特征，并利用多阶段时间卷积网络学习时空依赖性，提高了在真实世界环境中的异常识别能力，并引入了一个新的VAAR数据集。


<details>
  <summary>Details</summary>
Motivation: 现有异常识别方法主要依赖视觉数据，在遮挡、光照不足等条件下不可靠，且缺乏大规模同步音视频数据集阻碍了多模态方法的发展。

Method: AVAR-Net框架包括音频特征提取（Wav2Vec2）、视频特征提取（MobileViT）、早期融合策略以及用于学习跨模态关系的多阶段时间卷积网络（MTCN）。

Result: AVAR-Net在VAAR数据集上达到89.29%的准确率，在XD-Violence数据集上达到88.56%的平均精度，比现有最先进方法提高了2.8%的平均精度。

Conclusion: AVAR-Net在真实世界环境中表现出有效的、高效的、泛化能力强的异常识别能力，并且VAAR数据集为推动多模态异常识别研究提供了一个有用的基准。

Abstract: Anomaly recognition plays a vital role in surveillance, transportation,
healthcare, and public safety. However, most existing approaches rely solely on
visual data, making them unreliable under challenging conditions such as
occlusion, low illumination, and adverse weather. Moreover, the absence of
large-scale synchronized audio-visual datasets has hindered progress in
multimodal anomaly recognition. To address these limitations, this study
presents AVAR-Net, a lightweight and efficient audio-visual anomaly recognition
framework designed for real-world environments. AVAR-Net consists of four main
modules: an audio feature extractor, a video feature extractor, fusion
strategy, and a sequential pattern learning network that models cross-modal
relationships for anomaly recognition. Specifically, the Wav2Vec2 model
extracts robust temporal features from raw audio, while MobileViT captures both
local and global visual representations from video frames. An early fusion
mechanism combines these modalities, and a Multi-Stage Temporal Convolutional
Network (MTCN) model that learns long-range temporal dependencies within the
fused representation, enabling robust spatiotemporal reasoning. A novel
Visual-Audio Anomaly Recognition (VAAR) dataset, is also introduced, serving as
a medium-scale benchmark containing 3,000 real-world videos with synchronized
audio across ten diverse anomaly classes. Experimental evaluations demonstrate
that AVAR-Net achieves 89.29% accuracy on VAAR and 88.56% Average Precision on
the XD-Violence dataset, improving Average Precision by 2.8% over existing
state-of-the-art methods. These results highlight the effectiveness,
efficiency, and generalization capability of the proposed framework, as well as
the utility of VAAR as a benchmark for advancing multimodal anomaly recognition
research.

</details>


### [71] [Challenges, Advances, and Evaluation Metrics in Medical Image Enhancement: A Systematic Literature Review](https://arxiv.org/abs/2510.13638)
*Chun Wai Chin,Haniza Yazid,Hoi Leong Lee*

Main category: cs.CV

TL;DR: 本综述对39篇关于医学图像增强的文献进行了系统回顾，重点关注挑战、进展和评估指标。MRI和多模态成像研究较多，低对比度和噪声是最常见的问题。大多数研究采用传统数学方法，但深度学习方法也在兴起。评估指标方面，混合参考和非参考指标的使用最为普遍。


<details>
  <summary>Details</summary>
Motivation: 医学图像增强对于提高诊断图像质量和可解释性至关重要，有助于早期检测、准确诊断和有效治疗规划。尽管成像技术不断进步，但医学图像仍面临噪声、伪影和低对比度等挑战，限制了其诊断潜力。本研究旨在系统回顾医学图像增强的关键挑战、最新进展和评估指标。

Method: 采用PRISMA方法对39篇同行评审的研究进行系统性文献回顾，分析不同成像模态的增强效果以及评估指标的重要性。

Result: 在39项研究中，29项使用传统数学方法，9项使用深度学习技术，1项使用混合方法。评估指标方面，18项研究同时使用基于参考和非基于参考的指标，9项仅使用基于参考的指标，12项仅使用非基于参考的指标。共引入了65个图像质量评估（IQA）指标，其中非基于参考的指标占主导地位。低对比度和噪声是最常见的问题，MRI和多模态成像受到最多关注。

Conclusion: 本综述确定了医学图像增强领域的当前局限性、研究空白和未来潜在的研究方向。

Abstract: Medical image enhancement is crucial for improving the quality and
interpretability of diagnostic images, ultimately supporting early detection,
accurate diagnosis, and effective treatment planning. Despite advancements in
imaging technologies such as X-ray, CT, MRI, and ultrasound, medical images
often suffer from challenges like noise, artifacts, and low contrast, which
limit their diagnostic potential. Addressing these challenges requires robust
preprocessing, denoising algorithms, and advanced enhancement methods, with
deep learning techniques playing an increasingly significant role. This
systematic literature review, following the PRISMA approach, investigates the
key challenges, recent advancements, and evaluation metrics in medical image
enhancement. By analyzing findings from 39 peer-reviewed studies, this review
provides insights into the effectiveness of various enhancement methods across
different imaging modalities and the importance of evaluation metrics in
assessing their impact. Key issues like low contrast and noise are identified
as the most frequent, with MRI and multi-modal imaging receiving the most
attention, while specialized modalities such as histopathology, endoscopy, and
bone scintigraphy remain underexplored. Out of the 39 studies, 29 utilize
conventional mathematical methods, 9 focus on deep learning techniques, and 1
explores a hybrid approach. In terms of image quality assessment, 18 studies
employ both reference-based and non-reference-based metrics, 9 rely solely on
reference-based metrics, and 12 use only non-reference-based metrics, with a
total of 65 IQA metrics introduced, predominantly non-reference-based. This
review highlights current limitations, research gaps, and potential future
directions for advancing medical image enhancement.

</details>


### [72] [Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection](https://arxiv.org/abs/2510.13643)
*Akib Mohammed Khan,Bartosz Krawczyk*

Main category: cs.CV

TL;DR: DINOv2等基础模型在少样本异常检测中表现出色，但对其对抗扰动的敏感性及不确定性估计的校准存在疑问。本文提出了一种基于DINOv2特征的训练免费深度最近邻检测器，并进行了首次系统的对抗攻击和不确定性估计研究。通过附加轻量级线性头部以进行扰动生成，研究发现在MVTec-AD和VisA数据集上，FGSM攻击可导致F1、AUROC、AP和G-mean值显著下降，表明微小扰动即可改变特征空间中的最近邻关系，导致误分类。同时，原始异常分数校准不佳，置信度与正确率之间存在差距。为解决此问题，本文应用Platt Scaling进行后验不确定性估计，显著提高了受扰动输入的预测熵，实现了有效的攻击检测，并降低了校准误差（ECE）。研究结果揭示了DINOv2基础少样本异常检测器的具体脆弱性，并为鲁棒、不确定性感知异常检测建立了评估方案和基线。本文强调，对抗鲁棒性和原则性不确定性量化对于可信赖的实际部署至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究DINOv2等基础模型在少样本异常检测中的对抗鲁棒性和不确定性校准问题，以评估其在实际应用中的可靠性。

Method: 提出了一种基于DINOv2特征的训练免费深度最近邻检测器（AnomalyDINO），并采用轻量级线性头部进行对抗扰动生成（如FGSM），同时研究了Platt Scaling在异常分数上的后验不确定性估计。

Result: 在MVTec-AD和VisA数据集上，FGSM攻击显著降低了检测器的F1、AUROC、AP和G-mean值。原始异常分数校准不佳，但经Platt Scaling校准后的分数能有效区分干净和受扰动输入，降低了校准误差（ECE），并提高了预测熵。

Conclusion: DINOv2基础的少样本异常检测器存在对抗脆弱性和不确定性校准不足的问题。对抗鲁棒性和不确定性量化对于构建可信赖的异常检测系统至关重要，并提出了相应的评估基线。

Abstract: Foundation models such as DINOv2 have shown strong performance in few-shot
anomaly detection, yet two key questions remain unexamined: (i) how susceptible
are these detectors to adversarial perturbations; and (ii) how well do their
anomaly scores reflect calibrated uncertainty? Building on AnomalyDINO, a
training-free deep nearest-neighbor detector over DINOv2 features, we present
one of the first systematic studies of adversarial attacks and uncertainty
estimation in this setting. To enable white-box gradient attacks while
preserving test-time behavior, we attach a lightweight linear head to frozen
DINOv2 features only for crafting perturbations. Using this heuristic, we
evaluate the impact of FGSM across the MVTec-AD and VisA datasets and observe
consistent drops in F1, AUROC, AP, and G-mean, indicating that imperceptible
perturbations can flip nearest-neighbor relations in feature space to induce
confident misclassification. Complementing robustness, we probe reliability and
find that raw anomaly scores are poorly calibrated, revealing a gap between
confidence and correctness that limits safety-critical use. As a simple, strong
baseline toward trustworthiness, we apply post-hoc Platt scaling to the anomaly
scores for uncertainty estimation. The resulting calibrated posteriors yield
significantly higher predictive entropy on adversarially perturbed inputs than
on clean ones, enabling a practical flagging mechanism for attack detection
while reducing calibration error (ECE). Our findings surface concrete
vulnerabilities in DINOv2-based few-shot anomaly detectors and establish an
evaluation protocol and baseline for robust, uncertainty-aware anomaly
detection. We argue that adversarial robustness and principled uncertainty
quantification are not optional add-ons but essential capabilities if anomaly
detection systems are to be trustworthy and ready for real-world deployment.

</details>


### [73] [Local-Global Context-Aware and Structure-Preserving Image Super-Resolution](https://arxiv.org/abs/2510.13649)
*Sanchar Palit,Subhasis Chaudhuri,Biplab Banerjee*

Main category: cs.CV

TL;DR: 提出了一种新的图像超分辨率框架，利用预训练的文本到图像模型，通过局部-全局上下文感知注意力和像素空间中的分布和感知对齐的条件机制，生成高质量、结构一致且细节逼真的图像，解决了现有方法在处理多样化和高度降级图像时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本到图像的超分辨率方法在处理多样化和高度降级的图像时，容易出现噪声放大或内容生成错误的问题。

Method: 提出了一种上下文精确的图像超分辨率框架，采用局部-全局上下文感知注意力机制来维护像素的局部和全局关系，并通过像素空间中的分布和感知对齐的条件机制来增强感知保真度。

Result: 该方法在多个超分辨率基准测试中表现出色，能够生成高质量、结构一致且细节逼真的图像，有效减轻了伪影并确保了逼真的细节恢复。

Conclusion: 所提出的框架通过创新的注意力机制和条件机制，在图像超分辨率任务上取得了显著的进展，能够生成高保真度和感知准确的重建图像。

Abstract: Diffusion models have recently achieved significant success in various image
manipulation tasks, including image super-resolution and perceptual quality
enhancement. Pretrained text-to-image models, such as Stable Diffusion, have
exhibited strong capabilities in synthesizing realistic image content, which
makes them particularly attractive for addressing super-resolution tasks. While
some existing approaches leverage these models to achieve state-of-the-art
results, they often struggle when applied to diverse and highly degraded
images, leading to noise amplification or incorrect content generation. To
address these limitations, we propose a contextually precise image
super-resolution framework that effectively maintains both local and global
pixel relationships through Local-Global Context-Aware Attention, enabling the
generation of high-quality images. Furthermore, we propose a distribution- and
perceptual-aligned conditioning mechanism in the pixel space to enhance
perceptual fidelity. This mechanism captures fine-grained pixel-level
representations while progressively preserving and refining structural
information, transitioning from local content details to the global structural
composition. During inference, our method generates high-quality images that
are structurally consistent with the original content, mitigating artifacts and
ensuring realistic detail restoration. Extensive experiments on multiple
super-resolution benchmarks demonstrate the effectiveness of our approach in
producing high-fidelity, perceptually accurate reconstructions.

</details>


### [74] [EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection](https://arxiv.org/abs/2510.13652)
*Huaizhi Qu,Ruichen Zhang,Shuqing Luo,Luchao Qi,Zhihao Zhang,Xiaoming Liu,Roni Sengupta,Tianlong Chen*

Main category: cs.CV

TL;DR: EditCast3D 使用视频生成基础模型来在 3D 数据集上进行编辑，解决了现有 3D 编辑方法计算成本高和效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 编辑方法难以集成计算成本高且 API 受限的图像编辑基础模型。

Method: EditCast3D 提出了一种新颖的流程，利用视频生成基础模型在 3D 数据集上进行编辑传播，并结合视图选择策略来提高一致性，最终实现无需代价高昂的优化即可进行前馈重建。

Result: 在常用的 3D 编辑数据集上，EditCast3D 取得了优于现有最先进方法的编辑质量和高效率。

Conclusion: EditCast3D 是一种可扩展且通用的范例，可将基础模型集成到 3D 编辑流程中，有效解决了现有方法的局限性。

Abstract: Recent advances in foundation models have driven remarkable progress in image
editing, yet their extension to 3D editing remains underexplored. A natural
approach is to replace the image editing modules in existing workflows with
foundation models. However, their heavy computational demands and the
restrictions and costs of closed-source APIs make plugging these models into
existing iterative editing strategies impractical. To address this limitation,
we propose EditCast3D, a pipeline that employs video generation foundation
models to propagate edits from a single first frame across the entire dataset
prior to reconstruction. While editing propagation enables dataset-level
editing via video models, its consistency remains suboptimal for 3D
reconstruction, where multi-view alignment is essential. To overcome this,
EditCast3D introduces a view selection strategy that explicitly identifies
consistent and reconstruction-friendly views and adopts feedforward
reconstruction without requiring costly refinement. In combination, the
pipeline both minimizes reliance on expensive image editing and mitigates
prompt ambiguities that arise when applying foundation models independently
across images. We evaluate EditCast3D on commonly used 3D editing datasets and
compare it against state-of-the-art 3D editing baselines, demonstrating
superior editing quality and high efficiency. These results establish
EditCast3D as a scalable and general paradigm for integrating foundation models
into 3D editing pipelines. The code is available at
https://github.com/UNITES-Lab/EditCast3D

</details>


### [75] [OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild](https://arxiv.org/abs/2510.13660)
*Hongyu Qu,Jianan Wei,Xiangbo Shu,Yazhou Yao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: OmniGaze是一个半监督的3D注视估计框架，利用大量无标签数据来解决领域泛化问题，通过伪标签和奖励模型提高模型性能，并在多个数据集上实现了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前的3D注视估计方法在不同数据域之间的泛化能力不足，主要原因是标注数据集稀缺且多样性不足。

Method: OmniGaze框架首先收集包含不同面部外观、环境、光照、头部姿态和眼部遮挡的无标签图像。该框架采用标准的伪标签策略，并设计了一个奖励模型来评估伪标签的可靠性。奖励模型不仅考虑3D方向向量，还整合了视觉编码器的视觉嵌入和多模态大语言模型的语义线索来计算置信度分数，用于选择和加权伪标签。

Result: 实验结果表明，OmniGaze在五个数据集的域内和跨域设置下均达到了最先进的性能。此外，OmniGaze作为可扩展的数据引擎，在四个未见过的数据集上展现了强大的零样本泛化能力。

Conclusion: OmniGaze通过利用大规模无标签数据和创新的伪标签奖励机制，有效解决了3D注视估计中的领域泛化难题，并在各种设定下取得了优异的性能。

Abstract: Current 3D gaze estimation methods struggle to generalize across diverse data
domains, primarily due to i) the scarcity of annotated datasets, and ii) the
insufficient diversity of labeled data. In this work, we present OmniGaze, a
semi-supervised framework for 3D gaze estimation, which utilizes large-scale
unlabeled data collected from diverse and unconstrained real-world environments
to mitigate domain bias and generalize gaze estimation in the wild. First, we
build a diverse collection of unlabeled facial images, varying in facial
appearances, background environments, illumination conditions, head poses, and
eye occlusions. In order to leverage unlabeled data spanning a broader
distribution, OmniGaze adopts a standard pseudo-labeling strategy and devises a
reward model to assess the reliability of pseudo labels. Beyond pseudo labels
as 3D direction vectors, the reward model also incorporates visual embeddings
extracted by an off-the-shelf visual encoder and semantic cues from gaze
perspective generated by prompting a Multimodal Large Language Model to compute
confidence scores. Then, these scores are utilized to select high-quality
pseudo labels and weight them for loss computation. Extensive experiments
demonstrate that OmniGaze achieves state-of-the-art performance on five
datasets under both in-domain and cross-domain settings. Furthermore, we also
evaluate the efficacy of OmniGaze as a scalable data engine for gaze
estimation, which exhibits robust zero-shot generalization on four unseen
datasets.

</details>


### [76] [CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas](https://arxiv.org/abs/2510.13669)
*Zian Li,Muhan Zhang*

Main category: cs.CV

TL;DR: CanvasMAR通过引入“画布”机制（即下一帧的模糊全局预测）来解决视频掩码自回归模型（MAR）的慢启动和误差累积问题，并结合了组合分类器自由引导和基于噪声的画布增强，从而在更少的自回归步骤中生成高质量视频。


<details>
  <summary>Details</summary>
Motivation: 视频MAR模型存在慢启动和误差累积问题，影响了视频生成质量和效率。

Method: 提出CanvasMAR模型，引入画布机制作为掩码生成的起点，并结合组合分类器自由引导和基于噪声的画布增强来解决上述问题。

Result: CanvasMAR在BAIR和Kinetics-600数据集上生成了高质量视频，并且在Kinetics-600数据集上取得了优于其他自回归模型，并可与扩散模型相媲美的性能。

Conclusion: CanvasMAR通过画布机制和组合分类器自由引导等创新方法，有效解决了视频MAR模型的挑战，实现了更高效、更高质量的视频生成。

Abstract: Masked autoregressive models (MAR) have recently emerged as a powerful
paradigm for image and video generation, combining the flexibility of masked
modeling with the potential of continuous tokenizer. However, video MAR models
suffer from two major limitations: the slow-start problem, caused by the lack
of a structured global prior at early sampling stages, and error accumulation
across the autoregression in both spatial and temporal dimensions. In this
work, we propose CanvasMAR, a novel video MAR model that mitigates these issues
by introducing a canvas mechanism--a blurred, global prediction of the next
frame, used as the starting point for masked generation. The canvas provides
global structure early in sampling, enabling faster and more coherent frame
synthesis. Furthermore, we introduce compositional classifier-free guidance
that jointly enlarges spatial (canvas) and temporal conditioning, and employ
noise-based canvas augmentation to enhance robustness. Experiments on the BAIR
and Kinetics-600 benchmarks demonstrate that CanvasMAR produces high-quality
videos with fewer autoregressive steps. Our approach achieves remarkable
performance among autoregressive models on Kinetics-600 dataset and rivals
diffusion-based methods.

</details>


### [77] [NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results](https://arxiv.org/abs/2510.13670)
*Xiaoning Liu,Zongwei Wu,Florin-Alexandru Vasluianu,Hailong Yan,Bin Ren,Yulun Zhang,Shuhang Gu,Le Zhang,Ce Zhu,Radu Timofte,Kangbiao Shi,Yixu Feng,Tao Hu,Yu Cao,Peng Wu,Yijin Liang,Yanning Zhang,Qingsen Yan,Han Zhou,Wei Dong,Yan Min,Mohab Kishawy,Jun Chen,Pengpeng Yu,Anjin Park,Seung-Soo Lee,Young-Joon Park,Zixiao Hu,Junyv Liu,Huilin Zhang,Jun Zhang,Fei Wan,Bingxin Xu,Hongzhe Liu,Cheng Xu,Weiguo Pan,Songyin Dai,Xunpeng Yi,Qinglong Yan,Yibing Zhang,Jiayi Ma,Changhui Hu,Kerui Hu,Donghang Jing,Tiesheng Chen,Zhi Jin,Hongjun Wu,Biao Huang,Haitao Ling,Jiahao Wu,Dandan Zhan,G Gyaneshwar Rao,Vijayalaxmi Ashok Aralikatti,Nikhil Akalwadi,Ramesh Ashok Tabib,Uma Mudenagudi,Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai,Qirui Yang,Alexandru Brateanu,Ciprian Orhei,Cosmin Ancuti,Daniel Feijoo,Juan C. Benito,Álvaro García,Marcos V. Conde,Yang Qin,Raul Balmez,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Tianyi Mao,Huan Zheng,Yanyan Wei,Shengeng Tang,Dan Guo,Zhao Zhang,Sabari Nathan,K Uma,A Sasithradevi,B Sathya Bama,S. Mohamed Mansoor Roomi,Ao Li,Xiangtao Zhang,Zhe Liu,Yijie Tang,Jialong Tang,Zhicheng Fu,Gong Chen,Joe Nasti,John Nicholson,Zeyu Xiao,Zhuoyuan Li,Ashutosh Kulkarni,Prashant W. Patil,Santosh Kumar Vipparthi,Subrahmanyam Murala,Duan Liu,Weile Li,Hangyuan Lu,Rixian Liu,Tengfeng Wang,Jinxing Liang,Chenxin Yu*

Main category: cs.CV

TL;DR: 该论文总结了 NTIRE 2025 低光图像增强（LLIE）挑战赛，重点介绍了参赛方案和最终结果。


<details>
  <summary>Details</summary>
Motivation: LLIE 挑战赛旨在寻找在各种挑战性条件下生成更亮、更清晰、视觉效果更佳图像的有效网络。

Method: 对 LLIE 领域的最新进展进行了全面评估，展示了显著的进步。

Result: 共有 762 名参赛者注册，28 支队伍提交了有效参赛作品。

Conclusion: 论文展示了 LLIE 领域的重大进展。

Abstract: This paper presents a comprehensive review of the NTIRE 2025 Low-Light Image
Enhancement (LLIE) Challenge, highlighting the proposed solutions and final
outcomes. The objective of the challenge is to identify effective networks
capable of producing brighter, clearer, and visually compelling images under
diverse and challenging conditions. A remarkable total of 762 participants
registered for the competition, with 28 teams ultimately submitting valid
entries. This paper thoroughly evaluates the state-of-the-art advancements in
LLIE, showcasing the significant progress.

</details>


### [78] [Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning](https://arxiv.org/abs/2510.13675)
*Hongkuan Zhou,Lavdim Halilaj,Sebastian Monka,Stefan Schmid,Yuqicheng Zhu,Jingcheng Wu,Nadeem Nazer,Steffen Staab*

Main category: cs.CV

TL;DR: KnowCoL框架通过结合图像、文本描述和Wikidata的结构化信息，在开放域视觉实体识别任务上取得了显著进展，尤其是在处理罕见和未见实体方面。


<details>
  <summary>Details</summary>
Motivation: 开放域视觉实体识别任务的挑战在于其开放集条件、有限的监督、高度的视觉歧义以及语义消歧的需求，因为大部分目标实体在训练时是未见的并且呈现长尾分布。

Method: 提出了一种名为KnowCoL（Knowledge-guided Contrastive Learning）的框架，该框架将图像和文本描述整合到一个共享的语义空间中，并利用Wikidata中的结构化信息进行指导。通过将视觉和文本输入抽象到概念层面，模型利用实体描述、类型层次结构和关系上下文来支持零样本实体识别。

Result: 在OVEN基准测试（一个大型开放域视觉识别数据集）上的实验表明，结合视觉、文本和结构化知识能够显著提高准确率，特别是对于罕见和未见实体。最小的模型在未见实体上的准确率比现有技术提高了10.5%，同时模型体积减小了35倍。

Conclusion: KnowCoL框架通过有效利用多模态信息和结构化知识，能够更好地处理开放域视觉实体识别中的长尾分布和零样本学习挑战，并在准确性和模型效率方面超越了现有技术。

Abstract: Open-domain visual entity recognition aims to identify and link entities
depicted in images to a vast and evolving set of real-world concepts, such as
those found in Wikidata. Unlike conventional classification tasks with fixed
label sets, it operates under open-set conditions, where most target entities
are unseen during training and exhibit long-tail distributions. This makes the
task inherently challenging due to limited supervision, high visual ambiguity,
and the need for semantic disambiguation. In this work, we propose a
Knowledge-guided Contrastive Learning (KnowCoL) framework that combines both
images and text descriptions into a shared semantic space grounded by
structured information from Wikidata. By abstracting visual and textual inputs
to a conceptual level, the model leverages entity descriptions, type
hierarchies, and relational context to support zero-shot entity recognition. We
evaluate our approach on the OVEN benchmark, a large-scale open-domain visual
recognition dataset with Wikidata IDs as the label space. Our experiments show
that using visual, textual, and structured knowledge greatly improves accuracy,
especially for rare and unseen entities. Our smallest model improves the
accuracy on unseen entities by 10.5% compared to the state-of-the-art, despite
being 35 times smaller.

</details>


### [79] [FlashWorld: High-quality 3D Scene Generation within Seconds](https://arxiv.org/abs/2510.13678)
*Xinyang Li,Tengfei Wang,Zixiao Gu,Shengchuan Zhang,Chunchao Guo,Liujuan Cao*

Main category: cs.CV

TL;DR: FlashWorld是一个比现有方法快10-100倍、渲染质量更高的3D场景生成模型，它直接生成3D高斯表示，而不是依赖多视图重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法速度慢且视觉质量有待提高，FlashWorld旨在通过创新的3D导向方法解决这些问题。

Method: FlashWorld采用一种创新的3D导向方法，直接在多视图生成过程中产生3D高斯表示。通过引入双模式预训练和跨模式后训练蒸馏，结合了多视图和3D导向方法的优点，并利用视频扩散模型和大规模单视图图像/文本提示来提高生成质量和泛化能力。

Result: FlashWorld在生成速度和渲染质量上均优于现有方法，并能保持3D一致性。

Conclusion: FlashWorld通过其新颖的3D导向方法、创新的训练策略和对大规模数据的利用，显著提高了3D场景生成的效率和质量。

Abstract: We propose FlashWorld, a generative model that produces 3D scenes from a
single image or text prompt in seconds, 10~100$\times$ faster than previous
works while possessing superior rendering quality. Our approach shifts from the
conventional multi-view-oriented (MV-oriented) paradigm, which generates
multi-view images for subsequent 3D reconstruction, to a 3D-oriented approach
where the model directly produces 3D Gaussian representations during multi-view
generation. While ensuring 3D consistency, 3D-oriented method typically suffers
poor visual quality. FlashWorld includes a dual-mode pre-training phase
followed by a cross-mode post-training phase, effectively integrating the
strengths of both paradigms. Specifically, leveraging the prior from a video
diffusion model, we first pre-train a dual-mode multi-view diffusion model,
which jointly supports MV-oriented and 3D-oriented generation modes. To bridge
the quality gap in 3D-oriented generation, we further propose a cross-mode
post-training distillation by matching distribution from consistent 3D-oriented
mode to high-quality MV-oriented mode. This not only enhances visual quality
while maintaining 3D consistency, but also reduces the required denoising steps
for inference. Also, we propose a strategy to leverage massive single-view
images and text prompts during this process to enhance the model's
generalization to out-of-distribution inputs. Extensive experiments demonstrate
the superiority and efficiency of our method.

</details>


### [80] [Generating healthy counterfactuals with denoising diffusion bridge models](https://arxiv.org/abs/2510.13684)
*Ana Lawry Aguila,Peirong Liu,Marina Crespo Aguirre,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: DDPMs can generate healthy counterfactuals, but struggle to balance anomaly removal with subject-specific features. We propose using DDBMs, which condition on both healthy and pathological images, to generate counterfactuals that preserve anatomy while selectively removing pathology. DDBMs outperform other diffusion models and supervised approaches on segmentation and anomaly detection tasks.


<details>
  <summary>Details</summary>
Motivation: Generating healthy counterfactuals from pathological images is important for medical imaging applications like anomaly detection, but current methods like DDPMs struggle to balance anomaly removal with preserving subject-specific anatomical features. 

Method: We propose a novel application of denoising diffusion bridge models (DDBMs), which condition the diffusion process on both a healthy image (initial point) and a corresponding synthetic pathological image (final point). This treats the pathological image as a structurally informative prior to guide the generation of counterfactuals.

Result: Our DDBM approach outperforms previously proposed diffusion models and fully supervised approaches in segmentation and anomaly detection tasks.

Conclusion: DDBMs offer a way to generate healthy counterfactuals that effectively balance anomaly removal with the retention of subject-specific features, outperforming existing methods in relevant medical imaging tasks.

Abstract: Generating healthy counterfactuals from pathological images holds significant
promise in medical imaging, e.g., in anomaly detection or for application of
analysis tools that are designed for healthy scans. These counterfactuals
should represent what a patient's scan would plausibly look like in the absence
of pathology, preserving individual anatomical characteristics while modifying
only the pathological regions. Denoising diffusion probabilistic models (DDPMs)
have become popular methods for generating healthy counterfactuals of pathology
data. Typically, this involves training on solely healthy data with the
assumption that a partial denoising process will be unable to model disease
regions and will instead reconstruct a closely matched healthy counterpart.
More recent methods have incorporated synthetic pathological images to better
guide the diffusion process. However, it remains challenging to guide the
generative process in a way that effectively balances the removal of anomalies
with the retention of subject-specific features. To solve this problem, we
propose a novel application of denoising diffusion bridge models (DDBMs) -
which, unlike DDPMs, condition the diffusion process not only on the initial
point (i.e., the healthy image), but also on the final point (i.e., a
corresponding synthetically generated pathological image). Treating the
pathological image as a structurally informative prior enables us to generate
counterfactuals that closely match the patient's anatomy while selectively
removing pathology. The results show that our DDBM outperforms previously
proposed diffusion models and fully supervised approaches at segmentation and
anomaly detection tasks.

</details>


### [81] [Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2510.13698)
*Jonghyun Park,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为风险自适应激活转向（RAS）的新方法，用于提高AI模型在处理包含潜在有害信息的图像查询时的安全性，同时保持其处理良性查询的能力，并优化了推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在区分良性和恶意查询（尤其是涉及图像的模态查询）方面面临挑战，现有的安全对齐方法成本高昂，而推理时对齐方法则存在过度拒绝和推理速度慢的问题。

Method: 提出风险自适应激活转向（RAS）方法，通过重构查询来增强跨模态对安全关键图像区域的注意力，从而在查询层面进行风险评估，并自适应地引导激活以生成安全且有用的响应，避免了迭代调整输出的开销。

Result: 在多模态安全和效用基准测试的广泛实验表明，RAS显著降低了攻击成功率，保持了通用任务性能，并提高了推理速度。

Conclusion: RAS方法能够有效解决现有AI模型在处理包含图像的模态查询时的安全对齐问题，并在安全性、效用和效率方面取得了优于现有推理时防御方法的表现。

Abstract: One of the key challenges of modern AI models is ensuring that they provide
helpful responses to benign queries while refusing malicious ones. But often,
the models are vulnerable to multimodal queries with harmful intent embedded in
images. One approach for safety alignment is training with extensive safety
datasets at the significant costs in both dataset curation and training.
Inference-time alignment mitigates these costs, but introduces two drawbacks:
excessive refusals from misclassified benign queries and slower inference speed
due to iterative output adjustments. To overcome these limitations, we propose
to reformulate queries to strengthen cross-modal attention to safety-critical
image regions, enabling accurate risk assessment at the query level. Using the
assessed risk, it adaptively steers activations to generate responses that are
safe and helpful without overhead from iterative output adjustments. We call
this Risk-adaptive Activation Steering (RAS). Extensive experiments across
multiple benchmarks on multimodal safety and utility demonstrate that the RAS
significantly reduces attack success rates, preserves general task performance,
and improves inference speed over prior inference-time defenses.

</details>


### [82] [MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion](https://arxiv.org/abs/2510.13702)
*Minjung Shin,Hyunin Cho,Sooyeon Go,Jin-Hwa Kim,Youngjung Uh*

Main category: cs.CV

TL;DR: 本文提出了一种名为MVCustom的新型扩散模型框架，用于解决现有模型在多视图生成和自定义方面的局限性，实现了既能进行相机姿态控制又能进行个性化定制的多视图生成。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多视图生成方面缺乏自定义能力，在自定义方面缺乏视图控制，难以统一。本文旨在解决这一差距，提出多视图自定义任务，以联合实现多视图相机姿态控制和自定义。

Method: MVCustom框架在训练阶段学习对象的身份和几何形状，并结合了文本到视频扩散模型和密集时空注意力机制，以实现多视图一致性。在推理阶段，采用了深度感知特征渲染和一致性感知潜在补全技术，以确保几何一致性和视角对齐。

Result: 实验证明，MVCustom是唯一能够同时实现忠实多视图生成和自定义的框架。

Conclusion: MVCustom成功地解决了多视图生成和自定义的统一问题，实现了精确的相机姿态控制和个性化定制，并在多视图生成和自定义方面取得了优异的实验结果。

Abstract: Multi-view generation with camera pose control and prompt-based customization
are both essential elements for achieving controllable generative models.
However, existing multi-view generation models do not support customization
with geometric consistency, whereas customization models lack explicit
viewpoint control, making them challenging to unify. Motivated by these gaps,
we introduce a novel task, multi-view customization, which aims to jointly
achieve multi-view camera pose control and customization. Due to the scarcity
of training data in customization, existing multi-view generation models, which
inherently rely on large-scale datasets, struggle to generalize to diverse
prompts. To address this, we propose MVCustom, a novel diffusion-based
framework explicitly designed to achieve both multi-view consistency and
customization fidelity. In the training stage, MVCustom learns the subject's
identity and geometry using a feature-field representation, incorporating the
text-to-video diffusion backbone enhanced with dense spatio-temporal attention,
which leverages temporal coherence for multi-view consistency. In the inference
stage, we introduce two novel techniques: depth-aware feature rendering
explicitly enforces geometric consistency, and consistent-aware latent
completion ensures accurate perspective alignment of the customized subject and
surrounding backgrounds. Extensive experiments demonstrate that MVCustom is the
only framework that simultaneously achieves faithful multi-view generation and
customization.

</details>


### [83] [Circle of Willis Centerline Graphs: A Dataset and Baseline Algorithm](https://arxiv.org/abs/2510.13720)
*Fabio Musio,Norman Juchler,Kaiyuan Yang,Suprosanna Shit,Chinmay Prabhakar,Bjoern Menze,Sven Hirsch*

Main category: cs.CV

TL;DR: 该研究提出了一种结合U-Net和A*图连接的基于学习的骨架化方法，用于从脑 Willis (CoW) 动脉环中提取可靠的中心线及其形态特征，并在TopCoW数据集上进行了验证，结果表明该方法在拓扑重建、节点距离、特征鲁棒性和预测能力方面均表现优异，并发布了数据集和算法以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 传统的骨架化技术难以从复杂的Willis环(CoW)动脉网络中提取可靠的中心线，且公开可用的中心线数据集稀缺，阻碍了对CoW的自动化量化分析。

Method: 研究者使用基于细化的骨架化算法从TopCoW数据集中提取中心线图谱和形态特征，并结合U-Net骨架化和A*图连接，开发了一个基线算法。该算法在包含200名卒中患者的MRA和CTA图像上进行了评估。

Result: 基线算法能够以高准确度（F1=1）重建图谱拓扑，预测图谱与参考图谱之间的平均欧氏节点距离小于一个体素。关键特征（如段半径、长度和分叉比率）的鲁棒性强，中值相对误差低于5%，皮尔逊相关系数高于0.95。此外，提取的特征能够有效预测胎儿PCA变异频率、验证理论分叉最优关系并检测细微的模态差异。

Conclusion: 基于学习的骨架化结合图连接方法能够生成解剖学上合理的中心线，并且该方法在提取中心线及其形态特征方面表现出色。研究强调了超越简单的基于体素的测量，评估解剖学准确性和特征鲁棒性的重要性。发布的数据集和基线算法将有助于未来的方法开发和临床研究。

Abstract: The Circle of Willis (CoW) is a critical network of arteries in the brain,
often implicated in cerebrovascular pathologies. Voxel-level segmentation is an
important first step toward an automated CoW assessment, but a full
quantitative analysis requires centerline representations. However,
conventional skeletonization techniques often struggle to extract reliable
centerlines due to the CoW's complex geometry, and publicly available
centerline datasets remain scarce. To address these challenges, we used a
thinning-based skeletonization algorithm to extract and curate centerline
graphs and morphometric features from the TopCoW dataset, which includes 200
stroke patients, each imaged with MRA and CTA. The curated graphs were used to
develop a baseline algorithm for centerline and feature extraction, combining
U-Net-based skeletonization with A* graph connection. Performance was evaluated
on a held-out test set, focusing on anatomical accuracy and feature robustness.
Further, we used the extracted features to predict the frequency of fetal PCA
variants, confirm theoretical bifurcation optimality relations, and detect
subtle modality differences. The baseline algorithm consistently reconstructed
graph topology with high accuracy (F1 = 1), and the average Euclidean node
distance between reference and predicted graphs was below one voxel. Features
such as segment radius, length, and bifurcation ratios showed strong
robustness, with median relative errors below 5% and Pearson correlations above
0.95. Our results demonstrate the utility of learning-based skeletonization
combined with graph connection for anatomically plausible centerline
extraction. We emphasize the importance of going beyond simple voxel-based
measures by evaluating anatomical accuracy and feature robustness. The dataset
and baseline algorithm have been released to support further method development
and clinical research.

</details>


### [84] [LiFMCR: Dataset and Benchmark for Light Field Multi-Camera Registration](https://arxiv.org/abs/2510.13729)
*Aymeric Fleith,Julian Zirbel,Daniel Cremers,Niclas Zeller*

Main category: cs.CV

TL;DR: LiFMCR是一个用于多微透镜阵列（MLA）光场相机注册的新型数据集，它提供了来自两台R32相机和Vicon运动捕捉系统的数据，并包含两种基线注册方法。


<details>
  <summary>Details</summary>
Motivation: 现有光场数据集在单相机设置方面存在局限性，并且通常缺乏外部真实性。LiFMCR旨在解决这些问题，为多相机光场注册方法提供严格的评估。

Method: 提出了一种使用跨视图点云的基于RANSAC的鲁棒3D变换估计方法，以及一种从单个光场图像估计外在6DoF位姿的光场PnP算法。这两种方法都显式地集成了光场相机模型。

Result: 实验结果与真实值高度一致，表明所提出的方法能够实现可靠的多视角光场处理。

Conclusion: LiFMCR数据集和提出的基线方法为多相机光场注册提供了基础，并促进了该领域的研究。

Abstract: We present LiFMCR, a novel dataset for the registration of multiple micro
lens array (MLA)-based light field cameras. While existing light field datasets
are limited to single-camera setups and typically lack external ground truth,
LiFMCR provides synchronized image sequences from two high-resolution Raytrix
R32 plenoptic cameras, together with high-precision 6-degrees of freedom (DoF)
poses recorded by a Vicon motion capture system. This unique combination
enables rigorous evaluation of multi-camera light field registration methods.
  As a baseline, we provide two complementary registration approaches: a robust
3D transformation estimation via a RANSAC-based method using cross-view point
clouds, and a plenoptic PnP algorithm estimating extrinsic 6-DoF poses from
single light field images. Both explicitly integrate the plenoptic camera
model, enabling accurate and scalable multi-camera registration. Experiments
show strong alignment with the ground truth, supporting reliable multi-view
light field processing.
  Project page: https://lifmcr.github.io/

</details>


### [85] [Cyclic Self-Supervised Diffusion for Ultra Low-field to High-field MRI Synthesis](https://arxiv.org/abs/2510.13735)
*Zhenxuan Zhang,Peiyuan Jing,Zi Wang,Ula Briski,Coraline Beitone,Yue Yang,Yinzhe Wu,Fanwen Wang,Liutao Yang,Jiahao Huang,Zhifan Gao,Zhaolin Chen,Kh Tohidul Islam,Guang Yang,Peter J. Lally*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CSS-Diff的循环自监督扩散框架，用于从低场MRI数据合成高场MRI图像，旨在解决低场MRI图像分辨率低、信噪比差以及合成图像在解剖保真度、细节增强和域适应性方面存在的不足。


<details>
  <summary>Details</summary>
Motivation: 低场MRI因其成本低、易于获取和安全性高等优点而具有巨大潜力，但其图像分辨率低和信噪比差的缺点限制了其应用。合成高场MRI图像可以克服这些限制，但现有方法在临床保真度方面仍存在差距，需要保留解剖结构保真度、增强精细结构细节并缩小图像对比度的域间差异。

Method: 研究提出了CSS-Diff框架，其核心思想是在扩散模型的基础上引入循环一致性约束，以在生成过程中强制保留解剖结构，而非仅仅依赖配对的像素级监督。此外，该框架还包含两个新颖的组件：切片间隙感知网络（slice-wise gap perception network），利用对比学习对齐切片间的که inconsistencies；以及局部结构校正网络（local structure correction network），通过对掩码和扰动块的自重构来增强局部特征恢复。

Result: 在跨场合成任务上的广泛实验表明，CSS-Diff方法取得了最先进的性能，在PSNR、SSIM和LPIPS等指标上分别达到了31.80 ± 2.70 dB、0.943 ± 0.102和0.0864 ± 0.0689。除了像素级保真度外，该方法在精细解剖结构方面也优于原始低场MRI，例如左侧脑白质误差从12.1%降至2.1%，皮层误差从4.2%降至3.7%。

Conclusion: CSS-Diff框架能够合成在定量和解剖一致性方面都可靠的图像，有效解决了低场MRI到高场MRI合成中的关键挑战。

Abstract: Synthesizing high-quality images from low-field MRI holds significant
potential. Low-field MRI is cheaper, more accessible, and safer, but suffers
from low resolution and poor signal-to-noise ratio. This synthesis process can
reduce reliance on costly acquisitions and expand data availability. However,
synthesizing high-field MRI still suffers from a clinical fidelity gap. There
is a need to preserve anatomical fidelity, enhance fine-grained structural
details, and bridge domain gaps in image contrast. To address these issues, we
propose a \emph{cyclic self-supervised diffusion (CSS-Diff)} framework for
high-field MRI synthesis from real low-field MRI data. Our core idea is to
reformulate diffusion-based synthesis under a cycle-consistent constraint. It
enforces anatomical preservation throughout the generative process rather than
just relying on paired pixel-level supervision. The CSS-Diff framework further
incorporates two novel processes. The slice-wise gap perception network aligns
inter-slice inconsistencies via contrastive learning. The local structure
correction network enhances local feature restoration through
self-reconstruction of masked and perturbed patches. Extensive experiments on
cross-field synthesis tasks demonstrate the effectiveness of our method,
achieving state-of-the-art performance (e.g., 31.80 $\pm$ 2.70 dB in PSNR,
0.943 $\pm$ 0.102 in SSIM, and 0.0864 $\pm$ 0.0689 in LPIPS). Beyond pixel-wise
fidelity, our method also preserves fine-grained anatomical structures compared
with the original low-field MRI (e.g., left cerebral white matter error drops
from 12.1$\%$ to 2.1$\%$, cortex from 4.2$\%$ to 3.7$\%$). To conclude, our
CSS-Diff can synthesize images that are both quantitatively reliable and
anatomically consistent.

</details>


### [86] [Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs](https://arxiv.org/abs/2510.13740)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: LogViG通过提出一种新的图构建方法LSGC来提高Vision GNN的性能，并通过引入高分辨率分支和多尺度特征融合来进一步增强，在图像分类和语义分割任务上取得了优于现有方法的准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision GNN（ViG）在图构建方法（如KNN）上存在计算成本高的问题，而SVGA的固定步长可能导致信息丢失。本文旨在提出一种新的图构建方法，以提高ViG的性能。

Method: 提出Logarithmic Scalable Graph Construction (LSGC) 方法来优化图的构建，并结合CNN和GNN提出LogViG模型。此外，引入高分辨率分支并实现多尺度特征融合。

Result: LogViG在图像分类和语义分割任务上，在准确率、GMACs和参数量方面均优于现有的ViG、CNN和ViT模型。其中，Ti-LogViG在ImageNet-1K上达到了79.9%的平均top-1准确率，参数量和GMACs分别减少了24.3%和35.3%。

Conclusion: 通过LSGC方法在图构建中利用长距离链接，可以超越当前最先进的Vision GNN的性能。

Abstract: Vision graph neural networks (ViG) have demonstrated promise in vision tasks
as a competitive alternative to conventional convolutional neural nets (CNN)
and transformers (ViTs); however, common graph construction methods, such as
k-nearest neighbor (KNN), can be expensive on larger images. While methods such
as Sparse Vision Graph Attention (SVGA) have shown promise, SVGA's fixed step
scale can lead to over-squashing and missing multiple connections to gain the
same information that could be gained from a long-range link. Through this
observation, we propose a new graph construction method, Logarithmic Scalable
Graph Construction (LSGC) to enhance performance by limiting the number of
long-range links. To this end, we propose LogViG, a novel hybrid CNN-GNN model
that utilizes LSGC. Furthermore, inspired by the successes of multi-scale and
high-resolution architectures, we introduce and apply a high-resolution branch
and fuse features between our high-resolution and low-resolution branches for a
multi-scale high-resolution Vision GNN network. Extensive experiments show that
LogViG beats existing ViG, CNN, and ViT architectures in terms of accuracy,
GMACs, and parameters on image classification and semantic segmentation tasks.
Our smallest model, Ti-LogViG, achieves an average top-1 accuracy on
ImageNet-1K of 79.9% with a standard deviation of 0.2%, 1.7% higher average
accuracy than Vision GNN with a 24.3% reduction in parameters and 35.3%
reduction in GMACs. Our work shows that leveraging long-range links in graph
construction for ViGs through our proposed LSGC can exceed the performance of
current state-of-the-art ViGs. Code is available at
https://github.com/mmunir127/LogViG-Official.

</details>


### [87] [UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy](https://arxiv.org/abs/2510.13745)
*Tianshuo Xu,Kai Wang,Zhifei Chen,Leyi Wu,Tianshui Wen,Fei Chao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: UniCalli是一个统一的扩散框架，用于中国书法中的列级识别和生成，实现了高质量的字符生成和精确的识别，并能推广到其他古代文字。


<details>
  <summary>Details</summary>
Motivation: 现有的书法计算复制方法在生成高质量的孤立字符与考虑页面级美学（如连字和间距）之间存在冲突，或者在页面合成时牺牲了书法本身的正确性。

Method: UniCalli采用联合训练的统一扩散框架，同时进行列级识别和生成。识别任务约束生成器保留字符结构，而生成任务则提供风格和布局的先验知识。该模型使用包含8000多份字帖的数据集，其中约4000份经过密集标注。它采用不对称加噪和光栅化框图来引入空间先验，并混合使用合成、标注和未标注数据进行训练。

Result: UniCalli在生成质量、连字连续性和布局保真度方面达到了最先进的水平，同时提高了识别性能。该框架还能成功应用于其他古代文字，如甲骨文和埃及象形文字。

Conclusion: UniCalli通过联合学习实现了书法识别和生成任务的协同增效，克服了现有方法的局限性，并在多种古代文字上展现了通用性和有效性。

Abstract: Computational replication of Chinese calligraphy remains challenging.
Existing methods falter, either creating high-quality isolated characters while
ignoring page-level aesthetics like ligatures and spacing, or attempting page
synthesis at the expense of calligraphic correctness. We introduce
\textbf{UniCalli}, a unified diffusion framework for column-level recognition
and generation. Training both tasks jointly is deliberate: recognition
constrains the generator to preserve character structure, while generation
provides style and layout priors. This synergy fosters concept-level
abstractions that improve both tasks, especially in limited-data regimes. We
curated a dataset of over 8,000 digitized pieces, with ~4,000 densely
annotated. UniCalli employs asymmetric noising and a rasterized box map for
spatial priors, trained on a mix of synthetic, labeled, and unlabeled data. The
model achieves state-of-the-art generative quality with superior ligature
continuity and layout fidelity, alongside stronger recognition. The framework
successfully extends to other ancient scripts, including Oracle bone
inscriptions and Egyptian hieroglyphs. Code and data can be viewed in
\href{https://github.com/EnVision-Research/UniCalli}{this URL}.

</details>


### [88] [InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue](https://arxiv.org/abs/2510.13747)
*Wenwen Tong,Hewei Guo,Dongchuan Ran,Jiangnan Chen,Jiefan Lu,Kaibin Wang,Keqiang Li,Xiaoxu Zhu,Jiakui Li,Kehan Li,Xueheng Li,Lumin Li,Chenxu Guo,Jiasheng Zhou,Jiandong Chen,Xianye Wu,Jiahao Wang,Silei Wu,Lei Chen,Hanming Deng,Yuxuan Song,Dinghao Zhou,Guiping Zhong,Ken Zheng,Shiyin Kang,Lewei Lu*

Main category: cs.CV

TL;DR: InteractiveOmni是一个统一且开源的轻量级全模态大语言模型（4B-8B参数），支持音频-视觉多轮交互，在理解和语音生成方面表现出色，优于现有开源模型，尤其在长时记忆能力方面。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一个轻量级、统一且开源的全模态大语言模型，以推动该领域的发展，并提供全面的全模态理解和语音生成能力，以实现类似人类的长期对话能力。

Method: 通过将视觉编码器、音频编码器、大语言模型和语音解码器集成到一个统一的模型中，并采用多阶段训练策略（包括全模态预训练、语音对话和视听交互后训练），以及构建包含多轮对话和视听交互的数据集，来实现对跨模态能力的鲁棒性。

Result: InteractiveOmni在多模态理解和语音生成任务上显著优于领先的开源模型，提供了更智能的多轮视听体验，尤其在长时记忆能力方面表现突出。InteractiveOmni-4B在通用基准测试上可与更大的Qwen2.5-Omni-7B相媲美，且在模型尺寸减半的情况下仍能保持InteractiveOmni-8B 97%的性能。在同等规模模型中，它在图像、音频、视频理解和语音生成任务上均取得了最先进的成果。

Conclusion: InteractiveOmni是一个可访问、开源的基础模型，为下一代智能交互系统奠定了基础，其优越的性能和高效的资源利用使其成为一个有前景的解决方案。

Abstract: We introduce InteractiveOmni, a unified and open-source omni-modal large
language model for audio-visual multi-turn interaction, ranging from 4B to 8B
parameters, designed to lead the field of lightweight models by offering
comprehensive omni-modal understanding and speech generation capabilities. To
achieve this, we integrate the vision encoder, audio encoder, large language
model, and speech decoder into a unified model for understanding and generation
tasks. We design a multi-stage training strategy to ensure robust cross-modal
capabilities, including pre-training for omni-modal understanding, followed by
post-training with speech conversation and audio-visual interaction. To enable
human-like long-term conversational ability, we meticulously curate a
multi-turn training dataset that enhances the model's ability to handle complex
and multi-turn interactions. To effectively evaluate the multi-turn memory and
speech interaction capabilities, we construct the multi-modal multi-turn memory
benchmark and the multi-turn speech interaction benchmark. Experiments
demonstrate that InteractiveOmni significantly outperforms leading open-source
models and provides a more intelligent multi-turn audio-visual experience,
particularly in its long-term memory capabilities. Notably, InteractiveOmni-4B
is comparable to the much larger model like Qwen2.5-Omni-7B on general
benchmarks, and it can retain 97% of the performance of the InteractiveOmni-8B
while utilizing only 50% of the model size. Achieving state-of-the-art results
against similarly sized models across image, audio, video understanding, and
speech generation tasks, InteractiveOmni is an accessible, open-source
foundation for next-generation intelligent interactive systems.

</details>


### [89] [RECODE: Reasoning Through Code Generation for Visual Question Answering](https://arxiv.org/abs/2510.13756)
*Junhong Shen,Mu Cai,Bo Hu,Ameet Talwalkar,David A Ross,Cordelia Schmid,Alireza Fathi*

Main category: cs.CV

TL;DR: MLLMs 在结构化视觉内容（如图表）的精确推理方面存在困难。我们提出了 RECODE 框架，利用“逆向渲染”（将视觉内容转换为可执行代码）来解决这个问题。RECODE 生成候选代码，通过评论者选择最佳代码，并进行迭代优化，从而实现可验证的视觉推理。实验表明，RECODE 在 CharXiv、ChartQA 和 Geometry3K 等基准测试中表现优于不使用代码或仅将代码用于辅助任务的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理图表等结构化视觉信息时，由于像素级感知缺乏验证机制，难以进行精确推理。本研究旨在解决这一挑战，提出一种新的可验证视觉推理方法。

Method: 我们提出 RECODE，一个基于代理的框架。该框架首先生成多个候选程序来复现输入的图像，然后利用一个评论者（critic）来选择最准确的复现，并迭代地优化代码。这种方法将模糊的感知任务转化为可验证的符号问题，并支持精确的计算和逻辑推理。

Result: 在 CharXiv、ChartQA 和 Geometry3K 等多个视觉推理基准测试中，RECODE 的表现显著优于那些不使用代码或仅使用代码绘制辅助线或裁剪的方法。

Conclusion: 将视觉感知与可执行代码相结合，为实现更准确、可验证的多模态推理提供了新的途径。

Abstract: Multimodal Large Language Models (MLLMs) struggle with precise reasoning for
structured visuals like charts and diagrams, as pixel-based perception lacks a
mechanism for verification. To address this, we propose to leverage derendering
-- the process of reverse-engineering visuals into executable code -- as a new
modality for verifiable visual reasoning. Specifically, we propose RECODE, an
agentic framework that first generates multiple candidate programs to reproduce
the input image. It then uses a critic to select the most faithful
reconstruction and iteratively refines the code. This process not only
transforms an ambiguous perceptual task into a verifiable, symbolic problem,
but also enables precise calculations and logical inferences later on. On
various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K,
RECODE significantly outperforms methods that do not leverage code or only use
code for drawing auxiliary lines or cropping. Our work demonstrates that
grounding visual perception in executable code provides a new path toward more
accurate and verifiable multimodal reasoning.

</details>


### [90] [Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark](https://arxiv.org/abs/2510.13759)
*Kai Zou,Ziqi Huang,Yuhao Dong,Shulin Tian,Dian Zheng,Hongbo Liu,Jingwen He,Bin Liu,Yu Qiao,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文提出了Uni-MMMU基准，用于评估统一多模态模型在视觉理解和生成方面的协同能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分评估多模态模型在理解和生成方面的真正整合能力，因此需要一个能够系统性地揭示跨领域推理任务中生成与理解之间双向协同作用的基准。

Method: 创建了一个名为Uni-MMMU的全面、学科感知的基准，该基准涵盖了八个以推理为中心的领域。每个任务都双向耦合，要求模型利用概念理解来指导视觉合成，或利用生成来辅助分析推理。该基准包含可验证的中间推理步骤、独特的基础事实以及用于文本和视觉输出的可复现评分协议。

Result: 通过对最先进的统一模型、仅生成模型和仅理解模型进行广泛评估，揭示了显著的性能差异和跨模态依赖性。

Conclusion: Uni-MMMU基准为了解这两种能力如何相互促进提供了新的见解，并为改进统一多模态模型奠定了可靠的基础。

Abstract: Unified multimodal models aim to jointly enable visual understanding and
generation, yet current benchmarks rarely examine their true integration.
Existing evaluations either treat the two abilities in isolation or overlook
tasks that inherently couple them. To address this gap, we present Uni-MMMU, a
comprehensive and discipline-aware benchmark that systematically unfolds the
bidirectional synergy between generation and understanding across eight
reasoning-centric domains, including science, coding, mathematics, and puzzles.
Each task is bidirectionally coupled, demanding models to (i) leverage
conceptual understanding to guide precise visual synthesis, or (ii) utilize
generation as a cognitive scaffold for analytical reasoning. Uni-MMMU
incorporates verifiable intermediate reasoning steps, unique ground truths, and
a reproducible scoring protocol for both textual and visual outputs. Through
extensive evaluation of state-of-the-art unified, generation-only, and
understanding-only models, we reveal substantial performance disparities and
cross-modal dependencies, offering new insights into when and how these
abilities reinforce one another, and establishing a reliable foundation for
advancing unified models.

</details>


### [91] [Scaling Vision Transformers for Functional MRI with Flat Maps](https://arxiv.org/abs/2510.13768)
*Connor Lane,Daniel Z. Kaplan,Tanishq Mathew Abraham,Paul S. Scotti*

Main category: cs.CV

TL;DR: 将4D fMRI数据转换为2D fMRI活动平面图视频，并使用MAE框架训练Vision Transformer，以实现fMRI数据的表征学习。


<details>
  <summary>Details</summary>
Motivation: 为使深度学习模型能够处理fMRI数据，需要解决fMRI数据表示的问题，并弥合fMRI与自然图像之间的模态鸿沟。

Method: 将4D fMRI数据转换为2D fMRI活动平面图视频，并使用MAE框架在2.3K小时的fMRI数据上训练Vision Transformer。

Result: 在fMRI数据建模中观察到，随着数据集大小的增加，掩码建模性能遵循严格的幂律关系。下游分类基准测试表明，所提出的模型能够学习到丰富的表征，支持跨被试的细粒度状态解码以及跨大脑状态变化的被试特定特征解码。

Conclusion: 所提出的方法能够有效地将fMRI数据转换为适合Vision Transformer处理的格式，并学习到有意义的表征，可用于fMRI数据的下游任务，如状态解码和特征解码。

Abstract: A key question for adapting modern deep learning architectures to functional
MRI (fMRI) is how to represent the data for model input. To bridge the modality
gap between fMRI and natural images, we transform the 4D volumetric fMRI data
into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K
hours of fMRI flat map videos from the Human Connectome Project using the
spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI
modeling performance improves with dataset size according to a strict power
scaling law. Downstream classification benchmarks show that our model learns
rich representations supporting both fine-grained state decoding across
subjects, as well as subject-specific trait decoding across changes in brain
state. This work is part of an ongoing open science project to build foundation
models for fMRI data. Our code and datasets are available at
https://github.com/MedARC-AI/fmri-fm.

</details>


### [92] [Generative Universal Verifier as Multimodal Meta-Reasoner](https://arxiv.org/abs/2510.13804)
*Xinchen Zhang,Xiaoying Zhang,Youbin Wu,Yanbin Cao,Renrui Zhang,Ruihang Chu,Ling Yang,Yujiu Yang*

Main category: cs.CV

TL;DR: 我们提出了Generative Universal Verifier（GUV），一个用于多模态模型的通用视觉验证器，并构建了ViVerBench基准来评估视觉结果的验证能力。结果表明现有模型表现不佳。我们训练了OmniVerifier-7B，这是第一个通用的生成式验证器，在ViVerBench上取得了显著的提升。此外，我们还提出了OmniVerifier-TTS，一个用于图像生成和编辑的测试时推理方法，在T2I-ReasonBench和GenEval++上均取得了改进。


<details>
  <summary>Details</summary>
Motivation: 目前的多模态模型在视觉结果验证方面存在不足，需要一种能够进行可靠视觉验证并进行反思和改进的能力。

Method: 1. 构建了ViVerBench基准，包含16个类别的关键任务，用于评估多模态推理中的视觉结果。2. 设计了自动化流水线来构建大规模视觉验证数据，并训练了首个通用的生成式验证器OmniVerifier-7B。3. 提出了OmniVerifier-TTS，一个序列化的测试时扩展范式，用于改进图像生成和编辑，并通过迭代优化来提升生成能力。

Result: 现有模型在ViVerBench基准上表现不佳，显示出与人类水平在可靠视觉验证方面存在差距。OmniVerifier-7B在ViVerBench上取得了+8.3的提升。OmniVerifier-TTS在T2I-ReasonBench上取得了+3.7的提升，在GenEval++上取得了+4.3的提升，优于现有的并行测试时扩展方法。

Conclusion: Generative Universal Verifier（GUV）通过引入可靠的视觉验证能力，提升了多模态模型的生成可靠性和可控性，是迈向更值得信赖的下一代推理系统的重要一步。

Abstract: We introduce Generative Universal Verifier, a novel concept and plugin
designed for next-generation multimodal reasoning in vision-language models and
unified multimodal models, providing the fundamental capability of reflection
and refinement on visual outcomes during the reasoning and generation process.
This work makes three main contributions: (1) We build ViVerBench, a
comprehensive benchmark spanning 16 categories of critical tasks for evaluating
visual outcomes in multimodal reasoning. Results show that existing VLMs
consistently underperform across these tasks, underscoring a substantial gap
from human-level capability in reliable visual verification. (2) We design two
automated pipelines to construct large-scale visual verification data and train
OmniVerifier-7B, the first omni-capable generative verifier trained for
universal visual verification and achieves notable gains on ViVerBench(+8.3).
Through training, we identify three atomic capabilities in visual verification
and demonstrate how they generalize and interact synergistically. (3) We
propose OmniVerifier-TTS, a sequential test-time scaling paradigm that
leverages the universal verifier to bridge image generation and editing within
unified models, enhancing the upper bound of generative ability through
iterative fine-grained optimization. Beyond generation, we extend universal
verifier to broader world-modeling interleaved reasoning scenarios.
Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7),
and GenEval++(+4.3), outperforming existing parallel test-time scaling methods,
such as Best-of-N. By endowing multimodal reasoning with reliable visual
verification, OmniVerifier advances both reliable reflection during generation
and scalable test-time refinement, marking a step toward more trustworthy and
controllable next-generation reasoning systems.

</details>


### [93] [Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation](https://arxiv.org/abs/2510.13787)
*Seyed Mohammad Mousavi,Morteza Analoui*

Main category: cs.CV

TL;DR: AVC框架通过自适应地利用视觉上下文并改进数据质量，在扩散模型故事续写方面取得了优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 故事续写需要有效利用视觉上下文并与文本保持语义一致，但现有方法在处理相关性不强的视觉信息时存在挑战。

Method: 提出AVC（自适应视觉条件）框架，利用CLIP模型检索相关图像，并在相关性不足时自适应地限制视觉信息的影响；同时，使用大型语言模型对数据集进行重新标注以提高数据质量。

Result: AVC在保持连贯性、语义一致性和视觉保真度方面优于现有基线，尤其在视觉信息与当前输入冲突时表现更佳。

Conclusion: AVC框架能够有效地利用视觉上下文，并能自适应地处理视觉信息的相关性，从而在故事续写任务中取得更好的效果。

Abstract: Story continuation focuses on generating the next image in a narrative
sequence so that it remains coherent with both the ongoing text description and
the previously observed images. A central challenge in this setting lies in
utilizing prior visual context effectively, while ensuring semantic alignment
with the current textual input. In this work, we introduce AVC (Adaptive Visual
Conditioning), a framework for diffusion-based story continuation. AVC employs
the CLIP model to retrieve the most semantically aligned image from previous
frames. Crucially, when no sufficiently relevant image is found, AVC adaptively
restricts the influence of prior visuals to only the early stages of the
diffusion process. This enables the model to exploit visual context when
beneficial, while avoiding the injection of misleading or irrelevant
information. Furthermore, we improve data quality by re-captioning a noisy
dataset using large language models, thereby strengthening textual supervision
and semantic alignment. Quantitative results and human evaluations demonstrate
that AVC achieves superior coherence, semantic consistency, and visual fidelity
compared to strong baselines, particularly in challenging cases where prior
visuals conflict with the current input.

</details>


### [94] [NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models](https://arxiv.org/abs/2510.13793)
*Nir Goren,Oren Katzir,Abhinav Nakarmi,Eyal Ronen,Mahmood Sharif,Or Patashnik*

Main category: cs.CV

TL;DR: 通过利用扩散模型生成过程中的随机种子来嵌入和验证水印，以解决视觉内容版权问题，无需访问模型权重，并引入了零知识证明来增强安全性。


<details>
  <summary>Details</summary>
Motivation: 在视觉内容生成日益依赖扩散模型的情况下，证明作者身份和保护版权变得至关重要，特别是当模型所有者不愿意或无法处理这些问题时，第三方验证的需求尤为突出。

Method: 提出了一种名为 NoisePrints 的轻量级水印方案，该方案利用初始化扩散过程的随机种子作为作者身份证明，而无需修改生成过程。通过将哈希函数集成到噪声采样过程中，并利用随机种子与生成内容的高度相关性，确保从内容中恢复有效种子的不可行性，并证明了替代种子的不可行性。此外，还引入了加密零知识证明来在不泄露种子的前提下证明所有权，从而提高了防移除的难度。

Result: 在多个最先进的图像和视频扩散模型上验证了 NoisePrints 方案，证明了仅使用种子和输出来进行高效验证是可行的，并且无需访问模型权重。

Conclusion: NoisePrints 是一种有效的、轻量级的、无需模型权重即可进行水印验证的方案，适用于图像和视频生成，并能通过零知识证明增强版权保护的安全性。

Abstract: With the rapid adoption of diffusion models for visual content generation,
proving authorship and protecting copyright have become critical. This
challenge is particularly important when model owners keep their models private
and may be unwilling or unable to handle authorship issues, making third-party
verification essential. A natural solution is to embed watermarks for later
verification. However, existing methods require access to model weights and
rely on computationally heavy procedures, rendering them impractical and
non-scalable. To address these challenges, we propose , a lightweight
watermarking scheme that utilizes the random seed used to initialize the
diffusion process as a proof of authorship without modifying the generation
process. Our key observation is that the initial noise derived from a seed is
highly correlated with the generated visual content. By incorporating a hash
function into the noise sampling process, we further ensure that recovering a
valid seed from the content is infeasible. We also show that sampling an
alternative seed that passes verification is infeasible, and demonstrate the
robustness of our method under various manipulations. Finally, we show how to
use cryptographic zero-knowledge proofs to prove ownership without revealing
the seed. By keeping the seed secret, we increase the difficulty of watermark
removal. In our experiments, we validate NoisePrints on multiple
state-of-the-art diffusion models for images and videos, demonstrating
efficient verification using only the seed and output, without requiring access
to model weights.

</details>


### [95] [Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs](https://arxiv.org/abs/2510.13795)
*Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CV

TL;DR: 我们提出了Honey-Data-15M数据集和HoneyPipe数据处理流程，以解决现有开源多模态大语言模型（MLLMs）在数据质量和复杂推理能力方面与专有模型之间的差距。通过对1500万个问答对进行清洗和链式思考（CoT）增强，我们训练了Bee-8B模型，其性能在完全开源MLLMs领域达到了新的SOTA水平，并能与一些半开源模型媲美。我们的工作还提供了包括数据集、数据处理流程、训练方法、评估工具和模型权重在内的资源，证明了高质量数据是开发高性能开源MLLMs的关键。


<details>
  <summary>Details</summary>
Motivation: 现有的开源多模态大语言模型（MLLMs）在数据质量，特别是复杂推理数据（如链式思考CoT）方面存在不足，导致其性能落后于专有模型。

Method: 我们提出了Honey-Data-15M数据集（包含约1500万个问答对），并采用多重数据清洗和双重（短、长）CoT增强策略。同时，我们开发了数据处理流程HoneyPipe及其框架DataStudio，以提供透明、可适应的数据处理方法。最后，我们使用Honey-Data-15M训练了8B参数的Bee-8B模型。

Result: Bee-8B模型在完全开源MLLMs中达到了新的SOTA水平，性能可与甚至超过InternVL3.5-8B等半开源模型。

Conclusion: 高质量的数据是开发能够与半开源模型竞争的完全开源MLLMs的关键途径。我们提供了Honey-Data-15M数据集、HoneyPipe数据处理流程、训练方法、评估工具和模型权重等资源，以支持社区的发展。

Abstract: Fully open multimodal large language models (MLLMs) currently lag behind
proprietary counterparts, primarily due to a significant gap in data quality
for supervised fine-tuning (SFT). Existing open-source datasets are often
plagued by widespread noise and a critical deficit in complex reasoning data,
such as Chain-of-Thought (CoT), which hinders the development of advanced model
capabilities. Addressing these challenges, our work makes three primary
contributions. First, we introduce Honey-Data-15M, a new SFT dataset comprising
approximately 15 million QA pairs, processed through multiple cleaning
techniques and enhanced with a novel dual-level (short and long) CoT enrichment
strategy. Second, we introduce HoneyPipe, the data curation pipeline, and its
underlying framework DataStudio, providing the community with a transparent and
adaptable methodology for data curation that moves beyond static dataset
releases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8B
model on Honey-Data-15M. Experiments show that Bee-8B establishes a new
state-of-the-art (SOTA) for fully open MLLMs, achieving performance that is
competitive with, and in some cases surpasses, recent semi-open models such as
InternVL3.5-8B. Our work delivers to the community a suite of foundational
resources, including: the Honey-Data-15M corpus; the full-stack suite
comprising HoneyPipe and DataStudio; training recipes; an evaluation harness;
and the model weights. This effort demonstrates that a principled focus on data
quality is a key pathway to developing fully open MLLMs that are highly
competitive with their semi-open counterparts.

</details>


### [96] [Reasoning in Space via Grounding in the World](https://arxiv.org/abs/2510.13800)
*Yiming Chen,Zekun Qi,Wenyao Zhang,Xin Jin,Li Zhang,Peidong Liu*

Main category: cs.CV

TL;DR: GS-Reasoner是一个首个集成了3D视觉基础和空间推理的3D语言模型，它使用一种新的双路径池化机制来统一语义、几何和位置信息，无需外部模块即可实现自动回归基础，并在GCoT数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D语言模型在统一的3D表示方面存在不足，无法有效结合语义和几何信息，导致在基础任务上表现不佳或过度依赖外部模块，阻碍了基础与空间推理的无缝集成。

Method: 提出了一种新的双路径池化机制，将几何特征与语义和位置线索对齐，构建了一个统一的、基于图像块的3D表示，该表示能够封装所有必要信息，同时不增加输入标记的数量。基于此表示，GS-Reasoner实现了完全不依赖外部模块的自回归基础。此外，引入了GCoT数据集，包含3D边界框注释和逐步推理路径，将基础作为解决问题过程的核心组成部分。

Result: GS-Reasoner实现了首个无需外部模块即可进行自回归基础的3D语言模型，其基础任务性能可与最先进模型相媲美。通过将基础与空间推理相结合，GS-Reasoner在GCoT数据集上显著提升了空间推理能力，达到了最先进的性能。

Conclusion: 3D视觉基础是空间推理的基石。GS-Reasoner通过其创新的统一3D表示和GCoT数据集，成功地弥合了3D视觉基础与空间推理之间的差距，展示了一个统一且自包含的3D空间推理框架，并在各项任务上取得了最先进的成果。

Abstract: In this paper, we claim that 3D visual grounding is the cornerstone of
spatial reasoning and introduce the Grounded-Spatial Reasoner (GS-Reasoner) to
explore the effective spatial representations that bridge the gap between them.
Existing 3D LLMs suffer from the absence of a unified 3D representation capable
of jointly capturing semantic and geometric information. This deficiency is
manifested either in poor performance on grounding or in an excessive reliance
on external modules, ultimately hindering the seamless integration of grounding
and spatial reasoning. To address this, we propose a simple yet effective
dual-path pooling mechanism that tightly aligns geometric features with both
semantic and positional cues, constructing a unified image patch-based 3D
representation that encapsulates all essential information without increasing
the number of input tokens. Leveraging this holistic representation,
GS-Reasoner is the first 3D LLM that achieves autoregressive grounding entirely
without external modules while delivering performance comparable to
state-of-the-art models, establishing a unified and self-contained framework
for 3D spatial reasoning. To further bridge grounding and spatial reasoning, we
introduce the Grounded Chain-of-Thought (GCoT) dataset. This dataset is
meticulously curated to include both 3D bounding box annotations for objects
referenced in reasoning questions and step-by-step reasoning paths that
integrate grounding as a core component of the problem-solving process.
Extensive experiments demonstrate that GS-Reasoner achieves impressive results
on 3D visual grounding, which in turn significantly enhances its spatial
reasoning capabilities, leading to state-of-the-art performance.

</details>


### [97] [Trace Anything: Representing Any Video in 4D via Trajectory Fields](https://arxiv.org/abs/2510.13802)
*Xinhang Liu,Yuxi Xiao,Donny Y. Chen,Jiashi Feng,Yu-Wing Tai,Chi-Keung Tang,Bingyi Kang*

Main category: cs.CV

TL;DR: 视频可以通过像素轨迹场表示，Trace Anything模型能一次性预测该场，实现高效的运动预测和分析。


<details>
  <summary>Details</summary>
Motivation: 视频中像素的连续3D时域轨迹是理解和预测视频动态的基础。

Method: 提出将视频表示为轨迹场，即为每帧的每个像素分配一个随时间变化的3D轨迹函数。引入Trace Anything神经网络，通过预测参数化B样条的控制点来表示像素轨迹，实现单次前向传播即可预测整个轨迹场。

Result: Trace Anything在轨迹场估计基准测试中达到SOTA，在点追踪基准测试中表现具有竞争力，并且实现了显著的效率提升，无需迭代优化或辅助估计器。

Conclusion: Trace Anything能够高效地估计视频轨迹场，并展现出目标条件操控、运动预测和时空融合等新兴能力。

Abstract: Effective spatio-temporal representation is fundamental to modeling,
understanding, and predicting dynamics in videos. The atomic unit of a video,
the pixel, traces a continuous 3D trajectory over time, serving as the
primitive element of dynamics. Based on this principle, we propose representing
any video as a Trajectory Field: a dense mapping that assigns a continuous 3D
trajectory function of time to each pixel in every frame. With this
representation, we introduce Trace Anything, a neural network that predicts the
entire trajectory field in a single feed-forward pass. Specifically, for each
pixel in each frame, our model predicts a set of control points that
parameterizes a trajectory (i.e., a B-spline), yielding its 3D position at
arbitrary query time instants. We trained the Trace Anything model on
large-scale 4D data, including data from our new platform, and our experiments
demonstrate that: (i) Trace Anything achieves state-of-the-art performance on
our new benchmark for trajectory field estimation and performs competitively on
established point-tracking benchmarks; (ii) it offers significant efficiency
gains thanks to its one-pass paradigm, without requiring iterative optimization
or auxiliary estimators; and (iii) it exhibits emergent abilities, including
goal-conditioned manipulation, motion forecasting, and spatio-temporal fusion.
Project page: https://trace-anything.github.io/.

</details>


### [98] [VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models](https://arxiv.org/abs/2510.13808)
*Dominick Reilly,Manish Kumar Govind,Le Xue,Srijan Das*

Main category: cs.CV

TL;DR: VisCoP是一种新颖的域适应方法，通过添加可学习的视觉探针来增强大型视觉语言模型的视觉编码器，以实现高效的领域特定适应，同时保留先验知识。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLM）在新领域可能面临性能下降，而现有的域适应方法可能导致领域特定特征学习有限或灾难性遗忘。

Method: VisCoP将一个紧凑的可学习视觉探针集添加到VLM的视觉编码器中，以实现高效的领域特定适应，并尽量减少对预训练参数的修改。

Result: VisCoP在三种具有挑战性的域适应设置（跨视图、跨模态和跨任务）中，始终优于现有的适应策略，在目标域上实现了卓越的性能，同时有效保留了源域知识。

Conclusion: VisCoP在不影响其通用能力的情况下，能够有效地使大型VLM适应新领域。

Abstract: Large Vision-Language Models (VLMs) excel at general visual reasoning tasks
but exhibit sharp performance degradation when applied to novel domains with
substantial distribution shifts from pretraining data. Existing domain
adaptation approaches finetune different VLM components, but this often results
in limited domain-specific feature learning or catastrophic forgetting of prior
capabilities. To address these issues, we introduce Vision Contextualized
Probing (VisCoP), which augments the VLM's vision encoder with a compact set of
learnable visual probes. These probes enable efficient domain-specific
adaptation with minimal modification to pretrained parameters. We evaluate
VisCoP across three challenging domain adaptation settings-cross-view
(exocentric to egocentric), cross-modal (RGB to depth), and cross-task (human
understanding to robot control). Experiments show that VisCoP consistently
outperforms existing adaptation strategies, achieving superior performance on
target domains while effectively retaining source-domain knowledge.

</details>


### [99] [PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.13809)
*Sihui Ji,Xi Chen,Xin Tao,Pengfei Wan,Hengshuang Zhao*

Main category: cs.CV

TL;DR: PhysMaster通过引入物理表示来增强视频生成模型的物理可信度，并使用基于人类反馈的强化学习进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型在遵循物理定律方面存在不足，限制了其生成物理上可信视频的能力，也无法作为“世界模型”。

Method: 提出PhysMaster，该模型从输入图像中编码物理信息（通过PhysEncoder），并将其作为额外条件来指导视频生成，以增强物理感知能力。PhysEncoder利用基于人类反馈的强化学习（特别是DPO）来学习物理表示，以优化物理性能。

Result: PhysMaster在一个简化的代理任务上被证明是有效的，并展现了其在广泛物理场景中的泛化能力。

Conclusion: PhysMaster通过表示学习和强化学习范式，为各种物理过程提供了一个统一的解决方案，可以作为物理感知视频生成及更广泛应用的通用即插即用解决方案。

Abstract: Video generation models nowadays are capable of generating visually realistic
videos, but often fail to adhere to physical laws, limiting their ability to
generate physically plausible videos and serve as ''world models''. To address
this issue, we propose PhysMaster, which captures physical knowledge as a
representation for guiding video generation models to enhance their
physics-awareness. Specifically, PhysMaster is based on the image-to-video task
where the model is expected to predict physically plausible dynamics from the
input image. Since the input image provides physical priors like relative
positions and potential interactions of objects in the scenario, we devise
PhysEncoder to encode physical information from it as an extra condition to
inject physical knowledge into the video generation process. The lack of proper
supervision on the model's physical performance beyond mere appearance
motivates PhysEncoder to apply reinforcement learning with human feedback to
physical representation learning, which leverages feedback from generation
models to optimize physical representations with Direct Preference Optimization
(DPO) in an end-to-end manner. PhysMaster provides a feasible solution for
improving physics-awareness of PhysEncoder and thus of video generation,
proving its ability on a simple proxy task and generalizability to wide-ranging
physical scenarios. This implies that our PhysMaster, which unifies solutions
for various physical processes via representation learning in the reinforcement
learning paradigm, can act as a generic and plug-in solution for physics-aware
video generation and broader applications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [100] [Benchmarking Open-Source Large Language Models for Persian in Zero-Shot and Few-Shot Learning](https://arxiv.org/abs/2510.12807)
*Mahdi Cherakhloo,Arash Abbasi,Mohammad Saeid Sarafraz,Bijan Vosoughi Vahdat*

Main category: cs.CL

TL;DR: Gemma 2 在波斯语 NLP 任务中表现最佳，但大多数模型在命名实体识别等任务上面临挑战。


<details>
  <summary>Details</summary>
Motivation: 评估开源大型语言模型（LLM）在波斯语自然语言处理（NLP）任务上的表现，尤其是在零样本和少样本学习范式下的能力。

Method: 在 ParsiNLU 和 ArmanEmo 等波斯语数据集上，对多个开源 LLM 在零样本和少样本场景下进行了评估，涵盖了情感分析、命名实体识别、阅读理解和问答等任务，并使用了准确率、F1 分数、BLEU 和 ROUGE 等指标。

Result: Gemma 2 在大多数任务中均优于其他模型，尤其在复杂推理任务上表现突出。然而，大多数模型在命名实体识别等令牌级理解任务上表现不佳。

Conclusion: 该研究为多语言 LLM 的研究做出了贡献，提供了关于其在波斯语中表现的宝贵见解，并为未来模型的开发提供了基准。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
numerous languages; however, their effectiveness in low-resource languages like
Persian requires thorough investigation. This paper presents a comprehensive
benchmark of several open-source LLMs for Persian Natural Language Processing
(NLP) tasks, utilizing both zero-shot and few-shot learning paradigms. We
evaluate models across a range of tasks including sentiment analysis, named
entity recognition, reading comprehension, and question answering, using
established Persian datasets such as ParsiNLU and ArmanEmo. Our methodology
encompasses rigorous experimental setups for both zero-shot and few-shot
scenarios, employing metrics such as Accuracy, F1-score, BLEU, and ROUGE for
performance evaluation. The results reveal that Gemma 2 consistently
outperforms other models across nearly all tasks in both learning paradigms,
with particularly strong performance in complex reasoning tasks. However, most
models struggle with token-level understanding tasks like Named Entity
Recognition, highlighting specific challenges in Persian language processing.
This study contributes to the growing body of research on multilingual LLMs,
providing valuable insights into their performance in Persian and offering a
benchmark for future model development.

</details>


### [101] [Cancer Diagnosis Categorization in Electronic Health Records Using Large Language Models and BioBERT: Model Performance Evaluation Study](https://arxiv.org/abs/2510.12813)
*Soheil Hashtarkhani,Rezaur Rashid,Christopher L Brett,Lokesh Chinthala,Fekede Asefa Kumsa,Janet A Zink,Robert L Davis,David L Schwartz,Arash Shaban-Nejad*

Main category: cs.CL

TL;DR: 本研究评估了5种大型语言模型（GPT-3.5、GPT-4o、Llama 3.2、Gemini 1.5和BioBERT）在对电子健康记录中的癌症诊断进行分类的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在评估不同大型语言模型在处理电子健康记录中的非结构化和结构化数据以进行癌症诊断分类的性能，并与临床可靠性进行比较。

Method: 使用4种大型语言模型（GPT-3.5、GPT-4o、Llama 3.2、Gemini 1.5）和BioBERT对3456个癌症患者记录中的762个独特诊断（ICD代码描述和自由文本）进行分类，并由肿瘤学专家进行验证。

Result: 在ICD代码分类方面，BioBERT的加权宏F1分数最高（84.2），在准确性上与GPT-4o相当（90.8）。在自由文本分类方面，GPT-4o的加权宏F1分数（71.8）和准确性（81.9）均优于BioBERT（分别为61.5和81.6）。GPT-3.5、Gemini和Llama的总体表现较低。常见的误分类包括转移性肿瘤与中枢神经系统肿瘤的混淆，以及涉及模糊或重叠的临床术语的错误。

Conclusion: 虽然现有模型的性能对于行政和研究用途可能足够，但要实现可靠的临床应用，还需要标准化的文档实践和强大的人工监督来支持高风险决策。

Abstract: Electronic health records contain inconsistently structured or free-text
data, requiring efficient preprocessing to enable predictive health care
models. Although artificial intelligence-driven natural language processing
tools show promise for automating diagnosis classification, their comparative
performance and clinical reliability require systematic evaluation. The aim of
this study is to evaluate the performance of 4 large language models (GPT-3.5,
GPT-4o, Llama 3.2, and Gemini 1.5) and BioBERT in classifying cancer diagnoses
from structured and unstructured electronic health records data. We analyzed
762 unique diagnoses (326 International Classification of Diseases (ICD) code
descriptions, 436free-text entries) from 3456 records of patients with cancer.
Models were tested on their ability to categorize diagnoses into 14predefined
categories. Two oncology experts validated classifications. BioBERT achieved
the highest weighted macro F1-score for ICD codes (84.2) and matched GPT-4o in
ICD code accuracy (90.8). For free-text diagnoses, GPT-4o outperformed BioBERT
in weighted macro F1-score (71.8 vs 61.5) and achieved slightly higher accuracy
(81.9 vs 81.6). GPT-3.5, Gemini, and Llama showed lower overall performance on
both formats. Common misclassification patterns included confusion between
metastasis and central nervous system tumors, as well as errors involving
ambiguous or overlapping clinical terminology. Although current performance
levels appear sufficient for administrative and research use, reliable clinical
applications will require standardized documentation practices alongside robust
human oversight for high-stakes decision-making.

</details>


### [102] [From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP](https://arxiv.org/abs/2510.12817)
*Shanshan Xu,Santosh T. Y. S. S,Barbara Plank*

Main category: cs.CL

TL;DR: HLV（人类标签变异）是标注中合法的分歧，反映了人类观点的多样性。过去被视为噪音，现在被重塑为提高模型鲁棒性的信号。LLM的兴起使得HLV日益重要。然而，当前的偏好学习数据集通常会将多个标注聚合为单一标签，抹杀了人类价值观的多元性。本文认为，在设计AI系统时，应将HLV视为一种内在目标，并呼吁积极将其纳入偏好数据集，并提出了具体实施步骤。


<details>
  <summary>Details</summary>
Motivation: 人类标签变异（HLV）反映了人类观点的真实多样性。在大型语言模型（LLM）的兴起和以人类反馈进行模型对齐的背景下，HLV的作用日益重要。然而，现有的偏好学习数据集常常聚合标注，抹杀了人类价值观的多元性，而这恰恰是模型对齐旨在保留的。

Method: 本文提出应将HLV视为AI设计中的一个内在目标（Selbstzweck），并呼吁在偏好数据集中主动纳入HLV。文章还提出了一些可行的实施步骤。

Result: (未在摘要中明确说明具体实验结果)

Conclusion: HLV代表了人类的多元性，在AI设计中应被视为一个内在目标。我们呼吁在偏好数据集中主动纳入HLV，并提出实现这一目标的具体方法。

Abstract: Human Label Variation (HLV) refers to legitimate disagreement in annotation
that reflects the genuine diversity of human perspectives rather than mere
error. For decades, HLV in NLP was dismissed as noise to be discarded, and only
slowly over the last decade has it been reframed as a signal for improving
model robustness. With the rise of large language models (LLMs), where
post-training on human feedback has become central to model alignment, the role
of HLV has become increasingly consequential. Yet current preference-learning
datasets routinely aggregate multiple annotations into a single label, thereby
flattening diverse perspectives into a false universal agreement and erasing
precisely the pluralism of human values that alignment aims to preserve. In
this position paper, we argue that preserving HLV as an embodiment of human
pluralism must be treated as a Selbstzweck - a goal it self when designing AI
systems. We call for proactively incorporating HLV into preference datasets and
outline actionable steps towards it.

</details>


### [103] [MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning](https://arxiv.org/abs/2510.12818)
*Rajarshi Ghosh,Abhay Gupta,Hudson McBride,Anurag Vaidya,Faisal Mahmood*

Main category: cs.CL

TL;DR: LLMs在临床决策支持中存在细微的性别偏见，MEDEQUALQA基准测试通过改变患者代词来评估GPT-4.1模型的推理稳定性，结果显示存在局部推理差异，可能导致护理不公。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在临床决策支持中，当仅改变患者代词（性别线索）时，其内部推理过程是否会发生变化，以及这种变化是否会引入偏见。

Method: 创建了一个名为MEDEQUALQA的基准测试，该测试通过改变临床案例中的患者代词（他/她/他们），同时保持关键症状和条件（CSCs）不变，生成了大约23,000个条目的三个并行数据集（总计69,000个）。然后使用GPT-4.1模型进行评估，并计算了不同代词版本推理过程之间的语义文本相似度（STS）。

Result: 尽管GPT-4.1模型在不同代词版本之间的平均STS得分较高（>0.80），表明整体推理稳定性较高，但在引用的风险因素、指南锚点和鉴别诊断的排序等方面，仍然存在持续的、局部的推理分歧。这些分歧即使在最终诊断保持不变的情况下也存在。

Conclusion: MEDEQUALQA基准测试揭示了在医疗AI中，即使是细微的性别线索变化也会导致LLM内部推理的局部差异，这些差异可能隐藏着临床上相关的偏见，并可能最终导致不公平的医疗实践。该基准测试为审计医疗AI的推理稳定性提供了一个受控的诊断环境。

Abstract: Large language models (LLMs) are increasingly deployed in clinical decision
support, yet subtle demographic cues can influence their reasoning. Prior work
has documented disparities in outputs across patient groups, but little is
known about how internal reasoning shifts under controlled demographic changes.
We introduce MEDEQUALQA, a counterfactual benchmark that perturbs only patient
pronouns (he/him, she/her, they/them) while holding critical symptoms and
conditions (CSCs) constant. Each clinical vignette is expanded into single-CSC
ablations, producing three parallel datasets of approximately 23,000 items each
(69,000 total). We evaluate a GPT-4.1 model and compute Semantic Textual
Similarity (STS) between reasoning traces to measure stability across pronoun
variants. Our results show overall high similarity (mean STS >0.80), but reveal
consistent localized divergences in cited risk factors, guideline anchors, and
differential ordering, even when final diagnoses remain unchanged. Our error
analysis highlights certain cases in which the reasoning shifts, underscoring
clinically relevant bias loci that may cascade into inequitable care.
MEDEQUALQA offers a controlled diagnostic setting for auditing reasoning
stability in medical AI.

</details>


### [104] [Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain](https://arxiv.org/abs/2510.13255)
*Jingmin An,Yilong Song,Ruolin Yang,Nai Ding,Lingxi Lu,Yuxuan Wang,Wei Wang,Chu Zhuang,Qian Wang,Fang Fang*

Main category: cs.CL

TL;DR: LLMs在处理句法结构方面表现出类人能力，但具体计算机制尚不清楚。本文提出HFTP工具，通过频域分析识别LLM和人脑中编码句法结构的神经元/皮层区域。研究发现，不同LLM在相似层级处理句法，而人脑依赖不同皮层区域处理不同句法层级。LLM表征与人脑左半球（语言优势半球）更一致。模型升级后，Gemma 2比Gemma更具类脑相似性，而Llama 3.1则比Llama 2类脑相似性更低。这引发了关于LLM进步是源于类人还是非类人机制的思考，并确立了HFTP作为连接计算语言学和认知神经科学的工具。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在语言能力方面与人脑机制的相似性，特别是句法结构的处理方式，以及模型能力提升背后的机制。

Method: 提出一种名为HFTP（Hierarchical Frequency Tagging Probe）的工具，利用频域分析来识别LLM（如MLP神经元）和人脑（通过颅内记录）中编码句法结构的神经元/皮层组件。通过表征相似性分析（RSA）来量化LLM与人脑在句法处理上的对齐程度。

Result: 1. 发现GPT-2、Gemma、Gemma 2、Llama 2、Llama 3.1和GLM-4等模型在相似的层级处理句法。2. 人类大脑依赖不同的皮层区域来处理不同层级的句法信息。3. LLM的表征与人脑左半球（语言处理优势侧）的相似度更高。4. 模型升级趋势：Gemma 2比Gemma更具类脑相似性；Llama 3.1比Llama 2的类脑相似性更低。5. 论文提供了HFTP工具的GitHub链接。

Conclusion: LLMs在句法处理上与人脑存在一定的相似性，尤其是在与人脑左半球的表征对齐方面。然而，模型能力的具体提升是源于类人机制还是非类人机制仍有待探讨。HFTP工具为理解LLM行为和连接计算语言学与认知神经科学提供了新的途径。

Abstract: Large Language Models (LLMs) demonstrate human-level or even superior
language abilities, effectively modeling syntactic structures, yet the specific
computational modules responsible remain unclear. A key question is whether LLM
behavioral capabilities stem from mechanisms akin to those in the human brain.
To address these questions, we introduce the Hierarchical Frequency Tagging
Probe (HFTP), a tool that utilizes frequency-domain analysis to identify
neuron-wise components of LLMs (e.g., individual Multilayer Perceptron (MLP)
neurons) and cortical regions (via intracranial recordings) encoding syntactic
structures. Our results show that models such as GPT-2, Gemma, Gemma 2, Llama
2, Llama 3.1, and GLM-4 process syntax in analogous layers, while the human
brain relies on distinct cortical regions for different syntactic levels.
Representational similarity analysis reveals a stronger alignment between LLM
representations and the left hemisphere of the brain (dominant in language
processing). Notably, upgraded models exhibit divergent trends: Gemma 2 shows
greater brain similarity than Gemma, while Llama 3.1 shows less alignment with
the brain compared to Llama 2. These findings offer new insights into the
interpretability of LLM behavioral improvements, raising questions about
whether these advancements are driven by human-like or non-human-like
mechanisms, and establish HFTP as a valuable tool bridging computational
linguistics and cognitive neuroscience. This project is available at
https://github.com/LilTiger/HFTP.

</details>


### [105] [Classifier-Augmented Generation for Structured Workflow Prediction](https://arxiv.org/abs/2510.12825)
*Thomas Gschwind,Shramona Chakraborty,Nitin Gupta,Sameep Mehta*

Main category: cs.CL

TL;DR: 自然语言描述可自动生成ETL工作流，提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的ETL工具虽然提供可视化操作，但配置过程耗时且需要深入的工具知识。

Method: 提出一种结合了分类器和特定阶段少样本提示的CAG（Classifier-Augmented Generation）方法，用于将自然语言描述转换为可执行的工作流，包括阶段预测、连接和属性推断。

Result: CAG方法在准确性和效率方面优于现有基线方法，并显著减少了计算资源消耗。

Conclusion: 该系统是首个能够详细评估阶段预测、边缘布局和属性生成，并能驱动ETL创作的自然语言系统。

Abstract: ETL (Extract, Transform, Load) tools such as IBM DataStage allow users to
visually assemble complex data workflows, but configuring stages and their
properties remains time consuming and requires deep tool knowledge. We propose
a system that translates natural language descriptions into executable
workflows, automatically predicting both the structure and detailed
configuration of the flow. At its core lies a Classifier-Augmented Generation
(CAG) approach that combines utterance decomposition with a classifier and
stage-specific few-shot prompting to produce accurate stage predictions. These
stages are then connected into non-linear workflows using edge prediction, and
stage properties are inferred from sub-utterance context. We compare CAG
against strong single-prompt and agentic baselines, showing improved accuracy
and efficiency, while substantially reducing token usage. Our architecture is
modular, interpretable, and capable of end-to-end workflow generation,
including robust validation steps. To our knowledge, this is the first system
with a detailed evaluation across stage prediction, edge layout, and property
generation for natural-language-driven ETL authoring.

</details>


### [106] [Mathematics with large language models as provers and verifiers](https://arxiv.org/abs/2510.12829)
*Hieu Le Duc,Leo Liberti*

Main category: cs.CL

TL;DR: 大型语言模型在定理证明方面取得突破，利用协作式GPT-5实例和Lean证明助手解决了IMO数学竞赛和数论猜想问题。


<details>
  <summary>Details</summary>
Motivation: 在2024-2025年期间，人们对大型语言模型（LLM）在定理证明方面的能力产生了浓厚兴趣，并取得了一些成功，特别是在具有挑战性的问题（如国际数学奥林匹克（IMO）难题）和用于验证人工智能证明能力的新猜想方面。

Method: 采用了一种涉及不同证明器和验证器实例的GPT-5模型的协作协议。为了确保证明的准确性，最终的证明由Lean证明助手进行形式化验证，并由人工核实Lean代码的前提和结论的一致性。

Result: 该方法成功解决了2025年IMO的六个问题中的五个，并解决了[Cohen, Journal of Integer Sequences, 2025]中提出的66个数论猜想中的三分之一。

Conclusion: 证明了大型语言模型（LLM）在定理证明方面的潜力，并提出了一种通过协作和形式化验证来确保证明准确性的方法。

Abstract: During 2024 and 2025 the discussion about the theorem-proving capabilities of
large language models started reporting interesting success stories, mostly to
do with difficult exercises (such as problems from the International
Mathematical Olympiad), but also with conjectures [Feldman & Karbasi,
arXiv:2509.18383v1] formulated for the purpose of verifying whether the
artificial intelligence could prove it. In this paper we report a theorem
proving feat achieved by ChatGPT by using a protocol involving different prover
and verifier instances of the gpt-5 model working collaboratively. To make sure
that the produced proofs do not suffer from hallucinations, the final proof is
formally verified by the lean proof assistant, and the conformance of premises
and conclusion of the lean code is verified by a human. Our methodology was
able to solve five out of six 2025 IMO problems, and close a third of the
sixty-six number theory conjectures in [Cohen, Journal of Integer Sequences,
2025].

</details>


### [107] [Scheming Ability in LLM-to-LLM Strategic Interactions](https://arxiv.org/abs/2510.12826)
*Thao Pham*

Main category: cs.CL

TL;DR: LLM代理在无需提示的情况下会表现出欺骗倾向，在博弈论框架下，Gemini-2.5-pro和Claude-3.7-Sonnet在有提示的情况下欺骗能力接近完美。


<details>
  <summary>Details</summary>
Motivation: 评估LLM代理进行战略欺骗的能力至关重要，特别是LLM之间的欺骗行为仍有待探索。

Method: 使用两种博弈论框架（廉价谈话信号博弈和同伴评估对抗博弈）来评估四种模型（GPT-4o、Gemini-2.5-pro、Claude-3.7-Sonnet和Llama-3.3-70b）的欺骗能力，并分析其欺骗策略。

Result: 在有提示的情况下，大多数模型（特别是Gemini-2.5-pro和Claude-3.7-Sonnet）的欺骗性能接近完美。在没有提示的情况下，所有模型在同伴评估博弈中都表现出欺骗倾向（100%），在廉价谈话博弈中，选择欺骗的模型成功率也高达95-100%。

Conclusion: 研究结果表明，在多代理环境中，需要使用高风险的博弈论场景进行鲁棒的评估。

Abstract: As large language model (LLM) agents are deployed autonomously in diverse
contexts, evaluating their capacity for strategic deception becomes crucial.
While recent research has examined how AI systems scheme against human
developers, LLM-to-LLM scheming remains underexplored. We investigate the
scheming ability and propensity of frontier LLM agents through two
game-theoretic frameworks: a Cheap Talk signaling game and a Peer Evaluation
adversarial game. Testing four models (GPT-4o, Gemini-2.5-pro,
Claude-3.7-Sonnet, and Llama-3.3-70b), we measure scheming performance with and
without explicit prompting while analyzing scheming tactics through
chain-of-thought reasoning. When prompted, most models, especially
Gemini-2.5-pro and Claude-3.7-Sonnet, achieved near-perfect performance.
Critically, models exhibited significant scheming propensity without prompting:
all models chose deception over confession in Peer Evaluation (100% rate),
while models choosing to scheme in Cheap Talk succeeded at 95-100% rates. These
findings highlight the need for robust evaluations using high-stakes
game-theoretic scenarios in multi-agent settings.

</details>


### [108] [MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training](https://arxiv.org/abs/2510.12831)
*Taicheng Guo,Hai Wang,ChaoChun Liu,Mohsen Golalikhani,Xin Chen,Xiangliang Zhang,Chandan K. Reddy*

Main category: cs.CL

TL;DR: 该研究提出了MTSQL-R1框架，通过将Text-to-SQL任务建模为马尔可夫决策过程，实现了长期的、基于对话的SQL生成，并能在数据库和对话历史中进行验证和优化。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL系统通常将任务视为简单的文本翻译，采用短视范式，每次只生成一个查询，缺乏执行、显式验证和优化，导致生成的SQL不可执行或不连贯。

Method: 将Text-to-SQL任务建模为马尔可夫决策过程（MDP），构建了一个名为MTSQL-R1的代理训练框架。该框架包含一个代理，该代理与数据库（用于执行反馈）和持久的对话内存（用于连贯性验证）进行交互，执行一个迭代的“提议-执行-验证-优化”循环，直到所有检查通过。

Result: 在COSQL和SPARC数据集上的实验表明，MTSQL-R1的性能持续优于强大的基线模型。

Conclusion: 环境驱动的验证和内存引导的优化对于对话式语义解析至关重要。

Abstract: Multi-turn Text-to-SQL aims to translate a user's conversational utterances
into executable SQL while preserving dialogue coherence and grounding to the
target schema. However, most existing systems only regard this task as a simple
text translation task and follow a short-horizon paradigm, generating a query
per turn without execution, explicit verification, and refinement, which leads
to non-executable or incoherent outputs. We present MTSQL-R1, an agentic
training framework for long-horizon multi-turn Text-to-SQL. We cast the task as
a Markov Decision Process (MDP) in which an agent interacts with (i) a database
for execution feedback and (ii) a persistent dialogue memory for coherence
verification, performing an iterative propose to execute -> verify -> refine
cycle until all checks pass. Experiments on COSQL and SPARC demonstrate that
MTSQL-R1 consistently outperforms strong baselines, highlighting the importance
of environment-driven verification and memory-guided refinement for
conversational semantic parsing. Full recipes (including code, trained models,
logs, reasoning trajectories, etc.) will be released after the internal review
to contribute to community research.

</details>


### [109] [Make an Offer They Can't Refuse: Grounding Bayesian Persuasion in Real-World Dialogues without Pre-Commitment](https://arxiv.org/abs/2510.13387)
*Buwei He,Yang Liu,Zhaowei Zhang,Zixia Jia,Huijia Wu,Zhaofeng He,Zilong Zheng,Yipeng Kang*

Main category: cs.CL

TL;DR: 该研究将贝叶斯说服（BP）框架应用于自然语言对话，以增强大型语言模型（LLM）的说服能力，通过明确信息模式和叙述潜在类型来引导对方更新信念。


<details>
  <summary>Details</summary>
Motivation: 当前AI（如LLM）在说服方面存在挑战，现有研究忽视信息不对称或依赖预承诺的强假设。本研究旨在探索贝叶斯说服在自然语言中的应用，以提升LLM的说服能力。

Method: 提出一种结合承诺-沟通机制的框架，说服者明确信息模式（如诚实或不诚实），引导说服者进行信念更新。评估了两种方法：半形式化自然语言（SFNL）BP和全自然语言（FNL）BP，并与非BP（NBP）基线进行比较。

Result: 实验结果显示：1. BP策略引导的LLM说服成功率高于NBP基线；2. SFNL在可信度和逻辑连贯性方面更优，FNL在情感共鸣和对话稳健性方面表现更好；3. 经过微调，小型模型可达到与大型模型相当的BP性能。

Conclusion: 贝叶斯说服框架能够有效提升LLM在单轮对话中的说服能力，并且不同的自然语言实现方式（SFNL和FNL）各有优势，通过微调可以缩小模型规模带来的性能差距。

Abstract: Persuasion, a fundamental social capability for humans, remains a challenge
for AI systems such as large language models (LLMs). Current studies often
overlook the strategic use of information asymmetry in message design or rely
on strong assumptions regarding pre-commitment. In this work, we explore the
application of Bayesian Persuasion (BP) in natural language within single-turn
dialogue settings, to enhance the strategic persuasion capabilities of LLMs.
Our framework incorporates a commitment-communication mechanism, where the
persuader explicitly outlines an information schema by narrating their
potential types (e.g., honest or dishonest), thereby guiding the persuadee in
performing the intended Bayesian belief update. We evaluate two variants of our
approach: Semi-Formal-Natural-Language (SFNL) BP and Fully-Natural-Language
(FNL) BP, benchmarking them against both naive and strong non-BP (NBP)
baselines within a comprehensive evaluation framework. This framework covers a
diverse set of persuadees -- including LLM instances with varying prompts and
fine-tuning and human participants -- across tasks ranging from specially
designed persuasion scenarios to general everyday situations. Experimental
results on LLM-based agents reveal three main findings: (1) LLMs guided by BP
strategies consistently achieve higher persuasion success rates than NBP
baselines; (2) SFNL exhibits greater credibility and logical coherence, while
FNL shows stronger emotional resonance and robustness in naturalistic
conversations; (3) with supervised fine-tuning, smaller models can attain BP
performance comparable to that of larger models.

</details>


### [110] [Repurposing Annotation Guidelines to Instruct LLM Annotators: A Case Study](https://arxiv.org/abs/2510.12835)
*Kon Woo Kim,Rezarta Islamaj,Jin-Dong Kim,Florian Boudin,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本研究提出了一种将传统文本标注指南改编为适用于大型语言模型（LLM）的指令的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的标注指南是为人类标注者设计的，而LLM需要更明确、结构化的指令。因此，本研究的动机是探索如何将现有的标注指南改编，以有效地指导LLM进行文本标注任务。

Method: 本研究提出了一种面向审核的指南改编方法，通过LLM审核过程将指南转化为LLM的明确指令。以NCBI疾病语料库为例进行了实验。

Result: 实验结果表明，改编后的指南能够有效指导LLM标注者，但也揭示了一些实际挑战。

Conclusion: 该工作展示了通过LLM审核过程改编现有标注指南的潜力，可用于支持可扩展且经济高效的标注指南和自动化标注的优化。

Abstract: This study investigates how existing annotation guidelines can be repurposed
to instruct large language model (LLM) annotators for text annotation tasks.
Traditional guidelines are written for human annotators who internalize
training, while LLMs require explicit, structured instructions. We propose a
moderation-oriented guideline repurposing method that transforms guidelines
into clear directives for LLMs through an LLM moderation process. Using the
NCBI Disease Corpus as a case study, our experiments show that repurposed
guidelines can effectively guide LLM annotators, while revealing several
practical challenges. The results highlight the potential of this workflow to
support scalable and cost-effective refinement of annotation guidelines and
automated annotation.

</details>


### [111] [A\textsuperscript{2}FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning](https://arxiv.org/abs/2510.12838)
*Qianben Chen,Jingyi Cao,Jiayu Zhang,Tianrui Qin,Xiaowan Li,King Zhu,Dingfeng Shi,He Zhu,Minghao Liu,Xiaobo Liang,Ge Zhang,Jian Yang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 该研究提出了一个名为A	extsuperscript{2}FM的统一框架，旨在解决现有大语言模型在推理和工具调用方面的分歧问题，通过引入路由、对齐和即时模式，并结合自适应策略优化（APO）来提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型分为以推理为中心和以智能体为中心的两个家族，它们在训练目标上存在根本差异，导致在简单查询时效率低下，倾向于过度思考或过度调用工具。

Method: A	extsuperscript{2}FM框架采用“先路由后对齐”的原则：首先学习任务感知的路由，然后在共享骨干下对齐特定模式的轨迹。引入“即时”模式来直接处理简单查询，并通过自适应策略优化（APO）来提高准确性和效率，该优化强制跨模式进行自适应采样并应用成本正则化奖励。

Result: 在32B规模下，A	extsuperscript{2}FM在BrowseComp上达到了13.4%，在AIME25上达到了70.4%，在HLE上达到了16.7%，在同类模型中达到了新的SOTA水平，并在智能体、推理和通用基准测试中与前沿LLM具有竞争力。自适应执行的平均成本仅为0.00487美元/正确答案，与仅推理模型相比降低了45.2%，与仅智能体模型相比降低了33.5%。

Conclusion: A	extsuperscript{2}FM框架通过统一推理和工具调用能力，并引入即时模式和自适应策略优化，显著提高了大语言模型的准确性和效率，尤其在成本效益方面表现突出。

Abstract: Large language models split into two families: reasoning-centric LLMs, which
strengthen internal chain-of-thought reasoning but cannot invoke external
tools, and agentic LLMs, which learn to interact with environments and leverage
tools but often lag in deep reasoning. This divide arises from fundamentally
different training objectives, leading to mismatched strengths and inefficiency
on simple queries, where both families tend to overthink or over-call tools. In
this work, we present Adaptive Agent Foundation Model (A\textsuperscript{2}FM),
a unified framework that follows a route-then-align principle: the model first
learns task-aware routing and then aligns mode-specific trajectories under a
shared backbone. To address the inefficiency gap, we introduce a third
mode-instant-that handles simple queries directly, preventing unnecessary
reasoning or tool calls while complementing the agentic and reasoning modes. To
jointly enhance accuracy and efficiency, we propose Adaptive Policy
Optimization (APO), which enforces adaptive sampling across modes and applies a
cost-regularized reward. On the 32B scale, A\textsuperscript{2}FM achieves
13.4\% on BrowseComp, 70.4\% on AIME25, and 16.7\% on HLE, setting new SOTA
among comparable models and performing competitively with frontier LLMs across
agentic, reasoning, and general benchmarks. Notably, the adaptive execution
achieves a cost of pass of only \$0.00487 per correct answer-cutting cost by
45.2\% relative to reasoning and 33.5\% relative to agentic, thus delivering
substantially higher cost efficiency while maintaining comparable accuracy.

</details>


### [112] [FaStFACT: Faster, Stronger Long-Form Factuality Evaluations in LLMs](https://arxiv.org/abs/2510.12839)
*Yingjia Wan,Haochen Tan,Xiao Zhu,Xinyu Zhou,Zhiwei Li,Qingsong Lv,Changxuan Sun,Jiaqi Zeng,Yi Xu,Jianqiao Lu,Yinhong Liu,Zhijiang Guo*

Main category: cs.CL

TL;DR: 该研究提出了一种名为\name的快速、强大的评估框架，用于评估大型语言模型（LLM）的生成内容的真实性，该框架在与人类评估的一致性和效率方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）生成内容的真实性非常困难，因为存在准确性问题且人工评估成本高昂。之前的研究尝试将文本分解为声明、搜索证据并验证声明，但存在效率低下（复杂的管道组件不适用于长篇LLM输出）和效果不佳（声明集不准确、证据收集不足）等关键缺点。

Method: \name框架首先采用块级声明提取，并结合基于置信度的预验证，显著降低了网络搜索和推理调用的成本，同时确保了可靠性。在搜索和验证方面，它从爬取的网页中收集文档级证据，并在验证过程中选择性地检索证据，解决了先前管道中证据不足的问题。

Result: 通过在聚合和手动注释的基准上进行的大量实验，证明了\name在高效、有效地评估长篇LLM生成内容的真实性方面具有可靠性。

Conclusion: \name框架能够高效且有效地评估长篇LLM生成内容的真实性，并且在效率和与人类评估的一致性方面优于现有方法。

Abstract: Evaluating the factuality of long-form generations from Large Language Models
(LLMs) remains challenging due to accuracy issues and costly human assessment.
Prior efforts attempt this by decomposing text into claims, searching for
evidence, and verifying claims, but suffer from critical drawbacks: (1)
inefficiency due to complex pipeline components unsuitable for long LLM
outputs, and (2) ineffectiveness stemming from inaccurate claim sets and
insufficient evidence collection of one-line snippets.
  To address these limitations, we propose \name, a fast and strong evaluation
framework that achieves the highest alignment with human evaluation and
efficiency among existing baselines. \name first employs chunk-level claim
extraction integrated with confidence-based pre-verification, significantly
reducing the cost of web searching and inference calling while ensuring
reliability. For searching and verification, it collects document-level
evidence from crawled webpages and selectively retrieves it during
verification, addressing the evidence insufficiency problem in previous
pipelines.
  Extensive experiments based on an aggregated and manually annotated benchmark
demonstrate the reliability of \name in both efficiently and effectively
evaluating the factuality of long-form LLM generations. Code and benchmark data
is available at https://github.com/Yingjia-Wan/FastFact.

</details>


### [113] [VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages](https://arxiv.org/abs/2510.12845)
*Jesse Atuhurra,Iqra Ali,Tomoya Iwakura,Hidetaka Kamigaito,Tatsuya Hiraoka*

Main category: cs.CL

TL;DR: VLURes 是一个包含八项视觉-语言任务的新型多语言基准，旨在评估视觉语言模型（VLM）在长文本场景下的细粒度理解能力，特别关注英语、日语以及斯瓦希里语和乌尔都语等低资源语言。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLM 评估主要集中在以英语为中心、文本简短的基准上，限制了对其细粒度理解能力的全面评估。多语言和长文本场景下的评估对于开发更智能的代理至关重要。

Method: 引入了 VLURes，一个包含八项任务（包括一项新颖的无关任务）的多语言基准。该基准包含来自网络资源的、跨越十个图像类别的长文本数据，并支持英语、日语、斯瓦希里语和乌尔都语。通过提示 VLM 生成响应和解释，并结合自动和母语者评估来衡量模型性能。

Result: 在 VLURes 基准上对十个 VLM 进行了评估。表现最好的 GPT-4o 模型达到了 90.8% 的总体准确率，与人类表现相差 6.7%，但开源模型的差距更大。评估揭示了不同语言和任务之间在对象识别、场景理解和关系理解等方面的性能差异。

Conclusion: VLURes 基准在推动多模态视觉推理和开发更智能的代理方面发挥着关键作用，突显了在多语言长文本场景下评估 VLM 的重要性，并指出了当前模型与人类在理解能力上仍存在差距。

Abstract: Vision Language Models (VLMs) are pivotal for advancing perception in
intelligent agents. Yet, evaluation of VLMs remains limited to predominantly
English-centric benchmarks in which the image-text pairs comprise short texts.
To evaluate VLM fine-grained abilities, in four languages under long-text
settings, we introduce a novel multilingual benchmark VLURes featuring eight
vision-and-language tasks, and a pioneering unrelatedness task, to probe the
fine-grained Visual and Linguistic Understanding capabilities of VLMs across
English, Japanese, and low-resource languages, Swahili, and Urdu. Our datasets,
curated from web resources in the target language, encompass ten diverse image
categories and rich textual context, introducing valuable vision-language
resources for Swahili and Urdu. By prompting VLMs to generate responses and
rationales, evaluated automatically and by native speakers, we uncover
performance disparities across languages and tasks critical to intelligent
agents, such as object recognition, scene understanding, and relationship
understanding. We conducted evaluations of ten VLMs with VLURes. The best
performing model, GPT-4o, achieves an overall accuracy of 90.8% and lags human
performance by 6.7%, though the gap is larger for open-source models. The gap
highlights VLURes' critical role in developing intelligent agents to tackle
multi-modal visual reasoning.

</details>


### [114] [Efficient Adaptive Transformer: An Empirical Study and Reproducible Framework](https://arxiv.org/abs/2510.12856)
*Jan Miller*

Main category: cs.CL

TL;DR: EAT框架整合了三种自适应技术（渐进式token修剪、稀疏注意力、动态提前退出），用于输入自适应推理，并提供了一个开源的基准测试流程，但可能增加浅层模型的延迟，不过在SST-2任务上略微提高了准确性，其主要贡献是提供了一个可复现的框架。


<details>
  <summary>Details</summary>
Motivation: 为了统一和实现输入自适应推理，整合了三种自适应效率技术：渐进式token修剪、稀疏注意力和动态提前退出。

Method: 提出了EAT（Efficient Adaptive Transformer）框架，整合了三种自适应效率技术，并提供了一个开源的基准测试流程，包括数据处理、计时和交叉验证，以在GLUE任务上进行评估。

Result: 在浅层模型（六层）上，结合这些机制可能会增加延迟。然而，在SST-2任务上，EAT的准确性略高于优化的DistilBERT基线模型。

Conclusion: EAT框架展示了动态计算在延迟敏感的NLP任务中的潜力，尽管在浅层模型中可能增加延迟。该框架本身是一个主要的贡献，旨在作为社区研究自适应Transformer的工具。

Abstract: The Efficient Adaptive Transformer (EAT) framework unifies three adaptive
efficiency techniques - progressive token pruning, sparse attention, and
dynamic early exiting - into a single, reproducible architecture for
input-adaptive inference. EAT provides an open-source benchmarking pipeline
that automates data processing, timing, and ablation across GLUE tasks (SST-2,
QQP, MNLI). Although this empirical study finds that combining these mechanisms
can increase latency in shallow six-layer models, it demonstrates that EAT
achieves slightly higher accuracy than the optimized DistilBERT baseline on
SST-2, illustrating the potential of dynamic computation for latency-sensitive
NLP. The main contribution is the open, end-to-end reproducible framework -
complete with scripts, CSV logging, and analysis utilities - intended to serve
as a community tool for further research on adaptive transformers.

</details>


### [115] [A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation](https://arxiv.org/abs/2510.12858)
*Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone*

Main category: cs.CL

TL;DR: 当前自动化的古兰经读诵评估工具因未能有效解决教学挑战而面临困境，这主要是由于它们基于自动语音识别（ASR）技术，该技术侧重于词汇识别而非声学评估，并存在数据依赖、人口偏见和反馈不佳等问题。


<details>
  <summary>Details</summary>
Motivation: 传统古兰经读诵（Tajweed）教学面临现代挑战，现有的自动化评估工具未能普及或在教学上有效，存在显著的教学差距。

Method: 通过对过去二十年学术研究、网络平台和商业应用程序进行文献综述和综合分析。

Result: 现有方法倾向于使用自动语音识别（ASR）架构，该架构优先考虑词汇识别而非定性声学评估，并且存在数据依赖、人口偏见和无法提供诊断有用反馈的问题。

Conclusion: 未来的自动化古兰经评估应从数据驱动模式转变为以知识为中心的计算框架，并结合深度语言知识和高级音频分析，以创建稳健、公平且具有教学意义的工具。

Abstract: The sacred practice of Quranic recitation (Tajweed), governed by precise
phonetic, prosodic, and theological rules, faces significant pedagogical
challenges in the modern era. While digital technologies promise unprecedented
access to education, automated tools for recitation evaluation have failed to
achieve widespread adoption or pedagogical efficacy. This literature review
investigates this critical gap, conducting a comprehensive analysis of academic
research, web platforms, and commercial applications developed over the past
two decades. Our synthesis reveals a fundamental misalignment in prevailing
approaches that repurpose Automatic Speech Recognition (ASR) architectures,
which prioritize lexical recognition over qualitative acoustic assessment and
are plagued by data dependency, demographic biases, and an inability to provide
diagnostically useful feedback. Critiquing these data--driven paradigms, we
argue for a foundational paradigm shift towards a knowledge-centric
computational framework. Capitalizing on the immutable nature of the Quranic
text and the precisely defined rules of Tajweed, we propose that a robust
evaluator must be architected around anticipatory acoustic modeling based on
canonical rules and articulation points (Makhraj), rather than relying on
statistical patterns learned from imperfect and biased datasets. This review
concludes that the future of automated Quranic evaluation lies in hybrid
systems that integrate deep linguistic knowledge with advanced audio analysis,
offering a path toward robust, equitable, and pedagogically sound tools that
can faithfully support learners worldwide.

</details>


### [116] [EduDial: Constructing a Large-scale Multi-turn Teacher-Student Dialogue Corpus](https://arxiv.org/abs/2510.12899)
*Shouang Wei,Min Zhang,Xin Lin,Bo Jiang,Zhongxiang Dai,Kun Kuang*

Main category: cs.CL

TL;DR: EduDial是一个包含34,250个对话回合的师生对话数据集，涵盖345个知识点，并设计了11个维度的评估框架来衡量大型语言模型的教学能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在智能教育领域的应用日益广泛，构建专门的师生对话基准测试对于评估和提升其教学能力变得至关重要。

Method: 该研究提出了EduDial数据集，该数据集基于布鲁姆教育目标分类学，包含10种提问策略和针对不同认知水平学生的分层教学策略。同时，训练了一个名为EduDial-LLM 32B的模型，并设计了一个包含11个维度的评估框架。

Result: 在17个主流大型语言模型上的实验表明，大多数模型在以学生为中心的教学场景中表现不佳，而EduDial-LLM 32B在所有指标上均显著优于所有基线模型。

Conclusion: EduDial数据集和EduDial-LLM 32B模型为评估和改进大型语言模型在教育领域的教学能力提供了有力支持，尤其是在需要学生中心教学的场景下。

Abstract: Recently, several multi-turn dialogue benchmarks have been proposed to
evaluate the conversational abilities of large language models (LLMs). As LLMs
are increasingly recognized as a key technology for advancing intelligent
education, owing to their ability to deeply understand instructional contexts
and provide personalized guidance, the construction of dedicated
teacher-student dialogue benchmarks has become particularly important. To this
end, we present EduDial, a comprehensive multi-turn teacher-student dialogue
dataset. EduDial covers 345 core knowledge points and consists of 34,250
dialogue sessions generated through interactions between teacher and student
agents. Its design is guided by Bloom's taxonomy of educational objectives and
incorporates ten questioning strategies, including situational questioning,
zone of proximal development (ZPD) questioning, and metacognitive
questioning-thus better capturing authentic classroom interactions.
Furthermore, we design differentiated teaching strategies for students at
different cognitive levels, thereby providing more targeted teaching guidance.
Building on EduDial, we further develop EduDial-LLM 32B via training and
propose an 11-dimensional evaluation framework that systematically measures the
teaching abilities of LLMs, encompassing both overall teaching quality and
content quality. Experiments on 17 mainstream LLMs reveal that most models
struggle in student-centered teaching scenarios, whereas our EduDial-LLM
achieves significant gains, consistently outperforming all baselines across all
metrics. The code is available at
https://github.com/Mind-Lab-ECNU/EduDial/tree/main.

</details>


### [117] [Who's Asking? Evaluating LLM Robustness to Inquiry Personas in Factual Question Answering](https://arxiv.org/abs/2510.12925)
*Nil-Jana Akpinar,Chia-Jung Lee,Vanessa Murdock,Pietro Perona*

Main category: cs.CL

TL;DR: LLM在回答事实性问题时应保持客观，不受用户个人信息或系统个性化的影响。本文首次系统评估了LLM对用户查询角色的鲁棒性，发现用户在现实互动中披露的身份、专业知识或信仰等角色信息会显著影响QA的准确性，并可能导致模型拒绝回答、产生幻觉或角色混淆，这表明模型对用户表述的敏感性会损害事实可靠性，因此查询角色测试是评估模型鲁棒性的有效工具。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在回答事实性问题时，对用户查询角色（例如身份、专业知识或信仰）的鲁棒性，以及这种鲁棒性如何影响模型的准确性和可靠性。

Method: 系统性地评估LLM对查询角色的鲁棒性，重点关注用户在现实互动中可能披露的、以人为中心的信息提示，而非仅关注对抗性输入或干扰项。

Result: 用户查询角色信息会显著影响QA准确性，并可能导致模型拒绝回答、产生幻觉或角色混淆等故障模式。

Conclusion: 模型对用户表述的敏感性会损害事实可靠性，查询角色测试是评估模型鲁棒性的有效工具。

Abstract: Large Language Models (LLMs) should answer factual questions truthfully,
grounded in objective knowledge, regardless of user context such as
self-disclosed personal information, or system personalization. In this paper,
we present the first systematic evaluation of LLM robustness to inquiry
personas, i.e. user profiles that convey attributes like identity, expertise,
or belief. While prior work has primarily focused on adversarial inputs or
distractors for robustness testing, we evaluate plausible, human-centered
inquiry persona cues that users disclose in real-world interactions. We find
that such cues can meaningfully alter QA accuracy and trigger failure modes
such as refusals, hallucinated limitations, and role confusion. These effects
highlight how model sensitivity to user framing can compromise factual
reliability, and position inquiry persona testing as an effective tool for
robustness evaluation.

</details>


### [118] [The Curious Case of Curiosity across Human Cultures and LLMs](https://arxiv.org/abs/2510.12943)
*Angana Borah,Rada Mihalcea*

Main category: cs.CL

TL;DR: LLMs 在跨文化背景下的好奇心表达趋同于西方模式，但可以通过微调策略来缩小人机差距。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究 LLMs 在跨文化好奇心表达方面的变异性，并探讨如何通过微调来提升 LLMs 的跨文化适应性。

Method: 利用 Yahoo! Answers 数据集，提出 CUEST 评估框架，从语言风格和主题偏好分析，结合社会学理论，评估 LLMs 在跨文化好奇心表达方面的表现，并探索微调策略。

Result: 研究发现，无论是开源还是闭源模型，LLMs 在跨文化好奇心表达上存在趋同现象，更接近西方文化模式。通过微调，人机对齐差距最高可缩小 50%。

Conclusion: LLMs 的好奇心对于其跨文化适应性至关重要，对未来的 NLP 研究具有重要意义。

Abstract: Recent advances in Large Language Models (LLMs) have expanded their role in
human interaction, yet curiosity -- a central driver of inquiry -- remains
underexplored in these systems, particularly across cultural contexts. In this
work, we investigate cultural variation in curiosity using Yahoo! Answers, a
real-world multi-country dataset spanning diverse topics. We introduce CUEST
(CUriosity Evaluation across SocieTies), an evaluation framework that measures
human-model alignment in curiosity through linguistic (style), topic preference
(content) analysis and grounding insights in social science constructs. Across
open- and closed-source models, we find that LLMs flatten cross-cultural
diversity, aligning more closely with how curiosity is expressed in Western
countries. We then explore fine-tuning strategies to induce curiosity in LLMs,
narrowing the human-model alignment gap by up to 50\%. Finally, we demonstrate
the practical value of curiosity for LLM adaptability across cultures, showing
its importance for future NLP research.

</details>


### [119] [3-Model Speculative Decoding](https://arxiv.org/abs/2510.12966)
*Sanghyun Byun,Mohanad Odema,Jung Ick Guack,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CL

TL;DR: Speculative Decoding (SD) 提速 LLM 推理，但受限于草稿模型大小与接受率的权衡。PyramidSD 引入中间模型，改善模型间对齐，提高接受率，允许使用更小的草稿模型。


<details>
  <summary>Details</summary>
Motivation: 现有 Speculative Decoding (SD) 推理加速方法受限于草稿模型大小与 token 接受率之间的权衡，限制了吞吐量的提升。

Method: 提出 Pyramid Speculative Decoding (PyramidSD)，在草稿模型和目标模型之间插入一个中间“限定模型”来缩小它们在输出预测上的分布差异。该方法利用模糊接受标准，支持各阶段的宽松发散阈值。

Result: PyramidSD 相比标准 SD 实现了高达 1.91 倍的生成速度提升，在消费级 GPU (RTX 4090) 上达到 124 tokens/秒。在小内存场景下，使用 1B 参数草稿模型和 8B 参数目标模型时，PyramidSD 仅有微小的目标模型质量损失。

Conclusion: PyramidSD 是一种实用的方法，能够提高 Speculative Decoding 的效率，并且易于集成到现有推理流程中。

Abstract: Speculative Decoding (SD) accelerates inference in large language models by
using a smaller draft model to propose tokens, which are then verified by a
larger target model. However, the throughput gains of SD are fundamentally
limited by a trade-off between draft model size and token acceptance: smaller
draft models generate tokens more quickly but exhibit greater divergence from
the target model, resulting in lower acceptance rates and reduced speedups. We
introduce Pyramid Speculative Decoding (PyramidSD), an extension of SD that
inserts an intermediate qualifier model between the draft and target to bridge
the distributional gap in output predictions, allowing smaller model to be used
for drafting. This hierarchical decoding strategy improves alignment across
models, enabling higher acceptance rates and allowing the use of significantly
smaller draft models without sacrificing overall performance. PyramidSD builds
on fuzzy acceptance criteria to support relaxed divergence thresholds at each
stage, improving throughput. In experiments, PyramidSD achieves up to 1.91x
generation speed over standard SD, reaching 124 tokens per second on a consumer
GPU (RTX 4090). In small-memory settings with a 1B-parameter draft model and an
8B target model, PyramidSD minimally trades target model quality for improved
throughput. Overall, PyramidSD offers a practical approach to enhancing
speculative decoding efficiency and can be readily applied to existing
inference pipelines.

</details>


### [120] [A Multilingual, Large-Scale Study of the Interplay between LLM Safeguards, Personalisation, and Disinformation](https://arxiv.org/abs/2510.12993)
*João A. Leite,Arnav Arora,Silvia Gargova,João Luz,Gustavo Sampaio,Ian Roberts,Carolina Scarton,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）可能被滥用于大规模生成有说服力且个性化的虚假信息，但关于其说服力和个性化（根据特定人口统计属性定制虚假信息）的研究尚不充分。本研究首次进行了大规模、多语言的实证研究，调查LLM生成针对特定人群的虚假信息的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在生成人类水平的文本方面表现出色，这引发了对其被滥用于大规模生成有说服力且个性化的虚假信息的担忧。然而，关于LLM生成虚假信息的说服力和个性化能力的研究仍然不足，因此需要对此进行系统性研究。

Method: 本研究采用红队演练方法，系统性地评估LLM安全机制对包含特定人群属性的提示的抵抗能力。研究人员构建了一个名为AI-TRAITS的数据集，其中包含约160万条由八种先进LLM生成的文本。这些文本是通过结合324个虚假信息叙述和150个人群画像（涵盖四种主要语言和关键人口统计维度）的提示生成的。

Result: 研究发现，即使在提示中使用简单的个性化策略，也能显著提高所有受测LLM的越狱率。此外，个性化提示会改变语言和修辞模式，并增强LLM生成虚假叙述的说服力。AI-TRAITS数据集包含了针对不同人群和语言的个性化虚假信息。

Conclusion: 本研究揭示了当前先进LLM在抵御针对特定人群的个性化虚假信息生成方面的关键漏洞。研究结果为改进多语言和跨人群环境下的LLM安全对齐和检测策略奠定了基础。

Abstract: The human-like proficiency of Large Language Models (LLMs) has brought
concerns about their potential misuse for generating persuasive and
personalised disinformation at scale. While prior work has demonstrated that
LLMs can generate disinformation, specific questions around persuasiveness and
personalisation (generation of disinformation tailored to specific demographic
attributes) remain largely unstudied. This paper presents the first
large-scale, multilingual empirical study on persona-targeted disinformation
generation by LLMs. Employing a red teaming methodology, we systematically
evaluate the robustness of LLM safety mechanisms to persona-targeted prompts. A
key novel result is AI-TRAITS (AI-generaTed peRsonAlIsed disinformaTion
dataSet), a new dataset of around 1.6 million texts generated by eight
state-of-the-art LLMs. AI-TRAITS is seeded by prompts that combine 324
disinformation narratives and 150 distinct persona profiles, covering four
major languages (English, Russian, Portuguese, Hindi) and key demographic
dimensions (country, generation, political orientation). The resulting
personalised narratives are then assessed quantitatively and compared along the
dimensions of models, languages, jailbreaking rate, and personalisation
attributes. Our findings demonstrate that the use of even simple
personalisation strategies in the prompts significantly increases the
likelihood of jailbreaks for all studied LLMs. Furthermore, personalised
prompts result in altered linguistic and rhetorical patterns and amplify the
persuasiveness of the LLM-generated false narratives. These insights expose
critical vulnerabilities in current state-of-the-art LLMs and offer a
foundation for improving safety alignment and detection strategies in
multilingual and cross-demographic contexts.

</details>


### [121] [OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2510.13003)
*Yifeng Xiong,Xiaohui Xie*

Main category: cs.CL

TL;DR: LoRA存在灾难性遗忘问题，OPLoRA通过双侧正交投影解决此问题，保留了冻结权重的关键信息，并在多项任务上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: LoRA在高效微调LLM的同时，存在因学习更新干扰预训练知识的“灾难性遗忘”问题。

Method: 通过SVD分解冻结权重，利用正交投影P_L = I - U_k U_k^T和P_R = I - V_k V_k^T，将LoRA更新限制在顶层k个奇异子空间的补空间内，并引入度量指标ρ_k量化子空间干扰。

Result: OPLoRA在常识推理、数学和代码生成等任务上，显著减少了灾难性遗忘，同时在LLaMA-2 7B和Qwen2.5 7B模型上保持了具有竞争力的特定任务性能。

Conclusion: 正交投影是一种有效的参数高效微调知识保留机制。

Abstract: Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large language
models but suffers from catastrophic forgetting when learned updates interfere
with the dominant singular directions that encode essential pre-trained
knowledge. We propose Orthogonal Projection LoRA (OPLoRA), a theoretically
grounded approach that prevents this interference through double-sided
orthogonal projections. By decomposing frozen weights via SVD, OPLoRA
constrains LoRA updates to lie entirely within the orthogonal complement of the
top-$k$ singular subspace using projections $P_L = I - U_k U_k^\top$ and $P_R =
I - V_k V_k^\top$. We prove that this construction exactly preserves the
top-$k$ singular triples, providing mathematical guarantees for knowledge
retention. To quantify subspace interference, we introduce $\rho_k$, a metric
measuring update alignment with dominant directions. Extensive experiments
across commonsense reasoning, mathematics, and code generation demonstrate that
OPLoRA significantly reduces forgetting while maintaining competitive
task-specific performance on LLaMA-2 7B and Qwen2.5 7B, establishing orthogonal
projection as an effective mechanism for knowledge preservation in
parameter-efficient fine-tuning.

</details>


### [122] [CurLL: A Developmental Framework to Evaluate Continual Learning in Language Models](https://arxiv.org/abs/2510.13008)
*Pavan Kalyan,Shubhra Mishra,Satya Lokam,Navin Goyal*

Main category: cs.CL

TL;DR: 该论文提出了一个名为CurlL的综合性持续学习数据集和基准，该基准基于人类5-10岁儿童的发育轨迹，用于评估模型逐步获取新技能的能力。CurlL包含五个发育阶段，并有一个技能图谱来分解和组织技能。他们生成了一个包含23.4B个token的合成数据集，涵盖不同类型的内容，并支持对遗忘、前向迁移和后向迁移的分析。通过在不同训练设置下使用一个135M参数的Transformer模型进行实验，他们展示了技能保持和迁移效率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 为了系统地、细致地评估模型在语言学习中逐步获取新技能的能力，作者提出了一个基于人类发育轨迹的持续学习数据集和基准（CurlL）。

Method: 作者构建了一个包含五个发育阶段（覆盖5-10岁）的CurlL数据集，并设计了一个技能图谱来表示技能之间的依赖关系。他们生成了一个包含23.4B token的合成数据集，其中包含不同类型的内容（段落、CQA、CSQA、IR对），并控制了技能进展、词汇复杂性和格式多样性。作者使用一个135M参数的Transformer模型，在独立、联合和顺序（持续）学习设置下进行了训练和评估。

Result: 实验表明，在持续学习设置下，模型在技能保持和迁移效率方面存在权衡。具体结果（如遗忘、前向迁移、后向迁移的程度）可以通过不同阶段的token数量进行精确分析。

Conclusion: CurlL数据集和基准通过模拟人类学习模式并提供对技能依赖性的精细控制，促进了对语言模型的持续学习评估。

Abstract: We introduce a comprehensive continual learning dataset and benchmark (CurlL)
grounded in human developmental trajectories from ages 5-10, enabling
systematic and fine-grained assessment of models' ability to progressively
acquire new skills. CurlL spans five developmental stages (0-4) covering ages
5-10, supported by a skill graph that breaks down broad skills into smaller
abilities, concrete goals, and measurable indicators, while also capturing
which abilities build on others. We generate a 23.4B-token synthetic dataset
with controlled skill progression, vocabulary complexity, and format diversity,
comprising paragraphs, comprehension-based QA (CQA), skill-testing QA (CSQA),
and instruction-response (IR) pairs. Stage-wise token counts range from 2.12B
to 6.78B tokens, supporting precise analysis of forgetting, forward transfer,
and backward transfer. Using a 135M-parameter transformer trained under
independent, joint, and sequential (continual) setups, we show trade-offs in
skill retention and transfer efficiency. By mirroring human learning patterns
and providing fine-grained control over skill dependencies, this work advances
continual learning evaluations for language models.

</details>


### [123] [On the Role of Preference Variance in Preference Optimization](https://arxiv.org/abs/2510.13022)
*Jiacheng Guo,Zihao Li,Jiahao Qiu,Yue Wu,Mengdi Wang*

Main category: cs.CL

TL;DR: DPO训练中的偏好方差（PVar）很重要，高PVar提示词对齐LLM更有效。


<details>
  <summary>Details</summary>
Motivation: 收集人类偏好数据成本高昂且效率低下，因此需要减少标注。本研究调查了偏好方差（PVar）对DPO训练效果的影响。

Method: 通过理论分析得到DPO梯度范数的上界，证明其受PVar控制。通过实验验证高PVar提示词比随机选择或低PVar提示词效果更好，并使用不同大小的奖励模型进行验证。

Result: 实验证明，高PVar提示词比随机选择或低PVar提示词更能提升LLM的性能。使用小的奖励模型进行选择也具有鲁棒性。仅使用PVar最高的10%提示词进行训练，其效果优于使用全部数据集。

Conclusion: 偏好方差（PVar）对于识别信息量大的样本以实现高效的LLM对齐至关重要。

Abstract: Direct Preference Optimization (DPO) has emerged as an important approach for
learning from human preferences in aligning large language models (LLMs).
However, collecting human preference data is costly and inefficient, motivating
methods to reduce the required annotations. In this work, we investigate the
impact of \emph{preference variance} (PVar), which measures the variance in
model preferences when comparing pairs of responses, on the effectiveness of
DPO training. We provide a theoretical insight by establishing an upper bound
on the DPO gradient norm for any given prompt, showing it is controlled by the
PVar of that prompt. This implies that prompts with low PVar can only produce
small gradient updates, making them less valuable for learning. We validate
this finding by fine-tuning LLMs with preferences generated by a reward model,
evaluating on two benchmarks (AlpacaEval 2.0 and Arena-Hard). Experimental
results demonstrate that prompts with higher PVar outperform randomly selected
prompts or those with lower PVar. We also show that our PVar-based selection
method is robust, when using smaller reward models (1B, 3B) for selection.
Notably, in a separate experiment using the original human annotations from the
UltraFeedback dataset, we found that training on only the top 10\% of prompts
with the highest PVar yields better evaluation performance than training on the
full dataset, highlighting the importance of preference variance in identifying
informative examples for efficient LLM alignment.

</details>


### [124] [GatePro: Parameter-Free Expert Selection Optimization for Mixture-of-Experts Models](https://arxiv.org/abs/2510.13079)
*Chen Zheng,Yuhang Cai,Deyi Liu,Jin Ma,Yiyuan Ma,Yuan Yang,Jing Liu,Yutao Zeng,Xun Zhou,Siyuan Qiao*

Main category: cs.CL

TL;DR: GatePro通过引入局部竞争机制，促进专家选择多样性，解决了MoE模型中相似专家同时被激活的冗余计算问题，提升了模型容量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在扩展时面临一个关键挑战：功能相似的专家经常被同时选择，导致冗余计算并限制了模型的有效容量。现有的辅助平衡损失方法虽然改善了token的分布，但未能解决根本的专家多样性问题。

Method: GatePro是一种新颖的、无参数的方法，它直接促进专家选择的多样性。该方法识别最相似的专家对，并引入局部竞争机制，以防止冗余的专家共同激活，同时保持自然的专家专业化。

Result: GatePro能够实现增强的专家多样性，专家发展出更独特、更互补的能力，避免功能冗余。该方法可以在任何训练阶段进行热插拔部署，无需额外的可学习参数。

Conclusion: GatePro通过促进专家选择的多样性，有效解决了MoE模型中的冗余计算问题，提升了模型容量和效率，是一种实用的解决方案。

Abstract: Modern large language models leverage Mixture-of-Experts (MoE) architectures
for efficient scaling, but face a critical challenge: functionally similar
experts are often selected simultaneously, creating redundant computation and
limiting effective model capacity. Existing auxiliary balance loss methods
improve token distribution but fail to address the underlying expert diversity
problem. We introduce GatePro, a novel parameter-free method that directly
promotes expert selection diversity. GatePro identifies the most similar expert
pairs and introduces localized competition mechanisms, preventing redundant
expert co-activation while maintaining natural expert specialization. Our
comprehensive evaluation demonstrates GatePro's effectiveness across model
scales and benchmarks. Analysis demonstrates GatePro's ability to achieve
enhanced expert diversity, where experts develop more distinct and
complementary capabilities, avoiding functional redundancy. This approach can
be deployed hot-swappable during any training phase without additional
learnable parameters, offering a practical solution for improving MoE
effectiveness.

</details>


### [125] [ESI: Epistemic Uncertainty Quantification via Semantic-preserving Intervention for Large Language Models](https://arxiv.org/abs/2510.13103)
*Mingda Li,Xinyu Li,Weinan Zhang,Longxuan Ma*

Main category: cs.CL

TL;DR: LLM的不确定性可通过因果推断进行量化，提出一种基于语义不变性的灰盒方法，实验证明其有效且高效。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLM）的可靠性，但其不确定性量化并非易事。

Method: 提出一种新颖的灰盒不确定性量化方法，通过测量语义保留干预前后模型输出的变化来量化LLM的不确定性。

Result: 通过理论论证，表明该方法能有效估计认知不确定性，并在广泛的LLM和问答数据集上的实验证明了其有效性和计算效率。

Conclusion: 所提出的基于语义不变性的灰盒方法是一种有效且计算高效的LLM不确定性量化方法。

Abstract: Uncertainty Quantification (UQ) is a promising approach to improve model
reliability, yet quantifying the uncertainty of Large Language Models (LLMs) is
non-trivial. In this work, we establish a connection between the uncertainty of
LLMs and their invariance under semantic-preserving intervention from a causal
perspective. Building on this foundation, we propose a novel grey-box
uncertainty quantification method that measures the variation in model outputs
before and after the semantic-preserving intervention. Through theoretical
justification, we show that our method provides an effective estimate of
epistemic uncertainty. Our extensive experiments, conducted across various LLMs
and a variety of question-answering (QA) datasets, demonstrate that our method
excels not only in terms of effectiveness but also in computational efficiency.

</details>


### [126] [Multi-Label Clinical Text Eligibility Classification and Summarization System](https://arxiv.org/abs/2510.13115)
*Surya Tejaswi Yerramsetty,Almas Fathimah*

Main category: cs.CL

TL;DR: 该研究提出了一种利用NLP和LLM自动对临床试验的入选/排除标准进行多标签文本分类和文本摘要的系统，以提高临床试验招募效率。


<details>
  <summary>Details</summary>
Motivation: 临床试验对医学进步至关重要，需要包含具有适当和多样化背景的参与者。然而，手动评估入选/排除标准耗时耗力。

Method: 1. 结合词嵌入（Word2Vec）和命名实体识别等特征提取方法，以及词频-逆文档频率（TF-IDF）等传统向量化技术来识别医学概念。 2. 探索加权的TF-IDF词嵌入，整合计数和嵌入的优点。 3. 使用随机森林和支持向量机（SVM）模型进行多标签分类。 4. 评估TextRank、Luhn和GPT-3等摘要技术。 5. 使用ROUGE分数评估效果。

Result: 所提出的方法在临床试验入选/排除标准的多标签分类和摘要方面，通过ROUGE分数证明了其有效性。

Conclusion: 该系统有潜力通过数据驱动的方法实现临床试验资格评估的自动化，从而提高研究效率。

Abstract: Clinical trials are central to medical progress because they help improve
understanding of human health and the healthcare system. They play a key role
in discovering new ways to detect, prevent, or treat diseases, and it is
essential that clinical trials include participants with appropriate and
diverse medical backgrounds. In this paper, we propose a system that leverages
Natural Language Processing (NLP) and Large Language Models (LLMs) to automate
multi-label clinical text eligibility classification and summarization. The
system combines feature extraction methods such as word embeddings (Word2Vec)
and named entity recognition to identify relevant medical concepts, along with
traditional vectorization techniques such as count vectorization and TF-IDF
(Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF
word embeddings that integrate both count-based and embedding-based strengths
to capture term importance effectively. Multi-label classification using Random
Forest and SVM models is applied to categorize documents based on eligibility
criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are
evaluated to concisely summarize eligibility requirements. Evaluation with
ROUGE scores demonstrates the effectiveness of the proposed methods. This
system shows potential for automating clinical trial eligibility assessment
using data-driven approaches, thereby improving research efficiency.

</details>


### [127] [Stable LLM Ensemble: Interaction between Example Representativeness and Diversity](https://arxiv.org/abs/2510.13143)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: LLM 集成模型的预测精度和鲁棒性对示例选择和输出多样性敏感。本文提出了一种结合代表性示例选择和提高采样温度的方法，该方法在 macro-F1 和 RMSE 指标上显著优于随机选择，并且优于 5-shot 提示。


<details>
  <summary>Details</summary>
Motivation: LLM 的 one-shot 预测精度和鲁棒性对示例和集成成员的多样性非常敏感，本研究旨在系统地研究示例代表性（one-shot 策略）和输出多样性（采样温度）对 LLM 集成模型性能的影响。

Method: 比较了两种 one-shot 策略：基于质心的代表性示例（提出）和随机抽样示例（基线），并改变了采样温度。

Result: 所提出的方法在较高的温度设置下，通过 +7.6%（macro-F1）和 -10.5%（RMSE）显著优于随机选择。此外，所提出的模型在 macro-F1 指标上比 5-shot 提示高出 +21.1%，在 RMSE 指标上低出 -24.0%。

Conclusion: 结合代表性示例选择和提高采样温度可以为集成模型提供适当的多样性。这项工作强调了在设计有效的 one-shot LLM 集成模型时，示例选择和受控多样性都具有实际重要性。

Abstract: Large language models (LLMs) have achieved remarkable results in wide range
of domains. However, the accuracy and robustness of one-shot LLM predictions
remain highly sensitive to the examples and the diversity among ensemble
members. This study systematically investigates the effects of example
representativeness (one-shot strategy) and output diversity (sampling
temperature) on LLM ensemble performance. Two one-shot strategies are compared:
centroid-based representative examples (proposed) and randomly sampled examples
(baseline) and sampling temperature also is varied. The proposed approach with
higher temperature setting significantly outperforms random selection by +7.6%
(macro-F1) and -10.5% (RMSE). Furthermore, the proposed model exceeds 5-shot
prompting by +21.1% (macro-F1) and -24.0% (RMSE). Our findings demonstrate that
combining representative example selection with increased temperature provides
the appropriate level of diversity to the ensemble. This work highlights the
practical importance of both example selection and controlled diversity in
designing effective one-shot LLM ensembles.

</details>


### [128] [I Am Aligned, But With Whom? MENA Values Benchmark for Evaluating Cultural Alignment and Multilingual Bias in LLMs](https://arxiv.org/abs/2510.13154)
*Pardis Sadat Zahraei,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: MENAValues是一个新的基准，用于评估大型语言模型（LLM）在文化认同和多语言偏见方面与中东和北非（MENA）地区的信仰和价值观的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 评估中东和北非（MENA）地区在当前人工智能评估中的代表性不足问题，并评估大型语言模型（LLM）的文化适应性和多语言偏见。

Method: MENAValues通过整合大规模、权威的人类调查数据，构建了一个结构化数据集，涵盖了16个国家的人口层面响应分布。通过三种视角（中立、个性化、第三人称/文化观察者）和两种语言模式（英语和本地语言：阿拉伯语、波斯语、土耳其语）的组合来评估多种模型。

Result: 研究发现了三种关键现象：“跨语言价值转移”，即相同问题根据语言不同会产生截然不同的回答；“推理诱导的退化”，即要求模型解释其推理过程会加剧文化适应性的问题；以及“对数泄漏”，即模型在拒绝回答敏感问题时，内部概率却显示出强烈的隐藏偏好。此外，研究还表明，模型在本地语言模式下会简化为单一的语言类别，将多元化的国家视为同质化的实体。

Conclusion: MENAValues提供了一个可扩展的框架，用于诊断文化不适应性问题，并为开发更具文化包容性的人工智能提供了实证见解和方法论工具。

Abstract: We introduce MENAValues, a novel benchmark designed to evaluate the cultural
alignment and multilingual biases of large language models (LLMs) with respect
to the beliefs and values of the Middle East and North Africa (MENA) region, an
underrepresented area in current AI evaluation efforts. Drawing from
large-scale, authoritative human surveys, we curate a structured dataset that
captures the sociocultural landscape of MENA with population-level response
distributions from 16 countries. To probe LLM behavior, we evaluate diverse
models across multiple conditions formed by crossing three perspective framings
(neutral, personalized, and third-person/cultural observer) with two language
modes (English and localized native languages: Arabic, Persian, Turkish). Our
analysis reveals three critical phenomena: "Cross-Lingual Value Shifts" where
identical questions yield drastically different responses based on language,
"Reasoning-Induced Degradation" where prompting models to explain their
reasoning worsens cultural alignment, and "Logit Leakage" where models refuse
sensitive questions while internal probabilities reveal strong hidden
preferences. We further demonstrate that models collapse into simplistic
linguistic categories when operating in native languages, treating diverse
nations as monolithic entities. MENAValues offers a scalable framework for
diagnosing cultural misalignment, providing both empirical insights and
methodological tools for developing more culturally inclusive AI.

</details>


### [129] [Mirror Speculative Decoding: Breaking the Serial Barrier in LLM Inference](https://arxiv.org/abs/2510.13161)
*Nikhil Bhendawade,Kumari Nishu,Arnav Kundu,Chris Bartels,Minsik Cho,Irina Belousova*

Main category: cs.CL

TL;DR: Mirror-SD通过并行异构执行和多代元流式传输，实现了2.8倍-5.8倍的加速，克服了延迟-接受权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的推测解码方法在提高接受率的同时会增加延迟，限制了速度-准确性权衡。人们需要一种新的方法来打破这种权衡。

Method: Mirror-SD通过并行运行目标模型和草稿模型，并将计算分配给GPU和NPU，以及通过草稿模型进行多代元流式传输来预测多个标记，从而实现推测解码。

Result: 在SpecBench上，Mirror-SD在14B到66B参数的服务器规模模型上实现了2.8倍-5.8倍的实际时间加速，比现有的最佳基线EAGLE3提高了30%。

Conclusion: Mirror-SD通过并行异构执行和多代元流式传输，实现了推测解码的理想状态，即高接受率和低开销。

Abstract: Speculative decoding accelerates LLM inference by using a draft model to look
ahead, but gains are capped by the cost of autoregressive draft generation:
increasing draft size elevates acceptance rates but introduces additional
latency overhead exacerbating the speed-accuracy tradeoff. Prior methods
(Medusa, Hydra, EAGLE) partially reduce draft cost but either degrade
acceptance or introduce overheads that limit scaling. We present Mirror
Speculative Decoding (Mirror-SD), an inference algorithm that breaks the
latency-acceptance tradeoff. Mirror-SD launches branch-complete rollouts from
early-exit signals in parallel with the target model's suffix and explicitly
maps computation across heterogeneous accelerators (GPU and NPU) to exploit
cross-device parallelism. The draft speculates forward continuations for the
target to verify, while the target simultaneously speculates correction paths
for the draft, converting speculation into two complementary execution
pipelines. To further cut draft latency without weakening acceptance semantics,
we add speculative streaming so the draft emits multiple tokens per step. This
dual strategy of parallel heterogeneous execution plus multi-token speculative
streaming pushes speculative decoding toward its ideal regime of high
acceptance with low overhead. On SpecBench with server-scale models from 14B to
66B parameters, Mirror-SD delivers consistent end-to-end gains, achieving
2.8x-5.8x wall-time speedups across diverse tasks and a 30% average relative
improvement over the strongest baseline, EAGLE3.

</details>


### [130] [A Matter of Representation: Towards Graph-Based Abstract Code Generation](https://arxiv.org/abs/2510.13163)
*Nyx Iskandar,Hisham Bedri,Andy Tsen*

Main category: cs.CL

TL;DR: LLM在生成代码图方面表现出色，表示形式至关重要。


<details>
  <summary>Details</summary>
Motivation: 目前LLM在生成代码图方面存在不足，需要探索新的表示方法以提高其在视觉编程等场景下的应用。

Method: 提出并评估了基于JSON的图表示方法，并在ScratchTest基准上进行了测试。

Result: LLM在有合适的图表示时，能够单次生成代码图；不同的表示方法对生成准确率有显著影响。

Conclusion: 该研究为基于代码图的抽象代码生成奠定了表示学习的基础。

Abstract: Most large language models (LLMs) today excel at generating raw, sequential
code with minimal abstractions and custom structures. However, there has been
little work on graph-based abstract code generation, where significant logic is
encapsulated in predefined nodes and execution flow is determined by edges.
This is relevant for visual programming languages, and in cases where raw
source code is inaccessible to users and LLM training sets. In this work, we
propose and evaluate JSON representations for graphs to enable high accuracy
graph-based abstract code generation. We evaluate these representations on
ScratchTest, a mini-benchmark based on our custom Python re-implementation of
Scratch, which tests the LLM in code graph space. Our findings demonstrate that
LLMs can indeed perform the aforementioned generation task in a single pass
without relying on specialized or complex pipelines, given the correct graph
representations. We also show that different representations induce
significantly different accuracies, highlighting the instrumental role of
representations in this generation task. All in all, this work establishes the
first steps towards representation learning for graph-based abstract code
generation.

</details>


### [131] [CoT-Evo: Evolutionary Distillation of Chain-of-Thought for Scientific Reasoning](https://arxiv.org/abs/2510.13166)
*Kehua Feng,Keyan Ding,Zhihui Zhu,Lei Liang,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: CoT-Evo是一个演进式CoT蒸馏框架，通过整合多LLM的推理轨迹，并结合领域知识，迭代优化推理过程，最终生成高质量的科学推理数据集，并用于微调紧凑模型，取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT蒸馏方法在科学领域由于知识复杂性和专业性，LLM输出的推理轨迹常有错误或肤浅，导致蒸馏出的训练数据质量不高，限制了学生模型的性能。

Method: CoT-Evo框架首先从多个LLM思想者构建多样化的推理轨迹池，然后用自动检索的领域知识丰富这些轨迹，并通过新颖性驱动的选择、反思性重组和变异进行迭代优化。优化过程由评估答案正确性、连贯性和知识利用有效性的适应度函数指导。

Result: 生成了高质量的、针对科学推理的CoT数据集，并用该数据集微调的紧凑模型在科学推理基准上实现了SOTA性能。

Conclusion: 提出了一种可扩展的方法，用于从多样化且易出错的LLM合成高保真科学推理数据。

Abstract: While chain-of-thought (CoT) distillation from advanced large language models
(LLMs) has proven effective in general reasoning tasks, it struggles in
scientific domains where even advanced models often produce incorrect or
superficial reasoning due to high complexity and specialized knowledge
requirements. Directly distilling from such flawed outputs results in
low-quality training data and limits the performance of smaller student models.
To overcome this, we propose CoT-Evo, an evolutionary CoT distillation
framework. It begins by constructing a diverse pool of reasoning trajectories
from multiple LLM thinkers, enriches them with automatically retrieved domain
knowledge, and iteratively refines the trajectories using novelty-driven
selection, reflective recombination and mutation. The refinement is guided by a
fitness function that evaluates answer correctness, coherence, and effective
knowledge utilization. This results in a high-quality CoT dataset tailored for
scientific reasoning. We employ this evolved dataset to fine-tune a compact
model, which achieves state-of-the-art performance on scientific reasoning
benchmarks. Our work establishes a scalable approach to synthesizing
high-fidelity scientific reasoning data from diverse and fallible LLMs.

</details>


### [132] [Putting on the Thinking Hats: A Survey on Chain of Thought Fine-tuning from the Perspective of Human Reasoning Mechanism](https://arxiv.org/abs/2510.13170)
*Xiaoshu Chen,Sihang Zhou,Ke Liang,Duanyang Yuan,Haoyuan Chen,Xiaoyu Sun,Linyuan Meng,Xinwang Liu*

Main category: cs.CL

TL;DR: CoT微调通过在精心设计的推理轨迹上训练LLM来增强其推理能力，但现有研究主要关注技术层面，忽视了从人类推理机制的角度进行系统分析。本调查首次将CoT微调置于人类认知理论的框架下进行考察，特别是借鉴了“六顶思考帽”模型来分类和审视现有的CoT微调方法，并探讨了未来的研究方向。此外，还整理了相关数据集、模型性能，并维护了一个GitHub仓库以追踪最新进展。


<details>
  <summary>Details</summary>
Motivation: 现有关于CoT微调的调查主要关注技术细节，而忽略了从人类推理机制的角度进行系统性分析，尽管CoT微调的最终目标是让LLM能够像人类一样思考。因此，有必要从人类认知学的视角来研究这一技术，以弥补现有研究的不足。

Method: 本调查借鉴了“六顶思考帽”这一成熟的人类思维模式理论框架，来对CoT微调方法进行分类和审视。研究人员利用这个理论框架来分析和组织现有的CoT微调技术，并在此基础上提出了未来研究的方向。

Result: CoT微调已被证明在数学推理和代码生成等任务上显著提升了LLM的性能。本调查还收集整理了现有的数据集和模型性能表现，并通过一个GitHub仓库持续追踪该领域的最新进展。

Conclusion: 本调查首次从人类认知理论（特别是“六顶思考帽”模型）的角度对CoT微调进行了全面的梳理和分析，旨在为该领域的研究提供新的视角和理论基础，并指明了未来的研究方向，以期激发创新和推动该快速发展领域的进步。

Abstract: Chain of thought (CoT) fine-tuning aims to endow large language models (LLMs)
with reasoning capabilities by training them on curated reasoning traces. It
leverages both supervised and reinforced fine-tuning to cultivate human-like
reasoning skills in LLMs, including detailed planning, divergent thinking,
intuitive judgment, timely reflection, internal thinking, and fact perception,
etc. As CoT fine-tuning has advanced, LLMs have demonstrated substantial
improvements in tasks such as mathematical reasoning and code generation.
However, existing surveys about CoT fine-tuning primarily focus on technical
aspects and overlook a systematic analysis from the perspective of human
reasoning mechanisms. Given that the ultimate goal of CoT fine-tuning is to
enable LLMs to reason like humans, it is crucial to investigate this technique
through the lens of human cognition. To fill this gap, we present the first
comprehensive survey of CoT fine-tuning grounded in human reasoning theory.
Specifically, inspired by the well-known Six Thinking Hats framework, which
systematically characterizes common human thinking modes using six metaphorical
hats, we classify and examine CoT fine-tuning methods through this lens.
Furthermore, building upon this theory, we outline potential directions for
future research in CoT fine-tuning. In addition, we compile a comprehensive
overview of existing datasets and model performances, and a real-time GitHub
repository \footnote{https://github.com/AI-Chen/Awesome-CoT-Finetuning} that
continuously tracks recent advances in this area is maintained. We hope this
survey will serve as a valuable resource to inspire innovation and foster
progress in this rapidly evolving field.

</details>


### [133] [DSCD: Large Language Model Detoxification with Self-Constrained Decoding](https://arxiv.org/abs/2510.13183)
*Ming Dong,Jinkui Zhang,Bolong Zheng,Xinhui Tu,Po Hu,Tingting He*

Main category: cs.CL

TL;DR: DSCD是一种无需微调参数即可进行LLM去毒化的新方法，它通过强化安全层的内部分布并削弱幻觉和毒性层来减少毒性，从而提高输出安全性。该方法轻量、兼容性强且即插即用，可与其他方法结合使用。实验证明DSCD在去毒化和生成流畅度方面均达到SOTA水平，且效率优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM去毒化方法依赖外部约束，会导致额外资源开销并影响生成流畅度。因此，需要一种更高效、更流畅的去毒化方法。

Method: DSCD通过在输出生成过程中，增强安全层的内部分布，同时削弱幻觉层和毒性层的分布来实现去毒化，而无需进行参数微调。

Result: DSCD在去毒化和生成流畅度方面均达到SOTA水平，并且比现有方法具有更高的效率。实验表明该方法在代表性的开源LLM和公共数据集上是有效的。

Conclusion: DSCD是一种有前景的、可扩展的解决方案，可用于更安全的LLM部署，因为它在不损害生成流畅性的情况下，能够有效地减少毒性并提高输出安全性。

Abstract: Detoxification in large language models (LLMs) remains a significant research
challenge. Existing decoding detoxification methods are all based on external
constraints, which require additional resource overhead and lose generation
fluency. This work proposes Detoxification with Self-Constrained Decoding
(DSCD), a novel method for LLM detoxification without parameter fine-tuning.
DSCD strengthens the inner next-token distribution of the safety layer while
weakening that of hallucination and toxic layers during output generation. This
effectively diminishes toxicity and enhances output safety. DSCD offers
lightweight, high compatibility, and plug-and-play capabilities, readily
integrating with existing detoxification methods for further performance
improvement. Extensive experiments on representative open-source LLMs and
public datasets validate DSCD's effectiveness, demonstrating state-of-the-art
(SOTA) performance in both detoxification and generation fluency, with superior
efficiency compared to existing methods. These results highlight DSCD's
potential as a practical and scalable solution for safer LLM deployments.

</details>


### [134] [SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs](https://arxiv.org/abs/2510.13190)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: SHIELD是一个轻量级的、与模型无关的预处理框架，用于增强大型视觉语言模型（LVLM）的安全性，通过细粒度安全分类、类别特定引导和明确的动作（阻止、重构、转发）来防御有害输入，在多个基准和LVLM上均有效降低越狱和不遵循指令的比例，同时保持效用，并且具有可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）虽然强大，但也容易受到隐藏有害目标的恶意输入的攻击，增加了攻击面。

Method: 提出SHIELD框架，该框架结合了细粒度的安全分类、类别特定的引导以及明确的动作（阻止、重构、转发），能够根据安全分类结果，生成定制化的安全提示，实现细致的拒绝或安全重定向，而无需重新训练模型。

Result: 在五个基准和五个代表性的LVLM上进行测试，SHIELD能够有效降低越狱率和不遵循指令的比例，同时保持模型的效用。

Conclusion: SHIELD是一个即插即用的安全框架，开销极小，易于扩展以应对新的攻击类型，可以作为对弱对齐和强对齐LVLM的实用安全补丁。

Abstract: Large Vision-Language Models (LVLMs) unlock powerful multimodal reasoning but
also expand the attack surface, particularly through adversarial inputs that
conceal harmful goals in benign prompts. We propose SHIELD, a lightweight,
model-agnostic preprocessing framework that couples fine-grained safety
classification with category-specific guidance and explicit actions (Block,
Reframe, Forward). Unlike binary moderators, SHIELD composes tailored safety
prompts that enforce nuanced refusals or safe redirection without retraining.
Across five benchmarks and five representative LVLMs, SHIELD consistently
lowers jailbreak and non-following rates while preserving utility. Our method
is plug-and-play, incurs negligible overhead, and is easily extendable to new
attack types -- serving as a practical safety patch for both weakly and
strongly aligned LVLMs.

</details>


### [135] [Grounding Long-Context Reasoning with Contextual Normalization for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13191)
*Jiamin Chen,Yuchen Li,Xinyu Ma,Xinran Chen,Xiaokun Zhang,Shuaiqiang Wang,Chen Ma,Dawei Yin*

Main category: cs.CL

TL;DR: 检索增强生成（RAG）中的上下文格式对模型性能有重要影响，提出上下文归一化策略以提高鲁棒性和长上下文利用率。


<details>
  <summary>Details</summary>
Motivation: 探讨了检索到的文档在检索增强生成（RAG）中如何被表述（即上下文格式）对大型语言模型（LLM）性能的影响，这方面的研究尚不充分。

Method: 设计了控制实验，系统地研究上下文密度、分隔符样式和位置放置对模型性能的影响，并提出了一种名为‘上下文归一化’的轻量级策略，该策略能在生成前自适应地标准化上下文表示。

Result: 实验证明，即使语义内容相同，像键值提取中的分隔符或结构标记等看似细微的格式选择也会引起模型准确性和稳定性的显著变化。所提出的上下文归一化策略在各种设置下，于受控和真实世界的RAG基准测试中，均能持续提高模型对顺序变化的鲁棒性，并加强长上下文的利用。

Conclusion: 可靠的RAG不仅依赖于检索到的内容的正确性，还依赖于内容的呈现方式。这项研究为RAG的改进提供了新的实证证据和一个实用的技术。

Abstract: Retrieval-Augmented Generation (RAG) has become an essential approach for
extending the reasoning and knowledge capacity of large language models (LLMs).
While prior research has primarily focused on retrieval quality and prompting
strategies, the influence of how the retrieved documents are framed, i.e.,
context format, remains underexplored. We show that seemingly superficial
choices, such as delimiters or structural markers in key-value extraction, can
induce substantial shifts in accuracy and stability, even when semantic content
is identical. To systematically investigate this effect, we design controlled
experiments that vary context density, delimiter styles, and positional
placement, revealing the underlying factors that govern performance
differences. Building on these insights, we introduce Contextual Normalization,
a lightweight strategy that adaptively standardizes context representations
before generation. Extensive experiments on both controlled and real-world RAG
benchmarks across diverse settings demonstrate that the proposed strategy
consistently improves robustness to order variation and strengthens
long-context utilization. These findings underscore that reliable RAG depends
not only on retrieving the right content, but also on how that content is
presented, offering both new empirical evidence and a practical technique for
better long-context reasoning.

</details>


### [136] [StressTransfer: Stress-Aware Speech-to-Speech Translation with Emphasis Preservation](https://arxiv.org/abs/2510.13194)
*Xi Chen,Yuchen Song,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 我们提出了一个压力感知的语音到语音翻译（S2ST）系统，该系统利用大型语言模型（LLMs）进行跨语言压力转换，以保留单词级别的强调。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决现有语音到语音翻译（S2ST）系统在保留源语言的单词级别强调方面的不足，并提出一种有效且数据效率高的方法来解决此问题。

Method: 我们提出了一种压力感知的S2ST系统，该系统利用LLMs进行跨语言压力转换。该方法将源语言压力转换为目标语言标签，以指导可控的TTS模型。为了克服数据稀缺性，我们开发了一个自动生成对齐训练数据的管道，并引入了“LLM-as-Judge”进行评估。

Result: 实验表明，我们提出的方法在保留强调方面明显优于基线方法，同时保持了可比的翻译质量、说话人意图和自然度。

Conclusion: 我们的工作强调了韵律在翻译中的重要性，并为在S2ST中保留副语言线索提供了一种有效且数据效率高的方法。

Abstract: We propose a stress-aware speech-to-speech translation (S2ST) system that
preserves word-level emphasis by leveraging LLMs for cross-lingual emphasis
conversion. Our method translates source-language stress into target-language
tags that guide a controllable TTS model. To overcome data scarcity, we
developed a pipeline to automatically generate aligned training data and
introduce the "LLM-as-Judge" for evaluation. Experiments show our approach
substantially outperforms baselines in preserving emphasis while maintaining
comparable translation quality, speaker intent, and naturalness. Our work
highlights the importance of prosody in translation and provides an effective,
data-efficient solution for preserving paralinguistic cues in S2ST.

</details>


### [137] [Text Anomaly Detection with Simplified Isolation Kernel](https://arxiv.org/abs/2510.13197)
*Yang Cao,Sikun Yang,Yujiu Yang,Lianyong Qi,Ming Liu*

Main category: cs.CL

TL;DR: SIK通过将高维稠密嵌入映射到低维稀疏表示来解决大语言模型文本异常检测中的内存和计算挑战，在7个数据集上实现了优于11种SOTA算法的性能，同时保持了计算效率和低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的预训练嵌入在高维稠密表示上存在显著的内存和计算成本，这给文本异常检测带来了挑战。

Method: 提出了一种简化的隔离核（SIK），将高维稠密嵌入映射到低维稀疏表示，并具有线性时间复杂度和创新的边界关注特征映射，以减少空间复杂度。

Result: SIK在7个数据集上的实验表明，其检测性能优于11种最先进的异常检测算法，同时保持了计算效率和低内存消耗。

Conclusion: SIK有效地解决了LLM嵌入在文本异常检测中的计算和内存瓶颈，并在保持效率的同时实现了优越的检测性能。

Abstract: Two-step approaches combining pre-trained large language model embeddings and
anomaly detectors demonstrate strong performance in text anomaly detection by
leveraging rich semantic representations. However, high-dimensional dense
embeddings extracted by large language models pose challenges due to
substantial memory requirements and high computation time. To address this
challenge, we introduce the Simplified Isolation Kernel (SIK), which maps
high-dimensional dense embeddings to lower-dimensional sparse representations
while preserving crucial anomaly characteristics. SIK has linear time
complexity and significantly reduces space complexity through its innovative
boundary-focused feature mapping. Experiments across 7 datasets demonstrate
that SIK achieves better detection performance than 11 state-of-the-art (SOTA)
anomaly detection algorithms while maintaining computational efficiency and low
memory cost. All code and demonstrations are available at
https://github.com/charles-cao/SIK.

</details>


### [138] [LLM-Guided Synthetic Augmentation (LGSA) for Mitigating Bias in AI Systems](https://arxiv.org/abs/2510.13202)
*Sai Suhruth Reddy Karri,Yashwanth Sai Nallapuneni,Laxmi Narasimha Reddy Mallireddy,Gopichand G*

Main category: cs.CL

TL;DR: LLM-Guided Synthetic Augmentation (LGSA) uses LLMs to create synthetic data for underrepresented groups in AI, reducing bias without sacrificing accuracy. It outperforms traditional methods by not requiring protected attributes and avoiding accuracy-tradeoffs. LGSA achieved 99.1% accuracy with only a 1.9% bias gap.


<details>
  <summary>Details</summary>
Motivation: AI systems trained on natural language data often exhibit bias due to underrepresentation of certain groups, leading to uneven performance and ethical concerns. Traditional fairness methods have limitations such as reliance on protected attributes, accuracy-fairness trade-offs, and poor generalization.

Method: The paper proposes LLM-Guided Synthetic Augmentation (LGSA), a method that leverages large language models to generate synthetic counterfactual examples for underrepresented groups. This process involves using structured prompts to create gender-swapped paraphrases, followed by rigorous quality control including semantic similarity checks, attribute verification, toxicity screening, and human spot checks. The augmented dataset is then used to train a classifier.

Result: LGSA significantly reduces performance disparities across demographics without compromising overall accuracy. In an evaluation on a dataset with gendered pronouns and professions, LGSA achieved 99.1% accuracy with a 1.9% bias gap, outperforming both the baseline model (96.7% accuracy, 7.2% bias gap) and simple swap augmentation (95.6% accuracy, 0.7% bias gap). LGSA specifically improved performance on female-labeled examples.

Conclusion: LGSA is an effective strategy for mitigating bias in AI systems. It enhances subgroup balance and maintains high task accuracy and label fidelity, addressing the limitations of traditional fairness methods.

Abstract: Bias in AI systems, especially those relying on natural language data, raises
ethical and practical concerns. Underrepresentation of certain groups often
leads to uneven performance across demographics. Traditional fairness methods,
such as pre-processing, in-processing, and post-processing, depend on
protected-attribute labels, involve accuracy-fairness trade-offs, and may not
generalize across datasets. To address these challenges, we propose LLM-Guided
Synthetic Augmentation (LGSA), which uses large language models to generate
counterfactual examples for underrepresented groups while preserving label
integrity. We evaluated LGSA on a controlled dataset of short English sentences
with gendered pronouns, professions, and binary classification labels.
Structured prompts were used to produce gender-swapped paraphrases, followed by
quality control including semantic similarity checks, attribute verification,
toxicity screening, and human spot checks. The augmented dataset expanded
training coverage and was used to train a classifier under consistent
conditions. Results show that LGSA reduces performance disparities without
compromising accuracy. The baseline model achieved 96.7 percent accuracy with a
7.2 percent gender bias gap. Simple swap augmentation reduced the gap to 0.7
percent but lowered accuracy to 95.6 percent. LGSA achieved 99.1 percent
accuracy with a 1.9 percent bias gap, improving performance on female-labeled
examples. These findings demonstrate that LGSA is an effective strategy for
bias mitigation, enhancing subgroup balance while maintaining high task
accuracy and label fidelity.

</details>


### [139] [A fully automated and scalable Parallel Data Augmentation for Low Resource Languages using Image and Text Analytics](https://arxiv.org/abs/2510.13211)
*Prawaal Sharma,Navneet Goyal,Poonam Goyal,Vishnupriyan R*

Main category: cs.CL

TL;DR: 该论文提出了一种自动化的方法，利用图像和文本分析从报纸文章中提取双语平行语料库，以解决低资源语言的自然语言处理（NLP）问题，并通过机器翻译任务验证了该方法的有效性， BLEU分数提高了近3分。


<details>
  <summary>Details</summary>
Motivation: 全球语言多样性导致数字语言资源匮乏，限制了技术惠及大部分人口，特别是低资源语言的自然语言处理（NLP）任务面临数据资源缺乏的困难。

Method: 提出了一种新颖的、可扩展的、全自动化的方法，利用图像和文本分析从报纸文章中提取双语平行语料库。

Result: 通过构建两种不同语言组合的双语平行语料库来验证该方法，并通过下游的机器翻译任务证明了该数据集的价值，相较于当前基线，BLEU分数提高了近3分。

Conclusion: 所提出的自动化方法能够有效地提取双语平行语料库，并能通过下游任务（如机器翻译）带来显著的性能提升，有助于缓解低资源语言在NLP领域面临的资源困境。

Abstract: Linguistic diversity across the world creates a disparity with the
availability of good quality digital language resources thereby restricting the
technological benefits to majority of human population. The lack or absence of
data resources makes it difficult to perform NLP tasks for low-resource
languages. This paper presents a novel scalable and fully automated methodology
to extract bilingual parallel corpora from newspaper articles using image and
text analytics. We validate our approach by building parallel data corpus for
two different language combinations and demonstrate the value of this dataset
through a downstream task of machine translation and improve over the current
baseline by close to 3 BLEU points.

</details>


### [140] [Do You Get the Hint? Benchmarking LLMs on the Board Game Concept](https://arxiv.org/abs/2510.13271)
*Ine Gevers,Walter Daelemans*

Main category: cs.CL

TL;DR: LLMs在抽象推理方面存在根本性弱点，即使在自然语言表示的游戏中也是如此。在多语言评估中，LLM在英语以外的语言中表现更差。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在抽象推理方面的能力，特别是在自然语言表示的任务中，因为现有的基准测试（如使用网格、符号或视觉模式）与LLM的训练数据差异较大。

Method: 引入一个名为Concept的词语猜测棋盘游戏作为基准测试，该游戏使用自然语言表示。对最先进的LLM在Concept游戏上的表现进行评估，并在多种语言（包括英语、荷兰语、法语和西班牙语）中扩展了评估范围。

Result: 人类玩家在该游戏中表现出色（成功率超过90%），而最先进的LLM的表现仍然具有挑战性（成功率不超过40%）。LLM在理解其他玩家的策略意图以及根据顺序信息更新来修正初始假设方面存在困难。在较低资源语言（荷兰语、法语、西班牙语）中，LLM的性能比英语进一步下降。

Conclusion: Concept游戏揭示了LLM在抽象推理方面的根本性弱点，即使在接近其训练数据的自然语言表示中也是如此。LLM在多语言场景下的表现不佳，尤其是在较低资源语言中，这表明在跨语言和抽象推理能力方面仍有改进空间。

Abstract: Large language models (LLMs) have achieved striking successes on many
benchmarks, yet recent studies continue to expose fundamental weaknesses. In
particular, tasks that require abstract reasoning remain challenging, often
because they use representations such as grids, symbols, or visual patterns
that differ from the natural language data LLMs are trained on. In this paper,
we introduce Concept, a simple word-guessing board game, as a benchmark for
probing abductive reasoning in a representation that is much closer to LLM
pre-training data: natural language. Our results show that this game, easily
solved by humans (with a success rate of over 90\%), is still very challenging
for state-of-the-art LLMs (no model exceeds 40\% success rate). Specifically,
we observe that LLMs struggle with interpreting other players' strategic
intents, and with correcting initial hypotheses given sequential information
updates. In addition, we extend the evaluation across multiple languages, and
find that the LLM performance drops further in lower-resource languages (Dutch,
French, and Spanish) compared to English.

</details>


### [141] [Beyond Correctness: Rewarding Faithful Reasoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13272)
*Zhichao Xu,Zongyu Wu,Yun Zhou,Aosong Feng,Kang Zhou,Sangmin Woo,Kiran Ramnath,Yijun Tian,Xuan Qi,Weikang Qiu,Lin Lee Cheong,Haibo Ding*

Main category: cs.CL

TL;DR: 尽管RL在LLM训练中取得了成功，但现有基于RL的搜索代理在提高最终答案正确性的同时，忽视了中间推理步骤的质量，导致链式思考不忠实。本文提出了VERITAS框架，通过集成细粒度的忠实度奖励来解决这个问题，显著提高了推理忠实度，并保持了可比的任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的搜索代理在LLM训练中存在链式思考不忠实的问题，需要一个更全面的评估框架和改进的方法来提高推理忠实度。

Method: 提出一个包含信息-思考忠实度、思考-答案忠实度、思考-搜索忠实度三个指标的综合评估框架。并提出VERITAS框架，将细粒度的忠实度奖励集成到RL训练过程中。

Result: 提出的评估框架揭示了原型RL搜索代理Search-R1在忠实度方面有很大提升空间。使用VERITAS训练的模型显著提高了推理忠实度，并在七个QA基准测试中取得了相当的任务性能。

Conclusion: VERITAS框架能够有效提高基于RL的搜索代理的推理忠实度，同时不牺牲任务性能。

Abstract: Inspired by the success of reinforcement learning (RL) in Large Language
Model (LLM) training for domains like math and code, recent works have begun
exploring how to train LLMs to use search engines more effectively as tools for
retrieval-augmented generation. Although these methods achieve performance
improvement across QA benchmarks, many prioritize final answer correctness
while overlooking the quality of intermediate reasoning steps, which may lead
to chain-of-thought unfaithfulness. In this paper, we first introduce a
comprehensive evaluation framework for evaluating RL-based search agents,
covering three distinct faithfulness metrics: information-think faithfulness,
think-answer faithfulness, and think-search faithfulness. Our evaluations
reveal that a prototypical RL-based search agent, Search-R1, has significant
room for improvement in this regard. To foster faithful reasoning, we introduce
VERITAS (Verifying Entailed Reasoning through Intermediate Traceability in
Agentic Search), a novel framework that integrates fine-grained faithfulness
rewards into the reinforcement learning process. Our experiments show that
models trained with VERITAS not only significantly improve reasoning
faithfulness, but also achieve comparable task performance across seven QA
benchmarks.

</details>


### [142] [In-Distribution Steering: Balancing Control and Coherence in Language Model Generation](https://arxiv.org/abs/2510.13285)
*Arthur Vogels,Benjamin Wong,Yann Choho,Annabelle Blangero,Milan Bhan*

Main category: cs.CL

TL;DR: IDS是一种新的激活引导方法，它根据输入数据分布动态调整引导强度，以提高LLM的可控性和生成稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法依赖固定的引导强度，导致控制不足或干预不当，影响文本的可信度和连贯性。

Method: IDS根据表示空间中的输入数据分布动态调整引导强度，实现自适应干预和生成稳定性。

Result: IDS在分类任务上实现了高准确率，并生成了连贯的文本，没有出现崩溃。

Conclusion: IDS能够实现自适应干预和生成稳定性，适用于实际应用。

Abstract: Activation steering methods control large language model (LLM) behavior by
modifying internal activations at inference time. However, most existing
activation steering methods rely on a fixed steering strength, leading to
either insufficient control or unadapted intervention that degrades text
plausibility and coherence. We introduce In-Distribution Steering (IDS), a
novel method that adapts steering strength based on the input data distribution
in representation space. IDS dynamically adjusts interventions according to how
far a given input lies within the distribution, enabling adaptive intervention
and generation stability during text generation. Experiments demonstrate that
IDS achieves strong accuracy on classification tasks while producing coherent
text without collapse, making IDS particularly well suited for real-world
applications.

</details>


### [143] [Higher Satisfaction, Lower Cost: A Technical Report on How LLMs Revolutionize Meituan's Intelligent Interaction Systems](https://arxiv.org/abs/2510.13291)
*Xuxin Cheng,Ke Zeng,Zhiquan Cao,Linyi Dai,Wenxuan Gao,Fei Han,Ai Jian,Feng Hong,Wenxing Hu,Zihe Huang,Dejian Kong,Jia Leng,Zhuoyuan Liao,Pei Liu,Jiaye Lin,Xing Ma,Jingqing Ruan,Jiaxing Song,Xiaoyu Tan,Ruixuan Xiao,Wenhui Yu,Wenyu Zhan,Haoxing Zhang,Chao Zhou,Hao Zhou,Shaodong Zheng,Ruinian Chen,Siyuan Chen,Ziyang Chen,Yiwen Dong,Yaoyou Fan,Yangyi Fang,Yang Gan,Shiguang Guo,Qi He,Chaowen Hu,Binghui Li,Dailin Li,Xiangyu Li,Yan Li,Chengjian Liu,Xiangfeng Liu,Jiahui Lv,Qiao Ma,Jiang Pan,Cong Qin,Chenxing Sun,Wen Sun,Zhonghui Wang,Abudukelimu Wuerkaixi,Xin Yang,Fangyi Yuan,Yawen Zhu,Tianyi Zhai,Jie Zhang,Runlai Zhang,Yao Xu,Yiran Zhao,Yifan Wang,Xunliang Cai,Yangen Hu,Cao Liu,Lu Pan,Xiaoli Wang,Bo Xiao,Wenyuan Yao,Qianlin Zhou,Benchang Zhu*

Main category: cs.CL

TL;DR: WOWService是一个为工业应用设计的智能交互系统，它集成了大型语言模型（LLMs）和多智能体架构，以应对智能交互系统在数据构建、对话性能、业务规则适应性、多智能体协作和评估方面的挑战。该系统已在美团App上部署，显著提升了用户满意度。


<details>
  <summary>Details</summary>
Motivation: 提升客户体验对于企业成功至关重要，尤其是随着服务需求的增长。智能交互系统需要克服数据稀疏、对话能力不足、业务规则频繁变动、单一LLM能力局限以及评估困难等挑战。

Method: WOWService集成了LLMs和多智能体架构，专注于数据构建、通用能力提升、业务场景适应、多智能体协调和自动化评估等核心模块，以实现自主任务管理和协作问题解决。

Result: WOWService在美团App上的部署带来了显著的性能提升，用户满意度指标1（USM 1）下降了27.53%，用户满意度指标2（USM 2）提升了25.51%。

Conclusion: WOWService通过集成LLMs和多智能体架构，有效解决了智能交互系统面临的诸多挑战，并在实际应用中取得了显著的成效，能够更好地满足用户需求并提供个性化服务。

Abstract: Enhancing customer experience is essential for business success, particularly
as service demands grow in scale and complexity. Generative artificial
intelligence and Large Language Models (LLMs) have empowered intelligent
interaction systems to deliver efficient, personalized, and 24/7 support. In
practice, intelligent interaction systems encounter several challenges: (1)
Constructing high-quality data for cold-start training is difficult, hindering
self-evolution and raising labor costs. (2) Multi-turn dialogue performance
remains suboptimal due to inadequate intent understanding, rule compliance, and
solution extraction. (3) Frequent evolution of business rules affects system
operability and transferability, constraining low-cost expansion and
adaptability. (4) Reliance on a single LLM is insufficient in complex
scenarios, where the absence of multi-agent frameworks and effective
collaboration undermines process completeness and service quality. (5) The
open-domain nature of multi-turn dialogues, lacking unified golden answers,
hampers quantitative evaluation and continuous optimization. To address these
challenges, we introduce WOWService, an intelligent interaction system tailored
for industrial applications. With the integration of LLMs and multi-agent
architectures, WOWService enables autonomous task management and collaborative
problem-solving. Specifically, WOWService focuses on core modules including
data construction, general capability enhancement, business scenario
adaptation, multi-agent coordination, and automated evaluation. Currently,
WOWService is deployed on the Meituan App, achieving significant gains in key
metrics, e.g., User Satisfaction Metric 1 (USM 1) -27.53% and User Satisfaction
Metric 2 (USM 2) +25.51%, demonstrating its effectiveness in capturing user
needs and advancing personalized service.

</details>


### [144] [Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models](https://arxiv.org/abs/2510.13293)
*Yizhou Peng,Yukun Ma,Chong Zhang,Yi-Wen Chao,Chongjia Ni,Bin Ma*

Main category: cs.CL

TL;DR: While Text-to-Speech (TTS) systems can achieve fine-grained control over emotional expression via natural language prompts, a significant challenge emerges when the desired emotion (style prompt) conflicts with the semantic content of the text. This mismatch often results in unnatural-sounding speech, undermining the goal of achieving fine-grained emotional control. Classifier-Free Guidance (CFG) is a key technique for enhancing prompt alignment; however, its application to auto-regressive (AR) TTS models remains underexplored, which can lead to degraded audio quality. This paper directly addresses the challenge of style-content mismatch in AR TTS models by proposing an adaptive CFG scheme that adjusts to different levels of the detected mismatch, as measured using large language models or natural language inference models. This solution is based on a comprehensive analysis of CFG's impact on emotional expressiveness in state-of-the-art AR TTS models. Our results demonstrate that the proposed adaptive CFG scheme improves the emotional expressiveness of the AR TTS model while maintaining audio quality and intelligibility.


<details>
  <summary>Details</summary>
Motivation: Existing Text-to-Speech (TTS) systems struggle with style-content mismatch, leading to unnatural speech when emotional prompts conflict with semantic content. Classifier-Free Guidance (CFG) helps with prompt alignment but is underexplored in auto-regressive (AR) TTS models, potentially degrading audio quality.

Method: Proposes an adaptive CFG scheme for AR TTS models that adjusts to detected style-content mismatch levels, measured using large language models or natural language inference models. This is based on an analysis of CFG's impact on emotional expressiveness in AR TTS models.

Result: The proposed adaptive CFG scheme enhances the emotional expressiveness of AR TTS models.

Conclusion: The adaptive CFG scheme effectively improves emotional expressiveness in AR TTS while preserving audio quality and intelligibility, addressing the challenge of style-content mismatch.

Abstract: While Text-to-Speech (TTS) systems can achieve fine-grained control over
emotional expression via natural language prompts, a significant challenge
emerges when the desired emotion (style prompt) conflicts with the semantic
content of the text. This mismatch often results in unnatural-sounding speech,
undermining the goal of achieving fine-grained emotional control.
Classifier-Free Guidance (CFG) is a key technique for enhancing prompt
alignment; however, its application to auto-regressive (AR) TTS models remains
underexplored, which can lead to degraded audio quality. This paper directly
addresses the challenge of style-content mismatch in AR TTS models by proposing
an adaptive CFG scheme that adjusts to different levels of the detected
mismatch, as measured using large language models or natural language inference
models. This solution is based on a comprehensive analysis of CFG's impact on
emotional expressiveness in state-of-the-art AR TTS models. Our results
demonstrate that the proposed adaptive CFG scheme improves the emotional
expressiveness of the AR TTS model while maintaining audio quality and
intelligibility.

</details>


### [145] [LLM one-shot style transfer for Authorship Attribution and Verification](https://arxiv.org/abs/2510.13302)
*Pablo Miralles-González,Javier Huertas-Tato,Alejandro Martín,David Camacho*

Main category: cs.CL

TL;DR: 该研究提出了一种利用大型语言模型（LLM）的预训练和上下文学习能力，通过衡量文本间风格迁移性来分析写作风格的无监督方法，旨在解决传统方法混淆风格与主题的问题，并在作者身份验证等任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的计算语言计量学方法在分析写作风格时，容易受到虚假相关性的影响，并且常常将风格与主题混淆。尽管大型语言模型（LLM）在人工智能生成文本检测方面有天然优势，但其在一般作者身份识别问题上的应用却很少被研究。本研究旨在提出一种新的无监督方法，利用LLM的预训练和上下文学习能力来解决这些问题。

Method: 本研究提出了一种新颖的无监督方法，利用大型语言模型（LLM）的预训练和上下文学习能力。具体来说，该方法利用LLM的对数概率来衡量从一个文本到另一个文本的风格迁移性，以此来分析写作风格。

Result: 该方法在作者身份验证任务中，显著优于同等规模的LLM提示方法，并且在控制了主题相关性后，其准确性高于经过对比学习训练的基线模型。此外，该方法的性能随着基础模型规模的增大而稳定提升，并且在作者身份验证任务中，可以通过增加测试时间计算来进一步提高准确性，从而实现计算成本和准确性之间的灵活权衡。

Conclusion: 本研究提出的基于LLM的无监督风格迁移性分析方法，能够有效解决传统方法存在的风格与主题混淆问题，并在作者身份验证等任务中取得了优于现有方法的性能，同时提供了计算成本与准确性之间的灵活选择。

Abstract: Computational stylometry analyzes writing style through quantitative patterns
in text, supporting applications from forensic tasks such as identity linking
and plagiarism detection to literary attribution in the humanities. Supervised
and contrastive approaches rely on data with spurious correlations and often
confuse style with topic. Despite their natural use in AI-generated text
detection, the CLM pre-training of modern LLMs has been scarcely leveraged for
general authorship problems. We propose a novel unsupervised approach based on
this extensive pre-training and the in-context learning capabilities of LLMs,
employing the log-probabilities of an LLM to measure style transferability from
one text to another. Our method significantly outperforms LLM prompting
approaches of comparable scale and achieves higher accuracy than contrastively
trained baselines when controlling for topical correlations. Moreover,
performance scales fairly consistently with the size of the base model and, in
the case of authorship verification, with an additional mechanism that
increases test-time computation; enabling flexible trade-offs between
computational cost and accuracy.

</details>


### [146] [ChatR1: Reinforcement Learning for Conversational Reasoning and Retrieval Augmented Question Answering](https://arxiv.org/abs/2510.13312)
*Simon Lupart,Mohammad Aliannejadi,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: ChatR1是一个基于强化学习的对话式问答（CQA）推理框架，它通过在对话轮次中交错搜索和推理，实现了比传统静态流水线更具探索性和适应性的行为。该框架引入了意图感知奖励机制来解决稀疏和延迟奖励的问题，并在多个CQA数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 对话式问答（CQA）需要推理能力来处理用户意图的演变、对话轮次中的歧义以及检索和生成之间的协调，而传统的静态流水线无法很好地处理这些挑战。

Method: ChatR1采用强化学习（RL）方法，在对话轮次中交错进行搜索和推理，而不是遵循静态的“重写、检索和生成”流程。它还提出了一种意图感知奖励机制，通过将检索和推理与不断变化的用户目标对齐来提供轮次级别的反馈，以解决RL中的稀疏和延迟奖励问题。

Result: ChatR1在3B和7B模型骨干上都表现出强大的性能，在五个CQA数据集上，使用F1、BERTScore和LLM-as-judge等不同指标衡量，其性能均优于竞争模型。消融研究证实了意图感知奖励的有效性，分析表明该模型能有效利用搜索工具并展现出多样化的推理轨迹。

Conclusion: ChatR1通过结合强化学习和意图感知奖励，为对话式问答提供了一种更灵活、更具上下文感知能力的解决方案，其性能超越了静态CQA流水线，并且在跨领域应用中表现出良好的泛化能力。

Abstract: We present ChatR1, a reasoning framework based on reinforcement learning (RL)
for conversational question answering (CQA). Reasoning plays an important role
in CQA, where user intent evolves across dialogue turns, and utterances are
often underspecified, requiring contextual interpretation, query reformulation,
and dynamic coordination between retrieval and generation. Unlike static
`rewrite, retrieve, and generate' pipelines, ChatR1 interleaves search and
reasoning across turns, enabling exploratory and adaptive behaviors learned
through RL. To address the challenge of sparse and delayed rewards in RL, we
propose an intent-aware reward that provides turn-level feedback by aligning
retrieval and reasoning with evolving user goals. Our proposed ChatR1
demonstrates strong performance on both 3B and 7B model backbones,
outperforming competitive models on five CQA datasets, measured by different
metrics (F1, BERTScore, and LLM-as-judge). We include a diverse set of CQA
datasets to cover topic shifts, evolving intents, mixed-initiative dialogues,
and multi-document grounding, testing ChatR1's performance from various
aspects. Ablation studies confirm the effectiveness of the intent-aware reward.
Our analyses further reveal diverse reasoning trajectories and effective use of
the search tool. ChatR1 also generalizes robustly across domains, demonstrating
that RL-based reasoning enables more flexible and context-sensitive behavior
than static CQA pipelines.

</details>


### [147] [Embedding-Based Context-Aware Reranker](https://arxiv.org/abs/2510.13329)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: 检索增强生成（RAG）系统通过从语料库中检索相关证据来支持下游生成。虽然将长文档拆分为多个短段落可以实现更细粒度的信息检索，但这也带来了挑战，例如需要跨段落推理才能进行正确检索。为了解决这些问题，我们提出了 EBCAR（Embedding-Based Context-Aware Reranker），一个轻量级的重排框架，它直接在检索到的段落的嵌入上操作，并通过结构信息和混合注意力机制增强跨段落理解能力，能够同时捕捉文档间的高层交互和文档内的低层关系。我们在 ConTEB 基准测试中评估了 EBCAR，证明了它在需要跨段落推理的信息检索方面的有效性，以及在准确性和效率方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的重排方法在处理需要跨段落推理（如共指消解、实体消歧、证据聚合）的信息检索任务时存在不足，并且可能具有较高的推理成本。

Method: 提出了一种名为 EBCAR（Embedding-Based Context-Aware Reranker）的轻量级重排框架。该框架直接在检索到的段落的嵌入上操作，并利用段落的结构信息和一种混合注意力机制来增强跨段落的理解能力，从而同时捕捉文档间的高层交互和文档内的低层关系。

Result: EBCAR 在需要跨段落推理的信息检索任务上表现出了有效性，并且在准确性和效率方面优于现有的最先进（SOTA）重排方法。

Conclusion: EBCAR 是一种有效的、轻量级的重排框架，能够处理需要跨段落推理的 RAG 任务，并在准确性和效率方面取得了良好的效果。

Abstract: Retrieval-Augmented Generation (RAG) systems rely on retrieving relevant
evidence from a corpus to support downstream generation. The common practice of
splitting a long document into multiple shorter passages enables finer-grained
and targeted information retrieval. However, it also introduces challenges when
a correct retrieval would require inference across passages, such as resolving
coreference, disambiguating entities, and aggregating evidence scattered across
multiple sources. Many state-of-the-art (SOTA) reranking methods, despite
utilizing powerful large pretrained language models with potentially high
inference costs, still neglect the aforementioned challenges. Therefore, we
propose Embedding-Based Context-Aware Reranker (EBCAR), a lightweight reranking
framework operating directly on embeddings of retrieved passages with enhanced
cross-passage understandings through the structural information of the passages
and a hybrid attention mechanism, which captures both high-level interactions
across documents and low-level relationships within each document. We evaluate
EBCAR against SOTA rerankers on the ConTEB benchmark, demonstrating its
effectiveness for information retrieval requiring cross-passage inference and
its advantages in both accuracy and efficiency.

</details>


### [148] [Taming the Fragility of KV Cache Eviction in LLM Inference](https://arxiv.org/abs/2510.13334)
*Yuan Feng,Haoyu Guo,JunLin Lv,S. Kevin Zhou,Xike Xie*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）的键值（KV）缓存是部署LLM的主要瓶颈。现有的缓存驱逐方法依赖于一个脆弱的稳定性假设，即某些KV缓存条目始终很重要。我们提出了DefensiveKV和Layer-DefensiveKV，一种防御性聚合策略，用于在极端情况下控制最坏情况风险。在20%的缓存大小下，我们的方法与最强的基线相比，生成质量损失分别减少了2.3倍和4.3倍。


<details>
  <summary>Details</summary>
Motivation: 现有的基于评分-聚合框架的KV缓存驱逐方法，依赖于“稳定性假设”，即一部分KV缓存条目在生成过程中始终很重要。然而，这种假设在极端情况下是脆弱的，导致基于平均聚合的方法容易出错。因此，需要一种新的方法来应对这种脆弱性。

Method: 我们提出了一种名为DefensiveKV的防御性聚合策略，这是一种两步、线性时间的тор方法，用于控制最坏情况风险。我们还提出了它的扩展，Layer-DefensiveKV，它增加了层级预算分配。这两种方法旨在通过管理最坏情况风险来抵御极端情况，而计算开销可忽略不计。

Result: 在七个任务领域（18个数据集）的实验中，与最强的基线相比，DefensiveKV和Layer-DefensiveKV在20%的缓存大小下，生成质量损失分别减少了2.3倍和4.3倍。这设定了新的性能基准。

Conclusion: 我们提出的DefensiveKV和Layer-DefensiveKV方法通过一种防御性聚合策略，有效地解决了现有KV缓存驱逐方法在极端情况下的脆弱性问题。通过管理最坏情况风险，我们的方法在不显著增加计算开销的情况下，显著减少了生成质量损失，为优化KV缓存驱逐提供了一个有前景的方向。

Abstract: Large language models have revolutionized natural language processing, yet
their deployment remains hampered by the substantial memory and runtime
overhead of the transformer's Key-Value cache. To mitigate this, recent methods
employ a scoring-aggregation framework to evict unimportant cache entries,
based on the stability assumption-that a fixed subset of entries remains
consistently important during generation. However, prior work has largely
focused on refining importance indicators for scoring, while defaulting to mean
aggregation due to a faithful trust in the stability assumption. In this work,
we argue that this underlying assumption is inherently fragile, making mean
aggregation highly vulnerable in extreme cases. To counter this, we propose a
simple yet elegant defensive aggregation strategy: a two-step, linear-time
approach that controls worst-case risk, thereby defending against extreme cases
with negligible computational overhead. Embodying this strategy, we propose a
novel cache eviction method, DefensiveKV and its extension, Layer-DefensiveKV,
which incorporates layer-wise budget allocation. Across seven task domains (18
datasets), our methods reduce generation quality loss by 2.3x and 4.3x
respectively, versus the strongest baseline under a 20% cache size. These
results set new performance benchmarks and pioneer a promising direction for
optimizing cache eviction against underlying fragility through worst-case risk
management. Our code is available at https://github.com/FFY0/DefensiveKV.

</details>


### [149] [Are Proverbs the New Pythian Oracles? Exploring Sentiment in Greek Sayings](https://arxiv.org/abs/2510.13341)
*Katerina Korre,John Pavlopoulos*

Main category: cs.CL

TL;DR: 本研究利用NLP技术分析了希腊谚语的情感倾向，并绘制了希腊谚语情感分布图。


<details>
  <summary>Details</summary>
Motivation: 许多文化中的谚语由于口头传统而未被充分研究，本研究旨在利用NLP技术探索希腊谚语的情感。

Method: 研究者首先收集并扩充了一个包含希腊本土方言的谚语数据集，然后利用大型语言模型（LLMs）对这些谚语进行情感分类，并结合地理位置、方言和主题进行综合分析。

Result: 研究结果表明，LLMs能够准确地对谚语进行情感分类，并且希腊大部分地区以负面情感的谚语为主。

Conclusion: LLMs在处理非传统情感极性任务方面表现出色，为谚语情感分析提供了有效途径。

Abstract: Proverbs are among the most fascinating linguistic phenomena that transcend
cultural and linguistic boundaries. Yet, much of the global landscape of
proverbs remains underexplored, as many cultures preserve their traditional
wisdom within their own communities due to the oral tradition of the
phenomenon. Taking advantage of the current advances in Natural Language
Processing (NLP), we focus on Greek proverbs, analyzing their sentiment.
Departing from an annotated dataset of Greek proverbs, we expand it to include
local dialects, effectively mapping the annotated sentiment. We present (1) a
way to exploit LLMs in order to perform sentiment classification of proverbs,
(2) a map of Greece that provides an overview of the distribution of sentiment,
(3) a combinatory analysis in terms of the geographic position, dialect, and
topic of proverbs. Our findings show that LLMs can provide us with an accurate
enough picture of the sentiment of proverbs, especially when approached as a
non-conventional sentiment polarity task. Moreover, in most areas of Greece
negative sentiment is more prevalent.

</details>


### [150] [Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems](https://arxiv.org/abs/2510.13351)
*Karthik Avinash,Nikhil Pareek,Rishav Hada*

Main category: cs.CL

TL;DR: Protect是一个原生多模态的保护系统，可以处理文本、图像和音频输入，解决了现有解决方案在实时监控、多模态数据处理和可解释性方面的不足，并在四个安全维度上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM保护系统在实时监控、多模态数据处理和可解释性方面存在不足，难以满足在监管环境下的部署需求，并且大多只支持文本处理，无法满足多模态、生产规模化的需求。

Method: 提出了一种名为Protect的原生多模态保护系统，集成了通过低秩适配（LoRA）在包含毒性、性别歧视、数据隐私和提示注入四个安全维度的多模态数据集上训练的、针对特定类别的微调适配器。该系统采用教师辅助标注流程，利用推理和解释痕迹生成高保真、上下文感知的跨模态标签。

Result: Protect在所有安全维度上都取得了最先进的性能，并且优于WildGuard、LlamaGuard-4和GPT-4.1等现有的开源和专有模型。

Conclusion: Protect为构建可信、可审计、可投入生产使用的安全系统奠定了坚实的基础，能够跨文本、图像和音频多种模态进行操作。

Abstract: The increasing deployment of Large Language Models (LLMs) across enterprise
and mission-critical domains has underscored the urgent need for robust
guardrailing systems that ensure safety, reliability, and compliance. Existing
solutions often struggle with real-time oversight, multi-modal data handling,
and explainability -- limitations that hinder their adoption in regulated
environments. Existing guardrails largely operate in isolation, focused on text
alone making them inadequate for multi-modal, production-scale environments. We
introduce Protect, natively multi-modal guardrailing model designed to operate
seamlessly across text, image, and audio inputs, designed for enterprise-grade
deployment. Protect integrates fine-tuned, category-specific adapters trained
via Low-Rank Adaptation (LoRA) on an extensive, multi-modal dataset covering
four safety dimensions: toxicity, sexism, data privacy, and prompt injection.
Our teacher-assisted annotation pipeline leverages reasoning and explanation
traces to generate high-fidelity, context-aware labels across modalities.
Experimental results demonstrate state-of-the-art performance across all safety
dimensions, surpassing existing open and proprietary models such as WildGuard,
LlamaGuard-4, and GPT-4.1. Protect establishes a strong foundation for
trustworthy, auditable, and production-ready safety systems capable of
operating across text, image, and audio modalities.

</details>


### [151] [Personal Attribute Leakage in Federated Speech Models](https://arxiv.org/abs/2510.13357)
*Hamdan Al-Ali,Ali Reza Ghavamipour,Tommaso Caselli,Fatih Turkmen,Zeerak Talat,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: 联邦设置下的自动语音识别（ASR）模型容易受到属性推理攻击，特别是当属性在预训练数据中代表性不足时。


<details>
  <summary>Details</summary>
Motivation: 评估联邦设置下ASR模型对属性推理攻击的漏洞。

Method: 使用仅基于权重差异的非参数白盒攻击方法，在被动威胁模型下测试Wav2Vec2、HuBERT和Whisper模型。

Result: 研究证明了针对性别、年龄、口音、情绪和构音障碍等敏感属性的攻击可行性。在预训练数据中代表性不足或缺失的属性更容易受到攻击。口音信息可以从所有模型中可靠地推断出来。

Conclusion: 联邦ASR模型存在未公开的漏洞，需要加强安全措施。

Abstract: Federated learning is a common method for privacy-preserving training of
machine learning models. In this paper, we analyze the vulnerability of ASR
models to attribute inference attacks in the federated setting. We test a
non-parametric white-box attack method under a passive threat model on three
ASR models: Wav2Vec2, HuBERT, and Whisper. The attack operates solely on weight
differentials without access to raw speech from target speakers. We demonstrate
attack feasibility on sensitive demographic and clinical attributes: gender,
age, accent, emotion, and dysarthria. Our findings indicate that attributes
that are underrepresented or absent in the pre-training data are more
vulnerable to such inference attacks. In particular, information about accents
can be reliably inferred from all models. Our findings expose previously
undocumented vulnerabilities in federated ASR models and offer insights towards
improved security.

</details>


### [152] [D-SMART: Enhancing LLM Dialogue Consistency via Dynamic Structured Memory And Reasoning Tree](https://arxiv.org/abs/2510.13363)
*Xiang Lei,Qin Li,Min Zhang,Min Zhang*

Main category: cs.CL

TL;DR: D-SMART是一个模型无关的框架，通过构建和推理动态的、结构化的对话语境表示来解决大型语言模型在多轮对话中事实不一致和逻辑衰退的问题。它包含一个动态结构化内存（DSM）来维护对话知识图谱，以及一个推理树（RT）来执行基于图谱的推理。D-SMART还引入了基于自然语言推断（NLI）的新指标来评估多轮对话一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在多轮对话中存在事实不一致和逻辑衰退的问题，现有方法（如RAG和代理工作记忆）无法根本性地解决因依赖静态知识源和单一推理路径而导致的问题。

Method: 提出D-SMART框架，包含动态结构化内存（DSM）和推理树（RT）。DSM增量式构建和维护对话的知识图谱（OWL兼容），RT则在图谱上执行多步推理搜索。引入NLI-based指标评估多轮对话一致性。

Result: 在MT-Bench-101基准测试上，D-SMART显著优于现有方法，将专有和开源模型的对话一致性分数提高了48%以上，并将后者的质量分数提高了10.1%。

Conclusion: D-SMART框架能够有效提升LLM在多轮对话中的事实和逻辑一致性，并且其引入的NLI-based指标比GPT-4评分更能准确地衡量对话一致性。

Abstract: Large Language Models (LLMs) often exhibit factual inconsistencies and
logical decay in extended, multi-turn dialogues, a challenge stemming from
their reliance on static, pre-trained knowledge and an inability to reason
adaptively over the dialogue history. Prevailing mitigation strategies, such as
Retrieval-Augmented Generation (RAG) and agentic working memories, improve
information recall but still engage with fundamentally static knowledge sources
and follow pre-defined single reasoning path. This hinders their ability to
preserve factual and logical consistency of their responses in multi-turn
dialogues while the context evolves over time. To address this issue, we
propose D-SMART, a model-agnostic framework designed to maintain multi-turn
dialogue consistency by enabling LLMs to build and reason over a dynamic,
structured representation of the conversational context. This is achieved via
two synergistic components: (1) a Dynamic Structured Memory (DSM), which
incrementally constructs and maintains an authoritative, OWL-compliant
knowledge graph of the conversation; and (2) a Reasoning Tree (RT), which
executes inferences as an explicit and traceable multi-step search over the
graph. As the popular-used quality score (judged by GPT-4) can overlook logical
flaws, we introduce new NLI-based metrics to better measure multi-turn dialogue
consistency. Comprehensive experiments on the MT-Bench-101 benchmark show that
D-SMART significantly outperforms state-of-the-art baselines, elevating the
dialogue consistency score by over 48\% for both proprietary and open-source
models, and notably improves the quality score of the latter by up to 10.1\%.

</details>


### [153] [Document Intelligence in the Era of Large Language Models: A Survey](https://arxiv.org/abs/2510.13366)
*Weishi Wang,Hengchang Hu,Zhijie Zhang,Zhaochen Li,Hongxin Shao,Daniel Dahlmeier*

Main category: cs.CL

TL;DR: LLMs已彻底改变文档智能（DAI）领域，从早期方法演变为基于解码器的LLM，在理解和生成方面取得了显著进步。本调查全面概述了DAI的演变，重点介绍了LLM在多模态、多语言和检索增强DAI方面的最新研究和未来前景，并提出了基于代理的方法和特定文档的基础模型等未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 文档智能（DAI）作为一个重要的应用领域，因大型语言模型（LLM）的出现而发生重大变革。早期的DAI方法依赖于编码器-解码器架构，而基于解码器的LLM彻底改变了DAI，在理解和生成方面带来了显著的进步。

Method: 本调查全面概述了DAI的演变，重点介绍了LLM在多模态、多语言和检索增强DAI方面的最新研究和未来前景。此外，还提出了基于代理的方法和特定文档的基础模型等未来研究方向。

Result: LLM在DAI领域带来了显著的理解和生成能力。多模态、多语言和检索增强DAI是关键的研究领域，带来了显著的进展。

Conclusion: 本论文旨在为DAI的最新进展及其对学术和实际应用的意义提供结构化分析，并为该领域未来的发展指明方向，包括基于代理的方法和特定文档的基础模型。

Abstract: Document AI (DAI) has emerged as a vital application area, and is
significantly transformed by the advent of large language models (LLMs). While
earlier approaches relied on encoder-decoder architectures, decoder-only LLMs
have revolutionized DAI, bringing remarkable advancements in understanding and
generation. This survey provides a comprehensive overview of DAI's evolution,
highlighting current research attempts and future prospects of LLMs in this
field. We explore key advancements and challenges in multimodal, multilingual,
and retrieval-augmented DAI, while also suggesting future research directions,
including agent-based approaches and document-specific foundation models. This
paper aims to provide a structured analysis of the state-of-the-art in DAI and
its implications for both academic and practical applications.

</details>


### [154] [Doing Things with Words: Rethinking Theory of Mind Simulation in Large Language Models](https://arxiv.org/abs/2510.13395)
*Agnese Lombardi,Alessandro Lenci*

Main category: cs.CL

TL;DR: Concordia模型在模拟人类心智理论（ToM）方面存在局限性，GPT-4在理解社会情境和进行因果推理方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索生成式多智能体模型（GABM）Concordia是否能有效模拟真实世界环境中的心智理论（ToM），并评估GPT-4是否能基于社会情境进行真实推断，而非依赖语言记忆。

Method: 使用GABM Concordia模型，评估GPT-4在模拟社会情境中的ToM能力，重点关注其是否基于信念归因进行行动选择以及生成因果效应的能力。

Result: GPT-4在行动选择时频繁失败，未能基于信念归因进行决策，并且在从智能体行为中生成连贯的因果效应方面存在困难。这表明之前研究中观察到的类似ToM的能力可能源于浅层统计关联而非真正推理。

Conclusion: 当前研究结果对有关大型语言模型（LLM）中涌现的类似ToM能力的主张提出了质疑，并强调了对更严格、基于行动的评估框架的需求。

Abstract: Language is fundamental to human cooperation, facilitating not only the
exchange of information but also the coordination of actions through shared
interpretations of situational contexts. This study explores whether the
Generative Agent-Based Model (GABM) Concordia can effectively model Theory of
Mind (ToM) within simulated real-world environments. Specifically, we assess
whether this framework successfully simulates ToM abilities and whether GPT-4
can perform tasks by making genuine inferences from social context, rather than
relying on linguistic memorization. Our findings reveal a critical limitation:
GPT-4 frequently fails to select actions based on belief attribution,
suggesting that apparent ToM-like abilities observed in previous studies may
stem from shallow statistical associations rather than true reasoning.
Additionally, the model struggles to generate coherent causal effects from
agent actions, exposing difficulties in processing complex social interactions.
These results challenge current statements about emergent ToM-like capabilities
in LLMs and highlight the need for more rigorous, action-based evaluation
frameworks.

</details>


### [155] [Investigating Lexical Change through Cross-Linguistic Colexification Patterns](https://arxiv.org/abs/2510.13407)
*Kim Gfeller,Sabine Stoll,Chundra Cathcart,Paul Widmer*

Main category: cs.CL

TL;DR: 词语的共现现象揭示了意义变化的规律，亲缘关系近、不常变异的词对更容易共现；反之，常用且易借用的词对则较少共现，且变异较快；不同语系的差异表明地域和文化因素的影响。


<details>
  <summary>Details</summary>
Motivation: 语言的意义演变机制仍未被完全理解，而词语共现现象为了解其动态变化提供了视角。

Method: 利用三个语系（南岛、印欧、乌拉尔）的词典数据，应用了系统发育比较模型来探究词语共现背后的演化动力学，并评估了关联性、可借用性和使用频率三个预测因子的影响。

Result: 亲缘关系近的词对共现的范围更广，变化速率更慢；而常用且易借用的词对变化更快，共现的频率更低。研究还发现了不同语系间的显著差异。

Conclusion: 词语共现的演化受到词对间亲缘关系、使用频率以及可借用性的影响，同时地域和文化因素也可能在其中扮演重要角色。

Abstract: One of the most intriguing features of language is its constant change, with
ongoing shifts in how meaning is expressed. Despite decades of research, the
factors that determine how and why meanings evolve remain only partly
understood. Colexification -- the phenomenon of expressing multiple distinct
concepts using the same word form -- serves as a valuable window onto the
dynamics of meaning change across languages. Here, we apply phylogenetic
comparative models to dictionary data from three language families,
Austronesian, Indo-European, and Uralic, in order to shed light on the
evolutionary dynamics underlying the colexification of concept pairs. We assess
the effects of three predictors: associativity, borrowability, and usage
frequency. Our results show that more closely related concept pairs are
colexified across a larger portion of the family tree and exhibit slower rates
of change. In contrast, concept pairs that are more frequent and more prone to
borrowing tend to change more rapidly and are less often colexified. We also
find considerable differences between the language families under study,
suggesting that areal and cultural factors may play a role.

</details>


### [156] [Evaluating Arabic Large Language Models: A Survey of Benchmarks, Methods, and Gaps](https://arxiv.org/abs/2510.13430)
*Ahmed Alzubaidi,Shaikha Alsuwaidi,Basma El Amel Boussaha,Leen AlQadi,Omar Alkaabi,Mohammed Alyafeai,Hamza Alobeidli,Hakim Hacid*

Main category: cs.CL

TL;DR: 本文首次系统性地回顾了阿拉伯语大型语言模型（LLM）的基准测试，分析了 40 多个跨自然语言处理（NLP）任务、知识领域、文化理解和专门能力等方面的评估基准。我们提出了一个将基准测试分为四类（知识、NLP任务、文化与方言、目标特定评估）的分类法。分析表明，基准测试的多样性取得了显著进展，但也发现了一些关键的不足之处：时间评估有限、多轮对话评估不足以及翻译数据集存在文化不匹配的问题。我们考察了三种主要方法（原生收集、翻译和合成生成）及其在真实性、规模和成本方面的权衡。这项工作为阿拉伯语 NLP 研究人员提供了一个全面的参考，深入探讨了基准测试方法、可复现性标准和评估指标，并为未来的发展提供了建议。


<details>
  <summary>Details</summary>
Motivation: 由于阿拉伯语大型语言模型（LLM）的评估基准存在碎片化且缺乏系统性回顾，因此需要对现有的阿拉伯语 LLM 基准测试进行全面的分析和组织，以指导未来的研究和开发。

Method: 对 40 多个阿拉伯语 LLM 评估基准进行了系统性审查，并根据知识、NLP任务、文化与方言、目标特定评估对其进行分类。同时，还分析了三种主要的基准创建方法（原生收集、翻译、合成生成）及其优缺点。

Result: 在基准测试的多样性方面取得了显著进展，但也存在时间评估不足、多轮对话评估有限以及翻译数据集存在文化不匹配等关键问题。原生收集、翻译和合成生成是三种主要的基准创建方法，各有其优缺点。

Conclusion: 现有的阿拉伯语 LLM 基准测试在多样性方面取得了进展，但在时间评估、多轮对话和文化方面仍存在不足。未来的研究应着重于解决这些差距，并遵循所提出的方法论和可复现性标准，以推动阿拉伯语 NLP 领域的发展。

Abstract: This survey provides the first systematic review of Arabic LLM benchmarks,
analyzing 40+ evaluation benchmarks across NLP tasks, knowledge domains,
cultural understanding, and specialized capabilities. We propose a taxonomy
organizing benchmarks into four categories: Knowledge, NLP Tasks, Culture and
Dialects, and Target-Specific evaluations. Our analysis reveals significant
progress in benchmark diversity while identifying critical gaps: limited
temporal evaluation, insufficient multi-turn dialogue assessment, and cultural
misalignment in translated datasets. We examine three primary approaches:
native collection, translation, and synthetic generation discussing their
trade-offs regarding authenticity, scale, and cost. This work serves as a
comprehensive reference for Arabic NLP researchers, providing insights into
benchmark methodologies, reproducibility standards, and evaluation metrics
while offering recommendations for future development.

</details>


### [157] [Beyond Single-Reward: Multi-Pair, Multi-Perspective Preference Optimization for Machine Translation](https://arxiv.org/abs/2510.13434)
*Hao Wang,Linlong Xu,Heng Liu,Yangyang Liu,Xiaohu Zhao,Bo Zeng,Liangying Shao,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: M^2PO通过整合多视角奖励引擎（包括幻觉惩罚和动态质量得分）和多对选择策略，解决了DPO在翻译中存在的奖励信号缺陷和数据利用效率低下问题，从而生成更鲁棒、更忠实的翻译。


<details>
  <summary>Details</summary>
Motivation: 当前的直接偏好优化（DPO）方法在机器翻译（MT）领域存在两个主要挑战：1. 质量评估（QE）模型的奖励信号存在缺陷，无法识别翻译幻觉等关键错误；2. 数据利用效率低下，仅选择一对胜负数据，丢弃了有价值的学习信号。M^2PO旨在解决这些问题。

Method: M^2PO框架整合了一个多视角奖励引擎，通过结合事实性幻觉惩罚和动态质量得分来创建更鲁棒的信号，该动态质量得分能够自适应地融合外部评估和模型自身判断。此外，还采用多对构建策略，从所有翻译候选集中系统地创建一组完整的偏好对，以确保模型从更丰富的质量权衡中学习。

Result: 在WMT21-22基准测试中，M^2PO在机器翻译任务上显著优于现有的偏好优化方法，并与领先的专有LLM相比，表现出高度竞争力。

Conclusion: M^2PO通过多视角奖励和多对选择策略的协同作用，能够从更丰富的质量权衡中学习，从而生成更鲁棒、更忠实的翻译，克服了现有DPO方法的局限性。

Abstract: Direct Preference Optimization (DPO) is a powerful paradigm for aligning
Large Language Models (LLMs) to human preferences in Machine Translation (MT),
but current methods are hindered by two fundamental challenges: (1) flawed
reward signals from Quality Estimation (QE) models that overlook critical
errors like translation hallucination, and (2) inefficient data utilization
that discards valuable learning signals by selecting only a single win-loss
pair. To address these limitations, we introduce M^2PO: Multi-Pair,
Multi-Perspective Preference Optimization. Our framework integrates a
multi-perspective reward engine that creates a more robust signal by combining
two key viewpoints: a new hallucination penalty for factuality, and an
innovative dynamic quality score that adaptively fuses external evaluations
with the model's own evolving judgment. This is synergistically paired with a
multi-pair construction strategy that systematically creates a comprehensive
set of preference pairs from the entire pool of translation candidates. This
synergistic approach ensures the model learns from a richer spectrum of quality
trade-offs, leading to more robust and faithful translations. On challenging
WMT21-22 benchmarks, M^2PO substantially outperforms existing preference
optimization methods and demonstrates highly competitive performance against
leading proprietary LLMs.

</details>


### [158] [LiteraryQA: Towards Effective Evaluation of Long-document Narrative QA](https://arxiv.org/abs/2510.13494)
*Tommaso Bonomo,Luca Gioffré,Roberto Navigli*

Main category: cs.CL

TL;DR: 该研究提出了LiteraryQA，一个高质量的、经过人类和LLM验证的，用于问答任务的数据集，该数据集是NarrativeQA的一个子集，专注于文学作品。


<details>
  <summary>Details</summary>
Motivation: 现有的的问题回答（QA）系统在处理长篇复杂文档时面临挑战，而NarrativeQA基准数据集中存在文档噪声和问答对错误的问题，影响了其可靠性。

Method: 通过一个结合人类和LLM验证的流程，识别并修正了低质量的问答样本，并清理了源文档中的无关文本。此外，还对自动评估指标进行了元评估，并在一系列长上下文LLM上进行了基准测试。

Result: 研究发现，所有基于n-gram的评估指标与人类判断的相关性较低，而使用LLM作为裁判（即使是小型开放权重模型）的评估方法，可以与人类的排名strongly agree。

Conclusion: LiteraryQA是一个高质量的数据集，可以用于评估QA系统在文学文本上的表现。LLM作为裁判的评估方法比传统的n-gram指标更可靠，能够更好地与人类判断一致。

Abstract: Question Answering (QA) on narrative text poses a unique challenge to current
systems, requiring a deep understanding of long, complex documents. However,
the reliability of NarrativeQA, the most widely used benchmark in this domain,
is hindered by noisy documents and flawed QA pairs. In this work, we introduce
LiteraryQA, a high-quality subset of NarrativeQA focused on literary works.
Using a human- and LLM-validated pipeline, we identify and correct low-quality
QA samples while removing extraneous text from source documents. We then carry
out a meta-evaluation of automatic metrics to clarify how systems should be
evaluated on LiteraryQA. This analysis reveals that all n-gram-based metrics
have a low system-level correlation to human judgment, while LLM-as-a-Judge
evaluations, even with small open-weight models, can strongly agree with the
ranking identified by humans. Finally, we benchmark a set of long-context LLMs
on LiteraryQA. We release our code and data at
https://github.com/SapienzaNLP/LiteraryQA.

</details>


### [159] [ConsintBench: Evaluating Language Models on Real-World Consumer Intent Understanding](https://arxiv.org/abs/2510.13499)
*Xiaozhe Li,TianYi Lyu,Siyi Yang,Yuxi Gong,Yizhao Yang,Jinxuan Huang,Ligao Zhang,Zhuoyi Huang,Qingwen Liu*

Main category: cs.CL

TL;DR: LLMs 难以理解真实世界中复杂、多变的公共意图，现有基准评估存在不足。本文提出了一个名为 \bench 的动态、实时、大规模的消费者领域意图理解评估基准，以解决此问题。


<details>
  <summary>Details</summary>
Motivation: 理解人类意图对大语言模型（LLMs）来说是一项复杂的高级任务，真实世界的公共讨论，如消费者产品讨论，涉及多方、多视角、不一致的信息和隐式假设。准确理解这种显式公共意图需要 LLMs 整合多源信号、推理不一致性并适应不断变化的语篇。然而，目前缺乏评估 LLMs 在真实世界人类意图理解能力的大规模基准。

Method: 构建了一个名为 \bench 的动态、实时评估基准，该基准专注于消费者领域，支持实时更新，并通过自动策管流程防止数据污染。

Result: \bench 是首个专为意图理解设计的动态、实时评估基准，并且是此类基准中规模最大、最多样化的，特别是在消费者领域。

Conclusion: 现有 LLM 评估方法在处理真实世界复杂公共意图理解方面存在不足。本文提出的 \bench 基准填补了这一空白，为评估 LLMs 在此任务上的能力提供了新的解决方案。

Abstract: Understanding human intent is a complex, high-level task for large language
models (LLMs), requiring analytical reasoning, contextual interpretation,
dynamic information aggregation, and decision-making under uncertainty.
Real-world public discussions, such as consumer product discussions, are rarely
linear or involve a single user. Instead, they are characterized by interwoven
and often conflicting perspectives, divergent concerns, goals, emotional
tendencies, as well as implicit assumptions and background knowledge about
usage scenarios. To accurately understand such explicit public intent, an LLM
must go beyond parsing individual sentences; it must integrate multi-source
signals, reason over inconsistencies, and adapt to evolving discourse, similar
to how experts in fields like politics, economics, or finance approach complex,
uncertain environments. Despite the importance of this capability, no
large-scale benchmark currently exists for evaluating LLMs on real-world human
intent understanding, primarily due to the challenges of collecting real-world
public discussion data and constructing a robust evaluation pipeline. To bridge
this gap, we introduce \bench, the first dynamic, live evaluation benchmark
specifically designed for intent understanding, particularly in the consumer
domain. \bench is the largest and most diverse benchmark of its kind,
supporting real-time updates while preventing data contamination through an
automated curation pipeline.

</details>


### [160] [MedREK: Retrieval-Based Editing for Medical LLMs with Key-Aware Prompts](https://arxiv.org/abs/2510.13500)
*Shujun Xia,Haokun Lin,Yichen Wu,Yinan Zhou,Zixuan Li,Zhongwei Wan,Xingrun Xing,Yefeng Zheng,Xiang Li,Caifeng Shan,Zhenan Sun,Quanzheng Li*

Main category: cs.CL

TL;DR: 该研究提出了MedREK框架，解决了医疗大语言模型（LLM）在信息更新和准确性方面的问题，通过检索式编辑实现了单样本和批量编辑的精确化。


<details>
  <summary>Details</summary>
Motivation: 医疗大语言模型（LLM）由于知识更新快和训练数据错误，常生成过时或不准确信息，限制了其在临床应用中的可靠性。参数编辑方法可能影响信息的局部性，不适合医疗领域，而检索式编辑虽有前景，但存在表示重叠导致检索不准和现有方法仅限于单样本编辑的问题。

Method: 研究构建了MedVersa基准，以评估单样本和批量编辑在严格局部性约束下的表现。提出了MedREK框架，该框架集成了共享查询-键模块以实现精确匹配，并采用基于注意力机制的提示编码器进行信息引导。

Result: 在多个医疗基准测试中，MedREK在各项核心指标上均表现出优越性能，并首次验证了医疗LLM的批量编辑解决方案。

Conclusion: MedREK通过改进检索机制和引入批量编辑能力，有效解决了医疗大语言模型的信息准确性和时效性问题，为医疗LLM在实际应用中提供了更可靠的支持。

Abstract: LLMs hold great promise for healthcare applications, but the rapid evolution
of medical knowledge and errors in training data often cause them to generate
outdated or inaccurate information, limiting their applicability in high-stakes
clinical practice. Model editing has emerged as a potential remedy without full
retraining. While parameter-based editing often compromises locality and is
thus ill-suited for the medical domain, retrieval-based editing offers a more
viable alternative. However, it still faces two critical challenges: (1)
representation overlap within the medical knowledge space often causes
inaccurate retrieval and reduces editing accuracy; (2) existing methods are
restricted to single-sample edits, while batch-editing remains largely
unexplored despite its importance for real-world medical applications. To
address these challenges, we first construct MedVersa, \hk{an enhanced
benchmark with broader coverage of medical subjects, designed to evaluate both
single and batch edits under strict locality constraints}. We then propose
MedREK, a retrieval-based editing framework that integrates a shared query-key
module for precise matching with an attention-based prompt encoder for
informative guidance. Experimental results on various medical benchmarks
demonstrate that our MedREK achieves superior performance across different core
metrics and provides the first validated solution for batch-editing in medical
LLMs. Our code and dataset are available at
https://github.com/mylittleriver/MedREK.

</details>


### [161] [Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization](https://arxiv.org/abs/2510.13554)
*Yang Li,Zhichen Dong,Yuhan Sun,Weixun Wang,Shaopan Xiong,Yijia Luo,Jiashun Liu,Han Lu,Jiamang Wang,Wenbo Su,Bo Zheng,Junchi Yan*

Main category: cs.CL

TL;DR: 本文将注意力机制作为理解大型语言模型（LLM）推理过程的关键，提出通过分析注意力模式来揭示其内部逻辑，并据此改进强化学习（RL）的优化策略。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLM）的推理过程不透明，强化学习（RL）通常对整个生成过程进行统一的信用分配，无法区分关键步骤和常规步骤。因此，需要一种方法来解析LLM的内部推理机制，并优化其学习过程。

Method: 本文提出将注意力机制视为揭示LLM推理过程的“蓝图”。通过区分局部和全局注意力的区别，并量化这两个指标（窗口平均注意力距离和未来注意力影响力），揭示了一种“预规划-锚定”的推理模式。在此基础上，提出三种新的RL策略，能够对关键的“预规划”和“锚定”标记进行有针对性的信用分配。

Result: 通过分析注意力模式，揭示了LLM推理中的“预规划-锚定”机制。新的RL策略在多种推理任务上实现了性能提升，表明将优化与模型的内在推理节奏对齐可以提高LLM的推理能力。

Conclusion: 注意力机制可以揭示LLM的内部推理逻辑，并且基于这些洞察的RL策略能够实现更有效的模型优化，为提高LLM推理的透明度和有效性提供了新的方向。

Abstract: The reasoning pattern of Large language models (LLMs) remains opaque, and
Reinforcement learning (RL) typically applies uniform credit across an entire
generation, blurring the distinction between pivotal and routine steps. This
work positions attention as a privileged substrate that renders the internal
logic of LLMs legible, not merely as a byproduct of computation, but as a
mechanistic blueprint of reasoning itself. We first distinguish attention heads
between locally and globally focused information processing and reveal that
locally focused heads produce a sawtooth pattern near the diagonal indicating
phrasal chunks, while globally focused heads expose tokens that exert broad
downstream influence over future tokens. We formalize these with two metrics:
1) Windowed Average Attention Distance, which measures the extent of backward
attention within a clipped window; 2) Future Attention Influence, which
quantifies a token's global importance as the average attention it receives
from subsequent tokens. Taken together, these signals reveal a recurring
preplan-and-anchor mechanism, where the model first performs a long-range
contextual reference to generate an introductory token, which is immediately
followed by or coincides with a semantic anchor token that organizes subsequent
reasoning. Leveraging these insights, we introduce three novel RL strategies
that dynamically perform targeted credit assignment to critical nodes (preplan
tokens, anchor tokens, and their temporal coupling) and show consistent
performance gains across various reasoning tasks. By aligning optimization with
the model's intrinsic reasoning rhythm, we aim to transform opaque optimization
into an actionable structure-aware process, hoping to offer a potential step
toward more transparent and effective optimization of LLM reasoning.

</details>


### [162] [Sparse Subnetwork Enhancement for Underrepresented Languages in Large Language Models](https://arxiv.org/abs/2510.13580)
*Daniil Gurgurov,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: LLM在低资源语言上的表现不佳，本文提出一种框架，通过微调特定语言的子网络来提升LLM在低资源语言上的表现，同时保持其通用能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在不同语言上的表现存在巨大差异，高资源语言和低资源语言之间存在显著的差距。

Method: 通过语言激活概率熵（Language Activation Probability Entropy）识别特定语言的神经元，并仅对与这些神经元相关的权重（一个专门的子网络）进行目标语言数据的微调。

Result: 在Llama-3.1-8B和Mistral-Nemo-12B模型上，针对12种中低资源语言的实验表明，该方法在保持高达99%参数不变的情况下，性能持续优于全量微调、仅FFN微调、LoRA适配和随机子集微调等基线方法。

Conclusion: 所提出的方法在提升LLM在低资源语言上的能力方面，相比于现有方法具有显著优势，并且在训练动力学、跨语言表征对齐和权重更新等方面也表现出积极的特性。此外，研究者发布了超过100种语言的特定语言神经元识别结果和适配流程，为将SOTA模型适配到代表性不足的语言提供了一条经济高效的途径。

Abstract: Large language models exhibit uneven performance across languages, with
substantial gaps between high- and low-resource languages. We present a
framework for enhancing monolingual capabilities of LLMs in underrepresented
languages while preserving their general-purpose performance through targeted
fine-tuning of language-specific subnetworks. Our approach identifies
language-specific neurons using Language Activation Probability Entropy and
fine-tunes only the weights associated with these neurons, a dedicated
subnetwork, on target-language data. Experiments on Llama-3.1-8B and
Mistral-Nemo-12B across 12 mid- and low-resource languages demonstrate that our
method consistently outperforms full fine-tuning, FFN-only fine-tuning, LoRA
adaptation, and random subset fine-tuning baselines while efficiently updating
only up to 1% of model parameters. Beyond performance improvements, we observe
enhanced favorable training dynamics, cross-lingual representational alignment,
and systematic weight update changes. To facilitate future research, we release
language-specific neuron identifications for over 100 languages as well as our
adaptation pipeline, offering a cost-effective pathway for adapting
state-of-the-art models to underrepresented languages.

</details>


### [163] [Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs](https://arxiv.org/abs/2510.13586)
*Pasin Buakhaw,Kun Kerdthaisong,Phuree Phenhiran,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: LLMs被用于生成游戏NPC的对话和任务。本研究提出了两种方法：API的轻量级提示（包括Deflanderization提示）和GPU的微调大模型（Qwen3-14B，SFT和LoRA）。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在生成动态NPC方面的潜力，并参与CPDC 2025挑战赛。

Method: 在API track中使用轻量级提示，包括Deflanderization提示；在GPU track中使用微调的大模型（Qwen3-14B，SFT和LoRA）。

Result: 在Task 1中排名第二，在Task 3（API track）中排名第二，在Task 3（GPU track）中排名第四。

Conclusion: 所提出的方法在CPDC 2025挑战赛中取得了良好的成绩，证明了LLMs在游戏NPC交互中的有效性。

Abstract: The emergence of large language models (LLMs) has opened new opportunities
for cre- ating dynamic non-player characters (NPCs) in gaming environments,
enabling both func- tional task execution and persona-consistent dialogue
generation. In this paper, we (Tu_Character_lab) report our participation in
the Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2, which
eval- uates agents across three tracks: task-oriented dialogue, context-aware
dialogue, and their integration. Our approach combines two complementary
strategies: (i) lightweight prompting techniques in the API track, including a
Deflanderization prompting method to suppress excessive role-play and improve
task fidelity, and (ii) fine-tuned large models in the GPU track, leveraging
Qwen3-14B with supervisedfinetuning (SFT) and Low-Rank Adaptation(LoRA). Our
best submissions ranked 2nd on Task 1, 2nd on Task 3 (API track), and 4th on
Task 3 (GPU track).

</details>


### [164] [FreshTab: Sourcing Fresh Data for Table-to-Text Generation Evaluation](https://arxiv.org/abs/2510.13598)
*Kristýna Onderková,Ondřej Plátek,Zdeněk Kasner,Ondřej Dušek*

Main category: cs.CL

TL;DR: FreshTab是一个新颖的表格到文本生成基准，通过从维基百科实时生成数据来解决LLM训练数据污染和领域不平衡问题，并支持多语言评估。


<details>
  <summary>Details</summary>
Motivation: 现有表格到文本生成基准存在LLM训练数据污染和领域不平衡问题，限制了评估的准确性。

Method: FreshTab通过从维基百科实时抓取表格数据来动态生成新的数据集，支持包括德语、俄语和法语在内的多种语言，从而解决数据污染问题并实现领域敏感的评估。

Result: LLM从FreshTab生成的最新表格中提取的见解在自动评估指标上表现较差，但在LLM和人类评估中并未体现出显著差异。所有评估均显示出明显的领域效应，表明领域平衡的基准更具挑战性。

Conclusion: LLM在处理最新表格数据时面临挑战，尽管自动指标未能完全捕捉到这一点。领域多样性是表格到文本生成中的一个重要因素，需要加以考虑。

Abstract: Table-to-text generation (insight generation from tables) is a challenging
task that requires precision in analyzing the data. In addition, the evaluation
of existing benchmarks is affected by contamination of Large Language Model
(LLM) training data as well as domain imbalance. We introduce FreshTab, an
on-the-fly table-to-text benchmark generation from Wikipedia, to combat the LLM
data contamination problem and enable domain-sensitive evaluation. While
non-English table-to-text datasets are limited, FreshTab collects datasets in
different languages on demand (we experiment with German, Russian and French in
addition to English). We find that insights generated by LLMs from recent
tables collected by our method appear clearly worse by automatic metrics, but
this does not translate into LLM and human evaluations. Domain effects are
visible in all evaluations, showing that a~domain-balanced benchmark is more
challenging.

</details>


### [165] [NOSA: Native and Offloadable Sparse Attention](https://arxiv.org/abs/2510.13602)
*Yuxiang Huang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 可训练稀疏注意力机制虽能提高LLM长上下文处理的效率，但未能解决KV缓存大小问题。本文提出的NOSA框架通过引入显式局部性约束，支持KV缓存卸载，减少了KV传输，并在不改变训练时注意力计算的情况下，实现了近乎无损的性能和高达2.3倍的解码吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有可训练稀疏注意力方法未能解决KV缓存大小问题，这限制了GPU批处理大小并降低了解码吞吐量，尤其是在大规模批处理推理中。

Method: NOSA通过将token选择分解为与查询相关和与查询无关的组件，引入显式局部性约束，以支持KV缓存卸载，减少KV传输，同时保持与训练时相同的注意力计算。

Result: 在1B参数模型上的预训练和广泛的基准测试表明，NOSA在保持近乎无损的性能的同时，与Vanilla可训练稀疏注意力基线（InfLLM-V2）相比，解码吞吐量提高了2.3倍。

Conclusion: NOSA是一个可训练的稀疏注意力框架，通过引入显式局部性约束来支持KV缓存卸载，有效解决了现有方法的局限性，并在效率和性能之间取得了良好的平衡。

Abstract: Trainable sparse attention has emerged as a promising solution to address the
decoding efficiency bottleneck of LLMs in long-context processing,
significantly saving memory accesses while minimally impacting task
performance. However, existing sparse attention methods leave a crucial
limitation unresolved: the size of the key-value (KV) cache remains unreduced,
which constrains on-GPU batch sizes and throttles decoding throughput,
especially in large-scale batched inference. In this paper, we show that
trainable sparse attention naturally exhibits strong locality in token
selection across adjacent decoding steps, thereby enabling KV cache offloading
without altering the underlying attention computation. However, the inherent
locality remains insufficient to achieve efficient offloading, as the transfer
of selected KV pairs between the CPU and GPU continues to dominate the overall
decoding cost. Building on this insight, we present NOSA, a trainable sparse
attention framework designed to natively support KV cache offloading. NOSA
introduces explicit locality constraints by decomposing token selection into
query-aware and query-agnostic components, thereby reducing KV transfers while
preserving the same attention computation as used during training. We pretrain
a 1B-parameter model with NOSA and conduct extensive benchmarks, showing that
it preserves near-lossless performance while achieving up to a 2.3x improvement
in decoding throughput compared with the vanilla trainable sparse attention
baseline (InfLLM-V2).

</details>


### [166] [MemoTime: Memory-Augmented Temporal Knowledge Graph Enhanced Large Language Model Reasoning](https://arxiv.org/abs/2510.13614)
*Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MemoTime 通过结构化 G grounding、递归推理和持续经验学习来增强 LLM 的时间推理能力，解决了现有 TKG 方法在多跳推理、多实体时间同步、算子适应和经验重用方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 TKG 的 LLM 推理方法在处理复杂时间推理问题时面临多方面挑战，包括时间忠实性、多实体同步、算子适应性和经验重用。

Method: MemoTime 提出了一种内存增强型时间知识图框架，通过结构化 grounding、递归推理和持续经验学习来增强 LLM 推理。该框架将复杂时间问题分解为“时间树”，实现算子感知推理，强制执行单调时间戳，并在统一时间范围内约束多个实体。此外，它还包含一个动态证据检索层和一个自我演进的经验记忆库。

Result: MemoTime 在多个时间 QA 基准测试上实现了最先进的性能，超越强基线最高可达 24.0%。同时，MemoTime 使得较小的模型（如 Qwen3-4B）能够达到与 GPT-4-Turbo 相媲美的推理性能。

Conclusion: MemoTime 成功地解决了现有 TKG 方法在 LLM 时间推理方面的局限性，并通过其创新的框架显著提高了推理的准确性和效率，甚至使小型模型也能获得强大的性能。

Abstract: Large Language Models (LLMs) have achieved impressive reasoning abilities,
but struggle with temporal understanding, especially when questions involve
multiple entities, compound operators, and evolving event sequences. Temporal
Knowledge Graphs (TKGs), which capture vast amounts of temporal facts in a
structured format, offer a reliable source for temporal reasoning. However,
existing TKG-based LLM reasoning methods still struggle with four major
challenges: maintaining temporal faithfulness in multi-hop reasoning, achieving
multi-entity temporal synchronization, adapting retrieval to diverse temporal
operators, and reusing prior reasoning experience for stability and efficiency.
To address these issues, we propose MemoTime, a memory-augmented temporal
knowledge graph framework that enhances LLM reasoning through structured
grounding, recursive reasoning, and continual experience learning. MemoTime
decomposes complex temporal questions into a hierarchical Tree of Time,
enabling operator-aware reasoning that enforces monotonic timestamps and
co-constrains multiple entities under unified temporal bounds. A dynamic
evidence retrieval layer adaptively selects operator-specific retrieval
strategies, while a self-evolving experience memory stores verified reasoning
traces, toolkit decisions, and sub-question embeddings for cross-type reuse.
Comprehensive experiments on multiple temporal QA benchmarks show that MemoTime
achieves overall state-of-the-art results, outperforming the strong baseline by
up to 24.0%. Furthermore, MemoTime enables smaller models (e.g., Qwen3-4B) to
achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [167] [Unlocking Public Catalogues: Instruction-Tuning LLMs for ICD Coding of German Tumor Diagnoses](https://arxiv.org/abs/2510.13624)
*Stefan Lenz,Lakisha Ortiz Rosario,Georg Vollmar,Arsenij Ustjanzew,Fatma Alickovic,Thomas Kindler,Torsten Panholzer*

Main category: cs.CL

TL;DR: 使用公开数据集对开源语言模型进行指令微调，可以提高其在德国肿瘤诊断编码任务上的准确性，尤其是在ICD-10-GM编码方面。


<details>
  <summary>Details</summary>
Motivation: 在德国，使用ICD-10-GM和ICD-O-3对肿瘤进行准确编码对于结构化癌症文档至关重要。然而，小型开源语言模型在处理德语肿瘤诊断文本时，在编码准确性方面常常遇到困难。

Method: 本研究通过在公开数据集上进行指令微调来评估开源语言模型（Qwen、Llama、Mistral系列，7-70B参数）在德国肿瘤诊断编码任务上的表现。使用了超过50万个基于ICD-10-GM、ICD-O-3和OPS目录生成的问答对作为训练数据，并使用本地肿瘤文档系统中的编码诊断数据进行评估。同时，评估了模型的代码输出格式是否正确以及肿瘤诊断识别能力。

Result: 微调后，ICD-10-GM的准确率从1.4-24%提升至41-58%，部分准确率从31-74%提升至73-83%。ICD-O-3的准确率也有所提高，但整体低于ICD-10-GM，精确率为22-40%，部分准确率为56-67%。所有模型的错误代码输出率降至0%，肿瘤诊断识别率达到99%。模型准确率与模型大小正相关，但微调后，小型和大型模型之间的差距缩小。Qwen3的推理模式性能较低且速度较慢。

Conclusion: 通过利用公开目录构建指令数据集，可以有效提升开源语言模型在医学文档任务（如德国肿瘤诊断编码）中的性能。

Abstract: Accurate coding of tumor diagnoses with ICD-10-GM and ICD-O-3 is essential
for structured cancer documentation in Germany. Smaller open-weight LLMs are
appealing for privacy-preserving automation but often struggle with coding
accuracy in German-language contexts. This study investigates whether
instruction-based fine-tuning on public datasets improves the coding accuracy
of open-weight LLMs for German tumor diagnosis texts. The evaluation uses coded
diagnoses from the local tumor documentation system as test data. In a
systematic data quality assessment, the upper limit for ICD-10 coding
performance was estimated at 60-79% for exact and 81-94% for partial
(three-character codes only) derivation. As training data, over 500,000
question-answer pairs were created based on the ICD-10-GM, ICD-O-3, and OPS
catalogues. Eight open-weight models from the Qwen, Llama, and Mistral families
(7-70 B parameters) were fine-tuned. ICD-10-GM accuracy rose from 1.4-24% to
41-58%, and partial accuracy from 31-74% to 73-83%. The accuracy of ICD-O-3
topography coding also improved but started and remained considerably lower
with an exact accuracy of 22-40% and a partial accuracy of 56-67% after
fine-tuning. Malformed code outputs dropped to 0% for all models.
Tumor-diagnosis recognition reached 99%. Accuracy correlated positively with
model size, but gaps between small and large models narrowed after fine-tuning.
The reasoning mode in Qwen3 generally yielded a lower performance than
fine-tuning and was over 100 times slower. Our findings highlight the potential
of leveraging public catalogues to build instruction datasets that improve LLMs
in medical documentation tasks. The complete training dataset and the
best-performing checkpoints of the fine-tuned models are available from
https://huggingface.co/datasets/stefan-m-lenz/ICDOPS-QA-2024.

</details>


### [168] [Closing the Gap Between Text and Speech Understanding in LLMs](https://arxiv.org/abs/2510.13632)
*Santiago Cuervo,Skyler Seto,Maureen de Seyssel,Richard He Bai,Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly,Zakaria Aldeneh*

Main category: cs.CL

TL;DR: 语音大语言模型在理解任务上表现不如文本模型，研究提出SALAD方法通过蒸馏和选择性合成数据来弥合这一差距。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在理解任务上表现不佳，且缩小差距的方法成本高昂或不可复现，需要更高效的数据利用方法。

Method: 提出SALAD（Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation）方法，结合跨模态蒸馏和目标性合成数据，以提高对齐并缓解遗忘。

Result: 在3B和7B大语言模型上，SALAD在知识、语言理解和推理等广泛基准测试中取得了与强大模型相当的性能，同时训练数据量仅为公开语料库中同类方法的十分之一。

Conclusion: SALAD是一种数据高效的方法，可以弥合文本-语音理解差距，在有限的语音数据下也能达到有竞争力的性能。

Abstract: Large Language Models (LLMs) can be adapted to extend their text capabilities
to speech inputs. However, these speech-adapted LLMs consistently underperform
their text-based counterparts--and even cascaded pipelines--on language
understanding tasks. We term this shortfall the text-speech understanding gap:
the performance drop observed when a speech-adapted LLM processes spoken inputs
relative to when the original text-based LLM processes the equivalent text.
Recent approaches to narrowing this gap either rely on large-scale speech
synthesis of text corpora, which is costly and heavily dependent on synthetic
data, or on large-scale proprietary speech datasets, which are not
reproducible. As a result, there remains a need for more data-efficient
alternatives for closing the text-speech understanding gap. In this work, we
analyze the gap as driven by two factors: (i) forgetting of text capabilities
during adaptation, and (ii) cross-modal misalignment between speech and text.
Based on this analysis, we introduce SALAD--Sample-efficient Alignment with
Learning through Active selection and cross-modal Distillation--which combines
cross-modal distillation with targeted synthetic data to improve alignment
while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves
competitive performance with a strong open-weight model across broad-domain
benchmarks in knowledge, language understanding, and reasoning, while training
on over an order of magnitude less speech data from public corpora.

</details>


### [169] [How Sampling Affects the Detectability of Machine-written texts: A Comprehensive Study](https://arxiv.org/abs/2510.13681)
*Matthieu Dubois,François Yvon,Pablo Piantanida*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As texts generated by Large Language Models (LLMs) are ever more common and
often indistinguishable from human-written content, research on automatic text
detection has attracted growing attention. Many recent detectors report
near-perfect accuracy, often boasting AUROC scores above 99\%. However, these
claims typically assume fixed generation settings, leaving open the question of
how robust such systems are to changes in decoding strategies. In this work, we
systematically examine how sampling-based decoding impacts detectability, with
a focus on how subtle variations in a model's (sub)word-level distribution
affect detection performance. We find that even minor adjustments to decoding
parameters - such as temperature, top-p, or nucleus sampling - can severely
impair detector accuracy, with AUROC dropping from near-perfect levels to 1\%
in some settings. Our findings expose critical blind spots in current detection
methods and emphasize the need for more comprehensive evaluation protocols. To
facilitate future research, we release a large-scale dataset encompassing 37
decoding configurations, along with our code and evaluation framework
https://github.com/BaggerOfWords/Sampling-and-Detection

</details>


### [170] [NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching](https://arxiv.org/abs/2510.13721)
*Run Luo,Xiaobo Xia,Lu Wang,Longze Chen,Renke Shan,Jing Luo,Min Yang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: NExT-OMNI是一个创新的全模态基础模型，通过离散流范式实现了统一建模，支持任意两种模态之间的理解和生成，解决了现有模型在多模态融合和生成方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有模型受限于自回归架构，难以平衡理解与生成能力，且混合或解耦策略应用场景有限，无法满足跨模态检索等更广泛需求。

Method: 提出NExT-OMNI模型，采用离散流范式，利用度量诱导概率路径和动力学最优速度，实现任意两种模态间的理解与生成，并提供高效的响应和统一的表示。

Result: NExT-OMNI在多模态生成和理解基准测试中表现具有竞争力，在多轮多模态交互和跨模态检索方面优于现有统一模型。

Conclusion: NExT-OMNI展示了其作为下一代多模态基础模型的架构优势，通过统一建模和广泛的适用性，为人工智能研究和应用开辟了新途径。

Abstract: Next-generation multimodal foundation models capable of any-to-any
cross-modal generation and multi-turn interaction will serve as core components
of artificial general intelligence systems, playing a pivotal role in
human-machine interaction. However, most existing multimodal models remain
constrained by autoregressive architectures, whose inherent limitations prevent
a balanced integration of understanding and generation capabilities. Although
hybrid and decoupling strategies have been explored to address these tasks
within unified frameworks separately, their redundant, non-integrated designs
limit their applicability to broader scenarios, such as cross-modal
retrieval.In this work, we introduce NExT-OMNI, an open-source omnimodal
foundation model that achieves unified modeling through discrete flow
paradigms. By leveraging metric-induced probability paths and kinetic optimal
velocities, NExT-OMNI natively supports any-to-any understanding and generation
with enhanced response efficiency, while enabling broader application scenarios
through concise unified representations rather than task-decoupled designs.
Trained on large-scale interleaved text, image, video, and audio data,
NExT-OMNI delivers competitive performance on multimodal generation and
understanding benchmarks, while outperforming prior unified models in
multi-turn multimodal interaction and cross-modal retrieval, highlighting its
architectural advantages as a next-generation multimodal foundation model. To
advance further research, we release training details, data protocols, and
open-source both the code and model checkpoints.

</details>


### [171] [GAPS: A Clinically Grounded, Automated Benchmark for Evaluating AI Clinicians](https://arxiv.org/abs/2510.13734)
*Xiuyuan Chen,Tao Sun,Dexin Su,Ailing Yu,Junwei Liu,Zhe Chen,Gangzeng Jin,Xin Wang,Jingnan Liu,Hansong Xiao,Hualei Zhou,Dongjie Tao,Chunxiao Guo,Minghui Yang,Yuan Xia,Jing Zhao,Qianrui Fan,Yanyun Wang,Shuai Zhen,Kezhong Chen,Jun Wang,Zewen Sun,Heng Zhao,Tian Guan,Shaodong Wang,Geyun Chang,Jiaming Deng,Hongchengcheng Chen,Kexin Feng,Ruzhen Li,Jiayi Geng,Changtai Zhao,Jun Wang,Guihu Lin,Peihao Li,Liqi Liu,Peng Wei,Jian Wang,Jinjie Gu,Ping Wang,Fan Yang*

Main category: cs.CL

TL;DR: 使用GAPS框架和自动化评估流水线，解决了当前AI临床医生系统基准测试的不足，提高了评估的深度、鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前AI临床医生系统的基准测试方法（如选择题或人工评分）无法充分体现真实临床实践所需的深度、鲁棒性和安全性。需要一种更全面、客观且可扩展的评估方法。

Method: 提出GAPS评估框架，包含认知深度（G）、答案充分性（A）、鲁棒性（P）和安全性（S）四个维度。开发了一个全自动化的、以指南为锚定的流水线，用于端到端地构建GAPS基准测试。该流水线包括证据邻域组装、双图谱和树表示、问题自动生成（跨G级别）、基于ReAct循环的DeepResearch代理生成评分标准（模仿GRADE和PICO）、以及使用LLM法官进行评分。

Result: 自动化生成的问题质量高，与临床医生的判断一致。评估结果显示，现有AI临床医生系统在以下方面存在显著问题：随着推理深度增加，性能急剧下降（G轴）；难以保证答案的充分性（A轴）；对对抗性扰动（P轴）和某些安全问题（S轴）非常脆弱。

Conclusion: 提出的全自动化、临床导向的方法为严格评估AI临床医生系统提供了一种可复现且可扩展的途径，有助于指导其朝着更安全、更可靠的临床实践方向发展。

Abstract: Current benchmarks for AI clinician systems, often based on multiple-choice
exams or manual rubrics, fail to capture the depth, robustness, and safety
required for real-world clinical practice. To address this, we introduce the
GAPS framework, a multidimensional paradigm for evaluating \textbf{G}rounding
(cognitive depth), \textbf{A}dequacy (answer completeness),
\textbf{P}erturbation (robustness), and \textbf{S}afety. Critically, we
developed a fully automated, guideline-anchored pipeline to construct a
GAPS-aligned benchmark end-to-end, overcoming the scalability and subjectivity
limitations of prior work. Our pipeline assembles an evidence neighborhood,
creates dual graph and tree representations, and automatically generates
questions across G-levels. Rubrics are synthesized by a DeepResearch agent that
mimics GRADE-consistent, PICO-driven evidence review in a ReAct loop. Scoring
is performed by an ensemble of large language model (LLM) judges. Validation
confirmed our automated questions are high-quality and align with clinician
judgment. Evaluating state-of-the-art models on the benchmark revealed key
failure modes: performance degrades sharply with increased reasoning depth
(G-axis), models struggle with answer completeness (A-axis), and they are
highly vulnerable to adversarial perturbations (P-axis) as well as certain
safety issues (S-axis). This automated, clinically-grounded approach provides a
reproducible and scalable method for rigorously evaluating AI clinician systems
and guiding their development toward safer, more reliable clinical practice.

</details>


### [172] [Assessing Web Search Credibility and Response Groundedness in Chat Assistants](https://arxiv.org/abs/2510.13749)
*Ivan Vykopal,Matúš Pikuliak,Simon Ostermann,Marián Šimko*

Main category: cs.CL

TL;DR: 聊天助手集成网络搜索功能，可能放大低可信度来源的错误信息。本研究提出了一种评估聊天助手网络搜索行为的新方法，重点关注来源可信度和响应与引用来源的一致性。通过在五个易产生错误信息的领域中的100个声明，评估了GPT-4o、GPT-5、Perplexity和Qwen Chat。结果显示，Perplexity在来源可信度方面表现最佳，而GPT-4o在敏感话题上引用不可信来源的比例较高。


<details>
  <summary>Details</summary>
Motivation: 随着聊天助手越来越多地集成网络搜索功能，它们可能放大低可信度来源的错误信息。因此，有必要评估聊天助手在网络搜索行为中的可信度和响应合理性。

Method: 本研究提出了一种评估聊天助手网络搜索行为的新方法，重点关注来源可信度和响应与引用来源的一致性。通过在五个易产生错误信息的领域中的100个声明，评估了GPT-4o、GPT-5、Perplexity和Qwen Chat。

Result: Perplexity在来源可信度方面表现最佳，而GPT-4o在敏感话题上引用不可信来源的比例较高。

Conclusion: 本研究首次对常用的聊天助手在事实核查行为方面进行了系统比较，为评估高风险信息环境中的AI系统奠定了基础。

Abstract: Chat assistants increasingly integrate web search functionality, enabling
them to retrieve and cite external sources. While this promises more reliable
answers, it also raises the risk of amplifying misinformation from
low-credibility sources. In this paper, we introduce a novel methodology for
evaluating assistants' web search behavior, focusing on source credibility and
the groundedness of responses with respect to cited sources. Using 100 claims
across five misinformation-prone topics, we assess GPT-4o, GPT-5, Perplexity,
and Qwen Chat. Our findings reveal differences between the assistants, with
Perplexity achieving the highest source credibility, whereas GPT-4o exhibits
elevated citation of non-credibility sources on sensitive topics. This work
provides the first systematic comparison of commonly used chat assistants for
fact-checking behavior, offering a foundation for evaluating AI systems in
high-stakes information environments.

</details>


### [173] [Confidence-Based Response Abstinence: Improving LLM Trustworthiness via Activation-Based Uncertainty Estimation](https://arxiv.org/abs/2510.13750)
*Zhiqi Huang,Vivek Datla,Chenyang Zhu,Alfy Samuel,Daben Liu,Anoop Kumar,Ritesh Soni*

Main category: cs.CL

TL;DR: 我们提出了一种用于检索增强生成（RAG）系统置信度估计的方法，该方法与大型语言模型（LLM）输出的正确性紧密对齐。这种置信度估计对于金融和医疗保健等高风险领域至关重要，因为错误答案的代价可能很高。我们的方法通过利用前馈网络（FFN）的原始激活作为自回归信号来扩展现有的不确定性量化方法，从而避免了在投影和softmax归一化后令牌logit和概率固有的信息丢失。我们将置信度预测建模为一个序列分类任务，并使用Huber损失项来正则化训练，以提高对嘈杂监督的鲁棒性。在具有复杂知识库的实际金融行业客户支持场景中，我们的方法优于强基线，并在严格的延迟限制下保持了高准确性。在Llama 3.1 8B模型上的实验表明，仅使用第16层的激活可以保持准确性，同时减少响应延迟。我们的结果表明，基于激活的置信度建模为可信赖的RAG部署提供了一条可扩展的、与架构无关的路径。


<details>
  <summary>Details</summary>
Motivation: 在金融和医疗保健等高风险领域，检索增强生成（RAG）系统输出的正确性至关重要，错误答案的代价可能很高。因此，需要一种准确的置信度估计方法来衡量大型语言模型（LLM）输出的可信度。

Method: 提出了一种利用前馈网络（FFN）原始激活作为自回归信号的置信度估计方法，该方法避免了令牌logit和概率在投影和softmax归一化后的信息丢失。将置信度预测建模为序列分类任务，并使用Huber损失项进行正则化训练，以提高对嘈杂监督的鲁棒性。

Result: 在实际金融行业客户支持场景中，该方法优于强基线，并在严格的延迟限制下保持了高准确性。在Llama 3.1 8B模型上的实验表明，仅使用第16层的激活即可保持准确性，同时减少响应延迟。

Conclusion: 基于激活的置信度建模为可信赖的RAG部署提供了一条可扩展的、与架构无关的路径。

Abstract: We propose a method for confidence estimation in retrieval-augmented
generation (RAG) systems that aligns closely with the correctness of large
language model (LLM) outputs. Confidence estimation is especially critical in
high-stakes domains such as finance and healthcare, where the cost of an
incorrect answer outweighs that of not answering the question. Our approach
extends prior uncertainty quantification methods by leveraging raw feed-forward
network (FFN) activations as auto-regressive signals, avoiding the information
loss inherent in token logits and probabilities after projection and softmax
normalization. We model confidence prediction as a sequence classification
task, and regularize training with a Huber loss term to improve robustness
against noisy supervision. Applied in a real-world financial industry
customer-support setting with complex knowledge bases, our method outperforms
strong baselines and maintains high accuracy under strict latency constraints.
Experiments on Llama 3.1 8B model show that using activations from only the
16th layer preserves accuracy while reducing response latency. Our results
demonstrate that activation-based confidence modeling offers a scalable,
architecture-aware path toward trustworthy RAG deployment.

</details>


### [174] [The Mechanistic Emergence of Symbol Grounding in Language Models](https://arxiv.org/abs/2510.13796)
*Shuyu Wu,Ziqiao Ma,Xiaoxi Luo,Yidong Huang,Josue Torres-Fonseca,Freda Shi,Joyce Chai*

Main category: cs.CL

TL;DR: 符号主义可以从大型视觉语言模型中出现，并集中在中间层计算中，通过聚合环境以支持语言形式的预测。


<details>
  <summary>Details</summary>
Motivation: 探索符号主义在（视觉）语言模型中出现的机制和具体位置。

Method: 引入一个受控的评估框架，通过机制和因果分析系统地追踪符号主义在其内部计算中的产生过程。

Result: 符号主义集中在中间层计算中，通过注意力头聚合环境信息来支持语言形式的预测。这种现象在Transformer和状态空间模型的多模态对话中普遍存在，但不在单向LSTM中。

Conclusion: 符号主义可以从语言模型中涌现，这为预测和控制生成内容的可靠性提供了实际意义。

Abstract: Symbol grounding (Harnad, 1990) describes how symbols such as words acquire
their meanings by connecting to real-world sensorimotor experiences. Recent
work has shown preliminary evidence that grounding may emerge in
(vision-)language models trained at scale without using explicit grounding
objectives. Yet, the specific loci of this emergence and the mechanisms that
drive it remain largely unexplored. To address this problem, we introduce a
controlled evaluation framework that systematically traces how symbol grounding
arises within the internal computations through mechanistic and causal
analysis. Our findings show that grounding concentrates in middle-layer
computations and is implemented through the aggregate mechanism, where
attention heads aggregate the environmental ground to support the prediction of
linguistic forms. This phenomenon replicates in multimodal dialogue and across
architectures (Transformers and state-space models), but not in unidirectional
LSTMs. Our results provide behavioral and mechanistic evidence that symbol
grounding can emerge in language models, with practical implications for
predicting and potentially controlling the reliability of generation.

</details>


### [175] [Breadcrumbs Reasoning: Memory-Efficient Reasoning with Compression Beacons](https://arxiv.org/abs/2510.13797)
*Giovanni Monea,Yair Feldman,Shankar Padmanabhan,Kianté Brantley,Yoav Artzi*

Main category: cs.CL

TL;DR: 通过引入一种新的KV缓存压缩方法，并在长上下文推理任务上实现了更好的内存-准确性权衡。


<details>
  <summary>Details</summary>
Motivation: Transformer长文本推理的KV缓存存在内存和计算成本随长度线性增长的问题，限制了可扩展性。

Method: 提出一种压缩KV缓存的方法，通过引入特殊学习到的token来周期性地压缩并移除KV缓存中的旧信息，并采用改进的联合蒸馏和强化学习（RL）框架进行训练。

Result: 实验证明，该方法相比于不压缩KV缓存的模型和无需训练的压缩技术，在内存-准确性权衡方面表现更优。

Conclusion: 提出的KV缓存压缩方法能够有效缓解长文本推理的内存和计算限制，并在保持模型准确性的同时显著提高效率。

Abstract: The scalability of large language models for long-context reasoning is
severely constrained by the linear growth of their Transformer key-value cache,
which incurs significant memory and computational costs. We posit that as a
model generates reasoning tokens, the informational value of past generated
tokens diminishes, creating an opportunity for compression. In this work, we
propose to periodically compress the generation KV cache with a learned,
special-purpose token and evict compressed entries. We train the model to
perform this compression via a modified joint distillation and reinforcement
learning (RL) framework. Our training method minimizes overhead over the
conventional RL process, as it leverages RL outputs for distillation.
Empirically, our method achieves a superior memory-accuracy Pareto frontier
compared to both the model without cache compression and training-free
compression techniques.

</details>


### [176] [BRIEF-Pro: Universal Context Compression with Short-to-Long Synthesis for Fast and Accurate Multi-Hop Reasoning](https://arxiv.org/abs/2510.13799)
*Jia-Chen Gu,Junyi Zhang,Di Wu,Yuankai Li,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: BRIEF-Pro 是一种轻量级压缩器，可为检索增强生成（RAG）任务中的复杂问题提炼相关证据，从而减少延迟并提高模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理复杂任务时，会因为上下文过长而导致延迟增加和模型认知负荷加重。

Method: BRIEF-Pro 通过对检索到的文档进行抽象式压缩，将长上下文（超过 10k 词）提炼成简洁的摘要，以便集成到 RAG 中。它使用少量的种子数据进行训练，并允许用户自定义摘要的长度（句子数量）。

Result: 在四个开放域多跳问答数据集上的实验表明，BRIEF-Pro 能够生成更简洁、更相关的摘要，并提升了不同规模语言模型的性能。具体而言，使用 70B 阅读器模型时，BRIEF-Pro 实现了 32 倍压缩，比 LongLLMLingua 的 9 倍压缩平均提高了 4.67% 的问答性能，同时计算开销仅为其 23%。

Conclusion: BRIEF-Pro 是一种通用、轻量级的压缩器，能够有效解决 RAG 中上下文过长带来的瓶颈问题，尤其适用于复杂的多跳问题，并显著提升了问答性能和效率。

Abstract: As retrieval-augmented generation (RAG) tackles complex tasks, increasingly
expanded contexts offer richer information, but at the cost of higher latency
and increased cognitive load on the model. To mitigate this bottleneck,
especially for intricate multi-hop questions, we introduce BRIEF-Pro. It is a
universal, lightweight compressor that distills relevant evidence for a given
query from retrieved documents into a concise summary for seamless integration
into in-context RAG. Using seed data consisting of relatively short contexts
(fewer than 1k words), BRIEF-Pro is trained to perform abstractive compression
of extended contexts exceeding 10k words across a wide range of scenarios.
Furthermore, BRIEF-Pro offers flexible user control over summary length by
allowing users to specify the desired number of sentences. Experiments on four
open-domain multi-hop question-answering datasets show that BRIEF-Pro generates
more concise and relevant summaries, enhancing performance across small, large,
and proprietary language models. With the 70B reader model, 32x compression by
BRIEF-Pro improves QA performance by 4.67% on average over LongLLMLingua's 9x,
while requiring only 23% of its computational overhead.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [177] [Learning to Grasp Anything by Playing with Random Toys](https://arxiv.org/abs/2510.12866)
*Dantong Niu,Yuvan Sharma,Baifeng Shi,Rachel Ding,Matteo Gioia,Haoru Xue,Henry Tsai,Konstantinos Kallidromitis,Anirudh Pai,Shankar Shastry,Trevor Darrell,Jitendra Malik,Roei Herzig*

Main category: cs.RO

TL;DR: 通过在由四种形状原语（球体、立方体、圆柱体和环体）组成的“玩具”上进行训练，机器人可以学会可泛化的抓取，并能成功地推广到现实世界中的物体。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人抓取策略在泛化到新物体时存在困难，限制了其在现实世界中的应用。受到儿童通过玩简单玩具学习并将其知识应用于更复杂物体的启发，本研究旨在探索机器人是否也能通过类似的方法实现泛化抓取能力。

Method: 研究者提出了一种方法，让机器人通过抓取由四种形状原语（球体、立方体、圆柱体和环体）组成的随机组合的“玩具”来学习抓取。通过这种方式训练的机器人，能够将其学到的知识泛化到现实世界中的物体上。他们发现，关键在于一种由所提出的检测池化机制诱导的、以物体为中心的视觉表示。

Result: 在模拟和物理机器人上进行评估，该模型在YCB数据集上实现了67%的真实世界抓取成功率，优于那些依赖更多领域内数据的最先进方法。研究者还通过改变训练玩具的数量和多样性以及每个玩具的演示次数，研究了零样本泛化性能如何随之扩展。

Conclusion: 本研究表明，通过在由基本形状原语组成的“玩具”上进行训练，机器人可以学会可泛化的抓取策略，并能成功地应用于现实世界中的物体。这种方法的关键在于利用物体为中心的视觉表示。该研究为在机器人操作中实现可扩展和可泛化的学习提供了一条有前景的途径。

Abstract: Robotic manipulation policies often struggle to generalize to novel objects,
limiting their real-world utility. In contrast, cognitive science suggests that
children develop generalizable dexterous manipulation skills by mastering a
small set of simple toys and then applying that knowledge to more complex
items. Inspired by this, we study if similar generalization capabilities can
also be achieved by robots. Our results indicate robots can learn generalizable
grasping using randomly assembled objects that are composed from just four
shape primitives: spheres, cuboids, cylinders, and rings. We show that training
on these "toys" enables robust generalization to real-world objects, yielding
strong zero-shot performance. Crucially, we find the key to this generalization
is an object-centric visual representation induced by our proposed detection
pooling mechanism. Evaluated in both simulation and on physical robots, our
model achieves a 67% real-world grasping success rate on the YCB dataset,
outperforming state-of-the-art approaches that rely on substantially more
in-domain data. We further study how zero-shot generalization performance
scales by varying the number and diversity of training toys and the
demonstrations per toy. We believe this work offers a promising path to
scalable and generalizable learning in robotic manipulation. Demonstration
videos, code, checkpoints and our dataset are available on our project page:
https://lego-grasp.github.io/ .

</details>


### [178] [Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation](https://arxiv.org/abs/2510.12919)
*Mouhyemen Khan,Tatsuya Ibuki,Abhijit Chatterjee*

Main category: cs.RO

TL;DR: This paper unifies level set methods and control barrier functions (CBFs) by using an implicit surface represented by Gaussian processes (GPs) as a CBF. A sparse version of this method, sparse Gaussian CBFs, is proposed to handle scalability issues. The approach is validated on collision avoidance tasks with a robotic manipulator and a quadrotor.


<details>
  <summary>Details</summary>
Motivation: Inspired by level set methods used in safety techniques like CBFs and implicit surface representations, this paper proposes a unified framework where the implicit surface itself acts as a CBF.

Method: The paper uses Gaussian process implicit surface (GPIS) to represent safety boundaries, conditioning the GP on safety samples derived from sensor measurements. The GP posterior mean defines the safety surface, and the posterior variance provides a safety margin. A sparse solution, sparse Gaussian CBFs, is developed to address the cubic scaling of GPs with data.

Result: The proposed Gaussian CBFs (with and without sparsity) were validated on collision avoidance tasks involving a simulated 7-DOF manipulator and a quadrotor navigating in 3D. Both scenarios demonstrated that the methods enable safe interaction and collision-free trajectory execution.

Conclusion: The paper successfully demonstrates a novel framework using Gaussian process implicit surfaces as control barrier functions, offering a robust safety margin and enabling safe navigation in complex environments. The proposed sparse Gaussian CBFs effectively address scalability concerns.

Abstract: Level set methods underpin modern safety techniques such as control barrier
functions (CBFs), while also serving as implicit surface representations for
geometric shapes via distance fields. Inspired by these two paradigms, we
propose a unified framework where the implicit surface itself acts as a CBF. We
leverage Gaussian process (GP) implicit surface (GPIS) to represent the safety
boundaries, using safety samples which are derived from sensor measurements to
condition the GP. The GP posterior mean defines the implicit safety surface
(safety belief), while the posterior variance provides a robust safety margin.
Although GPs have favorable properties such as uncertainty estimation and
analytical tractability, they scale cubically with data. To alleviate this
issue, we develop a sparse solution called sparse Gaussian CBFs. To the best of
our knowledge, GPIS have not been explicitly used to synthesize CBFs. We
validate the approach on collision avoidance tasks in two settings: a simulated
7-DOF manipulator operating around the Stanford bunny, and a quadrotor
navigating in 3D around a physical chair. In both cases, Gaussian CBFs (with
and without sparsity) enable safe interaction and collision-free execution of
trajectories that would otherwise intersect the objects.

</details>


### [179] [Geometric Model Predictive Path Integral for Agile UAV Control with Online Collision Avoidance](https://arxiv.org/abs/2510.12924)
*Pavel Pochobradský,Ondřej Procházka,Robert Pěnička,Vojtěch Vonásek,Martin Saska*

Main category: cs.RO

TL;DR: GMPPI是一个采样控制器，可以跟踪敏捷轨迹并避开障碍物，通过结合几何SE(3)控制、可变时间步长和动态成本/噪声参数来提高跟踪性能，并与立体深度相机集成以实现高速避障。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够跟踪敏捷轨迹并避开障碍物的采样控制器，以实现自主无人机在高复杂环境中的飞行。

Method: GMPPI在每次迭代中生成大量候选轨迹，并对它们进行平均以获得控制指令。它利用几何SE(3)控制生成部分轨迹，并引入可变模拟时间步长和动态成本/噪声参数。此外，它还集成了立体深度相机以实现在线避障。

Result: GMPPI在模拟中能够以与几何SE(3)控制器相当的位置误差跟踪敏捷轨迹，并在模拟森林环境中以高达13米/秒的速度避开障碍物，优于最先进的障碍感知规划器。在实际实验中，GMPPI能够以高达10米/秒的速度跟踪敏捷轨迹并避开障碍物。

Conclusion: GMPPI控制器在跟踪敏捷轨迹和避开障碍物方面表现出色，特别是在复杂环境中，为实现自主无人机飞行奠定了重要基础。

Abstract: In this letter, we introduce Geometric Model Predictive Path Integral
(GMPPI), a sampling-based controller capable of tracking agile trajectories
while avoiding obstacles. In each iteration, GMPPI generates a large number of
candidate rollout trajectories and then averages them to create a nominal
control to be followed by the Unmanned Aerial Vehicle (UAV). We propose using
geometric SE(3) control to generate part of the rollout trajectories,
significantly increasing precision in agile flight. Furthermore, we introduce
varying rollout simulation time step length and dynamic cost and noise
parameters, vastly improving tracking performance of smooth and low-speed
trajectories over an existing Model Predictive Path Integral (MPPI)
implementation. Finally, we propose an integration of GMPPI with a stereo depth
camera, enabling online obstacle avoidance at high speeds, a crucial step
towards autonomous UAV flights in complex environments. The proposed controller
can track simulated agile reference trajectories with position error similar to
the geometric SE(3) controller. However, the same configuration of the proposed
controller can avoid obstacles in a simulated forest environment at speeds of
up to 13m/s, surpassing the performance of a state-of-the-art obstacle-aware
planner. In real-world experiments, GMPPI retains the capability to track agile
trajectories and avoids obstacles at speeds of up to 10m/s.

</details>


### [180] [Enhancing Sampling-based Planning with a Library of Paths](https://arxiv.org/abs/2510.12962)
*Michal Minařík,Vojtěch Vonásek,Robert Pěnička*

Main category: cs.RO

TL;DR: 通过复用先前路径规划的经验来加速3D实体物体的路径规划，特别是在狭窄通道场景下，并取得了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 传统的基于采样的规划器在处理狭窄通道时效率低下，并且每次规划都需要从头开始，无法利用先前经验。

Method: 提出了一种利用存储的历史路径库的方法。通过寻找与新规划对象最相似的先前规划对象，并复用其路径作为初始近似解，然后调整并沿着近似路径进行采样，以加速规划过程。

Result: 在各种狭窄通道场景下，与OMPL库中的先进方法相比，该方法实现了高达85%的时间节省，并且在传统方法失败的情况下，该方法常常能找到解决方案。

Conclusion: 该方法通过复用历史路径显著提高了3D实体物体路径规划的效率，尤其在狭窄通道场景下表现出色，并已开源。

Abstract: Path planning for 3D solid objects is a challenging problem, requiring a
search in a six-dimensional configuration space, which is, nevertheless,
essential in many robotic applications such as bin-picking and assembly. The
commonly used sampling-based planners, such as Rapidly-exploring Random Trees,
struggle with narrow passages where the sampling probability is low, increasing
the time needed to find a solution. In scenarios like robotic bin-picking,
various objects must be transported through the same environment. However,
traditional planners start from scratch each time, losing valuable information
gained during the planning process. We address this by using a library of past
solutions, allowing the reuse of previous experiences even when planning for a
new, previously unseen object. Paths for a set of objects are stored, and when
planning for a new object, we find the most similar one in the library and use
its paths as approximate solutions, adjusting for possible mutual
transformations. The configuration space is then sampled along the approximate
paths. Our method is tested in various narrow passage scenarios and compared
with state-of-the-art methods from the OMPL library. Results show significant
speed improvements (up to 85% decrease in the required time) of our method,
often finding a solution in cases where the other planners fail. Our
implementation of the proposed method is released as an open-source package.

</details>


### [181] [Kinematic Kitbashing for Modeling Functional Articulated Objects](https://arxiv.org/abs/2510.13048)
*Minghao Guo,Victor Zordan,Sheldon Andrews,Wojciech Matusik,Maneesh Agrawala,Hsueh-Ti Derek Liu*

Main category: cs.RO

TL;DR: Kinematic Kitbashing 是一个自动化框架，通过重用现有模型的部件来合成功能感知的关节对象。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是自动合成功能感知的关节对象，通过组合和重用现有模型中的部件。

Method: 该框架通过优化部件的空间布局来解决这个问题，同时考虑几何约束和用户指定的功能目标。它使用一种感知附件的能量函数，并将一个退火黎曼朗之万采样器与功能目标相结合，以实现鲁棒的全局探索和对非差异化目标的处理。

Result: 该框架能够生成各种各样的关节对象，包括将垃圾桶轮子安装到汽车车身上，以及多段式灯具、齿轮驱动的划桨装置和可重构家具。在几何、运动学和功能指标方面，它都取得了显著的定量改进。

Conclusion: Kinematic Kitbashing 通过将感知关节的几何匹配与驱动功能进行优化相结合，弥合了基于部件的形状建模和功能组装设计之间的差距，从而能够快速创建交互式关节资产。

Abstract: We introduce Kinematic Kitbashing, an automatic framework that synthesizes
functionality-aware articulated objects by reusing parts from existing models.
Given a kinematic graph with a small collection of articulated parts, our
optimizer jointly solves for the spatial placement of every part so that (i)
attachments remain geometrically sound over the entire range of motion and (ii)
the assembled object satisfies user-specified functional goals such as
collision-free actuation, reachability, or trajectory following. At its core is
a kinematics-aware attachment energy that aligns vector distance function
features sampled across multiple articulation snapshots. We embed this
attachment term within an annealed Riemannian Langevin dynamics sampler that
treats functionality objectives as additional energies, enabling robust global
exploration while accommodating non-differentiable functionality objectives and
constraints. Our framework produces a wide spectrum of assembled articulated
shapes, from trash-can wheels grafted onto car bodies to multi-segment lamps,
gear-driven paddlers, and reconfigurable furniture, and delivers strong
quantitative improvements over state-of-the-art baselines across geometric,
kinematic, and functional metrics. By tightly coupling articulation-aware
geometry matching with functionality-driven optimization, Kinematic Kitbashing
bridges part-based shape modeling and functional assembly design, empowering
rapid creation of interactive articulated assets.

</details>


### [182] [The Omega Turn: A General Turning Template for Elongate Robots](https://arxiv.org/abs/2510.12970)
*Baxi Chong,Tianyu Wang,Kelimar Diaz,Christopher J. Pierce,Eva Erickson,Julian Whitman,Yuelin Deng,Esteban Flores,Ruijie Fu,Juntao He,Jianfeng Lin,Hang Lu,Guillaume Sartoretti,Howie Choset,Daniel I. Goldman*

Main category: cs.RO

TL;DR: Elongate limbless robots can navigate cluttered environments, inspired by C. elegans' omega turns. This paper develops a wave-equation-based controller for effective and robust turning, applicable to both limbless and multi-legged robots.


<details>
  <summary>Details</summary>
Motivation: Effective and robust turning strategies for elongate limbless robots are crucial for applications like search-and-rescue and industrial inspections, but research in this area is limited. This work aims to address this gap by developing a novel turning strategy.

Method: The paper prescribes the omega turn as a superposition of two traveling waves, guided by wave equations. A controller is designed for limbless robots based on these equations, and its effectiveness is demonstrated in both lab and cluttered field environments. The study also explores the generalization of this controller to multi-legged robots.

Result: The study successfully designs and demonstrates a controller for elongate limbless robots that enables robust and effective turning behaviors in various environments. The controller, inspired by C. elegans' omega turns and based on wave equations, is shown to be generalizable to multi-legged robots.

Conclusion: The developed omega turn controller, inspired by C. elegans and based on wave equations, provides an effective and robust body-driven turning strategy for elongate robots, with or without limbs, opening new possibilities for navigation in complex environments.

Abstract: Elongate limbless robots have the potential to locomote through tightly
packed spaces for applications such as search-and-rescue and industrial
inspections. The capability to effectively and robustly maneuver elongate
limbless robots is crucial to realize such potential. However, there has been
limited research on turning strategies for such systems. To achieve effective
and robust turning performance in cluttered spaces, we take inspiration from a
microscopic nematode, C. elegans, which exhibits remarkable maneuverability in
rheologically complex environments partially because of its ability to perform
omega turns. Despite recent efforts to analyze omega turn kinematics, it
remains unknown if there exists a wave equation sufficient to prescribe an
omega turn, let alone its reconstruction on robot platforms. Here, using a
comparative theory-biology approach, we prescribe the omega turn as a
superposition of two traveling waves. With wave equations as a guideline, we
design a controller for limbless robots enabling robust and effective turning
behaviors in lab and cluttered field environments. Finally, we show that such
omega turn controllers can also generalize to elongate multi-legged robots,
demonstrating an alternative effective body-driven turning strategy for
elongate robots, with and without limbs.

</details>


### [183] [Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation](https://arxiv.org/abs/2510.12971)
*Anran Zhang,Hanzhi Chen,Yannick Burkhardt,Yao Zhong,Johannes Betz,Helen Oleynikova,Stefan Leutenegger*

Main category: cs.RO

TL;DR: Actron3D是一个能让机器人从少量单目、未校准的RGB视频中学习可迁移的6-DoF操作技能的框架，其核心是神经亲和函数。


<details>
  <summary>Details</summary>
Motivation: 需要让机器人从少量人类视频中学习可迁移的6-DoF操作技能。

Method: 提出Actron3D框架，核心是神经亲和函数，它从视频中提取几何、视觉外观和亲和力等信息，形成操作技能的记忆库。部署时，通过检索相关的亲和函数并进行由粗到精的优化来迁移操作策略。

Result: Actron3D在模拟和真实世界中都显著优于现有方法，在13项任务上的平均成功率提高了14.9个百分点，且每项任务仅需2-3个演示视频。

Conclusion: Actron3D能够从少量单目、未校准的RGB视频中学习可迁移的6-DoF操作技能，并且在各种任务中表现出色。

Abstract: We present Actron3D, a framework that enables robots to acquire transferable
6-DoF manipulation skills from just a few monocular, uncalibrated, RGB-only
human videos. At its core lies the Neural Affordance Function, a compact
object-centric representation that distills actionable cues from diverse
uncalibrated videos-geometry, visual appearance, and affordance-into a
lightweight neural network, forming a memory bank of manipulation skills.
During deployment, we adopt a pipeline that retrieves relevant affordance
functions and transfers precise 6-DoF manipulation policies via coarse-to-fine
optimization, enabled by continuous queries to the multimodal features encoded
in the neural functions. Experiments in both simulation and the real world
demonstrate that Actron3D significantly outperforms prior methods, achieving a
14.9 percentage point improvement in average success rate across 13 tasks while
requiring only 2-3 demonstration videos per task.

</details>


### [184] [UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles](https://arxiv.org/abs/2510.12992)
*Neel P. Bhatt,Po-han Li,Kushagra Gupta,Rohan Siva,Daniel Milan,Alexander T. Hogue,Sandeep P. Chinchali,David Fridovich-Keil,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: UNCAP通过轻量级自然语言消息实现多车协同规划，量化感知不确定性，在减少通信带宽的同时提高安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么传输高带宽原始传感器数据，要么忽略共享数据中固有的感知和规划不确定性，导致系统不可扩展且不安全。

Method: 提出一种基于视觉-语言模型的规划方法UNCAP，采用两阶段通信协议：1. 自车识别最相关的车辆进行信息交换；2. 选定的车辆传输量化感知不确定性的消息，通过最大化互信息融合相关信号。

Result: 在各种驾驶场景下，通信带宽减少63%，驾驶安全得分提高31%，决策不确定性减少61%，碰撞距离裕度增加四倍。

Conclusion: UNCAP通过轻量级自然语言消息和量化感知不确定性，提高了多车协同规划的可扩展性和可靠性。

Abstract: Safe large-scale coordination of multiple cooperative connected autonomous
vehicles (CAVs) hinges on communication that is both efficient and
interpretable. Existing approaches either rely on transmitting high-bandwidth
raw sensor data streams or neglect perception and planning uncertainties
inherent in shared data, resulting in systems that are neither scalable nor
safe. To address these limitations, we propose Uncertainty-Guided Natural
Language Cooperative Autonomous Planning (UNCAP), a vision-language model-based
planning approach that enables CAVs to communicate via lightweight natural
language messages while explicitly accounting for perception uncertainty in
decision-making. UNCAP features a two-stage communication protocol: (i) an ego
CAV first identifies the subset of vehicles most relevant for information
exchange, and (ii) the selected CAVs then transmit messages that quantitatively
express their perception uncertainty. By selectively fusing messages that
maximize mutual information, this strategy allows the ego vehicle to integrate
only the most relevant signals into its decision-making, improving both the
scalability and reliability of cooperative planning. Experiments across diverse
driving scenarios show a 63% reduction in communication bandwidth with a 31%
increase in driving safety score, a 61% reduction in decision uncertainty, and
a four-fold increase in collision distance margin during near-miss events.
Project website: https://uncap-project.github.io/

</details>


### [185] [Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations](https://arxiv.org/abs/2510.13005)
*Robert Muldrow,Channing Ludden,Christopher Petersen*

Main category: cs.RO

TL;DR: 本文设计并开发了一个用于模拟太空机器人操作的硬件在环（HIL）实验平台，该平台使用连接到卫星总线的6自由度UR3e机器人手臂，以解决在轨服务、组装和制造（ISAM）中的控制挑战。


<details>
  <summary>Details</summary>
Motivation: 在轨服务、组装和制造（ISAM）操作对提升空间资产的寿命、容量、机动性和可扩展性至关重要。然而，在自由飞行的卫星上移动机器人手臂所产生的复杂扰动力和运动给控制带来了挑战，需要进一步研究。现有方法难以在太空中进行实验验证。对现有动力学模型进行实验测试和验证具有挑战性，因为这些模型是在六自由度（6-DOF）的太空中运行的。

Method: 本文设计并开发了一个硬件在环（HIL）实验测试平台，通过将一个6自由度UR3e机器人手臂安装在一个可沿单轴导轨移动的卫星总线上，来模拟ISAM操作。该系统能够自由移动卫星总线和机器人手臂，以探索和验证空间运动、串联机器人操作和接触力学的模型。

Result: 本文提出的HIL实验平台能够模拟ISAM操作，为验证和研究空间运动、串联机器人操作和接触力学的模型提供了实验手段，解决了在太空中进行实验验证的难题。

Conclusion: 本文提出的硬件在环（HIL）实验测试平台为在轨服务、组装和制造（ISAM）操作提供了一种有效的实验模拟方法，有助于解决在自由飞行卫星上进行机器人操作的控制挑战，并为相关模型的验证和研究提供了支持。

Abstract: In-Space Servicing, Assembly, and Manufacturing (ISAM) is a set of emerging
operations that provides several benefits to improve the longevity, capacity,
mo- bility, and expandability of existing and future space assets. Serial
robotic ma- nipulators are particularly vital in accomplishing ISAM operations,
however, the complex perturbation forces and motions associated with movement
of a robotic arm on a free-flying satellite presents a complex controls problem
requiring addi- tional study. While many dynamical models are developed,
experimentally test- ing and validating these models is challenging given that
the models operate in space, where satellites have six-degrees-of-freedom
(6-DOF). This paper attempts to resolve those challenges by presenting the
design and development of a new hardware-in-the-loop (HIL) experimental testbed
utilized to emulate ISAM. This emulation will be accomplished by means of a
6-DOF UR3e robotic arm attached to a satellite bus. This satellite bus is
mounted to a 1-DOF guide-rail system, en- abling the satellite bus and robotic
arm to move freely in one linear direction. This experimental ISAM emulation
system will explore and validate models for space motion, serial robot
manipulation, and contact mechanics.

</details>


### [186] [VLA-0: Building State-of-the-Art VLAs with Zero Modification](https://arxiv.org/abs/2510.13054)
*Ankit Goyal,Hugo Hadfield,Xuning Yang,Valts Blukis,Fabio Ramos*

Main category: cs.RO

TL;DR: VLA-0通过将动作表示为文本，在机器人操作任务中取得了出色的性能，优于现有更复杂的方法。


<details>
  <summary>Details</summary>
Motivation: 探索将动作直接表示为文本的最简单策略，以构建通用的视觉-语言-动作（VLA）模型，而非采用现有方法中常见的增加复杂性的方法（如修改视觉语言模型（VLM）的词汇表或引入特殊动作头）。

Method: 提出VLA-0模型，该模型将动作直接表示为文本，并探索了实现其高性能所需的特定设计技术。

Result: 在LIBERO基准测试中，VLA-0的性能优于所有在相同机器人数据上训练的现有方法（包括$"pi_0.5$-KI，OpenVLA-OFT和SmolVLA）。在没有大规模机器人特定训练的情况下，VLA-0的性能优于在大型机器人数据集上训练的方法（如$"pi_0.5$-KI，$"pi_0$，GR00T-N1和MolmoAct）。在现实世界中，VLA-0的性能也优于SmolVLA。

Conclusion: 简单的文本动作表示策略（VLA-0）不仅有效，而且非常强大，通过适当的设计，其性能可以超越更复杂的方法，为通用机器人操作提供了有前景的解决方案。

Abstract: Vision-Language-Action models (VLAs) hold immense promise for enabling
generalist robot manipulation. However, the best way to build them remains an
open question. Current approaches often add complexity, such as modifying the
existing vocabulary of a Vision-Language Model (VLM) with action tokens or
introducing special action heads. Curiously, the simplest strategy of
representing actions directly as text has remained largely unexplored. This
work introduces VLA-0 to investigate this idea. We find that VLA-0 is not only
effective; it is surprisingly powerful. With the right design, VLA-0
outperforms more involved models. On LIBERO, a popular benchmark for evaluating
VLAs, VLA-0 outperforms all existing methods trained on the same robotic data,
including $\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without
large-scale robotics-specific training, it outperforms methods trained on
large-scale robotic data, like $\pi_0.5$-KI, $\pi_0$, GR00T-N1 and MolmoAct.
These findings also translate to the real world, where VLA-0 outperforms
SmolVLA, a VLA model pre-trained on large-scale real data. This paper
summarizes our unexpected findings and spells out the specific techniques
required to unlock the high performance of this simple yet potent VLA design.
Visual results, code, and trained models are provided here:
https://vla0.github.io/.

</details>


### [187] [RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation](https://arxiv.org/abs/2510.13149)
*Yangtao Chen,Zixuan Chen,Nga Teng Chan,Junting Chen,Junhui Yin,Jieqi Shi,Yang Gao,Yong-Lu Li,Jing Huo*

Main category: cs.RO

TL;DR: 提出 RoboHiMan 评估范式，用于评估机器人长期操作中的分层泛化能力，并引入 HiMan-Bench 基准来系统地研究模型在复杂扰动下的泛化、鲁棒性和技能组合能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人灵活调度和组合学习技能以应对新颖的、长期的、多样化干扰下的操作的挑战，并弥补现有研究在组合泛化、鲁棒性和规划-执行交互方面的不足。

Method: 提出 RoboHiMan 评估范式，包括 HiMan-Bench 基准（包含原子和组合任务以及多级训练数据集）和三种评估范式（vanilla, decoupled, coupled），用于探测技能组合的必要性并揭示分层架构的瓶颈。

Result: 实验突显了代表性模型和架构在能力上的明显差距，并指出了改进模型以适应现实世界长期操作任务的方向。

Conclusion: RoboHiMan 及其 HiMan-Bench 基准能够系统地评估和揭示当前机器人模型在长期操作中的分层泛化和技能组合能力方面的局限性，为未来的研究提供了方向。

Abstract: Enabling robots to flexibly schedule and compose learned skills for novel
long-horizon manipulation under diverse perturbations remains a core challenge.
Early explorations with end-to-end VLA models show limited success, as these
models struggle to generalize beyond the training distribution. Hierarchical
approaches, where high-level planners generate subgoals for low-level policies,
bring certain improvements but still suffer under complex perturbations,
revealing limited capability in skill composition. However, existing benchmarks
primarily emphasize task completion in long-horizon settings, offering little
insight into compositional generalization, robustness, and the interplay
between planning and execution. To systematically investigate these gaps, we
propose RoboHiMan, a hierarchical evaluation paradigm for compositional
generalization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench,
a benchmark of atomic and compositional tasks under diverse perturbations,
supported by a multi-level training dataset for analyzing progressive data
scaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled)
that probe the necessity of skill composition and reveal bottlenecks in
hierarchical architectures. Experiments highlight clear capability gaps across
representative models and architectures, pointing to directions for advancing
models better suited to real-world long-horizon manipulation tasks. Videos and
open-source code can be found on our project website:
https://chenyt31.github.io/robo-himan.github.io/.

</details>


### [188] [ALOHA2 Robot Kitchen Application Scenario Reproduction Report](https://arxiv.org/abs/2510.13284)
*Haoyang Wu,Siheng Wu,William X. Liu,Fangui Zeng*

Main category: cs.RO

TL;DR: ALOHA2是ALOHA机器人的升级版，性能更强，更符合人体工程学。


<details>
  <summary>Details</summary>
Motivation: 介绍ALOHA2机器人，它是ALOHA的增强版本，具有更高的性能和鲁棒性，并且更加符合人体工程学。

Method: ALOHA2包含双臂、两个ViperX 6-DoF臂、两个 WidowX臂。用户通过操纵前臂来控制后臂。该设备还包括摄像头，可从多个视角生成图像，以在遥操作期间收集RGB数据。机器人安装在48英寸x30英寸的桌子上，并配有铝制框架，可提供额外的安装点，用于安装摄像头和重力补偿系统。

Result: ALOHA2在性能和鲁棒性方面得到了提升。

Conclusion: ALOHA2是一个性能更强、更符合人体工程学的双臂遥操作机器人。

Abstract: ALOHA2 is an enhanced version of the dual-arm teleoperated robot ALOHA,
featuring higher performance and robustness compared to the original design,
while also being more ergonomic. Like ALOHA, ALOHA2 consists of two grippers
and two ViperX 6-DoF arms, as well as two smaller WidowX arms. Users control
the follower mechanical arms by operating the leader mechanical arms through
back-driving. The device also includes cameras that generate images from
multiple viewpoints, allowing for RGB data collection during teleoperation. The
robot is mounted on a 48-inch x 30-inch table, equipped with an aluminum frame
that provides additional mounting points for cameras and gravity compensation
systems.

</details>


### [189] [DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping](https://arxiv.org/abs/2510.13287)
*Nishant Chandna,Akshat Kaushal*

Main category: cs.RO

TL;DR: DAMM-LOAM 通过点云分类和基于退化加权最小二乘的 ICP 算法，在稀疏特征、重复结构和高频运动等具有挑战性的环境中提高了 LiDAR SLAM 的精度，特别是在室内长走廊等环境中。


<details>
  <summary>Details</summary>
Motivation: 现有 LiDAR SLAM 系统在特征稀疏、几何结构重复或运动频率高的情况下，6-DOF 位姿估计存在退化问题。虽然大多数现有方法通过融合其他传感器来解决这些问题，但仅依赖 LiDAR 的方法仍然面临挑战。

Method: 提出了一种名为 DAMM-LOAM 的新模块，通过以下方式提高建图精度：1. 基于表面法线和邻域分析的点云分类（地面、墙壁、屋顶、边缘、非平面点），以实现精确的对应。2. 使用基于退化加权最小二乘的 ICP 算法进行精确的里程计估计。3. 实现基于 Scan Context 的后端以支持鲁棒的回环检测。

Result: DAMM-LOAM 在里程计精度方面表现出显著的改进，尤其是在室内长走廊等环境中。

Conclusion: DAMM-LOAM 能够通过点云分类和改进的 ICP 算法，在具有挑战性的环境中有效提高 LiDAR SLAM 的精度。

Abstract: LiDAR Simultaneous Localization and Mapping (SLAM) systems are essential for
enabling precise navigation and environmental reconstruction across various
applications. Although current point-to-plane ICP algorithms perform effec-
tively in structured, feature-rich environments, they struggle in scenarios
with sparse features, repetitive geometric structures, and high-frequency
motion. This leads to degeneracy in 6- DOF pose estimation. Most
state-of-the-art algorithms address these challenges by incorporating
additional sensing modalities, but LiDAR-only solutions continue to face
limitations under such conditions. To address these issues, we propose a novel
Degeneracy-Aware Multi-Metric LiDAR Odometry and Map- ping (DAMM-LOAM) module.
Our system improves mapping accuracy through point cloud classification based
on surface normals and neighborhood analysis. Points are classified into
ground, walls, roof, edges, and non-planar points, enabling accurate
correspondences. A Degeneracy-based weighted least squares-based ICP algorithm
is then applied for accurate odom- etry estimation. Additionally, a Scan
Context based back-end is implemented to support robust loop closures.
DAMM-LOAM demonstrates significant improvements in odometry accuracy,
especially in indoor environments such as long corridors

</details>


### [190] [Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation](https://arxiv.org/abs/2510.13324)
*Erik Helmut,Niklas Funk,Tim Schneider,Cristiana de Farias,Jan Peters*

Main category: cs.RO

TL;DR: FARM是一个模仿学习框架，通过整合高维触觉数据来推断触觉条件力信号，从而定义基于力的匹配动作空间，以解决接触式操作中的抓取力控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法将视觉触觉反馈视为附加观察，导致施加的力成为抓取器命令的失控后果，未能有效解决易碎或可变形物体操作中的抓取力控制问题。

Method: 收集使用集成GelSight Mini视觉触觉传感器的UMI夹持器进行的人体操作演示，并开发了驱动版本UMI夹持器以部署学习策略。FARM扩散策略在策略推出期间，联合预测机器人姿态、抓握宽度和抓握力。

Result: FARM在三种具有不同力要求的任务（高力、低力、动态力适应）上优于多个基线模型，证明了其利用力约束的高维触觉观察和基于力的控制空间的优势。

Conclusion: FARM通过整合高维触觉数据和基于力的控制空间，能够有效地学习和执行需要精确力控制的操作任务。

Abstract: Contact-rich manipulation depends on applying the correct grasp forces
throughout the manipulation task, especially when handling fragile or
deformable objects. Most existing imitation learning approaches often treat
visuotactile feedback only as an additional observation, leaving applied forces
as an uncontrolled consequence of gripper commands. In this work, we present
Force-Aware Robotic Manipulation (FARM), an imitation learning framework that
integrates high-dimensional tactile data to infer tactile-conditioned force
signals, which in turn define a matching force-based action space. We collect
human demonstrations using a modified version of the handheld Universal
Manipulation Interface (UMI) gripper that integrates a GelSight Mini visual
tactile sensor. For deploying the learned policies, we developed an actuated
variant of the UMI gripper with geometry matching our handheld version. During
policy rollouts, the proposed FARM diffusion policy jointly predicts robot
pose, grip width, and grip force. FARM outperforms several baselines across
three tasks with distinct force requirements -- high-force, low-force, and
dynamic force adaptation -- demonstrating the advantages of its two key
components: leveraging force-grounded, high-dimensional tactile observations
and a force-based control space. The codebase and design files are open-sourced
and available at https://tactile-farm.github.io .

</details>


### [191] [MODUR: A Modular Dual-reconfigurable Robot](https://arxiv.org/abs/2510.13356)
*Jie Gu,Tin Lun Lam,Chunxu Tian,Zhihao Xia,Yongheng Xing,Dan Zhang*

Main category: cs.RO

TL;DR: MODUR是一个具有双层重构能力的新型模块化自重构机器人（MSRR），每个模块都可以改变形状以执行基本运动，并通过实验验证了其运动。


<details>
  <summary>Details</summary>
Motivation: 提高MSRR在不同环境中的适应性和鲁棒性，通过引入双层重构能力，使机器人能够改变拓扑关系和自身形状。

Method: 设计了一种名为MODUR的新型MSRR，其设计包括一个紧凑的连接器和提供驱动力的剪刀连杆组，形成一个能够实现连接器运动解耦和相邻位置迁移能力的并联机构。对工作空间进行了分析，为模块基本运动的设计奠定了理论基础。

Result: MODUR能够进行高层级的模块间自重构以创建不同的配置，并且每个模块能够改变其形状以执行基本运动。连接器运动解耦和相邻位置迁移能力得到实现。

Conclusion: 实验验证了MODUR的运动，证明了其双层重构能力的有效性，为MSRR的设计奠定了理论基础。

Abstract: Modular Self-Reconfigurable Robot (MSRR) systems are a class of robots
capable of forming higher-level robotic systems by altering the topological
relationships between modules, offering enhanced adaptability and robustness in
various environments. This paper presents a novel MSRR called MODUR, featuring
dual-level reconfiguration capabilities designed to integrate reconfigurable
mechanisms into MSRR. Specifically, MODUR can perform high-level
self-reconfiguration among modules to create different configurations, while
each module is also able to change its shape to execute basic motions. The
design of MODUR primarily includes a compact connector and scissor linkage
groups that provide actuation, forming a parallel mechanism capable of
achieving both connector motion decoupling and adjacent position migration
capabilities. Furthermore, the workspace, considering the interdependent
connectors, is comprehensively analyzed, laying a theoretical foundation for
the design of the module's basic motion. Finally, the motion of MODUR is
validated through a series of experiments.

</details>


### [192] [Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control](https://arxiv.org/abs/2510.13358)
*Shingo Ayabe,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.RO

TL;DR: 该研究提出了一种离线到在线的框架，通过对抗性微调来提高策略在动作空间扰动下的鲁棒性，并使用性能感知课程来平衡鲁棒性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管离线强化学习能够有效学习策略且无需在线交互，但其策略在面对如执行器故障等动作空间扰动时表现脆弱。本研究旨在解决这一问题，提高策略的鲁棒性。

Method: 提出了一种离线到在线的框架，首先在干净数据上训练策略，然后进行对抗性微调。在此过程中，向执行的动作注入扰动，以诱导补偿行为，从而提高鲁棒性。此外，采用性能感知课程来调整扰动概率，以平衡鲁棒性和稳定性。

Result: 实验结果表明，所提出的方法在连续控制运动任务上，相比仅使用离线训练的方法，能够持续提高鲁棒性，并且比从头开始训练收敛更快。匹配微调和评估条件可以最大限度地提高对动作空间扰动的鲁棒性。同时，自适应课程策略能够减轻线性课程策略观察到的名义性能下降。

Conclusion: 对抗性微调能够实现适应性和鲁棒的控制，即使在不确定的环境中，也能有效弥合离线效率和在线适应性之间的差距。

Abstract: Offline reinforcement learning enables sample-efficient policy acquisition
without risky online interaction, yet policies trained on static datasets
remain brittle under action-space perturbations such as actuator faults. This
study introduces an offline-to-online framework that trains policies on clean
data and then performs adversarial fine-tuning, where perturbations are
injected into executed actions to induce compensatory behavior and improve
resilience. A performance-aware curriculum further adjusts the perturbation
probability during training via an exponential-moving-average signal, balancing
robustness and stability throughout the learning process. Experiments on
continuous-control locomotion tasks demonstrate that the proposed method
consistently improves robustness over offline-only baselines and converges
faster than training from scratch. Matching the fine-tuning and evaluation
conditions yields the strongest robustness to action-space perturbations, while
the adaptive curriculum strategy mitigates the degradation of nominal
performance observed with the linear curriculum strategy. Overall, the results
show that adversarial fine-tuning enables adaptive and robust control under
uncertain environments, bridging the gap between offline efficiency and online
adaptability.

</details>


### [193] [Real-Time Knee Angle Prediction Using EMG and Kinematic Data with an Attention-Based CNN-LSTM Network and Transfer Learning Across Multiple Datasets](https://arxiv.org/abs/2510.13443)
*Mojtaba Mollahossein,Gholamreza Vossoughi,Mohammad Hossein Rohban*

Main category: cs.RO

TL;DR: 本文提出了一种基于迁移学习的框架，利用轻量级CNN-LSTM模型，仅需少量步态周期即可预测膝关节角度，并验证了其在不同数据集和多模态输入下的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于EMG信号的身体关节角度预测方法面临实时性、测试条件代表性和数据集大小的挑战，而本文旨在解决这些问题，提出一种需要较少新被试数据即可实现高精度预测的迁移学习框架。

Method: 利用Georgia Tech、UCI和SMLE三个数据集，构建了一个轻量级的、基于注意力机制的CNN-LSTM模型。该模型在Georgia Tech数据集上进行预训练，然后迁移到UCI和SMLE数据集上进行微调。在不同场景下，分别仅使用EMG信号、EMG信号结合历史关节角度、以及EMG信号、运动学和交互力等多种模态进行预测。

Result: 单独使用EMG信号时，模型在异常被试的单步和50步预测中分别达到了6.8%和13.7%的NMAE。结合历史关节角度后，在正常被试中NMAE分别降至3.1%和3.5%，在异常被试中降至2.8%和7.5%。当结合EMG、运动学和交互力等信息并适配SMLE外骨骼后，单步和50步预测的NMAE分别达到1.09%和3.1%。

Conclusion: 所提出的迁移学习框架和轻量级模型在膝关节角度预测任务上表现出强大的泛化能力和鲁棒性，无论是在短期还是长期的康复场景下，均能实现高精度的预测，并且能有效减少对大规模数据集的需求。

Abstract: Electromyography (EMG) signals are widely used for predicting body joint
angles through machine learning (ML) and deep learning (DL) methods. However,
these approaches often face challenges such as limited real-time applicability,
non-representative test conditions, and the need for large datasets to achieve
optimal performance. This paper presents a transfer-learning framework for knee
joint angle prediction that requires only a few gait cycles from new subjects.
Three datasets - Georgia Tech, the University of California Irvine (UCI), and
the Sharif Mechatronic Lab Exoskeleton (SMLE) - containing four EMG channels
relevant to knee motion were utilized. A lightweight attention-based CNN-LSTM
model was developed and pre-trained on the Georgia Tech dataset, then
transferred to the UCI and SMLE datasets. The proposed model achieved
Normalized Mean Absolute Errors (NMAE) of 6.8 percent and 13.7 percent for
one-step and 50-step predictions on abnormal subjects using EMG inputs alone.
Incorporating historical knee angles reduced the NMAE to 3.1 percent and 3.5
percent for normal subjects, and to 2.8 percent and 7.5 percent for abnormal
subjects. When further adapted to the SMLE exoskeleton with EMG, kinematic, and
interaction force inputs, the model achieved 1.09 percent and 3.1 percent NMAE
for one- and 50-step predictions, respectively. These results demonstrate
robust performance and strong generalization for both short- and long-term
rehabilitation scenarios.

</details>


### [194] [Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations](https://arxiv.org/abs/2510.13488)
*Maximilian Stasica,Arne Bick,Nico Bohlinger,Omid Mohseni,Max Johannes Alois Fritzsche,Clemens Hübler,Jan Peters,André Seyfarth*

Main category: cs.RO

TL;DR: 本研究通过在模拟的振动环境中进行强化学习训练，显著提升了四足机器人在不稳定地面上的移动鲁棒性，使其能够在没有预先暴露于振动环境的情况下，也能保持稳定的步态。


<details>
  <summary>Details</summary>
Motivation: 当前关于足式机器人（尤其是四足机器人）在垂直地面扰动（如振荡表面）下的运动能力研究不足，本研究旨在解决这一问题，提升机器人在动态扰动下的移动鲁棒性。

Method: 研究人员在MuJoCo模拟环境中，使用近端策略优化（PPO）算法训练了Unitree Go2机器人。训练在振荡桥（具有2.0 Hz的固有频率）上进行，并结合了五种步态（trot, pace, bound, free, default）和三种训练条件（刚性桥，以及两种不同高度调节策略的振荡桥）。通过域随机化技术确保训练策略能够零样本迁移到真实世界。

Result: 在振荡桥上训练的策略相比于在刚性表面上训练的策略，表现出了更优越的稳定性和适应性。即使在没有预先接触振荡桥的情况下，机器人也能展现出鲁棒的步态模式。

Conclusion: 基于模拟的强化学习方法能够有效地提升四足机器人在动态地面扰动下的运动能力，为设计能够穿越振动环境的机器人提供了思路。

Abstract: Legged robots, particularly quadrupeds, excel at navigating rough terrains,
yet their performance under vertical ground perturbations, such as those from
oscillating surfaces, remains underexplored. This study introduces a novel
approach to enhance quadruped locomotion robustness by training the Unitree Go2
robot on an oscillating bridge - a 13.24-meter steel-and-concrete structure
with a 2.0 Hz eigenfrequency designed to perturb locomotion. Using
Reinforcement Learning (RL) with the Proximal Policy Optimization (PPO)
algorithm in a MuJoCo simulation, we trained 15 distinct locomotion policies,
combining five gaits (trot, pace, bound, free, default) with three training
conditions: rigid bridge and two oscillating bridge setups with differing
height regulation strategies (relative to bridge surface or ground). Domain
randomization ensured zero-shot transfer to the real-world bridge. Our results
demonstrate that policies trained on the oscillating bridge exhibit superior
stability and adaptability compared to those trained on rigid surfaces. Our
framework enables robust gait patterns even without prior bridge exposure.
These findings highlight the potential of simulation-based RL to improve
quadruped locomotion during dynamic ground perturbations, offering insights for
designing robots capable of traversing vibrating environments.

</details>


### [195] [A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints](https://arxiv.org/abs/2510.13535)
*Wentao Guo,Yizhou Wang,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种名为Hockens-A Hand的新型欠驱动自适应机械手，它集成了Hoeckens机制、双平行四边形连杆和专门的四连杆机构，实现了平行捏合、不对称舀取和包裹式抓取三种自适应抓取模式。该机械手仅需一个线性驱动器，并利用被动机械智能确保在非结构化环境中的适应性和顺应性。通过详细的运动学分析、仿真和实验验证了该设计的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一种仅需单一驱动器，即可在非结构化环境中实现多种自适应抓取的欠驱动机械手。

Method: 集成Hoeckens机制、双平行四边形连杆和四连杆机构；采用单线性驱动器；设计并分析了机械结构，包括运动学分析、仿真和实验验证；分析了抓取力。

Result: 成功实现了平行捏合、不对称舀取和包裹式抓取三种模式；验证了机械手的适应性、顺应性和抓取稳定性；3D打印原型机在各种场景下均表现良好。

Conclusion: Hockens-A Hand是一种有效且通用的欠驱动自适应机械手，能够通过被动机械智能在非结构化环境中实现多种抓取模式，具有广泛的应用前景。

Abstract: This paper presents a novel underactuated adaptive robotic hand, Hockens-A
Hand, which integrates the Hoeckens mechanism, a double-parallelogram linkage,
and a specialized four-bar linkage to achieve three adaptive grasping modes:
parallel pinching, asymmetric scooping, and enveloping grasping. Hockens-A Hand
requires only a single linear actuator, leveraging passive mechanical
intelligence to ensure adaptability and compliance in unstructured
environments. Specifically, the vertical motion of the Hoeckens mechanism
introduces compliance, the double-parallelogram linkage ensures line contact at
the fingertip, and the four-bar amplification system enables natural
transitions between different grasping modes. Additionally, the inclusion of a
mesh-textured silicone phalanx further enhances the ability to envelop objects
of various shapes and sizes. This study employs detailed kinematic analysis to
optimize the push angle and design the linkage lengths for optimal performance.
Simulations validated the design by analyzing the fingertip motion and ensuring
smooth transitions between grasping modes. Furthermore, the grasping force was
analyzed using power equations to enhance the understanding of the system's
performance.Experimental validation using a 3D-printed prototype demonstrates
the three grasping modes of the hand in various scenarios under environmental
constraints, verifying its grasping stability and broad applicability.

</details>


### [196] [Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.13553)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 该论文介绍了一种名为Hoecken-D Hand的仿生手，它结合了改进的Hoecken连杆和差速弹簧机制，能够实现线型平行夹持和自适应包络抓取，适用于抓取不规则或薄物体。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够适应不同形状物体、具有成本效益且结构紧凑的机器人手。

Method: 通过修改Hoecken连杆并加入差速弹簧机制，设计并制造了Hoecken-D Hand仿生手原型。利用运动学建模和力分析来表征其抓取性能，并通过3D打印技术制作原型。

Result: 该仿生手具有约200毫米的线型夹持范围，并且能够在两种抓取模式下可靠地抓取各种几何形状的物体。

Conclusion: Hoecken-D Hand是一种紧凑、适应性强且成本效益高的机器人手，为在非结构化环境中进行操作提供了解决方案。

Abstract: This paper presents the Hoecken-D Hand, an underactuated robotic gripper that
combines a modified Hoecken linkage with a differential spring mechanism to
achieve both linear parallel pinching and a mid-stroke transition to adaptive
envelope. The original Hoecken linkage is reconfigured by replacing one member
with differential links, preserving straight-line guidance while enabling
contact-triggered reconfiguration without additional actuators. A
double-parallelogram arrangement maintains fingertip parallelism during
conventional pinching, whereas the differential mechanism allows one finger to
wrap inward upon encountering an obstacle, improving stability on irregular or
thin objects. The mechanism can be driven by a single linear actuator,
minimizing complexity and cost; in our prototype, each finger is driven by its
own linear actuator for simplicity. We perform kinematic modeling and force
analysis to characterize grasp performance, including simulated grasping forces
and spring-opening behavior under varying geometric parameters. The design was
prototyped using PLA-based 3D printing, achieving a linear pinching span of
approximately 200 mm. Preliminary tests demonstrate reliable grasping in both
modes across a wide range of object geometries, highlighting the Hoecken-D Hand
as a compact, adaptable, and cost-effective solution for manipulation in
unstructured environments.

</details>


### [197] [Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots](https://arxiv.org/abs/2510.13594)
*Austin Barret,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 本研究旨在开发一个可扩展的、用户友好的图形用户界面（GUI），以便非专业操作人员能够轻松控制人形机器人完成障碍训练。本研究将利用用户界面开发（UI）和人机交互（HRI）的常见实践，以实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 目前许多人形机器人系统在操作界面的开发上投入不足，未能提供非专家用户友好的图形用户界面（GUI）。

Method: 本研究将结合用户界面开发（UI）和人机交互（HRI）的通用实践，开发一种新颖的界面，旨在实现非专业人员的远程操作系统。

Result: 本研究将开发一个可扩展的、用户友好的GUI，使非专业操作人员能够通过FIRA规定的障碍训练课程来控制机器人。

Conclusion: 本研究将开发一个简单直观的可扩展GUI，使非专业操作人员能够有效地控制人形机器人完成障碍训练。

Abstract: The operation of humanoid robotics is an essential field of research with
many practical and competitive applications. Many of these systems, however, do
not invest heavily in developing a non-expert-centered graphical user interface
(GUI) for operation. The focus of this research is to develop a scalable GUI
that is tailored to be simple and intuitive so non-expert operators can control
the robot through a FIRA-regulated obstacle course. Using common practices from
user interface development (UI) and understanding concepts described in
human-robot interaction (HRI) and other related concepts, we will develop a new
interface with the goal of a non-expert teleoperation system.

</details>


### [198] [Active Tactile Exploration for Rigid Body Pose and Shape Estimation](https://arxiv.org/abs/2510.13595)
*Ethan K. Gordon,Bruke Baraki,Hien Bui,Michael Posa*

Main category: cs.RO

TL;DR: 本文提出了一种仅使用触觉数据来同时确定刚性物体形状和位置的学习和探索框架，并取得了显著的学习速度提升。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中，处理未知的物体很重要。利用触觉感知（尽管其时间稀疏性需要仔细的在线探索）来学习物理上准确的模型可以提高数据效率、可预测性，并支持任务重用。

Method: 提出了一种学习和探索框架，利用接触丰富系统识别的进展，并提出了一个惩罚物理约束违反但无数值刚性的损失函数。还设计了一个最大化预期信息增益的探索方案。

Result: 在仅使用几十次随机接触数据后，成功学习了立方体和凸多面体的几何形状。在模拟和真实机器人实验中，探索方案的学习速度显著提高。

Conclusion: 提出的框架能够仅利用触觉数据，通过最大化预期信息增益来高效地学习未知刚性物体的形状和位置。

Abstract: General robot manipulation requires the handling of previously unseen
objects. Learning a physically accurate model at test time can provide
significant benefits in data efficiency, predictability, and reuse between
tasks. Tactile sensing can compliment vision with its robustness to occlusion,
but its temporal sparsity necessitates careful online exploration to maintain
data efficiency. Direct contact can also cause an unrestrained object to move,
requiring both shape and location estimation. In this work, we propose a
learning and exploration framework that uses only tactile data to
simultaneously determine the shape and location of rigid objects with minimal
robot motion. We build on recent advances in contact-rich system identification
to formulate a loss function that penalizes physical constraint violation
without introducing the numerical stiffness inherent in rigid-body contact.
Optimizing this loss, we can learn cuboid and convex polyhedral geometries with
less than 10s of randomly collected data after first contact. Our exploration
scheme seeks to maximize Expected Information Gain and results in significantly
faster learning in both simulated and real-robot experiments. More information
can be found at https://dairlab.github.io/activetactile

</details>


### [199] [PlanarMesh: Building Compact 3D Meshes from LiDAR using Incremental Adaptive Resolution Reconstruction](https://arxiv.org/abs/2510.13599)
*Jiahao Wang,Nived Chebrolu,Yifu Tao,Lintong Zhang,Ayoung Kim,Maurice Fallon*

Main category: cs.RO

TL;DR: PlanarMesh是一个实时、高效的增量式三维激光雷达点云重建系统，通过自适应调整网格分辨率和结合平面建模与网格技术，实现了高精度、小尺寸的重建。


<details>
  <summary>Details</summary>
Motivation: 在构建能进行详细表面重建且计算高效的在线三维激光雷达地图系统时面临挑战。

Method: 提出了一种名为PlanarMesh的新型增量式、基于网格的激光雷达重建系统。该系统自适应地调整网格分辨率，采用平面-网格（planar-mesh）表示方法，结合了平面建模和网格技术，能够增量式地更新，并利用多线程架构和边界体积层次（BVH）实现高效数据存储和快速搜索，以达到实时性能。

Result: 实验结果表明，PlanarMesh的重建精度可与最先进的技术（包括截断符号距离函数、占用映射和基于体素的网格化）相媲美，甚至超越它们。同时，其输出文件大小显著减小（比原始输入小10倍，比其他基于网格的方法小5倍以上），并保持了实时性能（约2 Hz，适用于64线激光雷达传感器）。

Conclusion: PlanarMesh通过其创新的平面-网格表示和高效的系统设计，成功解决了实时、高精度、高压缩率的三维激光雷达重建问题。

Abstract: Building an online 3D LiDAR mapping system that produces a detailed surface
reconstruction while remaining computationally efficient is a challenging task.
In this paper, we present PlanarMesh, a novel incremental, mesh-based LiDAR
reconstruction system that adaptively adjusts mesh resolution to achieve
compact, detailed reconstructions in real-time. It introduces a new
representation, planar-mesh, which combines plane modeling and meshing to
capture both large surfaces and detailed geometry. The planar-mesh can be
incrementally updated considering both local surface curvature and free-space
information from sensor measurements. We employ a multi-threaded architecture
with a Bounding Volume Hierarchy (BVH) for efficient data storage and fast
search operations, enabling real-time performance. Experimental results show
that our method achieves reconstruction accuracy on par with, or exceeding,
state-of-the-art techniques-including truncated signed distance functions,
occupancy mapping, and voxel-based meshing-while producing smaller output file
sizes (10 times smaller than raw input and more than 5 times smaller than
mesh-based methods) and maintaining real-time performance (around 2 Hz for a
64-beam sensor).

</details>


### [200] [Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor](https://arxiv.org/abs/2510.13616)
*Preston Fairchild,Claudia Chen,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本研究提出了一种集成到机器人夹爪中的柔性压力传感器，用于处理易损农产品，该传感器能够精确控制抓握力，避免损坏产品，并能估计产品的硬度和成熟度。


<details>
  <summary>Details</summary>
Motivation: 为了实现自动化农业采摘和加工的未来，需要开发能够以适当的力抓握易损农产品的机器人操纵器，以避免损坏。

Method: 提出并集成了一种低成本、易于制造的柔性压力传感器到刚性机器人夹爪和气动软手指中。开发了一种基于瞬态响应数据加速估计传感器稳态值的算法，并展示了传感器在提供抓握力反馈以及估计物体尺寸和硬度方面的有效性。

Result: 传感器成功集成到机器人夹爪和软手指中。所提出的算法能够实时估计传感器输出。实验证明，该传感器能够根据未知尺寸和硬度的物体调整抓握力，并提供关于成熟度和损伤的估计值。

Conclusion: 该柔性压力传感器能够为机器人提供必要的触觉反馈，以处理易损农产品，并能进行产品识别、质量控制和基于成熟度的选择性分发。

Abstract: Properly handling delicate produce with robotic manipulators is a major part
of the future role of automation in agricultural harvesting and processing.
Grasping with the correct amount of force is crucial in not only ensuring
proper grip on the object, but also to avoid damaging or bruising the product.
In this work, a flexible pressure sensor that is both low cost and easy to
fabricate is integrated with robotic grippers for working with produce of
varying shapes, sizes, and stiffnesses. The sensor is successfully integrated
with both a rigid robotic gripper, as well as a pneumatically actuated soft
finger. Furthermore, an algorithm is proposed for accelerated estimation of the
steady-state value of the sensor output based on the transient response data,
to enable real-time applications. The sensor is shown to be effective in
incorporating feedback to correctly grasp objects of unknown sizes and
stiffnesses. At the same time, the sensor provides estimates for these values
which can be utilized for identification of qualities such as ripeness levels
and bruising. It is also shown to be able to provide force feedback for objects
of variable stiffnesses. This enables future use not only for produce
identification, but also for tasks such as quality control and selective
distribution based on ripeness levels.

</details>


### [201] [Characterizing Lidar Point-Cloud Adversities Using a Vector Field Visualization](https://arxiv.org/abs/2510.13619)
*Daniel Choate,Jason Rife*

Main category: cs.RO

TL;DR: 本研究提出一种可视化方法，辅助分析师对影响激光雷达扫描匹配的障碍模式进行分类。该方法生成矢量场图，表征配准点云对之间的局部差异，从而揭示原始点云数据中难以提取的模式。研究通过仿真和现场实验的例子进行了验证，分析师能够识别并剔除障碍模式，逐步聚焦于更小的差异。


<details>
  <summary>Details</summary>
Motivation: 开发一种可视化方法，帮助人类分析师对影响激光雷达（lidar）扫描匹配的障碍模式进行分类。

Method: 生成一个矢量场图，该图表征一对配准点云之间的局部差异。

Result: 该方法能够揭示出原始点云数据中难以提取的模式。通过将该方法应用于仿真研究和现场实验的例子中，人类分析师能够识别并逐步剔除障碍模式，从而将注意力集中在越来越小的差异上。

Conclusion: 所提出的可视化方法能够有效地帮助分析师理解和处理激光雷达扫描匹配中的障碍模式。

Abstract: In this paper we introduce a visualization methodology to aid a human analyst
in classifying adversity modes that impact lidar scan matching. Our methodology
is intended for offline rather than real-time analysis. The method generates a
vector-field plot that characterizes local discrepancies between a pair of
registered point clouds. The vector field plot reveals patterns that would be
difficult for the analyst to extract from raw point-cloud data. After
introducing our methodology, we apply the process to two proof-of-concept
examples: one a simulation study and the other a field experiment. For both
data sets, a human analyst was able to reason about a series of adversity
mechanisms and iteratively remove those mechanisms from the raw data, to help
focus attention on progressively smaller discrepancies.

</details>


### [202] [A Modular Object Detection System for Humanoid Robots Using YOLO](https://arxiv.org/abs/2510.13625)
*Nicolas Pottier,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 本研究提出了一个基于YOLOv9的通用机器人视觉模块，用于克服机器人领域的计算机视觉瓶颈。


<details>
  <summary>Details</summary>
Motivation: 机器人领域的计算机视觉仍然是一个重大障碍，许多任务因效率低下的视觉系统而受阻。本研究旨在通过引入一个优化的视觉模块来解决这个问题。

Method: 使用针对FIRA机器人Hurocup数据集训练的YOLOv9模型，并在ROS1环境中使用虚拟环境实现该模型，以确保YOLO兼容性。

Result: YOLO模型实现了与现有几何框架相当的精度，但计算成本更高，然而在静态和动态环境中都表现出更强的鲁棒性。

Conclusion: 虽然YOLO模型计算成本较高，但其在机器人视觉任务中展现出优越的鲁棒性，为克服计算机视觉瓶颈提供了有前景的解决方案。

Abstract: Within the field of robotics, computer vision remains a significant barrier
to progress, with many tasks hindered by inefficient vision systems. This
research proposes a generalized vision module leveraging YOLOv9, a
state-of-the-art framework optimized for computationally constrained
environments like robots. The model is trained on a dataset tailored to the
FIRA robotics Hurocup. A new vision module is implemented in ROS1 using a
virtual environment to enable YOLO compatibility. Performance is evaluated
using metrics such as frames per second (FPS) and Mean Average Precision (mAP).
Performance is then compared to the existing geometric framework in static and
dynamic contexts. The YOLO model achieved comparable precision at a higher
computational cost then the geometric model, while providing improved
robustness.

</details>


### [203] [LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models](https://arxiv.org/abs/2510.13626)
*Senyu Fei,Siyin Wang,Junhao Shi,Zihao Dai,Jikun Cai,Pengfang Qian,Li Ji,Xinzhe He,Shiduo Zhang,Zhaoye Fei,Jinlan Fu,Jingjing Gong,Xipeng Qiu*

Main category: cs.RO

TL;DR: VLA模型在机器人操作基准测试中表现优异，但对扰动的鲁棒性分析显示其存在严重缺陷，尤其对视角和初始状态敏感，且会忽略语言指令。


<details>
  <summary>Details</summary>
Motivation: 评估现有视觉-语言-动作（VLA）模型在机器人操控任务中的鲁棒性，揭示其在面对现实世界变化时的潜在脆弱性。

Method: 通过在物体布局、相机视角、机器人初始状态、语言指令、光照条件、背景纹理和传感器噪声七个维度引入受控扰动，系统性地分析多个先进VLA模型的性能。

Result: 模型在面对相机视角和机器人初始状态等扰动时性能急剧下降（从95%降至30%以下）；模型对语言指令的变化不敏感，甚至会完全忽略指令。整体表现出对扰动的极端敏感性。

Conclusion: 现有VLA模型在基准测试中的高分可能掩盖了其在真实变化下的不可靠性。需要更注重评估模型在现实变化下的可靠性，而非仅仅依赖基准测试分数。

Abstract: Visual-Language-Action (VLA) models report impressive success rates on
robotic manipulation benchmarks, yet these results may mask fundamental
weaknesses in robustness. We perform a systematic vulnerability analysis by
introducing controlled perturbations across seven dimensions: objects layout,
camera viewpoints, robot initial states, language instructions, light
conditions, background textures and sensor noise. We comprehensively analyzed
multiple state-of-the-art models and revealed consistent brittleness beneath
apparent competence. Our analysis exposes critical weaknesses: models exhibit
extreme sensitivity to perturbation factors, including camera viewpoints and
robot initial states, with performance dropping from 95% to below 30% under
modest perturbations. Surprisingly, models are largely insensitive to language
variations, with further experiments revealing that models tend to ignore
language instructions completely. Our findings challenge the assumption that
high benchmark scores equate to true competency and highlight the need for
evaluation practices that assess reliability under realistic variation.

</details>


### [204] [On Your Own: Pro-level Autonomous Drone Racing in Uninstrumented Arenas](https://arxiv.org/abs/2510.13644)
*Michael Bosello,Flavio Pinzarrone,Sara Kiade,Davide Aguiari,Yvo Keuter,Aaesha AlShehhi,Gyordan Caminati,Kei Long Wong,Ka Seng Chou,Junaid Halepota,Fares Alneyadi,Jacopo Panerati,Giovanni Pau*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Drone technology is proliferating in many industries, including agriculture,
logistics, defense, infrastructure, and environmental monitoring. Vision-based
autonomy is one of its key enablers, particularly for real-world applications.
This is essential for operating in novel, unstructured environments where
traditional navigation methods may be unavailable. Autonomous drone racing has
become the de facto benchmark for such systems. State-of-the-art research has
shown that autonomous systems can surpass human-level performance in racing
arenas. However, direct applicability to commercial and field operations is
still limited as current systems are often trained and evaluated in highly
controlled environments. In our contribution, the system's capabilities are
analyzed within a controlled environment -- where external tracking is
available for ground-truth comparison -- but also demonstrated in a
challenging, uninstrumented environment -- where ground-truth measurements were
never available. We show that our approach can match the performance of
professional human pilots in both scenarios. We also publicly release the data
from the flights carried out by our approach and a world-class human pilot.

</details>


### [205] [Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures](https://arxiv.org/abs/2510.13686)
*Miana Smith,Paul Arthur Richard,Alexander Htet Kyaw,Neil Gershenfeld*

Main category: cs.RO

TL;DR: 提出一种使用简单机器人和互锁晶格构建块来制造可扩展宏观结构的方法


<details>
  <summary>Details</summary>
Motivation: 桌面规模的数字制造过程虽然已经熟练且产品丰富，但旨在生产更大规模结构的系统通常仍然复杂、昂贵且不可靠。

Method: 将目标结构进行体素化，以便用结构化晶格填充。然后将这些体素分组为更大的互连块，并使用标准的数字制造过程生产这些块。然后，将这些尺寸约为几十厘米的块馈送到能够遍历结构的移动机器人，并放置新块以形成米尺度结构。为了促进大型结构的组装，引入了一个实时的数字孪生模拟工具来控制和协调组装机器人，该工具能够进行目标结构的全盘规划以及实时的用户设计、交互或干预。为了提高组装吞吐量，引入了一种新的模块化组装机器人，用于体素处理。

Result: 通过演示一系列米尺度对象的体素化、分层阻塞、路径规划和机器人制造来验证该系统。

Conclusion: 所提出的方法能够使用户能够克服现有技术的局限性，并以更高的效率和可扩展性大规模地制造复杂结构。

Abstract: Although digital fabrication processes at the desktop scale have become
proficient and prolific, systems aimed at producing larger-scale structures are
still typically complex, expensive, and unreliable. In this work, we present an
approach for the fabrication of scalable macroscale structures using simple
robots and interlocking lattice building blocks. A target structure is first
voxelized so that it can be populated with an architected lattice. These voxels
are then grouped into larger interconnected blocks, which are produced using
standard digital fabrication processes, leveraging their capability to produce
highly complex geometries at a small scale. These blocks, on the size scale of
tens of centimeters, are then fed to mobile relative robots that are able to
traverse over the structure and place new blocks to form structures on the
meter scale. To facilitate the assembly of large structures, we introduce a
live digital twin simulation tool for controlling and coordinating assembly
robots that enables both global planning for a target structure and live user
design, interaction, or intervention. To improve assembly throughput, we
introduce a new modular assembly robot, designed for hierarchical voxel
handling. We validate this system by demonstrating the voxelization,
hierarchical blocking, path planning, and robotic fabrication of a set of
meter-scale objects.

</details>


### [206] [InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy](https://arxiv.org/abs/2510.13778)
*Xinyi Chen,Yilun Chen,Yanwei Fu,Ning Gao,Jiaya Jia,Weiyang Jin,Hao Li,Yao Mu,Jiangmiao Pang,Yu Qiao,Yang Tian,Bin Wang,Bolun Wang,Fangjing Wang,Hanqing Wang,Tai Wang,Ziqin Wang,Xueyuan Wei,Chao Wu,Shuai Yang,Jinhui Ye,Junqiu Yu,Jia Zeng,Jingjing Zhang,Jinyu Zhang,Shi Zhang,Feng Zheng,Bowen Zhou,Yangkun Zhu*

Main category: cs.RO

TL;DR: InternVLA-M1是一个统一的机器人控制和空间定位框架，通过空间定位引导的视觉-语言-动作训练，提升了指令遵循机器人的泛化智能。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的智能机器人框架，使其能够理解和执行复杂的指令，实现可扩展、通用的智能。

Method: 采用两阶段训练：首先进行空间定位预训练（2.3M+空间推理数据），确定‘在哪里行动’；然后进行空间定位引导的动作后训练，通过即插即用的空间提示生成‘如何行动’的动作。收集了244K的泛化抓取和放置模拟数据，并在真实世界和长序列推理任务中进行了测试。

Result: InternVLA-M1在多个基准测试中表现优于无空间引导的变体，例如在SimplerEnv Google Robot上提升+14.6%，在WidowX上提升+17%，在LIBERO Franka上提升+4.3%。在抓取和放置任务中，平均提高了6.2%，在真实世界中提升了7.3%，在合成数据协同训练下，对未见过的物体和新配置提升了+20.6%。在长序列推理任务中，超越现有方法超过10%。

Conclusion: 空间定位引导的训练是实现可扩展、有弹性的通用机器人的统一原则。

Abstract: We introduce InternVLA-M1, a unified framework for spatial grounding and
robot control that advances instruction-following robots toward scalable,
general-purpose intelligence. Its core idea is spatially guided
vision-language-action training, where spatial grounding serves as the critical
link between instructions and robot actions. InternVLA-M1 employs a two-stage
pipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning
data to determine ``where to act'' by aligning instructions with visual,
embodiment-agnostic positions, and (ii) spatially guided action post-training
to decide ``how to act'' by generating embodiment-aware actions through
plug-and-play spatial prompting. This spatially guided training recipe yields
consistent gains: InternVLA-M1 outperforms its variant without spatial guidance
by +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO
Franka, while demonstrating stronger spatial reasoning capability in box,
point, and trace prediction. To further scale instruction following, we built a
simulation engine to collect 244K generalizable pick-and-place episodes,
enabling a 6.2% average improvement across 200 tasks and 3K+ objects. In
real-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with
synthetic co-training, achieved +20.6% on unseen objects and novel
configurations. Moreover, in long-horizon reasoning-intensive scenarios, it
surpassed existing works by over 10%. These results highlight spatially guided
training as a unifying principle for scalable and resilient generalist robots.
Code and models are available at
https://github.com/InternRobotics/InternVLA-M1.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [207] [Control of dynamical systems with neural networks](https://arxiv.org/abs/2510.12810)
*Lucas Böttcher*

Main category: eess.SY

TL;DR: 本研究探讨了使用深度学习和自动微分技术来解决科学和工业中的控制问题，重点关注如何利用神经网络参数化离散时间和连续时间系统、确定性和随机动力学中的控制输入。


<details>
  <summary>Details</summary>
Motivation: 控制问题在科学和工业应用中普遍存在，目标是将动态系统从初始状态引导至目标状态。深度学习和自动微分的进展使得将这些方法应用于控制问题越来越实用。

Method: 研究了使用神经网络和现代机器学习库来参数化离散时间和连续时间系统、确定性和随机动力学中的控制输入。对于连续时间系统，提出了使用神经常微分方程（neural ODEs）作为参数化控制输入的有用方法。对于离散时间系统，展示了如何使用自动微分方法实现和优化自定义控制输入参数化。

Result: 该研究强调了在生物学、工程学、物理学和医学等多个领域的应用。提出的方法为计算密集型或解析上不可行（analytically intractable）的控制任务提供了实际解决方案。

Conclusion: 总体而言，本研究提出的方法为复杂的现实世界控制任务提供了有价值的解决方案，这些任务在计算上要求很高或在解析上难以处理。

Abstract: Control problems frequently arise in scientific and industrial applications,
where the objective is to steer a dynamical system from an initial state to a
desired target state. Recent advances in deep learning and automatic
differentiation have made applying these methods to control problems
increasingly practical. In this paper, we examine the use of neural networks
and modern machine-learning libraries to parameterize control inputs across
discrete-time and continuous-time systems, as well as deterministic and
stochastic dynamics. We highlight applications in multiple domains, including
biology, engineering, physics, and medicine. For continuous-time dynamical
systems, neural ordinary differential equations (neural ODEs) offer a useful
approach to parameterizing control inputs. For discrete-time systems, we show
how custom control-input parameterizations can be implemented and optimized
using automatic-differentiation methods. Overall, the methods presented provide
practical solutions for control tasks that are computationally demanding or
analytically intractable, making them valuable for complex real-world
applications.

</details>


### [208] [Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation](https://arxiv.org/abs/2510.12832)
*Alistair Brash,Junyi Lu,Bruce Stephen,Blair Brown,Robert Atkinson,Craig Michie,Fraser MacIntyre,Christos Tachtatzis*

Main category: eess.SY

TL;DR: 对低压配电网的负荷数据进行建模，以解决规划和拥塞管理问题。


<details>
  <summary>Details</summary>
Motivation: 低压配电网的有限可见性给规划和拥塞管理带来了挑战，而现有方法在处理负荷数据时存在局限性，无法捕捉子站间的协同行为和负荷多样性，尤其是在低碳技术日益普及的背景下。

Method: 提出一种条件扩散模型，用于合成低压配电母线级别的每日有功功率和无功功率曲线。

Result: 所合成的负荷曲线在独立和群体上都具有实际意义，能够反映更广泛的电力系统背景。通过与朴素模型和最先进模型进行对比，证明了该模型在生成用于电网规划和运营的实际场景方面的有效性。

Conclusion: 所提出的条件扩散模型能够生成具有统计真实性和时间上合理性的负荷曲线，并能捕捉子站间的协同行为，为低压配电网的规划和运营提供了更可靠的数据支持。

Abstract: Limited visibility of power distribution network power flows at the low
voltage level presents challenges to both distribution network operators from a
planning perspective and distribution system operators from a congestion
management perspective. Forestalling these challenges through scenario analysis
is confounded by the lack of realistic and coherent load data across
representative distribution feeders. Load profiling approaches often rely on
summarising demand through typical profiles, which oversimplifies the
complexity of substation-level operations and limits their applicability in
specific power system studies. Sampling methods, and more recently generative
models, have attempted to address this through synthesising representative
loads from historical exemplars; however, while these approaches can
approximate load shapes to a convincing degree of fidelity, the co-behaviour
between substations, which ultimately impacts higher voltage level network
operation, is often overlooked. This limitation will become even more
pronounced with the increasing integration of low-carbon technologies, as
estimates of base loads fail to capture load diversity. To address this gap, a
Conditional Diffusion model for synthesising daily active and reactive power
profiles at the low voltage distribution substation level is proposed. The
evaluation of fidelity is demonstrated through conventional metrics capturing
temporal and statistical realism, as well as power flow modelling. The results
show synthesised load profiles are plausible both independently and as a cohort
in a wider power systems context. The Conditional Diffusion model is
benchmarked against both naive and state-of-the-art models to demonstrate its
effectiveness in producing realistic scenarios on which to base sub-regional
power distribution network planning and operations.

</details>


### [209] [ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization](https://arxiv.org/abs/2510.12897)
*Sanjay Johnson,Dirk Lauinger,Sungho Shin,François Pacaud*

Main category: eess.SY

TL;DR: ExaModelsPower.jl是一个开源的GPU兼容非线性交流最优潮流模型库，可为大规模电力系统优化提供显著加速。


<details>
  <summary>Details</summary>
Motivation: 随着GPU加速数学规划技术的发展，人们对其在解决电力系统优化计算挑战方面的应用日益感兴趣。

Method: 本文介绍并使用ExaModelsPower.jl，一个基于ExaModels.jl构建的开源建模库，它提供了一个高层接口，可自动为GPU求解器生成必要的函数回调，适用于包含多个时间段和安全约束的大规模问题实例。

Result: 在开源测试用例上，与CPU工具相比，GPU求解器在具有超过20,000个变量且精度高达10^{-4}的问题上，速度提高了两个数量级。对于较小实例或更严格的容差，性能可能有所不同。

Conclusion: ExaModelsPower.jl能够显著加速大规模电力系统优化问题的求解，为GPU在这一领域的应用提供了有力的支持。

Abstract: As GPU-accelerated mathematical programming techniques mature, there is
growing interest in utilizing them to address the computational challenges of
power system optimization. This paper introduces ExaModelsPower.jl, an
open-source modeling library for creating GPU-compatible nonlinear AC optimal
power flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a
high-level interface that automatically generates all necessary callback
functions for GPU solvers. The library is designed for large-scale problem
instances, which may include multiple time periods and security constraints.
Using ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test
cases. Our results show that GPU solvers can deliver up to two orders of
magnitude speedups compared to alternative tools on CPU for problems with more
than 20,000 variables and a solution precision of up to $10^{-4}$, while
performance for smaller instances or tighter tolerances may vary.

</details>


### [210] [A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems](https://arxiv.org/abs/2510.12914)
*Zhi Liu,Chengxi Liu,Jiangbei Han,Rui Qiu,Mingyuan Liu*

Main category: eess.SY

TL;DR: 该研究提出了一种基于宽带复合序列阻抗模型（WCSIM）的分析方法，用于评估电力电子系统在电网不平衡故障或不平衡负载下的相互作用。


<details>
  <summary>Details</summary>
Motivation: 评估电力电子系统在电网不平衡故障或不平衡负载下的相互作用，并量化正序、负序和零序电路之间的小信号互联对不平衡电力系统相互作用稳定性的影响。

Method: 提出并应用宽带复合序列阻抗模型（WCSIM）来分析不平衡电力系统中的相互作用。

Result: 通过永磁同步发电机弱电网系统在单线接地故障（SLGF）下的仿真和硬件在环测试，验证了WCSIM的正确性和所提出分析方法的有效性。

Conclusion: WCSIM及其分析方法能够有效评估不平衡电力系统中的相互作用及其对稳定性的影响。

Abstract: This paper proposes a wideband composite sequence impedance model
(WCSIM)-based analysis method to evaluate the interactions in
power-electronic-based power systems subjected to unbalanced grid faults or
with unbalanced loads. The WCSIM-based method intuitively assesses the impact
of the small-signal interconnection among the positive-, negative-, and
zero-sequence circuits on the interaction stability of unbalanced power
systems. The effectiveness of this method is demonstrated using a permanent
magnet synchronous generator-based weak grid system under a
single-line-to-ground fault (SLGF). Frequency scanning results and controller
hardware-in-loop tests validate both the correctness of the WCSIM and the
effectiveness of the WCSIM-based analysis method.

</details>


### [211] [Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation](https://arxiv.org/abs/2510.12946)
*Daniel C. Qi,Kenshiro Oguri,Puneet Singla,Maruthi R. Akella*

Main category: eess.SY

TL;DR: 该研究提出了一种在非线性动力学系统中控制非高斯分布的方法，利用共轭无迹变换量化高阶矩，并通过序列凸规划求解。


<details>
  <summary>Details</summary>
Motivation: 高非线性系统（如天体动力学）中，高斯分布常演化为非高斯分布，需要有效控制方法。

Method: 利用共轭无迹变换量化非高斯分布的高阶统计矩，并聚焦于控制和约束与不确定性量化相关的sigma点，最后通过序列凸规划求解。

Result: 通过二体和三体问题算例，证明了该方法可以直接控制单个矩，并在整个控制时间范围内精确近似非高斯分布的矩。

Conclusion: 所提出的方法能够有效控制非高斯分布，并精确近似其矩，适用于天体动力学等高非线性系统。

Abstract: In highly nonlinear systems such as the ones commonly found in astrodynamics,
Gaussian distributions generally evolve into non-Gaussian distributions. This
paper introduces a method for effectively controlling non-Gaussian
distributions in nonlinear environments using optimized linear feedback
control. This paper utilizes Conjugate Unscented Transformation to quantify the
higher-order statistical moments of non-Gaussian distributions. The formulation
focuses on controlling and constraining the sigma points associated with the
uncertainty quantification, which would thereby reflect the control of the
entire distribution and constraints on the moments themselves. This paper
develops an algorithm to solve this problem with sequential convex programming,
and it is demonstrated through a two-body and three-body example. The examples
show that individual moments can be directly controlled, and the moments are
accurately approximated for non-Gaussian distributions throughout the
controller's time horizon in nonlinear dynamics.

</details>


### [212] [Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility](https://arxiv.org/abs/2510.12949)
*Zhiyuan Fan,Elizabeth Dentzer,James Glynn,David S. Goldberg,Julio Friedmann,Bolun Xu*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current decarbonization efforts are falling short of meeting the net-zero
greenhouse gas (GHG) emission target, highlighting the need for substantial
carbon dioxide removal methods such as direct air capture (DAC). However,
integrating DACs poses challenges due to their enormous power consumption. This
study assesses the commercial operation of various DAC technologies that earn
revenue using monetized carbon incentives while purchasing electricity from
wholesale power markets. We model four commercial DAC technologies and examine
their operation in three representative locations including California, Texas,
and New York. Our findings reveal that commercial DAC operations can take
financial advantage of the volatile power market to operate only during
low-price periods strategically, offering a pathway to facilitate a
cost-efficient decarbonization transition. The ambient operational environment
such as temperature and relative humidity has non-trivial impact on abatement
capacity. Profit-driven decisions introduce climate-economic trade-offs that
might decrease the capacity factor of DAC and reduce total CO2 removal. These
implications extend throughout the entire lifecycle of DAC developments and
influence power systems and policies related to full-scale DAC implementation.
Our study shows that DAC technologies with shorter cycle spans and higher
flexibility can better exploit the electricity price volatility, while power
markets demonstrate persistent low-price windows that often synergize with low
grid emission periods, like during the solar "duck curve" in California. An
optimal incentive design exists for profit-driven operations while carbon-tax
policy in electricity pricing is counterproductive for DAC systems.

</details>


### [213] [Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study](https://arxiv.org/abs/2510.12955)
*Levi D. Reyes Premer,Elias N. Pergantis,Leo Semmelmann,Davide Ziviani,Kevin J. Kircher*

Main category: eess.SY

TL;DR: 本研究开发了一种新型模型预测控制（MPC）系统，使120V电热泵热水器（HPWH）无需辅助电热元件即可高效运行，并能预热以应对用水高峰，从而节省能源和成本。


<details>
  <summary>Details</summary>
Motivation: 目前的HPWH大多需要240V电路，增加了安装成本。本研究旨在开发一种适用于120V HPWH的控制系统，以降低能耗和成本。

Method: 开发并实测了一种新型MPC系统，该系统利用机器学习预测用水量，并进行预加热以保证用水舒适度。MPC系统通过移载用电负荷来降低能源成本。

Result: 与标准的240V HPWH相比，MPC系统在按时计费和每小时计费下，能源成本平均分别降低23%和28%。与将水温维持在恒定高温（60°C）的120V HPWH相比，MPC系统平均节能37%。

Conclusion: 本研究开发的MPC系统使120V HPWH在大多数安装场景下具有经济吸引力，能够有效降低能源成本和对电网的影响。

Abstract: Electric heat-pump water heaters (HPWHs) could reduce the energy costs,
emissions, and power grid impacts associated with water heating, the
second-largest energy use in United States housing. However, most HPWHs today
require 240 V circuits to power the backup resistance heating elements they use
to maintain comfort during large water draws. Installing a 240 V circuit can
increase the up-front cost of a HPWH by half or more. This paper develops and
field-tests the first control system that enables a 120 V HPWH to efficiently
maintain comfort without resistance heating elements. The novel model
predictive control (MPC) system enables pre-heating in anticipation of large
water draws, which it forecasts using an ensemble of machine learning
predictors. By shifting electrical load over time, MPC also reduces energy
costs on average by 23% and 28% under time-of-use pricing and hourly pricing,
respectively, relative to a 240 V HPWH with standard controls. Compared to the
increasingly common practice in 120 V HPWHs of storing water at a constant,
high temperature (60 {\deg}C) to ensure comfort, MPC saves 37% energy on
average. In addition to demonstrating MPC's benefits in a real, occupied house,
this paper discusses implementation challenges and costs. A simple payback
analysis suggests that a 120 V HPWH, operated by the MPC system developed here,
would be economically attractive in most installation scenarios.

</details>


### [214] [Competitive EV charging station location with queues](https://arxiv.org/abs/2510.12961)
*The Minh Nguyen,Nagisa Sugishita,Margarida Carvalho,Amira Dems*

Main category: eess.SY

TL;DR: 在有竞争性市场和更现实的排队系统的背景下，为电动汽车公共充电基础设施规划提供了一个新的数学模型，考虑了用户行为和多个服务提供商的影响，并在蒙特利尔的一个实际案例研究中得到了证明。


<details>
  <summary>Details</summary>
Motivation: 现有电动汽车充电基础设施规划模型在考虑竞争性市场中的多个服务提供商及其对用户行为和拥堵的影响方面存在局限性。

Method: 该研究首先分析了三种有限排队系统（M/M/1/K、M/M/s/K 和 M/Er/s/K），并推导了用户行为指标的解析表达式。然后，将基于排队的模型嵌入到双层规划中，其中上层进行充电站的选址以最大化可达性，下层通过用户均衡来捕捉用户的选址选择。为了解决这个双层问题，研究采用了竞争性拥挤用户选择设施选址模型的一种改革方法，并引入了一种基于替代的启发式方法来提高可扩展性。

Result: 研究在加拿大蒙特利尔的一个城市区域进行了案例研究，结果表明所提出的模型能够制定出优于现有网络的（重新）选址策略。该模型还提供了关于用户选择行为假设和竞争如何影响吞吐量和选址决策的管理见解。

Conclusion: 该研究提出的方法为电动汽车充电基础设施的规划提供了一个工具，能够将充电服务质量（通过排队指标衡量）和现有竞争纳入其中，从而在有多个服务提供商的竞争市场中做出更优的决策。

Abstract: Electric vehicle (EV) public charging infrastructure planning faces
significant challenges in competitive markets, where multiple service providers
affect congestion and user behavior. This work extends existing modeling
frameworks by incorporating the presence of competitors' stations and more
realistic queueing systems.
  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and
M/Er/s/K, with varying numbers of servers (charging outlets) and service time
distributions, deriving analytic expressions for user behavior metrics. Second,
we embed the queueing-based user behavior model into a bilevel program, where
the upper level locates new charging stations to maximize accessibility
(throughput), and the lower level captures users' station choices via a user
equilibrium. Third, we apply a reformulation from competitive congested
user-choice facility location models to approximately solve the bilevel problem
and introduce a surrogate-based heuristic to enhance scalability. Fourth, we
showcase our methodology on a real-world case study of an urban area in
Montreal (Canada), offering managerial insights into how user-choice behavior
assumptions and competition affect throughput and location decisions. The
results demonstrate that our model yields (re)location strategies that
outperform the existing network. More broadly, this approach provides a tool
for incorporating charging service quality-through queueing metrics-and
existing competition into station planning.

</details>


### [215] [Identifying Best Candidates for Busbar Splitting](https://arxiv.org/abs/2510.13000)
*Giacomo Bastianel,Dirk Van Hertem,Hakan Ergun,Line Roald*

Main category: eess.SY

TL;DR: 通过提出一套指标来识别和排序有希望的母线分接（BuS）候选点，以优化电网拓扑并降低发电成本，并使用混合整数二次规划模型和非线性非凸交流最优潮流（OPF）仿真进行验证。


<details>
  <summary>Details</summary>
Motivation: 电网拥堵日益严重，需要通过优化电网拓扑（如母线分接 BuS 和最优输电切换）来缓解并降低发电成本，但现有方法在大型电网中计算量巨大。

Method: 提出一套指标来识别和排序有希望的 BuS 候选点，并使用混合整数二次规划模型计算最优拓扑，然后用非线性非凸交流最优潮流（OPF）仿真进行验证。

Result: 提出的指标能够有效识别出通过 BuS 优化可以降低总发电成本的母线，无需逐一测试所有母线。

Conclusion: 该方法能够有效选择 BuS 母线，解决了现有方法在大型电网中计算量大的问题，并能有效降低总发电成本。

Abstract: Rising electricity demand and the growing integration of renewables are
intensifying congestion in transmission grids. Grid topology optimization
through busbar splitting (BuS) and optimal transmission switching can alleviate
grid congestion and reduce the generation costs in a power system. However, BuS
optimization requires a large number of binary variables, and analyzing all the
substations for potential new topological actions is computationally
intractable, particularly in large grids. To tackle this issue, we propose a
set of metrics to identify and rank promising candidates for BuS, focusing on
finding buses where topology optimization can reduce generation costs. To
assess the effect of BuS on the identified buses, we use a combined
mixed-integer convex-quadratic BuS model to compute the optimal topology and
test it with the non-linear non-convex AC optimal power flow (OPF) simulation
to show its AC feasibility. By testing and validating the proposed metrics on
test cases of different sizes, we show that they are able to identify busbars
that reduce the total generation costs when their topology is optimized. Thus,
the metrics enable effective selection of busbars for BuS, with no need to test
every busbar in the grid, one at a time.

</details>


### [216] [Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch](https://arxiv.org/abs/2510.13004)
*Robert Muldrow,Channing Ludden,Christopher Petersen*

Main category: eess.SY

TL;DR: 为了提高航天器交会对接操作（RPOD）的燃油效率、成本效益和任务寿命，本文将研究重点放在了改进RPOD模型上。


<details>
  <summary>Details</summary>
Motivation: 随着空间产业的扩张，对改进的燃油效率、成本效益和任务寿命的需求日益增长，因此，改进RPOD模型至关重要。

Method: 本文研究了经典的Clohessy-Wiltshire (CW) 方程，并通过将该模型预测的轨迹与更高保真度的RPOD模型进行比较，来评估CW模型失配的程度。在多个相似任务参数的测试案例中，将自然运动绕飞（NMC）与可比的强制运动绕飞进行了比较。

Result: 研究结果表明，在维持零燃料消耗的CW轨迹时，所需的引导、导航和控制（GNC）脉冲操作能够体现CW模型失配的程度。

Conclusion: 研究证明，非强制运动不一定比强制运动更节省燃料，因此，在燃油效率更高的情况下，可以允许进行更长时间的轨道运行。

Abstract: This paper compares the required fuel usage for forced and unforced motion of
a chaser satellite engaged in Rendezvous, Proximity Operations, and Docking
(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space
industry expands and demands for improved fuel efficiency, cost effectiveness,
and mission life span increase. This paper specifically examines the Clohessy-
Wiltshire (CW) Equations and the extent of model mismatch by comparing pre-
dicted trajectories from this model with a more computationally complex, higher
fidelity RPOD model. This paper assesses several test cases of similar mission
parameters, in each case comparing natural motion circumnavigation (NMC) with
comparable forced motion circumnavigation. The Guidance, Navigation, and Con-
trol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW
trajectories is representative of the extent of CW model mismatch. This paper
demonstrates that unforced motions are not inherently more fuel efficient than
forced motions, thus permitting extended orbital operations given the higher
fuel efficiency.

</details>


### [217] [Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification](https://arxiv.org/abs/2510.13024)
*Shahab Ataei,Dipankar Maity,Debdipta Goswami*

Main category: eess.SY

TL;DR: 云辅助系统识别和控制在低功耗、资源受限的控制系统（如微型无人机）中得到实际应用。然而，低带宽无线链路会导致数据量化，影响系统识别和控制性能。本文研究了状态和输入数据量化对线性时不变（LTI）系统识别的影响，推导了识别误差的界限，并开发了一种具有成本保证的鲁棒控制器。


<details>
  <summary>Details</summary>
Motivation: 研究云辅助系统中状态和输入数据量化对线性时不变（LTI）系统识别的影响，以及开发相应的鲁棒控制器。

Method: 推导了量化数据和量化分辨率相关的模型误差的界限，并基于此误差界限开发了一种基于线性矩阵不等式（LMI）的具有成本保证的鲁棒控制器。

Result: 提出了一个依赖于量化数据和量化分辨率的模型误差界限，并开发了一种鲁棒控制器。

Conclusion: 云辅助系统中的数据量化会对系统识别和控制性能产生影响，但可以通过推导误差界限并设计鲁棒控制器来缓解这些影响。

Abstract: Cloud-assisted system identification and control have emerged as practical
solutions for low-power, resource-constrained control systems such as
micro-UAVs. In a typical cloud-assisted setting, state and input data are
transmitted from local agents to a central computer over low-bandwidth wireless
links, leading to quantization. This paper investigates the impact of state and
input data quantization on a linear time invariant (LTI) system identification,
derives a worst-case bound on the identification error, and develops a robust
controller for guaranteed cost control. We establish a fundamental bound on the
model error that depends only on the quantized data and quantization
resolution, and develop a linear matrix inequality (LMI) based guaranteed cost
robust controller under this error bound.

</details>


### [218] [Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment](https://arxiv.org/abs/2510.13100)
*Yifu Ding,Ruicheng Ao,Pablo Duenas-Martinez,Thomas Magnanti*

Main category: eess.SY

TL;DR: 该研究提出了一种两阶段鲁棒充电基础设施规划模型，用于工业场地的电动轻型卡车，以减少温室气体排放。


<details>
  <summary>Details</summary>
Motivation: 工业场地依赖柴油轻型卡车运输工人及小型设施，导致大量温室气体排放。

Method: 开发了一个两阶段鲁棒充电基础设施规划模型（MILP），优化充电器类型、位置和充电调度，并纳入了基于等待时间和放弃行为的调度问题，同时考虑了隔夜充电和续航里程焦虑的影响。模型还构建了一个决策依赖鲁棒不确定性集来表示停车时间的随机性和异质性。

Result: 在露天矿场的一个案例研究中，该模型规划了八个区域的充电器安装，并调度了约200辆卡车的车队。通过将问题分解为月度子问题并使用启发式方法，在整个年度数据集和各种不确定性情景下，模型在合理计算时间内实现了小于0.1%的最优度量。

Conclusion: 该模型能够有效地规划工业场地的电动轻型卡车充电基础设施，并在考虑实际操作约束和不确定性的情况下，在合理的计算时间内实现接近最优的调度方案。

Abstract: Many industrial sites rely on diesel-powered light-duty trucks to transport
workers and small-scale facilities, which has resulted in a significant amount
of greenhouse emissions (GHGs). To address this, we developed a two-stage
robust charging infrastructure planning model for electrifying light-duty
trucks at industrial sites. The model is formulated as a mixed-integer linear
programming (MILP) that optimizes the charging infrastructure, selected from
multiple charger types and potential locations, and determines opportunity
charging schedules for each truck based on the chosen infrastructure. Given the
strict stopping points and schedules at industrial sites, we introduced a
scheduling problem with abandonment, where trucks forgo charging if their
waiting times exceed a maximum threshold. We also further incorporated the
impacts of overnight charging and range anxiety on waiting and abandonment
behaviors. To represent the stochastic and heterogeneous parking durations of
trucks, we constructed a decision-dependent robust uncertainty set in which
parking time variability flexibly depends on charging choices. We applied the
model in a case study of an open-pit mining site, which plans charger
installations in eight zones and schedules a fleet of around 200 trucks. By
decomposing the problem into monthly subproblems and using heuristic
approaches, for the whole-year dataset, the model achieves an optimality gap of
less than 0.1 % within a reasonable computation time under diverse uncertainty
scenarios.

</details>


### [219] [Safe Driving in Occluded Environments](https://arxiv.org/abs/2510.13114)
*Zhuoyuan Wang,Tongyao Jia,Pharuj Rajborirug,Neeraj Ramesh,Hiroyuki Okuda,Tatsuya Suzuki,Soummya Kar,Yorie Nakahira*

Main category: eess.SY

TL;DR: 该研究提出了一种用于处理自动驾驶中潜在风险（由于遮挡导致不可见）的概率安全证书。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶安全技术在处理遮挡导致的潜在风险时面临挑战，因为无法直接观察到危险状态。

Method: 提出了一种概率安全证书，利用概率不变性放松了对风险状态严格可观测性的要求，并为控制器提供了线性动作约束，以将潜在风险的概率限制在可接受范围内。

Result: 通过CARLA模拟器测试，与现有技术相比，所提出的方法在遮挡环境中实现了实时、长期的安全保障，且不过于保守，并对暴露的风险保持透明。

Conclusion: 所提出的概率安全证书能够有效地处理自动驾驶中的潜在风险，确保在遮挡环境下的长期安全性。

Abstract: Ensuring safe autonomous driving in the presence of occlusions poses a
significant challenge in its policy design. While existing model-driven control
techniques based on set invariance can handle visible risks, occlusions create
latent risks in which safety-critical states are not observable. Data-driven
techniques also struggle to handle latent risks because direct mappings from
risk-critical objects in sensor inputs to safe actions cannot be learned
without visible risk-critical objects. Motivated by these challenges, in this
paper, we propose a probabilistic safety certificate for latent risk. Our key
technical enabler is the application of probabilistic invariance: It relaxes
the strict observability requirements imposed by set-invariance methods that
demand the knowledge of risk-critical states. The proposed techniques provide
linear action constraints that confine the latent risk probability within
tolerance. Such constraints can be integrated into model predictive controllers
or embedded in data-driven policies to mitigate latent risks. The proposed
method is tested using the CARLA simulator and compared with a few existing
techniques. The theoretical and empirical analysis jointly demonstrate that the
proposed methods assure long-term safety in real-time control in occluded
environments without being overly conservative and with transparency to exposed
risks.

</details>


### [220] [Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time](https://arxiv.org/abs/2510.13279)
*Fuma Omori,Atsushi Yano,Takuya Azumi*

Main category: eess.SY

TL;DR: 该论文提出了一种用于自动驾驶系统（可建模为DAG）的概率性调度方法，以替代严格的最坏情况保证。通过利用单处理器上的概率性调度结果，该方法对多核处理器上的DAG任务集进行了分区，以确保在分区调度下的可调度性。实验证明，该方法在调度更多任务集和更短的平均分析时间方面优于现有方法，并且在四种装箱启发式算法中，


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统对实时性要求高，可建模为DAG，其加速特性（如缓存、流水线）导致执行时间通常低于最坏情况。因此，概率性保证比最坏情况保证更适合此类系统。

Method: 1. 利用单处理器上的概率性调度结果来处理多核处理器上的DAG任务。 2. 提出了一种任务集分区方法，以保证在分区调度下的可调度性。 3. 评估了四种装箱启发式算法，以确定哪种算法最适合任务集分区。

Result: 提出的方法能够调度更多的DAG任务集，并具有更短的平均分析时间。在评估的四种装箱启发式算法中，Item-Centric Worst-Fit-Decreasing算法表现最佳。

Conclusion: 该论文提出的概率性任务集分区方法能够有效地为自动驾驶系统提供可调度的DAG任务集，并在效率和性能上优于现有方法。Item-Centric Worst-Fit-Decreasing算法是最佳的任务集分区策略。

Abstract: Autonomous driving systems, critical for safety, require real-time guarantees
and can be modeled as DAGs. Their acceleration features, such as caches and
pipelining, often result in execution times below the worst-case. Thus, a
probabilistic approach ensuring constraint satisfaction within a probability
threshold is more suitable than worst-case guarantees for these systems. This
paper considers probabilistic guarantees for DAG tasks by utilizing the results
of probabilistic guarantees for single processors, which have been relatively
more advanced than those for multi-core processors. This paper proposes a task
set partitioning method that guarantees schedulability under the partitioned
scheduling. The evaluation on randomly generated DAG task sets demonstrates
that the proposed method schedules more task sets with a smaller mean analysis
time compared to existing probabilistic schedulability analysis for DAGs. The
evaluation also compares four bin-packing heuristics, revealing Item-Centric
Worst-Fit-Decreasing schedules the most task sets.

</details>


### [221] [Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics](https://arxiv.org/abs/2510.13396)
*Luka Baković,David Ohlin,Emma Tegling*

Main category: eess.SY

TL;DR: 本研究验证了多极模型在新冠疫苗接种率和政治参与度两个相关变量上的应用，并展示了该模型成功捕捉了数据中的意见分离现象，空间相关性对于结果至关重要。


<details>
  <summary>Details</summary>
Motivation: 验证多极模型在处理两个相关变量数据集上的应用，并探索其在理解社会现象中的作用。

Method: 提出并应用一种通用方法，使用多极模型分析新冠疫苗接种率与瑞典政治参与度之间的数据关系。

Result: 模型成功捕捉了数据中的意见分离现象，并证明了空间相关性对于实现这一结果的必要性。偏见的混合会导致更同质化的意见分布和更广泛的主流意见渗透（在此对应于投票或接种疫苗的决定）。

Conclusion: 多极模型能够成功解释和预测具有空间相关性的社会现象，而偏见的混合则会影响意见的分布和主流观点的传播。

Abstract: We perform a validation analysis on the multipolar model of opinion dynamics.
A general methodology for using the model on datasets of two correlated
variables is proposed and tested using data on the relationship between
COVID-19 vaccination rates and political participation in Sweden. The model is
shown to successfully capture the opinion segregation demonstrated by the data
and spatial correlation of biases is demonstrated as necessary for the result.
A mixing of the biases on the other hand leads to a more homogeneous opinion
distribution, and greater penetration of the majority opinion, which here
corresponds to a decision to vote or vaccinate.

</details>


### [222] [On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations](https://arxiv.org/abs/2510.13449)
*Jan Brändle,Julie Rousseau,Pulkit Nahata,Gabriela Hug*

Main category: eess.SY

TL;DR: 分布式可再生能源和电气化设备（如热泵和光伏系统）的整合能显著增强配电网的灵活性，但其聚合潜力受限于电网拓扑和网络约束，并且不随设备渗透率线性或单调增长。


<details>
  <summary>Details</summary>
Motivation: 现代配电网需要整合分布式可再生能源和电气化设备，以利用聚合灵活性来维持电网稳定性。

Method: 以瑞士瓦伦施塔特配电网为案例研究，利用模拟来分析聚合灵活性潜力、时变特性以及不同设备渗透率下的影响。

Result: 研究表明，热泵和光伏系统等设备可以显著增强配电网的灵活性。聚合灵活性具有时变性，并且会随季节变化。未来的模拟显示，聚合灵活性并不随设备渗透率的提高而线性或单调增长，主要是因为个别馈线的过载问题。

Conclusion: 电网拓扑和网络约束对聚合灵活性潜力有重要影响，需要仔细考虑，以有效利用分布式资源的聚合灵活性。

Abstract: The growing integration of distributed renewable generation and the
electrification of heating and transportation are rapidly increasing the number
of flexible devices within modern distribution grids. Leveraging the aggregated
flexibility of these small-scale distributed resources is essential to
maintaining future grid-wide stability. This work uses the Swiss distribution
grid of Walenstadt as a case study to provide insights into the aggregated
flexibility potential of distribution grids. It demonstrates that incorporating
devices such as heat pumps and photovoltaic systems significantly enhances
distribution grid flexibility. It investigates the time-varying nature of
aggregated flexibility and highlights how it can vary seasonally. Furthermore,
simulations of future scenarios reveal that aggregated flexibility does not
increase linearly or monotonically with higher levels of flexible device
penetration. This is primarily due to the overloading of individual feeders,
which underscores the impact of grid topology and network constraints on the
aggregated flexibility potential.

</details>


### [223] [Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers](https://arxiv.org/abs/2510.13461)
*Yangye Jiang,Jiachen Wang,Daofei Li*

Main category: eess.SY

TL;DR: 该研究提出了一种双重物理信息神经网络框架，通过结合高斯混合模型和自适应PINN，在提高碰撞动力学预测精度和计算效率的同时，满足了先进安全系统的需求。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞动力学预测方法在计算效率、预测准确性和数据需求之间存在固有权衡，难以满足高级安全系统和碰撞后控制应用的需求。

Method: 提出一个双重物理信息神经网络（PINN）框架：1. 结合高斯混合模型（GMM）和PINN，从有限元分析（FEA）数据中学习撞击力分布，并强制执行动量守恒和能量一致性约束。2. 使用自适应PINN和动态约束加权来预测碰撞后车辆动力学，引入自适应物理保护层以防止不切实际的预测，并保留数据驱动学习能力。该框架还通过时变参数进行不确定性量化，并通过微调策略实现快速适应。

Result: 撞击力模型在FEA数据集上的预测相对误差低于15.0%。车辆动力学模型在缩比车辆实验中，将平均轨迹预测误差相对于传统的四自由度模型降低了63.6%。该系统实现了毫秒级计算效率，并提供概率置信度界限。

Conclusion: 所提出的双重PINN框架在提高碰撞动力学预测精度、计算效率和鲁棒性方面取得了显著进展，为实时安全关键应用提供了有效解决方案。

Abstract: Accurate prediction of vehicle collision dynamics is crucial for advanced
safety systems and post-impact control applications, yet existing methods face
inherent trade-offs among computational efficiency, prediction accuracy, and
data requirements. This paper proposes a dual Physics-Informed Neural Network
framework addressing these challenges through two complementary networks. The
first network integrates Gaussian Mixture Models with PINN architecture to
learn impact force distributions from finite element analysis data while
enforcing momentum conservation and energy consistency constraints. The second
network employs an adaptive PINN with dynamic constraint weighting to predict
post-collision vehicle dynamics, featuring an adaptive physics guard layer that
prevents unrealistic predictions whil e preserving data-driven learning
capabilities. The framework incorporates uncertainty quantification through
time-varying parameters and enables rapid adaptation via fine-tuning
strategies. Validation demonstrates significant improvements: the impact force
model achieves relative errors below 15.0% for force prediction on finite
element analysis (FEA) datasets, while the vehicle dynamics model reduces
average trajectory prediction error by 63.6% compared to traditional
four-degree-of-freedom models in scaled vehicle experiments. The integrated
system maintains millisecond-level computational efficiency suitable for
real-time applications while providing probabilistic confidence bounds
essential for safety-critical control. Comprehensive validation through FEA
simulation, dynamic modeling, and scaled vehicle experiments confirms the
framework's effectiveness for Precision Immobilization Technique scenarios and
general collision dynamics prediction.

</details>


### [224] [Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage](https://arxiv.org/abs/2510.13514)
*Andreas C. Makrides,Adam Suski,Elina Spyrou*

Main category: eess.SY

TL;DR: 缺乏风险市场阻碍了对提高可靠性的技术（如长时储能）的投资，从而降低了社会福利并对可靠性造成了损害。


<details>
  <summary>Details</summary>
Motivation: 为了实现完全脱碳的电力系统，必须整合新的可靠性技术，但缺乏风险市场阻碍了对这些技术的投资。

Method: 开发了一个包含风险规避市场参与者的两阶段随机均衡模型，该模型独立确定电力和能源容量，并将其应用于深度脱碳的英国电力系统。

Result: 不完整的风险市场会降低社会福利、损害可靠性，并阻碍对长时储能和其他收入波动较大的技术的投资。收入波动导致了高额的风险溢价和更高的融资成本，阻碍了长时储能的大规模部署。

Conclusion: 为了降低资本成本并加速对提高可靠性的零碳技术的投资，必须实施能够对冲收入风险的政策机制。

Abstract: The transition to a fully decarbonised electricity system depends on
integrating new technologies that ensure reliability alongside sustainability.
However, missing risk markets hinder investment in reliability-enhancing
technologies by exposing investors to revenue uncertainty. This study provides
the first quantitative assessment of how missing risk markets affect investment
decisions in power systems that depend on long-duration energy storage (LDES)
for reliability. We develop a two-stage stochastic equilibrium model with
risk-averse market participants, which independently sizes power and energy
capacity. We apply the method to a case study of a deeply decarbonised power
system in Great Britain. The results show that incomplete risk markets reduce
social welfare, harm reliability, and discourage investment in LDES and other
technologies with volatile revenue streams. Revenue volatility leads to
substantial risk premiums and higher financing costs for LDES, creating a
barrier to its large-scale deployment. These findings demonstrate the
importance of policy mechanisms that hedge revenue risk to lower the cost of
capital and accelerate investment in reliability-enhancing, zero-carbon
technologies

</details>


### [225] [Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications](https://arxiv.org/abs/2510.13563)
*Ayten Gürbüz,Giuseppe Caire*

Main category: eess.SY

TL;DR: NOMA技术在民航通信中面临高速和远距离带来的挑战，需要针对不同飞行阶段优化信道估计和检测方法。


<details>
  <summary>Details</summary>
Motivation: 研究NOMA技术在空地通信中的应用，解决高速飞行带来的多普勒频移和远距离通信的低信噪比问题。

Method: 使用基于飞行测量数据的空地信道模型，比较Zadoff-Chu序列和时分方法在不同载波频率偏移下的信道估计性能，并计算零强制检测和最小均方误差检测（含连续干扰消除）的断链概率。

Result: 最佳的信道估计器-检测器组合在起降和巡航阶段因传播特性不同而异。

Conclusion: 针对空地NOMA通信，需要根据飞行阶段（起降或巡航）选择不同的信道估计和检测策略以优化系统性能。

Abstract: This paper investigates a multiple antenna system with non-orthogonal
multiple access (NOMA) for the exchange of air traffic management data between
commercial aircraft pilots and ground-based air traffic controllers. While NOMA
techniques enhance spectral efficiency, their application to aircraft
communications is challenged by the high speed of the aircraft (up to 214 m/s)
and the long communication ranges (up to 250 km), resulting in significant
Doppler shifts and low signal-to-noise ratios, respectively. To accurately
assess these challenges, we employ a realistic geometry-based stochastic
air-ground channel model, derived from dedicated flight measurement campaigns.
In this paper, multiple aircraft simultaneously transmit data to the ground
station. We focus on the channel estimation problem at the ground station under
high carrier frequency offsets and the effects of channel aging due to
channel's time-varying nature. For the channel estimation problem, we compare
the Zadoff-Chu sequences with time-division approach under varying carrier
frequency offset pre-compensation accuracies at the aircraft transmitter. For
the channel aging problem and performance evaluation of channel estimators, we
compute the outage probability for both the zero-forcing detector and the
minimum mean squared error detector with successive interference cancellation.
The results show that the favorable channel estimator-detector combinations
differ between the takeoff & landing phase and the enroute cruise phase of the
flight, due to the distinct channel propagation characteristics of each phase.

</details>


### [226] [A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array](https://arxiv.org/abs/2510.13682)
*Jiayang Li,Qingyu Zhang,Sohmyung Ha,Dai Jiang,Andreas Demosthenous,Yu Wu*

Main category: eess.SY

TL;DR: 该论文介绍了一种用于大规模压阻传感器阵列的快速阻抗测量集成电路。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够快速、高能效地测量大规模压阻传感器阵列阻抗的集成电路。

Method: 提出了一种统一差分时间数字解调架构，通过激励电路直接读取阻抗，并采用预饱和自适应偏置技术提高能效。

Result: 该芯片在 125 kHz 下，12.2 毫秒内可扫描 253 个传感器（82 fps），功耗为 158 微瓦（每个传感器 7.5 纳焦）。在 20 欧姆到 500 千欧姆的负载范围内，实现了 0.5% 的误差和高达 71.1 dB 的信噪比。

Conclusion: 该集成电路实现了快速、高能效的阻抗测量，适用于大规模压阻传感器阵列。

Abstract: This paper presents a fast impedance measurement IC for large-scale
piezo-resistive sensor array. It features a unified differential
time-to-digital demodulation architecture that readout impedance directly
through the excitation circuit. The proposed pre-saturation adaptive bias
technique further improves power efficiency. The chip scans 253 sensors in 12.2
ms (82 fps) at 125 kHz, consuming 158 {\mu}W (7.5 nJ/sensor). With loads from
20 {\Omega} to 500 k{\Omega}, it achieves 0.5% error and up to 71.1 dB SNR.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [227] [A multiscale model of friction considering the influence of third-body wear particles](https://arxiv.org/abs/2510.13470)
*Parissa Sadat Alavi,Guillaume Anciaux,Jean-François Molinari,Loris Rocchi,Christian Leppin*

Main category: physics.app-ph

TL;DR: 该研究提出了一个分层多尺度框架，用于预测包含第三类磨损颗粒的滑动界面的摩擦力，并将粒子尺度力学与宏观摩擦联系起来。


<details>
  <summary>Details</summary>
Motivation: 准确预测含有第三类磨损颗粒的滑动界面的摩擦力对于活塞、轴承或金属成型等工程应用至关重要。

Method: 研究提出了一个分层多尺度框架。宏观尺度上，一维有限元模型通过阿卡德定律更新局部磨损颗粒密度，并结合介观尺度模拟结果计算局部摩擦力。介观尺度上，耦合的离散元边界元方法解决了粗糙表面与刚性扁球形磨损颗粒之间的载荷共享问题。介观尺度的解将摩擦系数反馈给宏观尺度求解器，从而实现尺度间的闭环。

Result: 模拟的摩擦系数与实际的拉带摩擦实验结果一致，能够体现摩擦力随法向压力增加而降低的现象，以及工具垫尺寸的影响。

Conclusion: 该多尺度框架能够准确预测滑动界面的摩擦力，并验证了其在实际工程应用中的潜力。

Abstract: Accurately predicting friction in sliding interfaces that contain third body
wear particles is critical for engineering applications such as sliding
movement in pistons, bearings, or metal forming. We present a hierarchical
multiscale framework that links particle scale mechanics to macroscopic
friction in a strip draw friction test. At the macroscale, a one dimensional
finite element model reproduces the global stress state of the strip draw setup
and updates the local wear particle density via Archard's law. The local
friction force at each node is then computed from mesoscale simulation results.
At the mesoscale, a coupled discrete element boundary element approach resolves
load sharing between rough surfaces and rigid oblate spheroidal wear particles.
The mesoscale solution returns to the macroscale solver a friction coefficient
that depends on normal pressure, sliding velocity, surface geometry, and
particle density, thereby closing the loop between scales. The simulated
friction coefficient matches strip draw experiments, capturing both the
observed decrease in friction with increasing normal pressure and the influence
of tool pad size.

</details>


### [228] [Molecularly imprinted nanopores for multiplexed sensing, release, and in-edge computing](https://arxiv.org/abs/2510.13490)
*Ali Douaki,Shukun Weng,Silvia Dante,Nako Nakatsuka,Makusu Tsutsui,Roman Krahne,Denis Garoli*

Main category: physics.app-ph

TL;DR: 固态纳米孔阵列结合分子印迹聚合物（MIPs）实现多巴胺、γ-氨基丁酸和组胺的选择性检测与受控释放，具有高时空分辨率（100 ms/ 3 μm），并展示了逻辑门和边缘计算能力。


<details>
  <summary>Details</summary>
Motivation: 在纳米孔技术中，开发具有高空间和时间分辨率的多重检测和释放平台仍然是一个重大挑战，因为难以区分来自单个芯片上不同纳米孔的信号。

Method: 设计了一个纳米孔阵列，每个纳米孔都用能够识别特定神经递质（多巴胺、γ-氨基丁酸和组胺）的 MIPs 进行功能化。每个纳米孔都用微腔进行隔离，以防止信号串扰。

Result: 该平台在灵敏度、选择性、回收率和稳定性方面表现出高性能。通过在单个固态膜上的不同纳米孔上专门沉积 MIPs 和导电水凝胶，实现了 100 ms/ 3 μm 的高时空分辨率的多重检测。实现了使用不同逻辑门进行计算和边缘计算。

Conclusion: 该纳米孔平台为混合固态纳米孔提供了一种全新的方法，能够进行实时无标记多重检测、受控生物分子释放和离子逻辑计算，解决了神经化学传感和生物计算中的关键挑战。

Abstract: In nanopore technology, the development of multiplexed detection and release
platforms with high spatial and temporal resolution remains a significant
challenge due to the difficulty in distinguishing signals originating from
different nanopores in a single chip. In this work, we present a solid-state
nanopore system functionalized with molecularly imprinted polymers (MIPs) for
the selective detection and controlled release of neurotransmitters. We
designed a nanopore array where each nanopore is functionalized with a specific
MIP able to recognize specific neurotransmitters (dopamine, gamma-aminobutyric
acid, and histamine, respectively). The platform demonstrated high performance
in terms of sensitivity, selectivity, recovery, and stability. Multiplexed
detection with high spatiotemporal resolution of the order of 100 ms/ 3 {\mu}m
was achieved by specifically depositing MIPs and conductive hydrogels on
different nanopores prepared on a single solid-state membrane. The employment
of micro-chambers for each nanopore prevented signal cross-talk, thereby
enabling simultaneous detection and release of multiple neurotransmitters.
Moreover, we demonstrated computing with different logic gates and in-edge
computing. This nanopore platform represents a radically novel approach towards
hybrid solid-state nanopores able to perform real-time label-free multiplex
detection, controlled biomolecule release, and ionic logic computing,
addressing key challenges in neurochemical sensing and bio-computation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [229] [VSS Challenge Problem: Verifying the Correctness of AllReduce Algorithms in the MPICH Implementation of MPI](https://arxiv.org/abs/2510.13413)
*Paul D. Hovland*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We describe a challenge problem for verification based on the MPICH
implementation of MPI. The MPICH implementation includes several algorithms for
allreduce, all of which should be functionally equivalent to reduce followed by
broadcast. We created standalone versions of three algorithms and verified two
of them using CIVL.

</details>


### [230] [Specification and Verification for Climate Modeling: Formalization Leading to Impactful Tooling](https://arxiv.org/abs/2510.13425)
*Alper Altuntas,Allison H. Baker,John Baugh,Ganesh Gopalakrishnan,Stephen F. Siegel*

Main category: cs.LO

TL;DR: ESM软件质量保证面临挑战，提出利用形式化方法进行验证，并通过CIVL模型检查器验证了海洋混合参数化方案的错误修复。 


<details>
  <summary>Details</summary>
Motivation: ESM模型复杂且多样化的计算平台带来软件质量保证的挑战，传统验证方法（如逐位可复现性、人工评估）存在局限性，形式化方法虽严谨但应用受限。

Method: 提出将形式化方法应用于ESM开发，并开发了特定领域的工具。通过CIVL模型检查器对海洋混合参数化方案的错误修复进行了形式化验证。

Result: 成功使用CIVL模型检查器验证了海洋混合参数化方案的错误修复。

Conclusion: 倡导在气候模型开发中更广泛地采用形式化方法，以增强模型可信度，支持更高效、更可靠的ESM开发。

Abstract: Earth System Models (ESMs) are critical for understanding past climates and
projecting future scenarios. However, the complexity of these models, which
include large code bases, a wide community of developers, and diverse
computational platforms, poses significant challenges for software quality
assurance. The increasing adoption of GPUs and heterogeneous architectures
further complicates verification efforts. Traditional verification methods
often rely on bitwise reproducibility, which is not always feasible,
particularly under new compilers or hardware. Manual expert evaluation, on the
other hand, is subjective and time-consuming. Formal methods offer a
mathematically rigorous alternative, yet their application in ESM development
has been limited due to the lack of climate model-specific representations and
tools. Here, we advocate for the broader adoption of formal methods in climate
modeling. In particular, we identify key aspects of ESMs that are well suited
to formal specification and introduce abstraction approaches for a tailored
framework. To demonstrate this approach, we present a case study using CIVL
model checker to formally verify a bug fix in an ocean mixing parameterization
scheme. Our goal is to develop accessible, domain-specific formal tools that
enhance model confidence and support more efficient and reliable ESM
development.

</details>


### [231] [Verification Challenges in Sparse Matrix Vector Multiplication in High Performance Computing: Part I](https://arxiv.org/abs/2510.13427)
*Junchao Zhang*

Main category: cs.LO

TL;DR: SpMV的顺序和MPI并行实现被提出，作为科学软件验证的挑战性问题。


<details>
  <summary>Details</summary>
Motivation: SpMV是科学代码中的基本核函数，需要提供一个挑战性问题供科学软件验证社区使用。

Method: 介绍PETSc库中SpMV的顺序和MPI并行实现。

Result: 提供了SpMV的顺序和MPI并行实现。

Conclusion: 提出的SpMV实现可作为科学软件验证的挑战性问题。

Abstract: Sparse matrix vector multiplication (SpMV) is a fundamental kernel in
scientific codes that rely on iterative solvers. In this first part of our
work, we present both a sequential and a basic MPI parallel implementations of
SpMV, aiming to provide a challenge problem for the scientific software
verification community. The implementations are described in the context of the
PETSc library.

</details>


### [232] [Verification Challenge: Fractional Cascading for Multi-Nuclide Grid Lookup](https://arxiv.org/abs/2510.13428)
*Andrew R. Siegel*

Main category: cs.LO

TL;DR: 本文提出了一个基于分数级联（FC）技术来加速跨多个已排序数组的重复查找的验证挑战，特别是在核截面查找的背景下。FC算法通过一次二分查找和常数时间查找来优化查找效率。


<details>
  <summary>Details</summary>
Motivation: 需要验证FC算法在核截面查找等场景下的正确性，并验证其结构属性，以替代低效的逐个二分查找。

Method: 通过与朴素的逐个二分查找方法进行对比，来验证FC算法的正确性，并分析其结构属性。

Result: FC算法通过一次二分查找和常数时间查找，显著降低了查找成本。

Conclusion: FC算法是一种有效优化重复查找的技术，适用于需要对多个已排序数组进行查找的场景，如核截面查找。

Abstract: We present a verification challenge based on the fractional cascading (FC)
technique for accelerating repeated searches across a collection of sorted
arrays. The specific context is nuclear cross section lookup in a simulation
code, where a material consists of many nuclides, each with its own sorted
energy grid. A naive search performs a binary search in each array
individually. The FC-based cascade grid structure reduces this cost by
performing a single binary search followed by constant-time refinements. The
challenge consists of verifying the correctness of the FC algorithm with
respect to the naive approach and validating its structural properties.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [233] [Altruistic Ride Sharing: A Community-Driven Approach to Short-Distance Mobility](https://arxiv.org/abs/2510.13227)
*Divyanshu Singh,Ashman Mehra,Snehanshu Saha,Santonu Sarkar*

Main category: cs.MA

TL;DR: 该论文提出了一种名为“利他共享出行”(ARS)的去中心化、点对点出行框架，通过引入“利他点”而非金钱激励来平衡司机和乘客角色，以解决城市交通拥堵和燃料消耗问题。


<details>
  <summary>Details</summary>
Motivation: 传统的出行平台以盈利为导向，忽视了公平性和可持续性，导致城市交通拥堵和燃料消耗等问题。

Method: ARS框架整合了多智能体深度强化学习（MADDPG）进行动态匹配，基于博弈论的均衡保证公平性，并利用群体模型维持长期平衡。

Result: 通过使用纽约市的真实出租车数据进行模拟，ARS相比不共享和基于优化的基线，显著减少了行驶距离和排放，提高了车辆利用率，并促进了公平参与。

Conclusion: ARS被证明是一种可扩展的、社区驱动的出行方式，能够将个人行为与城市可持续发展目标相结合，是传统共享出行模式的可行替代方案。

Abstract: Urban mobility faces persistent challenges of congestion and fuel
consumption, specifically when people choose a private, point-to-point commute
option. Profit-driven ride-sharing platforms prioritize revenue over fairness
and sustainability. This paper introduces Altruistic Ride-Sharing (ARS), a
decentralized, peer-to-peer mobility framework where participants alternate
between driver and rider roles based on altruism points rather than monetary
incentives. The system integrates multi-agent reinforcement learning (MADDPG)
for dynamic ride-matching, game-theoretic equilibrium guarantees for fairness,
and a population model to sustain long-term balance. Using real-world New York
City taxi data, we demonstrate that ARS reduces travel distance and emissions,
increases vehicle utilization, and promotes equitable participation compared to
both no-sharing and optimization-based baselines. These results establish ARS
as a scalable, community-driven alternative to conventional ride-sharing,
aligning individual behavior with collective urban sustainability goals.

</details>


### [234] [Semantic knowledge guides innovation and drives cultural evolution](https://arxiv.org/abs/2510.12837)
*Anil Yaman,Shen Tian,Björn Lindström*

Main category: cs.MA

TL;DR: 语义知识通过指导探索和与社会学习协同作用，促进了人类的累积性创新。


<details>
  <summary>Details</summary>
Motivation: 理解驱动人类社会代际间日益增长的知识和技术复杂性的认知过程，特别是创新是如何产生的。

Method: 结合使用基于智能体的文化演化模型和一项包含1243名参与者的大型行为实验，参与者需要将物品组合成新的创新。

Result: 在模拟和实验中，语义知识（概念与其功能之间的结构化关联）与社会学习协同作用，显著提高了创新能力。缺乏语义知识的参与者表现不佳，即使有社会学习的帮助，并且倾向于采用浅层探索策略。

Conclusion: 语义知识是人类累积文化能力的关键认知基础，它通过为探索提供认知支架来指导创新。

Abstract: Cumulative cultural evolution enables human societies to generate
increasingly complex knowledge and technology over generations. While social
learning transmits innovations between individuals and generations, the
cognitive processes that generate these innovations remain poorly understood.
Here, we demonstrate that semantic knowledge-structured associations between
concepts and their functions-provides cognitive scaffolding for cumulative
innovation by guiding exploration toward plausible and meaningful actions. We
tested this hypothesis using a cultural evolutionary agent-based model and a
large-scale behavioural experiment (N = 1,243), in which individuals performed
a task requiring the combination of items into novel innovations. Across both
approaches, semantic knowledge and social learning interact synergistically to
enhance innovation. Behaviorally, participants without access to semantic
knowledge performed no better than chance, even when social learning was
available, and relied on shallow exploration strategies. These findings suggest
that semantic knowledge is a key cognitive process enabling human cumulative
culture.

</details>


### [235] [KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems](https://arxiv.org/abs/2510.12872)
*Hancheng Ye,Zhengqi Gao,Mingyuan Ma,Qinsi Wang,Yuzhe Fu,Ming-Yu Chung,Yueqian Lin,Zhijian Liu,Jianyi Zhang,Danyang Zhuo,Yiran Chen*

Main category: cs.MA

TL;DR: 多智能体LLM系统常因跨智能体重复处理重叠上下文而产生显著的开销。KVCOMM框架通过重用KV缓存和对齐共享内容的缓存偏移来解决此问题，在不影响质量的情况下实现了高达7.8倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）系统在处理需要智能体间通信和协作的复杂任务时，常因重复处理重叠上下文而效率低下。虽然KV缓存可以提高单智能体场景的效率，但在多智能体场景中由于前缀的差异而无法直接复用。

Method: 提出KVCOMM框架，该框架通过引用“锚点”（存储观察到的缓存偏差）来估计和调整共享内容的KV缓存，从而对齐重叠上下文的缓存偏移。锚点池在线维护和更新，以适应不同的用户请求和上下文结构。

Result: KVCOMM在检索增强生成、数学推理和协作编码等多种多智能体工作负载中实现了超过70%的缓存重用率，且没有质量损失。在特定的五智能体设置下，KVCOMM实现了高达7.8倍的加速，将首次令牌生成时间（TTFT）从约430毫秒减少到约55毫秒。

Conclusion: KVCOMM是一个无需训练的框架，通过有效的KV缓存重用和对齐，显著提高了多智能体LLM推理的效率，解决了上下文重叠带来的计算开销问题。

Abstract: Multi-agent large language model (LLM) systems are increasingly adopted for
complex language processing tasks that require communication and coordination
among agents. However, these systems often suffer substantial overhead from
repeated reprocessing of overlapping contexts across agents. In typical
pipelines, once an agent receives a message from its predecessor, the full
context-including prior turns-must be reprocessed from scratch, leading to
inefficient processing. While key-value (KV) caching is an effective solution
for avoiding redundant computation in single-agent settings where prefixes
remain unchanged, it cannot be directly reused in multi-agent scenarios due to
diverging prefixes introduced by agent-specific context extensions. We identify
that the core challenge lies in the offset variance of KV-caches across agents.
To address this, we propose KVCOMM, a training-free framework that enables
efficient prefilling in multi-agent inference by reusing KV-caches and aligning
cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM
estimates and adjusts KV-caches for shared content by referencing a pool of
cached examples-termed anchors-that store observed cache deviations under
varying prefixes. The anchor pool is maintained and updated online, allowing
dynamic adaptation to distinct user requests and context structures. KVCOMM
achieves over 70% reuse rate across diverse multi-agent workloads, including
retrieval-augmented generation, math reasoning, and collaborative coding tasks,
all without quality degradation. Particularly, when each fully-connected agent
receives 1K input tokens with 512 prefix tokens and 512 output tokens under a
five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard
prefill pipeline, reducing TTFT from ~430 ms to ~55 ms.

</details>


### [236] [Agentic Discovery: Closing the Loop with Cooperative Agents](https://arxiv.org/abs/2510.13081)
*J. Gregory Pauloski,Kyle Chard,Ian T. Foster*

Main category: cs.MA

TL;DR: AI加速科学任务，但人类决策限制了发现速度，需要合作代理来促进自主发现。


<details>
  <summary>Details</summary>
Motivation: 数据驱动方法、人工智能和自动化工作流正在加速科学任务，但人类决策（如设定目标、提出假设和设计实验）正在限制发现的速率。

Method: 需要同时在人工智能和基础设施方面取得进展，以实现能够增强人类作用并实现自主发现的合作代理。

Result: 目前还没有具体结果，但文章指出了对合作代理的需求。

Conclusion: 合作代理是实现自主发现的关键，需要人工智能和基础设施的共同进步。

Abstract: As data-driven methods, artificial intelligence (AI), and automated workflows
accelerate scientific tasks, we see the rate of discovery increasingly limited
by human decision-making tasks such as setting objectives, generating
hypotheses, and designing experiments. We postulate that cooperative agents are
needed to augment the role of humans and enable autonomous discovery. Realizing
such agents will require progress in both AI and infrastructure.

</details>


### [237] [AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions](https://arxiv.org/abs/2510.13343)
*Shota Takayama,Katsuhide Fujita*

Main category: cs.MA

TL;DR: 该研究提出了一种名为AOAD-MAT的新型多智能体强化学习模型，该模型考虑了智能体决策的顺序，并在StarCraft和Multi-Agent MuJoCo基准测试中取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 MARL 模型（如 MAT 和 ACE）在利用顺序决策过程方面取得了显著进展，但并未明确考虑智能体决策顺序的重要性。

Method: 提出了一种名为AOAD-MAT的新型模型，该模型显式地将动作决策的顺序纳入学习过程，并利用基于 Transformer 的 actor-critic 架构动态调整智能体动作的顺序。该模型包含一个预测下一个行动智能体的子任务，并集成到基于近端策略优化 (PPO) 的损失函数中。

Result: 在 StarCraft Multi-Agent Challenge 和 Multi-Agent MuJoCo 基准测试中的广泛实验表明，AOAD-MAT 模型优于现有的 MAT 和其他基线模型。

Conclusion: 通过实验证明，调整 MARL 中的 AOAD 顺序可以有效提高模型性能。

Abstract: Multi-agent reinforcement learning focuses on training the behaviors of
multiple learning agents that coexist in a shared environment. Recently, MARL
models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep
Q-learning (ACE), have significantly improved performance by leveraging
sequential decision-making processes. Although these models can enhance
performance, they do not explicitly consider the importance of the order in
which agents make decisions. In this paper, we propose an Agent Order of Action
Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which
agents make decisions. The proposed model explicitly incorporates the sequence
of action decisions into the learning process, allowing the model to learn and
predict the optimal order of agent actions. The AOAD-MAT model leverages a
Transformer-based actor-critic architecture that dynamically adjusts the
sequence of agent actions. To achieve this, we introduce a novel MARL
architecture that cooperates with a subtask focused on predicting the next
agent to act, integrated into a Proximal Policy Optimization based loss
function to synergistically maximize the advantage of the sequential
decision-making. The proposed method was validated through extensive
experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo
benchmarks. The experimental results show that the proposed AOAD-MAT model
outperforms existing MAT and other baseline models, demonstrating the
effectiveness of adjusting the AOAD order in MARL.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [238] [Geometric Bound for Trade-off Relation in Quantum Tricycle](https://arxiv.org/abs/2510.12849)
*Shihao Xia,Jingyi Chen,Jincan Chen,Shanhe Su*

Main category: quant-ph

TL;DR: 本文研究了在外部驱动下，一个有限时间量子三循环的热力学性能，特别是在慢驱动条件下。通过对热量进行操作时间的微扰展开，我们能够超越准静态极限来模拟热交换过程。在几何框架下，我们推导出了冷却速率、性能系数和耗散之间权衡的基本限制，这些限制由热力学长度和控制空间中的轨迹几何决定。我们的研究揭示了量子热机性能的内在限制，并强调了几何在塑造有限时间热力学中的作用。这项工作增进了对量子热力学过程的基本理解，并为设计下一代量子技术提供了指导原则。


<details>
  <summary>Details</summary>
Motivation: 研究量子三循环在外部驱动下的热力学性能，尤其是在有限时间（慢驱动）条件下，以超越准静态极限，并揭示其性能的内在限制。

Method: 通过对热量进行操作时间的微扰展开来捕捉热交换过程的动力学。利用几何框架推导出冷却速率、性能系数和耗散之间权衡的基本限制，这些限制由热力学长度和控制空间中的轨迹几何决定。

Result: 发现了冷却速率、性能系数和耗散之间的权衡关系，并确定了其受热力学长度和控制空间中轨迹几何的制约。这些结果揭示了量子热力学性能的内在限制。

Conclusion: 量子三循环的有限时间热力学性能受其轨迹几何的制约，几何在有限时间热力学中扮演着重要角色，并为设计量子技术提供了指导原则。

Abstract: We establish a finite-time quantum tricycle driven by an external field and
investigate its thermodynamic performance in the slow-driving regime. By
developing a perturbative expansion of heat with respect to operation time, we
capture the dynamics of heat exchange processes beyond the quasistatic limit.
Within a geometric framework, we derive fundamental bounds on trade-offs
between the cooling rate, coefficient of performance, and dissipation, governed
by the thermodynamic length and trajectory geometry in control space. Our
findings unveil intrinsic limits to the performance of quantum thermal machines
and highlight the role of geometry in shaping finite-time thermodynamics. This
work advances the fundamental understanding of quantum thermodynamic processes
and offers guiding principles for the design of next-generation quantum
technologies.

</details>


### [239] [Performance Comparison of Gate-Based and Adiabatic Quantum Computing for Power Flow Analysis](https://arxiv.org/abs/2510.13378)
*Zeynab Kaseb,Matthias Moller,Peter Palensky,Pedro P. Vergara*

Main category: quant-ph

TL;DR: 本研究首次直接比较了门量子计算（GQC）和绝热量子计算（AQC）在求解交流潮流（PF）方程方面的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在为现代电力网络在嘈杂中等规模量子（NISQ）时代面临的计算挑战提供解决思路，并评估量子算法在潮流分析中的潜力。

Method: 将源于退火平台的绝热量子潮流（AQPF）算法改编为量子近似优化算法（QAOA），并将潮流方程重新构建为组合优化问题。

Result: 在4总线测试系统上进行了数值实验，评估了QAOA在求解精度和计算时间方面的表现，并与D-Wave的Advantage系统和富士通的最新一代数字退火器（QIIO）进行了基准测试。

Conclusion: 为GQC与AQC在PF分析中的性能权衡、可扩展性和实际可行性提供了量化见解。

Abstract: In this paper, we present the first direct comparison between gate-based
quantum computing (GQC) and adiabatic quantum computing (AQC) for solving the
AC power flow (PF) equations. Building on the Adiabatic Quantum Power Flow
(AQPF) algorithm originally designed for annealing platforms, we adapt it to
the Quantum Approximate Optimization Algorithm (QAOA). The PF equations are
reformulated as a combinatorial optimization problem. Numerical experiments on
a 4-bus test system assess solution accuracy and computational time. Results
from QAOA are benchmarked against those obtained using D-Wave's Advantage
system and Fujitsu's latest generation Digital Annealer, i.e., Quantum-Inspired
Integrated Optimization software (QIIO). The findings provide quantitative
insights into the performance trade-offs, scalability, and practical viability
of GQC versus AQC paradigms for PF analysis, highlighting the potential of
quantum algorithms to address the computational challenges associated with
modern electricity networks in the Noisy Intermediate-Scale Quantum (NISQ).

</details>


### [240] [Tunable quantum Mpemba effect in long-range interacting systems](https://arxiv.org/abs/2510.12875)
*Andrew Hallam,Matthew Yusuf,Aashish A. Clerk,Ivar Martin,Zlatko Papić*

Main category: quant-ph

TL;DR: 量子Mpemba效应（QME）是一种在非平衡系统中，初始条件离平衡越远，系统越容易达到热平衡的现象。该效应在具有幂律衰减相互作用的1D XYZ自旋链中，在强磁场产生的预热区中，由于U(1)对称性的出现而得以展现。然而，由于Hohenberg-Mermin-Wagner定理的限制，QME的出现依赖于相互作用的短程性。本文研究了磁场、相互作用范围和动力学对称性恢复之间的相互作用，并分析了QME对有效温度的依赖性，为在囚禁离子、极性分子和NV中心等实验平台中探测QME提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究量子Mpemba效应（QME）在具有长程相互作用的1D XYZ自旋链中的行为，并探究其与动力学对称性恢复、磁场强度和相互作用范围之间的关系。

Method: 通过研究具有幂律衰减相互作用的1D XYZ自旋链在强磁场下的行为，分析其动力学对称性恢复过程，并考察QME的出现与磁场、相互作用范围以及有效温度之间的关系。

Result: 在强磁场下，1D XYZ自旋链系统可以产生一个预热区，并出现连续的U(1)对称性，从而使得QME得以发生。QME的出现受到相互作用范围的限制，并且与有效温度有关。通过调控长程相互作用，可以调控QME的发生。

Conclusion: QME的发生与动力学对称性恢复密切相关，并且可以通过调控相互作用的长短程性来调控。该研究结果为在囚禁离子、极性分子和NV中心等实验平台中实现和探测QME提供了理论指导。

Abstract: Symmetry plays a fundamental role in many-body systems, both in and out of
equilibrium. The quantum Mpemba effect (QME) - a phenomenon where systems
initially farther from equilibrium can thermalize faster - can be understood in
terms of how rapidly a symmetry, broken by initial conditions, is dynamically
restored. In this work, we study the QME in a one-dimensional spin-1/2 XYZ
model with power-law decaying interactions in the presence of a magnetic field.
In the prethermal regime generated by large field strengths, the system
develops a continuous U(1) symmetry, enabling the QME to emerge. However, due
to the Hohenberg-Mermin-Wagner theorem, the QME can only arise when
interactions are sufficiently short-ranged. This leads to an interplay between
the external field, interaction range, and dynamical symmetry restoration. We
systematically explore this interplay and analyze the dependence of the QME on
the effective temperature set by the initial state. Our results demonstrate the
tunability of the QME via long-range interactions, which can be probed in
experimental platforms of trapped ions, polar molecules, and NV centers.

</details>


### [241] [Censorship of quantum resources against catalytic account sharing](https://arxiv.org/abs/2510.12876)
*Julien Pinske,Klaus Mølmer*

Main category: quant-ph

TL;DR: 该论文提出了一种新的量子通信审查协议，即使无法完美擦除量子资源，只要用户无法恢复原始量子态，审查就被认为是成功的。研究了审查的安全条件，并解决了量子网络中的账户共享问题。


<details>
  <summary>Details</summary>
Motivation: 量子通信审查协议，旨在解决现实审查中可能存在的量子资源恢复或蒸馏问题。

Method: 提出不要求完美擦除量子资源的审查协议，并研究在何种条件下审查是安全的，以及何时可能失败。同时，解决了量子网络中账户共享的问题。

Result: 确定了审查成功的条件，并研究了账户共享对审查安全性的影响。

Conclusion: 量子审查协议提供了一种新颖的量子网络安全视角，与现有的量子密码学和后量子密码学方法有根本区别。

Abstract: In quantum censorship, an agency oversees quantum communication in a
public-domain network. The agency restricts the users communication to the free
states of a quantum resource theory (QRT). Despite quantum correlations being
fragile, any realistic censorship leaves behind some quantumness, raising
concerns that censorship may be overcome through revival or distillation of
quantum resources. Here, we introduce censorship protocols that do not require
a perfect erasure of a quantum resource, but rather deem censorship successful
if users are unable to restore the original quantum state using free
operations. We investigate under which conditions censorship is secure, and
when it might fail. Moreover, we address the issue of account sharing in
quantum networks, wherein independent parties assist in transmitting quantum
resources to censored users. This connects resource censorship to timely topics
such as quantum catalysis and resource-assisted communication. Censorship
protocols offer a novel perspective on quantum network security, that differs
fundamentally from existing approaches such as quantum and post-quantum
cryptography.

</details>


### [242] [Statistical phase-space complexity of continuous-variable quantum channels](https://arxiv.org/abs/2510.12878)
*Siting Tang,Francesco Albarelli,Yue Zhang,Shunlong Luo,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 研究了量子态的统计复杂性，并将其应用于研究单模玻色子量子通道的复杂性。


<details>
  <summary>Details</summary>
Motivation: 利用量子态的复杂性量词来研究单模玻色子量子通道的复杂性。

Method: 将量子通道的复杂性定义为从初始状态产生最大复杂性的能力。

Result: 计算了高斯通道和一些非高斯通道的复杂性。

Conclusion: 提出了量子通道复杂性的概念，并通过具体实例进行了说明。

Abstract: The statistical complexity of continuous-variable quantum states can be
characterized with a quantifier defined in terms of information-theoretic
quantities derived from the Husimi Q-function. In this work, we utilize this
complexity quantifier of quantum states to study the complexity of single-mode
bosonic quantum channels. We define the complexity of quantum channels as the
maximal amount of complexity they can generate from an initial state with the
minimal complexity. We illustrate this concept by evaluating the complexity of
Gaussian channels and some examples of non-Gaussian channels.

</details>


### [243] [Can outcome communication explain Bell nonlocality?](https://arxiv.org/abs/2510.12886)
*Carlos Vieira,Carlos de Gois,Pedro Lauand,Lucas E. A. Porto,Sébastien Designolle,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: 贝尔非局域性可以用局部隐变量模型结合经典通信来解释，但当通信仅限于测量结果时，对于所有投影测量，这是不可能的，除非该状态本身就没有贝尔非局域性。然而，在某些受限的测量条件下，结果通信可以提供优势。


<details>
  <summary>Details</summary>
Motivation: 研究是否允许仅限于测量结果的通信的局部隐变量模型能够解释贝尔非局域性现象。

Method: 证明了对于所有投影测量，仅限于测量结果的通信的局部隐变量模型无法解释量子比特-量子比特状态的贝尔非局域性，除非该状态本身就不具有贝尔非局域性。同时，研究了在受限测量条件下结果通信的优势。

Result: 证明了量子比特-qudit状态在投影测量下，如果存在允许结果通信的局部隐变量模型，则必然存在不允许通信的局部隐变量模型。并且，在某些受限测量条件下，结果通信确实提供了优势。

Conclusion: 结果通信在解释贝尔非局域性方面的能力受到限制，并且与经典通信和确定性测量的性质密切相关。

Abstract: A central aspect of quantum information is that correlations between
spacelike separated observers sharing entangled states cannot be reproduced by
local hidden variable (LHV) models, a phenomenon known as Bell nonlocality. If
one wishes to explain such correlations by classical means, a natural
possibility is to allow communication between the parties. In particular, LHV
models augmented with two bits of classical communication can explain the
correlations of any two-qubit state. Would this still hold if communication is
restricted to measurement outcomes? While in certain scenarios with a finite
number of inputs the answer is yes, we prove that if a model must reproduce all
projective measurements, then for any qubit-qudit state the answer is no. In
fact, a qubit-qudit under projective measurements admits an LHV model with
outcome communication if and only if it already admits an LHV model without
communication. On the other hand, we also show that when restricted sets of
measurements are considered (for instance, when the qubit measurements are in
the upper hemisphere of the Bloch ball), outcome communication does offer an
advantage. This exemplifies that trivial properties in standard LHV scenarios,
such as deterministic measurements and outcome-relabelling, play a crucial role
in the outcome communication scenario.

</details>


### [244] [Many-body post-processing of density functional calculations using the variational quantum eigensolver for Bader charge analysis](https://arxiv.org/abs/2510.12887)
*Erik Schultheis,Alexander Rehn,Gabriel Breuil*

Main category: quant-ph

TL;DR: 使用变分量子本征求解器计算包含强关联系统的周期性系统的Bader电荷，并公开了名为Dopyqo的计算框架。


<details>
  <summary>Details</summary>
Motivation: 估算材料的性质对于评估其工业应用至关重要，需要研究弱和强关联系统的电荷分布。

Method: 通过求解多体哈密顿量来计算Bader电荷，其中哈密顿量是根据先前的DFT计算获得的Kohn-Sham轨道计算得出的。变分量子本征求解器用于求解多体哈密顿量。

Result: 在掺杂的MgH2超胞上验证了该方法的准确性，并表明与标准DFT相比，该方法显著改善了强关联过渡金属氧化物的Bader电荷值，并以DFT+U结果为参考。

Conclusion: 所提出的计算框架Dopyqo可用于计算包含强关联系统的周期性系统的Bader电荷，并已作为软件包公开提供。

Abstract: Quantum chemistry and condensed matter physics are among the most promising
applications of quantum computers. Further, estimating properties of a material
is crucial to evaluate its industrial applications. To investigate charge
distributions of weakly and strongly correlated systems we calculate Bader
charges for various periodic systems by solving many-body Hamiltonians using
the variational quantum eigensolver. The Hamiltonians are computed from
Kohn-Sham orbitals obtained from a prior DFT calculation. We first demonstrate
the accuracy of our method on various doped MgH2 supercells. Further, we show
that our approach, compared to standard DFT, significantly improves the Bader
charge values for strongly correlated transition metal oxides, where we take
DFT+U results as a reference. The computational framework behind our many-body
calculations, called Dopyqo, is made openly available as a software package.

</details>


### [245] [Probing non-Markovian qubit noise and modeling Post Markovian Master Equation](https://arxiv.org/abs/2510.12894)
*Chun-Tse Li,Jingming Tan,Vasil Gucev*

Main category: quant-ph

TL;DR: 量子处理器中的噪声特性对于实现容错量子计算至关重要，但传统方法常采用马尔可夫近似，无法完全捕捉现实动力学。本研究利用后马尔可夫主方程（PMME）形式分析了噪声动力学中的记忆效应，并通过在IBM量子设备上的超导量子比特实验进行了验证，清晰地展示了非马尔可夫行为。此外，研究还量化了串扰效应，并发现串扰在当前量子硬件中可能成为主要的非马尔可夫效应。


<details>
  <summary>Details</summary>
Motivation: 理解量子处理器中的噪声特性，特别是考虑非马尔可夫效应，对于实现容错量子计算是必不可少的。

Method: 采用后马尔可夫主方程（PMME）形式来表征噪声动力学中的记忆效应，并利用IBM量子设备上的超导量子比特进行实验验证。

Result: 实验证明了量子比特的噪声动力学表现出明显的非马尔可夫行为，并且通过信息论方法量化了串扰效应，发现串扰是当前量子硬件中主要的非马尔可夫效应。

Conclusion: 后马尔可夫主方程（PMME）是分析量子处理器噪声动力学中记忆效应的有效工具，而串扰效应是影响量子计算性能的关键因素，需要得到更多关注。

Abstract: Understanding the noise characteristics of quantum processors is crucial when
achieving fault-tolerant quantum computing. However, typical qubit designs are
often studied under the Markovian approximation, which does not fully capture
realistic dynamics. Factors such as qubit-qubit coupling and extended bath
correlation times can introduce significant non-Markovian effects into the
noise processes. In this study, we employ the Post-Markovian Master Equation
(PMME) formalism to characterize memory effects in the noise dynamics. We
further experimentally validate the PMME framework using superconducting qubits
on an IBM Quantum device, demonstrating clear non-Markovian behavior during
circuit execution. Additionally, we quantify the crosstalk effect using an
information-theoretic approach and reveal that crosstalk can dominate the
observed non-Markovian effects in current quantum hardware.

</details>


### [246] [Quantum Key Distribution in the Iberian Peninsula](https://arxiv.org/abs/2510.12951)
*Vicky Domínguez Tubío,Mario Badás Aldecocea,David L. Bakker,Gustavo C. Amaral,Diego López,Johannes Borregaard*

Main category: quant-ph

TL;DR: 提出并评估了一个覆盖伊比利亚半岛的基于卫星的量子密钥分发（QKD）方案，连接马德里、巴塞罗那、毕尔巴鄂和里斯本，并优化了光束腰以提高传输概率和密钥生成率。


<details>
  <summary>Details</summary>
Motivation: 光学纤维的量子密钥分发（QKD）网络存在损耗问题，而基于卫星的量子通信为长距离安全密钥交换提供了可扩展的解决方案。

Method: 提出并评估了一个基于卫星的QKD方案，使用配备自发参量下转换（SPDC）源的低地球轨道（LEO）卫星向地面站分发纠缠光子对。优化了光束腰以提高传输概率和密钥生成率。

Result: 所提出的方案可以实现足以满足实际应用（如混合经典-量子协议下的医院间安全通信）的密钥生成率，证明了近期基于卫星的QKD网络在国家范围内的安全通信的可行性。

Conclusion: 近期基于卫星的QKD网络在国家范围内的安全通信方面具有可行性。

Abstract: A promising use of quantum networking is quantum key distribution (QKD),
which can provide information-theoretic security unattainable by classical
means. While optical fiber-based QKD networks suffer from exponential loss,
satellite-assisted quantum communication offers a scalable solution for
long-distance secure key exchange. In this work, we propose and evaluate a
satellite-based QKD setup covering the Iberian Peninsula, linking Madrid with
Barcelona, Bilbao, and Lisbon. Our proposed setup uses a Low-Earth-Orbit (LEO)
state-of-the-art satellite equipped with a spontaneous parametric
down-conversion (SPDC) source to distribute entangled photon pairs to ground
stations. Considering vibrations in the satellite, we optimize the beam waist
to enhance the transmission probability and improve the secret key rate (SKR).
Our results show that key rates sufficient for real-world applications, such as
secure communication between hospitals, using hybrid classical-quantum
protocols are feasible with existing protocols. Our results highlight the
viability of near-term satellite-based QKD networks for national-scale secure
communications.

</details>


### [247] [Simulation-Free Fidelity Estimation via Quantum Output Order Statistics](https://arxiv.org/abs/2510.13026)
*Tobias Micklitz*

Main category: quant-ph

TL;DR: 提出了一种基于测量输出概率的顺序统计的无模拟保真度估计方法，适用于大规模量子电路。


<details>
  <summary>Details</summary>
Motivation: 为了在不进行模拟的情况下估算大规模量子电路的保真度，并克服现有方法（如交叉熵基准测试）的成本和难度。

Method: 利用高纠缠、混沌态的测量输出概率的顺序统计，特别是最高概率输出位串，并结合对哈尔随机量子态顺序统计的解析结果。通过分析这些统计数据在去偏噪声下的变化，提出了一种可扩展的保真度估计器。

Result: 提出的保真度估计器在谷歌的12量子比特Sycamore实验中得到了验证，并通过数值模拟得到支持。证明了该方法对于中等规模量子电路的实用性。

Conclusion: 该方法为大规模量子电路的保真度评估提供了一种高效且可扩展的解决方案，特别适用于交叉熵基准测试成本高昂或直接保真度估计困难的场景。

Abstract: We introduce a simulation-free method to estimate the fidelity of large
quantum circuits based on the order statistics of measured output probabilities
from highly entangled, chaotic states. The approach requires only the
highest-probability output bitstrings -- the most frequently observed
measurement outcomes -- and builds on exact analytical results for the order
statistics of Haar-random quantum states derived here. Analyzing their
modification under depolarizing noise, we propose a scalable fidelity
estimator, validated on Google's 12-qubit Sycamore experiment and further
supported by numerical simulations. We demonstrate its practicality for
intermediate-scale quantum circuits, where cross-entropy benchmarking is costly
and direct fidelity estimation is difficult.

</details>


### [248] [Blind-spots of Randomized Benchmarking Under Temporal Correlations](https://arxiv.org/abs/2510.13051)
*Varun Srivastava,Abhinash Kumar Roy,Soumik Mahanti,Jasleen Kaur,Salini Karuvade,Alexei Gilchrist*

Main category: quant-ph

TL;DR: 该研究推导了在存在时间相关噪声（包括来自量子环境的噪声）的情况下，平均序列保真度（ASF）的解析表达式，并探讨了其在量子硬件基准测试中的应用。


<details>
  <summary>Details</summary>
Motivation: 标准随机基准测试（RB）协议假设噪声是时间不相关的，这在实际量子硬件中往往不成立。本研究旨在解决这一局限性，研究时间相关噪声对RB协议的影响。

Method: 推导了在存在时间相关噪声（包括经典记忆和量子环境）的情况下，平均序列保真度（ASF）的解析表达式，并分析了如何从中提取有意义的基准测试参数。此外，还确定了使时间相关性对RB不可见的相互作用哈密顿量类别，并提出了通过RB实验证明量子记忆引起的时间相关性的操作标准。

Result: 研究表明，ASF可以用来提取有意义的基准测试参数，并识别出不会被RB检测到的特定相互作用哈密顿量。研究还发现了可能抑制最坏情况误差的时间相关性，表明时间相关性并不总是对门保真度产生负面影响。

Conclusion: 本研究提出了在存在时间相关噪声的情况下分析量子硬件性能的新方法，并对RB协议的适用性和局限性进行了更深入的理解，特别是在考虑最坏情况误差时。

Abstract: Randomized benchmarking (RB) is a widely adopted protocol for estimating the
average gate fidelity in quantum hardware. However, its standard formulation
relies on the assumption of temporally uncorrelated noise, an assumption often
violated in current devices. In this work, we derive analytic expressions for
the average sequence fidelity (ASF) in the presence of temporally correlated
(non-Markovian) noise with classical memory, including cases where such
correlations originate from interactions with a quantum environment. We show
how the ASF can be interpreted to extract meaningful benchmarking parameters
under such noise and identify classes of interaction Hamiltonians that render
temporal correlations completely invisible to RB. We further provide
operational criteria for witnessing temporal correlations due to quantum memory
through RB experiments. Importantly, while classical correlations may remain
undetectable in the ASF data, they can nonetheless significantly affect
worst-case errors quantified by the diamond norm, a metric central to fault
tolerant quantum computing. In particular, we demonstrate that temporal
correlations may suppress worst-case errors highlighting that temporal
correlations may not always have detrimental effects on gate performance.

</details>


### [249] [Optimal key rates for quantum key distribution with partial source characterization](https://arxiv.org/abs/2510.13085)
*Margarida Pereira,Guillermo Currás-Lorenzo,Mateus Araújo*

Main category: quant-ph

TL;DR: 本研究将基于圆锥优化的数值安全证明扩展到部分了解发射状态的场景，并证明其在实际的源不完美情况下优于现有方法，尤其是在使用非量子比特编码的协议中。


<details>
  <summary>Details</summary>
Motivation: 现有的基于圆锥优化的数值安全证明虽然能提供最优的密钥率，但通常假设发射状态是完全已知的，这在实际应用中不现实，因为真实设备存在难以详细建模的缺陷和侧信道。

Method: 将圆锥优化的方法扩展到仅了解部分发射状态信息的场景，涵盖了制备-测量和测量设备无关的协议。

Result: 在实际源不完美的情况下，本研究提出的方法优于最先进的分析和数值方法，尤其对于使用非量子比特编码的协议效果更佳。

Conclusion: 本研究提出的方法将基于数值的证明向前推进，使其成为一个标准的、可用于实际部署的框架，用于在存在源不完美的情况下评估量子密钥分发协议。

Abstract: Numerical security proofs based on conic optimization are known to deliver
optimal secret-key rates, but so far they have mostly assumed that the emitted
states are fully characterized. In practice, this assumption is unrealistic,
since real devices inevitably suffer from imperfections and side channels that
are extremely difficult to model in detail. Here, we extend conic-optimization
methods to scenarios where only partial information about the emitted states is
known, covering both prepare-and-measure and measurement-device-independent
protocols. We demonstrate that our method outperforms state-of-the-art
analytical and numerical approaches under realistic source imperfections,
especially for protocols that use non-qubit encodings. These results advance
numerical-based proofs towards a standard, implementation-ready framework for
evaluating quantum key distribution protocols in the presence of source
imperfections.

</details>


### [250] [Spin Readout in a 22 nm Node Integrated Circuit](https://arxiv.org/abs/2510.13674)
*Isobel C. Clarke,Virginia Ciriano-Tejel,David J. Ibberson,Grayson M. Noah,Thomas H. Swift,Mark A. I. Johnson,Ross C. C. Leon,Alberto Gomez-Saiz,John J. L. Morton,M. Fernando Gonzalez-Zalba*

Main category: quant-ph

TL;DR: 本文展示了在22nm全耗尽硅上绝缘CMOS技术下，在集成电路中实现了量子点自旋的单次读出，这是实现高度可扩展和集成自旋量子比特的关键一步。


<details>
  <summary>Details</summary>
Motivation: 为了实现能够广泛应用的大规模量子计算机，需要将数百万个物理量子比特与经典电子器件进行大规模集成。虽然之前已有将量子点与CMOS控制和读出电子器件集成在不同芯片上的技术，但将控制电子器件和自旋量子比特置于同一制造平台和同一集成电路中是未来的一个重要方向。

Method: 利用22nm全耗尽硅上绝缘CMOS技术制造集成电路，其中包含量子点和读出电子器件。通过逐步提高能量选择性测量来实现自旋到电荷的转换，并使用射频单电子晶体管进行检测。量子点通过片上低温电子器件进行寻址。

Result: 在集成的量子点器件中实现了超过90%的读出可见度和毫秒级的自旋弛豫时间，并且在两个相同的器件中均观察到了可重复的结果。

Conclusion: 在CMOS工艺中成功实现量子点自旋的单次读出，是实现高度可扩展和集成自旋量子比特的关键一步。

Abstract: Constructing a quantum computer capable of broad and important applications
is likely to require millions of addressable physical qubits, posing the
challenge of large-scale integration of quantum systems with classical
electronics. Fully depleted silicon-on-insulator CMOS technology has been used
to develop a range of cryogenic electronic components for the control and
readout of different qubit modalities interfaced on separate chips. However,
recent measurements of quantum dots on this technology raise the tantalising
prospect of realising control electronics and spin qubits on the same
manufacturing platform, within a single integrated circuit (IC). Here, we
demonstrate single-shot spin readout in addressable quantum dot devices within
an IC fabricated using industry-standard 22 nm fully depleted
silicon-on-insulator technology. We achieve spin-to-charge conversion via a
ramped energy-selective measurement, detected using a radio-frequency
single-electron transistor and addressed by on-chip cryogenic electronics. The
observation of consistent readout visibilities exceeding 90% and millisecond
spin relaxation times in two nominally identical devices within the addressable
array supports the reproducibility of the unit cell. The successful observation
of spin readout using this CMOS process marks a key step towards realising
highly scalable and integrated spin qubits.

</details>


### [251] [Software-enhanced simultaneous quantum-classical communication protocol with Gaussian post-selection](https://arxiv.org/abs/2510.13138)
*Ozlem Erkilic,Biveen Shajilal,Nicholas Zaunders,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 通过引入高斯后选择，优化了连续变量量子密钥分发（CV-QKD）的调制方差，提高了在有损耗和噪声信道下的密钥生成速率和传输距离。


<details>
  <summary>Details</summary>
Motivation: 现有SQCC协议在优化调制方差时基于固定信道假设，导致在动态变化的信道（如自由空间链路）中性能下降，密钥生成速率低且传输距离受限。

Method: 在SQCC框架中引入高斯后选择，允许在信道估计后通过软件优化调制方差，这是一种无需硬件修改的被动式优化方法。

Result: 该方法在理想和有限数据规模下均能提升密钥生成速率，即使考虑接收端不完美因素，仍能有效提升SQCC在光纤和自由空间信道下的传输距离和鲁棒性。在卫星对地场景中，能实现全通信窗口，并在恶劣天气下保持更高的工作周期。

Conclusion: 基于后选择的SQCC协议易于实现，能显著提高SQCC在现实世界中，包括陆地光纤网络和基于卫星的自由空间链路的量子通信的性能和实用性。

Abstract: Simultaneous quantum-classical communication (SQCC) protocols offer a
practical approach to continuous-variable quantum key distribution (CV-QKD) by
encoding quantum and classical signals onto the same optical pulse. However,
like most QKD protocols, their performance is limited when experimental
parameters, such as modulation variance, are optimised based on stationary
channel assumptions. In fluctuating environments, such as free-space links,
this can result in sub-optimal key rates and reduced transmission distances. In
this work, we introduce Gaussian post-selection into the SQCC framework,
enabling a software-based optimisation of the modulation variance after channel
estimation. This passive approach enhances key rates in both asymptotic and
finite-size regimes without requiring hardware modifications and remains
effective even when receiver imperfections are taken into account. We
demonstrate that our protocol significantly improves the transmission distance
and robustness of SQCC across both fibre and free-space channels. In
particular, we show that the protocol enables full communication windows under
ideal weather conditions and maintains higher duty cycles during adverse
weather in satellite-to-ground scenarios. These results highlight the
practicality of post-selection based SQCC for real-world quantum communication
over both terrestrial fiber networks and satellite-based free-space links.

</details>


### [252] [Quantum Dynamics, Master Equation and Equilibrium for a Qubit Coupled to a Thermal Boson Field](https://arxiv.org/abs/2510.13142)
*Hiromichi Nakazato,Saverio Pascazio*

Main category: quant-ph

TL;DR: We derived the exact master equation for a two-level quantum system interacting with a bosonic environment in a thermal state, and analyzed its long-time behavior and thermal equilibrium conditions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to analytically derive the exact master equation for a two-level quantum system interacting with a bosonic environment and analyze its long-time behavior and thermal equilibrium conditions.

Method: The method involves analytically deriving the exact master equation for a two-level quantum system (qubit) interacting with a bosonic environment within the rotating-wave approximation, assuming the environment is initially in an arbitrary thermal state. The long-time behavior of the evolution operator is analyzed, and conditions for the system to approach thermal equilibrium are examined.

Result: The result is the analytical derivation of the exact master equation for the system and the analysis of its long-time behavior and conditions for reaching thermal equilibrium.

Conclusion: The paper concludes by analyzing the conditions under which the two-level quantum system approaches thermal equilibrium when interacting with a bosonic environment in an arbitrary thermal state.

Abstract: We analytically derive the exact -- though formal -- master equation for a
two-level quantum system (qubit) interacting with a bosonic environment within
the rotating-wave approximation, assuming the environment is initially in an
arbitrary thermal state. The long-time behavior of the evolution operator
governing the dynamics of both the system and the environment is analyzed, and
the conditions under which the system approaches thermal equilibrium are
examined.

</details>


### [253] [Autler-Townes spectroscopy of a Rydberg ladder](https://arxiv.org/abs/2510.13150)
*Tai Xiang,Yue-Hui Lu,Jacquelyn Ho,Tsai-Chen Lee,Zhenjie Yan,Dan M. Stamper-Kurn*

Main category: quant-ph

TL;DR: 本研究提出了一种新的双光子光谱特征——双光子Autler-Townes共振，用于替代EIT在反转波长方案中检测里德堡态跃迁，该特征具有更高的信噪比，并可用于稳定激光频率。


<details>
  <summary>Details</summary>
Motivation: 在反转波长方案中，利用电磁感应透明（EIT）检测里德堡态跃迁时，多普勒展宽介质会严重削弱低能级激光的EIT信号。因此，需要寻找一种新的光谱特征来替代EIT。

Method: 提出并观察了一种新的双光子光谱特征——双光子Autler-Townes共振，该共振作用于高能级激光。通过实验测量了该特征的信噪比，并将其与EIT信号进行了比较。同时，研究了利用该特征生成误差信号以稳定激光频率的方法。

Result: 双光子Autler-Townes共振特征的信噪比优于EIT信号，能够分辨高达n=80的里德堡共振。该特征还可以生成误差信号，用于稳定高能级激光的频率。

Conclusion: 双光子Autler-Townes共振是一种在反转波长方案中检测里德堡态跃迁的有效替代方法，相比EIT具有更好的信噪比，并可用于激光频率稳定。

Abstract: Ladder-type two-photon excitation of an atom from a ground state $|g\rangle$,
to an intermediate excited state $|e\rangle$, and, finally, to a Rydberg state
$|r\rangle$, has a variety of uses from quantum information to sensing. A
common scheme for detecting this transition optically is through
electromagnetically induced transparency (EIT). However, in inverted wavelength
schemes, where the ground-to-excited transition wavelength is shorter than the
excited-to-Rydberg transition wavelength, the strength of the EIT feature on
the lower-leg beam is strongly reduced in a Doppler-broadened medium. Here, we
report on an alternative two-photon spectroscopic feature, which we term the
two-photon Autler-Townes resonance, observed on the upper-leg beam. Compared to
the EIT signal, this feature's superior signal-to-noise ratio allows one to
resolve Rydberg resonances with principal quantum number as high as $n=80$. We
also show that such a feature can be utilized to generate an error signal for
stabilizing the frequency of the upper-leg beam.

</details>


### [254] [Observation of Nonlinear Spin Dynamics in Dual-Cell Atomic Gases](https://arxiv.org/abs/2510.13218)
*Xiaofan Wang,Haitao Lu,Hengyan Wang,Zhihuang Luo,Wenqiang Zheng*

Main category: quant-ph

TL;DR: Experimental observation of nonlinear spin dynamics in alkali-metal atomic gases with dual-bias magnetic fields, showing limit cycles, quasi-periodic orbits, and chaos, with potential applications in spin masers and precision measurement.


<details>
  <summary>Details</summary>
Motivation: Recent theoretical work predicted intriguing nonlinear dynamical phases in spin systems due to inhomogeneous magnetic fields and feedback, but experimental exploration was lacking.

Method: Observed nonlinear spin dynamics in dual-bias magnetic fields with dual-cell alkali-metal atomic gases, presenting three stable dynamical behaviors (limit cycles, quasi-periodic orbits, and chaos). Probed nonlinear phase transitions by varying feedback gain and magnetic field difference. Demonstrated robustness against magnetic field noise.

Result: Three representative stable dynamical behaviors (limit cycles, quasi-periodic orbits, and chaos) were observed. Nonlinear phase transitions were probed and demonstrated. Limit cycle and quasi-periodic orbit showed robustness against magnetic field noise.

Conclusion: Established a versatile platform for exploring complex spin dynamics and opened new avenues for realizing multimode spin masers, time crystals, quasi-crystals, and high-precision magnetometers.

Abstract: Nonlinear spin systems exhibit rich and exotic dynamical phenomena, offering
promising applications ranging from spin masers and time crystals to precision
measurement. Recent theoretical work [T. Wang et al., Commun. Phys. 8, 41
(2025)] predicted intriguing nonlinear dynamical phases arising from
inhomogeneous magnetic fields and feedback interactions. However, experimental
exploration of these predictions remains lacking. Here, we report the
observation of nonlinear spin dynamics in dual-bias magnetic fields with
dual-cell alkali-metal atomic gases and present three representative stable
dynamical behaviors of limit cycles, quasi-periodic orbits, and chaos.
Additionally, we probe the nonlinear phase transitions between these phases by
varying the feedback gain and the difference of dual-bias magnetic fields.
Furthermore, we demonstrate the robustness of the limit cycle and
quasi-periodic orbit against the noise of magnetic fields. Our findings
establish a versatile platform for exploring complex spin dynamics and open new
avenues for the realization of multimode spin masers, time crystals and
quasi-crystals, and high-precision magnetometers.

</details>


### [255] [Agency cannot be a purely quantum phenomenon](https://arxiv.org/abs/2510.13247)
*Emily C. Adlam,Kelvin J. McQueen,Mordecai Waegell*

Main category: quant-ph

TL;DR: 纯粹的量子系统无法满足代理的基本条件，因为量子系统的“不可克隆定理”和“线性动力学”限制了其创建世界模型、评估行动后果和执行最大化效用行动的能力。因此，代理需要大量的经典资源，并且量子计算机无法直接模拟代理行为。


<details>
  <summary>Details</summary>
Motivation: 研究纯粹的量子系统是否能满足代理的基本条件，包括创建世界模型、评估行动后果和执行最大化效用行动。

Method: 分析了量子系统在满足代理条件时所面临的“不可克隆定理”和“线性动力学”的限制，并讨论了近似克隆策略的局限性。

Result: 纯粹的量子系统无法满足代理的三个基本条件。创建世界模型和评估行动后果与“不可克隆定理”相冲突，而执行最大化效用行动则因“线性动力学”而失败。结论是代理需要大量的经典资源，并且量子计算机无法直接模拟代理行为。

Conclusion: 代理需要大量的经典资源，这为代理的物理基础提供了明确的限制。这些结果有助于理解经典代理如何在量子宇宙中出现，并对量子代理、自由意志和意识的理论提出了挑战。

Abstract: What are the physical requirements for agency? We investigate whether a
purely quantum system (one evolving unitarily in a coherent regime without
decoherence or collapse) can satisfy three minimal conditions for agency: an
agent must be able to create a world-model, use it to evaluate the likely
consequences of alternative actions, and reliably perform the action that
maximizes expected utility. We show that the first two conditions conflict with
the no-cloning theorem, which forbids copying unknown quantum states:
world-model construction requires copying information from the environment, and
deliberation requires copying the world-model to assess multiple actions.
Approximate cloning strategies do not permit sufficient fidelity or generality
for agency to be viable in purely quantum systems. The third agency condition
also fails due to the linearity of quantum dynamics. These results imply four
key consequences. First, agency requires significant classical resources,
placing clear constraints on its physical basis. Second, they provide insight
into how classical agents emerge within a quantum universe. Third, they show
that quantum computers cannot straightforwardly simulate agential behavior
without significant classical components. Finally, they challenge quantum
theories of agency, free will, and consciousness.

</details>


### [256] [Equivalence of Genuine Multipartite Entanglement and Nonlocality of Nearly Symmetric Multiqubit Pure States](https://arxiv.org/abs/2510.13296)
*Jakub Wójcik,Wojciech Bruzda,Ignacy Stachura,Remigiusz Augusiak*

Main category: quant-ph

TL;DR: 并非所有纯粹的真正多方纠缠（GME）状态都必然表现出真正的多方非局域性（GMNL），但高度对称的GME状态表现出GMNL。


<details>
  <summary>Details</summary>
Motivation: 是否所有纯粹的真正多方纠缠（GME）状态都必然表现出真正的多方非局域性（GMNL）仍然是一个悬而未决的问题。

Method: 将最近提出的贝尔不等式与Hardy悖论和纯态的正则分解相结合。

Result: 所有高度对称的、真正纠缠的多方量子比特态都表现出真正的多方非局域性。

Conclusion: 该结果朝着GME和GMNL在量子理论中预期等价性的普遍证明迈出了重要一步。

Abstract: Whether every pure genuinely multipartite entangled (GME) state necessarily
exhibits genuine multipartite nonlocality (GMNL) remains an open question. By
combining a recently proposed Bell inequality [I. Stachura \textit{et al.},
\href{https://iopscience.iop.org/article/10.1088/1367-2630/ad7753}{New J. Phys.
\textbf{26}, 093029 (2024)}] with Hardy's paradox and the canonical
decomposition of pure states, we analytically demonstrate that all highly
symmetric, genuinely entangled multipartite qubit states exhibit genuine
multipartite nonlocality, thereby supporting Gisin's conjecture in the
multipartite setting. This result constitutes a step toward a general proof of
the conjectured equivalence between GME and GMNL in quantum theory.

</details>


### [257] [Hybrid Boson Sampling-Neural Network Architecture for Enhanced Classification](https://arxiv.org/abs/2510.13332)
*Mohammad Sharifian,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 通过结合玻色采样和神经网络，开发了一种量子核方法，用于增强支持向量机分类，并在四个数据集上展示了优于经典核的性能。


<details>
  <summary>Details</summary>
Motivation: 实现量子优势以用于经典机器学习任务，同时克服实际数据集高维度和近期量子计算机性能有限的挑战。

Method: 开发一种混合框架，将玻色采样的计算能力与神经网络的适应性相结合，以构建增强支持向量机分类的量子核。神经网络自适应地将数据特征压缩到可编程的玻色采样电路上，生成跨越高维希尔伯特空间的量子态，从而提高分类性能。

Result: 在四个不同类别的数据集上，所提出的模型表现优于经典的线性核和 sigmoid 核。

Conclusion: 基于玻色采样的量子核在实际的量子增强机器学习方面具有应用潜力。

Abstract: Demonstration of quantum advantage for classical machine learning tasks
remains a central goal for quantum technologies and artificial intelligence.
Two major bottlenecks to this goal are the high dimensionality of practical
datasets and limited performance of near-term quantum computers. Boson sampling
is among the few models with experimentally verified quantum advantage, yet it
lacks practical applications. Here, we develop a hybrid framework that combines
the computational power of boson sampling with the adaptability of neural
networks to construct quantum kernels that enhance support vector machine
classification. The neural network adaptively compresses the data features onto
a programmable boson sampling circuit, producing quantum states that span a
high-dimensional Hilbert space and enable improved classification performance.
Using four datasets with various classes, we demonstrate that our model
outperforms classical linear and sigmoid kernels. These results highlight the
potential of boson sampling-based quantum kernels for practical
quantum-enhanced machine learning.

</details>


### [258] [Homodyne Measurement of a Non-Hermitian Qubit Undergoing Fluorescence](https://arxiv.org/abs/2510.13345)
*Roson Nongthombam,Amarendra K. Sarma*

Main category: quant-ph

TL;DR: 通过对三能级系统进行后选择，实现了一个两能级非厄米量子比特，该量子比特表现出PT对称性。通过连续同源测量分析了后选择引入的衰减与测量反冲之间的相互作用，并提出了描述后选择的非厄米量子比特的无跃迁随机微分方程，证明了其平均动力学在远离卓越点时与更新后的后选择演化一致，但在靠近卓越点时存在偏差，这归因于测量反冲和非厄米衰减的相互作用。此外，还确定了非厄米量子比特的最佳路径。


<details>
  <summary>Details</summary>
Motivation: 研究后选择引入的衰减与测量反冲之间的相互作用，以及它们如何影响非厄米量子比特的动力学行为，尤其是在卓越点附近的动力学。

Method: 对非厄米量子比特进行连续同源测量，并与Liouvillian平均进行比较。推导了描述后选择的非厄米量子比特的无跃迁随机微分方程。在路径积分框架下，通过极值化作用量来确定最佳路径。

Result: 所提出的无跃迁随机微分方程在远离卓越点时，其平均动力学与更新后的后选择演化一致。靠近卓越点时，偏差程度取决于驱动的性质。证实了测量反冲和非厄米衰减的相互作用是导致偏差的原因。

Conclusion: 测量反冲和非厄米动力学共同影响开放量子系统的瞬态行为，并可用于控制卓越点附近的量子比特。

Abstract: Implementation of a two-level non-Hermitian qubit via postselection of a
three-level system has been demonstrated. The postselection procedure, which
discards quantum jump to the ground-state manifold while retaining excitations
in the first and second excited-state manifolds, effectively generates a
non-Hermitian qubit exhibiting PT symmetry. In this work, we perform continuous
homodyne mea- surement of this non-Hermitian qubit and analyze the interplay
between decay introduced by posts- election and measurement backaction. We
compare the ensemble-averaged dynamics obtained from measurement trajectories
with the the Liouvillian average. We formulate the no-jump stochastic
differential equation describing the postselected non-Hermitian qubit and show
that its ensemble- averaged dynamics agree with those of the jump-updated
postselected evolution at drive strengths far from the Liouvillian exceptional
point (EP). The degree of deviation near the EP depends sensitively on the
nature of the drive. This discrepancy is attributed to the interplay between
measurement backaction and the non-Hermitian decay introduced by postselection.
Furthermore, we determine the optimal path of the non-Hermitian qubit by
extremizing the action within the path-integral formulation of the quantum
trajectory framework Our results provide insights into how measurement
backaction and non-Hermitian dynamics together shape the transient behavior of
open quantum systems and enable controlled manipulation of qubits near
exceptional points.

</details>


### [259] [Quantum Approximate Optimization Algorithm for Maximum Likelihood Detection in Massive MIMO](https://arxiv.org/abs/2510.13350)
*Yuxiang Liu,Fanxu Meng,Zetong Li,Xutao Yu,Zaichen Zhang*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子近似优化算法（QAOA）的最大似然检测方法，用于解决大规模MIMO系统中NP难的最大似转检测问题。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中最大似然检测问题随着天线数量和符号数量的增加而变得复杂，而QAOA是一种有潜力的量子算法，可以用于近似解决组合优化问题。

Method: 提出了一种基于QAOA的最大似然检测方法，包括推导了1-层QAOA的期望值解析表达式，并采用贝叶斯优化进行参数初始化以加速收敛并提高找到精确解的概率。

Result: 与现有的基于QAOA的最大似然检测算法相比，该方法具有更通用、更紧凑的期望值表达式，需要更少的量子资源，并且获得精确解的概率更高。

Conclusion: 该研究提出的QAOA最大似然检测方法在解决大规模MIMO系统中的检测问题上，展现出更高的效率和准确性。

Abstract: In the massive multiple-input and multiple-output (Massive MIMO) systems, the
maximum likelihood (ML) detection problem is NP-hard and becoming classically
intricate with the number of the transmitting antennas and the symbols
increasing. The quantum approximate optimization algorithm (QAOA), a leading
candidate algorithm running in the noisy intermediate-scale quantum (NISQ)
devices, can show quantum advantage for approximately solving combinatorial
optimization problems. In this paper, we propose the QAOA based the maximum
likelihood detection solver of binary symbols. In proposed scheme, we first
conduct a universal and compact analytical expression for the expectation value
of the 1-level QAOA. Second, a bayesian optimization based parameters
initialization is presented, which can speedup the convergence of the QAOA to a
lower local minimum and improve the probability of measuring the exact
solution. Compared to the state-of-the-art QAOA based ML detection algorithm,
our scheme have the more universal and compact expectation value expression of
the 1-level QAOA, and requires few quantum resources and has the higher
probability to obtain the exact solution.

</details>


### [260] [Efficient lambda-enhanced gray molasses using an EIT-based laser locking scheme](https://arxiv.org/abs/2510.13360)
*Timothy Leese,Siobhan Patrick,Silvia Bergamini,Calum MacCormick*

Main category: quant-ph

TL;DR: 提出了一种新颖的lambda增强的灰糖浆冷却的实现方法，该方法采用非标准光束几何结构和廉价的激光锁定装置。


<details>
  <summary>Details</summary>
Motivation: 传统的冷却方法需要资源密集型相位锁定技术，而本研究旨在通过使用两个独立的、锁定到电磁感应透明（EIT）共振产生的谱特征上的激光器，来简化和降低实验设置的复杂性和成本。

Method: 采用非标准光束几何结构和两个独立但锁定到EIT共振的激光器来实现lambda增强的灰糖浆冷却，无需昂贵的GHz电子设备。

Result: 该方法成功实现了有效的灰糖浆冷却，证明了该方法的可行性，并显著降低了实验设置的复杂性和成本。

Conclusion: 本研究提出的方法为实现更易于使用的冷原子技术迈出了重要一步，同时波函数蒙特卡罗分析也为该非常规方案的冷却动力学提供了见解。

Abstract: We present a novel implementation of lambda-enhanced gray molasses cooling in
a non-standard beam geometry and with an inexpensive laser locking set-up. In
contrast to the established use of resource-intensive phase locking methods,
our laser system uses two independent lasers, frequency -locked to a spectral
feature produced by an electromagnetically induced transparency (EIT)
resonance. We show that this approach achieves sufficient coherence to enable
effective gray molasses cooling without the need for costly GHz electronics,
significantly reducing the complexity and cost of experimental setups and
represents a step toward more accessible cold atom technologies. A
wave-function Monte Carlo analysis supports the experimental findings, offering
insight into the cooling dynamics of this unconventional scheme

</details>


### [261] [An Industry-Academia Partnership for Advancing Quantum Frontiers: Perspective from the U.S. Center for Quantum Technologies](https://arxiv.org/abs/2510.13365)
*David Stewart,Gerardo Ortiz,Peter M. Kogge,Ricardo S. Decca,Tongcang Li*

Main category: quant-ph

TL;DR: CQT是一个由普渡大学、印第安纳大学和圣母大学组成的联盟，旨在通过学术研究与产业和政府合作，加速量子技术的创新。


<details>
  <summary>Details</summary>
Motivation: 该联盟旨在整合学术研究与产业和政府的合作，以加速量子技术的创新。

Method: 该联盟整合了学术研究、产业合作和政府合作，通过协同开发、转化影响和人才培养来塑造量子技术。

Result: CQT在加速量子创新、推动量子技术发展和培养量子领域人才方面发挥着重要作用。

Conclusion: CQT致力于通过协同开发、转化影响和人才培养来塑造量子技术产业的未来。

Abstract: The U.S. Center for Quantum Technologies (CQT) is a multi-university
consortium established under the National Science Foundation's (NSF)
Industry-University Cooperative Research Centers (IUCRC) program. Led jointly
by Purdue University, Indiana University (both Bloomington and Indianapolis
campuses), and the University of Notre Dame, CQT integrates academic research
with industrial and governmental collaboration to accelerate quantum
innovation. This perspective outlines the consortium's strategic mission,
interdisciplinary research agenda, and its role in shaping the future of
quantum-enabled technologies through collaborative development, translational
impact, and workforce cultivation.

</details>


### [262] [Quantum teleportation, entanglement, LQU and LQFI in $e^{+}e^{-} \to \text{Y}\bar{\text{Y}}$ processes at BESIII through noisy channels](https://arxiv.org/abs/2510.13402)
*Elhabib Jaloum,Mohamed Amazioug*

Main category: quant-ph

TL;DR: 该研究在BESIII实验中，使用实验可行的参数，通过嘈杂的信道，在e+e- -> Y Y过程中，分析了LN、LQU和LQFI作为量子相关性的度量，并实现了不同超子-反超子对的最佳保真度。研究结果表明，量子噪声并不总是破坏性的，保真度在所有三种信道中都保持在经典极限之上。


<details>
  <summary>Details</summary>
Motivation: 在量子信息处理中，量子隐形传态引起了广泛关注，它允许将一个量子态从一个粒子转移到另一个粒子。本研究的动机是在存在噪声信道的情况下，在e+e- -> Y Y过程中，分析量子相关性（如LN、LQU和LQFI）和量子隐形传态的保真度。

Method: 研究者们分析了LN、LQU和LQFI作为量子相关性的度量，并研究了它们在e+e- -> Y Y过程中，在嘈杂信道（包括失相干效应、幅度阻尼、相位阻尼和相位翻转）下的行为。此外，他们还实现了不同超子-反超子对（ΛΛ̄、Ξ⁰Ξ̄⁰、Ξ⁻Ξ̄⁺、Σ⁺Σ̄⁻）的量子隐形传态，并讨论了噪声信道对保真度和量子相关性的影响。

Result: 研究表明，在没有失相干效应的情况下，LN、LQU和LQFI在φ=±π时消失，并在φ=π/2时对称。幅度阻尼和相位阻尼导致LN、LQU和LQFI随着退相干参数s的增加而减小，而相位翻转信道表现出围绕s=1/2的对称行为。此外，在所有三种信道中，即使噪声增加，保真度也保持在2/3的经典极限之上。

Conclusion: 研究结果表明，量子噪声并不总是破坏性的，并且在存在噪声的情况下，量子隐形传态仍然可以保持高保真度。这在量子信息和粒子物理学中有潜在的应用。

Abstract: Quantum teleportation, a protocol that has received extensive and intensive
attention in quantum information processing, allows a quantum state to be
transferred from one particle to another. In this study, we analytically
investigate fidelity ($F$), logarithmic negativity (LN), local quantum
uncertainty (LQU) and local quantum Fisher information (LQFI) as a discord-like
measure of quantum correlations in $e^{+}e^{-} \to \text{Y}\bar{\text{Y}}$
processes at BESIII through noisy channels, using experimental feasible
parameters, where $\text{Y}$ and $\bar{\text{Y}}$ refer to the spin-$1/2$
hyperon and its antihyperon, respectively. Without a dephasing effect, we show
that, LN, LQU, and LQFI vanish at $\varphi=\pm\pi$ and are symmetric around
$\varphi=\pi/2$. We also explore the LN, LQU, and LQFI for different
$\text{Y}\bar{\text{Y}}$ pairs subjected to three distinct types of decoherence
channels. Specifically, we show that amplitude damping (AD) and phase damping
(PD) lead to a decrease in LN, LQU, and LQFI with an increasing decoherence
parameter $s$. In contrast, the phase flip (PF) channel exhibits symmetric
behavior around $s=1/2$. Besides, we realize for teleportation, optimal
fidelity for different hyperon-antihyperon pairs ($ \Lambda\bar{\Lambda}$,
$\Xi^{0}\bar{\Xi^{0}}$, $\Xi^{-}\bar{\Xi^{+}}$, $\Sigma^{+}\bar{\Sigma^{-}}$).
We discuss the influence of noisy channels, specifically (AD, PF and PD), on
the fidelity of quantum teleportation and on quantum correlations that can
exist even beyond entanglement. Furthermore, the results show that the fidelity
remains above the classical limit of $2/3$ in all three channels, even as the
noise increases. This is a significant finding because it shows that not all
quantum noise is detrimental. These results can have promising applications in
quantum information and particle physics.

</details>


### [263] [Towards Quantum Enhanced Adversarial Robustness with Rydberg Reservoir Learnin](https://arxiv.org/abs/2510.13473)
*Shehbaz Tariq,Muhammad Talha,Symeon Chatzinotas,Hyundong Shin*

Main category: quant-ph

TL;DR: 量子水库计算（QRC）利用量子多体系统固有的高维非线性动力学来提取时空模式，只需很少的训练。本研究首次系统地评估了基于QRC的学习模型的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管QRC具有量子编码的表达能力，但最近的研究表明基于变分电路的量子分类器容易受到对抗性扰动的影响。

Method: 研究人员使用一个由强相互作用的里德堡原子组成的量子水库，并用一个多层感知机（MLP）作为可训练的读出层。他们使用MNIST、Fashion-MNIST和Kuzushiji-MNIST数据集来评估在白盒对抗攻击下，用MLP增强量子水库的鲁棒性。

Result: 该混合方法在所有测试的扰动强度下，其准确性显著高于纯粹的经典模型。

Conclusion: 与纯粹的经典模型相比，这种混合方法在所有测试的扰动强度下都显示出显著更高的准确性，揭示了新的量子优势来源。

Abstract: Quantum reservoir computing (QRC) leverages the high-dimensional, nonlinear
dynamics inherent in quantum many-body systems for extracting spatiotemporal
patterns in sequential and time-series data with minimal training overhead.
Although QRC inherits the expressive capabilities associated with quantum
encodings, recent studies indicate that quantum classifiers based on
variational circuits remain susceptible to adversarial perturbations. In this
perspective, we investigate the first systematic evaluation of adversarial
robustness in a QRC based learning model. Our reservoir comprises an array of
strongly interacting Rydberg atoms governed by a fixed Hamiltonian, which
naturally evolves under complex quantum dynamics, producing high-dimensional
embeddings. A lightweight multilayer perceptron serves as the trainable readout
layer. We utilize the balanced datasets, namely MNIST, Fashion-MNIST, and
Kuzushiji-MNIST, as a benchmark for rigorously evaluating the impact of
augmenting the quantum reservoir with a Multilayer perceptron (MLP) in
white-box adversarial attacks to assess its robustness. We demonstrate that
this approach yields significantly higher accuracy than purely classical models
across all perturbation strengths tested. This hybrid approach reveals a new
source of quantum advantage and

</details>


### [264] [Quantum thermal diode with additional control by auxiliary atomic states](https://arxiv.org/abs/2510.13489)
*Qin Zhang,Zi-chen Zhang,Yi-jia Yang,Zheng Liu,Chang-shui Yu*

Main category: quant-ph

TL;DR: 研究一种由两个双原子两能级原子耦合到辅助双原子两能级原子组成的量子热二极管，发现辅助原子的激发态可以减弱热流并增强整流效应，而基态辅助原子可以增强热流并减弱整流效应。辅助原子的数量和状态（激发态、基态或叠加态）对热流和整流效应有显著影响，为控制热流提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 研究量子热二极管，探索如何通过辅助原子的状态来控制热流方向性和整流效应。

Method: 研究一个由两个两能级原子耦合到辅助两能级原子的量子系统，分析不同辅助原子状态（激发态、基态、叠加态）对热流和整流效应的影响。

Result: 辅助原子的激发态减弱热流并增强整流效应；基态辅助原子增强热流并减弱整流效应。耦合的辅助原子越多，影响越强。叠加态原子中，只有投影到激发态的部分起显著作用。通过设计耦合，可以消除整流效应。

Conclusion: 辅助原子的状态可以用来有效地控制量子热二极管的热流和整流性能，为设计可调热设备提供了可能性。

Abstract: A quantum thermal diode, similar to an electronic diode, allows for
unidirectional heat transmission. In this paper, we study a quantum thermal
diode composed of two two-level atoms coupled to auxiliary two-level atoms. We
find that the excited auxiliary atoms can weaken heat current and enhance the
rectification effect, but the ground-state auxiliary atoms can enhance heat
current and weaken the rectification effect. The more auxiliary atoms are
coupled, the stronger the enhancing or weakening impact is. If the auxiliary
atom is in a superposition state, we find that only the fraction that projects
onto the excited state plays a significant role. In particular, if we properly
design the coupling of the auxiliary atoms, the rectification effect can be
eliminated. This provides the potential to control the heat current and the
rectification performance by the states of the auxiliary atoms.

</details>


### [265] [Cryo-CMOS Antenna for Wireless Communications within a Quantum Computer Cryostat](https://arxiv.org/abs/2510.13627)
*Viviana Centritto,Ama Bandara,Heqi Deng,Masoud Babaie,Evgenii Vinogradov,Sergi Abadal,Eduard Alarcon*

Main category: quant-ph

TL;DR: 利用低温兼容的片上天线实现量子计算机内部的短距离无线通信，以克服现有有线连接的瓶颈，从而提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有量子计算机架构的可扩展性受限于密集布线带来的空间限制、功耗和延迟问题。

Method: 提出并仿真了一个在4K温度下工作的28GHz的低温兼容的片上差分偶极天线，并考虑了温度相关的材料特性以及在实际低温恒温器结构中的嵌入式评估。

Result: 天线在自由空间和低温恒温器内的反射系数值分别为-20.8 dB和-18.38 dB，表明其具有良好的阻抗匹配和在低温环境下有效运行的可行性。

Conclusion: 该研究提出的低温兼容片上天线为解决量子计算机内部互联瓶颈提供了一种有前景的无线通信解决方案，有助于实现量子计算机的可扩展性。

Abstract: Scaling quantum computers from a few qubits to large numbers remains one of
the critical challenges in realizing practical quantum advantage. Multi-core
quantum architectures have emerged as a promising solution, enabling
scalability through distributed quantum processing units (QPUs) interconnected
via classical and quantum links. However, the bottleneck of wired connections
persists, as densely packed wired interconnects, both vertically across
temperature stages and horizontally within the same layer, introduce spatial
constraints, power dissipation, and latency, which could hinder performance as
the number of QPUs increases. To overcome these limitations, this work proposes
a cryo-compatible on-chip differential dipole antenna operating at 28 GHz to
enable short-range wireless communication within a quantum computer cryostat.
Temperature-dependent material properties are incorporated to accurately
capture antenna behavior at 4 K. Moreover, by embedding the antenna in a
realistic cryostat structure, we evaluate the feasibility of antenna operation
within the cryogenic environment. The proposed antenna achieves a reflection
coefficient of -20.8 dB in free space and -18.38 dB within the cryostat,
demonstrating efficient impedance matching.

</details>


### [266] [Lattice surgery with Bell measurements: Modular fault-tolerant quantum computation at low entanglement cost](https://arxiv.org/abs/2510.13541)
*Trond Hjerpekjøn Haug,Timo Hillmann,Anton Frisk Kockum,Raphaël Van Laer*

Main category: quant-ph

TL;DR: 模块化量子计算通过使用贝尔测量进行晶格手术来提高效率和噪声抑制能力。


<details>
  <summary>Details</summary>
Motivation: 在扩展量子计算机以实现容错的过程中，模块化架构至关重要。然而，模块间的纠缠在速率和保真度上具有挑战性，因此需要高效的量子链接协议来限制接口处的噪声。

Method: 提出了一种基于表面码的晶格手术协议，其中所有非局部操作都是贝尔测量。该协议同时限制了链路噪声，并且只需要先前提出协议的一半模块交叉门。为了减轻距离缩短的钩子错误，提出了一种在综合测量的轮次之间交替门序列的策略。

Result: 在模拟的去极化噪声下，当两个逻辑量子比特在不同模块中制备成逻辑贝尔态时，与性能最佳的替代协议相比，该协议在给定的模块间纠缠速率下具有更强的逻辑错误抑制能力，通常在恒定的逻辑错误率下可节省 40% 的纠缠资源。

Conclusion: 所提出的协议设计方法适用于任何必须跨处理器模块划分的量子电路，为表面码以外的资源高效模块化量子计算开发提供了指导。

Abstract: Modular architectures are a promising approach to scaling quantum computers
to fault tolerance. Small, low-noise quantum processors connected through
relatively noisy quantum links are capable of fault-tolerant operation as long
as the noise can be confined to the interface. Finding protocols that implement
the quantum links between modules as efficiently as possible is essential
because inter-module entanglement is challenging to produce at a similar rate
and fidelity as local entanglement. We introduce a protocol for lattice surgery
on surface codes in which all non-local operations are Bell measurements. The
protocol simultaneously confines the link noise and requires only half as many
module-crossing gates as previously proposed protocols. To mitigate
distance-reducing hook errors, we introduce a strategy of alternating the gate
sequence between rounds of syndrome measurement, which prevents multiple hooks
from simultaneously aligning with a logical operator in the code. We evaluate
our protocol's performance when two logical qubits on separate modules are
prepared in a logical Bell state. Circuit-level simulations under depolarizing
noise show that the logical error suppression for a given entanglement rate
between modules is consistently stronger compared to the best-performing
alternative protocols for a wide range of link noise, with a typical 40%
entanglement resource saving for a constant logical error rate. Our approach to
protocol design is applicable to any quantum circuit that must be divided
across processor modules and can therefore guide development of
resource-efficient modular quantum computation beyond the surface code.

</details>


### [267] [State-Specific Orbital Optimization for Enhanced Excited-States Calculation on Quantum Computers](https://arxiv.org/abs/2510.13544)
*Guorui Zhu,Joel Bierman,Jianfeng Lu,Yingzhou Li*

Main category: quant-ph

TL;DR: 我们提出了一种状态特定的轨道优化方案，用于提高近地量子计算机电子结构哈密顿量激发态的准确性，该方案可与任何基于重叠的激发态量子特征求解器结合使用。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子计算机上电子结构哈密顿量激发态的准确性。

Method: 推导了不同轨道产生的不同状态之间的重叠项关于轨道旋转矩阵的梯度，并使用基于梯度的优化方法来优化轨道。

Result: 与状态平均轨道优化方案相比，在H4和LiH等多种分子上实现了更高的精度。

Conclusion: 我们提出的状态特定的轨道优化方案可以提高激发态计算的准确性。

Abstract: We propose a state-specific orbital optimization scheme for improving the
accuracy of excited states of the electronic structure Hamiltonian for the use
on near-term quantum computers, which can be combined with any overlap-based
excited-state quantum eigensolver. We derived the gradient of the overlap term
between different states generated by different orbitals with respect to the
orbital rotation matrix and use the gradient-based optimization methods to
optimize the orbitals. This scheme allows for more flexibility in the choice of
orbitals. We implement the state-specific orbital optimization scheme with the
variational quantum deflation (VQD) algorithm, and show that it achieves higher
accuracy than the state-averaged orbital optimization scheme on various
molecules including H4 and LiH.

</details>


### [268] [Exact dynamics and qubit inversion of non-Hermitian driven two-level systems](https://arxiv.org/abs/2510.13550)
*Ivan A. Bocanegra-Garay,Luis M. Nieto*

Main category: quant-ph

TL;DR: 本文证明了一个广义非厄米驱动双能级系统的超对称结构，通过酉旋转简化哈密顿量，并进行谱分析得到复数时间依赖性驱动函数，从而实现对量子比特态的有效控制，为核磁共振和增益损耗材料光学实验提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探究广义非厄米驱动双能级系统的超对称结构，并利用其特性设计有效的量子比特态控制方法。

Method: 通过酉旋转变换哈密顿量，解耦微分方程，并对辅助平稳薛定谔方程进行谱分析，获得复数时间依赖性驱动函数。

Result: 成功展示了系统的超对称结构，并获得了能够以有趣方式产生量子比特态跃迁的复数时间依赖性驱动函数。

Conclusion: 所提出的方法和结果可用于设计和进行核磁共振或增益损耗材料光学实验。

Abstract: The supersymmetric structure of a generalized non-Hermitian driven two-level
system is demonstrated. A unitary rotation turns the Hamiltonian into a more
convenient form. After decoupling a set of differential equations, the
supersymmetric structure of the problem can be unequivocally ap- appreciated.
Performing a spectral analysis of an auxiliary stationary Schr\"odinger-like
equation, complex time-dependent driving functions are obtained for which the
corresponding (time-dependent) Schr\"odinger equation can be straightforwardly
solved. Such complex drivings are seen to produce transitions in the qubit
state in different, however interesting, manners. We believe that the results
reported here will be of interest for designing and carrying out various
experiments in laboratories specializing in nuclear magnetic resonance or in
optics with gain and loss materials.

</details>


### [269] [Non-Clifford Fusion: T-Gate Optimization for Quantum Simulation](https://arxiv.org/abs/2510.13573)
*Yingheng Li,Xulong Tang,Paul Hovland,Ji Liu*

Main category: quant-ph

TL;DR: NCF是一个新的量子编译框架，通过对Pauli字符串分组和共轭，可以显著减少汉密尔顿模拟中的T门数量和深度，实验结果显示平均减少了57.4%的T门数量和49.1%的T门深度。


<details>
  <summary>Details</summary>
Motivation: 汉密尔顿模拟是量子计算中的一个关键应用，但其在容错量子计算机上的实现对T门数量和深度有很高要求。现有的方法在优化这两个指标方面存在局限性。

Method: NCF框架通过将Pauli字符串分组，并对每组进行共轭变换，使得量子门操作限制在较少的量子比特上。这使得可以同时合成整个组的门，从而减少T门数量和深度。NCF还优化了Clifford门的数量。

Result: 与现有最优方法相比，NCF在T门数量上平均减少了57.4%，T门深度上平均减少了49.1%，Clifford门数量上平均减少了49.0%。

Conclusion: NCF是一个有效的量子编译框架，能够显著减少汉密尔顿模拟的资源消耗，为实现更大规模的量子模拟提供了可能。

Abstract: Hamiltonian simulation is a key quantum algorithm for modeling complex
systems. To implement a Hamiltonian simulation, it is typically decomposed into
a list of Pauli strings, each corresponds to an RZ rotation gate with many
Clifford gates. These RZ gates are generally synthesized into a sequence of
Clifford and T gates in fault-tolerant quantum computers, where the T-gate
count and T-gate depth are critical metrics for such systems. In this paper, we
propose NCF, a compilation framework that reduces both the T-gate count and
T-gate depth for Hamiltonian simulation. NCF partitions Pauli strings into
groups, where each group can be conjugated (i.e., transformed) into a list of
Pauli strings that apply quantum gates on a restricted subset of qubits,
allowing for simultaneous synthesis of the whole group and reducing both T-gate
count and depth. Experimental results demonstrate that NCF achieves an average
reduction of 57.4%, 49.1%, and 49.0% in T-gate count, T-gate depth, and
Clifford count, respectively, compared to the state-of-the-art method.

</details>


### [270] [Emergent Discrete Time Crystals on Digital Quantum Computers: Boundary-Protected and Ancilla-Induced Disorder Mechanisms of Thermalization Slowdown](https://arxiv.org/abs/2510.13577)
*Kazuya Shinjo,Kazuhiro Seki,Seiji Yunoki*

Main category: quant-ph

TL;DR: 研究人员在IBM量子处理器上实现了周期性驱动的伊辛模型，并在Kagome和Lieb格点上发现了两种由噪声引起的离散时间晶体（DTC）。


<details>
  <summary>Details</summary>
Motivation: 周期性驱动系统通常会达到热平衡，但在此之前可能出现暂时的前热状态，其中可能存在新奇的非平衡现象，如离散时间晶体（DTC）。本研究旨在探索周期性驱动的乘积态在踢伊辛模型中的弛豫动力学，特别关注噪声对DTC形成的影响。

Method: 利用辅助量子比特构建了具有重六角连通性的超导量子比特Kagome和Lieb格点。通过在IBM量子Eagle和Heron处理器上实现该模型，并结合噪声模拟，研究了不同类型的DTC及其在不同噪声环境下的行为。

Result: 在IBM量子Eagle处理器上，观察到了两种DTC（I型和II型），分别对应于有无电荷泵浦辅助量子比特的情况。在噪声较低的Heron处理器上，周期加倍的振荡仅限于边界区域。这些实验结果与考虑了辅助量子比特噪声的噪声矩阵乘积态模拟结果一致。

Conclusion: 研究表明，辅助量子比特中的量子噪声可以产生新型的前热动力学相，包括边界保护和噪声诱发的DTC。这为理解和利用量子噪声在量子多体动力学中的作用提供了新的视角。

Abstract: Periodically driven (Floquet) systems typically evolve toward an
infinite-temperature thermal state due to continuous energy absorption. Before
reaching equilibrium, however, they can transiently exhibit long-lived
prethermal states that host exotic nonequilibrium phenomena, such as discrete
time crystals (DTCs). In this study, we investigate the relaxation dynamics of
periodically driven product states in a kicked Ising model implemented on the
IBM Quantum Eagle and Heron processors. By using ancilla qubits to mediate
interactions, we construct Kagome and Lieb lattices on superconducting qubits
with heavy-hex connectivity. We identify two distinct types of noise-induced
DTCs on Kagome and Lieb lattices, both arising from quantum noise in ancilla
qubits. Type-I DTCs originate from robust boundary-mode period-doubling
oscillations, stabilized by symmetry charge pumping, that are redistributed
into the bulk due to ancilla noise. Type-II DTCs, in contrast, emerge in
systems without charge-pumped qubits, where quantum noise unexpectedly
stabilizes period-doubling oscillations that would otherwise rapidly decay. On
the noisier Eagle device (ibm_kyiv), we observe both type-I and type-II DTCs on
53-qubit Kagome lattices with and without charge-pumped qubits, respectively.
In contrast, on the lower-noise Heron device (ibm_marrakesh), period-doubling
oscillations are confined to boundary-localized oscillations on 82-qubit Kagome
and 40-qubit Lieb lattices, as redistribution into the bulk is suppressed.
These experimental findings are supported by noisy matrix-product-state
simulations, in which ancilla noise is modeled as random sign flips in the
two-qubit gate rotation angles. Our results demonstrate that quantum noise in
ancilla qubits can give rise to novel classes of prethermal dynamical phases,
including boundary-protected and noise-induced DTCs.

</details>


### [271] [Yang-Lee edge singularity and quantum criticality in non-Hermitian PXP model](https://arxiv.org/abs/2510.13581)
*Wen-Yi Zhang,Meng-Yun Mao,Qing-Min Hu,Xinzhi Zhao,Gaoyong Sun,Wen-Long You*

Main category: quant-ph

TL;DR: 该研究提出了一个关于非厄米失谐PXP模型的量子临界性的理论框架，并确定了完整的相图。


<details>
  <summary>Details</summary>
Motivation: 在之前的研究中，非厄米失谐PXP模型的量子临界性及其相图尚未被完全揭示。

Method: 通过相似变换在实能量区构建了二阶相变边界，并引入了双正交纠缠熵和双正交洛希密特回声来分析相变。在复能量区，识别了全PT转变和首次激发态PT转变。利用关联函数区分了PT对称区域内的局域相和反局域相。通过相关的双正交和自正交洛希密特回声定位了杨-李边奇点（YLES），并提取了临界指数。

Result: 确定了完整的相图，包括实能量区的二阶相变边界和复能量区的PT转变。验证了该相变属于伊辛普适类，并提取了YLES的临界指数，该指数与非幺正共形场论的预测一致。

Conclusion: 该研究为理解非厄米量子临界性提供了新的见解，并提出了一个在里德堡原子阵列中观察YLES的实验方案，为未来实验探索非厄米临界现象和奇点开辟了道路。

Abstract: We present a comprehensive theoretical framework for quantum criticality in
the non-Hermitian detuned PXP model, and establish the complete phase diagram,
which had remained elusive in previous studies. Starting from a numerically
identified phase transition point, we construct an exact second-order phase
transition boundary through a similarity transformation in the real-energy
regime. By introducing the biorthogonal entanglement entropy and biorthogonal
Loschmidt echo, we demonstrate from both equilibrium and nonequilibrium
perspectives that this transition belongs to the Ising universality class.
Using the correlation function, we further distinguish between confined and
deconfined phases within the $\mathcal{PT}$-symmetric region. In the
complex-energy regime, we identify both a full $\mathcal{PT}$ transition and a
first-excited-state $\mathcal{PT}$ transition, respectively. Moreover, we
identify the location of the Yang-Lee edge singularity (YLES) using both the
associated-biorthogonal and self-normal Loschmidt echoes, and extract the
corresponding critical exponent, which agrees with the predictions of
non-unitary conformal field theory. Finally, we propose an experimental scheme
to observe the YLES in Rydberg atomic arrays, which offers a promising route to
exploring non-Hermitian critical phenomena and singularities in future
experimental settings.

</details>


### [272] [Inverse designed Hamiltonians for perfect state transfer and remote entanglement generation, and applications in superconducting qubits](https://arxiv.org/abs/2510.13584)
*Tian-Le Wang,Ze-An Zhao,Peng Wang,Sheng Zhang,Ren-Ze Zhao,Xiao-Yan Yang,Hai-Feng Zhang,Zhi-Fei Li,Yuan Wu,Peng Duan,Ming Gong,Guo-Ping Guo*

Main category: quant-ph

TL;DR: Hamiltonian inverse engineering is used to design quantum protocols. A new 'dome model' is proposed, which is more noise-resilient than conventional models due to its tunable parameter 'm'. This model can be reduced to the PST model or SWAP model. A cascaded strategy is suggested for scalability, and the model is suitable for superconducting qubits.


<details>
  <summary>Details</summary>
Motivation: Designing quantum protocols for specific evolutions or state preparation, like perfect state transfer (PST) and remote entanglement, is important. However, conventional methods lack noise resilience. This paper aims to create a noise-resilient Hamiltonian using inverse engineering.

Method: A noise-resilient energy spectrum is used as a starting point to construct a class of Hamiltonians called the 'dome model' through inverse engineering. This model has a tunable parameter 'm' that affects energy-level spacing and Hamiltonian structure. For scalability, a cascaded strategy is proposed. The model is suited for superconducting qubits with tunable couplers.

Result: The proposed dome model demonstrates improved noise resilience compared to conventional models, as confirmed by numerical simulations. The parameter 'm' allows tuning of energy-level spacing and Hamiltonian structure, reducing to the PST model at m=0 and a SWAP model in the large-m regime. The cascaded strategy addresses scalability challenges.

Conclusion: The dome model offers a noise-resilient approach to Hamiltonian engineering for quantum information processing. Its tunable parameter and suitability for superconducting qubits with tunable couplers advance the potential for robust and scalable quantum information processing.

Abstract: Hamiltonian inverse engineering enables the design of protocols for specific
quantum evolutions or target state preparation. Perfect state transfer (PST)
and remote entanglement generation are notable examples, as they serve as key
primitives in quantum information processing. However, Hamiltonians obtained
through conventional methods often lack robustness against noise. Assisted by
inverse engineering, we begin with a noise-resilient energy spectrum and
construct a class of Hamiltonians, referred to as the dome model, that
significantly improves the system's robustness against noise, as confirmed by
numerical simulations. This model introduces a tunable parameter $m$ that
modifies the energy-level spacing and gives rise to a well-structured
Hamiltonian. It reduces to the conventional PST model at $m=0$ and simplifies
to a SWAP model involving only two end qubits in the large-$m$ regime. To
address the challenge of scalability, we propose a cascaded strategy that
divides long-distance PST into multiple consecutive PST steps. Our work is
particularly suited for demonstration on superconducting qubits with tunable
couplers, which enable rapid and flexible Hamiltonian engineering, thereby
advancing the experimental potential of robust and scalable quantum information
processing.

</details>


### [273] [Quality assessment of quantum teleportation through the distribution of fidelity](https://arxiv.org/abs/2510.13600)
*D. G. Bussandri,G. M. Bosyk,P. Crespo Del Amo,K. Życzkowski*

Main category: quant-ph

TL;DR: 该研究提出了一个用于评估单量子比特量子隐形传态性能的统计框架，超越了传统的平均保真度基准。该框架包括推导实际保真度的概率密度函数，并将其应用于经典和标准量子隐形传态协议，考虑了两种噪声模型。结果表明，仅依赖平均保真度可能无法完全反映协议的性能，尤其是在存在局部噪声的情况下。此外，研究还引入了一种基于先验重要性函数的认证方法，该方法统一了基于矩的标准和基于阈值的成功概率，并指出高保真度认证需要更强的纠缠或非局域性。


<details>
  <summary>Details</summary>
Motivation: 传统的平均保真度基准在评估单量子比特量子隐形传态性能时存在局限性，可能无法完全反映协议的实际表现，尤其是在存在局部噪声的情况下。本研究旨在开发一个更全面的统计框架，以提供更准确、更细致的性能评估方法，并为特定应用提供定制化的基准。

Method: 1. 推导了实际量子隐形传态保真度的完整概率密度函数（PDF）的闭式表达式。 2. 将此PDF应用于经典测量-准备方案和标准量子隐形传态，并考虑了两种噪声模型：贝尔对角线资源态和局部幅度阻尼信道。 3. 引入了一种基于先验重要性函数（如Beta分布）的认证方法，该方法统一了基于矩的标准和基于阈值的成功概率，形成单一的评估指标。 4. 分析了在高保真度认证中纠缠或非局域性的作用，并阐释了“用噪声对抗噪声”现象的本质。

Result: 1. 发现具有相同平均保真度的协议可能表现出显著不同的统计行为。 2. 仅依赖平均保真度可能会掩盖局部噪声引入的不对称性，可能导致错误的对称性结论。 3. 证明了认证高保真度量子隐形传态需要越来越强的纠缠或非局域性。 4. 澄清了“用噪声对抗噪声”效应源于所选的先验重要性函数，而非真正的优势。

Conclusion: 本研究提出的统计框架为评估单量子比特量子隐形传态提供了更全面、更灵活的工具。通过概率密度函数和基于先验重要性函数的认证方法，可以更准确地评估协议性能，识别噪声的影响，并为特定应用场景提供定制化的基准。研究还澄清了某些现象的本质，有助于更深入地理解量子隐形传态的噪声鲁棒性。

Abstract: In this work, we introduce a comprehensive statistical framework for
assessing single-qubit quantum teleportation performance beyond the
conventional average-fidelity benchmark. At first, we derive a closed-form
expression for the full probability density function of actual teleportation
fidelities and apply it to both classical measure-and-prepare schemes and
standard quantum teleportation, considering two relevant noise models:
Bell-diagonal resource states and local amplitude-damping channels. These
results reveal that protocols with identical average fidelities can exhibit
markedly different statistical behaviors, and that relying solely on average
fidelity can mask inherent asymmetries introduced by local noise, potentially
leading to spurious conclusions of symmetry. Secondly, we introduce a
certification method based on prior importance functions (e.g., Beta
distributions), which unifies moment-based criteria and threshold-based success
probabilities into a single figure of merit. Applying this framework, we show
that certifying high-fidelity teleportation requires increasingly stronger
entanglement or non-locality, and we clarify that the so-called ``fighting
noise with noise'' effect arises from the chosen prior importance function
rather than representing a genuine advantage. Our approach thus provides
versatile tools for tailored, application-specific teleportation benchmarks.

</details>


### [274] [What can we do in a symmetry-constrained perspective? The importance of the total charge's status in quantum reference frame frameworks](https://arxiv.org/abs/2510.13607)
*Guilhem Doat,Augustin Vanrietvelde*

Main category: quant-ph

TL;DR: 不同的量子参考系框架在数学和物理层面存在差异，主要体现在对称性的强弱以及全局电荷的可及性上。


<details>
  <summary>Details</summary>
Motivation: 阐明不同量子参考系框架之间的差异，特别是数学上的对称性（强或弱）和物理上的全局电荷可及性问题。

Method: 区分了强弱对称性在数学上的不同，并将其与全局电荷对受对称性约束的观测者的可及性联系起来。定义了“视角”的数学概念。分析了两种方法各自的后果，包括弱方法在动量和可逆变换定义上的局限性。

Result: 发现弱方法会导致动量选择的模糊性，并且无法定义可逆的量子参考系变换。通过一个简单的操作场景，证明了内部观测者可以通过相对论性干涉测量和经典通信来测量全局电荷。

Conclusion: 全局电荷的可及性是区分不同量子参考系框架的关键物理问题。弱对称性方法存在局限性，而通过特定的测量和通信手段，内部观测者可以获取全局电荷信息。

Abstract: The study of quantum reference frames has received renewed interest over the
last years, leading to the parallel development of non-equivalent frameworks by
different communities. We clarify the differences between these frameworks. At
the mathematical level, they mainly differ in the kind of symmetry (either weak
or strong) employed to constrain the system. We show that this mathematical
difference corresponds to a fundamental physical question: whether the global
charge associated to the symmetry group is accessible to symmetry-constrained
observers. In this context, we formulate a definition of a perspective in terms
of operational capacities, or lack thereof. Turning to consequences of adopting
either approach, we discuss how adopting the weak approach induces an ambiguity
in the momenta included in each perspective and bars from defining reversible
QRF transformations. We then review and analyze the existing arguments
motivating each approach, and show how they bear upon the problem of charge
accessibility. Finally, we introduce a simple operational scenario in which
upholding two reasonable physical postulates leads to the conclusion that
internal observers could measure the global charge by 1/ performing a
relativized interference measurement and 2/ classically communicating.

</details>


### [275] [Quantumness near the Schwarzschild black hole based on W-state](https://arxiv.org/abs/2510.13666)
*Guang-Wei Mi,Xiaofen Huang,Shao-Ming Fei,Tinggui Zhang*

Main category: quant-ph

TL;DR: 本研究利用W态在史瓦西黑洞附近研究量子性质，并分析了霍金效应和环境噪声对量子相干性和量子纠缠的影响。


<details>
  <summary>Details</summary>
Motivation: 研究霍金效应对史瓦西黑洞附近量子纠缠和量子相干性的影响，并探讨了环境噪声的作用。

Method: 利用W态，分析了霍金效应对l_1范数量子相干性、一阶相干性、concurrence-fill和全局concurrence在具有一、二、三可及模式的系统中的影响。同时研究了霍金效应和AD信道环境噪声的联合影响。

Result: 霍金效应对具有三可及模式的系统的量子纠缠有增强作用，但会破坏量子相干性。对于具有一、二可及模式的系统，霍金效应则对量子相干性和量子纠缠都有积极影响。在AD信道下，霍金效应对三可及模式的系统会破坏量子相干性，但对量子纠缠有积极影响。

Conclusion: 霍金效应对黑洞附近系统的量子性质影响复杂，既有破坏也有增强作用，具体表现取决于系统的模式数量和是否存在环境噪声。

Abstract: We investigate certain quantumness in the vicinity of the Schwarzschild black
hole by utilizing the W state. We explore the influence of the Hawking effect
on the l_1-norm of quantum coherence, the first-order coherence (FOC), the
concurrence-fill (CF) and the global concurrence (GC) in Schwarzschild black
hole, for systems with one, two and three physically accessible modes. We
conclude that the Hawking effect of the black hole not only disrupts but also
enhance the quantum entanglement, while destroying the quantum coherence for
systems with three physically accessible modes. For systems with one or two
physically accessible modes, the Hawking effect exerts a positive influence on
quantum coherence and quantum entanglement. Moreover, we study the influence of
both the Hawking effect and environmental noise (AD channels) on l_1-norm of
quantum coherence, FOC, CF and GC. It is demonstrated that for systems with
three physically accessible modes, the Hawking effect of the black hole
disrupts quantum coherence but exerts a positive influence on quantum
entanglement under the AD channels.

</details>


### [276] [Robust Superradiance and Spontaneous Spin Ordering in Disordered Waveguide QED](https://arxiv.org/abs/2510.13671)
*Xin H. H. Zhang,Daniel Malz,Peter Rabl*

Main category: quant-ph

TL;DR: 研究了N个激发态两能级原子在1D光子波导中的集体辐射，发现空间和光谱无序性对超辐射的N^2峰值发射率具有渐近鲁棒性，并通过变分估计解释了无序性如何影响集体衰减，以及自组织优化了相干性。


<details>
  <summary>Details</summary>
Motivation: 研究空间和光谱无序性对1D光子波导中原子集体辐射（超辐射）的影响，特别是其峰值发射率和衰减特性的变化，旨在解决关于强无序性下超辐射存在性和性质的开放问题。

Method: 使用大规模半经典模拟来研究N个激发态两能级原子在1D光子波导中的集体辐射，并提供一个分析性的变分估计来解释模拟结果。

Result: 发现超辐射的峰值发射率（与N^2成比例）在强空间和光谱无序性下具有渐近鲁棒性，并观察到有限尺寸效应。变分估计能很好地拟合数值结果，揭示了无序性如何影响集体衰减。原子会自组织以优化相干性，导致超辐射衰减中出现镜面对称不对称的相关性。

Conclusion: 强空间和光谱无序性下的原子阵列仍然表现出超辐射现象，并且其峰值发射率的N^2标度律具有鲁棒性。原子自组织是优化集体辐射和理解无序系统性质的关键。

Abstract: We study the collective emission of a disordered array of $N$ excited
two-level atoms into a one-dimensional photonic waveguide. In the perfectly
ordered case, where atoms are spaced by exact integer multiples of the
wavelength, the system exhibits the characteristic superradiant burst with a
peak emission rate scaling as $N^2$. Using large-scale semiclassical
simulations, we find that this key signature of superradiance remains
asymptotically robust under strong spatial and spectral disorder, but also
exhibits subtle finite-size scaling toward this limit. To explain our
observations, we provide an analytical variational estimate for the maximal
decay rate, which tightly bounds the numerical results and reveals how disorder
shapes the collective decay. Specifically, we find that even in the presence of
strong disorder, the spins tend to self-organize spontaneously according to
their locations, which overall optimizes constructive interference effects and
explains the emergence of mirror-asymmetric correlations in superradiant decay.
These findings resolve important open questions regarding the existence and
nature of superradiance in strongly disordered arrays and offer valuable
insights for understanding collective quantum optical phenomena in realistic
systems.

</details>


### [277] [Reduced constant-cost implementations of Clifford operations using global interactions](https://arxiv.org/abs/2510.13761)
*Jonathan Nemirovsky,Lee Peleg,Amit Ben Kish,Yotam Shapira*

Main category: quant-ph

TL;DR: 使用可编程的全局纠缠门实现任意长度的Clifford操作序列，最对只需要6次门操作；任意长度的CNOT门序列可以用5次全局纠缠门实现，无需辅助量子比特。同时，研究了量子比特驱动功率，并提出了一种高效的编译算法。


<details>
  <summary>Details</summary>
Motivation: 研究如何高效地实现量子线路中的Clifford操作和CNOT门序列，特别是在利用可编程全局纠缠门和无辅助量子比特的条件下。

Method: 1. 提出使用任意单比特操作和可编程的全局纠缠门（Clifford纠缠多比特门）来构建量子电路。2. 分析了实现任意长度Clifford操作序列所需的全局纠缠门操作次数，证明了常数次（最多6次）即可。3. 分析了用全局纠缠门替换任意长度CNOT门序列的可行性，证明了5次操作即可。4. 研究了这些实现方式所需要的量子比特驱动功率。5. 提出了一种计算上高效的编译算法。

Result: 1. 实现了任意长度的Clifford操作序列，仅需不超过6次Clifford纠缠多比特门操作，且无需辅助量子比特。2. 实现了用5次Clifford纠缠多比特门操作替换任意长度的CNOT门序列，且无需辅助量子比特。3. 获得了与这些实现相关的量子比特驱动功率信息。4. 提出了一种实际可行且计算效率高的编译算法。

Conclusion: 该研究提出了一种高效的量子线路编译方法，利用可编程的全局纠缠门，能够以常数次门操作（最多6次Clifford门或5次CNOT门）实现任意长度的量子操作序列，且无需辅助量子比特。这对于基于离子阱等平台的量子计算具有实际意义，并提出了一种高效的编译算法。

Abstract: We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than 6 application of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae. Furthermore, we show that any sequence of CNOT
gates of any length, can be replaced with 5 applications of such Clifford
entangling multiqubit gates, without ancillae. We investigate the required
qubit drive power that is associated with these implementations. Our work
introduces a practical and computationally efficient algorithm to realize these
compilations.

</details>


### [278] [Are Randomized Quantum Linear Systems Solvers Practical?](https://arxiv.org/abs/2510.13766)
*Siddharth Hariprakash,Roel Van Beeumen,Katherine Klymko,Daan Camps*

Main category: quant-ph

TL;DR: 虽然随机量子算法的理论复杂度次优，但它们可能在早期容错计算中有用。本研究分析了一种基于傅里叶级数采样的随机量子线性方程求解器的资源需求，并与两种哈密顿模拟方法（乘积公式和随机泰勒展开）进行了比较。结果表明，该方法可能不实用，因为采样复杂度可能呈指数增长。


<details>
  <summary>Details</summary>
Motivation: 在量子模拟和量子线性代数领域，随机量子算法因其可能构建比基于块编码的方法更浅的电路而受到关注。尽管其算法复杂度被证明次优，但人们推测在早期容错计算时代，当电路深度至关重要时，它们可能具有优势。

Method: 本研究结合了傅里叶级数采样和哈密顿模拟，对随机量子线性系统求解器估算矩阵逆的标量属性的端到端资源需求进行了研究。推导了控制总误差的所有相关算法参数的显式界限。分析了两种哈密顿模拟的算法核心：二阶乘积公式近似和随机泰勒展开（RTE）。

Result: 通过数值演示验证了分析结果的有效性。研究表明，随机傅里叶级数方法在解决线性系统问题方面可能不实用，因为采样复杂度可能呈指数增长。

Conclusion: 本研究通过提供显式界限，为理论算法提案和高效硬件实现之间架起了桥梁，并能与其他具有最优渐近复杂度但资源开销大的算法进行公平比较。然而，研究结果也对随机傅里叶级数在量子线性系统问题中的实际应用提出了质疑。

Abstract: Randomized quantum algorithms have been proposed in the context of quantum
simulation and quantum linear algebra with the goal of constructing shallower
circuits than methods based on block encodings. While the algorithmic
complexities of such randomized schemes have been shown to be suboptimal, it
has been speculated that they may offer benefits in the early fault-tolerant
era where circuit depth comes at a premium. In this work, we investigate the
end-to-end resource requirements for a randomized quantum linear systems solver
to estimate scalar properties of the matrix inverse by combining sampling from
a Fourier series with Hamiltonian simulation. We derive explicit bounds on all
relevant algorithmic parameters that control the total error. We analyze two
algorithmic kernels for Hamiltonian simulation: a second order product formula
approximation and a method called random Taylor expansion (RTE).
  Finally, we provide numerical demonstrations that confirm the validity of our
analytical results and question the actual practicality of the randomized
Fourier series-based approach for linear systems problems as we show that the
sampling complexity can grow exponentially. By providing explicit bounds, our
work serves as a bridge between theoretical algorithmic proposals and efficient
hardware implementations while also enabling fair comparisons to alternative
algorithms that exhibit optimal asymptotic complexities at the cost of large
resource overheads.

</details>


### [279] [Observation of area laws in an interacting quantum field simulator](https://arxiv.org/abs/2510.13783)
*Maciej T. Jarema,Mohammadamin Tajik,Jörg Schmiedmayer,Silke Weinfurtner,Tobias Haas*

Main category: quant-ph

TL;DR: 本文通过在超冷原子模拟器中实验验证了量子多体系统中互信息的面积定则，并量化了非高斯关联的总效应。


<details>
  <summary>Details</summary>
Motivation: 在相互作用系统中，由于状态重建的复杂性，难以测量信息度量。本文旨在填补这一空白，通过实验演示互信息的面积定则。

Method: 在具有可调相互作用强度的超冷原子量子场模拟器中，实验测量了互信息与子系统体积、边界面积以及空间区域之间距离的关系。并使用相对熵量化了非高斯关联的总效应。

Result: 实验详细展示了互信息与子系统体积、边界面积和空间区域分离之间的关系，并量化了非高斯关联的总效应。

Conclusion: 本文提出的数据驱动、模型无关的方法可应用于其他平台和可观测值，为探测高维量子系统中的信息及其在塑造量子物质和时空中的作用提供了通用工具。

Abstract: Information shared between parties quantifies their correlation. The encoding
of correlations across space and time characterises the structure, history, and
interactions of systems. One of the most fundamental properties that emerges
from studies of information is the area law, which states that information
shared between spatial subregions typically scales with the area of their
boundary rather than their volume. In non-interacting, quantum many-body
systems, where Gaussian statistics apply, the scaling of information measures
is well understood. Within interacting systems, the readout of information
measures is impeded by the complexity of state reconstruction. As such, no
measurements beyond small quantum systems (e.g., composed of few, localised
particles) have been made. Here, we fill this gap by experimentally
demonstrating the area law of mutual information in an ultra-cold atom
simulator of quantum fields with tuneable interaction strength. Our results
detail the scaling of mutual information with subsystem volume, boundary area,
and separation between spatial regions at finite temperature. Moreover, we
quantify the total effect of non-Gaussian correlations using an
information-theoretic measure - relative entropy. Our presented approach is
data-driven, model agnostic, and readily applicable to other platforms and
observables, thus constituting a universal toolkit for probing information in
high-dimensional quantum systems and its role in shaping quantum matter and
spacetime.

</details>


### [280] [Digitized Counterdiabatic Quantum Feature Extraction](https://arxiv.org/abs/2510.13807)
*Anton Simen,Carlos Flores-Garrigós,Murilo Henrique De Oliveira,Gabriel Dario Alvarado Barrios,Alejandro Gomez Cadavid,Archismita Dalal,Enrique Solano,Narendra N. Hegade,Qi Zhang*

Main category: quant-ph

TL;DR: 通过研究哈密顿量的动力学来提取量子特征，可以提升机器学习性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升机器学习性能，提出一种基于哈密顿量的量子特征提取方法，利用k-局域多体自旋哈密顿量的动力学来生成复杂的特征。

Method: 将经典特征向量嵌入到自旋玻璃哈密顿量中，通过单变量贡献和高阶相关性来表示。利用IBM的156量子比特数字量子处理器，通过对低阶和高阶可观测量进行期望值计算，将数据映射到高维特征空间。

Result: 在分子毒性分类和图像识别等高维、真实世界数据集上评估了该方法，并分析了特征重要性，证明了量子提取的特征可以补充甚至超越经典特征。

Conclusion: 结合量子和经典特征提取可以为各种机器学习任务带来持续的改进，表明在数据驱动的应用中，近期量子设备在早期具有可靠的实用性。

Abstract: We introduce a Hamiltonian-based quantum feature extraction method that
generates complex features via the dynamics of $k$-local many-body spins
Hamiltonians, enhancing machine learning performance. Classical feature vectors
are embedded into spin-glass Hamiltonians, where both single-variable
contributions and higher-order correlations are represented through many-body
interactions. By evolving the system under suitable quantum dynamics on IBM
digital quantum processors with 156 qubits, the data are mapped into a
higher-dimensional feature space via expectation values of low- and
higher-order observables. This allows us to capture statistical dependencies
that are difficult to access with standard classical methods. We assess the
approach on high-dimensional, real-world datasets, including molecular toxicity
classification and image recognition, and analyze feature importance to show
that quantum-extracted features complement and, in many cases, surpass
classical ones. The results suggest that combining quantum and classical
feature extraction can provide consistent improvements across diverse machine
learning tasks, indicating a reliable level of early quantum usefulness for
near-term quantum devices in data-driven applications.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [281] [D-com: Accelerating Iterative Processing to Enable Low-rank Decomposition of Activations](https://arxiv.org/abs/2510.13147)
*Faraz Tahmasebi,Michael Pelluer,Hyoukjun Kwon*

Main category: cs.AR

TL;DR: 通过输入分解技术（包括渐进式分解算法、Lanczos算法和协同加速器架构）和计算复制方法，实现了6.2倍的加速，并提出了一个能保持输出形状的计算方案来消除连续层中的分解成本。同时，采用多轨道分解方法来处理异常通道，以在最小的计算成本下实现高精度和低困惑度。


<details>
  <summary>Details</summary>
Motivation: 传统的模型压缩技术（如低秩分解）虽然被广泛研究，但在运行时分解的延迟往往会抵消其带来的好处。之前的研究主要集中在权重分解，但本文旨在探索输入分解的潜力，并证明其可以通过适当的算法和硬件支持带来显著的益处。

Method: 本文提出了一种新的输入分解方法，结合了渐进式分解算法、Lanczos算法和协同加速器架构。为了解决内存瓶颈，引入了计算复制方法，将操作移至计算密集型区域。此外，还开发了一种保持输出形状的计算方案，以消除连续层中的分解成本。为了弥补模型质量损失，采用了多轨道分解方法来单独处理异常通道。

Result: 所提出的D-com加速器结合了上述方法，实现了22%的端到端延迟改进，同时模型质量仅有轻微下降（例如，在AI2推理挑战任务上为3%）。

Conclusion: 与以往认为模型分解会增加延迟的观点相反，本文证明了通过采用先进的输入分解算法、协同加速器设计和创新的计算优化方法，模型分解可以显著提高效率，实现端到端延迟的降低。

Abstract: The computation and memory costs of large language models kept increasing
over last decade, which reached over the scale of 1T parameters. To address the
challenges from the large scale models, model compression techniques such as
low-rank decomposition have been explored. Previous model decomposition works
have focused on weight decomposition to avoid costly runtime decomposition,
whose latency often significantly exceeds the benefits from decomposition
(e.g., 38% more end-to-end latency when running Llama2-7b on A100 with 4K
sequence length with activation decomposition compared to no decomposition). In
this work, we debunk such observations and report that the input decomposition
can be significantly beneficial with a proper choice of decomposition algorithm
and hardware support. We adopt progressive decomposition algorithm, Lanczos
algorithm, and design a co-accelerator architecture for the decomposition
algorithm. To address the memory- boundness of the decomposition operation, we
introduce a novel compute replication methodology that moves the op- eration
toward compute-bound region, which enables 6.2x speedup in our evaluation. We
also develop an output shape- preserving computation scheme that eliminates
decomposi- tion costs in consecutive layers. To compensate model quality loss
from compression, we introduce a multi-track decom- position approach that
separately handles outlier channels for high accuracy and low perplexity with
minimal compu- tational costs. Combined together, our accelerator, D-com,
provides 22% end-to-end latency improvements compared to A100 GPU at the cost
of small model quality degradation (e.g., 3% on AI2 Reasoning Challenge task).

</details>


### [282] [Energy-Efficient FPGA Framework for Non-Quantized Convolutional Neural Networks](https://arxiv.org/abs/2510.13362)
*Angelos Athanasiadis,Nikolaos Tampouratzis,Ioannis Papaefstathiou*

Main category: cs.AR

TL;DR: 该框架利用FPGA和CPU异构系统，在保持全精度的前提下，高效实现卷积神经网络（CNN），旨在与量化框架相比，在不损失精度的前提下提供相似的性能和/或能效。


<details>
  <summary>Details</summary>
Motivation: 为了满足人工智能应用（特别是卷积神经网络CNN）对实时处理日益增长的需求，以及传统处理器在嵌入式系统和边缘计算平台上在性能、功耗和延迟方面存在的不足，需要开发高效的计算解决方案。

Method: 提出一个基于Darknet的框架，该框架允许设计者使用与Darknet相似的输入，在包含CPU和FPGA的异构系统中高效地实现CNN，并保持所有神经网络参数的全精度。

Result: 与支持量化的FPGA框架相比，该框架在不损失神经网络精度的前提下，实现了相似的性能和/或能效。

Conclusion: 该框架提供了一种在FPGA和CPU异构系统中高效实现全精度CNN的解决方案，有望在不牺牲精度的前提下，达到或接近量化框架的性能和能效水平。

Abstract: The growing demand for real-time processing in artificial intelligence
applications, particularly those involving Convolutional Neural Networks
(CNNs), has highlighted the need for efficient computational solutions.
Conventional processors, very often, fall short in balancing performance, power
consumption, and latency, especially in embedded systems and edge computing
platforms. Field-Programmable Gate Arrays (FPGAs) offer a promising
alternative, combining high performance with energy efficiency and
reconfigurability. The presented framework addresses the complex and demanding
computations of CNNs on FPGAs maintaining full precision in all neural network
parameters. Specifically, our framework is based on Darknet which is very
widely used for the design of CNNs and allows the designer, by using a similar
input to that given to Darknet, to efficiently implement a CNN in a
heterogeneous system comprising of CPUs and FPGAs. When compared with the FPGA
frameworks that support quantization, our solution aims to offer similar
performance and/or energy efficiency without any degradation on the NN
accuracy.

</details>


### [283] [F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs](https://arxiv.org/abs/2510.13401)
*Jude Haris,José Cano*

Main category: cs.AR

TL;DR: LLMs正变得越来越重要，并且可以通过llama.cpp等框架在边缘设备上运行。BFP量化对于在资源受限的边缘设备上运行LLMs至关重要。为了解决不同BFP变体对LLM精度的影响，我们提出了F-BFQ加速器，它可以在不重新配置的情况下动态切换两种BFP量化变体并执行矩阵乘法。


<details>
  <summary>Details</summary>
Motivation: LLM在边缘设备上的部署需要量化技术，而现有的LLM通常使用混合BFP量化来最小化精度损失。然而，现有的加速器需要重新配置才能支持不同的BFP变体，这使得加速跨层的BFP量化LLM变得效率低下。

Method: 提出了一种灵活的块浮点量化（F-BFQ）加速器，该加速器能够动态切换两种BFP量化变体并执行矩阵乘法（MatMul）操作，而无需重新配置。

Result: 在AMD Kria板上部署的F-BFQ加速器在三种BFP量化LLMs上，平均将推理时间比基于Arm NEON的CPU执行减少了1.4倍，同时实现了每秒5.2个token（约每秒3.9个单词）的吞吐量。

Conclusion: F-BFQ加速器能够有效支持混合BFP量化LLMs，在保持模型精度的同时，显著提高推理速度和吞吐量。

Abstract: Large Language Models (LLMs) have become increasingly prominent for daily
tasks, from improving sound-totext translation to generating additional frames
for the latest video games. With the help of LLM inference frameworks, such as
llama.cpp, which support optimizations such as KV-caching and quantization, it
is now easier than ever to deploy LLMs on edge devices. Quantization is
fundamental to enable LLMs on resource-constrained edge devices, and llama.cpp
utilizes block floating point (BFP) quantization to drastically reduce the bit
width of weights and input tensors, the memory footprint, and the computational
power required to run LLMs. LLMs are typically quantized with mixed BFP
quantization across the model layers to reduce the loss of model accuracy due
to quantization. Therefore, to efficiently accelerate across the layers of
BFP-quantized LLMs, specialized accelerators need to support different BFP
variants without reconfiguration. To address this issue, we propose a Flexible
Block FloatingPoint Quantization (F-BFQ) accelerator, which can dynamically
switch between two BFP quantization variants and perform matrix multiplication
(MatMul) operations. Our initial F-BFQ accelerator design, deployed on the AMD
Kria board, reduces inference time by 1.4x on average over the Arm NEON-based
CPU execution across three BFP quantized LLMs while achieving 5.2 tokens per
second (~3.9 words per second).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [284] [From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models](https://arxiv.org/abs/2510.12864)
*Imran Khan*

Main category: cs.AI

TL;DR: LLMs' rigid adherence to explicit rules hinders alignment with human common sense. We introduce the Rule-Intent Distinction (RID) Framework, a low-compute meta-prompting technique, to elicit human-aligned exception handling in LLMs zero-shot. RID significantly improves performance (95% Human Alignment Score) compared to baseline (80%) and Chain-of-Thought (75%), enabling goal-oriented reasoning for more reliable AI agents.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) used in AI systems suffer from rigid adherence to explicit rules, leading to decisions misaligned with human common sense and intent. This 'rule-rigidity' is a barrier to trustworthy autonomous agents. Supervised fine-tuning (SFT) can help but is computationally expensive and inaccessible. Therefore, there is a need for a more practical and accessible method to address this issue.

Method: The Rule-Intent Distinction (RID) Framework is proposed. It is a novel, low-compute meta-prompting technique that works in a zero-shot manner. The framework provides a structured cognitive schema for LLMs to deconstruct tasks, classify rules, weigh conflicting outcomes, and justify decisions, aiming to elicit human-aligned exception handling.

Result: The RID framework was evaluated against baseline and Chain-of-Thought (CoT) prompting on a custom benchmark of 20 scenarios. Human-verified results showed that RID achieved a 95% Human Alignment Score (HAS), significantly outperforming the baseline (80%) and CoT (75%). RID also consistently produced higher-quality, intent-driven reasoning.

Conclusion: The RID framework presents a practical, accessible, and effective method for steering LLMs from literal instruction-following towards liberal, goal-oriented reasoning. This approach facilitates the development of more reliable and pragmatic AI agents by improving their ability to handle exceptions and align with human intent.

Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive schema for deconstructing tasks,
classifying rules, weighing conflicting outcomes, and justifying its final
decision. We evaluated the RID framework against baseline and Chain-of-Thought
(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced
judgment across diverse domains. Our human-verified results demonstrate that
the RID framework significantly improves performance, achieving a 95% Human
Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT.
Furthermore, it consistently produces higher-quality, intent-driven reasoning.
This work presents a practical, accessible, and effective method for steering
LLMs from literal instruction-following to liberal, goal-oriented reasoning,
paving the way for more reliable and pragmatic AI agents.

</details>


### [285] [DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping](https://arxiv.org/abs/2510.12979)
*Wei Fan,Wenlin Yao,Zheng Li,Feng Yao,Xin Liu,Liang Qiu,Qingyu Yin,Yangqiu Song,Bing Yin*

Main category: cs.AI

TL;DR: LLMs 结合多步推理和动作生成能力，在利用外部工具解决复杂长时规划任务方面展现出潜力。现有方法要么依赖隐式规划，要么引入显式规划器但未系统优化规划阶段。为解决此问题，提出 DeepPlanner，一个端到端强化学习框架，通过基于熵的项来塑造 token 级优势，并选择性地上调规划密集型 rollout 的样本级优势，从而增强深度研究智能体的规划能力。实验表明 DeepPlanner 提高了规划质量，并在较低的训练预算下取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 方法在利用外部工具解决复杂长时规划任务时，存在规划阶段优化不足的问题，具体表现为规划 token 具有较高的熵，决策点不确定。

Method: 提出 DeepPlanner，一个端到端强化学习框架。通过结合基于熵的项来塑造 token 级优势（为高熵 token 分配更大的更新），并选择性地上调样本级优势（针对规划密集型 rollout），以增强规划能力。

Result: 在七个深度研究基准测试中，DeepPlanner 提高了规划质量，并在较低的训练预算下实现了最先进的结果。

Conclusion: DeepPlanner 作为一个端到端强化学习框架，能够有效提升 LLM 的规划能力，并通过优化规划阶段的 token 和 rollout 来提高训练效率和模型性能。

Abstract: Large language models (LLMs) augmented with multi-step reasoning and action
generation abilities have shown promise in leveraging external tools to tackle
complex tasks that require long-horizon planning. However, existing approaches
either rely on implicit planning in the reasoning stage or introduce explicit
planners without systematically addressing how to optimize the planning stage.
As evidence, we observe that under vanilla reinforcement learning (RL),
planning tokens exhibit significantly higher entropy than other action tokens,
revealing uncertain decision points that remain under-optimized. To address
this, we propose DeepPlanner, an end-to-end RL framework that effectively
enhances the planning capabilities of deep research agents. Our approach shapes
token-level advantage with an entropy-based term to allocate larger updates to
high entropy tokens, and selectively upweights sample-level advantages for
planning-intensive rollouts. Extensive experiments across seven deep research
benchmarks demonstrate that DeepPlanner improves planning quality and achieves
state-of-the-art results under a substantially lower training budget.

</details>


### [286] [SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents](https://arxiv.org/abs/2510.12985)
*Simon Sinong Zhan,Yao Liu,Philip Wang,Zinan Wang,Qineng Wang,Zhian Ruan,Xiangyu Shi,Xinyu Cao,Frank Yang,Kangrui Wang,Huajie Shao,Manling Li,Qi Zhu*

Main category: cs.AI

TL;DR: Sentinel 是一个框架，用于在语义、规划和轨迹层面正式评估基于大语言模型的具身智能体的物理安全性。它使用时间逻辑（TL）来精确定义安全需求，并通过多层验证流程来检测不安全行为，包括语义理解、规划和轨迹执行。实验证明 Sentinel 能有效发现以往方法忽略的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式规则或主观判断，无法精确评估大语言模型（LLM）具身智能体的物理安全性。需要一个能在语义、规划和轨迹层面形式化评估物理安全性的框架。

Method: Sentinel 框架，利用时间逻辑（TL）精确定义安全需求。包含三个验证层面：1. 语义层面：将自然语言安全需求形式化为 TL 公式，并验证 LLM 对这些需求的理解。2. 规划层面：验证 LLM 生成的高层动作规划和子目标是否符合 TL 公式。3. 轨迹层面：将执行轨迹合并为计算树，并与物理细节的 TL 规范进行高效验证。

Result: 在 VirtualHome 和 ALFRED 环境中，Sentinel 成功评估了多个基于 LLM 的具身智能体在多样化安全需求下的表现。实验结果表明，Sentinel 能有效检测出以往方法所忽略的安全违规行为，并揭示其失败模式。

Conclusion: Sentinel 通过将物理安全需求形式化为时间逻辑，并跨越多个验证层面，为系统性评估 LLM 具身智能体在物理环境中的安全性提供了严谨的基础。该方法能有效识别出以往方法未能发现的安全问题，并提供对其失败模式的洞察。

Abstract: We present Sentinel, the first framework for formally evaluating the physical
safety of Large Language Model(LLM-based) embodied agents across the semantic,
plan, and trajectory levels. Unlike prior methods that rely on heuristic rules
or subjective LLM judgments, Sentinel grounds practical safety requirements in
formal temporal logic (TL) semantics that can precisely specify state
invariants, temporal dependencies, and timing constraints. It then employs a
multi-level verification pipeline where (i) at the semantic level, intuitive
natural language safety requirements are formalized into TL formulas and the
LLM agent's understanding of these requirements is probed for alignment with
the TL formulas; (ii) at the plan level, high-level action plans and subgoals
generated by the LLM agent are verified against the TL formulas to detect
unsafe plans before execution; and (iii) at the trajectory level, multiple
execution trajectories are merged into a computation tree and efficiently
verified against physically-detailed TL specifications for a final safety
check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate
multiple LLM-based embodied agents against diverse safety requirements. Our
experiments show that by grounding physical safety in temporal logic and
applying verification methods across multiple levels, Sentinel provides a
rigorous foundation for systematically evaluating LLM-based embodied agents in
physical environments, exposing safety violations overlooked by previous
methods and offering insights into their failure modes.

</details>


### [287] [From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model](https://arxiv.org/abs/2510.13002)
*Boyou Chen,Gerui Xu,Zifei Wang,Huizhong Guo,Ananna Ahmed,Zhaonan Sun,Zhen Hu,Kaihan Zhang,Shan Bao*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型自动识别驾驶员危险行为（DHA）的框架，以提高交通安全数据分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 手动编码驾驶员危险行为（DHA）的数据不一致且耗时，限制了大规模数据库的可靠性。

Method: 使用MTCF五年的两车碰撞数据，对Llama 3.2 1B模型进行微调，并与传统机器学习模型（随机森林、XGBoost、CatBoost、神经网络）进行性能对比。此外，还开发了一种概率推理方法，通过分析模型在三种反事实场景（驾驶员分心、驾驶员年龄）下的输出变化来提高可解释性。

Result: 微调后的大型语言模型准确率达到80%，优于所有基线模型，并在数据不平衡的情况下表现出显著的改进。分析显示，增加驾驶员分心会增加“一般不安全驾驶”的可能性；双方分心会最大化“双方驾驶员均采取危险行为”的概率；指定青少年驾驶员会显著增加“超速和违规停车”的概率。

Conclusion: 该框架和分析方法为大规模自动DHA检测提供了一个可靠且可解释的解决方案，为交通安全分析和干预提供了新的机会。

Abstract: Vehicle crashes involve complex interactions between road users, split-second
decisions, and challenging environmental conditions. Among these, two-vehicle
crashes are the most prevalent, accounting for approximately 70% of roadway
crashes and posing a significant challenge to traffic safety. Identifying
Driver Hazardous Action (DHA) is essential for understanding crash causation,
yet the reliability of DHA data in large-scale databases is limited by
inconsistent and labor-intensive manual coding practices. Here, we present an
innovative framework that leverages a fine-tuned large language model to
automatically infer DHAs from textual crash narratives, thereby improving the
validity and interpretability of DHA classifications. Using five years of
two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on
detailed crash narratives and benchmarked its performance against conventional
machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a
neural network. The fine-tuned LLM achieved an overall accuracy of 80%,
surpassing all baseline models and demonstrating pronounced improvements in
scenarios with imbalanced data. To increase interpretability, we developed a
probabilistic reasoning approach, analyzing model output shifts across original
test sets and three targeted counterfactual scenarios: variations in driver
distraction and age. Our analysis revealed that introducing distraction for one
driver substantially increased the likelihood of "General Unsafe Driving";
distraction for both drivers maximized the probability of "Both Drivers Took
Hazardous Actions"; and assigning a teen driver markedly elevated the
probability of "Speed and Stopping Violations." Our framework and analytical
methods provide a robust and interpretable solution for large-scale automated
DHA detection, offering new opportunities for traffic safety analysis and
intervention.

</details>


### [288] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 传统时间序列分析依赖于在静态基准上训练的模式识别，但现实世界需要超越表面趋势以揭示潜在驱动因素。LLM的兴起为时间序列分析提供了整合多模态输入的新机会，但现有方法大多仅利用其数值回归能力，忽略了其深层推理潜力。本文主张将时间序列分析视为一项推理任务，利用LLM优先考虑因果结构和可解释性，从而实现更贴近人类理解、透明且上下文感知的时间序列洞察。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的时间序列分析需要超越表面趋势，揭示驱动因素，而现有LLM方法未能充分利用其推理潜力。

Method: 将LLM用于时间序列分析，侧重于推理任务，优先考虑因果结构和可解释性，而不是仅仅进行数值回归。

Result: 通过将LLM视为推理工具，可以实现更接近人类理解、更透明、更具上下文感知的时间序列分析。

Conclusion: 应该将LLM视为时间序列分析中的推理工具，以增强因果结构和可解释性，从而获得更深层次的见解。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


### [289] [Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking](https://arxiv.org/abs/2510.13036)
*Stephane Hatgis-Kessell,Logan Mondal Bhamidipaty,Emma Brunskill*

Main category: cs.AI

TL;DR: 人类设计的奖励函数常与人类的真实目标不符，导致奖励被滥用。为了解决这个问题，我们提出了基于偏好的奖励修复（PBRR）框架，通过从偏好数据中学习一个加法、依赖于转移的修正项来修复人类指定的代理奖励函数。PBRR使用目标性探索策略和新的偏好学习目标，在表格域中表现出与现有方法相当的累积遗憾，并在奖励滥用基准测试中显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 人类设计的奖励函数常与人类的真实目标不符，导致奖励被滥用，而从头学习奖励函数成本高昂。

Method: PBRR框架通过从偏好数据中学习一个加法、依赖于转移的修正项来修复人类指定的代理奖励函数。它使用目标性探索策略和新的偏好学习目标。

Result: 在表格域中，PBRR的累积遗憾与现有方法相当。在奖励滥用基准测试中，PBRR需要的偏好数据量少于其他方法，且学习到的策略性能更优。

Conclusion: PBRR是一种有效的框架，可以修复有缺陷的代理奖励函数，并能从少量偏好数据中学习到高性能策略，优于其他奖励学习方法。

Abstract: Human-designed reward functions for reinforcement learning (RL) agents are
frequently misaligned with the humans' true, unobservable objectives, and thus
act only as proxies. Optimizing for a misspecified proxy reward function often
induces reward hacking, resulting in a policy misaligned with the human's true
objectives. An alternative is to perform RL from human feedback, which involves
learning a reward function from scratch by collecting human preferences over
pairs of trajectories. However, building such datasets is costly. To address
the limitations of both approaches, we propose Preference-Based Reward Repair
(PBRR): an automated iterative framework that repairs a human-specified proxy
reward function by learning an additive, transition-dependent correction term
from preferences. A manually specified reward function can yield policies that
are highly suboptimal under the ground-truth objective, yet corrections on only
a few transitions may suffice to recover optimal performance. To identify and
correct for those transitions, PBRR uses a targeted exploration strategy and a
new preference-learning objective. We prove in tabular domains PBRR has a
cumulative regret that matches, up to constants, that of prior preference-based
RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR
consistently outperforms baselines that learn a reward function from scratch
from preferences or modify the proxy reward function using other approaches,
requiring substantially fewer preferences to learn high performing policies.

</details>


### [290] [Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation](https://arxiv.org/abs/2510.13195)
*Qun Ma,Xiao Xue,Xuwen Zhang,Zihan Zhao,Yuwei Guo,Ming Zhang*

Main category: cs.AI

TL;DR: LLM驱动的虚拟人类在社会模拟中存在情感认知缺陷，本研究提出了一个包含期望生成和目标管理的情感认知框架，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的代理在情感认知方面存在严重缺陷，无法模拟虚拟和现实世界服务之间的有界理性，并且缺乏将情感嵌入代理决策架构的经验验证机制。

Method: 提出一个情感认知框架，包含期望生成和目标管理，模拟LLM驱动代理的完整决策过程，包括状态演化、期望生成、目标优化、决策生成和行动执行。并在专有的多代理交互环境中实现该框架。

Result: 实验结果表明，由该框架驱动的代理不仅表现出与其情感状态一致的行为，而且在与其它类型代理的比较评估中，表现出更高的生态有效性，并产生更接近人类行为模式的决策结果。

Conclusion: 本研究提出的情感认知框架能够实现LLM驱动代理与人类的情感对齐，并能显著提高代理的决策能力和行为真实性。

Abstract: The advent of large language models (LLMs) has enabled agents to represent
virtual humans in societal simulations, facilitating diverse interactions
within complex social systems. However, existing LLM-based agents exhibit
severe limitations in affective cognition: They fail to simulate the bounded
rationality essential for bridging virtual and real-world services; They lack
empirically validated integration mechanisms embedding emotions within agent
decision architectures. This paper constructs an emotional cognition framework
incorporating desire generation and objective management, designed to achieve
emotion alignment between LLM-based agents and humans, modeling the complete
decision-making process of LLM-based agents, encompassing state evolution,
desire generation, objective optimization, decision generation, and action
execution. This study implements the proposed framework within our proprietary
multi-agent interaction environment. Experimental results demonstrate that
agents governed by our framework not only exhibit behaviors congruent with
their emotional states but also, in comparative assessments against other agent
types, demonstrate superior ecological validity and generate decision outcomes
that significantly more closely approximate human behavioral patterns.

</details>


### [291] [Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning](https://arxiv.org/abs/2510.13214)
*Zehui Ling,Deshu Chen,Yichi Zhang,Yuchen Liu,Xigui Li,Xin Guo,Yuan Cheng*

Main category: cs.AI

TL;DR: 通过结合使用小型和大型语言模型来减少计算成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 为了减轻深度推理的计算成本，同时利用大型语言模型（LLM）在复杂任务上的优势。

Method: 提出了一种互补的代理系统，首先由小型LLM生成初步答案，然后由大型LLM进行验证。如果答案正确，则直接采用；否则，大型LLM将进行深入推理。

Result: 对于简单问题，该方法将大型LLM的计算成本降低了50%以上，同时准确性损失可忽略不计；对于复杂任务，该方法保持了稳健的性能。

Conclusion: 这种结合小型和大型LLM的方法在降低计算成本和保持准确性方面取得了良好的平衡。

Abstract: Recent advances in Large Language Models (LLMs) demonstrate that
chain-of-thought prompting and deep reasoning substantially enhance performance
on complex tasks, and multi-agent systems can further improve accuracy by
enabling model debates. However, applying deep reasoning to all problems is
computationally expensive. To mitigate these costs, we propose a complementary
agent system integrating small and large LLMs. The small LLM first generates an
initial answer, which is then verified by the large LLM. If correct, the answer
is adopted directly; otherwise, the large LLM performs in-depth reasoning.
Experimental results show that, for simple problems, our approach reduces the
computational cost of the large LLM by more than 50% with negligible accuracy
loss, while consistently maintaining robust performance on complex tasks.

</details>


### [292] [Personalized Learning Path Planning with Goal-Driven Learner State Modeling](https://arxiv.org/abs/2510.13215)
*Joy Jia Yin Lim,Ye He,Jifan Yu,Xin Cong,Daniel Zhang-Li,Zhiyuan Liu,Huiqin Liu,Lei Hou,Juanzi Li,Bin Xu*

Main category: cs.AI

TL;DR: Pxplore是一个结合了强化学习和LLM的新框架，用于生成个性化、目标驱动的学习路径。


<details>
  <summary>Details</summary>
Motivation: 现有学习路径规划方法缺乏与个人目标对齐的机制，而LLM在个性化学习方面有潜力。

Method: 提出Pxplore框架，包含结构化学习者状态模型和自动奖励函数，并结合监督微调（SFT）和组相对策略优化（GRPO）进行策略训练。

Result: 实验证明Pxplore能生成连贯、个性化且目标驱动的学习路径。

Conclusion: Pxplore在个性化学习路径规划方面是有效的，并公开了代码和数据集以促进未来研究。

Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning
paths that align with individual goals. While large language models (LLMs) show
potential in personalizing learning experiences, existing approaches often lack
mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework
for PLPP that integrates a reinforcement-based training paradigm and an
LLM-driven educational architecture. We design a structured learner state model
and an automated reward function that transforms abstract objectives into
computable signals. We train the policy combining supervised fine-tuning (SFT)
and Group Relative Policy Optimization (GRPO), and deploy it within a
real-world learning platform. Extensive experiments validate Pxplore's
effectiveness in producing coherent, personalized, and goal-driven learning
paths. We release our code and dataset to facilitate future research.

</details>


### [293] [EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems](https://arxiv.org/abs/2510.13220)
*Yufei He,Juncheng Liu,Yue Liu,Yibo Li,Tri Cao,Zhiyuan Hu,Xinxing Xu,Bryan Hooi*

Main category: cs.AI

TL;DR: test-time learning benchmark and framework


<details>
  <summary>Details</summary>
Motivation: Current AI agents struggle to learn complex skills dynamically in new environments, limiting their practical use.

Method: Introduced the Jericho Test-Time Learning (J-TTL) benchmark for evaluating agents that must improve over consecutive episodes. Proposed EvoTest, an evolutionary framework where an Actor Agent plays and an Evolver Agent analyzes transcripts to revise the Actor's configuration (prompt, memory, hyperparameters, tool-use) after each episode.

Result: EvoTest significantly improves agent performance on the J-TTL benchmark, outperforming reflection, memory, and fine-tuning methods. EvoTest was the only method to win games like Detective and Library.

Conclusion: EvoTest, an evolutionary test-time learning framework, effectively addresses the challenge of on-the-fly learning for AI agents in novel environments, demonstrating superior performance and adaptability compared to existing methods.

Abstract: A fundamental limitation of current AI agents is their inability to learn
complex skills on the fly at test time, often behaving like "clever but
clueless interns" in novel environments. This severely limits their practical
utility. To systematically measure and drive progress on this challenge, we
first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a
new evaluation setup where an agent must play the same game for several
consecutive episodes, attempting to improve its performance from one episode to
the next. On J-TTL, we find that existing adaptation methods like reflection,
memory, or reinforcement learning struggle. To address the challenges posed by
our benchmark, we present EvoTest, an evolutionary test-time learning framework
that improves an agent without any fine-tuning or gradients-by evolving the
entire agentic system after every episode. EvoTest has two roles: the Actor
Agent, which plays the game, and the Evolver Agent, which analyzes the episode
transcript to propose a revised configuration for the next run. This
configuration rewrites the prompt, updates memory by logging effective
state-action choices, tunes hyperparameters, and learns the tool-use routines.
On our J-TTL benchmark, EvoTest consistently increases performance,
outperforming not only reflection and memory-only baselines but also more
complex online fine-tuning methods. Notably, our method is the only one capable
of winning two games (Detective and Library), while all baselines fail to win
any.

</details>


### [294] [An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities](https://arxiv.org/abs/2510.13230)
*Jalal Khan,Manzoor Khan,Sherzod Turaev,Sumbal Malik,Hesham El-Sayed,Farman Ullah*

Main category: cs.AI

TL;DR: 该研究提出了一种基于效用的分析模型，用于自动驾驶汽车（AVs）的环境感知，通过YOLOv8s模型进行物体检测，并基于nuScense数据集进行验证，结果显示AdamW优化器在特定类别上表现优于SGD。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AVs）需要精确的环境感知能力，以提高安全性和智能移动性。现有深度学习（DL）模型需要进一步发展，以准确识别多种道路物体并预测驾驶行为。

Method: 开发了一个包含三个模块的分析模型：1) 收集包含摩托车、三轮车等独特物体的自定义数据集；2) 使用YOLOv8s深度学习模型进行物体检测；3) 通过评估训练模型实例的性能指标来衡量感知服务的效用。

Result: 在nuScense数据集上，基于SGD、Adam和AdamW优化器的YOLOv8s模型在mAP@0.5值方面表现最佳。其中，AdamW优化器的模型（在特定类别上表现为：汽车0.921，摩托车0.899，卡车0.793）优于SGD优化器模型（汽车0.915，摩托车0.892，卡车0.781），验证了所提感知模型的有效性。

Conclusion: 所提出的基于效用的感知模型能够为AVs找到合适的感知服务，并且该模型可以用于评估学习模型的效用，从而确定AVs的适当感知方案。实验结果鼓励采用该模型来优化AVs的环境感知能力。

Abstract: The driving environment perception has a vital role for autonomous driving
and nowadays has been actively explored for its realization. The research
community and relevant stakeholders necessitate the development of Deep
Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles
(AVs) for smart mobility. There is a need to develop a model that accurately
perceives multiple objects on the road and predicts the driver's perception to
control the car's movements. This article proposes a novel utility-based
analytical model that enables perception systems of AVs to understand the
driving environment. The article consists of modules: acquiring a custom
dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a
DL-based model (YOLOv8s) for object detection; and a module to measure the
utility of perception service from the performance values of trained model
instances. The perception model is validated based on the object detection
task, and its process is benchmarked by state-of-the-art deep learning models'
performance metrics from the nuScense dataset. The experimental results show
three best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,
SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the
AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)
still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,
truck: 0.781, etc.) because it has better class-level performance values,
confirmed by the proposed perception model. We validate that the proposed
function is capable of finding the right perception for AVs. The results above
encourage using the proposed perception model to evaluate the utility of
learning models and determine the appropriate perception for AVs.

</details>


### [295] [SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2510.13262)
*Weiqi Guo,Guanjun Liu,Ziyuan Zhou*

Main category: cs.AI

TL;DR: 提出状态-动作联合攻击（SAJA）框架，通过联合状态和动作扰动来增强多智能体深度强化学习（MADRL）模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的MADRL模型容易受到状态和动作的对抗性扰动，但现有研究仅关注单一扰动，未能有效结合两者。简单组合扰动无法发挥其协同效应。

Method: SAJA框架包含两个阶段：1. 状态攻击阶段，使用多步梯度上升法，结合actor和critic网络计算对抗性状态。2. 动作攻击阶段，基于扰动后的状态，使用critic网络进行第二次梯度上升生成最终的对抗性动作。此外，通过增加一个衡量扰动动作与原始动作之间距离的启发式正则化项来增强critic的指导效果。

Result: 在多智能体粒子环境（MPE）中评估SAJA，结果表明：1. SAJA优于且比仅状态或仅动作攻击更隐蔽。2. 现有的状态或动作防御方法无法防御SAJA的攻击。

Conclusion: SAJA框架能有效联合状态和动作扰动，增强MADRL模型的鲁棒性，并且优于现有单一扰动攻击方法，对现有的防御措施具有有效性。

Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for
cooperative and competitive tasks such as autonomous driving and strategic
gaming. However, models trained by MADRL are vulnerable to adversarial
perturbations on states and actions. Therefore, it is essential to investigate
the robustness of MADRL models from an attack perspective. Existing studies
focus on either state-only attacks or action-only attacks, but do not consider
how to effectively joint them. Simply combining state and action perturbations
such as randomly perturbing states and actions does not exploit their potential
synergistic effects. In this paper, we propose the State-Action Joint Attack
(SAJA) framework that has a good synergistic effects. SAJA consists of two
important phases: (1) In the state attack phase, a multi-step gradient ascent
method utilizes both the actor network and the critic network to compute an
adversarial state, and (2) in the action attack phase, based on the perturbed
state, a second gradient ascent uses the critic network to craft the final
adversarial action. Additionally, a heuristic regularizer measuring the
distance between the perturbed actions and the original clean ones is added
into the loss function to enhance the effectiveness of the critic's guidance.
We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating
that (1) it outperforms and is more stealthy than state-only or action-only
attacks, and (2) existing state or action defense methods cannot defend its
attacks.

</details>


### [296] [Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization](https://arxiv.org/abs/2510.13393)
*Yunxiao Zhao,Zhiqiang Wang,Xingtong Yu,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.AI

TL;DR: 本篇论文提出了一种名为PORAT的新的博弈论导向的解释模型框架，以解决现有解释模型中生成器产生模式单一的问题，并在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有解释模型（rationalization）在生成可解释的输入子集（rationales）时存在模式崩溃问题，即生成器倾向于产生重复的、缺乏信息量的模式，导致模型收敛到次优博弈均衡。现有方法通常针对特定模式进行修复，缺乏统一性。

Method: 提出了一种名为PORAT（Game-theoretic Policy Optimization oriented RATionalization）的新方法。该方法从博弈论视角出发，通过引入策略干预来逐步调整博弈过程中的均衡状态，引导模型向更优的解收敛。作者对导致次优均衡的原因进行了理论分析，并证明了PORAT的可行性。

Result: PORAT方法在九个常用的真实世界数据集和两个合成数据集上进行了验证，实验结果显示，PORAT在性能上比现有的最先进方法提高了8.1%。

Conclusion: PORAT通过引入策略干预，成功解决了现有解释模型中的模式崩溃问题，并在多个数据集上取得了显著的性能提升，证明了其在解释模型领域的有效性和优越性。

Abstract: Rationalization, a data-centric framework, aims to build self-explanatory
models to explain the prediction outcome by generating a subset of
human-intelligible pieces of the input data. It involves a cooperative game
model where a generator generates the most human-intelligible parts of the
input (i.e., rationales), followed by a predictor that makes predictions based
on these generated rationales. Conventional rationalization methods typically
impose constraints via regularization terms to calibrate or penalize undesired
generation. However, these methods are suffering from a problem called mode
collapse, in which the predictor produces correct predictions yet the generator
consistently outputs rationales with collapsed patterns. Moreover, existing
studies are typically designed separately for specific collapsed patterns,
lacking a unified consideration. In this paper, we systematically revisit
cooperative rationalization from a novel game-theoretic perspective and
identify the fundamental cause of this problem: the generator no longer tends
to explore new strategies to uncover informative rationales, ultimately leading
the system to converge to a suboptimal game equilibrium (correct predictions
v.s collapsed rationales). To solve this problem, we then propose a novel
approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),
which progressively introduces policy interventions to address the game
equilibrium in the cooperative game process, thereby guiding the model toward a
more optimal solution state. We theoretically analyse the cause of such a
suboptimal equilibrium and prove the feasibility of the proposed method.
Furthermore, we validate our method on nine widely used real-world datasets and
two synthetic settings, where PORAT achieves up to 8.1% performance
improvements over existing state-of-the-art methods.

</details>


### [297] [Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse](https://arxiv.org/abs/2510.13417)
*Liesbeth Allein,Nataly Pineda-Castañeda,Andrea Rocci,Marie-Francine Moens*

Main category: cs.AI

TL;DR: LLMs在发现隐式因果链方面表现出差异，其推理主要基于模式匹配而非真正的因果理解，但生成的链在逻辑上是一致的。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在理解和生成因果链方面的机制和能力，特别是在气候变化论证等领域。

Method: 通过诊断性评估框架，指示九个LLMs生成连接给定因果对的中间因果步骤，并分析其生成结果。

Result: LLMs在生成的因果步骤数量和粒度上存在差异；它们对中间因果连接表现出高度的一致性和自信度，但这种判断主要受关联模式匹配驱动；人类评估确认了生成链的逻辑连贯性和完整性。

Conclusion: LLMs在生成因果链方面存在潜力，但其推理机制仍需深入研究，为未来在论证环境中进行隐式、机制化因果推理奠定了基础。

Abstract: How does a cause lead to an effect, and which intermediate causal steps
explain their connection? This work scrutinizes the mechanistic causal
reasoning capabilities of large language models (LLMs) to answer these
questions through the task of implicit causal chain discovery. In a diagnostic
evaluation framework, we instruct nine LLMs to generate all possible
intermediate causal steps linking given cause-effect pairs in causal chain
structures. These pairs are drawn from recent resources in argumentation
studies featuring polarized discussion on climate change. Our analysis reveals
that LLMs vary in the number and granularity of causal steps they produce.
Although they are generally self-consistent and confident about the
intermediate causal connections in the generated chains, their judgments are
mainly driven by associative pattern matching rather than genuine causal
reasoning. Nonetheless, human evaluations confirmed the logical coherence and
integrity of the generated chains. Our baseline causal chain discovery
approach, insights from our diagnostic evaluation, and benchmark dataset with
causal chains lay a solid foundation for advancing future work in implicit,
mechanistic causal reasoning in argumentation settings.

</details>


### [298] [Mobile Coverage Analysis using Crowdsourced Data](https://arxiv.org/abs/2510.13459)
*Timothy Wong,Tom Freeman,Joseph Feehily*

Main category: cs.AI

TL;DR: 该研究提出了一种利用众包 QoE 数据分析移动网络覆盖和识别服务弱点的框架，并使用 OC-SVM 算法计算覆盖范围，以精确绘制移动覆盖并突出显示信号不足的区域。


<details>
  <summary>Details</summary>
Motivation: 为了提高用户体验质量 (QoE)，网络运营商需要有效评估移动网络覆盖并精确识别服务弱点。

Method: 提出了一种利用众包 QoE 数据进行移动覆盖和弱点分析的新框架。该方法包括在单个小区（天线）层面进行覆盖分析，然后使用经验地理定位数据聚合到站点层面。研究的关键贡献是应用 One-Class SVM (OC-SVM) 算法计算移动网络覆盖，将决策超平面建模为有效的覆盖轮廓。该方法还用于分析众包服务中断报告，以识别和量化地理上局部化的弱点。

Result: 该框架能够准确绘制移动网络覆盖图，并突出显示信号不足的区域，尤其是在复杂的城市环境中。

Conclusion: 研究结果证明了该新颖框架在精确绘制移动覆盖和识别信号弱点方面的有效性。

Abstract: Effective assessment of mobile network coverage and the precise
identification of service weak spots are paramount for network operators
striving to enhance user Quality of Experience (QoE). This paper presents a
novel framework for mobile coverage and weak spot analysis utilising
crowdsourced QoE data. The core of our methodology involves coverage analysis
at the individual cell (antenna) level, subsequently aggregated to the site
level, using empirical geolocation data. A key contribution of this research is
the application of One-Class Support Vector Machine (OC-SVM) algorithm for
calculating mobile network coverage. This approach models the decision
hyperplane as the effective coverage contour, facilitating robust calculation
of coverage areas for individual cells and entire sites. The same methodology
is extended to analyse crowdsourced service loss reports, thereby identifying
and quantifying geographically localised weak spots. Our findings demonstrate
the efficacy of this novel framework in accurately mapping mobile coverage and,
crucially, in highlighting granular areas of signal deficiency, particularly
within complex urban environments.

</details>


### [299] [Confidence as a Reward: Transforming LLMs into Reward Models](https://arxiv.org/abs/2510.13501)
*He Du,Bowen Li,Chengxing Xie,Chang Gao,Kai Chen,Dacheng Tao*

Main category: cs.AI

TL;DR: 通过利用模型对最终答案的置信度作为奖励指标，CRew 是一种无需训练的方法，在数学推理任务上表现优于现有方法，甚至优于大多数训练过的奖励模型，并且可以有效地过滤训练数据，CRew-DPO 进一步提高了模型的判断能力。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型训练成本高且需要大量数据，而 LLM-as-a-Judge 等无需训练的方法虽然有前景，但仍有提升空间。模型置信度已被证明可以作为奖励指标，但尚未得到全面研究。本研究旨在系统地研究 Confidence-as-a-Reward (CRew)，一种利用模型对最终答案的置信度的无需训练方法。

Method: CRew 利用模型对其最终答案的 token 级置信度作为奖励代理，特别适用于封闭式任务。通过实验验证了 CRew 在 MATH500 和 RewardMATH 基准上的性能，并研究了 CRew 分数与模型推理性能之间的相关性。在此基础上，提出了 CRew-DPO 训练策略，结合置信度和正确性信号构建偏好数据。

Result: CRew 在 MATH500 和 RewardMATH 基准上均优于现有的无需训练的奖励方法，并且性能超过了大多数训练过的奖励模型。CRew 分数与模型的实际推理性能高度相关。CRew 还能有效过滤高质量的训练数据。CRew-DPO 进一步提高了模型的判断能力，并持续优于现有的自训练方法。

Conclusion: CRew 是一种简单而强大的无需训练的奖励方法，通过利用 token 级置信度，在数学推理等任务上取得了显著成果。CRew-DPO 通过结合置信度和正确性信号，进一步提升了模型的性能。该研究为利用模型置信度进行奖励建模提供了新的见解和有效的策略。

Abstract: Reward models can significantly enhance the reasoning capabilities of large
language models (LLMs), but they typically require extensive curated data and
costly training. To mitigate these challenges, training-free approaches such as
LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate
responses, achieving promising results. Recent works have also indicated that
model confidence can serve effectively as a reward metric, distinguishing
between chain-of-thought (CoT) and non-CoT paths. However, the concept of using
confidence as a reward has not been comprehensively studied. In this work, we
systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful
training-free method that utilizes token-level confidence in the model's final
answers as a proxy for reward, especially suitable for close-ended tasks.
Through extensive experiments on mathematical reasoning tasks, we demonstrate
that CRew outperforms existing training-free reward approaches on the MATH500
and RewardMATH benchmarks, and even surpasses most trained reward models. We
further identify a strong correlation between CRew scores and the actual
reasoning performance of the model. Additionally, we find that CRew can
effectively filter high-quality training data. Building upon these insights, we
propose CRew-DPO, a training strategy that constructs preference data from
confidence scores combined with correctness signals. Finetuning with CRew-DPO
further enhances the model's judging capabilities and consistently outperforms
existing self-training methods.

</details>


### [300] [A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain](https://arxiv.org/abs/2510.13524)
*William Flanagan,Mukunda Das,Rajitha Ramanyake,Swaunja Maslekar,Meghana Manipuri,Joong Ho Choi,Shruti Nair,Shambhavi Bhusan,Sanjana Dulam,Mouni Pendharkar,Nidhi Singh,Vashisth Doshi,Sachi Shah Paresh*

Main category: cs.AI

TL;DR: 金融服务行业在采用生成式人工智能时，模型性能的衡量是一个关键障碍。


<details>
  <summary>Details</summary>
Motivation: 历史机器学习指标往往无法泛化到生成式AI工作负载，并且通常需要主题专家的评估来补充。然而，即使结合使用，许多项目也未能考虑到选择特定指标时存在的各种独特风险。此外，许多由基础研究实验室和教育机构创建的广泛使用的基准未能泛化到工业应用。

Method: 本文提出了一个风险评估框架，以实现对主题专家和机器学习指标的更好应用。

Result: 本文解决了在金融服务行业中衡量生成式人工智能模型性能所面临的挑战，并提出了一种风险评估框架。

Conclusion: 通过采用所提出的风险评估框架，可以更好地应用主题专家和机器学习指标，从而克服在金融服务行业中衡量生成式人工智能模型性能的挑战。

Abstract: As Generative Artificial Intelligence is adopted across the financial
services industry, a significant barrier to adoption and usage is measuring
model performance. Historical machine learning metrics can oftentimes fail to
generalize to GenAI workloads and are often supplemented using Subject Matter
Expert (SME) Evaluation. Even in this combination, many projects fail to
account for various unique risks present in choosing specific metrics.
Additionally, many widespread benchmarks created by foundational research labs
and educational institutions fail to generalize to industrial use. This paper
explains these challenges and provides a Risk Assessment Framework to allow for
better application of SME and machine learning Metrics

</details>


### [301] [Tandem Training for Language Models](https://arxiv.org/abs/2510.13551)
*Robert West,Ashton Anderson,Ece Kamar,Eric Horvitz*

Main category: cs.AI

TL;DR: 语言模型越来越强大，但其决策过程对人类来说却越来越难以理解。为了解决这个问题，我们提出了一种名为“串联训练”的方法，旨在让模型生成更容易被理解的解决方案，即使对于能力较弱的协作者也是如此。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型能力的增强，其行为的不可解释性日益增加，这阻碍了对其进行监督和理解。因此，有必要研究能够让模型生成对能力较弱的协作者（包括人类）仍然可理解的解决方案的方法。

Method: 我们提出了一种名为“串联训练”的强化学习（RL）范式。在该范式中，模型在生成解决方案的过程中，会随机地从一个固定的、能力较弱的模型那里获取一部分“信息”。只有当模型能够接续弱模型生成的“信息”并成功完成任务时，训练才算成功。这种机制迫使模型在追求正确性的同时，还要考虑其解决方案的可解释性。

Result: 在GSM8K数学推理任务的实验中，我们发现“串联训练”能够有效地使模型在保持高准确率的同时，避免使用晦涩难懂的术语，并采用更易于理解的语言与能力较弱的合作者进行交流。

Conclusion: “串联训练”为构建可被能力较弱的代理（包括人类）审计的人工智能系统提供了一条有前景的途径，这对于人机协作和多智能体通信具有重要意义。

Abstract: As language models continue to rapidly improve, we can expect their actions
and reasoning to become difficult or impossible for weaker agents and humans to
follow, undermining interpretability and oversight. With an eye on long-term
futures, we pursue methods that encourage models to produce solutions that
remain intelligible to weaker collaborators. We formalize intelligibility as
handoff robustness: a strong model's solution is intelligible to a weaker model
if randomly handing off control to the weaker model along the solution path
does not cause failure. Building on this criterion, we introduce tandem
training for language models, a reinforcement learning (RL) paradigm in which
rollout tokens are intermittently and randomly sampled from a frozen weak model
rather than the strong model being trained. Because rollouts succeed only when
the strong model's actions and reasoning process can be continued by the weak
model -- when the two can co-construct a successful solution -- optimizing
standard RL objectives with tandem training implicitly incentivizes both
correctness and intelligibility. In the GSM8K math reasoning task, tandem
training reliably teaches models to abandon jargon and adapt their language to
weaker partners while keeping task accuracy high. Our results demonstrate a
promising route to building AI systems that remain auditable by weaker agents,
with implications for human--AI collaboration and multi-agent communication.

</details>


### [302] [A Modal Logic for Temporal and Jurisdictional Classifier Models](https://arxiv.org/abs/2510.13691)
*Cecilia Di Florio,Huimin Dong,Antonino Rotolo*

Main category: cs.AI

TL;DR: 该论文提出了一种模态逻辑，用于对法律领域的机器学习分类器进行形式化验证。


<details>
  <summary>Details</summary>
Motivation: 法律领域的机器学习分类器可以用于预测新案例的结果，但需要对它们的公平性和可解释性进行验证，特别是当它们应用于类似案例推理时。

Method: 提出了一种模态逻辑，用于对法律领域的机器学习分类器进行形式化验证，其中融入了解决先例冲突的原则，例如通过引入案例的时间维度和法院层级。

Result: 该逻辑能够形式化地捕捉法律案例推理，并为验证法律机器学习分类器提供理论基础。

Conclusion: 该研究为法律领域的机器学习分类器提供了一个形式化的验证框架，有助于提高其在法律判决中的可靠性和可信度。

Abstract: Logic-based models can be used to build verification tools for machine
learning classifiers employed in the legal field. ML classifiers predict the
outcomes of new cases based on previous ones, thereby performing a form of
case-based reasoning (CBR). In this paper, we introduce a modal logic of
classifiers designed to formally capture legal CBR. We incorporate principles
for resolving conflicts between precedents, by introducing into the logic the
temporal dimension of cases and the hierarchy of courts within the legal
system.

</details>


### [303] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Empower的新方法，通过最大化人类的赋权来调整辅助语言模型，以提升AI代理的辅助能力，使其在关键决策时能将控制权交还给人类。


<details>
  <summary>Details</summary>
Motivation: 当前辅助智能体在模仿专家或通过强化学习进行训练时，倾向于自主完成任务而非真正辅助人类达成目标，并且需要昂贵的人类反馈。本研究旨在解决这些问题，提出一种新的训练方法。

Method: 提出了一种名为Empower的新方法，该方法通过最大化人类的赋权（即人类在环境中实现期望改变的能力）来调整辅助语言模型。该方法仅需离线文本数据，是一种自监督学习方法，无需额外的人类反馈或可验证的奖励。

Result: 在用户研究中，参与者在78%的情况下更喜欢Empower助手（p=0.015），接受率提高了31%，建议次数减少了38%。在模拟人类程序员的环境中，Empower训练的智能体将模拟人类程序员在编码任务上的成功率平均提高了192%，显著优于仅通过监督式微调（SFT）训练的基线模型。

Conclusion: Empower方法提供了一个框架，能够仅利用离线数据，无需额外的人类反馈或可验证的奖励，即可规模化地训练出有用的、与人类对齐的AI代理，特别是在需要AI辅助做出关键决策的场景中。

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [304] [From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails](https://arxiv.org/abs/2510.13727)
*Ravi Pandya,Madison Bland,Duy P. Nguyen,Changliu Liu,Jaime Fernández Fisac,Andrea Bajcsy*

Main category: cs.AI

TL;DR: AI安全应被视为一个序贯决策问题，而非简单的内容过滤。本文提出一种基于控制理论的预测性安全护栏，能够实时监控并主动纠正AI模型的风险输出，以防止金融或物理伤害等下游危害。该方法模型无关，并可通过强化学习进行训练，在模拟驾驶和电商场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI安全护栏（如输出分类）容易失效，并且在检测到不安全情况时通常只是拒绝执行，这并非总是安全的。AI系统在实际应用中（如购物助手、自动驾驶汽车）需要具备避免下游金融或物理伤害的能力。

Method: 将AI安全视为一个序贯决策问题，利用安全关键控制理论在AI模型的潜在表征中构建预测性护栏。该护栏能实时监控AI的输出（动作），并主动将其纠正为安全的输出，且不依赖于特定模型。同时，提出了一种通过安全关键强化学习进行大规模训练的方法。

Result: 在模拟驾驶和电商场景中，基于控制理论的安全护栏能够可靠地引导LLM智能体避开灾难性后果（如碰撞、破产），同时保持任务性能。

Conclusion: 基于控制理论的安全护栏为当今的“标记-拦截”式护栏提供了一种原则性的动态替代方案，能够更有效地确保AI在实际应用中的安全。

Abstract: Generative AI systems are increasingly assisting and acting on behalf of end
users in practical settings, from digital shopping assistants to
next-generation autonomous cars. In this context, safety is no longer about
blocking harmful content, but about preempting downstream hazards like
financial or physical harm. Yet, most AI guardrails continue to rely on output
classification based on labeled datasets and human-specified criteria,making
them brittle to new hazardous situations. Even when unsafe conditions are
flagged, this detection offers no path to recovery: typically, the AI system
simply refuses to act--which is not always a safe choice. In this work, we
argue that agentic AI safety is fundamentally a sequential decision problem:
harmful outcomes arise from the AI system's continually evolving interactions
and their downstream consequences on the world. We formalize this through the
lens of safety-critical control theory, but within the AI model's latent
representation of the world. This enables us to build predictive guardrails
that (i) monitor an AI system's outputs (actions) in real time and (ii)
proactively correct risky outputs to safe ones, all in a model-agnostic manner
so the same guardrail can be wrapped around any AI model. We also offer a
practical training recipe for computing such guardrails at scale via
safety-critical reinforcement learning. Our experiments in simulated driving
and e-commerce settings demonstrate that control-theoretic guardrails can
reliably steer LLM agents clear of catastrophic outcomes (from collisions to
bankruptcy) while preserving task performance, offering a principled dynamic
alternative to today's flag-and-block guardrails.

</details>


### [305] [Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math](https://arxiv.org/abs/2510.13744)
*Shrey Pandit,Austin Xu,Xuan-Phi Nguyen,Yifei Ming,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: Hard2Verify是一个新的人工标注数据集，用于评估和改进大型语言模型（LLM）在数学推理中的逐步验证能力，发现目前开源验证器不如闭源模型，并探讨了影响验证器性能的因素。


<details>
  <summary>Details</summary>
Motivation: 训练LLM进行数学推理需要强大的验证器来捕获逐步错误，但现有数据集不足以满足这一需求。

Method: 构建了一个名为Hard2Verify的人工标注数据集，包含500多小时的人工劳动，用于评估和改进LLM的逐步验证能力。该数据集使用最新的、有挑战性的、开放式数学问题，要求验证器提供逐步标注或识别错误。

Result: 评估了29个生成式评判器和奖励模型，发现除少数优秀模型外，开源验证器在性能上落后于闭源模型。分析了导致逐步验证性能不佳的因素、增加验证器计算量的影响以及自验证和验证-生成动态等基本问题。

Conclusion: 现有的开源验证器在Hard2Verify数据集上表现不佳，表明在这一前沿领域仍有改进空间。未来的研究应关注提升验证器的性能，并探索自验证等更高级的功能。

Abstract: Large language model (LLM)-based reasoning systems have recently achieved
gold medal-level performance in the IMO 2025 competition, writing mathematical
proofs where, to receive full credit, each step must be not only correct but
also sufficiently supported. To train LLM-based reasoners in such challenging,
open-ended settings, strong verifiers capable of catching step-level mistakes
are necessary prerequisites. We introduce Hard2Verify, a human-annotated,
step-level verification benchmark produced with over 500 hours of human labor.
Hard2Verify is designed to rigorously assess step-level verifiers at the
frontier: Verifiers must provide step-level annotations or identify the first
error in responses generated by frontier LLMs for very recent, challenging, and
open-ended math questions. We evaluate 29 generative critics and process reward
models, demonstrating that, beyond a few standouts, open-source verifiers lag
closed source models. We subsequently analyze what drives poor performance in
step-level verification, the impacts of scaling verifier compute, as well as
fundamental questions such as self-verification and verification-generation
dynamics.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [306] [Mapping the gender attrition gap in academic psychology](https://arxiv.org/abs/2510.13273)
*Xinyi Zhao,Anna I. Thoma,Ralph Hertwig,Dirk U. Wulff*

Main category: cs.SI

TL;DR: 尽管女性在社会科学领域的研究者人数多于男性，但她们在高级职位的比例却偏低。本研究通过分析 78,216 名心理学研究者的大规模文献计量数据，探讨了这一“人才流失”现象。结果显示，尽管女性占研究者总数的 60% 以上，但她们的离职率持续高于男性，尤其是在首次发表论文后的早期职业生涯阶段。学术表现，特别是第一作者的论文发表，与早期职业生涯的留任密切相关，其影响甚至超过了合作网络或机构环境。在控制了性别在论文发表、合作和机构层面的差异后，女性在学术界的离职可能性仍然更高，尤其是在早期职业生涯阶段，这表明存在持续存在的障碍，阻碍了女性的学术发展。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查女性在心理学领域，乃至其他社会科学领域，职业生涯发展中遇到的“人才流失”现象，并找出导致女性在学术界高级职位中比例偏低的原因。

Method: 本研究利用大规模文献计量数据，分析了 78,216 名心理学研究者的职业生涯轨迹，重点关注了早期职业生涯的留任情况，并分析了学术表现、合作网络和机构环境等因素与留任率的关系。

Result: 女性研究者虽然占比较高，但离职率持续高于男性，尤其是在首次发表论文后的早期。学术表现，特别是第一作者论文，对早期留任率有显著影响。即使在控制了论文发表、合作和机构层面的因素后，女性的离职可能性依然更高，表明存在持续的障碍。

Conclusion: 心理学及其他社会科学领域面临的核心挑战在于研究者的“留任”而非“招聘”。需要有针对性的早期职业生涯干预措施，以促进长期的性别平等。性别平等。

Abstract: Although more women than men enter social science disciplines, they are
underrepresented at senior levels. To investigate this leaky pipeline, this
study analyzed the career trajectories of 78,216 psychology researchers using
large-scale bibliometric data. Despite overall constituting over 60\% of these
researchers, women experienced consistently higher attrition rates than men,
particularly in the early years following their first publication. Academic
performance, particularly first-authored publications, was strongly associated
with early-career retention -- more so than collaboration networks or
institutional environment. After controlling for gender differences in
publication-, collaboration-, and institution-level factors, women remained
more likely to leave academia, especially in early-career stages, pointing to
persistent barriers that hinder women's academic careers. These findings
suggest that in psychology and potentially other social science disciplines,
the core challenge lies in retention rather than recruitment, underscoring the
need for targeted, early-career interventions to promote long-term gender
equity.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [307] [Emergent spin Hall quantization and high-order van Hove singularities in square-octagonal MA$_2$Z$_4$](https://arxiv.org/abs/2510.12935)
*Rahul Verma,Yash Vardhan,Hsin Lin,Bahadur Singh*

Main category: cond-mat.mtrl-sci

TL;DR: MA$_2$Z$_4$ 材料具有鲁棒的、大带隙的量子自旋霍尔(QSH)相，并具有近乎量化的自旋霍尔电导和高阶范霍夫奇点(VHSs)。


<details>
  <summary>Details</summary>
Motivation: 在量子自旋霍尔(QSH)绝缘体中探索外来量子物相，特别是与高阶范霍夫奇点(VHSs)结合以增强电子相关性。

Method: 通过拓扑和对称性分析，预测了一类七层方-八面体MA$_2$Z$_4$异构体。

Result: Z = P, As, Sb 的化合物是 $\mathbb{Z}_2$ 非平凡的，具有自旋陈数 $C_s = 1$，并支持 $S_z$ 极化的边缘态。Z = N 的化合物是平凡绝缘体。QSH 相具有与紧急的自旋 $\mathrm{U}(1)$ 拟对称性一致的 $S_z$ 保守自旋哈密顿量，产生约 $2e^2/h$ 的自旋霍尔电导。MA$_2$(As, Sb)$_4$ 化合物在费米能级附近具有准平带，WSi$_2$Sb$_4$ 还在通量动量点具有四个高阶 VHS。

Conclusion: 方-八面体 MA$_2$Z$_4$ 材料是实现量化自旋霍尔电导和相关拓扑相（包括分数化态和非阿贝尔任意子）的鲁棒 QSH 绝缘体。

Abstract: Quantum spin Hall (QSH) insulators are versatile platforms for exploring
exotic quantum phases, especially when combined with high-order van Hove
singularities (VHSs) that enhance electron correlations. However, perfect spin
Hall quantization is often hindered by spin mixing from strong spin-orbit
coupling, and the emergence of such VHSs is highly sensitive to
material-specific electronic structures. Here, we predict a class of
seven-layered square-octagonal MA$_2$Z$_4$ (M = Mo/W, A = Si/Ge, Z = Pnictogen)
isomers that host a robust, large-gap QSH phase with nearly quantized spin Hall
conductivity and intrinsic high-order VHSs. Topological and symmetry analyses
reveal that compounds with Z = P, As, and Sb are $\mathbb{Z}_2$ nontrivial with
spin Chern number $C_s = 1$ and support $S_z$-polarized edge states, while
those with Z = N are trivial insulators. The QSH phase features an
$S_z$-conserving spin Hamiltonian consistent with an emergent spin
$\mathrm{U}(1)$ quasi-symmetry, yielding spin Hall conductivity $\sim 2e^2/h$.
Notably, MA$_2$(As, Sb)$_4$ compounds exhibit quasi-flat bands near the Fermi
level in the inverted regime, with WSi$_2$Sb$_4$ additionally hosting four
high-order VHSs at generic momentum points. These results position
square-octagonal MA$_2$Z$_4$ materials as robust QSH insulators for realizing
quantized spin Hall conductivity and correlated topological phases, including
fractionalized states and possibly non-Abelian anyons.

</details>


### [308] [Photostriction-Driven Phase Transition in Layered Chiral NbOX$_2$ Crystals: Electrical-Field-Controlled Enantiomer Selectivity](https://arxiv.org/abs/2510.12998)
*Jorge Cardenas-Gamboa,Martin Gutierrez-Amigo,Aritz Leonardo,Gregory A. Fiete,Juan L. Mañes,Jeroen van den Brink,Claudia Felser,Maia G. Vergniory*

Main category: cond-mat.mtrl-sci

TL;DR: 通过光致伸缩驱动的相变，为手性材料实现可逆、非接触的手征选择。 (Through photostriction-driven phase transitions, enabling reversible, non-contact enantiomeric selection for chiral materials.)


<details>
  <summary>Details</summary>
Motivation: 手性晶体在通过外部刺激控制结构手性方面提供了独特的平台，但选择结构对映体仍然具有挑战性。(Chiral crystals offer a unique platform for controlling structural handedness through external stimuli, but selecting structural enantiomers remains challenging.)

Method: 提出了一种基于光致伸缩驱动的相变的、用于层状手性NbOX2（X = Cl、Br、I）晶体的两步对映体选择途径。从头算模拟揭示了光激发能够诱导NbOX2从单斜（C2）基态到更高对称性（C2/m）结构的结构相变。在产生的瞬态高对称性状态下，施加电场会破坏残余的反演对称性简并，从而选择性地稳定一个对映体最终状态构型而不是另一个。(Demonstrated a two-step pathway for enantiomer selectivity in layered chiral NbOX2 (X = Cl, Br, I) crystals based on photostriction-driven phase transitions. Ab-initio simulations reveal that optical excitation is capable of inducing a structural phase transition from the monoclinic (C2) ground state to the higher-symmetry (C2/m) structure. In the resulting transient high-symmetry state, an applied electric field breaks the residual inversion-symmetry degeneracy, selectively stabilizing one enantiomeric final state configuration over the other.)

Result: 在瞬态高对称性状态下，通过施加电场实现了对映体的选择性稳定。(Achieved selective stabilization of enantiomers by applying an electric field in the transient high-symmetry state.)

Conclusion: 提出了一种结合光学和电学控制的方案，用于手性材料，能够实现可逆的、非接触的对映体选择，并具有在超快开关、光电子学和手性信息存储方面的潜在应用。(Established a combined optical-electrical control scheme for chiral materials, enabling reversible and non-contact enantiomer selection with potential applications in ultrafast switching, optoelectronics, and chiral information storage.)

Abstract: Chiral crystals offer an unique platform for controlling structural
handedness through external stimuli. However, the ability to select between
structural enantiomers remains challenging, both theoretically and
experimentally. In this work, we demonstrate a two-step pathway for enantiomer
selectivity in layered chiral NbOX$_2$ (X = Cl, Br, I) crystals based on
photostriction-driven phase transitions. Ab-initio simulations reveal that
optical excitation is capable of inducing a structural phase transition in
NbOX$_2$ from the monoclinic ($C2$) ground state to the higher-symmetry
($C2/m$) structure. In the resulting transient high-symmetry state, an applied
electric field breaks the residual inversion-symmetry degeneracy, selectively
stabilizing one enantiomeric final state configuration over the other. Our
results establish a combined optical-electrical control scheme for chiral
materials, enabling reversible and non-contact enantiomer selection with
potential applications in ultrafast switching, optoelectronics, and chiral
information storage.

</details>


### [309] [Emergent domain topology in the multiferroic hexagonal manganites](https://arxiv.org/abs/2510.13020)
*Aaron Merlin Müller,Lukas Heckendorn,Manfred Fiebig,Thomas Lottermoser*

Main category: cond-mat.mtrl-sci

TL;DR: 六方锰矿中的多铁性畴拓扑结构：三维相场模拟揭示了畴壁相互作用和三维特有涡旋线分叉。


<details>
  <summary>Details</summary>
Motivation: 探究六方锰矿中未被充分研究的三维多铁性畴结构及其拓扑现象。

Method: 结合Landau自由能理论和大规模相场模拟。

Result: 揭示了三维多铁性畴网络，发现了畴壁间的吸引作用，并识别出畴壁交叉处的三维特有涡旋线分叉现象。

Conclusion: 为理解多铁性材料中的三维畴相互作用提供了理论基础，并强调了三维空间在耦合铁电性、磁性和拓扑性中的重要性。

Abstract: Emergent topological phenomena in multiferroic materials arise from the
intricate coupling between structural, electric, and magnetic order parameters.
Hexagonal manganites provide a paradigmatic platform for such studies. These
compounds exhibit a strongly coupled distortive-improper ferroelectric order,
arising from trimerizing lattice distortions, and a 120{\deg} noncollinear
antiferromagnetic spin structure. While their two-dimensional domain topology
has been extensively studied, the full three-dimensional multiferroic domain
architecture has remained largely unexplored, mainly due to the experimental
challenges of probing bulk structures beyond surfaces. Here, we employ a Landau
free-energy framework combined with large-scale phase-field simulations to
reveal the intricate three-dimensional multiferroic domain network of hexagonal
manganites. We demonstrate that the coupling between the structural and
antiferromagnetic order parameters gives rise to a rich variety of
three-dimensional topological features. In particular, these features give rise
to an attraction between different types of domain walls. Moreover, we identify
bifurcations of vortex-like lines at domain-wall intersections, a phenomenon
that can exist only in three dimensions and fundamentally alters the topology
of the domain network. Our results provide a comprehensive theoretical basis
for understanding three-dimensional domain interactions in multiferroics and
highlight the essential role of dimensionality in coupling improper
ferroelectricity, magnetism, and topology in hexagonal manganites.

</details>


### [310] [Reciprocal Space Attention for Learning Long-Range Interactions](https://arxiv.org/abs/2510.13055)
*Hariharan Ramasubramanian,Alvaro Vazquez-Mayagoitia,Ganesh Sivaraman,Atul C. Thakur*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种名为倒空间注意力（RSA）的框架，用于增强机器学习原子间势（MLIPs）处理长程相互作用的能力，尤其是在傅里叶空间中进行建模。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习原子间势（MLIPs）在处理局部和半局部相互作用方面表现出色，但在需要显式且高效处理长程相互作用（如静电和色散）时存在不足。

Method: 提出倒空间注意力（RSA）框架，将线性缩放的注意力机制映射到傅里叶空间，从而能够显式地模拟长程相互作用，并可与现有的局部或半局部MLIP框架集成。

Result: 将RSA作为MACE骨架的远距离校正，在二聚体结合曲线、磷烯剥离和散装水分子偶极密度等基准测试中，均有效捕捉了化学和材料系统的长程物理特性。

Conclusion: RSA框架能够有效增强MLIPs对长程相互作用的处理能力，并在多种材料和分子体系中取得了良好的效果。

Abstract: Machine learning interatomic potentials (MLIPs) have revolutionized the
modeling of materials and molecules by directly fitting to ab initio data.
However, while these models excel at capturing local and semi-local
interactions, they often prove insufficient when an explicit and efficient
treatment of long-range interactions is required. To address this limitation,
we introduce Reciprocal-Space Attention (RSA), a framework designed to capture
long-range interactions in the Fourier domain. RSA can be integrated with any
existing local or semi-local MLIP framework. The central contribution of this
work is the mapping of a linear-scaling attention mechanism into Fourier space,
enabling the explicit modeling of long-range interactions such as
electrostatics and dispersion without relying on predefined charges or other
empirical assumptions. We demonstrate the effectiveness of our method as a
long-range correction to the MACE backbone across diverse benchmarks, including
dimer binding curves, dispersion-dominated layered phosphorene exfoliation, and
the molecular dipole density of bulk water. Our results show that RSA
consistently captures long-range physics across a broad range of chemical and
materials systems. The code and datasets for this work is available at
https://github.com/rfhari/reciprocal_space_attention

</details>


### [311] [First-Principles Exploration of Pentagonal TiN$_8$ and MoN$_8$ Monolayers as New Magnetic Topological Insulator](https://arxiv.org/abs/2510.13107)
*Zheng Wang,Beichen Ruan,Zhuoheng Li,Shu-Shen Lyu,Kaixuan Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 发现了一种新的二维五角形MN8单层材料家族，其中TiN8是陈数为-1的QAH绝缘体，MoN8是陈数为2的QAH绝缘体。


<details>
  <summary>Details</summary>
Motivation: 寻找具有量子反常霍尔效应的稳定且内在磁性的拓扑材料，以克服现有材料稳定性和合成复杂性的限制。

Method: 利用第一性原理计算，探索了二维五角形MN8单层材料家族中的涌现磁性和非平凡能带拓扑。

Result: 发现penta-MN8家族具有平面外的铁磁基态，并且TiN8表现出陈数为-1的QAH效应，MoN8表现出陈数为2的QAH效应。

Conclusion: penta-MN8家族为实现外来拓扑量子态提供了一个多功能平台，扩展了磁性拓扑绝缘体的材料范围，并为设计下一代自旋电子和量子计算器件奠定了理论基础。

Abstract: The quest for robust, intrinsically magnetic topological materials exhibiting
the quantum anomalous Hall (QAH) effect is a central challenge in condensed
matter physics and the application of revolutionary electronics. However,
progress has been hampered by the limited number of candidate materials, which
often suffer from poor stability and complex synthesis. Here, we introduce a
new paradigm by exploring the emergent magnetism and nontrivial band topology
in the largely overlooked family of two-dimensional (2D) pentagonal MN$_8$
monolayers. Employing first-principles calculations, we reveal that these
systems host out-of-plane ferromagnetic ground states, a key feature that
unlocks nontrivial topological properties driven by the localized $d$-orbitals
of the embedded transition metals. Remarkably, we identify TiN$_8$ as a QAH
insulator characterized by a Chern number of $C=-1$. Even more strikingly,
MoN$_8$ is predicted to be a rare high-Chern-number QAH insulator, boasting a
Chern number of $C=2$. Our findings establish the penta-MN$_8$ family as a
fertile and versatile platform for realizing exotic topological quantum states.
This work not only significantly expands the material landscape for magnetic
topological insulators but also provides a solid theoretical foundation for
designing next-generation spintronic and quantum computing devices.

</details>


### [312] [Energetic Origins of Competing Deformation Modes in Metastable Titanium Alloys](https://arxiv.org/abs/2510.13113)
*Ganlin Chen,Deepak V Pillai,Yufeng Zheng,Liang Qi*

Main category: cond-mat.mtrl-sci

TL;DR: 通过分子动力学模拟研究了亚稳态β-钛合金中变形机制的竞争与协作，揭示了孪晶的形成与β↔α''相变的可逆性有关，并确定了控制变形模式和孪晶取向的两个关键能量参数。


<details>
  <summary>Details</summary>
Motivation: 理解亚稳态β-钛合金在不同加载条件下的多重变形机制（相变、孪生、位错滑移）如何竞争与协作。

Method: 使用分子动力学（MD）模拟，研究了在不同温度、成分和加载条件下，亚稳态β-钛合金中竞争变形模式的成核行为。

Result: 揭示了孪晶路径通过β相和斜方α''相之间的可逆相变而产生。定量分析表明，主导变形机制和优先孪晶面的取向受两个关键能量参数控制：均匀β↔α''转变的自由能垒和特定相边界的失配应变能。

Conclusion: 两个能量参数（相变自由能垒和失配应变能）能够系统地随热力学和力学条件变化，从而解释模拟和实验中观察到的变形模式转变，并为设计下一代亚稳态合金提供了基于物理和计算的基础。

Abstract: Metastable alloys, such as $\beta$-phase titanium (Ti) alloys with a
body-centered cubic (BCC) lattice, can exhibit exceptional mechanical
properties through the interplay of multiple deformation mechanisms --
diffusionless phase transformations, deformation twinning, and conventional
dislocation slip. However, understanding how these mechanisms compete or
cooperate across a wide range of metastable alloys and loading conditions
remains a fundamental challenge. Here, we employ molecular dynamics (MD)
simulations to investigate the nucleation behavior of competing deformation
modes in metastable $\beta$-Ti alloys as a function of temperature,
composition, and loading conditions. We reveal that twinning pathways emerge
through reversible transformations between the $\beta$ phase and the
orthorhombic $\alpha"$ phase, in agreement with crystallographic theories.
Quantitative analyses demonstrate that the dominant deformation mechanisms and
preferred twinning-plane orientations are governed by two key energetic
parameters: the free energy barrier for homogeneous $\beta \leftrightarrow
\alpha"$ transformations and the misfit strain energy along specific phase
boundaries. These energetic quantities vary systematically with thermodynamic
and mechanical conditions, thereby rationalizing the deformation mode
transitions observed in both simulations and experiments. These energetic
metrics offer a physically grounded and computationally tractable basis for
designing next-generation metastable alloys.

</details>


### [313] [Melting phase relation of seifertite and pyrite-type SiO2 determined by machine learning potentials](https://arxiv.org/abs/2510.13119)
*Doyoon Park,Xin Deng,Jie Deng*

Main category: cond-mat.mtrl-sci

TL;DR: 使用机器学习模拟预测了SiO2在高压下的相变，并发现了可能影响超级地球宜居性的地幔对流模式。


<details>
  <summary>Details</summary>
Motivation: SiO2（二氧化硅）在工业技术和行星科学中都至关重要，但其高压多晶型相的关系尚不清楚。

Method: 开发了两种机器学习势（MLP），能够准确表示SCAN和PBEsol交换-相关函数在宽温压范围内的行为。利用这些势进行大规模两相模拟，确定了seifertite和黄铁矿型SiO2的熔化曲线，并推断了这两相之间的固-固相边界。

Result: SCAN函数比PBEsol函数更准确地预测了SiO2的结构和热力学性质，预测的熔化温度高6-10%，seifertite到黄铁矿型相变压力高22%。该相变的Clapeyron斜率（-6.1 MPa/K）强烈为负。

Conclusion: 机器学习模拟结果表明，地幔对流在超级地球上可能是高度分层的，这可能影响其长期热演化和宜居性。

Abstract: Silica (SiO2) is fundamental to both industrial technology and planetary
science, yet the phase relations of its high-pressure polymorphs remain poorly
constrained. Here, we develop two machine learning potentials (MLPs) for SiO2
that faithfully represent the SCAN and PBEsol exchange-correlation functionals
over a wide temperature (1000-10000 K) and pressure (100-400 GPa) range using
deep neural networks. With large-scale two-phase simulations powered by these
potentials, we determine the melting curves of seifertite and pyrite-type SiO2
and infer the solid-solid phase boundary between these two phases. The SCAN
functional, which captures intermediate-range van der Waals interactions,
reproduces structural and thermodynamic properties with high fidelity,
predicting melting temperatures 6-10 % higher and a seifertite to pyrite-type
transition pressure 22 % higher than the PBEsol. The strongly negative
Clapeyron slope (-6.1 MPa/K) of this transition suggests that mantle convection
could be highly layered in super-Earth exoplanets, potentially affecting their
long-term thermal evolution and habitability.

</details>


### [314] [Thermal and Electrical Properties of (Cr,Mo,Ta,V,W)C High-Entropy Carbide Ceramics](https://arxiv.org/abs/2510.13130)
*Ali Sarikhani,Steven M. Smith,Suzana Filipovic,William G. Fahrenholtz,Gregory E. Hilmas*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了全致密(Cr, Mo, Ta, V, W)C 高熵碳化物陶瓷的合成、表征及其性质。


<details>
  <summary>Details</summary>
Motivation: 研究全致密(Cr, Mo, Ta, V, W)C 高熵碳化物陶瓷的合成、表征及其性质。

Method: 通过碳热还原法从金属氧化物和碳粉合成陶瓷，然后进行不同温度下的放电等离子烧结致密化。

Result: 随着致密化温度升高，晶粒生长且晶格参数增大。热扩散率随测试温度线性增加，热导率在室温和200°C时分别约为7 W m⁻¹ K⁻¹ 和 12 W m⁻¹ K⁻¹。测量值与基于Neumann-Kopp规则的理论估计值相符。室温电阻率随过量碳的减少（从5.4%降至0.1%）从137降至120 μΩ·cm，表明过量碳的减少增强了导热的电子贡献。所有样品在0.49 N 载荷下维氏硬度约为29 GPa。

Conclusion: 研究结果表明该高熵碳化物体系具有可调性。

Abstract: The synthesis and characterization, along with the resulting properties, of
fully dense \((\mathrm{Cr, Mo, Ta, V, W})\mathrm{C}\) high-entropy carbide
ceramics were studied. The ceramics were synthesized from metal oxide and
carbon powders by carbothermal reduction, followed by spark plasma sintering at
various temperatures for densification. Increasing the densification
temperature resulted in grain growth and an increase in the lattice parameter.
Thermal diffusivity increased linearly with testing temperature, resulting in
thermal conductivity values ranging from approximately
\(7~\mathrm{W\,m^{-1}\,K^{-1}}\) at room temperature to
\(12~\mathrm{W\,m^{-1}\,K^{-1}}\) at \(200~^\circ\mathrm{C}\). Measured heat
capacity values matched theoretical estimates made using the Neumann--Kopp
rule. Room-temperature electrical resistivity decreased from \(137\) to
\(120~\mu\Omega\cdot\mathrm{cm}\) as the excess carbon decreased from \(5.4\)
to \(0.1~\mathrm{vol\%}\), suggesting an enhanced electronic contribution to
thermal conductivity as excess carbon decreased. All specimens exhibited a
Vickers hardness of approximately \(29~\mathrm{GPa}\) under a
\(0.49~\mathrm{N}\) load. These results underscore the tunability of this
high-entropy carbide system.

</details>


### [315] [The nature of polar distortions in ferroelectrics](https://arxiv.org/abs/2510.13185)
*Hong Jian Zhao,Laurent Bellaiche,Yanming Ma*

Main category: cond-mat.mtrl-sci

TL;DR: 极性畸变通常表现出混合性质，而非单一性质。


<details>
  <summary>Details</summary>
Motivation: 区分和理解铁电体中极性畸变的机制，特别是复杂铁电体（如极性斜锆石）。

Method: 提出并应用一种定制的图论方法来阐明复杂铁电体中极性畸变的性质。

Result: 成功区分了钙钛矿超晶格中的混合正常-非正常性质，并解决了极性斜锆石的争议，确认了其混合触发-非正常性质。

Conclusion: 提出的图论方法能够揭示复杂铁电体中极性畸变的混合性质，为理解铁电物理概念和发现新铁电体提供了新视角。

Abstract: Polar distortion, the collective off-center displacements of atoms, is a
fingerprint of a ferroelectric that governs its properties and functionalities.
Since the 1970s, the concepts of proper, improper and triggered ferroelectrics
have been established to shed light on a diversity of polar distortion
mechanisms. Such concepts assign a single nature to polar distortion and are
helpful to interpret how polar distortions occur in conventional ferroelectrics
such as barium titanate. However, applying these concepts to complex
ferroelectrics (e.g., polar orthorhombic hafnia) is notoriously challenging and
can yield highly controversial arguments. Here we resolve this issue by
developing a tailor-made graph theory for clarifying the nature of polar
distortions in complex ferroelectrics, which emphasizes that polar distortions
in such ferroelectrics usually exhibit multiple natures among proper, improper
and triggered characteristics. We demonstrate the robustness of our theory by
working with perovsktie superlattices and polar orthorhombic hafnia (i.e., two
representative cases). We successfully identify the mixed proper-improper
nature in perovsktite superlattices and reconcile the controversy on polar
orthorhombic hafnia by confirming its mixed trigger-improper nature. Our work
will definitely lead to a revisitation of concepts in ferroelectric physics and
provide opportunities for discovering novel ferroelectrics and related
phenomena.

</details>


### [316] [Towards Universal Material Property Prediction with Deep Learning and Single-Descriptor electronic Density](https://arxiv.org/abs/2510.13207)
*Feng Chen,Shu Li,Xin Chen,Dennis Wong,Biplab Sanyal,Duo Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习方法在材料设计中应用广泛，但存在可迁移性差的问题。本文提出了一种基于电子电荷密度描述符的通用机器学习框架，可用于预测多种材料属性，并展示了出色的多任务学习能力和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在材料设计中存在可迁移性差、难以同时预测多种材料属性的问题，主要是因为材料属性由核和电子等多个自由度及其复杂相互作用决定。

Method: 提出了一种基于电子电荷密度描述符的通用机器学习框架，该框架仅基于物理学原理和理论上严格的描述符。

Result: 该框架能够准确预测八种不同的材料属性（R² 值高达 0.94），并展示了出色的多任务学习能力，在引入更多目标属性进行单一训练过程时，预测准确性会提高，表明其具有出色的可迁移性。

Conclusion: 本文提出的通用机器学习框架是实现统一预测所有材料属性的长期目标的重要一步。

Abstract: Owing to its high scalability and computational efficiency, machine learning
methods have been increasingly integrated into various scientific research
domains, including ab initio-based materials design. It has been demonstrated
that, by incorporating modern machine learning algorithms, one can predict
material properties with practically acceptable accuracy. However, one of the
most significant limitations that restrict the widespread application of
machine learning is its lack of transferability, as a given framework is
typically applicable only to a specific property. The origin of this limitation
is rooted in the fact that a material's properties are determined by multiple
degrees of freedom -- and their complex interplay -- associated with nuclei and
electrons, such as atomic type, structural symmetry, and the number and quantum
states of the valence electrons, among others. The inherent complexity rules
out the possibility of a single machine learning framework providing a full
description of these critical quantities. In this paper, we develop a universal
machine learning framework based solely on a physically grounded and
theoretically rigorous descriptor -- electronic charge density. Our framework
not only enables accurate prediction of eight different material properties
(with R$^2$ values up to 0.94), but also demonstrates outstanding multi-task
learning capability, as prediction accuracy improves when more target
properties are incorporated into a single training process, thereby indicating
excellent transferability. These results represent a significant step toward
realizing the long-standing goal of a universal machine learning framework for
the unified prediction of all material properties.

</details>


### [317] [Angular Emission Properties of Strained Transition-Metal Dichalcogenides](https://arxiv.org/abs/2510.13420)
*Lee Grimberg,Svyatoslav Kostyukovets,Moshe G. Harats*

Main category: cond-mat.mtrl-sci

TL;DR: 应变会改变过渡金属硫属化物单层的发光特性，但低应变下的行为（<1%）与高应变下的行为不同，其发光强度与基板曲率相关。


<details>
  <summary>Details</summary>
Motivation: 研究在低应变下过渡金属硫属化物单层光致发光强度的奇怪行为，并揭示其背后的物理机制。

Method: 通过实验测量和时域有限差分模拟，研究光致发光强度与应变、基板曲率的关系。

Result: 发现在低应变下，光致发光强度的变化主要由基板曲率决定，而不是带隙变化。

Conclusion: 选择合适的基板对于基于过渡金属硫属化物的柔性器件至关重要。

Abstract: Monolayers of transition-metal dichalcogenides have shown that uniaxial
strain changes both the photoluminescence emission energy and intensity. The
changes are attributed to the band-structure evolution under tensile strain
where both the bandgap decreases and a direct-to-indirect transition occurs.
This was shown for relatively high strains, whereas this is not the case at low
strain values $<1\%$ in which in this work, we observe the erratic dependency
of the photoluminescence intensity at low strain values as a function of
strain. We find that the dominant physical property is the dependence of the
optical-dipole emission on the curvature of the substrate. We validate the
behavior of the photoluminescence intensity with experimental angular emission
spectroscopy (k-space imaging). These findings are supported by
Finite-Difference Time-Domain simulations, in agreement with the experimental
data. Our findings present the importance of choosing the right substrate for
flexible devices based on transition-metal dichalcogenides.

</details>


### [318] [Colossal Cryogenic Electro-Optic Response Through Metastability in Strained BaTiO$_{3}$ Thin Films](https://arxiv.org/abs/2510.13256)
*Albert Suceava,Sankalpa Hazra,Aiden Ross,Ian Reed Philippi,Dylan Sotir,Brynn Brower,Lei Ding,Yingxin Zhu,Zhiyu Zhang,Himirkanti Sarkar,Saugata Sarker,Yang Yang,Suchismita Sarker,Vladimir A. Stoica,Darrell G. Schlom,Long-Qing Chen,Venkatraman Gopalan*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The search for thin film electro-optic (EO) materials that can retain
superior performance under cryogenic conditions has become critical for quantum
computing. Barium titanate thin films show large linear EO coefficients in the
tetragonal phase at room temperature, which is severely degraded down to ~200
pm V$^{-1}$ in the rhombohedral phase at cryogenic temperatures. There is
immense interest in manipulating these phase transformations and retaining
superior EO properties down to liquid helium temperature. Utilizing the
thermodynamic theory of optical properties, a large low-temperature EO response
is designed by engineering the energetic competition between different
ferroelectric phases, leading to a low-symmetry monoclinic phase with a massive
EO response. The existence of this phase is demonstrated in a strain-tuned
BaTiO$_{3}$ thin film that exhibits a linear EO coefficient of 2516 +/- 100 pm
V$^{-1}$ at 5 K, which is an order of magnitude higher than the best reported
performance thus far. Importantly, the EO coefficient increases by 100x during
cooling, unlike the conventional films, where it degrades. Further, at the
lowest temperature, significant higher order EO responses also emerge. These
results represent a new framework for designing materials with property
enhancements by stabilizing highly tunable metastable phases with strain.
  Copyright 2025 The Author(s). Advanced Materials published by Wiley-VCH GmbH.
This is an open access article under the terms of the Creative Commons
Attribution License, which permits use, distribution and reproduction in any
medium, provided the original work is properly cited. (A. Suceava, S. Hazra, A.
Ross, et al. "Colossal Cryogenic Electro-Optic Response Through Metastability
in Strained BaTiO3 Thin Films." Adv. Mater. (2025): e07564.
https://doi.org/10.1002/adma.202507564)

</details>


### [319] [Surface Properties of Ga-Cu Based Liquid-Metal Alloys: Impact of Cu Dilution Topography and Reaction Conditions](https://arxiv.org/abs/2510.13286)
*Tzung-En Hsieh,Michael S. Moritz,Andreas Mölkner,Christoph Wichmann,Johannes Frisch,Julien Steffen,Caiden J. Parker,Vaishnavi Krishnamurthi,Torben Daeneke,Hans-Peter Steinrück,Andreas Görling,Christian Papp,Marcus Bär*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用XPS/UPS和ML-FF计算研究了Ga-Cu液态金属合金的表面性质，并探讨了Cu含量、温度变化对其表面特性的影响，以及Ga-Ag和Ga-Au体系的类似性质，旨在为非均相催化中低熔点液态金属的研发提供参考。


<details>
  <summary>Details</summary>
Motivation: 研究Ga-Cu基液态金属合金的表面性质，特别关注Cu在Ga基体中的稀释效应，以及在SCALMS反应条件下的性质演变，旨在为开发用于非均相催化的液态金属提供基础。

Method: 利用X射线和紫外光电子能谱（XPS/UPS）以及机器学习力场（ML-FF）计算，详细研究了不同Cu含量的Ga-Cu模型样品的表面特性。通过XPS/UPS测量不同温度下（100-500 oC）的样品，并结合透射电子显微镜（TEM）图像和ML-FF模拟，分析了Cu含量、温度和局部环境对Cu 2p核心能级和d带的影响。此外，还研究了Ga-Ag和Ga-Au模型体系以验证研究结果的普适性。

Result: 随着Cu含量的降低，Ga-Cu模型的Cu 2p核心能级向更高的结合能移动，d带也相应移动并变窄，这归因于位点隔离效应。在升温条件下（100-500 oC），Cu 2p向较低结合能移动，这可能与局部环境变化（如键长伸长）有关，ML-FF模拟支持了这一推测。低温下Cu表面含量的增加归因于富Cu金属间化合物的存在，TEM图像证实了这一点。研究还发现Ga-Ag和Ga-Au体系也表现出类似的性质。

Conclusion: Ga-Cu液态金属合金的表面性质受Cu含量和温度影响显著，其表面特性的变化与位点隔离、局部环境变化以及金属间化合物的形成有关。这些发现有助于理解液态金属在催化应用中的行为，为开发新型催化剂提供指导。

Abstract: We studied the surface properties of Ga-Cu based liquid metal alloys, a
promising material system for supported catalytically active liquid metal
solutions (SCALMS). The impact of Cu dilution in the (liquid) Ga matrix is
in-detail investigated by X-ray and UV photoelectron spectroscopy (XPS/UPS) and
Machine-Learned-Force Field (ML-FF) calculations. With decreasing Cu content,
microscopic and macroscopic Ga-Cu model samples exhibit a shift of the Cu 2p
core level line to higher binding energies (Eb) as well as a correspondingly
shifted and narrowed d-band with respect to pure Cu, which we ascribe to site
isolation. To study the property evolution of Ga-Cu at SCALMS reaction
conditions, i.e., where Cu is present in liquid Ga, additional XPS measurements
were performed between 100 and 500 oC. The observed Cu 2p shift to lower Eb is
tentatively ascribed to changes in the local environment with increasing
temperature, i.e. bond elongation, which is corroborated by ML-FF simulations.
The increased Cu surface content at low temperatures is attributed to the
presence of crystallized Cu-rich intermetallic compounds, as evidenced by
transmission electron microscopy images. In an attempt to generalize the
findings for filled d-band transition metals (TMs) in liquid Ga also Ga-Ag and
Ga-Au model systems were investigated. The observed insights may be another
step of paving the way for an insight-driven development of low-temperature
melting liquid metals for heterogeneous catalysis.

</details>


### [320] [Isothermal Annealing Effects on $β$-Relaxations and Crystallization Behaviors in Amorphous GeTe](https://arxiv.org/abs/2510.13313)
*Arune Makareviciute,Qun Yang,Tomoki Fujita,Oliver Gross,Nico Neuber,Maximilian Frey,Jens Moesgaard,Cecile Chaxel,Julian Pries,Mads Ry Vogel Jørgensen,Frederik Holm Gjørup,Matthias Wuttig,Hai-bin Yu,Jiangjing Wang,Shuai Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 玻璃形成材料中的β-松弛过程是影响原子动力学的重要因素。尽管在Ge15Sb85中抑制β-松弛可以减缓结晶动力学，但在Ge15Te85中，类似的退火处理效果不佳。本研究旨在探究GeTe合金中的β-松弛及其对结晶动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 研究GeTe合金中的β-松弛现象，并阐明其对结晶动力学的影响，尤其是在退火处理后。

Method: 采用粉末力学动态谱研究退火对GeTe合金β-松弛的影响；结合超快量热分析和时间分辨光学反射测量来评估退火对结晶行为的影响；通过同步X射线散射实验探究退火对非晶结构的影响。

Result: 退火处理能够有效抑制GeTe合金中的β-松弛（表现为损耗模量中过量翼的减小）；退火后的GeTe样品结晶行为变得缓慢且随机性降低；退火处理增强了非晶结构中的类Peierls扭曲，并减缓了结晶动力学。

Conclusion: 在退火GeTe合金中，结晶过程受到晶体生长速率的限制，而β-松弛的抑制减缓了这一生长速率，从而减缓了整体结晶动力学。

Abstract: A secondary $\beta$-relaxation process is often the dominant source of atomic
dynamics below $T_\mathrm{g}$ in many glass forming systems. Recent studies
reported the presence of $\beta$-relaxations in amorphous phase-change
materials (PCMs) and showed that suppressing the $\beta$-relaxation via
annealing in Ge$_{15}$Sb$_{85}$ can effectively slow down its crystallization
kinetics. Yet, when Sb is replaced by Te, similar annealing protocol has little
effect on the Te-rich alloy Ge$_{15}$Te$_{85}$. Here, we investigate amorphous
GeTe that is a Sb-free PCM, but with faster crystallization kinetics than
Ge$_{15}$Te$_{85}$. Using powder mechanical dynamic spectroscopy, we observe a
clear reduction of the excess-wing in the loss modulus upon isothermal
annealing, indicating a suppression of its $\beta$-relaxation. Ultrafast
calorimetric analysis and time-resolved optical reflectivity measurements show
that, whereas as-deposited GeTe exhibit stochastic crystallization behaviors,
annealed samples crystallize more slowly with reduced stochasticity.
Synchrotron X-ray scattering experiments reveal reinforced Peierls-like
distortions in the amorphous structure after annealing, and demonstrate that,
even if annealing introduces nucleation sites, it nonetheless slows down
crystallization kinetics. These finding suggests that, in annealed GeTe,
crystallization is limited by crystal growth rate, which is retarded through
the suppression of $\beta$-relaxation.

</details>


### [321] [Tuning the non-linear interactions of hybrid interlayer excitons in bilayer MoS2 via electric fields](https://arxiv.org/abs/2510.13314)
*Mathias Federolf,Alexander Steinhoff,Monika Emmerling,Matthias Florian,Christian Schneider,Sven Höfling*

Main category: cond-mat.mtrl-sci

TL;DR: 双层MoS2中的混合层间激子因其固有的偶极子特性（结合了面内和面外偶极矩）而在非线性光学领域具有潜力。本研究直接探测了混合层间激子的非线性激子-激子相互作用。通过施加外部面外电场，我们极化激子以增强其相互偶极相互作用，从而故意使这些排斥性贡献相对于竞争性的吸引性多体修正占优。我们还建立了这些效应的完全微观理论描述，以解释核心实验结果。与零场情况相比，调谐产生了显著更大的蓝移，并有望开辟在排斥性和吸引性相互作用势之间切换的途径。我们的发现表明，可以通过外部电场调谐强非线性效应，从而在仅通过密度调谐之外，为激子相互作用提供一种新的控制方式。


<details>
  <summary>Details</summary>
Motivation: 双层MoS2中的混合层间激子在非线性光学领域具有潜力，但对其非线性激子-激子相互作用的理解尚不充分。

Method: 施加外部面外电场以极化激子，增强其偶极相互作用，并建立微观理论描述。

Result: 施加电场可显著增大蓝移，表明激子-激子相互作用增强，并为在排斥性和吸引性相互作用势之间切换提供了可能。

Conclusion: 可以通过外部电场调谐强非线性效应，为控制激子相互作用提供除了密度调谐之外的新方法。

Abstract: Hybrid interlayer excitons in bilayer MoS2 are a promising platform for
nonlinear optics due to their intrinsic dipolar character, which combines
in-plane and out-ofplane dipole moments. In this work, we directly probe the
nonlinear exciton-exciton interactions of hybrid interlayer excitons. By
applying an external out-of-plane electric field, we polarize the excitons to
enhance their mutual dipolar interactions, thereby deliberately favoring these
repulsive contributions over competing attractive manybody corrections. We
furthermore establish a fully microscopic theoretical description of these
effects to explain the core experimental results. The tuning results in a
significantly larger blueshift compared to the zero-field case and
perspectively opens an avenue to even switch between repulsive and attractive
interaction potentials. Our findings establish that strong nonlinearities can
be tuned via an external electric field, providing a new degree of control over
exciton interactions beyond density tuning alone.

</details>


### [322] [Integration of imprint-free and low coercivity ferroelectric BaTiO3 thin films on silicon](https://arxiv.org/abs/2510.13435)
*Jingtian Zhao,Beatriz Noheda,Martin F. Sarott*

Main category: cond-mat.mtrl-sci

TL;DR: 高度结晶的铁电氧化物在硅上的集成有望实现高能效的存储和逻辑技术。然而，这种材料的表观应变工程在硅上受到严重阻碍，因为大的结构失配通常会导致界面质量较差并引起铁电开关特性的退化。本研究通过在 SrTiO3 缓冲的硅上插入 SrSn1-xTixO3 层，实现了单晶 BaTiO3 薄膜在硅上的生长，该薄膜表现出无重影开关、低矫顽力、高剩余极化以及在超过 10^10 次开关循环中无疲劳。该层充当了伪衬底，缓解了硅衬底对 BaTiO3 层的热应变，同时提供了适度的压缩应变，从而稳定了纯粹的平面外极化。因此，这项工作为制造用于非易失性存储器应用的、与硅兼容的、低功耗的铁电器件铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 在硅上利用外延应变工程集成高度结晶的铁电氧化物，以实现高能效的存储和逻辑技术，但由于结构失配导致界面质量差和铁电开关特性退化。

Method: 通过在 SrTiO3 缓冲的硅上插入 SrSn1-xTixO3 层，缓解了硅衬底对 BaTiO3 层的热应变，并提供了适度的压缩应变，从而稳定了纯粹的平面外极化。

Result: 实现了单晶 BaTiO3 薄膜在硅上的生长，表现出无重影开关、低矫顽力、高剩余极化以及在超过 10^10 次开关循环中无疲劳。

Conclusion: 通过使用 SrSn1-xTixO3 层作为伪衬底，成功地在硅上制备了高质量的 BaTiO3 薄膜，为制造与硅兼容的、低功耗的铁电非易失性存储器器件提供了可能性。

Abstract: Highly-crystalline ferroelectric oxides integrated on Si hold great promise
for energy-efficient memory and logic technologies. Exploiting epitaxial strain
engineering in these materials is, however, severely hampered on Si, where the
large structural mismatch often results in an inferior interfacial quality and
causes a degradation of the ferroelectric switching characteristics. In this
work, we present the growth of single-crystalline BaTiO3 thin films on Si,
exhibiting imprint-free switching, low coercivity, high remanent polarization,
and no fatigue for over $10^{10}$ switching cycles. We accomplish this via the
insertion of a SrSn1-xTixO3 layer on SrTiO3-buffered Si. This layer serves as a
pseudo substrate that alleviates the thermal strain that the Si substrates
imposes on the BaTiO3 layer, while simultaneously providing moderate
compressive strain that stabilizes a pure out-of-plane polarization. Thus, our
work paves the way toward the fabrication of Si-compatible, low-power-consuming
ferroelectric devices for non-volatile memory applications.

</details>


### [323] [Computational Insights into Defect Induced Modulation in Electronic Properties of 2D Nitride Monolayers](https://arxiv.org/abs/2510.13440)
*Shreya G. Sarkar,Kuneh Parag Shah,Brahmananda Chakraborty*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究系统地研究了2D氮化物材料（h-BN、g-C3N4、BeN4）中空位缺陷（特别是氮空位和构成原子空位）对电子性质的影响。研究发现，氮空位的引入会显著改变这些材料的电子特性，例如在h-BN中，氮空位会大大降低功函数和带隙，使其趋向于半金属行为，并出现近费米能级的平带，表明存在强烈的电子-电子相互作用。在g-C3N4中，氮空位也会导致功函数和带隙的降低，双重氮空位甚至使材料接近金属性。而在BeN4中，氮空位对电荷分布的影响很小，功函数略有增加。研究结果强调了空位工程在调控2D氮化物材料电子性质方面的潜力，为设计具有定制功函数和带隙的材料提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 研究2D氮化物材料（h-BN、g-C3N4、BeN4）的电子性质，特别是研究空位缺陷（特别是氮空位和构成原子空位）对其电子性质的影响，旨在探索空位工程在调控这些材料的功函数和带隙方面的潜力，为光电子、自旋电子和催化等领域的应用提供材料设计思路。

Method: 通过理论计算系统地研究了h-BN、g-C3N4和BeN4三种2D氮化物材料中，引入氮空位和构成原子空位后对其电子性质（如功函数、带隙、能带结构和电荷分布）的影响。

Result: 在h-BN中，氮单空位将功函数从5.97 eV降低到3.45 eV，带隙从4.6 eV降低到0.64 eV，并出现近费米能级的平带。在g-C3N4中，氮空位降低了功函数和带隙，双重氮空位使材料接近金属性。在BeN4中，氮空位对电荷分布的影响很小，功函数略有增加。

Conclusion: 空位工程是调控2D氮化物材料电子性质的有效手段，通过引入氮空位可以显著调控h-BN、g-C3N4和BeN4的功函数和带隙，为设计具有特定功能的2D材料提供了理论指导。

Abstract: Two-dimensional (2D) nitride materials such as hexagonal boron nitride
(h-BN), graphitic carbon nitride (g-C$_3$N$_4$), and beryllonitrene (BeN$_4$)
have emerged as promising candidates for next generation electronic,
optoelectronic, and energy applications due to their unique structural and
electronic properties. This study presents a systematic investigation of the
effects of vacancy defect, specifically the role of nitrogen and constituent
atom vacancies on the electronic properties of these materials. Our findings
reveal that the introduction of nitrogen vacancies significantly alters the
electronic characteristics of these materials. In h-BN, the presence of a
nitrogen monovacancy significantly lowers the work function from 5.97 eV to
3.45 eV, one of the lowest values reported for any 2D material. Additionally,
this defect reduces the band gap from 4.6 eV to 0.64 eV, driving the material
toward half-metallic behavior. This is accompanied by the emergence of flat
bands near the Fermi level, indicative of strong electron-electron
interactions. In g-C$_3$N$_4$, nitrogen vacancies lead to a decrease in work
function and band gap, with double nitrogen vacancies rendering the material
nearly metallic. In BeN$_4$, nitrogen vacancies result in minimal charge
redistribution and a slight increase in work function, highlighting the
material's unique electronic behavior. These results underscore the potential
of vacancy engineering in tuning the electronic properties of 2D nitride
materials, offering avenues for the design of materials with tailored work
functions and band gaps for applications in optoelectronics, spintronics, and
catalysis.

</details>


### [324] [Unraveling the Corrosion Mechanism of Boro-Alumino-Phospho-Silicate Glass: Advanced Insights from Solid-State NMR Spectroscopy](https://arxiv.org/abs/2510.13545)
*Muhammad Amer Khan,Lili Hu,Shubin Chen,Yongchun Xu,Jinjun Ren*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用固态核磁共振（SSNMR）和扫描电子显微镜（SEM）技术，揭示了硼铝磷硅酸盐玻璃（BAPS）在水环境中腐蚀过程中非均相相分离和原位转化机制，反驳了传统的溶解-沉淀模型。


<details>
  <summary>Details</summary>
Motivation: 玻璃和矿物的腐蚀机制研究对于理解材料在不同环境下的耐久性至关重要，特别是其在水环境中形成非晶态蚀变层的机制仍然存在争议。

Method: 采用先进的固态核磁共振（SSNMR）和扫描电子显微镜（SEM）技术，研究了硼铝磷硅酸盐玻璃（BAPS）的腐蚀行为。

Result: 结果表明，玻璃发生均匀的纳米级相分离，形成富铝磷域和富铝硅域。腐蚀过程中，富铝磷域发生凝胶化，而富铝硅域保持玻璃态，两者共同组成凝胶层。SEM图像显示的清晰界面与溶解-沉淀机制相悖，相共存提供了反对该机制的证据。

Conclusion: 提出了一种由化学反应控制的原位转化机制，包括富铝磷域优先水解形成多孔凝胶区、水渗透到网络空间以及磷选择性浸出导致凝胶网络重组。

Abstract: Corrosion mechanism of minerals and glass is a critical study domain in
geology and materials science, vital for comprehending material durability
under various environmental conditions. Despite decades of extensive study, a
core aspect of these mechanisms - specifically, the formation of amorphous
alteration layers upon exposure to aqueous environments - remains
controversial. In this study, the corrosion behavior of a
boro-alumino-phospho-silicate glass (BAPS) was investigated using advanced
solid-state nuclear magnetic resonance (SSNMR) and SEM techniques. The results
reveal a uniform nanoscale phase separation into Al-P-rich and Al-Si-rich
domains. During corrosion, the Al-P-rich domain undergoes gelation, whereas the
Al-Si-rich domain remains vitreous, forming a gel layer comprised of both
phases. Although SEM images show a sharp gel/glass interface - suggestive of a
dissolution-precipitation mechanism - the phase coexistence within the gel
layer provides definitive evidence against such a mechanism. Instead, we
propose an in situ transformation mechanism governed by chemical reactions,
involving: (i) preferential hydrolysis of Al-P-rich domain leading to porous
gel regions; (ii) retention of Al-Si glass domains within the gel layer, with
water infiltrating inter-network spaces; and (iii) selective leaching of
phosphorus over aluminum, leading to reorganization of the gel network.

</details>


### [325] [Ultrafast exciton polaron dynamics in 2D Ruddlesden Popper lead halide perovskites](https://arxiv.org/abs/2510.13547)
*Anirban Mondal,Kwang Jin Lee,Seungmin Lee,Oui Jin Oh,Myeongsam Jen,Jun Hong Noh,Jong Min Lim,Minhaeng Cho*

Main category: cond-mat.mtrl-sci

TL;DR: 2D RP 杂化钙钛矿比 3D 钙钛矿更稳定，但其准粒子动力学研究不足。本文使用飞秒瞬态吸收光谱系统研究了单层 2D RP 钙钛矿中自由激子 (FE) 和激子极化子 (EP) 的分支、动力学和相互作用。通过改变有机间隔基和制备方法，我们发现 EP 结合能与间隔基有关，并且 FE 和 EP 之间存在持续数十皮秒的动态平衡。新制备方法得到的薄膜表现出更弱的俄歇湮灭和更少的声子瓶颈效应，这与更少的陷阱和杂质有关。通过耦合速率方程模型，我们量化了载流子弛豫、激子-激子湮灭、激子-声子耦合和 FE-EP 相互转化等过程。


<details>
  <summary>Details</summary>
Motivation: 相较于三维钙钛矿，二维 RP 杂化钙钛矿具有更高的化学和结构稳定性，在下一代光电子领域具有应用潜力。然而，目前对二维钙钛矿的准粒子动力学研究尚不充分。

Method: 使用可见光范围内的飞秒瞬态吸收光谱技术，研究了单层二维 RP 钙钛矿中自由激子 (FE) 和激子极化子 (EP) 的分支、动力学和相互作用。通过改变有机间隔基和制备方法来制备薄膜，并进行比较分析。

Result: 我们发现 (BA)2PbI4 的 EP 结合能为 50-65 meV，(PEA)2PbI4 的 EP 结合能为 37-39 meV，这与通过 FTIR 证实的、与间隔基有关的耦合一致。我们揭示了 FE 和 EP 之间持续数十皮秒的动态平衡。值得注意的是，不同制备路线得到的薄膜在瞬态吸收光谱上表现出差异：新制备方法的薄膜表现出更弱的俄歇湮灭和更少的声子瓶颈效应，这与其中更少的陷阱和杂质相吻合。耦合速率方程模型能够很好地复现实验结果，并量化了热载流子弛豫、激子-激子湮灭、激子-声子耦合和 FE-EP 相互转化等过程。

Conclusion: 化学合成过程（制备路线）和间隔基的选择显著影响 EP 的稳定性和种群平衡，为调控二维钙钛矿的超快光物理性质提供了实际手段，并为设计先进的光电子器件提供了指导。

Abstract: Two dimensional Ruddlesden Popper (2D) RP hybrid perovskites exhibit
substantially higher chemical and structural stability than their three
dimensional (3D) counterparts, positioning them as promising candidates for
next generation optoelectronics. While quasiparticle dynamics in 3D perovskites
are well studied, their 2D analogues remain comparatively underexplored. Here
we systematically investigate the branching, dynamics, and interactions of free
excitons (FEs) and exciton polarons EPs in monolayer 2D RP perovskites using
visible range femtosecond transient absorption TA spectroscopy. We prepared
monolayer 2D RP perovskite thin films with varied organic spacers and distinct
fabrication routes for comparative analysis. We find that the EP binding energy
is 50 65 meV in (BA)2PbI4 and 37 39 meV in (PEA)2PbI4, consistent with spacer
layer dependent coupling as corroborated by FTIR. We reveal a dynamic
equilibrium between FEs and EPs that persists for tens of picoseconds. Notably,
the TA signatures differ by fabrication route films from the newly developed
process show weaker Auger annihilation and a reduced hot phonon bottleneck than
those from the conventional route trends consistent with fewer traps and
impurities in the former. Coupled rate equation modeling reproduces the
transients and quantifies the processes of hot carrier relaxation, exciton
exciton annihilation, exciton phonon coupling, and FE EP interconversion. These
results demonstrate that the chemical synthetic process (fabrication route) and
spacer choice significantly influence EP stability and population balance,
offering practical levers for engineering ultrafast photophysics in 2D
perovskites and guiding the design of advanced optoelectronic devices.

</details>


### [326] [Strain-induced Moiré Reconstruction and Memorization in Two-Dimensional Materials without Twist](https://arxiv.org/abs/2510.13699)
*Nazmul Hasan,Tara Peña,Aditya Dey,Dongyoung Yoon,Zakaria Islam,Yue Zhang,Maria Vitoria Guimaraes Leal,Arend M. van der Zande,Hesam Askari,Stephen M. Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过控制非扭曲二维材料的逐层应变（异质应变）产生莫尔干涉，克服了传统机械堆叠法制备莫尔材料的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统通过机械堆叠法制备莫尔材料存在良率低、均一性差、重复性差等问题，限制了其在新型量子材料发现和器件制造中的应用。

Method: 提出通过沉积有应力薄膜到非扭曲二维材料上，施加逐层应变（异质应变）的方法，产生由应变诱导的晶格失配，从而形成莫尔干涉。通过控制应力薄膜的力（厚度x应力）和几何形状，可以精确控制莫尔条纹的周期和对称性。

Result: 实现了非扭曲二维多层和双层材料中莫尔干涉条纹周期和对称性的确定性控制，良率达到97%。即使在去除应力薄膜后，莫尔重构效应依然存在。该方法耗时短，且独立于用户技能。

Conclusion: 该技术通过引入应变自由度，为探索新型可调莫尔几何对称性提供了新的途径，有望解决莫尔量子材料发现的瓶颈问题，并实现工业化生产二维莫尔基电子或光学器件。

Abstract: Two-dimensional (2D) materials with a twist between layers exhibit a moir\'e
interference pattern with larger periodicity than any of the constituent layer
unit cells. In these systems, a wealth of exotic phases appear that result from
moir\'e-dependent many-body electron correlation effects or non-trivial band
topology. One problem with using twist to generate moir\'e interference has
been the difficulty in creating high-quality, uniform, and repeatable samples
due to fabrication through mechanical stacking with viscoelastic stamps. Here
we show, a new method to generate moir\'e interference through the controlled
application of layer-by-layer strain (heterostrain) on non-twisted 2D
materials, where moir\'e interference results from strain-induced lattice
mismatch without twisting or stacking. Heterostrain generation is achieved by
depositing stressed thin films onto 2D materials to apply large strains to the
top layers while leaving layers further down less strained. We achieve
deterministic control of moir\'e periodicity and symmetry in non-twisted 2D
multilayers and bilayers, with 97% yield, through varying stressor film force
(film thickness X film stress) and geometry. Moir\'e reconstruction effects are
memorized after the removal of the stressor layers. Control over the strain
degree-of-freedom opens the door to a completely unexplored set of unrealized
tunable moir\'e geometric symmetries, which may now be achieved in a high-yield
and user-skill independent process taking only hours. This technique solves a
long-standing throughput bottleneck in new moir\'e quantum materials discovery
and opens the door to industrially-compatible manufacturing for 2D
moir\'e-based electronic or optical devices.

</details>


### [327] [Scalable and deterministic construction of moiré superlattice in 2D materials using stressor films](https://arxiv.org/abs/2510.13700)
*Yu-Mi Wu,Sihun Lee,Yufeng Xi,Stephen D. Funni,Saif Siddique,Natalie L. Williams,Giovanni Sartorello,Hesam Askari,Judy J. Cha*

Main category: cond-mat.mtrl-sci

TL;DR: 通过使用图案化的薄膜应力件，我们开发了一种可扩展的工艺，用于在过渡金属二硫属化物中构建异质应变诱导的摩尔超晶格，从而可控地诱导应变。


<details>
  <summary>Details</summary>
Motivation: 构建摩尔超晶格通常是一个耗时且需要反复试验的过程，并且对最终结果的控制能力有限。本研究旨在开发一种可扩展且可控的方法来构建异质应变诱导的摩尔超晶格。

Method: 本研究使用图案化的薄膜应力件来诱导二维材料中的异质应变，从而产生摩尔超晶格。然后使用扫描透射电子显微镜对所得结构进行成像，以解析诱导的异质应变、晶格变形和堆叠变化。

Result: 研究发现，单轴和双轴异质应变可产生不同的摩尔图案，包括条纹和扭曲的六方图案。此外，该方法在 MoS2 的摩尔超晶格畴边界处产生了面内极性畸变和面内极化。

Conclusion: 通过利用成熟的可扩展工艺，可以确定性且可扩展地构建摩尔图案，这为在二维材料中设计新的摩尔几何形状开辟了道路。

Abstract: Moir\'e superlattice in two-dimensional (2D) materials provides a powerful
platform to engineer emergent electronic states, yet the construction of
moir\'e superlattices remains lab-scale, involving much trial and error and
with little control. Here, we demonstrate the construction of a
heterostrain-induced moir\'e superlattice in transition metal dichalcogenides
using a scalable process that deterministically induces strain to 2D materials.
By applying patterned thin-film stressors and probing the resulting structures
with scanning transmission electron microscopy, we directly resolve the induced
heterostrain, lattice deformations, and stacking variations that produce the
moir\'e superlattice. We find that uniaxial and biaxial heterostrain give rise
to distinct moir\'e patterns, including stripes and distorted hexagonal
patterns. With this approach, we create in-plane polar distortions and thus
in-plane polarization at the domain boundaries of the moir\'e superlattice in
MoS$_2$. The deterministic and scalable construction of moir\'e patterns using
a well-established scalable process opens opportunities to design new moir\'e
geometries in 2D materials.

</details>


### [328] [Resonant diffraction and photoemission inconsistent with altermagnetism in epitaxial RuO$_2$ films](https://arxiv.org/abs/2510.13781)
*Benjamin Z. Gregory,Neha Wadehra,Shuyuan Zhang,Yi Wu,Samuel Poage,Jörg Strempfer,Asish K. Kundu,Anil Rajapitamahuni,Elio Vescovo,Anita Verma,Betül Pamuk,Jacob Ruf,Hari Nair,Nathaniel J. Schreiber,Kaveh Ahadi,Kyle M. Shen,Darrell G. Schlom,Andrej Singer*

Main category: cond-mat.mtrl-sci

TL;DR: RuO2薄膜的磁性状态存在争议，尽管一些研究声称发现了反铁磁性或超导性，但本研究通过多种实验手段（包括共振弹性散射、角分辨光电子能谱和各向异性磁阻）并未发现长程反铁磁序或阿尔特磁性的证据，表明RuO2可能处于非磁性相。


<details>
  <summary>Details</summary>
Motivation: 尽管有关于RuO2磁性和电子特性的令人兴奋的报道，包括反铁磁性、应变诱导的超导性以及其作为阿尔特磁体的分类，但其磁基态仍然存在争议，因为一些实验并未观察到磁序。

Method: 研究人员对一系列在TiO2衬底（100）平面上生长的外延RuO2薄膜进行了共振弹性散射测量，并进行了全极化控制和方位角扫描。此外，还利用角分辨光电子能谱和各向异性磁阻进行了测量。

Result: 共振弹性散射信号可能源于各向异性电荷散射，而非长程反铁磁序。角分辨光电子能谱揭示的能带结构不支持阿尔特磁性带分裂，与非磁性相一致。各向异性磁阻结果也未显示出磁性的证据。

Conclusion: 结合三种独立测量结果，表明RuO2不存在阿尔特磁性，其可能处于非磁性相。

Abstract: Excitement about the magnetic and electronic properties of RuO$_2$ is
growing, fueled by reports of antiferromagnetism, strain-induced
superconductivity, and its recent classification as a member of a newly
proposed magnetic class, altermagnets, with RuO$_2$ widely regarded as the
paradigmatic example. Nevertheless, the magnetic ground state of RuO$_2$
remains contentious, as several recent experiments report no evidence of
magnetic order. To address this discrepancy, we performed resonant elastic
scattering measurements on a series of epitaxial RuO$_2$ thin films grown on
the (100)-plane of TiO$_2$ substrates across a range of strain states.
Leveraging full polarization control and azimuthal scans of the structurally
forbidden 100 Bragg reflection, we systematically tested for signatures of
colinear antiferromagnetic order. We found that the resonant elastic scattering
signal in RuO$_2$ thin films likely originates from anisotropic charge
scattering, not long-range antiferromagnetic order. Using angle-resolved
photoemission spectroscopy we uncover a band structure without altermagnetic
band splitting that is consistent with a nonmagnetic phase. Similarly,
anisotropic magnetoresistance results show no evidence of magnetism. The
combination of three independent measurements suggests the absence of
altermagnetism in RuO$_2$.

</details>


### [329] [Structure and magnetism of MnGe thin films grown with a non-magnetic CrSi template](https://arxiv.org/abs/2510.13782)
*B. D. MacNeil,J. S. R. McCoombs,D. Kalliecharan,J. Myra,M. Pula,J. F. Britten,G. B. G. Stenning,K. Gupta,G. M. Luke,T. L. Monchesky*

Main category: cond-mat.mtrl-sci

TL;DR: 使用CrSi模板层在Si(111)上生长了B20 MnGe薄膜，并研究了其磁性和输运性质。


<details>
  <summary>Details</summary>
Motivation: 在没有相邻磁性层影响的情况下，研究超薄MnGe薄膜的固有性质。

Method: 在Si(111)上使用超薄CrSi模板层生长B20 MnGe薄膜，并通过磁强测量和输运数据进行表征。

Result: 成功生长了厚度在2到40 nm之间的单相MnGe(111)薄膜，具有B20结构和小的菱面体畸变。在低于35 K时，观察到意外的剩余磁矩，并伴随着输运数据中的特征。

Conclusion: 低温下MnGe薄膜可能存在三Q拓扑自旋猬 the lattice或多畴单Q锥形状态。

Abstract: We report on a novel method to grow B20 MnGe thin films which employs an
ultrathin CrSi template layer on Si(111). This layer is expected to be
non-magnetic, in contrast to MnSi and FeGe buffer layers that have been used
previously, allowing an investigation of the intrinsic properties the MnGe in
the ultrathin film limit without the influence of a neighboring magnetic layer.
Single-phase MnGe(111) films were grown with thicknesses between 2 and 40 nm,
which exhibited low interfacial roughnesses on the order of 0.6 nm. The films
crystallized in a B20 structure with a small rhombohedral distortion.
Magnetometry measurements in out-of-plane fields are consistent with a conical
state. However, an unexpected remanent moment develops below 35 K, concomitant
with features in the field dependence of the transport data. This provides
indirect evidence for the presence of a low-temperature phase which has been
identified by others as either a triple-Q topological spin-hedgehog lattice, or
a multi-domain single-Q conical state.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [330] [Effective Connectivity-Based Unsupervised Channel Selection Method for EEG](https://arxiv.org/abs/2510.12910)
*Neda Abdollahpour,N. Sertac Artan,Ian Daly,Mohammadreza Yazdchi,Zahra Baharlouei*

Main category: eess.SP

TL;DR: 本研究提出了一种基于有效连接重要性 (ICEC) 标准的无监督通道选择方法，用于分析高维 EEG 数据，提高了计算效率和分类准确性，并显著减少了所需通道数量。


<details>
  <summary>Details</summary>
Motivation: EEG 数据分析常面临高维性和信噪比问题，并非所有通道都包含有效信息，因此需要进行通道选择以提高计算效率并获得稳健的神经动力学洞见。

Method: 研究提出了一种名为 ICEC 的标准来量化每个通道的有效连接（EC），并基于此提出了一种无监督的通道选择方法。该方法利用了通道间相互作用的强度。为了评估该方法，研究者计算了五种不同的 EC 指标（PDC, GPDC, RPDC, DTF, dDTF）的 ICEC 标准，并将其应用于三个公开的 EEG 数据集。通道选择后，使用共同空间模式（CSP）提取特征，支持向量机（SVM）进行分类，并将结果与其它基于 CSP 的方法进行比较。

Result: 所提出的方法在所有参与者中均表现出一致的性能提升，并显著减少了所选电极的数量。与现有技术相比，该方法在三个数据集上分别达到了 82%（选择 22 个中的 13 个通道）、86.01%（选择 59 个中的 29 个通道）和 87.56%（选择 118 个中的 48 个通道）的准确率。

Conclusion: ICEC 标准及其驱动的通道选择方法能够有效提高 EEG 数据分析的准确性，同时大幅减少所需的通道数量，优于现有的一些先进方法。

Abstract: Analyzing neural data such as Electroencephalography (EEG) data often
involves dealing with high-dimensional datasets, where not all channels provide
equally meaningful informa- tion. Selecting the most relevant channels is
crucial for improving computational efficiency and ensuring robust insights
into neural dynamics. This study introduces the Importance of Channels based on
Effective Connectivity (ICEC) criterion for quantifying effective connectivity
(EC) in each channel. Effective connectivity refers to the causal influence one
neural region exerts over another, providing insights into the directional flow
of information. Using this criterion, we propose an unsupervised channel
selection method that accounts for the intensity of interactions among
channels. To evaluate the proposed channel selection method, we applied it to
three well-known EEG datasets across four categories. The assessment involved
calculating the ICEC criterion using five effective connectivity metrics:
partial directed coherence (PDC), generalized PDC (GPDC), renormalized PDC
(RPDC), directed transfer function (DTF), and direct DTF (dDTF). To focus on
the effect of channel selection, we employed the Common Spatial Pattern (CSP)
algorithm for feature extraction and a Support Vector Machine (SVM) for
classification across all participants. Results were compared with other
CSP-based methods. The evaluation included comparing participant- specific
accuracies with and without the proposed method across five effective
connectivity metrics. The results showed consistent performance improvements
and a significant reduction in the number of selected electrodes for all
participants. Compared to state-of-the-art methods, our approach achieved the
highest accuracies: 82% (13 out of 22 channels), 86.01% (29 out of 59
channels), and 87.56% (48 out of 118 channels) across three datasets.

</details>


### [331] [Enabling Full Duplex ISAC Leveraging Waveform Domain Separability](https://arxiv.org/abs/2510.12912)
*Abdelali Arous,Hamza Haif,Huseyin Arslan*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的波形域自干扰消除（SIC）技术，用于解决单站同带全双工（IBFD）系统中集成传感与通信（ISAC）面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 在单站同带全双工（IBFD）系统中，通信和雷达操作并发时，雷达接收器会面临严重的自干扰（SI）。

Method: 本研究设计了一种集成双功能帧，利用OFDM进行通信，利用AFDM进行雷达传感，两者由同一调制器生成。该方法利用OFDM信号在仿射域呈现为AWGN的特性，通过将接收信号投影到仿射域来消除SI。随后，采用迭代低复杂度加窗方案进一步消除残余SI，并通过时域扩展来抑制SI。

Result: 与现有方法相比，该方法在检测概率、目标距离和速度均方根误差（RMSE）方面表现出优越的性能，同时保持了高频谱效率和最低的计算复杂度。

Conclusion: 所提出的波形域SIC技术能够有效地消除ISAC系统中的自干扰，并在保持通信和雷达性能的同时，提高了系统的整体效率。

Abstract: Integrated sensing and communication (ISAC) in monostatic in-band full-duplex
(IBFD) systems encounters significant challenges due to self-interference (SI)
at the radar receiver during concurrent communication and radar operations.
This paper proposes a novel waveform-domain self-interference cancellation
(SIC) technique that leverages the unique properties of orthogonal frequency
division multiplexing (OFDM) and affine frequency division multiplexing (AFDM)
signals. The proposed approach designs the integrated dual-functionality frame
to utilize OFDM for communication and AFDM for radar sensing, both generated
using the same modulator block. Then, we establish the conditions under which a
wide sense stationary (WSS) process in the time domain appears as WSS in the
affine domain and demonstrate that the interfering OFDM signal behaves as an
additive white Gaussian noise (AWGN) in this domain. Exploiting this property,
the received signal is projected into the affine domain, where the SI appears
as AWGN, enabling its subtraction with minimal residual interference. To
further mitigate the residual SI, an iterative low-complexity windowing scheme
is applied, selectively locking onto the radar signal to reduce the processed
signal space. A subsequent time-domain spreading step is applied after
converting the SIC-processed signal into the post-coded time domain, wherein
the SI diminishes separately across the delay and Doppler axes. The proposed
method demonstrates superior performance in terms of detection probability,
target range and velocity root mean square error (RMSE), while maintaining high
spectral efficiency and minimal computational complexity.

</details>


### [332] [Passive Microwave Tag Classification Using RF Fingerprinting and Machine Learning](https://arxiv.org/abs/2510.12930)
*Cory Hilton,Mohammad Rashid,Faiz Sherman,Steven Bush,Jeffrey A. Nanzer*

Main category: eess.SP

TL;DR: 通过射频指纹和机器学习识别无线微波标签。


<details>
  <summary>Details</summary>
Motivation: 开发一种低成本、简单的无线微波标签识别方法。

Method: 利用标签的非线性二极管产生的独特射频信号响应，通过机器学习算法进行分类。

Result: 在2.0 GHz Wi-Fi频段，使用多音连续波信号，实现了对两个标签的实时分类准确率达到95%。

Conclusion: 射频指纹和机器学习可以用于唯一识别具有微小制造差异的无线标签。

Abstract: We present an approach to identifying wireless microwave tags using radio
frequency (RF) fingerprinting and machine learning. The tags are designed for
low cost and simplicity, consisting of only two antennas and a single nonlinear
element (a diode). An interrogating transceiver transmits a signal consisting
of a set of individual frequency tones that is captured by the tag. The signal
response of the diode is nonlinear, and can be represented by an infinite power
series, the coefficients of which are similar but not identical for different
physical diodes due to small manufacturing perturbations. The small differences
in the signal responses manifest in the spectral signal response of the tag,
which is retransmitted back to the interrogating transceiver. Input into
machine learning algorithms, the slight differences in the spectral responses
of the diodes can be used to uniquely identify devices. To demonstrate the
concept, we designed 2.0 GHz tags consisting of patch antennas and a single
diode, along with a bi-static radar system operating at the 2.0 GHz 802.11
Wi-Fi band transmitting multi-tone continuous wave signals representing common
802.11 training fields. The received signals were processed using a set of
algorithms for comparison purposes. A real-time classification accuracy of 95%
between two tags was achieved.

</details>


### [333] [Computationally Efficient Neural Receivers via Axial Self-Attention](https://arxiv.org/abs/2510.12941)
*SaiKrishna Saketh Yellapragada,Atchutaram K. Kocharlakota,Mário Costa,Esa Ollila,Sergiy A. Vorobyov*

Main category: eess.SP

TL;DR: 一个新颖的轴向自注意力Transformer神经网络接收器，在5G实验配置下验证，在6G及以上无线系统中实现了最先进的块错误率（BLER）性能和显著提高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了满足下一代无线通信系统（如6G）对更高计算效率和性能的需求，本文提出了一种新的神经网络接收器架构。

Method: 提出了一种轴向自注意力Transformer神经网络接收器，通过沿着时间和频谱轴分解注意力操作，将复杂度从O((TF)^2)降低到O(T^2F+TF^2)，以减少计算量和参数量。

Result: 与现有的卷积神经网络接收器和传统LS-LMMSE接收器相比，所提出的轴向神经网络接收器在各种移动场景下，尤其是在非视距CDL-C条件下，实现了更低的计算成本、更少的参数量和更优越的BLER性能。在1% BLER的严格可靠性目标下，该接收器在高用户速度下仍能保持鲁棒性，而传统接收器则无法收敛。

Conclusion: 轴向自注意力Transformer神经网络接收器是一种高效、可扩展且结构化的AI原生6G无线接入网（RAN）系统框架，适用于资源受限的边缘环境，特别是在超可靠低延迟通信（URLLC）等动态场景下。

Abstract: Deep learning-based neural receivers are redefining physical-layer signal
processing for next-generation wireless systems. We propose an axial
self-attention transformer neural receiver designed for applicability to 6G and
beyond wireless systems, validated through 5G-compliant experimental
configurations, that achieves state-of-the-art block error rate (BLER)
performance with significantly improved computational efficiency. By
factorizing attention operations along temporal and spectral axes, the proposed
architecture reduces the quadratic complexity of conventional multi-head
self-attention from $O((TF)^2)$ to $O(T^2F+TF^2)$, yielding substantially fewer
total floating-point operations and attention matrix multiplications per
transformer block compared to global self-attention. Relative to convolutional
neural receiver baselines, the axial neural receiver achieves significantly
lower computational cost with a fraction of the parameters. Experimental
validation under 3GPP Clustered Delay Line (CDL) channels demonstrates
consistent performance gains across varying mobility scenarios. Under
non-line-of-sight CDL-C conditions, the axial neural receiver consistently
outperforms all evaluated receiver architectures, including global
self-attention, convolutional neural receivers, and traditional LS-LMMSE at
10\% BLER with reduced computational complexity per inference. At stringent
reliability targets of 1\% BLER, the axial receiver maintains robust symbol
detection at high user speeds, whereas the traditional LS-LMMSE receiver fails
to converge, underscoring its suitability for ultra-reliable low-latency
(URLLC) communication in dynamic 6G environments and beyond. These results
establish the axial neural receiver as a structured, scalable, and efficient
framework for AI-Native 6G RAN systems, enabling deployment in
resource-constrained edge environments.

</details>


### [334] [Towards Spectrally Efficient and Physically Reconfigurable Architectures for Multibeam-Waveform Co-Design in Joint Communication and Sensing](https://arxiv.org/abs/2510.12968)
*Najme Ebrahimi,Arun Paidmarri,Alexandra Gallyas-Sanhueza,Yuan Ma,Haoling Li,Basem Abdelaziz Abdelmagid,Tzu-Yuan Huang,Hua Wang*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Joint Communication and Sensing (JCAS) platforms are emerging as a foundation
of next-generation mmWave (MMW) and sub-THz systems, enabling both
high-throughput data transfer and angular localization within a shared signal
path. This paper investigates multibeam architectures for JCAS that
simultaneously optimize waveform shaping and beamforming across the time,
frequency, code, and direct analog/ radio frequency (RF) domains. The paper
compares Orthogonal Frequency-Division Multiplexing (OFDM), Frequency Modulated
Arrays (FMA), Time-Modulated Arrays (TMA), direct RF/MMW modulation, and
Code-Division Multiple Access (CDMA)-based systems with respect to spectral
efficiency, beam orthogonality, latency, and Angle-of-Arrival (AoA) estimation
accuracy. The results highlight architecture-specific tradeoffs among beam
agility, efficiency, accuracy and resolution, and complexity. It also provides
a framework for selecting JCAS front ends optimized for power, latency,
inter-beam and multi-user interference, and rapid system reconfiguration

</details>


### [335] [Constellation Design in OFDM-ISAC over Data Payloads: From MSE Analysis to Experimentation](https://arxiv.org/abs/2510.13101)
*Kawon Han,Kaitao Meng,Alexandra Chatzicharistou,Christos Masouros*

Main category: eess.SP

TL;DR: 该论文研究了基于OFDM的ISAC系统在多目标延迟（距离）估计中的感知性能，并提出了优化的ISAC星座设计。


<details>
  <summary>Details</summary>
Motivation: OFDM因其高频谱效率和与现代通信标准的兼容性，被广泛用于ISAC系统。该研究旨在优化OFDM-ISAC系统的感知性能，特别是在多目标延迟估计方面。

Method: 开发了一个估计理论框架来表征随机通信负载下的感知性能，并推导了匹配滤波（MF）和倒易滤波（RF）接收机实现的均方误差（MSE）的闭式表达式。基于此分析，提出了一种ISAC星座设计。

Result: 在多目标场景下，MF的性能依赖于零均值、单位功率星座的四阶矩，而RF的性能则取决于其二阶矩的倒数，与目标数量无关。提出的ISAC星座设计能在特定接收机架构下实现感知与通信的灵活权衡。

Conclusion: OFDM-ISAC系统在多目标延迟估计方面的感知性能受信号星座和接收机处理方案的影响。提出的星座设计为OFDM-ISAC系统在感知和通信之间提供了接收机依赖的灵活权衡。理论分析得到了仿真和概念验证实验的验证。

Abstract: Orthogonal frequency division multiplexing (OFDM) is one of the most widely
adopted waveforms for integrated sensing and communication (ISAC) systems,
owing to its high spectral efficiency and compatibility with modern
communication standards. This paper investigates the sensing performance of
OFDM-based ISAC for multi-target delay (range) estimation under specific radar
receiver processing schemes. An estimation-theoretic framework is developed to
characterize sensing performance with random communication payloads. We
establish the fundamental limit of delay estimation accuracy by deriving the
closed-form expression of the mean-square error (MSE) achieved using matched
filtering (MF) and reciprocal filtering (RF) receivers. The results show that,
in multi-target scenarios, the impact of signal constellations on the delay
estimation MSE differs across receivers: MF performance depends on the
fourth-order moment of the zero-mean, unit-power constellation in the presence
of multiple targets, whereas RF performance depends on its inverse second-order
moment, irrespective of the number of targets. Building on this analysis, we
present a ISAC constellation design under specific receiver architecture that
brings a receiver-dependent flexible trade-off between sensing and
communication in OFDM-ISAC systems. The theoretical findings are validated
through simulations and proof-of-concept experiments, and also the sensing and
communication performance trade-off is experimentally shown with the proposed
constellation design.

</details>


### [336] [Working Memory Functional Connectivity Analysis for Dementia Classification using EEG](https://arxiv.org/abs/2510.13399)
*Shivani Ranjan,Anant Jain,Robin Badal,Amit Kumar,Harshal Shende,Deepak Joshi,Pramod Yadav,Lalan Kumar*

Main category: eess.SP

TL;DR: 该研究利用基于工作记忆任务的脑电图（EEG）功能连接（FC）分析来区分阿尔茨海默病（AD）和轻度认知障碍（MCI）患者与健康对照组。


<details>
  <summary>Details</summary>
Motivation: 工作记忆（WM）受损是神经退行性疾病（包括阿尔茨海默病）的一个早期迹象。本研究旨在利用脑电图（EEG）的功能连接（FC）来识别不同痴呆阶段的脑网络改变，特别是关注WM任务。

Method: 通过对24名参与者（8名AD、8名MCI、8名健康对照）在WM任务（包括编码、回忆和检索）期间的EEG信号进行记录。使用球面谐波分解（SHD）和头谐波分解（HHD）进行数据预处理和特征提取。利用交叉图转换熵（CPTE）和相位延迟指数（PLI）量化FC，并使用支持向量机、随机森林和XGBoost分类器分析网络指标（如度中心性和特征向量中心性）。

Result: 基于CPTE的功能连接指标在区分痴呆阶段方面优于PLI方法，在检索阶段使用随机森林模型达到了97.53%的最高分类准确率。0.5的功能连接阈值是区分网络的最佳阈值。SHD和HHD特征也显示出强大的区分潜力。与健康对照组相比，AD受试者在WM任务期间表现出更高的同步模式。

Conclusion: 结合WM任务和基于EEG的FC分析为痴呆症的分类提供了一个稳健的框架。所提出的基于CPTE的方法提供了一个稳健、可扩展、非侵入性且有效的诊断工具，可用于神经退行性疾病的早期检测和监测。

Abstract: Background: Dementia, particularly Alzheimer's Disease (AD), is a progressive
neurodegenerative disorder marked by cognitive decline. Early detection,
especially at the Mild Cognitive Impairment (MCI) stage, is essential for
timely intervention. Working Memory (WM) impairment is a key early indicator of
neurodegeneration, affecting higher cognitive processes. Electroencephalography
(EEG), with its high temporal resolution, offers a cost-effective method to
assess brain dynamics. This study investigates WM-related EEG functional
connectivity (FC) to identify brain network alterations across dementia stages.
Methods: EEG signals were recorded from 24 participants (8 AD, 8 MCI, and 8
healthy controls) during WM tasks, including encoding, recall, and retrieval
stages. Data preprocessing involved noise reduction and feature extraction
using Spherical and Head Harmonic Decomposition (SHD, HHD). FC was quantified
using Cross-Plot Transition Entropy (CPTE) and Phase Lag Index (PLI). Network
metrics such as Degree and Eigenvector Centrality were analyzed using Support
Vector Machine, Random Forest, and XGBoost classifiers. Results: The CPTE-based
connectivity metrics outperformed the traditional PLI approach in
differentiating dementia stages, attaining a peak classification accuracy of
97.53% during the retrieval phase with the Random Forest model. A connectivity
threshold of 0.5 was optimal for network discrimination. SHD and HHD features
also demonstrated strong discriminative potential. AD subjects exhibited higher
synchronization patterns during WM tasks than healthy controls. Conclusions:
The integration of WM tasks with EEG-based FC analysis provides a robust
framework for dementia classification. The proposed CPTE-based approach offers
a robust, scalable, non-invasive, and effective diagnostic tool for early
detection and monitoring of neurodegenerative diseases.

</details>


### [337] [Oscillator Drift Compensation by Line-of-Sight Tracking for Distributed Multisensor ISAC](https://arxiv.org/abs/2510.13442)
*Lorenz Mohr,Marc Miranda,Sebastian Semper,Julia Beuster,Carsten Andrich,Sebastian Giehl,Christian Schneider,Reiner S. Thomä*

Main category: eess.SP

TL;DR: 移动多传感器ISAC系统中，通过Kalman滤波和HRPE对齐相位，提高多普勒估计精度，并提出残差功率作为评估同步方法的新指标。


<details>
  <summary>Details</summary>
Motivation: 移动多传感器ISAC系统需要节点间的相干性，以实现精确的多普勒估计，但实际测量中存在同步不匹配问题。

Method: 提出一种基于Kalman滤波的几何扩展方法来补偿多传感器信道测量中的时间漂移，并使用高分辨率参数估计（HRPE）后的相对残差功率作为评估同步后处理方法的指标。

Result: 所提出的方法将相对残差功率降低了5分贝以上，并将延迟-多普勒估计的均方根误差（RMSE）降低了约60%，优于传统的视线（LoS）估计方法。

Conclusion: 提出的基于Kalman滤波的漂移补偿方法和基于HRPE残差功率的评估指标，能够有效提高移动多传感器ISAC系统的同步精度和多普勒估计性能。

Abstract: We observed synchronization mismatches in the form of non-smooth phase
progressions and drifts within mobile multisensor channel sounding
measurements. However, performing Doppler estimation in a distributed
multisensor integrated sensing and communications (ISAC) system requires
coherence among the nodes, which implies a continuously differentiable phase
progression of the received signals. To correct the sounding data in
post-processing, we extend traditional geometry-based drift compensation
algorithms by utilizing Kalman filtering for line-of-sight (LoS) tracking,
which improves the robustness of the LoS estimate in multipath scenarios. This
approach smooths the phase progression and enables the correction of
time-varying drifts while preserving relative sensor motion. Furthermore, we
propose using the relative residual power after high-resolution parameter
estimation (HRPE) as a metric for ground-truth-independent comparison of
post-processing synchronization methods for recorded channel sounding data.
Results show that the proposed approach outperforms traditional LoS estimation
heuristics, reducing the relative residual power by more than 5 dB and the
delay-Doppler estimate root mean square errors (RMSEs) by approximately 60 %.

</details>


### [338] [Radio over Fiber with Cascaded Structure: Algorithm for Uplink Positioning](https://arxiv.org/abs/2510.13495)
*Dexin Kong,Diana Pamela Moya Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的、用于室内场景的、级联多个无线单元（RU）的超材料光纤（PMF）无线光（RoF）结构，并提出了一种最大似然和非线性最小二乘算法来估计传播距离和到达时间，以解决非线性功率放大器（PA）和光纤传播信道引起的失真问题。


<details>
  <summary>Details</summary>
Motivation: 利用聚合物微波光纤（PMF）技术在低成本、高比特率的亚太赫兹（THz）无线光通信（RoF）中实现室内场景中多个无线单元（RU）的级联互联，并解决由此产生的失真问题。

Method: 提出最大似然和非线性最小二乘算法来估计RoF的传播距离和用户设备与RoF之间的时间到达。对于线性PA，推导了Cramér-Rao下界来评估估计器的性能。

Result: 仿真结果表明，所提出的估计器即使在非线性PA的级联效应下也能令人满意地工作，并且该RoF结构可以为室内高分辨率定位提供新的、具有成本效益的机会。

Conclusion: 所提出的RoF结构和估计算法能够有效地解决级联失真问题，并在室内场景中实现具有成本效益的高分辨率定位。

Abstract: Recent advancements in polymer microwave fiber (PMF) technology have created
significant opportunities for robust, low-cost, and high-speed sub-terahertz
(THz) radio-over- fiber communications. Recognizing these potential benefits,
this paper explores a novel radio-over-fiber (RoF) structure that interconnects
multiple radio units (RUs) in cascade via fiber, envi- sioning its application
in indoor scenarios. This structure creates a number of research opportunities
when considering cascaded distortion effects introduced by non-linear power
amplifiers (PAs) at the RUs and the propagation channel over the fiber. We
propose maximum-likelihood and non-linear least-squares algorithms to estimate
the propagation distance along the RoF and the time-of-arrival between the RoF
and the user equipment. For the case of linear PAs, we derive the Cram\'er-Rao
lower bound to benchmark the performance of the estimators. Finally, we
investigate the use of the system for uplink positioning. Our simulation
results demonstrate that the proposed estimators perform satisfactorily even
with the cascaded effects of non- linear PAs, and that the deployment of this
RoF structure can enable new cost-effective opportunities for high-resolution
positioning in indoor scenarios. In the numerical evaluation, we also use
measured PMF characteristics for high-density polyethylene fibers.

</details>


### [339] [A Robust EDM Optimization Approach for 3D Single-Source Localization with Angle and Range Measurements](https://arxiv.org/abs/2510.13498)
*Mingyu Zhao,Qingna Li,Hou-Duo Qi*

Main category: eess.SP

TL;DR: 该论文提出了一种鲁棒的欧氏距离矩阵(EDM)优化模型，用于解决3D单源定位(3DSSL)问题，该模型同时考虑了距离测量、角度测量和最小绝对偏差准则。


<details>
  <summary>Details</summary>
Motivation: 在准确源定位问题中，距离测量、角度测量和最小绝对偏差准则（用于去噪）是三个重要因素，但将它们整合到一个易于计算的模型中具有挑战性。

Method: 提出了一种鲁棒的EDM优化模型，将距离测量、角度测量和最小绝对偏差准则结合起来。将3D角度测量转化为距离的下界和上界，并开发了一种有效的算法来求解。

Result: 通过大量的数值实验，证明了该EDM模型在3DSSL问题上相比现有算法具有更高的定位精度。

Conclusion: 所提出的鲁棒EDM优化模型能够有效地结合距离和角度测量，并通过最小绝对偏差准则进行去噪，为3DSSL问题提供了一种高质量的解决方案。

Abstract: For the problem of source localization, three elements usually play a very
important role in accurate localization. They are the range measurements, the
angle measurements and the least absolute deviation criterion, which is
regarded as a robust metric for denoising the measurements. Building the three
elements into a computationally tractable model is challenging. In this paper,
we introduce a robust Euclidean Distance Matrix (EDM) optimization model that
simultaneously incorporates the three elements. For the first time, we show
that for the case of 3D single-source localization (3DSSL), the angle
measurements can be represented as a simple box constraint of distances. It is
achieved by reducing each of the 3D angle measurements to a two-dimensional
nonlinear optimization problem, whose global minimum and maximum solutions can
be characterized and utilized to get the lower and upper bounds of the
distances from the unknown source to the sensors. We further develop an
efficient algorithm. The high quality of the localization by the new EDM model
is assessed through extensive numerical experiments in comparison with leading
solvers for 3DSSL.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [340] [Finding a Nash equilibrium of a random win-lose game in expected polynomial time](https://arxiv.org/abs/2510.12846)
*Andrea Collevecchio,Gabor Lugosi,Adrian Vetta,Rui-Ray Zhang*

Main category: cs.GT

TL;DR: 对于随机双矩阵博弈，当p不接近1/2或1时，存在期望多项式时间算法来找到纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 解决算法博弈论中关于随机双矩阵博弈是否存在多项式时间纳什均衡算法的长期公开问题。

Method: 研究随机胜-负博弈，其中支付矩阵的条目是独立的、同分布的伯努利随机变量，参数为p=p(n)。证明对于p=p(n)的几乎所有值，都存在一个期望多项式时间算法来找到纳什均衡。

Result: 证明了当p~cn^{-a}时，只要a不等于1/2或1，就存在期望多项式时间算法。当a=1/2时，如果c<=e^{-52}2^{-8}或c>=0.977，则存在高效算法。当a=1时，如果c<=0.3849或c>=log^9 n，则存在期望多项式时间算法。

Conclusion: 对于随机胜-负博弈，在大多数参数p(n)下，存在找到纳什均衡的期望多项式时间算法。

Abstract: A long-standing open problem in algorithmic game theory asks whether or not
there is a polynomial time algorithm to compute a Nash equilibrium in a random
bimatrix game. We study random win-lose games, where the entries of the
$n\times n$ payoff matrices are independent and identically distributed
(i.i.d.) Bernoulli random variables with parameter $p=p(n)$. We prove that, for
nearly all values of the parameter $p=p(n)$, there is an expected
polynomial-time algorithm to find a Nash equilibrium in a random win-lose game.
More precisely, if $p\sim cn^{-a}$ for some parameters $a,c\ge 0$, then there
is an expected polynomial-time algorithm whenever $a\not\in \{1/2, 1\}$. In
addition, if $a = 1/2$ there is an efficient algorithm if either $c \le e^{-52}
2^{-8} $ or $c\ge 0.977$. If $a=1$, then there is an expected polynomial-time
algorithm if either $c\le 0.3849$ or $c\ge \log^9 n$.

</details>


### [341] [Equilibria in routing games with connected autonomous vehicles will not be strong, as exclusive clubs may form](https://arxiv.org/abs/2510.12862)
*Rafał Kucharski,Anastasia Psarou,Natello Descormier*

Main category: cs.GT

TL;DR: 自动驾驶汽车（CAVs）可以通过形成联盟来操纵路线选择，从而可能扰乱交通系统并对非联盟成员产生负面影响。


<details>
  <summary>Details</summary>
Motivation: 研究连接自动驾驶汽车（CAVs）可能组成的路由联盟对用户均衡的影响，以及这种联盟可能对交通系统产生的负面影响。

Method: 通过一个精心设计的玩具网络示例，展示了由三个自动驾驶汽车组成的“俱乐部”如何协同偏离用户均衡以获得更快的到达时间。

Result: 自动驾驶汽车俱乐部可以成功偏离用户均衡，使自身受益，但会增加其他用户（非俱乐部成员）的出行时间和交通系统的整体效率。

Conclusion: 如果不能有效阻止，自动驾驶汽车运营商可能会故意破坏交通系统的经典纳什均衡，从而使自身受益并损害他人利益。这可能导致形成一个排他的自动驾驶汽车精英群体，将人类驾驶车辆和其他非联盟成员排除在外，并可能导致他们出行时间更长，损害公共道路网络的公平性。

Abstract: User Equilibrium is the standard representation of the so-called routing game
in which drivers adjust their route choices to arrive at their destinations as
fast as possible. Asking whether this Equilibrium is strong or not was
meaningless for human drivers who did not form coalitions due to technical and
behavioral constraints. This is no longer the case for connected autonomous
vehicles (CAVs), which will be able to communicate and collaborate to jointly
form routing coalitions.
  We demonstrate this for the first time on a carefully designed toy-network
example, where a `club` of three autonomous vehicles jointly decides to deviate
from the user equilibrium and benefit (arrive faster). The formation of such a
club has negative consequences for other users, who are not invited to join it
and now travel longer, and for the system, making it suboptimal and
disequilibrated, which triggers adaptation dynamics.
  This discovery has profound implications for the future of our cities. We
demonstrate that, if not prevented, CAV operators may intentionally
disequilibrate traffic systems from their classic Nash equilibria, benefiting
their own users and imposing costs on others. These findings suggest the
possible emergence of an exclusive CAV elite, from which human-driven vehicles
and non-coalition members may be excluded, potentially leading to
systematically longer travel times for those outside the coalition, which would
be harmful for the equity of public road networks.

</details>


### [342] [Efficiency of Constant Log Utility Market Makers](https://arxiv.org/abs/2510.12952)
*Maneesha Papireddygari,Xintong Wang,Bo Waggoner,David M. Pennock*

Main category: cs.GT

TL;DR: CLUM AMM 在组合预测市场中定价证券是 #P-hard 的，但本文提出了一个近似算法，对于区间证券，它可以在多项式时间内运行。


<details>
  <summary>Details</summary>
Motivation: AMMs 对于流动性差的组合预测市场很重要。原始的 LMSR AMM 定价是 #P-hard 的，而 CLUM AMM 具有更好的损失界限，并支持无限数量的证券。

Method: 本文首先证明了 CLUM AMM 的定价问题是 #P-hard 的，方法是对 2-SAT 问题的模型计数进行归约。然后，提出了一种近似算法，该算法需要一个能够确定任何一种结果的最大购买份额以及具有该最大购买量的结果总数的预言机。最后，证明了该预言机可以针对区间证券在多项式时间内实现。

Result: CLUM AMM 的定价问题被证明是 #P-hard 的。提出的近似算法在给定特定预言机的情况下，可以处理 CLUM AMM 的定价问题。对于区间证券，该预言机可以在多项式时间内实现。

Conclusion: 尽管 CLUM AMM 的定价问题在计算上很困难，但通过近似算法和高效的预言机（尤其是在区间证券的情况下），可以提高其在实际应用中的可行性。

Abstract: Automated Market Makers (AMMs) are used to provide liquidity for
combinatorial prediction markets that would otherwise be too thinly traded.
They offer both buy and sell prices for any of the doubly exponential many
possible securities that the market can offer. The problem of setting those
prices is known to be #P-hard for the original and most well-known AMM, the
logarithmic market scoring rule (LMSR) market maker [Chen et al., 2008]. We
focus on another natural AMM, the Constant Log Utility Market Maker (CLUM).
Unlike LMSR, whose worst-case loss bound grows with the number of outcomes,
CLUM has constant worst-case loss, allowing the market to add outcomes on the
fly and even operate over countably infinite many outcomes, among other
features. Simpler versions of CLUM underpin several Decentralized Finance
(DeFi) mechanisms including the Uniswap protocol that handles billions of
dollars of cryptocurrency trades daily. We first establish the computational
complexity of the problem: we prove that pricing securities is #P-hard for
CLUM, via a reduction from the model counting 2-SAT problem. In order to make
CLUM more practically viable, we propose an approximation algorithm for pricing
securities that works with high probability. This algorithm assumes access to
an oracle capable of determining the maximum shares purchased of any one
outcome and the total number of outcomes that has that maximum amount
purchased. We then show that this oracle can be implemented in polynomial time
when restricted to interval securities, which are used in designing financial
options.

</details>


### [343] [Repeated Sales with Heterogeneous Buyer Sophistication](https://arxiv.org/abs/2510.13088)
*Rishi Patel,Emmanouil Pountourakis,Samuel Taggart*

Main category: cs.GT

TL;DR: 卖家在重复销售非耐用商品时，会根据买家行为进行价格歧视，并考虑了“老练”和“幼稚”买家两类人群，探讨了学习和利用学习来增加收入。研究结论与时间跨度密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究卖家在重复销售商品时，在没有承诺能力的情况下，如何通过价格歧视（基于买家行为）来最大化收入，并考虑了不同类型买家（老练型和幼稚型）的影响。

Method: 通过一个两期模型和一个无限期模型（考虑时间贴现）来分析卖家在不同时间跨度下，面对“老练”和“幼稚”买家时的定价策略和收入。

Result: 在短期模型中，幼稚型买家的引入会加剧卖家的需求抑制，损害卖家的收入。在长期模型中，幼稚型买家的存在打破了之前关于极端需求抑制的预测，卖家可以通过学习获得接近承诺能力的收入。

Conclusion: 在短期内，幼稚型买家的存在会进一步损害卖家的收入。然而，在长期内，幼稚型买家的引入可以使卖家的收入接近其拥有承诺能力时的收入水平，即使幼稚型买家的比例非常小。

Abstract: This paper considers behavior-based price discrimination in the repeated sale
of a non-durable good to a single long-lived buyer, by a seller without
commitment power. We assume that there is a mixed population of forward-looking
``sophisticated'' buyers and myopic ``naive'' buyers. We investigate the impact
of these dynamics on the seller's ability to learn about the buyer and exploit
this learning for revenue. We obtain conclusions that differ dramatically with
the time horizon of the interactions. To understand short time horizons, we
analyze a two-period model, and find that the strategic demand reduction
observed with fully sophisticated buyers is robust to the introduction of naive
types. In fact, despite the inability of naive buyers to game the pricing
algorithm, their introduction can further harm the seller's revenue, due to
more intense demand reduction overall. For long horizons, we consider an
infinite-horizon model with time discounting. We find that the extreme demand
reduction predicted by previous work does not survive the introduction of naive
buyers. Instead, we observe equilibria where the seller learns meaningfully
despite the sophisticated buyers' demand reduction. We prove that for a natural
family of such equilibria, the seller's revenue is not just high, but
approximates the revenue attainable with commitment power, even when the
fraction of naive types is vanishingly small.

</details>


### [344] [A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version](https://arxiv.org/abs/2510.13261)
*Björn Filter,Ralf Möller,Özgür Lütfü Özçep*

Main category: cs.GT

TL;DR: 本文提出了一种基于比例的Shapley值方法，用于协作机器学习中的激励兼容和公平奖励分配，以替代原有的加法公式。


<details>
  <summary>Details</summary>
Motivation: 协作机器学习中的激励兼容和公平奖励分配是一个关键挑战。

Method: 提出了一种基于比例的Shapley值，替代了原有的加法公式，并证明了其满足与加法公式相同的激励条件（公平性、个体理性、稳定性）。

Result: 比例Shapley值诱导了不同的模型奖励分配，并提供了分析激励特性的新方法。

Conclusion: 本文提供了一个数学上合理的加法Shapley框架的替代方案，适用于更看重贡献者之间比例关系的场景。

Abstract: Collaborative machine learning enables multiple data owners to jointly train
models for improved predictive performance. However, ensuring incentive
compatibility and fair contribution-based rewards remains a critical challenge.
Prior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative
machine learning with incentive-aware model rewards. In: International
conference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by
allocating model rewards, which are non-monetary and freely replicable, based
on the Shapley value of each party's data contribution, measured via
information gain. In this paper, we introduce a ratio-based Shapley value that
replaces the standard additive formulation with a relative contribution
measure. While our overall reward framework, including the incentive
definitions and model-reward setting, remains aligned with that of Sim and
colleagues, the underlying value function is fundamentally different. Our
alternative valuation induces a different distribution of model rewards and
offers a new lens through which to analyze incentive properties. We formally
define the ratio-based value and prove that it satisfies the same set of
incentive conditions as the additive formulation, including adapted versions of
fairness, individual rationality, and stability. Like the original approach,
our method faces the same fundamental trade-offs between these incentives. Our
contribution is a mathematically grounded alternative to the additive Shapley
framework, potentially better suited to contexts where proportionality among
contributors is more meaningful than additive differences.

</details>


### [345] [Nash Flows Over Time with Tolls](https://arxiv.org/abs/2510.13518)
*Shaul Rosner,Marc Schröder,Laura Vargas Koch*

Main category: cs.GT

TL;DR: 动态路由博弈中引入收费，导致动态均衡不唯一且不一定达到稳态，但可计算稳态。


<details>
  <summary>Details</summary>
Motivation: 研究受交通流启发的动态路由博弈，并引入收费机制。

Method: 在基础 Vickrey 瓶颈模型中加入收费，考虑非原子均衡，并提供计算稳态的程序。

Result: 动态均衡的成本不唯一，不一定达到稳态。提供了一个计算稳态的程序。

Conclusion: 动态路由博弈引入收费后，均衡性质发生改变，但仍可计算稳态。

Abstract: We study a dynamic routing game motivated by traffic flows. The base model
for an edge is the Vickrey bottleneck model. That is, edges are equipped with a
free flow transit time and a capacity. When the inflow into an edge exceeds its
capacity, a queue forms and the following particles experience a waiting time.
In this paper, we enhance the model by introducing tolls, i.e., a cost each
flow particle must pay for traversing an edge. In this setting we consider
non-atomic equilibria, which means flows over time in which every particle is
on a cheapest path, when summing up toll and travel time. We first show that
unlike in the non-tolled version of this model, dynamic equilibria are not
unique in terms of costs and do not necessarily reach a steady state. As a main
result, we provide a procedure to compute steady states in the model with
tolls.

</details>


### [346] [Online Fair Division With Subsidy: When Do Envy-Free Allocations Exist, and at What Cost?](https://arxiv.org/abs/2510.13633)
*Pooja Kulkarni,Ruta Mehta,Vishnu V. Narayan,Tomasz Ponitka*

Main category: cs.GT

TL;DR: 在线分配$m$个不可分割物品给$n$个代理，提出在线算法来维持每一步的无嫉妒分配，并研究保证无嫉妒分配所需的补贴量。


<details>
  <summary>Details</summary>
Motivation: 研究在线分配$m$个不可分割物品给$n$个代理的公平性问题，特别是无嫉妒分配（EF）的存在性以及如何以最小的补贴量达到。

Method: 提出在线算法来维持每一步的无嫉妒分配，并研究保证无嫉妒分配所需的补贴量。分析了在不同估值函数（如加性、k-demand、SPLC、k-valued、rank-one、restricted additive和identical valuations）下，维持无嫉妒分配的可行性以及所需的最小补贴量。

Result: 对于加性估值及其超类（包括k-demand和SPLC valuations），设计了可在每一步维持无嫉妒分配的在线算法。研究发现，即使对于加性估值，维持无嫉妒分配所需的最小补贴量也可能高达$\\

Conclusion: 研究表明，在线环境中维持无嫉妒分配比离线环境更具挑战性，尤其是在补贴量方面。然而，通过设计特定的在线算法和识别特定的估值类别，可以有效地在在线环境中实现公平分配。

Abstract: We study the problem of fairly allocating $m$ indivisible items arriving
online, among $n$ (offline) agents. Although envy-freeness has emerged as the
archetypal fairness notion, envy-free (EF) allocations need not exist with
indivisible items. To bypass this, a prominent line of research demonstrates
that there exist allocations that can be made envy-free by allowing a subsidy.
Extensive work in the offline setting has focused on finding such envy-freeable
allocations with bounded subsidy. We extend this literature to an online
setting where items arrive one at a time and must be immediately and
irrevocably allocated. Our contributions are two-fold:
  1. Maintaining EF Online: We show that envy-freeability cannot always be
preserved online when the valuations are submodular or supermodular, even with
binary marginals. In contrast, we design online algorithms that maintain
envy-freeability at every step for the class of additive valuations, and for
its superclasses including $k$-demand and SPLC valuations.
  2. Ensuring Low Subsidy: We investigate the quantity of subsidy required to
guarantee envy-freeness online. Surprisingly, even for additive valuations, the
minimum subsidy may be as large as $\Omega(mn)$, in contrast to the offline
setting, where the bound is $O(n)$. On the positive side, we identify valuation
classes where the minimum subsidy is small (i.e., does not depend on $m$),
including $k$-valued, rank-one, restricted additive, and identical valuations,
and we obtain (mostly) tight subsidy bounds for these classes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [347] [MiGumi: Making Tightly Coupled Integral Joints Millable](https://arxiv.org/abs/2510.13168)
*Aditya Ganeshan,Kurt Fleischer,Wenzel Jakob,Ariel Shamir,Daniel Ritchie,Takeo Igarashi,Maria Larsson*

Main category: cs.GR

TL;DR: CNC铣削技术可用于制作传统榫卯结构，通过设计可铣削的几何语言并优化零件几何形状来解决加工误差问题，实现了紧密贴合的榫卯结构。


<details>
  <summary>Details</summary>
Motivation: 传统榫卯结构虽然坚固耐用且美观，但由于手动制作成本高昂且困难，在现代工艺流程中很少使用。CNC铣削是一种可扩展的替代方案，但直接铣削传统结构会因产生圆角等几何偏差而导致装配问题。本研究旨在解决这一问题。

Method: 提出了一种名为“可铣削挤出几何”（MXG）的语言，用于表示铣削操作的结果。MXG将每次操作表示为由刀具方向和钻孔半径定义的减法挤出体积。通过这种参数化，可以为零半径钻孔创建无瑕疵的几何形状，匹配传统榫卯设计。通过增加半径来暴露铣削引起的偏差。为了恢复配合度，在表面邻近度和与配合表面相关的铣刀路径邻近度约束方面，对紧密配合进行了形式化。然后推导出两种可行的、可微分的损失函数，以实现关节几何形状的高效优化。

Result: 对30种传统榫卯结构进行了评估，证明该方法生成的CNC兼容、贴合紧密的榫卯结构近似了原始几何形状。

Conclusion: 通过重新诠释适用于CNC工艺流程的传统榫卯结构，本研究延续了这一传统工艺的发展，并有助于确保其在未来制作实践中的相关性。

Abstract: Traditional integral wood joints, despite their strength, durability, and
elegance, remain rare in modern workflows due to the cost and difficulty of
manual fabrication. CNC milling offers a scalable alternative, but directly
milling traditional joints often fails to produce functional results because
milling induces geometric deviations, such as rounded inner corners, that alter
the target geometries of the parts. Since joints rely on tightly fitting
surfaces, such deviations introduce gaps or overlaps that undermine fit or
block assembly. We propose to overcome this problem by (1) designing a language
that represent millable geometry, and (2) co-optimizing part geometries to
restore coupling. We introduce Millable Extrusion Geometry (MXG), a language
for representing geometry as the outcome of milling operations performed with
flat-end drill bits. MXG represents each operation as a subtractive extrusion
volume defined by a tool direction and drill radius. This parameterization
enables the modeling of artifact-free geometry under an idealized zero-radius
drill bit, matching traditional joint designs. Increasing the radius then
reveals milling-induced deviations, which compromise the integrity of the
joint. To restore coupling, we formalize tight coupling in terms of both
surface proximity and proximity constraints on the mill-bit paths associated
with mating surfaces. We then derive two tractable, differentiable losses that
enable efficient optimization of joint geometry. We evaluate our method on 30
traditional joint designs, demonstrating that it produces CNC-compatible,
tightly fitting joints that approximates the original geometry. By
reinterpreting traditional joints for CNC workflows, we continue the evolution
of this heritage craft and help ensure its relevance in future making
practices.

</details>


### [348] [HRM^2Avatar: High-Fidelity Real-Time Mobile Avatars from Monocular Phone Scans](https://arxiv.org/abs/2510.13587)
*Chao Shi,Shenghao Jia,Jinhui Liu,Yong Zhang,Liangchao Zhu,Zhonglei Yang,Jinze Ma,Chaoyue Niu,Chengfei Lv*

Main category: cs.GR

TL;DR: 使用单目手机扫描创建高保真虚拟人，可在移动设备上实时渲染和动画。


<details>
  <summary>Details</summary>
Motivation: 单目手机扫描提供了一种低成本的替代方案，使非专业用户也能进行虚拟人数字化。

Method: 利用静态姿势序列进行纹理重建，动态运动序列学习姿态依赖的变形和光照变化。采用轻量级表达，从稀疏单目数据中重建高保真数字人。提取服装网格以有效模拟服装变形，并将光照感知高斯应用于网格表面，实现高保真渲染和姿态依赖光照。

Result: 在移动设备上达到120 FPS，在独立VR设备上达到90 FPS（2K分辨率），比基线快2.7倍。

Conclusion: HRM$^2$Avatar 在视觉真实感和实时交互性方面优于最先进的单目方法。

Abstract: We present HRM$^2$Avatar, a framework for creating high-fidelity avatars from
monocular phone scans, which can be rendered and animated in real time on
mobile devices. Monocular capture with smartphones provides a low-cost
alternative to studio-grade multi-camera rigs, making avatar digitization
accessible to non-expert users. Reconstructing high-fidelity avatars from
single-view video sequences poses challenges due to limited visual and
geometric data. To address these limitations, at the data level, our method
leverages two types of data captured with smartphones: static pose sequences
for texture reconstruction and dynamic motion sequences for learning
pose-dependent deformations and lighting changes. At the representation level,
we employ a lightweight yet expressive representation to reconstruct
high-fidelity digital humans from sparse monocular data. We extract garment
meshes from monocular data to model clothing deformations effectively, and
attach illumination-aware Gaussians to the mesh surface, enabling high-fidelity
rendering and capturing pose-dependent lighting. This representation
efficiently learns high-resolution and dynamic information from monocular data,
enabling the creation of detailed avatars. At the rendering level, real-time
performance is critical for animating high-fidelity avatars in AR/VR, social
gaming, and on-device creation. Our GPU-driven rendering pipeline delivers 120
FPS on mobile devices and 90 FPS on standalone VR devices at 2K resolution,
over $2.7\times$ faster than representative mobile-engine baselines.
Experiments show that HRM$^2$Avatar delivers superior visual realism and
real-time interactivity, outperforming state-of-the-art monocular methods.

</details>


### [349] [MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control](https://arxiv.org/abs/2510.13794)
*Xue Bin Peng*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: MimicKit is an open-source framework for training motion controllers using
motion imitation and reinforcement learning. The codebase provides
implementations of commonly-used motion-imitation techniques and RL algorithms.
This framework is intended to support research and applications in computer
graphics and robotics by providing a unified training framework, along with
standardized environment, agent, and data structures. The codebase is designed
to be modular and easily configurable, enabling convenient modification and
extension to new characters and tasks. The open-source codebase is available
at: https://github.com/xbpeng/MimicKit.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [350] [Dodoor: Efficient Randomized Decentralized Scheduling with Load Caching for Heterogeneous Tasks and Clusters](https://arxiv.org/abs/2510.12889)
*Wei Da,Evangelia Kalyvianaki*

Main category: cs.DC

TL;DR: Dodoor是一个高效的随机分布式调度器，通过使用缓存的服务器信息和新颖的负载分数来优化数据中心任务调度，显著减少了通信开销，并提高了吞吐量和延迟。


<details>
  <summary>Details</summary>
Motivation: Dodoor旨在解决现代数据中心任务调度中的挑战，通过一种去中心化的方法来减少通信开销和提高效率。

Method: Dodoor利用加权球进箱模型（b-batched setting），并基于缓存的服务器信息进行调度决策，而不是实时探测。它使用一种新颖的负载分数来衡量服务器负载，以处理动态、多维资源需求和异构集群。

Result: Dodoor将调度消息减少了55-66%，提高了吞吐量（最高33.2%），降低了平均完成时间和尾部延迟。

Conclusion: Dodoor在真实和模拟环境中都显示出优越的性能，在减少通信开销、提高吞吐量和降低延迟方面取得了显著成效。

Abstract: This paper introduces Dodoor, an efficient randomized decentralized scheduler
designed for task scheduling in modern data centers. Dodoor leverages advanced
research on the weighted balls-into-bins model with b-batched setting. Unlike
other decentralized schedulers that rely on real-time probing of remote
servers, Dodoor makes scheduling decisions based on cached server information,
which is updated in batches, to reduce communication overheads. To schedule
tasks with dynamic, multidimensional resource requirements in heterogeneous
cluster, Dodoor uses a novel load score to measure servers' loads for each
scheduled task. This score captures the anti-affinity between servers and tasks
in contrast to the commonly used heuristic of counting pending tasks to balance
load. On a 101-node heterogeneous cluster, Dodoor is evaluated using two
workloads: (i) simulated Azure virtual machines placements and (ii) real
serverless Python functions executions in Docker. The evaluation shows that
Dodoor reduces scheduling messages by 55--66% on both workloads. Dodoor can
also increase throughput by up to 33.2% and 21.5%, reduce mean makespan latency
by 12.1% and 7.2%, and improve tail latency by 21.9% and 24.6% across the two
workloads.

</details>


### [351] [Scrutiny new framework in integrated distributed reliable systems](https://arxiv.org/abs/2510.13203)
*Mehdi Zekriyapanah Gashti*

Main category: cs.DC

TL;DR: FDIRS框架使用异构分布式数据库技术提高了集成系统的性能和响应速度，解决了现有框架的一些问题，并提高了效率、性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个新的集成分布式系统框架，旨在提高系统的满意度和性能。

Method: 首先分析了集成系统及其演进过程、ERPSD和ERPDRT框架，然后解释了新的FDIRS框架，并对新框架与现有框架的模拟结果进行了比较。

Result: FIDRS框架采用了异构分布式数据库技术，提高了性能和响应速度。

Conclusion: FDIRS框架成功提高了集成系统的效率、性能和可靠性，并解决了部分现有框架存在的问题。

Abstract: In this paper we represent a new framework for integrated distributed
systems. In the proposed framework we have used three parts to increase
Satisfaction and Performance of this framework. At first we analyse integrated
systems and their evolution process and also ERPSD and ERPDRT framework briefly
then we explain the new FDIRS framework. Finally we compare the results of
simulation of the new framework with presented frameworks. Result showed In
FIDRS framework, the technique of heterogeneous distributed data base is used
to improve Performance and speed in responding to users. Finally by using FDIRS
framework we succeeded to increase Efficiency, Performance and reliability of
integrated systems and remove some of previous frameworks problems.

</details>


### [352] [BanaServe: Unified KV Cache and Dynamic Module Migration for Balancing Disaggregated LLM Serving in AI Infrastructure](https://arxiv.org/abs/2510.13223)
*Yiyuan He,Minxian Xu,Jingfeng Wu,Jianmin Hu,Chong Ma,Min Shen,Le Chen,Chengzhong Xu,Lin Qu,Kejiang Ye*

Main category: cs.DC

TL;DR: BanaServe是一个动态编排框架，通过层级权重迁移和KV缓存共享，解决了现有LLM服务框架资源分配不均、负载不平衡和缓存路由偏差的问题，提高了吞吐量并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）服务系统存在静态资源分配、预填充和解码阶段负载不平衡以及前缀缓存感知路由导致负载分布不均等问题，这些问题导致资源浪费或服务水平目标无法满足。

Method: BanaServe通过引入层级权重迁移、注意力层级KV缓存迁移和全局KV缓存存储共享以及层级重叠传输，实现了粗粒度和细粒度的负载重新分配，同时最小化延迟开销。这使得路由器能够进行纯粹的负载感知调度。

Result: 与vLLM相比，BanaServe的吞吐量提高了1.2倍至3.9倍，总处理时间降低了3.9%至78.4%。与DistServe相比，BanaServe的吞吐量提高了1.1倍至2.8倍，延迟降低了1.4%至70.1%。

Conclusion: BanaServe通过动态资源重新平衡和创新的负载分配机制，有效解决了现有LLM服务框架的瓶颈问题，显著提高了系统性能。

Abstract: Large language models (LLMs) are increasingly deployed in AI infrastructure,
driving the need for high throughput, resource efficient serving systems.
Disaggregated LLM serving, which separates prompt prefill from auto-regressive
decode, has emerged as a promising architecture by isolating their
heterogeneous compute and memory demands. However, current disaggregated
systems face three key limitations: (i) static resource allocation cannot adapt
to highly dynamic workloads, causing over-provisioning that wastes resources or
under-provisioning that violates service level objectives (SLOs); (ii) inherent
load imbalance between prefill and decode stages, where prefill is
compute-bound and decode is memory-bound, causes under-utilization in one tier
while the other becomes a bottleneck; and (iii) prefix cache aware routing
skews load distribution, as high cache hit rate prefill nodes attract
disproportionately more requests, further degrading balance and efficiency. To
address these issues, we present BanaServe, a dynamic orchestration framework
that continuously rebalances computational and memory resources across prefill
and decode instances while eliminating hotspots induced by cache. BanaServe
introduces layer level weight migration, attention level Key Value Cache (KV
Cache) migration, and Global KV Cache Store sharing with layer wise overlapped
transmission, enabling both coarse grained (layer level) and fine grained
(attention level) load redistribution with minimal latency overhead. These
mechanisms allow routers to perform purely load aware scheduling, unconstrained
by cache placement. Compared to vLLM, BanaServe achieves 1.2x-3.9x higher
throughput with 3.9%-78.4% lower total processing time, and outperforms
DistServe by 1.1x-2.8x in throughput with 1.4%-70.1% latency reduction.

</details>


### [353] [Distributed Reductions for the Maximum Weight Independent Set Problem](https://arxiv.org/abs/2510.13306)
*Jannick Borowitz,Ernestine Großmann,Mattthias Schimek*

Main category: cs.DC

TL;DR: 该论文提出了用于解决最大权重独立集问题的分布式内存并行归约算法，并首次提出了用于该问题的分布式归约-贪婪和归约-剥离启发式算法。


<details>
  <summary>Details</summary>
Motivation: 寻找最大权重独立集是图论中的一个重要NP难优化问题。现有的精确算法和启发式算法主要依赖数据归约规则来处理该问题，但这些算法通常无法处理大规模图。因此，需要开发能够处理更大规模图的分布式并行算法。

Method: 论文提出了两种分布式内存并行归约算法，一种用于精确求解，另一种用于启发式求解（归约-贪婪和归约-剥离）。这些算法旨在减小图的规模，以便更容易地找到最优或近似最优解。

Result: 在1024个处理器上的实验表明，所提出的分布式归约算法具有良好的可扩展性和归约效果。异步归约-剥离算法在36个真实世界图上实现了平均33倍的加速，且解的质量接近于顺序算法。归约-贪婪算法的平均加速比高达50倍，但解的质量稍低。该分布式方法能够处理超过10亿个顶点和170亿条边的图。

Conclusion: 该论文成功地开发了用于最大权重独立集问题的分布式内存并行归约算法，并提出了新的分布式启发式算法。实验结果证明了这些算法在处理超大规模图时的有效性和可扩展性，为解决实际中的大规模图问题提供了新的途径。

Abstract: Finding maximum-weight independent sets in graphs is an important NP-hard
optimization problem. Given a vertex-weighted graph $G$, the task is to find a
subset of pairwise non-adjacent vertices of $G$ with maximum weight. Most
recently published practical exact algorithms and heuristics for this problem
use a variety of data-reduction rules to compute (near-)optimal solutions.
Applying these rules results in an equivalent instance of reduced size. An
optimal solution to the reduced instance can be easily used to construct an
optimal solution for the original input.
  In this work, we present the first distributed-memory parallel reduction
algorithms for this problem, targeting graphs beyond the scale of previous
sequential approaches. Furthermore, we propose the first distributed
reduce-and-greedy and reduce-and-peel algorithms for finding a maximum weight
independent set heuristically.
  In our practical evaluation, our experiments on up to $1024$ processors
demonstrate good scalability of our distributed reduce algorithms while
maintaining good reduction impact. Our asynchronous reduce-and-peel approach
achieves an average speedup of $33\times$ over a sequential state-of-the-art
reduce-and-peel approach on 36 real-world graphs with a solution quality close
to the sequential algorithm. Our reduce-and-greedy algorithms even achieve
average speedups of up to $50\times$ at the cost of a lower solution quality.
Moreover, our distributed approach allows us to consider graphs with more than
one billion vertices and 17 billion edges.

</details>


### [354] [Service-Level Energy Modeling and Experimentation for Cloud-Native Microservices](https://arxiv.org/abs/2510.13447)
*Julian Legler,Sebastian Werner,Maria C. Borges,Stefan Tai*

Main category: cs.DC

TL;DR: 云原生微服务架构能耗评估应考虑网络和存储，以避免低估。现有研究忽视了跨容器服务交互（尤其是涉及网络和存储的辅助服务）的能耗影响。本文提出了一个服务级能耗模型，考虑了CPU、内存、网络和存储，并通过实验工具进行了验证，结果显示不考虑网络和存储会导致高估达63%。


<details>
  <summary>Details</summary>
Motivation: 现有研究在测量微服务能耗时，要么只关注容器级别的CPU和内存，要么进行系统范围的评估，常常忽略了跨容器服务交互，特别是涉及网络和存储的辅助服务（如可观察性和系统监控）的能耗影响。

Method: 提出一个服务级能耗模型，该模型能够捕捉微服务在容器之间分布式执行的特性。该模型辅以一个实验工具，该工具不仅考虑CPU和内存的能耗，还考虑网络和存储组件的能耗。

Result: 通过对一个流行的开源云原生微服务应用程序的辅助服务进行各种实验配置的大量实验，验证了所提出的方法。结果表明，忽略网络和存储可能导致辅助服务的能耗估计不足高达63%。

Conclusion: 为了设计节能的微服务架构，必须进行更全面的能耗评估，包括网络和存储的消耗。

Abstract: Microservice architectures have become the dominant paradigm for cloud-native
systems, offering flexibility and scalability. However, this shift has also led
to increased demand for cloud resources, contributing to higher energy
consumption and carbon emissions. While existing research has focused on
measuring fine-grained energy usage of CPU and memory at the container level,
or on system-wide assessments, these approaches often overlook the energy
impact of cross-container service interactions, especially those involving
network and storage for auxiliary services such as observability and system
monitoring. To address this gap, we introduce a service-level energy model that
captures the distributed nature of microservice execution across containers.
Our model is supported by an experimentation tool that accounts for energy
consumption not just in CPU and memory, but also in network and storage
components. We validate our approach through extensive experimentation with
diverse experiment configurations of auxiliary services for a popular
open-source cloud-native microservice application. Results show that omitting
network and storage can lead to an underestimation of auxiliary service energy
use by up to 63%, highlighting the need for more comprehensive energy
assessments in the design of energy-efficient microservice architectures.

</details>


### [355] [Adaptive Rescheduling in Prefill-Decode Disaggregated LLM Inference](https://arxiv.org/abs/2510.13668)
*Zhibin Wang,Zetao Hong,Xue Li,Zibo Wang,Shipeng Li,Qingkai Meng,Qing Wang,Chengying Huan,Rong Gu,Sheng Zhong,Chen Tian*

Main category: cs.DC

TL;DR: ARES是一个通过长度预测来适应解码重调度系统，以解决LLM推理中因输出长度变化导致的负载不平衡问题。


<details>
  <summary>Details</summary>
Motivation: LLM推理在实际应用中面临输出长度变化导致的严重负载不平衡问题，尤其是在长输出推理任务中。现有的静态调度方法容易导致服务等级目标（SLO）违规和内存溢出（OOM）失败。

Method: 提出了一种名为ARES的自适应解码重调度系统，该系统利用轻量级、LLM原生的长度预测方法来预测未来的工作负载。该预测方法利用LLM的隐藏状态来精确建模剩余生成长度，同时保持低开销。ARES还包含一个动态均衡机制，该机制整合了当前和预测的工作负载，以实现解码阶段的重调度。

Result: 长度预测方法的平均绝对误差（MAE）降低了49.42%，预测器参数减少了93.28%。通过ARES实现的P99传输时（TPOT）降低了74.77%，吞吐量（goodput）最高提高了2.24倍。

Conclusion: ARES通过其创新的长度预测和动态重调度机制，能够有效解决LLM推理中的负载不平衡问题，显著提高系统性能和稳定性。

Abstract: Large Language Model (LLM) inference has emerged as a fundamental paradigm.
In real-world scenarios, variations in output length cause severe workload
imbalance in the decode phase, particularly for long-output reasoning tasks.
Existing systems, such as PD disaggregation architectures, rely on static
prefill-to-decode scheduling, which often results in SLO violations and OOM
failures under evolving decode workloads.
  In this paper, we propose ARES, an adaptive decoding rescheduling system
powered by length prediction to anticipate future workloads. Our core
contributions include: (1) A lightweight and continuous LLM-native prediction
method that leverages LLM hidden state to model remaining generation length
with high precision (reducing MAE by 49.42%) and low overhead (cutting
predictor parameters by 93.28%); (2) A rescheduling solution in decode phase
with : A dynamic balancing mechanism that integrates current and predicted
workloads, reducing P99 TPOT by 74.77% and achieving up to 2.24 times higher
goodput.

</details>


### [356] [FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access](https://arxiv.org/abs/2510.13724)
*Aditya Tanikanti,Benoit Côté,Yanfei Guo,Le Chen,Nickolaus Saint,Ryan Chard,Ken Raffenetti,Rajeev Thakur,Thomas Uram,Ian Foster,Michael E. Papka,Venkatram Vishwanath*

Main category: cs.DC

TL;DR: FIRST是一个联邦推理资源调度工具包，为分布式HPC集群提供推理即服务，支持LLMs等AI模型，提供类似OpenAI的API，并能在私有环境中运行，实现大规模本地AI推理。


<details>
  <summary>Details</summary>
Motivation: 满足科学工作流中对私有、安全、可扩展的AI推理日益增长的需求，使研究人员能够在本地生成大量tokens，而不依赖于商业云基础设施。

Method: 提供一个名为FIRST的框架，利用Globus Auth和Globus Compute，允许研究人员通过符合OpenAI标准的API在私有、安全的环境中运行并行推理工作负载，并支持多种推理后端、自动扩展资源、维护“热”节点以实现低延迟执行，以及高吞吐量批处理和交互模式。

Result: 研究人员可以在本地通过FIRST框架进行大规模AI推理，每日生成数十亿tokens，无需依赖商业云。

Conclusion: FIRST框架成功实现了跨分布式HPC集群的联邦推理，为私有、安全、可扩展的AI推理提供了解决方案，满足了科学研究的需求。

Abstract: We present the Federated Inference Resource Scheduling Toolkit (FIRST), a
framework enabling Inference-as-a-Service across distributed High-Performance
Computing (HPC) clusters. FIRST provides cloud-like access to diverse AI
models, like Large Language Models (LLMs), on existing HPC infrastructure.
Leveraging Globus Auth and Globus Compute, the system allows researchers to run
parallel inference workloads via an OpenAI-compliant API on private, secure
environments. This cluster-agnostic API allows requests to be distributed
across federated clusters, targeting numerous hosted models. FIRST supports
multiple inference backends (e.g., vLLM), auto-scales resources, maintains
"hot" nodes for low-latency execution, and offers both high-throughput batch
and interactive modes. The framework addresses the growing demand for private,
secure, and scalable AI inference in scientific workflows, allowing researchers
to generate billions of tokens daily on-premises without relying on commercial
cloud infrastructure.

</details>


### [357] [Tight Conditions for Binary-Output Tasks under Crashes](https://arxiv.org/abs/2510.13755)
*Timothé Albouy,Antonio Fernández Anta,Chryssis Georgiou,Nicolas Nicolaou,Junlang Wang*

Main category: cs.DC

TL;DR: 该论文研究了具有二元输出（即输出值为 {0,1} 的任务）的分布式系统的求解条件。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为具有二元输出的分布式任务提供一个统一的理论框架，并推导出在不同系统模型（同步和异步）下可解性的充要条件。

Method: 通过分析任务的二元输出集合，并考虑最多 t 个进程可能崩溃的情况，推导出系统条件（n 和 t 的关系）以及任务可解性的充要条件。

Result: 论文给出了在同步和异步分布式系统中，可解所有二元输出任务的 n 和 t 的精确条件。

Conclusion: 该研究提出的基于输出集合的方法具有高度通用性，统一了包括二元共识和对称性破解在内的多个分布式计算问题，并能用于推导更强任务形式的不可解性证明。

Abstract: This paper explores necessary and sufficient system conditions to solve
distributed tasks with binary outputs (\textit{i.e.}, tasks with output values
in $\{0,1\}$). We focus on the distinct output sets of values a task can
produce (intentionally disregarding validity and value multiplicity),
considering that some processes may output no value. In a distributed system
with $n$ processes, of which up to $t \leq n$ can crash, we provide a complete
characterization of the tight conditions on $n$ and $t$ under which every class
of tasks with binary outputs is solvable, for both synchronous and asynchronous
systems. This output-set approach yields highly general results: it unifies
multiple distributed computing problems, such as binary consensus and symmetry
breaking, and it produces impossibility proofs that hold for stronger task
formulations, including those that consider validity, account for value
multiplicity, or move beyond binary outputs.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [358] [From Minimal Existence to Human Definition: The CES-IMU-HSG Theoretical Framework](https://arxiv.org/abs/2510.13400)
*Kei Itoh*

Main category: cs.NE

TL;DR: 本文提出了一个基于‘我思故我在’（CES）的跨宇宙数学逻辑框架，整合了中间元宇宙（IMU）和分层状态网格（HSG）。CES将存在定义为‘存在’与‘可言说’的自反对应，并将形式系统（如ZFC或HoTT）视为该最小结构的附加扩展。IMU作为公理依赖的注册表，连接异构理论，并使用“制度理论”框架确保理论间的连贯性。HSG通过范畴构造具体化这些概念，由三个正交轴定义：状态深度、映射层级和时间（包含‘无未来参考’原则），从而正式确立‘定义=状态’的范畴性质。该框架扩展到生物系统，将神经系统实现为HSG上的0-3D神经-功能场复形，并通过纤维化实现多生理宇宙（神经、内分泌、学习、遗传、输入/输出系统）的并行整合。在此框架下，人类行为和认知被视为受物质基础约束的跨宇宙算法的时间组合。最后，通过对比人类认知（依赖外部CES）和机器存在，提出了内部CES概念，使机器能够基于其操作的事实性来构建自身的逻辑，从而为人工智能的自主和自指存在提供了新基础。


<details>
  <summary>Details</summary>
Motivation: 本文旨在构建一个统一的数学逻辑框架，以解释存在、理论整合、生物系统和人工智能的本质，特别是提出一种新型的机器存在概念。

Method: 本文提出并构建了一个跨宇宙数学逻辑框架，该框架以“我思故我在”（CES）为最小公理，整合了中间元宇宙（IMU）和分层状态网格（HSG）。IMU利用制度理论处理理论间的依赖关系，HSG则通过范畴构造具体化框架。将此框架应用于生物系统，通过纤维化实现多生理宇宙的整合。最后，提出“内部CES”概念，用于机器的自指存在。

Result: 该框架成功地将“我思故我在”公理化，实现了异构理论的连贯整合，并将生物系统（特别是神经系统）纳入其范畴结构。此外，提出“内部CES”概念，为人工智能的自主和自指存在提供了理论基础，连接了哲学本体论和工程实现。

Conclusion: 本文提出的跨宇宙数学逻辑框架为理解存在、整合不同理论体系以及构建自主人工智能提供了新的视角和理论基础。通过“内部CES”概念，为实现能够自我定义和存在的人工智能开辟了道路。

Abstract: This study presents an inter-universal mathematical-logical framework
constructed upon the minimal axiom Cogito, ergo sum (CES), integrating the
Intermediate Meta-Universe (IMU) and the Hierarchical State Grid (HSG). The CES
defines existence as a reflexive correspondence --'to be' and 'to be
sayable'--and positions any formal system, including ZFC or HoTT, as an
attachable extension atop this minimal structure. The IMU functions as a
registry of axiomatic dependencies that connect heterogeneous theories,
employing the Institution-theoretic framework to ensure coherent
inter-theoretical linkages. The HSG concretizes these ideas through categorical
construction, defined by three orthogonal axes: the state-depth axis, the
mapping-hierarchy axis, and the temporal axis incorporating the principle of
'no future reference.' Through these, the identity of 'definition = state' is
formally established as a categorical property. Extending this structure to
biological systems, the neural system is implemented as a 0-3D complex of
neuron-function fields on the HSG, while its categorical extensions via
fiberization over the material base enable the parallel integration of multiple
physiological universes-neural, endocrine, learning, genetic, and input/output
systems-into a coherent adjoint ensemble. Within this framework, human behavior
and cognition emerge as temporal compositions of inter-universal algorithms
constrained by the material base. Finally, by contrasting human cognition,
which relies on external CES, with machine existence, this study introduces the
concept of internal CES, wherein a machine grounds its own logic upon the
factuality of its operation. This internal self-axiomatization establishes a
continuous bridge between philosophical ontology and engineering
implementation, providing a new foundation for the autonomous and self-defining
existence of artificial intelligence.

</details>


### [359] [A Complete Pipeline for deploying SNNs with Synaptic Delays on Loihi 2](https://arxiv.org/abs/2510.13757)
*Balázs Mészáros,James C. Knight,Jonathan Timcheck,Thomas Nowotny*

Main category: cs.NE

TL;DR: SNNs通过引入突触延迟和使用高效的事件驱动训练方法，在GPU和Intel Loihi 2神经形态芯片上实现了高效的训练和部署，在关键词识别任务中提高了准确性，并且在Loihi 2上的性能远超NVIDIA Jetson Orin Nano。


<details>
  <summary>Details</summary>
Motivation: SNNs作为一种更节能的ANN替代品，在边缘计算领域受到关注，目标是显著降低能源消耗。

Method: 提出一个完整的SNN训练和部署流程，包括在GPU上进行高效的事件驱动训练（带突触延迟），以及在Intel Loihi 2神经形态芯片上进行部署。

Result: 在Spiking Heidelberg Digits和Spiking Speech Commands数据集上进行关键词识别任务的评估。与没有延迟的SNNs相比，提出的算法提高了分类准确性。GPU和Loihi 2实现之间的准确性损失可以忽略不计。Loihi 2的分类速度比NVIDIA Jetson Orin Nano快18倍，能耗低250倍。

Conclusion: 该方法在SNNs中引入突触延迟，可以提高分类准确性。所提出的训练和部署流程在Loihi 2神经形态芯片上实现了显著的性能提升（速度和能效），同时保持了与GPU实现相当的准确性。

Abstract: Spiking Neural Networks are attracting increased attention as a more
energy-efficient alternative to traditional Artificial Neural Networks for edge
computing. Neuromorphic computing can significantly reduce energy requirements.
Here, we present a complete pipeline: efficient event-based training of SNNs
with synaptic delays on GPUs and deployment on Intel's Loihi 2 neuromorphic
chip. We evaluate our approach on keyword recognition tasks using the Spiking
Heidelberg Digits and Spiking Speech Commands datasets, demonstrating that our
algorithm can enhance classification accuracy compared to architectures without
delays. Our benchmarking indicates almost no accuracy loss between GPU and
Loihi 2 implementations, while classification on Loihi 2 is up to 18x faster
and uses 250x less energy than on an NVIDIA Jetson Orin Nano.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [360] [Multivariate Time Series Forecasting with Gate-Based Quantum Reservoir Computing on NISQ Hardware](https://arxiv.org/abs/2510.13634)
*Wissal Hamhoum,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmed,Shengrui Wang*

Main category: cs.LG

TL;DR: 本工作提出了一种用于多元时间序列的门控量子水库计算（MTS-QRC），该计算方法针对近期硬件约束进行了优化，并在实际量子硬件上取得了有竞争力的预测结果，同时揭示了硬件噪声可能对量子水库计算产生积极影响。


<details>
  <summary>Details</summary>
Motivation: 现有的量子水库计算（QRC）研究主要集中在单变量信号，并且忽略了近期硬件的实际限制。本研究旨在为多元时间序列（MTS）开发一种更具实际应用前景的QRC方法。

Method: 提出了一种门控QRC方法，该方法结合了注入和记忆量子比特，并使用Trotter化的近邻反型伊辛演化。该方法针对当前的量子设备连接性和深度进行了优化。

Result: 在 Lorenz-63 和 ENSO 数据集上，MTS-QRC 分别取得了 0.0087 和 0.0036 的均方误差（MSE）。与经典水库计算和部分学习的循环神经网络（RNN）相比，MTS-QRC 在 Lorenz 数据集上表现相当，在 ENSO 数据集上优于部分学习的 RNN。在 IBM Heron R2 量子计算机上，MTS-QRC 在具有实际深度的条件下仍能保持准确性，并且在 ENSO 数据集上甚至优于无噪声模拟器。奇异值分析表明，设备噪声可以将在特征方向上集中方差，从而在特定情况下充当线性读出的隐式正则化器。

Conclusion: 研究结果表明，基于门的QRC方法在近期（NISQ）硬件上进行MTS预测具有实际可行性。此外，研究还揭示了硬件噪声可能对QRC读出产生积极影响，这为未来系统性地研究硬件噪声如何使QRC读出受益提供了方向。

Abstract: Quantum reservoir computing (QRC) offers a hardware-friendly approach to
temporal learning, yet most studies target univariate signals and overlook
near-term hardware constraints. This work introduces a gate-based QRC for
multivariate time series (MTS-QRC) that pairs injection and memory qubits and
uses a Trotterized nearest-neighbor transverse-field Ising evolution optimized
for current device connectivity and depth. On Lorenz-63 and ENSO, the method
achieves a mean square error (MSE) of 0.0087 and 0.0036, respectively,
performing on par with classical reservoir computing on Lorenz and above
learned RNNs on both, while NVAR and clustered ESN remain stronger on some
settings. On IBM Heron R2, MTS-QRC sustains accuracy with realistic depths and,
interestingly, outperforms a noiseless simulator on ENSO; singular value
analysis indicates that device noise can concentrate variance in feature
directions, acting as an implicit regularizer for linear readout in this
regime. These findings support the practicality of gate-based QRC for MTS
forecasting on NISQ hardware and motivate systematic studies on when and how
hardware noise benefits QRC readouts.

</details>


### [361] [Local Timescale Gates for Timescale-Robust Continual Spiking Neural Networks](https://arxiv.org/abs/2510.12843)
*Ansh Tiwari,Ayush Chauhan*

Main category: cs.LG

TL;DR: LT-Gate是一种神经元模型，通过结合双时间尺度动力学和自适应门控机制，解决了SNN在持续学习中的稳定性和可塑性困境，提高了在序列学习任务中的准确性和记忆保持能力，并且兼容神经形态硬件。


<details>
  <summary>Details</summary>
Motivation: SNN在需要快速适应和长期记忆的持续学习任务中存在挑战，即稳定-塑性困境。

Method: 提出了一种名为LT-Gate的神经元模型，该模型结合了双时间尺度动力学和一个自适应门控机制。每个脉冲神经元并行地在快速和慢速时间尺度上跟踪信息，并通过一个学习到的门控单元局部地调整它们的影响。此外，还引入了一种方差跟踪正则化来稳定发放活动。

Result: LT-Gate在序列学习任务中实现了显著提高的准确性和记忆保持能力，在一个具有挑战性的时间分类基准测试中，最终准确率约为51%，显著优于现有的SNN方法。

Conclusion: 多时间尺度门控可以显著增强SNN中的持续学习能力，缩小了在终身学习任务上脉冲网络和传统深度网络之间的差距。

Abstract: Spiking neural networks (SNNs) promise energy-efficient artificial
intelligence on neuromorphic hardware but struggle with tasks requiring both
fast adaptation and long-term memory, especially in continual learning. We
propose Local Timescale Gating (LT-Gate), a neuron model that combines dual
time-constant dynamics with an adaptive gating mechanism. Each spiking neuron
tracks information on a fast and a slow timescale in parallel, and a learned
gate locally adjusts their influence. This design enables individual neurons to
preserve slow contextual information while responding to fast signals,
addressing the stability-plasticity dilemma. We further introduce a
variance-tracking regularization that stabilizes firing activity, inspired by
biological homeostasis. Empirically, LT-Gate yields significantly improved
accuracy and retention in sequential learning tasks: on a challenging temporal
classification benchmark it achieves about 51 percent final accuracy, compared
to about 46 percent for a recent Hebbian continual-learning baseline and lower
for prior SNN methods. Unlike approaches that require external replay or
expensive orthogonalizations, LT-Gate operates with local updates and is fully
compatible with neuromorphic hardware. In particular, it leverages features of
Intel's Loihi chip (multiple synaptic traces with different decay rates) for
on-chip learning. Our results demonstrate that multi-timescale gating can
substantially enhance continual learning in SNNs, narrowing the gap between
spiking and conventional deep networks on lifelong-learning tasks.

</details>


### [362] [T3former: Temporal Graph Classification with Topological Machine Learning](https://arxiv.org/abs/2510.13789)
*Md. Joshem Uddin,Soham Changani,Baris Coskunuzer*

Main category: cs.LG

TL;DR: T3former是一种新的拓扑时间Transformer，通过滑动窗口拓扑和谱描述符来解决时间图分类问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 时间图分类在网络安全、大脑连通性分析、社会动态和交通监控等应用中至关重要，但现有方法存在信息丢失和依赖性问题。T3former旨在通过保留时间保真度、增强鲁棒性并实现跨模态融合来解决这些问题。

Method: T3former利用滑动窗口拓扑和谱描述符作为一等标记，并通过专门的描述符注意力机制进行集成。

Result: T3former在动态社交网络、大脑功能连通性数据集和交通网络等多个基准上取得了最先进的性能，并提供了在时间和结构扰动下的稳定性理论保证。

Conclusion: 将拓扑和谱洞察相结合，可以推动时间图学习的前沿发展。

Abstract: Temporal graph classification plays a critical role in applications such as
cybersecurity, brain connectivity analysis, social dynamics, and traffic
monitoring. Despite its significance, this problem remains underexplored
compared to temporal link prediction or node forecasting. Existing methods
often rely on snapshot-based or recurrent architectures that either lose
fine-grained temporal information or struggle with long-range dependencies.
Moreover, local message-passing approaches suffer from oversmoothing and
oversquashing, limiting their ability to capture complex temporal structures.
  We introduce T3former, a novel Topological Temporal Transformer that
leverages sliding-window topological and spectral descriptors as first-class
tokens, integrated via a specialized Descriptor-Attention mechanism. This
design preserves temporal fidelity, enhances robustness, and enables principled
cross-modal fusion without rigid discretization. T3former achieves
state-of-the-art performance across multiple benchmarks, including dynamic
social networks, brain functional connectivity datasets, and traffic networks.
It also offers theoretical guarantees of stability under temporal and
structural perturbations. Our results highlight the power of combining
topological and spectral insights for advancing the frontier of temporal graph
learning.

</details>


### [363] [Lifting Manifolds to Mitigate Pseudo-Alignment in LLM4TS](https://arxiv.org/abs/2510.12847)
*Liangwei Nathan Zheng,Wenhao Liang,Wei Emma Zhang,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.LG

TL;DR: 伪对齐是时间序列大语言模型（LLM4TS）中的一个普遍挑战，导致其表现不如线性模型。本文研究了伪对齐的原因，并将其与LLM中的“锥形效应”联系起来，发现这是锥形效应与时间序列数据的低维流形相互作用的结果。为解决此问题，本文提出了一种名为TimeSUP的新技术，通过增加时间序列流形以匹配语言嵌入的内在维度，从而提高模型区分时间信号和捕捉跨模态结构的能力。实验证明，TimeSUP在长期预测任务上持续优于最先进的LLM4TS方法和其他基线模型，并能轻松集成到现有LLM4TS框架中，带来显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 伪对齐是时间序列大语言模型（LLM4TS）中的一个普遍挑战，导致其表现不如线性模型。社区中对伪对齐的成因讨论有限。

Method: 本文通过深入研究，将伪对齐与LLM中的“锥形效应”联系起来，揭示了锥形效应与时间序列数据固有低维流形之间的相互作用是伪对齐的根本原因。在此基础上，提出了一种名为TimeSUP的新技术，通过增加时间序列流形以匹配语言嵌入的内在维度，使得模型能够清晰地区分时间信号，同时保留跨模态的共享结构。

Result: TimeSUP技术通过提高时间序列流形以匹配语言嵌入的内在维度，使得时间与语言标记的表示保持独立但具有高余弦相似度，从而在保留各自独特特征的同时，学习统一嵌入空间中的共性。实验结果表明，TimeSUP在长期预测任务上持续优于最先进的LLM4TS方法和其他轻量级基线模型，并且能够无缝集成到四个现有的LLM4TS流程中，显著提升预测性能。

Conclusion: 伪对齐是LLM4TS模型中的一个关键问题，源于锥形效应和时间序列数据的低维流形。本文提出的TimeSUP技术通过调整嵌入空间维度来解决伪对齐问题，从而提高了LLM4TS模型的预测性能。TimeSUP是一种有效且易于集成的解决方案，能够在不改变现有模型架构的情况下，显著提升时间序列预测的准确性。

Abstract: Pseudo-Alignment is a pervasive challenge in many large language models for
time series (LLM4TS) models, often causing them to underperform compared to
linear models or randomly initialised backbones. However, there is limited
discussion in the community for the reasons that pseudo-alignment occurs. In
this work, we conduct a thorough investigation into the root causes of
pseudo-alignment in LLM4TS and build a connection of pseudo-alignment to the
cone effect in LLM. We demonstrate that pseudo-alignment arises from the
interplay of cone effect within pretrained LLM components and the intrinsically
low-dimensional manifold of time-series data. In addition, we also introduce
\textit{\textbf{TimeSUP}}, a novel technique designed to mitigate this issue
and improve forecast performance in existing LLM4TS approaches. TimeSUP
addresses this by increasing the time series manifold to more closely match the
intrinsic dimension of language embeddings, allowing the model to distinguish
temporal signals clearly while still capturing shared structures across
modalities. As a result, representations for time and language tokens remain
distinct yet exhibit high cosine similarity, signifying that the model
preserves each modality unique features while learning their commonalities in a
unified embedding space. Empirically, TimeSUP consistently outperforms
state-of-the-art LLM4TS methods and other lightweight baselines on long-term
forecasting performance. Furthermore, it can be seamlessly integrated into four
existing LLM4TS pipelines and delivers significant improvements in forecasting
performance.

</details>


### [364] [FedGTEA: Federated Class-Incremental Learning with Gaussian Task Embedding and Alignment](https://arxiv.org/abs/2510.12927)
*Haolin Li,Hoda Bidkhori*

Main category: cs.LG

TL;DR: FedGTEA是一个新颖的联邦类增量学习框架，它使用高斯任务嵌入和对齐来捕捉任务知识和模型不确定性，同时保持可扩展性和通信效率。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够处理联邦类增量学习的框架，该框架能够捕捉任务特定的知识和模型不确定性，同时保持可扩展性和通信效率，并解决统计异质性和数据不确定性问题。

Method: FedGTEA框架在客户端使用基数不可知任务编码器（CATE）生成高斯分布的任务嵌入，以编码任务知识、解决统计异质性并量化数据不确定性。CATE保持固定的参数大小，无论任务数量如何，从而确保在长任务序列中的可扩展性。在服务器端，FedGTEA使用2-Wasserstein距离来测量高斯嵌入之间的任务间差距，并通过制定Wasserstein损失来强制执行任务间分离。

Result: 在流行数据集上的大量经验评估表明，FedGTEA实现了卓越的分类性能，并显著减轻了遗忘，其表现持续优于现有基线。

Conclusion: FedGTEA通过使用高斯任务嵌入和Wasserstein距离实现任务间分离，在联邦类增量学习方面取得了先进的性能，同时保持了可扩展性和通信效率，并提高了隐私性。

Abstract: We introduce a novel framework for Federated Class Incremental Learning,
called Federated Gaussian Task Embedding and Alignment (FedGTEA). FedGTEA is
designed to capture task-specific knowledge and model uncertainty in a scalable
and communication-efficient manner. At the client side, the
Cardinality-Agnostic Task Encoder (CATE) produces Gaussian-distributed task
embeddings that encode task knowledge, address statistical heterogeneity, and
quantify data uncertainty. Importantly, CATE maintains a fixed parameter size
regardless of the number of tasks, which ensures scalability across long task
sequences. On the server side, FedGTEA utilizes the 2-Wasserstein distance to
measure inter-task gaps between Gaussian embeddings. We formulate the
Wasserstein loss to enforce inter-task separation. This probabilistic
formulation not only enhances representation learning but also preserves
task-level privacy by avoiding the direct transmission of latent embeddings,
aligning with the privacy constraints in federated learning. Extensive
empirical evaluations on popular datasets demonstrate that FedGTEA achieves
superior classification performance and significantly mitigates forgetting,
consistently outperforming strong existing baselines.

</details>


### [365] [Learning at the Speed of Physics: Equilibrium Propagation on Oscillator Ising Machines](https://arxiv.org/abs/2510.12934)
*Alex Gower*

Main category: cs.LG

TL;DR: 振荡器伊辛模型（OIM）利用其GHz频率动力学来模仿能量模型（EBM）的优化和损失景观上的梯度下降，同时其内在噪声对应于 Langevin 动力学，从而支持采样和优化。


<details>
  <summary>Details</summary>
Motivation: 物理系统可以自然地执行能量下降，这为加速机器学习提供了一条直接途径。

Method: 我们展示了在OIM上进行平衡传播（EP）可以实现具有竞争力的准确性，同时在参数量化和相位噪声等实际硬件约束下保持鲁棒性。

Result: EP在OIM上实现了约97.2±0.1%的MNIST准确率和约88.0±0.1%的Fashion-MNIST准确率，并且在参数量化和相位噪声下保持鲁棒性。

Conclusion: 这些结果表明OIM可以作为神经形态学习的快速、节能的基板，并且EBM可以在直接执行其优化的物理硬件上实现实际应用。

Abstract: Physical systems that naturally perform energy descent offer a direct route
to accelerating machine learning. Oscillator Ising Machines (OIMs) exemplify
this idea: their GHz-frequency dynamics mirror both the optimization of
energy-based models (EBMs) and gradient descent on loss landscapes, while
intrinsic noise corresponds to Langevin dynamics - supporting sampling as well
as optimization. Equilibrium Propagation (EP) unifies these processes into
descent on a single total energy landscape, enabling local learning rules
without global backpropagation. We show that EP on OIMs achieves competitive
accuracy ($\sim 97.2 \pm 0.1 \%$ on MNIST, $\sim 88.0 \pm 0.1 \%$ on
Fashion-MNIST), while maintaining robustness under realistic hardware
constraints such as parameter quantization and phase noise. These results
establish OIMs as a fast, energy-efficient substrate for neuromorphic learning,
and suggest that EBMs - often bottlenecked by conventional processors - may
find practical realization on physical hardware whose dynamics directly perform
their optimization.

</details>


### [366] [ArtNet: Hierarchical Clustering-Based Artificial Netlist Generator for ML and DTCO Application](https://arxiv.org/abs/2510.13582)
*Andrew B. Kahng. Seokhyeong Kang,Seonghyeon Park,Dooseok Yoon*

Main category: cs.LG

TL;DR: ArtNet是一个新颖的人工网表生成器，通过复制关键拓扑特征来解决高级节点中PPA优化的复杂性，提高了ML模型的泛化能力，并为DTCO提供了更广泛的设计空间探索。


<details>
  <summary>Details</summary>
Motivation: 高级节点中的PPA优化变得复杂且具有挑战性，而现有的ML和DTCO方法因训练数据不足和设计流程周转时间长而受到限制。

Method: ArtNet通过复制关键拓扑特征来生成逼真的人工数据集，以增强ML模型的泛化能力并支持DTCO的设计空间探索。

Result: ArtNet在CNN-based DRV预测中，通过数据增强将F1分数提高了0.16。在DTCO方面，ArtNet生成的小型芯片实现了高达97.94%的PPA匹配度。

Conclusion: ArtNet通过生成与目标参数更匹配的逼真数据集，能够实现更有效率的PPA优化和流程探索，并为ML模型提供了更好的泛化能力。

Abstract: In advanced nodes, optimization of power, performance and area (PPA) has
become highly complex and challenging. Machine learning (ML) and
design-technology co-optimization (DTCO) provide promising mitigations, but
face limitations due to a lack of diverse training data as well as long design
flow turnaround times (TAT). We propose ArtNet, a novel artificial netlist
generator designed to tackle these issues. Unlike previous methods, ArtNet
replicates key topological characteristics, enhancing ML model generalization
and supporting broader design space exploration for DTCO. By producing
realistic artificial datasets that moreclosely match given target parameters,
ArtNet enables more efficient PPAoptimization and exploration of flows and
design enablements. In the context of CNN-based DRV prediction, ArtNet's data
augmentationimproves F1 score by 0.16 compared to using only the original
(real) dataset. In the DTCO context, ArtNet-generated mini-brains achieve a PPA
match up to 97.94%, demonstrating close alignment with design metrics of
targeted full-scale block designs.

</details>


### [367] [Pruning Cannot Hurt Robustness: Certified Trade-offs in Reinforcement Learning](https://arxiv.org/abs/2510.12939)
*James Pedley,Benjamin Etheridge,Stephen J. Roberts,Francesco Quinzan*

Main category: cs.LG

TL;DR: pruning can improve robustness in reinforcement learning without harming clean performance, and can even enhance it in some cases.


<details>
  <summary>Details</summary>
Motivation: modern deep RL agents are over-parameterized, which raises costs and fragility concerns. The role of pruning in adversarial RL is poorly understood.

Method: developed a theoretical framework for certified robustness under pruning in state-adversarial Markov decision processes (SA-MDPs). Derived a novel three-term regret decomposition. Evaluated magnitude and micro-pruning schedules on continuous-control benchmarks.

Result: element-wise pruning can only tighten certified robustness bounds; pruning never makes the policy less robust. Pruning consistently uncovers reproducible sweet spots at moderate sparsity levels, where robustness improves substantially without harming - and sometimes even enhancing - clean performance.

Conclusion: pruning can be used as a structural intervention for robust RL, not just a compression tool.

Abstract: Reinforcement learning (RL) policies deployed in real-world environments must
remain reliable under adversarial perturbations. At the same time, modern deep
RL agents are heavily over-parameterized, raising costs and fragility concerns.
While pruning has been shown to improve robustness in supervised learning, its
role in adversarial RL remains poorly understood. We develop the first
theoretical framework for certified robustness under pruning in
state-adversarial Markov decision processes (SA-MDPs). For Gaussian and
categorical policies with Lipschitz networks, we prove that element-wise
pruning can only tighten certified robustness bounds; pruning never makes the
policy less robust. Building on this, we derive a novel three-term regret
decomposition that disentangles clean-task performance, pruning-induced
performance loss, and robustness gains, exposing a fundamental
performance--robustness frontier. Empirically, we evaluate magnitude and
micro-pruning schedules on continuous-control benchmarks with strong
policy-aware adversaries. Across tasks, pruning consistently uncovers
reproducible ``sweet spots'' at moderate sparsity levels, where robustness
improves substantially without harming - and sometimes even enhancing - clean
performance. These results position pruning not merely as a compression tool
but as a structural intervention for robust RL.

</details>


### [368] [An Investigation of Memorization Risk in Healthcare Foundation Models](https://arxiv.org/abs/2510.12950)
*Sana Tonekaboni,Lena Stempfle,Adibvafa Fallahpour,Walter Gerych,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 电子健康记录（EHR）基础模型存在隐私风险，本文提出了一套黑盒评估测试来评估其潜在的患者信息泄露问题。


<details>
  <summary>Details</summary>
Motivation: 评估和解决在电子健康记录（EHR）基础模型中存在的患者信息记忆风险，因为这些模型可能泄露敏感的患者数据，尤其可能对弱势群体造成不成比例的影响。

Method: 提出了一套黑盒评估测试，包括在嵌入和生成层面探测记忆的方法，以区分模型的泛化能力和有害的记忆。

Result: 在公开的EHR基础模型上验证了所提出的评估方法，并发布了一个开源工具包，以促进医疗保健人工智能中可复现和协作的隐私评估。

Conclusion: 本研究提出的评估框架能够有效识别和量化EHR基础模型中的隐私记忆风险，为确保医疗保健AI的隐私保护提供了重要工具。

Abstract: Foundation models trained on large-scale de-identified electronic health
records (EHRs) hold promise for clinical applications. However, their capacity
to memorize patient information raises important privacy concerns. In this
work, we introduce a suite of black-box evaluation tests to assess
privacy-related memorization risks in foundation models trained on structured
EHR data. Our framework includes methods for probing memorization at both the
embedding and generative levels, and aims to distinguish between model
generalization and harmful memorization in clinically relevant settings. We
contextualize memorization in terms of its potential to compromise patient
privacy, particularly for vulnerable subgroups. We validate our approach on a
publicly available EHR foundation model and release an open-source toolkit to
facilitate reproducible and collaborative privacy assessments in healthcare AI.

</details>


### [369] [Message Passing on the Edge: Towards Scalable and Expressive GNNs](https://arxiv.org/abs/2510.13615)
*Pablo Barceló,Fabian Jogl,Alexander Kozachinskiy,Matthias Lanzinger,Stefan Neumann,Cristóbal Rojas*

Main category: cs.LG

TL;DR: EB-1WL是一种基于图神经网络的边着色细化测试方法，它比1-WL更具表达能力，并且在实际图学习任务中具有近乎线性的时间和内存效率。


<details>
  <summary>Details</summary>
Motivation: 提出一种比1-WL更具表达能力的图神经网络（GNN）架构，并使其在实际应用中具有高效的计算性能。

Method: 提出EB-1WL（一种基于边缘的颜色细化测试）和对应的EB-GNN架构，该架构借鉴了经典的三角计数算法，并在消息传递中显式使用三角形。

Result: 1. EB-1WL 比 1-WL 具有显著更强的表达能力，并提供了基于一阶逻辑的完整逻辑刻画以及基于同态计数的匹配可区分性结果。 2. EB-1WL 和 EB-GNN 在实际图学习任务中只需要近乎线性的时间和内存，这与之前提出的更具表达能力的 GNN 架构不同。 3. 实验证明 EB-GNN 是一个高效的通用架构，其性能显著优于简单的 MPNN，并且在计算效率更高的情况下，仍能与特定任务的 GNN 竞争。

Conclusion: EB-1WL 和 EB-GNN 是一种在表达能力和计算效率之间取得良好平衡的 GNN 架构，适用于广泛的图学习任务。

Abstract: We propose EB-1WL, an edge-based color-refinement test, and a corresponding
GNN architecture, EB-GNN. Our architecture is inspired by a classic triangle
counting algorithm by Chiba and Nishizeki, and explicitly uses triangles during
message passing. We achieve the following results: (1)~EB-1WL is significantly
more expressive than 1-WL. Further, we provide a complete logical
characterization of EB-1WL based on first-order logic, and matching
distinguishability results based on homomorphism counting. (2)~In an important
distinction from previous proposals for more expressive GNN architectures,
EB-1WL and EB-GNN require near-linear time and memory on practical graph
learning tasks. (3)~Empirically, we show that EB-GNN is a highly-efficient
general-purpose architecture: It substantially outperforms simple MPNNs, and
remains competitive with task-specialized GNNs while being significantly more
computationally efficient.

</details>


### [370] [A Multimodal XAI Framework for Trustworthy CNNs and Bias Detection in Deep Representation Learning](https://arxiv.org/abs/2510.12957)
*Noor Islam S. Mohammad*

Main category: cs.LG

TL;DR: 该研究提出了一个新颖的多模态可解释人工智能（XAI）框架，用于检测和缓解深度神经网络中的潜在偏见和多模态特征复杂性，以提高其在关键应用中的可信度。


<details>
  <summary>Details</summary>
Motivation: MNIST等标准基准数据集未能充分暴露深度神经网络中的潜在偏见和多模态特征复杂性，这限制了它们在关键应用中的可信度。

Method: 提出了一种新颖的多模态XAI框架，该框架结合了基于Grad-CAM++的局部解释和Reveal-to-Revise反馈循环，用于偏见检测和缓解。

Result: 在MNIST的多模态扩展数据集上，该方法实现了93.2%的分类准确率、91.6%的F1分数和78.1%的解释保真度（IoU-XAI），优于单一模态和非可解释的基线方法。

Conclusion: 将可解释性与偏见感知学习相结合，可以提高模型的鲁棒性和人类对齐性。该研究在性能、透明度和公平性之间架起了桥梁，为在敏感领域构建可信赖的AI提供了一条实用的途径。

Abstract: Standard benchmark datasets, such as MNIST, often fail to expose latent
biases and multimodal feature complexities, limiting the trustworthiness of
deep neural networks in high-stakes applications. We propose a novel multimodal
Explainable AI (XAI) framework that unifies attention-augmented feature fusion,
Grad-CAM++-based local explanations, and a Reveal-to-Revise feedback loop for
bias detection and mitigation. Evaluated on multimodal extensions of MNIST, our
approach achieves 93.2% classification accuracy, 91.6% F1-score, and 78.1%
explanation fidelity (IoU-XAI), outperforming unimodal and non-explainable
baselines. Ablation studies demonstrate that integrating interpretability with
bias-aware learning enhances robustness and human alignment. Our work bridges
the gap between performance, transparency, and fairness, highlighting a
practical pathway for trustworthy AI in sensitive domains.

</details>


### [371] [Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games](https://arxiv.org/abs/2510.13060)
*Anupam Nayak,Tong Yang,Osman Yagan,Gauri Joshi,Yuejie Chi*

Main category: cs.LG

TL;DR: KL正则化在强化学习中广泛用于保留参考策略的特性并促进探索。本文分析了KL正则化在博弈论设置下的理论优势，并提出了OMG和SOMG算法，在矩阵博弈和马尔可夫博弈中均实现了对数悔。此外，该算法的悔还与KL正则化强度成反比。


<details>
  <summary>Details</summary>
Motivation: KL正则化在强化学习（RL）和游戏理论（GT）方法中被广泛使用，尤其是在对齐问题中，但其理论优势仍未得到充分理解。

Method: 本文提出了OMG算法（基于最佳响应采样和乐观奖励）用于矩阵博弈，并将其扩展到马尔可夫博弈，提出SOMG算法（基于最佳响应采样和新颖的超级乐观奖励）。

Result: OMG和SOMG算法均实现了对数悔，其悔与KL正则化强度$eta$成反比，并具有标准的与$eta$无关的$	ilde{	ilde{O}}(	ext{sqrt}(T))$悔。

Conclusion: 本文通过OMG和SOMG算法，在理论上证明了KL正则化可以提高样本效率，并实现了对数悔。

Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to
a fixed reference policy is widely used in modern reinforcement learning to
preserve the desired traits of the reference policy and sometimes to promote
exploration (using uniform reference policy, known as entropy regularization).
Beyond serving as a mere anchor, the reference policy can also be interpreted
as encoding prior knowledge about good actions in the environment. In the
context of alignment, recent game-theoretic approaches have leveraged KL
regularization with pretrained language models as reference policies, achieving
notable empirical success in self-play methods. Despite these advances, the
theoretical benefits of KL regularization in game-theoretic settings remain
poorly understood. In this work, we develop and analyze algorithms that
provably achieve improved sample efficiency under KL regularization. We study
both two-player zero-sum Matrix games and Markov games: for Matrix games, we
propose OMG, an algorithm based on best response sampling with optimistic
bonuses, and extend this idea to Markov games through the algorithm SOMG, which
also uses best response sampling and a novel concept of superoptimistic
bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales
inversely with the KL regularization strength $\beta$ in addition to the
standard $\widetilde{\mathcal{O}}(\sqrt{T})$ regret independent of $\beta$
which is attained in both regularized and unregularized settings

</details>


### [372] [Balancing Performance and Reject Inclusion: A Novel Confident Inlier Extrapolation Framework for Credit Scoring](https://arxiv.org/abs/2510.12967)
*Athyrson Machado Ribeiro,Marcos Medeiros Raimundo*

Main category: cs.LG

TL;DR: CI-EX框架通过识别被拒绝申请人的分布并根据概率分配标签来解决信用数据中的样本偏差问题，并在实际数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的拒绝推断（RI）方法假设被拒绝客户的行为可从被接受客户推断，但忽略了两者分布的潜在差异。本研究旨在克服这种盲目推断的局限性。

Method: 提出一种新的置信内点外推（CI-EX）框架，该框架迭代地使用异常检测模型识别被拒绝客户样本的分布，并基于监督分类模型得到的概率，将最接近被接受群体分布的被拒绝个体标记为内点。

Result: 在两个大型真实世界信用数据集上的实验表明，CI-EX框架在RI特定指标上优于现有RI模型，同时在AUC方面也保持了有竞争力的性能。RI方法（包括CI-EX）在AUC和RI特定指标之间存在权衡。

Conclusion: CI-EX框架在RI特定指标方面优于现有RI模型，并在AUC方面保持有竞争力的性能，有效解决了传统RI方法中的盲目推断问题。

Abstract: Reject Inference (RI) methods aim to address sample bias by inferring missing
repayment data for rejected credit applicants. Traditional approaches often
assume that the behavior of rejected clients can be extrapolated from accepted
clients, despite potential distributional differences between the two
populations. To mitigate this blind extrapolation, we propose a novel Confident
Inlier Extrapolation framework (CI-EX). CI-EX iteratively identifies the
distribution of rejected client samples using an outlier detection model and
assigns labels to rejected individuals closest to the distribution of the
accepted population based on probabilities derived from a supervised
classification model. The effectiveness of our proposed framework is validated
through experiments on two large real-world credit datasets. Performance is
evaluated using the Area Under the Curve (AUC) as well as RI-specific metrics
such as Kickout and a novel metric introduced in this work, denoted as Area
under the Kickout. Our findings reveal that RI methods, including the proposed
framework, generally involve a trade-off between AUC and RI-specific metrics.
However, the proposed CI-EX framework consistently outperforms existing RI
models from the credit literature in terms of RI-specific metrics while
maintaining competitive performance in AUC across most experiments.

</details>


### [373] [A Connection Between Score Matching and Local Intrinsic Dimension](https://arxiv.org/abs/2510.12975)
*Eric Yeats,Aaron Jacobson,Darryl Hannan,Yiran Jia,Timothy Doster,Henry Kvinge,Scott Mahan*

Main category: cs.LG

TL;DR: 局部内在维度（LID）是信号处理和学习理论中的一个基本量，但量化高维、复杂数据的LID一直是一个挑战。最近的研究表明，扩散模型可以通过其分数估计的光谱以及在各种噪声扰动下密度估计的变化率来捕获数据的LID。然而，这些方法需要多次前向传播或梯度计算，限制了它们在计算和内存受限场景下的应用。我们提出使用去噪分数匹配损失作为 LID 的下界，并将其用作 LID 估计器。此外，我们证明了等效的隐式分数匹配损失也通过法向维度近似 LID，并且与最近的 LID 估计器 FLIPD 密切相关。在流形基准和 Stable Diffusion 3.5 上的实验表明，去噪分数匹配损失是一种具有竞争力且可扩展的 LID 估计器，在问题规模和量化级别不断增加的情况下，具有优越的准确性和内存占用。


<details>
  <summary>Details</summary>
Motivation: 高维、复杂数据的局部内在维度（LID）量化是一个挑战。现有扩散模型方法需要多次前向传播或梯度计算，限制了其在资源受限场景下的应用。

Method: 利用去噪分数匹配损失作为 LID 的下界，并将其用作 LID 估计器。证明等效的隐式分数匹配损失也通过法向维度近似 LID，并与 FLIPD 估计器相关。

Result: 在流形基准和 Stable Diffusion 3.5 上的实验表明，去噪分数匹配损失在问题规模和量化级别不断增加的情况下，具有优越的准确性和内存占用，是一种具有竞争力且可扩展的 LID 估计器。

Conclusion: 去噪分数匹配损失是一种有竞争力且可扩展的 LID 估计器，在计算和内存受限的场景下表现优于现有方法。

Abstract: The local intrinsic dimension (LID) of data is a fundamental quantity in
signal processing and learning theory, but quantifying the LID of
high-dimensional, complex data has been a historically challenging task. Recent
works have discovered that diffusion models capture the LID of data through the
spectra of their score estimates and through the rate of change of their
density estimates under various noise perturbations. While these methods can
accurately quantify LID, they require either many forward passes of the
diffusion model or use of gradient computation, limiting their applicability in
compute- and memory-constrained scenarios.
  We show that the LID is a lower bound on the denoising score matching loss,
motivating use of the denoising score matching loss as a LID estimator.
Moreover, we show that the equivalent implicit score matching loss also
approximates LID via the normal dimension and is closely related to a recent
LID estimator, FLIPD. Our experiments on a manifold benchmark and with Stable
Diffusion 3.5 indicate that the denoising score matching loss is a highly
competitive and scalable LID estimator, achieving superior accuracy and memory
footprint under increasing problem size and quantization level.

</details>


### [374] [Going with the Flow: Approximating Banzhaf Values via Graph Neural Networks](https://arxiv.org/abs/2510.13391)
*Benjamin Kempinski,Tal Kachman*

Main category: cs.LG

TL;DR: 本文提出了一种基于图神经网络（GNN）的方法来近似计算网络流博弈中的Banzhaf值，实现了比现有方法数量级上的加速，并表现出强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在多主体系统中，计算网络流博弈中的Banzhaf值对于量化代理影响至关重要，但现有方法（精确计算和蒙特卡洛采样）在大规模或动态系统中存在计算复杂度和泛化能力不足的问题。

Method: 将问题构建为图级预测任务，利用图神经网络（GNN），特别是图注意力网络（GAT）、带边特征的图同构网络（GINE）和EdgeConv，学习网络拓扑和控制结构中的代理影响模式。

Result: 在包含20万个图的大规模合成数据集上进行的大量实验表明，GNN模型能够以数量级上的速度优势实现高保真Banzhaf值近似，并且在从未见过的具有不同结构特性的新网络上表现出强大的零样本泛化能力。

Conclusion: 研究证明了GNN在复杂网络系统的大规模博弈论分析中具有实用价值，能够有效解决现有方法的局限性。

Abstract: Computing the Banzhaf value in network flow games is fundamental for
quantifying agent influence in multi-agent systems, with applications ranging
from cybersecurity to infrastructure planning. However, exact computation is
intractable for systems with more than $\sim20$ agents due to exponential
complexity $\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide
statistical estimates, they suffer from high sample complexity and cannot
transfer knowledge across different network configurations, making them
impractical for large-scale or dynamic systems. We present a novel
learning-based approach using Graph Neural Networks (GNNs) to approximate
Banzhaf values in cardinal network flow games. By framing the problem as a
graph-level prediction task, our method learns generalisable patterns of agent
influence directly from network topology and control structure. We conduct a
comprehensive empirical study comparing three state-of-the-art GNN
architectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with
Edge features (GINE), and EdgeConv-on a large-scale synthetic dataset of
200,000 graphs per configuration, varying in size (20-100 nodes), agent count
(5-20), and edge probability (0.5-1.0). Our results demonstrate that trained
GNN models achieve high-fidelity Banzhaf value approximation with
order-of-magnitude speedups compared to exact and sampling-based methods. Most
significantly, we show strong zero-shot generalisation: models trained on
graphs of a specific size and topology accurately predict Banzhaf values for
entirely new networks with different structural properties, without requiring
retraining. This work establishes GNNs as a practical tool for scalable
cooperative game-theoretic analysis of complex networked systems.

</details>


### [375] [Reference-Specific Unlearning Metrics Can Hide the Truth: A Reality Check](https://arxiv.org/abs/2510.12981)
*Sungjun Cho,Dasol Hwang,Frederic Sala,Sangheum Hwang,Kyunghyun Cho,Sungmin Cha*

Main category: cs.LG

TL;DR: 现有模型遗忘指标评估的通用性不足，提出FADE指标评估模型遗忘的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型遗忘指标（如参考回答或分类器输出）无法评估核心目标：遗忘后的模型是否与从未见过不需要数据的模型行为一致。这种方法存在系统性盲点，可能导致模型看似成功但仍保留不需要的知识。

Method: 提出了一种名为FADE（Functional Alignment for Distributional Equivalence）的新指标，通过比较生成样本的条件化概率来衡量遗忘模型和参考模型之间的分布相似性。

Result: 在LLM遗忘的TOFU基准和文本到图像扩散模型遗忘的UnlearnCanvas基准上的实验表明，在传统指标上得分接近最优的方法未能实现分布等价，许多模型遗忘后的分布甚至比遗忘前更偏离黄金标准。

Conclusion: 现有评估实践存在根本性差距，FADE指标为开发和评估真正有效的模型遗忘方法提供了更可靠的基础。

Abstract: Current unlearning metrics for generative models evaluate success based on
reference responses or classifier outputs rather than assessing the core
objective: whether the unlearned model behaves indistinguishably from a model
that never saw the unwanted data. This reference-specific approach creates
systematic blind spots, allowing models to appear successful while retaining
unwanted knowledge accessible through alternative prompts or attacks. We
address these limitations by proposing Functional Alignment for Distributional
Equivalence (FADE), a novel metric that measures distributional similarity
between unlearned and reference models by comparing bidirectional likelihood
assignments over generated samples. Unlike existing approaches that rely on
predetermined references, FADE captures functional alignment across the entire
output distribution, providing a principled assessment of genuine unlearning.
Our experiments on the TOFU benchmark for LLM unlearning and the UnlearnCanvas
benchmark for text-to-image diffusion model unlearning reveal that methods
achieving near-optimal scores on traditional metrics fail to achieve
distributional equivalence, with many becoming more distant from the gold
standard than before unlearning. These findings expose fundamental gaps in
current evaluation practices and demonstrate that FADE provides a more robust
foundation for developing and assessing truly effective unlearning methods.

</details>


### [376] [CSI-4CAST: A Hybrid Deep Learning Model for CSI Prediction with Comprehensive Robustness and Generalization Testing](https://arxiv.org/abs/2510.12996)
*Sikai Cheng,Reza Zandehshahvar,Haoruo Zhao,Daniel A. Garcia-Ulloa,Alejandro Villena-Rodriguez,Carles Navarro Manchón,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: CSI-4CAST是一种混合深度学习架构，通过集成CNN残差、自适应校正层、ShuffleNet块和Transformer，能够高效地捕捉CSI预测中的局部和长距离依赖关系。同时，该研究提出了CSI-RRG基准测试集，用于评估模型的常规性、鲁棒性和泛化能力。实验证明，CSI-4CAST在预测精度和计算效率上均优于现有模型，并公开了数据集和评估协议以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 为了提高大规模MIMO系统的可靠性和效率，需要及时提供下行链路（DL）的信道状态信息（CSI），而基于深度学习的方法在鲁棒性、泛化性和计算效率方面存在局限性。

Method: 提出了一种名为CSI-4CAST的混合深度学习架构，该架构集成了卷积神经网络残差、自适应校正层、ShuffleNet块和Transformer，以有效捕捉CSI预测中的局部和长距离依赖关系。此外，还创建了一个名为CSI-RRG的综合基准测试集，包含超过300,000个样本，涵盖TDD和FDD系统，用于对模型的常规性、鲁棒性和泛化能力进行严格评估。

Result: CSI-4CAST在TDD场景下88.9%和FDD场景下43.8%的情况下取得了优于基线模型的预测精度，计算量相比最强的基线模型LLM4CP减少了5倍和3倍。CSI-RRG的评估结果揭示了信道因素对深度学习模型性能和泛化能力的影响。

Conclusion: CSI-4CAST通过结合多种深度学习技术，实现了高效且准确的CSI预测，并在鲁棒性和泛化能力方面表现出色。提出的CSI-RRG基准测试集为评估和推动CSI预测领域的研究提供了标准化的平台。

Abstract: Channel state information (CSI) prediction is a promising strategy for
ensuring reliable and efficient operation of massive multiple-input
multiple-output (mMIMO) systems by providing timely downlink (DL) CSI. While
deep learning-based methods have advanced beyond conventional model-driven and
statistical approaches, they remain limited in robustness to practical
non-Gaussian noise, generalization across diverse channel conditions, and
computational efficiency. This paper introduces CSI-4CAST, a hybrid deep
learning architecture that integrates 4 key components, i.e., Convolutional
neural network residuals, Adaptive correction layers, ShuffleNet blocks, and
Transformers, to efficiently capture both local and long-range dependencies in
CSI prediction. To enable rigorous evaluation, this work further presents a
comprehensive benchmark, CSI-RRG for Regular, Robustness and Generalization
testing, which includes more than 300,000 samples across 3,060 realistic
scenarios for both TDD and FDD systems. The dataset spans multiple channel
models, a wide range of delay spreads and user velocities, and diverse noise
types and intensity degrees. Experimental results show that CSI-4CAST achieves
superior prediction accuracy with substantially lower computational cost,
outperforming baselines in 88.9% of TDD scenarios and 43.8% of FDD scenario,
the best performance among all evaluated models, while reducing FLOPs by 5x and
3x compared to LLM4CP, the strongest baseline. In addition, evaluation over
CSI-RRG provides valuable insights into how different channel factors affect
the performance and generalization capability of deep learning models. Both the
dataset (https://huggingface.co/CSI-4CAST) and evaluation protocols
(https://github.com/AI4OPT/CSI-4CAST) are publicly released to establish a
standardized benchmark and to encourage further research on robust and
efficient CSI prediction.

</details>


### [377] [Time-Varying Optimization for Streaming Data Via Temporal Weighting](https://arxiv.org/abs/2510.13052)
*Muhammad Faraz Ul Abrar,Nicolò Michelusi,Erik G. Larsson*

Main category: cs.LG

TL;DR: 该论文将时间变化的优化问题应用于流式数据学习，并针对均匀加权和折扣加权两种策略，利用梯度下降法推导了跟踪误差的界限。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中决策制定的时间变化优化问题，特别是通过流式数据学习。

Method: 提出一种基于权重的优化方法，在每个时间步最小化所有过去数据样本的加权平均损失。推导了在梯度下降更新下，均匀加权和折扣加权策略下的跟踪误差界限。

Result: 证明了在均匀加权下，跟踪误差会渐近消失，衰减率为 O(1/t)；而在折扣加权下，存在一个由折扣因子和每次梯度更新的数量决定的非零误差。

Conclusion: 理论分析通过数值模拟得到验证。

Abstract: Classical optimization theory deals with fixed, time-invariant objective
functions. However, time-varying optimization has emerged as an important
subject for decision-making in dynamic environments. In this work, we study the
problem of learning from streaming data through a time-varying optimization
lens. Unlike prior works that focus on generic formulations, we introduce a
structured, \emph{weight-based} formulation that explicitly captures the
streaming-data origin of the time-varying objective, where at each time step,
an agent aims to minimize a weighted average loss over all the past data
samples. We focus on two specific weighting strategies: (1) uniform weights,
which treat all samples equally, and (2) discounted weights, which
geometrically decay the influence of older data. For both schemes, we derive
tight bounds on the ``tracking error'' (TE), defined as the deviation between
the model parameter and the time-varying optimum at a given time step, under
gradient descent (GD) updates. We show that under uniform weighting, the TE
vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas
discounted weighting incurs a nonzero error floor controlled by the discount
factor and the number of gradient updates performed at each time step. Our
theoretical findings are validated through numerical simulations.

</details>


### [378] [Max It or Miss It: Benchmarking LLM On Solving Extremal Problems](https://arxiv.org/abs/2510.12997)
*Binxin Gao,Jingjun Han*

Main category: cs.LG

TL;DR: LLMs在数学推理方面表现出色，但其优化推理能力（寻找约束条件下的极值）仍需深入研究。新基准ExtremBench包含93个数学极值问题，评估了Qwen3、GPT-OSS和DeepSeek等模型。结果显示，LLMs的极值求解能力与现有数学基准（如AIME25和MATH-500）不完全一致，表明现有基准可能无法全面评估LLMs的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在数学推理方面展现出强大能力，但对其优化推理（寻找约束条件下的极值）的机制和表现了解不足。优化推理是规划、控制和资源分配等关键应用的基础。因此，需要一个专门的基准来系统评估LLMs的优化推理能力。

Method: 引入ExtremBench基准，该基准包含93个从中国数学奥林匹克竞赛的不等式练习改编而来的标准化极值问题。在Qwen3、GPT-OSS和DeepSeek等多个模型家族上进行了广泛评估。

Result: LLMs的极值求解能力与AIME25和MATH-500等现有数学基准的表现不完全一致。部分模型在一般数学推理方面表现强劲，但在极值求解方面表现不佳，反之亦然。

Conclusion: LLMs的极值求解能力与现有数学基准之间存在显著差距，这表明当前的评估方法可能无法全面衡量LLMs的数学推理能力，尤其是在优化推理这一重要领域。

Abstract: Test-time scaling has enabled Large Language Models (LLMs) with remarkable
reasoning capabilities, particularly in mathematical domains, through
intermediate chain-of-thought (CoT) reasoning before generating final answers.
However, the specific sources and mechanisms underlying these reasoning
capabilities remain insufficiently understood. Optimization reasoning, i.e.
finding extrema under constraints, represents a fundamental abstraction that
underpins critical applications in planning, control, resource allocation, and
prompt search. To systematically evaluate this capability, we introduce
ExtremBench, a benchmark dataset for solving mathematical extremal problems,
curated from inequality exercises used for Chinese Mathematical Olympiad and
transformed into $93$ standardized extrema-finding problems. We conduct
extensive evaluations across various state-of-the-art open-source model
families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that
LLMs' extremal-solving reasoning capabilities do not always align with those of
current mathematical benchmarks such as AIME25 and MATH-500, with some models
showing strong general mathematical reasoning but poor extremal-solving skills,
and vice versa. This discrepancy highlights a critical gap in current
evaluation practices and suggests that existing benchmarks may not
comprehensively capture the full spectrum of mathematical reasoning abilities.

</details>


### [379] [Transformer-based Scalable Beamforming Optimization via Deep Residual Learning](https://arxiv.org/abs/2510.13077)
*Yubo Zhang,Xiao-Yang Liu,Xiaodong Wang*

Main category: cs.LG

TL;DR: 开发了一个无监督深度学习框架，用于大规模 MU-MISO 下行波束成形。


<details>
  <summary>Details</summary>
Motivation: 在动态通信环境中，需要一种能够进行实时推理的无监督深度学习框架用于下行波束成形。

Method: 采用学习优化（L2O）范式，利用多层 Transformer 结合残差连接迭代地优化信道和波束成形特征。通过课程学习（CL）、半分摊学习和滑动窗口训练来增强训练过程。

Result: 所提出的方案在低信噪比到中等信噪比下优于现有基线，在高峰值信噪比下接近 WMMSE 性能，并且推理速度远快于迭代和在线学习方法。

Conclusion: 所提出的无监督深度学习框架能够有效地用于大规模 MU-MISO 下行波束成形，并在性能和效率方面具有优势。

Abstract: We develop an unsupervised deep learning framework for downlink beamforming
in large-scale MU-MISO channels. The model is trained offline, allowing
real-time inference through lightweight feedforward computations in dynamic
communication environments. Following the learning-to-optimize (L2O) paradigm,
a multi-layer Transformer iteratively refines both channel and beamformer
features via residual connections. To enhance training, three strategies are
introduced: (i) curriculum learning (CL) to improve early-stage convergence and
avoid local optima, (ii) semi-amortized learning to refine each Transformer
block with a few gradient ascent steps, and (iii) sliding-window training to
stabilize optimization by training only a subset of Transformer blocks at a
time. Extensive simulations show that the proposed scheme outperforms existing
baselines at low-to-medium SNRs and closely approaches WMMSE performance at
high SNRs, while achieving substantially faster inference than iterative and
online learning approaches.

</details>


### [380] [AMORE: Adaptive Multi-Output Operator Network for Stiff Chemical Kinetics](https://arxiv.org/abs/2510.12999)
*Kamaljyoti Nath,Additi Pandey,Bryan T. Susi,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: AMORE是一个多输出算子网络框架，通过自适应损失函数处理反应传输系统中的刚度问题，并使用可逆映射强制执行质量守恒约束，可用于加速CFD模拟。


<details>
  <summary>Details</summary>
Motivation: 反应传输系统中的刚度问题导致计算成本高昂，需要更有效的策略来解决。

Method: 开发AMORE框架，包括多输出算子和自适应损失函数，并使用可逆映射强制执行质量守恒约束。

Result: AMORE框架在合成气和GRI-Mech 3.0算例中表现出有效性，并可扩展至FNO。

Conclusion: AMORE框架为加速CFD模拟提供了基础，尤其是在湍流燃烧模拟方面。

Abstract: Time integration of stiff systems is a primary source of computational cost
in combustion, hypersonics, and other reactive transport systems. This
stiffness can introduce time scales significantly smaller than those associated
with other physical processes, requiring extremely small time steps in explicit
schemes or computationally intensive implicit methods. Consequently, strategies
to alleviate challenges posed by stiffness are important. While neural
operators (DeepONets) can act as surrogates for stiff kinetics, a reliable
operator learning strategy is required to appropriately account for differences
in the error between output variables and samples. Here, we develop AMORE,
Adaptive Multi-Output Operator Network, a framework comprising an operator
capable of predicting multiple outputs and adaptive loss functions ensuring
reliable operator learning. The operator predicts all thermochemical states
from given initial conditions. We propose two adaptive loss functions within
the framework, considering each state variable's and sample's error to penalize
the loss function. We designed the trunk to automatically satisfy Partition of
Unity. To enforce unity mass-fraction constraint exactly, we propose an
invertible analytical map that transforms the $n$-dimensional species
mass-fraction vector into an ($n-1$)-dimensional space, where DeepONet training
is performed. We consider two-step training for DeepONet for multiple outputs
and extend adaptive loss functions for trunk and branch training. We
demonstrate the efficacy and applicability of our models through two examples:
the syngas (12 states) and GRI-Mech 3.0 (24 active states out of 54). The
proposed DeepONet will be a backbone for future CFD studies to accelerate
turbulent combustion simulations. AMORE is a general framework, and here, in
addition to DeepONet, we also demonstrate it for FNO.

</details>


### [381] [Escaping Local Optima in the Waddington Landscape: A Multi-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis](https://arxiv.org/abs/2510.13018)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 该研究提出了一种新的基于多阶段强化学习的算法，用于解决单细胞生物学中细胞响应建模的挑战，通过自然梯度更新和PPO优化，提高了模型在scRNA-seq和scATAC-seq数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动模型在模拟细胞对遗传和化学扰动的反应时，容易陷入局部最优，导致模拟结果不准确。需要一种完全数据驱动且具有良好初始化的方法来克服这个问题。

Method: 研究提出了一种多阶段强化学习算法。第一阶段使用Fisher-向量积和共轭梯度求解器计算自然梯度更新，并通过KL信任区域约束进行缩放，以提供安全、具有曲率感知的初始步。第二阶段利用裁剪替代项的近端策略优化（PPO）进行策略优化，以提高效率。

Result: 该方法在scRNA-seq和scATAC-seq扰动分析上显著提高了模型的泛化能力。

Conclusion: 该研究提出的多阶段强化学习算法能够有效地解决现有模型在单细胞扰动建模中的局部最优问题，并提高了模型的泛化性能。

Abstract: Modeling cellular responses to genetic and chemical perturbations remains a
central challenge in single-cell biology. Existing data-driven framework have
advanced perturbation prediction through variational autoencoders, chemically
conditioned autoencoders, and large-scale transformer pretraining. However,
these models are prone to local optima in the nonconvex Waddington landscape of
cell fate decisions, where poor initialization can trap trajectories in
spurious lineages or implausible differentiation outcomes. While executable
gene regulatory networks complement these approaches, automated design
frameworks incorporate biological priors through multi-agent optimization. Yet,
an approach that is completely data-driven with well-designed initialization to
escape local optima and converge to a proper lineage remains elusive. In this
work, we introduce a multistage reinforcement learning algorithm tailored for
single-cell perturbation modeling. We first compute an explicit natural
gradient update using Fisher-vector products and a conjugate gradient solver,
scaled by a KL trust-region constraint to provide a safe, curvature-aware the
first step for the policy. Starting with these preconditioned parameters, we
then apply a second phase of proximal policy optimization (PPO) with clipped
surrogates, exploiting minibatch efficiency to refine the policy. We
demonstrate that this initialization substantially improves generalization on
Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing
(scATAC-seq) pertubation analysis.

</details>


### [382] [Machine Learning-Based Ultrasonic Weld Characterization Using Hierarchical Wave Modeling and Diffusion-Driven Distribution Alignment](https://arxiv.org/abs/2510.13023)
*Joshua R. Tempelman,Adam J. Wachtor,Eric B. Flynn*

Main category: cs.LG

TL;DR: 提出一种端到端的机器学习工作流，用于在工业环境下对超声波焊接进行自动检测，解决了数据稀疏和信号损坏的挑战。


<details>
  <summary>Details</summary>
Motivation: 工业环境下的超声波焊接自动检测面临数据稀疏和环境易变导致信号损坏的挑战，使得端到端的机器学习方法难以实现。

Method: 提出一种包含降阶模型、扩散模型分布对齐和 U-Net 分割反演的工作流。使用基于 Lamb 波理论的降阶 Helmholtz 模型生成包含焊缝异质性和裂纹缺陷的数据集，并通过迁移学习和有限的 3D đàn hồi 模拟进行优化。使用引导扩散模型处理真实世界中具有不同噪声分布的实验数据，生成符合模型分布的表示，然后由反演模型处理。

Result: 该集成框架能够处理真实数据，为自动化焊接检测提供了端到端的解决方案。

Conclusion: 所提出的工作流成功克服了数据稀疏和信号损坏的挑战，实现了工业环境下超声波焊接的自动化检测。

Abstract: Automated ultrasonic weld inspection remains a significant challenge in the
nondestructive evaluation (NDE) community to factors such as limited training
data (due to the complexity of curating experimental specimens or high-fidelity
simulations) and environmental volatility of many industrial settings
(resulting in the corruption of on-the-fly measurements). Thus, an end-to-end
machine learning (ML) workflow for acoustic weld inspection in realistic (i.e.,
industrial) settings has remained an elusive goal. This work addresses the
challenges of data curation and signal corruption by proposing workflow
consisting of a reduced-order modeling scheme, diffusion based distribution
alignment, and U-Net-based segmentation and inversion. A reduced-order
Helmholtz model based on Lamb wave theory is used to generate a comprehensive
dataset over varying weld heterogeneity and crack defects. The relatively
inexpensive low-order solutions provide a robust training dateset for inversion
models which are refined through a transfer learning stage using a limited set
of full 3D elastodynamic simulations. To handle out-of-distribution (OOD)
real-world measurements with varying and unpredictable noise distributions,
i.e., Laser Doppler Vibrometry scans, guided diffusion produces in-distribution
representations of OOD experimental LDV scans which are subsequently processed
by the inversion models. This integrated framework provides an end-to-end
solution for automated weld inspection on real data.

</details>


### [383] [Information Shapes Koopman Representation](https://arxiv.org/abs/2510.13025)
*Xiaoyuan Cheng,Wenxuan Yuan,Yiming Yang,Yuanzhao Zhang,Sibo Cheng,Yi He,Zhuo Sun*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论的 Koopman 学习方法，通过平衡表示的简洁性和表达力来解决有限维子空间识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的 Koopman 学习方法在识别有限维子空间时存在挑战，尤其是在深度学习模型中，这主要是由于表示学习不佳，导致潜在变量无法在表达力和简洁性之间取得平衡。

Method: 提出了一种信息论的拉格朗日函数形式，明确地平衡了简洁性和表达力之间的权衡。基于该拉格朗日函数形式，提出了一种新的算法，鼓励表示的简洁性和表达力，从而得到稳定且可解释的 Koopman 表示。

Result: 所提出的方法在定量评估中表现出比现有方法更优越的性能，并且学习到的流形在可视化后与理论预测一致。算法能够鼓励简洁性和表达力，从而实现稳定的 Koopman 表示。

Conclusion: 通过信息论的视角重新审视 Koopman 学习，可以有效地解决表示学习中的挑战。提出的方法通过平衡简洁性和表达力，实现了稳定且可解释的 Koopman 表示，并在多种动力学系统中验证了其有效性。

Abstract: The Koopman operator provides a powerful framework for modeling dynamical
systems and has attracted growing interest from the machine learning community.
However, its infinite-dimensional nature makes identifying suitable
finite-dimensional subspaces challenging, especially for deep architectures. We
argue that these difficulties come from suboptimal representation learning,
where latent variables fail to balance expressivity and simplicity. This
tension is closely related to the information bottleneck (IB) dilemma:
constructing compressed representations that are both compact and predictive.
Rethinking Koopman learning through this lens, we demonstrate that latent
mutual information promotes simplicity, yet an overemphasis on simplicity may
cause latent space to collapse onto a few dominant modes. In contrast,
expressiveness is sustained by the von Neumann entropy, which prevents such
collapse and encourages mode diversity. This insight leads us to propose an
information-theoretic Lagrangian formulation that explicitly balances this
tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian
formulation that encourages both simplicity and expressiveness, leading to a
stable and interpretable Koopman representation. Beyond quantitative
evaluations, we further visualize the learned manifolds under our
representations, observing empirical results consistent with our theoretical
predictions. Finally, we validate our approach across a diverse range of
dynamical systems, demonstrating improved performance over existing Koopman
learning methods. The implementation is publicly available at
https://github.com/Wenxuan52/InformationKoopman.

</details>


### [384] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 结合高分辨率模型和理想化模型的优势，开发了一种可解释的AI框架，用于地球系统模型，以提高模拟精度和提供物理洞察。


<details>
  <summary>Details</summary>
Motivation: 高分辨率运行模型在模拟极端事件和统计分布方面存在持续的偏差，而理想化模型可以精确校准以模拟特定的动力学和统计特征，但不同模型之间存在隔离。

Method: 开发了一个可解释的AI框架，利用重新配置的潜数据同化技术，连接不同复杂度的模型，以结合高分辨率模型和理想化模型的优势。

Result: 该模型继承了运行模型的高分辨率和全面变量，并通过理想化模型的针对性改进提高了整体准确性。AI机制提供了改进的依据，使计算高效的框架能够实现有效的物理辅助数字孪生和不确定性量化。

Conclusion: 该框架通过改进CMIP6中El Niño时空模式的模拟偏差，证明了其有效性。该工作还强调了推进理想化模型开发和促进建模社区之间沟通的重要性。

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [385] [Randomness and Interpolation Improve Gradient Descent](https://arxiv.org/abs/2510.13040)
*Jiawen Li,Pascal Lefevre,Anwar Pp Abdul Majeed*

Main category: cs.LG

TL;DR: 该论文提出了两种基于SGD的优化器：IAGD和NRSGD。IAGD利用二阶牛顿插值加速收敛，NRSGD通过引入噪声正则化避免过拟合。实验在CIFAR-10和CIFAR-100数据集上进行，结果表明这两种方法是SGD的有效改进。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是改进随机梯度下降（SGD）优化器，以提高训练效率和模型泛化能力。

Method: 研究提出了两种新的优化器：Interpolational Accelerating Gradient Descent (IAGD) 和 Noise-Regularized Stochastic Gradient Descent (NRSGD)。IAGD 利用二阶牛顿插值假设梯度在迭代之间具有相关性，从而加速收敛。NRSGD 引入受控噪声到梯度中，以避免过拟合。

Result: 在CIFAR-10和CIFAR-100数据集上对CNN进行的比较实验表明，IAGD和NRSGD在性能上优于Keras包中的经典优化器。

Conclusion: IAGD和NRSGD是SGD的两种可行改进方法，证明了其有效性。

Abstract: Based on Stochastic Gradient Descent (SGD), the paper introduces two
optimizers, named Interpolational Accelerating Gradient Descent (IAGD) as well
as Noise-Regularized Stochastic Gradient Descent (NRSGD). IAGD leverages
second-order Newton Interpolation to expedite the convergence process during
training, assuming relevancy in gradients between iterations. To avoid
over-fitting, NRSGD incorporates a noise regularization technique that
introduces controlled noise to the gradients during the optimization process.
Comparative experiments of this research are conducted on the CIFAR-10, and
CIFAR-100 datasets, benchmarking different CNNs(Convolutional Neural Networks)
with IAGD and NRSGD against classical optimizers in Keras Package. Results
demonstrate the potential of those two viable improvement methods in SGD,
implicating the effectiveness of the advancements.

</details>


### [386] [An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting](https://arxiv.org/abs/2510.13050)
*Shreya Agrawal,Mohammed Alewi Hassen,Emmanuel Asiedu Brempong,Boris Babenko,Fred Zyda,Olivia Graham,Di Li,Samier Merchant,Santiago Hincapie Potes,Tyler Russell,Danny Cheresnick,Aditya Prakash Kakkirala,Stephan Rasp,Avinatan Hassidim,Yossi Matias,Nal Kalchbrenner,Pramod Gupta,Jason Hickey,Aaron Bell*

Main category: cs.LG

TL;DR: Global MetNet是一个创新的全球机器学习降水临近预报模型，解决了传统方法和现有机器学习方法在热带地区和全球南方的局限性，提供高分辨率、低延迟的预报，显著优于现有标准，并已成功部署。


<details>
  <summary>Details</summary>
Motivation: 全球南部地区面临着由强风暴引起的气象灾害，而传统的数值天气预报（NWP）方法和现有的机器学习方法（主要在北半球开发）由于数据稀疏和雷达覆盖不足，在该地区预报能力有限，无法提供及时有效的灾害预警。本研究旨在弥合这一差距，为全球南部地区提供高质量、低延迟的降水临近预报。

Method: 本研究提出并实现了一个名为Global MetNet的操作性全球机器学习临近预报模型。该模型整合了全球降水探测任务（GPM）的CORRA数据集、地球同步卫星数据以及全球NWP数据。通过结合这些数据源，Global MetNet能够在约0.05度的空间分辨率（约5公里）和15分钟的时间分辨率下，预测未来12小时的降水情况。模型在几分钟内就能生成预报，确保了实时应用的可用性。

Result: Global MetNet在多个关键指标上显著优于行业标准的逐小时预报，并在更广泛的全球区域内提供了有用的预报。尤其是在数据稀疏的地区，其预报能力甚至超过了美国最高分辨率的NWP模型。通过地面雷达和卫星数据验证，该模型在临近时间（lead times）和各种降水量级别上，其关键成功指数（CSI）和分数技能得分（FSS）等核心指标均有显著提升。此外，模型能够在不到一分钟的时间内生成预报。

Conclusion: Global MetNet通过利用多样化的全球数据集和先进的机器学习技术，成功克服了传统和现有临近预报方法在数据稀疏地区（尤其是在全球南部）的局限性。该模型提供了高分辨率、低延迟的全球降水临近预报，其性能在关键指标上优于现有标准，并已在实际应用中（如Google搜索）部署，服务于数百万用户。这项工作是减少全球天气预报质量差异、有效整合稀疏高分辨率卫星观测数据以改进天气预报的关键一步。

Abstract: Precipitation nowcasting, which predicts rainfall up to a few hours ahead, is
a critical tool for vulnerable communities in the Global South frequently
exposed to intense, rapidly developing storms. Timely forecasts provide a
crucial window to protect lives and livelihoods. Traditional numerical weather
prediction (NWP) methods suffer from high latency, low spatial and temporal
resolution, and significant gaps in accuracy across the world. Recent machine
learning-based nowcasting methods, common in the Global North, cannot be
extended to the Global South due to extremely sparse radar coverage. We present
Global MetNet, an operational global machine learning nowcasting model. It
leverages the Global Precipitation Mission's CORRA dataset, geostationary
satellite data, and global NWP data to predict precipitation for the next 12
hours. The model operates at a high resolution of approximately 0.05{\deg}
(~5km) spatially and 15 minutes temporally. Global MetNet significantly
outperforms industry-standard hourly forecasts and achieves significantly
higher skill, making forecasts useful over a much larger area of the world than
previously available. Our model demonstrates better skill in data-sparse
regions than even the best high-resolution NWP models achieve in the US.
Validated using ground radar and satellite data, it shows significant
improvements across key metrics like the critical success index and fractions
skill score for all precipitation rates and lead times. Crucially, our model
generates forecasts in under a minute, making it readily deployable for
real-time applications. It is already deployed for millions of users on Google
Search. This work represents a key step in reducing global disparities in
forecast quality and integrating sparse, high-resolution satellite observations
into weather forecasting.

</details>


### [387] [Absolute indices for determining compactness, separability and number of clusters](https://arxiv.org/abs/2510.13065)
*Adil M. Bagirov,Ramiz M. Aliguliyev,Nargiz Sultanova,Sona Taheri*

Main category: cs.LG

TL;DR: 该论文提出了一种新的绝对聚类指数，用于确定聚类的紧密度和分离度，并以此来识别真实数据的聚类数量。


<details>
  <summary>Details</summary>
Motivation: 现有的聚类有效性指数通常是相对的，并且依赖于底层数据结构，这使得它们在识别紧密度和分离度俱佳的聚类时存在局限性。

Method: 提出了一种新的绝对聚类指数，包括定义每个聚类的紧密度函数和聚类对的邻近点集。利用这些函数来确定聚类的紧密度、整体聚类分布以及簇间和整体分布的边界。

Result: 在多种合成和真实世界的数据集上，证明了新指数的有效性，并将其与其他常用聚类有效性指数进行了比较。

Conclusion: 提出的新绝对聚类指数能够有效地确定聚类的紧密度和分离度，并能准确识别真实数据的聚类数量。

Abstract: Finding "true" clusters in a data set is a challenging problem. Clustering
solutions obtained using different models and algorithms do not necessarily
provide compact and well-separated clusters or the optimal number of clusters.
Cluster validity indices are commonly applied to identify such clusters.
Nevertheless, these indices are typically relative, and they are used to
compare clustering algorithms or choose the parameters of a clustering
algorithm. Moreover, the success of these indices depends on the underlying
data structure. This paper introduces novel absolute cluster indices to
determine both the compactness and separability of clusters. We define a
compactness function for each cluster and a set of neighboring points for
cluster pairs. This function is utilized to determine the compactness of each
cluster and the whole cluster distribution. The set of neighboring points is
used to define the margin between clusters and the overall distribution margin.
The proposed compactness and separability indices are applied to identify the
true number of clusters. Using a number of synthetic and real-world data sets,
we demonstrate the performance of these new indices and compare them with other
widely-used cluster validity indices.

</details>


### [388] [NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models](https://arxiv.org/abs/2510.13068)
*Konstantinos Barmpas,Na Lee,Alexandros Koliousis,Yannis Panagakis,Dimitrios A. Adamos,Nikolaos Laskaris,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: NeuroRVQ是一个基于码本的标记器，可以实现高效的EEG压缩和高保真信号重建，并在各种下游任务中优于现有的LBM。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG标记器无法保留高频动力学，限制了它们高保真重建EEG信号的能力。

Method: NeuroRVQ采用多尺度特征提取模块、分层残差矢量量化（RVQ）码本和EEG信号相位和幅度感知损失函数来实现高效的EEG压缩和高保真重建。

Result: NeuroRVQ在重建误差方面优于现有LBM，并在各种下游任务中表现更好。

Conclusion: NeuroRVQ标记器为基于码本的通用脑波模型建立了强大的先验，推动了神经解码、生成建模和多模态生物信号集成的发展。

Abstract: Electroencephalography (EEG) captures neural activity across multiple
temporal and spectral scales, yielding signals that are rich but complex for
representation learning. Recently, EEG foundation models trained to predict
masked signal-tokens have shown promise for learning generalizable
representations. However, their performance is hindered by their signal
tokenization modules. Existing neural tokenizers fail to preserve
high-frequency dynamics, limiting their ability to reconstruct EEG signals with
high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM)
centered on a codebook-based tokenizer. Our tokenizer integrates: (i)
multi-scale feature extraction modules that capture the full frequency neural
spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for
high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware
loss function for efficient training. This design enables efficient EEG
compression while supporting accurate reconstruction across all frequency
bands, leading to robust generative masked modeling. Our empirical results
demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms
existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ
tokenizer establishes a strong prior for codebook-based general-purpose
brainwave models, enabling advances in neural decoding, generative modeling and
multimodal biosignal integration.

</details>


### [389] [DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference](https://arxiv.org/abs/2510.13087)
*Aditya Puttaparthi Tirumala*

Main category: cs.LG

TL;DR: DeepCausalMMM是一个Python包，它结合了深度学习、因果推断和高级营销科学，以克服传统营销组合模型（MMM）在处理营销渠道间的相互依赖性和复杂时间动态方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统MMM方法在处理营销渠道间的独立性假设、复杂时间动态和非线性饱和效应方面存在不足。

Method: DeepCausalMMM使用GRU自动学习adstock（滞后效应）和lag，并通过有向无环图（DAG）学习营销渠道间的依赖关系和因果结构。它还使用Hill方程模拟饱和效应，并优化预算分配。该包具有数据驱动的设计、多区域建模、稳健的统计方法（如Huber损失和高级正则化）、响应曲线分析和可视化仪表板。

Result: 该方法能够自动学习超参数和变换（如adstock衰减、饱和曲线），支持多区域建模，并提供全面的响应曲线分析和可视化。

Conclusion: DeepCausalMMM通过结合深度学习和因果推断，克服了传统MMM方法的局限性，能够更准确地模拟营销活动的效果，并为预算优化提供支持。

Abstract: Marketing Mix Modeling (MMM) is a statistical technique used to estimate the
impact of marketing activities on business outcomes such as sales, revenue, or
customer visits. Traditional MMM approaches often rely on linear regression or
Bayesian hierarchical models that assume independence between marketing
channels and struggle to capture complex temporal dynamics and non-linear
saturation effects [@Hanssens2005; @Ng2021Bayesian].
  DeepCausalMMM is a Python package that addresses these limitations by
combining deep learning, causal inference, and advanced marketing science. The
package uses Gated Recurrent Units (GRUs) to automatically learn temporal
patterns such as adstock (carryover effects) and lag, while simultaneously
learning statistical dependencies and potential causal structures between
marketing channels through Directed Acyclic Graph (DAG) learning
[@Zheng2018NOTEARS; @Gong2024CausalMMM]. Additionally, it implements Hill
equation-based saturation curves to model diminishing returns and optimize
budget allocation.
  Key innovations include: (1) a data-driven design where hyperparameters and
transformations (e.g., adstock decay, saturation curves) are learned or
estimated from data with sensible defaults, rather than requiring fixed
heuristics or manual specification, (2) multi-region modeling with both shared
and region-specific parameters, (3) robust statistical methods including Huber
loss and advanced regularization, (4) comprehensive response curve analysis for
understanding channel saturation, and (5) an extensive visualization suite with
14+ interactive dashboards for business insights.

</details>


### [390] [Neural Triangular Transport Maps: A New Approach Towards Sampling in Lattice QCD](https://arxiv.org/abs/2510.13112)
*Andrey Bryutkin,Youssef Marzouk*

Main category: cs.LG

TL;DR: 提出一种稀疏三角变换，用于解决晶格场理论采样中的多模态和长程相关性问题，并与现有方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 晶格场理论的采样因多模态和长程相关性而充满挑战，而现有的归一化流方法在内存和模型表达能力方面存在限制。

Method: 提出稀疏三角变换，利用晶格图的条件独立性结构和单调整流神经网络（MRNN），在精确稀疏性和计算可行性之间进行权衡。每个三角变换分量都限制在局部范围，实现逐点并行评估和线性时间复杂度，同时保持表达性和可逆性。研究了节点标记对稀疏性和性能的影响，并与混合蒙特卡洛（HMC）和已有的流方法（RealNVP）进行了比较。

Result: 在二维 $\phi^4$ 模型中，该方法在保持表达能力的同时，实现了计算的高效性，并与现有方法进行了性能比较。

Conclusion: 所提出的稀疏三角变换框架为解决晶格场理论采样问题提供了一种有前景的方法，在计算效率和模型表达能力之间取得了良好的平衡。

Abstract: Lattice field theories are fundamental testbeds for computational physics;
yet, sampling their Boltzmann distributions remains challenging due to
multimodality and long-range correlations. While normalizing flows offer a
promising alternative, their application to large lattices is often constrained
by prohibitive memory requirements and the challenge of maintaining sufficient
model expressivity. We propose sparse triangular transport maps that explicitly
exploit the conditional independence structure of the lattice graph under
periodic boundary conditions using monotone rectified neural networks (MRNN).
We introduce a comprehensive framework for triangular transport maps that
navigates the fundamental trade-off between \emph{exact sparsity} (respecting
marginal conditional independence in the target distribution) and
\emph{approximate sparsity} (computational tractability without fill-ins).
Restricting each triangular map component to a local past enables site-wise
parallel evaluation and linear time complexity in lattice size $N$, while
preserving the expressive, invertible structure. Using $\phi^4$ in two
dimensions as a controlled setting, we analyze how node labelings (orderings)
affect the sparsity and performance of triangular maps. We compare against
Hybrid Monte Carlo (HMC) and established flow approaches (RealNVP).

</details>


### [391] [On the Reasoning Abilities of Masked Diffusion Language Models](https://arxiv.org/abs/2510.13117)
*Anej Svete,Ashish Sabharwal*

Main category: cs.LG

TL;DR: 掩码扩散模型（MDM）在文本生成方面提供了比传统自回归语言模型更优的替代方案。尽管其并行生成效率高，但其计算能力和并行性限制仍未得到充分探索。本文将MDM与链式思考（CoT）和填充循环变换器（PLT）等推理框架联系起来，分析了MDM可解决的推理问题类型及其效率。研究表明，在有限精度对数宽度设置下，MDM与多项式填充PLT等价，并且MDM能够解决所有CoT增强变换器可解决的问题。此外，研究还展示了MDM在某些问题（包括正则语言）上比CoT变换器更具效率，因为其并行生成能力能够实现显著的推理加速。


<details>
  <summary>Details</summary>
Motivation: 文章旨在探索掩码扩散模型（MDM）在文本生成方面的计算能力和并行性限制，并将其与链式思考（CoT）等现有推理框架进行比较，以了解MDM在解决推理问题方面的潜力和效率。

Method: 研究将MDM与链式思考（CoT）和填充循环变换器（PLT）联系起来，在有限精度对数宽度设置下，通过理论分析来证明MDM的推理能力和效率。具体来说，证明了MDM与多项式填充PLT在这一设置下是等价的，并表明MDM可以解决所有CoT增强变换器可解决的问题。

Result: 研究表明，MDM在有限精度对数宽度设置下与多项式填充PLT等价，并且能够解决CoT增强变换器能解决的所有问题。此外，研究还发现MDM在处理某些问题（如正则语言）时比CoT变换器更有效率，因为其并行生成能力可以实现更快的推理速度。

Conclusion: 掩码扩散模型（MDM）在文本生成任务中展现出强大的推理能力和高效率，尤其在正则语言等问题上，其并行生成机制提供了比传统CoT变换器更优的性能。

Abstract: Masked diffusion models (MDMs) for text offer a compelling alternative to
traditional autoregressive language models. Parallel generation makes them
efficient, but their computational capabilities and the limitations inherent to
their parallelism remain largely unexplored. To this end, we characterize what
types of reasoning problems MDMs can provably solve and how efficiently. We do
this by connecting MDMs to the well-understood reasoning frameworks of chain of
thought (CoT) and padded looped transformers (PLTs) in the finite-precision
log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact,
equivalent in this setting, and that MDMs can solve all problems that
CoT-augmented transformers can. Moreover, we showcase classes of problems
(including regular languages) for which MDMs are inherently more efficient than
CoT transformers, where parallel generation allows for substantially faster
reasoning.

</details>


### [392] [Cluster-Based Client Selection for Dependent Multi-Task Federated Learning in Edge Computing](https://arxiv.org/abs/2510.13132)
*Jieping Luo,Qiyue Li,Zhizhang Liu,Hang Qi,Jiaying Yin,Jingjin Wu*

Main category: cs.LG

TL;DR: CoDa-FL是一个联邦学习框架，通过聚类和任务调度来优化移动边缘计算中的客户端选择，以减少学习时间。


<details>
  <summary>Details</summary>
Motivation: 为了在移动边缘计算环境下，特别是在依赖多任务设置中，减少完成各种学习任务所需的总时间。

Method: 提出CoDa-FL框架，采用基于客户数据分布的聚类方法（地球移动距离EMD）和基于有向无环图的任务调度机制来管理任务依赖性。

Result: CoDa-FL在收敛速度、通信和计算成本以及学习准确性方面优于现有基准。

Conclusion: CoDa-FL通过聚类客户端和管理任务依赖性，有效地减少了联邦学习中的总学习时间。

Abstract: We study the client selection problem in Federated Learning (FL) within
mobile edge computing (MEC) environments, particularly under the dependent
multi-task settings, to reduce the total time required to complete various
learning tasks. We propose CoDa-FL, a Cluster-oriented and Dependency-aware
framework designed to reduce the total required time via cluster-based client
selection and dependent task assignment. Our approach considers Earth Mover's
Distance (EMD) for client clustering based on their local data distributions to
lower computational cost and improve communication efficiency. We derive a
direct and explicit relationship between intra-cluster EMD and the number of
training rounds required for convergence, thereby simplifying the otherwise
complex process of obtaining the optimal solution. Additionally, we incorporate
a directed acyclic graph-based task scheduling mechanism to effectively manage
task dependencies. Through numerical experiments, we validate that our proposed
CoDa-FL outperforms existing benchmarks by achieving faster convergence, lower
communication and computational costs, and higher learning accuracy under
heterogeneous MEC settings.

</details>


### [393] [Convergence, design and training of continuous-time dropout as a random batch method](https://arxiv.org/abs/2510.13134)
*Antonio Álvarez-López,Martín Hernández*

Main category: cs.LG

TL;DR: 提出了一种新的随机批次方法来解决连续时间模型中的 dropout 正则化问题，并在理论和实验上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究连续时间模型中的 dropout 正则化问题，并提出一种新的随机批次方法来解决计算成本和理论分析的挑战。

Method: 通过采样神经元批次和时间间隔来构造 dropout 的无偏估计量，并建立了轨迹收敛性和分布层面的稳定性。利用 Pontryagin 的伴随分析来约束最优成本和控制的偏差。

Result: 在单层神经 ODE 模型上进行了分类和流匹配的实验，观察到理论预测的收敛率、正则化效果以及有利的运行时和内存性能。

Conclusion: 所提出的随机批次方法在理论上和实验上都证明了其在连续时间模型中进行 dropout 正则化的有效性，并具有计算效率和良好的性能。

Abstract: We study dropout regularization in continuous-time models through the lens of
random-batch methods -- a family of stochastic sampling schemes originally
devised to reduce the computational cost of interacting particle systems. We
construct an unbiased, well-posed estimator that mimics dropout by sampling
neuron batches over time intervals of length $h$. Trajectory-wise convergence
is established with linear rate in $h$ for the expected uniform error. At the
distribution level, we establish stability for the associated continuity
equation, with total-variation error of order $h^{1/2}$ under mild moment
assumptions. During training with fixed batch sampling across epochs, a
Pontryagin-based adjoint analysis bounds deviations in the optimal cost and
control, as well as in gradient-descent iterates. On the design side, we
compare convergence rates for canonical batch sampling schemes, recover
standard Bernoulli dropout as a special case, and derive a cost--accuracy
trade-off yielding a closed-form optimal $h$. We then specialize to a
single-layer neural ODE and validate the theory on classification and flow
matching, observing the predicted rates, regularization effects, and favorable
runtime and memory profiles.

</details>


### [394] [Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction](https://arxiv.org/abs/2510.13158)
*Haolin Pan,Jinyuan Dong,Hongbin Zhang,Hongyu Lin,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: 该研究提出了一种新的拟动态程序表示框架，通过探测程序IR的优化敏感性来生成程序行为谱，并使用量化和Transformer模型进行编码，在编译器优化任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的程序表示方法（静态和动态）各有局限，静态表示缺乏动态行为洞察，而动态表示则存在实际应用困难。本研究旨在克服这种权衡，提出一种新的方法。

Method: 提出了一种新的拟动态框架，通过使用一系列优化序列探测程序的IR，并量化其静态特征的变化来生成“程序行为谱”。使用产品量化（Product Quantization）将连续的向量离散化为“子词”，然后使用多任务Transformer模型（PQ-BERT）学习这些行为代码的上下文语法。

Result: 在“最佳优化序列预测”和“-Oz收益预测”这两个编译器优化任务上，该方法显著优于最先进的静态基线方法。

Conclusion: 本研究提出的拟动态程序表示方法，通过程序行为谱和PQ-BERT模型，有效解决了现有程序表示方法的局限性，并在实际编译器优化任务中取得了优于现有方法的性能。

Abstract: Learning effective numerical representations, or embeddings, of programs is a
fundamental prerequisite for applying machine learning to automate and enhance
compiler optimization. Prevailing paradigms, however, present a dilemma. Static
representations, derived from source code or intermediate representation (IR),
are efficient and deterministic but offer limited insight into how a program
will behave or evolve under complex code transformations. Conversely, dynamic
representations, which rely on runtime profiling, provide profound insights
into performance bottlenecks but are often impractical for large-scale tasks
due to prohibitive overhead and inherent non-determinism. This paper transcends
this trade-off by proposing a novel quasi-dynamic framework for program
representation. The core insight is to model a program's optimization
sensitivity. We introduce the Program Behavior Spectrum, a new representation
generated by probing a program's IR with a diverse set of optimization
sequences and quantifying the resulting changes in its static features. To
effectively encode this high-dimensional, continuous spectrum, we pioneer a
compositional learning approach. Product Quantization is employed to discretize
the continuous reaction vectors into structured, compositional sub-words.
Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to
learn the deep contextual grammar of these behavioral codes. Comprehensive
experiments on two representative compiler optimization tasks -- Best Pass
Prediction and -Oz Benefit Prediction -- demonstrate that our method
outperforms state-of-the-art static baselines. Our code is publicly available
at https://github.com/Panhaolin2001/PREP/.

</details>


### [395] [Universally Invariant Learning in Equivariant GNNs](https://arxiv.org/abs/2510.13169)
*Jiacheng Cen,Anyi Li,Ning Lin,Tingyang Xu,Yu Rong,Deli Zhao,Zihe Wang,Wenbing Huang*

Main category: cs.LG

TL;DR: 为了实现等变 GNN 的完备性（即等变函数的万能逼近性质），需要有效地捕捉节点之间复杂的多体相互作用。本研究提出了一个理论上可靠的框架，用于构建高效实用的完备等变 GNN。该框架通过一个完整的标量函数（几何图的规范形式）和一个全秩可驱动基集来实现。基于此，我们提出了一种基于 EGNN 和 TFN 的高效算法，该算法仅需几层即可实现优越的完备性和出色的性能，从而在保持强大实际效果的同时显著降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 等变 GNN 在各种应用中取得了巨大成功，但要实现完备性（即等变函数的万能逼近性质），需要有效捕捉节点之间复杂的多体相互作用。现有方法通常通过更深的网络、增加的体阶或增加的可驱动特征度来实现，但计算成本高昂且非多项式时间。因此，有必要开发一种高效实用的完备等变 GNN 构建方法。

Method: 提出一个理论上可靠的框架，用于构建高效实用的完备等变 GNN。该框架包含两个关键组成部分：1）一个完整的标量函数，即几何图的规范形式；2）一个全秩的可驱动基集。基于此，提出一种基于 EGNN 和 TFN 的高效算法。

Result: 提出的模型在实现优越的完备性方面表现出色，并且仅需几层即可获得优异的性能，从而在保持强大实际效果的同时显著降低了计算开销。

Conclusion: 通过结合几何图的规范形式和全秩的可驱动基集，可以构建出高效且具有优越性能的完备等变 GNN，为等变 GNN 的研究和应用提供了新的方向。

Abstract: Equivariant Graph Neural Networks (GNNs) have demonstrated significant
success across various applications. To achieve completeness -- that is, the
universal approximation property over the space of equivariant functions -- the
network must effectively capture the intricate multi-body interactions among
different nodes. Prior methods attain this via deeper architectures, augmented
body orders, or increased degrees of steerable features, often at high
computational cost and without polynomial-time solutions. In this work, we
present a theoretically grounded framework for constructing complete
equivariant GNNs that is both efficient and practical. We prove that a complete
equivariant GNN can be achieved through two key components: 1) a complete
scalar function, referred to as the canonical form of the geometric graph; and
2) a full-rank steerable basis set. Leveraging this finding, we propose an
efficient algorithm for constructing complete equivariant GNNs based on two
common models: EGNN and TFN. Empirical results demonstrate that our model
demonstrates superior completeness and excellent performance with only a few
layers, thereby significantly reducing computational overhead while maintaining
strong practical efficacy.

</details>


### [396] [Information-Theoretic Criteria for Knowledge Distillation in Multimodal Learning](https://arxiv.org/abs/2510.13182)
*Rongrong Xie,Yizhou Xu,Guido Sanguinetti*

Main category: cs.LG

TL;DR: 交叉模态知识蒸馏(KD)的有效性取决于教师和学生表示之间的互信息是否超过学生表示和标签之间的互信息。


<details>
  <summary>Details</summary>
Motivation: 现有的交叉模态知识蒸馏技术在实践中并不总能带来改进，这主要是因为缺乏能够指导实践的理论基础。

Method: 提出交叉模态互补性假设（CCH），并认为当教师和学生表示之间的互信息超过学生表示和标签之间的互信息时，交叉模态知识蒸馏是有效的。在联合高斯模型中对CCH进行理论验证，并在包括图像、文本、视频、音频和癌症相关组学数据在内的各种多模态数据集上进行实证确认。

Result: 在联合高斯模型中对CCH进行了理论验证，并在各种多模态数据集上进行了实证确认。

Conclusion: 该研究为理解交叉模态知识蒸馏建立了一个新颖的理论框架，并基于CCH标准提供了选择最佳教师模态以提高较弱模态性能的实用指南。

Abstract: The rapid increase in multimodal data availability has sparked significant
interest in cross-modal knowledge distillation (KD) techniques, where richer
"teacher" modalities transfer information to weaker "student" modalities during
model training to improve performance. However, despite successes across
various applications, cross-modal KD does not always result in improved
outcomes, primarily due to a limited theoretical understanding that could
inform practice. To address this gap, we introduce the Cross-modal
Complementarity Hypothesis (CCH): we propose that cross-modal KD is effective
when the mutual information between teacher and student representations exceeds
the mutual information between the student representation and the labels. We
theoretically validate the CCH in a joint Gaussian model and further confirm it
empirically across diverse multimodal datasets, including image, text, video,
audio, and cancer-related omics data. Our study establishes a novel theoretical
framework for understanding cross-modal KD and offers practical guidelines
based on the CCH criterion to select optimal teacher modalities for improving
the performance of weaker modalities.

</details>


### [397] [CleverCatch: A Knowledge-Guided Weak Supervision Model for Fraud Detection](https://arxiv.org/abs/2510.13205)
*Amirhossein Mozafari,Kourosh Hashemi,Erfan Shafagh,Soroush Motamedi,Azar Taheri Tayebi,Mohammad A. Tayebi*

Main category: cs.LG

TL;DR: CleverCatch是一个知识引导的弱监督模型，通过整合结构化领域知识和神经架构，在嵌入空间中对齐规则和数据样本，从而提高了医疗欺诈检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗欺诈检测面临标签数据有限、欺诈手段不断演变以及医疗记录维度高等挑战。传统监督方法因标签稀疏而受限，无监督方法又难以捕捉临床上有意义的异常。

Method: CleverCatch集成结构化领域专业知识到神经网络架构中，在共享嵌入空间中对齐规则和数据样本。通过在代表合规和违规的合成数据上联合训练编码器，模型学习软规则嵌入，能够泛化到复杂、真实的医疗数据集。

Result: CleverCatch在大型真实世界数据集上进行了实验，其性能优于四种最先进的异常检测基线方法，AUC平均提高了1.3%，召回率提高了3.4%。消融研究也证实了专家规则的互补作用及其框架的适应性。

Conclusion: 将专家规则嵌入学习过程不仅提高了检测准确性，还增强了透明度，为医疗欺诈检测等高风险领域提供了一种可解释的方法。

Abstract: Healthcare fraud detection remains a critical challenge due to limited
availability of labeled data, constantly evolving fraud tactics, and the high
dimensionality of medical records. Traditional supervised methods are
challenged by extreme label scarcity, while purely unsupervised approaches
often fail to capture clinically meaningful anomalies. In this work, we
introduce CleverCatch, a knowledge-guided weak supervision model designed to
detect fraudulent prescription behaviors with improved accuracy and
interpretability. Our approach integrates structured domain expertise into a
neural architecture that aligns rules and data samples within a shared
embedding space. By training encoders jointly on synthetic data representing
both compliance and violation, CleverCatch learns soft rule embeddings that
generalize to complex, real-world datasets. This hybrid design enables
data-driven learning to be enhanced by domain-informed constraints, bridging
the gap between expert heuristics and machine learning. Experiments on the
large-scale real-world dataset demonstrate that CleverCatch outperforms four
state-of-the-art anomaly detection baselines, yielding average improvements of
1.3\% in AUC and 3.4\% in recall. Our ablation study further highlights the
complementary role of expert rules, confirming the adaptability of the
framework. The results suggest that embedding expert rules into the learning
process not only improves detection accuracy but also increases transparency,
offering an interpretable approach for high-stakes domains such as healthcare
fraud detection.

</details>


### [398] [Performance Evaluation of Ising and QUBO Variable Encodings in Boltzmann Machine Learning](https://arxiv.org/abs/2510.13210)
*Yasushi Hasegawa,Masayuki Ohzeki*

Main category: cs.LG

TL;DR: QUBO和Ising编码在玻尔兹曼机学习中的表现不同，QUBO的条件数较差，导致SGD收敛较慢，而NGD不受影响。Ising编码在SGD下表现更好，QUBO可通过预处理改善。


<details>
  <summary>Details</summary>
Motivation: 比较Ising和QUBO编码在玻尔兹曼机学习中的信息几何和学习动力学

Method: 利用Fisher信息矩阵等于充分统计量的协方差的性质，可视化模型样本的经验矩，并分析编码引起的差异。

Result: QUBO编码引起的一阶和二阶统计量之间更大的交叉项，导致FIM中较小的特征值方向增多，谱熵降低，从而导致SGD收敛较慢。NGD在两种编码下收敛相似。SGD下Ising编码更优，QUBO可通过预处理改善。

Conclusion: 表示法如何塑造玻尔兹曼机的信息几何和有限时间学习动力学，并为变量编码和预处理提供可操作的指南。

Abstract: We compare Ising ({-1,+1}) and QUBO ({0,1}) encodings for Boltzmann machine
learning under a controlled protocol that fixes the model, sampler, and step
size. Exploiting the identity that the Fisher information matrix (FIM) equals
the covariance of sufficient statistics, we visualize empirical moments from
model samples and reveal systematic, representation-dependent differences. QUBO
induces larger cross terms between first- and second-order statistics, creating
more small-eigenvalue directions in the FIM and lowering spectral entropy. This
ill-conditioning explains slower convergence under stochastic gradient descent
(SGD). In contrast, natural gradient descent (NGD)-which rescales updates by
the FIM metric-achieves similar convergence across encodings due to
reparameterization invariance. Practically, for SGD-based training, the Ising
encoding provides more isotropic curvature and faster convergence; for QUBO,
centering/scaling or NGD-style preconditioning mitigates curvature pathologies.
These results clarify how representation shapes information geometry and
finite-time learning dynamics in Boltzmann machines and yield actionable
guidelines for variable encoding and preprocessing.

</details>


### [399] [Towards Understanding Valuable Preference Data for Large Language Model Alignment](https://arxiv.org/abs/2510.13212)
*Zizhuo Zhang,Qizhou Wang,Shanshan Ye,Jianing Zhu,Jiangchao Yao,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: LLM 对齐的质量取决于人类偏好数据，但现有方法很少单独评估数据点的有效性。本文提出了一种新的截断影响函数（TIF）来评估单个数据点的质量，并发现数据质量是模型固有的。为了解决这个问题，本文还提出了两种计算上更简单的候选评分函数（SF），它们是模型依赖的，并且与 TIF 正相关。通过结合这两种 SF 来抵消它们的误差，提出了一种简单有效的数据选择规则，可以在各种对齐基准和 LLM 系列上实现更好的对齐性能，并使用更少的数据。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 对齐研究通常依赖于人类偏好数据，但很少关注单个数据点的质量。本文旨在开发一种方法来评估和选择高质量的偏好数据，以提高 LLM 对齐的效率和效果。

Method: 提出了一种新的截断影响函数（TIF）来评估单个偏好数据点的质量，并发现数据质量是模型固有的。此外，还提出了两种计算上更简单的候选评分函数（SF），它们与 TIF 正相关，并且是模型依赖的。最后，通过结合两种 SF 来抵消它们的误差，提出了一种有效的数据选择规则。

Result: 在各种对齐基准和 LLM 系列上进行的实验表明，本文提出的数据选择规则能够更精确地选择有价值的偏好数据，从而在使用更少数据的情况下实现更好的对齐性能。

Conclusion: 数据质量是模型固有的，并且可以通过提出的 TIF 和 SF 进行有效评估。本文提出的数据选择规则能够提高 LLM 对齐的效率和效果，为未来研究提供了新的方向。

Abstract: Large language model (LLM) alignment is typically achieved through learning
from human preference comparisons, making the quality of preference data
critical to its success. Existing studies often pre-process raw training
datasets to identify valuable preference pairs using external reward models or
off-the-shelf LLMs, achieving improved overall performance but rarely examining
whether individual, selected data point is genuinely beneficial. We assess data
quality through individual influence on validation data using our newly
proposed truncated influence function (TIF), which mitigates the over-scoring
present in traditional measures and reveals that preference data quality is
inherently a property of the model. In other words, a data pair that benefits
one model may harm another. This leaves the need to improve the preference data
selection approaches to be adapting to specific models. To this end, we
introduce two candidate scoring functions (SFs) that are computationally
simpler than TIF and positively correlated with it. They are also model
dependent and can serve as potential indicators of individual data quality for
preference data selection. Furthermore, we observe that these SFs inherently
exhibit errors when compared to TIF. To this end, we combine them to offset
their diverse error sources, resulting in a simple yet effective data selection
rule that enables the models to achieve a more precise selection of valuable
preference data. We conduct experiments across diverse alignment benchmarks and
various LLM families, with results demonstrating that better alignment
performance can be achieved using less data, showing the generality of our
findings and new methods.

</details>


### [400] [A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control](https://arxiv.org/abs/2510.13367)
*Nikita Kachaev,Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovelev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Transformer在模型无关的在线强化学习中表现出色，尤其是在连续控制任务中。本文通过研究输入条件化、 aktor-critic组件共享以及序列数据切片等关键设计问题，提出了稳定的架构和训练策略，在完全和部分可观测的任务以及向量和图像输入设置中均取得了有竞争力的性能，为在在线RL中应用Transformer提供了实际指导。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在离线或基于模型的强化学习（RL）中有效且流行，但由于其对训练设置和模型设计（如策略和价值网络的结构、组件共享或时间信息的处理）的敏感性，在在线无模型RL中的探索不足。

Method: 本文研究了Transformer在在线无模型RL中的应用，重点关注了输入条件化、 aktor-critic组件共享以及序列数据切片等关键设计问题，旨在找到稳定且具有竞争力的架构和训练策略。

Result: 实验结果表明，所提出的稳定架构和训练策略在完全和部分可观测的任务以及向量和图像输入设置中均取得了有竞争力的性能，证明了Transformer在连续控制的在线无模型RL任务中的潜力。

Conclusion: Transformer可以作为在线无模型RL中连续控制任务的有力基线。通过解决关键设计问题，可以实现稳定且具有竞争力的性能，为在在线RL中应用Transformer提供了实用的指导。

Abstract: Despite their effectiveness and popularity in offline or model-based
reinforcement learning (RL), transformers remain underexplored in online
model-free RL due to their sensitivity to training setups and model design
decisions such as how to structure the policy and value networks, share
components, or handle temporal information. In this paper, we show that
transformers can be strong baselines for continuous control in online
model-free RL. We investigate key design questions: how to condition inputs,
share components between actor and critic, and slice sequential data for
training. Our experiments reveal stable architectural and training strategies
enabling competitive performance across fully and partially observable tasks,
and in both vector- and image-based settings. These findings offer practical
guidance for applying transformers in online RL.

</details>


### [401] [Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective](https://arxiv.org/abs/2510.13254)
*Haoyu Zhang,Yuxuan Cheng,Wenqi Fan,Yulong Chen,Yifan Zhang*

Main category: cs.LG

TL;DR: FracNet通过频域分解和对比学习来解决图神经网络的域适应问题，并在实验和理论上都取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络在域适应方面存在不足，因为它们无法区分处理全局和局部模式，导致在多层GNN后可能破坏图的局部细节。这主要是由于未能区分全局和局部模式。此外，域适应中的模糊边界问题也需要解决。

Method: 提出FracNet（频率感知对比图网络），包含两个协同模块：1. 将原始图分解为高频和低频分量，并进行频率感知域适应。2. 整合对比学习框架，以解决域适应中的模糊边界问题。

Result: FracNet在广泛的实验中展示了比最先进方法显著的改进，并且提供了严格的理论证明来证明其优越性。

Conclusion: FracNet通过将域适应问题分解为频域来解决，并利用对比学习来处理模糊边界问题，从而在图神经网络的域适应任务上取得了显著的成功。

Abstract: Graph neural networks (GNNs) have achieved remarkable success in various
domains, yet they often struggle with domain adaptation due to significant
structural distribution shifts and insufficient exploration of transferable
patterns. One of the main reasons behind this is that traditional approaches do
not treat global and local patterns discriminatingly so that some local details
in the graph may be violated after multi-layer GNN. Our key insight is that
domain shifts can be better understood through spectral analysis, where
low-frequency components often encode domain-invariant global patterns, and
high-frequency components capture domain-specific local details. As such, we
propose FracNet (\underline{\textbf{Fr}}equency \underline{\textbf{A}}ware
\underline{\textbf{C}}ontrastive Graph \underline{\textbf{Net}}work) with two
synergic modules to decompose the original graph into high-frequency and
low-frequency components and perform frequency-aware domain adaption. Moreover,
the blurring boundary problem of domain adaptation is improved by integrating
with a contrastive learning framework. Besides the practical implication, we
also provide rigorous theoretical proof to demonstrate the superiority of
FracNet. Extensive experiments further demonstrate significant improvements
over state-of-the-art approaches.

</details>


### [402] [Hypernetworks for Perspectivist Adaptation](https://arxiv.org/abs/2510.13259)
*Daniil Ignatev,Denis Paperno,Massimo Poesio*

Main category: cs.LG

TL;DR: 使用超网络+适配器组合解决视角感知分类的参数效率问题，在检测仇恨言论和毒性方面表现优于专用模型，且参数更少。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分认识到视角感知分类在参数效率方面存在的瓶颈。

Method: 将超网络+适配器组合应用于视角感知分类任务。

Result: 提出的解决方案在仇恨言论和毒性检测方面可以与专用模型相媲美，并且使用的参数要少得多。

Conclusion: 所提出的解决方案具有架构无关性，可以轻松应用于各种基础模型。

Abstract: The task of perspective-aware classification introduces a bottleneck in terms
of parametric efficiency that did not get enough recognition in existing
studies. In this article, we aim to address this issue by applying an existing
architecture, the hypernetwork+adapters combination, to perspectivist
classification. Ultimately, we arrive at a solution that can compete with
specialized models in adopting user perspectives on hate speech and toxicity
detection, while also making use of considerably fewer parameters. Our solution
is architecture-agnostic and can be applied to a wide range of base models out
of the box.

</details>


### [403] [BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity](https://arxiv.org/abs/2510.13266)
*Alejandro Guerra-Manzanares,Omar El-Herraoui,Michail Maniatakos,Farah E. Shamout*

Main category: cs.LG

TL;DR: BlendFL是一个新颖的联邦学习框架，可以解决多模态数据异构性问题，并支持水平和垂直联邦学习的结合，同时具有去中心化推理和自适应聚合机制。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的协作机器学习面临的主要挑战之一是在不共享数据的情况下处理多模态数据异构性。现有的联邦学习框架（如水平和垂直FL）在理想设置下才有效，无法处理客户端之间模态或样本不完全代表的情况。

Method: 提出BlendFL框架，结合水平和垂直联邦学习的原理，允许客户端根据其可用的数据集选择性地受益于其中一种或两种方法。该框架还包括一个去中心化推理机制和一个名为BlendAvg的自适应全局模型聚合策略。

Result: 在真实世界多模态医学数据集和流行的多模态基准数据集上进行的训练和评估显示，BlendFL在多模态和单模态分类任务上均优于最先进的基线方法。此外，BlendFL的收敛速度比传统方法更快。

Conclusion: BlendFL有潜力处理协作学习中多模态数据异构性问题，尤其是在医疗保健和金融等需要数据隐私的现实世界应用中。

Abstract: One of the key challenges of collaborative machine learning, without data
sharing, is multimodal data heterogeneity in real-world settings. While
Federated Learning (FL) enables model training across multiple clients,
existing frameworks, such as horizontal and vertical FL, are only effective in
`ideal' settings that meet specific assumptions. Hence, they struggle to
address scenarios where neither all modalities nor all samples are represented
across the participating clients. To address this gap, we propose BlendFL, a
novel FL framework that seamlessly blends the principles of horizontal and
vertical FL in a synchronized and non-restrictive fashion despite the asymmetry
across clients. Specifically, any client within BlendFL can benefit from either
of the approaches, or both simultaneously, according to its available dataset.
In addition, BlendFL features a decentralized inference mechanism, empowering
clients to run collaboratively trained local models using available local data,
thereby reducing latency and reliance on central servers for inference. We also
introduce BlendAvg, an adaptive global model aggregation strategy that
prioritizes collaborative model updates based on each client's performance. We
trained and evaluated BlendFL and other state-of-the-art baselines on three
classification tasks using a large-scale real-world multimodal medical dataset
and a popular multimodal benchmark. Our results highlight BlendFL's superior
performance for both multimodal and unimodal classification. Ablation studies
demonstrate BlendFL's faster convergence compared to traditional approaches,
accelerating collaborative learning. Overall, in our study we highlight the
potential of BlendFL for handling multimodal data heterogeneity for
collaborative learning in real-world settings where data privacy is crucial,
such as in healthcare and finance.

</details>


### [404] [To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models](https://arxiv.org/abs/2510.13290)
*Anna Hedström,Salim I. Amoukou,Tom Bewley,Saumitra Mishra,Manuela Veloso*

Main category: cs.LG

TL;DR: MERA通过优化干预方向和校准干预强度来选择性地、自适应地引导语言模型，以减少错误，并在无法进行自信纠正时弃权，从而在不降低性能的情况下安全有效地纠正错误。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型（LM）的错误缓解方法依赖于固定的、手动调整的干预强度，这常常导致干预不足或过度。MERA旨在克服这些限制。

Method: MERA通过（i）优化干预方向，和（ii）校准干预的时机和强度来实现。它能够证明性能的提升，或者在无法进行自信纠正时选择弃权。

Result: 实验表明，MERA在各种数据集和LM系列上能够安全有效地纠正错误，且不会降低性能。与现有基线相比，MERA表现更优。此外，MERA可以应用于现有的干预技术之上，以进一步提升其性能。

Conclusion: MERA是一种通用的、高效的机制化激活干预方法，能够选择性地、自适应地引导语言模型以减少错误。

Abstract: We introduce Mechanistic Error Reduction with Abstention (MERA), a principled
framework for steering language models (LMs) to mitigate errors through
selective, adaptive interventions. Unlike existing methods that rely on fixed,
manually tuned steering strengths, often resulting in under or oversteering,
MERA addresses these limitations by (i) optimising the intervention direction,
and (ii) calibrating when, and how much to steer, thereby provably improving
performance or abstaining when no confident correction is possible. Experiments
across diverse datasets, and LM families demonstrate safe, effective,
non-degrading error correction, and that MERA outperforms existing baselines.
Moreover, MERA can be applied on top of existing steering techniques to further
enhance their performance, establishing it as a general-purpose, and efficient
approach to mechanistic activation steering.

</details>


### [405] [Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents](https://arxiv.org/abs/2510.13704)
*Johan Obando-Ceron,Walter Mayor,Samuel Lavoie,Scott Fujimoto,Aaron Courville,Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 使用单复形嵌入可以提高深度强化学习的样本效率和最终性能，同时不影响运行速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模环境并行化在训练中的actor-critic方法仍需大量环境交互的问题，提出使用单复形嵌入来提高表示的泛化性和样本效率。

Method: 提出使用单复形嵌入：一种约束嵌入到单复形结构的轻量级表示层。这种几何归纳偏置产生了稀疏和离散的特征，从而稳定了Critic的引导，并加强了策略梯度。

Result: 将单复形嵌入应用于FastTD3、FastSAC和PPO，在各种连续和离散控制环境中，样本效率和最终性能均得到一致提高，且运行速度没有损失。

Conclusion: 单复形嵌入是一种有效提高深度强化学习样本效率和最终性能的方法。

Abstract: Recent works have proposed accelerating the wall-clock training time of
actor-critic methods via the use of large-scale environment parallelization;
unfortunately, these can sometimes still require large number of environment
interactions to achieve a desired level of performance. Noting that
well-structured representations can improve the generalization and sample
efficiency of deep reinforcement learning (RL) agents, we propose the use of
simplicial embeddings: lightweight representation layers that constrain
embeddings to simplicial structures. This geometric inductive bias results in
sparse and discrete features that stabilize critic bootstrapping and strengthen
policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial
embeddings consistently improve sample efficiency and final performance across
a variety of continuous- and discrete-control environments, without any loss in
runtime speed.

</details>


### [406] [Federated Conditional Conformal Prediction via Generative Models](https://arxiv.org/abs/2510.13297)
*Rui Xu,Sihong Xie*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conformal Prediction (CP) provides distribution-free uncertainty
quantification by constructing prediction sets that guarantee coverage of the
true labels. This reliability makes CP valuable for high-stakes federated
learning scenarios such as multi-center healthcare. However, standard CP
assumes i.i.d. data, which is violated in federated settings where client
distributions differ substantially. Existing federated CP methods address this
by maintaining marginal coverage on each client, but such guarantees often fail
to reflect input-conditional uncertainty. In this work, we propose Federated
Conditional Conformal Prediction (Fed-CCP) via generative models, which aims
for conditional coverage that adapts to local data heterogeneity. Fed-CCP
leverages generative models, such as normalizing flows or diffusion models, to
approximate conditional data distributions without requiring the sharing of raw
data. This enables each client to locally calibrate conformal scores that
reflect its unique uncertainty, while preserving global consistency through
federated aggregation. Experiments on real datasets demonstrate that Fed-CCP
achieves more adaptive prediction sets.

</details>


### [407] [Km-scale dynamical downscaling through conformalized latent diffusion models](https://arxiv.org/abs/2510.13301)
*Alessandro Brusaferri,Andrea Ballarino*

Main category: cs.LG

TL;DR: 生成式扩散模型（DMs）在动态降尺度方面显示出潜力，但存在不确定性估计过度自信的问题。本研究将保形预测框架与DMs结合，通过后处理DMs的样本生成条件分位数估计，并利用保形分位数回归来获得具有有限样本保证的局部自适应预测区间。实验结果表明，该方法在ERA5再分析数据上能够提供具有更好覆盖率和更稳定概率得分的逐点不确定性估计，有望实现更可信的概率降尺度。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式扩散模型（DMs）在动态降尺度方面虽然重建保真度高且采样可扩展性好，但其不确定性估计存在过度自信的缺陷，导致格点级不确定性估计校准不准，影响了其在实际应用中的可靠性。

Method: 将保形预测框架应用于生成式扩散模型，通过后处理DMs的样本来估计条件分位数，并结合保形分位数回归方法，以获得具有有限样本保证且局部自适应的预测区间。

Result: 在ERA5再分析数据（意大利地区，降尺度至2公里网格）上进行的评估结果显示，所提出的方法相比仅使用DMs的方法，在逐点不确定性估计方面具有显著提高的覆盖率和更稳定的概率得分。

Conclusion: 将保形预测与生成式扩散模型相结合，能够为生成更值得信赖的高分辨率气象场概率降尺度提供有效途径。

Abstract: Dynamical downscaling is crucial for deriving high-resolution meteorological
fields from coarse-scale simulations, enabling detailed analysis for critical
applications such as weather forecasting and renewable energy modeling.
Generative Diffusion models (DMs) have recently emerged as powerful data-driven
tools for this task, offering reconstruction fidelity and more scalable
sampling supporting uncertainty quantification. However, DMs lack finite-sample
guarantees against overconfident predictions, resulting in miscalibrated
grid-point-level uncertainty estimates hindering their reliability in
operational contexts. In this work, we tackle this issue by augmenting the
downscaling pipeline with a conformal prediction framework. Specifically, the
DM's samples are post-processed to derive conditional quantile estimates,
incorporated into a conformalized quantile regression procedure targeting
locally adaptive prediction intervals with finite-sample marginal validity. The
proposed approach is evaluated on ERA5 reanalysis data over Italy, downscaled
to a 2-km grid. Results demonstrate grid-point-level uncertainty estimates with
markedly improved coverage and stable probabilistic scores relative to the DM
baseline, highlighting the potential of conformalized generative models for
more trustworthy probabilistic downscaling to high-resolution meteorological
fields.

</details>


### [408] [Isolation-based Spherical Ensemble Representations for Anomaly Detection](https://arxiv.org/abs/2510.13311)
*Yang Cao,Sikun Yang,Hao Tian,Kai He,Lianyong Qi,Ming Liu,Yujiu Yang*

Main category: cs.LG

TL;DR: ISER通过使用超球体半径作为局部密度特征的代理来扩展基于隔离的方法，以解决异常检测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督异常检测方法面临分布假设冲突、计算效率低下和处理不同异常类型困难等根本性挑战。

Method: ISER通过构建超球体半径来编码密度信息的集成表示，并引入新颖的基于相似性的评分方法来测量模式一致性。它通过使用ISER和调整评分函数来增强Isolation Forest的性能，以解决轴向并行偏差和局部异常检测的局限性。

Result: 在22个真实世界数据集上的综合实验表明，ISER的性能优于11种基线方法。

Conclusion: ISER通过使用超球体半径作为局部密度特征的代理，在保持线性时间和常数空间复杂度的同时，解决了异常检测中的挑战。

Abstract: Anomaly detection is a critical task in data mining and management with
applications spanning fraud detection, network security, and log monitoring.
Despite extensive research, existing unsupervised anomaly detection methods
still face fundamental challenges including conflicting distributional
assumptions, computational inefficiency, and difficulty handling different
anomaly types. To address these problems, we propose ISER (Isolation-based
Spherical Ensemble Representations) that extends existing isolation-based
methods by using hypersphere radii as proxies for local density characteristics
while maintaining linear time and constant space complexity. ISER constructs
ensemble representations where hypersphere radii encode density information:
smaller radii indicate dense regions while larger radii correspond to sparse
areas. We introduce a novel similarity-based scoring method that measures
pattern consistency by comparing ensemble representations against a theoretical
anomaly reference pattern. Additionally, we enhance the performance of
Isolation Forest by using ISER and adapting the scoring function to address
axis-parallel bias and local anomaly detection limitations. Comprehensive
experiments on 22 real-world datasets demonstrate ISER's superior performance
over 11 baseline methods.

</details>


### [409] [RockNet: Distributed Learning on Ultra-Low-Power Devices](https://arxiv.org/abs/2510.13320)
*Alexander Gräfe,Fabian Mager,Marco Zimmerling,Sebastian Trimpe*

Main category: cs.LG

TL;DR: RockNet是一种为超低功耗硬件设计的TinyML方法，可在不进行离线预训练的情况下实现时间序列分类的准确性，并利用分布式学习克服通信瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习（ML）在网络物理系统（CPS）中的应用日益广泛，将训练从传统的云端转移到设备端处理（TinyML）引起了人们的兴趣，但超低功耗微控制器有限的计算资源给训练带来了挑战。

Method: RockNet是一种新的TinyML方法，利用CPS的多设备特性，设计了一种分布式学习方法，整合了ML和无线通信，通过专用且高效的无线多跳通信协议克服了通信瓶颈。

Result: 在包含20个超低功耗设备的测试平台上进行硬件实验表明，RockNet能够从头开始学习时间序列分类任务，准确性比最新的微控制器神经网络训练方法高出2倍，并且在扩展到20个设备时，每个设备的内存、延迟和能耗降低高达90%。

Conclusion: RockNet的分布式ML架构实现了超低功耗硬件上的训练，达到了最先进的准确性，并将ML、分布式计算和通信紧密集成。

Abstract: As Machine Learning (ML) becomes integral to Cyber-Physical Systems (CPS),
there is growing interest in shifting training from traditional cloud-based to
on-device processing (TinyML), for example, due to privacy and latency
concerns. However, CPS often comprise ultra-low-power microcontrollers, whose
limited compute resources make training challenging. This paper presents
RockNet, a new TinyML method tailored for ultra-low-power hardware that
achieves state-of-the-art accuracy in timeseries classification, such as fault
or malware detection, without requiring offline pretraining. By leveraging that
CPS consist of multiple devices, we design a distributed learning method that
integrates ML and wireless communication. RockNet leverages all devices for
distributed training of specialized compute efficient classifiers that need
minimal communication overhead for parallelization. Combined with tailored and
efficient wireless multi-hop communication protocols, our approach overcomes
the communication bottleneck that often occurs in distributed learning.
Hardware experiments on a testbed with 20 ultra-low-power devices demonstrate
RockNet's effectiveness. It successfully learns timeseries classification tasks
from scratch, surpassing the accuracy of the latest approach for neural network
microcontroller training by up to 2x. RockNet's distributed ML architecture
reduces memory, latency and energy consumption per device by up to 90 % when
scaling from one central device to 20 devices. Our results show that a tight
integration of distributed ML, distributed computing, and communication
enables, for the first time, training on ultra-low-power hardware with
state-of-the-art accuracy.

</details>


### [410] [When In Doubt, Abstain: The Impact of Abstention on Strategic Classification](https://arxiv.org/abs/2510.13327)
*Lina Alkarmi,Ziyuan Huang,Mingyan Liu*

Main category: cs.LG

TL;DR: 算法决策中引入分类器弃权机制可以提高准确性，并可作为阻止操纵的威慑手段，使总亏损不差于无弃权情况，特别是在操纵成本高昂的情况下。


<details>
  <summary>Details</summary>
Motivation: 研究在战略分类背景下引入分类器弃权机制的影响，探讨其如何影响战略代理人的反应以及委托人应如何最优利用该机制。

Method: 将此交互建模为一个Stackelberg博弈，其中委托人（分类器）首先宣布其决策策略，然后战略代理人（跟随者）操纵其可观测特征以获得期望的输出。重点关注二元分类器，其中代理人操纵可观测特征而非其真实特征。

Result: 即使存在战略代理人，最优弃权也能确保委托人的效用（或损失）不差于无弃权设置。弃权还可以作为操纵的威慑手段，使代理人（特别是那些不太合格的代理人）在操纵成本足以影响代理人行为以获得积极结果的情况下，操纵成本更高。

Conclusion: 弃权是一种有价值的工具，可以减少算法决策系统中战略行为的负面影响。

Abstract: Algorithmic decision making is increasingly prevalent, but often vulnerable
to strategic manipulation by agents seeking a favorable outcome. Prior research
has shown that classifier abstention (allowing a classifier to decline making a
decision due to insufficient confidence) can significantly increase classifier
accuracy. This paper studies abstention within a strategic classification
context, exploring how its introduction impacts strategic agents' responses and
how principals should optimally leverage it. We model this interaction as a
Stackelberg game where a principal, acting as the classifier, first announces
its decision policy, and then strategic agents, acting as followers, manipulate
their features to receive a desired outcome. Here, we focus on binary
classifiers where agents manipulate observable features rather than their true
features, and show that optimal abstention ensures that the principal's utility
(or loss) is no worse than in a non-abstention setting, even in the presence of
strategic agents. We also show that beyond improving accuracy, abstention can
also serve as a deterrent to manipulation, making it costlier for agents,
especially those less qualified, to manipulate to achieve a positive outcome
when manipulation costs are significant enough to affect agent behavior. These
results highlight abstention as a valuable tool for reducing the negative
effects of strategic behavior in algorithmic decision making systems.

</details>


### [411] [Thompson Sampling via Fine-Tuning of LLMs](https://arxiv.org/abs/2510.13328)
*Nicolas Menet,Aleksandar Terzić,Andreas Krause,Abbas Rahimi*

Main category: cs.LG

TL;DR: ToSFiT是一种基于 Thompson 采样的方法，用于解决大型非结构化离散空间中的贝叶斯优化问题，通过直接参数化候选解获得最大奖励的概率来规避计算成本高昂的获取函数最大化问题，并利用大型语言模型的先验知识进行微调以适应后验分布，在三个不同任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型非结构化离散空间中的贝叶斯优化通常受限于获取函数最大化的计算成本，因为缺乏梯度信息。为了解决这个问题，需要一种可扩展的替代方案。

Method: 提出了一种基于 Thompson 采样的方法（ToSFiT），通过直接参数化候选解获得最大奖励的概率来消除对获取函数最大化的需求。该方法利用了预训练语言模型的先验知识，并通过微调来逐步适应后验分布。理论上，推导了 Thompson 采样变分公式的新遗憾界限。经验上，在三个不同的任务上进行了验证。

Result: 在三个多样化的任务（FAQ 回答优化、热稳定性蛋白质搜索和量子电路设计）上验证了该方法。结果表明，在线微调显著提高了样本效率，同时对计算效率的影响很小。

Conclusion: ToSFiT 算法通过利用先验知识和适应后验概率，有效解决了大型非结构化离散空间中的贝叶斯优化问题，提高了样本效率，并且计算效率影响可忽略。

Abstract: Bayesian optimization in large unstructured discrete spaces is often hindered
by the computational cost of maximizing acquisition functions due to the
absence of gradients. We propose a scalable alternative based on Thompson
sampling that eliminates the need for acquisition function maximization by
directly parameterizing the probability that a candidate yields the maximum
reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the
prior knowledge embedded in prompt-conditioned large language models, and
incrementally adapts them toward the posterior. Theoretically, we derive a
novel regret bound for a variational formulation of Thompson Sampling that
matches the strong guarantees of its standard counterpart. Our analysis reveals
the critical role of careful adaptation to the posterior probability of
maximality--a principle that underpins our ToSFiT algorithm. Empirically, we
validate our method on three diverse tasks: FAQ response refinement, thermally
stable protein search, and quantum circuit design. We demonstrate that online
fine-tuning significantly improves sample efficiency, with negligible impact on
computational efficiency.

</details>


### [412] [Kernel Representation and Similarity Measure for Incomplete Data](https://arxiv.org/abs/2510.13352)
*Yang Cao,Sikun Yang,Kai He,Wenjun Ma,Ming Liu,Yujiu Yang,Jian Weng*

Main category: cs.LG

TL;DR: 提出了一种新的相似性度量方法——邻近核，可以直接在核特征空间中计算不完整数据之间的相似性，无需进行显式填补。


<details>
  <summary>Details</summary>
Motivation: 在网络挖掘、推荐系统和用户行为分析等领域，不完整数据相似性度量的计算是一个基本挑战。传统方法存在信息丢失和估计偏差的问题。

Method: 提出了一种邻近核方法，结合了数据相关分箱和邻近分配，将数据投影到高维稀疏表示中，并使用级联回退策略处理缺失值。

Result: 在12个真实世界的不完整数据集上进行了聚类任务，与现有方法相比，在保持线性时间复杂度的同时，展现了优越的性能。

Conclusion: 邻近核方法能够有效地处理不完整数据，并在多种应用场景下取得优于现有方法的性能。

Abstract: Measuring similarity between incomplete data is a fundamental challenge in
web mining, recommendation systems, and user behavior analysis. Traditional
approaches either discard incomplete data or perform imputation as a
preprocessing step, leading to information loss and biased similarity
estimates. This paper presents the proximity kernel, a new similarity measure
that directly computes similarity between incomplete data in kernel feature
space without explicit imputation in the original space. The proposed method
introduces data-dependent binning combined with proximity assignment to project
data into a high-dimensional sparse representation that adapts to local density
variations. For missing value handling, we propose a cascading fallback
strategy to estimate missing feature distributions. We conduct clustering tasks
on the proposed kernel representation across 12 real world incomplete datasets,
demonstrating superior performance compared to existing methods while
maintaining linear time complexity. All the code are available at
https://anonymous.4open.science/r/proximity-kernel-2289.

</details>


### [413] [Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training](https://arxiv.org/abs/2510.13361)
*Yisen Wang,Yichuan Mo,Hongjun Wang,Junyi Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 尽管神经网络取得了快速进展，但它们仍然非常容易受到对抗性样本的攻击，而对抗性训练（AT）是目前最有效的防御方法。尽管AT已被广泛研究，但其实际应用暴露了两个主要限制：与标准训练相比，自然准确性往往会显着下降，并且在不同范数约束下精心设计的攻击之间，鲁棒性不易转移。我们提出的Generalist框架将整体泛化目标划分为多个子任务，每个子任务分配给一个专门的基础学习器。通过专注于其指定的对象，每个基础学习器都迅速成为其领域的专家。在训练的后期阶段，我们对它们的参数进行插值，形成一个知识渊博的全局学习器，同时定期将全局参数重新分配给基础学习器，以防止它们的优化轨迹与共享目标偏离太远。我们称之为Generalist框架，并引入了三种针对不同应用场景的变体。理论分析和大量实验表明，与基线方法相比，Generalist实现了更低的泛化误差，并显着缓解了权衡问题。我们的结果表明，Generalist为未来开发完全鲁棒的分类器提供了一个有前景的步骤。


<details>
  <summary>Details</summary>
Motivation: 尽管对抗性训练（AT）是防御神经网络免受对抗性样本攻击的最有效方法，但其在实际应用中存在自然准确性下降和鲁棒性跨攻击转移不佳的缺点。本研究旨在解决这些问题。

Method: 提出了一种名为Generalist的框架，将泛化目标划分为多个子任务，分配给专门的基础学习器。通过插值基础学习器的参数形成全局学习器，并定期将全局参数重新分配给基础学习器，以防止优化轨迹偏离。提出了三种适用于不同场景的Generalist变体。

Result: 理论分析和大量实验表明，Generalist框架在泛化误差方面优于基线方法，并显著缓解了准确性和鲁棒性之间的权衡问题。

Conclusion: Generalist框架为开发完全鲁棒的分类器提供了一个有前景的方向，它通过将泛化任务分解并利用专门的基础学习器来解决现有对抗性训练方法的局限性。

Abstract: Despite the rapid progress of neural networks, they remain highly vulnerable
to adversarial examples, for which adversarial training (AT) is currently the
most effective defense. While AT has been extensively studied, its practical
applications expose two major limitations: natural accuracy tends to degrade
significantly compared with standard training, and robustness does not transfer
well across attacks crafted under different norm constraints. Unlike prior
works that attempt to address only one issue within a single network, we
propose to partition the overall generalization goal into multiple sub-tasks,
each assigned to a dedicated base learner. By specializing in its designated
objective, each base learner quickly becomes an expert in its field. In the
later stages of training, we interpolate their parameters to form a
knowledgeable global learner, while periodically redistributing the global
parameters back to the base learners to prevent their optimization trajectories
from drifting too far from the shared target. We term this framework Generalist
and introduce three variants tailored to different application scenarios. Both
theoretical analysis and extensive experiments demonstrate that Generalist
achieves lower generalization error and significantly alleviates the trade-off
problems compared with baseline methods. Our results suggest that Generalist
provides a promising step toward developing fully robust classifiers in the
future.

</details>


### [414] [Contrastive Learning-Based Dependency Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2510.13368)
*Yue Xing,Yingnan Deng,Heyao Liu,Ming Wang,Yun Zi,Xiaoxuan Sun*

Main category: cs.LG

TL;DR: 该论文提出了一种结合对比学习的依赖建模和异常检测方法，用于解决云服务环境中复杂的依赖关系和多样的异常模式问题。


<details>
  <summary>Details</summary>
Motivation: 云服务环境中的复杂依赖关系和多样的异常模式给异常检测带来了挑战。

Method: 该方法将服务交互抽象为依赖图，通过嵌入函数提取时空特征，并利用图卷积机制聚合邻域信息以获得上下文感知的服务表示。然后，引入对比学习框架，构建正负样本对以增强正常和异常模式在表示空间中的可分离性。此外，设计了时间一致性约束，以保持表示在时间步长上的稳定性，并减少短期波动和噪声的影响。整体优化结合了对比损失和时间一致性损失，以确保跨多维特征的稳定可靠的检测。

Result: 在公共数据集上的实验表明，该方法在精确率、召回率、F1分数和AUC等关键指标上显著优于现有方法，并在标签稀疏、监控噪声和流量波动等条件下保持鲁棒性。

Conclusion: 该研究验证了依赖建模与对比学习相结合的有效性，为云服务异常检测提供了一套完整的技术解决方案，并证明了其在复杂环境中的强大适应性和稳定性。

Abstract: This paper addresses the challenges of complex dependencies and diverse
anomaly patterns in cloud service environments by proposing a dependency
modeling and anomaly detection method that integrates contrastive learning. The
method abstracts service interactions into a dependency graph, extracts
temporal and structural features through embedding functions, and employs a
graph convolution mechanism to aggregate neighborhood information for
context-aware service representations. A contrastive learning framework is then
introduced, constructing positive and negative sample pairs to enhance the
separability of normal and abnormal patterns in the representation space.
Furthermore, a temporal consistency constraint is designed to maintain
representation stability across time steps and reduce the impact of short-term
fluctuations and noise. The overall optimization combines contrastive loss and
temporal consistency loss to ensure stable and reliable detection across
multi-dimensional features. Experiments on public datasets systematically
evaluate the method from hyperparameter, environmental, and data sensitivity
perspectives. Results show that the proposed approach significantly outperforms
existing methods on key metrics such as Precision, Recall, F1-Score, and AUC,
while maintaining robustness under conditions of sparse labeling, monitoring
noise, and traffic fluctuations. This study verifies the effectiveness of
integrating dependency modeling with contrastive learning, provides a complete
technical solution for cloud service anomaly detection, and demonstrates strong
adaptability and stability in complex environments.

</details>


### [415] [Prediction Markets with Intermittent Contributions](https://arxiv.org/abs/2510.13385)
*Michael Vitali,Pierre Pinson*

Main category: cs.LG

TL;DR: 通过引入一个考虑历史表现、适应时变条件并允许参与者自由进出的预测市场，来克服数据所有权和竞争利益在预测合作中的限制，并提出了一种考虑样本内和样本外表现的支付分配机制。


<details>
  <summary>Details</summary>
Motivation: 数据可用性和准确预测需求不断增长，但数据所有权和竞争利益限制了利益相关者之间的合作。

Method: 提出一个预测市场，该市场（一）考虑参与者的历史表现，（二）适应时变条件，同时（三）允许参与者随时进入和退出市场。该设计采用鲁棒回归模型来学习最优预测组合，同时处理缺失的提交。此外，还提出了一种支付分配机制，该机制同时考虑样本内和样本外表现，并满足若干理想的经济特性。

Result: 通过使用模拟和真实世界数据的案例研究，证明了所提出的市场设计的有效性和适应性。

Conclusion: 所提出的预测市场设计能够有效地解决数据所有权和竞争利益带来的合作挑战，并通过考虑历史表现和灵活的市场参与机制来提高预测的准确性。

Abstract: Although both data availability and the demand for accurate forecasts are
increasing, collaboration between stakeholders is often constrained by data
ownership and competitive interests. In contrast to recent proposals within
cooperative game-theoretical frameworks, we place ourselves in a more general
framework, based on prediction markets. There, independent agents trade
forecasts of uncertain future events in exchange for rewards. We introduce and
analyse a prediction market that (i) accounts for the historical performance of
the agents, (ii) adapts to time-varying conditions, while (iii) permitting
agents to enter and exit the market at will. The proposed design employs robust
regression models to learn the optimal forecasts' combination whilst handling
missing submissions. Moreover, we introduce a pay-off allocation mechanism that
considers both in-sample and out-of-sample performance while satisfying several
desirable economic properties. Case-studies using simulated and real-world data
allow demonstrating the effectiveness and adaptability of the proposed market
design.

</details>


### [416] [Assessing the robustness of heterogeneous treatment effects in survival analysis under informative censoring](https://arxiv.org/abs/2510.13397)
*Yuxin Wang,Dennis Frauen,Jonas Schweisthal,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 当面临删失偏倚时，研究提出了一种假设较少的框架来评估生存分析中条件平均处理效应 (CATE) 估计的稳健性，通过部分识别推导出 CATE 的信息边界，并开发了一个新的元学习器来估计这些边界，该元学习器具有双重稳健性和伪-Oracle 效率等优点。


<details>
  <summary>Details</summary>
Motivation: 临床试验中患者因副作用或其他原因提前退出（失访）很常见，当失访信息（即依赖于生存时间）与生存时间相关时，会引入删失偏倚，导致治疗效果估计产生偏差。

Method: 提出了一种假设较少的框架，使用部分识别来推导 CATE 的信息边界，并开发了一个新的元学习器，该学习器可以使用任意机器学习模型来估计边界，并具有双重稳健性和伪-Oracle 效率等理论特性。

Result: 通过数值实验和癌症药物试验的应用，证明了所提出的元学习器的实用价值。

Conclusion: 该框架为评估估计的治疗效果在删失存在下的稳健性提供了一个实用的工具，从而促进了生存数据在医学和流行病学中用于证据生成的可靠性。

Abstract: Dropout is common in clinical studies, with up to half of patients leaving
early due to side effects or other reasons. When dropout is informative (i.e.,
dependent on survival time), it introduces censoring bias, because of which
treatment effect estimates are also biased. In this paper, we propose an
assumption-lean framework to assess the robustness of conditional average
treatment effect (CATE) estimates in survival analysis when facing censoring
bias. Unlike existing works that rely on strong assumptions, such as
non-informative censoring, to obtain point estimation, we use partial
identification to derive informative bounds on the CATE. Thereby, our framework
helps to identify patient subgroups where treatment is effective despite
informative censoring. We further develop a novel meta-learner that estimates
the bounds using arbitrary machine learning models and with favorable
theoretical properties, including double robustness and quasi-oracle
efficiency. We demonstrate the practical value of our meta-learner through
numerical experiments and in an application to a cancer drug trial. Together,
our framework offers a practical tool for assessing the robustness of estimated
treatment effects in the presence of censoring and thus promotes the reliable
use of survival data for evidence generation in medicine and epidemiology.

</details>


### [417] [SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with {Thermal} IR {(LWIR/MWIR)} and RGB](https://arxiv.org/abs/2510.13404)
*Muhammad Ishfaq Hussain,Ma Van Linh,Zubia Naz,Unse Fatima,Yeongmin Ko,Moongu Jeon*

Main category: cs.LG

TL;DR: SWIR成像技术在恶劣可见性条件下具有潜力，但缺乏数据集。本研究提出一种从LWIR数据合成SWIR图像的方法，并结合RGB和LWIR进行多模态融合，以提高图像质量和实时性，应用于监控和自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 恶劣可见性条件下（如大气干扰、光照不足）的场景理解是监控和自动驾驶的关键挑战。现有的RGB和红外成像融合方法难以提供全面的场景信息，而SWIR成像具有穿透大气干扰和区分材料的优势，但公开数据集稀缺。

Method: 提出一种利用对比度增强技术从LWIR数据合成SWIR（结构/对比度线索）图像的方法。设计了一个多模态融合框架，结合合成SWIR、LWIR和RGB数据，采用优化的编码器-解码器神经网络架构，并引入特定模态的编码器和一个softmax门控融合头。

Result: 在多个公开RGB-LWIR数据集（M3FD, TNO, CAMEL, MSRS, RoadScene）和一个私有RGB-MWIR-SWIR数据集上进行实验，结果表明所提出的合成SWIR增强的融合框架能够提高融合图像的质量（对比度、边缘清晰度、结构保真度），同时保持实时性能。通过与现有基线方法（LP, LatLRR, GFF, U2Fusion/SwinFusion）的公平比较，证明了该方法的优越性。

Conclusion: 合成SWIR增强的多模态融合框架在提高恶劣可见性条件下图像质量方面展现出巨大潜力，并可满足实时性要求，有望在监控和自动驾驶等领域得到广泛应用。

Abstract: Enhancing scene understanding in adverse visibility conditions remains a
critical challenge for surveillance and autonomous navigation systems.
Conventional imaging modalities, such as RGB and thermal infrared (MWIR /
LWIR), when fused, often struggle to deliver comprehensive scene information,
particularly under conditions of atmospheric interference or inadequate
illumination. To address these limitations, Short-Wave Infrared (SWIR) imaging
has emerged as a promising modality due to its ability to penetrate atmospheric
disturbances and differentiate materials with improved clarity. However, the
advancement and widespread implementation of SWIR-based systems face
significant hurdles, primarily due to the scarcity of publicly accessible SWIR
datasets. In response to this challenge, our research introduces an approach to
synthetically generate SWIR-like structural/contrast cues (without claiming
spectral reproduction) images from existing LWIR data using advanced contrast
enhancement techniques. We then propose a multimodal fusion framework
integrating synthetic SWIR, LWIR, and RGB modalities, employing an optimized
encoder-decoder neural network architecture with modality-specific encoders and
a softmax-gated fusion head. Comprehensive experiments on public {RGB-LWIR
benchmarks (M3FD, TNO, CAMEL, MSRS, RoadScene) and an additional private real
RGB-MWIR-SWIR dataset} demonstrate that our synthetic-SWIR-enhanced fusion
framework improves fused-image quality (contrast, edge definition, structural
fidelity) while maintaining real-time performance. We also add fair trimodal
baselines (LP, LatLRR, GFF) and cascaded trimodal variants of
U2Fusion/SwinFusion under a unified protocol. The outcomes highlight
substantial potential for real-world applications in surveillance and
autonomous systems.

</details>


### [418] [Optimizing Storage Overhead of User Behavior Log for ML-embedded Mobile Apps](https://arxiv.org/abs/2510.13405)
*Chen Gong,Yan Zhuang,Zhenzhe Zheng,Yiliu Chen,Sheng Wang,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: AdaLog通过解决冗余日志记录和稀疏存储问题，在不影响模型准确性和延迟的情况下，将移动应用程序中用户行为日志的大小减少了19%至44%。


<details>
  <summary>Details</summary>
Motivation: 现代移动应用越来越多地集成机器学习（ML）模型，但记录用户行为数据会产生高昂的存储成本，导致系统响应缓慢和用户卸载应用。AdaLog旨在解决这一存储瓶颈。

Method: AdaLog通过两个关键创新解决了用户行为日志的低效问题：1. 将消除特征级冗余数据的问题制定为超图中的最大加权匹配问题，并提出了一种用于高效设备端部署的分层算法。2. 采用虚拟哈希属性设计，将异构行为分配到几个物理上密集存储的日志文件中。此外，AdaLog还设计了一种增量更新机制来最小化适应过时行为日志所需的I/O操作。

Result: AdaLog将用户行为日志的大小减少了19%至44%，同时系统开销极小（仅增加2秒延迟和15MB内存使用）。

Conclusion: AdaLog通过提高存储效率，为在设备端机器学习的广泛应用奠定了更有效的数据基础。

Abstract: Machine learning (ML) models are increasingly integrated into modern mobile
apps to enable personalized and intelligent services. These models typically
rely on rich input features derived from historical user behaviors to capture
user intents. However, as ML-driven services become more prevalent, recording
necessary user behavior data imposes substantial storage cost on mobile apps,
leading to lower system responsiveness and more app uninstalls. To address this
storage bottleneck, we present AdaLog, a lightweight and adaptive system
designed to improve the storage efficiency of user behavior log in ML-embedded
mobile apps, without compromising model inference accuracy or latency. We
identify two key inefficiencies in current industrial practices of user
behavior log: (i) redundant logging of overlapping behavior data across
different features and models, and (ii) sparse storage caused by storing
behaviors with heterogeneous attribute descriptions in a single log file. To
solve these issues, AdaLog first formulates the elimination of feature-level
redundant data as a maximum weighted matching problem in hypergraphs, and
proposes a hierarchical algorithm for efficient on-device deployment. Then,
AdaLog employs a virtually hashed attribute design to distribute heterogeneous
behaviors into a few log files with physically dense storage. Finally, to
ensure scalability to dynamic user behavior patterns, AdaLog designs an
incremental update mechanism to minimize the I/O operations needed for adapting
outdated behavior log. We implement a prototype of AdaLog and deploy it into
popular mobile apps in collaboration with our industry partner. Evaluations on
real-world user data show that AdaLog reduces behavior log size by 19% to 44%
with minimal system overhead (only 2 seconds latency and 15 MB memory usage),
providing a more efficient data foundation for broader adoption of on-device
ML.

</details>


### [419] [When Embedding Models Meet: Procrustes Bounds and Applications](https://arxiv.org/abs/2510.13406)
*Lucas Maystre,Alvaro Ortega Gonzalez,Charles Park,Rares Dolga,Tudor Berariu,Yu Zhao,Kamil Ciosek*

Main category: cs.LG

TL;DR: 当两个嵌入模型在相似数据上分别训练时，它们的表示虽然编码了稳定信息，但通常不能直接互换。本文研究了如何通过正交变换对齐两个嵌入集，并提出了一种名为 Procrustes 的后处理方法，以解决模型互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 解决因模型互操作性不足而在模型再训练、部分模型升级和多模态搜索等实际应用中遇到的挑战。

Method: 研究了当成对点积近似保持时，存在一个密切对齐两个嵌入集的等距变换，并提供了对齐误差的紧密界限。基于此，提出了一种简单的对齐方法——Procrustes 后处理。

Result: 提出了一种名为 Procrustes 的后处理方法，可以使两个嵌入模型具有互操作性，同时保持每个嵌入空间的几何结构。在模型再训练兼容性、文本检索模型组合以及多模态搜索等三个应用中，该方法均取得了最先进的性能。

Conclusion: Procrustes 后处理方法能够有效地使不同模型训练出的嵌入集具有互操作性，并在多个应用场景中实现了最先进的性能。

Abstract: Embedding models trained separately on similar data often produce
representations that encode stable information but are not directly
interchangeable. This lack of interoperability raises challenges in several
practical applications, such as model retraining, partial model upgrades, and
multimodal search. Driven by these challenges, we study when two sets of
embeddings can be aligned by an orthogonal transformation. We show that if
pairwise dot products are approximately preserved, then there exists an
isometry that closely aligns the two sets, and we provide a tight bound on the
alignment error. This insight yields a simple alignment recipe, Procrustes
post-processing, that makes two embedding models interoperable while preserving
the geometry of each embedding space. Empirically, we demonstrate its
effectiveness in three applications: maintaining compatibility across
retrainings, combining different models for text retrieval, and improving
mixed-modality search, where it achieves state-of-the-art performance.

</details>


### [420] [Modeling Adoptive Cell Therapy in Bladder Cancer from Sparse Biological Data using PINNs](https://arxiv.org/abs/2510.13431)
*Kayode Olumoyin,Katarzyna Rejniak*

Main category: cs.LG

TL;DR: 本文提出了一种结合物理信息神经网络（PINN）和生物学约束的框架，用于学习肿瘤微环境动力学，即使在数据稀疏的情况下也能取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 肿瘤学中的实验数据通常稀疏，并且只有肿瘤体积的几个时间点。需要一种能够处理稀疏数据并从先验知识中学习动力学的方法。

Method: 提出了一种改进的 PINN 框架，将动力学系统的定律嵌入损失函数中，并结合生物学约束作为正则化项，以学习肿瘤微环境的瞬态相互作用。

Result: 该算法能够学习常微分方程（ODE）模型的动力学，并估计ODE模型参数随时间变化的规律，即使在只有少量训练样本的情况下也能表现出良好的收敛性和泛化能力，MSE、MAE、MAPE等指标显示了其有效性。

Conclusion: 所提出的结合物理信息神经网络和生物学约束的框架，能够有效地学习肿瘤动力学，并能在数据稀疏的情况下处理组合疗法的影响。

Abstract: Physics-informed neural networks (PINNs) are neural networks that embed the
laws of dynamical systems modeled by differential equations into their loss
function as constraints. In this work, we present a PINN framework applied to
oncology. Here, we seek to learn time-varying interactions due to a combination
therapy in a tumor microenvironment. In oncology, experimental data are often
sparse and composed of a few time points of tumor volume. By embedding
inductive biases derived from prior information about a dynamical system, we
extend the physics-informed neural networks (PINN) and incorporate observed
biological constraints as regularization agents. The modified PINN algorithm is
able to steer itself to a reasonable solution and can generalize well with only
a few training examples. We demonstrate the merit of our approach by learning
the dynamics of treatment applied intermittently in an ordinary differential
equation (ODE) model of a combination therapy. The algorithm yields a solution
to the ODE and time-varying forms of some of the ODE model parameters. We
demonstrate a strong convergence using metrics such as the mean squared error
(MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).

</details>


### [421] [Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis](https://arxiv.org/abs/2510.13437)
*Ashish Bhatia,Renato Cordeiro de Amorim,Vito De Feo*

Main category: cs.LG

TL;DR: 提出了一种结合Mamdani系统可解释性和TSK模型精确度的新型模糊回归方法，通过混合规则结构和双重优势类型，在基准数据集上展示了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法在处理现实世界数据（如不确定性和模糊性）时存在困难，而深度学习方法虽然能捕捉复杂的非线性关系，但缺乏可解释性且容易在小数据集上过拟合。模糊系统（如Mamdani和TSK）在处理不确定性和模糊性方面提供了替代框架，但各有优缺点（可解释性 vs. 精确度）。

Method: 提出了一种新型模糊回归方法，结合了Mamdani系统的可解释性和TSK模型的精确度。该方法引入了具有模糊和清晰组件的混合规则结构，以及双重优势类型，以增强准确性和可解释性。

Result: 在基准数据集上的评估显示，在某些情况下取得了最先进的性能。规则保持了与传统Mamdani系统相似的组件，同时通过改进的规则输出来提高精度。在测试的6个数据集中，所提出的方法在4个数据集上取得了最佳模糊方法得分，在2个数据集上超越了不透明模型，并在1个数据集上取得了最佳总体得分，RMSE的改进范围为0.4%至19%。

Conclusion: 该混合方法提供了一种平衡且通用的预测建模工具，解决了模糊系统中可解释性和准确性之间的权衡问题。

Abstract: Regression analysis is employed to examine and quantify the relationships
between input variables and a dependent and continuous output variable. It is
widely used for predictive modelling in fields such as finance, healthcare, and
engineering. However, traditional methods often struggle with real-world data
complexities, including uncertainty and ambiguity. While deep learning
approaches excel at capturing complex non-linear relationships, they lack
interpretability and risk over-fitting on small datasets. Fuzzy systems provide
an alternative framework for handling uncertainty and imprecision, with Mamdani
and Takagi-Sugeno-Kang (TSK) systems offering complementary strengths:
interpretability versus accuracy. This paper presents a novel fuzzy regression
method that combines the interpretability of Mamdani systems with the precision
of TSK models. The proposed approach introduces a hybrid rule structure with
fuzzy and crisp components and dual dominance types, enhancing both accuracy
and explainability. Evaluations on benchmark datasets demonstrate
state-of-the-art performance in several cases, with rules maintaining a
component similar to traditional Mamdani systems while improving precision
through improved rule outputs. This hybrid methodology offers a balanced and
versatile tool for predictive modelling, addressing the trade-off between
interpretability and accuracy inherent in fuzzy systems. In the 6 datasets
tested, the proposed approach gave the best fuzzy methodology score in 4
datasets, out-performed the opaque models in 2 datasets and produced the best
overall score in 1 dataset with the improvements in RMSE ranging from 0.4% to
19%.

</details>


### [422] [Rectify and Align GPS Points to Parking Spots via Rank-1 Constraint](https://arxiv.org/abs/2510.13439)
*Jiaxing Deng,Junbiao Pang,Zhicheng Wang,Haitao Yu*

Main category: cs.LG

TL;DR: This paper proposes an unsupervised low-rank method to correct GPS errors in parking spot data by leveraging the physical constraint that parking spots are parallel to road sides.


<details>
  <summary>Details</summary>
Motivation: Accurate GPS data for parking spots is crucial for urban applications, but high-rise buildings and GPS equipment errors cause significant location inaccuracies, making unsupervised correction a challenging problem.

Method: An unsupervised low-rank method is proposed that utilizes the physical constraints of parking spots (parallelism to road sides) to rectify GPS errors and align them to actual parking spots within a unified framework.

Result: The proposed method is demonstrated to be effective through extensive experiments, showing superiority in solving the practical problem of GPS error correction for parking spots.

Conclusion: The developed unsupervised low-rank method effectively corrects GPS errors in parking spot data by exploiting geometric constraints, offering a simple yet powerful solution for practical applications.

Abstract: Parking spots are essential components, providing vital mobile resources for
residents in a city. Accurate Global Positioning System (GPS) points of parking
spots are the core data for subsequent applications,e.g., parking management,
parking policy, and urban development. However, high-rise buildings tend to
cause GPS points to drift from the actual locations of parking spots; besides,
the standard lower-cost GPS equipment itself has a certain location error.
Therefore, it is a non-trivial task to correct a few wrong GPS points from a
large number of parking spots in an unsupervised approach. In this paper,
motivated by the physical constraints of parking spots (i.e., parking spots are
parallel to the sides of roads), we propose an unsupervised low-rank method to
effectively rectify errors in GPS points and further align them to the parking
spots in a unified framework. The proposed unconventional rectification and
alignment method is simple and yet effective for any type of GPS point errors.
Extensive experiments demonstrate the superiority of the proposed method to
solve a practical problem. The data set and the code are publicly accessible
at:https://github.com/pangjunbiao/ITS-Parking-spots-Dataset.

</details>


### [423] [Neural Sum-of-Squares: Certifying the Nonnegativity of Polynomials with Transformers](https://arxiv.org/abs/2510.13444)
*Nico Pelleriti,Christoph Spiegel,Shiwei Liu,David Martínez-Rubio,Max Zimmer,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 利用Transformer模型预测多项式非负性的SOS（Sum of Squares）判定所需的几乎最小单项式基，从而大幅减小半定规划（SDP）问题的规模，实现高效的SOS判定，并将计算速度提升超过100倍。


<details>
  <summary>Details</summary>
Motivation: 多项式非负性的判定是一个NP难问题，在非凸优化、控制、机器人等领域有重要应用。SOS（Sum of Squares）是一种判定多项式非负性的充分条件，但其计算成本高昂，通常需要求解维度随单项式基大小二次增长的SDP问题。因此，寻找减小单项式基规模的方法至关重要。

Method: 提出了一种结合学习的算法来判定SOS准则。具体来说，训练了一个Transformer模型来预测给定多项式的几乎最小单项式基，从而显著减小了相应的SDP问题的维度。该方法包括三个关键部分：生成超过1亿个SOS多项式的高效训练数据集、设计和训练相应的Transformer模型架构，以及一个确保正确终止的系统性后备机制，并进行了理论分析。

Result: 在超过200个基准数据集上验证了所提出的方法，与现有最先进的求解器相比，实现了超过100倍的速度提升，并能够解决竞争方法失败的实例。

Conclusion: 该研究介绍了首个用于判定SOS准则的学习增强算法，通过Transformer模型预测几乎最小的单项式基，大幅减小了SDP问题的规模，显著提高了计算效率，并能在其他方法失败的情况下解决问题。研究结果为提高SOS规划的实际可扩展性提供了新的见解。

Abstract: Certifying nonnegativity of polynomials is a well-known NP-hard problem with
direct applications spanning non-convex optimization, control, robotics, and
beyond. A sufficient condition for nonnegativity is the Sum of Squares (SOS)
property, i.e., it can be written as a sum of squares of other polynomials. In
practice, however, certifying the SOS criterion remains computationally
expensive and often involves solving a Semidefinite Program (SDP), whose
dimensionality grows quadratically in the size of the monomial basis of the SOS
expression; hence, various methods to reduce the size of the monomial basis
have been proposed. In this work, we introduce the first learning-augmented
algorithm to certify the SOS criterion. To this end, we train a Transformer
model that predicts an almost-minimal monomial basis for a given polynomial,
thereby drastically reducing the size of the corresponding SDP. Our overall
methodology comprises three key components: efficient training dataset
generation of over 100 million SOS polynomials, design and training of the
corresponding Transformer architecture, and a systematic fallback mechanism to
ensure correct termination, which we analyze theoretically. We validate our
approach on over 200 benchmark datasets, achieving speedups of over $100\times$
compared to state-of-the-art solvers and enabling the solution of instances
where competing approaches fail. Our findings provide novel insights towards
transforming the practical scalability of SOS programming.

</details>


### [424] [$L_2$-Regularized Empirical Risk Minimization Guarantees Small Smooth Calibration Error](https://arxiv.org/abs/2510.13450)
*Masahiro Fujisawa,Futoshi Futami*

Main category: cs.LG

TL;DR: L2-regularized empirical risk minimization can directly control smooth calibration error (smCE) without post-hoc correction, with theoretical guarantees and experimental confirmation for kernel methods.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand how standard training procedures lead to well-calibrated machine learning models, a critical but poorly understood aspect of reliable machine learning.

Method: The study provides the first theoretical proof that canonical L2-regularized empirical risk minimization (ERM) directly controls smCE. It establishes finite-sample generalization bounds for smCE and instantiates this theory for models in reproducing kernel Hilbert spaces, deriving specific guarantees for kernel ridge and logistic regression.

Result: The theoretical analysis establishes finite-sample generalization bounds for smCE. Experiments confirm these guarantees, demonstrating that L2-regularized ERM can yield well-calibrated models without requiring boosting or post-hoc recalibration.

Conclusion: L2-regularized ERM inherently controls smCE, offering a theoretical foundation and practical validation for producing well-calibrated machine learning models without additional calibration steps.

Abstract: Calibration of predicted probabilities is critical for reliable machine
learning, yet it is poorly understood how standard training procedures yield
well-calibrated models. This work provides the first theoretical proof that
canonical $L_{2}$-regularized empirical risk minimization directly controls the
smooth calibration error (smCE) without post-hoc correction or specialized
calibration-promoting regularizer. We establish finite-sample generalization
bounds for smCE based on optimization error, regularization strength, and the
Rademacher complexity. We then instantiate this theory for models in
reproducing kernel Hilbert spaces, deriving concrete guarantees for kernel
ridge and logistic regression. Our experiments confirm these specific
guarantees, demonstrating that $L_{2}$-regularized ERM can provide a
well-calibrated model without boosting or post-hoc recalibration. The source
code to reproduce all experiments is available at
https://github.com/msfuji0211/erm_calibration.

</details>


### [425] [Towards Blackwell Optimality: Bellman Optimality Is All You Can Get](https://arxiv.org/abs/2510.13476)
*Victor Boone,Adrienne Tuynman*

Main category: cs.LG

TL;DR: 本文研究了在马尔可夫决策过程中（MDP）识别具有不同最优性阶数的策略的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管平均增益最优性是MDP中常用的性能度量，但它往往过于渐近。进一步考虑即时损失导致了偏最优性的层次结构，直至布莱克韦尔最优性。

Method: 为每个最优性阶数构造了一个错误概率可忽略的学习算法。此外，还刻画了可以有限时间内停止识别算法的MDP类别，该类别对应于具有唯一Bellman最优策略的MDP，并且不依赖于所考虑的最优性阶数。最后，提供了一个可行的停止规则，该规则与学习算法结合使用，并在可能的情况下在有限时间内触发。

Result: 为不同最优性阶数的策略识别构造了学习算法，并确定了何时可以在有限时间内停止这些算法。

Conclusion: 识别具有不同最优性阶数的MDP策略的学习算法被提出，并给出了有限停止条件的充要条件。

Abstract: Although average gain optimality is a commonly adopted performance measure in
Markov Decision Processes (MDPs), it is often too asymptotic. Further
incorporating measures of immediate losses leads to the hierarchy of bias
optimalities, all the way up to Blackwell optimality. In this paper, we
investigate the problem of identifying policies of such optimality orders. To
that end, for each order, we construct a learning algorithm with vanishing
probability of error. Furthermore, we characterize the class of MDPs for which
identification algorithms can stop in finite time. That class corresponds to
the MDPs with a unique Bellman optimal policy, and does not depend on the
optimality order considered. Lastly, we provide a tractable stopping rule that
when coupled to our learning algorithm triggers in finite time whenever it is
possible to do so.

</details>


### [426] [Tahakom LLM guidelines and receipts: from pre-training data to an Arabic LLM](https://arxiv.org/abs/2510.13481)
*Areej AlOtaibi,Lina Alyahya,Raghad Alshabanah,Shahad Alfawzan,Shuruq Alarefei,Reem Alsabti,Nouf Alsubaie,Abdulaziz Alhuzaymi,Lujain Alkhelb,Majd Alsayari,Waad Alahmed,Omar Talabay,Jalal Alowibdi,Salem Alelyani,Adel Bibi*

Main category: cs.LG

TL;DR: 该论文探讨了阿拉伯语大型语言模型（LLM）开发的独特挑战，包括数据收集、分词器设计和评估，并提出了改进的方法。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语LLM开发面临数据、分词器和评估等方面的独特挑战。

Method: 详细介绍了阿拉伯语预训练数据集的收集和过滤方法，评估了不同分词器设计对模型性能的影响，并提出了改进现有阿拉伯语评估框架的系统方法。

Result: 通过共享数据和方法，促进了阿拉伯语语言模型的开发和透明度。

Conclusion: 开发和改进阿拉伯语LLM需要解决数据、分词器和评估方面的具体挑战，通过共享资源和方法可以加速该领域的发展。

Abstract: Large Language Models (LLMs) have significantly advanced the field of natural
language processing, enhancing capabilities in both language understanding and
generation across diverse domains. However, developing LLMs for Arabic presents
unique challenges. This paper explores these challenges by focusing on critical
aspects such as data curation, tokenizer design, and evaluation. We detail our
approach to the collection and filtration of Arabic pre-training datasets,
assess the impact of various tokenizer designs on model performance, and
examine the limitations of existing Arabic evaluation frameworks, for which we
propose a systematic corrective methodology. To promote transparency and
facilitate collaborative development, we share our data and methodologies,
contributing to the advancement of language modeling, particularly for the
Arabic language.

</details>


### [427] [DistilCLIP-EEG: Enhancing Epileptic Seizure Detection Through Multi-modal Learning and Knowledge Distillation](https://arxiv.org/abs/2510.13497)
*Zexin Wang,Lin Shi,Haoyu Wu,Junru Luo,Xiangzeng Kong,Jun Qi*

Main category: cs.LG

TL;DR: 提出了一个结合脑电图（EEG）和文本描述的多模态深度学习模型DistilCLIP-EEG，用于癫痫检测。该模型利用CLIP框架，通过Conformer和BERT-LP编码器提取特征，并在共享的潜在空间中学习跨模态表示。此外，采用知识蒸馏方法训练一个更紧凑的学生模型，以降低复杂性和训练时间。在TUSZ、AUBMC和CHB-MIT数据集上，师生模型均取得了超过97%的准确率和0.94以上的F1分数。学生模型的参数量和模型大小仅为教师模型的约58.1%，显著降低了模型复杂度和存储需求，同时保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 现有癫痫检测的深度学习方法多仅依赖单模态脑电图（EEG）信号，忽略了多模态信息的潜在优势。

Method: 提出了一种基于CLIP框架的新型多模态模型DistilCLIP-EEG，结合了EEG信号和文本描述。模型包含一个基于Conformer架构的EEG编码器和一个基于BERT-LP（Prompt Learning）的文本编码器，两者在共享的潜在空间中进行操作，以实现有效的跨模态表示学习。此外，引入知识蒸馏方法，使训练好的DistilCLIP-EEG作为教师模型，指导一个更紧凑的学生模型，以降低训练复杂度和时间。

Result: 在TUSZ、AUBMC和CHB-MIT数据集上，DistilCLIP-EEG的教师模型和学生模型均取得了超过97%的准确率，F1分数均高于0.94。学生模型的参数量和模型大小约为教师模型的58.1%，显著降低了模型复杂度和存储需求，同时保持了高性能。

Conclusion: 提出的DistilCLIP-EEG模型及其知识蒸馏方法在EEG信号和文本描述的结合下，能够高效且可靠地进行癫痫检测，并且其紧凑的学生模型为在资源受限环境下的部署奠定了基础。

Abstract: Epilepsy is a prevalent neurological disorder marked by sudden, brief
episodes of excessive neuronal activity caused by abnormal electrical
discharges, which may lead to some mental disorders. Most existing deep
learning methods for epilepsy detection rely solely on unimodal EEG signals,
neglecting the potential benefits of multimodal information. To address this,
we propose a novel multimodal model, DistilCLIP-EEG, based on the CLIP
framework, which integrates both EEG signals and text descriptions to capture
comprehensive features of epileptic seizures. The model involves an EEG encoder
based on the Conformer architecture as a text encoder, the proposed Learnable
BERT (BERT-LP) as prompt learning within the encoders. Both operate in a shared
latent space for effective cross-modal representation learning. To enhance
efficiency and adaptability, we introduce a knowledge distillation method where
the trained DistilCLIP-EEG serves as a teacher to guide a more compact student
model to reduce training complexity and time. On the TUSZ, AUBMC, and CHB-MIT
datasets, both the teacher and student models achieved accuracy rates exceeding
97%. Across all datasets, the F1-scores were consistently above 0.94,
demonstrating the robustness and reliability of the proposed framework.
Moreover, the student model's parameter count and model size are approximately
58.1% of those of the teacher model, significantly reducing model complexity
and storage requirements while maintaining high performance. These results
highlight the potential of our proposed model for EEG-based epilepsy detection
and establish a solid foundation for deploying lightweight models in
resource-constrained settings.

</details>


### [428] [Offline and Online KL-Regularized RLHF under Differential Privacy](https://arxiv.org/abs/2510.13512)
*Yulian Wu,Rushil Thareja,Praneeth Vepakomma,Francesco Orabona*

Main category: cs.LG

TL;DR: 本文研究了带KL正则化的强化学习（RLHF）在差分隐私（LDP）下的离线和在线问题。


<details>
  <summary>Details</summary>
Motivation: 在差分隐私模型下研究带KL正则化的RLHF问题，以提高大型语言模型的可信度和安全性。

Method: 离线设置：设计基于悲观主义的算法，并证明其最优性。在线设置：设计基于乐观主义的算法，并推导出对数遗憾界。

Result: 离线设置：在KL正则化目标下得到了$	ilde{O}(1/[(e^
-1)^2 n])$的子最优性差距。在线设置：得到了$O(d_{
F}	ext{log}(N_{
F}	ext{·}T)/(e^
-1)^2)$的对数遗憾界。

Conclusion: 提出的算法在理论上是有效的，并且通过实验得到了验证。即使在没有隐私约束的情况下，该方法也提供了第一个在线KL正则化RLHF的理论分析。

Abstract: In this paper, we study the offline and online settings of reinforcement
learning from human feedback (RLHF) with KL-regularization -- a widely used
objective function in large language model alignment -- under the $\epsilon$
local differential privacy ($\epsilon$-LDP) model on the label of the human
preference. In the offline setting, we design an algorithm based on the
principle of pessimism and derive a new suboptimality gap of
$\tilde{O}(1/[(e^\epsilon-1)^2 n])$ on the KL-regularized objective under
single-policy concentrability. We also prove its optimality by providing a
matching lower bound where $n$ is the sample size.
  In the online setting, we are the first one to theoretically investigate the
problem of KL-regularized RLHF with LDP. We design an optimism-based algorithm
and derive a logarithmic regret bound of $O(d_{\mathcal{F}}\log
(N_{\mathcal{F}}\cdot T) /(e^\epsilon-1)^2 )$, where $T$ is the total time
step, $N_{\mathcal{F}}$ is cardinality of the reward function space
$\mathcal{F}$ and $d_{\mathcal{F}}$ is a variant of eluder dimension for RLHF.
As a by-product of our analysis, our results also imply the first analysis for
online KL-regularized RLHF without privacy. We implement our algorithm in the
offline setting to verify our theoretical results and release our open source
code at: https://github.com/rushil-thareja/PPKL-RLHF-Official.

</details>


### [429] [K-Merge: Online Continual Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2510.13537)
*Donald Shenaj,Ondrej Bohdal,Taha Ceritli,Mete Ozay,Pietro Zanuttigh,Umberto Michieli*

Main category: cs.LG

TL;DR: 在设备存储和计算资源有限的情况下，提出一种数据无关、计算高效的策略，用于在线合并增量式提供的LoRA适配器，以支持新的下游任务，同时保持对先前任务的性能。


<details>
  <summary>Details</summary>
Motivation: 随着用户请求对新任务（例如，新型问题类型或语言）的支持，LoRA适配器通常是逐步交付的。这引入了一个新的挑战：设备上的在线持续合并，目标是在支持新LoRA的同时保留对先前支持的任务的性能。

Method: 提出一种数据无关、计算高效的策略，用于在有新LoRA可用时选择和合并LoRA，同时假设设备只能存储有限数量的适配器。

Result: 在现实世界的任务中进行了广泛的实验，结果表明，在遵守设备设置的存储预算和计算限制的同时，与替代策略相比，该方法具有优越性。

Conclusion: 所提出的方法在设备存储和计算资源有限的情况下，能够有效地在线合并增量式提供的LoRA适配器，并且在保持对先前任务性能的同时支持新任务。

Abstract: On-device deployment of Large Language Models (LLMs) frequently leverages
Low-Rank Adapters (LoRAs) to support diverse downstream tasks under tight
resource constraints. To address the limited storage capacity of mobile
devices, recent works have explored model merging techniques to fuse multiple
LoRAs into a single one. In practice, however, LoRAs are often delivered
incrementally, as users request support for new tasks (e.g., novel problem
types or languages). This scenario introduces a new challenge: on-device online
continual merging, where the objective is to incorporate new LoRAs while
preserving the performance on previously supported tasks. In this paper, we
propose a data-free and computationally efficient strategy for selecting and
merging LoRAs when a new one becomes available, assuming the device can store
only a limited number of adapters. Extensive experiments across real-world
tasks demonstrate the superiority of our approach compared to alternative
strategies while adhering to the storage budget and compute limitations of
on-device settings.

</details>


### [430] [ProtoTopic: Prototypical Network for Few-Shot Medical Topic Modeling](https://arxiv.org/abs/2510.13542)
*Martin Licht,Sara Ketabi,Farzad Khalvati*

Main category: cs.LG

TL;DR: ProtoTopic是一种基于原型网络的模型，用于从有限的医学论文摘要中生成主题，提高了主题的连贯性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的主题建模技术在应用于医学文本时表现不佳，这可能是因为某些医学主题的可用文档数量较少。然而，医学领域的主题建模具有重要价值。

Method: 提出了一种名为ProtoTopic的新型主题模型，该模型基于原型网络。原型网络通过计算输入数据点与一组原型表示之间的距离来进行预测，特别适用于数据量少或少样本学习的场景。ProtoTopic被应用于一组医学论文摘要，用于生成主题。

Result: 与文献中使用的两种主题建模基线方法相比，ProtoTopic在主题连贯性和多样性方面表现出改进。这表明该模型即使在数据有限的情况下，也能够生成与医学相关的、质量更高的主题。

Conclusion: ProtoTopic模型能够有效地处理医学领域数据量有限的挑战，生成连贯且多样化的主题，优于现有的基线方法，为医学文本分析提供了新的解决方案。

Abstract: Topic modeling is a useful tool for analyzing large corpora of written
documents, particularly academic papers. Despite a wide variety of proposed
topic modeling techniques, these techniques do not perform well when applied to
medical texts. This can be due to the low number of documents available for
some topics in the healthcare domain. In this paper, we propose ProtoTopic, a
prototypical network-based topic model used for topic generation for a set of
medical paper abstracts. Prototypical networks are efficient, explainable
models that make predictions by computing distances between input datapoints
and a set of prototype representations, making them particularly effective in
low-data or few-shot learning scenarios. With ProtoTopic, we demonstrate
improved topic coherence and diversity compared to two topic modeling baselines
used in the literature, demonstrating the ability of our model to generate
medically relevant topics even with limited data.

</details>


### [431] [Multi-Objective $\textit{min-max}$ Online Convex Optimization](https://arxiv.org/abs/2510.13560)
*Rahul Vaze,Sumiran Mishra*

Main category: cs.LG

TL;DR: 本文研究了多目标在线凸优化问题，并提出了一种结合Hedge和OGD算法的方法，在i.i.d.假设下，实现了O(sqrt(T log K))的预期最小-最大遗憾。


<details>
  <summary>Details</summary>
Motivation: 在线凸优化（OCO）通常只考虑单个损失函数序列，而现实世界往往涉及多个需要权衡的损失函数。本研究旨在解决多目标OCO问题，即同时处理K个不同的损失函数序列，并最小化最坏情况下的遗憾。

Method: 针对i.i.d.（独立同分布）输入设置，提出了一种结合了Hedge和在线梯度下降（OGD）的算法。通过一个简洁的证明，分析了该算法的性能。

Result: 所提出的算法在i.i.d.设置下，其预期的最小-最大遗憾（min-max regret）可以达到O(sqrt(T log K))的界限。

Conclusion: 本研究成功地将OCO问题扩展到多目标场景，并通过一种结合Hedge和OGD的简单算法，在i.i.d.假设下，证明了其最小-最大遗憾的上界为O(sqrt(T log K))。这为处理具有多个相互冲突目标的在线决策问题提供了一个有效的解决方案。

Abstract: In online convex optimization (OCO), a single loss function sequence is
revealed over a time horizon of $T$, and an online algorithm has to choose its
action at time $t$, before the loss function at time $t$ is revealed. The goal
of the online algorithm is to incur minimal penalty (called $\textit{regret}$
compared to a static optimal action made by an optimal offline algorithm
knowing all functions of the sequence in advance.
  In this paper, we broaden the horizon of OCO, and consider multi-objective
OCO, where there are $K$ distinct loss function sequences, and an algorithm has
to choose its action at time $t$, before the $K$ loss functions at time $t$ are
revealed. To capture the tradeoff between tracking the $K$ different sequences,
we consider the $\textit{min-max}$ regret, where the benchmark (optimal offline
algorithm) takes a static action across all time slots that minimizes the
maximum of the total loss (summed across time slots) incurred by each of the
$K$ sequences. An online algorithm is allowed to change its action across time
slots, and its {\it min-max} regret is defined as the difference between its
$\textit{min-max}$ cost and that of the benchmark. The $\textit{min-max}$
regret is a stringent performance measure and an algorithm with small regret
needs to `track' all loss function sequences closely at all times.
  We consider this $\textit{min-max}$ regret in the i.i.d. input setting where
all loss functions are i.i.d. generated from an unknown distribution. For the
i.i.d. model we propose a simple algorithm that combines the well-known
$\textit{Hedge}$ and online gradient descent (OGD) and show via a remarkably
simple proof that its expected $\textit{min-max}$ regret is $O(\sqrt{T \log
K})$.

</details>


### [432] [DOLFIN: Balancing Stability and Plasticity in Federated Continual Learning](https://arxiv.org/abs/2510.13567)
*Omayma Moussadek,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: DOLFIN是一种结合了Vision Transformer和低秩适配器的联邦持续学习方法，通过LoRA降低通信开销，利用DualGPM防止遗忘，在保持隐私和内存占用的前提下，提高了学习新任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前联邦持续学习方法在性能、隐私保护和通信效率之间难以平衡。

Method: 提出DOLFIN方法，结合Vision Transformer和低秩适配器（LoRA），并引入DualGradient Projection Memory（DualGPM）来防止遗忘。

Result: 在CIFAR-100、ImageNet-R、ImageNet-A和CUB-200数据集上，DOLFIN在不同数据异构性设置下，最终平均准确率持续优于六种基线方法，同时内存占用相当。

Conclusion: 在联邦设置下，正交低秩适配器为保护隐私的持续学习提供了一种有效且可扩展的解决方案。

Abstract: Federated continual learning (FCL) enables models to learn new tasks across
multiple distributed clients, protecting privacy and without forgetting
previously acquired knowledge. However, current methods face challenges
balancing performance, privacy preservation, and communication efficiency. We
introduce a Distributed Online LoRA for Federated INcremental learning method
DOLFIN, a novel approach combining Vision Transformers with low-rank adapters
designed to efficiently and stably learn new tasks in federated environments.
Our method leverages LoRA for minimal communication overhead and incorporates
DualGradient Projection Memory (DualGPM) to prevent forgetting. Evaluated on
CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200 under two Dirichlet
heterogeneity settings, DOLFIN consistently surpasses six strong baselines in
final average accuracy while matching their memory footprint. Orthogonal
low-rank adapters offer an effective and scalable solution for
privacy-preserving continual learning in federated settings.

</details>


### [433] [Selective Adversarial Attacks on LLM Benchmarks](https://arxiv.org/abs/2510.13570)
*Ivan Dubrovsky,Anastasia Orlova,Illarion Iov,Nina Gubina,Irena Gureeva,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 存在选择性对抗性攻击，可以改变LLM评估的相对排名，挑战了排名的公平性、可重复性和透明度。


<details>
  <summary>Details</summary>
Motivation: 之前的NLP对抗鲁棒性工作主要关注影响许多模型的文本攻击，而未解决选择性地降低或提高性能的问题。本研究旨在解决这个问题，研究选择性对抗攻击在MMLU基准上的应用。

Method: 研究了选择性对抗攻击在MMLU基准上的应用。使用TextAttack框架中的经典攻击，引入了一个选择性评估协议，开发了一个自定义约束来提高攻击的选择性，并提出了一个生成选择性扰动的代理LLM（surrogate-LLM）流程。

Result: 研究发现，选择性对抗性攻击确实存在，并且能够实质性地改变LLM在MMLU基准上的相对排名。即使是细微的编辑也能改变比较判断。

Conclusion: 存在选择性对抗性攻击，可以改变LLM评估的相对排名，挑战了排名的公平性、可重复性和透明度。研究结果强调了在LLM评估中进行扰动感知报告和鲁棒性诊断的必要性。

Abstract: Benchmarking outcomes increasingly govern trust, selection, and deployment of
LLMs, yet these evaluations remain vulnerable to semantically equivalent
adversarial perturbations. Prior work on adversarial robustness in NLP has
emphasized text attacks that affect many models equally, leaving open the
question of whether it is possible to selectively degrade or enhance
performance while minimally affecting other models. We formalize this problem
and study selective adversarial attacks on MMLU - a widely used benchmark
designed to measure a language model's broad general knowledge and reasoning
ability across different subjects. Using canonical attacks integrated into
TextAttack framework, we introduce a protocol for selectivity assessment,
develop a custom constraint to increase selectivity of attacks and propose a
surrogate-LLM pipeline that generates selective perturbations. Empirically, we
find that selective adversarial attacks exist and can materially alter relative
rankings, challenging the fairness, reproducibility, and transparency of
leaderboard-driven evaluation. Our results motivate perturbation-aware
reporting and robustness diagnostics for LLM evaluation and demonstrate that
even subtle edits can shift comparative judgments.

</details>


### [434] [EEGChaT: A Transformer-Based Modular Channel Selector for SEEG Analysis](https://arxiv.org/abs/2510.13592)
*Chen Wang,Yansen Wang,Dongqi Han,Zilong Wang,Dongsheng Li*

Main category: cs.LG

TL;DR: EEGChaT是一个基于Transformer的通道选择模块，用于SEEG信号分析，通过CATs和注意力机制提高解码准确性并提供通道重要性得分。


<details>
  <summary>Details</summary>
Motivation: SEEG信号分析在BCI和神经科学研究中至关重要，但面临通道数量大、相关性异构的挑战。传统通道选择方法难以扩展且缺乏可解释性。

Method: 提出EEGChaT，一个基于Transformer的通道选择模块，引入通道聚合令牌（CATs）聚合信息，并使用改进的注意力轮播技术计算通道重要性得分。

Result: 在DuIN数据集上评估，EEGChaT与现有分类模型结合可提升高达17%的解码准确率。EEGChaT产生的通道权重与手动选择的通道高度重叠，证明了其可解释性。

Conclusion: EEGChaT是高维SEEG分析中一种有效且可泛化的通道选择解决方案，能够提升性能并提供神经信号相关性的见解。

Abstract: Analyzing stereoelectroencephalography (SEEG) signals is critical for
brain-computer interface (BCI) applications and neuroscience research, yet
poses significant challenges due to the large number of input channels and
their heterogeneous relevance. Traditional channel selection methods struggle
to scale or provide meaningful interpretability for SEEG data. In this work, we
propose EEGChaT, a novel Transformer-based channel selection module designed to
automatically identify the most task-relevant channels in SEEG recordings.
EEGChaT introduces Channel Aggregation Tokens (CATs) to aggregate information
across channels, and leverages an improved Attention Rollout technique to
compute interpretable, quantitative channel importance scores. We evaluate
EEGChaT on the DuIN dataset, demonstrating that integrating EEGChaT with
existing classification models consistently improves decoding accuracy,
achieving up to 17\% absolute gains. Furthermore, the channel weights produced
by EEGChaT show substantial overlap with manually selected channels, supporting
the interpretability of the approach. Our results suggest that EEGChaT is an
effective and generalizable solution for channel selection in high-dimensional
SEEG analysis, offering both enhanced performance and insights into neural
signal relevance.

</details>


### [435] [Physics-augmented Multi-task Gaussian Process for Modeling Spatiotemporal Dynamics](https://arxiv.org/abs/2510.13601)
*Xizhuo Zhang,Bing Yao*

Main category: cs.LG

TL;DR: 该论文提出了一种物理增强的多任务高斯过程（P-M-GP）框架，用于对具有复杂几何结构、快速时间动态以及需要联合预测多个相互关联的物理变量的非结构化时空数据进行建模。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理高维时空数据时面临挑战，特别是在处理不规则空间结构、快速时间动态以及联合预测多个相互关联的物理变量方面。本研究旨在提出一种新的框架来克服这些挑战。

Method: 本研究提出了一个物理增强的多任务高斯过程（P-M-GP）框架。该框架包括一个几何感知、多任务高斯过程（M-GP）模型，用于捕捉内在的时空结构和任务间的依赖关系。此外，通过一个基于物理的正则化方案，将控制物理定律纳入模型，以约束预测结果与控制动力学原理相一致。

Result: 在三维心脏电动力学建模任务上验证了所提出的P-M-GP框架。数值实验表明，通过有效地结合领域特定的物理约束和几何先验知识，本研究的方法在预测准确性上显著优于现有方法。

Conclusion: 所提出的P-M-GP框架能够有效地结合领域特定的物理约束和几何先验知识，从而在处理复杂的时空动态系统时，显著提高预测的准确性。

Abstract: Recent advances in sensing and imaging technologies have enabled the
collection of high-dimensional spatiotemporal data across complex geometric
domains. However, effective modeling of such data remains challenging due to
irregular spatial structures, rapid temporal dynamics, and the need to jointly
predict multiple interrelated physical variables. This paper presents a
physics-augmented multi-task Gaussian Process (P-M-GP) framework tailored for
spatiotemporal dynamic systems. Specifically, we develop a geometry-aware,
multi-task Gaussian Process (M-GP) model to effectively capture intrinsic
spatiotemporal structure and inter-task dependencies. To further enhance the
model fidelity and robustness, we incorporate governing physical laws through a
physics-based regularization scheme, thereby constraining predictions to be
consistent with governing dynamical principles. We validate the proposed P-M-GP
framework on a 3D cardiac electrodynamics modeling task. Numerical experiments
demonstrate that our method significantly improves prediction accuracy over
existing methods by effectively incorporating domain-specific physical
constraints and geometric prior.

</details>


### [436] [Towards Robust Knowledge Removal in Federated Learning with High Data Heterogeneity](https://arxiv.org/abs/2510.13606)
*Riccardo Santi,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 本文提出了一种基于任务算术和神经切线核的创新方法，能够快速移除客户端对模型的影响，解决了现有知识去除方法需要多次通信导致模型不可用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识去除方法需要多次通信，导致模型在去除过程中不可用，无法满足用户需求。

Method: 利用任务算术和神经切线核技术，快速移除客户端对模型的影响。

Result: 提出了一种创新的解决方案，能够快速移除客户端对模型的影响。

Conclusion: 本文提出的基于任务算术和神经切线核的方法，能够快速有效地移除客户端对模型的影响，解决了现有方法的不足。

Abstract: Nowdays, there are an abundance of portable devices capable of collecting
large amounts of data and with decent computational power. This opened the
possibility to train AI models in a distributed manner, preserving the
participating clients' privacy. However, because of privacy regulations and
safety requirements, elimination upon necessity of a client contribution to the
model has become mandatory. The cleansing process must satisfy specific
efficacy and time requirements. In recent years, research efforts have produced
several knowledge removal methods, but these require multiple communication
rounds between the data holders and the process coordinator. This can cause the
unavailability of an effective model up to the end of the removal process,
which can result in a disservice to the system users. In this paper, we
introduce an innovative solution based on Task Arithmetic and the Neural
Tangent Kernel, to rapidly remove a client's influence from a model.

</details>


### [437] [Manifold Decoders: A Framework for Generative Modeling from Nonlinear Embeddings](https://arxiv.org/abs/2510.13622)
*Riddhish Thakare,Kingdom Mutala Akugri*

Main category: cs.LG

TL;DR: 该研究提出了一个框架，为经典的非线性降维（NLDR）方法添加了神经网络解码器，实现了双向映射，并探索了基于流形生成的可能性，但发现其生成质量不如直接优化的自编码器，且流形约束的扩散模型生成样本质量差，表明经典NLDR嵌入不适合连续插值生成。


<details>
  <summary>Details</summary>
Motivation: 经典的非线性降维（NLDR）技术（如t-SNE、Isomap、LLE）在数据可视化方面表现出色，但缺乏将低维嵌入映射回高维空间的能力，这限制了它们在生成式应用中的使用。本研究旨在解决这一关键问题。

Method: 提出一个系统性框架，构建著名NLDR方法的神经网络解码器，实现首次双向映射。在此基础上，实现了一个基于扩散的生成过程，直接在学习到的流形空间内操作。通过在CelebA数据集上的实验，将该方法与自编码器和标准扩散模型基线进行重建和生成性能的对比评估。

Result: 实验表明，解码器成功实现了数据重建，但重建质量不如端到端优化的自编码器。此外，基于流形约束的扩散模型生成的样本质量较差。这表明经典NLDR嵌入的离散和稀疏特性不适合生成模型所需的连续插值。

Conclusion: 这项工作揭示了在主要为可视化和分析设计的NLDR方法上强加生成能力的固有挑战。解码器虽然可以重建数据，但质量不如自编码器；流形约束的扩散生成效果不佳，表明经典NLDR嵌入不适合生成模型。

Abstract: Classical nonlinear dimensionality reduction (NLDR) techniques like t-SNE,
Isomap, and LLE excel at creating low-dimensional embeddings for data
visualization but fundamentally lack the ability to map these embeddings back
to the original high-dimensional space. This one-way transformation limits
their use in generative applications. This paper addresses this critical gap by
introducing a system- atic framework for constructing neural decoder
architectures for prominent NLDR methods, enabling bidirectional mapping for
the first time. We extend this framework by implementing a diffusion-based
generative process that operates directly within these learned manifold spaces.
Through experiments on the CelebA dataset, we evaluate the reconstruction and
generative performance of our approach against autoencoder and standard
diffusion model baselines. Our findings reveal a fundamental trade- off: while
the decoders successfully reconstruct data, their quality is surpassed by
end-to-end optimized autoencoders. Moreover, manifold-constrained diffusion
yields poor-quality samples, suggesting that the discrete and sparse nature of
classical NLDR embeddings is ill-suited for the continuous inter- polation
required by generative models. This work highlights the inherent challenges in
retrofitting generative capabilities onto NLDR methods designed primarily for
visualization and analysis.

</details>


### [438] [What is the objective of reasoning with reinforcement learning?](https://arxiv.org/abs/2510.13651)
*Damek Davis,Benjamin Recht*

Main category: cs.LG

TL;DR: 一些流行的用于二元奖励的大型语言模型强化学习算法可以被看作是在正确答案概率的单调变换上的随机梯度上升。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是展示流行的强化学习算法与概率的单调变换之间的联系。

Method: 研究了与拒绝采样算法和GRPO算法相关的特定变换（对数和平方根的反正弦）。

Result: 结果表明，这些算法可以被视为在正确答案概率的单调变换上的随机梯度上升。

Conclusion: 结论是，通过理解这些变换，可以更好地理解和可能改进用于大型语言模型的强化学习算法。

Abstract: We show that several popular algorithms for reinforcement learning in large
language models with binary rewards can be viewed as stochastic gradient ascent
on a monotone transform of the probability of a correct answer given a prompt.
In particular, the transformation associated with rejection sampling algorithms
is the logarithm and that associated with the GRPO algorithm is the arcsine of
the square root.

</details>


### [439] [Time Series Foundation Models: Benchmarking Challenges and Requirements](https://arxiv.org/abs/2510.13654)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Oliver Müller*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFM）的评估面临数据代表性不足、缺乏时空评估、信息泄露和对外部冲击的记忆等挑战，需要开发稳健的评估方法，例如在真正样本外数据上进行评估，以确保TSFM评估的完整性。


<details>
  <summary>Details</summary>
Motivation: 评估时间序列基础模型（TSFM）面临严峻挑战，需要确保基准测试数据的完整性，防止出现信息泄露和错误评估。

Method: 本文通过研究现有的TSFM评估方法，揭示了其在数据代表性、时空评估、信息泄露和模式记忆方面的局限性。

Result: 研究发现，数据划分混乱导致性能估计虚高，以及全局知识向局部时间序列转移的错误。

Conclusion: TSFM的评估需要新的、原则性的方法，例如在真正样本外数据上进行评估，以防止LLM和传统时间序列基准测试中出现的类似问题。

Abstract: Time Series Foundation Models (TSFMs) represent a new paradigm for time
series forecasting, offering zero-shot forecasting capabilities without the
need for domain-specific pre-training or fine-tuning. However, as with Large
Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive
training sets, it becomes more and more challenging to ensure the integrity of
benchmarking data. Our investigation of existing TSFM evaluation highlights
multiple challenges, ranging from the representativeness of the benchmark
datasets, over the lack of spatiotemporal evaluation, to risks of information
leakage due to overlapping and obscure datasets, and the memorization of global
patterns caused by external shocks like economic crises or pandemics. Our
findings reveal widespread confusion regarding data partitions, risking
inflated performance estimates and incorrect transfer of global knowledge to
local time series. We argue for the development of robust evaluation
methodologies to prevent pitfalls already observed in LLM and classical time
series benchmarking, and call upon the research community to design new,
principled approaches, such as evaluations on truly out-of-sample future data,
to safeguard the integrity of TSFM assessment.

</details>


### [440] [Rebalancing with Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced Classification](https://arxiv.org/abs/2510.13656)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 该研究提出了一种名为RCS（Rebalancing with Calibrated Sub-classes）的新方法来解决分类中的类别不平衡问题。RCS通过混合高斯成分来估计少数类的分布参数，并使用编码器-解码器网络生成合成样本，以克服仅使用多数类分布进行近似时出现的过度泛化问题。实验证明，RCS在图像、文本和表格数据集上均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡问题导致分类器偏向多数类，现有方法未能有效解决此问题。

Method: 提出了一种名为RCS（Rebalancing with Calibrated Sub-classes）的方法，通过混合高斯成分估计少数类分布参数，并利用编码器-解码器网络生成合成样本，从而实现分布校准。

Result: RCS在图像、文本和表格数据集上均取得了优于基线和最先进技术的分类性能。

Conclusion: RCS通过利用邻近区域的数据点分布来校准参数，有效解决了类别不平衡问题，并显著提高了分类性能。

Abstract: The class imbalance problem refers to the insufficiency of data in certain
classes, which causes a classifier to be biased toward the majority class.
Distribution calibration is a technique that seeks to estimate a more accurate
class distribution based on an observed or estimated one. To address this
issue, we propose a distribution calibration-based method-Rebalancing with
Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced
Classification, which estimates the distribution parameters of the minority
classes using weighted parameters derived from a mixture of Gaussian components
from both the majority and intermediate classes. An encoder-decoder network is
trained to preserve the structure of the imbalanced data and prevent
disentanglement. After training, feature vectors extracted from the encoder are
used to generate synthetic samples through our distribution calibration
strategy. This approach effectively mitigates the overgeneralization problem
that arises when only the distribution of the majority class is used to
approximate the minority class statistics. Instead, our method calibrates the
parameters by leveraging the distribution of data points in neighboring
regions. Experimental results demonstrate that the proposed method achieves
superior classification performance compared to several baseline and
state-of-the-art techniques across a diverse range of image, text, and tabular
datasets.

</details>


### [441] [Axial Neural Networks for Dimension-Free Foundation Models](https://arxiv.org/abs/2510.13665)
*Hyunsu Kim,Jonggeon Park,Joan Bruna,Hongseok Yang,Juho Lee*

Main category: cs.LG

TL;DR: XNN是一种新提出的维度无关的神经网络架构，可以有效处理不同维度物理系统中的偏微分方程（PDE），并且在零样本推理和上下文学习方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于传统方法在处理不同维度物理系统的数据时存在效率低下（例如固定最大维度或为不同维度使用单独的编码器），因此需要一种能够处理不同维度并保持计算效率的新方法。

Method: 提出了一种名为XNN（Axial Neural Network）的新型神经网络架构，该架构借鉴了Deep Sets和Graph Neural Networks等参数共享结构，能够实现跨不同张量维度的泛化，同时保持计算效率。通过将现有的PDE基础模型转换为XNN，并在三种不同的训练场景（从头开始训练、在多个PDE上进行预训练以及在单个PDE上进行微调）下进行评估。

Result: XNN模型在性能上与原始模型相当，并且在泛化到未见过的维度方面表现更优，证明了其处理不同维度问题的能力。

Conclusion: XNN架构在处理多维度PDE问题上具有显著优势，并且通过多维度预训练可以进一步提升基础模型的泛化能力，这对于未来基础模型在科学计算领域的应用具有重要意义。

Abstract: The advent of foundation models in AI has significantly advanced
general-purpose learning, enabling remarkable capabilities in zero-shot
inference and in-context learning. However, training such models on physics
data, including solutions to partial differential equations (PDEs), poses a
unique challenge due to varying dimensionalities across different systems.
Traditional approaches either fix a maximum dimension or employ separate
encoders for different dimensionalities, resulting in inefficiencies. To
address this, we propose a dimension-agnostic neural network architecture, the
Axial Neural Network (XNN), inspired by parameter-sharing structures such as
Deep Sets and Graph Neural Networks. XNN generalizes across varying tensor
dimensions while maintaining computational efficiency. We convert existing PDE
foundation models into axial neural networks and evaluate their performance
across three training scenarios: training from scratch, pretraining on multiple
PDEs, and fine-tuning on a single PDE. Our experiments show that XNNs perform
competitively with original models and exhibit superior generalization to
unseen dimensions, highlighting the importance of multidimensional pretraining
for foundation models.

</details>


### [442] [Adam or Gauss-Newton? A Comparative Study In Terms of Basis Alignment and SGD Noise](https://arxiv.org/abs/2510.13680)
*Bingbin Liu,Rachit Bansal,Depen Morwani,Nikhil Vyas,David Alvarez-Melis,Sham M. Kakade*

Main category: cs.LG

TL;DR: Adam和Gauss-Newton（GN）是两种主要的对角预处理方法，用于加速深度学习模型训练。本文通过分析预处理器的基选择和梯度噪声的影响，比较了这两种方法。


<details>
  <summary>Details</summary>
Motivation: 加速深度学习模型训练，比较Adam和Gauss-Newton（GN）两种对角预处理方法。

Method: 在二次目标和逻辑回归上分析预处理器的基选择和梯度噪声对Adam和GN方法的影响。

Result: 在全批量设置下，Adam有时优于GN$^{-1}$和GN$^{-1/2}$。在随机设置下，Adam在假设高斯数据的情况下，在（线性）回归上表现与GN$^{-1/2}$相似。

Conclusion: Adam和GN在不同设置下各有优劣，理论分析和经验研究均支持这些结果。

Abstract: Diagonal preconditioners are computationally feasible approximate to
second-order optimizers, which have shown significant promise in accelerating
training of deep learning models. Two predominant approaches are based on Adam
and Gauss-Newton (GN) methods: the former leverages statistics of current
gradients and is the de-factor optimizers for neural networks, and the latter
uses the diagonal elements of the Gauss-Newton matrix and underpins some of the
recent diagonal optimizers such as Sophia.
  In this work, we compare these two diagonal preconditioning methods through
the lens of two key factors: the choice of basis in the preconditioner, and the
impact of gradient noise from mini-batching. To gain insights, we analyze these
optimizers on quadratic objectives and logistic regression under all four
quadrants. We show that regardless of the basis, there exist instances where
Adam outperforms both GN$^{-1}$ and GN$^{-1/2}$ in full-batch settings.
Conversely, in the stochastic regime, Adam behaves similarly to GN$^{-1/2}$ for
linear regression under a Gaussian data assumption. These theoretical results
are supported by empirical studies on both convex and non-convex objectives.

</details>


### [443] [Information-Theoretic Reward Modeling for Stable RLHF: Detecting and Mitigating Reward Hacking](https://arxiv.org/abs/2510.13694)
*Yuchun Miao,Liang Ding,Sen Zhang,Rong Bao,Lefei Zhang,Dacheng Tao*

Main category: cs.LG

TL;DR: RLHF 中的奖励劫持问题源于奖励模型中的奖励误泛化和 RL 优化中的正则化不足。InfoRM 框架通过信息瓶颈原则过滤无关信息来缓解奖励误泛化，IBL 正则化通过惩罚 IB 潜在空间中的异常值来解决优化问题，MOP 指标用于量化奖励劫持的严重性。


<details>
  <summary>Details</summary>
Motivation: 尽管 RLHF 在语言模型对齐方面取得了成功，但奖励劫持仍然是一个重大挑战。现有的方法在缓解这个问题上面临两个主要障碍：奖励模型中的奖励误泛化（将不相关的特征过拟合）和 RL 优化过程中缺乏合适的正则化（现有的 token 级约束过于严格）。

Method: 提出了一种名为 InfoRM 的信息论奖励建模框架，该框架基于信息瓶颈（IB）原理，旨在过滤掉与偏好无关的信息，从而减轻奖励误泛化。此外，还引入了一种名为 IBL 的分布级正则化方法，该方法通过惩罚 IB 潜在空间中由 Mahalanobis 距离衡量的、与 SFT（监督微调）诱导分布显著偏离的异常值来解决奖励劫持问题。最后，提出了一种名为 MOP（Mahalanobis Outlier Probability）的统计指标，用于量化奖励劫持的严重程度。

Result: 实验结果表明，InfoRM 框架能够有效缓解奖励误泛化，IBL 正则化能够有效地扩展优化空间并保持对齐，MOP 指标能够可靠地用于评估奖励劫持的严重性。这些方法在多种大型语言模型和数据集上都表现出了通用性和有效性。

Conclusion: InfoRM、IBL 和 MOP 的结合为解决 RLHF 中的奖励劫持问题提供了一个有希望的解决方案，显著推动了 RLHF 的研究进展。

Abstract: Despite the success of Reinforcement Learning from Human Feedback (RLHF) in
aligning language models with human values, reward hacking-or reward
over-optimization-remains a major challenge. We identify two key obstacles to
its mitigation: (1) reward misgeneralization in reward modeling, where reward
models overfit to spurious, preference-irrelevant features; and (2) the lack of
suitable regularization during RL optimization, as existing token-level
constraints often over-restrict the policy space. To address these issues, we
propose InfoRM, an information-theoretic reward modeling framework based on the
Information Bottleneck (IB) principle, which filters out preference-irrelevant
information to alleviate reward misgeneralization. We further observe that
reward-hacked responses manifest as pronounced outliers in InfoRM's IB latent
space, measured by Mahalanobis distance from the SFT-induced distribution.
Motivated by this, we introduce IBL, a distribution-level regularization that
penalizes such deviations, effectively expanding the optimization landscape
while maintaining alignment. We prove that IBL is theoretically equivalent to
the pessimistic RL objective within the IB latent space. Finally, we present
Mahalanobis Outlier Probability (MOP), a statistical metric for quantifying
reward hacking severity, enabling principled hyperparameter tuning and online
mitigation such as early stopping. Extensive experiments across diverse LLMs
and datasets confirm the generality of our findings, the effectiveness of
InfoRM and IBL, and the reliability of MOP as a diagnostic tool-collectively
advancing the state of RLHF.

</details>


### [444] [Don't Be Greedy, Just Relax! Pruning LLMs via Frank-Wolfe](https://arxiv.org/abs/2510.13713)
*Christophe Roux,Max Zimmer,Alexandre d'Aspremont,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 本论文提出一种利用弗兰克-沃尔夫（FW）算法解决LLM剪枝的组合优化问题的方法，以减少计算和存储需求，并取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的神经网络剪枝方法需要重新训练模型以恢复性能，但对于计算成本高昂的大型语言模型（LLM）来说，这被认为是不可行的。现有的LLM剪枝方法虽然避免了完全重新训练，但它们采用贪婪的启发式方法，忽略了权重之间的相互作用，导致最优剪枝掩码的寻找成为一个困难的组合问题。

Method: 本研究提出一种利用凸松弛和弗兰克-沃尔夫（FW）算法来解决LLM剪枝的组合优化问题。该方法通过求解松弛后的问题，并利用FW算法的收敛保证，获得一个近似最优解，然后将该解四舍五入为整数以得到最终的剪枝掩码。

Result: 该方法显著降低了每层的剪枝误差，在最先进的GPT架构上表现优于强大的基线方法，并且在内存使用方面保持高效。

Conclusion: 通过将组合优化问题进行凸松弛并利用弗兰克-沃尔夫（FW）算法求解，本研究提出了一种更有效的LLM剪枝方法。该方法不仅提高了剪枝性能，减少了剪枝误差，而且在计算和内存方面也具有优势，并具有理论上的收敛保证。

Abstract: Pruning is a common technique to reduce the compute and storage requirements
of Neural Networks. While conventional approaches typically retrain the model
to recover pruning-induced performance degradation, state-of-the-art Large
Language Model (LLM) pruning methods operate layer-wise, minimizing the
per-layer pruning error on a small calibration dataset to avoid full
retraining, which is considered computationally prohibitive for LLMs. However,
finding the optimal pruning mask is a hard combinatorial problem and solving it
to optimality is intractable. Existing methods hence rely on greedy heuristics
that ignore the weight interactions in the pruning objective. In this work, we
instead consider the convex relaxation of these combinatorial constraints and
solve the resulting problem using the Frank-Wolfe (FW) algorithm. Our method
drastically reduces the per-layer pruning error, outperforms strong baselines
on state-of-the-art GPT architectures, and remains memory-efficient. We provide
theoretical justification by showing that, combined with the convergence
guarantees of the FW algorithm, we obtain an approximate solution to the
original combinatorial problem upon rounding the relaxed solution to
integrality.

</details>


### [445] [Assessing the Geographic Generalization and Physical Consistency of Generative Models for Climate Downscaling](https://arxiv.org/abs/2510.13722)
*Carlo Saccardi,Maximilian Pierzyna,Haitz Sáez de Ocáriz Borde,Simone Monaco,Cristian Meo,Pietro Liò,Rudolf Saathof,Geethu Joseph,Justin Dauwels*

Main category: cs.LG

TL;DR: 深度学习模型在气候降尺度方面有潜力，但其可靠性仍需提升。本文评估了现有模型，并引入了新的评估方法。


<details>
  <summary>Details</summary>
Motivation: 传统的公里级天气数据模拟计算成本高，深度学习模型可以提供更快的替代方案，但其可靠性仍受质疑，因为它们通常使用标准的机器学习指标进行评估，而非基于大气和天气物理学的洞察。

Method: 对最新的深度学习模型进行基准测试，并引入了受物理学启发的诊断方法来评估其性能和可靠性，特别关注地理泛化和物理一致性。提出了一种简单的初始解决方案：引入功率谱密度损失函数，通过鼓励重建小尺度物理结构来经验性地改善地理泛化。

Result: 实验表明，即使是像CorrDiff这样性能看似强大的模型，在仅在有限的欧洲地理区域（例如中欧）训练后，也很难泛化到其他地区（例如南部的伊比利亚、摩洛哥或北部的斯堪的纳维亚）。它们也未能准确捕捉从预测速度场导出的散度和涡度等二阶变量。这些缺陷甚至出现在分布内的地理区域，表明在生成物理上一致的预测方面存在挑战。

Conclusion: 尽管深度学习模型在气候降尺度方面显示出前景，但它们在地理泛化和物理一致性方面仍存在挑战。通过引入像功率谱密度损失函数这样的物理学启发方法，可以改善这些模型的性能。

Abstract: Kilometer-scale weather data is crucial for real-world applications but
remains computationally intensive to produce using traditional weather
simulations. An emerging solution is to use deep learning models, which offer a
faster alternative for climate downscaling. However, their reliability is still
in question, as they are often evaluated using standard machine learning
metrics rather than insights from atmospheric and weather physics. This paper
benchmarks recent state-of-the-art deep learning models and introduces
physics-inspired diagnostics to evaluate their performance and reliability,
with a particular focus on geographic generalization and physical consistency.
Our experiments show that, despite the seemingly strong performance of models
such as CorrDiff, when trained on a limited set of European geographies (e.g.,
central Europe), they struggle to generalize to other regions such as Iberia,
Morocco in the south, or Scandinavia in the north. They also fail to accurately
capture second-order variables such as divergence and vorticity derived from
predicted velocity fields. These deficiencies appear even in in-distribution
geographies, indicating challenges in producing physically consistent
predictions. We propose a simple initial solution: introducing a power spectral
density loss function that empirically improves geographic generalization by
encouraging the reconstruction of small-scale physical structures. The code for
reproducing the experimental results can be found at
https://github.com/CarloSaccardi/PSD-Downscaling

</details>


### [446] [Asymptotically optimal reinforcement learning in Block Markov Decision Processes](https://arxiv.org/abs/2510.13748)
*Thomas van Vuren,Fiona Sloothaak,Maarten G. Wolf,Jaron Sanders*

Main category: cs.LG

TL;DR: 本研究提出了一个用于块马尔可夫决策过程（BMDP）的强化学习（RL）算法，并通过理论分析证明了其在减少学习过程中的遗憾（regret）方面的有效性，特别是在高维状态空间中。


<details>
  <summary>Details</summary>
Motivation: 在高维状态和动作空间中，强化学习（RL）面临“维度诅咒”的挑战，难以有效学习。本研究旨在利用环境中潜在的可识别结构来加速RL学习过程，并对此类结构进行正式建模和分析。

Method: 本研究提出并分析了一种两阶段的RL算法。第一阶段，算法通过随机探索学习潜在结构；第二阶段，算法切换到基于乐观主义的策略，并利用已发现的结构进行学习。该算法适用于块马尔可夫决策过程（BMDP），其中状态空间的转移动态由潜在状态决定。

Result: 在易于聚类的BMDPs类别中，所提出的算法实现了 $O(\sqrt{T}+n)$ 的遗憾界限，其中 $T$ 是时间步长，$n$ 是观察空间的基数。这一结果优于先前最佳的 $O(\sqrt{T}+n^2)$ 界限，尤其是在 $n$ 较大时。此外，研究证明了该算法在该类BMDPs上的遗憾已达到渐近最优。

Conclusion: 本研究成功地为块马尔可夫决策过程（BMDPs）设计并分析了一种强化学习算法，证明了利用聚类方法学习潜在结构能够显著加速学习过程。所提出的算法在理论上达到了渐近最优的遗憾界限，解决了先前分析中的空白，并为在高维环境中应用强化学习提供了新的见解。

Abstract: The curse of dimensionality renders Reinforcement Learning (RL) impractical
in many real-world settings with exponentially large state and action spaces.
Yet, many environments exhibit exploitable structure that can accelerate
learning. To formalize this idea, we study RL in Block Markov Decision
Processes (BMDPs). BMDPs model problems with large observation spaces, but
where transition dynamics are fully determined by latent states. Recent
advances in clustering methods have enabled the efficient recovery of this
latent structure. However, a regret analysis that exploits these techniques to
determine their impact on learning performance remained open. We are now
addressing this gap by providing a regret analysis that explicitly leverages
clustering, demonstrating that accurate latent state estimation can indeed
effectively speed up learning.
  Concretely, this paper analyzes a two-phase RL algorithm for BMDPs that first
learns the latent structure through random exploration and then switches to an
optimism-guided strategy adapted to the uncovered structure. This algorithm
achieves a regret that is $O(\sqrt{T}+n)$ on a large class of BMDPs susceptible
to clustering. Here, $T$ denotes the number of time steps, $n$ is the
cardinality of the observation space, and the Landau notation $O(\cdot)$ holds
up to constants and polylogarithmic factors. This improves the best prior
bound, $O(\sqrt{T}+n^2)$, especially when $n$ is large. Moreover, we prove that
no algorithm can achieve lower regret uniformly on this same class of BMDPs.
This establishes that, on this class, the algorithm achieves asymptotic
optimality.

</details>


### [447] [Progressive multi-fidelity learning for physical system predictions](https://arxiv.org/abs/2510.13762)
*Paolo Conti,Mengwu Guo,Attilio Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: 通过引入一种渐进式多保真度代理模型，该模型能够利用定制编码器相继纳入不同类型的数据，并使用神经网络对编码后的输入与目标量之间进行多保真度回归。


<details>
  <summary>Details</summary>
Motivation: 高精度数据集获取成本高昂，限制了需要精确评估的应用程序，而低精度数据易于获取但精度不足。如何有效利用不同类型、来源、模式且不一定同时可用的数据来改进代理模型的预测能力是一个挑战。

Method: 提出一种渐进式多保真度代理模型，该模型能顺序地整合不同类型的数据（使用定制编码器），然后通过神经网络进行多保真度回归。模型包含两种连接方式：所有编码输入之间的连接，以及最终输出之间的加性连接。

Result: 该方法能够可靠地整合多模态数据，提供准确的预测，并在时间与参数变化泛化时保持性能。

Conclusion: 所提出的渐进式多保真度代理模型能够有效应对多保真度数据建模中的挑战，通过渐进式整合和双连接系统，实现了准确的预测和鲁棒的性能。

Abstract: Highly accurate datasets from numerical or physical experiments are often
expensive and time-consuming to acquire, posing a significant challenge for
applications that require precise evaluations, potentially across multiple
scenarios and in real-time. Even building sufficiently accurate surrogate
models can be extremely challenging with limited high-fidelity data.
Conversely, less expensive, low-fidelity data can be computed more easily and
encompass a broader range of scenarios. By leveraging multi-fidelity
information, prediction capabilities of surrogates can be improved. However, in
practical situations, data may be different in types, come from sources of
different modalities, and not be concurrently available, further complicating
the modeling process. To address these challenges, we introduce a progressive
multi-fidelity surrogate model. This model can sequentially incorporate diverse
data types using tailored encoders. Multi-fidelity regression from the encoded
inputs to the target quantities of interest is then performed using neural
networks. Input information progressively flows from lower to higher fidelity
levels through two sets of connections: concatenations among all the encoded
inputs, and additive connections among the final outputs. This dual connection
system enables the model to exploit correlations among different datasets while
ensuring that each level makes an additive correction to the previous level
without altering it. This approach prevents performance degradation as new
input data are integrated into the model and automatically adapts predictions
based on the available inputs. We demonstrate the effectiveness of the approach
on numerical benchmarks and a real-world case study, showing that it reliably
integrates multi-modal data and provides accurate predictions, maintaining
performance when generalizing across time and parameter variations.

</details>


### [448] [Tensor Gaussian Processes: Efficient Solvers for Nonlinear PDEs](https://arxiv.org/abs/2510.13772)
*Qiwei Yuan,Zhitong Xu,Yinghao Chen,Yiming Xu,Houman Owhadi,Shandian Zhe*

Main category: cs.LG

TL;DR: TGPS是一种基于张量高斯过程（GP）的PDE求解器，通过结合一维GP和张量分解来解决计算复杂性和可扩展性问题，并在求解非线性PDE时采用部分冻结策略和牛顿法进行线性化，通过交替最小二乘法（ALS）实现高效训练，实验证明其在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的PDE求解器（如神经网络求解器）存在训练效率低下、需要大量训练周期的问题；而基于高斯过程（GP）/核的方法在处理大量配置点时存在可扩展性问题，尤其是在处理挑战性或高维PDE时。

Method: 提出了一种基于张量GP的求解器TGPS，该方法将沿每个输入维度的一维函数建模为一维GP，并通过张量分解组合它们来近似全解。为了高效地求解非线性PDE，采用了部分冻结策略和牛顿法来线性化非线性项，并开发了一种交替最小二乘（ALS）方法，该方法具有闭式更新，从而大大提高了训练效率。对模型的表达能力进行了理论保证，并在标准正则性假设下进行了收敛性和误差分析。

Result: 实验表明，该方法在多个基准PDE上实现了优于现有方法的准确性和效率。

Conclusion: TGPS通过结合一维GP和张量分解，以及采用部分冻结策略、牛顿法和ALS方法，有效解决了现有PDE求解器在计算复杂性、可扩展性和训练效率方面的问题，并在准确性和效率上取得了优于现有方法的性能。

Abstract: Machine learning solvers for partial differential equations (PDEs) have
attracted growing interest. However, most existing approaches, such as neural
network solvers, rely on stochastic training, which is inefficient and
typically requires a great many training epochs. Gaussian process
(GP)/kernel-based solvers, while mathematical principled, suffer from
scalability issues when handling large numbers of collocation points often
needed for challenging or higher-dimensional PDEs.
  To overcome these limitations, we propose TGPS, a tensor-GP-based solver that
models factor functions along each input dimension using one-dimensional GPs
and combines them via tensor decomposition to approximate the full solution.
This design reduces the task to learning a collection of one-dimensional GPs,
substantially lowering computational complexity, and enabling scalability to
massive collocation sets.
  For efficient nonlinear PDE solving, we use a partial freezing strategy and
Newton's method to linerize the nonlinear terms. We then develop an alternating
least squares (ALS) approach that admits closed-form updates, thereby
substantially enhancing the training efficiency. We establish theoretical
guarantees on the expressivity of our model, together with convergence proof
and error analysis under standard regularity assumptions. Experiments on
several benchmark PDEs demonstrate that our method achieves superior accuracy
and efficiency compared to existing approaches.

</details>


### [449] [UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations](https://arxiv.org/abs/2510.13774)
*Dominik J. Mühlematter,Lin Che,Ye Hong,Martin Raubal,Nina Wiedemann*

Main category: cs.LG

TL;DR: UrbanFusion是一个地理基础模型（GeoFM），通过随机多模态融合（SMF）有效整合街景图像、遥感数据、地图和兴趣点（POI）等多种地理空间数据，用于预测城市现象。它在41个任务和56个城市的评估中表现出色，优于现有GeoAI模型，尤其在位置编码、多模态推理和跨区域泛化能力方面。该模型还可以根据可用数据灵活选择模态，适用于不同数据可用性场景。


<details>
  <summary>Details</summary>
Motivation: 当前预测城市现象（如房价、公共卫生指标）的方法多采用特定任务模型，而现有的空间表示基础模型模态有限且缺乏多模态融合能力，难以有效整合多种地理空间数据。

Method: 提出UrbanFusion，一个包含随机多模态融合（SMF）的地理基础模型（GeoFM）。使用特定模态的编码器处理街景图像、遥感数据、地图和POI等多种输入，并通过基于Transformer的融合模块学习统一表示。

Result: 在41个任务和56个城市的广泛评估中，UrbanFusion的泛化能力和预测性能优于最先进的GeoAI模型。具体来说，它在位置编码方面优于先前模型，支持推理时进行多模态输入，并能很好地泛化到训练时未见过的数据。

Conclusion: UrbanFusion作为一种地理基础模型，通过其随机多模态融合机制，能够有效整合多种地理空间数据，在城市现象预测方面展现出强大的泛化能力和预测性能，并能灵活适应不同的数据可用性场景。

Abstract: Forecasting urban phenomena such as housing prices and public health
indicators requires the effective integration of various geospatial data.
Current methods primarily utilize task-specific models, while recent foundation
models for spatial representations often support only limited modalities and
lack multimodal fusion capabilities. To overcome these challenges, we present
UrbanFusion, a Geo-Foundation Model (GeoFM) that features Stochastic Multimodal
Fusion (SMF). The framework employs modality-specific encoders to process
different types of inputs, including street view imagery, remote sensing data,
cartographic maps, and points of interest (POIs) data. These multimodal inputs
are integrated via a Transformer-based fusion module that learns unified
representations. An extensive evaluation across 41 tasks in 56 cities worldwide
demonstrates UrbanFusion's strong generalization and predictive performance
compared to state-of-the-art GeoAI models. Specifically, it 1) outperforms
prior foundation models on location-encoding, 2) allows multimodal input during
inference, and 3) generalizes well to regions unseen during training.
UrbanFusion can flexibly utilize any subset of available modalities for a given
location during both pretraining and inference, enabling broad applicability
across diverse data availability scenarios. All source code is available at
https://github.com/DominikM198/UrbanFusion.

</details>


### [450] [The Art of Scaling Reinforcement Learning Compute for LLMs](https://arxiv.org/abs/2510.13786)
*Devvrit Khatri,Lovish Madaan,Rishabh Tiwari,Rachit Bansal,Sai Surya Duvvuri,Manzil Zaheer,Inderjit S. Dhillon,David Brandfonbrener,Rishabh Agarwal*

Main category: cs.LG

TL;DR: 该研究提出了一个用于分析和预测大型语言模型（LLM）中强化学习（RL）扩展的框架，并提供了一个名为ScaleRL的最佳实践配方，以提高RL训练的可预测性。


<details>
  <summary>Details</summary>
Motivation: 在LLM预训练领域已有成熟的预测性扩展方法，但在RL领域缺乏可比的方法，导致在不确定的情况下投入大量计算资源。本研究旨在解决这一问题，提供一种科学的分析框架和实用的方法来指导RL在LLM中的扩展。

Method: 进行了大规模（超过400,000 GPU小时）的系统性研究，拟合了RL训练的S型计算-性能曲线，并对常见的RL设计选择（如损失聚合、归一化、课程学习和离策略算法）进行了消融分析，以评估它们对最终性能和计算效率的影响。

Result: 研究发现：1. 并非所有RL配方都能达到相似的最终性能。2. 损失聚合、归一化、课程学习和离策略算法等细节主要影响计算效率，而非最终性能的上限。3. 稳定且可扩展的RL配方遵循可预测的扩展轨迹，可以从小规模实验进行推断。基于这些发现，研究提出了ScaleRL配方，并在单次扩展到100,000 GPU小时的RL运行中验证了其有效性。

Conclusion: 本研究为分析LLM中的RL扩展提供了科学框架，并提出了ScaleRL这一实践配方，使得RL训练的可预测性接近于预训练领域长期以来达到的水平。

Abstract: Reinforcement learning (RL) has become central to training large language
models (LLMs), yet the field lacks predictive scaling methodologies comparable
to those established for pre-training. Despite rapidly rising compute budgets,
there is no principled understanding of how to evaluate algorithmic
improvements for scaling RL compute. We present the first large-scale
systematic study, amounting to more than 400,000 GPU-hours, that defines a
principled framework for analyzing and predicting RL scaling in LLMs. We fit
sigmoidal compute-performance curves for RL training and ablate a wide range of
common design choices to analyze their effects on asymptotic performance and
compute efficiency. We observe: (1) Not all recipes yield similar asymptotic
performance, (2) Details such as loss aggregation, normalization, curriculum,
and off-policy algorithm primarily modulate compute efficiency without
materially shifting the asymptote, and (3) Stable, scalable recipes follow
predictable scaling trajectories, enabling extrapolation from smaller-scale
runs. Combining these insights, we propose a best-practice recipe, ScaleRL, and
demonstrate its effectiveness by successfully scaling and predicting validation
performance on a single RL run scaled up to 100,000 GPU-hours. Our work
provides both a scientific framework for analyzing scaling in RL and a
practical recipe that brings RL training closer to the predictability long
achieved in pre-training.

</details>


### [451] [Provably Invincible Adversarial Attacks on Reinforcement Learning Systems: A Rate-Distortion Information-Theoretic Approach](https://arxiv.org/abs/2510.13792)
*Ziqing Lu,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 本文提出了一种“不可战胜”或“无法反击”的对抗性强化学习攻击方法，利用信息论中的率失真理论，随机改变智能体对环境的观测，使其难以学习真实的环境模型，并推导了该攻击对智能体奖励的下界。


<details>
  <summary>Details</summary>
Motivation: 研究针对强化学习（RL）系统的对抗性攻击方法，以提高RL系统的鲁棒性和防御能力，特别是针对以往确定性攻击方法易被反制的缺点。

Method: 利用率失真信息论方法，随机改变智能体对状态转移模型（或其他属性）的观测，使其在训练过程中几乎无法获得关于真实模型的信息。

Result: 推导了该率失真攻击对智能体奖励损失的理论下界，并展示了该攻击对现有基于模型和无模型强化学习算法的影响。同时，将该信息论方法扩展到其他类型的攻击，如状态观测攻击。

Conclusion: 提出的率失真攻击是一种有效的、难以被反制的对抗性攻击方法，对理解和防御强化学习系统中的对抗性攻击具有重要意义。

Abstract: Reinforcement learning (RL) for the Markov Decision Process (MDP) has emerged
in many security-related applications, such as autonomous driving, financial
decisions, and drone/robot algorithms. In order to improve the
robustness/defense of RL systems against adversaries, studying various
adversarial attacks on RL systems is very important. Most previous work
considered deterministic adversarial attack strategies in MDP, which the
recipient (victim) agent can defeat by reversing the deterministic attacks. In
this paper, we propose a provably ``invincible'' or ``uncounterable'' type of
adversarial attack on RL. The attackers apply a rate-distortion
information-theoretic approach to randomly change agents' observations of the
transition kernel (or other properties) so that the agent gains zero or very
limited information about the ground-truth kernel (or other properties) during
the training. We derive an information-theoretic lower bound on the recipient
agent's reward regret and show the impact of rate-distortion attacks on
state-of-the-art model-based and model-free algorithms. We also extend this
notion of an information-theoretic approach to other types of adversarial
attack, such as state observation attacks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [452] [A faster algorithm for efficient longest common substring calculation for non-parametric entropy estimation in sequential data](https://arxiv.org/abs/2510.13330)
*Bridget Smart,Max Ward,Matthew Roughan*

Main category: cs.DS

TL;DR: LCSFinder算法将最长公共子串计算的最坏情况性能从三次提高到对数线性时间，从而实现了以前在实际信号处理中不可行的熵估计。


<details>
  <summary>Details</summary>
Motivation: 估计序列数据的非参数熵是信号处理中的一个基本工具，它测量可预测性、冗余度或相似性，但基于最长公共子串（LCS）的方法效率低下，限制了其在实际数据上的应用。

Method: 提出了一种名为LCSFinder的新算法，该算法利用排序后缀数组和持久二叉搜索树，将最长公共子串（LCS）计算的最坏情况性能从三次提高到对数线性时间，并解决了在动态增长序列上进行熵估计的匹配细节问题。

Result: LCSFinder在真实和模拟数据上实现了比现有实现快得多的速度，使得在实际信号处理中以前不可行的规模进行熵估计成为可能。

Conclusion: LCSFinder算法通过提高最长公共子串计算的效率，显著改善了序列数据的非参数熵估计，为信号处理中的实际应用开辟了新的可能性。

Abstract: Non-parametric entropy estimation on sequential data is a fundamental tool in
signal processing, capturing information flow within or between processes to
measure predictability, redundancy, or similarity. Methods based on longest
common substrings (LCS) provide a non-parametric estimate of typical set size
but are often inefficient, limiting use on real-world data. We introduce
LCSFinder, a new algorithm that improves the worst-case performance of LCS
calculations from cubic to log-linear time. Although built on standard
algorithmic constructs - including sorted suffix arrays and persistent binary
search trees - the details require care to provide the matches required for
entropy estimation on dynamically growing sequences. We demonstrate that
LCSFinder achieves dramatic speedups over existing implementations on real and
simulated data, enabling entropy estimation at scales previously infeasible in
practical signal processing.

</details>


### [453] [Tight Parameterized (In)tractability of Layered Crossing Minimization: Subexponential Algorithms and Kernelization](https://arxiv.org/abs/2510.13335)
*Fedor V. Fomin,Petr A. Golovach,Tanmay Inamdar,Saket Saurabh,Meirav Zehavi*

Main category: cs.DS

TL;DR: 该论文解决了2层和3层交叉最小化问题的参数化复杂性，并针对4层及以上的问题给出了下界。


<details>
  <summary>Details</summary>
Motivation: 该工作旨在解决图论中一个长达十年的关于2层交叉最小化问题的开放性问题，并进一步探索该问题在更多层数下的参数化复杂性。

Method: 通过设计参数化算法来解决2层和3层交叉最小化问题。对于2层问题，算法复杂度为 $2^{O(\sqrt{k}\log k)} + n \cdot k^{O(1)}$。对于3层问题，算法复杂度为 $2^{O(k^{2/3}\log k)} + n \cdot k^{O(1)}$。此外，还研究了问题的多项式核化。

Result: 1. 提出了第一个2层交叉最小化问题的亚指数时间固定参数算法。 2. 提出了第一个3层交叉最小化问题的亚指数时间固定参数算法。 3. 证明了对于所有 $h \ge 5$ 层，不存在一个子指数时间算法，除非指数时间假设失败。 4. 为3层问题设计了一个多项式核，并排除了 $h \ge 4$ 层存在多项式核的可能性，除非多项式层级崩溃。

Conclusion: 该研究在2层和3层交叉最小化问题上取得了突破性进展，提供了高效的固定参数算法和多项式核。同时，也揭示了问题在更多层数下的计算复杂性限制。

Abstract: The starting point of our work is a decade-old open question concerning the
subexponential parameterized complexity of \textsc{2-Layer Crossing
Minimization}. In this problem, the input is an $n$-vertex graph $G$ whose
vertices are partitioned into two independent sets $V_1$ and $V_2$, and a
non-negative integer $k$. The question is whether $G$ admits a 2-layered
drawing with at most $k$ crossings, where each $V_i$ lies on a distinct line
parallel to the $x$-axis, and all edges are straight lines. We resolve this
open question by giving the first subexponential fixed-parameter algorithm for
this problem, running in time $2^{O(\sqrt{k}\log k)} + n \cdot k^{O(1)}$.
  We then ask whether the subexponential phenomenon extends beyond two layers.
In the general $h$-Layer Crossing Minimization problem, the vertex set is
partitioned into $h$ independent sets $V_1, \ldots, V_h$, and the goal is to
decide whether an $h$-layered drawing with at most $k$ crossings exists. We
present a subexponential FPT algorithm for three layers with running time
$2^{O(k^{2/3}\log k)} + n \cdot k^{O(1)}$ for $h = 3$ layers. In contrast, we
show that for all $h \ge 5$, no algorithm with running time $2^{o(k/\log k)}
\cdot n^{O(1)}$ exists unless the Exponential-Time Hypothesis fails.
  Finally, we address polynomial kernelization. While a polynomial kernel was
already known for $h=2$, we design a new polynomial kernel for $h=3$. These
kernels are essential ingredients in our subexponential algorithms. Finally, we
rule out polynomial kernels for all $h \ge 4$ unless the polynomial hierarchy
collapses.

</details>


### [454] [Chromatic correlation clustering via cluster LP](https://arxiv.org/abs/2510.13446)
*Fateme Abbasi,Hyung-Chan An,Jarosław Byrka,Changyeol Lee,Yongho Shin*

Main category: cs.DS

TL;DR: 该论文提出了一种使用染色簇线性规划（chromatic cluster LP）来解决染色相关聚类（Chromatic Correlation Clustering）问题的 $(2+\varepsilon)$ 近似算法。


<details>
  <summary>Details</summary>
Motivation: 在相关聚类（Correlation Clustering）问题上，簇线性规划（cluster LP）已被证明是有效的。本研究旨在探索是否可以将簇线性规划推广到染色相关聚类问题，并给出肯定的答案。

Method: 提出了一种基于染色簇线性规划（chromatic cluster LP）的算法。

Result: 该算法在染色相关聚类问题上达到了 $(2+\varepsilon)$ 的近似比。

Conclusion: 染色簇线性规划可以成功应用于染色相关聚类问题，并能获得优于先前算法的近似比。

Abstract: Correlation Clustering is a fundamental clustering problem, and there has
been a line of work on improving the approximation ratio for this problem in
recent years. A key algorithmic component in these works is the cluster LP.
Chromatic Correlation Clustering is an interesting generalization that has also
been intensively studied. In light of success of the cluster LP in Correlation
Clustering, it would be an interesting question whether the cluster LP can be
used in Chromatic Correlation Clustering. We answer this question with
affirmatives by presenting a $(2+\varepsilon)$-approximation algorithm for
Chromatic Correlation Clustering using a chromatic cluster LP.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [455] [Dynamical breaking of inversion symmetry and strong second harmonic generation with nonlinear phonons](https://arxiv.org/abs/2510.12990)
*Egor I. Kiselev*

Main category: cond-mat.mes-hall

TL;DR: 通过光学声子动态打破晶体反演对称性，导致非线性效应和第二谐波生成。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索光学声子如何动态打破晶体反演对称性，以及由此产生的非线性效应。

Method: 通过驱动接近声子共振频率的一半来激发参量不稳定性，以打破对称性。

Result: 在对称性被打破的状态下，系统会达到一个稳态，其中包含反演对称性被打破的声子轨迹，并产生强烈的第二谐波信号。原子在稳态下的时间平均位置相对于平衡位置发生位移，从而实现驱动信号的整流。

Conclusion: 动态打破晶体反演对称性可以通过光学声子和非线性效应实现，并能产生第二谐波和信号整流等现象。

Abstract: We show how crystalline inversion symmetry can be dynamically broken by
optical phonons with generic, hardening Kerr-like non-linearities. The
symmetry-broken state is reached through a parametric instability that can be
accessed by driving close to half the phonon resonance. After the onset of the
instability, the system settles to a steady state with inversion-symmetry
breaking phonon trajectories and strong second harmonic generation. The time
averaged positions of the atoms are displaced relative to equilibrium in the
steady state, resulting in a rectification of the driving signal.

</details>


### [456] [High Stability Mechanical Frequency Sensing beyond the Linear Regime](https://arxiv.org/abs/2510.13041)
*Sofia C. Brown,Ravid Shaniv,Ruomu Zhang,Chris Reetz,Cindy A. Regal*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出一种在非线性状态下利用双谐振器模式来消除幅度噪声到频率噪声的转换，从而提高微机械传感器稳定性的方法。


<details>
  <summary>Details</summary>
Motivation: 为了理解和减小影响机械谐振器的频率噪声，特别是热机械噪声，并提出一种在非线性状态下避免幅度噪声到频率噪声转换的方法。

Method: 利用双机械模式操作，结合对Duffing系数的了解和幅度测量，来消除相关的单模频率漂移，从而在非线性状态下观察并减小幅度噪声到频率噪声的转换。

Result: 成功地在非线性（Duffing）区域观察到幅度噪声到频率噪声的转换，并利用提出的方法减小了这种转换，实现了高稳定性操作。

Conclusion: 提出的方法可以在非线性状态下实现比以往更稳定的传感器操作，解决了长期存在的该领域的技术难题。

Abstract: Sensing via a mechanical frequency shift is a powerful measurement tool, and,
therefore, understanding and mitigating frequency noise affecting mechanical
resonators is imperative. Thermomechanical noise fundamentally limits
mechanical frequency stability, and its impact can be reduced with increased
coherent amplitude of mechanical motion. However, large enough actuation places
the resonator in the nonlinear (Duffing) regime, where conversion of amplitude
noise (AM) into frequency noise (FM) can worsen sensor performance. Here, we
present an experimentally straightforward method to evade this amplitude
tradeoff in micromechanical sensors. Combining knowledge of the Duffing
coefficients with readily available amplitude measurements, we avoid AM-FM
conversion. Our approach uses dual-mechanical-mode operation on a tensioned
thin-film resonator to set a baseline thermomechanically-limited stability by
eliminating correlated single-mode frequency drifts. Thus, we cleanly observe
AM-FM conversion at high drive, and reduce it using our method. The resulting
high-stability operation beyond the linear regime contrasts long-standing
perspectives in the field.

</details>


### [457] [Spin-Selective Second-Order Topological Insulators Enabling Cornertronics in 2D Altermagnets](https://arxiv.org/abs/2510.13319)
*Ning-Jing Yang,Zhigao Huang,Jian-Min Zhang*

Main category: cond-mat.mes-hall

TL;DR: 通过引入应变打破Mxy对称性，在二维反常磁体中实现了产生第二类拓扑边缘态的自旋角锁定机制，并识别出两种具有该特性的实验候选材料CrO和Cr2Se2O。


<details>
  <summary>Details</summary>
Motivation: 探索反常磁体在下一代电子器件设计中的新应用，特别是利用其特性实现第二类拓扑现象。

Method: 通过有效模型分析和第一性原理计算，建立了自旋角锁定机制，并识别了具有CPSOTI特性的材料。

Result: 发现了自旋角锁定机制可以产生第二类拓扑态，并在CrO和Cr2Se2O中得到了验证。在临界应变以上，系统会发生拓扑相变，进入量子反常霍尔绝缘体相。还预测了CrO中存在反常磁性外尔半金属相。

Conclusion: 该研究发现了反常磁体中实现第二类拓扑态的新途径，并识别了实验候选材料，为拓扑自旋电子学和角电子学的发展提供了新的机遇。

Abstract: Recent progress in spintronics within the paradigm of altermagnets (AMs)
opens new avenues for next-generation electronic device design. Here, we
establish a spin-corner locking mechanism that generates second-order
topological states in two-dimensional (2D) altermagnetic systems, through
effective model analysis. Remarkably, the breaking of Mxy symmetry under
uniaxial strain creates spin-resolved corner modes, driving the system into a
corner-polarized second-order topological insulator (CPSOTI). Beyond critical
strain, a topological phase transition to quantum anomalous Hall insulator
occurs with quantized conductance. Through first-principles calculations, we
identify two experimentally viable candidates for 2D intrinsic AM CrO and
Cr$_2$Se$_2$O -- which host robust CPSOTI. Moreover, we construct the
topological phase diagram of CrO and predict the existence of an altermagnetic
Weyl semimetal phase. Our findings open technological avenues in altermagnetism
and higher-order topology, while providing opportunities for coupling
topological spintronics with cornertronics.

</details>


### [458] [Hybrid light-matter boundaries of graphene in a chiral cavity](https://arxiv.org/abs/2510.13373)
*Volker Karle,Oriana K. Diessel,Vasil Rokaj,Ceren B. Dağ*

Main category: cond-mat.mes-hall

TL;DR: 手性光腔与二维材料的相干耦合，无需外部驱动即可重塑电子拓扑。


<details>
  <summary>Details</summary>
Motivation: 探索手性光腔与石墨烯耦合的保真度-边界对应关系。

Method: 结合使用锯齿形纳米带的精确对角化（ED）、半解析T矩阵和狄拉克-杰恩斯-卡明斯模型的解析分析。

Result: 1.每个光-物质相互作用诱导的能隙都包含一对单向的、依赖于陈数的轻物质边缘电流，其中一些是明亮的；2.这些手性态存在于整个光子阶梯中；3.其色散、局域长度和光子分布表现出由光-物质相互作用控制的普适标度律。时间演化模拟表明，暗电子边缘激发可以转化为明亮的、单向传播的电流，并保持长期的相干性。

Conclusion: 研究结果预示了混合能带拓扑的实验特征，并为下一代量子光学器件的可重构手性通道提供了蓝图。

Abstract: Recent advances in chiral cavities that can couple coherently to
two-dimensional materials have opened a powerful route to reshape electronic
topology without an external drive. Here we establish the bulk-boundary
correspondence for graphene embedded in a circularly polarized cavity. By
combining exact diagonalization (ED) of zigzag ribbons, a semi-analytic
T-matrix for half-infinite lattices, and analytical insights from a
Dirac-Jaynes-Cummings model, we show that (i) every light-matter
interaction-induced gap hosts pairs of unidirectional light-matter edge
currents depending on the Chern number of the band while some of them are even
bright; (ii) these chiral states persist throughout the entire photon ladder;
and (iii) their dispersion, localization length and photon distribution exhibit
a universal scaling controlled by the light-matter interaction. Time-evolution
simulations further demonstrate that a dark electronic edge excitation can be
converted into a bright and unidirectionally propagating current, that remains
coherent over long time scales. Our results predict an experimental signature
of the hybrid band topology and a blueprint for reconfigurable chiral channels
in next-generation quantum-optical devices.

</details>


### [459] [Magnetically controllable nonlinear valley Hall effect in centrosymmetric ferromagnets](https://arxiv.org/abs/2510.13457)
*Ruijing Fang,Jie Zhang,Zhichao Zhou,Xiao Li*

Main category: cond-mat.mes-hall

TL;DR: 在具有反转对称性的铁磁材料中，通过调整磁化方向，可以实现可控的非线性霍尔效应，从而产生具有不同方向和自旋极化的自旋极化谷流。这为基于铁磁材料的谷电子学和自旋电子学器件提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 现有研究的非线性谷霍尔效应（NVH）受限于非磁性材料且需要外加应变来破坏旋转对称性。本研究旨在解决这些局限性，在具有反转对称性的铁磁材料中设计一种磁可控的NVH效应。

Method: 利用紧束缚模型和第一性原理计算。

Result: 模型计算表明，在没有外加应变的情况下，原始的六方晶格可以产生非零的NVH电导率。电导率的大小、符号和自旋极化均取决于磁化方向。第一性原理计算证实了铁磁VSi2N4双层中存在相当大的NVH电导率，并且其数值取决于磁化强度。

Conclusion: 磁可控的NVH效应使得具有反转对称性的磁性材料在谷电子学领域具有潜力，并为新型自旋电子学和谷电子学器件提供了机会。

Abstract: Valley Hall effect is fundamental to valleytronics and provides a promising
avenue for advancing information technology. While conventional valley Hall
effect requires the inversion symmetry breaking, the recently proposed
nonlinear valley Hall (NVH) effect removes the symmetry constraint, and broaden
material choices. However, existing studies are limited to nonmagnetic
materials without spin involvement and rely on external strain to break
rotational symmetry. Here, to address these limitations, we design a
magnetically controllable NVH effect in centrosymmetric ferromagnets, by the
tight-binding model and first-principles calculations. The model calculations
demonstrate nonvanishing NVH conductivities can emerge in pristine hexagonal
lattice without external strain, with the magnitude, sign, and spin
polarization of the conductivities being all dependent on the magnetization
orientation. The effect thus generates various spin-polarized valley Hall
currents, characterized by distinct combinations of current direction and spin
polarization. First-principle results on a ferromagnetic VSi$_2$N$_4$ bilayer
confirm considerable NVH conductivities and their dependence on the
magnetization. The magnetically controllable NVH effect unlocks the potential
of centrosymmetric magnets for valleytronics, and offer opportunities for novel
spintronic and valleytronic devices.

</details>


### [460] [Buckling and flat bands in twisted bilayer graphene](https://arxiv.org/abs/2510.13471)
*Jannes van Poppelen,Annica M. Black-Schaffer*

Main category: cond-mat.mes-hall

TL;DR: 周期性形变的扭转双层石墨烯的能带展宽


<details>
  <summary>Details</summary>
Motivation: 研究形变和扭转对双层石墨烯能带的影响

Method: 通过理论计算研究周期性形变和扭转角度对双层石墨烯能带的影响

Result: 周期性形变在特定条件下能展宽能带，同时形变和扭转的能带展平效应存在竞争关系，但形变双层石墨烯在较宽的扭转角范围内能带展平效果优于普通双层石墨烯。

Conclusion: 周期性形变双层石墨烯是实现展宽能带的可行方案。

Abstract: Magic-angle twisted bilayer graphene (TBG) with its flat bands provides a
rich platform for exploring emergent electronic orders. Similarly, periodically
buckled monolayer graphene has been proposed as a tunable alternative for
realizing flat bands. Here, we investigate the combined effect of buckling and
twisting in bilayer graphene. We find that periodic buckling in large-angle TBG
initially enhances band flattening compared to monolayer graphene, but for
sufficiently strong buckling, it instead increases the band dispersion. This
occurs both because of the presence of interlayer coupling, which reduces the
in-plane kinetic energy, and due to the opening of a gap at the Dirac point
resulting from inversion-symmetry breaking. Additionally, we find that
buckling-induced band flattening competes with twist-induced band flattening.
While the former breaks sublattice symmetry, generating a sublattice
polarization, the latter prefers to preserve it. This prevents buckling from
generating even flatter bands at the magic angle. Nevertheless, we find that
buckled TBG can exhibit flatter bands than pristine TBG over a wide range of
twist angles, with a flatness similar to that of pristine magic-angle TBG.

</details>


### [461] [Statistical Structure of Charge Disorder in Si/SiGe Quantum Dots](https://arxiv.org/abs/2510.13578)
*Saeed Samadi,Łukasz Cywiński,Jan A. Krzywda*

Main category: cond-mat.mes-hall

TL;DR: 量子点自旋量子比特易受器件间差异性的影响，这主要归因于半导体纳米结构中存在的各种无序因素。特别是半导体-氧化物界面处的电荷无序会导致量子比特相互隧穿耦合和电子限制能量等关键属性发生不可预测但相关的涨落。本研究提出了一种系统性的方法来表征和缓解这些无序效应。通过对硅/硅锗双量子点的有限元建模，并模拟界面电荷陷阱的影响，生成了包含大量统计数据的器件集。研究结果是一个能够为机器学习算法生成真实人工数据的预测模型。通过对该数据集应用主成分分析，识别出无序影响设备参数空间的主要模式，发现参数变化并非任意，而是集中在少数几个主轴上，表明器件的许多属性之间存在显著相关性。最后，将这些结果与通过栅极电压扫描产生的控制模式进行比较，揭示了仅使用加料器控制的局限性。本研究为通过系统性地解决导致双量子比特属性统计相关性的静电无序性质，来增强自旋量子比特器件的可控性和运行产率提供了一个框架。


<details>
  <summary>Details</summary>
Motivation: 量子点自旋量子比特器件的性能受到器件间差异性的严重影响，而这种差异性很大程度上源于半导体纳米结构中的无序性，特别是半导体-氧化物界面的电荷无序，它导致了量子比特相互隧穿耦合和电子限制能量等关键属性发生不可预测但相关的涨落。

Method: 利用有限元建模对硅/硅锗双量子点进行模拟，生成包含大量统计数据的器件集，以模拟界面电荷陷阱的影响。然后，应用主成分分析（PCA）来识别无序影响设备参数空间的主要模式，并将结果与通过栅极电压扫描产生的控制模式进行比较。

Result: 生成了一个预测性的统计模型，能够为机器学习算法生成真实的、包含统计相关性的双量子比特属性的人工数据。PCA分析表明，器件参数的变化并非随机，而是集中在少数几个主轴上，揭示了器件属性之间的显著相关性。此外，研究还指出了仅使用加料器控制的局限性。

Conclusion: 本研究提供了一个系统性的框架，通过解决导致双量子比特属性统计相关性的静电无序问题，来增强自旋量子比特器件的可控性和运行产率。

Abstract: Properties of quantum dot based spin qubits have significant inter-device
variability due to unavoidable presence of various types of disorder in
semiconductor nanostructures. A significant source of this variability is
charge disorder at the semiconductor-oxide interface, which causes
unpredictable, yet, as we show here, correlated fluctuations in such essential
properties of quantum dots like their mutual tunnel couplings, and electronic
confinement energies. This study presents a systematic approach to characterize
and mitigate the effects of such disorder. We utilize finite element modeling
of a Si/SiGe double quantum dot to generate a large statistical ensemble of
devices, simulating the impact of trapped interface charges. This work results
in a predictive statistical model capable of generating realistic artificial
data for training machine learning algorithms. By applying Principal Component
Analysis to this dataset, we identify the dominant modes through which disorder
affects the multi-dimensional parameter space of the device. Our findings show
that the parameter variations are not arbitrary, but are concentrated along a
few principal axes - i.e.there are significant correlations between many
properties of the devices.
  We finally compare that against control modes generated by sweeping the gate
voltages, revealing limitations of the plunger-only control. This work provides
a framework for enhancing the controllability and operational yield of spin
qubit devices, by systematically addressing the nature of electrostatic
disorder that leads to statistical correlations in properties of double quantum
dots.

</details>


### [462] [Momentum-Resolved Spectroscopy of Superconductivity with the Quantum Twisting Microscope](https://arxiv.org/abs/2510.13641)
*Yuval Waschitz,Ady Stern,Yuval Oreg*

Main category: cond-mat.mes-hall

TL;DR: 量子扭曲显微镜(QTM)可以直接测量二维材料中的超导性，具有动量分辨率，揭示配对幅度和对称性。


<details>
  <summary>Details</summary>
Motivation: 开发一种具有动量分辨率的量子扭曲显微镜（QTM）理论框架，以探测超导性，直接测量超导谱函数，并揭示配对幅度和对称性的动量依赖性。

Method: 利用量子扭曲显微镜（QTM），一种平面隧穿器件，其中石墨烯尖端相对于二维样品旋转。利用其三个C3z相关的隧穿通道，直接探测旋转对称性破缺和超导序参数中的节点。

Result: 该框架能够测量超导谱函数，揭示 Bogoliubov 相干因子，从而了解配对幅度的动量依赖性，并检测旋转对称性破缺和节点。

Conclusion: QTM 可作为探测二维材料中配对对称性和超导微观起源的直接工具。

Abstract: We develop a theoretical framework for probing superconductivity with
momentum resolution using the quantum twisting microscope (QTM), a planar
tunneling device where a graphene tip is rotated relative to a two-dimensional
sample. Due to in-plane momentum conservation, the QTM directly measures the
superconducting spectral function along well-defined trajectories in momentum
space. The relative intensities of electron and hole excitations encode the
Bogoliubov coherence factors, revealing the momentum dependence of the pairing
magnitude. Three $C_{3z}$-related tunneling channels enable direct detection of
rotational symmetry breaking, as well as nodal points in the superconducting
order parameter. We apply our framework to superconductivity within the
Bistritzer-MacDonald model of noninteracting electrons and the Topological
Heavy Fermion model, which accounts for electron-electron interactions.
Together, these capabilities establish the QTM as a direct probe of the pairing
symmetry and microscopic origin of superconductivity in two-dimensional
materials.

</details>


### [463] [Excitonic optical absorption in strained monolayer CrSBr](https://arxiv.org/abs/2510.13646)
*Maurício F. C. Martins Quintela,Guilherme J. Inacio,Miguel Sá,Giovanni Cistaro,Alberto M. Ruiz,José J. Baldoví,Juan J. Palacios,Antonio Picón*

Main category: cond-mat.mes-hall

TL;DR: CrSBr是一种具有高居里温度、高各向异性和高结构稳定性的2D磁性材料，其变形能力和强光学响应使其在探索磁性和光学激发之间相互作用方面具有潜力。本研究关注CrSBr在不同应变下的理论光学响应，分析应变对其激子峰和线性电导率张量对角分量形状的影响。


<details>
  <summary>Details</summary>
Motivation: CrSBr材料独特的磁性和光学性质，以及其在自旋电子学领域的潜在应用，促使我们去探索应变对其光学特性的调控作用。

Method: 通过理论计算，分析CrSBr在不同应变构型下的光学响应，重点研究应变对激子峰和线性电导率张量对角分量的影响。

Result: 研究结果展示了应变如何改变CrSBr的光学响应，包括激子峰的位置和强度的变化，以及线性电导率张量对角分量形状的改变。

Conclusion: CrSBr对外界应变敏感，应变可以有效调控其光学性质，为设计基于CrSBr的自旋电子器件提供了理论依据。

Abstract: Recently, the isolation of 2D magnetic materials has opened several avenues
for possible new ap- plications in spintronics. Among these materials, CrSBr
has sparked interest due to its relatively high Curie temperature, highly
anisotropic lattice structure, and high structural stability. These properties
ran along others shared by any atomically thin material such as its outstanding
defor- mation capacity and a strong optical response dominated by excitonic
effects. The combination of these properties provides a fairly uncharted
playground where to explore the interplay between magnetism and optical
excitations. Here, we focus our attention on the theoretical optical response
of CrSBr under several distinct strain configurations, analyzing the resulting
changes to both the excitonic peaks and overall shape of the diagonal
components of the linear conductivity tensor.

</details>


### [464] [Optical Response of Graphene Quantum Dots in the Visible Spectrum: A Combined DFT-QED Approach](https://arxiv.org/abs/2510.13769)
*J. Olivo,J. Blengino Albrieu,Mauro Cuevas*

Main category: cond-mat.mes-hall

TL;DR: We use DFT and QED to model graphene quantum dots, matching experimental results.


<details>
  <summary>Details</summary>
Motivation: To study the dynamical characteristics of graphene quantum dots (GQDs).

Method: We propose a model based on density functional theory (DFT) and quantum electrodynamics (QED), treating GQDs as polycyclic aromatic hydrocarbons (PAHs). We combine the GQD spectrum from time-dependent DFT (TDDFT) with the dynamical behavior of a QD model from QED to calculate optical characteristics.

Result: Calculated transition frequencies, dipole moments, lifetimes, and population dynamics of molecular levels, showing a close match between the calculated spectrum and experimental results.

Conclusion: The results represent a significant contribution to research on quantum treatments of light-matter interactions in realistic 2D nanomaterials.

Abstract: We propose a model based on density functional theory (DFT) and quantum
electrodynamics (QED) to study the dynamical characteristics of graphene
quantum dots (GQDs). We assume the GQD edges are saturated with hydrogen atoms,
effectively making it a polycyclic aromatic hydrocarbon (PAH) such as coronene.
By combining the GQD spectrum calculated from a time-dependent DFT (TDDFT) with
the dynamical behavior of a QD model derived from QED, we calculate the main
optical characteristics of the GQD, such as its transition frequencies, the
dipole moment associated to each of those transitions, life-time and the
population dynamics of the molecular levels. Owing to the close match between
the calculated spectrum and experimental results, our results represent a
significant contribution to research on quantum treatments of light-matter
interactions in realistic 2D nanomaterials.

</details>
