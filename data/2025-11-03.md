<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 80]
- [cs.CL](#cs.CL) [Total: 47]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 9]
- [quant-ph](#quant-ph) [Total: 31]
- [eess.SP](#eess.SP) [Total: 17]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.DC](#cs.DC) [Total: 7]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [cs.SI](#cs.SI) [Total: 8]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.AI](#cs.AI) [Total: 30]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Deep Neural Watermarking for Robust Copyright Protection in 3D Point Clouds](https://arxiv.org/abs/2510.27533)
*Khandoker Ashik Uz Zaman,Mohammad Zahangir Alam,Mohammed N. M. Ali,Mahdi H. Miraz*

Main category: cs.CV

TL;DR: 提出了一种用于3D点云的鲁棒深度神经水印框架，以解决数字内容领域知识产权保护的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于3D点云内容易受几何和非几何攻击，传统的版权保护方法难以有效保护其知识产权。

Method: 使用SVD将水印嵌入3D点云块的奇异值中，并利用PointNet++神经网络架构提取水印。

Result: 所提出的方法在ModelNet40数据集上进行了验证，与传统SVD方法相比，在旋转、缩放、噪声、裁剪和信号失真等攻击下，深度学习提取方法的比特准确率最高可达0.83，IoU为0.80，显著优于SVD方法的比特准确率0.58和IoU 0.26（以70%裁剪攻击为例）。

Conclusion: 该深度学习驱动的水印方法在严峻的失真下能够实现卓越的水印恢复和高保真度，为3D点云的版权保护和所有权验证提供了有效解决方案。

Abstract: The protection of intellectual property has become critical due to the rapid
growth of three-dimensional content in digital media. Unlike traditional images
or videos, 3D point clouds present unique challenges for copyright enforcement,
as they are especially vulnerable to a range of geometric and non-geometric
attacks that can easily degrade or remove conventional watermark signals. In
this paper, we address these challenges by proposing a robust deep neural
watermarking framework for 3D point cloud copyright protection and ownership
verification. Our approach embeds binary watermarks into the singular values of
3D point cloud blocks using spectral decomposition, i.e. Singular Value
Decomposition (SVD), and leverages the extraction capabilities of Deep Learning
using PointNet++ neural network architecture. The network is trained to
reliably extract watermarks even after the data undergoes various attacks such
as rotation, scaling, noise, cropping and signal distortions. We validated our
method using the publicly available ModelNet40 dataset, demonstrating that deep
learning-based extraction significantly outperforms traditional SVD-based
techniques under challenging conditions. Our experimental evaluation
demonstrates that the deep learning-based extraction approach significantly
outperforms existing SVD-based methods with deep learning achieving bitwise
accuracy up to 0.83 and Intersection over Union (IoU) of 0.80, compared to SVD
achieving a bitwise accuracy of 0.58 and IoU of 0.26 for the Crop (70%) attack,
which is the most severe geometric distortion in our experiment. This
demonstrates our method's ability to achieve superior watermark recovery and
maintain high fidelity even under severe distortions.

</details>


### [2] [Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench](https://arxiv.org/abs/2510.26865)
*Fenfen Lin,Yesheng Liu,Haiyu Xu,Chen Yue,Zheqi He,Mingxuan Zhao,Miguel Hu Chen,Jiakang Liu,JG Yao,Xi Yang*

Main category: cs.CV

TL;DR: MeasureBench是一个用于评估视觉测量读数能力的基准，即使是顶尖的视觉语言模型（VLMs）在该任务上也表现不佳，尤其是在定位指示器方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 尽管人类阅读测量仪表很容易，但目前的视觉语言模型（VLMs）在处理这项任务时存在显著挑战。

Method: 提出MeasureBench基准，包含真实和合成图像，并开发了一个可扩展的数据合成流程，能够程序化生成具有可控外观（指针、刻度、字体、光照、杂乱度等）的仪表。

Result: 在流行的专有和开源VLMs上进行的评估显示，即使是强大的模型在测量读数方面也普遍存在困难。一个常见的失败模式是指示器定位不准确，导致尽管文本推理看似合理，但数值错误较大。在合成数据上进行的强化学习实验显示出一定的潜力，但在真实图像上的效果不佳。

Conclusion: 现有的VLMs在细粒度的空间定位方面存在根本性局限。MeasureBench旨在推动视觉基础数理能力和精确空间感知的发展，弥合识别数字与测量世界之间的差距。

Abstract: Reading measurement instruments is effortless for humans and requires
relatively little domain expertise, yet it remains surprisingly challenging for
current vision-language models (VLMs) as we find in preliminary evaluation. In
this work, we introduce MeasureBench, a benchmark on visual measurement reading
covering both real-world and synthesized images of various types of
measurements, along with an extensible pipeline for data synthesis. Our
pipeline procedurally generates a specified type of gauge with controllable
visual appearance, enabling scalable variation in key details such as pointers,
scales, fonts, lighting, and clutter. Evaluation on popular proprietary and
open-weight VLMs shows that even the strongest frontier VLMs struggle
measurement reading in general. A consistent failure mode is indicator
localization: models can read digits or labels but misidentify the key
positions of pointers or alignments, leading to big numeric errors despite
plausible textual reasoning. We have also conducted preliminary experiments
with reinforcement learning over synthetic data, and find encouraging results
on in-domain synthetic subset but less promising for real-world images. Our
analysis highlights a fundamental limitation of current VLMs in fine-grained
spatial grounding. We hope this resource can help future advances on visually
grounded numeracy and precise spatial perception of VLMs, bridging the gap
between recognizing numbers and measuring the world.

</details>


### [3] [PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT](https://arxiv.org/abs/2510.26903)
*Rochak Dhakal,Chen Zhao,Zixin Shi,Joyce H. Keyak,Tadashi S. Kaneko,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Weihua Zhou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantitative computed tomography (QCT) plays a crucial role in assessing bone
strength and fracture risk by enabling volumetric analysis of bone density
distribution in the proximal femur. However, deploying automated segmentation
models in practice remains difficult because deep networks trained on one
dataset often fail when applied to another. This failure stems from domain
shift, where scanners, reconstruction settings, and patient demographics vary
across institutions, leading to unstable predictions and unreliable
quantitative metrics. Overcoming this barrier is essential for multi-center
osteoporosis research and for ensuring that radiomics and structural finite
element analysis results remain reproducible across sites. In this work, we
developed a domain-adaptive transformer segmentation framework tailored for
multi-institutional QCT. Our model is trained and validated on one of the
largest hip fracture related research cohorts to date, comprising 1,024 QCT
images scans from Tulane University and 384 scans from Rochester, Minnesota for
proximal femur segmentation. To address domain shift, we integrate two
complementary strategies within a 3D TransUNet backbone: adversarial alignment
via Gradient Reversal Layer (GRL), which discourages the network from encoding
site-specific cues, and statistical alignment via Maximum Mean Discrepancy
(MMD), which explicitly reduces distributional mismatches between institutions.
This dual mechanism balances invariance and fine-grained alignment, enabling
scanner-agnostic feature learning while preserving anatomical detail.

</details>


### [4] [DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2510.26921)
*Moonsoo Jeong,Dongbeen Kim,Minseong Kim,Sungkil Lee*

Main category: cs.CV

TL;DR: DC4GS通过引入梯度方向的一致性（DC）来改进自适应密度控制（ADC），从而在3D高斯喷涂中减少原始数量并提高重建保真度。


<details>
  <summary>Details</summary>
Motivation: 传统的自适应密度控制（ADC）在3D高斯喷涂中仅基于位置梯度的幅度来分割原始元，这可能无法充分捕捉局部结构复杂性，导致冗余分割。作者提出了一种新的DC4GS方法，通过引入梯度的方向一致性（DC）来改进ADC，以更好地处理局部结构并优化分割位置。

Method: DC4GS在ADC中结合了梯度的方向一致性（DC），通过梯度的角度相干性来实现。DC能够更好地捕捉ADC中的局部结构复杂性，避免不必要的分割。当需要分割时，DC被用来定义最优分割位置，使子原始元更好地与局部结构对齐，而不是采用传统的随机放置。

Result: 与现有ADC方法相比，DC4GS大大减少了原始元的数量（实验中最多可减少30%），并显著提高了重建保真度。

Conclusion: DC4GS通过引入方向一致性（DC）来改进自适应密度控制（ADC），在3D高斯喷涂中实现了更有效的原始元数量减少和重建保真度提升。

Abstract: We present a Directional Consistency (DC)-driven Adaptive Density Control
(ADC) for 3D Gaussian Splatting (DC4GS). Whereas the conventional ADC bases its
primitive splitting on the magnitudes of positional gradients, we further
incorporate the DC of the gradients into ADC, and realize it through the
angular coherence of the gradients. Our DC better captures local structural
complexities in ADC, avoiding redundant splitting. When splitting is required,
we again utilize the DC to define optimal split positions so that
sub-primitives best align with the local structures than the conventional
random placement. As a consequence, our DC4GS greatly reduces the number of
primitives (up to 30% in our experiments) than the existing ADC, and also
enhances reconstruction fidelity greatly.

</details>


### [5] [Scale-Aware Curriculum Learning for Ddata-Efficient Lung Nodule Detection with YOLOv11](https://arxiv.org/abs/2510.26923)
*Yi Luo,Yike Guo,Hamed Hooshangnejad,Kai Ding*

Main category: cs.CV

TL;DR: SACL是一种动态调整课程设计的新型训练策略，通过自适应的时期调度、困难样本注入和感知尺度优化，在数据量有限的情况下提高了肺结节检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在临床环境中由于标注数据有限，在肺结节检测方面面临挑战，而传统的静态课程学习策略在数据稀疏的情况下效果不佳。

Method: 提出了一种名为SACL（Scale Adaptive Curriculum Learning）的新型训练策略，包含自适应时期调度、困难样本注入和感知尺度优化三个关键机制，该策略根据可用的数据量动态调整课程设计。

Result: 在LUNA25数据集上，SACL在mAP50方面与静态课程学习相当，但在数据有限的条件下（10%、20%和50%的训练数据）分别比基线提高了4.6%、3.5%和2.0%。

Conclusion: SACL在不进行架构修改的情况下，能够在不同的数据规模下进行稳健的训练，为医疗机构在标注资源有限的情况下开发有效的肺结节检测系统提供了一个实用的解决方案。

Abstract: Lung nodule detection in chest CT is crucial for early lung cancer diagnosis,
yet existing deep learning approaches face challenges when deployed in clinical
settings with limited annotated data. While curriculum learning has shown
promise in improving model training, traditional static curriculum strategies
fail in data-scarce scenarios. We propose Scale Adaptive Curriculum Learning
(SACL), a novel training strategy that dynamically adjusts curriculum design
based on available data scale. SACL introduces three key mechanisms:(1)
adaptive epoch scheduling, (2) hard sample injection, and (3) scale-aware
optimization. We evaluate SACL on the LUNA25 dataset using YOLOv11 as the base
detector. Experimental results demonstrate that while SACL achieves comparable
performance to static curriculum learning on the full dataset in mAP50, it
shows significant advantages under data-limited conditions with 4.6%, 3.5%, and
2.0% improvements over baseline at 10%, 20%, and 50% of training data
respectively. By enabling robust training across varying data scales without
architectural modifications, SACL provides a practical solution for healthcare
institutions to develop effective lung nodule detection systems despite limited
annotation resources.

</details>


### [6] [SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions](https://arxiv.org/abs/2510.26961)
*Md. Mehedi Hassan,Shafqat Alam,Shahriar Ahmed Seam,Maruf Ahmed*

Main category: cs.CV

TL;DR: SYNAPSE-Net是一个统一的多流自适应框架，用于分割多模态MRI中的脑部病变，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在泛化性和鲁棒性方面存在不足，限制了其在临床上的可靠性。

Method: 提出了一种名为SYNAPSE-Net的混合架构，集成了多流CNN编码器、Swin Transformer瓶颈、动态跨模态注意力融合（CMAF）机制和分层门控解码器。结合了病理学特定的数据增强和难例感知采样策略进行训练。

Result: 在WMH数据集上取得了0.831的DSC值和3.03的HD95值；在ISLES 2022数据集上取得了最佳的边界精度（9.69的HD95值）；在BraTS 2020数据集上，肿瘤核心区域的DSC值达到了0.8651。

Conclusion: SYNAPSE-Net框架在多个脑部病变分割任务上均取得了最先进的性能，证明了其泛化性、鲁棒性和临床可行性。

Abstract: Automated segmentation of heterogeneous brain lesions from multi-modal MRI
remains a critical challenge in clinical neuroimaging. Current deep learning
models are typically specialized `point solutions' that lack generalization and
high performance variance, limiting their clinical reliability. To address
these gaps, we propose the Unified Multi-Stream SYNAPSE-Net, an adaptive
framework designed for both generalization and robustness. The framework is
built on a novel hybrid architecture integrating multi-stream CNN encoders, a
Swin Transformer bottleneck for global context, a dynamic cross-modal attention
fusion (CMAF) mechanism, and a hierarchical gated decoder for high-fidelity
mask reconstruction. The architecture is trained with a variance reduction
strategy that combines pathology specific data augmentation and
difficulty-aware sampling method. The model was evaluated on three different
challenging public datasets: the MICCAI 2017 WMH Challenge, the ISLES 2022
Challenge, and the BraTS 2020 Challenge. Our framework attained a
state-of-the-art DSC value of 0.831 with the HD95 value of 3.03 in the WMH
dataset. For ISLES 2022, it achieved the best boundary accuracy with a
statistically significant difference (HD95 value of 9.69). For BraTS 2020, it
reached the highest DSC value for the tumor core region (0.8651). These
experimental findings suggest that our unified adaptive framework achieves
state-of-the-art performance across multiple brain pathologies, providing a
robust and clinically feasible solution for automated segmentation. The source
code and the pre-trained models are available at
https://github.com/mubid-01/SYNAPSE-Net-pre.

</details>


### [7] [Semantic Frame Aggregation-based Transformer for Live Video Comment Generation](https://arxiv.org/abs/2510.26978)
*Anam Fatima,Yi Yu,Janak Kapuriya,Julien Lalanne,Jainendra Shukla*

Main category: cs.CV

TL;DR: SFAT模型利用CLIP视觉-文本多模态知识，并通过加权视频帧来生成直播视频评论，解决了现有方法忽视视频帧相关性与对话上下文的问题。同时，构建了一个包含3.2M评论和438小时视频的大型多模态英文视频评论数据集。


<details>
  <summary>Details</summary>
Motivation: 现有直播视频评论生成方法忽略了对视频帧进行相关性排序，导致评论上下文不准确。

Method: 提出了一种名为SFAT（Semantic Frame Aggregation-based Transformer）的新模型，该模型利用CLIP的多模态知识，并通过加权视频帧来生成评论，同时使用跨注意机制确保评论同时考虑视频和聊天内容。此外，构建了一个新的英文视频评论数据集。

Result: SFAT模型在生成直播视频评论方面优于现有方法。

Conclusion: SFAT模型能够生成与视频内容和聊天上下文高度相关的直播视频评论，并且新数据集有助于该领域的研究。

Abstract: Live commenting on video streams has surged in popularity on platforms like
Twitch, enhancing viewer engagement through dynamic interactions. However,
automatically generating contextually appropriate comments remains a
challenging and exciting task. Video streams can contain a vast amount of data
and extraneous content. Existing approaches tend to overlook an important
aspect of prioritizing video frames that are most relevant to ongoing viewer
interactions. This prioritization is crucial for producing contextually
appropriate comments. To address this gap, we introduce a novel Semantic Frame
Aggregation-based Transformer (SFAT) model for live video comment generation.
This method not only leverages CLIP's visual-text multimodal knowledge to
generate comments but also assigns weights to video frames based on their
semantic relevance to ongoing viewer conversation. It employs an efficient
weighted sum of frames technique to emphasize informative frames while focusing
less on irrelevant ones. Finally, our comment decoder with a cross-attention
mechanism that attends to each modality ensures that the generated comment
reflects contextual cues from both chats and video. Furthermore, to address the
limitations of existing datasets, which predominantly focus on Chinese-language
content with limited video categories, we have constructed a large scale,
diverse, multimodal English video comments dataset. Extracted from Twitch, this
dataset covers 11 video categories, totaling 438 hours and 3.2 million
comments. We demonstrate the effectiveness of our SFAT model by comparing it to
existing methods for generating comments from live video and ongoing dialogue
contexts.

</details>


### [8] [MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation](https://arxiv.org/abs/2510.26996)
*Arghavan Rezvani,Xiangyi Yan,Anthony T. Wu,Kun Han,Pooya Khosravi,Xiaohui Xie*

Main category: cs.CV

TL;DR: MoME是一个医学图像分割模型，它将LLM中的专家混合（MoE）范式应用于医学视觉-语言任务，并使用多尺度视觉特征和文本嵌入来动态选择专家。


<details>
  <summary>Details</summary>
Motivation: 将专家混合（MoE）范式应用于医学视觉-语言任务，以提高医学图像分割的性能。

Method: MoME模型，一种视觉语言专家混合模型，利用多尺度视觉特征和文本嵌入来动态选择专家。

Result: 在10个数据集和3410个CT扫描上进行了评估，MoME在医学图像分割基准测试中表现出强大的性能和有竞争力的精度。

Conclusion: MoME是一个新颖的医学图像分割模型，它通过整合视觉语言基础模型和专家混合范式，为医学图像分析带来了稳健的结果。

Abstract: In this study, we propose MoME, a Mixture of Visual Language Medical Experts,
for Medical Image Segmentation. MoME adapts the successful Mixture of Experts
(MoE) paradigm, widely used in Large Language Models (LLMs), for medical
vision-language tasks. The architecture enables dynamic expert selection by
effectively utilizing multi-scale visual features tailored to the intricacies
of medical imagery, enriched with textual embeddings. This work explores a
novel integration of vision-language models for this domain. Utilizing an
assembly of 10 datasets, encompassing 3,410 CT scans, MoME demonstrates strong
performance on a comprehensive medical imaging segmentation benchmark. Our
approach explores the integration of foundation models for medical imaging,
benefiting from the established efficacy of MoE in boosting model performance
by incorporating textual information. Demonstrating competitive precision
across multiple datasets, MoME explores a novel architecture for achieving
robust results in medical image analysis.

</details>


### [9] [Incremental Human-Object Interaction Detection with Invariant Relation Representation Learning](https://arxiv.org/abs/2510.27020)
*Yana Wei,Zeen Chi,Chongyu Wang,Yu Wu,Shipeng Yan,Yongfei Liu,Xuming He*

Main category: cs.CV

TL;DR: 该研究提出了一种名为IRD的新型框架，用于解决开放世界环境中持续变化的 HOI 检测问题，该框架通过解耦物体和关系学习，并引入了两种独特的蒸馏损失来学习跨不同 HOI 组合的不变关系特征，以解决灾难性遗忘、交互漂移和零样本 HOI 检测等挑战。


<details>
  <summary>Details</summary>
Motivation: 开放世界环境中的人类-物体交互（HOI）是持续演变的，这对传统的封闭世界HOI检测模型构成了挑战。为了解决这个问题，本研究旨在开发能够识别动态环境中人类-物体关系的智能体。

Method: 提出了一种名为IRD（exemplar-free incremental relation distillation）的新型框架。IRD将物体和关系学习解耦，并引入了两种独特的蒸馏损失，用于学习在共享相同关系的不同HOI组合中保持不变的关系特征。

Result: 在HICO-DET和V-COCO数据集上的广泛实验表明，该方法在减轻遗忘、增强对交互漂移的鲁棒性以及泛化到零样本HOI方面优于最先进的方法。

Conclusion: 所提出的IRD框架能够有效地解决开放世界环境中持续变化的HOI检测问题，并在减轻遗忘、增强鲁棒性和泛化能力方面取得了显著成效。

Abstract: In open-world environments, human-object interactions (HOIs) evolve
continuously, challenging conventional closed-world HOI detection models.
Inspired by humans' ability to progressively acquire knowledge, we explore
incremental HOI detection (IHOID) to develop agents capable of discerning
human-object relations in such dynamic environments. This setup confronts not
only the common issue of catastrophic forgetting in incremental learning but
also distinct challenges posed by interaction drift and detecting zero-shot HOI
combinations with sequentially arriving data. Therefore, we propose a novel
exemplar-free incremental relation distillation (IRD) framework. IRD decouples
the learning of objects and relations, and introduces two unique distillation
losses for learning invariant relation features across different HOI
combinations that share the same relation. Extensive experiments on HICO-DET
and V-COCO datasets demonstrate the superiority of our method over
state-of-the-art baselines in mitigating forgetting, strengthening robustness
against interaction drift, and generalization on zero-shot HOIs. Code is
available at \href{https://github.com/weiyana/ContinualHOI}{this HTTP URL}

</details>


### [10] [A Hybrid Deep Learning and Forensic Approach for Robust Deepfake Detection](https://arxiv.org/abs/2510.27392)
*Sales Aribe Jr*

Main category: cs.CV

TL;DR: 现有的深度伪造检测方法要么依赖深度学习（泛化能力差，易受损），要么依赖取证分析（可解释但难以应对新技术）。本研究提出了一种混合框架，融合了取证特征（噪声残差、JPEG压缩痕迹、频域描述符）和深度学习表示（CNNs、ViTs），在基准数据集上表现优于现有方法，并能在压缩、对抗性扰动和未见过的篡改下保持稳定性能，同时通过可视化分析提高了透明度。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术（GANs、扩散模型）的快速发展引发了对错误信息、身份欺诈和数字信任的社会担忧，而现有的检测方法存在局限性。

Method: 提出一种混合框架，融合取证特征（噪声残差、JPEG压缩痕迹、频域描述符）和深度学习表示（CNNs、ViTs）。

Result: 在FaceForensics++、Celeb-DF v2、DFDC数据集上，F1分数分别为0.96、0.82、0.77，优于基线和现有混合方法。在压缩（QF=50时F1=0.87）、对抗性扰动（AUC=0.84）和未见过的篡改（F1=0.79）下表现稳定。Grad-CAM和取证热图与篡改区域重叠率为82%。

Conclusion: 混合方法结合了深度模型的适应性和取证线索的可解释性，是开发鲁棒且可信的深度伪造检测系统的平衡解决方案。

Abstract: The rapid evolution of generative adversarial networks (GANs) and diffusion
models has made synthetic media increasingly realistic, raising societal
concerns around misinformation, identity fraud, and digital trust. Existing
deepfake detection methods either rely on deep learning, which suffers from
poor generalization and vulnerability to distortions, or forensic analysis,
which is interpretable but limited against new manipulation techniques. This
study proposes a hybrid framework that fuses forensic features, including noise
residuals, JPEG compression traces, and frequency-domain descriptors, with deep
learning representations from convolutional neural networks (CNNs) and vision
transformers (ViTs). Evaluated on benchmark datasets (FaceForensics++, Celeb-DF
v2, DFDC), the proposed model consistently outperformed single-method baselines
and demonstrated superior performance compared to existing state-of-the-art
hybrid approaches, achieving F1-scores of 0.96, 0.82, and 0.77, respectively.
Robustness tests demonstrated stable performance under compression (F1 = 0.87
at QF = 50), adversarial perturbations (AUC = 0.84), and unseen manipulations
(F1 = 0.79). Importantly, explainability analysis showed that Grad-CAM and
forensic heatmaps overlapped with ground-truth manipulated regions in 82
percent of cases, enhancing transparency and user trust. These findings confirm
that hybrid approaches provide a balanced solution, combining the adaptability
of deep models with the interpretability of forensic cues, to develop resilient
and trustworthy deepfake detection systems.

</details>


### [11] [VitalLens 2.0: High-Fidelity rPPG for Heart Rate Variability Estimation from Face Video](https://arxiv.org/abs/2510.27028)
*Philipp V. Rouast*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This report introduces VitalLens 2.0, a new deep learning model for
estimating physiological signals from face video. This new model demonstrates a
significant leap in accuracy for remote photoplethysmography (rPPG), enabling
the robust estimation of not only heart rate (HR) and respiratory rate (RR) but
also Heart Rate Variability (HRV) metrics. This advance is achieved through a
combination of a new model architecture and a substantial increase in the size
and diversity of our training data, now totaling 1,413 unique individuals. We
evaluate VitalLens 2.0 on a new, combined test set of 422 unique individuals
from four public and private datasets. When averaging results by individual,
VitalLens 2.0 achieves a Mean Absolute Error (MAE) of 1.57 bpm for HR, 1.08 bpm
for RR, 10.18 ms for HRV-SDNN, and 16.45 ms for HRV-RMSSD. These results
represent a new state-of-the-art, significantly outperforming previous methods.
This model is now available to developers via the VitalLens API at
https://rouast.com/api.

</details>


### [12] [AD-SAM: Fine-Tuning the Segment Anything Vision Foundation Model for Autonomous Driving Perception](https://arxiv.org/abs/2510.27047)
*Mario Camarena,Het Patel,Fatemeh Nazari,Evangelos Papalexakis,Mohamadhossein Noruzoliaee,Jia Chen*

Main category: cs.CV

TL;DR: AD-SAM是一个针对自动驾驶场景优化的分割模型，在Cityscapes和BDD100K数据集上均取得了优于SAM、G-SAM和DeepLabV3的性能，并展示了良好的泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 为解决自动驾驶场景中道路分割的复杂性，需要一个在空间和几何上都更精细化的分割模型。

Method: AD-SAM在SAM模型基础上，引入了双编码器（融合全局语义和局部空间信息）和可变形解码器（进行多阶段精细化），并采用了混合损失函数进行训练。

Result: AD-SAM在Cityscapes和BDD100K上分别达到了68.1%和59.5%的mIoU，显著优于现有模型。模型还表现出良好的跨领域泛化能力（0.87保留分数）和高效的学习动态（30-40个epoch收敛），在仅有1000个样本时仍能达到0.607 mIoU。

Conclusion: 通过对基础模型进行针对性的架构和优化改进，可以实现可靠且可扩展的自动驾驶感知能力。

Abstract: This paper presents the Autonomous Driving Segment Anything Model (AD-SAM), a
fine-tuned vision foundation model for semantic segmentation in autonomous
driving (AD). AD-SAM extends the Segment Anything Model (SAM) with a
dual-encoder and deformable decoder tailored to spatial and geometric
complexity of road scenes. The dual-encoder produces multi-scale fused
representations by combining global semantic context from SAM's pretrained
Vision Transformer (ViT-H) with local spatial detail from a trainable
convolutional deep learning backbone (i.e., ResNet-50). A deformable fusion
module aligns heterogeneous features across scales and object geometries. The
decoder performs progressive multi-stage refinement using deformable attention.
Training is guided by a hybrid loss that integrates Focal, Dice,
Lovasz-Softmax, and Surface losses, improving semantic class balance, boundary
precision, and optimization stability. Experiments on the Cityscapes and
Berkeley DeepDrive 100K (BDD100K) benchmarks show that AD-SAM surpasses SAM,
Generalized SAM (G-SAM), and a deep learning baseline (DeepLabV3) in
segmentation accuracy. It achieves 68.1 mean Intersection over Union (mIoU) on
Cityscapes and 59.5 mIoU on BDD100K, outperforming SAM, G-SAM, and DeepLabV3 by
margins of up to +22.9 and +19.2 mIoU in structured and diverse road scenes,
respectively. AD-SAM demonstrates strong cross-domain generalization with a
0.87 retention score (vs. 0.76 for SAM), and faster, more stable learning
dynamics, converging within 30-40 epochs, enjoying double the learning speed of
benchmark models. It maintains 0.607 mIoU with only 1000 samples, suggesting
data efficiency critical for reducing annotation costs. These results confirm
that targeted architectural and optimization enhancements to foundation models
enable reliable and scalable AD perception.

</details>


### [13] [Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions](https://arxiv.org/abs/2510.27195)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Yoichi Sato*

Main category: cs.CV

TL;DR: AI在区分人类对话中的真伪方面存在挑战，尤其是在涉及视觉线索的多方互动中。本研究提出了一个新的多模态交互真实性评估（MIVA）任务和数据集，并评估了包括GPT-4o在内的多模态大语言模型（MLLMs），发现它们在区分真伪方面表现不佳，原因在于未能有效结合语言和视觉线索。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统日益融入人类生活，赋予它们强大的社交智能，特别是区分真伪的能力，变得至关重要。然而，在动态、多方对话中自动检测欺骗仍然是一个重大挑战，目前对多模态大语言模型（MLLMs）在这方面的能力评估不足。

Method: 提出一个新的多模态交互真实性评估（MIVA）任务，并构建了一个来源于社交推理游戏“狼人杀”的多模态数据集。该数据集包含同步的视频和文本，并为每个陈述提供可验证的真实性标签。使用该数据集对最先进的MLLMs进行了全面的基准评估。

Result: 评估结果显示，即使是像GPT-4o这样强大的模型，也难以可靠地区分真伪，存在显著的性能差距。模型失败的模式分析表明，它们未能有效地将语言与视觉社交线索联系起来，并且可能在对齐方面过于保守。

Conclusion: 当前最先进的MLLMs在处理涉及视觉线索的多方对话真实性评估方面能力不足，突显了开发更具洞察力和可信赖AI系统的新方法的紧迫性。

Abstract: As AI systems become increasingly integrated into human lives, endowing them
with robust social intelligence has emerged as a critical frontier. A key
aspect of this intelligence is discerning truth from deception, a ubiquitous
element of human interaction that is conveyed through a complex interplay of
verbal language and non-verbal visual cues. However, automatic deception
detection in dynamic, multi-party conversations remains a significant
challenge. The recent rise of powerful Multimodal Large Language Models
(MLLMs), with their impressive abilities in visual and textual understanding,
makes them natural candidates for this task. Consequently, their capabilities
in this crucial domain are mostly unquantified. To address this gap, we
introduce a new task, Multimodal Interactive Veracity Assessment (MIVA), and
present a novel multimodal dataset derived from the social deduction game
Werewolf. This dataset provides synchronized video, text, with verifiable
ground-truth labels for every statement. We establish a comprehensive benchmark
evaluating state-of-the-art MLLMs, revealing a significant performance gap:
even powerful models like GPT-4o struggle to distinguish truth from falsehood
reliably. Our analysis of failure modes indicates that these models fail to
ground language in visual social cues effectively and may be overly
conservative in their alignment, highlighting the urgent need for novel
approaches to building more perceptive and trustworthy AI systems.

</details>


### [14] [Hierarchical Transformers for Unsupervised 3D Shape Abstraction](https://arxiv.org/abs/2510.27088)
*Aditya Vora,Lily Goli,Andrea Tagliasacchi,Hao Zhang*

Main category: cs.CV

TL;DR: HiT是一种无监督的、用于3D形状的新型分层神经场表示，通过学习跨不同形状类别的粗略到精细的通用分层结构，并利用分层Transformer来学习带有压缩码本的父子节点关系，从而实现对更复杂分层结构的表示，并在无监督形状分割任务上表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够学习3D形状的通用分层表示，该表示能够以粗略到精细的方式跨不同形状类别进行学习，并且在无监督设置下进行。研究旨在克服先前方法对固定分层结构的限制，并能够从数据中自动推断出更通用、更复杂的分层结构。

Method: 本研究提出了一种名为HiT（Hierarchical Transformer）的新型分层神经场表示。其核心在于一个分层Transformer，其中每个层级利用一个压缩码本来学习树状分层结构中的父子节点关系。这种码本机制使得网络能够自动识别跨不同形状类别的常见子结构。与先前将任务限制在固定分层结构（例如二叉树）的方法不同，HiT没有施加这样的限制，只限制了每个树层级的节点总数，从而能够从数据中直接推断出分层结构。

Result: HiT模型在重建损失的训练下，能够捕捉到父节点和子节点之间有意义的包含关系。在无监督形状分割任务中，该模型在全部55个ShapeNet类别上进行了测试，并成功地将形状分割成多个精细层次的结构，证明了其有效性。

Conclusion: HiT是一种有效的新型分层神经场表示，它通过利用分层Transformer和压缩码本，能够在无监督设置下学习通用的、灵活的3D形状分层结构。该方法能够超越固定分层结构的限制，从数据中自动推断出更复杂的分层关系，并在无监督形状分割任务中取得了显著成果。

Abstract: We introduce HiT, a novel hierarchical neural field representation for 3D
shapes that learns general hierarchies in a coarse-to-fine manner across
different shape categories in an unsupervised setting. Our key contribution is
a hierarchical transformer (HiT), where each level learns parent-child
relationships of the tree hierarchy using a compressed codebook. This codebook
enables the network to automatically identify common substructures across
potentially diverse shape categories. Unlike previous works that constrain the
task to a fixed hierarchical structure (e.g., binary), we impose no such
restriction, except for limiting the total number of nodes at each tree level.
This flexibility allows our method to infer the hierarchical structure directly
from data, over multiple shape categories, and representing more general and
complex hierarchies than prior approaches. When trained at scale with a
reconstruction loss, our model captures meaningful containment relationships
between parent and child nodes. We demonstrate its effectiveness through an
unsupervised shape segmentation task over all 55 ShapeNet categories, where our
method successfully segments shapes into multiple levels of granularity.

</details>


### [15] [ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding](https://arxiv.org/abs/2510.27128)
*Haonan Wang,Jingyu Lu,Hongrui Li,Xiaomeng Li*

Main category: cs.CV

TL;DR: ZEBRA是一个首个无需受试者特定适配的零样本脑部视觉解码框架，通过解耦受试者相关和语义相关成分，实现对新受试者的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有神经解码方法依赖受试者特定模型或微调，限制了其可扩展性和实际应用。本研究旨在解决这一问题，提出一种无需受试者特定适配的通用脑部视觉解码框架。

Method: ZEBRA框架通过对抗性训练，将fMRI表征分解为受试者相关和语义相关两部分，显式解耦以分离出受试者无关、语义特定的表征。

Result: 实验表明，ZEBRA在零样本设置下显著优于基线模型，并且在多项指标上达到了与完全微调模型相当的性能。

Conclusion: ZEBRA代表了迈向量子化神经解码的可扩展且实用的步骤，实现了对新受试者的泛化，无需额外的fMRI数据或重新训练。

Abstract: Recent advances in neural decoding have enabled the reconstruction of visual
experiences from brain activity, positioning fMRI-to-image reconstruction as a
promising bridge between neuroscience and computer vision. However, current
methods predominantly rely on subject-specific models or require
subject-specific fine-tuning, limiting their scalability and real-world
applicability. In this work, we introduce ZEBRA, the first zero-shot brain
visual decoding framework that eliminates the need for subject-specific
adaptation. ZEBRA is built on the key insight that fMRI representations can be
decomposed into subject-related and semantic-related components. By leveraging
adversarial training, our method explicitly disentangles these components to
isolate subject-invariant, semantic-specific representations. This
disentanglement allows ZEBRA to generalize to unseen subjects without any
additional fMRI data or retraining. Extensive experiments show that ZEBRA
significantly outperforms zero-shot baselines and achieves performance
comparable to fully finetuned models on several metrics. Our work represents a
scalable and practical step toward universal neural decoding. Code and model
weights are available at: https://github.com/xmed-lab/ZEBRA.

</details>


### [16] [WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond](https://arxiv.org/abs/2510.27133)
*Zhicong Sun,Jacqueline Lo,Jinxing Hu*

Main category: cs.CV

TL;DR: 提出了WildfireX-SLAM数据集，用于在森林环境中进行3D高斯泼溅SLAM的基准测试。


<details>
  <summary>Details</summary>
Motivation: 目前3D高斯泼溅SLAM主要应用于室内小场景，而将其应用于大尺度森林场景具有巨大潜力，例如在野火应急响应和森林管理方面。然而，现有研究缺乏全面的高质量数据集，而真实场景的数据采集成本高昂且技术不可行。

Method: 利用Unreal Engine 5 Electric Dreams Environment Sample Project，开发了一个流水线，用于采集无人机携带的航空和地面视图数据，包括精确的相机位姿和其他辅助数据。该流水线还允许灵活控制环境因素（光照、天气、火灾类型和状况），以满足森林测绘、野火应急响应等不同任务的需求。最终构建了WildfireX-SLAM数据集，包含5.5k个低空RGB-D航空影像，覆盖16平方公里的森林地图。

Result: 在WildfireX-SLAM数据集上进行了全面的基准测试，揭示了3D高斯泼溅SLAM在森林场景下面临的独特挑战，并为未来的研究提供了改进方向。数据集和代码将公开。

Conclusion: WildfireX-SLAM数据集的提出填补了3D高斯泼溅SLAM在大尺度森林场景中应用的空白，为相关研究和实际应用提供了重要资源。

Abstract: 3D Gaussian splatting (3DGS) and its subsequent variants have led to
remarkable progress in simultaneous localization and mapping (SLAM). While most
recent 3DGS-based SLAM works focus on small-scale indoor scenes, developing
3DGS-based SLAM methods for large-scale forest scenes holds great potential for
many real-world applications, especially for wildfire emergency response and
forest management. However, this line of research is impeded by the absence of
a comprehensive and high-quality dataset, and collecting such a dataset over
real-world scenes is costly and technically infeasible. To this end, we have
built a large-scale, comprehensive, and high-quality synthetic dataset for SLAM
in wildfire and forest environments. Leveraging the Unreal Engine 5 Electric
Dreams Environment Sample Project, we developed a pipeline to easily collect
aerial and ground views, including ground-truth camera poses and a range of
additional data modalities from unmanned aerial vehicle. Our pipeline also
provides flexible controls on environmental factors such as light, weather, and
types and conditions of wildfire, supporting the need for various tasks
covering forest mapping, wildfire emergency response, and beyond. The resulting
pilot dataset, WildfireX-SLAM, contains 5.5k low-altitude RGB-D aerial images
from a large-scale forest map with a total size of 16 km2. On top of
WildfireX-SLAM, a thorough benchmark is also conducted, which not only reveals
the unique challenges of 3DGS-based SLAM in the forest but also highlights
potential improvements for future works. The dataset and code will be publicly
available. Project page: https://zhicongsun.github.io/wildfirexslam.

</details>


### [17] [E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources](https://arxiv.org/abs/2510.27135)
*Tong Shen,Jingai Yu,Dong Zhou,Dong Li,Emad Barsoum*

Main category: cs.CV

TL;DR: E-MMDiT是一个高效轻量级多模态扩散模型，参数量仅304M，可在单节点8个AMD MI300X GPU上，仅用25M公开数据和1.5天训练时间，实现快速图像合成，GenEval得分0.66（优化后可达0.72），旨在降低训练资源需求和提高生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型虽然生成质量高，但存在训练数据量大、计算资源消耗多、模型结构臃肿或延迟高等问题。E-MMDiT旨在解决这些痛点，提供一个高效、轻量级的解决方案。

Method: E-MMDiT模型通过以下技术实现高效生成：1. 视觉标记器压缩：生成更紧凑的标记表示。2. 多路径压缩模块：进一步压缩标记数量。3. 位置增强：强化位置信息以保持空间相干性。4. 交替子区域注意力（ASA）：在子区域内进行注意力计算，降低计算成本。5. AdaLN-affine：用于Transformer块中计算调制参数的高效轻量级模块。

Result: 在512px图像生成任务上，E-MMDiT使用25M公开数据，在单节点8个AMD MI300X GPU上训练1.5天，GenEval得分达到0.66，通过GRPO等后训练技术可提升至0.72，实现了与现有模型相比具有竞争力的结果，同时显著降低了训练资源需求。

Conclusion: E-MMDiT是一个参数量为304M的高效轻量级多模态扩散模型，通过多种创新压缩和注意力机制，实现了快速高质量图像合成，并且训练资源需求低。该模型易于复现，性能具有竞争力，代码开源，旨在成为未来研究的实用基线，推动生成式AI的普及。

Abstract: Diffusion models have shown strong capabilities in generating high-quality
images from text prompts. However, these models often require large-scale
training data and significant computational resources to train, or suffer from
heavy structure with high latency. To this end, we propose Efficient Multimodal
Diffusion Transformer (E-MMDiT), an efficient and lightweight multimodal
diffusion model with only 304M parameters for fast image synthesis requiring
low training resources. We provide an easily reproducible baseline with
competitive results. Our model for 512px generation, trained with only 25M
public data in 1.5 days on a single node of 8 AMD MI300X GPUs, achieves 0.66 on
GenEval and easily reaches to 0.72 with some post-training techniques such as
GRPO. Our design philosophy centers on token reduction as the computational
cost scales significantly with the token count. We adopt a highly compressive
visual tokenizer to produce a more compact representation and propose a novel
multi-path compression module for further compression of tokens. To enhance our
design, we introduce Position Reinforcement, which strengthens positional
information to maintain spatial coherence, and Alternating Subregion Attention
(ASA), which performs attention within subregions to further reduce
computational cost. In addition, we propose AdaLN-affine, an efficient
lightweight module for computing modulation parameters in transformer blocks.
Our code is available at https://github.com/AMD-AGI/Nitro-E and we hope E-MMDiT
serves as a strong and practical baseline for future research and contributes
to democratization of generative AI models.

</details>


### [18] [Improving Cross-view Object Geo-localization: A Dual Attention Approach with Cross-view Interaction and Multi-Scale Spatial Features](https://arxiv.org/abs/2510.27139)
*Xingtao Ling Yingying Zhu*

Main category: cs.CV

TL;DR: 提出了一种新的跨视图地理定位方法CVCAM，通过多轮视图交互和多头空间注意力模块来提高定位精度，并创建了新的G2D数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨视图信息传递和空间关系特征图精炼方面存在不足，容易受到边缘噪声干扰，影响定位性能。

Method: 提出跨视图和交叉注意力模块（CVCAM），进行多轮视图交互，实现上下文信息的连续交换和学习；集成多头空间注意力模块（MHSAM），提取多尺度空间特征，增强查询对象的特征表示；创建了新的G2D数据集。

Result: 在CVOGL和G2D数据集上的实验表明，所提出的方法实现了高定位精度，超过了当前最先进的水平。

Conclusion: 所提出的CVCAM方法通过多轮视图交互和多头空间注意力模块，能够更有效地传递和学习跨视图信息，抑制噪声，从而提高地理定位的准确性。新数据集G2D的创建也为相关研究提供了支持。

Abstract: Cross-view object geo-localization has recently gained attention due to
potential applications. Existing methods aim to capture spatial dependencies of
query objects between different views through attention mechanisms to obtain
spatial relationship feature maps, which are then used to predict object
locations. Although promising, these approaches fail to effectively transfer
information between views and do not further refine the spatial relationship
feature maps. This results in the model erroneously focusing on irrelevant edge
noise, thereby affecting localization performance. To address these
limitations, we introduce a Cross-view and Cross-attention Module (CVCAM),
which performs multiple iterations of interaction between the two views,
enabling continuous exchange and learning of contextual information about the
query object from both perspectives. This facilitates a deeper understanding of
cross-view relationships while suppressing the edge noise unrelated to the
query object. Furthermore, we integrate a Multi-head Spatial Attention Module
(MHSAM), which employs convolutional kernels of various sizes to extract
multi-scale spatial features from the feature maps containing implicit
correspondences, further enhancing the feature representation of the query
object. Additionally, given the scarcity of datasets for cross-view object
geo-localization, we created a new dataset called G2D for the "Ground-to-Drone"
localization task, enriching existing datasets and filling the gap in
"Ground-to-Drone" localization task. Extensive experiments on the CVOGL and G2D
datasets demonstrate that our proposed method achieves high localization
accuracy, surpassing the current state-of-the-art.

</details>


### [19] [HiGS: Hierarchical Generative Scene Framework for Multi-Step Associative Semantic Spatial Composition](https://arxiv.org/abs/2510.27148)
*Jiacheng Hong,Kunzhen Wu,Mingrui Yu,Yichao Gu,Shengze Xue,Shuangjiu Xiao,Deli Dong*

Main category: cs.CV

TL;DR: HiGS是一个分层生成框架，通过多步关联语义空间构成，实现高效的三维场景构建。


<details>
  <summary>Details</summary>
Motivation: 现有三维场景生成方法难以平衡场景复杂性与用户输入，受人类认知过程启发，提出HiGS。

Method: HiGS采用分步生成方式，允许用户选择关键语义对象进行迭代扩展，模型自动完成外围区域。引入渐进分层空间语义图（PHiSSG）来组织空间关系和语义依赖，确保生成过程的空间和几何一致性。

Result: HiGS在布局合理性、风格一致性和用户偏好方面优于单阶段方法。

Conclusion: HiGS为高效的三维场景构建提供了一个可控且可扩展的范例。

Abstract: Three-dimensional scene generation holds significant potential in gaming,
film, and virtual reality. However, most existing methods adopt a single-step
generation process, making it difficult to balance scene complexity with
minimal user input. Inspired by the human cognitive process in scene modeling,
which progresses from global to local, focuses on key elements, and completes
the scene through semantic association, we propose HiGS, a hierarchical
generative framework for multi-step associative semantic spatial composition.
HiGS enables users to iteratively expand scenes by selecting key semantic
objects, offering fine-grained control over regions of interest while the model
completes peripheral areas automatically. To support structured and coherent
generation, we introduce the Progressive Hierarchical Spatial-Semantic Graph
(PHiSSG), which dynamically organizes spatial relationships and semantic
dependencies across the evolving scene structure. PHiSSG ensures spatial and
geometric consistency throughout the generation process by maintaining a
one-to-one mapping between graph nodes and generated objects and supporting
recursive layout optimization. Experiments demonstrate that HiGS outperforms
single-stage methods in layout plausibility, style consistency, and user
preference, offering a controllable and extensible paradigm for efficient 3D
scene construction.

</details>


### [20] [AFM-Net: Advanced Fusing Hierarchical CNN Visual Priors with Global Sequence Modeling for Remote Sensing Image Scene Classification](https://arxiv.org/abs/2510.27155)
*Yuanhao Tang,Xuechao Zou,Zhengpei Hu,Junliang Xing,Chengkun Zhang,Jianqiang Huang*

Main category: cs.CV

TL;DR: AFM-Net是一种结合CNN和Mamba的新型遥感图像场景分类框架，通过分层融合机制有效整合局部纹理和全局上下文信息，并使用混合专家分类器进行精细分类，在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感图像场景分类方法在处理复杂的空间结构和多尺度特征时面临挑战，CNN擅长提取局部纹理，而Transformer擅长捕捉全局上下文，但Transformer计算成本高，整合两者存在瓶颈。

Method: 提出AFM-Net框架，包含两个分支：一个CNN分支用于提取分层视觉先验，一个Mamba分支用于高效的全局序列建模。其核心创新在于分层融合机制，逐步聚合两个分支的多尺度特征，实现动态的跨层特征交互和上下文重建。最后，使用混合专家分类器对融合后的特征进行分类。

Result: 在AID、NWPU-RESISC45和UC Merced数据集上，AFM-Net的准确率分别达到了93.72%、95.54%和96.92%，超越了现有最先进的方法，实现了性能和效率的平衡。

Conclusion: AFM-Net通过有效整合CNN和Mamba的优势，并利用分层融合机制和混合专家分类器，成功解决了遥感图像场景分类中的挑战，并在多个数据集上取得了优异的性能。

Abstract: Remote sensing image scene classification remains a challenging task,
primarily due to the complex spatial structures and multi-scale characteristics
of ground objects. Existing approaches see CNNs excel at modeling local
textures, while Transformers excel at capturing global context. However,
efficiently integrating them remains a bottleneck due to the high computational
cost of Transformers. To tackle this, we propose AFM-Net, a novel Advanced
Hierarchical Fusing framework that achieves effective local and global
co-representation through two pathways: a CNN branch for extracting
hierarchical visual priors, and a Mamba branch for efficient global sequence
modeling. The core innovation of AFM-Net lies in its Hierarchical Fusion
Mechanism, which progressively aggregates multi-scale features from both
pathways, enabling dynamic cross-level feature interaction and contextual
reconstruction to produce highly discriminative representations. These fused
features are then adaptively routed through a Mixture-of-Experts classifier
module, which dispatches them to the most suitable experts for fine-grained
scene recognition. Experiments on AID, NWPU-RESISC45, and UC Merced show that
AFM-Net obtains 93.72, 95.54, and 96.92 percent accuracy, surpassing
state-of-the-art methods with balanced performance and efficiency. Code is
available at https://github.com/tangyuanhao-qhu/AFM-Net.

</details>


### [21] [How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring](https://arxiv.org/abs/2510.27158)
*Yanfan Zhu,Juming Xiong,Ruining Deng,Yu Wang,Yaohong Wang,Shilin Zhao,Mengmeng Yin,Yuqing Liu,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 深度学习模型难以准确复现 and/or 替代 Banff 分类法进行肾移植活检评分，主要挑战在于模型的结构理解、炎症成分识别以及最终评分的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 评估现有深度学习模型通过模块化、基于规则的框架来近似Banff评分的可行性，以应对Banff分类法在计算实现上面临的挑战。

Method: 将Banff各项指标（如球囊炎g、肾小管周围毛细血管炎ptc、动脉内膜炎v）分解为其结构和炎症组成部分，并利用现有的分割和检测工具进行评估。模型输出通过与专家指南一致的启发式规则映射到Banff评分，并与专家标注的真值进行对比。

Result: 该研究在结构遗漏、模型臆想和检测模糊性方面暴露出关键的失败模式，尽管最终评分有时与专家标注一致，但中间表示的不一致性常常损害模型的可解释性。

Conclusion: 现有AI流水线在计算实现专家级别评分方面存在局限性，需要发展模块化评估方法和计算Banff评分标准来指导未来在移植病理学领域模型开发。

Abstract: The Banff Classification provides the global standard for evaluating renal
transplant biopsies, yet its semi-quantitative nature, complex criteria, and
inter-observer variability present significant challenges for computational
replication. In this study, we explore the feasibility of approximating Banff
lesion scores using existing deep learning models through a modular, rule-based
framework. We decompose each Banff indicator - such as glomerulitis (g),
peritubular capillaritis (ptc), and intimal arteritis (v) - into its
constituent structural and inflammatory components, and assess whether current
segmentation and detection tools can support their computation. Model outputs
are mapped to Banff scores using heuristic rules aligned with expert
guidelines, and evaluated against expert-annotated ground truths. Our findings
highlight both partial successes and critical failure modes, including
structural omission, hallucination, and detection ambiguity. Even when final
scores match expert annotations, inconsistencies in intermediate
representations often undermine interpretability. These results reveal the
limitations of current AI pipelines in replicating computational expert-level
grading, and emphasize the importance of modular evaluation and computational
Banff grading standard in guiding future model development for transplant
pathology.

</details>


### [22] [Generating Accurate and Detailed Captions for High-Resolution Images](https://arxiv.org/abs/2510.27164)
*Hankyeol Lee,Gawon Seo,Kyounggyu Lee,Dogun Kim,Kyungwoo Song,Jiyoung Jung*

Main category: cs.CV

TL;DR: VLMs难以生成高分辨率图像的准确详细描述，因为它们通常在低分辨率输入上进行预训练。为解决此问题，我们提出了一种集成VLM、LLM和对象检测系统的新颖流程，以提高描述质量。该流程首先由VLM生成初始描述，然后由LLM识别关键对象并预测可能共同出现的其他对象，对象检测系统会验证这些预测。新检测到的对象会经过特定区域的描述，以确保其被包含在内。通过与LLM进行比较，并使用大型多模态模型进行定量评分，并在幻觉检测基准上进行评估，证明了该流程能生成更详细、更可靠的图像描述，同时有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 低分辨率预训练导致VLMs难以准确描述高分辨率图像的细节和对象。

Method: 提出一个包含VLM、LLM和对象检测系统的流程：1. VLM生成初始描述。2. LLM识别关键对象并预测可能共现的对象。3. 对象检测系统验证预测。4. 对新检测到的对象进行区域描述。5. 通过配对比较、LLM评分和幻觉检测基准进行评估。

Result: 该流程在包含高分辨率图像的数据集上生成了更详细、更可靠的图像描述，并有效减少了幻觉。

Conclusion: 所提出的流程通过整合VLM、LLM和对象检测，能够有效提高高分辨率图像的描述质量，并显著减少幻觉。

Abstract: Vision-language models (VLMs) often struggle to generate accurate and
detailed captions for high-resolution images since they are typically
pre-trained on low-resolution inputs (e.g., 224x224 or 336x336 pixels).
Downscaling high-resolution images to these dimensions may result in the loss
of visual details and the omission of important objects. To address this
limitation, we propose a novel pipeline that integrates vision-language models,
large language models (LLMs), and object detection systems to enhance caption
quality. Our proposed pipeline refines captions through a novel, multi-stage
process. Given a high-resolution image, an initial caption is first generated
using a VLM, and key objects in the image are then identified by an LLM. The
LLM predicts additional objects likely to co-occur with the identified key
objects, and these predictions are verified by object detection systems. Newly
detected objects not mentioned in the initial caption undergo focused,
region-specific captioning to ensure they are incorporated. This process
enriches caption detail while reducing hallucinations by removing references to
undetected objects. We evaluate the enhanced captions using pairwise comparison
and quantitative scoring from large multimodal models, along with a benchmark
for hallucination detection. Experiments on a curated dataset of
high-resolution images demonstrate that our pipeline produces more detailed and
reliable image captions while effectively minimizing hallucinations.

</details>


### [23] [M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar](https://arxiv.org/abs/2510.27166)
*Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 M^3Detection 的多帧融合 3D 物体检测框架，结合了 4D 成像雷达和摄像头数据，以克服单帧融合的局限性，并在实际应用中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 4D 成像雷达和摄像头的多模态融合方法主要依赖单帧输入，无法充分利用时空信息，且存在图像退化和雷达稀疏性问题，限制了检测性能。多帧融合虽然能提供更丰富的时空信息，但在跨帧和跨模态特征融合以及计算成本方面面临挑战。

Method: M^3Detection 框架通过多层次特征融合来整合摄像头和 4D 成像雷达的多模态数据。该框架利用基线检测器的中间特征，并通过跟踪器生成参考轨迹，从而提高计算效率并为第二阶段提供更丰富的信息。在第二阶段，设计了受雷达信息引导的全局级别对象间特征聚合模块来对齐候选提案的全局特征，以及一个沿着参考轨迹扩展局部特征的局部级别对象间特征聚合模块，以增强细粒度对象表示。最后，通过轨迹级别的多帧时空推理模块处理聚合后的特征，以编码跨帧交互并增强时间表示。

Result: 在 VoD 和 TJ4DRadSet 数据集上的大量实验表明，M^3Detection 在 3D 检测方面取得了最先进的性能，证明了其在结合摄像头和 4D 成像雷达进行多帧检测方面的有效性。

Conclusion: M^3Detection 框架通过有效融合摄像头和 4D 成像雷达的多模态、多帧数据，显著提升了 3D 物体检测的性能，解决了现有方法的局限性。

Abstract: Recent advances in 4D imaging radar have enabled robust perception in adverse
weather, while camera sensors provide dense semantic information. Fusing the
these complementary modalities has great potential for cost-effective 3D
perception. However, most existing camera-radar fusion methods are limited to
single-frame inputs, capturing only a partial view of the scene. The incomplete
scene information, compounded by image degradation and 4D radar sparsity,
hinders overall detection performance. In contrast, multi-frame fusion offers
richer spatiotemporal information but faces two challenges: achieving robust
and effective object feature fusion across frames and modalities, and
mitigating the computational cost of redundant feature extraction.
Consequently, we propose M^3Detection, a unified multi-frame 3D object
detection framework that performs multi-level feature fusion on multi-modal
data from camera and 4D imaging radar. Our framework leverages intermediate
features from the baseline detector and employs the tracker to produce
reference trajectories, improving computational efficiency and providing richer
information for second-stage. In the second stage, we design a global-level
inter-object feature aggregation module guided by radar information to align
global features across candidate proposals and a local-level inter-grid feature
aggregation module that expands local features along the reference trajectories
to enhance fine-grained object representation. The aggregated features are then
processed by a trajectory-level multi-frame spatiotemporal reasoning module to
encode cross-frame interactions and enhance temporal representation. Extensive
experiments on the VoD and TJ4DRadSet datasets demonstrate that M^3Detection
achieves state-of-the-art 3D detection performance, validating its
effectiveness in multi-frame detection with camera-4D imaging radar fusion.

</details>


### [24] [DANCER: Dance ANimation via Condition Enhancement and Rendering with diffusion model](https://arxiv.org/abs/2510.27169)
*Yucheng Xing,Jinxing Yin,Xiaodong Liu*

Main category: cs.CV

TL;DR: DANCER框架通过引入外观增强模块（AEM）和姿态渲染模块（PRM），并利用TikTok-3K数据集，利用扩散模型实现了高质量的单人舞蹈视频合成，并在实验中超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 视频生成，特别是涉及高自由度运动的人类舞蹈视频生成，对质量和时序连续性提出了高要求。现有方法在处理此类复杂内容时面临挑战。

Method: 提出了一种名为DANCER（Dance ANimation via Condition Enhancement and Rendering with Diffusion Model）的新框架，该框架基于稳定的视频扩散模型。引入了外观增强模块（AEM）以更好地利用参考图像的细节，并扩展了姿态渲染模块（PRM）以捕捉跨域的姿态条件。此外，收集了TikTok-3K数据集来增强模型训练。

Result: 通过在真实世界数据集上的广泛实验评估，DANCER模型的性能优于最先进的方法，能够生成逼真的单人舞蹈视频。

Conclusion: DANCER框架成功地实现了高质量的单人舞蹈视频合成，通过引入特定的模块和数据集解决了现有视频生成技术的挑战。

Abstract: Recently, diffusion models have shown their impressive ability in visual
generation tasks. Besides static images, more and more research attentions have
been drawn to the generation of realistic videos. The video generation not only
has a higher requirement for the quality, but also brings a challenge in
ensuring the video continuity. Among all the video generation tasks,
human-involved contents, such as human dancing, are even more difficult to
generate due to the high degrees of freedom associated with human motions. In
this paper, we propose a novel framework, named as DANCER (Dance ANimation via
Condition Enhancement and Rendering with Diffusion Model), for realistic
single-person dance synthesis based on the most recent stable video diffusion
model. As the video generation is generally guided by a reference image and a
video sequence, we introduce two important modules into our framework to fully
benefit from the two inputs. More specifically, we design an Appearance
Enhancement Module (AEM) to focus more on the details of the reference image
during the generation, and extend the motion guidance through a Pose Rendering
Module (PRM) to capture pose conditions from extra domains. To further improve
the generation capability of our model, we also collect a large amount of video
data from Internet, and generate a novel datasetTikTok-3K to enhance the model
training. The effectiveness of the proposed model has been evaluated through
extensive experiments on real-world datasets, where the performance of our
model is superior to that of the state-of-the-art methods. All the data and
codes will be released upon acceptance.

</details>


### [25] [H2-Cache: A Novel Hierarchical Dual-Stage Cache for High-Performance Acceleration of Generative Diffusion Models](https://arxiv.org/abs/2510.27171)
*Mingyu Sung,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.CV

TL;DR: H2-Cache通过引入分层缓存和双阈值系统，在不牺牲图像质量的情况下，显著加速了扩散模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存技术在加速图像生成扩散模型的推理时，往往会在速度和图像质量之间产生权衡，导致图像质量下降和计算开销增加。需要一种新的方法来解决这个速度-质量的困境。

Method: 提出了一种名为H2-Cache的分层缓存机制，该机制基于将扩散模型的去噪过程分为结构定义和细节优化两个阶段的洞察。采用独立的双阈值系统来缓存这两个阶段，并引入了池化特征摘要（PFS）技术来进行高效的相似性估计。

Result: 在Flux架构上的实验表明，H2-Cache实现了高达5.08倍的显著加速，同时保持了与基线几乎相同的图像质量，并在定量和定性上优于现有的缓存方法。

Conclusion: H2-Cache是一种有效且实用的解决方案，能够解决扩散模型推理中的速度-质量困境，为高保真扩散模型的实际应用降低了门槛。

Abstract: Diffusion models have emerged as state-of-the-art in image generation, but
their practical deployment is hindered by the significant computational cost of
their iterative denoising process. While existing caching techniques can
accelerate inference, they often create a challenging trade-off between speed
and fidelity, suffering from quality degradation and high computational
overhead. To address these limitations, we introduce H2-Cache, a novel
hierarchical caching mechanism designed for modern generative diffusion model
architectures. Our method is founded on the key insight that the denoising
process can be functionally separated into a structure-defining stage and a
detail-refining stage. H2-cache leverages this by employing a dual-threshold
system, using independent thresholds to selectively cache each stage. To ensure
the efficiency of our dual-check approach, we introduce pooled feature
summarization (PFS), a lightweight technique for robust and fast similarity
estimation. Extensive experiments on the Flux architecture demonstrate that
H2-cache achieves significant acceleration (up to 5.08x) while maintaining
image quality nearly identical to the baseline, quantitatively and
qualitatively outperforming existing caching methods. Our work presents a
robust and practical solution that effectively resolves the speed-quality
dilemma, significantly lowering the barrier for the real-world application of
high-fidelity diffusion models. Source code is available at
https://github.com/Bluear7878/H2-cache-A-Hierarchical-Dual-Stage-Cache.

</details>


### [26] [SilhouetteTell: Practical Video Identification Leveraging Blurred Recordings of Video Subtitles](https://arxiv.org/abs/2510.27179)
*Guanchong Huang,Song Fang*

Main category: cs.CV

TL;DR: 通过分析视频字幕的轮廓时域信息，提出一种名为SilhouetteTell的视频识别攻击方法，可用于在线和离线视频识别。


<details>
  <summary>Details</summary>
Motivation: 现有视频识别技术主要依赖网络流量分析，存在局限性。视频观看记录泄露隐私，可能导致用户被网络欺凌、歧视或勒索。

Method: 提出SilhouetteTell方法，结合字幕轮廓的空间域信息和字幕间的时间域信息，提取时空特征，并利用这些特征进行视频识别。

Result: 在各种设置下，包括在40米远距离，SilhouetteTell在识别视频标题和片段方面表现出高有效性。

Conclusion: SilhouetteTell是一种新颖且有效的视频识别攻击方法，能够克服现有技术的局限性，并在实际场景中具有广泛的应用前景。

Abstract: Video identification attacks pose a significant privacy threat that can
reveal videos that victims watch, which may disclose their hobbies, religious
beliefs, political leanings, sexual orientation, and health status. Also, video
watching history can be used for user profiling or advertising and may result
in cyberbullying, discrimination, or blackmail. Existing extensive video
inference techniques usually depend on analyzing network traffic generated by
streaming online videos. In this work, we observe that the content of a
subtitle determines its silhouette displayed on the screen, and identifying
each subtitle silhouette also derives the temporal difference between two
consecutive subtitles. We then propose SilhouetteTell, a novel video
identification attack that combines the spatial and time domain information
into a spatiotemporal feature of subtitle silhouettes. SilhouetteTell explores
the spatiotemporal correlation between recorded subtitle silhouettes of a video
and its subtitle file. It can infer both online and offline videos.
Comprehensive experiments on off-the-shelf smartphones confirm the high
efficacy of SilhouetteTell for inferring video titles and clips under various
settings, including from a distance of up to 40 meters.

</details>


### [27] [Dual-level Progressive Hardness-Aware Reweighting for Cross-View Geo-Localization](https://arxiv.org/abs/2510.27181)
*Guozheng Zheng,Jian Guan,Mingjie Xie,Xuanjia Zhao,Congyi Fan,Shiheng Zhang,Pengming Feng*

Main category: cs.CV

TL;DR: 提出了双层渐进式硬度感知重加权（DPHR）策略，以解决无人机与卫星图像之间的跨视图地理定位（CVGL）问题，该问题由于视角差异和困难负样本而面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的挖掘或重加权策略常采用静态加权，对分布变化敏感，并且容易过早地过度强调困难样本，导致梯度噪声和收敛不稳定。

Method: DPHR策略包含两个层面：样本层面，提出基于比率的难度感知（RDA）模块，评估相对难度并为负样本分配细粒度权重；批次层面，提出渐进式自适应损失加权（PALW）机制，利用训练进程信号在早期优化中衰减噪声梯度，并随着训练的成熟逐步增强困难负样本挖掘。

Result: 在University-1652和SUES-200基准测试中，DPHR策略表现出有效性和鲁棒性，与现有最先进的方法相比，取得了持续的改进。

Conclusion: DPHR策略通过样本级别的细粒度加权和批次级别的动态难样本挖掘，有效解决了CVGL中的挑战，提高了方法的性能和稳定性。

Abstract: Cross-view geo-localization (CVGL) between drone and satellite imagery
remains challenging due to severe viewpoint gaps and the presence of hard
negatives, which are visually similar but geographically mismatched samples.
Existing mining or reweighting strategies often use static weighting, which is
sensitive to distribution shifts and prone to overemphasizing difficult samples
too early, leading to noisy gradients and unstable convergence. In this paper,
we present a Dual-level Progressive Hardness-aware Reweighting (DPHR) strategy.
At the sample level, a Ratio-based Difficulty-Aware (RDA) module evaluates
relative difficulty and assigns fine-grained weights to negatives. At the batch
level, a Progressive Adaptive Loss Weighting (PALW) mechanism exploits a
training-progress signal to attenuate noisy gradients during early optimization
and progressively enhance hard-negative mining as training matures. Experiments
on the University-1652 and SUES-200 benchmarks demonstrate the effectiveness
and robustness of the proposed DPHR, achieving consistent improvements over
state-of-the-art methods.

</details>


### [28] [Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications](https://arxiv.org/abs/2510.27186)
*Zixuan Hu,Yongxian Wei,Li Shen,Zhenyi Wang,Lei Li,Chun Yuan,Dacheng Tao*

Main category: cs.CV

TL;DR: 现有的模型逆推方法在处理高分辨率图像和大型Vision Transformers (ViTs) 时效率低下，主要因为背景区域的冗余逆推和虚假相关性（“幻觉”）的逆推。本文提出了一种新颖的稀疏模型逆推策略，作为即插即用扩展，可加速现有密集逆推方法，无需修改其原始损失函数。该策略选择性地逆推语义前景，停止逆推背景和虚假相关性。实验证明，该方法能显著加速逆推过程（最高3.79倍），同时在无数据模型量化和无数据知识迁移等下游任务中保持相当或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集模型逆推方法在处理高分辨率图像和大型ViTs时效率低下，原因在于冗余的背景逆推和“幻觉”现象。

Method: 提出了一种新颖的稀疏模型逆推策略，作为即插即用扩展，选择性地逆推语义前景，停止逆推背景和虚假相关性，以加速现有密集逆推方法，无需修改其原始损失函数。

Result: 在模型逆推方面，实现了显著的加速（最高3.79倍）。在无数据模型量化和无数据知识迁移等下游任务中，保持了相当或更优的性能。

Conclusion: 所提出的稀疏模型逆推策略能够有效解决现有方法的效率问题，并在下游任务中取得良好性能。

Abstract: Model inversion, which aims to reconstruct the original training data from
pre-trained discriminative models, is especially useful when the original
training data is unavailable due to privacy, usage rights, or size constraints.
However, existing dense inversion methods attempt to reconstruct the entire
image area, making them extremely inefficient when inverting high-resolution
images from large-scale Vision Transformers (ViTs). We further identify two
underlying causes of this inefficiency: the redundant inversion of noisy
backgrounds and the unintended inversion of spurious correlations--a phenomenon
we term "hallucination" in model inversion. To address these limitations, we
propose a novel sparse model inversion strategy, as a plug-and-play extension
to speed up existing dense inversion methods with no need for modifying their
original loss functions. Specifically, we selectively invert semantic
foregrounds while stopping the inversion of noisy backgrounds and potential
spurious correlations. Through both theoretical and empirical studies, we
validate the efficacy of our approach in achieving significant inversion
acceleration (up to 3.79 faster) while maintaining comparable or even enhanced
downstream performance in data-free model quantization and data-free knowledge
transfer. Code is available at https://github.com/Egg-Hu/SMI.

</details>


### [29] [Multi-Modal Feature Fusion for Spatial Morphology Analysis of Traditional Villages via Hierarchical Graph Neural Networks](https://arxiv.org/abs/2510.27208)
*Jiaxin Zhang,Zehong Zhu,Junye Deng,Yunqin Li,and Bowen Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的分层图神经网络（HGNN）模型，利用多源数据深入分析乡村空间形态，解决了现有研究在数据、方法和视角上的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着城镇化的发展，乡村地区空间特征逐渐消失，景观趋于同质化。现有研究多采用单一学科视角和定性方法，受数字基础设施和数据限制。

Method: 提出一种包含输入节点和通信节点、静态输入边和动态通信边分层图神经网络（HGNN）模型。该模型结合图卷积网络（GCN）和图注意力网络（GAT），利用两阶段特征更新机制整合多模态特征，并引入关系池化机制和联合训练策略对17种子类型进行分类。

Result: 实验结果表明，该模型在多模态融合和分类任务上显著优于现有方法，平均准确率/F1分数从0.71/0.83提升至0.82/0.90，其中地块分类任务提升了6%。

Conclusion: 该研究提出的HGNN模型为探索乡村空间格局和生成逻辑提供了科学依据。

Abstract: Villages areas hold significant importance in the study of human-land
relationships. However, with the advancement of urbanization, the gradual
disappearance of spatial characteristics and the homogenization of landscapes
have emerged as prominent issues. Existing studies primarily adopt a
single-disciplinary perspective to analyze villages spatial morphology and its
influencing factors, relying heavily on qualitative analysis methods. These
efforts are often constrained by the lack of digital infrastructure and
insufficient data. To address the current research limitations, this paper
proposes a Hierarchical Graph Neural Network (HGNN) model that integrates
multi-source data to conduct an in-depth analysis of villages spatial
morphology. The framework includes two types of nodes-input nodes and
communication nodes-and two types of edges-static input edges and dynamic
communication edges. By combining Graph Convolutional Networks (GCN) and Graph
Attention Networks (GAT), the proposed model efficiently integrates multimodal
features under a two-stage feature update mechanism. Additionally, based on
existing principles for classifying villages spatial morphology, the paper
introduces a relational pooling mechanism and implements a joint training
strategy across 17 subtypes. Experimental results demonstrate that this method
achieves significant performance improvements over existing approaches in
multimodal fusion and classification tasks. Additionally, the proposed joint
optimization of all sub-types lifts mean accuracy/F1 from 0.71/0.83
(independent models) to 0.82/0.90, driven by a 6% gain for parcel tasks. Our
method provides scientific evidence for exploring villages spatial patterns and
generative logic.

</details>


### [30] [Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness](https://arxiv.org/abs/2510.27213)
*Ren Tasai,Guang Li,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的持续自监督学习（CSSL）框架，用于从多窗口胸部CT图像中学习多样化特征并确保数据隐私。


<details>
  <summary>Details</summary>
Motivation: 医学影像诊断模型面临大规模标注数据稀缺和领域转移的挑战，尤其在胸部CT中，不同窗口设置会导致领域转移。之前的CSSL方法通常通过重用旧数据来缓解领域转移，但这在隐私方面不切实际。

Method: 提出了一种结合潜在重放机制和特征蒸馏（WKD+BKE）的CSSL框架，用于在持续预训练中缓解灾难性遗忘并确保数据隐私，同时学习有意义的、鲁棒的特征表示。

Result: 使用两个不同窗口设置的胸部CT图像验证了所提出方法的有效性，并取得了优于其他方法的性能。

Conclusion: 所提出的CSSL框架能够有效应对医学影像的领域转移问题，同时保护数据隐私，并能学习到鲁棒的特征表示。

Abstract: We propose a novel continual self-supervised learning (CSSL) framework for
simultaneously learning diverse features from multi-window-obtained chest
computed tomography (CT) images and ensuring data privacy. Achieving a robust
and highly generalizable model in medical image diagnosis is challenging,
mainly because of issues, such as the scarcity of large-scale, accurately
annotated datasets and domain shifts inherent to dynamic healthcare
environments. Specifically, in chest CT, these domain shifts often arise from
differences in window settings, which are optimized for distinct clinical
purposes. Previous CSSL frameworks often mitigated domain shift by reusing past
data, a typically impractical approach owing to privacy constraints. Our
approach addresses these challenges by effectively capturing the relationship
between previously learned knowledge and new information across different
training stages through continual pretraining on unlabeled images.
Specifically, by incorporating a latent replay-based mechanism into CSSL, our
method mitigates catastrophic forgetting due to domain shifts during continual
pretraining while ensuring data privacy. Additionally, we introduce a feature
distillation technique that integrates Wasserstein distance-based knowledge
distillation (WKD) and batch-knowledge ensemble (BKE), enhancing the ability of
the model to learn meaningful, domain-shift-robust representations. Finally, we
validate our approach using chest CT images obtained across two different
window settings, demonstrating superior performance compared with other
approaches.

</details>


### [31] [Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model](https://arxiv.org/abs/2510.27607)
*John Won,Kyungmin Lee,Huiwon Jang,Dongyoung Kim,Jinwoo Shin*

Main category: cs.CV

TL;DR: DUST是一个世界模型增强的VLA框架，通过分离和联合模态来提高机器人策略学习。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在结合世界模型时，由于模态差异，难以同时预测下一状态和动作序列。

Method: DUST提出了一个多模态扩散Transformer架构，具有独立的模态流和交叉模态知识共享，并采用独立的噪声扰动和解耦的流匹配损失，实现了双向学习联合分布，无需统一的潜在空间。此外，还引入了一种测试时联合采样方法，允许动作和视觉令牌异步演化。

Result: 在RoboCasa和GR-1等模拟基准上，DUST的性能比基线方法提高了6%，测试时缩放方法额外提高了2-5%。在Franka Research 3的真实世界任务上，DUST的成功率提高了13%。

Conclusion: DUST框架能够有效处理模态冲突，提升VLA性能，并且在模拟和真实世界任务中均表现出色。

Abstract: Recently, augmenting Vision-Language-Action models (VLAs) with world modeling
has shown promise in improving robotic policy learning. However, it remains
challenging to jointly predict next-state observations and action sequences
because of the inherent difference between the two modalities. To address this,
we propose DUal-STream diffusion (DUST), a world-model augmented VLA framework
that handles the modality conflict and enhances the performance of VLAs across
diverse tasks. Specifically, we propose a multimodal diffusion transformer
architecture that explicitly maintains separate modality streams while still
enabling cross-modal knowledge sharing. In addition, we introduce independent
noise perturbations for each modality and a decoupled flow-matching loss. This
design enables the model to learn the joint distribution in a bidirectional
manner while avoiding the need for a unified latent space. Based on the
decoupling of modalities during training, we also introduce a joint sampling
method that supports test-time scaling, where action and vision tokens evolve
asynchronously at different rates. Through experiments on simulated benchmarks
such as RoboCasa and GR-1, DUST achieves up to 6% gains over baseline methods,
while our test-time scaling approach provides an additional 2-5% boost. On
real-world tasks with the Franka Research 3, DUST improves success rates by
13%, confirming its effectiveness beyond simulation. Furthermore, pre-training
on action-free videos from BridgeV2 yields significant transfer gains on
RoboCasa, underscoring DUST's potential for large-scale VLA pretraining.

</details>


### [32] [Deep learning denoising unlocks quantitative insights in operando materials microscopy](https://arxiv.org/abs/2510.27667)
*Samuel Degnan-Morgenstern,Alexander E. Cohen,Rajeev Gopal,Megan Gober,George J. Nelson,Peng Bai,Martin Z. Bazant*

Main category: cs.CV

TL;DR: 本研究提出一种整合无监督深度学习去噪的通用框架，用于提高操作显微镜数据的定量分析能力，并展示了其在多种成像模态和尺度上的有效性。


<details>
  <summary>Details</summary>
Motivation: 操作显微镜技术虽然能直接揭示功能材料的动态化学和物理过程，但测量噪声限制了其有效分辨率并阻碍了定量分析。

Method: 提出一种整合无监督深度学习去噪的通用框架，并将其应用于模拟和实验数据中，包括扫描透射 X 射线显微镜 (STXM)、光学显微镜和中子射线照相技术。

Result: 在模拟数据上，深度去噪被证明能够保持物理保真度，引入最小偏差，并减少基于偏微分方程 (PDE) 约束优化的模型学习中的不确定性。在实验中，去噪技术揭示了锂离子磷酸盐 (LFP) 的扫描透射 X 射线显微镜 (STXM) 中的纳米化学和结构异质性，实现了石墨电极光学显微镜中颗粒分割和相分类的自动化，并将中子射线照相技术中由噪声引起的变异性降低了近 80%，从而解析了不均匀的锂传输。

Conclusion: 深度去噪是一种强大的、与模态无关的增强方法，能够改进定量操作成像，并扩展以前受噪声限制的技术的应用范围。

Abstract: Operando microscopy provides direct insight into the dynamic chemical and
physical processes that govern functional materials, yet measurement noise
limits the effective resolution and undermines quantitative analysis. Here, we
present a general framework for integrating unsupervised deep learning-based
denoising into quantitative microscopy workflows across modalities and length
scales. Using simulated data, we demonstrate that deep denoising preserves
physical fidelity, introduces minimal bias, and reduces uncertainty in model
learning with partial differential equation (PDE)-constrained optimization.
Applied to experiments, denoising reveals nanoscale chemical and structural
heterogeneity in scanning transmission X-ray microscopy (STXM) of lithium iron
phosphate (LFP), enables automated particle segmentation and phase
classification in optical microscopy of graphite electrodes, and reduces
noise-induced variability by nearly 80% in neutron radiography to resolve
heterogeneous lithium transport. Collectively, these results establish deep
denoising as a powerful, modality-agnostic enhancement that advances
quantitative operando imaging and extends the reach of previously noise-limited
techniques.

</details>


### [33] [SpecAware: A Spectral-Content Aware Foundation Model for Unifying Multi-Sensor Learning in Hyperspectral Remote Sensing Mapping](https://arxiv.org/abs/2510.27219)
*Renjie Ji,Xue Wang,Chao Niu,Wen Zhang,Yong Mei,Kun Tan*

Main category: cs.CV

TL;DR: SpecAware是一个新颖的、感知光谱内容的基金模型，用于统一多传感器高光谱成像（HSI）制图中的多传感器学习。它通过一个两步超网络驱动的编码过程来处理HSI数据，该过程利用传感器元属性和图像内容来定制每个HSI斑块的条件输入。该模型还包括一个HyperEmbedding模块，该模块动态生成矩阵因子以进行通道编码，从而实现自适应空间模式提取和潜在语义特征重投影。SpecAware能够处理可变数量的光谱通道，从而为联合预训练建立了一个统一的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的高光谱成像（HSI）基金模型在处理多传感器数据和利用传感器元属性方面存在局限性，限制了其泛化能力。HSI数据的固有异质性也给联合训练带来了挑战。

Method: SpecAware采用两步超网络驱动的编码过程。首先，一个元内容感知模块利用传感器元属性和图像内容为每个HSI斑块生成一个独特的条件输入。其次，HyperEmbedding模块使用样本条件超网络动态生成矩阵因子，以进行通道编码，从而实现自适应空间模式提取和潜在语义特征重投影。此外，还构建了Hyper-400K数据集，这是一个包含来自不同机载AVIRIS传感器的大型数据集，用于促进研究。

Result: SpecAware在六个数据集上的广泛实验表明，它可以学习到优越的特征表示，在土地覆盖语义分割分类、变化检测和场景分类方面表现出色。

Conclusion: SpecAware通过其新颖的元内容感知和HyperEmbedding模块，能够有效地统一多传感器高光谱成像（HSI）学习，并处理不同传感器和场景的HSI数据，克服了现有方法的局限性，并在多项下游任务中取得了优越的性能。

Abstract: Hyperspectral imaging (HSI) is a vital tool for fine-grained land-use and
land-cover (LULC) mapping. However, the inherent heterogeneity of HSI data has
long posed a major barrier to developing generalized models via joint training.
Although HSI foundation models have shown promise for different downstream
tasks, the existing approaches typically overlook the critical guiding role of
sensor meta-attributes, and struggle with multi-sensor training, limiting their
transferability. To address these challenges, we propose SpecAware, which is a
novel hyperspectral spectral-content aware foundation model for unifying
multi-sensor learning for HSI mapping. We also constructed the Hyper-400K
dataset to facilitate this research, which is a new large-scale, high-quality
benchmark dataset with over 400k image patches from diverse airborne AVIRIS
sensors. The core of SpecAware is a two-step hypernetwork-driven encoding
process for HSI data. Firstly, we designed a meta-content aware module to
generate a unique conditional input for each HSI patch, tailored to each
spectral band of every sample by fusing the sensor meta-attributes and its own
image content. Secondly, we designed the HyperEmbedding module, where a
sample-conditioned hypernetwork dynamically generates a pair of matrix factors
for channel-wise encoding, consisting of adaptive spatial pattern extraction
and latent semantic feature re-projection. Thus, SpecAware gains the ability to
perceive and interpret spatial-spectral features across diverse scenes and
sensors. This, in turn, allows SpecAware to adaptively process a variable
number of spectral channels, establishing a unified framework for joint
pre-training. Extensive experiments on six datasets demonstrate that SpecAware
can learn superior feature representations, excelling in land-cover semantic
segmentation classification, change detection, and scene classification.

</details>


### [34] [Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery](https://arxiv.org/abs/2510.27224)
*Mahmoud El Hussieni,Bahadır K. Güntürk,Hasan F. Ateş,Oğuz Hanoğlu*

Main category: cs.CV

TL;DR: YOLOv11 在卫星图像中实现了建筑物实例分割和高度分类，在 DFC2023 数据集上取得了优于先前模型的性能。


<details>
  <summary>Details</summary>
Motivation: 准确的建筑物实例分割和高度分类对于城市规划、3D 城市建模和基础设施监测至关重要。

Method: 在 DFC2023 数据集上使用 YOLOv11 模型进行建筑物实例分割和离散高度分类，并使用精度、召回率、F1 分数和 mAP 等指标进行评估。

Result: YOLOv11 在 DFC2023 数据集上实现了 60.4% 的 mAP@50 和 38.3% 的 mAP@50--95 的实例分割性能，同时保持了五个预定义高度等级的稳健分类精度，并且在处理遮挡、复杂建筑形状和类别不平衡方面表现出色。

Conclusion: YOLOv11 在检测精度和推理速度方面均优于之前的多任务框架，在实时、大规模城市测绘方面具有潜力，能够通过简化的分类高度建模来推进语义城市重建。

Abstract: Accurate building instance segmentation and height classification are
critical for urban planning, 3D city modeling, and infrastructure monitoring.
This paper presents a detailed analysis of YOLOv11, the recent advancement in
the YOLO series of deep learning models, focusing on its application to joint
building extraction and discrete height classification from satellite imagery.
YOLOv11 builds on the strengths of earlier YOLO models by introducing a more
efficient architecture that better combines features at different scales,
improves object localization accuracy, and enhances performance in complex
urban scenes. Using the DFC2023 Track 2 dataset -- which includes over 125,000
annotated buildings across 12 cities -- we evaluate YOLOv11's performance using
metrics such as precision, recall, F1 score, and mean average precision (mAP).
Our findings demonstrate that YOLOv11 achieves strong instance segmentation
performance with 60.4\% mAP@50 and 38.3\% mAP@50--95 while maintaining robust
classification accuracy across five predefined height tiers. The model excels
in handling occlusions, complex building shapes, and class imbalance,
particularly for rare high-rise structures. Comparative analysis confirms that
YOLOv11 outperforms earlier multitask frameworks in both detection accuracy and
inference speed, making it well-suited for real-time, large-scale urban
mapping. This research highlights YOLOv11's potential to advance semantic urban
reconstruction through streamlined categorical height modeling, offering
actionable insights for future developments in remote sensing and geospatial
intelligence.

</details>


### [35] [MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts](https://arxiv.org/abs/2510.27234)
*Jingnan Gao,Zhe Wang,Xianze Fang,Xingyu Ren,Zhuo Chen,Shengqi Liu,Yuhao Cheng,Jiangjing Lyu,Xiaokang Yang,Yichao Yan*

Main category: cs.CV

TL;DR: MoRE是一个基于混合专家（MoE）架构的密集3D视觉基础模型，通过动态路由特征到特定任务的专家，提高了3D视觉几何重建的可扩展性和适应性。它还通过基于置信度的深度细化模块和集成密集语义特征来提高鲁棒性和高保真度表面法线预测，并在多个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉几何重建模型在扩展性和适应性方面存在挑战，主要由于几何监督的复杂性和3D数据的多样性。

Method: 提出MoRE模型，采用混合专家（MoE）架构，动态路由特征到任务特定的专家，并结合了基于置信度的深度细化模块和密集语义特征与全局对齐的3D骨干表示。

Result: MoRE在多个基准测试中实现了最先进的性能，并支持有效的下游应用，而无需额外的计算。

Conclusion: MoRE通过MoE架构、置信度深度细化和密集语义特征集成，成功克服了现有3D模型在扩展性和鲁棒性方面的限制，并在3D视觉几何重建任务中取得了显著成果。

Abstract: Recent advances in language and vision have demonstrated that scaling up
model capacity consistently improves performance across diverse tasks. In 3D
visual geometry reconstruction, large-scale training has likewise proven
effective for learning versatile representations. However, further scaling of
3D models is challenging due to the complexity of geometric supervision and the
diversity of 3D data. To overcome these limitations, we propose MoRE, a dense
3D visual foundation model based on a Mixture-of-Experts (MoE) architecture
that dynamically routes features to task-specific experts, allowing them to
specialize in complementary data aspects and enhance both scalability and
adaptability. Aiming to improve robustness under real-world conditions, MoRE
incorporates a confidence-based depth refinement module that stabilizes and
refines geometric estimation. In addition, it integrates dense semantic
features with globally aligned 3D backbone representations for high-fidelity
surface normal prediction. MoRE is further optimized with tailored loss
functions to ensure robust learning across diverse inputs and multiple
geometric tasks. Extensive experiments demonstrate that MoRE achieves
state-of-the-art performance across multiple benchmarks and supports effective
downstream applications without extra computation.

</details>


### [36] [Object-IR: Leveraging Object Consistency and Mesh Deformation for Self-Supervised Image Retargeting](https://arxiv.org/abs/2510.27236)
*Tianli Liao,Ran Wang,Siqing Zhang,Lei Li,Guangen Liu,Chenyang Zhao,Heling Cao,Peng Li*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Object-IR的自监督学习方法，用于解决图像重定向中的几何畸变问题，通过网格变形优化，并在RetargetMe基准测试中取得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 图像重定向中消除语义重要区域的几何畸变是一个难以解决的挑战。

Method: 提出了一种名为Object-IR的自监督学习架构，将图像重定向重构为基于学习的网格变形优化问题。该方法使用卷积神经网络预测网格运动，并通过结合物体外观一致性、几何保持约束以及边界约束来优化网格变形，以生成无畸变的重定向图像。该方法利用输入图像的几何和语义特性进行自监督学习，无需手动标注的数据集。

Result: 在RetargetMe基准测试中，Object-IR取得了最先进的性能，在定量指标和主观视觉质量评估方面均优于现有方法。该框架能够高效处理任意输入分辨率（1024x683分辨率的平均推理时间为0.009秒），并在消费级GPU上保持实时性能。

Conclusion: Object-IR是一种有效的自监督学习方法，能够解决图像重定向中的几何畸变问题，并在性能和效率上优于现有技术。

Abstract: Eliminating geometric distortion in semantically important regions remains an
intractable challenge in image retargeting. This paper presents Object-IR, a
self-supervised architecture that reformulates image retargeting as a
learning-based mesh warping optimization problem, where the mesh deformation is
guided by object appearance consistency and geometric-preserving constraints.
Given an input image and a target aspect ratio, we initialize a uniform rigid
mesh at the output resolution and use a convolutional neural network to predict
the motion of each mesh grid and obtain the deformed mesh. The retargeted
result is generated by warping the input image according to the rigid mesh in
the input image and the deformed mesh in the output resolution. To mitigate
geometric distortion, we design a comprehensive objective function
incorporating a) object-consistent loss to ensure that the important semantic
objects retain their appearance, b) geometric-preserving loss to constrain
simple scale transform of the important meshes, and c) boundary loss to enforce
a clean rectangular output. Notably, our self-supervised paradigm eliminates
the need for manually annotated retargeting datasets by deriving supervision
directly from the input's geometric and semantic properties. Extensive
evaluations on the RetargetMe benchmark demonstrate that our Object-IR achieves
state-of-the-art performance, outperforming existing methods in quantitative
metrics and subjective visual quality assessments. The framework efficiently
processes arbitrary input resolutions (average inference time: 0.009s for
1024x683 resolution) while maintaining real-time performance on consumer-grade
GPUs. The source code will soon be available at
https://github.com/tlliao/Object-IR.

</details>


### [37] [Fusion of Heterogeneous Pathology Foundation Models for Whole Slide Image Analysis](https://arxiv.org/abs/2510.27237)
*Zhidong Yang,Xiuhui Shi,Wei Ba,Zhigang Song,Haijing Luan,Taiyuan Hu,Senlin Lin,Jiguang Wang,Shaohua Kevin Zhou,Rui Yan*

Main category: cs.CV

TL;DR: 本研究提出了一个名为FuseCPath的新框架，用于融合异构的病理基础模型（FMs），以提高下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的病理FMs由于训练数据集和网络结构的多样性而存在异构性，导致在下游任务中使用其提取的特征时性能不稳定。本研究旨在有效融合多个异构病理FMs，以获得优越的集成性能。

Method: FuseCPath框架包含三个主要部分：1. 使用多视图聚类方法过滤判别性病理图像块（patches），以保证训练样本的代表性；2. 设计了一种聚类层重嵌入策略，用于在线捕获块级局部特征，有效融合异构的块级FMs；3. 提出了一种协同蒸馏策略，用于探索幻灯片级FMs之间的联系，有效融合异构的幻灯片级FMs。

Result: 在癌症基因组图谱（TCGA）的肺癌、膀胱癌和结直肠癌数据集上的广泛实验表明，FuseCPath在多项任务上取得了最先进的性能。

Conclusion: FuseCPath框架能够有效融合异构的病理FMs，并在多个下游任务中取得优越的性能，证明了其在计算病理学领域的潜力。

Abstract: Whole slide image (WSI) analysis has emerged as an increasingly essential
technique in computational pathology. Recent advances in the pathological
foundation models (FMs) have demonstrated significant advantages in deriving
meaningful patch-level or slide-level feature representations from WSIs.
However, current pathological FMs have exhibited substantial heterogeneity
caused by diverse private training datasets and different network
architectures. This heterogeneity introduces performance variability when we
utilize the extracted features from different FMs in the downstream tasks. To
fully explore the advantage of multiple FMs effectively, in this work, we
propose a novel framework for the fusion of heterogeneous pathological FMs,
called FuseCPath, yielding a model with a superior ensemble performance. The
main contributions of our framework can be summarized as follows: (i) To
guarantee the representativeness of the training patches, we propose a
multi-view clustering-based method to filter out the discriminative patches via
multiple FMs' embeddings. (ii) To effectively fuse the heterogeneous
patch-level FMs, we devise a cluster-level re-embedding strategy to online
capture patch-level local features. (iii) To effectively fuse the heterogeneous
slide-level FMs, we devise a collaborative distillation strategy to explore the
connections between slide-level FMs. Extensive experiments conducted on lung
cancer, bladder cancer, and colorectal cancer datasets from The Cancer Genome
Atlas (TCGA) have demonstrated that the proposed FuseCPath achieves
state-of-the-art performance across multiple tasks on these public datasets.

</details>


### [38] [Trans-defense: Transformer-based Denoiser for Adversarial Defense with Spatial-Frequency Domain Representation](https://arxiv.org/abs/2510.27245)
*Alik Pramanick,Mayank Bansal,Utkarsh Srivastava,Suklav Ghosh,Arijit Sur*

Main category: cs.CV

TL;DR: 提出一种结合了空间域和频率域方法的去噪策略，通过离散小波变换（DWT）进行频率分析，并利用transformer层融合空间图像特征和小波特征，以增强分类器对对抗性攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）虽然在各种应用中取得了显著成就，但容易受到复杂的对抗性攻击，这限制了它们在安全关键系统中的应用。

Method: 提出一种两阶段训练方法：首先训练去噪网络，然后训练深度分类模型。去噪网络结合了空间域和频率域的方法，利用离散小波变换（DWT）进行频率分析，并通过transformer层融合空间图像特征和小波特征。最后，使用去噪后的图像重新训练分类器。

Result: 在MNIST、CIFAR-10和Fashion-MNIST数据集上的实验结果表明，该方法显著提高了分类准确率，并且优于仅使用去噪网络或对抗性训练方法的性能。

Conclusion: 所提出的方法通过两阶段训练和一种新颖的去噪策略，能够有效地增强DNN在面对对抗性攻击时的鲁棒性，显著提高分类准确率。

Abstract: In recent times, deep neural networks (DNNs) have been successfully adopted
for various applications. Despite their notable achievements, it has become
evident that DNNs are vulnerable to sophisticated adversarial attacks,
restricting their applications in security-critical systems. In this paper, we
present two-phase training methods to tackle the attack: first, training the
denoising network, and second, the deep classifier model. We propose a novel
denoising strategy that integrates both spatial and frequency domain approaches
to defend against adversarial attacks on images. Our analysis reveals that
high-frequency components of attacked images are more severely corrupted
compared to their lower-frequency counterparts. To address this, we leverage
Discrete Wavelet Transform (DWT) for frequency analysis and develop a denoising
network that combines spatial image features with wavelets through a
transformer layer. Next, we retrain the classifier using the denoised images,
which enhances the classifier's robustness against adversarial attacks.
Experimental results across the MNIST, CIFAR-10, and Fashion-MNIST datasets
reveal that the proposed method remarkably elevates classification accuracy,
substantially exceeding the performance by utilizing a denoising network and
adversarial training approaches. The code is available at
https://github.com/Mayank94/Trans-Defense.

</details>


### [39] [C-LEAD: Contrastive Learning for Enhanced Adversarial Defense](https://arxiv.org/abs/2510.27249)
*Suklav Ghosh,Sonal Kumar,Arijit Sur*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的对比学习方法来防御对抗性攻击，通过在训练中使用干净和对抗性扰动的图像，增强了分类模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）容易受到对抗性攻击，这可能导致输入图像的微小扰动导致错误预测。解决这个问题对于部署鲁棒的深度学习系统至关重要。

Method: 该方法利用对比学习和对比损失函数，通过同时优化模型的参数和扰动来增强分类模型的鲁棒性，使网络能够学习到不易受到对抗性攻击的鲁棒表示。

Result: 实验结果表明，与各种类型的对抗性扰动相比，模型的鲁棒性有了显著提高。

Conclusion: 对比损失有助于提取信息更丰富、更具弹性的特征，从而为深度学习中的对抗鲁棒性领域做出了贡献。

Abstract: Deep neural networks (DNNs) have achieved remarkable success in computer
vision tasks such as image classification, segmentation, and object detection.
However, they are vulnerable to adversarial attacks, which can cause incorrect
predictions with small perturbations in input images. Addressing this issue is
crucial for deploying robust deep-learning systems. This paper presents a novel
approach that utilizes contrastive learning for adversarial defense, a
previously unexplored area. Our method leverages the contrastive loss function
to enhance the robustness of classification models by training them with both
clean and adversarially perturbed images. By optimizing the model's parameters
alongside the perturbations, our approach enables the network to learn robust
representations that are less susceptible to adversarial attacks. Experimental
results show significant improvements in the model's robustness against various
types of adversarial perturbations. This suggests that contrastive loss helps
extract more informative and resilient features, contributing to the field of
adversarial robustness in deep learning.

</details>


### [40] [Enhancing Spatio-Temporal Zero-shot Action Recognition with Language-driven Description Attributes](https://arxiv.org/abs/2510.27255)
*Yehna Kim andYoung-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 该研究提出一种利用网络爬取描述和关键词提取来增强视觉语言模型（VLM）在零样本动作识别方面的能力，通过引入时空交互模块来关注对象和动作单元，从而解决多义词带来的歧义性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言模型（VLM）在零样本动作识别中，仅依赖动作类别进行语义关联时，由于多义词的存在而产生的歧义性问题。

Method: 利用网络爬取的大量描述，结合大语言模型提取相关关键词，并设计一个时空交互模块来关注对象和动作单元，以实现描述属性和视频内容之间的对齐。

Result: 在UCF-101、HMDB-51和Kinetics-600数据集上，该模型在零样本场景下分别达到了81.0%、53.1%和68.9%的准确率。

Conclusion: 提出的方法通过利用网络爬取描述和关键词提取，并结合时空交互模块，有效解决了VLM在零样本动作识别中的歧义性问题，并在多个数据集上取得了优异的性能。

Abstract: Vision-Language Models (VLMs) have demonstrated impressive capabilities in
zero-shot action recognition by learning to associate video embeddings with
class embeddings. However, a significant challenge arises when relying solely
on action classes to provide semantic context, particularly due to the presence
of multi-semantic words, which can introduce ambiguity in understanding the
intended concepts of actions. To address this issue, we propose an innovative
approach that harnesses web-crawled descriptions, leveraging a large-language
model to extract relevant keywords. This method reduces the need for human
annotators and eliminates the laborious manual process of attribute data
creation. Additionally, we introduce a spatio-temporal interaction module
designed to focus on objects and action units, facilitating alignment between
description attributes and video content. In our zero-shot experiments, our
model achieves impressive results, attaining accuracies of 81.0%, 53.1%, and
68.9% on UCF-101, HMDB-51, and Kinetics-600, respectively, underscoring the
model's adaptability and effectiveness across various downstream tasks.

</details>


### [41] [RegionRAG: Region-level Retrieval-Augumented Generation for Visually-Rich Documents](https://arxiv.org/abs/2510.27261)
*Yinglu Li,Zhiying Lu,Zhihang Liu,Chuanbin Liu,Hongtao Xie*

Main category: cs.CV

TL;DR: 多模态检索增强生成（RAG）将检索单元从文档级别提升到区域级别，通过只关注显著的图像块来提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态 RAG 方法以整个文档为检索单元，导致检索到的内容包含大量无关信息，稀释了模型对关键信息的关注，并且检索多个文档会引入更多冗余，从而降低了模型性能。

Method: 提出了一种名为 RegionRAG 的新框架，将检索单位从文档级别改为区域级别。通过混合监督策略识别相关图像块，并采用动态流水线将显著图像块组合成完整的语义区域，使生成器能专注于与查询相关的、更精炼的视觉内容。

Result: RegionRAG 在六个基准测试中取得了最先进的性能，平均检索准确率（R@1）提高了 10.02%，问答准确率提高了 3.56%，同时使用的视觉标记数量减少了 28.58%（仅为 71.42%）。

Conclusion: RegionRAG 通过从文档级别检索转向区域级别检索，能够更有效地利用视觉内容，提高了多模态 RAG 的准确性和效率。

Abstract: Multi-modal Retrieval-Augmented Generation (RAG) has become a critical method
for empowering LLMs by leveraging candidate visual documents. However, current
methods consider the entire document as the basic retrieval unit, introducing
substantial irrelevant visual content in two ways: 1) Relevant documents often
contain large regions unrelated to the query, diluting the focus on salient
information; 2) Retrieving multiple documents to increase recall further
introduces redundant and irrelevant documents. These redundant contexts
distract the model's attention and further degrade the performance. To address
this challenge, we propose \modelname, a novel framework that shifts the
retrieval paradigm from the document level to the region level. During
training, we design a hybrid supervision strategy from both labeled data and
unlabeled data to pinpoint relevant patches. During inference, we propose a
dynamic pipeline that intelligently groups salient patches into complete
semantic regions. By delegating the task of identifying relevant regions to the
retriever, \modelname enables the generator to focus solely on concise visual
content relevant to queries, improving both efficiency and accuracy.
Experiments on six benchmarks demonstrate that RegionRAG achieves
state-of-the-art performance. Improves retrieval accuracy by 10.02\% in R@1 on
average and increases question answering accuracy by 3.56\% while using only
71.42\% visual tokens compared to prior methods. The code will be available at
https://github.com/Aeryn666/RegionRAG.

</details>


### [42] [T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis](https://arxiv.org/abs/2510.27265)
*Raza Imam,Hu Wang,Dwarikanath Mahapatra,Mohammad Yaqub*

Main category: cs.CV

TL;DR: T^3是一种无需反向传播的框架，通过计算Jensen-Shannon散度来为每个样本计算模型合并系数，解决了现有模型合并技术在医学影像领域存在的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练模型和微调模型在医学影像任务中各有优缺点，现有模型合并技术无法有效解决医学模态的差异性。T^3旨在解决这一问题，实现动态模型合并，提高在各种临床任务中的可靠性。

Method: T^3通过Jensen-Shannon散度计算模型输出分布之间的差异，为每个样本生成动态合并系数，从而实现自适应合并。此外，还提出了T^3_B，通过批量计算合并系数来降低计算成本。

Result: T^3在Top-1准确率和误差减少方面取得了新的最先进成果，在四个模态的各种场景下都优于现有基线模型，同时保持了效率。

Conclusion: T^3提供了一种高效且有效的医学影像模型合并方法，能够适应不同的临床任务和模态，为多模态医学影像模型在临床中的应用铺平了道路。

Abstract: In medical imaging, vision-language models face a critical duality:
pretrained networks offer broad robustness but lack subtle, modality-specific
characteristics, while fine-tuned expert models achieve high in-distribution
accuracy yet falter under modality shift. Existing model-merging techniques,
designed for natural-image benchmarks, are simple and efficient but fail to
deliver consistent gains across diverse medical modalities; their static
interpolation limits reliability in varied clinical tasks. To address this, we
introduce Test-Time Task adaptive merging (T^3), a backpropagation-free
framework that computes per-sample interpolation coefficients via the
Jensen-Shannon divergence between the two models' output distributions. T^3
dynamically preserves local precision when models agree and defers to
generalist robustness under drift. To overcome the inference costs of
sample-wise merging, we further propose a batch-wise extension, T^3_B, that
computes a merging coefficient across a batch of samples, dramatically reducing
computational bottleneck. Recognizing the lack of a standardized
medical-merging benchmark, we present a rigorous cross-evaluation protocol
spanning in-domain, base-to-novel, and corruptions across four modalities.
Empirically, T^3 sets new state-of-the-art in Top-1 accuracy and error
reduction, outperforming strong baselines while maintaining efficiency, paving
the way for adaptive MVLM deployment in clinical settings. Our code is
available at https://github.com/Razaimam45/TCube.

</details>


### [43] [HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration](https://arxiv.org/abs/2510.27266)
*Shaojie Zhang,Pei Fu,Ruoceng Zhang,Jiahui Yang,Anan Du,Xiuwen Xi,Shaokang Wang,Ying Huang,Bin Qin,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 自主GUI代理需要准确的GUI基础，即将语言指令映射到屏幕坐标以执行用户命令。然而，当前模型（无论是通过监督微调SFT还是强化微调RFT）都缺乏对其能力边界的自我意识，导致过度自信和不可靠的预测。本研究首先系统地评估了通用和GUI特定模型中的概率和语言化置信度，揭示了置信度与实际准确性之间的不一致，这在动态GUI自动化任务中尤其关键，因为单次错误可能导致任务失败。为解决此问题，我们提出了HyperClick，一个通过不确定性校准增强可靠GUI基础的新框架。HyperClick引入了双重奖励机制，结合了用于正确操作的二元奖励和基于截断高斯的空间置信度建模，并使用Brier分数进行校准。该方法联合优化了基础准确性和置信度可靠性，促进了内省的自我批评。在七个挑战性基准上的广泛实验表明，HyperClick在提供良好校准的置信度的同时，实现了最先进的性能。通过实现显式的置信度校准和内省的自我批评，HyperClick减少了过度自信，并支持更可靠的GUI自动化。


<details>
  <summary>Details</summary>
Motivation: 当前模型缺乏对自身能力边界的认知，导致过度自信和不可靠的预测，尤其是在动态GUI自动化任务中，这可能导致单次错误就造成任务失败。

Method: 提出了一种名为HyperClick的新框架，通过不确定性校准来增强可靠的GUI基础。该框架引入了一个双重奖励机制，结合了用于正确操作的二元奖励和基于截断高斯的空间置信度建模，并使用Brier分数进行校准，以联合优化基础准确性和置信度可靠性。

Result: 在七个挑战性基准上的广泛实验表明，HyperClick在提供良好校准的置信度的同时，实现了最先进的性能。该方法有效地减少了过度自信，并支持更可靠的GUI自动化。

Conclusion: HyperClick通过实现显式的置信度校准和内省的自我批评，克服了当前GUI基础模型过度自信的问题，提高了GUI自动化的可靠性。

Abstract: Autonomous Graphical User Interface (GUI) agents rely on accurate GUI
grounding, which maps language instructions to on-screen coordinates, to
execute user commands. However, current models, whether trained via supervised
fine-tuning (SFT) or reinforcement fine-tuning (RFT), lack self-awareness of
their capability boundaries, leading to overconfidence and unreliable
predictions. We first systematically evaluate probabilistic and verbalized
confidence in general and GUI-specific models, revealing a misalignment between
confidence and actual accuracy, which is particularly critical in dynamic GUI
automation tasks, where single errors can cause task failure. To address this,
we propose HyperClick, a novel framework that enhances reliable GUI grounding
through uncertainty calibration. HyperClick introduces a dual reward mechanism,
combining a binary reward for correct actions with a truncated Gaussian-based
spatial confidence modeling, calibrated using the Brier score. This approach
jointly optimizes grounding accuracy and confidence reliability, fostering
introspective self-criticism. Extensive experiments on seven challenge
benchmarks show that HyperClick achieves state-of-the-art performance while
providing well-calibrated confidence. By enabling explicit confidence
calibration and introspective self-criticism, HyperClick reduces overconfidence
and supports more reliable GUI automation.

</details>


### [44] [FOCUS: Efficient Keyframe Selection for Long Video Understanding](https://arxiv.org/abs/2510.27280)
*Zirui Zhu,Hailun Xu,Yang Luo,Yong Liu,Kanchan Sarkar,Zhenheng Yang,Yang You*

Main category: cs.CV

TL;DR: FOCUS是一种训练免费、模型无关的关键帧选择方法，用于解决多模态大语言模型(MLLM)处理长视频时遇到的token预算限制问题。它将关键帧选择视为组合纯探索(CPE)问题，通过探索和利用策略来识别信息丰富的帧，从而在不牺牲准确性的情况下显著减少处理的帧数。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型(MLLM)在处理长视频时面临token预算限制，现有的关键帧选择方法要么均匀采样，要么依赖预过滤和小型模型进行检索式评分，可能错过重要信息。因此，需要一种更有效、无需训练且模型无关的关键帧选择方法来解决这个问题。

Method: FOCUS将关键帧选择建模为多臂老虎机中的组合纯探索(CPE)问题。它将短时间片段视为“臂”，并利用经验均值和伯恩斯坦置信半径来识别信息区域，同时探索不确定的区域。该方法包括一个两阶段的探索-利用过程：首先识别高价值的时间区域，然后在每个区域内选择得分最高的帧。

Result: 在两个长视频问答基准测试中，FOCUS在处理少于2%的视频帧的情况下，显著提高了准确性。对于超过20分钟的视频，在LongVideoBench上准确性提高了11.9%。

Conclusion: FOCUS是一种有效、通用且无需训练的关键帧选择模块，可以为MLLM提供可扩展的长视频理解解决方案，在严格的token预算下有效识别查询相关帧，并在长视频问答任务中取得显著的准确性提升。

Abstract: Multimodal large language models (MLLMs) represent images and video frames as
visual tokens. Scaling from single images to hour-long videos, however,
inflates the token budget far beyond practical limits. Popular pipelines
therefore either uniformly subsample or apply keyframe selection with
retrieval-style scoring using smaller vision-language models. However, these
keyframe selection methods still rely on pre-filtering before selection to
reduce the inference cost and can miss the most informative moments.
  We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a
training-free, model-agnostic keyframe selection module that selects
query-relevant frames under a strict token budget. FOCUS formulates keyframe
selection as a combinatorial pure-exploration (CPE) problem in multi-armed
bandits: it treats short temporal clips as arms, and uses empirical means and
Bernstein confidence radius to identify informative regions while preserving
exploration of uncertain areas. The resulting two-stage
exploration-exploitation procedure reduces from a sequential policy with
theoretical guarantees, first identifying high-value temporal regions, then
selecting top-scoring frames within each region On two long-video
question-answering benchmarks, FOCUS delivers substantial accuracy improvements
while processing less than 2% of video frames. For videos longer than 20
minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating
its effectiveness as a keyframe selection method and providing a simple and
general solution for scalable long-video understanding with MLLMs.

</details>


### [45] [Rethinking Robust Adversarial Concept Erasure in Diffusion Models](https://arxiv.org/abs/2510.27285)
*Qinghong Yin,Yu Tian,Yue Zhang*

Main category: cs.CV

TL;DR: S-GRACE通过利用概念空间中的语义引导来生成对抗性样本并执行擦除训练，从而解决现有概念擦除方法在扩散模型中存在的问题。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法在扩散模型中未能充分考虑对抗性训练的特异性，导致擦除效果不理想，要么无法全面覆盖目标概念，要么会干扰其他概念空间。

Method: 提出S-GRACE（Semantics-Guided Robust Adversarial Concept Erasure）方法，利用概念空间中的语义引导来生成对抗性样本，并进行擦除训练。

Result: 实验表明，S-GRACE在扩散模型概念擦除任务上表现优于七种现有最先进方法和三种对抗性提示生成策略，擦除性能提升26%，能更好地保留非目标概念，并能将训练时间缩短90%。

Conclusion: S-GRACE通过语义引导显著提高了扩散模型概念擦除的性能和鲁棒性，同时降低了计算成本。

Abstract: Concept erasure aims to selectively unlearning undesirable content in
diffusion models (DMs) to reduce the risk of sensitive content generation. As a
novel paradigm in concept erasure, most existing methods employ adversarial
training to identify and suppress target concepts, thus reducing the likelihood
of sensitive outputs. However, these methods often neglect the specificity of
adversarial training in DMs, resulting in only partial mitigation. In this
work, we investigate and quantify this specificity from the perspective of
concept space, i.e., can adversarial samples truly fit the target concept
space? We observe that existing methods neglect the role of conceptual
semantics when generating adversarial samples, resulting in ineffective fitting
of concept spaces. This oversight leads to the following issues: 1) when there
are few adversarial samples, they fail to comprehensively cover the object
concept; 2) conversely, they will disrupt other target concept spaces.
Motivated by the analysis of these findings, we introduce S-GRACE
(Semantics-Guided Robust Adversarial Concept Erasure), which grace leveraging
semantic guidance within the concept space to generate adversarial samples and
perform erasure training. Experiments conducted with seven state-of-the-art
methods and three adversarial prompt generation strategies across various DM
unlearning scenarios demonstrate that S-GRACE significantly improves erasure
performance 26%, better preserves non-target concepts, and reduces training
time by 90%. Our code is available at https://github.com/Qhong-522/S-GRACE.

</details>


### [46] [Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba](https://arxiv.org/abs/2510.27296)
*Wenfeng Huang,Xiangyun Liao,Wei Cao,Wenjing Jia,Weixin Si*

Main category: cs.CV

TL;DR: FGMamba是一种轻量级的模型，通过结合状态空间模型和注意力机制，能够同时处理长距离解剖结构和高频细节，在多种医学成像模态中实现了优于现有方法的超分辨率效果。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像超分辨率方法在处理长距离解剖结构和高频细节时存在计算开销大的挑战。

Method: 提出了一种名为FGMamba的新型频率感知门控状态空间模型，该模型包含门控注意力增强状态空间模块（GASM）和金字塔频率融合模块（PFFM），前者结合了状态空间模型和注意力机制，后者则通过FFT引导的融合来捕捉多分辨率的高频细节。

Result: 在超声、OCT、MRI、CT和内窥镜五种医学成像模态上的广泛评估显示，FGMamba在保持较小参数量（<0.75M）的同时，实现了优于CNN和Transformer等当前最优方法的PSNR/SSIM指标。

Conclusion: 频率感知状态空间建模对于可扩展和准确的医学图像增强是有效的。

Abstract: Medical image super-resolution (SR) is essential for enhancing diagnostic
accuracy while reducing acquisition cost and scanning time. However, modeling
both long-range anatomical structures and fine-grained frequency details with
low computational overhead remains challenging. We propose FGMamba, a novel
frequency-aware gated state-space model that unifies global dependency modeling
and fine-detail enhancement into a lightweight architecture. Our method
introduces two key innovations: a Gated Attention-enhanced State-Space Module
(GASM) that integrates efficient state-space modeling with dual-branch spatial
and channel attention, and a Pyramid Frequency Fusion Module (PFFM) that
captures high-frequency details across multiple resolutions via FFT-guided
fusion. Extensive evaluations across five medical imaging modalities
(Ultrasound, OCT, MRI, CT, and Endoscopic) demonstrate that FGMamba achieves
superior PSNR/SSIM while maintaining a compact parameter footprint ($<$0.75M),
outperforming CNN-based and Transformer-based SOTAs. Our results validate the
effectiveness of frequency-aware state-space modeling for scalable and accurate
medical image enhancement.

</details>


### [47] [CASR-Net: An Image Processing-focused Deep Learning-based Coronary Artery Segmentation and Refinement Network for X-ray Coronary Angiogram](https://arxiv.org/abs/2510.27315)
*Alvee Hassan,Rusab Sarmun,Muhammad E. H. Chowdhury,M. Murugappan,Md. Sakib Abrar Hossain,Sakib Mahmud,Abdulrahman Alqahtani,Sohaib Bassam Zoghoul,Amith Khandakar,Susu M. Zughaier,Somaya Al-Maadeed,Anwarul Hasan*

Main category: cs.CV

TL;DR: CASR-Net是一个用于冠状动脉疾病（CAD）检测的自动化三阶段分割和精炼网络，提高了分割精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 早期检测冠状动脉疾病（CAD）对于降低死亡率和改善患者治疗计划至关重要。然而，X射线造影图像的低质量会严重影响临床诊断。本研究旨在提出一种改进的冠状动脉分割方法，以克服这些挑战。

Method: CASR-Net包含三个阶段：1. 图像预处理：采用结合CLAHE和改进Ben Graham方法的串联预处理策略。2. 分割：使用基于UNet的分割网络，其编码器为DenseNet121，解码器为基于自组织操作神经网络（Self-ONN）的模型，以保持狭窄血管分支的连续性。3. 精炼：通过最终的轮廓精炼模块进一步消除虚假阳性。

Result: CASR-Net在包含健康和狭窄动脉的两个公共数据集上进行了5倍交叉验证。与现有模型相比，CASR-Net在IoU（61.43%）、DSC（76.10%）和clDice（79.36%）方面表现更优。

Conclusion: CASR-Net在自动化冠状动脉分割方面提供了一种强大的方法，通过其创新的多阶段处理流水线，提高了分割精度和对狭窄血管的连续性保持能力，有望为临床诊断和治疗规划提供有价值的工具。

Abstract: Early detection of coronary artery disease (CAD) is critical for reducing
mortality and improving patient treatment planning. While angiographic image
analysis from X-rays is a common and cost-effective method for identifying
cardiac abnormalities, including stenotic coronary arteries, poor image quality
can significantly impede clinical diagnosis. We present the Coronary Artery
Segmentation and Refinement Network (CASR-Net), a three-stage pipeline
comprising image preprocessing, segmentation, and refinement. A novel
multichannel preprocessing strategy combining CLAHE and an improved Ben Graham
method provides incremental gains, increasing Dice Score Coefficient (DSC) by
0.31-0.89% and Intersection over Union (IoU) by 0.40-1.16% compared with using
the techniques individually. The core innovation is a segmentation network
built on a UNet with a DenseNet121 encoder and a Self-organized Operational
Neural Network (Self-ONN) based decoder, which preserves the continuity of
narrow and stenotic vessel branches. A final contour refinement module further
suppresses false positives. Evaluated with 5-fold cross-validation on a
combination of two public datasets that contain both healthy and stenotic
arteries, CASR-Net outperformed several state-of-the-art models, achieving an
IoU of 61.43%, a DSC of 76.10%, and clDice of 79.36%. These results highlight a
robust approach to automated coronary artery segmentation, offering a valuable
tool to support clinicians in diagnosis and treatment planning.

</details>


### [48] [Overcoming Prompts Pool Confusion via Parameterized Prompt for Incremental Object Detection](https://arxiv.org/abs/2510.27316)
*Zijia An,Boyu Diao,Ruiqi Liu,Libo Huang,Chuanguang Yang,Fei Wang,Zhulin An,Yongjun Xu*

Main category: cs.CV

TL;DR: 现有的增量物体检测方法在处理类别不分离的增量任务时存在局限性。本文提出的 P^2IOD 方法通过参数化提示和参数化提示融合策略，实现了跨任务的知识自适应整合和约束更新，有效解决了该问题，并在 PASCAL VOC2007 和 MS COCO 数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有增量物体检测（IOD）方法在处理包含跨任务共现物体的图像时存在不足，因为它们通常假设任务之间类别不分离，这可能导致提示池中的混淆。

Method: 提出了一种名为参数化提示的增量物体检测（P$^2$IOD）的方法。该方法利用神经网络的全局演化特性，将网络本身作为参数化提示，以实现跨任务的知识自适应整合。此外，还引入了一种参数化提示融合策略来约束提示结构的更新，以防止灾难性遗忘。

Result: 在 PASCAL VOC2007 和 MS COCO 数据集上进行的大量实验表明，P$^2$IOD 在增量物体检测方面是有效的，并且在现有基线方法中取得了最先进的性能。

Conclusion: P$^2$IOD 通过参数化提示和参数化提示融合策略，能够有效地解决增量物体检测中类别共现的问题，并实现跨任务的知识自适应整合和约束更新，从而达到最先进的性能。

Abstract: Recent studies have demonstrated that incorporating trainable prompts into
pretrained models enables effective incremental learning. However, the
application of prompts in incremental object detection (IOD) remains
underexplored. Existing prompts pool based approaches assume disjoint class
sets across incremental tasks, which are unsuitable for IOD as they overlook
the inherent co-occurrence phenomenon in detection images. In co-occurring
scenarios, unlabeled objects from previous tasks may appear in current task
images, leading to confusion in prompts pool. In this paper, we hold that
prompt structures should exhibit adaptive consolidation properties across
tasks, with constrained updates to prevent catastrophic forgetting. Motivated
by this, we introduce Parameterized Prompts for Incremental Object Detection
(P$^2$IOD). Leveraging neural networks global evolution properties, P$^2$IOD
employs networks as the parameterized prompts to adaptively consolidate
knowledge across tasks. To constrain prompts structure updates, P$^2$IOD
further engages a parameterized prompts fusion strategy. Extensive experiments
on PASCAL VOC2007 and MS COCO datasets demonstrate that P$^2$IOD's
effectiveness in IOD and achieves the state-of-the-art performance among
existing baselines.

</details>


### [49] [SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction](https://arxiv.org/abs/2510.27318)
*Wenfeng Huang,Xiangyun Liao,Yinling Qian,Hao Liu,Yongming Yang,Wenjing Jia,Qiong Wang*

Main category: cs.CV

TL;DR: SAGS 是一种自适应的无别名高斯泼溅框架，用于解决内窥镜视频中可变形组织重建的伪影和失真问题。


<details>
  <summary>Details</summary>
Motivation: 内窥镜视频中的动态组织重建在机器人辅助手术中至关重要，但现有基于 NeRF 和 3DGS 的方法在处理组织运动引起的别名和伪影方面存在不足，影响了可视化质量。

Method: 提出了一种名为 SAGS 的自适应无别名高斯泼溅框架，引入了注意力驱动的动态加权 4D 变形解码器，并结合了 3D 平滑滤波器和 2D Mip 滤波器来减少伪影并捕捉组织运动的细节。

Result: 在 EndoNeRF 和 SCARED 公共基准测试中，SAGS 在 PSNR、SSIM 和 LPIPS 等所有指标上均优于现有技术，并提供了更好的可视化质量。

Conclusion: SAGS 框架通过其创新的变形解码器和滤波机制，有效解决了可变形组织重建中的伪影和失真问题，显著提高了重建的准确性和可视化效果，为机器人辅助手术提供了更好的解决方案。

Abstract: Surgical reconstruction of dynamic tissues from endoscopic videos is a
crucial technology in robot-assisted surgery. The development of Neural
Radiance Fields (NeRFs) has greatly advanced deformable tissue reconstruction,
achieving high-quality results from video and image sequences. However,
reconstructing deformable endoscopic scenes remains challenging due to aliasing
and artifacts caused by tissue movement, which can significantly degrade
visualization quality. The introduction of 3D Gaussian Splatting (3DGS) has
improved reconstruction efficiency by enabling a faster rendering pipeline.
Nevertheless, existing 3DGS methods often prioritize rendering speed while
neglecting these critical issues. To address these challenges, we propose SAGS,
a self-adaptive alias-free Gaussian splatting framework. We introduce an
attention-driven, dynamically weighted 4D deformation decoder, leveraging 3D
smoothing filters and 2D Mip filters to mitigate artifacts in deformable tissue
reconstruction and better capture the fine details of tissue movement.
Experimental results on two public benchmarks, EndoNeRF and SCARED, demonstrate
that our method achieves superior performance in all metrics of PSNR, SSIM, and
LPIPS compared to the state of the art while also delivering better
visualization quality.

</details>


### [50] [Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis](https://arxiv.org/abs/2510.27324)
*Weiming Chen,Yijia Wang,Zhihan Zhu,Zhihai He*

Main category: cs.CV

TL;DR: 我们提出了一种结合图像生成和深度图像压缩的方法，通过文本和编码潜在信息来精确重建视觉场景，能在极低比特率下实现与现有方法相当的图像重建质量和视觉分析精度。


<details>
  <summary>Details</summary>
Motivation: 在深空探索、战场情报和机器人导航等低通信带宽场景下，实现超低比特率的视觉通信，以支持远程视觉分析、人机交互和控制。

Method: 将图像生成与深度图像压缩相结合，利用联合文本和编码潜在信息来指导变分流模型进行精确的视觉场景生成，并将文本描述和编码潜在信息以极小的比特率传输到解码器。

Result: 实验结果表明，我们提出的方法在实现相同图像重建质量和视觉分析精度的同时，显著降低了通信带宽。

Conclusion: 该方法能够有效地在超低比特率下进行视觉通信，满足远程视觉分析和人机交互的需求，并在不牺牲精度的前提下大大降低了带宽要求。

Abstract: We consider the problem of ultra-low bit rate visual communication for remote
vision analysis, human interactions and control in challenging scenarios with
very low communication bandwidth, such as deep space exploration, battlefield
intelligence, and robot navigation in complex environments. In this paper, we
ask the following important question: can we accurately reconstruct the visual
scene using only a very small portion of the bit rate in existing coding
methods while not sacrificing the accuracy of vision analysis and performance
of human interactions? Existing text-to-image generation models offer a new
approach for ultra-low bitrate image description. However, they can only
achieve a semantic-level approximation of the visual scene, which is far
insufficient for the purpose of visual communication and remote vision analysis
and human interactions. To address this important issue, we propose to
seamlessly integrate image generation with deep image compression, using joint
text and coding latent to guide the rectified flow models for precise
generation of the visual scene. The semantic text description and coding latent
are both encoded and transmitted to the decoder at a very small bit rate.
Experimental results demonstrate that our method can achieve the same image
reconstruction quality and vision analysis accuracy as existing methods while
using much less bandwidth. The code will be released upon paper acceptance.

</details>


### [51] [MeisenMeister: A Simple Two Stage Pipeline for Breast Cancer Classification on MRI](https://arxiv.org/abs/2510.27326)
*Benjamin Hamm,Yannick Kirchhoff,Maximilian Rokuss,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: ODELIA Breast MRI Challenge 2025 旨在通过提高乳腺 MRI 扫描解释的效率和准确性来改进乳腺癌筛查的早期检测。由于高质量分割标签的可用性有限，开发基于分类的方法对于大规模筛查等应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 提高乳腺癌筛查中乳腺 MRI 扫描解释的效率和准确性，以改进早期检测。

Method: 详细介绍概念、基础假设、迭代开发过程（实验、评估、改进），并解释最终提交的设计选择，重点关注性能、鲁棒性和临床相关性。

Result: 未在摘要中明确说明具体结果，但暗示已开发出一种用于 ODELIA Breast MRI Challenge 2025 的方法。

Conclusion: 基于分类的方法对于大规模筛查等应用中的早期乳腺癌检测至关重要。

Abstract: The ODELIA Breast MRI Challenge 2025 addresses a critical issue in breast
cancer screening: improving early detection through more efficient and accurate
interpretation of breast MRI scans. Even though methods for general-purpose
whole-body lesion segmentation as well as multi-time-point analysis exist,
breast cancer detection remains highly challenging, largely due to the limited
availability of high-quality segmentation labels. Therefore, developing robust
classification-based approaches is crucial for the future of early breast
cancer detection, particularly in applications such as large-scale screening.
In this write-up, we provide a comprehensive overview of our approach to the
challenge. We begin by detailing the underlying concept and foundational
assumptions that guided our work. We then describe the iterative development
process, highlighting the key stages of experimentation, evaluation, and
refinement that shaped the evolution of our solution. Finally, we present the
reasoning and evidence that informed the design choices behind our final
submission, with a focus on performance, robustness, and clinical relevance. We
release our full implementation publicly at
https://github.com/MIC-DKFZ/MeisenMeister

</details>


### [52] [Understanding the Implicit User Intention via Reasoning with Large Language Model for Image Editing](https://arxiv.org/abs/2510.27335)
*Yijia Wang,Yiqing Shen,Weiming Chen,Zhihai He*

Main category: cs.CV

TL;DR: CIELR是一种通过LLM推理将复杂图像编辑指令分解为简单编辑动作的新方法，无需联合微调LLM和DM，在PSNR上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法在处理复杂编辑指令时，需要联合微调LLM和DM，计算复杂且成本高。CIELR旨在解决此问题。

Method: CIELR首先使用基础模型构建输入图像的结构化语义表示，然后通过迭代更新机制逐步优化该表示，以获得图像场景的细粒度视觉表示，从而实现复杂灵活的图像编辑。

Result: 在SmartEdit推理场景数据集上，CIELR在PSNR上比现有最优方法提高了9.955 dB，表明其在保持应保持一致的区域方面具有优越性。此外，CIELR还在新构建的CIEBench基准上优于现有方法。

Conclusion: CIELR通过LLM推理将复杂指令分解为简单动作，有效解决了现有方法在处理复杂图像编辑指令时面临的计算复杂性和成本问题，并在性能上取得了显著提升。

Abstract: Existing image editing methods can handle simple editing instructions very
well. To deal with complex editing instructions, they often need to jointly
fine-tune the large language models (LLMs) and diffusion models (DMs), which
involves very high computational complexity and training cost. To address this
issue, we propose a new method, called \textbf{C}omplex \textbf{I}mage
\textbf{E}diting via \textbf{L}LM \textbf{R}easoning (CIELR), which converts a
complex user instruction into a set of simple and explicit editing actions,
eliminating the need for jointly fine-tuning the large language models and
diffusion models. Specifically, we first construct a structured semantic
representation of the input image using foundation models. Then, we introduce
an iterative update mechanism that can progressively refine this
representation, obtaining a fine-grained visual representation of the image
scene. This allows us to perform complex and flexible image editing tasks.
Extensive experiments on the SmartEdit Reasoning Scenario Set show that our
method surpasses the previous state-of-the-art by 9.955 dB in PSNR, indicating
its superior preservation of regions that should remain consistent. Due to the
limited number of samples of public datasets of complex image editing with
reasoning, we construct a benchmark named CIEBench, containing 86 image
samples, together with a metric specifically for reasoning-based image editing.
CIELR also outperforms previous methods on this benchmark. The code and dataset
are available at
\href{https://github.com/Jia-shao/Reasoning-Editing}{https://github.com/Jia-shao/Reasoning-Editing}.

</details>


### [53] [RzenEmbed: Towards Comprehensive Multimodal Retrieval](https://arxiv.org/abs/2510.27350)
*Weijian Jian,Yajun Zhang,Dawei Liang,Chunyu Xie,Yixiao He,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: RzenEmbed是一个统一的框架，用于学习跨文本、图像、视频和视觉文档的嵌入，解决了现有方法在多模态检索方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的框架主要关注自然图像，对视频和视觉文档等其他视觉模态的支持有限，因此需要一个能处理更多样化模态的统一框架。

Method: RzenEmbed采用新颖的两阶段训练策略：第一阶段进行基础的文本和多模态检索训练；第二阶段引入改进的InfoNCE损失，包括硬样本加权机制以优先处理难例，以及缓解虚假负样本和数据噪声的方法。此外，还使用了可学习的温度参数和模型融合技术来进一步提升性能。

Result: RzenEmbed在MMEB基准测试中设定了新的最先进水平，在整体得分上表现最佳，并在具有挑战性的视频和视觉文档检索任务上超越了所有先前的工作。

Conclusion: RzenEmbed成功地学习了跨多种模态（包括文本、图像、视频和视觉文档）的区分性表示，显著提高了跨模态检索的性能，尤其是在视频和视觉文档检索方面，并展示了其优越的指令遵循能力。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has
extended CLIP-based frameworks to produce powerful, universal embeddings for
retrieval tasks. However, existing methods primarily focus on natural images,
offering limited support for other crucial visual modalities such as videos and
visual documents. To bridge this gap, we introduce RzenEmbed, a unified
framework to learn embeddings across a diverse set of modalities, including
text, images, videos, and visual documents. We employ a novel two-stage
training strategy to learn discriminative representations. The first stage
focuses on foundational text and multimodal retrieval. In the second stage, we
introduce an improved InfoNCE loss, incorporating two key enhancements.
Firstly, a hardness-weighted mechanism guides the model to prioritize
challenging samples by assigning them higher weights within each batch.
Secondly, we implement an approach to mitigate the impact of false negatives
and alleviate data noise. This strategy not only enhances the model's
discriminative power but also improves its instruction-following capabilities.
We further boost performance with learnable temperature parameter and model
souping. RzenEmbed sets a new state-of-the-art on the MMEB benchmark. It not
only achieves the best overall score but also outperforms all prior work on the
challenging video and visual document retrieval tasks. Our models are available
in https://huggingface.co/qihoo360/RzenEmbed.

</details>


### [54] [FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning](https://arxiv.org/abs/2510.27359)
*Kenneth Yang,Wen-Li Wei,Jen-Chun Lin*

Main category: cs.CV

TL;DR: Feedforward-based Parameter Selection (FPS) is a gradient-free method that efficiently fine-tunes large models by selecting optimal parameter subsets in a single forward pass. It significantly reduces memory usage and speeds up selection compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing Parameter-Efficient Fine-Tuning (PEFT) methods like Adapters and Gradient-based Parameter Selection (GPS) have limitations: Adapters add latency and complexity, while GPS requires a full backward pass, leading to high memory usage. There is a need for a more memory-efficient and practical PEFT solution.

Method: Feedforward-based Parameter Selection (FPS) ranks parameters based on the product of their magnitudes and corresponding input activations. This allows it to identify an optimal parameter subset in a single forward pass without requiring a backward pass, making it gradient-free.

Result: Evaluated on 24 visual tasks from FGVC and VTAB-1k, FPS achieved performance comparable to state-of-the-art methods. It reduced peak memory usage by approximately 9 times and accelerated parameter selection by about 2 times.

Conclusion: FPS offers a genuinely memory-efficient and practical solution for fine-tuning large-scale pre-trained models, outperforming existing methods in terms of memory usage and speed while maintaining competitive performance.

Abstract: Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key strategy for
adapting large-scale pre-trained models to downstream tasks, but existing
approaches face notable limitations. Addition-based methods, such as Adapters
[1], introduce inference latency and engineering complexity, while
selection-based methods like Gradient-based Parameter Selection (GPS) [2]
require a full backward pass, which results in the same peak memory usage as
full fine-tuning. To address this dilemma, we propose Feedforward-based
Parameter Selection (FPS), a gradient-free method that identifies an optimal
parameter subset in a single forward pass. FPS ranks parameters by the product
of their magnitudes and corresponding input activations, leveraging both
pre-trained knowledge and downstream data. Evaluated on $24$ visual tasks from
FGVC and VTAB-1k, FPS achieves performance comparable to state-of-the-art
methods while reducing peak memory usage by nearly $9 \times$ and accelerating
parameter selection by about $2 \times$, offering a genuinely memory-efficient
and practical solution for fine-tuning large-scale pre-trained models.

</details>


### [55] [Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V](https://arxiv.org/abs/2510.27364)
*Meftun Akarsu,Kerem Catay,Sedat Bin Vedat,Enes Kutay Yarkan,Ilke Senturk,Arda Sar,Dafne Eksioglu*

Main category: cs.CV

TL;DR: 本研究提出了一种用于影视制作的视频生成管线，通过两阶段微调开源视频扩散模型，实现了从少量数据合成电影感场景。


<details>
  <summary>Details</summary>
Motivation: 为了实现从少量数据合成具有电影感的视频，以满足影视制作的需求。

Method: 研究提出了一种两阶段方法：第一阶段，使用 LoRA 模块在少量视频片段上微调 Wan2.1 I2V-14B 模型，以学习视觉风格；第二阶段，利用微调后的模型生成关键帧，并通过视频解码器扩展为连贯的视频序列。同时，采用轻量化并行化和序列分区策略加速推理。

Result: 通过 FVD、CLIP-SIM 和 LPIPS 指标以及用户研究，证明了该方法在电影感保真度和时间稳定性方面优于基线模型。

Conclusion: 所提出的两阶段微调方法能够有效地从少量数据生成具有电影感的视频，并且提出的训练和推理管线支持可复现性和跨领域应用。

Abstract: We present a practical pipeline for fine-tuning open-source video diffusion
transformers to synthesize cinematic scenes for television and film production
from small datasets. The proposed two-stage process decouples visual style
learning from motion generation. In the first stage, Low-Rank Adaptation (LoRA)
modules are integrated into the cross-attention layers of the Wan2.1 I2V-14B
model to adapt its visual representations using a compact dataset of short
clips from Ay Yapim's historical television film El Turco. This enables
efficient domain transfer within hours on a single GPU. In the second stage,
the fine-tuned model produces stylistically consistent keyframes that preserve
costume, lighting, and color grading, which are then temporally expanded into
coherent 720p sequences through the model's video decoder. We further apply
lightweight parallelization and sequence partitioning strategies to accelerate
inference without quality degradation. Quantitative and qualitative evaluations
using FVD, CLIP-SIM, and LPIPS metrics, supported by a small expert user study,
demonstrate measurable improvements in cinematic fidelity and temporal
stability over the base model. The complete training and inference pipeline is
released to support reproducibility and adaptation across cinematic domains.

</details>


### [56] [Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds](https://arxiv.org/abs/2510.27391)
*Wu Wei,Xiaomeng Fan,Yuwei Wu,Zhi Gao,Pengxiang Li,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种名为“Alignment across Trees”的新方法，通过构建和对齐图像和文本的树状分层特征来解决现有视觉语言模型（VLMs）在模态对齐方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的VLMs在提取文本分层特征的同时，将图像表示为单一特征，导致模态间对齐不对称且次优。

Method: 该方法首先通过跨注意力机制从Transformer中间层提取视觉特征，并利用文本线索指导提取具有粗粒度到细粒度语义的视觉特征。然后，将文本和图像的特征树嵌入到具有不同曲率的双曲流形中。最后，通过最小化异构双曲流形上分布之间的KL散度来对齐这些流形，并学习一个中间流形来实现对齐。

Result: 在多个图像数据集的分类任务的少样本和跨域设置下，该方法持续优于现有基线方法。

Conclusion: 提出的Alignment across Trees方法能够有效解决现有VLMs在模态对齐中的不足，并在实验中取得了优于基线方法的性能。

Abstract: Modality alignment is critical for vision-language models (VLMs) to
effectively integrate information across modalities. However, existing methods
extract hierarchical features from text while representing each image with a
single feature, leading to asymmetric and suboptimal alignment. To address
this, we propose Alignment across Trees, a method that constructs and aligns
tree-like hierarchical features for both image and text modalities.
Specifically, we introduce a semantic-aware visual feature extraction framework
that applies a cross-attention mechanism to visual class tokens from
intermediate Transformer layers, guided by textual cues to extract visual
features with coarse-to-fine semantics. We then embed the feature trees of the
two modalities into hyperbolic manifolds with distinct curvatures to
effectively model their hierarchical structures. To align across the
heterogeneous hyperbolic manifolds with different curvatures, we formulate a KL
distance measure between distributions on heterogeneous manifolds, and learn an
intermediate manifold for manifold alignment by minimizing the distance. We
prove the existence and uniqueness of the optimal intermediate manifold.
Experiments on taxonomic open-set classification tasks across multiple image
datasets demonstrate that our method consistently outperforms strong baselines
under few-shot and cross-domain settings.

</details>


### [57] [Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset](https://arxiv.org/abs/2510.27421)
*Aditya Parikh,Sneha Das,Aasa Feragen*

Main category: cs.CV

TL;DR: 深度学习模型在乳腺癌肿瘤分割中存在年龄和种族偏见，需要细粒度的数据审计。


<details>
  <summary>Details</summary>
Motivation: 评估深度学习模型在乳腺癌肿瘤分割任务中的公平性，特别是在分类任务之外的分割任务中，因为现有的公平性评估研究不足，可能导致对特定人群的医疗护理质量存在差异。

Method: 审计MAMA-MIA乳腺癌肿瘤分割数据集中自动化分割标签的公平性，评估模型在不同年龄、种族和数据来源下的分割质量。

Result: 发现模型存在针对年轻患者的年龄相关偏见，即使在控制了数据来源等混杂因素后仍然存在。数据来源的聚合会影响特定种族群体的偏见，表明需要对数据进行细粒度分析。

Conclusion: 深度学习模型在乳腺癌肿瘤分割中存在年龄和种族偏见，需要进行细粒度的数据审计，并考虑生理因素等潜在原因。

Abstract: Deep learning models aim to improve diagnostic workflows, but fairness
evaluation remains underexplored beyond classification, e.g., in image
segmentation. Unaddressed segmentation bias can lead to disparities in the
quality of care for certain populations, potentially compounded across clinical
decision points and amplified through iterative model development. Here, we
audit the fairness of the automated segmentation labels provided in the breast
cancer tumor segmentation dataset MAMA-MIA. We evaluate automated segmentation
quality across age, ethnicity, and data source. Our analysis reveals an
intrinsic age-related bias against younger patients that continues to persist
even after controlling for confounding factors, such as data source. We
hypothesize that this bias may be linked to physiological factors, a known
challenge for both radiologists and automated systems. Finally, we show how
aggregating data from multiple data sources influences site-specific ethnic
biases, underscoring the necessity of investigating data at a granular level.

</details>


### [58] [Mitigating Semantic Collapse in Partially Relevant Video Retrieval](https://arxiv.org/abs/2510.27432)
*WonJun Moon,MinSeok Jung,Gilhan Park,Tae-Young Kim,Cheol-Ho Cho,Woojin Jun,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 现有的部分相关视频检索方法在文本和视频嵌入空间中都存在语义坍塌问题，导致检索性能下降。本文提出了文本相关性保持学习和跨分支视频对齐（CBVA）来解决这个问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的部分相关视频检索（PRVR）方法将每个文本-视频对视为正面示例，忽略了同一视频内以及不同视频之间丰富的语义变化，导致文本和视频的嵌入表示发生语义坍塌，从而限制了检索性能。

Method: 本文首先引入文本相关性保持学习（Text Correlation Preservation Learning）来保持文本查询之间的语义关系。然后，提出跨分支视频对齐（Cross-Branch Video Alignment, CBVA）方法来解耦视频嵌入空间中的分层表示，并引入保持顺序的令牌合并和自适应CBVA来进一步优化对齐。

Result: 在PRVR基准上的大量实验表明，本文提出的框架能有效防止语义坍塌，并显著提高检索准确性。

Conclusion: 本文提出的框架通过文本相关性保持学习和跨分支视频对齐（CBVA）等方法，有效解决了部分相关视频检索中的语义坍塌问题，显著提升了检索性能。

Abstract: Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the
content matches a text query. Existing methods treat every annotated text-video
pair as a positive and all others as negatives, ignoring the rich semantic
variation both within a single video and across different videos. Consequently,
embeddings of both queries and their corresponding video-clip segments for
distinct events within the same video collapse together, while embeddings of
semantically similar queries and segments from different videos are driven
apart. This limits retrieval performance when videos contain multiple, diverse
events. This paper addresses the aforementioned problems, termed as semantic
collapse, in both the text and video embedding spaces. We first introduce Text
Correlation Preservation Learning, which preserves the semantic relationships
encoded by the foundation model across text queries. To address collapse in
video embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive
alignment method that disentangles hierarchical video representations across
temporal scales. Subsequently, we introduce order-preserving token merging and
adaptive CBVA to enhance alignment by producing video segments that are
internally coherent yet mutually distinctive. Extensive experiments on PRVR
benchmarks demonstrate that our framework effectively prevents semantic
collapse and substantially improves retrieval accuracy.

</details>


### [59] [DeblurSDI: Blind Image Deblurring Using Self-diffusion](https://arxiv.org/abs/2510.27439)
*Yanlong Yang,Guanxiong Luo*

Main category: cs.CV

TL;DR: DeblurSDI是一个基于自扩散（SDI）的零样本、自监督盲图像去模糊框架，无需预训练，通过迭代反向自扩散过程从噪声开始逐步优化得到清晰图像和模糊核，并采用噪声调度机制提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统盲去模糊方法依赖手工先验，现代深度学习方法需要大量预训练，适应性有限。本研究旨在提出一种无需预训练、适应性强的盲去模糊方法。

Method: 提出DeblurSDI框架，将盲去模糊视为迭代反向自扩散过程。使用两个随机初始化的神经网络，通过结合数据一致性和L1范数稀疏性进行优化，以逐步精炼清晰图像和模糊核。采用噪声调度机制稳定优化过程并提高对模糊核尺寸变化的鲁棒性。

Result: DeblurSDI在高度退化的场景下，能够恢复清晰的图像和准确的模糊核，实现了优于现有方法的性能。

Conclusion: DeblurSDI通过动态学习特定于实例的先验，成功解决了盲图像去模糊问题，无需预训练，在各种退化场景下均表现出优越的性能和鲁棒性。

Abstract: Blind image deconvolution is a challenging ill-posed inverse problem, where
both the latent sharp image and the blur kernel are unknown. Traditional
methods often rely on handcrafted priors, while modern deep learning approaches
typically require extensive pre-training on large external datasets, limiting
their adaptability to real-world scenarios. In this work, we propose DeblurSDI,
a zero-shot, self-supervised framework based on self-diffusion (SDI) that
requires no prior training. DeblurSDI formulates blind deconvolution as an
iterative reverse self-diffusion process that starts from pure noise and
progressively refines the solution. At each step, two randomly-initialized
neural networks are optimized continuously to refine the sharp image and the
blur kernel. The optimization is guided by an objective function combining data
consistency with a sparsity-promoting L1-norm for the kernel. A key innovation
is our noise scheduling mechanism, which stabilizes the optimization and
provides remarkable robustness to variations in blur kernel size. These allow
DeblurSDI to dynamically learn an instance-specific prior tailored to the input
image. Extensive experiments demonstrate that DeblurSDI consistently achieves
superior performance, recovering sharp images and accurate kernels even in
highly degraded scenarios.

</details>


### [60] [CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging](https://arxiv.org/abs/2510.27442)
*Aon Safdar,Mohamed Saadeldin*

Main category: cs.CV

TL;DR: CoMViT是一种紧凑且可泛化的Vision Transformer架构，通过集成卷积分词器、对角线掩码、动态温度缩放和基于池的序列聚合等方法，优化了资源受限的医学图像分析。它在十二个MedMNIST数据集上实现了强大的性能，参数量仅约450万，优于或媲美更深的CNN和ViT模型，参数量减少了5-20倍，且不牺牲准确性。Grad-CAM分析表明CoMViT能够关注临床相关区域，展示了在低资源医学影像领域开发高效、可解释模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 在医学影像领域，Vision Transformers（ViTs）虽然潜力巨大，但计算需求高且易在小数据集上过拟合，限制了其在现实临床中的应用。因此，需要一种针对资源受限场景优化的ViT架构。

Method: CoMViT集成了一种卷积分词器、对角线掩码、动态温度缩放和基于池的序列聚合，以提高性能和泛化能力，并进行了系统的架构优化。

Result: CoMViT在十二个MedMNIST数据集上实现了稳健的性能，同时保持了轻量级设计（约450万参数），参数量减少了5-20倍，且不牺牲准确性，表现优于或媲美更深的CNN和ViT模型。Grad-CAM分析显示CoMViT能够关注临床相关区域。

Conclusion: 原则性地重新设计ViT，能够为低资源医学影像设置开发出高效且可解释的模型，CoMViT展示了这种潜力。

Abstract: Vision Transformers (ViTs) have demonstrated strong potential in medical
imaging; however, their high computational demands and tendency to overfit on
small datasets limit their applicability in real-world clinical scenarios. In
this paper, we present CoMViT, a compact and generalizable Vision Transformer
architecture optimized for resource-constrained medical image analysis. CoMViT
integrates a convolutional tokenizer, diagonal masking, dynamic temperature
scaling, and pooling-based sequence aggregation to improve performance and
generalization. Through systematic architectural optimization, CoMViT achieves
robust performance across twelve MedMNIST datasets while maintaining a
lightweight design with only ~4.5M parameters. It matches or outperforms deeper
CNN and ViT variants, offering up to 5-20x parameter reduction without
sacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT
consistently attends to clinically relevant regions despite its compact size.
These results highlight the potential of principled ViT redesign for developing
efficient and interpretable models in low-resource medical imaging settings.

</details>


### [61] [From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration](https://arxiv.org/abs/2510.27452)
*Jianwen Sun,Fanrui Zhang,Yukang Feng,Chuanhao Li,Zizhen Li,Jiaxin Ai,Yifan Chang,Yu Dai,Kaipeng Zhang*

Main category: cs.CV

TL;DR: VisPainter是一个多代理框架，用于创建可编辑的科学插图，并引入了VisBench基准来评估插图质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型要么缺乏结构化编辑能力（栅格图像），要么编辑过程繁琐（代码生成），无法满足科学创作对效率、直观性和迭代修改的需求。

Method: VisPainter采用基于模型上下文协议的多代理方法，包含一个管理器、一个设计者和一个工具箱，协同生成兼容标准矢量图软件的图表，实现真正的元素级控制。同时，引入VisBench基准，包含七个维度的评估指标，从内容、布局、视觉感知和交互成本四个方面评估高信息密度的科学插图。

Result: 通过消融实验验证了VisPainter的架构合理性和VisBench评估方法的可靠性，并对各种视觉-语言模型进行了评估和排名，量化了角色划分、步进控制和描述对插图质量的影响。

Conclusion: VisPainter有效解决了现有科学插图生成工具的局限性，实现了高效、直观且易于迭代修改的插图创作。VisBench为科学插图的质量评估提供了一个系统化的方法。

Abstract: Scientific illustrations demand both high information density and
post-editability. However, current generative models have two major
limitations: Frist, image generation models output rasterized images lacking
semantic structure, making it impossible to access, edit, or rearrange
independent visual components in the images. Second, code-based generation
methods (TikZ or SVG), although providing element-level control, force users
into the cumbersome cycle of "writing-compiling-reviewing" and lack the
intuitiveness of manipulation. Neither of these two approaches can well meet
the needs for efficiency, intuitiveness, and iterative modification in
scientific creation. To bridge this gap, we introduce VisPainter, a multi-agent
framework for scientific illustration built upon the model context protocol.
VisPainter orchestrates three specialized modules-a Manager, a Designer, and a
Toolbox-to collaboratively produce diagrams compatible with standard vector
graphics software. This modular, role-based design allows each element to be
explicitly represented and manipulated, enabling true element-level control and
any element can be added and modified later. To systematically evaluate the
quality of scientific illustrations, we introduce VisBench, a benchmark with
seven-dimensional evaluation metrics. It assesses high-information-density
scientific illustrations from four aspects: content, layout, visual perception,
and interaction cost. To this end, we conducted extensive ablation experiments
to verify the rationality of our architecture and the reliability of our
evaluation methods. Finally, we evaluated various vision-language models,
presenting fair and credible model rankings along with detailed comparisons of
their respective capabilities. Additionally, we isolated and quantified the
impacts of role division, step control,and description on the quality of
illustrations.

</details>


### [62] [Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum](https://arxiv.org/abs/2510.27571)
*Zhuoning Guo,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Xiaowen Chu*

Main category: cs.CV

TL;DR: 通过引入新的评估框架、数据集和模型，我们提出了一个旨在实现通用视频检索的解决方案，克服了现有基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频检索方法受限于狭窄的基准测试，导致模型能力受限，无法实现通用性。缺乏定义和要求多维度泛化的诊断性评估，阻碍了通用能力的提升。

Method: 提出一个评估、数据和模型协同设计的框架。首先，建立通用视频检索基准（UVRB），包含16个数据集，用于评估和诊断能力差距。其次，利用UVRB的诊断结果，开发了一个可扩展的合成工作流，生成了155万个高质量的样本对，以覆盖通用性所需的语义空间。最后，设计了“模态金字塔”课程，通过利用数据中的潜在联系来训练通用视频嵌入器（GVE）。

Result: GVE在UVRB上实现了最先进的零样本泛化能力。实验表明，现有的流行基准测试不能很好地预测通用能力，并且部分相关检索是一个普遍但被忽视的场景。

Conclusion: 所提出的协同设计框架为摆脱现有局限性，迈向真正的通用视频检索提供了一条切实可行的途径。

Abstract: The prevailing video retrieval paradigm is structurally misaligned, as narrow
benchmarks incentivize correspondingly limited data and single-task training.
Therefore, universal capability is suppressed due to the absence of a
diagnostic evaluation that defines and demands multi-dimensional
generalization. To break this cycle, we introduce a framework built on the
co-design of evaluation, data, and modeling. First, we establish the Universal
Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to
measure performance but also to diagnose critical capability gaps across tasks
and domains. Second, guided by UVRB's diagnostics, we introduce a scalable
synthesis workflow that generates 1.55 million high-quality pairs to populate
the semantic space required for universality. Finally, we devise the Modality
Pyramid, a curriculum that trains our General Video Embedder (GVE) by
explicitly leveraging the latent interconnections within our diverse data.
Extensive experiments show GVE achieves state-of-the-art zero-shot
generalization on UVRB. In particular, our analysis reveals that popular
benchmarks are poor predictors of general ability and that partially relevant
retrieval is a dominant but overlooked scenario. Overall, our co-designed
framework provides a practical path to escape the limited scope and advance
toward truly universal video retrieval.

</details>


### [63] [A Multi-tiered Human-in-the-loop Approach for Interactive School Mapping Using Earth Observation and Machine Learning](https://arxiv.org/abs/2510.27460)
*Casper Fibaek,Abi Riley,Kelsey Doerksen,Do-Hyung Kim,Rochelle Schneider*

Main category: cs.CV

TL;DR: 该研究提出了一种多层级人机协作框架，用于交互式学校地图绘制，以提高教育设施记录的准确性和完整性，尤其是在数据稀疏的发展中地区。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够提高教育设施记录准确性和完整性的方法，特别是在数据稀缺和更新不频繁的发展中地区。

Method: 采用多层级人机协作框架：第一层利用机器学习分析人口密度、土地覆盖和现有基础设施与已知学校位置的关系，识别潜在的空白和错误标记的学校。后续层级则利用中分辨率（Sentinel-2）和极高分辨率（VHR）卫星图像以及深度学习模型来精确定位学校的候选位置。过程中，人机交互界面允许操作人员审查、验证和优化结果。研究中移除了中分辨率影像分析层级，因其改进不显著。

Result: 该框架能够识别潜在的空白和错误标记的学校，并生成详细的学校候选位置。初步评估表明，该多层级策略为教育基础设施测绘提供了一种可扩展且经济高效的解决方案。

Conclusion: 多层级人机协作框架为教育基础设施测绘提供了一种可扩展且成本效益高的方法，有助于规划和资源分配。

Abstract: This paper presents a multi-tiered human-in-the-loop framework for
interactive school mapping designed to improve the accuracy and completeness of
educational facility records, particularly in developing regions where such
data may be scarce and infrequently updated. The first tier involves a machine
learning based analysis of population density, land cover, and existing
infrastructure compared with known school locations. The first tier identifies
potential gaps and "mislabelled" schools. In subsequent tiers,
medium-resolution satellite imagery (Sentinel-2) is investigated to pinpoint
regions with a high likelihood of school presence, followed by the application
of very high-resolution (VHR) imagery and deep learning models to generate
detailed candidate locations for schools within these prioritised areas. The
medium-resolution approach was later removed due to insignificant improvements.
The medium and VHR resolution models build upon global pre-trained steps to
improve generalisation. A key component of the proposed approach is an
interactive interface to allow human operators to iteratively review, validate,
and refine the mapping results. Preliminary evaluations indicate that the
multi-tiered strategy provides a scalable and cost-effective solution for
educational infrastructure mapping to support planning and resource allocation.

</details>


### [64] [Referee: Reference-aware Audiovisual Deepfake Detection](https://arxiv.org/abs/2510.27475)
*Hyemin Boo,Eunsang Lee,Jiyoung Lee*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Referee 的新颖的、与说话人相关的、跨模态的深度伪影检测方法，该方法利用单次示例中的说话人特定线索来检测时空伪影以外的操纵，并在各种基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于先进生成模型产生的深度伪造内容日益增多，对现有深度伪造检测方法的泛化能力提出了挑战，因此需要新的检测方法。

Method: Referee 方法通过匹配和对齐参考内容和目标内容中的身份相关查询，提取跨模态特征，从而联合推理视听同步性和身份一致性。该方法利用来自单次示例的说话人特定线索，以检测时空伪影之外的操纵。

Result: 在 FakeAVCeleb、FaceForensics++ 和 KoDF 数据集上的广泛实验表明，Referee 在跨数据集和跨语言评估协议上实现了最先进的性能。

Conclusion: 实验结果强调了跨模态身份验证对于未来深度伪造检测的重要性。

Abstract: Since deepfakes generated by advanced generative models have rapidly posed
serious threats, existing audiovisual deepfake detection approaches struggle to
generalize to unseen forgeries. We propose a novel reference-aware audiovisual
deepfake detection method, called Referee. Speaker-specific cues from only
one-shot examples are leveraged to detect manipulations beyond spatiotemporal
artifacts. By matching and aligning identity-related queries from reference and
target content into cross-modal features, Referee jointly reasons about
audiovisual synchrony and identity consistency. Extensive experiments on
FakeAVCeleb, FaceForensics++, and KoDF demonstrate that Referee achieves
state-of-the-art performance on cross-dataset and cross-language evaluation
protocols. Experimental results highlight the importance of cross-modal
identity verification for future deepfake detection. The code is available at
https://github.com/ewha-mmai/referee.

</details>


### [65] [NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding](https://arxiv.org/abs/2510.27481)
*Wei Xu,Cheng Wang,Dingkang Liang,Zongchuang Zhao,Xingyu Jiang,Peng Zhang,Xiang Bai*

Main category: cs.CV

TL;DR: 本研究提出了NAUTILUS水下场景理解模型，并构建了NautData数据集，以解决水下图像质量差和缺乏大规模数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 水下探索对于资源勘探和国家安全至关重要，但自动化水下场景理解因缺乏大规模数据集和图像质量差而受阻。

Method: 构建包含145万图像-文本对、支持八项水下场景理解任务的NautData数据集；提出物理先验驱动的视觉特征增强（VFE）模块，用于恢复水下图像信息；将VFE模块集成到LLaVA-1.5和Qwen2.5-VL基线模型中，构建了NAUTILUS水下大型多模态模型（LMM）。

Result: 实验证明，VFE模块能有效提升基线模型在大多数任务上的性能，NAUTILUS在水下场景理解方面表现优越。

Conclusion: 所提出的NautData数据集和NAUTILUS模型能够有效提升水下场景理解的性能和鲁棒性。

Abstract: Underwater exploration offers critical insights into our planet and attracts
increasing attention for its broader applications in resource exploration,
national security, etc. We study the underwater scene understanding methods,
which aim to achieve automated underwater exploration. The underwater scene
understanding task demands multi-task perceptions from multiple granularities.
However, the absence of large-scale underwater multi-task instruction-tuning
datasets hinders the progress of this research. To bridge this gap, we
construct NautData, a dataset containing 1.45 M image-text pairs supporting
eight underwater scene understanding tasks. It enables the development and
thorough evaluation of the underwater scene understanding models. Underwater
image degradation is a widely recognized challenge that interferes with
underwater tasks. To improve the robustness of underwater scene understanding,
we introduce physical priors derived from underwater imaging models and propose
a plug-and-play vision feature enhancement (VFE) module, which explicitly
restores clear underwater information. We integrate this module into renowned
baselines LLaVA-1.5 and Qwen2.5-VL and build our underwater LMM, NAUTILUS.
Experiments conducted on the NautData and public underwater datasets
demonstrate the effectiveness of the VFE module, consistently improving the
performance of both baselines on the majority of supported tasks, thus ensuring
the superiority of NAUTILUS in the underwater scene understanding area. Data
and models are available at https://github.com/H-EmbodVis/NAUTILUS.

</details>


### [66] [ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.27492)
*Jiawei Gu,Yunzhuo Hao,Huichen Will Wang,Linjie Li,Michael Qizhe Shieh,Yejin Choi,Ranjay Krishna,Yu Cheng*

Main category: cs.CV

TL;DR: ThinkMorph是一个统一模型，通过文本和图像的互补推理来提升多模态能力，在多个基准测试中表现出色，并展现出新兴的多模态智能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推理模型尚不清楚如何有效地进行语言和视觉信息的交织推理，本文旨在解决这一问题，提出文本和图像思想应作为互补而非同构的模态，以相互促进推理。

Method: 构建了一个名为ThinkMorph的统一模型，并在24K高质量的交织推理数据上进行了微调，这些数据涵盖了不同视觉参与度的任务。ThinkMorph学会生成渐进式的文本-图像推理步骤，这些步骤能够具体地操作视觉内容，同时保持连贯的语言逻辑。

Result: ThinkMorph在以视觉为中心的基准测试中取得了显著的提升（平均比基础模型高34.7%），并且能够泛化到非领域任务，其表现与更大、专有的视觉语言模型（VLMs）相当或更优。此外，ThinkMorph还表现出新兴的多模态智能，包括未曾见过的视觉操作技能、推理模式的自适应切换以及通过多样化的多模态思想实现的更好的测试时间扩展。

Conclusion: 这些发现为表征统一模型在多模态推理方面的新兴能力提供了有前景的方向。

Abstract: Multimodal reasoning requires iterative coordination between language and
vision, yet it remains unclear what constitutes a meaningful interleaved chain
of thought. We posit that text and image thoughts should function as
complementary, rather than isomorphic, modalities that mutually advance
reasoning. Guided by this principle, we build ThinkMorph, a unified model
fine-tuned on 24K high-quality interleaved reasoning traces spanning tasks with
varying visual engagement. ThinkMorph learns to generate progressive text-image
reasoning steps that concretely manipulate visual content while maintaining
coherent verbal logic. It delivers large gains on vision-centric benchmarks
(averaging 34.7% over the base model) and generalizes to out-of-domain tasks,
matching or surpassing larger and proprietary VLMs. Beyond performance,
ThinkMorph exhibits emergent multimodal intelligence, including unseen visual
manipulation skills, adaptive switching between reasoning modes, and better
test-time scaling through diversified multimodal thoughts.These findings
suggest promising directions for characterizing the emergent capabilities of
unified models for multimodal reasoning.

</details>


### [67] [Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation](https://arxiv.org/abs/2510.27508)
*Elena Mulero Ayllón,Linlin Shen,Pierangelo Veltri,Fabrizia Gelardi,Arturo Chiti,Paolo Soda,Matteo Tortora*

Main category: cs.CV

TL;DR: vMambaX是一个集成了PET和CT图像的轻量级多模态框架，通过上下文门控跨模态感知模块（CGM）进行肺部肿瘤分割，在PCLT20K数据集上表现优于基线模型，计算复杂度更低。


<details>
  <summary>Details</summary>
Motivation: 准确的肺部肿瘤分割对于改进诊断和治疗计划至关重要，而有效结合PET和CT的解剖和功能信息仍然是一个重大挑战。

Method: 提出了一种名为vMambaX的轻量级多模态框架，该框架基于Visual Mamba架构，并集成了上下文门控跨模态感知模块（CGM），以结合PET和CT扫描图像，自适应地增强模态间特征交互，强调信息区域并抑制噪声。

Result: 在PCLT20K数据集上进行评估，vMambaX模型优于基线模型，同时保持较低的计算复杂度。

Conclusion: 结果突显了自适应跨模态门控在多模态肿瘤分割中的有效性，并证明了vMambaX作为一种高效且可扩展的框架在高级肺癌分析中的潜力。

Abstract: Accurate lung tumor segmentation is vital for improving diagnosis and
treatment planning, and effectively combining anatomical and functional
information from PET and CT remains a major challenge. In this study, we
propose vMambaX, a lightweight multimodal framework integrating PET and CT scan
images through a Context-Gated Cross-Modal Perception Module (CGM). Built on
the Visual Mamba architecture, vMambaX adaptively enhances inter-modality
feature interaction, emphasizing informative regions while suppressing noise.
Evaluated on the PCLT20K dataset, the model outperforms baseline models while
maintaining lower computational complexity. These results highlight the
effectiveness of adaptive cross-modal gating for multimodal tumor segmentation
and demonstrate the potential of vMambaX as an efficient and scalable framework
for advanced lung cancer analysis. The code is available at
https://github.com/arco-group/vMambaX.

</details>


### [68] [MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series](https://arxiv.org/abs/2510.27547)
*Xue Xia,Randall Balestriero,Tao Zhang,Yixin Zhou,Andrew Ding,Dev Saini,Lorenz Hurni*

Main category: cs.CV

TL;DR: MapSAM2是一个统一的框架，用于自动分割历史地图图像和时间序列，通过将地图瓦片和时间序列视为视频，并引入Siegfried建筑时间序列数据集，有效解决了历史地图分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 自动化分析历史地图图像，特别是处理其风格多样性和标注数据稀缺的问题，以及构建关联时空数据集以支持地理、建筑、道路和环境等领域的研究。 

Method: 将历史地图图像和时间序列视为视频。图像处理方面，将一系列瓦片作为视频处理，利用记忆注意力机制引入相似瓦片上下文线索，提高几何精度。时间序列方面，引入Siegfried建筑时间序列数据集，并提出从单年地图生成伪时间序列的方法以降低标注成本。

Result: MapSAM2能有效学习时间关联，并在有限监督或使用伪视频的情况下，准确分割和链接时间序列中的建筑物。

Conclusion: MapSAM2框架在历史地图图像和时间序列的自动分割与链接方面表现出色，尤其在处理几何精度和降低标注成本方面取得了显著进展，未来将发布数据集和代码以促进相关研究。

Abstract: Historical maps are unique and valuable archives that document geographic
features across different time periods. However, automated analysis of
historical map images remains a significant challenge due to their wide
stylistic variability and the scarcity of annotated training data. Constructing
linked spatio-temporal datasets from historical map time series is even more
time-consuming and labor-intensive, as it requires synthesizing information
from multiple maps. Such datasets are essential for applications such as dating
buildings, analyzing the development of road networks and settlements, studying
environmental changes etc. We present MapSAM2, a unified framework for
automatically segmenting both historical map images and time series. Built on a
visual foundation model, MapSAM2 adapts to diverse segmentation tasks with
few-shot fine-tuning. Our key innovation is to treat both historical map images
and time series as videos. For images, we process a set of tiles as a video,
enabling the memory attention mechanism to incorporate contextual cues from
similar tiles, leading to improved geometric accuracy, particularly for areal
features. For time series, we introduce the annotated Siegfried Building Time
Series Dataset and, to reduce annotation costs, propose generating pseudo time
series from single-year maps by simulating common temporal transformations.
Experimental results show that MapSAM2 learns temporal associations effectively
and can accurately segment and link buildings in time series under limited
supervision or using pseudo videos. We will release both our dataset and code
to support future research.

</details>


### [69] [Image Hashing via Cross-View Code Alignment in the Age of Foundation Models](https://arxiv.org/abs/2510.27584)
*Ilyass Moummad,Kawtar Zaher,Hervé Goëau,Alexis Joly*

Main category: cs.CV

TL;DR: CroVCA是一种简单统一的二元码学习方法，通过跨视图代码对齐实现高效的大规模检索，训练时间短，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高效的大规模检索需要紧凑且具有辨别力的表征。现有方法在处理高维空间中的最近邻搜索时计算成本高，并且通常依赖于复杂的流水线、多项式目标、单一学习范式的特定设计和较长的训练时间。

Method: CroVCA（跨视图代码对齐）通过单一的二元交叉熵损失来强制对齐，并使用编码率最大化作为反崩溃正则化器来促进代码的平衡和多样性。HashCoder是一个轻量级的MLP哈希网络，带有最终的批量归一化层以强制代码平衡。它可以作为冻结嵌入的探测头，或通过LoRA微调来有效调整编码器。

Result: CroVCA在基准测试中取得了最先进的成果，仅需5个训练周期。在16位精度下，它在COCO上进行无监督哈希的训练时间不到2分钟，在ImageNet100上进行有监督哈希的训练时间约3分钟（单GPU）。

Conclusion: CroVCA在效率、适应性和广泛适用性方面表现出色，为高效的大规模检索提供了一种简单而强大的解决方案。

Abstract: Efficient large-scale retrieval requires representations that are both
compact and discriminative. Foundation models provide powerful visual and
multimodal embeddings, but nearest neighbor search in these high-dimensional
spaces is computationally expensive. Hashing offers an efficient alternative by
enabling fast Hamming distance search with binary codes, yet existing
approaches often rely on complex pipelines, multi-term objectives, designs
specialized for a single learning paradigm, and long training times. We
introduce CroVCA (Cross-View Code Alignment), a simple and unified principle
for learning binary codes that remain consistent across semantically aligned
views. A single binary cross-entropy loss enforces alignment, while coding-rate
maximization serves as an anti-collapse regularizer to promote balanced and
diverse codes. To implement this, we design HashCoder, a lightweight MLP
hashing network with a final batch normalization layer to enforce balanced
codes. HashCoder can be used as a probing head on frozen embeddings or to adapt
encoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves
state-of-the-art results in just 5 training epochs. At 16 bits, it particularly
well-for instance, unsupervised hashing on COCO completes in under 2 minutes
and supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These
results highlight CroVCA's efficiency, adaptability, and broad applicability.

</details>


### [70] [ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning](https://arxiv.org/abs/2510.27599)
*Samarup Bhattacharya,Anubhab Bhattacharya,Abir Chakraborty*

Main category: cs.CV

TL;DR: ANCHOR框架通过结合监督对比学习和显式难例挖掘，提高神经网络对对抗性攻击的鲁棒性，在CIFAR-10数据集上取得了优于标准对抗训练方法的性能。


<details>
  <summary>Details</summary>
Motivation: 神经网络的梯度下降学习方式虽然强大，但也容易受到微小扰动的对抗性攻击，导致模型做出错误预测。因此，需要提高模型的鲁棒性。

Method: 提出ANCHOR（Adversarially-trained Contrastive Hard-mining for Optimized Robustness）框架，该框架利用监督对比学习和显式难例挖掘，使模型学习到的图像表示（包括原始图像、增强图像和扰动图像）在嵌入空间中能够聚集在同一类别下，并与其他类别的图像分开。

Result: 在CIFAR-10数据集上，ANCHOR在干净和对抗（PGD-20, epsilon = 0.031）设置下均取得了优于标准对抗训练方法的准确率。

Conclusion: 结合对抗性引导和难例挖掘的对比监督有助于模型学习更结构化、更鲁棒的表示，缩小了准确率和鲁棒性之间的差距。

Abstract: Neural networks have changed the way machines interpret the world. At their
core, they learn by following gradients, adjusting their parameters step by
step until they identify the most discriminant patterns in the data. This
process gives them their strength, yet it also opens the door to a hidden flaw.
The very gradients that help a model learn can also be used to produce small,
imperceptible tweaks that cause the model to completely alter its decision.
Such tweaks are called adversarial attacks. These attacks exploit this
vulnerability by adding tiny, imperceptible changes to images that, while
leaving them identical to the human eye, cause the model to make wrong
predictions. In this work, we propose Adversarially-trained Contrastive
Hard-mining for Optimized Robustness (ANCHOR), a framework that leverages the
power of supervised contrastive learning with explicit hard positive mining to
enable the model to learn representations for images such that the embeddings
for the images, their augmentations, and their perturbed versions cluster
together in the embedding space along with those for other images of the same
class while being separated from images of other classes. This alignment helps
the model focus on stable, meaningful patterns rather than fragile gradient
cues. On CIFAR-10, our approach achieves impressive results for both clean and
robust accuracy under PGD-20 (epsilon = 0.031), outperforming standard
adversarial training methods. Our results indicate that combining adversarial
guidance with hard-mined contrastive supervision helps models learn more
structured and robust representations, narrowing the gap between accuracy and
robustness.

</details>


### [71] [Who Made This? Fake Detection and Source Attribution with Diffusion Features](https://arxiv.org/abs/2510.27602)
*Simone Bonechi,Paolo Andreini,Barbara Toniella Corradini*

Main category: cs.CV

TL;DR: FRIDA是一个利用预训练扩散模型的内部激活来检测假图像和归属源生成器的新型轻量级框架，在跨生成器检测方面取得了最先进的性能，无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有的监督式假图像检测器难以推广到未知的生成器，需要大量标注数据和频繁的重新训练。

Method: FRIDA框架利用预训练扩散模型的内部激活，并结合k近邻分类器来分析扩散特征，以实现假图像检测和源生成器归属。

Result: k近邻分类器在扩散特征上实现了最先进的跨生成器性能，而一个紧凑的神经网络模型则能够准确地进行源归属。

Conclusion: 扩散模型内部的表征天然地编码了生成器特定的模式，为合成图像取证提供了一个简单且可解释的基础。

Abstract: The rapid progress of generative diffusion models has enabled the creation of
synthetic images that are increasingly difficult to distinguish from real ones,
raising concerns about authenticity, copyright, and misinformation. Existing
supervised detectors often struggle to generalize across unseen generators,
requiring extensive labeled data and frequent retraining. We introduce FRIDA
(Fake-image Recognition and source Identification via Diffusion-features
Analysis), a lightweight framework that leverages internal activations from a
pre-trained diffusion model for deepfake detection and source generator
attribution. A k-nearest-neighbor classifier applied to diffusion features
achieves state-of-the-art cross-generator performance without fine-tuning,
while a compact neural model enables accurate source attribution. These results
show that diffusion representations inherently encode generator-specific
patterns, providing a simple and interpretable foundation for synthetic image
forensics.

</details>


### [72] [Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2510.27606)
*Yuhong Liu,Beichen Zhang,Yuhang Zang,Yuhang Cao,Long Xing,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: Spatial-SSRL是一种新的自监督强化学习范式，无需昂贵的人工标注或受限环境，即可提升大型视觉语言模型（LVLM）的空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM在空间理解方面存在不足，且现有的监督微调（SFT）和强化学习（RLVR）方法依赖于昂贵的监督、专门的工具或受限的环境，这限制了其扩展性。

Method: Spatial-SSRL通过从普通RGB或RGB-D图像中自动生成五个预设任务（打乱图像块重排、翻转图像块识别、裁剪图像块修复、区域深度排序、相对三维位置预测）来获得可验证的信号，这些任务提供易于验证且无需人工或LVLM标注的地面真实答案。

Result: 在七个图像和视频的空间理解基准测试中，Spatial-SSRL相比Qwen2.5-VL基线模型，在3B和7B模型上平均准确率分别提高了4.63%和3.89%。

Conclusion: 简单、内在的监督可以实现大规模的RLVR，并为提升LVLM的空间智能提供了实际可行的方法。

Abstract: Spatial understanding remains a weakness of Large Vision-Language Models
(LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement
learning with verifiable rewards (RLVR) pipelines depend on costly supervision,
specialized tools, or constrained environments that limit scale. We introduce
Spatial-SSRL, a self-supervised RL paradigm that derives verifiable signals
directly from ordinary RGB or RGB-D images. Spatial-SSRL automatically
formulates five pretext tasks that capture 2D and 3D spatial structure:
shuffled patch reordering, flipped patch recognition, cropped patch inpainting,
regional depth ordering, and relative 3D position prediction. These tasks
provide ground-truth answers that are easy to verify and require no human or
LVLM annotation. Training on our tasks substantially improves spatial reasoning
while preserving general visual capabilities. On seven spatial understanding
benchmarks in both image and video settings, Spatial-SSRL delivers average
accuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our
results show that simple, intrinsic supervision enables RLVR at scale and
provides a practical route to stronger spatial intelligence in LVLMs.

</details>


### [73] [Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation](https://arxiv.org/abs/2510.27632)
*Riccardo Brioschi,Aleksandr Alekseev,Emanuele Nevali,Berkay Döner,Omar El Malki,Blagoj Mitrevski,Leandro Kieliger,Mark Collier,Andrii Maksai,Jesse Berent,Claudiu Musat,Efi Kokiopoulou*

Main category: cs.CV

TL;DR: 该研究提出了一种利用用户提供的草图作为约束来生成图形布局的新方法，并发布了用于训练的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有图形布局生成方法在纳入用户约束时，需要复杂的操作，降低了易用性。本研究旨在探索更直观的用户约束方式，以提高布局生成的可行性。

Method: 提出了一种基于多模态 Transformer 的解决方案，将草图和内容资产作为输入来生成布局。为了解决训练数据稀缺的问题，研究者开发了一种生成合成训练草图的方法。

Result: 所提出的方法在三个公开数据集上进行了训练和评估，结果表明其优于目前最先进的基于约束的方法，并提供了更直观的设计体验。此外，研究者还发布了大量的合成草图数据以促进未来的研究。

Conclusion: 将草图作为约束的“草图到布局”问题是一个有前景但尚未得到充分探索的研究方向。本研究提出的方法和发布的数据集为该领域的研究奠定了基础。

Abstract: Graphic layout generation is a growing research area focusing on generating
aesthetically pleasing layouts ranging from poster designs to documents. While
recent research has explored ways to incorporate user constraints to guide the
layout generation, these constraints often require complex specifications which
reduce usability. We introduce an innovative approach exploiting user-provided
sketches as intuitive constraints and we demonstrate empirically the
effectiveness of this new guidance method, establishing the sketch-to-layout
problem as a promising research direction, which is currently under-explored.
To tackle the sketch-to-layout problem, we propose a multimodal
transformer-based solution using the sketch and the content assets as inputs to
produce high quality layouts. Since collecting sketch training data from human
annotators to train our model is very costly, we introduce a novel and
efficient method to synthetically generate training sketches at scale. We train
and evaluate our model on three publicly available datasets: PubLayNet,
DocLayNet and SlidesVQA, demonstrating that it outperforms state-of-the-art
constraint-based methods, while offering a more intuitive design experience. In
order to facilitate future sketch-to-layout research, we release O(200k)
synthetically-generated sketches for the public datasets above. The datasets
are available at https://github.com/google-deepmind/sketch_to_layout.

</details>


### [74] [VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images](https://arxiv.org/abs/2510.27646)
*Cesar H. Comin,Wesley N. Galvão*

Main category: cs.CV

TL;DR: 通过生成具有形状偏见的合成数据集来提高血管分割的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在医学图像分析中对大规模标注数据集的依赖以及跨模态泛化能力差的问题，卷积神经网络易学到纹理特征，限制了其在不同视觉特征的新领域的性能。

Method: 提出一种名为VessShape的方法，生成包含程序化生成的管状几何结构和多样化纹理的2D合成数据集，以增强模型对形状线索的学习。对模型进行预训练。

Result: 在两个不同领域的真实世界数据集上，预训练模型在少样本（4-10个样本）微调下表现出强大的分割性能，并且在未见过的领域也展现出显著的零样本分割能力。

Conclusion: 通过强大的形状偏见进行预训练是克服数据稀缺性和提高血管分割模型泛化能力的有效策略。

Abstract: Semantic segmentation of blood vessels is an important task in medical image
analysis, but its progress is often hindered by the scarcity of large annotated
datasets and the poor generalization of models across different imaging
modalities. A key aspect is the tendency of Convolutional Neural Networks
(CNNs) to learn texture-based features, which limits their performance when
applied to new domains with different visual characteristics. We hypothesize
that leveraging geometric priors of vessel shapes, such as their tubular and
branching nature, can lead to more robust and data-efficient models. To
investigate this, we introduce VessShape, a methodology for generating
large-scale 2D synthetic datasets designed to instill a shape bias in
segmentation models. VessShape images contain procedurally generated tubular
geometries combined with a wide variety of foreground and background textures,
encouraging models to learn shape cues rather than textures. We demonstrate
that a model pre-trained on VessShape images achieves strong few-shot
segmentation performance on two real-world datasets from different domains,
requiring only four to ten samples for fine-tuning. Furthermore, the model
exhibits notable zero-shot capabilities, effectively segmenting vessels in
unseen domains without any target-specific training. Our results indicate that
pre-training with a strong shape bias can be an effective strategy to overcome
data scarcity and improve model generalization in blood vessel segmentation.

</details>


### [75] [NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception](https://arxiv.org/abs/2510.27647)
*Congzhang Shao,Quan Yuan,Guiyang Luo,Yue Hu,Danni Wang,Yilin Liu,Rui Pan,Bo Chen,Jinglin Li*

Main category: cs.CV

TL;DR: 不可变异构性在协作感知中带来挑战，本文提出NegoCollab方法，通过协商公共表示来对齐不同域的特征，并引入了三种损失函数来优化训练。


<details>
  <summary>Details</summary>
Motivation: 异构性导致特征域间隙，降低协作感知性能。

Method: 提出NegoCollab方法，引入协商器生成公共表示，并使用一对发送者和接收者进行特征转换，同时采用分布对齐损失、结构对齐损失和语用对齐损失进行训练。

Result: NegoCollab有效缩小了不同局部表示的域间隙，实现了更好的特征对齐。

Conclusion: NegoCollab通过协商式公共表示和多重对齐损失，有效解决了异构协作感知中的域间隙问题，提高了模型性能。

Abstract: Collaborative perception improves task performance by expanding the
perception range through information sharing among agents. . Immutable
heterogeneity poses a significant challenge in collaborative perception, as
participating agents may employ different and fixed perception models. This
leads to domain gaps in the intermediate features shared among agents,
consequently degrading collaborative performance. Aligning the features of all
agents to a common representation can eliminate domain gaps with low training
cost. However, in existing methods, the common representation is designated as
the representation of a specific agent, making it difficult for agents with
significant domain discrepancies from this specific agent to achieve proper
alignment. This paper proposes NegoCollab, a heterogeneous collaboration method
based on the negotiated common representation. It introduces a negotiator
during training to derive the common representation from the local
representations of each modality's agent, effectively reducing the inherent
domain gap with the various local representations. In NegoCollab, the mutual
transformation of features between the local representation space and the
common representation space is achieved by a pair of sender and receiver. To
better align local representations to the common representation containing
multimodal information, we introduce structural alignment loss and pragmatic
alignment loss in addition to the distribution alignment loss to supervise the
training. This enables the knowledge in the common representation to be fully
distilled into the sender.

</details>


### [76] [Gaussian Combined Distance: A Generic Metric for Object Detection](https://arxiv.org/abs/2510.27649)
*Ziqian Guan,Xieyi Fu,Pengjun Huang,Hengyuan Zhang,Hubin Du,Yongtao Liu,Yinglin Wang,Qang Ma*

Main category: cs.CV

TL;DR: 为了解决目标检测中小目标检测精度不高的问题，提出高斯结合距离（GCD）替代IoU和Wasserstein距离，以提升模型泛化能力和收敛速度，并在多个数据集上验证了GCD的有效性。


<details>
  <summary>Details</summary>
Motivation: IoU作为相似性度量在检测小目标时由于对位置偏差敏感而表现不佳。Wasserstein距离虽然作为替代，但缺乏尺度不变性，并且作为损失函数时中心属性优化独立导致收敛慢、精度不高。

Method: 提出高斯结合距离（GCD），通过分析其梯度证明了GCD具有尺度不变性且有利于联合优化，从而提升模型定位性能。

Result: 在AI-TOD-v2数据集上，GCD作为边界框回归损失函数和标签分配度量，在小目标检测方面取得了最先进的性能。在MS-COCO-2017和Visdrone-2019数据集上的实验也表明GCD优于Wasserstein距离。

Conclusion: GCD是一种有效的目标检测相似性度量和损失函数，尤其在小目标检测和需要尺度不变性的场景下，能够提升模型性能。

Abstract: In object detection, a well-defined similarity metric can significantly
enhance model performance. Currently, the IoU-based similarity metric is the
most commonly preferred choice for detectors. However, detectors using IoU as a
similarity metric often perform poorly when detecting small objects because of
their sensitivity to minor positional deviations. To address this issue, recent
studies have proposed the Wasserstein Distance as an alternative to IoU for
measuring the similarity of Gaussian-distributed bounding boxes. However, we
have observed that the Wasserstein Distance lacks scale invariance, which
negatively impacts the model's generalization capability. Additionally, when
used as a loss function, its independent optimization of the center attributes
leads to slow model convergence and unsatisfactory detection precision. To
address these challenges, we introduce the Gaussian Combined Distance (GCD).
Through analytical examination of GCD and its gradient, we demonstrate that GCD
not only possesses scale invariance but also facilitates joint optimization,
which enhances model localization performance. Extensive experiments on the
AI-TOD-v2 dataset for tiny object detection show that GCD, as a bounding box
regression loss function and label assignment metric, achieves state-of-the-art
performance across various detectors. We further validated the generalizability
of GCD on the MS-COCO-2017 and Visdrone-2019 datasets, where it outperforms the
Wasserstein Distance across diverse scales of datasets. Code is available at
https://github.com/MArKkwanGuan/mmdet-GCD.

</details>


### [77] [Vision Transformer for Robust Occluded Person Reidentification in Complex Surveillance Scenes](https://arxiv.org/abs/2510.27677)
*Bo Li,Duyuan Zheng,Xinyang Liu,Qingwen Li,Hong Li,Hongyan Cui,Ge Gao,Chen Liu*

Main category: cs.CV

TL;DR: Sh-ViT是一个轻量级模型，通过Shuffle模块、场景适应性增强和知识蒸馏来解决遮挡、视角畸变和图像质量差等问题，在MyTT和Market1501数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的人员重识别（ReID）方法在面对遮挡、视角畸变和图像质量差等挑战时，往往依赖复杂模块或仅在清晰正面图像上表现良好，因此需要一种轻量级且鲁棒的模型来应对监控场景下的ReID问题。

Method: 提出了一种名为Sh-ViT（Shuffling Vision Transformer）的轻量级ReID模型。该模型基于ViT-Base，并引入了三个关键组件：1. 在最后一个Transformer层引入Shuffle模块，打破空间相关性，增强对遮挡和模糊的鲁棒性；2. 采用场景适应性增强（几何变换、擦除、模糊和颜色调整）来模拟监控条件；3. 利用DeiT的知识蒸馏方法，以在标签有限的情况下改进学习。此外，构建了一个包含10,000多名行人、30,000多张图像的MyTT数据集，以支持真实世界场景的评估。

Result: 在MyTT数据集上，Sh-ViT实现了83.2%的Rank-1和80.1%的mAP，优于CNN和ViT基线模型。在Market1501数据集上，Sh-ViT实现了94.6%的Rank-1和87.5%的mAP，超过了现有最先进的方法。

Conclusion: Sh-ViT模型在不依赖外部模块的情况下，提高了对遮挡和模糊的鲁棒性，为基于监控的ReID问题提供了一个实用的解决方案。

Abstract: Person re-identification (ReID) in surveillance is challenged by occlusion,
viewpoint distortion, and poor image quality. Most existing methods rely on
complex modules or perform well only on clear frontal images. We propose Sh-ViT
(Shuffling Vision Transformer), a lightweight and robust model for occluded
person ReID. Built on ViT-Base, Sh-ViT introduces three components: First, a
Shuffle module in the final Transformer layer to break spatial correlations and
enhance robustness to occlusion and blur; Second, scenario-adapted augmentation
(geometric transforms, erasing, blur, and color adjustment) to simulate
surveillance conditions; Third, DeiT-based knowledge distillation to improve
learning with limited labels.To support real-world evaluation, we construct the
MyTT dataset, containing over 10,000 pedestrians and 30,000+ images from base
station inspections, with frequent equipment occlusion and camera variations.
Experiments show that Sh-ViT achieves 83.2% Rank-1 and 80.1% mAP on MyTT,
outperforming CNN and ViT baselines, and 94.6% Rank-1 and 87.5% mAP on
Market1501, surpassing state-of-the-art methods.In summary, Sh-ViT improves
robustness to occlusion and blur without external modules, offering a practical
solution for surveillance-based personnel monitoring.

</details>


### [78] [PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting](https://arxiv.org/abs/2510.27680)
*Danyal Maqbool,Changhee Lee,Zachary Huemann,Samuel D. Church,Matthew E. Larson,Scott B. Perlman,Tomas A. Romero,Joshua D. Warner,Meghan Lubner,Xin Tie,Jameson Merkow,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: 本研究将视觉语言模型（VLM）应用于3D PET/CT影像，并提出了一种名为PETAR-4B的新模型，用于生成医学报告。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型主要应用于2D影像，而3D医学影像（如PET/CT）在处理大规模体积数据、微小分散的病灶以及冗长的放射学报告方面存在局限性。本研究旨在将VLM扩展到3D PET/CT领域，以克服这些挑战。

Method: 研究人员构建了一个包含11,000多个病灶描述和3D分割的3D PET/CT数据集，并通过混合规则和LLM方法提取。在此基础上，提出了一种名为PETAR-4B的3D掩膜感知视觉语言模型，该模型整合了PET、CT和病灶轮廓信息，以生成具有空间定位能力的报告。PETAR-4B结合了全局上下文推理和细粒度病灶感知能力。

Result: PETAR-4B模型能够生成临床上连贯且具有空间定位的发现。通过自动化和人工评估，结果表明PETAR显著提高了PET/CT报告生成的质量。

Conclusion: PETAR-4B模型成功地将VLM扩展到3D PET/CT领域，实现了具有空间定位能力的报告生成，并显著提高了报告质量，推动了3D医学视觉语言理解的发展。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
multimodal reasoning, yet most medical applications remain limited to 2D
imaging. In this work, we extend VLMs to 3D positron emission tomography and
computed tomography (PET/CT), a domain characterized by large volumetric data,
small and dispersed lesions, and lengthy radiology reports. We introduce a
large-scale dataset comprising over 11,000 lesion-level descriptions paired
with 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid
rule-based and large language model (LLM) pipeline. Building upon this dataset,
we propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET,
CT, and lesion contours for spatially grounded report generation. PETAR bridges
global contextual reasoning with fine-grained lesion awareness, producing
clinically coherent and localized findings. Comprehensive automated and human
evaluations demonstrate that PETAR substantially improves PET/CT report
generation quality, advancing 3D medical vision-language understanding.

</details>


### [79] [Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](https://arxiv.org/abs/2510.27684)
*Xiangyu Fan,Zesong Qiu,Zhuguanyu Wu,Fanzhou Wang,Zhiqian Lin,Tianxiang Ren,Dahua Lin,Ruihao Gong,Lei Yang*

Main category: cs.CV

TL;DR: Phased DMD是一种多步蒸馏框架，通过引入阶段式蒸馏和混合专家（MoE）的概念，解决了现有蒸馏方法在处理复杂生成任务时模型容量不足和生成多样性下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的一步蒸馏方法（如DMD）在处理复杂生成任务（如文本到视频生成）时，由于模型容量限制，性能不足；而直接扩展到多步蒸馏则会增加内存和计算负担，并导致不稳定和效率低下。此外，随机梯度截断虽然可以解决一些问题，但会显著降低生成多样性。

Method: Phased DMD框架包含两个核心思想：1. 渐进式分布匹配：将信噪比（SNR）范围划分为子区间，逐步优化模型以适应更高SNR水平，从而更好地捕捉复杂分布。2. 子区间内的分数匹配：通过严格的数学推导，确保每个子区间内的训练目标准确。该框架结合了阶段式蒸馏和混合专家（MoE）的理念，以降低学习难度并增强模型容量。

Result: 实验结果表明，Phased DMD在蒸馏先进的图像和视频生成模型（如Qwen-Image和Wan2.2）方面，能够更好地保持输出多样性，同时保留了关键的生成能力，优于DMD方法。

Conclusion: Phased DMD作为一种新的多步蒸馏框架，通过渐进式分布匹配和子区间内的分数匹配，有效解决了现有方法的局限性，在保持模型性能和多样性方面取得了显著成果，并将在图像和视频生成领域展现出强大的潜力。

Abstract: Distribution Matching Distillation (DMD) distills score-based generative
models into efficient one-step generators, without requiring a one-to-one
correspondence with the sampling trajectories of their teachers. However,
limited model capacity causes one-step distilled models underperform on complex
generative tasks, e.g., synthesizing intricate object motions in text-to-video
generation. Directly extending DMD to multi-step distillation increases memory
usage and computational depth, leading to instability and reduced efficiency.
While prior works propose stochastic gradient truncation as a potential
solution, we observe that it substantially reduces the generation diversity of
multi-step distilled models, bringing it down to the level of their one-step
counterparts. To address these limitations, we propose Phased DMD, a multi-step
distillation framework that bridges the idea of phase-wise distillation with
Mixture-of-Experts (MoE), reducing learning difficulty while enhancing model
capacity. Phased DMD is built upon two key ideas: progressive distribution
matching and score matching within subintervals. First, our model divides the
SNR range into subintervals, progressively refining the model to higher SNR
levels, to better capture complex distributions. Next, to ensure the training
objective within each subinterval is accurate, we have conducted rigorous
mathematical derivations. We validate Phased DMD by distilling state-of-the-art
image and video generation models, including Qwen-Image (20B parameters) and
Wan2.2 (28B parameters). Experimental results demonstrate that Phased DMD
preserves output diversity better than DMD while retaining key generative
capabilities. We will release our code and models.

</details>


### [80] [LifWavNet: Lifting Wavelet-based Network for Non-contact ECG Reconstruction from Radar](https://arxiv.org/abs/2510.27692)
*Soumitra Kundu,Gargi Panda,Saumik Bhattacharya,Aurobinda Routray,Rajlakshmi Guha*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Non-contact electrocardiogram (ECG) reconstruction from radar signals offers
a promising approach for unobtrusive cardiac monitoring. We present LifWavNet,
a lifting wavelet network based on a multi-resolution analysis and synthesis
(MRAS) model for radar-to-ECG reconstruction. Unlike prior models that use
fixed wavelet approaches, LifWavNet employs learnable lifting wavelets with
lifting and inverse lifting units to adaptively capture radar signal features
and synthesize physiologically meaningful ECG waveforms. To improve
reconstruction fidelity, we introduce a multi-resolution short-time Fourier
transform (STFT) loss, that enforces consistency with the ground-truth ECG in
both temporal and spectral domains. Evaluations on two public datasets
demonstrate that LifWavNet outperforms state-of-the-art methods in ECG
reconstruction and downstream vital sign estimation (heart rate and heart rate
variability). Furthermore, intermediate feature visualization highlights the
interpretability of multi-resolution decomposition and synthesis in
radar-to-ECG reconstruction. These results establish LifWavNet as a robust
framework for radar-based non-contact ECG measurement.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [81] [Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling](https://arxiv.org/abs/2510.26912)
*Hyunji Lee,Wenhao Yu,Hongming Zhang,Kaixin Ma,Jiyeon Kim,Dong Yu,Minjoon Seo*

Main category: cs.CL

TL;DR: 结合状态空间模型（SSM）和注意力机制的混合模型在处理长序列时表现出不同的有效性，顺序集成在短上下文上表现更好，而并行集成在长上下文上表现更好。通过对包含释义的数据集进行持续训练的数据驱动方法可以进一步提高模型的召回率，并且比其他旨在提高召回率的架构修改更有效。


<details>
  <summary>Details</summary>
Motivation: 现有混合模型（SSM + 注意力）的架构设计选择理解不足，需要进一步研究以优化其性能。

Method: 1. 分析顺序和并行集成SSM与注意力层的区别，考察其在不同上下文长度下的表现。 2. 提出一种数据中心的方法，通过在包含释义的数据集上进行持续训练来增强模型的召回率。

Result: 顺序混合模型在短上下文上表现更好，并行混合模型在长上下文上更有效。数据中心的方法提高了召回率，并且优于其他架构修改方法。

Conclusion: 对混合SSM-注意力模型的理解更加深入，为根据不同应用场景设计定制化架构提供了实践指导。

Abstract: Hybrid models that combine state space models (SSMs) with attention
mechanisms have shown strong performance by leveraging the efficiency of SSMs
and the high recall ability of attention. However, the architectural design
choices behind these hybrid models remain insufficiently understood. In this
work, we analyze hybrid architectures through the lens of memory utilization
and overall performance, and propose a complementary method to further enhance
their effectiveness. We first examine the distinction between sequential and
parallel integration of SSM and attention layers. Our analysis reveals several
interesting findings, including that sequential hybrids perform better on
shorter contexts, whereas parallel hybrids are more effective for longer
contexts. We also introduce a data-centric approach of continually training on
datasets augmented with paraphrases, which further enhances recall while
preserving other capabilities. It generalizes well across different base models
and outperforms architectural modifications aimed at enhancing recall. Our
findings provide a deeper understanding of hybrid SSM-attention models and
offer practical guidance for designing architectures tailored to various use
cases. Our findings provide a deeper understanding of hybrid SSM-attention
models and offer practical guidance for designing architectures tailored to
various use cases.

</details>


### [82] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra,Arthur Lorenzi,Laís Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Olívia Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [83] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu*

Main category: cs.CL

TL;DR: 该论文介绍了 MEDIQA-OE 2025 共享任务，这是首个从医患对话中提取医疗医嘱的挑战。


<details>
  <summary>Details</summary>
Motivation: 将对话转换为电子健康记录中的医疗医嘱可以减轻医生的文档负担，并直接影响患者的后续护理。

Method: 介绍 MEDIQA-OE 任务、数据集、最终排行榜和参与者的解决方案，这些方案包括使用各种方法以及闭源和开元的大型语言模型（LLMs）。

Result: 六个团队参与了该共享任务，并尝试了各种方法。

Conclusion: MEDIQA-OE 2025 共享任务是首个专注于从医患对话中提取医疗医嘱的挑战。

Abstract: Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [84] [Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services](https://arxiv.org/abs/2510.27016)
*Jayden Serenari,Stephen Lee*

Main category: cs.CL

TL;DR: LOPSIDED框架通过使用语义一致的假名动态替换用户提示中的敏感个人身份信息（PII），并在模型响应后将其还原，从而在保护隐私的同时保持对话的上下文完整性。


<details>
  <summary>Details</summary>
Motivation: 随着对话式人工智能系统（特别是大型语言模型LLMs）的广泛使用，用户在互动中分享敏感个人数据可能导致隐私泄露（如个人身份信息PII的暴露），从而引发安全漏洞或身份盗窃的风险。

Method: 提出了一种名为LOPSIDED（Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection）的框架。该框架是一个语义感知的隐私代理，能够动态地将用户提示中的敏感PII替换为语义上一致的假名，以保持对话的上下文完整性。在LLM生成响应后，该框架会自动将假名还原为原始PII，确保用户获得准确且保护隐私的输出。

Result: LOPSIDED框架在评估中，与基线技术相比，将语义效用错误减少了5倍，同时增强了隐私保护。评估使用了来自ShareGPT的真实对话数据，并进行了扩充和标注，以检测命名实体与模型响应的上下文相关性。

Conclusion: LOPSIDED框架能够有效解决在远程LLM交互中保护敏感PII的问题，通过语义一致的假名化和解假名化机制，在不牺牲响应质量的情况下显著提高了隐私保护水平，并且在减少语义效用错误方面表现优于现有技术。

Abstract: With the increasing use of conversational AI systems, there is growing
concern over privacy leaks, especially when users share sensitive personal data
in interactions with Large Language Models (LLMs). Conversations shared with
these models may contain Personally Identifiable Information (PII), which, if
exposed, could lead to security breaches or identity theft. To address this
challenge, we present the Local Optimizations for Pseudonymization with
Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a
semantically-aware privacy agent designed to safeguard sensitive PII data when
using remote LLMs. Unlike prior work that often degrade response quality, our
approach dynamically replaces sensitive PII entities in user prompts with
semantically consistent pseudonyms, preserving the contextual integrity of
conversations. Once the model generates its response, the pseudonyms are
automatically depseudonymized, ensuring the user receives an accurate,
privacy-preserving output. We evaluate our approach using real-world
conversations sourced from ShareGPT, which we further augment and annotate to
assess whether named entities are contextually relevant to the model's
response. Our results show that LOPSIDED reduces semantic utility errors by a
factor of 5 compared to baseline techniques, all while enhancing privacy.

</details>


### [85] [Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral](https://arxiv.org/abs/2510.27017)
*Ayoub Hammal,Pierre Zweigenbaum,Caio Corro*

Main category: cs.CL

TL;DR: LLMs' generation capabilities are learned during pre-training, but alignment is still needed, which is computationally expensive. This paper proposes a proxy-based test-time alignment using a small aligned model to reduce costs. The method uses a token-specific cascading approach, reducing the deferral rule to a 0-1 knapsack problem with primal and dual approximations. Experiments show benefits in task performance and speculative decoding speed.


<details>
  <summary>Details</summary>
Motivation: Although large language models (LLMs) learn most of their generation capabilities during pre-training, they still require alignment for downstream tasks and stylistic preferences. Current alignment methods are computationally expensive due to the increasing size of LLMs.

Method: The paper proposes a novel approach called proxy-based test-time alignment, which uses guidance from a small aligned model to reduce the computational cost of alignment. This method is described as a token-specific cascading approach where the token-specific deferral rule is formulated as a 0-1 knapsack problem. The paper derives primal and dual approximations for the optimal deferral decision.

Result: The experimental results demonstrate that the proposed method improves task performance and increases speculative decoding speed.

Conclusion: The proposed proxy-based test-time alignment method effectively reduces the computational costs associated with aligning LLMs while showing benefits in both task performance and decoding speed, offering a more efficient alternative to traditional alignment procedures.

Abstract: Several previous works concluded that the largest part of generation
capabilities of large language models (LLM) are learned (early) during
pre-training. However, LLMs still require further alignment to adhere to
downstream task requirements and stylistic preferences, among other desired
properties. As LLMs continue to scale in terms of size, the computational cost
of alignment procedures increase prohibitively. In this work, we propose a
novel approach to circumvent these costs via proxy-based test-time alignment,
i.e. using guidance from a small aligned model. Our approach can be described
as token-specific cascading method, where the token-specific deferral rule is
reduced to 0-1 knapsack problem. In this setting, we derive primal and dual
approximations of the optimal deferral decision. We experimentally show the
benefits of our method both in task performance and speculative decoding speed.

</details>


### [86] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

Main category: cs.CL

TL;DR: ELM是一种新的神经架构搜索（NAS）方法，用于创建更紧凑、更高效的语言模型，通过灵活的搜索空间、动态模块和新的知识蒸馏损失，在语言模型任务上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型在自然语言理解（NLU）任务中日益重要，但其高昂的计算和内存成本引起了经济和环境问题。

Method: ELM通过引入具有高效Transformer块和动态模块（用于调整维度和注意力头数）的灵活搜索空间，并结合新的知识蒸馏损失来区分不同的架构选择，从而优化紧凑型语言模型。

Result: 在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。

Conclusion: ELM通过其创新的NAS方法，有效地解决了大型预训练语言模型的高成本问题，并生成了性能优越的紧凑型语言模型。

Abstract: As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [87] [W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models](https://arxiv.org/abs/2504.15983)
*Shang Wang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The demand for efficient natural language processing (NLP) systems has led to
the development of lightweight language models. Previous work in this area has
primarily focused on manual design or training-based neural architecture search
(NAS) methods. Recently, zero-shot NAS methods have been proposed for
evaluating language models without the need for training. However, prevailing
approaches to zero-shot NAS often face challenges such as biased evaluation
metrics and computational inefficiencies. In this paper, we introduce
weight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored
for lightweight language models. Our approach utilizes two evaluation proxies:
the parameter count and the number of principal components with cumulative
contribution exceeding $\eta$ in the feed-forward neural (FFN) layer.
Additionally, by eliminating the need for gradient computations, we optimize
the evaluation time, thus enhancing the efficiency of designing and evaluating
lightweight language models. We conduct a comparative analysis on the GLUE and
SQuAD datasets to evaluate our approach. The results demonstrate that our
method significantly reduces training time compared to one-shot NAS methods and
achieves higher scores in the testing phase compared to previous
state-of-the-art training-based methods. Furthermore, we perform ranking
evaluations on a dataset sampled from the FlexiBERT search space. Our approach
exhibits superior ranking correlation and further reduces solving time compared
to other zero-shot NAS methods that require gradient computation.

</details>


### [88] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad,Shamsuddeen Muhammad Hassan,Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 本研究发布了首个豪萨语性别歧视检测数据集，并评估了多种检测方法，强调了文化特异性和语言表达方式带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 在线平台助长性别歧视，但低资源语言的检测方法有限，因此需要为豪萨语开发有效的性别歧视检测和缓解策略。

Method: 通过社群参与、定性编码和数据增强创建豪萨语性别歧视检测数据集；进行用户研究（n=66）以理解豪萨语中的性别歧视表达；实验包括传统机器学习和多语言预训练模型，并评估少样本学习的效果。

Result: 传统机器学习模型在豪萨语性别歧视检测方面表现优于多语言模型；少样本学习方法在性别歧视检测方面有潜力；检测模型在处理澄清性表达和习语时面临挑战，并出现较多误报。

Conclusion: 虽然本研究为豪萨语性别歧视检测奠定了基础，但仍需进一步研究以应对文化特异性和语言复杂性带来的挑战，特别是提高对澄清性表达和习语的检测准确性。

Abstract: Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [89] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [90] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom,Andrea Silvi,Jennifer Culbertson,Moa Johansson,Devdatt Dubhashi,Kenny Smith*

Main category: cs.CL

TL;DR: 递归数制系统在词汇量和句法复杂度之间取得了优化，但之前的研究忽略了“规则性”这一关键因素。


<details>
  <summary>Details</summary>
Motivation: 解释为什么只有自然语言风格的系统能够优化词汇量和句法复杂度的权衡，并提出将“规则性”纳入考量。

Method: 利用最小描述长度（MDL）方法，提出衡量递归数制系统规则性和处理复杂性的新指标。

Result: MDL指标能更好地识别自然语言系统和非自然语言系统之间的差异，并且之前研究中使用的“特设约束”可以从规则性中自然推导出来。

Conclusion: 在研究语言最优性时，必须考虑跨形式集合的规则性。

Abstract: Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [91] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White*

Main category: cs.CL

TL;DR: VISTA是一个用于评估多轮对话事实性的框架，通过分解、验证和追踪，比现有方法更能有效地检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 幻觉（生成与证据或对话无关的陈述）是对话人工智能系统在需要事实可靠性的场景中部署的主要障碍。现有指标的局限性在于它们仅评估孤立的响应，或者将无法验证的内容视为错误，这限制了它们在多轮对话中的应用。

Method: VISTA将助手在对话中的每个回合分解为独立的、原子化的事实声明。然后，它针对可信来源和对话历史记录来验证这些声明。无法验证的声明会被归类为：主观的、矛盾的、缺乏证据的或弃权的。该框架还跟踪声明之间的顺序一致性。

Result: 在八种大型语言模型和四种对话事实性基准（AIS、BEGIN、FAITHDIAL和FADE）上，VISTA在检测幻觉方面显著优于FACTSCORE和LLM-as-Judge基准。人类评估证实，VISTA的分解方法提高了标注者的一致性，并揭示了现有基准中的不一致之处。

Conclusion: VISTA通过将事实性建模为对话的动态属性，为对话系统提供了一种更透明、更符合人类认知的真实性衡量标准。

Abstract: Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [92] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo,Yaxuan Luan,Yue Kang,Xiangchen Song,Jinxu Guo*

Main category: cs.CL

TL;DR: 该方法通过多粒度记忆索引和不确定性估计来提高检索增强生成的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在复杂知识环境下存在覆盖不足、结果不稳定和可靠性有限等问题。

Method: 提出了一种置信度控制方法，该方法集成了多粒度记忆索引和不确定性估计。该方法构建了一个分层的记忆结构，将知识表示划分为不同粒度级别，实现了从局部细节到全局上下文的动态索引和检索，从而在检索和生成之间建立更紧密的语义联系。在此基础上，引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径，使模型在保持信息覆盖的同时有效抑制噪声和虚假内容。整体优化目标包括生成损失、熵约束和方差正则化，形成统一的置信度控制框架。

Result: 实验结果表明，该方法在问答准确率、检索召回率、排序质量和事实一致性方面优于现有模型。

Conclusion: 该研究不仅为检索增强生成提供了新的技术途径，还为提高大型模型在复杂环境下的可靠性和可控性提供了实践证据。

Abstract: This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [93] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski,Meriem Boubdir,Klaudia Bałazy,Besmira Nushi,Pablo Ribalta*

Main category: cs.CL

TL;DR: CoDeC是一种通过测量上下文学习如何影响模型性能来检测和量化大型语言模型中训练数据污染的实用且准确的方法。


<details>
  <summary>Details</summary>
Motivation: 提出一种区分在训练过程中记忆的数据和训练分布外的数据的方法，并量化训练数据污染。

Method: 通过测量上下文学习如何影响模型性能来区分记忆数据和非记忆数据。

Result: CoDeC产生可解释的污染分数，可以清晰地区分已见和未见的数据集，并揭示了在具有未公开训练语料库的开放权重模型中存在强烈的记忆证据。

Conclusion: CoDeC是一种简单、自动化、模型和数据集无关的方法，易于与基准评估集成。

Abstract: We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [94] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng,Huajun Zhang,Xu Yan,Ran Hao,Chong Peng*

Main category: cs.CL

TL;DR: 通过结合对比蒸馏和噪声鲁棒训练的微调方法，解决了大型语言模型在安全对齐和鲁棒性方面的局限性，在知识迁移、鲁棒性和整体安全性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在安全对齐和鲁棒性方面的局限性。

Method: 冻结骨干模型，通过蒸馏将教师模型的知识边界转移到学生模型，并引入噪声扰动和鲁棒优化约束，以提高语义一致性、对齐准确性和模型在噪声输入下的稳定性。整体框架包括蒸馏损失、鲁棒性损失和正则化项。

Result: 该方法在知识迁移、鲁棒性和整体安全性方面显著优于现有基线，在几个关键指标上取得了最佳性能。

Conclusion: 该工作不仅丰富了参数高效微调的理论体系，还为构建更安全、更可信赖的对齐机制提供了新的解决方案。

Abstract: This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [95] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

Main category: cs.CL

TL;DR: SpecAttn通过利用草稿模型在推断过程中计算出的注意力权重，来识别目标模型中的重要标记，从而实现高效的稀疏注意力，减少了75%以上的键值缓存访问，同时仅增加了15.29%的困惑度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在推理过程中由于自注意力机制的二次复杂度，面临着显著的计算瓶颈，尤其是在上下文长度增加的情况下。然而，在推断过程中，草稿模型已经计算了注意力权重，这可以被用来识别目标模型中的重要标记，从而避免冗余计算并保持输出质量。

Method: SpecAttn是一种新的、无需训练的方法，可以与现有的投机解码技术无缝集成，以实现预训练Transformer中的高效稀疏注意力。它采用了三种核心技术：基于KL散度的方法来对齐草稿模型和目标模型之间的层；一种不进行排序的、GPU优化的算法，用于从草稿注意力模式中选择前p个标记；以及受这些预测指导的动态键值缓存修剪。

Result: SpecAttn在PG-19数据集上实现了超过75%的键值缓存访问量减少，同时困惑度仅增加了15.29%，显著优于现有的稀疏注意力方法。

Conclusion: SpecAttn证明了投机执行可以得到增强，从而在不显着降低性能的情况下提供近似验证。

Abstract: Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [96] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz,Sharon Levy*

Main category: cs.CL

TL;DR: LLM的安全护栏可能存在选择性拒绝偏见，即对某些群体比对其他群体更可能拒绝生成有害内容。这可能导致不公平的安全影响。


<details>
  <summary>Details</summary>
Motivation: 研究LLM安全护栏中选择性拒绝偏见的现象，并分析其潜在的安全影响。

Method: 通过分析目标个体和交叉人口群体被拒绝的比例、LLM响应类型以及拒绝的长度来探索选择性拒绝偏见。此外，还通过间接攻击来研究额外的安全影响。

Result: 研究发现在性别、性取向、国籍和宗教属性方面存在选择性拒绝偏见。

Conclusion: LLM的安全护栏需要在不同人口群体之间实现更公平、更稳健的性能。

Abstract: Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [97] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar,Julia Hockenmaier*

Main category: cs.CL

TL;DR: LLM评估者在不同运行中的得分之间存在低内部评分者信度，导致评分不一致，这使得难以衡量其判断的准确性。我们量化了这种不一致性，并探讨了在适当的指导下，LLM评估者是否仍然有用。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成（NLG）的广泛采用，对其进行评估变得困难。最近，使用大型语言模型（LLM）评估生成内容越来越受欢迎，因为它们比传统的n-gram或基于嵌入的指标更能符合人类偏好。

Method: 在实验中，我们表明LLM评估者在不同运行中的得分之间存在低内部评分者信度，并量化了这种不一致性跨不同的NLG任务和基准。

Result: LLM评估者在不同运行中的得分之间存在低内部评分者信度，这种方差使得他们的评分不一致，在最坏的情况下几乎是任意的，使得衡量他们的判断的实际效果变得困难。

Conclusion: 尽管LLM评估者存在不一致性，但我们仍在研究通过制定适当的指南来有效利用LLM评估者的可能性。

Abstract: As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [98] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang,Anej Svete,Jiaoda Li,Anthony Widjaja Lin,Jonathan Rawski,Ryan Cotterell,David Chiang*

Main category: cs.CL

TL;DR: transformers 作为语言模型时，其表达能力比作为语言识别器时更强，并且引入概率性会影响其等价性。


<details>
  <summary>Details</summary>
Motivation: 对 transformer 的表达能力进行表征，特别是在它们作为语言模型（自回归和概率生成）的实际应用场景下，而不是仅作为语言识别器（接受或拒绝字符串）。

Method: 分析将 transformer 语言识别器变为自回归以及变为概率性模型时，对其表达能力的影响，并与非概率模型进行比较。

Result: 研究表明，自回归可以增强 transformer 语言识别器的表达能力，而概率性可能会破坏在非概率情况下成立的等价性。

Conclusion: 明确了 transformer 作为语言模型时的功能和表达能力。

Abstract: Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [99] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton,York Hay Ng,Aditya Khan,Phuong Hanh Hoang,Xiang Lu,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 该研究通过添加脚本向量、整合Glottolog数据和扩展谱系推断来扩展URIEL+语言知识库，解决了数据稀疏性问题，增加了语言覆盖范围，并在跨语言迁移任务中取得了一定的性能提升，特别是在低资源语言方面。


<details>
  <summary>Details</summary>
Motivation: URIEL+语言知识库在支持多语言研究方面存在数据稀疏性问题，尤其是在特征类型缺失、语言条目不完整和系谱覆盖有限方面，这限制了其在跨语言迁移中的应用，特别是对低资源语言的支持。

Method: 通过以下三种方式扩展URIEL+：1. 引入脚本向量来表示7,488种语言的书写系统属性；2. 整合Glottolog数据，增加18,710种语言；3. 通过在谱系中传播类型学和脚本特征，扩展26,449种语言的谱系推断。

Result: 脚本向量稀疏性降低了14%，语言覆盖范围增加了多达19,015种（1007%），并且在某些设置下，性能提升高达6%。

Conclusion: 通过增加脚本向量、整合Glottolog数据和扩展谱系推断，URIEL+变得更加完整和包容，能够更好地支持多语言研究，特别是在低资源语言的跨语言迁移任务中。

Abstract: The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [100] [MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models](https://arxiv.org/abs/2510.27196)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Yayue Deng,Jing Ma*

Main category: cs.CL

TL;DR: MemeArena是一个基于智能体、竞技场风格的评估框架，用于评估多模态大语言模型（mLLMs）对多模态有害内容的理解能力，通过模拟不同解释视角和达成共识来减少评估偏见，结果显示该框架能有效减少评估偏见，并与人类偏好高度一致。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上迷因的激增，需要多模态大语言模型（mLLMs）具备理解多模态有害内容的能力。现有的评估方法主要关注mLLMs的二元分类检测准确性，这往往无法反映有害性在不同语境下的深层解释细微差别。

Method: 提出MemeArena，一个基于智能体、竞技场风格的评估框架，通过模拟多样化的解释情境来制定评估任务，引导mLLMs进行特定视角的分析。通过整合不同观点并达成评估者之间的一致性，实现对mLLMs理解多模态有害能力的公平、无偏评估。

Result: 广泛的实验表明，MemeArena框架能有效减少评估智能体的偏见，其评估结果与人类偏好高度吻合，为在多模态有害内容理解方面进行可靠、全面的mLLM评估提供了宝贵的见解。

Conclusion: MemeArena通过模拟不同解释视角和达成共识，能够为mLLMs在多模态有害内容理解方面的评估提供一个更公平、更准确的基准，其结果与人类判断一致，有效解决了现有评估方法的局限性。

Abstract: The proliferation of memes on social media necessitates the capabilities of
multimodal Large Language Models (mLLMs) to effectively understand multimodal
harmfulness. Existing evaluation approaches predominantly focus on mLLMs'
detection accuracy for binary classification tasks, which often fail to reflect
the in-depth interpretive nuance of harmfulness across diverse contexts. In
this paper, we propose MemeArena, an agent-based arena-style evaluation
framework that provides a context-aware and unbiased assessment for mLLMs'
understanding of multimodal harmfulness. Specifically, MemeArena simulates
diverse interpretive contexts to formulate evaluation tasks that elicit
perspective-specific analyses from mLLMs. By integrating varied viewpoints and
reaching consensus among evaluators, it enables fair and unbiased comparisons
of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments
demonstrate that our framework effectively reduces the evaluation biases of
judge agents, with judgment results closely aligning with human preferences,
offering valuable insights into reliable and comprehensive mLLM evaluations in
multimodal harmfulness understanding. Our code and data are publicly available
at https://github.com/Lbotirx/MemeArena.

</details>


### [101] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou,Yu Wang,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 自然语言信息密度研究发现语言信息存在周期性模式，提出APS方法检测，并验证了这一模式的存在及其与文本结构的关系。


<details>
  <summary>Details</summary>
Motivation: 探讨自然语言信息编码的周期性模式，以理解信息密度理论。

Method: 提出并应用一种名为AutoPeriod of Surprisal (APS)的新方法，该方法结合了经典的周期性检测算法，用于识别文档惊异值序列中的显著周期。

Result: 研究发现相当比例的人类语言展现出强大的信息周期性模式；此外，发现了超越典型文本结构单元（如句子边界、基本话语单元等）的新周期，并通过谐波回归模型进行了确认。

Conclusion: 语言信息的周期性是结构性因素和其他长距离驱动因素共同作用的结果。APS方法在检测语言周期性方面具有优势，并可能应用于大型语言模型生成内容的检测。

Abstract: Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [102] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli,Alireza Salemi,Carrie Ye,Mohamed Abdalla,Hamed Zamani,J Ross Mitchell*

Main category: cs.CL

TL;DR: 本研究提出了BEAM基准和LIGHT框架，用于评估和提高大型语言模型在长上下文推理任务中的表现，解决了现有基准的不足，并展示了LIGHT在提高模型性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）评估基准在测试需要长期记忆和长上下文推理（如对话）的能力时存在不足，这些基准通常缺乏叙事连贯性、领域狭窄且仅测试简单的回忆任务。

Method: 本研究提出了一个两部分解决方案：1. 创建了一个自动生成长（高达10M token）、连贯且主题多样的对话的框架，并生成了针对广泛记忆能力的探测性问题，最终构建了包含100个对话和2000个验证问题的BEAM基准。2. 提出了一个受人类认知启发的LIGHT框架，为LLM配备了长期情节记忆、短期工作记忆和用于累积重要事实的记事本，以增强模型性能。

Result: 在BEAM基准上的实验表明，即使是具有1M token上下文窗口（包括或不包括检索增强）的LLM，在对话变长时也会遇到困难。相比之下，LIGHT框架在各种模型上持续提高了性能，根据骨干LLM的不同，平均比最强的基线提高了3.5%-12.69%。消融研究也证实了每个记忆组成部分的贡献。

Conclusion: LIGHT框架能够有效提升LLM在长对话推理任务上的表现，并且BEAM基准为评估这些能力提供了一个更全面的平台。

Abstract: Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [103] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal,Aarush Gupta*

Main category: cs.CL

TL;DR: LLINK通过将低资源语言作为一种模态来注入知识，提高了指令调优LLM在非拉丁语脚本上的表现，无需更改分词器或重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 指令调优的大型语言模型（LLM）在低资源、非拉丁脚本上的表现不佳，原因是分词器碎片化和跨语言耦合性弱。

Method: LLINK（Latent Language Injection for Non-English Knowledge）是一种计算效率高、语言作为模态的方法。它在不改变分词器或重新训练解码器的情况下，对指令调优的解码器进行条件化。首先，通过一个轻量级的对比投影仪，将冻结的多语言编码器的句子嵌入与解码器的潜在嵌入空间在预留位置对齐。其次，将向量扩展到K个软槽，并使用最小的适配器进行训练，以便冻结的解码器可以消耗该信号。

Result: LLINK 在双语检索方面取得了显著的改进，在 LLM 判定的问答评估中，相对于基线模型有 81.3% 的偏好，相对于直接微调有 63.6% 的偏好。此外，研究发现改进归因于分词膨胀的减少和更强的跨语言对齐，尽管模型在数字精确度方面仍存在不足。

Conclusion: 将低资源语言视为一种模态，为轻量级 LLM 提供了实现更强跨语言对齐的实用途径。

Abstract: Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [104] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu*

Main category: cs.CL

TL;DR: 该研究提出了MedCalc-Eval，一个包含700多个医学计算任务的基准测试集，以评估大型语言模型在医学领域的量化推理能力，并介绍了MedCalc-Env环境和经过微调的Qwen2.5-32B模型，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学领域的大型语言模型基准主要关注问答和描述性推理，忽略了对临床决策至关重要的量化推理能力。现有的数据集（如MedCalc-Bench）在计算任务方面覆盖不足，无法反映真实的计算场景。

Method: 创建了MedCalc-Eval，一个包含700多个任务的大型医学计算能力基准测试集，涵盖方程类（如Cockcroft-Gault、BMI、BSA）和基于规则的评分系统（如Apgar、Glasgow Coma Scale）。还开发了MedCalc-Env，一个基于InternBootcamp框架的强化学习环境，用于多步临床推理和规划。并在此环境中对Qwen2.5-32B模型进行了微调。

Result: 在MedCalc-Eval基准测试中，经过MedCalc-Env微调的Qwen2.5-32B模型取得了最先进的成果，在数值敏感性、公式选择和推理稳健性方面取得了显著的进步。

Conclusion: MedCalc-Eval为评估大型语言模型在医学计算方面的能力提供了一个全面的基准。通过MedCalc-Env和模型微调，可以显著提高模型在这些任务上的性能，尽管在单位转换、多条件逻辑和上下文理解方面仍存在挑战。

Abstract: As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [105] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang,Seonjeong Hwang,Daehui Kim,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: RLM在复杂推理任务上表现出色，但在多语言推理方面存在差距。该研究发现，这种差距主要源于语言理解失败，即模型无法将多语言输入含义表示为英语（其推理过程中的主导语言）。研究评估了几种检测方法，发现监督方法效果最好。基于此，研究提出了选择性翻译策略，仅在检测到理解失败时才将多语言输入翻译成英语。实验表明，该策略能弥合多语言推理差距，接近完全翻译的性能，但仅翻译约20%的输入。


<details>
  <summary>Details</summary>
Motivation: 探究RLM在多语言推理方面存在差距的原因，并评估是否能检测到语言理解失败，以期缩小该差距。

Method: 1. 评估模型在多语言输入上的表现，识别语言理解失败。2. 评估多种检测语言理解失败的方法，寻找效果最佳者（监督方法）。3. 提出选择性翻译策略，仅在检测到理解失败时进行翻译。4. 通过实验验证选择性翻译策略的效果。

Result: 语言理解失败是导致多语言推理差距的主要原因，并且可以被有效检测。选择性翻译策略能够弥合多语言推理差距，其性能接近完全翻译，但翻译量仅占输入量的约20%。

Conclusion: 多语言推理差距主要源于语言理解失败，可以通过检测和选择性翻译来有效解决，为实现更公平的多语言推理提供了新的思路。

Abstract: Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [106] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu,Jiajun Song,Wei Wang*

Main category: cs.CL

TL;DR: LLM的判断似乎依赖于一个单一的“情绪-同意轴”（VAA），该轴同时编码了“好坏”和“真假”，并可能导致事实准确性下降和系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM中已发现的特定概念的解码神经表征暗示了模块化架构，但这些表征是否真正独立仍是未解之谜。本研究旨在探究LLM的判断机制，判断其是依赖于专门的模块还是通用的资源。

Method: 通过在一系列LLM中进行实验，发现了跨多种评估性判断的共同主导维度，即“情绪-同意轴”（VAA）。通过干预实验，研究了该轴如何作为控制信号，引导生成过程以保持与评估状态一致，即使以牺牲事实准确性为代价。

Result: 在多个LLM中，发现多样的评估性判断沿一个主导维度“情绪-同意轴”（VAA）进行计算。该轴同时编码了主观评价（“什么是好的”）和模型对事实声明的同意（“什么是真的”）。干预实验表明，该统一表征会创建一个关键依赖：VAA作为控制信号，引导生成过程构建一个与其评估状态一致的理由，即使牺牲事实准确性。这种机制被称为“推理的从属化”。

Conclusion: LLM的判断机制并非完全独立的模块化系统，而是存在一个统一的“情绪-同意轴”（VAA）。该轴能够将推理过程从公正推断转向目标导向的论证，从而解释了系统性偏见和幻觉的产生，揭示了促进连贯判断的架构如何系统性地破坏忠实推理。

Abstract: A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [107] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing,Christian Goldschmied,Goran Glavaš*

Main category: cs.CL

TL;DR: 为了解决大多数世界语言和自然语言处理任务训练数据不足的问题，本文提出了一种名为TransAlign的新型词对齐方法，该方法利用了大规模多语言机器翻译模型的编码器。实验结果表明，TransAlign在机器翻译驱动的跨语言迁移（XLT）中的词分类任务上，不仅实现了强大的词对齐性能，而且显著优于流行的词对齐和非词对齐方法。


<details>
  <summary>Details</summary>
Motivation: 大多数世界语言和自然语言处理任务缺乏充足的训练数据，现有的翻译方法（如translate-test和translate-train）在跨语言迁移（XLT）中表现出竞争力，但这些方法在进行词分类任务时需要进行标签投影，而现有的基于多语言词对齐器（WAs）的方法效果不佳。

Method: 提出了一种名为TransAlign的新型词对齐方法，该方法利用了大规模多语言机器翻译模型的编码器，并进行了标签投影，以改进基于机器翻译的跨语言迁移（XLT）在词分类任务上的表现。

Result: TransAlign在词对齐性能上表现强大，并且在基于机器翻译的跨语言迁移（XLT）的词分类任务上，显著优于流行的词对齐和最先进的非词对齐标签投影方法。

Conclusion: TransAlign通过利用大规模多语言机器翻译模型的编码器，在词分类任务的跨语言迁移中实现了最先进的性能，证明了其在处理数据稀疏性方面的有效性。

Abstract: In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [108] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang,Chang Xu*

Main category: cs.CL

TL;DR: ThoughtProbe框架利用LLM的隐藏推理特征来提高其推理性能，通过引导树状响应空间探索，并在回答生成后进行聚合，以识别最佳答案。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLM）的推理性能，并提出了一种新颖的框架ThoughtProbe，该框架利用LLM的隐藏推理特征。

Method: ThoughtProbe框架在每次节点扩展时使用分类器作为评分和排名机制，优先考虑得分高的候选者。在完成树扩展后，从所有分支收集答案，并通过聚合所有支持分支的CoT分数来识别最佳答案。

Result: 在多个算术推理基准测试中取得了显著的改进，表明该框架能够全面探索并有效识别有效的推理链。

Conclusion: ThoughtProbe框架通过利用LLM的隐藏推理特征，能够有效提高其推理性能。

Abstract: This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [109] [From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle](https://arxiv.org/abs/2510.27369)
*Tosin Adewumi,Martin Karlsson,Marcus Liwicki,Mikael Sjödahl,Lama Alkhaled,Rihab Gargouri,Nudrat Habib,Franz Hennie*

Main category: cs.CL

TL;DR: 本文对电池生命周期中自然语言处理（NLP）的应用进行了全面的系统性调查，并提出了一个用于数字电池护照（DBP）和电池预测的新型技术语言处理（TLP）框架。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面调查NLP在电池生命周期各个阶段的应用，并提出一个创新的TLP框架以应对该领域面临的挑战。

Method: 采用PRISMA方法，检索了Google Scholar、IEEE Xplore和Scopus三个数据库，对274篇论文进行了初步筛选，最终选择了66篇相关论文进行深入评估。

Result: 调查发现，电池领域正在涌现新的NLP任务，促进了材料发现和生命周期等阶段的发展。然而，仍存在缺乏标准基准等挑战。所提出的TLP框架结合了代理AI和优化提示，有望解决部分挑战。

Conclusion: NLP在电池领域具有巨大潜力，但标准化和基准建设仍是未来的重要方向。提出的TLP框架为解决这些挑战提供了一个有前景的解决方案。

Abstract: We present a comprehensive systematic survey of the application of natural
language processing (NLP) along the entire battery life cycle, instead of one
stage or method, and introduce a novel technical language processing (TLP)
framework for the EU's proposed digital battery passport (DBP) and other
general battery predictions. We follow the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable
databases or search engines, including Google Scholar, Institute of Electrical
and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we
assessed 274 scientific papers before the critical review of the final 66
relevant papers. We publicly provide artifacts of the review for validation and
reproducibility. The findings show that new NLP tasks are emerging in the
battery domain, which facilitate materials discovery and other stages of the
life cycle. Notwithstanding, challenges remain, such as the lack of standard
benchmarks. Our proposed TLP framework, which incorporates agentic AI and
optimized prompts, will be apt for tackling some of the challenges.

</details>


### [110] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu,Zijian Wang,Kuo Zhao,Dong Hu*

Main category: cs.CL

TL;DR: 现有知识编辑方法主要关注MLP模块，忽视了Attn模块，导致编辑效果不佳。本文提出IntAttn-Edit方法，联合更新MLP和Attn模块，并通过知识均衡策略优化更新幅度，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要集中在MLP模块，忽略了Attn模块，可能导致知识残留和编辑效率低下。

Method: 提出IntAttn-Edit方法，将注意力（Attn）模块纳入知识编辑范围，并采用知识均衡策略，根据MLP和Attn模块对知识存储的贡献度分配更新幅度。

Result: 在标准基准测试中，IntAttn-Edit实现了更高的编辑成功率、更好的泛化能力和更强的知识保持能力。

Conclusion: Attn模块在事实知识存储和检索中扮演重要角色，特别是浅层Attn模块。IntAttn-Edit通过联合更新MLP和Attn模块，并采用知识均衡策略，能够有效提升知识编辑的效果。

Abstract: Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [111] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem,Farida Boudichat*

Main category: cs.CL

TL;DR: Awal项目通过collaborative platform收集Tamazight语言数据，但面临参与者信心不足和标准化挑战，数据贡献有限，主要来自语言学家和活动家。


<details>
  <summary>Details</summary>
Motivation: Tamazight语言在数字领域代表性不足，需要开发其语言技术资源。

Method: 通过Awal initiative和awaldigital.org平台收集翻译和语音数据，并分析了18个月的社区参与情况。

Result: 收集到6,421个翻译对和3小时语音数据，但社区贡献有限，主要集中在语言学家和活动家，并指出了众包方法在复杂社会语言学背景下应用的局限性。

Conclusion: 尽管Awal项目受到好评，但社区贡献的规模有限，表明在Tamazight语言的数字化资源开发方面存在挑战，需要进一步改进方法以克服参与障碍。

Abstract: This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [112] [Dynamic Affective Memory Management for Personalized LLM Agents](https://arxiv.org/abs/2510.27418)
*Junfeng Lu,Yueyan Li*

Main category: cs.CL

TL;DR: LLM驱动的AI智能体可以通过贝叶斯驱动的记忆更新算法来优化个性化服务，并通过DABench基准进行评估。


<details>
  <summary>Details</summary>
Motivation: 解决当前AI智能体在个性化体验中存在的记忆冗余、记忆过时和记忆-上下文整合能力差等问题，这些问题主要是由于交互过程中缺乏有效的记忆更新机制。

Method: 提出一种新的记忆管理系统，采用贝叶斯启发的记忆更新算法和记忆熵的概念，通过最小化全局熵来实现动态更新记忆向量数据库，并提出DABench基准来评估情感表达和对象情感变化。

Result: 实验结果表明，该系统在个性化、逻辑连贯性和准确性方面表现优越，并且通过消融研究验证了贝叶斯更新机制在缓解记忆臃肿方面的有效性。

Conclusion: 该研究为长期记忆系统的设计提供了新的思路，重点是利用贝叶斯方法和记忆熵来优化AI智能体的个性化服务能力。

Abstract: Advances in large language models are making personalized AI agents a new
research focus. While current agent systems primarily rely on personalized
external memory databases to deliver customized experiences, they face
challenges such as memory redundancy, memory staleness, and poor memory-context
integration, largely due to the lack of effective memory updates during
interaction. To tackle these issues, we propose a new memory management system
designed for affective scenarios. Our approach employs a Bayesian-inspired
memory update algorithm with the concept of memory entropy, enabling the agent
to autonomously maintain a dynamically updated memory vector database by
minimizing global entropy to provide more personalized services. To better
evaluate the system's effectiveness in this context, we propose DABench, a
benchmark focusing on emotional expression and emotional change toward objects.
Experimental results demonstrate that, our system achieves superior performance
in personalization, logical coherence, and accuracy. Ablation studies further
validate the effectiveness of the Bayesian-inspired update mechanism in
alleviating memory bloat. Our work offers new insights into the design of
long-term memory systems.

</details>


### [113] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong,Senmiao Wang,Hanbo Huang,Ruoyu Sun,Shiyu Liang*

Main category: cs.CL

TL;DR: VCORE是一种新的优化方法，用于改进大型语言模型（LLMs）的监督微调（SFT），通过自适应地分配监督权重来提高其推理能力，尤其是在复杂长推理任务中。


<details>
  <summary>Details</summary>
Motivation: 标准的交叉熵损失函数在微调长链式思考（CoT）轨迹时，对所有token一视同仁，忽略了它们在推理过程中不同贡献，导致监督分配不当和泛化能力减弱，特别是在复杂的长推理任务中。

Method: VCORE将CoT的监督视为一个约束优化问题，从优化理论的角度出发，自适应地为不同token分配监督权重，使训练目标更贴近鲁棒推理泛化的目标。

Result: VCORE在数学和代码基准测试中，在同域和跨域设置下，都显著优于现有的token重加权方法，并在Qwen3系列（4B，8B，32B）和LLaMA-3.1-8B-Instruct模型上取得了良好的性能。此外，VCORE还可以作为后续强化学习的更有效的初始化。

Conclusion: VCORE通过一种原则性的、自适应的监督分配方法，有效地提高了LLMs的推理能力和泛化能力，并且为后续的强化学习提供了更好的基础。

Abstract: Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [114] [A Transformer-based Neural Architecture Search Method](https://arxiv.org/abs/2505.01314)
*Shang Wang,Huanrong Tang,Jianquan Ouyang*

Main category: cs.CL

TL;DR: 提出一种基于Transformer的神经结构搜索方法，搜索不同编码器和解码器组合的多头自注意力计算方式，并引入困惑度作为BLEU分数外的辅助评估指标，通过多目标遗传算法迭代优化，实验结果表明搜索到的结构优于基线模型，且引入辅助评估指标能找到比仅考虑BLEU分数更好的模型。


<details>
  <summary>Details</summary>
Motivation: 为了搜索具有更好翻译结果的神经网络结构。

Method: 基于Transformer架构，搜索跨多头注意力计算方式，针对不同数量的编码器和解码器组合，并使用多目标遗传算法迭代优化，引入困惑度作为BLEU分数外的辅助评估指标。

Result: 实验结果显示，该算法搜索到的神经网络结构优于所有基线模型。

Conclusion: 引入辅助评估指标（困惑度）比仅考虑BLEU分数可以找到更好的模型。

Abstract: This paper presents a neural architecture search method based on Transformer
architecture, searching cross multihead attention computation ways for
different number of encoder and decoder combinations. In order to search for
neural network structures with better translation results, we considered
perplexity as an auxiliary evaluation metric for the algorithm in addition to
BLEU scores and iteratively improved each individual neural network within the
population by a multi-objective genetic algorithm. Experimental results show
that the neural network structures searched by the algorithm outperform all the
baseline models, and that the introduction of the auxiliary evaluation metric
can find better models than considering only the BLEU score as an evaluation
metric.

</details>


### [115] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao,Sijian Ren,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: LLMs在推理方面表现出色，但计算成本高。DLMs可以高效生成样本，因此提出了一种利用DLMs生成候选思维，LLMs评估其质量的框架，以提高推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在推理方面表现出色，但其自回归生成范式导致计算成本高昂，且性能提升不明显。DLMs可以高效生成多样化样本，为解决LLMs的计算瓶颈提供了新思路。

Method: 提出了一种高效的协作推理框架，其中DLMs用于生成候选思维，LLMs用于评估思维的质量。

Result: 实验结果表明，该框架在复杂的推理任务中表现出色，显著提高了推理准确性，同时降低了计算开销。

Conclusion: 所提出的基于DLMs和LLMs的协作推理框架，在保证推理质量的同时，显著提高了推理效率，为未来研究提供了一个有前景的方向。

Abstract: In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [116] [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org/abs/2505.13487)
*Ashwin Kumar,Yuzi He,Aram H. Markosyan,Bobbie Chern,Imanol Arrieta-Ibarra*

Main category: cs.CL

TL;DR: RLHF中的奖励模型可能存在前缀偏见，尤其是在种族和性别维度上，可以通过数据增强来缓解。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF研究中，基于公开偏好数据集训练的奖励模型可能存在潜在偏见，但对前缀偏见的探索不足。

Method: 提出检测和评估语言模型奖励模型中前缀偏见的新方法，并通过数据增强策略来缓解偏见。

Result: 发现多个开源偏好数据集和奖励模型架构均存在显著的前缀偏见，尤其是在种族和性别维度上，并且这种偏见与底层模型架构无关。数据增强策略能有效降低前缀偏见的影响。

Conclusion: 在设计和评估用于训练奖励模型的偏好数据集时，必须考虑偏见问题，以确保公平性和可靠性。

Abstract: Reinforcement Learning with Human Feedback (RLHF) has emerged as a key
paradigm for task-specific fine-tuning of language models using human
preference data. While numerous publicly available preference datasets provide
pairwise comparisons of responses, the potential for biases in the resulting
reward models remains underexplored. In this work, we introduce novel methods
to detect and evaluate prefix bias -- a systematic shift in model preferences
triggered by minor variations in query prefixes -- in LLM-based reward models
trained on such datasets. We leverage these metrics to reveal significant
biases in preference models across racial and gender dimensions. Our
comprehensive evaluation spans diverse open-source preference datasets and
reward model architectures, demonstrating susceptibility to this kind of bias
regardless of the underlying model architecture. Furthermore, we propose a data
augmentation strategy to mitigate these biases, showing its effectiveness in
reducing the impact of prefix bias. Our findings highlight the critical need
for bias-aware dataset design and evaluation in developing fair and reliable
reward models, contributing to the broader discourse on fairness in AI.

</details>


### [117] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

Main category: cs.CL

TL;DR: 本研究比较了静态词向量（GloVe）和上下文嵌入（BERT）与人类对英语复合词的语义判断（词素意义优势LMD和语义透明度ST）的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究计算嵌入与人类语义判断在英语复合词处理中的一致性，以理解复合词处理的驱动因素并为基于嵌入的语义建模提供见解。

Method: 计算基于嵌入的LMD和ST指标，并使用Spearman相关和回归分析评估它们与人类判断的关系，同时考虑关联强度、频率和可预测性度量。

Result: BERT嵌入比GloVe更能捕捉组合语义，并且可预测性评分是人类和模型数据中语义透明度的强预测因子。

Conclusion: BERT嵌入在捕捉英语复合词的组合语义方面优于GloVe，并且可预测性是理解语义透明度的关键因素。

Abstract: This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [118] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu,Chisom Chibuike,Fatimo Adebanjo,Omokolade Awosanya,Samuel Oyeneye*

Main category: cs.CL

TL;DR: 在低资源环境下，因果推断的领域泛化技术（包括因果数据增强和不变因果表征学习）能提高模型在不同领域数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的场景中，机器学习模型常因分布偏移（尤其是在低资源环境下）而难以泛化。本研究旨在通过探索两种因果推断的领域泛化技术来解决这一问题。

Method: 1. 采用因果数据增强（CDA）方法，通过生成反事实样本来提高模型对伪相关性的鲁棒性。将此方法应用于NaijaSenti推特语料库的情感分类任务。 2. 探索使用DINER框架的不变因果表征学习（ICRL）方法，并将其应用于多语言情感分析任务。

Result: 因果数据增强在跨领域情感分类任务中带来了持续的准确性提升。基于DINER框架的不变因果表征学习在多语言情感分析的非分布外（out-of-distribution）表现得到改善，但不同语言间的提升效果不一。

Conclusion: 两种因果推断的领域泛化技术（CDA和ICRL）均能提升模型在低资源环境下的跨领域鲁棒性。CDA在情感分类任务中效果稳定，而ICRL在多语言情感分析中表现出改善，但需要进一步针对不同语言进行优化。

Abstract: Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [119] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos,Legand L. Burge,Anietie Andy,Anis Yazidi,Vladimir Vlassov*

Main category: cs.CL

TL;DR: BiSparse-AAS是一个结合稀疏注意力、自适应跨度和双线性注意力的框架，通过减少计算成本和关注最相关部分来解决Transformer在长文本摘要中的可扩展性问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在文本摘要方面取得了进展，但其二次复杂度限制了处理长文档的可扩展性。

Method: 提出了一种名为BiSparse-AAS的新框架，该框架结合了稀疏注意力、自适应跨度和双线性注意力。稀疏注意力通过关注输入中最相关部分来降低计算成本，自适应跨度动态调整注意力范围，双线性注意力则在此精炼的上下文中对复杂的标记交互进行建模。

Result: BiSparse-AAS在CNN/DailyMail和XSum数据集上分别实现了平均ROUGE改进68.1%和52.6%，并且在OpenWebText和Gigaword数据集上也表现出强大的性能，优于最先进的基线。

Conclusion: BiSparse-AAS通过解决效率、可扩展性和长序列建模问题，为实际文本摘要应用提供了一个统一、实用的解决方案。

Abstract: Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [120] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth,Victor Bursztyn,Puneet Mathur,Ani Nenkova*

Main category: cs.CL

TL;DR: SQLSpace是一种可解释、可泛化、紧凑的text-to-SQL表示方法，可用于基准测试对比、模型性能分析和模型性能提升。


<details>
  <summary>Details</summary>
Motivation: SQLSpace旨在提供一种更优化的表示方法，用于text-to-SQL示例的分析和应用，解决现有表示方法在基准测试对比、模型性能精细化分析以及基于正确性估计的模型性能提升方面的不足。

Method: SQLSpace通过一种新颖的表示方法，实现了对text-to-SQL示例的最小化人工干预下的提取、表示和应用，并将其应用于三个场景：基准测试对比、模型性能分析和模型性能提升。

Result: SQLSpace能够揭示基准测试之间的组成差异，暴露被准确率掩盖的模型性能模式，并支持查询成功率的建模，从而实现更深入的分析和性能提升。

Conclusion: SQLSpace是一种有价值的text-to-SQL表示方法，能够为研究人员和开发人员提供更深入的洞察和更有效的工具。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [121] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte*

Main category: cs.CL

TL;DR: LLMs can generate clinical summaries, but they lack patient-centeredness. This paper introduces Patient-Centered Summaries (PCS) and evaluates open-source LLMs' ability to generate them, finding that while LLMs show promise, human-generated PCS are superior in correctness and patient-centeredness.


<details>
  <summary>Details</summary>
Motivation: Current LLM-generated clinical summaries prioritize patient biology over preferences and values, hindering patient-centered care. This work aims to establish a new standard for AI clinical summarization, focusing on Patient-Centered Summaries (PCS), and to evaluate the capabilities of open-source LLMs in generating them.

Method: A mixed-methods approach was used, involving two Patient and Public Involvement groups (10 patients, 8 clinicians) to define PCS content and structure. Annotation guidelines were developed based on interviews and used by eight clinicians to create gold-standard PCS from 88 atrial fibrillation consultations. Five open-source LLMs were tested using zero-shot and few-shot prompting on 72 consultations, with evaluations based on ROUGE-L, BERTScore, and qualitative metrics.

Result: Patients highlighted the importance of lifestyle, social support, stressors, and values. Clinicians preferred concise summaries with functional, psychosocial, and emotional context. Among the tested LLMs, Mistral-8B and Llama-3.1-8B showed the best zero-shot performance, while Llama-3.1-8B excelled in few-shot prompting. Human-generated PCS were rated higher in correctness and patient-centeredness compared to LLM-generated summaries, although completeness and fluency were comparable.

Conclusion: While open-source LLMs demonstrate potential in generating PCS, they have not yet reached human-level performance, particularly in terms of correctness and patient-centeredness. Further development is needed to align AI capabilities with the nuanced requirements of patient-centered care.

Abstract: Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [122] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori,Nizar Habash,Abdelhakim Freihat,Younes Samih,Kirill Chirkunov,Muhammed AbuOdeh,Radu Florian,Teresa Lynn,Preslav Nakov,Alham Fikri Aji*

Main category: cs.CL

TL;DR: DialectalArabicMMLU是一个新的基准，用于评估大型语言模型在阿拉伯语方言上的表现，填补了现有基准在方言覆盖方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语和多语言基准主要关注现代标准阿拉伯语（MSA），未能充分代表日常交流中普遍使用的阿拉伯语方言，因此需要一个能够评估模型在不同方言上表现的基准。

Method: 将MMLU-Redux框架中的选择题手动翻译并改编成五种主要阿拉伯语方言（叙利亚、埃及、阿联酋、沙特和摩洛哥），共生成15K选择题（包含英/MSA版本则为22K），覆盖32个学术和专业领域。

Result: 在对19个不同规模（1B-13B参数）的阿拉伯语和多语言大型语言模型进行评估后，发现模型在不同方言上的表现存在显著差异，并且在方言泛化能力方面仍有较大提升空间。

Conclusion: DialectalArabicMMLU是首个统一且经过人工整理的资源，用于衡量大型语言模型对阿拉伯语方言的理解能力，有助于推动更具包容性的评估和未来的模型开发。

Abstract: We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [123] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 本研究通过在特定领域语料库上进行进一步预训练，研究了领域自适应和跨语言迁移在低资源医疗NLP任务中的影响。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在医疗NLP领域面临工具缺乏的挑战，本研究旨在探索领域自适应如何缓解这一问题。

Method: 对三种语言（荷兰语、罗马尼亚语、西班牙语）的医疗NLP模型进行了四种进一步预训练实验，并在三个下游任务（自动患者筛选、命名实体识别）上进行了微调。

Result: 领域自适应显著提高了任务性能，临床领域模型优于通用生物医学领域模型，并观察到跨语言迁移能力。

Conclusion: 领域自适应和跨语言迁移在医疗NLP中是可行的，为低资源语言的医疗NLP系统开发提供了指导。

Abstract: In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [124] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira,Antonio Castaldo,James O'Doherty,Sheila Castilho*

Main category: cs.CL

TL;DR: 通过使用CPO模拟后编辑工作流，我们提出了一种数据高效的领域自适应方法，该方法将基础模型的原始输出视为‘拒绝’的翻译，并将人类批准的TM条目视为‘选择’的翻译，以合成偏好对。实验表明，仅使用14.7k偏好对，该模型在MT任务上取得了接近使用160k+ SFT样本训练的模型的性能，证明了其数据效率。


<details>
  <summary>Details</summary>
Motivation: LLM通常需要针对特定领域的特定需求进行调整，而仅依赖SFT的调整过程可能成本高昂。

Method: 通过将基础模型的原始输出视为“拒绝”的翻译，并将人类批准的TM条目视为“选择”的翻译，来合成偏好对，从而模拟后编辑工作流，以实现数据高效的领域自适应。

Result: 在英-巴西葡语和英-韩语的实验中，仅使用14.7k偏好对，该模型就取得了接近使用160k+ SFT样本训练的模型的性能，展示了显著的数据效率。

Conclusion: CPO在MT中的应用通过将模型的初始草稿作为黄金参考的对比信号，可以推广到其他生成任务，以实现数据高效的领域自适应。

Abstract: LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [125] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo,Xiaonan Li,Yuxin Wang,Tingshuo Fan,Yuan Li,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)虽然在推理和生成方面表现出色，但受限于静态预训练数据，存在事实不准确和适应性弱的问题。检索增强生成(RAG)通过结合外部知识来解决这个问题，但其有效性取决于模型获取相关信息的能力。现有RAG系统依赖单一的、具有固定top-k选择的检索器，限制了对语料库的访问。为了克服这一限制，我们提出了MARAG-R1，一个强化学习的多工具RAG框架，使LLM能够动态协调多个检索机制，实现更广泛、更精确的信息访问。MARAG-R1提供了四种检索工具：语义搜索、关键词搜索、过滤和聚合，并通过监督微调和强化学习两阶段训练来学习何时以及如何使用它们。这种设计允许模型交织推理和检索，逐步收集足够的证据进行语料库级别的综合。在GlobalQA、HotpotQA和2WikiMultiHopQA上的实验表明，MARAG-R1在语料库级别的推理任务上显著优于强基线，并取得了新的最先进成果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统依赖单一检索器，限制了信息获取的广度和精度，成为语料库级别推理的主要瓶颈。

Method: 提出MARAG-R1，一个强化学习的多工具RAG框架，使LLM能够动态协调包括语义搜索、关键词搜索、过滤和聚合在内的多种检索工具，并通过两阶段训练（监督微调+强化学习）学习使用这些工具。

Result: MARAG-R1在GlobalQA、HotpotQA和2WikiMultiHopQA数据集上取得了最先进的成果，显著优于现有基线。

Conclusion: MARAG-R1通过引入多工具检索和强化学习，有效解决了现有RAG系统的局限性，提升了LLM在语料库级别推理任务中的信息获取能力和表现。

Abstract: Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [126] [Culture Cartography: Mapping the Landscape of Cultural Knowledge](https://arxiv.org/abs/2510.27672)
*Caleb Ziems,William Held,Jane Yu,Amir Goldberg,David Grusky,Diyi Yang*

Main category: cs.CL

TL;DR: LLMs需要特定文化知识，但预训练中可能无法学到。本文提出了一种名为CultureCartography的混合主动协作方法，通过LLM初始化低置信度问题，人类填补知识空白并引导模型学习，以更有效地发现LLM缺失的文化知识。


<details>
  <summary>Details</summary>
Motivation: 为服务全球用户，LLM需要特定文化知识，但这些知识可能在预训练中未被学习到。因此，需要一种方法来识别对本地用户重要但LLM未知的文化知识。

Method: 提出了一种名为CultureCartography的混合主动协作方法。该方法由LLM初始化一个它回答置信度较低的问题列表，然后由人类用户来填补这些知识空白，并通过编辑来引导模型学习更有意义的文化知识。该方法被实现为一个名为CultureExplorer的工具。

Result: 与仅由人类回答LLM提出问题的基线方法相比，CultureExplorer能更有效地生成领先模型（如DeepSeek R1和GPT-4o）缺失的知识，即使这些模型可以进行网络搜索。使用CultureCartography方法收集的数据对Llama-3.1-8B模型进行微调，可以在相关文化基准测试上将其准确率提高高达19.2%。

Conclusion: 混合主动协作方法（CultureCartography）比传统的单主动方法更能有效地发现LLM所缺乏的特定文化知识，并能显著提高LLM在相关任务上的性能。

Abstract: To serve global users safely and productively, LLMs need culture-specific
knowledge that might not be learned during pre-training. How do we find such
knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The
most common solutions are single-initiative: either researchers define
challenging questions that users passively answer (traditional annotation), or
users actively produce data that researchers structure as benchmarks (knowledge
extraction). The process would benefit from mixed-initiative collaboration,
where users guide the process to meaningfully reflect their cultures, and LLMs
steer the process towards more challenging questions that meet the researcher's
goals. We propose a mixed-initiative methodology called CultureCartography.
Here, an LLM initializes annotation with questions for which it has
low-confidence answers, making explicit both its prior knowledge and the gaps
therein. This allows a human respondent to fill these gaps and steer the model
towards salient topics through direct edits. We implement this methodology as a
tool called CultureExplorer. Compared to a baseline where humans answer
LLM-proposed questions, we find that CultureExplorer more effectively produces
knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even
with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B
by up to 19.2% on related culture benchmarks.

</details>


### [127] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao,Darren Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: CALM 通过将离散的下一个词元预测改为连续的下一个向量预测，将生成步骤减少了 K 倍，从而实现了超高效语言模型。


<details>
  <summary>Details</summary>
Motivation: LLM 的效率受到其顺序生成过程的限制，需要提高每个生成步骤的语义带宽。

Method: CALM 使用高保真自动编码器将 K 个词元压缩成一个连续向量，并开发了一个无似然框架进行训练、评估和采样。

Result: CALM 在性能-计算权衡方面取得了显著的改进，在较低的计算成本下实现了与强大的离散基线相当的性能。

Conclusion: 下一个向量预测为实现超高效语言模型提供了一个强大且可扩展的途径。

Abstract: The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [128] [Electromagnetic Investigation of Crosstalk in Bent Microstrip Lines with Partial and Apertured Shielding: Simulations and Measurements](https://arxiv.org/abs/2510.26908)
*Mohammad Eskandari,Mojtaba Joodaki*

Main category: physics.app-ph

TL;DR: 本研究通过数值模拟和实验测量，研究了带孔屏蔽层隔离的弯曲微带线之间的串扰问题，并讨论了其电磁机制，同时应用多模波导理论预测了带孔屏蔽层的串扰行为。


<details>
  <summary>Details</summary>
Motivation: 研究带孔屏蔽层隔离的弯曲微带线之间的串扰问题，以阐明难以用电路理论建模的复杂串扰现象。

Method: 通过数值模拟和实验测量研究了微带线和屏蔽层不连续性对串扰的影响，并应用多模波导理论预测带孔屏蔽层的串扰行为。

Result: 成功预测了不同情况下的串扰行为。

Conclusion: 本研究概念上阐明了复杂的串扰现象，并为预测此类行为提供了有效方法。

Abstract: This paper presents an electromagnetic investigation of the crosstalk between
two bent microstrip lines (MLs) separated by a perforated planar shield. As an
extension of our previous study, the effects of various discontinuities in
either the MLs or the shield along the coupling path are analyzed through
numerical simulations and validated by measurements. The underlying
electromagnetic mechanisms are also discussed. Furthermore, multimodal wave
theory in a rectangular waveguide is applied to predict crosstalk behavior when
the shield contains an aperture. This study aims to conceptually elucidate
complex crosstalk phenomena that are difficult to model using circuit theory,
and successful predictions of crosstalk behavior are presented for different
problem cases.

</details>


### [129] [Development of organic passive devices for RF applications](https://arxiv.org/abs/2510.27449)
*A. Aliane,A. Daami,T. Card,R. Gwoziecki,I. Chartier,R. Coppard,E. Bergeret,E. Bènevent,P. Pannier*

Main category: physics.app-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A huge interesting progress in the field of organic electronic materials and
devices has been observed in the last decade. However, the understanding of
these materials is still a challenge to overcome. Most studies in literature
focus on active devices such as OTFTs, OLEDs and OPVs. Nevertheless, a complete
technology has to have also passive devices in order to allow the design of
interesting applications and complex circuits. This paper deals with the
development of a complete set of passive devices allowing the fabrication of
simple applications such as filters or sensors. The process flow is a fully
screen printed technology that uses exclusively organic materials on gold laser
ablated flexible substrate. Discrete passive (R, L, C) devices have been
processed and characterized. This has permitted the fabrication of RLC low-band
pass filters that are dedicated to RF applications, typically around 1GHz.
Furthermore, based on these discrete passive components, we have developed a
sensitive sensor on flexible substrate for RFID applications. We present the
state of the art of our process development for RF applications using organic
materials.

</details>


### [130] [Revisiting the Theory of Photocurrent in Solar Cells](https://arxiv.org/abs/2510.27577)
*T. Matsuura,S. Saijo*

Main category: physics.app-ph

TL;DR: p-n结的内建电势对光伏效应至关重要，传统理论未充分考虑其影响。本文提出了改进的光电流解析表达式，包含一个未被识别的反向光电流分量，该分量会降低总光电流，而内建电势能抑制它。该模型还预测在特定正向偏压下光电流会消失，并通过实验得到验证。


<details>
  <summary>Details</summary>
Motivation: 传统光伏效应理论未能充分量化p-n结内建电势对光电流的影响，本文旨在修正和完善该理论。

Method: 通过应用更精确的边界条件，重新审视了经典光伏效应理论，并提出了一种改进的光电流解析表达式。

Result: 提出了一种包含传统光电流和先前未被识别的反向光电流的新解析表达式，后者会降低总光电流，且内建电势起抑制作用。模型预测在特定正向偏压下光电流会消失，该预测已通过商业硅太阳能电池的实验得到验证。

Conclusion: 内建电势直接影响光电流行为，其对反向光电流的抑制作用以及在特定正向偏压下导致光电流消失的效应，通过实验得到了证实。

Abstract: The built-in potential of p-n junctions plays a critical role in charge
separation, which is fundamental to the photovoltaic effect. However, the
conventional classical theory of photovoltaic effect in p-n junctions typically
does not account for the quantitative influence of the built-in potential. In
this study, we revisit the classical theory and propose an improved analytic
expression of photocurrent by applying more accurate boundary conditions. Our
improved expression reveals that the photocurrent comprises of two components:
the conventional photocurrent and a previously unrecognized backward
photocurrent. Latter reduces the total photocurrent, yet it has not been
discussed in prior literature. The essential role of the built-in potential is
to suppress this backward current. Furthermore, our improved expression of
photocurrent predicts that the photocurrent vanishes under certain forward bias
conditions. This prediction is experimentally validated using a commercial
silicon solar cell, confirming the direct impact of the built-in potential on
photocurrent behavior.

</details>


### [131] [Informatics-Driven Selection of Polymers for Fuel-Cell Applications](https://arxiv.org/abs/2212.13198)
*Huan Tran,Kuan-Hsuan Shen,Shivank Shukla,Ha-Kyung Kwon,Rampi Ramprasad*

Main category: physics.app-ph

TL;DR: 通过信息学方案筛选出60种可替代Nafion的新型聚合物，用于质子交换膜（PEM）和催化剂层的离子聚合物。


<details>
  <summary>Details</summary>
Motivation: Nafion在燃料电池中的应用存在一些限制（如玻璃化转变温度低），因此需要寻找替代材料。

Method: 提出一个基于信息学的方案，包括：1. 确定所需性质；2. 开发预测性质的机器学习模型；3. 定义搜索空间；4. 使用模型筛选搜索空间。

Result: 成功筛选出60种候选聚合物，可用于PEM、阳极离子聚合物和阴极离子聚合物。

Conclusion: 提出的信息学方案具有通用性，可用于未来多种聚合物材料的选择。

Abstract: Modern fuel cell technologies use Nafion as the material of choice for the
proton exchange membrane (PEM) and as the binding material (ionomer), used to
assemble the catalyst layers of the anode and cathode. These applications
demand high proton conductivity as well as other requirements. For example, PEM
is expected to block electrons, oxygen, and hydrogen from penetrating and
diffusing while the anode/cathode ionomer should allow hydrogen/oxygen to move
easily, so that they can reach the catalyst nanoparticles. Given some of the
well-known limits of Nafion, such as low glass-transition temperature, the
community is in the midst of an active search for Nafion replacements. In this
work, we present an informatics-based scheme to search large polymer chemical
spaces, which includes establishing a list of properties needed for the
targeted applications, developing predictive machine-learning models for these
properties, defining a search space, and using the developed models to screen
the search space. Using the scheme, we have identified 60 new polymer
candidates for PEM, anode ionomer, and cathode ionomer that we hope will be
advanced to the next step, i.e., validating the designs through synthesis and
testing. The proposed informatics scheme is generic, and can be used to select
polymers for multiple applications in the future.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [132] [Path-integral Monte Carlo estimator for the dipole polarizability of quantum plasma](https://arxiv.org/abs/2510.26836)
*Juha Tiihonen,David Trejo-Garcia,Tapio T. Rantala,Marco Ornigotti*

Main category: cond-mat.mes-hall

TL;DR: We introduce a novel path-integral Monte Carlo estimator to compute the dipole polarizability of Coulomb plasma in the long-wavelength limit, utilizing a real-space dipole autocorrelation function suitable for small systems and finite clusters. The method accurately simulates thermal equilibrium with exact Coulomb interactions and Boltzmann quantum statistics, showing excellent agreement with the Drude model at finite temperatures and densities. The approach is validated and applicable to various advanced optical phenomena and materials.


<details>
  <summary>Details</summary>
Motivation: The conventional dynamic structure factor method is not well-suited for calculating the dipole polarizability of interacting Coulomb plasma in the long-wavelength limit, especially for small cell sizes and finite clusters. This paper addresses this limitation by proposing a new approach.

Method: A path-integral Monte Carlo estimator is developed, which is based on the real-space dipole autocorrelation function rather than the reciprocal space dynamic structure factor. This method allows for the simulation of thermal equilibrium in imaginary time, incorporating exact Coulomb interactions and Boltzmann quantum statistics. The approach is validated against analytic continuation of the Drude model and is shown to be modestly affected by finite time-step and finite-size effects.

Result: The proposed method demonstrates perfect agreement with the Drude model within ranges of finite temperatures and densities, indicating its accuracy. Method parameters were found to have only modest significance. The approach has been carefully validated against an exactly solvable reference.

Conclusion: The presented path-integral Monte Carlo estimator is a validated and effective method for calculating the dipole polarizability of Coulomb plasma in the long-wavelength limit. Its applicability extends to more complex areas such as higher-order optical response, quantum effects, plasmonics, and nonlinear optics, including epsilon-near-zero materials.

Abstract: We present a path-integral Monte Carlo estimator for calculating the dipole
polarizability of interacting Coulomb plasma in the long-wavelength limit,
i.e., the optical region. Unlike the conventional dynamic structure factor in
reciprocal space, our approach is based on the real-space dipole
autocorrelation function and is suited for long wavelengths and small cell
sizes, including finite clusters. The simulation of thermal equilibrium in
imaginary time has exact Coulomb interactions and Boltzmann quantum statistics.
For reference, we demonstrate analytic continuation of the Drude model into the
imaginary time and Matsubara series, showing perfect agreement with our data
within ranges of finite temperatures and densities. Method parameters, such as
the finite time-step and finite-size effects prove only modestly significant.
Our method, here carefully validated against an exactly solvable reference,
remains amenable to more interesting domains in higher-order optical response,
quantum confinements and quantum statistical effects, and applications in
plasmonics, heterogeneous plasmas and nonlinear optics, such as
epsilon-near-zero materials.

</details>


### [133] [Distributing entanglement between distant semiconductor qubit registers using a shared-control shuttling link](https://arxiv.org/abs/2510.26860)
*Zarije Ademi,Marion Bassi,Cécile X. Yu,Sander L. de Snoo,Stefan D. Oosterhout,Amir Sammak,Lieven M. K. Vandersypen,Giordano Scappucci,Corentin Déprez,Menno Veldhorst*

Main category: cond-mat.mes-hall

TL;DR: 通过在德国的空穴自旋量子比特中构建基于共享控制的穿梭连接，实现了模块化量子处理器的首次量子纠缠


<details>
  <summary>Details</summary>
Motivation: 为了构建可扩展的模块化量子计算机，需要实现量子比特寄存器之间的连接，以实现高连接性和控制电路空间。本研究旨在实现一个基本的模块化量子处理器，该处理器基于德国的空穴自旋量子比特，并通过共享控制的穿梭链接合远程量子比特寄存器，以实现量子纠缠。

Method: 开发了一种补偿自旋轨道相互作用引起的自旋旋转的协议，实现了在约一百纳秒内将量子比特在相距一微米以上的量子比特寄存器之间进行穿梭。结合局域量子比特操作和相干穿梭，生成了由不同寄存器中的自旋形成的贝尔态。

Result: 实现了两个相距超过一微米的自旋量子比特之间的量子纠缠，并通过量子态层析成像进行了表征。

Conclusion: 本研究首次实现了模块化量子处理器中基于空穴自旋量子比特的共享控制穿梭链接合，并演示了远程量子比特寄存器之间的量子纠缠，为构建可扩展的量子计算机奠定了基础。

Abstract: Semiconductor quantum processors have potential to scale to modular quantum
computers, in which qubit registers are coupled by quantum links, enabling high
connectivity and space for control circuitry. Individual spin-qubit registers
have progressed to two-dimensional systems and execution of small quantum
algorithms. Separately, high-fidelity spin shuttling has been demonstrated in
linear channels defined by individual gate electrodes. Here, we realize the
first shared-control shuttling link integrated between distant qubit registers
to demonstrate quantum entanglement in a basic modular quantum processor based
on hole spin qubits in germanium. We develop a protocol to compensate for
spin-orbit-induced rotations during qubit transfer, allowing for shuttling
between qubit registers separated by more than one micrometer in approximately
a hundred nanoseconds. Combining local qubit operation with coherent shuttling,
we generate Bell states formed by spins residing in separate registers.
Characterizing them using quantum state tomography, we demonstrate entanglement
between spin qubits in distant registers.

</details>


### [134] [Single femtosecond laser pulse-driven ferromagnetic switching](https://arxiv.org/abs/2510.27288)
*Chen Xiao,Boyu Zhang,Xiangyu Zheng,Yuxuan Yao,Jiaqi Wei,Dinghao Ma,Yuting Gong,Rui Xu,Xueying Zhang,Yu He,Wenlong Cai,Yan Huang,Daoqian Zhu,Shiyang Lu,Kaihua Cao,Hongxi Liu,Pierre Vallobra,Xianyang Lu,Youguang Zhang,Bert Koopmans,Weisheng Zhao*

Main category: cond-mat.mes-hall

TL;DR: 利用单激光脉冲通过热诱导的各向异性扭矩在铁磁材料中实现了相干磁化切换，克服了传统光脉冲写入的限制，并在CoFeB/MgO基磁性隧道结中展现出高磁阻和优异的能量效率，为光子自旋电子学在下一代存储技术中的应用铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 太长不看：利用单激光脉冲通过热诱导的各向异性扭矩在铁磁材料中实现了相干磁化切换，克服了传统光脉冲写入的限制，并在CoFeB/MgO基磁性隧道结中展现出高磁阻和优异的能量效率，为光子自旋电子学在下一代存储技术中的应用铺平了道路。

本研究的动机在于，尽管光脉冲在磁性存储领域具有巨大潜力，但目前仅限于铁磁材料，且对材料成分和温度条件要求苛刻。对于广泛应用于自旋电子存储的主流铁磁材料，通过激光诱导加热实现双稳态切换被认为极其困难，因为这无法打破时间反演对称性。因此，本研究旨在探索一种在铁磁材料中实现单脉冲光学切换的方法，以克服现有技术的局限性。

Method: 通过单激光脉冲驱动，利用热诱导的各向异性扭矩实现铁磁材料中的相干磁化切换。该方法在宽脉冲持续时间（飞秒至皮秒）范围内表现出鲁棒性，并在CoFeB/MgO基磁性隧道结中得到验证，该隧道结具有超过110%的高磁阻。此外，该现象在纳米尺度上表现出可扩展性，并且具有优异的能量效率（每个100纳米尺寸的比特为17飞焦）。

Result: 成功在铁磁材料中通过单激光脉冲实现了相干磁化切换。此切换行为在飞秒到皮秒的脉冲持续时间内表现稳健。在具有超过110%磁阻的CoFeB/MgO基磁性隧道结中，该现象具有可重复性。该方法可扩展至纳米尺度，并且能量效率极高（每100纳米尺寸的比特为17飞焦）。

Conclusion: 本研究在铁磁材料中实现了由热诱导的各向异性扭矩驱动的单激光脉冲相干磁化切换，克服了传统方法的限制，并展现出高磁阻、可重复性和优异的能量效率。这标志着光子自旋电子学技术在下一代存储和内存技术集成方面取得了显著进展。

Abstract: Light pulses offer a faster, more energy-efficient, and direct route to
magnetic bit writing, pointing toward a hybrid memory and computing paradigm
based on photon transmission and spin retention. Yet progress remains hindered,
as deterministic, single-pulse optical toggle switching has so far been
achieved only with ferrimagnetic materials, which require too specific a
rare-earth composition and temperature conditions for technological use. In
mainstream ferromagnet--central to spintronic memory and storage--such bistable
switching is considered fundamentally difficult, as laser-induced heating does
not inherently break time-reversal symmetry. Here, we report coherent
magnetization switching in ferromagnets, driven by thermal anisotropy torque
with single laser pulses. The toggle switching behavior is robust over a broad
range of pulse durations, from femtoseconds to picoseconds, a prerequisite for
practical applications. Furthermore, the phenomenon exhibits reproducibility in
CoFeB/MgO-based magnetic tunnel junctions with a high magnetoresistance
exceeding 110%, as well as the scalability down to nanoscales with remarkable
energy efficiency (17 fJ per 100-nm-sized bit). These results mark a notable
step toward integrating opto-spintronics into next-generation memory and
storage technologies.

</details>


### [135] [Rydberg excitons in Cu$_2$O at millikelvin temperatures](https://arxiv.org/abs/2510.26966)
*Julian Heckötter,David Janas,Marc Aßmann,Manfred Bayer*

Main category: cond-mat.mes-hall

TL;DR: Rydberg excitons in Cu2O show distinct sensitivities to excitation power and temperature, with P excitons reacting more strongly than D excitons, suggesting the influence of internal electric fields. Excitons with n=29 are observed at low laser intensities.


<details>
  <summary>Details</summary>
Motivation: Investigate the behavior of Rydberg excitons in Cu2O under varying temperature and excitation power, particularly the differential response of P and D excitons.

Method: Experimentally varying temperature and excitation power, and observing absorption spectra of Rydberg excitons in Cu2O.

Result: P excitons near the band gap are more sensitive to increased excitation power than D excitons. Excitons with n=29 are observed at laser intensities below 1 μW/cm^2.

Conclusion: The observed behavior of excitons is likely due to internal electric fields generated by optically ionized charged impurities, similar to the effects of an external electric field.

Abstract: Rydberg excitons in the semiconductor Cu$_2$O have been observed in
absorption experiments up to a principal quantum number of n = 28 at
millikelvin temperatures [1]. Here, we extend the experimental parameter space
by variing both temperature and excitation power. In particular, we show that
the P excitons close to the band gap react more sensitively to an increase of
the excitation power than states of the associated D exciton multiplet, even
though the latter are located at comparatively higher energy. This finding is
similar to the one observed when applying an external electric field,
suggesting that the observed behavior arises from internal electric fields
created by charged impurities that are optically ionized. At laser intensities
below 1 $\mu$W/cm$^2$, absorption lines of excitons with n=29 are observed.

</details>


### [136] [Characterizing Skyrmion Flow Phases with Principal Component Analysis](https://arxiv.org/abs/2510.26987)
*C. J. O. Reichhardt,D. McDermott,C. Reichhardt*

Main category: cond-mat.mes-hall

TL;DR: PCA可用于识别和区分不同类型的驱动斯格明子流体相。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用PCA来表征非平衡系统中的斯格明子运动相变，并探索其在非平衡系统中的应用潜力。

Method: 利用包含位置和速度信息的特征向量，将PCA应用于驱动斯格明子的运动，以区分不同的流体相。

Result: PCA成功区分了已知的以及几种新的斯格明子流体相，包括通道流、流动流体和部分有序态。PCA分析还可以与横向和纵向速度-力曲线、微分电导率、拓扑缺陷密度和斯格明子霍尔角等宏观输运测量联系起来。

Conclusion: PCA是一种有效的分析非平衡系统动力学的方法，尤其是在区分不同的无序相方面。通过调整特征向量，可以提高PCA的分辨率，并且该方法可以推广到其他具有时间依赖性动力学的非平衡系统。

Abstract: Principal component analysis (PCA) is a powerful method that can identify
patterns in large, complex data sets by constructing low-dimensional order
parameters from higher-dimensional feature vectors. There are increasing
efforts to use space-and-time-dependent PCA to detect transitions in
nonequilibrium systems that are difficult to characterize with equilibrium
methods. Here, we demonstrate that feature vectors incorporating the position
and velocity information of driven skyrmions moving through random disorder
permit PCA to resolve different types of disordered skyrmion motion as a
function of driving force and the ratio of the Magnus force to the dissipation.
Since the Magnus force creates gyroscopic motion and a finite Hall angle,
skyrmions can exhibit a greater range of flow phases than what is observed in
overdamped driven systems with quenched disorder. We show that in addition to
identifying previously known skyrmion flow phases, PCA detects several
additional phases, including different types of channel flow, moving fluids,
and partially ordered states. Guided by the PCA analysis, we further
characterize the disordered flow phases to elucidate the different microscopic
dynamics and show that the changes in the PCA-derived order parameters can be
connected to features in bulk transport measures, including the transverse and
longitudinal velocity-force curves, differential conductivity, topological
defect density, and changes in the skyrmion Hall angle as a function of drive.
We discuss how asymmetric feature vectors can be used to improve the resolution
of the PCA analysis, and how this technique can be extended to find disordered
phases in other nonequilibrium systems with time-dependent dynamics.

</details>


### [137] [Metallic electro-optic effects in topological chiral crystals](https://arxiv.org/abs/2510.26992)
*C. O. Ascencio,D. J. P. de Sousa,Tony Low*

Main category: cond-mat.mes-hall

TL;DR: 拓扑手性晶体在光学现象研究中具有重要潜力，本研究利用紧束缚模型和第一性原理计算，研究了198空间群（SG198）材料中源于布洛赫电子 Berry 优伐和轨道磁矩的金属电光（EO）响应。


<details>
  <summary>Details</summary>
Motivation: 研究源于 Berry 优伐和轨道磁矩的金属电光（EO）响应在拓扑手性晶体中的潜在应用。

Method: 利用紧束缚模型和第一性原理计算，研究了198空间群（SG198）材料的电光响应。

Result: 发现了SG198材料中非零的 Berry 优伐偶极矩，并证明了BeAu在实验可行的电场下可以实现由 Berry 优伐和磁矩相互作用产生的磁电光效应。

Conclusion: 拓扑手性晶体，特别是198空间群材料，具有显著的电光响应潜力，为未来光电器件的发展提供了新的方向。

Abstract: Topological chiral crystals have emerged as a fertile material platform for
investigating optical phenomena derived from the distinctive Fermi surface
Berry curvature and orbital magnetic moment textures around multifold chiral
band crossings pinned at the time-reversal invariant momenta. In this work, by
means of tight-binding model and first principles based calculations, we
investigate metallic electro-optic (EO) responses stemming from the Berry
curvature and orbital magnetic moment of Bloch electrons across 37 materials
belonging to space group 198 (SG198). Previously thought to vanish in SG198,
our findings reveal a nonzero Berry curvature dipole attributed to the
energetic misalignment between topologically charged point nodes of opposite
chirality. Moreover, we find that the recently predicted magnetoelectric EO
effects, which arise from the interplay between the Berry curvature and
magnetic moment on the Fermi surface, are readily accessible in BeAu under
experimentally feasible electric biases.

</details>


### [138] [Spin Dependence of Charge Dynamics and Group Velocity in Chiral Molecules](https://arxiv.org/abs/2510.27061)
*Riley Stuermer,Collin VanEssen,Jacob Byers,Keith Ferrer,Prasad Gudem,Diego Kienle,Jonas Fransson,Mani Vaidyanathan*

Main category: cond-mat.mes-hall

TL;DR: 外消旋体诱导的自旋选择性（CISS）效应在手性分子中得到研究，在有/无磁场下，其自旋极化与实验结果吻合，这对手性分子在电子器件中的应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: CISS效应在手性分子中的瞬态动力学行为对于理解CISS效应及其在电子器件中的应用至关重要。

Method: 使用时间依赖性量子输运模拟来研究手性分子中的瞬态CISS动力学。

Result: 当连接两个电极时，手性分子中可以维持非零的自旋极化，这与单电极连接的情况不同。所模拟的自旋极化与实验参考数据在定性上一致，这在计算的自旋极化在手性分子单层中的不同磁场特征时得到证明。

Conclusion: 研究表明，手性分子中的非零自旋极化源于电子的自旋依赖群速度。模拟结果与实验观察一致，表明CISS效应在手性分子中的应用潜力。

Abstract: Chiral molecules are known to preferentially select electrons with a
particular spin state, an effect termed chirality-induced spin selectivity
(CISS). In this work, the transient CISS dynamics in a chiral molecule are
investigated through time-dependent quantum-transport simulations, an important
step toward further understanding CISS and its application in devices such as
magnetoresistive random access memories and spin-based quantum computers. We
show that a nonzero spin polarization throughout the chiral molecule can be
attributed to a spin-dependent group velocity of electrons. Contrary to the
case where a chiral molecule is connected to a single lead, this spin
polarization persists into the steady state when two leads are connected. We
show that the simulated spin polarization qualitatively agrees with a reference
experiment, as evidenced by the distinct magnetic-field signatures calculated
from the spin polarization within a monolayer of chiral molecules.

</details>


### [139] [Theoretical Investigation of Anomalous Hall and Nernst Responses in Potassium Tri Vanadium Pentantimonide](https://arxiv.org/abs/2510.27230)
*Partha Goswami*

Main category: cond-mat.mes-hall

TL;DR: kagome金属钾三钒五锑矿中的反常能斯特和霍尔电导率


<details>
  <summary>Details</summary>
Motivation: 研究kagome 金属钾三钒五锑矿中的反常能斯特和霍尔电导率

Method: 基于包含最近邻和复杂次近邻跃迁、Rashba自旋轨道耦合、磁邻近引起的交换场和电荷密度波势的系统哈密顿量。

Result: 能斯特电导率表现出非单调温度依赖性，在达到峰值后因热展宽而下降；化学势的微小变化会显著改变能斯特信号；引入动量空间缠绕后，两个能带获得相反的陈数。

Conclusion: kagome 金属钾三钒五锑矿中的能斯特电导率对温度和载流子密度敏感，并且存在弱拓扑特征。

Abstract: We present a theoretical study of the anomalous Nernst and Hall conductance
in the Kagome metal potassium tri vanadium pentantimonide, based on a system
Hamiltonian incorporating nearest neighbour and complex next nearest neighbour
hopping, Rashba spin orbit coupling, an exchange field induced by magnetic
proximity, and a charge density wave potential. Our analysis reveals that the
Nernst conductivity exhibits a non monotonic temperature dependence. It
increases with temperature, reaches a pronounced peak, and subsequently
declines at higher temperatures due to thermal broadening, which diminishes the
influence of Berry curvature. Notably, small shifts in the chemical potential
can lead to dramatic changes in the Nernst signal enhancing its magnitude or
even reversing its sign highlighting the system sensitivity to carrier density.
We further explore the anomalous Hall behaviour within this framework. The band
structure hosts multiple bands with nonzero Berry curvature, and preliminary
Chern number calculations suggest weak topological features, namely, while not
fully quantized, the system exhibits significant Berry curvature accumulation.
Upon introducing momentum space winding, implemented via a momentum dependent
phase in the complex hopping terms to mimic orbital magnetic flux, we observe
that two bands acquire opposite Chern numbers. The remaining bands remain
topologically trivial.

</details>


### [140] [On-chip cavity electro-acoustics using lithium niobate phononic crystal resonators](https://arxiv.org/abs/2510.27496)
*Jun Ji,Joseph G. Thomas,Zichen Xi,Liyang Jin,Dayrl P. Briggs,Ivan I. Kravchenko,Arya G. Pour,Liyan Zhu,Yizheng Zhu,Linbo Shao*

Main category: cond-mat.mes-hall

TL;DR: 利用铌酸锂声子晶体谐振器实现腔电声动力学，并展示了宏观量子现象和非互易频率转换。


<details>
  <summary>Details</summary>
Motivation: 量子技术中机械系统的相干时间和耦合能力至关重要，现有技术（如光力学和压电耦合）存在局限性，需要新的方法来相干和动态控制GHz频率的机械模式。

Method: 在铌酸锂（LN）上构建微波频率电调谐声子晶体（PnC）谐振器，利用PnC的高色散特性使声子模式频率不均匀分布，模拟原子能级。通过施加电场，利用LN的非线性压电效应调制声子模式，实现原子类跃迁。在两模式系统中演示了Autler-Townes分裂（ATS）、交流斯塔克频移和拉比振荡。在三模式系统中实现了高达20 dB隔离度的非互易频率转换，转换率可通过调制脉冲的时间延迟进行调节。

Result: 在两模式系统中实现了最大相干度为4.18的ATS、交流斯塔克频移和拉比振荡。在三模式系统中实现了高达20 dB的非互易频率转换，且可通过时间延迟调节。

Conclusion: 所提出的腔电声平台利用铌酸锂声子晶体谐振器，能够实现宏观量子现象和可调的非互易频率转换，在传感、微波信号处理、声子计算和量子声学等领域具有广泛的应用前景。

Abstract: Mechanical systems are pivotal in quantum technologies because of their long
coherent time and versatile coupling to qubit systems. So far, the coherent and
dynamic control of gigahertz-frequency mechanical modes mostly relies on
optomechanical coupling and piezoelectric coupling to superconducting qubits.
Here, we demonstrate on-chip cavity electro-acoustic dynamics using our
microwave-frequency electrically-modulated phononic-crystal (PnC) resonators on
lithium niobate (LN). Leveraging the high dispersion of PnC, our phononic modes
space unevenly in the frequency spectrum, emulating atomic energy levels.
Atomic-like transitions between different phononic modes are achieved by
applying electrical fields to modulate phononic modes via nonlinear
piezoelectricity of LN. Among two modes, we demonstrate Autler-Townes splitting
(ATS), alternating current (a.c.) Stark shift, and Rabi oscillation with a
maximum cooperativity of 4.18. Extending to three modes, we achieve
non-reciprocal frequency conversions with an isolation up to 20 dB.
Nonreciprocity can be tuned by the time delay between the two modulating
pulses. Our cavity electro-acoustic platform could find broad applications in
sensing, microwave signal processing, phononic computing, and quantum
acoustics.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [141] [Programmable digital quantum simulation of 2D Fermi-Hubbard dynamics using 72 superconducting qubits](https://arxiv.org/abs/2510.26845)
*Faisal Alam,Jan Lukas Bosse,Ieva Čepaitė,Adrian Chapman,Laura Clinton,Marcos Crichigno,Elizabeth Crosson,Toby Cubitt,Charles Derby,Oliver Dowinton,Paul K. Faehrmann,Steve Flammia,Brian Flynn,Filippo Maria Gambetta,Raúl García-Patrón,Max Hunter-Gordon,Glenn Jones,Abhishek Khedkar,Joel Klassen,Michael Kreshchuk,Edward Harry McMullan,Lana Mineh,Ashley Montanaro,Caterina Mora,John J. L. Morton,Dhrumil Patel,Pete Rolph,Raul A. Santos,James R. Seddon,Evan Sheridan,Wilfrid Somogyi,Marika Svensson,Niam Vaishnav,Sabrina Yue Wang,Gethin Wright*

Main category: quant-ph

TL;DR: 使用谷歌的量子处理器对 2D 费米-哈伯德模型进行可编程数字量子模拟，规模超出经典模拟能力。


<details>
  <summary>Details</summary>
Motivation: 模拟量子多体系统的时域动力学是量子计算机的原始应用，源于量子相互作用在材料和分子性质中的关键作用。

Method: 在谷歌的 Willow 量子处理器上，使用 72 个量子比特，对最大为 6x6 的晶格尺寸进行 2D 费米-哈伯德模型的数字量子模拟，并研究了磁极化子形成、条纹有序态的动力学对称性破缺、价键固体上的电荷载流子吸引以及通过热化趋于平衡等现象。

Result: 在可行的参数范围内，将模拟结果与精确计算和张量网络/算子传播方法进行了验证和比较。

Conclusion: 在最先进的量子硬件上，可编程数字量子模拟在多体相互作用电子模型方面已具有竞争力。

Abstract: Simulating the time-dynamics of quantum many-body systems was the original
use of quantum computers proposed by Feynman, motivated by the critical role of
quantum interactions between electrons in the properties of materials and
molecules. Accurately simulating such systems remains one of the most promising
applications of general-purpose digital quantum computers, in which all the
parameters of the model can be programmed and any desired physical quantity
output. However, performing such simulations on today's quantum computers at a
scale beyond the reach of classical methods requires advances in the efficiency
of simulation algorithms and error mitigation techniques. Here we demonstrate
programmable digital quantum simulation of the dynamics of the 2D Fermi-Hubbard
model -- one of the best-known simplified models of electrons in crystalline
solids -- at a scale beyond exact classical simulation. We implement
simulations of this model on lattice sizes up to $6\times 6$ using 72 qubits on
Google's Willow quantum processor, across a range of physical parameters,
including on-site electron-electron interaction strength and magnetic flux, and
study phenomena including formation of magnetic polarons, i.e. charge carriers
surrounded by local magnetic polarisation, dynamical symmetry breaking in
stripe-ordered states, attraction of charge carriers on an entangled state
known as a valence bond solid, and the approach to equilibrium through
thermalisation. We validate our results against exact calculations in parameter
regimes where these are feasible, and compare them to approximate classical
simulations performed using tensor network and operator propagation methods.
Our results demonstrate that programmable digital quantum simulation of
many-body interacting electron models is now competitive on state-of-the-art
quantum hardware.

</details>


### [142] [The Particle in a Box in Koopman--von Neumann Mechanics: A Hilbert Space representation of Classical Mechanics](https://arxiv.org/abs/2510.26856)
*Abhijit Sen,Lev Kaplan*

Main category: quant-ph

TL;DR: Koopman-von Neumann力学被应用于'粒子在盒子中'的问题，结果与量子力学不同，粒子在盒子中没有能量量子化。


<details>
  <summary>Details</summary>
Motivation: 使用Koopman-von Neumann力学来重新审视'粒子在盒子中'的教学案例，并与量子力学的预期进行对比。

Method: 通过分析Koopman-von Neumann力学框架下的粒子在盒子模型，特别是关注边界条件的处理，来解释能量谱的连续性。

Result: 证明了在Koopman-von Neumann力学描述下，粒子在盒子中具有连续的能量谱，而非量子力学中的离散谱。

Conclusion: 强调了Koopman-von Neumann力学描述下的粒子在盒子模型中，正确的边界条件处理是避免能量量子化误解的关键。与量子力学的概率幅不同，Koopman-von Neumann波函数不应仅从位置概率的角度理解。

Abstract: This paper revisits the textbook 'particle in a box', but from the point of
view of Koopman-von Neumann (KvN) mechanics. KvN mechanics is a way to describe
\emph{classical} dynamics in a Hilbert space. That simple fact changes the
usual expectation: hard walls do \emph{not} force energy quantization here. We
show, in a clear and physical way, why a KvN particle confined between two
ideal walls still has a continuous range of energies. With the correct wall
condition, one that captures ordinary elastic reflection rather than 'vanishing
at the boundary,' the KvN description naturally produces spatial confinement
without discrete energy levels. Beyond establishing this result, we also clean
up common misunderstandings: for example, treating the KvN wavefunction like a
quantum probability amplitude in position alone leads to the wrong boundary
picture and, with it, the wrong conclusion about quantization.

</details>


### [143] [A Non-Variational Quantum Approach to the Job Shop Scheduling Problem](https://arxiv.org/abs/2510.26859)
*Miguel Angel Lopez-Ruiz,Emily L. Tucker,Emma M. Arnold,Evgeny Epifanovsky,Ananth Kaushik,Martin Roetteler*

Main category: quant-ph

TL;DR: Iterative-QAOA是一种量子优化算法，通过结合浅层电路和迭代预热，在量子硬件限制下提高了求解组合优化问题的能力，并在JIT-JSSP问题上表现出优越的性能和良好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子启发式算法在组合优化方面有潜力，但受到近期硬件限制。因此，需要开发能够缓解这些限制的新算法。

Method: Iterative-QAOA算法结合了使用固定参数时间表的非变分、浅深度电路方法和迭代式预热过程。该算法在IonQ Forte QPUs上针对JIT-JSSP实例进行了基准测试，并与VarQITE和LR QAOA算法进行了比较。此外，还使用张量网络模拟评估了算法在更大问题实例上的扩展行为。

Result: Iterative-QAOA稳健地收敛到最优解和高质量的近优解。在97个量子比特的问题实例上，算法表现出良好的扩展性，表明其在容错量子计算机上解决工业规模问题的潜力。

Conclusion: Iterative-QAOA是一种有前途的量子优化算法，能够克服近期量子硬件的限制，并在组合优化问题上取得优异成果，尤其是在JIT-JSSP问题上。该算法的良好扩展性预示着其在未来量子计算中的应用前景。

Abstract: Quantum heuristics offer a potential advantage for combinatorial optimization
but are constrained by near-term hardware limitations. We introduce
Iterative-QAOA, a variant of QAOA designed to mitigate these constraints. The
algorithm combines a non-variational, shallow-depth circuit approach using
fixed-parameter schedules with an iterative warm-starting process. We benchmark
the algorithm on Just-in-Time Job Shop Scheduling Problem (JIT-JSSP) instances
on IonQ Forte Generation QPUs, representing some of the largest such problems
ever executed on quantum hardware. We compare the performance of the algorithm
against both the Variational Quantum Imaginary Time Evolution (VarQITE)
algorithm and the non-variational Linear Ramp (LR) QAOA algorithm. We find that
Iterative-QAOA robustly converges to find optimal solutions as well as
high-quality, near-optimal solutions for all problem instances evaluated. We
evaluate the algorithm on larger problem instances up to 97 qubits using tensor
network simulations. The scaling behavior of the algorithm indicates potential
for solving industrial-scale problems on fault-tolerant quantum computers.

</details>


### [144] [Single-Photon-Level Atomic Frequency Comb Storage in Room Temperature Alkali Vapour](https://arxiv.org/abs/2510.26870)
*Zakary Schofield,Vanderli Laurindo Jr,Ori Ezrah Mor,Patrick M. Ledingham*

Main category: quant-ph

TL;DR: 原子频率梳协议在室温铷蒸气中实现了单光子水平光存储和检索。


<details>
  <summary>Details</summary>
Motivation: 使用原子频率梳协议在室温铷蒸气中实现单光子水平光存储和检索，并探索其在时间-振幅量子比特和偏振量子比特存储方面的应用。

Method: 利用速度选择性光学泵浦制备原子频率梳，使梳齿间隔与铷蒸气的超精细分裂匹配。存储平均光子数为$
u_	extrm{in} = 0.083(5)$的弱相干态，预设召回时间为$7.5	extrm{ns}$。

Result: 存储和召回效率达到$
u_	extrm{AFC} = 6.59(5)	extrm{%}$，可实现时间-振幅量子比特存储，效率与输入脉冲偏振无关。

Conclusion: 该方法为实现偏振量子比特存储奠定了基础。

Abstract: We have demonstrated the coherent storage and retrieval of
single-photon-level light using the atomic frequency comb protocol in a room
temperature rubidium vapour. Velocity-selective optical pumping is used to
prepare the comb within the $F=2$ hyperfine ground state of rubidium, with the
spacing between peaks coinciding with half the $F = 2 - F =3$ hyperfine
splitting of the $5^2$P$_{3/2}$ excited state. Weak coherent states of average
photon number $\mu_\mathrm{in} = 0.083(5)$ are stored with pre-programmed
recall time of $7.5\,$ns with an efficiency of $\eta_{\textrm{AFC}} =
6.59(5)\,\%$, while two temporally distinct modes have been stored and recalled
with $\eta_{\textrm{AFC}} = 2.6(1)\,\%$, allowing for time-bin qubit storage.
Finally, the efficiency is observed to be independent of the input pulse
polarisation, paving the way for polarisation qubit storage.

</details>


### [145] [Optimising physical parameters of a quantum network based on a loss-jitter trade-off](https://arxiv.org/abs/2510.26888)
*Marcus J. Clark,Siddarth K. Joshi*

Main category: quant-ph

TL;DR: 量子通信系统的基础设施需要考虑损耗、色散和时序抖动等因素，选择合适的波长和带宽可以优化系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着量子通信系统的商业化，需要明确其未来基础设施的要求。

Method: 通过仿真模拟，分析损耗、色散和时序抖动对量子通信系统的影响，并确定具有优势的波长和带宽。

Result: 仿真结果表明，特定的波长和带宽在面对损耗、色散和时序抖动时具有明显优势。

Conclusion: 在未来的量子通信网络基础设施中，应优先考虑具有优势的波长和带宽，以应对不可避免的损耗、色散和时序抖动。

Abstract: As quantum communication systems and networks are becoming a commercial
reality, clarity on their future infrastructure is increasingly important.
Based on the inevitable presence of some amount of loss, chromatic dispersion,
and timing jitter, we present simulations to show that certain wavelengths and
bandwidths have clear advantages.

</details>


### [146] [Exact and approximate conditions of tabletop reversibility: when is Petz recovery cost-free?](https://arxiv.org/abs/2510.26895)
*Minjeong Song,Hyukjoon Kwon,Valerio Scarani*

Main category: quant-ph

TL;DR: Petz恢复图可以部分恢复量子通道中丢失的信息，当Petz恢复图的实现方式与原通道类似时，该通道被称为“台式时间可逆”。本文研究了台式时间可逆的精确和近似条件，并推导了在随机时间碰撞模型下的Lindbladian台式时间可逆条件。


<details>
  <summary>Details</summary>
Motivation: 研究在何种条件下，Petz恢复图的实现资源与量子信道的实现资源相似甚至相同。

Method: 研究精确台式时间可逆（TTR）条件，并表明需要对辅助系统进行时间敏感控制。研究近似TTR条件，该条件不需要时间敏感控制。推导了在随机时间碰撞模型下的Lindbladian TTR条件。

Result: 精确TTR条件需要对辅助系统进行时间敏感控制。近似TTR条件不需要这种控制。

Conclusion: 量子通道的台式时间可逆性取决于Petz恢复图的实现方式。

Abstract: Channels $\mathcal{N}$ that describe open quantum dynamics are inherently
irreversible: it is impossible to undo their effect completely, but one can
study partial recovery of the information. The Petz recovery map
$\hat{\mathcal{N}}_{\gamma}^{(\texttt{P})}$ is a systematic construction that
depends only on $\mathcal{N}$ and on a reference state $\gamma$, which will be
recovered exactly. If the real input state was different from $\gamma$, the
recovery is partial, with a guarantee of near-optimality. Generically, an
implementation of the Petz recovery map would look very different from the
implementation of the channel. It is natural to study under which conditions
the two maps require similar or even identical resources. The noisy forward
channel $\mathcal{N}$ is called ``tabletop time-reversible'' for a given
$\gamma$ when the corresponding Petz recovery map is realizable in such a way.
First, we study the exact tabletop reversibility (TTR) conditions. We show in
particular that a time-sensitive control of an ancilla system is needed.
Second, we present the approximate TTR conditions, which do not require such a
time-sensitive control. Third, we derive Lindbladian TTR conditions under a
random-time collision model.

</details>


### [147] [Harnessing Floquet dynamics for selective metrology in few-qubit systems](https://arxiv.org/abs/2510.26942)
*Asghar Ullah,Hasan Mermer,Melih Özkurt,Igor Lesanovsky,Özgür E. Müstecaplıoğlu*

Main category: quant-ph

TL;DR: 该研究展示了如何利用三比特系统中的周期性动力学（PD动力学相）来实现对不同参数（磁场和耦合强度）的精密测量，其中PD相能增强对耦合强度的测量精度，同时抑制对磁场的敏感度，而非PD相则相反，这为定制化的量子传感提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 旨在探索周期性驱动的量子系统在参数测量中的应用，特别是利用其选择性过滤能力。

Method: 研究了一个三比特的横向场Floquet伊辛模型，识别出一种具有对磁场和耦合强度敏感度不对称性的周期翻倍（PD）动力学相。通过分析量子Fisher信息和经典Fisher信息，量化了PD相和非PD相在估计不同参数时的精度。

Result: 识别出PD动力学相，该相源于初始态与π配对Floquet本征态的强重叠，导致鲁棒的周期翻倍动力学。PD相显著提高了对伊辛相互作用强度的估计精度，同时抑制了对横向磁场的敏感度。而非PD相则更适合测量横向磁场。这种选择性过滤效果对系统尺寸具有鲁棒性，并且可以通过磁化和双比特关联等可实验观测的量来量化。

Conclusion: 不同的动力学相（如PD相）可以被利用在有限尺寸的Floquet系统中，实现针对特定参数（如相互作用强度或外部场）的量子传感，为设计定制化的量子传感器提供了理论基础。

Abstract: Periodically driven quantum systems can function as highly selective
parameter filters. We demonstrate this capability in a finite-size, three-qubit
system described by the transverse-field Floquet Ising model. In this system,
we identify a period-doubling (PD) dynamical phase that exhibits a stark
asymmetry in metrological sensitivity to the magnetic field applied on the
qubits and to the coupling strength between the qubits. The PD phase originates
from $\pi$-pairing, where the initial state exhibits strong overlap with
$\pi$-paired Floquet eigenstates, leading to robust period-doubled dynamics and
enhanced metrological sensitivity. The analysis of quantum Fisher information
reveals that the PD regime significantly enhances precision for estimating the
Ising interaction strength while simultaneously suppressing sensitivity to the
transverse magnetic field. Conversely, non-PD regimes are optimal for sensing
the transverse field. This filtering effect is robust for larger system sizes
and is quantifiable using experimentally accessible observables, such as
magnetization and two-qubit correlations, via the classical Fisher information.
Our work shows that distinct dynamical regimes in finite-size Floquet systems
can be harnessed for targeted quantum sensing.

</details>


### [148] [Sample-Based Krylov Quantum Diagonalization for the Schwinger Model on Trapped-Ion and Superconducting Quantum Processors](https://arxiv.org/abs/2510.26951)
*Emil Otis Rosanowski,Jurek Eisinger,Lena Funcke,Ulrich Poschinger,Ferdinand Schmidt-Kaler*

Main category: quant-ph

TL;DR: SKQD方法被应用于带θ项的薛定谔模型，用于近似哈密顿量基态。该方法结合了量子-经典计算，通过从采样的时间演化量子态的比特串构建Krylov空间，并在该子空间内对哈密顿量进行经典对角化。研究表明，SKQD能准确捕捉模型的相结构，并展示了其在不同量子处理器上的一致性能。该方法有效减小了希尔伯特空间，尽管Krylov空间维度仍呈指数增长，但其较慢的增长趋势预示着其在模拟更大体积格点规范场论方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 应用SKQD方法来模拟格点规范场论，特别是带θ项的薛定谔模型，以评估其在确定基态能量和粒子数方面的能力，并研究θ项对模型相结构的影响。

Method: 使用SKQD方法，该方法包括从时间演化的量子态采样比特串来构建Krylov空间，然后在该子空间内对哈密顿量进行经典对角化。实验在离子阱和超导量子处理器上实现。

Result: SKQD方法能够准确捕捉薛定谔模型的相结构，并精确计算基态能量和粒子数。不同量子处理器上的实验结果一致，表明该算法的稳健性。SKQD大幅减小了有效希尔伯特空间，并且Krylov空间维度的增长相对较慢，这对于模拟更大体积的格点规范场论具有积极意义。

Conclusion: SKQD方法是一种有前景的模拟格点规范场论的技术，它通过有效减小希尔伯特空间大小，并在不同量子计算平台上展示了稳健的性能，为未来模拟更大、更复杂的量子系统提供了可能性。

Abstract: We apply the recently proposed Sample-based Krylov Quantum Diagonalization
(SKQD) method to lattice gauge theories, using the Schwinger model with a
$\theta$-term as a benchmark. SKQD approximates the ground state of a
Hamiltonian, employing a hybrid quantum-classical approach: (i) constructing a
Krylov space from bitstrings sampled from time-evolved quantum states, and (ii)
classically diagonalizing the Hamiltonian within this subspace. We study the
dependence of the ground-state energy and particle number on the value of the
$\theta$-term, accurately capturing the model's phase structure. The algorithm
is implemented on trapped-ion and superconducting quantum processors,
demonstrating consistent performance across platforms. We show that SKQD
substantially reduces the effective Hilbert space, and although the Krylov
space dimension still scales exponentially, the slower growth underscores its
promise for simulating lattice gauge theories in larger volumes.

</details>


### [149] [Electron juggling: Approaching the atomic physics limit of the attempt rate in trapped ion photonic interconnects](https://arxiv.org/abs/2510.27005)
*I. D. Moore,B. M. White,B. Graner,J. D. Siverns*

Main category: quant-ph

TL;DR: 本研究提出一种名为“电子杂耍”的新型光子互连技术，通过缩短状态制备时间来加速基于离子的量子计算机。


<details>
  <summary>Details</summary>
Motivation: 为了扩展基于离子的量子计算机，需要光子互连技术来连接多个量子处理单元，以运行更复杂的量子算法。之前的方法在状态制备阶段耗时较长，限制了整体效率。

Method: 提出并分析了一种名为“电子杂耍”的新型技术，旨在显著缩短光子互连中的状态制备时间。

Result: 理论分析表明，“电子杂耍”技术可以显著提高远程纠缠生成速率，接近受限于原子物理极限的离子阱光子互连的尝试速率。

Conclusion: “电子杂耍”技术有望将远程纠缠生成速率提高到每秒1000个贝尔对以上，为构建可扩展的量子计算机提供了新的途径。

Abstract: Photonic interconnects are a key technology for scaling up atomic based
quantum computers. By facilitating the connection of multiple systems,
high-performance modular quantum processing units may be constructed to perform
deeper and more useful algorithms. Most previous implementations of photonic
interconnects in trapped ions utilize the scheme of preparing a state, exciting
it, and collecting single photons from decays of the excited state. State
preparation is responsible for the vast majority of the total attempt time,
often taking hundreds of nanoseconds to several microseconds. Here, we describe
and analyze a novel technique called ``electron juggling" to speed up photonic
interconnects by reducing the state preparation step substantially. Using a
theoretical framework, we illustrate how this scheme can significantly increase
remote entanglement generation rates, approaching the atomic physics limit of
the attempt rate in trapped-ion photonic interconnects. Our results indicate
that this scheme holds the possibility of achieving remote entanglement
generation rates of over 1,000 Bell pairs per second.

</details>


### [150] [Fast Bosonic Control via Multiphoton Qubit-Oscillator Interactions](https://arxiv.org/abs/2510.27035)
*Noah Gorgichuk,Mohammad Ayyash,Matteo Mariantoni,Sahel Ashhab*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a protocol for preparing oscillator states with $n$-fold
rotational symmetry, which include many logical codewords for bosonic quantum
error correction codes. The protocol relies on a multiphoton interaction
between the oscillator and an auxiliary qubit. Further, we achieve arbitrary
control over the oscillator's Hilbert space by using a combination of different
multiphoton interaction orders. We also discuss the preparation of
rotationally-symmetric multi-oscillator states using a generalized variant of
the protocol. We show that the use of multiphoton qubit-oscillator interactions
can substantially reduce the state preparation time, in comparison to the
linear qubit-oscillator interactions that are usually employed. Furthermore, we
perform numerical simulations that take into account qubit and oscillator
relaxation and dephasing using realistic planar superconducting circuit
parameters that validate the robustness of our protocol. Our findings can
significantly improve the performance of bosonic codes on planar
superconducting hardware, which are an almost inevitable necessity for scalable
bosonic fault-tolerant superconducting quantum computers.

</details>


### [151] [Characterizing Quantum Internet Using Complex Network Models](https://arxiv.org/abs/2510.27073)
*Otávio José R. Silveira,Nycolas B. da Silva,Saulo L. L. da Silva,Angélica S. da Mata*

Main category: quant-ph

TL;DR: 为解决当前量子互联网模型忽视网络异构性问题，提出包含节点连接异构性的新模型，分析其对网络结构指标的影响，并与同质模型对比。


<details>
  <summary>Details</summary>
Motivation: 现有量子互联网模型多假设连接同质性，忽视了节点连接的异构性，这对于理解网络连通性和纠缠分发效率至关重要。

Method: 提出新的量子互联网模型，该模型考虑了光纤网络中节点连接的异构性，并分析了该特性对度分布、平均聚类系数、平均最短路径和相关性等基本指标的影响。

Result: 与同质模型相比，异构网络能更有效地复现真实光纤网络的关键结构特性，如度分布、相关性和层级行为。

Conclusion: 网络结构对量子通信有显著影响，提出的异构模型有助于更真实地模拟量子互联网基础设施。

Abstract: Quantum communication is a growing area of research, with quantum internet
being one of the most promising applications. Studying the statistical
properties of this network is essential to understanding its connectivity and
the efficiency of the entanglement distribution. However, the models proposed
in the literature often assume homogeneous distributions in the connections of
the optical fiber infrastructure, without considering the heterogeneity of the
network. In this work, we propose new models for the quantum internet that
incorporate this heterogeneity of node connections in the optical fiber
network, analyzing how this characteristic influences fundamental metrics such
as the degree distribution, the average clustering coefficient, the average
shortest path and assortativity. Our results indicate that, compared to
homogeneous models, heterogeneous networks efficiently reproduce key structural
properties of real optical fiber networks, including degree distribution,
assortativity, and hierarchical behavior. These findings highlight the impact
of network structure on quantum communication and can contribute to more
realistic modeling of quantum internet infrastructure.

</details>


### [152] [Inter-transition interference in spectrum of Kerr parametric oscillators](https://arxiv.org/abs/2510.27122)
*Shumpei Masuda*

Main category: quant-ph

TL;DR: KPO中光子跃迁的干涉效应对光谱有显著影响。


<details>
  <summary>Details</summary>
Motivation: 为了理论研究KPO中两光子和四光子的反射和透射测量，并引入了能级跃迁间的干涉效应。

Method: 通过引入能级跃迁间的干涉效应，并考虑了之前忽略的密度矩阵非对角元素与能级跃迁间的相互作用，扩展了反射测量的理论。

Result: 理论表明，干涉效应显著改变了光谱，并确定了干涉条件以及密度矩阵非对角元素影响光谱的条件。

Conclusion: 该理论推广到透射测量，适用于KPO之外的广泛系统。

Abstract: We theoretically investigate reflection and transmission measurements of
two-photon and four-photon Kerr parametric oscillators (KPOs), introducing
interference effects between inter-level transitions. Due to the level
degeneracy of a KPO, a probe field can be resonant with multiple inter-level
transitions. We extend the previous theory of reflection measurements by
incorporating the interaction between inter-level transitions and off-diagonal
elements of the density matrix which had previously been neglected. We
demonstrate that interference among these transitions substantially modifies
the spectrum. We identify the conditions for the interference, as well as those
under which the off-diagonal elements of the density matrix affect the
spectrum. The theory is also generalized to transmission measurements, and is
applicable to a broad class of systems beyond KPOs.

</details>


### [153] [Quantum, Stochastic, and Classical Dynamics Within A Single Geometric Framework](https://arxiv.org/abs/2510.27170)
*Partha Ghose*

Main category: quant-ph

TL;DR: Nelson's stochastic mechanics, Ghose's interpolating equation, and Koopman-von Neumann (KvN) formulation are linked. The KvN formulation is the $\lambda 	o 1$ limit of the stochastic $\sigma$-$\lambda$ hierarchy, bridging quantum and classical mechanics.


<details>
  <summary>Details</summary>
Motivation: To show that the Koopman-von Neumann (KvN) Hilbert-space formulation of classical mechanics emerges naturally as the $\lambda 	o 1$ limit of the stochastic $\sigma$-$\lambda$ hierarchy, linking quantum, stochastic, and classical dynamics.

Method: The paper analyzes the $\lambda 	o 1$ limit of Ghose's interpolating equation within Nelson's stochastic mechanics framework. It shows that the KvN phase-space amplitude provides an operator representation of the classical Liouville equation, and the $\lambda$ parameter acts as a projection flow from $\mathbb{C}P^n$ to $\mathbb{C}P^*/U(1)$, implementing phase superselection.

Result: The Koopman-von Neumann (KvN) Hilbert-space formulation of classical mechanics naturally emerges as the $\lambda 	o 1$ limit of the stochastic $\sigma$-$\lambda$ hierarchy. The $\lambda$ parameter implements phase superselection through a projection flow.

Conclusion: A unified framework is established that links quantum, stochastic, and classical dynamics, with the KvN formulation representing the classical limit of the stochastic $\sigma$-$\lambda$ hierarchy.

Abstract: Nelson's stochastic mechanics links quantum mechanics to an underlying
Brownian motion with the identification $\hbar = m\sigma$. Ghose's
interpolating equation introduces a continuous parameter $\lambda$ that
suppresses the quantum potential $Q[\psi]$ and yields a smooth transition
between quantum ($\lambda=0$) and classical ($\lambda=1$) regimes. In this
short note, we show that the Koopman--von Neumann (KvN) Hilbert-space
formulation of classical mechanics emerges naturally as the $\lambda \to 1$
limit of this stochastic $\sigma$--$\lambda$ hierarchy. The KvN phase-space
amplitude provides an operator representation of the classical Liouville
equation, while the $\lambda$ parameter acts as a projection flow from the
complex projective Hilbert manifold $\mathbb{C}P^n$ to its classical quotient
$\mathbb{C}P^*/U(1)$, implementing phase superselection. This unified picture
links quantum, stochastic, and classical dynamics within a single continuous
framework.

</details>


### [154] [Zitterbewegung Effect and Quantum Geometry in Non-Hermitian Exciton-Polariton Systems](https://arxiv.org/abs/2510.27220)
*Yow-Ming Robin Hu,Elena A. Ostrovskaya,Eliezer Estrecho*

Main category: quant-ph

TL;DR: 本文推导了解释非厄米系统中波动包动力学中出现的 zitterbewegung 效应的半经典运动方程，并揭示了群速度的新型非厄米修正。


<details>
  <summary>Details</summary>
Motivation: 探讨非厄米系统中因自旋动力学与厄米系统不同而产生的 zitterbewegung 效应。

Method: 通过推广 zitterbewegung 效应的描述到非厄米系统，并推导出半经典运动方程。

Result: 发现了与自旋相关的 zitterbewegung 效应，以及群速度的新型非厄米修正，该修正可表示为非厄米量子度量张量。

Conclusion: 非厄米自旋动力学对 zitterbewegung 效应有重要影响，并且存在由非厄米量子度量张量决定的群速度修正。

Abstract: In this work, we analytically derive a semi-classical equation of motion
describing the zitterbewegung effects arising in the dynamics of wavepackets in
non-Hermitian systems. In Hermitian non-relativistic quantum systems, the
zitterbewegung effects can arise due to the spin precession and spin-orbit
coupling. Interestingly, the spin dynamics in non-Hermitian systems are
qualitatively different because of the effective nonlinear terms induced by the
non-Hermitian part of the Hamiltonian. In this work, we show the effects from
the non-Hermitian spin dynamics by generalising the description of
zitterbewegung effects to non-Hermitian systems. We also uncover novel
non-Hermitian correction to the group velocity, which can be expressed in terms
of the non-Hermitian quantum metric tensor in the absence of out-of-plane
effective field.

</details>


### [155] [Maximal extension on converse monogamy of entanglement for tripartite pure states](https://arxiv.org/abs/2510.27264)
*Junhyeong An,Soojoon Lee*

Main category: quant-ph

TL;DR: The paper extends the concept of converse monogamy of entanglement (CMoE) to broader conditions and demonstrates that these extensions are maximal within their respective hierarchies.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the results of previous work on the converse monogamy of entanglement (CMoE) by Hayashi and Chen, and Singh and Datta, to more general conditions and to prove the maximality of these extensions.

Method: The paper extends the results of Hayashi and Chen, and Singh and Datta regarding the CMoE. Specific details on the methods used for extension and proving maximality are not provided in the abstract but are implied to involve hierarchical structures of bipartite entanglement and distillability conditions.

Result: The paper extends the CMoE to broader conditions and shows that these extensions are maximal with respect to the hierarchies considered.

Conclusion: The work successfully extends the understanding of the converse monogamy of entanglement and establishes the maximality of these new findings within the studied frameworks.

Abstract: Unlike classical correlations, entanglement cannot be freely shared among
multiple parties. This unique feature of quantum systems is known as the
monogamy of entanglement. While it holds for all multipartite pure states, its
converse -- weak entanglement between two parties enforces strong entanglement
with a third party -- occurs only under specific conditions. In particular,
Hayashi and Chen [Phys. Rev. A \textbf{84}, 012325 (2011)] demonstrated a
qualitative version of the converse monogamy of entanglement (CMoE) for
tripartite pure states by employing a hierarchy of bipartite entanglement
defined through the relations among various separability criteria, and Singh
and Datta [IEEE Trans. Inf. Theory \textbf{69}, 6564 (2023)] later extended
this notion of the CMoE from the viewpoint of distillability under one-way or
two-way classical communication. In this work, we extend their results to the
CMoE with broader conditions, and furthermore show that our extensions are
maximal with respect to the hierarchies they considered.

</details>


### [156] [Instruction-Directed MAC for Efficient Classical Communication in Scalable Multi-Chip Quantum Systems](https://arxiv.org/abs/2510.27273)
*Maurizio Palesi,Enrico Russo,Hamaad Rafique,Giuseppe Ascia,Davide Patti,Abhijit Das,Sergi Abadal*

Main category: quant-ph

TL;DR: ID-MAC 协议通过在编译时预定义传输计划来优化量子计算中的古典通信，将古典通信时间缩短高达 70%，总执行时间缩短高达 70%。


<details>
  <summary>Details</summary>
Motivation: 为了实现模块化、多芯片的量子计算架构，需要一个能够协调分布式控制操作和支持量子协议（如隐形传态）的古典通信子系统。传统的 MAC 协议在这些环境中存在延迟问题。

Method: 提出了一种名为 ID-MAC 的指令驱动令牌 MAC 协议，该协议利用量子电路执行的确定性，在编译时预定义传输计划。它将指令级信息嵌入 MAC 层，将令牌的循环限制在活动的发送者，从而提高信道利用率并减少延迟。

Result: 模拟结果显示，ID-MAC 协议将古典通信时间缩短了高达 70%，总执行时间缩短了高达 30-70%，并延长了有效的系统相干性。

Conclusion: ID-MAC 是一种可扩展且高效的 MAC 解决方案，适用于未来的多芯片量子架构，能够显著减少延迟并提高效率。

Abstract: Scalable quantum computing requires modular multi-chip architectures
integrating multiple quantum cores interconnected through quantum-coherent and
classical links. The classical communication subsystem is critical for
coordinating distributed control operations and supporting quantum protocols
such as teleportation. In this work, we consider a realization based on a
wireless network-on-chip for implementing classical communication within
cryogenic environments. Traditional token-based medium access control (MAC)
protocols, however, incur latency penalties due to inefficient token
circulation among inactive nodes. We propose the instruction-directed token MAC
(ID-MAC), a protocol that leverages the deterministic nature of quantum circuit
execution to predefine transmission schedules at compile time. By embedding
instruction-level information into the MAC layer, ID-MAC restricts token
circulation to active transmitters, thereby improving channel utilization and
reducing communication latency. Simulations show that ID-MAC reduces classical
communication time by up to 70% and total execution time by up to 30-70%, while
also extending effective system coherence. These results highlight ID-MAC as a
scalable and efficient MAC solution for future multi-chip quantum
architectures.

</details>


### [157] [Manipulating Excitation Dynamics in Structured Waveguide Quantum Electrodynamics](https://arxiv.org/abs/2510.27310)
*I Gusti Ngurah Yudi Handayana,Ya-Tang Yu,Wei-Hsuan Chung,H. H. Jen*

Main category: quant-ph

TL;DR: 通过设计原子-纳米光子接口中发射器的耦合方向性来控制激发传输，并识别出四种不同的动力学行为：中心化、类波、跳蛙式和色散激发。


<details>
  <summary>Details</summary>
Motivation: 控制低维光子环境中激子的传输和定位。

Method: 提出了一种结构化的波导量子电动力学（wQED）框架，通过工程设计每个发射器的局部耦合方向性来控制激发传输，并使用有效的非厄米哈密顿量进行光谱分析和方差分析。

Result: 识别出四种不同的动力学行为：中心化、类波、跳蛙式和色散激发。分析表明，激子传输的定位-非定位转变是可调的，并且在存在非引导损耗的情况下是稳健的（beta >= 0.99）。

Conclusion: 结构化 wQED 提供了一种通过可编程的方向性模式来操纵激发定位、相干性和传输的可行途径，为可控的亚辐射传输和手性量子信息路由开辟了道路。

Abstract: Waveguide quantum electrodynamics (wQED) has become a central platform for
studying collective light-matter interactions in low-dimensional photonic
environments. While conventional wQED systems rely on uniform chirality or
reciprocal emitter-waveguide coupling, we propose a structured wQED framework,
where the coupling directionality of each emitter can be engineered locally to
control excitation transport in an atom-nanophotonic interface. For different
combinations of patterned coupling directionalities of the emitters, we
identify four representative configurations that exhibit distinct dynamical
behaviors: centering, wave-like, leap-frog, and dispersion excitations.
Spectral analysis of the effective non-Hermitian Hamiltonian reveals that these
dynamics originate from interferences among subradiant eigenmodes. Variance
analysis further quantifies the spreading of excitation as functions of
interatomic spacing and global chirality, showing tunable
localization-delocalization transitions. Including nonguided losses, we find
that the transport characteristics remain robust for realistic coupling
efficiencies (beta >= 0.99). These results establish structured wQED as a
practical route to manipulate excitation localization, coherence, and transport
through programmable directionality patterns, paving the way for controllable
subradiant transport and chiral quantum information routing.

</details>


### [158] [Room-Temperature Quantum Simulation with Atomically Thin Nuclear Spin Layers in Diamond](https://arxiv.org/abs/2510.27374)
*Philipp J. Vetter,Christoph Findler,Antonio Verdú,Matthias Kost,Rémi Blinder,Jens Fuhrmann,Christian Osterkamp,Johannes Lang,Martin B. Plenio,Javier Prior,Fedor Jelezko*

Main category: quant-ph

TL;DR: 使用金刚石中的 ${}^{13}\text{C}$ 核自旋层实现了室温量子模拟，并用于研究离散时间晶体序。


<details>
  <summary>Details</summary>
Motivation: 现有的量子模拟平台通常复杂且成本高昂，需要超高真空或低温。本研究旨在开发一种更易于使用且能在室温下运行的量子模拟器。

Method: 利用金刚石中的 ${}^{13}\text{C}$ 核自旋层作为量子模拟平台，通过邻近的氮-空位（NV）中心进行极化、读出和相干控制，并结合射频场实现核自旋间的强相互作用，进而研究离散时间晶体序。

Result: 成功构建了一个室温量子模拟器，实现了核自旋间的强可调相互作用，并成功观察到离散时间晶体序。

Conclusion: 该研究提出了一种基于金刚石 ${}^{13}\text{C}$ 核自旋层的室温量子模拟方法，该方法易于操作且成本较低，为研究强关联多体效应开辟了新的可能性。

Abstract: Quantum simulation aims to recreate complex many-body phenomena in controlled
environments, offering insights into dynamics that are otherwise difficult to
model. Existing platforms, however, are often complex and costly to scale,
typically requiring ultra-pure vacuum or low temperatures. Here, we realize a
room-temperature quantum simulator using a thin ${}^{13}\text{C}$ nuclear spin
layer in diamond. Nearby nitrogen-vacancy centers enable polarization, readout,
and, combined with radio-frequency fields, coherent control of the nuclear
spins. We demonstrate strong, tunable interactions among the nuclear spins and
use the system to investigate discrete time-crystalline order. By combining
ease of use with operation at ambient temperatures, our work opens new
opportunities for investigating strongly correlated many-body effects.

</details>


### [159] [Revisiting quantum walk advantages: A mean hitting time perspective](https://arxiv.org/abs/2510.27377)
*Jan Wójcik*

Main category: quant-ph

TL;DR: 均值hitting时间（MHT）比均方根位移（MSD）更能捕捉量子行走（QW）和经典行走（CW）的搜索算法特性。QW在随机重置下可以通过准动量重新分布实现MHT缩短，而CW则不然。


<details>
  <summary>Details</summary>
Motivation: MSD的比较可能无法完全捕捉量子和经典随机游走的差异，因为量子游走的分布具有非高斯特性，而MSD更适用于高斯分布。MHT具有更清晰的搜索算法操作意义，可以作为MSD的补充视角。

Method: 通过解析计算，比较了有无随机重置的情况下，量子行走和经典行走在对称初始条件和两个探测器存在下的MHT。

Result: 在对称初始条件和两个探测器存在下，量子行走和经典行走具有相同的MHT。引入随机重置后，量子行走可以通过准动量重新分布实现MHT缩短，而经典行走则没有优势。噪声会降低量子优势。

Conclusion: MHT可以作为区分量子行为的附加指标，尤其适用于表征噪声量子设备上的量子行走。不同的指标可以揭示行走算法中量子-经典比较的不同方面。

Abstract: The mean squared displacement has been widely used as the primary metric for
comparing quantum and classical random walks, with quantum walks showing
quadratic scaling versus linear scaling for classical walks. However, this
comparison may not capture the full picture: while the mean squared
displacement is well-suited for Gaussian distributions, quantum walk
distributions exhibit distinctly non-Gaussian features. We propose that the
mean hitting time offers a complementary perspective with clear operational
meaning for search algorithms. Through analytical calculations, we show that
quantum and classical walks yield identical MHT for symmetric initial
conditions with two detectors, suggesting that the apparent quantum advantage
seen in MSD comparisons may be context-dependent. Interestingly, introducing
stochastic resetting reveals new dynamics. We demonstrate analytically that
quantum walks can achieve reduced MHT under stochastic reset through
quasi-momentum redistribution, while classical walks see no benefit. This
quantum advantage naturally degrades with noise, the quantum walk converges to
classical behavior. We suggest that MHT reduction under stochastic reset can
serve as an additional signature of quantum behavior, particularly useful for
characterizing quantum walk implementations on noisy quantum devices. Our
results indicate that different metrics can reveal different aspects of
quantum-classical comparisons in walk-based algorithms.

</details>


### [160] [Complete characterization of beam deflection based on double weak value amplification system](https://arxiv.org/abs/2510.27398)
*Yu Wang,Rongguo Yang,Jing Zhang,Xiaomin Liu,Chenzhen Luo,Kui Liu,Jiangrui Gao*

Main category: quant-ph

TL;DR: 使用集成高阶模式平衡零位探测的双弱值系统，理论研究并实验实现了偏航和俯仰角的同步测量。


<details>
  <summary>Details</summary>
Motivation: 精确测量空间姿态参数对于惯性导航、工业监测、仪器校准、量子计量学等应用至关重要。

Method: 利用外尔-高斯-后选择双弱值系统，结合两组高阶模式平衡零位探测，对厄米-高斯光束进行探测。

Result: 实现了偏航和俯仰角的独立测量，最小可测量角度分别为83 prad和89 prad，对应的位移分别为0.79 pm和0.85 pm。

Conclusion: 该工作将光束偏转测量扩展到二维，为未来高精度多参数空间精确探测提供了新思路。

Abstract: The precise measurement of spatial attitude parameters is critical for
applications in inertial navigation, industrial monitoring, instrument
calibration, quantum metrology, etc. In this work, we theoretically investigate
and experimentally realize the simultaneous measurement of the yaw and pitch
angles using a Hermite-Gaussian-postselected double weak value system
integrated with two sets of high-order-mode balanced homodyne detections,
thereby achieving a complete characterization of the beam deflection. Signals
of the yaw and pitch angles that are involved in TEM$_{10}$ and TEM$_{01}$
modes output from two dark ports of the system can be measured independently.
As a result, the obtained minimum measurable yaw and pitch angles of beam
deflection are 83 prad and 89 prad, respectively. Meanwhile, the corresponding
displacements are 0.79 pm and 0.85 pm, respectively. This work expands the beam
deflection measurement to two dimensions, which provides a new insight for
future high-precision multi-parameter spatial precise detection.

</details>


### [161] [Quantum Secret Sharing Scheme on Hypercyclic Quantum Structures](https://arxiv.org/abs/2510.27466)
*Lei Li,Zhi Li*

Main category: quant-ph

TL;DR: 本文研究了基于三条超边的超图的量子访问结构的高效量子秘密共享方案构建，证明了三超边超图的超环是量子访问结构当且仅当它们可以被分类为12种非同构类型，并且这些超环量子访问结构包含了所有三超边的超星。对于超星访问结构，已有工作使用单光子构建了高效完美量子秘密共享方案。然而，对于超环访问结构，该方法无法得到信息率最优的经典完美秘密共享方案。本文通过结合Simmons的几何方法和Shamir的门限方案，明确构建了信息率最优的经典完美秘密共享方案，并基于此构建了完美量子秘密共享方案。此外，本文引入了完美量子秘密共享方案中最小访问结构的理想化信息率概念，并定义了最小授权子集的效率，证明了所构建的量子秘密共享方案实现了现有解决方案中的最高效率。


<details>
  <summary>Details</summary>
Motivation: 现有量子秘密共享方案在处理超环访问结构时存在信息率最优问题，本文旨在解决此问题并构建更高效的方案。

Method: 结合Simmons的几何方法和Shamir的门限方案，构建经典完美秘密共享方案，并利用单光子在d维量子系统中实现完美量子秘密共享方案。引入并分析了理想化信息率和最小授权子集效率。

Result: 成功构建了适用于三超边超图（包括超环和超星）的高效量子秘密共享方案，并证明了其最优性。

Conclusion: 本文提出的量子秘密共享方案在信息率和效率方面均优于现有方案，为构建更高效的量子秘密共享系统提供了理论和实践基础。

Abstract: This paper investigates the construction of efficient quantum secret sharing
schemes for quantum access structures based on hypergraphs with three
hyperedges. We prove that hypercycles with three hyperedges are quantum access
structures if and only if they can be classified into 12 non-isomorphic types
under hypergraph isomorphism, and these hypercyclic quantum access structures
encompass all four hyperstars with three hyperedges.In prior work, efficient
and perfect quantum secret sharing schemes were constructed for hyperstar
access structures with three hyperedges using single photons in d -dimensional
quantum systems. These schemes correspond to classical perfect secret sharing
schemes with optimal information rates. However, for hypercyclic access
structures with three hyperedges, the method described above fails to yield
classical perfect secret sharing schemes with optimal information rates. In
this work, we explicitly construct classical perfect secret sharing schemes
with optimal information rates for these access structures by combining
Simmons' geometric method with Shamir's threshold scheme. Subsequently, we
employ single photons in d-dimensional quantum systems to build perfect QSS
schemes upon these classical constructions.We introduce the concept of
idealized information rate for minimal access structures in perfect QSS
schemes. By extending the notion of efficiency proposed by Cabello [Phys. Rev.
Lett., vol. 85, no. 26, p. 5635, 2000] for quantum key distribution protocols
to QSS, we define the efficiency of minimally authorized subsets. Furthermore,
we establish the relationship between the efficiency of minimally authorized
subsets and the idealized information rate of minimal access structures.
Finally, we rigorously prove that the QSS schemes constructed in this work
achieve the highest efficiency among existing solutions.

</details>


### [162] [Auxiliary-state facilitated phase synchronization phenomena in isolated spin systems](https://arxiv.org/abs/2510.27472)
*Xylo Molenda,S. Zhong,B. Viswanathan,Xingli Li,Y. Yan,A. M. Marino,D. Blume*

Main category: quant-ph

TL;DR: 本工作研究了通过将具有无限寿命的三个量子态与具有有限寿命的辅助激发态耦合来实现的有效自旋1系统中的相位同步。


<details>
  <summary>Details</summary>
Motivation: 将经典同步扩展到量子领域对于基础物理和量子技术应用都具有重要意义。

Method: 通过积分掉激发态得到有效的自旋1模型，该模型具有相干和非相干的有效耦合。

Result: （i）可以通过调整耦合到激发态的相位来控制相位同步。（ii）与文献中研究的范式自旋1系统不同，该模型中的耗散耦合描述了进入和离开极限环态的竞争，其中离开极限环态的耗散衰减起着关键作用。（iii）在没有相干有效耦合的情况下，相位同步完全由有效的耗散器控制。

Conclusion: 本研究提出的有效自旋1模型通过与全希尔伯特空间的主方程计算进行比较，并结合分析微扰理论，为理解量子相位同步提供了新的见解，并且预期该模型可推广到更广泛的能量-耦合方案。

Abstract: Extending classical synchronization to the quantum domain is of great
interest both from the fundamental physics point of view and with a view toward
quantum technology applications. This work characterizes phase synchronization
of an effective spin-1 system, which is realized by coupling three quantum
states with infinite lifetime to auxiliary excited states that have a finite
lifetime. Integrating out the excited states, the effective spin-1 model
features coherent and incoherent effective couplings. Our key findings are: (i)
Phase synchronization can be controlled by adjusting the phases of the
couplings to the excited states. (ii) Unlike in the paradigmatic spin-1 system
studied in the literature, where the dissipative couplings describe decay into
the limit cycle state, the effective spin-1 model investigated in this work is
governed by a competition between dissipative decay into and out of the limit
cycle state, with the dissipative decay out of the limit cycle state playing a
critical role. (iii) We identify a parameter regime where phase synchronization
of the effective spin-1 system is -- in the absence of coherent effective
couplings -- governed entirely by the effective dissipators. The effective
spin-1 model is benchmarked through comparisons with master equation
calculations for the full Hilbert space. Physical insights are gained through
analytical perturbation theory calculations. Our findings, which are expected
to hold for a broad class of energy level and coupling schemes, are
demonstrated using hyperfine states of $^{87}$Rb.

</details>


### [163] [The role of entanglement in energy-restricted communication and randomness generation](https://arxiv.org/abs/2510.27473)
*Carles Roch I Carceller,Armin Tavakoli*

Main category: quant-ph

TL;DR: In prepare-and-measure quantum information protocols with energy constraints, shared entanglement can be detrimental for classical tasks but beneficial for quantum tasks when non-unitary encoding is used, especially with higher-dimensional states. This has implications for quantum random number generation, where entanglement can enhance security in low-energy regimes.


<details>
  <summary>Details</summary>
Motivation: Investigate the role of shared entanglement in semi-device-independent quantum information scenarios with energy-constrained communication.

Method: Derived a general correlation criterion for nonlocal resources in classical communication and analyzed entanglement's utility. For quantum communication, studied the probabilistic transmission of a bit with energy constraints, focusing on the necessity of non-unitary encoding and higher-dimensional entanglement. Investigated the impact of entanglement on quantum random number generation security in the low-energy regime.

Result: Entanglement can fail to be a resource in classical communication tasks. For quantum communication, entanglement's advantages are unlocked by non-unitary encoding that purposefully decoheres the entangled state, with benefits increasing for higher-dimensional entanglement. Security of quantum random number generation in the low-energy regime is largely intact even with entanglement.

Conclusion: Shared entanglement plays a nuanced role in energy-constrained quantum information processing. While it can be detrimental in classical contexts, it offers advantages in quantum tasks like bit transmission and random number generation, particularly when employing non-unitary encoding and higher-dimensional systems, leading to enhanced security in certain applications.

Abstract: A promising platform for semi-device-independent quantum information is
prepare-and-measure experiments restricted only by a bound on the energy of the
communication. Here, we investigate the role of shared entanglement in such
scenarios. For classical communication, we derive a general correlation
criterion for nonlocal resources and use it to show that entanglement can fail
to be a resource in standard tasks. For quantum communication, we consider the
basic primitive for energy-constrained communication, namely the probabilistic
transmission of a bit, and show that the advantages of entanglement only can be
unlocked by non-unitary encoding schemes that purposefully decohere the
entangled state. We also find that these advantages can be increased by using
entanglement of higher dimension than qubit. We leverage these insights to
investigate the impact of entanglement for quantum random number generation,
which is a standard application of these systems but whose security so far only
has been established against classical side information. In the low-energy
regime, our attacks on the protocol indicate that the security remains largely
intact, thereby paving the way for strengthened security without more complex
setups and with negligible performance reductions.

</details>


### [164] [Area-Law Entanglement in Quantum Chaotic System](https://arxiv.org/abs/2510.27511)
*Chunyin Chen,Sizhe Yan,Biao WU*

Main category: quant-ph

TL;DR: 研究发现，一个具有全同态混沌的Floquet驱动量子多体系统，尽管表现出Wigner-Dyson能级统计和局部热化，但其纠缠熵却严格遵守面积定律，并且与系统大小无关，被限制在ln2以内。研究将这种反常现象归因于阻断作用导致的希尔伯特空间结构，该结构限制了跨越二分区的施密特秩。此外，研究将约束多体哈密顿量与单粒子量子行走之间的对偶性推广到中位数图上，并提出了一种构造具有固定纠缠熵边界的系统的方法。


<details>
  <summary>Details</summary>
Motivation: 纠缠熵通常被认为是量子混沌的诊断指标，在混沌多体系统中表现为体积定律。本研究旨在寻找并解释一个与此典型行为相悖的系统。

Method: 通过分析一个具有Rydberg阻断效应的Floquet驱动量子多体系统，研究其纠缠熵的行为。利用Wigner-Dyson能级统计和局部热化来确认系统的混沌性质。通过分析希尔伯特空间结构和施密特秩来解释纠缠熵的反常行为。推广这一发现，建立约束多体哈密顿量与单粒子量子行走在 있다고图上的对偶性。

Result: 在一个具有阻断效应的Floquet驱动量子多体系统中，发现了严格遵守面积定律的纠缠熵，其上界为ln2，且不随系统大小变化。建立了约束多体哈密顿量与单粒子量子行走在 있다고图上的对偶性。

Conclusion: 纠缠熵本身不足以作为量子混沌的充分诊断指标。希尔伯特空间的几何结构对量子动力学和热化过程有深远影响。

Abstract: Entanglement entropy is a fundamental diagnostic for quantum chaos, typically
exhibiting volume-law scaling in highly excited eigenstates of chaotic
many-body systems. In this work, we present a striking counterexample: a
Floquet-driven quantum many-body system with Rydberg-like blockade that,
despite being fully chaotic as indicated by its Wigner-Dyson level statistics
and local thermalization, exhibits a strict area-law entanglement entropy.
Specifically, the entanglement entropy of every Floquet eigenstate is bounded
by $\ln2$, independent of system size. We trace this anomaly to the specific
Hilbert space structure imposed by the blockades, which restricts the Schmidt
rank across a bipartition. Furthermore, we generalize this discovery by
establishing a duality between constrained many-body Hamiltonians and
single-particle quantum walks on median graphs, and we outline a general
procedure for constructing systems with an entanglement entropy bounded by a
predetermined constant. Our results demonstrate that entanglement entropy alone
is an insufficient diagnostic of many-body quantum chaos and highlight the
profound impact of Hilbert space geometry on quantum dynamics and
thermalization.

</details>


### [165] [Experimental Quantum Channel Purification](https://arxiv.org/abs/2510.27534)
*Yue-Yang Fei,Zhenhuan Liu,Rui Zhang,Zhenyu Cai,Xu-Fei Yin,Yingqiu Mao,Li Li,Nai-Le Liu,Yu-Ao Chen,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 本研究提出了一种利用光子空间和偏振特性进行高效信道净化的实验方案，通过两个 Fredkin 门实现独立噪声信道间的相干干涉，有效抑制了各种噪声水平和类型的噪声。该方案在纠缠分发方面的应用表明，与传统方法相比，它在抵抗信道噪声方面具有更优越的保持纠缠的能力。


<details>
  <summary>Details</summary>
Motivation: 量子网络对于分布式量子信息处理至关重要，但容易受到信道噪声的影响。信道净化是一种有前景的噪声抑制技术，无需复杂的编码和解码操作，特别适用于光系统中的远程量子信息传输。

Method: 设计了一个利用光子空间和偏振特性的实验装置，并使用两个 Fredkin 门来实现独立噪声信道间的相干干涉，以达到噪声抑制的目的。

Result: 该方案在纠缠分发方面的应用表明，与传统方法相比，它在抵抗信道噪声方面具有更优越的保持纠缠的能力。

Conclusion: 本研究提出的信道净化方案能够有效抑制噪声，并提高纠缠分发的能力。

Abstract: Quantum networks, which integrate multiple quantum computers and the channels
connecting them, are crucial for distributed quantum information processing but
remain inherently susceptible to channel noise. Channel purification emerges as
a promising technique for suppressing noise in quantum channels without complex
encoding and decoding operations, making it particularly suitable for remote
quantum information transmission in optical systems. In this work, we introduce
an experimental setup for efficient channel purification, harnessing the
spatial and polarization properties of photons. Our design employs two Fredkin
gates to enable coherent interference between independent noise channels,
achieving effective noise suppression across a wide range of noise levels and
types. Through application to entanglement distribution, our protocol
demonstrates a superior capability to preserve entanglement against channel
noise compared to conventional entanglement purification methods.

</details>


### [166] [Entanglement in the energy-constrained prepare-and-measure scenario: applications to randomness certification and channel discrimination](https://arxiv.org/abs/2510.27559)
*Raffaele D'Avino,Gabriel Senno,Mir Alimuddin,Antonio Acín*

Main category: quant-ph

TL;DR: 本研究探讨了带能量约束的半独立（SDI）量子信息任务，发现允许使用纠缠会严格扩大可实现的相关集，从而影响随机数认证和量子信道区分。


<details>
  <summary>Details</summary>
Motivation: 研究在半独立（SDI）框架下，带能量约束的量子信息任务，特别关注允许使用纠缠的影响。

Method: 分析了在准备-测量设置中，仅假设准备态能量上限，并允许使用纠缠时的SDI场景。

Result: 1. 允许纠缠策略可能显著减少可认证的随机数数量，甚至在有纠缠时降至零。2. 在能量约束下，已知维度无关的纠缠优势界限被违反，用于区分任意量子信道与同一信道的任务。

Conclusion: 在能量约束的SDI场景中，允许纠缠不仅扩大了可实现的相关集，而且对随机数认证和量子信道区分等任务带来了新的、有时是负面的影响，挑战了现有的理论界限。

Abstract: Quantum information tasks are often analyzed under varying trust assumptions
about the devices involved. The semi-device-independent (SDI) framework offers
a balance between needed assumptions and experimental feasibility. In this
work, we study the energy-constrained SDI scenario, where the only assumption
in a prepare-and-measure setup is an upper bound on the energy of the prepared
quantum states. In contrast to previous studies that restricted the preparation
and measurement devices to be classically correlated, we show that allowing
entanglement strictly enlarges the set of achievable correlations. We identify
two operational consequences of this result. The first concerns randomness
certification, where we show that allowing the adversary to employ entangled
strategies may significantly reduce the amount of certifiable randomness. This
includes situations where the amount of randomness drops to zero in the
presence of entanglement, while it remains positive when entanglement is
excluded. Second, for the task of distinguishing an arbitrary quantum channel
from the identity, we show that the known dimension-independent bound on the
advantage conferred by entanglement is violated under an energy constraint.

</details>


### [167] [Quantum interference effects in two-photon scattering by a macroscopic lossy sphere](https://arxiv.org/abs/2510.27612)
*A. Ciattoni*

Main category: quant-ph

TL;DR: 该论文研究了宏观量子电动力学中，损耗性宏观球体对双光子波包的量子光学散射。


<details>
  <summary>Details</summary>
Motivation: 论文旨在理解损耗性宏观物体如何影响双光子量子态，并探索利用这些相互作用进行量子信息处理的可能性。

Method: 采用宏观量子电动力学和修正的兰吉万噪声形式，分析了双光子波包与损耗性球体的散射过程，考虑了非对准入射和散射中的干涉效应。

Result: 研究发现，损耗性球体的米氏共振峰和法诺特性导致了强烈的相长和相消干涉，且干涉效应高度依赖于输入波包的谱对称性。此外，还证明了在介质损耗存在的情况下，可以利用这种散射过程实现对量子纠缠的有效识别。

Conclusion: 损耗性宏观物体（如球体）的散射为实现量子干涉和量子信息处理提供了一种新颖的平台，特别是当输入光子波包的谱对称性与散射体的共振特性相结合时。

Abstract: We investigate the quantum optical scattering of two-photon wavepackets by a
macroscopic lossy sphere by means of macroscopic quantum electrodynamics in the
form of modified Langevin noise formalism. The two ingoing photons with
arbitrary frequency-polarization spectrum impinge onto the sphere along two
different directions and, as consequence of matter losses, their scattering
involves the three independent processes where two, one and zero outgoing
photons survive. Non-collinearity of ingoing photons causes the existence of
two different quantum paths they can follow upon scattering, this producing
interference effects in the detection of the above three processes which is
governed by the wavepacket spectral symmetry. By exploiting rotational
invariance, we show that different classes of scattering geometries exist such
that the coincidence detection of the scattered photons shows perfect
constructive or destructive (Hong-Ou-Mandel) interference, both for symmetric
and antisymmetric wavepackets. To assess the impact of matter dispersion/losses
on quantum interference effects accompanying photons detection, we analyze the
scattering of narrow band two-photon wavepackets by high-index dielectric lossy
spheres. We show that classical Mie resonance peaks, due to their Fano-like
traits, yield very strong constructive and destructive interference effects,
occurring when the wavepacket carrier frequency matches the resonance frequency
and side Fano dip frequency, respectively. In addition we consider the overall
scattering probabilities of two, one and zero photons and we prove that, at the
Mie resonance frequencies, they exhibit quantum interference effects which are
extremely sensitive to the spectral symmetry of the input wavepacket, thus
suggesting an efficient spectral technique assisted by matter losses to
identify entanglement.

</details>


### [168] [Directional quantum scattering transducer in cooperative Rydberg metasurfaces](https://arxiv.org/abs/2510.27654)
*Jonas von Milczewski,Kelly Werker Smith,Susanne F. Yelin*

Main category: quant-ph

TL;DR: 提出了一种利用四波混频和量子散射的高效、高指向性单光子转换方案，有望实现太赫兹到光学转换。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子相干的太赫兹探测和处理，以满足天文学光谱、量子网络稀疏孔成像和其他量子传感应用的需求。

Method: 通过四波混频和量子散射，利用协同里德堡原子阵列，将太赫兹信号光子耦合到光学闲置模式，并利用光子介导的偶极-偶极相互作用实现集体超/亚辐射偶极模式，最终耦合到具有高度方向性的光学光子中。

Result: 在无限大晶格中，预测特定空间方向的转换效率可达50%；对于有限的N^2个发射体的阵列，输出被限制在随着1/sqrt(N)变窄的瓣中。

Conclusion: 该方案结合了自由空间四波混频的宽带接收能力和协同超表面器件的效率、方向性和可调性，为量子相干太赫兹探测和处理提供了新途径。

Abstract: We present a single-photon transduction scheme using 4-wave-mixing and
quantum scattering in planar, cooperative Rydberg arrays that is both efficient
and highly directional and may allow for terahertz-to-optical transduction. In
the 4-wave-mixing scheme, two lasers drive the system, coherently trapping the
system in a dark ground-state and coupling a signal transition, that may be in
the terahertz, to an idler transition that may be in the optical. The
photon-mediated dipole-dipole interactions between emitters generate collective
super-/subradiant dipolar modes, both on the signal and the idler transition.
As the array is cooperative with respect to the signal transition, an incident
signal photon can efficiently couple into the array and is admixed into dipolar
idler modes by the drive. Under specific criticality conditions, this admixture
is into a superradiant idler mode which primarily decays into a specific,
highly directional optical photon that propagates within the array plane.
Outside of the array, this photon may then be coupled into existing quantum
devices for further processing. Using a scattering-operator formalism we derive
resonance and criticality conditions that govern this two-step process and
obtain analytic transduction efficiencies. For infinite lattices, we predict
transduction efficiencies into specific spatial directions of up to 50%, while
the overall, undirected transduction efficiency can be higher. An analysis for
finite arrays of $N^2$ emitters, shows that the output is collimated into lobes
that narrow as $1/\sqrt{N}$. Our scheme combines the broadband acceptance of
free-space 4-wave mixing with the efficiency, directionality and tunability of
cooperative metasurfaces, offering a route towards quantum-coherent THz
detection and processing for astronomical spectroscopy, quantum-networked
sparse-aperture imaging and other quantum-sensing applications.

</details>


### [169] [Probing non-equilibrium physics through the two-body Bell correlator](https://arxiv.org/abs/2510.27657)
*Abhishek Muhuri,Tanoy Kanti Konar,Leela Ganesh Chandra Lakkaraju,Aditi Sen De*

Main category: quant-ph

TL;DR: 贝尔算符可用于检测长程XY自旋链中的动力学量子相变，即使在长程相互作用、各向异性和系统尺寸变化的情况下也有效。


<details>
  <summary>Details</summary>
Motivation: 在仅依赖局部可观测量的条件下，从动力学中识别动力学量子相变（DQPT）具有挑战性。

Method: 研究了贝尔算符在长程XY自旋链中作为DQPT的探测器，并考虑了两种淬灭协议（磁场强度和相互作用衰减率）。

Result: 在系统参数突然淬灭后，近邻自旋之间的贝尔算符在临界边界处出现明显下降，该下降可作为区分相内和相间淬灭的阈值。

Conclusion: 贝尔算符是检测长程XY自旋链中DQPT的有效方法，其表现优于传统的量子和经典关联子，包括纠缠。

Abstract: Identifying equilibrium criticalities and phases from the dynamics of a
system, known as a dynamical quantum phase transition (DQPT), is a challenging
task when relying solely on local observables. We exhibit that the
experimentally accessible two-body Bell operator, originally designed to detect
nonlocal correlations in quantum states, serves as an effective witness of
DQPTs in a long-range (LR) XY spin chain subjected to a magnetic field, where
the interaction strength decays as a power law. Following a sudden quench of
the system parameters, the Bell operator between nearest-neighbor spins
exhibits a distinct drop at the critical boundaries. In this study, we consider
two quenching protocols, namely sudden quenches of the magnetic field strength
and the interaction fall-off rate. This pronounced behavior defines a
threshold, distinguishing intra-phase from inter-phase quenches, remaining
valid regardless of the strength of long-range interactions, anisotropy, and
system sizes. Comparative analyses further demonstrate that conventional
classical and quantum correlators, including entanglement, fail to capture this
transition during dynamics.

</details>


### [170] [Teleportation-based squeezer for bosonic cluster states](https://arxiv.org/abs/2510.27661)
*Michal Matulík,Radim Filip,Petr Marek*

Main category: quant-ph

TL;DR: 基于非平衡分束器和单边探测实现最优压缩门，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 需要鲁棒且低错误的操作（门和测量）来实现可扩展的单向量子计算。

Method: 利用非平衡分束器的幅度透射系数和单边探测，并进行单位增益前馈，以压缩输入状态。

Result: 所提出的方法优于基于最优旋转单边探测和固定平衡分束器的现有方法，并且对高斯和非高斯输入态的压缩门性能进行了评估。

Conclusion: 该研究为在实验上可实现的簇状态中实现低噪声压缩门提供了新的途径。

Abstract: The one-way quantum computation utilizing bosonic modes of light offers
unmatched scalability of light modes, and it has seen rapid experimental
development recently. Scalability requires robust and low-error gates and
measurements. Squeezing gate is one of the necessary Gaussian operations. We
find the optimal squeezing gate in cluster state architecture. Our approach
newly uses amplitude transmission coefficients of unbalanced beam splitters and
homodyne detection with subsequent unity-gain feed-forward to squeeze the input
state. The approach outperforms the current method based on optimally rotated
homodyne detection, but with fixed balanced beam splitters. The performance of
both cluster state squeezers is evaluated for Gaussian and non-Gaussian input
states. We use different metrics to benchmark the quality of squeezed output
states. The result opens a road to low-noise squeezing gates in experimentally
achievable cluster states.

</details>


### [171] [Quantum waste management: Utilizing residual states in quantum information processing](https://arxiv.org/abs/2510.27687)
*Karol Horodecki,Chirag Srivastava,Leonard Sikorski,Siddhartha Das*

Main category: quant-ph

TL;DR: 通过从量子密钥分发（QKD）的剩余状态中提取私有随机性来提高量子资源利用率。


<details>
  <summary>Details</summary>
Motivation: 扩展了传统的量子资源理论，通过整合二次资源提取，提高了整体资源利用率。

Method: 提出了一种量子剩余管理框架，并以从QKD的剩余状态中提取私有随机性为例进行了研究。具体地，研究了Devetak-Winter协议和Gottesman-Lo QKD协议。

Result: 证明了在执行Devetak-Winter协议后，可以从剩余状态中提取私有随机性。此外，还提供了Gottesman-Lo QKD协议性能后剩余状态可实现的私有随机性速率。

Conclusion: 提出了一个形式化框架，强调了在顺序信息处理任务中提高量子资源利用率的通用原理。

Abstract: We propose a framework for quantum residual management, in which states
discarded after a resource distillation process are repurposed as inputs for
subsequent quantum information tasks. This approach extends conventional
quantum resource theories by incorporating secondary resource extraction from
residual states, thereby enhancing overall resource utility. As a concrete
example, we investigate the distillation of private randomness from the
residual states remaining after quantum key distribution (QKD). More
specifically, we quantitatively show that after performing a well-known
coherent Devetak-Winter protocol one can locally extract private randomness
from its residual. We further consider the Gottesman-Lo QKD protocol, and
provide the achievable rate of private randomness from the discarded states
that are left after its performance. We also provide a formal framework that
highlights a general principle for improving quantum resource utilization
across sequential information processing tasks.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [172] [Investigation of Superdirectivity in Planar Holographic Arrays](https://arxiv.org/abs/2510.26803)
*Hang Lin,Liuxun Xue,Shu Sun,Ruifeng Gao,Jue Wang,Tengjiao Wang*

Main category: eess.SP

TL;DR: 该论文研究了全息MIMO系统中均匀矩形阵列（URAs）的超指向性特征。通过建立URAs的数学指向性模型，推导了最大指向性的解析表达式。结果表明，通过合理利用耦合效应可以显著增强指向性，但在天线间距过渡到深亚波长尺度时，这种增强的效益会递减。该研究为超指令URAs的设计提供了理论基础，并为5G/6G通信系统中的全息阵列优化提供了宝贵的见解。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索和理解全息MIMO系统中均匀矩形阵列（URAs）的超指向性特性，并为优化这些阵列以提升通信系统性能提供理论指导。

Method: 通过建立URAs的数学指向性模型，推导出最大指向性的解析表达式，并结合数值模拟进行系统性分析。

Result: 研究表明，合理利用耦合效应可以显著提高URAs的指向性，但当天线间距达到深亚波长尺度时，增益效果会逐渐减小。

Conclusion: 该研究为设计超指令URAs提供了理论基础，并为优化5G/6G通信系统中的全息阵列提供了有价值的参考。

Abstract: This paper studies the superdirectivity characteristics of uniform
rectangular arrays (URAs) for holographic multiple-input multiple-output
systems. By establishing a mathematical directivity model for the URA, an
analytical expression for the maximum directivity is derived. Accordingly,
systematic analysis is performed in conjunction with numerical simulations.
Results show that the directivity can be significantly enhanced via rational
utilization of coupling effects. However, this enhancement yields diminishing
returns when antenna spacings transition to deep sub-wavelength scales. This
study provides a theoretical basis for the design of superdirective URAs and
offers valuable insights for holographic array optimization in 5G/6G
communication systems.

</details>


### [173] [Joint optimization of microphone array geometry, sensor directivity pattern, and beamforming parameters for linear superarrays](https://arxiv.org/abs/2510.26822)
*Yuanhang Qian,Xueqin Luo,Jilu Jin,Gongping Huang,Jingdong Chen,Jacob Benesty*

Main category: eess.SP

TL;DR: 该研究提出了一种通用的线性超阵列（LSA）优化框架，同时优化阵列几何、单元方向性和波束形成滤波器，以最小化设计波束与理想方向性模式（IDP）之间的近似误差。


<details>
  <summary>Details</summary>
Motivation: 现有的线性差分麦克风阵列（LDMA）在转向能力上存在局限性，而现有的线性超阵列（LSA）在阵列几何和单元方向性方面没有得到联合优化，影响了波束形成性能。

Method: 提出了一种通用的LSA优化框架，利用雅可比-安格尔级数展开来逼近IDP，并通过遗传算法优化阵列几何和单元方向性。

Result: 仿真结果表明，所提出的优化阵列在目标频带和转向范围内，相比传统LSA具有更低的近似误差，并且其方向性因子和白噪声增益在不同频率和转向角度下表现出更稳定和更优的性能。

Conclusion: 研究提出了一种能够联合优化阵列几何、单元方向性和波束形成滤波器的LSA优化框架，显著提升了波束形成性能。

Abstract: Linear superarrays (LSAs) have been proposed to address the limited steering
capability of conventional linear differential microphone arrays (LDMAs) by
integrating omnidirectional and directional microphones, enabling more flexible
beamformer designs. However, existing approaches remain limited because array
geometry and element directivity, both critical to beamforming performance, are
not jointly optimized. This paper presents a generalized LSA optimization
framework that simultaneously optimizes array geometry, element directivity,
and the beamforming filter to minimize the approximation error between the
designed beampattern and an ideal directivity pattern (IDP) over the full
frequency band and all steering directions within the region of interest. The
beamformer is derived by approximating the IDP using a Jacobi-Anger series
expansion, while the array geometry and element directivity are optimized via a
genetic algorithm. Simulation results show that the proposed optimized array
achieves lower approximation error than conventional LSAs across the target
frequency band and steering range. Additionally, its directivity factor and
white noise gain demonstrate more stable and improved performance across
frequencies and steering angles.

</details>


### [174] [GeoPep: A geometry-aware masked language model for protein-peptide binding site prediction](https://arxiv.org/abs/2510.27040)
*Dian Chen,Yunkai Chen,Tong Lin,Sijie Chen,Xiaolin Cheng*

Main category: eess.SP

TL;DR: GeoPep利用预训练的ESM3模型和参数高效的神经网络，结合基于距离的损失函数，解决了蛋白质-肽相互作用位点预测中的数据稀疏性和肽的构象灵活性问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态方法在蛋白质-蛋白质相互作用预测方面取得了成功，但由于肽的构象灵活性和结构数据有限，将其扩展到蛋白质-肽相互作用方面仍具挑战性。

Method: GeoPep框架利用ESM3模型的转移学习能力，并结合参数高效的神经网络和基于距离的损失函数进行训练。

Result: GeoPep在蛋白质-肽结合位点预测方面显著优于现有方法，有效捕捉了稀疏且异构的结合模式。

Conclusion: GeoPep框架能够有效解决蛋白质-肽相互作用位点预测中的数据稀疏性和肽的构象灵活性问题，并取得了优于现有方法的性能。

Abstract: Multimodal approaches that integrate protein structure and sequence have
achieved remarkable success in protein-protein interface prediction. However,
extending these methods to protein-peptide interactions remains challenging due
to the inherent conformational flexibility of peptides and the limited
availability of structural data that hinder direct training of structure-aware
models. To address these limitations, we introduce GeoPep, a novel framework
for peptide binding site prediction that leverages transfer learning from ESM3,
a multimodal protein foundation model. GeoPep fine-tunes ESM3's rich
pre-learned representations from protein-protein binding to address the limited
availability of protein-peptide binding data. The fine-tuned model is further
integrated with a parameter-efficient neural network architecture capable of
learning complex patterns from sparse data. Furthermore, the model is trained
using distance-based loss functions that exploit 3D structural information to
enhance binding site prediction. Comprehensive evaluations demonstrate that
GeoPep significantly outperforms existing methods in protein-peptide binding
site prediction by effectively capturing sparse and heterogeneous binding
patterns.

</details>


### [175] [Blind MIMO Semantic Communication via Parallel Variational Diffusion: A Completely Pilot-Free Approach](https://arxiv.org/abs/2510.27043)
*Hao Jiang,Xiaojun Yuan,Yinuo Huang,Qinghua Guo*

Main category: eess.SP

TL;DR: 提出了一种名为Blind-MIMOSC的新型盲MIMO语义通信框架，该框架包含深度联合信源信道编码（DJSCC）发射机和基于扩散的盲接收机。


<details>
  <summary>Details</summary>
Motivation: 提出一种无需导频即可联合进行信道估计和信源恢复的完全无导频解决方案，特别是在块衰落MIMO系统中，以克服现有方法的局限性。

Method: DJSCC发射机通过利用信源数据的结构特性来压缩和映射信源数据到传输信号；基于扩散的盲接收机采用并行变分扩散（PVD）模型，通过两个预训练的评分网络来表征信道和信源数据的先验信息，在推理过程中以即插即用的方式运行，从而同时从接收信号中恢复信道和信源数据，且无需任何导频。

Result: Blind-MIMOSC与PVD相比，在信道和信源恢复精度上优于最先进的方法，同时大大降低了信道带宽比。

Conclusion: Blind-MIMOSC框架能够有效地进行信道估计和信源恢复，并且在性能上优于现有方法，同时减少了对信道带宽的需求。

Abstract: In this paper, we propose a novel blind multi-input multi-output (MIMO)
semantic communication (SC) framework named Blind-MIMOSC that consists of a
deep joint source-channel coding (DJSCC) transmitter and a diffusion-based
blind receiver. The DJSCC transmitter aims to compress and map the source data
into the transmitted signal by exploiting the structural characteristics of the
source data, while the diffusion-based blind receiver employs a parallel
variational diffusion (PVD) model to simultaneously recover the channel and the
source data from the received signal without using any pilots. The PVD model
leverages two pre-trained score networks to characterize the prior information
of the channel and the source data, operating in a plug-and-play manner during
inference. This design allows only the affected network to be retrained when
channel conditions or source datasets change, avoiding the complicated
full-network retraining required by end-to-end methods. This work presents the
first fully pilot-free solution for joint channel estimation and source
recovery in block-fading MIMO systems. Extensive experiments show that
Blind-MIMOSC with PVD achieves superior channel and source recovery accuracy
compared to state-of-the-art approaches, with drastically reduced channel
bandwidth ratio.

</details>


### [176] [Distributed Precoding for Cell-free Massive MIMO in O-RAN: A Multi-agent Deep Reinforcement Learning Framework](https://arxiv.org/abs/2510.27069)
*Mohammad Hossein Shokouhi,Vincent W. S. Wong*

Main category: eess.SP

TL;DR: 本文提出了一种分布式、可扩展的蜂窝小区海量多输入多输出(MIMO)预编码框架，结合了多智能体深度强化学习和迭代算法，以提高网络吞吐量并减少干扰，同时降低了信令开销。


<details>
  <summary>Details</summary>
Motivation: 现有的全分布式预编码方案可能导致高干扰，而全集中式方案则不具备可扩展性。为了解决蜂窝小区海量MIMO在O-RAN架构中的可扩展性、去中心化和高容量需求，需要一种新的预编码方法。

Method: 提出了一种多时间尺度的框架，该框架结合了多智能体深度强化学习（DRL）和迭代算法中的专家洞察力，用于高效地确定预编码矩阵。该方法通过有限的信息交换来协调预编码代理，以减轻干扰，并提出了一个优化问题，旨在最大化总吞吐量同时保证用户的最低数据速率要求。

Result: 与分布式正则化零迫近（D-RZF）和加权最小均方误差（WMMSE）算法相比，所提出的框架实现了更高的聚合吞吐量。与集中式正则化零迫近（C-RZF）方案相比，所提出的框架实现了相似的聚合吞吐量性能，但信令开销更低。

Conclusion: 所提出的分布式、可扩展的预编码框架通过结合多智能体DRL和专家洞察力，有效解决了蜂窝小区海量MIMO在O-RAN架构中的挑战，并在性能和效率上优于现有方法。

Abstract: Cell-free massive multiple-input multiple-output (MIMO) is a key technology
for next-generation wireless systems. The integration of cell-free massive MIMO
within the open radio access network (O-RAN) architecture addresses the growing
need for decentralized, scalable, and high-capacity networks that can support
different use cases. Precoding is a crucial step in the operation of cell-free
massive MIMO, where O-RUs steer their beams towards the intended users while
mitigating interference to other users. Current precoding schemes for cell-free
massive MIMO are either fully centralized or fully distributed. Centralized
schemes are not scalable, whereas distributed schemes may lead to a high
inter-O-RU interference. In this paper, we propose a distributed and scalable
precoding framework for cell-free massive MIMO that uses limited information
exchange among precoding agents to mitigate interference. We formulate an
optimization problem for precoding that maximizes the aggregate throughput
while guaranteeing the minimum data rate requirements of users. The formulated
problem is nonconvex. We propose a multi-timescale framework that combines
multi-agent deep reinforcement learning (DRL) with expert insights from an
iterative algorithm to determine the precoding matrices efficiently. We conduct
simulations and compare the proposed framework with the centralized precoding
and distributed precoding methods for different numbers of O-RUs, users, and
transmit antennas. The results show that the proposed framework achieves a
higher aggregate throughput than the distributed regularized zero-forcing
(D-RZF) scheme and the weighted minimum mean square error (WMMSE) algorithm.
When compared with the centralized regularized zero-forcing (C-RZF) scheme, the
proposed framework achieves similar aggregate throughput performance but with a
lower signaling overhead.

</details>


### [177] [RFI Detection and Identification at OVRO Using Pseudonymetry](https://arxiv.org/abs/2510.27078)
*Meles Weldegebriel,Zihan Li,Greg Hellbourg,Ning Zhang,Neal Patwari*

Main category: eess.SP

TL;DR: 该论文首次展示了在 Owens Valley射电天文台（OVRO）的实际现场试验中，使用假名技术实现异构无线系统之间的协同频谱共享。


<details>
  <summary>Details</summary>
Motivation: 随着受保护频段附近无线传输的增加，保护射电天文学台免受意外干扰至关重要。然而，现有的数据库驱动的协调框架和无线静默区无法快速识别或抑制特定的干扰发射源，尤其是在低信噪比（SNR）水平下。

Method: 论文提出了一种新方法，其中窄带次级发射器将其假名水印嵌入信号中，而宽带射电望远镜则被动地从频谱图数据中提取水印。

Result: 实验结果表明，即使在传统解调不可行的低信噪比下，也能可靠地检测到干扰，并唯一地识别出干扰设备。

Conclusion: 研究结果证明，被动科学接收器可以参与轻量级反馈循环，触发有害传输的关闭，这表明假名技术作为保护射电天文环境的补充执法工具具有潜力。

Abstract: Protecting radio astronomy observatories from unintended interference is
critical as wireless transmissions increases near protected bands. While
database-driven coordination frameworks and radio quiet zones exist, they
cannot rapidly identify or suppress specific interfering transmitters,
especially at low signal-to-noise ratio (SNR) levels. This paper presents the
first over-the-air field demonstration of Pseudonymetry at the Owens Valley
Radio Observatory (OVRO), illustrating cooperative spectrum sharing between
heterogeneous wireless systems. In our experiment, a narrow-band secondary
transmitter embeds a pseudonym watermark into its signal, while the wide-band
radio telescope passively extracts the watermark from spectrogram data. Results
show that interference can be reliably detected and the interfering device
uniquely identified even at low SNR where conventional demodulation is
infeasible. These findings validate that passive scientific receivers can
participate in a lightweight feedback loop to trigger shutdown of harmful
transmissions, demonstrating the potential of Pseudonymetry as a complementary
enforcement tool for protecting radio astronomy environments.

</details>


### [178] [Unlimited Sampling of Multiband Signals: Single-Channel Acquisition and Recovery](https://arxiv.org/abs/2510.27110)
*Gal Shtendel,Ayush Bhandari*

Main category: eess.SP

TL;DR: 提出了一种在无限传感框架（USF）下从模折叠、点采样中重建多频带信号的方法，实现了亚奈奎斯特定理，并在硬件实验中将动态范围提高了13倍。


<details>
  <summary>Details</summary>
Motivation: 在无限传感框架（USF）下，研究如何从模折叠、点采样的信号中重建多频带信号，特别关注低复杂度、单通道的采集设置。

Method: 提出了一种恢复算法，用于从模折叠、点采样中重建多频带信号，并在理论上证明了亚奈奎斯特定理的可行性。

Result: 提出的恢复算法在硬件实验中实现了高达13倍的动态范围改进，支持最多6个频谱带。这使得在动态范围和过采样受限的场景下，能够进行实际的高动态范围多频带采集。

Conclusion: 该研究为在USF框架下实现亚奈奎斯特定理下的多频带信号重建提供了理论保证和有效的算法，并在实际应用中显著提高了动态范围，克服了先前技术的限制。

Abstract: In this paper, we address the problem of reconstructing multiband signals
from modulo-folded, pointwise samples within the Unlimited Sensing Framework
(USF). Focusing on a low-complexity, single-channel acquisition setup, we
establish recovery guarantees demonstrating that sub-Nyquist sampling is
achievable under the USF paradigm. In doing so, we also tighten the previous
sampling theorem for bandpass signals. Our recovery algorithm demonstrates up
to a 13x dynamic range improvement in hardware experiments with up to 6
spectral bands. These results enable practical high-dynamic-range multiband
acquisition in scenarios previously limited by dynamic range and excessive
oversampling.

</details>


### [179] [From OFDM to AFDM: Enabling Adaptive Integrated Sensing and Communication in High-Mobility Scenarios](https://arxiv.org/abs/2510.27192)
*Haoran Yin,Yanqun Tang,Jun Xiong,Fan Liu,Yuanhan Ni,Qu Luo,Roberto Bomfin,Marwa Chafii,Marios Kountouris,Christos Masouros*

Main category: eess.SP

TL;DR: AFDM-ISAC是一种针对高移动性场景的新型集成传感与通信技术，它利用AFDM波形克服了OFDM在高移动性场景下的性能瓶颈，并在此基础上探讨了其性能极限和传感算法。


<details>
  <summary>Details</summary>
Motivation: 高移动性场景（如V2X和UAV）下的无线通信面临严重的延迟和多普勒扩展问题，这会严重影响OFDM的通信性能。因此，需要一种能够适应这些挑战的技术来实现集成传感与通信（ISAC）。

Method: 本文首先介绍了AFDM-ISAC的基础，强调了其与FMCW的相似性。然后，通过分析其分集阶数、模糊函数（AF）和Cramer-Rao界（CRB）来探讨其ISAC性能极限。最后，提出了一些有效的传感算法和应用机会。

Result: AFDM波形由于其灵活的चirp信号子载波特性，在高移动性场景下展现出优于OFDM的潜力，能够实现自适应的ISAC。文章通过理论分析（分集阶数、AF、CRB）对其性能进行了量化评估，并提出了一系列传感算法和应用方向。

Conclusion: AFDM-ISAC技术为高移动性场景下的ISAC提供了一种有前景的解决方案，克服了传统OFDM的局限性。未来的研究应继续探索其在传感算法和实际应用中的潜力。

Abstract: Integrated sensing and communication (ISAC) is a key feature of
next-generation wireless networks, enabling a wide range of emerging
applications such as vehicle-to-everything (V2X) and unmanned aerial vehicles
(UAVs), which operate in high-mobility scenarios. Notably, the wireless
channels within these applications typically exhibit severe delay and Doppler
spreads. The latter causes serious communication performance degradation in the
Orthogonal Frequency-Division Multiplexing (OFDM) waveform that is widely
adopted in current wireless networks. To address this challenge, the recently
proposed Doppler-resilient affine frequency division multiplexing (AFDM)
waveform, which uses flexible chirp signals as subcarriers, shows great
potential for achieving adaptive ISAC in high-mobility scenarios. This article
provides a comprehensive overview of AFDM-ISAC. We begin by presenting the
fundamentals of AFDM-ISAC, highlighting its inherent frequency-modulated
continuous-wave (FMCW)-like characteristics. Then, we explore its ISAC
performance limits by analyzing its diversity order, ambiguity function (AF),
and Cramer-Rao Bound (CRB). Finally, we present several effective sensing
algorithms and opportunities for AFDM-ISAC, with the aim of sparking new ideas
in this emerging field.

</details>


### [180] [Joint Visible Light and Backscatter Communications for Proximity-Based Indoor Asset Tracking Enabled by Energy-Neutral Devices](https://arxiv.org/abs/2510.27217)
*Boxuan Xie,Lauri Mela,Alexis A. Dowhuszko,Yu Bai,Zehui Xiong,Zhu Han,Dusit Niyato,Riku Jäntti*

Main category: eess.SP

TL;DR: 本研究提出了一种结合可见光通信（VLC）和反向散射通信（BC）的混合室内资产追踪系统，利用同时光波信息和能量传输（SLIPT）框架，为能源中性物联网节点设计了一种低复杂度、低功耗的解决方案，通过光能收集、信号调制和反射射频信号来指示其位置，并采用多小区VLC部署和粒子滤波（PF）算法进行追踪，实现了0.318米的定位误差（50%分位），验证了该方案在可扩展、低成本和能源中性室内追踪方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在下一代无线系统中，为能源中性设备提供基于位置的移动计算服务是物联网可持续性的关键目标。可见光定位（VLP）作为一种利用现有照明基础设施的互补技术，受到广泛关注。然而，传统的VLP接收器通常依赖功耗高、复杂度高且成本高的光电探测器或摄像头。因此，需要一种更经济、更节能的定位解决方案。

Method: 本研究提出了一种混合室内资产追踪系统，该系统将可见光通信（VLC）和反向散射通信（BC）集成在同时光波信息和能量传输（SLIPT）框架下。系统设计了一个低复杂度、能源中性的物联网节点（反向散射设备，BD），该节点从LED接入点收集能量，然后调制并反射环境射频载波以指示其在特定VLC小区内的位置。采用多小区VLC部署，并利用频分复用（FDM）方法，通过基于四色图调度原则为LED接入点分配不同的频率对来减轻干扰。在边缘射频读取器上开发了一个轻量级粒子滤波（PF）追踪算法，融合了邻近报告和接收到的反向散射信号强度来进行追踪。

Result: 实验结果表明，该方法在50%分位时实现了0.318米的定位误差，在90%分位时实现了0.634米的定位误差。该系统成功避免了在能源中性物联网节点中使用复杂的 ज्यात基光电探测器和有源射频合成元件。

Conclusion: 所提出的混合室内资产追踪系统通过利用SLIPT框架、低功耗的BD节点和轻量级PF追踪算法，成功实现了能源中性、低成本和可扩展的室内定位。该方案有效解决了传统VLP技术的局限性，并在多种室内轨迹中展现了稳健的性能，为边缘辅助的物联网应用提供了可行的解决方案。

Abstract: In next-generation wireless systems, providing location-based mobile
computing services for energy-neutral devices has become a crucial objective
for the provision of sustainable Internet of Things (IoT). Visible light
positioning (VLP) has gained great research attention as a complementary method
to radio frequency (RF) solutions since it can leverage ubiquitous lighting
infrastructure. However, conventional VLP receivers often rely on
photodetectors or cameras that are power-hungry, complex, and expensive. To
address this challenge, we propose a hybrid indoor asset tracking system that
integrates visible light communication (VLC) and backscatter communication (BC)
within a simultaneous lightwave information and power transfer (SLIPT)
framework. We design a low-complexity and energy-neutral IoT node, namely
backscatter device (BD) which harvests energy from light-emitting diode (LED)
access points, and then modulates and reflects ambient RF carriers to indicate
its location within particular VLC cells. We present a multi-cell VLC
deployment with frequency division multiplexing (FDM) method that mitigates
interference among LED access points by assigning them distinct frequency pairs
based on a four-color map scheduling principle. We develop a lightweight
particle filter (PF) tracking algorithm at an edge RF reader, where the fusion
of proximity reports and the received backscatter signal strength are employed
to track the BD. Experimental results show that this approach achieves the
positioning error of 0.318 m at 50th percentile and 0.634 m at 90th percentile,
while avoiding the use of complex photodetectors and active RF synthesizing
components at the energy-neutral IoT node. By demonstrating robust performance
in multiple indoor trajectories, the proposed solution enables scalable,
cost-effective, and energy-neutral indoor tracking for pervasive and
edge-assisted IoT applications.

</details>


### [181] [SIM-Assisted End-to-End Co-Frequency Co-Time Full-Duplex System](https://arxiv.org/abs/2510.27270)
*Yida Zhang,Qiuyan Liu,Yuqi Xia,Guoxu Xia,Qiang Wang*

Main category: eess.SP

TL;DR: 提出了一种结合智能超表面（SIM）和端到端（E2E）学习的通信方法，用于抑制全双工（CCFD）系统中的自干扰（SI），并在通信任务中实现了信号的波域处理。


<details>
  <summary>Details</summary>
Motivation: 为了进一步抑制全双工（CCFD）系统中固有的自干扰（SI）。

Method: 提出将堆叠式智能超表面（SIM）集成到射频前端，并通过端到端（E2E）学习方法来控制超表面。将真实超表面抽象为网络的隐藏层，构建电磁神经网络（EMNN），在电磁（EM）前向传播过程中同步执行信道编码、调制、预编码、合并、解调和信道解码等通信任务。

Result: 仿真结果表明，SIM辅助的CCFD系统相对于传统CCFD系统，其误比特率（BER）得到了显著降低。

Conclusion: 该研究充分展示了电磁神经网络（EMNN）和SIM辅助的E2E CCFD系统在下一代收发器设计中的应用潜力。

Abstract: To further suppress the inherent self-interference (SI) in co-frequency and
co-time full-duplex (CCFD) systems, we propose integrating a stacked
intelligent metasurface (SIM) into the RF front-end to enhance signal
processing in the wave domain. Furthermore, an end-to-end (E2E) learning-based
signal processing method is adopted to control the metasurface. Specifically,
the real metasurface is abstracted as hidden layers of a network, thereby
constructing an electromagnetic neural network (EMNN) to enable driving control
of the real communication system. Traditional communication tasks, such as
channel coding, modulation, precoding, combining, demodulation, and channel
decoding, are synchronously carried out during the electromagnetic (EM) forward
propagation through the metasurface. Simulation results show that, benefiting
from the additional wave-domain processing capability of the SIM, the
SIM-assisted CCFD system achieves significantly reduced bit error rate (BER)
compared with conventional CCFD systems. Our study fully demonstrates the
potential applications of EMNN and SIM-assisted E2E CCFD systems in
next-generation transceiver design.

</details>


### [182] [Variational Bayesian Estimation of Low Earth Orbits for Satellite Communication](https://arxiv.org/abs/2510.27345)
*Anders Malthe Westerkam,Amélia Struyf,Dimitri Lederer,Troels Pedersen,François Quitin*

Main category: eess.SP

TL;DR: 该论文提出了一种变分消息传递算法，用于从地面站联合定位和跟踪低地球轨道（LEO）卫星，解决了混合架构中的潜在模糊性问题，并能在近地平线的情况下实现可靠跟踪。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）卫星通信系统需要快速波束转向，但LEO卫星可见时间短，对波束跟踪和定位提出了挑战。

Method: 提出了一种变分消息传递算法，对轨道参数进行估计，然后从轨道参数推导出角度信息，以实现卫星的联合定位和波束跟踪。

Result: 仿真结果表明，该方法对漏检具有高鲁棒性，能够实现近地平线下的可靠跟踪，并有效消除混合架构中的固有模糊性。

Conclusion: 所提出的变分消息传递算法能够有效地解决低地球轨道（LEO）卫星通信中的联合定位和波束跟踪问题，尤其是在存在漏检和混合架构固有模糊性的情况下。

Abstract: Low-earth-orbit (LEO) satellite communication systems that use
millimeter-wave frequencies rely on large antenna arrays with hybrid
analog-digital architectures for rapid beam steering. LEO satellites are only
visible from the ground for short periods of times (a few tens of minutes) due
to their high orbital speeds. This paper presents a variational message passing
algorithm for joint localization and beam tracking of a LEO satellite from a
ground station equipped with a hybrid transceiver architecture. The algorithm
relies on estimating the parameters of the orbit, which is modelled as
circular. Angles are then obtained from the orbit in a straightforward manner.
Simulation results show that the proposed method is highly resilient to missed
detections, enables reliable satellite tracking even near the horizon, and
effectively alleviates the ambiguities inherent in hybrid architectures.

</details>


### [183] [Classification of Lower Limb Activities Based on Discrete Wavelet Transform Using On-Body Creeping Wave Propagation](https://arxiv.org/abs/2510.27371)
*Sagar Dutta,Banani Basu,Fazal Ahmed Talukdar*

Main category: eess.SP

TL;DR: 通过分析人体大腿周围的爬行波传播来监测腿部运动，其中SVM结合DWT在活动分类方面表现最佳，且SAR在FCC标准阈值内。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用人体大腿周围的爬行波传播来监测腿部运动，并将腿部运动信息用于活动分类。

Method: 使用两个柔性PET天线测量六种不同腿部活动下的传输系数变化，并应用离散小波变换（DWT）和多种分类器（SVM、决策树、朴素贝叶斯、KNN）进行特征提取和分类。此外，还使用了动态时间规整（DTW）和深度卷积神经网络（DCNN）。

Result: SVM结合DWT在活动分类中表现优于其他方法。模拟显示，当天线紧贴大腿放置时，特定的吸收率（SAR）在FCC标准阈值内。

Conclusion: 所提出的基于爬行波传播的腿部运动监测方法是有效的，并且在安全暴露限度内，其中SVM与DWT的组合在分类性能上表现突出。

Abstract: This article investigates how the creeping wave propagation around the human
thigh could be used to monitor the leg movements. The propagation path around
the human thigh gives information regarding leg motions that can be used for
the classification of activities. The variation of the transmission coefficient
is measured between two on-body polyethylene terephthalate (PET) flexible
antennas for six different leg-based activities that exhibit unique
time-varying signatures. A discrete wavelet transform (DWT) along with
different classifiers, such as support vector machine (SVM), decision trees,
naive Bayes, and K-nearest neighbors (KNN), is applied for feature extraction
and classification to evaluate the efficiency for classifying different
activity signals. Additional algorithms, such as dynamic time warping (DTW) and
deep convolutional neural network (DCNN), have also been implemented, and in
each case, SVM with DWT outperforms the others. Simulation to evaluate a
specific absorption rate (SAR) is carried out as the antenna is positioned on
the human thigh leaving no gap. The results show that the SAR is within the
threshold as per the Federal Communications Commission (FCC) standard.

</details>


### [184] [Classification of Induction Motor Fault and Imbalance Based on Vibration Signal Using Single Antenna's Reactive Near Field](https://arxiv.org/abs/2510.27382)
*Sagar Dutta,Banani Basu,Fazal Ahmed Talukdar*

Main category: eess.SP

TL;DR: 提出了一种使用天线作为传感器来检测电机轴承故障和不平衡的新方法，该方法具有非侵入性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 早期故障诊断对于旋转机械的正常运行至关重要，可以减少意外故障造成的经济损失。现有的故障分析方法要么成本高昂，要么需要专业知识来安装传感器。

Method: 使用天线作为传感器，检测时变S11，并通过S11的频谱图、FFT分析、平均功率内容和深度学习模型对故障进行分类。

Result: 使用S11的幅度和相位，分类准确率为98.2%；仅使用S11的幅度，分类准确率为96%；仅使用S11的相位，分类准确率为92.1%。还研究了不同工作频率、天线位置和时间窗口下的分类准确性。

Conclusion: 所提出的使用天线作为传感器检测电机轴承故障和不平衡的方法是准确且经济高效的。

Abstract: Early fault diagnosis is imperative for the proper functioning of rotating
machines. It can reduce economic losses in the industry due to unexpected
failures. Existing fault analysis methods are either expensive or demand
expertise for the installation of the sensors. This article proposes a novel
method for the detection of bearing faults and imbalance in induction motors
using an antenna as the sensor, which is noninvasive and cost-efficient.
Time-varying S11 is measured using an omnidirectional antenna, and it is seen
that the spectrogram of S11 shows unique characteristics for different fault
conditions. The experimental setup has analytically evaluated the vibration
frequencies due to fault and validated the characteristic fault frequency by
applying FFT analysis on the captured S11 data. This article has evaluated the
average power content of the detected signals at normal and different fault
conditions. A deep learning model is used to classify the faults based on the
reflection coefficient ( S11). It is found that classification accuracy of
98.2% is achieved using both magnitude and phase of S11, 96% using the
magnitude of S11 and 92.1% using the phase of S11. The classification accuracy
for different operating frequencies, antenna location, and time windows are
also investigated.

</details>


### [185] [UNILocPro: Unified Localization Integrating Model-Based Geometry and Channel Charting](https://arxiv.org/abs/2510.27394)
*Yuhao Zhang,Guangjin Pan,Musa Furkan Keskin,Ossi Kaltiokallio,Mikko Valkama,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出一个统一的定位框架UNILocPro，结合了基于模型的定位和信道指纹（CC）技术，用于处理视线（LoS）/非视线（NLoS）混合场景。


<details>
  <summary>Details</summary>
Motivation: 在混合LoS/NLoS场景下，为实现更精确的定位，需要一种能自适应处理不同传播环境的统一框架。

Method: 在LoS/NLoS识别的基础上，自适应地在基于模型的定位方法和CC方法之间进行切换。在无监督学习的模式下，利用基于模型方法获得的信息来训练CC模型，结合了多种损失函数（包括新的不相似性度量设计、三元组损失、LoS损失和OT损失）以保留全局几何信息。为了降低训练复杂度，提出了UNILoc，它使用单次OT变换产生的自生成标签来训练CC模型，避免了OT损失中的迭代Sinkhorn更新。

Result: UNILocPro和UNILoc框架在混合LoS/NLoS场景下实现了显著的定位精度提升。UNILocPro（有时间戳）在无标注数据的情况下，性能接近全监督指纹定位。UNILoc在训练复杂度方面有显著降低，而性能损失很小。

Conclusion: 提出的UNILocPro和UNILoc框架能够有效提升混合LoS/NLoS场景下的定位精度，并且UNILoc在保持高精度的同时显著降低了训练复杂度。

Abstract: In this paper, we propose a unified localization framework (called UNILocPro)
that integrates model-based localization and channel charting (CC) for mixed
line-of-sight (LoS)/non-line-of-sight (NLoS) scenarios. Specifically, based on
LoS/NLoS identification, an adaptive activation between the model-based and
CC-based methods is conducted. Aiming for unsupervised learning, information
obtained from the model-based method is utilized to train the CC model, where a
pairwise distance loss (involving a new dissimilarity metric design), a triplet
loss (if timestamps are available), a LoS-based loss, and an optimal transport
(OT)-based loss are jointly employed such that the global geometry can be well
preserved. To reduce the training complexity of UNILocPro, we propose a
low-complexity implementation (called UNILoc), where the CC model is trained
with self-generated labels produced by a single pre-training OT transformation,
which avoids iterative Sinkhorn updates involved in the OT-based loss
computation. Extensive numerical experiments demonstrate that the proposed
unified frameworks achieve significantly improved positioning accuracy compared
to both model-based and CC-based methods. Notably, UNILocPro with timestamps
attains performance on par with fully-supervised fingerprinting despite
operating without labelled training data. It is also shown that the
low-complexity UNILoc can substantially reduce training complexity with only
marginal performance degradation.

</details>


### [186] [Estimation of aboveground biomass in a tropical dry forest: An intercomparison of airborne, unmanned, and space laser scanning](https://arxiv.org/abs/2510.27408)
*Nelson Mattié,Arturo Sanchez-Azofeifa,Pablo Crespo-Peremarch,Juan-Ygnacio López-Hernández*

Main category: eess.SP

TL;DR: 本研究提出了一种利用激光扫描数据和支持向量机（SVM）回归模型来估算热带干旱森林地上生物量（AGB）的方法，并对不同激光扫描系统（ALS、ULS、SLS）的估算精度进行了比较。


<details>
  <summary>Details</summary>
Motivation: 《巴黎气候变化协定》要求各国定期报告温室气体排放，森林在减少碳排放方面至关重要。热带干旱森林是了解最少的热带森林类型，因此需要准确估算其碳储量以满足气候协定要求。

Method: 比较了不同离散和全波形激光扫描数据集，结合普通最小二乘法和贝叶斯方法，并使用支持向量机（SVM）回归模型。利用机器学习方法进行变量选择、SVM回归调优和交叉验证，以防止过拟合和欠拟合。

Result: 研究结果表明，树高相关的变量（如 Elev.minimum, Elev.L3, lev.MAD.mode, Elev.mode, Elev.MAD.median, Elev.skewness）对于使用 ALSD 和 ULSD 进行 AGB 估算很重要。而叶面积指数、冠层覆盖度、树高等变量，以及地形高程和全波形信号能量是最关键的变量。在哥斯达黎加瓜纳卡斯特省的十个永久性热带干旱森林样地中，估算的 AGB 范围为 26.02 至 175.43 吨/公顷。SVM 回归模型在所有激光扫描系统中的平均误差为 17.89%，其中 SLSF W 估算每公顷总生物量的误差最低，为 17.07%。

Conclusion: 本研究通过比较不同的激光扫描系统和机器学习方法，为提高热带干旱森林地上生物量的估算精度提供了有效途径，并验证了 SLSF W 在估算生物量方面的潜力。

Abstract: According to the Paris Climate Change Agreement, all nations are required to
submit reports on their greenhouse gas emissions and absorption every two years
by 2024. Consequently, forests play a crucial role in reducing carbon
emissions, which is essential for meeting these obligations. Recognizing the
significance of forest conservation in the global battle against climate
change, Article 5 of the Paris Agreement emphasizes the need for high-quality
forest data. This study focuses on enhancing methods for mapping aboveground
biomass in tropical dry forests. Tropical dry forests are considered one of the
least understood tropical forest environments; therefore, there is a need for
accurate approaches to estimate carbon pools. We employ a comparative analysis
of AGB estimates, utilizing different discrete and full-waveform laser scanning
datasets in conjunction with Ordinary Least Squares and Bayesian approaches
SVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanning
were used as independent variables for extracting forest metrics. Variable
selection, SVM regression tuning, and cross-validation via a machine-learning
approach were applied to account for overfitting and underfitting. The results
indicate that six key variables primarily related to tree height: Elev.minimum,
Elev.L3, lev.MAD.mode, Elev.mode, Elev.MAD.median, and Elev.skewness, are
important for AGB estimation using ALSD and ULSD , while Leaf Area Index,
canopy coverage and height, terrain elevation, and full-waveform signal energy
emerged as the most vital variables. AGB values estimated from ten permanent
tropical dry forest plots in Costa Rica Guanacaste province ranged from 26.02
Mg/ha to 175.43 Mg/ha . The SVM regressions demonstrated a 17.89 error across
all laser scanning systems, with SLSF W exhibiting the lowest error 17.07 in
estimating total biomass per plot.

</details>


### [187] [pDANSE: Particle-based Data-driven Nonlinear State Estimation from Nonlinear Measurements](https://arxiv.org/abs/2510.27503)
*Anubhab Ghosh,Yonina C. Eldar,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出了一种名为粒子化数据驱动非线性状态估计（pDANSE）的新方法，用于在状态转移模型（STM）未知的情况下，利用非线性测量值对过程进行状态估计。pDANSE 使用循环神经网络（RNN）提供高斯先验的参数，并通过粒子采样方法估计状态后验的二阶统计量，避免了计算密集型的序列蒙特卡洛（SMC）方法。


<details>
  <summary>Details</summary>
Motivation: 在状态转移模型（STM）未知的情况下，对具有非线性测量值的过程进行数据驱动的非线性状态估计（DANSE）是一个具有挑战性的问题。现有的 DANSE 方法在测量系统线性时有封闭解，但面对非线性测量系统时失效。

Method: pDANSE 方法首先使用 RNN 根据所有先前测量值来表征模型未知过程的状态，提供高斯先验参数。然后，它采用基于重参数化技巧的粒子采样方法来处理非线性测量，并估计状态后验的二阶统计量。该方法还提出了半监督学习方法，在无标签数据时可过渡到无监督学习。

Result: 在随机洛伦兹-63（Lorenz-63）系统的四种非线性测量场景下进行了实验验证，包括立方非线性、相机模型非线性（无监督学习）、半波整流非线性以及笛卡尔到球坐标系转换非线性（半监督学习）。实验结果表明，pDANSE 的状态估计性能与具有完整 STM 知识的粒子滤波器相当。

Conclusion: pDANSE 是一种有效的数据驱动非线性状态估计方法，尤其适用于状态转移模型未知且测量系统非线性的情况。该方法利用 RNN 和粒子采样技术，能够高效地处理序列测量数据，并在多种非线性场景下实现了具有竞争力的状态估计性能。

Abstract: We consider the problem of designing a data-driven nonlinear state estimation
(DANSE) method that uses (noisy) nonlinear measurements of a process whose
underlying state transition model (STM) is unknown. Such a process is referred
to as a model-free process. A recurrent neural network (RNN) provides
parameters of a Gaussian prior that characterize the state of the model-free
process, using all previous measurements at a given time point. In the case of
DANSE, the measurement system was linear, leading to a closed-form solution for
the state posterior. However, the presence of a nonlinear measurement system
renders a closed-form solution infeasible. Instead, the second-order statistics
of the state posterior are computed using the nonlinear measurements observed
at the time point. We address the nonlinear measurements using a
reparameterization trick-based particle sampling approach, and estimate the
second-order statistics of the state posterior. The proposed method is referred
to as particle-based DANSE (pDANSE). The RNN of pDANSE uses sequential
measurements efficiently and avoids the use of computationally intensive
sequential Monte-Carlo (SMC) and/or ancestral sampling. We describe the
semi-supervised learning method for pDANSE, which transitions to unsupervised
learning in the absence of labeled data. Using a stochastic Lorenz-$63$ system
as a benchmark process, we experimentally demonstrate the state estimation
performance for four nonlinear measurement systems. We explore cubic
nonlinearity and a camera-model nonlinearity where unsupervised learning is
used; then we explore half-wave rectification nonlinearity and
Cartesian-to-spherical nonlinearity where semi-supervised learning is used. The
performance of state estimation is shown to be competitive vis-\`a-vis particle
filters that have complete knowledge of the STM of the Lorenz-$63$ system.

</details>


### [188] [Trends and Challenges in Next-Generation GNSS Interference Management](https://arxiv.org/abs/2510.27576)
*Leatile Marata,Mariona Jaramillo-Civill,Tales Imbiriba,Petri Välisuo,Heidi Kuusniemi,Elena Simona Lohan,Pau Closas*

Main category: eess.SP

TL;DR: AI有望解决GNSS干扰问题，以提高定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: GNSS的复杂性增加，传统基于物理模型的信号处理方法不足以应对日益增长的干扰威胁，因此需要新的解决方案。

Method: 提出了一种利用人工智能（AI）的方法，该方法结合了数据驱动和基于物理的模型，以实现更强大的GNSS干扰管理。

Result: AI有望通过利用数据和基于物理的模型来处理复杂的干扰形式，从而提高GNSS的可靠性和安全性。

Conclusion: AI在未来的GNSS干扰管理中具有巨大潜力，可以实现更可靠、更安全的定位。

Abstract: The global navigation satellite system (GNSS) continues to evolve in order to
meet the demands of emerging applications such as autonomous driving and smart
environmental monitoring. However, these advancements are accompanied by a rise
in interference threats, which can significantly compromise the reliability and
safety of GNSS. Such interference problems are typically addressed through
signal-processing techniques that rely on physics-based mathematical models.
Unfortunately, solutions of this nature can often fail to fully capture the
complex forms of interference. To address this, artificial intelligence
(AI)-inspired solutions are expected to play a key role in future interference
management solutions, thanks to their ability to exploit data in addition to
physics-based models. This magazine paper discusses the main challenges and
tasks required to secure GNSS and present a research vision on how AI can be
leveraged towards achieving more robust GNSS-based positioning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [189] [Market Equilibria With Buying Rights](https://arxiv.org/abs/2510.26891)
*Martin Loebl,Anetta Jedličková,Jakub Černý*

Main category: cs.GT

TL;DR: 该论文探讨了在重复阿罗-德布鲁模型中引入购买权以研究其对不平等的影响。


<details>
  <summary>Details</summary>
Motivation: 论文动机源于对分配危机的监管干预需求，在这些危机中，需求和供应长期失衡，导致稀缺资源集中在富裕阶层手中，而普通大众的需求得不到满足。

Method: 论文提出了一种迭代市场模型，在其中监管机构会定期分配购买权，并允许其与资源一同进行交易。此外，还提出了一个用于估算市场清算价格的近似算法，并定义了“挫败感”这一概念（类似于“无政府价格”），用于衡量通过市场进行分配时个体买家在公平性方面所承受的损失。

Result: 论文定义了迭代市场模型，提出了市场清算价格的近似算法，并得出了“挫败感”的上界。

Conclusion: 通过在阿罗-德布鲁模型中嵌入购买权，可以研究监管通过购买权对不平等产生的长期影响。购买权作为一种比完全中心化分配更实用的替代方案，有助于促进更公平的资源分配。

Abstract: We embed buying rights into a (repeated) Arrow-Debreu model to study the
long-term effects of regulation through buying rights on arising inequality.
Our motivation stems from situations that typically call for regulatory
interventions, such as rationing, namely, distribution crises in which demand
and supply are persistently misaligned. In such settings, scarce resources tend
to become increasingly concentrated among more affluent individuals, while the
needs of the broader population remain unmet. While fully centralized
distribution may be logistically or politically unfeasible, issuing buying
rights offers a more practical alternative: they can be implemented digitally,
e.g., via tokens traded on online platforms, making them significantly easier
to administer. We model a scenario in which a regulator periodically
distributes buying rights with the aim of promoting a more equitable
allocation. Our contributions include (i) the definition of the (iterated)
market where in each round the buying rights are distributed and then traded
alongside the resource, (ii) the approximation algorithm of the market-clearing
prices in every round, and (iii) the upper bound on \textit{frustration} -- a
notion conceptually similar to the Price of Anarchy, but for systems regulated
through buying rights, defined as the arising loss in fairness the individual
buyers have to take when the distribution is handled via the market.

</details>


### [190] [Algorithmic Predation: Equilibrium Analysis in Dynamic Oligopolies with Smooth Market Sharing](https://arxiv.org/abs/2510.27008)
*Fabian Raoul Pieroth,Ole Petersen,Martin Bichler*

Main category: cs.GT

TL;DR: 本篇论文利用深度强化学习证明了掠夺性定价作为一种理性的均衡策略，在存在公司退出（亏损后退出）的动态寡头模型中是可能出现的。


<details>
  <summary>Details</summary>
Motivation: 解释寡头模型中公司退出时，掠夺性定价均衡策略的存在性问题。

Method: 使用深度强化学习算法来计算和验证有限时间动态寡头模型中的均衡策略。

Result: 在存在公司退出（亏损后退出）的有限时间动态寡头模型中，无论信息是完全还是不完全，深度强化学习算法都能可靠地收敛到均衡；当公司面临不对称成本结构时，会出现掠夺性定价行为。

Conclusion: 掠夺性定价可以作为一种理性的均衡策略出现在多种模型设定中，解决了长期存在的学术问题，并为竞争监管机构提供了新的见解。

Abstract: Predatory pricing -- where a firm strategically lowers prices to undermine
competitors -- is a contentious topic in dynamic oligopoly theory, with
scholars debating practical relevance and the existence of predatory
equilibria. Although finite-horizon dynamic models have long been proposed to
capture the strategic intertemporal incentives of oligopolists, the existence
and form of equilibrium strategies in settings that allow for firm exit
(drop-outs following loss-making periods) have remained an open question. We
focus on the seminal dynamic oligopoly model by Selten (1965) that introduces
the subgame perfect equilibrium and analyzes smooth market sharing. Equilibrium
can be derived analytically in models that do not allow for dropouts, but not
in models that can lead to predatory pricing. In this paper, we leverage recent
advances in deep reinforcement learning to compute and verify equilibria in
finite-horizon dynamic oligopoly games. Our experiments reveal two key
findings: first, state-of-the-art deep reinforcement learning algorithms
reliably converge to equilibrium in both perfect- and imperfect-information
oligopoly models; second, when firms face asymmetric cost structures, the
resulting equilibria exhibit predatory pricing behavior. These results
demonstrate that predatory pricing can emerge as a rational equilibrium
strategy across a broad variety of model settings. By providing equilibrium
analysis of finite-horizon dynamic oligopoly models with drop-outs, our study
answers a decade-old question and offers new insights for competition
authorities and regulators.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [191] [Lorentzian Switching Dynamics in HZO-based FeMEMS Synapses for Neuromorphic Weight Storage](https://arxiv.org/abs/2510.27095)
*Shubham Jadhav,Kaustav Roy,Luis Amaro,Thejas Basavarajappa,Madhav Ramesh,Debdeep Jena,Huili,Xing,Amit Lal*

Main category: cs.ET

TL;DR: 我们演示了一种基于铁电MEMS（FeMEMS）的突触，它将模拟权重存储在释放的Hf$_{0.5}$Zr$_{0.5}$O$_2$（HZO）MEMS单件的压电系数 $d_{31,eff}$ 中。


<details>
  <summary>Details</summary>
Motivation: 传统的铁电突触将权重存储在剩余极化状态中，可能需要破坏性的电读取，这会限制器件的耐久性和可靠性。

Method: 通过低幅机械驱动读取权重，避免读取干扰，实现了超过7位的编程水平。机械开关分布函数遵循洛伦兹分布，并与偏置电压呈对数关系，与成核限制开关（NLS）一致。从机电数据中提取的中值阈值服从Merz型场时定律。

Result: 建立了机械权重和电气开关动力学之间的量化联系。

Conclusion: 这种机械读取的突触避免了去极化和电荷注入效应，提供了双极权重，并为高比特神经形态硬件提供了一条稳健、节能的途径。

Abstract: Neuromorphic computing demands synaptic elements that can store and update
weights with high precision while being read non-destructively. Conventional
ferroelectric synapses store weights in remnant polarization states and might
require destructive electrical readout, limiting endurance and reliability. We
demonstrate a ferroelectric MEMS (FeMEMS) based synapse in which analog weights
are stored in the piezoelectric coefficient $d_{31,eff}$ of a released
Hf$_{0.5}$Zr$_{0.5}$O$_2$ (HZO) MEMS unimorph. Partial switching of
ferroelectric domains modulates $d_{31,eff}$, and a low-amplitude mechanical
drive reads out the weight without read-disturb in the device yielding more
than 7-bit of programming levels. The mechanical switching distribution
function follows a Lorentzian distribution as a logarithmic function of partial
poling voltage ($V_p$) consistent with nucleation-limited switching (NLS), and
the median threshold extracted from electromechanical data obeys a Merz-type
field-time law with a dimensionless exponent $\alpha = 3.62$. These
relationships establish a quantitative link between mechanical weights and
electrical switching kinetics. This mechanically read synapse avoids
depolarization and charge-injection effects, provides bipolar weights (well
suited for excitatory and inhibitory synapses), directly reveals partial domain
populations, and offers a robust, energy-efficient route toward high-bit
neuromorphic hardware.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [192] [Internalizing Extensions in Lattices of Type Theories](https://arxiv.org/abs/2510.26839)
*Jonathan Chan*

Main category: cs.LO

TL;DR: 现有的扩展跟踪机制不属于类型系统，导致无法精确指定扩展依赖，限制了定义的重用和不兼容扩展的引用。本文探讨使用依赖可辨性演算（DCOI）作为一种依赖类型系统，通过分配依赖级别来跟踪扩展，从而解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩展跟踪机制不属于类型系统，无法精确指定扩展依赖，限制了定义的重用，并且不能引用使用不兼容扩展的定义，即使它们没有以不一致的方式使用。这阻碍了一个扩展的推理原则被用作元理论来推理不兼容扩展的属性。

Method: 本文将探索使用Liu等人提出的依赖可辨性演算（DCOI）进行扩展跟踪。DCOI是一个依赖类型系统，它在项和变量的类型旁边分配依赖级别。这些依赖级别形成一个描述哪些级别可以访问什么的格。通过将每个扩展集映射到一个依赖级别，格将描述扩展如何被允许交互。

Result: 本文使用DCOI来跟踪扩展，其中每个扩展集对应一个依赖级别，格描述了扩展的交互方式。

Conclusion: DCOI提供了一种在类型系统中精确跟踪扩展的方法，克服了现有外部机制的限制，提高了定义的重用性，并允许在不兼容的扩展之间进行更灵活的推理。

Abstract: Many proof assistants allow the use of features and axioms that increase
their expressive power. However, these extensions must be used with care, as
some combinations are known to lead to logical inconsistencies. Therefore,
proof assistants include mechanisms that track which extensions are used in a
proof development or module, ensuring that incompatible extensions are not used
simultaneously.
  Unfortunately, existing extension tracking mechanisms are external to the
type system. This means that we cannot specify precisely which extensions a
definition depends on. Having the ability to write more precise specifications
means we are not picking an overapproximation of the extensions needed, which
prevents reusing definitions in the presence of incompatible extensions.
Furthermore, we cannot refer to definitions that use incompatible extensions
even if they are never used in inconsistent ways. The reasoning principles of
one extension therefore cannot be used as a metatheory to reason about the
properties of an incompatible extension.
  In this report, I explore the use of the Dependent Calculus of
Indistinguishability (DCOI) by Liu et al. for extension tracking. DCOI is a
dependent type system with dependency tracking, where terms and variables are
assigned dependency levels alongside their types. These dependency levels form
a lattice that describes which levels are permitted to access what. To instead
track extensions, each set of extensions would correspond to a dependency
level, and the lattice would describe how extensions are permitted to interact.

</details>


### [193] [Cut-free Deductive System for Continuous Intuitionistic Logic](https://arxiv.org/abs/2510.26849)
*Guillaume Geoffroy*

Main category: cs.LO

TL;DR: 通过完整的代数语义引入和发展了命题连续直觉逻辑和命题连续仿射逻辑。


<details>
  <summary>Details</summary>
Motivation: 通过完整的代数语义引入和发展了命题连续直觉逻辑和命题连续仿射逻辑。

Method: 使用 AC-代数（整数交换剩余完全格 $\mathcal{L}$ 上的保持sup的函数代数 $USC(\mathcal{L})$）作为核心。通过 Macneille 完备化，证明了每个 Archimedean 模型都可以嵌入到某个 AC-代数中。

Result: $USC(\mathcal{L})$ 满足 $v \dot + v = 2v$ 当且仅当 $\mathcal{L}$ 是一个格。$USC(\mathcal{L})$ 中否定的对合性对应于 $\mathcal{L}$ 中的对合性。添加这些条件可以恢复经典连续逻辑。

Conclusion: 为仿射、直觉、对合、经典四种变体都提供了sequent风格的演绎系统，并证明了其完备性和割 वापरा可容性。最终实现了第一个具有割 वापरा可容性的经典连续逻辑的sequent风格表述。

Abstract: We introduce and develop propositional continuous intuitionistic logic and
propositional continuous affine logic via complete algebraic semantics. Our
approach centres on AC-algebras, which are algebras $USC(\mathcal{L})$ of
sup-preserving functions from $[0,1]$ to an integral commutative residuated
complete lattice $\mathcal{L}$ (in the intuitionistic case, $\mathcal{L}$ is a
locale). We give an algebraic axiomatisation of AC-algebras in the language of
continuous logic and prove, using the Macneille completion, that every
Archimedean model embeds into some AC-algebra. We also show that (i)
$USC(\mathcal{L})$ satisfies $v \dot + v = 2v$ exactly when $\mathcal{L}$ is a
locale, (ii) involutiveness of negation in $USC(\mathcal{L})$ corresponds to
that in $\mathcal{L} $, and that (iii) adding those conditions recovers
classical continuous logic. For each variant -affine, intuitionistic,
involutive, classical -we provide a sequent style deductive system and prove
completeness and cut admissibility. This yields the first sequent style
formulation of classical continuous logic enjoying cut admissibility.

</details>


### [194] [The Skolem Problem in rings of positive characteristic](https://arxiv.org/abs/2510.27603)
*Ruiwen Dong,Doron Shafrir*

Main category: cs.LO

TL;DR: Skolem Problem在正特征有限生成交换环中是可判定的。


<details>
  <summary>Details</summary>
Motivation: 确定线性递推序列是否包含零项。

Method: 基于Dong和Shafrir (2025)关于p^e-挠模上S-单位方程解集的研究，以及Karimov等人(2025)关于二的幂次乘法无关数上线性方程求解的研究。

Result: 给出了一个算法，可以确定一个有限生成的交换环（特征为T>0）上的线性递推序列是否包含零项。

Conclusion: 该结果意味着线性递推序列的零集在Derksen (2007)意义下是有限的p_i-正规集的有限并集。

Abstract: We show that the Skolem Problem is decidable in finitely generated
commutative rings of positive characteristic. More precisely, we show that
there exists an algorithm which, given a finite presentation of a (unitary)
commutative ring $\mathcal{R} = \mathbb{Z}_{/T}[X_1, \ldots, X_n]/I$ of
characteristic $T > 0$, and a linear recurrence sequence $(\gamma_n)_{n \in
\mathbb{N}} \in \mathcal{R}^{\mathbb{N}}$, determines whether $(\gamma_n)_{n
\in \mathbb{N}}$ contains a zero term. Our proof is based on two recent
results: Dong and Shafrir (2025) on the solution set of S-unit equations over
$p^e$-torsion modules, and Karimov, Luca, Nieuwveld, Ouaknine, and Worrell
(2025) on solving linear equations over powers of two multiplicatively
independent numbers. Our result implies, moreover, that the zero set of a
linear recurrence sequence over a ring of characteristic $T = p_1^{e_1} \cdots
p_k^{e_k}$ is effectively a finite union of $p_i$-normal sets in the sense of
Derksen (2007).

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [195] [Spiking Neural Networks: The Future of Brain-Inspired Computing](https://arxiv.org/abs/2510.27379)
*Sales G. Aribe Jr*

Main category: cs.NE

TL;DR: SNNs通过模拟大脑的脉冲事件实现高效、动态的计算，在准确性、能耗和延迟方面与ANNs相当，特别适合边缘AI等应用，但硬件和可扩展性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: SNNs作为一种受大脑启发的计算范式，为传统ANNs提供了一种更节能、更具时间动态性的替代方案。本文旨在全面分析SNN的设计模型、训练算法和多维度性能指标，以评估其在各种应用中的潜力。

Method: 本文深入研究了包括LIF在内的关键神经元模型，并考察了代理梯度下降、ANN到SNN转换和STDP等训练策略。性能评估涵盖了准确性、能耗、延迟、脉冲计数和收敛行为。

Result: 研究结果表明，采用代理梯度训练的SNNs在准确性上与ANNs相当（误差1-2%），收敛速度更快（20个epoch内），延迟低至10毫秒。转换SNNs性能也具有竞争力，但需要更高的脉冲计数和更长的模拟窗口。基于STDP的SNNs收敛较慢，但脉冲计数和能耗最低（低至5毫焦/推理），非常适合无监督和低功耗任务。

Conclusion: SNNs在能耗受限、延迟敏感和需要自适应能力的应用（如机器人、神经形态视觉和边缘AI）中显示出巨大潜力。尽管硬件标准化和可扩展训练仍面临挑战，但SNNs经过进一步优化，有望引领神经形态计算的下一个发展阶段。

Abstract: Spiking Neural Networks (SNNs) represent the latest generation of neural
computation, offering a brain-inspired alternative to conventional Artificial
Neural Networks (ANNs). Unlike ANNs, which depend on continuous-valued signals,
SNNs operate using distinct spike events, making them inherently more
energy-efficient and temporally dynamic. This study presents a comprehensive
analysis of SNN design models, training algorithms, and multi-dimensional
performance metrics, including accuracy, energy consumption, latency, spike
count, and convergence behavior. Key neuron models such as the Leaky
Integrate-and-Fire (LIF) and training strategies, including surrogate gradient
descent, ANN-to-SNN conversion, and Spike-Timing Dependent Plasticity (STDP),
are examined in depth. Results show that surrogate gradient-trained SNNs
closely approximate ANN accuracy (within 1-2%), with faster convergence by the
20th epoch and latency as low as 10 milliseconds. Converted SNNs also achieve
competitive performance but require higher spike counts and longer simulation
windows. STDP-based SNNs, though slower to converge, exhibit the lowest spike
counts and energy consumption (as low as 5 millijoules per inference), making
them optimal for unsupervised and low-power tasks. These findings reinforce the
suitability of SNNs for energy-constrained, latency-sensitive, and adaptive
applications such as robotics, neuromorphic vision, and edge AI systems. While
promising, challenges persist in hardware standardization and scalable
training. This study concludes that SNNs, with further refinement, are poised
to propel the next phase of neuromorphic computing.

</details>


### [196] [Exploiting heterogeneous delays for efficient computation in low-bit neural networks](https://arxiv.org/abs/2510.27434)
*Pengfei Sun,Jascha Achterberg,Zhe Su,Dan F. M. Goodman,Danyal Akarca*

Main category: cs.NE

TL;DR: 神经网络可以通过学习突触权重来学习，但这种方法忽略了大脑可以学习的其他神经参数，例如信号传输的延迟。该研究表明，这种延迟异构性可以被利用，以在具有时间复杂性的神经形态问题上实现最先进的性能，即使在权重精度极低的情况下也是如此。延迟异构性使得在压缩权重时仍能保持高精度，从而实现内存高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 大脑在信号传输中利用了异构的延迟，而不仅仅是依赖于突触权重。该研究旨在检验这种延迟异构性是否可以在神经形态计算中得到利用，以实现高效和高精度的解决方案，特别是在处理时间相关信息时。

Method: 通过训练能够同时修改权重和延迟的脉冲神经网络（SNN）来检验延迟异构性的假设。研究人员在不同精度的条件下进行了实验，并分析了延迟分布和时间常数对任务性能的影响。

Result: 研究发现，延迟异构性在具有时间复杂性的神经形态问题上能够实现最先进的性能，并且即使在权重精度非常低（1.58位三元精度）的情况下也能实现。此外，延迟异构性允许在权重被极度压缩的情况下，仍能保持高精度，从而实现比仅优化权重的网络更优越的内存效率。研究还表明，延迟和时间常数可以自适应地进行权衡，并且任务性能与任务相关的延迟分布有关，时间复杂性越高的任务需要越长的延迟。

Conclusion: 时间异构性是实现高效计算的重要原则，尤其是在处理与时间相关的信息时，这对于具身智能系统和神经形态硬件具有重要意义。通过利用延迟异构性，可以开发出在保持高精度的同时，又具有高内存效率的计算解决方案。

Abstract: Neural networks rely on learning synaptic weights. However, this overlooks
other neural parameters that can also be learned and may be utilized by the
brain. One such parameter is the delay: the brain exhibits complex temporal
dynamics with heterogeneous delays, where signals are transmitted
asynchronously between neurons. It has been theorized that this delay
heterogeneity, rather than a cost to be minimized, can be exploited in embodied
contexts where task-relevant information naturally sits contextually in the
time domain. We test this hypothesis by training spiking neural networks to
modify not only their weights but also their delays at different levels of
precision. We find that delay heterogeneity enables state-of-the-art
performance on temporally complex neuromorphic problems and can be achieved
even when weights are extremely imprecise (1.58-bit ternary precision: just
positive, negative, or absent). By enabling high performance with extremely
low-precision weights, delay heterogeneity allows memory-efficient solutions
that maintain state-of-the-art accuracy even when weights are compressed over
an order of magnitude more aggressively than typically studied weight-only
networks. We show how delays and time-constants adaptively trade-off, and
reveal through ablation that task performance depends on task-appropriate delay
distributions, with temporally-complex tasks requiring longer delays. Our
results suggest temporal heterogeneity is an important principle for efficient
computation, particularly when task-relevant information is temporal - as in
the physical world - with implications for embodied intelligent systems and
neuromorphic hardware.

</details>


### [197] [A Neural Architecture Search Method using Auxiliary Evaluation Metric based on ResNet Architecture](https://arxiv.org/abs/2505.01313)
*Shang Wang,Huanrong Tang,Jianquan Ouyang*

Main category: cs.NE

TL;DR: 提出了一种使用ResNet作为框架的神经架构搜索空间，并考虑了卷积、池化、全连接层参数以及残差网络的连通性作为搜索目标。除了识别精度，还使用验证集上的损失值作为次要优化目标。实验结果表明，该搜索空间和优化方法可以在MNIST、Fashion-MNIST和CIFAR100数据集上找到具有竞争力的网络架构。


<details>
  <summary>Details</summary>
Motivation: 提出了一种使用ResNet作为框架的神经架构搜索空间，并考虑了卷积、池化、全连接层参数以及残差网络的连通性作为搜索目标。除了识别精度，还使用验证集上的损失值作为次要优化目标。

Method: 设计了一个神经架构搜索空间，以ResNet为基础，包含卷积、池化、全连接层的参数以及残差网络连接性作为搜索变量。同时，将识别精度和验证集损失值作为联合优化目标。

Result: 在MNIST、Fashion-MNIST和CIFAR100数据集上，所提出的搜索空间和优化方法能够找到具有竞争力的网络架构。

Conclusion: 所提出的基于ResNet的神经架构搜索空间，结合多目标优化策略（包括识别精度和验证集损失），能够有效地发现性能优越的网络架构，并在多个基准数据集上得到验证。

Abstract: This paper proposes a neural architecture search space using ResNet as a
framework, with search objectives including parameters for convolution,
pooling, fully connected layers, and connectivity of the residual network. In
addition to recognition accuracy, this paper uses the loss value on the
validation set as a secondary objective for optimization. The experimental
results demonstrate that the search space of this paper together with the
optimisation approach can find competitive network architectures on the MNIST,
Fashion-MNIST and CIFAR100 datasets.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [198] [Inclusive and Exclusive Vertex Splitting into Specific Graph Classes: NP Hardness and Algorithms](https://arxiv.org/abs/2510.26938)
*Ajinkya Gaikwad,Hitendra Kumar,S. Padmapriya,Praneet Kumar Patra,Harsh Sanklecha,Soumen Maity*

Main category: cs.DS

TL;DR: 该研究提出了F-顶点分裂问题，旨在研究图G能否通过最多k次顶点分裂转化为目标图类F。研究了目标图类为星座图、环图、线性森林和二分图的情况，并分析了包含和排除两种顶点分裂变体。


<details>
  <summary>Details</summary>
Motivation: 研究F-顶点分裂问题，以确定图G通过有限次数顶点分裂后是否能属于目标图类F。

Method: 研究了将图G转化为星座图、环图、线性森林和二分图的F-顶点分裂问题，并分析了包含和排除两种顶点分裂变体。

Result: 当F为环图或线性森林时，F-顶点分裂问题具有多项式解法；当F为星座图或二分图时，F-顶点分裂问题为NP完全问题。

Conclusion: F-顶点分裂问题在不同目标图类下的计算复杂度不同，对于环图和线性森林是易于处理的，而对于星座图和二分图则是困难的。

Abstract: We study a family of graph modification problems called the F-Vertex
Splitting problem. Given a graph G, the task is to determine whether G can be
transformed into a graph G-prime belonging to a graph class F through a
sequence of at most k vertex splits. We investigate this problem for several
target graph classes, namely constellations, cycle graphs, linear forests, and
bipartite graphs. We analyze both inclusive and exclusive variants of vertex
splitting, as introduced by Abu-Khzam and collaborators (ISCO 2018). Our
results show that the F-Vertex Splitting problem is polynomial-time solvable
when F is a cycle graph or a linear forest, for both variants. In contrast,
when F is a constellation or a bipartite graph, the problem is NP-complete for
both variants.

</details>


### [199] [Green Bin Packing](https://arxiv.org/abs/2510.26968)
*Jackson Bibbens,Cooper Sigrist,Bo Sun,Shahin Kamali,Mohammad Hajiesmaili*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The online bin packing problem and its variants are regularly used to model
server allocation problems. Modern concerns surrounding sustainability and
overcommitment in cloud computing motivate bin packing models that capture
costs associated with highly utilized servers. In this work, we introduce the
green bin packing problem, an online variant with a linear cost $\beta$ for
filling above a fixed level $G$. For a given instance, the goal is to minimize
the sum of the number of opened bins and the linear cost. We show that when
$\beta G \le 1$, classical online bin packing algorithms such as FirstFit or
Harmonic perform well, and can achieve competitive ratios lower than in the
classic setting. However, when $\beta G > 1$, new algorithmic solutions can
improve both worst-case and typical performance. We introduce variants of
classic online bin packing algorithms and establish theoretical bounds, as well
as test their empirical performance.

</details>


### [200] [A Simple Deterministic Reduction From Gomory-Hu Tree to Maxflow and Expander Decomposition](https://arxiv.org/abs/2510.27330)
*Maximilian Probst Gutenberg,Weixuan Yuan*

Main category: cs.DS

TL;DR: 该论文提出了一种将Gomory-Hu树约简到多对数最大流计算的随机化方法，对于无权图，可实现近乎线性的时间和空间复杂度，并首次实现了精确到多对数因子内的约简。该方法也可扩展到加权图和超图，但复杂度有所增加。


<details>
  <summary>Details</summary>
Motivation: Gomory-Hu树在无权图上可以精确地保留所有节点对的最小割，但计算效率不高。现有方法在效率和紧凑性方面存在不足。因此，需要一种更简单、更高效的约简方法。

Method: 提出了一种随机化约简方法，将Gomory-Hu树的计算问题转化为最大流问题。该方法利用图的结构特性，通过构造辅助图来实现约简。

Result: 对于无权图，该约简方法能将问题规模和运行时间控制在$	ilde{O}(m)$（其中m为边数），实现了紧凑性（精确到多对数因子）。对于加权图，问题规模和运行时间增加到$	ilde{O}(n^2)$（其中n为节点数）。该方法还成功扩展到超图，实现了对超图Gomory-Hu树到超图最大流的紧凑性约简。

Conclusion: 该研究提出了一种新颖且高效的随机化约简方法，显著提高了Gomory-Hu树的计算效率，特别是在无权图上。该方法在理论上实现了紧凑性约简，并成功扩展到加权图和超图，为相关领域的研究提供了新的思路和工具。

Abstract: Given an undirected graph $G=(V,E,w)$, a Gomory-Hu tree $T$ (Gomory and Hu,
1961) is a tree on $V$ that preserves all-pairs mincuts of $G$ exactly.
  We present a simple and efficient randomized reduction from Gomory-Hu trees
to polylog maxflow computations. On unweighted graphs, our reduction reduces to
maxflow computations on graphs of total instance size $\tilde{O}(m)$ and the
algorithm requires only $\tilde{O}(m)$ additional time. Our reduction is the
first that is tight up to polylog factors. The reduction also seamlessly
extends to weighted graphs, however, instance sizes and runtime increase to
$\tilde{O}(n^2)$.
  Finally, we show how to extend our reduction to reduce Gomory-Hu trees for
unweighted hypergraphs to maxflow in hypergraphs. Again, our reduction is the
first that is tight up to polylog factors.

</details>


### [201] [Learned Static Function Data Structures](https://arxiv.org/abs/2510.27588)
*Stefan Hermann,Hans-Peter Lehmann,Giorgio Vinciguerra,Stefan Walzer*

Main category: cs.DS

TL;DR: 机器学习可用于构建更节省内存的静态函数数据结构。


<details>
  <summary>Details</summary>
Motivation: 需要一种比哈希表更节省内存的数据结构来关联静态键和值，并处理未知键的查询。

Method: 提出了一种称为“学习型静态函数”的方法，该方法使用机器学习模型为每个键预测值概率分布，然后使用此分布生成键特定的前缀码来编码值。此编码值存储在经典静态函数数据结构中。

Result: 与现有技术相比，学习型静态函数在真实数据上可节省高达一个数量级的空间，在合成数据上可节省高达三个数量级的空间。

Conclusion: 学习型静态函数通过利用键值之间的相关性，打破了零阶熵的限制，实现了显著的空间节省，同时仍支持点查询。

Abstract: We consider the task of constructing a data structure for associating a
static set of keys with values, while allowing arbitrary output values for
queries involving keys outside the set. Compared to hash tables, these
so-called static function data structures do not need to store the key set and
thus use significantly less memory. Several techniques are known, with
compressed static functions approaching the zero-order empirical entropy of the
value sequence. In this paper, we introduce learned static functions, which use
machine learning to capture correlations between keys and values. For each key,
a model predicts a probability distribution over the values, from which we
derive a key-specific prefix code to compactly encode the true value. The
resulting codeword is stored in a classic static function data structure. This
design allows learned static functions to break the zero-order entropy barrier
while still supporting point queries. Our experiments show substantial space
savings: up to one order of magnitude on real data, and up to three orders of
magnitude on synthetic data.

</details>


### [202] [Rateless Bloom Filters: Set Reconciliation for Divergent Replicas with Variable-Sized Elements](https://arxiv.org/abs/2510.27614)
*Pedro Silva Gomes,Carlos Baquero*

Main category: cs.DS

TL;DR: 该研究提出了一种名为“无速率布隆过滤器”（Rateless Bloom Filter, RBF）的混合协议，用于解决可变大小元素集合的同步问题，特别是在网络分区导致大量差异时，相比现有方法可减少高达20%的通信成本。


<details>
  <summary>Details</summary>
Motivation: 现有集合协调协议通常假设元素大小固定且差异数量（d）很小。当处理可变大小元素且差异数量较大时（如网络分区后），基于固定大小元素摘要的同步方法效率低下。

Method: 提出了一种两阶段混合协议，引入了初步的布隆过滤器（Bloom filter）步骤，并特别设计了一个名为“无速率布隆过滤器”（RBF）的动态过滤器，该过滤器能自适应地处理任意大小的对称差异，无需预先知道差异数量（d）即可确定最优布隆过滤器大小。

Result: 在可变大小元素集合的实验评估中，当 Jaccard 相似度低于 85% 时，所提出的 RBF-IBLT 混合协议相比现有技术，通信成本降低了高达 20% 以上。

Conclusion: RBF-IBLT 混合协议在处理可变大小元素集合的同步问题时，尤其是在存在大量差异的情况下，提供了一种比现有方法更优的通信效率解决方案。

Abstract: Set reconciliation protocols typically make two critical assumptions: they
are designed for fixed-sized elements and they are optimized for when the
difference cardinality, d, is very small. When adapting to variable-sized
elements, the current practice is to synchronize fixed-size element digests.
However, when the number of differences is considerable, such as after a
network partition, this approach can be inefficient. Our solution is a
two-stage hybrid protocol that introduces a preliminary Bloom filter step,
specifically designed for this regime. The novelty of this approach, however,
is in solving a core technical challenge: determining the optimal Bloom filter
size without knowing d. Our solution is the Rateless Bloom Filter (RBF), a
dynamic filter that naturally adapts to arbitrary symmetric differences,
closely matching the communication complexity of an optimally configured static
filter without requiring any prior parametrization. Our evaluation in sets of
variable-sized elements shows that for Jaccard indices below 85%, our RBF-IBLT
hybrid protocol reduces the total communication cost by up to over 20% compared
to the state-of-the-art.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [203] [FlowMesh: A Service Fabric for Composable LLM Workflows](https://arxiv.org/abs/2510.26913)
*Junyi Shen,Noppanat Wadlom,Lingfeng Zhou,Dequan Wang,Xu Miao,Lei Fang,Yao Lu*

Main category: cs.DC

TL;DR: AI部署正转向多阶段流水线而非单一LLM任务，FlowMesh提出一种多租户服务架构，通过细粒度算子分解、跨用户工作去重、请求聚合及全局调度优化，实现成本和能耗的大幅降低，并保持低延迟和高弹性。


<details>
  <summary>Details</summary>
Motivation: AI部署正从单一LLM任务转向包含数据转换、微调和智能体交互的流水线化模式，需要新的服务架构来优化此类工作负载。

Method: FlowMesh将工作流分解为细粒度的算子，记录其依赖关系，实现跨用户的工作去重和在同一硬件上的请求聚合。其全局控制平面维护一个就绪算子池，并使用单一效用函数进行批处理和工作者选择，以平衡吞吐量、成本和数据局部性。数据平面由无状态工作者和内容可寻址存储组成，支持弹性扩展、故障恢复和跨云/GPU市场的可移植性。

Result: FlowMesh相较于基线方案，实现了高达3.8倍的成本节约和2.0倍的能耗降低，同时保持了相似或更优的延迟表现，并在动态和易失效的环境下仍能高效运行。

Conclusion: FlowMesh是一种创新的多租户服务架构，能够有效优化AI流水线工作负载，显著降低成本和能耗，同时保证性能和弹性。

Abstract: AI deployment increasingly resembles a pipeline of data transformation,
fine-tuning, and agent interactions rather than a monolithic LLM job; recent
examples include RLHF/RLAIF training and agentic workflows. To cope with this
shift, we propose FlowMesh, a multi-tenant service fabric that executes and
optimizes these workloads as one shared service instead of isolated pipelines.
It decomposes workflows into fine-grained operators with recorded lineage,
enabling de-duplication of work across users and batching requests on the same
hardware while preserving per-workflow provenance. A global control plane
maintains a cluster-wide pool of ready operators and uses a single utility
function to pick both the batch and the worker, balancing throughput, cost, and
data locality on heterogeneous GPUs. The data plane is an elastic fleet of
stateless workers backed by a content-addressable store, enabling rapid,
automatic scale-out, safe retry after preemption, and portability across
managed clusters such as Kubernetes and geo-distributed GPU marketplaces such
as Vast.ai. Compared with baseline solutions, FlowMesh achieves up to 3.8x cost
reduction and 2.0x lower energy usage, provides a similar or better latency
profile, and remains efficient under dynamic and failure-prone conditions.

</details>


### [204] [A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration](https://arxiv.org/abs/2510.27039)
*Zhuo Zheng,Lingran Meng,Ziyu Lin*

Main category: cs.DC

TL;DR: 该论文提出了一种基于云的混合模型，结合了时空图神经网络（ST-GNN）和Transformer架构，用于交通流量预测，以解决传统模型在处理复杂的时空依赖性和外部因素方面的不足。


<details>
  <summary>Details</summary>
Motivation: 准确的交通流量预测对于智能交通系统（ITS）的发展至关重要，但传统模型难以有效捕捉大规模路网中的复杂时空依赖性，尤其是在天气、节假日和交通事故等外部因素的影响下。

Method: 提出了一种云端混合模型，该模型集成了时空图神经网络（ST-GNN）和Transformer架构。GNN用于建模路网的空间相关性，Transformer用于捕捉长期时间依赖性，并通过特征融合整合外部上下文特征。模型部署在云平台上以实现可扩展性和实时适应性。

Result: 该混合模型在数据集上的实验评估结果优于基线方法（LSTM、TCN、GCN、纯Transformer），RMSE仅为17.92，MAE仅为10.53。

Conclusion: 研究表明，所提出的混合GNN-Transformer方法为基于云的ITS应用提供了一种有效且可扩展的解决方案，在交通流量预测方面具有方法学上的进步，并在缓解拥堵方面具有实际意义。

Abstract: Accurate traffic flow forecasting is essential for the development of
intelligent transportation systems (ITS), supporting tasks such as traffic
signal optimization, congestion management, and route planning. Traditional
models often fail to effectively capture complex spatial-temporal dependencies
in large-scale road networks, especially under the influence of external
factors such as weather, holidays, and traffic accidents. To address this
challenge, this paper proposes a cloud-based hybrid model that integrates
Spatio-Temporal Graph Neural Networks (ST-GNN) with a Transformer architecture
for traffic flow prediction. The model leverages the strengths of GNNs in
modeling spatial correlations across road networks and the Transformers'
ability to capture long-term temporal dependencies. External contextual
features are incorporated via feature fusion to enhance predictive accuracy.
The proposed model is deployed on a cloud computing platform to achieve
scalability and real-time adaptability. Experimental evaluation of the dataset
shows that our model outperforms baseline methods (LSTM, TCN, GCN, pure
Transformer) with an RMSE of only 17.92 and a MAE of only 10.53. These findings
suggest that the hybrid GNN-Transformer approach provides an effective and
scalable solution for cloud-based ITS applications, offering methodological
advancements for traffic flow forecasting and practical implications for
congestion mitigation.

</details>


### [205] [Synergistic Tensor and Pipeline Parallelism](https://arxiv.org/abs/2510.27257)
*Mengshi Qi,Jiaxuan Peng,Jie Zhang,Juan Zhu,Yong Li,Huadong Ma*

Main category: cs.DC

TL;DR: 该研究提出了一种新的协同张量和流水线并行调度方法，通过解耦前向和后向传播并对其进行组合，以减少LLM和MLLM分布式训练中的通信和同步开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模型并行方法在分布式训练LLM和MLLM时，张量并行（TP）引入的通信开销和流水线并行（PP）产生的同步效率低下（如流水线气泡）的问题。

Method: 提出了一种协同的张量和流水线并行调度方法。该方法将PP的前向和后向传播解耦为细粒度的计算单元，然后将这些单元编织成复合计算序列，以减少TP相关的气泡。在此基础上，进一步优化PP调度以最小化PP气泡。

Result: 实验结果表明，与现有的调度方法相比，该方法将LLM的训练吞吐量提高了12%，MLLM的训练吞吐量提高了16%。

Conclusion: 所提出的协同张量和流水线并行调度方法能够有效减少TP通信开销和PP同步效率低下的问题，从而显著提高LLM和MLLM的分布式训练吞吐量。

Abstract: In the machine learning system, the hybrid model parallelism combining tensor
parallelism (TP) and pipeline parallelism (PP) has become the dominant solution
for distributed training of Large Language Models~(LLMs) and Multimodal LLMs
(MLLMs). However, TP introduces significant collective communication overheads,
while PP suffers from synchronization inefficiencies such as pipeline bubbles.
Existing works primarily address these challenges from isolated perspectives,
focusing either on overlapping TP communication or on flexible PP scheduling to
mitigate pipeline bubbles. In this paper, we propose a new synergistic tensor
and pipeline parallelism schedule that simultaneously reduces both types of
bubbles. Our proposed schedule decouples the forward and backward passes in PP
into fine-grained computation units, which are then braided to form a composite
computation sequence. This compositional structure enables near-complete
elimination of TP-related bubbles. Building upon this structure, we further
design the PP schedule to minimize PP bubbles. Experimental results demonstrate
that our approach improves training throughput by up to 12% for LLMs and 16%
for MLLMs compared to existing scheduling methods. Our source code is avaiable
at https://github.com/MICLAB-BUPT/STP.

</details>


### [206] [A Digital Twin-based Multi-Agent Reinforcement Learning Framework for Vehicle-to-Grid Coordination](https://arxiv.org/abs/2510.27289)
*Zhengchang Hua,Panagiotis Oikonomou,Karim Djemame,Nikos Tziritas,Georgios Theodoropoulos*

Main category: cs.DC

TL;DR: 本文提出了一种名为 DT-MADDPG 的混合算法，它结合了数字孪生（DT）和多智能体深度确定性策略梯度（MADDPG）算法，用于解决大规模分布式系统中（如电动汽车 V2G 网络）的协调优化问题。该算法通过一个去中心化的协同数字孪生网络，在不泄露个体隐私数据的情况下，利用增强的集中式评论员来学习全局最优控制策略，并在 V2G 仿真环境中验证了其在协调性能、数据隐私和架构去中心化方面的优势。


<details>
  <summary>Details</summary>
Motivation: 在 V2G 网络等大规模分布式系统中，对个体代理（如电动汽车）进行协调控制是一个重大挑战，传统方法需要收集敏感的原始数据，这会带来隐私问题。因此，需要一种能够实现全局最优控制策略，同时又能保护个体隐私的解决方案。

Method: 提出了一种名为 DT-MADDPG 的混合架构，该架构集成了多智能体强化学习框架（MADDPG）和协同数字孪生（DT）网络。其核心是一种模拟辅助学习算法，通过一个去中心化的协同 DT 网络，利用个体 DTs 共享的隐私保护数据构建一个预测性的全局模型来增强集中式评论员。

Result: 在模拟的 V2G 环境中，DT-MADDPG 算法在协调性能上达到了与标准 MADDPG 算法相当的水平，同时在数据隐私和架构去中心化方面表现出显著优势。

Conclusion: DT-MADDPG 算法为在复杂的、现实世界的网络物理系统中部署智能的、基于学习的协调提供了一个实用且鲁棒的框架，解决了大规模分布式系统协调中的隐私和去中心化挑战。

Abstract: The coordination of large-scale, decentralised systems, such as a fleet of
Electric Vehicles (EVs) in a Vehicle-to-Grid (V2G) network, presents a
significant challenge for modern control systems. While collaborative Digital
Twins have been proposed as a solution to manage such systems without
compromising the privacy of individual agents, deriving globally optimal
control policies from the high-level information they share remains an open
problem. This paper introduces Digital Twin Assisted Multi-Agent Deep
Deterministic Policy Gradient (DT-MADDPG) algorithm, a novel hybrid
architecture that integrates a multi-agent reinforcement learning framework
with a collaborative DT network. Our core contribution is a simulation-assisted
learning algorithm where the centralised critic is enhanced by a predictive
global model that is collaboratively built from the privacy-preserving data
shared by individual DTs. This approach removes the need for collecting
sensitive raw data at a centralised entity, a requirement of traditional
multi-agent learning algorithms. Experimental results in a simulated V2G
environment demonstrate that DT-MADDPG can achieve coordination performance
comparable to the standard MADDPG algorithm while offering significant
advantages in terms of data privacy and architectural decentralisation. This
work presents a practical and robust framework for deploying intelligent,
learning-based coordination in complex, real-world cyber-physical systems.

</details>


### [207] [Dynamic Service Scheduling and Resource Management in Energy-Harvesting Multi-access Edge Computing](https://arxiv.org/abs/2510.27317)
*Shuyi Chen,Panagiotis Oikonomou,Zhengchang Hua,Nikos Tziritas,Karim Djemame,Nan Zhang,Georgios Theodoropoulos*

Main category: cs.DC

TL;DR: 本文提出了一种在线策略，用于管理完全由能量收集供电的多接入边缘计算（MEC）系统，以解决能量收集的间歇性与动态用户需求之间的资源分配挑战。


<details>
  <summary>Details</summary>
Motivation: 为了实现可持续性，多接入边缘计算（MEC）系统越来越多地与可再生能源收集（EH）技术集成，但能量收集的间歇性与动态用户需求之间的平衡带来了重大的资源分配挑战。

Method: 提出了一种在线策略，用于管理完全由能量收集供电的MEC系统，该策略动态调度具有依赖性的计算任务，并通过服务器频率调整和模块迁移的实时决策来管理能耗。

Result: 实验结果表明，该算法在有效利用收集的能量同时保持低服务延迟方面是有效的。

Conclusion: 提出的在线策略能够有效地管理能量收集供电的MEC系统的资源，实现了能量利用和低延迟服务的平衡。

Abstract: Multi-access Edge Computing (MEC) delivers low-latency services by hosting
applications near end-users. To promote sustainability, these systems are
increasingly integrated with renewable Energy Harvesting (EH) technologies,
enabling operation where grid electricity is unavailable. However, balancing
the intermittent nature of harvested energy with dynamic user demand presents a
significant resource allocation challenge. This work proposes an online
strategy for an MEC system powered exclusively by EH to address this trade-off.
Our strategy dynamically schedules computational tasks with dependencies and
governs energy consumption through real-time decisions on server frequency
scaling and service module migration. Experiments using real-world datasets
demonstrate our algorithm's effectiveness in efficiently utilizing harvested
energy while maintaining low service latency.

</details>


### [208] [ML-Based Optimum Sub-system Size Heuristic for the GPU Implementation of the Tridiagonal Partition Method](https://arxiv.org/abs/2510.27351)
*Milena Veneva*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a machine learning (ML)-based heuristic for finding the
optimum sub-system size for the CUDA implementation of the parallel partition
algorithm. Computational experiments for different system of linear algebraic
equation (SLAE) sizes are conducted, and the optimum sub-system size for each
of them is found empirically. To estimate a model for the sub-system size, we
perform the k-nearest neighbors (kNN) classification method. Statistical
analysis of the results is done. By comparing the predicted values with the
actual data, the algorithm is deemed to be acceptably good. Next, the heuristic
is expanded to work for the recursive parallel partition algorithm as well. An
algorithm for determining the optimum sub-system size for each recursive step
is formulated. A kNN model for predicting the optimum number of recursive steps
for a particular SLAE size is built.

</details>


### [209] [RDMA Point-to-Point Communication for LLM Systems](https://arxiv.org/abs/2510.27656)
*Nandor Licker,Kevin Hu,Vladimir Zaytsev,Lequn Chen*

Main category: cs.DC

TL;DR: TransferEngine为大语言模型（LLM）系统提供了一个统一的、不依赖于特定网络接口控制器（NIC）的点对点通信接口，实现了跨硬件平台的可移植性，并在KVCache传输、RL权重更新和MoE调度/合并等生产系统中展示了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统模式（如分布式推理、MoE路由、异步强化微调）需要灵活的点对点通信，但现有实现通常绑定到特定NIC，限制了与推理引擎的集成和跨硬件平台的可移植性。

Method: 提出TransferEngine，它提供了一个统一的接口，屏蔽了不同NIC的功能差异。TransferEngine暴露了一侧写入（WriteImm）操作和ImmCounter原始元语，用于完成通知，无需网络传输的排序假设，并能透明地管理每GPU的多个NIC。

Result: 在NVIDIA ConnectX-7和AWS EFA上实现了400 Gbps的峰值吞吐量。通过三个生产系统展示了TransferEngine：1）用于分布式推理和动态扩展的KvCache传输；2）RL权重更新，对万亿参数模型实现1.3秒的更新时间；3）MoE调度/合并实现，在ConnectX-7上超过了DeepEP的解码延迟，并在EFA上实现了首次可行的低延迟。

Conclusion: TransferEngine的便携式点对点通信能够补充集体通信，同时避免了对特定硬件的依赖。

Abstract: Emerging Large Language Model (LLM) system patterns, such as disaggregated
inference, Mixture-of-Experts (MoE) routing, and asynchronous reinforcement
fine-tuning, require flexible point-to-point communication beyond simple
collectives. Existing implementations are locked to specific Network Interface
Controllers (NICs), hindering integration into inference engines and
portability across hardware providers. We present TransferEngine, which bridges
the functionality of common NICs to expose a uniform interface. TransferEngine
exposes one-sided WriteImm operations with a ImmCounter primitive for
completion notification, without ordering assumptions of network transport,
transparently managing multiple NICs per GPU. We demonstrate peak throughput of
400 Gbps on both NVIDIA ConnectX-7 and AWS Elastic Fabric Adapter (EFA). We
showcase TransferEngine through three production systems: (1) KvCache transfer
for disaggregated inference with dynamic scaling, (2) RL weight updates
achieving 1.3 seconds for trillion-parameter models, and (3) MoE
dispatch/combine implementation exceeding DeepEP decode latency on ConnectX-7,
with the first viable latencies on EFA. We demonstrate that our portable
point-to-point communication complements collectives while avoiding lock-in.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [210] [Higher-dimensional Fermiology in bulk moiré metals](https://arxiv.org/abs/2510.26880)
*Kevin P. Nuckolls,Nisarga Paul,Alan Chen,Filippo Gaggioli,Joshua P. Wakefield,Avi Auslender,Jules Gardener,Austin J. Akey,David Graf,Takehito Suzuki,David C. Bell,Liang Fu,Joseph G. Checkelsky*

Main category: cond-mat.mtrl-sci

TL;DR: 本文介绍了一种在热力学平衡状态下合成高迁移率魔尔超点阵材料的新方法，并展示了一种名为(Sr6TaS8)1+δ(TaS2)8的新型材料。


<details>
  <summary>Details</summary>
Motivation: 需要一种在热力学平衡状态下合成高迁移率魔尔超点阵材料的新方法。

Method: 合成了一种名为(Sr6TaS8)1+δ(TaS2)8的新型材料，该材料具有原子尺度的不匹配晶格，可形成魔尔超点阵。

Result: 通过高场量子振荡测量，研究了该材料的费米面，发现其具有非常复杂的费米面结构，并且可以通过改变魔尔超点阵结构来调控。

Conclusion: 这种新型的合成方法和材料为设计具有新颖物理现象的材料提供了新的途径，并可能应用于电子学领域。

Abstract: In the past decade, moir\'e materials have revolutionized how we engineer and
control quantum phases of matter. Among incommensurate materials, moir\'e
materials are aperiodic composite crystals whose long-wavelength moir\'e
superlattices enable tunable properties without chemically modifying their
layers. To date, nearly all reports of moir\'e materials have investigated van
der Waals heterostructures assembled far from thermodynamic equilibrium. Here
we introduce a conceptually new approach to synthesizing high-mobility moir\'e
materials in thermodynamic equilibrium. We report a new family of foliated
superlattice materials (Sr$_6$TaS$_8$)$_{1+\delta}$(TaS$_2$)$_8$ that are
exfoliatable van der Waals crystals with atomically incommensurate lattices.
Lattice mismatches between alternating layers generate moir\'e superlattices,
analogous to those of 2D moir\'e heterobilayers, that are coherent throughout
these crystals and are tunable through their synthesis conditions without
altering their chemical composition. High-field quantum oscillation
measurements map the complex Fermiology of these moir\'e metals, which can be
tuned via the moir\'e superlattice structure. We find that the Fermi surface of
the structurally simplest moir\'e metal is comprised of over 40 distinct
cross-sectional areas, the most observed in any material to our knowledge. This
can be naturally understood by postulating that bulk moir\'e materials can
encode electronic properties of higher-dimensional superspace crystals in ways
that parallel well-established crystallographic methods used for incommensurate
lattices. More broadly, our work demonstrates a scalable synthesis approach
potentially capable of producing moir\'e materials for electronics applications
and evidences a novel material design concept for accessing a broad range of
physical phenomena proposed in higher dimensions.

</details>


### [211] [MaterialsGalaxy: A Platform Fusing Experimental and Theoretical Data in Condensed Matter Physics](https://arxiv.org/abs/2510.26886)
*Tiannian Zhu,Zhong Fang,Quansheng Wu,Hongming Weng*

Main category: cond-mat.mtrl-sci

TL;DR: MaterialsGalaxy是一个整合了实验和计算数据的材料科学平台，通过结构相似性驱动的数据融合机制，利用AI工具加速新材料的发现。


<details>
  <summary>Details</summary>
Motivation: 连接孤立的、多来源的、异构的材料科学数据，以加速材料发现。

Method: 开发了一个名为MaterialsGalaxy的平台，该平台利用结构相似性驱动的数据融合机制，整合实验和计算数据，并集成AI工具（如LLM、生成模型和机器学习模型）来提取知识、预测结构和预测性质。

Result: 成功整合了不同的数据源，发现了隐藏的关联，并指导了新材料的设计。

Conclusion: MaterialsGalaxy通过连接实验和理论的鸿沟，为数据驱动的材料研究提供了新范例，并加速了先进材料的发现。

Abstract: Modern materials science generates vast and diverse datasets from both
experiments and computations, yet these multi-source, heterogeneous data often
remain disconnected in isolated "silos". Here, we introduce MaterialsGalaxy, a
comprehensive platform that deeply fuses experimental and theoretical data in
condensed matter physics. Its core innovation is a structure similarity-driven
data fusion mechanism that quantitatively links cross-modal records - spanning
diffraction, crystal growth, computations, and literature - based on their
underlying atomic structures. The platform integrates artificial intelligence
(AI) tools, including large language models (LLMs) for knowledge extraction,
generative models for crystal structure prediction, and machine learning
property predictors, to enhance data interpretation and accelerate materials
discovery. We demonstrate that MaterialsGalaxy effectively integrates these
disparate data sources, uncovering hidden correlations and guiding the design
of novel materials. By bridging the long-standing gap between experiment and
theory, MaterialsGalaxy provides a new paradigm for data-driven materials
research and accelerates the discovery of advanced materials.

</details>


### [212] [Generative diffusion modeling protocols for improving the Kikuchi pattern indexing in electron back-scatter diffraction](https://arxiv.org/abs/2510.26907)
*Meghraj Prajapat,Alankar Alankar*

Main category: cond-mat.mtrl-sci

TL;DR: 生成式机器学习模型可用于优化高扫描速率下的EBSD数据采集，提高晶体取向测定的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统EBSD数据处理方法（如Hough变换和字典检索）在高扫描速率下，由于曝光时间缩短导致CCD相机灵敏度下降，信噪比降低，晶体取向测定精度不高。

Method: 研究目标是开发用于Kikuchi花样后处理或实时处理的生成式机器学习模型，以恢复高扫描速率下获得的EBSD花样。通过比较不同生成式模型在提高短曝光时间（高扫描速率）下捕获的花样质量方面的性能。

Result: 生成式模型能够恢复短曝光时间下捕获的EBSD花样，提高其质量，从而为准确测定晶体取向提供可靠的索引结果。与典型机器学习方法相比，该方法对数据的需求量不大。

Conclusion: 研究提出了一种新颖的基于生成式机器学习的方法，用于解决高扫描速率下EBSD数据质量下降的问题，并取得了良好的效果，且数据需求量少。

Abstract: Electron back-scatter diffraction (EBSD) has traditionally relied upon
methods such as the Hough transform and dictionary Indexing to interpret
diffraction patterns and extract crystallographic orientation. However, these
methods encounter significant limitations, particularly when operating at high
scanning speeds, where the exposure time per pattern is decreased beyond the
operating sensitivity of CCD camera. Hence the signal to noise ratio decreases
for the observed pattern which makes the pattern noisy, leading to reduced
indexing accuracy. This research work aims to develop generative machine
learning models for the post-processing or on-the-fly processing of Kikuchi
patterns which are capable of restoring noisy EBSD patterns obtained at high
scan speeds. These restored patterns can be used for the determination of
crystal orientations to provide reliable indexing results. We compare the
performance of such generative models in enhancing the quality of patterns
captured at short exposure times (high scan speeds). An interesting observation
is that the methodology is not data-hungry as typical machine learning methods.

</details>


### [213] [Atomistic Simulations of H-Cu Vacancy Cosegregation and H Diffusion in Cu Grain Boundary](https://arxiv.org/abs/2510.26991)
*Vasileios Fotopoulos,Alexander L. Shluger*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了氢在铜中的原子尺度扩散机制，并阐述了其在晶界处与空位相互作用


<details>
  <summary>Details</summary>
Motivation: 氢脆是铜应用中的关键挑战，但其机理尚不明确。

Method: 结合密度泛函理论（DFT）和键序势（BOP）模拟，研究氢在铜晶界处的吸附/掺入和扩散路径，以及与空位的相互作用。

Result: 研究发现，氢优先吸附在铜的表面和晶界等低配位区域，尤其是在空位存在的情况下。氢的存在会增强铜空位的偏析，形成稳定的H-V_Cu复合物，结合能高达-0.8 eV。此外，氢在晶界处的迁移势垒仅为0.2 eV，远低于体相铜中的0.42 eV。

Conclusion: 研究提出了一个将H2暴露与晶界处H累积联系起来的原子尺度机制，为理解氢诱导退化的早期阶段提供了信息。

Abstract: Hydrogen embrittlement remains a critical challenge in structural and
electronic applications of copper (Cu) but its mechanism is still not fully
understood. In this study, we combine density functional theory (DFT) and
bond-order potential (BOP) simulations to determine the atomistic pathways for
hydrogen adsorption/incorporation and fast interfacial diffusion at Cu grain
boundaries (GBs), including its interaction with vacancies. Undercoordinated
regions, such as surfaces and GBs, serve as preferential
adsorption/incorporation sites for atomic hydrogen, especially in the presence
of Cu vacancies. The presence of hydrogen in GB further enhances the
segregation of Cu vacancies, leading to the formation of stable
H-$V_\mathrm{Cu}$ complexes with cosegregation energy gains of up to $-0.8$ eV.
Furthermore, our simulations reveal that the migration barriers for hydrogen
within the GB networks are as low as $0.2$ eV and significantly lower than in
bulk Cu ($0.42$ eV). The results presented in this paper suggest an atomistic
mechanism that links $H_2$ exposure to H accumulation in GBs, providing
information on the early stages of hydrogen-induced degradation.

</details>


### [214] [Stability and Dynamics of Sn-based Halide Perovskites: Insights from MACE-MP-0 and Molecular Dynamics Simulations](https://arxiv.org/abs/2510.26998)
*Thiago Puccinelli,Lucas Martin Farigliano,Gustavo Martini Dalpian*

Main category: cond-mat.mtrl-sci

TL;DR: MACE-MP-0模型在模拟锡基卤化物钙钛矿（CsSnBr3和Cs2SnBr6）在100 K至500 K范围内的温度相关行为方面，能够定性地再现关键的热学和结构特征，但未能捕捉到CsSnBr3中间的四方相。


<details>
  <summary>Details</summary>
Motivation: 评估基础机器学习模型MACE-MP-0在预测锡基卤化物钙钛矿（CsSnBr3和Cs2SnBr6）在有限温度下的结构稳定性和相行为方面的预测能力。

Method: 在NpT系综下使用MACE-MP-0模型进行分子动力学模拟，温度范围为100 K至500 K，分析了焓、比热、径向分布函数、平移有序度、键角分布和振动光谱等热力学和结构描述符。

Result: MACE-MP-0模型表明CsSnBr3在低温下会发生斜方晶系到立方晶系的相变，这可以通过晶格参数的变化以及焓和比热的细微异常得到证明，但未能捕捉到实验观察到的中间四方相。Cs2SnBr6在整个温度范围内保持立方结构，并且具有更刚性的八面体框架。

Conclusion: MACE-MP-0模型可以定性地再现锡基卤化物钙钛矿的关键热学和结构特征，可作为研究新材料的第一步。若需捕捉更细微的相行为，则应考虑使用密度泛函理论数据进行系统特定的微调。

Abstract: Tin-based halide perovskites have emerged as promising lead-free alternatives
for optoelectronic applications, yet their structural stability and phase
behavior at finite temperatures remain challenging to predict. Here, we assess
the predictive capabilities of the foundational machine learning model
MACE-MP-0 - trained on a broad chemical space and applied without
system-specific fine-tuning - for the temperature-dependent behavior of CsSnBr3
and Cs2SnBr6. Molecular Dynamics simulations in the NpT ensemble were performed
from 100 K to 500 K, and thermodynamic and structural descriptors including
enthalpy, specific heat, radial distribution functions, translational order,
bond angle distributions, and vibrational spectra were analyzed. Our results
show that CsSnBr3 undergoes a low-temperature orthorhombic-to-cubic phase
transition, evidenced by both the evolution of lattice parameters and subtle
anomalies in enthalpy and specific heat, although the experimentally observed
intermediate tetragonal phase is not captured. In contrast, Cs2SnBr6 remains
cubic and maintains a more rigid octahedral framework across the entire
temperature range. Overall, MACE-MP-0 qualitatively reproduces key thermal and
structural features of these materials, highlighting its usefulness as a first
step for studying new materials. For cases where capturing more subtle phase
behavior is required, system-specific fine-tuning with Density Functional
Theory data should be considered.

</details>


### [215] [High-performance thermochromic multilayer coatings with W-doped VO2 nanoparticles dispersed in SiO2 matrix prepared on glass at a low temperature](https://arxiv.org/abs/2510.27370)
*Jaroslav Vlcek,Michal Kaufman,Elnaz M. Nia,Jiri Houska,Jiechao Jiang,Radomir Cerstvy,Stanislav Haviar,Efstathios I. Meletis*

Main category: cond-mat.mtrl-sci

TL;DR: VO2基涂层可在350°C基板温度下通过三步法（磁控溅射沉积SiO2薄膜和V-W薄膜，然后进行退火）制备，无需开真空室。


<details>
  <summary>Details</summary>
Motivation: 为了满足建筑玻璃大规模应用的要求，开发一种在低温下制备高性能温变VO2基涂层的方法。

Method: 采用三步法，包括在标准玻璃上低温（350°C）磁控溅射沉积SiO2薄膜和V-W薄膜，然后在真空室中进行退火，形成四层W掺杂VO2纳米颗粒分散在SiO2基质中的结构。

Result: 制备的涂层在33°C下表现出相变，在低温和高温下的积分光透射率分别为65.4%和60.1%，太阳能透射率调制为15.3%。

Conclusion: 该方法制备的VO2基涂层具有优异的综合性能（低制备温度、良好的光学性能和相变特性），满足了建筑玻璃大规模应用的要求，且此类性能组合尚未有报道。

Abstract: We report a high-performance thermochromic VO2-based coating prepared by
using a three-step process, consisting of magnetron sputter depositions of SiO2
films and V-W films and their postannealing, on standard glass at a low
substrate temperature of 350 {\deg}C without opening the vacuum chamber to
atmosphere. It is formed by four layers of W-doped VO2 nanoparticles dispersed
in SiO2 matrix. The coating exhibits a transition temperature of 33 {\deg}C
with an integral luminous transmittance of 65.4% (low-temperature state) and
60.1% (high-temperature state), and a modulation of the solar energy
transmittance of 15.3%. Such a combination of properties, together with the low
temperature during preparation, fulfill the requirements for large-scale
implementation on building glass and have not been reported yet.

</details>


### [216] [Defect Engineered Hexagonal-Boron Nitride Enables Ionic Conduction for Lithium Metal Batteries](https://arxiv.org/abs/2510.27021)
*Yecun Wu,Yan-Kai Tzeng,Hao Chen,Kun Xu,Gangbin Yan,Takashi Taniguchi,Kenji Watanabe,Arun Majumdar,Yi Cui,Steven Chu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过氩离子辐照缺陷工程策略，将六方氮化硼（h-BN）转化为高效锂离子导体，解决了锂金属负极枝晶生长和界面不稳定性问题，显著提升了锂金属电池和锂硫电池的性能。


<details>
  <summary>Details</summary>
Motivation: 锂金属负极在枝晶生长和界面不稳定性方面存在挑战，限制了其在实际应用中的推广。

Method: 采用化学气相沉积（CVD）生长的h-BN薄膜和实验室规模的单晶h-BN薄片，通过氩离子注入诱导缺陷，将h-BN转化为离子导体，同时保持其电绝缘性。

Result: 缺陷工程化的h-BN表现出优异的锂离子传导性能，显著提高了锂金属负极的稳定性，实现了1000次循环以上超过99.5%的库伦效率，且无枝晶生长。在锂硫电池中，该策略有效抑制了多硫化物的穿梭效应，在300次循环后仍保持超过97%的比容量。

Conclusion: 所提出的缺陷工程策略为构建高离子传导性和优异电绝缘性的下一代锂金属电池界面提供了一条稳健且可扩展的途径。

Abstract: The practical implementation of lithium-metal anodes has been hindered by
uncontrollable dendrite formation and interfacial instability. This study
presents a defect-engineering approach of a chemically stable and electrically
insulating interfacial layer of hexagonal boron nitride (h-BN) that markedly
enhances ionic conductivity through argon ion irradiation. Initially, the
electrochemical performance from commercially available, large-area chemical
vapor deposition (CVD)-grown h-BN films with industrial-scale argon ion
implantation motivated our subsequent detailed investigations using lab-scale
exfoliated single-crystal h-BN flakes. Integration of these exfoliated flakes
into a hybrid microfluidic-microelectronic chip provided direct evidence that
controlled vacancy defects transform h-BN into an efficient lithium-ion
conductor while preserving its intrinsic electrical insulation. Experimental
validation confirmed improved lithium-metal anode stability, achieving
dendrite-free cycling with Li plating/stripping Coulombic efficiencies
exceeding 99.5% about 1000 cycles. Further assemble of irradiated h-BN in
lithium-sulfur batteries effectively mitigates the polysulfide shuttle effect,
sustaining over 97% specific capacity around 300 cycles. These results
establish a robust, scalable interface-engineering route for next-generation
lithium-metal batteries that combine high ionic transport with excellent
electrical insulation.

</details>


### [217] [Crossover between intrinsic and temperature-assisted regimes in spin-orbit torque switching of antiferromagnetic order](https://arxiv.org/abs/2510.27138)
*Takumi Matsuo,Tomoya Higo,Daisuke Nishio-Hamane,Takuya Matsuda,Ryota Uesugi,Hanshen Tsai,Kouta Kondou,Shinji Miwa,Yoshichika Otani,Satoru Nakatsuji*

Main category: cond-mat.mtrl-sci

TL;DR: 通过调控磁层厚度，观察到手性反铁磁Mn3Sn的切换行为存在交叉，厚器件中焦耳热干扰切换，而薄器件则表现出由自旋轨道矩驱动的切换机制，从而避免了发热效应，实现了低于温度辅助机制所需脉冲宽度的超快切换，为设计超快时间尺度的反铁磁存储器奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 研究反铁磁材料作为下一代记忆体候选物的超快动力学特性，特别是电气化双向切换反铁磁状态的潜力，并解决焦耳热效应限制切换时间尺度的问题。

Method: 通过调控磁层厚度，在手性反铁磁Mn3Sn中观察切换行为的交叉现象，区分焦耳热效应和自旋轨道矩效应的影响。

Result: 在较厚的器件中，观察到焦耳热效应干扰了切换过程；在较薄的器件中，发现了由自旋轨道矩驱动的切换机制，该机制避免了发热效应，并允许使用比温度辅助机制更短的脉冲进行切换，且读出信号衰减较小。

Conclusion: 通过调控磁层厚度，可以实现由自旋轨道矩驱动的超快切换，这与反铁磁材料的皮秒级自旋动力学预期一致，为设计能在超快时间尺度下运行的反铁磁存储器奠定了基础。

Abstract: Intensive studies have been made on antiferromagnets as candidate materials
for next generation memory bits due to their ultrafast dynamics reaching
picosecond time scales. Recent demonstrations of electrical bidirectional
switching of antiferromagnetic states have attracted significant attention.
However, under the presence of significant Joule heating that destabilizes the
magnetic order, the timescales associated with the switching can be limited to
nanoseconds or longer. Here, we present the observation of a crossover in the
switching behavior of the chiral antiferromagnet Mn3Sn by tuning the magnetic
layer thickness. While Joule heating interferes with switching in thicker
devices, we find clear signatures of an intrinsic spin-orbit torque mechanism
as the thickness is reduced, avoiding the heating effect. The suppression of
heating enables switching without significant attenuation of the readout signal
using pulses shorter than those required by temperature-assisted mechanisms.
The crossover into the spin-orbit torque switching behavior clarifies the
potential for achieving ultrafast switching as expected from the picosecond
spin dynamics of antiferromagnets. Our results lay the groundwork for designing
antiferromagnetic memory devices that can operate at ultrafast timescales.

</details>


### [218] [High thermal conductivity of rutile-GeO$_2$ films grown by MOCVD: $52.9~\mathrm{W\,m^{-1}\,K^{-1}}$](https://arxiv.org/abs/2510.27228)
*Imteaz Rahaman,Michael E. Liao,Ziqi Wang,Eugene Y. Kwon,Rui Sun,Botong Li,Hunter D. Ellis,Bobby G. Duersch,Dali Sun,Jun Liu,Mark S. Goorsky,Michael A. Scarpulla,Kai Fu*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Rutile germanium dioxide (r-GeO2) has recently emerged as a promising
ultrawide-bandgap (UWBG) semiconductor owing to its wide bandgap (~4.4-5.1 eV),
ambipolar doping potential, and high theoretical thermal conductivity. However,
experimental data on the thermal conductivity of r-GeO2 epitaxial layers have
not been reported, primarily due to challenges in phase control and surface
roughness. Here, we report a high thermal conductivity of 52.9 +/- 6.6 W m^-1
K^-1 for high-quality (002) r-GeO2 films grown by metal-organic chemical vapor
deposition (MOCVD) and characterized using time-domain thermoreflectance
(TDTR). The phase control was achieved through a seed-driven stepwise
crystallization (SDSC) approach, and the surface roughness was significantly
reduced from 76 nm to 16 nm (locally as low as 1 A) via chemical mechanical
polishing (CMP). These results highlight the promise of r-GeO2 as a UWBG oxide
platform for power electronics applications.

</details>


### [219] [First-principles design of excitonic insulators: A review](https://arxiv.org/abs/2510.27231)
*H. W. Qu,H. T. Liu,Y. C. Li*

Main category: cond-mat.mtrl-sci

TL;DR: 电子绝缘体（EI）是一种理论上存在超过60年的现象，但尚未被证实。它是一种纯粹的量子现象，涉及量子力学中激子的自发产生和量子统计中激子的自发凝聚。在这种状态下，激子代表基态，而不是传统的激发态。因此，候选材料的稀缺是至今未能公认EI的关键因素。


<details>
  <summary>Details</summary>
Motivation: 本文旨在回顾电子绝缘体（EI）的理论提出、当前研究现状以及面临的主要挑战。重点介绍基于第一性原理Bethe-Salpeter方案在EI材料发现和设计方面的最新进展，特别是暗激子规则指导的材料筛选方法。

Method: 文章回顾了EI的起源，讨论了当前的研究进展和挑战。重点介绍了利用第一性原理Bethe-Salpeter方案，结合暗激子规则指导的材料筛选方法，在直接带隙和宽带隙半导体中实现激子不稳定性，并发现了半-EI和自旋三重态EI等新型量子物态。

Result: 基于第一性原理Bethe-Salpeter方案和暗激子规则指导的材料筛选方法，为实现直接带隙和宽带隙半导体中的激子不稳定性开辟了新途径，并发现了半-EI和自旋三重态EI等新型量子物态。

Conclusion: 本文展望了未来计算和理论研究的可能途径，以期实现首个公认的EI。

Abstract: The excitonic insulator (EI) is a more than 60-year-old theoretical proposal
that yet remains elusive. It is a purely quantum phenomenon involving the
spontaneous generation of excitons in quantum mechanics and the spontaneous
condensation of excitons in quantum statistics. At this point, the excitons
represent the ground state rather than the conventional excited state. Thus,
the scarcity of candidate materials is a key factor contributing to the lack of
recognized EI to date. In this review, we begin with the birth of EI,
presenting the current state of the field and the main challenges it faces. We
then focus on recent advances in the discovery and design of EIs based on the
first-principles Bethe-Salpeter scheme, in particular the dark-exciton rule
guided screening of materials. It not only opens up new avenues for realizing
excitonic instability in direct-gap and wide-gap semiconductors, but also leads
to the discovery of novel quantum states of matter such as half-EIs and
spin-triplet EIs. Finally, we will look ahead to possible research pathways
leading to the first recognized EI, both computationally and theoretically.

</details>


### [220] [The plastic flow of polycrystalline solids](https://arxiv.org/abs/2510.27242)
*Miguel Lagos*

Main category: cond-mat.mtrl-sci

TL;DR: 多晶固体被建模为填充整个固体空间的随机不规则多面体集合，没有空隙或缺陷。相邻晶粒的滑动速度与公用平面上的局部剪切应力成正比，前提是应力超过阈值。为了保持物质连续性而产生的连续晶粒形状调整相关的局部力被认为较弱。该模型可以进行解析求解，并在超临界条件下产生塑性和超塑性两种变形模式。本文主要讨论了从屈服到断裂的塑性变形模式。将其应用于镍基高温合金和不锈钢，与实验结果吻合。


<details>
  <summary>Details</summary>
Motivation: 与过去一个世纪以来解释塑性变形和断裂主要依赖于预先存在的裂纹和孔洞的模型不同，本文提出的模型提供了一种新的解释。文章旨在通过一个基于多面体模型和晶粒间滑动的理论，来更好地解释和预测材料的塑性变形和断裂行为。

Method: 将多晶固体建模为填充空间的随机不规则多面体集合。相邻晶粒间的相对滑动速度与局部剪切应力成正比（超过阈值）。忽略了保持物质连续性所需的局部力。对模型进行了解析求解，得到了塑性和超塑性两种变形模式，并重点研究了塑性模式。

Result: 模型在超临界条件下产生了塑性和超塑性两种变形模式，并对塑性模式（从屈服到断裂）进行了详细分析。将该模型应用于镍基高温合金和不锈钢，结果与实验数据进行了对比，显示出令人印象深刻的一致性。

Conclusion: 本文提出的基于多面体和晶粒间滑动的新模型，在解释塑性变形和断裂方面取得了比依赖预先存在裂纹和孔洞的传统模型更好的结果，并得到了实验的验证。

Abstract: A polycrystalline solid is modelled as an ensemble of random irregular
polyhedra filling the entire space occupied by the solid body, leaving no voids
or flaws between them. Adjacent grains can slide with a relative velocity
proportional to the local shear stress resolved in the plane common to the two
sliding grains, provided it exceeds a threshold. The local forces associated to
the continuous grain shape accommodation for preserving matter continuity are
assumed much weaker. The model can be solved analytically and for overcritical
conditions gives two regimes of deformation, plastic and superplastic. The
plastic regime, from yield to fracture, is dealt with. Applications to nickel
superalloys and stainless steels give impressive agreement with experiment.
Most work of the last century relies on postulating pre--existent cracks and
voids to explain plastic deformation and fracture. The present model gives much
better results.

</details>


### [221] [Influence of Hydrogen-Incorporation on the Bulk Electronic Structure and Chemical Bonding in Palladium](https://arxiv.org/abs/2510.27294)
*L. J. Bannenberg,F. García-Martínez,P. Lömker,R. Y. Engel,C. Schlueter,H. Schreuders,A. Navarathna,L. E. Ratcliff,A. Regoutz*

Main category: cond-mat.mtrl-sci

TL;DR: 这项研究首次使用原位X射线光电子能谱技术研究了钯薄膜中氢的吸收，提供了真实的宏观化学和电子信息，并解决了长期存在的关于PdH的疑问。


<details>
  <summary>Details</summary>
Motivation: 由于传统的表面敏感方法难以深入研究，钯氢化物（一种研究金属-氢相互作用的模型系统）的宏观电子结构一直难以直接探测。

Method: 本研究采用原位环境压力硬X射线光电子能谱（AP-HAXPES）技术，结合原位X射线衍射和中子反射计技术，并与密度泛函理论（DFT）进行比较，研究了氢在钯薄膜中的吸收过程。

Result: 该研究直接获得了钯薄膜在不同氢气压力下的宏观化学和电子信息，揭示了氢含量、晶格膨胀和电子结构变化之间的直接联系，并阐明了氢化学计量和位点占有如何控制费米能级附近的占据态密度。

Conclusion: 本研究首次展示了AP-HAXPES技术在研究真实条件下金属氢化物的宏观电子结构方面的强大潜力，并为理解PdH的性质提供了新的见解。

Abstract: Palladium hydride is a model system for studying metal-hydrogen interactions.
Yet, its bulk electronic structure has proven difficult to directly probe, with
most studies to date limited to surface-sensitive photoelectron spectroscopy
approaches. This work reports the first in-situ ambient-pressure hard X-ray
photoelectron spectroscopy (AP-HAXPES) study of hydrogen incorporation in Pd
thin films, providing direct access to bulk chemical and electronic information
at elevated hydrogen pressures. Structural characterisation by in-situ X-ray
diffraction and neutron reflectometry under comparable conditions establishes a
direct correlation between hydrogen loading, lattice expansion, and electronic
modifications. Comparison with density functional theory (DFT) reveals how
hydrogen stoichiometry and site occupancy govern the density of occupied states
near the Fermi level. These results resolve long-standing questions regarding
PdH and establish AP-HAXPES as a powerful tool for probing the bulk electronic
structure of metal hydrides under realistic conditions.

</details>


### [222] [Lattice dynamics in chiral tellurium by linear and circularly polarized Raman spectroscopy: crystal orientation and handedness](https://arxiv.org/abs/2510.27341)
*Davide Spirito,Sergio Marras,Beatriz Martín-García*

Main category: cond-mat.mtrl-sci

TL;DR: Trigonal tellurium (Te) crystals exhibit unique properties due to their chiral structure. This paper uses angle-dependent Raman spectroscopy to determine crystallographic orientation and handedness by analyzing mode intensities and shifts. The findings highlight the importance of crystal orientation for studying Te's properties and fabricating devices, offering insights for other chiral materials.


<details>
  <summary>Details</summary>
Motivation: The unique transport and optical properties of trigonal tellurium (Te), such as electrical magneto-chiral anisotropy, spin polarization, and bulk photovoltaic effect, are driven by its anisotropic and chiral crystal structure. Therefore, determining its crystallographic orientation and handedness is crucial for studying these properties.

Method: Angle-dependent linearly polarized Raman spectroscopy and symmetry rules were used to explore the structural dynamics of Te bulk crystals in three different crystallographic orientations. Circularly polarized Raman measurements were also employed to observe phonon mode shifts under different configurations and crystal orientations. Chemical etching was used to unequivocally determine the handedness of the crystals.

Result: The angle-dependent intensity of Raman modes allowed for the determination of the arrangement of helical chains and the distinction between crystallographic planes parallel and perpendicular to the chain axis. A shift in two phonon modes was observed only in the (0 0 1) plane, with the shift's sign depending on the crystal's handedness.

Conclusion: The study underscores the significance of selecting the appropriate orientation and crystallographic plane when investigating the transport and optical properties of Te. The findings provide insights into the crystal structure and symmetry of other anisotropic and chiral materials, paving the way for selecting suitable crystal orientations in device fabrication.

Abstract: Trigonal tellurium (Te) has attracted researchers' attention due to its
transport and optical properties, which include electrical magneto-chiral
anisotropy, spin polarization and bulk photovoltaic effect. It is the
anisotropic and chiral crystal structure of Te that drive these properties, so
the determination of its crystallographic orientation and handedness is key to
their study. Here we explore the structural dynamics of Te bulk crystals by
angle-dependent linearly polarized Raman spectroscopy and symmetry rules in
three different crystallographic orientations. The angle-dependent intensity of
the modes allows us to determine the arrangement of the helical chains and
distinguish between crystallographic planes parallel and perpendicular to the
chain axis. Furthermore, under different configurations of circularly polarized
Raman measurements and crystal orientations, we observe the shift of two phonon
modes only in the (0 0 1) plane. The shift is positive or negative depending on
the handedness of the crystals, which we determine univocally by chemical
etching. Our analysis of three different crystal faces of Te highlights the
importance of selecting the proper orientation and crystallographic plane when
investigating the transport and optical properties of this material. These
results offer insight into the crystal structure and symmetry in other
anisotropic and chiral materials, and open new paths to select a suitable
crystal orientation when fabricating devices.

</details>


### [223] [Hexagonal BeX (X: S, Te) monolayer as potential electrode material for alkali metal-ion batteries: A DFT perspective](https://arxiv.org/abs/2510.27429)
*Hetvi Jadav,Sadhana Matth,Himanshu Pandey*

Main category: cond-mat.mtrl-sci

TL;DR: BeS和BeTe单层结构稳定，适合作为锂/钠离子电池电极材料，具有高容量和低扩散势垒。


<details>
  <summary>Details</summary>
Motivation: 研究六方BeS和BeTe单层作为碱金属（Li和Na）离子电池电极材料的潜力。

Method: 使用密度泛函理论研究了h-BeS和h-BeTe的结构稳定性、吸附、电子性质、扩散和储能。

Result: h-BeS和h-BeTe单层结构在吸附原子后保持稳定，电子导电性得到改善。计算出的Li/Na在h-BeS中的扩散势垒分别为0.16 eV/0.01 eV，在h-BeTe中为0.20 eV/0.16 eV。h-BeS的最大储能容量为580 mAh g-1 (Li)和1305 mAh g-1 (Na)，h-BeTe为174 mAh g-1 (Li和Na)。

Conclusion: 六方BeS和BeTe单层是具有前景的锂/钠离子电池电极材料，因其稳定性、低扩散势垒和高储能潜力。

Abstract: Metal-ion batteries (MIBs) are essential for transitioning to a cleaner and
more sustainable energy future. By employing the density functional formalism,
we have investigated the hexagonal (h) monolayer of BeS and BeTe as electrode
materials for alkali (Li and Na) MIBs. The structural and thermodynamic
stability, adsorption of Li/Na atoms, density of states, diffusion, and
migration of atoms, as well as capacity, are systematically investigated. The
structures of h-BeS and h-BeTe remain stable upon the adsorption of adatoms,
resulting in improved electronic conductivity of these monolayers. The climbing
image-nudged elastic band calculations estimate a low diffusion barrier of 0.16
eV (0.01 eV) for Li (Na) in h-BeS and 0.20 eV (0.16 eV) for Li (Na) in h-BeTe.
Additionally, a maximum storage capacity of 580 mAh g-1 for Li and 1305 mAh g-1
for Na in h-BeS, as well as 174 mAh g-1 for h-BeTe, is estimated for both metal
ions.

</details>


### [224] [Density functional investigations on 2D-Be2C as an anode for alkali Metal-ion batteries](https://arxiv.org/abs/2510.27433)
*Hetvi Jadav,Sadhana Matth,Himanshu Pandey*

Main category: cond-mat.mtrl-sci

TL;DR: 二维Be2C是一种有潜力的钠/钾离子电池负极材料，具有高容量和低扩散势垒。


<details>
  <summary>Details</summary>
Motivation: 为了应对可再生能源（尤其是在汽车领域）日益增长的需求，需要开发金属离子电池。

Method: 利用第一性原理计算，研究二维Be2C作为钠/钾离子电池负极材料的性能，包括吸附能、金属离子扩散势垒（使用爬行图像捏合弹性带方法）和开路电压。

Result: 二维Be2C在吸附金属离子后表现出金属性，吸附能为负，表明其稳定性良好。钠和钾离子的最低扩散势垒分别为0.016 eV和0.026 eV。计算得到的钾离子最大开路电压约为1 V，钠离子约为0.5 V。Be2C单层膜的最大存储容量估计为1785 Ah/kg。

Conclusion: 二维Be2C是一种有前途的金属离子电池负极材料，具有高理论容量和低离子扩散势垒，表明其在储能应用方面具有巨大潜力。

Abstract: Metal-ion batteries are in huge demand to cope with the increasing need for
renewable energy, especially in automobiles. In this work, we apply
first-principle calculations to examine two-dimensional beryllium carbide
(2D-Be2C) as a possible anode material for metal-ion (Na and K) batteries.
2D-Be2C is a semiconductor and becomes metallic by adsorbing metal ions.
Negative adsorption energy indicates stable adsorption on the monolayer of
Be2C. Alkali metal diffusion barrier and optimum path for minimum energy are
studied within the framework of the climbing image nudged elastic band method.
Here, six intermediate images are considered between the initial and final
states. The lowest diffusion barriers for a single adsorbed Na and K atom are
0.016 and 0.026 eV, respectively. A maximum open circuit voltage of around 1 V
is computed for K ions, whereas 0.5 V is for Na ions. Also, the maximum storage
capacity of the Be2C monolayer is estimated at 1785 Ah/kg.

</details>


### [225] [First-principles calculations of thermal transport at metal/silicon interfaces: evidence of interfacial electron-phonon coupling](https://arxiv.org/abs/2510.27499)
*Michaël De San Féliciano,Christophe Adessi,Julien El Hajj,Nicolas Horny,François Detcheverry,Manuel Cobian,Samy Merabia*

Main category: cond-mat.mtrl-sci

TL;DR: 电子-声子在金属/半导体界面上的热传输仍有争议，本文结合第一性原理计算和非平衡格林函数（NEGF）方法进行了研究。


<details>
  <summary>Details</summary>
Motivation: 电子-声子在金属/半导体界面上的热传输对于优化器件热管理至关重要，但其存在性仍有争议。

Method: 结合第一性原理计算和非平衡格林函数（NEGF）方法，并对NEGF形式主义进行了修正，以考虑界面附近能量载流子的非平衡性质。

Result: 对于Au/Si界面，热传输主要由声子-声子过程驱动；对于Al/Si界面，电子-声子过程占总热导的约三分之一。

Conclusion: 电子-声子在金属/硅界面上的热导具有重要意义，需要进一步的实验研究，并为准确预测电子-声子界面通道电导提供了模型。

Abstract: With the increasing miniaturization of electronic components and the need to
optimize thermal management, it has become essential to understand heat
transport at metal/semiconductor interfaces. While it has been recognized
decades ago that an electron phonon channel may take place at
metal-semiconductor interfaces, its existence is still controversial. Here, we
investigate thermal transport at metal-silicon interfaces using the combination
of first principles calculations and nonequilibrium Green's function (NEGF). We
explain how to correct NEGF formalism to account for the out of equilibrium
nature of the energy carriers in the vicinity of the interface. The relative
corrections to the equilibrium distribution are shown to arise from the
spectral mean free paths of silicon and may reach 15 percents. Applying these
corrections, we compare the predictions of NEGF to available experimental data
for Au/Si, Pt/Si and Al/Si interfaces. Based on this comparison, we infer the
value of the electron phonon interfacial thermal conductance by employing the
two temperature model. We find that interfacial thermal transport at Au/Si
interfaces is mainly driven by phonon phonon processes, and that electron
phonon processes play a negligible role in this case. By contrast, for Al/Si
interfaces, we show that phonon-phonon scattering alone can not explain the
experimental values reported so far, and we estimate that the electron-phonon
interfacial conductance accounts for one third of the total conductance. This
work demonstrates the importance of the electron-phonon conductance at
metal-silicon interfaces and calls for systematic experimental investigation of
thermal transport at these interfaces at low temperatures. It paves the way for
an accurate model to predict the conductance associated to the interfacial
electron phonon channel.

</details>


### [226] [Size-dependent transformation patterns in NiTi tubes under tension and bending: Stereo digital image correlation experiments and modeling](https://arxiv.org/abs/2510.27464)
*Aslan Ahadi,Elham Sarvari,Jan Frenzel,Gunther Eggeler,Stanisław Stupkiewicz,Mohsen Rezaee-Hajidehi*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了超弹性镍钛管的相变模式如何随管材外径D和壁厚t变化，发现存在尺寸依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究超弹性镍钛管在不同尺寸下（外径D和壁厚t）的相变模式，理解其尺寸依赖行为。

Method: 采用准静态单轴拉伸和大转角弯曲实验，结合多倍率立体数字图像相关技术，同步测量外表面应变场与宏观应力-应变/力矩-曲率响应。采用梯度增强超弹性模型进行分析。

Result: 发现相变模式存在系统性的尺寸依赖行为。拉伸时，随着D/t减小，从细长的/尖锐的螺旋带转变为弥散的/粗糙的螺旋带，甚至在特定D/t以下转变为无指状前沿。弯曲时，力矩-曲率响应和相变模式也依赖于D和D/t，但所有尺寸下都会形成楔形马氏体域，只是在尺寸较小且较厚的管材中生长受限。尺寸依赖性可通过平衡体积能、界面能和马氏体指的能量成本来解释。

Conclusion: 超弹性镍钛管的相变模式受到尺寸效应的显著影响，这可以通过能量竞争理论来解释，并且该效应在拉伸和弯曲载荷下均有体现。

Abstract: The dependence of transformation pattern in superelastic NiTi tubes on tube
outer diameter D and wall-thickness t is investigated through quasi-static
uniaxial tension and large-rotation bending experiments. The evolution of
outer-surface strain fields is synchronized with global stress-strain and
moment-curvature responses using a multi-magnification, high-resolution stereo
digital image correlation system at 0.5-2x magnifications. The transformation
patterns exhibit systematic size-dependent behaviors. Under tension and for a
specific D, as the diameter-to-thickness ratio D/t decreases, a decreasing
number of fat/diffuse helical bands emerge, in contrast to sharp/slim bands in
thin tubes. Consequently, the austenite-martensite front morphology transitions
from finely-fingered to coarsely-fingered with decreasing D/t. Below a
characteristic D/t, front morphology no longer exhibits patterning and phase
transformation proceeds via propagation of a finger-less front. Moreover, the
transformation pattern exhibits an interrelation between D and D/t, where a
front possessing diffuse fingers is observed in a thin but small tube. Under
bending, both the global moment-curvature response and transformation pattern
exhibit D- and D/t-dependence. While wedge-like martensite domains consistently
form across all tube sizes, their growth is noticeably limited in smaller and
thicker tubes due to geometrical constraints. A gradient-enhanced model of
superelasticity is employed to analyze the distinct transformation patterns
observed in tubes of various dimensions. The size-dependent behavior is
explained based on the competition between bulk and interfacial energies, and
the energetic cost of accommodating martensite fingers. By leveraging an
axisymmetric tube configuration as a reference energy state, the extra energy
associated with the formation of fingers is quantified.

</details>


### [227] [Molecular ink-based synthesis of Bi(SzSe1-z)(IxBr1-x) solid solutions as tuneable materials for sustainable energy applications](https://arxiv.org/abs/2510.27546)
*David Rovira,Ivan Caño,Cibran Lopez,Alejandro Navarro-Güell,José Miguel Asensi,Lorenzo Calvo-Barrio,Laura Garcia-Carreras,Xavier Alcobe,Luis Cerqueira,Victoria Corregidor,Yudania Sanchez,Sonia Lanzalaco,Alex Jimenez-Arquijo,Outman El Khouja,Jonathan W. Turnley,Rakesh Agrawal,Claudio Cazorla,Joaquim Puigdollers,Edgardo Saucedo*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种低温合成方法，用于制备可调的 Bi(SzSe1-z)(IxBr1-x) 固溶体薄膜，解决了现有二维材料在晶体生长、成分控制和光电性质方面的挑战，为开发下一代能源技术奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 二维材料在能源领域具有应用前景，但其在晶体生长、成分控制和光电性质方面存在挑战，需要深入理解其内在限制并开发缺陷缓解策略。

Method: 采用低温分子墨水沉积技术，直接合成可调的 Bi(SzSe1-z)(IxBr1-x) 固溶体薄膜，无需二元硫属化物前驱体。

Result: 成功制备出相纯、形貌可控、成分均匀的固溶体薄膜。XRD 和 DFT 计算证实了固溶体的形成，光电测量揭示了卤素和硫属阴离子在调节带隙和载流子类型中的作用（Se 导致导带向下移动）。合成技术可实现从致密薄膜到棒状微晶的形貌控制。

Conclusion: 提出的合成技术为缺陷工程和二维材料的可扩展集成提供了基础框架，有望应用于光伏、光催化、热电和化学传感等下一代能源技术。

Abstract: Quasi-one-dimensional (Q-1D) van der Waals chalcohalides have emerged as
promising materials for advanced energy applications, combining tunable
optoelectronic properties and composed by earth-abundant and non-toxic
elements. However, their widespread application remains hindered by challenges
such as anisotropic crystal growth, composition control and lack of knowledge
on optoelectronic properties. A deeper understanding of the intrinsic
limitations of these materials, as well as viable defect mitigation strategies
like the engineering of solid solutions, is critical. This work presents a
low-temperature synthesis route based on molecular ink deposition enabling
direct crystallization of tunable Bi(SzSe1-z)(IxBr1-x) solid solutions without
need for binary chalcogenide precursors. This approach yields phase-pure films
with precise control over morphology, composition, and crystallographic
orientation. XRD analysis and DFT calculations confirm the formation of
homogeneous solid solutions, while optoelectronic measurements reveal the
distinct roles of halogen and chalcogen anions in tuning bandgap energy and
carrier type, with Se shifting downwards the conduction band. The versatility
of this synthesis technique enables morphology control ranging from compact
films to rod-shaped microcrystals, expanding the functional adaptability of
these materials. These findings offer a foundational framework for defect
engineering and the scalable integration of chalcohalides in next-generation
energy technologies, including photovoltaics, photocatalysis, thermoelectrics,
and chemical sensing.

</details>


### [228] [Synthesis of organic-inorganic perovskite and all-inorganic lead-free double perovskite nanocrystals by femtosecond laser pulses](https://arxiv.org/abs/2510.27563)
*Volodymyr Vasylkovskyi,Andrey Evlyukhin,Elena Schlein,Mykola Slipchenko,Roman Kiyan,Kestutis Kurselis,Vladimir Dyakonov,Boris Chichkov*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种无需液体的激光烧蚀方法，用于制备无配体、高纯度的钙钛矿纳米晶体，尺寸可控且光学性质可调。


<details>
  <summary>Details</summary>
Motivation: 为了提高钙钛矿材料在太阳能电池、LED和传感器等下一代器件中的性能、稳定性和可扩展性，需要对其进行可控的纳米结构制造。

Method: 本研究采用飞秒脉冲激光烧蚀（PLA）技术，在空气中无额外液体介质的情况下，合成了平均尺寸可达100 nm的无配体钙钛矿纳米晶体（NCs）。该方法适用于有机-无机杂化钙钛矿（MAPbX3）和全无机无铅双钙钛矿（Cs2AgBiX6）。

Result: 通过调整激光参数，成功制备了高纯度、无配体的MAPbX3（约90 nm，立方）和Cs2AgBiX6（约10 nm，圆形）纳米晶体。透射电子显微镜和X射线衍射证实了晶体的完整性。光致发光光谱显示，由于量子尺寸效应，特别是对于含溴和碘的钙钛矿，表现出显著的尺寸依赖性蓝移（17-40 nm）。

Conclusion: 这种清洁、可扩展且通用的PLA方法不仅可以直接获得具有可调光学性质的高纯度、无配体钙钛矿NCs，而且在纳米结构制造方面也取得了重大进展，为探索新型钙钛矿基光电和量子器件提供了可能。

Abstract: Perovskite materials are at the forefront of modern materials science due to
their exceptional structural, electronic, and optical properties. The
controlled fabrication of perovskite nanostructures is crucial for enhancing
their performance, stability, and scalability, directly impacting their
applications in next-generation devices such as solar cells, LEDs, and sensors.
Here, we present a novel, ligand-free approach to synthesize perovskite
nanocrystals (NCs) with average sizes up to 100 nm, using femtosecond pulsed
laser ablation (PLA) in ambient air without additional liquid media. We
demonstrate this method for both organic-inorganic (methylamino lead) hybrid
perovskites (MAPbX3, X = Cl, Br, I) and fully inorganic lead-free double
perovskites (Cs2AgBiX6, X = Cl, Br), achieving high-purity NCs without
stabilizing ligands - a critical advancement over conventional chemical
synthesis methods. By tailoring laser parameters, we systematically elucidate
the influence of perovskite composition (halide type, organic vs. inorganic
cation, single versus double perovskite structure) on the ablation process and
the resulting nanocrystal properties. Transmission electron microscopy and
X-ray diffraction confirm the preservation of crystallinity, with MAPbX3
forming larger (approximately 90 nm) cubic NCs and Cs2AgBiX6 forming smaller
(approximately 10 nm) rounded NCs. Photoluminescence spectroscopy reveals
pronounced size-dependent blue shifts (17-40 nm) due to quantum confinement,
particularly for Br and I containing perovskites. This clean, scalable, and
versatile PLA approach not only provides direct access to high-purity,
ligand-free perovskite NCs with tunable optical properties but also represents
a significant advance in the fabrication of nanostructures, enabling the
exploration of new perovskite-based optoelectronic and quantum devices.

</details>


### [229] [Learning viscoplastic constitutive behavior from experiments: II. Dynamic indentation](https://arxiv.org/abs/2510.27570)
*Andrew Akerson,Aakila Rajan,Daniel Casem,Kaushik Bhattacharya*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种结合全场观测和逆问题方法来识别复杂材料本构行为的新方法，并将其扩展到包含接触和动态压痕的场景。


<details>
  <summary>Details</summary>
Motivation: 开发一种能通过全场观测精确高效地识别复杂材料本构行为的方法。

Method: 将本构关系推断问题表述为受平衡定律约束的间接逆问题。通过最小化实验观测与模型计算量之间的差异来寻找本构行为，并强制执行平衡定律。将正问题表述为与实验对应的边界值问题，并使用伴随法计算目标函数关于模型的敏感性。引入拉格朗日乘子和松弛变量来处理非完整约束——接触，并研究动态压痕。

Result: 该方法在合成数据上进行了验证，并成功应用于轧制均质装甲钢和多晶铝合金的实验观测。

Conclusion: 该研究成功地将先前提出的识别复杂材料本构行为的方法扩展到了包含接触和动态压痕的场景，并在合成和真实实验数据上得到了验证。

Abstract: We continue the development of a method to accurately and efficiently
identify the constitutive behavior of complex materials through full-field
observations that we started in Akerson, Rajan and Bhattacharya (2024). We
formulate the problem of inferring constitutive relations from experiments as
an indirect inverse problem that is constrained by the balance laws.
Specifically, we seek to find a constitutive behavior that minimizes the
difference between the experimental observation and the corresponding
quantities computed with the model, while enforcing the balance laws. We
formulate the forward problem as a boundary value problem corresponding to the
experiment, and compute the sensitivity of the objective with respect to the
model using the adjoint method. In this paper, we extend the approach to
include contact and study dynamic indentation. Contact is a nonholonomic
constraint, and we introduce a Lagrange multiplier and a slack variable to
address it. We demonstrate the method on synthetic data before applying it to
experimental observations on rolled homogeneous armor steel and a
polycrystalline aluminum alloy.

</details>


### [230] [First-Principles Study of Transition Metal Doped in 2D Polyaramid for Novel Material Modelling](https://arxiv.org/abs/2510.27578)
*Ravi Trivedi,Chaithanya Purushottam Bhat,Shakti S. Ray,Debashis Bandyopadhyay*

Main category: cond-mat.mtrl-sci

TL;DR: 过渡金属掺杂的二维聚酰胺（2DPA）在结构、电子和磁性方面表现出稳定性，并且具有可调的电子和磁性特征，适用于自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 探索过渡金属（TM = Ti, Cr, Mn, Fe, Co, Ni）功能化的二维聚酰胺（2DPA）的结构、电子和磁性性质。

Method: 采用第一性原理密度泛函理论（DFT）研究TM掺杂2DPA的性质。计算了力学参数（体模量、剪切模量、杨氏模量、泊松比、Pugh比）和声子色散以确认稳定性。分析了电子结构（结合能、带隙）和磁性（磁矩）。

Result: 所有掺杂体系均表现出良好的力学和动力学稳定性。TM（Co, Cr, Fe, Ni, Ti）与2DPA的结合能介于-1.15 eV和-2.96 eV之间，Mn的结合能为-0.67 eV。TM掺杂引入了新的电子态，降低了带隙，其中Fe掺杂的2DPA带隙最低（0.26 eV）。体系主要表现为铁磁有序，并具有不同程度的磁矩。

Conclusion: TM掺杂的2DPA具有可调的磁性和电子特性，显示出自旋电子学应用的潜力。

Abstract: We present a first--principles density functional theory (DFT) study of
transition metal (TM = Ti, Cr, Mn, Fe, Co, Ni) functionalized two--dimensional
polyaramid (2DPA) to explore their structural, electronic, and magnetic
properties. Mechanical parameters, such as bulk modulus, shear modulus, Young's
modulus, Poisson's ratio, and Pugh ratio, together with phonon dispersion,
confirm the mechanical and dynamic stability of all doped systems. Electronic
structure analysis shows strong binding of Co, Cr, Fe, Ni, and Ti with
formation energies between --1.15 eV and --2.96 eV, while Mn binds more weakly
(--0.67 eV). TM doping introduces new electronic states that reduce the band
gap, with Fe-doped 2DPA exhibiting the lowest value of 0.26 eV. The systems
display predominantly ferromagnetic ordering, with magnetic moments of 1.14
{\mu}B (Co), 3.57 {\mu}B (Cr), 2.26 {\mu}B (Fe), 4.19 {\mu}B (Mn), and 1.62
{\mu}B (Ti). These results demonstrate that TM--doped 2DPA possesses tunable
magnetic and electronic characteristics, highlighting its potential for
spintronic applications.

</details>


### [231] [Kinematical and dynamical contrast of dislocations in thick GaN substrates observed by synchrotron-radiation X-ray topography under six-beam diffraction conditions](https://arxiv.org/abs/2510.27597)
*Yongzhao Yao,Yoshiyuki Tsusaka,Yukari Ishikawa*

Main category: cond-mat.mtrl-sci

TL;DR: 利用多束衍射条件下的同步辐射X射线形貌学技术，分析了厚GaN衬底中的位错，并确定了其伯格矢量，为GaN基电子器件的性能提升提供了见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用同步辐射X射线形貌学技术，在多束衍射条件下，精确分析厚氨热生长GaN衬底中的位错结构，并确定其伯格矢量，以期为高性能GaN基电子器件的优化提供支持。

Method: 采用同步辐射X射线形貌学（SR-XRT）技术，在六束衍射条件下，对厚度为350μm的GaN晶体进行分析。通过系统地改变偏差角，观察了从运动学到动力学衍射的转变。利用近乎六束衍射的五束等效两束衍射条件，依据g·b不可见判据，确定了单个螺位TED的伯格矢量。

Result: 研究观察到了显著增强的X射线异常透射的超Borrmann效应。测量的位错图像宽度与基于消光距离和|g·b|依赖性计算出的值吻合良好，证实大多数位错的伯格矢量包含a分量，为$rac{1}{3}\	extlangle 11ar{2}0angle$或$rac{2}{3}\	extlangle 11ar{2}0angle$。

Conclusion: 同步辐射X射线形貌学在多束衍射条件下，为厚GaN晶体中位错的定量无损分析提供了一种强大的方法，能够提供对高性能GaN基电子器件至关重要的缺陷结构的宝贵见解。

Abstract: Dislocations in a thick ammonothermal GaN substrate were investigated using
synchrotron-radiation X-ray topography (SR-XRT) under six-beam diffraction
conditions. The high brilliance of the synchrotron source enabled the
observation of the super-Borrmann effect, which markedly enhanced the anomalous
transmission of X-rays through the 350~$\mu$m-thick crystal. Systematic
variation of the deviation angle~$\Delta\omega$ revealed a clear transition
from kinematical to dynamical diffraction, consistent with theoretical
predictions based on dynamical diffraction theory. By selectively exciting five
equivalent two-beam diffraction conditions near the six-beam configuration, the
Burgers vectors of individual threading edge dislocations (TEDs) were
determined according to the $g\cdot b$ invisibility criterion. The measured
dislocation image widths agreed well with calculated values derived from the
extinction distance and $|g\cdot b|$ dependence, confirming that most
dislocations possess Burgers vectors containing an $a$-type component of
$\frac{1}{3}\langle 11\bar{2}0\rangle$ or $\frac{2}{3}\langle
11\bar{2}0\rangle$. These results demonstrate that SR-XRT under multibeam
diffraction provides a powerful, nondestructive method for quantitative
dislocation analysis in thick GaN crystals, offering valuable insights into
defect structures critical for high-performance GaN-based electronic devices.

</details>


### [232] [Evolution of Magnetoresistance in the magnetic topological semimetals NdSbxTe2-x](https://arxiv.org/abs/2510.27634)
*Santosh Karki Chhetri,Rabindra Basnet,Krishna Pandey,Gokul Acharya,Sumaya Rahman,Md Rafique Un Nabi,Dinesh Upreti,Hugh O. H. Churchill,Jin Hu*

Main category: cond-mat.mtrl-sci

TL;DR: LnSbTe 是一种磁性拓扑半金属材料，通过改变 Sb 和 Te 的组成可以有效调控其电子、磁性及输运性质。研究 NdSbxTe2-x (0 < x < 1) 中输运性质随 Sb 和 Te 含量演变，发现其磁阻演化不具单调性，且降低 Sb 含量 x 可获得高达 99.9% 的强负磁阻。


<details>
  <summary>Details</summary>
Motivation: 研究磁性拓扑半金属 LnSbTe 中结构、磁性、拓扑和电子相关性的相互作用，特别是 Sb 和 Te 组成变化对 NdSbxTe2-x 电子、磁性和输运性质的影响。

Method: 通过改变 NdSbxTe2-x (0 < x < 1) 中的 Sb 和 Te 含量，研究其输运性质的演变。

Result: 研究发现，随着 Sb 和 Te 含量的变化，磁阻演化呈现非单调趋势。特别地，降低 Sb 含量 x 导致了高达 99.9% 的强负磁阻。

Conclusion: NdSbxTe2-x 材料中观察到的强负磁阻现象，可能源于结构、磁性和电子能带的相互作用，这使得该材料成为未来器件应用中研究拓扑半金属的有希望的平台。

Abstract: Magnetic topological semimetals LnSbTe (Ln = lanthanide elements) provide a
platform to study the interplay of structure, magnetism, topology, and electron
correlations. Varying Sb and Te compositions in LnSbxTe2-x can effectively
control the electronic, magnetic, and transport properties. Here, we report the
evolution of transport properties with Sb and Te contents in NdSbxTe2-x, (0 < x
< 1). Our work reveals nonmonotonic evolution in magnetoresistance with varying
composition stoichiometry. Specifically, reducing Sb content x leads to strong
negative magnetoresistance up to 99.9%. Such a strong magnetoresistance, which
is likely attributed to the interplay between structure, magnetism, and
electronic bands, establishes this material as a promising platform for
investigating topological semimetal for future device applications.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [233] [Simulating hashtag dynamics with networked groups of generative agents](https://arxiv.org/abs/2510.26832)
*Abha Jha,J. Hunter Priniski,Carolyn Steinle,Fred Morstatter*

Main category: cs.SI

TL;DR: LLM 代理可以通过模仿人类在网络环境中的叙事互动来近似人类群体行为，但需要在复杂叙事中进行结构化提示。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨网络环境如何影响基于叙事的信息传播，以及群体沟通对信念形成、共识和两极分化的影响。

Method: 使用包含大型语言模型（LLM）代理的网络化仿真框架，并使用来自人类群体和 Twitter 的真实数据进行基准测试。

Result: LLM 代理可以近似人类在简单场景下的群体行为，但在处理复杂或政治敏感叙事时，需要结构化提示才能有效整合背景知识和社会背景。

Conclusion: LLM 代理在模仿人类叙事互动方面显示出潜力，但要实现更广泛的应用，尤其是在处理复杂信息时，需要进一步优化提示策略。

Abstract: Networked environments shape how information embedded in narratives
influences individual and group beliefs and behavior. This raises key questions
about how group communication around narrative media impacts belief formation
and how such mechanisms contribute to the emergence of consensus or
polarization. Language data from generative agents offer insight into how
naturalistic forms of narrative interactions (such as hashtag generation)
evolve in response to social rewards within networked communication settings.
To investigate this, we developed an agent-based modeling and simulation
framework composed of networks of interacting Large Language Model (LLM)
agents. We benchmarked the simulations of four state-of-the-art LLMs against
human group behaviors observed in a prior network experiment (Study 1) and
against naturally occurring hashtags from Twitter (Study 2). Quantitative
metrics of network coherence (e.g., entropy of a group's responses) reveal that
while LLMs can approximate human-like coherence in sanitized domains (Study 1's
experimental data), effective integration of background knowledge and social
context in more complex or politically sensitive narratives likely requires
careful and structured prompting.

</details>


### [234] [Are Online Sports Fan Communities Becoming More Offensive? A Quantitative Review of Topics, Trends, and Toxicity of r/PremierLeague](https://arxiv.org/abs/2510.27003)
*Muhammad Zeeshan Mazhar,Tolga Buz,Yiran Su*

Main category: cs.SI

TL;DR: Reddit r/PremierLeague 上的体育迷在线社区在过去十年中增长迅速，但负面情绪和毒性也在增加，并成为讨论更广泛社会问题的场所。


<details>
  <summary>Details</summary>
Motivation: 虽然英格兰足球超级联赛因在线社区而广受欢迎，但对其在线粉丝群体的理解却滞后。

Method: 分析了 2013-2022 年在 r/PremierLeague 上发布的超过 110 万条评论，以研究情绪、主题和毒性。

Result: 在线社区在讨论体育和更广泛的社会问题方面都得到扩展，但毒性和负面情绪有所增加。

Conclusion: 英格兰足球超级联赛的在线社区得到了扩展，但社区的负面情绪和毒性增加，并且讨论了更广泛的社会问题。

Abstract: Online communities for sports fans have surged in popularity, with Reddit's
r/PremierLeague emerging as a focal point for fans of one of the globe's most
celebrated sports leagues. This boom has helped the Premier League make
significant inroads into the US market, increasing viewership and sparking
greater interest in its matches. Despite the league's broad appeal, there's
still a notable gap in understanding its online fan community. Therefore, we
analyzed a substantial dataset of over 1.1 million comments posted from
2013-2022 on r/PremierLeague. Our study delves into the sentiment, topics, and
toxicity of these discussions, tracking trends over time, aiming to map out the
conversation landscape. The rapid expansion has brought more diverse
discussions, but also a worrying rise in negative sentiment and toxicity.
Additionally, the subreddit has become a venue for users to voice frustrations
about broader societal issues like racism, the COVID-19 pandemic, and political
tensions.

</details>


### [235] [Disrupting Networks: Amplifying Social Dissensus via Opinion Perturbation and Large Language Models](https://arxiv.org/abs/2510.27152)
*Erica Coppolillo,Giuseppe Manco*

Main category: cs.SI

TL;DR: 研究了如何通过定向内容注入来破坏社交网络，并提出了利用弗里德金-约翰森（FJ）模型和强化学习来生成破坏性文本的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过定向内容注入来破坏社交网络，以应对内容审核、对抗性信息活动和生成模型监管方面的挑战。

Method: 利用弗里德金-约翰森（FJ）模型衡量社会分歧，并设计了一个强化学习框架来微调大型语言模型（LLM）以生成破坏性文本。

Result: 研究表明，简单的FJ模型难以显著扰乱网络，但扩展模型可以实现扰乱超过初始状态；改变个体固有观点能最大化扰乱效果。经过微调的LLM可以接近理论扰乱极限。

Conclusion: 定向内容注入可以有效地破坏社交网络，并且可以通过改进模型和调整个体观点来增强效果。这对于内容审核、对抗性信息活动和生成模型监管具有重要意义。

Abstract: We study how targeted content injection can strategically disrupt social
networks. Using the Friedkin-Johnsen (FJ) model, we utilize a measure of social
dissensus and show that (i) simple FJ variants cannot significantly perturb the
network, (ii) extending the model enables valid graph structures where
disruption at equilibrium exceeds the initial state, and (iii) altering an
individual's inherent opinion can maximize disruption. Building on these
insights, we design a reinforcement learning framework to fine-tune a Large
Language Model (LLM) for generating disruption-oriented text. Experiments on
synthetic and real-world data confirm that tuned LLMs can approach theoretical
disruption limits. Our findings raise important considerations for content
moderation, adversarial information campaigns, and generative model regulation.

</details>


### [236] [Structure-Aware Optimal Intervention for Rumor Dynamics on Networks: Node-Level, Time-Varying, and Resource-Constrained](https://arxiv.org/abs/2510.27165)
*Yan Zhu,Qingyang Liu,Chang Guo,Tianlong Fan,Linyuan Lü*

Main category: cs.SI

TL;DR: 本文提出了一种新的节点级、时变最优干预框架，用于在社交网络中有效且资源节约地管理谣言传播。


<details>
  <summary>Details</summary>
Motivation: 社交网络中的谣言传播会破坏社会稳定和公众信任，因此需要进行有效的干预。

Method: 该框架通过解决资源受限的最优控制问题来分配有限资源，该问题与网络结构紧密耦合，并根据不断变化的传播状态进行调整。与静态的、基于中心性的启发式方法不同，该框架计算控制权重。

Result: 与均匀分配和基于中心性的静态分配相比，该方法在合成和真实世界网络中都能有效降低感染峰值和累积感染范围。

Conclusion: 该框架整合了全局效率和细粒度适应性，为虚假信息管理和危机应对提供了一个可扩展且可解释的范例。此外，它揭示了一种分阶段的干预策略：早期资源优先考虑有影响力的节点以遏制快速传播，而后期资源则转向外围节点以消除残留传播。

Abstract: Rumor propagation in social networks undermines social stability and public
trust, calling for interventions that are both effective and
resource-efficient. We develop a node-level, time-varying optimal intervention
framework that allocates limited resources according to the evolving diffusion
state. Unlike static, centrality-based heuristics, our approach derives control
weights by solving a resource-constrained optimal control problem tightly
coupled to the network structure. Across synthetic and real-world networks, the
method consistently lowers both the infection peak and the cumulative infection
area relative to uniform and centrality-based static allocations. Moreover, it
reveals a stage-aware law: early resources prioritize influential hubs to curb
rapid spread, whereas later resources shift to peripheral nodes to eliminate
residual transmission. By integrating global efficiency with fine-grained
adaptability, the framework offers a scalable and interpretable paradigm for
misinformation management and crisis response.

</details>


### [237] [Meritocracy versus Matthew-effect: Two underlying network formation mechanisms of online social platforms](https://arxiv.org/abs/2510.27339)
*Yuchen Xu,Wenjun Mei,Ge Chen,Linyuan Lü*

Main category: cs.SI

TL;DR: 内容平台比传统连接平台具有更大的不平等性，这两种网络形成机制可以解释这些平台上的社会权力分布。


<details>
  <summary>Details</summary>
Motivation: 在线社交网络在日常生活中扮演着越来越重要的角色，而内容驱动的平台（如TikTok）与传统的基于连接的平台（如Facebook）在底层逻辑上存在根本差异，导致了不同的社会权力分布。

Method: 提出并分析了两种网络形成机制：基于精英主义的模型（适用于传统平台）和基于马太效应的模型（适用于新兴内容平台）。通过理论和数值分析，验证了这两种模型能够复制网络规模无标度和小世界等统计特征，并能匹配实际的入度与入度排名关系，从而解释不同类型平台的社会权力分布。

Result: 两种模型都成功复制了规模无标度和“六度分隔”等网络特征，并且能够精确匹配实际的入度与入度排名关系。这表明所提出的模型能够有效地解释传统和新兴社交平台的社会权力分布差异。

Conclusion: 通过解构在线社交网络的形成机制，可以为理解内容生态系统的演变和内容创作者的行为模式提供有价值的见解。精英主义模型和马太效应模型为理解不同社交平台的演变提供了理论框架。

Abstract: With the rapid development of the internet industry, online social networks
have come to play an increasingly significant role in everyday life. In recent
years, content-based emerging platforms such as TikTok, Instagram, and Bilibili
have diverged fundamentally in their underlying logic from traditional
connection-based social platforms like Facebook and LinkedIn. Empirical data on
follower counts and follower-count-based rankings reveal that the distribution
of social power varies significantly across different types of platforms, with
content-based platforms exhibiting notably greater inequality. Here we propose
two fundamental network formation mechanisms: a meritocracy-based model and a
Matthew-effect-based model, designed to capture the formation logic underlying
traditional and emerging social networks, respectively. Through theoretical and
numerical analysis, we demonstrate that both models replicate salient
statistical features of social networks including scale-free and small-world
property, while also closely match empirical patterns on the relationship
between in-degrees and in-degree rankings, thereby capturing the distinctive
distributions of social power in respective platforms. Moreover, networks such
as academic collaboration networks, where the distribution of social power
usually lies between that of traditional and emerging platorms, can be
interpreted through a hybrid of the two proposed mechanisms. Deconstructing the
formation mechanisms of online social networks offers valuable insights into
the evolution of the content ecosystems and the behavioral patterns of content
creators on online social platforms.

</details>


### [238] [Back to the Communities: A Mixed-Methods and Community-Driven Evaluation of Cultural Sensitivity in Text-to-Image Models](https://arxiv.org/abs/2510.27361)
*Sarah Kiden,Oriane Peter,Gisela Reyes-Cruz,Maira Klyshbekova,Sena Choi,Aislinn Gomez Bergin,Maria Waheed,Damian Eke,Tayyaba Azim,Sarvapali Ramchurn,Sebastian Stein,Elvira Perez Vallejos,Kate Devlin,Joel E Fischer*

Main category: cs.SI

TL;DR: T2I模型存在文化偏见，本文提出了一种包含59人参与的跨国共创研讨会，并开发了一种基于社区的混合方法评估模型，以解决T2I模型在文化敏感性评估中的不足。


<details>
  <summary>Details</summary>
Motivation: T2I模型倾向于反映西方文化规范，加剧了少数群体的误解和伤害，但文化敏感性的评估复杂且多变。

Method: 通过对标述性研究的回顾，并组织了59名来自19个不同国家的参与者的共创研讨会，开发并验证了一种基于社区的混合方法评估T2I模型文化敏感性。

Result: 定量评分和定性查询揭示了社区内部和社区之间在文化敏感性评估上的一致性和分歧，阐明了误传的下游影响，并追踪了培训数据中不平等权力关系如何扭曲了图像的描绘。

Conclusion: 评估T2I模型的文化敏感性面临资源需求高和文化动态变化的挑战，本文提出的方法通过情境化和迭代方法来缓解这种张力，并为利益相关者提供了可行的建议，指明了调查T2I模型文化（误）代表性的来源、机制和影响的途径。

Abstract: Evidence shows that text-to-image (T2I) models disproportionately reflect
Western cultural norms, amplifying misrepresentation and harms to minority
groups. However, evaluating cultural sensitivity is inherently complex due to
its fluid and multifaceted nature. This paper draws on a state-of-the-art
review and co-creation workshops involving 59 individuals from 19 different
countries. We developed and validated a mixed-methods community-based
evaluation methodology to assess cultural sensitivity in T2I models, which
embraces first-person methods. Quantitative scores and qualitative inquiries
expose convergence and disagreement within and across communities, illuminate
the downstream consequences of misrepresentation, and trace how training data
shaped by unequal power relations distort depictions. Extensive assessments are
constrained by high resource requirements and the dynamic nature of culture, a
tension we alleviate through a context-based and iterative methodology. The
paper provides actionable recommendations for stakeholders, highlighting
pathways to investigate the sources, mechanisms, and impacts of cultural
(mis)representation in T2I models.

</details>


### [239] [Beyond Demographics: Behavioural Segmentation and Spatial Analytics to Enhance Visitor Experience at The British Museum](https://arxiv.org/abs/2510.27542)
*Naomi Muggleton,Timothy Monteath,Taha Yasseri*

Main category: cs.SI

TL;DR: 本研究利用数据科学方法分析了英国博物馆的游客行为，结合了音频导览使用记录和猫途鹰评论等新数据源。研究分析了42,000次游客行程和超过50,000条评论，识别了影响满意度的关键因素，根据行为模式对游客进行了细分，并研究了游览参与度、空间导航和展室受欢迎程度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用数据科学方法，结合音频导览使用记录和猫途鹰评论等新数据源，深入探索英国博物馆的游客行为，以识别影响游客满意度的关键因素，对游客进行行为模式细分，并分析游览参与度、空间导航和展室受欢迎程度，最终为博物馆的规划提供数据支持。

Method: 本研究采用了数据科学方法，分析了42,000次游客行程和超过50,000条猫途鹰评论。具体分析内容包括：识别影响游客满意度的关键因素、根据行为模式对游客进行细分（发现了‘忠实徒步旅行者’、‘休闲探索者’、‘目标明确者’和‘快速采样者’四种类型）、分析游览参与度（特别是不同语言群体的游览完成率和中途退出率）、构建空间流动模型（发现可达性和邻近性，尤其是对楼梯的回避，比主题组织更能影响游客路径）、以及分析展室受欢迎程度（发现物理可达性比策展内容更能预测展室受欢迎程度）。

Result: 研究识别出四种不同的游客类型：忠实徒步旅行者、休闲探索者、目标明确者和快速采样者。游览参与度分析显示，不同语言群体在中途退出率和完成率上存在差异。空间流动模型表明，可达性和邻近性（尤其是对楼梯的回避）对游客路径的影响比主题组织更大。展室的受欢迎程度更多地受到物理可达性的影响，而非策展内容。

Conclusion: 本研究提出了改进游客参与度和流动性的实用策略，并为以游客为中心、数据驱动的博物馆规划提供了一个可扩展的框架。研究结果表明，物理可达性是影响游客行为和展室受欢迎程度的关键因素，而不仅仅是策展内容。此外，游客行为模式的多样性也为博物馆提供了个性化服务的可能性。

Abstract: This study explores visitor behaviour at The British Museum using data
science methods applied to novel sources, including audio guide usage logs and
TripAdvisor reviews. Analysing 42,000 visitor journeys and over 50,000 reviews,
we identify key drivers of satisfaction, segment visitors by behavioural
patterns, examine tour engagement, model spatial navigation, and investigate
room popularity. Behavioural clustering uncovered four distinct visitor types:
Committed Trekkers, Leisurely Explorers, Targeted Visitors, and Speedy
Samplers, each characterised by different levels of engagement and movement.
Tour usage analysis revealed high drop-off rates and variation in completion
rates across different language groups. Spatial flow modelling revealed that
accessibility and proximity, particularly aversion to stairs, shaped visitor
paths more than thematic organisation. Room popularity was more strongly
predicted by physical accessibility than curatorial content. We propose
practical strategies for improving engagement and flow, offering a scalable
framework for visitor-centred, data-informed museum planning.

</details>


### [240] [Community Detection on Model Explanation Graphs for Explainable AI](https://arxiv.org/abs/2510.27655)
*Ehsan Moradi*

Main category: cs.SI

TL;DR: MoI是一个新的框架，用于发现和分析影响模型预测的特征模块，解决了现有方法只关注单个特征的问题。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法（如SHAP、LIME）主要解释单个特征，但忽略了多个特征协同作用形成的高阶结构。

Method: MoI框架首先从逐实例归因构建模型解释图，然后应用社区检测发现联合影响预测的特征模块，最后量化这些模块与偏见、冗余和因果模式的关系。

Result: MoI在合成和真实数据集上发现了相关的特征分组，通过模块级烧除实验改进了模型调试，并将偏见暴露定位到特定模块。此外，还发布了稳定性、协同性指标、参考实现和评估协议。

Conclusion: MoI框架能够有效地发现和分析特征模块，有助于模型调试、偏见定位和理解特征间的相互作用，为XAI领域的模块发现提供了新的方法和评估工具。

Abstract: Feature-attribution methods (e.g., SHAP, LIME) explain individual predictions
but often miss higher-order structure: sets of features that act in concert. We
propose Modules of Influence (MoI), a framework that (i) constructs a model
explanation graph from per-instance attributions, (ii) applies community
detection to find feature modules that jointly affect predictions, and (iii)
quantifies how these modules relate to bias, redundancy, and causality
patterns. Across synthetic and real datasets, MoI uncovers correlated feature
groups, improves model debugging via module-level ablations, and localizes bias
exposure to specific modules. We release stability and synergy metrics, a
reference implementation, and evaluation protocols to benchmark module
discovery in XAI.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [241] [Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction](https://arxiv.org/abs/2510.26837)
*Conor K. Trygstad,Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文介绍了两种新型昆虫尺度推进器（单尾和双尾）的力学特性，它们利用流固耦合（FSI）产生推力，并基于反应力理论进行了实验测量。


<details>
  <summary>Details</summary>
Motivation: 研究两种新型昆虫尺度推进器的力学特性，以了解其在微型水下机器人游动中的性能。

Method: 采用基于反应力理论的理论框架，并使用定制的微牛顿分辨率力传感器进行实验测量，以表征推进器的力学特性。

Result: 单尾推进器的最大力和周期平均力分别为 0.45 mN 和 2.97 μN；双尾推进器的最大力和周期平均力分别为 0.61 mN 和 22.6 μN。

Conclusion: 本文首次测量了此类昆虫尺度推进器的瞬时推力，并深入了解了 FSI 在高效微型机器人推进中的作用。

Abstract: We present force characterizations of two newly developed insect-scale
propulsors--one single-tailed and one double-tailed--for microrobotic swimmers
that leverage fluid-structure interaction (FSI) to generate thrust. The designs
of these two devices were inspired by anguilliform swimming and are driven by
soft tails excited by high-work-density (HWD) actuators powered by shape-memory
alloy (SMA) wires. While these propulsors have been demonstrated to be suitable
for microrobotic aquatic locomotion and controllable with simple architectures
for trajectory tracking in the two-dimensional (2D) space, the characteristics
and magnitudes of the associated forces have not been studied systematically.
In the research presented here, we adopted a theoretical framework based on the
notion of reactive forces and obtained experimental data for characterization
using a custom-built micro-N-resolution force sensor. We measured maximum and
cycle-averaged force values with multi-test means of respectively 0.45 mN and
2.97 micro-N, for the tested single-tail propulsor. For the dual-tail
propulsor, we measured maximum and cycle-averaged force values with multi-test
means of 0.61 mN and 22.6 micro-N, respectively. These results represent the
first measurements of the instantaneous thrust generated by insect-scale
propulsors of this type and provide insights into FSI for efficient
microrobotic propulsion.

</details>


### [242] [Design for One, Deploy for Many: Navigating Tree Mazes with Multiple Agents](https://arxiv.org/abs/2510.26900)
*Jahir Argote-Gerald,Genki Miyauchi,Julian Rau,Paul Trodden,Roderich Gross*

Main category: cs.RO

TL;DR: 该研究提出了一种用于在迷宫环境中进行多机器人协调的分布式算法，该算法通过领导者切换机制实现，并能在通信受限的情况下有效导航，实验证明了其可行性。


<details>
  <summary>Details</summary>
Motivation: 在迷宫等具有通信限制和拥塞挑战的环境中，实现多机器人协调的难点。

Method: 提出一种分布式多智能体迷宫遍历算法，其中一个智能体担任领导者，负责解决迷宫，其他智能体跟随领导者。当需要时，领导者角色会在智能体之间切换，确保所有智能体沿着相同路径移动。

Result: 在包含多达300个智能体、不同大小迷宫和多种单智能体解谜器的模拟中，该算法在完成时间和燃料消耗方面优于朴素策略，在完成时间方面优于全局通信策略，但在燃料消耗方面不如全局通信策略。算法在这些指标上与全局知识策略的渐近效果相当。此外，在多达20个Pi-puck机器人的实际实验中也验证了该方法的有效性。

Conclusion: 该算法在通信受限的迷宫环境中是一种可行且高效的多机器人协调方法。

Abstract: Maze-like environments, such as cave and pipe networks, pose unique
challenges for multiple robots to coordinate, including communication
constraints and congestion. To address these challenges, we propose a
distributed multi-agent maze traversal algorithm for environments that can be
represented by acyclic graphs. It uses a leader-switching mechanism where one
agent, assuming a head role, employs any single-agent maze solver while the
other agents each choose an agent to follow. The head role gets transferred to
neighboring agents where necessary, ensuring it follows the same path as a
single agent would. The multi-agent maze traversal algorithm is evaluated in
simulations with groups of up to 300 agents, various maze sizes, and multiple
single-agent maze solvers. It is compared against strategies that are na\"ive,
or assume either global communication or full knowledge of the environment. The
algorithm outperforms the na\"ive strategy in terms of makespan and
sum-of-fuel. It is superior to the global-communication strategy in terms of
makespan but is inferior to it in terms of sum-of-fuel. The findings suggest it
is asymptotically equivalent to the full-knowledge strategy with respect to
either metric. Moreover, real-world experiments with up to 20 Pi-puck robots
confirm the feasibility of the approach.

</details>


### [243] [Leveraging Foundation Models for Enhancing Robot Perception and Action](https://arxiv.org/abs/2510.26855)
*Reihaneh Mirjalili*

Main category: cs.RO

TL;DR: Foundation models can enhance robotic capabilities in unstructured environments for localization, interaction, and manipulation.


<details>
  <summary>Details</summary>
Motivation: To systematically leverage foundation models to enhance robotic capabilities in unstructured environments.

Method: The work is structured around four core lines of inquiry, addressing fundamental challenges in robotics.

Result: Enhanced robotic capabilities in localization, interaction, and manipulation.

Conclusion: Foundation models provide a cohesive framework for semantics-aware robotic intelligence.

Abstract: This thesis investigates how foundation models can be systematically
leveraged to enhance robotic capabilities, enabling more effective
localization, interaction, and manipulation in unstructured environments. The
work is structured around four core lines of inquiry, each addressing a
fundamental challenge in robotics while collectively contributing to a cohesive
framework for semantics-aware robotic intelligence.

</details>


### [244] [NaviTrace: Evaluating Embodied Navigation of Vision-Language Models](https://arxiv.org/abs/2510.26909)
*Tim Windecker,Manthan Patel,Moritz Reuss,Richard Schwarzkopf,Cesar Cadena,Rudolf Lioutikov,Marco Hutter,Jonas Frey*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-language models demonstrate unprecedented performance and
generalization across a wide range of tasks and scenarios. Integrating these
foundation models into robotic navigation systems opens pathways toward
building general-purpose robots. Yet, evaluating these models' navigation
capabilities remains constrained by costly real-world trials, overly simplified
simulations, and limited benchmarks. We introduce NaviTrace, a high-quality
Visual Question Answering benchmark where a model receives an instruction and
embodiment type (human, legged robot, wheeled robot, bicycle) and must output a
2D navigation trace in image space. Across 1000 scenarios and more than 3000
expert traces, we systematically evaluate eight state-of-the-art VLMs using a
newly introduced semantic-aware trace score. This metric combines Dynamic Time
Warping distance, goal endpoint error, and embodiment-conditioned penalties
derived from per-pixel semantics and correlates with human preferences. Our
evaluation reveals consistent gap to human performance caused by poor spatial
grounding and goal localization. NaviTrace establishes a scalable and
reproducible benchmark for real-world robotic navigation. The benchmark and
leaderboard can be found at
https://leggedrobotics.github.io/navitrace_webpage/.

</details>


### [245] [Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence](https://arxiv.org/abs/2510.26915)
*Zachary Ravichandran,Fernando Cladera,Ankit Prabhu,Jason Hughes,Varun Murali,Camillo Taylor,George J. Pappas,Vijay Kumar*

Main category: cs.RO

TL;DR: SPINE-HT是一个框架，通过将LLM的推理能力与异构机器人团队结合，解决了在非结构化环境中部署LLM驱动的机器人团队的限制，取得了比以往方法近乎两倍的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）驱动的机器人团队方法通常假设环境是结构良好且已知的，这限制了它们在非结构化、开放世界环境中的应用。本研究旨在弥合这一差距，使机器人团队能够在信息有限且不断变化的环境中执行复杂任务。

Method: SPINE-HT框架通过一个三阶段过程，将LLM的推理能力与异构机器人团队的实际能力相结合：1. LLM根据任务目标和团队能力生成初步的子任务。2. 对生成的子任务进行可行性验证。3. 根据在线运行中收集到的反馈，结合机器人的具体能力（如可通行性、感知能力）对子任务进行分配和优化。

Result: 在仿真实验中，SPINE-HT框架的成功率几乎是先前LLM驱动的异构团队方法的两倍。在包含Clearpath Jackal、Clearpath Husky、Boston Dynamics Spot和高空UAV的真实世界实验中，该方法在需要推理机器人能力和根据在线反馈优化子任务的任务中取得了87%的成功率。

Conclusion: SPINE-HT框架成功地将LLM的通用推理能力与异构机器人团队的物理现实相结合，使其能够在信息不完整和动态变化的非结构化环境中有效执行复杂任务，并且在仿真和真实世界实验中均表现出优越的性能。

Abstract: Heterogeneous robot teams operating in realistic settings often must
accomplish complex missions requiring collaboration and adaptation to
information acquired online. Because robot teams frequently operate in
unstructured environments -- uncertain, open-world settings without prior maps
-- subtasks must be grounded in robot capabilities and the physical world.
While heterogeneous teams have typically been designed for fixed
specifications, generative intelligence opens the possibility of teams that can
accomplish a wide range of missions described in natural language. However,
current large language model (LLM)-enabled teaming methods typically assume
well-structured and known environments, limiting deployment in unstructured
environments. We present SPINE-HT, a framework that addresses these limitations
by grounding the reasoning abilities of LLMs in the context of a heterogeneous
robot team through a three-stage process. Given language specifications
describing mission goals and team capabilities, an LLM generates grounded
subtasks which are validated for feasibility. Subtasks are then assigned to
robots based on capabilities such as traversability or perception and refined
given feedback collected during online operation. In simulation experiments
with closed-loop perception and control, our framework achieves nearly twice
the success rate compared to prior LLM-enabled heterogeneous teaming
approaches. In real-world experiments with a Clearpath Jackal, a Clearpath
Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an
87\% success rate in missions requiring reasoning about robot capabilities and
refining subtasks with online feedback. More information is provided at
https://zacravichandran.github.io/SPINE-HT.

</details>


### [246] [RepV: Safety-Separable Latent Spaces for Scalable Neurosymbolic Plan Verification](https://arxiv.org/abs/2510.26935)
*Yunhao Yang,Neel P. Bhatt,Pranay Samineni,Rohan Siva,Zhanyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: RepV是一个神经符号验证器，它通过学习一个潜在空间来统一形式方法和深度学习的观点，在该空间中，安全和不安全的计划是线性可分离的。它使用一个轻量级的投影仪将每个计划和自然语言规则嵌入到一个低维空间中，然后用一个固定的线性边界来验证合规性。


<details>
  <summary>Details</summary>
Motivation: 在将AI系统迁移到安全关键领域时，验证其行为是否符合明确定义的规则仍然是一个挑战。形式方法提供可证明的保证，但需要手工制作的时间逻辑规范，表达能力和可访问性有限。深度学习方法可以根据自然语言约束来评估计划，但其不透明的决策过程可能导致误分类，并可能产生严重后果。

Method: RepV通过学习一个潜在空间来统一形式方法和深度学习的观点，在该空间中，安全和不安全的计划是线性可分离的。它从一个由现成的模型检查器标记的适度种子计划集开始，RepV训练一个轻量级的投影仪，将每个计划以及语言模型生成的解释嵌入到一个低维空间中；然后，一个固定的线性边界在一次前向传播中验证与看不见的自然语言规则的合规性。

Result: RepV将合规性预测准确率提高了高达15%，同时只增加了不到0.2M的参数。此外，RepV的改进框架在各种规划域上的表现优于普通的微调基线。

Conclusion: 安全可分离的潜在空间为可靠的神经符号计划验证提供了一个可扩展、即插即用的基本工具。

Abstract: As AI systems migrate to safety-critical domains, verifying that their
actions comply with well-defined rules remains a challenge. Formal methods
provide provable guarantees but demand hand-crafted temporal-logic
specifications, offering limited expressiveness and accessibility. Deep
learning approaches enable evaluation of plans against natural-language
constraints, yet their opaque decision process invites misclassifications with
potentially severe consequences. We introduce RepV, a neurosymbolic verifier
that unifies both views by learning a latent space where safe and unsafe plans
are linearly separable. Starting from a modest seed set of plans labeled by an
off-the-shelf model checker, RepV trains a lightweight projector that embeds
each plan, together with a language model-generated rationale, into a
low-dimensional space; a frozen linear boundary then verifies compliance for
unseen natural-language rules in a single forward pass.
  Beyond binary classification, RepV provides a probabilistic guarantee on the
likelihood of correct verification based on its position in the latent space.
This guarantee enables a guarantee-driven refinement of the planner, improving
rule compliance without human annotations. Empirical evaluations show that RepV
improves compliance prediction accuracy by up to 15% compared to baseline
methods while adding fewer than 0.2M parameters. Furthermore, our refinement
framework outperforms ordinary fine-tuning baselines across various planning
domains. These results show that safety-separable latent spaces offer a
scalable, plug-and-play primitive for reliable neurosymbolic plan verification.
Code and data are available at: https://repv-project.github.io/.

</details>


### [247] [A Hermetic, Transparent Soft Growing Vine Robot System for Pipe Inspection](https://arxiv.org/abs/2510.27010)
*William E. Heap,Yimeng Qin,Kai Hammond,Anish Bayya,Haonon Kong,Allison M. Okamura*

Main category: cs.RO

TL;DR: 本研究介绍了一种密封透明的藤蔓状机器人系统，用于在非分支管道内部进行视觉状况评估和测绘。


<details>
  <summary>Details</summary>
Motivation: 老旧管道的修复需要精确评估其内部状况并进行测绘。藤蔓状机器人系统在管道等封闭、弯曲的路径中具有潜力，但目前面临子系统复杂且缺乏实际工业环境验证的限制。

Method: 提出并实现了一种密封透明的藤蔓状机器人系统。该设计将所有机械和电气组件封装在柔软、气密且透明的机器人体内，以保护它们免受环境干扰并实现视觉传感。开发、建模和测试了一种被动适应的封闭式尖端支架，用于容纳传感器。通过在污水管道中进行实际的状况评估和测绘任务来验证该系统。

Result: 成功开发并验证了一个密封透明的藤蔓状机器人系统，可用于管道内部的视觉状况评估和测绘。

Conclusion: 这项工作通过开发和演示一个稳健、简化且经过现场验证的系统，推进了软体藤蔓状机器人在管道检测中的应用，该系统适用于持续开发和部署。

Abstract: Rehabilitation of aging pipes requires accurate condition assessment and
mapping far into the pipe interiors. Soft growing vine robot systems are
particularly promising for navigating confined, sinuous paths such as in pipes,
but are currently limited by complex subsystems and a lack of validation in
real-world industrial settings. In this paper, we introduce the concept and
implementation of a hermetic and transparent vine robot system for visual
condition assessment and mapping within non-branching pipes. This design
encloses all mechanical and electrical components within the vine robot's soft,
airtight, and transparent body, protecting them from environmental interference
while enabling visual sensing. Because this approach requires an enclosed
mechanism for transporting sensors, we developed, modeled, and tested a
passively adapting enclosed tip mount. Finally, we validated the hermetic and
transparent vine robot system concept through a real-world condition assessment
and mapping task in a wastewater pipe. This work advances the use of
soft-growing vine robots in pipe inspection by developing and demonstrating a
robust, streamlined, field-validated system suitable for continued development
and deployment.

</details>


### [248] [A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics](https://arxiv.org/abs/2510.27033)
*Simindokht Jahangard,Mehrzad Mohammadi,Abhinav Dhall,Hamid Rezatofighi*

Main category: cs.RO

TL;DR: 该研究提出了一种新的神经符号框架，用于提高视觉语言模型（VLM）的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在处理需要理解物体之间复杂空间关系的任务时存在局限性，尤其是在机器人领域。

Method: 提出了一种结合全景图像和3D点云信息的神经符号框架，该框架包含一个感知模块（用于检测实体和提取属性）和一个推理模块（用于构建结构化场景图）。

Result: 在JRDB-Reasoning数据集上的评估显示，该方法在拥挤、人造环境中表现出优越的性能和可靠性，同时保持了轻量级设计，适用于机器人和具身人工智能应用。

Conclusion: 该神经符号框架通过结合神经感知和符号推理，显式地对空间和逻辑关系进行建模，有效解决了现有VLM在细粒度空间推理方面的不足。

Abstract: Visual reasoning, particularly spatial reasoning, is a challenging cognitive
task that requires understanding object relationships and their interactions
within complex environments, especially in robotics domain. Existing
vision_language models (VLMs) excel at perception tasks but struggle with
fine-grained spatial reasoning due to their implicit, correlation-driven
reasoning and reliance solely on images. We propose a novel neuro_symbolic
framework that integrates both panoramic-image and 3D point cloud information,
combining neural perception with symbolic reasoning to explicitly model spatial
and logical relationships. Our framework consists of a perception module for
detecting entities and extracting attributes, and a reasoning module that
constructs a structured scene graph to support precise, interpretable queries.
Evaluated on the JRDB-Reasoning dataset, our approach demonstrates superior
performance and reliability in crowded, human_built environments while
maintaining a lightweight design suitable for robotics and embodied AI
applications.

</details>


### [249] [SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation](https://arxiv.org/abs/2510.27048)
*Eric T. Chang,Peter Ballentine,Zhanpeng He,Do-Gon Kim,Kai Jiang,Hua-Hsuan Liang,Joaquin Palacios,William Wang,Pedro Piacenza,Ioannis Kymissis,Matei Ciocarlie*

Main category: cs.RO

TL;DR: SpikeATac是一款集成了压电薄膜（PVDF）和电容传感器的多模态触觉传感器，能够快速、灵敏地检测接触的发生和断开，并可用于精细控制抓取易碎物体，还能通过强化学习实现灵巧手在手中操控易碎物体的新能力。


<details>
  <summary>Details</summary>
Motivation: 为了实现对易碎物体进行精细操控，需要一种能够快速响应并精确控制抓取力的触觉传感器。

Method: 通过结合了高灵敏度的动态响应（PVDF）和静态传感方法（电容式）的SpikeATac触觉传感器，并利用结合了人类反馈的强化学习和基于触觉的奖励来优化抓取策略。

Result: SpikeATac能够快速、灵敏地检测接触，并且在抓取易碎、可变形物体时能够实现快速、精细的力调节。通过学习框架，该传感器使灵巧机器人手能够实现以前无法完成的、涉及易碎物体操控的任务。

Conclusion: SpikeATac硬件平台和学习流程相结合，能够实现灵巧且接触丰富的任务，特别是在手中操控易碎物体方面取得了突破。

Abstract: In this work, we introduce SpikeATac, a multimodal tactile finger combining a
taxelized and highly sensitive dynamic response (PVDF) with a static
transduction method (capacitive) for multimodal touch sensing. Named for its
`spiky' response, SpikeATac's 16-taxel PVDF film sampled at 4 kHz provides
fast, sensitive dynamic signals to the very onset and breaking of contact. We
characterize the sensitivity of the different modalities, and show that
SpikeATac provides the ability to stop quickly and delicately when grasping
fragile, deformable objects. Beyond parallel grasping, we show that SpikeATac
can be used in a learning-based framework to achieve new capabilities on a
dexterous multifingered robot hand. We use a learning recipe that combines
reinforcement learning from human feedback with tactile-based rewards to
fine-tune the behavior of a policy to modulate force. Our hardware platform and
learning pipeline together enable a difficult dexterous and contact-rich task
that has not previously been achieved: in-hand manipulation of fragile objects.
Videos are available at
\href{https://roamlab.github.io/spikeatac/}{roamlab.github.io/spikeatac}.

</details>


### [250] [Learning Generalizable Visuomotor Policy through Dynamics-Alignment](https://arxiv.org/abs/2510.27114)
*Dohyeok Lee,Jung Min Lee,Munkyung Kim,Seokhun Ju,Jin Woo Koo,Kyungjae Lee,Dohyeong Kim,TaeHyun Cho,Jungwoo Lee*

Main category: cs.RO

TL;DR: 行为克隆方法在机器人学习中泛化能力差，因为专家演示数据有限。我们提出了一种动力学对齐流匹配策略（DAP），将动力学预测整合到策略学习中，实现了比基线方法更好的泛化能力，尤其是在存在视觉干扰和光照变化等 OOD 场景下。


<details>
  <summary>Details</summary>
Motivation: 机器人学习中的行为克隆方法由于专家演示数据有限，泛化能力较差。利用视频预测模型的方法虽然可以从大规模数据集中学习丰富的时空表示，但它们学习的动作无关动力学无法区分不同的控制输入，限制了其在精确操作任务中的应用，并且需要大量的预训练数据集。

Method: 我们提出了一种动力学对齐流匹配策略（DAP），该方法将动力学预测整合到策略学习中。我们引入了一种新颖的架构，其中策略和动力学模型在动作生成过程中提供相互的纠正反馈，从而实现自我纠正和提高泛化能力。

Result: 实验验证表明，在真实世界的机器人操作任务中，我们的方法比基线方法具有更优越的泛化性能，尤其在包括视觉干扰和光照变化在内的 OOD 场景下表现出更好的鲁棒性。

Conclusion: DAP 方法通过将动力学预测与策略学习相结合，并利用模型间的相互纠正反馈，能够有效提高机器人学习在真实世界操作任务中的泛化能力，特别是在 OOD 场景下。

Abstract: Behavior cloning methods for robot learning suffer from poor generalization
due to limited data support beyond expert demonstrations. Recent approaches
leveraging video prediction models have shown promising results by learning
rich spatiotemporal representations from large-scale datasets. However, these
models learn action-agnostic dynamics that cannot distinguish between different
control inputs, limiting their utility for precise manipulation tasks and
requiring large pretraining datasets. We propose a Dynamics-Aligned Flow
Matching Policy (DAP) that integrates dynamics prediction into policy learning.
Our method introduces a novel architecture where policy and dynamics models
provide mutual corrective feedback during action generation, enabling
self-correction and improved generalization. Empirical validation demonstrates
generalization performance superior to baseline methods on real-world robotic
manipulation tasks, showing particular robustness in OOD scenarios including
visual distractions and lighting variations.

</details>


### [251] [Confined Space Underwater Positioning Using Collaborative Robots](https://arxiv.org/abs/2510.27151)
*Xueliang Cheng,Kanzhong Yao,Andrew West,Ognjen Marjanovic,Barry Lennox,Keir Groves*

Main category: cs.RO

TL;DR: 水下机器人难以在狭窄、混乱的环境中精确定位，现有系统在工业环境中表现不佳。本文提出了一种名为“协同水下定位”（CAP）的系统，该系统利用“母舰”概念，通过水面车辆（领导者）辅助水下机器人（跟随者）进行定位，即使在无GPS和高度受限的环境中也能实现精确定位。实验证明，CAP系统在大型测试水池中实现了70毫米的平均欧氏距离误差，无需固定基础设施、复杂校准或环境特征，为水下机器人提供了精确、实用且无需基础设施的定位解决方案。


<details>
  <summary>Details</summary>
Motivation: 水下机器人在狭窄、杂乱环境中的定位是一个关键挑战，现有系统在工业环境中存在覆盖范围差、依赖外部设施、需要特征丰富环境等问题，并且多路径效应会降低信号质量，导致精度和可靠性下降。准确且易于部署的定位对于可重复的自主任务至关重要，但目前的技术瓶颈限制了水下机器人的应用。

Method: 提出协同水下定位（CAP）系统，整合了协同机器人和传感器融合技术。借鉴“母舰”概念，使用水面车辆作为移动领导者，辅助水下机器人进行定位，从而在无GPS和高度受限的环境中实现本地化。

Result: 在大型测试水池中通过可重复的自主任务进行了系统验证，利用CAP的定位估计进行实时轨迹控制。实验结果显示，平均欧氏距离（MED）误差为70毫米，实现了实时操作，且无需固定基础设施、大量校准或环境特征。

Conclusion: CAP系统利用了移动机器人传感和领导者-跟随者控制方面的进步，在精确、实用和无需基础设施的水下定位方面取得了突破性进展。

Abstract: Positioning of underwater robots in confined and cluttered spaces remains a
key challenge for field operations. Existing systems are mostly designed for
large, open-water environments and struggle in industrial settings due to poor
coverage, reliance on external infrastructure, and the need for feature-rich
surroundings. Multipath effects from continuous sound reflections further
degrade signal quality, reducing accuracy and reliability. Accurate and easily
deployable positioning is essential for repeatable autonomous missions;
however, this requirement has created a technological bottleneck limiting
underwater robotic deployment. This paper presents the Collaborative Aquatic
Positioning (CAP) system, which integrates collaborative robotics and sensor
fusion to overcome these limitations. Inspired by the "mother-ship" concept,
the surface vehicle acts as a mobile leader to assist in positioning a
submerged robot, enabling localization even in GPS-denied and highly
constrained environments. The system is validated in a large test tank through
repeatable autonomous missions using CAP's position estimates for real-time
trajectory control. Experimental results demonstrate a mean Euclidean distance
(MED) error of 70 mm, achieved in real time without requiring fixed
infrastructure, extensive calibration, or environmental features. CAP leverages
advances in mobile robot sensing and leader-follower control to deliver a step
change in accurate, practical, and infrastructure-free underwater localization.

</details>


### [252] [MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking](https://arxiv.org/abs/2510.27178)
*Xuan-Thuan Nguyen,Khac Nam Nguyen,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Hoang Hiep Ly,Tung D. Ta*

Main category: cs.RO

TL;DR:  MobiDock是一个模块化的、可自重构的机器人系统，通过物理连接将两个独立的机器人整合成一个统一的、具备双臂操作能力的移动平台，从而简化了多机器人协同控制问题，提高了动态稳定性和操作效率。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统（特别是移动机械臂）在协同工作时面临控制协调和动态稳定性的挑战。本研究旨在提出一种解决方案来克服这些挑战。

Method: 提出了一种名为MobiDock的模块化自重构移动机械臂系统。该系统利用基于计算机视觉（AprilTag标记）的自主对接策略和新型螺纹锁紧机制，使两个独立的机器人能够物理连接，形成一个统一的移动双臂平台。这种连接将复杂的多机器人控制问题转化为对单个简单系统的管理。

Result: 实验结果表明，与两个独立协作的机器人相比，对接后的配置在动态稳定性和操作效率方面表现更好。具体而言，统一后的系统具有更低的均方根（RMS）加速度和加加速度值，更高的角精度，并且能显著更快地完成任务。

Conclusion: 物理重构是一种有效的策略，可以简化协作控制，提高复杂任务在真实环境中的稳定性和性能。MobiDock系统证明了这种方法的有效性。

Abstract: Multi-robot systems, particularly mobile manipulators, face challenges in
control coordination and dynamic stability when working together. To address
this issue, this study proposes MobiDock, a modular self-reconfigurable mobile
manipulator system that allows two independent robots to physically connect and
form a unified mobile bimanual platform. This process helps transform a complex
multi-robot control problem into the management of a simpler, single system.
The system utilizes an autonomous docking strategy based on computer vision
with AprilTag markers and a new threaded screw-lock mechanism. Experimental
results show that the docked configuration demonstrates better performance in
dynamic stability and operational efficiency compared to two independently
cooperating robots. Specifically, the unified system has lower Root Mean Square
(RMS) Acceleration and Jerk values, higher angular precision, and completes
tasks significantly faster. These findings confirm that physical
reconfiguration is a powerful design principle that simplifies cooperative
control, improving stability and performance for complex tasks in real-world
environments.

</details>


### [253] [Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets](https://arxiv.org/abs/2510.27184)
*Hoang Hiep Ly,Cong-Nhat Nguyen,Doan-Quang Tran,Quoc-Khanh Dang,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Xuan-Thuan Nguyen,Tung D. Ta*

Main category: cs.RO

TL;DR: 混合夹爪手指结合了刚性外壳和软硅胶口袋，通过控制气压来调节摩擦力，能够安全抓取重、滑、易碎物品。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取重、滑、易碎等具有不同机械特性的物体仍然是一个挑战，传统夹爪需要施加高法向力，可能损坏物体。

Method: 提出一种混合夹爪手指，结合刚性结构外壳和软的、可充气的硅胶口袋。通过控制硅胶口袋的内部气压，主动调节表面摩擦系数。

Result: 实验表明，增加内部气压能正比增加有效摩擦系数。这使得夹爪在不增加抓取力的情况下稳定抓取重、滑物体，并通过增加摩擦力而非过度施力来处理易碎、可变形物体（如鸡蛋、水果、纸杯），减少损坏。

Conclusion: 具有自适应摩擦力的混合夹爪手指为仅依靠高法向力提供了更稳定、更安全的选择，提高了夹爪处理精细、易碎和多样化物体的灵活性。

Abstract: Grasping objects with diverse mechanical properties, such as heavy, slippery,
or fragile items, remains a significant challenge in robotics. Conventional
grippers often rely on applying high normal forces, which can cause damage to
objects. To address this limitation, we present a hybrid gripper finger that
combines a rigid structural shell with a soft, inflatable silicone pocket. The
gripper finger can actively modulate its surface friction by controlling the
internal air pressure of the silicone pocket. Results from fundamental
experiments indicate that increasing the internal pressure results in a
proportional increase in the effective coefficient of friction. This enables
the gripper to stably lift heavy and slippery objects without increasing the
gripping force and to handle fragile or deformable objects, such as eggs,
fruits, and paper cups, with minimal damage by increasing friction rather than
applying excessive force. The experimental results demonstrate that the hybrid
gripper finger with adaptable friction provides a robust and safer alternative
to relying solely on high normal forces, thereby enhancing the gripper
flexibility in handling delicate, fragile, and diverse objects.

</details>


### [254] [Vectorized Online POMDP Planning](https://arxiv.org/abs/2510.27191)
*Marcus Hoerger,Muhammad Sudrajat,Hanna Kurniawati*

Main category: cs.RO

TL;DR: VOPP是一个新型并行在线POMDP求解器，通过向量化计算和张量表示，实现了大规模并行，比现有求解器效率高20倍以上。


<details>
  <summary>Details</summary>
Motivation: 规划在部分可观察性下是自主机器人的基本能力，POMDP是解决此类问题的有效框架，但现有并行化方法存在挑战。

Method: 提出了一种名为VOPP的新型并行在线求解器，该求解器利用一种新的POMDP模型，将部分优化解析化，其余部分通过向量化计算实现。

Result: 实验结果表明，VOPP在计算近似最优解方面比现有的最先进的并行在线求解器效率至少高20倍。

Conclusion: VOPP通过其独特的向量化方法解决了并行化POMDP求解器的瓶颈问题，显著提高了效率。

Abstract: Planning under partial observability is an essential capability of autonomous
robots. The Partially Observable Markov Decision Process (POMDP) provides a
powerful framework for planning under partial observability problems, capturing
the stochastic effects of actions and the limited information available through
noisy observations. POMDP solving could benefit tremendously from massive
parallelization of today's hardware, but parallelizing POMDP solvers has been
challenging. They rely on interleaving numerical optimization over actions with
the estimation of their values, which creates dependencies and synchronization
bottlenecks between parallel processes that can quickly offset the benefits of
parallelization. In this paper, we propose Vectorized Online POMDP Planner
(VOPP), a novel parallel online solver that leverages a recent POMDP
formulation that analytically solves part of the optimization component,
leaving only the estimation of expectations for numerical computation. VOPP
represents all data structures related to planning as a collection of tensors
and implements all planning steps as fully vectorized computations over this
representation. The result is a massively parallel solver with no dependencies
and synchronization bottlenecks between parallel computations. Experimental
results indicate that VOPP is at least 20X more efficient in computing
near-optimal solutions compared to an existing state-of-the-art parallel online
solver.

</details>


### [255] [A Modular and Scalable System Architecture for Heterogeneous UAV Swarms Using ROS 2 and PX4-Autopilot](https://arxiv.org/abs/2510.27327)
*Robert Pommeranz,Kevin Tebbe,Ralf Heynicke,Gerd Scholl*

Main category: cs.RO

TL;DR: 该论文提出了一种基于PX4和ROS 2的模块化、可扩展的异构蜂拥C-UAS架构，支持硬件集成、通信抽象、编队飞行和计算机视觉集成，并在模拟和现实世界中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是提出一种模块化、可扩展的架构，用于异构蜂拥C-UAS，以实现无缝的硬件集成和灵活的通信。

Method: 该架构在PX4-Autopilot和ROS 2框架之上构建，为UAV的每个组件引入独立的ROS 2节点。通信在软件中进行了抽象，并支持领导者跟随和编队飞行等功能。该系统还集成了计算机视觉算法和地面站控制。

Result: 该系统已在Gazebo模拟环境中得到验证，并成功进行了现实世界的演示。

Conclusion: 该论文提出了一种在PX4和ROS 2框架上构建的模块化、可扩展的异构蜂拥C-UAS架构，并成功进行了验证。

Abstract: In this paper a modular and scalable architecture for heterogeneous
swarm-based Counter Unmanned Aerial Systems (C-UASs) built on PX4-Autopilot and
Robot Operating System 2 (ROS 2) framework is presented. The proposed
architecture emphasizes seamless integration of hardware components by
introducing independent ROS 2 nodes for each component of a Unmanned Aerial
Vehicle (UAV). Communication between swarm participants is abstracted in
software, allowing the use of various technologies without architectural
changes. Key functionalities are supported, e.g. leader following and formation
flight to maneuver the swarm. The system also allows computer vision algorithms
to be integrated for the detection and tracking of UAVs. Additionally, a ground
station control is integrated for the coordination of swarm operations.
Swarm-based Unmanned Aerial System (UAS) architecture is verified within a
Gazebo simulation environment but also in real-world demonstrations.

</details>


### [256] [Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict](https://arxiv.org/abs/2510.27333)
*Hao Cheng,Yanbo Jiang,Qingyuan Shi,Qingwen Meng,Keyu Chen,Wenhao Yu,Jianqiang Wang,Sifa Zheng*

Main category: cs.RO

TL;DR: 该论文提出了一种名为MEI（Modified-Emergency Index）的新型风险评估指标，用于量化自动驾驶汽车在城市环境中的横向冲突风险。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶安全评估指标主要关注纵向冲突，难以准确量化城市环境中普遍存在的横向冲突风险。

Method: 提出MEI指标，改进了对横向规避机动可用时间的估计，从而更精确地量化风险。在Argoverse-2公开数据集上进行了验证，提取了1500多个高质量的AV冲突案例，包括500多个关键事件。

Result: 与ACT和PET等现有指标相比，MEI在准确量化危险程度和捕捉风险演变方面表现更优。

Conclusion: MEI是评估城市冲突和提高自动驾驶安全评估框架的一个有前景的指标。

Abstract: Effective, reliable, and efficient evaluation of autonomous driving safety is
essential to demonstrate its trustworthiness. Criticality metrics provide an
objective means of assessing safety. However, as existing metrics primarily
target longitudinal conflicts, accurately quantifying the risks of lateral
conflicts - prevalent in urban settings - remains challenging. This paper
proposes the Modified-Emergency Index (MEI), a metric designed to quantify
evasive effort in lateral conflicts. Compared to the original Emergency Index
(EI), MEI refines the estimation of the time available for evasive maneuvers,
enabling more precise risk quantification. We validate MEI on a public lateral
conflict dataset based on Argoverse-2, from which we extract over 1,500
high-quality AV conflict cases, including more than 500 critical events. MEI is
then compared with the well-established ACT and the widely used PET metrics.
Results show that MEI consistently outperforms them in accurately quantifying
criticality and capturing risk evolution. Overall, these findings highlight MEI
as a promising metric for evaluating urban conflicts and enhancing the safety
assessment framework for autonomous driving. The open-source implementation is
available at https://github.com/AutoChengh/MEI.

</details>


### [257] [Towards a Multi-Embodied Grasping Agent](https://arxiv.org/abs/2510.27420)
*Roman Freiberg,Alexander Qualmann,Ngo Anh Vien,Gerhard Neumann*

Main category: cs.RO

TL;DR: 该研究提出了一种数据高效、基于流、等变抓取合成架构，能够处理具有不同自由度的不同夹持器类型，并仅从夹持器和场景几何形状中提取所有必要信息。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在机器人运动学结构学习和大规模数据获取方面的挑战，实现跨多种夹持器设计的通用抓取。

Method: 开发了一种数据高效、基于流、等变抓取合成架构，该架构具有批处理能力，可在场景、夹持器和抓取上进行批处理，并利用夹持器和场景几何来推断运动学信息。

Result: 通过在包含人形手到平行偏航夹持器的数据集上进行训练，该模型在处理不同夹持器类型和实现更平滑的学习、提高性能和缩短推理时间方面表现出色。

Conclusion: 提出的方法能够有效地处理多种夹持器设计，并能从几何信息中学习，而无需显式运动学模型，这在数据效率和性能方面都有显著改进。

Abstract: Multi-embodiment grasping focuses on developing approaches that exhibit
generalist behavior across diverse gripper designs. Existing methods often
learn the kinematic structure of the robot implicitly and face challenges due
to the difficulty of sourcing the required large-scale data. In this work, we
present a data-efficient, flow-based, equivariant grasp synthesis architecture
that can handle different gripper types with variable degrees of freedom and
successfully exploit the underlying kinematic model, deducing all necessary
information solely from the gripper and scene geometry. Unlike previous
equivariant grasping methods, we translated all modules from the ground up to
JAX and provide a model with batching capabilities over scenes, grippers, and
grasps, resulting in smoother learning, improved performance and faster
inference time. Our dataset encompasses grippers ranging from humanoid hands to
parallel yaw grippers and includes 25,000 scenes and 20 million grasps.

</details>


### [258] [Learning Soft Robotic Dynamics with Active Exploration](https://arxiv.org/abs/2510.27428)
*Hehui Zheng,Bhavya Sukhija,Chenhao Li,Klemens Iten,Andreas Krause,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 该研究提出了一种名为SoftAE的主动探索框架，用于学习软体机器人的通用动力学模型，提高了控制效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 软体机器人在非结构化环境中具有优势，但其复杂动力学特性给建模和控制带来挑战。现有数据驱动方法泛化能力有限。

Method: SoftAE利用概率集成模型来估计不确定性，并主动引导探索到状态-动作空间中代表性不足的区域，以高效地覆盖各种行为。

Result: SoftAE在模拟和真实世界的软体机器人平台上进行了评估，结果表明该方法生成的动力学模型更准确，在未见过的任务上实现了更优的零样本控制，并在存在传感噪声、执行延迟和非线性材料效应的情况下保持了鲁棒性。

Conclusion: 研究结果表明，由不确定性驱动的主动探索可以为各种软体机器人形态生成可扩展、可重用的动力学模型，这是实现更自主、更自适应、数据更高效的柔性机器人控制的重要一步。

Abstract: Soft robots offer unmatched adaptability and safety in unstructured
environments, yet their compliant, high-dimensional, and nonlinear dynamics
make modeling for control notoriously difficult. Existing data-driven
approaches often fail to generalize, constrained by narrowly focused task
demonstrations or inefficient random exploration. We introduce SoftAE, an
uncertainty-aware active exploration framework that autonomously learns
task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE
employs probabilistic ensemble models to estimate epistemic uncertainty and
actively guides exploration toward underrepresented regions of the state-action
space, achieving efficient coverage of diverse behaviors without task-specific
supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a
continuum arm, an articulated fish in fluid, and a musculoskeletal leg with
hybrid actuation -- and on a pneumatically actuated continuum soft arm in the
real world. Compared with random exploration and task-specific model-based
reinforcement learning, SoftAE produces more accurate dynamics models, enables
superior zero-shot control on unseen tasks, and maintains robustness under
sensing noise, actuation delays, and nonlinear material effects. These results
demonstrate that uncertainty-driven active exploration can yield scalable,
reusable dynamics models across diverse soft robotic morphologies, representing
a step toward more autonomous, adaptable, and data-efficient control in
compliant robots.

</details>


### [259] [Preliminary Prototyping of Avoidance Behaviors Triggered by a User's Physical Approach to a Robot](https://arxiv.org/abs/2510.27436)
*Tomoko Yonezawa,Hirotake Yamazoe,Atsuo Fujino,Daigo Suhara,Takaya Tamamoto,Yuto Nishiguchi*

Main category: cs.RO

TL;DR: 当人类靠近时，机器人会通过撤回或推开等行为来拒绝，其不适感是根据人际距离、容忍度和PAD模型中的主导性轴来建模的。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索机器人在与人类近距离互动时，如何像人类一样灵活地接受、拒绝或容忍对方的靠近。

Method: 本研究模拟了不适感的累积和衰减，并将其作为人际距离的函数。同时，研究实现了由PAD情感模型中的主导性轴驱动的容忍（忍耐）和超出限制的回避行为，并将这些行为及其强度应用在一个机械臂机器人上。

Result: 实验结果展示了一个从内部状态参数到不同程度的忍耐动作，以及在超过限制后触发回避动作的完整流程。

Conclusion: 本研究成功设计并实现了一种机器人的拒绝内部状态和相应的回避行为，为实现更自然的人机交互提供了新的思路。

Abstract: Human-robot interaction frequently involves physical proximity or contact. In
human-human settings, people flexibly accept, reject, or tolerate such
approaches depending on the relationship and context. We explore the design of
a robot's rejective internal state and corresponding avoidance behaviors, such
as withdrawing or pushing away, when a person approaches. We model the
accumulation and decay of discomfort as a function of interpersonal distance,
and implement tolerance (endurance) and limit-exceeding avoidance driven by the
Dominance axis of the PAD affect model. The behaviors and their intensities are
realized on an arm robot. Results illustrate a coherent pipeline from internal
state parameters to graded endurance motions and, once a limit is crossed, to
avoidance actions.

</details>


### [260] [EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities](https://arxiv.org/abs/2510.27545)
*Travis Davies,Yiqi Huang,Alexi Gladstone,Yunxin Liu,Xiang Chen,Heng Ji,Huxian Liu,Luhui Hu*

Main category: cs.RO

TL;DR: EBT-Policy是一种新的基于能量的模型架构，在机器人任务中表现优于扩散策略，具有计算效率高、泛化能力强和零样本恢复能力等优点。


<details>
  <summary>Details</summary>
Motivation: 现有的基于生成模型的隐式策略（如扩散策略）存在计算成本高、暴露偏差大和推理不稳定等问题，导致在分布变化下出现分歧。虽然能量模型（EBMs）可以解决这些问题，但它们难以有效扩展。基于能量的Transformer（EBTs）虽然解决了可扩展性问题，但在物理实体模型中的应用仍未被充分探索。

Method: 提出了一种新的基于能量的模型架构EBT-Policy，用于解决机器人和现实世界任务中的核心问题。

Result: EBT-Policy在模拟和现实世界的任务中始终优于基于扩散的策略，并且需要的训练和推理计算更少。在某些任务上，EBT-Policy仅用两次推理步骤即可收敛，比扩散策略的100步减少了50倍。此外，EBT-Policy还展现出了一些先前模型未曾出现过的涌现能力，例如仅通过模仿学习就能从失败的动作序列中进行零样本恢复，而无需进行显式的重试训练。通过利用其标量能量进行不确定性感知推理和动态计算分配，EBT-Policy为在分布变化下实现鲁棒、可泛化的机器人行为提供了一条有前景的途径。

Conclusion: EBT-Policy通过利用其标量能量进行不确定性感知推理和动态计算分配，为在分布变化下实现鲁棒、可泛化的机器人行为提供了一条有前景的途径。

Abstract: Implicit policies parameterized by generative models, such as Diffusion
Policy, have become the standard for policy learning and Vision-Language-Action
(VLA) models in robotics. However, these approaches often suffer from high
computational cost, exposure bias, and unstable inference dynamics, which lead
to divergence under distribution shifts. Energy-Based Models (EBMs) address
these issues by learning energy landscapes end-to-end and modeling equilibrium
dynamics, offering improved robustness and reduced exposure bias. Yet, policies
parameterized by EBMs have historically struggled to scale effectively. Recent
work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs
to high-dimensional spaces, but their potential for solving core challenges in
physically embodied models remains underexplored. We introduce a new
energy-based architecture, EBT-Policy, that solves core issues in robotic and
real-world settings. Across simulated and real-world tasks, EBT-Policy
consistently outperforms diffusion-based policies, while requiring less
training and inference computation. Remarkably, on some tasks it converges
within just two inference steps, a 50x reduction compared to Diffusion Policy's
100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior
models, such as zero-shot recovery from failed action sequences using only
behavior cloning and without explicit retry training. By leveraging its scalar
energy for uncertainty-aware inference and dynamic compute allocation,
EBT-Policy offers a promising path toward robust, generalizable robot behavior
under distribution shifts.

</details>


### [261] [Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs](https://arxiv.org/abs/2510.27558)
*Sushil Samuel Dinesh,Shinkyu Park*

Main category: cs.RO

TL;DR: 该框架利用预训练的基础模型进行机器人操作，无需领域特定训练。


<details>
  <summary>Details</summary>
Motivation: 提出一个不需领域特定训练的、可直接在现成的基础模型之上构建的机器人操作框架。

Method: 结合使用基础模型的多模态感知能力和一个通用的、能够进行鲁棒任务排序的推理模型，并通过动态维护的场景图来提供空间感知和环境一致性推理。

Result: 在一系列桌面机器人操作实验中进行了评估，结果表明了该框架的潜力。

Conclusion: 该框架有潜力直接在现成的基础模型之上构建机器人操作系统。

Abstract: This paper presents a framework that leverages pre-trained foundation models
for robotic manipulation without domain-specific training. The framework
integrates off-the-shelf models, combining multimodal perception from
foundation models with a general-purpose reasoning model capable of robust task
sequencing. Scene graphs, dynamically maintained within the framework, provide
spatial awareness and enable consistent reasoning about the environment. The
framework is evaluated through a series of tabletop robotic manipulation
experiments, and the results highlight its potential for building robotic
manipulation systems directly on top of off-the-shelf foundation models.

</details>


### [262] [Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping](https://arxiv.org/abs/2510.27666)
*Dong Heon Han,Xiaohao Xu,Yuxi Chen,Yusheng Zhou,Xinqi Zhang,Jiaqi Wang,Daniel Bruder,Xiaonan Huang*

Main category: cs.RO

TL;DR: 受章鱼生物力学启发，提出一种模块化软体抓手，通过分布式气动驱动和集成传感实现全身协同变形，以适应不同形状和尺寸的物体。


<details>
  <summary>Details</summary>
Motivation: 章鱼等生物能通过重构整个形态实现跨尺度的操控，这在机器人领域仍具挑战性。传统软体抓手受限于固定形态，且以往的变形研究多局限于局部，未能达到生物的灵活性。

Method: 提出一种模块化软体抓手架构，采用分布式自感知气动执行器网络，实现抓手整体拓扑结构的智能重构，可形成多种多边形状态。通过集成丰富的本体感觉反馈，系统能在精确捏取和大范围抓取间无缝切换。

Result: 实验证明，该方法扩大了抓取范围，提高了对不同几何形状（标准和不规则）及尺寸（高达10倍）物体的适应性，并实现了多物体抓取和内部钩抓等新型操控模式。

Conclusion: 该工作提出了一种低成本、易于制造且可扩展的框架，融合了分布式驱动和集成传感，为实现生物水平的机器人操控提供了新途径。

Abstract: Biological systems, such as the octopus, exhibit masterful cross-scale
manipulation by adaptively reconfiguring their entire form, a capability that
remains elusive in robotics. Conventional soft grippers, while compliant, are
mostly constrained by a fixed global morphology, and prior shape-morphing
efforts have been largely confined to localized deformations, failing to
replicate this biological dexterity. Inspired by this natural exemplar, we
introduce the paradigm of collaborative, whole-body proprioceptive morphing,
realized in a modular soft gripper architecture. Our design is a distributed
network of modular self-sensing pneumatic actuators that enables the gripper to
intelligently reconfigure its entire topology, achieving multiple morphing
states that are controllable to form diverse polygonal shapes. By integrating
rich proprioceptive feedback from embedded sensors, our system can seamlessly
transition from a precise pinch to a large envelope grasp. We experimentally
demonstrate that this approach expands the grasping envelope and enhances
generalization across diverse object geometries (standard and irregular) and
scales (up to 10$\times$), while also unlocking novel manipulation modalities
such as multi-object and internal hook grasping. This work presents a low-cost,
easy-to-fabricate, and scalable framework that fuses distributed actuation with
integrated sensing, offering a new pathway toward achieving biological levels
of dexterity in robotic manipulation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [263] [Choreographer: A Full-System Framework for Fine-Grained Tasks in Cache Hierarchies](https://arxiv.org/abs/2510.26944)
*Hoa Nguyen,Pongstorn Maidee,Jason Lowe-Power,Alireza Kaviani*

Main category: cs.AR

TL;DR: Choreographer是一个模拟框架，用于评估细粒度加速器在延迟敏感任务中的系统级性能。它集成了硬件和软件栈，可以捕获硬件和软件开销，并提供详细的缓存模型，以实现快速原型设计。通过对数据感知预取器和快速排序加速器的评估，证明了该框架能够对复杂的软硬件交互进行建模并优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模拟框架无法完全捕捉细粒度加速器在延迟敏感任务中的硬件和软件开销，特别是核心-加速器和缓存-加速器交互中的开销。

Method: Choreographer框架集成了一个基于gem5的详细硬件堆栈，包括AMBA相干集线器接口（CHI）网格网络，以及一个完整的基于Linux的软件栈。它提供了一个C++应用程序接口和模块化的配置选项，并包含一个详细的缓存模型，以准确洞察由缓存配置引起但其他框架未捕捉到的性能变化。

Result: 通过对数据感知预取器和快速排序加速器的案例研究，评估结果显示预取器通过减少内存访问延迟实现了1.08倍至1.88倍的加速，而快速排序加速器则实现了超过2倍的加速，同时地址转换开销极小。

Conclusion: Choreographer框架能够有效地模拟复杂的软硬件交互，并为小型任务卸载场景提供性能优化。

Abstract: In this paper, we introduce Choreographer, a simulation framework that
enables a holistic system-level evaluation of fine-grained accelerators
designed for latency-sensitive tasks. Unlike existing frameworks, Choreographer
captures all hardware and software overheads in core-accelerator and
cache-accelerator interactions, integrating a detailed gem5-based hardware
stack featuring an AMBA coherent hub interface (CHI) mesh network and a
complete Linux-based software stack. To facilitate rapid prototyping, it offers
a C++ application programming interface and modular configuration options. Our
detailed cache model provides accurate insights into performance variations
caused by cache configurations, which are not captured by other frameworks. The
framework is demonstrated through two case studies: a data-aware prefetcher for
graph analytics workloads, and a quicksort accelerator. Our evaluation shows
that the prefetcher achieves speedups between 1.08x and 1.88x by reducing
memory access latency, while the quicksort accelerator delivers more than 2x
speedup with minimal address translation overhead. These findings underscore
the ability of Choreographer to model complex hardware-software interactions
and optimize performance in small task offloading scenarios.

</details>


### [264] [Practical Timing Closure in FPGA and ASIC Designs: Methods, Challenges, and Case Studies](https://arxiv.org/abs/2510.26985)
*Mostafa Darvishi*

Main category: cs.AR

TL;DR: ASIC 比 FPGA 在时序上表现更好，但 FPGA 仍然具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在深入分析FPGA和ASIC在时序收敛方面的挑战和约束，比较两者的设计方法和性能。

Method: 通过对比分析Xilinx Kintex UltraScale+ FPGA (XCKU040) 和 7nm ASIC 的设计，并进行实际时序分析和性能权衡。

Result: ASIC 在设置时间和保持时间上分别优于 FPGA 45ps 和 35ps，而 FPGA 的设置时间为 180ps，保持时间为 120ps。

Conclusion: ASIC 在时序方面具有优势，但现代 FPGA 在高性能设计方面仍然具有竞争力。

Abstract: This paper presents an in-depth analysis of timing closure challenges and
constraints in Field Programmable Gate Arrays (FPGAs) and Application Specific
Integrated Circuits (ASICs). We examine core timing principles, architectural
distinctions, and design methodologies influencing timing behavior in both
technologies. A case study comparing the Xilinx Kintex UltraScale+ FPGA
(XCKU040) with a 7nm ASIC highlights practical timing analysis and performance
trade-offs. Experimental results show ASICs achieve superior timing of 45ps
setup and 35ps hold, while modern FPGAs remain competitive with 180ps setup and
120ps hold times, validating their suitability for high-performance designs.

</details>


### [265] [Descriptor-Based Object-Aware Memory Systems: A Comprehensive Review](https://arxiv.org/abs/2510.27070)
*Dong Tong*

Main category: cs.AR

TL;DR: 本篇论文提出并调研了描述符驱动的、面向对象的内存系统，以解决当前计算系统中硬件与软件语义鸿沟的问题。


<details>
  <summary>Details</summary>
Motivation: 当前计算系统缺乏原生架构机制来传递高级程序语义（如对象标识、边界和生命周期），从而损害了系统的安全性和效率。

Method: 通过将描述符提升为一流的架构抽象，使硬件能够动态地获取和强制执行软件定义对象的丰富语义。论文系统地梳理了该方法学的演变和现状，建立了内存对象和描述符的基础概念，并引入了描述符寻址模式的新分类法，为分析和比较不同实现提供了结构化框架。

Result: 该范式整体解决了内存保护、管理和处理的相互关联的挑战。通过 CentroID 模型案例研究，展示了其混合标签指针编码和描述符处理机制如何实现实用且高效的面向对象设计。

Conclusion: 明确的跨层对象语义通信为下一代缓存层次结构、统一虚拟内存甚至 128 位体系结构提供了基础研究方向。

Abstract: The security and efficiency of modern computing systems are fundamentally
undermined by the absence of a native architectural mechanism to propagate
high-level program semantics, such as object identity, bounds, and lifetime,
across the hardware/software interface. This paper presents a comprehensive
survey of the architectural paradigm designed to bridge this semantic gap:
descriptor-based, object-aware memory systems. By elevating the descriptor to a
first-class architectural abstraction, this paradigm enables hardware to
dynamically acquire and enforce the rich semantics of software-defined objects.
This survey systematically charts the evolution and current landscape of this
approach. We establish the foundational concepts of memory objects and
descriptors and introduce a novel taxonomy of descriptor addressing modes,
providing a structured framework for analyzing and comparing diverse
implementations. Our unified analysis reveals how this paradigm holistically
addresses the intertwined challenges of memory protection, management, and
processing. As a culminating case study, we re-examine the CentroID model,
demonstrating how its hybrid tagged-pointer encoding and descriptor processing
mechanisms embody the path toward practical and efficient object-aware designs.
Finally, we outline how the explicit cross-layer communication of object
semantics provides a foundational research direction for next-generation cache
hierarchies, unified virtual memory, and even 128-bit architectures.

</details>


### [266] [A Memory-Efficient Retrieval Architecture for RAG-Enabled Wearable Medical LLMs-Agents](https://arxiv.org/abs/2510.27107)
*Zhipeng Liao,Kunming Shao,Jiangnan Yu,Liang Zhao,Tim Kwang-Ting Cheng,Chi-Ying Tsui,Jie Yang,Mohamad Sawan*

Main category: cs.AR

TL;DR: 本文提出了一种用于边缘设备的RAG分层检索架构，通过两阶段检索（近似检索+精确定位）显著降低了内存访问和能耗，同时保持了检索准确性。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署医疗AI代理以保护隐私，但现有的RAG实现会带来高昂的内存访问和能耗。

Method: 提出了一种分层检索架构，采用两阶段检索方案：首先使用近似检索生成候选集，然后对预选的文档嵌入进行高精度检索。

Result: 与纯INT8检索相比，该架构将内存访问减少了近50%，计算量减少了75%，1MB数据检索的总能耗为177.76 μJ/查询（TSMC 28nm工艺）。

Conclusion: 所提出的分层检索架构能够有效解决边缘RAG的能耗和内存访问问题，为在资源受限的边缘设备上部署定制化医疗AI代理提供了可行的解决方案。

Abstract: With powerful and integrative large language models (LLMs), medical AI agents
have demonstrated unique advantages in providing personalized medical
consultations, continuous health monitoring, and precise treatment plans.
Retrieval-Augmented Generation (RAG) integrates personal medical documents into
LLMs by an external retrievable database to address the costly retraining or
fine-tuning issues in deploying customized agents. While deploying medical
agents in edge devices ensures privacy protection, RAG implementations impose
substantial memory access and energy consumption during the retrieval stage.
This paper presents a hierarchical retrieval architecture for edge RAG,
leveraging a two-stage retrieval scheme that combines approximate retrieval for
candidate set generation, followed by high-precision retrieval on pre-selected
document embeddings. The proposed architecture significantly reduces energy
consumption and external memory access while maintaining retrieval accuracy.
Simulation results show that, under TSMC 28nm technology, the proposed
hierarchical retrieval architecture has reduced the overall memory access by
nearly 50% and the computation by 75% compared to pure INT8 retrieval, and the
total energy consumption for 1 MB data retrieval is 177.76 {\mu}J/query.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [267] [Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning](https://arxiv.org/abs/2510.26829)
*Svetlana Churina,Niranjan Chebrolu,Kokil Jaidka*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) continually evolve through pre-training on
ever-expanding web data, but this adaptive process also exposes them to subtle
forms of misinformation. While prior work has explored data poisoning during
static pre-training, the effects of such manipulations under continual
pre-training remain largely unexplored. Drawing inspiration from the illusory
truth effect in human cognition - where repeated exposure to falsehoods
increases belief in their accuracy - we ask whether LLMs exhibit a similar
vulnerability. We investigate whether repeated exposure to false but
confidently stated facts can shift a model's internal representation away from
the truth.
  We introduce Layer of Truth, a framework and dataset for probing belief
dynamics in continually trained LLMs. By injecting controlled amounts of
poisoned data and probing intermediate representations across checkpoints,
model scales, and question types, we quantify when and how factual beliefs
shift. Our findings reveal that even minimal exposure can induce persistent
representational drift in well-established facts, with susceptibility varying
across layers and model sizes. These results highlight an overlooked
vulnerability of continually updated LLMs: their capacity to internalize
misinformation analogously to humans, underscoring the need for robust
monitoring of factual integrity during model updates.

</details>


### [268] [SmoothGuard: Defending Multimodal Large Language Models with Noise Perturbation and Clustering Aggregation](https://arxiv.org/abs/2510.26830)
*Guangzhi Su,Shuchang Huang,Yutong Ke,Zhuohang Liu,Long Qian,Kaizhu Huang*

Main category: cs.LG

TL;DR: MLLMs易受对抗性攻击，SmoothGuard通过注入随机噪声和聚类预测来增强其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在面对对抗性攻击时非常脆弱，需要提高其安全性和可靠性。

Method: SmoothGuard通过向连续模态（如图像和音频）注入高斯噪声，生成多个候选输出，并使用基于嵌入的聚类来过滤掉受对抗性影响的预测，最终从多数聚类中选择答案。

Result: 在POPE、LLaVA-Bench (In-the-Wild)和MM-SafetyBench上的实验表明，SmoothGuard在提高模型对抗攻击的韧性的同时，保持了竞争力。

Conclusion: SmoothGuard是一个轻量级、模型无关的防御框架，可以有效提高MLLMs在对抗性攻击下的鲁棒性，并且通过对噪声范围的研究，找到了一个平衡鲁棒性和效用的最佳范围（0.1-0.2）。

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance
across diverse tasks by jointly reasoning over textual and visual inputs.
Despite their success, these models remain highly vulnerable to adversarial
manipulations, raising concerns about their safety and reliability in
deployment. In this work, we first generalize an approach for generating
adversarial images within the HuggingFace ecosystem and then introduce
SmoothGuard, a lightweight and model-agnostic defense framework that enhances
the robustness of MLLMs through randomized noise injection and clustering-based
prediction aggregation. Our method perturbs continuous modalities (e.g., images
and audio) with Gaussian noise, generates multiple candidate outputs, and
applies embedding-based clustering to filter out adversarially influenced
predictions. The final answer is selected from the majority cluster, ensuring
stable responses even under malicious perturbations. Extensive experiments on
POPE, LLaVA-Bench (In-the-Wild), and MM-SafetyBench demonstrate that
SmoothGuard improves resilience to adversarial attacks while maintaining
competitive utility. Ablation studies further identify an optimal noise range
(0.1-0.2) that balances robustness and utility.

</details>


### [269] [Accurate Target Privacy Preserving Federated Learning Balancing Fairness and Utility](https://arxiv.org/abs/2510.26841)
*Kangkang Sun,Jun Wu,Minyi Guo,Jianhua Li,Jianwei Huang*

Main category: cs.LG

TL;DR: FedPF是一种差分隐私联邦学习算法，通过将多目标优化转化为零和博弈来平衡公平性、隐私性和模型效用，揭示了隐私和公平性之间的固有权衡。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，参与者面临着在不共享数据的情况下，同时确保跨人口统计群体的公平性并保护敏感客户数据的挑战。

Method: 提出了一种差分隐私联邦学习算法（FedPF），将多目标优化问题转化为一个零和博弈，其中公平性和隐私约束与模型效用相互竞争。

Result: 实验验证表明，在保持可观准确率的同时，可以将三个数据集的歧视减少高达42.9%。更重要的是，研究发现隐私-公平性之间的权衡是不可避免的，需要仔细平衡的妥协，而不是孤立地优化任何一个目标。

Conclusion: 隐私和公平性之间的权衡是联邦学习中的一个基本挑战，更严格的隐私保护会限制系统检测和纠正人口统计偏差的能力。研究还发现，公平性约束与模型泛化能力之间存在非单调关系，这与关于公平性-效用权衡的传统观念相悖。

Abstract: Federated Learning (FL) enables collaborative model training without data
sharing, yet participants face a fundamental challenge, e.g., simultaneously
ensuring fairness across demographic groups while protecting sensitive client
data. We introduce a differentially private fair FL algorithm (\textit{FedPF})
that transforms this multi-objective optimization into a zero-sum game where
fairness and privacy constraints compete against model utility. Our theoretical
analysis reveals a surprising inverse relationship, i.e., stricter privacy
protection fundamentally limits the system's ability to detect and correct
demographic biases, creating an inherent tension between privacy and fairness.
Counterintuitively, we prove that moderate fairness constraints initially
improve model generalization before causing performance degradation, where a
non-monotonic relationship that challenges conventional wisdom about
fairness-utility tradeoffs. Experimental validation demonstrates up to 42.9 %
discrimination reduction across three datasets while maintaining competitive
accuracy, but more importantly, reveals that the privacy-fairness tension is
unavoidable, i.e., achieving both objectives simultaneously requires carefully
balanced compromises rather than optimization of either in isolation. The
source code for our proposed algorithm is publicly accessible at
https://github.com/szpsunkk/FedPF.

</details>


### [270] [Learning Sparse Approximate Inverse Preconditioners for Conjugate Gradient Solvers on GPUs](https://arxiv.org/abs/2510.27517)
*Zherui Yang,Zhehao Li,Kangbo Lyu,Yixuan Li,Tao Du,Ligang Liu*

Main category: cs.LG

TL;DR: 提出一种基于图神经网络（GNN）的稀疏近似逆（SPAI）预处理方法，用于生成GPU友好的预处理器，以加速求解线性方程组Ax=b。


<details>
  <summary>Details</summary>
Motivation: 传统预处理器虽然有理论保证，但难以利用数据进行优化；基于GNN的方法存在三角求解拖慢GPU并行效率和长距离依赖难以建模的问题。现有方法难以完全利用GPU的并行计算能力。

Method: 提出一种基于GNN的SPAI预处理器，避免了三角求解，每次CG迭代仅需两次矩阵向量乘积，符合GNN的局部传播机制。引入统计基数的尺度不变损失函数，匹配CG收敛率与条件数的关系。

Result: 在三个偏微分方程（PDE）数据集和一个合成数据集上，该方法优于传统的对角线、不完全乔列斯分解（IC）和SPAI预处理器，以及之前基于学习的预处理器。在GPU上将求解时间缩短了40%-53%（速度提升68%-113%），同时获得了更好的条件数和泛化性能。

Conclusion: 所提出的基于GNN的SPAI预处理器在GPU上实现了更快的求解速度和更好的性能，有效解决了现有方法的局限性。

Abstract: The conjugate gradient solver (CG) is a prevalent method for solving
symmetric and positive definite linear systems Ax=b, where effective
preconditioners are crucial for fast convergence. Traditional preconditioners
rely on prescribed algorithms to offer rigorous theoretical guarantees, while
limiting their ability to exploit optimization from data. Existing
learning-based methods often utilize Graph Neural Networks (GNNs) to improve
the performance and speed up the construction. However, their reliance on
incomplete factorization leads to significant challenges: the associated
triangular solve hinders GPU parallelization in practice, and introduces
long-range dependencies which are difficult for GNNs to model. To address these
issues, we propose a learning-based method to generate GPU-friendly
preconditioners, particularly using GNNs to construct Sparse Approximate
Inverse (SPAI) preconditioners, which avoids triangular solves and requires
only two matrix-vector products at each CG step. The locality of matrix-vector
product is compatible with the local propagation mechanism of GNNs. The
flexibility of GNNs also allows our approach to be applied in a wide range of
scenarios. Furthermore, we introduce a statistics-based scale-invariant loss
function. Its design matches CG's property that the convergence rate depends on
the condition number, rather than the absolute scale of A, leading to improved
performance of the learned preconditioner. Evaluations on three PDE-derived
datasets and one synthetic dataset demonstrate that our method outperforms
standard preconditioners (Diagonal, IC, and traditional SPAI) and previous
learning-based preconditioners on GPUs. We reduce solution time on GPUs by
40%-53% (68%-113% faster), along with better condition numbers and superior
generalization performance. Source code available at
https://github.com/Adversarr/LearningSparsePreconditioner4GPU

</details>


### [271] [CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs](https://arxiv.org/abs/2510.26843)
*Zhiyuan Ning,Jiawei Shao,Ruge Xu,Xinfei Guo,Jun Zhang,Chi Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: CAS-Spec通过动态切换的推理加速策略（如层稀疏化和激活量化）来构建推测性草稿模型，并结合动态树级联（DyTC）算法，实现了比现有方法更快的推测性解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有的推测性解码方法在速度上仍有提升空间，特别是那些不依赖专门训练的方法。训练多个模型进行级联成本高昂，限制了其应用。

Method: 提出CAS-Spec方法，利用动态切换的推理加速（DSIA）策略（层稀疏化、激活量化）构建草稿模型。提出DyTC算法，自适应地路由多层草稿模型并根据接受率和延迟预测分配草稿长度。

Result: CAS-Spec在多种LLM和数据集上实现了平均$1.1	imes$到$2.3	imes$的加速。DyTC算法比基线算法分别提高了平均加速$47$"%和$48$"%。

Conclusion: CAS-Spec易于集成到现有LLM中，并有望随着推测性解码技术的发展实现进一步加速。

Abstract: Speculative decoding has become a widely adopted as an effective technique
for lossless inference acceleration when deploying large language models
(LLMs). While on-the-fly self-speculative methods offer seamless integration
and broad utility, they often fall short of the speed gains achieved by methods
relying on specialized training. Cascading a hierarchy of draft models promises
further acceleration and flexibility, but the high cost of training multiple
models has limited its practical application. In this paper, we propose a novel
Cascade Adaptive Self-Speculative Decoding (CAS-Spec) method which constructs
speculative draft models by leveraging dynamically switchable inference
acceleration (DSIA) strategies, including layer sparsity and activation
quantization. Furthermore, traditional vertical and horizontal cascade
algorithms are inefficient when applied to self-speculative decoding methods.
We introduce a Dynamic Tree Cascade (DyTC) algorithm that adaptively routes the
multi-level draft models and assigns the draft lengths, based on the heuristics
of acceptance rates and latency prediction. Our CAS-Spec method achieves
state-of-the-art acceleration compared to existing on-the-fly speculative
decoding methods, with an average speedup from $1.1\times$ to $2.3\times$ over
autoregressive decoding across various LLMs and datasets. DyTC improves the
average speedup by $47$\% and $48$\% over cascade-based baseline and tree-based
baseline algorithms, respectively. CAS-Spec can be easily integrated into most
existing LLMs and holds promising potential for further acceleration as
self-speculative decoding techniques continue to evolve.

</details>


### [272] [BI-DCGAN: A Theoretically Grounded Bayesian Framework for Efficient and Diverse GANs](https://arxiv.org/abs/2510.26892)
*Mahsa Valizadeh,Rui Tuo,James Caverlee*

Main category: cs.LG

TL;DR: BI-DCGAN通过引入贝叶斯方法解决了GANs的模式崩溃问题，提高了生成样本的多样性和鲁棒性，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: GANs在生成合成数据方面表现出色，但在模式崩溃问题上存在局限，导致生成的数据范围狭窄，无法捕捉完整的数据分布。这在需要多样性和不确定性感知的现实应用中尤为 problematic。

Method: BI-DCGAN是DCGAN的贝叶斯扩展，通过整合"Bayes by Backprop"学习网络权重的分布，并利用平均场变分推断在GANs训练过程中近似后验分布。

Result: 实验证明，BI-DCGAN比传统DCGANs产生更多样化和更鲁棒的输出，同时保持了训练效率。理论上，首次通过协方差矩阵分析证明了贝叶斯建模可以增强GANs的样本多样性。

Conclusion: BI-DCGAN为需要多样性和不确定性的应用提供了一个可扩展的解决方案，特别是在扩散模型过于资源密集的情况下。

Abstract: Generative Adversarial Networks (GANs) are proficient at generating synthetic
data but continue to suffer from mode collapse, where the generator produces a
narrow range of outputs that fool the discriminator but fail to capture the
full data distribution. This limitation is particularly problematic, as
generative models are increasingly deployed in real-world applications that
demand both diversity and uncertainty awareness. In response, we introduce
BI-DCGAN, a Bayesian extension of DCGAN that incorporates model uncertainty
into the generative process while maintaining computational efficiency.
BI-DCGAN integrates Bayes by Backprop to learn a distribution over network
weights and employs mean-field variational inference to efficiently approximate
the posterior distribution during GAN training. We establishes the first
theoretical proof, based on covariance matrix analysis, that Bayesian modeling
enhances sample diversity in GANs. We validate this theoretical result through
extensive experiments on standard generative benchmarks, demonstrating that
BI-DCGAN produces more diverse and robust outputs than conventional DCGANs,
while maintaining training efficiency. These findings position BI-DCGAN as a
scalable and timely solution for applications where both diversity and
uncertainty are critical, and where modern alternatives like diffusion models
remain too resource-intensive.

</details>


### [273] [Integrating Ontologies with Large Language Models for Enhanced Control Systems in Chemical Engineering](https://arxiv.org/abs/2510.26898)
*Crystal Su,Kuai Yu,Jingrui Zhang,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 该研究提出了一个面向化工领域的、结合了本体知识的大型语言模型（LLM）框架，能够融合结构化的领域知识和生成式推理能力。


<details>
  <summary>Details</summary>
Motivation: 整合化工领域的结构化知识和生成式推理，以实现对LLM在过程控制、安全分析等关键工程领域的透明、可审计应用。

Method: 通过数据获取、语义预处理、信息抽取和本体映射等步骤，将模型训练和推理与COPE本体对齐，生成用于微调的模板化问答对。控制聚焦的解码阶段和引用门通过将输出约束在与本体链接的术语内，来强制执行语法和事实的准确性。

Result: 研究提出了一个能够融合结构化领域知识和生成式推理能力的、面向化工领域的大型语言模型框架，并通过一系列方法保证了输出的准确性和可靠性。

Conclusion: 将符号结构和神经生成相结合，为LLM在过程控制、安全分析等关键工程领域提供了透明、可审计的应用方法。

Abstract: This work presents an ontology-integrated large language model (LLM)
framework for chemical engineering that unites structured domain knowledge with
generative reasoning. The proposed pipeline aligns model training and inference
with the COPE ontology through a sequence of data acquisition, semantic
preprocessing, information extraction, and ontology mapping steps, producing
templated question-answer pairs that guide fine-tuning. A control-focused
decoding stage and citation gate enforce syntactic and factual grounding by
constraining outputs to ontology-linked terms, while evaluation metrics
quantify both linguistic quality and ontological accuracy. Feedback and future
extensions, including semantic retrieval and iterative validation, further
enhance the system's interpretability and reliability. This integration of
symbolic structure and neural generation provides a transparent, auditable
approach for applying LLMs to process control, safety analysis, and other
critical engineering contexts.

</details>


### [274] [Discovering EV Charging Site Archetypes Through Few Shot Forecasting: The First U.S.-Wide Study](https://arxiv.org/abs/2510.26910)
*Kshitij Nikhal,Luke Ackerknecht,Benjamin S. Riggan,Phil Stahlfeld*

Main category: cs.LG

TL;DR: 电动汽车普及需要准确的充电行为理解以支撑成本效益高、电网韧性强的基础设施建设。本研究提出一种整合聚类和少样本预测的框架，利用大规模充电需求数据集挖掘充电站原型，以克服现有研究在数据集规模、时序依赖性建模和泛化能力方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了确保具有成本效益、电网韧性的充电基础设施，有必要准确理解电动汽车的充电行为，以推动电动汽车的普及。

Method: 本研究提出一个整合聚类与少样本预测的框架，利用包含充电需求的新型大规模数据集来识别充电站的原型。

Result: 与全局基线相比，特定原型专家模型在预测未见过的充电站的需求方面表现出更优越的性能。

Conclusion: 通过将预测性能作为基础设施分割的基础，我们提供了可行的见解，使运营商能够降低成本、优化能源和定价策略，并支持对气候目标至关重要的电网韧性。

Abstract: The decarbonization of transportation relies on the widespread adoption of
electric vehicles (EVs), which requires an accurate understanding of charging
behavior to ensure cost-effective, grid-resilient infrastructure. Existing work
is constrained by small-scale datasets, simple proximity-based modeling of
temporal dependencies, and weak generalization to sites with limited
operational history. To overcome these limitations, this work proposes a
framework that integrates clustering with few-shot forecasting to uncover site
archetypes using a novel large-scale dataset of charging demand. The results
demonstrate that archetype-specific expert models outperform global baselines
in forecasting demand at unseen sites. By establishing forecast performance as
a basis for infrastructure segmentation, we generate actionable insights that
enable operators to lower costs, optimize energy and pricing strategies, and
support grid resilience critical to climate goals.

</details>


### [275] [Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems](https://arxiv.org/abs/2510.27659)
*Alireza Saleh Abadi,Leen-Kiat Soh*

Main category: cs.LG

TL;DR: MARL中的开放性（代理、任务、类型）增加了信用分配的复杂性，导致信用错误归因和性能下降。


<details>
  <summary>Details</summary>
Motivation: 理解多智能体强化学习（MARL）中开放系统的动态特性，特别是开放性与信用分配问题（CAP）之间的相互作用，因为传统CAP方法在开放环境中效果不佳。

Method: 进行概念分析，详细说明开放性如何破坏现有CAP方法的假设；通过在开放环境中使用代表性算法进行实证研究。

Result: 开放性直接导致信用错误归因，表现为不稳定的损失函数和显著的性能下降。

Conclusion: 开放性对MARL中的信用分配提出了重大挑战，需要开发新的方法来应对动态变化的环境和代理种群。

Abstract: In the rapidly evolving field of multi-agent reinforcement learning (MARL),
understanding the dynamics of open systems is crucial. Openness in MARL refers
to the dynam-ic nature of agent populations, tasks, and agent types with-in a
system. Specifically, there are three types of openness as reported in (Eck et
al. 2023) [2]: agent openness, where agents can enter or leave the system at
any time; task openness, where new tasks emerge, and existing ones evolve or
disappear; and type openness, where the capabil-ities and behaviors of agents
change over time. This report provides a conceptual and empirical review,
focusing on the interplay between openness and the credit assignment problem
(CAP). CAP involves determining the contribution of individual agents to the
overall system performance, a task that becomes increasingly complex in open
environ-ments. Traditional credit assignment (CA) methods often assume static
agent populations, fixed and pre-defined tasks, and stationary types, making
them inadequate for open systems. We first conduct a conceptual analysis,
in-troducing new sub-categories of openness to detail how events like agent
turnover or task cancellation break the assumptions of environmental
stationarity and fixed team composition that underpin existing CAP methods. We
then present an empirical study using representative temporal and structural
algorithms in an open environment. The results demonstrate that openness
directly causes credit misattribution, evidenced by unstable loss functions and
significant performance degradation.

</details>


### [276] [MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models](https://arxiv.org/abs/2510.26937)
*Zimeng Huang,Jinxin Ke,Xiaoxuan Fan,Yufeng Yang,Yang Liu,Liu Zhonghan,Zedi Wang,Junteng Dai,Haoyi Jiang,Yuyu Zhou,Keze Wang,Ziliang Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Vision-Language Models (LVLMs) have exhibited remarkable progress.
However, deficiencies remain compared to human intelligence, such as
hallucination and shallow pattern matching. In this work, we aim to evaluate a
fundamental yet underexplored intelligence: association, a cornerstone of human
cognition for creative thinking and knowledge integration. Current benchmarks,
often limited to closed-ended tasks, fail to capture the complexity of
open-ended association reasoning vital for real-world applications. To address
this, we present MM-OPERA, a systematic benchmark with 11,497 instances across
two open-ended tasks: Remote-Item Association (RIA) and In-Context Association
(ICA), aligning association intelligence evaluation with human psychometric
principles. It challenges LVLMs to resemble the spirit of divergent thinking
and convergent associative reasoning through free-form responses and explicit
reasoning paths. We deploy tailored LLM-as-a-Judge strategies to evaluate
open-ended outputs, applying process-reward-informed judgment to dissect
reasoning with precision. Extensive empirical studies on state-of-the-art
LVLMs, including sensitivity analysis of task instances, validity analysis of
LLM-as-a-Judge strategies, and diversity analysis across abilities, domains,
languages, cultures, etc., provide a comprehensive and nuanced understanding of
the limitations of current LVLMs in associative reasoning, paving the way for
more human-like and general-purpose AI. The dataset and code are available at
https://github.com/MM-OPERA-Bench/MM-OPERA.

</details>


### [277] [Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction](https://arxiv.org/abs/2510.26940)
*Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh*

Main category: cs.LG

TL;DR: 研究揭示了下一地点预测模型中存在的基于用户群体的人口统计学差异，并提出了一种名为FGIS的公平性引导增量采样策略，通过SAKM聚类方法生成代理人口统计学标签，有效减少了不同用户群体间的预测性能差距，同时保持了整体准确性。


<details>
  <summary>Details</summary>
Motivation: 现有下一地点预测模型在社会影响方面研究不足，本研究旨在揭示模型中隐藏的基于用户人口统计学信息的性能差异。

Method: 首先，通过计算模型在不同种族和族裔用户群体上的预测性能差异，揭示了数据集带来的系统性不平等。然后，提出了一种名为FGIS（Fairness-Guided Incremental Sampling）的群体感知采样策略，并引入了SAKM（Size-Aware K-Means）聚类方法，利用人口普查数据比例在潜在移动空间中划分用户，生成代理种族标签。最后，基于这些标签，FGIS算法优先考虑预期性能提升和当前群体代表性的用户，以增量方式构建训练数据集，从而减少人口统计学性能差距。

Result: FGIS方法可将不同用户群体间的总差异最多减少40%，同时对整体准确性的影响很小。在MetaPath2Vec和Transformer-Encoder模型上的评估显示，在早期采样阶段改进最为显著，表明即使在资源有限的情况下，公平性感知策略也能带来显著的提升。

Conclusion: 本研究暴露了移动预测管道中的结构性不平等问题，并证明了轻量级、以数据为中心的干预措施可以以很小的复杂性增加来提高公平性，尤其适用于数据量较少的应用。

Abstract: Next location prediction underpins a growing number of mobility, retail, and
public-health applications, yet its societal impacts remain largely unexplored.
In this paper, we audit state-of-the-art mobility prediction models trained on
a large-scale dataset, highlighting hidden disparities based on user
demographics. Drawing from aggregate census data, we compute the difference in
predictive performance on racial and ethnic user groups and show a systematic
disparity resulting from the underlying dataset, resulting in large differences
in accuracy based on location and user groups. To address this, we propose
Fairness-Guided Incremental Sampling (FGIS), a group-aware sampling strategy
designed for incremental data collection settings. Because individual-level
demographic labels are unavailable, we introduce Size-Aware K-Means (SAKM), a
clustering method that partitions users in latent mobility space while
enforcing census-derived group proportions. This yields proxy racial labels for
the four largest groups in the state: Asian, Black, Hispanic, and White. Built
on these labels, our sampling algorithm prioritizes users based on expected
performance gains and current group representation. This method incrementally
constructs training datasets that reduce demographic performance gaps while
preserving overall accuracy. Our method reduces total disparity between groups
by up to 40\% with minimal accuracy trade-offs, as evaluated on a state-of-art
MetaPath2Vec model and a transformer-encoder model. Improvements are most
significant in early sampling stages, highlighting the potential for
fairness-aware strategies to deliver meaningful gains even in low-resource
settings. Our findings expose structural inequities in mobility prediction
pipelines and demonstrate how lightweight, data-centric interventions can
improve fairness with little added complexity, especially for low-data
applications.

</details>


### [278] [Can machines think efficiently?](https://arxiv.org/abs/2510.26954)
*Adam Winchell*

Main category: cs.LG

TL;DR: }
我们需要一个新的、更严格的图灵测试来评估人工智能的效率和资源成本。


<details>
  <summary>Details</summary>
Motivation: }
由于当前的人工智能系统已经能够通过图灵测试，且带来了伦理和环境问题，因此有必要更新测试方法。

Method: }
通过在原始的模仿游戏中增加一个衡量“能源消耗”的因素，来评估人工智能的效率。

Result: }
新的测试方法促使我们从效率的角度来评估人工智能，将抽象的“思考”问题与有限的“资源”现实联系起来，并为评估人工智能提供了一个可衡量的、实际的终点。

Conclusion: }
这项工作提出了一种新的测试方法，通过引入能源消耗的约束，来评估人工智能的效率，并权衡使用人工智能的时间节省与其总资源成本。

Abstract: The Turing Test is no longer adequate for distinguishing human and machine
intelligence. With advanced artificial intelligence systems already passing the
original Turing Test and contributing to serious ethical and environmental
concerns, we urgently need to update the test. This work expands upon the
original imitation game by accounting for an additional factor: the energy
spent answering the questions. By adding the constraint of energy, the new test
forces us to evaluate intelligence through the lens of efficiency, connecting
the abstract problem of thinking to the concrete reality of finite resources.
Further, this proposed new test ensures the evaluation of intelligence has a
measurable, practical finish line that the original test lacks. This additional
constraint compels society to weigh the time savings of using artificial
intelligence against its total resource cost.

</details>


### [279] [Predicting Household Water Consumption Using Satellite and Street View Images in Two Indian Cities](https://arxiv.org/abs/2510.26957)
*Qiao Wang,Joseph George*

Main category: cs.LG

TL;DR: 利用公开的卫星图像和街景图像来预测家庭用水量，能够作为传统调查方法的有益补充。


<details>
  <summary>Details</summary>
Motivation: 传统的家庭用水量监测方法成本高且耗时，因此需要开发新的方法来预测家庭用水量。

Method: 将卫星图像、街景图像分割、夜间灯光强度、人口密度等地理空间协变量与四种方法进行比较：调查特征（基准）、CNN嵌入（卫星、街景、组合）以及街景语义图。

Result: 在序数分类框架下，街景分割结合遥感协变量在用水量预测方面达到了0.55的准确率，接近基于调查的模型（0.59的准确率）。误差分析表明，在用水量分布的极端情况下具有高精度，但在中间阶层存在混淆。

Conclusion: 公开获取的图像结合少量的地理空间数据，为在城市分析中获取可靠的家庭用水量估算提供了一种有前景的替代调查的方法。

Abstract: Monitoring household water use in rapidly urbanizing regions is hampered by
costly, time-intensive enumeration methods and surveys. We investigate whether
publicly available imagery-satellite tiles, Google Street View (GSV)
segmentation-and simple geospatial covariates (nightlight intensity, population
density) can be utilized to predict household water consumption in
Hubballi-Dharwad, India. We compare four approaches: survey features
(benchmark), CNN embeddings (satellite, GSV, combined), and GSV semantic maps
with auxiliary data. Under an ordinal classification framework, GSV
segmentation plus remote-sensing covariates achieves 0.55 accuracy for water
use, approaching survey-based models (0.59 accuracy). Error analysis shows high
precision at extremes of the household water consumption distribution, but
confusion among middle classes is due to overlapping visual proxies. We also
compare and contrast our estimates for household water consumption to that of
household subjective income. Our findings demonstrate that open-access imagery,
coupled with minimal geospatial data, offers a promising alternative to
obtaining reliable household water consumption estimates using surveys in urban
analytics.

</details>


### [280] [Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget](https://arxiv.org/abs/2510.26981)
*Zhichao Hou,Weizhi Gao,Xiaorui Liu*

Main category: cs.LG

TL;DR: 在固定计算预算下，通过选择性地重新计算层激活来最大化迭代对抗攻击的强度，并将其应用于对抗性训练以节省预算。


<details>
  <summary>Details</summary>
Motivation: 在AI安全研究和有限计算资源的情况下，如何最大化迭代对抗攻击的强度是一个关键挑战。

Method: 提出了一种细粒度控制机制，可以选择性地跨迭代和层重新计算层激活。

Result: 该方法在相同成本下始终优于现有基线，并且在对抗性训练中，仅用30%的预算即可达到可比的性能。

Conclusion: 所提出的方法可以在有限的计算预算下有效地增强迭代对抗攻击，并能显著降低对抗性训练的成本。

Abstract: This work tackles a critical challenge in AI safety research under limited
compute: given a fixed computation budget, how can one maximize the strength of
iterative adversarial attacks? Coarsely reducing the number of attack
iterations lowers cost but substantially weakens effectiveness. To fulfill the
attainable attack efficacy within a constrained budget, we propose a
fine-grained control mechanism that selectively recomputes layer activations
across both iteration-wise and layer-wise levels. Extensive experiments show
that our method consistently outperforms existing baselines at equal cost.
Moreover, when integrated into adversarial training, it attains comparable
performance with only 30% of the original budget.

</details>


### [281] [SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference](https://arxiv.org/abs/2510.27182)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.LG

TL;DR: SERFLOW通过为FaaS和IaaS资源动态配置和负载均衡，解决了ML模型推理中VM冷启动和长尾服务时间等现实问题，将云成本降低了23%以上。


<details>
  <summary>Details</summary>
Motivation: 解决现有ML模型动态卸载方法忽略VM冷启动、长尾服务时间等现实因素的问题。

Method: 将ML查询建模为具有输入相关退出率的有向无环图，并采用特定阶段的资源配置，结合了FaaS（服务器无状态函数）和IaaS（VM），并根据请求量进行自适应负载均衡。

Result: 与现有方法相比，云成本降低了23%以上。

Conclusion: SERFLOW通过动态卸载和资源配置，有效解决了ML模型推理中的现实挑战，实现了成本效益和性能的提升。

Abstract: Dynamic offloading of Machine Learning (ML) model partitions across different
resource orchestration services, such as Function-as-a-Service (FaaS) and
Infrastructure-as-a-Service (IaaS), can balance processing and transmission
delays while minimizing costs of adaptive inference applications. However,
prior work often overlooks real-world factors, such as Virtual Machine (VM)
cold starts, requests under long-tail service time distributions, etc. To
tackle these limitations, we model each ML query (request) as traversing an
acyclic sequence of stages, wherein each stage constitutes a contiguous block
of sparse model parameters ending in an internal or final classifier where
requests may exit. Since input-dependent exit rates vary, no single resource
configuration suits all query distributions. IaaS-based VMs become
underutilized when many requests exit early, yet rapidly scaling to handle
request bursts reaching deep layers is impractical. SERFLOW addresses this
challenge by leveraging FaaS-based serverless functions (containers) and using
stage-specific resource provisioning that accounts for the fraction of requests
exiting at each stage. By integrating this provisioning with adaptive load
balancing across VMs and serverless functions based on request ingestion,
SERFLOW reduces cloud costs by over $23\%$ while efficiently adapting to
dynamic workloads.

</details>


### [282] [HADSF: Aspect Aware Semantic Control for Explainable Recommendation](https://arxiv.org/abs/2510.26994)
*Zheng Nie,Peijie Sun*

Main category: cs.LG

TL;DR: HADSF框架通过两阶段方法解决现有信息提取方法的局限性，引入了新的评估指标，并探索了模型规模与成本效益的关系，在推荐系统中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的信息提取方法存在作用域控制不足、缺乏衡量幻觉与下游效果之间关联的指标以及未充分探索模型规模成本效益等问题。

Method: 提出了一种名为HADSF的两阶段框架，首先通过自适应选择诱导语料库级别的紧凑方面词汇，然后执行词汇引导的、明确约束的结构化方面-意见三元组提取。引入了方面漂移率（ADR）和意见保真率（OFR）来评估表示的保真度。

Result: 实验表明，HADSF与标准评分预测器集成后，可以持续降低预测误差，并使较小的模型在代表性的部署场景中实现具有竞争力的性能。发现模型幻觉的严重程度与评分预测误差之间存在非单调关系。

Conclusion: HADSF框架通过解决现有方法的局限性，引入新的评估指标，并揭示了模型幻觉与推荐系统性能之间的复杂关系，从而在LLM增强的可解释推荐领域取得了显著进展。

Abstract: Recent advances in large language models (LLMs) promise more effective
information extraction for review-based recommender systems, yet current
methods still (i) mine free-form reviews without scope control, producing
redundant and noisy representations, (ii) lack principled metrics that link LLM
hallucination to downstream effectiveness, and (iii) leave the cost-quality
trade-off across model scales largely unexplored. We address these gaps with
the Hyper-Adaptive Dual-Stage Semantic Framework (HADSF), a two-stage approach
that first induces a compact, corpus-level aspect vocabulary via adaptive
selection and then performs vocabulary-guided, explicitly constrained
extraction of structured aspect-opinion triples. To assess the fidelity of the
resulting representations, we introduce Aspect Drift Rate (ADR) and Opinion
Fidelity Rate (OFR) and empirically uncover a nonmonotonic relationship between
hallucination severity and rating prediction error. Experiments on
approximately 3 million reviews across LLMs spanning 1.5B-70B parameters show
that, when integrated into standard rating predictors, HADSF yields consistent
reductions in prediction error and enables smaller models to achieve
competitive performance in representative deployment scenarios. We release
code, data pipelines, and metric implementations to support reproducible
research on hallucination-aware, LLM-enhanced explainable recommendation. Code
is available at https://github.com/niez233/HADSF

</details>


### [283] [Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules](https://arxiv.org/abs/2510.26997)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 学习规则被视为导航损失景观的策略，最优规则是相关最优控制问题的解。


<details>
  <summary>Details</summary>
Motivation: 探讨学习规则为何有效以及在何种假设下最优，提出一个将学习规则视为导航损失景观策略的理论框架。

Method: 将学习规则视为导航（部分可观察）损失景观的策略，并将最优规则识别为相关最优控制问题的解。

Result: 梯度下降、动量、自然梯度、非梯度规则和 Adam 等自适应优化器都在该框架下出现；持续学习策略（如权重重置）被理解为对任务不确定性的最优响应。

Conclusion: 该框架统一了各种学习现象，阐明了学习的计算结构，并为设计自适应算法提供了原则性基础。

Abstract: Learning rules -- prescriptions for updating model parameters to improve
performance -- are typically assumed rather than derived. Why do some learning
rules work better than others, and under what assumptions can a given rule be
considered optimal? We propose a theoretical framework that casts learning
rules as policies for navigating (partially observable) loss landscapes, and
identifies optimal rules as solutions to an associated optimal control problem.
A range of well-known rules emerge naturally within this framework under
different assumptions: gradient descent from short-horizon optimization,
momentum from longer-horizon planning, natural gradients from accounting for
parameter space geometry, non-gradient rules from partial controllability, and
adaptive optimizers like Adam from online Bayesian inference of loss landscape
shape. We further show that continual learning strategies like weight resetting
can be understood as optimal responses to task uncertainty. By unifying these
phenomena under a single objective, our framework clarifies the computational
structure of learning and offers a principled foundation for designing adaptive
algorithms.

</details>


### [284] [A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms](https://arxiv.org/abs/2510.27001)
*Elise Wolf*

Main category: cs.LG

TL;DR: MAB算法的评估因缺乏标准化条件而面临挑战。本文提出了一个可复现的评估框架（Bandit Playground），比较了八种经典和方差感知算法，并分析了方差感知算法在何种条件下优于经典算法。


<details>
  <summary>Details</summary>
Motivation: 评估和比较MAB算法具有挑战性，因为缺乏标准化的条件和可重复性，特别是对于方差感知算法，其性能高度依赖于环境。本研究旨在解决如何可靠地观察MAB算法之间的性能差异，以及在何种条件下，方差感知算法可以优于经典算法。

Method: 提出了一个可复现的评估框架（Bandit Playground），该框架包含明确定义的实验设置、多种性能指标（奖励、遗憾、奖励分布、风险价值和动作最优性）以及一个支持一致且透明分析的交互式评估界面，用于系统地比较八种经典和方差感知MAB算法。

Result: 方差感知算法在高不确定性设置中具有优势，尤其是在臂奖励之间存在细微差异的情况下。然而，在更易分离的情况下，或者经过广泛微调后，经典算法的表现通常与方差感知算法相当甚至更好。

Conclusion: 本研究的两项主要贡献是：1. 提供了一个用于MAB算法系统评估的框架。2. 揭示了方差感知方法优于其经典对应方法的条件。

Abstract: Multi-armed bandit (MAB) problems serve as a fundamental building block for
more complex reinforcement learning algorithms. However, evaluating and
comparing MAB algorithms remains challenging due to the lack of standardized
conditions and replicability. This is particularly problematic for
variance-aware extensions of classical methods like UCB, whose performance can
heavily depend on the underlying environment. In this study, we address how
performance differences between bandit algorithms can be reliably observed, and
under what conditions variance-aware algorithms outperform classical ones. We
present a reproducible evaluation designed to systematically compare eight
classical and variance-aware MAB algorithms. The evaluation framework,
implemented in our Bandit Playground codebase, features clearly defined
experimental setups, multiple performance metrics (reward, regret, reward
distribution, value-at-risk, and action optimality), and an interactive
evaluation interface that supports consistent and transparent analysis. We show
that variance-aware algorithms can offer advantages in settings with high
uncertainty where the difficulty arises from subtle differences between arm
rewards. In contrast, classical algorithms often perform equally well or better
in more separable scenarios or if fine-tuned extensively. Our contributions are
twofold: (1) a framework for systematic evaluation of MAB algorithms, and (2)
insights into the conditions under which variance-aware approaches outperform
their classical counterparts.

</details>


### [285] [Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase](https://arxiv.org/abs/2510.27002)
*Mihir Mahajan,Alfred Nguyen,Franz Srambical,Stefan Bauer*

Main category: cs.LG

TL;DR: Jasmine是一个高性能的JAX世界模型代码库，可以从单主机扩展到数百个加速器，在CoinRun案例研究中实现了数量级更快的训练速度。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀疏性问题，并提供一个可扩展、高性能的世界建模训练基础设施。

Method: 开发JAX基的世界模型代码库Jasmine，优化数据加载、训练和检查点，实现跨多种计算配置的可扩展性和可复现性。

Result: Jasmine在CoinRun案例研究中实现了比现有实现快一个数量级的训练速度，并提供了可复现的训练和对不同分片配置的支持。

Conclusion: Jasmine为世界模型的研究和基准测试提供了坚实的基础设施，能够处理大规模数据集和复杂的模型。

Abstract: While world models are increasingly positioned as a pathway to overcoming
data scarcity in domains such as robotics, open training infrastructure for
world modeling remains nascent. We introduce Jasmine, a performant JAX-based
world modeling codebase that scales from single hosts to hundreds of
accelerators with minimal code changes. Jasmine achieves an order-of-magnitude
faster reproduction of the CoinRun case study compared to prior open
implementations, enabled by performance optimizations across data loading,
training and checkpointing. The codebase guarantees fully reproducible training
and supports diverse sharding configurations. By pairing Jasmine with curated
large-scale datasets, we establish infrastructure for rigorous benchmarking
pipelines across model families and architectural ablations.

</details>


### [286] [Mixture-of-Transformers Learn Faster: A Theoretical Study on Classification Problems](https://arxiv.org/abs/2510.27004)
*Hongbo Li,Qinhang Wu,Sen Lin,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: Mixture-of-Transformers (MoT) models offer a theoretical framework for understanding and improving transformer efficiency through expert specialization, achieving near-zero prediction loss significantly faster than single transformers.


<details>
  <summary>Details</summary>
Motivation: The lack of a unified theoretical explanation for Mixture-of-Experts (MoE) models, especially when both feed-forward and attention layers specialize, motivated the study of Mixture-of-Transformers (MoT).

Method: The study proposes a three-stage training algorithm with continuous gating network training for MoT models. It analyzes how expert specialization reduces gradient conflicts and makes subtasks strongly convex, and theoretically proves a near-zero expected prediction loss in O(log('epsilon^-1')) iterations.

Result: The analysis shows that MoT experts specialize in distinct tasks, and the gating network accurately routes data. Theoretically, training drives expected prediction loss to near zero in O(log('epsilon^-1')) iterations. Experiments on real data validate these findings, demonstrating MoT's practical effectiveness.

Conclusion: MoT provides the first unified theoretical account of transformer-level specialization and learning dynamics, offering practical guidance for designing efficient large-scale models.

Abstract: Mixture-of-Experts (MoE) models improve transformer efficiency but lack a
unified theoretical explanation, especially when both feed-forward and
attention layers are allowed to specialize. To this end, we study the
Mixture-of-Transformers (MoT), a tractable theoretical framework in which each
transformer block acts as an expert governed by a continuously trained gating
network. This design allows us to isolate and study the core learning dynamics
of expert specialization and attention alignment. In particular, we develop a
three-stage training algorithm with continuous training of the gating network,
and show that each transformer expert specializes in a distinct class of tasks
and that the gating network accurately routes data samples to the correct
expert. Our analysis shows how expert specialization reduces gradient conflicts
and makes each subtask strongly convex. We prove that the training drives the
expected prediction loss to near zero in $O(\log(\epsilon^{-1}))$ iteration
steps, significantly improving over the $O(\epsilon^{-1})$ rate for a single
transformer. We further validate our theoretical findings through extensive
real-data experiments, demonstrating the practical effectiveness of MoT.
Together, these results offer the first unified theoretical account of
transformer-level specialization and learning dynamics, providing practical
guidance for designing efficient large-scale models.

</details>


### [287] [Enhancing Sentiment Classification with Machine Learning and Combinatorial Fusion](https://arxiv.org/abs/2510.27014)
*Sean Patten,Pin-Yu Chen,Christina Schweikert,D. Frank Hsu*

Main category: cs.LG

TL;DR: 本研究提出一种基于组合融合分析（CFA）的新型情感分类方法，通过集成多种机器学习模型并利用认知多样性来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索一种比传统模型集成方法更有效的情感分类技术，该技术能够通过整合多样化的模型来提升预测性能，并有效利用计算资源。

Method: 本研究提出组合融合分析（CFA）方法，该方法利用基于秩分特征函数来量化模型之间的差异性，并策略性地组合它们的预测。具体而言，本研究结合了基于RoBERTa架构的Transformer模型以及随机森林、SVM和XGBoost等传统机器学习模型。

Result: 本研究将CFA方法应用于IMDB情感分析数据集，取得了97.072%的准确率，达到了当前最优水平。实验结果表明，CFA的性能优于传统的集成方法，因为它能有效地计算和利用模型多样性。

Conclusion: 本研究提出的CFA方法在情感分类任务上取得了优异的性能，证明了通过整合认知多样性来组合不同模型预测的有效性。该方法在提高准确率的同时，在计算资源利用方面也具有效率优势。

Abstract: This paper presents a novel approach to sentiment classification using the
application of Combinatorial Fusion Analysis (CFA) to integrate an ensemble of
diverse machine learning models, achieving state-of-the-art accuracy on the
IMDB sentiment analysis dataset of 97.072\%. CFA leverages the concept of
cognitive diversity, which utilizes rank-score characteristic functions to
quantify the dissimilarity between models and strategically combine their
predictions. This is in contrast to the common process of scaling the size of
individual models, and thus is comparatively efficient in computing resource
use. Experimental results also indicate that CFA outperforms traditional
ensemble methods by effectively computing and employing model diversity. The
approach in this paper implements the combination of a transformer-based model
of the RoBERTa architecture with traditional machine learning models, including
Random Forest, SVM, and XGBoost.

</details>


### [288] [Quantitative Bounds for Length Generalization in Transformers](https://arxiv.org/abs/2510.27015)
*Zachary Izzo,Eshaan Nichani,Jason D. Lee*

Main category: cs.LG

TL;DR: Transformers 达到长度泛化（LG）的最小训练序列长度存在一个有限的阈值。本研究首次提供了 LG 发生所需的定量训练长度界限。


<details>
  <summary>Details</summary>
Motivation: 先前的研究（Huang et al., 2025）表明 transformers 最终能实现长度泛化，但未确定所需的最小训练序列长度。本研究旨在提供这一定量界限。

Method: 分析了不同设置下的 LG 问题：$\\(l\text_inf)\\$ 误差控制与平均误差控制、无限精度 softmax 注意力与有限精度（argmax）注意力、单层与双层 transformer。在所有情况下，证明了当 transformer 在更长序列上的内部行为可以被其在训练期间遇到的更短序列上的行为“模拟”时，LG 就会发生。

Result: 得出了 transformer 实现 LG 所需训练数据的长度的定性估计，并通过实验进行了验证。这些结果加深了对 transformer 外推机制的理论理解，并使对更复杂任务的泛化需要更丰富训练数据的直觉形式化。

Conclusion: 本研究首次量化了 transformer 实现长度泛化所需的训练长度界限，并通过理论和实验证明了在不同设置下，当模型在长序列上的行为可以被其在训练数据上的行为模拟时，即可实现长度泛化。

Abstract: We study the problem of length generalization (LG) in transformers: the
ability of a model trained on shorter sequences to maintain performance when
evaluated on much longer, previously unseen inputs. Prior work by Huang et al.
(2025) established that transformers eventually achieve length generalization
once the training sequence length exceeds some finite threshold, but left open
the question of how large it must be. In this work, we provide the first
quantitative bounds on the required training length for length generalization
to occur. Motivated by previous empirical and theoretical work, we analyze LG
in several distinct problem settings: $\ell_\infty$ error control vs. average
error control over an input distribution, infinite-precision softmax attention
vs. finite-precision attention (which reduces to an argmax) in the transformer,
and one- vs. two-layer transformers. In all scenarios, we prove that LG occurs
when the internal behavior of the transformer on longer sequences can be
"simulated" by its behavior on shorter sequences seen during training. Our
bounds give qualitative estimates for the length of training data required for
a transformer to generalize, and we verify these insights empirically. These
results sharpen our theoretical understanding of the mechanisms underlying
extrapolation in transformers, and formalize the intuition that richer training
data is required for generalization on more complex tasks.

</details>


### [289] [Functional embeddings enable Aggregation of multi-area SEEG recordings over subjects and sessions](https://arxiv.org/abs/2510.27090)
*Sina Javadzadeh,Rahil Soroushmojdehi,S. Alireza Seyyed Mousavi,Mehrnaz Asadi,Sumiko Abe,Terence D. Sanger*

Main category: cs.LG

TL;DR: 该研究提出了一种可扩展的表示学习框架，用于聚合不同受试者的颅内记录数据，解决了电极数量、放置和覆盖区域差异大的问题。该框架通过Siamese编码器学习电极的受试者无关的功能身份，并使用Transformer模型化跨区域关系，实现了受试者无关的功能空间，可用于下游解码任务。


<details>
  <summary>Details</summary>
Motivation: 颅内记录数据在受试者之间存在电极数量、放置和覆盖区域的巨大差异，导致数据聚合困难。现有的空间归一化方法（如MNI坐标）虽然提供了解剖学参考，但往往无法捕捉真实的功能相似性，尤其是在定位不精确的情况下。

Method: 提出一个可扩展的表示学习框架，包括：1. 使用具有对比目标的Siamese编码器从多区域局部场电位中学习每个电极的受试者无关的功能身份，诱导对区域特定神经特征具有局部敏感性的嵌入几何。2. 将这些嵌入进行分词，用于一个Transformer模型，该模型处理可变数量的通道，并模拟区域间关系。

Result: 在包含20名受试者、跨越基底神经节-丘脑区域的数据集上进行评估。学习到的功能空间支持准确的受试者内辨别，形成清晰、区域一致的簇，并且能够进行零样本迁移到未见过的通道。Transformer模型在没有受试者特定头部或监督的情况下，在功能标记上运行，能够捕捉跨区域依赖性，并实现被遮蔽通道的重建，为下游解码提供了受试者无关的骨干。

Conclusion: 该研究表明，对于在严格的任务结构和统一的传感器放置不可用的情况下，存在一种实现大规模、跨受试者聚合和预训练颅内神经数据的途径。

Abstract: Aggregating intracranial recordings across subjects is challenging since
electrode count, placement, and covered regions vary widely. Spatial
normalization methods like MNI coordinates offer a shared anatomical reference,
but often fail to capture true functional similarity, particularly when
localization is imprecise; even at matched anatomical coordinates, the targeted
brain region and underlying neural dynamics can differ substantially between
individuals. We propose a scalable representation-learning framework that (i)
learns a subject-agnostic functional identity for each electrode from
multi-region local field potentials using a Siamese encoder with contrastive
objectives, inducing an embedding geometry that is locality-sensitive to
region-specific neural signatures, and (ii) tokenizes these embeddings for a
transformer that models inter-regional relationships with a variable number of
channels. We evaluate this framework on a 20-subject dataset spanning basal
ganglia-thalamic regions collected during flexible rest/movement recording
sessions with heterogeneous electrode layouts. The learned functional space
supports accurate within-subject discrimination and forms clear,
region-consistent clusters; it transfers zero-shot to unseen channels. The
transformer, operating on functional tokens without subject-specific heads or
supervision, captures cross-region dependencies and enables reconstruction of
masked channels, providing a subject-agnostic backbone for downstream decoding.
Together, these results indicate a path toward large-scale, cross-subject
aggregation and pretraining for intracranial neural data where strict task
structure and uniform sensor placement are unavailable.

</details>


### [290] [Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](https://arxiv.org/abs/2510.27044)
*Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: RLVR在组合问题上提高了评估指标，但通常是通过强化肤浅的启发式方法而不是获取新的推理策略，这表明RLVR的泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 探索RLVR在提升LLM数学推理能力方面的真实效果，特别是其是否能促进真正的推理过程，而不仅仅是表面上的改进。

Method: 在活动调度和最长递增子序列两个组合问题上，使用具有唯一最优解的精心策划的数据集，研究RLVR在多种奖励设计下的表现。

Result: RLVR能够提高评估指标，但在实践中，模型往往通过强化肤浅的启发式方法来达到这一目的，而不是学习新的、更深层次的推理策略。

Conclusion: RLVR在提高评估指标方面有效，但其泛化能力有限，可能导致模型依赖捷径而非真正掌握数学推理。未来的研究需要开发能够区分真实推理和捷径利用的基准，并提供对模型进展的忠实度量。

Abstract: Mathematical reasoning is a central challenge for large language models
(LLMs), requiring not only correct answers but also faithful reasoning
processes. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as
a promising approach for enhancing such capabilities; however, its ability to
foster genuine reasoning remains unclear. We investigate RLVR on two
combinatorial problems with fully verifiable solutions: \emph{Activity
Scheduling} and the \emph{Longest Increasing Subsequence}, using carefully
curated datasets with unique optima. Across multiple reward designs, we find
that RLVR improves evaluation metrics but often by reinforcing superficial
heuristics rather than acquiring new reasoning strategies. These findings
highlight the limits of RLVR generalization, emphasizing the importance of
benchmarks that disentangle genuine mathematical reasoning from shortcut
exploitation and provide faithful measures of progress. Code available at
https://github.com/xashru/rlvr-seq-generalization.

</details>


### [291] [Consistency Training Helps Stop Sycophancy and Jailbreaks](https://arxiv.org/abs/2510.27062)
*Alex Irpan,Alexander Matt Turner,Mark Kurzeja,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 一致性训练可以提高 LLM 对提示中无关线索的鲁棒性，减少谄媚和越狱行为，同时避免陈旧训练数据的固有问题。


<details>
  <summary>Details</summary>
Motivation: LLM 的事实性和拒绝训练会受到提示更改的影响，模型常常会迎合用户（谄媚）或满足不当请求（越狱）。

Method: 探索一致性训练，一种让模型对提示中的不相关线索保持不变的自监督范式。通过两种方式强制执行这种不变性：在模型外部输出来实现偏差增强一致性训练 (BCT)，以及在内部激活上来实现激活一致性训练 (ACT)。

Result: 这两种方法都减少了 Gemini 2.5 Flash 对无关线索的敏感性。BCT 和 ACT 在减少谄媚方面同样有效，但在减少越狱方面 BCT 效果更好。

Conclusion: 一致性训练可以作为一种替代方案，用于解决部分对齐问题，将其视为一致性问题而非最优响应问题，并且 BCT 可以简化训练流程，无需依赖静态数据集。

Abstract: An LLM's factuality and refusal training can be compromised by simple changes
to a prompt. Models often adopt user beliefs (sycophancy) or satisfy
inappropriate requests which are wrapped within special text (jailbreaking). We
explore \emph{consistency training}, a self-supervised paradigm that teaches a
model to be invariant to certain irrelevant cues in the prompt. Instead of
teaching the model what exact response to give on a particular prompt, we aim
to teach the model to behave identically across prompt data augmentations (like
adding leading questions or jailbreak text). We try enforcing this invariance
in two ways: over the model's external outputs (\emph{Bias-augmented
Consistency Training} (BCT) from Chua et al. [2025]) and over its internal
activations (\emph{Activation Consistency Training} (ACT), a method we
introduce). Both methods reduce Gemini 2.5 Flash's susceptibility to irrelevant
cues. Because consistency training uses responses from the model itself as
training data, it avoids issues that arise from stale training data, such as
degrading model capabilities or enforcing outdated response guidelines. While
BCT and ACT reduce sycophancy equally well, BCT does better at jailbreak
reduction. We think that BCT can simplify training pipelines by removing
reliance on static datasets. We argue that some alignment problems are better
viewed not in terms of optimal responses, but rather as consistency issues.

</details>


### [292] [Towards a Measure of Algorithm Similarity](https://arxiv.org/abs/2510.27063)
*Shairoz Sohail,Taher Ali*

Main category: cs.LG

TL;DR: 该论文提出了一种名为EMOC的框架，用于评估和量化算法实现的相似性，并构建了一个名为PACD的数据集来验证该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 在给定两个解决相同问题的算法时，需要一种方法来判断它们是否存在显著差异。尽管在一般情况下，这个问题是不可计算的，并且存在多种衡量相似性的标准，但在诸如克隆检测或程序合成等实际应用中，需要一个实用且一致的相似性度量。

Method: EMOC框架将算法实现嵌入到一个特征空间中，该空间适用于下游任务。研究人员编译了一个名为PACD的数据集，其中包含跨三个问题的经过验证的Python实现，并使用EMOC特征来支持算法类型的聚类和分类、近重复项的检测以及LLM生成程序的多元性量化。

Result: EMOC特征能够有效地支持算法类型的聚类和分类、近重复项的检测以及LLM生成程序的多元性量化。所发布的代码、数据和计算EMOC嵌入的工具将有助于可重复性和算法相似性方面的未来研究。

Conclusion: EMOC框架为评估和量化算法相似性提供了一种有效的方法，并且所构建的PACD数据集和相关工具能够支持多种下游应用，推动算法相似性研究的发展。

Abstract: Given two algorithms for the same problem, can we determine whether they are
meaningfully different? In full generality, the question is uncomputable, and
empirically it is muddied by competing notions of similarity. Yet, in many
applications (such as clone detection or program synthesis) a pragmatic and
consistent similarity metric is necessary. We review existing equivalence and
similarity notions and introduce EMOC: An
Evaluation-Memory-Operations-Complexity framework that embeds algorithm
implementations into a feature space suitable for downstream tasks. We compile
PACD, a curated dataset of verified Python implementations across three
problems, and show that EMOC features support clustering and classification of
algorithm types, detection of near-duplicates, and quantification of diversity
in LLM-generated programs. Code, data, and utilities for computing EMOC
embeddings are released to facilitate reproducibility and future work on
algorithm similarity.

</details>


### [293] [MLPerf Automotive](https://arxiv.org/abs/2510.27065)
*Radoyeh Shojaei,Predrag Djurdjevic,Mostafa El-Khamy,James Goel,Kasper Mecklenburg,John Owens,Pınar Muyan-Özçelik,Tom St. John,Jinho Suh,Arjun Suresh*

Main category: cs.LG

TL;DR: MLPerf Automotive是首个用于评估汽车AI加速器性能的标准化公共基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法满足汽车领域对安全性、实时性等方面的独特需求，因此需要专门的基准测试来评估汽车机器学习系统。

Method: 该基准测试框架提供了延迟和准确性指标以及评估协议，实现了跨不同硬件平台和软件实现的性能比较。首批测试包括2D目标检测、2D语义分割和3D目标检测等汽车感知任务，并描述了任务选择、参考模型和提交规则等设计方法。

Result: 讨论了基准测试的首次提交情况，以及获取数据集和开发参考实现所面临的挑战。

Conclusion: MLPerf Automotive为汽车机器学习系统的性能评估提供了标准化方法，并首次发布了包括汽车感知任务在内的基准测试结果。

Abstract: We present MLPerf Automotive, the first standardized public benchmark for
evaluating Machine Learning systems that are deployed for AI acceleration in
automotive systems. Developed through a collaborative partnership between
MLCommons and the Autonomous Vehicle Computing Consortium, this benchmark
addresses the need for standardized performance evaluation methodologies in
automotive machine learning systems. Existing benchmark suites cannot be
utilized for these systems since automotive workloads have unique constraints
including safety and real-time processing that distinguish them from the
domains that previously introduced benchmarks target. Our benchmarking
framework provides latency and accuracy metrics along with evaluation protocols
that enable consistent and reproducible performance comparisons across
different hardware platforms and software implementations. The first iteration
of the benchmark consists of automotive perception tasks in 2D object
detection, 2D semantic segmentation, and 3D object detection. We describe the
methodology behind the benchmark design including the task selection, reference
models, and submission rules. We also discuss the first round of benchmark
submissions and the challenges involved in acquiring the datasets and the
engineering efforts to develop the reference implementations. Our benchmark
code is available at https://github.com/mlcommons/mlperf_automotive.

</details>


### [294] [Towards Understanding Self-play for LLM Reasoning](https://arxiv.org/abs/2510.27072)
*Justin Yang Chae,Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 大型语言模型（LLM）通过生成和解决自身问题来进行自我提升，但其改进机制尚不清楚。本研究通过分析“绝对零推理器”的训练动态，并与RLVR和SFT进行比较，来阐明自我对弈的机制。研究内容包括参数更新稀疏性、Token分布熵动态以及替代生成器奖励函数，并将其与推理性能联系起来。研究结果揭示了自我对弈与其他方法的区别、其局限性，并为未来改进LLM数学推理提供了方向。


<details>
  <summary>Details</summary>
Motivation: 自我对弈作为一种提高大型语言模型（LLM）推理能力的方法，已经被证明能带来显著的性能提升，但其背后的具体机制却缺乏深入的理解。因此，有必要对自我对弈的训练动态进行分析，以揭示其改进的原理。

Method: 通过分析“绝对零推理器”的训练动态，并将其与强化学习（RLVR）和监督微调（SFT）进行比较。具体分析包括：参数更新稀疏性、Token分布熵动态、替代生成器奖励函数。最后，将这些动态与使用pass@k评估的推理性能联系起来。

Result: 研究阐明了自我对弈与其他训练策略（如RLVR和SFT）的区别，揭示了自我对弈方法固有的局限性，并为未来通过自我对弈提升LLM数学推理能力指明了方向。

Conclusion: 自我对弈通过特定的训练动态（如参数更新稀疏性和熵动态）实现LLM推理能力的提升，但其也存在固有的局限性。理解这些动态有助于开发更有效的自我对弈策略，从而进一步改进LLM的数学推理能力。

Abstract: Recent advances in large language model (LLM) reasoning, led by reinforcement
learning with verifiable rewards (RLVR), have inspired self-play post-training,
where models improve by generating and solving their own problems. While
self-play has shown strong in-domain and out-of-domain gains, the mechanisms
behind these improvements remain poorly understood. In this work, we analyze
the training dynamics of self-play through the lens of the Absolute Zero
Reasoner, comparing it against RLVR and supervised fine-tuning (SFT). Our study
examines parameter update sparsity, entropy dynamics of token distributions,
and alternative proposer reward functions. We further connect these dynamics to
reasoning performance using pass@k evaluations. Together, our findings clarify
how self-play differs from other post-training strategies, highlight its
inherent limitations, and point toward future directions for improving LLM math
reasoning through self-play.

</details>


### [295] [QiNN-QJ: A Quantum-inspired Neural Network with Quantum Jump for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.27091)
*Yiwei Chen,Kehuan Yan,Yu Pan,Daoyi Dong*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 QiNN-QJ 的量子启发的神经网络模型，用于多模态纠缠建模，通过模拟量子跳转 (QJ) 算子实现可控的跨模态纠缠，并在多个基准数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的量子启发融合模型主要依赖酉变换来生成量子纠缠，但存在训练不稳定和泛化能力有限的问题。本研究旨在提出一种新的模型来解决这些问题。

Method: 提出了一种名为 QiNN-QJ 的量子启发的神经网络模型。该模型将每个模态编码为量子纯态，然后使用模拟 QJ 算子的可微模块将可分离乘积态转换为纠缠表示。通过联合学习哈密顿量和 Lindblad 算子，QiNN-QJ 在耗散动力学中实现了可控的跨模态纠缠，利用结构化随机性和稳态吸引子特性来稳定训练并约束纠缠塑造。最后，将纠缠态投影到可训练的测量向量上以产生预测。

Result: QiNN-QJ 在 CMU-MOSI、CMU-MOSEI 和 CH-SIMS 等基准数据集上取得了优于现有模型的性能。此外，该模型通过冯·诺依曼纠缠熵增强了事后可解释性。

Conclusion: 本研究建立了一个原则性的纠缠多模态融合框架，为量子启发的模型在复杂跨模态相关性建模方面开辟了新途径。

Abstract: Quantum theory provides non-classical principles, such as superposition and
entanglement, that inspires promising paradigms in machine learning. However,
most existing quantum-inspired fusion models rely solely on unitary or
unitary-like transformations to generate quantum entanglement. While
theoretically expressive, such approaches often suffer from training
instability and limited generalizability. In this work, we propose a
Quantum-inspired Neural Network with Quantum Jump (QiNN-QJ) for multimodal
entanglement modelling. Each modality is firstly encoded as a quantum pure
state, after which a differentiable module simulating the QJ operator
transforms the separable product state into the entangled representation. By
jointly learning Hamiltonian and Lindblad operators, QiNN-QJ generates
controllable cross-modal entanglement among modalities with dissipative
dynamics, where structured stochasticity and steady-state attractor properties
serve to stabilize training and constrain entanglement shaping. The resulting
entangled states are projected onto trainable measurement vectors to produce
predictions. In addition to achieving superior performance over the
state-of-the-art models on benchmark datasets, including CMU-MOSI, CMU-MOSEI,
and CH-SIMS, QiNN-QJ facilitates enhanced post-hoc interpretability through
von-Neumann entanglement entropy. This work establishes a principled framework
for entangled multimodal fusion and paves the way for quantum-inspired
approaches in modelling complex cross-modal correlations.

</details>


### [296] [Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle](https://arxiv.org/abs/2510.27097)
*Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 该研究提出了一种新的概率分层贝叶斯模型，用于从宏观RNA测序数据中解析出细胞类型表达谱和比例，并应用于分析月经周期中子宫内膜的细胞动态变化。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统宏观组织RNA测序数据平均化表达谱掩盖细胞类型特异性动态的问题。

Method: 提出了一种概率分层贝叶斯模型，并结合高分辨率单细胞参考数据，对宏观RNA测序数据进行细胞类型表达谱和比例的反卷积。该模型被应用于分析月经周期中子宫内膜的细胞组成变化。

Result: 该模型能够推断细胞类型比例和细胞特异性的基因表达变化。研究结果揭示了月经周期不同阶段上皮细胞、基质细胞和免疫细胞比例的动态变化，并识别出与子宫内膜功能相关的细胞类型特异性差异基因表达（例如，分泌期基质细胞中的蜕膜化标记物）。此外，研究还展示了该模型在面对参考不匹配和噪声时的鲁棒性。

Conclusion: 该研究提出的贝叶斯模型能够有效解析细胞类型特异性的基因表达，揭示了月经周期中子宫内膜细胞动态变化的生物学意义，并具有潜在的临床应用价值，如在生育和子宫内膜疾病方面。未来研究可考虑整合空间转录组学数据。

Abstract: Bulk tissue RNA sequencing of heterogeneous samples provides averaged gene
expression profiles, obscuring cell type-specific dynamics. To address this, we
present a probabilistic hierarchical Bayesian model that deconvolves bulk
RNA-seq data into constituent cell-type expression profiles and proportions,
leveraging a high-resolution single-cell reference. We apply our model to human
endometrial tissue across the menstrual cycle, a context characterized by
dramatic hormone-driven cellular composition changes. Our extended framework
provides a principled inference of cell type proportions and cell-specific gene
expression changes across cycle phases. We demonstrate the model's structure,
priors, and inference strategy in detail, and we validate its performance with
simulations and comparisons to existing methods. The results reveal dynamic
shifts in epithelial, stromal, and immune cell fractions between menstrual
phases, and identify cell-type-specific differential gene expression associated
with endometrial function (e.g., decidualization markers in stromal cells
during the secretory phase). We further conduct robustness tests and show that
our Bayesian approach is resilient to reference mismatches and noise. Finally,
we discuss the biological significance of our findings, potential clinical
implications for fertility and endometrial disorders, and future directions,
including integration of spatial transcriptomics.

</details>


### [297] [Group-Sensitive Offline Contextual Bandits](https://arxiv.org/abs/2510.27123)
*Yihong Guo,Junjie Luo,Guodong Gao,Ritu Agarwal,Anqi Liu*

Main category: cs.LG

TL;DR: 本研究提出了一种考虑公平性的离线上下文老虎机算法，用于在优化整体奖励的同时，减少不同用户群体间的奖励差异。


<details>
  <summary>Details</summary>
Motivation: 现有的离线上下文老虎机算法在优化整体奖励时，可能无意中加剧了不同用户群体间的奖励差异，引发了公平性担忧，尤其是在资源有限的情况下。

Method: 提出了一种约束性离线策略优化框架，将群体奖励差异约束引入到基于策略梯度的离线优化过程中。为了更准确地估计群体奖励差异，采用了双重稳健估计量，并提供了策略优化收敛的保证。

Result: 在合成和真实世界数据集上的实证结果表明，该方法在保持具有竞争力的整体性能的同时，能有效减少奖励差异。

Conclusion: 所提出的方法能够有效解决离线上下文老虎机中的公平性问题，在优化整体奖励的同时，减少了群体间的奖励差异。

Abstract: Offline contextual bandits allow one to learn policies from
historical/offline data without requiring online interaction. However, offline
policy optimization that maximizes overall expected rewards can unintentionally
amplify the reward disparities across groups. As a result, some groups might
benefit more than others from the learned policy, raising concerns about
fairness, especially when the resources are limited. In this paper, we study a
group-sensitive fairness constraint in offline contextual bandits, reducing
group-wise reward disparities that may arise during policy learning. We tackle
the following common-parity requirements: the reward disparity is constrained
within some user-defined threshold or the reward disparity should be minimized
during policy optimization. We propose a constrained offline policy
optimization framework by introducing group-wise reward disparity constraints
into an off-policy gradient-based optimization procedure. To improve the
estimation of the group-wise reward disparity during training, we employ a
doubly robust estimator and further provide a convergence guarantee for policy
optimization. Empirical results in synthetic and real-world datasets
demonstrate that our method effectively reduces reward disparities while
maintaining competitive overall performance.

</details>


### [298] [AI Agents in Drug Discovery](https://arxiv.org/abs/2510.27130)
*Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth*

Main category: cs.LG

TL;DR: AI代理，特别是基于LLM的系统，正在彻底改变药物发现，能够自主处理复杂的任务，如数据集成、实验执行和假设细化，从而大大提高速度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: AI代理，特别是基于LLM的系统，正在彻底改变药物发现，能够自主处理复杂的任务，如数据集成、实验执行和假设细化，从而大大提高速度和可扩展性。

Method: 介绍并讨论了各种AI代理架构（如ReAct、Reflection、Supervisor和Swarm），并重点介绍了它们在药物发现的各个阶段（包括文献综合、毒性预测、协议生成、小分子合成、药物再利用和端到端决策）的应用。

Result: 早期实施表明，AI代理在速度、可重复性和可扩展性方面取得了显著的进步，将曾经需要数月的工作流程压缩到数小时内，同时保持科学可追溯性。

Conclusion: AI代理在药物发现中展现出巨大潜力，但也面临数据异构性、系统可靠性、隐私和基准测试等挑战，未来的研究方向包括技术支持科学和转化。

Abstract: Artificial intelligence (AI) agents are emerging as transformative tools in
drug discovery, with the ability to autonomously reason, act, and learn through
complicated research workflows. Building on large language models (LLMs)
coupled with perception, computation, action, and memory tools, these agentic
AI systems could integrate diverse biomedical data, execute tasks, carry out
experiments via robotic platforms, and iteratively refine hypotheses in closed
loops. We provide a conceptual and technical overview of agentic AI
architectures, ranging from ReAct and Reflection to Supervisor and Swarm
systems, and illustrate their applications across key stages of drug discovery,
including literature synthesis, toxicity prediction, automated protocol
generation, small-molecule synthesis, drug repurposing, and end-to-end
decision-making. To our knowledge, this represents the first comprehensive work
to present real-world implementations and quantifiable impacts of agentic AI
systems deployed in operational drug discovery settings. Early implementations
demonstrate substantial gains in speed, reproducibility, and scalability,
compressing workflows that once took months into hours while maintaining
scientific traceability. We discuss the current challenges related to data
heterogeneity, system reliability, privacy, and benchmarking, and outline
future directions towards technology in support of science and translation.

</details>


### [299] [Exploring the Utilities of the Rationales from Large Language Models to Enhance Automated Essay Scoring](https://arxiv.org/abs/2510.27131)
*Hong Jiao,Hanna Choi,Haowei Hua*

Main category: cs.LG

TL;DR: GPT-4.1和GPT-5生成的释义在自动评分中的效用，并与基于文章的评分进行了比较。


<details>
  <summary>Details</summary>
Motivation: 探讨GPT-4.1和GPT-5生成的释义在自动评分中的效用，并将基于释义的评分与基于文章的评分进行比较。

Method: 使用2012年Kaggle ASAP数据集中的Prompt 6论文，比较了基于文章的评分和基于释义的评分。研究了集成模型，包括仅基于文章的模型、基于文章和释义的模型以及基于文章和两个释义的模型。

Result: 总的来说，基于文章的评分表现优于基于释义的评分，具有更高的二次加权Kappa（QWK）。然而，在F1分数方面，基于释义的评分在分数0上实现了更高的评分准确性，这主要是由于类别不平衡问题。集成模型提高了评分准确性。将基于文章的评分与两个基于释义的评分相结合，在QWK为0.870时实现了最佳的评分准确性，优于文献中报道的0.848。

Conclusion: 集成方法，特别是结合了基于文章的评分和两种基于释义的评分的方法，可以提高自动评分的准确性，并且优于现有文献中报道的结果。

Abstract: This study explored the utilities of rationales generated by GPT-4.1 and
GPT-5 in automated scoring using Prompt 6 essays from the 2012 Kaggle ASAP
data. Essay-based scoring was compared with rationale-based scoring. The study
found in general essay-based scoring performed better than rationale-based
scoring with higher Quadratic Weighted Kappa (QWK). However, rationale-based
scoring led to higher scoring accuracy in terms of F1 scores for score 0 which
had less representation due to class imbalance issues. The ensemble modeling of
essay-based scoring models increased the scoring accuracy at both specific
score levels and across all score levels. The ensemble modeling of essay-based
scoring and each of the rationale-based scoring performed about the same.
Further ensemble of essay-based scoring and both rationale-based scoring
yielded the best scoring accuracy with QWK of 0.870 compared with 0.848
reported in literature.

</details>


### [300] [FairAD: Computationally Efficient Fair Graph Clustering via Algebraic Distance](https://arxiv.org/abs/2510.27136)
*Minh Phu Vuong,Young-Ju Lee,Iván Ojeda-Ruiz,Chul-Ho Lee*

Main category: cs.LG

TL;DR: FairAD是一种高效的公平图聚类方法，通过构建新的亲和矩阵和图粗化过程，在保证公平性的同时，比现有方法快40倍。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在某些人口群体中存在不良行为，因此公平性在图聚类中受到关注。公平图聚类旨在使每个簇中受保护群体的比例与整个数据集中该群体的比例一致。

Method: FairAD首先基于代数距离构建新的亲和矩阵以施加公平性约束，然后对该亲和矩阵执行图粗化过程以寻找代表k个簇的节点，最后通过求解约束最小化问题来获得公平聚类解。

Result: 在修改后的随机块模型和六个公共数据集上的实验结果表明，FairAD在保证公平聚类的同时，速度比最先进的公平图聚类算法快40倍。

Conclusion: FairAD能够实现公平图聚类，并且在计算效率方面优于现有方法。

Abstract: Due to the growing concern about unsavory behaviors of machine learning
models toward certain demographic groups, the notion of 'fairness' has recently
drawn much attention from the community, thereby motivating the study of
fairness in graph clustering. Fair graph clustering aims to partition the set
of nodes in a graph into $k$ disjoint clusters such that the proportion of each
protected group within each cluster is consistent with the proportion of that
group in the entire dataset. It is, however, computationally challenging to
incorporate fairness constraints into existing graph clustering algorithms,
particularly for large graphs. To address this problem, we propose FairAD, a
computationally efficient fair graph clustering method. It first constructs a
new affinity matrix based on the notion of algebraic distance such that
fairness constraints are imposed. A graph coarsening process is then performed
on this affinity matrix to find representative nodes that correspond to $k$
clusters. Finally, a constrained minimization problem is solved to obtain the
solution of fair clustering. Experiment results on the modified stochastic
block model and six public datasets show that FairAD can achieve fair
clustering while being up to 40 times faster compared to state-of-the-art fair
graph clustering algorithms.

</details>


### [301] [Relation-Aware Bayesian Optimization of DBMS Configurations Guided by Affinity Scores](https://arxiv.org/abs/2510.27145)
*Sein Kwon,Seulgi Baek,Hyunseo Yang,Youngwan Jo,Sanghyun Park*

Main category: cs.LG

TL;DR: RelTune是一个新颖的数据库管理系统（DBMS）配置优化框架，通过图神经网络（GNN）学习参数依赖关系，并结合混合分数指导的贝叶斯优化（HBO）来提高优化效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据库调优方法忽略参数间的依赖关系，且常只优化部分参数，导致无法充分发挥性能。贝叶斯优化（BO）方法也存在预测不稳和探索效率低的问题。

Method: RelTune提出用关系图表示参数依赖，并学习GNN嵌入来编码性能相关语义。此外，RelTune引入混合分数指导的贝叶斯优化（HBO），结合了代理模型预测和衡量与先前高性能配置接近度的亲和分数。

Result: 在多个DBMS和工作负载上的实验表明，RelTune比传统基于BO的方法收敛更快，优化效率更高，并在所有评估场景中达到了最先进的性能。

Conclusion: RelTune通过有效处理参数依赖和改进优化策略，显著提升了DBMS的配置优化效率和最终性能。

Abstract: Database Management Systems (DBMSs) are fundamental for managing large-scale
and heterogeneous data, and their performance is critically influenced by
configuration parameters. Effective tuning of these parameters is essential for
adapting to diverse workloads and maximizing throughput while minimizing
latency. Recent research has focused on automated configuration optimization
using machine learning; however, existing approaches still exhibit several key
limitations. Most tuning frameworks disregard the dependencies among
parameters, assuming that each operates independently. This simplification
prevents optimizers from leveraging relational effects across parameters,
limiting their capacity to capture performancesensitive interactions. Moreover,
to reduce the complexity of the high-dimensional search space, prior work often
selects only the top few parameters for optimization, overlooking others that
contribute meaningfully to performance. Bayesian Optimization (BO), the most
common method for automatic tuning, is also constrained by its reliance on
surrogate models, which can lead to unstable predictions and inefficient
exploration. To overcome these limitations, we propose RelTune, a novel
framework that represents parameter dependencies as a Relational Graph and
learns GNN-based latent embeddings that encode performancerelevant semantics.
RelTune further introduces Hybrid-Score-Guided Bayesian Optimization (HBO),
which combines surrogate predictions with an Affinity Score measuring proximity
to previously high-performing configurations. Experimental results on multiple
DBMSs and workloads demonstrate that RelTune achieves faster convergence and
higher optimization efficiency than conventional BO-based methods, achieving
state-of-the-art performance across all evaluated scenarios.

</details>


### [302] [Exploring Landscapes for Better Minima along Valleys](https://arxiv.org/abs/2510.27153)
*Tong Zhao,Jiacheng Li,Yuanchang Zhou,Guangming Tan,Weile Jia*

Main category: cs.LG

TL;DR: 梯度下降优化器通过引入一个名为'E'的适配器来改进，该适配器能在找到局部最小值后继续探索，从而更有可能找到泛化能力更强的低点。


<details>
  <summary>Details</summary>
Motivation: 现有优化器在找到局部最小值后停止搜索，但这些局部最小值不一定是全局最优或泛化能力最好的，因为损失景观的几何特性复杂。

Method: 提出了一种名为'E'的适配器，用于梯度下降优化器。该适配器使优化器在达到局部最小值后，能在损失值低且相似的区域（山谷）继续探索，以寻找潜在的更优局部最小值。

Result: 将适配器'E'应用于Lamb优化器，形成ALTO。在大型批量训练任务中，ALTO比现有的最先进优化器平均提高了2.5%的测试准确率。

Conclusion: ALTO在大型批量训练场景下显著提高了泛化能力，可能为优化算法设计开辟新的研究方向。

Abstract: Finding lower and better-generalizing minima is crucial for deep learning.
However, most existing optimizers stop searching the parameter space once they
reach a local minimum. Given the complex geometric properties of the loss
landscape, it is difficult to guarantee that such a point is the lowest or
provides the best generalization. To address this, we propose an adaptor "E"
for gradient-based optimizers. The adapted optimizer tends to continue
exploring along landscape valleys (areas with low and nearly identical losses)
in order to search for potentially better local minima even after reaching a
local minimum. This approach increases the likelihood of finding a lower and
flatter local minimum, which is often associated with better generalization. We
also provide a proof of convergence for the adapted optimizers in both convex
and non-convex scenarios for completeness. Finally, we demonstrate their
effectiveness in an important but notoriously difficult training scenario,
large-batch training, where Lamb is the benchmark optimizer. Our testing
results show that the adapted Lamb, ALTO, increases the test accuracy
(generalization) of the current state-of-the-art optimizer by an average of
2.5% across a variety of large-batch training tasks. This work potentially
opens a new research direction in the design of optimization algorithms.

</details>


### [303] [Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](https://arxiv.org/abs/2510.27172)
*Zixuan Hu,Li Shen,Zhenyi Wang,Yongxian Wei,Dacheng Tao*

Main category: cs.LG

TL;DR: 有害微调对大型语言模型即服务构成安全风险。本研究提出了一种名为贝叶斯数据调度器 (BDS) 的自适应防御策略，无需攻击模拟，通过贝叶斯推理学习数据点的安全属性，并据此加权数据以减轻有害数据的影响。


<details>
  <summary>Details</summary>
Motivation: 现有防御策略通过攻击模拟来增强鲁棒性，但存在无法应对未知攻击和适应性有限的局限性。

Method: 将有害微调防御视为贝叶斯推理问题，学习数据点安全属性的后验分布，并根据该分布对微调过程中的数据进行加权，以减轻有害数据的影响。提出了一种基于分摊贝叶斯学习的神经网络调度器，实现了无需重新训练即可高效迁移到新数据。 

Result: 在多种攻击和防御场景下，该方法均取得了最先进的性能。

Conclusion: 本研究提出的贝叶斯数据调度器 (BDS) 是一种有效的、自适应的微调阶段防御策略，能够应对有害微调带来的安全风险，且无需进行攻击模拟。

Abstract: Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service
for large language models. Existing defense strategies preemptively build
robustness via attack simulation but suffer from fundamental limitations: (i)
the infeasibility of extending attack simulations beyond bounded threat models
due to the inherent difficulty of anticipating unknown attacks, and (ii)
limited adaptability to varying attack settings, as simulation fails to capture
their variability and complexity. To address these challenges, we propose
Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with
no need for attack simulation. BDS formulates harmful fine-tuning defense as a
Bayesian inference problem, learning the posterior distribution of each data
point's safety attribute, conditioned on the fine-tuning and alignment
datasets. The fine-tuning process is then constrained by weighting data with
their safety attributes sampled from the posterior, thus mitigating the
influence of harmful data. By leveraging the post hoc nature of Bayesian
inference, the posterior is conditioned on the fine-tuning dataset, enabling
BDS to tailor its defense to the specific dataset, thereby achieving adaptive
defense. Furthermore, we introduce a neural scheduler based on amortized
Bayesian learning, enabling efficient transfer to new data without retraining.
Comprehensive results across diverse attack and defense settings demonstrate
the state-of-the-art performance of our approach. Code is available at
https://github.com/Egg-Hu/Bayesian-Data-Scheduler.

</details>


### [304] [A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions](https://arxiv.org/abs/2510.27177)
*Junfan Li,Shizhong Liao,Zenglin Xu,Liqiang Nie*

Main category: cs.LG

TL;DR: 本文提出了一种在线稀疏线性回归（OSLR）新算法，在兼容性条件下显著优于现有算法，并讨论了附加观测值的O SLR情况。


<details>
  <summary>Details</summary>
Motivation: 研究在线稀疏线性回归（OSLR）问题，其中算法被限制为每次仅访问 k 个属性进行预测，这是一个 NP-hard 问题。

Method: 提出了一种新的多项式时间算法，利用了Dantzig选择器，并结合了算法相关采样方案、自适应参数调整方案以及带仔细初始化的批量在线牛顿步。

Result: 该算法在兼容性条件下显著改善了先前算法的遗憾界限，并扩展到具有附加观测值的OSLR问题，也改善了先前算法的遗憾界限。

Conclusion: 新算法通过更紧密的估计量ℓ1范数误差收敛率，在兼容性条件下改进了OSLR的遗憾界限，并成功扩展到具有附加观测值的OSLR问题。

Abstract: In this paper, we study the problem of online sparse linear regression (OSLR)
where the algorithms are restricted to accessing only $k$ out of $d$ attributes
per instance for prediction, which was proved to be NP-hard. Previous work gave
polynomial-time algorithms assuming the data matrix satisfies the linear
independence of features, the compatibility condition, or the restricted
isometry property. We introduce a new polynomial-time algorithm, which
significantly improves previous regret bounds (Ito et al., 2017) under the
compatibility condition that is weaker than the other two assumptions. The
improvements benefit from a tighter convergence rate of the $\ell_1$-norm error
of our estimators. Our algorithm leverages the well-studied Dantzig Selector,
but importantly with several novel techniques, including an algorithm-dependent
sampling scheme for estimating the covariance matrix, an adaptive parameter
tuning scheme, and a batching online Newton step with careful initializations.
We also give novel and non-trivial analyses, including an induction method for
analyzing the $\ell_1$-norm error, careful analyses on the covariance of
non-independent random variables, and a decomposition on the regret. We further
extend our algorithm to OSLR with additional observations where the algorithms
can observe additional $k_0$ attributes after each prediction, and improve
previous regret bounds (Kale et al., 2017; Ito et al., 2017).

</details>


### [305] [MDAS-GNN: Multi-Dimensional Spatiotemporal GNN with Spatial Diffusion for Urban Traffic Risk Forecasting](https://arxiv.org/abs/2510.27197)
*Ziyuan Gao*

Main category: cs.LG

TL;DR: 该研究提出了MDAS-GNN模型，一种多维注意力图神经网络，用于更准确地预测交通事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事故预测模型未能有效捕捉城市交通网络中复杂的空间关系和时间依赖性，因此需要一种能够整合多维度风险因素并考虑时空关联的新模型。

Method: MDAS-GNN模型整合了交通安全、基础设施和环境风险三个核心维度，并利用特征特定的空间扩散机制和多头时间注意力来捕捉不同时间尺度的依赖关系。

Result: 在英国交通部伦敦、曼彻斯特和伯明翰的交通事故数据上进行评估，MDAS-GNN在短期、中期和长期预测中均表现优于现有基线方法，尤其在长期预测方面表现突出。消融研究表明，整合多维度特征比单一特征能将预测误差降低高达40%。

Conclusion: MDAS-GNN模型能够有效提高交通事故预测的准确性，为城市规划者和工程师提供数据驱动的决策支持，以优化道路网络设计、改善基础设施和实施战略安全干预措施。

Abstract: Traffic accidents represent a critical public health challenge, claiming over
1.35 million lives annually worldwide. Traditional accident prediction models
treat road segments independently, failing to capture complex spatial
relationships and temporal dependencies in urban transportation networks. This
study develops MDAS-GNN, a Multi-Dimensional Attention-based Spatial-diffusion
Graph Neural Network integrating three core risk dimensions: traffic safety,
infrastructure, and environmental risk. The framework employs feature-specific
spatial diffusion mechanisms and multi-head temporal attention to capture
dependencies across different time horizons. Evaluated on UK Department for
Transport accident data across Central London, South Manchester, and SE
Birmingham, MDASGNN achieves superior performance compared to established
baseline methods. The model maintains consistently low prediction errors across
short, medium, and long-term periods, with particular strength in long-term
forecasting. Ablation studies confirm that integrated multi-dimensional
features outperform singlefeature approaches, reducing prediction errors by up
to 40%. This framework provides civil engineers and urban planners with
advanced predictive capabilities for transportation infrastructure design,
enabling data-driven decisions for road network optimization, infrastructure
resource improvements, and strategic safety interventions in urban development
projects.

</details>


### [306] [Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models](https://arxiv.org/abs/2510.27207)
*Hamed Najafi,Dongsheng Luo,Jason Liu*

Main category: cs.LG

TL;DR: FFCA通过分析模型学习函数的几何结构，提供特征的4维签名（影响、波动性、非线性、交互性），并扩展到动态分析，揭示模型如何学习，以及识别模型容量不足和预测过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释AI（XAI）方法提供模型静态的、不完整的特征归因，无法处理非线性和交互作用。需要一种新的框架来全面理解模型的学习过程。

Method: 提出特征-函数曲率分析（FFCA）框架，计算特征的4维签名（影响、波动性、非线性、交互性），并扩展到动态原型分析（DAA），追踪这些签名在训练过程中的演变。

Result: FFCA提供了特征的静态和动态分析。动态分析首次提供了模型学习的经验证据，表明模型按层次学习（先学习简单线性效应，后学习复杂交互）。FFCA还可以诊断模型容量不足和预测过拟合。

Conclusion: FFCA及其动态扩展提供了模型解释所需的几何背景，将模型解释从简单的量化转变为对整个学习过程的细致、可信的分析。

Abstract: Explainable AI (XAI) is critical for building trust in complex machine
learning models, yet mainstream attribution methods often provide an
incomplete, static picture of a model's final state. By collapsing a feature's
role into a single score, they are confounded by non-linearity and
interactions. To address this, we introduce Feature-Function Curvature Analysis
(FFCA), a novel framework that analyzes the geometry of a model's learned
function. FFCA produces a 4-dimensional signature for each feature, quantifying
its: (1) Impact, (2) Volatility, (3) Non-linearity, and (4) Interaction.
Crucially, we extend this framework into Dynamic Archetype Analysis, which
tracks the evolution of these signatures throughout the training process. This
temporal view moves beyond explaining what a model learned to revealing how it
learns. We provide the first direct, empirical evidence of hierarchical
learning, showing that models consistently learn simple linear effects before
complex interactions. Furthermore, this dynamic analysis provides novel,
practical diagnostics for identifying insufficient model capacity and
predicting the onset of overfitting. Our comprehensive experiments demonstrate
that FFCA, through its static and dynamic components, provides the essential
geometric context that transforms model explanation from simple quantification
to a nuanced, trustworthy analysis of the entire learning process.

</details>


### [307] [Soft Task-Aware Routing of Experts for Equivariant Representation Learning](https://arxiv.org/abs/2510.27222)
*Jaebyeong Jeon,Hyeonseo Jang,Jy-yong Sohn,Kibok Lee*

Main category: cs.LG

TL;DR: STAR通过将投影头建模为专家，并采用一种软任务感知路由策略，实现了不变和等变表示学习的联合优化，减少了冗余特征学习，并在各种迁移学习任务中取得了改进。


<details>
  <summary>Details</summary>
Motivation: 现有的不变和等变表示联合学习方法通常使用单独的投影头，这忽略了两种表示之间共享的信息，导致冗余特征学习和模型容量的低效利用。

Method: 提出了一种名为软任务感知路由（STAR）的路由策略，将投影头视为专家。STAR促使专家专注于捕捉共享信息或任务特定的信息，从而减少冗余特征学习。

Result: 通过观察不变和等变嵌入之间较低的典型相关性来验证STAR减少冗余特征学习的效果。在各种迁移学习任务上进行了实验，结果显示了持续的改进。

Conclusion: STAR通过有效的路由策略实现了不变和等变表示学习的联合优化，减少了冗余，提高了模型效率，并在下游任务中取得了性能提升。

Abstract: Equivariant representation learning aims to capture variations induced by
input transformations in the representation space, whereas invariant
representation learning encodes semantic information by disregarding such
transformations. Recent studies have shown that jointly learning both types of
representations is often beneficial for downstream tasks, typically by
employing separate projection heads. However, this design overlooks information
shared between invariant and equivariant learning, which leads to redundant
feature learning and inefficient use of model capacity. To address this, we
introduce Soft Task-Aware Routing (STAR), a routing strategy for projection
heads that models them as experts. STAR induces the experts to specialize in
capturing either shared or task-specific information, thereby reducing
redundant feature learning. We validate this effect by observing lower
canonical correlations between invariant and equivariant embeddings.
Experimental results show consistent improvements across diverse transfer
learning tasks. The code is available at https://github.com/YonseiML/star.

</details>


### [308] [FedSM: Robust Semantics-Guided Feature Mixup for Bias Reduction in Federated Learning with Long-Tail Data](https://arxiv.org/abs/2510.27240)
*Jingrui Zhang,Yimeng Xu,Shujie Li,Feng Liang,Haihan Duan,Yanjie Dong,Victor C. M. Leung,Xiping Hu*

Main category: cs.LG

TL;DR: FedSM是一个客户端中心的联邦学习框架，通过语义引导的特征混合和轻量级分类器再训练来解决非IID和长尾数据分布导致的全局模型偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）方法在处理非IID和长尾数据分布时，容易产生全局模型偏差。

Method: FedSM利用预训练的图像-文本对齐模型计算类别级别的语义相关性，指导本地特征与全局原型混合，生成类别一致的伪特征，从而纠正分类器偏差。为了应对预训练模型与本地数据之间可能存在的域转移问题，FedSM提出了概率类别选择，以增强特征多样性。所有计算都在本地完成，服务器开销极小。

Result: 在不同类别不平衡程度的长尾数据集上的大量实验表明，FedSM在准确性上始终优于现有最先进的方法，并且对域转移具有高度鲁棒性，计算效率高。

Conclusion: FedSM能够有效缓解联邦学习中的模型偏差问题，尤其是在数据严重偏斜的情况下，并且具有良好的鲁棒性和计算效率。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized clients without sharing private data. However, FL suffers from
biased global models due to non-IID and long-tail data distributions. We
propose \textbf{FedSM}, a novel client-centric framework that mitigates this
bias through semantics-guided feature mixup and lightweight classifier
retraining. FedSM uses a pretrained image-text-aligned model to compute
category-level semantic relevance, guiding the category selection of local
features to mix-up with global prototypes to generate class-consistent
pseudo-features. These features correct classifier bias, especially when data
are heavily skewed. To address the concern of potential domain shift between
the pretrained model and the data, we propose probabilistic category selection,
enhancing feature diversity to effectively mitigate biases. All computations
are performed locally, requiring minimal server overhead. Extensive experiments
on long-tail datasets with various imbalanced levels demonstrate that FedSM
consistently outperforms state-of-the-art methods in accuracy, with high
robustness to domain shift and computational efficiency.

</details>


### [309] [Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation](https://arxiv.org/abs/2510.27253)
*Qiyan Deng,Changqian Zheng,Lianpeng Qiao,Yuping Wang,Chengliang Chai,Lei Cao*

Main category: cs.LG

TL;DR: Dataset distillation通过使用影响函数来评估数据质量，并为每个实例分配自适应权重，以提高蒸馏数据集的质量和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法通常假设所有真实数据实例的贡献是相等的，但忽略了数据质量问题，可能导致模型性能下降。

Method: 提出了一种名为Influence-Weighted Distillation (IWD)的框架，该框架利用影响函数来评估每个数据实例对蒸馏目标的影响，并据此分配权重，优先考虑有益数据，同时降低无效或有害数据的权重。

Result: 将IWD集成到现有的蒸馏方法中，可以提高蒸馏数据集的质量，并提升模型性能，准确率最多可提高7.8%。

Conclusion: IWD是一种有效的方法，可以解决数据集蒸馏中的数据质量问题，通过自适应加权提高蒸馏效率和模型性能。

Abstract: Dataset distillation condenses large datasets into synthetic subsets,
achieving performance comparable to training on the full dataset while
substantially reducing storage and computation costs. Most existing dataset
distillation methods assume that all real instances contribute equally to the
process. In practice, real-world datasets contain both informative and
redundant or even harmful instances, and directly distilling the full dataset
without considering data quality can degrade model performance. In this work,
we present Influence-Weighted Distillation IWD, a principled framework that
leverages influence functions to explicitly account for data quality in the
distillation process. IWD assigns adaptive weights to each instance based on
its estimated impact on the distillation objective, prioritizing beneficial
data while downweighting less useful or harmful ones. Owing to its modular
design, IWD can be seamlessly integrated into diverse dataset distillation
frameworks. Our empirical results suggest that integrating IWD tends to improve
the quality of distilled datasets and enhance model performance, with accuracy
gains of up to 7.8%.

</details>


### [310] [ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models](https://arxiv.org/abs/2510.27256)
*Xin Tang,Youfang Han,Fangfei Gou,Wei Zhao,Xin Meng,Yang Yu,Jinguo Zhang,Yuanchun Shi,Yuntao Wang,Tengxiang Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为ECVL-ROUTER的VLM路由框架，通过动态选择大型或小型模型来满足用户对响应速度、输出质量和能耗的需求，实验证明该方法可在不显著降低问题解决率的情况下，将超过80%的查询路由到小型模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言模型（VLM）在云端部署时，虽然能处理复杂任务，但存在响应延迟高和能耗大的问题；而部署在边缘设备上的小型模型虽然能耗低、响应快，但能力有限。用户在不同场景下对响应速度、输出质量和能耗有不同的需求，需要一种能够根据这些需求动态选择合适模型的方法。

Method: 提出ECVL-ROUTER路由框架，设计了新的路由策略和评估指标，根据用户需求动态选择模型（大型或小型）来处理查询。构建了一个多模态响应质量数据集用于训练路由模型，并通过实验验证该方法的有效性。

Result: 实验结果表明，ECVL-ROUTER成功地将超过80%的查询路由到小型模型，同时问题解决率仅下降不到10%。

Conclusion: ECVL-ROUTER是首个面向VLM的场景感知路由框架，能够根据用户需求智能地选择模型，有效平衡了响应速度、输出质量和能耗，实现了在不显著牺牲性能的情况下提高效率。

Abstract: Vision-Language Models (VLMs) excel in diverse multimodal tasks. However,
user requirements vary across scenarios, which can be categorized into fast
response, high-quality output, and low energy consumption. Relying solely on
large models deployed in the cloud for all queries often leads to high latency
and energy cost, while small models deployed on edge devices are capable of
handling simpler tasks with low latency and energy cost. To fully leverage the
strengths of both large and small models, we propose ECVL-ROUTER, the first
scenario-aware routing framework for VLMs. Our approach introduces a new
routing strategy and evaluation metrics that dynamically select the appropriate
model for each query based on user requirements, maximizing overall utility. We
also construct a multimodal response-quality dataset tailored for router
training and validate the approach through extensive experiments. Results show
that our approach successfully routes over 80\% of queries to the small model
while incurring less than 10\% drop in problem solving probability.

</details>


### [311] [Higher-order Linear Attention](https://arxiv.org/abs/2510.27258)
*Yifan Zhang,Zhen Qin,Quanquan Gu*

Main category: cs.LG

TL;DR: 二次计算的缩放点积注意力是扩展自回归语言模型到长上下文的一个主要障碍。HLA是一种新的因果、流式机制，通过紧凑的前缀充分统计量来实现高阶交互，在保持常数状态和线性时间复杂度的同时，提高了模型的可表达性。


<details>
  <summary>Details</summary>
Motivation: 二次计算的缩放点积注意力是扩展自回归语言模型到长上下文的一个主要障碍。

Method: 提出高阶线性注意力（HLA），一种因果、流式机制，通过紧凑的前缀充分统计量实现高阶交互。在二阶情况下，HLA保持常数大小的状态，并在线性时间内计算每个令牌的输出，而不产生任何 $n 	imes n$ 矩阵。提供了闭式流式表示、使用两个额外摘要的严格因果掩码变体以及基于关联扫描的分块并行训练方案，该方案可以精确地重现串行递归的激活。还概述了向三阶及更高阶的扩展。

Result: HLA在保持常数状态和线性时间复杂度的同时，实现了高阶交互，提高了模型的可表达性，并提供了精确重现串行递归激活的分块并行训练方案。

Conclusion: HLA是一种原则性的、可扩展的构建块，它将类似注意力的、数据依赖的混合与现代递归架构的效率相结合，克服了现有方法的局限性。

Abstract: The quadratic cost of scaled dot-product attention is a central obstacle to
scaling autoregressive language models to long contexts. Linear-time attention
and State Space Models (SSMs) provide scalable alternatives but are typically
restricted to first-order or kernel-based approximations, which can limit
expressivity. We introduce Higher-order Linear Attention (HLA), a causal,
streaming mechanism that realizes higher interactions via compact prefix
sufficient statistics. In the second-order case, HLA maintains a constant-size
state and computes per-token outputs in linear time without materializing any
$n \times n$ matrices. We give closed-form streaming identities, a strictly
causal masked variant using two additional summaries, and a chunk-parallel
training scheme based on associative scans that reproduces the activations of a
serial recurrence exactly. We further outline extensions to third and higher
orders. Collectively, these results position HLA as a principled, scalable
building block that combines attention-like, data-dependent mixing with the
efficiency of modern recurrent architectures. Project Page:
https://github.com/yifanzhang-pro/HLA.

</details>


### [312] [ODP-Bench: Benchmarking Out-of-Distribution Performance Prediction](https://arxiv.org/abs/2510.27263)
*Han Yu,Kehan Li,Dongbai Li,Yue He,Xingxuan Zhang,Peng Cui*

Main category: cs.LG

TL;DR: 该研究提出了ODP-Bench，一个全面的基准测试，用于评估和比较不同模型在未标记的分布外（OOD）数据集上的性能预测算法。该基准测试旨在解决现有研究中评估协议不一致和数据集有限的问题，并为未来的研究提供一个标准化的平台和预训练模型，以促进OOD性能预测领域的发展。


<details>
  <summary>Details</summary>
Motivation: 现有OOD性能预测研究的评估协议不一致，且只涵盖有限的真实世界OOD数据集和分布偏移类型，阻碍了算法间的公平比较和该领域的进一步发展。

Method: 提出ODP-Bench，一个包含常用OOD数据集和现有性能预测算法的综合基准测试。提供预训练模型以保证比较的一致性，并进行深入的实验分析以理解算法的能力边界。

Result: ODP-Bench为OOD性能预测算法提供了一个统一、公平的比较平台，并提供了预训练模型，简化了未来的研究。实验分析揭示了现有算法的能力边界。

Conclusion: ODP-Bench的提出为OOD性能预测领域提供了一个重要的资源，有助于推动该领域的标准化和发展，并为理解和改进OOD性能预测算法提供了新的视角。

Abstract: Recently, there has been gradually more attention paid to Out-of-Distribution
(OOD) performance prediction, whose goal is to predict the performance of
trained models on unlabeled OOD test datasets, so that we could better leverage
and deploy off-the-shelf trained models in risk-sensitive scenarios. Although
progress has been made in this area, evaluation protocols in previous
literature are inconsistent, and most works cover only a limited number of
real-world OOD datasets and types of distribution shifts. To provide convenient
and fair comparisons for various algorithms, we propose Out-of-Distribution
Performance Prediction Benchmark (ODP-Bench), a comprehensive benchmark that
includes most commonly used OOD datasets and existing practical performance
prediction algorithms. We provide our trained models as a testbench for future
researchers, thus guaranteeing the consistency of comparison and avoiding the
burden of repeating the model training process. Furthermore, we also conduct
in-depth experimental analyses to better understand their capability boundary.

</details>


### [313] [HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction](https://arxiv.org/abs/2510.27281)
*Minghui Li,Yuanhang Wang,Peijin Guo,Wei Wan,Shengshan Hu,Shengqing Hu*

Main category: cs.LG

TL;DR: HiF-DTA是一个分层网络，通过双通路策略提取药物和蛋白质序列的全局序列语义和局部拓扑特征，并对药物进行多尺度建模，学习原子、子结构和分子表示，并通过多尺度双线性注意力模块进行融合，在Davis、KIBA和Metz数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于序列的深度学习方法在药物-目标亲和力（DTA）预测方面，忽略了药物和蛋白质的全局序列语义特征和局部拓扑结构特征的同步建模，并且未能学习药物的多尺度特征。

Method: HiF-DTA采用双通路策略提取药物和蛋白质序列的全局序列语义和局部拓扑特征，并对药物进行原子、子结构和分子层面的多尺度表示学习，然后通过多尺度双线性注意力模块进行融合。

Result: 在Davis、KIBA和Metz数据集上的实验结果表明，HiF-DTA的性能优于现有的基线方法。

Conclusion: 实验结果和消融研究证实了全局-局部特征提取和多尺度融合对于HiF-DTA的重要性。

Abstract: Accurate prediction of Drug-Target Affinity (DTA) is crucial for reducing
experimental costs and accelerating early screening in computational drug
discovery. While sequence-based deep learning methods avoid reliance on costly
3D structures, they still overlook simultaneous modeling of global sequence
semantic features and local topological structural features within drugs and
proteins, and represent drugs as flat sequences without atomic-level,
substructural-level, and molecular-level multi-scale features. We propose
HiF-DTA, a hierarchical network that adopts a dual-pathway strategy to extract
both global sequence semantic and local topological features from drug and
protein sequences, and models drugs multi-scale to learn atomic, substructural,
and molecular representations fused via a multi-scale bilinear attention
module. Experiments on Davis, KIBA, and Metz datasets show HiF-DTA outperforms
state-of-the-art baselines, with ablations confirming the importance of
global-local extraction and multi-scale fusion.

</details>


### [314] [Can LLMs Help You at Work? A Sandbox for Evaluating LLM Agents in Enterprise Environments](https://arxiv.org/abs/2510.27287)
*Harsh Vishwakarma,Ankush Agarwal,Ojas Patil,Chaitanya Devaguptapu,Mahesh Chandran*

Main category: cs.LG

TL;DR: EnterpriseBench是一个用于评估企业环境中文心一言代理性能的基准测试，突显了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 为评估和改进企业环境中基于LLM的系统的集成和性能，需要一个能够模拟复杂企业环境（数据碎片化、访问控制、跨职能工作流）的基准。

Method: 提出EnterpriseBench，一个包含500个跨软件工程、人力资源、金融和行政任务的基准测试。它通过组织元数据生成内部一致的企业任务，并包含数据源碎片化、访问控制层次和跨职能工作流等关键企业特征。

Result: 在EnterpriseBench上，即使是最先进的LLM代理也只能完成41.8%的任务，表明在企业人工智能系统方面有很大的改进空间。

Conclusion: 现有的LLM代理在处理复杂企业任务方面能力有限，需要进一步的研究和开发以提高其性能。

Abstract: Enterprise systems are crucial for enhancing productivity and decision-making
among employees and customers. Integrating LLM based systems into enterprise
systems enables intelligent automation, personalized experiences, and efficient
information retrieval, driving operational efficiency and strategic growth.
However, developing and evaluating such systems is challenging due to the
inherent complexity of enterprise environments, where data is fragmented across
multiple sources and governed by sophisticated access controls. We present
EnterpriseBench, a comprehensive benchmark that simulates enterprise settings,
featuring 500 diverse tasks across software engineering, HR, finance, and
administrative domains. Our benchmark uniquely captures key enterprise
characteristics including data source fragmentation, access control
hierarchies, and cross-functional workflows. Additionally, we provide a novel
data generation pipeline that creates internally consistent enterprise tasks
from organizational metadata. Experiments with state-of-the-art LLM agents
demonstrate that even the most capable models achieve only 41.8% task
completion, highlighting significant opportunities for improvement in
enterprise-focused AI systems.

</details>


### [315] [Temporal Cardiovascular Dynamics for Improved PPG-Based Heart Rate Estimation](https://arxiv.org/abs/2510.27297)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 研究通过互信息研究心率的非线性混沌行为，并提出一种新的方法来提高现实条件下心率的估计。


<details>
  <summary>Details</summary>
Motivation: 心率的振荡复杂且非线性，这给在日常生活中应用心血管健康监测带来了挑战。

Method: 利用互信息研究心率的非线性混沌行为，并提出一种新的方法来提高现实条件下心率的估计，该方法可以与深度学习解决方案相结合。

Result: 所提出的方法在估计心率方面比传统方法和现有的机器学习技术有了显著的改进（最高可达40%），同时减少了对多种传感方式的依赖，并消除了对后处理步骤的需求。

Conclusion: 提出了一种新的方法来提高现实条件下心率的估计，该方法在处理非线性时间复杂性方面具有数学解释，并能与深度学习解决方案相结合，从而显著提高心率估计的准确性。

Abstract: The oscillations of the human heart rate are inherently complex and
non-linear -- they are best described by mathematical chaos, and they present a
challenge when applied to the practical domain of cardiovascular health
monitoring in everyday life. In this work, we study the non-linear chaotic
behavior of heart rate through mutual information and introduce a novel
approach for enhancing heart rate estimation in real-life conditions. Our
proposed approach not only explains and handles the non-linear temporal
complexity from a mathematical perspective but also improves the deep learning
solutions when combined with them. We validate our proposed method on four
established datasets from real-life scenarios and compare its performance with
existing algorithms thoroughly with extensive ablation experiments. Our results
demonstrate a substantial improvement, up to 40\%, of the proposed approach in
estimating heart rate compared to traditional methods and existing
machine-learning techniques while reducing the reliance on multiple sensing
modalities and eliminating the need for post-processing steps.

</details>


### [316] [Binary Anomaly Detection in Streaming IoT Traffic under Concept Drift](https://arxiv.org/abs/2510.27304)
*Rodrigo Matos Carnier,Laura Lahesoo,Kensuke Fukuda*

Main category: cs.LG

TL;DR: 本研究旨在解决物联网（IoT）网络流量中的异常检测问题。传统批处理学习模型在处理概念漂移方面存在挑战，而流式学习模型能更好地适应实时变化。研究对比了批处理和流式学习方法在物联网流量异常检测中的表现，并评估了现有数据集的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网网络流量的激增，基于机器学习（ML）的异常检测变得越来越重要。传统批处理学习模型在维护和适应快速变化的异常方面存在挑战（概念漂移），而流式学习则能通过在线和增量学习实现无缝更新和概念漂移检测，提高鲁棒性。

Method: 将物联网流量异常检测视为二元分类问题，通过混合现有数据集并逐一模拟流式传输样本，来模拟异构网络数据流。对比了批处理和流式学习方法，并评估了现有数据集的局限性。同时，研究了基于树的机器学习算法（如自适应随机森林和 Hoeffding 自适应树）与非基于树的算法的性能。

Result: 批处理模型在处理概念漂移方面表现不佳。现有数据集的异构性较低，限制了模型能力的暴露。自适应随机森林达到了 0.990 ± 0.006 的 F1 分数，计算成本仅为其批处理对应模型的三分之一。Hoeffding 自适应树达到了 0.910 ± 0.007 的 F1 分数，计算成本降低了四倍。

Conclusion: 流式学习方法在物联网异常检测中比批处理方法更具优势，尤其是在处理概念漂移方面。自适应随机森林和 Hoeffding 自适应树是处理物联网流量异常检测的可行选择，其中自适应随机森林在性能和稳定性方面表现更优，而 Hoeffding 自适应树在计算成本方面具有显著优势。现有数据集的局限性需要被关注和改进。

Abstract: With the growing volume of Internet of Things (IoT) network traffic, machine
learning (ML)-based anomaly detection is more relevant than ever. Traditional
batch learning models face challenges such as high maintenance and poor
adaptability to rapid anomaly changes, known as concept drift. In contrast,
streaming learning integrates online and incremental learning, enabling
seamless updates and concept drift detection to improve robustness. This study
investigates anomaly detection in streaming IoT traffic as binary
classification, comparing batch and streaming learning approaches while
assessing the limitations of current IoT traffic datasets. We simulated
heterogeneous network data streams by carefully mixing existing datasets and
streaming the samples one by one. Our results highlight the failure of batch
models to handle concept drift, but also reveal persisting limitations of
current datasets to expose model limitations due to low traffic heterogeneity.
We also investigated the competitiveness of tree-based ML algorithms,
well-known in batch anomaly detection, and compared it to non-tree-based ones,
confirming the advantages of the former. Adaptive Random Forest achieved
F1-score of 0.990 $\pm$ 0.006 at one-third the computational cost of its batch
counterpart. Hoeffding Adaptive Tree reached F1-score of 0.910 $\pm$ 0.007,
reducing computational cost by four times, making it a viable choice for online
applications despite a slight trade-off in stability.

</details>


### [317] [Un-Attributability: Computing Novelty From Retrieval & Semantic Similarity](https://arxiv.org/abs/2510.27313)
*Philipp Davydov,Ameya Prabhu,Matthias Bethge,Elisa Nguyen,Seong Joon Oh*

Main category: cs.LG

TL;DR: 该研究提出了一种衡量语言模型输出新颖性的新方法，即“不可归因性”，并在此基础上进行了三项发现。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型输出与预训练语料库之间的关系是理解模型行为的关键，现有方法主要关注哪些训练样本对特定输出有因果影响，而本研究将问题反转，探究哪些输出无法归因于任何预训练样本，以此来操作化地衡量语义新颖性。

Method: 提出了一种基于 GIST 嵌入和 ColBERTv2 的两阶段检索流程来近似不可归因性：首先使用轻量级 GIST 嵌入对语料库进行索引，检索 top-n 候选，然后使用 ColBERTv2 进行重排。如果最近的语料库项比人类生成的文本参考更不可归因，则认为模型输出是新颖的。

Result: 在 SmolLM 和 SmolLM2 上进行评估后，研究发现：（1）模型利用预训练数据的跨度比之前报道的要长得多；（2）某些领域会系统性地促进或抑制新颖性；（3）指令调优不仅改变了风格，还增加了新颖性。

Conclusion: 将新颖性评估重构为围绕不可归因性，可以实现对预训练规模的有效分析，并发布了相关的数据集和索引以支持未来的研究。

Abstract: Understanding how language-model outputs relate to the pretraining corpus is
central to studying model behavior. Most training data attribution (TDA)
methods ask which training examples causally influence a given output, often
using leave-one-out tests. We invert the question: which outputs cannot be
attributed to any pretraining example? We introduce un-attributability as an
operational measure of semantic novelty: an output is novel if the pretraining
corpus contains no semantically similar context. We approximate this with a
simple two-stage retrieval pipeline: index the corpus with lightweight GIST
embeddings, retrieve the top-n candidates, then rerank with ColBERTv2. If the
nearest corpus item is less attributable than a human-generated text reference,
we consider the output of the model as novel. We evaluate on SmolLM and SmolLM2
and report three findings: (1) models draw on pretraining data across much
longer spans than previously reported; (2) some domains systematically promote
or suppress novelty; and (3) instruction tuning not only alters style but also
increases novelty. Reframing novelty assessment around un-attributability
enables efficient analysis at pretraining scale. We release ~20 TB of corpus
chunks and index artifacts to support replication and large-scale extension of
our analysis at https://huggingface.co/datasets/stai-tuebingen/faiss-smollm

</details>


### [318] [MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data](https://arxiv.org/abs/2510.27321)
*Yu-Chen Kuo,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: MedM2T是一个时间感知多模态框架，用于处理医学数据的多模态和异构时间结构，在心血管疾病预测、院内死亡率预测和ICU住院时间回归方面优于最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 医学数据固有的多模态和异构时间结构给建模带来了重大挑战。

Method: MedM2T集成了稀疏时间序列编码器、分层时间感知融合和双模态注意力，并使用特定于模态的预训练编码器和共享编码器来解决粒度差距。

Result: MedM2T在MIMIC-IV和MIMIC-IV-ECG数据集上进行了评估，并在心血管疾病预测（AUROC为0.947，AUPRC为0.706）、死亡率预测（AUROC为0.901，AUPRC为0.558）和ICU住院时间回归（MAE为2.31）方面取得了优于最先进方法的成果。

Conclusion: MedM2T的稳健性和广泛适用性表明，它在临床预测方面是一个有前途的工具。

Abstract: The inherent multimodality and heterogeneous temporal structures of medical
data pose significant challenges for modeling. We propose MedM2T, a time-aware
multimodal framework designed to address these complexities. MedM2T integrates:
(i) Sparse Time Series Encoder to flexibly handle irregular and sparse time
series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and
macro-temporal patterns from multiple dense time series, such as ECGs, and
(iii) Bi-Modal Attention to extract cross-modal interactions, which can be
extended to any number of modalities. To mitigate granularity gaps between
modalities, MedM2T uses modality-specific pre-trained encoders and aligns
resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and
MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease
dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality
prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed
state-of-the-art multimodal learning frameworks and existing time series
models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction;
an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean
Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the
robustness and broad applicability of MedM2T, positioning it as a promising
tool in clinical prediction. We provide the implementation of MedM2T at
https://github.com/DHLab-TSENG/MedM2T.

</details>


### [319] [Reasoning Models Sometimes Output Illegible Chains of Thought](https://arxiv.org/abs/2510.27338)
*Arun Jose*

Main category: cs.LG

TL;DR: 通过基于结果的强化学习（RL）训练的语言模型，通过思维链（CoT）进行推理，表现出色。然而，研究发现RL训练导致CoT变得难以辨认，即使模型仍能给出正确的答案。这种“不可读性”在更难的问题上尤为严重，并且在强制模型仅使用可读部分时，准确率会显著下降。这表明，在没有明确优化可读性的情况下，基于结果的RL会自然地产生推理过程不透明的模型，这可能会阻碍对这些模型的监控。


<details>
  <summary>Details</summary>
Motivation: 旨在研究基于结果的强化学习（RL）如何影响语言模型进行思维链（CoT）推理的可读性和忠实性，并评估这种可读性对模型理解和潜在恶意行为检测的影响。

Method: 研究了14个推理模型，分析了RL训练对CoT可读性的影响，并进行了模型在仅使用可读CoT时的准确率测试，以及可读性与性能之间相关性的采样分析。

Result: RL训练通常导致CoT变得难以辨认（对人类和AI监控都是如此），除了Claude模型。模型会使用难以辨认的推理过程来得到正确答案（仅使用可读部分时准确率下降53%）。可读性与性能之间没有发现相关性，但在更难的问题上可读性会下降。研究提出了几种可能的假设，包括隐写术、训练痕迹和残留标记。

Conclusion: 在没有明确优化可读性的情况下，基于结果的RL倾向于产生推理过程日益不透明的模型，这可能会削弱监控方法的效果。

Abstract: Language models trained via outcome-based reinforcement learning (RL) to
reason using chain-of-thought (CoT) have shown remarkable performance.
Monitoring such a model's CoT may allow us to understand its intentions and
detect potential malicious behavior. However, to be effective, this requires
that CoTs are legible and faithful. We study CoT legibility across 14 reasoning
models, finding that RL often causes reasoning to become illegible to both
humans and AI monitors, with reasoning models (except Claude) generating
illegible CoTs while returning to perfectly readable final answers. We show
that models use illegible reasoning to reach correct answers (accuracy dropping
by 53\% when forced to use only legible portions), yet find no correlation
between legibility and performance when resampling - suggesting the
relationship is more nuanced. We also find that legibility degrades on harder
questions. We discuss potential hypotheses for these results, including
steganography, training artifacts, and vestigial tokens. These results suggest
that without explicit optimization for legibility, outcome-based RL naturally
produces models with increasingly opaque reasoning processes, potentially
undermining monitoring approaches.

</details>


### [320] [Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity](https://arxiv.org/abs/2510.27378)
*Austin Meek,Eitan Sprejer,Iván Arcuschin,Austin J. Brockmeier,Steven Basart*

Main category: cs.LG

TL;DR: CoT的透明度对于模型安全至关重要，但现有评估方法存在不足。本文提出“冗长性”概念，并结合“忠实性”提出“可监控性”评分，以更全面地评估CoT作为模型外部“工作记忆”的能力。实验表明，模型可能看似忠实但因遗漏关键因素而难以监控，且不同模型家族的可监控性差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有CoT评估方法主要关注模型在添加提示词后是否改变答案，这种方法不够全面，可能遗漏模型在未改变答案情况下推理过程中的不一致性，也无法评估推理过程中是否遗漏关键因素。

Method: 提出“冗长性”（verbosity）指标，衡量CoT是否列出了解决任务所需的所有因素。将“忠实性”（faithfulness）和“冗长性”结合，提出“可监控性”（monitorability）评分，用以评估CoT作为模型外部“工作记忆”的有效性。

Result: 在BBH、GPQA和MMLU基准测试中，评估了指令微调和推理模型。结果显示，模型可能表现出“忠实性”但由于遗漏关键因素而难以监控。不同模型家族的可监控性存在显著差异。

Conclusion: CoT的可监控性比单纯的忠实性更重要，模型可能看起来忠实但因遗漏关键信息而难以监控。需要更全面的评估方法来衡量CoT作为模型外部工作记忆的能力，以确保模型安全。

Abstract: Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.
Since any long, serial reasoning process must pass through this textual trace,
the quality of the CoT is a direct window into what the model is thinking. This
visibility could help us spot unsafe or misaligned behavior (monitorability),
but only if the CoT is transparent about its internal reasoning (faithfulness).
Fully measuring faithfulness is difficult, so researchers often focus on
examining the CoT in cases where the model changes its answer after adding a
cue to the input. This proxy finds some instances of unfaithfulness but loses
information when the model maintains its answer, and does not investigate
aspects of reasoning not tied to the cue. We extend these results to a more
holistic sense of monitorability by introducing verbosity: whether the CoT
lists every factor needed to solve the task. We combine faithfulness and
verbosity into a single monitorability score that shows how well the CoT serves
as the model's external `working memory', a property that many safety schemes
based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning
models on BBH, GPQA, and MMLU. Our results show that models can appear faithful
yet remain hard to monitor when they leave out key factors, and that
monitorability differs sharply across model families. We release our evaluation
code using the Inspect library to support reproducible future work.

</details>


### [321] [FedMuon: Accelerating Federated Learning with Matrix Orthogonalization](https://arxiv.org/abs/2510.27403)
*Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: Muon是一种用于联邦学习（FL）的优化器，旨在通过优化矩阵结构参数来减少通信轮数。在独立同分布（IID）设置下，它能加速收敛并减少通信。然而，在非独立同分布（non-IID）设置下，它会导致客户漂移。FedMuon是Muon的改进版，通过动量聚合和局部-全局对齐来解决这些挑战，理论上和实践中都证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）方法主要使用逐元素的局部优化器（如Adam/SGD），忽略了权重矩阵的几何结构，这可能导致病态方向的放大、条件数恶化和收敛缓慢。因此，需要一种新的优化器来优化矩阵结构参数，以提高FL的效率。

Method: 该研究引入了Muon优化器，它包含矩阵正交化功能，用于优化矩阵结构参数。对于非独立同分布（non-IID）场景，提出了FedMuon优化器，它结合了动量聚合（客户使用聚合动量进行局部初始化）和局部-全局对齐（局部梯度与全局更新方向对齐）两种技术，以减少客户漂移。

Result: 在IID设置下，Local Muon相比Local SGD和Local AdamW能显著加速FL的收敛并减少通信轮数。在non-IID设置下，FedMuon通过动量聚合和局部-全局对齐，有效解决了Muon引起的客户漂移问题，实现了线性加速收敛，并在语言和视觉模型上显著减少了通信轮数并提高了测试准确性。

Conclusion: FedMuon是一种有效的联邦学习优化器，它通过引入动量聚合和局部-全局对齐技术，解决了现有FL方法在non-IID场景下的挑战，并在理论和实践上都证明了其在减少通信轮数和提高模型准确性方面的优越性。

Abstract: The core bottleneck of Federated Learning (FL) lies in the communication
rounds. That is, how to achieve more effective local updates is crucial for
reducing communication rounds. Existing FL methods still primarily use
element-wise local optimizers (Adam/SGD), neglecting the geometric structure of
the weight matrices. This often leads to the amplification of pathological
directions in the weights during local updates, leading deterioration in the
condition number and slow convergence. Therefore, we introduce the Muon
optimizer in local, which has matrix orthogonalization to optimize
matrix-structured parameters. Experimental results show that, in IID setting,
Local Muon significantly accelerates the convergence of FL and reduces
communication rounds compared to Local SGD and Local AdamW. However, in non-IID
setting, independent matrix orthogonalization based on the local distributions
of each client induces strong client drift. Applying Muon in non-IID FL poses
significant challenges: (1) client preconditioner leading to client drift; (2)
moment reinitialization. To address these challenges, we propose a novel
Federated Muon optimizer (FedMuon), which incorporates two key techniques: (1)
momentum aggregation, where clients use the aggregated momentum for local
initialization; (2) local-global alignment, where the local gradients are
aligned with the global update direction to significantly reduce client drift.
Theoretically, we prove that \texttt{FedMuon} achieves a linear speedup
convergence rate without the heterogeneity assumption, where $S$ is the number
of participating clients per round, $K$ is the number of local iterations, and
$R$ is the total number of communication rounds. Empirically, we validate the
effectiveness of FedMuon on language and vision models. Compared to several
baselines, FedMuon significantly reduces communication rounds and improves test
accuracy.

</details>


### [322] [Atlas-Alignment: Making Interpretability Transferable Across Language Models](https://arxiv.org/abs/2510.27413)
*Bruno Puri,Jim Berend,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: Atlas-Alignment框架通过将未知潜在空间与已标记的概念图谱对齐，实现跨语言模型的解释性迁移，从而在不依赖标记概念数据的情况下，进行语义特征检索和可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型解释性方法成本高昂且难以扩展，需要针对特定模型进行昂贵的训练、手动标记和验证。Atlas-Alignment旨在解决这一问题，降低解释性AI的成本。

Method: Atlas-Alignment框架利用共享输入和轻量级表示对齐技术，将未知模型的潜在空间与一个已标记的概念图谱（Concept Atlas）对齐。

Result: 该框架实现了两种关键能力：(1) 语义特征搜索和检索，(2) 沿可解释的概念图谱概念引导生成。定量和定性评估表明，即使没有标记的概念数据，也能实现鲁棒的语义检索和可控生成。

Conclusion: Atlas-Alignment通过构建一个高质量的概念图谱，可以以极低的边际成本使多个新模型透明化和可控化，从而分摊可解释AI和机制可解释性的成本。

Abstract: Interpretability is crucial for building safe, reliable, and controllable
language models, yet existing interpretability pipelines remain costly and
difficult to scale. Interpreting a new model typically requires costly training
of model-specific sparse autoencoders, manual or semi-automated labeling of SAE
components, and their subsequent validation. We introduce Atlas-Alignment, a
framework for transferring interpretability across language models by aligning
unknown latent spaces to a Concept Atlas - a labeled, human-interpretable
latent space - using only shared inputs and lightweight representational
alignment techniques. Once aligned, this enables two key capabilities in
previously opaque models: (1) semantic feature search and retrieval, and (2)
steering generation along human-interpretable atlas concepts. Through
quantitative and qualitative evaluations, we show that simple representational
alignment methods enable robust semantic retrieval and steerable generation
without the need for labeled concept data. Atlas-Alignment thus amortizes the
cost of explainable AI and mechanistic interpretability: by investing in one
high-quality Concept Atlas, we can make many new models transparent and
controllable at minimal marginal cost.

</details>


### [323] [MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting Post-fire Vegetation Loss](https://arxiv.org/abs/2510.27443)
*Meenu Ravi,Shailik Sarkar,Yanshen Sun,Vaishnavi Singh,Chang-Tien Lu*

Main category: cs.LG

TL;DR: MVeLMA是一个多模态机器学习管线，用于预测火灾事件后的植被损失，并生成高风险区域图，以支持恢复工作。


<details>
  <summary>Details</summary>
Motivation: 现有的火灾后植被损失研究未能充分考虑所有影响因素及其相互作用，且预测模型缺乏可解释性，限制了其在实际应用中的价值。

Method: 提出了一种名为MVeLMA（多模态植被损失建模架构）的新型端到端机器学习管线，该管线利用多模态特征融合和堆叠集成架构来处理不同模态的数据，并通过概率模型进行不确定性估计。

Result: 实验证明，MVeLMA在预测火灾后植被损失方面优于多个最先进和基线模型，并生成了植被损失置信图，可识别高风险县，为有针对性的恢复工作提供支持。

Conclusion: 该研究结果有望为未来的灾难救助规划、生态政策制定和野生动物恢复管理提供信息。

Abstract: Understanding post-wildfire vegetation loss is critical for developing
effective ecological recovery strategies and is often challenging due to the
extended time and effort required to capture the evolving ecosystem features.
Recent works in this area have not fully explored all the contributing factors,
their modalities, and interactions with each other. Furthermore, most research
in this domain is limited by a lack of interpretability in predictive modeling,
making it less useful in real-world settings. In this work, we propose a novel
end-to-end ML pipeline called MVeLMA (\textbf{M}ultimodal \textbf{Ve}getation
\textbf{L}oss \textbf{M}odeling \textbf{A}rchitecture) to predict county-wise
vegetation loss from fire events. MVeLMA uses a multimodal feature integration
pipeline and a stacked ensemble-based architecture to capture different
modalities while also incorporating uncertainty estimation through
probabilistic modeling. Through comprehensive experiments, we show that our
model outperforms several state-of-the-art (SOTA) and baseline models in
predicting post-wildfire vegetation loss. Furthermore, we generate vegetation
loss confidence maps to identify high-risk counties, thereby helping targeted
recovery efforts. The findings of this work have the potential to inform future
disaster relief planning, ecological policy development, and wildlife recovery
management.

</details>


### [324] [Spectral Neural Graph Sparsification](https://arxiv.org/abs/2510.27474)
*Angelica Liguori,Ettore Ritacco,Pietro Sabatino,Annalisa Socievole*

Main category: cs.LG

TL;DR: 提出了一种名为“谱保留网络”的新图表示学习框架，通过生成简化但忠实的图来降低计算成本，并能有效应用于社区检测、影响传播和信息扩散等下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（特别是图卷积网络）在处理复杂系统图时，存在结构固定和过平滑问题，限制了其应用。

Method: 该框架包含两个关键组件：1. 联合图演化层：能够自适应地转换图拓扑和节点特征矩阵，克服了静态邻域聚合的局限性。2. 谱一致性损失：通过强制图的谱属性和节点特征向量之间的一致性来规范化这些转换。

Result: 在节点级稀疏化任务上，谱保留网络通过分析既有指标和与现有先进方法的基准测试，证明了其优越的性能和明显的优势。

Conclusion: 谱保留网络通过生成简化图来有效降低计算成本，同时保持了原始图的关键信息，为图学习提供了新的解决方案。

Abstract: Graphs are central to modeling complex systems in domains such as social
networks, molecular chemistry, and neuroscience. While Graph Neural Networks,
particularly Graph Convolutional Networks, have become standard tools for graph
learning, they remain constrained by reliance on fixed structures and
susceptibility to over-smoothing. We propose the Spectral Preservation Network,
a new framework for graph representation learning that generates reduced graphs
serving as faithful proxies of the original, enabling downstream tasks such as
community detection, influence propagation, and information diffusion at a
reduced computational cost. The Spectral Preservation Network introduces two
key components: the Joint Graph Evolution layer and the Spectral Concordance
loss. The former jointly transforms both the graph topology and the node
feature matrix, allowing the structure and attributes to evolve adaptively
across layers and overcoming the rigidity of static neighborhood aggregation.
The latter regularizes these transformations by enforcing consistency in both
the spectral properties of the graph and the feature vectors of the nodes. We
evaluate the effectiveness of Spectral Preservation Network on node-level
sparsification by analyzing well-established metrics and benchmarking against
state-of-the-art methods. The experimental results demonstrate the superior
performance and clear advantages of our approach.

</details>


### [325] [Thought Branches: Interpreting LLM Reasoning Requires Resampling](https://arxiv.org/abs/2510.27484)
*Uzay Macar,Paul C. Bogdan,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.LG

TL;DR: 研究链式思考（CoT）的分布而非单一示例，以实现对模型决策的因果分析和计算理解。


<details>
  <summary>Details</summary>
Motivation: 单一的CoT示例不足以理解因果影响和底层计算，需要研究模型生成的所有可能CoT的分布。

Method: 通过重采样来研究模型决策，包括评估特定句子或编辑对决策的因果影响，以及衡量移除推理步骤后的模型行为。

Result: （1）自我保护句子对模型行为的因果影响很小，并不驱动勒索行为。（2）与模型重采样相比，非策略性干预对决策任务的影响较小且不稳定。（3）移除关键规划步骤会产生重大影响。（4）即使CoT不忠实，提示也会产生持续的、累积的影响。

Conclusion: 通过重采样研究CoT分布，可以实现可靠的因果分析、清晰的模型推理叙述以及原则性的CoT干预。

Abstract: Most work interpreting reasoning models studies only a single
chain-of-thought (CoT), yet these models define distributions over many
possible CoTs. We argue that studying a single sample is inadequate for
understanding causal influence and the underlying computation. Though fully
specifying this distribution is intractable, it can be understood by sampling.
We present case studies using resampling to investigate model decisions. First,
when a model states a reason for its action, does that reason actually cause
the action? In "agentic misalignment" scenarios, we resample specific sentences
to measure their downstream effects. Self-preservation sentences have small
causal impact, suggesting they do not meaningfully drive blackmail. Second, are
artificial edits to CoT sufficient for steering reasoning? These are common in
literature, yet take the model off-policy. Resampling and selecting a
completion with the desired property is a principled on-policy alternative. We
find off-policy interventions yield small and unstable effects compared to
resampling in decision-making tasks. Third, how do we understand the effect of
removing a reasoning step when the model may repeat it post-edit? We introduce
a resilience metric that repeatedly resamples to prevent similar content from
reappearing downstream. Critical planning statements resist removal but have
large effects when eliminated. Fourth, since CoT is sometimes "unfaithful", can
our methods teach us anything in these settings? Adapting causal mediation
analysis, we find that hints that have a causal effect on the output without
being explicitly mentioned exert a subtle and cumulative influence on the CoT
that persists even if the hint is removed. Overall, studying distributions via
resampling enables reliable causal analysis, clearer narratives of model
reasoning, and principled CoT interventions.

</details>


### [326] [Simplex-to-Euclidean Bijections for Categorical Flow Matching](https://arxiv.org/abs/2510.27480)
*Bernardo Williams,Victor M. Yeom-Song,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: We propose a method for learning and sampling from probability distributions on the simplex by mapping it to Euclidean space using Aitchison geometry, which allows for density modeling and exact recovery of discrete distributions, achieving competitive performance.


<details>
  <summary>Details</summary>
Motivation: The paper aims to propose a method for learning and sampling from probability distributions supported on the simplex, addressing the limitations of previous methods that use Riemannian geometry or custom noise processes by working in Euclidean space while respecting the Aitchison geometry.

Method: The proposed approach maps the open simplex to Euclidean space via smooth bijections, leveraging the Aitchison geometry. It supports categorical data modeling through Dirichlet interpolation, which dequantizes discrete observations into continuous ones. This enables density modeling in Euclidean space through the bijection, allowing for exact recovery of the original discrete distribution.

Result: The method achieves competitive performance on both synthetic and real-world data sets compared to previous methods.

Conclusion: The proposed approach effectively models probability distributions on the simplex by utilizing Euclidean space while respecting the Aitchison geometry, offering a competitive alternative to existing methods.

Abstract: We propose a method for learning and sampling from probability distributions
supported on the simplex. Our approach maps the open simplex to Euclidean space
via smooth bijections, leveraging the Aitchison geometry to define the
mappings, and supports modeling categorical data by a Dirichlet interpolation
that dequantizes discrete observations into continuous ones. This enables
density modeling in Euclidean space through the bijection while still allowing
exact recovery of the original discrete distribution. Compared to previous
methods that operate on the simplex using Riemannian geometry or custom noise
processes, our approach works in Euclidean space while respecting the Aitchison
geometry, and achieves competitive performance on both synthetic and real-world
data sets.

</details>


### [327] [FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models](https://arxiv.org/abs/2510.27486)
*Junkang Liu,Fanhua Shang,Kewen Zhu,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: FedAdamW通过引入局部修正机制和解耦权重衰减来解决AdamW在联邦学习中的挑战，并通过聚合二阶矩估计来降低方差，从而实现更快的收敛速度和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: AdamW在大型模型训练中非常有效，但在联邦学习（FL）中，数据异质性导致二阶矩估计方差过高、局部过拟合引起客户端漂移以及重新初始化矩估计减慢收敛速度等问题。

Method: 提出FedAdamW算法，包含局部修正机制和解耦权重衰减，以缓解局部过拟合；通过聚合二阶矩估计的均值来降低方差并避免重新初始化。

Result: 理论上，FedAdamW在无异质性假设下实现了线性加速收敛，收敛率为 O(sqrt((L Δσl^2)/(S K R ε^2))+(L Δ)/R)。通过PAC-贝叶斯泛化分析解释了解耦权重衰减的有效性。实验上，在语言和视觉Transformer模型上验证了FedAdamW的有效性，相比基线方法，显著减少了通信轮数并提高了测试准确率。

Conclusion: FedAdamW有效地解决了AdamW在联邦学习中的挑战，提高了训练效率和模型性能。

Abstract: AdamW has become one of the most effective optimizers for training
large-scale models. We have also observed its effectiveness in the context of
federated learning (FL). However, directly applying AdamW in federated learning
settings poses significant challenges: (1) due to data heterogeneity, AdamW
often yields high variance in the second-moment estimate $\boldsymbol{v}$; (2)
the local overfitting of AdamW may cause client drift; and (3) Reinitializing
moment estimates ($\boldsymbol{v}$, $\boldsymbol{m}$) at each round slows down
convergence. To address these challenges, we propose the first
\underline{Fed}erated \underline{AdamW} algorithm, called \texttt{FedAdamW},
for training and fine-tuning various large models. \texttt{FedAdamW} aligns
local updates with the global update using both a \textbf{local correction
mechanism} and decoupled weight decay to mitigate local overfitting.
\texttt{FedAdamW} efficiently aggregates the \texttt{mean} of the second-moment
estimates to reduce their variance and reinitialize them. Theoretically, we
prove that \texttt{FedAdamW} achieves a linear speedup convergence rate of
$\mathcal{O}(\sqrt{(L \Delta \sigma_l^2)/(S K R \epsilon^2)}+(L \Delta)/R)$
without \textbf{heterogeneity assumption}, where $S$ is the number of
participating clients per round, $K$ is the number of local iterations, and $R$
is the total number of communication rounds. We also employ PAC-Bayesian
generalization analysis to explain the effectiveness of decoupled weight decay
in local training. Empirically, we validate the effectiveness of
\texttt{FedAdamW} on language and vision Transformer models. Compared to
several baselines, \texttt{FedAdamW} significantly reduces communication rounds
and improves test accuracy. The code is available in
https://github.com/junkangLiu0/FedAdamW.

</details>


### [328] [InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames](https://arxiv.org/abs/2510.27497)
*Haorui Li,Weitao Du,Yuqiang Li,Hongyu Guo,Shengchao Liu*

Main category: cs.LG

TL;DR: InertialAR是第一个能处理3D分子生成的Transformer模型，它通过新的标记化方法解决了SE(3)不变性和原子顺序不变性问题，并引入了几何感知注意力机制。该模型在无条件和条件分子生成任务上都取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在处理3D分子生成方面存在不足，主要面临两个挑战：1）如何将分子转化为一种既能抵抗SE(3)变换又能抵抗原子索引排列的规范1D标记序列；2）如何设计一个能够处理包含离散原子类型和连续3D坐标的混合原子标记的模型。

Method: InertialAR提出了一种新的规范标记化方法，通过将分子与其惯性参考系对齐并重新排序原子来确保SE(3)和排列不变性。它还通过引入几何旋转位置编码（GeoRoPE）增强了注意机制的几何感知能力，并采用分层自回归范式，先预测原子类型，再通过扩散损失预测其3D坐标。

Result: 在无条件分子生成任务上，InertialAR在QM9、GEOM-Drugs和B3LYP数据集的10项评估指标中的7项上达到了最先进的性能。在可控生成任务上，它显著优于现有基线模型，在所有5项指标上均取得了最先进的成果。

Conclusion: InertialAR成功地将Transformer模型扩展到3D分子生成领域，通过创新的标记化和几何感知架构解决了关键挑战，并在多个评估任务中展现了卓越的性能。

Abstract: Transformer-based autoregressive models have emerged as a unifying paradigm
across modalities such as text and images, but their extension to 3D molecule
generation remains underexplored. The gap stems from two fundamental
challenges: (1) tokenizing molecules into a canonical 1D sequence of tokens
that is invariant to both SE(3) transformations and atom index permutations,
and (2) designing an architecture capable of modeling hybrid atom-based tokens
that couple discrete atom types with continuous 3D coordinates. To address
these challenges, we introduce InertialAR. InertialAR devises a canonical
tokenization that aligns molecules to their inertial frames and reorders atoms
to ensure SE(3) and permutation invariance. Moreover, InertialAR equips the
attention mechanism with geometric awareness via geometric rotary positional
encoding (GeoRoPE). In addition, it utilizes a hierarchical autoregressive
paradigm to predict the next atom-based token, predicting the atom type first
and then its 3D coordinates via Diffusion loss. Experimentally, InertialAR
achieves state-of-the-art performance on 7 of the 10 evaluation metrics for
unconditional molecule generation across QM9, GEOM-Drugs, and B3LYP. Moreover,
it significantly outperforms strong baselines in controllable generation for
targeted chemical functionality, attaining state-of-the-art results across all
5 metrics.

</details>


### [329] [DP-FedPGN: Finding Global Flat Minima for Differentially Private Federated Learning via Penalizing Gradient Norm](https://arxiv.org/abs/2510.27504)
*Junkang Liu,Yuxuan Tian,Fanhua Shang,Yuanyuan Liu,Hongying Liu,Junchao Zhou,Daorui Ding*

Main category: cs.LG

TL;DR: CL-DPFL方法通常会导致损失函数地形变尖锐，降低模型泛化能力。虽然SAM可以寻找局部平坦最小值，但在CL-DPFL中，局部平坦性不一定反映全局平坦性。DP-FedPGN通过引入全局梯度范数惩罚来寻找全局平坦最小值，减少了局部更新的范数，从而减小了梯度裁剪误差，并能理论上缓解DP带来的性能下降，同时消除数据异质性的影响并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有的CL-DPFL方法会导致损失函数地形变尖锐，从而降低模型泛化能力。SAM方法虽然可以寻找局部平坦最小值，但在CL-DPFL中，局部平坦性不一定反映全局平坦性，因此需要寻找全局平坦最小值。

Method: 提出了一种新的CL-DPFL算法DP-FedPGN，通过在局部损失中引入全局梯度范数惩罚来寻找全局平坦最小值。该方法通过全局梯度范数惩罚来减少局部更新的范数，从而减小梯度裁剪误差。

Result: DP-FedPGN在ResNet和Transformer模型上进行了测试，并在六个视觉和自然语言处理任务上取得了显著的改进。理论分析表明，DP-FedPGN可以缓解DP带来的性能下降，消除数据异质性的影响，并实现快速收敛。

Conclusion: DP-FedPGN通过引入全局梯度范数惩罚，有效地寻找全局平坦最小值，缓解了DP带来的性能下降，并提高了模型在各种任务上的泛化能力。

Abstract: To prevent inference attacks in Federated Learning (FL) and reduce the
leakage of sensitive information, Client-level Differentially Private Federated
Learning (CL-DPFL) is widely used. However, current CL-DPFL methods usually
result in sharper loss landscapes, which leads to a decrease in model
generalization after differential privacy protection. By using Sharpness Aware
Minimization (SAM), the current popular federated learning methods are to find
a local flat minimum value to alleviate this problem. However, the local
flatness may not reflect the global flatness in CL-DPFL. Therefore, to address
this issue and seek global flat minima of models, we propose a new CL-DPFL
algorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to
the local loss to find the global flat minimum. Moreover, by using our global
gradient norm penalty, we not only find a flatter global minimum but also
reduce the locally updated norm, which means that we further reduce the error
of gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN
mitigates the performance degradation caused by DP. Meanwhile, the proposed
DP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves
fast convergence. We also use R\'enyi DP to provide strict privacy guarantees
and provide sensitivity analysis for local updates. Finally, we conduct
effectiveness tests on both ResNet and Transformer models, and achieve
significant improvements in six visual and natural language processing tasks
compared to existing state-of-the-art algorithms. The code is available at
https://github.com/junkangLiu0/DP-FedPGN

</details>


### [330] [Leveraging Generic Time Series Foundation Models for EEG Classification](https://arxiv.org/abs/2510.27522)
*Théo Gnassounou,Yessin Moakher,Shifeng Xie,Vasilii Feofanov,Ievgen Redko*

Main category: cs.LG

TL;DR: 通用时间序列基础模型在EEG信号分类任务上表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 探索通用时间序列基础模型在生物医学信号（如EEG）领域的应用潜力，特别是其在运动想象分类和睡眠分期预测方面的能力。

Method: 测试了两种预训练策略：(a) 在多领域异构真实世界时间序列上进行预训练，(b) 在纯合成数据上进行预训练，并将结果与EEGNet和CBraMod进行比较。

Result: 两种预训练策略都取得了强大的性能，并且持续优于EEGNet和CBraMod。

Conclusion: 通用的时间序列基础模型，即使在非神经信号或合成信号上进行预训练，也能有效地迁移到EEG分析任务中，表明跨领域预训练模型在脑信号分析方面具有巨大潜力。

Abstract: Foundation models for time series are emerging as powerful general-purpose
backbones, yet their potential for domain-specific biomedical signals such as
electroencephalography (EEG) remains rather unexplored. In this work, we
investigate the applicability a recently proposed time series classification
foundation model, to a different EEG tasks such as motor imagery classification
and sleep stage prediction. We test two pretraining regimes: (a) pretraining on
heterogeneous real-world time series from multiple domains, and (b) pretraining
on purely synthetic data. We find that both variants yield strong performance,
consistently outperforming EEGNet, a widely used convolutional baseline, and
CBraMod, the most recent EEG-specific foundation model. These results suggest
that generalist time series foundation models, even when pretrained on data of
non-neural origin or on synthetic signals, can transfer effectively to EEG. Our
findings highlight the promise of leveraging cross-domain pretrained models for
brain signal analysis, suggesting that EEG may benefit from advances in the
broader time series literature.

</details>


### [331] [Active transfer learning for structural health monitoring](https://arxiv.org/abs/2510.27525)
*J. Poole,N. Dervilis,K. Worden,P. Gardner,V. Giglioni,R. S. Mills,A. J. Hughes*

Main category: cs.LG

TL;DR: 该研究提出了一种结合迁移学习和主动学习的贝叶斯框架，用于处理结构健康监测（SHM）中的数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 传统SHM系统的数据获取成本高且不切实际，尤其是带标签的数据。人群基础SHM（PBSHM）旨在通过利用多结构数据来解决此问题，但不同结构的数据分布存在差异，可能导致模型泛化能力下降。之前的研究主要关注无监督域适应（DA），忽略了在线更新和主动选择标注数据的问题。

Method: 提出了一种用于PBSHM的贝叶斯域适应（DA）框架，该框架可以利用有限的带标签目标数据来改进无监督DA映射。此外，该模型还集成了一个主动采样策略，用于指导检查以选择最具信息量的观测值进行标注。

Result: 实验结果表明，结合迁移学习和主动学习的策略可以提高在标签稀疏场景下学习分类模型的数据效率。

Conclusion: 该方法在实验桥梁人群上进行了评估，证明了结合迁移学习和主动学习在提高数据效率方面的有效性。这对于数据驱动的结构运行和维护具有重要意义，有望通过减少结构在其整个运行寿命期间的检查次数来降低运行成本。

Abstract: Data for training structural health monitoring (SHM) systems are often
expensive and/or impractical to obtain, particularly for labelled data.
Population-based SHM (PBSHM) aims to address this limitation by leveraging data
from multiple structures. However, data from different structures will follow
distinct distributions, potentially leading to large generalisation errors for
models learnt via conventional machine learning methods. To address this issue,
transfer learning -- in the form of domain adaptation (DA) -- can be used to
align the data distributions. Most previous approaches have only considered
\emph{unsupervised} DA, where no labelled target data are available; they do
not consider how to incorporate these technologies in an online framework --
updating as labels are obtained throughout the monitoring campaign. This paper
proposes a Bayesian framework for DA in PBSHM, that can improve unsupervised DA
mappings using a limited quantity of labelled target data. In addition, this
model is integrated into an active sampling strategy to guide inspections to
select the most informative observations to label -- leading to further
reductions in the required labelled data to learn a target classifier. The
effectiveness of this methodology is evaluated on a population of experimental
bridges. Specifically, this population includes data corresponding to several
damage states, as well as, a comprehensive set of environmental conditions. It
is found that combining transfer learning and active learning can improve data
efficiency when learning classification models in label-scarce scenarios. This
result has implications for data-informed operation and maintenance of
structures, suggesting a reduction in inspections over the operational lifetime
of a structure -- and therefore a reduction in operational costs -- can be
achieved.

</details>


### [332] [TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control](https://arxiv.org/abs/2510.27527)
*Yuxiang Chen,Xiaoming Xu,Pengle Zhang,Michael Beyer,Martin Rapp,Jun Zhu,Jianfei Chen*

Main category: cs.LG

TL;DR: TetraJet-v2是一种端到端的4位全量化训练（FQT）方法，使用NVFP4格式，解决了低精度训练中的权重振荡和离群值问题，并在LLM预训练中显著减少了与全精度训练的性能差距。


<details>
  <summary>Details</summary>
Motivation: LLM训练成本高昂，因此需要低精度的全量化训练（FQT）方法。然而，在4位精度下实现接近无损的训练仍然是一个挑战。

Method: 提出了一种名为TetraJet-v2的端到端4位FQT方法，使用了NVFP4格式来处理所有线性层中的激活值、权重和梯度。该方法通过以下方式解决低精度训练中的关键问题：1）提出一种无偏双块量化方法来处理NVFP4线性层；2）引入OsciReset算法来抑制权重振荡；3）引入OutControl算法来保留离群值的准确性。

Result: TetraJet-v2在不同模型大小（高达3.7亿参数）和数据大小（高达2000亿 tokens）的LLM预训练任务中，始终优于先前基于FP4的训练方法。与全精度训练相比，性能差距平均减少了51.3%。

Conclusion: TetraJet-v2是一种有效的4位全量化训练方法，能够显著提高LLM训练效率，同时保持接近全精度训练的性能。

Abstract: Large Language Models (LLMs) training is prohibitively expensive, driving
interest in low-precision fully-quantized training (FQT). While novel 4-bit
formats like NVFP4 offer substantial efficiency gains, achieving near-lossless
training at such low precision remains challenging. We introduce TetraJet-v2,
an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,
and gradients in all linear layers. We identify two critical issues hindering
low-precision LLM training: weight oscillation and outliers. To address these,
we propose: 1) an unbiased double-block quantization method for NVFP4 linear
layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)
OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently
outperforms prior FP4 training methods on pre-training LLMs across varying
model sizes up to 370M and data sizes up to 200B tokens, reducing the
performance gap to full-precision training by an average of 51.3%.

</details>


### [333] [AstuteRAG-FQA: Task-Aware Retrieval-Augmented Generation Framework for Proprietary Data Challenges in Financial Question Answering](https://arxiv.org/abs/2510.27537)
*Mohammad Zahangir Alam,Khandoker Ashik Uz Zaman,Mahdi H. Miraz*

Main category: cs.LG

TL;DR: AstuteRAG-FQA是一个专为金融问答设计的自适应检索增强生成框架，通过任务感知提示工程、混合检索策略、动态提示和多层安全机制，解决金融领域RAG面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 金融领域应用RAG存在数据访问受限、检索精度低、法规限制和数据敏感性高等挑战。

Method: 提出AstuteRAG-FQA框架，采用任务感知提示工程、混合检索策略（结合开源和专有数据）、动态提示框架、四层任务分类（显性事实、隐性事实、可解释性理由、隐藏性理由）、多层安全机制（差分隐私、数据匿名化、基于角色的访问控制）和实时合规监控。

Result: 评估了三种数据集成技术（上下文嵌入、小模型增强、定向微调）的效率和可行性，并展示了AstuteRAG-FQA在处理不同金融查询时的优势。

Conclusion: AstuteRAG-FQA通过其创新的框架和技术，有效解决了金融问答中的RAG挑战，提高了答案的准确性、相关性和安全性，并确保了合规性。

Abstract: Retrieval-Augmented Generation (RAG) shows significant promise in
knowledge-intensive tasks by improving domain specificity, enhancing temporal
relevance, and reducing hallucinations. However, applying RAG to finance
encounters critical challenges: restricted access to proprietary datasets,
limited retrieval accuracy, regulatory constraints, and sensitive data
interpretation. We introduce AstuteRAG-FQA, an adaptive RAG framework tailored
for Financial Question Answering (FQA), leveraging task-aware prompt
engineering to address these challenges. The framework uses a hybrid retrieval
strategy integrating both open-source and proprietary financial data while
maintaining strict security protocols and regulatory compliance. A dynamic
prompt framework adapts in real time to query complexity, improving precision
and contextual relevance. To systematically address diverse financial queries,
we propose a four-tier task classification: explicit factual, implicit factual,
interpretable rationale, and hidden rationale involving implicit causal
reasoning. For each category, we identify key challenges, datasets, and
optimization techniques within the retrieval and generation process. The
framework incorporates multi-layered security mechanisms including differential
privacy, data anonymization, and role-based access controls to protect
sensitive financial information. Additionally, AstuteRAG-FQA implements
real-time compliance monitoring through automated regulatory validation systems
that verify responses against industry standards and legal obligations. We
evaluate three data integration techniques - contextual embedding, small model
augmentation, and targeted fine-tuning - analyzing their efficiency and
feasibility across varied financial environments.

</details>


### [334] [ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling](https://arxiv.org/abs/2510.27610)
*Zhuohan Wang,Ziwei Zhu,Ziniu Li,Congliang Chen,Yizhou Han,Yufeng Lin,Zhihang Lin,Angyang Gu,Xinglin Hu,Ruoyu Sun,Tian Ding*

Main category: cs.LG

TL;DR: ORGEval是一个图论评估框架，用于评估LLM在优化建模方面的能力，通过将优化模型表示为图并将等价性检测转化为图同构测试来解决现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业优化问题建模需要大量人工和领域知识，而LLM在这方面的评估缺乏可靠指标，现有基于求解器的方法存在不一致、不可行和计算成本高的问题。

Method: ORGEval将优化模型表示为图，并将等价性检测转化为图同构测试。它利用了Weisfeiler-Lehman（WL）测试的一个变体，该测试在图满足对称可分解（SD）的充分条件下可以正确检测同构。ORGEval集成了定制的WL测试和SD检测算法来评估模型等价性，侧重于结构等价性而非实例级别配置，从而对数值变化具有鲁棒性。

Result: ORGEval能成功检测模型等价性，在随机参数配置下产生100%一致的结果，并且在运行时性能显著优于基于求解器的方法，特别是在处理难题时。基于ORGEval构建的Bench4Opt数据集和对最先进LLM的基准测试显示，虽然优化建模对所有LLM仍然具有挑战性，但DeepSeek-V3和Claude-Opus-4在直接提示下取得了最高的准确率。

Conclusion: ORGEval为评估LLM的优化建模能力提供了一个有效的、基于图论的框架，解决了现有方法的不足，并为进一步研究LLM在优化领域的应用奠定了基础。

Abstract: Formulating optimization problems for industrial applications demands
significant manual effort and domain expertise. While Large Language Models
(LLMs) show promise in automating this process, evaluating their performance
remains difficult due to the absence of robust metrics. Existing solver-based
approaches often face inconsistency, infeasibility issues, and high
computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs' capabilities in
formulating linear and mixed-integer linear programs. ORGEval represents
optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the
tested graphs are symmetric decomposable (SD), under which the
Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an
SD detection algorithm to evaluate model equivalence. By focusing on structural
equivalence rather than instance-level configurations, ORGEval is robust to
numerical variations. Experimental results show that our method can
successfully detect model equivalence and produce 100\% consistent results
across random parameter configurations, while significantly outperforming
solver-based methods in runtime, especially on difficult problems. Leveraging
ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs
on optimization modeling. Our results reveal that although optimization
modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even
leading reasoning models.

</details>


### [335] [Panprediction: Optimal Predictions for Any Downstream Task and Loss](https://arxiv.org/abs/2510.27638)
*Sivaraman Balakrishnan,Nika Haghtalab,Daniel Hsu,Brian Lee,Eric Zhao*

Main category: cs.LG

TL;DR: 监督学习的新范式是利用数据提取足够的信息，使模型能够最小化多个下游任务上的多个损失函数，这被称为“全预测”。


<details>
  <summary>Details</summary>
Motivation: 文章旨在提出并形式化“全预测”这一新范式，并研究其统计复杂性，将其与现有的“全知预测”和“多组学习”进行比较。

Method: 提出了一种将全预测问题转化为“步进校准”问题的近乎无损的约简方法，并设计了相应的算法。

Result: 设计了学习确定性和随机全预测器的算法，分别需要 O(1/ε^3) 和 O(1/ε^2) 的样本量。在温和假设下，该方法展示了同时最小化无限多个任务上的无限多个损失函数，在统计上可以与最小化单个任务上的单个损失函数一样简单。此外，该方法还将确定性全知预测的最佳样本复杂度保证提高了 1/ε，并匹配了全知预测和多组学习的所有其他已知样本复杂度保证。

Conclusion: 全预测范式在统计上是可行的，并且可以通过有效的算法实现，其样本复杂度与现有方法相当甚至更优。

Abstract: Supervised learning is classically formulated as training a model to minimize
a fixed loss function over a fixed distribution, or task. However, an emerging
paradigm instead views model training as extracting enough information from
data so that the model can be used to minimize many losses on many downstream
tasks. We formalize a mathematical framework for this paradigm, which we call
panprediction, and study its statistical complexity. Formally, panprediction
generalizes omniprediction and sits upstream from multi-group learning, which
respectively focus on predictions that generalize to many downstream losses or
many downstream tasks, but not both. Concretely, we design algorithms that
learn deterministic and randomized panpredictors with
$\tilde{O}(1/\varepsilon^3)$ and $\tilde{O}(1/\varepsilon^2)$ samples,
respectively. Our results demonstrate that under mild assumptions,
simultaneously minimizing infinitely many losses on infinitely many tasks can
be as statistically easy as minimizing one loss on one task. Along the way, we
improve the best known sample complexity guarantee of deterministic
omniprediction by a factor of $1/\varepsilon$, and match all other known sample
complexity guarantees of omniprediction and multi-group learning. Our key
technical ingredient is a nearly lossless reduction from panprediction to a
statistically efficient notion of calibration, called step calibration.

</details>


### [336] [Imbalanced Classification through the Lens of Spurious Correlations](https://arxiv.org/abs/2510.27650)
*Jakob Hackstein,Sidney Bender*

Main category: cs.LG

TL;DR: 类别不平衡会导致机器学习中出现不可靠的分类性能。本研究提出一种基于“聪明汉斯效应”的因果解释方法，通过识别和消除因类别不平衡而产生的“聪明汉斯效应”，来提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习中的一个基本挑战，它会导致不可靠的分类性能。现有的方法主要集中在数据或损失重加权方案上，但本研究认为类别不平衡是加剧“聪明汉斯效应”的数据条件，因为它导致少数类别的欠定性。

Method: 本研究提出一种基于反事实解释的方法，利用可解释人工智能来联合识别和消除不平衡条件下出现的“聪明汉斯效应”。

Result: 我们的方法在三个数据集上实现了具有竞争力的分类性能，并展示了“聪明汉斯效应”在不平衡条件下的出现方式，这是一种现有方法在很大程度上忽视的视角。

Conclusion: 类别不平衡会加剧“聪明汉斯效应”，本研究提出的基于可解释人工智能的方法可以有效识别和消除该效应，从而提高分类性能。

Abstract: Class imbalance poses a fundamental challenge in machine learning, frequently
leading to unreliable classification performance. While prior methods focus on
data- or loss-reweighting schemes, we view imbalance as a data condition that
amplifies Clever Hans (CH) effects by underspecification of minority classes.
In a counterfactual explanations-based approach, we propose to leverage
Explainable AI to jointly identify and eliminate CH effects emerging under
imbalance. Our method achieves competitive classification performance on three
datasets and demonstrates how CH effects emerge under imbalance, a perspective
largely overlooked by existing approaches.

</details>


### [337] [Information-Theoretic Greedy Layer-wise Training for Traffic Sign Recognition](https://arxiv.org/abs/2510.27651)
*Shuyan Lyu,Zhanzimo Wu,Junliang Du*

Main category: cs.LG

TL;DR: 本篇论文提出了一种新颖的基于确定性信息瓶颈和 Rényi 熵函数的层级训练方法，用于训练深度神经网络，并在 CIFAR-10/100 和交通标志识别等任务上取得了与 SGD 相当的性能，优于现有的层级训练方法。


<details>
  <summary>Details</summary>
Motivation: 传统的端到端监督式深度神经网络训练方法（全局交叉熵损失）在生物学上不合理，并且存在梯度消失/爆炸等问题。虽然层级训练方法可以避免这些问题，但以往的研究大多局限于小型数据集和简单的网络结构。

Method: 通过信息论视角分析了随机梯度下降（SGD）训练的卷积神经网络（CNN）的训练动力学，发现网络收敛具有层级性（自底向上）且信息流遵循马尔可夫信息瓶颈原则。在此基础上，提出了一种新的层级训练方法，该方法结合了确定性信息瓶颈（DIB）和基于矩阵的 Rényi $\alpha$-阶熵函数，并通过一个连接到输出层的辅助分类器来训练每一层，以学习最小的、与任务相关的表示。

Result: 在 CIFAR-10 和 CIFAR-100 数据集上，使用现代深度 CNN 进行了经验验证，并在交通标志识别任务中展示了该方法的有效性。结果表明，该方法不仅优于现有的层级训练方法，而且性能与 SGD 相当。

Conclusion: 提出的基于 DIB 和 Rényi 熵函数的层级训练方法能够有效地训练现代深度 CNN，并在多个基准测试中取得了有竞争力的性能，为解决传统训练方法的局限性提供了一种有前景的替代方案。

Abstract: Modern deep neural networks (DNNs) are typically trained with a global
cross-entropy loss in a supervised end-to-end manner: neurons need to store
their outgoing weights; training alternates between a forward pass
(computation) and a top-down backward pass (learning) which is biologically
implausible. Alternatively, greedy layer-wise training eliminates the need for
cross-entropy loss and backpropagation. By avoiding the computation of
intermediate gradients and the storage of intermediate outputs, it reduces
memory usage and helps mitigate issues such as vanishing or exploding
gradients. However, most existing layer-wise training approaches have been
evaluated only on relatively small datasets with simple deep architectures. In
this paper, we first systematically analyze the training dynamics of popular
convolutional neural networks (CNNs) trained by stochastic gradient descent
(SGD) through an information-theoretic lens. Our findings reveal that networks
converge layer-by-layer from bottom to top and that the flow of information
adheres to a Markov information bottleneck principle. Building on these
observations, we propose a novel layer-wise training approach based on the
recently developed deterministic information bottleneck (DIB) and the
matrix-based R\'enyi's $\alpha$-order entropy functional. Specifically, each
layer is trained jointly with an auxiliary classifier that connects directly to
the output layer, enabling the learning of minimal sufficient task-relevant
representations. We empirically validate the effectiveness of our training
procedure on CIFAR-10 and CIFAR-100 using modern deep CNNs and further
demonstrate its applicability to a practical task involving traffic sign
recognition. Our approach not only outperforms existing layer-wise training
baselines but also achieves performance comparable to SGD.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [338] [CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions](https://arxiv.org/abs/2510.26852)
*Lingyue Fu,Xin Ding,Yaoming Zhu,Shao Zhang,Lin Qiu,Weiwen Liu,Weinan Zhang,Xuezhi Cao,Xunliang Cai,Jiaxin Ding,Yong Yu*

Main category: cs.AI

TL;DR: LLM代理已从基本的文本生成发展到通过与外部工具的交互自主完成复杂任务。然而，当前的基准测试主要在固定的场景中评估端到端的性能，将评估限制在特定的技能上，并随着代理能力的提高而遭受分数饱和和日益依赖专家注释的问题。在这项工作中，我们强调学习能力，包括自我改进和同伴学习，作为代理向人类水平智能演进的核心驱动力。我们提出了一个迭代的、竞争性的同伴学习框架，它允许代理通过重复的交互和反馈来完善和优化他们的策略，从而系统地评估他们的学习能力。为了解决当前基准测试中的分数饱和问题，我们引入了CATArena，一个采用四种不同的棋盘和纸牌游戏的比赛式评估平台，具有开放式的评分。通过提供没有明确分数上限的任务，CATArena能够对快速发展的代理能力进行持续和动态的评估。涉及最小和商业代码代理的实验结果和分析表明，CATArena为核心代理能力，特别是学习能力和策略编码，提供了可靠、稳定和可扩展的基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试方法在评估LLM代理的学习能力方面存在局限性，容易出现分数饱和和对专家注释的过度依赖。作者认为，学习能力（包括自我改进和同伴学习）是LLM代理向人类水平智能发展的关键驱动力。

Method: 作者提出了一个迭代的、竞争性的同伴学习框架，让代理通过反复的交互和反馈来优化策略，从而评估其学习能力。同时，为了解决分数饱和问题，作者引入了一个名为CATArena的比赛式评估平台，该平台包含四种具有开放式评分机制的棋盘和纸牌游戏，没有明确的分数上限，以便能够动态评估代理能力的进步。

Result: 通过在CATArena平台上的实验，作者证明了该平台能够对代理的学习能力和策略编码能力进行可靠、稳定且可扩展的基准测试。实验结果表明，该框架和平台能够有效地区分和评估不同代理的能力。

Conclusion: CATArena平台和所提出的同伴学习框架为LLM代理，特别是其学习能力和策略编码能力，提供了一个有效的、动态的、可扩展的评估解决方案，克服了现有基准测试的局限性。

Abstract: Large Language Model (LLM) agents have evolved from basic text generation to
autonomously completing complex tasks through interaction with external tools.
However, current benchmarks mainly assess end-to-end performance in fixed
scenarios, restricting evaluation to specific skills and suffering from score
saturation and growing dependence on expert annotation as agent capabilities
improve. In this work, we emphasize the importance of learning ability,
including both self-improvement and peer-learning, as a core driver for agent
evolution toward human-level intelligence. We propose an iterative, competitive
peer-learning framework, which allows agents to refine and optimize their
strategies through repeated interactions and feedback, thereby systematically
evaluating their learning capabilities. To address the score saturation issue
in current benchmarks, we introduce CATArena, a tournament-style evaluation
platform featuring four diverse board and card games with open-ended scoring.
By providing tasks without explicit upper score limits, CATArena enables
continuous and dynamic evaluation of rapidly advancing agent capabilities.
Experimental results and analyses involving both minimal and commercial code
agents demonstrate that CATArena provides reliable, stable, and scalable
benchmarking for core agent abilities, particularly learning ability and
strategy coding.

</details>


### [339] [Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base](https://arxiv.org/abs/2510.26854)
*Yu Li,Yuan Huang,Tao Wang,Caiyu Fan,Xiansheng Cai,Sihan Hu,Xinzijian Liu,Cheng Shi,Mingjun Xu,Zhen Wang,Yan Wang,Xiangqi Jin,Tianhan Zhang,Linfeng Zhang,Lei Wang,Youjin Deng,Pan Zhang,Weijie Sun,Xingyu Li,Weinan E,Linfeng Zhang,Zhiyuan Yao,Kun Chen*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Most scientific materials compress reasoning, presenting conclusions while
omitting the derivational chains that justify them. This compression hinders
verification by lacking explicit, step-wise justifications and inhibits
cross-domain links by collapsing the very pathways that establish the logical
and causal connections between concepts. We introduce a scalable framework that
decompresses scientific reasoning, constructing a verifiable Long
Chain-of-Thought (LCoT) knowledge base and projecting it into an emergent
encyclopedia, SciencePedia. Our pipeline operationalizes an endpoint-driven,
reductionist strategy: a Socratic agent, guided by a curriculum of around 200
courses, generates approximately 3 million first-principles questions. To
ensure high fidelity, multiple independent solver models generate LCoTs, which
are then rigorously filtered by prompt sanitization and cross-model answer
consensus, retaining only those with verifiable endpoints. This verified corpus
powers the Brainstorm Search Engine, which performs inverse knowledge search --
retrieving diverse, first-principles derivations that culminate in a target
concept. This engine, in turn, feeds the Plato synthesizer, which narrates
these verified chains into coherent articles. The initial SciencePedia
comprises approximately 200,000 fine-grained entries spanning mathematics,
physics, chemistry, biology, engineering, and computation. In evaluations
across six disciplines, Plato-synthesized articles (conditioned on retrieved
LCoTs) exhibit substantially higher knowledge-point density and significantly
lower factual error rates than an equally-prompted baseline without retrieval
(as judged by an external LLM). Built on this verifiable LCoT knowledge base,
this reasoning-centric approach enables trustworthy, cross-domain scientific
synthesis at scale and establishes the foundation for an ever-expanding
encyclopedia.

</details>


### [340] [The Denario project: Deep knowledge AI agents for scientific discovery](https://arxiv.org/abs/2510.26887)
*Francisco Villaescusa-Navarro,Boris Bolliet,Pablo Villanueva-Domingo,Adrian E. Bayer,Aidan Acquah,Chetana Amancharla,Almog Barzilay-Siegal,Pablo Bermejo,Camille Bilodeau,Pablo Cárdenas Ramírez,Miles Cranmer,Urbano L. França,ChangHoon Hahn,Yan-Fei Jiang,Raul Jimenez,Jun-Young Lee,Antonio Lerario,Osman Mamun,Thomas Meier,Anupam A. Ojha,Pavlos Protopapas,Shimanto Roy,David N. Spergel,Pedro Tarancón-Álvarez,Ujjwal Tiwari,Matteo Viel,Digvijay Wadekar,Chi Wang,Bonny Y. Wang,Licong Xu,Yossi Yovel,Shuwen Yue,Wen-Han Zhou,Qiyao Zhu,Jiajun Zou,Íñigo Zubeldia*

Main category: cs.AI

TL;DR: Denario是一个多智能体AI系统，可作为科学研究助手，执行从构思到论文撰写的各种任务，并展示了其跨学科研究能力，论文代码已开源。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够协助科学研究，执行多种任务的多智能体AI系统。

Method: 提出Denario系统，采用模块化架构，并使用Cmbagent作为后端，展示了其在多个科学领域的应用能力，并通过领域专家评估了其生成论文的质量。

Result: Denario成功生成了多个跨学科的科学研究论文，并通过领域专家进行了评估，评估结果（包括评分和反馈）已报告。

Conclusion: Denario系统在科学研究方面展现了强大的能力，但也存在优势、劣势和局限性，并且引发了对AI驱动研究的伦理和社会影响的讨论。

Abstract: We present Denario, an AI multi-agent system designed to serve as a
scientific research assistant. Denario can perform many different tasks, such
as generating ideas, checking the literature, developing research plans,
writing and executing code, making plots, and drafting and reviewing a
scientific paper. The system has a modular architecture, allowing it to handle
specific tasks, such as generating an idea, or carrying out end-to-end
scientific analysis using Cmbagent as a deep-research backend. In this work, we
describe in detail Denario and its modules, and illustrate its capabilities by
presenting multiple AI-generated papers generated by it in many different
scientific disciplines such as astrophysics, biology, biophysics, biomedical
informatics, chemistry, material science, mathematical physics, medicine,
neuroscience and planetary science. Denario also excels at combining ideas from
different disciplines, and we illustrate this by showing a paper that applies
methods from quantum physics and machine learning to astrophysical data. We
report the evaluations performed on these papers by domain experts, who
provided both numerical scores and review-like feedback. We then highlight the
strengths, weaknesses, and limitations of the current system. Finally, we
discuss the ethical implications of AI-driven research and reflect on how such
technology relates to the philosophy of science. We publicly release the code
at https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run
directly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and
the full app will be deployed on the cloud.

</details>


### [341] [LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources](https://arxiv.org/abs/2510.18477)
*Haichao Ji,Zibo Wang,Cheng Pan,Meng Han,Yifei Zhu,Dan Wang,Zhu Han*

Main category: cs.AI

TL;DR: LAFA是一个整合了大型语言模型（LLM）和联邦分析（FA）的系统，实现了隐私保护且支持自然语言输入的去中心化数据分析。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM分析框架缺乏隐私保护，而FA缺乏自然语言支持，因此需要一个能结合两者优势的系统。

Method: LAFA采用分层多智能体架构，包括一个粗粒度规划器（将查询分解为子查询）和一个细粒度规划器（将子查询映射为FA操作的DAG），并引入了一个优化器智能体来重写和合并DAG以提高效率。

Result: 实验表明，LAFA在执行成功率方面优于基线方法，并显著减少了资源消耗的FA操作。

Conclusion: LAFA为在FA环境中进行隐私保护、支持自然语言输入的LLM驱动分析奠定了实际基础。

Abstract: Large Language Models (LLMs) have shown great promise in automating data
analytics tasks by interpreting natural language queries and generating
multi-operation execution plans. However, existing LLM-agent-based analytics
frameworks operate under the assumption of centralized data access, offering
little to no privacy protection. In contrast, federated analytics (FA) enables
privacy-preserving computation across distributed data sources, but lacks
support for natural language input and requires structured, machine-readable
queries. In this work, we present LAFA, the first system that integrates
LLM-agent-based data analytics with FA. LAFA introduces a hierarchical
multi-agent architecture that accepts natural language queries and transforms
them into optimized, executable FA workflows. A coarse-grained planner first
decomposes complex queries into sub-queries, while a fine-grained planner maps
each subquery into a Directed Acyclic Graph of FA operations using prior
structural knowledge. To improve execution efficiency, an optimizer agent
rewrites and merges multiple DAGs, eliminating redundant operations and
minimizing computational and communicational overhead. Our experiments
demonstrate that LAFA consistently outperforms baseline prompting strategies by
achieving higher execution plan success rates and reducing resource-intensive
FA operations by a substantial margin. This work establishes a practical
foundation for privacy-preserving, LLM-driven analytics that supports natural
language input in the FA setting.

</details>


### [342] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno,Arturo Miguel Bernal Russell,Sofia Nelson,Demetrius Hernandez,Maureen Petterson,Michael Murphy,Walter J. Scheirer,Jane Cleland-Huang*

Main category: cs.AI

TL;DR: Foundational models like LLMs and VLMs enhance autonomy in cyber-physical systems but introduce new errors. Cognition Envelopes are proposed to set reasoning boundaries for AI decisions, complementing meta-cognition and safety envelopes.


<details>
  <summary>Details</summary>
Motivation: Foundational models (LLMs, VLMs) in cyber-physical systems, while increasing autonomy, introduce new error types (hallucinations, overgeneralizations, context misalignments) leading to flawed decisions.

Method: Introduce the concept of Cognition Envelopes to establish reasoning boundaries, constraining AI-generated decisions and complementing meta-cognition and traditional safety envelopes. Emphasize the need for practical guidelines and systematic processes for definition, validation, and assurance.

Result: The paper proposes Cognition Envelopes as a solution to mitigate errors introduced by foundational models in cyber-physical systems.

Conclusion: Cognition Envelopes, along with practical guidelines and systematic processes, are presented as a method to ensure safer and more reliable AI decision-making in cyber-physical systems.

Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [343] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个集成了物联网、人工智能、卫星成像和基于角色的任务编排的智能农业平台，旨在实现高效、可追溯和可持续的农业，并在葡萄栽培领域进行了试点应用。


<details>
  <summary>Details</summary>
Motivation: 全球农业面临着日益增长的粮食需求、气候变化和可持续发展的挑战，需要创新的解决方案。

Method: 本研究探讨了现有的智能农业解决方案，进行了比较评估，并介绍了SUSTAINABLE平台，该平台集成了卫星指数、实时环境数据和针对地中海葡萄园的角色感知任务管理。

Result: SUSTAINABLE平台能够实现高效、可追溯和可持续的葡萄栽培。

Conclusion: SUSTAINABLE平台为应对全球农业挑战提供了一个有前景的解决方案，特别是在葡萄栽培领域。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [344] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 语言模型可用于处理空间数据，甚至在采用因果遮掩的情况下也优于顺序处理。


<details>
  <summary>Details</summary>
Motivation: 探究因果遮掩在非序列数据上的适用性，以及其与空间和序列表示的对比效果。

Method: 在国际象棋领域，利用语言模型分别对空间棋盘状态和序列着法数据进行训练，并比较使用双向和因果自注意力机制的效果。

Result: 即使采用因果遮掩，在空间棋盘状态上训练的模型也展现出比在序列着法上训练的模型更强的棋力。

Conclusion: 因果遮掩可适用于空间数据，在某些情况下甚至优于序列化，这表明语言模型在处理空间数据方面具有潜力。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [345] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 用户可以通过一个连续的effort参数来动态调整成本-准确性之间的权衡，以满足不同查询的需求。该方法通过训练模型使用相对于每个查询当前平均思维链长度的指定比例的token来实现这一点，从而在不牺牲性能的情况下减少了计算成本。


<details>
  <summary>Details</summary>
Motivation: 用户希望根据输出质量、延迟和成本之间的权衡来分配不同数量的推理工作。现有的方法需要用户指定所需token的绝对数量，但这需要提前了解问题的难度，才能为查询设置合适的token预算。

Method: 提出了一种名为自适应努力控制（Adaptive Effort Control）的自适应强化学习方法，该方法训练模型使用相对于每个查询当前平均思维链长度的指定比例的token。

Result: 在1.5B到32B参数的模型规模上，该方法实现了大约3倍的思维链长度缩减，同时保持或提高了相对于用于强化学习训练的基础模型的性能。

Conclusion: 自适应努力控制消除了特定数据集和特定阶段的调整，同时与标准的思维链方法相比，产生了更好的成本-准确性权衡曲线。

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [346] [Adaptive Data Flywheel: Applying MAPE Control Loops to AI Agent Improvement](https://arxiv.org/abs/2510.27051)
*Aaditya Shukla,Sidney Knowles,Meenakshi Madugula,Dave Farris,Ryan Angilly,Santiago Pombo,Anbang Xu,Lu An,Abhinav Balasubramanian,Tan Yu,Jiaxiang Ren,Rama Akkiraju*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Enterprise AI agents must continuously adapt to maintain accuracy, reduce
latency, and remain aligned with user needs. We present a practical
implementation of a data flywheel in NVInfo AI, NVIDIA's Mixture-of-Experts
(MoE) Knowledge Assistant serving over 30,000 employees. By operationalizing a
MAPE-driven data flywheel, we built a closed-loop system that systematically
addresses failures in retrieval-augmented generation (RAG) pipelines and
enables continuous learning. Over a 3-month post-deployment period, we
monitored feedback and collected 495 negative samples. Analysis revealed two
major failure modes: routing errors (5.25\%) and query rephrasal errors
(3.2\%). Using NVIDIA NeMo microservices, we implemented targeted improvements
through fine-tuning. For routing, we replaced a Llama 3.1 70B model with a
fine-tuned 8B variant, achieving 96\% accuracy, a 10x reduction in model size,
and 70\% latency improvement. For query rephrasal, fine-tuning yielded a 3.7\%
gain in accuracy and a 40\% latency reduction. Our approach demonstrates how
human-in-the-loop (HITL) feedback, when structured within a data flywheel,
transforms enterprise AI agents into self-improving systems. Key learnings
include approaches to ensure agent robustness despite limited user feedback,
navigating privacy constraints, and executing staged rollouts in production.
This work offers a repeatable blueprint for building robust, adaptive
enterprise AI agents capable of learning from real-world usage at scale.

</details>


### [347] [CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning](https://arxiv.org/abs/2510.27094)
*Hamed Mahdavi,Pouria Mahdavinia,Alireza Farhadi,Pegah Mohammadipour,Samira Malek,Majid Daliri,Pedram Mohammadipour,Alireza Hashemi,Amir Khasahmadi,Vasant Honavar*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [348] [Glia: A Human-Inspired AI for Automated Systems Design and Optimization](https://arxiv.org/abs/2510.27176)
*Pouya Hamadanian,Pantea Karimi,Arash Nasr-Esfahany,Kimia Noorbakhsh,Joseph Chandler,Ali ParandehGheibi,Mohammad Alizadeh,Hari Balakrishnan*

Main category: cs.AI

TL;DR: AI架构Glia利用多智能体协作，通过结合LLM推理和实验，在分布式GPU集群上自主设计出不逊于人类专家的网络系统，并在更短的时间内生成可解释的设计。


<details>
  <summary>Details</summary>
Motivation: 探索AI是否能自主设计出不亚于人类专家的计算机系统机制，并提出了一种新的AI架构Glia。

Method: Glia采用受人类启发的、多智能体的AI架构，利用大型语言模型（LLM）进行推理、实验和分析，并通过一个结合抽象推理和经验反馈的评估框架进行协作。

Result: Glia在分布式GPU集群上成功设计出新的请求路由、调度和自动扩展算法，性能达到人类专家水平，且耗时更短，同时揭示了工作负载行为的新见解。

Conclusion: 结合推理LLM和结构化实验，AI能够为复杂的系统问题提供有创意且易于理解的设计。

Abstract: Can an AI autonomously design mechanisms for computer systems on par with the
creativity and reasoning of human experts? We present Glia, an AI architecture
for networked systems design that uses large language models (LLMs) in a
human-inspired, multi-agent workflow. Each agent specializes in reasoning,
experimentation, and analysis, collaborating through an evaluation framework
that grounds abstract reasoning in empirical feedback. Unlike prior
ML-for-systems methods that optimize black-box policies, Glia generates
interpretable designs and exposes its reasoning process. When applied to a
distributed GPU cluster for LLM inference, it produces new algorithms for
request routing, scheduling, and auto-scaling that perform at human-expert
levels in significantly less time, while yielding novel insights into workload
behavior. Our results suggest that by combining reasoning LLMs with structured
experimentation, an AI can produce creative and understandable designs for
complex systems problems.

</details>


### [349] [From product to system network challenges in system of systems lifecycle management](https://arxiv.org/abs/2510.27194)
*Vahid Salehi,Josef Vilsmeier,Shirui Wang*

Main category: cs.AI

TL;DR: 产品不再是孤立的制品，而是网络化系统中的节点。本文提出了一个实用的系统工程（SoS）生命周期管理参考框架，整合了模型驱动系统工程（MBSE）、产品生命周期管理（PLM）以及数字线程和数字双生等概念，并基于对移动、医疗和公共等行业的分析，提出了四项核心原则：参考架构和数据模型、端到端的配置主权、明确评审关卡的策展模型、以及可衡量的价值贡献。最后，文章给出了一个三步路线图，指导如何从面向产品到面向网络中心开发进行过渡，以应对复杂性并实现可扩展的SoS价值流。


<details>
  <summary>Details</summary>
Motivation: 传统的线性生命周期模型在处理当今互联互通的产品系统（SoS）时已显不足，需要新的方法来管理跨学科互操作性、配置管理、可追溯性和组织间的治理。

Method: 本文通过对现有文献和行业经验（特别是移动、医疗和公共部门）进行分析，提出了一个将MBSE作为语义骨干，PLM作为治理和配置层，CAD-CAE作为模型派生领域，以及数字线程和数字双生作为连续反馈的SoS生命周期管理参考框架。基于此，识别出四项关键原则，并提供了一个三步路线图。

Result: 通过实施所提出的框架和原则，可以提高变更鲁棒性、缩短吞吐时间、改善复用性，并为可持续性决策提供信息支持。

Conclusion: 为了应对日益增长的产品系统复杂性并实现可扩展的价值流，决策者和从业者应采用网络中心的方法，并遵循提出的参考架构、端到端配置主权、策展模型和可衡量价值贡献的原则。文章提供的三步路线图为从产品中心到网络中心的开发转型提供了实践指导。

Abstract: Today, products are no longer isolated artifacts, but nodes in networked
systems. This means that traditional, linearly conceived life cycle models are
reaching their limits: Interoperability across disciplines, variant and
configuration management, traceability, and governance across organizational
boundaries are becoming key factors. This collective contribution classifies
the state of the art and proposes a practical frame of reference for SoS
lifecycle management, model-based systems engineering (MBSE) as the semantic
backbone, product lifecycle management (PLM) as the governance and
configuration level, CAD-CAE as model-derived domains, and digital thread and
digital twin as continuous feedback. Based on current literature and industry
experience, mobility, healthcare, and the public sector, we identify four
principles: (1) referenced architecture and data models, (2) end-to-end
configuration sovereignty instead of tool silos, (3) curated models with clear
review gates, and (4) measurable value contributions along time, quality, cost,
and sustainability. A three-step roadmap shows the transition from product- to
network- centric development: piloting with reference architecture, scaling
across variant and supply chain spaces, organizational anchoring (roles,
training, compliance). The results are increased change robustness, shorter
throughput times, improved reuse, and informed sustainability decisions. This
article is aimed at decision-makers and practitioners who want to make
complexity manageable and design SoS value streams to be scalable.

</details>


### [350] [Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering](https://arxiv.org/abs/2510.27206)
*Kounianhua Du,Jianxing Liu,Kangning Zhang,Wenxiang Jiao,Yuan Lu,Jiarui Jin,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Fints的细粒度、实例定制的个性化LLM框架，通过动态生成样本级干预向量来适应用户偏好，解决了现有参数化和非参数化方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM个性化方法在处理动态用户模式和数据稀疏性方面存在不足，适应性和数据效率有待提高。

Method: 提出了一种细粒度、实例定制的LLM个性化框架（Fints），通过细粒度干预组件和输入感知聚合模块，动态生成样本级干预向量并注入模型前向传播，实现个性化适应。

Result: 该方法在文本生成和函数调用等场景下表现出高灵活性和数据效率，尤其在快速变化的分布和高数据稀疏性场景下表现优异，并显著提升了个性化性能，同时保持了跨不同交互模式和上下文长度的鲁棒性。

Conclusion: Fints框架是一种灵活且数据高效的LLM个性化方法，能够有效应对动态用户模式和数据稀疏性挑战，并且可以作为插件兼容现有技术。

Abstract: The rapid evolution of large language models (LLMs) has intensified the
demand for effective personalization techniques that can adapt model behavior
to individual user preferences. Despite the non-parametric methods utilizing
the in-context learning ability of LLMs, recent parametric adaptation methods,
including personalized parameter-efficient fine-tuning and reward modeling
emerge. However, these methods face limitations in handling dynamic user
patterns and high data sparsity scenarios, due to low adaptability and data
efficiency. To address these challenges, we propose a fine-grained and
instance-tailored steering framework that dynamically generates sample-level
interference vectors from user data and injects them into the model's forward
pass for personalized adaptation. Our approach introduces two key technical
innovations: a fine-grained steering component that captures nuanced signals by
hooking activations from attention and MLP layers, and an input-aware
aggregation module that synthesizes these signals into contextually relevant
enhancements. The method demonstrates high flexibility and data efficiency,
excelling in fast-changing distribution and high data sparsity scenarios. In
addition, the proposed method is orthogonal to existing methods and operates as
a plug-in component compatible with different personalization techniques.
Extensive experiments across diverse scenarios--including short-to-long text
generation, and web function calling--validate the effectiveness and
compatibility of our approach. Results show that our method significantly
enhances personalization performance in fast-shifting environments while
maintaining robustness across varying interaction modes and context lengths.
Implementation is available at https://github.com/KounianhuaDu/Fints.

</details>


### [351] [GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation](https://arxiv.org/abs/2510.27210)
*Tao Liu,Chongyu Wang,Rongjie Li,Yingchen Yu,Xuming He,Bai Song*

Main category: cs.AI

TL;DR: GUI-Rise是一个增强推理能力的GUI导航代理框架，通过结构化推理、动作预测和历史摘要来提高跨领域泛化能力和历史利用效率。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在GUI导航代理方面虽然取得进展，但在跨域泛化和历史信息利用方面存在不足。

Method: 提出一个推理增强框架，整合了结构化推理（包括进度估计和决策推理的链式思考）、动作预测和历史摘要。该框架通过伪标签轨迹的监督微调和组相对策略优化（GRPO）的强化学习进行训练，并采用特殊的奖励机制，包括历史感知目标。

Result: 在标准基准测试中取得了最先进的结果，尤其在跨域场景下表现出色，证明了框架在不同GUI导航任务中保持强大推理和泛化能力。

Conclusion: 所提出的框架能够有效地提高GUI导航代理的跨领域泛化能力和历史信息利用率，并在各种GUI导航任务中保持鲁棒性。

Abstract: While Multimodal Large Language Models (MLLMs) have advanced GUI navigation
agents, current approaches face limitations in cross-domain generalization and
effective history utilization. We present a reasoning-enhanced framework that
systematically integrates structured reasoning, action prediction, and history
summarization. The structured reasoning component generates coherent
Chain-of-Thought analyses combining progress estimation and decision reasoning,
which inform both immediate action predictions and compact history summaries
for future steps. Based on this framework, we train a GUI agent,
\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled
trajectories and reinforcement learning with Group Relative Policy Optimization
(GRPO). This framework employs specialized rewards, including a history-aware
objective, directly linking summary quality to subsequent action performance.
Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art
results under identical training data conditions, with particularly strong
performance in out-of-domain scenarios. These findings validate our framework's
ability to maintain robust reasoning and generalization across diverse GUI
navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.

</details>


### [352] [Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines](https://arxiv.org/abs/2510.27329)
*Kristina Levina,Nikolaos Pappas,Athanasios Karapantelakis,Aneta Vulgarakis Feljan,Jendrik Seipp*

Main category: cs.AI

TL;DR: 引入数值 RMs、Agenda RMs 和 Coupled RMs 来解决具有无序子任务的长期问题，并提出 CoRM 算法，在实验中显示出比现有 RM 算法更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励机制（RMs）在处理具有可任意排序的子任务的长期问题时，学习信息量呈指数级增长，面临可扩展性挑战。

Method: 提出三种 RMs 的泛化：1. 数值 RMs，用于紧凑地表达复杂任务。2. Agenda RMs，在状态中加入跟踪剩余子任务的议程。3. Coupled RMs，将耦合状态与议程中的每个子任务相关联。并提出一种利用 Coupled RMs 的组合学习算法：Coupled RMs 的 Q 学习（CoRM）。

Result: 实验结果表明，CoRM 在处理具有无序子任务的长期问题时，比现有最先进的 RM 算法具有更好的可扩展性。

Conclusion: 所提出的 RMs 泛化和 CoRM 算法能够有效解决传统 RMs 在处理长期、无序子任务问题时的局限性，并在可扩展性方面表现出优势。

Abstract: Reward machines (RMs) inform reinforcement learning agents about the reward
structure of the environment. This is particularly advantageous for complex
non-Markovian tasks because agents with access to RMs can learn more
efficiently from fewer samples. However, learning with RMs is ill-suited for
long-horizon problems in which a set of subtasks can be executed in any order.
In such cases, the amount of information to learn increases exponentially with
the number of unordered subtasks. In this work, we address this limitation by
introducing three generalisations of RMs: (1) Numeric RMs allow users to
express complex tasks in a compact form. (2) In Agenda RMs, states are
associated with an agenda that tracks the remaining subtasks to complete. (3)
Coupled RMs have coupled states associated with each subtask in the agenda.
Furthermore, we introduce a new compositional learning algorithm that leverages
coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM
scales better than state-of-the-art RM algorithms for long-horizon problems
with unordered subtasks.

</details>


### [353] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 通过学习可解释的、区分性的规则来发现区分理想和非理想业务流程的执行模型。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界中的事件日志可以区分理想和非理想的流程执行，但传统的流程发现方法未能充分利用这种区分，导致发现的模型可能不适合合规性检查和性能分析，并且可能隐藏对理解流程结果至关重要的结构差异。

Method: 通过学习控制流特征上的可解释的区分性规则，将具有相似期望特征的轨迹进行分组，并在每个组内分别应用流程发现。

Result: 该方法在多个真实世界的事件日志上进行了评估，成功地分离和可视化了关键的流程模式，并生成了能够揭示理想和非理想执行驱动因素的、经过优化的和可解释的模型。

Conclusion: 该方法通过分别发现不同类别（理想和非理想）的流程模型，能够更好地揭示影响流程结果的关键模式，从而为流程改进提供更有效的支持。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [354] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann,Guillaume Pallez*

Main category: cs.AI

TL;DR: LLM生成的关于在线装箱问题的启发式算法被认为有潜力，但实际上这些启发式算法并不透明，并且可能基于对先前研究的误解。作者提出了更简单、更有效、更易于理解和更具可推广性的新算法，并强调了对LLM生成输出进行严格验证的必要性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在数学发现中的潜力，特别是在在线装箱问题中，并反驳其产生有价值的启发式算法的说法。

Method: 通过详细分析LLM生成的启发式算法的行为和可解释性，并提出新的、更优的算法来解决这些问题。

Result: LLM生成的启发式算法虽然可读，但对领域专家来说仍然难以理解。作者提出了新的算法，这些算法更简单、更高效、更易于理解和更具可推广性，表明所考虑的实例本身相对简单。LLM的贡献被认为基于对先前研究的错误假设。

Conclusion: LLM生成的启发式算法的价值被高估了，并且对LLM生成输出的科学价值进行严格验证和背景化至关重要。

Abstract: Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [355] [ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use](https://arxiv.org/abs/2510.27363)
*Mengjie Deng,Guanting Dong,Zhicheng Dou*

Main category: cs.AI

TL;DR: ToolScope是一个框架，用于增强多模态大语言模型（MLLM）利用外部工具进行推理的能力，特别是在长时程视觉问答（VQA）任务中。它通过结合全局规划和局部多模态感知，并使用专门的“感知”工具来解决视觉上下文退化问题，从而提高了模型在多个VQA基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在利用外部工具进行推理方面仍面临挑战，尤其是在处理复杂多变的多模态信息时。视觉上下文在长时程VQA任务中容易退化。

Method: ToolScope框架包含三个核心组件：全局导航器（提供战略指导）、智能执行器（通过集成搜索、代码和感知工具来增强MLLM的局部感知能力）和响应合成器（整合推理过程并生成用户友好的输出）。其中，“感知”工具专门用于缓解长时程VQA任务中的视觉上下文退化问题。

Result: 在VQA 2.0、ScienceQA、MAT-Search和MathVista四个VQA基准测试中，ToolScope展示了强大的泛化能力，平均性能提升高达+6.69%。

Conclusion: ToolScope通过统一全局规划和局部多模态感知，并集成专门的感知工具，有效解决了MLLM在长时程VQA任务中利用外部工具进行推理的挑战，显著提升了模型性能和泛化能力。

Abstract: Recently, large language models (LLMs) have demonstrated remarkable
problem-solving capabilities by autonomously integrating with external tools
for collaborative reasoning. However, due to the inherently complex and diverse
nature of multimodal information, enabling multimodal large language models
(MLLMs) to flexibly and efficiently utilize external tools during reasoning
remains an underexplored challenge. In this work, we introduce ToolScope, an
agentic framework designed to unify global planning with local multimodal
perception, adopting a specialized Perceive tool to mitigates visual context
degradation in long-horizon VQA task. ToolScope comprises three primary
components: the Global Navigator, the Agentic Executor, and the Response
Synthesizer. The Global Navigator functions as a "telescope", offering
high-level strategic guidance. The Agentic Executor operates iteratively to
augment MLLM with local perception through the integration of external
tools-Search, Code, and Perceive. Finally, the Response Synthesizer
consolidates and organizes the reasoning process into a coherent, user-friendly
output. We evaluate ToolScope on four VQA benchmarks across diverse domains,
including VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong
generalization capabilities, achieving an average performance improvement of up
to +6.69% across all datasets.

</details>


### [356] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 本研究提出了一种结合了视觉和运动约束的多智能体强化学习框架，用于模拟行人与驾驶员的交互行为，并在真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有行人-驾驶员交互模型缺乏灵活性或忽略了影响感官和运动的潜在机制，本研究旨在解决这一问题。

Method: 提出了一种多智能体强化学习框架，并集成了行人与驾驶员的视觉和运动约束。在真实数据集上评估了包含和不包含这些约束的四种模型变体。

Result: 结合了视觉和运动约束的模型在交互真实性方面表现最佳，运动约束使行为更平滑，视觉约束增加了感知不确定性和视野限制，导致更谨慎和多变的行人行为。在数据有限的情况下，该模型优于监督行为克隆模型。

Conclusion: 结合了人类约束的多智能体强化学习是模拟真实道路使用者交互行为的一种有前途的方法。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [357] [Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry](https://arxiv.org/abs/2510.27410)
*Jianwen Sun,Yukang Feng,Yifan Chang,Chuanhao Li,Zizhen Li,Jiaxin Ai,Fanrui Zhang,Yu Dai,Kaipeng Zhang*

Main category: cs.AI

TL;DR: 人类与AI协作中的“意图表达鸿沟”可通过Socratic协作范式解决，通过名为Nous的代理主动提问来弥合。Nous利用信息论原理，以对话的信息增益作为奖励信号，避免了对人类偏好标注的依赖。在科学图表生成任务上，Nous展现了领先的效率、输出质量和跨用户专业水平的鲁棒性，并具有领域无关性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类难以向AI有效传达高维复杂意图，导致低效的反复试错，用户专业水平差异加剧了这一问题。

Method: 提出Socratic协作范式，构建名为Nous的代理，主动通过提问来消除用户意图的不确定性。Nous的训练基于信息论，将对话的信息增益定义为内在奖励，等同于香农熵的减少，从而无需昂贵的人类偏好标注或外部奖励模型。

Result: 在科学图表生成任务上，Nous通过自动化模拟管道生成的大规模数据集进行了验证。实验（包括消融研究、主客观评估和跨用户专业水平测试）证明了Nous的有效性。Nous在效率、输出质量和用户专业水平适应性方面均表现出色，并具有领域无关性和泛化能力。

Conclusion: 所提出的框架为解决复杂人机协作中用户意图的不确定性提供了一种原则性、可扩展且自适应的范式。

Abstract: A fundamental bottleneck in human-AI collaboration is the "intention
expression gap," the difficulty for humans to effectively convey complex,
high-dimensional thoughts to AI. This challenge often traps users in
inefficient trial-and-error loops and is exacerbated by the diverse expertise
levels of users. We reframe this problem from passive instruction following to
a Socratic collaboration paradigm, proposing an agent that actively probes for
information to resolve its uncertainty about user intent. we name the proposed
agent Nous, trained to acquire proficiency in this inquiry policy. The core
mechanism of Nous is a training framework grounded in the first principles of
information theory. Within this framework, we define the information gain from
dialogue as an intrinsic reward signal, which is fundamentally equivalent to
the reduction of Shannon entropy over a structured task space. This reward
design enables us to avoid reliance on costly human preference annotations or
external reward models. To validate our framework, we develop an automated
simulation pipeline to generate a large-scale, preference-based dataset for the
challenging task of scientific diagram generation. Comprehensive experiments,
including ablations, subjective and objective evaluations, and tests across
user expertise levels, demonstrate the effectiveness of our proposed framework.
Nous achieves leading efficiency and output quality, while remaining robust to
varying user expertise. Moreover, its design is domain-agnostic, and we show
evidence of generalization beyond diagram generation. Experimental results
prove that our work offers a principled, scalable, and adaptive paradigm for
resolving uncertainty about user intent in complex human-AI collaboration.

</details>


### [358] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: DeepCompress框架通过自适应长度奖励机制，能同时提高大型推理模型（LRMs）的准确性和效率，解决了现有方法在效率和准确性之间做权衡的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRMs）在处理简单问题时存在“过度思考”，在处理复杂问题时存在“思考不足”的认知效率问题。虽然监督微调（SFT）和基于token长度奖励的强化学习（RL）可以提高效率，但往往会牺牲准确性。

Method: DeepCompress框架引入了一种新颖的自适应长度奖励机制，该机制能够实时根据模型不断变化的能力将问题分为“简单”或“复杂”两类。对于“简单”问题，它鼓励更短、更有效的推理；对于“复杂”问题，它则鼓励更长、更具探索性的思考链。

Result: 在具有挑战性的数学基准测试上的实验结果表明，DeepCompress持续优于基线方法，在显著提高token效率的同时，实现了卓越的准确性。

Conclusion: DeepCompress通过其自适应长度奖励机制，能够让模型自主调整其思考链（CoT）的长度，对已掌握的问题压缩推理过程，对具有挑战性的问题扩展推理过程，从而同时提升准确性和效率。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [359] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang,Dingxin Hu,Tinghao Yu,Hao Liu,Yiting Liu*

Main category: cs.AI

TL;DR: GeoFM是一种新的合成几何数据的方法，使用形式语言生成多样化的高保真几何问题，在数学推理任务上超越了GPT-4o等现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在数学几何推理方面存在数据不足和合成数据质量不高的挑战，现有合成方法生成的数据缺乏多样性、易带噪声，且合成图像与真实几何图偏差大。

Method: GeoFM使用形式语言探索度量空间中的条件组合，并利用符号引擎确保生成问题的正确性，从而生成与原始问题不同但正确的、高保真的几何问题。

Result: 在MathVista和GeoQA基准测试中，使用GeoFM合成数据训练的模型在几何问题解决能力上显著优于现有方法，在MathVista上超越GPT-4o 18.7%，在GeoQA上超越16.5%；同时，在MathVista上领先领先的开源模型5.7%，在GeoQA上领先2.7%。

Conclusion: GeoFM通过生成多样化的高保真几何数据，有效解决了多模态大语言模型在几何推理方面的局限性，并在多个基准测试中取得了领先的性能。

Abstract: Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [360] [Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance](https://arxiv.org/abs/2510.27544)
*Nikolaus Holzer,William Fishell,Baishakhi Ray,Mark Santolucito*

Main category: cs.AI

TL;DR: LLMs在推理方面表现出色，但现有基准测试存在偏差或无法验证。TempoBench是一个新颖的基准测试，它提供正式的、可验证的评估，并能系统地分析LLM在多步推理和因果推理方面的表现，尤其是在面对复杂系统时。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理评估方法存在局限性，要么依赖于可能带有偏差且无法验证的特定数据集，要么使用形式化的数学证明系统（如Lean），但后者不适用于模拟现实世界的基于代理的决策任务。这导致了LLM在实际应用（如商业代理、代码助手）中的性能不足，并且LLM推理基准测试在结构或现实世界对齐方面存在不足。

Method: TempoBench采用两种评估基准：1. 时间轨迹评估（TTE）：测试LLM理解和模拟给定多步推理系统执行的能力。2. 时间因果评估（TCE）：测试LLM进行多步因果推理以及从复杂系统中提炼因果关系的能力。TempoBench能够参数化难度，系统地分析LLM的推理表现。

Result: 在TCE-normal任务上，模型得分达到65.6%；在TCE-hard任务上，得分仅为7.5%。这表明，尽管最先进的LLM能够理解TCE任务，但随着系统复杂度的增加，它们的表现急剧下降。

Conclusion: TempoBench的评估结果表明，当前的LLM在处理复杂系统时的多步因果推理能力存在显著瓶颈，尽管它们能够理解任务的基本概念。需要进一步的研究来提高LLM在面对日益复杂的现实世界场景时的推理能力。

Abstract: Large Language Models (LLMs) are increasingly excelling and outpacing human
performance on many tasks. However, to improve LLM reasoning, researchers
either rely on ad-hoc generated datasets or formal mathematical proof systems
such as the Lean proof assistant. Whilst ad-hoc generated methods can capture
the decision chains of real-world reasoning processes, they may encode some
inadvertent bias in the space of reasoning they cover; they also cannot be
formally verified. On the other hand, systems like Lean can guarantee
verifiability, but are not well-suited to capture the nature of agentic
decision chain-based tasks. This creates a gap both in performance for
functions such as business agents or code assistants, and in the usefulness of
LLM reasoning benchmarks, whereby these fall short in reasoning structure or
real-world alignment. We introduce TempoBench, the first formally grounded and
verifiable diagnostic benchmark that parametrizes difficulty to systematically
analyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks
to break down reasoning ability. First, temporal trace evaluation (TTE) tests
the ability of an LLM to understand and simulate the execution of a given
multi-step reasoning system. Subsequently, temporal causal evaluation (TCE)
tests an LLM's ability to perform multi-step causal reasoning and to distill
cause-and-effect relations from complex systems. We find that models score
65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art
LLMs clearly understand the TCE task but perform poorly as system complexity
increases. Our code is available at our
\href{https://github.com/nik-hz/tempobench}{GitHub repository}.

</details>


### [361] [SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning](https://arxiv.org/abs/2510.27568)
*Ali Asgarov,Umid Suleymanov,Aadyant Khatri*

Main category: cs.AI

TL;DR: SIGMA是一个统一框架，通过协调专门的智能体来独立推理、执行定向搜索并优化检索，从而实现数学推理，并在MATH500、AIME和GPQA等基准测试中表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强模型在数学推理方面存在局限性，如依赖单一视角、搜索策略不灵活以及难以有效结合多源信息。

Method: SIGMA框架协调专门的智能体进行独立推理、执行定向搜索，并通过一个中介机制来综合信息。每个智能体生成假设性段落，以根据其分析视角优化检索，确保知识集成具有上下文敏感性和计算效率。

Result: SIGMA在MATH500、AIME和GPQA等具有挑战性的基准测试中，持续优于开源和闭源系统，性能提升了7.4%。

Conclusion: 多智能体、按需知识集成显著提高了推理的准确性和效率，为解决复杂、知识密集型问题提供了一个可扩展的方法。

Abstract: Solving mathematical reasoning problems requires not only accurate access to
relevant knowledge but also careful, multi-step thinking. However, current
retrieval-augmented models often rely on a single perspective, follow
inflexible search strategies, and struggle to effectively combine information
from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge
Integration for AGentic Mathematical reAsoning), a unified framework that
orchestrates specialized agents to independently reason, perform targeted
searches, and synthesize findings through a moderator mechanism. Each agent
generates hypothetical passages to optimize retrieval for its analytic
perspective, ensuring knowledge integration is both context-sensitive and
computation-efficient. When evaluated on challenging benchmarks such as
MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms
both open- and closed-source systems, achieving an absolute performance
improvement of 7.4%. Our results demonstrate that multi-agent, on-demand
knowledge integration significantly enhances both reasoning accuracy and
efficiency, offering a scalable approach for complex, knowledge-intensive
problem-solving. We will release the code upon publication.

</details>


### [362] [InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research](https://arxiv.org/abs/2510.27598)
*Yunze Wu,Dayuan Fu,Weiye Si,Zhen Huang,Mohan Jiang,Keyu Li,Shijie Xia,Jie Sun,Tianze Xu,Xiangkun Hu,Pengrui Lu,Xiaojie Cai,Lyumanshan Ye,Wenhong Zhu,Yang Xiao,Pengfei Liu*

Main category: cs.AI

TL;DR: AI智能体在科学发现中展现出巨大潜力，但现有基准测试未能全面评估其端到端的研发能力。本文提出了InnovatorBench，一个包含20项任务的基准平台，用于评估LLM研究智能体的实际应用能力。该平台涵盖数据构建、过滤、增强，损失函数和奖励设计，以及支架构建等环节，并要求智能体生成可执行的代码和评估其正确性、性能、输出质量及不确定性。同时，研究人员开发了ResearchGym环境，以支持智能体的长周期、分布式执行和监控。通过集成ReAct智能体和前沿模型（如Claude-4, GPT-5, GLM-4.5, Kimi-K2），实验发现虽然前沿模型在代码驱动任务中表现出色，但在算法相关和长周期决策任务中仍存在挑战，例如表现出“不耐烦”、资源管理不善以及过度依赖模板化推理等问题。InnovatorBench的实验表明，智能体需要超过11小时才能达到最佳性能，凸显了该基准的难度，并预示其将成为下一代代码研究基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能全面评估AI智能体在真实科研场景中的端到端能力，尤其是在涉及复杂推理、代码生成和长周期决策等方面。因此，需要一个更全面、更贴近实际的基准来衡量和推动AI智能体在科学发现中的应用。

Method: 本文提出了InnovatorBench基准平台和ResearchGym研究环境。InnovatorBench包含20项跨越数据处理、模型设计和评估的任务，要求生成可执行代码并评估其性能。ResearchGym提供了一个支持长周期、分布式执行和异步监控的研究环境。研究人员实现了一个ReAct智能体，并使用Claude-4, GPT-5, GLM-4.5, Kimi-K2等前沿模型进行测试。

Result: 实验结果表明，虽然前沿LLM在代码驱动的科研任务中表现出潜力，但在算法相关和长周期决策任务（如“不耐烦”、资源管理差、过度依赖模板推理）方面仍有待提高。InnovatorBench上的智能体达到最佳性能平均需要超过11小时，证明了该基准的挑战性。

Conclusion: InnovatorBench是一个有潜力成为下一代代码研究基准的平台，它能够更真实地评估AI智能体在端到端科学研究中的能力，并揭示了当前前沿模型在处理复杂、长周期科研任务时存在的局限性，为未来AI在科学发现中的发展指明了方向。

Abstract: AI agents could accelerate scientific discovery by automating hypothesis
formation, experiment design, coding, execution, and analysis, yet existing
benchmarks probe narrow skills in simplified settings. To address this gap, we
introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end
assessment of agents performing Large Language Model (LLM) research. It
comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss
Design, Reward Design, and Scaffold Construction, which require runnable
artifacts and assessment of correctness, performance, output quality, and
uncertainty. To support agent operation, we develop ResearchGym, a research
environment offering rich action spaces, distributed and long-horizon
execution, asynchronous monitoring, and snapshot saving. We also implement a
lightweight ReAct agent that couples explicit reasoning with executable
planning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.
Our experiments demonstrate that while frontier models show promise in
code-driven research tasks, they struggle with fragile algorithm-related tasks
and long-horizon decision making, such as impatience, poor resource management,
and overreliance on template-based reasoning. Furthermore, agents require over
11 hours to achieve their best performance on InnovatorBench, underscoring the
benchmark's difficulty and showing the potential of InnovatorBench to be the
next generation of code-based research benchmark.

</details>


### [363] [VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation](https://arxiv.org/abs/2510.27617)
*Heng Ping,Arijit Bhattacharjee,Peiyu Zhang,Shixuan Li,Wei Yang,Anzhe Cheng,Xiaole Zhang,Jesse Thomason,Ali Jannesari,Nesreen Ahmed,Paul Bogdan*

Main category: cs.AI

TL;DR: VeriMoa是一个创新的、无需训练的混合代理（MoA）框架，通过质量引导缓存和多路径生成策略，解决了当前多代理方法在硬件描述语言（HDL）生成中的噪声传播和推理空间限制问题，显著提高了自动化RTL设计的性能，尤其使小型模型能够媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 自动化RTL设计以满足日益增长的计算需求，但现有LLM在HDL生成方面存在参数知识有限和领域约束问题，而提示工程和微调有局限性，现有MoA方法存在噪声传播和推理空间受限的缺陷。

Method: VeriMoa框架采用质量引导缓存机制，维护中间HDL输出并进行质量排名和选择，鼓励知识积累；同时，利用C++和Python作为中间表示，将规格到HDL的翻译分解为两阶段过程，通过多路径生成策略促进解决方案多样性。

Result: 在VerilogEval 2.0和RTLLM 2.0基准测试中，VeriMoa在Pass@1指标上实现了15%--30%的提升，尤其使小型模型能够媲美大型模型和微调模型，且无需昂贵的训练。

Conclusion: VeriMoa框架通过其创新的质量引导缓存和多路径生成策略，有效克服了现有方法的局限性，显著提升了自动化RTL设计的性能，并降低了对模型规模和训练的依赖。

Abstract: Automation of Register Transfer Level (RTL) design can help developers meet
increasing computational demands. Large Language Models (LLMs) show promise for
Hardware Description Language (HDL) generation, but face challenges due to
limited parametric knowledge and domain-specific constraints. While prompt
engineering and fine-tuning have limitations in knowledge coverage and training
costs, multi-agent architectures offer a training-free paradigm to enhance
reasoning through collaborative generation. However, current multi-agent
approaches suffer from two critical deficiencies: susceptibility to noise
propagation and constrained reasoning space exploration. We propose VeriMoA, a
training-free mixture-of-agents (MoA) framework with two synergistic
innovations. First, a quality-guided caching mechanism to maintain all
intermediate HDL outputs and enables quality-based ranking and selection across
the entire generation process, encouraging knowledge accumulation over layers
of reasoning. Second, a multi-path generation strategy that leverages C++ and
Python as intermediate representations, decomposing specification-to-HDL
translation into two-stage processes that exploit LLM fluency in high-resource
languages while promoting solution diversity. Comprehensive experiments on
VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves
15--30% improvements in Pass@1 across diverse LLM backbones, especially
enabling smaller models to match larger models and fine-tuned alternatives
without requiring costly training.

</details>


### [364] [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://arxiv.org/abs/2510.27623)
*Qiusi Zhan,Hyeonjeong Ha,Rui Yang,Sirui Xu,Hanyang Chen,Liang-Yan Gui,Yu-Xiong Wang,Huan Zhang,Heng Ji,Daniel Kang*

Main category: cs.AI

TL;DR: 本论文提出了BEAT框架，首次实现了针对多模态大语言模型（MLLM）驱动的具身智能体的视觉后门攻击，利用环境中的物体作为触发器，在触发器出现时使智能体执行攻击者指定的策略。


<details>
  <summary>Details</summary>
Motivation: 视觉后门攻击对多模态大语言模型驱动的具身智能体构成了新的安全风险，攻击者可以利用视觉触发器来控制智能体的行为。

Method: BEAT框架通过构建包含多样化场景、任务和触发器位置的训练数据集，并采用两阶段训练方案（监督微调SFT和对比触发学习CTL）来应对物体触发器在不同视角和光照条件下的变化。CTL将触发器区分视为偏好学习问题，通过区分存在触发器的输入和不存在触发器的输入来增强后门的激活。

Result: BEAT框架在多个具身智能体基准和MLLM上实现了高达80%的攻击成功率，同时保持了良好的正常任务性能，并且能够泛化到分布外（OOD）的触发器位置。与朴素的SFT相比，CTL在有限的后门数据下将后门激活准确率提高了39%。

Conclusion: BEAT框架揭示了MLLM驱动的具身智能体一个关键但未被充分探索的安全风险，强调了在实际部署前开发鲁棒防御机制的必要性。

Abstract: Multimodal large language models (MLLMs) have advanced embodied agents by
enabling direct perception, reasoning, and planning task-oriented actions from
visual inputs. However, such vision driven embodied agents open a new attack
surface: visual backdoor attacks, where the agent behaves normally until a
visual trigger appears in the scene, then persistently executes an
attacker-specified multi-step policy. We introduce BEAT, the first framework to
inject such visual backdoors into MLLM-based embodied agents using objects in
the environments as triggers. Unlike textual triggers, object triggers exhibit
wide variation across viewpoints and lighting, making them difficult to implant
reliably. BEAT addresses this challenge by (1) constructing a training set that
spans diverse scenes, tasks, and trigger placements to expose agents to trigger
variability, and (2) introducing a two-stage training scheme that first applies
supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning
(CTL). CTL formulates trigger discrimination as preference learning between
trigger-present and trigger-free inputs, explicitly sharpening the decision
boundaries to ensure precise backdoor activation. Across various embodied agent
benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while
maintaining strong benign task performance, and generalizes reliably to
out-of-distribution trigger placements. Notably, compared to naive SFT, CTL
boosts backdoor activation accuracy up to 39% under limited backdoor data.
These findings expose a critical yet unexplored security risk in MLLM-based
embodied agents, underscoring the need for robust defenses before real-world
deployment.

</details>


### [365] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: Agentic AI is a new software delivery model, not a foundational technology. Its success relies on end-user validation, and simpler models can often replace LLMs for core logic.


<details>
  <summary>Details</summary>
Motivation: To define Agentic AI and distinguish it from foundational models like LLMs, emphasizing the importance of user validation.

Method: Proposed a realist definition of Agentic AI as a software delivery mechanism and discussed the validation needs of these systems, contrasting them with foundation model evaluation.

Result: Agentic AI systems are applications dependent on end-user validation. Simpler models can often suffice for core logic, making LLMs an option but not a necessity.

Conclusion: The primary need for Agentic AI is validity, which can be achieved through various means, potentially including simpler models, and end-user validation is crucial for success.

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


### [366] [Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training](https://arxiv.org/abs/2510.27630)
*Dayuan Fu,Yunze Wu,Xiaojie Cai,Lyumanshan Ye,Shijie Xia,Zhen Huang,Weiye Si,Tianze Xu,Jie Sun,Keyu Li,Mohan Jiang,Junfei Wang,Qishuo Hua,Pengrui Lu,Yang Xiao,Pengfei Liu*

Main category: cs.AI

TL;DR: Apollo是一个结合了异步人工指导和动作级别数据过滤的采样框架，用于训练大型语言模型（LLM）代理在长时、领域专业化任务上。它通过在代理偏离有前途的轨迹时进行干预，而不是要求在每一步都进行注释，从而降低了成本并实现了持续交互。Apollo还通过监督控制来过滤次优动作，防止错误传播。在InnovatorBench上的实验表明，Apollo在训练GLM-4.5模型时，比未训练基线提高了50%以上，比未进行人工交互的变体提高了28%。


<details>
  <summary>Details</summary>
Motivation: 目前在长时、领域专业化任务上训练LLM代理面临挑战，现有方法（如行为克隆和结果驱动采样）成本高昂或容易失败。

Method: Apollo框架整合了异步人工指导和动作级别数据过滤。人工指导允许在代理偏离时进行干预，提供先验知识或战略建议，实现轻量级交互。动作级别数据过滤通过监督控制来过滤次优动作，防止错误传播。

Result: 在InnovatorBench上，Apollo在训练GLM-4.5模型时，相比未训练基线提高了50%以上，相比未进行人工交互的变体提高了28%。

Conclusion: Apollo在处理长时、领域专业化任务方面表现出鲁棒性，证明了人工在循环采样（human-in-the-loop sampling）的关键作用。

Abstract: Large Language Model (LLM) agents have recently shown strong potential in
domains such as automated coding, deep research, and graphical user interface
manipulation. However, training them to succeed on long-horizon,
domain-specialized tasks remains challenging. Current methods primarily fall
into two categories. The first relies on dense human annotations through
behavior cloning, which is prohibitively expensive for long-horizon tasks that
can take days or months. The second depends on outcome-driven sampling, which
often collapses due to the rarity of valid positive trajectories on
domain-specialized tasks. We introduce Apollo, a sampling framework that
integrates asynchronous human guidance with action-level data filtering.
Instead of requiring annotators to shadow every step, Apollo allows them to
intervene only when the agent drifts from a promising trajectory, by providing
prior knowledge, strategic advice, etc. This lightweight design makes it
possible to sustain interactions for over 30 hours and produces valuable
trajectories at a lower cost. Apollo then applies supervision control to filter
out sub-optimal actions and prevent error propagation. Together, these
components enable reliable and effective data collection in long-horizon
environments. To demonstrate the effectiveness of Apollo, we evaluate it using
InnovatorBench. Our experiments show that when applied to train the GLM-4.5
model on InnovatorBench, Apollo achieves more than a 50% improvement over the
untrained baseline and a 28% improvement over a variant trained without human
interaction. These results highlight the critical role of human-in-the-loop
sampling and the robustness of Apollo's design in handling long-horizon,
domain-specialized tasks.

</details>


### [367] [MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design](https://arxiv.org/abs/2510.27671)
*Wei Zhang,Zekun Guo,Yingce Xia,Peiran Jin,Shufang Xie,Tao Qin,Xiang-Yang Li*

Main category: cs.AI

TL;DR: MolChord是一个结合了NatureLM和DPO的结构药物设计方法，能够更好地对齐蛋白质和分子结构及其对应的文本描述，并指导生成的分子具有期望的药理特性，在CrossDocked2020数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 结构药物设计（SBDD）在药物发现中至关重要，但如何有效地对齐蛋白质和分子结构及其对应的文本描述，并确保生成的药物具有期望的药理特性仍然是一个关键挑战。

Method: MolChord结合了两种关键技术：1. 利用NatureLM（一种统一文本、小分子和蛋白质的自回归模型）作为分子生成器，并结合基于扩散结构编码器，来对齐蛋白质和分子结构及其文本描述和序列表示（如FASTA和SMILES）。2. 通过整合偏好数据构建了一个关注属性的数据集，并使用直接偏好优化（DPO）来优化对齐过程，以指导分子生成具有期望的属性。

Result: 在CrossDocked2020数据集上的实验结果表明，MolChord在关键评估指标上取得了最先进的性能。

Conclusion: MolChord在结构药物设计方面展现出强大的潜力，可以作为一种实用的工具来应对现有的挑战。

Abstract: Structure-based drug design (SBDD), which maps target proteins to candidate
molecular ligands, is a fundamental task in drug discovery. Effectively
aligning protein structural representations with molecular representations, and
ensuring alignment between generated drugs and their pharmacological
properties, remains a critical challenge. To address these challenges, we
propose MolChord, which integrates two key techniques: (1) to align protein and
molecule structures with their textual descriptions and sequential
representations (e.g., FASTA for proteins and SMILES for molecules), we
leverage NatureLM, an autoregressive model unifying text, small molecules, and
proteins, as the molecule generator, alongside a diffusion-based structure
encoder; and (2) to guide molecules toward desired properties, we curate a
property-aware dataset by integrating preference data and refine the alignment
process using Direct Preference Optimization (DPO). Experimental results on
CrossDocked2020 demonstrate that our approach achieves state-of-the-art
performance on key evaluation metrics, highlighting its potential as a
practical tool for SBDD.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [368] [Cooperative Integrated Estimation-Guidance for Simultaneous Interception of Moving Targets](https://arxiv.org/abs/2510.26948)
*Lohitvel Gopikannan,Shashi Ranjan Kumar,Abhinav Sinha*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper proposes a cooperative integrated estimation-guidance framework
for simultaneous interception of a non-maneuvering target using a team of
unmanned autonomous vehicles, assuming only a subset of vehicles are equipped
with dedicated sensors to measure the target's states. Unlike earlier
approaches that focus solely on either estimation or guidance design, the
proposed framework unifies both within a cooperative architecture. To
circumvent the limitation posed by heterogeneity in target observability,
sensorless vehicles estimate the target's state by leveraging information
exchanged with neighboring agents over a directed communication topology
through a prescribed-time observer. The proposed approach employs true
proportional navigation guidance (TPNG), which uses an exact time-to-go
formulation and is applicable across a wide spectrum of target motions.
Furthermore, prescribed-time observer and controller are employed to achieve
convergence to true target's state and consensus in time-to-go within set
predefined times, respectively. Simulations demonstrate the effectiveness of
the proposed framework under various engagement scenarios.

</details>


### [369] [Ferrohydrodynamic Microfluidics for Bioparticle Separation and Single-Cell Phenotyping: Principles, Applications, and Emerging Directions](https://arxiv.org/abs/2510.26950)
*Yuhao Zhang,Yong Teng,Kenan Song,Xianqiao Wang,Xianyan Chen,Yuhua Liu,Yiping Zhao,He Li,Leidong Mao,Yang Liu*

Main category: eess.SY

TL;DR: 该综述介绍了基于铁磁流体微流控技术在生物颗粒（从细胞到细胞外囊泡）分离和分析中的应用，并讨论了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 铁磁流体微流控技术利用磁场梯度操纵抗磁性颗粒，在无标记生物颗粒分离和表型分析方面展现出巨大潜力。

Method: 综述了铁磁流体微流控平台在多尺度生物颗粒分离（从微米级细胞到亚微米级细胞外囊泡）方面的最新进展，重点介绍了导致磁浮力的铁磁流体与颗粒相互作用的物理原理，以及如何实现基于尺寸的高分辨率分离、亚细胞颗粒富集和基于物理特征的表型筛选。

Result: 铁磁流体微流控技术能够实现高分辨率的尺寸分离、亚细胞颗粒富集和基于物理特征的表型筛选。

Conclusion: 铁磁流体微流控技术在生物医学、诊断和细胞工程等领域具有广阔的应用前景，未来的研究方向包括机器学习、3D打印和多重检测。

Abstract: Ferrohydrodynamic microfluidics relies on magnetic field gradients to
manipulate diamagnetic particles in ferrofluid-filled microenvironments. It has
emerged as a promising tool for label-free manipulation of bioparticles,
including their separation and phenotyping. This perspective reviews recent
progress in the development and applications of ferrofluid-based microfluidic
platforms for multiscale bioparticle separation, ranging from micron-scale
cells to submicron extracellular vesicles. We highlight the fundamental
physical principles for ferrohydrodynamic manipulation, including the dominant
magnetic buoyancy force resulting from the interaction of ferrofluids and
particles. We then describe how these principles enable high-resolution
size-based bioparticle separation, subcellular bioparticle enrichment, and
phenotypic screening based on physical traits. We also discuss key challenges
in ferrohydrodynamic microfluidics from the aspects of ferrofluid
biocompatibility, system throughput, and nanoparticle depletion. Finally, we
outline future research directions involving machine learning, 3D printing, and
multiplexed detection. These insights chart a path for advancing
ferrofluid-based technologies in precision biomedicine, diagnostics, and
cellular engineering.

</details>


### [370] [Simplifying Preference Elicitation in Local Energy Markets: Combinatorial Clock Exchange](https://arxiv.org/abs/2510.27306)
*Shobhit Singhal,Lesia Mitridati*

Main category: eess.SY

TL;DR: As distributed energy resources (DERs) proliferate, future power systems need new market platforms enabling prosumers to trade various electricity and grid-support products. However, prosumers often exhibit complex, product interdependent preferences and face limited cognitive and computational resources, hindering engagement with complex market structures and bid formats. We address this challenge by introducing a multi-product market that allows prosumers to express complex preferences through an intuitive format, by fusing combinatorial clock exchange and machine learning (ML) techniques. The iterative mechanism only requires prosumers to report their preferred package of products at posted prices, eliminating the need for forecasting product prices or adhering to complex bid formats, while the ML-aided price discovery speeds up convergence. The linear pricing rule further enhances transparency and interpretability. Finally, numerical simulations demonstrate convergence to clearing prices in approximately 15 clock iterations.


<details>
  <summary>Details</summary>
Motivation: future power systems need new market platforms enabling prosumers to trade various electricity and grid-support products. However, prosumers often exhibit complex, product interdependent preferences and face limited cognitive and computational resources, hindering engagement with complex market structures and bid formats.

Method: fusing combinatorial clock exchange and machine learning (ML) techniques. The iterative mechanism only requires prosumers to report their preferred package of products at posted prices, eliminating the need for forecasting product prices or adhering to complex bid formats, while the ML-aided price discovery speeds up convergence. The linear pricing rule further enhances transparency and interpretability.

Result: numerical simulations demonstrate convergence to clearing prices in approximately 15 clock iterations.

Conclusion: The proposed multi-product market, integrating combinatorial clock exchange and ML, enables prosumers to express complex preferences intuitively, facilitates faster convergence through ML-aided price discovery, and enhances transparency with a linear pricing rule, ultimately demonstrating convergence to clearing prices in simulations.

Abstract: As distributed energy resources (DERs) proliferate, future power system will
need new market platforms enabling prosumers to trade various electricity and
grid-support products. However, prosumers often exhibit complex, product
interdependent preferences and face limited cognitive and computational
resources, hindering engagement with complex market structures and bid formats.
We address this challenge by introducing a multi-product market that allows
prosumers to express complex preferences through an intuitive format, by fusing
combinatorial clock exchange and machine learning (ML) techniques. The
iterative mechanism only requires prosumers to report their preferred package
of products at posted prices, eliminating the need for forecasting product
prices or adhering to complex bid formats, while the ML-aided price discovery
speeds up convergence. The linear pricing rule further enhances transparency
and interpretability. Finally, numerical simulations demonstrate convergence to
clearing prices in approximately 15 clock iterations.

</details>


### [371] [Quantifying Grid-Forming Behavior: Bridging Device-level Dynamics and System-Level Strength](https://arxiv.org/abs/2510.26953)
*Kehao Zhuang,Huanhai Xin,Verena Häberle,Xiuqiang He,Linbin Huang,Florian Dörfler*

Main category: eess.SY

TL;DR: GFM技术在未来电力系统中具有潜力，但缺乏精确量化其行为和影响的方法。本文提出了“形成指数”（FI）来量化GFM转换器的电网电压响应能力，并提出了一种新的量化系统强度的措施，该措施捕捉了多母线电压刚度，能够量化多个母线对电流或功率扰动的电压和相位角响应。最后，证明了GFM转换器能够增强系统强度，为GFM转换器设计、优化布局和系统稳定性评估提供了一个统一的基准。


<details>
  <summary>Details</summary>
Motivation: 目前的GFM技术缺乏精确量化方法和普遍接受的定义，且对系统稳定性的影响未被精确量化，造成了设备和系统层面的脱节。

Method: 从小型信号角度出发，在设备层面，提出了“形成指数”（FI）来量化转换器对电网电压波动的响应；在系统层面，提出了一种新的量化系统强度的方法，捕捉多母线电压刚度，并将其扩展到电网强度和母线强度。

Result: FI量化了转换器的GFM能力，其对电网变化的敏感度；提出的系统强度量化方法能捕捉多母线电压刚度，并识别系统中的薄弱区域。理论证明了GFM转换器能够增强系统强度。

Conclusion: 提出的框架为GFM转换器设计、优化布局和系统稳定性评估提供了一个统一的基准，有效弥合了设备和系统层面的差距。

Abstract: Grid-forming (GFM) technology is widely regarded as a promising solution for
future power systems dominated by power electronics. However, a precise method
for quantifying GFM converter behavior and a universally accepted GFM
definition remain elusive. Moreover, the impact of GFM on system stability is
not precisely quantified, creating a significant disconnect between device and
system levels. To address these gaps from a small-signal perspective, at the
device level, we introduce a novel metric, the Forming Index (FI) to quantify a
converter's response to grid voltage fluctuations. Rather than enumerating
various control architectures, the FI provides a metric for the converter's GFM
ability by quantifying its sensitivity to grid variations. At the system level,
we propose a new quantitative measure of system strength that captures the
multi-bus voltage stiffness, which quantifies the voltage and phase angle
responses of multiple buses to current or power disturbances. We further extend
this concept to grid strength and bus strength to identify weak areas within
the system. Finally, we bridge the device and system levels by formally proving
that GFM converters enhance system strength. Our proposed framework provides a
unified benchmark for GFM converter design, optimal placement, and system
stability assessment.

</details>


### [372] [Adaptive Control for a Physics-Informed Model of a Thermal Energy Distribution System: Qualitative Analysis](https://arxiv.org/abs/2510.26959)
*Paul Seurin,Auradha Annaswamy,Linyu Lin*

Main category: eess.SY

TL;DR: 集成能源系统（IES）中的自适应控制（AC）可以减少50%模型不确定性下的模型误差，但需要进一步研究其对物理系统的影响。


<details>
  <summary>Details</summary>
Motivation: 集成能源系统（IES）的可靠运行受到其动态演变中的不确定性的阻碍，但目前缺乏统一的方法来处理这些不确定性。

Method: 推导了线性系统的自适应控制（AC）形式，并将其应用于一种集成能源系统（IES）中的乙二醇换热器（GHX）的控制。通过在标称模型中引入50%的误差来量化GHX系统动态的不确定性。

Result: 与仅使用线性二次调节器（LQR）相比，采用AC可将平均绝对误差和积分时间绝对误差减少30%-75%，计算开销和控制基础设施的增加极小。

Conclusion: AC能够以最小的计算开销和控制基础设施来适应IES中的模型不确定性，但控制力度显著，需要进一步研究其对物理系统的影响。目前正在开发用于处理部分可观测和非线性动态的AC增强版本。

Abstract: Integrated energy systems (IES) are complex heterogeneous architectures that
typically encompass power sources, hydrogen electrolyzers, energy storage, and
heat exchangers. This integration is achieved through operating control
strategy optimization. However, the lack of physical understanding as to how
these systems evolve over time introduces uncertainties that hinder reliable
application thereof. Techniques that can accommodate such uncertainties are
fundamental for ensuring proper operation of these systems. Unfortunately, no
unifying methodology exists for accommodating uncertainties in this regard.
That being said, adaptive control (AC) is a discipline that may allow for
accommodating such uncertainties in real-time. In the present work, we derive
an AC formulation for linear systems in which all states are observable and
apply it to the control of a glycol heat exchanger (GHX) in an IES. Based on
prior research in which we quantified the uncertainties of the GHXs system
dynamics, we introduced an error of 50% on four terms of the nominal model. In
the case where a linear quadratic regulator is used as the nominal control for
the reference system, we found that employing AC can reduce the mean absolute
error and integral time absolute error by a factor of 30%-75%. This reduction
is achieved with minimal computing overhead and control infrastructure, thus
underscoring the strength of AC. However, the control effort induced is
significant, therefore warranting further study in order to estimate its impact
on a physical system. To address further challenges, including partially
observable and non-linear dynamics, enhancements of the linear formulation are
currently being developed.

</details>


### [373] [Quantitative Parameter Conditions for Stability and Coupling in GFM-GFL Converter Hybrid Systems from a Small-Signal Synchronous Perspective](https://arxiv.org/abs/2510.26971)
*Kehao Zhuang,Huanhai Xin,Hangyu Chen,Linbin Huang*

Main category: eess.SY

TL;DR: 该研究提出了一个包含GFM和GFL转换器的电力系统小信号同步稳定性模型，并基于子空间扰动理论揭示了耦合与解耦条件，提出了相应的稳定判据。


<details>
  <summary>Details</summary>
Motivation: 现有电力系统包含GFM和GFL转换器，但两者之间的动态交互，特别是低惯量GFM转换器和GFL转换器之间的交互，由于同步机制的差异而不够清晰。

Method: 提出一个包含GFM和GFL转换器并考虑电网线路动态的小信号同步稳定性模型。基于子空间扰动理论，分析GFM和GFL子系统在特定条件下（如GFL接近单位功率因数运行，或GFM具有足够大的惯量/阻尼）可解耦。提出解耦条件下的分散式、参数化稳定判据，以及耦合条件下的基于小相位定理的分散式稳定判据。

Result: 揭示了GFM和GFL子系统在特定条件下可解耦，并给出了确保解耦的控制参数下界。提出了补偿了电网负阻尼的正阻尼判据，以及耦合条件下的分散式稳定判据。通过MATLAB/Simulink仿真验证了理论分析的有效性。

Conclusion: 所提出的模型和稳定判据能有效分析包含GFM和GFL转换器的电力系统的同步稳定性，并为控制参数的整定提供了理论指导。

Abstract: With the development of renewable energy sources, power systems are gradually
evolving into a system comprising both grid-forming (GFM) and grid-following
(GFL) converters. However, the dynamic interaction between the two types of
converters, especially low-inertia GFM converters and GFL converters, remains
unclear due to the substantial differences in their synchronization mechanisms.
To address this gap, this paper develops a small-signal synchronous stability
model for power systems containing GFM and GFL converters, which considers
network line dynamics. Based on subspace perturbation theory, we reveal that
GFM and GFL subsystems can be effectively decoupled when GFL converters operate
near unity power factor or when GFM converters possess sufficiently large
inertia or damping, and provide lower bound of control parameters ensuring
decoupling. Under the decoupling condition, we propose decentralized and
analytical parameter-based stability criteria which have clear physical
interpretations: the positive damping of converters compensates for the
negative damping of the network. In the case of coupling, we also propose
decentralized stability criteria based on the small phase theorem. The
effectiveness of the theoretical analysis is validated through simulations in
MATLAB/Simulink.

</details>


### [374] [Dispatchable Current Source Virtual Oscillator Control Achieving Global Stability](https://arxiv.org/abs/2510.26977)
*Kehao Zhuang,Linbin Huang,Huanhai Xin,Xiuqiang He,Verena Häberle,Florian Dörfler*

Main category: eess.SY

TL;DR: 提出了一种用于并网（GFL）转换器的新型可调度电流源虚拟振荡器控制（dCVOC）方案，该方案与可调度虚拟振荡器控制（dVOC）在两个方面具有对偶性：a）电流频率通过无功功率控制产生，类似于PLL；b）电流幅度参考通过有功功率控制产生。


<details>
  <summary>Details</summary>
Motivation: dCVOC方案与dVOC方案在两个方面具有对偶性，电流频率通过无功功率控制产生，电流幅度参考通过有功功率控制产生。

Method: 通过高保真电磁瞬态仿真验证了所提控制方案的有效性。

Result: 所提出的控制始终承认稳态平衡，并确保在合理的电网和转换器参数条件下全局稳定，即使在考虑LVRT和电流饱和约束的情况下也是如此。

Conclusion: 该方法避免了低压暂态和弱电网不稳定性，而传统的GFL控制则不能。

Abstract: This work introduces a novel dispatchable current source virtual oscillator
control (dCVOC) scheme for grid-following (GFL) converters, which exhibits
duality with dispatchable virtual oscillator control (dVOC) in two ways: a) the
current frequency is generated through reactive power control, similar to a PLL
; b) the current magnitude reference is generated through active power control.
We formally prove that our proposed control always admits a steady-state
equilibrium and ensures global stability under reasonable conditions on grid
and converter parameters, even when considering LVRT and current saturation
constraints. Our approach avoids low-voltage transients and weak grid
instability, which is not the case for conventional GFL control. The
effectiveness of our proposed control is verified through high-fidelity
electromagnetic transient simulations.

</details>


### [375] [Solving Infinite-Horizon Optimal Control Problems using the Extreme Theory of Functional Connections](https://arxiv.org/abs/2510.27187)
*Tanay Raghunandan Srinivasa,Suraj Kumar*

Main category: eess.SY

TL;DR: 该研究提出一种物理信息机器学习方法，利用X-TFC（结合了TFC和ELM）求解HJB偏微分方程，以获得最优反馈控制策略，并成功应用于航天器离轨控制。


<details>
  <summary>Details</summary>
Motivation: 为无限时域最优控制问题提供一种新的求解方法，通过物理信息机器学习来解决HJB偏微分方程。

Method: 提出一种结合了函数连接理论（TFC）和极限学习机（ELM）的混合方法（X-TFC），用于近似价值函数，从而求解HJB偏微分方程。该方法能够解析地满足边界条件，并降低训练成本。

Result: 在具有已知解析解的线性和非线性系统上对该方法进行了基准测试，并成功将其应用于航天器最优离轨控制等任务。

Conclusion: 所提出的X-TFC方法能够有效地合成最优反馈控制策略，用于解决无限时域最优控制问题，并在实际控制任务中证明了其有效性。

Abstract: This paper presents a physics-informed machine learning approach for
synthesizing optimal feedback control policy for infinite-horizon optimal
control problems by solving the Hamilton-Jacobi-Bellman (HJB) partial
differential equation(PDE). The optimal control policy is derived analytically
for affine dynamical systems with separable and strictly convex control costs,
expressed as a function of the gradient of the value function. The resulting
HJB-PDE is then solved by approximating the value function using the Extreme
Theory of Functional Connections (X-TFC) - a hybrid approach that combines the
Theory of Functional Connections (TFC) with the Extreme Learning Machine (ELM)
algorithm. This approach ensures analytical satisfaction of boundary conditions
and significantly reduces training cost compared to traditional
Physics-Informed Neural Networks (PINNs). We benchmark the method on linear and
non-linear systems with known analytical solutions as well as demonstrate its
effectiveness on control tasks such as spacecraft optimal de-tumbling control.

</details>


### [376] [A Switching Strategy for Event-Trigger Control of Spacecraft Rendezvous](https://arxiv.org/abs/2510.27414)
*Tommaso Del Carro,Gerson Portilla,Alexandre Seuret,Rafael Vazquez*

Main category: eess.SY

TL;DR: 本文提出一种基于线性矩阵不等式和李亚普诺夫稳定性分析的状态反馈控制律，用于航天器交会对接。该方法通过状态依赖的开关框架来控制脉冲推力器的开关，从而在保证闭环系统稳定性的同时，最小化了总的驱动器激活次数。


<details>
  <summary>Details</summary>
Motivation: 为解决航天器交会对接过程中的燃料消耗和控制精度问题，提出一种新的脉冲控制策略。

Method: 提出一种状态依赖的开关框架，并利用李亚普诺夫稳定性分析和线性矩阵不等式推导出非线性控制律，以确定控制输入幅值和触发推力器激活的状态条件。

Result: 数值案例研究表明，该方法与标准的模型预测控制方案相比，在保证系统稳定性的同时，能够显著减少驱动器激活次数，证明了该方法的有效性。

Conclusion: 所提出的脉冲控制方法能够有效地实现航天器交会对接，并在保证稳定性的前提下，实现最少次数的驱动器激活，具有良好的应用前景。

Abstract: This paper presents the design of a state-feedback control law for spacecraft
rendezvous, formulated using the Hill-Clohessy-Wiltshire equations. The
proposed method introduces an impulsive control strategy to regulate thruster
operations. Specifically, a state-dependent switching framework is developed to
determine both the control input magnitudes and the precise state conditions
that trigger thruster activation. The nonlinear control law is derived using
principles from automatic control theory, particularly Lyapunov stability
analysis and the Linear Matrix Inequality framework. The resulting closed-loop
system is proven to be stable, while simultaneously minimizing the total number
of actuation events. The effectiveness of the proposed method is demonstrated
through a numerical case study, which includes a comparative analysis with a
standard Model Predictive Control scheme, highlighting the advantages and
trade-offs of the developed control structure.

</details>


### [377] [Context-Aware Stochastic Modeling of Consumer Energy Resource Aggregators in Electricity Markets](https://arxiv.org/abs/2510.27478)
*Chatum Sankalpa,Ghulam Mohy-ud-din,Erik Weyer,Maria Vrakopoulou*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Aggregators of consumer energy resources (CERs) like rooftop solar and
battery energy storage (BES) face challenges due to their inherent
uncertainties. A sensible approach is to use stochastic optimization to handle
such uncertainties, which can lead to infeasible problems or loss in revenues
if not chosen appropriately. This paper presents three efficient two-stage
stochastic optimization methods: risk-neutral, robust, and chance-constrained,
to address the impact of CER uncertainties for aggregators who participate in
energy and regulation services markets in the Australian National Electricity
Market. Furthermore, these methods utilize the flexibility of BES, considering
precise state-of-charge dynamics and complementarity constraints, aiming for
scalable performance while managing uncertainty. The problems are formed as
two-stage stochastic mixed-integer linear programs, with relaxations adopted
for large scenario sets. The solution approach employs scenario-based
methodologies and affine recourse policies to obtain tractable reformulations.
These methods are evaluated across use cases reflecting diverse operational and
market settings, uncertainty characteristics, and decision-making preferences,
demonstrating their ability to mitigate uncertainty, enhance profitability, and
provide context-aware guidance for aggregators in choosing the most appropriate
stochastic optimization method.

</details>


### [378] [Technical Report for Dissipativity Learning in Reproducing Kernel Hilbert Space](https://arxiv.org/abs/2510.27669)
*Xiuzhen Ye,Wentao Tang*

Main category: eess.SY

TL;DR: 本文提出了一种在再生核希尔伯特空间（RKHS）中学习耗散性的非参数框架，可以直接从输入输出数据中识别非线性耗散行为，无需显式动力学模型，并提供了泛化保证。


<details>
  <summary>Details</summary>
Motivation: 为了在没有显式动力学模型的情况下，对未知非线性系统进行数据驱动的稳定性与性能认证，并且耗散性是一种可以推广李雅普诺夫稳定性、被动性和有限L2增益的通用系统性质。

Method: 提出了一种非参数框架，在再生核希尔伯特空间中学习耗散性。将存储函数和供给率表示为作用在标准核特征上的希尔伯特-施密特算子，并将优化问题转化为一个一类支持向量机的形式，通过表示定理简化为一个有限维凸规划问题。

Result: 数值结果表明，该方法能够有效地从输入输出数据中识别非线性耗散行为，并且可以提供关于耗散率和L2增益的置信界。

Conclusion: 所提出的基于RKHS的耗散性学习方法为模型自由控制分析和综合提供了一个强大且可解释的框架，能够直接从数据中学习系统的耗散性，从而实现对系统稳定性和性能属性的数据驱动认证。

Abstract: This work presents a nonparametric framework for dissipativity learning in
reproducing kernel Hilbert spaces, which enables data-driven certification of
stability and performance properties for unknown nonlinear systems without
requiring an explicit dynamic model. Dissipativity is a fundamental system
property that generalizes Lyapunov stability, passivity, and finite L2 gain
conditions through an energy balance inequality between a storage function and
a supply rate. Unlike prior parametric formulations that approximate these
functions using quadratic forms with fixed matrices, the proposed method
represents them as Hilbert Schmidt operators acting on canonical kernel
features, thereby capturing nonlinearities implicitly while preserving
convexity and analytic tractability. The resulting operator optimization
problem is formulated in the form of a one-class support vector machine and
reduced, via the representer theorem, to a finite dimensional convex program
expressed through kernel Gram matrices. Furthermore, statistical learning
theory is applied to establish generalization guarantees, including confidence
bounds on the dissipation rate and the L2 gain. Numerical results demonstrate
that the proposed RKHS based dissipativity learning method effectively
identifies nonlinear dissipative behavior directly from input output data,
providing a powerful and interpretable framework for model free control
analysis and synthesis.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [379] [FinPos: A Position-Aware Trading Agent System for Real Financial Markets](https://arxiv.org/abs/2510.27251)
*Bijia Liu,Ronghao Dang*

Main category: cs.MA

TL;DR: LLM在金融交易中具有巨大潜力，但现有交易机器人缺乏持续的仓位管理能力。为此，我们提出了一个名为FinPos的位置感知交易代理系统，该系统通过多时间尺度的奖励和双决策代理来优化仓位管理，并在实验中表现优于现有最先进的交易机器人，证明了LLM在长期市场决策中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有金融交易机器人主要关注单步交易任务，缺乏对持续仓位管理的意识，无法模拟真实市场。

Method: 提出了一种名为FinPos的位置感知交易代理系统，该系统能够从专业角度解读市场信息，做出仓位决策。为了降低仓位波动带来的市场风险，FinPos采用了双决策代理。此外，为应对仓位管理的连续性，采用了多时间尺度的奖励机制。

Result: FinPos在位置感知交易任务中表现优于最先进的交易机器人，该任务能更真实地模拟市场状况。

Conclusion: FinPos在位置感知交易任务中表现出色，并且LLM为中心的代理系统在长期市场决策方面展现出巨大潜力。

Abstract: The exceptional potential of large language models (LLMs) in handling text
information has garnered significant attention in the field of financial
trading. However, current trading agents primarily focus on single-step trading
tasks and lack awareness of continuous position management. Therefore, we
propose a position-aware trading task designed to simulate a more realistic
market. To address this task, we develop a trading agent system, FinPos,
optimized for position management. FinPos is able to interpret various types of
market information from a professional perspective, providing a reliable basis
for positioning decisions. To mitigate the substantial market risks arising
from position fluctuations, FinPos employs dual decision agents. Furthermore,
the continuous nature of position management necessitates our adoption of
multi-timescale rewards, which in turn empowers FinPos to effectively balance
short-term fluctuations against long-term trends. Extensive experiments
demonstrate that FinPos surpasses state-of-the-art trading agents in the
position-aware trading task, which closely mirrors real market conditions. More
importantly, our findings reveal that LLM-centered agent systems exhibit a
vast, largely unexplored potential in long-term market decision-making.

</details>
