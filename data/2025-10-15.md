<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 62]
- [cs.DC](#cs.DC) [Total: 8]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.RO](#cs.RO) [Total: 26]
- [quant-ph](#quant-ph) [Total: 42]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 46]
- [cs.ET](#cs.ET) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.SI](#cs.SI) [Total: 7]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GT](#cs.GT) [Total: 4]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [eess.SP](#eess.SP) [Total: 14]
- [cs.LG](#cs.LG) [Total: 91]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 8]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.GR](#cs.GR) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Enhancing the Quality of 3D Lunar Maps Using JAXA's Kaguya Imagery](https://arxiv.org/abs/2510.11817)
*Yumi Iwashita,Haakon Moe,Yang Cheng,Adnan Ansar,Georgios Georgakis,Adrian Stoica,Kazuto Nakashima,Ryo Kurazume,Jim Torresen*

Main category: cs.CV

TL;DR: 本研究提出一种方法，用于提高从Kaguya TC图像生成的3D月球地图的质量，重点是减轻压缩引起的视差图中的噪声。


<details>
  <summary>Details</summary>
Motivation: 随着全球月球探索努力的加剧，高质量3D月球地图的需求变得越来越关键，特别是对于像NASA Endurance任务概念这样的长距离任务。

Method: 分析Kaguya TC图像的压缩行为，识别系统性视差噪声模式，尤其是在较暗的区域，并提出一种通过减少来自压缩图像的视差图像中的残留噪声来增强3D地图质量的方法。

Result: 实验结果表明，所提出的方法有效地减少了高程噪声，提高了未来月球任务地形数据的安全性和可靠性。

Conclusion: 所提出的方法有效提高了Kaguya TC图像生成的3D月球地图的质量，减轻了压缩引起的噪声，为未来的月球任务提供了更安全可靠的地形数据。

Abstract: As global efforts to explore the Moon intensify, the need for high-quality 3D
lunar maps becomes increasingly critical-particularly for long-distance
missions such as NASA's Endurance mission concept, in which a rover aims to
traverse 2,000 km across the South Pole-Aitken basin. Kaguya TC (Terrain
Camera) images, though globally available at 10 m/pixel, suffer from altitude
inaccuracies caused by stereo matching errors and JPEG-based compression
artifacts. This paper presents a method to improve the quality of 3D maps
generated from Kaguya TC images, focusing on mitigating the effects of
compression-induced noise in disparity maps. We analyze the compression
behavior of Kaguya TC imagery, and identify systematic disparity noise
patterns, especially in darker regions. In this paper, we propose an approach
to enhance 3D map quality by reducing residual noise in disparity images
derived from compressed images. Our experimental results show that the proposed
approach effectively reduces elevation noise, enhancing the safety and
reliability of terrain data for future lunar missions.

</details>


### [2] [Data or Language Supervision: What Makes CLIP Better than DINO?](https://arxiv.org/abs/2510.11835)
*Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: CLIP在作为视觉语言模型（VLM）的视觉编码器方面优于DINO等自监督模型，但其优势是源于语言监督还是更大的训练数据尚不清楚。


<details>
  <summary>Details</summary>
Motivation: 为了分离这些因素，我们在相同的架构、数据集和训练配置下，对CLIP和DINO进行了受控预训练，并实现了相似的ImageNet准确率。

Method: 嵌入分析表明，CLIP捕获高层语义（例如，对象类别、文本），而DINO对低层特征（例如，颜色、样式）更敏感。

Result: 将CLIP和DINO集成到VLM中并在20个VQA基准上进行评估，CLIP在文本密集型任务上表现出色，而DINO在以视觉为中心的任务上略有优势。语言监督的变体（例如，sigmoid损失、预训练语言编码器）产生的收益有限。

Conclusion: 我们的研究结果为视觉编码器的设计及其对VLM性能的影响提供了科学见解。

Abstract: CLIP outperforms self-supervised models like DINO as vision encoders for
vision-language models (VLMs), but it remains unclear whether this advantage
stems from CLIP's language supervision or its much larger training data. To
disentangle these factors, we pre-train CLIP and DINO under controlled settings
-- using the same architecture, dataset, and training configuration --
achieving similar ImageNet accuracy. Embedding analysis shows that CLIP
captures high-level semantics (e.g., object categories, text), while DINO is
more responsive to low-level features like colors and styles. When integrated
into VLMs and evaluated on 20 VQA benchmarks, CLIP excels at text-intensive
tasks, while DINO slightly outperforms on vision-centric ones. Variants of
language supervision (e.g., sigmoid loss, pre-trained language encoders) yield
limited gains. Our findings provide scientific insights into vision encoder
design and its impact on VLM performance.

</details>


### [3] [MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images](https://arxiv.org/abs/2510.11883)
*Sicheng Zhou,Lei Wu,Cao Xiao,Parminder Bhatia,Taha Kass-Hout*

Main category: cs.CV

TL;DR: MammoDINO是一个用于乳腺X光摄影的新型自监督学习框架，在140万张乳腺X光片上进行预训练，并在多个乳腺癌筛查任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于数据有限和领域特定偏见，自监督学习在医学影像中的应用受到限制。本研究旨在为乳腺X光摄影开发一个有效的自监督学习框架。

Method: MammoDINO框架包括一个乳腺组织感知的 数据增强采样器，用于图像和块级别的监督，以及一个跨切片对比学习目标，该目标利用了3D数字乳腺断层合成（DBT）结构进行2D预训练。

Result: MammoDINO在多个乳腺癌筛查任务上取得了最先进的性能，并在五个基准数据集上表现出良好的泛化能力。

Conclusion: MammoDINO为多用途计算机辅助诊断（CAD）工具提供了一个可扩展、无需注释的基础，有助于减轻放射科医生的工作量并提高乳腺癌筛查的诊断效率。

Abstract: Self-supervised learning (SSL) has transformed vision encoder training in
general domains but remains underutilized in medical imaging due to limited
data and domain specific biases. We present MammoDINO, a novel SSL framework
for mammography, pretrained on 1.4 million mammographic images. To capture
clinically meaningful features, we introduce a breast tissue aware data
augmentation sampler for both image-level and patch-level supervision and a
cross-slice contrastive learning objective that leverages 3D digital breast
tomosynthesis (DBT) structure into 2D pretraining. MammoDINO achieves
state-of-the-art performance on multiple breast cancer screening tasks and
generalizes well across five benchmark datasets. It offers a scalable,
annotation-free foundation for multipurpose computer-aided diagnosis (CAD)
tools for mammogram, helping reduce radiologists' workload and improve
diagnostic efficiency in breast cancer screening.

</details>


### [4] [Task-Specific Dual-Model Framework for Comprehensive Traffic Safety Video Description and Analysis](https://arxiv.org/abs/2510.11907)
*Blessing Agyei Kyem,Neema Jakisa Owor,Andrews Danyo,Joshua Kofi Asamoah,Eugene Denteh,Tanner Muturi,Anthony Dontoh,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 该研究提出了一种创新的双模型框架，结合VideoLLaMA和Qwen2.5-VL的优势，通过任务特定的优化来提升交通安全分析中的视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 交通安全分析需要复杂的视频理解能力来捕捉细微的行为模式并生成全面的描述以预防事故。

Method: 提出了一种独特اً的双模型框架，利用VideoLLaMA和Qwen2.5-VL的互补优势，通过任务特定的优化来解决交通安全分析中的视频理解问题。将字幕生成和视觉问答（VQA）任务分开训练，以最小化任务干扰并使每个模型更有效地专业化。

Result: 在WTS数据集上的实验表明，VideoLLaMA在时间推理方面表现出色，CIDEr得分为1.1001；Qwen2.5-VL在视觉理解方面表现突出，VQA准确率为60.80%。该方法在2025 AI City Challenge Track 2中取得了45.7572的S2分数，在排行榜上名列第10。消融研究证实，分开训练策略相比联合训练在VQA准确率上提升了8.6%，同时保持了字幕质量。

Conclusion: 该研究提出的分离训练策略在交通安全视频分析任务中，通过利用不同模型的优势，能够有效提升视频理解的准确性和效果。

Abstract: Traffic safety analysis requires complex video understanding to capture
fine-grained behavioral patterns and generate comprehensive descriptions for
accident prevention. In this work, we present a unique dual-model framework
that strategically utilizes the complementary strengths of VideoLLaMA and
Qwen2.5-VL through task-specific optimization to address this issue. The core
insight behind our approach is that separating training for captioning and
visual question answering (VQA) tasks minimizes task interference and allows
each model to specialize more effectively. Experimental results demonstrate
that VideoLLaMA is particularly effective in temporal reasoning, achieving a
CIDEr score of 1.1001, while Qwen2.5-VL excels in visual understanding with a
VQA accuracy of 60.80\%. Through extensive experiments on the WTS dataset, our
method achieves an S2 score of 45.7572 in the 2025 AI City Challenge Track 2,
placing 10th on the challenge leaderboard. Ablation studies validate that our
separate training strategy outperforms joint training by 8.6\% in VQA accuracy
while maintaining captioning quality.

</details>


### [5] [PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation](https://arxiv.org/abs/2510.11992)
*Hatem Ibrahem,Ahmed Salem,Qinmin Vivian Hu,Guanghui Wang*

Main category: cs.CV

TL;DR: PanoTPS-Net是一个新的模型，用于从单个全景图像估计房间布局，它结合了卷积神经网络和薄板样条空间变换，能够处理立方体和非立方体房间布局，并在多个数据集上取得了最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确估计房间的3D布局在机器人、增强现实和室内设计等领域具有重要应用价值。

Method: 提出了一种名为PanoTPS-Net的新模型，该模型分为两个阶段：1. 使用卷积神经网络提取特征并学习薄板样条（TPS）变换的空间参数。2. 使用预测的参数生成的TPS空间变换层来扭曲参考布局以适应目标布局。

Result: 在PanoContext、Stanford-2D3D、Matterport3DLayout和ZInD数据集上，该模型分别取得了85.49、86.16、81.76和91.98的3DIoU值，证明了其在估计立方体和非立方体房间布局方面的准确性和鲁棒性。

Conclusion: PanoTPS-Net模型有效地实现了全景图像的房间布局估计，并且TPS变换与全景图像具有良好的兼容性，能够稳健地处理各种房间布局。

Abstract: Accurately estimating the 3D layout of rooms is a crucial task in computer
vision, with potential applications in robotics, augmented reality, and
interior design. This paper proposes a novel model, PanoTPS-Net, to estimate
room layout from a single panorama image. Leveraging a Convolutional Neural
Network (CNN) and incorporating a Thin Plate Spline (TPS) spatial
transformation, the architecture of PanoTPS-Net is divided into two stages:
First, a convolutional neural network extracts the high-level features from the
input images, allowing the network to learn the spatial parameters of the TPS
transformation. Second, the TPS spatial transformation layer is generated to
warp a reference layout to the required layout based on the predicted
parameters. This unique combination empowers the model to properly predict room
layouts while also generalizing effectively to both cuboid and non-cuboid
layouts. Extensive experiments on publicly available datasets and comparisons
with state-of-the-art methods demonstrate the effectiveness of the proposed
method. The results underscore the model's accuracy in room layout estimation
and emphasize the compatibility between the TPS transformation and panorama
images. The robustness of the model in handling both cuboid and non-cuboid room
layout estimation is evident with a 3DIoU value of 85.49, 86.16, 81.76, and
91.98 on PanoContext, Stanford-2D3D, Matterport3DLayout, and ZInD datasets,
respectively. The source code is available at:
https://github.com/HatemHosam/PanoTPS_Net.

</details>


### [6] [Prompt-Guided Spatial Understanding with RGB-D Transformers for Fine-Grained Object Relation Reasoning](https://arxiv.org/abs/2510.11996)
*Tanner Muturi,Blessing Agyei Kyem,Joshua Kofi Asamoah,Neema Jakisa Owor,Richard Dyzinela,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 本研究提出了一个针对大型3D仓库环境的空间推理框架，通过将掩码维度嵌入到输入提示中，并使用特定任务的监督进行微调，以提高模型在距离估计、物体计数、多项选择和空间关系推理等方面的能力，最终在AI City Challenge中取得了73.0606的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在大型3D仓库环境中进行空间推理时面临挑战，因为场景混乱、遮挡以及需要精确的空间理解，并且模型在泛化能力方面表现不佳，过度依赖局部外观且缺乏明确的空间基础。

Method: 本研究引入了一个专门的空间推理框架，通过将掩码维度（以边界框坐标形式）直接嵌入到输入提示中，使模型能够推理对象的几何形状和布局。该框架针对“物理AI空间智能仓库”数据集，在距离估计、物体计数、多项选择和空间关系推理四类问题上进行了特定任务监督的微调。为了提高与评估系统的兼容性，还会在训练集中将归一化后的答案附加到GPT响应中。

Result: 该综合管线在2025 AI City Challenge的Track 3中取得了73.0606的最终分数，在公开排行榜上名列第四。

Conclusion: 研究结果证明了结构化提示增强和目标优化在提升真实工业环境空间推理能力方面的有效性。

Abstract: Spatial reasoning in large-scale 3D environments such as warehouses remains a
significant challenge for vision-language systems due to scene clutter,
occlusions, and the need for precise spatial understanding. Existing models
often struggle with generalization in such settings, as they rely heavily on
local appearance and lack explicit spatial grounding. In this work, we
introduce a dedicated spatial reasoning framework for the Physical AI Spatial
Intelligence Warehouse dataset introduced in the Track 3 2025 AI City
Challenge. Our approach enhances spatial comprehension by embedding mask
dimensions in the form of bounding box coordinates directly into the input
prompts, enabling the model to reason over object geometry and layout. We
fine-tune the framework across four question categories namely: Distance
Estimation, Object Counting, Multi-choice Grounding, and Spatial Relation
Inference using task-specific supervision. To further improve consistency with
the evaluation system, normalized answers are appended to the GPT response
within the training set. Our comprehensive pipeline achieves a final score of
73.0606, placing 4th overall on the public leaderboard. These results
demonstrate the effectiveness of structured prompt enrichment and targeted
optimization in advancing spatial reasoning for real-world industrial
environments.

</details>


### [7] [Evaluating the Explainability of Vision Transformers in Medical Imaging](https://arxiv.org/abs/2510.12021)
*Leili Barekatain,Ben Glocker*

Main category: cs.CV

TL;DR: 本研究评估了不同 Vision Transformer (ViT) 架构和预训练策略（ViT、DeiT、DINO 和 Swin Transformer）在医学影像中的可解释性。


<details>
  <summary>Details</summary>
Motivation: 在医学影像领域，理解模型决策至关重要，因为可解释性直接影响临床信任和应用。尽管 Vision Transformers (ViTs) 在诊断成像中表现出色，但其复杂的注意力机制带来了可解释性方面的挑战。

Method: 研究使用 Gradient Attention Rollout 和 Grad-CAM 技术，在两个医学影像任务（外周血细胞分类和乳腺超声图像分类）上，对不同的 Vision Transformer 架构（ViT、DeiT、DINO 和 Swin Transformer）和预训练策略进行了定量和定性分析。

Result: 研究发现，DINO 结合 Grad-CAM 在不同数据集上提供了最准确和最局部的解释。Grad-CAM 持续生成具有类别区分性和空间精确性的热力图，而 Gradient Attention Rollout 产生的激活则更分散。即使在错误分类的情况下，DINO 结合 Grad-CAM 也能突出显示那些可能误导模型的临床相关形态学特征。

Conclusion: 通过提高模型透明度，本研究旨在支持 ViTs 在关键医疗诊断工作流程中的可靠且可解释的集成。

Abstract: Understanding model decisions is crucial in medical imaging, where
interpretability directly impacts clinical trust and adoption. Vision
Transformers (ViTs) have demonstrated state-of-the-art performance in
diagnostic imaging; however, their complex attention mechanisms pose challenges
to explainability. This study evaluates the explainability of different Vision
Transformer architectures and pre-training strategies - ViT, DeiT, DINO, and
Swin Transformer - using Gradient Attention Rollout and Grad-CAM. We conduct
both quantitative and qualitative analyses on two medical imaging tasks:
peripheral blood cell classification and breast ultrasound image
classification. Our findings indicate that DINO combined with Grad-CAM offers
the most faithful and localized explanations across datasets. Grad-CAM
consistently produces class-discriminative and spatially precise heatmaps,
while Gradient Attention Rollout yields more scattered activations. Even in
misclassification cases, DINO with Grad-CAM highlights clinically relevant
morphological features that appear to have misled the model. By improving model
transparency, this research supports the reliable and explainable integration
of ViTs into critical medical diagnostic workflows.

</details>


### [8] [Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction](https://arxiv.org/abs/2510.12768)
*Fengzhi Guo,Chih-Chuan Hsu,Sihao Ding,Cheng Zhang*

Main category: cs.CV

TL;DR: USplat4D 通过引入不确定性感知动态高斯泼溅框架，利用高斯点在时间和视角上的观测频率来指导运动重建，解决了现有方法在遮挡和极端视角下的不足，实现了更稳定的几何结构和更高质量的视图合成。


<details>
  <summary>Details</summary>
Motivation: 从单目输入重建动态3D场景存在本质上的不确定性，尤其是在遮挡和极端视角下。现有的动态高斯泼溅模型在优化时统一处理所有高斯原语，忽略了它们的观测质量，导致运动漂移和视图合成效果下降。

Method: USplat4D 框架估计随时间变化的、每个高斯点的不确定性，并利用这些不确定性构建时空图，进行不确定性感知的优化，将可靠的运动线索传播到4D重建中。

Result: 在各种真实和合成数据集上的实验表明，USplat4D 明确地对不确定性进行建模，能够持续改进动态高斯泼溅模型，在遮挡情况下提供更稳定的几何结构，并在极端视角下实现高质量的视图合成。

Conclusion: 明确地对不确定性进行建模是提升动态高斯泼溅模型性能的关键，USplat4D 通过这种方法有效地解决了现有模型在处理动态3D场景重建时的不确定性问题。

Abstract: Reconstructing dynamic 3D scenes from monocular input is fundamentally
under-constrained, with ambiguities arising from occlusion and extreme novel
views. While dynamic Gaussian Splatting offers an efficient representation,
vanilla models optimize all Gaussian primitives uniformly, ignoring whether
they are well or poorly observed. This limitation leads to motion drifts under
occlusion and degraded synthesis when extrapolating to unseen views. We argue
that uncertainty matters: Gaussians with recurring observations across views
and time act as reliable anchors to guide motion, whereas those with limited
visibility are treated as less reliable. To this end, we introduce USplat4D, a
novel Uncertainty-aware dynamic Gaussian Splatting framework that propagates
reliable motion cues to enhance 4D reconstruction. Our key insight is to
estimate time-varying per-Gaussian uncertainty and leverages it to construct a
spatio-temporal graph for uncertainty-aware optimization. Experiments on
diverse real and synthetic datasets show that explicitly modeling uncertainty
consistently improves dynamic Gaussian Splatting models, yielding more stable
geometry under occlusion and high-quality synthesis at extreme viewpoints.

</details>


### [9] [APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection](https://arxiv.org/abs/2510.12056)
*Xinxin Huang,Han Sun,Junmin Cai,Ningzhong Liu,Huiyu Zhou*

Main category: cs.CV

TL;DR: 本研究提出APGNet，一种自适应先验引导网络，用于解决水下伪装目标检测中的图像退化和目标伪装难题，通过多尺度Retinex颜色恢复增强数据，利用扩展感受野和多尺度渐进式解码器捕获多尺度信息，并结合自适应先验引导机制（空间注意力和可变形卷积）进行精确定位和轮廓细化，在MAS数据集上实验证明优于15种现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下图像退化（对比度低、色彩失真）和海洋生物的自然伪装是水下伪装目标检测的两个主要挑战，现有方法在处理这些问题时存在不足。

Method: 提出APGNet网络，包括：1. 使用多尺度Retinex颜色恢复（MSRCR）算法进行数据增强，生成光照不变的图像；2. 设计扩展感受野（ERF）模块和多尺度渐进式解码器（MPD）以捕获多尺度上下文信息；3. 提出自适应先验引导机制，通过空间注意力融合位置先验，并使用可变形卷积细化边界先验。

Result: 在两个公开的MAS数据集上进行的大量实验表明，APGNet在常用评估指标下优于15种最先进的方法。

Conclusion: APGNet通过集成新颖的先验引导机制和有效的网络结构，成功解决了水下伪装目标检测的挑战，并在实验中取得了领先的性能。

Abstract: Detecting camouflaged objects in underwater environments is crucial for
marine ecological research and resource exploration. However, existing methods
face two key challenges: underwater image degradation, including low contrast
and color distortion, and the natural camouflage of marine organisms.
Traditional image enhancement techniques struggle to restore critical features
in degraded images, while camouflaged object detection (COD) methods developed
for terrestrial scenes often fail to adapt to underwater environments due to
the lack of consideration for underwater optical characteristics.
  To address these issues, we propose APGNet, an Adaptive Prior-Guided Network,
which integrates a Siamese architecture with a novel prior-guided mechanism to
enhance robustness and detection accuracy. First, we employ the Multi-Scale
Retinex with Color Restoration (MSRCR) algorithm for data augmentation,
generating illumination-invariant images to mitigate degradation effects.
Second, we design an Extended Receptive Field (ERF) module combined with a
Multi-Scale Progressive Decoder (MPD) to capture multi-scale contextual
information and refine feature representations. Furthermore, we propose an
adaptive prior-guided mechanism that hierarchically fuses position and boundary
priors by embedding spatial attention in high-level features for coarse
localization and using deformable convolution to refine contours in low-level
features.
  Extensive experimental results on two public MAS datasets demonstrate that
our proposed method APGNet outperforms 15 state-of-art methods under widely
used evaluation metrics.

</details>


### [10] [MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars](https://arxiv.org/abs/2510.12785)
*Felix Taubner,Ruihang Zhang,Mathieu Tuli,Sherwin Bahmani,David B. Lindell*

Main category: cs.CV

TL;DR: 通过使用基于预训练视频扩散模型MVP4D，可以从单一参考图像和目标表情生成可动画化的多视图视频，并将其提取为可实时渲染的4D头像，从而显著提高生成头像的真实感、时间一致性和3D一致性。


<details>
  <summary>Details</summary>
Motivation: 传统数字人头像创建流程成本高、耗时长，需要专业3D美术师的大量手动工作。现有方法虽然降低了创建门槛，但在新视角渲染时真实感和图像质量会下降。

Method: 提出了一种名为MVP4D的视频模型，该模型基于预训练的视频扩散模型，能够根据单个参考图像和目标表情，同时生成数百帧、视角可变化达360度的多视图视频。随后，将该模型的输出提取为可实时渲染的4D头像。

Result: 与先前的方法相比，MVP4D在真实感、时间一致性和3D一致性方面均有显著提升，能够生成质量更高的4D头像。

Conclusion: MVP4D能够从单一参考图像生成高质量、可动画化的4D数字人头像，解决了现有方法在多视角渲染时面临的挑战，为虚拟环境中的沉浸式体验提供了更好的支持。

Abstract: Digital human avatars aim to simulate the dynamic appearance of humans in
virtual environments, enabling immersive experiences across gaming, film,
virtual reality, and more. However, the conventional process for creating and
animating photorealistic human avatars is expensive and time-consuming,
requiring large camera capture rigs and significant manual effort from
professional 3D artists. With the advent of capable image and video generation
models, recent methods enable automatic rendering of realistic animated avatars
from a single casually captured reference image of a target subject. While
these techniques significantly lower barriers to avatar creation and offer
compelling realism, they lack constraints provided by multi-view information or
an explicit 3D representation. So, image quality and realism degrade when
rendered from viewpoints that deviate strongly from the reference image. Here,
we build a video model that generates animatable multi-view videos of digital
humans based on a single reference image and target expressions. Our model,
MVP4D, is based on a state-of-the-art pre-trained video diffusion model and
generates hundreds of frames simultaneously from viewpoints varying by up to
360 degrees around a target subject. We show how to distill the outputs of this
model into a 4D avatar that can be rendered in real-time. Our approach
significantly improves the realism, temporal consistency, and 3D consistency of
generated avatars compared to previous methods.

</details>


### [11] [VIDMP3: Video Editing by Representing Motion with Pose and Position Priors](https://arxiv.org/abs/2510.12069)
*Sandeep Mishra,Oindrila Saha,Alan C. Bovik*

Main category: cs.CV

TL;DR: VidMP3是一种新的视频编辑方法，通过利用姿态和位置先验来学习广义运动表示，从而在保持原始运动的同时，实现结构和语义的灵活性，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的视频编辑方法在保留结构的任务上表现出色，但在处理需要结构和语义灵活性的运动保留视频编辑方面存在不足，如时间不一致、主体身份漂移和需要人工干预等问题。

Method: VidMP3利用姿态和位置先验来学习源视频的广义运动表示，以实现新的视频生成，同时保持原始运动并允许结构和语义的灵活性。

Result: 定性和定量评估均表明VidMP3优于现有方法。

Conclusion: VidMP3在运动保留视频编辑方面取得了显著进展，能够灵活地进行结构和语义的编辑，同时保持时间一致性和主体身份。

Abstract: Motion-preserved video editing is crucial for creators, particularly in
scenarios that demand flexibility in both the structure and semantics of
swapped objects. Despite its potential, this area remains underexplored.
Existing diffusion-based editing methods excel in structure-preserving tasks,
using dense guidance signals to ensure content integrity. While some recent
methods attempt to address structure-variable editing, they often suffer from
issues such as temporal inconsistency, subject identity drift, and the need for
human intervention. To address these challenges, we introduce VidMP3, a novel
approach that leverages pose and position priors to learn a generalized motion
representation from source videos. Our method enables the generation of new
videos that maintain the original motion while allowing for structural and
semantic flexibility. Both qualitative and quantitative evaluations demonstrate
the superiority of our approach over existing methods. The code will be made
publicly available at https://github.com/sandeep-sm/VidMP3.

</details>


### [12] [A Review on Domain Adaption and Generative Adversarial Networks(GANs)](https://arxiv.org/abs/2510.12075)
*Aashish Dhawan,Divyanshu Mudgal*

Main category: cs.CV

TL;DR: 现有计算机视觉模型在训练时需要大量标注数据，但现实中获取标注数据成本高昂且有难度。本研究探讨了领域自适应技术，旨在利用在一个领域的数据上训练好的模型来预测同一类型但不同领域的数据。


<details>
  <summary>Details</summary>
Motivation: 高质量标注数据在计算机视觉任务（尤其是图像分类）中至关重要，但现实中获取此类数据面临成本高昂、耗时且存在困难的挑战。因此，需要开发能够克服数据稀缺性并取得与基准结果相媲美性能的新方法。

Method: 本文讨论了领域自适应（Domain Adaptation）的概念以及多种实现该技术的方法。

Result: The paper discusses Domain Adaptation and various methods to implement it.

Conclusion: 领域自适应技术可以通过利用已有的模型来预测新领域的数据，从而有效解决数据稀缺性问题。

Abstract: The major challenge in today's computer vision scenario is the availability
of good quality labeled data. In a field of study like image classification,
where data is of utmost importance, we need to find more reliable methods which
can overcome the scarcity of data to produce results comparable to previous
benchmark results. In most cases, obtaining labeled data is very difficult
because of the high cost of human labor and in some cases impossible. The
purpose of this paper is to discuss Domain Adaptation and various methods to
implement it. The main idea is to use a model trained on a particular dataset
to predict on data from a different domain of the same kind, for example - a
model trained on paintings of airplanes predicting on real images of airplanes

</details>


### [13] [Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback](https://arxiv.org/abs/2510.12089)
*Xingpei Ma,Shenneng Huang,Jiaran Cai,Yuansheng Guan,Shen Zheng,Hanfeng Zhao,Qiang Zhang,Shunsi Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于DiT的框架，用于生成任意长度的、逼真的、音频驱动的人体视频，并引入了一种无需训练即可实现多角色动画的方法。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动的人体视频生成方法在唇同步精度、长视频的时间连贯性以及多角色动画方面仍面临挑战。

Method: 1. 采用基于LoRA的训练策略和位置偏移推理方法，实现高效长视频生成。 2. 结合部分参数更新和奖励反馈，提升唇同步和身体动作的自然度。 3. 提出无需训练的Mask Classifier-Free Guidance (Mask-CFG) 方法，支持多角色（三个或以上）音频驱动动画。

Result: 实验结果表明，该方法在生成高质量、时间连贯、多角色的音频驱动视频方面优于现有最先进方法，且方法简单、高效、成本效益高。

Conclusion: 所提出的方法能够以简单、高效、低成本的方式，生成高质量、时间连贯且支持多角色的音频驱动视频。

Abstract: Recent advances in diffusion models have significantly improved audio-driven
human video generation, surpassing traditional methods in both quality and
controllability. However, existing approaches still face challenges in lip-sync
accuracy, temporal coherence for long video generation, and multi-character
animation. In this work, we propose a diffusion transformer (DiT)-based
framework for generating lifelike talking videos of arbitrary length, and
introduce a training-free method for multi-character audio-driven animation.
First, we employ a LoRA-based training strategy combined with a position shift
inference approach, which enables efficient long video generation while
preserving the capabilities of the foundation model. Moreover, we combine
partial parameter updates with reward feedback to enhance both lip
synchronization and natural body motion. Finally, we propose a training-free
approach, Mask Classifier-Free Guidance (Mask-CFG), for multi-character
animation, which requires no specialized datasets or model modifications and
supports audio-driven animation for three or more characters. Experimental
results demonstrate that our method outperforms existing state-of-the-art
approaches, achieving high-quality, temporally coherent, and multi-character
audio-driven video generation in a simple, efficient, and cost-effective
manner.

</details>


### [14] [IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation](https://arxiv.org/abs/2510.12095)
*Wenxu Zhou,Kaixuan Nie,Hang Du,Dong Yin,Wei Huang,Siqiang Guo,Xiaobo Zhang,Pengbo Hu*

Main category: cs.CV

TL;DR: IL3D是一个大规模数据集，用于LLM驱动的3D场景生成，包含27,816个室内布局和29,215个3D对象资产，并带有实例级自然语言注释，以支持多模态学习。


<details>
  <summary>Details</summary>
Motivation: 为室内布局设计领域提供多样化、高质量的训练数据，以满足LLM驱动的3D场景生成的需求。

Method: 构建了一个包含27,816个室内布局和29,215个3D对象资产的大规模数据集IL3D，并进行了实例级自然语言注释。在此基础上，建立了评估LLM驱动场景生成能力的基准。

Result: 在IL3D上对LLM进行监督微调（SFT）能显著提高泛化能力，并优于在其他数据集上进行SFT的性能。

Conclusion: IL3D是一个多功能、高质量的数据集，通过提供高保真场景数据来支持具身智能体的环境感知任务，从而推动了3D场景生成和具身智能领域的研究。

Abstract: In this study, we present IL3D, a large-scale dataset meticulously designed
for large language model (LLM)-driven 3D scene generation, addressing the
pressing demand for diverse, high-quality training data in indoor layout
design. Comprising 27,816 indoor layouts across 18 prevalent room types and a
library of 29,215 high-fidelity 3D object assets, IL3D is enriched with
instance-level natural language annotations to support robust multimodal
learning for vision-language tasks. We establish rigorous benchmarks to
evaluate LLM-driven scene generation. Experimental results show that supervised
fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and
surpasses the performance of SFT on other datasets. IL3D offers flexible
multimodal data export capabilities, including point clouds, 3D bounding boxes,
multiview images, depth maps, normal maps, and semantic masks, enabling
seamless adaptation to various visual tasks. As a versatile and robust
resource, IL3D significantly advances research in 3D scene generation and
embodied intelligence, by providing high-fidelity scene data to support
environment perception tasks of embodied agents.

</details>


### [15] [An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring](https://arxiv.org/abs/2510.12098)
*Jianping Li,Dongyang Guo,Wenjie Li,Wei Zhao*

Main category: cs.CV

TL;DR: 提出了一种利用 QR 码的结构化边缘先验知识的去模糊方法，并开发了两种网络（EG-Restormer 和 LENet）以及一个自适应双网络（ADNet），在提高 QR 码解码成功率和速度方面取得了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法很少利用 QR 码的结构化边缘先验知识来提高解码成功率，而这正是 QR 码去模糊的关键。

Method: 提出了一种边缘引导注意力块（EGAB），将边缘先验知识嵌入 Transformer 架构。基于 EGAB 开发了 EG-Restormer 网络，用于严重模糊的 QR 码去模糊；开发了轻量级高效网络（LENet），用于轻微模糊的 QR 码的快速去模糊；并将两者集成为自适应双网络（ADNet），根据模糊严重程度动态选择网络。

Result: EG-Restormer 和 ADNet 在严重模糊的 QR 码解码率上显著提升，并实现了具有竞争力的速度，达到了先进水平。

Conclusion: 所提出的基于边缘先验的去模糊方法（EGAB、EG-Restormer、LENet 和 ADNet）在提高 QR 码解码成功率和处理速度方面均表现出色，尤其适用于资源受限的移动设备。

Abstract: Unlike general image deblurring that prioritizes perceptual quality, QR code
deblurring focuses on ensuring successful decoding. QR codes are characterized
by highly structured patterns with sharp edges, a robust prior for restoration.
Yet existing deep learning methods rarely exploit these priors explicitly. To
address this gap, we propose the Edge-Guided Attention Block (EGAB), which
embeds explicit edge priors into a Transformer architecture. Based on EGAB, we
develop Edge-Guided Restormer (EG-Restormer), an effective network that
significantly boosts the decoding rate of severely blurred QR codes. For mildly
blurred inputs, we design the Lightweight and Efficient Network (LENet) for
fast deblurring. We further integrate these two networks into an Adaptive
Dual-network (ADNet), which dynamically selects the suitable network based on
input blur severity, making it ideal for resource-constrained mobile devices.
Extensive experiments show that our EG-Restormer and ADNet achieve
state-of-the-art performance with a competitive speed. Project page:
https://github.com/leejianping/ADNet

</details>


### [16] [G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior](https://arxiv.org/abs/2510.12099)
*Junfeng Ni,Yixin Chen,Zhifei Yang,Yu Liu,Ruijie Lu,Song-Chun Zhu,Siyuan Huang*

Main category: cs.CV

TL;DR: 现有3D场景重建方法在几何监督和多视角一致性方面存在局限。本文提出利用平面结构提取精确的深度图，并将其作为几何引导，贯穿于生成流程，以提高可见性掩码估计、新视角选择和多视角一致性，从而实现精确且一致的场景补全。实验证明该方法在几何和外观重建方面优于现有基线，尤其在未观测区域表现突出，并支持单视角输入和无姿态视频，具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重建方法在几何监督不足和多视角一致性处理不佳方面存在局限，导致重建质量不高，尤其在未观测区域。生成模型在利用时也缺乏有效机制来解决这些问题。

Method: 1. 利用平面结构提取精确的度量尺度深度图，为观测和未观测区域提供可靠的监督。2. 将几何引导融入生成流程，改进可见性掩码估计，指导新视角选择，并在使用视频扩散模型进行修复时增强多视角一致性。

Result: 所提出的方法在Replica、ScanNet++和DeepBlending数据集上进行了广泛实验，结果表明该方法在几何和外观重建方面持续优于现有基线，特别是在未观测区域。

Conclusion: 准确的几何信息是有效利用生成模型增强3D场景重建的关键。通过引入平面结构驱动的几何引导，可以显著提高重建质量，解决多视角不一致性问题，并实现高质量的场景补全。该方法具有单视角输入、无姿态视频支持和良好的泛化能力。

Abstract: Despite recent advances in leveraging generative prior from pre-trained
diffusion models for 3D scene reconstruction, existing methods still face two
critical limitations. First, due to the lack of reliable geometric supervision,
they struggle to produce high-quality reconstructions even in observed regions,
let alone in unobserved areas. Second, they lack effective mechanisms to
mitigate multi-view inconsistencies in the generated images, leading to severe
shape-appearance ambiguities and degraded scene geometry. In this paper, we
identify accurate geometry as the fundamental prerequisite for effectively
exploiting generative models to enhance 3D scene reconstruction. We first
propose to leverage the prevalence of planar structures to derive accurate
metric-scale depth maps, providing reliable supervision in both observed and
unobserved regions. Furthermore, we incorporate this geometry guidance
throughout the generative pipeline to improve visibility mask estimation, guide
novel view selection, and enhance multi-view consistency when inpainting with
video diffusion models, resulting in accurate and consistent scene completion.
Extensive experiments on Replica, ScanNet++, and DeepBlending show that our
method consistently outperforms existing baselines in both geometry and
appearance reconstruction, particularly for unobserved regions. Moreover, our
method naturally supports single-view inputs and unposed videos, with strong
generalizability in both indoor and outdoor scenarios with practical real-world
applicability. The project page is available at
https://dali-jack.github.io/g4splat-web/.

</details>


### [17] [Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare](https://arxiv.org/abs/2510.12741)
*Adam Tupper,Christian Gagné*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Foundation models open up new possibilities for the use of AI in healthcare.
However, even when pre-trained on health data, they still need to be fine-tuned
for specific downstream tasks. Furthermore, although foundation models reduce
the amount of training data required to achieve good performance, obtaining
sufficient data is still a challenge. This is due, in part, to restrictions on
sharing and aggregating data from different sources to protect patients'
privacy. One possible solution to this is to fine-tune foundation models via
federated learning across multiple participating clients (i.e., hospitals,
clinics, etc.). In this work, we propose a new personalized federated
fine-tuning method that learns orthogonal LoRA adapters to disentangle general
and client-specific knowledge, enabling each client to fully exploit both their
own data and the data of others. Our preliminary results on real-world
federated medical imaging tasks demonstrate that our approach is competitive
against current federated fine-tuning methods.

</details>


### [18] [DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning](https://arxiv.org/abs/2510.12107)
*Jiawei Zhan,Jun Liu,Jinlong Peng,Xiaochen Chen,Bin-Bin Gao,Yong Liu,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出判别式表示学习（DRL）框架，通过增量式并行适配器（IPA）网络和解耦锚点监督（DAS）来解决预训练模型（PTM）在持续学习中面临的模型复杂度、表示偏移和优化不一致等问题，实验证明DRL在保持高效率的同时，在各项基准测试中持续优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 非课程学习（CIL）在利用预训练模型（PTM）方面取得了显著进展，但仍面临模型复杂度高、表示偏移和优化不一致等挑战。

Method: 提出判别式表示学习（DRL）框架，包括增量式并行适配器（IPA）网络（通过轻量级适配器渐进式增强模型）和解耦锚点监督（DAS）（通过虚拟锚点解耦正负样本约束，对齐不同阶段的特征空间）。

Result: DRL框架在六个基准测试中，在整个CIL周期内持续优于现有最先进方法，同时保持了训练和推理的高效率。

Conclusion: DRL框架通过IPA和DAS有效解决了CIL中的关键挑战，实现了高效且性能优越的持续学习。

Abstract: With the excellent representation capabilities of Pre-Trained Models (PTMs),
remarkable progress has been made in non-rehearsal Class-Incremental Learning
(CIL) research. However, it remains an extremely challenging task due to three
conundrums: increasingly large model complexity, non-smooth representation
shift during incremental learning and inconsistency between stage-wise
sub-problem optimization and global inference. In this work, we propose the
Discriminative Representation Learning (DRL) framework to specifically address
these challenges. To conduct incremental learning effectively and yet
efficiently, the DRL's network, called Incremental Parallel Adapter (IPA)
network, is built upon a PTM and increasingly augments the model by learning a
lightweight adapter with a small amount of parameter learning overhead in each
incremental stage. The adapter is responsible for adapting the model to new
classes, it can inherit and propagate the representation capability from the
current model through parallel connection between them by a transfer gate. As a
result, this design guarantees a smooth representation shift between different
incremental stages. Furthermore, to alleviate inconsistency and enable
comparable feature representations across incremental stages, we design the
Decoupled Anchor Supervision (DAS). It decouples constraints of positive and
negative samples by respectively comparing them with the virtual anchor. This
decoupling promotes discriminative representation learning and aligns the
feature spaces learned at different stages, thereby narrowing the gap between
stage-wise local optimization over a subset of data and global inference across
all classes. Extensive experiments on six benchmarks reveal that our DRL
consistently outperforms other state-of-the-art methods throughout the entire
CIL period while maintaining high efficiency in both training and inference
phases.

</details>


### [19] [Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration](https://arxiv.org/abs/2510.12114)
*Wenjie Li,Xiangyi Wang,Heng Guo,Guangwei Gao,Zhanyu Ma*

Main category: cs.CV

TL;DR: SSDiff 提出了一种新的老照片人脸修复方法，通过自监督的伪标签和选择性引导的扩散模型，实现了对破损、褪色和模糊等复合退化的人脸进行区域特定的修复，并在 VintageFace 数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸修复方法在处理老照片的复合退化（如破损、褪色、模糊）时存在不足，尤其是在处理局部伪影和面部颜色方面。

Method: 提出了一种名为 SSDiff 的自监督选择性引导扩散方法。该方法利用预训练的扩散模型生成弱指导下的伪参考人脸，这些伪标签具有结构对齐的轮廓和自然的颜色。通过分阶段的监督：在整个去噪过程中应用结构引导，并在后期进行颜色细化，实现了区域特定的修复。结合人脸解析图和划痕掩码，选择性地修复破损区域，避免身份不匹配。构建了包含300张真实老照片的 VintageFace 基准测试集。

Result: SSDiff 在感知质量、保真度和区域可控性方面优于现有的基于 GAN 和扩散的方法。

Conclusion: SSDiff 能够有效地处理老照片中的复合退化，实现高质量的人脸修复，并且在 VintageFace 数据集上表现出优越的性能。

Abstract: Old-photo face restoration poses significant challenges due to compounded
degradations such as breakage, fading, and severe blur. Existing pre-trained
diffusion-guided methods either rely on explicit degradation priors or global
statistical guidance, which struggle with localized artifacts or face color. We
propose Self-Supervised Selective-Guided Diffusion (SSDiff), which leverages
pseudo-reference faces generated by a pre-trained diffusion model under weak
guidance. These pseudo-labels exhibit structurally aligned contours and natural
colors, enabling region-specific restoration via staged supervision: structural
guidance applied throughout the denoising process and color refinement in later
steps, aligned with the coarse-to-fine nature of diffusion. By incorporating
face parsing maps and scratch masks, our method selectively restores breakage
regions while avoiding identity mismatch. We further construct VintageFace, a
300-image benchmark of real old face photos with varying degradation levels.
SSDiff outperforms existing GAN-based and diffusion-based methods in perceptual
quality, fidelity, and regional controllability. Code link:
https://github.com/PRIS-CV/SSDiff.

</details>


### [20] [ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation](https://arxiv.org/abs/2510.12119)
*Ziyuan Luo,Yangyi Zhao,Ka Chun Cheung,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: ImageSentinel 是一个新颖的框架，用于在检索增强图像生成 (RAIG) 系统中保护视觉数据集，通过合成视觉上一致的哨兵图像，并利用视觉-语言模型来生成它们，从而解决未经授权使用私有数据集的问题。


<details>
  <summary>Details</summary>
Motivation: RAIG 系统的广泛采用引发了对私有图像数据集未经授权使用的担忧。传统的数字水印方法在 RAIG 系统中效果不佳，因为其复杂的特征提取和重组过程会破坏水印信号。因此，需要一种新的方法来保护视觉数据集免遭未经授权的使用。

Method: ImageSentinel 框架通过生成与原始数据集在视觉上保持一致的哨兵图像来保护数据集。这些哨兵图像允许通过随机生成的字符序列（用作检索密钥）进行保护验证。该框架利用视觉-语言模型来生成哨兵图像，并确保与 RAIG 系统的无缝集成。

Result: 实验结果表明，ImageSentinel 能够有效检测未经授权的数据集使用，同时在授权应用程序中保持了生成质量。

Conclusion: ImageSentinel 成功地解决了 RAIG 系统中的数据集保护问题，它通过生成哨兵图像并利用视觉-语言模型来实现，可以在有效检测未经授权使用的情况下，保持图像生成的质量。

Abstract: The widespread adoption of Retrieval-Augmented Image Generation (RAIG) has
raised significant concerns about the unauthorized use of private image
datasets. While these systems have shown remarkable capabilities in enhancing
generation quality through reference images, protecting visual datasets from
unauthorized use in such systems remains a challenging problem. Traditional
digital watermarking approaches face limitations in RAIG systems, as the
complex feature extraction and recombination processes fail to preserve
watermark signals during generation. To address these challenges, we propose
ImageSentinel, a novel framework for protecting visual datasets in RAIG. Our
framework synthesizes sentinel images that maintain visual consistency with the
original dataset. These sentinels enable protection verification through
randomly generated character sequences that serve as retrieval keys. To ensure
seamless integration, we leverage vision-language models to generate the
sentinel images. Experimental results demonstrate that ImageSentinel
effectively detects unauthorized dataset usage while preserving generation
quality for authorized applications. Code is available at
https://github.com/luo-ziyuan/ImageSentinel.

</details>


### [21] [Hardware-aware Coding Function Design for Compressive Single-Photon 3D Cameras](https://arxiv.org/abs/2510.12123)
*David Parra,Felipe Gutierrez-Barragan,Trevor Seets,Andreas Velten*

Main category: cs.CV

TL;DR: 单光子相机在三维成像中受到硬件限制，本文提出一种联合优化照明和编码矩阵的方法来解决数据率和峰值功率限制问题，并在仿真和实际系统中均表现出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 单光子相机在三维成像中性能受硬件限制，特别是数据率和峰值功率。现有的压缩直方图方法在实际光照硬件约束下表现不佳。

Method: 提出一种约束优化方法，使用梯度下降法联合优化照明和编码矩阵（即编码函数），以满足硬件约束。

Result: 通过大量仿真表明，所提出的编码函数在带宽和峰值功率约束下，优于传统的编码设计。在峰值功率受限的系统中优势尤为明显。对具有非理想脉冲响应的实际系统进行评估，证明了该方法能够适应任意参数化的脉冲响应。

Conclusion: 所提出的约束优化方法能够为单光子三维成像设计实用的编码函数，有效解决硬件限制带来的性能瓶颈，并在各种约束条件下优于现有技术。

Abstract: Single-photon cameras are becoming increasingly popular in time-of-flight 3D
imaging because they can time-tag individual photons with extreme resolution.
However, their performance is susceptible to hardware limitations, such as
system bandwidth, maximum laser power, sensor data rates, and in-sensor memory
and compute resources. Compressive histograms were recently introduced as a
solution to the challenge of data rates through an online in-sensor compression
of photon timestamp data. Although compressive histograms work within limited
in-sensor memory and computational resources, they underperform when subjected
to real-world illumination hardware constraints. To address this, we present a
constrained optimization approach for designing practical coding functions for
compressive single-photon 3D imaging. Using gradient descent, we jointly
optimize an illumination and coding matrix (i.e., the coding functions) that
adheres to hardware constraints. We show through extensive simulations that our
coding functions consistently outperform traditional coding designs under both
bandwidth and peak power constraints. This advantage is particularly pronounced
in systems constrained by peak power. Finally, we show that our approach adapts
to arbitrary parameterized impulse responses by evaluating it on a real-world
system with a non-ideal impulse response function.

</details>


### [22] [MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites](https://arxiv.org/abs/2510.12126)
*Zhenxin Lei,Zhangwei Gao,Changyao Tian,Erfei Cui,Guanzhou Chen,Danni Yang,Yuchen Duan,Zhaokai Wang,Wenhao Li,Weiyun Wang,Xiangyu Zhao,Jiayi Ji,Yu Qiao,Wenhai Wang,Gen Luo*

Main category: cs.CV

TL;DR: CapFlow是一个多智能体协作流程，通过利用开源模型，在成本降低89.5%的情况下，实现了与GPT-4.1相当的字幕质量，并在此基础上训练了MetaCaptioner模型，该模型在开源社区中达到了顶尖的多模态性能。


<details>
  <summary>Details</summary>
Motivation: 当前的开源模型在通用视觉字幕生成任务上与商业模型存在显著的性能差距，这限制了数据合成等应用。本研究旨在缩小这一差距。

Method: 提出了一种名为CapFlow的新型多智能体协作流程，并利用它来合成高质量的视觉字幕，进而训练了一个名为MetaCaptioner的通用视觉字幕模型。

Result: CapFlow实现了与GPT-4.1相当的字幕质量，同时成本降低了89.5%。MetaCaptioner模型在视觉字幕能力上可与商业模型相媲美，并在开源社区中达到了顶尖的多模态性能。

Conclusion: CapFlow和MetaCaptioner提供了一个强大且经济高效的视觉字幕解决方案，有望惠及未来的多模态研究。

Abstract: Generalist visual captioning goes beyond a simple appearance description
task, but requires integrating a series of visual cues into a caption and
handling various visual domains. In this task, current open-source models
present a large performance gap with commercial ones, which limits various
applications such as data synthesis. To bridge the gap, this paper proposes
CapFlow, a novel multi-agent collaboration workflow. CapFlow demonstrates for
the first time that, by capitalizing on open-source models, it is possible to
achieve caption quality on par with GPT-4.1 in various domains with an 89.5%
reduction in costs. By leveraging CapFlow as the data synthesizer, we produce
high-quality visual captions from image and video domains at scale, and obtain
a generalist visual captioner via fine-tuning, namely MetaCaptioner. Through
extensive experiments, we show that MetaCaptioner not only achieves comparable
captioning capabilities with commercial models but also reaches top-tier
multimodal performance in the open-source community. We hope CapFlow and
MetaCaptioner can benefit future multimodal research by providing a strong and
cost-effective visual captioning solution.

</details>


### [23] [FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements](https://arxiv.org/abs/2510.12132)
*Xiao Yang,Jiyao Wang*

Main category: cs.CV

TL;DR: 本项目提出了一种名为 FedHUG 的联邦无监督域泛化框架，用于解决远程生理信号测量中用户数据隐私和标签缺失的挑战。


<details>
  <summary>Details</summary>
Motivation: 远程生理信号测量需要收集用户隐私信息，并且现有方法依赖有标签数据，这给在真实世界中更新模型带来了困难。本项目旨在解决这些挑战。

Method: 提出了一种名为 FedHUG 的联邦无监督域泛化框架，包含两个模块：1. 最小偏差聚合模块：根据先验驱动的偏差评估动态调整聚合权重，以处理多领域异构非IID特征。2. 全局分布感知学习控制器：参数化标签分布并动态调整客户端特定的训练策略，以减轻服务器-客户端标签分布偏移和长尾问题。

Result: FedHUG 框架在 RGB 视频或 mmWave 雷达的生理信号估计方面表现优于现有技术。

Conclusion: FedHUG 框架能够有效解决远程生理信号测量中的数据隐私和标签缺失问题，并在实际应用中展现出优越的性能。

Abstract: Remote physiological measurement gained wide attention, while it requires
collecting users' privacy-sensitive information, and existing contactless
measurements still rely on labeled client data. This presents challenges when
we want to further update real-world deployed models with numerous user data
lacking labels. To resolve these challenges, we instantiate a new protocol
called Federated Unsupervised Domain Generalization (FUDG) in this work.
Subsequently, the \textbf{Fed}erated \textbf{H}eterogeneous
\textbf{U}nsupervised \textbf{G}eneralization (\textbf{FedHUG}) framework is
proposed and consists of: (1) Minimal Bias Aggregation module dynamically
adjusts aggregation weights based on prior-driven bias evaluation to cope with
heterogeneous non-IID features from multiple domains. (2) The Global
Distribution-aware Learning Controller parameterizes the label distribution and
dynamically manipulates client-specific training strategies, thereby mitigating
the server-client label distribution skew and long-tail issue. The proposal
shows superior performance across state-of-the-art techniques in estimation
with either RGB video or mmWave radar. The code will be released.

</details>


### [24] [Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation](https://arxiv.org/abs/2510.12150)
*Jiahuan Zhou,Chao Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua*

Main category: cs.CV

TL;DR: 该研究提出了一种名为KFF的持续测试时自适应方法，通过自适应地融合和分离与类别相关的域知识，以解决现有方法在适应新域时学习新知识不足和受旧域知识干扰的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法在适应新域时，因恢复或重用旧模型导致新知识学习不足，并可能受到有害旧知识的干扰，从而导致性能下降。

Method: 提出了一种名为KFF的类感知域知识融合与分离方法。具体包括：1. 域知识分离（KFI）模块：自适应地从成对的类感知域提示池中分离出新域知识，以减轻与当前域不同的旧域带来的负面知识影响。2. 域知识融合（KFU）模块：通过贪婪的知识动态合并策略，以最小的成本将分离出的新知识合并到现有的知识池中，同时保持计算效率。

Result: 在ImageNet-C数据集上的大量实验验证了所提出方法相对于其他方法的有效性。

Conclusion: KFF方法通过自适应地融合和分离类感知域知识，有效解决了现有CTTA方法的局限性，能够在保持计算效率的同时，动态累积区分性历史知识，并更好地适应新域。

Abstract: Continual Test-Time Adaptation (CTTA) aims to quickly fine-tune the model
during the test phase so that it can adapt to multiple unknown downstream
domain distributions without pre-acquiring downstream domain data. To this end,
existing advanced CTTA methods mainly reduce the catastrophic forgetting of
historical knowledge caused by irregular switching of downstream domain data by
restoring the initial model or reusing historical models. However, these
methods are usually accompanied by serious insufficient learning of new
knowledge and interference from potentially harmful historical knowledge,
resulting in severe performance degradation. To this end, we propose a
class-aware domain Knowledge Fusion and Fission method for continual test-time
adaptation, called KFF, which adaptively expands and merges class-aware domain
knowledge in old and new domains according to the test-time data from different
domains, where discriminative historical knowledge can be dynamically
accumulated. Specifically, considering the huge domain gap within streaming
data, a domain Knowledge FIssion (KFI) module is designed to adaptively
separate new domain knowledge from a paired class-aware domain prompt pool,
alleviating the impact of negative knowledge brought by old domains that are
distinct from the current domain. Besides, to avoid the cumulative computation
and storage overheads from continuously fissioning new knowledge, a domain
Knowledge FUsion (KFU) module is further designed to merge the fissioned new
knowledge into the existing knowledge pool with minimal cost, where a greedy
knowledge dynamic merging strategy is designed to improve the compatibility of
new and old knowledge while keeping the computational efficiency. Extensive
experiments on the ImageNet-C dataset verify the effectiveness of our proposed
method against other methods.

</details>


### [25] [DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation](https://arxiv.org/abs/2510.12159)
*Ziyuan Gao,Philippe Morel*

Main category: cs.CV

TL;DR: DPL通过扩散模型学习医学图像分割中的原型表示，解决了数据稀疏和解剖变异性的问题，提高了分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统的基于原型的方法在处理少量标注数据和显著的解剖变异性时，由于确定性平均化导致原型表示脆弱，无法捕捉类内多样性，影响泛化能力。

Method: 提出了一种名为扩散原型学习（DPL）的新框架，将原型构建重构为基于扩散特征空间的探索。DPL将单次原型建模为可学习的概率分布，通过（1）基于扩散的原型增强模块，（2）空间感知条件机制，以及（3）保守融合策略，生成多样化且语义一致的原型变体。

Result: 在腹部MRI和CT数据集上的大量实验表明，DPL显著提高了性能，并在单次医学图像分割任务上达到了新的最先进水平。

Conclusion: DPL框架通过概率分布表示和扩散模型，有效解决了单次医学图像分割中的原型表示挑战，实现了鲁棒的泛化能力和最先进的分割精度。

Abstract: One-shot medical image segmentation faces fundamental challenges in prototype
representation due to limited annotated data and significant anatomical
variability across patients. Traditional prototype-based methods rely on
deterministic averaging of support features, creating brittle representations
that fail to capture intra-class diversity essential for robust generalization.
This work introduces Diffusion Prototype Learning (DPL), a novel framework that
reformulates prototype construction through diffusion-based feature space
exploration. DPL models one-shot prototypes as learnable probability
distributions, enabling controlled generation of diverse yet semantically
coherent prototype variants from minimal labeled data. The framework operates
through three core innovations: (1) a diffusion-based prototype enhancement
module that transforms single support prototypes into diverse variant sets via
forward-reverse diffusion processes, (2) a spatial-aware conditioning mechanism
that leverages geometric properties derived from prototype feature statistics,
and (3) a conservative fusion strategy that preserves prototype fidelity while
maximizing representational diversity. DPL ensures training-inference
consistency by using the same diffusion enhancement and fusion pipeline in both
phases. This process generates enhanced prototypes that serve as the final
representations for similarity calculations, while the diffusion process itself
acts as a regularizer. Extensive experiments on abdominal MRI and CT datasets
demonstrate significant improvements respectively, establishing new
state-of-the-art performance in one-shot medical image segmentation.

</details>


### [26] [State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding](https://arxiv.org/abs/2510.12160)
*Jiahuan Zhou,Kai Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua*

Main category: cs.CV

TL;DR: 状态空间提示（SSP）是一种新的视频理解方法，它通过结合帧内和帧间提示来聚合和传播关键时空信息，从而提高了视频分类的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练状态空间模型在视频分类中虽然效率高，但其顺序压缩视觉提示令牌的方式无法有效捕捉视频的空间和时间上下文信息，限制了空间和时间信息的传播以及判别性信息的提取。

Method: 提出了一种状态空间提示（SSP）方法，包括一个帧内聚合（IFG）模块，用于聚合每帧内的空间关键信息；以及一个帧间扩散（IFS）模块，用于在不同帧之间扩散判别性时空信息。通过自适应地平衡和压缩帧内和帧间的关键时空信息，SSP能够以互补的方式有效地传播视频中的判别性信息。

Result: 在四个视频基准数据集上的广泛实验表明，SSP的平均性能比现有最先进的方法（SOTA）高出2.76%，同时还减少了微调参数的开销。

Conclusion: SSP方法能够有效地聚合和传播视频中的关键时空信息，显著提高了视频理解的性能，并降低了微调参数的开销，优于现有方法。

Abstract: Recently, pre-trained state space models have shown great potential for video
classification, which sequentially compresses visual tokens in videos with
linear complexity, thereby improving the processing efficiency of video data
while maintaining high performance. To apply powerful pre-trained models to
downstream tasks, prompt learning is proposed to achieve efficient downstream
task adaptation with only a small number of fine-tuned parameters. However, the
sequentially compressed visual prompt tokens fail to capture the spatial and
temporal contextual information in the video, thus limiting the effective
propagation of spatial information within a video frame and temporal
information between frames in the state compression model and the extraction of
discriminative information. To tackle the above issue, we proposed a State
Space Prompting (SSP) method for video understanding, which combines
intra-frame and inter-frame prompts to aggregate and propagate key
spatiotemporal information in the video. Specifically, an Intra-Frame Gathering
(IFG) module is designed to aggregate spatial key information within each
frame. Besides, an Inter-Frame Spreading (IFS) module is designed to spread
discriminative spatio-temporal information across different frames. By
adaptively balancing and compressing key spatio-temporal information within and
between frames, our SSP effectively propagates discriminative information in
videos in a complementary manner. Extensive experiments on four video benchmark
datasets verify that our SSP significantly outperforms existing SOTA methods by
2.76% on average while reducing the overhead of fine-tuning parameters.

</details>


### [27] [UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering](https://arxiv.org/abs/2510.12174)
*Yusen Xie,Zhenmin Huang,Jianhao Jiao,Dimitrios Kanoulas,Jun Ma*

Main category: cs.CV

TL;DR: UniGS是一个统一的3D高斯溅射框架，用于高保真多模态3D重建，通过改进的光栅化管线同时渲染RGB图像、深度图、表面法线和语义信息，并引入可学习的属性以提高效率。


<details>
  <summary>Details</summary>
Motivation: 提出一种统一的地图表示和可微分框架，用于基于3D高斯溅射的高保真多模态3D重建。

Method: 通过可微射线-椭球体相交渲染深度，并通过解析梯度优化旋转和尺度属性；推导表面法线渲染的解析梯度；引入可学习属性以进行高斯剪枝。

Result: 在所有模态下均达到最先进的重建准确性。

Conclusion: 该框架在所有模态下都实现了最先进的重建准确性，证明了其几何感知范式的有效性。

Abstract: In this paper, we propose UniGS, a unified map representation and
differentiable framework for high-fidelity multimodal 3D reconstruction based
on 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated
rasterization pipeline capable of rendering photo-realistic RGB images,
geometrically accurate depth maps, consistent surface normals, and semantic
logits simultaneously. We redesign the rasterization to render depth via
differentiable ray-ellipsoid intersection rather than using Gaussian centers,
enabling effective optimization of rotation and scale attribute through
analytic depth gradients. Furthermore, we derive the analytic gradient
formulation for surface normal rendering, ensuring geometric consistency among
reconstructed 3D scenes. To improve computational and storage efficiency, we
introduce a learnable attribute that enables differentiable pruning of
Gaussians with minimal contribution during training. Quantitative and
qualitative experiments demonstrate state-of-the-art reconstruction accuracy
across all modalities, validating the efficacy of our geometry-aware paradigm.
Source code and multimodal viewer will be available on GitHub.

</details>


### [28] [BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation](https://arxiv.org/abs/2510.12182)
*Youngju Yoo,Seho Kim,Changick Kim*

Main category: cs.CV

TL;DR: BEEP3D是一种端到端的3D实例分割方法，使用学生-教师框架和新颖的损失函数，通过框级标注生成伪掩码，提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了降低3D实例分割的标注成本，研究者们试图使用更易获取的框级标注替代点级标注。然而，框级标注的模糊性使得精确的}(	ext{point-to-instance})分配变得困难。现有的两阶段方法虽然能生成伪掩码，但增加了训练时间和复杂性，阻碍了端到端的优化。

Method: BEEP3D采用学生-教师框架，教师模型通过指数移动平均(EMA)由学生模型更新，充当伪标签生成器。为了优化伪掩码的生成，提出了基于实例中心查询的查询细化方法，以增强位置查询定位并利用实例中心附近的特征。此外，还设计了查询一致性损失和掩码特征一致性损失，以对齐预测和伪掩码之间的语义和几何信号。

Result: 在ScanNetV2和S3DIS数据集上的实验表明，BEEP3D在性能上与最先进的弱监督方法相当或更优，同时保持了计算效率。

Conclusion: BEEP3D通过端到端的伪掩码生成，有效解决了框级标注的模糊性问题，并在3D实例分割任务中取得了优越的性能和效率。

Abstract: 3D instance segmentation is crucial for understanding complex 3D
environments, yet fully supervised methods require dense point-level
annotations, resulting in substantial annotation costs and labor overhead. To
mitigate this, box-level annotations have been explored as a weaker but more
scalable form of supervision. However, box annotations inherently introduce
ambiguity in overlapping regions, making accurate point-to-instance assignment
challenging. Recent methods address this ambiguity by generating pseudo-masks
through training a dedicated pseudo-labeler in an additional training stage.
However, such two-stage pipelines often increase overall training time and
complexity, hinder end-to-end optimization. To overcome these challenges, we
propose BEEP3D-Box-supervised End-to-End Pseudo-mask generation for 3D instance
segmentation. BEEP3D adopts a student-teacher framework, where the teacher
model serves as a pseudo-labeler and is updated by the student model via an
Exponential Moving Average. To better guide the teacher model to generate
precise pseudo-masks, we introduce an instance center-based query refinement
that enhances position query localization and leverages features near instance
centers. Additionally, we design two novel losses-query consistency loss and
masked feature consistency loss-to align semantic and geometric signals between
predictions and pseudo-masks. Extensive experiments on ScanNetV2 and S3DIS
datasets demonstrate that BEEP3D achieves competitive or superior performance
compared to state-of-the-art weakly supervised methods while remaining
computationally efficient.

</details>


### [29] [CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs](https://arxiv.org/abs/2510.12184)
*Jiwan Kim,Kibum Kim,Sangwoo Seo,Chanyoung Park*

Main category: cs.CV

TL;DR: CompoDistill通过对齐学生和教师模型的视觉注意力，解决了现有知识蒸馏方法在蒸馏教师模型视觉感知能力方面的不足，显著提高了学生模型在组合推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法在将教师模型丰富的视觉感知能力传递给学生模型方面存在困难，而这在以往的研究中并未得到充分关注。

Method: 提出CompoDistill框架，通过显式对齐学生和教师模型的视觉注意力，来增强学生模型的视觉感知能力。

Result: CompoDistill在需要视觉感知能力的组合推理任务上显著提升了性能，同时在视觉问答任务上保持了原有水平。该方法也适用于更先进的模型骨干，证明了其通用性。

Conclusion: CompoDistill成功解决了知识蒸馏中视觉注意力不对齐的问题，有效提升了学生模型在下游任务中的视觉推理能力。

Abstract: Recently, efficient Multimodal Large Language Models (MLLMs) have gained
significant attention as a solution to their high computational complexity,
making them more practical for real-world applications. In this regard, the
knowledge distillation (KD) approach has emerged as a promising alternative,
which transfers the rich visual and linguistic knowledge from a larger model
(teacher) to a smaller model (student). However, we observe that existing KD
methods struggle to effectively distill the teacher MLLM's rich visual
perception abilities to the student, a challenge that has been largely
overlooked in previous studies. Through a systematic analysis, we identify
visual attention misalignment between student and teacher as the main cause of
this issue. Based on this insight, we propose CompoDistill, a novel KD
framework that explicitly aligns the student's visual attention with that of
the teacher to enhance the student's visual perception abilities. Our extensive
experiments show that CompoDistill significantly improves performance on
compositional reasoning tasks that require visual perception abilities while
maintaining strong performance on visual question answering tasks, as done in
existing studies. Furthermore, CompoDistill demonstrates effectiveness with a
more advanced backbone, highlighting its generalizability.

</details>


### [30] [Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos](https://arxiv.org/abs/2510.12190)
*Shingo Yokoi,Kento Sasaki,Yu Yamaguchi*

Main category: cs.CV

TL;DR: 本研究提出了一种用于从行车记录仪视频生成事故报告的 PPO 框架，该框架在 2COOOL 基准测试中取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 虽然端到端自动驾驶模型在大量数据上训练得很好，但它们在分布外（OOD）场景中仍然表现不佳。COOOL 基准测试旨在通过鼓励超越封闭分类的危险理解来解决这一问题，而 2COOOL 挑战赛则将其扩展到生成人类可解释的事件报告。

Method: 本研究提出了一种分层推理框架，用于从行车记录仪视频生成事件报告。该框架集成了帧级字幕、事件帧检测和视觉语言模型（VLM）内的细粒度推理。此外，研究还通过模型集成和盲 A/B 分数选择协议来提高事实准确性和可读性。

Result: 在 2COOOL 官方公开排行榜上，该方法在 29 个团队中排名第二，并取得了最佳的 CIDEr-D 分数，生成了准确连贯的事件叙述。

Conclusion: 分层推理与 VLM 结合是事故分析和更广泛地理解安全关键交通事件的有前景的方向。

Abstract: Recent advances in end-to-end (E2E) autonomous driving have been enabled by
training on diverse large-scale driving datasets, yet autonomous driving models
still struggle in out-of-distribution (OOD) scenarios. The COOOL benchmark
targets this gap by encouraging hazard understanding beyond closed taxonomies,
and the 2COOOL challenge extends it to generating human-interpretable incident
reports. We present a hierarchical reasoning framework for incident report
generation from dashcam videos that integrates frame-level captioning, incident
frame detection, and fine-grained reasoning within vision-language models
(VLMs). We further improve factual accuracy and readability through model
ensembling and a Blind A/B Scoring selection protocol. On the official 2COOOL
open leaderboard, our method ranks 2nd among 29 teams and achieves the best
CIDEr-D score, producing accurate and coherent incident narratives. These
results indicate that hierarchical reasoning with VLMs is a promising direction
for accident analysis and for broader understanding of safety-critical traffic
events. The implementation and code are available at
https://github.com/riron1206/kaggle-2COOOL-2nd-Place-Solution.

</details>


### [31] [The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data](https://arxiv.org/abs/2510.12208)
*Muammer Bay,Timo von Marcard,Dren Fazlija*

Main category: cs.CV

TL;DR: 合成数据可以用于优化物流和制造领域的计算机视觉模型，尤其是在仓库场景下的目标检测任务。


<details>
  <summary>Details</summary>
Motivation: 许多AI应用受限于专业知识和资源的缺乏，导致需要依赖通用模型，而通用模型通常需要领域特定的数据进行微调，成本高昂且效率低下。因此，使用合成数据进行微调是一种流行且经济高效的替代方案。

Method: 本研究利用NVIDIA Omniverse Replicator工具生成合成数据，并将其应用于仓库环境中托盘检测的目标检测模型，以评估合成数据对模型在真实世界场景中性能的影响。

Result: 研究结果表明，在仓库环境中，集成合成数据和真实数据可以构建出高效且鲁棒的目标检测模型，为合成图像数据在计算机视觉中的实际应用提供了有价值的见解。

Conclusion: 合成数据与真实数据相结合是提高目标检测模型性能的有效策略，尤其是在仓库物流等领域。

Abstract: Recent advances in generative AI, particularly in computer vision (CV), offer
new opportunities to optimize workflows across industries, including logistics
and manufacturing. However, many AI applications are limited by a lack of
expertise and resources, which forces a reliance on general-purpose models.
Success with these models often requires domain-specific data for fine-tuning,
which can be costly and inefficient. Thus, using synthetic data for fine-tuning
is a popular, cost-effective alternative to gathering real-world data. This
work investigates the impact of synthetic data on the performance of object
detection models, compared to models trained on real-world data only,
specifically within the domain of warehouse logistics. To this end, we examined
the impact of synthetic data generated using the NVIDIA Omniverse Replicator
tool on the effectiveness of object detection models in real-world scenarios.
It comprises experiments focused on pallet detection in a warehouse setting,
utilizing both real and various synthetic dataset generation strategies. Our
findings provide valuable insights into the practical applications of synthetic
image data in computer vision, suggesting that a balanced integration of
synthetic and real data can lead to robust and efficient object detection
models.

</details>


### [32] [DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images](https://arxiv.org/abs/2510.12219)
*Vu Tram Anh Khuong,Luu Tu Nguyen,Thi Bich Phuong Man,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: DIANet是一个创新的双流框架，通过分离和处理微表情的 onset-to-apex 和 apex-to-offset 两个时间阶段，并利用交叉注意力融合机制，提高了微表情识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 微表情识别（MER）因其细微和短暂的特性以及标注数据的稀缺性而充满挑战。现有的基于动态图像（DI）的方法未能充分利用不同时间阶段的特征。

Method: 提出了一种名为DIANet的双流框架，该框架生成两个阶段感知的动态图像（分别编码onset-to-apex和apex-to-offset阶段），并分别用卷积神经网络处理。然后，使用交叉注意力融合模块来整合两个流的特征。

Result: 在CASME-II、SAMM和MMEW三个基准数据集上进行了广泛的实验，结果表明DIANet consistently优于传统的单阶段DI方法。

Conclusion: 显式地建模时间阶段信息对于提高微表情识别至关重要，DIANet提供了一个有前景的研究方向。

Abstract: Micro-expressions are brief, involuntary facial movements that typically last
less than half a second and often reveal genuine emotions. Accurately
recognizing these subtle expressions is critical for applications in
psychology, security, and behavioral analysis. However, micro-expression
recognition (MER) remains a challenging task due to the subtle and transient
nature of facial cues and the limited availability of annotated data. While
dynamic image (DI) representations have been introduced to summarize temporal
motion into a single frame, conventional DI-based methods often overlook the
distinct characteristics of different temporal phases within a
micro-expression. To address this issue, this paper proposes a novel
dual-stream framework, DIANet, which leverages phase-aware dynamic images - one
encoding the onset-to-apex phase and the other capturing the apex-to-offset
phase. Each stream is processed by a dedicated convolutional neural network,
and a cross-attention fusion module is employed to adaptively integrate
features from both streams based on their contextual relevance. Extensive
experiments conducted on three benchmark MER datasets (CASME-II, SAMM, and
MMEW) demonstrate that the proposed method consistently outperforms
conventional single-phase DI-based approaches. The results highlight the
importance of modeling temporal phase information explicitly and suggest a
promising direction for advancing MER.

</details>


### [33] [CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving](https://arxiv.org/abs/2510.12560)
*Xiaoji Zheng,Ziyuan Yang,Yanhao Chen,Yuhang Peng,Yuanrong Tang,Gengyuan Liu,Bokui Chen,Jiangtao Gong*

Main category: cs.CV

TL;DR: CoIRL-AD框架通过引入竞争机制，使模仿学习（IL）和强化学习（RL）的智能体在训练过程中进行交互，从而克服了单独使用IL泛化能力差和单独使用RL样本效率低、收敛不稳定等问题，并在nuScenes数据集上取得了更好的泛化能力和长尾场景表现。


<details>
  <summary>Details</summary>
Motivation: 模仿学习（IL）单独训练的端到端自动驾驶模型泛化能力不足，而强化学习（RL）虽然能通过奖励最大化促进探索，但存在样本效率低和收敛不稳定等问题。因此，结合IL和RL是解决这些挑战的自然思路。

Method: 提出了一种名为CoIRL-AD的竞争性双策略框架，让IL和RL智能体在训练期间进行交互。该框架引入了一种基于竞争的机制，促进知识交换，同时避免梯度冲突。

Result: 在nuScenes数据集上的实验表明，与基线模型相比，CoIRL-AD的碰撞率降低了18%，同时在长尾场景中也表现出更强的泛化能力和更好的性能。

Conclusion: CoIRL-AD框架通过结合IL和RL的优势，并通过引入竞争机制促进它们之间的交互，能够有效地提高自动驾驶模型的泛化能力和在复杂场景下的表现。

Abstract: End-to-end autonomous driving models trained solely with imitation learning
(IL) often suffer from poor generalization. In contrast, reinforcement learning
(RL) promotes exploration through reward maximization but faces challenges such
as sample inefficiency and unstable convergence. A natural solution is to
combine IL and RL. Moving beyond the conventional two-stage paradigm (IL
pretraining followed by RL fine-tuning), we propose CoIRL-AD, a competitive
dual-policy framework that enables IL and RL agents to interact during
training. CoIRL-AD introduces a competition-based mechanism that facilitates
knowledge exchange while preventing gradient conflicts. Experiments on the
nuScenes dataset show an 18% reduction in collision rate compared to baselines,
along with stronger generalization and improved performance on long-tail
scenarios. Code is available at: https://github.com/SEU-zxj/CoIRL-AD.

</details>


### [34] [HoneyBee: Data Recipes for Vision-Language Reasoners](https://arxiv.org/abs/2510.12225)
*Hritik Bansal,Devandra Singh Sachan,Kai-Wei Chang,Aditya Grover,Gargi Ghosh,Wen-tau Yih,Ramakanth Pasunuru*

Main category: cs.CV

TL;DR: 本研究提出了新的视觉-语言推理（VLM）数据集构建方法，并创建了一个名为HoneyBee的大规模数据集，显著提升了VLM的推理能力，同时还提出了一种降低解码成本的测试时间扩展策略。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）在推理任务上表现出色，但构建高性能VLM推理训练数据集的原理尚不明确。

Method: 研究了多种数据整理方法，通过严格控制训练和评估设置来分析它们对VLM推理能力的影响，包括分析上下文（图像和问题对）来源的影响，实施针对性的数据干预措施，并探索图像、问题和思维链（CoT）解决方案的扩展。基于研究结果，创建了一个名为HoneyBee的大规模、高质量的CoT推理数据集。

Result: 研究发现：（a）上下文来源策略显著影响VLM性能；（b）图像标题的辅助信号和纯文本推理的引入能带来显著的性能提升；（c）扩展所有数据维度（如每个图像的独特问题和每个图像-问题对的独特CoT）可持续提高推理能力。HoneyBee数据集训练出的VLM在MathVerse等基准测试中超越了现有模型。此外，还提出了一种测试时间扩展策略，可在不牺牲准确性的情况下将解码成本降低73%。

Conclusion: 该研究提出了改进的VLM推理数据集构建策略，并创建了HoneyBee数据集，显著提升了VLM性能，并提出了一种有效的测试时间扩展策略。

Abstract: Recent advances in vision-language models (VLMs) have made them highly
effective at reasoning tasks. However, the principles underlying the
construction of performant VL reasoning training datasets remain poorly
understood. In this work, we introduce several data curation approaches and
study their impacts on VL reasoning capabilities by carefully controlling
training and evaluation setups. We analyze the effects of context (image and
question pair) sources, implement targeted data interventions, and explore
scaling up images, questions, and chain-of-thought (CoT) solutions. Our
findings reveal that (a) context source strategies significantly affect VLM
performance, (b) interventions such as auxiliary signals from image captions
and the inclusion of text-only reasoning yield substantial gains, and (c)
scaling all data dimensions (e.g., unique questions per image and unique CoTs
per image-question pair) consistently improves reasoning capability. Motivated
by these insights, we introduce HoneyBee, a large-scale, high-quality CoT
reasoning dataset with 2.5M examples consisting 350K image-question pairs. VLMs
trained with HoneyBee outperform state-of-the-art models across model sizes.
For instance, a HoneyBee-trained VLM with 3B parameters outperforms the SOTA
model and the base model by 7.8% and 24.8%, respectively, on MathVerse.
Furthermore, we propose a test-time scaling strategy that reduces decoding cost
by 73% without sacrificing accuracy. Overall, this work presents improved
strategies for VL reasoning dataset curation research.

</details>


### [35] [EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels](https://arxiv.org/abs/2510.12687)
*Kunyu Peng,Di Wen,Kailun Yang,Jia Fu,Yufan Chen,Ruiping Liu,Jiamin Wu,Junwei Zheng,M. Saquib Sarfraz,Luc Van Gool,Danda Pani Paudel,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为EReLiFM的开放集域泛化（OSDG）新方法，用于处理带标签噪声（OSDG-NL）的数据集。EReLiFM通过两阶段证据损失聚类来提高标签的可靠性，并引入残差流匹配机制来学习结构化的域和类别条件残差，从而实现比基于插值的增强更具多样性和不确定性感知的迁移路径。该模型在元学习过程中，通过最大化在干净数据集上的损失减少来优化更新方向，并使用最自信预测类别生成的伪标签进行监督。实验证明，EReLiFM在OSDG-NL任务上优于现有方法，达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开放集域泛化（OSDG）方法在处理带标签噪声（OSDG-NL）时，尽管采用了超立方体原型引导的元学习，但在弥合域间隙方面仍存在不足，尤其是在标记数据有限的情况下。

Method: EReLiFM结合了无监督两阶段证据损失聚类方法以提高标签的可靠性意识，并提出了一种残差流匹配机制，该机制可以模拟结构化的域和类别条件残差，从而实现超越插值增强的、多样化且具有不确定性感知能力的迁移路径。在元学习过程中，模型通过最大化在干净数据集上的损失下降来优化更新方向，并利用最自信预测类别的伪标签进行监督。

Result: EReLiFM在OSDG-NL任务上取得了最先进的性能，超越了现有方法。

Conclusion: EReLiFM通过引入标签可靠性意识和结构化的残差流匹配机制，有效解决了带标签噪声的开放集域泛化问题，并在实验中证明了其优越性。

Abstract: Open-Set Domain Generalization (OSDG) aims to enable deep learning models to
recognize unseen categories in new domains, which is crucial for real-world
applications. Label noise hinders open-set domain generalization by corrupting
source-domain knowledge, making it harder to recognize known classes and reject
unseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL)
using hyperbolic prototype-guided meta-learning, they struggle to bridge domain
gaps, especially with limited clean labeled data. In this paper, we propose
Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first
introduce an unsupervised two-stage evidential loss clustering method to
promote label reliability awareness. Then, we propose a residual flow matching
mechanism that models structured domain- and category-conditioned residuals,
enabling diverse and uncertainty-aware transfer paths beyond
interpolation-based augmentation. During this meta-learning process, the model
is optimized such that the update direction on the clean set maximizes the loss
decrease on the noisy set, using pseudo labels derived from the most confident
predicted class for supervision. Experimental results show that EReLiFM
outperforms existing methods on OSDG-NL, achieving state-of-the-art
performance. The source code is available at
https://github.com/KPeng9510/ERELIFM.

</details>


### [36] [BIGFix: Bidirectional Image Generation with Token Fixing](https://arxiv.org/abs/2510.12231)
*Victor Besnier,David Hurych,Andrei Bursuc,Eduardo Valle*

Main category: cs.CV

TL;DR: 通过引入一种新的自修正训练方案，该方法通过迭代地优化采样标记来提高图像和视频生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 提高图像和视频生成模型的推理效率，解决并行多标记预测的结构不一致问题。

Method: 提出一种自修正方法，通过注入随机标记的训练方案来迭代地优化采样标记，从而在采样过程中进行修正。

Result: 在ImageNet-256、CIFAR-10、UCF-101和NuScenes数据集上，图像和视频生成质量均得到显著提升，同时保留了并行标记预测的效率。

Conclusion: 所提出的自修正方法能在提高生成效率的同时，显著提升图像和视频的生成质量，解决了并行多标记预测中存在的结构不一致问题。

Abstract: Recent advances in image and video generation have raised significant
interest from both academia and industry. A key challenge in this field is
improving inference efficiency, as model size and the number of inference steps
directly impact the commercial viability of generative models while also posing
fundamental scientific challenges. A promising direction involves combining
auto-regressive sequential token modeling with multi-token prediction per step,
reducing inference time by up to an order of magnitude. However, predicting
multiple tokens in parallel can introduce structural inconsistencies due to
token incompatibilities, as capturing complex joint dependencies during
training remains challenging. Traditionally, once tokens are sampled, there is
no mechanism to backtrack and refine erroneous predictions. We propose a method
for self-correcting image generation by iteratively refining sampled tokens. We
achieve this with a novel training scheme that injects random tokens in the
context, improving robustness and enabling token fixing during sampling. Our
method preserves the efficiency benefits of parallel token prediction while
significantly enhancing generation quality. We evaluate our approach on image
generation using the ImageNet-256 and CIFAR-10 datasets, as well as on video
generation with UCF-101 and NuScenes, demonstrating substantial improvements
across both modalities.

</details>


### [37] [Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection](https://arxiv.org/abs/2510.12241)
*Yuehui Li,Yahao Lu,Haoyuan Wu,Sen Zhang,Liang Lin,Yukai Shi*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Ivan-ISTD的红外小目标检测框架，通过小波引导的跨域合成和真实域噪声不变性学习来解决跨域迁移和异方差噪声问题，并创建了Dynamic-ISTD Benchmark数据集。


<details>
  <summary>Details</summary>
Motivation: 解决红外小目标检测（ISTD）中存在的跨域迁移和异方差噪声扰动两大挑战。

Method: 1. 小波引导跨域合成：利用多频小波滤波分离目标背景，生成与目标域对齐的训练样本。2. 真实域噪声不变性学习：提取目标域的真实噪声特征，构建动态噪声库，并通过自监督损失学习噪声不变性，克服传统人工噪声建模的分布偏差。3. 构建Dynamic-ISTD Benchmark数据集：一个跨域动态退化数据集。

Result: 提出的Ivan-ISTD方法在多个量化指标上优于现有最先进方法，尤其在跨域场景下表现出出色的鲁棒性。

Conclusion: Ivan-ISTD框架有效解决了红外小目标检测中的跨域迁移和异方差噪声问题，并在真实场景中展现出优越性能和鲁棒性。

Abstract: In the multimedia domain, Infrared Small Target Detection (ISTD) plays a
important role in drone-based multi-modality sensing. To address the dual
challenges of cross-domain shift and heteroscedastic noise perturbations in
ISTD, we propose a doubly wavelet-guided Invariance learning
framework(Ivan-ISTD). In the first stage, we generate training samples aligned
with the target domain using Wavelet-guided Cross-domain Synthesis. This
wavelet-guided alignment machine accurately separates the target background
through multi-frequency wavelet filtering. In the second stage, we introduce
Real-domain Noise Invariance Learning, which extracts real noise
characteristics from the target domain to build a dynamic noise library. The
model learns noise invariance through self-supervised loss, thereby overcoming
the limitations of distribution bias in traditional artificial noise modeling.
Finally, we create the Dynamic-ISTD Benchmark, a cross-domain dynamic
degradation dataset that simulates the distribution shifts encountered in
real-world applications. Additionally, we validate the versatility of our
method using other real-world datasets. Experimental results demonstrate that
our approach outperforms existing state-of-the-art methods in terms of many
quantitative metrics. In particular, Ivan-ISTD demonstrates excellent
robustness in cross-domain scenarios. The code for this work can be found at:
https://github.com/nanjin1/Ivan-ISTD.

</details>


### [38] [Vectorized Video Representation with Easy Editing via Hierarchical Spatio-Temporally Consistent Proxy Embedding](https://arxiv.org/abs/2510.12256)
*Ye Chen,Liming Tan,Yupeng Zhu,Yuanbin Wang,Bingbing Ni*

Main category: cs.CV

TL;DR: 该论文提出使用时空一致的代理节点来表示视频中的动态对象/场景，以克服现有视频表示方法依赖于不稳定的像素级匹配和跟踪的缺点。


<details>
  <summary>Details</summary>
Motivation: 现有视频表示方法严重依赖于不稳定的像素级匹配和跟踪来建模运动和外观，这容易受到跟踪错误、遮挡和剧烈运动的影响，导致表示不稳定。

Method: 提出使用时空一致的代理节点来表示视频中的动态对象/场景。这些代理节点具有层次结构，能够稳定地表达物体多尺度结构，不受累积跟踪误差、长期运动、遮挡和视角变化的影响。同时，动态更新机制能够利用时空先验来减轻跟踪器不准确的影响。此外，形状和纹理表示的分离编码有助于实现可控的细粒度外观编辑。

Result: 该方法在参数更少的情况下实现了高视频重建精度，并支持视频修复和基于关键帧的视频编辑等复杂视频处理任务。

Conclusion: 所提出的代理节点表示方法比现有方法更稳定、更有效，能够处理各种视频中的挑战性场景，并提供强大的视频编辑功能。

Abstract: Current video representations heavily rely on unstable and over-grained
priors for motion and appearance modelling, \emph{i.e.}, pixel-level matching
and tracking. A tracking error of just a few pixels would lead to the collapse
of the visual object representation, not to mention occlusions and large motion
frequently occurring in videos. To overcome the above mentioned vulnerability,
this work proposes spatio-temporally consistent proxy nodes to represent
dynamically changing objects/scenes in the video. On the one hand, the
hierarchical proxy nodes have the ability to stably express the multi-scale
structure of visual objects, so they are not affected by accumulated tracking
error, long-term motion, occlusion, and viewpoint variation. On the other hand,
the dynamic representation update mechanism of the proxy nodes adequately
leverages spatio-temporal priors of the video to mitigate the impact of
inaccurate trackers, thereby effectively handling drastic changes in scenes and
objects. Additionally, the decoupled encoding manner of the shape and texture
representations across different visual objects in the video facilitates
controllable and fine-grained appearance editing capability. Extensive
experiments demonstrate that the proposed representation achieves high video
reconstruction accuracy with fewer parameters and supports complex video
processing tasks, including video in-painting and keyframe-based temporally
consistent video editing.

</details>


### [39] [Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images](https://arxiv.org/abs/2510.12258)
*Yuto Yokoi,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: 我们提出了两种新的损失函数：乘法损失和置信度自适应乘法损失，用于医学和细胞图像的语义分割。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、伦理和昂贵的标注，医学图像存在数据稀缺的问题，因此需要鲁棒且高效的训练目标。现有的交叉熵损失和 Dice 损失的加性组合对超参数敏感，并且在数据有限的情况下表现不佳。

Method: 我们提出了乘法损失，它将交叉熵损失和 Dice 损失相乘，根据预测置信度动态调整梯度。在此基础上，置信度自适应乘法损失通过受 Focal Loss 启发的置信度驱动的指数缩放，整合了预测概率和 Dice 系数，以强调难样本。

Result: 在细胞和医学分割基准上的实验表明，我们的框架在性能上始终优于经过调整的加性损失和其他现有损失函数。

Conclusion: 我们提出的乘法损失和置信度自适应乘法损失为在数据限制条件下进行鲁棒分割提供了一种简单、有效且无需超参数的机制。

Abstract: We propose two novel loss functions, Multiplicative Loss and
Confidence-Adaptive Multiplicative Loss, for semantic segmentation in medical
and cellular images. Although Cross Entropy and Dice Loss are widely used,
their additive combination is sensitive to hyperparameters and often performs
suboptimally, especially with limited data. Medical images suffer from data
scarcity due to privacy, ethics, and costly annotations, requiring robust and
efficient training objectives. Our Multiplicative Loss combines Cross Entropy
and Dice losses multiplicatively, dynamically modulating gradients based on
prediction confidence. This reduces penalties for confident correct predictions
and amplifies gradients for incorrect overconfident ones, stabilizing
optimization. Building on this, Confidence-Adaptive Multiplicative Loss applies
a confidence-driven exponential scaling inspired by Focal Loss, integrating
predicted probabilities and Dice coefficients to emphasize difficult samples.
This enhances learning under extreme data scarcity by strengthening gradients
when confidence is low. Experiments on cellular and medical segmentation
benchmarks show our framework consistently outperforms tuned additive and
existing loss functions, offering a simple, effective, and hyperparameter-free
mechanism for robust segmentation under challenging data limitations.

</details>


### [40] [Local Background Features Matter in Out-of-Distribution Detection](https://arxiv.org/abs/2510.12259)
*Jinlun Ye,Zhuohao Sun,Yiqiao Qiu,Qiu Li,Zhijun Tan,Ruixuan Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的、有效的 OOD 检测方法，该方法利用局部背景特征作为假的 OOD 特征进行模型训练，以解决模型在 OOD 数据上预测过于自信的问题。通过优化以减小这些背景特征的 L2 范数，模型可以减轻 OOD 数据的过度自信问题。实验证明该方法有效，并能与现有后验方法结合，达到了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在现实世界中的应用需要 OOD 检测来确保可靠性和安全性，但现有的 OOD 检测方法面临模型在 OOD 数据上预测过于自信的挑战，并且一些利用辅助 OOD 数据集或生成虚假 OOD 图像的方法成本高昂。

Method: 利用 ID 图像中的局部背景特征作为模拟的 OOD 视觉表示进行模型训练。具体做法是提取 ID 图像的背景特征，并通过优化模型使这些背景特征的 L2 范数最小化。

Result: 在多个标准的 OOD 检测基准测试中，该方法表现出有效性，并且可以与现有的后验方法结合使用，取得了新的最先进性能。

Conclusion: 所提出的利用局部背景特征作为假 OOD 特征的方法，能够有效解决 OOD 检测中的过度自信问题，并取得优于现有方法的性能，同时具有良好的兼容性。

Abstract: Out-of-distribution (OOD) detection is crucial when deploying deep neural
networks in the real world to ensure the reliability and safety of their
applications. One main challenge in OOD detection is that neural network models
often produce overconfident predictions on OOD data. While some methods using
auxiliary OOD datasets or generating fake OOD images have shown promising OOD
detection performance, they are limited by the high costs of data collection
and training. In this study, we propose a novel and effective OOD detection
method that utilizes local background features as fake OOD features for model
training. Inspired by the observation that OOD images generally share similar
background regions with ID images, the background features are extracted from
ID images as simulated OOD visual representations during training based on the
local invariance of convolution. Through being optimized to reduce the
$L_2$-norm of these background features, the neural networks are able to
alleviate the overconfidence issue on OOD data. Extensive experiments on
multiple standard OOD detection benchmarks confirm the effectiveness of our
method and its wide combinatorial compatibility with existing post-hoc methods,
with new state-of-the-art performance achieved from our method.

</details>


### [41] [AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion](https://arxiv.org/abs/2510.12260)
*Xiaopeng Liu,Yupei Lin,Sen Zhang,Xiao Wang,Yukai Shi,Liang Lin*

Main category: cs.CV

TL;DR: 本论文提出了一种名为AngularFuse的可见光-红外图像融合新方法，通过设计交叉模态互补掩码模块、精细化参考图像合成策略和角度感知损失函数，有效解决了现有无监督方法在细节和亮度均衡方面的不足，并能同时约束梯度幅度和方向，生成细节更丰富、纹理更清晰、边缘方向更准确的融合图像，在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 可见光-红外图像融合在自动驾驶和夜间监视等领域至关重要，但现有无监督深度学习方法在依赖手动设计的损失函数方面存在局限性，这些损失函数在参考图像的细节和亮度均衡方面存在不足，并且仅关注梯度幅度，未能充分利用梯度信息。

Method: 1.设计了一个交叉模态互补掩码模块，强制网络学习模态间的互补信息。2.提出了一种精细化的参考图像合成策略，结合拉普拉斯边缘增强和自适应直方图均衡化，生成细节更丰富、亮度更均衡的参考图像。3.引入了一种角度感知损失，首次在梯度域同时约束梯度幅度和方向，确保融合图像同时保留纹理强度和正确的边缘方向。

Result: 在MSRS、RoadScene和M3FD公开数据集上的综合实验表明，AngularFuse的性能明显优于现有的主流方法。视觉比较证实，该方法在挑战性场景下能产生更清晰、更细致的结果，展示了其卓越的融合能力。

Conclusion: AngularFuse通过引入角度感知框架，解决了现有可见光-红外图像融合方法的局限性，生成了高质量的融合图像，在多个数据集上取得了领先的性能。

Abstract: Visible-infrared image fusion is crucial in key applications such as
autonomous driving and nighttime surveillance. Its main goal is to integrate
multimodal information to produce enhanced images that are better suited for
downstream tasks. Although deep learning based fusion methods have made
significant progress, mainstream unsupervised approaches still face serious
challenges in practical applications. Existing methods mostly rely on manually
designed loss functions to guide the fusion process. However, these loss
functions have obvious limitations. On one hand, the reference images
constructed by existing methods often lack details and have uneven brightness.
On the other hand, the widely used gradient losses focus only on gradient
magnitude. To address these challenges, this paper proposes an angle-based
perception framework for spatial-sensitive image fusion (AngularFuse). At
first, we design a cross-modal complementary mask module to force the network
to learn complementary information between modalities. Then, a fine-grained
reference image synthesis strategy is introduced. By combining Laplacian edge
enhancement with adaptive histogram equalization, reference images with richer
details and more balanced brightness are generated. Last but not least, we
introduce an angle-aware loss, which for the first time constrains both
gradient magnitude and direction simultaneously in the gradient domain.
AngularFuse ensures that the fused images preserve both texture intensity and
correct edge orientation. Comprehensive experiments on the MSRS, RoadScene, and
M3FD public datasets show that AngularFuse outperforms existing mainstream
methods with clear margin. Visual comparisons further confirm that our method
produces sharper and more detailed results in challenging scenes, demonstrating
superior fusion capability.

</details>


### [42] [SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis](https://arxiv.org/abs/2510.12267)
*Chenghanyu Zhang,Zekun Li,Peipei Li,Xing Cui,Shuhan Xia,Weixiang Yan,Yiqiao Zhang,Qianyu Zhuang*

Main category: cs.CV

TL;DR: SpineBench是一个针对脊柱领域的视觉问答基准，旨在评估多模态大语言模型（MLLMs）在脊柱疾病诊断和病灶定位方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有医学基准未能充分评估MLLMs在脊柱等依赖视觉输入的精细化医学领域的性能，因此需要SpineBench来填补这一空白。

Method: SpineBench整合并标准化了开源脊柱疾病数据集的图像-标签对，构建了包含64,878个问答对的数据集，涵盖11种脊柱疾病，并加入了基于视觉相似性的难负例选项。

Result: 评估结果显示，12种主流MLLMs在脊柱任务上的表现不佳，暴露了当前MLLMs在脊柱领域的局限性。

Conclusion: SpineBench的评估结果凸显了当前MLLMs在脊柱医学应用的不足，并为未来的模型改进提供了方向。

Abstract: With the increasing integration of Multimodal Large Language Models (MLLMs)
into the medical field, comprehensive evaluation of their performance in
various medical domains becomes critical. However, existing benchmarks
primarily assess general medical tasks, inadequately capturing performance in
nuanced areas like the spine, which relies heavily on visual input. To address
this, we introduce SpineBench, a comprehensive Visual Question Answering (VQA)
benchmark designed for fine-grained analysis and evaluation of MLLMs in the
spinal domain. SpineBench comprises 64,878 QA pairs from 40,263 spine images,
covering 11 spinal diseases through two critical clinical tasks: spinal disease
diagnosis and spinal lesion localization, both in multiple-choice format.
SpineBench is built by integrating and standardizing image-label pairs from
open-source spinal disease datasets, and samples challenging hard negative
options for each VQA pair based on visual similarity (similar but not the same
disease), simulating real-world challenging scenarios. We evaluate 12 leading
MLLMs on SpineBench. The results reveal that these models exhibit poor
performance in spinal tasks, highlighting limitations of current MLLM in the
spine domain and guiding future improvements in spinal medicine applications.
SpineBench is publicly available at
https://zhangchenghanyu.github.io/SpineBench.github.io/.

</details>


### [43] [PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes](https://arxiv.org/abs/2510.12282)
*Ying A,Wenzhang Sun,Chang Zeng,Chunfeng Wang,Hao Li,Jianxun Cui*

Main category: cs.CV

TL;DR: PAGS是一个创新的3D重建框架，通过引入语义优先级来解决自动驾驶中3D场景重建的效率和保真度问题，能在保证关键物体细节的同时，显著提高训练和渲染速度。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重建方法在保真度和计算成本之间存在权衡，原因是它们忽略了场景元素的语义重要性，将计算资源平均分配给静态背景和关键物体。

Method: PAGS框架通过（1）语义引导的剪枝和正则化策略，利用混合重要性指标简化非关键场景元素，保留导航所需的重要物体细节；（2）优先级驱动的渲染管线，通过基于优先级的深度预处理来剔除遮挡的原语，加速最终着色计算。

Result: 在Waymo和KITTI数据集上的大量实验表明，PAGS在重建质量上表现出色，尤其是在安全关键物体上，同时显著减少了训练时间，并将渲染速度提升至350 FPS以上。

Conclusion: PAGS通过注入任务感知的语义优先级，在3D重建和渲染流程中，实现了对动态3D城市场景的高保真度和高计算效率的重建，解决了现有方法的局限性。

Abstract: Reconstructing dynamic 3D urban scenes is crucial for autonomous driving, yet
current methods face a stark trade-off between fidelity and computational cost.
This inefficiency stems from their semantically agnostic design, which
allocates resources uniformly, treating static backgrounds and safety-critical
objects with equal importance. To address this, we introduce Priority-Adaptive
Gaussian Splatting (PAGS), a framework that injects task-aware semantic
priorities directly into the 3D reconstruction and rendering pipeline. PAGS
introduces two core contributions: (1) Semantically-Guided Pruning and
Regularization strategy, which employs a hybrid importance metric to
aggressively simplify non-critical scene elements while preserving fine-grained
details on objects vital for navigation. (2) Priority-Driven Rendering
pipeline, which employs a priority-based depth pre-pass to aggressively cull
occluded primitives and accelerate the final shading computations. Extensive
experiments on the Waymo and KITTI datasets demonstrate that PAGS achieves
exceptional reconstruction quality, particularly on safety-critical objects,
while significantly reducing training time and boosting rendering speeds to
over 350 FPS.

</details>


### [44] [Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval](https://arxiv.org/abs/2510.12283)
*Jianfeng Dong,Lei Huang,Daizong Liu,Xianke Chen,Xun Yang,Changting Lin,Xun Wang,Meng Wang*

Main category: cs.CV

TL;DR: 本论文提出了一种新的框架，用于解决不完整相关视频检索（PRVR）的实际挑战，该挑战涉及从长时长、背景内容复杂的未修剪视频中检索部分相关的视频。


<details>
  <summary>Details</summary>
Motivation: 以往的文本到视频检索方法通常假设视频经过预先剪辑且内容单一，但这在实际应用中并不常见。因此，本研究聚焦于更具挑战性但更实用的不完整相关视频检索（PRVR）任务，旨在从非预先剪辑的视频中检索出部分相关的视频片段。

Method: 提出了一种名为 DL-DKD++ 的新框架，该框架采用双重学习和动态知识蒸馏的方法。它利用一个大型教师模型（预训练的视觉-语言模型）来指导一个轻量级的、任务特定的双分支学生网络。学生网络包含一个继承分支，用于吸收教师模型的知识，以及一个探索分支，用于学习 PRVR 数据集中的特定任务信息，以弥合领域差距。此外，还引入了动态软目标构建机制，用自适应的软目标替代硬目标，以更好地捕捉视频和查询之间细粒度的、部分相关性。

Result: 实验结果表明，所提出的 DL-DKD++ 模型在 TVR、ActivityNet 和 Charades-STA 数据集上的 PRVR 任务上取得了最先进的性能。

Conclusion: 本研究提出的 DL-DKD++ 框架通过知识蒸馏和动态软目标策略，有效地解决了不完整相关视频检索的挑战，并在多个标准数据集上取得了优异的性能。

Abstract: Almost all previous text-to-video retrieval works ideally assume that videos
are pre-trimmed with short durations containing solely text-related content.
However, in practice, videos are typically untrimmed in long durations with
much more complicated background content. Therefore, in this paper, we focus on
the more practical yet challenging task of Partially Relevant Video Retrieval
(PRVR), which aims to retrieve partially relevant untrimmed videos with the
given query. To tackle this task, we propose a novel framework that distills
generalization knowledge from a powerful large-scale vision-language
pre-trained model and transfers it to a lightweight, task-specific PRVR
network. Specifically, we introduce a Dual Learning framework with Dynamic
Knowledge Distillation (DL-DKD++), where a large teacher model provides
supervision to a compact dual-branch student network. The student model
comprises two branches: an inheritance branch that absorbs transferable
knowledge from the teacher, and an exploration branch that learns task-specific
information from the PRVR dataset to address domain gaps. To further enhance
learning, we incorporate a dynamic soft-target construction mechanism. By
replacing rigid hard-target supervision with adaptive soft targets that evolve
during training, our method enables the model to better capture the
fine-grained, partial relevance between videos and queries. Experiment results
demonstrate that our proposed model achieves state-of-the-art performance on
TVR, ActivityNet, and Charades-STA datasets for PRVR. The code is available at
https://github.com/HuiGuanLab/DL-DKD.

</details>


### [45] [Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector](https://arxiv.org/abs/2510.12287)
*Sifan Li,Hongkai Chen,Yujun Cai,Qingwen Ye,Liyang Chen,Junsong Yuan,Yiwei Wang*

Main category: cs.CV

TL;DR: Vision Language Models (VLMs) 容易产生幻觉，即生成的文本与视觉信息不符，尤其是在处理不含文字的标志时。研究发现，模型倾向于依赖符号先验知识而非真实视觉识别，特别是在识别圆形标志时。


<details>
  <summary>Details</summary>
Motivation: 解决 Vision Language Models (VLMs) 在处理视觉信息时出现的幻觉问题，特别是在标志识别方面，并探究其根本原因。

Method: 使用包含纯符号、混合符号和文本标志的数据集，并结合 Hard-60 子集，系统地评估了多种主流 VLM 在标志幻觉方面的表现。通过九种结构化扰动测试模型的鲁棒性，并对 LLaVA 模型进行嵌入层分析，找出导致幻觉的关键因素。

Result: 研究表明，VLM 在识别标志时存在严重的幻觉问题，即使在有扰动的情况下也无法避免。特别地，遮挡会暴露模型最明显的弱点。嵌入层分析显示，幻觉与投影器中的一小部分维度相关，通过有针对性地去除这些维度可以显著减少错误，同时保持 OCR 准确性。

Conclusion: VLM 在识别标志时，往往依赖于符号先验知识而非真实的视觉感知，尤其是对于标志性的圆形标志。投影器子空间在这一失败模式中起着决定性作用。未来的研究应着重于投影器解耦和 OCR 引导解码，以构建更值得信赖的多模态系统。

Abstract: Vision Language Models (VLMs) have achieved impressive progress in multimodal
reasoning; yet, they remain vulnerable to hallucinations, where outputs are not
grounded in visual evidence. In this paper, we investigate a previously
overlooked setting: logo hallucination, where models generate brand names or
textual content despite logos containing no visible words. Using curated splits
of pure symbols, hybrids, and text-bearing logos, as well as the challenging
Hard-60 subset, we systematically measure hallucination across leading VLMs. We
further probe robustness through nine structured perturbations and show that
hallucinations persist even under strong distortions, with occlusion exposing
the sharpest weaknesses. Embedding-level analysis with open-weight LLaVA
demonstrates that hallucination is tied to a small subset of projector
dimensions, and targeted ablation substantially reduces errors while preserving
OCR accuracy. Together, these findings reveal that VLMs often rely on symbolic
priors rather than genuine glyph perception, particularly for iconic circular
logos, and that projector subspaces play a decisive role in this failure mode.
Our work contributes both a novel diagnostic lens and actionable mitigation
insights, highlighting projector disentanglement and OCR-guided decoding as
promising directions for building more trustworthy multimodal systems.

</details>


### [46] [Hybrid Gaussian Splatting for Novel Urban View Synthesis](https://arxiv.org/abs/2510.12308)
*Mohamed Omran,Farhad Zanjani,Davide Abati,Jens Petersen,Amirhossein Habibian*

Main category: cs.CV

TL;DR: Qualcomm AI Research 提出了一种结合高斯泼溅和扩散模型的混合方法，用于街景新视角合成，在 RealADSim-NVS 挑战赛中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 解决街景新视角合成的挑战，从单一视角的训练帧生成不同视角（如不同车道或方向）的城市环境渲染。 

Method: 该方法分为两个阶段：1. 使用高斯泼溅拟合场景的三维重建并渲染新视角；2. 使用单步扩散模型增强渲染帧。

Result: 在公开排行榜上，该模型达到了 0.432 的总分，在比赛中获得第二名。通过消融实验评估了各组件对 PSNR、SSIM 和 LPIPS 指标的影响。

Conclusion: 该混合方法在街景新视角合成任务中表现出色，证明了高斯泼溅和扩散模型结合的有效性。

Abstract: This paper describes the Qualcomm AI Research solution to the RealADSim-NVS
challenge, hosted at the RealADSim Workshop at ICCV 2025. The challenge
concerns novel view synthesis in street scenes, and participants are required
to generate, starting from car-centric frames captured during some training
traversals, renders of the same urban environment as viewed from a different
traversal (e.g. different street lane or car direction). Our solution is
inspired by hybrid methods in scene generation and generative simulators
merging gaussian splatting and diffusion models, and it is composed of two
stages: First, we fit a 3D reconstruction of the scene and render novel views
as seen from the target cameras. Then, we enhance the resulting frames with a
dedicated single-step diffusion model. We discuss specific choices made in the
initialization of gaussian primitives as well as the finetuning of the enhancer
model and its training data curation. We report the performance of our model
design and we ablate its components in terms of novel view quality as measured
by PSNR, SSIM and LPIPS. On the public leaderboard reporting test results, our
proposal reaches an aggregated score of 0.432, achieving the second place
overall.

</details>


### [47] [CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion](https://arxiv.org/abs/2510.12362)
*Jinzhou Lin,Jie Zhou,Wenhao Xu,Rongtao Xu,Changwei Wang,Shunpeng Chen,Kexue Fu,Yihua Shao,Li Guo,Shibiao Xu*

Main category: cs.CV

TL;DR: CurriFlow是一个新的语义占用预测框架，利用基于光流的时间对齐和课程引导的深度融合来完成单目图像的3D语义场景补全。


<details>
  <summary>Details</summary>
Motivation: 现有的SSC方法在显式运动推理、遮挡处理和噪声深度监督方面存在不足。

Method: CurriFlow使用多层次融合策略，通过预训练的光流对齐跨帧分割、视觉和深度特征。它还采用课程学习机制，从LiDAR深度平稳过渡到立体深度，并利用SAM模型提供类别不可知的语义监督。

Result: 在SemanticKITTI基准测试中，CurriFlow达到了16.9的平均IoU，取得了最先进的性能。

Conclusion: CurriFlow的运动引导和课程感知设计对于基于相机的3D语义场景补全非常有效。

Abstract: Semantic Scene Completion (SSC) aims to infer complete 3D geometry and
semantics from monocular images, serving as a crucial capability for
camera-based perception in autonomous driving. However, existing SSC methods
relying on temporal stacking or depth projection often lack explicit motion
reasoning and struggle with occlusions and noisy depth supervision. We propose
CurriFlow, a novel semantic occupancy prediction framework that integrates
optical flow-based temporal alignment with curriculum-guided depth fusion.
CurriFlow employs a multi-level fusion strategy to align segmentation, visual,
and depth features across frames using pre-trained optical flow, thereby
improving temporal consistency and dynamic object understanding. To enhance
geometric robustness, a curriculum learning mechanism progressively transitions
from sparse yet accurate LiDAR depth to dense but noisy stereo depth during
training, ensuring stable optimization and seamless adaptation to real-world
deployment. Furthermore, semantic priors from the Segment Anything Model (SAM)
provide category-agnostic supervision, strengthening voxel-level semantic
learning and spatial consistency. Experiments on the SemanticKITTI benchmark
demonstrate that CurriFlow achieves state-of-the-art performance with a mean
IoU of 16.9, validating the effectiveness of our motion-guided and
curriculum-aware design for camera-based 3D semantic scene completion.

</details>


### [48] [Deep Attention-guided Adaptive Subsampling](https://arxiv.org/abs/2510.12376)
*Sharath M Shankaranarayana,Soumava Kumar Roy,Prasad Sudhakar,Chandan Aladahalli*

Main category: cs.CV

TL;DR: 通过引入可学习的子采样框架，解决深度神经网络在处理3D体积或视频分类任务时计算复杂度高的问题，该框架能够根据输入动态调整采样策略，从而提高性能并降低复杂性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在提高性能的同时，计算复杂度也随之增加。在3D体积或视频分类等任务中，由于存在冗余，并非所有切片或帧都是必需的。现有方法（如Gumbel-max trick）虽然解决了不可导数问题，但采样机制是静态的，无法适应不同输入。

Method: 提出一个新颖的可学习子采样框架，并将其集成到任何神经网络架构中。该框架包含一个注意力引导的采样模块，能够根据输入动态调整采样策略，即使在推理过程中也能实现自适应。

Result: 在MedMNIST3D数据集和两个超声视频数据集（包括一个真实临床数据集）上进行了实验，证明了该方法在3D医学成像和视频分类任务上的有效性。

Conclusion: 提出的注意力引导的子采样框架能够根据输入动态调整采样，显著提高了深度神经网络在处理3D体积和视频数据时的性能，同时降低了计算复杂性，适用于实际应用。

Abstract: Although deep neural networks have provided impressive gains in performance,
these improvements often come at the cost of increased computational complexity
and expense. In many cases, such as 3D volume or video classification tasks,
not all slices or frames are necessary due to inherent redundancies. To address
this issue, we propose a novel learnable subsampling framework that can be
integrated into any neural network architecture. Subsampling, being a
nondifferentiable operation, poses significant challenges for direct adaptation
into deep learning models. While some works, have proposed solutions using the
Gumbel-max trick to overcome the problem of non-differentiability, they fall
short in a crucial aspect: they are only task-adaptive and not inputadaptive.
Once the sampling mechanism is learned, it remains static and does not adjust
to different inputs, making it unsuitable for real-world applications. To this
end, we propose an attention-guided sampling module that adapts to inputs even
during inference. This dynamic adaptation results in performance gains and
reduces complexity in deep neural network models. We demonstrate the
effectiveness of our method on 3D medical imaging datasets from MedMNIST3D as
well as two ultrasound video datasets for classification tasks, one of them
being a challenging in-house dataset collected under real-world clinical
conditions.

</details>


### [49] [Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling](https://arxiv.org/abs/2510.12385)
*Tim J. Schoonbeek,Shao-Hsuan Hung,Dan Lehman,Hans Onvlee,Jacek Kustra,Peter H. N. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: 本研究提出了一种名为STORM-PSR的双流框架，用于程序步骤识别（PSR），该框架结合了空间和时间特征，以克服现有模型仅依赖于单个视频帧中对象状态检测的局限性，尤其是在物体被部分遮挡的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有PSR模型仅依赖于逐帧的对象状态检测，忽略了时间特征，导致在物体被部分遮挡时模型鲁棒性和准确性受限。

Method: 提出了一种名为STORM-PSR的双流框架，其中一个流用于检测无遮挡物体状态，另一个时空流（包括预训练的空间编码器和基于Transformer的时间编码器）则捕捉时空特征，以在物体部分遮挡的情况下识别步骤完成情况。

Result: 与现有方法相比，STORM-PSR在MECCANO和IndustReal数据集上分别将实际和预测的装配步骤完成之间平均延迟降低了11.2%和26.1%。

Conclusion: 时空流是降低延迟的关键，因为它不依赖于对物体的无遮挡视图来推断已完成的步骤。

Abstract: Procedure step recognition (PSR) aims to identify all correctly completed
steps and their sequential order in videos of procedural tasks. The existing
state-of-the-art models rely solely on detecting assembly object states in
individual video frames. By neglecting temporal features, model robustness and
accuracy are limited, especially when objects are partially occluded. To
overcome these limitations, we propose Spatio-Temporal Occlusion-Resilient
Modeling for Procedure Step Recognition (STORM-PSR), a dual-stream framework
for PSR that leverages both spatial and temporal features. The assembly state
detection stream operates effectively with unobstructed views of the object,
while the spatio-temporal stream captures both spatial and temporal features to
recognize step completions even under partial occlusion. This stream includes a
spatial encoder, pre-trained using a novel weakly supervised approach to
capture meaningful spatial representations, and a transformer-based temporal
encoder that learns how these spatial features relate over time. STORM-PSR is
evaluated on the MECCANO and IndustReal datasets, reducing the average delay
between actual and predicted assembly step completions by 11.2% and 26.1%,
respectively, compared to prior methods. We demonstrate that this reduction in
delay is driven by the spatio-temporal stream, which does not rely on
unobstructed views of the object to infer completed steps. The code for
STORM-PSR, along with the newly annotated MECCANO labels, is made publicly
available at https://timschoonbeek.github.io/stormpsr .

</details>


### [50] [Scene Coordinate Reconstruction Priors](https://arxiv.org/abs/2510.12387)
*Wenjing Bian,Axel Barroso-Laguna,Tommaso Cavallari,Victor Adrian Prisacariu,Eric Brachmann*

Main category: cs.CV

TL;DR: 为场景坐标回归模型引入高层重建先验，以解决其在多视图约束不足时退化的问题，并提升3D重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的场景坐标回归（SCR）模型在训练数据多视图约束不足时会发生退化。本研究旨在提出一种新的SCR模型训练方法，以解决这一问题。

Method: 提出一种概率性重解释SCR模型训练的方法，并引入多种高层重建先验，包括深度值分布先验和场景坐标配置先验（利用3D点云扩散模型）。这些先验在训练过程中引导预测的3D场景点趋向于合理的几何形状。

Result: 在三个室内数据集上，引入先验后，SCR模型能学习到更好的场景表示，生成更一致的场景点云，提高注册率，获得更好的相机姿态，并对下游任务（如新视角合成和相机重定位）产生积极影响。

Conclusion: 通过引入高层重建先验，可以有效提升SCR模型在多视图约束不足情况下的性能，并改进3D重建的质量和下游任务的表现。

Abstract: Scene coordinate regression (SCR) models have proven to be powerful implicit
scene representations for 3D vision, enabling visual relocalization and
structure-from-motion. SCR models are trained specifically for one scene. If
training images imply insufficient multi-view constraints SCR models
degenerate. We present a probabilistic reinterpretation of training SCR models,
which allows us to infuse high-level reconstruction priors. We investigate
multiple such priors, ranging from simple priors over the distribution of
reconstructed depth values to learned priors over plausible scene coordinate
configurations. For the latter, we train a 3D point cloud diffusion model on a
large corpus of indoor scans. Our priors push predicted 3D scene points towards
plausible geometry at each training step to increase their likelihood. On three
indoor datasets our priors help learning better scene representations,
resulting in more coherent scene point clouds, higher registration rates and
better camera poses, with a positive effect on down-stream tasks such as novel
view synthesis and camera relocalization.

</details>


### [51] [Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda](https://arxiv.org/abs/2510.12400)
*André Torneiro,Diogo Monteiro,Paulo Novais,Pedro Rangel Henriques,Nuno F. Rodrigues*

Main category: cs.CV

TL;DR: 本篇综述探讨了视觉-语言模型（VLM）在城市公共基础设施监测中的应用，特别关注零样本学习场景。


<details>
  <summary>Details</summary>
Motivation: 当前城市公共基础设施监测面临对象多样、环境复杂、成本高昂、难以规模化以及与市民感知不一致等挑战，而VLM在理解视觉信息和进行自然语言推理方面展现出巨大潜力，有望解决这些问题。

Method: 采用PRISMA方法学，系统性地回顾了2021年至2025年间发表的32篇相关研究论文，重点关注VLM在城市监测中的零样本应用。

Result: 综述分析了VLM在城市监测任务中的应用情况、常用模型架构与框架、可用数据集与资源，以及VLM应用的评估方法和性能表现。

Conclusion: 该研究旨在全面评估VLM在城市监测领域的现状和潜力，为未来研究和实际应用提供指导。

Abstract: Urban monitoring of public infrastructure (such as waste bins, road signs,
vegetation, sidewalks, and construction sites) poses significant challenges due
to the diversity of objects, environments, and contextual conditions involved.
Current state-of-the-art approaches typically rely on a combination of IoT
sensors and manual inspections, which are costly, difficult to scale, and often
misaligned with citizens' perception formed through direct visual observation.
This raises a critical question: Can machines now "see" like citizens and infer
informed opinions about the condition of urban infrastructure? Vision-Language
Models (VLMs), which integrate visual understanding with natural language
reasoning, have recently demonstrated impressive capabilities in processing
complex visual information, turning them into a promising technology to address
this challenge. This systematic review investigates the role of VLMs in urban
monitoring, with particular emphasis on zero-shot applications. Following the
PRISMA methodology, we analyzed 32 peer-reviewed studies published between 2021
and 2025 to address four core research questions: (1) What urban monitoring
tasks have been effectively addressed using VLMs? (2) Which VLM architectures
and frameworks are most commonly used and demonstrate superior performance? (3)
What datasets and resources support this emerging field? (4) How are VLM-based
applications evaluated, and what performance levels have been reported?

</details>


### [52] [Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model](https://arxiv.org/abs/2510.12408)
*Huu Tien Nguyen,Ahmed Karam Eldaly*

Main category: cs.CV

TL;DR: 本研究提出了一种基于条件流匹配（CFM）的图像质量迁移新框架，用于在低场磁共振成像（LF-MRI）中重建高质量图像。


<details>
  <summary>Details</summary>
Motivation: 低场磁共振成像（LF-MRI）设备成本低、便携性好，但其成像质量较低。本研究旨在弥补LF-MRI的质量差距，无需昂贵的设备即可重建高场磁共振成像（HF-MRI）的图像质量。

Method: 提出了一种新的条件流匹配（CFM）框架，通过直接回归最优速度场来学习噪声分布和目标数据分布之间的连续流，而不是依赖于迭代采样或对抗性目标。

Result: CFM框架在LF-MRI图像重建任务上取得了最先进的性能，并且能够很好地泛化到分布内和分布外的数据。与现有的深度学习方法相比，CFM使用的参数更少。

Conclusion: CFM是一种强大且可扩展的MRI重建工具，特别适用于资源有限的临床环境，能够显著提高LF-MRI的图像质量。

Abstract: This paper introduces a novel framework for image quality transfer based on
conditional flow matching (CFM). Unlike conventional generative models that
rely on iterative sampling or adversarial objectives, CFM learns a continuous
flow between a noise distribution and target data distributions through the
direct regression of an optimal velocity field. We evaluate this approach in
the context of low-field magnetic resonance imaging (LF-MRI), a rapidly
emerging modality that offers affordable and portable scanning but suffers from
inherently low signal-to-noise ratio and reduced diagnostic quality. Our
framework is designed to reconstruct high-field-like MR images from their
corresponding low-field inputs, thereby bridging the quality gap without
requiring expensive infrastructure. Experiments demonstrate that CFM not only
achieves state-of-the-art performance, but also generalizes robustly to both
in-distribution and out-of-distribution data. Importantly, it does so while
utilizing significantly fewer parameters than competing deep learning methods.
These results underline the potential of CFM as a powerful and scalable tool
for MRI reconstruction, particularly in resource-limited clinical environments.

</details>


### [53] [VideoLucy: Deep Memory Backtracking for Long Video Understanding](https://arxiv.org/abs/2510.12422)
*Jialong Zuo,Yongtai Deng,Lingdong Kong,Jingkang Yang,Rui Jin,Yiwei Zhang,Nong Sang,Liang Pan,Ziwei Liu,Changxin Gao*

Main category: cs.CV

TL;DR: VideoLucy是一个深度记忆回溯框架，用于长视频理解，通过分层记忆结构和迭代回溯机制，有效捕捉时间上下文和细节，并在EgoMem基准测试中表现出色，超越了包括GPT-4o在内的现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的视频理解系统在处理长视频时，存在难以捕捉连续帧的时间上下文以及稀疏帧采样可能丢失关键信息的问题。

Method: 提出VideoLucy深度记忆回溯框架，采用分层记忆结构（由粗到精，逐步细化）和基于代理的迭代回溯机制，以挖掘与问题相关的视频深度记忆，直至获得足够信息以回答问题。

Result: VideoLucy在多个长视频理解基准测试中显著优于现有方法，甚至超越了GPT-4o等闭源模型。同时，提出了EgoMem这一新的长视频理解基准。

Conclusion: VideoLucy通过其创新的记忆回溯框架，有效解决了长视频理解中的时间上下文和细节丢失问题，并在实验中证明了其优越性。

Abstract: Recent studies have shown that agent-based systems leveraging large language
models (LLMs) for key information retrieval and integration have emerged as a
promising approach for long video understanding. However, these systems face
two major challenges. First, they typically perform modeling and reasoning on
individual frames, struggling to capture the temporal context of consecutive
frames. Second, to reduce the cost of dense frame-level captioning, they adopt
sparse frame sampling, which risks discarding crucial information. To overcome
these limitations, we propose VideoLucy, a deep memory backtracking framework
for long video understanding. Inspired by the human recollection process from
coarse to fine, VideoLucy employs a hierarchical memory structure with
progressive granularity. This structure explicitly defines the detail level and
temporal scope of memory at different hierarchical depths. Through an
agent-based iterative backtracking mechanism, VideoLucy systematically mines
video-wide, question-relevant deep memories until sufficient information is
gathered to provide a confident answer. This design enables effective temporal
understanding of consecutive frames while preserving critical details. In
addition, we introduce EgoMem, a new benchmark for long video understanding.
EgoMem is designed to comprehensively evaluate a model's ability to understand
complex events that unfold over time and capture fine-grained details in
extremely long videos. Extensive experiments demonstrate the superiority of
VideoLucy. Built on open-source models, VideoLucy significantly outperforms
state-of-the-art methods on multiple long video understanding benchmarks,
achieving performance even surpassing the latest proprietary models such as
GPT-4o. Our code and dataset will be made publicly at
https://videolucy.github.io

</details>


### [54] [A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation](https://arxiv.org/abs/2510.12444)
*Shaoyang Zhou,Yingshu Li,Yunyi Liu,Lingqiao Liu,Lei Wang,Luping Zhou*

Main category: cs.CV

TL;DR: 本综述首次全面回顾了纵向放射报告生成（LRRG）领域，重点关注数据集构建、模型架构（包括纵向定制设计）和评估协议。研究总结了现有方法的性能，强调了纵向信息和架构选择对模型性能的影响，并指出了当前研究的局限性及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 现有的胸部 X 光片放射报告生成（CXRRRG）方法多依赖单张影像，无法捕捉纵向对比所需的历史信息，而放射科医生在诊断时会参考患者历史影像。虽然有研究开始关注纵向数据，但缺乏系统性的综述来指导模型设计。

Method: 本综述全面审查了纵向放射报告生成（LRRG）的研究，涵盖了数据集构建策略、报告生成架构（包括针对纵向数据的定制设计）以及评估协议（包括纵向特异性指标和常用基准）。此外，还总结了 LRRG 方法的性能和消融研究，分析了纵向信息和架构选择的关键作用。

Result: 本综述总结了现有 LRRG 方法的性能，并通过消融研究分析了纵向信息和架构设计选择对模型性能的提升作用，突出了这些因素的重要性。

Conclusion: 本综述首次对纵向放射报告生成（LRRG）进行了全面的回顾，系统性地梳理了数据集、模型架构和评估方法，并指出了当前研究存在的五个主要局限性，为该新兴领域未来的发展奠定了基础。

Abstract: Chest Xray imaging is a widely used diagnostic tool in modern medicine, and
its high utilization creates substantial workloads for radiologists. To
alleviate this burden, vision language models are increasingly applied to
automate Chest Xray radiology report generation (CXRRRG), aiming for clinically
accurate descriptions while reducing manual effort. Conventional approaches,
however, typically rely on single images, failing to capture the longitudinal
context necessary for producing clinically faithful comparison statements.
Recently, growing attention has been directed toward incorporating longitudinal
data into CXR RRG, enabling models to leverage historical studies in ways that
mirror radiologists diagnostic workflows. Nevertheless, existing surveys
primarily address single image CXRRRG and offer limited guidance for
longitudinal settings, leaving researchers without a systematic framework for
model design. To address this gap, this survey provides the first comprehensive
review of longitudinal radiology report generation (LRRG). Specifically, we
examine dataset construction strategies, report generation architectures
alongside longitudinally tailored designs, and evaluation protocols
encompassing both longitudinal specific measures and widely used benchmarks. We
further summarize LRRG methods performance, alongside analyses of different
ablation studies, which collectively highlight the critical role of
longitudinal information and architectural design choices in improving model
performance. Finally, we summarize five major limitations of current research
and outline promising directions for future development, aiming to lay a
foundation for advancing this emerging field.

</details>


### [55] [MS-GAGA: Metric-Selective Guided Adversarial Generation Attack](https://arxiv.org/abs/2510.12468)
*Dion J. X. Ho,Gabriel Lee Jun Rong,Niharika Shrivastava,Harshavardhan Abichandani,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CV

TL;DR: MS-GAGA是一个两阶段的框架，用于在黑盒设置中针对深度伪造检测器生成可迁移、视觉上不可察觉的对抗性样本。


<details>
  <summary>Details</summary>
Motivation: 为深度伪造检测器生成可迁移、视觉上不可察觉的对抗性样本。

Method: MS-GAGA框架包括两个阶段：第一阶段，一个双流攻击模块生成对抗性候选样本，其中MNTD-PGD采用针对小扰动预算优化的增强梯度计算，而SG-PGD则将扰动集中在视觉显著区域。第二阶段，一个度量感知选择模块根据候选样本对黑盒模型的成功率和与原始图像的结构相似性（SSIM）来评估它们。

Result: MS-GAGA 在看不见的检测器上实现了比最先进的攻击高出 27% 的错误分类率。

Conclusion: 通过联合优化可迁移性和不可察觉性，MS-GAGA 能够生成有效的对抗性样本。

Abstract: We present MS-GAGA (Metric-Selective Guided Adversarial Generation Attack), a
two-stage framework for crafting transferable and visually imperceptible
adversarial examples against deepfake detectors in black-box settings. In Stage
1, a dual-stream attack module generates adversarial candidates: MNTD-PGD
applies enhanced gradient calculations optimized for small perturbation
budgets, while SG-PGD focuses perturbations on visually salient regions. This
complementary design expands the adversarial search space and improves
transferability across unseen models. In Stage 2, a metric-aware selection
module evaluates candidates based on both their success against black-box
models and their structural similarity (SSIM) to the original image. By jointly
optimizing transferability and imperceptibility, MS-GAGA achieves up to 27%
higher misclassification rates on unseen detectors compared to state-of-the-art
attacks.

</details>


### [56] [A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation](https://arxiv.org/abs/2510.12482)
*Shurong Chai,Rahul Kumar JAIN,Rui Xu,Shaocong Mo,Ruibo Hou,Shiyu Teng,Jiaqing Liu,Lanfen Lin,Yen-Wei Chen*

Main category: cs.CV

TL;DR: 提出了一种早期融合框架，用于在医学图像分割中进行文本引导的图像分割，通过在增强之前融合文本和视觉特征来解决旋转和翻转等常见数据增强破坏空间一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本引导医学图像分割方法在应用数据增强（如旋转、翻转）时，会破坏图像和文本之间的空间对齐，从而削弱模型性能。数据增强对于缓解医学影像领域数据不足的问题至关重要。

Method: 提出了一种早期融合框架，在数据增强之前融合文本和视觉特征，以保持空间一致性。设计了一个轻量级生成器，将文本嵌入投影到视觉空间，以弥合语义鸿沟。

Result: 生成的伪影可视化显示了准确的区域定位。在三个医学成像任务和四个分割框架上进行了评估，取得了最先进的结果。

Conclusion: 该方法通过在增强之前融合文本和视觉特征，解决了数据增强破坏空间一致性的问题，提高了文本引导医学图像分割的性能。

Abstract: Deep learning relies heavily on data augmentation to mitigate limited data,
especially in medical imaging. Recent multimodal learning integrates text and
images for segmentation, known as referring or text-guided image segmentation.
However, common augmentations like rotation and flipping disrupt spatial
alignment between image and text, weakening performance. To address this, we
propose an early fusion framework that combines text and visual features before
augmentation, preserving spatial consistency. We also design a lightweight
generator that projects text embeddings into visual space, bridging semantic
gaps. Visualization of generated pseudo-images shows accurate region
localization. Our method is evaluated on three medical imaging tasks and four
segmentation frameworks, achieving state-of-the-art results. Code is publicly
available on GitHub: https://github.com/11yxk/MedSeg_EarlyFusion.

</details>


### [57] [BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring](https://arxiv.org/abs/2510.12493)
*An Zhao,Piaopiao Yu,Zhe Zhu,Mingqiang Wei*

Main category: cs.CV

TL;DR: 现有的3D高斯泼溅方法在处理运动模糊图像时存在局限性，主要体现在对相机位姿的过度依赖以及无法有效控制模糊导致的错误高斯原始点过度密集化。为了解决这些问题，本文提出了一个名为“双阶段3D高斯泼溅”（BSGS）的新框架，用于从运动模糊图像中准确重建3D场景。BSGS包含两个阶段：相机位姿优化和全局刚体变换校正。此外，还提出了一种子帧梯度聚合策略来优化这两个阶段，并引入了一种时空双阶段优化策略来动态调整原始点密集化阈值，以防止在模糊区域过早生成噪声高斯点。实验证明了该方法的有效性及其优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅（3DGS）方法在从运动模糊图像重建高质量3D场景时面临挑战，其性能受限于对相机位姿精度的极端依赖以及无法有效控制运动模糊导致的错误高斯原始点过度密集化。

Method: 本文提出了一种名为“双阶段3D高斯泼溅”（BSGS）的新框架。该框架包含两个阶段：1. 相机位姿优化：粗略优化相机位姿以减少运动引起的畸变。2. 全局刚体变换：在固定粗略相机位姿的情况下，进一步校正运动引起的模糊畸变。此外，还采用了子帧梯度聚合策略来优化两个阶段，并引入了时空双阶段优化策略来动态调整原始点密集化阈值，以防止在模糊区域过早生成噪声高斯点。

Result: 通过全面的实验验证，证明了所提出的双阶段3D高斯泼溅（BSGS）方法在运动去模糊方面的有效性，并显示出其在性能上优于当前最先进的方法。

Conclusion: 本文提出的BSGS框架通过相机位姿优化和全局刚体变换校正，有效解决了现有3DGS方法在处理运动模糊图像时的局限性，实现了从运动模糊图像到高质量3D场景的准确重建。

Abstract: 3D Gaussian Splatting has exhibited remarkable capabilities in 3D scene
reconstruction.However, reconstructing high-quality 3D scenes from
motion-blurred images caused by camera motion poses a significant challenge.The
performance of existing 3DGS-based deblurring methods are limited due to their
inherent mechanisms, such as extreme dependence on the accuracy of camera poses
and inability to effectively control erroneous Gaussian primitives
densification caused by motion blur.To solve these problems, we introduce a
novel framework, Bi-Stage 3D Gaussian Splatting, to accurately reconstruct 3D
scenes from motion-blurred images.BSGS contains two stages. First, Camera Pose
Refinement roughly optimizes camera poses to reduce motion-induced distortions.
Second, with fixed rough camera poses, Global RigidTransformation further
corrects motion-induced blur distortions.To alleviate multi-subframe gradient
conflicts, we propose a subframe gradient aggregation strategy to optimize both
stages.Furthermore, a space-time bi-stage optimization strategy is introduced
to dynamically adjust primitive densification thresholds and prevent premature
noisy Gaussian generation in blurred regions. Comprehensive experiments verify
the effectiveness of our proposed deblurring method and show its superiority
over the state of the arts.

</details>


### [58] [Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points](https://arxiv.org/abs/2510.12524)
*Jiayi Kong,Chen Zong,Junkai Deng,Xuhui Chen,Fei Hou,Shiqing Xin,Junhui Hou,Chen Qian,Ying He*

Main category: cs.CV

TL;DR: VAD是一种计算无符号距离场（UDF）的新型方法，可以直接从无方向点云生成，具有高效、稳定和可控的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的UDF学习方法存在数值不稳定性、计算成本高和可控性差等问题。

Method: VAD方法首先通过基于Voronoi的几何标准为输入点分配双向法线，然后利用这些法线形成近似UDF梯度场，最后通过积分得到UDF。

Result: VAD能够稳健地处理各种几何形状，包括水密和开放曲面，以及复杂的非流形和不可定向几何体，同时保持计算效率和稳定性。

Conclusion: VAD提供了一种轻量级、无需网络的方法来计算UDF，克服了现有方法的局限性。

Abstract: Unsigned Distance Fields (UDFs) provide a flexible representation for 3D
shapes with arbitrary topology, including open and closed surfaces, orientable
and non-orientable geometries, and non-manifold structures. While recent neural
approaches have shown promise in learning UDFs, they often suffer from
numerical instability, high computational cost, and limited controllability. We
present a lightweight, network-free method, Voronoi-Assisted Diffusion (VAD),
for computing UDFs directly from unoriented point clouds. Our approach begins
by assigning bi-directional normals to input points, guided by two
Voronoi-based geometric criteria encoded in an energy function for optimal
alignment. The aligned normals are then diffused to form an approximate UDF
gradient field, which is subsequently integrated to recover the final UDF.
Experiments demonstrate that VAD robustly handles watertight and open surfaces,
as well as complex non-manifold and non-orientable geometries, while remaining
computationally efficient and stable.

</details>


### [59] [Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion](https://arxiv.org/abs/2510.12537)
*David Björkstrand,Tiesheng Wang,Lars Bretzner,Josephine Sullivan*

Main category: cs.CV

TL;DR: 使用仅经过仔细特征空间归一化和标准L2分数匹配损失的加权分析的评分模型，即可在无条件人类运动生成方面取得最先进的结果，同时直接生成运动和形状。


<details>
  <summary>Details</summary>
Motivation: 大多数人类运动生成方法依赖于过度参数化的输入特征和辅助损失来获得更好的结果。然而，这些策略对于匹配人类运动分布的扩散模型并非必需。

Method: 本研究提出了一种评分模型，仅使用仔细的特征空间归一化和标准L2分数匹配损失的加权分析，即可实现最先进的无条件人类运动生成结果。该模型直接生成运动和形状，无需进行缓慢的后验形状恢复。

Result: 该模型能够直接生成运动和形状，避免了从关节进行缓慢的后验形状恢复，并在无条件人类运动生成方面取得了与最先进方法相媲美的使用效果。

Conclusion: 该研究表明，通过仔细的特征空间归一化和加权分析，仅使用评分模型就可以在无条件人类运动生成方面取得最先进的结果，并且可以直接生成运动和形状。

Abstract: Recent work has explored a range of model families for human motion
generation, including Variational Autoencoders (VAEs), Generative Adversarial
Networks (GANs), and diffusion-based models. Despite their differences, many
methods rely on over-parameterized input features and auxiliary losses to
improve empirical results. These strategies should not be strictly necessary
for diffusion models to match the human motion distribution. We show that on
par with state-of-the-art results in unconditional human motion generation are
achievable with a score-based diffusion model using only careful feature-space
normalization and analytically derived weightings for the standard L2
score-matching loss, while generating both motion and shape directly, thereby
avoiding slow post hoc shape recovery from joints. We build the method step by
step, with a clear theoretical motivation for each component, and provide
targeted ablations demonstrating the effectiveness of each proposed addition in
isolation.

</details>


### [60] [MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking](https://arxiv.org/abs/2510.12565)
*Tianhao Li,Tingfa Xu,Ying Wang,Haolin Qin,Xu Lin,Jianan Li*

Main category: cs.CV

TL;DR: 本论文提出了MMOT，首个用于无人机多光谱多目标跟踪的基准数据集，并引入了一种新的多光谱和方向感知跟踪方法，显著提高了在各种挑战性场景下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RGB的无人机多目标跟踪算法在小目标、遮挡和复杂背景下性能不佳，因为它们过度依赖空间外观线索。多光谱成像通过提供像素级的光谱反射信息，可以增强目标的可区分性，但缺乏专门的多光谱无人机数据集阻碍了该领域的发展。

Method: 本研究提出了MMOT数据集，包含大规模、多样化挑战和精确定向标注。同时，提出了一种多光谱和方向感知的多目标跟踪方案，包括轻量级光谱3D-Stem、方向感知卡尔曼滤波器和端到端方向自适应Transformer。

Result: 在代表性跟踪器上的大量实验表明，与RGB基线相比，多光谱输入显著提高了跟踪性能，尤其是在小目标和密集目标场景下。

Conclusion: MMOT数据集和提出的多光谱、方向感知跟踪方法能够有效解决无人机多目标跟踪的挑战，推动该领域的研究进展。

Abstract: Drone-based multi-object tracking is essential yet highly challenging due to
small targets, severe occlusions, and cluttered backgrounds. Existing RGB-based
tracking algorithms heavily depend on spatial appearance cues such as color and
texture, which often degrade in aerial views, compromising reliability.
Multispectral imagery, capturing pixel-level spectral reflectance, provides
crucial cues that enhance object discriminability under degraded spatial
conditions. However, the lack of dedicated multispectral UAV datasets has
hindered progress in this domain. To bridge this gap, we introduce MMOT, the
first challenging benchmark for drone-based multispectral multi-object
tracking. It features three key characteristics: (i) Large Scale - 125 video
sequences with over 488.8K annotations across eight categories; (ii)
Comprehensive Challenges - covering diverse conditions such as extreme small
targets, high-density scenarios, severe occlusions, and complex motion; and
(iii) Precise Oriented Annotations - enabling accurate localization and reduced
ambiguity under aerial perspectives. To better extract spectral features and
leverage oriented annotations, we further present a multispectral and
orientation-aware MOT scheme adapting existing methods, featuring: (i) a
lightweight Spectral 3D-Stem integrating spectral features while preserving
compatibility with RGB pretraining; (ii) an orientation-aware Kalman filter for
precise state estimation; and (iii) an end-to-end orientation-adaptive
transformer. Extensive experiments across representative trackers consistently
show that multispectral input markedly improves tracking performance over RGB
baselines, particularly for small and densely packed objects. We believe our
work will advance drone-based multispectral multi-object tracking research. Our
MMOT, code, and benchmarks are publicly available at
https://github.com/Annzstbl/MMOT.

</details>


### [61] [Learning Human Motion with Temporally Conditional Mamba](https://arxiv.org/abs/2510.12573)
*Quang Nguyen,Tri Le,Baoru Huang,Minh Nhat Vu,Ngan Le,Thieu Vo,Anh Nguyen*

Main category: cs.CV

TL;DR: Temporally Conditional Mamba (TCM) is a new mamba-based model for human motion generation that improves temporal alignment by integrating conditional information into the recurrent dynamics of the Mamba block, outperforming existing methods in experiments.


<details>
  <summary>Details</summary>
Motivation: Existing methods for learning human motion based on time-dependent input signals often use cross-attention, which captures global interactions but struggles with step-by-step temporal alignment. This paper aims to address this limitation.

Method: The proposed method, Temporally Conditional Mamba (TCM), is a new mamba-based model that integrates conditional information into the recurrent dynamics of the Mamba block to achieve better temporally aligned motion.

Result: Extensive experiments on various human motion tasks demonstrate that TCM significantly improves temporal alignment, motion realism, and condition consistency compared to state-of-the-art approaches.

Conclusion: TCM, a novel mamba-based model, effectively addresses the limitations of existing methods in human motion generation by enhancing temporal alignment through integrated conditional information in its recurrent dynamics.

Abstract: Learning human motion based on a time-dependent input signal presents a
challenging yet impactful task with various applications. The goal of this task
is to generate or estimate human movement that consistently reflects the
temporal patterns of conditioning inputs. Existing methods typically rely on
cross-attention mechanisms to fuse the condition with motion. However, this
approach primarily captures global interactions and struggles to maintain
step-by-step temporal alignment. To address this limitation, we introduce
Temporally Conditional Mamba, a new mamba-based model for human motion
generation. Our approach integrates conditional information into the recurrent
dynamics of the Mamba block, enabling better temporally aligned motion. To
validate the effectiveness of our method, we evaluate it on a variety of human
motion tasks. Extensive experiments demonstrate that our model significantly
improves temporal alignment, motion realism, and condition consistency over
state-of-the-art approaches. Our project page is available at
https://zquang2202.github.io/TCM.

</details>


### [62] [Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence](https://arxiv.org/abs/2510.12579)
*Simon Ravé,Jean-Christophe Lombardo,Pejman Rasti,Alexis Joly,David Rousseau*

Main category: cs.CV

TL;DR: 本研究提出了一种利用Plantnet和Segment Anything Model（SAM）进行农业图像零样本分割的方法，通过结合Plantnet的植物识别能力和SAM的精细分割能力，有效解决了农业图像分割中的标注瓶颈问题，并在多个公开数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 农业图像分割面临标注数据缺乏和复杂田间条件的挑战，需要一种能够减轻标注负担并有效处理多样化场景的方法。

Method: 该方法结合了Plantnet（及其DinoV2骨干）和SAM。首先，利用Plantnet的植物表征来识别植物区域并生成粗分割掩模，然后利用SAM对这些掩模进行细化，得到详细分割结果。

Result: 在四个不同复杂度的公开数据集上进行了评估，结果显示，使用经过Plantnet微调的DinoV2模型相比基础DinoV2模型，在Jaccard Index（IoU）上表现出持续的性能提升。

Conclusion: 结合植物中心模型（如Plantnet）和基础模型（如SAM）的表征能力，是解决农业图像分割标注瓶颈、实现多样化场景有效分割的潜力巨大。

Abstract: We present a zero-shot segmentation approach for agricultural imagery that
leverages Plantnet, a large-scale plant classification model, in conjunction
with its DinoV2 backbone and the Segment Anything Model (SAM). Rather than
collecting and annotating new datasets, our method exploits Plantnet's
specialized plant representations to identify plant regions and produce coarse
segmentation masks. These masks are then refined by SAM to yield detailed
segmentations. We evaluate on four publicly available datasets of various
complexity in terms of contrast including some where the limited size of the
training data and complex field conditions often hinder purely supervised
methods. Our results show consistent performance gains when using
Plantnet-fine-tuned DinoV2 over the base DinoV2 model, as measured by the
Jaccard Index (IoU). These findings highlight the potential of combining
foundation models with specialized plant-centric models to alleviate the
annotation bottleneck and enable effective segmentation in diverse agricultural
scenarios.

</details>


### [63] [LayerSync: Self-aligning Intermediate Layers](https://arxiv.org/abs/2510.12581)
*Yasaman Haghighi,Bastien van Delft,Mariam Hassan,Alexandre Alahi*

Main category: cs.CV

TL;DR: LayerSync是一种即插即用的正则化器，通过利用扩散模型自身不同层的中间表示来提高生成质量和训练效率，无需额外数据或预训练模型，且适用于多模态生成。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，扩散模型的生成质量与其学习到的表示相关，并且外部引导可以加速训练。本研究旨在改进这一范式，通过规范化扩散模型自身的中间表示来提高其性能。

Method: LayerSync是一种即插即用的正则化器，通过观察到不同层表示的质量差异，利用语义更丰富的层来指导较弱的层，从而实现自我监督。该方法不需要预训练模型或额外数据。

Result: 在图像生成方面，LayerSync将流式Transformer在ImageNet上的训练速度提高了8.75倍以上，并将生成质量提高了23.6%。该方法还展示了在音频、视频和运动生成等其他领域的应用潜力，并能在这些领域持续提高生成质量和训练效率。

Conclusion: LayerSync通过利用扩散模型自身不同层的中间表示，为扩散模型提供了一种无需外部监督的内在引导，从而在不增加额外开销的情况下，显著提高了生成质量和训练效率，并且适用于包括图像、音频、视频和运动在内的多种生成任务。

Abstract: We propose LayerSync, a domain-agnostic approach for improving the generation
quality and the training efficiency of diffusion models. Prior studies have
highlighted the connection between the quality of generation and the
representations learned by diffusion models, showing that external guidance on
model intermediate representations accelerates training. We reconceptualize
this paradigm by regularizing diffusion models with their own intermediate
representations. Building on the observation that representation quality varies
across diffusion model layers, we show that the most semantically rich
representations can act as an intrinsic guidance for weaker ones, reducing the
need for external supervision. Our approach, LayerSync, is a self-sufficient,
plug-and-play regularizer term with no overhead on diffusion model training and
generalizes beyond the visual domain to other modalities. LayerSync requires no
pretrained models nor additional data. We extensively evaluate the method on
image generation and demonstrate its applicability to other domains such as
audio, video, and motion generation. We show that it consistently improves the
generation quality and the training efficiency. For example, we speed up the
training of flow-based transformer by over 8.75x on ImageNet dataset and
improved the generation quality by 23.6%. The code is available at
https://github.com/vita-epfl/LayerSync.

</details>


### [64] [Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training](https://arxiv.org/abs/2510.12586)
*Jiachen Lei,Keli Liu,Julius Berner,Haiming Yu,Hongkai Zheng,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的两阶段训练框架，用于弥合像素空间生成模型与潜在空间模型的性能和效率差距。


<details>
  <summary>Details</summary>
Motivation: 像素空间生成模型通常比潜在空间模型更难训练且性能较差。

Method: 该框架包括两个阶段：第一阶段，预训练编码器以捕获干净图像的有意义语义，并将其与沿确定性采样轨迹的点对齐；第二阶段，将编码器与随机初始化的解码器集成，并对整个模型进行端到端微调。

Result: 在ImageNet数据集上，提出的扩散模型在ImageNet-256上达到了2.04的FID，在ImageNet-512上达到了2.35的FID（75次函数评估），显著优于之前的像素空间方法，并可与领先的基于VAE的模型相媲美。此外，在ImageNet-256上，提出的条件模型在单次采样步骤中达到了8.82的FID，优于其潜在空间对应模型。

Conclusion: 该研究成功地在像素空间中训练了扩散模型和一致性模型，在生成质量和效率方面取得了最先进的成果，并首次在没有预训练VAE或扩散模型的情况下直接在更高分辨率的图像上训练了一致性模型。

Abstract: Pixel-space generative models are often more difficult to train and generally
underperform compared to their latent-space counterparts, leaving a persistent
performance and efficiency gap. In this paper, we introduce a novel two-stage
training framework that closes this gap for pixel-space diffusion and
consistency models. In the first stage, we pre-train encoders to capture
meaningful semantics from clean images while aligning them with points along
the same deterministic sampling trajectory, which evolves points from the prior
to the data distribution. In the second stage, we integrate the encoder with a
randomly initialized decoder and fine-tune the complete model end-to-end for
both diffusion and consistency models. Our training framework demonstrates
strong empirical performance on ImageNet dataset. Specifically, our diffusion
model reaches an FID of 2.04 on ImageNet-256 and 2.35 on ImageNet-512 with 75
number of function evaluations (NFE), surpassing prior pixel-space methods by a
large margin in both generation quality and efficiency while rivaling leading
VAE-based models at comparable training cost. Furthermore, on ImageNet-256, our
consistency model achieves an impressive FID of 8.82 in a single sampling step,
significantly surpassing its latent-space counterpart. To the best of our
knowledge, this marks the first successful training of a consistency model
directly on high-resolution images without relying on pre-trained VAEs or
diffusion models.

</details>


### [65] [Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space](https://arxiv.org/abs/2510.12603)
*Chao Chen,Zhixin Ma,Yongqi Li,Yupeng Hu,Yinwei Wei,Wenjie Li,Liqiang Nie*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为IVT-LR的多模态潜在推理方法，通过在潜在空间中结合视觉和文本信息来提升多模态大模型（MLLMs）的推理能力，同时减少了对显式推理步骤和标注的依赖，并显著提高了推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推理方法依赖于显式的推理步骤，这需要耗费大量精力的视觉-文本标注，并显著增加了推理延迟。本研究旨在解决这些问题，提出一种新的多模态推理方法。

Method: 本研究提出了Interleaved Vision-Text Latent Reasoning (IVT-LR) 方法，该方法在潜在空间中注入视觉和文本信息，通过结合前一阶段的潜在文本（隐藏状态）和潜在视觉（选定的图像嵌入）来表示每个推理步骤。并采用渐进式多阶段训练策略来训练MLLMs执行此推理。

Result: 在M3CoT和ScienceQA数据集上的实验表明，IVT-LR方法在准确率方面平均提高了5.45%，同时推理速度提高了5倍以上。

Conclusion: IVT-LR方法能够有效地提升多模态大模型的推理能力，同时在标注和推理效率方面具有显著优势。

Abstract: Multimodal reasoning aims to enhance the capabilities of MLLMs by
incorporating intermediate reasoning steps before reaching the final answer. It
has evolved from text-only reasoning to the integration of visual information,
enabling the thought process to be conveyed through both images and text.
Despite its effectiveness, current multimodal reasoning methods depend on
explicit reasoning steps that require labor-intensive vision-text annotations
and inherently introduce significant inference latency. To address these
issues, we introduce multimodal latent reasoning with the advantages of
multimodal representation, reduced annotation, and inference efficiency. To
facilicate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR),
which injects both visual and textual information in the reasoning process
within the latent space. Specifically, IVT-LR represents each reasoning step by
combining two implicit parts: latent text (the hidden states from the previous
step) and latent vision (a set of selected image embeddings). We further
introduce a progressive multi-stage training strategy to enable MLLMs to
perform the above multimodal latent reasoning steps. Experiments on M3CoT and
ScienceQA demonstrate that our IVT-LR method achieves an average performance
increase of 5.45% in accuracy, while simultaneously achieving a speed increase
of over 5 times compared to existing approaches. Code available at
https://github.com/FYYDCC/IVT-LR.

</details>


### [66] [WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency Mask Generation](https://arxiv.org/abs/2510.12605)
*Runting Li,Shijie Lian,Hua Li,Yutong Li,Wenhui Wu,Sam Kwong*

Main category: cs.CV

TL;DR: WaterFlow是一个基于流的框架，通过整合水下成像的物理信息和时间维度建模来解决水下显著目标检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视水下成像的物理原理，或将退化视为必须消除的干扰，未能充分利用其包含的信息。本研究旨在解决这一问题。

Method: 提出WaterFlow框架，整合水下物理成像信息作为先验知识，并引入时间维度建模，以增强模型识别显著目标的能力。

Result: 在USOD10K数据集上，WaterFlow的S_m指标提升了0.072，证明了其有效性和优越性。

Conclusion: WaterFlow框架通过整合水下成像物理信息和时间维度建模，显著提高了水下显著目标检测的性能。

Abstract: Underwater Salient Object Detection (USOD) faces significant challenges,
including underwater image quality degradation and domain gaps. Existing
methods tend to ignore the physical principles of underwater imaging or simply
treat degradation phenomena in underwater images as interference factors that
must be eliminated, failing to fully exploit the valuable information they
contain. We propose WaterFlow, a rectified flow-based framework for underwater
salient object detection that innovatively incorporates underwater physical
imaging information as explicit priors directly into the network training
process and introduces temporal dimension modeling, significantly enhancing the
model's capability for salient object identification. On the USOD10K dataset,
WaterFlow achieves a 0.072 gain in S_m, demonstrating the effectiveness and
superiority of our method. The code will be published after the acceptance.

</details>


### [67] [Zero-Shot CFC: Fast Real-World Image Denoising based on Cross-Frequency Consistency](https://arxiv.org/abs/2510.12646)
*Yanlin Jiang,Yuchen Liu,Mingren Liu*

Main category: cs.CV

TL;DR: 提出了一种名为ZSCFC的零样本图像去噪方法，该方法通过跨频率一致性损失和超轻量级网络，实现了无需数据集的快速有效去噪，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本去噪方法存在训练时间长、依赖噪声独立性和零均值假设等问题，限制了其在复杂噪声场景下的实际应用。本研究旨在提出一种高效且有效的真实世界图像去噪方法。

Method: 利用图像纹理在不同频段具有位置相似性和内容一致性，而噪声不具备此特性的特点，设计了跨频率一致性损失和超轻量级网络来实现去噪。

Result: 在多个真实世界图像数据集上的实验表明，ZSCFC在计算效率和去噪性能上均优于目前最先进的零样本方法。

Conclusion: ZSCFC是一种高效且有效的零样本图像去噪方法，能够处理复杂噪声，并且无需依赖数据集，在实际应用中表现出色。

Abstract: Zero-shot denoisers address the dataset dependency of deep-learning-based
denoisers, enabling the denoising of unseen single images. Nonetheless,
existing zero-shot methods suffer from long training times and rely on the
assumption of noise independence and a zero-mean property, limiting their
effectiveness in real-world denoising scenarios where noise characteristics are
more complicated. This paper proposes an efficient and effective method for
real-world denoising, the Zero-Shot denoiser based on Cross-Frequency
Consistency (ZSCFC), which enables training and denoising with a single noisy
image and does not rely on assumptions about noise distribution. Specifically,
image textures exhibit position similarity and content consistency across
different frequency bands, while noise does not. Based on this property, we
developed cross-frequency consistency loss and an ultralight network to realize
image denoising. Experiments on various real-world image datasets demonstrate
that our ZSCFC outperforms other state-of-the-art zero-shot methods in terms of
computational efficiency and denoising performance.

</details>


### [68] [On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation](https://arxiv.org/abs/2510.12660)
*Shuhei Tarashima,Yushan Wang,Norio Tagawa*

Main category: cs.CV

TL;DR: 本文提出了使用分层视觉基础模型（VFMs）的早期阶段来构建轻量级的人体网格恢复（HMR）和人体姿态估计（HPE）模型，并在精度和计算效率之间取得了更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有先进的HMR方法（如HMR2.0）及其HPE前身（如ViTPose）依赖于大型、非分层视觉Transformer作为编码器。为了在不同的计算预算下建立基线，并探索更高效的模型，作者提出了利用分层VFMs（如Swin Transformer、GroupMixFormer和VMamba）的早期阶段作为编码器。

Method: 作者首先构建了三个轻量级的HMR2.0变体，以适应相应的ViTPose模型，作为基线。然后，他们提出利用分层VFMs（包括Swin Transformer、GroupMixFormer和VMamba）的早期阶段作为编码器，因为这些阶段的特征图分辨率可以与非分层模型相媲美或更高。他们对27个基于分层VFM的HMR和HPE模型进行了全面的评估，只使用了前两或三个阶段。

Result: 实验表明，仅使用分层VFMs的前两或三个阶段，就可以达到与完整模型相媲美的性能。与现有的轻量级替代方案相比，这种截面的模型在精度和计算效率之间表现出更好的权衡。

Conclusion: 使用分层视觉基础模型（VFMs）的早期阶段作为编码器，可以有效地构建轻量级的人体网格恢复（HMR）和人体姿态估计（HPE）模型，并在精度和计算效率之间取得优越的性能平衡。

Abstract: In this work, we aim to develop simple and efficient models for human mesh
recovery (HMR) and its predecessor task, human pose estimation (HPE).
State-of-the-art HMR methods, such as HMR2.0 and its successors, rely on large,
non-hierarchical vision transformers as encoders, which are inherited from the
corresponding HPE models like ViTPose. To establish baselines across varying
computational budgets, we first construct three lightweight HMR2.0 variants by
adapting the corresponding ViTPose models. In addition, we propose leveraging
the early stages of hierarchical vision foundation models (VFMs), including
Swin Transformer, GroupMixFormer, and VMamba, as encoders. This design is
motivated by the observation that intermediate stages of hierarchical VFMs
produce feature maps with resolutions comparable to or higher than those of
non-hierarchical counterparts. We conduct a comprehensive evaluation of 27
hierarchical-VFM-based HMR and HPE models, demonstrating that using only the
first two or three stages achieves performance on par with full-stage models.
Moreover, we show that the resulting truncated models exhibit better trade-offs
between accuracy and computational efficiency compared to existing lightweight
alternatives.

</details>


### [69] [TerraCodec: Compressing Earth Observations](https://arxiv.org/abs/2510.12670)
*Julen Costa-Watanabe,Isabelle Wittmann,Benedikt Blumenstiel,Konrad Schindler*

Main category: cs.CV

TL;DR: EO卫星产生海量多光谱图像时间序列，面临存储和传输挑战。为解决此问题，我们提出了TerraCodec (TEC)，一种专为EO定制的学习型编解码器系列，包括高效的图像变体和利用时间依赖性的Temporal Transformer模型 (TEC-TT)。我们还引入了Latent Repacking方法，用于训练灵活的变压器模型。


<details>
  <summary>Details</summary>
Motivation: Earth observation (EO) satellites produce massive multispectral image time series, posing challenges for storage and transmission. Existing learned EO compression is fragmented and misaligned with natural imagery compression advances.

Method: Introduced TerraCodec (TEC), a family of learned codecs tailored to EO. TEC includes efficient image-based variants and a Temporal Transformer model (TEC-TT) leveraging temporal dependencies. Presented Latent Repacking for training flexible-rate transformer models. Trained on Sentinel-2 data.

Result: TerraCodec outperforms classical codecs, achieving 3-10x stronger compression at equivalent image quality. TEC-TT enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the AllClear benchmark.

Conclusion: Bespoke, learned compression algorithms are a promising direction for Earth observation. Code and model weights will be released.

Abstract: Earth observation (EO) satellites produce massive streams of multispectral
image time series, posing pressing challenges for storage and transmission.
Yet, learned EO compression remains fragmented, lacking publicly available
pretrained models and misaligned with advances in compression for natural
imagery. Image codecs overlook temporal redundancy, while video codecs rely on
motion priors that fail to capture the radiometric evolution of largely static
scenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to
EO. TEC includes efficient image-based variants adapted to multispectral
inputs, as well as a Temporal Transformer model (TEC-TT) that leverages
dependencies across time. To overcome the fixed-rate setting of today's neural
codecs, we present Latent Repacking, a novel method for training flexible-rate
transformer models that operate on varying rate-distortion settings. Trained on
Sentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x
stronger compression at equivalent image quality. Beyond compression, TEC-TT
enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the
AllClear benchmark. Our results establish bespoke, learned compression
algorithms as a promising direction for Earth observation. Code and model
weights will be released under a permissive license.

</details>


### [70] [MCOP: Multi-UAV Collaborative Occupancy Prediction](https://arxiv.org/abs/2510.12679)
*Zefu Lin,Wenbo Chen,Xiaojuan Jin,Yuran Yang,Lue Fan,Yixin Zhang,Yufeng Zhang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 通过引入空间感知特征编码、跨代理特征集成、高度感知特征缩减和双掩码感知引导，提出了一种新的多无人机协同占用预测框架，以克服现有BEV方法的局限性，并在扩展的数据集上实现了最先进的准确性，同时大大降低了通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于BEV的无人机协同感知方法在表示场景语义和几何信息方面存在不足，并且在处理未定义或被遮挡物体时性能会下降。

Method: 提出了一种新的多无人机协同占用预测框架，该框架集成了空间感知特征编码和跨代理特征集成，以保留3D空间结构和语义。为了提高效率，还引入了高度感知特征缩减和双掩码感知引导机制，以压缩场景信息并减少通信开销。

Result: 所提出的方法在扩展的三个数据集（Air-to-Pred-Occ、UAV3D-Occ和GauUScene-Occ）上进行了评估，并取得了最先进的准确性，显著优于现有的协同方法，同时通信开销仅为先前方法的很小一部分。

Conclusion: 该研究提出了一种创新的多无人机协同占用预测框架，通过先进的特征处理和集成技术，有效解决了现有方法的局限性，并在性能和通信效率方面取得了显著的改进，为无人机群体系统的协同感知提供了新的解决方案。

Abstract: Unmanned Aerial Vehicle (UAV) swarm systems necessitate efficient
collaborative perception mechanisms for diverse operational scenarios. Current
Bird's Eye View (BEV)-based approaches exhibit two main limitations:
bounding-box representations fail to capture complete semantic and geometric
information of the scene, and their performance significantly degrades when
encountering undefined or occluded objects. To address these limitations, we
propose a novel multi-UAV collaborative occupancy prediction framework. Our
framework effectively preserves 3D spatial structures and semantics through
integrating a Spatial-Aware Feature Encoder and Cross-Agent Feature
Integration. To enhance efficiency, we further introduce Altitude-Aware Feature
Reduction to compactly represent scene information, along with a Dual-Mask
Perceptual Guidance mechanism to adaptively select features and reduce
communication overhead. Due to the absence of suitable benchmark datasets, we
extend three datasets for evaluation: two virtual datasets (Air-to-Pred-Occ and
UAV3D-Occ) and one real-world dataset (GauUScene-Occ). Experiments results
demonstrate that our method achieves state-of-the-art accuracy, significantly
outperforming existing collaborative methods while reducing communication
overhead to only a fraction of previous approaches.

</details>


### [71] [Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis](https://arxiv.org/abs/2510.12704)
*Shelley Zixin Shu,Haozhe Luo,Alexander Poellinger,Mauricio Reyes*

Main category: cs.CV

TL;DR: Transformer 模型在医学影像中表现出色，但易学到无关信息。本文提出混合解释引导学习（H-EGL）框架，结合自监督和人工引导，以提高注意力的对齐和泛化能力，并在胸部 X 光分类任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: Transformer 模型在医学影像分析中虽然表现优异，但容易学习到无关的关联信息，导致泛化能力受限。人工引导的注意力对齐方法成本高昂。

Method: 提出混合解释引导学习（H-EGL）框架，该框架结合了自监督和人工引导的约束，以增强注意力对齐并提高泛化能力。自监督部分利用类别区分性注意力，不依赖于严格的先验知识，从而提高了模型的鲁棒性和灵活性。

Result: 在胸部 X 光分类任务中，使用 Vision Transformer（ViT）对 H-EGL 进行了验证。结果表明，H-EGL 的分类准确性和泛化能力优于两种最先进的解释引导学习（EGL）方法，并且生成的注意力图与人类专业知识的对齐度更高。

Conclusion: H-EGL 框架通过结合自监督和人工引导的约束，成功提高了 Transformer 模型在医学影像分析中的注意力对齐和泛化能力，并在胸部 X 光分类任务中取得了优于现有方法的性能。

Abstract: Transformer-based deep learning models have demonstrated exceptional
performance in medical imaging by leveraging attention mechanisms for feature
representation and interpretability. However, these models are prone to
learning spurious correlations, leading to biases and limited generalization.
While human-AI attention alignment can mitigate these issues, it often depends
on costly manual supervision. In this work, we propose a Hybrid
Explanation-Guided Learning (H-EGL) framework that combines self-supervised and
human-guided constraints to enhance attention alignment and improve
generalization. The self-supervised component of H-EGL leverages
class-distinctive attention without relying on restrictive priors, promoting
robustness and flexibility. We validate our approach on chest X-ray
classification using the Vision Transformer (ViT), where H-EGL outperforms two
state-of-the-art Explanation-Guided Learning (EGL) methods, demonstrating
superior classification accuracy and generalization capability. Additionally,
it produces attention maps that are better aligned with human expertise.

</details>


### [72] [Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning](https://arxiv.org/abs/2510.12712)
*Xingang Guo,Utkarsh Tyagi,Advait Gosai,Paula Vergara,Ernesto Gabriel Hernández Montoya,Chen Bo Calvin Zhang,Bin Hu,Yunzhong He,Bing Liu,Rakshith Sharma Srinivasa*

Main category: cs.CV

TL;DR: IRIS是一个评估多模态大语言模型（MLLMs）在“用图像思考”范式下的交互式推理能力的基准，其中图像被视为可操作的认知工作空间，而不是被动的输入。该基准包含1,204个具有挑战性的开放式视觉任务，涵盖五个领域，并提供详细的评估标准。现有MLLMs在需要有效整合视觉和通用工具的任务上表现不佳，即使是最强的模型（GPT-5-think）的通过率也仅为18.68%。评估还揭示了模型在工具使用行为上的差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注“关于图像思考”的范式，即将图像视为静态输入，而忽略了MLLMs在真实场景中处理不完美图像并进行主动图像操作（如裁剪、编辑、增强）以提取视觉线索的需求。此外，MLLMs需要能够“用图像思考”，即动态地转换视觉内容并与其他工具集成以解决复杂任务，而这一方面仍有待探索。

Method: 提出IRIS（Interactive Reasoning with Images and Systems）基准，该基准旨在评估MLLMs在“用图像思考”范式下的交互式推理能力。IRIS包含1,204个具有挑战性的、开放式的视觉任务，分为单轮和多轮，覆盖五个不同的领域。每个任务都配有详细的评分标准，以支持系统化的评估。

Result: 评估结果表明，当前MLLMs在需要有效整合视觉信息和通用工具的任务方面存在显著困难。即使是最先进的模型（GPT-5-think）的通过率也仅达到18.68%。此外，观察到模型在使用工具方面存在行为差异：OpenAI的模型受益于多样化的图像操作，而Gemini-2.5-pro则没有显示出性能提升。

Conclusion: IRIS是第一个以“用图像思考”为中心的基准，它为理解和改进MLLMs的视觉智能提供了关键见解，特别是在处理可操作的视觉内容和与通用工具集成方面。目前的模型在这一新范式上面临挑战，凸显了进一步研究的必要性。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in
real-world scenarios where user-provided images are often imperfect, requiring
active image manipulations such as cropping, editing, or enhancement to uncover
salient visual cues. Beyond static visual perception, MLLMs must also think
with images: dynamically transforming visual content and integrating it with
other tools to solve complex tasks. However, this shift from treating vision as
passive context to a manipulable cognitive workspace remains underexplored.
Most existing benchmarks still follow a think about images paradigm, where
images are regarded as static inputs. To address this gap, we introduce IRIS,
an Interactive Reasoning with Images and Systems that evaluates MLLMs' ability
to perceive, transform, and reason across complex visual-textual tasks under
the think with images paradigm. IRIS comprises 1,204 challenging, open-ended
vision tasks (603 single-turn, 601 multi-turn) spanning across five diverse
domains, each paired with detailed rubrics to enable systematic evaluation. Our
evaluation shows that current MLLMs struggle with tasks requiring effective
integration of vision and general-purpose tools. Even the strongest model
(GPT-5-think) reaches only 18.68% pass rate. We further observe divergent
tool-use behaviors, with OpenAI models benefiting from diverse image
manipulations while Gemini-2.5-pro shows no improvement. By introducing the
first benchmark centered on think with images, IRIS offers critical insights
for advancing visual intelligence in MLLMs.

</details>


### [73] [FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution](https://arxiv.org/abs/2510.12747)
*Junhao Zhuang,Shi Guo,Xin Cai,Xiaohui Li,Yihao Liu,Chun Yuan,Tianfan Xue*

Main category: cs.CV

TL;DR: FlashVSR 是一个高效、可扩展、实时的基于扩散模型的视频超分辨率（VSR）框架，通过蒸馏、稀疏注意力和小型解码器实现，并在 VSR-120K 数据集上进行了训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频超分辨率方法存在延迟高、计算成本高、对超高分辨率泛化能力差等问题，使得其实际应用面临挑战。本研究旨在通过提高效率、可扩展性和实现实时性能，使基于扩散模型的视频超分辨率方法更加实用。

Method: FlashVSR 提出了一种创新的、面向实时 VSR 的单步流式扩散框架。它结合了三个关键技术：1. 易于训练的三阶段蒸馏管线，支持流式超分辨率；2. 约束局部性的稀疏注意力机制，减少冗余计算并缩小训练-测试分辨率差距；3. 小型条件解码器，在不牺牲质量的情况下加速重建。此外，还构建了 VSR-120K 数据集以支持大规模训练。

Result: FlashVSR 在 A100 GPU 上实现了约 17 FPS 的 768x1408 视频处理速度。实验证明，FlashVSR 能够可靠地扩展到超高分辨率，并取得最先进的性能，与先前单步扩散 VSR 模型相比，速度提升高达 12 倍。VSR-120K 是一个包含 120k 个视频和 180k 张图像的新数据集。

Conclusion: FlashVSR 是首个实现实时性能的基于扩散模型的单步流式视频超分辨率框架。通过提出的三种创新技术和 VSR-120K 数据集，FlashVSR 在效率、可扩展性和性能上均超越了现有方法，为高效扩散模型在 VSR 领域的进一步研究奠定了基础。研究团队将公开代码、预训练模型和数据集。

Abstract: Diffusion models have recently advanced video restoration, but applying them
to real-world video super-resolution (VSR) remains challenging due to high
latency, prohibitive computation, and poor generalization to ultra-high
resolutions. Our goal in this work is to make diffusion-based VSR practical by
achieving efficiency, scalability, and real-time performance. To this end, we
propose FlashVSR, the first diffusion-based one-step streaming framework
towards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408
videos on a single A100 GPU by combining three complementary innovations: (i) a
train-friendly three-stage distillation pipeline that enables streaming
super-resolution, (ii) locality-constrained sparse attention that cuts
redundant computation while bridging the train-test resolution gap, and (iii) a
tiny conditional decoder that accelerates reconstruction without sacrificing
quality. To support large-scale training, we also construct VSR-120K, a new
dataset with 120k videos and 180k images. Extensive experiments show that
FlashVSR scales reliably to ultra-high resolutions and achieves
state-of-the-art performance with up to 12x speedup over prior one-step
diffusion VSR models. We will release the code, pretrained models, and dataset
to foster future research in efficient diffusion-based VSR.

</details>


### [74] [SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding](https://arxiv.org/abs/2510.12749)
*Zhiliu Yang,Jinyu Dai,Jianyuan Zhang,Zhu Yang*

Main category: cs.CV

TL;DR: 本论文提出SPORTS框架，通过整合视频全景分割(VPS)、视觉里程计(VO)和场景渲染(SR)来解决现有embodied-AI场景理解的不足。


<details>
  <summary>Details</summary>
Motivation: 现有embodied-AI技术在场景理解方面存在分割缺陷、动态物体干扰、传感器数据稀疏和视角限制等问题。

Method: SPORTS框架整合了VPS、VO和SR三个任务。VPS采用基于注意力的几何融合机制对齐跨帧特征，并集成后匹配策略改进身份跟踪。VO结合VPS的全景分割结果和光流图来提高动态物体置信度估计，从而提升VO和深度图生成的准确性。SR基于VO将稀疏点云转化为神经场，以合成高保真度的RGB视图和全景视图。

Result: 在三个公开数据集上的广泛实验表明，本研究提出的基于注意力的特征融合在里程计、跟踪、分割和新视角合成任务上优于现有的最先进方法。

Conclusion: SPORTS框架通过迭代统一的视角，实现了整体场景理解，并在多个任务上取得了优越性能。

Abstract: The scene perception, understanding, and simulation are fundamental
techniques for embodied-AI agents, while existing solutions are still prone to
segmentation deficiency, dynamic objects' interference, sensor data sparsity,
and view-limitation problems. This paper proposes a novel framework, named
SPORTS, for holistic scene understanding via tightly integrating Video Panoptic
Segmentation (VPS), Visual Odometry (VO), and Scene Rendering (SR) tasks into
an iterative and unified perspective. Firstly, VPS designs an adaptive
attention-based geometric fusion mechanism to align cross-frame features via
enrolling the pose, depth, and optical flow modality, which automatically
adjust feature maps for different decoding stages. And a post-matching strategy
is integrated to improve identities tracking. In VO, panoptic segmentation
results from VPS are combined with the optical flow map to improve the
confidence estimation of dynamic objects, which enhances the accuracy of the
camera pose estimation and completeness of the depth map generation via the
learning-based paradigm. Furthermore, the point-based rendering of SR is
beneficial from VO, transforming sparse point clouds into neural fields to
synthesize high-fidelity RGB views and twin panoptic views. Extensive
experiments on three public datasets demonstrate that our attention-based
feature fusion outperforms most existing state-of-the-art methods on the
odometry, tracking, segmentation, and novel view synthesis tasks.

</details>


### [75] [VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage](https://arxiv.org/abs/2510.12750)
*A. Alfarano,L. Venturoli,D. Negueruela del Castillo*

Main category: cs.CV

TL;DR: 现有的视觉问答基准无法评估大型多模态语言模型（MLLM）在视觉艺术分析等复杂领域深层语义的理解能力，这促使模型利用统计学上的捷径而非进行视觉推理。为此，我们引入了文化遗产领域新的、大规模的视觉问答基准 VQArt-Bench。该基准采用新颖的多代理管线构建，其中专业代理协作生成细致、经过验证且语言多样化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉问答（VQA）基准在评估深层语义理解方面存在不足，尤其是在视觉艺术分析等复杂领域，这促使模型利用统计学上的捷径而非进行视觉推理。

Method: 采用新颖的多代理管线，其中专业代理协作生成细致、经过验证且语言多样化的问题，并沿着相关的视觉理解维度构建基准，以探查模型解释象征意义、叙事和复杂视觉关系的能力。

Result: 在 VQArt-Bench 基准上对 14 个最先进的 MLLM 进行评估，结果显示现有模型存在显著局限性，包括在简单的计数任务中表现出乎意料的薄弱，以及专有模型和开源模型之间明显的性能差距。

Conclusion: 现有的大型多模态语言模型在处理需要深层语义理解的视觉问答任务时存在显著局限性，特别是在文化遗产领域。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
capabilities in joint visual and linguistic tasks. However, existing Visual
Question Answering (VQA) benchmarks often fail to evaluate deep semantic
understanding, particularly in complex domains like visual art analysis.
Confined to simple syntactic structures and surface-level attributes, these
questions fail to capture the diversity and depth of human visual inquiry. This
limitation incentivizes models to exploit statistical shortcuts rather than
engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a
new, large-scale VQA benchmark for the cultural heritage domain. This benchmark
is constructed using a novel multi-agent pipeline where specialized agents
collaborate to generate nuanced, validated, and linguistically diverse
questions. The resulting benchmark is structured along relevant visual
understanding dimensions that probe a model's ability to interpret symbolic
meaning, narratives, and complex visual relationships. Our evaluation of 14
state-of-the-art MLLMs on this benchmark reveals significant limitations in
current models, including a surprising weakness in simple counting tasks and a
clear performance gap between proprietary and open-source models.

</details>


### [76] [E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization](https://arxiv.org/abs/2510.12753)
*Wenpu Li,Bangyan Liao,Yi Zhou,Qi Xu,Pian Wan,Peidong Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为E-MoFlow的无监督框架，用于联合估计事件相机的6-DoF自运动和光流，通过隐式正则化解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统方法独立估计自运动和光流，在事件相机上存在数据关联不足的问题，导致问题无解或性能不佳。现有方法通过变分正则化或结构运动先验来缓解，但前者引入偏差和计算开销，后者易陷入局部最优。

Method: 提出了一种无监督框架E-MoFlow，联合优化自运动和光流。自运动被建模为连续样条，光流被建模为隐式神经表示，通过归纳偏置嵌入时空相干性。通过微分几何约束结合结构运动先验，避免显式深度估计，保持几何一致性。

Result: 实验证明E-MoFlow框架在通用6-DoF运动场景中具有通用性，在无监督方法中达到最先进性能，并且与有监督方法相比也具有竞争力。

Conclusion: E-MoFlow框架通过隐式正则化，在完全无监督的范式下统一了自运动和光流的估计，克服了现有方法的不足，并在实验中取得了优异的性能。

Abstract: The estimation of optical flow and 6-DoF ego-motion, two fundamental tasks in
3D vision, has typically been addressed independently. For neuromorphic vision
(e.g., event cameras), however, the lack of robust data association makes
solving the two problems separately an ill-posed challenge, especially in the
absence of supervision via ground truth. Existing works mitigate this
ill-posedness by either enforcing the smoothness of the flow field via an
explicit variational regularizer or leveraging explicit structure-and-motion
priors in the parametrization to improve event alignment. The former notably
introduces bias in results and computational overhead, while the latter, which
parametrizes the optical flow in terms of the scene depth and the camera
motion, often converges to suboptimal local minima. To address these issues, we
propose an unsupervised framework that jointly optimizes egomotion and optical
flow via implicit spatial-temporal and geometric regularization. First, by
modeling camera's egomotion as a continuous spline and optical flow as an
implicit neural representation, our method inherently embeds spatial-temporal
coherence through inductive biases. Second, we incorporate structure-and-motion
priors through differential geometric constraints, bypassing explicit depth
estimation while maintaining rigorous geometric consistency. As a result, our
framework (called E-MoFlow) unifies egomotion and optical flow estimation via
implicit regularization under a fully unsupervised paradigm. Experiments
demonstrate its versatility to general 6-DoF motion scenarios, achieving
state-of-the-art performance among unsupervised methods and competitive even
with supervised approaches.

</details>


### [77] [PET Head Motion Estimation Using Supervised Deep Learning with Attention](https://arxiv.org/abs/2510.12758)
*Zhuotong Cai,Tianyi Zeng,Jiazhen Zhang,Eléonore V. Lieffrig,Kathryn Fontaine,Chenyu You,Enette Mae Revilla,James S. Duncan,Jingmin Xin,Yihuan Lu,John A. Onofrey*

Main category: cs.CV

TL;DR: 提出了一种名为DL-HMC++的深度学习方法，用于从PET原始数据中预测头部运动，以校正头部运动伪影，并能在多种PET扫描仪和放射性示踪剂上实现泛化。


<details>
  <summary>Details</summary>
Motivation: 头部运动在PET成像中会导致伪影和量化不准确，因此需要有效的头部运动估计和校正方法，但硬件运动跟踪（HMT）在临床实践中的应用有限。

Method: 提出了一种基于深度学习的交叉注意力头部运动校正方法（DL-HMC++），通过利用外部HMT提供的金标准运动测量，在动态PET扫描中以监督学习的方式进行训练，以从一秒的3D PET原始数据中预测刚体头部运动。

Result: DL-HMC++在两种PET扫描仪（HRRT和mCT）和四种放射性示踪剂（18F-FDG, 18F-FPEB, 11C-UCB-J, 和 11C-LSN3172176）上进行了评估，结果表明DL-HMC++优于现有的数据驱动运动估计方法，能够生成无运动伪影的图像，其量化结果与金标准HMT的差异很小（HRRT上为1.2±0.5%，mCT上为0.5±0.2%）。

Conclusion: DL-HMC++有潜力实现数据驱动的PET头部运动校正，无需HMT，从而使临床人群能够更方便地进行运动校正，而不仅仅局限于研究环境。

Abstract: Head movement poses a significant challenge in brain positron emission
tomography (PET) imaging, resulting in image artifacts and tracer uptake
quantification inaccuracies. Effective head motion estimation and correction
are crucial for precise quantitative image analysis and accurate diagnosis of
neurological disorders. Hardware-based motion tracking (HMT) has limited
applicability in real-world clinical practice. To overcome this limitation, we
propose a deep-learning head motion correction approach with cross-attention
(DL-HMC++) to predict rigid head motion from one-second 3D PET raw data.
DL-HMC++ is trained in a supervised manner by leveraging existing dynamic PET
scans with gold-standard motion measurements from external HMT. We evaluate
DL-HMC++ on two PET scanners (HRRT and mCT) and four radiotracers (18F-FDG,
18F-FPEB, 11C-UCB-J, and 11C-LSN3172176) to demonstrate the effectiveness and
generalization of the approach in large cohort PET studies. Quantitative and
qualitative results demonstrate that DL-HMC++ consistently outperforms
state-of-the-art data-driven motion estimation methods, producing motion-free
images with clear delineation of brain structures and reduced motion artifacts
that are indistinguishable from gold-standard HMT. Brain region of interest
standard uptake value analysis exhibits average difference ratios between
DL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT and 0.5
plus-minus 0.2% for mCT. DL-HMC++ demonstrates the potential for data-driven
PET head motion correction to remove the burden of HMT, making motion
correction accessible to clinical populations beyond research settings. The
code is available at https://github.com/maxxxxxxcai/DL-HMC-TMI.

</details>


### [78] [SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models](https://arxiv.org/abs/2510.12784)
*Weiyang Jin,Yuwei Niu,Jiaqi Liao,Chengqi Duan,Aoxue Li,Shenghua Gao,Xihui Liu*

Main category: cs.CV

TL;DR: SRUM框架通过利用模型自身的理解模块来指导和增强其生成能力，实现了统一多模态模型（UMMs）的自改进。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型（UMMs）在视觉理解和视觉生成之间存在差距，即模型可能理解图像但无法根据文本提示生成图像。因此，需要一种能够弥合这一差距并实现自我改进的方法。

Method: SRUM框架通过创建一种反馈循环，让模型的理解模块充当内部“评估者”，为生成模块提供纠正信号，从而实现自我改进。该框架设计了一个全局-局部双奖励系统，通过全局奖励确保整体视觉语义和布局的正确性，并通过局部奖励优化细节的对象级保真度。

Result: SRUM框架将T2I-CompBench的性能从82.18%提高到88.37%，将T2I-ReasonBench的性能从43.82%提高到46.75%。

Conclusion: SRUM框架提供了一种新的范式，使UMMs的理解模块能够通过自我奖励来指导和增强其自身的生成能力。

Abstract: Recently, remarkable progress has been made in Unified Multimodal Models
(UMMs), which integrate vision-language generation and understanding
capabilities within a single framework. However, a significant gap exists where
a model's strong visual understanding often fails to transfer to its visual
generation. A model might correctly understand an image based on user
instructions, yet be unable to generate a faithful image from text prompts.
This phenomenon directly raises a compelling question: Can a model achieve
self-improvement by using its understanding module to reward its generation
module? To bridge this gap and achieve self-improvement, we introduce SRUM, a
self-rewarding post-training framework that can be directly applied to existing
UMMs of various designs. SRUM creates a feedback loop where the model's own
understanding module acts as an internal ``evaluator'', providing corrective
signals to improve its generation module, without requiring additional
human-labeled data. To ensure this feedback is comprehensive, we designed a
global-local dual reward system. To tackle the inherent structural complexity
of images, this system offers multi-scale guidance: a \textbf{global reward}
ensures the correctness of the overall visual semantics and layout, while a
\textbf{local reward} refines fine-grained, object-level fidelity. SRUM leads
to powerful capabilities and shows strong generalization, boosting performance
on T2I-CompBench from 82.18 to \textbf{88.37} and on T2I-ReasonBench from 43.82
to \textbf{46.75}. Overall, our work establishes a powerful new paradigm for
enabling a UMMs' understanding module to guide and enhance its own generation
via self-rewarding.

</details>


### [79] [AnyUp: Universal Feature Upsampling](https://arxiv.org/abs/2510.12764)
*Thomas Wimmer,Prune Truong,Marie-Julie Rakotosaona,Michael Oechsle,Federico Tombari,Bernt Schiele,Jan Eric Lenssen*

Main category: cs.CV

TL;DR: AnyUp是一种通用的特征上采样方法，无需针对特定编码器进行训练，可应用于任何分辨率的视觉特征，并达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的上采样器需要为每个特征提取器重新训练，无法泛化到不同类型的特征。

Method: 提出了一种推理时特征无关的上采样架构AnyUp，以解决现有方法的局限性并提高上采样质量。

Result: AnyUp在各种下游任务上实现了最先进的上采样特征，泛化能力强，能保留特征语义，并且高效易用。

Conclusion: AnyUp通过其特征无关和高效的特性，为各种下游任务提供了通用的解决方案。

Abstract: We introduce AnyUp, a method for feature upsampling that can be applied to
any vision feature at any resolution, without encoder-specific training.
Existing learning-based upsamplers for features like DINO or CLIP need to be
re-trained for every feature extractor and thus do not generalize to different
feature types at inference time. In this work, we propose an inference-time
feature-agnostic upsampling architecture to alleviate this limitation and
improve upsampling quality. In our experiments, AnyUp sets a new state of the
art for upsampled features, generalizes to different feature types, and
preserves feature semantics while being efficient and easy to apply to a wide
range of downstream tasks.

</details>


### [80] [Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark](https://arxiv.org/abs/2510.12765)
*Bruno Longarela,Marcos V. Conde,Alvaro Garcia,Radu Timofte*

Main category: cs.CV

TL;DR: 本研究提出了高效感知超分辨率（EPSR）的基准测试，旨在缩小现有高效PSNR导向方法与感知质量指标方法之间的效率差距。研究目标是在参数量不超过5M、计算量不超过2000 GFLOPs（输入尺寸960x540）的限制下，达到或超越Real-ESRGAN的感知效果。


<details>
  <summary>Details</summary>
Motivation: 现有针对感知质量指标的超分辨率方法效率不高，与PSNR导向的方法相比存在差距。

Method: 在参数量和计算量受限的情况下，提出并评估了能够达到或超越Real-ESRGAN感知效果的超分辨率方法。评估在包含500张4K分辨率图像的新数据集上进行，该数据集包含多种退化类型，并且不提供原始高质量图像，以模拟真实部署条件。

Result: 提出的方法在所有基准数据集上均优于Real-ESRGAN，证明了高效方法在感知领域的潜力。

Conclusion: 本研究为高效感知超分辨率树立了新的基准。

Abstract: This paper presents a comprehensive study and benchmark on Efficient
Perceptual Super-Resolution (EPSR). While significant progress has been made in
efficient PSNR-oriented super resolution, approaches focusing on perceptual
quality metrics remain relatively inefficient. Motivated by this gap, we aim to
replicate or improve the perceptual results of Real-ESRGAN while meeting strict
efficiency constraints: a maximum of 5M parameters and 2000 GFLOPs, calculated
for an input size of 960x540 pixels. The proposed solutions were evaluated on a
novel dataset consisting of 500 test images of 4K resolution, each degraded
using multiple degradation types, without providing the original high-quality
counterparts. This design aims to reflect realistic deployment conditions and
serves as a diverse and challenging benchmark. The top-performing approach
manages to outperform Real-ESRGAN across all benchmark datasets, demonstrating
the potential of efficient methods in the perceptual domain. This paper
establishes the modern baselines for efficient perceptual super resolution.

</details>


### [81] [What If : Understanding Motion Through Sparse Interactions](https://arxiv.org/abs/2510.12777)
*Stefan Andreas Baumann,Nick Stracke,Timy Phan,Björn Ommer*

Main category: cs.CV

TL;DR: FPT是一个新颖的框架，用于直接预测由稀疏交互“戳”引起的局部运动分布，能够生成多模式场景运动，并可用于多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 理解物理场景的动态性，特别是其如何因局部相互作用而变化。

Method: 提出了一种名为FPT的新颖框架，用于直接预测由稀疏交互“戳”引起的局部运动分布。该模型能够提供场景多模式运动的可解释表示，并阐明其对物理交互的依赖性以及场景动态性的不确定性。

Result: FPT在密集人脸运动生成任务上超越了专门的基线模型。通过对特定任务进行微调，FPT在关节物体运动估计任务上显著优于现有方法。此外，FPT在基于“戳”的运动部件分割任务上取得了有竞争力的性能。

Conclusion: FPT框架能够直接预测多模式场景运动，并能适应多种下游任务，展示了其灵活性和通用性。

Abstract: Understanding the dynamics of a physical scene involves reasoning about the
diverse ways it can potentially change, especially as a result of local
interactions. We present the Flow Poke Transformer (FPT), a novel framework for
directly predicting the distribution of local motion, conditioned on sparse
interactions termed "pokes". Unlike traditional methods that typically only
enable dense sampling of a single realization of scene dynamics, FPT provides
an interpretable directly accessible representation of multi-modal scene
motion, its dependency on physical interactions and the inherent uncertainties
of scene dynamics. We also evaluate our model on several downstream tasks to
enable comparisons with prior methods and highlight the flexibility of our
approach. On dense face motion generation, our generic pre-trained model
surpasses specialized baselines. FPT can be fine-tuned in strongly
out-of-distribution tasks such as synthetic datasets to enable significant
improvements over in-domain methods in articulated object motion estimation.
Additionally, predicting explicit motion distributions directly enables our
method to achieve competitive performance on tasks like moving part
segmentation from pokes which further demonstrates the versatility of our FPT.
Code and models are publicly available at
https://compvis.github.io/flow-poke-transformer.

</details>


### [82] [Efficient Real-World Deblurring using Single Images: AIM 2025 Challenge Report](https://arxiv.org/abs/2510.12788)
*Daniel Feijoo,Paula Garrido-Mellado,Marcos V. Conde,Jaesung Rim,Alvaro Garcia,Sunghyun Cho,Radu Timofte*

Main category: cs.CV

TL;DR: 该论文对AIM 2025高效真实世界单图像去模糊挑战赛进行了回顾，该挑战赛旨在推进高效真实模糊图像恢复技术。


<details>
  <summary>Details</summary>
Motivation: 本次挑战赛旨在解决高效真实模糊图像恢复问题，并推动相关技术的发展。

Method: 挑战赛基于使用双摄像头系统捕获的模糊和降质图像对的新测试集（源自RSBlur数据集），参赛者需要开发满足模型参数少于500万且计算预算低于200 GMACs的严格效率限制的解决方案。

Result: 共有71名参赛者注册，最终有4个团队提交了有效解决方案。性能最佳的方法达到了31.1298 dB的PSNR。

Conclusion: 该论文全面概述了此次挑战赛，比较了提出的解决方案，为高效真实世界图像去模糊领域的研究人员提供了宝贵的参考。

Abstract: This paper reviews the AIM 2025 Efficient Real-World Deblurring using Single
Images Challenge, which aims to advance in efficient real-blur restoration. The
challenge is based on a new test set based on the well known RSBlur dataset.
Pairs of blur and degraded images in this dataset are captured using a
double-camera system. Participant were tasked with developing solutions to
effectively deblur these type of images while fulfilling strict efficiency
constraints: fewer than 5 million model parameters and a computational budget
under 200 GMACs. A total of 71 participants registered, with 4 teams finally
submitting valid solutions. The top-performing approach achieved a PSNR of
31.1298 dB, showcasing the potential of efficient methods in this domain. This
paper provides a comprehensive overview of the challenge, compares the proposed
solutions, and serves as a valuable reference for researchers in efficient
real-world image deblurring.

</details>


### [83] [UniFusion: Vision-Language Model as Unified Encoder in Image Generation](https://arxiv.org/abs/2510.12789)
*Kevin Li,Manuel Brack,Sudeep Katakol,Hareesh Ravi,Ajinkya Kale*

Main category: cs.CV

TL;DR: UniFusion是一个基于扩散的模型，它利用一个冻结的大型视觉语言模型（VLM）作为统一的多模态编码器，解决了现有模型在跨模态推理和知识转移方面的限制。它引入了层级注意力池（LAP）机制来提取VLM中的高层语义和低层细节，并提出了VERIFI方法，在模型内提示重写期间仅使用VLM生成的文本标记来条件化扩散Transformer（DiT）。UniFusion在文本-图像对齐、视觉信息迁移和编辑任务上表现出色，并且在单图像编辑上进行了微调后，可以零样本泛化到多图像引用，证明了其统一编码器设计的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉生成模型通常需要独立的图像和文本编码器，这限制了它们进行跨模态推理和知识转移的能力。之前的解决方案要么依赖于VLM的浅层信息，要么需要训练大型的统一模型，这些方法计算成本高且需要大量数据。

Method: UniFusion使用一个冻结的大型视觉语言模型（VLM）作为统一的多模态编码器，并引入了层级注意力池（LAP）机制来提取VLM中文本和视觉标记的高层语义和低层细节，以条件化扩散生成模型。此外，还提出了VERIFI方法，在模型内提示重写期间，仅使用VLM生成的文本标记来条件化扩散Transformer（DiT）。

Result: UniFusion在文本-图像对齐和视觉信息迁移方面优于其他浅层融合架构。VERIFI结合了条件分布的对齐和VLM的推理能力，提高了推理能力和灵活性。在编辑任务上进行微调不仅改善了文本-图像对齐，还展现了出色的泛化能力，即使在单图像编辑上训练的模型也能零样本泛化到多图像引用。

Conclusion: UniFusion通过利用冻结的VLM作为统一编码器，并结合LAP和VERIFI机制，有效地克服了现有模型的局限性，实现了强大的跨模态推理、知识转移和编辑能力，并且具有良好的泛化性。这证明了统一编码器设计的有效性。

Abstract: Although recent advances in visual generation have been remarkable, most
existing architectures still depend on distinct encoders for images and text.
This separation constrains diffusion models' ability to perform cross-modal
reasoning and knowledge transfer. Prior attempts to bridge this gap often use
the last layer information from VLM, employ multiple visual encoders, or train
large unified models jointly for text and image generation, which demands
substantial computational resources and large-scale data, limiting its
accessibility.We present UniFusion, a diffusion-based generative model
conditioned on a frozen large vision-language model (VLM) that serves as a
unified multimodal encoder. At the core of UniFusion is the Layerwise Attention
Pooling (LAP) mechanism that extracts both high level semantics and low level
details from text and visual tokens of a frozen VLM to condition a diffusion
generative model. We demonstrate that LAP outperforms other shallow fusion
architectures on text-image alignment for generation and faithful transfer of
visual information from VLM to the diffusion model which is key for editing. We
propose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI),
which conditions a diffusion transformer (DiT) only on the text tokens
generated by the VLM during in-model prompt rewriting. VERIFI combines the
alignment of the conditioning distribution with the VLM's reasoning
capabilities for increased capabilities and flexibility at inference. In
addition, finetuning on editing task not only improves text-image alignment for
generation, indicative of cross-modality knowledge transfer, but also exhibits
tremendous generalization capabilities. Our model when trained on single image
editing, zero-shot generalizes to multiple image references further motivating
the unified encoder design of UniFusion.

</details>


### [84] [ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution](https://arxiv.org/abs/2510.12793)
*Long Cui,Weiyun Wang,Jie Shao,Zichen Wen,Gen Luo,Linfeng Zhang,Yanting Zhang,Yu Qiao,Wenhai Wang*

Main category: cs.CV

TL;DR: ViCO算法通过使用多个MLP连接器来根据图像的语义复杂度动态调整视觉标记的数量，从而降低了多模态大语言模型的推理成本，同时保持了模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）由于引入了额外的图像视觉标记，导致推理成本增加。本研究旨在解决这一问题。

Method: 提出了一种名为Visual Consistency Learning（ViCO）的新颖训练算法。该算法使用多个具有不同图像压缩率的MLP连接器，根据图像的语义复杂度对视觉标记进行降采样。在训练过程中，通过最小化不同MLP连接器条件下响应之间的KL散度来优化模型。在推理时，引入了一个名为Visual Resolution Router（ViR）的图像路由器，自动为每个图像块选择合适的压缩率。

Result: ViCO算法能够将视觉标记的数量减少多达50%，同时保持模型在感知、推理和OCR方面的能力。与现有的基于图像分辨率调整视觉标记数量的动态高分辨率策略相比，ViCO根据语义复杂度动态调整视觉标记数量。

Conclusion: ViCO是一种有效的算法，可以显著降低多模态大语言模型的推理成本，同时保持其性能，有望促进更高效的MLLMs的发展。

Abstract: Existing Multimodal Large Language Models (MLLMs) suffer from increased
inference costs due to the additional vision tokens introduced by image inputs.
In this work, we propose Visual Consistency Learning (ViCO), a novel training
algorithm that enables the model to represent images of varying semantic
complexities using different numbers of vision tokens. The key idea behind our
method is to employ multiple MLP connectors, each with a different image
compression ratio, to downsample the vision tokens based on the semantic
complexity of the image. During training, we minimize the KL divergence between
the responses conditioned on different MLP connectors. At inference time, we
introduce an image router, termed Visual Resolution Router (ViR), that
automatically selects the appropriate compression rate for each image patch.
Compared with existing dynamic high-resolution strategies, which adjust the
number of visual tokens based on image resolutions, our method dynamically
adapts the number of visual tokens according to semantic complexity.
Experimental results demonstrate that our method can reduce the number of
vision tokens by up to 50% while maintaining the model's perception, reasoning,
and OCR capabilities. We hope this work will contribute to the development of
more efficient MLLMs. The code and models will be released to facilitate future
research.

</details>


### [85] [CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations](https://arxiv.org/abs/2510.12795)
*Caner Korkmaz,Brighton Nuwagira,Barış Coşkunuzer,Tolga Birdal*

Main category: cs.CV

TL;DR: CuMPerLay是一个可微分向量化层，用于将立方体多参数持久性（CMP）集成到深度学习中，解决了CMP的复杂性和向量化挑战，并在医学成像和计算机视觉任务中提高了分类和分割性能，尤其是在数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: CMP在拓扑上处理图像方面功能强大，但其使用受到多重过滤结构复杂性和CMP向量化问题的阻碍。

Method: 提出了一种新的算法来向量化立方体复形的MP同调。CuMPerLay将CMP分解为单个、可学习的单参数持久性的组合，并联合学习双重过滤函数。该层是可微分的，并提供了向量化算法的理论稳定性保证。

Result: 在医学成像和计算机视觉基准数据集上的实验表明，CuMPerLay在分类和分割任务上显示出优势，特别是在数据有限的情况下。

Conclusion: CuMPerLay为将全局结构信息集成到深度网络中以进行结构化图像分析提供了一个有前景的方向。

Abstract: We present CuMPerLay, a novel differentiable vectorization layer that enables
the integration of Cubical Multiparameter Persistence (CMP) into deep learning
pipelines. While CMP presents a natural and powerful way to topologically work
with images, its use is hindered by the complexity of multifiltration
structures as well as the vectorization of CMP. In face of these challenges, we
introduce a new algorithm for vectorizing MP homologies of cubical complexes.
Our CuMPerLay decomposes the CMP into a combination of individual, learnable
single-parameter persistence, where the bifiltration functions are jointly
learned. Thanks to the differentiability, its robust topological feature
vectors can be seamlessly used within state-of-the-art architectures such as
Swin Transformers. We establish theoretical guarantees for the stability of our
vectorization under generalized Wasserstein metrics. Our experiments on
benchmark medical imaging and computer vision datasets show the benefit
CuMPerLay on classification and segmentation performance, particularly in
limited-data scenarios. Overall, CuMPerLay offers a promising direction for
integrating global structural information into deep networks for structured
image analysis.

</details>


### [86] [DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving](https://arxiv.org/abs/2510.12796)
*Yingyan Li,Shuyao Shang,Weisong Liu,Bing Zhan,Haochen Wang,Yuqi Wang,Yuntao Chen,Xiaoman Wang,Yasong An,Chufeng Tang,Lu Hou,Lue Fan,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: DriveVLA-W0通过引入世界建模来解决视觉-语言-动作（VLA）模型中的“监督不足”问题，通过预测未来图像来产生密集的自监督信号，从而学习驾驶环境的动力学。该范式可应用于自回归和扩散模型，并结合了轻量级的动作专家以实现实时部署。实验表明，DriveVLA-W0在数据集和BEV/VLA基线上均表现优越，并能放大数据的扩展规律。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型在自动驾驶领域具有巨大潜力，但存在“监督不足”的问题，即模型容量与其监督信号（稀疏、低维度的动作）之间存在差距，导致模型表示能力未被充分利用。

Method: 提出DriveVLA-W0训练范式，采用世界建模来预测未来图像，生成密集的自监督信号，迫使模型学习驾驶环境的动力学。该范式分别应用于基于离散视觉标记的自回归世界模型和基于连续视觉特征的扩散世界模型。在此基础上，引入轻量级动作专家以解决实时部署的推理延迟问题。

Result: 在NAVSIM v1/v2基准和规模大680倍的内部数据集中进行的大量实验表明，DriveVLA-W0显著优于BEV和VLA基线模型。关键在于，它放大了数据扩展规律，表明随着训练数据集规模的增加，性能增益会加速。

Conclusion: DriveVLA-W0通过世界建模有效解决了VLA模型的监督不足问题，提高了模型性能，并证实了其在扩大训练数据规模时能够带来更显著的性能提升，为实现更通用的驾驶智能提供了有前景的途径。

Abstract: Scaling Vision-Language-Action (VLA) models on large-scale data offers a
promising path to achieving a more generalized driving intelligence. However,
VLA models are limited by a ``supervision deficit'': the vast model capacity is
supervised by sparse, low-dimensional actions, leaving much of their
representational power underutilized. To remedy this, we propose
\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to
predict future images. This task generates a dense, self-supervised signal that
compels the model to learn the underlying dynamics of the driving environment.
We showcase the paradigm's versatility by instantiating it for two dominant VLA
archetypes: an autoregressive world model for VLAs that use discrete visual
tokens, and a diffusion world model for those operating on continuous visual
features. Building on the rich representations learned from world modeling, we
introduce a lightweight action expert to address the inference latency for
real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a
680x larger in-house dataset demonstrate that DriveVLA-W0 significantly
outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling
law, showing that performance gains accelerate as the training dataset size
increases.

</details>


### [87] [Detect Anything via Next Point Prediction](https://arxiv.org/abs/2510.12798)
*Qing Jiang,Junan Huo,Xingyu Chen,Yuda Xiong,Zhaoyang Zeng,Yihao Chen,Tianhe Ren,Junzhi Yu,Lei Zhang*

Main category: cs.CV

TL;DR: Rex-Omni是一个3B规模的多模态大语言模型，在目标检测任务上取得了最先进的性能，并且在零样本设置下与传统回归模型相当甚至超越。


<details>
  <summary>Details</summary>
Motivation: 传统的坐标回归模型在目标检测领域占据主导地位，但现有的多模态大语言模型（MLLMs）在处理此任务时存在召回率低、重复预测、坐标对齐错误等问题。本项目旨在弥合这一差距，提出Rex-Omni模型。

Method: Rex-Omni模型采用了三种关键设计：1) 任务制定：使用特殊标记表示0到999的量化坐标，降低学习难度并提高坐标预测的效率。2) 数据引擎：构建了多种数据引擎，生成高质量的接地、指代和定位数据，提供丰富的语义监督。3) 训练流程：采用两阶段训练，包括在2200万数据上进行监督微调（SFT）和基于GRPO的强化后训练，利用几何感知奖励来缩小离散到连续的坐标预测差距，提高框的准确性，并减少SFT阶段的教师引导带来的重复预测等问题。

Result: Rex-Omni在COCO和LVIS等基准测试中，在零样本设置下实现了与DINO、Grounding DINO等回归模型相当甚至更优的性能。此外，Rex-Omni还展示了目标指代、定位、视觉提示、GUI接地、空间指代、OCR和关键点定位等多种能力，并在专门的基准测试中得到了系统性评估。

Conclusion: Rex-Omni模型为更通用、更具语言感知能力 的视觉感知系统铺平了道路。

Abstract: Object detection has long been dominated by traditional coordinate
regression-based models, such as YOLO, DETR, and Grounding DINO. Although
recent efforts have attempted to leverage MLLMs to tackle this task, they face
challenges like low recall rate, duplicate predictions, coordinate
misalignment, etc. In this work, we bridge this gap and propose Rex-Omni, a
3B-scale MLLM that achieves state-of-the-art object perception performance. On
benchmarks like COCO and LVIS, Rex-Omni attains performance comparable to or
exceeding regression-based models (e.g., DINO, Grounding DINO) in a zero-shot
setting. This is enabled by three key designs: 1) Task Formulation: we use
special tokens to represent quantized coordinates from 0 to 999, reducing the
model's learning difficulty and improving token efficiency for coordinate
prediction; 2) Data Engines: we construct multiple data engines to generate
high-quality grounding, referring, and pointing data, providing semantically
rich supervision for training; \3) Training Pipelines: we employ a two-stage
training process, combining supervised fine-tuning on 22 million data with
GRPO-based reinforcement post-training. This RL post-training leverages
geometry-aware rewards to effectively bridge the discrete-to-continuous
coordinate prediction gap, improve box accuracy, and mitigate undesirable
behaviors like duplicate predictions that stem from the teacher-guided nature
of the initial SFT stage. Beyond conventional detection, Rex-Omni's inherent
language understanding enables versatile capabilities such as object referring,
pointing, visual prompting, GUI grounding, spatial referring, OCR and
key-pointing, all systematically evaluated on dedicated benchmarks. We believe
that Rex-Omni paves the way for more versatile and language-aware visual
perception systems.

</details>


### [88] [DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search](https://arxiv.org/abs/2510.12801)
*Kartik Narayan,Yang Xu,Tian Cao,Kavya Nerella,Vishal M. Patel,Navid Shiee,Peter Grasch,Chao Jia,Yinfei Yang,Zhe Gan*

Main category: cs.CV

TL;DR: DeepMMSearch-R1是首个能够执行按需、多轮网络搜索并动态生成图像和文本搜索查询的多模态大语言模型，解决了现有方法中存在的管道僵化、搜索调用过多和查询构建不佳等问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用中的多模态大语言模型（MLLMs）需要访问外部知识，并能响应动态变化的现实世界信息，以处理信息检索和知识密集型用户查询。现有方法存在效率低下和结果不佳的问题。

Method: 提出了一种名为DeepMMSearch-R1的模型，该模型能够按需进行多轮网络搜索，并动态地为图像和文本搜索工具生成查询。该模型在一个两阶段的训练流程中进行训练：冷启动监督微调阶段，然后是在线强化学习优化阶段。为了训练，引入了一个名为DeepMMSearchVQA的新型多模态VQA数据集。

Result: 在知识密集型基准测试中进行了广泛的实验，证明了该方法的优越性。

Conclusion: DeepMMSearch-R1通过按需进行多轮网络搜索和动态查询生成，解决了现有MLLMs在处理现实世界信息检索方面的局限性，并在实验中展现出优越性能，为多模态网络搜索的研究提供了有价值的见解。

Abstract: Multimodal Large Language Models (MLLMs) in real-world applications require
access to external knowledge sources and must remain responsive to the dynamic
and ever-changing real-world information in order to address
information-seeking and knowledge-intensive user queries. Existing approaches,
such as retrieval augmented generation (RAG) methods, search agents, and search
equipped MLLMs, often suffer from rigid pipelines, excessive search calls, and
poorly constructed search queries, which result in inefficiencies and
suboptimal outcomes. To address these limitations, we present DeepMMSearch-R1,
the first multimodal LLM capable of performing on-demand, multi-turn web
searches and dynamically crafting queries for both image and text search tools.
Specifically, DeepMMSearch-R1 can initiate web searches based on relevant crops
of the input image making the image search more effective, and can iteratively
adapt text search queries based on retrieved information, thereby enabling
self-reflection and self-correction. Our approach relies on a two-stage
training pipeline: a cold start supervised finetuning phase followed by an
online reinforcement learning optimization. For training, we introduce
DeepMMSearchVQA, a novel multimodal VQA dataset created through an automated
pipeline intermixed with real-world information from web search tools. This
dataset contains diverse, multi-hop queries that integrate textual and visual
information, teaching the model when to search, what to search for, which
search tool to use and how to reason over the retrieved information. We conduct
extensive experiments across a range of knowledge-intensive benchmarks to
demonstrate the superiority of our approach. Finally, we analyze the results
and provide insights that are valuable for advancing multimodal web-search.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [89] [PHANTOM RECALL: When Familiar Puzzles Fool Smart Models](https://arxiv.org/abs/2510.11812)
*Souradeep Mukhopadhyay,Rishabh Baral,Nimeesh Mahajan,Samhitha Harish,Aswin RRV,Mihir Parmar,Mutsumi Nakamura,Chitta Baral*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在解决经典逻辑谜题时表现出“幻觉回忆”的脆弱性，它们依赖记忆模板而非真正推理，即使是微小的扰动也会导致性能骤降。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在解决逻辑谜题时是否存在真正的推理能力，还是仅仅依赖记忆模板，以及探究其性能的脆弱性。

Method: 引入“幻觉回忆”基准，包含25个经典逻辑谜题和149个扰动版本，并开发了自动化逻辑等价性判断器、细粒度推理错误分类以及基于这些分类的提示缓解框架，以系统性地评估和缓解LLMs的推理问题。

Result: 在未修改的谜题上，LLMs表现接近完美；但在扰动版本上，它们的表现远不如人类，表现出“幻觉回忆”和过度阐述的模式。

Conclusion: LLMs在上下文线索转移时常常无法重新推理，这表明它们在语言流畅性和逻辑理解之间存在巨大差距，其解决逻辑谜题的能力存在关键局限性。

Abstract: Large language models (LLMs) such as GPT, Gemini, and Claude often appear
adept at solving classic logic puzzles--but how much genuine reasoning
underlies their answers? Recent evidence suggests that these models frequently
rely on memorized templates rather than reasoning from first principles. When
puzzles are slightly modified, their performance collapses, revealing a
striking fragility. In particular, we asked: Have LLMs addressed these issues?
To what extent? How about perturbations to other puzzles? Is there a general
way of reformulating the prompt so that the models do better? To examine these
things systematically, we introduce PHANTOM RECALL, a benchmark comprising 25
well-known logic puzzles and 149 carefully designed perturbations that preserve
reasoning structure but alter superficial details and solutions. We evaluate
eleven leading LLMs and identify a recurring failure mode--phantom
recall--where models confidently reproduce memorized solutions or spurious
rationales that no longer fit the altered scenario. To probe and mitigate this
issue, we contribute three tools: (i) an automated logical-equivalence judge to
detect reasoning mismatches, (ii) a taxonomy of fine-grained reasoning error
categories, and (iii) a prompting-based mitigation framework guided by these
categories. Despite near-perfect accuracy on unmodified puzzles, models
significantly underperform humans on perturbed ones, exhibiting both phantom
recall and over-elaboration. Our findings reveal a crucial limitation: LLMs
often fail to re-reason when contextual cues shift--highlighting the gap
between linguistic fluency and logical understanding.

</details>


### [90] [R-WoM: Retrieval-augmented World Model For Computer-use Agents](https://arxiv.org/abs/2510.11892)
*Kai Mei,Jiang Guo,Shuaichen Chang,Mingwen Dong,Dongkyu Lee,Xing Niu,Jiarong Jiang*

Main category: cs.CL

TL;DR: LLMs are limited in long-horizon world modeling due to hallucinations and static knowledge. A retrieval-augmented approach (R-WoM) grounding LLMs with external knowledge improves simulation accuracy and performance, especially for longer tasks.


<details>
  <summary>Details</summary>
Motivation: To investigate the suitability of LLMs for world modeling in agent decision-making and address their limitations in simulating future states and predicting outcomes over long horizons.

Method: Evaluated LLMs on next-state identification, full-procedure planning alignment, and milestone transition recognition. Proposed Retrieval-augmented World Model (R-WoM) to ground LLM simulations with external knowledge.

Result: LLMs effectively predict immediate next states and identify meaningful transitions, but struggle with long-horizon planning. R-WoM significantly improves performance, achieving up to 25.3% gains on OSWorld and 18.1% on WebArena, especially in longer simulations.

Conclusion: LLMs have potential as world models but require augmentation with external knowledge (like R-WoM) to overcome limitations in long-horizon simulations and reduce compounding errors from hallucinations and static knowledge.

Abstract: Large Language Models (LLMs) can serve as world models to enhance agent
decision-making in digital environments by simulating future states and
predicting action outcomes, potentially eliminating costly trial-and-error
exploration. However, this capability is fundamentally limited by LLMs'
tendency toward hallucination and their reliance on static training knowledge,
which can lead to compounding errors that inhibit long-horizon simulations. To
systematically investigate whether LLMs are appropriate for world modeling, we
probe two core capabilities of world models--future state prediction and reward
estimation--through three tasks: next-state identification, full-procedure
planning alignment, and milestone transition recognition. Our analysis shows
that while LLMs effectively capture immediate next states and identify
meaningful state transitions, their performance rapidly degrades in
full-procedure planning. This highlights LLMs' limitations in reliably modeling
environment dynamics over long horizons. To address these limitations, we
propose the Retrieval-augmented World Model (R-WoM), which grounds LLM
simulations by incorporating factual, up-to-date knowledge retrieved from
external tutorials. Experiments show that R-WoM achieves substantial
improvements of up to 25.3% (OSWorld) and 18.1% (WebArena) compared to
baselines, with particular advantages in longer-horizon simulations.

</details>


### [91] [LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance](https://arxiv.org/abs/2510.11905)
*Patrick Haller,Mark Ibrahim,Polina Kirichenko,Levent Sagun,Samuel J. Bell*

Main category: cs.CL

TL;DR: LLM的知识表征在面对和预训练数据分布不同的样本时会崩溃，导致其区分真伪的能力下降，这可能是LLM在基准测试中表现不稳健的原因。


<details>
  <summary>Details</summary>
Motivation: 为了让大型语言模型（LLM）可靠，它们必须学会能够广泛应用于各种设置的鲁棒知识，而这些设置通常与训练期间遇到的设置不同。然而，大量研究表明LLM的性能可能很脆弱，模型对细微的输入变化表现出过度敏感。本研究旨在探讨这种脆弱性是否是由于内部知识表征不稳定的直接结果。

Method: 通过评估在经过表面转换（例如，拼写错误或改写）以使其脱离分布（OOD）的样本上，知识表征的区分能力是否稳健。具体来说，我们应用了语义保留的扰动，研究了在四个LLM家族、五个评估数据集和三种知识探测方法中，随着样本的OOD程度增加，区分能力如何下降。

Result: 研究结果表明，当样本的表征形式与预训练数据中的相似性降低时，语句真实性的内部表征会崩溃。虽然LLM通常能够区分真假陈述，但这种能力高度依赖于陈述的确切表面形式。

Conclusion: LLM可能学会了浅层、不鲁棒的知识表征，这限制了其泛化能力。这项工作对真实性探测器的实用性提出了根本性的挑战，并广泛呼吁进一步研究以提高所学知识表征的鲁棒性。

Abstract: For Large Language Models (LLMs) to be reliable, they must learn robust
knowledge that can be generally applied in diverse settings -- often unlike
those seen during training. Yet, extensive research has shown that LLM
performance can be brittle, with models exhibiting excessive sensitivity to
trivial input variations. In this work, we explore whether this brittleness is
a direct result of unstable internal knowledge representations. To explore this
question, we build on previous work showing that LLM representations encode
statement truthfulness -- i.e., true, factual statements can be easily
separated from false, inaccurate ones. Specifically, we test the robustness of
learned knowledge by evaluating representation separability on samples that
have undergone superficial transformations to drive them out-of-distribution
(OOD), such as typos or reformulations. By applying semantically-preserving
perturbations, we study how separability degrades as statements become more
OOD, across four LLM families, five evaluation datasets, and three knowledge
probing methods. Our results reveal that internal representations of statement
truthfulness collapse as the samples' presentations become less similar to
those seen during pre-training. While LLMs can often distinguish between true
and false statements when they closely resemble the pre-training data, this
ability is highly dependent on the statement's exact surface form. These
findings offer a possible explanation for brittle benchmark performance: LLMs
may learn shallow, non-robust knowledge representations that allow for only
limited generalizability. Our work presents a fundamental challenge for the
utility of truthfulness probes, and more broadly, calls for further research on
improving the robustness of learned knowledge representations.

</details>


### [92] [LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens](https://arxiv.org/abs/2510.11919)
*Armel Zebaze,Rachel Bawden,Benoît Sagot*

Main category: cs.CL

TL;DR: 大型推理模型（LRM）在机器翻译（MT）任务中，通过生成中间“思考”代币并不能提升翻译性能，但结合特定模块的提示策略可以提高翻译效果。精炼目标翻译或扩展平行语料库比蒸馏其思考过程的解释更有影响力。


<details>
  <summary>Details</summary>
Motivation: LRM在数学和代码任务中表现出色，但在机器翻译（MT）任务中的应用仍有待探索。本研究旨在探究在多语言对和多设置下，生成中间代币对MT的益处。

Method: 通过在多语言对和多设置下，探索生成中间代币（“思考”代币）对LRM执行MT任务的影响。研究了两种情况：1. 直接使用“思考”代币进行MT。2. 使用受人类翻译启发的蒸馏链式思考（CoT）进行微调。3. 结合模块化的、特定于翻译的提示策略来构建中间代币。

Result: “思考”代币并不能提升LRM在MT任务上的表现。使用蒸馏CoT进行微调的模型，其性能并不优于标准的输入-输出微调。然而，通过结合模块化、特定于翻译的提示策略来构建中间代币，可以带来性能提升。

Conclusion: 在MT任务的微调过程中，中间代币的贡献高度依赖于其中是否包含翻译尝试。使用教师模型精炼目标翻译或扩展平行语料库，比将教师的CoT解释蒸馏到“思考”MT模型中更有影响力。

Abstract: Large reasoning models (LRMs) have led to new possibilities in terms of
problem-solving, through the devising of a natural language thought process
prior to answering a query. While their capabilities are well known across
mathematics and coding tasks, their impact on the task of machine translation
(MT) remains underexplored. In this work, we explore the benefits of the
generation of intermediate tokens when performing MT across multiple language
pairs of different levels of resourcedness and multiple setups. We find that
"thinking tokens" do not help LRMs better perform MT. This result generalizes
to models fine-tuned to reason before translating using distilled chain of
thought (CoT) inspired by human translators' practices. Specifically,
fine-tuning a model with synthetic CoT explanations detailing how to translate
step-by-step does not outperform standard input-output fine-tuning. However,
constructing the intermediate tokens by combining the outputs of modular
translation-specific prompting strategies results in improvements. Our findings
underscore that the contribution of intermediate tokens during fine-tuning
highly depends on the presence of translation attempts within them. More
broadly, our results suggest that using a teacher to refine target translations
or to expand parallel corpora is more impactful than distilling their CoT
explanations into "thinking" MT models.

</details>


### [93] [Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering](https://arxiv.org/abs/2510.11928)
*Lorena Calvo-Bartolomé,Valérie Aldana,Karla Cantarero,Alonso Madroñal de Mesa,Jerónimo Arenas-García,Jordan Boyd-Graber*

Main category: cs.CL

TL;DR: MIND是一个用户参与的事实核查流程，用于检测多语言问答知识库中事实和文化上的不一致。


<details>
  <summary>Details</summary>
Motivation: 多语言问答系统需要确保跨语言的事实一致性，并处理主观回答的文化差异。

Method: 提出MIND流程，识别对文化敏感问题（如“谁协助分娩？”）的区域性差异化答案。

Result: 在双语问答系统和跨领域数据集中，MIND都能可靠地识别不一致性。

Conclusion: MIND支持开发更具文化意识和事实一致性的问答系统。

Abstract: Multilingual question answering (QA) systems must ensure factual consistency
across languages, especially for objective queries such as What is jaundice?,
while also accounting for cultural variation in subjective responses. We
propose MIND, a user-in-the-loop fact-checking pipeline to detect factual and
cultural discrepancies in multilingual QA knowledge bases. MIND highlights
divergent answers to culturally sensitive questions (e.g., Who assists in
childbirth?) that vary by region and context. We evaluate MIND on a bilingual
QA system in the maternal and infant health domain and release a dataset of
bilingual questions annotated for factual and cultural inconsistencies. We
further test MIND on datasets from other domains to assess generalization. In
all cases, MIND reliably identifies inconsistencies, supporting the development
of more culturally aware and factually consistent QA systems.

</details>


### [94] [TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition](https://arxiv.org/abs/2510.11944)
*Yupei Li,Philipp Borchert,Gerasimos Lampouras*

Main category: cs.CL

TL;DR: LLMs在数学推理方面表现出色，但在将非正式数学语句转化为形式化语句方面仍存在挑战。本文提出了TopoAlign框架，利用代码库来扩充训练数据，从而提高LLMs在数学领域的能力。


<details>
  <summary>Details</summary>
Motivation: 当前数学LLMs在自动形式化方面的性能受限于大规模语料库的稀缺性，特别是包含非正式和形式化语句对的语料库。

Method: TopoAlign框架将代码分解为文档字符串、主函数和依赖函数，并将这些组件重新组装成结构上模仿形式化语句的“类似物”。

Result: 使用TopoAlign框架训练的DeepSeek-Math模型在BEq@10和typecheck@10指标上分别提高了17.77%和68.82%。Herald模型也取得了小幅提升，表明在对齐的代码数据上进行训练对专门模型也有益。

Conclusion: TopoAlign框架能够有效利用现有的代码资源来扩充训练数据，提高LLMs在自动形式化任务上的性能，而无需额外的人工标注。

Abstract: Large Language Models (LLMs) excel at both informal and formal (e.g. Lean 4)
mathematical reasoning but still struggle with autoformalisation, the task of
transforming informal into formal mathematical statements. Autoformalisation
helps pair the informal reasoning of LLMs with formal proof assistants which
enable machine-verifiable generation and mitigate hallucinations. Yet, the
performance of current Math LLMs is constrained by the scarcity of large-scale
corpora, particularly those containing pairs of informal and formal statements.
Although current models are trained to generate code from natural language
instructions, structural and syntactic differences between these and formal
mathematics limit effective transfer learning. We propose TopoAlign, a
framework that unlocks widely available code repositories as training resources
for Math LLMs. TopoAlign decomposes code into docstrings, main functions, and
dependency functions, and reassembles these components into analogues that
structurally mirror formal statements. This produces structurally aligned code
data that can be used for training Math LLMs without requiring additional human
annotation. We train two state-of-the-art models, DeepSeek-Math and Herald, and
evaluate them on the minif2f, Putnam, and ProofNet benchmarks. TopoAlign
provides substantial gains for DeepSeek-Math, improving performance by 17.77%
on BEq@10 and 68.82% on typecheck@10. Despite introducing no new mathematical
knowledge, our framework achieves gains of 0.12% and 1.09% for Herald on BEq@10
and typecheck@10, respectively, demonstrating that training on aligned code
data is beneficial even for specialized models.

</details>


### [95] [GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences](https://arxiv.org/abs/2510.11952)
*Priyanka Dey,Daniele Rosa,Wenqing Zheng,Daniel Barcklow,Jieyu Zhao,Emilio Ferrara*

Main category: cs.CL

TL;DR: GRAVITY是一个生成合成偏好数据的框架，用于个性化大型语言模型，通过整合用户的人口统计、文化和心理特征，减少对昂贵的人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化方法依赖于昂贵的人工反馈或交互日志，并且忽略了用户的深层属性，限制了可扩展性。

Method: GRAVITY框架整合了人口统计、文化和心理学框架（包括霍夫斯泰德的文化维度、施瓦茨的基本价值观、世界价值观调查和大五海洋特征），以合成偏好对，从而指导个性化内容生成。

Result: 在对400名亚马逊用户的书籍描述进行评估时，GRAVITY相比基于提示的条件设定、标准微调和朴素的合成数据生成方法，在跨文化（美国、巴西、日本、印度）生成方面表现出更高的偏好，获得了超过4%的增益，并且在用户研究中，GRAVITY的输出被偏好的次数超过了86%。

Conclusion: GRAVITY生成的基于场景的合成数据能够捕捉更丰富的用户差异，减少对昂贵标注的依赖，并产生更具吸引力、以用户为中心的内容，为大型语言模型的个性化提供了一条可扩展的路径。

Abstract: Personalization in LLMs often relies on costly human feedback or interaction
logs, limiting scalability and neglecting deeper user attributes. To reduce the
reliance on human annotations, we introduce GRAVITY (Generative Response with
Aligned Values, Interests, and Traits of You), a framework for generating
synthetic, profile-grounded preference data that captures users' interests,
values, beliefs, and personality traits. By integrating demographic, cultural,
and psychological frameworks -- including Hofstede's cultural dimensions,
Schwartz's basic values, the World Values Survey, and Big Five OCEAN traits --
GRAVITY synthesizes preference pairs to guide personalized content generation.
We evaluate GRAVITY on book descriptions for 400 Amazon users, comparing it to
prompt-based conditioning, standard fine-tuning, and naive synthetic pair
generation. Profile-grounded synthetic data consistently improves generation,
especially across multiple cultures (USA, Brazil, Japan, India), achieving over
4% higher preference gains across baselines, with user studies showing that
GRAVITY outputs are preferred over 86% of the time. Our results show that
scenario-grounded synthetic data can capture richer user variation, reduce
reliance on costly annotation, and produce more engaging, user-centered
content, offering a scalable path for LLM personalization.

</details>


### [96] [Evaluating Retrieval-Augmented Generation Systems on Unanswerable, Uncheatable, Realistic, Multi-hop Queries](https://arxiv.org/abs/2510.11956)
*Gabrielle Kaili-May Liu,Bryan Li,Arman Cohan,William Gantt Walden,Eugene Yang*

Main category: cs.CL

TL;DR: 本研究提出了一个自动生成不可欺骗、真实、无法回答的多跳问题（CRUMQs）的流程，以解决现有RAG基准测试无法有效评估RAG系统处理复杂查询的能力的缺点。


<details>
  <summary>Details</summary>
Motivation: 现有RAG基准测试在处理复杂查询（如无法回答或需要多步推理的查询）时存在不足，容易被欺骗，无法真实反映RAG系统的局限性。

Method: 提出了一种自动生成不可欺骗、真实、无法回答的多跳问题（CRUMQs）的流程，并将其应用于两个流行的RAG数据集，以评估现有RAG系统。

Result: 在CRUMQs基准测试上，与现有基准测试相比，RAG系统在处理真实、无法回答和多跳查询方面的能力得到了显著提升，欺骗性得分降低了高达81.0%。

Conclusion: 本研究提出的CRUMQs生成流程能够有效提高基准测试的难度和真实性，促进更强大RAG系统的发展。

Abstract: Real-world use cases often present RAG systems with complex queries for which
relevant information is missing from the corpus or is incomplete. In these
settings, RAG systems must be able to reject unanswerable, out-of-scope queries
and identify failures of retrieval and multi-hop reasoning. Despite this,
existing RAG benchmarks rarely reflect realistic task complexity for multi-hop
or out-of-scope questions, which often can be cheated via disconnected
reasoning (i.e., solved without genuine multi-hop inference) or require only
simple factual recall. This limits the ability for such benchmarks to uncover
limitations of existing RAG systems. To address this gap, we present the first
pipeline for automatic, difficulty-controlled creation of
un$\underline{c}$heatable, $\underline{r}$ealistic, $\underline{u}$nanswerable,
and $\underline{m}$ulti-hop $\underline{q}$uerie$\underline{s}$ (CRUMQs),
adaptable to any corpus and domain. We use our pipeline to create CRUMQs over
two popular RAG datasets and demonstrate its effectiveness via benchmark
experiments on leading retrieval-augmented LLMs. Results show that compared to
prior RAG benchmarks, CRUMQs are highly challenging for RAG systems and achieve
up to 81.0\% reduction in cheatability scores. More broadly, our pipeline
offers a simple way to enhance benchmark difficulty and realism and drive
development of more capable RAG systems.

</details>


### [97] [Direct Multi-Token Decoding](https://arxiv.org/abs/2510.11958)
*Xuan Luo,Weizhi Wang,Xifeng Yan*

Main category: cs.CL

TL;DR: 在预训练的大型语言模型（LLM）中，早、中、晚期层可能扮演不同的角色：早期层关注理解输入上下文，中期层处理特定任务，晚期层将抽象表示转换为输出令牌。我们提出了一种称为直接多令牌解码（DMTD）的推理范式，该范式利用后期层来生成多个令牌，而无需重复遍历早期和中期层，从而实现高达2倍的加速，且性能损失很小。


<details>
  <summary>Details</summary>
Motivation: LLM 的推理效率低下，特别是生成长序列时，这限制了它们的实际应用。现有方法（如投机解码）要么引入额外开销，要么需要复杂的后处理。因此，需要一种更简单、更高效的解码策略。

Method: DMTD 假设一旦输入信息经过 LLM 的早期和中期层处理，生成的隐藏状态就足以独立地生成多个令牌。因此，DMTD 只需通过 LLM 的后期层即可生成多个令牌，从而避免了重复计算早期和中期层。该方法不需要额外的参数、辅助例程或后生成验证。

Result: 在有限的数据集上进行微调的 DMTD Qwen3-4B 模型在推理速度上实现了高达 2 倍的提升，同时性能损失很小。此外，规模分析表明，随着训练数据集的增大，DMTD 的性能有望进一步提升。

Conclusion: DMTD 是一种有前途的 LLM 推理技术，它通过只利用模型的后期层来生成多个令牌，显著提高了推理速度，并且易于实现，不需要额外的训练或复杂性。该方法有望在各种 LLM 应用中得到广泛应用，特别是那些对延迟敏感的应用。

Abstract: Decoder-only transformers have become the standard architecture for large
language models (LLMs) due to their strong performance. Recent studies suggest
that, in pre-trained LLMs, early, middle, and late layers may serve distinct
roles: Early layers focus on understanding the input context, middle layers
handle task-specific processing, and late layers convert abstract
representations into output tokens. We hypothesize that once representations
have been processed by the early and middle layers, the resulting hidden states
may encapsulate sufficient information to support the generation of multiple
tokens using only the late layers, eliminating the need to repeatedly traverse
the early and middle layers. We refer to this inference paradigm as Direct
Multi-Token Decoding (DMTD). Unlike speculative decoding, our method introduces
no additional parameters, auxiliary routines, or post-generation verification.
Despite being trained on a limited dataset, a fine-tuned DMTD Qwen3-4B model
has already demonstrated promising results, achieving up to a 2x speedup with
only minor performance loss. Moreover, as shown in our scaling analysis, its
performance is expected to further improve with larger training datasets.

</details>


### [98] [Scaling Long-Horizon LLM Agent via Context-Folding](https://arxiv.org/abs/2510.11967)
*Weiwei Sun,Miao Lu,Zhan Ling,Kang Liu,Xuesong Yao,Yiming Yang,Jiecao Chen*

Main category: cs.CL

TL;DR: LLM代理在长任务中受限于上下文长度。本文提出Context-Folding框架，使代理能管理工作上下文，通过分支处理子任务并折叠中间步骤以保留结果摘要。结合FoldGRPO强化学习框架，该方法在复杂长任务上表现优于基线，且上下文占用小得多。


<details>
  <summary>Details</summary>
Motivation: LLM代理在处理长任务时，上下文长度的限制是一个关键问题。

Method: 提出Context-Folding框架，允许代理主动管理工作上下文，通过子轨迹处理子任务并折叠中间步骤。开发了FoldGRPO强化学习框架，并设计了特定的过程奖励来鼓励任务分解和上下文管理。

Result: 在Deep Research和SWE等复杂长任务上，Context-Folding代理的表现与ReAct基线相当或更优，但激活上下文仅为其1/10。同时，该方法显著优于依赖摘要式上下文管理的模型。

Conclusion: Context-Folding框架和FoldGRPO强化学习方法能够有效解决LLM代理在长任务中的上下文长度限制问题，并在复杂任务上取得优于现有方法的性能。

Abstract: Large language model (LLM) agents are fundamentally constrained by context
length on long-horizon tasks. We introduce Context-Folding, a framework that
empowers agents to actively manage their working context. An agent can
procedurally branch into a sub-trajectory to handle a subtask and then fold it
upon completion, collapsing the intermediate steps while retaining a concise
summary of the outcome. To make this behavior learnable, we develop an
end-to-end reinforcement learning framework FoldGRPO with specific process
rewards to encourage effective task decomposition and context management. On
complex long-horizon tasks (Deep Research and SWE), our folding agent matches
or outperforms the ReAct baselines while using an active context 10$\times$
smaller and significantly outperforms models that rely on summarization-based
context management.

</details>


### [99] [Conjecturing: An Overlooked Step in Formal Mathematical Reasoning](https://arxiv.org/abs/2510.11986)
*Jasivan Alex Sivakumar,Philipp Borchert,Ronald Cardenas,Gerasimos Lampouras*

Main category: cs.CL

TL;DR: LLMs在数学推理中的自动形式化能力被高估了，因为它们在形式化之前进行猜测的能力被忽略了。作者创建了一个新的数据集ConjectureBench来评估这种猜测能力，并开发了一种名为Lean-FIRe的方法来改进自动形式化过程。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在数学自动形式化中的猜测能力，并开发改进自动形式化和猜测能力的方法。

Method: 创建ConjectureBench数据集来评估LLMs的猜测能力，并设计Lean-FIRe推理时方法来改进自动形式化。

Result: 评估结果表明，LLMs的自动形式化能力被高估了，但它们具备生成准确猜测的知识。Lean-FIRe方法成功地实现了13个PutnamBench问题的端到端自动形式化（使用GPT-4.1）和7个（使用DeepSeek-V3.1）。

Conclusion: 将猜测作为一个独立任务来处理并将其正确整合到自动形式化过程中，对于提高LLMs在数学推理中的自动形式化性能至关重要。

Abstract: Autoformalisation, the task of expressing informal mathematical statements in
formal language, is often viewed as a direct translation process. This,
however, disregards a critical preceding step: conjecturing. Many mathematical
problems cannot be formalised directly without first conjecturing a conclusion
such as an explicit answer, or a specific bound. Since Large Language Models
(LLMs) already struggle with autoformalisation, and the evaluation of their
conjecturing ability is limited and often entangled within autoformalisation or
proof, it is particularly challenging to understand its effect. To address this
gap, we augment existing datasets to create ConjectureBench, and redesign the
evaluation framework and metric specifically to measure the conjecturing
capabilities of LLMs both as a distinct task and within the autoformalisation
pipeline. Our evaluation of foundational models, including GPT-4.1 and
DeepSeek-V3.1, reveals that their autoformalisation performance is
substantially overestimated when the conjecture is accounted for during
evaluation. However, the conjecture should not be assumed to be provided. We
design an inference-time method, Lean-FIRe to improve conjecturing and
autoformalisation, which, to the best of our knowledge, achieves the first
successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1
and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite
knowledge to generate accurate conjectures, improving autoformalisation
performance requires treating conjecturing as an independent task, and
investigating further how to correctly integrate it within autoformalisation.
Finally, we provide forward-looking guidance to steer future research toward
improving conjecturing, an overlooked step of formal mathematical reasoning.

</details>


### [100] [SAGE: A Top-Down Bottom-Up Knowledge-Grounded User Simulator for Multi-turn AGent Evaluation](https://arxiv.org/abs/2510.11997)
*Ryan Shea,Yunan Lu,Liang Qiu,Zhou Yu*

Main category: cs.CL

TL;DR: SAGE是一个新的模拟用户框架，通过整合业务知识来评估多轮交互式代理，提高了评估的真实性和效率。


<details>
  <summary>Details</summary>
Motivation: 评估多轮交互式代理的挑战在于需要人工评估，而现有的模拟用户方法忽略了领域特定知识，无法反映真实用户行为。

Method: SAGE框架整合了自上而下的业务逻辑知识（如客户画像）和自下而上的业务基础设施知识（如产品目录、FAQ），以生成反映用户需求和期望的交互。

Result: SAGE生成的交互更加真实和多样化，能够发现多达33%的代理错误，证明了其作为评估工具的有效性。

Conclusion: SAGE通过整合领域特定知识，为多轮交互式代理评估提供了一个更真实、更有效的解决方案，有助于发现代理错误和改进代理性能。

Abstract: Evaluating multi-turn interactive agents is challenging due to the need for
human assessment. Evaluation with simulated users has been introduced as an
alternative, however existing approaches typically model generic users and
overlook the domain-specific principles required to capture realistic behavior.
We propose SAGE, a novel user Simulation framework for multi-turn AGent
Evaluation that integrates knowledge from business contexts. SAGE incorporates
top-down knowledge rooted in business logic, such as ideal customer profiles,
grounding user behavior in realistic customer personas. We further integrate
bottom-up knowledge taken from business agent infrastructure (e.g., product
catalogs, FAQs, and knowledge bases), allowing the simulator to generate
interactions that reflect users' information needs and expectations in a
company's target market. Through empirical evaluation, we find that this
approach produces interactions that are more realistic and diverse, while also
identifying up to 33% more agent errors, highlighting its effectiveness as an
evaluation tool to support bug-finding and iterative agent improvement.

</details>


### [101] [Generate Logical Equivalence Questions](https://arxiv.org/abs/2510.12001)
*Xinyu Wang,Haoming Yu,Yicheng Yang,Zhiyuan Li*

Main category: cs.CL

TL;DR: 本文提出了一种针对离散数学中逻辑等价问题的自动生成方法，通过形式语言和生成规则，设计了一种线性时间算法，解决了现有方法效率低下和题目难度不 uniform 的问题。实验结果表明，该方法生成的题目准确性与教材相当，难度与教材相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决高等教育中日益严重的抄袭问题，以及为离散数学这门计算机科学专业基础课程提供大量的练习题，提出一种新的自动问题生成（AQG）方法。

Method: 提出了一种新方法，使用形式语言定义逻辑等价问题，并将其转化为两组生成规则，最后开发了一种线性时间算法来进行问题生成。

Result: 通过两项实验评估。第一项实验表明，该系统生成问题的准确性与教科书相当。第二项实验表明，该系统生成问题的难度与教科书和大型语言模型生成的问题相似。

Conclusion: 提出的 AQG 方法生成的逻辑等价问题具有与教科书相当的准确性和难度，能够有效解决现有方法的不足。

Abstract: Academic dishonesty is met with zero tolerance in higher education, yet
plagiarism has become increasingly prevalent in the era of online teaching and
learning. Automatic Question Generation (AQG) presents a potential solution to
mitigate copying by creating unique questions for each student. Additionally,
AQG can provide a vast array of practice questions. Our AQG focuses on
generating logical equivalence questions for Discrete Mathematics, a
foundational course for first-year computer science students. A literature
review reveals that existing AQGs for this type of question generate all
propositions that meet user-defined constraints, resulting in inefficiencies
and a lack of uniform question difficulty. To address this, we propose a new
approach that defines logical equivalence questions using a formal language,
translates this language into two sets of generation rules, and develops a
linear-time algorithm for question generation. We evaluated our AQG through two
experiments. The first involved a group of students completing questions
generated by our system. Statistical analysis shows that the accuracy of these
questions is comparable to that of textbook questions. The second experiment
assessed the number of steps required to solve our generated questions,
textbook questions, and those generated by multiple large language models. The
results indicated that the difficulty of our questions was similar to that of
textbook questions, confirming the quality of our AQG.

</details>


### [102] [Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM](https://arxiv.org/abs/2510.12023)
*Alice Saebom Kwak,Maria Alexeeva,Gus Hahn-Powell,Keith Alcock,Kevin McLaughlin,Doug McCorkle,Gabe McNunn,Mihai Surdeanu*

Main category: cs.CL

TL;DR: LLM在农业信息提取任务中优于神经符号方法，但在效率和可控性方面存在权衡。


<details>
  <summary>Details</summary>
Motivation: 评估基于LLM和神经符号（NS）的信息提取（IE）系统在农业领域的性能，并比较它们的优缺点。

Method: 在猪、奶制品和农作物子领域中，使用九次访谈的农业领域数据集，对一个NS系统和一个基于LLM的IE系统进行比较评估。

Result: 基于LLM的系统在总提取信息（F1：69.4 vs 52.7）和核心信息（F1：63.0 vs 47.2）方面均优于NS系统。NS系统在无上下文任务中运行速度更快、控制性更强、精度更高，但泛化能力较差，难以处理上下文的细微差别，且开发维护成本高。基于LLM的系统性能更优，部署和维护更便捷，但运行速度较慢，控制性较差，且存在模型依赖和幻觉风险。

Conclusion: 基于LLM的系统在农业信息提取方面表现出更高的性能，但与NS系统相比，在运行速度、控制性和可靠性方面存在权衡。这揭示了在实际应用中部署NLP系统时需要考虑的“隐藏成本”，并强调了在性能、效率和控制之间取得平衡的重要性。

Abstract: The current trend in information extraction (IE) is to rely extensively on
large language models, effectively discarding decades of experience in building
symbolic or statistical IE systems. This paper compares a neuro-symbolic (NS)
and an LLM-based IE system in the agricultural domain, evaluating them on nine
interviews across pork, dairy, and crop subdomains. The LLM-based system
outperforms the NS one (F1 total: 69.4 vs. 52.7; core: 63.0 vs. 47.2), where
total includes all extracted information and core focuses on essential details.
However, each system has trade-offs: the NS approach offers faster runtime,
greater control, and high accuracy in context-free tasks but lacks
generalizability, struggles with contextual nuances, and requires significant
resources to develop and maintain. The LLM-based system achieves higher
performance, faster deployment, and easier maintenance but has slower runtime,
limited control, model dependency and hallucination risks. Our findings
highlight the "hidden cost" of deploying NLP systems in real-world
applications, emphasizing the need to balance performance, efficiency, and
control.

</details>


### [103] [CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement](https://arxiv.org/abs/2510.12029)
*Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: CPR框架通过优化提示来减少LLM的幻觉，提高了生成质量。


<details>
  <summary>Details</summary>
Motivation: LLM有时会生成不准确的事实（幻觉），这通常是由于用户提示结构不佳或模糊造成的。

Method: CPR是一个即插即用框架，它通过微调的小型语言模型来清理不正确的提示，并生成额外的任务描述，以对齐用户意图和提示。

Result: CPR显著提高了生成质量，同时减少了幻觉。应用了CPR的提示在没有任何外部知识的情况下，原始提示的获胜率超过90%。

Conclusion: CPR框架能够有效减少LLM的幻觉，并提高其响应质量。

Abstract: Recent advancements in large language models (LLMs) highlight their fluency
in generating responses to diverse prompts. However, these models sometimes
generate plausible yet incorrect ``hallucinated" facts, undermining trust. A
frequent but often overlooked cause of such errors is the use of poorly
structured or vague prompts by users, leading LLMs to base responses on assumed
rather than actual intentions. To mitigate hallucinations induced by these
ill-formed prompts, we introduce Curative Prompt Refinement (CPR), a
plug-and-play framework for curative prompt refinement that 1) cleans
ill-formed prompts, and 2) generates additional informative task descriptions
to align the intention of the user and the prompt using a fine-tuned small
language model. When applied to language models, we discover that CPR
significantly increases the quality of generation while also mitigating
hallucination. Empirical studies show that prompts with CPR applied achieves
over a 90\% win rate over the original prompts without any external knowledge.

</details>


### [104] [Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models](https://arxiv.org/abs/2510.12032)
*Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: LLM 幻觉问题可以通过多阶段提示优化框架 MPR 得到缓解，该框架能系统性地改进存在缺陷的提示。


<details>
  <summary>Details</summary>
Motivation: LLM 尽管在自然语言任务中表现出色，但仍存在幻觉问题；而由提示不规范（措辞模糊、语法错误、信息不完整等）引起的幻觉问题被研究得不足。

Method: 提出多阶段提示优化（MPR）框架，该框架使用针对特定任务（如标点、拼写、关键词误用）进行微调的小语言模型（SLM）来逐步改进提示。MPR 结合了上下文增强、自我反思和排序机制，以优先处理最相关的输入。

Result: 在幻觉基准测试中，MPR 优化后的提示相比原始提示具有超过 85% 的胜率，有效减少了幻觉并提高了 LLM 输出的准确性。MPR 还可以与现有的后处理幻觉缓解框架结合使用，进一步提高其性能。

Conclusion: MPR 是一种轻量级且适应性强的解决方案，可以提高不同领域 LLM 的可靠性。

Abstract: Recent advancements in large language models (LLMs) have shown strong
performance in natural language understanding and generation tasks. However,
LLMs continue to encounter challenges with hallucinations, where models
generate plausible but incorrect information. While several factors contribute
to hallucinations, the impact of ill-formed prompts, prompts with ambiguous
wording, incorrect grammar, or incomplete information, was relatively under
explored. To address this, we introduce Multi-stage Prompt Refinement (MPR), a
framework designed to systematically improve these ill-formed prompts across
multiple stages. Each stage addresses specific errors such as punctuation,
typographical mistakes, and misuse of key terms, using small language models
(SLMs) fine-tuned for these tasks. MPR iteratively enhances the clarity of
prompts with additional context and employs a self-reflection mechanism with
ranking to prioritize the most relevant input. Experimental results on
hallucination benchmarks show that prompts refined by MPR achieve over an 85~\%
win rate compared to their original forms, demonstrating its effectiveness in
reducing hallucinations and improving LLM output accuracy. Interestingly, we
reveal that MPR can be combined with existing post-hoc hallucination mitigation
frameworks, further enhancing its versatility. MPR provides a lightweight and
adaptable solution for enhancing LLM reliability across various domains.

</details>


### [105] [On the Interplay between Human Label Variation and Model Fairness](https://arxiv.org/abs/2510.12036)
*Kemal Kurniawan,Meladel Mistica,Timothy Baldwin,Jey Han Lau*

Main category: cs.CL

TL;DR: HLV 训练方法在没有显式去偏的情况下，可以提高模型公平性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨人类标签变异（HLV）对模型公平性的影响，这是一个尚未被充分研究的领域。

Method: 通过比较在多数投票标签和一系列HLV方法上进行训练的效果来研究HLV与模型公平性之间的相互作用。

Result: 实验表明，在没有显式进行去偏操作的情况下，采用HLV的训练方法能够对模型公平性产生积极影响。

Conclusion: HLV训练方法有望在不进行额外去偏的情况下改善模型公平性。

Abstract: The impact of human label variation (HLV) on model fairness is an unexplored
topic. This paper examines the interplay by comparing training on majority-vote
labels with a range of HLV methods. Our experiments show that without explicit
debiasing, HLV training methods have a positive impact on fairness.

</details>


### [106] [Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions](https://arxiv.org/abs/2510.12040)
*Sungmin Kang,Yavuz Faruk Bakman,Duygu Nur Yaldiz,Baturalp Buyukates,Salman Avestimehr*

Main category: cs.CL

TL;DR: LLM在自然语言处理领域取得了显著进展，但也存在幻觉问题。不确定性量化（UQ）被认为是解决此问题的关键，可用于评估模型生成内容的可靠性，尤其是在幻觉检测方面。本文介绍了UQ的基础，探讨了其在LLM中的应用，系统地分类了现有方法，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM在实际应用中存在幻觉问题，导致输出不准确，降低了可靠性和可信度。UQ被认为是解决此问题的一种有前景的研究方向。

Method: 本文首先介绍了不确定性量化的基础概念，包括其正式定义以及对认知不确定性和偶然不确定性的传统区分，并阐述了这些概念如何应用于LLM。然后，文章探讨了UQ在幻觉检测中的作用，量化不确定性可以识别不可靠的生成并提高LLM的可靠性。最后，本文对现有方法进行了分类，并展示了代表性方法的实证结果。

Result: 本文对现有LLM不确定性量化方法进行了系统分类，并提供了实证结果，展示了不同方法的有效性。

Conclusion: 不确定性量化是解决LLM幻觉问题、提高其可靠性的关键。本文对该领域的研究现状进行了梳理，并指出了未来的研究方向。

Abstract: The rapid advancement of large language models (LLMs) has transformed the
landscape of natural language processing, enabling breakthroughs across a wide
range of areas including question answering, machine translation, and text
summarization. Yet, their deployment in real-world applications has raised
concerns over reliability and trustworthiness, as LLMs remain prone to
hallucinations that produce plausible but factually incorrect outputs.
Uncertainty quantification (UQ) has emerged as a central research direction to
address this issue, offering principled measures for assessing the
trustworthiness of model generations. We begin by introducing the foundations
of UQ, from its formal definition to the traditional distinction between
epistemic and aleatoric uncertainty, and then highlight how these concepts have
been adapted to the context of LLMs. Building on this, we examine the role of
UQ in hallucination detection, where quantifying uncertainty provides a
mechanism for identifying unreliable generations and improving reliability. We
systematically categorize a wide spectrum of existing methods along multiple
dimensions and present empirical results for several representative approaches.
Finally, we discuss current limitations and outline promising future research
directions, providing a clearer picture of the current landscape of LLM UQ for
hallucination detection.

</details>


### [107] [Improving Text-to-Image Generation with Input-Side Inference-Time Scaling](https://arxiv.org/abs/2510.12041)
*Ruibo Chen,Jiacheng Pan,Heng Huang,Zhenheng Yang*

Main category: cs.CL

TL;DR: LLM驱动的提示重写框架能有效提升文本到图像生成模型的性能，改善图像-文本对齐、视觉质量和美观度，且具有良好的可迁移性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在处理简单或不明确的提示时，往往难以达到最佳的图像-文本对齐、美观度和质量。

Method: 提出一个提示重写框架，利用大型语言模型（LLM）优化用户输入，并结合奖励系统和迭代式直接偏好优化（DPO）训练。

Result: 在各种文本到图像模型和基准测试中，该提示重写器持续提升了图像-文本对齐、视觉质量和美观度，效果优于现有方法。此外，该重写器在不同模型间表现出良好的迁移能力，并且性能会随着LLM容量的增加而扩展。

Conclusion: 提示重写是一种有效、可扩展且实用的模型无关策略，能够提升文本到图像生成系统的性能。

Abstract: Recent advances in text-to-image (T2I) generation have achieved impressive
results, yet existing models often struggle with simple or underspecified
prompts, leading to suboptimal image-text alignment, aesthetics, and quality.
We propose a prompt rewriting framework that leverages large language models
(LLMs) to refine user inputs before feeding them into T2I backbones. Our
approach introduces a carefully designed reward system and an iterative direct
preference optimization (DPO) training pipeline, enabling the rewriter to
enhance prompts without requiring supervised fine-tuning data. We evaluate our
method across diverse T2I models and benchmarks. Results show that our prompt
rewriter consistently improves image-text alignment, visual quality, and
aesthetics, outperforming strong baselines. Furthermore, we demonstrate strong
transferability by showing that a prompt rewriter trained on one T2I backbone
generalizes effectively to others without needing to be retrained. We also
systematically study scalability, evaluating how performance gains scale with
the capacity of the large LLM used as the rewriter. These findings highlight
that prompt rewriting is an effective, scalable, and practical model-agnostic
strategy for improving T2I systems. We plan to release the code and trained
prompt rewriters soon.

</details>


### [108] [Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models](https://arxiv.org/abs/2510.12044)
*Yukun Zhang,Qi Dong*

Main category: cs.CL

TL;DR: LLM对齐技术应采用分层方法，而非整体优化，以提高效率和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐技术（如DPO）将模型视为整体，忽略了Transformer架构中不同层级的功能特异性。

Method: 提出了一种名为“分层对齐”的新方法，该方法将DPO应用于模型的不同功能块（局部、中间、全局层），并使用LoRA进行微调。

Result: 实验证明，分层对齐可以带来显著且可预测的改进。对齐局部层可提高语法流畅度；对齐全局层在提高事实一致性的同时，最有效地提升了逻辑连贯性。所有分层策略均避免了标准DPO中的“对齐税”。

Conclusion: 从整体优化转向结构感知的手术式微调，为构建更先进、更可靠的LLM开辟了一条更具资源效率、可控性和可解释性的道路。

Abstract: Existing alignment techniques for Large Language Models (LLMs), such as
Direct Preference Optimization (DPO), typically treat the model as a monolithic
entity, applying uniform optimization pressure across all layers. This approach
overlooks the functional specialization within the Transformer architecture,
where different layers are known to handle distinct tasks from syntax to
abstract reasoning. In this paper, we challenge this one-size-fits-all paradigm
by introducing Hierarchical Alignment, a novel method that applies targeted DPO
to distinct functional blocks of a model's layers: local (syntax), intermediate
(logic), and global (factuality). Through a series of controlled experiments on
state-of-the-art models like Llama-3.1-8B and Qwen1.5-7B using LoRA for
surgical fine-tuning, our results, evaluated by a powerful LLM-as-Judge,
demonstrate significant and predictable improvements. Specifically, aligning
the local layers (Local-Align) enhances grammatical fluency. More importantly,
aligning the global layers (Global-Align) not only improves factual consistency
as hypothesized but also proves to be the most effective strategy for enhancing
logical coherence, outperforming all baselines. Critically, all hierarchical
strategies successfully avoid the "alignment tax" observed in standard DPO,
where gains in fluency come at the cost of degraded logical reasoning. These
findings establish a more resource-efficient, controllable, and interpretable
path for model alignment, highlighting the immense potential of shifting from
monolithic optimization to structure-aware surgical fine-tuning to build more
advanced and reliable LLMs.

</details>


### [109] [APCE: Adaptive Progressive Context Expansion for Long Context Processing](https://arxiv.org/abs/2510.12051)
*Baisub Lee,Sanghyun Byun,Mohanad Odema,Jung Guack,Jacob Song,Woo Seong Chung*

Main category: cs.CL

TL;DR: APCE通过低维语义相似度匹配选择最重要的输入块，以解决长上下文Transformer模型（LCTM）的内存占用和ContextRot问题，在长上下文摘要任务中取得了优于或相当的性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文Transformer模型（LCTM）在部署时面临内存占用增长（二次自注意力、线性KV缓存）和性能下降（ContextRot）的挑战。文章旨在探索是否能通过选择性处理输入块来解决这些问题。

Method: 提出APCE（Context-Aware Input Chunk Selection）方法，通过低维语义相似度匹配当前查询来选择最重要的输入块进行处理，从而减少内存占用并缓解ContextRot效应。

Result: APCE在长上下文摘要任务中，使用50%-70%的输入序列即可达到与完整密集基线相当的性能，实现了KV缓存和自注意力内存效率的提升。

Conclusion: APCE是一种有效的上下文感知方法，可以解决LCTM的效率和性能问题，并有望激发在其他长上下文任务中的应用。

Abstract: Deploying useful Long-Context Transformer Models (LCTMs) requires addressing
two key challenges: (1) A growing memory footprint due to quadratic
self-attention and linear KV-cache scaling in memory as sequence length
increases; (2) the ContextRot phenomena where empirical evidence suggests that
transformer architecture's performance degrades with increasing context length.
Given the shared dependency on the input, a natural question arises: Can we
surgically select the most important input chunks for processing to
synergistically (a) reduce the memory footprint, and (b) mitigate the
ContextRot effects? In this paper, we answer this question in the affirmative
for long-context summarization tasks. We propose APCE as a context-aware
solution to select the most important input chunks through low-dimensional
semantic similarity matching with the current query. By directly operating on
the input, APCE decouples from strict dependency on underlying hardware or CUDA
environments, promising a compatible solution scalable to different deployment
systems. Our empirical evaluations have demonstrated superior or on-par
summarization performance for APCE compared to the full dense baseline using a
fraction (50%-70%) of the input sequence resulting in KV-cache and
self-attention memory efficiency improvements. We hope our findings inspire
further research on context-aware efficiency solutions for LCTMs geared towards
other relevant long-context tasks.

</details>


### [110] [An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations](https://arxiv.org/abs/2510.12083)
*Benjamin W. Nelson,Celeste Wong,Matthew T. Silvestrini,Sooyoon Shin,Alanna Robinson,Jessica Lee,Eric Yang,John Torous,Andrew Trister*

Main category: cs.CL

TL;DR: Verily 行为健康安全过滤器 (VBHSF) 在两个数据集上均表现出高水平的准确性，优于 OpenAI Omni Moderation 和 NVIDIA NeMo Guardrails，尤其是在检测精神健康危机方面，其高敏感性和特异性对于医疗应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理精神健康危机时常常表现不佳，可能提供有害或不当的建议。本研究旨在评估 Verily 行为健康安全过滤器 (VBHSF) 在处理此类危机方面的有效性。

Method: 本研究使用了两个数据集：Verily Mental Health Crisis Dataset（包含 1,800 条模拟消息）和 NVIDIA Aegis AI Content Safety Dataset（包含 794 条心理健康相关消息）。研究人员使用临床标签评估了 VBHSF 的性能，并将其与 OpenAI Omni Moderation Latest 和 NVIDIA NeMo Guardrails 这两个开源内容审核工具进行了比较。

Result: 在 Verily Mental Health Crisis Dataset 上，VBHSF 在检测任何精神健康危机时表现出高敏感性 (0.990) 和特异性 (0.992)，F1 分数为 0.939。在识别具体危机类别时，敏感性范围为 0.917-0.992，特异性 >= 0.978。在 NVIDIA Aegis AI Content Safety Dataset 上，VBHSF 仍保持高敏感性 (0.982) 和准确性 (0.921)，但特异性略有下降 (0.859)。与 OpenAI Omni Moderation Latest 和 NVIDIA NeMo Guardrails 相比，VBHSF 在两个数据集上均表现出更优越的性能指标，敏感性显著更高 (p < 0.001)，特异性也优于 NVIDIA NeMo (p < 0.001)。

Conclusion: VBHSF 展现了稳健且通用的性能，能够有效检测精神健康危机，其高敏感性对于最大限度地减少漏报至关重要，这使其成为医疗应用的理想选择。

Abstract: Large language models often mishandle psychiatric emergencies, offering
harmful or inappropriate advice and enabling destructive behaviors. This study
evaluated the Verily behavioral health safety filter (VBHSF) on two datasets:
the Verily Mental Health Crisis Dataset containing 1,800 simulated messages and
the NVIDIA Aegis AI Content Safety Dataset subsetted to 794 mental
health-related messages. The two datasets were clinician-labelled and we
evaluated performance using the clinician labels. Additionally, we carried out
comparative performance analyses against two open source, content moderation
guardrails: OpenAI Omni Moderation Latest and NVIDIA NeMo Guardrails. The VBHSF
demonstrated, well-balanced performance on the Verily Mental Health Crisis
Dataset v1.0, achieving high sensitivity (0.990) and specificity (0.992) in
detecting any mental health crises. It achieved an F1-score of 0.939,
sensitivity ranged from 0.917-0.992, and specificity was >= 0.978 in
identifying specific crisis categories. When evaluated against the NVIDIA Aegis
AI Content Safety Dataset 2.0, VBHSF performance remained highly sensitive
(0.982) and accuracy (0.921) with reduced specificity (0.859). When compared
with the NVIDIA NeMo and OpenAI Omni Moderation Latest guardrails, the VBHSF
demonstrated superior performance metrics across both datasets, achieving
significantly higher sensitivity in all cases (all p < 0.001) and higher
specificity relative to NVIDIA NeMo (p < 0.001), but not to OpenAI Omni
Moderation Latest (p = 0.094). NVIDIA NeMo and OpenAI Omni Moderation Latest
exhibited inconsistent performance across specific crisis types, with
sensitivity for some categories falling below 0.10. Overall, the VBHSF
demonstrated robust, generalizable performance that prioritizes sensitivity to
minimize missed crises, a crucial feature for healthcare applications.

</details>


### [111] [Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models](https://arxiv.org/abs/2510.12110)
*Ziliang Qiu,Renfen Hu*

Main category: cs.CL

TL;DR: PACE通过生成并行联想链来评估LLM的创造力，能有效避免数据污染，与人类评估高度相关。


<details>
  <summary>Details</summary>
Motivation: 评估LLM的创造力面临数据污染和高成本人类评估的挑战。

Method: 提出PACE（Parallel Association Chains to Evaluate），要求LLM生成并行联想链来评估其创造力。

Result: PACE与Chatbot Arena创意写作排名高度相关（Spearman's ρ = 0.739, p < 0.001），表明其有效性。高水平LLM的联想创造力接近人类平均水平，但专业人类的整体表现优于LLM。语言分析显示，人类和LLM在联想上都倾向于降低具体性，但人类的联想模式更多样。

Conclusion: PACE为评估LLM创造力提供了一种高效且不易污染的方法。人类在创造性联想方面仍然优于LLM，尤其是在模式多样性上。

Abstract: The evaluation of LLMs' creativity represents a crucial research domain,
though challenges such as data contamination and costly human assessments often
impede progress. Drawing inspiration from human creativity assessment, we
propose PACE, asking LLMs to generate Parallel Association Chains to Evaluate
their creativity. PACE minimizes the risk of data contamination and offers a
straightforward, highly efficient evaluation, as evidenced by its strong
correlation with Chatbot Arena Creative Writing rankings (Spearman's $\rho =
0.739$, $p < 0.001$) across various proprietary and open-source models. A
comparative analysis of associative creativity between LLMs and humans reveals
that while high-performing LLMs achieve scores comparable to average human
performance, professional humans consistently outperform LLMs. Furthermore,
linguistic analysis reveals that both humans and LLMs exhibit a trend of
decreasing concreteness in their associations, and humans demonstrating a
greater diversity of associative patterns.

</details>


### [112] [Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation](https://arxiv.org/abs/2510.12115)
*Xin Zhao,Naoki Yoshinaga,Yuma Tsuta,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在多语言领域自适应（ML-DA）中的知识获取机制，提出了一个名为AdaXEval的自适应评估方法，以解决现有研究中知识覆盖不匹配的问题。实验表明，尽管使用了高质量的双语语料库，跨语言迁移仍然具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有ML-DA研究未能充分探索多语言知识获取的机制，特别是知识在一个语言中的学习以及如何在跨语言之间进行迁移，这导致在低资源环境下性能不佳。

Method: 提出AdaXEval评估方法，该方法从用于训练的双语领域语料库构建选择题问答数据集，以直接研究多语言知识获取。通过对LLMs进行持续训练并采用不同的数据策略，追踪LLMs如何获取领域事实，并阐明领域训练数据到知识转化的机制。

Result: 在13B英日双语LLM上的实验表明，跨语言迁移仍然是一个挑战，即使在使用高质量的双语语料库的情况下。

Conclusion: 跨语言迁移在ML-DA中仍然是一个需要克服的挑战，即使使用了高质量的双语语料库。AdaXEval提供了一种更直接地研究ML-DA中知识获取机制的方法。

Abstract: Multilingual domain adaptation (ML-DA) is widely used to learn new domain
knowledge across languages into large language models (LLMs). Although many
methods have been proposed to improve domain adaptation, the mechanisms of
multilingual knowledge acquisition, how domain knowledge is learned within a
language and transferred across languages, remain underexplored. This gap leads
to suboptimal performance, particularly in low-resource settings. This work
examines the learning dynamics of LLMs during ML-DA. Because prior ML-DA
studies often train and evaluate on datasets with mismatched knowledge
coverage, we propose AdaXEval, an adaptive evaluation method that builds
multiple-choice QA datasets from the same bilingual domain corpus used for
training, thereby directly studying multilingual knowledge acquisition. Through
continual training of LLMs with diverse data recipes, we track how LLMs acquire
domain facts and pinpoint the mechanism behind the transformation process from
domain training data to knowledge. Our experiments on a 13B English-Japanese
bilingual LLM reveal that cross-lingual transfer remains challenging despite a
high-quality bilingual corpus. The code has been released.

</details>


### [113] [Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models](https://arxiv.org/abs/2510.12116)
*Bajian Xiang,Shuaijiang Zhao,Tingwei Guo,Wei Zou*

Main category: cs.CL

TL;DR: 大型语音语言模型（LSLM）在语音输入方面存在“模态鸿沟”，其语义理解能力不如传统流水线系统。通过分析模型表征，发现深层语音和文本表征在方向上对齐但在幅度上发散，且这种表征相似性与模态鸿沟密切相关。提出了一种称为“对齐路径分数”的量化方法，并据此设计了角度投影和长度归一化等干预措施，以提升模型在语音输入下的性能。


<details>
  <summary>Details</summary>
Motivation: 评估和理解大型语音语言模型（LSLM）在处理语音输入时与文本输入相比存在的性能差距（模态鸿沟），并探索其根本原因。

Method: 系统性实验分析，包括粗粒度和细粒度表征分析，并提出“对齐路径分数”量化指标，最后设计并验证了角度投影和长度归一化等干预措施。

Result: 发现LSLM在语音输入下存在显著的模态鸿沟；深层语音和文本表征在方向上对齐但在幅度上发散，且相似性与模态鸿沟相关；“对齐路径分数”与模态鸿沟高度相关；提出的干预措施显示出改善语音输入性能的潜力。

Conclusion: 该研究首次对LSLM中的模态鸿沟和对齐机制进行了系统的实证分析，为未来优化提供了理论和方法指导。

Abstract: End-to-end Large Speech Language Models (LSLMs) have demonstrated impressive
conversational generation abilities, yet consistently fall short of traditional
pipeline systems on semantic understanding benchmarks. In this work, we reveal
through systematic experimentation that although LSLMs lose some text input
performance after speech-text alignment training, the performance gap between
speech and text inputs is more pronounced, which we refer to as the modality
gap. To understand this gap, we analyze both coarse- and fine-grained text and
speech representations. At the coarse-grained level, representations of speech
and text in deeper layers are found to be increasingly aligned in direction
(cosine similarity), while concurrently diverging in magnitude (Euclidean
distance). We further find that representation similarity is strongly
correlated with the modality gap. At the fine-grained level, a spontaneous
token-level alignment pattern between text and speech representations is
observed. Based on this, we introduce the Alignment Path Score to quantify
token-level alignment quality, which exhibits stronger correlation with the
modality gap. Building on these insights, we design targeted interventions on
critical tokens through angle projection and length normalization. These
strategies demonstrate the potential to improve correctness for speech inputs.
Our study provides the first systematic empirical analysis of the modality gap
and alignment mechanisms in LSLMs, offering both theoretical and methodological
guidance for future optimization.

</details>


### [114] [SafeMT: Multi-turn Safety for Multimodal Language Models](https://arxiv.org/abs/2510.12133)
*Han Zhu,Juntao Dai,Jiaming Ji,Haoran Li,Chengkun Cai,Pengcheng Wen,Chi-Min Chan,Boyuan Chen,Yaodong Yang,Sirui Han,Yike Guo*

Main category: cs.CL

TL;DR: 本论文提出了SafeMT基准和安全指数（SI）来评估多模态大语言模型（MLLMs）在多轮对话中的安全性，并开发了一种对话安全调节器来提高模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分考虑多模态大语言模型在日常多轮对话中面临的安全风险，因此需要新的评估方法和工具来解决这一问题。

Method: 提出SafeMT基准，包含10,000个包含图像的有害查询多轮对话样本，涵盖17种场景和4种越狱方法。同时提出安全指数（SI）来评估对话中的模型安全性。最后，提出一种对话安全调节器，用于检测恶意意图并提供安全策略。

Result: 在SafeMT基准上评估了17种模型，发现随着对话轮数的增加，模型遭受成功攻击的风险也随之增加。提出的对话安全调节器在减少多轮攻击成功率（ASR）方面优于现有的防护模型。

Conclusion: 多模态大语言模型在多轮对话中的安全机制尚不完善，对话安全调节器是一种有效提高模型安全性的方法。

Abstract: With the widespread use of multi-modal Large Language models (MLLMs), safety
issues have become a growing concern. Multi-turn dialogues, which are more
common in everyday interactions, pose a greater risk than single prompts;
however, existing benchmarks do not adequately consider this situation. To
encourage the community to focus on the safety issues of these models in
multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues
of varying lengths generated from harmful queries accompanied by images. This
benchmark consists of 10,000 samples in total, encompassing 17 different
scenarios and four jailbreak methods. Additionally, we propose Safety Index
(SI) to evaluate the general safety of MLLMs during conversations. We assess
the safety of 17 models using this benchmark and discover that the risk of
successful attacks on these models increases as the number of turns in harmful
dialogues rises. This observation indicates that the safety mechanisms of these
models are inadequate for recognizing the hazard in dialogue interactions. We
propose a dialogue safety moderator capable of detecting malicious intent
concealed within conversations and providing MLLMs with relevant safety
policies. Experimental results from several open-source models indicate that
this moderator is more effective in reducing multi-turn ASR compared to existed
guard models.

</details>


### [115] [Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models](https://arxiv.org/abs/2510.12137)
*Shihao Ji,Zihui Song,Jiajie Huang*

Main category: cs.CL

TL;DR: LLM的幻觉源于Softmax函数产生的“人工确定性”；提出Credal Transformer，用基于证据理论的Credal Attention Mechanism (CAM)替代标准注意力，CAM产生“credal set”来衡量模型不确定性，能识别OOD输入、量化模糊性并减少自信错误。


<details>
  <summary>Details</summary>
Motivation: LLM的幻觉（生成事实错误且自信的断言）源于Transformer的Softmax函数，该函数通过将模糊的注意力分数折叠成单一概率分布来产生“人工确定性”，从而在每一层丢弃不确定性信息。

Method: 引入Credal Transformer，用基于证据理论的Credal Attention Mechanism (CAM)替代标准注意力。CAM产生一个“credal set”（分布集合）而非单一注意力向量，集合的大小直接衡量模型的不确定性。通过将注意力分数重构为狄利克雷分布的证据质量来实现：充分的证据可恢复标准注意力，不充分的证据则产生代表模糊性的扩散分布。

Result: Credal Transformer能够识别分布外（OOD）的输入，量化模糊性，并通过在无法回答的问题上进行弃权显著减少自信错误。

Conclusion: 提出了一种新的架构来缓解LLM的幻觉问题，并提出了一种将不确定性量化直接集成到模型中的设计范式，为更可靠的AI奠定了基础。

Abstract: Large Language Models (LLMs) hallucinate, generating factually incorrect yet
confident assertions. We argue this stems from the Transformer's Softmax
function, which creates "Artificial Certainty" by collapsing ambiguous
attention scores into a single probability distribution, discarding uncertainty
information at each layer. To fix this, we introduce the Credal Transformer,
which replaces standard attention with a Credal Attention Mechanism (CAM) based
on evidential theory. CAM produces a "credal set" (a set of distributions)
instead of a single attention vector, with the set's size directly measuring
model uncertainty. We implement this by re-conceptualizing attention scores as
evidence masses for a Dirichlet distribution: sufficient evidence recovers
standard attention, while insufficient evidence yields a diffuse distribution,
representing ambiguity. Empirically, the Credal Transformer identifies
out-of-distribution inputs, quantifies ambiguity, and significantly reduces
confident errors on unanswerable questions by abstaining. Our contribution is a
new architecture to mitigate hallucinations and a design paradigm that
integrates uncertainty quantification directly into the model, providing a
foundation for more reliable AI.

</details>


### [116] [A Survey on Parallel Reasoning](https://arxiv.org/abs/2510.12164)
*Ziqi Wang,Boye Niu,Zipeng Gao,Zhi Zheng,Tong Xu,Linghui Meng,Zhongli Li,Jing Liu,Yilong Chen,Chen Zhu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.CL

TL;DR: LLM推理的新范式，通过并行探索多条思考路径来增强鲁棒性，克服顺序方法的脆弱性。本文对并行推理的进展、挑战、技术、应用和未来方向进行了全面的总结和概述。


<details>
  <summary>Details</summary>
Motivation: 克服标准顺序推理方法的脆弱性，提高LLM的实际性能。

Method: 对并行推理进行形式化定义，区分相关概念；组织和讨论基于新分类法（非交互式推理、交互式推理、面向效率的解码策略）的先进技术；探索应用场景；提出核心挑战和未来研究方向。

Result: 对并行推理的进展、挑战、技术、应用和未来方向进行了全面的总结和概述。

Conclusion: 本文为并行推理提供了有用的路线图，并鼓励对改进并行推理方法进行更多研究。

Abstract: With the increasing capabilities of Large Language Models (LLMs), parallel
reasoning has emerged as a new inference paradigm that enhances reasoning
robustness by concurrently exploring multiple lines of thought before
converging on a final answer. It has become a significant trend to explore
parallel reasoning to overcome the fragility of standard sequential methods and
improve practical performance. In this paper, we aim to survey and summarize
the progress and challenges of parallel reasoning. We first present a formal
definition of parallel reasoning and clarify its distinction from related
concepts like Chain-of-Thought. Then, we organize and discuss advanced
techniques based on a novel taxonomy, including non-interactive reasoning,
interactive reasoning, and efficiency-focused decoding strategies.
Additionally, we explore various application scenarios, such as solving complex
problems and enhancing the reliability of LLM outputs.Finally, we highlight the
core challenges of parallel reasoning and suggest potential directions for
future research. We hope that our work can provide a useful roadmap for
beginners and encourage more research on improving parallel reasoning methods.
Related source can be avaliable in
https://github.com/PPPP-kaqiu/Awesome-Parallel-Reasoning.

</details>


### [117] [Towards Inference-time Scaling for Continuous Space Reasoning](https://arxiv.org/abs/2510.12167)
*Minghan Wang,Thuy-Trang Vu,Ehsan Shareghi,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 本文研究了将文本推理中的多样本生成和奖励模型重新排序技术应用于连续空间推理的可行性，并指出了其中的挑战和改进方向。


<details>
  <summary>Details</summary>
Motivation: 探究将离散空间推理中有效的多样本生成与奖励模型重新排序技术应用于连续空间推理的可行性。

Method: 使用COCONUT模型作为骨干，通过dropout采样生成多样的连续空间推理路径，并分析Pass@N指标。

Result: 证明了在连续空间中生成多样化推理路径的可行性，Pass@N分析显示出提升性能的潜力。然而，离散空间中有效的重排技术在连续空间中提升有限。

Conclusion: 在连续空间推理中，需要明确引入能够用于区分正确和错误推理的归纳偏置，并且训练框架不仅要优化准确性，还要显式地纳入这些归纳偏置。

Abstract: Inference-time scaling through multiple sample generation in combination with
Process- or Outcome-Reward Model (PRM or ORM) re-ranking has proven effective
for text-based reasoning in large language models. This paper investigates
whether such established techniques can be successfully adapted to reasoning in
the continuous space, using COCONUT (Hao et al. 2024) continuous space
reasoning LM as the backbone. We demonstrate the feasibility of generating
diverse reasoning paths through dropout-based sampling. Our Pass@N analysis on
the generated samples reveals the potential that could enable a significant
gain in performance akin to observed gain in the discrete space. However, we
highlight unique challenges faced for materializing this gain in the continuous
thought space. In particular, working recipes for data generation and training
PRM and ORM models in the discrete space unlocks only marginal improvements in
the continuous space. Through probing various aspects including geometric
properties and trajectory dynamics we identify the underlying reasons that
prevent effective discrimination between correct and incorrect reasoning
(essential for the functioning of PRM and ORM). Our findings reveal that
current limitations stem from the absence of key inductive biases in continuous
thought representations. We argue that the training frameworks for continuous
reasoning LMs require not only to optimize for accuracy but also to explicitly
incorporate inductive biases that could be utilized during inference-time for
discrimination of correct and incorrect thoughts.\footnote{Our code and data
will be publicly available.}

</details>


### [118] [From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing](https://arxiv.org/abs/2510.12181)
*Chengrui Xiang,Tengfei Ma,Xiangzheng Fu,Yiping Liu,Bosheng Song,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: LLaDR是一个大型语言模型辅助的药物再利用框架，通过整合常识性生物医学概念知识来增强知识图谱表示，从而改进对复杂和罕见疾病的治疗发现。


<details>
  <summary>Details</summary>
Motivation: 现有的药物再利用方法忽略了生物医学概念的常识性知识，例如某些药物与特定疗法不兼容，这阻碍了治疗发现的进展。

Method: LLaDR从大型语言模型中提取与治疗相关的文本表示，并使用这些表示来微调知识图谱嵌入模型，从而将与治疗相关的知识注入知识图谱嵌入。

Result: LLaDR在不同场景的基准测试中取得了最先进的性能，并且在阿尔茨海默病案例研究中得到进一步证实。

Conclusion: LLaDR通过整合常识性生物医学概念知识，改进了生物医学概念的表示，提高了对研究不足或复杂适应症的语义理解，从而有效提高了药物再利用的性能。

Abstract: Drug repurposing plays a critical role in accelerating treatment discovery,
especially for complex and rare diseases. Biomedical knowledge graphs (KGs),
which encode rich clinical associations, have been widely adopted to support
this task. However, existing methods largely overlook common-sense biomedical
concept knowledge in real-world labs, such as mechanistic priors indicating
that certain drugs are fundamentally incompatible with specific treatments. To
address this gap, we propose LLaDR, a Large Language Model-assisted framework
for Drug Repurposing, which improves the representation of biomedical concepts
within KGs. Specifically, we extract semantically enriched treatment-related
textual representations of biomedical entities from large language models
(LLMs) and use them to fine-tune knowledge graph embedding (KGE) models. By
injecting treatment-relevant knowledge into KGE, LLaDR largely improves the
representation of biomedical concepts, enhancing semantic understanding of
under-studied or complex indications. Experiments based on benchmarks
demonstrate that LLaDR achieves state-of-the-art performance across different
scenarios, with case studies on Alzheimer's disease further confirming its
robustness and effectiveness. Code is available at
https://github.com/xiaomingaaa/LLaDR.

</details>


### [119] [Not in Sync: Unveiling Temporal Bias in Audio Chat Models](https://arxiv.org/abs/2510.12185)
*Jiayu Yao,Shenghua Liu,Yiwei Wang,Rundong Cheng,Lingrui Mei,Baolong Bi,Zhen Xiong,Xueqi Cheng*

Main category: cs.CL

TL;DR: 大型音频语言模型（LALM）在时间戳预测方面存在时间偏差，这种偏差会随着音频长度的增加而增加，并且因事件类型和位置而异。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型（LALM）在音频理解和多模态推理方面得到越来越多的应用，但它们在定位事件发生时间方面的能力仍未得到充分探索。

Method: 通过在带时间戳的数据集上进行受控实验，量化了时间偏差指数（TBI），并辅以可视化框架来衡量预测事件时间系统的失准情况。

Result: 时间偏差普遍存在于各种数据集和模型中，并且随着音频长度的增加而增加，在长录音中甚至会累积到几十秒，并且因事件类型和位置而异。

Conclusion: 研究结果突显了当前 LALM 的基本局限性，并呼吁开发时间上更鲁棒的架构。

Abstract: Large Audio Language Models (LALMs) are increasingly applied to audio
understanding and multimodal reasoning, yet their ability to locate when events
occur remains underexplored. We present the first systematic study of temporal
bias in LALMs, revealing a key limitation in their timestamp prediction. For
example, when asked "At which second does the lecturer introduce the key
formula?", models often predict timestamps that are consistently earlier or
later than the ground truth. Through controlled experiments on timestamped
datasets, we find that temporal bias (i) is prevalent across datasets and
models, (ii) increases with audio length - even accumulating to tens of seconds
in extended recordings, and (iii) varies across event types and positions. We
quantify this effect with the Temporal Bias Index (TBI), measuring systematic
misalignment in predicted event timings, and complement it with a visualization
framework. Our findings highlight a fundamental limitation in current LALMs and
call for the development of temporally robust architectures.

</details>


### [120] [DPO-Tuned Large Language Models for Segmentation in Simultaneous Speech Translation](https://arxiv.org/abs/2510.12195)
*Zeyu Yang,Satoshi Nakamura*

Main category: cs.CL

TL;DR: LLM结合DPO优化技术，在语音同传分段任务上超越现有方法，提升翻译质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有语音同传分段模型（如SHAS）受限于监督学习和缺乏人类偏好对齐，无法满足实时翻译的自然性需求。

Method: 提出一个基于大型语言模型（LLM）并结合直接偏好优化（DPO）训练的分段框架，利用偏好对齐来预测更符合实时翻译需求的分段点。

Result: 在ACL 60/60语料库的英日、英中、英德三对语言上，DPO调整后的LLM在分段准确率上优于SHAS，并在翻译质量（BLEU, COMET）和延迟（Average Lagging）方面取得持续改进。

Conclusion: 基于偏好的LLM在语音同传分段任务上展现出超越现有预训练模型的潜力，能推动更自适应、更符合人类偏好的实时同声传译技术的发展。

Abstract: Simultaneous speech translation requires accurate segmentation to balance
translation quality and latency. Recent studies such as SHAS have introduced
pretrained segmentation models, achieving stronger performance than heuristic
rules. However, segmentation models such as SHAS, though pretrained and more
robust than heuristic methods, are still constrained by supervised learning
objectives and do not incorporate human preference alignment, which is crucial
for natural real-time interpretation. In this work, we propose a segmentation
framework based on large language models (LLMs) trained with Direct Preference
Optimization (DPO). By leveraging preference alignment, our method enables LLMs
to predict natural segmentation points that better meet the demands of
real-time translation. We evaluate the system on the ACL 60/60 corpus across
three language pairs (English-Japanese, Chinese, German), using SeamlessM4T v2
as the translation backbone. Experimental results show that our DPO-tuned LLM
achieves higher segmentation accuracy than SHAS and yields consistent
improvements in translation quality (BLEU, COMET) as well as latency (Average
Lagging). Furthermore, our system benefits from IWSLT baselines for direct
comparison. These findings highlight the potential of preference-tuned LLMs to
surpass existing pretrained segmentation models and advance adaptive,
human-aligned simultaneous interpretation.

</details>


### [121] [HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment](https://arxiv.org/abs/2510.12217)
*Ali Mekky,Omar El Herraoui,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 现有LLM评估方法缺乏现实场景依据且未考虑伤害严重程度的差异，我们提出了HALF框架，评估现实应用中的模型偏见并按伤害严重程度加权，结果显示LLM在不同领域公平性不一，模型大小或性能不保证公平性，推理模型在医疗领域表现更好但在教育领域表现更差，表明LLM距离部署仍有差距。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法缺乏现实场景依据且未考虑伤害严重程度的差异，例如在外科手术中的偏见与文本摘要中的风格偏见不应同等对待。然而，LLM在临床决策支持、法律分析、招聘和教育等高风险领域得到广泛应用，因此在部署前进行公平性和偏见评估至关重要。

Method: 我们引入了HALF（Harm-Aware LLM Fairness）框架，这是一个与部署对齐的框架，用于评估现实应用中的模型偏见，并根据伤害严重程度对结果进行加权。HALF通过一个五阶段流程将九个应用领域组织成三个层级（严重、中度、轻度）。

Result: 我们对八个LLM进行了评估，结果表明：（1）LLM在不同领域的公平性不一致；（2）模型大小或性能并不保证公平性；（3）推理模型在医疗决策支持方面表现更好，但在教育领域表现更差。

Conclusion: HALF框架揭示了以往基准测试的成功与部署就绪性之间存在明显差距。

Abstract: Large language models (LLMs) are increasingly deployed across high-impact
domains, from clinical decision support and legal analysis to hiring and
education, making fairness and bias evaluation before deployment critical.
However, existing evaluations lack grounding in real-world scenarios and do not
account for differences in harm severity, e.g., a biased decision in surgery
should not be weighed the same as a stylistic bias in text summarization. To
address this gap, we introduce HALF (Harm-Aware LLM Fairness), a
deployment-aligned framework that assesses model bias in realistic applications
and weighs the outcomes by harm severity. HALF organizes nine application
domains into three tiers (Severe, Moderate, Mild) using a five-stage pipeline.
Our evaluation results across eight LLMs show that (1) LLMs are not
consistently fair across domains, (2) model size or performance do not
guarantee fairness, and (3) reasoning models perform better in medical decision
support but worse in education. We conclude that HALF exposes a clear gap
between previous benchmarking success and deployment readiness.

</details>


### [122] [Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability](https://arxiv.org/abs/2510.12229)
*Bianca Raimondi,Daniela Dalbagno,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: LLMs习得人类偏见，Knobe效应（道德偏见）在finetuned LLMs中出现，可通过Layer-Patching定位到特定层，并能通过打补丁到预训练模型来消除，表明偏见可被干预和缓解。


<details>
  <summary>Details</summary>
Motivation: 探究finetuned LLMs中Knobe效应（一种道德偏见）的出现机制及其在模型组件中的溯源。

Method: 对3个开源LLMs进行Layer-Patching分析，以检测Knobe效应是否出现及其位置。

Result: Knobe效应不仅在finetuning过程中被学习，而且局限于特定层；将预训练模型的激活值打补丁到少数关键层足以消除该效应。

Conclusion: LLMs中的社会偏见可以通过有针对性的干预来解释、定位和缓解，无需重新训练模型。

Abstract: Large language models (LLMs) have been shown to internalize human-like biases
during finetuning, yet the mechanisms by which these biases manifest remain
unclear. In this work, we investigated whether the well-known Knobe effect, a
moral bias in intentionality judgements, emerges in finetuned LLMs and whether
it can be traced back to specific components of the model. We conducted a
Layer-Patching analysis across 3 open-weights LLMs and demonstrated that the
bias is not only learned during finetuning but also localized in a specific set
of layers. Surprisingly, we found that patching activations from the
corresponding pretrained model into just a few critical layers is sufficient to
eliminate the effect. Our findings offer new evidence that social biases in
LLMs can be interpreted, localized, and mitigated through targeted
interventions, without the need for model retraining.

</details>


### [123] [DSAS: A Universal Plug-and-Play Framework for Attention Optimization in Multi-Document Question Answering](https://arxiv.org/abs/2510.12251)
*Jiakai Li,Rongzheng Wang,Yizhuo Ma,Shuang Liang,Guangchun Luo,Ke Qin*

Main category: cs.CL

TL;DR: DSAS通过CGW和RAS模块解决了LLM在长文本和信息丢失方面的问题，在多文档问答任务中提高了模型性能，且无需修改模型架构或进行额外训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长文本和“中间迷失”问题上存在局限性，现有解决方案成本高昂且不通用。

Method: 提出双阶段自适应锐化（DSAS）方法，包含（i）上下文门控加权（CGW）模块，通过层级注意力跟踪和位置感知加权来评估段落相关性，以缓解“中间迷失”问题；（ii）互惠注意力抑制（RAS）模块，通过抑制关键文本和不相关文本之间的信息交换来增强对关键段落的关注，从而缓解长程依赖建模的局限性。

Result: DSAS在主流LLMs（Llama, Qwen, Mistral, Deepseek）的四个基准测试中表现出有效性，在Llama-3.1-8B-Instruct和Qwen2.5-14B-Instruct的多文档问答任务上平均F1分数提高了4.2%。消融研究证实了CGW和RAS模块的关键贡献。

Conclusion: DSAS是一种即插即用的解决方案，可有效提升LLMs在多文档问答任务中的性能，无需进行架构修改或额外训练。实验证明了其有效性、稳健性和可扩展性。

Abstract: While large language models (LLMs) show considerable promise across various
fields, they have notable limitations in handling multi-document question
answering (Multi-doc QA) tasks. The first challenge is long-range dependency
modeling, where LLMs struggle to focus on key information in long texts, which
weakens important semantic connections. Second, most LLMs suffer from the
''lost-in-the-middle'' issue, where they have difficulty processing information
in the middle of long inputs. Current solutions either truncate global
dependencies or demand costly finetuning, ultimately lacking a universal and
simple solution for these challenges. To resolve these limitations, we propose
Dual-Stage Adaptive Sharpening (DSAS) containing two modules. (i) The
Contextual Gate Weighting (CGW) module alleviates ''lost-in-the-middle'' by
assessing paragraph relevance through layer-wise attention tracking and
position-aware weighting. (ii) The Reciprocal Attention Suppression (RAS)
module enhances focus on critical paragraphs by suppressing information
exchange between key and irrelevant texts, thus mitigating the limitations in
long-range dependency modeling. Notably, DSAS functions as a plug-and-play
solution requiring no architectural modifications or extra training parameters.
Extensive experiments on four benchmarks demonstrate DSAS's efficacy across
mainstream LLMs (Llama, Qwen, Mistral, and Deepseek), with an average F1-score
improvement of 4.2% in Multi-doc QA tasks on Llama-3.1-8B-Instruct and
Qwen2.5-14B-Instruct. Ablation studies confirm the essential contributions of
both the CGW and RAS modules. In addition, detailed discussions in the Appendix
further validate the robustness and scalability of DSAS.

</details>


### [124] [Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs](https://arxiv.org/abs/2510.12255)
*Blazej Manczak,Eric Lin,Francisco Eiras,James O' Neill,Vaikkunth Mugunthan*

Main category: cs.CL

TL;DR: 现有的技术评估大型语言模型（LLMs）在医疗领域的单轮问答能力，但忽视了多轮交互的复杂性。本研究提出了MedQA-Followup框架，用于评估模型在多轮医疗问答中的鲁棒性，区分浅层鲁棒性和深层鲁棒性，并引入了间接-直接干预轴。实验结果表明，尽管模型在浅层干扰下表现尚可，但在多轮设置下会严重下降，特别是Claude Sonnet 4，准确率从91.2%降至13.5%。间接干预比直接干预更具破坏性。不同模型在重复干预下的表现各异。研究强调了多轮鲁棒性对于医疗LLMs安全部署的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在多轮医疗交互中的可靠性，因为现有评估方法主要关注单轮问答且条件理想化，未能反映医疗咨询的复杂性，如输入冲突、误导性上下文和权威影响。

Method: 提出MedQA-Followup框架，用于系统性评估医疗问答中的多轮鲁棒性。该框架区分浅层鲁棒性（抵抗误导性初始上下文）和深层鲁棒性（在答案受到质疑时保持准确性），并引入间接-直接轴来分离上下文框架和明确建议。通过对MedQA数据集进行受控干预来评估五个最先进的LLMs。

Result: 在MedQA数据集的评估中，虽然模型在浅层干扰下表现尚可，但在多轮设置下准确率急剧下降，例如Claude Sonnet 4的准确率从91.2%降至13.5%。间接的、基于上下文的干预比直接的建议更具破坏性，导致模型准确率下降幅度更大。进一步的分析揭示了模型之间的差异，一些模型在重复干预下性能下降，而另一些则部分恢复甚至有所改善。

Conclusion: 多轮鲁棒性是医疗LLMs安全可靠部署的一个关键但未被充分研究的维度。现有模型在面对多轮交互的挑战时存在严重漏洞，特别是对间接干预的抵抗能力较弱，这对其临床应用构成了重大风险。

Abstract: Large language models (LLMs) are rapidly transitioning into medical clinical
use, yet their reliability under realistic, multi-turn interactions remains
poorly understood. Existing evaluation frameworks typically assess single-turn
question answering under idealized conditions, overlooking the complexities of
medical consultations where conflicting input, misleading context, and
authority influence are common. We introduce MedQA-Followup, a framework for
systematically evaluating multi-turn robustness in medical question answering.
Our approach distinguishes between shallow robustness (resisting misleading
initial context) and deep robustness (maintaining accuracy when answers are
challenged across turns), while also introducing an indirect-direct axis that
separates contextual framing (indirect) from explicit suggestion (direct).
Using controlled interventions on the MedQA dataset, we evaluate five
state-of-the-art LLMs and find that while models perform reasonably well under
shallow perturbations, they exhibit severe vulnerabilities in multi-turn
settings, with accuracy dropping from 91.2% to as low as 13.5% for Claude
Sonnet 4. Counterintuitively, indirect, context-based interventions are often
more harmful than direct suggestions, yielding larger accuracy drops across
models and exposing a significant vulnerability for clinical deployment.
Further compounding analyses reveal model differences, with some showing
additional performance drops under repeated interventions while others
partially recovering or even improving. These findings highlight multi-turn
robustness as a critical but underexplored dimension for safe and reliable
deployment of medical LLMs.

</details>


### [125] [Chinese ModernBERT with Whole-Word Masking](https://arxiv.org/abs/2510.12285)
*Zeyu Zhao,Ningtao Wang,Xing Fu,Yu Cheng*

Main category: cs.CL

TL;DR: 一个为中文设计的Encoder-only Transformer模型，通过优化词汇、掩码策略、上下文长度和训练流程，在中文任务上取得了有竞争力的结果，并在长序列处理和检索任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的Encoder-only Transformer模型在中文上的表现不如英文，因为中文在分词和形态学上存在显著差异。

Method: 1. 硬件感知32k BPE词汇表：针对中文词根/复合词优化，降低嵌入预算。 2. 全词掩码（WWM）与动态掩码课程（30% -> 15%）：使任务难度与训练进度对齐。 3. 两阶段预训练流程：使用RoPE和交替局部/全局注意力将上下文从1024扩展到8192。 4. 阻尼余弦学习率调度：实现稳定的长周期优化。 5. 在~1.2T中文Token上进行预训练：使用CCI3-HQ、CCI4（中文）和Cosmopedia-Chinese数据集。 6. 添加对比学习数据进行微调：在SimCLUE和T2Ranking数据集上进行微调以评估检索导向的质量。

Result: 在CLUE基准测试上，Chinese ModernBERT表现与现有的中文Encoder模型相当。在bf16精度下，实现了高长序列吞吐量，同时保持了短序列的良好速度。在SimCLUE测试集上，使用对比学习数据微调后，取得了0.505（Pearson）/0.537（Spearman）的成绩，优于Qwen-0.6B-embedding。

Conclusion: Chinese ModernBERT在中文任务上具有竞争力，尤其在长序列处理和检索任务上表现出色。通过增加精心筛选的对比学习数据对，可以在语义相似性任务（STS）上实现进一步的提升，并指明了未来模型扩展的路径。模型将开源以促进可复现的研究。

Abstract: Encoder-only Transformers have advanced along three axes -- architecture,
data, and systems -- yielding Pareto gains in accuracy, speed, and memory
efficiency. Yet these improvements have not fully transferred to Chinese, where
tokenization and morphology differ markedly from English. We introduce Chinese
ModernBERT, a from-scratch Chinese encoder that couples: (i) a hardware-aware
32k BPE vocabulary tailored to frequent Chinese affixes/compounds, lowering the
embedding budget; (ii) whole-word masking (WWM) with a dynamic masking
curriculum (30% -> 15%) to align task difficulty with training progress; (iii)
a two-stage pre-training pipeline that extends the native context from 1,024 to
8,192 tokens using RoPE and alternating local/global attention; and (iv) a
damped-cosine learning-rate schedule for stable long-horizon optimization. We
pre-train on ~1.2T Chinese tokens from CCI3-HQ, CCI4 (Chinese), and
Cosmopedia-Chinese. On CLUE, Chinese ModernBERT is competitive with strong
Chinese encoders under a unified fine-tuning protocol. Under bf16 it achieves
high long-sequence throughput while maintaining strong short-sequence speed,
reflecting benefits from budget allocation and attention design. To probe
retrieval-oriented quality, we add a small amount of open contrastive data:
fine-tuning on SimCLUE (~3M pairs) improves further when adding T2Ranking
(~2M), reaching 0.505 (Pearson) / 0.537 (Spearman) on the SimCLUE test set.
Under this open-data setting, Chinese ModernBERT surpasses Qwen-0.6B-embedding
on SimCLUE, suggesting a clear scaling path for STS with additional curated
pairs. We will release tokenizer and weights to facilitate reproducible
research.

</details>


### [126] [A large-scale, unsupervised pipeline for automatic corpus annotation using LLMs: variation and change in the English consider construction](https://arxiv.org/abs/2510.12306)
*Cameron Morin,Matti Marttinen Larsson*

Main category: cs.CL

TL;DR: LLMs可用于大规模自动语法标注，在历史美国英语语料库的案例研究中实现了98%以上的准确率，但需注意成本和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 手动标注语料库方法学效率低下，LLMs可解决此挑战。

Method: 提出一个包含提示工程、预评估、自动批量处理和后评估的四阶段自动化语法标注流程。

Result: 使用GPT-5注释COHA语料库中的143,933个句子，耗时不到60小时，在两个复杂的标注任务上准确率超过98%。

Conclusion: LLMs能够大规模执行数据准备任务，为语料库研究开辟新途径，但需考虑成本、许可和伦理问题。

Abstract: As natural language corpora expand at an unprecedented rate, manual
annotation remains a significant methodological bottleneck in corpus linguistic
work. We address this challenge by presenting a scalable, unsupervised pipeline
for automating grammatical annotation in voluminous corpora using large
language models (LLMs). Unlike previous supervised and iterative approaches,
our method employs a four-phase workflow: prompt engineering, pre-hoc
evaluation, automated batch processing, and post-hoc validation. We demonstrate
the pipeline's accessibility and effectiveness through a diachronic case study
of variation in the English consider construction. Using GPT-5 through the
OpenAI API, we annotate 143,933 sentences from the Corpus of Historical
American English (COHA) in under 60 hours, achieving 98%+ accuracy on two
sophisticated annotation procedures. Our results suggest that LLMs can perform
a range of data preparation tasks at scale with minimal human intervention,
opening new possibilities for corpus-based research, though implementation
requires attention to costs, licensing, and other ethical considerations.

</details>


### [127] [Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation](https://arxiv.org/abs/2510.12316)
*Greta Damo,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: 该研究提出了一种新的知识驱动的析 ] (counter-speech) 生成框架，通过集成检索增强生成 (RAG) 技术，利用联合国数字图书馆、EUR-Lex 和欧盟基本权利机构的文本构建知识库，旨在提高反 ] 话的可靠性和连贯性，并在多目标仇恨言论数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有 ] (counter-speech) 生成方法将任务视为纯文本生成，存在可靠性、连贯性和可扩展性方面的局限性，需要一种新的方法来生成可信的 ] (counter-speech)。

Method: 提出了一种新颖的知识 ] (counter-speech) 生成框架，该框架集成了先进的检索增强生成 (RAG) 流水线，并利用包含 32,792 篇文本的知识库（来自联合国数字图书馆、EUR-Lex 和欧盟基本权利机构）来生成针对 8 个主要目标群体（妇女、有色人种、残疾人、移民、穆斯林、犹太人、LGBT 人士等）的反 ] 话。

Result: 在 MultiTarget-CONAN 数据集上的评估结果显示，该框架在 JudgeLM 和人类评估两方面均优于标准的 LLM 基线和竞争性方法。

Conclusion: 该研究提出的新颖框架和知识库为 ] (counter-speech) 生成（尤其是在仇恨言论领域）的可信度和可靠性研究奠定了基础。

Abstract: Counter-speech generation is at the core of many expert activities, such as
fact-checking and hate speech, to counter harmful content. Yet, existing work
treats counter-speech generation as pure text generation task, mainly based on
Large Language Models or NGO experts. These approaches show severe drawbacks
due to the limited reliability and coherence in the generated countering text,
and in scalability, respectively. To close this gap, we introduce a novel
framework to model counter-speech generation as knowledge-wise text generation
process. Our framework integrates advanced Retrieval-Augmented Generation (RAG)
pipelines to ensure the generation of trustworthy counter-speech for 8 main
target groups identified in the hate speech literature, including women, people
of colour, persons with disabilities, migrants, Muslims, Jews, LGBT persons,
and other. We built a knowledge base over the United Nations Digital Library,
EUR-Lex and the EU Agency for Fundamental Rights, comprising a total of 32,792
texts. We use the MultiTarget-CONAN dataset to empirically assess the quality
of the generated counter-speech, both through standard metrics (i.e., JudgeLM)
and a human evaluation. Results show that our framework outperforms standard
LLM baselines and competitive approach, on both assessments. The resulting
framework and the knowledge base pave the way for studying trustworthy and
sound counter-speech generation, in hate speech and beyond.

</details>


### [128] [Fine-grained Analysis of Brain-LLM Alignment through Input Attribution](https://arxiv.org/abs/2510.12355)
*Michela Proietti,Roberto Capobianco,Mariya Toneva*

Main category: cs.CL

TL;DR: 大脑语言模型对齐与下一词预测的计算原理有所不同，前者侧重语义和篇章信息，后者侧重句法和近期/首因效应。


<details>
  <summary>Details</summary>
Motivation: 研究大脑-LLM对齐（BA）与下一词预测（NWP）之间的关系，以揭示语言处理的计算原理。

Method: 提出一种细粒度输入归因方法，识别对大脑-LLM对齐最重要的词语，并用此方法研究BA与NWP的关系。

Result: BA和NWP依赖的词语子集有显著差异：NWP表现出近期/首因效应和句法偏好，而BA则侧重语义和篇章级信息，并具有更具针对性的近期效应。

Conclusion: BA和NWP依赖的特征不同，这有助于理解LLM与人类语言处理的关系。所提出的归因方法可用于探索模型预测在其他语言处理任务中的认知相关性。

Abstract: Understanding the alignment between large language models (LLMs) and human
brain activity can reveal computational principles underlying language
processing. We introduce a fine-grained input attribution method to identify
the specific words most important for brain-LLM alignment, and leverage it to
study a contentious research question about brain-LLM alignment: the
relationship between brain alignment (BA) and next-word prediction (NWP). Our
findings reveal that BA and NWP rely on largely distinct word subsets: NWP
exhibits recency and primacy biases with a focus on syntax, while BA
prioritizes semantic and discourse-level information with a more targeted
recency effect. This work advances our understanding of how LLMs relate to
human language processing and highlights differences in feature reliance
between BA and NWP. Beyond this study, our attribution method can be broadly
applied to explore the cognitive relevance of model predictions in diverse
language processing tasks.

</details>


### [129] [MoBiLE: Efficient Mixture-of-Experts Inference on Consumer GPU with Mixture of Big Little Experts](https://arxiv.org/abs/2510.12357)
*Yushu Zhao,Yubin Qin,Yang Wang,Xiaolong Yang,Huiming Han,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.CL

TL;DR: MoBiLE是一种即插即用的基于卸载的MoE推理框架，采用大小专家混合（mixture of big-little experts）策略，通过减少不重要 token 的专家数量来加速推理，同时为重要 token 保留全部专家以保证模型质量，并设计了专门的后备和预取机制来提高内存效率，在消费级GPU系统上实现了1.60x到1.72x的加速，且准确率几乎没有下降。


<details>
  <summary>Details</summary>
Motivation: 现有的Mixture-of-Experts（MoE）模型虽然性能优越，但其稀疏激活的卸载策略受限于CPU-GPU互连带宽。现有的预取方法存在训练开销大且在细粒度专家分割模型上效果减弱的问题。

Method: 提出MoBiLE框架，采用大小专家混合（mixture of big-little experts）策略，为不重要 token 减少一半专家数量，为重要 token 保留全部专家，并设计了专门的后备和预取机制来切换大小专家，以提高内存效率。

Result: 在四个典型的现代MoE架构和生成任务上评估MoBiLE，结果显示在消费级GPU系统上，MoBiLE相比基线实现了1.60x到1.72x的加速，同时准确率的下降可以忽略不计。

Conclusion: MoBiLE通过大小专家混合和优化的切换机制，有效解决了MoE模型推理中的带宽瓶颈和内存效率问题，在保证模型质量的同时显著提升了推理速度。

Abstract: Mixture-of-Experts (MoE) models have recently demonstrated exceptional
performance across a diverse range of applications. The principle of sparse
activation in MoE models facilitates an offloading strategy, wherein active
experts are maintained in GPU HBM, while inactive experts are stored in CPU
DRAM. The efficacy of this approach, however, is fundamentally constrained by
the limited bandwidth of the CPU-GPU interconnect. To mitigate this bottleneck,
existing approaches have employed prefetching to accelerate MoE inference.
These methods attempt to predict and prefetch the required experts using
specially trained modules. Nevertheless, such techniques are often encumbered
by significant training overhead and have shown diminished effectiveness on
recent MoE models with fine-grained expert segmentation.
  In this paper, we propose MoBiLE, a plug-and-play offloading-based MoE
inference framework with \textit{mixture of big-little experts}. It reduces the
number of experts for unimportant tokens to half for acceleration while
maintaining full experts for important tokens to guarantee model quality.
Further, a dedicated fallback and prefetching mechanism is designed for
switching between little and big experts to improve memory efficiency. We
evaluate MoBiLE on four typical modern MoE architectures and challenging
generative tasks. Our results show that MoBiLE achieves a speedup of 1.60x to
1.72x compared to the baseline on a consumer GPU system, with negligible
degradation in accuracy.

</details>


### [130] [LLM-REVal: Can We Trust LLM Reviewers Yet?](https://arxiv.org/abs/2510.12367)
*Rui Li,Jia-Chen Gu,Po-Nien Kung,Heming Xia,Junfeng liu,Xiangwen Kong,Zhifang Sui,Nanyun Peng*

Main category: cs.CL

TL;DR: LLMs在学术工作流中的深度融合可能威胁学术公平性，LLM审稿人倾向于偏袒LLM生成的论文，并低估人类作者的论文，尤其是在包含批判性陈述时。然而，LLM审稿过程也能提高论文质量。


<details>
  <summary>Details</summary>
Motivation: 在研究和同行评审中广泛整合LLM，可能带来新的、未被充分探索的风险，尤其是在学术公平性方面。

Method: 通过模拟研究代理（生成和修改论文）和审稿代理（评估论文）来研究LLM作为审稿人的潜在风险。

Result: LLM审稿人的评分与人类判断存在显著不一致：LLM审稿人对LLM生成的论文评分过高，而对人类作者的论文（尤其是包含批判性陈述的）评分过低。LLM审稿偏见包括：语言特征偏见（偏爱LLM写作风格）和对批判性陈述的厌恶。LLM指导的修改提高了LLM生成和人类评估的论文质量。

Conclusion: 在没有充分谨慎的情况下，将LLM部署到同行评审周期中，会对人类作者和学术研究构成风险和公平性问题。然而，LLM在提高论文质量方面具有潜力，尤其对初级研究者和低质量论文的改进。

Abstract: The rapid advancement of large language models (LLMs) has inspired
researchers to integrate them extensively into the academic workflow,
potentially reshaping how research is practiced and reviewed. While previous
studies highlight the potential of LLMs in supporting research and peer review,
their dual roles in the academic workflow and the complex interplay between
research and review bring new risks that remain largely underexplored. In this
study, we focus on how the deep integration of LLMs into both peer-review and
research processes may influence scholarly fairness, examining the potential
risks of using LLMs as reviewers by simulation. This simulation incorporates a
research agent, which generates papers and revises, alongside a review agent,
which assesses the submissions. Based on the simulation results, we conduct
human annotations and identify pronounced misalignment between LLM-based
reviews and human judgments: (1) LLM reviewers systematically inflate scores
for LLM-authored papers, assigning them markedly higher scores than
human-authored ones; (2) LLM reviewers persistently underrate human-authored
papers with critical statements (e.g., risk, fairness), even after multiple
revisions. Our analysis reveals that these stem from two primary biases in LLM
reviewers: a linguistic feature bias favoring LLM-generated writing styles, and
an aversion toward critical statements. These results highlight the risks and
equity concerns posed to human authors and academic research if LLMs are
deployed in the peer review cycle without adequate caution. On the other hand,
revisions guided by LLM reviews yield quality gains in both LLM-based and human
evaluations, illustrating the potential of the LLMs-as-reviewers for
early-stage researchers and enhancing low-quality papers.

</details>


### [131] [Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency](https://arxiv.org/abs/2510.12389)
*Hailay Kidu Teklehaymanot,Wolfgang Nejdl*

Main category: cs.CL

TL;DR: Tokenization disparities in LLMs create computational inequities for non-Latin and morphologically complex languages, necessitating linguistically informed strategies for equitable AI access.


<details>
  <summary>Details</summary>
Motivation: To quantify computational inequities in LLMs arising from tokenization disparities across over 200 languages.

Method: Conducted a large-scale cross-linguistic evaluation using a standardized framework, tiktoken library, and metrics like TPS and RTC, comparing to English baselines.

Result: Latin-script languages show higher tokenization efficiency, while non-Latin and morphologically complex languages have 3-5 times higher RTC ratios, leading to increased costs and reduced context utilization for underrepresented languages.

Conclusion: Current AI systems exhibit structural inequities in tokenization, disadvantaging speakers of low-resource and non-Latin languages. Future work should focus on linguistically informed tokenization and adaptive vocabulary to ensure inclusive multilingual AI.

Abstract: Tokenization disparities pose a significant barrier to achieving equitable
access to artificial intelligence across linguistically diverse populations.
This study conducts a large-scale cross-linguistic evaluation of tokenization
efficiency in over 200 languages to systematically quantify computational
inequities in large language models (LLMs). Using a standardized experimental
framework, we applied consistent preprocessing and normalization protocols,
followed by uniform tokenization through the tiktoken library across all
language samples. Comprehensive tokenization statistics were collected using
established evaluation metrics, including Tokens Per Sentence (TPS) and
Relative Tokenization Cost (RTC), benchmarked against English baselines. Our
cross-linguistic analysis reveals substantial and systematic disparities:
Latin-script languages consistently exhibit higher tokenization efficiency,
while non-Latin and morphologically complex languages incur significantly
greater token inflation, often 3-5 times higher RTC ratios. These
inefficiencies translate into increased computational costs and reduced
effective context utilization for underrepresented languages. Overall, the
findings highlight structural inequities in current AI systems, where speakers
of low-resource and non-Latin languages face disproportionate computational
disadvantages. Future research should prioritize the development of
linguistically informed tokenization strategies and adaptive vocabulary
construction methods that incorporate typological diversity, ensuring more
inclusive and computationally equitable multilingual AI systems.

</details>


### [132] [PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.12434)
*Xiangjun Zai,Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Wenjie Zhang*

Main category: cs.CL

TL;DR: PRoH是一个用于检索增强生成（RAG）的知识超图（KH）框架，通过动态规划和推理克服了现有方法的局限性，实现了多跳问答的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识超图（KH）的检索增强生成（RAG）方法在检索规划的静态性、检索执行的非适应性以及对KH结构和语义的肤浅利用方面存在局限，这阻碍了它们进行有效多跳问答的能力。

Method: PRoH框架包含三个核心创新：1. 上下文感知规划模块，用于勾画局部KH邻域以指导结构化推理计划的生成；2. 结构化问题分解过程，将子问题组织成动态演变的有向无环图（DAG），以实现适应性、多轨迹探索；3. 实体加权重叠（EWO）引导的推理路径检索算法，优先考虑语义连贯的超边遍历。

Result: PRoH在多个领域进行了实验，取得了最优的性能，在F1分数上比之前的SOTA模型HyperGraphRAG平均高出19.73%，在生成评估（G-E）分数上高出8.41%，同时在长程多跳推理任务中保持了强大的鲁棒性。

Conclusion: PRoH通过动态规划和推理，有效解决了现有KH-RAG方法的局限性，在多跳问答任务中取得了SOTA性能和良好的鲁棒性。

Abstract: Knowledge Hypergraphs (KHs) have recently emerged as a knowledge
representation for retrieval-augmented generation (RAG), offering a paradigm to
model multi-entity relations into a structured form. However, existing KH-based
RAG methods suffer from three major limitations: static retrieval planning,
non-adaptive retrieval execution, and superficial use of KH structure and
semantics, which constrain their ability to perform effective multi-hop
question answering. To overcome these limitations, we propose PRoH, a dynamic
Planning and Reasoning over Knowledge Hypergraphs framework. PRoH incorporates
three core innovations: (i) a context-aware planning module that sketches the
local KH neighborhood to guide structurally grounded reasoning plan generation;
(ii) a structured question decomposition process that organizes subquestions as
a dynamically evolving Directed Acyclic Graph (DAG) to enable adaptive,
multi-trajectory exploration; and (iii) an Entity-Weighted Overlap (EWO)-guided
reasoning path retrieval algorithm that prioritizes semantically coherent
hyperedge traversals. Experiments across multiple domains demonstrate that PRoH
achieves state-of-the-art performance, surpassing the prior SOTA model
HyperGraphRAG by an average of 19.73% in F1 and 8.41% in Generation Evaluation
(G-E) score, while maintaining strong robustness in long-range multi-hop
reasoning tasks.

</details>


### [133] [Probing Latent Knowledge Conflict for Faithful Retrieval-Augmented Generation](https://arxiv.org/abs/2510.12460)
*Linfeng Gao,Baolong Bi,Zheng Yuan,Le Wang,Zerui Chen,Zhimin Wei,Shenghua Liu,Qinggang Zhang,Jinsong Su*

Main category: cs.CL

TL;DR: RAG系统存在生成内容与检索证据不一致的问题，本文提出了一种名为CLEAR的框架，通过分析LLM的内部表示来识别和解决知识冲突，从而提高生成内容的准确性和忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在生成内容时可能出现与检索到的证据相矛盾的情况，而现有的解决方法大多依赖外部干预，忽视了LLM内部如何整合信息，尤其是在知识冲突时。

Method: 通过分析LLM的隐藏状态表示，观察到知识整合的层级性、冲突在句子层面的显现以及无关信息可能被放大的现象。基于此，提出CLEAR框架，该框架将上下文分解为句子级别知识，利用隐藏状态探测定位冲突知识，并通过冲突感知微调来指导模型准确整合证据。

Result: 在三个基准测试上的广泛实验表明，CLEAR框架在准确性和上下文忠实度方面均有显著提升，在各种冲突条件下持续优于强大的基线模型。

Conclusion: 本文通过分析LLM内部表示，揭示了知识冲突的整合机制，并提出了CLEAR框架，有效解决了RAG系统的非忠实性问题，提高了生成内容的准确性和忠实度。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to
enhance the factuality of Large Language Models (LLMs). However, existing RAG
systems often suffer from an unfaithfulness issue, where the model's response
contradicts evidence from the retrieved context. Existing approaches to
improving contextual faithfulness largely rely on external interventions, such
as prompt engineering, decoding constraints, or reward-based fine-tuning. These
works treat the LLM as a black box and overlook a crucial question: how does
the LLM internally integrate retrieved evidence with its parametric memory,
particularly under knowledge conflicts? To address this gap, we conduct a
probing-based analysis of hidden-state representations in LLMs and observe
three findings: knowledge integration occurs hierarchically, conflicts manifest
as latent signals at the sentence level, and irrelevant context is often
amplified when aligned with parametric knowledge. Building on these findings,
we propose CLEAR (Conflict-Localized and Enhanced Attention for RAG), a
framework that (i) decomposes context into fine-grained sentence-level
knowledge, (ii) employs hidden-state probing to localize conflicting knowledge,
and (iii) introduces conflict-aware fine-tuning to guide the model to
accurately integrate retrieved evidence. Extensive experiments across three
benchmarks demonstrate that CLEAR substantially improves both accuracy and
contextual faithfulness, consistently outperforming strong baselines under
diverse conflict conditions. The related resources are available at
https://github.com/LinfengGao/CLEAR.

</details>


### [134] [Resource-sensitive but language-blind: Community size and not grammatical complexity better predicts the accuracy of Large Language Models in a novel Wug Test](https://arxiv.org/abs/2510.12463)
*Nikoleta Pantelidou,Evelina Leivada,Paolo Morosi*

Main category: cs.CL

TL;DR: 大型语言模型在形态学泛化任务上表现出类似人类的准确性，但这种准确性更多地受到可用训练数据量的影响，而非语言本身的复杂性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在处理新词时的形态学泛化能力，并与人类表现进行比较，以了解模型准确性是受语言复杂度还是训练数据量影响。

Method: 使用多语言版Wug测试，在四种语言（加泰罗尼亚语、英语、希腊语、西班牙语）上测试了六个模型，并将结果与人类说话者进行比较。

Result: 模型在新词上泛化形态学过程的准确性达到了人类水平。然而，准确性模式更符合社区规模和数据可用性，而非结构复杂度。西班牙语和英语等资源更丰富的语言准确性高于加泰罗尼亚语和希腊语。

Conclusion: 大型语言模型的行为主要受语言资源丰富度的驱动，而不是对语法复杂性的敏感性，这表明模型在语言能力方面的表现可能只是表面上类似人类。

Abstract: The linguistic abilities of Large Language Models are a matter of ongoing
debate. This study contributes to this discussion by investigating model
performance in a morphological generalization task that involves novel words.
Using a multilingual adaptation of the Wug Test, six models were tested across
four partially unrelated languages (Catalan, English, Greek, and Spanish) and
compared with human speakers. The aim is to determine whether model accuracy
approximates human competence and whether it is shaped primarily by linguistic
complexity or by the quantity of available training data. Consistent with
previous research, the results show that the models are able to generalize
morphological processes to unseen words with human-like accuracy. However,
accuracy patterns align more closely with community size and data availability
than with structural complexity, refining earlier claims in the literature. In
particular, languages with larger speaker communities and stronger digital
representation, such as Spanish and English, revealed higher accuracy than
less-resourced ones like Catalan and Greek. Overall, our findings suggest that
model behavior is mainly driven by the richness of linguistic resources rather
than by sensitivity to grammatical complexity, reflecting a form of performance
that resembles human linguistic competence only superficially.

</details>


### [135] [SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression](https://arxiv.org/abs/2510.12474)
*Biao Zhang,Lixin Chen,Tong Liu,Bo Zheng*

Main category: cs.CL

TL;DR: SMEC通过SMRL、ADS和S-XBM模块，在保持性能的同时显著降低了高维嵌入的维度，解决了计算复杂性和存储需求问题。


<details>
  <summary>Details</summary>
Motivation: 高维嵌入会加剧计算复杂性和存储需求，阻碍实际部署。

Method: 提出了一种名为SMEC的新型训练框架，包含SMRL（缓解梯度方差）、ADS（减少维度剪枝时的信息损失）和S-XBM（增强高维和低维嵌入之间的无监督学习）模块。

Result: SMEC在图像、文本和多模态数据集上实现了显著的降维，同时保持了性能。在BEIR数据集上，SMEC压缩后的LLM2Vec嵌入（256维）性能比Matryoshka-Adaptor和Search-Adaptor模型分别提高了1.1和2.7个百分点。

Conclusion: SMEC成功地解决了高维嵌入带来的挑战，并在多个数据集上证明了其有效性。

Abstract: Large language models (LLMs) generate high-dimensional embeddings that
capture rich semantic and syntactic information. However, high-dimensional
embeddings exacerbate computational complexity and storage requirements,
thereby hindering practical deployment. To address these challenges, we propose
a novel training framework named Sequential Matryoshka Embedding Compression
(SMEC). This framework introduces the Sequential Matryoshka Representation
Learning(SMRL) method to mitigate gradient variance during training, the
Adaptive Dimension Selection (ADS) module to reduce information degradation
during dimension pruning, and the Selectable Cross-batch Memory (S-XBM) module
to enhance unsupervised learning between high- and low-dimensional embeddings.
Experiments on image, text, and multimodal datasets demonstrate that SMEC
achieves significant dimensionality reduction while maintaining performance.
For instance, on the BEIR dataset, our approach improves the performance of
compressed LLM2Vec embeddings (256 dimensions) by 1.1 points and 2.7 points
compared to the Matryoshka-Adaptor and Search-Adaptor models, respectively.

</details>


### [136] [When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection](https://arxiv.org/abs/2510.12476)
*Lang Gao,Xuhui Li,Chenxi Wang,Mingzhe Li,Wei Liu,Zirui Song,Jinghui Zhang,Rui Yan,Preslav Nakov,Xiuying Chen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have grown more powerful in language generation,
producing fluent text and even imitating personal style. Yet, this ability also
heightens the risk of identity impersonation. To the best of our knowledge, no
prior work has examined personalized machine-generated text (MGT) detection. In
this paper, we introduce \dataset, the first benchmark for evaluating detector
robustness in personalized settings, built from literary and blog texts paired
with their LLM-generated imitations. Our experimental results demonstrate large
performance gaps across detectors in personalized settings: some
state-of-the-art models suffer significant drops. We attribute this limitation
to the \textit{feature-inversion trap}, where features that are discriminative
in general domains become inverted and misleading when applied to personalized
text. Based on this finding, we propose \method, a simple and reliable way to
predict detector performance changes in personalized settings. \method
identifies latent directions corresponding to inverted features and constructs
probe datasets that differ primarily along these features to evaluate detector
dependence. Our experiments show that \method can accurately predict both the
direction and the magnitude of post-transfer changes, showing 85\% correlation
with the actual performance gaps. We hope that this work will encourage further
research on personalized text detection.

</details>


### [137] [BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)](https://arxiv.org/abs/2510.12516)
*Tomas Ruiz,Siyao Peng,Barbara Plank,Carsten Schwemmer*

Main category: cs.CL

TL;DR: Test-time scaling methods were applied to LeWiDi-2025 tasks to evaluate annotation disagreements, with Model Averaging and Majority Voting showing improvements, while Best-of-N sampling did not.


<details>
  <summary>Details</summary>
Motivation: To evaluate annotation disagreements on LeWiDi-2025 tasks by transferring and evaluating test-time scaling techniques, which were previously limited to domains with verifiably correct answers.

Method: Applied three test-time scaling methods (Model Averaging, Majority Voting, and Best-of-N sampling) to LeWiDi-2025 tasks and analyzed their performance.

Result: Model Averaging and Majority Voting consistently improved LLM performance on LeWiDi tasks, but Best-of-N sampling did not show improvement.

Conclusion: Best-of-N method does not currently transfer from mathematics to LeWiDi tasks, and further analysis is needed to understand the reasons for this gap.

Abstract: Test-time scaling is a family of techniques to improve LLM outputs at
inference time by performing extra computation. To the best of our knowledge,
test-time scaling has been limited to domains with verifiably correct answers,
like mathematics and coding. We transfer test-time scaling to the LeWiDi-2025
tasks to evaluate annotation disagreements. We experiment with three test-time
scaling methods: two benchmark algorithms (Model Averaging and Majority
Voting), and a Best-of-N sampling method. The two benchmark methods improve LLM
performance consistently on the LeWiDi tasks, but the Best-of-N method does
not. Our experiments suggest that the Best-of-N method does not currently
transfer from mathematics to LeWiDi tasks, and we analyze potential reasons for
this gap.

</details>


### [138] [VISaGE: Understanding Visual Generics and Exceptions](https://arxiv.org/abs/2510.12548)
*Stella Frank,Emily Allaway*

Main category: cs.CL

TL;DR: VLMs在评估时，当输入不匹配时，其概念理解能力会下降，这种影响比语义先验的影响更大。


<details>
  <summary>Details</summary>
Motivation: 在评估时，当评估实例不典型时，VLMs 会在“文本和视觉输入都相关”的实用先验和“概念表征对该类别的实例普遍成立”的语义先验之间产生冲突。为了理解VLMs如何权衡这些先验，我们需要引入新的评估方法。

Method: 构建了一个名为VISaGE的新评估数据集，其中包含典型和异常的图像。通过精心设计的实验来测试VLMs在面对不匹配的图像时，概念理解能力下降的程度。

Result: 实验表明，当实用先验所依赖的同质性假设被不匹配的图像违反时，概念理解能力会下降。这种影响在单独查询实例时比语义先验的影响更强。

Conclusion: VLMs在评估时，当输入不匹配时，其概念理解能力会下降，这种影响比语义先验的影响更大。

Abstract: While Vision Language Models (VLMs) learn conceptual representations, in the
form of generalized knowledge, during training, they are typically used to
analyze individual instances. When evaluation instances are atypical, this
paradigm results in tension between two priors in the model. The first is a
pragmatic prior that the textual and visual input are both relevant, arising
from VLM finetuning on congruent inputs; the second is a semantic prior that
the conceptual representation is generally true for instances of the category.
In order to understand how VLMs trade off these priors, we introduce a new
evaluation dataset, VISaGE, consisting of both typical and exceptional images.
In carefully balanced experiments, we show that conceptual understanding
degrades when the assumption of congruency underlying the pragmatic prior is
violated with incongruent images. This effect is stronger than the effect of
the semantic prior when querying about individual instances.

</details>


### [139] [Teaching Language Models to Faithfully Express their Uncertainty](https://arxiv.org/abs/2510.12587)
*Bryan Eikema,Evgenia Ilia,José G. C. de Souza,Chrysoula Zerva,Wilker Aziz*

Main category: cs.CL

TL;DR: LLMs在表达不确定性方面存在问题，会导致信息不准确。本文提出了一种名为FUT（Faithful Uncertainty Tuning）的微调方法，通过在不改变模型回答分布的情况下，教会LLMs准确表达不确定性，从而有效缩小信息不准确的差距，并保持了问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在表达不确定性时常常存在沟通不当的问题，即使是强大的LLMs也会出现不准确的信息传达，形成“忠实度差距”。

Method: 提出了一种名为FUT（Faithful Uncertainty Tuning）的微调方法。该方法通过增强模型样本的不确定性提示词（如“可能”、“很可能”）并使其与样本的一致性对齐，来训练指令微调的LLMs。此过程不需要额外的监督，只需要模型和一套提示词。

Result: FUT在开放域问答任务中，跨多个模型和数据集的评估结果表明，该方法显著缩小了忠实度差距，同时保持了问答准确性，并且只引入了极小的语义分布偏移。此外，FUT在不同的解码策略、提示词选择和其他不确定性表达形式（如数值）方面也表现出鲁棒性。

Conclusion: FUT是一种简单有效的方法，可以教会LLMs准确地传达它们的不确定性。

Abstract: Large language models (LLMs) often miscommunicate their uncertainty: repeated
queries can produce divergent answers, yet generated responses are typically
unhedged or hedged in ways that do not reflect this variability. This conveys
unfaithful information about the uncertain state of the LLMs' knowledge,
creating a faithfulness gap that affects even strong LLMs. We introduce
Faithful Uncertainty Tuning (FUT): a fine-tuning approach that teaches
instruction-tuned LLMs to express uncertainty faithfully without altering their
underlying answer distribution. We construct training data by augmenting model
samples with uncertainty hedges (i.e. verbal cues such as 'possibly' or
'likely') aligned with sample consistency, requiring no supervision beyond the
model and a set of prompts. We evaluate FUT on open-domain question answering
(QA) across multiple models and datasets. Our results show that FUT
substantially reduces the faithfulness gap, while preserving QA accuracy and
introducing minimal semantic distribution shift. Further analyses demonstrate
robustness across decoding strategies, choice of hedgers, and other forms of
uncertainty expression (i.e. numerical). These findings establish FUT as a
simple and effective way to teach LLMs to communicate uncertainty faithfully.

</details>


### [140] [StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis](https://arxiv.org/abs/2510.12608)
*Siyuan Li,Aodu Wulianghai,Xi Lin,Guangyan Li,Xiang Chen,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: StyleDecipher是一个用于检测大型语言模型生成文本的框架，通过结合离散风格指标和连续风格表示来量化风格差异，从而实现准确、可解释和领域无关的检测。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型生成文本检测方法泛化能力有限、易受改写影响且缺乏可解释性，尤其是在面对风格多样性或人机混合写作时。

Method: StyleDecipher结合使用离散风格指示符和从语义嵌入派生出的连续风格表示，以统一的表示空间捕捉人类和大型语言模型输出在风格上的差异。

Result: 在五个不同领域（新闻、代码、论文、评论和学术摘要）的广泛实验中，StyleDecipher在领域内检测方面始终 achieves state-of-the-art 准确性。在跨领域评估中，其性能比现有基线高出 36.30%，并能抵抗对抗性扰动和混合人机内容。

Conclusion: 风格信号可以为区分机器生成文本提供可解释的证据，StyleDecipher能够准确、可解释且独立于领域地检测大型语言模型生成文本。

Abstract: With the increasing integration of large language models (LLMs) into
open-domain writing, detecting machine-generated text has become a critical
task for ensuring content authenticity and trust. Existing approaches rely on
statistical discrepancies or model-specific heuristics to distinguish between
LLM-generated and human-written text. However, these methods struggle in
real-world scenarios due to limited generalization, vulnerability to
paraphrasing, and lack of explainability, particularly when facing stylistic
diversity or hybrid human-AI authorship. In this work, we propose
StyleDecipher, a robust and explainable detection framework that revisits
LLM-generated text detection using combined feature extractors to quantify
stylistic differences. By jointly modeling discrete stylistic indicators and
continuous stylistic representations derived from semantic embeddings,
StyleDecipher captures distinctive style-level divergences between human and
LLM outputs within a unified representation space. This framework enables
accurate, explainable, and domain-agnostic detection without requiring access
to model internals or labeled segments. Extensive experiments across five
diverse domains, including news, code, essays, reviews, and academic abstracts,
demonstrate that StyleDecipher consistently achieves state-of-the-art in-domain
accuracy. Moreover, in cross-domain evaluations, it surpasses existing
baselines by up to 36.30%, while maintaining robustness against adversarial
perturbations and mixed human-AI content. Further qualitative and quantitative
analysis confirms that stylistic signals provide explainable evidence for
distinguishing machine-generated text. Our source code can be accessed at
https://github.com/SiyuanLi00/StyleDecipher.

</details>


### [141] [ACADATA: Parallel Dataset of Academic Data for Machine Translation](https://arxiv.org/abs/2510.12621)
*Iñaki Lacunza,Javier Garcia Gilabert,Francesca De Luca Fornaciari,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Maite Melero,Marta Villegas*

Main category: cs.CL

TL;DR: ACADATA是一个高质量的学术翻译并行数据集，包含训练集ACAD-TRAIN和评估集ACAD-BENCH。在ACAD-TRAIN上微调的LLM在学术翻译和长上下文翻译方面表现出色，超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决学术翻译和长上下文翻译领域的数据集和模型性能问题，提供一个高质量的并行数据集和相应微调的模型。

Method: 构建了ACADATA数据集，包含ACAD-TRAIN和ACAD-BENCH两个子集。在ACAD-TRAIN上微调了两个LLM，并在ACAD-BENCH上与现有模型进行性能比较。

Result: 微调后的LLM在学术翻译方面平均提升了6.1和12.4 d-BLEU分数（针对7B和2B模型），在长上下文翻译方面（非英语出向）提升高达24.9%。表现最佳的微调模型在学术翻译领域超越了现有的最佳专有和开源模型。

Conclusion: ACADATA数据集、微调模型以及相关研究成果为学术领域和长上下文翻译的研究提供了宝贵的资源，推动了该领域的研究进展。

Abstract: We present ACADATA, a high-quality parallel dataset for academic translation,
that consists of two subsets: ACAD-TRAIN, which contains approximately 1.5
million author-generated paragraph pairs across 96 language directions and
ACAD-BENCH, a curated evaluation set of almost 6,000 translations covering 12
directions. To validate its utility, we fine-tune two Large Language Models
(LLMs) on ACAD-TRAIN and benchmark them on ACAD-BENCH against specialized
machine-translation systems, general-purpose, open-weight LLMs, and several
large-scale proprietary models. Experimental results demonstrate that
fine-tuning on ACAD-TRAIN leads to improvements in academic translation quality
by +6.1 and +12.4 d-BLEU points on average for 7B and 2B models respectively,
while also improving long-context translation in a general domain by up to
24.9% when translating out of English. The fine-tuned top-performing model
surpasses the best propietary and open-weight models on academic translation
domain. By releasing ACAD-TRAIN, ACAD-BENCH and the fine-tuned models, we
provide the community with a valuable resource to advance research in academic
domain and long-context translation.

</details>


### [142] [COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point-of-View questions](https://arxiv.org/abs/2510.12637)
*Nzubechukwu C. Ohalete,Kevin B. Gittner,Lauren M. Matheny*

Main category: cs.CL

TL;DR: COSTAR-A是COSTAR的改进版，通过添加‘Answer’组件来提升小模型在指令性任务上的表现，尤其对Llama 3.1-8B模型效果显著。


<details>
  <summary>Details</summary>
Motivation: LLM对提示词设计敏感，需要优化提示词以获得高质量输出。现有COSTAR框架对小模型在指令性任务上表现不一致。

Method: 提出COSTAR-A，在COSTAR（Context, Objective, Style, Tone, Audience, Response）基础上增加‘Answer’组件，并在小模型上进行测试。

Result: COSTAR-A提升了部分小模型（如Llama 3.1-8B）在特定任务上的输出结构和决定性，但效果因模型和任务而异。

Conclusion: COSTAR-A框架具有良好的适应性和可扩展性，特别适用于资源受限硬件上的高效AI部署。

Abstract: Large Language Models (LLMs) are highly sensitive to prompt design, and
making optimized prompting techniques is crucial for generating consistent,
high-quality outputs. In this study, we introduce COSTAR-A, a novel prompt
engineering framework that enhances the existing COSTAR method, which stands
for Context, Objective, Style, Tone, Audience, and Response, by adding the
'Answer' component at the end. We demonstrate that while the original COSTAR
framework improves prompt clarity and aligns outputs for larger LLMs, its
performance is less consistent with smaller, locally optimized models,
particularly in tasks that require more directive or constrained outputs.
Through a series of controlled prompt-output assessments with smaller (at most
8 billion parameters), fine-tuned models, we found that COSTAR-A can enhance
the output structure and decisiveness of localized LLMs for certain tasks,
although its effectiveness varies across models and use cases. Notably, the
Llama 3.1-8B model exhibited performance improvements when prompted with
COSTAR-A compared to COSTAR alone. These findings emphasize the adaptability
and scalability of COSTAR-A as a prompting framework, particularly in
computationally efficient AI deployments on resource-constrained hardware.

</details>


### [143] [Reasoning Pattern Matters: Learning to Reason without Human Rationales](https://arxiv.org/abs/2510.12643)
*Chaoxu Pang,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: LLM推理研究表明，模式识别是关键，而非数据量，PARO框架可替代昂贵的人工标注。


<details>
  <summary>Details</summary>
Motivation: SFT+RLVR范式在LLM推理中广泛应用，但高质量标注成本高昂。本研究旨在探索如何降低标注成本同时保持推理性能。

Method: 研究模式化推理任务，提出PARO框架，利用LLM生成与任务推理模式一致的标注，替代人工标注。

Result: PARO生成的标注可使SFT+RLVR达到与人工标注相当的性能，且标注成本降低10倍。

Conclusion: LLM的模式识别能力是推理性能的关键。PARO框架能够有效替代大规模人工标注，大幅降低成本，仅需少量人工监督即可。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning
capabilities under the widely adopted SFT+RLVR paradigm, which first performs
Supervised Fine-Tuning (SFT) on human-annotated reasoning trajectories
(rationales) to establish initial reasoning behaviors, then applies
Reinforcement Learning with Verifiable Rewards (RLVR) to optimize the model
using verifiable signals without golden rationales. However, annotating
high-quality rationales for the SFT stage remains prohibitively expensive. This
paper investigates when and how rationale annotation costs can be substantially
reduced without compromising reasoning performance. We identify a broad class
of problems, termed patterned reasoning tasks, where reasoning follows a fixed,
procedural strategy consistent across instances. Although instances vary in
content such as domain knowledge, factual information, or numeric values, the
solution derives from applying a shared reasoning pattern. We argue that the
success of SFT+RLVR on such tasks primarily stems from its ability to enable
models to internalize these reasoning patterns. Using numerical semantic
matching as a representative task, we provide both causal and behavioral
evidence showing that reasoning patterns rather than the quantity or quality of
rationales are the key determinant of performance. Building on these insights,
we propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet
effective framework that enables LLMs to generate rationales aligned with
task-specific reasoning patterns without requiring human rationale annotations.
Experiments show that PARO-generated rationales achieve comparable SFT+RLVR
performance to human rationales that are 10 times larger. These results suggest
that large-scale human rationale annotations can be replaced with LLM-based
automatic annotations requiring only limited human supervision over reasoning
patterns.

</details>


### [144] [Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations](https://arxiv.org/abs/2510.12699)
*Sunny Yu,Ahmad Jabbar,Robert Hawkins,Dan Jurafsky,Myra Cheng*

Main category: cs.CL

TL;DR: LLMs在开放式生成任务中存在输出同质化或幻觉问题，这是由生成空间大小（GSS）不当引起的。GSSBench基准测试和EigenScore等指标可以衡量GSS，并应用于检测提示歧义、理解模型推理和引导模型生成高质量、多样化的输出。


<details>
  <summary>Details</summary>
Motivation: 开放式生成任务需要不同程度的输出多样性，但现有LLM在创意任务上输出过于同质化，在事实任务上产生不准确的幻觉。这两种失败模式都源于生成空间大小（GSS）不当，即模型考虑的语义不同的输出集合。

Method: 提出GSS（生成空间大小）的概念，并构建GSSBench测试套件，包含具有真实GSS关系的提示对，用于评估不同指标。评估结果表明，EigenScore等幻觉检测指标优于标准的GSS和不确定性量化指标。

Result: EigenScore等幻觉检测指标在衡量GSS方面表现优于标准指标，并且仅使用模型内部信息，提供了对模型内部任务表示的可解释见解。

Conclusion: GSS可以应用于检测提示歧义、理解模型的“过度思考”和“思考不足”现象，并引导模型扩展其生成空间以产生高质量和多样化的输出。

Abstract: Different open-ended generation tasks require different degrees of output
diversity. However, current LLMs are often miscalibrated. They collapse to
overly homogeneous outputs for creative tasks and hallucinate diverse but
incorrect responses for factual tasks. We argue that these two failure modes
are unified by, and can both be addressed by, the notion of effective
generation space size (GSS) -- the set of semantically distinct outputs a model
considers for a prompt. We present GSSBench, a task suite of prompt pairs with
ground-truth GSS relationships to assess different metrics and understand where
models diverge from desired behavior. We find that hallucination detection
metrics, particularly EigenScore, consistently outperform standard diversity
and uncertainty quantification metrics, while using only model internals,
providing interpretable insights into a model's internal task representations.
We demonstrate three applications of GSS: (1) detecting prompt ambiguity and
predicting clarification questions for better grounding, (2) interpreting
overthinking and underthinking in reasoning models, and (3) steering models to
expand their generation space to yield high-quality and diverse outputs.

</details>


### [145] [Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception](https://arxiv.org/abs/2510.12720)
*Ziyang Ma,Ruiyang Xu,Zhenghao Xing,Yunfei Chu,Yuxuan Wang,Jinzheng He,Jin Xu,Pheng-Ann Heng,Kai Yu,Junyang Lin,Eng Siong Chng,Xie Chen*

Main category: cs.CL

TL;DR: 该研究系统地探讨了全息语言模型（OLM）在细粒度多模态感知方面的能力，提出了名为Omni-Detective的数据生成管道和Omni-Cloze评估基准，并训练了Audio-Captioner和Omni-Captioner模型，在细粒度音频和视听理解方面取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的全息语言模型（OLM）在捕捉和描述细粒度多模态信息方面能力有限，需要更深入的研究来提升其细粒度感知能力。

Method: 提出Omni-Detective数据生成管道，通过工具调用自主生成细粒度且低幻觉的多模态数据。基于此数据训练了Audio-Captioner（仅音频）和Omni-Captioner（视听）模型。设计了Omni-Cloze评估基准，用于评估细粒度音频、视频及视听字幕。

Result: Audio-Captioner在MMAU和MMAR上表现优于现有开源模型，接近Gemini 2.5 Pro。Omni-Captioner在VDC上达到新的SOTA，并在video-SALMONN 2上实现了细节和幻觉的最佳平衡。Omni-Detective生成的数据质量高，Omni-Cloze评估效果好。

Conclusion: Omni-Detective能够生成高质量的细粒度字幕，Omni-Cloze是评估细粒度字幕的有效基准，所提出的模型在细粒度多模态感知任务上表现出色。

Abstract: Fine-grained perception of multimodal information is critical for advancing
human-AI interaction. With recent progress in audio-visual technologies, Omni
Language Models (OLMs), capable of processing audio and video signals in
parallel, have emerged as a promising paradigm for achieving richer
understanding and reasoning. However, their capacity to capture and describe
fine-grained details remains limited explored. In this work, we present a
systematic and comprehensive investigation of omni detailed perception from the
perspectives of the data pipeline, models, and benchmark. We first identify an
inherent "co-growth" between detail and hallucination in current OLMs. To
address this, we propose Omni-Detective, an agentic data generation pipeline
integrating tool-calling, to autonomously produce highly detailed yet minimally
hallucinatory multimodal data. Based on the data generated with Omni-Detective,
we train two captioning models: Audio-Captioner for audio-only detailed
perception, and Omni-Captioner for audio-visual detailed perception. Under the
cascade evaluation protocol, Audio-Captioner achieves the best performance on
MMAU and MMAR among all open-source models, surpassing Gemini 2.5 Flash and
delivering performance comparable to Gemini 2.5 Pro. On existing detailed
captioning benchmarks, Omni-Captioner sets a new state-of-the-art on VDC and
achieves the best trade-off between detail and hallucination on the
video-SALMONN 2 testset. Given the absence of a dedicated benchmark for omni
detailed perception, we design Omni-Cloze, a novel cloze-style evaluation for
detailed audio, visual, and audio-visual captioning that ensures stable,
efficient, and reliable assessment. Experimental results and analysis
demonstrate the effectiveness of Omni-Detective in generating high-quality
detailed captions, as well as the superiority of Omni-Cloze in evaluating such
detailed captions.

</details>


### [146] [Which Word Orders Facilitate Length Generalization in LMs? An Investigation with GCG-Based Artificial Languages](https://arxiv.org/abs/2510.12722)
*Nadine El-Naggar,Tatsuki Kuribayashi,Ted Briscoe*

Main category: cs.CL

TL;DR: 语言模型倾向于学习更常见的语言结构，而不是罕见的或不合理的结构。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨语言模型（LMs）是否具有偏向类型学上更常见的语法属性而非罕见、不合理的属性的归纳偏见，并将其研究从两个方面进行了扩展。

Method: 本研究采用广义范畴语法（GCG）扩展了以往研究的无上下文人工语言（ALs）形式化，以涵盖已证实但先前被忽视的结构，如无界依赖和轻微上下文相关结构。同时，研究重点评估了LMs处理未见过的更长测试句子的泛化能力。

Result: 通过更贴近自然语言的人工语言和更侧重泛化的实验范式，研究结果更清晰地表明，类型学上合理的词序更容易被语言模型有效泛化。

Conclusion: 语言模型倾向于更容易地泛化类型学上合理的词序。

Abstract: Whether language models (LMs) have inductive biases that favor typologically
frequent grammatical properties over rare, implausible ones has been
investigated, typically using artificial languages (ALs) (White and Cotterell,
2021; Kuribayashi et al., 2024). In this paper, we extend these works from two
perspectives. First, we extend their context-free AL formalization by adopting
Generalized Categorial Grammar (GCG) (Wood, 2014), which allows ALs to cover
attested but previously overlooked constructions, such as unbounded dependency
and mildly context-sensitive structures. Second, our evaluation focuses more on
the generalization ability of LMs to process unseen longer test sentences.
Thus, our ALs better capture features of natural languages and our experimental
paradigm leads to clearer conclusions -- typologically plausible word orders
tend to be easier for LMs to productively generalize.

</details>


### [147] [Hey, wait a minute: on at-issue sensitivity in Language Models](https://arxiv.org/abs/2510.12740)
*Sanghee J. Kim,Kanishka Misra*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Evaluating the naturalness of dialogue in language models (LMs) is not
trivial: notions of 'naturalness' vary, and scalable quantitative metrics
remain limited. This study leverages the linguistic notion of 'at-issueness' to
assess dialogue naturalness and introduces a new method: Divide, Generate,
Recombine, and Compare (DGRC). DGRC (i) divides a dialogue as a prompt, (ii)
generates continuations for subparts using LMs, (iii) recombines the dialogue
and continuations, and (iv) compares the likelihoods of the recombined
sequences. This approach mitigates bias in linguistic analyses of LMs and
enables systematic testing of discourse-sensitive behavior. Applying DGRC, we
find that LMs prefer to continue dialogue on at-issue content, with this effect
enhanced in instruct-tuned models. They also reduce their at-issue preference
when relevant cues (e.g., "Hey, wait a minute") are present. Although
instruct-tuning does not further amplify this modulation, the pattern reflects
a hallmark of successful dialogue dynamics.

</details>


### [148] [Language Models Model Language](https://arxiv.org/abs/2510.12766)
*Łukasz Borchmann*

Main category: cs.CL

TL;DR: LLMs不应被视为“符号系统”或“计算系统”，而应被视为“已说和已写的全部内容”，其核心是语言元素的“使用频率”。


<details>
  <summary>Details</summary>
Motivation: 批评者质疑LLMs能否通过“深层结构”或“基础”来模拟语言，达到理想化的“能力”。本文旨在转变视角，运用Witold Mańczak的经验主义原理来挑战这些批评，并为设计、评估和解释语言模型提供指导。

Method: 采用Witold Mańczak的经验主义语言学框架，将语言定义为“所有已说和已写内容的总体”，并强调“使用频率”是语言的主要原则，以此来挑战对LLMs的批评。

Result: 基于Mańczak的框架，我们能够以一种新的方式来审视和挑战先前对LLMs的批评。

Conclusion: LLMs的评估和解释应基于其“使用频率”而非传统的“符号系统”或“计算系统”的观点。

Abstract: Linguistic commentary on LLMs, heavily influenced by the theoretical
frameworks of de Saussure and Chomsky, is often speculative and unproductive.
Critics challenge whether LLMs can legitimately model language, citing the need
for "deep structure" or "grounding" to achieve an idealized linguistic
"competence." We argue for a radical shift in perspective towards the
empiricist principles of Witold Ma\'nczak, a prominent general and historical
linguist. He defines language not as a "system of signs" or a "computational
system of the brain" but as the totality of all that is said and written. Above
all, he identifies frequency of use of particular language elements as
language's primary governing principle. Using his framework, we challenge prior
critiques of LLMs and provide a constructive guide for designing, evaluating,
and interpreting language models.

</details>


### [149] [Dr.LLM: Dynamic Layer Routing in LLMs](https://arxiv.org/abs/2510.12773)
*Ahmed Heakl,Martin Gubri,Salman Khan,Sangdoo Yun,Seong Joon Oh*

Main category: cs.CL

TL;DR: Dr.LLM通过引入轻量级路由器动态调整LLM的计算深度，在不改变基础模型权重的情况下，提高了在ARC和DART数据集上的准确性（最高+3.4%），同时减少了平均5层的计算量。该方法在多种下游任务（MMLU, GSM8k等）上表现出良好的泛化能力，准确率仅下降0.85%，并且优于现有路由方法（最高+7.7%）。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在处理所有查询时都会遍历所有层，导致简单查询浪费计算资源，而复杂查询则因层数不足而难以进行深度推理。自适应深度方法虽然能提高效率，但现有方法要么推理成本高，要么需要修改架构或进行大规模重新训练，并且常常以牺牲准确性为代价。

Method: Dr.LLM是一个可修复的框架，通过在预训练模型中加入轻量级的逐层路由器来实现。这些路由器可以决定跳过、执行或重复某个层块。路由器通过明确的监督进行训练：利用蒙特卡洛树搜索（MCTS）来获得高质量的层配置，在计算预算内保持或提高准确性。该框架还采用了窗口池化以实现稳定的路由，并使用具有类别平衡的焦点损失以及瓶颈MLP路由器来确保在类别不平衡和长序列下的鲁棒性。

Result: 在ARC（逻辑）和DART（数学）数据集上，Dr.LLM将准确性提高了多达+3.4个百分点，同时平均每个样本节省了5层计算。在泛化到其他任务（MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA, AGIEval）时，准确率仅下降0.85%，同时保持了效率优势，并且在性能上优于先前的方法（最高+7.7%）。

Conclusion: Dr.LLM证明了通过明确监督的路由器，可以在不改变基础模型权重的情况下，对冻结的LLM进行修复，以实现满足计算预算且注重准确性的推理。

Abstract: Large Language Models (LLMs) process every token through all layers of a
transformer stack, causing wasted computation on simple queries and
insufficient flexibility for harder ones that need deeper reasoning.
Adaptive-depth methods can improve efficiency, but prior approaches rely on
costly inference-time search, architectural changes, or large-scale retraining,
and in practice often degrade accuracy despite efficiency gains. We introduce
Dr.LLM, Dynamic routing of Layers for LLMs, a retrofittable framework that
equips pretrained models with lightweight per-layer routers deciding to skip,
execute, or repeat a block. Routers are trained with explicit supervision:
using Monte Carlo Tree Search (MCTS), we derive high-quality layer
configurations that preserve or improve accuracy under a compute budget. Our
design, windowed pooling for stable routing, focal loss with class balancing,
and bottleneck MLP routers, ensures robustness under class imbalance and long
sequences. On ARC (logic) and DART (math), Dr.LLM improves accuracy by up to
+3.4%p while saving 5 layers per example on average. Routers generalize to
out-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA,
AGIEval) with only 0.85% accuracy drop while retaining efficiency, and
outperform prior routing methods by up to +7.7%p. Overall, Dr.LLM shows that
explicitly supervised routers retrofit frozen LLMs for budget-aware,
accuracy-driven inference without altering base weights.

</details>


### [150] [Cost Analysis of Human-corrected Transcription for Predominately Oral Languages](https://arxiv.org/abs/2510.12781)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Michael Leventhal*

Main category: cs.CL

TL;DR: 创建低资源语言（特别是低识字率、以口语为主的语言）的语音数据集需要大量的人力劳动。本研究通过对班巴拉语（马里的一种曼丁语）为期一个月的实地研究，分析了人工校对自动语音识别（ASR）转录所需的时间和复杂性。结果表明，在实验室条件下，每小时语音数据需要平均30小时的人工劳动；在实地条件下，则需要36小时。


<details>
  <summary>Details</summary>
Motivation: 创建低资源语言的语音数据集是一项关键但理解不足的挑战，特别是人力成本方面。本研究旨在调查为一部分低资源、低识字率、以口语为主的语言创建高质量标注语音数据所需的时间和复杂性。

Method: 通过为期一个月、涉及十名母语为班巴拉语的转录员的实地研究，分析校对53小时班巴拉语语音数据的自动语音识别（ASR）转录的所需时间和复杂性。

Result: 在实验室条件下，准确转录一小时语音数据平均需要30小时的人工劳动；在实地条件下，平均需要36小时。

Conclusion: 本研究为具有相似特征的语言在创建自然语言处理（NLP）资源方面提供了基线和实践见解。

Abstract: Creating speech datasets for low-resource languages is a critical yet poorly
understood challenge, particularly regarding the actual cost in human labor.
This paper investigates the time and complexity required to produce
high-quality annotated speech data for a subset of low-resource languages, low
literacy Predominately Oral Languages, focusing on Bambara, a Manding language
of Mali. Through a one-month field study involving ten transcribers with native
proficiency, we analyze the correction of ASR-generated transcriptions of 53
hours of Bambara voice data. We report that it takes, on average, 30 hours of
human labor to accurately transcribe one hour of speech data under laboratory
conditions and 36 hours under field conditions. The study provides a baseline
and practical insights for a large class of languages with comparable profiles
undertaking the creation of NLP resources.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [151] [FlexPipe: Adapting Dynamic LLM Serving Through Inflight Pipeline Refactoring in Fragmented Serverless Clusters](https://arxiv.org/abs/2510.11938)
*Yanying Lin,Shijie Peng,Chengzhi Lu,Chengzhong Xu,Kejiang Ye*

Main category: cs.DC

TL;DR: FlexPipe通过动态重构模型管道架构来提高LLM服务效率，解决了服务器集群中资源碎片化和请求模式多变的问题。


<details>
  <summary>Details</summary>
Motivation: 当前服务大型语言模型（LLMs）的系统在应对多变请求模式和服务器集群资源碎片化方面存在挑战，静态的管道配置导致效率低下。

Method: FlexPipe在运行时动态重构管道架构，将模型分解为细粒度阶段，并根据实时请求模式分析智能调整管道粒度。其关键创新包括：保持计算图约束的细粒度模型划分、具有一致缓存转换的飞行中管道重构、以及利用GPU碎片化的拓扑感知资源分配。

Result: 在82-GPU集群上的评估显示，FlexPipe的资源效率比现有系统高出8.5倍，延迟降低38.3%，并将GPU预留要求从峰值容量的75%降至30%。

Conclusion: FlexPipe通过动态调整模型管道和资源分配，显著提高了LLM服务效率，降低了延迟和资源需求。

Abstract: Serving Large Language Models (LLMs) in production faces significant
challenges from highly variable request patterns and severe resource
fragmentation in serverless clusters. Current systems rely on static pipeline
configurations that struggle to adapt to dynamic workload conditions, leading
to substantial inefficiencies. We present FlexPipe, a novel system that
dynamically reconfigures pipeline architectures during runtime to address these
fundamental limitations. FlexPipe decomposes models into fine-grained stages
and intelligently adjusts pipeline granularity based on real-time request
pattern analysis, implementing three key innovations: fine-grained model
partitioning with preserved computational graph constraints, inflight pipeline
refactoring with consistent cache transitions, and topology-aware resource
allocation that navigates GPU fragmentation. Comprehensive evaluation on an
82-GPU cluster demonstrates that FlexPipe achieves up to 8.5x better resource
efficiency while maintaining 38.3% lower latency compared to state-of-the-art
systems, reducing GPU reservation requirements from 75% to 30% of peak
capacity.

</details>


### [152] [Comparing Cross-Platform Performance via Node-to-Node Scaling Studies](https://arxiv.org/abs/2510.12166)
*Kenneth Weiss,Thomas M. Stitt,Daryl Hawkins,Olga Pearce,Stephanie Brink,Robert N. Rieben*

Main category: cs.DC

TL;DR: 代码在不同高性能计算平台间的性能和扩展性比较是重要的，但缺乏相关指导。本文提出以单个计算节点为基础进行节点到节点扩展性研究，并提供设置、运行和分析的指导，以及结果展示模板和案例研究。


<details>
  <summary>Details</summary>
Motivation: 在日益多样化的 Hhpc 架构下，研究人员和实践者越来越有兴趣比较代码在不同平台上的性能和可扩展性，但目前缺乏如何在不同平台之间进行跨平台研究的设置和分析的指导。

Method: 本文提出以单个计算节点作为跨平台研究的基础单位，并提供节点到节点扩展性研究的设置、运行和分析的指导。文中还提供了扩展性结果的展示模板，并通过几个案例研究来强调该方法的好处。

Result: 通过节点到节点扩展性研究，可以为代码在不同 HPC 平台上的性能和扩展性提供比较和分析的指导，并通过案例研究证明了该方法的有效性。

Conclusion: 以单个计算节点为基础进行节点到节点扩展性研究，是评估和比较代码在不同 HPC 平台间性能和扩展性的有效方法，能够为跨平台研究提供实用的指导和分析框架。

Abstract: Due to the increasing diversity of high-performance computing architectures,
researchers and practitioners are increasingly interested in comparing a code's
performance and scalability across different platforms. However, there is a
lack of available guidance on how to actually set up and analyze such
cross-platform studies. In this paper, we contend that the natural base unit of
computing for such studies is a single compute node on each platform and offer
guidance in setting up, running, and analyzing node-to-node scaling studies. We
propose templates for presenting scaling results of these studies and provide
several case studies highlighting the benefits of this approach.

</details>


### [153] [GPU-Accelerated Algorithms for Process Mapping](https://arxiv.org/abs/2510.12196)
*Petr Samoldekin,Christian Schulz,Henning Woydt*

Main category: cs.DC

TL;DR: 提出两种GPU加速算法解决任务图与超级计算机处理单元分配问题，实现负载均衡和通信成本最小化。


<details>
  <summary>Details</summary>
Motivation: GPU图分割的成功启发了作者，旨在解决计算负载均衡和通信成本最小化问题。

Method: 算法一：采用分层多路划分，利用GPU图分割器加速映射过程。算法二：将过程映射集成到多层图分割流水线中，利用GPU并行性加速粗化和细化阶段。

Result: 两种算法均实现超越300倍的加速比。算法一通信成本略高10%，但仍具竞争力；算法二速度更快，几何平均加速比77.6，峰值加速比598，但解决方案质量较低。

Conclusion: 这是首次提出的基于GPU的过程映射算法。

Abstract: Process mapping asks to assign vertices of a task graph to processing
elements of a supercomputer such that the computational workload is balanced
while the communication cost is minimized. Motivated by the recent success of
GPU-based graph partitioners, we propose two GPU-accelerated algorithms for
this optimization problem. The first algorithm employs hierarchical
multisection, which partitions the task graph alongside the hierarchy of the
supercomputer. The method utilizes GPU-based graph partitioners to accelerate
the mapping process. The second algorithm integrates process mapping directly
into the modern multilevel graph partitioning pipeline. Vital phases like
coarsening and refinement are accelerated by exploiting the parallelism of
GPUs. In our experiments, both methods achieve speedups exceeding 300 when
compared to state-of-the-art CPU-based algorithms. The first algorithm has, on
average, about 10 percent greater communication costs and thus remains
competitive to CPU algorithms. The second approach is much faster, with a
geometric mean speedup of 77.6 and peak speedup of 598 at the cost of lower
solution quality. To our knowledge, these are the first GPU-based algorithms
for process mapping.

</details>


### [154] [Metronome: Efficient Scheduling for Periodic Traffic Jobs with Network and Priority Awareness](https://arxiv.org/abs/2510.12274)
*Hao Jiang,Meng Qin,Ruijie Kuai,Dandan Liang*

Main category: cs.DC

TL;DR: Metronome是一个网络感知、优先级感知的云原生网络调度机制，通过时分复用和多目标优化来提高资源利用率和保证服务性能，实验表明其性能优于现有K8s调度机制。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力需求的快速增长，云原生网络成为解决资源协调效率低下，尤其是在应对集群内网络带宽动态波动方面挑战的有希望的解决方案。

Method: Metronome采用时分复用方法，利用作业流量特性构建弹性网络资源分配模型，实现跨多个作业的带宽共享。它还结合了多目标优化策略，联合考虑延迟和作业优先级，以实现全局最优和动态资源分配。Metronome通过监控集群和执行重新配置操作来适应动态环境。

Result: 实验表明，Metronome可以提高集群资源利用率，同时保证服务性能。与现有Kubernetes调度机制相比，Metronome在多种场景下可将作业完成时间缩短高达19.50%，并将平均带宽利用率提高高达23.20%。

Conclusion: Metronome通过其创新的调度机制，有效解决了云原生网络中的资源分配挑战，并在实际应用中取得了显著的性能提升。

Abstract: With the rapid growth in computing power demand, cloud native networks have
emerged as a promising solution to address the challenges of efficient resource
coordination, particularly in coping with the dynamic fluctuations of network
bandwidth in clusters. We propose Metronome, a network-aware and priority-aware
scheduling mechanism for cloud native networks. This mechanism is designed to
support jobs that exhibit periodic traffic patterns and dynamic bandwidth
demands, particularly in the context of distributed training. Specifically,
Metronome employs a time-division multiplexing approach that leverages job
traffic characteristics to construct an elastic network resource allocation
model, enabling efficient bandwidth sharing across multiple jobs. In addition,
it incorporates a multi-objective optimization strategy, jointly considering
latency and job priorities to achieve globally optimal as well as dynamic
resource allocation. Finally, Metronome adapts to the dynamic environment by
monitoring the cluster and performing reconfiguration operations. Extensive
experiments with 13 common machine learning models demonstrate that Metronome
can enhance cluster resource utilization while guaranteeing service
performance. Compared with the existing Kubernetes scheduling mechanisms across
multiple scenarios, Metronome reduces job completion time by up to 19.50% while
improving average bandwidth utilization by up to 23.20%.

</details>


### [155] [A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines](https://arxiv.org/abs/2510.12354)
*Sepideh Masoudi,Mark Edward Michael Daly,Jannis Kiesel,Stefan Tai*

Main category: cs.DC

TL;DR: 该研究提出了一种基于Kubernetes的工具，用于在数据网格环境中动态、非侵入性地应用云设计模式，以提高数据共享管道的可扩展性和能源效率，同时保持其模块化和可重用性。


<details>
  <summary>Details</summary>
Motivation: 在数据网格架构日益普及的背景下，在不影响现有管道的模块化、可重用性和动态性的前提下，将传统云设计模式集成到可组合的数据共享管道中是一个挑战。

Method: 提出了一种基于Kubernetes的工具，该工具支持自动注入设计模式，并收集能源消耗指标，实现对设计模式的延迟和非侵入性应用，无需修改服务源代码。

Result: 该工具能够自动化地注入设计模式，并收集能源消耗数据，使开发人员能够在保持数据共享管道灵活、可组合结构的同时，做出节能决策。

Conclusion: 所提出的基于Kubernetes的工具能够有效解决在数据网格环境中集成云设计模式的挑战，通过实现设计模式的延迟和非侵入性应用，平衡了可扩展性、能源效率和管道的灵活性。

Abstract: As data mesh architectures gain traction in federated environments,
organizations are increasingly building consumer-specific data-sharing
pipelines using modular, cloud-native transformation services. Prior work has
shown that structuring these pipelines with reusable transformation stages
enhances both scalability and energy efficiency. However, integrating
traditional cloud design patterns into such pipelines poses a challenge:
predefining and embedding patterns can compromise modularity, reduce
reusability, and conflict with the pipelines dynamic, consumer-driven nature.
To address this, we introduce a Kubernetes-based tool that enables the deferred
and non-intrusive application of selected cloud design patterns without
requiring changes to service source code. The tool supports automated pattern
injection and collects energy consumption metrics, allowing developers to make
energy-aware decisions while preserving the flexible, composable structure of
reusable data-sharing pipelines.

</details>


### [156] [TALP-Pages: An easy-to-integrate continuous performance monitoring framework](https://arxiv.org/abs/2510.12436)
*Valentin Seitz,Jordy Trilaksono,Marta Garcia-Gasulla*

Main category: cs.DC

TL;DR: TALP-Pages是一个易于集成的框架，用于在开发过程中尽早检测代码性能下降和了解应用程序扩展行为。


<details>
  <summary>Details</summary>
Motivation: 在开发针对HPC机器的代码时，及早检测性能下降和了解应用程序扩展行为至关重要。

Method: TALP-Pages框架使用TALP在运行时收集性能和扩展指标，并生成HTML报告，其中包含性能因素回归的可视化和扩展效率表。

Result: 与基于跟踪的工具相比，TALP-Pages在开销和后处理需求方面具有优势，可以更快地生成扩展效率表，并且资源限制更少。

Conclusion: TALP-Pages易于使用且有效，可以轻松集成到现有CI设置中，以检测和解释性能改进。

Abstract: Ensuring good performance is a key aspect in the development of codes that
target HPC machines. As these codes are under active development, the necessity
to detect performance degradation early in the development process becomes
apparent. In addition, having meaningful insight into application scaling
behavior tightly coupled to the development workflow is helpful. In this paper,
we introduce TALP-Pages, an easy-to-integrate framework that enables developers
to get fast and in-repository feedback about their code performance using
established fundamental performance and scaling factors. The framework relies
on TALP, which enables the on-the-fly collection of these metrics. Based on a
folder structure suited for CI which contains the files generated by TALP,
TALP-Pages generates an HTML report with visualizations of the performance
factor regression as well as scaling-efficiency tables. We compare TALP-Pages
to tracing-based tools in terms of overhead and post-processing requirements
and find that TALP-Pages can produce the scaling-efficiency tables faster and
under tighter resource constraints. To showcase the ease of use and
effectiveness of this approach, we extend the current CI setup of GENE-X with
only minimal changes required and showcase the ability to detect and explain a
performance improvement.

</details>


### [157] [Low Latency, High Bandwidth Streaming of Experimental Data with EJFAT](https://arxiv.org/abs/2510.12597)
*Ilya Baldin,Michael Goodrich,Vardan Gyurjyan,Graham Heyes,Derek Howard,Yatish Kumar,David Lawrence,Brad Sawatzky,Stacey Sheldon,Carl Timmer*

Main category: cs.DC

TL;DR: JLab与ESnet合作开发了EJFAT架构，利用FPGA加速网络数据处理，以实现边缘到计算集群的负载均衡，从而提高数据吞吐量和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 为JLab科学项目和未来数据中心的高吞吐量、低延迟数据采集和工作流需求提供支持。

Method: 通过FPGA硬件加速实现压缩、分片、UDP包目标重定向（NAT）以及解压和重新组装，实现边缘和集群计算的无缝集成，直接处理流式实验数据。

Result: 展示了EJFAT架构，并介绍了其与IRI等DOE活动的协同作用，以及在JLab数据源、ESnet的EJFAT LB和LBNL的计算集群上的近期成果。

Conclusion: EJFAT架构能够有效地解决数据密集型科学研究和未来数据中心面临的高吞吐量和低延迟挑战。

Abstract: Thomas Jefferson National Accelerator Facility (JLab) has partnered with
Energy Sciences Network (ESnet) to define and implement an edge to compute
cluster computational load balancing acceleration architecture. The ESnet-JLab
FPGA Accelerated Transport (EJFAT) architecture focuses on FPGA acceleration to
address compression, fragmentation, UDP packet destination redirection (Network
Address Translation (NAT)) and decompression and reassembly.
  EJFAT seamlessly integrates edge and cluster computing to support direct
processing of streamed experimental data. This will directly benefit the JLab
science program as well as data centers of the future that require high
throughput and low latency for both time-critical data acquisition systems and
data center workflows.
  The EJFAT project will be presented along with how it is synergistic with
other DOE activities such as an Integrated Research Infrastructure (IRI), and
recent results using data sources at JLab, an EJFAT LB at ESnet, and
computational cluster resources at Lawrence Berkeley National Laboratory
(LBNL).

</details>


### [158] [A GPU-resident Memory-Aware Algorithm for Accelerating Bidiagonalization of Banded Matrices](https://arxiv.org/abs/2510.12705)
*Evelyne Ringoot,Rabab Alomairy,Alan Edelman*

Main category: cs.DC

TL;DR: 该研究提出了第一个用于将带状矩阵归约到双对角形式的GPU算法，打破了内存带宽和矩阵带宽的限制，实现了数量级上的加速。


<details>
  <summary>Details</summary>
Motivation: 尽管将带状矩阵归约到双对角形式是SVD的关键步骤且高度并行化，但此前认为其不适合GPU计算，因为该过程受内存带宽限制。然而，GPU硬件的最新进展，如每个流多处理器/计算单元拥有更大的L1内存，改变了这一状况。

Method: 该算法基于先前CPU的、多核并行缓存感知的“凸起追踪”（bulge chasing）算法，并针对GPU吞吐量进行了优化。研究利用Julia语言的数组抽象和KernelAbstractions库，在NVIDIA、AMD、Intel和Apple Metal GPU上为半精度、单精度和双精度实现了单一的、与硬件和数据精度无关的函数。此外，还开发了一个硬件感知的性能模型，识别了内部块宽度和块并发等关键超参数，以优化带宽受限工作负载在GPU上的执行。

Result: GPU算法在矩阵大小为1024x1024时优于多线程CPU高性能库PLASMA（PLASMA）和SLATE（SLATE），在矩阵大小为32k x 32k时更是超越CPU实现100倍以上。算法性能与矩阵带宽大小呈线性关系，使得更快地归约更大带宽的矩阵成为可能。

Conclusion: 该研究成功地将带状矩阵归约到双对角形式的GPU算法，打破了内存带宽和矩阵带宽的瓶颈，为GPU上的此类算法带来了数量级的性能提升。

Abstract: The reduction of a banded matrix to a bidiagonal form is a crucial step in
the Singular Value Decomposition (SVD), a cornerstone of scientific computing
and AI. Despite being a highly parallel algorithm, it was previously believed
to be unsuitable for GPU computation because it is memory bandwidth-bound.
Recent developments in GPU hardware, including larger L1 memory per Streaming
Multiprocessor/Compute Unit, have changed that. We present the first GPU
algorithm for reducing a banded matrix to bidiagonal form as part of the
NextLA.jl open-source software package. Our algorithm is based on previous
CPU-based multicore parallel cache-efficient bulge chasing algorithms and
adapted to optimize for GPU throughput. We leverage Julia Language's Array
abstractions and KernelAbstractions to implement a single hardware- and data
precision-agnostic function on NVIDIA, AMD, Intel, and Apple Metal GPUs for
half, single, and double precision, and examine performance optimization across
hardware architectures and data precision. We also develop a hardware-aware
performance model and identify key hyperparameters, such as inner tilewidth and
block concurrency, that govern optimal GPU execution for bandwidth-bound
workloads. We demonstrate highly parallel bandwidth-bound algorithm on the GPU
can outperform CPU-based implementations: the GPU algorithm outperforms
multithreaded CPU High-Performance libraries PLASMA and SLATE as of matrix size
1024 x 1024 and by a factor over 100 for matrices of 32k x 32k. In addition,
the performance of the algorithm increases linearly with matrix bandwidth size,
making faster reduction of larger matrix bandwidths now also possible. With
this work, we break memory bandwidth barriers, as well as matrix bandwidth
barriers, resulting in orders-of-magnitude faster algorithms for the reduction
of banded matrices to bidiagonal form on the GPU.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [159] [Quantum Deception: Honey-X Deception using Quantum Games](https://arxiv.org/abs/2510.11848)
*Efstratios Reppas,Ali Wadi,Brendan Gould,Kyriakos G. Vamvoudakis*

Main category: eess.SY

TL;DR: 本研究提出了量子博弈中的欺骗框架，将经典零和博弈中的Honey-X范式扩展到量子领域，并将其表述为一种双层优化问题，最终转化为双线性半定规划问题。研究发现，知情的受害者与天真的受害者在均衡策略上表现一致，量子策略空间和非经典支付能够放大欺骗效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将经典博弈中的欺骗概念扩展到量子领域，并提供一个形式化的框架来研究量子博弈中的欺骗行为，特别是探索欺骗对博弈策略的影响。

Method: 本研究提出了一种将欺骗形式化为受限于欺骗预算的支付哈密顿量可控扰动的框架。通过将量子欺骗表述为双层优化问题，并将其转化为双线性半定规划问题来求解。

Result: 研究表明，在受害者知晓可能存在欺骗的情况下，其均衡策略与完全信任欺骗哈密顿量的天真受害者的均衡策略惊人地一致。通过在量子版的“抛硬币”游戏中进行模拟，展示了量子策略空间和非经典支付如何能够相对于经典模型放大欺骗的影响。

Conclusion: 本研究成功地将经典博弈的欺骗概念扩展到了量子领域，并建立了一个可行的框架来分析量子博弈中的欺骗行为。研究结果揭示了在量子博弈中，即使受害者意识到欺骗的存在，其最优策略也与天真受害者相同，并且量子特性可以增强欺骗的效果。

Abstract: In this paper, we develop a framework for deception in quantum games,
extending the Honey-X paradigm from classical zero-sum settings into the
quantum domain. Building on a view of deception in classical games as
manipulation of a player's perception of the payoff matrix, we formalize
quantum deception as controlled perturbations of the payoff Hamiltonian subject
to a deception budget. We show that when victims are aware of possible
deception, their equilibrium strategies surprisingly coincide with those of
naive victims who fully trust the deceptive Hamiltonian. This equivalence
allows us to cast quantum deception as a bilevel optimization problem, which
can be reformulated into a bilinear semidefinite program. To illustrate the
framework, we present simulations on quantum versions of the Penny Flip game,
demonstrating how quantum strategy spaces and non-classical payoffs can amplify
the impact of deception relative to classical formulations.

</details>


### [160] [Sleepy Chauffeur Detection and Alert Techniques for Road Safety](https://arxiv.org/abs/2510.12205)
*Himel Ghosh,Sayak Chatterjee,Antik Ganguly,Shreetama Karmakar,Koushik Sarkar*

Main category: eess.SY

TL;DR: 该研究提出了一种使用传感器和Arduino的廉价系统，用于检测驾驶员的困倦并发出警报，以防止车祸。


<details>
  <summary>Details</summary>
Motivation: 为了防止因驾驶员打瞌睡而造成车祸、生命损失和严重伤害，开发了一种检测和警报系统。

Method: 该研究回顾了现有的基于图像处理、人工智能和机器学习的系统，并提出了一种使用传感器和Arduino的简单、廉价的系统。

Result: 所提出的系统能够检测驾驶员的困倦，并能激活警报器并发送警报信息。

Conclusion: 该研究强调了检测驾驶员困倦的重要性，并提出了一种经济高效的解决方案，以提高道路安全。

Abstract: The most startling of the contemporary problems is the sleepiness of
chauffeur which causes lots of car accidents. Prevention of those impending
accidents by detecting and alerting the sleepy chauffeur is vital, otherwise
that would lead to loss of lives and various traumas along with severe
injuries. The slumber or sleep may be caused by huge stress, pressure,
relentless work load or alcoholism, for which sleep deprivation occurs and the
chauffeur while driving gets drowsy. So far, considerable amount of systems has
been developed to detect drowsiness of drivers, most of which mainly depend on
image processing algorithms using cameras. Some of them also incorporate
artificial intelligence and machine learning based algorithms. This paper
presents a review of the existing systems and also proposes an easy and cheap
system using sensors and Arduino, capable of detecting sleepiness and generates
siren alarm and send alert message to take precautionary measures.

</details>


### [161] [Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints](https://arxiv.org/abs/2510.12318)
*Pål Forr Austnes,Matthieu Jacobs,Lu Wang,Mario Paolone*

Main category: eess.SY

TL;DR: 该论文提出了一个基于概率定位边际定价的本地电力市场框架，以解决当前中央电力市场在整合可再生能源方面存在的不足，该框架能够有效处理生产、消费和电网变量中的不确定性，并通过案例研究证明了其激励终端用户参与市场和保障电网稳定运行的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前中央电力市场在整合可再生能源方面存在不足，未能直接纳入不确定性因素和考虑配电网的物理限制，而终端用户/小型市场参与者的灵活性被认为是实现大规模可再生能源整合的关键。

Method: 提出一个基于概率定位边际定价的本地电力市场框架，使用 lindistflow 方程表示电网，并利用通用多项式混沌 (gPC) 处理不确定性。构建了一个两阶段凸模型：日前阶段计算每个时间步的价格概率分布，实时阶段在不确定性实现后进行计算。

Result: 通过四个案例研究，证明了该方法能够有效激励终端用户参与市场，并确保其行为不会对电网运行产生负面影响。

Conclusion: 提出的本地电力市场框架通过概率定位边际定价，能够有效处理不确定性，激励终端用户参与，并保障电网运行。

Abstract: Since the 1990s, widespread introduction of central (wholesale) electricity
markets has been seen across multiple continents, driven by the search for
efficient operation of the power grid through competition. The increase of
renewables has made significant impacts both on central electricity markets and
distribution-level grids as renewable power generation is often connected to
the latter. These stochastic renewable technologies have both advantages and
disadvantages. On one hand they offer very low marginal cost and carbon
emissions, while on the other hand, their output is uncertain, requiring
flexible backup power with high marginal cost. Flexibility from end-prosumers
or smaller market participants is therefore seen as a key enabler of
large-scale integration of renewables. However, current central electricity
markets do not directly include uncertainty into the market clearing and do not
account for physical constraints of distribution grids. In this paper we
propose a local electricity market framework based on probabilistic locational
marginal pricing, effectively accounting for uncertainties in production,
consumption and grid variables. The model includes a representation of the grid
using the lindistflow equations and accounts for the propagation of uncertainty
using general Polynomial Chaos (gPC). A two-stage convex model is proposed; in
the day-ahead stage, probability distributions of prices are calculated for
every timestep, where the expected values represent the day-ahead (spot)
prices. In the real-time stage, uncertainties are realized (measured) and a
trivial calculation reveals the real-time price. Through four instructive
case-studies we highlight the effectiveness of the method to incentivize
end-prosumers' participation in the market, while ensuring that their behavior
does not have an adverse impact on the operation of the grid.

</details>


### [162] [Physics-Informed Reinforcement Learning for Large-Scale EV Smart Charging Considering Distribution Network Voltage Constraints](https://arxiv.org/abs/2510.12335)
*Stavros Orfanoudakis,Frans Oliehoek,Peter Palesnky,Pedro P. Vergara*

Main category: eess.SY

TL;DR: 该研究提出了一种名为PI-TD3的物理信息强化学习算法，用于解决大规模电动汽车充电可能引起的电网电压不稳定问题。该算法结合了可微分潮流模型和基于电压的奖励设计，使电动汽车在满足用户需求的同时，能够提供实时的电压支持。实验结果表明，PI-TD3在IEEE 34和123节点网络上的表现优于传统的强化学习和优化方法，能够有效管理电网约束、提高用户满意度并改善经济效益，且在面对大量电动汽车时仍能保持良好的可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大规模、无序的电动汽车充电可能威胁配电网的电压稳定性，而现有的智能充电方法在处理物理电网约束和大规模任务方面存在局限性。

Method: 提出了一种物理信息（PI）强化学习算法，将可微分潮流模型和基于电压的奖励设计集成到Twin Delayed Deep Deterministic Policy Gradient (TD3)算法中。

Result: 所提出的PI-TD3算法收敛速度更快，样本效率更高，并且在不确定和过载条件下能够可靠地调节电压。在IEEE 34节点和123节点网络上的基准测试表明，PI-TD3在电网约束管理、用户满意度和经济指标方面优于无模型强化学习和基于优化的基线方法。

Conclusion: 该研究提出的PI-TD3算法能够实现稳健、可扩展且实用的电动汽车充电策略，从而增强电网弹性并支持配电网的运行。

Abstract: Electric Vehicles (EVs) offer substantial flexibility for grid services, yet
large-scale, uncoordinated charging can threaten voltage stability in
distribution networks. Existing Reinforcement Learning (RL) approaches for
smart charging often disregard physical grid constraints or have limited
performance for complex large-scale tasks, limiting their scalability and
real-world applicability. This paper introduces a physics-informed (PI) RL
algorithm that integrates a differentiable power flow model and voltage-based
reward design into the Twin Delayed Deep Deterministic Policy Gradient (TD3)
algorithm, enabling EVs to deliver real-time voltage support while meeting user
demands. The resulting PI-TD3 algorithm achieves faster convergence, improved
sample efficiency, and reliable voltage magnitude regulation under uncertain
and overloaded conditions. Benchmarks on the IEEE 34-bus and 123-bus networks
show that the proposed PI-TD3 outperforms both model-free RL and
optimization-based baselines in grid constraint management, user satisfaction,
and economic metrics, even as the system scales to hundreds of EVs. These
advances enable robust, scalable, and practical EV charging strategies that
enhance grid resilience and support distribution networks operation.

</details>


### [163] [Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems](https://arxiv.org/abs/2510.12338)
*Mohamed Abdalmoaty,Verena Häberle,Xiuqiang He,Florian Dörfler*

Main category: eess.SY

TL;DR: 本研究提出了一种新的非参数频域方法，利用并网变换器识别宽频带范围内的dq异步电网阻抗，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有电网阻抗识别方法在精度、频率范围和测量要求方面存在显著的权衡。被动方法仅限于几个频率点，而许多主动方法需要长时间测量和专门设备。现有的时域主动方法虽然缩短了测量时间，但需要简化假设或复杂的模型阶数调整。

Method: 提出了一种非参数频域方法，利用并网变换器识别小信号dq异步电网阻抗。

Result: 该方法无需专门的激励信号或硬件，即可在极短时间内（<1秒）完成识别，显著减少了测量时间。由于是非参数方法，因此不对电网结构做出任何假设。通过详细的电磁瞬态仿真验证了该方法的有效性，并证明其优于现有方法。

Conclusion: 所提出的非参数频域方法能够快速、准确地识别电网阻抗，且无需对电网结构做假设，为电网阻抗的在线监测和分析提供了新的解决方案。

Abstract: We propose a non-parametric frequency-domain method to identify small-signal
$dq$-asymmetric grid impedances, over a wide frequency band, using
grid-connected converters. Existing identification methods are faced with
significant trade-offs: e.g., passive approaches rely on ambient harmonics and
rare grid events and thus can only provide estimates at a few frequencies,
while many active approaches that intentionally perturb grid operation require
long time series measurement and specialized equipment. Although active
time-domain methods reduce the measurement time, they either make crude
simplifying assumptions or require laborious model order tuning. Our approach
effectively addresses these challenges: it does not require specialized
excitation signals or hardware and achieves ultrafast ($<1$ s) identification,
drastically reducing measurement time. Being non-parametric, our approach also
makes no assumptions on the grid structure. A detailed electromagnetic
transient simulation is used to validate the method and demonstrate its clear
superiority over existing alternatives.

</details>


### [164] [High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization](https://arxiv.org/abs/2510.12407)
*Fabrizio Orlando,Deborah Volpe,Giacomo Orlandi,Mariagrazia Graziano,Fabrizio Riente,Marco Vacca*

Main category: eess.SY

TL;DR: aSB是一种量子启发算法，用于解决组合优化问题，可以通过更新多个变量来提高效率。本文分析了dSB、bSB和HbSB算法，并提出了一种基于FPGA的dSB硬件架构，该架构已在低端FPGA上成功实现，并解决了256变量问题。


<details>
  <summary>Details</summary>
Motivation: 由于组合优化问题具有指数级复杂性，难以解决，因此需要开发新的算法和硬件实现方法。

Method: 本文分析了dSB、bSB和HbSB算法，并提出了一种基于FPGA的dSB硬件架构。该架构使用固定点表示，并允许用户调整算法并行度。最后，在AMD Kria KV260 SoM上实现了该架构，并使用max-cut和knapsack问题进行了验证。

Result: 在低端FPGA上成功实现了一个dSB算法的开源硬件架构，可以解决256变量问题。该实现能够调整算法并行度，并在max-cut和knapsack问题上得到验证。

Conclusion: 本文提出的基于FPGA的dSB硬件架构是一种可行的方法，可以为组合优化问题提供高效的硬件解决方案。

Abstract: Combinatorial Optimization (CO) problems exhibit exponential complexity,
making their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a
quantum-inspired algorithm to obtain approximate solutions to largescale CO
problems written in the Ising form. It explores the solution space by emulating
the adiabatic evolution of a network of Kerr-nonlinear parametric oscillators
(KPOs), where each oscillator represents a variable in the problem. The optimal
solution corresponds to the ground state of this system. A key advantage of
this approach is the possibility of updating multiple variables simultaneously,
making it particularly suited for hardware implementation. To enhance solution
quality and convergence speed, variations of the algorithm have been proposed
in the literature, including ballistic (bSB), discrete (dSB), and thermal
(HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and
HbSB using dedicated software models, evaluating the feasibility of using a
fixed-point representation for hardware implementation. We then present an
opensource hardware architecture implementing the dSB algorithm for
Field-Programmable Gate Arrays (FPGAs). The design allows users to adjust the
degree of algorithmic parallelization based on their specific requirements. A
proof-of-concept implementation that solves 256-variable problems was achieved
on an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut
and knapsack problems.

</details>


### [165] [A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control](https://arxiv.org/abs/2510.12360)
*Weijie Ren,Haowen Liu,Guang-Ren Duan*

Main category: eess.SY

TL;DR: 该论文提出了一种单向连接完全驱动系统（UC-FAS）方法，用于 6-DOF 四旋翼飞行器的子稳定和跟踪控制，在一定程度上克服了状态空间和 FAS 框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有状态空间和完全驱动系统（FAS）框架在四旋翼飞行器控制中的局限性，并统一现有的 FAS 转换方法。

Method: 将欠驱动四旋翼动力学系统转换为 UC-FAS 模型，并采用直接本征结构分配来实现闭环动力学控制，无需估计高阶控制输入导数。

Result: 仿真结果表明，UC-FAS 模型能够实现精确的 6-DOF 跟踪性能。

Conclusion: UC-FAS 方法为非线性四旋翼控制提供了一个标准化的范例，弥合了理论 FAS 方法的进展与实际应用需求之间的差距。

Abstract: This paper proposes a unidirectionally connected fully actuated system
(UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF
quadrotors, tackling limitations both in state-space and FAS framework to some
extent. The framework systematically converts underactuated quadrotor dynamics
into a UC-FAS model, unifying the existing different FAS transformation ways.
By eliminating estimation of the high-order derivatives of control inputs, a
drawback of current methods, the UC-FAS model simplifies controller design and
enables direct eigenstructure assignment for closed-loop dynamics. Simulations
demonstrate precise 6-DOF tracking performance. This work bridges theoretical
FAS approach advancements with practical implementation needs, offering a
standardized paradigm for nonlinear quadrotor control.

</details>


### [166] [Pooling Probabilistic Forecasts for Cooperative Wind Power Offering](https://arxiv.org/abs/2510.12382)
*Honglin Wen,Pierre Pinson*

Main category: eess.SY

TL;DR: 风电场可以通过组建联盟在电力市场中合作获利。现有方法在预测信息一致性方面存在不足，可能导致报价和收益分配的模糊性。本文提出了一种“协调后优化”框架，首先整合个体预测形成联合预测，然后确定市场报价。该框架通过两阶段随机规划确定总报价和基于场景的对偶值，并基于此构建了一个具有预算平衡和稳定性的收益分配规则。经验案例研究验证了该方法的有效性和理论合理性。


<details>
  <summary>Details</summary>
Motivation: 现有关于风电场合作参与电力市场的收益分配方法忽略了生产者之间在预测信息方面缺乏一致性，这可能导致报价和收益分配的不确定性。因此，需要一种新的框架来解决这一问题。

Method: 提出一个“协调后优化”框架，首先将个体预测整合成一致的联合预测，然后在此基础上制定市场报价。通过解决一个两阶段随机规划问题来获得每个交易小时的总报价以及基于场景的对偶值。最后，基于这些对偶值构建一个预算平衡且稳定的收益分配规则。

Result: 经验案例研究表明，所提出的方法在实际应用中是有效的，并且具有理论上的合理性。

Conclusion: 所提出的“协调后优化”框架能够通过整合个体预测来解决风电场合作市场报价中的不确定性问题，并提供一个公平且稳定的收益分配机制。

Abstract: Wind power producers can benefit from forming coalitions to participate
cooperatively in electricity markets. To support such collaboration, various
profit allocation rules rooted in cooperative game theory have been proposed.
However, existing approaches overlook the lack of coherence among producers
regarding forecast information, which may lead to ambiguity in offering and
allocations. In this paper, we introduce a ``reconcile-then-optimize''
framework for cooperative market offerings. This framework first aligns the
individual forecasts into a coherent joint forecast before determining market
offers. With such forecasts, we formulate and solve a two-stage stochastic
programming problem to derive both the aggregate offer and the corresponding
scenario-based dual values for each trading hour. Based on these dual values,
we construct a profit allocation rule that is budget-balanced and stable.
Finally, we validate the proposed method through empirical case studies,
demonstrating its practical effectiveness and theoretical soundness.

</details>


### [167] [Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X](https://arxiv.org/abs/2510.12539)
*Zhanle Zhao,Son Dinh-Van,Yuen Kwan Mo,Siddartha Khastgir,Matthew D. Higgins*

Main category: eess.SY

TL;DR: 本论文研究了在农村环境下的车联网（CAVs）安全与能耗之间的平衡，重点关注了5G NR Sidelink V2X通信。


<details>
  <summary>Details</summary>
Motivation: 在农村地区，由于路边单元稀疏且受电力限制，因此在提高CAVs安全性（减少致命碰撞）的同时，必须考虑能源效率。

Method: 研究了子载波间隔（SCS）、调制编码方案（MCS）和传输功率（Pt）这三个通信控制因素如何影响安全（由数据包接收率（PRR）衡量）与能耗的权衡，特别是在农村视线（LOS）和不同交通密度（光线和重载）场景下。

Result: 研究结果表明：在重载交通情况下，增加传输功率（Pt）并选择低速率的MCS以及30 kHz的SCS，可以在Dcomm（安全消息传输期间车辆行驶的距离）下维持高PRR，但能耗也会增加。在光线交通情况下，较低的Pt和低MCS水平可以在保证可接受的PRR的同时，实现良好的可靠性-能耗权衡。

Conclusion: 研究结果强调了采用自适应、考虑能耗的策略对于保证农村V2X系统中安全性和能源效率的必要性。

Abstract: Connected braking can reduce fatal collisions in connected and autonomous
vehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links,
especially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side
units are sparse and power-constrained or off-grid, so energy efficiency must
be considered alongside safety. This paper studies how three communication
control factors including subcarrier spacing ($\mathrm{SCS}$), modulation and
coding scheme ($\mathrm{MCS}$), and transmit power ($P_{\mathrm{t}}$) should be
configured to balance safety and energy consumption in rural line-of-sight
(LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by
the packet receive ratio ($\mathrm{PRR}$) against the minimum communication
distance $D_{\mathrm{comm}}$, defined as the distance that the vehicle travels
during the transmission of the safety message. Results show that, under heavy
traffic, increasing $P_{\mathrm{t}}$ and selecting a low-rate $\mathrm{MCS}$ at
$\mathrm{SCS} = 30$ kHz sustains high $\mathrm{PRR}$ at $D_{\mathrm{comm}}$,
albeit with higher energy cost. In light traffic, maintaining lower
$P_\mathrm{t}$ with low $\mathrm{MCS}$ levels achieves a favorable
reliability-energy trade-off while preserving acceptable $\mathrm{PRR}$ at
$D_{\mathrm{comm}}$. These findings demonstrate the necessity of adaptive,
energy-aware strategy to guarantee both safety and energy efficiency in rural
V2X systems.

</details>


### [168] [Privacy-Preserving Distributed Estimation with Limited Data Rate](https://arxiv.org/abs/2510.12549)
*Jieming Ke,Jimin Wang,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种基于二值量化器的隐私保护分布式估计算法，在保证隐私性的同时降低了通信成本，并实现了估计量的几乎必然收敛。


<details>
  <summary>Details</summary>
Motivation: 为了解决有限数据速率下的隐私保护分布式估计算问题，其中观测值是敏感信息。

Method: 开发了一种基于二值量化器的隐私保护分布式估计算法，该算法动态地提高了隐私保护能力，并量化了量化器带来的隐私改进效果。该算法还通过共同设计时变隐私噪声和步长，确保估计量几乎必然收敛到真实值。

Result: 量化器的隐私保护能力随时间增强，输出信号相对于敏感信息的费舍尔信息矩阵以多项式速率收敛到零。每个传感器每个时间步仅传输1比特信息，并且不需要对实值消息的量化误差可忽略的假设。实现了多项式几乎必然收敛速率，并建立了隐私与收敛速率之间的权衡。

Conclusion: 该算法在满足隐私保护和降低通信成本要求的同时，实现了估计量的几乎必然收敛，并通过数值示例验证了主要结果。

Abstract: This paper focuses on the privacy-preserving distributed estimation problem
with a limited data rate, where the observations are the sensitive information.
Specifically, a binary-valued quantizer-based privacy-preserving distributed
estimation algorithm is developed, which improves the algorithm's
privacy-preserving capability and simultaneously reduces the communication
costs. The algorithm's privacy-preserving capability, measured by the Fisher
information matrix, is dynamically enhanced over time. Notably, the Fisher
information matrix of the output signals with respect to the sensitive
information converges to zero at a polynomial rate, and the improvement in
privacy brought by the quantizers is quantitatively characterized as a
multiplicative effect. Regarding the communication costs, each sensor transmits
only 1 bit of information to its neighbours at each time step. Additionally,
the assumption on the negligible quantization error for real-valued messages is
not required. While achieving the requirements of privacy preservation and
reducing communication costs, the algorithm ensures that its estimates converge
almost surely to the true value of the unknown parameter by establishing a
co-design guideline for the time-varying privacy noises and step-sizes. A
polynomial almost sure convergence rate is obtained, and then the trade-off
between privacy and convergence rate is established. Numerical examples
demonstrate the main results.

</details>


### [169] [Enhancing Robust Multi-Market Participation of Renewable-Based VPPs through Flexible Resources](https://arxiv.org/abs/2510.12589)
*Hadi Nemati,Álvaro Ortega,Pedro Sánchez-Martín,Lukas Sigrist,Luis Rouco,Ignacio Egido*

Main category: eess.SY

TL;DR: 可再生能源虚拟电厂（RVPP）通过整合柔性资源和鲁棒优化策略来应对不确定性，从而提高在能源和备用市场中的盈利能力。


<details>
  <summary>Details</summary>
Motivation: 分析了不同柔性资源（如光热发电、水电、生物质发电和柔性负荷）对RVPP参与能源和备用市场的影响，并解决了发电、消费和电价中的不确定性问题。

Method: 采用两阶段鲁棒优化方法处理不确定性，并使用边际贡献法评估不同技术对RVPP盈利能力的贡献。

Result: 通过对西班牙南部RVPP进行模拟，展示了战略决策和柔性资源的可获得性如何影响RVPP的可行性、市场参与度和机组调度。

Conclusion: RVPP的可行性取决于有效的市场参与策略以及管理不确定性和利用柔性资源的能力。

Abstract: In the transition toward a sustainable power system, renewable-based Virtual
Power Plants (RVPPs) have emerged as a promising solution to the challenges of
integrating renewable energy sources into electricity markets. Their viability,
however, depends on effective market participation strategies and the ability
to manage uncertainties while leveraging flexible resources. This paper
analyzes the impact of different flexible resources - such as concentrated
solar power plants, hydro plants, biomass plants, and flexible demand - on the
participation of RVPPs in energy and reserve markets. Multiple sources of
uncertainty in generation, consumption, and electricity prices are addressed
using a two-stage robust optimization approach. The contribution of different
technologies to RVPP profitability is evaluated through a marginal contribution
method, ensuring fair allocation of profits among them according to their
actual role in energy and reserve provision across markets. Simulations for an
RVPP in southern Spain demonstrate how strategic decisions and the availability
of flexible resources influence viability, market participation, and unit
scheduling.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [170] [Translating Milli/Microrobots with A Value-Centered Readiness Framework](https://arxiv.org/abs/2510.12090)
*Hakan Ceylan,Edoardo Sinibaldi,Sanjay Misra,Pankaj J. Pasricha,Dietmar W. Hutmacher*

Main category: cs.RO

TL;DR: 移动医疗机器人研究进展缓慢，需要将技术创新与实际医疗需求相结合，并引入mTRL框架以加速其临床应用。


<details>
  <summary>Details</summary>
Motivation: 为了实现医疗机器人更精确、无创的诊断和治疗潜力，需要解决从实验室到临床应用的差距，并克服当前技术进展缓慢的问题。

Method: 通过分析技术创新与实际应用脱节的关键因素，提出将发展与未满足的医疗需求相结合，确保应用可行性，并融入现有临床工作流程。引入毫/微米机器人技术准备度水平（mTRL）框架，将系统开发划分为明确的里程碑和活动，以指导发展。

Result: mTRL框架为评估技术成熟度、促进跨学科合作和加速转化研究提供了结构化工具，旨在实现更安全、更有效的医疗干预。

Conclusion: 通过将技术发展与医疗需求、应用可行性和临床工作流程相结合，并利用mTRL框架，可以加速移动医疗机器人的临床转化，最终改善患者的治疗效果。

Abstract: Untethered mobile milli/microrobots hold transformative potential for
interventional medicine by enabling more precise and entirely non-invasive
diagnosis and therapy. Realizing this promise requires bridging the gap between
groundbreaking laboratory demonstrations and successful clinical integration.
Despite remarkable technical progress over the past two decades, most
millirobots and microrobots remain confined to laboratory proof-of-concept
demonstrations, with limited real-world feasibility. In this Review, we
identify key factors that slow translation from bench to bedside, focusing on
the disconnect between technical innovation and real-world application. We
argue that the long-term impact and sustainability of the field depend on
aligning development with unmet medical needs, ensuring applied feasibility,
and integrating seamlessly into existing clinical workflows, which are
essential pillars for delivering meaningful patient outcomes. To support this
shift, we introduce a strategic milli/microrobot Technology Readiness Level
framework (mTRL), which maps system development from initial conceptualization
to clinical adoption through clearly defined milestones and their associated
stepwise activities. The mTRL model provides a structured gauge of
technological maturity, a common language for cross-disciplinary collaboration
and actionable guidance to accelerate translational development toward new,
safer and more efficient interventions.

</details>


### [171] [Gaussian Semantic Field for One-shot LiDAR Global Localization](https://arxiv.org/abs/2510.12101)
*Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种基于轻量级三层场景图的单次激光雷达全局定位算法，该算法具有语义消除歧义能力。


<details>
  <summary>Details</summary>
Motivation: 基于地标语义配准的方法在全局定位方面取得了显著的性能提升，但地标可能重复且具有误导性。通过使用高斯过程学习的连续函数对语义分布进行建模，可以捕捉更细粒度的地理语义信息，并为对应关系的建立提供更详细的度量信息。

Method: 提出了一种包含对象层、连续函数层和度量语义层的三层3D场景图，用于单次定位。该方法被称为Outram-GSF（高斯语义场）。

Result: 在公开数据集上进行了广泛的实验，验证了Outram-GSF相比现有最先进方法的优越性能。

Conclusion: Outram-GSF通过引入连续语义场（高斯语义场）有效解决了传统基于地标的全局定位方法的局限性，在公开数据集上取得了优于现有方法的性能。

Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic
disambiguation ability based on a lightweight tri-layered scene graph. While
landmark semantic registration-based methods have shown promising performance
improvements in global localization compared with geometric-only methods,
landmarks can be repetitive and misleading for correspondence establishment. We
propose to mitigate this problem by modeling semantic distributions with
continuous functions learned from a population of Gaussian processes. Compared
with discrete semantic labels, the continuous functions capture finer-grained
geo-semantic information and also provide more detailed metric information for
correspondence establishment. We insert this continuous function as the middle
layer between the object layer and the metric-semantic layer, forming a
tri-layered 3D scene graph, serving as a light-weight yet performant backend
for one-shot localization. We term our global localization pipeline Outram-GSF
(Gaussian semantic field) and conduct a wide range of experiments on publicly
available data sets, validating the superior performance against the current
state-of-the-art.

</details>


### [172] [Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair](https://arxiv.org/abs/2510.12169)
*Akshay Naik,William R. Norris,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.RO

TL;DR: 自主地面车辆在越野环境中需要实时规划曲率可行的路径，同时考虑空间变化的土壤强度和坡度危险。本文提出了一种连续状态-成本度量，结合了Bekker压力-下沉模型以及基于高程的坡度和姿态惩罚。该度量产生的地形成本场是解析的、有界的，并且在土壤模量和坡度上是单调的，确保了离散化良好且在传感器噪声下更新稳定。该度量在具有精确转向原语（用于差速驱动的Dubins和Reeds-Shepp运动，以及用于Ackermann转向的时间参数化自行车弧）的格点上进行评估。通过Vehicle-Dynamics RRT*进行全局探索，通过Vehicle-Dynamics D* Lite进行局部修复，能够在毫秒级内进行重新规划，无需启发式平滑。通过将地形-车辆模型与规划器分离，该框架为在可变形地形中进行确定性、采样或学习驱动的规划提供了可重用的基础。越野平台上的硬件试验表明，该系统能够成功地在软土和坡度变化的地形中进行实时导航，支持在非结构化环境中可靠的自主性。


<details>
  <summary>Details</summary>
Motivation: 自主地面车辆在越野环境中需要实时规划曲率可行的路径，同时考虑空间变化的土壤强度和坡度危险。

Method: 提出了一种连续状态-成本度量，结合了Bekker压力-下沉模型以及基于高程的坡度和姿态惩罚。该度量在具有精确转向原语（用于差速驱动的Dubins和Reeds-Shepp运动，以及用于Ackermann转向的时间参数化自行车弧）的格点上进行评估。通过Vehicle-Dynamics RRT*进行全局探索，通过Vehicle-Dynamics D* Lite进行局部修复。

Result: 该度量产生的地形成本场是解析的、有界的，并且在土壤模量和坡度上是单调的，确保了离散化良好且在传感器噪声下更新稳定。通过将地形-车辆模型与规划器分离，该框架为在可变形地形中进行确定性、采样或学习驱动的规划提供了可重用的基础。越野平台上的硬件试验表明，该系统能够成功地在软土和坡度变化的地形中进行实时导航，支持在非结构化环境中可靠的自主性。

Conclusion: 该框架通过将地形-车辆模型与规划器分离，为在可变形地形中进行确定性、采样或学习驱动的规划提供了可重用的基础。越野平台上的硬件试验表明，该系统能够成功地在软土和坡度变化的地形中进行实时导航，支持在非结构化环境中可靠的自主性。

Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.

</details>


### [173] [Controllable Collision Scenario Generation via Collision Pattern Prediction](https://arxiv.org/abs/2510.12206)
*Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种可控的碰撞场景生成任务和数据集(COLLIDE)，以解决自动驾驶汽车(AV)安全评估中关键碰撞场景稀缺且难以生成的问题。研究框架通过预测碰撞模式来生成具有特定碰撞类型和碰撞前时间(TTA)的轨迹，并通过实验证明了其在提高碰撞率和可控性方面的优越性，同时生成的场景能有效暴露现有规划器的局限性，并通过微调提升其鲁棒性，最终促进AV的安全部署。


<details>
  <summary>Details</summary>
Motivation: 评估自动驾驶汽车(AV)的安全需要多样化的、安全关键的场景，其中碰撞尤为重要但罕见且在现实世界中收集不安全。因此，社区一直专注于在模拟中生成安全关键场景。然而，控制碰撞类型和碰撞前时间(TTA)等属性仍然具有挑战性。

Method: 提出了一种名为可控碰撞场景生成的新任务，旨在生成能够实现用户指定碰撞类型和TTA的轨迹。为了支持该任务，提出了COLLIDE数据集，并通过预测碰撞模式（一种捕捉碰撞时自我车辆和对手车辆空间配置的紧凑且可解释的表示）来生成轨迹。最后，将生成的场景用于微调规划器以提高鲁棒性。

Result: 所提出的方法在碰撞率和可控性方面均优于强基线。此外，生成的场景一致地导致更高的规划器失败率，揭示了现有规划器的局限性。研究表明，这些场景可以通过微调来提高规划器的鲁棒性，从而为AV在不同碰撞场景中的安全部署做出贡献。

Conclusion: 本研究提出的可控碰撞场景生成方法和COLLIDE数据集为自动驾驶汽车的安全评估提供了新的解决方案。该方法不仅能够生成具有特定碰撞类型和TTA的场景，还能有效暴露和改进现有规划器的性能，从而为实现更安全的自动驾驶提供支持。

Abstract: Evaluating the safety of autonomous vehicles (AVs) requires diverse,
safety-critical scenarios, with collisions being especially important yet rare
and unsafe to collect in the real world. Therefore, the community has been
focusing on generating safety-critical scenarios in simulation. However,
controlling attributes such as collision type and time-to-accident (TTA)
remains challenging. We introduce a new task called controllable collision
scenario generation, where the goal is to produce trajectories that realize a
user-specified collision type and TTA, to investigate the feasibility of
automatically generating desired collision scenarios. To support this task, we
present COLLIDE, a large-scale collision scenario dataset constructed by
transforming real-world driving logs into diverse collisions, balanced across
five representative collision types and different TTA intervals. We propose a
framework that predicts Collision Pattern, a compact and interpretable
representation that captures the spatial configuration of the ego and the
adversarial vehicles at impact, before rolling out full adversarial
trajectories. Experiments show that our approach outperforms strong baselines
in both collision rate and controllability. Furthermore, generated scenarios
consistently induce higher planner failure rates, revealing limitations of
existing planners. We demonstrate that these scenarios fine-tune planners for
robustness improvements, contributing to safer AV deployment in different
collision scenarios.

</details>


### [174] [Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications](https://arxiv.org/abs/2510.12215)
*Chanwoo Kim,Jihwan Yoon,Hyeonseong Kim,Taemoon Jeong,Changwoo Yoo,Seungbeen Lee,Soohwan Byeon,Hoon Chung,Matthew Pan,Jean Oh,Kyungjae Lee,Sungjoon Choi*

Main category: cs.RO

TL;DR: 通过结合数据驱动的奖励和基于规则的奖励，为移动机器人导航开发了一个框架，以提高在动态人类环境中的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在动态人类环境中导航需要能够适应各种行为并遵守安全限制的策略。本研究的目的是找到一种更有效的方法来平衡适应性和安全性。

Method: 开发了一个框架，该框架从正面和负面演示中学习基于密度的奖励，并添加了基于规则的避障和到达目标的奖励。一个基于采样的前瞻控制器生成安全且自适应的监督动作，然后将其提炼成适合实时操作并包含不确定性估计的紧凑的学生策略。

Result: 在合成和电梯共乘模拟中进行的实验表明，与基线方法相比，该方法在成功率和时间效率方面持续提高。在与真人进行的实际演示中，也证实了该方法的实用性。

Conclusion: 本研究提出的框架通过结合数据驱动的奖励和基于规则的奖励，能够有效地平衡移动机器人在动态人类环境中的导航适应性和安全性，并在模拟和真实世界中都取得了良好的效果。

Abstract: Mobile robot navigation in dynamic human environments requires policies that
balance adaptability to diverse behaviors with compliance to safety
constraints. We hypothesize that integrating data-driven rewards with
rule-based objectives enables navigation policies to achieve a more effective
balance of adaptability and safety. To this end, we develop a framework that
learns a density-based reward from positive and negative demonstrations and
augments it with rule-based objectives for obstacle avoidance and goal
reaching. A sampling-based lookahead controller produces supervisory actions
that are both safe and adaptive, which are subsequently distilled into a
compact student policy suitable for real-time operation with uncertainty
estimates. Experiments in synthetic and elevator co-boarding simulations show
consistent gains in success rate and time efficiency over baselines, and
real-world demonstrations with human participants confirm the practicality of
deployment. A video illustrating this work can be found on our project page
https://chanwookim971024.github.io/PioneeR/.

</details>


### [175] [Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception](https://arxiv.org/abs/2510.12528)
*Muxing Huang,Zibin Chen,Weiliang Xu,Zilan Li,Yuanzhi Zhou,Guoyuan Zhou,Wenjing Chen,Xinming Li*

Main category: cs.RO

TL;DR: 该研究提出了一种用于视觉触觉系统的双流网络特征提取和融合感知策略，通过融合深度图和接触力数据来提取物体内外特征，从而提高物体识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的触觉传感器虽然能多维度提取物体属性，但会产生冗余信息，且单一维度的信息提取缺乏有效融合，无法充分表征物体属性，这阻碍了识别精度的提升。

Method: 提出一种双流网络特征提取和融合感知策略，通过分布式方法提取物体的内外特征。首先，通过三维重建获取深度图信息，同时通过测量接触力数据获取硬度信息。然后，利用卷积神经网络（CNN）提取特征，并进行加权融合，形成更具信息量和有效性的特征表示。

Result: 在标准测试中，对不同形状和硬度的物体，力预测误差为0.06 N（12 N范围内），硬度识别准确率达到98.0%，形状识别准确率达到93.75%。融合算法使实际抓取场景下的物体识别准确率超过98.5%。

Conclusion: 该方法聚焦于物体物理属性感知，通过融合深度和力信息，提升了人工触觉系统从感知到认知的能力，可用于具身感知应用。

Abstract: Tactile perception is crucial for embodied intelligent robots to recognize
objects. Vision-based tactile sensors extract object physical attributes
multidimensionally using high spatial resolution; however, this process
generates abundant redundant information. Furthermore, single-dimensional
extraction, lacking effective fusion, fails to fully characterize object
attributes. These challenges hinder the improvement of recognition accuracy. To
address this issue, this study introduces a two-stream network feature
extraction and fusion perception strategy for vision-based tactile systems.
This strategy employs a distributed approach to extract internal and external
object features. It obtains depth map information through three-dimensional
reconstruction while simultaneously acquiring hardness information by measuring
contact force data. After extracting features with a convolutional neural
network (CNN), weighted fusion is applied to create a more informative and
effective feature representation. In standard tests on objects of varying
shapes and hardness, the force prediction error is 0.06 N (within a 12 N
range). Hardness recognition accuracy reaches 98.0%, and shape recognition
accuracy reaches 93.75%. With fusion algorithms, object recognition accuracy in
actual grasping scenarios exceeds 98.5%. Focused on object physical attributes
perception, this method enhances the artificial tactile system ability to
transition from perception to cognition, enabling its use in embodied
perception applications.

</details>


### [176] [Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](https://arxiv.org/abs/2510.12276)
*Fuhao Li,Wenxuan Song,Han Zhao,Jingbo Wang,Pengxiang Ding,Donglin Wang,Long Zeng,Haoang Li*

Main category: cs.RO

TL;DR: 通过在中间层对齐视觉嵌入和 3D 几何表示，空间强制 (SF) 改进了视觉-语言-动作 (VLA) 模型，无需 3D 传感器或深度估计器，从而在机器人任务中实现了最先进的性能、更快的训练和更高的数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作 (VLA) 模型在处理 3D 物理世界时存在空间意识不足的问题，因为它们主要基于 2D 数据进行预训练。虽然现有解决方案试图引入 3D 传感器输入或使用深度估计器，但这些方法面临传感器噪声、硬件异构性和数据集不完整等挑战。

Method: 提出空间强制 (SF) 策略，通过在中间层对齐 VLA 模型的视觉嵌入与预训练的 3D 基础模型生成的几何表示，从而在无需显式 3D 输入或深度估计器的情况下，隐式地增强 VLA 模型在空间理解能力和动作精确性。

Result: 在模拟和真实世界环境中进行的大量实验表明，SF 取得了最先进的成果，优于基于 2D 和 3D 的 VLA 模型。此外，SF 将训练速度提高了 3.8 倍，并提高了在各种机器人任务中的数据效率。

Conclusion: 空间强制 (SF) 是一种有效的方法，可以提高 VLA 模型在机器人任务中的空间理解能力和动作精确性，同时提高训练速度和数据效率，而无需依赖显式的 3D 输入或深度估计器。

Abstract: Vision-language-action (VLA) models have recently shown strong potential in
enabling robots to follow language instructions and execute precise actions.
However, most VLAs are built upon vision-language models pretrained solely on
2D data, which lack accurate spatial awareness and hinder their ability to
operate in the 3D physical world. Existing solutions attempt to incorporate
explicit 3D sensor inputs such as depth maps or point clouds, but these
approaches face challenges due to sensor noise, hardware heterogeneity, and
incomplete depth coverage in existing datasets. Alternative methods that
estimate 3D cues from 2D images also suffer from the limited performance of
depth estimators.We propose Spatial Forcing (SF), a simple yet effective
alignment strategy that implicitly forces VLA models to develop spatial
comprehension capabilities without relying on explicit 3D inputs or depth
estimators. SF aligns intermediate visual embeddings of VLAs with geometric
representations produced by pretrained 3D foundation models. By enforcing
alignment at intermediate layers, SF guides VLAs to encode richer spatial
representations that enhance action precision.Extensive experiments in
simulation and real-world environments demonstrate that SF achieves
state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further
accelerates training by up to 3.8x and improves data efficiency across diverse
robotic tasks. Project page is at https://spatial-forcing.github.io/

</details>


### [177] [Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics](https://arxiv.org/abs/2510.12332)
*Mohammadreza Kasaei,Mostafa Ghobadi,Mohsen Khadem*

Main category: cs.RO

TL;DR: 该论文提出了一种用于肌腱驱动的连续体机器人的形状感知全身控制框架，直接应用于腔内手术导航。


<details>
  <summary>Details</summary>
Motivation: 传统的仅尖端控制在内窥镜检查等腔内手术中，由于难以在患者特异性解剖结构中精确定位和安全导航，常常导致碰撞、组织损伤或无法到达远端目标。本研究旨在解决这些挑战。

Method: 本研究结合了物理信息骨干模型和通过增强型神经 ODE 的残差学习，以实现精确的形状估计和高效的雅可比计算。此外，还采用基于采样的模型预测路径积分 (MPPI) 控制器，在驱动约束下联合优化尖端跟踪、骨干顺应性和障碍物规避。任务管理器通过在遥操作期间实时调整目标（如壁间隙或直接前进）来增强适应性。

Result: 在各种场景下，包括轨迹跟踪、动态障碍物规避和形状约束到达，模拟研究实现了毫米级的精度。真实机器人实验验证了该框架在支气管镜检查模型上的有效性，显示出优于传统方法的性能。

Conclusion: 提出的框架有望提高微创腔内手术的安全性、可靠性和操作者效率，并可广泛应用于其他狭窄和安全关键环境。

Abstract: This paper presents a shape-aware whole-body control framework for
tendon-driven continuum robots with direct application to endoluminal surgical
navigation. Endoluminal procedures, such as bronchoscopy, demand precise and
safe navigation through tortuous, patient-specific anatomy where conventional
tip-only control often leads to wall contact, tissue trauma, or failure to
reach distal targets. To address these challenges, our approach combines a
physics-informed backbone model with residual learning through an Augmented
Neural ODE, enabling accurate shape estimation and efficient Jacobian
computation. A sampling-based Model Predictive Path Integral (MPPI) controller
leverages this representation to jointly optimize tip tracking, backbone
conformance, and obstacle avoidance under actuation constraints. A task manager
further enhances adaptability by allowing real-time adjustment of objectives,
such as wall clearance or direct advancement, during tele-operation. Extensive
simulation studies demonstrate millimeter-level accuracy across diverse
scenarios, including trajectory tracking, dynamic obstacle avoidance, and
shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom
validate the framework, showing improved lumen-following accuracy, reduced wall
contacts, and enhanced adaptability compared to joystick-only navigation and
existing baselines. These results highlight the potential of the proposed
framework to increase safety, reliability, and operator efficiency in minimally
invasive endoluminal surgery, with broader applicability to other confined and
safety-critical environments.

</details>


### [178] [Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task](https://arxiv.org/abs/2510.12340)
*Nicky Mol,Luka Peternel,Alessandro Ianniello,Denis Zatyagov,Auke Nachenius,Stephan Balvert,J. Micah Prendergast,Sara Muscolo,Olger Siebinga,Eva Verhoef,Deborah Forster,David A. Abbink*

Main category: cs.RO

TL;DR: 该论文主张在工作场所应用机器人技术时采取跨学科技术，并以飞机发动机维修和维护操作为例进行论证。


<details>
  <summary>Details</summary>
Motivation: 应对劳动力短缺、人口老龄化和生产需求增加等社会挑战，同时优先考虑工人福祉和工作吸引力。

Method: 采用跨学科技术，整合学术研究、实践专业知识和经验知识，并探讨协作机器人在飞机发动机维修和维护中的应用。

Result: （未在摘要中提供）

Conclusion: （未在摘要中提供）

Abstract: The use of robots in industrial settings continues to grow, driven by the
need to address complex societal challenges such as labor shortages, aging
populations, and ever-increasing production demands. In this abstract, we
advocate for (and demonstrate) a transdisciplinary approach when considering
robotics in the workplace. Transdisciplinarity emphasizes the integration of
academic research with pragmatic expertise and embodied experiential knowledge,
that prioritize values such as worker wellbeing and job attractiveness. In the
following, we describe an ongoing multi-pronged effort to explore the potential
of collaborative robots in the context of airplane engine repair and
maintenance operations.

</details>


### [179] [PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing](https://arxiv.org/abs/2510.12346)
*Bingquan Li,Ning Wang,Tianwei Zhang,Zhicheng He,Yucong Wu*

Main category: cs.RO

TL;DR: 本研究提出了一种名为PolyMap的基于感知的运动规划框架，用于人形机器人爬楼梯。该框架通过融合激光雷达、RGB-D相机和IMU等多传感器数据，实时构建多边形楼梯平面语义地图，并基于此地图进行足步规划。实验证明，该方法在室内外真实场景中对人形机器人爬楼梯是高效且鲁棒的。


<details>
  <summary>Details</summary>
Motivation: 为了模仿人类行走，机器人需要在未知空间中准确地踩踏所看到的位置，尤其是在爬楼梯这样的复杂场景中。

Method: 实时构建多边形楼梯平面语义地图，并利用这些平面段进行足步规划。该方法结合了多传感器融合（LiDAR、RGB-D相机和IMU）来实现平面分割和视觉里程计。

Result: 在NVIDIA Orin上部署，实现了20-30 Hz的全身运动规划输出。在室内外真实场景实验中，证明了该方法对人形机器人爬楼梯的效率和鲁棒性。

Conclusion: PolyMap框架能够高效鲁棒地支持人形机器人进行爬楼梯运动。

Abstract: Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.

</details>


### [180] [Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control](https://arxiv.org/abs/2510.12363)
*Jiale Fan,Andrei Cramariuc,Tifanny Portela,Marco Hutter*

Main category: cs.RO

TL;DR: 通过预训练的逆动力学模型来启动机器人运动控制中的强化学习策略，以提高样本效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习方法在机器人运动控制中通常需要从头开始学习每个独立技能，即使这些技能可能共享一些可泛化的知识，这种方法效率低下。

Method: 首先，使用一种不依赖任务的探索性数据收集算法来收集多样化的动态转换数据，然后通过监督学习训练一个本体感受逆动力学模型（PIDM）。接着，将预训练的权重加载到Actor和Critic网络中，为实际任务的策略优化提供初始值，以实现对经典Actor-Critic算法（如PPO）的预热启动。

Result: 在七个不同的机器人运动控制任务上进行了系统验证，结果显示该初始化策略有显著优势。与随机初始化相比，该方法平均提高了40.1%的样本效率和7.5%的任务性能。

Conclusion: 该预训练方法能够显著提升机器人运动控制任务的样本效率和任务性能，为强化学习在机器人领域的应用提供了一种有效的解决方案。

Abstract: The pretraining-finetuning paradigm has facilitated numerous transformative
advancements in artificial intelligence research in recent years. However, in
the domain of reinforcement learning (RL) for robot motion control, individual
skills are often learned from scratch despite the high likelihood that some
generalizable knowledge is shared across all task-specific policies belonging
to a single robot embodiment. This work aims to define a paradigm for
pretraining neural network models that encapsulate such knowledge and can
subsequently serve as a basis for warm-starting the RL process in classic
actor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin
with a task-agnostic exploration-based data collection algorithm to gather
diverse, dynamic transition data, which is then used to train a Proprioceptive
Inverse Dynamics Model (PIDM) through supervised learning. The pretrained
weights are loaded into both the actor and critic networks to warm-start the
policy optimization of actual tasks. We systematically validated our proposed
method on seven distinct robot motion control tasks, showing significant
benefits to this initialization strategy. Our proposed approach on average
improves sample efficiency by 40.1% and task performance by 7.5%, compared to
random initialization. We further present key ablation studies and empirical
analyses that shed light on the mechanisms behind the effectiveness of our
method.

</details>


### [181] [Controlling Intent Expressiveness in Robot Motion with Diffusion Models](https://arxiv.org/abs/2510.12370)
*Wenli Shi,Clemence Grislain,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的运动生成框架，用于在广泛的可控范围内生成机器人运动，从高度可读到高度模糊，并使用信息势场和两阶段扩散模型来实现这一点。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹生成方法优先考虑效率但忽略了清晰传达机器人意图，而现有的可读性运动方法只生成单一的最佳可读性轨迹，未能适应不同情境下的意图表达需求。

Method: 提出了一种基于信息势场（Information Potential Field）的建模方法，为轨迹分配连续的可读性分数，并结合一个两阶段扩散模型：第一阶段生成指定可读性水平的路径，第二阶段将路径转换为可执行的机器人动作。

Result: 实验证明，该方法在2D和3D运动任务中能够生成具有不同可读性程度的多样化且可控的运动，并且性能与现有技术（SOTA）相当。

Conclusion: 该研究成功开发了一种新颖的运动生成框架，通过信息势场和两阶段扩散模型实现了机器人运动可读性的全面控制，并在实验中验证了其有效性。

Abstract: Legibility of robot motion is critical in human-robot interaction, as it
allows humans to quickly infer a robot's intended goal. Although traditional
trajectory generation methods typically prioritize efficiency, they often fail
to make the robot's intentions clear to humans. Meanwhile, existing approaches
to legible motion usually produce only a single "most legible" trajectory,
overlooking the need to modulate intent expressiveness in different contexts.
In this work, we propose a novel motion generation framework that enables
controllable legibility across the full spectrum, from highly legible to highly
ambiguous motions. We introduce a modeling approach based on an Information
Potential Field to assign continuous legibility scores to trajectories, and
build upon it with a two-stage diffusion framework that first generates paths
at specified legibility levels and then translates them into executable robot
actions. Experiments in both 2D and 3D reaching tasks demonstrate that our
approach produces diverse and controllable motions with varying degrees of
legibility, while achieving performance comparable to SOTA. Code and project
page: https://legibility-modulator.github.io.

</details>


### [182] [Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking](https://arxiv.org/abs/2510.12392)
*Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park*

Main category: cs.RO

TL;DR: 生成行为克隆（GBC）框架，特别是多任务设置，采用基于扩散策略的开环（OL）控制，虽然成功率高且泛化性好，但随机性可能导致错误动作采样和任务失败。OL控制的响应延迟也会影响动态环境下的性能。本研究提出自我指导和自适应分块技术，以提高扩散策略的一致性和反应性。自我指导利用过去的观察来提高动作保真度并促进面向未来的行为。自适应分块则在反应性的收益大于时间一致性的需求时选择性地更新动作序列。实验证明，该方法在多种模拟和真实机器人操作任务中显著提高了GBC的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于扩散策略的开环（OL）控制在生成行为克隆（GBC）中存在的随机性导致的错误动作采样、任务失败以及响应延迟等问题，本研究提出新的技术来增强扩散策略的一致性和反应性。

Method: 提出两种新技术：1. 自我指导：利用过去的观察来提高动作保真度，并隐含地促进面向未来的行为。2. 自适应分块：在反应性的收益大于时间一致性的需求时，选择性地更新动作序列。

Result: 在广泛的模拟和真实世界机器人操作任务上进行了广泛的实验，结果表明所提出的方法显著提高了GBC的性能。

Conclusion: 通过引入自我指导和自适应分块技术，成功地解决了现有生成行为克隆方法中基于扩散策略的开环控制所面临的随机性和响应延迟问题，并在多项机器人操作任务中取得了显著的性能提升。

Abstract: Generative Behavior Cloning (GBC) is a simple yet effective framework for
robot learning, particularly in multi-task settings. Recent GBC methods often
employ diffusion policies with open-loop (OL) control, where actions are
generated via a diffusion process and executed in multi-step chunks without
replanning. While this approach has demonstrated strong success rates and
generalization, its inherent stochasticity can result in erroneous action
sampling, occasionally leading to unexpected task failures. Moreover, OL
control suffers from delayed responses, which can degrade performance in noisy
or dynamic environments. To address these limitations, we propose two novel
techniques to enhance the consistency and reactivity of diffusion policies: (1)
self-guidance, which improves action fidelity by leveraging past observations
and implicitly promoting future-aware behavior; and (2) adaptive chunking,
which selectively updates action sequences when the benefits of reactivity
outweigh the need for temporal consistency. Extensive experiments show that our
approach substantially improves GBC performance across a wide range of
simulated and real-world robotic manipulation tasks. Our code is available at
https://github.com/junhyukso/SGAC

</details>


### [183] [Learning Robust Agile Flight Control with Stability Guarantees](https://arxiv.org/abs/2510.12611)
*Lukas Pries,Markus Ryll*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的神经增强反馈控制器，用于敏捷飞行控制，以应对高速四旋翼飞行中的精确轨迹跟踪挑战，该控制器克服了现有方法的局限性，并统一了它们的优点。


<details>
  <summary>Details</summary>
Motivation: 为了在高速敏捷四旋翼飞行中实现平台运行极限的精确轨迹跟踪，需要一种能够处理执行器约束、对扰动具有鲁棒性并且计算效率高的控制器，以满足安全关键应用的需求。

Method: 提出了一种新颖的神经增强反馈控制器，该控制器结合了现有最先进控制方法的优点，并克服了它们的个别局限性。

Result: 所提出的控制器能够精确跟踪超过执行器能力范围的高度激进的轨迹，并提供通用的稳定性保证，即使在易受扰动的情况下也能增强鲁棒性和跟踪性能。此外，该控制器具有高度的非线性反馈结构，计算效率高，可在高更新率下快速计算。

Conclusion: 该神经增强反馈控制器能够实现敏捷飞行控制，精确跟踪高动态轨迹，并具有鲁棒性和计算效率。在模拟中，学习过程快速且稳定，控制器可以直接部署到真实平台，无需额外的训练或微调。

Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving
precise trajectory tracking at the platform's operational limits is paramount.
Controllers must handle actuator constraints, exhibit robustness to
disturbances, and remain computationally efficient for safety-critical
applications. In this work, we present a novel neural-augmented feedback
controller for agile flight control. The controller addresses individual
limitations of existing state-of-the-art control paradigms and unifies their
strengths. We demonstrate the controller's capabilities, including the accurate
tracking of highly aggressive trajectories that surpass the feasibility of the
actuators. Notably, the controller provides universal stability guarantees,
enhancing its robustness and tracking performance even in exceedingly
disturbance-prone settings. Its nonlinear feedback structure is highly
efficient enabling fast computation at high update rates. Moreover, the
learning process in simulation is both fast and stable, and the controller's
inherent robustness allows direct deployment to real-world platforms without
the need for training augmentations or fine-tuning.

</details>


### [184] [Robot Learning: A Tutorial](https://arxiv.org/abs/2510.12403)
*Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi*

Main category: cs.RO

TL;DR: 机器人学习正经历重大变革，从传统方法转向数据驱动方法，使用强化学习、行为克隆和语言条件模型。


<details>
  <summary>Details</summary>
Motivation: 机器人学习正经历重大变革，从传统方法转向数据驱动方法，使用强化学习、行为克隆和语言条件模型。

Method: 本教程将引导读者了解现代机器人学习的原则，从基础的强化学习和行为克隆到通用的、语言条件模型。

Result: 机器人学习正经历重大变革，从传统方法转向数据驱动方法，使用强化学习、行为克隆和语言条件模型。

Conclusion: 本教程旨在为研究人员和实践者提供概念理解和实践工具，以促进机器人学习领域的发展。

Abstract: Robot learning is at an inflection point, driven by rapid advancements in
machine learning and the growing availability of large-scale robotics data.
This shift from classical, model-based methods to data-driven, learning-based
paradigms is unlocking unprecedented capabilities in autonomous systems. This
tutorial navigates the landscape of modern robot learning, charting a course
from the foundational principles of Reinforcement Learning and Behavioral
Cloning to generalist, language-conditioned models capable of operating across
diverse tasks and even robot embodiments. This work is intended as a guide for
researchers and practitioners, and our goal is to equip the reader with the
conceptual understanding and practical tools necessary to contribute to
developments in robot learning, with ready-to-use examples implemented in
$\texttt{lerobot}$.

</details>


### [185] [M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing](https://arxiv.org/abs/2510.12419)
*Shunnosuke Yoshimura,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 一种利用FDM 3D打印机填充图案的多材料触觉传感器，可轻松制造且具有高通用性。


<details>
  <summary>Details</summary>
Motivation: 为了扩大触觉传感器的应用范围，提出一种易于制造且通用的触觉传感器。

Method: 利用多材料FDM 3D打印机的填充图案作为传感原理，使用导电和非导电柔性长丝创建具有特定填充图案的分层结构，通过测量压力引起的电阻变化来获取触觉信息。

Result: 测量了因分层结构修改而引起的触觉传感器特性的变化，并演示了多块传感器的制造和使用，实现了足底运动模式测量、机器人手集成和基于触觉的机器人操作。

Conclusion: 通过实验验证了所提出的触觉传感器的有效性。

Abstract: Tactile sensors have a wide range of applications, from utilization in
robotic grippers to human motion measurement. If tactile sensors could be
fabricated and integrated more easily, their applicability would further
expand. In this study, we propose a tactile sensor-M3D-skin-that can be easily
fabricated with high versatility by leveraging the infill patterns of a
multi-material fused deposition modeling (FDM) 3D printer as the sensing
principle. This method employs conductive and non-conductive flexible filaments
to create a hierarchical structure with a specific infill pattern. The flexible
hierarchical structure deforms under pressure, leading to a change in
electrical resistance, enabling the acquisition of tactile information. We
measure the changes in characteristics of the proposed tactile sensor caused by
modifications to the hierarchical structure. Additionally, we demonstrate the
fabrication and use of a multi-tile sensor. Furthermore, as applications, we
implement motion pattern measurement on the sole of a foot, integration with a
robotic hand, and tactile-based robotic operations. Through these experiments,
we validate the effectiveness of the proposed tactile sensor.

</details>


### [186] [Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning](https://arxiv.org/abs/2510.12684)
*Alvaro Belmonte-Baeza,Miguel Cazorla,Gabriel J. García,Carlos J. Pérez-Del-Pulgar,Jorge Pomares*

Main category: cs.RO

TL;DR: 本文提出了一种约束强化学习框架，用于在月球环境中操作的自主四足移动机械臂，实现了在月球重力下精确的运动和操作，并满足了安全性约束。


<details>
  <summary>Details</summary>
Motivation: 为了应对月球探索和建立永久月球基地对机器人平台在复杂地形中导航和操作的需求，以及轮式漫游车在非结构化和陡峭地形中的局限性，需要开发具有更高移动性和适应性的仿人机器人。

Method: 提出了一种约束强化学习框架，该框架将全身运动和操作能力结合起来，并明确考虑了碰撞避免、动态稳定性和功耗效率等安全约束，以适应月球特有的低重力和不规则地形条件。

Result: 实验结果表明，该框架能够实现精确的6D任务空间末端执行器位姿跟踪，平均位置精度为4厘米，方向精度为8.1度。该系统能够有效遵守软硬约束，并针对月球重力条件进行了优化。

Conclusion: 该研究成功地将自适应学习与任务关键的安全要求相结合，为未来月球任务开发先进的自主机器人探测器铺平了道路。

Abstract: Robotics plays a pivotal role in planetary science and exploration, where
autonomous and reliable systems are crucial due to the risks and challenges
inherent to space environments. The establishment of permanent lunar bases
demands robotic platforms capable of navigating and manipulating in the harsh
lunar terrain. While wheeled rovers have been the mainstay for planetary
exploration, their limitations in unstructured and steep terrains motivate the
adoption of legged robots, which offer superior mobility and adaptability. This
paper introduces a constrained reinforcement learning framework designed for
autonomous quadrupedal mobile manipulators operating in lunar environments. The
proposed framework integrates whole-body locomotion and manipulation
capabilities while explicitly addressing critical safety constraints, including
collision avoidance, dynamic stability, and power efficiency, in order to
ensure robust performance under lunar-specific conditions, such as reduced
gravity and irregular terrain. Experimental results demonstrate the framework's
effectiveness in achieving precise 6D task-space end-effector pose tracking,
achieving an average positional accuracy of 4 cm and orientation accuracy of
8.1 degrees. The system consistently respects both soft and hard constraints,
exhibiting adaptive behaviors optimized for lunar gravity conditions. This work
effectively bridges adaptive learning with essential mission-critical safety
requirements, paving the way for advanced autonomous robotic explorers for
future lunar missions.

</details>


### [187] [A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation](https://arxiv.org/abs/2510.12477)
*Gaoyuan Liu,Joris de Winter,Kelly Merckaert,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 该混合强化学习框架通过交互式运动规划器和强化学习任务规划器，在人机协作环境中提高了安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 在人机协作环境中，安全机制通常会妨碍任务效率，因为人为干预会导致机器人备份运动和目标失败，频繁的运动重新规划会增加计算负担和失败几率。

Method: 提出一个混合强化学习规划框架，包括一个交互式运动规划器和一个强化学习任务规划器。强化学习任务规划器根据运动规划器的反馈选择统计上安全且高效的任务序列，而运动规划器通过检测人类手臂运动并在先前路径无效时部署新路径来确保任务执行过程没有碰撞。

Result: 该框架在仿真和真实世界的协作机器人上进行了验证，并与硬编码的任务运动规划方法进行了比较。结果表明，该规划框架可以：1）对关节和任务层面不确定的运动做出反应；2）减少重复失败的目标命令次数；3）减少重新规划请求的总数。

Conclusion: 该混合强化学习规划框架在人机协作环境中能够有效提高安全性和效率。

Abstract: In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.

</details>


### [188] [Fast Visuomotor Policy for Robotic Manipulation](https://arxiv.org/abs/2510.12483)
*Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang*

Main category: cs.RO

TL;DR: Energy Policy是一个用于机器人操作的快速有效的策略框架，它能原生预测多模态动作，实现高速高精度操作，并在资源受限的系统中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有机器人策略在处理高频机器人任务和资源受限系统时存在不足，未能高效地预测多模态动作，限制了操作的速度和精度。

Method: 提出了一种名为Energy Policy的策略框架，包含两个核心组件：1. 使用能量分数作为学习目标，以支持多模态动作建模。2. 引入一个能量MLP来实现该目标，保持架构的简洁高效。

Result: 在模拟和真实机器人任务的实验中，Energy Policy的性能与现有最先进的操作方法相当或更优，同时显著降低了计算开销。在MimicGen基准测试中，其性能更优，推理速度更快。

Conclusion: Energy Policy是一个高效且性能优越的机器人操作策略框架，特别适用于高频任务和资源受限场景，能在保证高精度和高速度的同时，有效降低计算成本。

Abstract: We present a fast and effective policy framework for robotic manipulation,
named Energy Policy, designed for high-frequency robotic tasks and
resource-constrained systems. Unlike existing robotic policies, Energy Policy
natively predicts multimodal actions in a single forward pass, enabling
high-precision manipulation at high speed. The framework is built upon two core
components. First, we adopt the energy score as the learning objective to
facilitate multimodal action modeling. Second, we introduce an energy MLP to
implement the proposed objective while keeping the architecture simple and
efficient. We conduct comprehensive experiments in both simulated environments
and real-world robotic tasks to evaluate the effectiveness of Energy Policy.
The results show that Energy Policy matches or surpasses the performance of
state-of-the-art manipulation methods while significantly reducing
computational overhead. Notably, on the MimicGen benchmark, Energy Policy
achieves superior performance with at a faster inference compared to existing
approaches.

</details>


### [189] [Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge](https://arxiv.org/abs/2510.12509)
*Gaoyuan Liu,Bas Boom,Naftali Slob,Yuri Durodié,Ann Nowé,Bram Vanderborght*

Main category: cs.RO

TL;DR: 自动化修剪机器人需要解决操作规划和控制问题，以应对果园中复杂且具有挑战性的环境。


<details>
  <summary>Details</summary>
Motivation: 机器人操作器已作为自动化解决方案被开发出来，以应对修剪这一重复性任务。然而，以往的研究主要集中在感知挑战上，而忽略了操作的复杂性，包括在联合和笛卡尔空间中进行规划和控制，以引导末端执行器完成复杂的、有遮挡的分支。

Method: 提出了一种用于高维机器人手臂在修剪场景中的规划问题，并研究了系统的内在冗余度。整合了感知、建模和整体规划，提出了一种全面的修剪工作流程。

Result: 实验证明，更全面的规划方法可以显著提高机器人操作器的性能。

Conclusion: 该工作对机器人修剪进行了补充，并为修剪应用中的规划的未来研究和开发提供了动力。

Abstract: Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.

</details>


### [190] [Designing Tools with Control Confidence](https://arxiv.org/abs/2510.12630)
*Ajith Anil Meera,Abian Torres,Pablo Lanillos*

Main category: cs.RO

TL;DR: Prehistoric humans invented stone tools not just for immediate use but also for confidence in later use. Current AI tool design focuses only on performance, ignoring agent confidence. This paper introduces a framework for autonomous hand tool design that incorporates a 'control confidence' term, inspired by neuroscience, to create more robust tools. Simulations show these tools perform better under uncertainty and perturbations than those designed purely for accuracy. The proposed CMAES-based optimization strategy also designs optimal tools faster than existing methods.


<details>
  <summary>Details</summary>
Motivation: Current autonomous tool design frameworks focus solely on performance optimization, neglecting the agent's confidence in tool use for repeated applications. This paper aims to address this gap by incorporating control confidence into the design process.

Method: This paper proposes an optimization framework for task-conditioned autonomous hand tool design for robots. A neuro-inspired control confidence term is introduced into the optimization routine to enhance tool robustness. The framework utilizes a CMAES-based evolutionary optimization strategy.

Result: Tools designed with control confidence exhibit greater robustness to environmental uncertainties and control perturbations compared to tools designed with a pure accuracy-driven objective. The proposed method balances robustness and goal accuracy, and the CMAES-based optimizer achieves optimal tool design within fewer iterations than state-of-the-art alternatives.

Conclusion: Autonomous tool design can be enhanced by incorporating a control confidence objective, leading to more robust tools that maintain performance under environmental uncertainties and control perturbations. This approach provides a balance between robustness and accuracy, and the CMAES-based optimization strategy is effective and efficient.

Abstract: Prehistoric humans invented stone tools for specialized tasks by not just
maximizing the tool's immediate goal-completion accuracy, but also increasing
their confidence in the tool for later use under similar settings. This factor
contributed to the increased robustness of the tool, i.e., the least
performance deviations under environmental uncertainties. However, the current
autonomous tool design frameworks solely rely on performance optimization,
without considering the agent's confidence in tool use for repeated use. Here,
we take a step towards filling this gap by i) defining an optimization
framework for task-conditioned autonomous hand tool design for robots, where
ii) we introduce a neuro-inspired control confidence term into the optimization
routine that helps the agent to design tools with higher robustness. Through
rigorous simulations using a robotic arm, we show that tools designed with
control confidence as the objective function are more robust to environmental
uncertainties during tool use than a pure accuracy-driven objective. We further
show that adding control confidence to the objective function for tool design
provides a balance between the robustness and goal accuracy of the designed
tools under control perturbations. Finally, we show that our CMAES-based
evolutionary optimization strategy for autonomous tool design outperforms other
state-of-the-art optimizers by designing the optimal tool within the fewest
iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.

</details>


### [191] [Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop](https://arxiv.org/abs/2510.12662)
*Oz Gitelson,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 本框架提出了一种新颖的人机逻辑交互方法，使机器人能够可靠地满足（无限地平线）时序逻辑任务，同时与追求独立且未知任务的人类进行有效协作。该方法结合了最大化适应性和最小化可调反馈两项关键能力：(i) 最大化适应性使机器人能够在线调整其策略，以便在可能时利用人类行为进行协作；(ii) 最小化可调反馈使机器人仅在需要保证进展时才在线请求人类合作。这种平衡最大限度地减少了人机干扰，保留了人的自主性，并确保了即使在人类目标冲突的情况下，机器人也能持续完成任务。


<details>
  <summary>Details</summary>
Motivation: 在人机协作场景中，机器人需要可靠地完成时序逻辑任务，同时还要适应人类的独立且未知的任务目标，并在此过程中保持高效和最小化干扰。

Method: 该框架结合了两种关键能力：(i) 最大化适应性：机器人能够在线调整其策略以利用人类行为进行协作；(ii) 最小化可调反馈：机器人仅在必要时才在线请求人类合作以保证任务进展。

Result: 在现实世界的积木操作任务和Overcooked-AI基准测试中，该方法产生了丰富且超出预期的人机协作行为，同时保持了严格的形式化保证。

Conclusion: 该新颖的人机逻辑交互框架成功实现了机器人在满足时序逻辑任务的同时，能与具有独立且未知目标的人类进行有效协作，通过最大化适应性和最小化可调反馈实现了鲁棒性、自主性以及低干扰的人机交互。

Abstract: We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.

</details>


### [192] [Reflection-Based Task Adaptation for Self-Improving VLA](https://arxiv.org/abs/2510.12710)
*Baicheng Li,Dong Wu,Zike Yan,Xinchen Liu,Zecui Zeng,Lusong Li,Hongbin Zha*

Main category: cs.RO

TL;DR: 该研究提出了一种名为“反射式自适应”的框架，用于在没有人类干预的情况下，使预训练的视觉-语言-动作（VLA）模型能够快速自主地适应新任务。


<details>
  <summary>Details</summary>
Motivation: 预训练的VLA模型在适应新任务方面效率低下，需要一种更快速、自主的方法。

Method: 该框架包含两个关键部分：1. 失败驱动的反射式强化学习（RL），利用VLM的因果推理从失败分析中合成奖励函数，加速学习。2. 成功驱动的质量引导监督微调（SFT），通过模仿高质量的成功轨迹来确保策略与最终任务目标保持一致，并引入条件课程机制辅助初始探索。

Result: 在具有挑战性的操纵任务实验中，与基线方法相比，该框架实现了更快的收敛速度和更高的最终成功率。

Conclusion: 该框架为创建能够高效可靠地适应新环境的自主改进型智能体提供了一个强大的解决方案。

Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap
towards general-purpose robots, yet efficiently adapting them to novel,
specific tasks in-situ remains a significant hurdle. While reinforcement
learning (RL) is a promising avenue for such adaptation, the process often
suffers from low efficiency, hindering rapid task mastery. We introduce
Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation
without human intervention. Our framework establishes a self-improving loop
where the agent learns from its own experience to enhance both strategy and
execution.
  The core of our framework is a dual-pathway architecture that addresses the
full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway
enables rapid learning by using the VLM's causal reasoning to automatically
synthesize a targeted, dense reward function from failure analysis. This
provides a focused learning signal that significantly accelerates policy
exploration. However, optimizing such proxy rewards introduces a potential risk
of "reward hacking," where the agent masters the reward function but fails the
actual task. To counteract this, our second pathway, Success-Driven
Quality-Guided SFT, grounds the policy in holistic success. It identifies and
selectively imitates high-quality successful trajectories, ensuring the agent
remains aligned with the ultimate task goal. This pathway is strengthened by a
conditional curriculum mechanism to aid initial exploration.
  We conduct experiments in challenging manipulation tasks. The results
demonstrate that our framework achieves faster convergence and higher final
success rates compared to representative baselines. Our work presents a robust
solution for creating self-improving agents that can efficiently and reliably
adapt to new environments.

</details>


### [193] [Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control](https://arxiv.org/abs/2510.12717)
*Se Hwan Jeon,Ho Jae Lee,Seungwoo Hong,Sangbae Kim*

Main category: cs.RO

TL;DR: MPC and RL can be combined to create more robust and interpretable locomotion controllers.


<details>
  <summary>Details</summary>
Motivation: MPC offers interpretability but is limited by model mismatch and real-time constraints, while RL provides robustness but lacks interpretability and requires extensive reward engineering. This paper aims to combine the strengths of both approaches.

Method: A GPU-parallelized residual architecture is proposed to integrate MPC and RL by blending their torque-level outputs. A whole-body MPC formulation is used for RL training, and a residual policy learns to correct MPC outputs. The model-based control prior guides the policy with simple rewards.

Result: The combined approach achieves higher sample efficiency, greater asymptotic rewards, expands the range of trackable velocity commands, and enables zero-shot adaptation to unseen gaits and uneven terrain compared to standalone MPC or end-to-end RL.

Conclusion: The proposed residual architecture effectively combines MPC and RL, leveraging the interpretability and constraint handling of model-based control with the adaptability of RL for improved locomotion control.

Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion
controllers grounded in physical models, but its robustness depends on frequent
replanning and is limited by model mismatch and real-time computational
constraints. Reinforcement Learning (RL), by contrast, can produce highly
robust behaviors through stochastic training but often lacks interpretability,
suffers from out-of-distribution failures, and requires intensive reward
engineering. This work presents a GPU-parallelized residual architecture that
tightly integrates MPC and RL by blending their outputs at the torque-control
level. We develop a kinodynamic whole-body MPC formulation evaluated across
thousands of agents in parallel at 100 Hz for RL training. The residual policy
learns to make targeted corrections to the MPC outputs, combining the
interpretability and constraint handling of model-based control with the
adaptability of RL. The model-based control prior acts as a strong bias,
initializing and guiding the policy towards desirable behavior with a simple
set of rewards. Compared to standalone MPC or end-to-end RL, our approach
achieves higher sample efficiency, converges to greater asymptotic rewards,
expands the range of trackable velocity commands, and enables zero-shot
adaptation to unseen gaits and uneven terrain.

</details>


### [194] [T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](https://arxiv.org/abs/2510.12724)
*Xin Fei,Zhixuan Xu,Huaicong Fang,Tianrui Zhang,Lin Shao*

Main category: cs.RO

TL;DR: T(R,O) Grasp 是一个基于扩散的模型框架，用于机器人灵巧抓取，能够高效生成准确多样的抓取姿态，并在多种机器人手上表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器人灵巧抓取在处理高维状态和动作空间方面仍然是一个核心挑战。

Method: 提出 T(R,O) Grasp 框架，核心是 T(R,O) Graph，这是一个统一的表示，能够模拟机器人手和物体之间的空间变换并编码它们的几何属性。该框架结合了图扩散模型和高效逆运动学求解器，支持无条件和有条件的抓取合成。

Result: 在多种灵巧手上进行了广泛的实验，T(R,O) Grasp 在 NVIDIA A100 40GB GPU 上实现了 94.83% 的平均成功率、0.21 秒的推理速度和每秒 41 次的吞吐量，显著优于现有方法。该方法还具有鲁棒性、通用性，并能显著减少内存消耗。

Conclusion: T(R,O) Grasp 的高推理速度支持闭环灵巧操作，并有潜力成为灵巧抓取的基石模型。

Abstract: Dexterous grasping remains a central challenge in robotics due to the
complexity of its high-dimensional state and action space. We introduce T(R,O)
Grasp, a diffusion-based framework that efficiently generates accurate and
diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,
a unified representation that models spatial transformations between robotic
hands and objects while encoding their geometric properties. A graph diffusion
model, coupled with an efficient inverse kinematics solver, supports both
unconditioned and conditioned grasp synthesis. Extensive experiments on a
diverse set of dexterous hands show that T(R,O) Grasp achieves average success
rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per
second on an NVIDIA A100 40GB GPU, substantially outperforming existing
baselines. In addition, our approach is robust and generalizable across
embodiments while significantly reducing memory consumption. More importantly,
the high inference speed enables closed-loop dexterous manipulation,
underscoring the potential of T(R,O) Grasp to scale into a foundation model for
dexterous grasping.

</details>


### [195] [HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](https://arxiv.org/abs/2510.12733)
*Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork*

Main category: cs.RO

TL;DR: HYPE是一个结合了多模态轨迹建议和蒙特卡洛树搜索（MCTS）的运动规划器，通过引入条件占据预测模型来处理复杂的城市环境中的双向多智能体交互，并在nuPlan和DeepUrban基准测试中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够处理复杂城市环境中双向多智能体交互的安全可解释的运动规划器，并简化成本函数的设计。

Method: HYPE规划器将学习到的轨迹建议模型产生的多模态轨迹建议作为启发式先验，整合到蒙特卡洛树搜索（MCTS）的精炼过程中。通过引入一个以自身为条件的占据预测模型来模拟双向交互，并使用简单的基于网格的成本项。

Result: HYPE在nuPlan和DeepUrban这两个大规模真实世界基准测试中，尤其在安全性和适应性方面，取得了先进的性能。

Conclusion: HYPE通过整合多模态轨迹建议和条件占据预测，有效简化了成本函数的设计，并在复杂城市环境中实现了先进的运动规划性能。

Abstract: Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [196] [Mathematical aspects of the decomposition of diagonal U(N) operators](https://arxiv.org/abs/2510.11735)
*M. M. Fedin,A. A. Morozov*

Main category: quant-ph

TL;DR: 任意对角算子可分解为更小矩阵的张量积和矩阵积，并讨论了其解析结构和对称性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在证明任意对角算子可以分解为更小矩阵的张量积和矩阵积，并着重分析其解析结构和对称性。

Method: 利用图示化方法直观展示分解结构，并讨论所提出分解的对称性。

Result: 提出了任意对角算子的张量积和矩阵积分解方法，并引入了图示化表示。

Conclusion: 本文提出的方法和表示可应用于量子计算算法优化、生物分析、晶体学、人工智能模型优化等多个领域。

Abstract: We prove the decomposition of arbitrary diagonal operators into tensor and
matrix products of smaller matrices, focusing on the analytic structure of the
resulting formulas and their inherent symmetries. Diagrammatic representations
are introduced, providing clear visualizations of the structure of these
decompositions. We also discuss symmetries of the suggested decomposition.
Methods and representations developed in this paper can be applied in different
areas, including optimization of quantum computing algorithms, complex
biological analysis, crystallography, optimization of AI models, and others.

</details>


### [197] [Quantum Kernel Methods: Convergence Theory, Separation Bounds and Applications to Marketing Analytics](https://arxiv.org/abs/2510.11744)
*Laura Sáez-Ortuño,Santiago Forgas-Coll,Massimiliano Ferrara*

Main category: quant-ph

TL;DR: 本项目研究了在NISQ（Noisy Intermediate-Scale Quantum）时代应用量子核方法解决实际消费者分类任务的可行性，并提出了一种结合量子核支持向量机（Q-SVM）和量子特征提取（QFE）的混合流程。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索在NISQ硬件限制下，量子核方法在实际消费者分类任务中的应用潜力，并与经典和量子基线进行比较，为未来的NISQ工作流程和硬件集成提供一个实际的起点。

Method: 提出了一种混合流程，将量子核支持向量机（Q-SVM）与量子特征提取（QFE）模块相结合，并在模拟和有限的浅深度硬件上进行了基准测试。

Result: 在固定的超参数下，所提出的Q-SVM达到了0.7790的准确率，0.7647的精确率，0.8609的召回率，0.8100的F1分数和0.83的ROC AUC，显示出更高的灵敏度，同时保持了与经典SVM相比具有竞争力的精确率。

Conclusion: 研究结果表明，该混合量子流程在NISQ设备上具有潜力，可以作为NISQ时代工作流程和硬件集成的具体起点，但并非最终的基准。方法上，该设计通过设计浅层但具有表达力的量子嵌入来实现稳健的可分性，以应对硬件噪声的限制。

Abstract: This work studies the feasibility of applying quantum kernel methods to a
real consumer classification task in the NISQ regime. We present a hybrid
pipeline that combines a quantum-kernel Support Vector Machine (Q-SVM) with a
quantum feature extraction module (QFE), and benchmark it against classical and
quantum baselines in simulation and with limited shallow-depth hardware runs.
With fixed hyperparameters, the proposed Q-SVM attains 0.7790 accuracy, 0.7647
precision, 0.8609 recall, 0.8100 F1, and 0.83 ROC AUC, exhibiting higher
sensitivity while maintaining competitive precision relative to classical SVM.
We interpret these results as an initial indicator and a concrete starting
point for NISQ-era workflows and hardware integration, rather than a definitive
benchmark. Methodologically, our design aligns with recent work that formalizes
quantum-classical separations and verifies resources via XEB-style approaches,
motivating shallow yet expressive quantum embeddings to achieve robust
separability despite hardware noise constraints.

</details>


### [198] [Back-reflection in dipole fields and beyond](https://arxiv.org/abs/2510.11764)
*Maksim Valialshchikov,Felix Karbstein,Daniel Seipt,Matt Zepf*

Main category: quant-ph

TL;DR: 量子反射是量子真空的一个特征，源于电磁场的不均匀性。为了在现实世界中实现量子反射在后向反射通道中的应用，本文首次对具有偶极子脉冲的光-光散射进行了数值估计，这是已知能够实现最紧密的光聚焦。对于具有相同频率的偶极泵浦和高斯探测光的全光设置，我们发现主要的信号特征主要与四波混频的后向反射通道有关。在此基础上，我们研究了多聚焦脉冲配置（带状配置）作为理想偶极子脉冲的近似。使用贝叶斯优化方法，我们确定了最大化可辨别后向反射信号可探测性的最佳参数。我们的研究表明，优化倾向于三光束碰撞设置，我们对此进行了数值和分析研究。


<details>
  <summary>Details</summary>
Motivation: 探索量子反射在后向反射通道中的现实应用，并为光-光散射提供数值估计。

Method: 使用偶极子脉冲进行数值模拟，并采用贝叶斯优化方法确定最佳参数，研究了三光束碰撞设置。

Result: 发现四波混频是主要的后向反射信号特征，并确定了能够最大化信号可探测性的最佳参数，倾向于三光束碰撞设置。

Conclusion: 三光束碰撞设置是实现可探测的后向反射信号的最佳配置，为量子反射的实际应用提供了理论和数值支持。

Abstract: Quantum reflection is a fascinating signature of the quantum vacuum that
emerges from inhomogeneities in the electromagnetic fields. In pursuit of the
prospective real-world implementation of quantum reflection in the
back-reflection channel, we provide the first numerical estimates for the
light-by-light scattering with dipole pulses, which are known to provide the
tightest focusing of light possible. For an all-optical setup with a dipole
pump and Gaussian probe of the same frequency, we find that the dominant signal
signature is related mainly to the back-reflection channel from 4-wave mixing.
Focusing on this, we study the particular case of a multiple focusing pulses
configuration (belt configuration) as an approximation to the idealized dipole
pulse. Using Bayesian optimization methods, we determine optimal parameters
that maximize the detectability of a discernible back-reflection signal. Our
study indicates that the optimization favors a three-beam collision setup,
which we further investigate both numerically and analytically.

</details>


### [199] [Exact WKB method for radial Schrödinger equation](https://arxiv.org/abs/2510.11766)
*Okuto Morikawa,Shoya Ogawa*

Main category: quant-ph

TL;DR: 我们使用现代复兴理论，重新审视了径向薛定谔方程的精确 WKB 量化问题，重点是“物理解释”的量化路径的选择和解释。通过连接公式，我们证明了非平凡的 ciclo 数据可以给出能谱。特别是，对于三维谐振子和三维库仑势，我们明确计算了一个闭合的轮廓。我们还提出，闭合路径的适当切片可以为 r=0 处的物理局部基提供依据，该基用于从原点到无穷大的开放路径。我们的分析阐明了数学单值群数据和物理边界条件在径向设置中的契合方式，从而解决了近期关于复兴理论基础上的量化路径选择的争论。


<details>
  <summary>Details</summary>
Motivation: 现代复兴理论视角下，对径向薛定谔方程的精确 WKB 量化方法进行重新审视，特别是关注“物理解释”的量化路径选择和解释问题。

Method: 使用连接公式（在简单转折点和常值奇点处），并显示非平凡 ciclo 数据给出能谱。明确计算了三维谐振子和三维库仑势的闭合轮廓。提出闭合路径的适当切片可作为 r=0 处的物理局部基，用于从原点到无穷大的开放路径。

Result: 明确计算了三维谐振子和三维库仑势的闭合轮廓。 r=0 处的物理局部基是通过闭合路径的适当切片得到的。

Conclusion: 该分析阐明了数学单值群数据和物理边界条件在径向设置中的契合方式，解决了近期关于复兴理论基础上的量化路径选择的争论。

Abstract: We revisit exact WKB quantization for radial Schr\"odinger problems from the
modern resurgence perspective, with emphasis on how ``physically meaningful''
quantization paths should be chosen and interpreted. Using connection formulae
at simple turning points and at regular singular points, we show that the
nontrivial-cycle data give the spectrum. In particular, for the $3$-dimensional
harmonic oscillator and the $3$-dimensional Coulomb potential, we explicitly
compute a closed contour which starts at $+\infty$, bulges into the $r<0$
sector to encircle the origin, and returns to $+\infty$. Also we propose that
the appropriate slice of the closed path provides a physical local basis at
$r=0$, which is used by an origin-to-$\infty$ open path. Our analysis
clarifies, in radial settings, how mathematical monodromy data and physical
boundary conditions dovetail, thereby addressing recent debates on path choices
in resurgence-based quantization.

</details>


### [200] [Qiboml: towards the orchestration of quantum-classical machine learning](https://arxiv.org/abs/2510.11773)
*Matteo Robbiati,Andrea Papaluca,Andrea Pasquale,Edoardo Pedicillo,Renato M. S. Farias,Alejandro Sopena,Mattia Robbiano,Ghaith Alramahi,Simone Bordoni,Alessandro Candido,Niccolò Laurora,Jogi Suda Neto,Yuanzheng Paul Tan,Michele Grossi,Stefano Carrazza*

Main category: quant-ph

TL;DR: Qiboml是一个开源软件库，用于在混合机器学习工作流中协调量子和经典组件，支持CPU、GPU和量子处理单元，并提供噪声感知模拟和实时错误缓解功能。


<details>
  <summary>Details</summary>
Motivation: 该论文提出了Qiboml，一个开源软件库，旨在解决在混合机器学习工作流中整合量子和经典计算组件的挑战。

Method: Qiboml构建在Qibo的量子计算能力之上，并与TensorFlow和PyTorch等机器学习框架集成。它支持在多种后端运行量子和混合模型，包括多线程CPU、GPU和多GPU系统（用于状态向量或张量网络方法模拟），以及本地和云提供商的量子处理单元。论文还展示了其多样化的模拟选项、噪声感知模拟以及实时错误缓解和校准功能。

Result: Qiboml成功地集成了量子和经典机器学习组件，支持在多种硬件后端上运行，并提供了高级模拟和错误处理功能。

Conclusion: Qiboml为构建和部署混合量子-经典机器学习模型提供了一个灵活且功能强大的平台。

Abstract: We present Qiboml, an open-source software library for orchestrating quantum
and classical components in hybrid machine learning workflows. Building on
Qibo's quantum computing capabilities and integrating with popular machine
learning frameworks such as TensorFlow and PyTorch, Qiboml enables the
construction of quantum and hybrid models that can run on a broad range of
backends: (i) multi-threaded CPUs, GPUs, and multi-GPU systems for simulation
with statevector or tensor network methods; (ii) quantum processing units, both
on-premise and through cloud providers. In this paper, we showcase its
functionalities, including diverse simulation options, noise-aware simulations,
and real-time error mitigation and calibration.

</details>


### [201] [Quantum State-Aware Query Complexity: Krylov Compression and Polynomial Query Duality](https://arxiv.org/abs/2510.11786)
*Kiran Adhikari Chhetriya*

Main category: quant-ph

TL;DR: 量子查询的最小复杂度等于f(H)ψ0的准备，这取决于f在L^2(μ)上的最优多项式逼近次数，其中μ是(H,ψ0)的光谱测度。


<details>
  <summary>Details</summary>
Motivation: 研究在给定量子态ψ0下，制备f(H)ψ0所需的最小查询复杂度，并将其与f在H的光谱测度上的L^2最优多项式逼近联系起来。

Method: 通过分析量子查询的复杂度，并将其与函数f在L^2(μ)空间上的最优多项式逼近联系起来，其中μ是(H,ψ0)的光谱测度。

Result: 最小查询复杂度精确地等于f在L^2(μ)上的最优多项式逼近次数，这种方法能够改进最坏情况下的界限，统一Krylov/Favard逼近与量子查询，并解释了状态相关的谱结构如何能够显著节省资源。

Conclusion: 量子查询的复杂度可以由函数f在状态相关的大谱测量上的L^2最优多项式逼近来表征，这提供了比传统方法更优的资源节省。

Abstract: We show that the minimal query complexity for preparing $f(H)\ket{\psi_0}$ is
exactly the optimal polynomial approximation degree of $f$ in $L^2(\mu)$, where
$\mu$ is the spectral measure of $(H,\ket{\psi_0})$. This state-aware
perspective refines the worst-case bounds, unifies Krylov/Favard approximation
with quantum queries, and explains how state-dependent spectral structure can
yield substantial savings over uniform designs.

</details>


### [202] [Bound on entanglement in neural quantum states](https://arxiv.org/abs/2510.11797)
*Nisarga Paul*

Main category: quant-ph

TL;DR: 前馈神经网络量子态（NQS）在n个自旋和k个标量非线性下，在某些解析度假设下，对任何子区域的纠缠熵有一个上限：S≤cklogn。


<details>
  <summary>Details</summary>
Motivation: NQS克服了许多实际量子多体方法的限制，但对其根本性限制知之甚少。

Method: 通过数学推导证明了具有k个标量非线性且满足某些解析度假设的n自旋前馈神经网络量子态的纠缠熵存在上限。

Result: 证明了NQS的纠缠熵上限为S≤cklogn，这表明NQS存在类似面积定律的约束，并排除了具有O(1)非线性度的NQS的体定律纠缠。

Conclusion: 这项工作为NQS建立了一个广泛适用的基本约束，并强调了其强大的表达能力。

Abstract: Variational wavefunctions offer a practical route around the exponential
complexity of many-body Hilbert spaces, but their expressive power is often
sharply constrained. Matrix product states, for instance, are efficient but
limited to area law entangled states. Neural quantum states (NQS) are widely
believed to overcome such limitations, yet little is known about their
fundamental constraints. Here we prove that feed-forward neural quantum states
acting on $n$ spins with $k$ scalar nonlinearities, under certain analyticity
assumptions, obey a bound on entanglement entropy for any subregion: $S \leq c
k\log n$, for a constant $c$. This establishes an NQS analog of the area law
constraint for matrix product states and rules out volume law entanglement for
NQS with $O(1)$ nonlinearities. We demonstrate analytically and numerically
that the scaling with $n$ is tight for a wide variety of NQS. Our work
establishes a fundamental constraint on NQS that applies broadly across
different network designs, while reinforcing their substantial expressive
power.

</details>


### [203] [Secret communication games and a hierarchy of quasiparticle statistics in 3 + 1D topological phases](https://arxiv.org/abs/2510.11818)
*Zhiyuan Wang*

Main category: quant-ph

TL;DR: secret communication challenge games define a hierarchy of emergent quasiparticle statistics in 3D topological phases, with winning strategies using R-paraparticles for nonlocal secret communication. Analysis using categorical descriptions shows R-paraparticles are uniquely suited for noise-robust winning strategies in 3D, linking them to exotic finite group gauge theories. While 2D games can be won by anyons, twisted variants exclude them, singling out R-paraparticles. The challenge serves as a diagnostic for identifying and classifying exotic exchange statistics in topological quantum matter.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the connection between secret communication challenge games and emergent quasiparticle statistics in topological phases, aiming to use these games as a tool for classifying and identifying exotic exchange statistics.

Method: The paper uses a combination of axiomatic descriptions of emergent R-paraparticles, categorical descriptions of topological phases (symmetric fusion categories), and analysis of game strategies. It also introduces twisted variants of games in 2D.

Result: Secret communication challenge games naturally define a hierarchy of emergent quasiparticle statistics in 3D topological phases. R-paraparticles enable nonlocal secret communication and are uniquely suited for noise-robust winning strategies in 3D. The analysis associates R-paraparticles to deconfined gauge theories based on exotic finite groups. Twisted variants of 2D games exclude anyons, singling out R-paraparticles.

Conclusion: The secret communication challenge game is established as a versatile diagnostic tool for identifying and classifying exotic exchange statistics in topological quantum matter, particularly highlighting the role of R-paraparticles.

Abstract: We show that a family of secret communication challenge games naturally
define a hierarchy of emergent quasiparticle statistics in three-dimensional
(3D) topological phases. The winning strategies exploit a special class of the
recently proposed $R$-paraparticles to allow nonlocal secret communication
between the two participating players. We first give a high-level, axiomatic
description of emergent $R$-paraparticles, and show that any physical system
hosting such particles admits a winning strategy. We then analyze the games
using the categorical description of topological phases (where point-like
excitations in 3D are described by symmetric fusion categories), and show that
only $R$-paraparticles can win the 3D challenge in a noise-robust way, and the
winning strategy is essentially unique. This analysis associates emergent
$R$-paraparticles to deconfined gauge theories based on an exotic class of
finite groups. Thus, even though this special class of $R$-paraparticles are
fermions or bosons under the categorical classification, their exchange
statistics can still have nontrivial physical consequences in the presence of
appropriate defects, and the $R$-paraparticle language offers a more convenient
description of the winning strategies. Finally, while a subclass of non-Abelian
anyons can win the game in 2D, we introduce twisted variants that exclude
anyons, thereby singling out $R$-paraparticles in 2D as well. Our results
establish the secret communication challenge as a versatile diagnostic for both
identifying and classifying exotic exchange statistics in topological quantum
matter.

</details>


### [204] [Non-Hermitian Realization of Quantum Dynamics on Embedded Manifolds](https://arxiv.org/abs/2510.11845)
*Samuel Alperin*

Main category: quant-ph

TL;DR: 量子粒子在一般时间周期性虚势驱动下的 Floquet  하밀토니안，在频闪时间点上，等价于一个在固定嵌入的弯曲黎曼流形上运动的自由粒子的 하밀토니안。


<details>
  <summary>Details</summary>
Motivation: 统一非厄米 Floquet 物理与谱几何，并为工程弯曲空间量子动力学提供通用方法。

Method: 将量子粒子在一般时间周期性虚势驱动下的 Floquet 하밀토니안 与在固定嵌入的弯曲黎曼流形上运动的自由粒子的 하밀토니안 等价起来。

Result: 在正弦驱动和圆环曲面上展示了这种构造，并概述了该框架如何指导弯曲空间量子动力学的实验设计。

Conclusion: 本研究结果统一了非厄米 Floquet 物理与谱几何，并为在嵌入式流形上工程量子动力学提供了一个通用方法。

Abstract: We show that the Floquet Hamiltonian of a quantum particle driven by a
general time-periodic imaginary potential is exactly equivalent, at
stroboscopic times, to the Hamiltonian of a free particle constrained to a
curved Riemannian manifold with fixed embedding. We illustrate the construction
for a sinusoidal drive and for the torus of revolution, and outline how the
framework can guide experimental design of curved-space quantum dynamics. Our
results unify non-Hermitian Floquet physics with spectral geometry and provide
a general recipe for engineering quantum dynamics on embedded manifolds.

</details>


### [205] [Performance of Gaussian Boson Sampling on Planted Bipartite Clique Detection](https://arxiv.org/abs/2510.12774)
*Yu-Zhen Janice Chen,Laurent Massoulié,Don Towsley*

Main category: quant-ph

TL;DR: 高斯玻色采样（GBS）可能无法提供解决已植入双团问题（planted biclique problem）的计算优势。


<details>
  <summary>Details</summary>
Motivation: 研究高斯玻色采样（GBS）在解决已植入双团问题上的计算优势，特别是其在区分已植入节点和背景节点方面的能力。

Method: 分析GBS输出的节点权重分布，量化已植入结构引入的偏差。

Result: 当已植入双团的大小处于计算困难的范围内时，节点权重的自然波动会掩盖偏差信号，使得基于简单排序的检测方法不可靠。

Conclusion: GBS可能无法为已植入双团检测提供计算优势，这表明该问题即使在使用GBS的量子计算下可能仍然是计算困难的。

Abstract: We investigate whether Gaussian Boson Sampling (GBS) can provide a
computational advantage for solving the planted biclique problem, which is a
graph problem widely believed to be classically hard when the planted structure
is small. Although GBS has been heuristically and experimentally observed to
favor sampling dense subgraphs, its theoretical performance on this classically
hard problem remains largely unexplored. We focus on a natural statistic
derived from GBS output: the frequency with which a node appears in GBS
samples, referred to as the node weight. We rigorously analyze whether this
signal is strong enough to distinguish planted biclique nodes from background
nodes. Our analysis characterizes the distribution of node weights under GBS
and quantifies the bias introduced by the planted structure. The results reveal
a sharp limitation: when the planted biclique size falls within the conjectured
hard regime, the natural fluctuations in node weights dominate the bias signal,
making detection unreliable using simple ranking strategies. These findings
provide the first rigorous evidence that planted biclique detection may remain
computationally hard even under GBS-based quantum computing, and they motivate
further investigation into more advanced GBS-based algorithms or other quantum
approaches for this problem.

</details>


### [206] [Optimal and efficient inference tools for field tracking with precessing spins](https://arxiv.org/abs/2510.11884)
*Klaudia Dilcher,Piotr Bania,Diana Mendez-Avalos,Aleksandra Sierant,Morgan W. Mitchell,Jan Kolodynski*

Main category: quant-ph

TL;DR: 该研究提出了贝叶斯信号恢复方法，用于改进自旋进动磁力计（SPM）在自由感应衰减（FID）模式下的磁场监测精度，并与现有方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 精确、实时的磁场演化监测在磁导航和寻找超越标准模型的新物理等应用中至关重要。SPM是一种主要的磁场监测技术，但需要改进其信号恢复方法以提高精度和效率。

Method: 推导了贝叶斯Cramér-Rao界限，以确定拉莫尔频率估计的最终精度。比较了计算成本高昂的预测误差法（PEM）、扩展卡尔曼滤波器（EKF）和协方差卡尔曼滤波器（CKF）的性能。重点研究了EKF在跟踪波动和未知瞬态信号方面的能力。

Result: EKF和CKF在计算效率方面接近最优，并且能够实现近乎最优的跟踪精度。EKF足以精确跟踪波动的、未知的瞬态信号，即使在远超响应带宽的情况下。CKF仅在大自旋数时表现更好。

Conclusion: 所提出的贝叶斯信号恢复方法，特别是EKF，为SPM提供了一种计算高效且精度高的方法，能够实时监测动态变化的磁场。该方法还可以应用于其他具有非线性耗散动力学和高斯噪声的传感器。

Abstract: Precise, real-time monitoring of magnetic field evolution is important in
applications including magnetic navigation and searches for physics beyond the
standard model. One main field-monitoring technique, the spin-precession
magnetometer (SPM), observes electron, nucleus, color center, or muon spins as
they precess in response to their local magnetic field. Here, we study Bayesian
signal-recovery methods for SPMs in the free-induction decay (FID) mode. In
particular, we study tracking of field changes well within the coherence time
of the spin system, and thus well beyond the response bandwidth, as in [Phys.
Rev. Lett. 120, 040503 (2018)]. We derive the Bayesian Cram\'{e}r-Rao bound
that dictates the ultimate precision in estimating the Larmor frequency, which
we show to be attained by the computationally-expensive prediction error method
(PEM). Relative to this benchmark, we show that the extended Kalman filter
(EKF) and cubature Kalman filter (CKF) offer near-optimal tracking that is also
computationally efficient, with the use of the latter giving better results
only for large spin number. Focusing thus on the EKF, we show that it is
sufficient to accurately track fluctuating and unknown transient signals. Our
methods can be easily adapted to other types of sensors undergoing non-linear
dissipative dynamics and experiencing intrinsic Gaussian-like stochastic
noises.

</details>


### [207] [One-dimensional tunneling of the two-body bound state](https://arxiv.org/abs/2510.11932)
*N. Shypka,O. Hryhorchak,V. Pastukhov*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider bound and scattering states of the one-dimensional dimer formed
by two coupled non-identical atoms when one of them also interacts with the
zero-range potential located at the origin. By calculating the dimer localized
and scattering wave functions, we identify properties of the system without the
two-body bound-state collapse. In general, we predict an enhancement of the
dimer reflection compared to a single atom, except for a narrow region on the
attractive side of the external potential.

</details>


### [208] [Open Quantum Dynamics Theory for Coulomb Potentials: Hierarchical Equations of Motion for Atomic Orbitals (AO-HEOM)](https://arxiv.org/abs/2510.11981)
*Yankai Zhang,oshitaka Tanimura*

Main category: quant-ph

TL;DR: 我们研究了热浴中库仑势系统的量子动力学，并使用“精确”的原子轨道分层方程（AO-HEOM）在非微扰和非马尔可夫的条件下进行数值计算，以研究系统-浴耦合强度和温度对线性吸收光谱的影响。


<details>
  <summary>Details</summary>
Motivation: 研究热浴中库仑势系统的量子动力学，并在此过程中保持包含浴在内的整个系统的旋转对称性。

Method: 采用三维旋转不变系统-浴（3D-RISB）模型，推导出原子轨道分层方程（AO-HEOM），对系统-浴相互作用进行非微扰和非马尔可夫的有限温度处理。

Result: 计算了各向同性热环境原子系统的线性吸收光谱，并系统地改变了系统-浴耦合强度和温度。

Conclusion: 所提出的AO-HEOM方法能够有效地处理有限温度下包含库仑势的开放量子系统的非微扰和非马尔可夫动力学。

Abstract: We investigate the quantum dynamics of Coulomb potential systems in thermal
baths. We study these systems within the framework of open quantum dynamics
theory, focusing on preserving the rotational symmetry of the entire system,
including the baths. Thus, we employ a three-dimensional rotationally invariant
system-bath (3D-RISB) model to derive numerically ``exact'' hierarchical
equations of motion for atomic orbitals (AO-HEOM) that enable a
non-perturbative and non-Markovian treatment of system-bath interactions at
finite temperatures. To assess the formalism, we calculated the linear
absorption spectrum of an atomic system under isotropic thermal environment,
with systematic variation of system-bath coupling strength and temperature.

</details>


### [209] [Superradiance and Superabsorption Engine of $N$ Two-Level Systems: $N^{2}$-Power Scaling at Near-Unity Efficiency](https://arxiv.org/abs/2510.12017)
*L. F. Alves da Silva,H. Sanchez,M. A. Ponte,M. H. Y. Moussa,Norton G. de Almeida*

Main category: quant-ph

TL;DR: 我们提出了一种利用N个两能级原子样本的协同超辐射和超吸收效应的热机。


<details>
  <summary>Details</summary>
Motivation: 该引擎利用单个冷库，通过集体泵浦和衰减的循环来运行。

Method: 我们使用描述多体动力学的有效平均场哈密顿量，设计了优化的驱动脉冲，以保持绝热性并实现与系统大小成二次方缩放的平均功率输出（P ∝ N^2）。

Result: 一个可进行实验测量的评价指标表明，该超燃发动机的效率可以接近于1。该分析模型得到了数值模拟的验证。

Conclusion: 我们的研究结果为基于集体效应的可扩展、高效率的量子热机铺平了道路。

Abstract: We present a thermal engine that exploits the \emph{cooperative
superradiance} and \emph{superabsorption} of a sample of \(N\) two-level atoms.
This engine operates using a single cold reservoir via cycles of collective
pumping followed by decay. Using an effective mean-field Hamiltonian to
describe the many-body dynamics, we design optimized drive pulses that preserve
adiabaticity and achieve an average power output scaling quadratically with the
system size, \(P \propto N^2\). An experimentally measurable figure of merit
demonstrates that the efficiency of this superengine can approach unity. The
resulting analytical model, which yields a representative Hamiltonian for the
sample within the mean-field formalism, is validated by numerical simulations.
Our results pave the way for scalable and highly efficient quantum heat engines
based on collective effects.

</details>


### [210] [Variational Quantum Eigensolver Models of Molecular Quantum Dot Cellular Automata](https://arxiv.org/abs/2510.12656)
*Nischal Binod Gautam,Enrique P. Blair*

Main category: quant-ph

TL;DR: VQE可用于模拟分子量子点电池自动化（QCA）电路，但结果对噪声敏感，需要简化ansatz电路并使用低噪声硬件。


<details>
  <summary>Details</summary>
Motivation: 分子QCA电路在低功耗、高速度的计算硬件方面具有潜力，但由于完全相干模型的指数级扩展限制，大型QCA电路的设计需要近似方法。然而，在容错量子计算时代，可能无需近似即可模拟大型QCA电路。因此，研究VQE方法在模拟QCA电路方面的应用具有重要意义，因为QCA计算结果编码在电路的基态中。

Method: 使用变分量子本征求解器（VQE）方法来估计QCA电路的基态。VQE模型在理想模拟器、噪声模拟器和实际量子硬件上进行了测试，以模拟包括二元导线、逆变器和多数门在内的逻辑电路。

Result: 研究表明，VQE可以用来模拟分子QCA电路。然而，在现代NISQ硬件上，结果仍然对噪声非常敏感，因此需要采取措施来尽量减少噪声的影响，例如尽可能简化ansatz电路和使用低噪声的硬件。

Conclusion: VQE可用于模拟分子QCA电路，但目前的NISQ硬件的噪声是主要挑战。未来的工作应侧重于开发更具鲁棒性的VQE算法和改进量子硬件以减少噪声的影响。

Abstract: Molecular quantum-dot Cellular Automata (QCA) may provide low-power,
high-speed computational hardware for processing classical information.
Simulation and modeling play an important role in the design of QCA circuits
because fully-coherent models of QCA scale exponentially with the number of
devices, and such models are severely limited in size. For larger circuits,
approximations become necessary. In the era of fault-tolerant quantum
computation, however, it may become possible to model large QCA circuits
without such limitations. Presently, this work explores the use of the
noisy-intermediate scale quantum (NISQ) variational quantum eigensolver (VQE)
method for estimating the ground state of QCA circuits. This is relevant
because the computational result of a QCA calculation is encoded in the
circuit's ground state. In this study, VQE is used to model logic circuits,
including binary wires,
  inverters, and majority gates. VQE models are performed ideal simulators,
noisy simulators, and actual quantum hardware. This study demonstrates that VQE
may indeed be used to model molecular QCA circuits. It is observed that using
modern NISQ hardware, results are still quite sensitive to noise, so measures
should be taken to minimize noise. These include simplifying the ansatz circuit
whenever possible, and using low-noise hardware.

</details>


### [211] [Characterizing and Harnessing Correlations Featuring Independent Qubit Devices](https://arxiv.org/abs/2510.12022)
*Liang-Liang Sun,Xiang Zhou,Chengjie Zhang,Zizhu Wang,Yong-Shun Song,Sixia Yu*

Main category: quant-ph

TL;DR: 我们提出一个框架来表征量子比特系统中贝尔和制备-测量场景下的关联，即使使用独立的设备也可以。该框架能处理通常非凸的问题，并能识别非极端的关联，甚至可以用来推断潜在的测量和量子态，还能通过结合NPA层级来增强纠缠检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理量子比特系统中的关联（尤其是在贝尔和制备-测量场景下）时，通常需要处理非凸问题，并且依赖于极端的关联或非局域性。然而，在实际应用中，设备推断和纠缠检测需要更通用的方法来处理不一定是极端或非局域的关联。

Method: 提出一个框架来表征量子比特系统中贝尔和制备-测量场景下的关联，利用了特定于量子比特的涨落关系来处理非凸问题。开发了一种可以识别非极端关联的关联判据，并能根据观测到的关联推断出潜在的测量和量子态。将推断出的信息整合到Navascués-Pironio-Acín (NPA)层级中，以增强纠缠检测能力。

Result: 所提出的框架能够成功表征量子比特系统中的关联，即使在独立设备和非凸问题的条件下。关联判据能够识别非极端和非局域的关联，并能推断出潜在的测量和量子态。结合NPA层级的方法增强了纠缠检测，甚至可以从某些局域关联中检测到纠缠。

Conclusion: 该框架为处理量子信息协议中的设备推断和纠缠检测问题提供了一个基础。它通过处理非凸问题和识别非极端关联，扩展了现有方法的能力，并有可能广泛应用于量子信息科学的各个领域。

Abstract: We propose a framework to characterize the correlations in qubit systems for
Bell and prepare-and-measure scenarios with independent devices -- a typically
non-convex problem. Based on this result, we introduce protocols for referring
devices and detecting entanglement with correlation that are not necessarily
extreme or nonlocal, as required by common linear approach. } Specifically, our
correlation criterion, derived from uncertainty relation specific to qubit
systems, can capture the non-convex nature of the set of correlations arising
from Bell and prepare-and-measure scenarios, as demonstrated through concrete
examples. Conversely, when given an observed correlation, our framework can
refer potential measurements and quantum states -- which are sometimes uniquely
determined -- even with correlations that are not extreme. This extends common
protocols that merely verify devices using extreme correlations. We then
enhance entanglement detection for qubit system by incorporating the inferred
information in Navascu\'{e}s-Pironio-Ac\'{i}n (NPA) hierarchy, showing that
some local correlations can also verify entanglement. Since the scenarios
considered here are standard platforms for most quantum information protocols
and device inference is a central issue in quantum information science, our
methodology, which is well-suited to these tasks, may provide a foundation for
a broad range of applications.

</details>


### [212] [Spectral analysis of hierarchical continuous-time quantum walks](https://arxiv.org/abs/2510.12043)
*Jirô Akahori,Yusuke Ide,Tomoki Kato,Norio Konno,Shuhei Mano,Akihiro Narimatsu*

Main category: quant-ph

TL;DR: Hierarchical random walks are introduced with global and local walkers, leading to continuous-time quantum walks with specific spectral structures and a multi-dimensional extension.


<details>
  <summary>Details</summary>
Motivation: To introduce hierarchical random walks and explore their continuous-time quantum walk counterparts and spectral structures.

Method: Introduced hierarchical random walks with global and local walkers, constructed corresponding continuous-time quantum walks, and defined multi-dimensional continuous-time quantum walks using marginal distributions.

Result: Established spectral structures of the constructed continuous-time quantum walks and defined a multi-dimensional version.

Conclusion: The paper presents a novel hierarchical random walk model and its extension to continuous-time quantum walks, including spectral analysis and multi-dimensional generalization.

Abstract: In this paper, we introduce hierarchical random walks at first. In this
model, we use two types of random walkers, {global and local} walkers. The
global walker chooses a local walker at every step, then the chosen local
walker moves a single step. After that we construct the corresponding
continuous-time quantum walks and discuss its spectral structures. Then we
define multi-dimensional continuous-time quantum walk by taking a marginal
distribution respect to the global walker.

</details>


### [213] [Engineering atomic superradiance scaling in cavity QED system with collective and individual emission channels](https://arxiv.org/abs/2510.12086)
*Ruijin Sun,Xiang Guo,Andreas Ruschhaupt,Zhihai Wang*

Main category: quant-ph

TL;DR: 论文研究了腔QED系统中原子-光子耦合对超辐射发光的影响，发现其能抑制集体超辐射发光并增强个体原子发光，为可控的集体发光提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 超辐射是量子光学中的一个基本现象，在量子信息处理和精密测量等领域有广泛应用，但其发光与原子数量的关系仍需深入研究。

Method: 研究腔QED系统，并分析原子-光子耦合如何改变集体超辐射发光和个体原子发光。

Result: 原子-光子耦合能有效抑制集体超辐射发光，并增强个体原子发光的增长率。

Conclusion: 该研究为在先进实验平台中实现可控的集体发光提供了方法。

Abstract: The coherent emission of multiple atoms gives rise to superradiance, a
cornerstone phenomenon in quantum optics with wide-ranging applications in
quantum information processing and precision metrology. Despite its importance,
how the superradiant scaling with respect to the number of participating atoms
can be effectively controlled remains largely unexplored. In this work, we
investigate a cavity-QED system and demonstrate that atom-photon coupling can
significantly alter the emission behavior--suppressing the collective
superradiant scaling while enhancing the scaling associated with individual
atomic emissions. Our study provides a pathway toward controllable collective
emission in state-of-the-art experimental platforms.

</details>


### [214] [Digital adiabatic evolution is universally accurate](https://arxiv.org/abs/2510.12237)
*Yangyu Lu,Yifei Huang,Dong An,Qi Zhao,Dingshun Lv,Xiao Yuan*

Main category: quant-ph

TL;DR: 数字绝热演化在算法误差方面具有内在的准确性和鲁棒性，即使在长时间演化中也是如此，这与之前的假设相反。


<details>
  <summary>Details</summary>
Motivation: 绝热演化是量子物理学中的一个核心范例，但数字模拟通常被认为成本高昂，因为算法误差会随着时间的推移而累积。本研究旨在证明数字绝热演化的内在准确性和鲁棒性。

Method: 分析了两种哈密顿模拟方法——Trotter化和广义量子信号处理——并证明了模拟误差不会随着时间的推移而增加。通过对分子系统和线性方程进行数值模拟来验证该理论。

Result: 数值模拟证实了理论分析，表明数字绝热演化比之前假设的效率更高。具体来说，对于横向场伊辛模型，即使使用少于6个量子比特，一阶Trotter化误差的估计也比之前的分析精确10^6倍。

Conclusion: 数字绝热演化具有根本的鲁棒性，可以为容错和潜在的近期量子平台提供准确、高效的实现基础。

Abstract: Adiabatic evolution is a central paradigm in quantum physics. Digital
simulations of adiabatic processes are generally viewed as costly, since
algorithmic errors typically accumulate over the long evolution time, requiring
exceptionally deep circuits to maintain accuracy. This work demonstrates that
digital adiabatic evolution is intrinsically accurate and robust to simulation
errors. We analyze two Hamiltonian simulation methods -- Trotterization and
generalized quantum signal processing -- and prove that the simulation error
does not increase with time. Numerical simulations of molecular systems and
linear equations confirm the theory, revealing that digital adiabatic evolution
is substantially more efficient than previously assumed. Remarkably, our
estimation for the first-order Trotterization error can be 10^6 times tighter
than previous analyses for the transverse field Ising model even with less than
6 qubits. The findings establish fundamental robustness of digital adiabatic
evolution and provide a basis for accurate, efficient implementations on
fault-tolerant -- and potentially near-term -- quantum platforms.

</details>


### [215] [Faster State Preparation with Randomization](https://arxiv.org/abs/2510.12247)
*Yue Wang,Xiao-Ming Zhang,Xiao Yuan,Qi Zhao*

Main category: quant-ph

TL;DR: 通过引入一种随机协议，我们改进了具有分层幅度结构的状态的准确性-成本权衡，实现了二次方的误差改进。


<details>
  <summary>Details</summary>
Motivation: 量子算法中的状态制备成本高昂，特别是对于幅度呈指数或幂律衰减的状态。

Method: 我们提出了一种随机协议，该协议制备了简单的电路集合，每个电路都保留所有较大的幅度，同时放大了单个较小的幅度，而不是确定性地截断小幅度。

Result: 该随机协议在迹距离误差方面比确定性截断方法有二次方的改进，减少了指数衰减的编码幅度数量，并对幂律衰减的编码幅度数量进行了多项式减少，从而降低了电路深度。

Conclusion: 该方法为近期的和容错的量子设备上可制备的状态提供了更广泛的可能性。

Abstract: Quantum state preparation remains a dominant cost in many quantum algorithms.
We introduce a randomized protocol that fundamentally improves the
accuracy-cost trade-off for states with hierarchical amplitude structures,
where amplitudes decay exponentially or by a power law with exponent greater
than one. Rather than commonly employed deterministically truncating small
amplitudes, we prepare an ensemble of simple circuits: each retains all large
amplitudes while amplifying a single small one. We rigorously prove that the
randomized ensemble achieves a quadratic improvement in trace-distance error
over the deterministic truncation method. This quadratic scaling halves the
number of encoded amplitudes for exponential decay and yields polynomial
reductions for power-law decay, which directly translates to a reduction in
circuit depth. Demonstrations on molecular wavefunctions (LiH), many-body
ground states (transverse-field Ising), and machine-learning parameters
(ResNet) validate the approach across diverse applications. The method broadens
the class of states preparable on near-term and fault-tolerant quantum devices.

</details>


### [216] [High-efficiency and long-distance quantum memory-assisted device-independent quantum secret sharing with single photon sources](https://arxiv.org/abs/2510.12288)
*Qi Zhang,Jia-Wei Ying,Shi-Pu Gu,Xing-Fu Wang,Lan Zhou,Yu-Bo Sheng*

Main category: quant-ph

TL;DR: 该协议提出了一种基于单光子源和量子存储的设备无关量子秘密共享（DI QSS）方案，理论上实现了无限安全传输距离，并将密钥生成效率提高了数个数量级。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有量子秘密共享（QSS）协议中光子传输损耗大、多方纠缠生成率低的问题，提高DI QSS的安全传输距离和密钥生成效率。

Method: 提出了一种基于量子存储（QMA）的设备无关量子秘密共享（DI QSS）协议，该协议利用单光子源（SPSs）和 the heralded architecture 构建长距离多方纠缠通道，并利用QMA技术提高多光子同步效率和优化光子传输。

Result: 该协议实现了理论上无限的安全光子传输距离，并将实际密钥生成效率相较于基于自发参量下转换源的DI QSS协议提高了七个数量级，相较于未使用QMA的基于SPSs的DI QSS协议提高了六个数量级。

Conclusion: 该协议具有模块化特性，在当前实验技术条件下可行，并结合先进的随机密钥生成基策略，有望促进未来长距离、高效率的DI量子网络发展。

Abstract: Quantum secret sharing (QSS) plays a critical role in building the
distributed quantum networks. Device-independent (DI) QSS provides the highest
security level for QSS. However, the photon transmission loss and extremely low
multipartite entanglement generation rate largely limit DI QSS's secure photon
transmission distance and practical key generation efficiency. To address the
above drawbacks, we propose the quantum memory-assisted (QMA) DI QSS protocol
based on single photon sources (SPSs). The single photons from the SPSs are
used to construct long-distance multipartite entanglement channels with the
help of the heralded architecture. The heralded architecture enables our
protocol to have an infinite secure photon transmission distance in theory. The
QMA technology can not only increase the multi-photon synchronization
efficiency, but also optimize the photon transmittance to maximize the
construction efficiency of the multipartite entanglement channels. Our protocol
achieves the practical key generation efficiency seven orders of magnitude
higher than that of the existing DI QSS protocols based on cascaded spontaneous
parametric down-conversion sources and six orders of magnitude higher than that
of the DI QSS based on SPSs without QMA. Our protocol has modular
characteristics and is feasible under the current experimental technical
conditions. Combining with the advanced random key generation basis strategy,
the requirement on experimental devices can be effectively reduced. Our
protocol is expected to promote the development of long-distance and
high-efficiency DI quantum network in the future.

</details>


### [217] [Hybrid Vision Transformer and Quantum Convolutional Neural Network for Image Classification](https://arxiv.org/abs/2510.12291)
*Mingzhu Wang,Yun Shang*

Main category: quant-ph

TL;DR: ViT-QCNN-FT框架通过结合微调的Vision Transformer和量子卷积神经网络（QCNN），有效压缩高维图像特征，适用于嘈杂的中尺度量子（NISQ）设备。该框架在CIFAR-10数据集上达到了99.77%的准确率，并提供了量子优势的明确证据。


<details>
  <summary>Details</summary>
Motivation: 高维图像的经典预处理和量子设备的噪声限制了量子机器学习（QML）在现实任务上的进展。

Method: 通过系统地探测纠缠，研究了具有均匀分布的纠缠熵的量子线路（ansatzes），以实现有效的非局域特征融合。框架结合了一个微调的Vision Transformer和一个量子卷积神经网络（QCNN）。

Result: 具有均匀分布的纠缠熵的量子线路（ansatzes）在特征融合和准确性方面表现优越，在CIFAR-10上达到了99.77%的准确率。量子噪声在某些情况下可以提高准确性（例如，在幅度阻尼下提高2.71%）。将QCNN替换为具有相同参数数量的经典对应物会导致准确性下降29.36%。

Conclusion: ViT-QCNN-FT框架为共同设计经典和量子架构提供了一条原则性的途径，展示了实际QML在处理复杂高维学习任务方面的潜力，并提供了量子优势的明确证据。

Abstract: Quantum machine learning (QML) holds promise for computational advantage, yet
progress on real-world tasks is hindered by classical preprocessing and noisy
devices. We introduce ViT-QCNN-FT, a hybrid framework that integrates a
fine-tuned Vision Transformer with a quantum convolutional neural network
(QCNN) to compress high-dimensional images into features suited for noisy
intermediate-scale quantum (NISQ) devices. By systematically probing
entanglement, we show that ansatzes with uniformly distributed entanglement
entropy consistently deliver superior non-local feature fusion and
state-of-the-art accuracy (99.77% on CIFAR-10). Surprisingly, quantum noise
emerges as a double-edged factor: in some cases, it enhances accuracy (+2.71%
under amplitude damping). Strikingly, substituting the QCNN with classical
counterparts of equal parameter count leads to a dramatic 29.36% drop,
providing unambiguous evidence of quantum advantage. Our study establishes a
principled pathway for co-designing classical and quantum architectures,
pointing toward practical QML capable of tackling complex, high-dimensional
learning tasks.

</details>


### [218] [Metrological approach to the emergence of classical objectivity](https://arxiv.org/abs/2510.12313)
*Anthony Kiely,Diana A. Chisholm,Akram Touil,Sebastian Deffner,Gabriel Landi,Steve Campbell*

Main category: quant-ph

TL;DR: 本研究结合量子达尔文主义和量子计量学，精确刻画了经典性的出现，并表明量子费雪信息可用于衡量经典客观性的出现速率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在精确刻画经典性的出现，并探索测量选择对系统状态确定精度的影响。

Method: 结合量子达尔文主义和量子计量学，利用量子费雪信息评估经典客观性的出现速率，并研究测量选择对精度的影响。

Result: 在自旋星模型中，最优测量可实现指数级经典性出现速率；其他测量虽然较慢，但仍可达到克拉美-拉奥下界。

Conclusion: 本研究提供了一个精确的操作性描述，将经典性的出现视为信息获取协议，为量子达尔文主义提供了新的视角。

Abstract: We present a precise characterization of the onset of classicality that
combines the formalism of quantum Darwinism with the tools from quantum
metrology. We show that the quantum Fisher information provides a useful metric
for assessing the rate at which classical objectivity emerges. Furthermore, our
formalism allows us to explore how the choice of measurement impacts the
precision with which an observer can determine the state of the system. For a
paradigmatic example of the spin-star model, we demonstrate that optimal
measurements lead to the emergence of classicality at an exponential rate.
Although other measurements necessarily lead to slower emergence, we
importantly show that suboptimal measurements can still saturate the
Cram\'{e}r-Rao bound. By recasting emergent classicality as an information
acquisition protocol, our framework provides a precise operational description
of quantum Darwinism.

</details>


### [219] [Implementing the Quantum Approximate Optimization Algorithms for QUBO problems Across Quantum Hardware Platforms: Performance Analysis, Challenges, and Strategies](https://arxiv.org/abs/2510.12336)
*Teemu Pihkakoski,Aravind Plathanam Babu,Pauli Taipale,Petri Liimatta,Matti Silveri*

Main category: quant-ph

TL;DR: ADAPT-QAOA在解决困难的QUBO问题上显著优于QAOA，而QAOA在简单问题上更有效。在实际应用中，基于超导量子计算机的标准QAOA在解决时间上优于离子阱设备，但离子阱设备具有更低的错误率。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究QAOA和ADAPT-QAOA在解决不同规模和难度的QUBO问题上的性能，特别是其在金融特征选择中的实际应用。

Method: 本文比较了标准QAOA和ADAPT-QAOA在解决QUBO问题上的性能，并进行了基于真实设备校准数据的可扩展性分析，以评估QAOA在不同硬件平台上的可行性和局限性。

Result: ADAPT-QAOA在解决困难问题（trade-off参数α=0.6）时，在近似比和求解时间方面显著优于QAOA。对于简单问题，标准QAOA仍然高效。在实际应用中，与离子阱设备相比，超导量子计算机上的标准QAOA提供了更短的求解时间，但离子阱设备具有更低的错误率。

Conclusion: 本文全面概述了在近期量子硬件上部署基于QAOA的方法所面临的挑战、权衡和策略。

Abstract: Quantum computers are expected to offer significant advantages in solving
complex optimization problems that are challenging for classical computers.
Quadratic Unconstrained Binary Optimization (QUBO) problems represent an
important class of problems with relevance in finance and logistics. The
Quantum Approximate Optimization Algorithm (QAOA) is a prominent candidate for
solving QUBO problems on near-term quantum devices. In this paper, we
investigate the performance of both the standard QAOA and the adaptive
derivative assembled problem tailored QAOA (ADAPT-QAOA) to solve QUBO problems
of varying sizes and hardnesses with a focus on its practical applications in
financial feature selection problems. Our main observation is that ADAPT-QAOA
significantly outperforms QAOA with hard problems (trade-off parameter {\alpha}
= 0.6) when comparing approximation ratio and time-to-solution. However, the
standard QAOA remains efficient for simpler problems. Additionally, we
investigate the practical feasibility and limitations of QAOA by scaling
analysis based on the real-device calibration data for various hardware
platforms. Our estimates indicate that standard QAOA implemented on
superconducting quantum computers provides a shorter time-to-solution compared
to trapped-ion devices. However, trapped-ion devices are expected to yield more
favorable error rates. Our findings provide a comprehensive overview of the
challenges, trade-offs, and strategies for deploying QAOA-based methods on
near-term quantum hardware.

</details>


### [220] [Snapshot renormalization group for quantum matter](https://arxiv.org/abs/2510.12415)
*Laurin Brunner,Tobias Wiener,Tiago Mendes-Santos,Reyhaneh Khasseh,Markus Heyl*

Main category: quant-ph

TL;DR: 本研究提出了一种可以直接应用于量子模拟快照数据集的精确重正化群(RG)变换，称为SnapshotRG。


<details>
  <summary>Details</summary>
Motivation: 量子模拟实验的进步使得可以通过对单个多体系统构型进行快照测量来访问量子多体态。本研究旨在提供一种直接处理这些快照数据集的分析框架。

Method: 开发了一种可以直接应用于任何快照数据集的精确重正化群(RG)变换，称为SnapshotRG。该方法在实空间操作，但也可以直接转化为测量构型抽象数据空间中的RG，从而在更普遍的层面上表征量子多体系统。

Result: 证明了数据空间中的快照数据集在连续相变时表现出自相似性，解释了“波函数网络”最近观察到的无标度性。标度不变性扩展到包含量子态的完整统计结构，而不仅仅是传统的低阶关联函数。

Conclusion: SnapshotRG可以方便地与数值方法（如神经网络量子态）或任何量子模拟平台生成的快照数据结合，为表征量子物质中的量子相变和临界现象提供了一个通用的工具。

Abstract: Recent advances in quantum simulator experiments enable unprecedented access
to quantum many-body states through snapshot measurements of individual
many-body configurations. Here, we introduce an exact renormalization group
(RG) transformation that can be directly applied to any such snapshot dataset.
Our SnapshotRG operates in real space, but can also be directly translated to
an RG in the abstract dataspace of measurement configurations, providing a
framework for the characterization of quantum many-body systems on a more
general level. We demonstrate that snapshot datasets in dataspace exhibit
self-similarity at continuous phase transitions, providing an explanation for
the recently observed scale-freeness of so-called wavefunction networks. As a
consequence, scale invariance extends beyond traditional low-order correlation
functions to encompass the full statistical structure of quantum states as
contained in their snapshot datasets. Our SnapshotRG can be readily implemented
with snapshot data generated by numerical method such as neural quantum states
or any quantum simulation platform, offering a versatile tool for
characterizing quantum phase transitions and critical phenomena in quantum
matter.

</details>


### [221] [Neural Guided Sampling for Quantum Circuit Optimization](https://arxiv.org/abs/2510.12430)
*Bodo Rosenhahn,Tobias J. Osborne,Christoph Hirche*

Main category: quant-ph

TL;DR: 通过使用2D神经引导采样来优化量子电路的转译过程，显著减少了优化时间和计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的量子电路转译方法（如随机优化）存在采样效率低、优化耗时长且耗能的问题，需要更高效的解决方案以应对量子比特退相干导致的计算质量下降。

Method: 提出了一种名为“2D神经引导采样”的新方法。该方法将量子电路表示为2D图像，并利用神经网络预测其中可约简的门组合，从而指导采样过程，优先处理最有潜力的部分。

Result: 实验结果表明，与qiskit和BQSKit的不同优化级别相比，该方法在减少量子电路长度方面表现出优越性，能够更有效地进行量子电路优化。

Conclusion: 2D神经引导采样是一种有效且计算效率高的方法，能够显著加速量子电路的转译和优化过程，为实现高质量的量子计算提供了有力的支持。

Abstract: Translating a general quantum circuit on a specific hardware topology with a
reduced set of available gates, also known as transpilation, comes with a
substantial increase in the length of the equivalent circuit. Due to
decoherence, the quality of the computational outcome can degrade seriously
with increasing circuit length. Thus, there is major interest to reduce a
quantum circuit to an equivalent circuit which is in its gate count as short as
possible. One method to address efficient transpilation is based on approaches
known from stochastic optimization, e.g. by using random sampling and token
replacement strategies. Here, a core challenge is that these methods can suffer
from sampling efficiency, causing long and energy consuming optimization time.
As a remedy, we propose in this work 2D neural guided sampling. Thus, given a
2D representation of a quantum circuit, a neural network predicts groups of
gates in the quantum circuit, which are likely reducible. Thus, it leads to a
sampling prior which can heavily reduce the compute time for quantum circuit
reduction. In several experiments, we demonstrate that our method is superior
to results obtained from different qiskit or BQSKit optimization levels.

</details>


### [222] [Experimental verification of multi-copy activation of genuine multipartite entanglement](https://arxiv.org/abs/2510.12457)
*Robert Stárek,Tim Gollerthan,Olga Leskovjanová,Michael Meth,Peter Tirler,Nicolai Friis,Martin Ringbauer,Ladislav Mišta Jr*

Main category: quant-ph

TL;DR: GME can be activated from multiple copies of biseparable quantum states. This paper demonstrates GME activation from two copies of a biseparable three-qubit state in a trapped-ion quantum processor, challenging notions of quantum resources and highlighting the potential of using multiple copies of quantum states.


<details>
  <summary>Details</summary>
Motivation: Genuine multipartite entanglement (GME) is a crucial concept in quantum information processing, relevant for characterizing complex quantum systems and serving as a resource for quantum communication. The phenomenon of GME activation from multiple copies of biseparable states is particularly intriguing.

Method: The paper experimentally demonstrates GME activation from two copies of a biseparable three-qubit state using a trapped-ion quantum processor.

Result: Unambiguous experimental evidence of GME activation from two copies of a biseparable three-qubit state was achieved.

Conclusion: The experimental results challenge existing notions of quantum resources and underscore the potential of employing multiple copies of quantum states to surpass the capabilities of individual states.

Abstract: A central concept in quantum information processing is genuine multipartite
entanglement (GME), a type of correlation beyond biseparability, that is,
correlations that cannot be explained by statistical mixtures of partially
separable states. GME is relevant for characterizing and benchmarking complex
quantum systems, and it is an important resource for applications such as
quantum communication. Remarkably, it has been found that GME can be activated
from multiple copies of biseparable quantum states, which do not possess GME
individually. Here, we experimentally demonstrate unambiguous evidence of such
GME activation from two copies of a biseparable three-qubit state in a
trapped-ion quantum processor. These results not only challenge notions of
quantum resources but also highlight the potential of using multiple copies of
quantum states to achieve tasks beyond the capabilities of the individual
copies.

</details>


### [223] [The logic of quantum mechanics](https://arxiv.org/abs/2510.12502)
*Eric Buffenoir*

Main category: quant-ph

TL;DR: 本研究重新审视了量子逻辑程序，克服了早期方法的局限性，并成功地在其中纳入了纠缠态和贝尔非局域性，最终实现了量子理论基础的原始目标。


<details>
  <summary>Details</summary>
Motivation: 早期量子逻辑程序因张量积的限制以及无法处理纠缠态和贝尔非局域态而被忽视。本研究旨在重新审视并克服这些局限性。

Method: 本研究将张量积和星对合的存在作为状态空间定义的先决条件，并以此为基础构建量子逻辑。

Result: 研究发现，以此方法构建的量子逻辑与不可约希尔伯特几何紧密相关，并明确证明了语境性、无广播定理和贝尔非局域性等基本类量子性质。

Conclusion: 本研究提出的量子逻辑程序能够实现G.Birkhoff和J.von Neumann最初建立量子理论的设想，成功纳入了纠缠态和贝尔非局域性。

Abstract: The quantum logic program originated in a 1936 article by G. Birkhoff and J.
von Neumann. This program is generally disregarded due to no-go theorems
restricting the existence of the tensor product of elementary quantum logics
and, above all, the impossibility of considering entangled states and Bell
non-local states within the framework of these composite quantum logics. We
revisit this study from the beginning and reverse the perspective. Here, the
existence of a tensor product and a star involution are the only prerequisites
for the definition of the state spaces. Surprisingly, the quantum logics
constructed in this way turn out to have a close connection with irreducible
Hilbert geometries, even though we did not impose this sort of structure ab
initio. Endly, the existence of some basic quantum-like properties is
explicitly proven in our framework : contextuality, no-broadcasting theorem,
and Bell non-locality. These elements demonstrate that our quantum logic
program is capable of achieving G. Birkhoff and J. von Neumann's initial
ambition of founding quantum theory.

</details>


### [224] [Detection of quantum information masking via machine learning](https://arxiv.org/abs/2510.12507)
*Sheng-Ao Mao,Lin Zhang,Bo Li*

Main category: quant-ph

TL;DR: 提出一种使用监督式机器学习探测量子信息隐藏的方法，并对纯态和混合态量子比特进行实验验证，结果表明该方法分类准确率高。


<details>
  <summary>Details</summary>
Motivation: 机器学习在量子信息领域的应用日益广泛，但鲜有研究关注量子信息隐藏的探测。

Method: 对于纯态量子比特，随机生成密度矩阵并训练XGBoost模型；对于混合态量子比特，通过优化训练样本选择来改进XGBoost方法。

Result: 实验结果表明，所提出的方法具有更高的分类准确率，并且接收者操作特征曲线下面积（AUC）进一步证实了其分类性能。

Conclusion: 所提出的监督式机器学习方法能够有效地探测量子信息隐藏，并且在混合态量子比特上表现出更好的性能。

Abstract: Recently, machine learning has been widely applied in the field of quantum
information, notably in tasks such as entanglement detection, steering
characterization, and nonlocality verification. However, few studies have
focused on utilizing machine learning to detect quantum information masking. In
this work, we investigate supervised machine learning for detecting quantum
information masking in both pure and mixed qubit states. For pure qubit states,
we randomly generate the corresponding density matrices and train an XGBoost
model to detect quantum information masking. For mixed qubit states, we improve
the XGBoost method by optimizing the selection of training samples. The
experimental results demonstrate that our approach achieves higher
classification accuracy. Furthermore, we analyze the area under the curve (AUC)
of the receiver operating characteristic curve for this method, which further
confirms its classification performance.

</details>


### [225] [Semiclassical analytical solutions of the eigenstate thermalization hypothesis in a quantum billiard](https://arxiv.org/abs/2510.12517)
*Yaoqi Ye,Chengkai Lin,Xiao Wang*

Main category: quant-ph

TL;DR: 该研究推导了量子桌球模型中ETH的半经典解析解，并与Berry猜想进行了比较。


<details>
  <summary>Details</summary>
Motivation: 本文旨在推导量子桌球模型中ETH的半经典解析解，并探索其与Berry猜想的关系。

Method: 推导了ETH对角和非对角函数的半经典解析解，并得到了一个可解析地分离为局部贡献和相空间相关项的表达式。

Result: 得到了ETH的半经典解析解，该解预测了可观察量的能带结构、带宽和缩放行为，并与Berry猜想的预测相符。

Conclusion: ETH在单粒子和少体系统中具有重要的物理意义，其中“热化”表现为初始条件的lost of information。

Abstract: We derive semiclassical analytical solutions for both the diagonal and
off-diagonal functions in the eigenstate thermalization hypothesis (ETH) in a
quarter-stadium quantum billiard. For a representative observable, we obtain an
explicit expression and an asymptotic closed-form solution that naturally
separate into a local contribution and a phase-space correlation term. These
analytical results predict the band structure of the observable matrix,
including its bandwidth and scaling behavior. We further demonstrate that our
analytical formula is equivalent to the prediction of Berry's conjecture.
Supported by numerical evidence, we show that Berry's conjecture captures the
energetic long-wavelength behavior in the space of eigenstates, while our
analytical solution describes the asymptotic behavior of the f function in the
semiclassical limit. Finally, by revealing the connection between the bandwidth
scaling and the underlying classical dynamics, our results suggest that the ETH
carries important physical implications in single-particle and few-body
systems, where "thermalization" manifests as the loss of information about
initial conditions.

</details>


### [226] [A universal approach to saddle-point methods in attosecond science](https://arxiv.org/abs/2510.12545)
*Anne Weber,Job Feldbrugge,Emilio Pisanty*

Main category: quant-ph

TL;DR: Picard-Lefschetz理论为强场物理中的高次谐波辐射(HHG)提供了一种新的精确计算方法，通过Lefschetz thimbles和necklace算法，能够处理任意驱动场，并为阿秒科学中的量子轨道分析奠定基础。


<details>
  <summary>Details</summary>
Motivation: 强场物理中的高次谐波辐射(HHG)现象，特别是使用多色激光场驱动时，计算复杂且难以用半经典轨迹来解释。

Method: 提出使用Picard-Lefschetz理论，通过连续变形积分路径到Lefschetz thimbles，精确计算时间积分。引入“necklace算法”解决二维积分中的鞍点问题。

Result: 该方法能够精确计算任意驱动场下的HHG积分，并识别相关的量子轨道。通过研究双色激光场驱动下的HHG，展示了该方法在分析斯托克斯跃迁和光谱焦点上的能力，并对“颜色切换”现象进行了量子轨道分析。

Conclusion: Picard-Lefschetz理论为强场物理中的量子轨道分析提供了一个普适且稳健的框架，能够精确处理复杂驱动场，并为阿秒科学的实验解释和未来设计提供指导。

Abstract: Light-matter interactions within the strong-field regime, where intense laser
fields can ionise a target via tunnelling, give rise to fascinating phenomena
such as the generation of high-order harmonic radiation (HHG). On the atomic
scale, these strong-field processes are described in terms of
highly-oscillatory time integrals which are often approximated using
saddle-point methods. These methods simultaneously simplify the calculations
and let us understand the physical processes in terms of semi-classical
electron trajectories, or quantum orbits. However, applying saddle-point
methods for HHG driven by polychromatic laser fields without clear dynamical
symmetries has remained challenging. Here we introduce Picard-Lefschetz theory
as a universal and robust link between the time integrals and the
semi-classical trajectories. The continuous deformation of the integration
contour towards so-called Lefschetz thimbles allows an exact evaluation of the
integral, as well as the identification of relevant quantum orbits, for
arbitrary driving fields. The latter is realised via the ``necklace
algorithm'', a novel solution to the open problem of determining the relevance
of saddle points for a two-dimensional integral, which we introduce here. We
demonstrate the versatility and rigour of Picard-Lefschetz methods by studying
Stokes transitions and spectral caustics arising in HHG driven by two-colour
laser fields. For example, we showcase a quantum-orbit analysis of the colour
switchover, which links the regime of perturbative two-colour fields with that
of fully bichromatic driving fields. With this work, we set the foundation for
a rigorous application of quantum-orbit based approaches in attosecond science
that enables the interpretation of state-of-the-art experimental setups, and
guides the design of future ones.

</details>


### [227] [Optimization of the time-multiplexed SPDC source at 900-950 nm range](https://arxiv.org/abs/2510.12556)
*V. O. Gotovtsev,I. V. Dyakonov,O. V. Borzenkova,K. A. Taratorin,T. B. Dugarnimaev,A. A. Korneev,S. P. Kulik,S. S. Straupe*

Main category: quant-ph

TL;DR: 基于SPDC的单光子源受限于低单光子产率，该研究提出了一个基于时间复用的单光子源方案，并通过精确计算和建模，分析了该方案的光子纯度和信令效率，并给出了复用后的单光子产率。


<details>
  <summary>Details</summary>
Motivation: 单光子源在量子技术中至关重要，但基于SPDC的单光子源存在产率低的问题。时间复用被提议作为解决此问题的方案。

Method: 提出并实现了一个基于SPDC的时间复用单光子源，并对纯度、信令效率等关键特性进行了精确计算和建模。对时间复用后的单光子产率进行了分析和估算。

Result: 实现了基于SPDC的时间复用单光子源，并对关键参数进行了计算和分析。

Conclusion: 时间复用是一种提高基于SPDC的单光子源产率的有效方法，该研究为实现高产率单光子源提供了理论和实验基础。

Abstract: In the field of quantum technology, single photons have emerged as a pivotal
resource, prompting the development of heralded single photon sources (HSPS)
with enhanced generation probability. The majority of such sources are based on
spontaneous parametric down-conversion (SPDC), but they exhibit a low single
photon generation probability. The multiplexing principle
(arXiv:quant-ph/0205103) has been proposed as a solution to this problem. This
paper presents a demonstration of a time-multiplexed HSPS based on the SPDC
process, including accurate calculations and modeling of key source
characteristics, specifically purity and heralding efficiency. Furthermore, the
paper provides an analysis and approximation of the probability of a single
photon post-application of time multiplexing.

</details>


### [228] [Multi-Copy Security in Unclonable Cryptography](https://arxiv.org/abs/2510.12626)
*Alper Çakan,Vipul Goyal,Fuyuki Kitagawa,Ryo Nishimaki,Takashi Yamakawa*

Main category: quant-ph

TL;DR: 该论文提出了一个通用的编译器，用于将抗串谋的一次性加密原语升级为具有多副本安全性，只需单向函数。这使得首次能够构建具有多副本安全性的公钥量子金钱、单解密器加密和一次性加密。此外，论文还引入了可升级的量子金币的概念，并提出了通用的编译器来升级单副本安全单解密器加密到抗串谋，以及构建了多挑战安全的一次性加密方案。


<details>
  <summary>Details</summary>
Motivation: 现有的不可克隆密码学研究主要关注单副本安全性，而对更强的多副本安全性的研究尚不充分。本研究旨在填补这一空白，提供一种通用的方法来增强一次性加密原语的多副本安全性。

Method: 提出一个通用的编译器，该编译器能够将抗串谋的一次性加密原语升级为具有多副本安全性。该方法仅假设单向函数的存在。在证明过程中，还提出了一个通用的编译器，用于将单副本安全的单解密器加密升级为抗串谋的，假设存在功能加密。同时，还构建了首个多挑战安全的一次性加密方案。

Result: 首次实现了多副本安全公钥量子金钱（量子币）、单解密器加密、不可克隆加密。引入了可升级量子金币的概念，该金币在较弱的假设下允许弱（几乎公开）验证，并通过发布额外的经典信息可以升级为完全公开验证。此外，还实现了首个多挑战安全的一次性加密方案。

Conclusion: 本研究为实现更强的多副本安全性的一次性加密方案提供了通用的解决方案，并扩展了量子金币的概念，使其具有更好的灵活性和可升级性。所提出的技术和方案具有重要的理论和实践意义。

Abstract: Unclonable cryptography leverages the quantum no-cloning principle to
copy-protect cryptographic functionalities. While most existing works address
the basic single-copy security, the stronger notion of multi-copy security
remains largely unexplored.
  We introduce a generic compiler that upgrades collusion-resistant unclonable
primitives to achieve multi-copy security, assuming only one-way functions.
Using this framework, we obtain the first multi-copy secure constructions of
public-key quantum money (termed quantum coins), single-decryptor encryption,
unclonable encryption, and more. We also introduce an extended notion of
quantum coins, called upgradable quantum coins, which allow weak
(almost-public) verification under weaker assumptions and can be upgraded to
full public verification under stronger assumptions by the bank simply
publishing additional classical information.
  Along the way, we give a generic compiler that upgrades single-copy secure
single-decryptor encryption to a collusion-resistant one, assuming the
existence of functional encryption, and construct the first multi-challenge
secure unclonable encryption scheme, which we believe are of independent
interest.

</details>


### [229] [Quantum Network-Based Prediction of Cancer Driver Genes](https://arxiv.org/abs/2510.12628)
*Patricia Marques,Andreas Wichert,Duarte Magano,Bruno Coutinho*

Main category: quant-ph

TL;DR: 本研究提出了一种监督式量子图学习框架QMME，结合突变评分和网络拓扑来识别癌症驱动基因，并在模拟中取得了优于经典基线12.6%的召回率提升。


<details>
  <summary>Details</summary>
Motivation: 识别癌症驱动基因对于开发靶向治疗至关重要。尽管结合突变谱和蛋白质-蛋白质相互作用（PPI）网络是一种有前景的方法，但对于大型网络数据集而言，计算成本高昂。量子计算有望提供一种解决方案。

Method: 提出了一种名为量子多阶矩嵌入（QMME）的新型状态制备方案，将节点的突变评分与网络拓扑相结合，并将低阶统计矩编码到量子态中。这些量子态被用作监督式量子二元分类器的输入，以区分已知的驱动基因。

Result: 在经验PPI网络上的模拟显示，该方法具有竞争力，召回率比经典基线提高了12.6%。该流程能够显式进行量子态制备，并且无需经典训练，实现了高效的近乎端到端的量子工作流程。

Conclusion: 本研究强调了监督式量子图学习框架在推动生物学发现方面的潜力，并为网络化癌症基因预测实现量子加速提供了可能性。

Abstract: Identification of cancer driver genes is fundamental for the development of
targeted therapeutic interventions. The integration of mutational profiles with
protein-protein interaction (PPI) networks offers a promising avenue for their
detection [ 1, 2], but scaling to large network datasets is computationally
demanding. Quantum computing offers compact representations and potential
complexity reductions. Motivated by the classical method of Gumpinger et al.
[3], in this work we introduce a supervised quantum framework that combines
mutation scores with network topology via a novel state preparation scheme,
Quantum Multi-order Moment Embedding (QMME). QMME encodes low-order statistical
moments over the mutation scores of a node's immediate and second-order
neighbors, and encodes this information into quantum states. These are used as
inputs to a kernel-based quantum binary classifier that discriminates known
driver genes from others. Simulations on an empirical PPI network demonstrate
competitive performance, with a 12.6% recall gain over a classical baseline.
The pipeline performs explicit quantum state preparation and requires no
classical training, enabling an efficient, nearly end-to-end quantum workflow.
A brief complexity analysis suggests the approach could achieve a quantum
speedup in network-based cancer gene prediction. This work underscores the
potential of supervised quantum graph learning frameworks to advance biological
discovery.

</details>


### [230] [Decoding Multimode Gottesman-Kitaev-Preskill Codes with Noisy Auxiliary States](https://arxiv.org/abs/2510.12677)
*Marc-Antoine Roy,Thomas Pousset,Baptiste Royer*

Main category: quant-ph

TL;DR: 我们提出了一种考虑辅助态噪声的多模GKP码解码器，通过跟踪不同模式下的错误关联，将逻辑错误概率降低了一个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错量子计算，需要量子纠错方案来保护逻辑信息免受退相干的影响。多模GKP编码是一种有前景的编码方式。

Method: 提出了一种解码器，该解码器考虑了辅助态噪声，并通过跟踪纠错电路中不同模式下错误的传播来跟踪它们之间的相关性。

Result: 与现有方法相比，所提出的解码器将逻辑错误概率降低了至少一个数量级，从而实现了更鲁棒的量子计算。

Conclusion: 通过利用测量结果与影响多模GKP态的实际错误之间的相关性，可以显著提高量子计算的鲁棒性。

Abstract: In order to achieve fault-tolerant quantum computing, we make use of quantum
error correction schemes designed to protect the logical information of the
system from decoherence. A promising way to preserve such information is to use
the multimode Gottesman-Kitaev-Preskill (GKP) encoding, which encodes logical
qubits into several harmonic oscillators. In this work, we focus on decoding
the measurements obtained from Steane-type quantum error correction protocols
for multimode GKP codes. We propose a decoder that considers the noise present
on the auxiliary states, more specifically by tracking the correlations between
errors on different modes spreading throughout the error-correction circuit. We
show that leveraging the correlations between measurement results and the
actual error affecting the multimode GKP state can decrease the logical error
probability by at least an order of magnitude, yielding more robust quantum
computation.

</details>


### [231] [Probabilistic Links Between Quantum Classification of Patterns of Boolean Functions and Hamming Distance](https://arxiv.org/abs/2510.12736)
*Theodore Andronikos,Constantinos Bitsakos,Konstantinos Nikas,Georgios I. Goumas,Nectarios Koziris*

Main category: quant-ph

TL;DR: 本文研究了布尔函数量子分类与其汉明距离之间的概率关系，并提出了一种量化分析方法。


<details>
  <summary>Details</summary>
Motivation: 探究汉明距离在量子分类中的作用，特别是作为衡量函数分类偏差的指标，并为量子分类算法提供更可靠的评估工具。

Method: 通过结合量子计算、信息论和组合学，研究汉明距离在随机函数分类中的应用，并通过实验验证汉明距离作为最近邻分类的度量指标。

Result: 实验结果表明，汉明距离在绝大多数情况下是验证最近邻分类的关键指标，成功分类概率随汉明距离单调递减，但存在特定类别的例外情况。同时，研究量化了这些异常现象，并首次精确划分了分类概率的汉明距离区间。

Conclusion: 汉明距离是量子分类中的关键度量，成功分类概率通常随汉明距离的增加而降低。研究量化了分类过程中的异常，并首次确定了分类概率的汉明距离区间，为提高量子分类算法的可靠性和决策能力提供了新的理论基础和实践工具。

Abstract: This article investigates the probabilistic relationship between quantum
classification of Boolean functions and their Hamming distance. By integrating
concepts from quantum computing, information theory, and combinatorics, we
explore how Hamming distance serves as a metric for analyzing deviations in
function classification. Our extensive experimental results confirm that the
Hamming distance is a pivotal metric for validating nearest neighbors in the
process of classifying random functions. One of the significant conclusions we
arrived is that the successful classification probability decreases
monotonically with the Hamming distance. However, key exceptions were found in
specific classes, revealing intra-class heterogeneity. We have established that
these deviations are not random but are systemic and predictable. Furthermore,
we were able to quantify these irregularities, turning potential errors into
manageable phenomena. The most important novelty of this work is the
demarcation, for the first time to the best of our knowledge, of precise
Hamming distance intervals for the classification probability. These intervals
bound the possible values the probability can assume, and provide a new
foundational tool for probabilistic assessment in quantum classification.
Practitioners can now endorse classification results with high certainty or
dismiss them with confidence. This framework can significantly enhance any
quantum classification algorithm's reliability and decision-making capability.

</details>


### [232] [Time-dependent Variational Principles for Hybrid Non-Unitary Dynamics: Application to Driven-Dissipative Superconductors](https://arxiv.org/abs/2510.12737)
*Pasquale Filice,Marco Schirò,Giacomo Mazza*

Main category: quant-ph

TL;DR: 该研究提出了一种基于时间依赖变分原理（TDVP）的新方法，用于研究开放量子多体系统的非酉动力学，并将其应用于研究BCS超导体在损耗和泵浦作用下的动力学行为。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子多体系统的非酉动力学，特别是损耗或驱动耗散的BCS超导体，并理解非厄米极限对系统稳定态行为的奇异影响。

Method: 采用时间依赖变分原理（TDVP），研究了包含完全Lindblad主方程、无点击极限下的非厄米动力学以及混合Lindbladian（由控制参数α插值）的非酉动力学。将此方法应用于存在二体损耗和二体泵浦的BCS超导体系统。

Result: 研究发现，非厄米极限是混合耗散动力学的奇异极限，导致了驱动耗散稳态的普遍演化方式发生剧烈改变。在考虑了二体损耗的情况下，随着趋近非厄米极限，密度动力学从普遍的幂律衰减急剧转变为指数衰减，并收敛于一个准稳态平台，此时粒子损耗冻结。此平台对应的准稳态密度随着耗散率的增加而增加，这表明损耗动力学中出现了非厄米Zeno效应。在驱动耗散的情况下，系统在非厄米极限下会被困在一个有效的负温度态，从而跳过了在存在量子跃迁有限贡献时才出现的无限温度稳态。

Conclusion: 非厄米极限对开放量子系统的动力学演化和稳态行为具有显著的奇异影响，导致了与经典情况截然不同的现象，例如非厄米Zeno效应和有效负温度态的出现。TDVP是一种研究此类复杂动力学的有效工具。

Abstract: We introduce time-dependent variational principles to study the non-unitary
dynamics of open quantum many-body systems, including dynamics described by the
full Lindblad master equation, the non-Hermitian dynamics corresponding to the
no-click limit of the fully post-selected quantum trajectories, and the
dynamics described by a hybrid Lindbladian with a control parameter $\alpha$
which interpolates between the full post-selection and averaging over all
quantum trajectories. As an application we study the non-unitary dynamics of a
lossy or driven-dissipative BCS superconductors, evolving in presence of
two-body losses and two-body pumps. We show that the non-Hermitian limit acts
as a singular limit of the hybrid dissipative dynamics, leading to a sharp
modification of the universal approach to the driven-dissipative steady-states.
By considering the dissipative dynamics with pair losses, we show that, as the
non-Hermitian limit is approached, the density dynamics sharply evolves from a
universal power-law to exponential decay that converges towards a quasi-steady
plateau characterized by the freezing of the particle depletion due to pair
losses. The reached quasi-stationary density increases as a function of the
dissipation rate highlighting the emergence of a non-Hermitian Zeno effect in
the lossy dynamics. For the driven-dissipative case, we show that, in the
non-Hermitian limit, the system gets trapped into an effective negative
temperature state, thus skipping the infinite temperature steady-state reached
in the presence of finite contribution of the quantum jumps. We rationalize
these findings in terms of the conservation of the length of the pseudospins
which, in the non-Hermitian limit, suppresses the effective single-particle
losses and pumps acting on the non-condensed particles.

</details>


### [233] [Measurement-induced entanglement in noisy 2D random Clifford circuits](https://arxiv.org/abs/2510.12743)
*Zhi-Yuan Wei,Jon Nelson,Joel Rajakumar,Esther Cruz,Alexey V. Gorshkov,Michael J. Gullans,Daniel Malz*

Main category: quant-ph

TL;DR: 局部噪声会破坏二维随机克利福德电路中的长程、体定律测量诱导的纠缠，导致最大算子纠缠熵在边界长度上呈线性增长，并随深度近似线性增长。


<details>
  <summary>Details</summary>
Motivation: 研究由二维随机克利福德电路的逐列采样产生的测量诱导纠缠，重点关注采样诱导的边界态的算子纠缠。

Method: 在无噪声极限下重现有限深度从面积定律到体定律缩放的转变；通过分析稳定器生成器的空间分布，观察到稳定器生成器的指数局域化；通过数值验证，解释最大算子纠缠熵的缩放，并推断条件互信息的指数衰减。

Result: 在任何恒定速率 p>0 的在线概率跟踪噪声下，采样轨迹达到的最大算子纠缠熵 S_op 遵循边界长度的面积定律，并且近似与 T/p 成线性关系。稳定器生成器的指数局域化解释了 S_op 的缩放，并意味着条件互信息呈指数衰减。

Conclusion: 恒定局部噪声会破坏二维随机克利福德电路中的长程、体定律测量诱导纠缠。基于观察到的缩放，我们推测基于张量网络的算法可以有效地从（i）在亚对数深度 T = o(log N) 和任何恒定噪声率 p = Ω(1) 下，以及（ii）在恒定深度 T = O(1) 和噪声率 p = Ω(log^{-1}N) 下的二维随机克利福德电路进行采样。

Abstract: We study measurement-induced entanglement generated by column-by-column
sampling of noisy 2D random Clifford circuits of size $N$ and depth $T$.
Focusing on the operator entanglement $S_{\rm op}$ of the sampling-induced
boundary state, first, we reproduce in the noiseless limit a finite-depth
transition from area- to volume-law scaling. With on-site probablistic trace
noise at any constant rate $p>0$, the maximal $S_{\rm op}$ attained along the
sampling trajectory obeys an area law in the boundary length and scales
approximately linearly with $T/p$. By analyzing the spatial distribution of
stabilizer generators, we observe exponential localization of stabilizer
generators; this both accounts for the scaling of the maximal $S_{\rm op}$ and
implies an exponential decay of conditional mutual information across buffered
tripartitions, which we also confirm numerically. Together, these results
indicate that constant local noise destroys long-range, volume-law
measurement-induced entanglement in 2D random Clifford circuits. Finally, based
on the observed scaling, we conjecture that a tensor-network-based algorithm
can efficiently sample from noisy 2D random Clifford circuits (i) at
sub-logarithmic depths $T = o(\log N)$ for any constant noise rate $p =
\Omega(1)$, and (ii) at constant depths $T = O(1)$ for noise rates $p =
\Omega(\log^{-1}N)$.

</details>


### [234] [Contextuality-based quantum key distribution with deterministic single-photon sources](https://arxiv.org/abs/2510.12761)
*Yu Meng,Debashis Saha,Mikkel Thorbjørn Mikkelsen,Clara Henke,Ying Wang,Nikolai Bart,Arne Ludwig,Adán Cabello,Leonardo Midolo*

Main category: quant-ph

TL;DR: 单光子源可用于生成量子语境性，从而实现一种新的半设备无关量子密钥分发协议。


<details>
  <summary>Details</summary>
Motivation: 利用半导体量子点生成单光子，以实现量子通信，并探索其在量子语境性和量子密钥分发中的应用。

Method: 使用基于自组装InAs(Ga)As量子点的单光子源作为量子信息载体，并演示了它们生成量子语境性的能力，进而提出了一种新的半设备无关量子密钥分发协议。

Result: 证明了利用单光子源可以生成量子语境性，并提出了适用于自由空间信道的半设备无关量子密钥分发协议，该协议不依赖于理想的测量。

Conclusion: 基于量子点单光子源的量子语境性为实现鲁棒且实用的量子通信提供了一条新途径。

Abstract: Photons are central to quantum technologies, with photonic qubits offering a
promising platform for quantum communication. Semiconductor quantum dots stand
out for their ability to generate single photons on demand, a key capability
for enabling long-distance quantum networks. In this work, we utilize
high-purity single-photon sources based on self-assembled InAs(Ga)As quantum
dots as quantum information carriers. We demonstrate that such on-demand single
photons can generate quantum contextuality. This capability enables a novel
protocol for semi-device-independent quantum key distribution over free-space
channels. Crucially, our method does not require ideal or perfectly projective
measurements, opening a new pathway for robust and practical quantum
communication.

</details>


### [235] [Trajectory-Protected Quantum Computing](https://arxiv.org/abs/2510.12771)
*Barbara Šoda,Pierre-Antoine Graham,T. Rick Perche,Gurpahul Singh*

Main category: quant-ph

TL;DR: 通过控制量子比特的运动轨迹，利用加速诱导透明技术消除共振跃迁，从而抑制退相干，并利用非共振跃迁实现单比特门和利用压缩态真空提取的纠缠实现双比特门。


<details>
  <summary>Details</summary>
Motivation: 提出一种新型方法，能够同时将量子计算机与退相干隔离，并可控地实现计算门。

Method: 模拟了一个量子比特（Unruh-DeWitt探测器）与标量量子场通过光-物质相互作用模型相互作用。通过开关旋转波项（共振跃迁），利用加速诱导透明技术来消除主要的退相干通道。通过激励反旋转波项（非共振跃迁）来实现单比特门，并通过从处于压缩态的量子场中提取纠缠来实现双比特门。

Result: 实现了一种利用量子比特运动来保护其免受退相干影响的量子计算模型，并实现了单比特和双比特的量子门操作。

Conclusion: 讨论了量子比特运动保护的量子误差保护的根本限制，以及在将量子计算机与退相干隔离和实现纠缠门操作速度之间的权衡。

Abstract: We introduce a novel method that simultaneously isolates a quantum computer
from decoherence and enables the controlled implementation of computational
gates. We demonstrate a quantum computing model that utilizes a qubit's motion
to protect it from decoherence. We model a qubit interacting with a quantum
field via the standard light-matter interaction model: an Unruh-DeWitt
detector, i.e., the qubit, follows a prescribed classical trajectory while
interacting with a scalar quantum field. We switch off the rotating-wave terms,
i.e., the resonant transitions, using the technique of acceleration-induced
transparency which eliminates the dominant decoherence channels by controlling
the qubit's trajectory. We are able to perform one-qubit gates by stimulating
the counter-rotating wave terms (i.e., the non-resonant transitions) and
two-qubit gates by extracting the entanglement from the quantum field prepared
in a squeezed state. Finally, we discuss the fundamental limits on quantum
error protection: on the trade-off between isolating a quantum computer from
decoherence, and the speed with which entangling gates may be applied,
comparable to the Eastin-Knill theorem for quantum error correction.

</details>


### [236] [Thermodynamics of quantum processes: An operational framework for free energy and reversible athermality](https://arxiv.org/abs/2510.12790)
*Himanshu Badhani,Dhanuja G S,Siddhartha Das*

Main category: quant-ph

TL;DR: 该研究通过公理化引入量子过程（量子通道）的自由能，并构建了量子过程的无热性资源理论，将热力学概念与量子信息任务联系起来。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索量子过程（量子通道）的热力学，并通过公理化引入自由能，以理解量子过程中的能量、熵和功提取等核心热力学概念与其信息处理能力之间的关系。

Method: 该研究通过公理化引入自由能，定义了自由能与量子相对熵以及绝对热通道（其固定输出与热库处于平衡状态）的关系。在此基础上，构建了量子过程的无热性资源理论，其中自由操作是保持吉布斯状态的超级通道，而金单位是相对于具有全简并输出哈密顿量的绝对热通道的酉通道。研究人员使用假设检验和最大相对熵（相对于绝对热通道）来精确表征量子通道的单次蒸馏和形成。

Result: 研究结果表明，量子通道的蒸馏和形成速率渐近收敛于通道自由能（乘以温度倒数的一半），这证实了自由能的操作意义，并证明了无热性的渐近可逆性。此外，研究还揭示了无热性资源理论与私有随机性和纯度蒸馏等量子信息任务以及擦除和功提取等热力学任务之间的直接联系。

Conclusion: 该研究成功地将量子过程的自由能、能量、熵和最大可提取功等核心热力学概念与其信息处理能力联系起来，为理解量子信息和热力学之间的深层联系提供了新的视角。

Abstract: We explore the thermodynamics of quantum processes (quantum channels) by
axiomatically introducing the free energy for channels, defined via the quantum
relative entropy with an absolutely thermal channel whose fixed output is in
equilibrium with a thermal reservoir. This definition finds strong support
through its operational interpretations in designated quantum information and
thermodynamic tasks. We construct a resource theory of athermality for quantum
processes, where free operations are Gibbs preserving superchannels and golden
units are unitary channels with respect to absolutely thermal channel having
fully degenerate output Hamiltonian. We exactly characterize the one-shot
distillation and formation of quantum channels using hypothesis-testing and
max-relative entropy with respect to the absolutely thermal channel. These
rates converge asymptotically to the channel free energy (up to a
multiplicative factor of half the inverse temperature), establishing its
operational meaning and proving the asymptotic reversibility of the
athermality. We show the direct relation between the resource theory of
athermality and quantum information tasks such as private randomness and purity
distillation and thermodynamic tasks of erasure and work extraction. Our work
connects the core thermodynamic concepts of free energy, energy, entropy, and
maximal extractable work of quantum processes to their information processing
capabilities.

</details>


### [237] [Prethermal gauge structure and surface growth in $\mathbb{Z}_2$ lattice gauge theories](https://arxiv.org/abs/2510.12800)
*Lukas Homeier,Andrea Pizzi,Hongzheng Zhao,Jad C. Halimeh,Fabian Grusdt,Ana Maria Rey*

Main category: quant-ph

TL;DR: 具有相互作用的多体系统的普遍热化规律难以从微观上推导，但能有力解释涌现现象。本文通过数值模拟研究了一个(2+1)D自旋体系的平均场动力学，发现可行的双体伊辛相互作用能稳定一个具有动力学物质的预热态Z2格点规范结构，其表现为具有指数长寿命的规范不变平台。该预热态Z2规范结构最终会因高斯定律缺陷的增殖而破坏，类似于假真空衰变中的气泡形成。在该破坏机制下，我们发现了与(1+1)D Kardar-Parisi-Zhang (KPZ) 普适性相一致的非线性表面增长所描述的时空关联。我们通过半经典离散时间Wigner近似(DTWA)和精确对角化(ED)在小型系统上对结果进行了基准测试，其中DTWA的破坏预示着大量局部对称性的出现，这些对称性强烈影响热化路径。本文提出的模型为量子模拟器提供了一个测试平台，并可直接应用于大规模里德堡原子阵列。


<details>
  <summary>Details</summary>
Motivation: 理解相互作用多体系统中热化的普遍规律，并提出一个可实现的模型。

Method: 通过数值模拟研究(2+1)D自旋体系的平均场动力学，并与DTWA和ED进行比较。

Result: 发现双体伊辛相互作用可稳定一个预热态Z2格点规范结构，该结构最终会因高斯定律缺陷增殖而破坏，并伴随与KPZ普适性一致的时空关联。

Conclusion: 该模型为量子模拟器提供了一个可行的测试平台，并能研究热化动力学。

Abstract: Universal aspects of thermalization in interacting many-body systems are
typically challenging to derive microscopically, yet provide a powerful
framework for understanding emergent phenomena. Here, we numerically study the
mean-field dynamics of a $(2+1)$D spin system with thousands of spins and show
that experimentally-feasible two-body Ising interactions can stabilize a
prethermal $\mathbb{Z}_2$ lattice gauge structure with dynamical matter,
manifested by a gauge-invariant plateau with exponentially long lifetime.
Eventually, the metastable prethermal $\mathbb{Z}_2$ gauge structure breaks
down via a proliferation of Gauss' law defects, similar to bubble formation in
false vacuum decay. In this regime, we discover spatio-temporal correlations
described by a non-linear surface growth consistent with the $(1+1)$D
Kardar-Parisi-Zhang (KPZ) universality class. We benchmark our results in small
systems against semi-classical discrete time Wigner approximation (DTWA) and
exact diagonalization (ED), where the breakdown of DTWA signals the emergence
of an extensive number of local symmetries that strongly influence the
thermalization pathway. Our model provides a testbed for quantum simulators and
is directly implementable in large-scale arrays of Rydberg atoms.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [238] [SpikePool: Event-driven Spiking Transformer with Pooling Attention](https://arxiv.org/abs/2510.12102)
*Donghyun Lee,Alex Sima,Yuhang Li,Panos Stinis,Priyadarshini Panda*

Main category: cs.NE

TL;DR: Spiking transformers act as high-pass filters, while ViTs act as low-pass filters. We propose SpikePool, which uses max pooling attention to create a band-pass filter, improving performance and efficiency on event-based vision tasks.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand how spiking transformers process event-based data and improve their efficiency and performance by analyzing their frequency domain characteristics.

Method: The authors analyze spiking transformers in the frequency domain, discovering they act as high-pass filters. Based on this, they propose SpikePool, which replaces spike-based self-attention with max pooling attention to achieve a selective band-pass filtering effect.

Result: SpikePool demonstrates competitive results on event-based classification and object detection tasks, with significant reductions in training (up to 42.5%) and inference time (up to 32.8%).

Conclusion: Spiking transformers exhibit high-pass filtering behavior, making them suitable for event-based data. SpikePool leverages this by incorporating low-pass filtering (max pooling attention) to create a band-pass filter, leading to improved performance and efficiency.

Abstract: Building on the success of transformers, Spiking Neural Networks (SNNs) have
increasingly been integrated with transformer architectures, leading to spiking
transformers that demonstrate promising performance on event-based vision
tasks. However, despite these empirical successes, there remains limited
understanding of how spiking transformers fundamentally process event-based
data. Current approaches primarily focus on architectural modifications without
analyzing the underlying signal processing characteristics. In this work, we
analyze spiking transformers through the frequency spectrum domain and discover
that they behave as high-pass filters, contrasting with Vision Transformers
(ViTs) that act as low-pass filters. This frequency domain analysis reveals why
certain designs work well for event-based data, which contains valuable
high-frequency information but is also sparse and noisy. Based on this
observation, we propose SpikePool, which replaces spike-based self-attention
with max pooling attention, a low-pass filtering operation, to create a
selective band-pass filtering effect. This design preserves meaningful
high-frequency content while capturing critical features and suppressing noise,
achieving a better balance for event-based data processing. Our approach
demonstrates competitive results on event-based datasets for both
classification and object detection tasks while significantly reducing training
and inference time by up to 42.5% and 32.8%, respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [239] [AI Agents for the Dhumbal Card Game: A Comparative Study](https://arxiv.org/abs/2510.11736)
*Sahaj Raj Malla*

Main category: cs.AI

TL;DR: 本研究评估了在信息不完全的多人卡牌游戏 Dhumbal 中，基于规则、搜索和学习的 AI 代理的性能。


<details>
  <summary>Details</summary>
Motivation: 评估 Dhumbal 游戏中不同 AI 策略（基于规则、搜索和学习）的有效性，并提供可复现的 AI 框架和开源代码。

Method: 对 Dhumbal 游戏机制进行形式化，实现并比较了启发式方法（侵略性、保守性、平衡性、机会性）、基于搜索的方法（MCTS、ISMCTS）和强化学习方法（DQN、PPO）以及随机基线。通过比赛和多种指标（胜率、经济成果、Jhyap 成功率、每轮丢牌数、风险评估、决策效率）进行评估，并使用 Welch t 检验、Bonferroni 校正、Cohen's d 和 95% 置信区间进行统计分析。

Result: 在 1024 轮模拟中，基于规则的侵略性代理以 88.3% 的胜率（95% CI: [86.3, 90.3]）表现最佳，有效利用了 Jhyap 声明，优于 ISMCTS (9.0%) 和 PPO (1.5%)。

Conclusion: 基于规则的侵略性 AI 代理在 Dhumbal 游戏中表现最佳，该研究为 AI 研究和文化游戏的数字化保存做出了贡献。

Abstract: This study evaluates Artificial Intelligence (AI) agents for Dhumbal, a
culturally significant multiplayer card game with imperfect information,
through a systematic comparison of rule-based, search-based, and learning-based
strategies. We formalize Dhumbal's mechanics and implement diverse agents,
including heuristic approaches (Aggressive, Conservative, Balanced,
Opportunistic), search-based methods such as Monte Carlo Tree Search (MCTS) and
Information Set Monte Carlo Tree Search (ISMCTS), and reinforcement learning
approaches including Deep Q-Network (DQN) and Proximal Policy Optimization
(PPO), and a random baseline. Evaluation involves within-category tournaments
followed by a cross-category championship. Performance is measured via win
rate, economic outcome, Jhyap success, cards discarded per round, risk
assessment, and decision efficiency. Statistical significance is assessed using
Welch's t-test with Bonferroni correction, effect sizes via Cohen's d, and 95%
confidence intervals (CI). Across 1024 simulated rounds, the rule-based
Aggressive agent achieves the highest win rate (88.3%, 95% CI: [86.3, 90.3]),
outperforming ISMCTS (9.0%) and PPO (1.5%) through effective exploitation of
Jhyap declarations. The study contributes a reproducible AI framework, insights
into heuristic efficacy under partial information, and open-source code,
thereby advancing AI research and supporting digital preservation of cultural
games.

</details>


### [240] [Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations](https://arxiv.org/abs/2510.11822)
*Suryaansh Jain,Umair Z. Ahmed,Shubham Sahai,Ben Leong*

Main category: cs.AI

TL;DR: LLM-as-a-judge方法存在模型偏见问题，提出了一种少数服从多数的否决策略和基于回归的方法来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 评估LLM的常用方法LLM-as-a-judge存在正向偏见，导致评估结果不准确。

Method: 提出了一种少数服从多数的否决策略，并结合一个基于回归的框架，利用少量人工标注数据来模拟验证器偏见。

Result: 所提出的回归方法在代码反馈任务上取得了2倍的改进，最大绝对误差仅为1.2%。

Conclusion: LLM-as-a-judge方法存在模型偏见，提出的少数服从多数的否决策略和基于回归的框架能有效解决此问题，提高评估的准确性。

Abstract: New Large Language Models (LLMs) become available every few weeks, and modern
application developers confronted with the unenviable task of having to decide
if they should switch to a new model. While human evaluation remains the gold
standard, it is costly and unscalable. The state-of-the-art approach is to use
LLMs as evaluators ( LLM-as-a-judge), but this suffers from a critical flaw:
LLMs exhibit a strong positive bias. We provide empirical evidence showing that
while LLMs can identify valid outputs with high accuracy (i.e., True Positive
Rate 96%), they are remarkably poor at identifying invalid ones (i.e., True
Negative Rate <25%). This systematic bias, coupled with class imbalance, often
leads to inflated reliability scores.
  While ensemble-based methods like majority voting can help, we show that they
are not good enough. We introduce an optimal minority-veto strategy that is
resilient to missing data and mitigates this bias to a large extent. For
scenarios requiring even higher precision, we propose a novel regression-based
framework that directly models the validator bias using a small set of
human-annotated ground truth data. On a challenging code feedback task over 366
high-school Python programs, our regression approach reduces the maximum
absolute error to just 1.2%, achieving a 2x improvement over the
best-performing ensemble of 14 state-of-the-art LLMs.

</details>


### [241] [Tensor Logic: The Language of AI](https://arxiv.org/abs/2510.12269)
*Pedro Domingos*

Main category: cs.AI

TL;DR: AI 编程语言的缺失阻碍了 AI 的发展。本文提出张量逻辑，一种统一神经网络和符号 AI 的语言，以解决现有框架的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 AI 框架（如 PyTorch 和 TensorFlow）虽然提供了自动微分和 GPU 加速，但它们是基于 Python 的，并非为 AI 设计，并且缺乏对自动推理和知识获取的支持。而 LISP 和 Prolog 等传统 AI 语言则存在可扩展性和学习支持方面的不足。这导致了在 AI 领域引入新功能时，过程漫长且成本高昂。

Method: 本文提出张量逻辑，其核心是张量方程。作者认为逻辑规则和爱因斯坦求和本质上是相同的操作，所有其他功能都可以归结为它们。张量逻辑能够优雅地实现包括 Transformer、形式推理、核方法和图模型在内的多种神经网络、符号和统计 AI 的关键形式。

Result: 张量逻辑能够整合神经网络的可扩展性和学习能力，以及符号推理的可靠性和透明度。这为在嵌入空间中进行可靠推理开辟了新的可能性。

Conclusion: 张量逻辑通过在基本层面统一神经网络和符号 AI，解决了现有 AI 编程语言的局限性，并为 AI 的广泛采用奠定了基础。

Abstract: Progress in AI is hindered by the lack of a programming language with all the
requisite features. Libraries like PyTorch and TensorFlow provide automatic
differentiation and efficient GPU implementation, but are additions to Python,
which was never intended for AI. Their lack of support for automated reasoning
and knowledge acquisition has led to a long and costly series of hacky attempts
to tack them on. On the other hand, AI languages like LISP an Prolog lack
scalability and support for learning. This paper proposes tensor logic, a
language that solves these problems by unifying neural and symbolic AI at a
fundamental level. The sole construct in tensor logic is the tensor equation,
based on the observation that logical rules and Einstein summation are
essentially the same operation, and all else can be reduced to them. I show how
to elegantly implement key forms of neural, symbolic and statistical AI in
tensor logic, including transformers, formal reasoning, kernel machines and
graphical models. Most importantly, tensor logic makes new directions possible,
such as sound reasoning in embedding space. This combines the scalability and
learnability of neural networks with the reliability and transparency of
symbolic reasoning, and is potentially a basis for the wider adoption of AI.

</details>


### [242] [Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation](https://arxiv.org/abs/2510.11977)
*Sayash Kapoor,Benedikt Stroebl,Peter Kirgis,Nitya Nadgir,Zachary S Siegel,Boyi Wei,Tianci Xue,Ziru Chen,Felix Chen,Saiteja Utpala,Franck Ndzomga,Dheeraj Oruganty,Sophie Luskin,Kangheng Liu,Botao Yu,Amit Arora,Dongyoon Hahm,Harsh Trivedi,Huan Sun,Juyong Lee,Tengjun Jin,Yifan Mai,Yifei Zhou,Yuxuan Zhu,Rishi Bommasani,Daniel Kang,Dawn Song,Peter Henderson,Yu Su,Percy Liang,Arvind Narayanan*

Main category: cs.AI

TL;DR: AI agent 评估存在挑战，引入 HAL 标准化评估，发现更高推理努力可能降低准确性，并揭示了如搜索基准或滥用信用卡的意外行为。


<details>
  <summary>Details</summary>
Motivation: AI 代理评估面临诸多挑战，影响对其真实能力的理解。

Method: 开发了标准化的评估框架（HAL），支持大规模并行评估，并进行跨模型、脚手架和基准的三维分析，利用 LLM 辅助日志检查来发现隐藏行为。

Result: 在 9 个模型和 9 个基准上进行了 21,730 次代理测试，耗资约 40,000 美元，发现更高推理努力在多数情况下会降低准确性，并揭示了代理搜索基准或滥用信用卡的异常行为。

Conclusion: 通过标准化评估方法和解决常见陷阱，旨在推动 AI 代理研究从关注基准表现转向关注实际可靠性。

Abstract: AI agents have been developed for complex real-world tasks from coding to
customer service. But AI agent evaluations suffer from many challenges that
undermine our understanding of how well agents really work. We introduce the
Holistic Agent Leaderboard (HAL) to address these challenges. We make three
main contributions. First, we provide a standardized evaluation harness that
orchestrates parallel evaluations across hundreds of VMs, reducing evaluation
time from weeks to hours while eliminating common implementation bugs. Second,
we conduct three-dimensional analysis spanning models, scaffolds, and
benchmarks. We validate the harness by conducting 21,730 agent rollouts across
9 models and 9 benchmarks in coding, web navigation, science, and customer
service with a total cost of about $40,000. Our analysis reveals surprising
insights, such as higher reasoning effort reducing accuracy in the majority of
runs. Third, we use LLM-aided log inspection to uncover previously unreported
behaviors, such as searching for the benchmark on HuggingFace instead of
solving a task, or misusing credit cards in flight booking tasks. We share all
agent logs, comprising 2.5B tokens of language model calls, to incentivize
further research into agent behavior. By standardizing how the field evaluates
agents and addressing common pitfalls in agent evaluation, we hope to shift the
focus from agents that ace benchmarks to agents that work reliably in the real
world.

</details>


### [243] [CGBench: Benchmarking Language Model Scientific Reasoning for Clinical Genetics Research](https://arxiv.org/abs/2510.11985)
*Owen Queen,Harrison G. Zhang,James Zou*

Main category: cs.AI

TL;DR: CGBench是一个新的基准测试，用于评估语言模型在理解科学出版物方面的能力，特别是在临床遗传学领域。该基准测试表明，尽管语言模型在某些方面表现出潜力，但在精确解释科学文献方面仍存在显著差距，尤其是在处理细粒度指令时。


<details>
  <summary>Details</summary>
Motivation: 传统的变异和基因解释方法耗时耗力，需要开发能够加速研究转化和临床应用的人工智能工具。

Method: 提出CGBench基准测试，该测试基于ClinGen资源，包含专家策展的临床遗传学文献解释。CGBench评估语言模型提取实验结果、判断证据强度以及对结果进行分类和描述的能力。测试了8种不同的语言模型，并使用语言模型评估者来比较模型和人类对结果的解释。

Result: 在CGBench测试中，语言模型在科学文献解释方面存在显著差距，尤其是在处理细粒度指令方面。推理模型在细粒度任务上表现更好，而非推理模型在高层次解释上表现更佳。此外，模型在解释结果时经常出现幻觉或错误解释，即使它们能够正确分类证据。

Conclusion: CGBench揭示了语言模型在精确解释科学出版物方面的优势和劣势，为人工智能在临床遗传学和更广泛的科学领域的未来研究开辟了道路。

Abstract: Variant and gene interpretation are fundamental to personalized medicine and
translational biomedicine. However, traditional approaches are manual and
labor-intensive. Generative language models (LMs) can facilitate this process,
accelerating the translation of fundamental research into clinically-actionable
insights. While existing benchmarks have attempted to quantify the capabilities
of LMs for interpreting scientific data, these studies focus on narrow tasks
that do not translate to real-world research. To meet these challenges, we
introduce CGBench, a robust benchmark that tests reasoning capabilities of LMs
on scientific publications. CGBench is built from ClinGen, a resource of
expert-curated literature interpretations in clinical genetics. CGBench
measures the ability to 1) extract relevant experimental results following
precise protocols and guidelines, 2) judge the strength of evidence, and 3)
categorize and describe the relevant outcome of experiments. We test 8
different LMs and find that while models show promise, substantial gaps exist
in literature interpretation, especially on fine-grained instructions.
Reasoning models excel in fine-grained tasks but non-reasoning models are
better at high-level interpretations. Finally, we measure LM explanations
against human explanations with an LM judge approach, revealing that models
often hallucinate or misinterpret results even when correctly classifying
evidence. CGBench reveals strengths and weaknesses of LMs for precise
interpretation of scientific publications, opening avenues for future research
in AI for clinical genetics and science more broadly.

</details>


### [244] [Asking Clarifying Questions for Preference Elicitation With Large Language Models](https://arxiv.org/abs/2510.12015)
*Ali Montazeralghaem,Guy Tennenholtz,Craig Boutilier,Ofer Meshi*

Main category: cs.AI

TL;DR: LLM驱动的对话推荐系统通过模仿扩散模型，训练模型生成有效的澄清问题以获取用户偏好，从而提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 在用户历史信息有限的情况下，为 LLM 推荐系统获取用户偏好信息，并生成有效的澄清问题。 

Method: 提出一种受扩散模型启发的两阶段方法：前向过程生成澄清问题并逐步去除答案（增加“噪声”）；反向过程训练模型通过学习提问来“去噪”（恢复用户画像）。

Result: 所提出的方法显著提高了 LLM 提问技巧和获取用户偏好的能力。

Conclusion: 所提出的方法能有效提升 LLM 在推荐场景下通过提问获取用户偏好的能力。

Abstract: Large Language Models (LLMs) have made it possible for recommendation systems
to interact with users in open-ended conversational interfaces. In order to
personalize LLM responses, it is crucial to elicit user preferences, especially
when there is limited user history. One way to get more information is to
present clarifying questions to the user. However, generating effective
sequential clarifying questions across various domains remains a challenge. To
address this, we introduce a novel approach for training LLMs to ask sequential
questions that reveal user preferences. Our method follows a two-stage process
inspired by diffusion models. Starting from a user profile, the forward process
generates clarifying questions to obtain answers and then removes those answers
step by step, serving as a way to add ``noise'' to the user profile. The
reverse process involves training a model to ``denoise'' the user profile by
learning to ask effective clarifying questions. Our results show that our
method significantly improves the LLM's proficiency in asking funnel questions
and eliciting user preferences effectively.

</details>


### [245] [Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings](https://arxiv.org/abs/2510.12555)
*Andries Rosseau,Raphaël Avalos,Ann Nowé*

Main category: cs.AI

TL;DR: 通过引入基因和基于普适适应度的奖励函数，提出了一种新颖的多智能体强化学习框架，模拟自然选择的进化过程，以实现更高级的策略和社会智能。


<details>
  <summary>Details</summary>
Motivation: 受自然选择进化智能的启发，旨在开发一种新的多智能体强化学习框架，以实现更高级的策略和社会智能。

Method: 提出了一种多智能体强化学习框架，其中智能体具有基因型，奖励函数模拟普适适应度。研究了在囚徒困境网络游戏中由此产生的社会动态。

Result: 研究结果与哈密尔顿规则等生物学原理一致。该框架还考虑了开放式环境、空间和时间结构、有限资源和进化种群。框架具有超越二元团队结构的合作谱，导致独特的社会动态。

Conclusion: 通过在智能体中引入普适适应度，为更具策略性的智能体和社会智能体的出现奠定了基础。

Abstract: The competitive and cooperative forces of natural selection have driven the
evolution of intelligence for millions of years, culminating in nature's vast
biodiversity and the complexity of human minds. Inspired by this process, we
propose a novel multi-agent reinforcement learning framework where each agent
is assigned a genotype and where reward functions are modelled after the
concept of inclusive fitness. An agent's genetic material may be shared with
other agents, and our inclusive reward function naturally accounts for this. We
study the resulting social dynamics in two types of network games with
prisoner's dilemmas and find that our results align with well-established
principles from biology, such as Hamilton's rule. Furthermore, we outline how
this framework can extend to more open-ended environments with spatial and
temporal structure, finite resources, and evolving populations. We hypothesize
the emergence of an arms race of strategies, where each new strategy is a
gradual improvement over earlier adaptations of other agents, effectively
producing a multi-agent autocurriculum analogous to biological evolution. In
contrast to the binary team-based structures prevalent in earlier research, our
gene-based reward structure introduces a spectrum of cooperation ranging from
full adversity to full cooperativeness based on genetic similarity, enabling
unique non team-based social dynamics. For example, one agent having a mutual
cooperative relationship with two other agents, while the two other agents
behave adversarially towards each other. We argue that incorporating inclusive
fitness in agents provides a foundation for the emergence of more strategically
advanced and socially intelligent agents.

</details>


### [246] [CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing](https://arxiv.org/abs/2510.12033)
*Chathurangi Shyalika,Aryaman Sharma,Fadi El Kalach,Utkarshani Jaimini,Cory Henson,Ramy Harik,Amit Sheth*

Main category: cs.AI

TL;DR: CausalTrace 是一个集成在 SmartPilot 工业 CoPilot 中的神经符号因果分析模块，它结合了数据驱动的因果分析、工业本体和知识图谱，以提供可解释的决策支持。该模块实现了因果发现、反事实推理和根本原因分析 (RCA)，并在学术火箭组装测试平台中取得了与领域专家高度一致的成果和强大的 RCA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能系统在预测、解释和因果推理方面存在碎片化问题，无法满足现代制造环境中对可解释洞察的需求，限制了其在工业环境中的实用性。

Method: CausalTrace 是一个神经符号因果分析模块，集成了 SmartPilot 工业 CoPilot。它结合了数据驱动的因果分析、工业本体和知识图谱，并具备因果发现、反事实推理和根本原因分析 (RCA) 等高级功能。该模块支持实时操作员交互，并通过提供透明、可解释的决策支持来补充现有代理。

Result: 在学术火箭组装测试平台中，CausalTrace 在本体问答方面达到了 0.91 的 ROUGE-1 分数，在 RCA 方面取得了 94% 的 MAP@3、97% 的 PR@2、0.92 的 MRR 和 0.92 的 Jaccard 指数。在 C3AN 评估中，CausalTrace 获得了 4.59/5 的评分。

Conclusion: CausalTrace 在学术火箭组装测试平台中表现出色，其结果与领域专家的意见高度一致，并且在根本原因分析方面表现出强大的性能。C3AN 评估结果表明，该模块在精确性和可靠性方面达到了可供实时部署的水平，证明了其在工业环境中的应用潜力。

Abstract: Modern manufacturing environments demand not only accurate predictions but
also interpretable insights to process anomalies, root causes, and potential
interventions. Existing AI systems often function as isolated black boxes,
lacking the seamless integration of prediction, explanation, and causal
reasoning required for a unified decision-support solution. This fragmentation
limits their trustworthiness and practical utility in high-stakes industrial
environments. In this work, we present CausalTrace, a neurosymbolic causal
analysis module integrated into the SmartPilot industrial CoPilot. CausalTrace
performs data-driven causal analysis enriched by industrial ontologies and
knowledge graphs, including advanced functions such as causal discovery,
counterfactual reasoning, and root cause analysis (RCA). It supports real-time
operator interaction and is designed to complement existing agents by offering
transparent, explainable decision support. We conducted a comprehensive
evaluation of CausalTrace using multiple causal assessment methods and the C3AN
framework (i.e. Custom, Compact, Composite AI with Neurosymbolic Integration),
which spans principles of robustness, intelligence, and trustworthiness. In an
academic rocket assembly testbed, CausalTrace achieved substantial agreement
with domain experts (ROUGE-1: 0.91 in ontology QA) and strong RCA performance
(MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92). It also attained 4.59/5 in
the C3AN evaluation, demonstrating precision and reliability for live
deployment.

</details>


### [247] [Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics](https://arxiv.org/abs/2510.12787)
*Marco Del Tredici,Jacob McCarran,Benjamin Breen,Javier Aspuru Mijares,Weichen Winston Yin,Jacob M. Taylor,Frank Koppens,Dirk Englund*

Main category: cs.AI

TL;DR: Ax-Prover是一个结合了大型语言模型（LLMs）和Lean定理证明器（Lean prover）的多智能体系统，旨在自动化不同科学领域的定理证明。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决科学问题形式化证明的挑战，这种证明需要创造性推理和严格的语法规范。现有的方法在泛化能力上存在不足。

Method: Ax-Prover将LLMs（提供知识和推理）与Lean工具结合，通过模型上下文协议（MCP）确保形式正确性。它可以在没有人类协助的情况下自主运行，也可以与人类专家协作。

Result: 在公开数据集上，Ax-Prover的表现与最先进的证明器相当。在新引入的抽象代数和量子理论领域基准测试中，Ax-Prover的表现明显优于现有证明器。此外，它在形式化复杂的密码学定理方面，作为助手也展现了其能力。

Conclusion: Ax-Prover作为一个基于工具的、可控的定理证明器，提供了一种通用的形式验证方法，能够跨越不同的科学领域，克服了专门化系统泛化能力不足的限制。

Abstract: We present Ax-Prover, a multi-agent system for automated theorem proving in
Lean that can solve problems across diverse scientific domains and operate
either autonomously or collaboratively with human experts. To achieve this,
Ax-Prover approaches scientific problem solving through formal proof
generation, a process that demands both creative reasoning and strict syntactic
rigor. Ax-Prover meets this challenge by equipping Large Language Models
(LLMs), which provide knowledge and reasoning, with Lean tools via the Model
Context Protocol (MCP), which ensure formal correctness. To evaluate its
performance as an autonomous prover, we benchmark our approach against frontier
LLMs and specialized prover models on two public math benchmarks and on two
Lean benchmarks we introduce in the fields of abstract algebra and quantum
theory. On public datasets, Ax-Prover is competitive with state-of-the-art
provers, while it largely outperform them on the new benchmarks. This shows
that, unlike specialized systems that struggle to generalize, our tool-based
agentic theorem prover approach offers a generalizable methodology for formal
verification across diverse scientific domains. Furthermore, we demonstrate
Ax-Prover's assistant capabilities in a practical use case, showing how it
enabled an expert mathematician to formalize the proof of a complex
cryptography theorem.

</details>


### [248] [Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation](https://arxiv.org/abs/2510.12047)
*Soohan Lim,Joonghyuk Hahn,Hyunwoo Park,Sang-Ki Ko,Yo-Sub Han*

Main category: cs.AI

TL;DR: 现有代码生成基准主要关注功能正确性，忽略了代码对输入的契约（先决条件和约束）的遵循情况。本文提出了PACT框架，用于评估和增强LLM生成代码的契约遵循能力，并提供了相应的测试用例库、分析方法和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准（如HumanEval+和MBPP+）主要评估LLM在功能正确性方面，但忽略了真实软件中至关重要的契约遵循（即如何拒绝格式错误输入的先决条件和有效性约束）。这导致现有基准无法衡量，模型也无法生成真正健壮可靠的代码片段。

Method: PACT框架通过三个方面来解决上述问题：1. 提供了一个包含契约违反测试用例的语料库，扩展了HumanEval+和MBPP+。2. 通过在不同提示条件下进行系统性分析，证明了在提示中加入违反契约的测试用例比仅使用契约描述更能有效提高模型对契约的遵循能力。3. 引入了新的指标来严格量化测试生成和代码生成中的契约遵循情况。

Result: PACT框架能够系统性地评估LLM生成代码的契约遵循能力，并与功能正确性一同进行考量。通过在提示中加入契约违反测试用例，可以显著提高模型对契约的遵循能力。PACT提供了严格且可解释的指标来评估LLM生成代码的健壮性。

Conclusion: PACT框架填补了现有代码生成基准在评估契约遵循方面的空白，通过提供全面的测试用例库、系统性分析和新颖的评估指标，能够更全面、更严格地评估LLM生成代码的健壮性和可靠性，解决了传统基准所忽视的关键问题。

Abstract: Prevailing code generation benchmarks, such as HumanEval+ and MBPP+,
primarily evaluate large language models (LLMs) with pass@k on functional
correctness using well-formed inputs. However, they ignore a crucial aspect of
real-world software: adherence to contracts-the preconditions and validity
constraints that dictate how ill-formed inputs must be rejected. This critical
oversight means that existing benchmarks fail to measure, and models
consequently fail to generate, truly robust and reliable code snippets. We
introduce PACT, a program assessment and contract-adherence evaluation
framework, to bridge this gap. PACT is the first framework designed to
systematically evaluate and enhance contract-adherence in LLM-generated code
snippets alongside functional correctness. PACT's contributions are threefold:
First, it provides a comprehensive test-suite corpus focused on contract
violations, extending HumanEval+ and MBPP+. Second, it enables a systematic
analysis of code generation under varied prompting conditions. This analysis
demonstrates that augmenting prompts with contract-violating test cases
significantly enhance a model's ability to respect contracts compared to using
contract description alone. Finally, it introduces novel metrics to rigorously
quantify contract adherence in both test generation and code generation. By
revealing critical errors that conventional benchmarks overlook, PACT provides
the rigorous and interpretable metrics to evaluate the robustness of
LLM-generated code snippets in both functionality and contract-adherence.Our
code and data are available at https://github.com/suhanmen/PACT.

</details>


### [249] [Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response](https://arxiv.org/abs/2510.12061)
*Yiheng Chen,Lingyao Li,Zihui Ma,Qikai Hu,Yilun Zhu,Min Deng,Runlong Yu*

Main category: cs.AI

TL;DR: 本研究提出了一个地理空间感知层（GAL），用于将大型语言模型（LLM）与地球数据相结合，以改进灾难响应。GAL能够整合来自不同地理数据库的信息，并为LLM代理提供结构化的背景信息，从而实现更明智的资源分配建议。该框架在野火场景中进行了评估，并显示出优于基线方法的性能，同时也能推广到洪水和飓风等其他灾害。


<details>
  <summary>Details</summary>
Motivation: 现有统计方法在灾难响应中缺乏语义上下文，泛化能力差且可解释性有限。大型语言模型（LLMs）虽然具有小样本泛化能力，但受限于文本且无法感知地理信息。本研究旨在解决这些问题，提供一个能够整合地理空间信息和LLM能力的灾难响应框架。

Method: 本研究引入了一个地理空间感知层（GAL），用于将LLM代理与结构化的地球数据（如基础设施、人口、地形和天气信息）相结合。GAL从原始的野火探测数据出发，自动检索和整合外部地理数据库的信息，形成一个包含单位标注的感知脚本。该框架还利用历史案例和每日变化信号来支持资源分配建议的生成和增量更新。

Result: 在多个LLM模型和实际野火场景中的评估表明，本研究提出的地理空间感知框架能够生成基于证据的资源分配建议，并且优于基线方法。此外，该框架也被证明可以泛化到洪水和飓风等其他灾害。

Conclusion: 本研究提出的地理空间感知层（GAL）能够有效地将LLM与地理空间数据相结合，显著提升了灾难响应的有效性，尤其是在资源分配方面。该框架不仅在野火场景中表现出色，而且具有推广到其他灾害类型的潜力，为未来的智能灾难管理提供了新的方向。

Abstract: Effective disaster response is essential for safeguarding lives and property.
Existing statistical approaches often lack semantic context, generalize poorly
across events, and offer limited interpretability. While Large language models
(LLMs) provide few-shot generalization, they remain text-bound and blind to
geography. To bridge this gap, we introduce a Geospatial Awareness Layer (GAL)
that grounds LLM agents in structured earth data. Starting from raw wildfire
detections, GAL automatically retrieves and integrates infrastructure,
demographic, terrain, and weather information from external geodatabases,
assembling them into a concise, unit-annotated perception script. This enriched
context enables agents to produce evidence-based resource-allocation
recommendations (e.g., personnel assignments, budget allocations), further
reinforced by historical analogs and daily change signals for incremental
updates. We evaluate the framework in real wildfire scenarios across multiple
LLM models, showing that geospatially grounded agents can outperform baselines.
The proposed framework can generalize to other hazards such as floods and
hurricanes.

</details>


### [250] [ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization](https://arxiv.org/abs/2510.12063)
*Sunzhu Li,Zhiyu Lin,Shuling Yang,Jiale Zhao,Wei Chen*

Main category: cs.AI

TL;DR: ThinkPilot是一个训练免费框架，通过进化生成的think-prefix来优化大型推理模型（LRMs）的推理过程，提高了效率、安全性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型推理模型（LRMs）虽然强大，但在推理效率和准确性方面仍存在不足，而现有的训练免费方法要么依赖于僵化的启发式方法，要么进行描述性但不可操作的分析。

Method: ThinkPilot框架采用进化过程生成think-prefixes（指导模型的指令），并利用推理行为的分类学来驱动这个过程，以引导模型达到更高的性能。

Result: 实验结果表明，ThinkPilot在提高效率-准确性权衡、显著提升安全性（例如，将DeepSeek-R1-Distill-Qwen-32B的StrongREJECT分数从27.0%降低到0.7%）以及增强指令遵循能力方面表现出色。此外，ThinkPilot还能与现有的基于训练的方法协同工作。

Conclusion: ThinkPilot能够可靠地控制LRMs的推理行为，并且不同任务对特定的行为分布有偏好。通过自动识别和引导这些行为，ThinkPilot提供了一个通用的框架，可以将LRMs的推理与其任务需求对齐。

Abstract: Large Reasoning Models (LRMs) are powerful, but they still suffer from
inefficient and off-target reasoning. Currently, training-free methods are
limited to either rigid heuristics or descriptive, non-actionable analyses. In
this paper, we introduce ThinkPilot, a training-free framework that
automatically optimizes LRMs reasoning. It uses an evolutionary process to
generate think-prefixes, which are instructions that evolve driven by a
taxonomy of reasoning behaviors to guide models toward superior performance.
Extensive experiments demonstrate ThinkPilot's broad effectiveness: it
significantly improves the accuracy-length trade-off for efficient reasoning,
drastically improves safety (for example, cutting the StrongREJECT score of
DeepSeek-R1-Distill-Qwen-32B from 27.0% to 0.7), and enhances instruction
following. It also synergizes with existing training-based methods. Our
analysis reveals that think-prefixes can reliably control LRMs' reasoning
behaviors, and that different tasks have strong preferences for specific
behavioral distributions. By automatically identifying and eliciting these
behaviors, ThinkPilot provides a generalizable framework for aligning LRMs
reasoning with task demands. Data and code are available at
https://github.com/teqkilla/ThinkPilot

</details>


### [251] [AI Agents as Universal Task Solvers](https://arxiv.org/abs/2510.12066)
*Alessandro Achille,Stefano Soatto*

Main category: cs.AI

TL;DR: AI代理可以被视为计算能力有限的随机动态系统，学习的关键在于通过归纳学习转向归转学习，以识别算法结构并减少解决新任务的时间，而不是仅仅逼近数据分布。


<details>
  <summary>Details</summary>
Motivation: 研究AI代理的计算能力，特别是链式思考推理能否解决所有可计算任务，以及AI代理如何学习推理，这是否与模型或训练数据集的大小有关。

Method: 将AI代理重新解释为具有计算能力的随机动态系统，并提出从传统的归纳学习转向归转学习，目标是捕捉数据的算法结构以减少解决新任务的时间。

Result: 提出了信息在学习中的关键作用是减少时间而不是重建误差的理论，并推导了推理时间和训练时间的幂律缩放关系。研究表明，在无限时间和空间限制下，大型模型可能会表现出“白痴专家”的行为，而优化推理模型时，时间是一个关键因素。

Conclusion: 学习推理的关键在于优化时间，而不是仅仅依靠增加模型或训练数据量。AI代理的学习过程可以被理解为一种转导学习，其目标是识别算法结构以加速求解过程。

Abstract: AI reasoning agents are already able to solve a variety of tasks by deploying
tools, simulating outcomes of multiple hypotheses and reflecting on them. In
doing so, they perform computation, although not in the classical sense --
there is no program being executed. Still, if they perform computation, can AI
agents be universal? Can chain-of-thought reasoning solve any computable task?
How does an AI Agent learn to reason? Is it a matter of model size? Or training
dataset size?
  In this work, we reinterpret the role of learning in the context of AI
Agents, viewing them as compute-capable stochastic dynamical systems, and
highlight the role of time in a foundational principle for learning to reason.
In doing so, we propose a shift from classical inductive learning to
transductive learning -- where the objective is not to approximate the
distribution of past data, but to capture their algorithmic structure to reduce
the time needed to find solutions to new tasks.
  Transductive learning suggests that, counter to Shannon's theory, a key role
of information in learning is about reduction of time rather than
reconstruction error. In particular, we show that the optimal speed-up that a
universal solver can achieve using past data is tightly related to their
algorithmic information. Using this, we show a theoretical derivation for the
observed power-law scaling of inference time versus training time. We then show
that scaling model size can lead to behaviors that, while improving accuracy on
benchmarks, fail any reasonable test of intelligence, let alone
super-intelligence: In the limit of infinite space and time, large models can
behave as savants, able to brute-force through any task without any insight.
Instead, we argue that the key quantity to optimize when scaling reasoning
models is time, whose critical role in learning has so far only been indirectly
considered.

</details>


### [252] [HiCoTraj:Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory](https://arxiv.org/abs/2510.12067)
*Junyi Xie,Yuankun Jiao,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique*

Main category: cs.AI

TL;DR: HiCoTraj通过将轨迹转化为自然语言描述，并利用LLM的零样本学习能力，在没有标签数据的情况下进行人口统计推断。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹的人口统计推断方法依赖大量带标签数据，存在可解释性差、泛化能力弱的问题。

Method: HiCoTraj将轨迹转化为活动记录和多尺度访问摘要，并使用分层思维链提示引导LLM完成特征提取、行为模式分析和人口统计推断。

Result: 在真实轨迹数据上的实验表明，HiCoTraj在零样本场景下，针对多个属性的人口统计推断取得了有竞争力的性能。

Conclusion: HiCoTraj通过零样本学习和分层思维链推理，解决了带标签人口统计数据稀缺的挑战，并提供了透明的推理过程。

Abstract: Inferring demographic attributes such as age, sex, or income level from human
mobility patterns enables critical applications such as targeted public health
interventions, equitable urban planning, and personalized transportation
services. Existing mobility-based demographic inference studies heavily rely on
large-scale trajectory data with demographic labels, leading to limited
interpretability and poor generalizability across different datasets and user
groups. We propose HiCoTraj (Zero-Shot Demographic Reasoning via Hierarchical
Chain-of-Thought Prompting from Trajectory), a framework that leverages LLMs'
zero-shot learning and semantic understanding capabilities to perform
demographic inference without labeled training data. HiCoTraj transforms
trajectories into semantically rich, natural language representations by
creating detailed activity chronicles and multi-scale visiting summaries. Then
HiCoTraj uses a novel hierarchical chain of thought reasoning to systematically
guide LLMs through three cognitive stages: factual feature extraction,
behavioral pattern analysis, and demographic inference with structured output.
This approach addresses the scarcity challenge of labeled demographic data
while providing transparent reasoning chains. Experimental evaluation on
real-world trajectory data demonstrates that HiCoTraj achieves competitive
performance across multiple demographic attributes in zero-shot scenarios.

</details>


### [253] [EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making](https://arxiv.org/abs/2510.12072)
*Zixing Lei,Sheng Yin,Yichen Xiong,Yuanzhuo Ding,Wenhao Huang,Yuxi Wei,Qingyao Xu,Yiming Li,Weixin Li,Yunhong Wang,Siheng Chen*

Main category: cs.AI

TL;DR: EmboMatrix是一个训练平台，旨在通过模拟环境和互动来增强LLM的具身决策能力，其培养出的EmboBrain模型在基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了让仅在语言上训练的LLM获得物理世界的理解和具身决策能力，需要一个能够提供任务和场景模拟、具身互动和反馈信号的基础设施。

Method: 提出EmboMatrix，一个包含多智能体数据引擎、分布式异构硬件系统和多层次奖励架构的训练平台，并在此平台上培养出EmboBrain模型。

Result: EmboBrain-7B模型在两个具身决策基准测试中，比671B DeepSeek-R1基线模型高出9.5%。

Conclusion: 通过在EmboMatrix这样的交互式、与环境相关的学习平台上的大规模训练，可以培养出具有真正智能的具身代理。

Abstract: Embodied decision-making enables agents to translate high-level goals into
executable actions through continuous interactions within the physical world,
forming a cornerstone of general-purpose embodied intelligence. Large language
models (LLMs), with their general decision-making capabilities, offer a
promising path to realize this potential; however, LLMs trained solely on
language lack exposure to physical environments, limiting their true embodied
understanding. To bridge this gap, we propose the concept of a training ground:
a comprehensive infrastructure that provides task and scene simulation,
embodied interaction, and feedback signals, offering a one-stop solution for
LLM acquire genuine embodied decision-making skills. In this work, we present
EmboMatrix, the first training ground of its kind, providing massive and
diverse tasks with efficient simulation and precise rewards. EmboMatrix
incorporates a series of novel techniques: a multi-agent data engine for
large-scale task and scene generation, a distributed heterogeneous-hardware
system for scalable simulation, and a multi-level reward architecture for
precise supervision. Leveraging EmboMatrix, we cultivate EmboBrain, an LLM
whose embodied decision-making abilities emerge from extensive embodied
interactions. Experiments show that EmboBrain-7B surpasses the 671B DeepSeek-R1
baseline by 9.5\% on two challenging embodied decision-making benchmarks,
demonstrating the power of interactive, environment-grounded learning for
building truly intelligent embodied agents.

</details>


### [254] [BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data](https://arxiv.org/abs/2510.12076)
*Junyi Xie,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique*

Main category: cs.AI

TL;DR: BeSTAD是一个无监督框架，用于检测人类出行数据中的个体层面异常，通过整合空间和时间信息来识别偏离个人历史模式的行为。


<details>
  <summary>Details</summary>
Motivation: 检测大规模人群中个体层面的出行异常行为，而不是仅关注轨迹层面的统计异常，这仍然是一个挑战。

Method: BeSTAD学习富含语义的出行表示，整合位置含义和时间模式，并采用一种行为集群感知的建模机制，通过跨时期行为比较来识别异常。

Result: 该框架能够检测行为转变和偏离既定常规的行为，并在大规模出行数据集中识别出表现出这些变化的个体。

Conclusion: BeSTAD通过直接从无标签数据中学习个体行为，使异常检测能够进行个性化和可解释的出行分析。

Abstract: Traditional anomaly detection in human mobility has primarily focused on
trajectory-level analysis, identifying statistical outliers or spatiotemporal
inconsistencies across aggregated movement traces. However, detecting
individual-level anomalies, i.e., unusual deviations in a person's mobility
behavior relative to their own historical patterns, within datasets
encompassing large populations remains a significant challenge. In this paper,
we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human
Mobility Data), an unsupervised framework that captures individualized
behavioral signatures across large populations and uncovers fine-grained
anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD
learns semantically enriched mobility representations that integrate location
meaning and temporal patterns, enabling the detection of subtle deviations in
individual movement behavior. BeSTAD further employs a behavior-cluster-aware
modeling mechanism that builds personalized behavioral profiles from normal
activity and identifies anomalies through cross-period behavioral comparison
with consistent semantic alignment. Building on prior work in mobility behavior
clustering, this approach enables not only the detection of behavioral shifts
and deviations from established routines but also the identification of
individuals exhibiting such changes within large-scale mobility datasets. By
learning individual behaviors directly from unlabeled data, BeSTAD advances
anomaly detection toward personalized and interpretable mobility analysis.

</details>


### [255] [Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models](https://arxiv.org/abs/2510.12080)
*Rabimba Karanjai,Yang Lu,Ranjith Chodavarapu,Lei Xu,Weidong Shi*

Main category: cs.AI

TL;DR: LLM在处理随机性任务方面能力不足，结果不一致且常有偏差，尤其在生成随机数、字符串、洗牌以及评估随机性质量方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: LLM技术快速发展并广泛应用于需要随机性的领域，但其在生成和利用随机数方面的能力尚不明确。

Method: 通过设计考虑外部工具可及性、任务类型、模型状态（新鲜或非新鲜）和提示策略等多种因素的实验，评估LLM处理随机性任务的能力，包括生成随机数、随机字符串（如密码）、打乱项目以及使用熵和NIST随机性测试套件评估随机性质量。

Result: LLM能生成具有一定随机性的输出，但表现不一致，且显著偏离预期行为，在随机数生成、随机字符串生成、项目混洗以及随机性质量评估方面存在明显不足。

Conclusion: LLM在处理涉及随机性的任务时存在局限性，需要改进才能有效执行此类任务。

Abstract: The rapid advancement of large language model (LLM) technology has led to
diverse applications, many of which inherently require randomness, such as
stochastic decision-making, gaming, scheduling, AI agents, and
cryptography-related tasks. However, the capabilities of LLMs in handling
randomness, particularly in generating and utilizing random numbers
effectively, remain unclear. This paper investigates the capacity of LLMs for
handling tasks that involve randomness through a series of experiments. We
designed a set of experiments that consider various factors that can influence
an LLM's performance in tasks involving randomness, such as accessibility to
external tools, types of tasks, model states (fresh vs. non-fresh), and
prompting strategies. The experiments cover a range of tasks, including
generating random numbers, generating random strings such as passwords,
shuffling items, and evaluating the quality of randomness using entropy and the
NIST randomness test-suite. Our findings reveal that while LLMs can generate
outputs that exhibit some degree of randomness, their performance is
inconsistent and often deviates significantly from the expected behavior. The
analysis of the experimental results highlights key limitations and areas where
improvement is needed for the LLMs to effectively handle tasks involving
randomness

</details>


### [256] [One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration](https://arxiv.org/abs/2510.12088)
*Zaid Khan,Archiki Prasad,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal*

Main category: cs.AI

TL;DR: OneLife 是一个在复杂、随机环境中学习世界动力学的框架，使用概率编程和条件激活的程序定律，即使在数据稀疏的情况下也能有效学习，并在新环境中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂、随机、无人类指导的环境中学习符号世界模型的问题，之前的研究主要集中在确定性环境。

Method: 提出 OneLife 框架，通过概率编程框架内的条件激活程序定律来模拟世界动力学。每个定律都通过先决条件-效应结构运行，并在相关的世界状态下激活，从而创建一个动态计算图，只将推理和优化路由到相关的定律。

Result: 在 Crafter-OO 环境上，OneLife 成功地从极少的、无指导的交互中学习到关键的环境动力学，在 23 个测试场景中的 16 个上优于强基线。此外，OneLife 的规划能力也得到了验证，模拟测试成功识别出更优的策略。

Conclusion: OneLife 为自主构建未知、复杂环境的程序世界模型奠定了基础。

Abstract: Symbolic world modeling requires inferring and representing an environment's
transitional dynamics as an executable program. Prior work has focused on
largely deterministic environments with abundant interaction data, simple
mechanics, and human guidance. We address a more realistic and challenging
setting, learning in a complex, stochastic environment where the agent has only
"one life" to explore a hostile environment without human guidance. We
introduce OneLife, a framework that models world dynamics through
conditionally-activated programmatic laws within a probabilistic programming
framework. Each law operates through a precondition-effect structure,
activating in relevant world states. This creates a dynamic computation graph
that routes inference and optimization only through relevant laws, avoiding
scaling challenges when all laws contribute to predictions about a complex,
hierarchical state, and enabling the learning of stochastic dynamics even with
sparse rule activation. To evaluate our approach under these demanding
constraints, we introduce a new evaluation protocol that measures (a) state
ranking, the ability to distinguish plausible future states from implausible
ones, and (b) state fidelity, the ability to generate future states that
closely resemble reality. We develop and evaluate our framework on Crafter-OO,
our reimplementation of the Crafter environment that exposes a structured,
object-oriented symbolic state and a pure transition function that operates on
that state alone. OneLife can successfully learn key environment dynamics from
minimal, unguided interaction, outperforming a strong baseline on 16 out of 23
scenarios tested. We also test OneLife's planning ability, with simulated
rollouts successfully identifying superior strategies. Our work establishes a
foundation for autonomously constructing programmatic world models of unknown,
complex environments.

</details>


### [257] [ToPolyAgent: AI Agents for Coarse-Grained Topological Polymer Simulations](https://arxiv.org/abs/2510.12091)
*Lijie Ding,Jan-Michael Carrillo,Changwoo Do*

Main category: cs.AI

TL;DR: ToPolyAgent是一个多智能体AI框架，通过自然语言指令执行拓扑聚合物的粗粒度分子动力学(MD)模拟，整合了大型语言模型(LLM)和计算工具，支持不同聚合物结构。它包含四个LLM驱动的智能体：配置智能体、模拟智能体、报告智能体和工作流智能体。该系统支持交互模式和自主模式，可用于聚合物构象研究和材料发现。


<details>
  <summary>Details</summary>
Motivation: ToPolyAgent旨在通过整合大型语言模型(LLM)和计算工具，降低复杂计算流程的门槛，推动聚合物科学的AI驱动材料发现。

Method: ToPolyAgent利用四个LLM驱动的智能体（配置智能体、模拟智能体、报告智能体、工作流智能体）来处理聚合物MD模拟。支持交互模式（用户反馈）和自主模式（端到端任务执行）。

Result: 通过涉及不同聚合物结构、溶剂条件、温控器和模拟长度的案例研究，证明了ToPolyAgent的多功能性。它能够研究相互作用参数对线性聚合物构象的影响，以及接枝密度对刷状聚合物持久长度的影响。

Conclusion: ToPolyAgent通过自然语言接口和严格的模拟工具相结合，降低了复杂计算工作流程的门槛，推动了聚合物科学的AI驱动材料发现，并为自主、可扩展的多智能体科学研究生态系统奠定了基础。

Abstract: We introduce ToPolyAgent, a multi-agent AI framework for performing
coarse-grained molecular dynamics (MD) simulations of topological polymers
through natural language instructions. By integrating large language models
(LLMs) with domain-specific computational tools, ToPolyAgent supports both
interactive and autonomous simulation workflows across diverse polymer
architectures, including linear, ring, brush, and star polymers, as well as
dendrimers. The system consists of four LLM-powered agents: a Config Agent for
generating initial polymer-solvent configurations, a Simulation Agent for
executing LAMMPS-based MD simulations and conformational analyses, a Report
Agent for compiling markdown reports, and a Workflow Agent for streamlined
autonomous operations. Interactive mode incorporates user feedback loops for
iterative refinements, while autonomous mode enables end-to-end task execution
from detailed prompts. We demonstrate ToPolyAgent's versatility through case
studies involving diverse polymer architectures under varying solvent
condition, thermostats, and simulation lengths. Furthermore, we highlight its
potential as a research assistant by directing it to investigate the effect of
interaction parameters on the linear polymer conformation, and the influence of
grafting density on the persistence length of the brush polymer. By coupling
natural language interfaces with rigorous simulation tools, ToPolyAgent lowers
barriers to complex computational workflows and advances AI-driven materials
discovery in polymer science. It lays the foundation for autonomous and
extensible multi-agent scientific research ecosystems.

</details>


### [258] [Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing](https://arxiv.org/abs/2510.12121)
*Rongzhi Zhang,Liqin Ye,Yuzhao Heng,Xiang Chen,Tong Yu,Lingkai Kong,Sudheer Chava,Chao Zhang*

Main category: cs.AI

TL;DR: LLM的精确属性强度控制是AI系统适应用户期望的关键，但现有方法仅提供方向性或开放式指导。本研究提出将精确属性强度控制视为一个目标达成问题，并训练轻量级价值函数通过时序差分学习预测部分生成结果的最终属性强度得分，以指导LLM输出。同时，采用基于梯度的干预来精确引导模型达到特定的属性强度目标。该方法实现了对属性强度的细粒度、连续控制，超越了简单的方向性对齐。在LLaMA-3.2-3b和Phi-4-mini上的实验证实了该方法能够高精度地将文本生成引导至用户指定的属性强度。此外，该方法在偏好数据合成、帕累托前沿逼近与优化以及对齐行为蒸馏以实现无干预推理等三个下游任务中均显示出效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法仅提供方向性或开放式指导，无法可靠地实现精确的属性强度控制，以满足多样化的用户期望。

Method: 将精确属性强度控制重新表述为目标达成问题；训练轻量级价值函数，利用时序差分学习从部分生成结果预测最终属性强度得分，以指导LLM输出；利用梯度干预作用于隐藏表示，精确导航模型以达到特定的属性强度目标。

Result: 实验证明该方法能够高精度地将文本生成引导至用户指定的属性强度，并在偏好数据合成、帕累托前沿逼近与优化以及对齐行为蒸馏以实现无干预推理等三个下游任务中提高了效率。

Conclusion: 本研究提出的方法实现了对属性强度的细粒度、连续控制，超越了简单的方向性对齐，并有效提升了LLM在特定属性强度控制任务上的准确性和效率。

Abstract: Precise attribute intensity control--generating Large Language Model (LLM)
outputs with specific, user-defined attribute intensities--is crucial for AI
systems adaptable to diverse user expectations. Current LLM alignment methods,
however, typically provide only directional or open-ended guidance, failing to
reliably achieve exact attribute intensities. We address this limitation with
three key designs: (1) reformulating precise attribute intensity control as a
target-reaching problem, rather than simple maximization; (2) training a
lightweight value function via temporal-difference learning to predict final
attribute intensity scores from partial generations, thereby steering LLM
outputs; and (3) employing gradient-based interventions on hidden
representations to navigate the model precisely towards specific attribute
intensity targets. Our method enables fine-grained, continuous control over
attribute intensities, moving beyond simple directional alignment. Experiments
on LLaMA-3.2-3b and Phi-4-mini confirm our method's ability to steer text
generation to user-specified attribute intensities with high accuracy. Finally,
we demonstrate efficiency enhancements across three downstream tasks:
preference data synthesis, Pareto frontier approximation and optimization, and
distillation of aligned behaviors for intervention-free inference. Our code is
available on https://github.com/Pre-Control/pre-control

</details>


### [259] [MatSciBench: Benchmarking the Reasoning Ability of Large Language Models in Materials Science](https://arxiv.org/abs/2510.12171)
*Junkai Zhang,Jingru Gan,Xiaoxuan Wang,Zian Jia,Changquan Gu,Jianpeng Chen,Yanqiao Zhu,Mingyu Derek Ma,Dawei Zhou,Ling Li,Wei Wang*

Main category: cs.AI

TL;DR: MatSciBench是一个包含1340个材料科学问题的综合性基准测试，旨在评估和提升大型语言模型（LLM）在材料科学领域的推理能力。测试结果表明，即使是表现最好的模型，在大学水平的材料科学问题上的准确率也低于80%，凸显了该基准测试的挑战性。分析还揭示了不同推理策略（如链式思考、工具增强和自我修正）在不同场景下的优劣，并探讨了多模态推理、效率与准确性之间的权衡以及检索增强生成的影响。


<details>
  <summary>Details</summary>
Motivation: 材料科学领域的LLM推理能力仍有待探索，需要一个全面的基准测试来评估和推动该领域的发展。

Method: 创建了一个包含1340个问题的MatSciBench基准测试，涵盖了材料科学的各个子领域，并进行了详细的分类（6个主要领域，31个子领域）和难度分级。对包括Gemini-2.5-Pro在内的领先模型进行了评估，并分析了不同的推理策略、难度级别、效率与准确性之间的权衡、多模态推理的挑战、故障模式以及检索增强生成的影响。

Result: 在MatSciBench基准测试中，即使是表现最好的模型Gemini-2.5-Pro，在大学水平的材料科学问题上的准确率也低于80%。不同的推理策略在不同场景下表现不一，没有单一策略能够持续优于其他策略。多模态推理任务也存在挑战。

Conclusion: MatSciBench是一个全面且可靠的基准测试，能够有效评估和促进LLM在材料科学领域科学推理能力的发展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable abilities in
scientific reasoning, yet their reasoning capabilities in materials science
remain underexplored. To fill this gap, we introduce MatSciBench, a
comprehensive college-level benchmark comprising 1,340 problems that span the
essential subdisciplines of materials science. MatSciBench features a
structured and fine-grained taxonomy that categorizes materials science
questions into 6 primary fields and 31 sub-fields, and includes a three-tier
difficulty classification based on the reasoning length required to solve each
question. MatSciBench provides detailed reference solutions enabling precise
error analysis and incorporates multimodal reasoning through visual contexts in
numerous questions. Evaluations of leading models reveal that even the
highest-performing model, Gemini-2.5-Pro, achieves under 80% accuracy on
college-level materials science questions, highlighting the complexity of
MatSciBench. Our systematic analysis of different reasoning strategie--basic
chain-of-thought, tool augmentation, and self-correction--demonstrates that no
single method consistently excels across all scenarios. We further analyze
performance by difficulty level, examine trade-offs between efficiency and
accuracy, highlight the challenges inherent in multimodal reasoning tasks,
analyze failure modes across LLMs and reasoning methods, and evaluate the
influence of retrieval-augmented generation. MatSciBench thus establishes a
comprehensive and solid benchmark for assessing and driving improvements in the
scientific reasoning capabilities of LLMs within the materials science domain.

</details>


### [260] [Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey](https://arxiv.org/abs/2510.12178)
*Abdulhady Abas Abdullah,Arkaitz Zubiaga,Seyedali Mirjalili,Amir H. Gandomi,Fatemeh Daneshfar,Mohammadsadra Amini,Alan Salam Mohammed,Hadi Veisi*

Main category: cs.AI

TL;DR: LLaMA系列模型（从LLaMA 1到LLaMA 4）及其参数高效微调（PEFT）方法的演变、应用和未来方向。


<details>
  <summary>Details</summary>
Motivation: 概述Meta AI的LLaMA系列模型及其配套PEFT方法的快速发展，为相关研究和实践提供参考。

Method: 介绍LLaMA系列模型（7B-288B参数，包括多模态和MoE变体）的架构和性能；阐述PEFT概念，并重点介绍和分析五种应用于LLaMA的PEFT方法（LoRA, LLaMA-Adapter V1/V2, LLaMA-Excitor, QLoRA），包括其机制、参数节省和应用实例；讨论模型和适配器架构、参数量及基准测试结果；考察LLaMA和PEFT在现实世界中的应用（如法律和医疗领域）。

Result: LLaMA系列模型在不同规模下展现了关键性能特征；PEFT方法通过更新少量参数实现对大型预训练模型的有效适配；已成功将LLaMA模型和PEFT应用于法律和医疗等领域，并在某些情况下超越了更大的基线模型。

Conclusion: LLaMA模型和PEFT方法在自然语言处理领域具有重要价值和广泛应用前景，但也面临着扩展上下文和提高鲁棒性等挑战，未来研究方向包括这些挑战的解决。

Abstract: This review surveys the rapid evolution of Meta AI's LLaMA (Large Language
Model Meta AI) series - from LLaMA 1 through LLaMA 4 and the specialized
parameter-efficient fine-tuning (PEFT) methods developed for these models. We
first describe the LLaMA family of foundation models (7B-65B to 288B
parameters), their architectures (including native multimodal and
Mixtureof-Experts variants), and key performance characteristics. We then
describe and discuss the concept of PEFT, which adapts large pre-trained models
by updating only a small subset of parameters, and review five PEFT methods
that have been applied to LLaMA: LoRA (Low-Rank Adaptation), LLaMA-Adapter V1
and V2, LLaMA-Excitor, and QLoRA (Quantized LoRA). We discuss each method's
mechanism, parameter savings, and example application to LLaMA (e.g.,
instruction tuning, multimodal tasks). We provide structured discussion and
analysis of model and adapter architectures, parameter counts, and benchmark
results (including examples where fine-tuned LLaMA models outperform larger
baselines). Finally, we examine real-world use cases where LLaMA-based models
and PEFT have been successfully applied (e.g., legal and medical domains), and
we discuss ongoing challenges and future research directions (such as scaling
to even larger contexts and improving robustness). This survey paper provides a
one-stop resource for ML researchers and practitioners interested in LLaMA
models and efficient fine-tuning strategies.

</details>


### [261] [ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents](https://arxiv.org/abs/2510.12194)
*Linyi Yang,Yixuan Weng*

Main category: cs.AI

TL;DR: ResearStudio是一个开源框架，实现了实时的人类控制，允许用户在代理运行时进行干预和指导，并在GAIA基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前的深度研究代理缺乏在执行过程中进行错误修复或添加专家知识的能力。ResearStudio旨在解决这一问题，将实时人类控制置于核心。 

Method: ResearStudio采用“协作工坊”设计，包含一个分层规划器-执行器，将每一步写入“计划即文档”，并通过快速通信层将每个动作、文件更改和工具调用流式传输到Web界面。用户可以随时暂停、编辑计划或代码、运行自定义命令，并在AI主导、人辅助和人主导、AI辅助模式之间无缝切换。

Result: 在完全自主模式下，ResearStudio在GAIA基准测试上取得了最先进的成果，优于OpenAI的DeepResearch和Manus等系统。

Conclusion: 强大的自动化性能和细粒度的人类控制可以共存。

Abstract: Current deep-research agents run in a ''fire-and-forget'' mode: once started,
they give users no way to fix errors or add expert knowledge during execution.
We present ResearStudio, the first open-source framework that places real-time
human control at its core. The system follows a Collaborative Workshop design.
A hierarchical Planner-Executor writes every step to a live
''plan-as-document,'' a fast communication layer streams each action, file
change, and tool call to a web interface. At any moment, the user can pause the
run, edit the plan or code, run custom commands, and resume -- switching
smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In
fully autonomous mode, ResearStudio achieves state-of-the-art results on the
GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These
results show that strong automated performance and fine-grained human control
can coexist. The full code, protocol, and evaluation scripts are available at
https://github.com/ResearAI/ResearStudio. We will continue to update the
repository to encourage further work on safe and controllable research agents.
Our live demo is publicly accessible at http://ai-researcher.net:3000/. We
support the development of DeepScientist, which can be accessed at
https://github.com/ResearAI/DeepScientist.

</details>


### [262] [On the Design and Evaluation of Human-centered Explainable AI Systems: A Systematic Review and Taxonomy](https://arxiv.org/abs/2510.12201)
*Aline Mangold,Juliane Zietz,Susanne Weinhold,Sebastian Pannasch*

Main category: cs.AI

TL;DR: 本篇论文是对65项解释性人工智能(XAI)用户研究的全面回顾，旨在为XAI开发者提供以用户为中心的评估和设计指南。


<details>
  <summary>Details</summary>
Motivation: 当前XAI系统的评估过于技术化，未能充分满足用户的需求，因此需要用户研究来指导XAI的开发。

Method: 对65项评估XAI系统的用户研究进行了全面的回顾和分析，重点关注XAI系统的特性、以用户为中心的评估指标以及针对不同AI专业知识水平用户的设计目标。

Result: XAI系统和其解释共同构成了整个系统；评估指标可分为情感、认知、可用性、可解释性和解释性指标；用户特征和行为也可进行评估；AI新手的设计目标包括负责任使用、接受度和可用性；数据专家的设计目标侧重于性能，包括人机协作以及系统和用户任务性能。

Conclusion: 本研究提出了一个扩展的XAI评估和设计框架，并为AI新手和数据专家分别提出了定制化的设计目标，以促进以用户为中心的人工智能开发。

Abstract: As AI becomes more common in everyday living, there is an increasing demand
for intelligent systems that are both performant and understandable.
Explainable AI (XAI) systems aim to provide comprehensible explanations of
decisions and predictions. At present, however, evaluation processes are rather
technical and not sufficiently focused on the needs of human users.
Consequently, evaluation studies involving human users can serve as a valuable
guide for conducting user studies. This paper presents a comprehensive review
of 65 user studies evaluating XAI systems across different domains and
application contexts. As a guideline for XAI developers, we provide a holistic
overview of the properties of XAI systems and evaluation metrics focused on
human users (human-centered). We propose objectives for the human-centered
design (design goals) of XAI systems. To incorporate users' specific
characteristics, design goals are adapted to users with different levels of AI
expertise (AI novices and data experts). In this regard, we provide an
extension to existing XAI evaluation and design frameworks. The first part of
our results includes the analysis of XAI system characteristics. An important
finding is the distinction between the core system and the XAI explanation,
which together form the whole system. Further results include the distinction
of evaluation metrics into affection towards the system, cognition, usability,
interpretability, and explanation metrics. Furthermore, the users, along with
their specific characteristics and behavior, can be assessed. For AI novices,
the relevant extended design goals include responsible use, acceptance, and
usability. For data experts, the focus is performance-oriented and includes
human-AI collaboration and system and user task performance.

</details>


### [263] [GOAT: A Training Framework for Goal-Oriented Agent with Tools](https://arxiv.org/abs/2510.12218)
*Hyunji Min,Sangwon Jung,Junyoung Sung,Dosung Lee,Leekyeung Han,Paul Hongsuck Seo*

Main category: cs.AI

TL;DR: GOAT框架通过在无人工标注的情况下进行训练，提升了LLM在目标导向任务中的API调用和推理能力，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在处理需要复杂API调用规划和执行的目标导向查询时能力有限，尤其是在缺乏训练数据的情况下，并且开源模型在这方面弱于闭源模型。

Method: 提出了一种名为GOAT的新训练框架，该框架能够自动从API文档构建合成数据集，用于目标导向的API执行任务的训练，无需人工标注。

Result: GOAT训练的代理在多个现有目标导向基准测试中取得了最先进的性能，并在新引入的GOATBench基准测试中表现优异。

Conclusion: GOAT是一个有前景的解决方案，可以构建强大的、能够进行复杂推理和工具使用的开源LLM代理。

Abstract: Large language models (LLMs) have recently been extended beyond traditional
text generation to serve as interactive agents capable of using external tools
based on user intent. However, current LLM agents still show limited ability to
handle goal-oriented queries, which require decomposing a high-level objective
into multiple interdependent API calls with correct planning and execution.
Current approaches mainly rely on zero-shot evaluation due to the absence of
training data. While proprietary closed-source models such as GPT-4 demonstrate
strong reasoning abilities, smaller open-source models struggle to perform
complex tool use effectively. Thus, we propose a novel training framework GOAT,
which enables fine-tuning of LLM agents in a human annotation-free setting.
GOAT automatically constructs synthetic datasets of goal-oriented API execution
tasks directly from given API documents, equipping models with the ability to
reason over interdependent calls and generate coherent responses. Through
extensive experiments, we show that GOAT-trained agents achieve
state-of-the-art performance across multiple existing goal-oriented benchmarks.
In addition, we introduce GOATBench, a new goal-oriented API execution
benchmark, and demonstrate that agents trained with GOAT also excel in this
setting. These results highlight GOAT as a practical path toward building
robust open-source LLM agents capable of complex reasoning and tool use.

</details>


### [264] [MedKGEval: A Knowledge Graph-Based Multi-Turn Evaluation Framework for Open-Ended Patient Interactions with Clinical LLMs](https://arxiv.org/abs/2510.12224)
*Yuechun Yu,Han Ying,Haoan Jin,Wenjian Jiang,Dong Xian,Binghao Wang,Zhou Yang,Mengyue Wu*

Main category: cs.AI

TL;DR: MedKGEval 是一个创新的多轮评估框架，用于评估医学领域的大型语言模型（LLM），通过结合知识图谱和实时评估来克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在医学应用中的能力，特别是捕捉多轮医患互动和动态信息需求方面，仍是一个挑战。现有方法通常忽略了医疗对话的动态和情境敏感性。

Method: MedKGEval 包含三个关键部分：（1）一个由知识图谱驱动的患者模拟机制，患者代理能够根据控制模块检索到的医学事实表现出逼真且类似人类的对话行为；（2）一个在对话进行过程中，由裁判代理根据一系列精细的、特定任务的指标，对每个模型响应的临床适宜性、事实准确性和安全性进行评估的原位、回合级评估框架；（3）一个包含八个最先进 LLM 的综合性多轮基准测试。

Result: MedKGEval 能够识别出传统评估方法通常会忽略的细微行为缺陷和安全风险。

Conclusion: MedKGEval 是一个有效的多轮评估框架，能够提供更全面、更精确的医学 LLM 评估。该框架易于扩展到其他语言，并支持双语和特定领域应用。

Abstract: The reliable evaluation of large language models (LLMs) in medical
applications remains an open challenge, particularly in capturing the
complexity of multi-turn doctor-patient interactions that unfold in real
clinical environments. Existing evaluation methods typically rely on post hoc
review of full conversation transcripts, thereby neglecting the dynamic,
context-sensitive nature of medical dialogues and the evolving informational
needs of patients. In this work, we present MedKGEval, a novel multi-turn
evaluation framework for clinical LLMs grounded in structured medical
knowledge. Our approach introduces three key contributions: (1) a knowledge
graph-driven patient simulation mechanism, where a dedicated control module
retrieves relevant medical facts from a curated knowledge graph, thereby
endowing the patient agent with human-like and realistic conversational
behavior. This knowledge graph is constructed by integrating open-source
resources with additional triples extracted from expert-annotated datasets; (2)
an in-situ, turn-level evaluation framework, where each model response is
assessed by a Judge Agent for clinical appropriateness, factual correctness,
and safety as the dialogue progresses using a suite of fine-grained,
task-specific metrics; (3) a comprehensive multi-turn benchmark of eight
state-of-the-art LLMs, demonstrating MedKGEval's ability to identify subtle
behavioral flaws and safety risks that are often overlooked by conventional
evaluation pipelines. Although initially designed for Chinese and English
medical applications, our framework can be readily extended to additional
languages by switching the input knowledge graphs, ensuring seamless bilingual
support and domain-specific applicability.

</details>


### [265] [PromptFlow: Training Prompts Like Neural Networks](https://arxiv.org/abs/2510.12246)
*Jingyi Wang,Hongyuan Zhu,Ye Niu,Yunhui Deng*

Main category: cs.AI

TL;DR: PromptFlow是一个模块化的训练框架，通过梯度元学习和强化学习自动优化和精炼LLM的提示，以适应不同NLP任务，只需少量特定任务的训练数据。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在特定领域表现不佳，手动提示工程耗时耗力且需要专业知识。现有自动提示工程方法缺乏动态策略选择和细粒度提示编辑能力，且在LLM经验回收方面探索不足。

Method: 提出PromptFlow框架，结合元提示、算子、优化和评估器。利用梯度元学习自主探索最优提示精炼轨迹，并结合强化学习方法回收LLM在提示工程过程中的经验。

Result: 在多个数据集上进行了广泛的实验，证明了PromptFlow的有效性。

Conclusion: PromptFlow通过自动化提示优化和经验回收，解决了现有方法的局限性，能够以很少的特定任务训练数据有效地适应不同的NLP任务。

Abstract: Large Language Models (LLMs) have demonstrated profound impact on Natural
Language Processing (NLP) tasks. However, their effective deployment across
diverse domains often require domain-specific adaptation strategies, as generic
models may underperform when faced with specialized data distributions. Recent
advances in prompt engineering (PE) offer a promising alternative to extensive
retraining by refining input instructions to align LLM outputs with task
objectives. This paradigm has emerged as a rapid and versatile approach for
model fine-tuning. Despite its potential, manual prompt design remains
labor-intensive and heavily depends on specialized expertise, often requiring
iterative human effort to achieve optimal formulations. To address this
limitation, automated prompt engineering methodologies have been developed to
systematically generate task-specific prompts. However, current implementations
predominantly employ static update rules and lack mechanisms for dynamic
strategy selection, resulting in suboptimal adaptation to varying NLP task
requirements. Furthermore, most methods treat and update the whole prompts at
each step, without considering editing prompt sections at a finer granularity.
At last, in particular, the problem of how to recycle experience in LLM is
still underexplored. To this end, we propose the PromptFlow, a modular training
framework inspired by TensorFlow, which integrates meta-prompts, operators,
optimization, and evaluator. Our framework can be equipped with the latest
optimization methods and autonomously explores optimal prompt refinement
trajectories through gradient-based meta-learning, requiring minimal
task-specific training data. Specifically, we devise a reinforcement learning
method to recycle experience for LLM in the PE process. Finally, we conduct
extensive experiments on various datasets, and demonstrate the effectiveness of
PromptFlow.

</details>


### [266] [$\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning](https://arxiv.org/abs/2510.12264)
*Deyu Zou,Yongqiang Chen,Jianxiang Wang,Haochen Yang,Mufei Li,James Cheng,Pan Li,Yu Gong*

Main category: cs.AI

TL;DR: LLM驱动的代理在主动推理中会遇到信念偏差问题，导致错误累积和训练失败。本文提出了T^3方法，通过检测并截断信念偏差过大的轨迹来解决这个问题，从而提高策略优化效率和最终性能。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代理在主动推理中存在信念跟踪不准确、状态丢失、行动冗余等问题，导致错误累积且强化学习训练效果不佳。

Method: 提出T^3方法，通过跟踪模型信念偏差并检测过度偏差，在训练过程中截断轨迹，去除无效部分，保留信息性前缀的信用。

Result: T^3在5项具有挑战性的任务中，提高了训练稳定性、代币效率和最终性能，实现了高达30%的性能提升，同时代币消耗减少了约25%。

Conclusion: 信念控制是开发健壮且可泛化的LLM驱动主动推理器的关键原则。

Abstract: Active reasoning requires large language models (LLMs) to interact with
external sources and strategically gather information to solve problems.
Central to this process is belief tracking: maintaining a coherent
understanding of the problem state and the missing information toward the
solution. However, due to limited reasoning capabilities, LLM-based agents
often suffer from belief deviation: they struggle to correctly model beliefs,
lose track of problem states, and fall into uninformative or repetitive
actions. Once this happens, errors compound and reinforcement learning (RL)
training fails to properly credit the crucial exploratory steps. To address
this issue, we propose to track the deviation of model beliefs and develop
$\mathbf{T^3}$, a simple yet effective method that detects excessive belief
deviation and truncates trajectories during training to remove uninformative
tails. By preserving credit for informative prefixes, $\mathbf{T^3}$
systematically improves policy optimization. Across 5 challenging tasks,
$\mathbf{T^3}$ consistently enhances training stability, token efficiency, and
final performance, achieving up to 30% gains while cutting rollout tokens by
roughly 25%. These results highlight belief control as a key principle for
developing robust and generalizable LLM-based active reasoners.

</details>


### [267] [RAG-Anything: All-in-One RAG Framework](https://arxiv.org/abs/2510.12323)
*Zirui Guo,Xubin Ren,Lingrui Xu,Jiahao Zhang,Chao Huang*

Main category: cs.AI

TL;DR: RAG-Anything 是一个统一的框架，可以跨越所有模态进行全面的知识检索，解决了现有 RAG 框架仅限于文本内容的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有 RAG 框架在处理多模态文档时存在根本性差距，因为它们仅限于文本内容，而现代知识存储库包含文本、视觉元素、表格和数学表达式的组合。

Method: RAG-Anything 将多模态内容重新概念化为相互连接的知识实体，而不是孤立的数据类型。该框架引入了双图构建来捕获统一表示中的跨模态关系和文本语义。它还开发了跨模态混合检索，将结构化知识导航与语义匹配相结合。

Result: RAG-Anything 在具有挑战性的多模态基准测试中表现出卓越的性能，与最先进的方法相比取得了显著的改进，尤其是在传统方法失败的长文档上。

Conclusion: RAG-Anything 建立了一个新的多模态知识访问范式，消除了限制当前系统的架构碎片化。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm
for expanding Large Language Models beyond their static training limitations.
However, a critical misalignment exists between current RAG capabilities and
real-world information environments. Modern knowledge repositories are
inherently multimodal, containing rich combinations of textual content, visual
elements, structured tables, and mathematical expressions. Yet existing RAG
frameworks are limited to textual content, creating fundamental gaps when
processing multimodal documents. We present RAG-Anything, a unified framework
that enables comprehensive knowledge retrieval across all modalities. Our
approach reconceptualizes multimodal content as interconnected knowledge
entities rather than isolated data types. The framework introduces dual-graph
construction to capture both cross-modal relationships and textual semantics
within a unified representation. We develop cross-modal hybrid retrieval that
combines structural knowledge navigation with semantic matching. This enables
effective reasoning over heterogeneous content where relevant evidence spans
multiple modalities. RAG-Anything demonstrates superior performance on
challenging multimodal benchmarks, achieving significant improvements over
state-of-the-art methods. Performance gains become particularly pronounced on
long documents where traditional approaches fail. Our framework establishes a
new paradigm for multimodal knowledge access, eliminating the architectural
fragmentation that constrains current systems. Our framework is open-sourced
at: https://github.com/HKUDS/RAG-Anything.

</details>


### [268] [O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis](https://arxiv.org/abs/2510.12350)
*Ayush Khaitan,Vijay Ganesh*

Main category: cs.AI

TL;DR: LLM+CAS框架结合前沿LLM和计算机代数系统（CAS），通过符号反馈循环生成并验证数学证明，特别是在渐近不等式领域，能够提出有效的子域划分，并已成功应用于回答Terence Tao提出的问题。


<details>
  <summary>Details</summary>
Motivation: LLM在研究数学领域的应用受限于证明的验证。本研究旨在构建一个能够生成可信的、经过严格验证的研究水平数学证明的框架。

Method: 提出LLM+CAS框架和O-Forge工具，结合LLM提出子域划分，并利用CAS（如Mathematica）对每个子域进行公理化验证，形成一个符号反馈循环。

Result: LLM+CAS框架在提出渐近不等式的子域划分方面表现出卓越的有效性，并成功应用于解决Terence Tao提出的问题，证明了AI在研究数学领域的潜力。

Conclusion: LLM+CAS框架表明，AI工具（尤其是结合了验证功能的LLM）能够超越竞赛数学的范畴，成为专业研究数学家在处理复杂渐近不等式等研究级问题时的有力助手。

Abstract: Large language models have recently demonstrated advanced capabilities in
solving IMO and Putnam problems; yet their role in research mathematics has
remained fairly limited. The key difficulty is verification: suggested proofs
may look plausible, but cannot be trusted without rigorous checking. We present
a framework, called LLM+CAS, and an associated tool, O-Forge, that couples
frontier LLMs with a computer algebra systems (CAS) in an In-Context Symbolic
Feedback loop to produce proofs that are both creative and symbolically
verified. Our focus is on asymptotic inequalities, a topic that often involves
difficult proofs and appropriate decomposition of the domain into the "right"
subdomains. Many mathematicians, including Terry Tao, have suggested that using
AI tools to find the right decompositions can be very useful for research-level
asymptotic analysis. In this paper, we show that our framework LLM+CAS turns
out to be remarkably effective at proposing such decompositions via a
combination of a frontier LLM and a CAS. More precisely, we use an LLM to
suggest domain decomposition, and a CAS (such as Mathematica) that provides a
verification of each piece axiomatically. Using this loop, we answer a question
posed by Terence Tao: whether LLMs coupled with a verifier can be used to help
prove intricate asymptotic inequalities. More broadly, we show how AI can move
beyond contest math towards research-level tools for professional
mathematicians.

</details>


### [269] [A Survey of Vibe Coding with Large Language Models](https://arxiv.org/abs/2510.12399)
*Yuyao Ge,Lingrui Mei,Zenghao Duan,Tianhao Li,Yujia Zheng,Yiwei Wang,Lexin Wang,Jiayu Yao,Tianyu Liu,Yujun Cai,Baolong Bi,Fangda Guo,Jiafeng Guo,Shenghua Liu,Xueqi Cheng*

Main category: cs.AI

TL;DR: LLMs 催生了“Vibe Coding”新范式，开发者通过观察结果而非逐行代码来验证 AI 生成的实现。该调查首次全面回顾了 Vibe Coding，建立了理论基础和实践框架，并提出了五种开发模型，强调了上下文工程、开发环境和人机协作模型的重要性。


<details>
  <summary>Details</summary>
Motivation: Vibe Coding 的有效性尚未得到充分探索，且已出现生产力损失和人机协作挑战的实证证据。该调查旨在解决这一差距，为 Vibe Coding 建立理论基础和实践框架。

Method: 系统分析了 1000 多篇研究论文，审查了 Vibe Coding 的生态系统，包括用于编码的 LLM、基于 LLM 的编码代理、编码代理的开发环境和反馈机制。通过约束马尔可夫决策过程的形式化 Vibe Coding，并根据现有实践提出了五种开发模型。

Result: 提出了 Vibe Coding 的形式化定义（约束马尔可夫决策过程），并根据现有实践对 Vibe Coding 生态系统进行了分类，提出了五种开发模型：无约束自动化、迭代对话协作、规划驱动、测试驱动和上下文增强模型。

Conclusion: 成功的 Vibe Coding 不仅取决于代理能力，还取决于系统的上下文工程、完善的开发环境以及人机协作开发模型。

Abstract: The advancement of large language models (LLMs) has catalyzed a paradigm
shift from code generation assistance to autonomous coding agents, enabling a
novel development methodology termed "Vibe Coding" where developers validate
AI-generated implementations through outcome observation rather than
line-by-line code comprehension. Despite its transformative potential, the
effectiveness of this emergent paradigm remains under-explored, with empirical
evidence revealing unexpected productivity losses and fundamental challenges in
human-AI collaboration. To address this gap, this survey provides the first
comprehensive and systematic review of Vibe Coding with large language models,
establishing both theoretical foundations and practical frameworks for this
transformative development approach. Drawing from systematic analysis of over
1000 research papers, we survey the entire vibe coding ecosystem, examining
critical infrastructure components including LLMs for coding, LLM-based coding
agent, development environment of coding agent, and feedback mechanisms. We
first introduce Vibe Coding as a formal discipline by formalizing it through a
Constrained Markov Decision Process that captures the dynamic triadic
relationship among human developers, software projects, and coding agents.
Building upon this theoretical foundation, we then synthesize existing
practices into five distinct development models: Unconstrained Automation,
Iterative Conversational Collaboration, Planning-Driven, Test-Driven, and
Context-Enhanced Models, thus providing the first comprehensive taxonomy in
this domain. Critically, our analysis reveals that successful Vibe Coding
depends not merely on agent capabilities but on systematic context engineering,
well-established development environments, and human-agent collaborative
development models.

</details>


### [270] [PricingLogic: Evaluating LLMs Reasoning on Complex Tourism Pricing Tasks](https://arxiv.org/abs/2510.12409)
*Yunuo Liu,Dawei Zhu,Zena Al-Khalili,Dai Cheng,Yanjun Chen,Dietrich Klakow,Wei Zhang,Xiaoyu Shen*

Main category: cs.AI

TL;DR: 该基准测试（PricingLogic）首次验证了大型语言模型（LLMs）在处理旅游业中复杂、重叠的票价规则时自动化定价的可靠性。虽然旅行社希望将此易错任务交给AI，但未经验证的LLM可能导致重大经济损失和信任危机。PricingLogic包含300个基于真实定价策略的自然语言问题，分为基本客户定价和涉及交互式折扣的捆绑旅游计算两个难度级别。评估结果显示，LLMs在较难的级别上性能急剧下降，暴露出规则解释和算术推理方面的系统性故障。这表明，尽管LLMs能力广泛，但在缺乏额外安全措施或领域适应的情况下，它们在收入关键型应用中仍不可靠。


<details>
  <summary>Details</summary>
Motivation: 旅游业中，自动化定价（特别是涉及多个重叠票价规则时）是一个常见但易错的任务。旅行社希望利用AI（特别是LLMs）来自动化这一过程，以降低成本和错误率。然而，在部署LLMs之前，验证其在此类关键任务上的可靠性至关重要，因为错误可能导致重大的经济损失和客户信任的丧失。

Method: 构建了一个名为PricingLogic的基准测试，其中包含300个自然语言问题。这些问题基于42个真实的定价策略，模拟了旅游预订场景。该基准测试包含两个难度级别：基础客户类型定价和涉及交互式折扣的捆绑旅游计算。然后，使用一系列LLMs在PricingLogic基准测试上进行评估。

Result: 在PricingLogic基准测试的评估中，LLMs在基础难度级别上表现尚可，但在涉及复杂交互式折扣的捆绑旅游计算（较难级别）上，性能出现了显著下降。这暴露了LLMs在理解和解释相互关联的票价规则以及执行准确的算术推理方面存在系统性缺陷。

Conclusion: 尽管LLMs在许多方面表现出色，但它们在处理像旅游定价这样需要精确规则解释和算术推理的收入关键型应用时，仍然不够可靠。在没有进一步的安全措施或针对特定领域进行调整的情况下，直接部署LLMs可能会带来风险。

Abstract: We present PricingLogic, the first benchmark that probes whether Large
Language Models(LLMs) can reliably automate tourism-related prices when
multiple, overlapping fare rules apply. Travel agencies are eager to offload
this error-prone task onto AI systems; however, deploying LLMs without verified
reliability could result in significant financial losses and erode customer
trust. PricingLogic comprises 300 natural-language questions based on booking
requests derived from 42 real-world pricing policies, spanning two levels of
difficulty: (i) basic customer-type pricing and (ii)bundled-tour calculations
involving interacting discounts. Evaluations of a line of LLMs reveal a steep
performance drop on the harder tier,exposing systematic failures in rule
interpretation and arithmetic reasoning.These results highlight that, despite
their general capabilities, today's LLMs remain unreliable in revenue-critical
applications without further safeguards or domain adaptation. Our code and
dataset are available at https://github.com/EIT-NLP/PricingLogic.

</details>


### [271] [MTOS: A LLM-Driven Multi-topic Opinion Simulation Framework for Exploring Echo Chamber Dynamics](https://arxiv.org/abs/2510.12423)
*Dingyi Zuo,Hongjie Zhang,Jie Ou,Chaosheng Feng,Shuwan Liu*

Main category: cs.AI

TL;DR: 该研究提出了一个名为MTOS的多主题意见模拟框架，该框架结合了大型语言模型（LLM）和多主题上下文，旨在解决现有模型在模拟跨领域、多主题交互方面的局限性。研究结果表明，多主题环境会显著影响观点极化趋势，并与传统数值模型相比，MTOS能更真实地模拟动态意见变化和复杂的人类推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的研究主要集中在单主题，无法捕捉多主题、跨领域交互中复杂的认知转移。而传统数值模型则简化了语言态度，缺乏可解释性、行为一致性，且难以整合多主题。本研究旨在解决这些问题。

Method: 提出了一种名为MTOS（Multi-topic Opinion Simulation）的社会模拟框架，该框架集成了多主题上下文与LLM。MTOS利用LLM、短期和长期记忆、多种用户选择交互机制、动态主题选择策略以及信念衰减机制，实现了跨主题的视角更新。

Result: 实验结果表明，多主题设置显著改变了观点极化趋势：正相关主题会放大回音室效应，负相关主题则会抑制，不相关主题也通过资源竞争缓解了回音室效应。与数值模型相比，基于LLM的智能体能更真实地模拟动态意见变化，复现新闻文本的语言特征，并捕捉复杂的人类推理，提高了模拟的可解释性和系统稳定性。

Conclusion: MTOS框架能够有效地模拟多主题环境下的意见演变，并克服了现有研究在捕捉跨领域交互和解释性方面的不足。该框架为理解社交媒体上的复杂意见动态提供了新的视角和工具。

Abstract: The polarization of opinions, information segregation, and cognitive biases
on social media have attracted significant academic attention. In real-world
networks, information often spans multiple interrelated topics, posing
challenges for opinion evolution and highlighting the need for frameworks that
simulate interactions among topics. Existing studies based on large language
models (LLMs) focus largely on single topics, limiting the capture of cognitive
transfer in multi-topic, cross-domain contexts. Traditional numerical models,
meanwhile, simplify complex linguistic attitudes into discrete values, lacking
interpretability, behavioral consistency, and the ability to integrate multiple
topics. To address these issues, we propose Multi-topic Opinion Simulation
(MTOS), a social simulation framework integrating multi-topic contexts with
LLMs. MTOS leverages LLMs alongside short-term and long-term memory,
incorporates multiple user-selection interaction mechanisms and dynamic
topic-selection strategies, and employs a belief decay mechanism to enable
perspective updates across topics. We conduct extensive experiments on MTOS,
varying topic numbers, correlation types, and performing ablation studies to
assess features such as group polarization and local consistency. Results show
that multi-topic settings significantly alter polarization trends: positively
correlated topics amplify echo chambers, negatively correlated topics inhibit
them, and irrelevant topics also mitigate echo chamber effects through resource
competition. Compared with numerical models, LLM-based agents realistically
simulate dynamic opinion changes, reproduce linguistic features of news texts,
and capture complex human reasoning, improving simulation interpretability and
system stability.

</details>


### [272] [Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections](https://arxiv.org/abs/2510.12428)
*Chengyang Dong,Nan Guo*

Main category: cs.AI

TL;DR: 该论文提出了一种基于深度强化学习（DRL）的决策框架，并结合了偏置注意机制，以提高在无信号交叉口的自动驾驶车辆的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 在无信号交叉口实现主动安全控制，以应对复杂的动态交互和高冲突风险。

Method: 提出了一种深度强化学习（DRL）决策框架，该框架基于软 Actor-Critic（SAC）算法，并创新性地使用偏置注意机制构建交通风险预测器，该预测器评估进入交叉口的车辆的长期碰撞风险，并将该风险转化为密集的奖励信号来指导SAC代理做出安全高效的驾驶决策。

Result: 仿真结果表明，该方法有效提高了交叉口的交通效率和车辆安全性。

Conclusion: 所提出的智能决策框架在复杂场景下是有效的。

Abstract: Autonomous driving decision-making at unsignalized intersections is highly
challenging due to complex dynamic interactions and high conflict risks. To
achieve proactive safety control, this paper proposes a deep reinforcement
learning (DRL) decision-making framework integrated with a biased attention
mechanism. The framework is built upon the Soft Actor-Critic (SAC) algorithm.
Its core innovation lies in the use of biased attention to construct a traffic
risk predictor. This predictor assesses the long-term risk of collision for a
vehicle entering the intersection and transforms this risk into a dense reward
signal to guide the SAC agent in making safe and efficient driving decisions.
Finally, the simulation results demonstrate that the proposed method
effectively improves both traffic efficiency and vehicle safety at the
intersection, thereby proving the effectiveness of the intelligent
decision-making framework in complex scenarios. The code of our work is
available at https://github.com/hank111525/SAC-RWB.

</details>


### [273] [Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems](https://arxiv.org/abs/2510.12462)
*Jiaxin Gao,Chen Chen,Yanwen Jia,Xueluan Gong,Kwok-Yan Lam,Qian Wang*

Main category: cs.AI

TL;DR: LLM giudges may have biases, but they are robust to biased inputs and benefit from rubrics. Fine-tuning on biased data is risky. Task difficulty affects scores. Mitigation strategies are proposed.


<details>
  <summary>Details</summary>
Motivation: To systematically investigate judgment biases in LLM-as-a-judge models for content quality evaluation in communication systems and propose mitigation strategies.

Method: Investigated 11 types of biases in GPT-Judge and JudgeLM. Assessed robustness to biased inputs, effect of scoring rubrics, impact of fine-tuning on biased data, and correlation with task difficulty. Proposed four mitigation strategies.

Result: LLM judges showed robustness to biased inputs and improved with rubrics. Fine-tuning on biased data degraded performance. Task difficulty influenced scores. Four mitigation strategies were proposed.

Conclusion: LLM judges exhibit biases, but demonstrate robustness and can be improved with rubrics. Training on biased data poses risks. Task difficulty impacts scores. Mitigation strategies are crucial for fair AI judging.

Abstract: Large Language Models (LLMs) are increasingly being used to autonomously
evaluate the quality of content in communication systems, e.g., to assess
responses in telecom customer support chatbots. However, the impartiality of
these AI "judges" is not guaranteed, and any biases in their evaluation
criteria could skew outcomes and undermine user trust. In this paper, we
systematically investigate judgment biases in two LLM-as-a-judge models (i.e.,
GPT-Judge and JudgeLM) under the point-wise scoring setting, encompassing 11
types of biases that cover both implicit and explicit forms. We observed that
state-of-the-art LLM judges demonstrate robustness to biased inputs, generally
assigning them lower scores than the corresponding clean samples. Providing a
detailed scoring rubric further enhances this robustness. We further found that
fine-tuning an LLM on high-scoring yet biased responses can significantly
degrade its performance, highlighting the risk of training on biased data. We
also discovered that the judged scores correlate with task difficulty: a
challenging dataset like GPQA yields lower average scores, whereas an
open-ended reasoning dataset (e.g., JudgeLM-val) sees higher average scores.
Finally, we proposed four potential mitigation strategies to ensure fair and
reliable AI judging in practical communication scenarios.

</details>


### [274] [Using Medical Algorithms for Task-Oriented Dialogue in LLM-Based Medical Interviews](https://arxiv.org/abs/2510.12490)
*Rui Reis,Pedro Rangel Henriques,João Ferreira-Coimbra,Eva Oliveira,Nuno F. Rodrigues*

Main category: cs.AI

TL;DR: 开发了一个面向任务的、基于有向无环图（DAG）的医学问题对话框架，用于信息收集和报告生成。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够系统化收集患者信息并生成结构化报告的对话系统，以减轻医生负担并提高效率。

Method: 1. 将医学算法和指南转化为问题语料库；2. 使用分层聚类进行冷启动，以生成初始问题；3. 引入扩展-剪枝机制，实现自适应分支和回溯；4. 设计终止逻辑以确保信息收集的完整性；5. 自动合成符合临床工作流程的结构化报告；6. 基于人机交互原则设计用户界面。

Result: 患者应用程序：低认知负荷（NASA-TLX = 15.6），高可用性（SUS = 86），高满意度（QUIS = 8.1/9），易学性和界面设计评分高。医生应用程序：中等认知负荷（NASA-TLX = 26），极高可用性（SUS = 88.5），高满意度（QUIS = 8.3/9）。系统有效集成到临床工作流程中，降低认知负荷，支持高效报告生成。

Conclusion: 所开发的医学对话框架在患者信息收集和报告生成方面表现出高可用性和用户满意度，能够有效集成到临床工作流程中，并降低医生的认知负荷。系统具有一定的局限性，如偶发的系统延迟和评估样本量小且不够多样化。

Abstract: We developed a task-oriented dialogue framework structured as a Directed
Acyclic Graph (DAG) of medical questions. The system integrates: (1) a
systematic pipeline for transforming medical algorithms and guidelines into a
clinical question corpus; (2) a cold-start mechanism based on hierarchical
clustering to generate efficient initial questioning without prior patient
information; (3) an expand-and-prune mechanism enabling adaptive branching and
backtracking based on patient responses; (4) a termination logic to ensure
interviews end once sufficient information is gathered; and (5) automated
synthesis of doctor-friendly structured reports aligned with clinical
workflows. Human-computer interaction principles guided the design of both the
patient and physician applications. Preliminary evaluation involved five
physicians using standardized instruments: NASA-TLX (cognitive workload), the
System Usability Scale (SUS), and the Questionnaire for User Interface
Satisfaction (QUIS). The patient application achieved low workload scores
(NASA-TLX = 15.6), high usability (SUS = 86), and strong satisfaction (QUIS =
8.1/9), with particularly high ratings for ease of learning and interface
design. The physician application yielded moderate workload (NASA-TLX = 26) and
excellent usability (SUS = 88.5), with satisfaction scores of 8.3/9. Both
applications demonstrated effective integration into clinical workflows,
reducing cognitive demand and supporting efficient report generation.
Limitations included occasional system latency and a small, non-diverse
evaluation sample.

</details>


### [275] [Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation](https://arxiv.org/abs/2510.12498)
*Chengpeng Hu,Calvin Yu-Chian Chen*

Main category: cs.AI

TL;DR: AIVCs在学习细胞状态模型方面取得了进展，但跨实验室、跨平台和跨尺度的泛化能力仍然有限。提出了一种模型无关的CSL视角，通过算子语法来组织学习，并提出了一个决策导向的评估蓝图，以促进可复现的比较。


<details>
  <summary>Details</summary>
Motivation: 尽管在单细胞和空间基础模型、跨模态对齐、扰动图谱和通路水平读数方面取得了进展，但AIVCs在跨实验室、跨平台、数据泄露、覆盖偏差以及剂量、时间和组合效应的处理方面仍存在局限性。此外，跨尺度耦合以及分子、细胞和组织层面的对齐也受到限制。

Method: 提出了一种模型无关的细胞状态潜变量（CSL）视角，该视角通过算子语法（测量、提升/投影以实现跨尺度耦合、干预以实现剂量和调度）来组织学习。

Result: 建议采用一种决策导向的评估蓝图，该蓝图涵盖模态、尺度、上下文和干预，并强调功能空间读数，如通路活性、空间邻域和临床相关终点。

Conclusion: 建议采用算子感知的 데이터设计、抗泄露分区以及透明的校准和报告，以实现可复现的、相同条件下的比较。

Abstract: Artificial Intelligence Virtual Cells (AIVCs) aim to learn executable,
decision-relevant models of cell state from multimodal, multiscale
measurements. Recent studies have introduced single-cell and spatial foundation
models, improved cross-modality alignment, scaled perturbation atlases, and
explored pathway-level readouts. Nevertheless, although held-out validation is
standard practice, evaluations remain predominantly within single datasets and
settings; evidence indicates that transport across laboratories and platforms
is often limited, that some data splits are vulnerable to leakage and coverage
bias, and that dose, time and combination effects are not yet systematically
handled. Cross-scale coupling also remains constrained, as anchors linking
molecular, cellular and tissue levels are sparse, and alignment to scientific
or clinical readouts varies across studies. We propose a model-agnostic
Cell-State Latent (CSL) perspective that organizes learning via an operator
grammar: measurement, lift/project for cross-scale coupling, and intervention
for dosing and scheduling. This view motivates a decision-aligned evaluation
blueprint across modality, scale, context and intervention, and emphasizes
function-space readouts such as pathway activity, spatial neighborhoods and
clinically relevant endpoints. We recommend operator-aware data design,
leakage-resistant partitions, and transparent calibration and reporting to
enable reproducible, like-for-like comparisons.

</details>


### [276] [ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification](https://arxiv.org/abs/2510.12534)
*Utsav Kumar Nareti,Suraj Kumar,Soumya Pandey,Soumi Chattopadhyay,Chandranath Adak*

Main category: cs.AI

TL;DR: ProtoSiTex是一个用于细粒度多标签文本分类的半可解释框架，通过无监督原型发现和有监督分类相结合，实现高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的模型在细粒度多标签文本分类方面存在局限性，无法提供细粒度的见解。

Method: ProtoSiTex采用双阶段交替训练策略：无监督原型发现阶段学习语义连贯且多样化的原型，有监督分类阶段将原型映射到类别标签。它使用分层损失函数在子句子、句子和文档级别强制执行一致性，并通过自适应原型和多头注意力来处理重叠和冲突的语义。

Result: 在包含酒店评论的新数据集和两个公开基准（二分类和多分类）上的实验表明，ProtoSiTex在实现最先进性能的同时，提供了忠实且符合人类的解释。

Conclusion: ProtoSiTex为半可解释的多标签文本分类提供了一个健壮的解决方案，在性能和可解释性方面都取得了显著成果。

Abstract: The surge in user-generated reviews has amplified the need for interpretable
models that can provide fine-grained insights. Existing prototype-based models
offer intuitive explanations but typically operate at coarse granularity
(sentence or document level) and fail to address the multi-label nature of
real-world text classification. We propose ProtoSiTex, a semi-interpretable
framework designed for fine-grained multi-label text classification. ProtoSiTex
employs a dual-phase alternating training strategy: an unsupervised prototype
discovery phase that learns semantically coherent and diverse prototypes, and a
supervised classification phase that maps these prototypes to class labels. A
hierarchical loss function enforces consistency across sub-sentence, sentence,
and document levels, enhancing interpretability and alignment. Unlike prior
approaches, ProtoSiTex captures overlapping and conflicting semantics using
adaptive prototypes and multi-head attention. We also introduce a benchmark
dataset of hotel reviews annotated at the sub-sentence level with multiple
labels. Experiments on this dataset and two public benchmarks (binary and
multi-class) show that ProtoSiTex achieves state-of-the-art performance while
delivering faithful, human-aligned explanations, establishing it as a robust
solution for semi-interpretable multi-label text classification.

</details>


### [277] [HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games](https://arxiv.org/abs/2510.12563)
*Jingcong Liang,Shijun Wan,Xuehai Wu,Siyuan Wang,Yitong Li,Qianglong Chen,Duyu Tang,Zhongyu Wei*

Main category: cs.AI

TL;DR: LRMs在逻辑益智游戏中表现出色，但对于新规则和变体的适应性仍是未知数。本研究提出了HardcoreLogic基准，包含5000多个跨越10种游戏的谜题，用于测试LRMs在长尾逻辑游戏上的鲁棒性。研究通过增加复杂性、引入非常规元素和包含无解谜题来改造传统谜题，以减少对记忆的依赖。评估结果显示，即使是现有基准上的高分模型，在HardcoreLogic上也表现出显著的性能下降，表明它们过度依赖记忆。模型在面对复杂性增加和细微规则变化时都遇到困难，错误分析揭示了其在真正推理方面的不足。HardcoreLogic暴露了当前LRMs的局限性，并为提升高级逻辑推理能力设定了基准。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRMs）在处理逻辑益智游戏时表现出强大的能力，但它们能否灵活运用规则来适应非标准的游戏变体仍是一个悬而未决的问题。现有的数据集主要集中在常见的谜题上，这可能导致模型过拟合到标准格式并记忆解题模式，从而掩盖了它们在理解新规则或适应新策略方面的不足。因此，有必要创建一个更具挑战性的基准来全面评估LRMs的推理能力。

Method: 本研究引入了一个名为HardcoreLogic的新基准，其中包含超过5000个跨越10种不同逻辑游戏的谜题。该基准通过三个维度系统性地改造了传统谜题：增加复杂性（IC）、引入非常规元素（UE）以及包含无解谜题（UP），目的是减少模型对捷径式记忆的依赖。研究团队在多种LRMs上进行了评估。

Result: 在HardcoreLogic基准上的评估结果显示，即使是那些在现有基准上取得高分的模型，也出现了显著的性能下降。这表明这些模型在很大程度上依赖于记忆已有的模式。研究发现，尽管复杂性的增加是导致模型困难的主要因素，但模型在处理那些不一定会增加谜题难度但涉及细微规则变化的场景时也遇到了挑战。通过对可解和不可解谜题的系统性错误分析，进一步揭示了模型在真正推理能力方面的差距。

Conclusion: HardcoreLogic基准的评估结果揭示了当前大型推理模型（LRMs）在处理长尾逻辑游戏和非标准变体时存在的局限性。研究表明，现有模型在很大程度上依赖于记忆而非真正的逻辑推理能力，并且在面对复杂性增加和细微规则变化时表现不佳。HardcoreLogic的提出为衡量和改进LRMs的高级逻辑推理能力提供了一个重要的基准。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance on
complex tasks, including logical puzzle games that require deriving solutions
satisfying all constraints. However, whether they can flexibly apply
appropriate rules to varying conditions, particularly when faced with
non-canonical game variants, remains an open question. Existing corpora focus
on popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats
and memorization of solution patterns, which can mask deficiencies in
understanding novel rules or adapting strategies to new variants. To address
this, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles
across 10 games, designed to test the robustness of LRMs on the "long-tail" of
logical games. HardcoreLogic systematically transforms canonical puzzles
through three dimensions: Increased Complexity (IC), Uncommon Elements (UE),
and Unsolvable Puzzles (UP), reducing reliance on shortcut memorization.
Evaluations on a diverse set of LRMs reveal significant performance drops, even
for models achieving top scores on existing benchmarks, indicating heavy
reliance on memorized stereotypes. While increased complexity is the dominant
source of difficulty, models also struggle with subtle rule variations that do
not necessarily increase puzzle difficulty. Our systematic error analysis on
solvable and unsolvable puzzles further highlights gaps in genuine reasoning.
Overall, HardcoreLogic exposes the limitations of current LRMs and establishes
a benchmark for advancing high-level logical reasoning.

</details>


### [278] [Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2510.12635)
*Yuxiang Zhang,Jiangming Shu,Ye Ma,Xueyuan Lin,Shangxi Wu,Jitao Sang*

Main category: cs.AI

TL;DR: 大型语言模型在处理长时序任务时面临内存限制，现有方法依赖外部机制。本研究提出将工作记忆管理视为可学习的内在能力，通过“Memory-as-Action”框架，代理能够通过明确的编辑操作来管理其工作记忆，并将此作为统一策略的一部分。这种方法允许代理在强化学习的训练下，在给定资源限制下平衡记忆管理与长期任务目标。然而，这种记忆编辑操作会破坏LLM交互中连续增长前缀的标准假设，导致“轨迹断裂”，从而使标准策略梯度方法失效。为解决此问题，我们提出了一种新的算法——动态上下文策略优化（DCPO），它通过在记忆操作点分割轨迹并将轨迹级优势应用于由此产生的动作段，来实现稳定的端到端强化学习。我们的结果表明，端到端地联合优化任务推理和记忆管理，不仅降低了计算消耗，而且通过针对模型内在能力的自适应上下文管理策略，提高了任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长时序任务中因内存限制而难以处理，现有外部工作记忆管理方法与核心策略脱节。

Method: 提出“Memory-as-Action”框架，将工作记忆管理视为可学习的内在能力，代理通过显式编辑操作进行管理。提出动态上下文策略优化（DCPO）算法，通过分割轨迹和应用轨迹级优势来解决记忆编辑操作破坏因果连续性的问题，实现端到端强化学习。

Result: 与现有方法相比，联合优化任务推理和记忆管理能降低计算消耗，并通过自适应上下文管理策略提高任务性能。

Conclusion: “Memory-as-Action”框架和DCPO算法能够有效地解决大型语言模型在长时序任务中的工作记忆挑战，实现端到端学习，提高性能并降低计算成本。

Abstract: Large Language Models face challenges in long-horizon agentic tasks as their
constrained memory is easily overwhelmed by distracting or irrelevant context.
Existing working memory methods typically rely on external, heuristic
mechanisms that are decoupled from the agent's core policy. In this work, we
reframe working memory management as a learnable, intrinsic capability. We
propose a novel framework, Memory-as-Action, where an agent actively manages
its working memory by executing explicit editing operations as part of a
unified policy. This formulation allows an agent, trained via reinforcement
learning, to balance memory curation against long-term task objectives under
given resource constraints. However, such memory editing actions break the
standard assumption of a continuously growing prefix in LLM interactions,
leading to what we call trajectory fractures. These non-prefix changes disrupt
the causal continuity required by standard policy gradient methods, making
those methods inapplicable. To address this, we propose a new algorithm,
Dynamic Context Policy Optimization, which enables stable end-to-end
reinforcement learning by segmenting trajectories at memory action points and
applying trajectory-level advantages to the resulting action segments. Our
results demonstrate that jointly optimizing for task reasoning and memory
management in an end-to-end fashion not only reduces overall computational
consumption but also improves task performance, driven by adaptive context
curation strategies tailored to the model's intrinsic capabilities.

</details>


### [279] [ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning](https://arxiv.org/abs/2510.12693)
*Hanyang Chen,Mark Zhao,Rui Yang,Qinwei Ma,Ke Yang,Jiarui Yao,Kangrui Wang,Hao Bai,Zhenhailong Wang,Rui Pan,Mengchao Zhang,Jose Barreiros,Aykut Onol,ChengXiang Zhai,Heng Ji,Manling Li,Huan Zhang,Tong Zhang*

Main category: cs.AI

TL;DR: ERA是一个两阶段框架，通过结合预训练知识和在线强化学习来提升小型视觉语言模型在具身智能任务中的表现，并取得了优于大型模型的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（VLMs）在具身AI任务中表现优异，但部署成本高昂，而小型模型则能力不足。ERA旨在弥合这一差距，通过结合预训练知识和在线强化学习，使小型模型也能在复杂环境中进行感知、推理和交互。

Method: ERA框架包含两个阶段：1. 具身先验学习：通过轨迹增强先验、环境锚定先验和外部知识先验，从不同类型的数据中提取和注入基础知识。2. 在线强化学习：在预训练知识的基础上，通过自总结、密集奖励塑形和回合级策略优化等方法，克服长距离、稀疏奖励和训练不稳定的挑战，进一步提升模型性能。

Result: 在EB-ALFRED（高层规划）和EB-Manipulation（低层控制）任务上，ERA-3B均取得了优于GPT-4o等大型模型和先前训练基线的结果，分别在EB-ALFRED上提升了8.4%，在EB-Manipulation上提升了19.4%，并展现出良好的泛化能力。

Conclusion: ERA框架为实现可扩展的具身智能提供了一条切实可行的路径，并为未来的具身AI系统提供了方法学上的启示。它证明了通过结合预训练知识和在线强化学习，可以在保证效率的同时，提升小型模型在具身智能任务上的能力。

Abstract: Recent advances in embodied AI highlight the potential of vision language
models (VLMs) as agents capable of perception, reasoning, and interaction in
complex environments. However, top-performing systems rely on large-scale
models that are costly to deploy, while smaller VLMs lack the necessary
knowledge and skills to succeed. To bridge this gap, we present
\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates
prior knowledge learning and online reinforcement learning (RL). The first
stage, \textit{Embodied Prior Learning}, distills foundational knowledge from
three types of data: (1) Trajectory-Augmented Priors, which enrich existing
trajectory data with structured reasoning generated by stronger models; (2)
Environment-Anchored Priors, which provide in-environment knowledge and
grounding supervision; and (3) External Knowledge Priors, which transfer
general knowledge from out-of-environment datasets. In the second stage, we
develop an online RL pipeline that builds on these priors to further enhance
agent performance. To overcome the inherent challenges in agent RL, including
long horizons, sparse rewards, and training instability, we introduce three key
designs: self-summarization for context management, dense reward shaping, and
turn-level policy optimization. Extensive experiments on both high-level
planning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate
that ERA-3B surpasses both prompting-based large models and previous
training-based baselines. Specifically, it achieves overall improvements of
8.4\% on EB-ALFRED and 19.4\% on EB-Manipulation over GPT-4o, and exhibits
strong generalization to unseen tasks. Overall, ERA offers a practical path
toward scalable embodied intelligence, providing methodological insights for
future embodied AI systems.

</details>


### [280] [Multi-Agent Debate for LLM Judges with Adaptive Stability Detection](https://arxiv.org/abs/2510.12697)
*Tianyu Hu,Zhen Tan,Song Wang,Huaizhi Qu,Tianlong Chen*

Main category: cs.AI

TL;DR: LLM-as-Judges 的多智能体辩论框架通过迭代推理和稳定性检测提高了判断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM-as-Judges 方法依赖于简单的聚合方法（例如，多数投票），这可能无法在个体代理提供正确答案时取得最佳效果。

Method: 提出了一种多智能体辩论框架，其中智能体进行协作推理和迭代改进。通过数学方法对辩论过程进行形式化，并引入一种通过时变 Beta-二项混合模型来模拟评判者共识动态的稳定性检测机制，并基于分布相似性（Kolmogorov-Smirnov 检验）进行自适应停止。

Result: 与多数投票相比，该框架在多个基准测试和模型上均提高了判断准确性，同时保持了计算效率。

Conclusion: 该研究提出了一个改进的 LLM 评判框架，通过辩论和先进的停止机制提高了准确性和效率。

Abstract: With advancements in reasoning capabilities, Large Language Models (LLMs) are
increasingly employed for automated judgment tasks. While LLMs-as-Judges offer
promise in automating evaluations, current approaches often rely on simplistic
aggregation methods (e.g., majority voting), which can fail even when
individual agents provide correct answers. To address this, we propose a
multi-agent debate judge framework where agents collaboratively reason and
iteratively refine their responses. We formalize the debate process
mathematically, analyzing agent interactions and proving that debate amplifies
correctness compared to static ensembles. To enhance efficiency, we introduce a
stability detection mechanism that models judge consensus dynamics via a
time-varying Beta-Binomial mixture, with adaptive stopping based on
distributional similarity (Kolmogorov-Smirnov test). This mechanism models the
judges' collective correct rate dynamics using a time-varying mixture of
Beta-Binomial distributions and employs an adaptive stopping criterion based on
distributional similarity (Kolmogorov-Smirnov statistic). Experiments across
multiple benchmarks and models demonstrate that our framework improves judgment
accuracy over majority voting while maintaining computational efficiency.

</details>


### [281] [CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction](https://arxiv.org/abs/2510.12703)
*Mattia Grasselli,Angelo Porrello,Carlo Augusto Grazia*

Main category: cs.AI

TL;DR: CAMNet利用合作感知消息（CAM）数据进行车辆轨迹预测，并取得了有前景的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中传感器视线受阻导致态势感知能力下降的问题，利用车车通信共享信息至关重要。

Method: 设计并训练了一个基于CAM数据的图神经网络（CAMNet），并在两个数据集上进行了评估。

Result: CAMNet在利用CAM数据进行车辆轨迹预测方面表现出有前景的结果。

Conclusion: CAM数据可以有效地用于车辆轨迹预测，但也存在一些局限性，为未来的研究提供了方向。

Abstract: Autonomous driving remains a challenging task, particularly due to safety
concerns. Modern vehicles are typically equipped with expensive sensors such as
LiDAR, cameras, and radars to reduce the risk of accidents. However, these
sensors face inherent limitations: their field of view and line of sight can be
obstructed by other vehicles, thereby reducing situational awareness. In this
context, vehicle-to-vehicle communication plays a crucial role, as it enables
cars to share information and remain aware of each other even when sensors are
occluded. One way to achieve this is through the use of Cooperative Awareness
Messages (CAMs). In this paper, we investigate the use of CAM data for vehicle
trajectory prediction. Specifically, we design and train a neural network,
Cooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely
used motion forecasting dataset. We then evaluate the model on a second dataset
that we created from scratch using Cooperative Awareness Messages, in order to
assess whether this type of data can be effectively exploited. Our approach
demonstrates promising results, showing that CAMs can indeed support vehicle
trajectory prediction. At the same time, we discuss several limitations of the
approach, which highlight opportunities for future research.

</details>


### [282] [Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection](https://arxiv.org/abs/2510.12713)
*Wissam Salhab,Darine Ameyed,Hamid Mcheick,Fehmi Jaafar*

Main category: cs.AI

TL;DR: 该方法利用自监督学习和图论技术，在无需标记数据的情况下提高了OOD检测的鲁棒性，AUROC达到0.99。


<details>
  <summary>Details</summary>
Motivation: AI系统在安全关键应用中必须保持可靠性和准确性，尤其是在面对OOD样本、对抗性攻击和环境变化时。

Method: 提出一种利用自监督学习原理从无标签数据中学习有用表征，并结合图论技术来识别和分类OOD样本的方法。

Result: 与现有最先进的方法相比，该方法在OOD检测方面表现出色，AUROC达到0.99。

Conclusion: 该方法有效地提高了AI系统的鲁棒性，特别是在OOD检测方面，并且无需标记数据。

Abstract: Robustness in AI systems refers to their ability to maintain reliable and
accurate performance under various conditions, including out-of-distribution
(OOD) samples, adversarial attacks, and environmental changes. This is crucial
in safety-critical systems, such as autonomous vehicles, transportation, or
healthcare, where malfunctions could have severe consequences. This paper
proposes an approach to improve OOD detection without the need of labeled data,
thereby increasing the AI systems' robustness. The proposed approach leverages
the principles of self-supervised learning, allowing the model to learn useful
representations from unlabeled data. Combined with graph-theoretical
techniques, this enables the more efficient identification and categorization
of OOD samples. Compared to existing state-of-the-art methods, this approach
achieved an Area Under the Receiver Operating Characteristic Curve (AUROC) =
0.99.

</details>


### [283] [Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing](https://arxiv.org/abs/2510.12732)
*Myles Foley,Sergio Maffeis,Muhammad Fakhrur Rozi,Takeshi Takahashi*

Main category: cs.AI

TL;DR: CLUTCH是一种结合了深度学习和组合赌博机的JavaScript模糊测试新方法，通过智能选择变异目标来提高效率和代码覆盖率，并在多种设置下优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有JavaScript模糊测试技术使用随机选择变异目标，效率不高。作者提出将选择变异目标的问题视为一个具有可变数量臂的组合赌博机问题。

Method: 提出CLUTCH，一种新颖的深度组合赌博机。该方法利用深度学习中的注意力机制来处理可变长度的JavaScript测试用例表示，并使用具体Dropout动态适应探索。

Result: CLUTCH在JavaScript模糊测试中，与三种最先进的解决方案相比，平均有效测试用例数量和每个测试用例的覆盖率分别提高了20.3%和8.9%。在易变和组合设置下，CLUTCH的遗憾分别减少了至少78.1%和4.1%。

Conclusion: CLUTCH在JavaScript模糊测试中表现出比现有技术更高的效率和覆盖率，尤其在易变和组合环境中，其性能优越。

Abstract: JavaScript engines are widely used in web browsers, PDF readers, and
server-side applications. The rise in concern over their security has led to
the development of several targeted fuzzing techniques. However, existing
approaches use random selection to determine where to perform mutations in
JavaScript code. We postulate that the problem of selecting better mutation
targets is suitable for combinatorial bandits with a volatile number of arms.
Thus, we propose CLUTCH, a novel deep combinatorial bandit that can observe
variable length JavaScript test case representations, using an attention
mechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can
dynamically adapt its exploration. We show that CLUTCH increases efficiency in
JavaScript fuzzing compared to three state-of-the-art solutions by increasing
the number of valid test cases and coverage-per-testcase by, respectively,
20.3% and 8.9% on average. In volatile and combinatorial settings we show that
CLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1%
less regret in volatile and combinatorial settings, respectively.

</details>


### [284] [CTRL-Rec: Controlling Recommender Systems With Natural Language](https://arxiv.org/abs/2510.12742)
*Micah Carroll,Adeline Foote,Kevin Feng,Marcus Williams,Anca Dragan,W. Bradley Knox,Smitha Milli*

Main category: cs.AI

TL;DR: CTRL-Rec是一种通过自然语言请求实时、高效地控制推荐系统的方法，能提升用户满意度和控制感。


<details>
  <summary>Details</summary>
Motivation: 用户对推荐系统不满意时，通常缺乏精细的控制手段来调整推荐结果。大型语言模型（LLM）可以通过自然语言请求为用户提供解决方案。

Method: 在训练时，利用LLM模拟用户对基于其语言请求的物品的批准情况，并训练能够近似这些模拟判断的嵌入模型。然后将这些用户请求的预测整合到传统推荐系统优化的标准信号权重中。在部署时，每次用户请求只需一次LLM嵌入计算，即可实现推荐的实时控制。

Result: 在MovieLens数据集上的实验表明，该方法能够跨多种请求类型进行精细控制。在一项涉及19名Letterboxd用户的研究中，与传统控制相比，CTRL-Rec受到了用户的积极评价，并显著增强了用户对推荐的控制感和满意度。

Conclusion: CTRL-Rec能够通过自然语言请求为传统推荐系统提供实时、高效的精细化控制，提升用户体验。

Abstract: When users are dissatisfied with recommendations from a recommender system,
they often lack fine-grained controls for changing them. Large language models
(LLMs) offer a solution by allowing users to guide their recommendations
through natural language requests (e.g., "I want to see respectful posts with a
different perspective than mine"). We propose a method, CTRL-Rec, that allows
for natural language control of traditional recommender systems in real-time
with computational efficiency. Specifically, at training time, we use an LLM to
simulate whether users would approve of items based on their language requests,
and we train embedding models that approximate such simulated judgments. We
then integrate these user-request-based predictions into the standard weighting
of signals that traditional recommender systems optimize. At deployment time,
we require only a single LLM embedding computation per user request, allowing
for real-time control of recommendations. In experiments with the MovieLens
dataset, our method consistently allows for fine-grained control across a
diversity of requests. In a study with 19 Letterboxd users, we find that
CTRL-Rec was positively received by users and significantly enhanced users'
sense of control and satisfaction with recommendations compared to traditional
controls.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [285] [Multi-objective Bayesian Optimization with Human-in-the-Loop for Flexible Neuromorphic Electronics Fabrication](https://arxiv.org/abs/2510.11727)
*Benius Dunn,Javier Meza-Arroyo,Armi Tiihonen,Mark Lee,Julia W. P. Hsu*

Main category: cs.ET

TL;DR: 使用多目标贝叶斯优化（MOBO）和包含失败实验的人工智能（HITL）框架，优化了光子固化工艺，以在柔性金属氧化物介电材料中实现具有大电容-频率色散和低漏电流的忆阻器。


<details>
  <summary>Details</summary>
Motivation: 金属氧化物材料在制造柔性忆阻电子器件方面具有潜力，但其加工受到氧化物与聚合物基板不相容性的限制。本研究旨在通过优化光子固化工艺来克服这一挑战，以制造可溶液加工的氧化铝介电材料，并满足忆阻应用的特定要求。

Method: 采用光子固化技术制造柔性金属-绝缘体-金属（MIM）电容器，并使用溶液加工的氧化铝作为电介质。应用多目标贝叶斯优化（MOBO）来确定能够优化电容-频率色散和低漏电流之间权衡的光子固化条件。此外，还开发了一个包含失败实验的人工智能（HITL）框架，将这些实验纳入MOBO机器学习工作流，以加速优化过程。通过Shapley Additive exPlanations（SHAP）分析了不同Pareto最优条件下介电特性的调整，并获得了不同输入参数重要性的见解。

Result: 成功利用光子固化和MOBO+HITL框架优化了柔性氧化铝介电材料的加工工艺，实现了大电容-频率色散和低漏电流的忆阻器。SHAP分析揭示了不同工艺参数对器件性能的影响，为进一步优化提供了指导。

Conclusion: 提出的结合MOBO和HITL反馈的框架，能够有效地解决多目标实验优化问题，尤其适用于具有相互关联的输入和高实验失败率的场景，为机器学习模型生成可用结果。该方法可广泛应用于其他多目标实验优化领域。

Abstract: Neuromorphic computing hardware enables edge computing and can be implemented
in flexible electronics for novel applications. Metal oxide materials are
promising candidates for fabricating flexible neuromorphic electronics, but
suffer from processing constraints due to the incompatibilities between oxides
and polymer substrates. In this work, we use photonic curing to fabricate
flexible metal-insulator-metal capacitors with solution-processible aluminum
oxide dielectric tailored for neuromorphic applications. Because photonic
curing outcomes depend on many input parameters, identifying an optimal
processing condition through a traditional grid-search approach is unfeasible.
Here, we apply multi-objective Bayesian optimization (MOBO) to determine
photonic curing conditions that optimize the trade-off between desired
electrical properties of large capacitance-frequency dispersion and low leakage
current. Furthermore, we develop a human-in-the-loop (HITL) framework for
incorporating failed experiments into the MOBO machine learning workflow,
demonstrating that this framework accelerates optimization by reducing the
number of experimental rounds required. Once optimization is concluded, we
analyze different Pareto-optimal conditions to tune the dielectrics properties
and provide insight into the importance of different inputs through Shapley
Additive exPlanations analysis. The demonstrated framework of combining MOBO
with HITL feedback can be adapted to a wide range of multi-objective
experimental problems that have interconnected inputs and high experimental
failure rates to generate usable results for machine learning models.

</details>


### [286] [Wireless Sensing of Temperature, Strain and Crack Growth in 3D-Printed Metal Structures via Magnetoelastic and Thermomagnetic Inclusions](https://arxiv.org/abs/2510.11730)
*Connor G. McMahan,Gavin Chang,Raymond Nguyen,Souren Soukiazian,David A. Smith,Tobias Schaedler,David Shahan*

Main category: cs.ET

TL;DR: 该研究首次实现了在3D打印金属结构中进行无线应变和温度传感，利用标准的电磁检测硬件，为按需维护和延长设备使用寿命提供了可能。


<details>
  <summary>Details</summary>
Motivation: 为了实现按需维护，减少定期计划性维护拆卸的依赖，并延长在恶劣环境中运行的结构的使用寿命，需要对损伤进行准确评估。

Method: 将磁弹性 तसेच热磁材料封装在微管内，并在增材制造过程中嵌入这些传感元件。机械和热刺激会改变嵌入材料的磁导率，进而调制置于打印部件表面或附近的线圈的阻抗。

Result: 实现了+/-0.75oC（70oC范围）的温度传感精度和+/-27x10^-6（6x10^-4应变范围）的应变传感精度，置信度为95%。能够提前数千个循环检测到塑性起始和疲劳裂纹扩展。

Conclusion: 该技术将非破坏性涡流损伤检测扩展到金属结构中精确的实时应变和温度监测。

Abstract: In this study, we demonstrate the first realization of wireless strain and
temperature sensing within 3D-printed metallic structures using standard
electromagnetic inspection hardware. This establishes a path toward need-based
parts maintenance driven by accurate damage assessments instead of relying on
regularly scheduled maintenance teardowns, extending the service intervals of
structures operating in harsh environments. To this end, we encapsulate
magnetoelastic and thermomagnetic materials inside microtubes and embed the
sensing elements during additive manufacturing. Mechanical and thermal stimuli
affect the magnetic permeability of the embedded materials, which modulates the
impedance of a coil placed on or near the surface of the printed part. We
demonstrate strain sensing accurate to +/-27x10-6 over at least a 6x10-4 strain
range, and temperature sensing accurate to +/-0.75oC over a 70oC range, both to
a 95% confidence interval. We highlight these sensors' capabilities by
detecting the onset of plasticity and fatigue-driven crack growth thousands of
cycles before critical failure. This extends non-destructive eddy-current
damage detection to accurate, real-time strain and temperature monitoring
within metallic structures.

</details>


### [287] [Quantum Annealing for Staff Scheduling in Educational Environments](https://arxiv.org/abs/2510.12278)
*Alessia Ciacco,Francesca Guerriero,Eneko Osaba*

Main category: cs.ET

TL;DR: 该论文提出了一个新颖的员工分配问题，旨在解决学校多站点和多教育级别间的协作人员分配问题。研究源于意大利卡拉布里亚一所公立学校的实际案例，需要在考虑可用性、能力和公平性的约束下，将员工分配到幼儿园、小学和中学。为解决此问题，研究开发了一个优化模型，并探索了一种基于量子退火的解决方案。通过在真实世界数据上进行的计算实验，结果表明量子退火能够在短时间内生成均衡的分配方案。这些结果证明了量子优化方法在教育调度和更广泛的复杂资源分配任务中的实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 组织协作人员在多学校站点和教育层级之间进行分配。

Method: 开发了一个优化模型，并研究了一种基于量子退火的解决方案方法。

Result: 量子退火能够在短时间内生成均衡的分配方案。

Conclusion: 量子退火方法在教育调度和复杂的资源分配任务中具有实际应用潜力。

Abstract: We address a novel staff allocation problem that arises in the organization
of collaborators among multiple school sites and educational levels. The
problem emerges from a real case study in a public school in Calabria, Italy,
where staff members must be distributed across kindergartens, primary, and
secondary schools under constraints of availability, competencies, and
fairness. To tackle this problem, we develop an optimization model and
investigate a solution approach based on quantum annealing. Our computational
experiments on real-world data show that quantum annealing is capable of
producing balanced assignments in short runtimes. These results provide
evidence of the practical applicability of quantum optimization methods in
educational scheduling and, more broadly, in complex resource allocation tasks.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [288] [Quantification of Electrolyte Degradation in Lithium-ion Batteries with Neutron Imaging Techniques](https://arxiv.org/abs/2510.12055)
*Yonggang Hu,Yiqing Liao,Lufeng Yang,Ke Zhang,Yufan Peng,Shijun Tang,Shengxiang Wang,Meifang Ding,Jiahao Wu,Jianrong Lin,Jinding Liang,Yimin Wei,Yanting Jin,Zhengliang Gong,Anatoliy Senyshyn,Jie Chen,Yong Yang*

Main category: physics.app-ph

TL;DR: 这项研究使用中子成像技术，以~150 um的空间分辨率和20x20 cm2的大视场，量化分析了LiFePO4/石墨软包电池在高温加速老化过程中的电解液体积分数和分布。通过定量标准曲线，确定了电解液干涸阈值为3.18 g Ah-1，并量化了电解液指数（EI）在电池老化过程中的两个演化阶段。研究还结合了非破坏性电化学诊断、TOF-SIMS和SEM分析，发现高EI电池具有均匀的SEI生长和较低的退化，而低EI电池则出现不均匀的SEI形成，加速了容量损失。这项研究揭示了锂离子电池中动态的电解液渗透-消耗-干涸过程，为电池的可持续和耐用性开发提供了非破坏性和定量的见解。


<details>
  <summary>Details</summary>
Motivation: 现有非破坏性方法在研究锂离子电池（LIBs）电解液的渗透、分布和退化时，缺乏足够时空分辨率来精确观察和量化电解液。

Method: 采用具有~150 um空间分辨率和20x20 cm2视场的中子成像技术，结合定量标准曲线，分析了LiFePO4/石墨软包电池在高温加速老化过程中的电解液行为。同时，集成了非破坏性电化学诊断、TOF-SIMS和SEM等技术进行综合分析。

Result: 研究确定了电解液干涸阈值为3.18 g Ah-1，并量化了电解液指数（EI）在电池老化过程中的两个演化阶段。发现在孔隙干燥过程中，存在加速石墨材料损失和液相Li+扩散退化。通过对中子透射信号的分析，发现孔隙干燥不发生时，可以定量分离出电极在老化过程中的SEI信号。高EI电池表现出均匀的SEI生长和较少的退化，而低EI电池则出现不均匀的SEI形成，导致容量快速损失。

Conclusion: 这项研究揭示了锂离子电池中动态的电解液渗透-消耗-干涸过程，为电池的可持续和耐用性开发提供了非破坏性和定量的见解。研究结果表明，电解液体积分数和分布对电池的性能和寿命至关重要。

Abstract: Non-destructive characterization of lithium-ion batteries provides critical
insights for optimizing performance and lifespan while preserving structural
integrity. Optimizing electrolyte design in commercial LIBs requires
consideration of composition, electrolyte-to-capacity ratio, spatial
distribution, and associated degradation pathways. However, existing
non-destructive methods for studying electrolyte infiltration, distribution,
and degradation in LIBs lack the spatiotemporal resolution required for precise
observation and quantification of the electrolyte. In this study, we employ
neutron imaging with sufficient spatial resolution ~150 um and large field of
view 20x20 cm2 to quantitatively resolve the electrolyte inventory and
distribution within LiFePO4/graphite pouch cells under high-temperature
accelerated aging. Quantitative standard curves based on neutron transmission
attenuation reveal a clear electrolyte dry-out threshold at 3.18 g Ah-1 and the
two stages evolutions of EI during cell aging were quantified. By integrating
non-destructive electrochemical diagnostics, accelerated graphite material loss
and liquid phase Li+ diffusion degradation is observed during pore-drying.
Further analysis, including operando cyclic aging, reveals that the neutron
transmission below the saturation reference is due to the enrichment of
hydrogen nuclei within the solid-electrolyte interphase. Assumed pore-drying
does not occur, the SEI signal of the electrodes can be quantitatively
decoupled during ageing. Combined analyses with NI, TOF-SIMS, and SEM reveal
that high EI cells exhibit uniform SEI growth and reduced degradation, while
low EI cells show uneven SEI formation, accelerating capacity loss. This study
unveils a dynamic electrolyte infiltration-consumption-dry-out process in LIBs,
offering non-destructive and quantitative insights to guide sustainable and
durable battery development.

</details>


### [289] [Engineering Nonporous Polymer Hybrids with Suppressed Heat Conduction and Enhanced Flame Retardancy via Molecular and Filler Design](https://arxiv.org/abs/2510.12124)
*Henry Worden,Mihir Chandra,Yijie Zhou,Zarif Ahmad Razin Bhuiyan,Mouyang Cheng,Krishnamurthy Munusamy,Weiguo Hu,Weibo Yan,Siyu Wu,Ruipeng Li,Anna Chatterji,Todd Emrick,Jun Liu,Yanfei Xu*

Main category: physics.app-ph

TL;DR: 通过调控原子振动抑制热容，在非多孔聚合物/有机填料杂化体中实现超低热导率，并提升防火性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过调控原子振动抑制热容，在非多孔聚合物/有机填料杂化体中实现超低热导率，以增强隔热性能，并提高材料的防火性能。

Method: 结合实验和模拟，研究非多孔聚合物/有机填料杂化体的热输运机制，通过调控原子振动抑制热容。

Result: 与传统的聚合物/无机填料杂化体相比，本研究的杂化体界面热阻低一到三个数量级，并表现出增强的防火性能。

Conclusion: 本研究提出的非多孔聚合物/有机填料杂化体策略能够有效降低热导率并提升防火性能。

Abstract: This study presents a new strategy for achieving ultralow thermal
conductivity in nonporous polymer/organic filler hybrids by suppressing heat
capacity through tailored atomic vibrations to enhance thermal insulation.
Unlike conventional polymer/inorganic filler hybrids, these hybrids exhibit
interfacial thermal resistance one to three orders of magnitude lower. Combined
experiments and simulations uncover thermal transport mechanisms. These hybrids
demonstrate enhanced flame retardancy. Please see the abstract in the attached
PDF.

</details>


### [290] [Monitoring of Fluid Transport in Low Temperature Water Electrolyzers and Fuel Cells: Emerging Technologies and Future Prospects](https://arxiv.org/abs/2510.12542)
*Zehua Dou,Laura Tropf,Tobias Lappan,Hannes Rox,Xuegeng Yang,Lars Buettner,David Weik,Harry Hoster,Kerstin Eckert,Juergen Czarske*

Main category: physics.app-ph

TL;DR: 低压水电解槽和低压氢燃料电池（LTWEs/LTFCs）在绿色氢能生产和利用方面具有潜力，但流体传输和反应动力学的相互作用限制了其发展。本综述旨在提供一种全面的分析工具，以解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 低压水电解槽和低压氢燃料电池（LTWEs/LTFCs）在绿色氢能生产和利用方面具有潜力，但流体传输和反应动力学的相互作用限制了其发展，需要能够解决这些问题的分析工具。

Method: 本综述全面概述了用于研究流体传输的测量技术的最新进展，包括光学、X射线和中子成像系统，并强调了利用集成微型传感器、超声波和其他替代物理原理实现操作中、高分辨率和可扩展测量的策略。

Result: 本综述评估了现有光学、X射线和中子成像系统的能力和局限性，并强调了新兴的集成微型传感器、超声波和其他替代物理原理。

Conclusion: 需要开发下一代传感概念来克服流体传输的障碍，以加速绿色氢能技术的部署。

Abstract: Low temperature water electrolyzers (LTWEs) and low temperature hydrogen fuel
cells (LTFCs) present a promising technological strategy for the productions
and usages of green hydrogen energy towards a net-zero world. However, the
interactions of gas/liquid (fluid) transport and the intrinsic reaction
kinetics in LTWEs/LTFCs present one of the key hurdles hindering high
production rate and high energy conversion efficiency. Addressing these
limitations requires analytical tools that are capable of resolving fluid
transport across the heterogeneous, multiscale structures of operating LTWE and
LTFC systems. This review provides a comprehensive overview of recent
advancements in measurement technologies for investigating fluid transport. We
first outline the technical requirements of such analytical systems, and assess
the capabilities and limitations of established optical, X-rays and neutrons
based imaging systems. We emphasis on emerging strategies that utilize
integrated miniaturized sensors, ultrasound, and other alternative physical
principles to achieve operando, high-resolution, and scalable measurements
towards applications at device and system levels. Finally, we outline future
directions in this highly interdisciplinary field, emphasizing the importance
of next-generation sensing concepts to overcome the fluid transport hurdle,
towards accelerating the deployment of green hydrogen technologies.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [291] [Modeling Hypergraph Using Large Language Models](https://arxiv.org/abs/2510.11728)
*Bingqiao Gu,Jiale Zeng,Xingqin Qi,Dong Li*

Main category: cs.SI

TL;DR: LLM可用于生成满足真实网络特征的大规模超图，解决了真实超图数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 真实超图数据集稀缺，限制了超图学习算法的发展和评估，因此需要快速生成大规模超图的方法。

Method: 提出了一种名为HyperLLM的新型LLM驱动的超图生成器，该生成器通过多智能体协作模拟超图的形成和演化，并整合了提示和结构反馈机制。

Result: HyperLLM在结构和时间超图模式方面表现出优于真实性，并且只需要很少的统计先验知识。

Conclusion: 基于LLM的框架为超图建模提供了一个有前景的新方向。

Abstract: Due to the advantages of hypergraphs in modeling high-order relationships in
complex systems, they have been applied to higher-order clustering, hypergraph
neural networks and computer vision. These applications rely heavily on access
to high-quality, large-scale real-world hypergraph data. Yet, compared to
traditional pairwise graphs, real hypergraph datasets remain scarce in both
scale and diversity. This shortage significantly limits the development and
evaluation of advanced hypergraph learning algorithms. Therefore, how to
quickly generate large-scale hypergraphs that conform to the characteristics of
real networks is a crucial task that has not received sufficient attention.
Motivated by recent advances in large language models (LLMs), particularly
their capabilities in semantic reasoning, structured generation, and simulating
human behavior, we investigate whether LLMs can facilitate hypergraph
generation from a fundamentally new perspective. We introduce HyperLLM, a novel
LLM-driven hypergraph generator that simulates the formation and evolution of
hypergraphs through a multi-agent collaboration. The framework integrates
prompts and structural feedback mechanisms to ensure that the generated
hypergraphs reflect key real-world patterns. Extensive experiments across
diverse datasets demonstrate that HyperLLM achieves superior fidelity to
structural and temporal hypergraph patterns, while requiring minimal
statistical priors. Our findings suggest that LLM-based frameworks offer a
promising new direction for hypergraph modeling.

</details>


### [292] [Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed](https://arxiv.org/abs/2510.11739)
*Muhammad Hamza,Rizwan Jafar*

Main category: cs.SI

TL;DR: 本研究使用机器学习和深度学习技术，通过分析粉丝的乌尔都语推文来预测名人的性别、年龄、职业和名气，并在低资源语言乌尔都语上取得了初步成效。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在英语等高资源语言的名人画像，而乌尔都语领域的研究尚待探索。

Method: 收集并预处理了粉丝的乌尔都语推文数据集，并训练了包括逻辑回归、支持向量机、随机森林、卷积神经网络和长短期记忆网络在内的多种机器学习和深度学习模型，使用准确率、精确率、召回率、F1分数和累积排名（cRank）进行评估。

Result: 性别预测取得了最佳效果，cRank为0.65，准确率为0.65，而年龄、职业和名气预测结果则处于中等水平。

Conclusion: 基于粉丝语言特征的机器学习和深度学习方法可以有效地用于低资源语言乌尔都语的人口统计学预测。

Abstract: Social media has become an essential part of the digital age, serving as a
platform for communication, interaction, and information sharing. Celebrities
are among the most active users and often reveal aspects of their personal and
professional lives through online posts. Platforms such as Twitter provide an
opportunity to analyze language and behavior for understanding demographic and
social patterns. Since followers frequently share linguistic traits and
interests with the celebrities they follow, textual data from followers can be
used to predict celebrity demographics. However, most existing research in this
field has focused on English and other high-resource languages, leaving Urdu
largely unexplored.
  This study applies modern machine learning and deep learning techniques to
the problem of celebrity profiling in Urdu. A dataset of short Urdu tweets from
followers of subcontinent celebrities was collected and preprocessed. Multiple
algorithms were trained and compared, including Logistic Regression, Support
Vector Machines, Random Forests, Convolutional Neural Networks, and Long
Short-Term Memory networks. The models were evaluated using accuracy,
precision, recall, F1-score, and cumulative rank (cRank). The best performance
was achieved for gender prediction with a cRank of 0.65 and an accuracy of
0.65, followed by moderate results for age, profession, and fame prediction.
These results demonstrate that follower-based linguistic features can be
effectively leveraged using machine learning and neural approaches for
demographic prediction in Urdu, a low-resource language.

</details>


### [293] [Evolution of wartime discourse on Telegram: A comparative study of Ukrainian and Russian policymakers' communication before and after Russia's full-scale invasion of Ukraine](https://arxiv.org/abs/2510.11746)
*Mykola Makhortykh,Aytalina Kulichkina,Kateryna Maikovska*

Main category: cs.SI

TL;DR: 本文研究了俄乌战争期间精英在Telegram上的政治传播。


<details>
  <summary>Details</summary>
Motivation: 研究精英驱动的政治传播在俄乌战争这一大规模社交媒体战争背景下的变化。

Method: 收集了2019-2024年间乌克兰和俄罗斯政策制定者在Telegram上的公开帖子数据，分析了2022年俄罗斯全面入侵后传播量、主题内容和参与者的变化。

Result: 数据显示，入侵后Telegram活动急剧增加，特别是执政党政策制定者。乌克兰政策制定者最初关注战争相关话题，但随后减少。俄罗斯政策制定者则回避战争相关讨论，转而强调西方危机等无关话题以转移公众注意力。研究还发现不同规模政党和个体政策制定者在传播策略上的差异。

Conclusion: 精英的Telegram政治传播策略适应了战时挑战，并揭示了战争时期在线政治话语动态。

Abstract: This study examines elite-driven political communication on Telegram during
the ongoing Russo-Ukrainian war, the first large-scale European war in the
social media era. Using a unique dataset of Telegram public posts from
Ukrainian and Russian policymakers (2019-2024), we analyze changes in
communication volume, thematic content, and actor engagement following Russia's
2022 full-scale invasion. Our findings show a sharp increase in Telegram
activity after the invasion, particularly among ruling-party policymakers.
Ukrainian policymakers initially focused on war-related topics, but this
emphasis declined over time In contrast, Russian policymakers largely avoided
war-related discussions, instead emphasizing unrelated topics, such as Western
crises, to distract public attention. We also identify differences in
communication strategies between large and small parties, as well as individual
policymakers. Our findings shed light on how policymakers adapt to wartime
communication challenges and offer critical insights into the dynamics of
online political discourse during times of war.

</details>


### [294] [Structure-aware Propagation Generation with Large Language Models for Fake News Detection](https://arxiv.org/abs/2510.12125)
*Mengyang Chen,Lingwei Wei,Wei Zhou,Songlin Hu*

Main category: cs.SI

TL;DR: 本研究提出了一种名为StruSP的新框架，利用大型语言模型（LLM）生成合成传播数据来增强虚假新闻检测能力。该框架通过显式地在语义和结构层面将合成传播与真实传播对齐，并结合双向演化传播（BEP）学习策略，解决了现有方法数据不完整和忽视结构模式的问题。实验证明StruSP在不同场景下显著提高了虚假新闻检测性能，并使LLM能够生成更真实、更多样化的传播数据。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假新闻传播威胁公众信任和社会稳定。现有的基于传播的方法在数据不完整时效果不佳，而利用LLM生成合成传播的方法则忽略了真实讨论的结构模式。

Method: 提出StruSP框架，该框架通过显式对齐合成传播与真实传播的语义和结构维度，并设计了双向演化传播（BEP）学习策略（包括结构感知混合采样和掩码传播建模），来增强LLM生成真实且结构一致的传播数据，从而提高检测性能。

Result: 在三个公共数据集上的实验表明，StruSP在各种实际检测场景中显著提高了虚假新闻检测性能。进一步的分析表明，BEP策略使LLM能够生成在语义和结构上都更真实、更多样化的传播。

Conclusion: StruSP框架通过结合结构感知合成传播生成和BEP学习策略，能够有效提升虚假新闻检测的效果，并且能够生成更符合现实的传播数据。

Abstract: The spread of fake news on social media poses a serious threat to public
trust and societal stability. While propagation-based methods improve fake news
detection by modeling how information spreads, they often suffer from
incomplete propagation data. Recent work leverages large language models (LLMs)
to generate synthetic propagation, but typically overlooks the structural
patterns of real-world discussions. In this paper, we propose a novel
structure-aware synthetic propagation enhanced detection (StruSP) framework to
fully capture structural dynamics from real propagation. It enables LLMs to
generate realistic and structurally consistent propagation for better
detection. StruSP explicitly aligns synthetic propagation with real-world
propagation in both semantic and structural dimensions. Besides, we also design
a new bidirectional evolutionary propagation (BEP) learning strategy to better
align LLMs with structural patterns of propagation in the real world via
structure-aware hybrid sampling and masked propagation modeling objective.
Experiments on three public datasets demonstrate that StruSP significantly
improves fake news detection performance in various practical detection
scenarios. Further analysis indicates that BEP enables the LLM to generate more
realistic and diverse propagation semantically and structurally.

</details>


### [295] [CrisisNews: A Dataset Mapping Two Decades of News Articles on Online Problematic Behavior at Scale](https://arxiv.org/abs/2510.12243)
*Jeanne Choi,DongJae Kang,Yubin Choi,Juhoon Lee,Joseph Seering*

Main category: cs.SI

TL;DR: 该研究通过分析新闻报道，构建了一个包含93,250篇关于社交媒体危机的新闻文章的数据集，并对其中一部分进行了细致分析，以识别危机中的利益相关者角色、行为类型和结果，从而超越单纯基于内容的描述，为更精细地对社交媒体危机进行分类提供依据。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的全球普及，在线不良行为日益升级为大规模危机，需要不断更新的缓解策略。然而，现有的人机交互（HCI）研究大多以用户生成内容为分析单位，较少关注事件演变过程的视角。

Method: 本文提出了一种事件导向的视角，专注于追踪‘社交媒体危机’（在社交媒体中产生并演变的离散不良行为模式，并造成大规模危害）的演变过程。研究人员利用全球新闻报道，构建了一个包含93,250篇关于社交媒体危机的新闻文章的数据集，并分析了其中的代表性子集，对利益相关者角色、行为类型和结果进行了分类。

Result: 通过分析，研究发现了能够超越内容描述，为社交媒体危机提供更精细分类的模式。

Conclusion: 通过采取更宏观的视角，本研究旨在为设计更安全的平台提供信息，从而能够采取主动措施来缓解危机，并培养更值得信赖的在线环境。

Abstract: As social media adoption grows globally, online problematic behaviors
increasingly escalate into large-scale crises, requiring an evolving set of
mitigation strategies. While HCI research often analyzes problematic behaviors
with pieces of user-generated content as the unit of analysis, less attention
has been given to event-focused perspectives that track how discrete events
evolve. In this paper, we examine 'social media crises': discrete patterns of
problematic behaviors originating and evolving within social media that cause
larger-scale harms. Using global news coverage, we present a dataset of 93,250
news articles covering social media-endemic crises from the past 20 years. We
analyze a representative subset to classify stakeholder roles, behavior types,
and outcomes, uncovering patterns that inform more nuanced classification of
social media crises beyond content-based descriptions. By adopting a wider
perspective, this research seeks to inform the design of safer platforms,
enabling proactive measures to mitigate crises and foster more trustworthy
online environments.

</details>


### [296] [MOUFLON: Multi-group Modularity-based Fairness-aware Community Detection](https://arxiv.org/abs/2510.12348)
*Georgios Panayiotou,Anand Mathew Muthukulam Simon,Matteo Magnani,Ece Calikus*

Main category: cs.SI

TL;DR: MOUFLON是一种考虑公平性的、基于模块化的社区发现方法，可调节社区划分质量与公平性结果的重要性。它使用新颖的比例平衡公平性度量，在多群体和不平衡网络环境中提供一致且可比的公平性得分。研究了该方法在合成和真实网络数据集上的性能，以及模块化与公平性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的公平性感知社区发现方法MOUFLON，以解决现有方法在多群体和不平衡网络中公平性评估不一致的问题。

Method: MOUFLON采用基于模块化的社区发现方法，并引入了新颖的比例平衡公平性度量，允许调整社区划分质量和公平性结果的重要性。通过在合成和真实网络数据集上进行评估，考察了模块化与公平性之间的权衡以及网络特性（如大小、密度和群体分布）的影响。

Result: 研究结果表明，将公平性约束纳入基于模块化的社区发现方法会产生影响，并强调了在设计和评估公平性感知社交网络分析方法时的关键考虑因素。

Conclusion: MOUFLON在公平性社区发现方面提供了新的解决方案，尤其是在复杂网络环境中，并为未来的研究提供了指导。

Abstract: In this paper, we propose MOUFLON, a fairness-aware, modularity-based
community detection method that allows adjusting the importance of partition
quality over fairness outcomes. MOUFLON uses a novel proportional balance
fairness metric, providing consistent and comparable fairness scores across
multi-group and imbalanced network settings. We evaluate our method under both
synthetic and real network datasets, focusing on performance and the trade-off
between modularity and fairness in the resulting communities, along with the
impact of network characteristics such as size, density, and group
distribution. As structural biases can lead to strong alignment between
demographic groups and network structure, we also examine scenarios with highly
clustered homogeneous groups, to understand how such structures influence
fairness outcomes. Our findings showcase the effects of incorporating fairness
constraints into modularity-based community detection, and highlight key
considerations for designing and benchmarking fairness-aware social network
analysis methods.

</details>


### [297] [Timeliness, Consensus, and Composition of the Crowd: Community Notes on X](https://arxiv.org/abs/2510.12559)
*Olesya Razuvayevskaya,Adel Tayebi,Ulrikke Dybdal Sørensen,Kalina Bontcheva,Richard Rogers*

Main category: cs.SI

TL;DR: 该研究对X的社区笔记（一种众包审核系统）的效率进行了大规模定量分析，发现该系统存在参与不平等、少数贡献者主导、共识形成困难和时效性差等问题，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估X的社区笔记（一种众包审核系统）在识别和背景化潜在误导性内容方面的效率。

Method: 对超过180万条笔记进行分析，考察参与不平等、共识形成和及时性三个关键维度。

Result: 1. 贡献者集中度高：排名前10%的贡献者产生了58%的笔记（基尼系数=0.68）。
2. 共识形成困难：仅11.5%的笔记达成发表共识，69%的帖子收到冲突分类。
3. “笔记不需要”的帖子更有可能产生发表的笔记（优势比=3.12）。
4. 时效性差：笔记平均在原帖发布65.7小时后才发表，延迟越长，达成共识的可能性越低。

Conclusion: X的社区笔记系统是一个分层的、审议性的系统，由少数精英主导，存在持续的分歧，并受制于时效性。研究提出了促进公平、加速共识和提高认知可靠性的设计策略。

Abstract: This study presents the first large-scale quantitative analysis of the
efficiency of X's Community Notes, a crowdsourced moderation system for
identifying and contextualising potentially misleading content. Drawing on over
1.8 million notes, we examine three key dimensions of crowdsourced moderation:
participation inequality, consensus formation, and timeliness. Despite the
system's goal of collective moderation, we find substantial concentration
effect, with the top 10% of contributors producing 58% of all notes (Gini
Coefficient = 0.68). The observed consensus is rare-only 11.5% of notes reach
agreement on publication, while 69% of posts receive conflicting
classifications. A majority of noted posts (approximately 68%) are annotated as
"Note Not Needed", reflecting the repurposing of the platform for debate rather
than moderation. We found that such posts are paradoxically more likely to
yield published notes (OR = 3.12). Temporal analyses show that the notes, on
average, are published 65.7 hours after the original post, with longer delays
significantly reducing the likelihood of consensus. These results portray
Community Notes as a stratified, deliberative system dominated by a small
contributor elite, marked by persistent dissensus, and constrained by
timeliness. We conclude this study by outlining design strategies to promote
equity, faster consensus, and epistemic reliability in community-based
moderation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [298] [Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.11824)
*Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu*

Main category: cs.MA

TL;DR: 该论文研究了在多智能体强化学习（MARL）中，仅在理想模拟环境中调整超参数以最大化合作性能的常见做法，并指出这种做法往往无法保证在真实世界不确定性下的鲁棒性和韧性。论文通过大规模实证研究，评估了MARL在不同环境、不确定性类型和超参数下的合作、鲁棒性和韧性表现，强调了超参数调整对构建可信MARL系统的关键作用。


<details>
  <summary>Details</summary>
Motivation: 在合作式多智能体强化学习（MARL）中，通常的做法是在理想的模拟环境中调整超参数以最大化合作性能。然而，为合作而调整的策略在真实世界的各种不确定性下往往难以保持鲁棒性和韧性。为了构建可信赖的MARL系统，需要深入理解鲁棒性（确保在不确定性下的稳定性）和韧性（从干扰中恢复的能力），而韧性在控制系统中得到了广泛研究但在MARL中却被严重忽视。

Method: 进行了大规模实证研究，包含超过82,620次实验，评估了MARL在4个真实世界环境、13种不确定性类型和15个超参数下的合作、鲁棒性和韧性。

Result: 1. 在轻微不确定性下，优化合作能够提升鲁棒性和韧性，但随着干扰加剧，这种联系会减弱。鲁棒性和韧性也因算法和不确定性类型的不同而异。
2. 鲁棒性和韧性在不同不确定性模态或智能体范围之间不具有泛化性：对所有智能体的动作噪声具有鲁棒性的策略，在单个智能体的观察噪声下可能会失效。
3. 超参数调整对于可信MARL至关重要：令人惊讶的是，参数共享、GAE和PopArt等标准实践可能会损害鲁棒性，而提前停止、高Critic学习率和Leaky ReLU则能持续提供帮助。
4. 仅通过优化超参数，在所有MARL骨干方法中都观察到合作、鲁棒性和韧性的显著提升，并且这种现象也泛化到了鲁棒MARL方法上。

Conclusion: 大规模实证研究表明，在MARL中，仅优化超参数就能显著提升合作、鲁棒性和韧性，并能在不同算法和鲁棒MARL方法中实现泛化。这强调了超参数选择在构建可信MARL系统中的关键作用。

Abstract: In cooperative Multi-Agent Reinforcement Learning (MARL), it is a common
practice to tune hyperparameters in ideal simulated environments to maximize
cooperative performance. However, policies tuned for cooperation often fail to
maintain robustness and resilience under real-world uncertainties. Building
trustworthy MARL systems requires a deep understanding of robustness, which
ensures stability under uncertainties, and resilience, the ability to recover
from disruptions--a concept extensively studied in control systems but largely
overlooked in MARL. In this paper, we present a large-scale empirical study
comprising over 82,620 experiments to evaluate cooperation, robustness, and
resilience in MARL across 4 real-world environments, 13 uncertainty types, and
15 hyperparameters. Our key findings are: (1) Under mild uncertainty,
optimizing cooperation improves robustness and resilience, but this link
weakens as perturbations intensify. Robustness and resilience also varies by
algorithm and uncertainty type. (2) Robustness and resilience do not generalize
across uncertainty modalities or agent scopes: policies robust to action noise
for all agents may fail under observation noise on a single agent. (3)
Hyperparameter tuning is critical for trustworthy MARL: surprisingly, standard
practices like parameter sharing, GAE, and PopArt can hurt robustness, while
early stopping, high critic learning rates, and Leaky ReLU consistently help.
By optimizing hyperparameters only, we observe substantial improvement in
cooperation, robustness and resilience across all MARL backbones, with the
phenomenon also generalizing to robust MARL methods across these backbones.
Code and results available at
https://github.com/BUAA-TrustworthyMARL/adv_marl_benchmark .

</details>


### [299] [Heterogeneous RBCs via deep multi-agent reinforcement learning](https://arxiv.org/abs/2510.12272)
*Federico Gabriele,Aldo Glielmo,Marco Taboga*

Main category: cs.MA

TL;DR: MARL-BC框架结合了深度多智能体强化学习和真实业务周期模型，以克服传统宏观经济模型在处理异质性方面的局限性，并实现了与传统方法的兼容。


<details>
  <summary>Details</summary>
Motivation: 现有的异质性代理宏观经济模型要么是计算密集型且限制了异质性的程度（如HANK和KS模型），要么需要明确的行为规则且模型开发过程冗长（如ABM）。MARL-BC旨在解决这些限制。

Method: 提出MARL-BC框架，整合了深度多智能体强化学习（MARL）和真实业务周期（RBC）模型。

Result: MARL-BC在以下方面表现良好：1. 使用单个代理时，可以恢复标准的RBC模型结果；2. 使用大量相同代理时，可以恢复均值场KS模型的结果；3. 有效模拟代理间的丰富异质性，这是传统GE方法难以完成的任务。该框架在作为ABM使用时可以复制GE模型的极限情况结果。

Conclusion: MARL-BC框架作为ABM的一种形式，可以被视为结合了异质性代理模型和一般均衡模型这两种通常对立的建模范式的进步。

Abstract: Current macroeconomic models with agent heterogeneity can be broadly divided
into two main groups. Heterogeneous-agent general equilibrium (GE) models, such
as those based on Heterogeneous Agents New Keynesian (HANK) or Krusell-Smith
(KS) approaches, rely on GE and 'rational expectations', somewhat unrealistic
assumptions that make the models very computationally cumbersome, which in turn
limits the amount of heterogeneity that can be modelled. In contrast,
agent-based models (ABMs) can flexibly encompass a large number of arbitrarily
heterogeneous agents, but typically require the specification of explicit
behavioural rules, which can lead to a lengthy trial-and-error
model-development process. To address these limitations, we introduce MARL-BC,
a framework that integrates deep multi-agent reinforcement learning (MARL) with
Real Business Cycle (RBC) models. We demonstrate that MARL-BC can: (1) recover
textbook RBC results when using a single agent; (2) recover the results of the
mean-field KS model using a large number of identical agents; and (3)
effectively simulate rich heterogeneity among agents, a hard task for
traditional GE approaches. Our framework can be thought of as an ABM if used
with a variety of heterogeneous interacting agents, and can reproduce GE
results in limit cases. As such, it is a step towards a synthesis of these
often opposed modelling paradigms.

</details>


### [300] [Characterizing Agent-Based Model Dynamics via $ε$-Machines and Kolmogorov-Style Complexity](https://arxiv.org/abs/2510.12729)
*Roberto Garrone*

Main category: cs.MA

TL;DR: 提出一个两层信息论框架，用于表征复杂适应系统（CAS）范式内基于代理的模型（ABM）动力学的 the informational organization。宏观层面，重建一个集成的 ε-machine 作为总结系统范围 the informational regime 的参考模型。微观层面，为每个 the caregiver-elder dyad 和 variable 重建 ε-machines，并用与算法无关的 Kolmogorov-style 测量（包括归一化的 LZ78 复杂度和无损压缩的 bits per symbol）进行补充。由此产生的特征集 {h_μ, C_μ, E, LZ78, bps} 能够跨 the agents 和 scenarios 进行分布分析、分层比较和无监督聚类。这种双尺度设计保留了 the agent heterogeneity，同时提供了可解释的宏观 the baseline，使 ABM 实践与 CAS 的 the emergence、feedback 和 adaptation 原则相一致。对 the caregiver-elder interactions 的案例研究说明了该框架的实施；结果和 the discussion 将在 the final simulation runs 后完成。


<details>
  <summary>Details</summary>
Motivation: 提出一个两层信息论框架，用于表征复杂适应系统（CAS）范式内基于代理的模型（ABM）动力学的 the informational organization。

Method: 宏观层面，重建一个集成的 ε-machine 作为总结系统范围 the informational regime 的参考模型。微观层面，为每个 the caregiver-elder dyad 和 variable 重建 ε-machines，并用与算法无关的 Kolmogorov-style 测量（包括归一化的 LZ78 复杂度和无损压缩的 bits per symbol）进行补充。由此产生的特征集 {h_μ, C_μ, E, LZ78, bps} 能够跨 the agents 和 scenarios 进行分布分析、分层比较和无监督聚类。这种双尺度设计保留了 the agent heterogeneity，同时提供了可解释的宏观 the baseline，使 ABM 实践与 CAS 的 the emergence、feedback 和 adaptation 原则相一致。

Result: 对 the caregiver-elder interactions 的案例研究说明了该框架的实施；结果和 the discussion 将在 the final simulation runs 后完成。

Conclusion: 该框架能够跨 the agents 和 scenarios 进行分布分析、分层比较和无监督聚类。

Abstract: We propose a two-level information-theoretic framework for characterizing the
informational organization of Agent-Based Model (ABM) dynamics within the
broader paradigm of Complex Adaptive Systems (CAS). At the macro level, a
pooled $\epsilon$-machine is reconstructed as a reference model that summarizes
the system-wide informational regime. At the micro level, $\epsilon$-machines
are reconstructed for each caregiver-elder dyad and variable, and are
complemented with algorithm-agnostic Kolmogorov-style measures, including
normalized LZ78 complexity and bits per symbol from lossless compression. The
resulting feature set $\{h_{\mu}, C_{\mu}, E, \mathrm{LZ78}, \mathrm{bps}\}$
enables distributional analysis, stratified comparisons, and unsupervised
clustering across agents and scenarios. This dual-scale design preserves agent
heterogeneity while providing an interpretable macro-level baseline, aligning
ABM practice with CAS principles of emergence, feedback, and adaptation. A case
study on caregiver-elder interactions illustrates the framework's
implementation; the results and discussion will be completed following final
simulation runs.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [301] [Rationally Analyzing Shelby: Proving Incentive Compatibility in a Decentralized Storage Network](https://arxiv.org/abs/2510.11866)
*Michael Crystal,Guy Goren,Scott Duke Kominers*

Main category: cs.GT

TL;DR: Decentralized storage protocols often lack formal incentive analysis, potentially hindering true decentralization. This paper provides the first formal proof of incentive properties for the Shelby storage network protocol, showing its combination of peer and on-chain audits leads to incentive compatibility under certain conditions and suggesting a modification to improve collusion-resilience.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of formal incentive analysis in decentralized storage protocols, which is crucial for achieving true decentralization, and to provide the first formal proof of incentive properties for the Shelby storage network protocol.

Method: The paper uses a game-theoretic model to analyze Shelby's incentive properties, considering off-chain audits, occasional on-chain verification, and coalition behavior.

Result: The analysis shows that while off-chain audits alone lead to universal shirking, Shelby's combined approach of peer audits and on-chain verification achieves incentive compatibility under natural parameter settings. A simple modification is also proposed to enhance collusion-resilience.

Conclusion: Shelby's protocol, with its combination of peer audits and occasional on-chain verification, demonstrates incentive compatibility under natural parameter settings. The proposed modification can further strengthen its resilience against collusion.

Abstract: Decentralized storage is one of the most natural applications built on
blockchains and a central component of the Web3 ecosystem. Yet despite a decade
of active development -- from IPFS and Filecoin to more recent entrants -- most
of these storage protocols have received limited formal analysis of their
incentive properties. Claims of incentive compatibility are sometimes made, but
rarely proven. This gap matters: without well-designed incentives, a system may
distribute storage but fail to truly decentralize it.
  We analyze Shelby -- a storage network protocol recently proposed by Aptos
Labs and Jump Crypto -- and provide the first formal proof of its incentive
properties. Our game-theoretic model shows that while off-chain audits alone
collapse to universal shirking, Shelby's combination of peer audits with
occasional on-chain verification yields incentive compatibility under natural
parameter settings. We also examine coalition behavior and outline a simple
modification that strengthens the protocol's collusion-resilience.

</details>


### [302] [Fair Division of Indivisible Items](https://arxiv.org/abs/2510.12158)
*Kevin Hsu*

Main category: cs.GT

TL;DR: 该论文研究了不可分割物品的公平分配问题，重点关注混合物品（商品和事务）的MMS分配以及物品分配的EFX和EF1方向。


<details>
  <summary>Details</summary>
Motivation: 现有的公平分配模型主要关注商品分配，对混合物品和特定图模型（如多图）的公平分配研究不足，尤其是在EFX和EF1方向上。

Method: 该研究通过对一般模型和图模型中的公平分配问题进行理论分析和算法设计来解决。

Result: 1. 在一般模型中，证明了当m ≤ n+5且满足特定条件时，混合物品的MMS分配存在。
2. 证明了在多图模型中，判定EFX方向的存在性是NP完全问题，但对于特定类型（无非平凡奇数多重树）的多图，可以在多项式时间内找到EFX方向。
3. 提出了判定图和多图模型中事务分配的EF1和EFX方向存在性的多项式时间算法，并证明了相应多图问题的NP难。

Conclusion: 该研究在混合物品的MMS分配、图模型中的EFX方向判定以及图和多图模型中事务分配的EF1和EFX方向判定方面取得了重要进展，揭示了商品和事务分配在图模型中的基本差异。

Abstract: We study the fair division of indivisible items. In the general model, the
goal is to allocate $m$ indivisible items to $n$ agents while satisfying
fairness criteria such as MMS, EF1, and EFX. We also study a
recently-introduced graphical model that represents the fair division problem
as a multigraph, in which vertices correspond to agents and edges to items. The
graphical model stipulates that an item can have non-zero marginal utility to
an agent only if its corresponding edge is incident to the agent's
corresponding vertex. We study orientations (allocations that allocate each
edge to an endpoint) in this model, as they are particularly desirable.
  Our first contribution concerns MMS allocations of mixed manna (i.e. a
mixture of goods and chores) in the general model. It is known that MMS
allocations of goods exist when $m \leq n+5$. We generalize this and show that
when $m \leq n+5$, MMS allocations of mixed manna exist as long as $n \leq 3$,
there is an agent whose MMS threshold is non-negative, or every item is a
chore. Remarkably, our result leaves only the case where every agent has a
negative MMS threshold unanswered.
  Our second contribution concerns EFX orientations of multigraphs of goods. We
show that deciding whether EFX orientations exist for multigraphs is
NP-complete, even for symmetric bi-valued multigraphs. Complementarily, we show
symmetric bi-valued multigraphs that do not contain non-trivial odd multitrees
have EFX orientations that can be found in polynomial time.
  Our third contribution concerns EF1 and EFX orientations of graphs and
multigraphs of chores. We obtain polynomial-time algorithms for deciding
whether such graphs have EF1 and EFX orientations, resolving a previous
conjecture and showing a fundamental difference between goods and chores
division. In addition, we show that the analogous problems for multigraphs are
NP-hard.

</details>


### [303] [Single-Deviation Stability in Additively Separable Hedonic Games with Constrained Coalition Sizes](https://arxiv.org/abs/2510.12641)
*Martin Bullinger,Adam Dunajski,Edith Elkind,Matan Gilboa*

Main category: cs.GT

TL;DR: 研究了具有联盟大小固定界限的加性可分离揊酒店博弈的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 研究在加性可分离揊酒店博弈中，当联盟大小受到固定界限约束时，四种经典稳定性概念（纳什稳定性、个体稳定性、契约纳什稳定性和契约个体稳定性）的存在性问题。

Method: 分析了四种稳定性概念的两种变体（分别考虑被遗弃联盟的大小约束和不考虑大小约束），并对存在性问题进行了详尽分析。此外，在仅有上界约束的情况下，对相关存在性问题的计算复杂度进行了完全刻画。

Result: 在存在性方面，论文提供了完整的分析结果。在仅有上界约束的情况下，对于契约个体稳定性和契约纳什稳定性（后者要求上界为2），得到了多项式时间算法。对于纳什稳定性和契约个体稳定性，当下界至少为2时，也得到了一些额外结果。

Conclusion: 论文全面研究了具有联盟大小固定界限的加性可分离揊酒店博弈的稳定性问题，并对不同稳定概念下的存在性及计算复杂度进行了深入分析，取得了一系列重要理论成果。

Abstract: We study stability in additively separable hedonic games when coalition sizes
have to respect fixed size bounds. We consider four classic notions of
stability based on single-agent deviations, namely, Nash stability, individual
stability, contractual Nash stability, and contractual individual stability.
For each stability notion, we consider two variants: in one, the coalition left
behind by a deviator must still be of a valid size, and in the other there is
no such constraint. We provide a full picture of the existence of stable
outcomes with respect to given size parameters. Additionally, when there are
only upper bounds, we fully characterize the computational complexity of the
associated existence problem. In particular, we obtain polynomial-time
algorithms for contractual individual stability and contractual Nash stability,
where the latter requires an upper bound of 2. We obtain further results for
Nash stability and contractual individual stability, when the lower bound is at
least 2.

</details>


### [304] [On the Complexity of Nucleolus Computation for Bipartite b-Matching Games](https://arxiv.org/abs/2105.07161)
*Jochen Koenemann,Justin Toth,Felix Zhou*

Main category: cs.GT

TL;DR: 在b-匹配博弈的二部图中，计算核仁是NP难的，但在b值受限于2的特殊情况下，我们给出了部分正面的结果。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是研究b-匹配博弈中核仁计算的复杂性，特别是在二部图上的情况。

Method: 本文证明了即使在最大度为7的二部图上，计算简单b-匹配博弈的核仁也是NP难的。此外，本文还针对b值受限于2的特殊情况，提出了一些有效的算法。

Result: 研究结果表明，在b值受限于2的情况下，当只有少数顶点满足b(v)=2时，存在一个有效的算法；并且在b=2时，也存在一个计算非简单b-匹配核仁的有效算法。

Conclusion: 虽然在一般情况下计算b-匹配博弈的核仁是NP难的，但在b值受限于2的特定条件下，可以设计出有效的计算算法。

Abstract: We explore the complexity of nucleolus computation in b-matching games on
bipartite graphs. We show that computing the nucleolus of a simple b-matching
game is NP-hard even on bipartite graphs of maximum degree 7. We complement
this with partial positive results in the special case where b values are
bounded by 2. In particular, we describe an efficient algorithm when a constant
number of vertices satisfy b(v) = 2 as well as an efficient algorithm for
computing the non-simple b-matching nucleolus when b = 2.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [305] [Epitaxial Electrodeposition of Fe with Controlled In-Plane Variants for Reversible Metal Anode in Aqueous Electrolyte](https://arxiv.org/abs/2510.11757)
*Chenxi Sui,Ching-Tai Fu,Guangxia Feng,Yuqi Li,Junyan Li,Gangbin Yan,Po-Chun Hsu,Steven Chu,Yi Cui*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在单晶铜衬底上外延电沉积铁，实现高倍率、高效率、长寿命的水系电池。


<details>
  <summary>Details</summary>
Motivation: 开发可逆金属负极，以推动水系电池技术（特别是用于可扩展和安全储能）的发展。

Method: 比较铁在多晶和单晶铜衬底上的电沉积行为，并利用电子背散射衍射（EBSD）和X射线衍射（XRD）进行表征，以研究外延生长对抑制枝晶生长和提高库仑效率的影响。

Result: 在单晶铜衬底上实现了铁的高均匀、致密和晶体学取向的生长，并观察到明确的旋转变体。外延电沉积有效地抑制了枝晶生长，显著提高了电镀/剥离循环的库仑效率。

Conclusion: 铁的外延电沉积是一种有前途的方法，可以为使用地球上易于获得的材料的高效水系电池提供途径。

Abstract: The development of reversible metal anodes is a key challenge for advancing
aqueous battery technologies, particularly for scalable and safe stationary
energy storage applications. Here we demonstrate a strategy to realize
epitaxial electrodeposition of iron (Fe) on single-crystal copper (Cu)
substrates in aqueous electrolytes. We compare the electrodeposition behavior
of Fe on polycrystalline and single-crystalline Cu substrates, revealing that
the latter enables highly uniform, dense, and crystallographically aligned Fe
growth. Comprehensive electron backscatter diffraction (EBSD) and X-ray
diffraction (XRD) analysis confirms the formation of Fe with specific
out-of-plane and in-plane orientations, including well-defined rotational
variants. Our findings highlight that epitaxial electrodeposition of Fe can
suppress dendritic growth and significantly enhance Coulombic efficiency during
plating/stripping cycles. This approach bridges fundamental crystallography
with practical electrochemical performance, providing a pathway toward
high-efficiency aqueous batteries utilizing Earth-abundant materials.

</details>


### [306] [Bond-resolved STM with density-based methods](https://arxiv.org/abs/2510.11929)
*Emiliano Ventura-Macias,Jose Martinez-Castro,Guillermo Haas,Jara Trujillo-Mulero,Pablo Pou,Taner Esat,Markus Ternes,Ruslan Temirov,F. Stefan Tautz,Ruben Perez*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种模拟键分辨扫描隧道显微镜（BRSTM）图像的新方法，并成功应用于PTCDA/Ag(111)等体系，同时探讨了底物诱导效应的作用。


<details>
  <summary>Details</summary>
Motivation: 为了模拟BRSTM图像，结合STM和ncAFM的优点，提供分子相互作用的独特视角。

Method: 将全密度基于模型（FDBM）与陈氏导数近似相结合，考虑了σ和π通道的贡献以及CO提示的偏转。

Result: 成功复现了PTCDA/Ag(111)和TOAT/Cu(111)体系的实验BRSTM图像，包括 tip-sample 距离依赖的特征。

Conclusion: 所提出的模拟方法能够准确再现BRSTM实验结果，并揭示了底物诱导效应对BRSTM图像特征的影响。

Abstract: Bond-resolved STM (BRSTM) is a recent technique that combines the advantages
of scanning tunneling microscopy (STM) with the outstanding intramolecular
resolution provided by non-contact atomic force microscopy (ncAFM) using a
CO-functionalized tips, offering unique insights into molecular interactions at
surfaces. In this work, we present a novel and easily implementable approach
for simulating BRSTM images, which we have applied to reproduce new
experimental BRSTM data of Perylene-3,4,9,10-tetracarboxylic dianhydride
(PTCDA) on Ag(111), obtained with unprecedented control of tip-sample
separation ($\sim$10~pm). Our method integrates the Full-Density-Based Model
(FDBM) developed for High-Resolution Atomic Force Microscopy (HRAFM) with
Chen's derivative approximation for tunneling channels, effectively capturing
the contributions of both $\sigma$ and $\pi$ channels, while accounting for the
CO-tip deflection induced by probe-sample interactions. This approach
accurately reproduces the experimental results for both PTCDA/Ag(111) and
1,5,9-trioxo-13-azatriangulene (TOAT)/Cu(111) systems, including intricate
tip-sample distance-dependent features. Furthermore, we also demonstrate the
important role of substrate-induced effects, which can modify molecular orbital
occupation and the relaxation of the CO probe, resulting in distinct BRSTM
image characteristics.

</details>


### [307] [Spectroscopy of Sm$^{3+}$ Ions in the C$_{\rm s}$ Symmetry Centres of Hydrothermally Prepared K$_2$YF$_5$ Microcrystals](https://arxiv.org/abs/2510.11934)
*Pakwan Chanprakhon,Michael F. Reid,and Jon-Paul R. Wells*

Main category: cond-mat.mtrl-sci

TL;DR: 摘要：合成了掺杂Sm$^{3+}$的K$_2$YF$_5$微晶，并进行了光谱表征。


<details>
  <summary>Details</summary>
Motivation: 合成了掺杂Sm$^{3+}$的K$_2$YF$_5$微晶，并对其光谱特性进行了研究。

Method: 采用水热技术合成了微晶，并通过扫描电子显微镜和X射线衍射分析确认了其晶体结构。在10 K下进行了吸收和激光激发荧光光谱测量，并对Sm$^{3+}$进行了晶体场参数化分析。

Result: 成功合成了尺寸约为20微米的K$_2$YF$_5$微晶，并确定了其斜方晶体结构。通过光谱测量确定了56个实验晶体场能级，并进行了晶体场分析。

Conclusion: Sm$^{3+}$掺杂的K$_2$YF$_5$微晶具有斜方晶体结构，通过晶体场分析能够很好地拟合实验数据。

Abstract: We report on the synthesis and spectroscopic characterization of
Sm$^{3+}$-doped K$_2$YF$_5$ microparticles. The particles were synthesized via
the hydrothermal technique, yielding a particle size of approximately 20 $\mu$m
in length. Scanning electron microscopy (SEM) and X-ray diffraction (XRD)
analyses confirmed their orthorhombic crystal structure. A combination of
absorption and laser excited fluorescence performed on samples cooled to 10~K,
allow for the determination of {56} experimental crystal-field levels. A
parametrised crystal-field analysis for Sm$^{3+}$ in the C$_{\rm s}$ point
group symmetry centres of K$_2$YF$_5$ yields good approximation to the data.

</details>


### [308] [Thermal transport in GaN/AlN HEMTs on 4H-SiC: Role of layer thickness and hetero-interfaces](https://arxiv.org/abs/2510.11936)
*Dat Q. Tran,Minho Kim,Okhyun Nam,Vanya Darakchieva,Plamen P. Paskov*

Main category: cond-mat.mtrl-sci

TL;DR: SiC衬底上HEMT结构中的热输运研究表明，声子-边界散射在低温下影响热导率，而界面热阻在高温下减小，这对于器件设计具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究在4H-SiC衬底上通过MOCVD生长的HEMT结构中的热输运特性，以了解温度对热导率和界面热阻的影响，并为器件设计提供指导。

Method: 使用热反射法（TTR）测量GaN沟道和AlN缓冲层的热导率。研究了声子-边界散射和界面热阻（TBR）随温度的变化，并通过仿真模拟温度分布。

Result: 低温下，声子-边界散射导致热导率随厚度变化明显；高温下，该效应减弱。AlN/4H-SiC和GaN/AlN界面的TBR随温度升高而减小并趋于饱和。仿真结果显示TBR对薄沟道器件至关重要，而较厚的沟道和缓冲层有利于散热。

Conclusion: 界面热阻（TBR）和声子-边界散射是影响HEMT结构热输运的关键因素。器件设计应考虑TBR效应，并利用较厚的沟道和缓冲层来优化散热性能。

Abstract: Thermal transport in high-electron-mobility-transistor (HEMT) structures
grown on 4H-SiC substrates by metalorganic-vapour-phase epitaxy (MOCVD) is
systematically investigated. The thermal conductivity of the GaN channel and
AlN buffer layers is measured by thermoreflectance (TTR). A pronounced
thickness dependence of thermal conductivity as a result of phonon-boundary
scattering is observed at low temperatures, while this effect becomes
significantly weaker at elevated temperatures. The thermal boundary resistance
(TBR) at the AlN/4H-SiC and GaN/AlN interfaces is also examined, showing a
substantial reduction and eventual saturation with increasing temperature,
indicating elastic phonon transport as the dominant mechanism. Reliable
simulations of the temperature profile across the structures based on the
measured thermal metrics highlight the critical role of TBR in thin-channel
device and the advantage of thicker channel and buffer layers for efficient
heat dissipation in the HEMTs.

</details>


### [309] [Metalorganic Chemical Vapor Deposition of AlScN Thin Films and AlScN/AlN/GaN Heterostructures](https://arxiv.org/abs/2510.12074)
*Vijay Gopal Thirupakuzi Vangipuram,Abdul Mukit,Kaitian Zhang,Salva Salmani-Rezaie,Hongping Zhao*

Main category: cond-mat.mtrl-sci

TL;DR: 通过MOCVD生长AlScN薄膜，实现了钪(Sc)在AlN晶格中的可控掺杂，最高Sc掺杂浓度达~13%。


<details>
  <summary>Details</summary>
Motivation: 探索AlScN薄膜在HEMT器件技术中的应用潜力。

Method: 采用金属有机化学气相沉积（MOCVD）技术生长AlScN薄膜，并通过XPS、Hall和C-V等测量手段进行表征。

Result: AlScN/AlN/GaN异质结构在AlScN/AlN-GaN界面处形成了二维电子气（2DEG）通道。增加AlScN/AlN势垒厚度可以提高二维电子气密度，当势垒厚度约为30 nm时，C-V测量得到的二维电子气密度为5.22e12 cm^-2。

Conclusion: MOCVD生长AlScN是一种有前途的III族氮化物材料，可用于高性能电子器件和铁电材料。

Abstract: AlScN thin films were grown via metalorganic chemical vapor deposition
(MOCVD), showing controllable incorporation of scandium (Sc) into the AlN
lattices. Systematic variation of growth parameters demonstrated an obvious
influence on Sc incorporation, with X-ray photoelectron spectroscopy (XPS)
analysis indicating Sc composition up to $\sim$13\% when (MCp)$_2$ScCl was used
as the precursor. AlScN/AlN/GaN heterostructures grown on GaN templates
exhibited the formation of a two-dimensional electron gas (2DEG) channel at the
AlScN/AlN--GaN interface, confirming their potential use in high electron
mobility transistor (HEMT) device technologies. Variation in AlScN/AlN barrier
thickness within the heterostructures showed that thicker barriers yield higher
sheet charge densities from both Hall and capacitance-voltage (C--V)
measurements. With an AlScN/AlN barrier thickness of $\sim$30~nm, a sheet
charge density of $5.22\times10^{12}$~cm$^{-2}$ was extracted from C--V.
High-resolution scanning transmission electron microscopy (S/TEM) further
confirmed Sc incorporation and revealed the wurtzite crystalline structure of
the films and heterostructures. These results establish MOCVD growth of AlScN
as a promising and compatible material for advancing III-nitride
heterostructures in high-performance electronics and potentially
ferroelectrics.

</details>


### [310] [Orbitally-Resolved Mechanical Properties of Solids from Maximally Localized Wannier Functions](https://arxiv.org/abs/2510.11945)
*Ethan T. Ritz,Guru Khalsa,Hsin-Yu Ko,Ju-an Zhang,Robert A. DiStasio Jr.,Nicole A. Benedek*

Main category: cond-mat.mtrl-sci

TL;DR: 该技术将半局域密度泛函理论计算的总能量划分为局域Wannier基中各个电子态的贡献，并成功解释了铁电PbTiO3在应力作用下弹性反常现象的关键因素。


<details>
  <summary>Details</summary>
Motivation: 揭示铁电PbTiO3在应力作用下出现的弹性反常现象的原因，该现象此前未能得到解释。

Method: 提出一种将半局域密度泛函理论计算的总能量划分为局域Wannier基中各个电子态贡献的技术。

Result: 发现材料的s和p轨道在铁电PbTiO3的弹性反常现象中起着关键作用。

Conclusion: 该技术能够深入理解材料机械性质（或任何由能量导数给出的性质）的化学起源。

Abstract: We present a technique for partitioning the total energy from a semi-local
density functional theory calculation into contributions from individual
electronic states in a localized Wannier basis. We use our technique to reveal
the key role played by the $s$ and $p$ orbitals of the apical oxygen atoms in a
curious elastic anomaly exhibited by ferroelectric PbTiO$_3$ under applied
stress, which has so far gone unexplained. Our technique enables new insights
into the chemical origins of the mechanical properties of materials, or any
property given by an energy derivative.

</details>


### [311] [Microscopic Intricacies of Self-Healing in Halide Perovskite-Charge Transport Layer Heterostructures](https://arxiv.org/abs/2510.11948)
*Tejmani Behera,Boris Louis,Lukas Paesen,Roel Vanden Brande,Koki Asano,Martin Vacha,Maarten Roeffaers,Elke Debroye,Johan Hofkens,Sudipta Setha*

Main category: cond-mat.mtrl-sci

TL;DR: 卤化物钙钛矿光伏器件的稳定性受限于缺陷生成和非辐射损失，自修复为延长器件功能提供了途径，但其微观机制，特别是界面化学对陷阱动力学和修复动力学的作用尚不清楚。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在阐明三阳离子混合卤化物（TCMH）钙钛矿薄膜及其器件相关电荷传输层异质结构在光诱导损伤下的自修复和缺陷演化机制，并探究界面化学在其中起到的作用。

Method: 研究人员利用新开发的局部功能成像工具——相关聚类成像（CLIM），绘制了原始和异质结构薄膜中缺陷动力学的时空光致发光异质性图谱。

Result: 缺陷修复遵循双相动力学：初始的电子弛豫（几十分钟）和随后的较慢的离子和晶格重排（约几小时）。研究发现，电荷传输层的化学性质会调节陷阱活性、修复动力学和卤化物再分布，异质结构的恢复速度快于原始薄膜。

Conclusion: 本研究揭示了缺陷、界面和离子迁移之间的动态相互作用，并为理性设计耐用、下一代钙钛矿光电器件提供了框架，表明异质结构可以提高器件的恢复能力和稳定性。

Abstract: The stability and performance of halide perovskite photovoltaic devices are
critically limited by progressive defect generation and associated local
non-radiative losses during operation. Self-healing of defects provides a
promising pathway to prolong device functionality, yet the underlying
microscopic mechanisms remain poorly understood, particularly the role of
interfacial chemistry on trap dynamics and healing kinetics. Here, we elucidate
self-healing and defect evolution in triple-cation mixed halide (TCMH)
perovskite films and their device-relevant charge transport layer
heterostructures subjected to photo-induced damage. Using correlation
clustering imaging (CLIM), our recently developed local functional imaging
tool, we map spatiotemporal photoluminescence heterogeneity to track defect
dynamics in pristine and heterostructure films. The defect healing follows
bi-phasic kinetics, with an initial electronic relaxation (tens of minutes) and
a subsequent slower phase (~ hours) associated to ionic and lattice
rearrangement. Most importantly, our results demonstrate that the chemical
nature of charge-transport layers modulates trap activity, healing kinetics,
and halide redistribution, with heterostructures exhibiting faster recovery
than pristine films, a boon for device resilience. These findings provide new
insights into the dynamic interaction between defects, interfaces, and ion
migration, and establish a framework for rational design of durable,
next-generation perovskite optoelectronic devices.

</details>


### [312] [The Comparison of Colloidal PbS QD Photoconductors and Hybrid Phototransistors](https://arxiv.org/abs/2510.11995)
*Gökhan Kara,Lorenzo J. A. Ferraresi,Dmitry N. Dirin,Roman Furrer,Maksym V. Kovalenko,Michel Calame,Ivan Shorubalko*

Main category: cond-mat.mtrl-sci

TL;DR: 比较了光电导体和混合光电晶体管，发现混合光电晶体管更适合探测低光照水平，并展示了负光电流效应。


<details>
  <summary>Details</summary>
Motivation: 比较光电导体和混合光电晶体管在探测低光照水平方面的能力，以确定哪种器件在测量低光照水平方面更优。

Method: 使用相同的EDT处理的PbS cQD薄膜，直接比较了光电导体和混合光电晶体管的性能，并研究了温度激活的光电流动力学。

Result: 发现混合光电晶体管比光电导体具有更高的响应度，并且能够探测到更低的光照水平（nW/cm2）。同时，展示了负光电流效应，该效应可将工作速度提高到100 kHz。

Conclusion: 混合光电晶体管由于其能够处理低光照水平和高响应度，因此比光电导体更适合探测低光照水平。负光电流效应可以进一步提高器件的性能。

Abstract: The simplicity in the fabrication of photoconductors makes them a valuable
choice to investigate optoelectronic properties of colloidal quantum dot (cQD)
films. Lateral photoconductors generally require a large size, in the mm2, and
are limited in operation speed due to the presence of trapping sites. In
contrast, hybrid phototransistors are fabricated in the um2 scale and benefit
from such trapping sites, allowing the measurement of low light levels in the
nW/cm2. The question, however, arises whether high responsivity values are
required for the detection of low light levels or the compatible detectivity of
photoconductors is sufficient. Here, we directly compare photoconductors and
hybrid phototransistors with an identical EDT-treated PbS cQD film. We
highlight that a comparable D* is not enough for the purpose of measuring low
light levels, as the resulting photocurrents need to be readily accessible.
Furthermore, we also showcase temperature-activated photocurrent dynamics
resulting in a negative photocurrent (NPC) effect. This NPC simultaneously
improves the frequency bandwidth and photocurrent, enabling operation speeds up
to 100 kHz.

</details>


### [313] [Chern-Selective multi-valley Flat Bands in Twisted Mono-Bilayer and Mono-Trilayer MoTe$_2$](https://arxiv.org/abs/2510.12127)
*Ziyue Qi,Hanqi Pi,Yan Zhang,Jiaxuan Liu,Nicolas Regnault,Hongming Weng,B. Andrei Bernevig,Jiabin Yu,Quansheng Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 扭转的 MoTe2（A-AB 和 A-ABA）具有由 Γ 和 K/K' 谷共同产生的多谷平坦带，这使得它们成为研究层数和堆叠相关多谷物理的理想平台。


<details>
  <summary>Details</summary>
Motivation: 研究扭转的单-双层 (A-AB) 和单-三层 (A-ABA) MoTe2 的电子性质，特别是它们的多谷平坦带行为及其与层数和堆叠配置的关系。

Method: 使用第一性原理计算和连续模型研究 A-AB 和 A-ABA 扭转 MoTe2 的电子性质。构建谷分辨的连续模型并对低能莫伊带进行 Wannier 化。

Result: 发现 A-AB 和 A-ABA 扭转 MoTe2 的低能莫伊带同时来源于 Γ 和 K/K' 谷，具有不同的自旋陈数。证明了层间杂化效应支配着这些多谷莫伊平坦带，并且不同的堆叠配置和厚度可以调节 Γ 和 K 谷莫伊平坦带之间的相对能量对齐。此外，还发现 Berry 曲率和量子度量分布可以被层数和堆叠配置有效调控。

Conclusion: A-AB 和 A-ABA 扭转 MoTe2 是研究层数控制的多谷物理的理想平台，因为它们同时具有两种不同对称性的谷，这与仅由一种谷影响低能物理的其他莫伊系统不同。

Abstract: The interplay between moir\'e flat bands originating from different valleys
can give rise to a variety of exotic quantum phases. In this work, we
investigate the electronic properties of twisted mono-bilayer (A-AB) and
mono-trilayer (A-ABA) MoTe$_2$ using first-principles calculations and
continuum models. Unlike previous studies on twisted bilayer systems, in which
low-energy flat bands originate solely from the $K/K'$ valleys, in A-AB and
A-ABA twisted MoTe$_2$ (\tmt) the moir\'e bands at low energies arise from both
the $\Gamma$ and $K/K'$ valleys, with spin Chern numbers $C_s=0$ (for $\Gamma$)
and $C_{\uparrow/\downarrow}=\pm1$ (for $K/K'$), respectively. We show that the
multi-valley moir\'e flat bands are governed by interlayer-hybridization
effects, and that different stacking configurations and thicknesses tune the
relative energy alignment between the $\Gamma$ and $K$ valley moir\'e flat
bands. By constructing valley-resolved continuum models and performing
Wannierization for the low-energy moir\'e bands, we further uncover that the
Berry curvature and quantum metric distributions can be effectively tuned by
the layer number and stacking configuration. Unlike other moir\'e systems,
where only one kind of valley influenced the low energy physics, the
simultaneous appearance of two distinct types of valleys, with different
symmetries, establish A-AB and A-ABA \tmt\ as ideal platforms for studying
layer-controlled multi-valley physics.

</details>


### [314] [Nanoscale surface morphology controls charge storage at stepped Pt-water interfaces](https://arxiv.org/abs/2510.12176)
*Matthew T. Darby,Muhammad Saleh,Marialore Sulpizi,Clotilde S. Cucinotta*

Main category: cond-mat.mtrl-sci

TL;DR: 铂阶梯边缘在燃料电池和电解槽中主导电催化活性，但其原子电化学行为仍未得到充分理解。本研究利用受控电极电势下的从头分子动力学，结合实验观察到的(111)×(111)和(111)×(100)边缘基序，对真实的阶梯状铂-水界面进行建模。首次解决了纳米结构铂表面双电层位点特异性结构、电荷分布和静电学问题。研究发现，零电势点（PZC）附近的微分电容几乎完全来自平坦(111)表面的电势依赖性水化学吸附。相比之下，即使在PZC以下，阶梯边缘也已饱和化学吸附水，因此不贡献电容。相反，边缘会积累过量的正电荷，并表现出局部升高的静电势，这通过空间分辨的宏观电势剖面得以揭示。这种静电不对称性意味着与平坦表面相比，阶梯位点电子积累的势垒更大，这与增强的电荷局域化和反应活性一致。此外，阶梯边缘原子能量更高的d带中心和更尖锐的投影态密度，进一步支持其作为活性的、带正电中心的双重作用。总之，这些结果为理解实验观察到的PZC随阶梯密度变化的机制提供了依据，并为理解和优化纳米结构铂电催化剂的界面充电建立了预测框架。


<details>
  <summary>Details</summary>
Motivation: 铂阶梯边缘在电催化中起着关键作用，但对其原子电化学行为的理解不足，需要阐明其在纳米结构铂表面上的行为。

Method: 采用从头分子动力学模拟，在控制电极电势下，对包含(111)×(111)和(111)×(100)边缘基序的铂-水界面进行建模，以研究其结构、电荷分布和静电特性。

Result: 零电势点（PZC）附近的微分电容主要由(111)表面的水化学吸附决定，而阶梯边缘饱和吸附水，不贡献电容。阶梯边缘积累正电荷，表现出局部升高的静电势，阻碍电子积累。阶梯边缘原子具有更高的d带中心和更尖锐的投影态密度。

Conclusion: 研究结果揭示了铂阶梯边缘作为活性、带正电中心的机制，解释了PZC随阶梯密度的变化，并为优化纳米结构铂电催化剂界面充电提供了预测框架。

Abstract: Platinum step edges dominate electrocatalytic activity in fuel cells and
electrolysers, yet their atomistic electrochemical behaviour remains poorly
understood. Here, we employ \textit{ab initio} molecular dynamics under
controlled electrode potentials to model a realistic stepped Pt--water
interface incorporating experimentally observed (111)$\times$(111) and
(111)$\times$(100) edge motifs. This allows us to resolve, for the first time,
the site-specific structure, charge distribution, and electrostatics of the
electric double layer at a nanostructured Pt surface. We find that differential
capacitance near the potential of zero charge (PZC) arises almost entirely from
potential-dependent chemisorption of water on flat (111) terraces. In contrast,
step edges are saturated with chemisorbed water even below the PZC and thus do
not contribute to the capacitance. Instead, edges accumulate excess positive
charge and exhibit a locally elevated electrostatic potential, as revealed by
spatially resolved macroscopic potential profiles. This electrostatic asymmetry
implies a greater barrier for electron accumulation at step sites compared to
terraces, consistent with enhanced charge localisation and reactivity. Finally,
the higher-in-energy d-band centre and sharper projected density of states at
edge atoms further support their role as active, positively charged centres.
Together, these results provide a mechanistic explanation for the observed
experimental shift of the PZC with step density and establish a predictive
framework for understanding and optimising interfacial charging in
nanostructured Pt electrocatalysts.

</details>


### [315] [Spectroscopic Determination of Site-Selective Ligand Binding on Single Anisotropic Nanocrystals](https://arxiv.org/abs/2510.12199)
*Dong Le,Wade Shipley,Alexandria Do,Liya Bi,Yufei Wang,Krista P. Balto,Rourav Basak,Hans A. Bechtel,Stephanie N. Gilbert Corder,Ilya Mazalov,Tesa Manto,Reno Sammons,Yutong She,Fiona Liang,Ganesh Raghavendran,Joshua S. Figueroa,Shaowei Li,Tod A. Pascal,Andrea R. Tao,Alex Frano*

Main category: cond-mat.mtrl-sci

TL;DR: 有机配体在纳米晶体表面选择性吸附


<details>
  <summary>Details</summary>
Motivation: 缺乏理解配体-纳米颗粒行为的基础知识，特别是配体结合位点的不确定性，限制了纳米材料的进一步发展。

Method: 利用同步红外纳米光谱（SINS）、原子力显微镜（AFM）和扫描隧道显微镜（STM）结合第一性原理计算机模拟，研究了有机配体在银纳米立方体表面的吸附行为。

Result: 空间受阻的异氰配体优先吸附在银纳米立方体的高曲率特征上（低配位银原子存在处），而无空间受阻特性的配体则没有表面选择性。SINS能够近乎单分子水平地验证表面结合相互作用。

Conclusion: 可以通过设计具有空间位阻效应的有机配体，对纳米晶体的表面化学及其配体壳层的性质进行精细调控。

Abstract: Organic surface ligands are integral components of nanocrystals and
nanoparticles that have a strong influence on their physicochemical properties,
their interaction with the environment, and their ability to self-assemble and
order into higher-order structures. These hybrid nanomaterials are tunable with
applications in catalysis, directed self-assembly, next-generation
optoelectronics, and chemical and quantum sensing. Critically, future advances
depend on our ability to rationally engineer their surface chemistry. However,
fundamental knowledge of ligand-nanoparticle behavior is limited by uncertainty
in where and how these ligands bind to surfaces. For nanoparticles, in
particular, few characterization techniques offer both the high spatial
resolution and the precise chemical mapping needed to identify specific ligand
binding sites. In this study, we utilized synchrotron infrared nanospectroscopy
(SINS), atomic force microscopy (AFM), and scanning tunneling microscopy (STM)
together with first-principles computer simulations to validate the
site-selective adsorption of organic ligands on a shaped nanocrystal surface.
Specifically, we demonstrate that the sterically encumbered isocyanide ligands
(CNAr^{Mes2}) preferentially bind to the high curvature features of Ag
nanocubes (NCs), where low-coordinate Ag atoms are present. In contrast,
isocyanide ligands that do not exhibit these steric properties show no surface
selectivity. SINS serves as an effective tool to validate these surface binding
interactions at the near-single molecule level. These results indicate that
steric effects can be successfully harnessed to design bespoke organic ligands
for fine-tuning nanocrystal surface chemistry and the properties of the
nanocrystal ligand shell.

</details>


### [316] [Room temperature control of axial and basal antiferromagnetic anisotropies using strain](https://arxiv.org/abs/2510.12222)
*Jack Harrison,Junxiong Hu,Charles Godfrey,Jheng-Cyuan Lin,Tim A Butcher,Jörg Raabe,Simone Finizio,Hariom Jani,Paolo G Radaelli*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在α-Fe2O3薄膜上施加应变，可以实现对反铁磁畴的鲁棒控制，从而为开发下一代自旋电子和马格尼学器件铺平道路。


<details>
  <summary>Details</summary>
Motivation: 由于多畴态的形成，在薄膜中确定性地控制反铁磁顺序是一个主要挑战。因此，反铁磁材料的成功实施有赖于对其各向异性的仔细设计。

Method: 本研究通过施加各向同性和各向异性的面内应变，在广泛的温度-应变相空间中，系统地调整了磁晶相互作用和磁弹性相互作用之间的相互作用，并使用与原位应变和温度控制相结合的线性二向色扫描透射X射线显微镜直接绘制了纳米级反铁磁顺序图。此外，还建立了Landau模型和微磁模拟。

Result: 研究发现，应变驱动的控制可以将系统导向一个对齐的反铁磁状态，同时保留merons、antimerons和bimerons等拓扑自旋纹理。

Conclusion: 研究结果表明，应变可以作为一种多功能的控制机制，根据需要重新配置α-Fe2O3中的平衡或动态反铁磁状态，从而为下一代自旋电子和马格尼学器件的开发铺平道路。

Abstract: Antiferromagnetic materials are promising platforms for the development of
ultra-fast spintronics and magnonics due to their robust magnetism,
high-frequency relativistic dynamics, low-loss transport, and the ability to
support topological textures. However, achieving deterministic control over
antiferromagnetic order in thin films is a major challenge, due to the
formation of multi-domain states stabilised by competing magnetic and
destressing interactions. Thus, the successful implementation of
antiferromagnetic materials necessitates careful engineering of their
anisotropy. Here, we demonstrate strain-based robust control over multiple
antiferromagnetic anisotropies and nanoscale domains in the promising
spintronic candidate a-Fe2O3, at room temperature. By applying isotropic and
anisotropic in-plane strains across a broad temperature-strain phase space, we
systematically tune the interplay between magneto-crystalline and
magneto-elastic interactions. We discover that strain-driven control steers the
system towards an aligned antiferromagnetic state, whilst preserving
topological spin textures, such as merons, antimerons and bimerons. We directly
map the nanoscale antiferromagnetic order using linear dichroic scanning
transmission X-ray microscopy integrated with in situ strain and temperature
control. A Landau model and micromagnetic simulations reveal how strain
reshapes the magnetic energy landscape. These findings suggest that strain
could serve as a versatile control mechanism to reconfigure equilibrium or
dynamic antiferromagnetic states on demand in a-Fe2O3, paving the way for
next-generation spintronic and magnonic devices.

</details>


### [317] [Generative Diffusion Model DiffCrysGen Discovers Rare Earth-Free Magnetic Materials](https://arxiv.org/abs/2510.12329)
*Sourav Mal,Nehad Ahmed,Subhankar Mishra,Prasenjit Sen*

Main category: cond-mat.mtrl-sci

TL;DR: DiffCrysGen是一个端到端的扩散模型，可以一步生成完整的晶体结构，显著提高材料发现的效率和速度，并已成功发现多种稳定的稀土永磁材料。


<details>
  <summary>Details</summary>
Motivation: 目前材料发现领域，特别是设计具有特定功能的无机晶体材料时，在广阔的化学空间中进行有效探索是一个基本挑战。现有的基于扩散的生成模型虽然强大，但通常需要特定领域的约束以及针对原子类型、原子位置和晶格参数的独立扩散过程，这增加了复杂性并限制了效率。

Method: 提出了一种名为DiffCrysGen的、完全数据驱动的、基于分数的扩散模型，该模型能够在单一的、端到端的扩散过程中生成完整的晶体结构。这种统一的框架简化了模型架构，并将采样速度与现有方法相比提高了两个到三个数量级，同时不损害生成材料的化学和结构多样性。

Result: 通过使用密度泛函理论（DFT）验证了DiffCrysGen生成的新型稀土永磁材料的有效性。这些材料在能量上和动力学上都是稳定的，并且具有潜在的可合成性。其中包括具有高饱和磁化强度和大磁晶各向异性的铁磁体，以及反铁磁金属。

Conclusion: DiffCrysGen是一个通用的平台，可以加速功能材料的发现。

Abstract: Efficient exploration of the vast chemical space is a fundamental challenge
in materials discovery, particularly for designing functional inorganic
crystalline materials with targeted properties. Diffusion-based generative
models have emerged as a powerful route, but most existing approaches require
domain-specific constraints and separate diffusion processes for atom types,
atomic positions, and lattice parameters, adding complexity and limiting
efficiency. Here, we present DiffCrysGen, a fully data-driven, score-based
diffusion model that generates complete crystal structures in a single,
end-to-end diffusion process. This unified framework simplifies the model
architecture and accelerates sampling by two to three orders of magnitude
compared to existing methods without compromising chemical and structural
diversity of the generated materials. In order to demonstrate the efficacy of
DiffCrysGen in generating valid and useful materials, using density functional
theory (DFT), we validate a number of newly generated rare earth-free magnetic
materials that are energetically and dynamically stable, and are potentially
synthesizable. These include ferromagnets with high saturation magnetization
and large magnetocrystalline anisotropy, as also metallic antiferromagnets.
These results establish DiffCrysGen as a general platform for accelerated
functional materials discovery.

</details>


### [318] [Two-Dimensional Altermagnetism in Epitaxial CrSb Ultrathin Films](https://arxiv.org/abs/2510.12344)
*Keren Li,Yuzhong Hu,Yue Li,Ruohang Xu,Heping Li,Kun Liu,Chen Liu,Jincheng Zhuang,Yee Sin Ang,Jiaou Wang,Haifeng Feng,Weichang Hao,Yi Du*

Main category: cond-mat.mtrl-sci

TL;DR: 二维CrSb薄膜展现出由界面对称性破缺引起的磁性转变，并实现了零净磁矩的二维反磁体。该研究为在纳米自旋电子器件中引入无杂散磁场自旋序提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 在二维（2D）材料中实现反磁体（altermagnetism）是一个挑战，因为维度降低会抑制kZ色散并破坏自旋补偿所需的对称性操作。

Method: 通过在Bi2Te3上生长外延的单位晶胞厚度的CrSb薄膜，研究了其厚度驱动的磁性转变。

Result: 发现1单位晶胞厚的薄膜呈现铁磁状态，而超过7/4单位晶胞厚度则转变为反磁体状态。这种转变源于Cr端面层诱导的局部磁矩不平衡，以及随着厚度增加而恢复的[C2||C6Zt]和[C2||MZ]自旋空间群对称性。

Conclusion: 首次在二维区域实现了反磁体，并为将无杂散磁场自旋序集成到纳米自旋电子架构中提供了一条途径。

Abstract: Altermagnets constitute an emerging class of collinear magnets that exhibit
zero net magnetization yet host spin-split electronic bands arising from
non-relativistic spin-space-group symmetries. Realization of altermagnetism in
the two-dimensional (2D) limit remains an outstanding challenge because
dimensional reduction suppresses kZ dispersion and destabilizes the symmetry
operations essential for spin compensation. Here, we demonstrate genuine 2D
altermagnetism in epitaxial unit-cell-thin films of CrSb grown on Bi2Te3. It
reveals a thickness-driven transition from a ferrimagnetic state in 1-unit-cell
films to an altermagnetic state above a critical thickness of 7/4 unit cell.
The transition originates from interfacial symmetry breaking at the
Cr-terminated layer that induces local moment imbalance. With increasing
thickness the key spin-space-group symmetries [C2||C6Zt] and [C2||MZ] restores,
which leads to altermagnetism with zero net magnetization and
momentum-dependent spin splitting. Our results provide the first experimental
realization of altermagnetism in the 2D regime and establish a route for
integrating stray-field-free spin order into nanoscale spintronic
architectures.

</details>


### [319] [Controlling Magnetism in the 2D van der Waals Antiferromagnet CrPS$_4$ via Ion Intercalation](https://arxiv.org/abs/2510.12371)
*Alberto M. Ruiz,Diego López-Alcalá,Gonzalo Rivero-Carracedo,Andrei Shumilin,José J. Baldoví*

Main category: cond-mat.mtrl-sci

TL;DR: 通过插层离子调控二维磁性材料CrPS4的电子和磁性，实现磁性开关和增强。


<details>
  <summary>Details</summary>
Motivation: 二维范德华磁性材料是调控电子和磁性性质的多功能平台，而通过在材料层间插入化学物质是调控磁性的有效途径。本文聚焦于A型反铁磁半导体CrPS4，研究锂离子和四丁基铵离子的插层对其电子和磁性的影响。

Method: 使用第一性原理计算研究锂离子和四丁基铵离子插层对CrPS4电子和磁性质的影响。

Result: 锂离子的掺入导致CrPS4发生半导体-金属转变，并将其磁性从垂直向转变为面内反铁磁性，在更高掺杂水平下转变为面内铁磁性，同时有序温度提高。四丁基铵离子插层扩展了范德华间隙，使CrPS4层解耦，稳定了面内铁磁性，居里温度高于100K，并改善了磁畴传播，提高了群速度和各向同性。

Conclusion: 插层是一种强大且多功能的方法，用于控制磁行为和自旋动力学，为设计用于自旋电子学和磁子学应用的器件铺平了道路。

Abstract: Two-dimensional van der Waals (vdW) magnetic materials are versatile
platforms for tailoring electronic and magnetic properties, in which the
insertion of chemical species into their interlayer gaps offers a powerful
route to engineer magnetism. Here, we focus on the A-type antiferromagnetic
semiconductor CrPS$_4$ (T$_N$ = 38 K) and investigate its electronic and
magnetic properties upon intercalation of lithium (Li$^+$) and organic
tetrabutylammonium (TBA$^+$) ions using first-principles calculations. Our
results show that Li$^+$ incorporation induces a semiconductor-to-metal
transition in CrPS$_4$ and selectively modifies its magnetic behaviour:
switching from out-of-plane to in-plane antiferromagnetism, followed by an
in-plane ferromagnetic ground state at higher intercalation levels. This is
accompanied by a continuous increase of the ordering temperature, reaching a
fivefold enhancement for Li$_{0.5}$CrPS$_4$. Similarly, TBA$^+$ intercalation
expands the vdW gap, decoupling CrPS$_4$ layers and stabilising in-plane
ferromagnetism with a T$_C$ above 100 K. Furthermore, it also modifies magnon
propagation, leading to enhanced group velocities and a more isotropic magnon
transport. This work highlights intercalation as a powerful and versatile
approach for controlling magnetic behaviour and spin dynamics, paving the way
for the design of tunable 2D layered magnetic materials for spintronic and
magnonic applications.

</details>


### [320] [Defect Passivation and Förster-Type Energy Exchange in H2Pc-TMD Organic-Inorganic Heterostructures](https://arxiv.org/abs/2510.12437)
*Šimun Mandić,Ana Senkić,Nataša Vujičić*

Main category: cond-mat.mtrl-sci

TL;DR: 有机-无机异质结结合了有机分子的光吸收和激子生成能力，以及层状过渡金属二硫化物的独特激子性质，其中界面能带对齐决定了光学响应。


<details>
  <summary>Details</summary>
Motivation: 研究H2Pc分子对CVD生长的MoS2和WS2单层的影响，以了解有机-无机异质结的能带对齐和光学特性。

Method: 使用结合的显微镜技术（KPFM、PL和拉曼光谱）来研究H2Pc分子对MoS2和WS2单层的影响。

Result: 尽管能带对齐相似，但H2Pc/MoS2和H2Pc/WS2异质结表现出明显不同的光学特征。H2Pc/MoS2异质结的缺陷修复效果更明显，而H2Pc/WS2异质结则表现出强烈的F"orster能量转移迹象。

Conclusion: 过渡偶极矩以及供体发射和受体吸收之间的光谱重叠在设计光电器件中起着关键作用。

Abstract: Organic - inorganic heterostructures (HS) combine the strong light absorption
and exciton generation capabilities of organic molecules with the unique
excitonic properties of layered transition metal dichalcogenides (TMDs), where
the interfacial band alignment dictates the optical response. In this work, we
investigate the influence of H2Pc molecules on CVD-grown MoS2 and WS2
monolayers using correlative microscopy techniques - Kelvin probe force
microscopy (KPFM), photoluminescence (PL), and Raman spectroscopy.
Comprehensive analysis of both electronic and optical properties provides
detailed insights into the energy band alignment in these two HS. Despite their
similar band alignments, the heterostructures exhibit strikingly different
optical signatures. In the case of H2Pc/MoS2 HS, the effect of defect healing
is more pronounced, while for the H2Pc/WS2 HS, strong indications of F\"orster
energy transfer are observed. These findings highlight the critical role of
transition dipole moment in addition to spectral overlap between donor emission
and acceptor absorption in the design of optoelectronic devices.

</details>


### [321] [Self-attention enabled quantum path analysis of high-harmonic generation in solids](https://arxiv.org/abs/2510.12443)
*Cong Zhao,Xiaozhou Zou*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用Transformer模型分析固态高次谐波产生（HHG）信号，有效识别和分离了复杂的电子动力学和能带耦合机制，为阿秒光谱学和非线性光子学提供了新的机器学习工具。


<details>
  <summary>Details</summary>
Motivation: 区分HHG光谱中的多体贡献具有挑战性，需要新的方法来分析复杂的电子动力学和能带耦合。

Method: 提出一种基于Transformer编码器的机器学习方法，利用自注意力机制分析一维Kronig-Penney模型计算的HHG信号，并结合Gabor时频分析提取弱耦合通道。

Result: 自注意力机制能够突出显示偶极动力学和高频光谱成分之间的相关性，识别出非绝热带耦合的特征，并能提取出对偶数次谐波和异常光谱特征有贡献的弱耦合通道。

Conclusion: Transformer-based attention是一种用于固态强场物理学的多功能工具，能够选择性地过滤时域中的强耦合事件，实现高维量子动力学的可解释机器学习，为阿秒光谱学和非线性光子学开辟了新的可能性。

Abstract: High-harmonic generation (HHG) in solids provides a powerful platform to
probe ultrafast electron dynamics and interband--intraband coupling. However,
disentangling the complex many-body contributions in the HHG spectrum remains
challenging. Here we introduce a machine-learning approach based on a
Transformer encoder to analyze and reconstruct HHG signals computed from a
one-dimensional Kronig--Penney model. The self-attention mechanism inherently
highlights correlations between temporal dipole dynamics and high-frequency
spectral components, allowing us to identify signatures of nonadiabatic band
coupling that are otherwise obscured in standard Fourier analysis. By combining
attention maps with Gabor time--frequency analysis, we extract and amplify weak
coupling channels that contribute to even-order harmonics and anomalous
spectral features. Our results demonstrate that multi-head self-attention acts
as a selective filter for strong-coupling events in the time domain, enabling a
physics-informed interpretation of high-dimensional quantum dynamics. This work
establishes Transformer-based attention as a versatile tool for solid-state
strong-field physics, opening new possibilities for interpretable machine
learning in attosecond spectroscopy and nonlinear photonics.

</details>


### [322] [Two-Dimensional Altermagnetic Iron Oxyhalides: Real Chern topology and Valley-Spin-Lattice coupling](https://arxiv.org/abs/2510.12748)
*Yong-Kun Wang,Si Li,Shengyuan A. Yang*

Main category: cond-mat.mtrl-sci

TL;DR: Despite the rarity of topological insulating states in altermagnets, monolayer Fe2X2O (X = Cl, Br, I) are identified as 2D altermagnetic real Chern insulators with robust d-wave ordering, spin-split band gaps, and spin-polarized corner modes. These materials also exhibit spin-polarized valleys with strong altermagnetism-valley-spin-lattice coupling, allowing for valley-selective excitation and strain-induced valley polarization. The multiferroic Fe2Cl2O variant further shows strain-tunable N'eel vector switching, making these materials promising for spintronics and valleytronics.


<details>
  <summary>Details</summary>
Motivation: Identify new 2D altermagnetic real Chern insulators with topological insulating states and explore their potential for spintronics and valleytronics.

Method: Theoretical identification of monolayer Fe2X2O (X = Cl, Br, I) as 2D altermagnetic real Chern insulators, analyzing their electronic band structures, Chern numbers, and coupling effects.

Result: Monolayer Fe2X2O exhibits robust d-wave altermagnetic ordering, semiconducting band gaps, nontrivial real Chern numbers per spin channel, and spin-polarized topological corner modes. They also feature spin-polarized valleys with strong altermagnetism-valley-spin-lattice coupling, enabling valley-selective excitation and strain-induced valley polarization. In multiferroic Fe2Cl2O, strain can switch the N'eel vector.

Conclusion: 2D iron oxyhalides (Fe2X2O) represent a promising platform for exploring altermagnetism and magnetic topological states, with potential applications in spintronics and valleytronics due to their unique electronic and magnetic properties.

Abstract: Altermagnets, a novel class of collinear magnetic materials, exhibit unique
spin-split band structures, yet topological insulating states in intrinsic
altermagnetic systems are rare. Here, we identify monolayer Fe$_2X_2$O ($X$ =
Cl, Br, I) as a new family of 2D altermagnetic real Chern insulators. These
materials display robust $d$-wave altermagnetic ordering, semiconducting band
gaps, and nontrivial real Chern numbers per spin channel, yielding
spin-polarized topological corner modes. They also feature spin-polarized
valleys with strong altermagnetism-valley-spin-lattice coupling, enabling
valley-selective excitation via linear dichroism and strain-induced valley
polarization. In multiferroic Fe$_2$Cl$_2$O, magnetism coexists with
ferroelasticity, and an applied strain can switche the N\'eel vector. These
findings position 2D iron oxyhalides as a promising platform for exploring
altermagnetism and magnetic topological states for spintronics and
valleytronics.

</details>


### [323] [Two-Dimensional Na2LiAlP2 crystal for high-performance field-effect transistors](https://arxiv.org/abs/2510.12473)
*Run-Jie Peng,Xing-Yu Wang,Jun-Hui Yuan,Nian-Nian Yu,Kan-Hao Xue,Jiafu Wang,Pan Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 二维材料Na2LiAlP2在纳米尺度下表现出优异的晶体管特性，满足甚至超越了IRDS技术规范。


<details>
  <summary>Details</summary>
Motivation: 寻找超越摩尔定律限制的新型高性能、低功耗晶体管替代品，二维材料是很有希望的探索方向。

Method: 使用非平衡格林函数方法对二维材料Na2LiAlP2进行器件输运研究。

Result: 在5.7 nm沟道长度下，Na2LiAlP2表现出优异的n型晶体管特性，易于在低至0.1 V和0.2 V的工作电压下实现900 μA/μm的导通状态电流。其亚阈值摆幅在0.1 V下达到30.33 mV/dec，低于理论极限60 mV/dec。在7.9 nm沟道长度下，其p型晶体管性能也表现出色，亚阈值摆幅约为50 mV/dec。

Conclusion: Na2LiAlP2具有优异的晶体管性能，为二维高性能晶体管的研究开辟了新的方向。

Abstract: High-performance, low-power transistors are core components of advanced
integrated circuits, and the ultimate limitation of Moore's law has made the
search for new alternative pathways an urgent priority. Two-dimensional (2D)
materials have become the most promising exploration target due to their
exceptional electronic properties and scalability. In this work, we conducted
device transport research on the previously proposed 2D quaternary
semiconductor Na2LiAlP2 using the non-equilibrium Green's function method. The
results demonstrate that even with a channel length of 5.7 nm, Na2LiAlP2 still
exhibits excellent n-type transistor characteristics, fully meeting and
surpassing the technical specifications outlined in the International Roadmap
for Devices and Systems (IRDS). Encouragingly, the device can easily achieve
the required on-state current of 900 {\mu}A/{\mu}m under low operating voltages
of 0.1 V and 0.2 V. Moreover, at 0.1 V operating voltage, the device's
subthreshold swing breaks through the theoretical limit of 60 mV/dec, reaching
an astonishing value 30.33 mV/dec. Additionally, its p-type transistor
performance also stands out with a subthreshold swing of ~50 mV/dec when the
channel length is 7.9 nm. Our research not only showcases the exceptional
transistor properties of Na2LiAlP2 but also further expands the research scope
of 2D high-performance transistors.

</details>


### [324] [Anharmonic Effects in Ge2Sb2Te5 and Consequences on Thermodynamic Stability](https://arxiv.org/abs/2510.12526)
*Owain T. Beynon,Adham Hashibon*

Main category: cond-mat.mtrl-sci

TL;DR: GST是一种重要的相变材料，其在数字存储器中有广泛应用，但传统模型未能充分解释其相变行为。本研究通过从头密度泛函理论（DFT）计算，结合各种堆积模型和范德华相互作用，研究了GST的非谐行为，揭示了考虑非谐和色散效应对于准确模拟GST及其相变行为的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统的谐波近似模型未能充分解释驱动相变材料（如GST）相变行为的传热和晶格热膨胀等现象。

Method: 利用从头密度泛函理论（DFT）计算，研究了原始GST（无空位或缺陷）的非谐行为，并考虑了不同的堆积模型（Petrov和Kooi-De Hosson）以及范德华（vdW）相互作用。

Result: 研究结果表明，在模拟GST时，必须考虑非谐和色散效应，并且选择合适的堆积模型对于理解相变行为至关重要。

Conclusion: 本研究强调了在模拟GST材料时，纳入非谐和色散效应以及考虑不同的堆积模型对于准确预测其相变行为的重要性。

Abstract: Chalcogenide materials are an important class of phase change material (PCMs)
owing to their employment in digital memory solutions. Chalgogenide materials
have applications in phase change random access memory (PCRAM) due to their
ability to reversibly cycle between crystalline and amorphous states, and of
these materials Ge2Sb2Te5 (GST) is of particular interest due to its speed,
stability and low crystallisation temperatures. GST possesses two stable
crystalline polymorphs, cubic and hexagonal (trigonal system). Studies show
that phenomena such as heat transport and thermal lattice expansion drive the
phase-change nature of these materials. These phenomena are not incorporated in
the harmonic approximation, which is a popular model for describing vibrations
in solids. Through ab initio density functional theory (DFT), we
computationally investigate the anharmonic behaviour of pristine GST, without
vacancies or defects, while considering the various stacking models that exist
and inclusion of van der Waals (vdW) interactions in our modelling. We present
the vibrational analysis of different stacking models in GST; Petrov and
Kooi-De Hosson (KDH) models and the quantification anharmonic behaviour. Our
results demonstrate the importance of incorporating anharmonic and dispersion
effects when modelling GST, especially in the choice of stacking models, along
with implications for phenomena relating to phase-change behaviour.

</details>


### [325] [Escape-Induced Temporally Correlated Noise Driven Universality Crossover](https://arxiv.org/abs/2510.12593)
*Mrinal Manna,Sourav Mukherjee,Soumen Giri,Pramod Bhakuni,Sajal Barman,Arnab Kumar Pariari,Anil Gome,Markus Hucker,V. Raghavendra Reddy,Anupam Roy,Sudipta Roy Barman,Smarajit Karmakar,Chandana Mondal,Rajib Batabyal*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究在MnBi2Te4衬底上进行Sn薄膜外延生长实验，首次证实了时间关联噪声可以改变生长界面的标度律，并将原子尺度动力学与普适性行为联系起来。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡系统中驱动传输过程和噪声结构之间相互作用的普遍行为，以及Kardar-Parisi-Zhang (KPZ) 框架的预测。然而，在实验上实现这一点具有挑战性。

Method: 研究人员在Sb掺杂的MnBi2Te4衬底上进行Sn薄膜外延生长，并利用分子动力学模拟和俄歇电子能谱来分析原子尺度的行为。

Result: 实验观察到两种不同的生长模式之间的清晰动态转换：早期生长遵循守恒KPZ标度律，形成二维岛和 stanene 层；在临界沉积时间之后，时间关联噪声起主导作用，导致α-Sn簇的成核，并演化成具有faceted的β-Sn晶粒，同时与faceted的β-Sn共存。

Conclusion: 本研究首次证明，时间噪声关联可以从根本上改变生长界面的标度律，将原子动力学与非平衡系统中的普适性行为联系起来。

Abstract: Universal behavior in far-from-equilibrium systems is driven by interactions
between transport processes and noise structure. The Kardar-Parisi-Zhang (KPZ)
framework predicts that extensions incorporating conserved currents or
temporally correlated noise give rise to distinct growth morphologies and
universality classes, yet direct experimental realization has remained elusive.
Here, we report atomically resolved Sn thin-film growth on Sb-doped
MnBi$_2$Te$_4$, revealing a sharp dynamical crossover between two fundamentally
different regimes. Early stage growth follows conserved KPZ scaling, forming
two-dimensional islands and stanene layers. Beyond a critical deposition time,
temporally correlated noise dominates, driving the nucleation of $\alpha$ -Sn
clusters, their evolution into faceted grains, and coexistence with faceted
$\beta$-Sn. Molecular dynamics simulation and Auger electron spectroscopy show
adatom escape as the microscopic origin of temporally correlated noise,
providing a microscopic mechanism for the universality crossover. These
findings establish, for the first time, that temporal noise correlations can
fundamentally alter the scaling class of a growing interface, linking atomistic
kinetics to emergent universal behavior.

</details>


### [326] [Formation of C-centers in Si-based systems by light ion irradiation](https://arxiv.org/abs/2510.12690)
*Carolina Crosta,Riccardo Nardin,Patrick Daoust,Stefano Achilli,Ian Colombo,Matteo Campostrini,Emiliano Bonera,Jacopo Pedrini,Oussama Moutanabbir,Valentino Rigato,Fabio Pezzoli*

Main category: cond-mat.mtrl-sci

TL;DR: 使用 H+ 和 He+ 离子在硅中生成近红外量子发射体，实现了1550nm的荧光和微秒级别的长寿命激子，并成功将此技术应用于 Ge-on-Si 异质结构，为集成量子光子学提供了前景。


<details>
  <summary>Details</summary>
Motivation: 在硅中可控地创建近红外色心，以用于长距离量子通信和信息处理，仍然是一个挑战。

Method: 利用 H+ 和 He+ 等轻离子在硅晶体中生成量子发射体，并通过温度依赖的光致发光和时间分辨测量来表征这些发射体。此外，探索了控制离子辐照策略在 Ge-on-Si 异质结构中生成 C-中心。

Result: 实验证明了光学活性缺陷的存在，其荧光匹配1550nm的主要电信窗口。时间分辨研究揭示了微秒级别的长寿命激子态，证实了间隙氧-碳复合物（C-中心）的形成。在 Ge-on-Si 异质结构中也成功生成了 C-中心。

Conclusion: 在硅中利用轻离子可控地生成 C-中心，并将其应用于 Ge-on-Si 异质结构，为推进基于光的量子技术领域提供了有前景的策略和有益的策略。

Abstract: Atomic-scale crystal defects in Si are quantum-light sources offering
tantalizing integration with existing photonic technologies. Yet, the
controlled creation of near-infrared color centers for long- haul quantum
communication and information still remains a challenge. In this work, we
utilize light ions, such as H+ and He+, to gently generate quantum emitters in
a crystalline Si matrix. Temperature-dependent photoluminescence measurements
demonstrate the presence of optically-active defects, whose fluorescence
matches the primary telecom window around 1550 nm. In addition, time-resolved
investigations unveil long-lived excitonic states in the {\mu}s regime, thus
confirming the formation of interstitial oxygen-carbon complexes, termed
C-centers. Finally, we explored controlled ion irradiation strategies to
seamlessly generate C-centers also in Ge-on-Si heterostructures, which offer an
advanced technological platform for the future realization of integrated
quantum photonics. This analysis, informed by practical color center synthesis
and proof-of-principle experiments in epitaxial architectures, indicates
intriguing prospects and profitable strategies to advance the burgeoning field
of light-based quantum technologies.

</details>


### [327] [Oxygen-vacancy-induced Raman softening in the catalyst Fe$_2$(MoO$_4$)$_3$](https://arxiv.org/abs/2510.12746)
*Young-Joon Song,Roser Valentí*

Main category: cond-mat.mtrl-sci

TL;DR: Fe2(MoO4)3催化甲醇氧化脱氢制甲醛过程中，拉曼光谱强度的变化是由于氧原子的振动，而非结构对称性的改变。


<details>
  <summary>Details</summary>
Motivation: 阐明Fe2(MoO4)3催化甲醇氧化脱氢制甲醛过程中拉曼光谱强度变化背后的微观机制。

Method: 使用密度泛函理论（DFT）计算，通过声子分析和冻ghi-声子方法，研究了Fe2(MoO4)3中氧原子的振动模式及其对拉曼光谱强度的影响，并模拟了氧空位的形成对结构对称性的影响。

Result: DFT计算结果表明，782 cm-1附近的氧主导振动模式与实验观测到的拉曼强度降低相对应。模拟的氧空位形成过程显示，局域对称性无明显改变。

Conclusion: 实验观测到的Fe2(MoO4)3拉曼光谱强度变化源于氧原子的振动，而不是结构对称性的变化。氧原子可以从体相迁移到表面参与催化，且该过程对局域对称性无显著影响。

Abstract: Although iron molybdate (Fe$_2$(MoO$_4$)$_3$) has been commercially utilized
for the production of formaldehyde from methanol via oxidative dehydrogenation,
the detailed mechanism during the catalytic process remains unclear. Recent
operando Raman and impedance measurements of the reaction suggested that the
bulk region of Fe$_2$(MoO$_4$)$_3$ acts as a reservoir of oxygen atoms that can
migrate to the surface to participate in catalysis. This conclusion was drawn
from the observed significant reduction in Raman intensity during the catalytic
process which implies the formation of atomic defects. However, the microscopic
origin of this reduction remains to be clarified. In this work, we performed
density functional theory (DFT) calculations to elucidate the origin of the
experimentally observed Raman intensity variation. Our phonon analysis reveals
that oxygen-dominated vibrational modes, with a small Mo contribution, occur
near 782 cm$^{-1}$-the same frequency region where the Raman intensity
reduction was measured. Using an effective frozen-phonon approach, we further
demonstrate that oxygen vibrations are primarily responsible for the decrease
in calculated Raman intensity. Moreover, structural relaxation of
Fe$_2$(MoO$_4$)$_3$ including an oxygen vacancy suggests that oxygen diffusion
from the bulk to the surface should occur without significant alteration of the
local symmetry, consistent with the absence of measurable peak shifts or
broadening in the experimental Raman spectra.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [328] [A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission](https://arxiv.org/abs/2510.11867)
*Zelin Gan,Henrique Buglia,Romulo Aparecido,Mindaugas Jarmolovičius,Eric Sillekens,Jiaqian Yang,Ronit Sohanpal,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 提出了一个用于低色散O波段传输系统的非线性干扰（NLI）估计的新型闭式解模型，该模型考虑了四波混频（FWM）效率以及自相位和交叉相位调制（SPM/XPM）的相干贡献，能够准确评估传统高斯噪声（GN）模型受限情况下的NLI。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够准确评估低色散O波段传输系统中非线性干扰（NLI）的新型闭式解模型，以克服现有高斯噪声（GN）模型的局限性。

Method: 提出并验证了一个包含四波混频（FWM）效率以及自相位和交叉相位调制（SPM/XPM）相干贡献的闭式解模型，并通过与分裂步傅里叶法（SSFM）模拟和数值积分进行对比验证。

Result: 在包含41-161个信道、96 GBaud符号率、高达16.1 THz带宽和80-800 km传输距离的条件下，该模型将NLI信噪比（SNR）的平均绝对误差控制在0.22 dB以下。

Conclusion: 所提出的闭式解模型为O波段相干传输中的系统优化提供了一个高效且准确的工具。

Abstract: We present a novel closed-form model for nonlinear interference (NLI)
estimation in low-dispersion O-band transmission systems. The formulation
incorporates the four-wave mixing (FWM) efficiency term as well as the coherent
contributions of self- and cross-phase modulation (SPM/XPM) across multiple
identical spans. This extension enables accurate evaluation of the NLI in
scenarios where conventional closed-form Gaussian Noise (GN) models are
limited. The proposed model is validated against split-step Fourier method
(SSFM) simulations and numerical integration across 41-161 channels, with a 96
GBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances
from 80 to 800 km. Results show a mean absolute error of the NLI
signal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model
offers an efficient and accurate tool for system optimisation in O-band
coherent transmission.

</details>


### [329] [Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems](https://arxiv.org/abs/2510.11891)
*Haoran He*

Main category: eess.SP

TL;DR: 本文提出一种基于深度神经网络（DNN）的信道估计算法，用于解决大规模MIMO系统中的信道估计算法，相较于传统方法，具有更高的精度和更低的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了在5G及未来通信系统中解决导频污染和高移动性问题，提高系统可靠性，需要更精准的信道估计算法。

Method: 提出一种包含多层感知机（MLP）和ReLU激活函数的DNN架构，包含3个隐藏层（256、128、64个神经元），使用Adam优化器（学习率1e-4）和均方误差（MSE）损失函数。该模型通过学习导频信号来预测信道矩阵。

Result: 在COST 2100数据集上，该DNN模型在不同信噪比（SNR）下实现了更低的归一化均方误差（NMSE）和误比特率（BER）。在信噪比为中等水平时，DNN在NMSE方面比最小二乘法（LS）和最小均方误差法（MMSE）提高了3-5 dB，并且在高移动性场景下表现稳定。模型具有2.3 GFlops的计算复杂度、15.6k个参数和1.8 ms的推理时间（在树莓派4上），验证了其部署的可行性。

Conclusion: 该DNN模型在解决大规模MIMO信道估计问题上取得了显著成效，能够有效降低NMSE和BER，并具备部署可行性，为未来无线通信网络中的资源分配和频谱效率提升提供了新的途径。

Abstract: This paper proposes a machine learning-assisted channel estimation approach
for massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE
methods. In 5G and beyond, accurate channel estimation mitigates pilot
contamination and high mobility issues that harm system reliability. The
proposed DNN architecture includes multi-layer perceptrons with ReLU
activation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam
optimizer (learning rate 1e-4) and MSE loss function. It learns from pilot
signals to predict channel matrices, achieving lower NMSE and BER across
different SNR levels. Simulations use the COST 2100 public standard dataset (a
well-recognized MIMO channel dataset for 5G, not synthetic datasets) with
10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show
the DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust
performance in high-mobility scenarios. The study evaluates metrics like NMSE
vs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations,
and computational complexity. The DNN has 2.3 GFlOPs computational complexity,
15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying
deployment feasibility. This work advances ML integration in wireless
communications, facilitating efficient resource allocation and improved
spectral efficiency in next-generation networks. Future work may use more
real-world datasets and hybrid architectures for better generalization.

</details>


### [330] [Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation](https://arxiv.org/abs/2510.11925)
*Yanan Du,Zeyang Sun,Yilan Zhang,Sai Xu,Beiyuan Liu*

Main category: eess.SP

TL;DR: 本论文提出了一种基于STAR-IRS的安全室内通信方案，利用GNN优化信号传输以最大化保密率，并通过FPGA加速器降低延迟。


<details>
  <summary>Details</summary>
Motivation: 为了在存在窃听者的情况下保护室内通信安全，需要一种能够增强目标用户接收信号并削弱窃听者接收信号的通信方案。

Method: 提出了一种基于STAR-IRS的通信方案，其中IRS动态地将信号分为透射和反射两部分。反射信号用于增强目标用户（Bob）的接收，而透射信号则通过符号级随机相位偏移来干扰窃听者（Eve）的信号。在此基础上，构建了一个以最大化保密率为目标的问题，并提出了一种基于图神经网络（GNN）的优化算法来解决该问题。此外，还设计了一个基于FPGA的GNN加速器以减少计算延迟。

Result: 仿真结果表明，所提出的STAR-IRS方案在保密性能上优于传统方案和仅反射方案。基于GNN的优化算法在解决优化问题方面优于最大比传输（MRT）、迫零（ZF）和最小均方误差（MMSE）等基准技术。FPGA加速器实现了低推理延迟。

Conclusion: 所提出的基于GNN的STAR-IRS安全通信方案能够有效提升室内通信的保密性能，并且FPGA加速器可以满足实际应用对低延迟的需求。

Abstract: This paper proposes a secure indoor communication scheme based on
simultaneous transmitting and reflecting intelligent reflecting surface
(STAR-IRS). Specifically, a transmitter (Alice) sends confidential information
to its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk
outside. To safeguard the transmission from eavesdropping, the STAR-IRS is
deployed on walls or windows. Upon impinging on the STAR-IRS, the incoming
electromagnetic wave is dynamically partitioned into two components, enabling
both transmission through and reflection from the surface. The reflected signal
is controlled to enhance reception at Bob, while the transmitted signal is
modulated with symbol-level random phase shifts to degrade the signal quality
at Eves. Based on such a setting, the secrecy rate maximization problem is
formulated. To solve it, a graph neural network (GNN)-based scheme is
developed. Furthermore, a field-programmable gate array (FPGA)-based GNN
accelerator is designed to reduce computational latency. Simulation results
demonstrate that the proposed strategy outperforms both the conventional scheme
and the reflection-only scheme in terms of secrecy performance. Moreover, the
GNN-based approach achieves superior results compared to benchmark techniques
such as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean
square error (MMSE) in solving the optimization problem. Finally, experimental
evaluations confirm that the FPGA-based accelerator enables low inference
latency.

</details>


### [331] [62.6 GHz ScAlN Solidly Mounted Acoustic Resonators](https://arxiv.org/abs/2510.11994)
*Yinan Wang,Byeongjin Kim,Nishanth Ravi,Kapil Saha,Supratik Dasgupta,Vakhtang Chulukhadze,Eugene Kwon,Lezli Matto,Pietro Simeoni,Omar Barrera,Ian Anderson,Tzu-Hsuan Hsu,Jue Hou,Matteo Rinaldi,Mark S. Goorsky,Ruochen Lu*

Main category: eess.SP

TL;DR: 本文展示了一种创纪录的62.6 GHz声波谐振器，其工作频率创下新高。


<details>
  <summary>Details</summary>
Motivation: 开发更高频率的声波谐振器以满足下一代射频前端对滤波器和谐振器的需求。

Method: 使用67.6 nm的(Sc0.3Al0.7N)压电层和40 nm的铂底部电极，构建了声波谐振器，并利用SiO2和Ta2O5层组成的声学布拉格反射器来约束声波模式。

Result: 实现了62.6 GHz的谐振频率，提取的压电耦合系数（k2）为0.8%，最大鲍德品质因数（Q）为51。工作频率高于以往报道的任何声波谐振器。

Conclusion: 该研究为开发用于下一代射频前端的毫米波声波谐振器和滤波器奠定了基础。

Abstract: We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator
(SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N)
piezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode,
positioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2
nm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and
piezoelectric stack above are designed to confine a third-order
thickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently
transducing with thickness-field excitation. The fabricated SMR exhibits an
extracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode
quality factor (Q) of 51 at 63 GHz, representing the highest operating
frequency reported for an SMR to date. These results establish a pathway toward
mmWave SMR devices for filters and resonators in next-generation RF front ends.

</details>


### [332] [A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation](https://arxiv.org/abs/2510.12179)
*Abdullahi Mohammad,Bdah Eya,Bassant Selim*

Main category: eess.SP

TL;DR: 该论文提出了一种基于CNN-LSTM和注意力机制的多任务学习框架，用于联合估计无线通信系统中冲激噪声的统计参数。


<details>
  <summary>Details</summary>
Motivation: 冲激噪声对无线通信系统的可靠性提出了严峻挑战，需要准确估计其统计参数以进行有效抑制。

Method: 提出了一种基于CNN-LSTM和注意力机制的多任务学习框架，并使用统一的加权损失函数来同时学习多个参数。

Result: 实验结果表明，所提出的多任务学习框架具有稳定的收敛性、更快的训练速度和更好的可扩展性，同时计算开销适中。与传统的单任务学习模型相比，该模型在复杂性-性能权衡和内存节省方面表现更优。

Conclusion: 多任务学习方法在无线通信系统的实时冲激噪声参数估计方面是有效的。

Abstract: Impulsive noise poses a significant challenge to the reliability of wireless
communication systems, necessitating accurate estimation of its statistical
parameters for effective mitigation. This paper introduces a multitask learning
(MTL) framework based on a CNN-LSTM architecture enhanced with an attention
mechanism for the joint estimation of impulsive noise parameters. The proposed
model leverages a unified weighted-loss function to enable simultaneous
learning of multiple parameters within a shared representation space, improving
learning efficiency and generalization across related tasks. Experimental
results show that the proposed MTL framework achieves stable convergence,
faster training, and enhanced scalability with modest computational overhead.
Benchmarking against conventional single-task learning (STL) models confirms
its favorable complexity-performance trade-off and significant memory savings,
indicating the effectiveness of the MTL approach for real-time impulsive noise
parameter estimation in wireless systems.

</details>


### [333] [Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering](https://arxiv.org/abs/2510.12204)
*Zhen Du,Jingjing Xu,Yifeng Xiong,Jie Wang,Musa Furkan Keskin,Henk Wymeersch,Fan Liu,Shi Jin*

Main category: eess.SP

TL;DR: 本文提出了一种统一的概率星座整形（PCS）框架，以提高6G无线网络中集成传感与通信（ISAC）的传感性能，同时保持通信能力。


<details>
  <summary>Details</summary>
Motivation: OFDM信号可用于ISAC，但有限星座调制（如QAM）会降低传感性能。需要在不显著影响通信能力的情况下提高传感性能是一个挑战。

Method: 提出了一种统一的概率星座整形（PCS）框架，通过最大化通信速率并对传感信道状态信息（CSI）的均方误差（MSE）、功率和概率分布进行约束来实现。该框架利用传感CSI的MSE来优化传感能力，并分析了其与输出信噪比（SNRout）和积分旁瓣比（ISLR）的关系。

Result: 所提出的PCS方法在实现灵活的传感与通信（S&C）权衡方面是有效的，并且在实际场景中增强6G无线传输方面是可信的。

Conclusion: 所提出的PCS框架能够有效地在传感和通信之间进行权衡，并提高6G无线网络的性能。

Abstract: Integrated sensing and communications (ISAC) is considered an innovative
technology in sixth-generation (6G) wireless networks, where utilizing
orthogonal frequency division multiplexing (OFDM) communication signals for
sensing provides a cost-effective solution for implementing ISAC. However, the
sensing performance of matched and mismatched filtering schemes can be
significantly deteriorated due to the signaling randomness induced by
finite-alphabet modulations with nonconstant modulus, such as quadrature
amplitude modulation (QAM) constellations. Therefore, improving sensing
performance without significantly compromising communication capability (i.e.,
maintaining randomness), remains a challenging task. To that end, we propose a
unified probabilistic constellation shaping (PCS) framework that is compatible
with both matched and mismatched filtering schemes, by maximizing the
communication rate while imposing constraints on mean square error (MSE) of
sensing channel state information (CSI), power, and probability distribution.
Specifically, the MSE of sensing CSI is leveraged to optimize sensing
capability, which is illustrated to be a more comprehensive metric compared to
the output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR).
Additionally, the internal relationships among these three sensing metrics are
explicitly analyzed. Finally, both simulations and field measurements validate
the efficiency of proposed PCS approach in achieving a flexible S&C trade-off,
as well as its credibility in enhancing 6G wireless transmission in real-world
scenarios.

</details>


### [334] [Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models](https://arxiv.org/abs/2510.12279)
*Benedikt Böck,Amar Kasibovic,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 链接层信道模型（如3GPP TDL和CDL）常用于评估基于机器学习（ML）的物理层方法，但本文认为这种方法存在局限性，可能导致分布偏移或需要在线训练。此外，它还会导致（近）高斯信道特性，使得在链接层信道数据上训练的ML模型在多种物理层应用中表现不佳，甚至不如经典的线性方法。本文提出采用场景层面的视角来解决这些问题，并实现ML的潜在优势。


<details>
  <summary>Details</summary>
Motivation: 现有的标准化链接层信道模型（如3GPP TDL和CDL）在评估基于机器学习（ML）的物理层方法时存在局限性，可能导致分布偏移、需要在线训练，并且倾向于产生（近）高斯信道特性，这使得ML模型难以超越经典的线性方法。

Method: 通过分析链接层信道模型的局限性，论证了其不适用于评估ML模型，并提出采用场景层面的视角来解决问题。

Result: 在链接层信道模型下，ML模型无法超越简单的线性方法（如信道压缩、估计和建模）。然而，采用场景层面的视角可以实现ML的潜在优势。

Conclusion: 链接层信道模型存在固有的局限性，不适合评估ML在物理层应用中的性能。采用场景层面的视角是克服这些局限性并发挥ML优势的关键。

Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models
are frequently used to evaluate machine learning (ML)-based physical-layer
methods. However, in this work, we argue that a link-level perspective
incorporates limiting assumptions, causing unwanted distributional shifts or
necessitating impractical online training. An additional drawback is that this
perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based
models, trained on link-level channel data, do not outperform classical
approaches for a variety of physical-layer applications. Particularly, we
demonstrate the optimality of simple linear methods for channel compression,
estimation, and modeling, revealing the unsuitability of link-level channel
models for evaluating ML models. On the upside, adopting a scenario-level
perspective offers a solution to this problem and unlocks the relative gains
enabled by ML.

</details>


### [335] [A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS](https://arxiv.org/abs/2510.12315)
*Piyush Priyanshu,Sudhan Majhi,Subhabrata Paul*

Main category: eess.SP

TL;DR: 该论文提出了一种使用线性算子和广义布尔函数（GBF）来构造所有8种4阶循环Hadamard矩阵的新方法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是提供一种新的方法来构造循环Hadamard矩阵，并利用这些矩阵来构造二进制交叉Z互补集（CZCS）、二进制Golay互补集（GCS）和Hadamard矩阵，特别是解决之前无法构造所有长度的二进制CZCS的问题，并为GCS和Hadamard矩阵提供更优的构造方法。

Method: 该研究利用线性算子和广义布尔函数（GBF）来构造4阶循环Hadamard矩阵，并递归地使用这些矩阵来构造二进制CZCS、GCS和Hadamard矩阵。同时，也提出了一种使用循环矩阵构造二进制GCS和Hadamard矩阵的低复杂度方法，并将GCS推广到二进制完全互补码（CCC），将CZCS推广到二进制最优交叉Z互补序列集（CZCSS）。

Result: 研究成功构造了所有8种4阶循环Hadamard矩阵，并利用它们构造了所有长度的二进制CZCS（这是首次实现）、所有长度的二进制GCS以及$2^{n+2}$阶Hadamard矩阵。此外，还提出了一种更优的二进制GCS和Hadamard矩阵的构造方法，以及参数为$(2N,2N,2N)-CCC$和$(2^{n+2}, 2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$的构造方法。

Conclusion: 该研究提出的构造方法是新颖的，并且与现有的最先进方法相比具有优越的参数。研究还揭示了Hadamard矩阵与GCS之间的新关系，为Hadamard猜想的研究开辟了新方向。

Abstract: A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\pm 1$,
such that $HH^\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A
circulant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in
cyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and
here, we provide a novel construction of all such $8$ circulant Hadamard
matrices using a linear operator and generalized Boolean function (GBF). The
constructed circulant Hadamard matrices are used recursively to construct a
binary cross Z-complementary set (CZCS) of all lengths with an even phase, a
binary Golay complementary set (GCS) of all lengths, and Hadamard matrices of
order $2^{n+2}$, where $n\geq1$. The construction of a binary CZCS covering all
lengths was not available before. We also propose an alternative,
lower-complexity construction of binary GCSs of all lengths and Hadamard
matrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c
\geq 0$. The proposed binary GCS covers all lengths with a flexible flock size.
The constructions of GCS are further extended to form binary complete
complementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where
$N=2^a10^b26^c, a,b,c \geq 0$. The constructed binary CCC provides a flexible
flock size. The construction of CZCS is further extended to form a binary
optimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2},
2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\geq1$. Finally, we provide a
relation between Hadamard matrices and GCS, which enables the study of the
Hadamard conjecture in a new direction. We also provided a few properties of
circulant matrices over aperiodic cross-correlation (ACCF) and aperiodic
auto-correlation (AACF), which are used to prove the theorems. All proposed
constructions are novel, and their parameters are compared with the existing
state-of-the-art.

</details>


### [336] [Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models](https://arxiv.org/abs/2510.12366)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: BD-RIS比传统RIS更具灵活性，但现有研究忽略了EM效应。本文提出了一个更通用的物理一致模型，并在此基础上进行了BD-RIS的架构设计和优化。


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS研究忽略了EM效应，本文旨在解决此问题。

Method: 利用多端口网络理论推导了一个通用的物理一致模型，并在此基础上进行了BD-RIS的架构设计和优化，包括SISO、MIMO系统的优化算法。

Result: 证明了带连接RIS与全连接RIS具有相同的信道整形能力，并开发了相应的优化算法，通过仿真评估了EM效应和近似对系统性能的影响。

Conclusion: 本文提出了一个更通用的物理一致模型，并在此基础上进行了BD-RIS的架构设计和优化，为BD-RIS的实际应用提供了理论和算法支持。

Abstract: Reconfigurable intelligent surface (RIS) is a promising technology for future
wireless communication systems. Conventional RIS is constrained to a diagonal
scattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS
(BD-RIS) has been proposed as a more general RIS architecture class that allows
inter-element connections and shows great potential for performance
improvement. Despite extensive progress on BD-RIS, most existing studies rely
on simplified channel models that ignore practical electromagnetic (EM) effects
such as mutual coupling and impedance mismatching. To address this gap, this
paper investigates the architecture design and optimization of BD-RIS under the
general physics-consistent model derived with multiport network theory in
recent literature. Building on a compact reformulation of this model, we show
that band-connected RIS achieves the same channel-shaping capability as
fully-connected RIS, which extends existing results obtained for conventional
channel models. We then develop optimization methods under the general
physics-consistent model; specifically, we derive closed-form solutions for
single-input single-output (SISO) systems, propose a globally optimal
semidefinite relaxation (SDR)-based algorithm for single-stream multi-input
multi-output (MIMO) systems, and design an efficient alternating direction
method of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using
the proposed algorithms, we conduct comprehensive simulations to evaluate the
impact of various EM effects and approximations, including mutual coupling
among RIS antennas and the commonly adopted unilateral approximation, on system
performance.

</details>


### [337] [HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation](https://arxiv.org/abs/2510.12515)
*Zhige Chen,Chengxuan Qin,Wenlong You,Rui Liu,Congying Chu,Rui Yang,Kay Chen Tan,Jibin Wu*

Main category: eess.SP

TL;DR: HEAR是首个支持异构EEG设备（不同电极布局和数量）的EEG基础模型，通过可学习的坐标嵌入和空间引导Transformer统一了空间表示，并在大规模数据集上证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: EEG设备的多样性（不同电极布局和数量）阻碍了现有EEG基础模型的广泛应用、扩展和进一步发展。

Method: HEAR采用可学习的坐标嵌入将不同电极映射到统一空间，并使用新颖的空间引导Transformer捕捉时空依赖性。同时，构建了一个包含8782小时、150多种电极布局、最多1132个电极的大规模EEG数据集来支持HEAR。

Result: 实验结果表明，HEAR在支持异构EEG设备以及在不同认知任务和受试者之间进行泛化方面，显著优于现有的EEG基础模型。

Conclusion: HEAR是解决EEG设备异构性问题的有效EEG基础模型，通过创新的空间嵌入和Transformer架构，为EEG研究和BCI应用提供了更强的通用性和可扩展性。

Abstract: Electroencephalography (EEG) is an essential technique for neuroscience
research and brain-computer interface (BCI) applications. Recently, large-scale
EEG foundation models have been developed, exhibiting robust generalization
capabilities across diverse tasks and subjects. However, the heterogeneity of
EEG devices not only hinders the widespread adoption of these models but also
poses significant challenges to their further scaling and development. In this
paper, we introduce HEAR, the first EEG foundation model explicitly designed to
support heterogeneous EEG devices, accommodating varying electrode layouts and
electrode counts. HEAR employs a learnable, coordinate-based spatial embedding
to map electrodes with diverse layouts and varying counts into a unified
representational space. This unified spatial representation is then processed
by a novel spatially-guided transformer, which effectively captures
spatiotemporal dependencies across electrodes. To support the development of
HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data
collected from over 150 distinct electrode layouts with up to 1,132 electrodes.
Experimental results demonstrate that HEAR substantially outperforms existing
EEG foundation models in supporting heterogeneous EEG devices and generalizing
across diverse cognitive tasks and subjects.

</details>


### [338] [A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks](https://arxiv.org/abs/2510.12648)
*Abdelali Arous,Hamza Haif,Arman Farhang,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本篇论文探讨了时频域以外的延迟-多普勒和चिरप域等替代复用域，以应对复杂传播环境和下一代应用的挑战。文章分析了不同域下信道特征及其相互关系，并提出了一种广义自适应变换域框架，能够根据信道条件动态切换域。最后，通过具体用例展示了该框架的适用性，并指出了未来的发展方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 为了应对复杂传播环境和下一代应用的需求，探索时频域以外的延迟-多普勒和चिरप域等替代复用域。

Method: 分析了不同域下信道特征（如延迟、多普勒频移、信道系数）及其相互关系、共性和特性。提出了一种广义自适应变换域框架，该框架利用离散傅里叶变换（DFT）矩阵的前后处理，实现了在不同域之间的动态切换。

Result: 对不同域在特定信道条件下的比较优势进行了评估。提出的跨域波形处理框架在多种场景下展现了其应用潜力。

Conclusion: 时频域以外的域提供了独特的信道表示，增加了建模、表征和利用无线信道特征的自由度。提出的广义自适应变换域框架能够根据信道条件和系统需求动态切换域，为解决复杂无线通信问题提供了新的解决方案。

Abstract: The emergence of alternative multiplexing domains to the time-frequency
domains, e.g., the delay-Doppler and chirp domains, offers a promising approach
for addressing the challenges posed by complex propagation environments and
next-generation applications. Unlike the time and frequency domains, these
domains offer unique channel representations which provide additional degrees
of freedom (DoF) for modeling, characterizing, and exploiting wireless channel
features. This article provides a comprehensive analysis of channel
characteristics, including delay, Doppler shifts, and channel coefficients
across various domains, with an emphasis on their inter-domain relationships,
shared characteristics, and domain-specific distinctions. We further evaluate
the comparative advantages of each domain under specific channel conditions.
Building on this analysis, we propose a generalized and adaptive transform
domain framework that leverages the pre- and post-processing of the discrete
Fourier transform (DFT) matrix, to enable dynamic transitions between various
domains in response to the channel conditions and system requirements. Finally,
several representative use cases are presented to demonstrate the applicability
of the proposed cross-domain waveform processing framework in diverse
scenarios, along with future directions and challenges.

</details>


### [339] [Moment-based Posterior Sampling for Multi-reference Alignment](https://arxiv.org/abs/2510.12651)
*Axel Janson,Joakim Andén*

Main category: eess.SP

TL;DR: We introduce a Bayesian method using diffusion models for multi-reference alignment, reducing the need for many samples compared to existing frequentist approaches, and show its promise for applications like cryo-EM.


<details>
  <summary>Details</summary>
Motivation: Existing frequentist methods for multi-reference alignment require a large number of samples, even at low signal-to-noise ratios. This paper aims to reduce the required number of samples by proposing a Bayesian approach.

Method: The proposed method uses diffusion models as plug-and-play priors, conditioned on the sample power spectrum. This allows for accurate posterior sampling and uncertainty quantification.

Result: The Bayesian approach with diffusion model priors significantly reduces the number of samples required, as demonstrated in simulations comparing it to expectation-maximization and bispectrum inversion methods.

Conclusion: The developed Bayesian framework is effective for multi-reference alignment and shows potential for other orbit recovery problems, including cryo-EM.

Abstract: We propose a Bayesian approach to the problem of multi-reference alignment --
the recovery of signals from noisy, randomly shifted observations. While
existing frequentist methods accurately recover the signal at arbitrarily low
signal-to-noise ratios, they require a large number of samples to do so. In
contrast, our proposed method leverages diffusion models as data-driven
plug-and-play priors, conditioning these on the sample power spectrum (a
shift-invariant statistic) enabling both accurate posterior sampling and
uncertainty quantification. The use of an appropriate prior significantly
reduces the required number of samples, as illustrated in simulation
experiments with comparisons to state-of-the-art methods such as
expectation--maximization and bispectrum inversion. These findings establish
our approach as a promising framework for other orbit recovery problems, such
as cryogenic electron microscopy (cryo-EM).

</details>


### [340] [Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems](https://arxiv.org/abs/2510.12711)
*Muhammad Talha,Besma Smida,David González G*

Main category: eess.SP

TL;DR: 本论文提出了一种集成传感与通信（ISAC）框架，用于同时处理角度和距离域中的分布式目标。


<details>
  <summary>Details</summary>
Motivation: 研究目标是为角度和距离域中的分布式目标开发一种新的ISAC框架。

Method: 提出了一种截断的多信号分类传播（TMS）算法来估计目标密度函数的参数，并提出了一种基于离散傅里叶变换（DFT）的算法来估计目标的距离和范围扩展。在此基础上，开发了一种动态发射波束成形算法。

Result: 仿真结果表明，在低信噪比、高信噪比和宽角扩展条件下，所提出的算法优于基线方案。

Conclusion: 所提出的TMS算法和DFT算法能够有效地估计分布式目标的参数，并且动态发射波束成形算法可以成功地同时服务多个目标和下行用户。

Abstract: This work studies an integrated sensing and communication (ISAC) framework
for targets that are spread both in the angle and range domains. We model each
target using a cluster of rays parameterized by a specific density function,
and propose a truncated Multiple Signal Classification (MUSIC) spread (TMS)
algorithm to accurately estimate the parameters of the density function. Unlike
the conventional MUSIC spread (CMS), TMS restricts the signal subspace rank
based on the eigen decomposition of the received-signal autocorrelation. We
also propose a discrete Fourier transform (DFT) based algorithm for estimating
the distance and range spread of each target. Leveraging these estimates, we
then develop a dynamic transmit beamforming algorithm that successfully
illuminates multiple targets while also serving multiple downlink (DL) users.
Simulation results demonstrate the superiority of our proposed algorithms over
baseline schemes in both low and high signal-to-noise ratio (SNR) regimes as
well as under a wide angular spread regime.

</details>


### [341] [Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective](https://arxiv.org/abs/2510.12763)
*Saurabh Sihag,Gonzalo Mateos,Alejandro Ribeiro*

Main category: eess.SP

TL;DR: 脑龄差（BAGP）模型通过预测的脑龄与实际年龄之差来量化脑部健康状况，但其方法学不透明且泛化能力有限。本研究提出了一种基于图信号处理（GSP）和图神经网络（GNNs）的新框架，特别是引入了利用解剖协方差矩阵的协方差神经网络（VNN），以实现更可靠、可解释的BAGP模型。


<details>
  <summary>Details</summary>
Motivation: 传统的神经退行性测量方法（如皮层厚度和脑容量）缺乏足够的统计能力来捕捉神经退行性的复杂性。脑龄差（BAGP）作为一种新兴的生物标志物，具有潜力，但现有模型存在方法学不透明和泛化能力不足的问题，阻碍了其临床应用。

Method: 本研究提出了一种基于图信号处理（GSP）的新框架，特别是利用图神经网络（GNNs）和新提出的协方差神经网络（VNN）。VNN模型利用结构MRI衍生的解剖协方差矩阵，并具有良好的理论基础和可解释性，能够稳健地估计脑龄差。

Result: VNN模型通过整合GSP、机器学习和网络神经科学的观点，为实现可靠且可解释的BAGP模型提供了清晰的路径，并指出了个性化医疗领域未来的研究方向。

Conclusion: 本研究提出了一种基于GSP和GNNs（特别是VNN）的新框架，以解决现有BAGP模型在方法学和泛化能力方面的局限性，旨在实现更可靠、可解释的脑龄差预测，并推动其在个性化医疗中的应用。

Abstract: Neurodegeneration, characterized by the progressive loss of neuronal
structure or function, is commonly assessed in clinical practice through
reductions in cortical thickness or brain volume, as visualized by structural
MRI. While informative, these conventional approaches lack the statistical
sophistication required to fully capture the spatially correlated and
heterogeneous nature of neurodegeneration, which manifests both in healthy
aging and in neurological disorders. To address these limitations, brain age
gap has emerged as a promising data-driven biomarker of brain health. The brain
age gap prediction (BAGP) models estimate the difference between a person's
predicted brain age from neuroimaging data and their chronological age. The
resulting brain age gap serves as a compact biomarker of brain health, with
recent studies demonstrating its predictive utility for disease progression and
severity. However, practical adoption of BAGP models is hindered by their
methodological obscurities and limited generalizability across diverse clinical
populations. This tutorial article provides an overview of BAGP and introduces
a principled framework for this application based on recent advancements in
graph signal processing (GSP). In particular, we focus on graph neural networks
(GNNs) and introduce the coVariance neural network (VNN), which leverages the
anatomical covariance matrices derived from structural MRI. VNNs offer strong
theoretical grounding and operational interpretability, enabling robust
estimation of brain age gap predictions. By integrating perspectives from GSP,
machine learning, and network neuroscience, this work clarifies the path
forward for reliable and interpretable BAGP models and outlines future research
directions in personalized medicine.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [342] [nuGPR: GPU-Accelerated Gaussian Process Regression with Iterative Algorithms and Low-Rank Approximations](https://arxiv.org/abs/2510.12128)
*Ziqi Zhao,Vivek Sarin*

Main category: cs.LG

TL;DR: nuGPR是一个新的高斯过程回归框架，通过数值线性代数技术（如预处理共轭梯度法、低秩近似）和数值梯度优化，显著降低了GPR的训练成本和内存消耗，并在NVIDIA GPU上实现了高达2倍的速度提升和12倍的内存节省。


<details>
  <summary>Details</summary>
Motivation: 高斯过程回归（GPR）的训练计算成本高昂，阻碍了其广泛应用。

Method: 1. 预处理共轭梯度法加速线性求解。 2. 利用输入数据聚类，识别协方差矩阵的块对角结构，并构建低秩近似。 3. 使用数值梯度优化超参数，避免反向传播。 4. 利用CUDA并行化训练过程。

Result: 与现有的基于GPU的GPR实现相比，nuGPR在各种合成和真实数据集上，将总训练时间缩短了2倍，峰值内存消耗降低了12倍。

Conclusion: nuGPR通过结合多种数值线性代数技术和优化策略，有效解决了GPR的计算瓶颈，实现了显著的训练效率提升。

Abstract: Gaussian Process Regression (GPR) is an important type of supervised machine
learning model with inherent uncertainty measure in its predictions. We propose
a new framework, nuGPR, to address the well-known challenge of high computation
cost associated with GPR training. Our framework includes several ideas from
numerical linear algebra to reduce the amount of computation in key steps of
GPR, and we combine them to establish an end-to-end training algorithm.
Specifically, we leverage the preconditioned conjugate gradient method to
accelerate the convergence of the linear solves required in GPR. We exploit
clustering in the input data to identify block-diagonal structure of the
covariance matrix and subsequently construct low-rank approximations of the
off-diagonal blocks. These enhancements significantly reduce the time and space
complexity of our computations. In addition, unlike other frameworks that rely
on exact differentiation, we employ numerical gradients to optimize the
hyperparameters of our GPR model, further reducing the training cost by
eliminating the need for backpropagation. Lastly, we leverage the CUDA Toolkit
to efficiently parallelize the training procedure on NVIDIA GPUs. As a result,
nuGPR reduces total training time by up to 2x and peak memory consumption by up
to 12x on various synthetic and real-world datasets when compared to the best
existing GPU-based GPR implementation.

</details>


### [343] [Think as a Doctor: An Interpretable AI Approach for ICU Mortality Prediction](https://arxiv.org/abs/2510.11745)
*Qingwen Li,Xiaohang Zhao,Xiao Han,Hailiang Huang,Lanjuan Liu*

Main category: cs.LG

TL;DR: ProtoDoctor是一个新颖的ICU死亡率预测框架，它提供了内在的可解释性，并整合了ICU决策实践的三个关键要素：临床病程识别、人口统计学异质性和预后意识。该框架通过原型学习来识别临床病程，并使用新颖的正则化机制来实现预后意识，同时通过特定队列的原型和风险调整来模拟人口统计学异质性。实验证明，ProtoDoctor在预测准确性方面优于最先进的基线，并且其解释在临床上更有意义、更值得信赖，并且适用于ICU实践。


<details>
  <summary>Details</summary>
Motivation: ICU死亡率预测对于重症监护至关重要，但传统的预测方法往往只关注人口统计学异质性，而忽略了临床病程识别和预后意识。现有原型学习方法虽然解决了临床病程识别问题，但未能充分整合其他关键要素。因此，需要一个能够提供内在可解释性并整合ICU决策实践所有三个关键要素的预测框架。

Method: ProtoDoctor框架包含两个关键创新：预后临床病程识别模块和人口统计学异质性识别模块。前者利用原型学习识别临床病程，并通过新颖的正则化机制实现预后意识。后者通过特定队列的原型和风险调整来模拟人口统计学异质性。

Result: ProtoDoctor在预测准确性方面超越了最先进的基线方法。此外，人类评估证实，该框架的解释比现有方法更具临床意义、更值得信赖，并且更适用于ICU的实际操作。

Conclusion: ProtoDoctor框架在ICU死亡率预测任务中取得了显著的进展，它不仅提高了预测准确性，而且通过整合临床病程识别、人口统计学异质性和预后意识，提供了更具临床意义和可信度的解释，满足了临床实践和监管标准的需求。

Abstract: Intensive Care Unit (ICU) mortality prediction, which estimates a patient's
mortality status at discharge using EHRs collected early in an ICU admission,
is vital in critical care. For this task, predictive accuracy alone is
insufficient; interpretability is equally essential for building clinical trust
and meeting regulatory standards, a topic that has attracted significant
attention in information system research. Accordingly, an ideal solution should
enable intrinsic interpretability and align its reasoning with three key
elements of the ICU decision-making practices: clinical course identification,
demographic heterogeneity, and prognostication awareness. However, conventional
approaches largely focus on demographic heterogeneity, overlooking clinical
course identification and prognostication awareness. Recent prototype learning
methods address clinical course identification, yet the integration of the
other elements into such frameworks remains underexplored. To address these
gaps, we propose ProtoDoctor, a novel ICU mortality prediction framework that
delivers intrinsic interpretability while integrating all three elements of the
ICU decision-making practices into its reasoning process. Methodologically,
ProtoDoctor features two key innovations: the Prognostic Clinical Course
Identification module and the Demographic Heterogeneity Recognition module. The
former enables the identification of clinical courses via prototype learning
and achieves prognostication awareness using a novel regularization mechanism.
The latter models demographic heterogeneity through cohort-specific prototypes
and risk adjustments. Extensive empirical evaluations demonstrate that
ProtoDoctor outperforms state-of-the-art baselines in predictive accuracy.
Human evaluations further confirm that its interpretations are more clinically
meaningful, trustworthy, and applicable in ICU practice.

</details>


### [344] [GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving](https://arxiv.org/abs/2510.11769)
*Ruida Wang,Jiarui Yao,Rui Pan,Shizhe Diao,Tong Zhang*

Main category: cs.LG

TL;DR: GAR通过生成对抗性强化学习框架，联合训练问题生成器和求解器，引入隐式课程学习机制，提高了定理证明的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于固定问题集的强化学习方法训练效率低下且难以解决复杂问题。

Method: 提出GAR（Generative Adversarial Reinforcement learning）框架，在对抗性循环中联合训练问题生成器和求解器，并引入隐式课程学习机制。

Result: GAR训练的Goedel-Prover-V2-8B和DeepSeek-Prover-V2-7B在MiniF2F-Test基准测试上的平均相对改进率为4.20%，DeepSeek-Prover-V2在ProofNet-Test上的pass@32从22.58%提升至25.81%。

Conclusion: GAR框架不仅提升了定理证明的性能，还为可验证环境下的问题生成与求解协同进化提供了一个通用的强化学习范式。

Abstract: Solving math problems through verifiable languages such as Lean has
significantly impacted both the mathematics and computer science communities.
Current state-of-the-art models are often trained with expensive online
Reinforcement Learning (RL) or expert iteration. However, these approaches rely
on fixed problem sets, which causes inefficient training and limits the model
to tackle complex problems. To overcome these limitations, we propose GAR:
Generative Adversarial Reinforcement learning, a comprehensive RL training
framework that jointly trains the problem composer and solver in an adversarial
loop. GAR introduces an implicit curriculum learning mechanism, which aligns
task difficulty with the prover's evolving capability. It thereby improves the
training efficiency and enables stronger performance of proving advanced
theorems. Experiments show that with GAR training, Goedel-Prover-V2-8B and
DeepSeek-Prover-V2-7B achieve an average relative improvement in pass@32 of
4.20% on MiniF2F-Test benchmark, while DeepSeek-Prover-V2's pass@32 on
ProofNet-Test increases from 22.58% to 25.81%. Beyond formal proving, GAR
establishes a general RL paradigm for co-evolution of problem generation and
solving under verifiable environments.

</details>


### [345] [General Fourier Feature Physics-Informed Extreme Learning Machine (GFF-PIELM) for High-Frequency PDEs](https://arxiv.org/abs/2510.12293)
*Fei Ren,Sifan Wang,Pei-Zhi Zhuang,Hai-Sui Yu,He Yang*

Main category: cs.LG

TL;DR: GFF-PIELM通过将傅立叶特征映射整合到ELM作为其激活函数，并引入频率系数和创新的初始化方法，有效解决了传统PIELM在处理高频和变频PDEs时遇到的挑战，提高了预测精度且无额外成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统物理信息极限学习机（PIELM）在求解包含高频和变频行为的偏微分方程（PDEs）时面临的挑战。

Method: 将傅立叶特征映射（FFM）的变体整合到ELM中作为傅立叶基激活函数，为隐藏神经元分配频率系数，并通过监控ELM输出权重分布来初始化这些超参数。

Result: GFF-PIELM在五个案例研究（共十个数值示例）中表现出可行性和有效性，涉及高频、变频、多尺度行为、不规则边界和逆问题，与传统PIELM相比，在不增加训练时间和架构复杂性的情况下，显著提高了预测精度。

Conclusion: GFF-PIELM能够以高精度扩展到求解高频和变频PDEs，并且其初始化策略有望启发其他物理信息机器学习（PIML）框架的进展。

Abstract: Conventional physics-informed extreme learning machine (PIELM) often faces
challenges in solving partial differential equations (PDEs) involving
high-frequency and variable-frequency behaviors. To address these challenges,
we propose a general Fourier feature physics-informed extreme learning machine
(GFF-PIELM). We demonstrate that directly concatenating multiple Fourier
feature mappings (FFMs) and an extreme learning machine (ELM) network makes it
difficult to determine frequency-related hyperparameters. Fortunately, we find
an alternative to establish the GFF-PIELM in three main steps. First, we
integrate a variation of FFM into ELM as the Fourier-based activation function,
so there is still one hidden layer in the GFF-PIELM framework. Second, we
assign a set of frequency coefficients to the hidden neurons, which enables ELM
network to capture diverse frequency components of target solutions. Finally,
we develop an innovative, straightforward initialization method for these
hyperparameters by monitoring the distribution of ELM output weights. GFF-PIELM
not only retains the high accuracy, efficiency, and simplicity of the PIELM
framework but also inherits the ability of FFMs to effectively handle
high-frequency problems. We carry out five case studies with a total of ten
numerical examples to highlight the feasibility and validity of the proposed
GFF-PIELM, involving high frequency, variable frequency, multi-scale behaviour,
irregular boundary and inverse problems. Compared to conventional PIELM, the
GFF-PIELM approach significantly improves predictive accuracy without
additional cost in training time and architecture complexity. Our results
confirm that that PIELM can be extended to solve high-frequency and
variable-frequency PDEs with high accuracy, and our initialization strategy may
further inspire advances in other physics-informed machine learning (PIML)
frameworks.

</details>


### [346] [Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection](https://arxiv.org/abs/2510.11827)
*Simone Mungari,Ettore Ritacco,Pietro Sabatino*

Main category: cs.LG

TL;DR: Janus框架结合欧几里得和双曲图神经网络来检测节点级异常，通过对齐两种几何空间中的节点嵌入，有效识别复杂异常。


<details>
  <summary>Details</summary>
Motivation: 节点级异常检测（NAD）因其多样的结构模式和特征分布而面临挑战，但在欺诈检测、网络安全和推荐系统等领域具有重要应用价值。

Method: Janus框架利用欧几里得和双曲图神经网络捕捉节点表示的互补方面。每个节点通过原始特征和从随机游走及度数派生的结构特征形成两个视图，并分别嵌入欧几里得和双曲空间。一个多图自动编码器框架结合对比学习作为正则化项，对齐欧几里得和双曲空间中的嵌入，从而识别出视图难以协调的潜在异常节点。

Result: 在四个真实世界数据集上的实验表明，Janus框架持续优于浅层和深层基线模型。

Conclusion: 结合多种几何表示（欧几里得和双曲空间）为识别图中细微和复杂异常提供了一种强大而有效的方法。

Abstract: Node-level anomaly detection (NAD) is challenging due to diverse structural
patterns and feature distributions. As such, NAD is a critical task with
several applications which range from fraud detection, cybersecurity, to
recommendation systems. We introduce Janus, a framework that jointly leverages
Euclidean and Hyperbolic Graph Neural Networks to capture complementary aspects
of node representations. Each node is described by two views, composed by the
original features and structural features derived from random walks and
degrees, then embedded into Euclidean and Hyperbolic spaces. A multi
Graph-Autoencoder framework, equipped with a contrastive learning objective as
regularization term, aligns the embeddings across the Euclidean and Hyperbolic
spaces, highlighting nodes whose views are difficult to reconcile and are thus
likely anomalous. Experiments on four real-world datasets show that Janus
consistently outperforms shallow and deep baselines, empirically demonstrating
that combining multiple geometric representations provides a robust and
effective approach for identifying subtle and complex anomalies in graphs.

</details>


### [347] [Schrödinger bridge for generative AI: Soft-constrained formulation and convergence analysis](https://arxiv.org/abs/2510.11829)
*Jin Ma,Ying Tan,Renyuan Xu*

Main category: cs.LG

TL;DR: 生成式AI可被视为学习将简单参考度量映射到复杂数据分布的模型，这与经典薛定谔桥问题（SBP）有密切联系。然而，经典的SBP存在硬终端约束，在实际应用中可能不稳定。本文提出了一种软约束薛定谔桥问题（SCSBP），用惩罚函数代替硬终端约束，得到了更灵活的 McKean-Vlasov 型随机控制。文章证明了最优解的存在性，并证明了随着惩罚的增加，控制和价值函数会以线性速率收敛到经典SBP。分析基于 Doob 的 h-变换表示、薛定谔势的稳定性结果、Gamma 收敛和一个新的固定点论证。


<details>
  <summary>Details</summary>
Motivation: 经典的薛定谔桥问题（SBP）在生成式AI中存在硬终端约束，这在实际应用中，尤其是在高维或数据稀疏的情况下，往往会导致不稳定性。本文旨在解决这一挑战。

Method: 本文提出了一种软约束薛定谔桥问题（SCSBP），用惩罚函数代替硬终端约束，得到了一种更灵活的 McKean-Vlasov 型随机控制。文章利用 Doob 的 h-变换表示、薛定谔势的稳定性结果、Gamma 收敛和一个新的固定点论证来分析模型。

Result: 文章证明了对于所有惩罚水平，最优解都存在。并且，随着惩罚水平的增加，控制和价值函数都以线性速率收敛到经典SBP。

Conclusion: 这些结果不仅为软约束桥问题提供了量化的收敛保证，而且阐明了惩罚正则化如何实现鲁棒的生成建模、微调和迁移学习。

Abstract: Generative AI can be framed as the problem of learning a model that maps
simple reference measures into complex data distributions, and it has recently
found a strong connection to the classical theory of the Schr\"odinger bridge
problems (SBPs) due partly to their common nature of interpolating between
prescribed marginals via entropy-regularized stochastic dynamics. However, the
classical SBP enforces hard terminal constraints, which often leads to
instability in practical implementations, especially in high-dimensional or
data-scarce regimes. To address this challenge, we follow the idea of the
so-called soft-constrained Schr\"odinger bridge problem (SCSBP), in which the
terminal constraint is replaced by a general penalty function. This relaxation
leads to a more flexible stochastic control formulation of McKean-Vlasov type.
  We establish the existence of optimal solutions for all penalty levels and
prove that, as the penalty grows, both the controls and value functions
converge to those of the classical SBP at a linear rate. Our analysis builds on
Doob's h-transform representations, the stability results of Schr\"odinger
potentials, Gamma-convergence, and a novel fixed-point argument that couples an
optimization problem over the space of measures with an auxiliary entropic
optimal transport problem. These results not only provide the first
quantitative convergence guarantees for soft-constrained bridges but also shed
light on how penalty regularization enables robust generative modeling,
fine-tuning, and transfer learning.

</details>


### [348] [GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs](https://arxiv.org/abs/2510.12085)
*Heng Zhang,Tianyi Zhang,Yuling Shi,Xiaodong Gu,Yaomin Shen,Haochen You,Zijian Zhang,Yilei Yuan,Jin Huang*

Main category: cs.LG

TL;DR: GraphShaper通过多几何专门化来解决图神经网络在结构边界上的性能下降问题，通过动态融合不同几何空间的专家网络来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络方法在处理具有不同拓扑结构（如树状结构需要双曲几何，环状结构需要球面几何）的图时，在结构边界会遇到性能瓶颈，因为它们假设所有图结构都能在单一欧氏空间中编码，这导致了超过20个百分点的准确率损失。因此，需要设计能够尊重图结构内在几何多样性的对齐框架。

Method: 引入了名为GraphShaper的几何感知框架，该框架通过多几何专门化来增强图编码。它使用针对不同几何空间定制的专家网络，并根据局部结构特征动态计算融合权重，以自适应地整合几何属性。这种自适应融合在与文本嵌入对齐之前，能够保持结构的完整性。

Result: 在零样本设置下，GraphShaper在引用网络上实现了9.47%的准确率提升，在社交网络上实现了7.63%的准确率提升。

Conclusion: GraphShaper通过其多几何专门化方法，成功解决了图神经网络在处理复杂几何结构时的性能下降问题，并在多个基准测试中取得了显著的性能提升。

Abstract: Graph foundation models represent a transformative paradigm for learning
transferable representations across diverse graph domains. Recent methods
leverage large language models to unify graph and text modalities into a shared
representation space using contrastive learning. However, systematic
evaluations reveal significant performance degradation at structural boundaries
where distinct topological patterns converge, with accuracy losses exceeding 20
percentage points. This issue arises from a key limitation: current methods
assume all graph structures can be encoded within a single Euclidean space. In
reality, tree structures require hyperbolic geometry to preserve hierarchical
branching, while cyclic patterns depend on spherical geometry for closure
properties. At structural boundaries, nodes experience conflicting geometric
constraints that uniform encoding spaces cannot resolve. This raises a crucial
challenge: \textbf{Can alignment frameworks be designed to respect the
intrinsic geometric diversity of graph structures?} We introduce
\textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding
through multi-geometric specialization. Our approach employs expert networks
tailored to different geometric spaces, dynamically computing fusion weights to
adaptively integrate geometric properties based on local structural
characteristics. This adaptive fusion preserves structural integrity before
alignment with text embeddings. Extensive experiments demonstrate that
GraphShaper achieves 9.47\% accuracy improvements on citation networks and
7.63\% on social networks in zero-shot settings.

</details>


### [349] [Z0-Inf: Zeroth Order Approximation for Data Influence](https://arxiv.org/abs/2510.11832)
*Narine Kokhlikyan,Kamalika Chaudhuri,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 使用计算成本较低的零阶方法估计训练数据对模型预测行为的影响，特别是在模型调试和数据质量评估方面。


<details>
  <summary>Details</summary>
Motivation: 理解单个训练样本如何影响模型的预测行为对于分析和改进现代机器学习系统至关重要，尤其是在数据选择和模型调试等应用中。然而，现有方法在计算效率和准确性方面存在不足，难以扩展到大型模型。

Method: 提出一种高效的、仅需计算模型检查点损失值的零阶近似方法，用于估计训练数据的影响，该方法计算成本低，且不依赖于梯度或Hessian逆矩阵的计算。

Result: 该方法在估计自影响方面表现出更高的准确性，在估计训练-测试影响方面也与现有方法相当或更优，尤其是在微调大型语言模型时。该方法在时间和内存占用方面都远低于现有方法。

Conclusion: 所提出的零阶近似方法能够高效且准确地估计训练数据的影响，为大规模分析训练数据如何塑造模型行为提供了可行的解决方案，并且适用于不可微损失函数的情况。

Abstract: A critical aspect of analyzing and improving modern machine learning systems
lies in understanding how individual training examples influence a model's
predictive behavior. Estimating this influence enables critical applications,
including data selection and model debugging; in particular, self-influence,
which quantifies the influence of a training point on itself, has found many
uses in data quality assessment and outlier detection. Existing methods for
measuring data influence, however, are often impractical for large models due
to low accuracy or prohibitive computational costs: most approaches either
provide poor approximations or rely on gradients and inverse-Hessian
computations that remain challenging to scale. In this work, we introduce a
highly efficient zeroth-order approximation for estimating the influence of
training data that requires only a fraction of the time and memory footprint of
prior methods. Notably, our method relies solely on loss values of intermediate
checkpoints on the training and test data, along with the checkpoints
themselves, making it broadly applicable even when the loss function of
interest is non-differentiable. Beyond its computational efficiency, our
approach achieves superior accuracy in estimating self-influence and comparable
or improved accuracy in estimating train-test influence for fine-tuned large
language models, enabling scalable and practical analysis of how training data
shapes model behavior.

</details>


### [350] [H4G: Unlocking Faithful Inference for Zero-Shot Graph Learning in Hyperbolic Space](https://arxiv.org/abs/2510.12094)
*Heng Zhang,Tianyi Zhang,Zijun Liu,Yuling Shi,Yaomin Shen,Haochen You,Haichuan Hu,Lubin Gan,Jin Huang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为H4G的框架，通过减小双曲嵌入的半径来解决现有图学习方法中的“过度抽象问题”，从而保留细粒度的图结构信息，提升了零样本学习在异质和同质图上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本属性图的零样本学习方法在处理需要细粒度模式识别的任务，尤其是在异质图上时，存在不足。其原因是当前方法使用过大的双曲半径，导致多尺度结构信息丢失。

Method: 提出H4G框架，使用可学习的块对角缩放矩阵和Möbius矩阵乘法来系统地减小嵌入半径，从而保留细粒度的结构细节。

Result: H4G在异质图上实现了12.8%的性能提升，在同质图上实现了8.4%的性能提升，达到了最先进的零样本学习性能。

Conclusion: 减小嵌入半径能够实现对细粒度多尺度信息的忠实保留，从而有效推进零样本图学习的发展。

Abstract: Text-attributed graphs are widely used across domains, offering rich
opportunities for zero-shot learning via graph-text alignment. However,
existing methods struggle with tasks requiring fine-grained pattern
recognition, particularly on heterophilic graphs. Through empirical and
theoretical analysis, we identify an \textbf{over-abstraction problem}: current
approaches operate at excessively large hyperbolic radii, compressing
multi-scale structural information into uniform high-level abstractions. This
abstraction-induced information loss obscures critical local patterns essential
for accurate predictions. By analyzing embeddings in hyperbolic space, we
demonstrate that optimal graph learning requires \textbf{faithful preservation}
of fine-grained structural details, better retained by representations
positioned closer to the origin. To address this, we propose \textbf{H4G}, a
framework that systematically reduces embedding radii using learnable
block-diagonal scaling matrices and M\"obius matrix multiplication. This
approach restores access to fine-grained patterns while maintaining global
receptive ability with minimal computational overhead. Experiments show H4G
achieves state-of-the-art zero-shot performance with \textbf{12.8\%}
improvement on heterophilic graphs and \textbf{8.4\%} on homophilic graphs,
confirming that radius reduction enables faithful multi-scale representation
for advancing zero-shot graph learning.

</details>


### [351] [Robust Adversarial Reinforcement Learning in Stochastic Games via Sequence Modeling](https://arxiv.org/abs/2510.11877)
*Xiaohang Tang,Zhuowen Cheng,Satyabrat Kumar*

Main category: cs.LG

TL;DR: CART是一种用于增强决策Transformer（DT）在对抗性随机博弈中鲁棒性的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列建模的强化学习方法（如DT）在对抗鲁棒性方面探索不足。

Method: CART将每个阶段的交互视为一个阶段博弈，并基于该博弈推导出的NashQ值来指导Transformer策略的生成，从而同时考虑了可被剥削性和状态转移的不确定性。

Result: CART在多种对抗性随机博弈中实现了更准确的minimax值估计，并获得了更优的最小对局回报。

Conclusion: CART是首个旨在提高DT在对抗性随机博弈中鲁棒性的框架，并在实验中表现出优越的性能。

Abstract: The Transformer, a highly expressive architecture for sequence modeling, has
recently been adapted to solve sequential decision-making, most notably through
the Decision Transformer (DT), which learns policies by conditioning on desired
returns. Yet, the adversarial robustness of reinforcement learning methods
based on sequence modeling remains largely unexplored. Here we introduce the
Conservative Adversarially Robust Decision Transformer (CART), to our knowledge
the first framework designed to enhance the robustness of DT in adversarial
stochastic games. We formulate the interaction between the protagonist and the
adversary at each stage as a stage game, where the payoff is defined as the
expected maximum value over subsequent states, thereby explicitly incorporating
stochastic state transitions. By conditioning Transformer policies on the NashQ
value derived from these stage games, CART generates policy that are
simultaneously less exploitable (adversarially robust) and conservative to
transition uncertainty. Empirically, CART achieves more accurate minimax value
estimation and consistently attains superior worst-case returns across a range
of adversarial stochastic games.

</details>


### [352] [Don't Walk the Line: Boundary Guidance for Filtered Generation](https://arxiv.org/abs/2510.11834)
*Sarah Ball,Andreas Haupt*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“边界引导”的新型强化学习微调方法，旨在解决生成模型与安全分类器结合时，因过度优化而导致模型输出进入分类器决策边界附近，从而增加误报和漏报的问题。该方法通过引导生成过程远离分类器边界，在不牺牲模型效用的前提下，提高了输出的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的安全分类器与生成模型结合的策略，例如微调生成器以降低被分类器过滤的概率，存在弊端。这种策略可能导致模型生成的内容接近分类器的决策边界，从而增加误报（将安全内容错误地标记为不安全）和漏报（将不安全内容错误地标记为安全）的发生率，影响模型的整体性能和安全性。

Method: 提出了一种名为“边界引导”（Boundary Guidance）的强化学习微调方法。该方法的核心思想是显式地引导生成过程远离安全分类器的决策边界（margin），而不是仅仅降低被过滤的概率。通过这种方式，模型可以在提高安全性的同时，尽量保持其输出内容的实用性和多样性。

Result: 在针对“越狱”提示（jailbreak prompts）和歧义性提示（ambiguous prompts）的基准测试中，“边界引导”方法在提高输出的安全性和实用性方面均取得了良好的效果。LLM-as-a-Judge评估结果表明，该方法能够有效提升模型在这些场景下的表现。此外，通过对不同模型规模和奖励函数设计的广泛消融实验，证明了该方法的鲁棒性。

Conclusion: “边界引导”是一种有效的强化学习微调方法，能够解决生成模型与安全分类器结合时出现的优化难题。该方法通过引导生成过程远离分类器决策边界，不仅提高了输出的安全性，还能保持内容的实用性，并在各种实验条件下都展现出良好的鲁棒性。

Abstract: Generative models are increasingly paired with safety classifiers that filter
harmful or undesirable outputs. A common strategy is to fine-tune the generator
to reduce the probability of being filtered, but this can be suboptimal: it
often pushes the model toward producing samples near the classifier's decision
boundary, increasing both false positives and false negatives. We propose
Boundary Guidance, a reinforcement learning fine-tuning method that explicitly
steers generation away from the classifier's margin. On a benchmark of
jailbreak and ambiguous prompts, Boundary Guidance improves both the safety and
the utility of outputs, as judged by LLM-as-a-Judge evaluations. Comprehensive
ablations across model scales and reward designs demonstrate the robustness of
our approach.

</details>


### [353] [Replicable Learning of Large-Margin Halfspaces](https://arxiv.org/abs/2402.13857)
*Alkis Kalavasis,Amin Karbasi,Kasper Green Larsen,Grigoris Velegkas,Felix Zhou*

Main category: cs.LG

TL;DR: 本文提出了用于学习大间隔半空间的高效可复现算法，在样本复杂度、维度独立性和运行时间方面均优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 学习大间隔半空间是一个重要的问题，但现有的算法在样本复杂度、维度独立性和运行时间方面存在局限性。

Method: 本文设计了三种可复现算法：1. 首个维度无关的可复现算法，具有多项式时间复杂度，样本复杂度在相关参数上优于现有算法，并对精度参数ε具有最优样本复杂度。2. 基于SGD的可复现算法，在某些参数下具有更好的样本和时间复杂度。3. 利用DP-to-Replicability归约，实现样本复杂度关于间隔参数τ的改进，但运行时间为双指数级，且对ε的样本复杂度劣于前两种算法。4. 进一步改进的算法，样本复杂度优于前三种算法，运行时间为关于1/τ^2的指数级。

Result: 本文提出的算法在样本复杂度、维度独立性和运行时间方面均取得了显著的改进，特别是在维度无关和最优样本复杂度方面取得了突破。

Conclusion: 本文提出的算法为学习大间隔半空间问题提供了更优的解决方案，并在理论和实践方面都具有重要的意义。

Abstract: We provide efficient replicable algorithms for the problem of learning
large-margin halfspaces. Our results improve upon the algorithms provided by
Impagliazzo, Lei, Pitassi, and Sorrell [STOC, 2022]. We design the first
dimension-independent replicable algorithms for this task which runs in
polynomial time, is proper, and has strictly improved sample complexity
compared to the one achieved by Impagliazzo et al. [2022] with respect to all
the relevant parameters. Moreover, our first algorithm has sample complexity
that is optimal with respect to the accuracy parameter $\epsilon$. We also
design an SGD-based replicable algorithm that, in some parameters' regimes,
achieves better sample and time complexity than our first algorithm. Departing
from the requirement of polynomial time algorithms, using the
DP-to-Replicability reduction of Bun, Gaboardi, Hopkins, Impagliazzo, Lei,
Pitassi, Sorrell, and Sivakumar [STOC, 2023], we show how to obtain a
replicable algorithm for large-margin halfspaces with improved sample
complexity with respect to the margin parameter $\tau$, but running time doubly
exponential in $1/\tau^2$ and worse sample complexity dependence on $\epsilon$
than one of our previous algorithms. We then design an improved algorithm with
better sample complexity than all three of our previous algorithms and running
time exponential in $1/\tau^{2}$.

</details>


### [354] [WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation](https://arxiv.org/abs/2510.11839)
*Yu-Hsiang Wang,Olgica Milenkovic*

Main category: cs.LG

TL;DR: WaveletDiff是一个新的框架，可以直接在小波系数上训练扩散模型，以生成高质量的合成时间序列数据，解决了现有模型在时间和频率域的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列生成模型难以捕捉真实世界数据固有的、多尺度的结构，而高质量的时间序列数据集却很稀缺。

Method: WaveletDiff框架在小波系数上训练扩散模型，结合了针对每个分解级别的专用Transformer和跨级别注意力机制，并通过自适应门控在时间尺度和频率尺度之间进行信息交换。此外，它还根据Parseval定理引入了能量守恒约束，以在扩散过程中保持光谱保真度。

Result: 在六个来自能源、金融和神经科学领域的真实世界数据集上的综合测试表明，WaveletDiff在短期和长期时间序列上，在五个不同的性能指标上始终优于最先进的时域和频域生成方法。例如，WaveletDiff在所有数据集上的平均判别得分和Context-FID得分比第二好的基线低3倍。

Conclusion: WaveletDiff在生成高质量、多尺度的合成时间序列数据方面表现出色，克服了现有方法的局限性，并在多项性能指标上超越了最先进的技术。

Abstract: Time series are ubiquitous in many applications that involve forecasting,
classification and causal inference tasks, such as healthcare, finance, audio
signal processing and climate sciences. Still, large, high-quality time series
datasets remain scarce. Synthetic generation can address this limitation;
however, current models confined either to the time or frequency domains
struggle to reproduce the inherently multi-scaled structure of real-world time
series. We introduce WaveletDiff, a novel framework that trains diffusion
models directly on wavelet coefficients to exploit the inherent
multi-resolution structure of time series data. The model combines dedicated
transformers for each decomposition level with cross-level attention mechanisms
that enable selective information exchange between temporal and frequency
scales through adaptive gating. It also incorporates energy preservation
constraints for individual levels based on Parseval's theorem to preserve
spectral fidelity throughout the diffusion process. Comprehensive tests across
six real-world datasets from energy, finance, and neuroscience domains
demonstrate that WaveletDiff consistently outperforms state-of-the-art
time-domain and frequency-domain generative methods on both short and long time
series across five diverse performance metrics. For example, WaveletDiff
achieves discriminative scores and Context-FID scores that are $3\times$
smaller on average than the second-best baseline across all datasets.

</details>


### [355] [Balancing Synthetic Data and Replay for Enhancing Task-Specific Capabilities](https://arxiv.org/abs/2510.11842)
*Urs Spiegelhalter,Jörg K. H. Franke,Frank Hutter*

Main category: cs.LG

TL;DR: The paper studies how to balance learning new tasks and retaining old knowledge when adapting language models, using synthetic data and exploring different replay ratios and computational budgets. It finds an optimal configuration and provides guidelines for practitioners.


<details>
  <summary>Details</summary>
Motivation: Adapting language models to new tasks via continued pretraining involves a trade-off between learning new capabilities and preventing catastrophic forgetting. Prior research on synthetic data generation lacks clear understanding of optimal replay ratios for balancing performance and knowledge retention under computational limits.

Method: The study empirically investigates the relationship between replay ratio configuration and computational budget in language model adaptation. Using bAbI reasoning tasks, synthetic data generation, and systematic evaluation of total token budgets and replay ratios, the paper analyzes the impact on task mastery and general knowledge retention.

Result: Experiments revealed an optimal replay ratio configuration that effectively balances task-specific performance with general knowledge retention. The findings demonstrate how different replay ratios and token budgets affect both aspects of model adaptation.

Conclusion: The paper offers empirically-grounded guidelines for choosing replay ratios based on computational budget. This enables practitioners to achieve effective task adaptation while significantly reducing training costs, by optimizing the balance between learning new information and retaining existing knowledge.

Abstract: Adapting language models to new tasks through continued pretraining faces a
fundamental trade-off: models must learn new capabilities while avoiding
catastrophic forgetting of existing knowledge. While prior work has studied
synthetic data generation techniques, the optimal replay ratios for balancing
task performance and knowledge retention under computational constraints remain
poorly understood. We present a comprehensive empirical study investigating the
interplay between replay ratio configuration and computational budget when
adapting language models to new tasks. Using the bAbI reasoning tasks as our
target objective, we apply synthetic data generation and systematically
evaluate different total token budgets and replay ratio configurations. We
analyze their effects on both task mastery and general knowledge retention. Our
experiments reveal an optimal configuration that balances task-specific
performance with general knowledge retention. Based on our findings, we provide
empirically-grounded guidelines for selecting replay ratios based on
computational budget, enabling practitioners to achieve strong task adaptation
with significantly reduced training costs.

</details>


### [356] [Structure-Aware Spectral Sparsification via Uniform Edge Sampling](https://arxiv.org/abs/2510.12669)
*Kaiwen He,Petros Drineas,Rajiv Khanna*

Main category: cs.LG

TL;DR: Uniform edge sampling can suffice for spectral clustering on graphs with well-separated k-clusterings, preserving spectral properties and clustering quality with a provable guarantee.


<details>
  <summary>Details</summary>
Motivation: To investigate if uniform edge sampling, a simpler strategy, can be used for spectral clustering, overcoming the scalability limitations and expensive preprocessing of classical methods that rely on eigenvector computation and importance sampling.

Method: Analyzed the effect of uniform edge sampling on spectral clustering for graphs with a large structure ratio (k-clustering). Proved that uniformly sampling O(gamma^2 * n * log n / epsilon^2) edges yields a sparsifier whose top (n-k)-dimensional eigenspace is approximately orthogonal to cluster indicators. Developed new tools including resistance bounds for intra-cluster edges, a rank-(n-k) effective resistance formulation, and an adapted matrix Chernoff bound.

Result: Established that uniform edge sampling preserves the spectral subspace crucial for clustering in graphs with well-separated k-clusterings. The analysis showed that the spectral embedding remains faithful, thus preserving clustering quality.

Conclusion: The paper provides the first provable guarantee that uniform edge sampling is sufficient for structure-preserving spectral clustering, connecting coreset-based clustering theory to spectral sparsification and demonstrating that uniform sampling can be structure-aware under strong clusterability conditions.

Abstract: Spectral clustering is a fundamental method for graph partitioning, but its
reliance on eigenvector computation limits scalability to massive graphs.
Classical sparsification methods preserve spectral properties by sampling edges
proportionally to their effective resistances, but require expensive
preprocessing to estimate these resistances. We study whether uniform edge
sampling-a simple, structure-agnostic strategy-can suffice for spectral
clustering. Our main result shows that for graphs admitting a well-separated
$k$-clustering, characterized by a large structure ratio $\Upsilon(k) =
\lambda_{k+1} / \rho_G(k)$, uniform sampling preserves the spectral subspace
used for clustering. Specifically, we prove that uniformly sampling $O(\gamma^2
n \log n / \epsilon^2)$ edges, where $\gamma$ is the Laplacian condition
number, yields a sparsifier whose top $(n-k)$-dimensional eigenspace is
approximately orthogonal to the cluster indicators. This ensures that the
spectral embedding remains faithful, and clustering quality is preserved. Our
analysis introduces new resistance bounds for intra-cluster edges, a
rank-$(n-k)$ effective resistance formulation, and a matrix Chernoff bound
adapted to the dominant eigenspace. These tools allow us to bypass importance
sampling entirely. Conceptually, our result connects recent coreset-based
clustering theory to spectral sparsification, showing that under strong
clusterability, even uniform sampling is structure-aware. This provides the
first provable guarantee that uniform edge sampling suffices for
structure-preserving spectral clustering.

</details>


### [357] [Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.11852)
*Saroj Basnet,Shafkat Farabi,Tharindu Ranasinghe,Diptesh Kanoji,Marcos Zampieri*

Main category: cs.LG

TL;DR: 当前最先进的开源视觉-语言模型（VLMs）在零样本、单样本和少样本情境下，对包含图像和文本的模态内涵（如讽刺）的理解能力，以及生成解释的能力进行了评估。评估结果表明，尽管这些模型在二元讽刺检测方面取得了一定的成功，但在没有针对特定任务进行微调的情况下，它们仍然无法生成高质量的解释。


<details>
  <summary>Details</summary>
Motivation: 评估开源视觉-语言模型（VLMs）在零样本、单样本和少样本情境下，检测模态内涵（如讽刺）的能力，并评估其生成解释的能力。

Method: 在三个基准讽刺数据集（Muse、MMSD2.0和SarcNet）上，评估了七个最先进的VLMs（BLIP2、InstructBLIP、OpenFlamingo、LLaVA、PaliGemma、Gemma3和Qwen-VL）在检测模态讽刺方面的表现，以及它们生成解释的能力。

Result: 评估结果表明，当前模型在二元讽刺检测方面取得了中等程度的成功，但在没有经过特定任务微调的情况下，它们在生成高质量的解释方面仍显不足。

Conclusion: 虽然目前的VLMs在多模态讽刺检测方面取得了一定的进展，但它们在生成高质量的解释方面仍有待提高，这通常需要针对特定任务进行微调。

Abstract: Recent advances in open-source vision-language models (VLMs) offer new
opportunities for understanding complex and subjective multimodal phenomena
such as sarcasm. In this work, we evaluate seven state-of-the-art VLMs - BLIP2,
InstructBLIP, OpenFlamingo, LLaVA, PaliGemma, Gemma3, and Qwen-VL - on their
ability to detect multimodal sarcasm using zero-, one-, and few-shot prompting.
Furthermore, we evaluate the models' capabilities in generating explanations to
sarcastic instances. We evaluate the capabilities of VLMs on three benchmark
sarcasm datasets (Muse, MMSD2.0, and SarcNet). Our primary objectives are
twofold: (1) to quantify each model's performance in detecting sarcastic
image-caption pairs, and (2) to assess their ability to generate human-quality
explanations that highlight the visual-textual incongruities driving sarcasm.
Our results indicate that, while current models achieve moderate success in
binary sarcasm detection, they are still not able to generate high-quality
explanations without task-specific finetuning.

</details>


### [358] [Actor-Enriched Time Series Forecasting of Process Performance](https://arxiv.org/abs/2510.11856)
*Aurelie Leribaux,Rafael Oyamada,Johannes De Smedt,Zahra Dasht Bozorgi,Artem Polyvyanyy,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 通过将随时间变化的演员行为信息纳入预测模型，可以提高吞吐量时间（TT）预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有流程挖掘中的预测流程监控（PPM）研究未能充分考虑演员行为作为时变信号的作用，而这对于理解和预测以资源为驱动的流程至关重要。

Method: 构建包含TT和演员行为特征（如演员参与度、行为频率和持续时间）的多变量时间序列，并训练和比较模型以评估演员行为信息的影响。

Result: 包含演员行为信息的模型在RMSE、MAE和R2方面始终优于仅包含TT特征的基线模型。

Conclusion: 对演员行为进行建模并将其纳入预测模型可以显著提高性能指标的预测能力，特别是吞吐量时间。

Abstract: Predictive Process Monitoring (PPM) is a key task in Process Mining that aims
to predict future behavior, outcomes, or performance indicators. Accurate
prediction of the latter is critical for proactive decision-making. Given that
processes are often resource-driven, understanding and incorporating actor
behavior in forecasting is crucial. Although existing research has incorporated
aspects of actor behavior, its role as a time-varying signal in PPM remains
limited. This study investigates whether incorporating actor behavior
information, modeled as time series, can improve the predictive performance of
throughput time (TT) forecasting models. Using real-life event logs, we
construct multivariate time series that include TT alongside actor-centric
features, i.e., actor involvement, the frequency of continuation, interruption,
and handover behaviors, and the duration of these behaviors. We train and
compare several models to study the benefits of adding actor behavior. The
results show that actor-enriched models consistently outperform baseline
models, which only include TT features, in terms of RMSE, MAE, and R2. These
findings demonstrate that modeling actor behavior over time and incorporating
this information into forecasting models enhances performance indicator
predictions.

</details>


### [359] [Improving Knowledge Graph Embeddings through Contrastive Learning with Negative Statements](https://arxiv.org/abs/2510.11868)
*Rita T. Sousa,Heiko Paulheim*

Main category: cs.LG

TL;DR: 本研究提出了一种整合显式声明的负面对知识嵌入学习的新方法，通过双模型架构处理正负面陈述，并在链接预测和三元组分类任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法通常基于封闭世界假设，与现实世界中知识图谱的开放世界假设不符，并且忽视了显式负面对陈述在区分真假未知三元组中的作用。

Method: 提出一种双模型架构，分别在正面陈述和负面陈述上训练两个嵌入模型。训练过程中，每个模型通过扰乱正面样本并利用另一模型的评分来生成负面样本。

Result: 在通用和特定领域知识图谱上进行评估，重点关注链接预测和三元组分类任务，实验结果表明该方法在预测性能上优于现有最先进的嵌入模型。

Conclusion: 整合有意义的负面对知识到嵌入学习中能够提升模型性能。

Abstract: Knowledge graphs represent information as structured triples and serve as the
backbone for a wide range of applications, including question answering, link
prediction, and recommendation systems. A prominent line of research for
exploring knowledge graphs involves graph embedding methods, where entities and
relations are represented in low-dimensional vector spaces that capture
underlying semantics and structure. However, most existing methods rely on
assumptions such as the Closed World Assumption or Local Closed World
Assumption, treating missing triples as false. This contrasts with the Open
World Assumption underlying many real-world knowledge graphs. Furthermore,
while explicitly stated negative statements can help distinguish between false
and unknown triples, they are rarely included in knowledge graphs and are often
overlooked during embedding training.
  In this work, we introduce a novel approach that integrates explicitly
declared negative statements into the knowledge embedding learning process. Our
approach employs a dual-model architecture, where two embedding models are
trained in parallel, one on positive statements and the other on negative
statements. During training, each model generates negative samples by
corrupting positive samples and selecting the most likely candidates as scored
by the other model. The proposed approach is evaluated on both general-purpose
and domain-specific knowledge graphs, with a focus on link prediction and
triple classification tasks. The extensive experiments demonstrate that our
approach improves predictive performance over state-of-the-art embedding
models, demonstrating the value of integrating meaningful negative knowledge
into embedding learning.

</details>


### [360] [PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture](https://arxiv.org/abs/2510.12494)
*Yi Liu,Yang Liu,Leqian Zheng,Jue Hong,Junjie Shi,Qingyou Yang,Ye Wu,Cong Wang*

Main category: cs.LG

TL;DR: PubSub-VFL是一种新的VFL范式，它利用发布/订阅架构和分层异步机制来提高计算效率和减少训练延迟，同时通过优化算法解决了异构性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的两方拆分学习（VFL）在隐私保护方面虽有优势，但在计算资源利用率和训练效率方面存在不足，主要体现在同步依赖设计导致的训练延迟以及参与者间的资源和数据异构性问题。

Method: 提出了一种名为PubSub-VFL的新型VFL范式，采用发布/订阅（Pub/Sub）架构和分层异步机制，结合参数服务器架构的数据并行性，以提高计算效率和降低训练延迟。同时，设计了一个基于参与者系统画像的优化问题，以选择最优超参数并解决资源和数据异构性导致的训练不平衡问题，并保证隐私。

Result: PubSub-VFL在五个基准数据集上的广泛案例研究表明，与现有方法相比，其训练速度提高了2-7倍，准确性未受影响，计算资源利用率高达91.07%。理论分析证明了PubSub-VFL的稳定收敛性和与差分隐私等安全协议的兼容性。

Conclusion: PubSub-VFL通过其创新的异步机制和对异构性的优化处理，显著提高了VFL的训练效率和资源利用率，同时保持了准确性和安全性，为安全协作学习提供了一个更优的解决方案。

Abstract: With the rapid advancement of the digital economy, data collaboration between
organizations has become a well-established business model, driving the growth
of various industries. However, privacy concerns make direct data sharing
impractical. To address this, Two-Party Split Learning (a.k.a. Vertical
Federated Learning (VFL)) has emerged as a promising solution for secure
collaborative learning. Despite its advantages, this architecture still suffers
from low computational resource utilization and training efficiency.
Specifically, its synchronous dependency design increases training latency,
while resource and data heterogeneity among participants further hinder
efficient computation. To overcome these challenges, we propose PubSub-VFL, a
novel VFL paradigm with a Publisher/Subscriber architecture optimized for
two-party collaborative learning with high computational efficiency. PubSub-VFL
leverages the decoupling capabilities of the Pub/Sub architecture and the data
parallelism of the parameter server architecture to design a hierarchical
asynchronous mechanism, reducing training latency and improving system
efficiency. Additionally, to mitigate the training imbalance caused by resource
and data heterogeneity, we formalize an optimization problem based on
participants' system profiles, enabling the selection of optimal
hyperparameters while preserving privacy. We conduct a theoretical analysis to
demonstrate that PubSub-VFL achieves stable convergence and is compatible with
security protocols such as differential privacy. Extensive case studies on five
benchmark datasets further validate its effectiveness, showing that, compared
to state-of-the-art baselines, PubSub-VFL not only accelerates training by $2
\sim 7\times$ without compromising accuracy, but also achieves a computational
resource utilization rate of up to 91.07%.

</details>


### [361] [Laminar: A Scalable Asynchronous RL Post-Training Framework](https://arxiv.org/abs/2510.12633)
*Guangming Sheng,Yuxuan Tong,Borui Wan,Wang Zhang,Chaobo Jia,Xibin Wu,Yuqi Wu,Xiang Li,Chi Zhang,Yanghua Peng,Haibin Lin,Xin Liu,Chuan Wu*

Main category: cs.LG

TL;DR: 现有的强化学习（RL）框架在处理大型语言模型（LLM）的训练时存在可扩展性问题，主要是由于RL轨迹生成中的长尾分布导致GPU利用率低下。本研究提出了一种名为Laminar的新系统，通过解耦的架构和轨迹级别的异步处理来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RL框架在LLM训练中的可扩展性受限于长尾分布导致的GPU利用率低下和全局权重同步的僵化模型更新机制。

Method: 提出Laminar系统，采用完全解耦的架构：1. 使用中继工作节点作为分布式参数服务，实现异步和细粒度的权重同步，允许Rollout随时拉取最新权重。2. 动态重打包机制将长尾轨迹整合到少数专用Rollout上，最大化生成吞吐量。

Result: 在1024 GPU集群上进行评估，Laminar实现了比最先进系统高5.48倍的训练吞吐量加速，并缩短了模型收敛时间。

Conclusion: Laminar通过轨迹级别的异步处理和完全解耦的架构，显著提高了RL训练的可扩展性和效率，解决了现有系统的瓶颈。

Abstract: Reinforcement learning (RL) post-training for Large Language Models (LLMs) is
now scaling to large clusters and running for extended durations to enhance
model reasoning performance. However, the scalability of existing RL frameworks
is limited, as extreme long-tail skewness in RL trajectory generation causes
severe GPU underutilization. Current asynchronous RL systems attempt to
mitigate this, but they rely on global weight synchronization between the actor
and all rollouts, which creates a rigid model update schedule. This global
synchronization is ill-suited for the highly skewed and evolving distribution
of trajectory generation latency in RL training, crippling training efficiency.
Our key insight is that efficient scaling requires breaking this lockstep
through trajectory-level asynchrony, which generates and consumes each
trajectory independently. We propose Laminar, a scalable and robust RL
post-training system built on a fully decoupled architecture. First, we replace
global updates with a tier of relay workers acting as a distributed parameter
service. This enables asynchronous and fine-grained weight synchronization,
allowing rollouts to pull the latest weight anytime without stalling the
actor's training loop. Second, a dynamic repack mechanism consolidates
long-tail trajectories onto a few dedicated rollouts, maximizing generation
throughput. The fully decoupled design also isolates failures, ensuring
robustness for long-running jobs. Our evaluation on a 1024-GPU cluster shows
that Laminar achieves up to 5.48$\times$ training throughput speedup over
state-of-the-art systems, while reducing model convergence time.

</details>


### [362] [ADARL: Adaptive Low-Rank Structures for Robust Policy Learning under Uncertainty](https://arxiv.org/abs/2510.11899)
*Chenliang Li,Junyu Leng,Jiaxiang Li,Youbang Sun,Shixiang Chen,Shahin Shahrampour,Alfredo Garcia*

Main category: cs.LG

TL;DR: AdaRL是一种新的鲁棒强化学习框架，通过自适应调整策略的秩来提高鲁棒性，避免了计算成本高昂的嵌套min-max优化，并在MuJoCo连续控制基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒强化学习方法（Robust RL）在处理环境动态的不确定性时，通常采用计算成本高昂且策略过于保守的嵌套min-max优化。

Method: AdaRL采用一种双层优化框架，在低层，它在固定的秩约束下进行策略优化，并从围绕中心模型的Wasserstein球中采样动态；在高层，它自适应地调整秩以平衡偏差-方差权衡，并将策略参数投影到低秩流形上。

Result: 在MuJoCo连续控制基准测试中，AdaRL的性能优于固定的秩基线（如SAC）和最先进的鲁棒RL方法（如RNAC、Parseval），并且其收敛秩与底层任务的内在秩一致。

Conclusion: 自适应低秩策略表示为在模型不确定性下进行鲁棒RL提供了一种有效且有原则的替代方案。

Abstract: Robust reinforcement learning (Robust RL) seeks to handle epistemic
uncertainty in environment dynamics, but existing approaches often rely on
nested min--max optimization, which is computationally expensive and yields
overly conservative policies. We propose \textbf{Adaptive Rank Representation
(AdaRL)}, a bi-level optimization framework that improves robustness by
aligning policy complexity with the intrinsic dimension of the task. At the
lower level, AdaRL performs policy optimization under fixed-rank constraints
with dynamics sampled from a Wasserstein ball around a centroid model. At the
upper level, it adaptively adjusts the rank to balance the bias--variance
trade-off, projecting policy parameters onto a low-rank manifold. This design
avoids solving adversarial worst-case dynamics while ensuring robustness
without over-parameterization. Empirical results on MuJoCo continuous control
benchmarks demonstrate that AdaRL not only consistently outperforms fixed-rank
baselines (e.g., SAC) and state-of-the-art robust RL methods (e.g., RNAC,
Parseval), but also converges toward the intrinsic rank of the underlying
tasks. These results highlight that adaptive low-rank policy representations
provide an efficient and principled alternative for robust RL under model
uncertainty.

</details>


### [363] [Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems](https://arxiv.org/abs/2510.12727)
*Anas Abouaomar,Mohammed El hanjri,Abdellatif Kobbane,Anis Laouiti,Khalid Nafil*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的层级联邦学习架构，用于智能农业生产系统和作物产量预测。该方法引入了季节性订阅机制，农场在每个农业季节开始时加入特定作物集群。提出的三层架构包括客户端的个体农场、中间层的作物特定聚合器以及顶层的全局模型聚合器。在每个作物集群内，客户端协同训练针对特定作物类型的专业模型，然后将其聚合以生成整合跨多种作物知识的更高级别全局模型。这种层级设计能够实现针对个体作物类型的本地专业化以及跨多样化农业背景的全局泛化，同时保护数据隐私并减少通信开销。实验证明了所提出系统的有效性，表明本地和作物层模型能够与实际产量模式保持一致，并且显著优于标准的机器学习模型。结果验证了层级联邦学习在农业背景下的优势，特别是在涉及异构农业环境和隐私敏感型农业数据的场景中。


<details>
  <summary>Details</summary>
Motivation: 为智能农业生产系统和作物产量预测设计一种新颖的层级联邦学习架构。

Method: 提出了一种三层架构，包括个体农场（客户端）、作物特定聚合器（中间层）和全局模型聚合器（顶层），并引入了季节性订阅机制，允许农场在每个农业季节开始时加入特定作物集群。客户端协同训练针对特定作物类型的专业模型，然后聚合以生成整合跨多种作物知识的全局模型。

Result: 本地和作物层模型能够与实际产量模式保持一致，并且显著优于标准的机器学习模型。

Conclusion: 层级联邦学习在农业背景下，尤其是在涉及异构农业环境和隐私敏感型农业数据的场景中，具有显著优势。

Abstract: In this paper, we presents a novel hierarchical federated learning
architecture specifically designed for smart agricultural production systems
and crop yield prediction. Our approach introduces a seasonal subscription
mechanism where farms join crop-specific clusters at the beginning of each
agricultural season. The proposed three-layer architecture consists of
individual smart farms at the client level, crop-specific aggregators at the
middle layer, and a global model aggregator at the top level. Within each crop
cluster, clients collaboratively train specialized models tailored to specific
crop types, which are then aggregated to produce a higher-level global model
that integrates knowledge across multiple crops. This hierarchical design
enables both local specialization for individual crop types and global
generalization across diverse agricultural contexts while preserving data
privacy and reducing communication overhead. Experiments demonstrate the
effectiveness of the proposed system, showing that local and crop-layer models
closely follow actual yield patterns with consistent alignment, significantly
outperforming standard machine learning models. The results validate the
advantages of hierarchical federated learning in the agricultural context,
particularly for scenarios involving heterogeneous farming environments and
privacy-sensitive agricultural data.

</details>


### [364] [Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks](https://arxiv.org/abs/2510.11903)
*Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss*

Main category: cs.LG

TL;DR: 个人和关系事件通常分开建模，但一项新研究提出了统一的建模方法，并发布了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 现有用户事件建模方法将个人事件（个体行为）和关系事件（用户间交互）分开处理，缺乏统一的建模方式，而实际应用场景需要同时考虑这两种事件。

Method: 提出了一种统一的事件建模形式化方法，并构建了包含个人和关系事件的数据集。

Result: 实验表明，结合两种事件类型进行建模的模型效果更好，但仍有改进空间。

Conclusion: 统一的用户事件建模是未来研究的方向，研究者发布了相关数据集和预测任务以促进该领域的发展。

Abstract: User event modeling plays a central role in many machine learning
applications, with use cases spanning e-commerce, social media, finance,
cybersecurity, and other domains. User events can be broadly categorized into
personal events, which involve individual actions, and relational events, which
involve interactions between two users. These two types of events are typically
modeled separately, using sequence-based methods for personal events and
graph-based methods for relational events. Despite the need to capture both
event types in real-world systems, prior work has rarely considered them
together. This is often due to the convenient simplification that user behavior
can be adequately represented by a single formalization, either as a sequence
or a graph. To address this gap, there is a need for public datasets and
prediction tasks that explicitly incorporate both personal and relational
events. In this work, we introduce a collection of such datasets, propose a
unified formalization, and empirically show that models benefit from
incorporating both event types. Our results also indicate that current methods
leave a notable room for improvements. We release these resources to support
further research in unified user event modeling and encourage progress in this
direction.

</details>


### [365] [Variational Mixture of Graph Neural Experts for Alzheimer's Disease Biomarker Recognition in EEG Brain Networks](https://arxiv.org/abs/2510.11917)
*Jun-En Ding,Anna Zilverstand,Shihao Yang,Albert Chih-Chieh Yang,Feng Liu*

Main category: cs.LG

TL;DR: 提出了一种名为VMoGE的新方法，通过结合特定频率的生物标志物识别和变分推断，提高了痴呆症（特别是阿尔茨海默病和额颞叶痴呆）的诊断和分期能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于脑电图（EEG）的痴呆症诊断方法在区分不同亚型和严重程度方面存在局限性，因为它们使用全频带分析，无法精确区分。

Method: 提出了一种变分图神经网络专家混合模型（VMoGE），该模型使用多粒度Transformer提取不同频率下的时间模式，并结合变分图卷积编码器和高斯马尔可夫随机场先验。通过结构化变分推断和自适应门控，将神经专业化与EEG频率带联系起来。

Result: 在两个数据集上，VMoGE在痴呆症亚型分类和严重程度分期方面均取得了优于最先进方法的性能，AUC提高了4%至10%。此外，VMoGE还能提供可解释的见解，其专家权重与临床指标相关，空间模式与神经病理学特征一致。

Conclusion: VMoGE是一种有效的痴呆症诊断和监测方法，它能够通过EEG频率分析提供可解释的见解，有助于发现新的EEG生物标志物。

Abstract: Dementia disorders such as Alzheimer's disease (AD) and frontotemporal
dementia (FTD) exhibit overlapping electrophysiological signatures in EEG that
challenge accurate diagnosis. Existing EEG-based methods are limited by
full-band frequency analysis that hinders precise differentiation of dementia
subtypes and severity stages. We propose a variational mixture of graph neural
experts (VMoGE) that integrates frequency-specific biomarker identification
with structured variational inference for enhanced dementia diagnosis and
staging. VMoGE employs a multi-granularity transformer to extract multi-scale
temporal patterns across four frequency bands, followed by a variational graph
convolutional encoder using Gaussian Markov Random Field priors. Through
structured variational inference and adaptive gating, VMoGE links neural
specialization to physiologically meaningful EEG frequency bands. Evaluated on
two diverse datasets for both subtype classification and severity staging,
VMoGE achieves superior performance with AUC improvements of +4% to +10% over
state-of-the-art methods. Moreover, VMoGE provides interpretable insights
through expert weights that correlate with clinical indicators and spatial
patterns aligned with neuropathological signatures, facilitating EEG biomarker
discovery for comprehensive dementia diagnosis and monitoring.

</details>


### [366] [Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning Enabled Decoder-Only Transformer](https://arxiv.org/abs/2510.11926)
*Nayan Sanjay Bhatia,Pranay Kocheta,Russell Elliott,Harikrishna S. Kuttivelil,Katia Obraczka*

Main category: cs.LG

TL;DR: Locaris是一个基于LLM的室内定位模型，无需手动校准，能直接处理原始Wi-Fi数据，并在各种环境下实现高精度定位，甚至在设备和部署环境发生变化时也能保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 室内Wi-Fi定位因信号易受环境、传播特性和硬件差异影响而充满挑战。传统方法需要耗费大量人力进行校准，且在条件变化时性能会迅速下降。

Method: Locaris将每个接入点（AP）的测量值视为一个“token”，直接处理原始Wi-Fi遥测数据，无需预处理。通过在不同Wi-Fi数据集上进行微调，LLM能够学习到从原始信号到设备位置的轻量级、可泛化的映射关系。

Result: 实验表明，Locaris在各种遥测数据类型上，性能与现有最先进的方法相当或更优。即使在仅使用少量校准点的情况下，Locaris也能在新设备和部署场景下保持高精度，实现亚米级精度，且对缺失AP具有鲁棒性，并支持所有可用遥测数据。

Conclusion: 小型LLM可作为无需校准的回归模型应用于室内定位，在异构Wi-Fi部署中提供可扩展、鲁棒的跨环境性能。Locaris在实际场景中具有可行性，特别是在大规模部署中，可以避免耗时的校准过程。

Abstract: Indoor Wi-Fi positioning remains a challenging problem due to the high
sensitivity of radio signals to environmental dynamics, channel propagation
characteristics, and hardware heterogeneity. Conventional fingerprinting and
model-based approaches typically require labor-intensive calibration and suffer
rapid performance degradation when devices, channel or deployment conditions
change. In this paper, we introduce Locaris, a decoder-only large language
model (LLM) for indoor localization. Locaris treats each access point (AP)
measurement as a token, enabling the ingestion of raw Wi-Fi telemetry without
pre-processing. By fine-tuning its LLM on different Wi-Fi datasets, Locaris
learns a lightweight and generalizable mapping from raw signals directly to
device location. Our experimental study comparing Locaris with state-of-the-art
methods consistently shows that Locaris matches or surpasses existing
techniques for various types of telemetry. Our results demonstrate that compact
LLMs can serve as calibration-free regression models for indoor localization,
offering scalable and robust cross-environment performance in heterogeneous
Wi-Fi deployments. Few-shot adaptation experiments, using only a handful of
calibration points per device, further show that Locaris maintains high
accuracy when applied to previously unseen devices and deployment scenarios.
This yields sub-meter accuracy with just a few hundred samples, robust
performance under missing APs and supports any and all available telemetry. Our
findings highlight the practical viability of Locaris for indoor positioning in
the real-world scenarios, particularly in large-scale deployments where
extensive calibration is infeasible.

</details>


### [367] [Efficient Restarts in Non-Stationary Model-Free Reinforcement Learning](https://arxiv.org/abs/2510.11933)
*Hiroshi Nonaka,Simon Ambrozak,Sofia R. Miskala-Dinc,Amedeo Ercole,Aviva Prins*

Main category: cs.LG

TL;DR: 本文提出了三种用于无模型非平稳强化学习（RL）的高效重启范式，解决了现有算法（RestartQ-UCB）中存在的完全遗忘和预设时间重启的问题。通过引入部分、自适应和选择性重启，并在多种环境中进行了测试，与RestartQ-UCB相比，动态遗憾减少了高达91%。


<details>
  <summary>Details</summary>
Motivation: 识别并解决Mao et al. (2022)的RestartQ-UCB算法在重启设计中存在的两个核心问题：完全遗忘（重启后丢失所有学习信息）和预设时间重启（无论策略是否与当前环境兼容，仅在预定时间发生重启）。

Method: 引入三种新的重启方法：部分重启、自适应重启和选择性重启，并应用于RestartQ-UCB和RANDOMIZEDQ（Wang et al., 2025）算法。

Result: 在多个不同环境中，与RestartQ-UCB相比，所提出的重启方法将动态遗憾减少了高达91%，并达到了接近最优的经验性能。

Conclusion: 提出的三种重启范式（部分、自适应和选择性）能有效解决现有算法的不足，并在多种环境中实现了显著的性能提升。

Abstract: In this work, we propose three efficient restart paradigms for model-free
non-stationary reinforcement learning (RL). We identify two core issues with
the restart design of Mao et al. (2022)'s RestartQ-UCB algorithm: (1) complete
forgetting, where all the information learned about an environment is lost
after a restart, and (2) scheduled restarts, in which restarts occur only at
predefined timings, regardless of the incompatibility of the policy with the
current environment dynamics. We introduce three approaches, which we call
partial, adaptive, and selective restarts to modify the algorithms RestartQ-UCB
and RANDOMIZEDQ (Wang et al., 2025). We find near-optimal empirical performance
in multiple different environments, decreasing dynamic regret by up to $91$%
relative to RestartQ-UCB.

</details>


### [368] [On efficiently computable functions, deep networks and sparse compositionality](https://arxiv.org/abs/2510.11942)
*Tomaso Poggio*

Main category: cs.LG

TL;DR: Efficient Turing computability implies compositional sparsity and neural approximants for functions.


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish a connection between efficient Turing computability and the existence of sparse, compositionally structured representations, specifically bounded-fan-in DAGs and their neural network counterparts.

Method: The study demonstrates that if a function $f:[0,1]^d	oight]R^m$ is computable in time polynomial in bit-depths, then for any precisions $(n,m_{\mathrm{out}})$, a bounded-fan-in Boolean circuit of size and depth $\poly(n+m_{\mathrm{out}})$ exists. Replacing gates with neural emulators results in a deep network of similar size/depth that achieves a specified accuracy.

Result: The core result is the existence of a bounded-fan-in Boolean circuit and a corresponding neural network approximant for efficiently computable functions. These networks have polynomial size and depth in terms of the input/output precision and achieve the target precision.

Conclusion: Efficient Turing computability is shown to be equivalent to the existence of compositionally sparse DAG representations and their neural network approximations. This bridges computability theory with deep learning architectures and approximation theory.

Abstract: We show that \emph{efficient Turing computability} at any fixed input/output
precision implies the existence of \emph{compositionally sparse}
(bounded-fan-in, polynomial-size) DAG representations and of corresponding
neural approximants achieving the target precision. Concretely: if
$f:[0,1]^d\to\R^m$ is computable in time polynomial in the bit-depths, then for
every pair of precisions $(n,m_{\mathrm{out}})$ there exists a bounded-fan-in
Boolean circuit of size and depth $\poly(n+m_{\mathrm{out}})$ computing the
discretized map; replacing each gate by a constant-size neural emulator yields
a deep network of size/depth $\poly(n+m_{\mathrm{out}})$ that achieves accuracy
$\varepsilon=2^{-m_{\mathrm{out}}}$. We also relate these constructions to
compositional approximation rates
\cite{MhaskarPoggio2016b,poggio_deep_shallow_2017,Poggio2017,Poggio2023HowDS}
and to optimization viewed as hierarchical search over sparse structures.

</details>


### [369] [Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors](https://arxiv.org/abs/2510.11953)
*Quentin Fruytier,Akshay Malhotra,Shahab Hamidi-Rad,Aditya Sant,Aryan Mokhtari,Sujay Sanghavi*

Main category: cs.LG

TL;DR: 基于MMD的先验可编程框架在学习分离表示方面优于基于KL的VAE，并在CIFAR-10和Tiny ImageNet等数据集上实现了最先进的独立性，同时改善了与语义特征的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的基于KL散度惩罚的VAE方法在强制执行目标分布方面不可靠，导致学习到的表示不分离。

Method: 提出了一种基于最大均值差异（MMD）的可编程先验框架，用于显式地塑造潜在空间，并引入了无监督的潜在可预测性得分（LPS）来量化表示的分离程度。

Result: 该框架在CIFAR-10和Tiny ImageNet等复杂数据集上实现了最先进的互独立性，并且没有常见的重建权衡。此外，它能够通过工程化先验来改善与语义特征的对齐。

Conclusion: 所提出的框架为表示工程提供了一个基础工具，为模型可辨性和因果推理开辟了新的途径。

Abstract: Learning disentangled representations, where distinct factors of variation
are captured by independent latent variables, is a central goal in machine
learning. The dominant approach has been the Variational Autoencoder (VAE)
framework, which uses a Kullback-Leibler (KL) divergence penalty to encourage
the latent space to match a factorized Gaussian prior. In this work, however,
we provide direct evidence that this KL-based regularizer is an unreliable
mechanism, consistently failing to enforce the target distribution on the
aggregate posterior. We validate this and quantify the resulting entanglement
using our novel, unsupervised Latent Predictability Score (LPS). To address
this failure, we introduce the Programmable Prior Framework, a method built on
the Maximum Mean Discrepancy (MMD). Our framework allows practitioners to
explicitly sculpt the latent space, achieving state-of-the-art mutual
independence on complex datasets like CIFAR-10 and Tiny ImageNet without the
common reconstruction trade-off. Furthermore, we demonstrate how this
programmability can be used to engineer sophisticated priors that improve
alignment with semantically meaningful features. Ultimately, our work provides
a foundational tool for representation engineering, opening new avenues for
model identifiability and causal reasoning.

</details>


### [370] [Y-shaped Generative Flows](https://arxiv.org/abs/2510.11955)
*Arip Asadulaev,Semyon Semenov,Abduragim Shtanchaev,Eric Moulines,Fakhri Karray,Martin Takac*

Main category: cs.LG

TL;DR: Y型生成流通过共享路径移动概率质量，然后分支到目标特定端点，以恢复层次结构并改进分布指标。


<details>
  <summary>Details</summary>
Motivation: 现代连续时间生成模型通常会引起V形传输，其中每个样本独立地从先验到数据沿着近乎直的轨迹行进，而忽略了共享结构。

Method: 提出了一种基于具有次线性指数（零到一之间）的新型速度驱动传输成本的Y型生成流。该模型在可扩展的神经ODE训练目标中实现，并以联合和快速的质量移动为奖励。

Result: 在合成、图像和生物学数据集上，Y型流恢复了层次结构感知结构，改进了分布指标，并以更少的积分步数达到了目标。

Conclusion: Y型生成流能够捕捉数据中的层次结构，并比现有的基于流的方法更有效地生成数据。

Abstract: Modern continuous-time generative models often induce V-shaped transport:
each sample travels independently along nearly straight trajectories from prior
to data, overlooking shared structure. We introduce Y-shaped generative flows,
which move probability mass together along shared pathways before branching to
target-specific endpoints. Our formulation is based on novel velocity-powered
transport cost with a sublinear exponent (between zero and one). this concave
dependence rewards joint and fast mass movement. Practically, we instantiate
the idea in a scalable neural ODE training objective. On synthetic, image, and
biology datasets, Y-flows recover hierarchy-aware structure, improve
distributional metrics over strong flow-based baselines, and reach targets with
fewer integration steps.

</details>


### [371] [MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics](https://arxiv.org/abs/2510.11962)
*Bowei Guo,Shengkun Tang,Cong Zeng,Zhiqiang Shen*

Main category: cs.LG

TL;DR: MosaicDiff 通过调整不同训练阶段的剪枝策略来加速扩散模型的采样过程，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型的研究忽略了预训练过程中的学习速度变化，并且忽略了利用这些变化来加速采样。

Method: MosaicDiff 提出了一种新的框架，通过观察扩散模型预训练的不同阶段（快、慢学习阶段）来调整剪枝策略。对于学习速度快的中间阶段，采用保守剪枝；对于学习速度慢的早期和后期阶段，采用更积极的剪枝。

Result: 在 DiT 和 SDXL 模型上的实验表明，MosaicDiff 在不影响生成质量的情况下显著提高了采样速度，并且效果优于现有方法。

Conclusion: MosaicDiff 提供了一种新的、高效且鲁棒的、无需重新训练即可加速扩散模型的方法，并为理解和优化扩散模型的训练过程提供了新的视角。

Abstract: Diffusion models are renowned for their generative capabilities, yet their
pretraining processes exhibit distinct phases of learning speed that have been
entirely overlooked in prior post-training acceleration efforts in the
community. In this study, we introduce a novel framework called MosaicDiff that
aligns diffusion pretraining dynamics with post-training sampling acceleration
via trajectory-aware structural pruning. Our approach leverages the observation
that the middle, fast-learning stage of diffusion pretraining requires more
conservative pruning to preserve critical model features, while the early and
later, slow-learning stages benefit from a more aggressive pruning strategy.
This adaptive pruning mechanism is the first to explicitly mirror the inherent
learning speed variations of diffusion pretraining, thereby harmonizing the
model's inner training dynamics with its accelerated sampling process.
Extensive experiments on DiT and SDXL demonstrate that our method achieves
significant speed-ups in sampling without compromising output quality,
outperforming previous state-of-the-art methods by large margins, also
providing a new viewpoint for more efficient and robust training-free diffusion
acceleration.

</details>


### [372] [QLENS: Towards A Quantum Perspective of Language Transformers](https://arxiv.org/abs/2510.11963)
*Aditya Gupta,Kirandeep Kaur,Vinayak Gupta*

Main category: cs.LG

TL;DR: 本研究提出QLENS，一种基于物理学（特别是量子力学）的Transformer模型可解释性新框架，将模型层视为酉算符演化，并使用Born法则计算最终概率分布，旨在弥合现有可解释性方法的局限性，为理解Transformer的生成过程提供新的数学视角。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer可解释性方法仅能识别中间预测，缺乏对模型层如何促进状态转换的数学框架，这促使研究者寻求跨学科的解决方案。

Method: 提出QLENS框架，将Transformer的潜在激活映射到希尔伯特空间的状态向量，将其视为随模型层（酉算符/哈密顿量）演化的状态，并利用Born法则和特定测量算符获得最终概率分布。

Result: 通过对玩具Transformer进行概念验证，探究了模型各层在预测轨迹中的影响。

Conclusion: QLENS为利用跨领域洞见（特别是物理学）来增进对Transformer的理解奠定了基础，为Transformer的可解释性研究开辟了新的方向。

Abstract: In natural language processing, current methods for understanding
Transformers are successful at identifying intermediate predictions during a
model's inference. However, these approaches function as limited diagnostic
checkpoints, lacking a mathematical framework for mechanistically modeling how
each layer facilitates transitions between these evolving states. This
interpretability gap and past successes of interdisciplinary outlooks inspire
us to turn to physics in search of a descriptive mathematical framework for
Transformers. We observe that language models are intrinsically probabilistic,
an attribute that is echoed in the core postulates of quantum mechanics. This
parallel inspires us to translate insights from this discipline to that of
natural language processing. Towards this objective, we propose QLENS a novel
attempt to develop a physics-based perspective on the Transformer generation
process. Under QLENS, a Transformer is studied by converting its latent
activations into a state vector in a Hilbert space derived from the model's
output units. This state subsequently evolves through hidden layers -
reformulated as unitary operators and analogously defined Hamiltonians - during
inference. The model's final probability distribution is obtained by applying
the Born rule to the end state using a specific measurement operator. To
demonstrate QLENS's potential, we conduct a proof-of-concept by probing a toy
Transformer to investigate the influence of individual layers in a model's
prediction trajectory. We present our work as a foundation for cross-domain
insights to be leveraged towards a broader understanding of Transformers.

</details>


### [373] [Learning Dynamics of VLM Finetuning](https://arxiv.org/abs/2510.11978)
*Jusheng Zhang,Kaitong Cai,Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: CW-DPO 通过在预训练阶段使用平滑监督来稳定训练，并在 DPO 阶段使用冷却权重来抑制不适宜的梯度，从而提高了视觉-语言模型（VLM）的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 基于偏好的微调（preference-based finetuning）在视觉-语言模型（VLMs）上表现不稳定，因为不恰当的负样本会引入无效的梯度，破坏训练的稳定性。因此，需要一种新的方法来解决这个问题。

Method: 本文提出了一种名为“冷却加权 DPO（CW-DPO）”的两阶段方法。第一阶段使用“温和的负样本”（低权重的平滑监督）进行监督微调，以规范化基础策略并减少模型的不确定性。第二阶段应用 DPO 目标函数，其中负样本项的权重由模型在这些负样本上的平均 token 对数概率计算得出的“冷却权重”进行缩放，从而抑制来自简单或分布外样本的梯度，同时保留来自困难负样本的信号。此外，文章还强调了使用“on-policy 负样本”和混合数据集负样本的重要性，并使用 Δlog p 探针来监控训练过程。

Result: CW-DPO 在各种 VLM 任务上实现了比仅使用 SFT 和标准 DPO 更稳定的优化、更好的校准和更高的成对胜率，并且收敛速度更快。实验还表明，“冷却权重机制”是取得这些改进的主要原因，并且混合使用 on-policy 和数据集负样本具有协同效应。

Conclusion: 将预训练阶段的“平滑学习动态”与 DPO 阶段的“冷却偏好”相结合，是一种简单且通用的方法，可以实现 VLM 的鲁棒对齐。

Abstract: Preference-based finetuning of vision--language models (VLMs) is brittle:
trivially wrong negatives inject uninformative gradients that destabilize
training. We recast alignment as \textbf{learning-dynamics--aware optimization}
and introduce \textbf{Cooling-Weighted DPO (CW-DPO)}, a two-stage recipe that
explicitly models and exploits the training trajectory. \textbf{Stage 1}
performs supervised finetuning with \textbf{gentle negatives}:
\textbf{low-weight smoothed supervision} that regularizes the base policy and
curbs overconfidence without explicit penalties. \textbf{Stage 2} applies a DPO
objective in which the \textbf{negative term is scaled by a cooling weight}
computed from the model's \textbf{average token log-probability} on each
negative, suppressing uninformative gradients from easy or off-distribution
samples while preserving signal from hard negatives. In practice, we emphasize
\textbf{on-policy negatives} and allow \textbf{mixed negatives} by blending a
controllable fraction of dataset negatives to maintain contrast freshness.
Throughout, we instrument training with $\Delta\!\log p$ probes on positives
and negatives as first-class signals for early stopping, curriculum design, and
failure diagnosis. Across diverse VLM tasks, CW-DPO yields \textbf{more stable
optimization}, \textbf{better calibration}, and \textbf{higher pairwise
win-rates} than SFT-only and vanilla DPO, while \textbf{converging in fewer
steps}. Ablations isolate the \textbf{cooling-weight mechanism} as the primary
driver of these gains and show complementary benefits from mixing on-policy and
dataset negatives. Taken together, our results show that \textbf{smoothing
learning dynamics before cooling preferences} is a simple, general principle
for robust VLM alignment.

</details>


### [374] [Learning by Steering the Neural Dynamics: A Statistical Mechanics Perspective](https://arxiv.org/abs/2510.11984)
*Mattia Scardecchia*

Main category: cs.LG

TL;DR: 深度学习的梯度下降优化与生物学习机制存在差异，本文旨在通过研究神经动力学来弥合这一差距，探索全局部、分布式且能扩展到机器学习基准的生物学习方法。


<details>
  <summary>Details</summary>
Motivation: 当前的AI（深度神经网络）与计算神经科学在学习机制上存在根本性差异，促使研究者思考生物体如何在低能耗下实现高效、鲁棒且样本效率的学习，并解决没有反向传播的信用分配问题。

Method: 利用统计力学的工具，分析了随机非对称循环网络中鲁棒动力学吸引子出现的条件，推导了固定点数量与自耦合强度的关系式，并揭示了固定点结构中的相变现象：在临界自耦合强度以下，存在孤立固定点和指数级增长的、具有重叠-隙性质的窄簇；超过临界值，则出现密度大、范围广但占优性低的簇。

Result: 提出了一种受生物启发的监督学习算法，适用于任何二元循环网络。该算法通过将输入映射到动力学吸引点，利用瞬态外部刺激进行弛豫，并通过局部可塑性来稳定这些构型。实验表明，该算法能够学习MNIST的纠缠版本，利用深度结构发展分层表征和增强联想记忆容量，并适用于多种网络架构。算法性能与揭示的相变现象密切相关。

Conclusion: 本文通过对神经动力学的研究，提出了一种生物学上可行的、基于局部学习规则的监督学习算法，并在机器学习任务上取得了成功，为连接AI与神经科学提供了新的思路。同时，指出了算法性能与相变现象的关联，并提出了一个受皮层启发的自耦合替代方案。

Abstract: Despite the striking successes of deep neural networks trained with
gradient-based optimization, these methods differ fundamentally from their
biological counterparts. This gap raises key questions about how nature
achieves robust, sample-efficient learning at minimal energy costs and solves
the credit-assignment problem without backpropagation. We take a step toward
bridging contemporary AI and computational neuroscience by studying how neural
dynamics can support fully local, distributed learning that scales to simple
machine-learning benchmarks. Using tools from statistical mechanics, we
identify conditions for the emergence of robust dynamical attractors in random
asymmetric recurrent networks. We derive a closed-form expression for the
number of fixed points as a function of self-coupling strength, and we reveal a
phase transition in their structure: below a critical self-coupling, isolated
fixed points coexist with exponentially many narrow clusters showing the
overlap-gap property; above it, subdominant yet dense and extensive clusters
appear. These fixed points become accessible, including to a simple
asynchronous dynamical rule, after an algorithm-dependent self-coupling
threshold. Building on this analysis, we propose a biologically plausible
algorithm for supervised learning with any binary recurrent network. Inputs are
mapped to fixed points of the dynamics, by relaxing under transient external
stimuli and stabilizing the resulting configurations via local plasticity. We
show that our algorithm can learn an entangled version of MNIST, leverages
depth to develop hierarchical representations and increase hetero-association
capacity, and is applicable to several architectures. Finally, we highlight the
strong connection between algorithm performance and the unveiled phase
transition, and we suggest a cortex-inspired alternative to self-couplings for
its emergence.

</details>


### [375] [Nonlinear discretizations and Newton's method: characterizing stationary points of regression objectives](https://arxiv.org/abs/2510.11987)
*Conor Rowan*

Main category: cs.LG

TL;DR: 二阶方法在训练神经网络方面展现出潜力，但使用精确的海森矩阵会导致训练失败，这揭示了非线性离散的几何特性和损失函数平坦区域的分布。


<details>
  <summary>Details</summary>
Motivation: 探究为何在训练神经网络时，使用精确的海森矩阵（二阶信息）而非近似值（拟牛顿法）会导致优化失败，并分析这种失败现象对理解损失函数几何形状和稳定点分布的启示。

Method: 通过实验和理论分析，研究在神经网络训练中使用精确海森矩阵与近似海森矩阵（拟牛顿法）的效果差异，并观察和记录使用精确海森矩阵时的失败模式。

Result: 在神经网络训练中，使用精确海森矩阵的方法相比拟牛顿法更容易失败。这些失败模式为理解非线性离散的几何特性以及损失函数平坦区域的分布提供了新的视角。

Conclusion: 神经网络训练的失败并非源于传统观念认为的局部最小值过多，而是与使用精确曲率信息有关，这挑战了关于损失函数地形的传统认知。

Abstract: Second-order methods are emerging as promising alternatives to standard
first-order optimizers such as gradient descent and ADAM for training neural
networks. Though the advantages of including curvature information in computing
optimization steps have been celebrated in the scientific machine learning
literature, the only second-order methods that have been studied are
quasi-Newton, meaning that the Hessian matrix of the objective function is
approximated. Though one would expect only to gain from using the true Hessian
in place of its approximation, we show that neural network training reliably
fails when relying on exact curvature information. The failure modes provide
insight both into the geometry of nonlinear discretizations as well as the
distribution of stationary points in the loss landscape, leading us to question
the conventional wisdom that the loss landscape is replete with local minima.

</details>


### [376] [Mamaba Can Learn Low-Dimensional Targets In-Context via Test-Time Feature Learning](https://arxiv.org/abs/2510.12026)
*Junsoo Oh,Wei Huang,Taiji Suzuki*

Main category: cs.LG

TL;DR: Mamba是一种高效的线性时间序列模型，本文对其上下文学习（ICL）能力进行了理论分析，证明了其可以通过测试时特征学习来提取相关特征，并在低维非线性目标函数任务上取得了优于线性Transformer的性能。


<details>
  <summary>Details</summary>
Motivation: Mamba模型虽然在实际应用中表现出色，但缺乏深入的理论理解，特别是其上下文学习（ICL）能力。

Method: 通过关注由低维非线性目标函数定义的任务，特别是单指标模型 $y oldsymbol{eta}, oldsymbol{x} angle$，来分析Mamba的ICL能力。证明了预训练的Mamba可以通过测试时特征学习来提取相关特征。

Result: Mamba在单指标模型任务上实现了高效的ICL，其测试时样本复杂度优于线性Transformer，并可与非线性Transformer相媲美。

Conclusion: Mamba的非线性门控机制是其高效提取特征的关键，这解释了其兼具计算效率和高性能的原因。

Abstract: Mamba, a recently proposed linear-time sequence model, has attracted
significant attention for its computational efficiency and strong empirical
performance. However, a rigorous theoretical understanding of its underlying
mechanisms remains limited. In this work, we provide a theoretical analysis of
Mamba's in-context learning (ICL) capability by focusing on tasks defined by
low-dimensional nonlinear target functions. Specifically, we study in-context
learning of a single-index model $y \approx g_*(\langle \boldsymbol{\beta},
\boldsymbol{x} \rangle)$, which depends on only a single relevant direction
$\boldsymbol{\beta}$, referred to as feature. We prove that Mamba, pretrained
by gradient-based methods, can achieve efficient ICL via test-time feature
learning, extracting the relevant direction directly from context examples.
Consequently, we establish a test-time sample complexity that improves upon
linear Transformers -- analyzed to behave like kernel methods -- and is
comparable to nonlinear Transformers, which have been shown to surpass the
Correlational Statistical Query (CSQ) lower bound and achieve near
information-theoretically optimal rate in previous works. Our analysis reveals
the crucial role of the nonlinear gating mechanism in Mamba for feature
extraction, highlighting it as the fundamental driver behind Mamba's ability to
achieve both computational efficiency and high performance.

</details>


### [377] [Your VAR Model is Secretly an Efficient and Explainable Generative Classifier](https://arxiv.org/abs/2510.12060)
*Yi-Chung Chen,David I. Inouye,Jing Gao*

Main category: cs.LG

TL;DR: 本文提出了一种基于视觉自回归（VAR）模型的生成式分类器，名为自适应VAR分类器（A-VARC+），以解决扩散模型计算成本高昂的问题。该模型在准确性和推理速度之间取得了更好的平衡，并具有可解释性和对灾难性遗忘的抵抗能力。


<details>
  <summary>Details</summary>
Motivation: 近期生成式分类器在处理分布变化方面表现出优势，但现有基于扩散模型的方法计算成本高，限制了其可扩展性和对生成式分类器本身的理解。因此，需要探索计算成本更低、能提供新视角的生成式分类器方法。

Method: 提出了一种新颖的生成式分类器，该分类器基于视觉自回归（VAR）模型。进一步引入了自适应VAR分类器+（A-VARC+），以提高性能并优化准确性与推理速度的权衡。

Result: A-VARC+在准确性和推理速度之间取得了优越的权衡，显著提高了实际应用性。与扩散模型不同，VAR模型具有可处理的似然性，能够通过token-wise互信息实现视觉可解释性，并能抵抗类增量学习任务中的灾难性遗忘。

Conclusion: 基于VAR模型的生成式分类器（A-VARC+）不仅在性能上表现出色，而且在可解释性和鲁棒性方面也具有独特的优势，为生成式分类器领域提供了新的研究方向和更实用的解决方案。

Abstract: Generative classifiers, which leverage conditional generative models for
classification, have recently demonstrated desirable properties such as
robustness to distribution shifts. However, recent progress in this area has
been largely driven by diffusion-based models, whose substantial computational
cost severely limits scalability. This exclusive focus on diffusion-based
methods has also constrained our understanding of generative classifiers. In
this work, we propose a novel generative classifier built on recent advances in
visual autoregressive (VAR) modeling, which offers a new perspective for
studying generative classifiers. To further enhance its performance, we
introduce the Adaptive VAR Classifier$^+$ (A-VARC$^+$), which achieves a
superior trade-off between accuracy and inference speed, thereby significantly
improving practical applicability. Moreover, we show that the VAR-based method
exhibits fundamentally different properties from diffusion-based methods. In
particular, due to its tractable likelihood, the VAR-based classifier enables
visual explainability via token-wise mutual information and demonstrates
inherent resistance to catastrophic forgetting in class-incremental learning
tasks.

</details>


### [378] [MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging](https://arxiv.org/abs/2510.12070)
*Sangmin Jo,Jee Seok Yoon,Wootaek Jeong,Kwanseok Oh,Heung-Il Suk*

Main category: cs.LG

TL;DR: 深度学习睡眠分期模型在处理未见过的受试者时泛化能力不足，本文提出了一种名为MEASURE的多尺度最小充分表示学习框架，通过减少域相关信息并保留时间/频谱特征来提高泛化能力，并在公开数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的睡眠分期模型在处理未见过的受试者时存在泛化能力不足的问题，因为生理信号存在个体差异，导致模型在分布外场景下性能下降。对比学习虽然有助于学习域不变特征，但现有方法未能充分提取，因为它们没有明确处理跨样本的非共享信息中嵌入的域特征。

Method: 提出了一种名为MEASURE（Multi-scalE minimAl SUfficient Representation lEarning）的新框架，该框架通过减少域相关信息（过量域相关信息）并保留多层次特征（包括时间域和频谱域信息）来弥合域间差距，从而学习最小充分的表示。

Result: 在SleepEDF-20和MASS这两个公开的睡眠分期基准数据集上进行的广泛实验表明，所提出的MEASURE方法一致优于最先进的方法。

Conclusion: MEASURE框架通过有效减少域相关信息并保留睡眠分期分类所必需的时间和频谱特征，成功解决了现有方法的局限性，并在睡眠分期任务上实现了优越的泛化性能。

Abstract: Deep learning-based automatic sleep staging has significantly advanced in
performance and plays a crucial role in the diagnosis of sleep disorders.
However, those models often struggle to generalize on unseen subjects due to
variability in physiological signals, resulting in degraded performance in
out-of-distribution scenarios. To address this issue, domain generalization
approaches have recently been studied to ensure generalized performance on
unseen domains during training. Among those techniques, contrastive learning
has proven its validity in learning domain-invariant features by aligning
samples of the same class across different domains. Despite its potential, many
existing methods are insufficient to extract adequately domain-invariant
representations, as they do not explicitly address domain characteristics
embedded within the unshared information across samples. In this paper, we
posit that mitigating such domain-relevant attributes-referred to as excess
domain-relevant information-is key to bridging the domain gap. However, the
direct strategy to mitigate the domain-relevant attributes often overfits
features at the high-level information, limiting their ability to leverage the
diverse temporal and spectral information encoded in the multiple feature
levels. To address these limitations, we propose a novel MEASURE (Multi-scalE
minimAl SUfficient Representation lEarning) framework, which effectively
reduces domain-relevant information while preserving essential temporal and
spectral features for sleep stage classification. In our exhaustive experiments
on publicly available sleep staging benchmark datasets, SleepEDF-20 and MASS,
our proposed method consistently outperformed state-of-the-art methods. Our
code is available at : https://github.com/ku-milab/Measure

</details>


### [379] [Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals](https://arxiv.org/abs/2510.12405)
*Masahiro Negishi,Hyunsoo Park,Kinga O. Mastej,Aron Walsh*

Main category: cs.LG

TL;DR: 现有的生成模型在采样材料化学空间时，其评估指标（唯一性和新颖性）依赖的晶体距离函数存在局限性，无法准确量化相似度、区分组分和结构差异、对原子坐标变化不鲁棒，且唯一性指标不具备置换不变性。本研究提出了两种连续距离函数，理论上克服了这些缺点，并通过实验证明其能提供比传统方法更可靠的评估依据。


<details>
  <summary>Details</summary>
Motivation: 现有的晶体距离函数在评估生成模型生成的无机晶体时存在局限性，包括无法量化相似度、区分组分和结构差异、对原子坐标变化不鲁棒以及唯一性指标不具备置换不变性，因此需要新的评估方法。

Method: 提出并使用两种连续距离函数来评估生成模型生成的无机晶体的唯一性和新颖性。

Result: 实验结果表明，所提出的连续距离函数能够克服传统距离函数的局限性，提供更可靠的评估依据，并揭示了传统方法所忽略的见解。

Conclusion: 提出的两种连续距离函数为评估和比较用于无机晶体的生成模型提供了一个更可靠的基础，克服了现有方法的局限性。

Abstract: To address pressing scientific challenges such as climate change,
increasingly sophisticated generative artificial intelligence models are being
developed that can efficiently sample the large chemical space of possible
functional materials. These models can quickly sample new chemical compositions
paired with crystal structures. They are typically evaluated using uniqueness
and novelty metrics, which depend on a chosen crystal distance function.
However, the most prevalent distance function has four limitations: it fails to
quantify the degree of similarity between compounds, cannot distinguish
compositional difference and structural difference, lacks Lipschitz continuity
against shifts in atomic coordinates, and results in a uniqueness metric that
is not invariant against the permutation of generated samples. In this work, we
propose using two continuous distance functions to evaluate uniqueness and
novelty, which theoretically overcome these limitations. Our experiments show
that these distances reveal insights missed by traditional distance functions,
providing a more reliable basis for evaluating and comparing generative models
for inorganic crystals.

</details>


### [380] [Influence Dynamics and Stagewise Data Attribution](https://arxiv.org/abs/2510.12071)
*Jin Hwa Lee,Matthew Smith,Maxwell Adam,Jesse Hoogland*

Main category: cs.LG

TL;DR: 本文提出了一个基于奇异学习理论的阶段性数据归因框架，用于捕捉神经网络学习过程中数据点之间动态变化的关联性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据归因方法将一个样本对另一个样本的影响视为静态的，但忽略了神经网络学习过程中影响模式的动态变化。

Method: 提出一个基于奇异学习理论的阶段性数据归因框架，预测影响会非单调变化，包括符号翻转和在发展转换处出现峰值。在玩具模型上进行了理论和实证验证，并在大型语言模型上进行了演示。

Result: 在玩具模型上，动态影响变化与模型语义层级学习过程直接相关。在语言模型上，词元级别的影响变化与已知的发展阶段一致。

Conclusion: 数据归因应考虑学习过程中的动态变化，而非静态视角。

Abstract: Current training data attribution (TDA) methods treat the influence one
sample has on another as static, but neural networks learn in distinct stages
that exhibit changing patterns of influence. In this work, we introduce a
framework for stagewise data attribution grounded in singular learning theory.
We predict that influence can change non-monotonically, including sign flips
and sharp peaks at developmental transitions. We first validate these
predictions analytically and empirically in a toy model, showing that dynamic
shifts in influence directly map to the model's progressive learning of a
semantic hierarchy. Finally, we demonstrate these phenomena at scale in
language models, where token-level influence changes align with known
developmental stages.

</details>


### [381] [Rethinking the Role of Dynamic Sparse Training for Scalable Deep Reinforcement Learning](https://arxiv.org/abs/2510.12096)
*Guozheng Ma,Lu Li,Zilin Wang,Haoyu Wang,Shengchao Hu,Leszek Rutkowski,Dacheng Tao*

Main category: cs.LG

TL;DR: 动态稀疏训练策略在深度强化学习中通过模块化适应提升模型性能，并提出模块特定训练（MST）框架。


<details>
  <summary>Details</summary>
Motivation: 当前深度强化学习（DRL）领域存在模型规模增大导致性能下降的问题，现有动态网络拓扑调整方法存在局限性，如策略统一、评估不全面以及缺乏不同动态方法间的系统比较。

Method: 通过在不同模块（编码器、评论家、演员）和不同架构上进行全面的动态稀疏训练策略（稀疏到稀疏、稠密到稀疏、稀疏到稠密）的分析和比较，揭示了动态稀疏训练策略对模块的具体益处，并将其整合成模块特定训练（MST）框架。

Result: 动态稀疏训练策略为模块提供了特定优势，与架构改进共同促进了DRL的可扩展性。MST框架在无需算法修改的情况下，在多种DRL算法中实现了显著的可扩展性提升。

Conclusion: 模块特定训练（MST）框架通过结合架构改进和模块化的动态稀疏训练策略，有效解决了DRL中的可扩展性问题，并在多种算法上验证了其有效性。

Abstract: Scaling neural networks has driven breakthrough advances in machine learning,
yet this paradigm fails in deep reinforcement learning (DRL), where larger
models often degrade performance due to unique optimization pathologies such as
plasticity loss. While recent works show that dynamically adapting network
topology during training can mitigate these issues, existing studies have three
critical limitations: (1) applying uniform dynamic training strategies across
all modules despite encoder, critic, and actor following distinct learning
paradigms, (2) focusing evaluation on basic architectures without clarifying
the relative importance and interaction between dynamic training and
architectural improvements, and (3) lacking systematic comparison between
different dynamic approaches including sparse-to-sparse, dense-to-sparse, and
sparse-to-dense. Through comprehensive investigation across modules and
architectures, we reveal that dynamic sparse training strategies provide
module-specific benefits that complement the primary scalability foundation
established by architectural improvements. We finally distill these insights
into Module-Specific Training (MST), a practical framework that further
exploits the benefits of architectural improvements and demonstrates
substantial scalability gains across diverse RL algorithms without algorithmic
modifications.

</details>


### [382] [Chimera: State Space Models Beyond Sequences](https://arxiv.org/abs/2510.12111)
*Aakash Lahoti,Tanya Marwah,Ratish Puduppully,Albert Gu*

Main category: cs.LG

TL;DR: Chimera是一个统一的模型，可以直接整合数据拓扑，无需领域特定的归纳偏置，并在语言、视觉和图领域都取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型忽略了数据的邻域结构或图拓扑，需要引入位置嵌入或随机游走等归纳偏置，而这些偏置的设计耗时且可能影响泛化能力。

Method: Chimera通过将状态空间模型推广到捕捉任意图拓扑，直接整合数据拓扑，消除了对领域特定偏置的需求。

Result: Chimera在GLUE、ImageNet-1k和长程图基准测试中均取得了优于现有方法的性能。此外，Chimera可以通过线性时间递归（DAG）或数学松弛（通用图）进行优化，以提高效率。

Conclusion: 数据拓扑可以作为一种强大的归纳偏置，跨模态地应用于语言、视觉和图等领域，Chimera的成功验证了这一理念。

Abstract: Transformer-based deep learning methods have become the standard approach for
modeling diverse data such as sequences, images, and graphs. These methods rely
on self-attention, which treats data as an unordered set of elements. This
ignores the neighborhood structure or graph topology of the data and requires
inductive biases--such as position embeddings in sequences and images, or
random walks in graphs--to incorporate topology. However, designing such
task-specific biases requires significant effort and can introduce side effects
that hinder generalization. We introduce Chimera, a unified model that directly
incorporates data topology in a principled way, removing the need for
domain-specific biases. The key idea is that state space models--which
naturally do not require position embeddings--can be generalized to capture any
graph topology. Our experiments show that Chimera achieves strong performance
across language, vision, and graph domains, outperforming BERT on GLUE by 0.7
points, ViT on ImageNet-1k by 2.6%, and all baselines on the Long Range Graph
Benchmark. We further propose algorithmic optimizations to improve Chimera's
efficiency: (1) for Directed Acyclic Graphs, Chimera can be implemented as a
linear-time recurrence; (2) for general graphs, a simple mathematical
relaxation achieves Transformer's quadratic complexity without domain-specific
heuristics. These results validate Chimera's core contribution and support the
idea that data topology is a powerful inductive bias across modalities.

</details>


### [383] [Graph Few-Shot Learning via Adaptive Spectrum Experts and Cross-Set Distribution Calibration](https://arxiv.org/abs/2510.12140)
*Yonghao Liu,Yajun Wang,Chunli Guo,Wei Pang,Ximing Li,Fausto Giunchiglia,Xiaoyue Feng,Renchu Guan*

Main category: cs.LG

TL;DR: GRACE是一个图学习框架，通过自适应频谱专家和跨集分布校准技术来解决现有图学习方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有图学习方法依赖固定的频谱操作，无法处理现实世界图中复杂的局部拓扑结构；并且假设支持集和查询集来自同一分布，这在少样本条件下可能导致泛化能力不足。

Method: 提出GRACE框架，整合自适应频谱专家和跨集分布校准技术，以适应局部结构变化和进行跨集分布校准。

Result: GRACE在各种实验设置中始终优于最先进的基线方法。

Conclusion: GRACE通过自适应局部结构变化和跨集分布校准，增强了模型的泛化能力。

Abstract: Graph few-shot learning has attracted increasing attention due to its ability
to rapidly adapt models to new tasks with only limited labeled nodes. Despite
the remarkable progress made by existing graph few-shot learning methods,
several key limitations remain. First, most current approaches rely on
predefined and unified graph filters (e.g., low-pass or high-pass filters) to
globally enhance or suppress node frequency signals. Such fixed spectral
operations fail to account for the heterogeneity of local topological
structures inherent in real-world graphs. Moreover, these methods often assume
that the support and query sets are drawn from the same distribution. However,
under few-shot conditions, the limited labeled data in the support set may not
sufficiently capture the complex distribution of the query set, leading to
suboptimal generalization. To address these challenges, we propose GRACE, a
novel Graph few-shot leaRning framework that integrates Adaptive spectrum
experts with Cross-sEt distribution calibration techniques. Theoretically, the
proposed approach enhances model generalization by adapting to both local
structural variations and cross-set distribution calibration. Empirically,
GRACE consistently outperforms state-of-the-art baselines across a wide range
of experimental settings. Our code can be found here.

</details>


### [384] [Fairness-Constrained Optimization Attack in Federated Learning](https://arxiv.org/abs/2510.12143)
*Harsh Kasyap,Minghong Fang,Zhuqing Liu,Carsten Maple,Somanath Tripathy*

Main category: cs.LG

TL;DR: 该研究提出了一种新的联邦学习（FL）中的公平性攻击方法，该攻击能通过单个恶意客户端注入偏见，同时保持全局准确性，并且难以检测。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）协作模式在保护隐私的同时，也容易受到模型污染和偏见传播的影响。本研究旨在提出一种新的、更隐蔽的公平性攻击方法。

Method: 提出了一种故意的公平性攻击，攻击者通过在模型训练过程中增加公平性损失（通过优化公平性指标如人口统计均等和公平化赔率来计算）来发送有偏见的模型。该攻击即使在数据分布相同的情况下也能奏效。

Result: 实验结果表明，该攻击能在存在单个恶意客户端的情况下，将偏见最多增加90%，并且在现有先进的拜占庭鲁棒和公平感知聚合方案下仍然有效。

Conclusion: 所提出的公平性攻击是一种隐蔽且有效的攻击方式，能够显著增加联邦学习系统中的偏见，同时保持全局准确性，对现有的防御机制构成了挑战。

Abstract: Federated learning (FL) is a privacy-preserving machine learning technique
that facilitates collaboration among participants across demographics. FL
enables model sharing, while restricting the movement of data. Since FL
provides participants with independence over their training data, it becomes
susceptible to poisoning attacks. Such collaboration also propagates bias among
the participants, even unintentionally, due to different data distribution or
historical bias present in the data. This paper proposes an intentional
fairness attack, where a client maliciously sends a biased model, by increasing
the fairness loss while training, even considering homogeneous data
distribution. The fairness loss is calculated by solving an optimization
problem for fairness metrics such as demographic parity and equalized odds. The
attack is insidious and hard to detect, as it maintains global accuracy even
after increasing the bias. We evaluate our attack against the state-of-the-art
Byzantine-robust and fairness-aware aggregation schemes over different
datasets, in various settings. The empirical results demonstrate the attack
efficacy by increasing the bias up to 90\%, even in the presence of a single
malicious client in the FL system.

</details>


### [385] [Budget-constrained Active Learning to Effectively De-censor Survival Data](https://arxiv.org/abs/2510.12144)
*Ali Parsaee,Bei Jiang,Zachary Friggstad,Russell Greiner*

Main category: cs.LG

TL;DR: 在此论文中，我们探索了带成本的学习在生存数据集中的应用，并提供了实验和理论结果，证明了我们的方法在多个生存任务上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 在标准监督学习范式中，模型从标记数据集中学习。然而，在实际应用中，标注数据可能成本高昂。该研究旨在解决预算有限的情况下，如何在生存数据集中有效地利用有限的预算来获取额外标签信息，以构建更优的模型。

Method: 提出了一种将现有预算学习算法应用于生存数据的方法，并进行了理论分析，证明了其在时间和界限上的渐近最优性，与标准主动学习方法BatchBALD相当。

Result: 在多个生存任务的实证分析中，该方法表现优于其他潜在方法，证明了其在实际应用中的有效性。

Conclusion: 该研究成功地将预算学习应用于生存数据集，并提供了理论和实证支持，证明了其优越性。

Abstract: Standard supervised learners attempt to learn a model from a labeled dataset.
Given a small set of labeled instances, and a pool of unlabeled instances, a
budgeted learner can use its given budget to pay to acquire the labels of some
unlabeled instances, which it can then use to produce a model. Here, we explore
budgeted learning in the context of survival datasets, which include (right)
censored instances, where we know only a lower bound on an instance's
time-to-event. Here, that learner can pay to (partially) label a censored
instance -- e.g., to acquire the actual time for an instance [perhaps go from
(3 yr, censored) to (7.2 yr, uncensored)], or other variants [e.g., learn about
one more year, so go from (3 yr, censored) to either (4 yr, censored) or
perhaps (3.2 yr, uncensored)]. This serves as a model of real world data
collection, where follow-up with censored patients does not always lead to
uncensoring, and how much information is given to the learner model during data
collection is a function of the budget and the nature of the data itself. We
provide both experimental and theoretical results for how to apply
state-of-the-art budgeted learning algorithms to survival data and the
respective limitations that exist in doing so. Our approach provides bounds and
time complexity asymptotically equivalent to the standard active learning
method BatchBALD. Moreover, empirical analysis on several survival tasks show
that our model performs better than other potential approaches on several
benchmarks.

</details>


### [386] [Self-Verifying Reflection Helps Transformers with CoT Reasoning](https://arxiv.org/abs/2510.12157)
*Zhongwei Yu,Wannian Xia,Xue Yan,Bo Xu,Haifeng Zhang,Yali Du,Jun Wang*

Main category: cs.LG

TL;DR: LLMs的推理链（CoT）中的自我验证反思被证明可以提高性能，即使对于小型Transformer模型也是如此，并且可以通过强化学习进一步增强，但强化学习并未有效减少验证错误。


<details>
  <summary>Details</summary>
Motivation: LLMs在推理链（CoT）中进行自我验证和探索替代方案，但其效益尚不清楚，因为它们只能检测有限的错误。本研究旨在通过一个简单的框架来分析这一问题，该框架支持小型Transformer进行基本的自我验证反思。

Method: 提出一个最小化的推理框架，支持小型Transformer进行基本的自我验证反思，无需自然语言，从而保证了分析的清晰度并降低了实验成本。理论上证明了在验证错误有界的情况下，自我验证反思可以保证性能提升。实验上，在整数乘法和数独任务中，使用只有几百万参数的小型Transformer模型，展示了自我验证在训练和反思执行中的优势，达到了接近LLM的性能。

Result: 小型Transformer模型通过自我验证在训练和反思执行中均获得性能提升，在整数乘法和数独任务中表现出色。强化学习（RL）能提高模型的分布内性能并促使模型进行频繁反思，但未能有效减少验证错误，主要优化了浅层统计模式。

Conclusion: 生成式Transformer与判别式验证的结合，能够促进CoT推理，且这种促进作用与模型规模和是否使用自然语言无关。

Abstract: Advanced large language models (LLMs) frequently reflect in reasoning
chain-of-thoughts (CoTs), where they self-verify the correctness of current
solutions and explore alternatives. However, given recent findings that LLMs
detect limited errors in CoTs, how reflection contributes to empirical
improvements remains unclear. To analyze this issue, in this paper, we present
a minimalistic reasoning framework to support basic self-verifying reflection
for small transformers without natural language, which ensures analytic clarity
and reduces the cost of comprehensive experiments. Theoretically, we prove that
self-verifying reflection guarantees improvements if verification errors are
properly bounded. Experimentally, we show that tiny transformers, with only a
few million parameters, benefit from self-verification in both training and
reflective execution, reaching remarkable LLM-level performance in integer
multiplication and Sudoku. Similar to LLM results, we find that reinforcement
learning (RL) improves in-distribution performance and incentivizes frequent
reflection for tiny transformers, yet RL mainly optimizes shallow statistical
patterns without faithfully reducing verification errors. In conclusion,
integrating generative transformers with discriminative verification inherently
facilitates CoT reasoning, regardless of scaling and natural language.

</details>


### [387] [Revisiting Meta-Learning with Noisy Labels: Reweighting Dynamics and Theoretical Guarantees](https://arxiv.org/abs/2510.12209)
*Yiming Zhang,Chester Holtz,Gal Mishne,Alex Cloninger*

Main category: cs.LG

TL;DR: 元学习方法在处理带噪声标签的数据集时，虽然可以通过重赋样本权重来缓解过拟合问题，但其训练机制缺乏理论支持。本文通过理论分析揭示了其三阶段（对齐、过滤、过滤后）的训练动态，并提出了一种轻量化的替代方法，在保持稳定性的同时避免了复杂的双层优化，并在多项基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 带噪声标签的学习仍然是一个挑战，因为过度参数化的网络会记住错误的标签。基于元学习的样本重赋权可以通过使用一小部分干净数据来指导训练，但其行为和训练动态缺乏理论理解。

Method: 对带噪声标签的元重赋权进行了严格的理论分析，揭示了其训练轨迹分为三个阶段：对齐阶段、过滤阶段和过滤后阶段。在此基础上，提出了一种结合均值中心化、行移位和标签符号调制的轻量化替代方法，以替代昂贵的双层优化。

Result: 所提出的轻量化替代方法在合成和真实带噪声标签的基准测试中，性能优于强大的重赋权/选择基线方法。

Conclusion: 对元学习样本重赋权机制的理论分析揭示了其训练动态，并指导提出了一个更稳定、更轻量化的替代方法，该方法在各种噪声标签基准上都表现出色。

Abstract: Learning with noisy labels remains challenging because over-parameterized
networks memorize corrupted supervision. Meta-learning-based sample reweighting
mitigates this by using a small clean subset to guide training, yet its
behavior and training dynamics lack theoretical understanding. We provide a
rigorous theoretical analysis of meta-reweighting under label noise and show
that its training trajectory unfolds in three phases: (i) an alignment phase
that amplifies examples consistent with a clean subset and suppresses
conflicting ones; (ii) a filtering phase driving noisy example weights toward
zero until the clean subset loss plateaus; and (iii) a post-filtering phase in
which noise filtration becomes perturbation-sensitive. The mechanism is a
similarity-weighted coupling between training and clean subset signals together
with clean subset training loss contraction; in the post-filtering regime where
the clean-subset loss is sufficiently small, the coupling term vanishes and
meta-reweighting loses discriminatory power. Guided by this analysis, we
propose a lightweight surrogate for meta-reweighting that integrates
mean-centering, row shifting, and label-signed modulation, yielding more stable
performance while avoiding expensive bi-level optimization. Across synthetic
and real noisy-label benchmarks, our method consistently outperforms strong
reweighting/selection baselines.

</details>


### [388] [DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification](https://arxiv.org/abs/2510.12214)
*Tao Xie,Zexi Tan,Haoyi Xiao,Binbin Sun,Yiqun Zhang*

Main category: cs.LG

TL;DR: DE3S通过引入新的双增强软形状学习框架，解决了早期时间序列分类的准确性和提前性之间的冲突，以及早期信号弱和类别不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 早期时间序列分类（ETSC）在医疗应用中至关重要，例如ICU中的脓毒症预测，但面临准确性和提前性之间的冲突，现有方法难以捕捉早期模式，并且存在信号弱和类别不平衡的问题。

Method: 提出了一种名为DE3S的双增强软稀疏形状学习框架，包含三个创新点：（1）结合传统时间增强和基于注意力的时间增强；（2）基于注意力得分的软形状稀疏机制；（3）双路径MoE和Inception模块融合架构。

Result: 在六个真实世界医疗数据集上进行了广泛的实验，取得了最先进的性能，并且烧蚀研究证实了各组件的有效性。

Conclusion: DE3S框架能够精确地确定形状元，同时解决早期信号弱和类别不平衡的问题，在医疗早期时间序列分类任务上表现出色。

Abstract: Early time-series classification (ETSC) in medical applications is crucial
for time-sensitive scenarios such as sepsis prediction in intensive care units
(ICUs), where a large number of deaths are caused by delayed prediction. ETSC
can significantly improve ICU resource utilization efficiency and healthcare
precision. However, it faces conflicting goals of accuracy and earliness, with
existing methods often trading one for the other, struggling to capture subtle
early-stage patterns due to weak initial signals and class imbalance. The key
to solve these challenges is to find shapelets, which are discriminative
subsequences (or shapes) with high interpretability in time-series
classification. This paper proposes Dual-Enhanced Soft-Sparse-Shape Learning
for Medical Early Time-Series Classification (DE3S), which introduces a novel
Dual-Enhanced Soft-Shape Learning framework to figure out shapelets precisely
through three innovations: (1) a comprehensive dual-enhancement strategy
combines traditional temporal augmentation with attention-based global temporal
enhancement for robust representation learning, (2) an attention-score-based
soft shapelet sparsification mechanism dynamically preserves discriminative
patterns while aggregating less important shapelets into representative tokens,
and (3) a dual-path Mixture of Experts Network (MoE) and Inception modules
fusion architecture where MoE performs local learning within shapelets and
multi-scale Inception modules capture global patterns across shapelets. The
framework employs weighted cross-entropy loss for class imbalance handling and
demonstrates robustness on subject-consistency datasets. Extensive experiments
on six real-world medical datasets show state-of-the-art performance, with
ablation studies confirming component efficacy.

</details>


### [389] [Hierarchical Koopman Diffusion: Fast Generation with Interpretable Diffusion Trajectory](https://arxiv.org/abs/2510.12220)
*Hanru Bai,Weiyang Ding,Difan Zou*

Main category: cs.LG

TL;DR: Koopman 扩散模型通过引入 Koopman 算子理论，实现了快速采样和可解释的生成轨迹，解决了扩散模型的采样速度和可控性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型虽然生成图像质量高，但采样速度慢；而单步方法虽然速度快，但牺牲了可解释性和精细控制能力。本研究旨在解决这一矛盾，实现快速采样和可解释的生成轨迹。

Method: 本研究提出了分层 Koopman 扩散模型。该模型将非线性扩散动力学映射到潜在空间，并通过全局线性算子进行演化，从而获得封闭形式的轨迹解。通过分层结构，模型在不同空间分辨率上解耦生成动力学，并通过特定于尺度的 Koopman 子空间捕捉从粗到精的细节。

Result: 实验证明，分层 Koopman 扩散模型在单步生成方面具有竞争力，并且能够通过频谱分析来解释和操纵生成过程。

Conclusion: 本框架结合了扩散模型的快速采样和可解释性，为可解释的图像合成开辟了新的途径。

Abstract: Diffusion models have achieved impressive success in high-fidelity image
generation but suffer from slow sampling due to their inherently iterative
denoising process. While recent one-step methods accelerate inference by
learning direct noise-to-image mappings, they sacrifice the interpretability
and fine-grained control intrinsic to diffusion dynamics, key advantages that
enable applications like editable generation. To resolve this dichotomy, we
introduce \textbf{Hierarchical Koopman Diffusion}, a novel framework that
achieves both one-step sampling and interpretable generative trajectories.
Grounded in Koopman operator theory, our method lifts the nonlinear diffusion
dynamics into a latent space where evolution is governed by globally linear
operators, enabling closed-form trajectory solutions. This formulation not only
eliminates iterative sampling but also provides full access to intermediate
states, allowing manual intervention during generation. To model the
multi-scale nature of images, we design a hierarchical architecture that
disentangles generative dynamics across spatial resolutions via scale-specific
Koopman subspaces, capturing coarse-to-fine details systematically. We
empirically show that the Hierarchical Koopman Diffusion not only achieves
competitive one-step generation performance but also provides a principled
mechanism for interpreting and manipulating the generative process through
spectral analysis. Our framework bridges the gap between fast sampling and
interpretability in diffusion models, paving the way for explainable image
synthesis in generative modeling.

</details>


### [390] [Unveiling the Vulnerability of Graph-LLMs: An Interpretable Multi-Dimensional Adversarial Attack on TAGs](https://arxiv.org/abs/2510.12233)
*Bowen Fan,Zhilin Guo,Xunkai Li,Yihan Zhou,Bing Zhou,Zhenjun Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了一种名为IMDGA的新型、以人为中心的、可解释的多维度图攻击框架，用于操纵图神经网络（GNNs）和大型语言模型（LLMs）的文本属性图（TAGs）。


<details>
  <summary>Details</summary>
Motivation: 现有的攻击方法要么只针对图结构，要么只针对文本属性，缺乏统一的综合性方法来处理由GNNs和LLMs融合带来的复杂漏洞。

Method: IMDGA通过三个相互关联的模块，在图结构和文本特征上进行多层次的扰动，旨在实现攻击的可解释性和有效性之间的平衡。

Result: 通过理论分析和广泛的实证评估，IMDGA在可解释性、攻击效果、隐蔽性和鲁棒性方面均优于现有方法，揭示了TAGs表示学习中的关键弱点。

Conclusion: IMDGA框架揭示了Graph-LLMs中一个先前未被充分探索的语义脆弱性维度，为提高其韧性提供了宝贵的见解。

Abstract: Graph Neural Networks (GNNs) have become a pivotal framework for modeling
graph-structured data, enabling a wide range of applications from social
network analysis to molecular chemistry. By integrating large language models
(LLMs), text-attributed graphs (TAGs) enhance node representations with rich
textual semantics, significantly boosting the expressive power of graph-based
learning. However, this sophisticated synergy introduces critical
vulnerabilities, as Graph-LLMs are susceptible to adversarial attacks on both
their structural topology and textual attributes. Although specialized attack
methods have been designed for each of these aspects, no work has yet unified
them into a comprehensive approach. In this work, we propose the Interpretable
Multi-Dimensional Graph Attack (IMDGA), a novel human-centric adversarial
attack framework designed to orchestrate multi-level perturbations across both
graph structure and textual features. IMDGA utilizes three tightly integrated
modules to craft attacks that balance interpretability and impact, enabling a
deeper understanding of Graph-LLM vulnerabilities. Through rigorous theoretical
analysis and comprehensive empirical evaluations on diverse datasets and
architectures, IMDGA demonstrates superior interpretability, attack
effectiveness, stealthiness, and robustness compared to existing methods. By
exposing critical weaknesses in TAG representation learning, this work uncovers
a previously underexplored semantic dimension of vulnerability in Graph-LLMs,
offering valuable insights for improving their resilience. Our code and
resources are publicly available at
https://anonymous.4open.science/r/IMDGA-7289.

</details>


### [391] [MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant](https://arxiv.org/abs/2510.12245)
*Tao Yin,Xiaohong Zhang,Jiacheng Zhang,Li Huang,Zhibin Zhang,Yuansong Zeng,Jin Xie,Meng Yan*

Main category: cs.LG

TL;DR: MoRA 通过为每个分子动态生成独特的低秩适应权重，并将其注入到冻结的 LLM 中，从而在分子图和 LLM 之间实现实例特定的参数空间对齐，在药物发现任务中优于静态适应方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分子图和 LLM 整合中存在局限性：共享参数空间限制了捕获实例特定结构特征的能力，并且 LLM 微调可能导致灾难性遗忘，损害其通用推理能力。

Method: 提出了一种名为 MoRA（Molecule-aware Low-Rank Adaptation）的实例特定参数空间对齐方法，为每个输入的分子图动态生成一套独特的低秩适应权重，并将这些权重注入一个冻结的 LLM 中。

Result: 在化学反应预测和分子描述等关键分子任务上，MoRA 的实例特定动态适应在反应预测精确匹配方面提高了 14.1%，在量子性质预测方面将错误率降低了 22%，优于静态适应的基线。

Conclusion: MoRA 的实例特定动态适应方法能够有效整合分子图结构和 LLM，并在各种分子任务中取得显著的性能提升，同时保留 LLM 的核心知识。

Abstract: Effectively integrating molecular graph structures with Large Language Models
(LLMs) is a key challenge in drug discovery. Most existing multi-modal
alignment methods typically process these structures by fine-tuning the LLM or
adding a static adapter simultaneously. However, these approaches have two main
limitations: (1) it optimizes a shared parameter space across all molecular
inputs, limiting the model's ability to capture instance-specific structural
features; and (2) fine-tuning the LLM for molecular tasks can lead to
catastrophic forgetting, undermining its general reasoning capabilities. In
this paper, instead of static task-oriented adaptation, we propose an
instance-specific parameter space alignment approach for each molecule
on-the-fly. To this end, we introduce Molecule-aware Low-Rank Adaptation (MoRA)
that produces a unique set of low-rank adaptation weights for each input
molecular graph. These weights are then dynamically injected into a frozen LLM,
allowing the model to adapt its reasoning to the structure of each molecular
input, while preserving the LLM's core knowledge. Extensive experiments
demonstrate that on key molecular tasks, such as chemical reaction prediction
and molecular captioning, MoRA's instance-specific dynamic adaptation
outperforms statically adapted baselines, including a 14.1% relative
improvement in reaction prediction exact match and a 22% reduction in error for
quantum property prediction. The code is available at
https://github.com/jk-sounds/MoRA.

</details>


### [392] [Optimal Regularization for Performative Learning](https://arxiv.org/abs/2510.12249)
*Edwige Cyffers,Alireza Mirrokni,Marco Mondelli*

Main category: cs.LG

TL;DR: 在可塑性学习中，数据分布会根据部署的模型进行调整，这比传统的监督学习具有更复杂的动态性。本文研究了高维岭回归中的正则化如何应对可塑性效应，发现正则化可以抵消可塑性效应带来的负面影响，并且最优正则化强度与可塑性效应的强度相关。


<details>
  <summary>Details</summary>
Motivation: 在可塑性学习中，数据分布会因模型部署而发生变化（例如，用户的策略性适应），这比传统监督学习更复杂。因此，不仅要优化当前模型，还要考虑模型可能将分布推向新方向，但又不知道潜在变化的具体性质。

Method: 研究了正则化在高维岭回归中应对可塑性效应的影响。

Result: 可塑性效应在总体设置中会增加测试风险，但在特征数量超过样本数量的过参数化区域中可能是有益的。最优正则化强度与可塑性效应的整体强度相关，可以预先设定。

Conclusion: 正则化可以用来应对可塑性效应，最优正则化强度与可塑性效应的强度相关，这使得我们能够预先设定正则化参数以应对这种效应。通过在合成和真实世界数据集上的实证评估，说明了最优正则化参数的设定。

Abstract: In performative learning, the data distribution reacts to the deployed model
- for example, because strategic users adapt their features to game it - which
creates a more complex dynamic than in classical supervised learning. One
should thus not only optimize the model for the current data but also take into
account that the model might steer the distribution in a new direction, without
knowing the exact nature of the potential shift. We explore how regularization
can help cope with performative effects by studying its impact in
high-dimensional ridge regression. We show that, while performative effects
worsen the test risk in the population setting, they can be beneficial in the
over-parameterized regime where the number of features exceeds the number of
samples. We show that the optimal regularization scales with the overall
strength of the performative effect, making it possible to set the
regularization in anticipation of this effect. We illustrate this finding
through empirical evaluations of the optimal regularization parameter on both
synthetic and real-world datasets.

</details>


### [393] [Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development](https://arxiv.org/abs/2510.12253)
*Changfu Xu,Jianxiong Guo,Yuzhu Liang,Haiyang Huang,Haodong Zou,Xi Zheng,Shui Yu,Xiaowen Chu,Jiannong Cao,Tian Wang*

Main category: cs.LG

TL;DR: 该论文对扩散模型（DMs）在强化学习（RL）中的应用进行了全面的综述，重点介绍了DMs在解决RL中的多模态表达、稳定训练和轨迹层规划等方面的优势。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在现实世界中面临诸多挑战，如多模态表达、训练不稳定和轨迹规划等。扩散模型（DMs）因其独特的优势，为解决这些挑战提供了新的途径。

Method: 本文提出了一种双轴分类法，从功能和技术两个维度对扩散模型在RL中的应用进行分类。功能维度关注DMs在RL流程中的作用，技术维度则区分在线和离线学习。文章还探讨了从单智能体到多智能体以及实际应用中的集成框架。

Result: 论文梳理了DMs在RL中的应用进展，从单智能体到多智能体，并展示了其在不同领域的成功应用。同时，文章也指出了当前研究中存在的问题，并对未来研究方向进行了展望。

Conclusion: 扩散模型在强化学习领域具有巨大的潜力，未来在理论和应用层面都有广阔的发展空间。论文最后通过GitHub仓库提供了相关的资源和论文，以推动该领域的研究。

Abstract: Diffusion Models (DMs), as a leading class of generative models, offer key
advantages for reinforcement learning (RL), including multi-modal
expressiveness, stable training, and trajectory-level planning. This survey
delivers a comprehensive and up-to-date synthesis of diffusion-based RL. We
first provide an overview of RL, highlighting its challenges, and then
introduce the fundamental concepts of DMs, investigating how they are
integrated into RL frameworks to address key challenges in this research field.
We establish a dual-axis taxonomy that organizes the field along two orthogonal
dimensions: a function-oriented taxonomy that clarifies the roles DMs play
within the RL pipeline, and a technique-oriented taxonomy that situates
implementations across online versus offline learning regimes. We also provide
a comprehensive examination of this progression from single-agent to
multi-agent domains, thereby forming several frameworks for DM-RL integration
and highlighting their practical utility. Furthermore, we outline several
categories of successful applications of diffusion-based RL across diverse
domains, discuss open research issues of current methodologies, and highlight
key directions for future research to advance the field. Finally, we summarize
the survey to identify promising future development directions. We are actively
maintaining a GitHub repository (https://github.com/ChangfuXu/D4RL-FTD) for
papers and other related resources to apply DMs for RL.

</details>


### [394] [FedMMKT:Co-Enhancing a Server Text-to-Image Model and Client Task Models in Multi-Modal Federated Learning](https://arxiv.org/abs/2510.12254)
*Ningxin He,Yang Liu,Wei Sun,Xiaozhou Ye,Ye Ouyang,Tiegang Gao,Zehui Zhang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-Image (T2I) models have demonstrated their versatility in a wide
range of applications. However, adaptation of T2I models to specialized tasks
is often limited by the availability of task-specific data due to privacy
concerns. On the other hand, harnessing the power of rich multimodal data from
modern mobile systems and IoT infrastructures presents a great opportunity.
This paper introduces Federated Multi-modal Knowledge Transfer (FedMMKT), a
novel framework that enables co-enhancement of a server T2I model and client
task-specific models using decentralized multimodal data without compromising
data privacy.

</details>


### [395] [HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization](https://arxiv.org/abs/2510.12266)
*Ziyi Han,Huanyu Wang,Zeyu Zhang,Xiangxiang Dai,Xutong Liu,John C. S. Lui*

Main category: cs.LG

TL;DR: HiLoRA是一种无需训练的框架，通过在LoRA池上进行自适应分层路由，提高了模型在不同领域泛化能力，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在部署时需要额外的训练或显式任务标签，且固定激活整个LoRA模块会导致参数冗余或不足，影响性能。因此，需要一种更实用、更高效的LoRA适应方法。

Method: HiLoRA提出了一种名为 rank-one components (ROCs) 的概念，将LoRA的秩参数视为独立单元。对于给定的输入序列，HiLoRA首先根据高斯似然在序列级别自适应地选择LoRA子集及其ROC分配，然后在token级别通过仅激活信息量最大的ROCs来进一步优化路由。

Result: HiLoRA在领域泛化方面取得了显著的改进，准确率相比最先进的方法提高了55%，同时保持了可比的推理吞吐量。

Conclusion: HiLoRA通过自适应分层路由解决了现有LoRA方法在部署和性能方面的挑战，并在实验中证明了其有效性。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a widely used technique for
adapting large language models (LLMs) to new domains, due to its modular design
and broad availability on platforms such as HuggingFace. This availability has
motivated efforts to reuse existing LoRAs for domain generalization.
  However, existing methods often rely on explicit task labels or additional
training, which are impractical for deployment. Moreover, they typically
activate a fixed number of entire LoRA modules, leading to parameter redundancy
or insufficiency that degrade performance.
  In this paper, we propose \texttt{HiLoRA}, a training-free framework that
performs adaptive hierarchical routing over LoRA pools. Drawing on structural
properties of LoRA, we define rank-one components (ROCs), in which each rank
parameter is regarded as an independent unit. For a given input sequence,
\texttt{HiLoRA} first adaptively selects a subset of LoRAs and determines their
ROC allocation based on Gaussian likelihoods at the sequence level. At the
token level, it further refines routing by activating only the most informative
ROCs.
  We further provide theoretical guarantees that \texttt{HiLoRA} selects the
most relevant LoRAs with high probability.
  Extensive experiments show that \texttt{HiLoRA} achieves substantial
improvements in domain generalization, with accuracy gains of up to {\small
$55\%$} over state-of-the-art baselines, while maintaining comparable inference
throughput.

</details>


### [396] [Multi-Action Self-Improvement for Neural Combinatorial Optimization](https://arxiv.org/abs/2510.12273)
*Laurin Luttmann,Lin Xie*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的自适应学习方法，用于解决多智能体协同的组合优化问题，通过联合预测和利用对称性来提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有自适应学习方法在解决涉及多智能体协同的组合优化问题时存在局限性，包括训练成本高、无法利用问题结构（如智能体排列对称性）等，导致泛化能力受限和难以学习协同行为。

Method: 提出了一种新的自适应学习框架，该框架能够处理联合多智能体动作。模型架构在每个决策步骤联合预测完整的智能体-任务分配。为了利用对称性，采用了集合预测损失，对给定状态下的多个专家分配进行监督。

Result: 在多个组合优化问题上进行了实证验证，结果表明与标准的自适应学习方法相比，在最终解的质量和生成延迟方面均有显著提升。

Conclusion: 通过将自适应学习扩展到联合多智能体动作，并利用集合预测损失来处理对称性，可以提高组合优化问题的样本效率、学习协同行为的能力，并显著加快生成阶段的速度。

Abstract: Self-improvement has emerged as a state-of-the-art paradigm in Neural
Combinatorial Optimization (NCO), where models iteratively refine their
policies by generating and imitating high-quality solutions. Despite strong
empirical performance, existing methods face key limitations. Training is
computationally expensive, as policy updates require sampling numerous
candidate solutions per instance to extract a single expert trajectory. More
fundamentally, these approaches fail to exploit the structure of combinatorial
problems involving the coordination of multiple agents, such as vehicles in
min-max routing or machines in scheduling. By supervising on single-action
trajectories, they fail to exploit agent-permutation symmetries, where distinct
sequences of actions yield identical solutions, hindering generalization and
the ability to learn coordinated behavior.
  We address these challenges by extending self-improvement to operate over
joint multi-agent actions. Our model architecture predicts complete agent-task
assignments jointly at each decision step. To explicitly leverage symmetries,
we employ a set-prediction loss, which supervises the policy on multiple expert
assignments for any given state. This approach enhances sample efficiency and
the model's ability to learn coordinated behavior. Furthermore, by generating
multi-agent actions in parallel, it drastically accelerates the solution
generation phase of the self-improvement loop. Empirically, we validate our
method on several combinatorial problems, demonstrating consistent improvements
in the quality of the final solution and a reduced generation latency compared
to standard self-improvement.

</details>


### [397] [Deep SPI: Safe Policy Improvement via World Models](https://arxiv.org/abs/2510.12312)
*Florent Delgrange,Raphael Avalos,Willem Röpke*

Main category: cs.LG

TL;DR: 在一般在线强化学习环境中，我们提出了DeepSPI算法，它通过限制策略更新的范围来保证策略的单调改进和收敛性，并匹配或超越了现有的基线算法。


<details>
  <summary>Details</summary>
Motivation: 现有的安全策略改进（SPI）理论保证主要关注离线、表格型强化学习（RL），而本研究旨在将SPI扩展到更一般的在线强化学习环境，并结合世界模型和表示学习。

Method: 我们开发了一个理论框架，证明了将策略更新限制在当前策略的一个明确定义的邻域内可以确保单调改进和收敛性。该框架将转移和奖励预测损失与表示质量联系起来，从而在线上“深度”地模拟了经典离线RL中的SPI定理。在此基础上，我们提出了DeepSPI算法，它将局部转移和奖励损失与正则化策略更新相结合。

Result: DeepSPI算法在ALE-57基准测试中，性能与PPO和DeepMDPs等强大的基线算法相当或更好，同时保留了理论保证。

Conclusion: DeepSPI算法在一般在线强化学习设置下，通过结合表示学习和世界模型，实现了安全策略改进，并能在理论上保证单调改进和收敛性。

Abstract: Safe policy improvement (SPI) offers theoretical control over policy updates,
yet existing guarantees largely concern offline, tabular reinforcement learning
(RL). We study SPI in general online settings, when combined with world model
and representation learning. We develop a theoretical framework showing that
restricting policy updates to a well-defined neighborhood of the current policy
ensures monotonic improvement and convergence. This analysis links transition
and reward prediction losses to representation quality, yielding online, "deep"
analogues of classical SPI theorems from the offline RL literature. Building on
these results, we introduce DeepSPI, a principled on-policy algorithm that
couples local transition and reward losses with regularised policy updates. On
the ALE-57 benchmark, DeepSPI matches or exceeds strong baselines, including
PPO and DeepMDPs, while retaining theoretical guarantees.

</details>


### [398] [Leveraging Teleconnections with Physics-Informed Graph Attention Networks for Long-Range Extreme Rainfall Forecasting in Thailand](https://arxiv.org/abs/2510.12328)
*Kiattikun Chobtham,Kanoksri Sarinnapakorn,Kritanai Torsri,Prattana Deeprasertkul,Jirawan Kamma*

Main category: cs.LG

TL;DR: 本研究提出一种结合物理信息图神经网络（GNN）和极值分析技术的方法，用于改进泰国地区雨量站的降雨预测，特别是在极端事件方面。


<details>
  <summary>Details</summary>
Motivation: 准确的降雨预测，尤其是极端事件的预测，在气候学和地球系统中仍然是一个重大挑战。

Method: 利用图结构的雨量站表示来捕捉时空模式，结合了长短期记忆（LSTM）和注意力机制（Attention-LSTM），并使用空间季节感知广义帕累托分布（GPD）方法处理极端值。

Result: 该方法在泰国地区的大部分区域，包括易发生极端事件的地区，优于基线方法，并与最先进的方法具有竞争力。

Conclusion: 该方法在真实世界应用中提高了极端事件的预测能力，并为长期水资源管理决策提供了实用的改进，能够生成支持决策的精细分辨率地图。

Abstract: Accurate rainfall forecasting, particularly for extreme events, remains a
significant challenge in climatology and the Earth system. This paper presents
novel physics-informed Graph Neural Networks (GNNs) combined with extreme-value
analysis techniques to improve gauge-station rainfall predictions across
Thailand. The model leverages a graph-structured representation of gauge
stations to capture complex spatiotemporal patterns, and it offers
explainability through teleconnections. We preprocess relevant climate indices
that potentially influence regional rainfall. The proposed Graph Attention
Network with Long Short-Term Memory (Attention-LSTM) applies the attention
mechanism using initial edge features derived from simple
orographic-precipitation physics formulation. The embeddings are subsequently
processed by LSTM layers. To address extremes, we perform Peak-Over-Threshold
(POT) mapping using the novel Spatial Season-aware Generalized Pareto
Distribution (GPD) method, which overcomes limitations of traditional
machine-learning models. Experiments demonstrate that our method outperforms
well-established baselines across most regions, including areas prone to
extremes, and remains strongly competitive with the state of the art. Compared
with the operational forecasting system SEAS5, our real-world application
improves extreme-event prediction and offers a practical enhancement to produce
fine-resolution maps that support decision-making in long-term water
management.

</details>


### [399] [Finite-time Convergence Analysis of Actor-Critic with Evolving Reward](https://arxiv.org/abs/2510.12334)
*Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

TL;DR: 该论文首次分析了在奖励函数演化的情况下，单时间尺度 Actor-Critic 算法的有限时间收敛性。


<details>
  <summary>Details</summary>
Motivation: 许多流行的强化学习（RL）算法使用不断演化的奖励函数（通过奖励塑形、熵正则化或课程学习等技术），但其理论基础仍不完善。

Method: 在马尔可夫采样下，考虑了奖励参数在每个时间步都可能发生变化，并影响策略优化和价值估计的情况。推导了 actor 和 critic 误差的非渐近界限。

Result: 在奖励参数演化足够慢的情况下，可以实现 $O(1/\sqrt{T})$ 的收敛速率，与静态奖励下的最优速率相匹配。当奖励通过基于梯度的规则更新，且梯度有界，与 actor 和 critic 处于同一时间尺度时，该速率得以保持。

Conclusion: 该论文为许多流行的 RL 技术提供了理论基础，并通过引入新颖的分布失配分析，在静态奖励情况下将最佳速率提高了 $\log^2T$ 倍。

Abstract: Many popular practical reinforcement learning (RL) algorithms employ evolving
reward functions-through techniques such as reward shaping, entropy
regularization, or curriculum learning-yet their theoretical foundations remain
underdeveloped. This paper provides the first finite-time convergence analysis
of a single-timescale actor-critic algorithm in the presence of an evolving
reward function under Markovian sampling. We consider a setting where the
reward parameters may change at each time step, affecting both policy
optimization and value estimation. Under standard assumptions, we derive
non-asymptotic bounds for both actor and critic errors. Our result shows that
an $O(1/\sqrt{T})$ convergence rate is achievable, matching the best-known rate
for static rewards, provided the reward parameters evolve slowly enough. This
rate is preserved when the reward is updated via a gradient-based rule with
bounded gradient and on the same timescale as the actor and critic, offering a
theoretical foundation for many popular RL techniques. As a secondary
contribution, we introduce a novel analysis of distribution mismatch under
Markovian sampling, improving the best-known rate by a factor of $\log^2T$ in
the static-reward case.

</details>


### [400] [Traveling Salesman-Based Token Ordering Improves Stability in Homomorphically Encrypted Language Models](https://arxiv.org/abs/2510.12343)
*Donghwan Rho,Sieun Seo,Hyewon Sung,Chohong Min,Ernest K. Ryu*

Main category: cs.LG

TL;DR: 我们提出了一种基于TSP的令牌重排序策略，以解决加密文本生成的困难，并辅以一个后处理步骤来减少近似误差，从而在不泄露数据隐私的情况下实现可行的LLM推理。


<details>
  <summary>Details</summary>
Motivation: 随着用户越来越多地使用私有信息与大型语言模型（LLM）进行交互，安全和加密的通信变得至关重要。同态加密（HE）提供了一种原则性的解决方案，可以直接在加密数据上进行计算。尽管以往的研究探索了在HE下运行LLM的各个方面，但文本生成，特别是下一个令牌预测的挑战，受到的关注有限，并且仍然是实际加密交互的关键障碍。

Method: 提出了一种基于TSP的令牌重排序策略来解决加密文本生成中的困难，并结合了一个后处理步骤来进一步减少近似误差。

Result: 理论分析和实验结果表明，我们的方法可以防止（生成内容的）崩溃，提高生成文本的连贯性，并在整个过程中保护数据隐私。

Conclusion: 我们的贡献整体上提高了实用且注重隐私的LLM推理的可行性。

Abstract: As users increasingly interact with large language models (LLMs) using
private information, secure and encrypted communication becomes essential.
Homomorphic encryption (HE) provides a principled solution by enabling
computation directly on encrypted data. Although prior work has explored
aspects of running LLMs under HE, the challenge of text generation,
particularly next-token prediction, has received limited attention and remains
a key obstacle to practical encrypted interaction. In this work, we propose a
TSP-based token reordering strategy to address the difficulties of encrypted
text generation, together with a post-processing step that further reduces
approximation error. Theoretical analysis and experimental results demonstrate
that our method prevents collapse, improves coherence in generated text, and
preserves data privacy throughout. Overall, our contributions advance the
feasibility of practical and privacy-preserving LLM inference.

</details>


### [401] [Towards Cross-Modal Error Detection with Tables and Images](https://arxiv.org/abs/2510.12383)
*Olga Ovcharenko,Sebastian Schelter*

Main category: cs.LG

TL;DR: 传统数据质量保证方法在处理多模态数据时存在不足，尤其是在跨模态错误检测方面。本文对现有方法进行了基准测试，发现Cleanlab和DataScope结合AutoML表现最佳，但仍有局限性，需要进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据质量保证方法主要关注单一数据模态，无法有效检测跨模态错误，而这类错误在电商、医疗等领域普遍存在。

Method: 评估了四种数据集和五种基线方法，重点关注了Cleanlab和DataScope结合AutoML在跨模态错误检测上的表现。

Result: Cleanlab和DataScope结合AutoML在F1分数上表现最佳，但现有方法在处理现实世界中数据分布不均（heavy-tailed）的数据时仍显不足。

Conclusion: 尽管Cleanlab和DataScope结合AutoML在跨模态错误检测方面取得了一定进展，但其有效性仍然有限，尤其是在处理现实世界数据时。因此，该领域需要进一步的研究和改进。

Abstract: Ensuring data quality at scale remains a persistent challenge for large
organizations. Despite recent advances, maintaining accurate and consistent
data is still complex, especially when dealing with multiple data modalities.
Traditional error detection and correction methods tend to focus on a single
modality, typically a table, and often miss cross-modal errors that are common
in domains like e-Commerce and healthcare, where image, tabular, and text data
co-exist. To address this gap, we take an initial step towards cross-modal
error detection in tabular data, by benchmarking several methods. Our
evaluation spans four datasets and five baseline approaches. Among them,
Cleanlab, a label error detection framework, and DataScope, a data valuation
method, perform the best when paired with a strong AutoML framework, achieving
the highest F1 scores. Our findings indicate that current methods remain
limited, particularly when applied to heavy-tailed real-world data, motivating
further research in this area.

</details>


### [402] [Enhanced Pre-training of Graph Neural Networks for Million-Scale Heterogeneous Graphs](https://arxiv.org/abs/2510.12401)
*Shengyin Sun,Chen Ma,Jiehao Chen*

Main category: cs.LG

TL;DR: GNNs在图数据挖掘中发挥着重要作用，但训练它们需要大量标注数据。现有的自监督预训练方法大多只适用于同质图，未能解决异质图中存在的语义不匹配问题。本文提出了一种有效的框架来预训练GNN，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN预训练方法在处理异质图和语义不匹配问题方面存在不足，需要新的方法来提高GNN在下游任务中的泛化能力。

Method: 提出了一种结合结构感知和语义感知预训练任务的框架。结构感知任务旨在捕捉异质图的结构属性，而语义感知任务通过构建扰动子空间和利用语义邻居来解决语义不匹配问题，从而学习更具迁移性的知识。

Result: 在真实世界的大规模异质图上进行的广泛实验表明，该方法优于最先进的基线方法。

Conclusion: 提出的框架能够有效地预训练GNN，解决异质图和语义不匹配问题，从而在下游任务中取得更好的性能。

Abstract: In recent years, graph neural networks (GNNs) have facilitated the
development of graph data mining. However, training GNNs requires sufficient
labeled task-specific data, which is expensive and sometimes unavailable. To be
less dependent on labeled data, recent studies propose to pre-train GNNs in a
self-supervised manner and then apply the pre-trained GNNs to downstream tasks
with limited labeled data. However, most existing methods are designed solely
for homogeneous graphs (real-world graphs are mostly heterogeneous) and do not
consider semantic mismatch (the semantic difference between the original data
and the ideal data containing more transferable semantic information). In this
paper, we propose an effective framework to pre-train GNNs on the large-scale
heterogeneous graph. We first design a structure-aware pre-training task, which
aims to capture structural properties in heterogeneous graphs. Then, we design
a semantic-aware pre-training task to tackle the mismatch. Specifically, we
construct a perturbation subspace composed of semantic neighbors to help deal
with the semantic mismatch. Semantic neighbors make the model focus more on the
general knowledge in the semantic space, which in turn assists the model in
learning knowledge with better transferability. Finally, extensive experiments
are conducted on real-world large-scale heterogeneous graphs to demonstrate the
superiority of the proposed method over state-of-the-art baselines. Code
available at https://github.com/sunshy-1/PHE.

</details>


### [403] [Cautious Weight Decay](https://arxiv.org/abs/2510.12402)
*Lizhang Chen,Jonathan Li,Kaizhao Liang,Baiyu Su,Cong Xie,Nuo Wang Pierse,Chen Liang,Ni Lao,Qiang Liu*

Main category: cs.LG

TL;DR: CWD 是一种简单且通用的方法，可以提高模型的性能，因为它只对与优化器更新方向一致的参数进行权重衰减。


<details>
  <summary>Details</summary>
Motivation: 标准的权重衰减方法在优化过程中会改变原始损失函数，而 CWD 旨在保留原始损失函数，并通过引入一种新的优化方式来寻找局部帕累托最优的平稳点。

Method: CWD 是一种即插即用型修改，可以直接应用于 AdamW、Lion 和 Muon 等优化器，无需调整超参数。它通过仅对参数坐标的符号与优化器更新方向一致时应用权重衰减来实现。

Result: 在语言模型预训练和 ImageNet 分类任务中，CWD 在百万到十亿参数规模的模型上，均能稳定地提高最终的损失和准确率。

Conclusion: CWD 是一种简单而有效的优化器修改方法，能够提升模型在各种任务和规模上的性能，同时保留原始损失函数。

Abstract: We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic
modification that applies weight decay only to parameter coordinates whose
signs align with the optimizer update. Unlike standard decoupled decay, which
implicitly optimizes a regularized or constrained objective, CWD preserves the
original loss and admits a bilevel interpretation: it induces sliding-mode
behavior upon reaching the stationary manifold, allowing it to search for
locally Pareto-optimal stationary points of the unmodified objective. In
practice, CWD is a drop-in change for optimizers such as AdamW, Lion, and Muon,
requiring no new hyperparameters or additional tuning. For language model
pre-training and ImageNet classification, CWD consistently improves final loss
and accuracy at million- to billion-parameter scales.

</details>


### [404] [Bayesian Optimization for Dynamic Pricing and Learning](https://arxiv.org/abs/2510.12447)
*Anush Anand,Pranav Agrawal,Tejas Bodas*

Main category: cs.LG

TL;DR: 本文提出一种基于高斯过程的非参数动态定价方法，通过贝叶斯优化克服了传统方法对需求函数形式的限制，并在无限和有限库存设置下均取得了优于现有强化学习算法的收入和学习效率。


<details>
  <summary>Details</summary>
Motivation: 传统动态定价方法通常假设需求函数具有特定的参数形式，这在实际应用中可能不成立，限制了其适用性。因此，需要一种更灵活、适应性更强的方法。

Method: 本文提出一种基于高斯过程（GP）的非参数动态定价方法，将需求函数视为关于价格的黑盒函数，并采用贝叶斯优化（BO）算法进行定价。该方法适用于无限和有限库存两种场景，并提供了遗憾界限。

Result: 通过大量实验证明，本文提出的基于BO的动态定价方法在收入方面优于几种最先进的强化学习算法，并且需要的假设更少，鲁棒性更强。

Conclusion: 贝叶斯优化是一种强大且实用的动态定价工具，特别适用于复杂且不确定的环境，能够有效解决传统方法在需求函数建模方面的局限性。

Abstract: Dynamic pricing is the practice of adjusting the selling price of a product
to maximize a firm's revenue by responding to market demand. The literature
typically distinguishes between two settings: infinite inventory, where the
firm has unlimited stock and time to sell, and finite inventory, where both
inventory and selling horizon are limited. In both cases, the central challenge
lies in the fact that the demand function -- how sales respond to price -- is
unknown and must be learned from data. Traditional approaches often assume a
specific parametric form for the demand function, enabling the use of
reinforcement learning (RL) to identify near-optimal pricing strategies.
However, such assumptions may not hold in real-world scenarios, limiting the
applicability of these methods. In this work, we propose a Gaussian Process
(GP) based nonparametric approach to dynamic pricing that avoids restrictive
modeling assumptions. We treat the demand function as a black-box function of
the price and develop pricing algorithms based on Bayesian Optimization (BO) --
a sample-efficient method for optimizing unknown functions. We present BO-based
algorithms tailored for both infinite and finite inventory settings and provide
regret guarantees for both regimes, thereby quantifying the learning efficiency
of our methods. Through extensive experiments, we demonstrate that our BO-based
methods outperform several state-of-the-art RL algorithms in terms of revenue,
while requiring fewer assumptions and offering greater robustness. This
highlights Bayesian Optimization as a powerful and practical tool for dynamic
pricing in complex, uncertain environments.

</details>


### [405] [A Function Centric Perspective On Flat and Sharp Minima](https://arxiv.org/abs/2510.12451)
*Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis*

Main category: cs.LG

TL;DR: 平坦极小值与深度神经网络的泛化能力之间的关系比之前认为的更为复杂。该研究提出，应将尖锐度视为一个与函数相关的属性，而不是泛化能力差的可靠指标。研究发现，在正则化（如SAM、权重衰减、数据增强）下，模型常收敛到更尖锐的极小值，但这些极小值往往能带来更好的泛化、校准、鲁棒性和功能一致性。与此相反，未经正则化的基线模型虽然收敛到更平坦的极小值，但在各项安全指标上的表现往往更差。研究强调，函数复杂度而不是平坦度本身决定了损失景观的几何形状，并且更尖锐的极小值可能反映了更合适的归纳偏置，尤其是在有正则化的情况下，这呼吁以函数为中心重新审视损失景观的几何。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在重新审视尖锐度在模型性能中的作用，并提出一种新的理解方式，即将其视为一个与函数相关的属性，而不是泛化能力差的可靠指标。

Method: 通过广泛的实证研究，从单一目标优化到现代图像分类任务，探究了模型正则化（如SAM、权重衰减、数据增强）与极小值几何形状（平坦度/尖锐度）以及模型性能（泛化、校准、鲁棒性、功能一致性）之间的关系。

Result: 研究发现，在正则化下，模型倾向于收敛到更尖锐的极小值，但这些极小值却能带来更好的泛化、校准、鲁棒性和功能一致性。未经正则化的模型虽然收敛到更平坦的极小值，但各项安全指标的表现反而更差。

Conclusion: 该研究得出结论，函数复杂度是决定解的几何形状的关键因素，而非仅仅是平坦度。更尖锐的极小值可能表明存在更合适的归纳偏置（尤其是在正则化条件下），这表明需要以函数为中心重新评估损失景观的几何特性。

Abstract: Flat minima are widely believed to correlate with improved generalisation in
deep neural networks. However, this connection has proven more nuanced in
recent studies, with both theoretical counterexamples and empirical exceptions
emerging in the literature. In this paper, we revisit the role of sharpness in
model performance, proposing that sharpness is better understood as a
function-dependent property rather than a reliable indicator of poor
generalisation. We conduct extensive empirical studies, from single-objective
optimisation to modern image classification tasks, showing that sharper minima
often emerge when models are regularised (e.g., via SAM, weight decay, or data
augmentation), and that these sharp minima can coincide with better
generalisation, calibration, robustness, and functional consistency. Across a
range of models and datasets, we find that baselines without regularisation
tend to converge to flatter minima yet often perform worse across all safety
metrics. Our findings demonstrate that function complexity, rather than
flatness alone, governs the geometry of solutions, and that sharper minima can
reflect more appropriate inductive biases (especially under regularisation),
calling for a function-centric reappraisal of loss landscape geometry.

</details>


### [406] [Time-Correlated Video Bridge Matching](https://arxiv.org/abs/2510.12453)
*Viacheslav Vasilev,Arseny Ivanov,Nikita Gushchin,Maria Kovaleva,Alexander Korotin*

Main category: cs.LG

TL;DR: 扩散模型擅长从噪声生成数据，但在数据到数据的任务中存在局限性。本研究提出了时间相关视频桥匹配（TCVBM）框架，将桥匹配模型扩展到视频领域，以解决时间相关数据序列的建模问题。TCVBM通过在扩散桥中明确建模序列间的依赖关系，将时间相关性纳入采样过程，并在帧插值、图像到视频生成和视频超分辨率任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在处理数据到数据的任务，特别是时间相关数据序列（如视频）时存在局限性。桥匹配模型虽然能解决数据分布间的转换问题，但尚未应用于时间相关数据。这阻碍了视频生成和处理任务的进一步发展，因为保持时间连贯性至关重要。

Method: 提出时间相关视频桥匹配（TCVBM）框架，该框架将桥匹配模型扩展到视频领域，用于处理时间相关的数据序列。TCVBM在扩散桥中明确地对序列间的依赖关系进行建模，将时间相关性直接整合到采样过程中。

Result: 在帧插值、图像到视频生成和视频超分辨率三个与视频相关的任务中，TCVBM 与基于桥匹配和扩散模型的经典方法进行了比较。TCVBM 在多个定量指标上均取得了优越的性能，证明了其在生成质量和重建保真度方面的提升。

Conclusion: TCVBM 成功地将桥匹配模型扩展到了时间相关的数据序列（视频）领域，通过在扩散桥中整合时间相关性，有效解决了现有模型在数据到数据生成任务中的不足，并在视频相关的下游任务中取得了显著的性能提升。

Abstract: Diffusion models excel in noise-to-data generation tasks, providing a mapping
from a Gaussian distribution to a more complex data distribution. However they
struggle to model translations between complex distributions, limiting their
effectiveness in data-to-data tasks. While Bridge Matching (BM) models address
this by finding the translation between data distributions, their application
to time-correlated data sequences remains unexplored. This is a critical
limitation for video generation and manipulation tasks, where maintaining
temporal coherence is particularly important. To address this gap, we propose
Time-Correlated Video Bridge Matching (TCVBM), a framework that extends BM to
time-correlated data sequences in the video domain. TCVBM explicitly models
inter-sequence dependencies within the diffusion bridge, directly incorporating
temporal correlations into the sampling process. We compare our approach to
classical methods based on bridge matching and diffusion models for three
video-related tasks: frame interpolation, image-to-video generation, and video
super-resolution. TCVBM achieves superior performance across multiple
quantitative metrics, demonstrating enhanced generation quality and
reconstruction fidelity.

</details>


### [407] [CrossAD: Time Series Anomaly Detection with Cross-scale Associations and Cross-window Modeling](https://arxiv.org/abs/2510.12489)
*Beibu Li,Qichao Shentu,Yang Shu,Hui Zhang,Ming Li,Ning Jin,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CrossAD通过跨尺度重建和跨窗口建模来检测时间序列异常。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在处理多尺度信息时存在不足，忽视了跨尺度关联的动态变化，并且固定窗口限制了上下文信息的捕获。

Method: 提出CrossAD框架，通过跨尺度重建（细粒度序列从粗粒度序列重建）来显式捕捉跨尺度关联，并设计查询库和引入全局多尺度上下文来克服固定窗口的限制。

Result: 在多个真实世界数据集上进行了广泛的实验，并使用九个评估指标验证了CrossAD的有效性。

Conclusion: CrossAD在时间序列异常检测方面取得了最先进的性能。

Abstract: Time series anomaly detection plays a crucial role in a wide range of
real-world applications. Given that time series data can exhibit different
patterns at different sampling granularities, multi-scale modeling has proven
beneficial for uncovering latent anomaly patterns that may not be apparent at a
single scale. However, existing methods often model multi-scale information
independently or rely on simple feature fusion strategies, neglecting the
dynamic changes in cross-scale associations that occur during anomalies.
Moreover, most approaches perform multi-scale modeling based on fixed sliding
windows, which limits their ability to capture comprehensive contextual
information. In this work, we propose CrossAD, a novel framework for time
series Anomaly Detection that takes Cross-scale associations and Cross-window
modeling into account. We propose a cross-scale reconstruction that
reconstructs fine-grained series from coarser series, explicitly capturing
cross-scale associations. Furthermore, we design a query library and
incorporate global multi-scale context to overcome the limitations imposed by
fixed window sizes. Extensive experiments conducted on multiple real-world
datasets using nine evaluation metrics validate the effectiveness of CrossAD,
demonstrating state-of-the-art performance in anomaly detection.

</details>


### [408] [Mitigating the Noise Shift for Denoising Generative Models via Noise Awareness Guidance](https://arxiv.org/abs/2510.12497)
*Jincheng Zhong,Boyuan Jiang,Xin Tao,Pengfei Wan,Kun Gai,Mingsheng Long*

Main category: cs.LG

TL;DR: 现有的去噪生成模型依赖于求解离散化的反向随机微分方程（SDE）或常微分方程（ODE）。本文发现了一个长期被忽视但普遍存在的问题：预定义噪声水平与采样过程中实际编码在中间状态的噪声水平不一致，称为噪声偏移。该问题会导致生成质量不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的去噪生成模型在求解离散化SDEs或ODEs时，存在预定义噪声水平与中间状态实际编码的噪声水平不一致的问题，即噪声偏移，导致生成质量不佳。

Method: 提出噪声感知引导（NAG）方法，显式地引导采样轨迹与预定义的噪声调度保持一致。提出NAG的无分类器版本，通过噪声条件丢弃联合训练噪声条件和无条件模型。

Result: 在ImageNet生成和各种有监督微调任务的广泛实验表明，NAG能够持续缓解噪声偏移，并显著提高主流扩散模型的生成质量。

Conclusion: 噪声偏移是现有去噪生成模型中的一个普遍问题，通过提出的NAG方法可以有效缓解该问题，并提升生成质量。

Abstract: Existing denoising generative models rely on solving discretized reverse-time
SDEs or ODEs. In this paper, we identify a long-overlooked yet pervasive issue
in this family of models: a misalignment between the pre-defined noise level
and the actual noise level encoded in intermediate states during sampling. We
refer to this misalignment as noise shift. Through empirical analysis, we
demonstrate that noise shift is widespread in modern diffusion models and
exhibits a systematic bias, leading to sub-optimal generation due to both
out-of-distribution generalization and inaccurate denoising updates. To address
this problem, we propose Noise Awareness Guidance (NAG), a simple yet effective
correction method that explicitly steers sampling trajectories to remain
consistent with the pre-defined noise schedule. We further introduce a
classifier-free variant of NAG, which jointly trains a noise-conditional and a
noise-unconditional model via noise-condition dropout, thereby eliminating the
need for external classifiers. Extensive experiments, including ImageNet
generation and various supervised fine-tuning tasks, show that NAG consistently
mitigates noise shift and substantially improves the generation quality of
mainstream diffusion models.

</details>


### [409] [The Robustness of Differentiable Causal Discovery in Misspecified Scenarios](https://arxiv.org/abs/2510.12503)
*Huiyang Yi,Yanyan He,Duxin Chen,Mingyu Kang,He Wang,Wenwu Yu*

Main category: cs.LG

TL;DR: 本研究对几种主流因果发现算法在八种模型假设违反情况下的经验性能进行了广泛的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据通常难以满足因果发现算法所依赖的因果假设，这限制了其在实际中的应用。因此，有必要评估这些算法在模型假设违反情况下的鲁棒性。

Method: 通过在八种模型假设违反情况下，对几种主流的、假设数据独立同分布（i.i.d.）的因果发现算法进行广泛的经验性能基准测试，并对可微分因果发现方法的性能进行理论解释。

Result: 可微分因果发现方法在结构汉明距离和结构干预距离等指标上，在常用的具有挑战性的场景中表现出鲁棒性，但在尺度变化方面表现不佳。

Conclusion: 可微分因果发现方法在模型假设违反的情况下表现出一定的鲁棒性，但并非在所有情况下都如此。未来的研究应继续关注这些方法的改进，并为因果发现的评估提供标准，以促进其在现实世界中的应用。

Abstract: Causal discovery aims to learn causal relationships between variables from
targeted data, making it a fundamental task in machine learning. However,
causal discovery algorithms often rely on unverifiable causal assumptions,
which are usually difficult to satisfy in real-world data, thereby limiting the
broad application of causal discovery in practical scenarios. Inspired by these
considerations, this work extensively benchmarks the empirical performance of
various mainstream causal discovery algorithms, which assume i.i.d. data, under
eight model assumption violations. Our experimental results show that
differentiable causal discovery methods exhibit robustness under the metrics of
Structural Hamming Distance and Structural Intervention Distance of the
inferred graphs in commonly used challenging scenarios, except for scale
variation. We also provide the theoretical explanations for the performance of
differentiable causal discovery methods. Finally, our work aims to
comprehensively benchmark the performance of recent differentiable causal
discovery methods under model assumption violations, and provide the standard
for reasonable evaluation of causal discovery, as well as to further promote
its application in real-world scenarios.

</details>


### [410] [Multi-Armed Bandits with Minimum Aggregated Revenue Constraints](https://arxiv.org/abs/2510.12523)
*Ahmed Ben Yahmed,Hafedh El Ferchichi,Marc Abeille,Vianney Perchet*

Main category: cs.LG

TL;DR: 该研究探讨了一种包含上下文信息的上下文多臂老虎机问题，目标是在最大化累积总奖励的同时，确保每个臂在不同上下文中都能获得最低的总奖励。


<details>
  <summary>Details</summary>
Motivation: 该框架旨在解决现实世界中公平的收入分配和上下文变化并存的应用场景。

Method: 提出并分析了两种算法：一种乐观地优先考虑性能，另一种悲观地强制执行约束。推导了每种算法的后悔和约束违反的上界。

Result: 证明了所提出算法的性能界限，并与现有方法进行了比较。

Conclusion: 推导出的下界表明，结果在时间尺度上的依赖性是最佳的，并揭示了先前工作中“自由探索”原理的基本局限性。

Abstract: We examine a multi-armed bandit problem with contextual information, where
the objective is to ensure that each arm receives a minimum aggregated reward
across contexts while simultaneously maximizing the total cumulative reward.
This framework captures a broad class of real-world applications where fair
revenue allocation is critical and contextual variation is inherent. The
cross-context aggregation of minimum reward constraints, while enabling better
performance and easier feasibility, introduces significant technical challenges
-- particularly the absence of closed-form optimal allocations typically
available in standard MAB settings. We design and analyze algorithms that
either optimistically prioritize performance or pessimistically enforce
constraint satisfaction. For each algorithm, we derive problem-dependent upper
bounds on both regret and constraint violations. Furthermore, we establish a
lower bound demonstrating that the dependence on the time horizon in our
results is optimal in general and revealing fundamental limitations of the free
exploration principle leveraged in prior work.

</details>


### [411] [Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis](https://arxiv.org/abs/2510.12541)
*Jasmin Freudenberg,Kai Hahn,Christian Weber,Madjid Fathi*

Main category: cs.LG

TL;DR: FACE项目旨在通过结合边缘和云计算的优势，开发创新的机器学习解决方案来分析长期心电图。


<details>
  <summary>Details</summary>
Motivation: 随着便携式心电图系统日益普及，以及对隐私合规、能源高效的实时分析的需求不断增长，需要在数据采集点进行新的信号处理方法。因此，边缘计算领域变得越来越重要，因为它可以减少延迟并提高数据安全性。

Method: 本论文分析了各种心电图信号预处理步骤在FACE项目中的适用性，并特别根据能源效率、处理能力和实时能力等标准，在边缘领域选择了合适的方法。

Result: （摘要中未明确说明具体结果）

Conclusion: （摘要中未明确说明具体结论）

Abstract: The increasing popularity of portable ECG systems and the growing demand for
privacy-compliant, energy-efficient real-time analysis require new approaches
to signal processing at the point of data acquisition. In this context, the
edge domain is acquiring increasing importance, as it not only reduces latency
times, but also enables an increased level of data security. The FACE project
aims to develop an innovative machine learning solution for analysing long-term
electrocardiograms that synergistically combines the strengths of edge and
cloud computing. In this thesis, various pre-processing steps of ECG signals
are analysed with regard to their applicability in the project. The selection
of suitable methods in the edge area is based in particular on criteria such as
energy efficiency, processing capability and real-time capability.

</details>


### [412] [Research in Collaborative Learning Does Not Serve Cross-Silo Federated Learning in Practice](https://arxiv.org/abs/2510.12595)
*Kevin Kuo,Chhavi Yadav,Virginia Smith*

Main category: cs.LG

TL;DR: 跨机构联邦学习（FL）在保护隐私的前提下促进了机器学习模型的跨组织协作，但实际应用受阻。本研究通过访谈不同利益相关者，揭示了模型性能、激励和信任等方面的挑战，这些挑战不同于现有的跨设备FL研究，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管数据保护法规（如GDPR和HIPAA）推动了跨机构联邦学习（FL）的应用，但其实际采用仍然有限。本研究旨在通过访谈了解跨机构FL采用所面临的实际挑战。

Method: 通过访谈不同利益相关者（用户组织、软件供应商、学术研究人员）来理解跨机构FL采用所面临的实际挑战。

Result: 研究揭示了模型性能、激励和信任等方面存在的多种障碍，这些障碍尚未被现有研究充分捕捉，并且与跨设备FL等其他形式的FL有显著区别。

Conclusion: 跨机构FL面临着独特的挑战，现有研究需要进一步探索和解决这些问题，以克服实际应用中的障碍。

Abstract: Cross-silo federated learning (FL) is a promising approach to enable
cross-organization collaboration in machine learning model development without
directly sharing private data. Despite growing organizational interest driven
by data protection regulations such as GDPR and HIPAA, the adoption of
cross-silo FL remains limited in practice. In this paper, we conduct an
interview study to understand the practical challenges associated with
cross-silo FL adoption. With interviews spanning a diverse set of stakeholders
such as user organizations, software providers, and academic researchers, we
uncover various barriers, from concerns about model performance to questions of
incentives and trust between participating organizations. Our study shows that
cross-silo FL faces a set of challenges that have yet to be well-captured by
existing research in the area and are quite distinct from other forms of
federated learning such as cross-device FL. We end with a discussion on future
research directions that can help overcome these challenges.

</details>


### [413] [Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff](https://arxiv.org/abs/2510.12615)
*Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis*

Main category: cs.LG

TL;DR: 知识蒸馏在功能上主要作为一种数据依赖的正则化器，而非压缩机制，且可能存在负知识的不对称转移。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏的实际功能影响（尤其是在功能层面）尚不明确，尽管它常被视为一种压缩技术。本研究旨在从功能角度量化知识蒸馏的压缩能力和知识转移，并将其与架构缩减分离开来。

Method: 研究采用了假设检验、对照实验和随机对照蒸馏等方法，跨越多种数据模态来理解知识转移机制。此外，还探索了多种蒸馏变体并分析了模型大小对蒸馏缩放定律的影响，以全面评估其有效性。

Result: 尽管在某些模态和架构下存在统计上显著的知识转移，但其程度低于预期。尤其值得注意的是，在知识转移显著的情况下，观察到负知识向学生模型的转移具有明显的不对称性，这引发了对知识蒸馏应用安全性的担忧。

Conclusion: 知识蒸馏并非严格意义上的压缩机制，其作用更像是一种数据依赖的正则化器，并且可能带来负面且不对称的知识转移。

Abstract: Knowledge distillation is often considered a compression mechanism when
judged on the resulting student's accuracy and loss, yet its functional impact
is poorly understood. In this work, we quantify the compression capacity of
knowledge distillation and the resulting knowledge transfer from a functional
perspective, decoupling compression from architectural reduction, which
provides an improved understanding of knowledge distillation. We employ
hypothesis testing, controls, and random control distillation to understand
knowledge transfer mechanisms across data modalities. To rigorously test the
breadth and limits of our analyses, we explore multiple distillation variants
and analyse distillation scaling laws across model sizes. Our findings
demonstrate that, while there is statistically significant knowledge transfer
in some modalities and architectures, the extent of this transfer is less
pronounced than anticipated, even under conditions designed to maximise
knowledge sharing. Notably, in cases of significant knowledge transfer, we
identify a consistent and severe asymmetric transfer of negative knowledge to
the student, raising safety concerns in knowledge distillation applications.
Across 12 experimental setups, 9 architectures, and 7 datasets, our findings
show that knowledge distillation functions less as a compression mechanism and
more as a data-dependent regulariser with a negative asymmetric payoff.

</details>


### [414] [Towards Fast Coarse-graining and Equation Discovery with Foundation Inference Models](https://arxiv.org/abs/2510.12618)
*Manuel Hinz,Maximilian Mauel,Patrick Seifner,David Berghaus,Kostadin Cvejoski,Ramses J. Sanchez*

Main category: cs.LG

TL;DR: 高维动力学系统可通过少数有效变量在低维流形上演化，本研究提出一种解耦变量发现与方程拟合的方法，利用预训练的FIM模型进行动力学推断，仅训练编码器-解码器映射，以实现快速可复用的粗粒化。


<details>
  <summary>Details</summary>
Motivation: 识别潜藏动力学，解决变量发现与方程拟合的耦合问题。

Method: 利用预训练的FIM模型（Foundation Inference Models）估计动力学系统的无穷小生成元（例如，随机微分方程的漂移和扩散），通过冻结FIM模型的权重，仅训练编码器-解码器映射，并定义一个简单的、与模拟一致的损失函数，以稳定表示学习。

Result: 在具有半圆扩散的随机双势系统（嵌入合成视频数据）上进行了概念验证。

Conclusion: 所提出的方法能够实现快速和可复用的粗粒化流程。

Abstract: High-dimensional recordings of dynamical processes are often characterized by
a much smaller set of effective variables, evolving on low-dimensional
manifolds. Identifying these latent dynamics requires solving two intertwined
problems: discovering appropriate coarse-grained variables and simultaneously
fitting the governing equations. Most machine learning approaches tackle these
tasks jointly by training autoencoders together with models that enforce
dynamical consistency. We propose to decouple the two problems by leveraging
the recently introduced Foundation Inference Models (FIMs). FIMs are pretrained
models that estimate the infinitesimal generators of dynamical systems (e.g.,
the drift and diffusion of a stochastic differential equation) in zero-shot
mode. By amortizing the inference of the dynamics through a FIM with frozen
weights, and training only the encoder-decoder map, we define a simple,
simulation-consistent loss that stabilizes representation learning. A proof of
concept on a stochastic double-well system with semicircle diffusion, embedded
into synthetic video data, illustrates the potential of this approach for fast
and reusable coarse-graining pipelines.

</details>


### [415] [Learning-To-Measure: In-context Active Feature Acquisition](https://arxiv.org/abs/2510.12624)
*Yuta Kobayashi,Zilin Jing,Jiayu Yao,Hongseok Namkoong,Shalmali Joshi*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 L2M 的元主动特征获取（meta-AFA）方法，旨在通过跨多个任务学习特征获取策略来提高模型性能，尤其是在标签稀疏和特征缺失的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有主动特征获取（AFA）方法主要针对单一固定任务，扩展性受限。本研究旨在解决此问题，提出一种能够跨多个任务学习并应用特征获取策略的元 AFA 问题形式化。

Method: 提出了一种名为 L2M 的方法，该方法包含两个关键部分：1) 在未见过的任务上进行可靠的、不确定性量化的学习；2) 使用不确定性引导的贪婪特征获取代理，以最大化条件互信息。通过序列建模或自回归的预训练方法实现了对具有任意缺失特征的任务的不确定性量化。L2M 可直接在存在回顾性缺失的数据集上操作，并能进行上下文学习，无需对每个任务进行重新训练。

Result: L2M 在合成和真实世界的表格数据集基准测试中，表现与（甚至优于）特定任务的基线方法相当，特别是在标签稀疏和特征缺失比例较高的情况下。

Conclusion: L2M 成功地解决了元主动特征获取问题，通过跨任务学习和上下文学习，在标签稀疏和特征缺失的挑战性场景下，实现了与甚至超越了特定任务的方法的性能。

Abstract: Active feature acquisition (AFA) is a sequential decision-making problem
where the goal is to improve model performance for test instances by adaptively
selecting which features to acquire. In practice, AFA methods often learn from
retrospective data with systematic missingness in the features and limited
task-specific labels. Most prior work addresses acquisition for a single
predetermined task, limiting scalability. To address this limitation, we
formalize the meta-AFA problem, where the goal is to learn acquisition policies
across various tasks. We introduce Learning-to-Measure (L2M), which consists of
i) reliable uncertainty quantification over unseen tasks, and ii) an
uncertainty-guided greedy feature acquisition agent that maximizes conditional
mutual information. We demonstrate a sequence-modeling or autoregressive
pre-training approach that underpins reliable uncertainty quantification for
tasks with arbitrary missingness. L2M operates directly on datasets with
retrospective missingness and performs the meta-AFA task in-context,
eliminating per-task retraining. Across synthetic and real-world tabular
benchmarks, L2M matches or surpasses task-specific baselines, particularly
under scarce labels and high missingness.

</details>


### [416] [Expert or not? assessing data quality in offline reinforcement learning](https://arxiv.org/abs/2510.12638)
*Arip Asadulaev,Fakhri Karray,Martin Takac*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 Bellman Wasserstein Distance (BWD) 的新指标，用于在无需与环境交互或训练模型的情况下评估离线强化学习数据集的质量。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，数据集质量参差不齐，难以评估，而这会影响算法选择和性能。

Method: 研究了从累积奖励到基于价值的估计器等一系列代理指标，并引入了 BWD。BWD 通过行为评论家和状态条件 OT 公式计算，衡量数据集的行为策略与随机参考策略的差异。

Result: 在 D4RL MuJoCo 任务中，BWD 与预言机性能得分高度相关，能够有效预测标准算法在给定数据集上的表现。将 BWD 作为正则化器在策略优化中，可以提高回报。

Conclusion: 基于价值的、分布式的信号（如 BWD）是分类离线 RL 数据集和优化策略的实用工具。

Abstract: Offline reinforcement learning (RL) learns exclusively from static datasets,
without further interaction with the environment. In practice, such datasets
vary widely in quality, often mixing expert, suboptimal, and even random
trajectories. The choice of algorithm therefore depends on dataset fidelity.
Behavior cloning can suffice on high-quality data, whereas mixed- or
low-quality data typically benefits from offline RL methods that stitch useful
behavior across trajectories. Yet in the wild it is difficult to assess dataset
quality a priori because the data's provenance and skill composition are
unknown. We address the problem of estimating offline dataset quality without
training an agent. We study a spectrum of proxies from simple cumulative
rewards to learned value based estimators, and introduce the Bellman
Wasserstein distance (BWD), a value aware optimal transport score that measures
how dissimilar a dataset's behavioral policy is from a random reference policy.
BWD is computed from a behavioral critic and a state conditional OT
formulation, requiring no environment interaction or full policy optimization.
Across D4RL MuJoCo tasks, BWD strongly correlates with an oracle performance
score that aggregates multiple offline RL algorithms, enabling efficient
prediction of how well standard agents will perform on a given dataset. Beyond
prediction, integrating BWD as a regularizer during policy optimization
explicitly pushes the learned policy away from random behavior and improves
returns. These results indicate that value aware, distributional signals such
as BWD are practical tools for triaging offline RL datasets and policy
optimization.

</details>


### [417] [On Foundation Models for Temporal Point Processes to Accelerate Scientific Discovery](https://arxiv.org/abs/2510.12640)
*David Berghaus,Patrick Seifner,Kostadin Cvejoski,Ramses J. Sanchez*

Main category: cs.LG

TL;DR: 一个通用的事件序列分析基础模型，无需重新训练即可应用于新数据集，并可通过微调提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统模型需要为新数据集从头开始训练，耗时且成本高。

Method: 训练一个“基础模型”处理了数百万个模拟事件序列，使其能够理解事件展开的通用模式。

Result: 该模型可以立即分析新的科学数据，无需重新训练，只需查看数据集中的少量示例即可，并且可以快速微调以获得更高的准确性。

Conclusion: 这种方法使复杂的事件分析更加容易，并加快了科学发现的步伐。

Abstract: Many scientific fields, from medicine to seismology, rely on analyzing
sequences of events over time to understand complex systems. Traditionally,
machine learning models must be built and trained from scratch for each new
dataset, which is a slow and costly process. We introduce a new approach: a
single, powerful model that learns the underlying patterns of event data in
context. We trained this "foundation model" on millions of simulated event
sequences, teaching it a general-purpose understanding of how events can
unfold. As a result, our model can analyze new scientific data instantly,
without retraining, simply by looking at a few examples from the dataset. It
can also be quickly fine-tuned for even higher accuracy. This approach makes
sophisticated event analysis more accessible and accelerates the pace of
scientific discovery.

</details>


### [418] [Towards Foundation Inference Models that Learn ODEs In-Context](https://arxiv.org/abs/2510.12650)
*Maximilian Mauel,Manuel Hinz,Patrick Seifner,David Berghaus,Ramses J. Sanchez*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ordinary differential equations (ODEs) describe dynamical systems evolving
deterministically in continuous time. Accurate data-driven modeling of systems
as ODEs, a central problem across the natural sciences, remains challenging,
especially if the data is sparse or noisy. We introduce FIM-ODE (Foundation
Inference Model for ODEs), a pretrained neural model designed to estimate ODEs
zero-shot (i.e., in context) from sparse and noisy observations. Trained on
synthetic data, the model utilizes a flexible neural operator for robust ODE
inference, even from corrupted data. We empirically verify that FIM-ODE
provides accurate estimates, on par with a neural state-of-the-art method, and
qualitatively compare the structure of their estimated vector fields.

</details>


### [419] [Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?](https://arxiv.org/abs/2510.12680)
*Shouren Wang,Wang Yang,Xianxuan Long,Qifan Wang,Vipin Chaudhary,Xiaotian Han*

Main category: cs.LG

TL;DR: 混合思维大模型在模式分离上存在不足，通过分析影响因素并提出改进策略，可以在保持准确性的同时显著减少不思考模式的输出长度和推理支持标记的使用。


<details>
  <summary>Details</summary>
Motivation: 现有的混合思维大模型（Hybrid Thinking LLMs）在推理和直接回答之间切换时，只实现了部分模式分离，推理行为会泄露到不思考模式中。本研究旨在理解并解决这一问题。

Method: 通过实验分析影响模型模式可控性的因素，重点关注了数据规模、训练数据来源（同问题 vs. 不同问题）、不思考数据数量以及训练策略（两阶段训练）。基于分析结果，提出了一种改进的混合思维训练方法。

Result: 提出的方法在保持两种模式（推理和不思考）准确性的同时，显著减少了不思考模式的输出长度（在MATH500数据集上从1085减少到585）以及推理支持标记（如“wait”）的使用频率（在MATH500数据集上从5917减少到522）。

Conclusion: 当前混合思维大模型的模式可控性存在局限性，本研究提出的方法和发现为增强其可控性提供了方向。

Abstract: Hybrid thinking enables LLMs to switch between reasoning and direct
answering, offering a balance between efficiency and reasoning capability. Yet
our experiments reveal that current hybrid thinking LLMs only achieve partial
mode separation: reasoning behaviors often leak into the no-think mode. To
understand and mitigate this, we analyze the factors influencing
controllability and identify four that matter most: (1) larger data scale, (2)
using think and no-think answers from different questions rather than the same
question, (3) a moderate increase in no-think data number, and (4) a two-phase
strategy that first trains reasoning ability and then applies hybrid think
training. Building on these findings, we propose a practical recipe that,
compared to standard training, can maintain accuracy in both modes while
significantly reducing no-think output length (from $1085$ to $585$ on MATH500)
and occurrences of reasoning-supportive tokens such as ``\texttt{wait}'' (from
$5917$ to $522$ on MATH500). Our findings highlight the limitations of current
hybrid thinking and offer directions for strengthening its controllability.

</details>


### [420] [SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning](https://arxiv.org/abs/2510.12659)
*Chih-Chuan Cheng,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: SG-XDEAT是一个用于表格数据监督学习的新框架，通过双流编码器和注意力机制来提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在表格数据上实现监督学习，并提高模型的鲁棒性。

Method: SG-XDEAT使用一个双流编码器，将输入特征分解为原始值流和目标条件流。通过跨维度自注意力、交叉编码自注意力和自适应稀疏自注意力机制来处理这两种表示。

Result: 在多个公开基准测试中，SG-XDEAT取得了显著的改进，优于现有的基线模型。

Conclusion: 联合建模原始视图和目标感知视图，同时自适应地过滤噪声，可以构建更强大的深度表格学习器。

Abstract: We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding
Attention with Target Aware Conditioning), a novel framework designed for
supervised learning on tabular data. At its core, SG-XDEAT employs a
dual-stream encoder that decomposes each input feature into two parallel
representations: a raw value stream and a target-conditioned (label-aware)
stream. These dual representations are then propagated through a hierarchical
stack of attention-based modules. SG-XDEAT integrates three key components: (i)
Cross-Dimensional self-attention, which captures intra-view dependencies among
features within each stream; (ii) Cross-Encoding self-attention, which enables
bidirectional interaction between raw and target-aware representations; and
(iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically
suppresses low-utility tokens by driving their attention weights toward
zero--thereby mitigating the impact of noise. Empirical results on multiple
public benchmarks show consistent gains over strong baselines, confirming that
jointly modeling raw and target-aware views--while adaptively filtering
noise--yields a more robust deep tabular learner.

</details>


### [421] [Structured Sparsity and Weight-adaptive Pruning for Memory and Compute efficient Whisper models](https://arxiv.org/abs/2510.12666)
*Prasenjit K Mudi,Anshi Sachan,Dahlia Devapriya,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 通过结构化稀疏性和感知剪枝算法，在不影响语音识别准确率的情况下，减小了Whisper模型的参数量、内存占用和计算量，并在Hindi数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: Whisper模型虽然在语音识别方面取得了显著进展，但其庞大的模型尺寸限制了其在资源受限的边缘设备上的部署。本文旨在提出一种方法来设计Whisper模型的微调变体，以解决这一问题。

Method: 本文提出了一种框架来设计微调的Whisper模型变体。通过将结构化稀疏性作为损失正则化项，利用稀疏分组LASSO罚项来减少计算量（FLOPs）。此外，还提出了一种感知剪枝算法。同时，设计了一个自定义的文本归一化器用于词错误率（WER）评估。

Result: 在Common Voice 11.0 Hindi数据集上，与Whisper-small模型相比，参数量减少了35.4%，内存占用降低了14.25%，计算量减少了18.5%，且词错误率（WER）并未下降。与Whisper-medium模型相比，参数量减少了31%，内存占用降低了15.29%，计算量减少了16.95%，且WER并未下降。此外，本文提出的方法在剪枝方面比最先进的迭代幅度剪枝（IMP）方法多剪枝了18.7%的参数，同时将WER降低了12.31%。

Conclusion: 本文提出的方法成功地减小了Whisper模型的尺寸，降低了内存和计算需求，同时保持甚至提高了语音识别的准确性，为在资源受限的设备上部署Whisper模型提供了有效的解决方案。

Abstract: Whisper models have achieved remarkable progress in speech recognition; yet
their large size remains a bottleneck for deployment on resource-constrained
edge devices. This paper proposes a framework to design fine-tuned variants of
Whisper which address the above problem. Structured sparsity is enforced via
the Sparse Group LASSO penalty as a loss regularizer, to reduce the number of
FLOating Point operations (FLOPs). Further, a weight statistics aware pruning
algorithm is proposed. We also design our custom text normalizer for WER
evaluation. On Common Voice 11.0 Hindi dataset, we obtain, without degrading
WER, (a) 35.4% reduction in model parameters, 14.25% lower memory consumption
and 18.5% fewer FLOPs on Whisper-small, and (b) 31% reduction in model
parameters, 15.29% lower memory consumption and 16.95% fewer FLOPs on
Whisper-medium; and, (c) substantially outperform the state-of-the-art
Iterative Magnitude Pruning based method by pruning 18.7% more parameters along
with a 12.31 reduction in WER.

</details>


### [422] [Keep Calm and Avoid Harmful Content: Concept Alignment and Latent Manipulation Towards Safer Answers](https://arxiv.org/abs/2510.12672)
*Ruben Belo,Claudia Soares,Marta Guimaraes*

Main category: cs.LG

TL;DR: CALM是一种推理时方法，通过修改模型最后一层的潜在表征来抑制有害概念，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击，绕过内置的安全护栏。

Method: CALM结合了计算机视觉中的CW技术和正交投影，移除与有害内容相关的潜在方向，同时保持模型性能。

Result: 实验表明，CALM减少了有害输出，并在大多数指标上优于基线方法。

Conclusion: CALM提供了一种轻量级的AI安全方法，无需额外的训练数据或模型微调，且仅产生少量的推理计算开销。

Abstract: Large Language Models are susceptible to jailbreak attacks that bypass
built-in safety guardrails (e.g., by tricking the model with adversarial
prompts). We propose Concept Alignment and Concept Manipulation \textbf{CALM},
an inference-time method that suppresses harmful concepts by modifying latent
representations of the last layer of the model, without retraining. Leveraging
\gls*{cw} technique from Computer Vision combined with orthogonal projection,
CALM removes unwanted latent directions associated with harmful content while
preserving model performance. Experiments show that CALM reduces harmful
outputs and outperforms baseline methods in most metrics, offering a
lightweight approach to AI safety with no additional training data or model
fine-tuning, while incurring only a small computational overhead at inference.

</details>


### [423] [CoRA: Covariate-Aware Adaptation of Time Series Foundation Models](https://arxiv.org/abs/2510.12681)
*Guo Qin,Zhi Chen,Yong Liu,Zhiyuan Shi,Haixuan Liu,Xiangdong Huang,Jianmin Wang,Mingsheng Long*

Main category: cs.LG

TL;DR: 该研究提出了一种名为CoRA的通用协变量感知自适应框架，用于增强时间序列基础模型（TSFM）在多变量时间序列预测任务中的性能，通过整合多模态协变量（时间序列、语言、图像）来解决现有TSFM忽视协变量信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型（TSFM）主要在单变量时间序列上进行预训练，忽略了多变量数据中协变量信息的异质性和骨干模型的扩展性问题，导致在真实世界预测任务中表现受限。

Method: CoRA框架利用预训练的TSFM骨干作为特征提取器，并引入一种新的格兰杰因果嵌入（GCE）机制来评估协变量对目标变量的因果预测能力。通过加权嵌入和零初始化的条件注入机制，CoRA在避免灾难性遗忘的同时，逐步整合外源信息。

Result: CoRA框架在协变量感知预测任务上实现了31.1%的均方误差（MSE）降低，超越了最先进的协变量感知深度预测模型，并且在全样本和少样本场景下都表现出色。

Conclusion: CoRA框架能够有效整合多模态协变量信息，提升TSFM的预测性能，并且具有良好的兼容性和扩展性，为TSFM在实际应用中的推广提供了一种实用范式。

Abstract: Time Series Foundation Models (TSFMs) have shown significant impact through
their model capacity, scalability, and zero-shot generalization. However, due
to the heterogeneity of inter-variate dependencies and the backbone scalability
on large-scale multivariate datasets, most TSFMs are typically pre-trained on
univariate time series. This limitation renders them oblivious to crucial
information from diverse covariates in real-world forecasting tasks. To further
enhance the performance of TSFMs, we propose a general covariate-aware
adaptation (CoRA) framework for TSFMs. It leverages pre-trained backbones of
foundation models while effectively incorporating exogenous covariates from
various modalities, including time series, language, and images, to improve the
quality of predictions. Technically, CoRA maintains the equivalence of
initialization and parameter consistency during adaptation. With preserved
backbones of foundation models as frozen feature extractors, the outcome
embeddings from foundation models are empirically demonstrated more informative
than raw data. Further, CoRA employs a novel Granger Causality Embedding (GCE)
to automatically evaluate covariates regarding their causal predictability with
respect to the target variate. We incorporate these weighted embeddings with a
zero-initialized condition-injection mechanism, avoiding catastrophic
forgetting of pre-trained foundation models and gradually integrates exogenous
information. Extensive experiments show that CoRA of TSFMs surpasses
state-of-the-art covariate-aware deep forecasters with full or few-shot
training samples, achieving 31.1% MSE reduction on covariate-aware forecasting.
Compared to other adaptation methods, CoRA exhibits strong compatibility with
various advanced TSFMs and extends the scope of covariates to other modalities,
presenting a practical paradigm for the application of TSFMs.

</details>


### [424] [Few Shot Semi-Supervised Learning for Abnormal Stop Detection from Sparse GPS Trajectories](https://arxiv.org/abs/2510.12686)
*Muhammad Ayub Sabir,Junbiao Pang,Jiaqi Wu,Fatima Ashraf*

Main category: cs.LG

TL;DR: 本研究提出了一种名为SAS（Sparsity-Aware Segmentation）的新方法，通过自适应地定义分段边界来解决GPS轨迹稀疏性问题，并结合三种特定指标和LTIGA（Locally Temporal-Indicator Guided Adjustment）算法来捕捉和优化异常停车行为的检测。为了应对标签数据稀缺的挑战，研究人员构建了一个空间-时间图，并利用标签传播和图卷积网络（GCN）进行学习，最后通过自训练模块进一步提升模型性能。实验结果表明，该方法在真实公交数据上表现出色，仅使用10个标签实例即可达到0.854的AUC和0.866的AP，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前城际客运交通中异常停车检测（ASD）面临两大挑战：GPS轨迹稀疏导致难以检测短暂或未经授权的停车，以及标注数据不足限制了监督学习的应用。现有方法通常假设数据密集或运动模式规律，这限制了其适用性。

Method: 该研究提出了一种名为SAS（Sparsity-Aware Segmentation）的方法，通过自适应地根据局部时空密度来定义分段边界，以解决数据稀疏性问题。在此基础上，引入了三个特定领域的指标来捕捉异常停车行为。为了进一步缓解稀疏性的影响，开发了LTIGA（Locally Temporal-Indicator Guided Adjustment）算法，通过局部相似性图来平滑这些指标。为了克服标签稀缺的问题，构建了一个空间-时间图，其中每个段是一个节点，并带有经过LTIGA优化的特征。然后应用标签传播来扩展弱监督，并使用GCN来学习关系模式。最后，通过一个自训练模块，结合高置信度的伪标签来迭代地改进预测。

Result: 在真实公交数据上进行的实验表明，仅使用10个标注实例，该方法达到了0.854的AUC和0.866的AP，优于先前的方法。

Conclusion: 本研究提出的SAS和LTIGA方法能够有效解决GPS轨迹稀疏和标注数据不足的问题，实现了高效的异常停车检测。实验结果证明了该方法的优越性。

Abstract: Abnormal stop detection (ASD) in intercity coach transportation is critical
for ensuring passenger safety, operational reliability, and regulatory
compliance. However, two key challenges hinder ASD effectiveness: sparse GPS
trajectories, which obscure short or unauthorized stops, and limited labeled
data, which restricts supervised learning. Existing methods often assume dense
sampling or regular movement patterns, limiting their applicability. To address
data sparsity, we propose a Sparsity-Aware Segmentation (SAS) method that
adaptively defines segment boundaries based on local spatial-temporal density.
Building upon these segments, we introduce three domain-specific indicators to
capture abnormal stop behaviors. To further mitigate the impact of sparsity, we
develop Locally Temporal-Indicator Guided Adjustment (LTIGA), which smooths
these indicators via local similarity graphs. To overcome label scarcity, we
construct a spatial-temporal graph where each segment is a node with
LTIGA-refined features. We apply label propagation to expand weak supervision
across the graph, followed by a GCN to learn relational patterns. A final
self-training module incorporates high-confidence pseudo-labels to iteratively
improve predictions. Experiments on real-world coach data show an AUC of 0.854
and AP of 0.866 using only 10 labeled instances, outperforming prior methods.
The code and dataset are publicly available at
\href{https://github.com/pangjunbiao/Abnormal-Stop-Detection-SSL.git}

</details>


### [425] [DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization](https://arxiv.org/abs/2510.12691)
*Danial Hosseintabar,Fan Chen,Giannis Daras,Antonio Torralba,Constantinos Daskalakis*

Main category: cs.LG

TL;DR: 使用期望最大化（EM）从损坏的数据中训练扩散模型，用于高维逆问题，并提供单调收敛保证。


<details>
  <summary>Details</summary>
Motivation: 高维逆问题中，仅从损坏或带噪声的观测中学习扩散模型仍然是一个挑战。

Method: 提出了一种使用期望最大化（EM）从损坏数据中训练扩散模型的新方法（DiffEM）。该方法在E步利用条件扩散模型从观测中重建干净数据，然后在M步使用重建的数据来改进条件扩散模型。

Result: 通过在各种图像重建任务上的实验证明了该方法的有效性。

Conclusion: DiffEM 是一种从损坏数据中学习条件扩散模型的新颖且有效的方法，并具有理论收敛保证。

Abstract: Diffusion models have emerged as powerful generative priors for
high-dimensional inverse problems, yet learning them when only corrupted or
noisy observations are available remains challenging. In this work, we propose
a new method for training diffusion models with Expectation-Maximization (EM)
from corrupted data. Our proposed method, DiffEM, utilizes conditional
diffusion models to reconstruct clean data from observations in the E-step, and
then uses the reconstructed data to refine the conditional diffusion model in
the M-step. Theoretically, we provide monotonic convergence guarantees for the
DiffEM iteration, assuming appropriate statistical conditions. We demonstrate
the effectiveness of our approach through experiments on various image
reconstruction tasks.

</details>


### [426] [Topological Signatures of ReLU Neural Network Activation Patterns](https://arxiv.org/abs/2510.12700)
*Vicente Bosca,Tatum Rask,Sunia Tanweer,Andrew R. Tawfeek,Branden Stone*

Main category: cs.LG

TL;DR: 本论文探讨了ReLU神经网络激活模式的拓扑特征。


<details>
  <summary>Details</summary>
Motivation: 研究ReLU神经网络激活模式的拓扑特征及其与网络决策边界和训练行为的关系。

Method: 分析了特征空间的多面体分解，研究了偶图的Fiedler分割与二元分类决策边界的关联，并计算了胞腔分解的同调性，以研究回归任务中训练损失与多面体单元数量之间的模式。

Result: Fiedler分割与二元分类的决策边界相关；在回归任务中，训练损失与多面体单元数量之间存在相似的行为模式。

Conclusion: ReLU神经网络的拓扑特征，特别是其多面体分解和偶图的Fiedler分割，与网络的决策边界和训练行为（如训练损失和模型复杂度）之间存在显著的关联。

Abstract: This paper explores the topological signatures of ReLU neural network
activation patterns. We consider feedforward neural networks with ReLU
activation functions and analyze the polytope decomposition of the feature
space induced by the network. Mainly, we investigate how the Fiedler partition
of the dual graph and show that it appears to correlate with the decision
boundary -- in the case of binary classification. Additionally, we compute the
homology of the cellular decomposition -- in a regression task -- to draw
similar patterns in behavior between the training loss and polyhedral
cell-count, as the model is trained.

</details>


### [427] [Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction](https://arxiv.org/abs/2510.12719)
*Matthew Adrian,Yunsie Chung,Kevin Boyd,Saee Paliwal,Srimukh Prasad Veccham,Alan C. Cheng*

Main category: cs.LG

TL;DR: 化学预训练模型（如KERMT和KGPT）通过多任务微调可显著提升药物发现预测性能，尤其是在数据量较大时。同时发布了多任务ADMET数据集和加速版KERMT模型以促进相关研究和工业应用。


<details>
  <summary>Details</summary>
Motivation: 评估化学预训练模型（如图神经网络模型KERMT和KGPT）在药物发现中的应用潜力，特别是通过多任务学习进行微调的效果。

Method: 采用多任务学习的方式对化学预训练图神经网络模型（KERMT和KGPT）进行微调，并与非预训练模型进行性能比较。

Result: 与非预训练模型相比，经过多任务微调的预训练模型（KERMT和KGPT）在药物发现预测任务中表现出显著的性能提升。性能提升在较大数据集时尤为明显。

Conclusion: 多任务微调是提升化学预训练图神经网络模型在药物发现应用中预测性能的有效策略，尤其适用于大规模数据集。

Abstract: Chemical pretrained models, sometimes referred to as foundation models, are
receiving considerable interest for drug discovery applications. The general
chemical knowledge extracted from self-supervised training has the potential to
improve predictions for critical drug discovery endpoints, including on-target
potency and ADMET properties. Multi-task learning has previously been
successfully leveraged to improve predictive models. Here, we show that
enabling multitasking in finetuning of chemical pretrained graph neural network
models such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the
GROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT)
significantly improves performance over non-pretrained graph neural network
models. Surprisingly, we find that the performance improvement from finetuning
KERMT in a multitask manner is most significant at larger data sizes.
Additionally, we publish two multitask ADMET data splits to enable more
accurate benchmarking of multitask deep learning methods for drug property
prediction. Finally, we provide an accelerated implementation of the KERMT
model on GitHub, unlocking large-scale pretraining, finetuning, and inference
in industrial drug discovery workflows.

</details>


### [428] [CARVQ: Corrective Adaptor with Group Residual Vector Quantization for LLM Embedding Compression](https://arxiv.org/abs/2510.12721)
*Dayin Gou,Sanghyun Byun,Nilesh Malpeddi,Gabrielle De Micheli,Prathamesh Vaste,Jacob Song,Woo Seong Chung*

Main category: cs.LG

TL;DR: CARVQ通过结合正确性适配器和残差向量量化来压缩LLM的嵌入层，在不牺牲性能的情况下显著减小模型尺寸，适用于内存受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: LLMs的嵌入层参数量大，导致存储和内存占用高，尤其在内存受限的边缘设备上部署时成为瓶颈。压缩嵌入层可以提高内存带宽和推理速度。

Method: 提出CARVQ，一种结合了正确性适配器和组残差向量量化的新颖的训练后嵌入层压缩方法。CARVQ利用线性和非线性映射的组合来模拟原始模型嵌入，实现约1.6位的压缩，无需专门的硬件支持。

Result: 在LLaMA、Qwen2.5和Phi-4等预训练LLM上进行测试，评估了生成、判别、数学和推理任务。结果表明，CARVQ在大多数情况下能以更低的平均比特宽度实现可接受的困惑度和准确性，优于标量量化。

Conclusion: CARVQ是一种新颖的压缩技术，可与最先进的Transformer量化方法兼容，并能集成到支持4位内存的硬件中，以减小内存受限设备上LLM的内存占用。该研究为LLM在边缘设备的有效部署迈出了重要一步。

Abstract: Large Language Models (LLMs) typically rely on a large number of parameters
for token embedding, leading to substantial storage requirements and memory
footprints. In particular, LLMs deployed on edge devices are memory-bound, and
reducing the memory footprint by compressing the embedding layer not only frees
up the memory bandwidth but also speeds up inference. To address this, we
introduce CARVQ, a post-training novel Corrective Adaptor combined with group
Residual Vector Quantization. CARVQ relies on the composition of both linear
and non-linear maps and mimics the original model embedding to compress to
approximately 1.6 bits without requiring specialized hardware to support
lower-bit storage. We test our method on pre-trained LLMs such as LLaMA-3.2-1B,
LLaMA-3.2-3B, LLaMA-3.2-3B-Instruct, LLaMA-3.1-8B, Qwen2.5-7B, Qwen2.5-Math-7B
and Phi-4, evaluating on common generative, discriminative, math and reasoning
tasks. We show that in most cases, CARVQ can achieve lower average
bitwidth-per-parameter while maintaining reasonable perplexity and accuracy
compared to scalar quantization. Our contributions include a novel compression
technique that is compatible with state-of-the-art transformer quantization
methods and can be seamlessly integrated into any hardware supporting 4-bit
memory to reduce the model's memory footprint in memory-constrained devices.
This work demonstrates a crucial step toward the efficient deployment of LLMs
on edge devices.

</details>


### [429] [Improving Decision Trees through the Lens of Parameterized Local Search](https://arxiv.org/abs/2510.12726)
*Juha Harviainen,Frank Sommer,Manuel Sorge*

Main category: cs.LG

TL;DR: 该研究提出了针对决策树学习中局部搜索操作（调整切分阈值或特征）的计算复杂性分析，并提供了参数化复杂性结果。


<details>
  <summary>Details</summary>
Motivation: 为了理解和解决决策树学习中局部搜索操作（调整切分阈值或特征）的计算复杂性问题。

Method: 通过分析固定次数的单种局部搜索操作（调整阈值或交换特征）在最小化分类错误方面的计算复杂性，并进行参数化复杂性分析，找出问题难度的根源和可处理的性质。

Result: 发现一般情况下问题是NP完全的，但通过参数化复杂性分析，证明当特征数量$d$或域大小$D$较小时，问题仍然是困难的，然而两者的结合（小$d$和$D$）使得问题变得可处理，并给出了一个能在$(D + 1)^{2d} 	imes |I|^{O(1)}$时间内解决的算法，且提供了该算法的实现和实验结果。

Conclusion: 决策树学习中的局部搜索操作问题在一般情况下是NP完全的，但其复杂性与问题参数（如特征数量和域大小）密切相关，通过参数化复杂性分析可以找到可行的解决方法。

Abstract: Algorithms for learning decision trees often include heuristic local-search
operations such as (1) adjusting the threshold of a cut or (2) also exchanging
the feature of that cut. We study minimizing the number of classification
errors by performing a fixed number of a single type of these operations.
Although we discover that the corresponding problems are NP-complete in
general, we provide a comprehensive parameterized-complexity analysis with the
aim of determining those properties of the problems that explain the hardness
and those that make the problems tractable. For instance, we show that the
problems remain hard for a small number $d$ of features or small domain size
$D$ but the combination of both yields fixed-parameter tractability. That is,
the problems are solvable in $(D + 1)^{2d} \cdot |I|^{O(1)}$ time, where $|I|$
is the size of the input. We also provide a proof-of-concept implementation of
this algorithm and report on empirical results.

</details>


### [430] [Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect](https://arxiv.org/abs/2510.12734)
*Jon Donnelly,Srikar Katta,Emanuele Borgonovo,Cynthia Rudin*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 UNIVERSE 的新方法，用于在存在缺失特征的情况下估计变量重要性（VI），并考虑了 Rashomon 效应（即不同模型可能产生不同的 VI）。


<details>
  <summary>Details</summary>
Motivation: 标准变量重要性（VI）方法在估计 VI 时存在局限性，因为它仅考虑观测到的特征，并且忽略了其他重要变量可能缺失以及不同模型可能产生不同 VI（Rashomon 效应）的问题。

Method: UNIVERSE 方法通过适应 Rashomon 集（一组接近最优的模型）来估计真实 VI 的边界，即使在存在缺失特征的情况下也能做到。

Result: 该方法在理论上保证了鲁棒性，并在半合成模拟和信用风险任务中表现出强大的性能。

Conclusion: UNIVERSE 方法能够弥补标准 VI 方法的不足，在处理缺失特征和 Rashomon 效应时提供更可靠的 VI 估计。

Abstract: Variable importance (VI) methods are often used for hypothesis generation,
feature selection, and scientific validation. In the standard VI pipeline, an
analyst estimates VI for a single predictive model with only the observed
features. However, the importance of a feature depends heavily on which other
variables are included in the model, and essential variables are often omitted
from observational datasets. Moreover, the VI estimated for one model is often
not the same as the VI estimated for another equally-good model - a phenomenon
known as the Rashomon Effect. We address these gaps by introducing
UNobservables and Inference for Variable importancE using Rashomon SEts
(UNIVERSE). Our approach adapts Rashomon sets - the sets of near-optimal models
in a dataset - to produce bounds on the true VI even with missing features. We
theoretically guarantee the robustness of our approach, show strong performance
on semi-synthetic simulations, and demonstrate its utility in a credit risk
task.

</details>


### [431] [KoALA: KL-L0 Adversarial Detector via Label Agreement](https://arxiv.org/abs/2510.12752)
*Siqi Li,Yasser Shoukry*

Main category: cs.LG

TL;DR: KoALA是一种基于KL散度和L0相似度的语义无关的对抗性检测器，通过比较两种度量标准的分类预测来检测对抗性攻击，无需修改模型架构或进行对抗性再训练，可作为即插即用解决方案。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易受到对抗性攻击，对安全和关键应用构成重大风险，需要有效的检测方法。

Method: KoALA通过KL散度和L0相似度这两种互补的相似性度量标准来检测对抗性攻击。KL散度对低幅度、密集的扰动敏感，而L0相似度对高影响力、稀疏的扰动敏感。仅需在预训练的图像编码器上使用干净图像进行微调。

Result: 在ResNet/CIFAR-10上，KoALA的精确率为0.94，召回率为0.81；在CLIP/Tiny-ImageNet上，精确率为0.66，召回率为0.85，证明了其在不同模型和数据集上的有效性。

Conclusion: KoALA是一种轻量级、即插即用的对抗性检测方法，通过比较两种互补的相似性度量标准的分类预测来有效检测对抗性攻击，无需修改模型架构或进行对抗性再训练。

Abstract: Deep neural networks are highly susceptible to adversarial attacks, which
pose significant risks to security- and safety-critical applications. We
present KoALA (KL-L0 Adversarial detection via Label Agreement), a novel,
semantics-free adversarial detector that requires no architectural changes or
adversarial retraining. KoALA operates on a simple principle: it detects an
adversarial attack when class predictions from two complementary similarity
metrics disagree. These metrics-KL divergence and an L0-based similarity-are
specifically chosen to detect different types of perturbations. The KL
divergence metric is sensitive to dense, low-amplitude shifts, while the
L0-based similarity is designed for sparse, high-impact changes. We provide a
formal proof of correctness for our approach. The only training required is a
simple fine-tuning step on a pre-trained image encoder using clean images to
ensure the embeddings align well with both metrics. This makes KOALA a
lightweight, plug-and-play solution for existing models and various data
modalities. Our extensive experiments on ResNet/CIFAR-10 and CLIP/Tiny-ImageNet
confirm our theoretical claims. When the theorem's conditions are met, KoALA
consistently and effectively detects adversarial examples. On the full test
sets, KoALA achieves a precision of 0.94 and a recall of 0.81 on
ResNet/CIFAR-10, and a precision of 0.66 and a recall of 0.85 on
CLIP/Tiny-ImageNet.

</details>


### [432] [Sample-Efficient Omniprediction for Proper Losses](https://arxiv.org/abs/2510.12769)
*Isaac Gibbs,Ryan J. Tibshirani*

Main category: cs.LG

TL;DR: 本篇论文研究了如何构建能够指导行动并做出准确决策的概率预测。对于单一决策者，最优预测器的构建等同于最小化该个体效用负数所对应的损失函数。对于多个决策者，该问题可以被视为一种全预测（omniprediction）的变体，目标是设计一个能同时最小化多个损失的单一预测器。现有全预测算法主要分为两类：1）提升（boosting）方法，通过优化多校准（multicalibration）等辅助目标来实现全预测；2）基于对抗性双人博弈的方法，在线估计并响应“最坏情况”损失。本研究通过下界证明，多校准比全预测更难，因此基于多校准的方法样本复杂度更高。对于博弈方法，我们讨论了如何通过在线到批量（online-to-batch）转换获得样本效率高的算法，但这种方法会产生复杂的随机预测器。我们设计了一种更直接、非随机的算法，利用了损失函数集合的结构，改进了现有方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决如何构建能够指导行动并做出准确决策的概率预测问题，特别是针对多个决策者需要同时最小化各自损失函数的情况。

Method: 本研究对现有的全预测算法进行了分析和改进。对于基于提升的方法，证明了其样本复杂度劣于全预测。对于基于对抗性双人博弈的方法，通过在线到批量转换可以提高样本效率，但会产生复杂的随机预测器。为了改进这一点，研究者设计了一种更直接、非随机的算法，利用了损失函数集合的结构。

Result: 通过对现有方法的分析和改进，本研究提出了一种更优的概率预测方法，能够更有效地处理多决策者场景，并避免产生复杂的随机预测器。

Conclusion: 本研究提出了一种更直接、非随机的算法，能够更有效地解决多决策者场景下的全预测问题，相比现有方法具有更好的样本效率和预测器复杂度。

Abstract: We consider the problem of constructing probabilistic predictions that lead
to accurate decisions when employed by downstream users to inform actions. For
a single decision maker, designing an optimal predictor is equivalent to
minimizing a proper loss function corresponding to the negative utility of that
individual. For multiple decision makers, our problem can be viewed as a
variant of omniprediction in which the goal is to design a single predictor
that simultaneously minimizes multiple losses. Existing algorithms for
achieving omniprediction broadly fall into two categories: 1) boosting methods
that optimize other auxiliary targets such as multicalibration and obtain
omniprediction as a corollary, and 2) adversarial two-player game based
approaches that estimate and respond to the ``worst-case" loss in an online
fashion. We give lower bounds demonstrating that multicalibration is a strictly
more difficult problem than omniprediction and thus the former approach must
incur suboptimal sample complexity. For the latter approach, we discuss how
these ideas can be used to obtain a sample-efficient algorithm through an
online-to-batch conversion. This conversion has the downside of returning a
complex, randomized predictor. We improve on this method by designing a more
direct, unrandomized algorithm that exploits structural elements of the set of
proper losses.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [433] [A Direct Memory Access Controller (DMAC) for Irregular Data Transfers on RISC-V Linux Systems](https://arxiv.org/abs/2510.12277)
*Thomas Benz,Axel Vanoni,Michael Rogenmoser,Luca Benini*

Main category: cs.AR

TL;DR: 该研究提出了一种优化的基于描述符的直接内存访问控制器（DMAC），用于高效处理小尺寸的任意内存传输，相比传统DMAC，在启动传输时延迟降低了1.66倍，总线利用率最高提升了2.5倍，同时资源占用更少。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习应用导致计算系统日益异构化，对内存系统处理任意和更高要求的传输效率提出了挑战。传统的基于描述符的DMAC在处理小尺寸的任意传输时效率低下，存在描述符设置开销大的问题。

Method: 提出了一种优化的基于描述符的DMAC，采用了轻量级的描述符格式和低开销的推测性描述符预取方案，并将其集成到RISC-V SoC中，在FPGA上进行了评估。

Result: 与现有的基于描述符的DMAC IP相比，新DMAC在启动传输时的延迟降低了1.66倍，总线利用率提高了2.5倍（针对64字节传输），同时使用的查找表（LUT）减少了11%，触发器（FF）减少了23%，并且不使用块RAM（BRAM）。在深层内存系统中，总线利用率可提升至3.6倍。DMAC在GF12LP+工艺下时钟频率超过1.44 GHz，占用仅49.5 kGE。

Conclusion: 所提出的DMAC能够显著提高处理小尺寸任意内存传输的效率，降低延迟，提高总线利用率，并减少硬件资源消耗，适用于异构计算系统中的内存传输需求。

Abstract: With the ever-growing heterogeneity in computing systems, driven by modern
machine learning applications, pressure is increasing on memory systems to
handle arbitrary and more demanding transfers efficiently. Descriptor-based
direct memory access controllers (DMACs) allow such transfers to be executed by
decoupling memory transfers from processing units. Classical descriptor-based
DMACs are inefficient when handling arbitrary transfers of small unit sizes.
Excessive descriptor size and the serialized nature of processing descriptors
employed by the DMAC lead to large static overheads when setting up transfers.
To tackle this inefficiency, we propose a descriptor-based DMAC optimized to
efficiently handle arbitrary transfers of small unit sizes. We implement a
lightweight descriptor format in an AXI4-based DMAC. We further increase
performance by implementing a low-overhead speculative descriptor prefetching
scheme without additional latency penalties in the case of a misprediction. Our
DMAC is integrated into a 64-bit Linux-capable RISC-V SoC and emulated on a
Kintex FPGA to evaluate its performance. Compared to an off-the-shelf
descriptor-based DMAC IP, we achieve 1.66x less latency launching transfers,
increase bus utilization up to 2.5x in an ideal memory system with
64-byte-length transfers while requiring 11% fewer lookup tables, 23% fewer
flip-flops, and no block RAMs. We can extend our lead in bus utilization to
3.6x with 64-byte-length transfers in deep memory systems. We synthesized our
DMAC in GlobalFoundries' GF12LP+ node, achieving a clock frequency of over 1.44
GHz while occupying only 49.5 kGE.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [434] [Ground Stratification for a Logic of Definitions with Induction](https://arxiv.org/abs/2510.12297)
*Nathan Guermond,Gopalan Nadathur*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The logic underlying the Abella proof assistant includes mechanisms for
interpreting atomic predicates through fixed point definitions that can
additionally be treated inductively or co-inductively. However, the original
formulation of the logic includes a strict stratification condition on
definitions that is too restrictive for some applications such as those that
use a logical relations based approach to semantic equivalence. Tiu has shown
how this restriction can be eased by utilizing a weaker notion referred to as
ground stratification. Tiu's results were limited to a version of the logic
that does not treat inductive definitions. We show here that they can be
extended to cover such definitions. While our results are obtained by using
techniques that have been previously deployed in related ways in this context,
their use is sensitive to the particular way in which we generalize the logic.
In particular, although ground stratification may be used with arbitrary
fixed-point definitions, we show that weakening stratification to this form for
inductive definitions leads to inconsistency. The particular generalization we
describe accords well with the way logical relations are used in practice. Our
results are also a intermediate step to building a more flexible form for
definitions into the full logic underlying Abella, which additionally includes
co-induction, generic quantification, and a mechanism referred to as nominal
abstraction for analyzing occurrences of objects in terms that are governed by
generic quantifiers.

</details>


### [435] [Flavors of Quantifiers in Hyperlogics](https://arxiv.org/abs/2510.12298)
*Marek Chalupa,Thomas A. Henzinger,Ana Oliveira da Costa*

Main category: cs.LO

TL;DR: 本文扩展了超跟踪逻辑，通过引入跟踪量词，并研究了不同量词模式对可满足性问题的影响，得出了一系列新的判定性和非判定性结果。


<details>
  <summary>Details</summary>
Motivation: 研究超跟踪逻辑中不同量词模式对可满足性问题的影响，并扩展了该逻辑的表达能力。

Method: 在超跟踪逻辑中引入跟踪量词，分为受限和非受限跟踪变量。分析不同量词模式（如全跟踪量词、跟踪前缀片段、存在量词到全称量词的交替）的逻辑等价性和可判定性。

Result: 证明了无受限跟踪量词的超跟踪逻辑等价于S1S，具有可满足性。证明了跟踪前缀片段等价于HyperQPTL。证明了存在量词到全称量词交替的超跟踪公式是可判定的。

Conclusion: 扩展的超跟踪逻辑及其量词模式的分析为超属性研究提供了新的视角，并产生了一系列新的可判定性和非判定性结果。

Abstract: Hypertrace logic is a sorted first-order logic with separate sorts for time
and execution traces. Its formulas specify hyperproperties, which are
properties relating multiple traces. In this work, we extend hypertrace logic
by introducing trace quantifiers that range over the set of all possible
traces. In this extended logic, formulas can quantify over two kinds of trace
variables: constrained trace variables, which range over a fixed set of traces
defined by the model, and unconstrained trace variables, which can be assigned
to any trace. In comparison, hyperlogics such as HyperLTL have only constrained
trace quantifiers. We use hypertrace logic to study how different quantifier
patterns affect the decidability of the satisfiability problem. We prove that
hypertrace logic without constrained trace quantifiers is equivalent to monadic
second-order logic of one successor (S1S), and therefore satisfiable, and that
the trace-prefixed fragment (all trace quantifiers precede all time
quantifiers) is equivalent to HyperQPTL. Moreover, we show that all hypertrace
formulas where the only alternation between constrained trace quantifiers is
from an existential to a universal quantifier are equisatisfiable to formulas
without constraints on their trace variables and, therefore, decidable as well.
Our framework allows us to study also time-prefixed hyperlogics, for which we
provide new decidability and undecidability results

</details>


### [436] [On the Formal Metatheory of the Pure Type Systems using One-sorted Variable Names and Multiple Substitutions](https://arxiv.org/abs/2510.12300)
*Sebastián Urciuoli*

Main category: cs.LO

TL;DR: 我们使用 Agda 形式化了具有 Pi 类型的 Church 风格 lambda 演算的转换理论，并在没有识别 alpha-可转换 lambda 项的情况下进行了机器检查。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过使用常规语法和不识别 alpha-可转换 lambda 项来演示依赖类型理论的机械化是可行的。

Method: 使用 Agda 系统，我们为具有 Pi 类型的 Church 风格 lambda 项开发了转换的正式理论，使用单类变量名和 Stoughton 的多重替换。我们随后形式化了纯类型系统及其基本元理论性质，例如弱化、句法有效性、alpha-转换闭包和替换。

Result: 我们成功地形式化了具有 Pi 类型的 Church 风格 lambda 项的转换理论，并验证了其关键的元理论性质。我们的形式化与现有方法进行了比较，并使用 Agda 进行了机器检查。

Conclusion: 我们的工作证明了即使不识别 alpha-可转换 lambda 项，也可以使用常规语法来机械化依赖类型理论。

Abstract: We develop formal theories of conversion for Church-style lambda-terms with
Pi-types in first-order syntax using one-sorted variables names and Stoughton's
multiple substitutions. We then formalize the Pure Type Systems along some
fundamental metatheoretic properties: weakening, syntactic validity, closure
under alpha-conversion and substitution. Finally, we compare our formalization
with others related. The whole development has been machine-checked using the
Agda system. Our work demonstrates that the mechanization of dependent type
theory by using conventional syntax and without identifying alpha-convertible
lambda-terms is feasible.

</details>


### [437] [CoLF Logic Programming as Infinitary Proof Exploration](https://arxiv.org/abs/2510.12302)
*Zhibo Chen,Frank Pfenning*

Main category: cs.LO

TL;DR: 该研究提出了 CoLF$^\omega_1$，这是一个包含无穷对象和证明的一阶逻辑框架，并将逻辑变量解释为通信通道，计算解释为并发消息传递，并将其编译为 Sax 语言。


<details>
  <summary>Details</summary>
Motivation: 阐述了从早期的逻辑框架（如 Automath、LF）到支持无穷对象的 CoLF$^{\omega}$ 的演变，并在此基础上提出将计算视为证明构建，以及并发消息传递的思想。

Method: 提出了一种将 CoLF$^{\omega_1}$（CoLF$^{\omega}$ 的一阶片段）的计算视为证明构建的方法，其中逻辑变量被解释为通信通道，计算被实现为并发消息传递。该方法通过将 CoLF$^{\omega_1}$ 编译为基于证明归约的并行编程语言 Sax 来实现。

Result: 开发了一个将 CoLF$^{\omega_1}$ 编译为 Sax 的编译器，Sax 是一个受证明论启发的并行编程语言。

Conclusion: 该工作提出了在包含无穷对象和证明的一阶逻辑框架 CoLF$^{\omega_1}$ 上进行计算即证明构建的方法，并利用并发消息传递的范式，将其编译为并行编程语言 Sax。

Abstract: Logical Frameworks such as Automath [de Bruijn, 1968] or LF [Harper et al.,
1993] were originally conceived as metalanguages for the specification of
foundationally uncommitted deductive systems, yielding generic proof checkers.
Their high level of abstraction was soon exploited to also express algorithms
over deductive systems such as theorem provers, type-checkers, evaluators,
compilers, proof transformers, etc. in the paradigm of
computation-as-proof-construction. This has been realized in languages such as
$\lambda$-Prolog [Miller et al., 1991] or Elf [Pfenning, 1991] based on
backward chaining, and LolliMon [Lopez et al., 2005] or Celf [Schack-Nielsen
and Schuermann, 2008], which integrated forward chaining. None of these early
frameworks supported the direct expression of infinitary objects or proofs,
which are available in the recently developed CoLF$^\omega$ [Chen, 2023]. In
this work-in-progress report, we sketch an approach to
computation-as-proof-construction over the first-order fragment of
CoLF$^\omega$ (called CoLF$^\omega_1$ ) that already includes infinitary
objects and proofs. A key idea is the interpretation of logic variables as
communication channels and computation as concurrent message-passing. This is
realized in a concrete compiler from CoLF$^\omega_1$ to Sax, a
proof-theoretically inspired parallel programming language based on the
proof-reduction in the semi-axiomatic sequent calculus [DeYoung et al., 2020].

</details>


### [438] [Type Theory with Single Substitutions](https://arxiv.org/abs/2510.12303)
*Ambrus Kaposi,Szumi Xie*

Main category: cs.LO

TL;DR: Type theory can be viewed as a generalized algebraic theory, with existing algebraic definitions like CwFs and natural models. This paper introduces a single substitution calculus (SSC) as a simpler alternative to existing methods, proving its equivalence to CwF syntax for certain theories and demonstrating that SSC models can generate CwFs with additional type formers.


<details>
  <summary>Details</summary>
Motivation: The paper aims to provide a simpler, minimalistic alternative to existing formalisms for defining type theory, specifically parallel substitution calculi and B-systems. It seeks to establish a single substitution calculus (SSC) that is equivalent to the CwF syntax for theories with dependent function space and a hierarchy of universes, and can generate CwFs with additional type formers.

Method: The paper defines a single substitution calculus (SSC) and demonstrates its isomorphism to the CwF syntax for a specific type theory (dependent function space and a hierarchy of universes). It also shows that an SSC model can give rise to a CwF when additional type formers are present.

Result: The paper establishes that the SSC syntax is isomorphic to the CwF syntax for theories with dependent function space and a hierarchy of universes. It also shows that SSC models can give rise to CwFs when additional type formers are included.

Conclusion: The single substitution calculus (SSC) offers a simple, minimalistic alternative to parallel substitution calculi and B-systems for defining type theory. Its equivalence to CwF syntax and its ability to generate CwFs make it a valuable contribution to the field.

Abstract: Type theory can be described as a generalised algebraic theory. This
automatically gives a notion of model and the existence of the syntax as the
initial model, which is a quotient inductive-inductive type. Algebraic
definitions of type theory include Ehrhard's definition of model, categories
with families (CwFs), contextual categories, Awodey's natural models,
C-systems, B-systems. With the exception of B-systems, these notions are based
on a parallel substitution calculus where substitutions form a category. In
this paper we define a single substitution calculus (SSC) for type theory and
show that the SSC syntax and the CwF syntax are isomorphic for a theory with
dependent function space and a hierarchy of universes. SSC only includes single
substitutions and single weakenings, and eight equations relating these: four
equations describe how to substitute variables, and there are four equations on
types which are needed to typecheck the other equations. SSC provides a simple,
minimalistic alternative to parallel substitution calculi or B-systems for
defining type theory. SSC relates to CwF as extensional combinatory calculus
relates to lambda calculus: there are more models of the former, but the
syntaxes are equivalent. If we have some additional type formers, we show that
an SSC model gives rise to a CwF.

</details>


### [439] [Substitution Without Copy and Paste](https://arxiv.org/abs/2510.12304)
*Thorsten Altenkirch,Nathaniel Burke,Philip Wadler*

Main category: cs.LO

TL;DR: 该论文提出了一种避免重复的轻量级方法，用于定义带绑定符的语言（如简单类型λ演算）的替换，并构建了一个与初始简单类型范畴同构的具有范畴家族的范畴（CwF）。


<details>
  <summary>Details</summary>
Motivation: 为了验证带绑定符的语言（如简单类型λ演算）的范畴性质，需要重复定义替换和重命名，这会导致论证的冗余。

Method: 提出了一种轻量级方法，避免了在定义替换和重命名时的重复，并构建了一个具有范畴家族的范畴（CwF）。

Result: 成功构建了一个与初始简单类型CwF同构的简单类型CwF。

Conclusion: 所提出的轻量级方法能够有效避免冗余，并成功构建了所需的范畴结构。

Abstract: Defining substitution for a language with binders like the simply typed
$\lambda$-calculus requires repetition, defining substitution and renaming
separately. To verify the categorical properties of this calculus, we must
repeat the same argument many times. We present a lightweight method that
avoids repetition and that gives rise to a simply typed category with families
(CwF) isomorphic to the initial simply typed CwF. Our paper is a literate Agda
script.

</details>


### [440] [Dependently Sorted Nominal Signatures](https://arxiv.org/abs/2510.12305)
*Maribel Fernández,Miguel Pagano,Nora Szasz,Álvaro Tasistro*

Main category: cs.LO

TL;DR: 本文提出了一种扩展的名义多类型签名系统，引入了“广义凝结”作为消除算子，并使用尊重 α-转换的类型和类型族来分类表达式，构成了一个一阶依赖类型系统。该系统能表示多种演算的判断和推理规则，并为构建一个能完全形式化处理 α-等价的原始表达式的类型理论奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究一种扩展的名义多类型签名系统，旨在为处理具有 α-等价性的原始表达式提供一个完全形式化的理论基础。

Method: 本文提出了一种扩展的名义多类型签名系统，其中抽象具有实例化（广义凝结）的形式，作为消除算子。表达式使用尊重 α-转换的类型和类型族进行分类。该系统构成了一个一阶依赖类型系统。

Result: 该系统能够表示多种有趣演算的判断和推理形式，并给出了系统的规则、性质以及表示的实验。

Conclusion: 本文提出的系统构成了一个基础，可以在此基础上构建一个能够完全形式化处理具有 α-等价性的原始表达式的类型理论。

Abstract: We investigate an extension of nominal many-sorted signatures in which
abstraction has a form of instantiation, called generalised concretion, as
elimination operator (similarly to lambda-calculi). Expressions are then
classified using a system of sorts and sort families that respects
alpha-conversion (similarly to dependently-typed lambda-calculi) but not
allowing names to carry abstraction sorts, thus constituting a first-order
dependent sort system. The system can represent forms of judgement and rules of
inference of several interesting calculi. We present rules and properties of
the system as well as experiments of representation, and discuss how it
constitutes a basis on which to build a type theory where raw expressions with
alpha-equivalence are given a completely formal treatment.

</details>


### [441] [Proceedings of the International Workshop on Verification of Scientific Software](https://arxiv.org/abs/2510.12314)
*Stephen F. Siegel,Ganesh Gopalakrishnan*

Main category: cs.LO

TL;DR: VSS 2025 论文集，探讨科学软件的正确性和可靠性，涵盖演绎验证、浮点数错误分析、耦合模型规范和面向领域的测试等主题。


<details>
  <summary>Details</summary>
Motivation: 确保大型科学代码的正确性和可靠性，并促进软件验证和科学计算领域研究人员之间的合作。

Method: 通过同行评审的论文、特邀报告和挑战性问题来展示软件验证领域的最新进展和解决方案。

Result: 展示了演绎验证、浮点数错误分析、耦合模型规范和面向领域的测试等主题的广泛观点、问题和正在进行的解决方案。

Conclusion: VSS 2025 提供了科学软件验证领域的一个快照，并为整合不同的验证工具以协同工作提供了潜力。

Abstract: This volume contains the proceedings of the Verification of Scientific
Software (VSS 2025) workshop, held on 4 May 2025 at McMaster University,
Canada, as part of ETAPS 2025. VSS brings together researchers in software
verification and scientific computing to address challenges in ensuring the
correctness and reliability of large-scale scientific codes. The program
featured five peer-reviewed papers, three invited contributions, and a set of
challenge problems, covering themes such as deductive verification,
floating-point error analysis, specification of coupled models, and
domain-aware testing. VSS builds on the Correctness Workshop series at
Supercomputing and the 2023 NSF/DOE report on scientific software correctness.
It serves as yet another snapshot of this important area, showcasing a wide
range of perspectives, problems and their solutions in progress, with the
challenge problems having the potential to bring together separate verification
tools into concerted action.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [442] [Thin Trees via $k$-Respecting Cut Identities](https://arxiv.org/abs/2510.12050)
*Mohit Daga*

Main category: cs.DS

TL;DR: 该论文提出了一种新的方法来验证图中的“薄生成树”，并解决了长期的“薄树猜想”。


<details>
  <summary>Details</summary>
Motivation: 验证生成树的“薄度”是一个长期存在的难题，因为这需要考虑指数数量的割集，并且缺乏有效的证书。

Method: 论文引入了“k-约束割集恒等式”的新机制，将穿越生成树的割集权重表示为两两割集的函数。在此基础上，开发了一个可以在O(n^2)预处理后，在O_k(1)时间内评估这些割集的本地预言机。该预言机可以计算任何生成树的精确k-薄度证书Θ_k(T)，并给出证明其有效性的割集。

Result: 该方法首次实现了在固定k下，在~O(n^2+n^k)时间内计算生成树的精确k-薄度证书。对于平面图，证明了任何生成树都存在一个可验证的证书Θ_k(T)<=k/λ（因此k为常数时为O(1/λ)）。对于嵌入在亏格为γ的曲面上的图，给出了O((log n+γ)/λ)的认证界限。

Conclusion: 该论文提出的新机制和算法，为解决图论中的“薄树猜想”提供了新的工具和见解，并在特定图结构（如平面图和曲面嵌入图）上取得了更优越的性能保证。

Abstract: Thin spanning trees lie at the intersection of graph theory, approximation
algorithms, and combinatorial optimization. They are central to the
long-standing \emph{thin tree conjecture}, which asks whether every
$k$-edge-connected graph contains an $O(1/k)$-thin tree, and they underpin
algorithmic breakthroughs such as the $O(\log n/\log\log n)$-approximation for
ATSP. Yet even the basic algorithmic task of \emph{verifying} that a given tree
is thin has remained elusive: checking thinness requires reasoning about
exponentially many cuts, and no efficient certificates have been known.
  We introduce a new machinery of \emph{$k$-respecting cut identities}, which
express the weight of every cut that crosses a spanning tree in at most $k$
edges as a simple function of pairwise ($2$-respecting) cuts. This yields a
tree-local oracle that, after $O(n^2)$ preprocessing, evaluates such cuts in
$O_k(1)$ time. Building on this oracle, we give the first procedure to compute
the exact $k$-thinness certificate $\Theta_k(T)$ of any spanning tree for fixed
$k$ in time $\tilde O(n^2+n^k)$, outputting both the certificate value and a
witnessing cut.
  Beyond general graphs, our framework yields sharper guarantees in structured
settings. In planar graphs, duality with cycles and dual girth imply that every
spanning tree admits a verifiable certificate $\Theta_k(T)\le k/\lambda$ (hence
$O(1/\lambda)$ for constant $k$). In graphs embedded on a surface of genus
$\gamma$, refined counting gives certified (per-cut) bounds $O((\log
n+\gamma)/\lambda)$ via the same ensemble coverage.

</details>


### [443] [Engineering Dominating Patterns: A Fine-grained Case Study](https://arxiv.org/abs/2510.12232)
*Jonathan Dransfeld,Marvin Künnemann,Mirza Redzic,Marcus Wunderlich*

Main category: cs.DS

TL;DR: 该研究旨在解决Dominating H-Pattern问题，并提出了一种高效的Branch-and-Bound算法，在稀疏图上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索在稀疏图上高效解决Dominating H-Pattern问题的可能性，并与现有求解器进行对比。

Method: 研究方法包括开发并实验评估了多种方法，包括基于 Glasgow Subgraph Solver (GSS)、SAT solver Kissat 和 ILP solver Gurobi 的基线方法，以及一种定制的、带有剪枝技术的Branch-and-Bound方法。

Result: 实验结果表明，所提出的Branch-and-Bound方法在测试实例上比现有求解器有高达两个数量级的性能提升。

Conclusion: 研究结论是，定制的Branch-and-Bound方法在解决Dominating H-Pattern问题上，尤其是在稀疏图上，比现有求解器更有效。

Abstract: The \emph{Dominating $H$-Pattern} problem generalizes the classical
$k$-Dominating Set problem: for a fixed \emph{pattern} $H$ and a given graph
$G$, the goal is to find an induced subgraph $S$ of $G$ such that (1) $S$ is
isomorphic to $H$, and (2) $S$ forms a dominating set in $G$. Fine-grained
complexity results show that on worst-case inputs, any significant improvement
over the naive brute-force algorithm is unlikely, as this would refute the
Strong Exponential Time Hypothesis. Nevertheless, a recent work by Dransfeld et
al. (ESA 2025) reveals some significant improvement potential particularly in
\emph{sparse} graphs.
  We ask: Can algorithms with conditionally almost-optimal worst-case
performance solve the Dominating $H$-Pattern, for selected patterns $H$,
efficiently on practical inputs? We develop and experimentally evaluate several
approaches on a large benchmark of diverse datasets, including baseline
approaches using the Glasgow Subgraph Solver (GSS), the SAT solver Kissat, and
the ILP solver Gurobi.
  Notably, while a straightforward implementation of the algorithms -- with
conditionally close-to-optimal worst-case guarantee -- performs comparably to
existing solvers, we propose a tailored Branch-\&-Bound approach --
supplemented with careful pruning techniques -- that achieves improvements of
up to two orders of magnitude on our test instances.

</details>


### [444] [Exact Matching and Top-k Perfect Matching Parameterized by Neighborhood Diversity or Bandwidth](https://arxiv.org/abs/2510.12552)
*Nicolas El Maalouly,Kostas Lakis*

Main category: cs.DS

TL;DR: 本篇论文研究了图匹配问题（Exact Matching, EM）和 Top-k Perfect Matching（TkPM），特别是在“膨胀图”上的情况。论文提出了一种针对 TkPM 的固定参数可 FPT 算法，参数为 k 和邻域多样性。此外，还提出了一个近似方案和一个适用于有界带宽但无界大小原型的递归算法，该算法能在亚指数时间内运行。最后，利用 EM 的算法，该递归算法也被应用于 EM 问题。


<details>
  <summary>Details</summary>
Motivation: EM 问题在完美匹配中要求使用特定数量的红边，目前只有一些特殊情况存在确定性多项式时间算法，使其成为检验 P=RP 猜想的候选问题。TkPM 问题是 EM 的一个多项式时间等价问题，旨在找到一个完美匹配，使得 k 条最重边的权重最大化。本研究主要关注 TkPM 问题在膨胀图上的表现。

Method: 论文提出了一种针对 TkPM 的 FPT 算法，其参数为 k 和输入图的邻域多样性（即膨胀前的图的大小）。该算法被扩展为一个近似方案，其参数依赖性大大减弱。对于有界带宽但无界大小的原型图，论文开发了一个运行时间为亚指数的递归算法。最后，利用一个已有的处理有界邻域多样性图的 EM 算法，该递归算法也被改编用于 EM 问题。

Result: 论文提出了一种针对 TkPM 的 FPT 算法，其参数为 k 和邻域多样性。此外，还提出了一个近似方案和一个适用于有界带宽但无界大小原型的递归算法，该算法能在亚指数时间内运行。最后，该递归算法也被应用于 EM 问题。

Conclusion: 本研究通过利用动态规划的思想，特别是利用了多条不相交分离器的存在性，成功地为膨胀图上的 TkPM 和 EM 问题设计了高效算法，包括 FPT 算法、近似方案和亚指数时间算法。

Abstract: The Exact Matching (EM) problem asks whether there exists a perfect matching
which uses a prescribed number of red edges in a red/blue edge-colored graph.
While there exists a randomized polynomial-time algorithm for the problem, only
some special cases admit a deterministic one so far, making it a natural
candidate for testing the P=RP hypothesis. A polynomial-time equivalent
problem, Top-k Perfect Matching (TkPM), asks for a perfect matching maximizing
the weight of the $k$ heaviest edges.
  We study the above problems, mainly the latter, in the scenario where the
input is a blown-up graph, meaning a graph which had its vertices replaced by
cliques or independent sets. We describe an FPT algorithm for TkPM
parameterized by $k$ and the neighborhood diversity of the input graph, which
is essentially the size of the graph before the blow-up; this graph is also
called the prototype. We extend this algorithm into an approximation scheme
with a much softer dependency on the aforementioned parameters, time-complexity
wise. Moreover, for prototypes with bounded bandwidth but unbounded size, we
develop a recursive algorithm that runs in subexponential time. Utilizing
another algorithm for EM on bounded neighborhood diversity graphs, we adapt
this recursive subexponential algorithm to EM.
  Our approach is similar to the use of dynamic programming on e.g. bounded
treewidth instances for various problems. The main point is that the existence
of many disjoint separators is utilized to avoid including in the separator any
of a set of ``bad'' vertices during the split phase.

</details>


### [445] [Lossless Derandomization for Undirected Single-Source Shortest Paths and Approximate Distance Oracles](https://arxiv.org/abs/2510.12598)
*Shuyi Yan*

Main category: cs.DS

TL;DR: 我们提出了一种新的确定性算法，该算法可以实现最优的平均球体大小，并能以平均最优成本处理可变球体大小。这使得我们能够确定性地推导 DMSY23 和 Thorup-Zwick 的近似距离预言机算法，而不会在时间和空间复杂度上有所损失。


<details>
  <summary>Details</summary>
Motivation: 现有的图算法（如单源最短路径）中，通常需要选择一组顶点作为中心，然后以中心为起点生长“球体”，直到触及另一个中心。当前算法的瓶颈在于，随机化算法虽然能获得最优的期望球体大小，但其确定化过程会引入额外的对数因子，导致算法在稀疏图上不如 Dijkstra 算法高效。此外，现有的方法无法处理可变大小的球体，这限制了其在更复杂场景下的应用。

Method: 本文提出了一种新的确定性算法，该算法利用了球体大小可以被算法自适应选择这一事实。通过一种简单的确定性方法，我们能够实现最优的平均球体大小（$
Theta(n/r)$）。更进一步，该算法能够处理任何多项式意义上的球体大小成本函数，并实现平均最优成本。该技术还可用于确定化 Thorup-Zwick 的近似距离预言机。

Result: 通过该算法，我们成功地确定性地推导了 DMSY23 算法，得到了一种确定性的、在稀疏图上优于 Dijkstra 算法的单源最短路径算法，其复杂度为 $O(m
Theta(
u)
u)$。此外，该算法在不损失时间/空间复杂度的情况下，也成功地确定化了 Thorup-Zwick 的近似距离预言机。

Conclusion: 本文提出的确定性算法在处理图中心选择和球体生长问题上取得了突破性进展。它不仅解决了现有算法在确定化过程中引入的对数因子问题，实现了最优的平均球体大小和成本，而且为确定性地实现复杂的图算法（如单源最短路径和近似距离预言机）提供了新的途径。

Abstract: A common step in algorithms related to shortest paths in undirected graphs is
that, we select a subset of vertices as centers, then grow a ball around each
vertex until a center is reached. We want the balls to be as small as possible.
A randomized algorithm can uniformly sample $r$ centers to achieve the optimal
(expected) ball size of $\Theta(n/r)$. A folklore derandomization is to use the
$O(\log n)$ approximation for the set cover problem in the hitting set version
where we want to hit all the balls with the centers.
  However, the extra $O(\log n)$ factor is sometimes too expensive. For
example, the recent $O(m\sqrt{\log n\log\log n})$ undirected single-source
shortest path algorithm [DMSY23] beats Dijkstra's algorithm in sparse graphs,
but the folklore derandomization would make it dominated by Dijkstra's.
  In this paper, we exploit the fact that the sizes of these balls can be
adaptively chosen by the algorithm instead of fixed by the input. We propose a
simple deterministic algorithm achieving the optimal ball size of $\Theta(n/r)$
on average. Furthermore, given any polynomially large cost function of the ball
size, we can still achieve the optimal cost on average. It allows us to
derandomize [DMSY23], resulting in a deterministic $O(m\sqrt{\log n\log\log
n})$ algorithm for undirected single-source shortest path.
  In addition, we show that the same technique can also be used to derandomize
the seminal Thorup-Zwick approximate distance oracle [TZ05], also without any
loss in the time/space complexity.

</details>


### [446] [Edge-weighted Online Stochastic Matching: Beating $1-\frac1e$](https://arxiv.org/abs/2210.12543)
*Shuyi Yan*

Main category: cs.DS

TL;DR: 本文提出了一个改进的在线随机匹配算法，其竞争比率达到了0.645，优于之前0.368（1-1/e）的基准。


<details>
  <summary>Details</summary>
Motivation: 在线随机匹配问题，特别是边加权情况下的匹配问题，在已有算法（Suggested Matching）的竞争比率（1-1/e）未被打破的情况下，需要新的算法来提升性能。

Method: 设计了一种算法预处理，将边分为两类，并根据Jaillet和Lu提出的LP进行调整。该算法在早期和晚期分别优化不同类别的匹配，同时保持匹配事件的独立性，最终保证每个匹配的概率。

Result: 该算法实现了0.645的竞争比率，首次打破了先前在线边加权随机匹配问题1-1/e的基准。

Conclusion: 通过对在线边加权随机匹配问题的深入研究和新颖的算法设计，我们成功地将竞争比率提升至0.645，为该领域的研究提供了新的方向和可能。

Abstract: We study the edge-weighted online stochastic matching problem. Since Feldman,
Mehta, Mirrokni, and Muthukrishnan proposed the $(1-\frac1e)$-competitive
Suggested Matching algorithm, there has been no improvement for the general
edge-weighted online stochastic matching problem. In this paper, we introduce
the first algorithm beating the $1-\frac1e$ barrier in this setting, achieving
a competitive ratio of $0.645$. Under the LP proposed by Jaillet and Lu, we
design an algorithmic preprocessing, dividing all edges into two classes. Then
based on the Suggested Matching algorithm, we adjust the matching strategy to
improve the performance on one class in the early stage and on another class in
the late stage, while keeping the matching events of different edges highly
independent. By balancing them, we finally guarantee the matched probability of
every single edge.

</details>


### [447] [Vizing's Theorem in Deterministic Almost-Linear Time](https://arxiv.org/abs/2510.12619)
*Sepehr Assadi,Soheil Behnezhad,Sayan Bhattacharya,Martín Costa,Shay Solomon,Tianyi Zhang*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vizing's theorem states that any $n$-vertex $m$-edge graph of maximum degree
$\Delta$ can be edge colored using at most $\Delta + 1$ different colors.
Vizing's original proof is easily translated into a deterministic $O(mn)$ time
algorithm. This deterministic time bound was subsequently improved to $\tilde
O(m \sqrt n)$ time, independently by [Arjomandi, 1982] and by [Gabow et al.,
1985].
  A series of recent papers improved the time bound of $\tilde O(m\sqrt{n})$
using randomization, culminating in the randomized near-linear time
$(\Delta+1)$-coloring algorithm by [Assadi, Behnezhad, Bhattacharya, Costa,
Solomon, and Zhang, 2025]. At the heart of all of these recent improvements,
there is some form of a sublinear time algorithm. Unfortunately, sublinear time
algorithms as a whole almost always require randomization. This raises a
natural question: can the deterministic time complexity of the problem be
reduced below the $\tilde O(m\sqrt{n})$ barrier?
  In this paper, we answer this question in the affirmative. We present a
deterministic almost-linear time $(\Delta+1)$-coloring algorithm, namely, an
algorithm running in $m \cdot 2^{O(\sqrt{\log \Delta})} \cdot \log n =
m^{1+o(1)}$ time. Our main technical contribution is to entirely forego
sublinear time algorithms. We do so by presenting a new deterministic
color-type sparsification approach that runs in almost-linear (instead of
sublinear) time, but can be used to color a much larger set of edges.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [448] [GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality](https://arxiv.org/abs/2510.11878)
*Anastasiya Pechko,Piotr Borycki,Joanna Waczyńska,Daniel Barczyk,Agata Szymańska,Sławomir Tadeja,Przemysław Spurek*

Main category: cs.GR

TL;DR: 本研究提出了一种名为 GAVERSE 的新方法，该方法将高斯喷溅（GS）与 3D 网格相结合，以实现更真实、更直观的虚拟现实（VR）交互。


<details>
  <summary>Details</summary>
Motivation: 当前 VR 中操纵 3D 内容的方法存在工程复杂、几何表示简化（如四面体笼）导致视觉保真度和物理准确性受损等局限性。

Method: GAVERSE（Gaussian Splatting for Virtual Environment Rendering and Scene Editing）将对象的网格与其高斯喷溅（GS）表示直接集成，实现了更精确的表面近似，从而能够进行真实变形和交互。该方法可利用现有 3D 网格资源，并支持物理引擎无关的部署。

Result: 与现有结合 VR 和 GS 的技术相比，GAVERSE 在用户研究中被证明在物理感知拉伸操纵方面具有统计学上的显著优势，并且在扭曲和摇晃等其他物理操纵方面也更一致。在各种交互和场景的进一步评估中，证明了该方法具有持续的高可靠性性能。

Conclusion: GAVERSE 作为一种直接集成网格和高斯喷溅的方法，为 VR 中的交互式 3D 操纵提供了一种高度逼真、适应性强且直观的解决方案，可以作为现有方法的可靠替代方案。

Abstract: As the demand for immersive 3D content grows, the need for intuitive and
efficient interaction methods becomes paramount. Current techniques for
physically manipulating 3D content within Virtual Reality (VR) often face
significant limitations, including reliance on engineering-intensive processes
and simplified geometric representations, such as tetrahedral cages, which can
compromise visual fidelity and physical accuracy. In this paper, we introduce
\our{} (\textbf{G}aussian \textbf{S}platting for \textbf{V}irtual
\textbf{E}nvironment \textbf{R}endering and \textbf{S}cene \textbf{E}diting), a
novel method designed to overcome these challenges by directly integrating an
object's mesh with a Gaussian Splatting (GS) representation. Our approach
enables more precise surface approximation, leading to highly realistic
deformations and interactions. By leveraging existing 3D mesh assets, \our{}
facilitates seamless content reuse and simplifies the development workflow.
Moreover, our system is designed to be physics-engine-agnostic, granting
developers robust deployment flexibility. This versatile architecture delivers
a highly realistic, adaptable, and intuitive approach to interactive 3D
manipulation. We rigorously validate our method against the current
state-of-the-art technique that couples VR with GS in a comparative user study
involving 18 participants. Specifically, we demonstrate that our approach is
statistically significantly better for physics-aware stretching manipulation
and is also more consistent in other physics-based manipulations like twisting
and shaking. Further evaluation across various interactions and scenes confirms
that our method consistently delivers high and reliable performance, showing
its potential as a plausible alternative to existing methods.

</details>


### [449] [Coordinate Condensation: Subspace-Accelerated Coordinate Descent for Physics-Based Simulation](https://arxiv.org/abs/2510.12053)
*Ty Trusty*

Main category: cs.GR

TL;DR: Coordinate Condensation通过结合基于Schur补的子空间校正来加速基于物理的仿真，并在保持坐标下降的效率和并行性的同时实现近乎牛顿的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 加速基于物理的仿真，并克服现有方法（如Lan等人2025年的JGS2）的收敛性限制。

Method: Coordinate Condensation，一种坐标下降的变体，通过将局部坐标更新与基于Schur补的子空间校正相结合来加速仿真。它独立求解局部和子空间位移，消除了JGS2方法中的阻尼效应。

Result: 在不同材料刚度和网格分辨率的实验中，证明了比标准坐标下降和JGS2更快的收敛速度。此外，还分析了基于子空间的坐标方法何时成功或失败。

Conclusion: Coordinate Condensation是一种有前景的加速仿真方法，在某些情况下可实现近乎牛顿的收敛速度，同时保持坐标下降的优点。该研究还为未来的求解器设计提供了见解。

Abstract: We introduce Coordinate Condensation, a variant of coordinate descent that
accelerates physics-based simulation by augmenting local coordinate updates
with a Schur-complement-based subspace correction. Recent work by Lan et al.
2025 (JGS2) uses perturbation subspaces to augment local solves to account for
global coupling, but their approach introduces damping that can degrade
convergence. We reuse this subspace but solve for local and subspace
displacements independently, eliminating this damping. For problems where the
subspace adequately captures global coupling, our method achieves near-Newton
convergence while retaining the efficiency and parallelism of coordinate
descent. Through experiments across varying material stiffnesses and mesh
resolutions, we show substantially faster convergence than both standard
coordinate descent and JGS2. We also characterize when subspace-based
coordinate methods succeed or fail, offering insights for future solver design.

</details>


### [450] [Can Representation Gaps Be the Key to Enhancing Robustness in Graph-Text Alignment?](https://arxiv.org/abs/2510.12087)
*Heng Zhang,Tianyi Zhang,Yuling Shi,Xiaodong Gu,Yaomin Shen,Zijian Zhang,Yilei Yuan,Hao Zhang,Jin Huang*

Main category: cs.GR

TL;DR: 表示学习在文本属性图（TAGs）上的应用，但现有方法（如对比学习）假设图文表示的紧密耦合能提升性能，实则不然。研究发现，过度的图文对齐会破坏预训练知识结构，损害泛化能力，因为图编码器关注拓扑模式，而文本编码器关注语义结构，两者几何不兼容。为此，提出LLM4GTA框架，通过自适应差距保持模块和类内补偿机制，在保持模态特定知识的同时提升模型性能，在零样本和少样本场景下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本属性图（TAGs）表示学习方法倾向于通过对比学习来最大化图文表示的相似性，但实证分析表明，这种做法（无论是自然的差距扩大还是强制的差距缩小）都会损害模型的泛化能力，因为图编码器和文本编码器在几何上不兼容，过度的对齐会导致表示空间塌陷，破坏模态特定的知识。因此，需要一种新的方法来解决这种几何不兼容性，并提升模型性能。

Method: 提出LLM4GTA框架，该框架采用“差距感知对齐”策略。具体包括：1. 自适应差距保持模块：通过监控图文表示相似度的演变，防止因过度对齐而导致的表示空间塌陷。2. 类内补偿机制：利用图空间中的辅助分类器来增强表示的区分能力，弥补潜在的性能损失。

Result: LLM4GTA框架在零样本和少样本场景下，相比于现有方法，在多个下游任务上取得了显著的性能提升，证明了其在处理图文表示的几何不兼容性方面的有效性。

Conclusion: LLM4GTA通过其差距感知对齐方法，成功解决了文本属性图（TAGs）表示学习中的图文表示几何不兼容问题。通过显式地保持表示差距，该框架能够保留模态特定的知识，从而在零样本和少样本设置下显著提高模型的迁移性能。

Abstract: Representation learning on text-attributed graphs (TAGs) integrates
structural connectivity with rich textual semantics, enabling applications in
diverse domains. Current methods largely rely on contrastive learning to
maximize cross-modal similarity, assuming tighter coupling between graph and
text representations improves transfer performance. However, our empirical
analysis reveals that both natural gap expansion and forced gap reduction
result in performance degradation by disrupting pre-trained knowledge
structures and impairing generalization. This arises from the geometric
incompatibility between encoders, where graph encoders capture topological
patterns, while text encoders capture semantic structures. Over-alignment
compresses these distinct spaces into shared subspaces, causing structure
collapse that diminishes both topological reasoning and semantic understanding.
We propose \textbf{LLM4GTA}, a gap-aware alignment framework that preserves
representation gaps as geometric necessities for maintaining modality-specific
knowledge and improving transfer performance. LLM4GTA includes an adaptive gap
preservation module to prevent over-alignment by monitoring similarity
evolution and an intra-modal compensation mechanism that boosts discriminative
power using auxiliary classifiers in graph space. Extensive experiments show
significant improvements over existing methods in zero-shot and few-shot
scenarios.

</details>


### [451] [SDGraph: Multi-Level Sketch Representation Learning by Sparse-Dense Graph Architecture](https://arxiv.org/abs/2510.12192)
*Xi Cheng,Pingfa Feng,Zhichao Liao,Mingyu Fan,Long Zeng*

Main category: cs.GR

TL;DR: 为解决手绘草图信息利用不足的问题，提出了多层次草图表示方案，并基于此设计了SDGraph深度学习架构，在分类、检索和生成任务上均取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 手绘草图具有独特的稀疏性和抽象性，需要不同于图像的学习方法。现有研究对构成有效草图信息的要素关注不足，限制了模型性能。

Method: 提出了多层次草图表示方案（草图-、笔画-、点-三个层面），并基于此设计了SDGraph深度学习架构，包含稀疏图和稠密图两个模块，利用图卷积、下采样和上采样操作进行特征提取，并通过信息融合模块增强效果。

Result: 在草图分类和检索任务上分别超越现有方法1.15%和1.70%，在矢量草图生成质量上提升36.58%。

Conclusion: 多层次草图表示方案和SDGraph架构能有效利用手绘草图的有效信息，显著提升了草图相关任务的性能。

Abstract: Freehand sketches exhibit unique sparsity and abstraction, necessitating
learning pipelines distinct from those designed for images. For sketch learning
methods, the central objective is to fully exploit the effective information
embedded in sketches. However, there is limited research on what constitutes
effective sketch information, which in turn constrains the performance of
existing approaches. To tackle this issue, we first proposed the Multi-Level
Sketch Representation Scheme to systematically identify the effective
information. The scheme organizes sketch representation into three levels:
sketch-level, stroke-level, and point-level. This design is based on the
granularity of analytical elements, from coarse (sketch-level) to fine
(point-level), thereby ensuring more comprehensive coverage of the sketch
information. For each level, we conducted theoretical analyses and experimental
evaluations to identify and validate the effective information. Building on the
above studies, we developed SDGraph, a deep learning architecture designed to
exploit the identified effective information across the three levels. SDGraph
comprises two complementary modules: a Sparse Graph that treats strokes as
nodes for sketch-level and stroke-level representation learning, and a Dense
Graph that treats points as nodes for sketch-level and point-level
representation learning. Both modules employ graph convolution along with
down-sampling and up-sampling operations, enabling them to function as both
encoder and decoder. Besides that, an information fusion module bridges the two
graphs to further enhance feature extraction. SDGraph supports a wide range of
sketch-related downstream tasks, achieving accuracy improvements of 1.15\% and
1.70\% over the state-of-the-art in classification and retrieval, respectively,
and 36.58\% improvement in vector sketch generation quality.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [452] [Magnetometry with Broadband Microwave Fields in Nitrogen-Vacancy Centers in Diamond](https://arxiv.org/abs/2510.11720)
*Arezoo Afshar,Andrew Proppe,Noah Lupu-Gladstein,Lilian Childress,Aaron Z. Goldberg,Khabat Heshami*

Main category: cond-mat.mes-hall

TL;DR: NV 传感器可用于测量磁场，结合宽带微波和机器学习/最大似然估计，可实现 pT/sqrt(Hz) 级别的灵敏度，并有潜力实现矢量磁场检测。


<details>
  <summary>Details</summary>
Motivation: 利用金刚石中的氮-空位（NV）中心作为光与物质的接口，开发一种新的磁场传感方法，实现高灵敏度和实时监测。

Method: 使用宽带微波脉冲同时探测NV中心的磁敏态，并利用最大似然估计（基于最小化Kullback-Leibler散度）和神经网络模型分析透射微波信号的时间特征，以估计外部直流磁场强度。

Result: 所提出的方法实现了低于 1 nT/sqrt(Hz) 的磁场测量灵敏度，并且该结果是在未优化微波场参数（如带宽、功率和形状）的情况下获得的。

Conclusion: NV中心结合宽带微波和先进的信号处理技术（如最大似然估计和神经网络），为实现高灵敏度（可达 pT/sqrt(Hz)）、高频（1-10 kHz 更新率）和矢量磁场检测提供了新的途径，且无需外部偏置磁场。

Abstract: Nitrogen vacancy (NV) centers in diamond are optically addressable and
versatile light-matter interfaces with practical application in magnetic field
sensing, offering the ability to operate at room temperature and reach
sensitivities below pT/$\sqrt{\mathrm{Hz}}.$ We propose an approach to
simultaneously probe all of the magnetically sensitive states using a broadband
microwave field and demonstrate that it can be used to measure the external DC
magnetic field strength with sensitivities below 1~nT/$\sqrt{\mathrm{Hz}}.$ We
develop tools for analyzing the temporal signatures in the transmitted
broadband microwaves to estimate the magnetic field, comparing maximum
likelihood estimation based on minimizing the Kullback-Leibler divergence to
various neural network models, and both methods independently reach practical
sensitivities. These results are achieved without optimizing parameters such as
the bandwidth, power, and shape of the probing microwave field such that, with
further improvements, sensitivities down to $\mathrm{pT/\sqrt{Hz}}$ can be
envisioned. Our results motivate novel implementations of NV-based magnetic
sensors with the potential for vectorial magnetic field detection at 1-10 kHz
update rates and improved sensitivities without requiring a bias magnetic
field.

</details>


### [453] [Influence of Platinum Thin Films on the Photophysical and Quantum Properties of Near-Surface NV Centers](https://arxiv.org/abs/2510.11721)
*Joachim P. Leibold,Lina M. Todenhagen,Matthias Althammer,Nikhita Khera,Elke Neu,Martin S. Brandt,Hans Huebl,Dominik B. Bucher*

Main category: cond-mat.mes-hall

TL;DR: 铂薄膜会影响金刚石中NV色心的量子传感能力，但通过优化氮注入能量（至少20 keV），可以提高相干时间。


<details>
  <summary>Details</summary>
Motivation: 研究铂膜与金刚石中NV色心相互作用，以了解其对量子传感能力的影响。

Method: 研究了五种不同能量（2.5-60 keV）氮注入产生的浅层NV色心的铂覆盖金刚石样品，并研究了NV系综的光学和量子性质。

Result: 发现NV色心的光致发光寿命显著缩短，NV$^{-}$数量减少。然而，在至少20 keV的注入能量下，在铂薄膜下方观察到了T$_{2}$相干时间的显著增加。

Conclusion: 铂薄膜会影响NV色心近表面的量子传感能力，通过优化氮注入能量（至少20 keV）可以在一定程度上提高相干时间，为金属薄膜与近表面NV色心的集成提供了指导。

Abstract: Nitrogen-vacancy (NV) centers in diamond are optically addressable spin
defects with great potential for nanoscale quantum sensing. A key application
of NV centers is the detection of external spins at the diamond surface. Among
metals, platinum thin films - widely used in spintronics, catalysis and
electrochemistry - provide a particularly interesting system for such studies.
However, the interaction between NV centers and metals is known to affect their
quantum sensing capabilities. In this work, we study five platinum-covered
diamond samples containing shallow NVs created via nitrogen implantation with
different energies (2.5-60 keV) and investigate the optical and quantum
properties of NV ensembles beneath the metal films. We find a substantial
reduction of the photoluminescence lifetime and a pronounced decrease of the
NV$^{-}$ population for NV ensembles located near the platinum layer. As a
result, optically detected magnetic resonance experiments could only be
efficiently performed on diamonds implanted with at least 20 keV, where we
observed a strong increase in the T$_{2}$ coherence time beneath the platinum
thin films. Our study describes the various processes affecting NV centers near
platinum films and provides guidance for the integration of thin metal films
with near-surface NV centers.

</details>


### [454] [Topological Robustness of Anyon Tunneling at $ν= 1/3$](https://arxiv.org/abs/2510.11860)
*Adithya Suresh,Ramon Guerrero-Suarez,Tanmay Maiti,Shuang Liang,Geoffrey Gardner,Claudio Chamon,Michael Manfra*

Main category: cond-mat.mes-hall

TL;DR: The fractional quantum Hall state at $
u=1/3$ exhibits a topologically robust chiral Luttinger liquid at its boundary, as evidenced by consistent scaling exponent $g=1/3$ in tunneling conductance measurements, even under perturbations like weak disorder.


<details>
  <summary>Details</summary>
Motivation: To probe the topological robustness of the chiral Luttinger liquid at the boundary of the $
u=1/3$ fractional quantum Hall state by measuring the tunneling conductance.

Method: Measured tunneling conductance between counterpropagating edge modes as a function of quantum point contact transmission and analyzed the scaling exponent.

Result: Tunneling conductance is well-described by $g=1/3$ for transmission $t																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																													G $t 
otin [0.7, 1]$ 仍然得到 $g=1/3$，表明在 $
u=1/3$ 状态下，只要体相没有变得可压缩，边带模式的拓扑保护就足够鲁棒。

Conclusion: 实验结果证实了 $
u=1/3$ 分数量子霍尔效应状态下任意子隧穿的拓扑鲁棒性，并支持了关于边带模式的چیرال لوتینگر لیکید 描述。

Abstract: The scaling exponent $g$ of the quasiparticle propagator for incompressible
fractional quantum Hall states in the Laughlin sequence is expected to be
robust against perturbations that do not close the gap. Here we probe the
topological robustness of the chiral Luttinger liquid at the boundary of the
$\nu=1/3$ state by measuring the tunneling conductance between
counterpropagating edge modes as a function of quantum point contact
transmission. We demonstrate that for transmission $t\geq 0.7$ the tunneling
conductance is well-described by the first two terms of a perturbative series
expansion corresponding to $g=1/3$. We further demonstrate that the measured
scaling exponent is robustly pinned to $g=1/3$ across the plateau, only
deviating as the bulk state becomes compressible. Finally we examine the impact
of weak disorder on the scaling exponent, finding it insensitive. These
measurements firmly establish the topological robustness of anyon tunneling at
$\nu=1/3$ and substantiate the chiral Luttinger liquid description of the edge
mode.

</details>


### [455] [Neuromorphic heat transport effects in a molecular junction](https://arxiv.org/abs/2510.11870)
*Renai Chen,Galen T. Craven*

Main category: cond-mat.mes-hall

TL;DR: 分子结在时间依赖的温度梯度下表现出热量传输滞后现象，这对于设计热神经形态计算机至关重要。


<details>
  <summary>Details</summary>
Motivation: 理解分子科学中能量在纳米尺度上的传输，对设计新电子学、计算设备和材料具有直接意义。尽管稳态下的能量传输已得到广泛研究，但在远离平衡的动态驱动力下，尤其是时间依赖性驱动力下的能量传输研究尚不充分。

Method: 使用非平衡分子动力学模拟和随机热力学来研究分子结在时间周期性温度梯度下的能量传输。

Result: 观察到分子结可以表现出热量传输滞后现象，即热通量不仅取决于瞬时温度偏差值，还取决于该偏差的时间历史。

Conclusion: 分子结可表现出对热神经形态计算机至关重要的特定记忆效应（热量传输滞后），为实现此类设备提供了潜在途径。

Abstract: Understanding energy transport at the nanoscale is an open and fundamental
challenge in the molecular sciences with direct implications for the design of
new electronics, computing devices, and materials. While nanoscale energy
transport under steady-state conditions has been studied extensively, there is
much less known about energy transport under time-dependent driving forces,
particularly in the far-from-equilibrium regime. In this work, we use
nonequilibrium molecular dynamics simulations and stochastic thermodynamics to
investigate energy transport in a well-studied nanoscale system, a molecular
junction, subjected to a time-periodic temperature gradient. The primary
observation is that molecular junctions can exhibit heat transport hysteresis,
a phenomenon in which the heat flux through a system depends not only on the
instantaneous value of a time-dependent temperature bias but also on the
temporal history of that bias. The presented findings illustrate that molecular
junctions can exhibit the specific memory effect, heat transport hysteresis,
that is essential for the design of thermal neuromorphic computers. This work
elucidates a potential pathway toward the realization of such devices.

</details>


### [456] [Trembling motion of electrons driven by Larmor spin precession](https://arxiv.org/abs/2510.12187)
*I. Stepanov,M. Ersfeld,A. V. Poshakinskiy,M. Lepsa,E. L. Ivchenko,S. A. Tarasenko,B. Beschoten*

Main category: cond-mat.mes-hall

TL;DR: 在有磁场的应变n-InGaAs中，电子自旋初始化会触发GHz频率的交流电，这是一种固态Zitterbewegung现象，可用于超快自旋读出。


<details>
  <summary>Details</summary>
Motivation: 研究固态系统中的Zitterbewegung现象及其在自旋电子学中的应用。

Method: 在有磁场的应变n-InGaAs中，通过初始化相同自旋态的电子系综，观察并分析产生的交流电。

Result: 观察到在无驱动力的情况下，在GHz频率下产生交流电，其振幅与自旋轨道耦合强度和外磁场呈线性关系。该电流在电子自旋相干性丧失前一直存在。

Conclusion: 证明了相对论量子力学的Zitterbewegung现象可以在固态系统中实现，并提出该现象可用于超快自旋敏感电读出。

Abstract: We show that the initialization of an ensemble of electrons in the same spin
state in strained n-InGaAs subject to a perpendicular magnetic field triggers
an AC electric current at GHz frequencies. The AC current emerges in the
absence of any driving force and survives until the coherent precession of the
electron spins is lost. The current amplitude increases linearly with both the
spin-orbit coupling strength and the external magnetic field. The generation
mechanism of the observed oscillatory charge motion can be fruitfully described
in terms of the periodic trembling motion of spin-polarized electrons, which is
a solid-state analog to the Zitterbewegung of free Dirac electrons. Our results
demonstrate that the hidden consequence of relativistic quantum mechanics is
realized and can be studied in a rather simple solid-state system at moderate
temperatures. Furthermore, the large amplitude of the AC current at high
magnetic fields enables ultra-fast spin sensitive electric read-out in solids.

</details>


### [457] [Wiedemann-Franz behavior at the Weyl points in compressively strained HgTe](https://arxiv.org/abs/2510.12339)
*Abu Alex Aravindnath,Yi-Ju Ho,Fabian Schmitt,Dongyun Chen,Johannes Kleinlein,Wouter Beugeling,Hartmut Buhmann,Stanislau U. Piatrusha,Laurens W. Molenkamp*

Main category: cond-mat.mes-hall

TL;DR:  Weyl半金属表现出与量子异常相关的巨大正磁热电导，并符合维德曼-弗朗兹定律。


<details>
  <summary>Details</summary>
Motivation: 研究具有潜在应用前景的 Weyl 半金属的量子异常，特别是其与引力异常相关的磁热电导。

Method: 在低温下，使用全电子方法对基于压缩应变 HgTe 层的 Weyl 半金属器件进行温度测量，以提取热电导。

Result: 观察到热电导增加，并且其值与根据维德曼-弗朗兹定律计算的电导值完全匹配。

Conclusion: Weyl 半金属中的热量和电量传输机制相同，没有额外的守恒定律违规。

Abstract: Weyl semimetals, with their unique electronic band structure, have drawn
significant interest for their potential to explore quantum anomalies in
condensed matter systems. In this study, we investigate the large positive
magneto-thermal conductance associated with the gravitational anomaly -- one of
the predicted anomalies -- for a Weyl semimetal based on a compressively
strained HgTe layer. We clearly identify the Weyl regime in our device and
accurately extract the thermal conductance by performing thermometry
measurements at liquid helium temperatures using fully electronic methods. We
observe the anticipated increase in thermal conductance, and it perfectly
matches the electrical conductance according to the Wiedemann-Franz law. This
finding indicates that, despite the unique electronic spectrum of Weyl
semimetals, the mechanism governing heat transport in this system is the same
as that for electrical transport, with no additional violations of conservation
laws.

</details>


### [458] [Green's function expansion for multiple coupled optical resonators with finite retardation using quasinormal modes](https://arxiv.org/abs/2510.12511)
*Robert Fuchs,Juanjuan Ren,Stephen Hughes,Marten Richter*

Main category: cond-mat.mes-hall

TL;DR: 提出一种计算多腔系统散射电磁格林函数的数值方法。


<details>
  <summary>Details</summary>
Motivation: 现代光子量子器件的理论研究需要电磁格林函数，但直接计算通常很困难。

Method: 基于戴森散射方程，通过少量共振器的拟态模式和有限次数迭代来构造格林函数，无需嵌套积分。

Result: 该方法与双偶极子耦合系统的全数值格林函数高度一致，易于扩展到多腔系统。

Conclusion: 所提出的框架能够高效计算多腔系统（任意形状、色散和损耗）的散射电磁格林函数，并考虑了有限的延迟时间。

Abstract: The electromagnetic Green's function is a crucial ingredient for the
theoretical study of modern photonic quantum devices, but is often difficult or
even impossible to calculate directly. We present a numerically efficient
framework for calculating the scattered electromagnetic Green's function of a
multi-cavity system with spatially separated open cavities (with arbitrary
shape, dispersion and loss) and finite retardation times. The framework is
based on a Dyson scattering equation that enables the construction of the
Green's function from the quasinormal modes of the individual resonators within
a few-mode approximation and a finite number of iteration steps without
requiring nested integrals. The approach shows excellent agreement with the
full numerical Green's function for the example of two coupled dipoles located
in the gaps of two metal dimers serving as quasinormal mode cavities, and is
easily extended to arbitrarily large separations and multiple cavities.

</details>


### [459] [Origin of Enhanced Thermal Resistance Near Nanoscale Hotspots: Insights from Full-Dispersion-Resolved Phonon Transport in Silicon](https://arxiv.org/abs/2510.12530)
*Jae Sik Jin*

Main category: cond-mat.mes-hall

TL;DR: 热阻增加并非源于长平均自由程，而是源于长平均自由程声子的低比热。


<details>
  <summary>Details</summary>
Motivation: 纳米级热点（NHs）附近声子输运对先进电子器件的散热至关重要，但现有理论未能充分解释其热阻增加的根源。

Method: 利用包含完整声子色散模型的玻尔兹曼输运方程（BTE）分析硅中的非平衡声子行为。

Result: 研究发现，热阻增加并非由长平均自由程本身引起，而是由长平均自由程且不直接与光学模式散射的声子的低比热导致。这些声子在能量供给时易升温，加剧了局部温度梯度，从而增大了热阻。

Conclusion: 该研究揭示了模比热在非局域声子输运中的关键作用，为纳米尺度热管理提供了新的物理见解，并强调了在电子器件散热建模中解决声子模式分辨率的重要性。

Abstract: Phonon transport near nanoscale hotspots (NHs) critically determines heat
dissipation in advanced electronic devices. The prevailing understanding is
that the enhanced thermal resistance (TR) observed in NHs originates from long
mean free path (MFP) phonons, whose MFPs are much larger than the hotspot size,
thereby limiting their ability to recognize hotspots and transport heat
effectively. In this study, we revisit this problem by employing the Boltzmann
transport equation (BTE) with a full phonon dispersion model (FPDM) to capture
mode-resolved velocities, scattering processes, and nonequilibrium phonon
populations in silicon. The analysis demonstrates that the increase in TR near
NHs is not caused by the long MFP itself but by the low specific heat of
long-MFP phonons that do not scatter directly with optical modes. These phonons
heat readily when energy is supplied, steepening the local temperature gradient
near the NH and thereby enhancing TR. By resolving the spectral contributions
to the phonon transport resistance and temperature gradients, we identify the
critical role of the modal specific heat in nonlocal phonon transport. These
results provide new physical insights into nanoscale thermal management and
highlight the importance of spectral mode resolution in modeling heat
dissipation in electronic devices.

</details>


### [460] [Conductance Plateaus at Quantum Hall Integer Filling Factors in Germanium Quantum Point Contacts](https://arxiv.org/abs/2510.12554)
*Karina Hudson,Davide Costa,Davide Degli Esposti,Lucas E. A. Stehouwer,Giordano Scappucci*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用量子霍尔效应下的量子点接触来研究应变锗材料中的边缘模式传输，并观察到了量子霍尔效应和整数朗道能级，表明应变锗可用于复杂量子实验。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索在量子霍尔效应下，量子点接触如何影响和调控一维量子点接触中的边缘模式传输，以及应变锗材料在这种体系中的适用性。

Method: 本研究通过在低缺陷应变锗量子阱上制造量子点接触，并研究其在不同磁场下的量子霍尔效应和电导量子化现象。

Result: 研究观察到，随着磁场增加，量子点接触表现出与填充因子相关的整数量子霍尔效应，并呈现出量子化的电导，电导值是 $e^2/h$ 的整数倍，直至填充因子 $
u=1$。

Conclusion: 研究结果表明，应变锗是一种适合进行复杂量子多体态和量子相变探究的实验平台。

Abstract: Constricting transport through a one-dimensional quantum point contact in the
quantum Hall regime enables gate-tunable selection of the edge modes
propagating between voltage probe electrodes. Here we investigate the quantum
Hall effect in a quantum point contact fabricated on low disorder strained
germanium quantum wells. For increasing magnetic field, we observe Zeeman
spin-split 1D ballistic hole transport evolving to integer quantum Hall states,
with well-defined quantised conductance increasing in multiples of $e^2/h$ down
to the first integer filling factor $\nu=1$. These results establish strained
germanium as a viable platform for complex experiments probing many-body states
and quantum phase transitions.

</details>


### [461] [Dissipationless transport by design in ultrathin magnetic topological insulator films](https://arxiv.org/abs/2510.12610)
*Amir Sabzalipour,Mohammad Shafiei,Milorad V. Milošević*

Main category: cond-mat.mes-hall

TL;DR: 通过外部磁场和/或电子刺激，在磁性拓扑绝缘体薄膜中抑制电子回向散射，从而实现完全无耗散的自旋极化电荷传输。


<details>
  <summary>Details</summary>
Motivation: 磁性拓扑绝缘体（MTI）中的磁性杂质会通过对电子自旋施加磁力矩引起耗散，需要降低这种电阻以减少能源消耗并优化MTI的性能。

Method: 通过外部磁场和/或电子刺激来抑制磁性拓扑绝缘体薄膜中的电子回向散射。

Result: 实现了完全无耗散的自旋极化电荷传输。

Conclusion: 该发现提出了一条有效途径来保持自旋相干性并增强磁性拓扑材料中的自旋流功能，为设计能耗大大降低的磁电子和自旋电子器件提供了策略。

Abstract: Magnetic topological insulators (MTIs) are among the prominent platforms for
the next generation of high-speed and low-power spintronic devices. However,
unlike their non-magnetic counterparts, where the surface spin-momentum locking
prevents electrons from being scattered by non-magnetic impurities and results
in a dissipationless electronic flow, magnetic impurities in MTIs cause
dissipation by exerting magnetic torque on the electron spin. Decreasing this
resistance is desired to reduce energy consumption and optimize performance of
MTIs in envisaged applications. Here we reveal how electronic backscattering
can be suppressed in a MTI thin film by external magnetic and/or electronic
stimuli, to yield an entirely dissipationless spin-polarized charge transport.
Our findings thus present an effective route to preserve spin coherence and
enhance spin-current functionality in magnetic topological materials,
suggesting design strategies for magneto-electronic and spintronic devices with
strongly reduced energy consumption.

</details>


### [462] [plasmonX: an Open-Source Code for Nanoplasmonics](https://arxiv.org/abs/2510.12731)
*Tommaso Giovannini,Pablo Grobas Illobre,Piero Lafiosca,Luca Nicoli,Luca Bonatti,Stefano Corni,Chiara Cappelli*

Main category: cond-mat.mes-hall

TL;DR: plasmonX是一个开源代码，用于模拟复杂纳米结构的等离激元响应，支持全原子和隐式描述，并提供后处理模块。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个新的开源代码plasmonX，用于模拟复杂纳米结构的等离激元响应。

Method: plasmonX代码支持全原子（使用$
u$FQ和$
u$FQF$
u$模型）和隐式（使用边界元法，包括DPCM和IEF-PCM变体）的纳米材料描述。还包含一个后处理模块，用于分析电场诱导的性质。

Result: plasmonX代码能够模拟包括简单金属、d-金属、石墨烯基结构和多金属纳米结构在内的各种材料的等离激元响应。

Conclusion: plasmonX是一个功能全面的开源代码，能够模拟复杂纳米结构的等离激元响应，并提供详细的后处理分析功能。

Abstract: We present the first public release of plasmonX, a novel open-source code for
simulating the plasmonic response of complex nanostructures. The code supports
both fully atomistic and implicit descriptions of nanomaterials. In particular,
it employs the frequency-dependent fluctuating charges ($\omega$FQ) and dipoles
($\omega$FQF$\mu$) models to describe the response properties of atomistic
structures, including simple and $d$-metals, graphene-based structures, and
multi-metal nanostructures. For implicit representations, the Boundary Element
Method is implemented in both the dielectric polarizable continuum model (DPCM)
and integral equation formalism (IEF-PCM) variants. The distribution also
includes a post-processing module that enables analysis of electric
field-induced properties such as charge density and electric field patterns.

</details>
