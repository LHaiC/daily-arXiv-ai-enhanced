<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications](https://arxiv.org/abs/2510.25140)
*Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P*

Main category: cs.CV

TL;DR: DINO-YOLO是一种结合了YOLOv12和DINOv3的混合架构，通过在输入预处理和骨干网络增强处集成DINOv3特征，实现了在数据有限的土木工程领域的对象检测性能提升，同时保持了实时推理能力。


<details>
  <summary>Details</summary>
Motivation: 土木工程应用中的对象检测受限于专业领域内标注数据的不足。

Method: 将DINOv3的特征集成到YOLOv12架构的两个位置：输入预处理（P0）和中骨干增强（P3），形成DINO-YOLO混合架构。

Result: 在隧道裂缝检测、施工安全帽检测和KITTI数据集上分别取得了12.4%、13.7%和88.6%的性能提升，同时保持了30-47 FPS的实时推理能力。消融实验表明，中等规模的YOLO架构结合P0P3集成在55.77% mAP@0.5时达到最优，而小规模架构需要三重集成（53.63% mAP@0.5）。推理开销增加了2-4倍，但仍可接受。

Conclusion: DINO-YOLO在数据量小于10K的土木工程数据集上达到了最先进的性能，同时保持了计算效率，为数据受限环境下的施工安全监控和基础设施检测提供了实用的解决方案。

Abstract: Object detection in civil engineering applications is constrained by limited
annotated data in specialized domains. We introduce DINO-YOLO, a hybrid
architecture combining YOLOv12 with DINOv3 self-supervised vision transformers
for data-efficient detection. DINOv3 features are strategically integrated at
two locations: input preprocessing (P0) and mid-backbone enhancement (P3).
Experimental validation demonstrates substantial improvements: Tunnel Segment
Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K
images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while
maintaining real-time inference (30-47 FPS). Systematic ablation across five
YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures
achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while
Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead
(21-33ms versus 8-16ms baseline) remains acceptable for field deployment on
NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil
engineering datasets (<10K images) while preserving computational efficiency,
providing practical solutions for construction safety monitoring and
infrastructure inspection in data-constrained environments.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [2] [Artificial Transmission Line Synthesis Tailored for Traveling-Wave Parametric Processes](https://arxiv.org/abs/2510.24753)
*M. Malnou*

Main category: physics.app-ph

TL;DR: 本论文提出了一种用于设计人工传输线的通用合成框架，该框架结合了周期结构理论和无源网络合成，并将其应用于设计两种新型的旅行波参数放大器（TWPA）。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统的人工传输线（TWPA 的基础）设计方法。

Method: 该方法结合了周期加载合成（通过对独立于频率的组件进行空间调制）和滤波器合成（通过对空间均匀的组件引入频率依赖的响应）。在设计用于参数过程的传输线时，会加入非线性元件（通常是超导电路中的非线性电感），并确保相互作用的频率之间的能量和动量守恒。

Result: 基于该框架，设计了一种具有新颖相位匹配结构的新型动力电感 TWPA，以及一种利用左右手（ambidextrous）传输线的反向泵浦约瑟夫森 TWPA。

Conclusion: 所提出的合成框架为设计人工传输线和 TWPA 提供了一种系统的方法，并成功应用于两种新型 TWPA 的设计。

Abstract: Artificial transmission lines built with lumped-element inductors and
capacitors form the backbone of broadband, nearly quantum-limited
traveling-wave parametric amplifiers (TWPAs). However, systematic design
methods for TWPAs, and more generally artificial transmission lines, are
lacking. Here, I develop a general synthesis framework for lossless artificial
transmission lines by borrowing from periodic structure theory and passive
network synthesis. These complementary approaches divide the design space:
periodic loading synthesis employs spatial modulation of frequency-independent
components, while filter synthesis employs frequency-dependent responses in
spatially-uniform components. When tailoring transmission lines for parametric
processes, nonlinear elements are added, typically nonlinear inductances in
superconducting circuits, while ensuring energy and momentum conservation
between interacting tones. Applying this framework, I design a kinetic
inductance TWPA with a novel phase-matching architecture, and a backward-pumped
Josephson TWPA exploiting an ambidextrous i.e., right-left-handed transmission
line.

</details>
