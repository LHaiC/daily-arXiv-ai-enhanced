<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 94]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.ET](#cs.ET) [Total: 4]
- [cs.GR](#cs.GR) [Total: 3]
- [quant-ph](#quant-ph) [Total: 23]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 9]
- [cs.LG](#cs.LG) [Total: 59]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]
- [eess.SP](#eess.SP) [Total: 13]
- [cs.RO](#cs.RO) [Total: 30]
- [cs.AI](#cs.AI) [Total: 11]
- [eess.SY](#eess.SY) [Total: 10]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.MA](#cs.MA) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 1]
- [cs.NE](#cs.NE) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 一种用于注视信号的隐私增强机制，可防止用户跨会话重新识别，同时保留数据用于良性任务的可用性。


<details>
  <summary>Details</summary>
Motivation: 为了防止用户跨会话被重新识别，同时保留数据用于良性任务的可用性。

Method: 提出了一种使用潜噪声自编码器的隐私增强机制。

Result: 该方法显著降低了生物识别可识别性，并最大程度地减少了效用损失，同时保留了符合生理学的注视模式，适用于下游使用。

Conclusion: 该研究提出了一种用于注视信号的隐私增强机制，该机制使用潜噪声自编码器，可在未经用户同意的情况下防止用户跨会话重新识别，同时保留数据用于良性任务的可用性。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [2] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: This survey provides a comprehensive review of Video Temporal Grounding using Multimodal Large Language Models (VTG-MLLMs), covering their roles, training, and feature processing. It also discusses datasets, evaluation, findings, limitations, and future research directions.


<details>
  <summary>Details</summary>
Motivation: Despite extensive surveys on general video-language understanding, comprehensive reviews specifically addressing VTG-MLLMs remain scarce. This survey aims to fill this gap.

Method: This survey systematically examines current research on VTG-MLLMs through a three-dimensional taxonomy: 1) the functional roles of MLLMs, highlighting their architectural significance; 2) training paradigms, analyzing strategies for temporal reasoning and task adaptation; and 3) video feature processing techniques, which determine spatiotemporal representation effectiveness. The survey also discusses benchmark datasets, evaluation protocols, and summarizes empirical findings.

Result: The survey systematically examines current research on VTG-MLLMs, discusses benchmark datasets, evaluation protocols, and summarizes empirical findings. It also identifies existing limitations and proposes promising research directions.

Conclusion: VTG-MLLMs are gradually surpassing traditional fine-tuned methods, achieving competitive performance and excelling in generalization across zero-shot, multi-task, and multi-domain settings.

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [3] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF是一种新的负面提示引导方法，简单高效，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 介绍一种用于在少步长扩散和流匹配图像生成模型中结合负面提示引导的简单高效方法VSF。

Method: VSF通过翻转负面提示的注意力值符号来动态抑制不希望的内容，计算开销小，可与MMDiT和交叉注意力模型集成。

Result: VSF在包含复杂提示对的挑战性数据集上进行了验证，并在静态图像和视频生成任务中展示了卓越的性能。

Conclusion: VSF在少步长模型中显著提高了负面提示的遵循性，在非少步长模型中甚至优于CFG，同时保持了有竞争力的图像质量。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [4] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: 本文提出了一种新的摄像头定位方法，通过将摄像头位姿自动编码器（PAE）应用于相对位姿回归（RPR），并结合绝对位姿回归（APR）进行优化，提高了定位精度，并减少了数据需求。


<details>
  <summary>Details</summary>
Motivation: 准确的摄像头定位对于现代零售环境至关重要，可实现增强的客户体验、简化的库存管理和自主运营。虽然从单个图像进行绝对位姿回归（APR）提供了一种有前途的解决方案，但结合视觉和空间场景先验的方法往往能获得更高的精度。摄像头位姿自动编码器（PAE）最近被引入以将这些先验知识嵌入APR。

Method: 本文将PAE扩展到相对位姿回归（RPR）任务，并提出了一种新颖的重新定位方案，该方案通过基于PAE的RPR来优化APR预测，无需额外的图像或位姿数据存储。首先，本文介绍了基于PAE的RPR，并通过与等效架构的基于图像的RPR模型进行比较来确立其有效性。然后，本文证明了所提出的由基于PAE的RPR驱动的优化策略能够提高室内基准测试中的APR定位精度。

Result: 本文提出的优化策略通过基于PAE的RPR，提高了APR定位精度。与仅使用30%数据训练的基线模型相比，本文方法实现了具有竞争力的性能。

Conclusion: 本文提出的基于PAE的RPR方法在室内基准测试中提高了APR定位精度，并且在仅使用30%数据训练的情况下仍能达到具有竞争力的性能，大大降低了零售部署的数据收集负担。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [5] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE 是一种视频处理引擎，用于从视频中提取 3D 信息（如相机姿态和深度图），解决了数据标注难题，性能优越且速度快，并已用于构建大规模数据集以推动空间 AI 发展。


<details>
  <summary>Details</summary>
Motivation: 解决现有状态最先进的 3D 几何感知方法依赖于大规模训练数据，而从真实世界的视频中获取一致且精确的 3D 注释仍然是一个关键挑战。

Method: 提出了一种名为 ViPE 的视频处理引擎，用于从非约束原始视频中高效估计相机内参、相机运动和近乎度量的密集深度图，能够处理各种场景和相机模型。

Result: ViPE 在 TUM/KITTI 数据集上，其性能分别比现有的未校准姿态估计基线提高了 18%/50%，并且在标准输入分辨率下，单 GPU 运行速度可达 3-5FPS。该引擎已用于注释包含约 100K 个真实互联网视频、1M 个高质量 AI 生成视频和 2K 个全景视频的数据集，总计约 96M 帧。

Conclusion: ViPE 引擎已开源，并且其注释的数据集也已公开，旨在加速空间人工智能系统的发展。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [6] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: HQ-OV3D 框架通过跨模态交叉验证提案生成器和标注类别辅助降噪器，解决了现有开放词汇 3D 检测中伪标签几何质量不高的问题，显著提高了模型在新增类别上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决了现有开放词汇 3D 检测方法中，虽然视觉语言模型 (VLM) 提高了伪标签的语义准确性，但其几何质量（尤其是边界框精度）仍然被忽视的问题。

Method: 提出了一种名为 HQ-OV3D 的框架，该框架包含两个关键组件：1. 跨模态交叉验证 (IMCV) 提案生成器，利用跨模态几何一致性生成高质量的初始 3D 提案。2. 标注类别辅助 (ACA) 降噪器，通过基于 DDIM 的降噪机制利用标注类别的几何先验来逐步精炼 3D 提案。

Result: 与最先进的方法相比，使用 HQ-OV3D 生成的伪标签进行训练，在新增类别上的 mAP 提高了 7.37%，证明了该框架生成的伪标签的优越质量。

Conclusion:  HQ-OV3D 框架不仅可以作为一个强大的独立开放词汇 3D 检测器，还可以作为现有开放词汇 3D 检测或注释管道的即插即用高质量伪标签生成器。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [7] [DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring](https://arxiv.org/abs/2508.11591)
*Durga Joshi,Chandi Witharana,Robert Fahey,Thomas Worthley,Zhe Zhu,Diego Cerrai*

Main category: cs.CV

TL;DR: 研究人员开发了一种利用行车记录仪视频进行实时路边植被和基础设施结构评估和地理定位的新方法。该方法结合了深度估计、GPS定位和相机几何，可以准确地测量物体的位置和高度，成本低廉且易于实施。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提出一个低成本、可复现的框架，利用常见的行车记录仪视频数据，对路边植被和基础设施进行实时、对象级别的结构评估和地理定位。

Method: 该研究开发了一个端到端的流程，结合了单目深度估计、深度误差校正和几何三角测量。首先使用先进的单目深度模型估计深度图，然后通过梯度提升回归框架进行优化，以校正低估，特别是对于远处物体。深度校正模型在一个转换尺度上实现了强大的预测性能（R2 = 0.92，MAE = 0.31），显著减少了超过15米以外的偏差。此外，使用基于GPS的三角测量来估算物体位置，并使用针孔相机几何来计算物体高度。

Result: 该研究在低速车辆和车内摄像头条件下进行了评估，实现了最高的准确性，平均地理定位误差为 2.83 米，树木高度估计的平均绝对误差 (MAE) 为 2.09 米，杆的高度估计的平均绝对误差 (MAE) 为 0.88 米。

Conclusion: 该研究提出了一个新颖、低成本且可复现的框架，利用常见的但未被充分利用的行车记录仪视频数据，对路边植被和基础设施进行实时、对象级别的结构评估和地理定位。该方法结合了单目深度估计、深度误差校正和几何三角测量，从车辆安装的行车记录仪的街道级视频流生成准确的空间和结构数据。该方法在各种摄像头放置和车速条件下进行了评估，为城市植被和基础设施的监控提供了一种快速、实时且经济高效的解决方案。

Abstract: Our study introduces a novel, low-cost, and reproducible framework for
real-time, object-level structural assessment and geolocation of roadside
vegetation and infrastructure with commonly available but underutilized
dashboard camera (dashcam) video data. We developed an end-to-end pipeline that
combines monocular depth estimation, depth error correction, and geometric
triangulation to generate accurate spatial and structural data from
street-level video streams from vehicle-mounted dashcams. Depth maps were first
estimated using a state-of-the-art monocular depth model, then refined via a
gradient-boosted regression framework to correct underestimations, particularly
for distant objects. The depth correction model achieved strong predictive
performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly
reducing bias beyond 15 m. Further, object locations were estimated using
GPS-based triangulation, while object heights were calculated using pin hole
camera geometry. Our method was evaluated under varying conditions of camera
placement and vehicle speed. Low-speed vehicle with inside camera gave the
highest accuracy, with mean geolocation error of 2.83 m, and mean absolute
error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To
the best of our knowledge, it is the first framework to combine monocular depth
modeling, triangulated GPS-based geolocation, and real-time structural
assessment for urban vegetation and infrastructure using consumer-grade video
data. Our approach complements conventional RS methods, such as LiDAR and image
by offering a fast, real-time, and cost-effective solution for object-level
monitoring of vegetation risks and infrastructure exposure, making it
especially valuable for utility companies, and urban planners aiming for
scalable and frequent assessments in dynamic urban environments.

</details>


### [8] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: 提出一种新方法，利用稀疏3D语义高斯图进行协同3D语义占用预测，降低通信成本同时提高精度。


<details>
  <summary>Details</summary>
Motivation: 现有的仅视觉方法在协同感知中存在通信成本高或需要额外监督的问题，本研究旨在提出一种能克服这些挑战的协同3D语义占用预测方法。

Method: 利用稀疏3D语义高斯图作为协同3D语义占用预测的范式，通过基于邻域的跨代理融合来去除重复并抑制不一致的高斯图，并联合编码每个图元的几何和语义信息，以减少对深度监督的依赖并实现简单的刚性对齐。

Result: 与单代理感知和基线协同方法相比，在mIoU和IoU方面分别取得了+8.42/+3.28和+5.11/+22.41的提升。在通信量减少的情况下，仍能保持竞争力的性能。

Conclusion: 提出的方法通过共享和融合中间高斯图元，实现了协同3D语义占用预测，在减少通信成本的同时提高了精度。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [9] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: IDFSR通过遮蔽、扭曲和ID嵌入来解决极端退化下的FSR问题，提高了ID一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有面部超分辨率（FSR）方法在极端退化（例如，尺度>8×）下难以重建真实且ID一致的面部，倾向于生成缺乏真实ID约束的幻觉面孔。

Method: 1. 遮蔽（Masking）：遮蔽低分辨率（LR）图像中的面部区域，以消除不可靠的ID线索。
2. 扭曲（Warping）：将参考图像扭曲以匹配LR输入，提供风格指导。
3. ID嵌入（ID embeddings）：利用从真实（GT）图像提取的ID嵌入进行细粒度的ID建模和个性化适应。
该方法首先预训练一个基于扩散的模型，通过强制其使用风格和身份嵌入来重建被遮蔽的LR面部区域，从而显式地解耦风格和ID。
随后，冻结大部分网络参数，并使用少量目标ID图像对ID嵌入进行轻量级微调。

Result: IDFSR在极端退化情况下显著优于现有方法，尤其在ID一致性和感知质量方面。

Conclusion: 所提出的IDFSR方法在极端退化情况下显著优于现有方法，尤其在ID一致性方面表现出色。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [10] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [11] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: A new pooling layer called NIRMAL Pooling improves CNN accuracy in image classification by using adaptive max pooling with ReLU activation, outperforming standard Max Pooling on MNIST and CIFAR-10 datasets.


<details>
  <summary>Details</summary>
Motivation: The paper aims to enhance the performance of Convolutional Neural Networks (CNNs) in image classification tasks by proposing a novel pooling layer, NIRMAL Pooling, which addresses limitations of traditional pooling methods.

Method: This paper introduces NIRMAL Pooling, a novel pooling layer for CNNs that combines adaptive max pooling with a non-linear activation function (ReLU). NIRMAL stands for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum, Adaptive, and Localized. The layer dynamically adjusts pooling parameters and applies ReLU activation post-pooling to improve robustness and feature expressiveness.

Result: NIRMAL Pooling achieved higher test accuracies than standard Max Pooling on benchmark datasets: 99.25% vs. 99.12% on MNIST Digits, 91.59% vs. 91.44% on MNIST Fashion, and 70.49% vs. 68.87% on CIFAR-10.

Conclusion: NIRMAL Pooling, a novel pooling layer, demonstrates consistent improvements over traditional Max Pooling in image classification tasks, especially on complex datasets like CIFAR-10. It offers a flexible and reliable alternative for enhancing CNN performance.

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [12] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: 该研究提出了一种使用低分辨率CT和3D-UNet量化压实纺织品嵌套行为的方法，平均层厚和嵌套程度的提取结果与显微照片验证高度一致，为复合材料预制件的逆建模奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 对跨越多个尺度的材料结构进行详细理解，对于预测性地模拟纺织增强复合材料至关重要。嵌套——其特点是相邻织物层通过纱线的局部互穿和错位而相互联锁——在定义刚度、渗透性和损伤容限等机械性能方面起着关键作用。

Method: 本研究提出了一个使用低分辨率计算机断层扫描（CT）量化干性纺织增强材料在压实行为下嵌套行为的框架。对各种堆叠配置进行了原位压实实验，并以每个体素20.22μm的分辨率获取了CT扫描。使用定制的3D-UNet对纤维体积分数为50%–60%的压实阶段的基体、纬纱和填充纱相进行了语义分割。该模型实现了0.822的最小平均交并比和0.902的F1分数。随后使用两点相关函数S2对空间结构进行分析，从而能够概率性地提取平均层厚和嵌套程度。

Result: 研究结果表明，所提出的方法与基于显微照片的验证结果高度一致。

Conclusion: 该方法为提取关键几何特征和复合材料预制件的逆建模与基于描述符的结构分析奠定了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [13] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 这项工作研究了一种称为 Artcodes 的装饰性标记，它通过将信息编码到其拓扑结构中来伪装自己，并提出了一种新的特征描述符来检测它们。


<details>
  <summary>Details</summary>
Motivation: 为了提醒人们注意这些对象（Artcodes）的存在，并触发附着在这些对象上的数字材料，这项工作研究了一种特殊的 Artcodes。

Method: 提出了一种新的特征描述符，称为方向直方图的形状，用于描述 Artcode 的通用拓扑结构。

Result: 实验结果表明，所提出的特征向量在表示拓扑结构方面是可行的，并且所提出的系统在检测 Artcode 提案方面是有效的。

Conclusion: 这项工作是开发用于检测诸如 Artcodes 之类的拓扑对象的基于特征的系统的初步尝试，它将开启新的交互机会，并激发拓扑对象检测的潜在应用。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [14] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: iWatchRoad is an automated system for detecting, geotagging, and mapping potholes using a YOLO model, OCR, and GPS, with a focus on improving road safety and maintenance in India.


<details>
  <summary>Details</summary>
Motivation: Potholes pose a significant threat to road safety and vehicle longevity, especially on India's diverse and under-maintained roads. This necessitates an automated system for pothole detection, tagging, and mapping to aid in road maintenance and planning.

Method: The iWatchRoad system uses a fine-tuned YOLO model for real-time pothole detection, a custom OCR module for timestamp extraction from video frames, and GPS logs for accurate geotagging. A large, self-annotated dataset of over 7,000 frames was curated from dashcam footage captured in various Indian road conditions. The processed data, including pothole details and frames, is stored in a database and visualized on a web interface using OpenStreetMap.

Result: The iWatchRoad system enables automated pothole detection, GPS tagging, and real-time mapping using OpenStreetMap. It offers improved detection accuracy under challenging conditions and provides visualized metadata on a web interface for road assessment and maintenance planning.

Conclusion: iWatchRoad is a cost-effective, hardware-efficient, and scalable solution that improves detection accuracy under challenging conditions and provides government-compatible outputs for road assessment and maintenance planning, making it a practical tool for road management in developing regions.

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [15] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: IPG 是一种新方法，可以更有效地生成对抗性贴片，提高了 AI 模型的鲁棒性，并在自动驾驶、安全和医疗成像等领域具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 对抗性贴片对人工智能模型（尤其是计算机视觉任务中的对象检测）的鲁棒性构成了重大挑战。与传统的对抗性示例不同，这些贴片会针对图像的特定区域，导致人工智能模型发生故障。

Method: 提出增量贴片生成（IPG）方法，以比现有方法高出 11.1 倍的效率生成对抗性贴片。

Result: 实验和消融研究（包括 YOLO 的特征分布可视化和对抗性训练结果）证明了 IPG 的有效性，表明它能生成泛化性好且能有效覆盖更广泛模型漏洞的贴片。

Conclusion: 增量贴片生成（IPG）在保持可比的攻击性能的同时，生成对抗性贴片的效率比现有方法高出 11.1 倍。IPG 生成的数据集可以作为构建稳健模型、实现结构化表示、高级推理和主动防御的稳健知识基础。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [16] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas is a new benchmark for evaluating AI in medical diagnosis, featuring realistic multi-turn conversations and various medical images (CT, MRI, etc.). Current AI models show significant weaknesses in complex clinical reasoning tasks evaluated by this benchmark, which aims to improve trustworthy medical AI.


<details>
  <summary>Details</summary>
Motivation: Existing medical multi-modal benchmarks are limited to single-image, single-turn tasks, lacking multi-modal medical image integration and failing to capture the longitudinal and multi-modal interactive nature inherent to clinical practice. This gap hinders the development of AI models capable of adapting to diverse real-world scenarios and performing complex diagnostic reasoning.

Method: MedAtlas is a novel benchmark framework designed to evaluate large language models on realistic medical reasoning tasks. It features multi-turn dialogue, multi-modal medical image interaction, multi-task integration, and high clinical fidelity. It supports four core tasks: open-ended multi-turn question answering, closed-ended multi-turn question answering, multi-image joint reasoning, and comprehensive disease diagnosis. Cases are derived from real diagnostic workflows and incorporate temporal interactions between textual medical histories and multiple imaging modalities (CT, MRI, PET, ultrasound, X-ray). The framework also proposes two novel evaluation metrics: Round Chain Accuracy and Error Propagation Resistance.

Result: Benchmark results with existing multi-modal models reveal substantial performance gaps in multi-stage clinical reasoning. This indicates that current multi-modal models struggle with the complexities of realistic medical reasoning tasks as evaluated by MedAtlas.

Conclusion: MedAtlas is a novel benchmark framework that addresses the limitations of existing medical multi-modal benchmarks by incorporating multi-turn dialogue, multi-modal medical image interaction, multi-task integration, and high clinical fidelity. It supports four core tasks and includes expert-annotated gold standards and new evaluation metrics. Benchmark results indicate substantial performance gaps in multi-stage clinical reasoning, highlighting MedAtlas's potential to advance the development of robust and trustworthy medical AI.

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [17] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: 本研究提出并验证了一个名为 FastFOD-Net 的深度学习框架，用于增强弥散 MRI 中的纤维方向分布 (FOD)。该框架比其前身快 60 倍，并在健康和患病人群中均表现出稳健性，有望加速临床神经科学研究和实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决从单层、低角分辨率采集的临床协议生成可靠 FOD 的挑战，并验证现有深度学习方法在健康和患病受试者中的适用性，以促进其临床应用。

Method: 提出并优化了一个名为 FastFOD-Net 的端到端深度学习框架，用于增强纤维方向分布 (FOD)，该框架在训练和推理方面具有效率，比其前身快 60 倍。

Result: FastFOD-Net 在健康对照组和六种神经系统疾病患者中均得到验证，展示了其在加速临床神经科学研究、疾病鉴别、connectome 应用可解释性以及减少样本量要求方面的潜力。

Conclusion: FastFOD-Net 框架能够加速临床神经科学研究，通过疾病鉴别赋能弥散 MRI 分析，提高 connectome 应用的可解释性，并减少测量误差以降低样本量要求。该框架能够对真实世界的临床弥散 MRI 数据进行稳健分析，其效果可与高质量的研究采集相媲美。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [18] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: UWB-PostureGuard是一种利用UWB技术进行非接触式坐姿监测的系统，可提高准确性和隐私性。


<details>
  <summary>Details</summary>
Motivation: 解决长时间使用电脑时坐姿不当引起的公共卫生问题，克服传统基于摄像头或可穿戴传感器的姿势监测方法的隐私和用户舒适度障碍。

Method: 提出了一种名为UWB-PostureGuard的隐私保护超宽带（UWB）传感系统，利用商业UWB设备和全面的特征工程提取坐姿特征，并开发了PoseGBDT来捕捉坐姿模式中的时间依赖性。

Result: 在10名参与者和19种不同姿势的广泛真实世界评估中，该系统实现了99.11%的准确率，并能抵抗环境变化。

Conclusion: 该系统提供了一个可扩展的、保护隐私的移动健康解决方案，可在现有平台上进行前瞻性的人体工程学管理，以低成本提高生活质量。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [19] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: MLLMs are powerful but face challenges. Augmenting them with external tools can improve data, task performance, and evaluation, offering a path to more capable AI. This paper surveys how tools help MLLMs.


<details>
  <summary>Details</summary>
Motivation: Despite the success of MLLMs like GPT-4V, challenges such as limited data quality, poor performance on complex tasks, and inadequate evaluation hinder their reliability and applicability. Augmenting MLLMs with external tools is proposed as a solution.

Method: This paper provides a comprehensive survey structured along four key dimensions: data acquisition/annotation, downstream task performance improvement, evaluation, and limitations/future directions of tool-augmented MLLMs.

Result: The survey analyzes how external tools can facilitate high-quality multimodal data acquisition and annotation, assist in improving MLLM performance on challenging tasks, and enable comprehensive and accurate evaluation, ultimately aiming to advance MLLM capabilities.

Conclusion: The paper surveys the use of external tools to enhance Multimodal Large Language Models (MLLMs), highlighting their potential to improve data quality, task performance, and evaluation, while also discussing limitations and future directions.

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [20] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: 现有的视觉语言模型（VLM）在物体属性推理方面表现不佳，尤其是在处理真实图像、反事实推理和需要更高计数的问题时。我们提出了ORBIT基准来评估这些能力，实验表明当前VLM与人类相比存在巨大差距。


<details>
  <summary>Details</summary>
Motivation: 评估VLM在物体属性推理方面的能力，即识别和识别低级细节和更高级别的抽象。

Method: 提出一个系统的评估框架，包含三种代表性图像、三个递增的推理复杂性级别和四个由常识推理驱动的物体属性维度，并创建了一个名为ORBIT的多层次推理VQA基准，包含360张图像和1080个计数问题。

Result: 在零样本设置下，12个最先进的VLM的实验表明，与人类相比，它们存在显著的局限性，最好的模型准确率仅为40%。

Conclusion: VLMs 在物体属性推理方面存在显著局限性，尤其是在处理写实图像、反事实推理和计数方面。需要开发可扩展的基准测试方法和通用注释指南，并探索更多推理VLM。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [21] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本研究提出一种高光谱成像带选择方法，通过识别关键波段（497nm、607nm、895nm）并生成伪彩色图像，显著提高了弱势道路使用者（VRU）的可见性，解决了RGB图像中的视觉歧义问题，从而提升了自动驾驶感知安全性。


<details>
  <summary>Details</summary>
Motivation: 为了解决汽车感知系统中，尤其是在同质异谱现象（RGB图像中不同材料外观相似）导致的视觉歧义下，保护弱势道路使用者（VRU）的安全挑战。高光谱成像（HSI）能够捕捉可见光谱之外的独特材料信息，特别是近红外（NIR）信息，以克服这一限制。

Method: 提出了一种高光谱成像（HSI）带选择策略，该策略结合了信息论技术（联合互信息最大化、相关性分析）和图像质量度量（对比度信噪比），以识别对VRU识别最有信息量的高光谱波段。使用H-City数据集，识别出3个最优波段（497nm、607nm、895nm），并重构伪彩色图像与RGB图像进行比较。

Result: 所选的高光谱波段在区分度（欧氏距离、SAM、$T^2$）和感知（CIE $	riangle E$）指标上分别带来了70.24%、528.46%、1206.83%和246.62%的提升，显著优于RGB图像，并有效减少了同质异谱的混淆。

Conclusion: 所提出的基于高光谱成像和带选择的方法通过利用近红外光谱信息，显著提高了弱势道路使用者（VRU）与背景的区分度，克服了RGB图像中的同质异谱现象，为高级驾驶辅助系统（ADAS）和自动驾驶（AD）在复杂视觉环境下的感知任务奠定了坚实基础，最终有助于提高道路安全。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [22] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: EVCtrl是一种轻量级适配器，通过时空双缓存策略减少了ControlNet的延迟和计算量，在不牺牲生成质量的情况下显著提高了图像和视频生成速度。


<details>
  <summary>Details</summary>
Motivation: 旨在解决ControlNet在进行可控图像和视频生成时存在的延迟增加和冗余计算问题，特别是针对视频生成场景。

Method: EVCtrl提出了一种时空双缓存策略来解决ControlNet的延迟和冗余计算问题。具体来说，它首先分析了DiT-ControlNet的每一层对细粒度控制的响应，并将网络划分为全局和局部功能区，利用感知局部性的缓存来聚焦于真正需要的局部区域，跳过了大部分全局区域的冗余计算。其次，通过有选择地省略不必要的去噪步骤来处理时间冗余，从而提高效率。

Result: 通过在CogVideo-Controlnet、Wan2.1-Controlnet和Flux上的大量实验证明，EVCtrl在图像和视频控制生成方面无需训练即可实现有效控制。例如，在CogVideo-Controlnet和Wan2.1-Controlnet上分别实现了2.16倍和2.05倍的速度提升，同时生成质量几乎没有下降。

Conclusion: EVCtrl是一种轻量级、即插即用的控制适配器，可在不进行模型再训练的情况下大幅降低开销，有效解决了ControlNet在视频生成中存在的延迟和冗余计算问题。通过时空双缓存策略，EVCtrl在保证图像和视频生成质量的同时，实现了显著的速度提升。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [23] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: This paper explores using AI (VLMs) to simulate the vision of people with low vision. Researchers collected data from 40 participants and used it to prompt an AI. They found that giving the AI both information about the participants' vision and examples of their responses greatly improved the AI's accuracy in mimicking their perception. One good example was much better than many weak ones.


<details>
  <summary>Details</summary>
Motivation: To investigate the potential of Vision Language Models (VLMs) in simulating the vision perception of low vision individuals for accessibility applications, an area not previously explored.

Method:  The study involved a survey with 40 low vision participants to collect vision information and image perception responses. This data was used to create prompts for VLMs (GPT-4o) to simulate agents. The agreement between VLM-generated responses and participants' original answers was evaluated.

Result: VLMs tend to infer beyond specified abilities with minimal prompts, leading to low agreement (0.59). Providing only vision information or example responses also resulted in low agreement (0.59). However, combining both vision information and example responses significantly increased agreement (0.70, p < 0.0001). A single example incorporating both open-ended and multiple-choice responses showed significant improvement over using either type of example alone (p < 0.0001), with diminishing returns from additional examples (p > 0.05).

Conclusion:  VLMs can simulate the vision perception of low vision individuals, with prompt engineering significantly impacting accuracy. A combination of vision information and example responses in prompts yields the best results, and a single, well-crafted example is more effective than multiple weaker examples.

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [24] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: 该研究提出了一个名为ConstructionSite 10k的大规模数据集，包含10,000张施工现场图像，涵盖图像字幕、安全规则违规VQA和施工元素视觉基础三个任务，旨在为施工安全检查领域的VLM评估和微调提供支持。


<details>
  <summary>Details</summary>
Motivation: 当前VLM在施工安全检查领域的应用受限于小规模、监督式数据集，限制了它们在未经直接训练任务中的适用性。需要开放数据集来全面评估和进一步微调VLM。

Method: 提出了包含10,000张施工现场图像的数据集ConstructionSite 10k，并注释了三个相互关联的任务：图像字幕、安全规则违规视觉问答（VQA）和施工元素视觉基础。

Result: 对现有最先进的大型预训练VLM的评估显示，它们在零样本和少样本设置中具有显著的泛化能力，但仍需额外训练才能应用于实际施工现场。

Conclusion: 该数据集为研究人员提供了训练和评估自有VLM新架构和技术的平台，为施工安全检查提供了宝贵的基准。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [25] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: 本研究评估了多种多模态大语言模型在文档欺诈检测方面的能力，发现表现最佳的模型在零样本泛化方面优于传统方法，但模型大小和推理能力与准确度的相关性有限，强调了特定任务微调的重要性。


<details>
  <summary>Details</summary>
Motivation: 文档欺诈对依赖安全和可验证文件的行业构成了重大威胁，因此需要强大的检测机制。

Method: 本研究测试了包括 OpenAI O1、OpenAI 4o、Gemini Flash（思考）、Deepseek Janus、Grok、Llama 3.2 和 4、Qwen 2 和 2.5 VL、Mistral Pixtral 以及 Claude 3.5 和 3.7 Sonnet 在内的最先进多模态大语言模型在检测欺诈文件方面的效果。研究人员通过提示优化和对模型推理过程的详细分析，在一包含真实交易文件的标准数据集上对这些模型进行了基准测试，并将它们与彼此以及先前在文档欺诈检测技术方面的工作进行了比较。

Result: 研究结果表明，表现最佳的多模态大语言模型在零样本泛化方面表现出色，在非分布数据集上的表现优于传统方法，而一些视觉大语言模型则表现出不一致或不佳的性能。值得注意的是，模型大小和高级推理能力与检测准确度的相关性有限，这表明特定任务的微调至关重要。

Conclusion: 该研究强调了多模态大语言模型在增强文档欺诈检测系统方面的潜力，并为未来研究可解释和可扩展的欺诈缓解策略奠定了基础。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [26] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: MedSAMix是一种创新的训练无关模型合并方法，它通过零阶优化自动融合通用模型和专用医学模型，显著提升了医学图像分割的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用医学图像分割模型在临床应用中展现出巨大潜力，但现有基于通用视觉模型（如SAM）微调的专用模型（如MedSAM）在面对多样性、标注稀疏性和分布偏移等挑战时，泛化能力受限。因此，需要一种方法来整合通用模型和专用模型的优势，以提升模型在广泛医学分割任务上的表现。

Method: MedSAMix是一种训练无关的模型合并方法，它结合了通用视觉模型（如SAM）和针对医学分割任务微调的专用模型（如MedSAM）的优点。该方法通过零阶优化技术自动寻找最优的层级合并策略，以整合不同模型的优势。此外，MedSAMix提供了两种优化机制：单任务优化和多目标优化，以适应不同应用场景下对领域特异性和泛化能力的需求。

Result: 在25个医学分割任务上的广泛评估表明，MedSAMix能够有效缓解模型偏差，并在特定任务的准确性和多任务泛化能力方面均实现一致的性能提升，具体表现为在专门任务上提升6.67%，在多任务评估上提升4.37%。

Conclusion: MedSAMix通过结合通用模型（如SAM）和专用模型（如MedSAM）的优势，并采用零阶优化方法自动寻找最优的逐层合并方案，有效解决了现有模型在处理多样化、标注稀疏和分布偏移的医学影像数据时泛化能力受限的问题。实验证明，MedSAMix能够减轻模型偏差，在特定任务的准确性和多任务泛化能力上均取得显著提升，分别提高了6.67%和4.37%。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [27] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: Existing 3D vision-language datasets lack multi-view and multi-object reasoning capabilities. This paper introduces MV-ScanQA and TripAlign datasets to address these limitations, along with LEGO, a method that achieves state-of-the-art performance by transferring knowledge from 2D to 3D domains.


<details>
  <summary>Details</summary>
Motivation: Existing 3D vision-language datasets have limitations, such as requiring reasoning only within a close range of objects from a single viewpoint and annotating instructions to single objects, missing richer contextual alignments between multiple objects. This hinders the development of models capable of deep, multi-view 3D scene understanding over distant objects.

Method: The paper introduces two datasets: MV-ScanQA, which requires multi-view reasoning, and TripAlign, a large-scale pre-training corpus with 1M <2D view, set of 3D objects, text> triplets for multi-object alignment. They also propose LEGO, a baseline method for multi-view reasoning by transferring knowledge from 2D LVLMs to the 3D domain using TripAlign.

Result: MV-ScanQA requires multi-view reasoning, with 68% of questions needing information from multiple views. TripAlign provides 1M multi-object alignment signals. LEGO, pre-trained on TripAlign, achieves state-of-the-art results on MV-ScanQA and existing 3D benchmarks.

Conclusion: LEGO, which transfers knowledge from pre-trained 2D LVLMs to the 3D domain using TripAlign, achieves state-of-the-art performance on MV-ScanQA, 3D dense captioning, and question answering benchmarks.

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [28] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 本研究利用 AI 分析腹部 CT 影像，发现内脏脂肪、皮下脂肪、骨骼肌脂肪化和胰腺特征是 2 型糖尿病的共同风险因素，这些因素在不同体重类别人群中均存在。


<details>
  <summary>Details</summary>
Motivation: 尽管高 BMI 是 2 型糖尿病的已知风险因素，但在一些消瘦成人中出现该疾病，而在肥胖者中却不存在，这表明详细的身体成分可能揭示 2 型糖尿病的腹部表型。利用 AI 技术，可以大规模地从腹部 3D 临床影像中提取详细的尺寸、形状和脂肪含量测量数据，从而提供一个经验性定义与 2 型糖尿病风险和保护相关的身体成分特征的机会。

Method: 本研究利用人工智能（AI）技术，对腹部 CT 影像进行分析，提取身体成分特征。研究应用了随机森林分类模型，并通过 SHAP 分析评估特征对模型预测风险或保护的贡献度。最后，通过聚类分析和解剖学关联，识别与 2 型糖尿病相关的腹部模式。

Result: 研究在不同 BMI 分组（总队列、消瘦、超重、肥胖）中均实现了 0.72-0.74 的平均 AUC。研究发现了各分组中共同的 2 型糖尿病特征，包括脂肪浸润的骨骼肌、年龄较大、内脏和皮下脂肪增加，以及胰腺体积较小或脂肪含量较高。单变量逻辑回归证实了 14-18 个预测因子在各亚组中的预测方向（p < 0.05）。

Conclusion: 研究结果表明，腹部因素对 2 型糖尿病的影响可能在不同的体重类别中是一致的。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [29] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: HierOctFusion 是一种新的 3D 内容生成模型，通过部件感知和多尺度方法提高了效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于八叉树的扩散模型在生成 3D 内容时，通常将 3D 对象视为整体，忽略了其语义部件层次结构，并且在处理高分辨率模型时计算成本高昂。然而，现实世界中的对象本质上是稀疏和分层的，这为分层生成提供了可能性。

Method: 提出了一种名为 HierOctFusion 的部件感知多尺度八叉树扩散模型，该模型通过交叉注意力机制注入部件级信息，以增强生成细粒度和稀疏对象结构的能力。此外，构建了一个带有部件类别注释的 3D 数据集以进行训练和评估。

Result: HierOctFusion 实现了优于先前方法的形状质量和效率。

Conclusion: HierOctFusion 在形状质量和效率方面优于先前的方法。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [30] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 提出了一种名为RBDM的双向扩散模型，可以进行去雾和生成雾霾的转换，并在图像块上学习以提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度去雾方法仅能从模糊图像中去除雾霾，而缺乏在模糊和无模糊图像之间进行转换的能力。

Method: 提出了一种基于残差的高效双向扩散模型（RBDM），该模型包含两个关键部分：1. 提出对偶马尔可夫链，用于有效转移残差并促进它们之间的双向平滑转换。2. RBDM在单个时间步长上扰动模糊和无模糊图像，并预测扰动数据中的噪声，以同时学习条件分布。此外，为了提高在相对较小数据集上的性能并降低计算成本，该方法在图像块而非整个图像上学习统一的分数函数。

Result: 所提出的RBDM在合成和真实世界的数据集上实现了优于或至少可比于最先进方法的性能。

Conclusion: 所提出的RBDM能够实现无尺寸限制的双向转换，并且仅需15步采样。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [31] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: 提出了一种名为MICC的新型跨模态谣言检测方法，通过整合多尺度图像内容和文本上下文信息，并利用对比学习来提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的谣言检测方法常常忽略图像内容以及跨不同视觉尺度的上下文与图像之间固有的关系，导致识别谣言的关键信息丢失。

Method: 提出了一种新颖的基于对比学习的跨模态谣言检测方案（MICC），包括：1.设计SCLIP编码器生成文本和多尺度图像块的统一语义嵌入；2.引入跨模态多尺度对齐模块，通过互信息最大化和信息瓶颈原理，以及基于跨模态相关性矩阵的Top-K选择策略，识别与文本语义最相关的图像区域；3.设计了一个感知多尺度的融合网络，通过为图像区域分配基于其语义重要性和跨模态相关性的自适应权重，来整合高度相关的多尺度图像特征与全局文本特征。

Result: 在两个真实世界数据集上的广泛评估表明，该方法在谣言检测方面取得了显著的性能提升，优于现有的最先进方法。

Conclusion: 实验结果表明，所提出的方法在谣言检测方面取得了比现有最先进方法显著的性能提升，证明了其在实际应用中的有效性和潜力。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [32] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: "LEARN是一个为STEM教育生成教学插图的布局感知扩散框架。它使用BookCover数据集，通过布局条件生成、对比视觉-语义训练和提示调整来生成支持推理和减少认知负荷的视觉序列。该方法旨在对抗碎片化注意力，促进概念专注，并可能与多模态系统和知识图谱集成。LEARN是结合布局叙事、语义结构学习和认知支架的第一个生成方法，为教育领域的生成式人工智能开辟了新方向。 "


<details>
  <summary>Details</summary>
Motivation: "STEM教育中的插图生成往往缺乏教学一致性，导致学生注意力分散和理解碎片化。LEARN旨在通过提供具有叙事布局和结构化视觉线索的插图来解决这一问题，以支持中高级推理并减少认知负荷。" 

Method:  "LEARN通过利用精选的BookCover数据集，该数据集提供叙事布局和结构化视觉线索，从而实现布局感知的生成。它通过基于布局的条件生成、对比视觉-语义训练和提示调整来生成连贯的视觉序列，以支持与布鲁姆分类法一致的从中高级推理，同时减少认知负荷理论所强调的额外认知负荷。" 

Result: "LEARN能够生成连贯的视觉序列，支持中高级推理，并减少认知负荷。该框架通过促进空间组织和驱动故事叙述的叙述，可以对抗短媒体引起的注意力分散，并促进持续的概念关注。 "

Conclusion: "LEARN是第一个将基于布局的故事叙述、语义结构学习和认知支架结合起来的生成方法，代表了生成式人工智能在教育领域的一个新方向。代码和数据集将发布，以促进未来的研究和实际应用。 "

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [33] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 通过EM和B3DM模型，结合两阶段学习和RDC模块，实现高效半监督图像去雾，并在真实和合成数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法难以处理真实世界的模糊图像，特别是浓雾场景，主要原因是缺乏真实配对数据和鲁棒先验。

Method: 提出了一种基于期望最大化（EM）和双向布朗桥扩散模型（B3DM）的半监督图像去雾方法，并采用两阶段学习方案。第一阶段，利用EM算法解耦配对的模糊和清晰图像的联合分布，并使用统一的布朗桥扩散模型来捕捉它们之间的结构和内容相关性。第二阶段，利用预训练模型和大规模无配对数据进一步提升性能。此外，引入了增强细节的残差差分卷积（RDC）模块来捕捉梯度级信息。

Result: EM-B3DM在合成和真实世界数据集上均取得了优于或相当的性能。

Conclusion: 提出的EM-B3DM方法在合成和真实世界数据集上均优于现有最先进的方法。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [34] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: VG-DETR是一种新的半监督方法，通过利用视觉基础模型（VFM）和少量目标数据，解决了遥感图像中源域无关目标检测的伪标签噪声问题，并取得了更好的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的遥感场景中，隐私和传输限制常常无法获取源域数据，限制了无监督域自适应方法的实际应用。源域无关目标检测（SFOD）作为一种有前景的替代方案，旨在无需源数据的情况下实现跨域自适应，但现有SFOD方法（主要通过自训练范式）常因伪标签噪声导致训练崩溃，尤其是在遥感图像中目标密集且背景复杂的情况下。考虑到在实践中获取有限的目标域标注是可行的，因此需要一种新的方法来解决这些问题。

Method: 提出了一种名为VG-DETR的半监督框架，用于源域无关的遥感目标检测。该框架将视觉基础模型（VFM）以“免费午餐”的方式集成到训练流程中，利用少量的标记目标数据来减轻伪标签噪声并增强检测器的特征提取能力。具体而言，引入了一种VFM引导的伪标签挖掘策略，利用VFM的语义先验来评估伪标签的可靠性，并通过恢复低置信度输出来提高伪标签的质量和数量。此外，提出了一种双重VFM引导的对齐方法，在实例和图像层面将检测器特征与VFM嵌入进行对齐，通过细粒度原型之间的对比学习和特征图之间的相似性匹配，增强了特征表示对领域差距的鲁棒性。

Result: VG-DETR通过VFM引导的伪标签挖掘策略和双重VFM引导的对齐方法，有效缓解了伪标签噪声问题，提升了特征提取能力和鲁棒性，在源域无关的遥感目标检测任务中取得了优越的性能。

Conclusion: VG-DETR在源域无关的遥感目标检测任务中取得了优越的性能。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [35] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: IOVQA通过整数标签和目标掩码策略优化VLM视频质量评估，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在视频内容评估方面存在结果不精确和损失计算效率低的问题，限制了模型在关键评估指标上的表现。需要一种方法来提高VLM在视频质量评估任务中的性能。

Method: IOVQA是一种新颖的微调方法，通过在数据集构建中将十进制的Overall_MOS转换为整数作为标签（范围限制在[10, 50]），并采用目标掩码策略，在损失计算时仅保留标签的前两位整数，迫使模型关注关键的数值评估组件。

Result: 使用IOVQA微调Qwen2.5-VL模型后，实验结果表明该方法显著提高了模型在VQA任务中的准确性和一致性，在VQualA 2025 GenAI-Bench AIGC视频质量评估挑战赛（Track I）中排名第三。

Conclusion: IOVQA方法通过约束模型输出为整数、采用目标掩码策略进行损失计算，有效提升了VLM在视频质量评估任务中的准确性和一致性。该方法为优化VLM在量化评估场景下的表现提供了有效思路，并在VQualA 2025 GenAI-Bench AIGC视频质量评估挑战赛中取得了优异成绩。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [36] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为IDOD的新方法，用于连续类别发现（CCD）。IDOD通过三个模块解决现有CCD方法的局限性：独立多样性丰富、联合新颖性发现和基于正交性的连续递增。与现有方法相比，IDOD在不占用更多存储空间的情况下，更好地处理了新类别发现和分类之间的矛盾，减少了错误累积，并有效防止了遗忘。在细粒度数据集上的实验结果证明了该方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 由于新到达的数据中没有类别数量和标签，并且需要缓解灾难性遗忘，因此这是一个具有挑战性的问题。大多数CCD方法不能很好地处理新类别发现和分类之间的矛盾。它们还容易在逐渐发现新类别的过程中累积错误。此外，大多数方法使用知识蒸馏和数据重放来防止遗忘，这会占用更多的存储空间。

Method: IDOD主要包括独立多样性丰富模块、联合新颖性发现模块和基于正交性的连续递增模块。在独立丰富中，主干使用对比损失单独训练，以避免其仅关注分类特征。联合发现将多阶段新颖类别发现转化为单阶段，减少了错误累积的影响。基于正交性的连续递增模块生成相互正交的类别原型，并通过代表性表示重放以较低的空间开销防止遗忘。

Result: 实验结果表明，在具有挑战性的细粒度数据集上，我们的方法优于最先进的方法。

Conclusion: 实验结果表明，在具有挑战性的细粒度数据集上，我们的方法优于最先进的方法。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [37] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: LatHAdapter通过利用双曲学习和潜在语义层次结构，改进了视觉语言模型在小样本分类任务中的适配器微调方法，解决了现有方法在处理一对多关联和未知类别泛化方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于适配器的方法在微调预训练的视觉语言模型（VLMs）用于小样本分类任务时，通常通过嵌入空间中的显式空间邻近性来对齐视觉和文本表示，但这未能捕获类别与图像样本之间固有的一对多关联，并且难以建立未知类别与图像之间的准确关联。

Method: 提出了一种新颖的潜在分层适配器（LatHAdapter），利用下游训练数据的潜在语义层次结构，通过可学习的“属性”提示作为桥梁来对齐类别和图像，并在双曲空间中进行投影，利用分层正则化来学习类别、可学习属性和图像样本之间的潜在语义层次结构，以解决现有适配器在捕获类别与图像样本之间的一对多关联以及建立未知类别与图像之间准确关联方面的不足。

Result: LatHAdapter 能够完全模拟类别、可学习属性和图像样本之间固有的一对多关联，从而在小样本分类任务上实现更好的性能。

Conclusion: LatHAdapter 在四个具有挑战性的小样本任务上持续优于其他微调方法，尤其在适应已知类别和泛化到未知类别方面表现突出。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [38] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: GVT是一种新的视频标记器，利用2D高斯泼溅来提高空间适应性和时间通用性，在视频重建、动作识别和压缩方面均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的视频标记方法（如固定网格和块状标记）在空间和时间上都存在局限性，可能导致信息丰富度低的区域过度编码，并且难以在不区分静态和动态内容的情况下减少冗余。

Method: 本文提出了一种名为高斯视频变换器（GVT）的通用视频标记器，该标记器基于生成式2D高斯泼溅（2DGS）策略。通过提出的时空高斯嵌入（STGE）机制，将视频剪辑的潜在刚性特征表示为一组2D高斯。通过高斯集合划分（GSP）策略将2D高斯分为静态和动态集，以增强时间通用性。

Result: GVT在UCF101、Kinetics和Davis数据集上进行了评估，在视频重建方面实现了最先进的质量，在动作识别方面优于基线模型MAGVIT-v2，并在视频压缩方面实现了可比的性能。

Conclusion: GVT在视频重建、动作识别和视频压缩方面取得了最先进的性能，在视频重建方面质量最高，在动作识别方面优于基线模型MAGVIT-v2，在视频压缩方面表现相当。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [39] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: This paper analyzes the impact of camera height variations on monocular 3D object detectors, finding depth estimation to be a key factor. It proposes CHARM3R, a method that averages depth estimates to improve generalization to unseen camera heights, achieving state-of-the-art performance on the CARLA dataset.


<details>
  <summary>Details</summary>
Motivation: Monocular 3D object detectors struggle with unseen or out-of-distribution camera heights. This paper investigates the impact of camera height variations on SoTA Mono3D models and proposes a solution.

Method: CHARM3R averages both depth estimates within the model to mitigate the impact of camera height variations.

Result: The study observes that depth estimation is a primary factor influencing performance under height variations. It also mathematically proves and empirically observes consistent negative and positive trends in mean depth error of regressed and ground-based depth models, respectively, under camera height changes.

Conclusion: The proposed CHARM3R method improves generalization to unseen camera heights by more than 45%, achieving SoTA performance on the CARLA dataset.

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [40] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: 本研究提出了一种自动化的方法，利用大型语言模型将单人教学视频转换为两人对话，以协助完成现实世界任务。该方法创建了一个名为 HowToDIV 的大型数据集，包含 507 次对话、6636 个问答对和 24 小时的视频片段，涵盖了烹饪、机械和种植等领域。研究人员还建立了基于 Gemma-3 模型的基准性能，为未来的研究铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 许多日常任务，如修理设备、烹饪食谱和汽车保养，都需要专业知识，尤其是当任务复杂且涉及多个步骤时。尽管人们对人工智能代理的兴趣日益浓厚，但用于现实世界任务协助的、以真实世界任务为基础的对话视频数据集却很少。

Method: 本论文提出了一种将单人教学视频转换为两人对话的方法，该对话与细粒度步骤和视频剪辑对齐。该方法利用大型语言模型实现全自动化，以克服人工收集数据成本高昂的缺点。

Result: 我们构建了一个名为HowToDIV的大规模数据集，其中包含 507 次对话、6636 个问答对以及跨越烹饪、机械和种植等不同任务的 24 小时视频片段。我们还使用 Gemma-3 模型在 HowToDIV 数据集上建立了基准性能，为未来在此类程序性任务辅助对话的新任务上开展研究奠定了基础。

Conclusion: 我们提出了一个将单人教学视频转换为两人对话以进行任务指导的简单而有效的方法，该方法与细粒度步骤和视频片段对齐。我们的全自动方法由大型语言模型支持，为人类辅助数据收集所需的大量成本和精力提供了一种有效的替代方案。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [41] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: 针对无人机航空影像的挑战，提出轻量级VLM Uav-vl-r1，采用SFT和基于GRPO的RL混合训练，并引入HRVQA-VL数据集。结果显示UAV-VL-R1在准确率、鲁棒性和资源效率方面均优于现有模型，适合无人机实时部署。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型在无人机航空影像上的性能会下降，因为航空影像具有高分辨率、复杂的空间语义和严格的实时性限制。这些挑战阻碍了通用视觉语言模型在结构化航空推理任务中的应用。

Method: 提出了一种名为UAV-VL-R1的轻量级视觉语言模型，该模型采用监督微调（SFT）和多阶段强化学习（RL）的混合方法进行训练。利用组相对策略优化（GRPO）算法，通过规则引导的奖励和组内策略对齐来促进结构化和可解释的推理。同时，引入了高分辨率视觉问答数据集HRVQA-VL，包含50,019个标注样本，涵盖八种与无人机相关的推理任务。

Result: UAV-VL-R1在零样本准确率上比基线模型Qwen2-VL-2B-Instruct高48.17%，并且在多个任务上优于其72B规模的版本。消融实验表明，SFT提高了语义对齐，但可能降低了数学任务的推理多样性，而基于GRPO的RL增强了逻辑灵活性和推理鲁棒性。UAV-VL-R1在FP16下仅需3.9GB内存，量化为INT8后为2.5GB，支持在资源受限的无人机平台上进行实时部署。

Conclusion: UAV-VL-R1在资源受限的无人机平台上实现了高效且准确的航空视觉推理，在零样本准确率上显著优于基线模型，并展示了其在各种航空视觉任务中的鲁棒性和可部署性。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [42] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 提出了一种新颖的粗到细两阶段知识蒸馏框架，通过引入关节结构损失和图像引导渐进图卷积网络（IGP-GCN），有效解决了传统知识蒸馏未能充分利用关节间上下文信息的问题，并在COCO和CrowdPose数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了获得准确、鲁棒且轻量级的人体姿态估计器，通过知识蒸馏将姿态知识从强大的教师模型转移到参数较少学生模型是一种可行的方法。然而，传统的知识蒸馏框架未能充分探索人体关节间的上下文信息。

Method: 提出了一种新颖的粗到细两阶段知识蒸馏框架，用于人体姿态估计。在第一阶段蒸馏中，引入了人体关节结构损失来挖掘关节间的结构信息，将高层语义知识从教师模型迁移到学生模型。在第二阶段蒸馏中，利用图像引导渐进图卷积网络（IGP-GCN）来优化从第一阶段获得的初始人体姿态，并通过教师模型的最终输出来渐进地监督IGP-GCN的训练。

Result: 所提出的方法在COCO关键点和CrowdPose数据集上进行了广泛的实验，结果表明该方法在性能上优于许多现有的最先进的人体姿态估计方法，尤其是在更复杂的CrowdPose数据集上，性能提升更为显著。

Conclusion: 所提出的方法在COCO关键点和CrowdPose数据集上进行了广泛的实验，结果表明该方法在性能上优于许多现有的最先进的人体姿态估计方法，尤其是在更复杂的CrowdPose数据集上，性能提升更为显著。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [43] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 提出轻量级UMM框架，解决自动驾驶行人ReID中的不确定模态问题，无需微调即可融合多模态信息，并实现高效鲁棒的识别。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中，来自RGB、红外、草图或文本描述等不确定或缺失的输入模态对传统ReID方法的挑战，以及现有大模型计算开销大的问题。

Method: 提出了一种轻量级的非确定性模态建模（UMM）框架，该框架集成了多模态令牌映射器、合成模态增强策略和跨模态线索交互学习器。UMM利用CLIP的视觉-语言对齐能力，无需大量微调即可有效地融合多模态输入。

Result: 实验结果表明，UMM在不确定的模态条件下实现了强大的鲁棒性、泛化性和计算效率。

Conclusion: UMM框架在不确定的模态条件下实现了强大的鲁棒性、泛化性和计算效率，为自动驾驶场景中的行人重新识别提供了可扩展且实用的解决方案。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [44] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 通过Talking-Critic奖励模型和TLPO框架，解决了现有音频驱动肖像动画方法在满足多维度人类偏好方面的不足，显著提高了动画质量和对齐精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在满足运动自然度、唇语同步精度和视觉质量等多维度精细化人类偏好方面存在困难，因为优化相互冲突的偏好目标以及缺乏包含多维度偏好注释的大规模、高质量数据集。

Method: 提出了一种名为TLPO（Timestep-Layer adaptive multi-expert Preference Optimization）的新型框架，该框架将偏好解耦为专门的专家模块，并跨时间步和网络层进行融合，从而在所有维度上实现全面的、细粒度的增强，且不会相互干扰。同时，引入了Talking-Critic，一个多模态奖励模型，用于学习人类偏好函数。

Result: Talking-Critic显著优于现有方法；TLPO在唇语同步精度、动作自然度和视觉质量方面取得显著改进。

Conclusion: TLPO框架在唇语同步精度、动作自然度和视觉质量方面取得了显著进步，并在定性和定量评估中均表现出优越的性能。Talking-Critic在与人类偏好评级对齐方面显著优于现有方法。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [45] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP通过解耦CLIP的自注意力机制，并融合来自VFMs和扩散模型的线索，分别增强了“内容”和“上下文”特征，解决了CLIP在密集视觉感知任务中局部特征表示不足的问题，在多项任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的密集视觉感知任务受限于预定义的类别，限制了其在现实世界中的应用。尽管CLIP等视觉语言模型（VLMs）在开放词汇任务中表现出潜力，但由于局部特征表示的限制，其在密集感知任务上的直接应用性能不佳。CLIP的图像标记难以有效地聚合来自空间或语义相关区域的信息，导致特征缺乏局部可辨别性和空间一致性。

Method: 提出DeCLIP框架，通过解耦自注意力机制来获得“内容”和“上下文”特征。上下文特征通过融合视觉基础模型（VFMs）的语义相关性和扩散模型的物体完整性线索来增强，以提高空间一致性。内容特征则通过与图像裁剪表示对齐并受VFMs的区域相关性约束来提高局部可辨别性。

Result: DeCLIP在2D检测和分割、3D实例分割、视频实例分割和6D物体姿态估计等任务上取得了最先进的性能。

Conclusion: DeCLIP为开放词汇的密集视觉感知奠定了坚实的基础，在2D检测和分割、3D实例分割、视频实例分割和6D物体姿态估计等广泛任务中始终 achieves state-of-the-art performance。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [46] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 视觉-语言模型在性别关联上存在偏见，本研究通过分析模型如何将性别与职业关联来量化这种偏见。


<details>
  <summary>Details</summary>
Motivation: 为了探究视觉-语言模型（VLM）在对齐图像和文本时可能产生的性别刻板印象，即使标准准确率指标无法显现。

Method: 研究人员利用包含220张面部照片和150个陈述的数据集，计算了男性和女性嵌入的平均余弦相似度之间的差异，以量化性别关联。通过自助法置信区间和标签交换模型来评估关联的稳健性。

Result: 研究结果呈现了在对比式视觉-语言空间中，陈述和类别层面的性别关联图，并附带了不确定性评估、健全性检查和一个稳健的性别偏见评估框架。

Conclusion: 该研究揭示了在对比式视觉-语言模型中存在的性别关联，即模型将男性和女性的嵌入与其相关的职业和活动短语进行区分。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [47] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: 提出了一种名为 CGE 和 GCL 的新框架，用于改善 3D 点云分割的领域泛化。该方法专注于类别级几何属性和对齐，以提高模型在不同环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 3D 分割中的领域泛化在将模型部署到未知环境中时是一个关键挑战。现有方法通过增强点云的数据分布来缓解领域转移。然而，模型学习点云中的全局几何模式，而忽略了类别级分布和对齐。

Method: 提出了一种类别级几何学习框架，用于探索领域泛化 3D 语义分割的领域不变几何特征。具体来说，提出类别级几何嵌入（CGE）来感知点云特征的细粒度几何属性，构建每个类别的几何属性并将几何嵌入与语义学习相结合。其次，提出几何一致性学习（GCL）来模拟潜在的 3D 分布并对齐类别级几何嵌入，使模型能够专注于几何不变信息以提高泛化能力。

Result: 与最先进的领域泛化点云方法相比，具有非常竞争的分割精度。

Conclusion: 实验结果验证了所提出方法的有效性，与最先进的领域泛化点云方法相比，具有非常竞争的分割精度。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [48] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: 提出了一种名为 PMTFR 的新框架，通过增强视觉信息理解和利用无训练调整范式，在 composto imagen retrieval 任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 compuesto imagen retrieval 方法通常采用两阶段方法，需要额外的排序模型训练。Chain-of-Thought (CoT) 技术在降低语言模型训练成本方面取得了成功，但在 compuesto imagen retrieval 任务中的应用有限，并且主要用于零样本 compuesto imagen retrieval，在监督 compuesto imagen retrieval 中难以取得满意结果。

Method: 提出了一种包含 "Pyramid Matching Model with Training-Free Refinement" (PMTFR) 的框架，该框架使用 "Pyramid Patcher" 模块来增强金字塔匹配模型对不同粒度视觉信息的理解，并通过表示工程提取 COT 数据的表示并将其注入 LVLMs，在无训练调整范式中获得改进的检索分数。

Result: 通过金字塔匹配模型和无训练调整，PMTFR 框架在视觉信息理解和检索性能方面得到了提升，并在公开的 compuesto imagen retrieval 基准测试中取得了优于现有最先进方法的成果。

Conclusion: PMTFR框架在监督 compuesto imagen retrieval 任务上超越了最先进的方法。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [49] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: SAE在视觉模型中表现出色，能够提高可解释性、泛化性和可控性，为SAE在视觉领域的应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管SAE在语言模型中很受欢迎，但在视觉领域的研究仍然不足。

Method: 对SAE在三种视觉模型架构（视觉嵌入模型、多模态LMM和扩散模型）上的表示能力进行了广泛评估。

Result: SAE特征具有语义意义，提高了分布外泛化能力，并实现了可控生成。在视觉嵌入模型中，SAE特征可用于OOD检测，并能恢复底层模型的本体结构。在扩散模型中，SAE能够通过文本编码器操纵实现语义引导，并发现了可供人类理解的属性。在多模态LLM上进行的探索性实验表明，SAE特征揭示了跨视觉和语言模态的共享表示。

Conclusion: SAE在视觉模型中具有提高可解释性、泛化性和可控性的巨大潜力，为SAE在视觉模型中的评估奠定了基础。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [50] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: 提出了一种新的单目内窥镜组织重建框架，通过深度预测和时间精炼来解决现有方法的局限性，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了提高单目微创手术的导航精度和空间感知能力，需要实现精确的内窥镜姿态估计和三维组织表面重建。然而，现有的单目内窥镜姿态估计和组织重建方法面临深度模糊、生理组织变形、内窥镜运动不一致、纹理保真度有限和视场受限等挑战。

Method: 提出了一种统一的单目内窥镜组织重建框架，集成了尺度感知深度预测和时间约束感知精炼。该框架包含一个MAPIS-Depth模块，利用Depth Pro进行初始化，Depth Anything进行逐帧深度预测，并结合L-BFGS-B优化生成伪度量深度估计。然后，使用RAFT计算像素对应关系，并基于LPIPS感知相似性自适应地融合流扭曲帧，以进行时间精炼。此外，还集成了一个WEMA-RT6D模块来优化旋转和平移，以实现合成的伪RGBD帧的精确配准。最后，采用截断符号距离函数（TSDF）进行体积融合，并结合Marching Cubes提取三维表面网格。

Result: 通过在HEVD和SCARED数据集上的评估、消融研究和对比分析，证明了所提出的框架在应对单目内窥镜组织重建挑战方面的鲁棒性和优越性，其性能优于现有最先进的方法。

Conclusion: 该框架通过集成尺度感知深度预测和时间约束感知精炼，克服了单目内窥镜组织重建中的深度模糊、生理组织变形、内窥镜运动不一致、纹理保真度有限和视场受限等挑战，并在HEVD和SCARED数据集上进行了评估，证明了其鲁棒性和优于最先进方法的性能。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [51] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: TimeMachine框架通过注入年龄信息和使用ACG模块，实现了精确可控的面部年龄编辑，同时保留身份信息。该框架在HFFA数据集上进行了训练和验证，并在实验中取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 实现精细的年龄编辑，同时保留个人身份信息仍然是一个挑战。

Method: TimeMachine框架通过在多重交叉注意力模块中注入高精度年龄信息，明确分离年龄相关和身份相关特征，以实现精细的年龄编辑。此外，还提出了年龄分类器指导（ACG）模块，在潜在空间中直接预测年龄，而不是在训练期间进行去噪图像重建，以提高年龄编辑的准确性。同时，构建了一个包含一百万张高分辨率图像、并带有身份及面部属性标签的HFFA数据集（高质量精细面部年龄数据集），以解决缺乏大规模、高质量面部年龄数据集的问题。

Result: 实验结果表明，TimeMachine在精细年龄编辑方面取得了最先进的性能，同时保持了身份一致性。

Conclusion: TimeMachine在年龄编辑方面取得了最先进的性能，同时保持了身份一致性。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [52] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 高光谱成像结合最佳波段选择（CSNR-JMIM）能显著提高汽车感知系统中行人分割的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决RGB成像中的同质性问题，即行人和背景在视觉上难以区分，从而提高汽车感知系统中行人分割的安全关键性。

Method: 本研究将HSI数据转换为三通道表示（PCA和CSNR-JMIM），并评估了U-Net、DeepLabV3+和SegFormer三种语义分割模型，以提升城市驾驶场景下的行人分割能力。

Result: 与RGB相比，CSNR-JMIM在高光谱数据处理方面表现更优，在行人分割的IoU和F1分数上分别平均提高了1.44%和2.18%，在骑行者分割方面也取得了相似的提升。

Conclusion: 本研究证明了通过最佳高光谱成像(HSI)波段选择可以实现稳健的行人分割，这对于安全关键的汽车应用具有巨大的潜力。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [53] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出了一种新的“去噪-检索”方法（DRNet），通过去除视频中与文本无关的内容，然后进行检索，提高了视频时刻检索的准确性。该方法在两个基准数据集上均取得了最佳效果，并且易于集成到现有模型中。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时刻检索方法会将所有视频片段（包括不相关的片段）进行编码，这会干扰多模态信息的对齐并阻碍优化过程。为了解决这个问题，本文提出了一种“去噪-检索”范式，旨在显式地过滤掉文本不相关的视频片段，然后利用净化后的多模态表示进行检索。

Method: 提出了一种名为“去噪-检索网络”（DRNet）的方法，该网络包含“文本条件去噪”（TCD）和“文本重建反馈”（TRF）两个模块。TCD利用交叉注意力和结构化状态空间块来动态识别和去除噪声片段，生成一个去噪掩码来净化视频表示。TRF则从净化后的视频表示中提炼出单一查询嵌入，并使其与文本嵌入对齐，作为训练期间去噪的辅助监督。

Result: 实验结果表明，所提出的DRNet方法在Charades-STA和QVHighlights数据集上，在所有评估指标上均超越了现有的最先进方法。此外，该去噪-检索范式具有良好的适应性，可以无缝集成到先进的视频时刻检索模型中以提升性能。

Conclusion: 该研究提出的“去噪-检索”范式能够有效地过滤掉与文本不相关的视频片段，并通过提炼后的多模态表示进行检索，从而提高了视频时刻检索的准确性。该方法在Charades-STA和QVHighlights数据集上均取得了优于现有最先进方法的性能，并且易于集成到其他模型中以提升效果。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [54] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 现有视觉语言模型（VLMs）在逻辑理解方面存在不足。研究者提出了LogicBench基准测试和LogicCLIP训练框架来解决这个问题。LogicCLIP通过改进的数据生成和训练策略，显著提升了VLMs的逻辑推理能力，并且不影响其通用性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在逻辑理解方面存在“逻辑盲点”，限制了其在实际应用中的可靠性，需要对其进行系统诊断并提升其逻辑理解能力。

Method: 提出LogicBench基准测试，包含50,000多个跨越9个逻辑类别和4种场景的视觉-语言对，并提出LogicCLIP训练框架，通过数据生成和优化目标来增强视觉语言模型的逻辑敏感性。LogicCLIP采用逻辑感知数据生成、对比学习策略，结合粗粒度对齐、细粒度多项选择和新颖的逻辑结构感知目标。

Result: 现有VLMs在LogicBench上的准确率比人类低40多个百分点，尤其在因果关系和条件句方面。LogicCLIP在LogicBench所有领域都显著提高了逻辑理解能力，并且在通用视觉-语言基准测试上表现出竞争力，甚至超越了基线模型。

Conclusion: LogicBench和LogicCLIP是推进视觉语言模型逻辑能力的重要资源。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [55] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: RETFound, a foundation model for fundus images, was adapted for optic disc segmentation and achieved ~96% Dice score on multiple datasets, outperforming existing methods with limited training data.


<details>
  <summary>Details</summary>
Motivation: The motivation was to explore the applicability of the RETFound foundation model beyond its known uses in disease diagnosis from retinal images and to adapt it for the fundamental task of optic disc segmentation.

Method: The study adapted the RETFound foundation model for optic disc segmentation, a foundational task in retinal image analysis. A segmentation head was trained using a small number of task-specific examples.

Result: The adapted RETFound model achieved approximately 96% Dice score consistently across four public datasets (IDRID, Drishti-GS, RIM-ONE-r3, REFUGE) and one private dataset (GoDARTS). It outperformed state-of-the-art, segmentation-specific baseline networks and demonstrated excellent performance in internal verification, domain generalization, and domain adaptation.

Conclusion: RETFound, a foundation model for fundus images, has been successfully adapted for optic disc segmentation, outperforming state-of-the-art segmentation-specific models with minimal task-specific training data. The adapted model achieved consistent Dice scores of ~96% across multiple public and private datasets, demonstrating excellent performance in internal verification, domain generalization, and domain adaptation.

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [56] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: DSC-Track通过一种线索一致性原则，利用点对特征和Transformer来处理3D多目标跟踪中的遮挡和干扰问题，并在nuScenes和Waymo数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理密集场景或不准确检测时，由于忽略了物体间的几何关系，效果不佳。而现有的考虑几何关系的方法容易受到无关物体的干扰，导致特征模糊和关联错误。因此，需要一种能利用空间线索并克服干扰的方法。

Method: 提出了一种名为动态场景线索一致性跟踪器（DSC-Track）的方法。该方法包括一个统一的时空编码器（使用点对特征PPF）来学习具有区分性的轨迹嵌入并抑制干扰，一个线索一致性Transformer模块来明确地对齐历史轨迹和当前检测之间的特征表示，以及一个动态更新机制来保留显著的时空信息以实现稳定的在线跟踪。

Result: 通过在nuScenes和Waymo Open Datasets上的实验证明了该方法的有效性和鲁棒性，并在nuScenes数据集上达到了最先进的性能，AMOTA分别达到了73.2%（验证集）和70.3%（测试集）。

Conclusion: 该方法在nuScenes和Waymo Open Datasets上进行了广泛的实验，验证了其有效性和鲁棒性。在nuScenes基准上，该方法在验证集和测试集上分别达到了73.2%和70.3%的AMOTA，达到了最先进的性能。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [57] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: NoOp 通过优化“好”噪声来稳定扩散分类器（DC）的性能，解决了噪声不稳定性问题，并提高了分类速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前预训练的视觉-语言模型（如 CLIP）存在的词袋问题和虚假偏差，以及当前扩散分类器（DC）存在的噪声不稳定性问题（即不同的随机噪声会导致显著的性能变化），并提高 DC 的分类速度（现有方法通过集成大量采样噪声来解决不稳定性问题，显著降低了速度）。

Method: 提出了一种名为 NoOp 的新颖噪声优化方法，以学习匹配的（“好”）噪声来解决 DC 的噪声不稳定性问题。NoOp 包含两个关键部分：1. **频率匹配**：优化特定数据集和时间步 t 的噪声。2. **空间匹配**：训练一个元网络，该网络以图像作为输入并输出图像特定的噪声偏移。通过将优化后的噪声和噪声偏移相结合，NoOp 可以替代 DC 中的随机噪声，从而实现更稳定的分类性能。

Result: 通过大量消融实验，证明了 NoOp 在各种数据集上的有效性，能够缓解 DC 的噪声不稳定性问题，并提高分类性能和速度。

Conclusion: NoOp 通过优化和元网络学习匹配的“好”噪声，可以缓解扩散分类器（DC）的噪声不稳定性问题，并在各种数据集上展示了有效性。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [58] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: This paper presents a new method to control how MLLMs describe images by guiding their output with rewards for accuracy (precision) and completeness (recall). This allows users to tune the model's responses on the fly, balancing detail and accuracy, and improves performance compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: To adapt Multimodal Large Language Models (MLLMs) for diverse user needs by enabling controlled decoding, specifically to improve their visual grounding capabilities.

Method: The paper introduces a reward-guided decoding method for MLLMs, using two separate reward models to control object precision and recall independently. This method guides the MLLM's decoding process on-the-fly by adjusting the relative importance of reward functions and controlling the search breadth during decoding.

Result: The method demonstrates significant controllability over MLLM inference, allowing users to dynamically trade off object precision for recall and control the trade-off between compute time and grounding degree. It consistently outperforms existing hallucination mitigation methods on standard benchmarks.

Conclusion: The proposed reward-guided decoding method offers significant controllability over MLLM inference, outperforming existing hallucination mitigation methods and allowing dynamic trade-offs between object precision and recall.

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [59] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: GANDiff FR是一个创新的合成框架，通过精确控制人口和环境因素来衡量、解释和减少偏差，并已成功用于公平性审计，减少了组间差异，并证实了其合成数据的真实性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 为了精确控制人口和环境因素，以可复现的严谨性来衡量、解释和减少偏差，从而建立一个符合法规标准的公平性审计框架。

Method: GANDiff FR框架统一了基于StyleGAN3的身份保持生成和基于扩散的属性控制，能够实现对人脸姿态（约30度）、光照（四方向）和表情（五级别）等因素的精细操控，同时保持其他条件不变。

Result: 在相同的运行点下，对ArcFace、CosFace和AdaFace的基准测试表明，AdaFace将组间TPR差异减少了60%（2.5% vs. 6.3%），其中光照因素占了剩余偏差的42%。跨数据集（RFW、BUPT和CASIA WebFace）的评估证实了合成数据与真实数据之间具有很强的迁移性（r=0.85）。

Conclusion: GANDiff FR是一个首创的合成框架，能够精确控制人口和环境因素，以可复现的严谨性来衡量、解释和减少偏差。该框架结合了基于StyleGAN3的身份保持生成和基于扩散的属性控制，能够对约30度的人脸姿态、四种方向的光照和五个级别的影响进行精细操控。通过合成10,000张跨五个队列的人脸，并经过自动检测（98.2%）和人工审查（89%）验证其真实性，以分离和量化偏差驱动因素。实验证明，与纯GANs相比，GANDiff FR在计算开销增加约20%的情况下，能产生三倍的属性条件变体，为公平性审计建立了一个可复现、符合法规（欧盟人工智能法案）的标准。代码和数据已发布，以支持透明、可扩展的偏差评估。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [60] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的索引对齐查询蒸馏（IAQD）方法，用于解决增量对象检测中的知识遗忘问题。与现有的匈牙利匹配方法不同，IAQD通过匹配具有相同索引的查询并仅在关键查询上进行蒸馏，有效保留了模型对先前类别的检测能力，同时学习新类别，最终取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在增量对象检测（IOD）任务中，基于Transformer的检测模型可能会出现灾难性知识遗忘问题。先前的研究主要依赖知识蒸馏（KD）来缓解此问题，具体方法是使用匈牙利匹配来匹配查询并对齐输出。然而，研究者发现匈牙利匹配在这种任务中并非最佳选择，因为它可能导致模型遗忘先前编码的知识。

Method: 提出了一种名为索引对齐查询蒸馏（IAQD）的新蒸馏方法。该方法通过建立具有相同索引的前一阶段和当前阶段模型的查询之间的对应关系，并仅在对检测先前类别至关重要的部分查询上执行索引对齐蒸馏，从而在不干扰新类别学习的情况下，在很大程度上保留了先前的前语义和空间编码能力。

Result: IAQD成功缓解了知识遗忘问题，并在增量对象检测任务中取得了新的最先进的性能。

Conclusion: 所提出的IAQD方法有效缓解了灾难性遗忘问题，并在代表性基准测试中取得了新的最先进的性能。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [61] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: SRL损失函数在分割细长管状结构方面的性能被证明并不优于传统基线模型。


<details>
  <summary>Details</summary>
Motivation: 为了评估SRL（一种用于分割细长管状结构的拓扑保持损失函数）的有效性，并探究基于拓扑的损失函数的局限性。

Method: 对SRL损失函数的梯度进行了理论分析，并在多个管状数据集上进行了实证评估，将SRL模型的性能与传统基线模型进行了比较。

Result: SRL模型的分割性能并未超过传统的基线模型，这与原始研究的声称不符。

Conclusion: 该研究通过理论分析和实证评估，揭示了基于拓扑的损失函数（特别是SRL）在分割细长管状结构方面的局限性，表明其性能并未优于传统基线模型，并为开发更有效的分割模型提供了见解。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [62] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: Active labeling reduces human cost in training cervical cell classifiers by intelligently selecting images to label based on model uncertainty.


<details>
  <summary>Details</summary>
Motivation: Existing automatic classification methods for cervical cells require representative training datasets, which incur high human costs. This paper addresses the need for a more cost-effective approach.

Method: Active labeling that leverages the classifier's uncertainty on unlabeled cervical cell images to select the most beneficial images for labeling, with a fast estimation of uncertainty.

Result: The active labeling algorithm enhances the representative ability of the training dataset and demonstrates efficacy in navigating human cost usage, leading to data-efficient cervical cell classification.

Conclusion: The proposed active labeling method efficiently constructs a representative training dataset with reduced human cost for data-efficient cervical cell classification, confirmed by empirical results.

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [63] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: G-CUT3R是一种新的3D场景重建方法，它通过结合深度和相机信息等额外数据来改进CUT3R模型。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈方法仅依赖输入图像，而G-CUT3R旨在利用真实世界场景中常见的辅助数据（如深度、相机标定或相机位置）来提升3D场景重建的性能。

Method: G-CUT3R是一种前馈方法，通过引入专门的编码器来处理辅助数据（如深度、相机标定、相机位置），并使用零卷积将提取的特征与RGB图像特征融合。

Result: 在多个基准测试中，包括3D重建和其他多视图任务，G-CUT3R均展示了显著的性能提升，证明了其有效利用可用先验信息的能力，并能兼容不同的输入模态。

Conclusion: G-CUT3R通过整合先验信息（如深度、相机标定或相机位置）增强了CUT3R模型，实现了更优的3D场景重建效果。该方法采用轻量级修改，为不同模态数据设计了专用编码器，并通过零卷积与RGB图像特征融合，能够灵活处理各种先验信息。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [64] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 本文提出了一种利用预训练模型（如BERT、CLIP）进行语义分析的方法，来选择对视觉模型进行对抗性攻击时最有利或最不利的目标标签，这种方法比传统的基于WordNet的方法更有效且更具可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有针对视觉模型的定向对抗性攻击中，目标标签的选择至关重要但常被忽视。现有的策略（随机、模型预测、静态语义资源）在可解释性、可复现性或灵活性方面存在局限。因此，需要一种更有效、更具解释性的目标标签选择方法。

Method: 本文提出了一种语义引导框架，利用预训练的语言模型（BERT, TinyLLAMA）和视觉-语言模型（CLIP）的跨模态知识迁移能力，来选择与真实标签语义上最相关和最不相关的目标标签，从而构建最佳和最差情况的对抗性场景。

Result: 实验结果表明，所提出的语义引导框架能够生成实用的对抗性目标，并且在处理远距离类别关系时优于WordNet等静态词汇数据库。此外，静态测试目标标签可以初步评估相似性源的有效性（先验测试）。

Conclusion: 本文提出的语义引导框架通过跨模态知识迁移，利用预训练语言和视觉-语言模型来选择对抗性目标标签，并在实践中验证了其有效性，优于传统的WordNet等静态词汇数据库，为构建可解释、标准化、可扩展的对抗性基准提供了新的途径。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [65] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

TL;DR: HOID-R1 是首个结合思维链（CoT）引导的监督微调（SFT）和组相对策略优化（GRPO）的 HOI 检测框架，利用强化学习（RL）范式，并引入“MLLM-as-a-judge”机制来减轻幻觉，在 HOI 检测任务中取得了最先进的性能和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放词汇 HOI 检测中仅依赖大型语言模型进行文本提示，忽略了其固有的三维空间理解能力。本研究旨在解决这一局限性。

Method: HOID-R1 是一个整合了思维链（CoT）引导的监督微调（SFT）和基于强化学习（RL）范式的多智能体深度确定性策略梯度（MADDPG）的 HOI 检测框架。首先，SFT 用于为模型注入基本的推理能力，强制模型在输出中阐述其思考过程。然后，MADDPG 用于利用多奖励信号进行策略优化，从而增强跨模态的对齐。为了减轻 CoT 推理中的幻觉，引入了“MLLM-as-a-judge”机制来监督 CoT 输出，进一步提高了泛化能力。

Result: HOID-R1 在 HOI 检测基准上取得了最先进的性能，并在开放世界对新场景的泛化能力方面优于现有方法。

Conclusion: HOID-R1 在 HOI 检测基准上取得了最先进的性能，并在开放世界对新场景的泛化能力方面优于现有方法。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [66] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

TL;DR: 提出了一种新的知识蒸馏框架，通过结合实例级和关系级信息，提高了人脸识别模型的性能，并能使学生模型超越教师模型。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏对于在计算资源有限的环境（如边缘设备）中优化人脸识别模型至关重要。传统的知识蒸馏方法难以同时捕捉细粒度的实例级细节和复杂的关系结构，导致性能不佳。

Method: 提出了一种统一的方法，集成了两种新的损失函数：实例级嵌入蒸馏和基于关系对相似性蒸馏。实例级嵌入蒸馏利用动态困难挖掘策略对齐单个特征嵌入；基于关系对相似性蒸馏通过成对相似性关系捕获关系信息，并采用内存库机制和样本挖掘策略。

Result: 实验评估表明，该统一框架在多个基准人脸识别数据集上的表现优于最先进的蒸馏方法。特别地，当使用强教师网络时，该统一知识蒸馏方法使学生模型的准确性甚至超过了教师模型。

Conclusion: 该统一框架在多个基准人脸识别数据集上的表现优于最先进的蒸馏方法，学生模型的准确性甚至超过了教师模型。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [67] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: RMFAT是一种高效、实时的视频恢复方法，通过轻量级循环框架和多尺度特征处理来解决大气湍流问题，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer和3D架构的方法计算成本高、内存占用大，限制了在资源受限场景下的实时部署。

Method: 提出了一种名为RMFAT（循环多尺度特征大气湍流修复器）的轻量级循环框架，该框架每次仅使用两个输入帧进行恢复，并集成了多尺度特征编码和解码以及时间扭曲模块，以增强空间细节和时间连贯性。

Result: 实验结果表明，RMFAT在清晰度恢复和推理速度上均显著优于现有方法，非常适合实时大气湍流抑制。

Conclusion: RMFAT通过采用轻量级循环框架、多尺度特征编码解码以及集成的时间扭曲模块，在清晰度恢复（SSIM提高近9%）和推理速度（运行时间减少四倍以上）方面均优于现有方法，特别适合实时大气湍流抑制任务。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [68] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出了一种高效、实时的纯视觉室内导航深度学习方法，结合了图生成路径、可解释数据增强和课程学习，并发布了相关数据集、代码和 Android 应用。


<details>
  <summary>Details</summary>
Motivation: 现有的室内导航解决方案部署复杂且有额外要求，而该方法旨在提供一个高效、实时且易于部署的纯视觉解决方案。

Method: 提出了一种基于视觉输入的、可进行实时部署的深度学习方法，通过新颖的图生成路径方法、可解释的数据增强和课程学习来预测移动设备图像中的目标方向。

Result: 创建了一个大规模数据集，包含购物中心内的视频片段，并对每个帧进行了指向不同目标的目的地的正确方向标注。

Conclusion: 该方法仅依赖视觉信息，无需特殊传感器、路径标记、场景地图或网络连接。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [69] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

TL;DR: SelfAdapt adapts pre-trained cell segmentation models like Cellpose to new domains without needing labeled data, using a student-teacher approach with novel regularization and stopping criteria. It improves performance and can even enhance models already fine-tuned with supervision.


<details>
  <summary>Details</summary>
Motivation: While generalist models like Cellpose achieve state-of-the-art performance in biomedical instance segmentation, their effectiveness diminishes on domains different from their training data. Supervised fine-tuning can address this, but requires scarce annotated data. Therefore, there is a need for methods that can adapt these models without labels.

Method: SelfAdapt builds upon student-teacher augmentation consistency training, incorporating L2-SP regularization and label-free stopping criteria to achieve unsupervised domain adaptation for pre-trained cell segmentation models.

Result: On the LiveCell and TissueNet datasets, SelfAdapt showed relative improvements in AP0.5 of up to 29.64% over baseline Cellpose. The method also demonstrated the capability to further enhance models that had already undergone supervised fine-tuning.

Conclusion: SelfAdapt enables the adaptation of pre-trained cell segmentation models without the need for labels, demonstrating significant improvements over baseline Cellpose and even outperforming supervised fine-tuning in some cases. It can also further enhance already fine-tuned models, and is released as an accessible extension to the Cellpose framework.

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [70] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

TL;DR: 该研究提出了一种通过融合多种生物特征（面部、指纹、虹膜）的深度神经网络提取的特征来减少生物特征模板大小的方法。通过对特征向量进行降维，可以在同态加密域中实现更高效的处理，同时保持与单一生物识别相当或更优的准确性和安全性。实验证明，该方法可以将模板大小减小 67%，而不会影响等于错误率 (EER)。


<details>
  <summary>Details</summary>
Motivation: 生物特征识别的普及使得提取的模板的隐私和安全成为关键问题。然而，利用同态加密 (HE) 的生物特征模板保护方案由于工作量增加而带来重大的计算挑战。

Method: 使用深度神经网络 (DNN) 提取面部、指纹和虹膜特征，并在 FRGC、MCYT 和 CASIA 数据库上进行实验。评估的方法包括 (i) 可解释且易于在加密下实现，(ii) 无需训练，以及 (iii) 能够泛化。对特征向量进行降维。

Result: 通过融合特征向量，模板大小可减小 67%，且不影响等于错误率 (EER)，其性能与性能最佳的单一模态相当或更优。

Conclusion: 通过融合来自多种生物特征模态的特征向量，可以将模板大小减小 67%，而不会在等于错误率 (EER) 方面造成任何损失，与性能最佳的单一模态相比。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [71] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

TL;DR: 本研究使用TrOCR模型和创新的数据增强及集成学习技术，在处理16世纪拉丁手稿时，将历史手写文本识别的错误率降低了50%，是处理历史文献的重大进展。


<details>
  <summary>Details</summary>
Motivation: 历史手写文本识别（HTR）对于发掘档案文献的文化和学术价值至关重要，但其数字化进程受到转录稀少、语言变异和多样化手写风格的阻碍。

Method: 本研究将最先进的基于Transformer的HTR模型TrOCR应用于鲁道夫·瓜尔瑟16世纪拉丁手稿。研究重点在于图像预处理和数据增强技术，特别是引入了四种针对历史手写特征的新型增强方法，并评估了利用集成学习策略来结合不同增强模型优势的方法。

Result: 在瓜尔瑟数据集上，最佳的单一模型增强（Elastic）实现了1.86的字符错误率（CER），而顶级的五模型投票集成达到了1.60的CER，这相比报告的最佳TrOCR_BASE结果有50%的相对提升，并比之前的技术水平提高了42%。

Conclusion: 该研究通过应用TrOCR模型并结合定制化的数据增强技术和集成学习策略，显著提高了历史手写文本识别（HTR）在16世纪拉丁手稿上的性能，达到了1.60的字符错误率（CER），相比现有最佳结果有大幅提升。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


### [72] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: ImagiDrive框架通过结合VLM的预测能力和DWM的场景生成能力，并引入早期停止和轨迹选择机制，实现了更优的自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要丰富的上下文理解和精确的预测推理能力。虽然VLMs在多模态理解和行为预测方面表现出色，DWMs在生成详细的未来驾驶场景方面具有优势，但将两者结合起来以利用其互补优势是一个有前景但研究不足的领域。然而，这种集成在连接动作级决策和像素级预测以及保持计算效率方面存在挑战。

Method: 提出了一种名为ImagiDrive的新型端到端自动驾驶框架，该框架集成了视觉-语言模型（VLM）和驾驶世界模型（DWM）。具体来说，它包括一个由VLM驱动的驾驶代理，用于根据多模态输入预测初始驾驶轨迹；一个由DWM驱动的场景想象器，用于根据驾驶代理的预测生成未来场景；以及一个用于迭代优化驾驶代理规划决策的想象-规划循环。为了解决效率和预测准确性问题，该框架还引入了早期停止机制和轨迹选择策略。

Result: 在nuScenes和NAVSIM数据集上进行了广泛的实验验证，结果表明ImagiDrive在开放和闭环条件下均优于现有方法，证明了其鲁棒性和有效性。

Conclusion: ImagiDrive框架通过集成基于VLM的驾驶代理和基于DWM的场景想象器，形成了一个统一的想象-规划循环，并在nuScenes和NAVSIM数据集上进行了广泛的实验验证，证明了其在开放和闭环条件下的鲁棒性和优越性。

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [73] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

TL;DR: 本研究提出了一个用于评估3D高斯泼溅中物体移除后语义残留的新基准和数据集（Remove360），实验发现现有方法仍有局限性，需要更强的解决方案。


<details>
  <summary>Details</summary>
Motivation: 理解物体移除后语义信息的持久性对于保护隐私的3D重建和可编辑场景表示至关重要。

Method: 提出了一种新的基准和评估框架，用于衡量3D高斯泼溅中物体移除后的语义残留，并进行了室内外场景的实验。

Result: 实验表明，即使在没有视觉几何的情况下，当前方法也能保留语义信息，突显了现有3D物体移除技术的局限性。

Conclusion: 当前3D物体移除技术在处理真实世界复杂性方面存在关键限制，需要更鲁棒的解决方案来处理语义残留问题。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [74] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

TL;DR: MM-R1框架通过X-CoT和GRPO，使统一的MLLMs能够零样本地进行个性化图像生成，提高了主题保真度和文本对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在个性化图像生成方面存在局限性，因为它们通常是特定主题的，需要为每个新主题进行数据密集型微调，这限制了其可扩展性。本文旨在解决这一挑战。

Method: MM-R1框架集成了跨模态的思维链（X-CoT）推理策略，并将个性化过程构建为集成的视觉推理和生成过程：1.通过解释和理解用户提供的图像及上下文线索来识别主题概念；2.基于提取的主题表示和用户提示生成个性化图像。此外，采用分组奖励近端策略优化（GRPO）来对齐生成过程。

Result: 实验证明，MM-R1框架能够在零样本的情况下，生成具有高主题保真度和强文本对齐性的个性化图像，有效解决了现有方法的局限性。

Conclusion: MM-R1框架通过集成跨模态的思维链（X-CoT）推理策略，成功地释放了统一的多模态大语言模型（MLLMs）在个性化图像生成方面的潜力，实现了零样本的个性化图像生成，并达到了高主题保真度和强文本对齐性。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [75] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

TL;DR: A Swin Transformer V2-B based model with data augmentation and sample generation techniques achieved excellence in detecting Deepfakes.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges posed by deepfake technology to digital security by developing a method to detect whether a face image is a Deepfake image and output its probability score.

Method: The method is based on the Swin Transformer V2-B classification network, utilizing online data augmentation and offline sample generation to enhance training samples and model generalization.

Result: The approach achieved an award of excellence in the Deepfake image detection competition.

Conclusion: The approach achieved excellence in Deepfake image detection using Swin Transformer V2-B, online data augmentation, and offline sample generation, enriching training data diversity and improving model generalization.

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [76] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: CoFi是一个用于EM图像GBM分割的少样本分割流水线，它通过粗到细的方法减少了标注和计算负担，同时实现了高精度的分割。


<details>
  <summary>Details</summary>
Motivation: 监督深度学习方法在GBM分割中精度高，但需要大量的像素级标注，这在临床应用中不切实际。少样本学习可以减少标注负担，但往往难以捕捉GBM分析所需的精细结构细节。

Method: CoFi是一个快速高效的粗到细少样本分割流程，用于EM图像中的GBM描绘。它首先使用三个带注释的图像训练一个轻量级神经网络，以产生初始粗分割掩模。然后，该掩模经过自动处理，生成具有形态感知修剪的高质量点提示，这些提示随后用于指导SAM进行分割优化。

Result: CoFi实现了出色的GBM分割性能，Dice系数为74.54%，推理速度为1.9 FPS。

Conclusion: CoFi通过减轻注释和计算负担，在EM图像中实现了准确可靠的GBM分割，在研究和临床应用中都显示出巨大潜力。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [77] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

TL;DR: TACR-YOLO是一个用于异常行为检测的新框架，通过引入注意力模块和优化技术，提高了对小目标、分类回归冲突和多尺度融合的处理能力，并在PABD数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决YOLO类检测方法在特殊场景下的异常人类行为检测（AHBD）任务中面临的小目标、任务冲突和多尺度融合等挑战。

Method: 提出了一种名为TACR-YOLO的新型实时框架，其中包含坐标注意力模块（用于增强小目标检测）、任务感知注意力模块（用于处理分类-回归冲突）和加强颈部网络（用于精细化多尺度融合）。此外，还使用K-means聚类优化了Anchor Box尺寸，并部署了DIoU-Loss来改进边界框回归。此外，还提出了包含8,529个样本（涵盖四种行为类别）的人员异常行为检测（PABD）数据集。

Result: TACR-YOLO在PABD数据集上实现了91.92%的mAP，并展现出良好的速度和鲁棒性。消融研究验证了每个改进模块的有效性。

Conclusion: TACR-YOLO在PABD数据集上实现了91.92%的mAP，并且具有竞争力 的速度和鲁棒性，为特殊场景下的异常行为检测提供了新的见解。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [78] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

TL;DR: 本研究对建筑行业51个公开视觉数据集进行了系统性审查和分类，构建了OpenConstruction目录，并提出了遵循FAIR原则的数据基础设施的未来发展路线图，旨在促进建筑领域AI应用的发展。


<details>
  <summary>Details</summary>
Motivation: 现有建筑领域视觉数据集在规模、模态、标注质量和代表性方面存在显著差异，缺乏对其数据特性和应用背景的系统性审查，这阻碍了社区充分理解数据集现状、识别关键差距并指导未来AI应用的发展。

Method: 通过广泛搜索学术数据库和开放数据平台，对2005-2024年间的51个公开视觉数据集进行了系统性审查和分类。分类维度包括数据基本信息（大小、许可）、数据模态（RGB、点云）、标注框架（边界框）以及下游应用领域（进度跟踪）。

Result: 构建了一个名为OpenConstruction的开源目录，对51个数据集进行了分类和汇总，为数据驱动的方法开发提供了支持。研究还讨论了现有建筑数据集的关键局限性，并提出了一个基于FAIR原则的数据基础设施的未来路线图。

Conclusion: 本研究通过对51个公开数据集的广泛搜索和分类，总结了现有建筑领域视觉数据集的特点和应用背景，发现了当前数据集的局限性，并提出了遵循FAIR原则的数据基础设施的未来路线图，以支持建筑行业数据驱动的解决方案的进步。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


### [79] [Is ChatGPT-5 Ready for Mammogram VQA?](https://arxiv.org/abs/2508.11628)
*Qiang Li,Shansong Wang,Mingzhe Hu,Mojtaba Safari,Zachary Eidex,Xiaofeng Yang*

Main category: cs.CV

TL;DR: GPT-5在乳腺X线照片VQA任务中表现出潜力，但临床应用尚需优化，其性能不如人类专家。


<details>
  <summary>Details</summary>
Motivation: 旨在评估GPT-5系列和GPT-4o在乳腺X线照片VQA任务中的能力，以支持乳腺癌筛查。

Method: 系统性评估了GPT-5系列和GPT-4o模型在EMBED、InBreast、CMMD、CBIS-DDSM四个公共乳腺X线照片数据集上的表现，任务包括BI-RADS评估、异常检测和恶性肿瘤分类。

Result: GPT-5在所有评估数据集中均表现最佳，但在密度、扭曲、肿块、钙化和恶性肿瘤分类方面，以及BI-RADS准确性、异常检测和恶性肿瘤分类方面，均落后于人类专家和领域特定模型。GPT-5的敏感性（63.5%）和特异性（52.3%）低于人类专家。

Conclusion: GPT-5在乳腺X线照片VQA任务中展现出潜力，但在临床应用前需要针对性优化，其性能仍落后于人类专家和领域特定模型。

Abstract: Mammogram visual question answering (VQA) integrates image interpretation
with clinical reasoning and has potential to support breast cancer screening.
We systematically evaluated the GPT-5 family and GPT-4o model on four public
mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,
abnormality detection, and malignancy classification tasks. GPT-5 consistently
was the best performing model but lagged behind both human experts and
domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores
among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),
calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it
attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%
malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection
and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS
accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared
with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and
specificity (52.3%). While GPT-5 exhibits promising capabilities for screening
tasks, its performance remains insufficient for high-stakes clinical imaging
applications without targeted domain adaptation and optimization. However, the
tremendous improvements in performance from GPT-4o to GPT-5 show a promising
trend in the potential for general large language models (LLMs) to assist with
mammography VQA tasks.

</details>


### [80] [CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models](https://arxiv.org/abs/2508.11484)
*Xiaoxue Wu,Bingjie Gao,Yu Qiao,Yaohui Wang,Xinyuan Chen*

Main category: cs.CV

TL;DR: CineTrans是一个新的框架，可以生成具有电影般转场的多镜头视频。它使用掩码控制在任意点进行转场，并在Cine250K数据集上进行了训练，该数据集具有镜头标注。CineTrans在转场控制、时间连贯性和整体质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频合成技术在多镜头视频生成方面仍处于初级阶段，即使使用扩展的模型和海量数据集，镜头转换能力也显得粗糙且不稳定，导致生成的视频大多局限于单镜头序列。本研究旨在解决这一问题，探索生成具有电影化、风格化镜头转换的多镜头视频。

Method: 提出了一种名为CineTrans的新框架，用于生成具有电影风格转换的多镜头视频。该框架利用了视频扩散模型中注意力图与镜头边界之间的对应关系，设计了一种基于掩码的控制机制。该机制允许在任意位置进行镜头转换，并且在无需训练的情况下具有良好的迁移性。此外，研究人员构建了一个包含详细镜头标注的多镜头视频-文本数据集Cine250K，用于模型训练和分析。

Result: CineTrans在Cine250K数据集上进行微调后，能够生成符合电影剪辑风格的、连贯的多镜头序列，避免了不稳定的转换或简单的拼接。研究人员还提出了专门用于评估转换控制、时间一致性和整体质量的评价指标，并通过大量实验证明CineTrans在所有标准上均显著优于现有基线。

Conclusion: CineTrans框架能够生成符合电影剪辑风格的、连贯的多镜头视频，克服了现有视频生成模型在镜头转换方面存在的鲁棒性不足和不稳定性问题。通过在Cine250K数据集上进行微调并结合掩码控制机制，CineTrans能够在任意位置实现镜头转换，并且在无需额外训练的情况下表现出良好的迁移能力。实验结果表明，CineTrans在转换控制、时间一致性和整体质量方面均显著优于现有基线方法。

Abstract: Despite significant advances in video synthesis, research into multi-shot
video generation remains in its infancy. Even with scaled-up models and massive
datasets, the shot transition capabilities remain rudimentary and unstable,
largely confining generated videos to single-shot sequences. In this work, we
introduce CineTrans, a novel framework for generating coherent multi-shot
videos with cinematic, film-style transitions. To facilitate insights into the
film editing style, we construct a multi-shot video-text dataset Cine250K with
detailed shot annotations. Furthermore, our analysis of existing video
diffusion models uncovers a correspondence between attention maps in the
diffusion model and shot boundaries, which we leverage to design a mask-based
control mechanism that enables transitions at arbitrary positions and transfers
effectively in a training-free setting. After fine-tuning on our dataset with
the mask mechanism, CineTrans produces cinematic multi-shot sequences while
adhering to the film editing style, avoiding unstable transitions or naive
concatenations. Finally, we propose specialized evaluation metrics for
transition control, temporal consistency and overall quality, and demonstrate
through extensive experiments that CineTrans significantly outperforms existing
baselines across all criteria.

</details>


### [81] [Automated Building Heritage Assessment Using Street-Level Imagery](https://arxiv.org/abs/2508.11486)
*Kristina Dabrock,Tim Johansson,Anna Donarelli,Mikael Mangold,Noah Pflugradt,Jann Michael Weinand,Jochen Linßen*

Main category: cs.CV

TL;DR: 通过使用GPT和机器学习识别建筑文化遗产价值，以支持节能改造。


<details>
  <summary>Details</summary>
Motivation: 为了在不损害文化遗产的情况下量化建筑（如围护结构改造）的节能措施，需要详细的数据。新型人工智能工具可能比成本高昂且耗时的人工清单更有效地识别建筑中的遗产价值。

Method: 本研究使用大型语言模型GPT来检测门面图像中的各种文化遗产价值方面，并结合建筑登记数据作为特征，训练机器学习模型来对瑞典斯德哥尔摩的多户住宅和非住宅建筑进行分类。

Result: 使用GPT检索的特征和登记数据相结合的机器学习模型，在与专家创建的清单进行验证时，宏观F1分数为0.71；仅使用GPT检索的数据，得分为0.60。所提出的方法可以提高数据库的质量。

Conclusion: 利用GPT和机器学习技术，可以更高效地识别建筑的文化遗产价值，并将其应用于大规模的建筑节能改造中，以支持谨慎的节能措施和遗产价值的整合考虑。

Abstract: Detailed data is required to quantify energy conservation measures in
buildings, such as envelop retrofits, without compromising cultural heritage.
Novel artificial intelligence tools may improve efficiency in identifying
heritage values in buildings compared to costly and time-consuming traditional
inventories. In this study, the large language model GPT was used to detect
various aspects of cultural heritage value in fa\c{c}ade images. Using this
data and building register data as features, machine learning models were
trained to classify multi-family and non-residential buildings in Stockholm,
Sweden. Validation against an expert-created inventory shows a macro F1-score
of 0.71 using a combination of register data and features retrieved from GPT,
and a score of 0.60 using only GPT-derived data. The presented methodology can
contribute to a higher-quality database and thus support careful energy
efficiency measures and integrated consideration of heritage value in
large-scale energetic refurbishment scenarios.

</details>


### [82] [Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.11488)
*Bozhou Zhang,Jingyu Li,Nan Song,Li Zhang*

Main category: cs.CV

TL;DR: VeteranAD是一个端到端自动驾驶框架，通过将感知集成到规划过程中，并使用多模态锚定轨迹作为规划先验，实现了更精确、更可靠的驾驶。在NAVSIM和Bench2Drive数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升端到端自动驾驶的规划性能，将感知集成到规划过程中，实现由不断变化的规划目标驱动的针对性感知。

Method: 提出了一种名为VeteranAD的感知与规划耦合框架，该框架通过将多模态锚定轨迹作为规划先验，使感知模块能够收集这些轨迹上的交通元素，从而实现有针对性的感知。然后，基于感知结果和规划先验生成规划轨迹。采用自回归策略逐步预测未来轨迹，并专注于相关区域进行目标感知。

Result: VeteranAD实现了更准确、更可靠的驾驶行为。

Conclusion: VeteranAD在NAVSIM和Bench2Drive数据集上取得了最先进的性能。

Abstract: End-to-end autonomous driving has achieved remarkable advancements in recent
years. Existing methods primarily follow a perception-planning paradigm, where
perception and planning are executed sequentially within a fully differentiable
framework for planning-oriented optimization. We further advance this paradigm
through a perception-in-plan framework design, which integrates perception into
the planning process. This design facilitates targeted perception guided by
evolving planning objectives over time, ultimately enhancing planning
performance. Building on this insight, we introduce VeteranAD, a coupled
perception and planning framework for end-to-end autonomous driving. By
incorporating multi-mode anchored trajectories as planning priors, the
perception module is specifically designed to gather traffic elements along
these trajectories, enabling comprehensive and targeted perception. Planning
trajectories are then generated based on both the perception results and the
planning priors. To make perception fully serve planning, we adopt an
autoregressive strategy that progressively predicts future trajectories while
focusing on relevant regions for targeted perception at each step. With this
simple yet effective design, VeteranAD fully unleashes the potential of
planning-oriented end-to-end methods, leading to more accurate and reliable
driving behavior. Extensive experiments on the NAVSIM and Bench2Drive datasets
demonstrate that our VeteranAD achieves state-of-the-art performance.

</details>


### [83] [Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition](https://arxiv.org/abs/2508.11497)
*Feiyue Zhao,Zhichao Zhang*

Main category: cs.CV

TL;DR: HGFE框架通过集成图卷积和自适应频率调制，增强了CNN处理图像结构和语义信息的能力，并在多项视觉任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络（CNN）在视觉识别任务中表现出强大的性能，但其固有的对规则网格结构的依赖限制了它们在图像内建模复杂拓扑关系和非局部语义的能力。

Method: 提出了一种名为分层图特征增强（HGFE）的新颖框架，该框架将基于图的推理集成到CNN中，以增强结构感知和特征表示。HGFE构建了两个互补的图结构层：窗口内图卷积用于捕获局部空间依赖性，窗口间超级节点交互用于模拟全局语义关系。此外，还引入了一个自适应频率调制模块，动态平衡低频和高频信号传播，以保留关键的边缘和纹理信息，同时减轻过平滑问题。

Result: HGFE在CIFAR-100、PASCAL VOC、VisDrone、CrackSeg和CarParts等数据集上的实验结果表明，该方法能够有效提升模型的结构表示能力和整体识别性能。

Conclusion: HGFE模块轻量级、可端到端训练，并可无缝集成到标准的CNN骨干网络中。在CIFAR-100（分类）、PASCAL VOC和VisDrone（检测）以及CrackSeg和CarParts（分割）上的大量实验验证了HGFE在改进结构表示和增强整体识别性能方面的有效性。

Abstract: Convolutional neural networks (CNNs) have
  demonstrated strong performance in visual recognition tasks,
  but their inherent reliance on regular grid structures limits
  their capacity to model complex topological relationships and
  non-local semantics within images. To address this limita tion, we propose
the hierarchical graph feature enhancement
  (HGFE), a novel framework that integrates graph-based rea soning into CNNs to
enhance both structural awareness and
  feature representation. HGFE builds two complementary levels
  of graph structures: intra-window graph convolution to cap ture local spatial
dependencies and inter-window supernode
  interactions to model global semantic relationships. Moreover,
  we introduce an adaptive frequency modulation module that
  dynamically balances low-frequency and high-frequency signal
  propagation, preserving critical edge and texture information
  while mitigating over-smoothing. The proposed HGFE module
  is lightweight, end-to-end trainable, and can be seamlessly
  integrated into standard CNN backbone networks. Extensive
  experiments on CIFAR-100 (classification), PASCAL VOC,
  and VisDrone (detection), as well as CrackSeg and CarParts
  (segmentation), validated the effectiveness of the HGFE in
  improving structural representation and enhancing overall
  recognition performance.

</details>


### [84] [An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture](https://arxiv.org/abs/2508.11532)
*Jingsong Xia,Yue Yin,Xiuhan Li*

Main category: cs.CV

TL;DR: 该研究提出了一种改进的ConvNeXt-Tiny模型，通过结合双全局池化、SEVector注意力模块和特征平滑损失，在资源受限环境下实现了高效准确的医学图像分类。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的计算环境中实现高效、高精度的医学图像分类仍然是一个挑战。

Method: 提出了一种基于改进ConvNeXt-Tiny架构的医学图像分类方法，通过结构优化和损失函数设计来增强特征提取能力和分类性能，并降低计算复杂度。具体包括：引入双全局池化（全局平均池化和全局最大池化）特征融合策略；设计轻量级通道注意力模块SEVector以提高通道权重分配适应性并最小化参数开销；采用特征平滑损失函数以增强类内特征一致性并抑制类内方差。

Result: 在仅CPU（8线程）条件下，该方法在10个训练周期内实现了89.10%的最大测试集分类准确率，并且损失值呈现出稳定的收敛趋势。

Conclusion: 该方法在资源受限的环境下有效提升了医学图像分类性能，为医学影像分析模型提供了一个可行的、高效的解决方案。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis. However, achieving efficient and high-accuracy image
classification in resource-constrained computational environments remains
challenging. This study proposes a medical image classification method based on
an improved ConvNeXt-Tiny architecture. Through structural optimization and
loss function design, the proposed method enhances feature extraction
capability and classification performance while reducing computational
complexity. Specifically, the method introduces a dual global pooling (Global
Average Pooling and Global Max Pooling) feature fusion strategy into the
ConvNeXt-Tiny backbone to simultaneously preserve global statistical features
and salient response information. A lightweight channel attention module,
termed Squeeze-and-Excitation Vector (SEVector), is designed to improve the
adaptive allocation of channel weights while minimizing parameter overhead.
Additionally, a Feature Smoothing Loss is incorporated into the loss function
to enhance intra-class feature consistency and suppress intra-class variance.
Under CPU-only conditions (8 threads), the method achieves a maximum
classification accuracy of 89.10% on the test set within 10 training epochs,
exhibiting a stable convergence trend in loss values. Experimental results
demonstrate that the proposed method effectively improves medical image
classification performance in resource-limited settings, providing a feasible
and efficient solution for the deployment and promotion of medical imaging
analysis models.

</details>


### [85] [AIM: Amending Inherent Interpretability via Self-Supervised Masking](https://arxiv.org/abs/2508.11502)
*Eyad Alshami,Shashank Agnihotri,Bernt Schiele,Margret Keuper*

Main category: cs.CV

TL;DR: AIM 是一种无监督方法，通过特征掩蔽来提升深度神经网络的可解释性和准确性，促使模型关注真实特征。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）在进行决策时，常常会同时使用真实特征和虚假特征。本研究旨在提出一种能够促使网络优先使用真实特征、抑制虚假特征的方法，以提升模型的内在可解释性。

Method: AIM（Amending Inherent Interpretability via Self-Supervised Masking）方法利用多编码阶段的特征，通过无监督的、样本特定的特征掩蔽过程，引导网络优先使用真实特征。

Result: AIM 在 ImageNet100、HardImageNet、ImageWoof、Waterbirds、TravelingBirds 和 CUB-200 等多样化的挑战性数据集上进行了验证。实验结果表明，AIM 在可解释性（通过能量指向游戏 EPG 分数衡量）和准确性方面均优于强基线模型，在不同领域和架构上均实现了稳健的提升。

Conclusion: AIM 能够有效促进模型使用真实特征而非虚假特征，从而在不依赖额外标注的情况下，提升模型的性能和可解释性。该方法在多种基准数据集和多种网络架构上均表现出显著的优势，证实了其在提高泛化能力和人类可对齐的可解释性方面的有效性。

Abstract: It has been observed that deep neural networks (DNNs) often use both genuine
as well as spurious features. In this work, we propose "Amending Inherent
Interpretability via Self-Supervised Masking" (AIM), a simple yet interestingly
effective method that promotes the network's utilization of genuine features
over spurious alternatives without requiring additional annotations. In
particular, AIM uses features at multiple encoding stages to guide a
self-supervised, sample-specific feature-masking process. As a result, AIM
enables the training of well-performing and inherently interpretable models
that faithfully summarize the decision process. We validate AIM across a
diverse range of challenging datasets that test both out-of-distribution
generalization and fine-grained visual understanding. These include
general-purpose classification benchmarks such as ImageNet100, HardImageNet,
and ImageWoof, as well as fine-grained classification datasets such as
Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual
benefits: interpretability improvements, as measured by the Energy Pointing
Game (EPG) score, and accuracy gains over strong baselines. These consistent
gains across domains and architectures provide compelling evidence that AIM
promotes the use of genuine and meaningful features that directly contribute to
improved generalization and human-aligned interpretability.

</details>


### [86] [A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11](https://arxiv.org/abs/2508.11517)
*Shaoze Huang,Qi Liu,Chao Chen,Yuhang Chen*

Main category: cs.CV

TL;DR: 针对长江三角洲地区交通基础设施老化及裂缝检测难题，提出 YOLOv11-KW-TA-FP 模型，结合 KWConv、TA 和 FP-IoU 损失，显著提升了裂缝检测精度和效率，具有重要的工程应用价值。


<details>
  <summary>Details</summary>
Motivation: 为了克服手动检测效率低下以及现有深度学习模型在复杂背景下小目标裂缝检测性能不佳的局限性，同时应对长江三角洲地区快速发展背景下交通基础设施加速老化的问题。

Method: 提出了一种基于 YOLOv11n 架构的多任务混凝土裂缝检测和分割模型 YOLOv11-KW-TA-FP，该模型包含三个主要部分：1.在骨干网络中嵌入动态核仓库卷积（KWConv）以增强特征表示；2.在特征金字塔中引入三注意力机制（TA）以加强通道-空间交互建模；3.设计 FP-IoU 损失函数以促进自适应边界框回归惩罚。

Result: 实验验证表明，所提出的增强模型在精度、召回率和 mAP@50 方面取得了显著的性能提升，分别达到了 91.3%、76.6% 和 86.4%，优于基线模型。消融实验证实了所提出模块的协同功效，鲁棒性测试表明模型在数据稀疏和噪声干扰下仍能保持稳定性能。

Conclusion: 该研究提出了一种名为 YOLOv11-KW-TA-FP 的多任务混凝土裂缝检测和分割模型，基于 YOLOv11n 架构，通过集成动态核仓库卷积（KWConv）、三注意力机制（TA）和 FP-IoU 损失函数，在裂缝检测任务上取得了显著的性能提升，为自动化基础设施检测提供了有效的计算机视觉解决方案，具有重要的实际工程价值。

Abstract: Accelerated aging of transportation infrastructure in the rapidly developing
Yangtze River Delta region necessitates efficient concrete crack detection, as
crack deterioration critically compromises structural integrity and regional
economic growth. To overcome the limitations of inefficient manual inspection
and the suboptimal performance of existing deep learning models, particularly
for small-target crack detection within complex backgrounds, this paper
proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and
segmentation model based on the YOLOv11n architecture. The proposed model
integrates a three-stage optimization framework: (1) Embedding dynamic
KernelWarehouse convolution (KWConv) within the backbone network to enhance
feature representation through a dynamic kernel sharing mechanism; (2)
Incorporating a triple attention mechanism (TA) into the feature pyramid to
strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU
loss function to facilitate adaptive bounding box regression penalization.
Experimental validation demonstrates that the enhanced model achieves
significant performance improvements over the baseline, attaining 91.3%
precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the
synergistic efficacy of the proposed modules. Furthermore, robustness tests
indicate stable performance under conditions of data scarcity and noise
interference. This research delivers an efficient computer vision solution for
automated infrastructure inspection, exhibiting substantial practical
engineering value.

</details>


### [87] [Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction](https://arxiv.org/abs/2508.11531)
*Shilei Wang,Gong Cheng,Pujian Lai,Dong Gao,Junwei Han*

Main category: cs.CV

TL;DR: MST通过轻量级的多状态特征增强和交互，提升了高效跟踪器的性能，在准确性、鲁棒性和速度上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有高效跟踪器在追求速度的同时牺牲特征表示能力，导致难以准确捕捉目标状态的问题，MST被提出来提高跟踪的鲁棒性。

Method: MST（Multi-State Tracker）通过多阶段生成（MSG）产生多状态特征，然后利用状态增强（SSE）和跨状态交互（CSI）进行优化和聚合。SSE和CSI模块采用了轻量级的基于隐藏状态自适应的状态空间对偶（HSA-SSD）设计，计算量仅为0.1 GFLOPs，参数量为0.66M。

Result: MST在多个数据集上超越了所有先前的高效跟踪器，特别是在GOT-10K数据集上，AO得分比HCAT提高了4.5%，展示了其在准确性和鲁棒性方面的优越性，并保持了出色的运行时性能。

Conclusion: MST通过利用轻量级的状态增强和跨状态交互，在保持高效的同时，显著提高了跟踪的准确性和鲁棒性。实验结果表明，MST在多个数据集上超越了所有先前的高效跟踪器，并在GOT-10K数据集上比之前的SOTA高效跟踪器HCAT取得了4.5%的AO得分提升。

Abstract: Efficient trackers achieve faster runtime by reducing computational
complexity and model parameters. However, this efficiency often compromises the
expense of weakened feature representation capacity, thus limiting their
ability to accurately capture target states using single-layer features. To
overcome this limitation, we propose Multi-State Tracker (MST), which utilizes
highly lightweight state-specific enhancement (SSE) to perform specialized
enhancement on multi-state features produced by multi-state generation (MSG)
and aggregates them in an interactive and adaptive manner using cross-state
interaction (CSI). This design greatly enhances feature representation while
incurring minimal computational overhead, leading to improved tracking
robustness in complex environments. Specifically, the MSG generates multiple
state representations at multiple stages during feature extraction, while SSE
refines them to highlight target-specific features. The CSI module facilitates
information exchange between these states and ensures the integration of
complementary features. Notably, the introduced SSE and CSI modules adopt a
highly lightweight hidden state adaptation-based state space duality (HSA-SSD)
design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.
Experimental results demonstrate that MST outperforms all previous efficient
trackers across multiple datasets, significantly improving tracking accuracy
and robustness. In particular, it shows excellent runtime performance, with an
AO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT on
the GOT-10K dataset. The code is available at https://github.com/wsumel/MST.

</details>


### [88] [Reinforcing Video Reasoning Segmentation to Think Before It Segments](https://arxiv.org/abs/2508.11538)
*Sitong Gong,Lu Zhang,Yunzhi Zhuge,Xu Jia,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: Veason-R1通过强化学习（GRPO）和链式思考（CoT）初始化改进了视频推理分割（VRS），提高了性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 先前的视频推理分割（VRS）方法利用大型视觉语言模型（LVLM）将对象语义编码为掩模预测的<SEG>标记。然而，这种范例在推理过程中可解释性有限，并且由于时空推理不足，性能不佳。

Method: 提出了一种名为Veason-R1的视频推理分割（VRS）专用LVLM，该模型通过强化学习进行训练。首先，通过引导的链式思考（CoT）初始化来监督微调模型（Veason-SFT），以解决跨视频级语义和帧级空间基础的结构化推理问题。然后，通过结合链式思考（CoT）初始化和整体奖励机制来优化推理链，以提高空间对齐和时间一致性。

Result: Veason-R1在多个基准测试中取得了最先进的性能，在ReVOS和ReasonVOS上的性能分别提高了+1.3 J&F和+10.0 J&F，并且在处理幻觉方面表现出鲁棒性（+8.8 R）。

Conclusion: Veason-R1在多个基准测试中取得了最先进的性能，在ReVOS和ReasonVOS上的性能分别提高了+1.3 J&F和+10.0 J&F，并且在处理幻觉方面表现出鲁棒性（+8.8 R）。

Abstract: Video reasoning segmentation (VRS) endeavors to delineate referred objects in
videos guided by implicit instructions that encapsulate human intent and
temporal logic. Previous approaches leverage large vision language models
(LVLMs) to encode object semantics into <SEG> tokens for mask prediction.
However, this paradigm suffers from limited interpretability during inference
and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing
inspiration from seminal breakthroughs in reinforcement learning, we introduce
Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in
segmentation. Veason-R1 is trained through Group Relative Policy Optimization
(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we
curate high-quality CoT training data to instill structured reasoning
trajectories, bridging video-level semantics and frame-level spatial grounding,
yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO
fine-tuning encourages efficient exploration of the reasoning space by
optimizing reasoning chains. To this end, we incorporate a holistic reward
mechanism that synergistically enhances spatial alignment and temporal
consistency, bolstering keyframe localization and fine-grained grounding.
Comprehensive empirical evaluations demonstrate that Veason-R1 achieves
state-of-the-art performance on multiple benchmarks, surpassing prior art by
significant margins (e.g., +1.3 J &F in ReVOS and +10.0 J &F in ReasonVOS),
while exhibiting robustness to hallucinations (+8.8 R). Our code and model
weights will be available at Veason-R1.

</details>


### [89] [Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model](https://arxiv.org/abs/2508.11550)
*Zuo Zuo,Jiahao Dong,Yanyun Qu,Zongze Wu*

Main category: cs.CV

TL;DR: AAG is a training-free framework using Stable Diffusion to generate realistic anomalies for industrial anomaly detection, improving performance on downstream tasks.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of data scarcity in industrial anomaly detection by proposing a novel, training-free anomaly generation framework.

Method: AAG is a training-free framework based on Stable Diffusion, utilizing Cross-Attention Enhancement (CAE) to guide anomaly generation based on masks and text prompts, and Self-Attention Enhancement (SAE) to ensure coherence with original patterns.

Result: AAG generates realistic and plausible anomalies, enhancing downstream anomaly inspection tasks. Experiments on MVTec AD and VisA datasets demonstrate its effectiveness.

Conclusion: AAG can effectively generate realistic anomalies while preserving normal regions, and can improve downstream anomaly detection tasks.

Abstract: Industrial anomaly detection (AD) plays a significant role in manufacturing
where a long-standing challenge is data scarcity. A growing body of works have
emerged to address insufficient anomaly data via anomaly generation. However,
these anomaly generation methods suffer from lack of fidelity or need to be
trained with extra data. To this end, we propose a training-free anomaly
generation framework dubbed AAG, which is based on Stable Diffusion (SD)'s
strong generation ability for effective anomaly image generation. Given a
normal image, mask and a simple text prompt, AAG can generate realistic and
natural anomalies in the specific regions and simultaneously keep contents in
other regions unchanged. In particular, we propose Cross-Attention Enhancement
(CAE) to re-engineer the cross-attention mechanism within Stable Diffusion
based on the given mask. CAE increases the similarity between visual tokens in
specific regions and text embeddings, which guides these generated visual
tokens in accordance with the text description. Besides, generated anomalies
need to be more natural and plausible with object in given image. We propose
Self-Attention Enhancement (SAE) which improves similarity between each normal
visual token and anomaly visual tokens. SAE ensures that generated anomalies
are coherent with original pattern. Extensive experiments on MVTec AD and VisA
datasets demonstrate effectiveness of AAG in anomaly generation and its
utility. Furthermore, anomaly images generated by AAG can bolster performance
of various downstream anomaly inspection tasks.

</details>


### [90] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

TL;DR: TrajSV是一个基于轨迹的体育分析框架，解决了数据可用性、缺乏有效框架和监督标签不足的问题。它通过CRNet和VRN学习视频和剪辑表示，并使用无监督的三重对比损失进行优化。在三个数据集和三个下游应用中，TrajSV均取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的体育分析研究面临数据不可用、缺乏有效的基于轨迹的框架以及需要充足监督标签等问题。

Method: TrajSV框架包括数据预处理、剪辑表示网络（CRNet）和视频表示网络（VRNet）。CRNet使用基于轨迹的Transformer来学习剪辑表示，VRNet通过聚合剪辑表示和视觉特征来学习视频表示。最后，使用三重对比损失进行无监督优化。

Result: 在足球、篮球和排球三个数据集上进行了实验，TrajSV在体育视频检索、动作识别和视频字幕生成三个下游应用中均表现出色，取得了最先进的成果。

Conclusion: TrajSV在体育视频检索、动作识别和视频字幕生成方面均取得了最先进的性能，其中体育视频检索的性能提升了近70%，动作识别在17个动作类别中有9个达到了最先进的水平，视频字幕生成也提升了近20%。此外，还部署了一个基于TrajSV的系统。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [91] [Causality Matters: How Temporal Information Emerges in Video Language Models](https://arxiv.org/abs/2508.11576)
*Yumeng Shi,Quanyu Long,Yin Wu,Wenya Wang*

Main category: cs.CV

TL;DR: "本文发现，视频语言模型中的时间理解主要依赖于跨帧注意力而非位置编码。通过优化注意力机制和引入时间退出机制，可以提高模型效率。"


<details>
  <summary>Details</summary>
Motivation: "视频语言模型（VideoLM）在多模态理解方面取得了显著进展，但时间理解（如事件顺序、持续时间和时间关系）仍然是一个核心挑战。先前的工作普遍认为位置编码（PEs）是编码时间结构的关键，但本研究旨在深入探究VideoLM中时间信息的实际处理方式，并寻找更优化的方法。"

Method: "本文通过一系列分析实验来探究视频语言模型（VideoLM）中的时间信息整合机制。研究发现，位置编码（PEs）对时间理解的影响很小，而反转帧序列则会导致性能显著下降。通过追踪信息流，揭示了时间线索通过跨帧注意力逐步合成，并在最后一帧聚合，最终整合到查询令牌中的因果信息通路。基于这些发现，提出了分阶段跨模态注意力和时间退出机制这两种提高效率的策略。"

Result: "实验结果表明，移除或修改PEs对视频模型的时间理解能力影响甚微，而反转帧序列则会严重损害模型性能。这揭示了时间信息并非主要依赖PEs，而是通过跨帧注意力机制、在最后一帧聚合，并整合到查询令牌中的过程自然涌现。提出的分阶段跨模态注意力和时间退出机制在两个基准测试中均验证了其有效性，证明了这些策略可以提高模型的效率。"

Conclusion: "未来的视频语言模型可以通过利用这种新发现的跨帧注意力机制来改进，并结合所提出的效率策略，例如分阶段的跨模态注意力和时间退出机制，以实现更有效的时间推理。"

Abstract: Video language models (VideoLMs) have made significant progress in multimodal
understanding. However, temporal understanding, which involves identifying
event order, duration, and relationships across time, still remains a core
challenge. Prior works emphasize positional encodings (PEs) as a key mechanism
for encoding temporal structure. Surprisingly, we find that removing or
modifying PEs in video inputs yields minimal degradation in the performance of
temporal understanding. In contrast, reversing the frame sequence while
preserving the original PEs causes a substantial drop. To explain this
behavior, we conduct substantial analysis experiments to trace how temporal
information is integrated within the model. We uncover a causal information
pathway: temporal cues are progressively synthesized through inter-frame
attention, aggregated in the final frame, and subsequently integrated into the
query tokens. This emergent mechanism shows that temporal reasoning emerges
from inter-visual token interactions under the constraints of causal attention,
which implicitly encodes temporal structure. Based on these insights, we
propose two efficiency-oriented strategies: staged cross-modal attention and a
temporal exit mechanism for early token truncation. Experiments on two
benchmarks validate the effectiveness of both approaches. To the best of our
knowledge, this is the first work to systematically investigate video temporal
understanding in VideoLMs, offering insights for future model improvement.

</details>


### [92] [CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion](https://arxiv.org/abs/2508.11603)
*Zhe Zhu,Honghua Chen,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: CoreEditor通过约束注意机制解决了现有3D编辑方法中的视图间不一致性问题，实现了更精确、更一致的文本到3D编辑。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的3D编辑方法通常将预训练的2D图像编辑器应用于多视图输入，但缺乏跨视图信息交换的显式控制，导致视图间不一致、编辑效果不理想和细节模糊。

Method: 引入了一个新颖的框架CoreEditor，其核心是一个约束注意机制，用于在扩散去噪过程中保持跨视图像素的一致性。该方法还结合了去噪过程中估计的语义相似性，并设计了一个选择性编辑流程，允许用户选择最佳编辑结果。

Result: CoreEditor能够生成高质量、3D一致性强且细节更锐利的编辑结果，在各种实验中表现优于先前的方法。

Conclusion: CoreEditor在3D一致性、细节锐化和用户控制方面显著优于现有方法。

Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual
descriptions, and most existing approaches tackle this by adapting pre-trained
2D image editors to multi-view inputs. However, without explicit control over
multi-view information exchange, they often fail to maintain cross-view
consistency, leading to insufficient edits and blurry details. We introduce
CoreEditor, a novel framework for consistent text-to-3D editing. The key
innovation is a correspondence-constrained attention mechanism that enforces
precise interactions between pixels expected to remain consistent throughout
the diffusion denoising process. Beyond relying solely on geometric alignment,
we further incorporate semantic similarity estimated during denoising, enabling
more reliable correspondence modeling and robust multi-view editing. In
addition, we design a selective editing pipeline that allows users to choose
preferred results from multiple candidates, offering greater flexibility and
user control. Extensive experiments show that CoreEditor produces high-quality,
3D-consistent edits with sharper details, significantly outperforming prior
methods.

</details>


### [93] [LoRAtorio: An intrinsic approach to LoRA Skill Composition](https://arxiv.org/abs/2508.11624)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

TL;DR: LoRAtorio 是一个新颖的、无需训练的框架，用于有效组合多个 LoRA 适配器，解决了现有方法在开放式场景下的组合难题。它通过分析潜在空间中的噪声相似度来指导加权聚合，并结合无分类器指导和动态模块选择来优化性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 LoRA 方法在组合多个 LoRA 适配器时存在困难，尤其是在无法预先确定所需技能的数量和性质的开放式场景中。本研究旨在解决这一问题，通过提出一种能够有效组合多个 LoRA 适配器的新框架。

Method: LoRAtorio 是一个新颖的、无需训练的框架，用于多 LoRA 组合，它利用内在的模型行为。该方法通过将潜在空间划分为空间块，并计算每个块的预测噪声与基础模型预测噪声之间的余弦相似度来操作。这些相似度用于构建一个空间感知的权重矩阵，指导 LoRA 输出的加权聚合。为了解决领域漂移问题，还提出了一种修改后的无分类器指导方法，将基础模型的无条件分数纳入组合。此外，还提出了一种动态模块选择机制，能够在推理时从大量 LoRA 适配器中选择相关的适配器。

Result: LoRAtorio 在 ClipScore 方面提高了 1.3%，在 GPT-4V 配对评估中获胜率为 72.43%，并且能够有效地推广到多个潜在扩散模型。

Conclusion: LoRAtorio框架在多 LoRA 组合方面取得了最先进的性能，在 ClipScore 方面提高了 1.3%，在 GPT-4V 配对评估中获胜率为 72.43%，并且能够有效地推广到多个潜在扩散模型。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted technique in
text-to-image diffusion models, enabling the personalisation of visual concepts
such as characters, styles, and objects. However, existing approaches struggle
to effectively compose multiple LoRA adapters, particularly in open-ended
settings where the number and nature of required skills are not known in
advance. In this work, we present LoRAtorio, a novel train-free framework for
multi-LoRA composition that leverages intrinsic model behaviour. Our method is
motivated by two key observations: (1) LoRA adapters trained on narrow domains
produce denoised outputs that diverge from the base model, and (2) when
operating out-of-distribution, LoRA outputs show behaviour closer to the base
model than when conditioned in distribution. The balance between these two
observations allows for exceptional performance in the single LoRA scenario,
which nevertheless deteriorates when multiple LoRAs are loaded. Our method
operates in the latent space by dividing it into spatial patches and computing
cosine similarity between each patch's predicted noise and that of the base
model. These similarities are used to construct a spatially-aware weight
matrix, which guides a weighted aggregation of LoRA outputs. To address domain
drift, we further propose a modification to classifier-free guidance that
incorporates the base model's unconditional score into the composition. We
extend this formulation to a dynamic module selection setting, enabling
inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio
achieves state-of-the-art performance, showing up to a 1.3% improvement in
ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises
effectively to multiple latent diffusion models.

</details>


### [94] [Thyme: Think Beyond Images](https://arxiv.org/abs/2508.11630)
*Yi-Fan Zhang,Xingyu Lu,Shukang Yin,Chaoyou Fu,Wei Chen,Xiao Hu,Bin Wen,Kaiyu Jiang,Changyi Liu,Tianke Zhang,Haonan Fan,Kaibing Chen,Jiankang Chen,Haojie Ding,Kaiyu Tang,Zhang Zhang,Liang Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: Thyme是一个新范式，使LMM能够通过自主生成和执行代码来超越现有的“图像思考”方法。它通过两阶段训练（SFT+RL）和GRPO-ATS算法实现，能在处理图像和执行代码时保持高自主性，并在多项基准测试中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMM）在“图像思考”方面存在局限，缺乏像专有模型（O3）那样丰富的功能集，无法同时进行多样化的图像操作并增强代码逻辑推理能力。该研究旨在弥补这一差距。

Method: Thyme通过两阶段训练策略实现其能力：首先在500K样本的精心策划的数据集上进行SFT训练以教授代码生成，然后进行RL阶段以优化决策。在RL阶段，提出GRPO-ATS（Group Relative Policy Optimization with Adaptive Temperature Sampling）算法，通过对文本和代码生成应用不同的温度来平衡推理探索和代码执行精度。

Result: Thyme能够自主生成和执行多样化的图像处理和计算操作，实现丰富的即时图像操作（如裁剪、旋转、对比度增强）和数学计算，同时保持高度自主性。实验评估显示，Thyme在近20项基准测试中取得了显著且一致的性能提升，特别是在高分辨率感知和复杂推理任务上。

Conclusion: Thyme在近20项基准测试中展现出显著且一致的性能提升，尤其在具有挑战性的高分辨率感知和复杂推理任务方面。

Abstract: Following OpenAI's introduction of the ``thinking with images'' concept,
recent efforts have explored stimulating the use of visual information in the
reasoning process to enhance model performance in perception and reasoning
tasks. However, to the best of our knowledge, no open-source work currently
offers a feature set as rich as proprietary models (O3), which can perform
diverse image manipulations and simultaneously enhance logical reasoning
capabilities through code. In this paper, we make a preliminary attempt in this
direction by introducing Thyme (Think Beyond Images), a novel paradigm for
enabling MLLMs to transcend existing ``think with images'' approaches by
autonomously generating and executing diverse image processing and
computational operations via executable code. This approach not only
facilitates a rich, on-the-fly set of image manipulations (e.g., cropping,
rotation, contrast enhancement) but also allows for mathematical computations,
all while maintaining high autonomy in deciding when and how to apply these
operations. We activate this capability through a two-stage training strategy:
an initial SFT on a curated dataset of 500K samples to teach code generation,
followed by a RL phase to refine decision-making. For the RL stage, we manually
collect and design high-resolution question-answer pairs to increase the
learning difficulty, and we propose GRPO-ATS (Group Relative Policy
Optimization with Adaptive Temperature Sampling), an algorithm that applies
distinct temperatures to text and code generation to balance reasoning
exploration with code execution precision. We conduct extensive experimental
analysis and ablation studies. Comprehensive evaluations on nearly 20
benchmarks show that Thyme yields significant and consistent performance gains,
particularly in challenging high-resolution perception and complex reasoning
tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [95] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

TL;DR: A2HCoder利用LLM技术，通过分层框架和逐步翻译，解决了算法设计与硬件实现之间的差距，提高了代码生成效率和可靠性，并成功应用于5G通信领域。


<details>
  <summary>Details</summary>
Motivation: 在无线通信系统中，超低延迟和功耗等严格要求增加了对高效算法到硬件部署的需求。然而，算法设计与硬件实现之间仍然存在显著差距，传统上需要大量的领域知识和耗时的手动开发，因为像MATLAB这样的高级编程语言与Verilog这样的硬件描述语言在内存访问模式、数据处理方式和数据类型表示方面存在根本性不匹配。

Method: A2HCoder是一个分层的算法到HDL编码代理，利用大型语言模型（LLMs）驱动，通过分层框架来增强鲁棒性和可解释性，并抑制LLM生成的代码中常见的幻觉问题。在横向维度，A2HCoder将复杂算法分解为模块化功能块；在纵向维度，A2HCoder不依赖于端到端的生成，而是进行逐步的、细粒度的翻译，并利用MATLAB和Vitis HLS等外部工具链进行调试和电路级综合。

Result: A2HCoder成功实现了算法到硬件的转换，解决了传统方法中的挑战，并通过5G无线通信领域的实际部署案例证明了其有效性。

Conclusion: A2HCoder通过在5G无线通信领域的实际部署案例进行了验证，证明了其在实际应用中的可行性、可靠性和部署效率。

Abstract: In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [96] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: PersonaTwin框架通过整合多维度用户数据，构建能够进行真实且包含情感细微差别模拟的数字孪生，显著提升了LLM在个性化数字用户建模和行为分析方面的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）虽然在用户建模和行为近似方面提供了新的可能性，但它们往往无法捕捉个体用户的多维度细微差别。

Method: PersonaTwin是一个多层提示条件框架，通过整合人口统计、行为和心理测量数据来构建自适应的数字孪生。

Result: 该框架在模拟保真度上能与“神谕”设置相媲美。此外，在PersonaTwin构建的数字孪生上训练的下游模型，在预测和公平性指标上，可以近似于在真实个体数据上训练的模型，这在基于GPT-4o和Llama的模型上均得到了验证。

Conclusion: 大型语言模型（LLM）在用户建模和行为模拟方面有巨大潜力，但难以捕捉个体用户的多维度细微差别。PersonaTwin框架通过整合人口统计、行为和心理测量数据，构建自适应的数字孪生，有效解决了这一问题。实验结果表明，PersonaTwin在模拟保真度上能与“神谕”设置相媲美，并且基于PersonaTwin训练的下游模型在预测和公平性指标上与基于个体训练的模型相当，无论是在GPT-4o还是Llama模型上。

Abstract: While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [97] [E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection](https://arxiv.org/abs/2508.11197)
*Ahmad Mousavi,Yeganeh Abdollahinejad,Roberto Corizzo,Nathalie Japkowicz,Zois Boukouvalas*

Main category: cs.CL

TL;DR: E-CaTCH是一个用于多模态社交媒体错误信息检测的框架，它通过事件级分析和跨模态时间建模来提高准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能捕捉跨时间与跨模态的事件级结构，导致多模态社交媒体错误信息检测具有挑战性。

Method: E-CaTCH框架通过聚类帖子形成伪事件，然后利用文本和视觉特征提取、跨模态注意力对齐、趋势感知LSTM进行时间演化建模，并结合自适应类别加权、时间一致性正则化和困难样本挖掘来处理类别不平衡和促进稳定学习。

Result: E-CaTCH在Fakeddit、IND和COVID-19 MISINFOGRAPH数据集上持续优于最先进的基线方法。

Conclusion: E-CaTCH框架在Fakeddit、IND和COVID-19 MISINFOGRAPH数据集上均优于现有最先进的方法，并且在跨数据集评估中表现出良好的鲁棒性、泛化性和实用性。

Abstract: Detecting multimodal misinformation on social media remains challenging due
to inconsistencies between modalities, changes in temporal patterns, and
substantial class imbalance. Many existing methods treat posts independently
and fail to capture the event-level structure that connects them across time
and modality. We propose E-CaTCH, an interpretable and scalable framework for
robustly detecting misinformation. If needed, E-CaTCH clusters posts into
pseudo-events based on textual similarity and temporal proximity, then
processes each event independently. Within each event, textual and visual
features are extracted using pre-trained BERT and ResNet encoders, refined via
intra-modal self-attention, and aligned through bidirectional cross-modal
attention. A soft gating mechanism fuses these representations to form
contextualized, content-aware embeddings of each post. To model temporal
evolution, E-CaTCH segments events into overlapping time windows and uses a
trend-aware LSTM, enhanced with semantic shift and momentum signals, to encode
narrative progression over time. Classification is performed at the event
level, enabling better alignment with real-world misinformation dynamics. To
address class imbalance and promote stable learning, the model integrates
adaptive class weighting, temporal consistency regularization, and hard-example
mining. The total loss is aggregated across all events. Extensive experiments
on Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH
consistently outperforms state-of-the-art baselines. Cross-dataset evaluations
further demonstrate its robustness, generalizability, and practical
applicability across diverse misinformation scenarios.

</details>


### [98] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

TL;DR: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models that push the frontier of accuracy and inference cost. They use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and reinforcement learning. The models have strong agentic capabilities and achieve strong results on benchmarks ranging from mathematics, coding, and safety. We release the model weights and related resources under an Apache 2.0 license.


<details>
  <summary>Details</summary>
Motivation: To push the frontier of accuracy and inference cost with open-weight reasoning models.

Method: The models use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and reinforcement learning. We optimize the models to have strong agentic capabilities (deep research browsing, python tool use, and support for developer-provided functions), all while using a rendered chat format that enables clear instruction following and role delineation.

Result: Both models achieve strong results on benchmarks ranging from mathematics, coding, and safety.

Conclusion: We release the model weights, inference implementations, tool environments, and tokenizers under an Apache 2.0 license to enable broad use and further research.

Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [99] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

TL;DR: 本研究旨在自动从新闻文章中提取公司风险因素，并发现微调的预训练语言模型比大型语言模型在识别风险因素方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了识别与公司相关的风险，这对于投资者和整体金融市场的福祉非常重要。

Method: 本研究提出了一种新的包含七个不同方面（如供应链、法规和竞争）的模式，并对744篇新闻文章进行了抽样和标注，以对各种机器学习模型进行基准测试。实验表明，虽然大型语言模型在各种自然语言处理任务中取得了巨大进展，但零样本和少样本提示的先进大型语言模型（如LLaMA-2）在识别风险因素方面只能达到中低等性能。而微调的预训练语言模型在大多数风险因素上的表现更好。

Result: 通过分析超过277,000篇彭博社新闻文章，证明了从新闻中识别风险因素可以为公司和行业的运营提供广泛的见解。

Conclusion: 识别新闻中的公司风险因素对于投资者和金融市场至关重要。本研究构建了一个计算框架，用于从新闻文章中自动提取公司风险因素。

Abstract: Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [100] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

TL;DR: Rule2Text uses LLMs to explain complex logical rules from knowledge graphs in natural language, making them easier to understand. The framework includes advanced evaluation methods and a fine-tuned model for high-quality explanations.


<details>
  <summary>Details</summary>
Motivation: Logical rules mined from knowledge graphs (KGs) are often difficult for humans to interpret due to complexity and idiosyncratic labeling. This work aims to improve KG accessibility and usability by generating natural language explanations for these rules.

Method: Developed Rule2Text, a framework leveraging LLMs for natural language explanations of logical rules. Evaluated multiple LLMs with various prompting strategies (zero-shot, few-shot, variable type incorporation, Chain-of-Thought). Conducted human evaluation and developed an LLM-as-a-judge framework for scalability. Fine-tuned the Zephyr model using curated datasets and integrated a type inference module.

Result: Fine-tuning the Zephyr model significantly improved explanation quality, especially on domain-specific datasets. The LLM-as-a-judge framework showed strong agreement with human evaluation. The type inference module supports KGs lacking explicit type information.

Conclusion: LLMs can generate natural language explanations for mined logical rules, improving KG accessibility. Fine-tuning Zephyr with high-quality datasets resulted in significant explanation quality improvements. The Rule2Text framework, including an LLM-as-a-judge evaluation and a type inference module, enhances KG usability.

Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [101] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: MDMs are good for text generation, and a new method makes them even better.


<details>
  <summary>Details</summary>
Motivation: To improve the generation quality of masked diffusion language models (MDMs) by leveraging inference-time scaling methods similar to those used in other diffusion models.

Method: A verifier-based inference-time scaling method is proposed to guide the denoising process of MDMs.

Result: Experiments show that MDMs perform well on text-style transfer tasks and that the proposed verifier improves generation quality.

Conclusion: MDMs are a better alternative to autoregressive language models for text-style transfer tasks, and a soft-value-based verifier can significantly improve generation quality.

Abstract: Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [102] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 现有的AI安全框架未能充分满足儿童的需求，本研究提出了SproutBench评估套件，用于评估LLM在儿童使用中的安全性，并发现了显著的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有的AI安全框架主要针对成人用户，忽视了未成年人的独特发育脆弱性，因此有必要重新评估针对儿童和青少年的LLM的安全框架。

Method: 提出了包含1,283个符合发展规律的对抗性提示的SproutBench评估套件，用于探测诸如情感依赖、隐私侵犯和模仿危险行为等风险。对47个不同的LLM进行了严格的实证评估。

Result: 研究发现，现有的LLM在安全方面存在显著的漏洞，并且发现交互性与年龄适宜性之间存在显著的负相关关系。

Conclusion: 该研究提出了SproutBench评估套件，并揭示了现有LLM在儿童和青少年使用中存在的重大安全漏洞，为儿童为中心的AI设计和部署提供了实用指南。

Abstract: The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [103] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

TL;DR: LLMs在处理跨语言信息时会产生幻觉，本研究通过训练小型Transformer模型发现，统一的跨语言表征是解决此问题的关键，并提出了通过数据调整和分词来改善跨语言迁移的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在跨语言知识迁移方面存在挑战，即当模型被用一种语言提问，但训练数据主要包含另一种语言的事实时，模型会产生幻觉。这项研究旨在通过一个受控的实验环境来深入理解这一现象的根本原因和动态过程。

Method: 本研究通过在合成多语言数据集上从头训练小的Transformer模型，来研究LLMs在跨语言知识迁移中的问题。研究识别出一个关键的学习阶段，在此阶段模型会形成对同一事实的跨语言表征，并证明了表征的统一性对于实现跨语言迁移是必要的。研究还量化了表征统一性与数据语言互信息及语言提取难度之间的关系。在此基础上，研究提出了通过操纵数据分布和分词方法来调节跨语言迁移水平的策略，并开发了相应的度量和可视化工具来评估这些策略的效果。

Result: 研究表明，模型在训练过程中会经历一个学习阶段，在此阶段模型会形成对同一事实的独立或统一的跨语言表征，而统一的表征对于有效的跨语言迁移至关重要。研究还发现，表征的统一程度受到事实与训练数据语言之间互信息量以及语言提取难度的影响。通过调整数据分布和分词策略，可以有效调控跨语言迁移的水平。

Conclusion: LLMs在跨语言知识迁移方面存在不足，表现为在用一种语言提问时，会幻觉出在训练时用另一种语言表达的事实。通过在合成多语言数据集上从头训练小的Transformer模型，我们为研究这一现象的起因和动态提供了一个受控环境。我们发现模型会经历一个学习阶段，在此阶段，模型会为同一事实发展出跨语言的独立或统一的表征，而统一的表征对于跨语言迁移至关重要。此外，我们证明了表征的统一程度取决于事实与训练数据语言之间的互信息量以及语言提取的难易程度。基于这些发现，我们提出了通过调整数据分布和分词（tokenization）来调控跨语言迁移水平的方法，并引入了正式表征其对统一性影响的度量和可视化。我们的研究展示了受控环境如何揭示预训练动态，并为改善LLMs的跨语言迁移能力提供了新的方向。

Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [104] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

TL;DR: 语言模型代理在面对外部失败时，难以制定和执行备用计划，即使在搜索空间受限的情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: 研究当语言模型代理在现实世界复杂问题中遇到意外失败时，它们寻找替代方案以达成目标的能力。

Method: 提出一个专门的代理规划基准来研究这个问题，该基准通过函数调用组合来解决规划问题，代理从超过四千种可能性中搜索相关函数，并观察函数输出或错误消息形式的环境反馈。

Result: 即使引入外部失败（例如函数突然变得不可用），模型在规划任务上的表现也会受到影响。最先进的模型虽然通常能在正确上下文中识别正确的函数，但在适应环境反馈和追求替代行动方面存在困难。

Conclusion: 语言模型代理在面对超出其控制范围的原因而失败时，在寻求替代方法以实现目标方面存在困难，即使在搜索空间受到人为限制的情况下也是如此。

Abstract: As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [105] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

TL;DR: 该研究提出了一个评估大型语言模型（LLMs）中与极化相关的偏见的新框架，该框架可重用、细粒度且与主题无关。通过使用合成的、包含冲突相关陈述的平衡数据集和对极化敏感的sentiment指标，研究评估了包括GPT-4和Gemini在内的多个LLMs，发现总体上对乌克兰的情感倾向更积极，并揭示了模型在不同语义类别中的细微行为差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在下游任务中表现出偏见，尤其是在处理政治言论、性别认同、民族关系或国家刻板印象等敏感话题时。虽然在偏见检测和缓解技术方面已取得显著进展，但仍有一些挑战未被充分探索。

Method: 提出一个可重用的、细粒度的、与主题无关的框架来评估LLM（包括开源和闭源）中与极化相关的偏见。该方法结合了对极化敏感的sentiment指标和一个合成生成的、包含冲突相关陈述的平衡数据集，并使用预定义的语义类别。

Result: 通过一个聚焦于俄乌战争的合成数据集，评估了Llama-3、Mistral、GPT-4、Claude 3.5和Gemini 1.0等LLM的偏见。结果显示，总体上对乌克兰的情感倾向更积极，并且该框架能够进行细粒度分析，揭示了模型之间不同的行为模式。对提示修改的适应性进一步显示出对先入为主的语言和公民身份修改的偏见。

Conclusion: 该框架支持自动化数据集生成和细粒度偏见评估，适用于各种由极化驱动的场景和主题，并且与许多其他偏见评估策略正交。

Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [106] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

TL;DR: This paper embeds digital dictionaries into AMR graphs using LLMs, reduces the graphs while preserving their properties, and analyzes the results in the context of the symbol grounding problem.


<details>
  <summary>Details</summary>
Motivation: To describe how real digital dictionaries can be embedded into AMR digraphs and analyze the properties of the reduced digraphs in relation to the symbol grounding problem.

Method: Embedding real digital dictionaries into AMR digraphs using pre-trained large language models and reducing those graphs in a confluent manner.

Result: Real digital dictionaries can be embedded into AMR digraphs, and their reduced properties are analyzed concerning the symbol grounding problem.

Conclusion: The properties of the reduced digraphs are analyzed and discussed in relation to the symbol grounding problem.

Abstract: Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [107] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

TL;DR: RAMP是一个多代理框架，利用LLM规划、工具和长期记忆来改进营销中的受众策划，显著提高了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: LLM代理在真实世界应用中的可靠性文献有限，需要研究其在动态、面向行业的环境中的部署。

Method: 提出了一种名为RAMP的多代理框架，用于营销中的受众策划。该框架通过迭代规划、工具调用、输出验证和改进建议来运作，并结合了长期记忆库（特定客户事实和历史查询）。

Result: RAMP框架将准确性提高了28个百分点（基于88个评估查询）。对于模糊查询，迭代验证和反思可将召回率提高约20个百分点，并提高用户满意度。

Conclusion: LLM规划和记忆可以提高营销任务的准确性，迭代验证和反思可以提高模糊查询的召回率和用户满意度。

Abstract: Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [108] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

TL;DR: MoNaCo 是一个包含 1,315 个自然、复杂问题的基准测试，用于评估 LLM 在需要大量中间步骤的信息检索任务方面的能力。现有 LLM 在此基准测试上的表现不佳，凸显了对更强推理能力的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 基准测试缺乏能够充分反映人类解决问题所需时间和复杂性的自然问题，因此需要一个能够衡量 LLM 在处理现实世界信息检索任务方面的能力的新基准。

Method: 开发了一个分解式标注流程，用于大规模收集和手动回答自然、耗时的问题，以构建 MoNaCo 基准测试。

Result: 在 MoNaCo 基准测试上，当前的 LLM 最多只能达到 61.2% 的 F1 分数，这主要是由于召回率低和幻觉造成的。

Conclusion: LLMs 在处理需要大量中间步骤的复杂、信息检索型问题方面仍然存在不足，MoNaCo 基准测试突显了对更强推理能力的需求。

Abstract: Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [109] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

TL;DR: MobQA是一个用于评估大型语言模型在人类移动数据方面的语义理解能力的数据集。虽然模型在事实检索方面表现良好，但在语义推理和解释方面存在不足，轨迹长度是影响模型性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在通过自然语言问答理解人类移动数据方面的语义理解能力，现有模型虽然能预测移动模式，但对其底层原因或语义含义的理解能力尚不清楚。

Method: 提出了一个名为MobQA的基准数据集，包含5800个高质量问答对，涵盖事实检索、多项选择推理和自由形式解释三种问题类型，用于评估大型语言模型在理解人类移动数据方面的能力。

Result: 在对主要大型语言模型的评估中，发现在事实检索方面表现强劲，但在语义推理和解释性问答方面存在显著局限性，并且轨迹长度对模型有效性有显著影响。

Conclusion: 现有的大型语言模型在理解人类移动模式的语义方面存在显著局限性，尤其是在需要空间、时间和语义推理的解释性问题上。模型在事实检索方面表现良好，但在语义推理和问答方面能力有限，且轨迹长度会严重影响模型性能。

Abstract: This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [110] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

TL;DR: Tulu语社交媒体内容冒犯性语言识别：BiGRU模型优于Transformer，数据集和基准已建立。


<details>
  <summary>Details</summary>
Motivation: Tulu语作为一种低资源语言，在数字领域日益增长但计算资源有限，需要专门的NLP研究工具和数据集来处理其代码混合的社交媒体内容。

Method: 构建了一个包含3,845条YouTube评论的Tulu语代码混合冒犯性语言识别基准数据集，并对GRU、LSTM、BiGRU、BiLSTM、CNN、注意力机制模型以及mBERT、XLM-RoBERTa等Transformer模型进行了评估。

Result: 带有自注意力机制的BiGRU模型在Tulu语代码混合冒犯性语言识别任务中表现最佳，达到了82%的准确率和0.81的宏观F1分数。Transformer模型表现不佳，显示出多语言预训练模型在低资源、代码混合语境下的局限性。

Conclusion: 该研究为印度南部低资源多语种Tulu语言的冒犯性语言识别（OLI）奠定了基础，展示了深度学习模型（特别是带有自注意力机制的BiGRU）在处理混合编码社交媒体内容方面的潜力，并指出了现有Transformer模型在该类上下文中的局限性。

Abstract: Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [111] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

TL;DR: 本研究提出了一种用于生成个性化干扰项的框架，以解决现有方法无法捕捉个体学生推理错误的问题。通过蒙特卡洛树搜索（MCTS）构建学生误解原型，并模拟学生推理过程生成干扰项。实验证明该方法在个性化和群体干扰项生成上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的干扰项生成方法，虽然能生成群体层面的干扰项，但未能捕捉到个别学生的推理错误，限制了其诊断效果。为了解决这个问题，提出个性化干扰项生成任务，旨在根据从学生历史问答记录中推断出的个体误解来生成量身定制的干扰项，以有效地暴露每个学生特定的推理错误。

Method: 提出了一种无需训练的、分为两个阶段的框架。第一阶段，通过应用蒙特卡洛树搜索（MCTS）来恢复学生过去的错误答案所隐含的推理轨迹，构建学生特定的误解原型。第二阶段，该原型指导模型在新的问题上模拟学生的推理过程，生成与学生常见误解一致的个性化干扰项。

Result: 实验表明，该方法在为140名学生生成个性化干扰项方面取得了最佳性能，并且能够有效地泛化到群体层面。

Conclusion: 所提出的方法在为140名学生生成个性化干扰项方面取得了最佳效果，并且在群体层面也表现良好，显示出其鲁棒性和适应性。

Abstract: Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [112] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出了一种寄生双尺度方法，通过 KVSPN 模块和蒸馏技术，在保持甚至提升 Whisper 翻译性能的同时，实现了 2.6 倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 统一的多语言语音到文本翻译模型虽然能够同时处理多种语言，但通常参数量巨大，难以在保证推理效率和性能之间取得平衡，尤其是在本地部署场景下。

Method: 提出了一种创新的寄生双尺度方法（Parasitic Dual-Scale Approach），结合了增强的推测性采样（speculative sampling）方法、模型压缩和知识蒸馏技术。在此基础上，对 Whisper Medium 模型进行了增强，使其成为 whisperM2M，并集成了新颖的 KVSPN 模块。

Result: 在六种流行语言上实现了最先进的性能，并提高了推理效率。KVSPN 模块实现了 40% 的加速，且 BLEU 分数没有下降。结合蒸馏方法，相较于原始的 Whisper Medium 模型，实现了 2.6 倍的加速，同时性能更优。

Conclusion: 所提出的 KVSPN 模块和蒸馏方法实现了 40% 的速度提升，且 BLEU 分数没有下降。与原始的 Whisper Medium 模型相比，整体速度提升了 2.6 倍，同时性能更优，达到了包括六种流行语言在内的最先进水平。

Abstract: Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


### [113] [Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2508.11247)
*Changjian Wang,Weihong Deng,Weili Guan,Quan Lu,Ning Jiang*

Main category: cs.CL

TL;DR: HGRAG是一种用于多跳问答的新型RAG方法，通过超图结合结构和语义信息，提高了QA性能并加速了检索。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法主要关注文本语义相似性，忽略了分散知识的结构关联，限制了其在多跳问答（MHQA）任务中的有效性。而GraphRAG方法过度依赖结构信息和细粒度检索，导致文本语义利用不足。

Method: 提出了一种名为HGRAG的新型RAG方法，利用超图实现了结构和语义信息的跨粒度集成。通过构建实体超图（实体作为节点，段落作为超边）来建立知识关联，并设计了一种通过超图扩散集成细粒度实体相似性和粗粒度段落相似性的超图检索方法。最后，通过检索增强模块进一步优化检索结果，以获得最相关的段落作为LLM的回答生成上下文。

Result: 实验结果表明，HGRAG方法在QA性能上优于最先进的方法，并实现了6倍的检索效率提升。

Conclusion: HGRAG方法在MHQA任务上超越了现有方法，并在检索效率上实现了6倍的加速。

Abstract: Multi-hop question answering (MHQA) requires integrating knowledge scattered
across multiple passages to derive the correct answer. Traditional
retrieval-augmented generation (RAG) methods primarily focus on coarse-grained
textual semantic similarity and ignore structural associations among dispersed
knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods
address this by leveraging knowledge graphs (KGs) to capture structural
associations, but they tend to overly rely on structural information and
fine-grained word- or phrase-level retrieval, resulting in an underutilization
of textual semantics. In this paper, we propose a novel RAG approach called
HGRAG for MHQA that achieves cross-granularity integration of structural and
semantic information via hypergraphs. Structurally, we construct an entity
hypergraph where fine-grained entities serve as nodes and coarse-grained
passages as hyperedges, and establish knowledge association through shared
entities. Semantically, we design a hypergraph retrieval method that integrates
fine-grained entity similarity and coarse-grained passage similarity via
hypergraph diffusion. Finally, we employ a retrieval enhancement module, which
further refines the retrieved results both semantically and structurally, to
obtain the most relevant passages as context for answer generation with the
LLM. Experimental results on benchmark datasets demonstrate that our approach
outperforms state-of-the-art methods in QA performance, and achieves a
6$\times$ speedup in retrieval efficiency.

</details>


### [114] [UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?](https://arxiv.org/abs/2508.11260)
*Mukund Choudhary,KV Aditya Srivatsa,Gaurja Aeron,Antara Raaghavi Bhattacharya,Dang Khoa Dang Dinh,Ikhlasul Akmal Hanif,Daria Kotova,Ekaterina Kochmar,Monojit Choudhury*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have demonstrated potential in reasoning tasks,
but their performance on linguistics puzzles remains consistently poor. These
puzzles, often derived from Linguistics Olympiad (LO) contests, provide a
minimal contamination environment to assess LLMs' linguistic reasoning
abilities across low-resource languages. This work analyses LLMs' performance
on 629 problems across 41 low-resource languages by labelling each with
linguistically informed features to unveil weaknesses. Our analyses show that
LLMs struggle with puzzles involving higher morphological complexity and
perform better on puzzles involving linguistic features that are also found in
English. We also show that splitting words into morphemes as a pre-processing
step improves solvability, indicating a need for more informed and
language-specific tokenisers. These findings thus offer insights into some
challenges in linguistic reasoning and modelling of low-resource languages.

</details>


### [115] [LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought](https://arxiv.org/abs/2508.11280)
*Ruiyan Qi,Congding Wen,Weibo Zhou,Shangsong Liang,Lingbo Li*

Main category: cs.CL

TL;DR: 该研究提出了一种名为LETToT的无标注框架，利用专家思维树来评估旅游领域的大型语言模型，解决了标注成本和模型幻觉问题。实验证明该方法有效，并发现了模型规模和推理能力对表现的影响。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在旅游等特定领域的表现面临挑战，主要包括标注数据的成本高昂以及模型幻觉等问题。因此，需要一种无需标注数据即可进行有效评估的方法。

Method: LETToT框架，通过迭代优化和验证层次化思维树组件，并结合专家反馈和通用质量维度来评估旅游领域的大型语言模型。该方法不依赖于标注数据。

Result: 1. LETToT框架通过系统优化的专家思维树，在评估中实现了比基线模型高4.99%-14.15%的相对质量提升。2. 在不同规模的模型（32B-671B参数）评估中，发现：a) 规模法则在专业领域依然适用（DeepSeek-V3表现最佳），但经过推理增强的小型模型（如DeepSeek-R1-Distill-Llama-70B）能够缩小与大型模型的差距；b) 对于参数量小于72B的模型，显式的推理架构在准确性和简洁性方面优于其他模型（p<0.05）。

Conclusion: 该研究提出了一个名为LETToT的框架，用于在没有标注数据的情况下评估旅游领域的大型语言模型。通过使用专家生成的推理结构（思维树），LETToT克服了标注成本高和模型幻觉等问题。实验结果表明，该框架能够有效提升模型评估的质量，并揭示了模型规模和推理能力对旅游领域LLM表现的影响规律。

Abstract: Evaluating large language models (LLMs) in specific domain like tourism
remains challenging due to the prohibitive cost of annotated benchmarks and
persistent issues like hallucinations. We propose $\textbf{L}$able-Free
$\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert
$\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that
leverages expert-derived reasoning structures-instead of labeled data-to access
LLMs in tourism. First, we iteratively refine and validate hierarchical ToT
components through alignment with generic quality dimensions and expert
feedback. Results demonstrate the effectiveness of our systematically optimized
expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we
apply LETToT's optimized expert ToT to evaluate models of varying scales
(32B-671B parameters), revealing: (1) Scaling laws persist in specialized
domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,
DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit
reasoning architectures outperform counterparts in accuracy and conciseness
($p<0.05$). Our work established a scalable, label-free paradigm for
domain-specific LLM evaluation, offering a robust alternative to conventional
annotated benchmarks.

</details>


### [116] [ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection](https://arxiv.org/abs/2508.11281)
*Axel Delaval,Shujian Yang,Haicheng Wang,Han Qiu,Jialiang Lu*

Main category: cs.CL

TL;DR: 该研究提出了TOXIFRENCH数据集，并发现小型语言模型（SLM）在法语毒性检测任务中表现优于大型模型。研究人员提出了一种新的思维链（CoT）微调策略，显著提高了模型的性能，使其在F1分数上优于GPT-40和Gemini-2.5。该方法还表现出强大的跨语言能力。


<details>
  <summary>Details</summary>
Motivation: 为了应对法语毒性检测中缺乏相关数据集的挑战，并探索模型规模与毒性检测任务鲁棒性和泛化能力之间的关系。

Method: 使用包含53,622个法语在线评论的TOXIFRENCH基准测试，通过结合高置信度的大语言模型（LLM）预标注和人工验证的半自动化标注流程，同时对包括小型语言模型（SLM）在内的一系列模型进行了基准测试，并提出了一种新颖的思维链（CoT）微调策略，该策略使用动态加权损失来逐步强调模型的最终决策。

Result: 所提出的思维链（CoT）微调策略显著提高了模型的忠实度，微调后的4B模型在F1分数上比基线模型提高了13%，并且优于GPT-40和Gemini-2.5等大型语言模型。

Conclusion: 检测结果表明，该方法在跨语言毒性检测基准测试中表现出强大的多语言能力，表明该方法可以有效地扩展到其他语言和安全关键的分类任务。

Abstract: Detecting toxic content using language models is crucial yet challenging.
While substantial progress has been made in English, toxicity detection in
French remains underdeveloped, primarily due to the lack of culturally
relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new
public benchmark of 53,622 French online comments, constructed via a
semi-automated annotation pipeline that reduces manual labeling to only 10%
through high-confidence LLM-based pre-annotation and human verification. Then,
we benchmark a broad range of models and uncover a counterintuitive insight:
Small Language Models (SLMs) outperform many larger models in robustness and
generalization under the toxicity detection task. Motivated by this finding, we
propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic
weighted loss that progressively emphasizes the model's final decision,
significantly improving faithfulness. Our fine-tuned 4B model achieves
state-of-the-art performance, improving its F1 score by 13% over its baseline
and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a
cross-lingual toxicity benchmark demonstrates strong multilingual ability,
suggesting that our methodology can be effectively extended to other languages
and safety-critical classification tasks.

</details>


### [117] [AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries](https://arxiv.org/abs/2508.11285)
*Arya VarastehNezhad,Reza Tavasoli,Soroush Elyasi,MohammadHossein LotfiNia,Hamed Farbeh*

Main category: cs.CL

TL;DR: 不同的大型语言模型在回应心理健康问题时，情绪表达差异很大。模型选择和问题类型（抑郁、焦虑、压力）对情绪有显著影响，而用户画像的影响较小。Mixtral倾向于负面情绪，Llama则更乐观。


<details>
  <summary>Details</summary>
Motivation: 随着抑郁、焦虑和压力等心理健康问题日益普遍，人们越来越依赖大型语言模型（LLMs）来获取信息，因此有必要研究LLMs在回应这些问题时的表现。

Method: 研究了八种LLM（Claude Sonnet, Copilot, Gemini Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity）对包含抑郁、焦虑、压力等心理健康问题的二十种实际问题的回应，这些问题针对六种用户画像（基线、女性、男性、年轻人、老年人、大学生）进行了设定。分析了模型生成的2880个回答的情感和情绪。

Result: 所有LLM的回答中，乐观、恐惧和悲伤是主要情绪，中性情感占比较高。Mixtral模型表达的负面情绪（如不满、烦恼、悲伤）最多，而Llama模型则展现出最乐观、最愉快的响应。焦虑问题引发了极高的恐惧分数（0.974），抑郁问题产生了较高的悲伤分数（0.686）和最负面的情绪，而压力相关问题则带来了最乐观（0.755）和较高的愉悦及信任度。用户画像的设定对情绪基调影响很小。模型和心理健康状况是影响情绪表达的主要因素。

Conclusion: LLM在回应心理健康问题时，其情绪表达存在显著差异，模型选择对用户体验至关重要。

Abstract: Depression, anxiety, and stress are widespread mental health concerns that
increasingly drive individuals to seek information from Large Language Models
(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini
Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty
pragmatic questions about depression, anxiety, and stress when those questions
are framed for six user profiles (baseline, woman, man, young, old, and
university student). The models generated 2,880 answers, which we scored for
sentiment and emotions using state-of-the-art tools. Our analysis revealed that
optimism, fear, and sadness dominated the emotional landscape across all
outputs, with neutral sentiment maintaining consistently high values.
Gratitude, joy, and trust appeared at moderate levels, while emotions such as
anger, disgust, and love were rarely expressed. The choice of LLM significantly
influenced emotional expression patterns. Mixtral exhibited the highest levels
of negative emotions including disapproval, annoyance, and sadness, while Llama
demonstrated the most optimistic and joyful responses. The type of mental
health condition dramatically shaped emotional responses: anxiety prompts
elicited extraordinarily high fear scores (0.974), depression prompts generated
elevated sadness (0.686) and the highest negative sentiment, while
stress-related queries produced the most optimistic responses (0.755) with
elevated joy and trust. In contrast, demographic framing of queries produced
only marginal variations in emotional tone. Statistical analyses confirmed
significant model-specific and condition-specific differences, while
demographic influences remained minimal. These findings highlight the critical
importance of model selection in mental health applications, as each LLM
exhibits a distinct emotional signature that could significantly impact user
experience and outcomes.

</details>


### [118] [SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory](https://arxiv.org/abs/2508.11290)
*Utsav Maskey,Sumit Yadav,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: LLMs over-refuse benign instructions due to safety mechanisms. This paper introduces SafeConstellations, an inference-time method that analyzes embedding space trajectories to guide models away from refusal, reducing over-refusal by up to 73% with minimal impact on utility.


<details>
  <summary>Details</summary>
Motivation: LLMs exhibit over-refusal behavior, rejecting benign instructions that resemble harmful content, which diminishes their utility in production applications. This paper aims to address this issue by analyzing the underlying mechanisms and proposing a mitigation strategy.

Method: SafeConstellations, an inference-time trajectory-shifting approach that tracks task-specific trajectory patterns in embedding space and guides representations toward non-refusal pathways to mitigate over-refusal behavior in LLMs.

Result: Comprehensive evaluation demonstrates that LLMs still tend to refuse harmful instructions even when reframed as benign. Mechanistic analysis reveals distinct 'constellation' patterns in embedding space during response generation. SafeConstellations reduces over-refusal rates by up to 73% with minimal impact on utility.

Conclusion: LLMs' over-refusal behavior can be mitigated by SafeConstellations, an inference-time approach that guides model representations toward non-refusal pathways by tracking task-specific trajectory patterns. This method reduces over-refusal rates by up to 73% with minimal impact on utility, offering a principled way to address the issue.

Abstract: LLMs increasingly exhibit over-refusal behavior, where safety mechanisms
cause models to reject benign instructions that superficially resemble harmful
content. This phenomena diminishes utility in production applications that
repeatedly rely on common prompt templates or applications that frequently rely
on LLMs for specific tasks (e.g. sentiment analysis, language translation).
Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse
responses to harmful instructions when those instructions are reframed to
appear as benign tasks. Our mechanistic analysis reveal that LLMs follow
distinct "constellation" patterns in embedding space as representations
traverse layers, with each task maintaining consistent trajectories that shift
predictably between refusal and non-refusal cases. We introduce
SafeConstellations, an inference-time trajectory-shifting approach that tracks
task-specific trajectory patterns and guides representations toward non-refusal
pathways. By selectively guiding model behavior only on tasks prone to
over-refusal, and by preserving general model behavior, our method reduces
over-refusal rates by up to 73% with minimal impact on utility-offering a
principled approach to mitigating over-refusals.

</details>


### [119] [SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](https://arxiv.org/abs/2508.11310)
*Beichen Guo,Zhiyuan Wen,Yu Yang,Peng Gao,Ruosong Yang,Jiaxing Shen*

Main category: cs.CL

TL;DR: SGSimEval是一个用于自动问卷生成的评估基准，通过整合大纲、内容、参考文献评估，并结合大语言模型评分和人类偏好指标，克服了现有评估方法的局限性。实验表明，ASG系统在大纲生成上表现良好，但在内容和参考文献生成上需改进。


<details>
  <summary>Details</summary>
Motivation: 现有自动问卷生成（ASG）的评估方法存在局限性，如指标偏差、缺乏人类偏好以及过度依赖大语言模型作为裁判。

Method: 提出了一种名为SGSimEval的综合评估基准，该基准整合了对问卷大纲、内容和参考文献的评估，并结合了基于大语言模型的评分与定量指标。SGSimEval还引入了强调固有质量和与人类相似度的人类偏好指标。

Result: 通过大量实验发现，现有ASG系统在问卷大纲生成方面表现出与人类相当的优势，但在内容和参考文献生成方面仍有显著的改进空间。SGSimEval评估指标能与人类评估结果保持高度一致性。

Conclusion: 现有自动问卷生成系统在问卷大纲生成方面达到了人类可比的水平，但在内容和参考文献生成方面仍有提升空间。SGSimEval评估指标与人类评估结果高度一致。

Abstract: The growing interest in automatic survey generation (ASG), a task that
traditionally required considerable time and effort, has been spurred by recent
advances in large language models (LLMs). With advancements in
retrieval-augmented generation (RAG) and the rising popularity of multi-agent
systems (MASs), synthesizing academic surveys using LLMs has become a viable
approach, thereby elevating the need for robust evaluation methods in this
domain. However, existing evaluation methods suffer from several limitations,
including biased metrics, a lack of human preference, and an over-reliance on
LLMs-as-judges. To address these challenges, we propose SGSimEval, a
comprehensive benchmark for Survey Generation with Similarity-Enhanced
Evaluation that evaluates automatic survey generation systems by integrating
assessments of the outline, content, and references, and also combines
LLM-based scoring with quantitative metrics to provide a multifaceted
evaluation framework. In SGSimEval, we also introduce human preference metrics
that emphasize both inherent quality and similarity to humans. Extensive
experiments reveal that current ASG systems demonstrate human-comparable
superiority in outline generation, while showing significant room for
improvement in content and reference generation, and our evaluation metrics
maintain strong consistency with human assessments.

</details>


### [120] [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)
*Sahil Sk,Debasish Dhal,Sonal Khosla,Sk Shahid,Sambit Shekhar,Akash Dhaka,Shantipriya Parida,Dilip K. Prasad,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本研究评估了4位GSQ和GPTQ量化技术在LLaMA 1B、Qwen 0.5B和PHI 1.5B模型上的性能，通过在多个NLP任务上进行基准测试，分析了模型压缩与任务表现之间的权衡，为LLM的实际部署提供了参考。


<details>
  <summary>Details</summary>
Motivation: 为了提高LLM的可访问性，通过减少内存使用和计算成本，同时保持性能。研究旨在评估低比特量化技术对不同规模模型和NLP任务的影响，为实际部署提供决策依据。

Method: 将4位GSQ和GPTQ量化技术应用于LLaMA 1B、Qwen 0.5B和PHI 1.5B模型，并在MS MARCO、BoolQ和GSM8K数据集上进行基准测试，评估其在准确性和效率方面的表现。

Result: 量化技术在所测试的模型和任务上表现出不同的准确性和效率权衡。研究结果为用户根据特定需求选择合适的量化策略提供了指导。

Conclusion: 通过在LLaMA 1B、Qwen 0.5B和PHI 1.5B模型上应用4位GSQ和GPTQ量化技术，并在MS MARCO、BoolQ和GSM8K数据集上进行评估，本研究为低比特量化在不同规模模型上的适用性提供了见解，并讨论了GSQ和GPTQ的优缺点，为未来的量化研究奠定了基准。

Abstract: Quantization is an essential and popular technique for improving the
accessibility of large language models (LLMs) by reducing memory usage and
computational costs while maintaining performance. In this study, we apply
4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer
Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their
impact across multiple NLP tasks. We benchmark these models on MS MARCO
(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K
(Mathematical Reasoning) datasets, assessing both accuracy and efficiency
across various tasks. The study measures the trade-offs between model
compression and task performance, analyzing key evaluation metrics, namely
accuracy, inference latency, and throughput (total output tokens generated per
second), providing insights into the suitability of low-bit quantization for
real-world deployment. Using the results, users can then make suitable
decisions based on the specifications that need to be met. We discuss the pros
and cons of GSQ and GPTQ techniques on models of different sizes, which also
serve as a benchmark for future experiments.

</details>


### [121] [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)
*Haitong Luo,Weiyao Zhang,Suhang Wang,Wenji Zou,Chungang Lin,Xuying Meng,Yujun Zhang*

Main category: cs.CL

TL;DR: 本研究将文本检测视为信号处理问题，通过分析文本的频域特性，发现人类写作比LLM生成文本具有更高的频谱能量。基于此提出的SpecDetect检测器在性能上优于现有方法，且运行速度更快。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）生成高质量文本的能力增强，对文本进行可靠且高效的检测变得日益重要。现有的无训练检测方法虽然有潜力，但通常依赖于表面统计特征，忽略了文本生成过程中潜在的信号属性。因此，需要一种新的方法来更深入地理解和区分机器生成文本与人类写作。

Method: 本研究将文本检测重构为信号处理问题，通过分析token对数概率序列的频谱特性来区分人类写作和LLM生成文本。具体方法包括使用全局离散傅里叶变换（DFT）和短时傅里叶变换（STFT）来分析文本信号的频谱属性。研究者发现人类写作具有更高的频谱能量，并基于此提出了SpecDetect（基于DFT总能量）和SpecDetect++（引入采样差异机制）两种检测器。

Result: 实验结果表明，SpecDetect和SpecDetect++在检测性能上优于现有最先进的模型，并且运行时间缩短了近一半。这证明了所提出的基于信号处理的方法在效率和准确性方面都具有优势。

Conclusion: 本研究将文本检测重构为信号处理问题，提出了一种在频域分析token对数概率序列的新范式。通过在频域中分析文本的频谱特性，发现人类写作的文本相比于LLM生成的文本具有更高的频谱能量，这反映了人类写作中比LLM生成文本更显著的幅度波动。基于此，研究者构建了SpecDetect和SpecDetect++，前者基于全局离散傅里叶变换（DFT）的单一鲁棒特征——DFT总能量，后者则引入了采样差异机制以增强鲁棒性。实验结果表明，该方法在性能上优于现有最先进模型，同时运行时间缩短近一半。本研究为LLM生成文本检测开辟了一条新的、高效且可解释的途径，证明了经典的信号处理技术在应对这一现代挑战方面具有强大的能力。

Abstract: The proliferation of high-quality text from Large Language Models (LLMs)
demands reliable and efficient detection methods. While existing training-free
approaches show promise, they often rely on surface-level statistics and
overlook fundamental signal properties of the text generation process. In this
work, we reframe detection as a signal processing problem, introducing a novel
paradigm that analyzes the sequence of token log-probabilities in the frequency
domain. By systematically analyzing the signal's spectral properties using the
global Discrete Fourier Transform (DFT) and the local Short-Time Fourier
Transform (STFT), we find that human-written text consistently exhibits
significantly higher spectral energy. This higher energy reflects the
larger-amplitude fluctuations inherent in human writing compared to the
suppressed dynamics of LLM-generated text. Based on this key insight, we
construct SpecDetect, a detector built on a single, robust feature from the
global DFT: DFT total energy. We also propose an enhanced version,
SpecDetect++, which incorporates a sampling discrepancy mechanism to further
boost robustness. Extensive experiments demonstrate that our approach
outperforms the state-of-the-art model while running in nearly half the time.
Our work introduces a new, efficient, and interpretable pathway for
LLM-generated text detection, showing that classical signal processing
techniques offer a surprisingly powerful solution to this modern challenge.

</details>


### [122] [Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning](https://arxiv.org/abs/2508.11364)
*Sylvio Rüdian,Yassin Elsir,Marvin Kretschmer,Sabine Cayrou,Niels Pinkwart*

Main category: cs.CL

TL;DR: 本研究使用 Llama 3.1 从学生作业中提取反馈指标，发现其结果与人类评分高度一致，为自动生成反馈提供了新的方法。


<details>
  <summary>Details</summary>
Motivation: 为了生成高质量、信息丰富的形成性反馈，必须首先提取相关指标，这是构建反馈的基础。教师通常使用包含各种指标的反馈标准网格进行系统评估。本研究旨在考察使用 LLM 提取这些指标的初始阶段。

Method: 本研究使用大型语言模型 Llama 3.1 提取学生语言学习课程作业中的相关指标，并研究了 LLM 生成的指标与人类评分在不同反馈标准下的一致性。

Result: 研究结果显示，LLM 生成的指标与人类评分在各种反馈标准之间具有统计上显著的强相关性，即使在涉及未预料到的指标和标准组合的情况下也是如此。

Conclusion: 本研究提出的使用大型语言模型（LLM）从学生作业中提取指标的方法，为自动生成可解释、透明的形成性反馈奠定了基础。

Abstract: Automated feedback generation has the potential to enhance students' learning
progress by providing timely and targeted feedback. Moreover, it can assist
teachers in optimizing their time, allowing them to focus on more strategic and
personalized aspects of teaching. To generate high-quality, information-rich
formative feedback, it is essential first to extract relevant indicators, as
these serve as the foundation upon which the feedback is constructed. Teachers
often employ feedback criteria grids composed of various indicators that they
evaluate systematically. This study examines the initial phase of extracting
such indicators from students' submissions of a language learning course using
the large language model Llama 3.1. Accordingly, the alignment between
indicators generated by the LLM and human ratings across various feedback
criteria is investigated. The findings demonstrate statistically significant
strong correlations, even in cases involving unanticipated combinations of
indicators and criteria. The methodology employed in this paper offers a
promising foundation for extracting indicators from students' submissions using
LLMs. Such indicators can potentially be utilized to auto-generate explainable
and transparent formative feedback in future research.

</details>


### [123] [When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs](https://arxiv.org/abs/2508.11383)
*Mikhail Seleznyov,Mikhail Chaichuk,Gleb Ershov,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: LLM对提示的微小变化很敏感。我们评估了5种方法来提高提示的鲁棒性，并在8个模型和52个任务上进行了测试。我们的研究结果提供了关于如何使LLM更可靠的实用建议。


<details>
  <summary>Details</summary>
Motivation: LLM对提示措辞和格式的细微、非语义变化高度敏感，这影响了其在实际应用中的稳定性和可靠性。

Method: 系统性评估了5种提高提示鲁棒性的方法，涵盖了微调和上下文学习范式，并在8个模型（Llama、Qwen、Gemma系列）的52个任务上进行了基准测试，并测试了它们在多种分布 shifts 上的泛化能力。此外，还评估了GPT-4.1和DeepSeek V3模型对格式扰动的鲁棒性。

Result: 本研究系统性评估了5种提高提示鲁棒性的方法，并提供了关于这些方法相对有效性的可操作见解，以帮助实践者做出明智的决策。

Conclusion: LLM在提示措辞和格式的细微、非语义变化上高度敏感。本研究首次在一个统一的实验框架内，对5种提高提示鲁棒性的方法进行了系统评估，这些方法涵盖了微调和上下文学习范式，并在8个模型（Llama、Qwen、Gemma系列）的52个任务上进行了基准测试。评估结果表明，这些方法在应对多种分布 shifts 方面具有一定的泛化能力。研究还扩展到GPT-4.1和DeepSeek V3模型，以评估前沿模型对格式扰动的鲁棒性。研究结果为实践者在追求稳定可靠的LLM性能时，提供了关于这些鲁棒性方法相对有效性的可操作见解。

Abstract: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic
variations in prompt phrasing and formatting. In this work, we present the
first systematic evaluation of 5 methods for improving prompt robustness within
a unified experimental framework. We benchmark these techniques on 8 models
from Llama, Qwen and Gemma families across 52 tasks from Natural Instructions
dataset. Our evaluation covers robustness methods from both fine-tuned and
in-context learning paradigms, and tests their generalization against multiple
types of distribution shifts. Finally, we extend our analysis to GPT-4.1 and
DeepSeek V3 to assess frontier models' current robustness to format
perturbations. Our findings offer actionable insights into the relative
effectiveness of these robustness methods, enabling practitioners to make
informed decisions when aiming for stable and reliable LLM performance in
real-world applications. Code:
https://github.com/AIRI-Institute/when-punctuation-matters.

</details>


### [124] [Retrieval-augmented reasoning with lean language models](https://arxiv.org/abs/2508.11386)
*Ryan Sze-Yin Chan,Federico Nanni,Tomas Lazauskas,Rosie Wood,Penelope Yong,Lionel Tarassenko,Mark Girolami,James Geddes,Andrew Duncan*

Main category: cs.CL

TL;DR: 本报告提出了一种在轻量级语言模型中结合推理和检索增强生成（RAG）的新方法，使用Qwen2.5-Instruct模型和密集检索器，通过领域特定微调提高了回答的准确性和一致性，适用于资源受限环境的本地部署。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决现有RAG系统依赖大型模型和外部API的问题，满足在资源受限或安全环境中部署高性能、保护隐私的解决方案的需求。

Method: 本研究结合了推理和检索增强生成（RAG）到一个轻量级语言模型架构中，集成了密集检索器和经过微调的Qwen2.5-Instruct模型，并利用了来自前沿模型（如DeepSeek-R1）的合成查询生成和推理轨迹，处理了NHS A-Z 状况页面这一特定语料库。研究还探索了基于摘要的文档压缩、合成数据设计以及面向推理的微调对模型性能的影响。

Result: 实验结果表明，与非推理和通用轻量级模型相比，该领域特定的微调方法在答案准确性和一致性方面表现出显著的优势，性能接近前沿模型，并且易于本地部署。

Conclusion: 该研究通过领域特定的微调方法，在答案准确性和一致性方面取得了显著的性能提升，接近了前沿模型的水平，同时适用于本地部署。

Abstract: This technical report details a novel approach to combining reasoning and
retrieval augmented generation (RAG) within a single, lean language model
architecture. While existing RAG systems typically rely on large-scale models
and external APIs, our work addresses the increasing demand for performant and
privacy-preserving solutions deployable in resource-constrained or secure
environments. Building on recent developments in test-time scaling and
small-scale reasoning models, we develop a retrieval augmented conversational
agent capable of interpreting complex, domain-specific queries using a
lightweight backbone model. Our system integrates a dense retriever with
fine-tuned Qwen2.5-Instruct models, using synthetic query generation and
reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a
curated corpus, in this case, the NHS A-to-Z condition pages. We explore the
impact of summarisation-based document compression, synthetic data design, and
reasoning-aware fine-tuning on model performance. Evaluation against both
non-reasoning and general-purpose lean models demonstrates that our
domain-specific fine-tuning approach yields substantial gains in answer
accuracy and consistency, approaching frontier-level performance while
remaining feasible for local deployment. All implementation details and code
are publicly released to support reproducibility and adaptation across domains.

</details>


### [125] [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://arxiv.org/abs/2508.11388)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 提出了一种新的基于梯度遮挡的方法，用于为神经网络预测生成抽取式解释，满足充分性、完备性和紧凑性，并成功应用于图像和文本。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络在自然语言处理和计算机视觉等领域取得快速进展，对这些黑盒模型预测进行解释的需求日益增长。

Method: 提出了一种新的抽取式解释生成方法，该方法基于遮挡输入中模型不认为是指示性的部分。遮挡过程通过基于梯度的优化和一种新的正则化方案实现，该方案强制执行充分性、完备性和紧凑性。

Result: 该方法不仅适用于自然语言处理，还成功应用于图像输入，为图像分类生成高质量的解释，表明所提出的用于自然语言处理的推理提取条件更广泛地适用于不同类型的输入。

Conclusion: 本研究提出的基于梯度的遮挡方法，结合了新的正则化方案，能够生成满足充分性、完备性和紧凑性原则的抽取式解释，证明了无需训练专用模型，仅基于已训练分类器即可实现 لهذه 属性。

Abstract: Concurrent to the rapid progress in the development of neural-network based
models in areas like natural language processing and computer vision, the need
for creating explanations for the predictions of these black-box models has
risen steadily. We propose a new method to generate extractive explanations for
predictions made by neural networks, that is based on masking parts of the
input which the model does not consider to be indicative of the respective
class. The masking is done using gradient-based optimization combined with a
new regularization scheme that enforces sufficiency, comprehensiveness and
compactness of the generated explanation, three properties that are known to be
desirable from the related field of rationale extraction in natural language
processing. In this way, we bridge the gap between model interpretability and
rationale extraction, thereby proving that the latter of which can be performed
without training a specialized model, only on the basis of a trained
classifier. We further apply the same method to image inputs and obtain high
quality explanations for image classifications, which indicates that the
conditions proposed for rationale extraction in natural language processing are
more broadly applicable to different input types.

</details>


### [126] [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://arxiv.org/abs/2508.11393)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

TL;DR: A new training method for rationalized transformers makes them more stable and better aligned with human judgments by using a single model instead of three, without needing extra labeled data.


<details>
  <summary>Details</summary>
Motivation: To address the training instabilities common in existing rationalized model approaches and to improve the alignment of rationales with human annotations without explicit supervision.

Method: An end-to-end differentiable training paradigm for stable training of a rationalized transformer classifier, simplifying the traditional three-player-game into a single model that performs classification and token scoring. Incorporates advances in parameterizing and regularizing rationales.

Result: A single model that simultaneously classifies samples and scores input tokens based on relevance, achieving substantially improved and state-of-the-art alignment with human annotations.

Conclusion: The proposed approach simplifies the three-player-game for training rationalized models into a single model, leading to more efficient training and improved stability. It also extends to produce class-wise rationales with state-of-the-art alignment to human annotations without explicit supervision.

Abstract: We propose an end-to-end differentiable training paradigm for stable training
of a rationalized transformer classifier. Our approach results in a single
model that simultaneously classifies a sample and scores input tokens based on
their relevance to the classification. To this end, we build on the widely-used
three-player-game for training rationalized models, which typically relies on
training a rationale selector, a classifier and a complement classifier. We
simplify this approach by making a single model fulfill all three roles,
leading to a more efficient training paradigm that is not susceptible to the
common training instabilities that plague existing approaches. Further, we
extend this paradigm to produce class-wise rationales while incorporating
recent advances in parameterizing and regularizing the resulting rationales,
thus leading to substantially improved and state-of-the-art alignment with
human annotations without any explicit supervision.

</details>


### [127] [Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions](https://arxiv.org/abs/2508.11414)
*Shangrui Nie,Florian Mai,David Kaczér,Charles Welch,Zhixue Zhao,Lucie Flek*

Main category: cs.CL

TL;DR: 微调LLM以回答价值调查问题可以改变其在调查和下游任务中的行为。


<details>
  <summary>Details</summary>
Motivation: 为了在不依赖大量训练数据的情况下，有效地引导大型语言模型（LLM）以符合人类价值观的方式行事，本研究探索了一种简单的方法：通过训练模型回答价值调查问题来修改其价值体系。

Method: 研究人员首先通过让几个开源LLM对跨越20种不同人类价值观的相关描述进行评分来构建它们的价值画像，并将其用作后续实验的基线。然后，他们研究了通过在价值调查上进行微调来控制模型价值体系的可能性。研究通过评估模型在模型内部的（领域内、保留的调查问题）和模型外部的（情景化道德判断数据集和基于Reddit帖子的文本冒险游戏）行为变化来评估微调的效果。

Result: 研究表明，通过在价值调查问题上进行微调，不仅可以改变模型在领域内调查问题上的回答，还能在隐性的下游任务行为中产生显著的价值对齐变化。

Conclusion: 通过在价值调查问题上进行微调，可以有效地改变大型语言模型（LLM）的价值体系，并对其下游行为产生显著影响。

Abstract: Large language models implicitly encode preferences over human values, yet
steering them often requires large training data. In this work, we investigate
a simple approach: Can we reliably modify a model's value system in downstream
behavior by training it to answer value survey questions accordingly? We first
construct value profiles of several open-source LLMs by asking them to rate a
series of value-related descriptions spanning 20 distinct human values, which
we use as a baseline for subsequent experiments. We then investigate whether
the value system of a model can be governed by fine-tuning on the value
surveys. We evaluate the effect of finetuning on the model's behavior in two
ways; first, we assess how answers change on in-domain, held-out survey
questions. Second, we evaluate whether the model's behavior changes in
out-of-domain settings (situational scenarios). To this end, we construct a
contextualized moral judgment dataset based on Reddit posts and evaluate
changes in the model's behavior in text-based adventure games. We demonstrate
that our simple approach can not only change the model's answers to in-domain
survey questions, but also produces substantial shifts (value alignment) in
implicit downstream task behavior.

</details>


### [128] [HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor](https://arxiv.org/abs/2508.11429)
*Shivam Dubey*

Main category: cs.CL

TL;DR: HumorPlanSearch通过结合规划、文化推理、知识图谱、新颖性过滤和迭代修订，在自动化幽默生成中明确地对上下文进行建模，从而生成更具适应性和文化意识的笑话，并在评估中获得更高的幽默生成分数（HGS）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的自动化幽默生成通常会产生通用、重复或不合时宜的笑话，因为幽默是根植于情境的，并且取决于听众的文化背景、心态和即时背景。

Method: HumorPlanSearch是一个模块化管道，通过以下方式显式地模拟上下文：(1) Plan-Search用于多样化、面向主题的策略；(2) 幽默思维链（HuCoT）模板捕捉文化和风格推理；(3) 知识图谱用于检索和适应高性能的历史策略；(4) 通过语义嵌入进行新颖性过滤；(5) 迭代的、由裁判驱动的修订循环。

Result: 在九个主题的实验中，我们的完整管道（KG + Revision）将平均HGS比强基线提高了15.4%（p < 0.05）。

Conclusion: HumorPlanSearch通过在从策略规划到多信号评估的每个阶段优先考虑上下文，将人工智能驱动的幽默推向更连贯、更适应和更具文化意识的喜剧。

Abstract: Automated humor generation with Large Language Models (LLMs) often yields
jokes that feel generic, repetitive, or tone-deaf because humor is deeply
situated and hinges on the listener's cultural background, mindset, and
immediate context. We introduce HumorPlanSearch, a modular pipeline that
explicitly models context through: (1) Plan-Search for diverse, topic-tailored
strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and
stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt
high-performing historical strategies; (4) novelty filtering via semantic
embeddings; and (5) an iterative judge-driven revision loop. To evaluate
context sensitivity and comedic quality, we propose the Humor Generation Score
(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,
and topic relevance. In experiments across nine topics with feedback from 13
human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent
(p < 0.05) over a strong baseline. By foregrounding context at every stage from
strategy planning to multi-signal evaluation, HumorPlanSearch advances
AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.

</details>


### [129] [Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse](https://arxiv.org/abs/2508.11434)
*Aditi Dutta,Susan Banducci*

Main category: cs.CL

TL;DR: 大型语言模型在识别和分类网络反性别歧视言论方面存在困难，常常将其误判为有害内容，尤其是在政治敏感时期，这可能导致压制边缘化群体的声音。研究建议改进审核系统设计，纳入人工审核和包含反击性言论的训练数据。


<details>
  <summary>Details</summary>
Motivation: 在线民主辩论中，反性别歧视言论至关重要，但现有的大型语言模型（LLMs）在区分反性别歧视言论和它所抵制的性别歧视方面可能存在困难。本研究旨在解决这一问题。

Method: 本研究通过分析五个大型语言模型（LLMs）对2022年英国涉及女性议员的政治推文进行分类，考察模型如何区分性别歧视、反性别歧视和中性推文，特别关注高敏感度触发事件。

Result: 研究结果表明，模型经常错误地将反性别歧视言论分类为有害内容，尤其是在政治性强的事件中，此时有害言论和抵抗言论的修辞风格趋于一致。

Conclusion: 自动化内容审核系统在区分反性别歧视言论和性别歧视言论时存在挑战，特别是在政治敏感事件中。现有模型频繁将反性别歧视言论错误分类为有害内容，这可能压制挑战性别歧视的声音，对边缘化群体产生不成比例的影响。因此，审核系统的设计需要超越二元分类，整合人工审核，并明确包含反击性言论的训练数据。

Abstract: Anti-sexist speech, i.e., public expressions that challenge or resist
gendered abuse and sexism, plays a vital role in shaping democratic debate
online. Yet automated content moderation systems, increasingly powered by large
language models (LLMs), may struggle to distinguish such resistance from the
sexism it opposes. This study examines how five LLMs classify sexist,
anti-sexist, and neutral political tweets from the UK, focusing on
high-salience trigger events involving female Members of Parliament in the year
2022. Our analysis show that models frequently misclassify anti-sexist speech
as harmful, particularly during politically charged events where rhetorical
styles of harm and resistance converge. These errors risk silencing those who
challenge sexism, with disproportionate consequences for marginalised voices.
We argue that moderation design must move beyond binary harmful/not-harmful
schemas, integrate human-in-the-loop review during sensitive events, and
explicitly include counter-speech in training data. By linking feminist
scholarship, event-based analysis, and model evaluation, this work highlights
the sociotechnical challenges of safeguarding resistance speech in digital
political spaces.

</details>


### [130] [CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity](https://arxiv.org/abs/2508.11442)
*Bowen Zhang,Zixin Song,Chunquan Chen,Qian-Wen Zhang,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: CoDiEmb框架通过创新的训练策略和融合方法，解决了在信息检索和语义文本相似性任务之间进行联合训练时常见的性能权衡问题，并在多个基准测试中取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 学习统一的文本嵌入以适应多样化的下游任务是一个核心目标，但负迁移（negative transfer）是一个持续存在的问题，尤其是在联合训练用于信息检索（IR）和语义文本相似性（STS）的单一编码器时，这通常会导致性能权衡。

Method: CoDiEmb框架整合了任务专业化目标、动态采样器、对比损失、跨设备采样、感知顺序目标和delta-guided模型融合策略，实现了IR和STS任务的有效联合优化。

Result: CoDiEmb在15个标准的IR和STS基准测试中进行了广泛实验，结果表明该框架不仅减轻了跨任务的权衡，还可衡量地改善了嵌入空间的几何特性。

Conclusion: CoDiEmb框架通过解耦任务特定学习信号、采用delta-guided模型融合策略和高效的单阶段训练流程，成功地缓解了跨任务的权衡，并改善了嵌入空间的几何特性。

Abstract: Learning unified text embeddings that excel across diverse downstream tasks
is a central goal in representation learning, yet negative transfer remains a
persistent obstacle. This challenge is particularly pronounced when jointly
training a single encoder for Information Retrieval (IR) and Semantic Textual
Similarity (STS), two essential but fundamentally disparate tasks for which
naive co-training typically yields steep performance trade-offs. We argue that
resolving this conflict requires systematically decoupling task-specific
learning signals throughout the training pipeline. To this end, we introduce
CoDiEmb, a unified framework that reconciles the divergent requirements of IR
and STS in a collaborative yet distinct manner. CoDiEmb integrates three key
innovations for effective joint optimization: (1) Task-specialized objectives
paired with a dynamic sampler that forms single-task batches and balances
per-task updates, thereby preventing gradient interference. For IR, we employ a
contrastive loss with multiple positives and hard negatives, augmented by
cross-device sampling. For STS, we adopt order-aware objectives that directly
optimize correlation and ranking consistency. (2) A delta-guided model fusion
strategy that computes fine-grained merging weights for checkpoints by
analyzing each parameter's deviation from its pre-trained initialization,
proving more effective than traditional Model Soups. (3) An efficient,
single-stage training pipeline that is simple to implement and converges
stably. Extensive experiments on 15 standard IR and STS benchmarks across three
base encoders validate CoDiEmb. Our results and analysis demonstrate that the
framework not only mitigates cross-task trade-offs but also measurably improves
the geometric properties of the embedding space.

</details>


### [131] [Reference Points in LLM Sentiment Analysis: The Role of Structured Context](https://arxiv.org/abs/2508.11454)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 与自然语言提示相比，使用JSON格式和附加信息的提示可以提高小型语言模型在情感分析任务上的性能，尤其是在资源受限的环境中。


<details>
  <summary>Details</summary>
Motivation: 营销理论，如预期理论和期望-确认理论指出，客户的评价不仅受到实际体验的影响，还受到其他参考点的塑造。因此，本研究旨在探讨这些补充信息的内容和格式如何影响使用LLM的情感分析。

Method: 通过比较自然语言（NL）和JSON格式的提示，并使用适合实际营销应用的轻量级3B参数模型，研究了这些补充信息的内容和格式如何影响使用LLM进行的情感分析。

Result: 在两个Yelp类别（餐厅和夜生活）上的实验表明，带有附加信息的JSON提示在未经微调的情况下优于所有基线：Macro-F1分别提高了1.6%和4%，而RMSE分别降低了16%和9.1%，使其可以在资源受限的边缘设备上部署。此外，后续分析证实，性能提升源于真正的上下文推理，而非标签代理。

Conclusion: 这项工作表明，结构化提示可以使较小的模型获得具有竞争力的性能，为大规模模型部署提供了一种实用的替代方案。

Abstract: Large language models (LLMs) are now widely used across many fields,
including marketing research. Sentiment analysis, in particular, helps firms
understand consumer preferences. While most NLP studies classify sentiment from
review text alone, marketing theories, such as prospect theory and
expectation--disconfirmation theory, point out that customer evaluations are
shaped not only by the actual experience but also by additional reference
points. This study therefore investigates how the content and format of such
supplementary information affect sentiment analysis using LLMs. We compare
natural language (NL) and JSON-formatted prompts using a lightweight 3B
parameter model suitable for practical marketing applications. Experiments on
two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with
additional information outperforms all baselines without fine-tuning: Macro-F1
rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it
deployable in resource-constrained edge devices. Furthermore, a follow-up
analysis confirms that performance gains stem from genuine contextual reasoning
rather than label proxying. This work demonstrates that structured prompting
can enable smaller models to achieve competitive performance, offering a
practical alternative to large-scale model deployment.

</details>


### [132] [Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models](https://arxiv.org/abs/2508.11534)
*Monika Jotautaitė,Lucius Caviola,David A. Brewster,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）的物种主义偏见。研究发现，LLMs能识别物种主义言论但对其道德评价不高，且在特定情境下优先考虑人类而非动物，尤其是在动物能力不如人类的情况下。模型在处理农场动物的伤害时表现出双重标准。研究认为，LLMs的偏见可能源于对认知能力的侧重，而非单纯的物种歧视。为AI公平性纳入对非人类动物的考量至关重要。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛部署，考察它们的伦理倾向至关重要。基于对人工智能公平和歧视的研究，本研究旨在调查LLMs是否表现出物种主义偏见（基于物种成员的歧视），以及它们如何评价非人类动物。

Method: 本研究采用了三种范式来系统地研究LLMs的物种主义偏见：1. 物种主义基准测试（SpeciesismBench）：一个包含1003个项目的基准，用于评估LLMs识别和道德评价物种主义陈述的能力。2. 心理测量学方法：使用已建立的心理测量学工具，比较LLMs的反应与人类参与者的反应。3. 文本生成任务：通过开放式文本生成任务，探查LLMs在阐述或抵制物种主义合理化方面的表现。

Result: 在物种主义基准测试中，LLMs能够可靠地识别物种主义陈述，但很少谴责它们，并常常认为物种主义态度在道德上是可接受的。在心理测量学研究中，结果好坏参半：LLMs表达的显式物种主义略低于人类，但在直接权衡中，它们更倾向于选择拯救一个人类而不是多个动物。初步解释是，LLMs可能更看重认知能力而非物种本身：当能力相同时，它们不表现出物种偏好；当动物被描述为能力更强时，它们倾向于优先考虑该动物而非能力较弱的人类。在开放式文本生成任务中，LLMs经常为农场动物的伤害辩护或合理化，却拒绝为非农场动物这样做。

Conclusion: LLMs在识别和评估物种主义陈述方面表现出能力，但常常不谴责，并将物种主义态度视为道德上可接受的。在显式评估中，LLMs表现出略低的物种主义倾向，但在直接权衡中，它们更倾向于优先考虑人类。当能力相同时，它们不表现出物种偏好，并且在动物被描述为能力更强时，它们倾向于优先考虑动物而不是能力较弱的人类。在开放式文本生成任务中，LLMs经常正常化或合理化对农场动物的伤害，同时拒绝为非农场动物这样做。这些发现表明，LLMs反映了进步和主流人类观点的混合体，但它们仍然重现了围绕动物剥削的根深蒂固的文化规范。为AI公平和对齐框架纳入非人类道德患者对于减少这些偏见和防止物种主义态度在AI系统和社会中根深蒂固至关重要。

Abstract: As large language models (LLMs) become more widely deployed, it is crucial to
examine their ethical tendencies. Building on research on fairness and
discrimination in AI, we investigate whether LLMs exhibit speciesist bias --
discrimination based on species membership -- and how they value non-human
animals. We systematically examine this issue across three paradigms: (1)
SpeciesismBench, a 1,003-item benchmark assessing recognition and moral
evaluation of speciesist statements; (2) established psychological measures
comparing model responses with those of human participants; (3) text-generation
tasks probing elaboration on, or resistance to, speciesist rationalizations. In
our benchmark, LLMs reliably detected speciesist statements but rarely
condemned them, often treating speciesist attitudes as morally acceptable. On
psychological measures, results were mixed: LLMs expressed slightly lower
explicit speciesism than people, yet in direct trade-offs they more often chose
to save one human over multiple animals. A tentative interpretation is that
LLMs may weight cognitive capacity rather than species per se: when capacities
were equal, they showed no species preference, and when an animal was described
as more capable, they tended to prioritize it over a less capable human. In
open-ended text generation tasks, LLMs frequently normalized or rationalized
harm toward farmed animals while refusing to do so for non-farmed animals.
These findings suggest that while LLMs reflect a mixture of progressive and
mainstream human views, they nonetheless reproduce entrenched cultural norms
around animal exploitation. We argue that expanding AI fairness and alignment
frameworks to explicitly include non-human moral patients is essential for
reducing these biases and preventing the entrenchment of speciesist attitudes
in AI systems and the societies they influence.

</details>


### [133] [Language models align with brain regions that represent concepts across modalities](https://arxiv.org/abs/2508.11536)
*Maria Ryskina,Greta Tuckute,Alexander Fung,Ashley Malkin,Evelina Fedorenko*

Main category: cs.CL

TL;DR: 语言模型可能在内部表示跨模态概念含义，即使在语言处理不敏感的大脑区域也是如此。


<details>
  <summary>Details</summary>
Motivation: 解决认知科学和神经科学中区分语言表征与概念意义表征的挑战，以及语言模型（LMs）中存在的相同问题。

Method: 使用fMRI数据集（Pereira et al., 2018）的实验，将语言模型-大脑对齐与两个神经指标相关联：（1）处理句子时的大脑激活水平，（2）跨输入模态的意义一致性的新测量方法，量化大脑区域如何跨范式（句子、词云、图像）一致地响应相同概念。

Result: 语言-语言模型和语言-视觉模型都能更好地预测大脑中意义更一致区域的信号，即使这些区域对语言处理不敏感。

Conclusion: LM可能在内部表示跨模态概念含义

Abstract: Cognitive science and neuroscience have long faced the challenge of
disentangling representations of language from representations of conceptual
meaning. As the same problem arises in today's language models (LMs), we
investigate the relationship between LM--brain alignment and two neural
metrics: (1) the level of brain activation during processing of sentences,
targeting linguistic processing, and (2) a novel measure of meaning consistency
across input modalities, which quantifies how consistently a brain region
responds to the same concept across paradigms (sentence, word cloud, image)
using an fMRI dataset (Pereira et al., 2018). Our experiments show that both
language-only and language-vision models predict the signal better in more
meaning-consistent areas of the brain, even when these areas are not strongly
sensitive to language processing, suggesting that LMs might internally
represent cross-modal conceptual meaning.

</details>


### [134] [AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment](https://arxiv.org/abs/2508.11567)
*Jinpeng Hu,Ao Wang,Qianqian Xie,Hui Ma,Zhuo Li,Dan Guo*

Main category: cs.CL

TL;DR: 提出了一种用于心理健康评估的多智能体框架，通过模拟临床医生与患者的对话，并利用自适应提问和树状结构记忆来提高信息提取和上下文跟踪能力，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的临床医生方法受到合格专业人员短缺的限制，而现有的自动心理评估方法大多依赖于静态文本分析，无法捕捉动态交互和迭代提问中产生的更深层次和信息更丰富的见解。

Method: 提出了一种多智能体框架，包含负责提问、充分性评估、评分和更新的专门智能体。引入了自适应提问机制，由评估智能体评估用户回应的充分性，以确定是否有必要生成有针对性的后续查询。采用树状结构记忆，根节点编码用户基本信息，子节点根据不同的症状类别和交互轮次组织关键信息，并在交互过程中动态更新。

Result: 实验结果表明，本研究提出的多智能体框架在DAIC-WOZ数据集上实现了比现有方法更好的性能。

Conclusion: 本研究提出的多智能体框架在DAIC-WOZ数据集上的实验结果表明，该方法优于现有方法。

Abstract: Mental health assessment is crucial for early intervention and effective
treatment, yet traditional clinician-based approaches are limited by the
shortage of qualified professionals. Recent advances in artificial intelligence
have sparked growing interest in automated psychological assessment, yet most
existing approaches are constrained by their reliance on static text analysis,
limiting their ability to capture deeper and more informative insights that
emerge through dynamic interaction and iterative questioning. Therefore, in
this paper, we propose a multi-agent framework for mental health evaluation
that simulates clinical doctor-patient dialogues, with specialized agents
assigned to questioning, adequacy evaluation, scoring, and updating. We
introduce an adaptive questioning mechanism in which an evaluation agent
assesses the adequacy of user responses to determine the necessity of
generating targeted follow-up queries to address ambiguity and missing
information. Additionally, we employ a tree-structured memory in which the root
node encodes the user's basic information, while child nodes (e.g., topic and
statement) organize key information according to distinct symptom categories
and interaction turns. This memory is dynamically updated throughout the
interaction to reduce redundant questioning and further enhance the information
extraction and contextual tracking capabilities. Experimental results on the
DAIC-WOZ dataset illustrate the effectiveness of our proposed method, which
achieves better performance than existing approaches.

</details>


### [135] [Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2508.11582)
*Qiguang Chen,Dengyun Peng,Jinhao Liu,HuiKang Su,Jiannan Guan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: DR. SAF框架通过动态调整推理深度来提高LLM的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决长链思想（CoT）方法在复杂推理任务中存在的冗余问题，提高计算效率，并克服现有方法依赖人工定义难度先验的不足。

Method: DR. SAF框架整合了边界自我意识对齐、自适应奖励管理和边界保留机制，使模型能够根据问题复杂度动态评估和调整推理深度。

Result: DR. SAF框架实现了49.27%的响应令牌总数减少，准确性损失极小；令牌效率提高了6.59倍，训练时间缩短了5倍。在极端训练下，DR. SAF在令牌效率方面超越了传统指令模型，准确性提高了16%以上。

Conclusion: DR. SAF框架通过动态调整推理深度，在提高效率的同时保持了准确性，并在实验中实现了显著的性能提升，包括减少响应令牌、提高令牌效率和缩短训练时间。

Abstract: Recent advancements in large language models (LLMs) have greatly improved
their capabilities on complex reasoning tasks through Long Chain-of-Thought
(CoT). However, this approach often results in substantial redundancy,
impairing computational efficiency and causing significant delays in real-time
applications. To improve the efficiency, current methods often rely on
human-defined difficulty priors, which do not align with the LLM's self-awared
difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic
Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to
dynamically assess and adjust their reasoning depth in response to problem
complexity. DR. SAF integrates three key components: Boundary Self-Awareness
Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.
These components allow models to optimize their reasoning processes, balancing
efficiency and accuracy without compromising performance. Our experimental
results demonstrate that DR. SAF achieves a 49.27% reduction in total response
tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain
in token efficiency and a 5x reduction in training time, making it well-suited
to resource-limited settings. During extreme training, DR. SAF can even surpass
traditional instruction-based models in token efficiency with more than 16%
accuracy improvement.

</details>


### [136] [Representing Speech Through Autoregressive Prediction of Cochlear Tokens](https://arxiv.org/abs/2508.11598)
*Greta Tuckute,Klemen Kotar,Evelina Fedorenko,Daniel L. K. Yamins*

Main category: cs.CL

TL;DR: AuriStream是一个受生物启发的两阶段语音模型，通过耳蜗令牌和自回归模型学习语音表示，并在SUPERB任务上表现良好，还能生成和可视化音频。


<details>
  <summary>Details</summary>
Motivation: 受到人类听觉处理层级的启发，引入了一个生物学启发的模型AuriStream，用于通过一个两阶段框架对语音进行编码。

Method: AuriStream首先将原始音频转换为基于人耳耳蜗的时频表示，提取离散的耳蜗令牌。然后，一个自回归序列模型应用于这些耳蜗令牌。

Result: AuriStream学习了有意义的音素和单词表示以及最先进的词汇语义，并在多样化的下游SUPERB语音任务上表现出具有竞争力的性能。此外，AuriStream生成的音频续续可以在频谱图空间中进行可视化，并解码回音频，从而深入了解模型的预测。

Conclusion: AuriStream是一个两阶段的语音表示学习框架，旨在开发更具人类模仿能力的、能高效处理各种语音任务的模型。

Abstract: We introduce AuriStream, a biologically inspired model for encoding speech
via a two-stage framework inspired by the human auditory processing hierarchy.
The first stage transforms raw audio into a time-frequency representation based
on the human cochlea, from which we extract discrete \textbf{cochlear tokens}.
The second stage applies an autoregressive sequence model over the cochlear
tokens. AuriStream learns meaningful phoneme and word representations, and
state-of-the-art lexical semantics. AuriStream shows competitive performance on
diverse downstream SUPERB speech tasks. Complementing AuriStream's strong
representational capabilities, it generates continuations of audio which can be
visualized in a spectrogram space and decoded back into audio, providing
insights into the model's predictions. In summary, we present a two-stage
framework for speech representation learning to advance the development of more
human-like models that efficiently handle a range of speech-based tasks.

</details>


### [137] [Dataset Creation for Visual Entailment using Generative AI](https://arxiv.org/abs/2508.11605)
*Rob Reijtenbach,Suzan Verberne,Gijs Wijnholds*

Main category: cs.CL

TL;DR: 本研究提出并验证了一种新的合成数据集，用于训练视觉蕴含模型。该数据集基于SNLI数据集，利用Stable Diffusion生成图像。实验证明，该合成数据集在保持模型性能方面效果良好，可作为数据稀疏情况下的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉蕴含数据集相对于文本蕴含数据集而言，规模小且数据稀疏，手动创建成本高。本研究旨在创建一个新的合成数据集来解决这个问题。

Method: 利用SNLI数据集的文本作为提示，通过Stable Diffusion生成图像，以构建视觉蕴含的训练数据集。

Result: 在SNLI-VE数据集上的实验显示，使用合成数据训练的模型F分数从0.703下降到0.686；在SICK-VTE数据集上的实验显示，F分数从0.400下降到0.384。这表明合成数据在数据稀疏的情况下是可行的。

Conclusion: 生成的数据集可以作为视觉蕴含模型训练的替代方案，尤其是在数据稀疏的情况下，并且只会在性能上带来微小的下降。

Abstract: In this paper we present and validate a new synthetic dataset for training
visual entailment models. Existing datasets for visual entailment are small and
sparse compared to datasets for textual entailment. Manually creating datasets
is labor-intensive. We base our synthetic dataset on the SNLI dataset for
textual entailment. We take the premise text from SNLI as input prompts in a
generative image model, Stable Diffusion, creating an image to replace each
textual premise. We evaluate our dataset both intrinsically and extrinsically.
For extrinsic evaluation, we evaluate the validity of the generated images by
using them as training data for a visual entailment classifier based on CLIP
feature vectors. We find that synthetic training data only leads to a slight
drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when
trained on real data. We also compare the quality of our generated training
data to original training data on another dataset: SICK-VTE. Again, there is
only a slight drop in F-score: from 0.400 to 0.384. These results indicate that
in settings with data sparsity, synthetic data can be a promising solution for
training visual entailment models.

</details>


### [138] [TinyTim: A Family of Language Models for Divergent Generation](https://arxiv.org/abs/2508.11607)
*Christopher J. Agostino*

Main category: cs.CL

TL;DR: TinyTim 是一个在《芬尼根的守灵夜》上微调的大型语言模型系列，其特点是具有高词汇多样性和低语义连贯性，可作为创造性架构中的发散知识源。


<details>
  <summary>Details</summary>
Motivation: 介绍 TinyTim 模型系列，该系列在 James Joyce 的《芬尼根的守灵夜》上进行了微调。

Method: 通过对 TinyTim V1 进行量化评估，并与基线模型进行对比。

Result: TinyTim V1 具有高词汇多样性和低语义连贯性的统计上不同的生成特征。

Conclusion: TinyTim V1 产生了一个统计上不同的生成特征，具有高词汇多样性和低语义连贯性。这些发现可以通过创造力和复杂问题解决的理论来解释，并认为这种专业模型可以在更广泛的创造性架构中作为发散知识源发挥作用，从而在各种环境中驱动自动发现机制。

Abstract: This work introduces TinyTim, a family of large language models fine-tuned on
James Joyce's `Finnegans Wake'. Through quantitative evaluation against
baseline models, we demonstrate that TinyTim V1 produces a statistically
distinct generative profile characterized by high lexical diversity and low
semantic coherence. These findings are interpreted through theories of
creativity and complex problem-solving, arguing that such specialized models
can function as divergent knowledge sources within more extensive creative
architectures, powering automated discovery mechanisms in diverse settings.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [139] [When Algorithms Mirror Minds: A Confirmation-Aware Social Dynamic Model of Echo Chamber and Homogenization Traps](https://arxiv.org/abs/2508.11516)
*Ming Tang,Xiaowen Huang,Jitao Sang*

Main category: cs.SI

TL;DR: 推荐系统存在回音室和用户同质化问题，由算法和用户行为共同导致。本研究提出的模型解释了这些现象的成因，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决推荐系统日益严重的回音室和用户同质化问题，这些问题源于算法推荐和人类行为之间的动态相互作用。

Method: 提出了一种包含用户心理和社会关系的“确认感知社会动态模型”，以模拟用户和推荐系统之间的实际交互过程。

Result: 理论分析证明了回音室（推荐多样性降低）和同质化陷阱（用户表征同质化）不可避免地会发生。通过在真实和合成数据集上的广泛实证模拟，研究了影响这些现象的根本因素，并展示了四种可以减轻回音室和用户同质化的实用策略，但会牺牲一些推荐准确性。

Conclusion: 该研究提供了关于回音室和用户同质化现象的理论和实证见解，并为以人为中心的新型推荐系统设计提供了可行的指导。

Abstract: Recommender systems increasingly suffer from echo chambers and user
homogenization, systemic distortions arising from the dynamic interplay between
algorithmic recommendations and human behavior. While prior work has studied
these phenomena through the lens of algorithmic bias or social network
structure, we argue that the psychological mechanisms of users and the
closed-loop interaction between users and recommenders are critical yet
understudied drivers of these emergent effects. To bridge this gap, we propose
the Confirmation-Aware Social Dynamic Model which incorporates user psychology
and social relationships to simulate the actual user and recommender
interaction process. Our theoretical analysis proves that echo chambers and
homogenization traps, defined respectively as reduced recommendation diversity
and homogenized user representations, will inevitably occur. We also conduct
extensive empirical simulations on two real-world datasets and one synthetic
dataset with five well-designed metrics, exploring the root factors influencing
the aforementioned phenomena from three level perspectives: the stochasticity
and social integration degree of recommender (system-level), the psychological
mechanisms of users (user-level), and the dataset scale (platform-level).
Furthermore, we demonstrate four practical mitigation strategies that help
alleviate echo chambers and user homogenization at the cost of some
recommendation accuracy. Our findings provide both theoretical and empirical
insights into the emergence and drivers of echo chambers and user
homogenization, as well as actionable guidelines for human-centered recommender
design.

</details>


### [140] [FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning](https://arxiv.org/abs/2508.07264)
*Van Duc Cuong,Ta Dinh Tam,Tran Duc Chinh,Nguyen Thi Hanh*

Main category: cs.SI

TL;DR: FLUID通过令牌蒸馏和专家混合，实现了鲁棒且可扩展的多模态分类，在GLAMI-1M数据集上达到91%的准确率。


<details>
  <summary>Details</summary>
Motivation: 常见的融合策略在处理视觉和文本信号时，容易受到特定模态噪声的影响，鲁棒性较差。本研究提出了一种新的集成方法，以提高跨模态的鲁棒性和可扩展性。

Method: 	extsc{FLUID}采用基于令牌的流水线，通过令牌蒸馏实现专家专业化，以改进跨模态鲁棒性和可扩展性。其核心要素包括：1) Q-transforms，用于从特定模态的骨干网络中提取和保留显著令牌级特征的可学习查询令牌；2) 一个强制跨模态一致性的两阶段融合方案，通过对比对齐和通过门控机制以及选择性压缩信息的Q-bottleneck进行自适应、任务感知融合；3) 一个轻量级的、负载均衡的专家混合（MoE）预测器，以实现对不同语义模式的高效专业化。

Result: FLUID在GLAMI-1M基准测试中达到了91%的准确率，显著优于现有方法，并表现出对标签噪声、长尾类别不平衡和语义异质性的强大韧性。消融研究也证实了所提出组件的单独和协同效益。

Conclusion: FLUID是一种可扩展、抗噪的多模态产品分类解决方案。

Abstract: Multimodal classification requires robust integration of visual and textual
signals, yet common fusion strategies are brittle and vulnerable to
modality-specific noise. In this paper, we present \textsc{FLUID}-Flow-Latent
Unified Integration via Token Distillation for Expert Specialization, a
principled token-level pipeline that improves cross-modal robustness and
scalability. \textsc{FLUID} contributes three core elements: (1)
\emph{Q-transforms}, learnable query tokens that distill and retain salient
token-level features from modality-specific backbones; (2) a two-stage fusion
scheme that enforces cross-modal consistency via contrastive alignment and then
performs adaptive, task-aware fusion through a gating mechanism and a
\emph{Q-bottleneck} that selectively compresses information for downstream
reasoning; and (3) a lightweight, load-balanced Mixture-of-Experts at
prediction time that enables efficient specialization to diverse semantic
patterns. Extensive experiments demonstrate that \textsc{FLUID} attains
\(91\%\) accuracy on the GLAMI-1M benchmark, significantly outperforming prior
baselines and exhibiting strong resilience to label noise, long-tail class
imbalance, and semantic heterogeneity. Targeted ablation studies corroborate
both the individual and synergistic benefits of the proposed components,
positioning \textsc{FLUID} as a scalable, noise-resilient solution for
multimodal product classification.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [141] [RAG for Geoscience: What We Expect, Gaps and Opportunities](https://arxiv.org/abs/2508.11246)
*Runlong Yu,Shiyuan Luo,Rahul Ghosh,Lingyao Li,Yiqun Xie,Xiaowei Jia*

Main category: cs.ET

TL;DR: Geo-RAG 扩展了 RAG，使其能够处理地学任务中的多模态数据，并包含推理和验证步骤，以实现更可信的工作流程。


<details>
  <summary>Details</summary>
Motivation: 当前以文本为中心、'检索后生成'的工作流程不适用于需要多模态证据的地学任务，例如使用模拟场景填补缺失观测值、检索方程和参数以校准模型、根据视觉线索对地理位置进行现场照片定位或汇总历史案例研究以支持政策分析。

Method: Geo-RAG 被设想为一个模块化的“检索 → 推理 → 生成 → 验证”循环，支持多模态地球数据检索、物理和领域约束推理、科学级产物生成以及生成假设验证。

Result: Geo-RAG 旨在增强地学任务中检索增强生成（RAG）的应用，克服了当前 RAG 的局限性，使其能够处理多模态数据并进行推理和验证。

Conclusion: Geo-RAG通过支持多模态数据检索、物理和领域约束推理、科学级产物生成以及针对数值模型、地面测量和专家评估的生成假设验证，开辟了更值得信赖和透明的地学工作流程的新机遇。

Abstract: Retrieval-Augmented Generation (RAG) enhances language models by combining
retrieval with generation. However, its current workflow remains largely
text-centric, limiting its applicability in geoscience. Many geoscientific
tasks are inherently evidence-hungry. Typical examples involve imputing missing
observations using analog scenes, retrieving equations and parameters to
calibrate models, geolocating field photos based on visual cues, or surfacing
historical case studies to support policy analyses. A simple
``retrieve-then-generate'' pipeline is insufficient for these needs. We
envision Geo-RAG, a next-generation paradigm that reimagines RAG as a modular
retrieve $\rightarrow$ reason $\rightarrow$ generate $\rightarrow$ verify loop.
Geo-RAG supports four core capabilities: (i) retrieval of multi-modal Earth
data; (ii) reasoning under physical and domain constraints; (iii) generation of
science-grade artifacts; and (iv) verification of generated hypotheses against
numerical models, ground measurements, and expert assessments. This shift opens
new opportunities for more trustworthy and transparent geoscience workflows.

</details>


### [142] [Banking 2.0: The Stablecoin Banking Revolution -- How Digital Assets Are Reshaping Global Finance](https://arxiv.org/abs/2508.11395)
*Kevin McNamara,Rhea Pritham Marpu*

Main category: cs.ET

TL;DR: 稳定币是银行业自金本位废除以来最重要的演进，有望通过融合加密货币和传统金融来推动“银行 2.0”。它解决了法定货币的漏洞，并得到了美国立法和主要金融机构（如摩根大通和 PayPal）的支持，有潜力解决宏观经济失衡问题，并为更互联的国际金融体系铺平道路。


<details>
  <summary>Details</summary>
Motivation: 全球金融体系正处于一个关键的转折点，稳定币作为自金本位废除以来银行业最重要的演进，有望通过无缝融合加密货币创新与传统金融基础设施来推动“银行 2.0”的发展。

Method: 本文综合分析了现实世界中的案例、当前市场数据以及对其变革潜力的分析。

Result: 稳定币的广泛实施通过更稳健、更多样化的支持机制，解决了关键的宏观经济失衡问题，特别是现代货币体系中存在的通胀-生产率缺口。此外，稳定币还有助于放松管制和提高效率，为更具互联性的国际金融体系铺平道路。

Conclusion: 稳定币通过增强稳定性、降低欺诈风险和统一的全球交易，解决了现代法定货币的漏洞，并有望实现

Abstract: The global financial system stands at an inflection point. Stablecoins
represent the most significant evolution in banking since the abandonment of
the gold standard, positioned to enable "Banking 2.0" by seamlessly integrating
cryptocurrency innovation with traditional finance infrastructure. This
transformation rivals artificial intelligence as the next major disruptor in
the financial sector. Modern fiat currencies derive value entirely from
institutional trust rather than physical backing, creating vulnerabilities that
stablecoins address through enhanced stability, reduced fraud risk, and unified
global transactions that transcend national boundaries. Recent developments
demonstrate accelerating institutional adoption: landmark U.S. legislation
including the GENIUS Act of 2025, strategic industry pivots from major players
like JPMorgan's crypto-backed loan initiatives, and PayPal's comprehensive "Pay
with Crypto" service. Widespread stablecoin implementation addresses critical
macroeconomic imbalances, particularly the inflation-productivity gap plaguing
modern monetary systems, through more robust and diversified backing
mechanisms. Furthermore, stablecoins facilitate deregulation and efficiency
gains, paving the way for a more interconnected international financial system.
This whitepaper comprehensively explores how stablecoins are poised to reshape
banking, supported by real-world examples, current market data, and analysis of
their transformative potential.

</details>


### [143] [Open Questions about Time and Self-reference in Living Systems](https://arxiv.org/abs/2508.11423)
*Samson Abramsky,Wolfgang Banzhaf,Leo S. D. Caves,Michael Levin,Penousal Machado,Charles Ofria,Susan Stepney,Roger White*

Main category: cs.ET

TL;DR: Living systems are active, self-referential, and self-modifying, posing challenges for conventional scientific approaches. This paper introduces 'natural time' and 'representational time' to explain how these systems function. It suggests new modeling frameworks like domain theory and co-algebra are needed to understand life\


<details>
  <summary>Details</summary>
Motivation: living systems exhibit a range of fundamental characteristics: they are active, self-referential, self-modifying systems. This paper explores how these characteristics create challenges for conventional scientific approaches and why they require new theoretical and formal frameworks.

Method: introduce a distinction between \

Result: living systems navigate the apparent contradictions arising from self-reference as natural time unwinds self-referential loops into developmental spirals. Conventional mathematical and computational formalisms struggle to model self-referential and self-modifying systems without running into paradox. We identify promising new directions for modelling self-referential systems, including domain theory, co-algebra, genetic programming, and self-modifying algorithms.

Conclusion: self-reference and self-modification are core features of living systems that must be modelled to understand life\

Abstract: Living systems exhibit a range of fundamental characteristics: they are
active, self-referential, self-modifying systems. This paper explores how these
characteristics create challenges for conventional scientific approaches and
why they require new theoretical and formal frameworks. We introduce a
distinction between 'natural time', the continuing present of physical
processes, and 'representational time', with its framework of past, present and
future that emerges with life itself. Representational time enables memory,
learning and prediction, functions of living systems essential for their
survival. Through examples from evolution, embryogenesis and metamorphosis we
show how living systems navigate the apparent contradictions arising from
self-reference as natural time unwinds self-referential loops into
developmental spirals. Conventional mathematical and computational formalisms
struggle to model self-referential and self-modifying systems without running
into paradox. We identify promising new directions for modelling
self-referential systems, including domain theory, co-algebra, genetic
programming, and self-modifying algorithms. There are broad implications for
biology, cognitive science and social sciences, because self-reference and
self-modification are not problems to be avoided but core features of living
systems that must be modelled to understand life's open-ended creativity.

</details>


### [144] [CoMoNM: A Cost Modeling Framework for Compute-Near-Memory Systems](https://arxiv.org/abs/2508.11451)
*Hamid Farzaneh,Asif Ali Khan,Jeronimo Castrillon*

Main category: cs.ET

TL;DR: CoMoNM is a fast and accurate cost modeling framework for CNM systems that helps automate compiler optimizations by estimating execution time, reducing reliance on slow simulations.


<details>
  <summary>Details</summary>
Motivation: Automating optimization decisions in Compute-Near-Memory (CNM) systems is challenging due to unique hardware and programming models, and the tediousness of exploring the optimization space, especially when simulations are time-consuming.

Method: CoMoNM, a generic cost modeling framework for CNM systems, estimates execution time using a high-level application representation, target system specifications, and a mapping specification.

Result: Evaluation on benchmarks shows CoMoNM achieves low estimation errors (within 7.80% and 2.99%) and provides estimates significantly faster (seven orders of magnitude) than existing simulators.

Conclusion: CoMoNM can be integrated into CNM compilers to improve offloading decisions, with estimation errors within 7.80% and 2.99% compared to real systems/simulators, and is seven orders of magnitude faster.

Abstract: Compute-Near-Memory (CNM) systems offer a promising approach to mitigate the
von Neumann bottleneck by bringing computational units closer to data. However,
optimizing for these architectures remains challenging due to their unique
hardware and programming models. Existing CNM compilers often rely on manual
programmer annotations for offloading and optimizations. Automating these
decisions by exploring the optimization space, common in CPU/GPU systems, is
difficult for CNMs as constructing and navigating the transformation space is
tedious and time consuming. This is particularly the case during system-level
design, where evaluation requires time-consuming simulations. To address this,
we present CoMoNM, a generic cost modeling framework for CNM systems for
execution time estimation in milliseconds. It takes a high-level,
hardware-agnostic application representation, target system specifications, and
a mapping specification as input and estimates the execution time for the given
application on the target CNM system. We show how CoMoNM can be seamlessly
integrated into state-of-the-art CNM compilers, providing improved offloading
decisions. Evaluation on established benchmarks for CNM shows estimation errors
within 7.80% and 2.99%, when compared to the real UPMEM CNM system and
Samsung's HBM-PIM simulator. Notably, CoMoNM delivers estimates seven orders of
magnitude faster compared to the UPMEM and HBM-PIM simulators.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [145] [LayoutRectifier: An Optimization-based Post-processing for Graphic Design Layout Generation](https://arxiv.org/abs/2508.11177)
*I-Chao Shen,Ariel Shamir,Takeo Igarashi*

Main category: cs.GR

TL;DR: A new method called LayoutRectifier fixes common flaws in AI-generated graphic designs like misalignment and overlaps using a two-stage optimization process based on grid systems and a novel box containment function. It improves design quality without retraining.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning methods for generating graphic design layouts often produce flaws such as misalignment, unwanted overlaps, and unsatisfied containment. There is a need to rectify these auto-generated layouts to improve their quality and suitability for graphic design tasks.

Method: LayoutRectifier is an optimization-based method that uses a two-stage optimization process. Stage one utilizes grid systems for discrete search to mitigate misalignments. Stage two introduces a novel box containment function to adjust element positions and sizes, preventing overlaps and promoting containment.

Result: LayoutRectifier was evaluated on content-agnostic and content-aware layout generation tasks, achieving better-quality layouts with fewer flaws compared to existing methods. The rectified layouts are more suitable for downstream graphic design tasks.

Conclusion: LayoutRectifier can improve the quality of auto-generated graphic design layouts by reducing flaws like misalignment, unwanted overlaps, and unsatisfied containment, while minimizing deviation from the original layout. It achieves better-quality layouts suitable for downstream tasks and complements existing methods without requiring additional training.

Abstract: Recent deep learning methods can generate diverse graphic design layouts
efficiently. However, these methods often create layouts with flaws, such as
misalignment, unwanted overlaps, and unsatisfied containment. To tackle this
issue, we propose an optimization-based method called LayoutRectifier, which
gracefully rectifies auto-generated graphic design layouts to reduce these
flaws while minimizing deviation from the generated layout. The core of our
method is a two-stage optimization. First, we utilize grid systems, which
professional designers commonly use to organize elements, to mitigate
misalignments through discrete search. Second, we introduce a novel box
containment function designed to adjust the positions and sizes of the layout
elements, preventing unwanted overlapping and promoting desired containment. We
evaluate our method on content-agnostic and content-aware layout generation
tasks and achieve better-quality layouts that are more suitable for downstream
graphic design tasks. Our method complements learning-based layout generation
methods and does not require additional training.

</details>


### [146] [StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation](https://arxiv.org/abs/2508.11203)
*Seungmi Lee,Kwan Yun,Junyong Noh*

Main category: cs.GR

TL;DR: StyleMM 是一个新框架，可根据文本描述构建风格化 3DMM，保持身份属性，并提供对形状、表情和纹理的控制。


<details>
  <summary>Details</summary>
Motivation: 旨在构建一个可以根据用户定义的文本描述来构建风格化 3DMM 的框架，以实现对人脸风格的控制。

Method: StyleMM 通过微调预训练的网格变形网络和纹理生成器来构建风格化的 3DMM。它使用文本到图像的翻译来生成风格化的面部图像，并引入了一种保留面部属性的风格化方法，以确保身份的一致性。

Result: StyleMM 在身份级别的人脸多样性和风格化能力方面优于最先进的方法。

Conclusion: StyleMM 能够生成具有风格化人脸的 3DMM，能够保持身份、面部对齐和表情，同时提供对形状、表情和纹理的显式控制。

Abstract: We introduce StyleMM, a novel framework that can construct a stylized 3D
Morphable Model (3DMM) based on user-defined text descriptions specifying a
target style. Building upon a pre-trained mesh deformation network and a
texture generator for original 3DMM-based realistic human faces, our approach
fine-tunes these models using stylized facial images generated via text-guided
image-to-image (i2i) translation with a diffusion model, which serve as
stylization targets for the rendered mesh. To prevent undesired changes in
identity, facial alignment, or expressions during i2i translation, we introduce
a stylization method that explicitly preserves the facial attributes of the
source image. By maintaining these critical attributes during image
stylization, the proposed approach ensures consistent 3D style transfer across
the 3DMM parameter space through image-based training. Once trained, StyleMM
enables feed-forward generation of stylized face meshes with explicit control
over shape, expression, and texture parameters, producing meshes with
consistent vertex connectivity and animatability. Quantitative and qualitative
evaluations demonstrate that our approach outperforms state-of-the-art methods
in terms of identity-level facial diversity and stylization capability. The
code and videos are available at
[kwanyun.github.io/stylemm_page](kwanyun.github.io/stylemm_page).

</details>


### [147] [SPG: Style-Prompting Guidance for Style-Specific Content Creation](https://arxiv.org/abs/2508.11476)
*Qian Liang,Zichong Chen,Yang Zhou,Hui Huang*

Main category: cs.GR

TL;DR: SPG是一种用于文本到图像生成的新型采样策略，可以通过风格噪声向量实现对生成图像风格的精确控制，同时保持语义准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像（T2I）扩散模型在根据文本提示生成图像方面表现出色，但控制生成图像的视觉风格仍然是一个挑战。

Method: SPG通过构建风格噪声向量，并利用其与无条件噪声的方向偏差来指导扩散过程，使其朝着目标风格分布进行。该方法简单、稳健，并能与ControlNet和IPAdapter等可控框架兼容。

Result: SPG与Classifier-Free Guidance（CFG）相结合，实现了语义保真度和风格一致性。实验证明了该方法相对于最先进方法的有效性和通用性。

Conclusion: Style-Prompting Guidance (SPG)是一种新颖的采样策略，能够实现特定风格的图像生成，同时保持语义保真度和风格一致性。

Abstract: Although recent text-to-image (T2I) diffusion models excel at aligning
generated images with textual prompts, controlling the visual style of the
output remains a challenging task. In this work, we propose Style-Prompting
Guidance (SPG), a novel sampling strategy for style-specific image generation.
SPG constructs a style noise vector and leverages its directional deviation
from unconditional noise to guide the diffusion process toward the target style
distribution. By integrating SPG with Classifier-Free Guidance (CFG), our
method achieves both semantic fidelity and style consistency. SPG is simple,
robust, and compatible with controllable frameworks like ControlNet and
IPAdapter, making it practical and widely applicable. Extensive experiments
demonstrate the effectiveness and generality of our approach compared to
state-of-the-art methods. Code is available at
https://github.com/Rumbling281441/SPG.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [148] [High-contrast double Bragg interferometry via detuning control](https://arxiv.org/abs/2508.10968)
*Rui Li,V. J. Martínez-Lahuerta,Naceur Gaaloul,Klemens Hammerer*

Main category: quant-ph

TL;DR: 提出了一种新的激光失谐控制策略，用于提高在加速度条件下运行的原子干涉仪的对比度，其中最优控制理论（OCT）策略效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了提高在外部加速度条件下运行的马赫-曾德尔原子干涉仪的对比度，并减少微分多普勒频移和实验误差。

Method: 通过数值模拟和五能级S矩阵模型评估了四种失谐控制策略（常规双布拉格衍射、恒定失谐、线性失谐扫描和结合失谐扫描与最优控制理论的混合方案），以减少微分多普勒频移和实验误差。

Result: 最优控制理论（OCT）策略在实际条件下表现出最高的鲁棒性，对比度保持在95%以上；线性失谐扫描（DS-DBD）策略对于准直良好的玻色-爱因斯坦凝聚体，对比度可保持在90%以上。

Conclusion: 所提出的方案为高对比度马赫-曾德尔原子干涉仪的设计提供了实用的方法，特别是在外部加速度条件下，该方法能够通过优化激光失谐控制来提高精密量子传感和基础物理学测试的性能。

Abstract: We propose high-contrast Mach-Zehnder atom interferometers based on double
Bragg diffraction (DBD) operating under external acceleration. To mitigate
differential Doppler shifts and experimental imperfections, we introduce a
tri-frequency laser scheme with dynamic detuning control. We evaluate four
detuning-control strategies&mdash;conventional DBD, constant detuning, linear
detuning sweep (DS-DBD), and a hybrid protocol combining detuning sweep with
optimal control theory (OCT)&mdash;using exact numerical simulations and a
five-level S-matrix model. The OCT strategy provides the highest robustness,
maintaining contrast above 95\% under realistic conditions, while the DS-DBD
strategy sustains contrast above 90\% for well-collimated Bose-Einstein
condensates. These results offer practical pathways to enhancing DBD-based
interferometers for precision quantum sensing and fundamental physics tests.

</details>


### [149] [Generation of frequency-bin-encoded dual-rail cluster states via time-frequency multiplexing of microwave photonic qubits](https://arxiv.org/abs/2508.10990)
*Zhiling Wang,Takeaki Miyamura,Yoshiki Sunada,Keika Sunada,Jesper Ilves,Kohei Matsuura,Yasunobu Nakamura*

Main category: quant-ph

TL;DR: 使用超导电路和时频复用技术生成频率-比特双轨编码的双轨集群态，实现了超过50%的保真度和长链纠缠，并证明了该编码相比单轨方案具有更好的抗光子损耗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 集群态在量子计量和单向量子计算等领域有广泛应用。

Method: 利用包含固定频率超导量子比特、谐振器和Purcell滤波器的超导电路，通过顺序发射不同频率的微波光子来实现时频复用，采用频率-比特双轨编码实现基于光子占有率的擦除检测。

Result: 实现了由多达四个逻辑量子比特组成的集群态，保真度超过50%；局域化纠缠可跨越多达七个逻辑量子比特链；在剔除擦除错误后，保真度对多达八个逻辑量子比特的集群态超过50%，纠缠可跨越多达十一个逻辑量子比特链。

Conclusion: 该研究为高维纠缠态生成和微波域光量子信息处理提供了一条可扩展的途径。

Abstract: Cluster states are a class of multi-qubit entangled states with broad
applications such as quantum metrology and one-way quantum computing. Here, we
present a protocol to generate frequency-bin-encoded dual-rail cluster states
using a superconducting circuit consisting of a fixed-frequency transmon qubit,
a resonator and a Purcell filter. We implement time-frequency multiplexing by
sequentially emitting co-propagating microwave photons of distinct frequencies.
The frequency-bin dual-rail encoding enables erasure detection based on photon
occupancy. We characterize the state fidelity using quantum tomography and
quantify the multipartite entanglement using the metric of localizable
entanglement. Our implementation achieves a state fidelity exceeding 50$\%$ for
a cluster state consisting of up to four logical qubits. The localizable
entanglement remains across chains of up to seven logical qubits. After
discarding the erasure errors, the fidelity exceeds 50% for states with up to
eight logical qubits, and the entanglement persists across chains of up to
eleven qubits. These results highlight the improved robustness of frequency-bin
dual-rail encoding against photon loss compared to conventional single-rail
schemes. This work provides a scalable pathway toward high-dimensional
entangled state generation and photonic quantum information processing in the
microwave domain.

</details>


### [150] [Reliable high-accuracy error mitigation for utility-scale quantum circuits](https://arxiv.org/abs/2508.10997)
*Dorit Aharonov,Ori Alberton,Itai Arad,Yosi Atia,Eyal Bairey,Matan Ben Dov,Asaf Berkovitch,Zvika Brakerski,Itsik Cohen,Eran Fuchs,Omri Golan,Or Golan,Barak D. Gur,Ilya Gurwich,Avieli Haber,Rotem Haber,Dorri Halbertal,Yaron Itkin,Barak A. Katzir,Oded Kenneth,Shlomi Kotler,Roei Levi,Eyal Leviatan,Yotam Y. Lifshitz,Adi Ludmer,Shlomi Matityahu,Ron Aharon Melcer,Adiel Meyer,Omrie Ovdat,Aviad Panahi,Gil Ron,Ittai Rubinstein,Gili Schul,Tali Shnaider,Maor Shutman,Asif Sinay,Tasneem Watad,Assaf Zubida,Netanel H. Lindner*

Main category: quant-ph

TL;DR: QESEM is a new, highly accurate, and reliable error mitigation software for quantum computing that outperforms existing methods like zero-noise extrapolation and shows promise for future quantum advantage.


<details>
  <summary>Details</summary>
Motivation: Error mitigation is crucial for realizing the full potential of quantum algorithms and achieving quantum advantage, especially as quantum hardware advances and requires robust methods for accurate and reliable outputs.

Method: QESEM is a characterization-based software that implements efficient, unbiased quasi-probabilistic error mitigation. It employs innovative components for its operation.

Result: QESEM was demonstrated in the largest utility-scale error mitigation experiment using an unbiased method, simulating the kicked transverse field Ising model on an IBM Heron device. Its versatility was validated on IBM Heron and IonQ devices using molecular VQE circuits, consistently outperforming zero-noise extrapolation in accuracy.

Conclusion: QESEM in consistently achieves higher accuracy compared to zero-noise extrapolation and represents a significant advancement in accuracy and reliability for executing quantum circuits on current devices across various algorithmic applications. Projections show its potential for near-term devices toward quantum advantage.

Abstract: Error mitigation is essential for unlocking the full potential of quantum
algorithms and accelerating the timeline toward quantum advantage. As quantum
hardware progresses to push the boundaries of classical simulation, efficient
and robust error mitigation methods are becoming increasingly important for
producing accurate and reliable outputs. We introduce QESEM, a reliable,
high-accuracy, characterization-based software implementing efficient, unbiased
quasi-probabilistic error mitigation. We explain the innovative components
underlying the operation of QESEM and demonstrate its capabilities in the
largest utility-scale error mitigation experiment based on an unbiased method.
This experiment simulates the kicked transverse field Ising model with
far-from-Clifford parameters on an IBM Heron device. We further validate
QESEM's versatility across arbitrary quantum circuits and devices through
high-accuracy error-mitigated molecular VQE circuits executed on IBM Heron and
IonQ trapped-ion devices. Compared with multiple variants of the widely used
zero-noise extrapolation method, QESEM consistently achieves higher accuracy.
These results mark a significant step forward in accuracy and reliability for
running quantum circuits on devices available today across diverse algorithmic
applications. Finally, we provide projections of QESEM's performance on
near-term devices toward quantum advantage.

</details>


### [151] [Hybrid Fiber-Free-Space Entanglement Distribution Using Off-the-Shelf Quantum Devices](https://arxiv.org/abs/2508.11023)
*Gustavo C. Amaral,Nienke M. ten Haaf,Breno Perlingeiro,David L. Bakker,Mark G. M. Boekel,Tim E. van Duivenbode,Karthik Selvan,Nicolas Oidtmann,Rafael Ochsendorf,Rick N. M. Wasserman,Mael Flament,Felipe Giraldo,Shane Andrewski,Mehdi Namazi,Federica Facchin,Mario Castañeda,Fokko de Vries,Sayali Shevate,Shaurya Bhave,Marco Gorter,Nico Coesel,David Mytling,Mike Mabry,Carlo Page,Alexandra Pinto,Joanneke Jansen,Rahul Vyas,Marc X. Makkes*

Main category: quant-ph

TL;DR: 研究人员构建了一个由商业组件组成的校园级量子网络，并成功地通过光纤和自由空间链路分发了纠缠光子，证明了量子通信技术的进步和实际部署的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了实现超越经典极限的通信和计算任务，以及互联量子处理器以进行分布式量子计算，需要跨网络分发纠缠。

Method: 利用商业可用组件构建了一个包含光纤和自由空间光链路的校园规模三节点量子网络，并成功分发了偏振纠缠光子对。

Result: 成功地在校园规模的三节点量子网络（包括光纤和自由空间光链路）中分发了偏振纠缠光子对。

Conclusion: 该研究成功地在包含光纤和自由空间光链路的校园规模三节点量子网络中分发了偏振纠缠光子对，展示了量子通信技术的成熟度和实际部署的可行性，为未来地球和太空中的量子网络奠定了基础。

Abstract: Entanglement serves as a fundamental resource for quantum technologies,
enabling communication and computation tasks that surpass classical limits. Its
distribution across networks is essential for interconnecting quantum
processors, enabling distributed quantum computing to address complex
challenges in areas such as drug discovery, material science, and optimization.
In this work, we report the successful distribution of polarization-entangled
photon pairs across a campus-scale, three-node quantum network comprising both
fiber and free-space optical links. The entire system was built using
commercially available components provided by partners within the Netherlands
Quantum Ecosystem. This result represents advancements in the technological
maturity of quantum communication systems and demonstrates a pathway towards
the practical deployment of early-stage quantum networks both on Earth and in
space.

</details>


### [152] [Wireless Josephson parametric amplifier above 20 GHz](https://arxiv.org/abs/2508.11137)
*Z. Hao,J. Cochran,Y. Chuang,H. M. Cole,S. Shankar*

Main category: quant-ph

TL;DR: 超导量子比特的可扩展性需要高频放大。我们报告了一种运行频率高于二十吉赫的无线约瑟夫森参数放大器（ WJPA），其增益超过二十二分贝，附加噪声约为两个光子。


<details>
  <summary>Details</summary>
Motivation: 为了在更高的工作频率下实现超导量子比特的可扩展性，需要高频放大。

Method: 设计和实现了一个无线约瑟夫森参数放大器（ WJPA），工作在高于二十吉赫的频率，用于高频放大，并具有近量子极限的噪声特性。

Result: WJPA 在二十一到二十三点五吉赫的频率范围内实现了超过二十二分贝的增益，具有三兆赫的典型动态带宽，并且附加噪声约为两个光子。ansir量测量和基于量子比特的光子数校准证实了该放大器的性能。 WJPAs 的无线设计消除了在高频下会引起问题的损耗和阻抗失配。

Conclusion: 在二十二吉赫附近，约两个光子的附加噪声（相当于量子极限的1.1倍）被认为是在使用约十亿分之一秒的测量时间尺度时，具有约二十二吉赫的带宽以及超过二十二分贝的增益。

Abstract: Operating superconducting qubits at elevated temperatures offers increased
cooling power and thus system scalability, but requires suppression of thermal
photons to preserve coherence and readout fidelity. This motivates migration to
higher operation frequencies, which demands high-frequency amplification with
near-quantum-limited noise characteristics for qubit readout. Here, we report
the design and experimental realization of a wireless Josephson parametric
amplifier (WJPA) operating above 20~GHz. The wireless design eliminates losses
and impedance mismatches that become problematic at high frequencies. The WJPA
achieves more than 20~dB of gain across a tunable frequency range of
21--23.5~GHz, with a typical dynamic bandwidth of 3~MHz. Through Y-factor
measurements and a qubit-based photon number calibration, we show that the
amplifier exhibits an added noise of approximately two photons.

</details>


### [153] [The Role of Entanglement in Quantum Reservoir Computing with Coupled Kerr Nonlinear Oscillators](https://arxiv.org/abs/2508.11175)
*Ali Karimi,Hadi Zadeh-Haghighi,Youssef Kora,Christoph Simon*

Main category: quant-ph

TL;DR: 量子水库计算使用量子动力学处理时间序列数据。本研究使用耦合的克尔振荡器，发现纠缠在特定条件下可提高预测性能，但对最佳误差无改善。


<details>
  <summary>Details</summary>
Motivation: 为了研究基于量子动力学的量子水库计算（QRC）在处理时间序列数据方面的潜力，特别是探讨耦合克尔非线性振荡器作为QRC的适用性，以及纠缠在提高水库计算性能中的作用。

Method: 研究基于两个耦合的克尔非线性振荡器构建量子水库计算（QRC）框架，并分析了输入驱动强度、克尔非线性、振荡器耦合以及纠缠等关键物理参数对时间序列预测性能的影响。使用对数负值量化纠缠，使用归一化均方根误差（NRMSE）评估预测准确性。

Result: 研究发现，纠缠可以提供计算优势，提高预测性能，尤其是在非平凡时间序列的预测上。此外，研究还发现较高的耗散率可以提高性能，但纠缠并未能改善最佳情况下的误差。

Conclusion: 该研究表明，在一定输入频率阈值内，纠缠可以为时间序列预测提供计算优势，并且这种优势在一定程度的耗散和退相干下仍然存在。然而，纠缠并未能改善最佳情况下的误差。

Abstract: Quantum Reservoir Computing (QRC) uses quantum dynamics to efficiently
process temporal data. In this work, we investigate a QRC framework based on
two coupled Kerr nonlinear oscillators, a system well-suited for time-series
prediction tasks due to its complex nonlinear interactions and potentially
high-dimensional state space. We explore how its performance in time-series
prediction depends on key physical parameters: input drive strength, Kerr
nonlinearity, and oscillator coupling, and analyze the role of entanglement in
improving the reservoir's computational performance, focusing on its effect on
predicting non-trivial time series. Using logarithmic negativity to quantify
entanglement and normalized root mean square error (NRMSE) to evaluate
predictive accuracy, our results suggest that entanglement provides a
computational advantage on average-up to a threshold in the input
frequency-that persists under some levels of dissipation and dephasing. In
particular, we find that higher dissipation rates can enhance performance.
While the entanglement advantage manifests as improvements in both average and
worst-case performance, it does not lead to improvements in the best-case
error. These findings contribute to the broader understanding of quantum
reservoirs for high performance, efficient quantum machine learning and
time-series forecasting.

</details>


### [154] [Quantum Control of Thermal Emission from Photonic Crystals with Two-Level Atoms](https://arxiv.org/abs/2508.11191)
*Chih-Wei Wang,Jhih-Sheng Wu*

Main category: quant-ph

TL;DR: 量子二能级原子与光子晶体相互作用可调控热发射，在特定条件下可实现普朗克辐射或超普朗克辐射，应用于量子计算和辐射冷却。


<details>
  <summary>Details</summary>
Motivation: 热光工程是一个备受关注且潜力巨大的领域。本研究旨在探索利用量子效应调控热发射，以期在量子计算等领域实现低热噪声或增强辐射冷却等应用。

Method: 本研究采用量子二能级原子代替传统黑体模型中的经典振子，并将其置于一维光子晶体中，以研究量子光-物质相互作用对热发射的影响。通过理论建模，分析了在热库和泵浦作用下，原子与光子模式的相互作用如何调制热发射。重点研究了自发辐射、受激吸收和受激发射过程，并考察了泵浦与热弛豫率竞争导致的平衡与非平衡动力学行为。通过调整光-物质相互作用强度、光子衰减率和泵浦强度，分析了不同条件下光子数和原子布居数的稳态行为，特别是普朗克辐射和超普朗克辐射的出现。

Result: 强光-物质相互作用和光子衰减决定了动力学和稳态。在平衡状态下，高热弛豫率下，光子数受自发辐射和受激吸收影响，最终趋于稳定，且强相互作用下表现出普朗克辐射。带隙内外光子稳态时间尺度不同。带隙抑制作用与相互作用强度和光子衰减有关。在非平衡状态下，系统表现出多时间尺度动力学，稳态下原子布居数偏离费米-狄拉克分布，光子数表现出超普朗克辐射。

Conclusion: 本研究通过引入量子二能级系统替代传统黑体模型中的经典振子，研究了在量子二能级系统作为活性介质的一维光子晶体中的量子光-物质相互作用。结果表明，在热库和泵浦的共同作用下，这些二能级原子能够调制热发射。该模型考虑了自发辐射、受激吸收和受激发射过程。系统在平衡与非平衡状态之间的转换取决于泵浦和热弛豫率的竞争。强光-物质相互作用和光子衰减决定了系统的动力学行为和稳态。在平衡状态下，当热弛豫率较高时，光子数最初由自发辐射决定，随后在光-物质相互作用强度的影响下，通过受激吸收趋于稳定。带隙内光子的稳态时间尺度比带隙外光子长一到两个数量级。特别地，当光-物质相互作用较强时，所有平衡状态下的光子都表现出普朗克辐射，与它们是否处于带隙无关。带隙对热发射的抑制作用在光-物质相互作用较弱或光子衰减较大时更为显著。在非平衡状态下，由于强泵浦和受激过程，光子数的动力学演化呈现多时间尺度的过程并过渡到稳态。稳态下二能级原子的电子布居数偏离费米-狄拉克分布，稳态光子数表现出超普朗克辐射。这些发现为量子调控热发射光谱提供了可能，这对于减少量子计算中的热噪声或增强辐射冷却具有重要意义。

Abstract: Thermal light engineering is a field of considerable interest and potential.
We study quantum light-matter interactions in a one-dimensional photonic
crystal with two-level atoms as the active medium, replacing classical
oscillators in traditional blackbody models. In a thermal bath with pumping,
these atoms modulate thermal emission via interactions with photonic modes. The
model with quantum two-level systems enables the processes of spontaneous
emission, stimulated absorption, and stimulated emission. Equilibrium and
nonequilibrium regimes depend on competition between pumping and thermal
relaxation rates. Strong light-matter interaction and photon decay govern
dynamics and steady states. In equilibrium, with a high thermal relaxation
rate, photon numbers are initially determined by spontaneous emission and later
stabilize due to stimulated absorption, influenced by light-matter interaction
strength. In-band-gap photons reach steady states at a time scale of one or two
orders of magnitude longer than outside-band-gap photons. Interestingly, for a
strong light-matter interaction, all photons in the equilibrium regimes show
Planckian radiation, regardless of their frequencies in or out of the band
gaps. Band-gap suppression of thermal emission is more pronounced with weaker
light-matter interaction or larger photon decay. In the nonequilibrium regime,
the dynamics of photon numbers exhibit a multi-time-scale process transitioning
to steady states due to strong pumping and stimulated processes. Steady-state
electron populations of two-level atoms deviate from the Fermi-Dirac
distribution, and the steady-state photon numbers exhibit super-Planckian
emission. These findings enable quantum control of thermal emission spectra,
which is relevant for reducing thermal noise in quantum computing or enhancing
radiative cooling.

</details>


### [155] [Learning to Restore Heisenberg Limit in Noisy Quantum Sensing via Quantum Digital Twin](https://arxiv.org/abs/2508.11198)
*Hang Xu,Tailong Xiao,Jingzheng Huang,Jianping Fan,Guihua Zeng*

Main category: quant-ph

TL;DR: 量子数字孪生协议利用状态重构和强化学习来克服环境噪声对量子传感的限制，实现了海森堡极限，并兼容NISQ设备。


<details>
  <summary>Details</summary>
Motivation: 环境噪声引起的快速退相干是实现量子传感器海森堡极限的关键限制因素。

Method: 提出一种量子数字孪生协议，包括可观测量约束的状态重构以推断退相干过程中的随机误差，以及利用强化学习推导自适应补偿控制策略。

Result: 通过在离散、连续变量和多量子比特电路系统中进行演示，该方法绕过了量子态层析成像的指数级开销，并发现了恢复海森堡极限的最优控制方案，实现了噪声鲁棒传感。

Conclusion: 本研究提出了量子数字孪生协议，通过可观测量约束的状态重构来推断退相干过程中的随机误差，并利用强化学习获得自适应补偿控制策略，以在存在环境噪声的情况下实现海森堡极限。该方法无需量子态层析成像的指数级开销，并能发现最优控制方案来恢复海森堡极限。与需要精确噪声表征和辅助量子比特的量子纠错或缓解方案不同，该自主协议通过环境自适应控制序列实现抗噪声传感。本工作将量子数字孪生确立为一种通用的量子控制方法论，并提出了一种适用于包含噪声的下一代量子传感器的范式，该范式与NISQ时代的实验限制兼容。

Abstract: Quantum sensors leverage nonclassical resources to achieve sensing precision
at the Heisenberg limit, surpassing the standard quantum limit attainable
through classical strategies. However, a critical issue is that the
environmental noise induces rapid decoherence, fundamentally limiting the
realizability of the Heisenberg limit. In this Letter, we propose a quantum
digital twin protocol to overcome this issue. The protocol first establishes
observable-constrained state reconstruction to infer random errors in the
decoherence process, and then utilizes reinforcement learning to derive
adaptive compensatory control strategies. Demonstrated across discrete,
continuous variable and multi-qubit circuit systems, our approach bypasses
quantum state tomography's exponential overhead and discovers optimal control
schemes to restore the Heisenberg limit. Unlike quantum error correction or
mitigation schemes requiring precise noise characterization and ancillary
qubits, our autonomous protocol achieves noise-resilient sensing through
environment-adaptive control sequencing. This work establishes quantum digital
twin as a generic methodology for quantum control, proposing a noise-immune
paradigm for next-generation quantum sensors compatible with NISQ-era
experimental constraints.

</details>


### [156] [Sunlight-Excited Spontaneous Parametric Down-Conversion for Quantum Imaging](https://arxiv.org/abs/2508.11207)
*Ye Xing,Deifei Xu,Yuan Li,Wuhong Zhang,Lixiang Chen*

Main category: quant-ph

TL;DR: 利用阳光进行量子成像，太空应用潜力巨大。


<details>
  <summary>Details</summary>
Motivation: 探索将阳光这一非传统光源应用于量子成像，拓展量子信息的照明选项，特别是在激光不易部署的太空场景中。

Method: 利用阳光作为泵浦光，激发自发参量下转换过程，获取双光子的量子关联，并验证了这些光子对在位置上的良好关联性，从而可用于量子成像。

Result: 实现了利用阳光进行量子成像，证明了光子对在位置上的良好关联性，为非相干光源在量子成像中的应用提供了可能性。

Conclusion: 本研究证实了利用阳光作为泵浦源进行量子成像的可行性，并强调了其在太空等非传统场景下的应用潜力。

Abstract: Quantum imaging, which harnesses quantum correlations to achieve imaging with
multiple advantages over classical optics, has been in development for several
years. Here, we explore sunlight, serving as the pump beam, to excite
spontaneous parametric down-conversion to get the quantum correlation of two
photons. Remarkably, our investigations disclose that the photon pairs produced
from sunlight are well correlated in position such that they can be used for
quantum imaging. Consequently, this demonstrates a latent application scenario
in which the incoherent beam is harnessed as the pump source for quantum
imaging. Our research is of substantial significance as it broadens the scope
of available illumination options, such as using scattering light or
non-traditional artificial incoherent light sources, for quantum information, a
prime potential application being a space-based quantum information mechanism
where this approach allows the system to operate independently of a laser.

</details>


### [157] [Fault-tolerant mixed boundary punctures on the toric code](https://arxiv.org/abs/2508.11230)
*Yao Shen,Fu-Lin Zhang*

Main category: quant-ph

TL;DR: 托利码的混合边界穿孔模型在对称和反对称子空间中均支持非阿贝尔统计，并且具有容错性。


<details>
  <summary>Details</summary>
Motivation: 为了探索和利用二维量子材料（如托利码）中非阿贝尔统计的潜力，本研究旨在扩展混合边界穿孔模型，并揭示其在不同子空间中的非阿贝尔性质及容错能力。

Method: 通过理论分析和量子模拟，研究了混合边界穿孔模型中非阿贝尔统计的性质，并验证了其在对称和反对称子空间中的存在性以及对噪声的容错性。最后，提出了一个量子信息掩蔽方案。

Result: 混合边界穿孔模型在对称和反对称子空间中均表现出非阿贝尔统计特性，并对集体退相干噪声和集体旋转噪声具有容错性。此外，提出的量子信息掩蔽方案在三方混合边界穿孔模型中得到了验证。

Conclusion: 该研究表明，三方混合边界穿孔模型中的非阿贝尔统计不仅存在于对称子空间，而且也存在于非对称子空间，并且该模型在两个子空间中都具有容错性，能够抵抗集体退相干噪声和集体旋转噪声。此外，研究还提出了一个量子信息掩蔽方案。

Abstract: Defects on the toric code, a well-known exactly solvable Abelian anyon model,
can exhibit non-Abelian statistical properties, which can be classified into
punctures and twists. Benhemou et al.[Phys. Rev. A. 105, 042417 (2022)]
introduced a mixed boundary puncture model that integrates the advantages of
both punctures and twists. They proposed that non-Abelian properties could be
realized in the symmetric subspace {$|++\rangle$, $|--\rangle$}. This work
demonstrates that the nontrivial antisymmetric subspace{$|+-\rangle$,
$|-+\rangle$} also supports non-Abelian statistics. The mixed boundary puncture
model is shown to be fault-tolerant in both subspaces, offering resistance to
collective dephasing noise and collective rotation noise. In addition, we
propose and validate a quantum information masking scheme within the
three-partite mixed boundary puncture model.

</details>


### [158] [Multi-QIDA method for VQE state preparation in molecular systems](https://arxiv.org/abs/2508.11270)
*Fabio Tarocco,Davide Materia,Leonardo Ratini,Leonardo Guidoni*

Main category: quant-ph

TL;DR: 本研究提出了一种名为Multi-QIDA的新型量子算法，用于解决量子化学中的复杂分子问题。该算法利用量子互信息（QMI）来构建高效、浅层的量子电路，并结合VQE优化技术，在处理分子基态能量估计时表现出优越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 量子化学计算的复杂性对经典计算方法提出了挑战。变分量子本征求解器（VQE）作为一种混合量子-经典算法，虽然有潜力解决这些问题，但面临着可扩展性、电路深度和无براین平原等挑战。本研究的动机是提出一种能够克服这些挑战，并提高VQE在分子系统上估计基态能量的效率和准确性的方法。

Method: 该研究提出了一种名为多阈值量子信息驱动ansatz（Multi-QIDA）的新方法，该方法利用量子互信息（QMI）来构建紧凑、由相关驱动的量子电路。该方法结合了QMI图的有效创建、利用最小/最大生成树减少相关器数量以及迭代层状VQE优化例程，并采用了SO(4)相关器等替代门结构来增强电路的可表达性。

Result: 在H2O、BeH2和NH3等小分子以及H2O-6-31G-CAS(4,4)和N2-cc-pVTZ-CAS(6,6)等活性空间模型上，Multi-QIDA方法在恢复分子系统中的缺失相关性方面表现出优越性，同时保持了计算效率。与传统的硬件高效ansatz相比，该方法能够构建更浅、更分层的量子电路，并有效处理相关性。

Conclusion: Multi-QIDA通过利用量子化学计算获得的近似量子互信息（QMI）矩阵，结合QMI图的有效创建、利用最小/最大生成树减少所需的相关器数量以及迭代层状VQE优化例程，在分子系统上系统地构建浅层、分层量子电路，以应对VQE面临的挑战。

Abstract: The development of quantum algorithms and their application to quantum
chemistry has introduced new opportunities for solving complex molecular
problems that are computationally infeasible for classical methods. In quantum
chemistry, the Variational Quantum Eigensolver (VQE) is a hybrid
quantum-classical algorithm designed to estimate ground-state energies of
molecular systems. Despite its promise, VQE faces challenges such as
scalability issues, high circuit depths, and barren plateaus that make the
optimization of the variational wavefunction. To mitigate these challenges, the
Quantum Information Driven Ansatz (QIDA) leverages Quantum Mutual Information
(QMI) to construct compact, correlation-driven circuits. In this work, we go
back to the original field of application of QIDA, by applying the already
defined Multi-Threshold Quantum Information Driven Ansatz (Multi-QIDA)
methodology on Molecular Systems. to systematically construct shallow, layered
quantum circuits starting from approximate QMI matrices obtained by Quantum
Chemistry calculations. The Multi-QIDA approach combines efficient creation of
the QMI map, reduction of the number of correlators required by exploiting
Minimum/Maximum spanning tress, and an iterative layer-wise VQE optimization
routine. These enhancements allow the method to recover missing correlations in
molecular systems while maintaining computational efficiency. Additionally, the
approach incorporates alternative gate constructions, such as SO(4)
correlators, to enhance the circuit expressibility without significantly
increasing the circuit complexity. We benchmark Multi-QIDA on systems ranging
from small molecules like H2O, BeH2, and NH3 in Iterative Natural Orbitals
(INOs) basis set, to active-space models such as H2O-6-31G-CAS(4,4) and
N2-cc-pVTZ-CAS(6,6), comparing it to traditional hardware-efficient ansatze.

</details>


### [159] [Unveiling the link between quantum ghost imaging and Grover's quantum searching algorithm](https://arxiv.org/abs/2508.11296)
*Neelan Gounden,Fazilah Nothlawala,Paola C. Obando,Thomas Konrad,Andrew Forbes,Isaac Nape*

Main category: quant-ph

TL;DR: 本研究将量子鬼成像（GI）与Grover量子搜索算法（GSA）联系起来，利用纠缠光子和相位编码，在GI系统中实现了GSA，用于搜索非结构化数据库。


<details>
  <summary>Details</summary>
Motivation: 探索量子鬼成像（GI）与全光学计算的交叉领域，揭示其与Grover量子搜索算法（GSA）的联系。

Method: 利用纠缠光子对，其中一个光子用于编码“神谕”特征，另一个光子用于寻找被标记的目标项。

Result: 实现了将GSA应用于包含相位编码的GI系统，以搜索非结构化数据库中的目标项。

Conclusion: 本研究揭示了量子鬼成像（GI）与Grover量子搜索算法（GSA）之间存在概念和操作上的联系，其中目标项被编码为光子在位置基态下的相位。

Abstract: Photonic quantum technologies have become pivotal in the implementation of
communication, imaging and computing modalities. Among these applications,
quantum ghost imaging (GI) exploits photon correlations to surpass classical
limits, with recent advances in spatial-mode encoding and phase imaging. In
parallel, all-optical computing offers powerful, passive-light processing
capabilities. Here, we explore the intersection of these domains, revealing a
conceptual and operational link between GI and Grover's quantum search
algorithm (GSA) which is designed to search for elements in an unstructured
database. Here, the elements are encoded as phases in the position basis states
of photons. To show this, we use entangled photon pairs, with one photon
encoding the oracle features while the other photon is used to find the marked
element.

</details>


### [160] [Spectral characterizations of entanglement witnesses](https://arxiv.org/abs/2508.11308)
*Zhiwei Song,Lin Chen*

Main category: quant-ph

TL;DR: 本研究深入探讨了纠缠见证的谱性质，区分了可分和不可分见证，并证明了不可分见证在探测量子态方面具有更强的能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统地研究纠缠见证（EWs）的谱性质，并区分可分（DEWs）和不可分纠缠见证（NDEWs）的特性，以期了解它们的异同，并为纠缠态的探测提供新的方法和见解。

Method: 本研究系统地分析了纠缠见证（EWs）的谱性质，包括最大特征值的下确界和上确界、最小特征值、负度（所有负特征值之和的绝对值）以及单位迹（归一化）纠缠见证的平方弗罗贝尼乌斯范数，并确定了这些值被达到的条件。通过比较DEWs和NDEWs，揭示了NDEWs的最小特征值下确界是严格不可达的，而DEWs可以达到。

Result: 研究表明，DEWs可以达到最小特征值下确界，而NDEWs则不能。此外，研究为EW拥有镜像EW提供了必要条件，并证明了NDEWs能够探测除两量子比特和量子比特-量子三比特系统外的所有NPT态。

Conclusion: 该研究为纠缠见证（EWs）的谱性质提供了系统的研究，区分了可分（DEWs）和不可分纠缠见证（NDEWs），并揭示了它们在最小特征值下确界方面的根本区别。此外，研究还应用这些结果来确定EW具有镜像EW的必要条件，并证明了NDEWs的优越探测能力，能够探测除两量子比特和量子比特-量子三比特系统外的任何非正交换（NPT）态。

Abstract: We present a systematic investigation of the spectral properties of
entanglement witnesses (EWs). Specifically, we analyze the infimum and supremum
of the largest eigenvalue, the smallest eigenvalue, the negativity (defined as
the absolute value of the sum of negative eigenvalues), and the squared
Frobenius norm of a unit-trace (normalized) entanglement witness, along with
the conditions under which these values are attained. Our study provides
distinct characterizations for decomposable (DEWs) and nondecomposable
entanglement witnesses (NDEWs). While these two classes share many spectral
similarities, we reveal a fundamental divergence by proving that the infimum of
the smallest eigenvalue can be attained by DEWs, yet remains strictly
unattainable for all NDEWs. We apply the results to provide necessary
conditions for an EW to possess a mirrored EW. Furthermore, we demonstrate the
superior detection capability of NDEWs by proving that any
non-positive-transpose (NPT) state beyond the two-qubit and qubit-qutrit
systems can be detected by an NDEW.

</details>


### [161] [Quantum-Enhanced Sensing of Excited-State Dynamics with Correlated Photons](https://arxiv.org/abs/2508.11311)
*Jiahao Joel Fan,Feihong Liu,Dangyuan Lei,Zhedong Zhang*

Main category: quant-ph

TL;DR: 利用被压缩光子进行瞬态吸收光谱分析，实现了对物质（特别是单层过渡金属硫族化物材料）谷激子及其动力学的实时监测，超越了传统方法。


<details>
  <summary>Details</summary>
Motivation: 利用被压缩光子（一种具有降低噪声的量子关联光）作为传感物质结构的资源。

Method: 利用光谱相关的被压缩光子，提出一种瞬态吸收（TA）方案，并建立微观理论进行研究。

Result: 所提出的TA方案具有高度的时间-能量分辨特性，可实现对谷激子及其动力学的实时监测，并且中间压缩比的被压缩光子更适用于时间分辨光谱学。

Conclusion: 该研究为研究物质的非平衡动力学提供了一个新范式，可应用于光催化和光电子学领域。

Abstract: The squeezed photons, as a quantum-correlated light with reduced noise, have
emerged as a great resource for sensing the structures of matter. Here we study
the transient absorption (TA) scheme using the squeezed photons whose spectral
correlation of amplitudes can be tailored. A microscopic theory is developed,
revealing a highly time-energy-resolved nature of the signal that is not
attainable by conventional TA scheme. Such a capability is elaborated by
applying to monolayer transition metal dichalcogenide materials (TMDs),
achieving a real-time monitoring of valley excitons and their dynamics.
Moreover, we show the intermediate squeezing regime-not the strong
squeezing-which the time-resolved spectroscopy is in favor of. Our work offers
a new paradigm for studying nonequilibrium dynamics of matter, in light of the
photocatalysis and optoelectronics.

</details>


### [162] [Noise Resilience of Spin Quantum Battery in the presence of DM Interactions](https://arxiv.org/abs/2508.11333)
*Vigneshwar B,Sankaranarayanan R*

Main category: quant-ph

TL;DR: 量子电池的抗噪声能力可以通过手征自旋相互作用（如DMI）来提高，特别是当DMI强度较强且初始相干性较高时。


<details>
  <summary>Details</summary>
Motivation: 环境噪声会降低量子电池存储的能量，研究手征自旋相互作用如何提高量子电池的抗噪声能力。

Method: 研究了单量子比特和双量子比特Heisenberg XYZ模型，并考虑了振幅阻尼、比特翻转和相位翻转噪声，以及Dzyaloshinsky-Moria相互作用（DMI）。

Result: 在单量子比特系统中，振幅阻尼和比特翻转噪声导致能量损失，而相位翻转噪声允许部分能量保存。在双量子比特系统中，发现临界相互作用强度可以增强能量保持能力，强DMI和初始相干性可以抵抗噪声。

Conclusion: 量子电池的能量保持能力可以通过手征自旋相互作用来增强，即使在重复的噪声作用下也能保护功。

Abstract: Quantum batteries utilize quantum effects to enhance energy storage and work
extraction, offering promising avenues for nanoscale energy applications.
However, environmental noise poses a significant challenge by degrading stored
energy. For a single qubit, we show that amplitude damping and bit-flip noises
lead to ergotropy loss, while phase-flip noise permits partial preservation of
work. Extending to a two-qubit Heisenberg XYZ model with Dzyaloshinsky-Moria
interaction (DMI), we identify a critical interaction strength that enhances
energy retention. We show that strong DMI and initial coherence protects
ergotropy even under repeated noise applications, highlighting chiral spin
interactions as a resource for noise-resilient quantum batteries.

</details>


### [163] [A solution of the quantum time of arrival problem via mathematical probability theory](https://arxiv.org/abs/2508.11368)
*Maik Reddiger*

Main category: quant-ph

TL;DR: 该研究提出了一个基于几何量子理论的到达时间概率分布模型，解决了量子力学中的一个难题，并为未来的研究开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 在量子理论中，粒子的到达时间概率分布尚未有普遍接受的解决方案。

Method: 通过构建一个通过数学概率论的理想探测器模型，该模型确保了概率流通过探测器表面始终为正，并借鉴了 Daumer、Dürr、Goldstein 和 Zanghì 最初提出的方法，推导出了相应的概率分布。

Result: 推导出了单个粒子（无自旋）在没有任何其他力或障碍的情况下撞击理想探测器的到达时间概率分布的通用解，并解决了该情况下的屏幕问题。

Conclusion: 该研究提出的动力学模型严格来说与量子力学不兼容，但在几何量子理论中得到了很好的描述。几何量子理论是对量子力学的一种新颖的调整，它使后者与数学概率论相一致。

Abstract: Time of arrival refers to the time a particle takes after emission to impinge
upon a suitably idealized detector surface. Within quantum theory, no generally
accepted solution exists so far for the corresponding probability distribution
of arrival times. In this work we derive a general solution for a single body
without spin impacting on a so called ideal detector in the absence of any
other forces or obstacles. A solution of the so called screen problem for this
case is also given. We construct the ideal detector model via mathematical
probability theory, which in turn suggests an adaption of the Madelung
equations in this instance. This detector model assures that the probability
flux through the detector surface is always positive, so that the corresponding
distributions can be derived via an approach originally suggested by Daumer,
D\"urr, Goldstein, and Zangh\`i. The resulting dynamical model is, strictly
speaking, not compatible with quantum mechanics, yet it is well-described
within geometric quantum theory. Geometric quantum theory is a novel adaption
of quantum mechanics, which makes the latter consistent with mathematical
probability theory. Implications to the general theory of measurement and
avenues for future research are also provided. Future mathematical work should
focus on finding an appropriate distributional formulation of the evolution
equations and studying the well-posedness of the corresponding Cauchy problem.

</details>


### [164] [Generation and certification of pure phase entangled light](https://arxiv.org/abs/2508.11418)
*Rounak Chatterjee,Mayuresh Kanagal,Vikas S Bhat,Kiran Bajar,Sushil Mujumdar*

Main category: quant-ph

TL;DR: 本文研究了一种新颖的‘纯’相位纠缠态，其特点是两光子间没有直接的位置或动量相关性，但存在相位关联。研究提出了实验制备和验证方法，并探讨了其在量子光学和成像中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对空间纠缠态，特别是相位纠缠态的物理意义和应用研究不足，本文旨在填补此空白。

Method: 理论和实验上研究了一种新的‘纯’相位纠缠态，该纠缠态的特点是单个光子的位置与另一个光子的动量相关，而光子间没有直接的位置或动量相关性。

Result: 成功从已知的相位纠缠态构建了‘纯’相位纠缠态，并提出了一种可以通过‘单粒子动量测量’来验证其性质的实验方案。

Conclusion: 该研究为量子光学和成像实验提供了一种新的相位纠缠态，并提出了验证其性质的实验方案。

Abstract: Biphoton systems exhibiting entanglement in position-momentum variables,
known as spatial entanglement, are among the most intriguing and well-studied
phenomena in quantum optics. A notable subset of these are phase entangled
states, where entanglement manifests purely through correlations in the spatial
phase of the wavefunction. While the generation of such states from biphotons
via spontaneous parametric down-conversion has been explored, their physical
implications and applications remain under-investigated. In this work, we
theoretically and experimentally examine a unique form of phase entanglement
known as `pure' phase entanglement. This state exhibits the unusual feature
that the position of one photon is correlated with the momentum of the other.
Unlike typical spatially entangled states, it shows no direct correlation in
position or momentum between the two photons, underscoring that all
correlations arise purely from the spatial phase of the wavefunction. We delve
deeper into the theory of this state and experimentally construct it from known
phase-entangled states. To certify its properties, we propose a setup that
performs a "one-particle momentum measurement" and explore the various tunable
parameters. We also highlight potential applications of this state in quantum
optics and imaging experiments.

</details>


### [165] [The Effect of Permanent Dipoles on Dark States in Molecular Dimers](https://arxiv.org/abs/2508.11445)
*Matthew Freed,Dominic M. Rouse,Andrea Rocco,Jim Al-Khalili,Marian Florescu,Adam Burgess*

Main category: quant-ph

TL;DR: Organic molecule permanent dipoles affect light interactions. This paper shows how these dipoles in dimers create robust 'dark states' that could boost solar cells.


<details>
  <summary>Details</summary>
Motivation: To address the common neglect of permanent dipoles in quantum optics treatments and explore their influence on intermolecular coupling and optical field interactions, specifically in organic dimers.

Method: Investigating optical properties and their effect on dark states of dimers with excitation-dependent permanent dipoles, analyzing the coupling mechanisms and resulting interference effects.

Result: Demonstrated that excitation-dependent permanent dipoles enable optical transitions between bright and dark states in dimers, leading to indirectly coupled, localized dark states that are more robust to energy fluctuations.

Conclusion: Permanent dipoles in organic molecules, especially when excitation-dependent, enable optical transitions between bright and dark states in dimers. This coupling, mediated by static driving terms, leads to interference with transition dipoles, forming localized dark states with enhanced robustness against fluctuations, potentially improving photovoltaic device efficiency.

Abstract: Many organic molecules possess large permanent dipole moments that differ
depending on the electronic state. These permanent dipoles influence both
intermolecular coupling and interactions with the optical fields, yet they are
often neglected in typical theoretical quantum optics treatments. Here, we
investigate the optical properties and their effect on dark states of dimers
possessing such permanent dipoles. We show that when monomers have
excitation-dependent permanent dipoles, optical transitions between the bright
and dark states of the dimer are enabled. We investigate how permanent dipoles
allow for the existence of static driving terms between the ground and excited
states of each monomer. In turn, these can cause the excited states of the
monomers to couple indirectly to the zero excitation state of the dimer. This
leads to interference between permanent and transition dipoles and can result
in the formation of dark states that are entirely localised. Furthermore, dark
states formed through indirect coupling exhibit enhanced robustness against
energy level fluctuations, which may improve the efficiency of the design of
photovoltaic devices.

</details>


### [166] [Anisotropic fluorescence signals retarded dipole-dipole interactions in a thermal atomic cloud](https://arxiv.org/abs/2508.11480)
*Vyacheslav Shatokhin,Friedemann Landmesser,Mario Niebuhr,Frank Stienkemeier,Andreas Buchleitner,Lukas Bruder*

Main category: quant-ph

TL;DR: Anisotropic multiple quantum coherence signals in potassium vapors were observed and explained using inter-atomic dipole-dipole interaction.


<details>
  <summary>Details</summary>
Motivation: Anisotropic multiple quantum coherence signals in the fluorescence from dilute thermal potassium vapors.

Method: We experimentally observe and theoretically explain anisotropic multiple quantum coherence signals in the fluorescence from dilute thermal potassium vapors.

Result: We experimentally observe and theoretically explain anisotropic multiple quantum coherence signals in the fluorescence from dilute thermal potassium vapors, at room temperature and particle densities $\sim 10^8m{cm}^{-3}$. The retarded part of the geometrically fully resolved inter-atomic, resonant dipole-dipole interaction is identified as the crucial ingredient to theoretically reproduce all qualitative features of the experimental spectra.

Conclusion: We identify the retarded part of the geometrically fully resolved inter-atomic, resonant dipole-dipole interaction as the crucial ingredient to theoretically reproduce all qualitative features of the experimental spectra.

Abstract: We experimentally observe and theoretically explain anisotropic multiple
quantum coherence signals in the fluorescence from dilute thermal potassium
vapors, at room temperature and particle densities $\sim 10^8\ \rm{cm}^{-3}$.
We identify the retarded part of the geometrically fully resolved inter-atomic,
resonant dipole-dipole interaction as the crucial ingredient to theoretically
reproduce all qualitative features of the experimental spectra.

</details>


### [167] [Random Unitaries in Constant (Quantum) Time](https://arxiv.org/abs/2508.11487)
*Ben Foxman,Natalie Parham,Francisca Vasconcelos,Henry Yuen*

Main category: quant-ph

TL;DR: 该研究展示了在更弱的量子计算模型（如具有多量子比特门或中途测量的恒定深度电路）中，可以有效地构造随机幺正。这在量子计算和复杂性理论方面具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究随机幺正（random unitaries）在量子信息、量子计算、量子多体物理和量子密码学中的应用，以及近期关于使用$\\(n)$深度幺正电路构造幺正设计和伪随机幺正（PRUs）的研究。

Method: 通过在具有多量子比特Toffoli门、多量子比特FANOUT门或带经典前馈控制的中途测量等非局域操作的恒定深度量子电路中进行构造。

Result: 1. 证明了幺正设计和PRUs可以在一些研究较多的恒定时间量子计算模型中有效构造。 2. 构造了在具有多量子比特Toffoli门的恒定深度电路中的PRUs，这表明在密码学假设下，不存在$\\\mathsf{QAC}^0$的电路类的多项式时间学习算法。 3. 提出了新的方法来证明PARITY不可在$\\\mathsf{QAC}^0$中计算。

Conclusion: 该研究表明，在之前认为更弱的量子计算模型中，可以有效地构造幺正设计和伪随机幺正（PRUs）。

Abstract: Random unitaries are a central object of study in quantum information, with
applications to quantum computation, quantum many-body physics, and quantum
cryptography. Recent work has constructed unitary designs and pseudorandom
unitaries (PRUs) using $\Theta(\log \log n)$-depth unitary circuits with
two-qubit gates.
  In this work, we show that unitary designs and PRUs can be efficiently
constructed in several well-studied models of $\textit{constant-time}$ quantum
computation (i.e., the time complexity on the quantum computer is independent
of the system size). These models are constant-depth circuits augmented with
certain nonlocal operations, such as (a) many-qubit TOFFOLI gates, (b)
many-qubit FANOUT gates, or (c) mid-circuit measurements with classical
feedforward control. Recent advances in quantum computing hardware suggest
experimental feasibility of these models in the near future.
  Our results demonstrate that unitary designs and PRUs can be constructed in
much weaker circuit models than previously thought. Furthermore, our
construction of PRUs in constant-depth with many-qubit TOFFOLI gates shows
that, under cryptographic assumptions, there is no polynomial-time learning
algorithm for the circuit class $\mathsf{QAC}^0$. Finally, our results suggest
a new approach towards proving that PARITY is not computable in
$\mathsf{QAC}^0$, a long-standing question in quantum complexity theory.

</details>


### [168] [Surpassing Carnot efficiency with relativistic motion](https://arxiv.org/abs/2508.11554)
*Dimitris Moustos,Obinna Abah*

Main category: quant-ph

TL;DR: This paper uses a quantum heat engine with moving parts to show that relativistic effects can boost the engine's performance beyond classical limits, and derives a new version of the second law of thermodynamics.


<details>
  <summary>Details</summary>
Motivation: Relativistic thermal devices provide a novel way to explore the interactions between motion, quantum fields, and thermodynamics, leading to phenomena not observable in static systems. This research specifically focuses on a heat engine utilizing relativistic effects.

Method: The paper analyzes a two-qubit SWAP heat engine with inertially moving Unruh-DeWitt qubit detectors coupled to scalar quantum fields at different temperatures. It investigates how relativistic motion induces frequency-dependent effective temperatures for the qubits, which can differ from their reservoir temperatures.

Result: The analysis demonstrates that the effective temperatures perceived by the moving qubits are dependent on frequency and can be higher or lower than their reservoir temperatures. This relativistic temperature shift acts as a resource to enhance the engine's performance (work output and efficiency at maximum power). Furthermore, a generalized second law is derived, indicating that such engines can exceed the Carnot efficiency limit.

Conclusion: The relativistic temperature shift due to motion can be utilized as a thermodynamic resource to improve the work output and efficiency at maximum power of a two-qubit SWAP heat engine. The study also derives a generalized second law for heat engines with moving working media, showing they can surpass the Carnot bound.

Abstract: Relativistic thermal devices offer a unique platform for understanding the
interplay between motion, quantum fields, and thermodynamics, revealing
phenomena inaccessible to stationary systems. We consider a two-qubit SWAP heat
engine whose working medium consists of inertially moving Unruh-DeWitt qubit
detectors, each coupled to a scalar quantum field in thermal equilibrium at a
distinct temperature. Relativistic motion causes the qubits to perceive
frequency-dependent effective temperatures that are either hotter or colder
than their respective reservoir temperature. We show that the relativistic
temperature shift, perhaps the qubit velocity, can be harnessed as a
thermodynamic resource to enhance the work output and the efficiency at maximum
power of the heat engine. We derive a generalized second law for a heat engine
with a moving working medium and demonstrate that it can exceed the standard
Carnot bound defined by rest-frame temperatures.

</details>


### [169] [Dependence of the recoherence times and recoherence increments on the state of phonon bath in a single qubit dephasing model](https://arxiv.org/abs/2508.11606)
*V. V. Ignatyuk,Ch. Samorodov*

Main category: quant-ph

TL;DR: 研究了单量子比特退相干模型中相干回跳时间 t* 和相干回跳增量 γ_extr 与浴参数的关系。发现短时间相干回跳和长时间退相干行为密切相关，并指出了影响这些参数的环境特征。


<details>
  <summary>Details</summary>
Motivation: 研究相干回跳时间 t* 和相干回跳增量 γ_extr 的函数行为，以期理解环境的基本特征，并找到最优的 t* 和 γ_extr。

Method: 研究了单个量子比特退相干模型中，通过特殊类型的非选择性测量制备的初始状态下，相干回跳时间 t* 和相干回跳增量 γ_extr 的最大值作为浴参数函数的行为。

Result: 在退相干模型中，发现相干/退相干事件（RDE）在系统演化的初始阶段，其行为与长时间尺度上的系统动力学既有相似之处，也存在差异。例如，与长时标上观察到的 RDE 不同，在短时间相干回跳方面，次欧姆和欧姆耦合机制比超欧姆耦合机制更有利。另一方面，短时间相干回跳行为与长时间退相干动力学密切相关：退相干类型发生改变（从完全退相干到不完全退相干）的欧姆指数区域，同时也是相干回跳最弱的区域。$
The recoherence times $t^*$ and the maximum values of the recoherence increments $\gamma_{\rm extr}$ are studied as functions of the bath parameters for a single qubit dephasing model, prepared initially by a special kind of the non-selective measurements. The recoherence/decoherence events (RDE), occurring at the initial stage of the system evolution, are found to be both similar and different from the system dynamics at large times. For instance, in contrast to the RDE observed on large time scales, the sub-Ohmic and Ohmic coupling regimes are more favourable for the short-time recoherence than the super-Ohmic one. On the other hand, the short-time behaviour of the recoherence and the long-time dynamics of the decoherence are closely related: the domain of the ohmicity indexes, where the decoherence changes its type (from the complete to incomplete one), is, simultaneously, that of the weakest recoherence.

Conclusion: 研究结果为理解环境的基本特征提供了一些线索，这些特征可能在某种意义上提供最优的 t* 和 γ_extr 值。

Abstract: The recoherence times $t^*$ and the maximum values of the recoherence
increments $\gamma_{\rm extr}$ are studied as functions of the bath parameters
for a single qubit dephasing model, prepared initially by a special kind of the
non-selective measurements. The recoherence/decoherence events (RDE), occurring
at the initial stage of the system evolution, are found to be both similar and
different from the system dynamics at large times. For instance, in contrast to
the RDE observed on large time scales, the sub-Ohmic and Ohmic coupling regimes
are more favourable for the short-time recoherence than the super-Ohmic one. On
the other hand, the short-time behaviour of the recoherence and the long-time
dynamics of the decoherence are closely related: the domain of the ohmicity
indexes, where the decoherence changes its type (from the complete to
incomplete one), is, simultaneously, that of the weakest recoherence. The
obtained results give us some hints about the basic characteristics of the
environment, which might provide the most optimal values of $t^*$ and
$\gamma_{\rm extr}$ in some sense.

</details>


### [170] [Quantum Simulation of Collective Neutrino Oscillations in Dense Neutrino Environment](https://arxiv.org/abs/2508.11610)
*Shvetaank Tripathi,Sandeep Joshi,Garima Rajpoot,Prashant Shukla*

Main category: quant-ph

TL;DR: Neutrino oscillations in dense environments like neutron star mergers were simulated on quantum computers. The study modeled neutrino interactions, decomposed them for quantum circuits, and calculated flavour transformation and entanglement.


<details>
  <summary>Details</summary>
Motivation: The motivation was to study collective neutrino oscillations within dense neutrino gases, such as those found in neutron star mergers or core-collapse supernovae, where flavour transformation and swapping occur due to strong self-interactions.

Method: The study modeled the effective Hamiltonian governing neutrino interactions and used the Trotter-Suzuki approximation to decompose it for quantum circuit implementation. The neutrino state for two- and three-neutrino systems was encoded onto qubits to compute the time evolution of the inversion probability and evaluate entanglement using quantum circuits.

Result: The study computed the time evolution of the inversion probability relative to the initial product state for two- and three-neutrino systems and presented quantum circuits to evaluate the concurrence as a measure of entanglement between neutrinos.

Conclusion: Inside dense neutrino gases, collective neutrino effects cause flavour transformation, with prevalence of flavour swapping due to strong neutrino self-interactions. This study simulated these collective neutrino oscillations on quantum simulators and processors.

Abstract: Inside dense neutrino gases, such as neutron star mergers or core-collapse
supernovae, collective neutrino effects cause the transformation of one
neutrino flavour into another. Due to strong neutrino self-interactions in
these environments, there is prevalence of flavour swapping. Considering these
environments to be isotropic and homogeneous, we present a study of collective
neutrino oscillations by simulating such a system on a noisy quantum simulator
(Qiskit AerSimulator) and a quantum processor (ibm\_brisbane). We model the
effective Hamiltonian governing neutrino interactions and by applying the
Trotter-Suzuki approximation, decompose it into a tractable form suitable for
quantum circuit implementation of the time-evolution propagator. Encoding the
neutrino state for a system of two- and three-neutrinos onto qubits, we compute
the time evolution of the inversion probability relative to the initial product
state. Furthermore, we present quantum circuits to evaluate the concurrence as
a measure of entanglement between the neutrinos.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [171] [Tunable optical emissions of Eu3+ ions enabled by pressure-driven phase transition in ZnO](https://arxiv.org/abs/2508.10953)
*C. Ianhez-Pereira,U. F. Kaneko,A. D. Rodrigues,I. S. S. de Oliveira,M. P. F. de Godoy*

Main category: cond-mat.mtrl-sci

TL;DR: External hydrostatic pressure can tune the optical properties of rare-earth ions in semiconductors by inducing phase transitions and altering the local environment, offering a new method for designing photonic devices.


<details>
  <summary>Details</summary>
Motivation: Controlling the optical properties of rare-earth ions in wide-bandgap semiconductors is crucial for advancing photonic materials. This research investigates the use of external hydrostatic pressure to achieve such control.

Method: The study combines in situ synchrotron X-ray diffraction and photoluminescence spectroscopy under high-pressure conditions with first-principles calculations to analyze ZnO thin films with embedded Eu3+ ions.

Result: A pressure-induced phase transition from hexagonal wurtzite to cubic rocksalt structure was observed in ZnO thin films near 10 GPa. This transition led to the quenching and partial recovery of Eu3+ emissions, with redshifts and broadening of emission bands observed due to enhanced crystal field strength and changes in lattice symmetry.

Conclusion: The paper demonstrates that hydrostatic pressure can effectively tune the optical emissions of rare-earth ions in wide-bandgap semiconductors by altering their symmetry and local environment. This provides a foundation for developing pressure-controlled photonic devices and luminescent materials.

Abstract: Controlling the optical properties of rare-earth ions in wide-bandgap
semiconductors remains a major challenge in the development of next-generation
photonic materials. Here, we show that external hydrostatic pressure modulates
the structural characteristics of ZnO thin films and, in turn, tunes the
optical emission behavior of embedded Eu3+ ions. By combining in situ
synchrotron X-ray diffraction and photoluminescence spectroscopy under
high-pressure conditions with first-principles calculations, we capture a
pressure-induced phase transition from the hexagonal wurtzite to the cubic
rocksalt structure near 10 GPa. This transformation is accompanied by complete
quenching of the D0 - FJ Europium emissions near the transition threshold,
followed by a partial recovery at higher pressures, likely associated with the
emergence of structural disorder. Concurrently, the Stark components of the
emission bands exhibit a redshift and significant broadening with increasing
pressure, reflecting enhanced crystal field strength as interatomic distances
decrease. Additional first-principles calculations support the observed
pressure-induced shifts in the Eu-4f states and emphasize the influence of
lattice symmetry on their electronic environment. These results show that
hydrostatic pressure is an effective way to adjust the optical emissions of
rare-earth ions by changing their symmetry and local environment, providing a
basis for designing photonic devices and luminescent materials controlled by
pressure.

</details>


### [172] [Electron Ptychography Images Hydrogen Atom Superlattices and 3D Inhomogeneities in Palladium Hydride Nanoparticles](https://arxiv.org/abs/2508.11142)
*Zixiao Shi,Qihao Li,Himani Mishra,Desheng Ma,Héctor D. Abruña,David A. Muller*

Main category: cond-mat.mtrl-sci

TL;DR: 电子断层扫描技术首次在三维空间中成像钯氢化物中的氢原子，发现氢原子的一维超晶格排序和三维团簇现象。


<details>
  <summary>Details</summary>
Motivation: 金属氢化物（MHx）在基础科学和技术应用中具有广泛的兴趣。然而，确定氢原子在MHx中的位置以及其是否在部分占据的间隙位置上进行排序，对于预测和理解氢化物 resultant 的物理和电子性质至关重要。由于氢原子尺寸小且与宿主金属的相互作用独特，传统成像技术难以直接成像氢原子。

Method: 使用电子断层扫描技术（electron ptychography），这是一种扫描透射电子显微镜技术，用于成像钯氢化物（PdHx）纳米立方体中的氢原子三维分布。

Result: 首次在三维空间中观察到钯氢化物（PdHx）纳米立方体中的氢原子分布，发现了意想不到的氢原子一维超晶格排序和三维氢原子团簇现象，揭示了先前其他方法无法触及的金属氢化物纳米粒子中的空间异质性。

Conclusion: 该研究使用电子断层扫描技术首次在三维空间中成像了钯氢化物（PdHx）纳米立方体中的氢原子分布，揭示了氢原子的一维超晶格排序和局部区域的三维团簇现象，这为了解金属氢化物的物理和电子特性提供了新的视角。

Abstract: When hydrogen atoms occupy interstitial sites in metal lattices, they form
metal hydrides (MHx), whose structural and electronic properties can differ
significantly from the host metals. Owing to the small size of hydrogen atom
and its unique interactions with the host metal, MHx is of broad interest in
both fundamental science and technological applications. Determining where the
hydrogen is located within the MHx, and whether it orders on the partially
occupied interstitial sites is crucial for predicting and understanding the
resultant physical and electronic properties of the hydride. Directly imaging
hydrogen within a host material remains a major challenge due to its weak
interaction with X-rays and electrons in conventional imaging techniques. Here,
we employ electron ptychography, a scanning transmission electron microscopy
technique, to image the three-dimensional (3D) distribution of H atoms in
Palladium hydrides (PdHx) nanocubes, one of the most studied and industrially
relevant MHx materials. We observe an unexpected one-dimensional superlattice
ordering of hydrogen within the PdHx nanocubes and 3D hydrogen clustering in
localized regions within PdHx nanocubes, revealing spatial heterogeneity in
metal hydride nanoparticles previously inaccessible by other methods.

</details>


### [173] [Uncovering the Fourier Structure of Wavefunctions in Semiconductors](https://arxiv.org/abs/2508.11225)
*Yunfan Liang,Damien West,Shengbai Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: Material symmetry governs physical properties. Bravais lattice and atomic symmetry create planewave degeneracies in the Brillouin zone (BZ). Optical properties arise from lifted degeneracies. For Si, one band transition with two planewaves explains dielectric properties. Non-linear optical response comes from higher-order degeneracies on high-symmetry lines/points.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to understand how the symmetry of materials dictates their physical properties, particularly their optical response. It aims to explain the underlying principles governing optical transitions in semiconductors by considering the role of planewaves and degeneracies within the Brillouin zone (BZ). The paper seeks to provide a theoretical framework for understanding both linear and non-linear optical properties, demonstrating that these arise from specific symmetry-induced degeneracies.

Method: The paper analyzes the role of symmetry in determining the physical properties of materials, specifically focusing on how Bravais lattice symmetry and atomic interactions create degeneracies in planewaves within the Brillouin zone (BZ). It explains that optical transitions are forbidden between degenerate planewaves and thus only regions near lifted degeneracies contribute to optical properties. The method involves applying this framework to semiconductors like Si to understand their optical response, including both linear and non-linear properties.

Result: The analysis reveals that a single band transition involving only two planewaves can effectively describe the dielectric properties of semiconductors like Si. Furthermore, the study demonstrates that non-linear optical response originates from higher-order degeneracies that exist along high-symmetry lines and points within the BZ.

Conclusion: Symmetry determines the physical properties of materials. The symmetry of the Bravais lattice and atomic interactions define degeneracies in planewaves within the Brillouin zone (BZ). Optical transitions only occur near lifted degeneracies, contributing to optical properties. The analysis of Si and other semiconductors shows that a single band transition with two planewaves sufficiently describes their dielectric properties. Higher-order degeneracies along high-symmetry lines/points in the BZ are responsible for non-linear optical response.

Abstract: Symmetry dictates the physical properties of materials. The symmetry of the
Bravais lattice defines the set of points, lines, and planes over which sets of
planewaves are degenerate, upon which atomic symmetry determines the
interaction potentials which may lift such degeneracies. This results in
wavefunctions which are single planewaves throughout the BZ, except in the
vicinity of the removed degeneracies. As optical transitions between any two
planewaves are forbidden, only regions of the Brillouin zone (BZ) near these
lifted degeneracies contribute to optical properties. Application to optical
response of Si and other semiconductors reveals that a single band transition,
with only two planewaves, well describes their dielectric properties. Further,
it provides a framework to understand non-linear optical response which is
demonstrated to arise from higher order degeneracy existing along high symmetry
lines/points of the BZ.

</details>


### [174] [Metallic Contact Contributions in Thermal Hall Conductivity Measurements](https://arxiv.org/abs/2508.11240)
*Hongyu Ma,Xuesong Hu,Junren Shi*

Main category: cond-mat.mtrl-sci

TL;DR: 金属触点旁路热流会影响热霍尔测量，需要抑制该效应。


<details>
  <summary>Details</summary>
Motivation: 探究金属触点对热霍尔测量的影响，揭示旁路热电流产生虚假热霍尔信号的潜在问题。

Method: 通过分析典型的测量配置，演示了金属触点旁路热电流会产生非微小的热霍尔信号，即使在实际测量的绝缘体的热霍尔电导率为零时也是如此。研究表明，该效应预测的热霍尔电导率与各种材料的实际实验观测结果相比具有可比性，通过假设样品宽度数量级的有效触点厚度，重现了它们的温度依赖性和幅度。它甚至可以重现具有高和低纵向热导率的材料之间温度依赖性的细微差别。

Result: 研究结果表明，金属触点旁路热电流产生的热霍尔信号的预测与实际实验观测结果相当，重现了温度依赖性和幅度，并能区分高低纵向热导率材料的细微差别。

Conclusion: 该研究表明，在热霍尔测量中，金属触点旁路热电流会产生可观的热霍尔信号，即使在绝缘体实际热霍尔电导率为零的情况下也是如此。研究结果表明，该效应能够很好地重现各种材料的实验观测结果，包括它们的温度依赖性和幅度，这表明需要抑制旁路热电流。

Abstract: We investigate the influence of metallic contacts on thermal Hall
measurements. By analyzing typical measurement configurations, we demonstrate
that heat currents bypassing through metallic contacts can generate
non-negligible thermal Hall signals, even when the actual thermal Hall
conductivity of a measured insulator is zero. We show that the effect predicts
thermal Hall conductivities that compare favorably with actual experimental
observations across a variety of materials, reproducing both their temperature
dependencies and magnitudes by assuming effective contact thicknesses on the
order of 10$^{-2}$ of sample widths. It even reproduces the subtle differences
in temperature dependencies between materials with high and low longitudinal
thermal conductivity. Our study suggests the necessity of suppressing the
bypass heat currents in thermal Hall measurements, which can be achieved by
properly arranging the measurement configurations.

</details>


### [175] [Atomistic spin dynamics with quantum colored noise](https://arxiv.org/abs/2508.11315)
*Fried-Conrad Weber,Felix Hartmann,Matias Bargheer,Janet Anders,Richard F. L. Evans*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在ASD模拟中加入量子修正和有色噪声，我们能够更准确地预测磁化动力学，并与实验结果高度吻合。


<details>
  <summary>Details</summary>
Motivation: 经典的ASD模拟在预测温度依赖的磁化动力学方面存在显著偏差，尤其是在低温下，这促使了对更精确模拟方法的需求。

Method: 提出了一种量子修正的ASD方法，将其集成到Vampire软件中，并使用基于开放系统Landau-Lifshitz-Gilbert方程和量子恒温器的模型，该模型包含了记忆效应和源于量子力学考虑的有色噪声。

Result: 所提出的方法在镍和钆的整个温度范围内与实验磁化曲线表现出优异的定量一致性，证明了包含量子环境效应和有色噪声能够有效提升ASD模拟的预测能力。

Conclusion: 本研究通过将量子修正的ASD集成到Vampire软件中，并结合考虑量子力学效应的含记忆效应和有色噪声的开放系统LLG方程，实现了对温度相关磁化动力学的精确预测，显著提高了ASD模拟的预测能力，为局部磁矩磁性系统的温度相关磁性现象建模提供了稳健的框架。

Abstract: The accurate prediction of temperature-dependent magnetization dynamics is a
fundamental challenge in computational magnetism. While Atomistic Spin Dynamics
(ASD) simulations have emerged as a powerful tool for studying magnetic
phenomena, their classical nature leads to significant deviations from
experimental observations, particularly at low temperatures. Here we present a
comprehensive implementation of quantum-corrected ASD into the Vampire software
package, based on the open-system Landau-Lifshitz-Gilbert equation with a
quantum thermostat. Our implementation incorporates memory effects along with
colored noise derived from quantum-mechanical considerations that improve the
description of the equilibrium magnetization. We demonstrate excellent
quantitative agreement with experimental magnetization curves for nickel and
gadolinium across the full temperature range. Our results establish that
incorporating quantum environmental effects and colored noise substantially
enhances the predictive capabilities of ASD simulations, providing a robust
framework for modeling temperature-dependent magnetic phenomena in localized
moment magnetic systems.

</details>


### [176] [Enhanced anomalous Hall conductivity via Ga doping in Mn\textsubscript{3}Sn and Mn\textsubscript{3}Ge](https://arxiv.org/abs/2508.11321)
*Chenyue Wen,Danrong Xiong,Chengyi Yang,Dapeng Zhu,Weisheng Zhao*

Main category: cond-mat.mtrl-sci

TL;DR: 通过掺杂Ga调控Mn3Z（Z=Ga, Ge, Sn）的电子结构，成功大幅提升了反常霍尔电导率，为优化该类材料的AHE提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 探索和增强非共线反铁磁材料中的反常霍尔效应（AHE）。

Method: 利用密度泛函理论和第一性原理计算，通过掺杂Ga来调节Mn3Sn和Mn3Ge的电子密度，以提高反常霍尔电导率（AHC）。

Result: 研究表明，反常霍尔电导率对电子填充非常敏感。将Ga掺杂到Mn3Sn和Mn3Ge中可以显著提高AHC，其中Ga:Sn=1:5的比例可使AHC超过700（Ω·cm）⁻¹，而Ga:Ge=3:7的比例可使AHC超过600（Ω·cm）⁻¹。虚拟晶体近似和超胞构建方法在模拟掺杂效果上得到了一致的趋势。

Conclusion: 该研究通过掺杂揭示了赫斯勒系列Mn3Z（Z=Ga, Ge, Sn）中反常霍尔效应（AHE）与电子填充之间的关系，并成功调控了非共线反铁磁结构以增强AHE。

Abstract: This study examines the anomalous Hall effect (AHE) in the Heusler series
\ce{Mn3Z} (Z=Ga, Ge, Sn), with a particular emphasis on the manipulation of
non-collinear antiferromagnetic structures to enhance AHE. By employing
density-functional theory and first-principles calculations, we demonstrate
that the anomalous Hall conductivity is markedly responsive to electron
filling. By strategically doping Ga into \ce{Mn3Sn} and \ce{Mn3Ge} in order to
modulate the electron density, a significant increase in anomalous Hall
conductivity (AHC) is achieved. It is noteworthy that a Ga:Sn ratio of 1:5
yields peak AHC values exceeding $\mathrm{700(\Omega \cdot cm)^{-1}}$, while
3:7 Ga-Ge ratios can result in AHC values surpassing $600\mathrm{(\Omega \cdot
cm)^{-1}}$. A comparison between the virtual crystal approximation and
supercell construction methods for doping has revealed consistent trends. The
results of this study pave the way for optimizing AHE in non-collinear AFM
materials.

</details>


### [177] [Hole doping as an efficient route to increase the Curie temperature in monolayer CrI$_3$](https://arxiv.org/abs/2508.11397)
*Marko Orozović,Božidar N. Šoškić,Silvia Picozzi,Željko Šljivančanin,Srdjan Stavrić*

Main category: cond-mat.mtrl-sci

TL;DR: 通过理论模拟，我们发现给二维磁体 CrI$_3$ 掺杂空穴可以增强其磁性，提高磁化温度。


<details>
  <summary>Details</summary>
Motivation: 探索载流子掺杂如何影响二维范德华磁体（以 CrI$_3$ 为例）的磁相互作用。

Method: 采用结合密度泛函理论、自旋哈密顿量建模和维格纳函数分析的多尺度理论框架。

Result: 研究发现，空穴掺杂能有效增强 CrI$_3$ 的铁磁交换和磁各向异性，并且高浓度空穴掺杂可以将 CrI$_3$ 单层的居里温度提高到 200 K 以上。

Conclusion: 载流子掺杂能提高 CrI$_3$ 单层的居里温度，证明了各向异性工程可以稳定高温磁有序。

Abstract: Two-dimensional van der Waals (vdW) magnets offer unprecedented opportunities
to control magnetism at the atomic scale. Through charge carrier doping -
realized by electrostatic gating, intercalation/adsorption, or interfacial
charge transfer - one can efficiently tune exchange interactions and
spin-orbit-induced effects in these systems. In this work, through a
multi-scale theoretical framework combining density functional theory, spin
Hamiltonian modeling, and Wannier-function analysis, we choose monolayer
CrI$_3$ to unravel how carrier doping affects the isotropic as well as
anisotropic exchange interactions in this prototypical vdW ferromagnet. The
remarkable efficiency of hole doping in enhancing ferromagnetic exchange and
magnetic anisotropy found in our study was explained through orbital-resolved
analysis. Crucially, we demonstrated that unlike the undoped system - where
isotropic exchange interactions govern magnetic long-range order - the
hole-doped CrI$_3$ exhibits anisotropic terms comparable in magnitude to
isotropic ones. Finally, we show that a high concentration of holes in a
CrI$_3$ monolayer can increase its Curie temperature above 200 K. This work
advances our understanding of doping-controlled magnetism in semiconducting 2D
materials, demonstrating how anisotropy engineering can stabilize
high-temperature magnetic order.

</details>


### [178] [The contribution of electron and hole conductivity to the transport loss in organic solar cells](https://arxiv.org/abs/2508.11399)
*Chen Wang,Toni Seiler,Doyoung Sun,Safa Shoaee,Maria Saladina,Carsten Deibel*

Main category: cond-mat.mtrl-sci

TL;DR: 有机太阳能电池的电导率可以通过电流-电压测量直接提取，其有效电导率遵循电子和空穴电导率的谐波平均关系，这与常用的几何平均法不同。


<details>
  <summary>Details</summary>
Motivation: 有机太阳能电池的传输电阻是影响功率转换效率的关键损失因素，准确理解和量化电导率对于器件优化至关重要。

Method: 通过实验测量PM6:Y12共混物的电流-电压特性，并分析其有效电导率与电子和空穴电导率的依赖关系，验证了有效电导率遵循电子和空穴电导率的谐波平均值。

Result: 研究发现，在PM6:Y12共混物中，有效电导率与电子和空穴电导率的乘积成正比，即使在电导率差异高达三个数量级时也成立，证实了谐波平均模型的有效性。

Conclusion: 该研究提出的基于电流-电压测量的有效电导率提取方法，以及电子和空穴电导率的谐波平均关系，为理解和优化有机太阳能电池的电荷传输提供了更准确的框架，并挑战了传统几何平均法的应用。

Abstract: The effective conductivity determines the reciprocal of the transport
resistance, the dominant loss of fill factor in organic solar cells. We
experimentally determine the dependence of effective conductivity on its
electron and hole contributions. Using PM6:Y12 blends with tunable
morphological and energetic disorder, we show that the effective conductivity
follows a harmonic mean of electron and hole conductivities even across nearly
three orders of magnitude in conductivity imbalance. We also validate the
method for directly extracting effective conductivity from current-voltage
measurements, eliminating the need to rely on indirect mobility and charge
carrier density-based proxies. Our findings challenge the widespread use of
geometric mean approximations and offer a more accurate framework for analysing
and modelling transport in disordered organic semiconductors.

</details>


### [179] [Ultrafast X-ray interaction with photovoltaic materials: Thermal and nonthermal responses](https://arxiv.org/abs/2508.11549)
*Aldo Artímez Peña,Nikita Medvedev*

Main category: cond-mat.mtrl-sci

TL;DR: Ultrafast X-ray irradiation of CdTe, PbS, and ITO using XTANT-3 code reveals varying material responses, including thermal and nonthermal melting, band gap tuning, and transient superionic behavior in ITO. Femtosecond lasers show potential for modifying photovoltaic semiconductor band gaps.


<details>
  <summary>Details</summary>
Motivation: To simulate the kinetics of material response to ultrafast X-ray irradiation for important electronic materials like CdTe, PbS, and ITO, and to understand how laser irradiation selectively modifies their semiconductor properties.

Method: Utilizing the hybrid multiscale code XTANT-3 to simulate the kinetics of material response to ultrafast X-ray irradiation, accounting for nonequilibrium electronic and atomic dynamics, nonadiabatic coupling, nonthermal melting, and bond breaking due to electronic excitation.

Result: CdTe demonstrates the highest radiation resistance. Melting is primarily thermal at threshold doses, accompanied by band gap closure, while nonthermal melting occurs at higher doses. Threshold doses increase with energy sinks and recrystallization. Band gaps recover or stabilize at amorphous states with increasing doses. ITO shows transient superionic behavior in a specific dose window. Ablation occurs at 0.6 eV/atom for CdTe and 0.4 eV/atom for PbS and ITO.

Conclusion: Cadmium telluride (CdTe), lead sulfide (PbS), and indium tin oxide (ITO) exhibit varying responses to ultrafast X-ray irradiation, with CdTe showing higher radiation resistance. Melting can be thermal or nonthermal depending on the dose. Including energy sinks and recrystallization increases threshold doses. Band gaps can recover or decrease with increasing dose, leading to amorphous states. ITO displays transient superionic behavior under specific conditions. Material ablation occurs at characteristic doses for each material. The findings suggest femtosecond lasers can tune the band gaps of photovoltaic semiconductors.

Abstract: Cadmium telluride (CdTe), lead sulfide (PbS), and indium tin oxide (ITO) are
important in various electronic technologies, for which laser irradiation is
used to selectively modify and design their unique semiconductor properties. We
employ the hybrid multiscale code XTANT-3 to simulate the kinetics of material
response to ultrafast X-ray irradiation. The code accounts for nonequilibrium
electronic and atomic dynamics, nonadiabatic coupling, nonthermal melting, and
bond breaking due to electronic excitation. Among the materials studied, CdTe
exhibits the highest radiation resistance, similar to CdS. At the respective
threshold doses, the melting is primarily thermal, driven by electron-phonon
coupling, which is accompanied by the band gap closure. Additionally, all
materials show nonthermal melting at higher doses. Threshold doses increase
further if energy sinks and recrystallization are included. In CdTe and PbS,
below 1.5 eV/atom, the band gap returns to its original value upon
recrystallization. As the dose increases, the cooled state becomes more
amorphous, reducing the band gap until it stabilizes. Curiously, in a narrow
window of deposited doses, ITO exhibit transient superionic behavior, with the
liquid oxygen but solid In and Sn sublattices. At 0.6 eV/atom in CdTe and 0.4
eV/atom in PbS and ITO, material ablation from the surface occurs. The results
suggest that femtosecond lasers may be used for tuning the band gap of
photovoltaic semiconductors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [180] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: 本研究提出了一种利用合作博弈解决多标准情境下投票集成模型赋权问题的方法，通过同时考虑多种评价标准来优化权重分配，实验结果证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的投票集成方法在将分类器的先验信息反映到权重时，仅考虑单一评价标准，这限制了在模型中现实地考虑各种信息。

Method: 提出了一种在多标准情境下通过合作博弈来制定决策的方法，该方法可以同时考虑并反映分类器中已知的各种信息，从而实现适当的权重分配和性能提升。

Result: 通过将机器学习算法应用于Open-ML-CC18数据集，并将所提方法与现有的集成赋权方法进行比较，实验结果表明该方法优于其他赋权方法。

Conclusion: 提出了一种在多标准情境下通过合作博弈来制定决策的方法，并进行了实验验证，结果显示该方法优于现有的赋权方法。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [181] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: Apriel-Nemotron-15B-Thinker是一个150亿参数的模型，性能与320亿参数模型相当，但内存占用减半，适用于企业环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在实际企业应用中因高昂的内存和计算成本而受到限制的问题。

Method: 该模型采用了包括基础模型增量训练、持续预训练、监督微调（SFT）以及使用GRPO的强化学习在内的四阶段训练流程。

Result: 在多项基准测试中的综合评估结果表明，Apriel-Nemotron-15B-Thinker模型的性能与同类320亿参数模型相当甚至更优，但模型尺寸却只有后者的一半。

Conclusion: Apriel-Nemotron-15B-Thinker在与320亿参数模型相当的性能下，内存占用却只有他们的一半，尽管模型参数量仅为150亿。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [182] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: 嵌套OpInf通过利用降阶空间中的层次结构，为物理信息降阶模型学习提供了一种改进的初始猜测方法，能够在保持可比的离线时间的情况下减少重建误差，并已在热传导和冰盖模型等问题上展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 该方法旨在通过利用降阶空间中的层次结构来改进OpInf学习问题，优先考虑主导模式的相互作用，从而在学习物理信息降阶模型时获得更小的快照重建误差，并支持动态基和模型形式更新等应用场景。

Method: 提出了一种数据驱动的、嵌套的算子推理（OpInf）方法，用于从高维动力系统的快照数据中学习物理信息约束的降阶模型（ROM）。该方法利用降阶空间中固有的层次结构，为OpInf学习问题迭代地构建初始猜测，优先考虑主要模式的相互作用。

Result: 与标准OpInf相比，嵌套OpInf在三次热传导问题上实现了四倍小的误差，且离线时间相当。在格陵兰冰盖的参数化模型上，学习到的ROM平均误差为3%，计算加速因子大于19,000。

Conclusion: 该方法在三次热传导问题上实现了比标准OpInf小四倍的误差，并且离线时间相当。在格陵兰冰盖的参数化模型上，该方法学习到的ROM平均误差为3%，计算加速因子超过19,000。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [183] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: 由于医学数据共享受限，模型更新困难且易遗忘。本研究提出PCL方法，通过提示池和正则化技术，在提高模型性能的同时降低成本，促进医疗AI发展。


<details>
  <summary>Details</summary>
Motivation: 传统的模型训练方法在处理因数据共享限制而只能在本地进行增量更新的医学数据时，容易出现过拟合和灾难性遗忘的问题。同时，医学数据的分布会因诊断设备和人群的变化而发生偏移。现有的持续学习方法大多针对自然图像，对医学领域的研究不足。

Method: 提出了一种基于提示的持续学习（PCL）方法，该方法包含一个统一的提示池，采用最小化扩展策略，通过扩展和冻结部分提示来降低计算开销。此外，引入了一个新颖的正则化项来平衡知识的保留和适应性。

Result: 在三个糖尿病视网膜病变数据集（Aptos2019、LI2019和Diabetic Retinopathy Detection）上的实验结果显示，与现有先进方法相比，该模型将最终分类准确率提高了至少10%，F1分数提高了9个点，同时降低了推理成本。

Conclusion: 该研究提出了一个名为PCL（prompt-based continual learning）的新方法，通过统一的提示池和最小化扩展策略，结合新的正则化项，有效解决了医学领域中由于数据共享限制而导致的模型更新问题。实验证明，PCL在提高最终分类准确率和F1分数方面，相比现有先进方法有显著提升，同时降低了推理成本。该方法有望推动分布式医疗AI的发展，支持实时诊断、患者监护和远程医疗等应用。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [184] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: Retro-Expert is a new framework that uses LLMs and specialized models with reinforcement learning for interpretable retrosynthesis prediction, outperforming existing methods and providing chemical insights.


<details>
  <summary>Details</summary>
Motivation: Existing retrosynthesis models rely on static pattern-matching, limiting their decision-making abilities and resulting in black-box outcomes. The proposed framework aims to provide interpretable retrosynthesis prediction through collaborative reasoning.

Method: Retro-Expert is an interpretable retrosynthesis framework that combines Large Language Models and specialized models via reinforcement learning. It consists of three components: specialized models for shallow reasoning to create a high-quality chemical decision space, an LLM for critical reasoning to generate predictions and interpretable reasoning paths, and reinforcement learning to optimize the decision policy.

Result: Experiments show that Retro-Expert outperforms both LLM-based and specialized models on various metrics and provides expert-aligned explanations.

Conclusion: Retro-Expert surpasses existing LLM-based and specialized models in retrosynthesis prediction, offering expert-aligned explanations that bridge the gap between AI predictions and actionable chemical insights.

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [185] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: BeyondWeb是一个新的合成数据生成框架，能显著提升LLM预训练性能，速度更快，且在性能上优于现有方法。然而，高质量合成数据的生成需要综合优化多种因素。


<details>
  <summary>Details</summary>
Motivation: 随着LLM预训练数据量的增加，性能提升逐渐遇到瓶颈（数据墙），合成数据成为提高性能的有望途径，但影响合成数据质量的因素尚不明确。

Method: 提出BeyondWeb合成数据生成框架。

Result: BeyondWeb在14项基准评估中平均性能优于Cosmopedia和Nemotron-Synth。BeyondWeb训练速度比Cosmopedia快7.7倍，比Nemotron-Synth快2.7倍。使用BeyondWeb训练的3B模型在180B token上优于在Cosmopedia上训练的8B模型。此外，还提供了关于数据质量影响因素的见解。

Conclusion: 生成高质量的预训练合成数据需要综合优化多个因素，没有一蹴而就的方法。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [186] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 该研究提出了一个名为M&C的T2I模型选择框架，通过匹配图和图嵌入特征，可以高效地预测哪个预训练T2I模型在特定数据集上微调后效果最佳，无需逐一尝试所有模型，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散和Transformer架构的文本到图像（T2I）模型的发展，用户在HuggingFace等平台分享的预训练模型，在进行微调以应用于特定数据集时，面临着一个挑战：如何选择最适合的预训练模型。现有的模型选择方法在分类任务上已有较好的解决，但在T2I模型及其在目标域上的性能指示方面，研究尚不充分。因此，本研究旨在解决T2I模型选择的难题，提出一个能高效选择预训练T2I模型的框架。

Method: 该研究的核心是提出一个名为M&C的选择框架，该框架包含一个匹配图。匹配图由节点（代表可用的模型和已分析的数据集）和边（分别代表模型-数据对的微调性能和数据-数据对的数据相似性）组成。在此基础上，研究构建了一个模型，该模型能够根据输入的模型/数据特征以及从匹配图中提取的关键的图嵌入特征，来预测哪个模型在目标域上进行微调后能获得最佳质量。

Result: 研究在32个数据集上，对10个T2I模型进行了选择评估，并将M&C框架与三个基线方法进行了比较。结果显示，M&C框架在61.3%的情况下成功预测了用于微调的最佳模型，在剩余的情况下也能预测出性能相近的模型。

Conclusion: 该研究提出了首个文本到图像（T2I）模型的选择框架M&C，用于在目标数据集上进行微调时，从模型平台（如HuggingFace）中高效选择合适的预训练T2I模型，而无需对所有模型进行详尽的微调。M&C框架通过一个匹配图来捕捉模型-数据和数据-数据对之间的微调性能和数据相似性，并利用图嵌入特征来预测在目标域上微调后能达到最佳质量的模型。实验结果表明，M&C在选择T2I模型时，有61.3%的情况下能成功预测最佳模型，其余情况也能预测出性能接近的模型。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [187] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: CURE 是一个解决 RLVR 中熵坍塌问题的新框架，通过两阶段方法（高熵关键标记重新生成和稳定训练）提高了 LLM 在数学推理任务上的性能和多样性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 RLVR 管道中，重复使用从数据集中精确抽取的静态初始状态样本导致模型行为过于确定、多样性低、熵快速坍塌以及在长期训练中阻碍持续性能提升的问题。

Method: CURE (Critical-token-gUided Re concatenation for Entropy-collapse prevention) 是一个两阶段框架。第一阶段，通过在高熵的关键标记上进行重新生成，并联合优化原始和分支轨迹，以引导模型探索新颖的上下文。第二阶段，通过 DAPO 使用静态初始状态采样继续训练，以加强利用。

Result: CURE 在 Qwen-2.5-Math-7B 模型上进行了广泛实验，在六个数学基准测试中取得了 5% 的性能增益，在熵和准确性方面均达到最先进水平。

Conclusion: CURE 通过在第一阶段引导模型探索新颖但连贯的上下文，并在第二阶段通过 DAPO 稳定训练，在数学推理任务上取得了显著的性能提升，同时保持了高熵水平以促进探索，并在六个数学基准测试中实现了 5% 的性能增益，在熵和准确性方面均达到最先进水平。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [188] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 该研究将SLTH框架扩展到量化神经网络，证明了在量化设置下离散神经网络可以被精确表示，并确定了所需的初始网络过参数化程度的优化边界。


<details>
  <summary>Details</summary>
Motivation: 解决现有理论研究主要集中在连续域，无法扩展到量化域的问题，为量化神经网络的理论理解提供支持。

Method: 基于Borgs等人在数论分问题上的基础性研究，为量化设置下的随机子集和问题推导出新的理论结果，并将SLTH框架扩展到有限精度网络。

Result: 在量化设置下，证明了离散神经网络的等价类可以被精确表示，并证明了初始网络过参数化程度的优化边界，将SLTH框架成功扩展到有限精度网络。

Conclusion: 该研究将SLTH框架扩展到有限精度网络，证明了在量化设置下，离散神经网络的等价类可以被精确表示，并证明了初始网络过参数化程度的优化边界。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [189] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: Zono-conformal prediction is a new uncertainty quantification method that uses zonotopes for prediction sets, offering computational and data efficiency with strong coverage guarantees, outperforming existing methods in terms of conservativeness.


<details>
  <summary>Details</summary>
Motivation: Current conformal prediction methods are computationally expensive and data-intensive due to the need for pre-calibration uncertainty modeling. Existing interval-based prediction sets also have limitations in capturing dependencies in multi-dimensional outputs. This work addresses these limitations.

Method: Zono-conformal prediction, inspired by interval predictor models and reachset-conformant identification, constructs prediction zonotopes with assured coverage by integrating zonotopic uncertainty sets directly into the base predictor model. Identification is achieved through a single, data-efficient linear program. The method is applicable to arbitrary nonlinear base predictors, with a focus on feed-forward neural networks, and can be applied to both regression and classification tasks.

Result: Zono-conformal predictors are less conservative than interval predictor models and standard conformal prediction methods while achieving similar coverage. The paper also provides methods for detecting outliers in the identification data.

Conclusion: The proposed zono-conformal prediction method offers a computationally efficient and data-efficient alternative to existing uncertainty quantification techniques, achieving competitive coverage with less conservative prediction sets.

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [190] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 本篇论文界定并形式化了“信心”这一概念，它不同于概率或似然，更能捕捉学习率、证据权重等直观概念。研究提出了度量信心的方法，并将其与向量场、损失函数联系起来，最终将贝叶斯规则表述为一种特殊的线性期望损失优化学习器。


<details>
  <summary>Details</summary>
Motivation: 为了表征学习或更新信念时产生的“信心”概念，即对输入信息的信任程度及其对信念状态的影响。

Method: 通过形式化公理化“带信心学习”的含义，提出两种度量信心的方法，并证明其表示。在附加假设下，将基于信心的学习表示为向量场和损失函数，并推导出化合物“并行”观测的扩展语言。

Result: 正式公理化了带信心的学习，给出了两种度量信心的典型方法，并证明信心总是可以以这种方式表示。在附加假设下，推导出了基于信心的学习的更紧凑的表示，即向量场和损失函数，并提出了化合物“并行”观测的扩展语言。将贝叶斯规则表征为损失表示为线性期望的优化学习器的特例。

Conclusion: 本研究为学习或更新信念中出现的“信心”概念提供了形式化定义，并证明了信心可以被表示为一种度量。此外，研究还推导出了基于信心的学习的紧凑表示，并揭示了贝叶斯规则作为一种优化学习器的特例。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [191] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: 即使数据是非高斯分布（广义非正态分布），也可以通过精度矩阵推断条件独立结构，并提出了一种高效的算法。


<details>
  <summary>Details</summary>
Motivation: 对于非高斯分布，传统的协方差和精度矩阵无法像在高斯分布中那样明确地揭示变量的独立性结构。本研究旨在扩展在高斯分布中的发现，即在某些条件下，即使数据是非高斯的，也可以从精度矩阵中推断出条件独立性。

Method: 本文提出了一种基于精度矩阵推断条件独立结构的理论，并开发了一种简单且计算高效的算法来实现这一目标。该算法适用于广义非正态分布，这类分布是通过对高斯分布进行对角变换得到的。

Result: 通过合成实验和真实世界数据的应用，证明了所提出算法的有效性。该算法能够从广义非正态分布数据中成功恢复条件独立结构。

Conclusion: 该研究表明，对于一类称为“广义非正态分布”的非高斯分布，即使它们与高斯分布不同，我们仍然可以从其精度矩阵中推断出变量之间的条件独立结构。这对于理解非高斯数据中的依赖关系具有重要意义。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [192] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: 该研究调查了LIME和SHAP解释方法在有偏见模型中的易感性，并提出了一种新的测试框架来评估和增强这些方法的鲁棒性，以提高机器学习系统的透明度和公平性。


<details>
  <summary>Details</summary>
Motivation: 由于LIME和SHAP等事后解释方法容易受到对抗性操纵，可能隐藏有害偏见，因此本研究旨在调查LIME和SHAP在有偏见模型中的易感性，并评估提高其鲁棒性的策略。

Method: 本研究构建了一个模块化的测试框架，用于系统地评估不同分类器上增强和集成解释方法的性能。使用此框架，研究人员评估了多种LIME/SHAP集成配置在分布外模型上的表现，并将其偏见隐藏抵抗能力与原始方法进行了比较。

Result: 研究发现了能够显著提升偏见检测能力的LIME/SHAP集成配置。

Conclusion: 研究结果发现了能够显著提升偏见检测能力的配置，这表明了在部署高风险机器学习系统时增强透明度的潜力。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [193] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: 提出一种考虑类群丰度的集合Transformer方法，用于生成微生物样本的嵌入，并在分类任务中取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于嵌入的微生物样本表示方法（如简单平均序列嵌入）忽略了类群丰度的生物学重要性，限制了下游任务（如表型预测和环境分类）的性能。

Method: 提出一种基于丰度的集合Transformer变体，通过根据相对丰度对序列嵌入进行加权来构建固定大小的样本级嵌入，并应用基于自注意力的聚合。

Result: 该方法在实际微生物分类任务中表现优于平均池化和未加权的集合Transformer，在某些情况下达到了完美的性能。

Conclusion: 该方法通过结合序列级丰度信息到Transformer的样本嵌入中，为微生物数据提供了更鲁棒和具有生物学意义的表示，并在实际的微生物分类任务中取得了优于平均池化和未加权集合Transformer的性能。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [194] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: This paper uses contraction theory to make neural networks (NODEs) more robust to noise and attacks by ensuring similar inputs lead to similar outputs, verified on image classification tasks.


<details>
  <summary>Details</summary>
Motivation: Neural networks are fragile to input noise and adversarial attacks. This work aims to improve the robustness of continuous-depth neural networks (NODEs) by leveraging contraction theory.

Method: We propose to use contraction theory to improve the robustness of Convolutional Neural Ordinary Differential Equations (NODEs). Contractivity is induced during training using a regularization term involving the Jacobian of the system dynamics or through weight regularization terms for NODEs with slope-restricted activation functions.

Result: Contractive Convolutional NODEs exhibit increased robustness because slight perturbations in features do not lead to significant changes in the output. The effectiveness of the proposed regularizers was shown on image classification tasks with corrupted images.

Conclusion: The proposed regularization terms improve the robustness of Contractive Convolutional NODEs against input noise and adversarial attacks, as demonstrated on MNIST and FashionMNIST datasets.

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [195] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文提出了一种经济可行的预测编码解决方案，用于对即时消息进行分类，通过数据管理、特征选择和逻辑回归，并使用降维技术提高性能。


<details>
  <summary>Details</summary>
Motivation: 由于即时消息的非正式性质和较小的尺寸，在包含即时消息的数据集上使用机器学习进行文档分类（即预测编码）面临额外的挑战。

Method: 文章提出了一种数据管理工作流，用于对即时消息进行分组，然后进行特征选择和逻辑回归分类。通过降维来提高模型性能。

Result: 文章在包含丰富定量信息的Instant Bloomberg数据集上测试了所提出的方法，并提供了成本节约的示例。

Conclusion: 文章提出了一个数据管理工作流，通过将消息分组到每日聊天中，然后进行特征选择和逻辑回归分类，为即时消息数据集提供了一种经济可行的预测编码解决方案。通过降维（特别关注定量特征）来提高解决方案的基线模型性能。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [196] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: Watch time is a flawed proxy for user satisfaction in video recommendations. This paper proposes a framework to correct watch time by comparing it to reference distributions, leading to better recommendations. It also introduces a method to efficiently represent this corrected signal.


<details>
  <summary>Details</summary>
Motivation: Raw watch times are influenced by confounding factors like video duration, popularity, and user behaviors, potentially distorting preference signals and leading to biased recommendation models.

Method: A novel relative advantage debiasing framework that corrects watch time by comparing it to empirically derived reference distributions conditioned on user and item groups. A two-stage architecture separates distribution estimation from preference learning. Distributional embeddings parameterize watch-time quantiles without online sampling or storing historical data.

Result: Significant improvements in recommendation accuracy and robustness compared to existing baseline methods, demonstrated through offline and online experiments.

Conclusion: Watch time debiasing using relative advantage and distributional embeddings improves recommendation accuracy and robustness.

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [197] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 该研究提出了一种压缩元学习框架，利用神经网络优化压缩学习的编码和解码过程，以提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了应对因新数据集快速扩张而产生的对快速高效参数学习技术的需求，压缩学习框架应运而生。然而，现有的编码和解码技术未能利用数据底层结构。

Method: 提出了一种元学习压缩学习框架，利用神经网络来优化编码和解码过程。

Result: 所提出的压缩元学习框架在多个应用中（包括压缩PCA、压缩岭回归、压缩k-means和自动编码器）都优于当前最先进的方法，实现了更快速和更准确的系统。

Conclusion: 该框架通过元学习编码和解码阶段，利用神经网络提供比当前最先进方法更快、更准确的系统，展示了其在神经元网络基础的压缩PCA、压缩岭回归、压缩k-means和自动编码器等多个应用中的潜力。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [198] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 通过多模态融合和加权的 الزمنية 损失，实现了ICD编码的早期预测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决患者住院初期信息有限的预测建模挑战，实现早期预测ICD编码，从而识别健康风险、建议有效治疗或优化资源配置。

Method: 提出了一种多模态系统，融合临床笔记和电子健康记录中的表格事件，集成了预训练编码器、特征池化和跨模态注意力，并采用加权的 الزمنية 损失。

Result: 实验表明，所提出的策略能够提升早期预测模型性能，超越当前最先进的系统。

Conclusion: 该模型通过融合临床笔记和表格事件，并采用加权的 الزمنية 损失，在早期预测ICD编码方面优于现有技术。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [199] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: FGAT, a new framework inspired by HFGN, uses a hierarchical graph and attention mechanism with visual-textual features to improve fashion recommendations by considering both outfit compatibility and user preferences simultaneously.


<details>
  <summary>Details</summary>
Motivation: Addressing outfit compatibility and personalized recommendations simultaneously is challenging due to independent treatment in existing studies, overlooking complex interactions between items and user preferences in fashion e-commerce.

Method: FGAT framework constructs a three-tier hierarchical graph of users, outfits, and items, integrating visual and textual features to simultaneously model outfit compatibility and user preferences. A graph attention mechanism dynamically weights node importance during representation propagation.

Result: FGAT outperforms baseline models like HFGN on the POG dataset in precision, HR, recall, NDCG, and accuracy.

Conclusion: FGAT combined multimodal visual-textual features with a hierarchical graph structure and attention mechanisms to enhance the accuracy and efficiency of personalized fashion recommendation systems.

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [200] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: This paper explores Piecewise-Affine Regularization (PAR) for optimizing problems with discrete variables, particularly in supervised learning. It provides theoretical insights into PAR, showing that it leads to highly quantized solutions in overparameterized settings. The study also derives practical methods for solving PAR-regularized problems and demonstrates that PAR can achieve statistical guarantees comparable to traditional regularization techniques while producing quantized results.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of optimization problems with discrete or quantized variables due to their complex search spaces, by leveraging the flexible modeling and computational framework of piecewise-affine regularization (PAR) based on continuous optimization.

Method: The paper analyzes the theoretical foundations of PAR from optimization and statistical perspectives. It demonstrates that in the overparameterized regime, critical points of the PAR-regularized loss function exhibit high quantization. It also derives closed-form proximal mappings for various PARs and solves PAR-regularized problems using proximal gradient methods and ADMM.

Result: The paper shows that in the overparameterized regime, every critical point of the PAR-regularized loss function exhibits a high degree of quantization. It derives closed-form proximal mappings for various PARs and demonstrates their solvability using proximal gradient methods and ADMM. Furthermore, it studies the statistical guarantees of PAR-regularized linear regression, showing approximations to classical formulations with similar statistical guarantees.

Conclusion: PAR-regularized linear regression problems can approximate classical formulations and achieve similar statistical guarantees with quantized solutions.

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [201] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: CTRL is a meta-learning method that improves ML predictions accuracy and preserves source-level heterogeneity, outperforming benchmarks on large-scale datasets.


<details>
  <summary>Details</summary>
Motivation: Machine learning (ML) tasks often utilize large-scale data that is drawn from several distinct sources, practitioners often desire predictions that not only exhibit good overall accuracy, but also remain reliable within each source and preserve the differences that matter across sources.

Method: CTRL, a meta-learning method that combines the strengths of cross-domain residual learning and adaptive pooling/clustering in order to simultaneously improve overall accuracy and preserve source-level heterogeneity.

Result: CTRL navigates the trade-off between data quantity and data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5 large-scale datasets. CTRL consistently outperforms the benchmarks across several key metrics and when using a range of different base learners.

Conclusion: CTRL consistently outperforms the benchmarks across several key metrics and when using a range of different base learners.

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [202] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 提出了一种名为NeuralKDB的新型高阶贝叶斯网络分类器，通过学习特征值的分布表示来解决传统贝叶斯网络分类器在处理复杂数据时的局限性。实验证明，NeuralKDB在捕捉高阶特征依赖关系方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于参数爆炸和数据稀疏性问题，传统的贝叶斯网络分类器仅限于低阶特征依赖性建模，难以推断复杂现实世界数据的出现概率。需要一种新的方法来设计高阶贝叶斯网络分类器。

Method: 通过学习特征值的分布表示来设计高阶贝叶斯网络分类器，并重新设计了KDB，使其成为神经版本（NeuralKDB），利用新颖的神经网络架构来学习特征值的分布表示并参数化相互依赖特征之间的条件概率。设计了一种基于随机梯度下降的算法来有效地训练NeuralKDB模型。

Result: 所提出的NeuralKDB分类器通过学习分布表示，能够有效地捕捉高阶特征依赖关系，并在60个UCI数据集的广泛分类实验中表现出优于传统贝叶斯网络分类器和其他竞争性分类器的性能。

Conclusion: 提出的NeuralKDB分类器在捕捉高阶特征依赖关系方面表现出色，并且显著优于传统的贝叶斯网络分类器以及其他具有竞争力的分类器，包括两个没有分布表示学习的基于神经网络的分类器。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [203] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: 本研究探讨了物联网多模态在线联邦学习（MMO-FL）中的模态数量和质量不平衡（QQI）问题，并提出了一种名为QQR的算法来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 随着边缘智能的发展，物联网设备能够处理异构多模态数据，这需要分布式学习范式。同时，边缘设备的存储限制和数据的连续性需要在线学习框架。MMO-FL虽然有前景，但面临设备不稳定性导致的数据模态数量和质量不平衡（QQI）挑战。

Method: 提出了一种名为QQR的算法，这是一种基于原型学习的方法，与训练过程并行操作，以解决MMO-FL中的模态数量和质量不平衡问题。

Result: 提出的QQR算法在两个真实世界的跨模态数据集上进行了广泛的实验，结果表明在模态不平衡的条件下，QQR算法的表现优于基准算法，并具有良好的学习性能。

Conclusion: MMO-FL面临的模态数量和质量不平衡（QQI）问题，并提出了一个名为QQR的算法，通过原型学习来解决这个问题。实验证明，QQR在模态不平衡的情况下表现优于其他算法。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [204] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种半监督生成模型，用于解决多视图学习中的缺失视图和缺失标签问题。该模型能有效利用标记和未标记数据，并通过跨视图互信息最大化来提升性能，在图像和多组学数据上均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图学习方法虽然在处理缺失视图问题上取得了进展，但IB框架的局限性在于其完全监督的性质，无法利用未标记数据。因此，有必要开发一种能够同时处理缺失视图和缺失标签，并有效利用未标记数据的半监督方法。

Method: 提出了一种半监督生成模型，该模型利用标记和未标记样本，并通过最大化未标记样本的似然来学习与信息瓶颈（IB）共享的潜在空间。此外，还通过在潜在空间中执行跨视图互信息最大化来增强跨视图共享信息的提取。

Result: 与现有方法相比，本模型在图像和多组学数据上实现了更好的预测和填充性能，尤其是在存在缺失视图和有限标记样本的情况下。

Conclusion: 本研究提出的半监督生成模型通过联合利用标记和未标记样本，并在潜在空间中进行跨视图互信息最大化，从而增强了跨视图共享信息的提取，在具有缺失视图和有限标记样本的图像和多组学数据上均取得了比现有方法更好的预测和填充性能。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [205] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: 本研究提出了 QBM-VAE，一种混合量子-经典深度学习模型，利用量子计算机从玻尔兹曼分布中采样，解决了传统深度学习模型在处理复杂生物数据时的局限性。该模型在处理大规模单细胞数据集时表现优于现有模型，并在科学发现方面展现了实际的量子优势。


<details>
  <summary>Details</summary>
Motivation: 为了克服概率深度学习中主要依赖高斯先验的局限性，高斯先验无法准确捕捉自然数据复杂的非高斯景观，尤其是在复杂的生物数据等要求苛刻的领域，严重阻碍了模型在科学发现中的保真度。玻尔兹曼分布提供了一种更具表现力的替代方案，但在经典计算机上计算上不可行。

Method: 本研究引入了一种名为量子玻尔兹曼机-变分自编码器（QBM-VAE）的大规模、长时间稳定的混合量子-经典架构。该框架利用量子处理器从玻尔兹曼分布中进行高效采样，并将其作为深度生成模型中的强大先验。

Result: QBM-VAE 在处理来自多个来源的百万级单细胞数据集时，生成的潜在空间能更好地保留复杂的生物结构，在 omics 数据集成、细胞类型分类和轨迹推理等基本任务中始终优于 VAE 和 SCVI 等传统基于高斯分布的深度学习模型。

Conclusion: 本研究展示了在大型科学问题上深度学习的实际量子优势，并为开发混合量子人工智能模型提供了可转移的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [206] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 提出了一种基于调制的元学习框架，用于结构保持的动力学建模，通过将模型条件化于系统参数的潜在表示来克服现有方法的局限性，实现了跨参数族的、可扩展且可泛化的学习，并在少样本设置中取得了准确的预测结果。


<details>
  <summary>Details</summary>
Motivation: 现有的结构保持方法通常针对固定的系统配置进行训练，需要显式的系统参数知识，并且在每次更改参数时都需要昂贵的重新训练，这在许多查询或参数变化的情况下是一个主要限制。虽然元学习提供了一种潜在的解决方案，但现有的基于优化的元学习方法往往存在训练不稳定或泛化能力有限的问题。

Method: 提出了一种基于调制的元学习框架，该框架直接将结构保持模型条件化于潜在的、未知的系统参数的紧凑潜在表示，从而避免了对灰色盒系统知识和适应期间显式优化的需求。

Result: 在标准基准问题上，我们的方法在少样本学习设置中实现了准确的预测，同时保持了动态稳定性和跨参数空间的有效泛化性能所必需的基本物理约束。

Conclusion: 通过新颖的调制策略将结构保持模型应用于参数化能量守恒和耗散系统，实现了跨越动态系统参数族的、可扩展且可泛化的学习。在标准基准问题上的实验表明，我们的方法在少样本学习设置中实现了准确的预测，同时不影响动态稳定性和跨参数空间的有效泛化性能所必需的基本物理约束。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [207] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: BFF框架通过借鉴后期数据信息来改进早期风险评估的预测能力。


<details>
  <summary>Details</summary>
Motivation: 临床上希望能够尽早进行可靠的风险评估，但早期风险评估的预测精度通常不如后期评估。因此，本研究旨在提高早期风险评估的预测性能。

Method: 研究提出了一种名为“Borrowing From the Future (BFF)”的对比多模态框架，该框架将每个时间窗口视为一个独立的模态。在训练过程中，模型会利用所有可用数据，并在进行风险评估时使用最新信息。这种对比框架使得模型能够借鉴后期阶段（如儿童健康访视）的有用信号，来隐式地指导早期阶段（如产前/出生阶段）的学习。

Result: 在两个真实世界的儿科结局预测任务中，BFF均表现出一致的改进，提高了早期风险评估的准确性。

Conclusion: 该研究通过对比学习框架Borrowing From the Future (BFF)，利用后期数据（如儿童健康访视）的信号来隐式监督早期阶段（如产前/出生）的学习，从而提高了早期风险评估的预测性能。研究在两个儿科风险预测任务中验证了BFF的有效性，并展示了其在早期风险评估方面的持续改进。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [208] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: This paper uses causal abstraction to explain computational implementation in cognitive science and machine learning, focusing on representation, generalization, and prediction.


<details>
  <summary>Details</summary>
Motivation: Explanations of cognitive behavior often appeal to computations over representations. This work explores what it takes for a system to implement a given computation over suitable representational vehicles within that system.

Method: We provide an account of computational implementation grounded in causal abstraction and examine the role of representation.

Result: We illustrate how classical themes in the philosophy of computation and cognition resurface in contemporary machine learning, specifically in deep learning with artificial neural networks.

Conclusion: We argue that computational implementation is best understood through causal abstraction, with representation playing a key role, particularly in relation to generalization and prediction.

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [209] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: 提出了一种混合CNN-LSTM模型来预测PM2.5浓度，该模型结合了CNN的空间特征提取能力和LSTM的时间依赖性建模能力。实验结果优于传统模型，但在处理多元输入时计算资源需求较高，且对复杂大气因素的处理能力有待优化。


<details>
  <summary>Details</summary>
Motivation: 随着全球气候变化的加剧，空气质量指标（尤其是PM2.5浓度）的准确预测在环境保护、公众健康和城市管理等领域变得越来越重要。

Method: 提出了一种基于混合CNN-LSTM架构的空气质量PM2.5指数预测模型，利用CNN提取局部空间特征，利用LSTM对时间序列数据中的时间依赖性进行建模。

Result: 实验结果显示，该模型预测的PM2.5平均浓度（6小时间隔）的均方根误差（RMSE）为5.236，在准确性和泛化能力方面优于传统时间序列模型。

Conclusion: 该模型在PM2.5浓度预测方面表现出巨大潜力，可用于空气污染预警系统。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [210] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: An enhanced map matching algorithm improves GPS trajectory reconstruction accuracy and applicability by integrating imputation, optimized voting, and OpenStreetMap data.


<details>
  <summary>Details</summary>
Motivation: To reconstruct GPS trajectories with high accuracy, independent of input data quality, and to extend the applicability of the original algorithm to diverse real-world scenarios.

Method: The enhanced version of the Interactive Voting-Based Map Matching algorithm integrates trajectory imputation and a distance-bounded interactive voting strategy to reduce computational complexity. It also includes modifications to address missing data in the road network and uses a custom-built asset derived from OpenStreetMap.

Result: The enhanced algorithm preserves the core strengths of the original algorithm while significantly extending its applicability.

Conclusion: The enhanced algorithm can process trajectories with varying sampling rates and reconstruct GPS trajectories with high accuracy, regardless of input data quality. It is applicable to any geographic region covered by OpenStreetMap.

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [211] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR:  GODNF 通过节点特定的行为建模和动态邻域影响来克服现有 GNN 的局限性，以实现异构扩散和可解释性，并在各种任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的 GNN 方法存在三个关键限制：(1) 依赖于具有静态动态的同质扩散，难以适应不同的图结构；(2) 由于计算开销和可解释性下降，其深度受到限制；(3) 其收敛行为的理论理解仍然有限。

Method: 提出了一种名为 GODNF 的广义意见动力学神经网络框架，该框架将多种意见动力学模型统一为一种原则性的、可训练的扩散机制。该框架通过节点特定的行为建模和动态邻域影响来捕获异构扩散模式和时间动态，同时确保即使在深层网络中也能实现高效且可解释的消息传播。

Result: GODNF 能够模拟不同的收敛配置，并且在节点分类和影响估计任务上的表现优于最先进的 GNN。

Conclusion: GODNF 在节点分类和影响估计任务上优于最先进的 GNN。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [212] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 本研究提出了一种通过提示从闭合权重 LLM 中提取公平分类器的框架，以解决上下文学习中的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的公平性执行方法无法用于 GPT-4、Gemini 和 Claude 等闭合权重 LLM 的上下文学习。

Method: 该框架将 LLM 视为特征提取器，并通过精心设计的提示从其概率预测中提取特征，以获得公平分类的充分统计数据，然后采用后验方法应用公平算法训练轻量级公平分类器。

Result: 实验表明，该框架在准确性-公平性权衡方面表现出色，并且数据效率高。

Conclusion: 该框架从开放权重和闭合权重 LLM 中提取的分类器在准确性-公平性权衡方面表现出色，并且具有数据效率，优于在 LLM 嵌入或原始表格特征上训练的公平分类器。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [213] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: This paper introduces RTE, a method to make Spiking Neural Networks more resistant to adversarial attacks by improving the robustness of their temporal components and reducing how vulnerabilities spread over time. Experiments show RTE works better than current methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the poor understanding and vulnerability of Spiking Neural Networks (SNNs) to adversarial perturbations by revisiting their robustness through the lens of temporal ensembling, which reveals challenges like the fragility of individual temporal sub-networks and adversarial vulnerability transfer across time.

Method: The paper proposes Robust Temporal self-Ensemble (RTE), a training framework that improves the robustness of each sub-network while reducing the temporal transferability of adversarial perturbations by integrating both objectives into a unified loss and employing a stochastic sampling strategy for efficient optimization.

Result: RTE consistently outperforms existing training methods in the robust-accuracy trade-off across multiple benchmarks. It reshapes the internal robustness landscape of SNNs, leading to more resilient and temporally diversified decision boundaries.

Conclusion: Spiking Neural Networks (SNNs) are vulnerable to adversarial perturbations, but this work proposes Robust Temporal self-Ensemble (RTE) to improve their robustness by treating the network as evolving sub-networks across timesteps. RTE integrates objectives to enhance sub-network robustness and reduce adversarial transferability, outperforming existing methods and reshaping SNNs' internal robustness for more resilient and temporally diversified decision boundaries.

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [214] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: HS-GPPT通过混合光谱滤波器和对比学习，并设计提示图来对齐预训练和下游任务的光谱，解决了现有图预训练方法在处理不同同质性图时的局限性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的图预训练和提示调整方法依赖于基于同质性的低频知识，未能处理具有不同同质性的现实世界图中多样化的光谱分布。当预训练和下游任务的光谱存在较大差异时，在有限的监督下，知识转移的有效性会受到阻碍。

Method: HS-GPPT模型框架，它利用混合光谱滤波器骨干和局部-全局对比学习来获取丰富的谱知识，并通过设计提示图来对齐光谱分布与预训练任务，促进谱知识跨同质性和异质性的转移。

Result: 所提出的HS-GPPT模型在转导和归纳学习设置下均表现出有效性，成功解决了现有方法在处理不同光谱分布图时的局限性。

Conclusion: 图的预训练和提示调整通过在预训练目标下对齐下游任务来实现，从而在有限的监督下实现有效的知识转移。然而，现有的方法依赖于基于同质性的低频知识，未能处理现实世界图中具有不同同质性的多样光谱分布。我们的理论分析揭示了光谱特异性原理：最优知识转移需要预训练光谱滤波器与下游图的内在光谱对齐。在有限的监督下，预训练和下游任务之间的光谱间隙会阻碍有效的适应。为了弥合这一差距，我们提出了HS-GPPT模型，一个在预训练和提示调整过程中确保光谱对齐的新颖框架。我们利用混合光谱滤波器骨干和局部-全局对比学习来获取丰富的谱知识。然后，我们设计提示图，将光谱分布与上文对齐，促进跨同质性和异质性的谱知识转移。广泛的实验验证了在转导和归纳学习设置下的有效性。我们的代码可在https://anonymous.4open.science/r/HS-GPPT-62D2/获得。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [215] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: RegimeNAS是一个新的架构搜索框架，通过整合市场状态感知来提高加密货币交易性能。它使用贝叶斯搜索空间、动态神经模块和多目标损失函数。实验证明，与现有方法相比，RegimeNAS的性能显著提高，收敛速度更快。


<details>
  <summary>Details</summary>
Motivation: 金融环境高度动态，传统的静态深度学习模型难以适应。因此，需要一种能够感知和适应不同市场状态（如趋势、波动性或区间交易）的架构搜索方法，以提高交易性能。

Method: RegimeNAS是一个新颖的可微分架构搜索框架，它明确地整合了市场状态感知，以增强加密货币交易表现。其核心创新包括：1.一个经过理论验证的贝叶斯搜索空间，优化具有可证明收敛特性的架构；2.专门的、动态激活的神经模块（波动性、趋势和范围模块），以适应不同的市场条件；3.多目标损失函数，整合了市场特定惩罚（例如，波动性匹配、转换平滑度）和数学上强制执行的Lipschitz稳定性约束。

Result: 在广泛的真实加密货币数据上进行的严格实证评估表明，RegimeNAS显著优于最先进的基准。与最好的传统循环基线相比，平均绝对误差（MAE）降低了80.3%，并且收敛速度更快（9个epoch vs 50+个epoch）。消融研究和特定状态分析证实了每个组件的关键贡献，特别是状态感知的适应机制。

Conclusion: RegimeNAS通过将市场状态感知直接嵌入神经结构搜索（NAS）过程，为金融等动态领域开发鲁棒且自适应的模型提供了一个重要的范例。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [216] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: CP methods have imbalanced coverage on long-tail data. TACP and sTACP are proposed to fix this by being tail-aware and using reweighting, improving minority class predictions.


<details>
  <summary>Details</summary>
Motivation: Existing CP methods exhibit imbalanced coverage across classes under long-tail distributions, leading to under coverage of minority classes, which undermines reliability.

Method: Conformal Prediction (CP) converts a pretrained model's point prediction into a prediction set. Tail-Aware Conformal Prediction (TACP) utilizes the long-tail structure to narrow the head-tail coverage gap. Soft TACP (sTACP) further improves coverage balance via a reweighting mechanism.

Result: TACP consistently achieves a smaller head-tail coverage gap than standard methods. Experiments demonstrate the effectiveness of TACP and sTACP on multiple long-tail benchmark datasets.

Conclusion: TACP and sTACP are proposed to mitigate the under coverage of tail classes and improve coverage balance, showing effectiveness on long-tail datasets.

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [217] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: NeMo is a new method for making deep learning models smaller and easier to reuse by breaking them into modules during training. It works on different types of models, including large ones like Transformers, and improves performance while reducing size.


<details>
  <summary>Details</summary>
Motivation: Existing MwT methods are limited to small-scale CNN models at the convolutional kernel level and struggle with diverse DNNs and large-scale models, particularly Transformer-based models. There is a need for a scalable and generalizable MwT approach to address the prohibitive construction costs of DNN models in software systems.

Method: NeMo proposes a scalable and generalizable MwT approach that operates at the neuron level, ensuring applicability to Transformers and various architectures. It utilizes a contrastive learning-based modular training method with a composite loss function for scalability to large-scale models.

Result: Comprehensive experiments on Transformer-based and CNN models demonstrate NeMo

Conclusion: NeMo is a scalable and generalizable modularizing-while-training (MwT) approach that operates at the neuron level, making it applicable to diverse DNN architectures including Transformers. It outperforms existing MwT methods, achieving significant gains in module classification accuracy and reduction in module size. NeMo also shows potential benefits in practical scenarios through a case study on open-source projects.

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [218] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: 该研究通过整合一手信息和卫星数据，创建了一个大规模的全球植树造林项目数据集，并提出了位置数据完整性评分（LDIS）来评估项目数据的可靠性，发现大部分项目存在地理位置数据问题。


<details>
  <summary>Details</summary>
Motivation: 应对当前植树造林和再造林项目在碳汇增加方面的效果常依赖于项目开发者自行报告或有限的外部验证，导致数据可靠性和项目完整性受到质疑，增加了自愿碳市场的审查压力。

Method: 通过整合一手（元）信息，并结合时间序列卫星图像和其他二手数据，构建了一个全球植树造林和再造林项目数据集。引入了位置数据完整性评分（LDIS）来评估地理位置信息的准确性。

Result: 开发了一个包含1,289,068个种植点、45,628个项目、覆盖33年的全球植树造林和再造林数据集。评估显示，79%的地理参考种植点至少在一个LDIS指标上存在问题，15%的项目缺乏机器可读的地理数据。

Conclusion: 该研究构建了一个包含1,289,068个种植点和45,628个项目的全球植树造林和再造林项目数据集，涵盖33年历史。研究发现，约79%的地理参考种植点在至少一个位置数据完整性（LDIS）指标上存在缺陷，15%的项目缺乏机器可读的地理数据。该数据集旨在提高自愿碳市场的透明度和问责制，并可作为计算机视觉任务的训练数据。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [219] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: HGD 是一种新的梯度下降算法，通过平衡梯度范数来解决不平衡数据流问题，无需数据缓冲或额外参数，并且在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中普遍存在的、按时间顺序收集且具有偏斜类别分布的（即不平衡）数据流学习问题。

Method: 通过调整梯度下降技术，引入了 harmonized gradient descent (HGD) 算法，该算法旨在平衡不同类别的梯度范数。

Result: HGD 实现了令人满意的次线性遗憾界限，并且在各种不平衡数据流场景下，相比于常用的在线不平衡学习方法，在广泛的实验评估中证明了其效率和有效性。

Conclusion: HGD 算法在处理不平衡数据流方面高效且有效，在减少次类欠拟合和实现均衡在线学习方面表现出色。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [220] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: 本研究提出了一种新的测试时强化学习（TTRL）方法，通过引入熵机制来解决现有TTRL方法的局限性，提高了大型语言模型在无监督推理任务中的表现和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在无监督场景下适应性有限、以及现有测试时强化学习（TTRL）方法面临的高推理成本和早期估计偏差等问题。

Method: 本文提出了一种基于熵的机制，包括熵-叉树多数滚动（ETMR）和基于熵的优势重塑（EAR）两种策略，以增强测试时强化学习中的探索-利用平衡。

Result: 与基线方法相比，本文提出的方法使Llama3.1-8B在AIME 2024基准测试上实现了68%的Pass at 1指标相对提升，同时仅消耗了60%的滚动令牌预算。

Conclusion: 该方法通过引入基于熵的机制，在测试时强化学习中增强了探索-利用平衡，解决了现有TTRL方法面临的高推理成本和早期估计偏差问题。实验结果表明，该方法能有效优化推理效率、多样性和估计鲁棒性之间的权衡，从而推动了用于开放域推理任务的无监督强化学习的发展。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [221] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: PTSM框架通过解耦时空模式和潜在嵌入，实现了跨受试者的EEG解码，提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 跨受试者脑电图（EEG）解码由于受试者间的变异性和受试者不变表征的稀缺性，仍然是脑机接口（BCI）研究中的一个根本挑战。

Method: PTSM（生理感知和任务不变时空建模）框架，采用双分支掩码机制来独立学习个性化和共享的时空模式，并通过信息论约束将潜在嵌入分解为正交的任务相关和受试者相关子空间。模型通过整合分类、对比度和解耦目标的多目标损失进行端到端训练。

Result: PTSM在跨受试者运动想象数据集上的实验证明，其实现了强大的零样本泛化能力，在没有受试者特定校准的情况下，性能优于最先进的基线模型。

Conclusion: PTSM通过解耦的神经表征在非平稳神经生理学环境中实现了个性化和可迁移的解码，在跨受试者运动想象任务中实现了强大的零样本泛化能力，优于最先进的基线模型。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [222] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: DFA is a reinforcement learning algorithm that combines individual rewards and pairwise preferences, outperforming existing methods in control environments and GridWorld.


<details>
  <summary>Details</summary>
Motivation: To fuse both individual rewards and pairwise preferences into a single update rule for reinforcement learning.

Method: DFA uses the policy's log-probabilities directly to model the preference probability, avoiding a separate reward-modeling step. Preferences can be provided by human-annotators or be synthesized online from Q-values. Under a Bradley-Terry model, minimizing DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC) policy.

Result: DFA trained on generated preferences matches or exceeds SAC on six control environments and demonstrates a more stable training process. DFA outperforms reward-modeling RLHF baselines in a stochastic GridWorld and approaches the performance of an oracle with true rewards.

Conclusion: DFA matches or exceeds SAC on six control environments and demonstrates a more stable training process. With only a semi-synthetic preference dataset under Bradley-Terry model, DFA outperforms reward-modeling RLHF baselines in a stochastic GridWorld and approaches the performance of an oracle with true rewards.

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [223] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: Gradient-based DFL for LPs often fails due to zero gradients. Smoothing doesn't fix this. Minimizing surrogate losses works better, even with differentiable layers like DYS-Net, leading to similar or better results with much faster training.


<details>
  <summary>Details</summary>
Motivation: Existing gradient-based DFL approaches for LPs struggle because the gradient of the regret with respect to predicted parameters is often zero. Smoothing the LP or minimizing surrogate losses are common workarounds. This paper aims to address the limitations of smoothing methods and demonstrate the effectiveness of minimizing surrogate losses, even with differentiable optimization layers.

Method: The paper proposes minimizing surrogate losses for decision-focused learning (DFL) with linear programs (LPs), even when a differentiable optimization layer is used. This approach is applied to DYS-Net, a differentiable optimization technique for LPs, to compute approximate solutions and gradients using feedforward neural networks.

Result: Experiments show that minimizing surrogate losses with differentiable optimization layers achieves regret comparable to or better than existing DFL methods. When applied to DYS-Net, this approach achieves state-of-the-art regret while significantly reducing training time.

Conclusion: DFL methods that minimize surrogate losses can achieve regret comparable to or better than existing methods, even when using a differentiable optimization layer. Applying this to DYS-Net significantly reduces training time while maintaining state-of-the-art regret. Therefore, minimizing surrogate losses is a viable and efficient approach for DFL, particularly with differentiable optimization techniques for LPs.

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [224] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: Geometric and Topological Deep Learning uses lifting to transform data to expressive topologies. This paper proposes a structural lifting strategy using Forman-Ricci curvature to represent network backbones as hyperedges, overcoming information distortion and over-squashing in graph learning.


<details>
  <summary>Details</summary>
Motivation: Leverage higher-order topological domains and structures in real-world systems (e.g., social, biological networks) for improved Graph Neural Network performance, specifically addressing information distortion and over-squashing in message passing across long distances.

Method: Utilized Forman-Ricci curvature to define an edge-based network characteristic based on Riemannian geometry, capturing local and global graph properties to identify network backbones represented as hyperedges.

Result: Successfully provided a remedy to information distortion and over-squashing in message passing across long distances and graph bottlenecks by representing network backbones as hyperedges.

Conclusion: Proposed a structural lifting strategy using Forman-Ricci curvature to address information distortion and over-squashing in graph learning by representing network backbones as hyperedges.

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [225] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: CHORD框架通过动态加权将SFT作为RL的辅助目标，有效解决了现有方法易破坏模型模式和过拟合的问题，实现了更稳定、更高效的学习，并在实验中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SFT和RL集成方法存在破坏模型固有模式和过拟合专家数据的风险。

Method: 提出了一种名为CHORD（可控谐波的在线离线强化学习动态加权）的框架，该框架将SFT视为在线RL过程中的一个动态加权辅助目标，并结合了全局系数和逐令牌加权函数，以协调离线模仿和在线探索，同时保留在线探索并减轻离线数据的影响。

Result: CHORD在广泛使用的基准测试中取得了稳定的学习过程和显著的性能提升，证明了其有效性。

Conclusion: CHORD通过有效协调离线专家数据和在线探索，显著优于基线方法，实现了稳定高效的学习过程。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [226] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: LEAD是一个创新的抗体设计框架，通过在共享潜在空间优化序列和结构，显著提高了效率和性能，并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原始数据空间中优化抗体CDRs以改善可开发性，导致搜索效率低下，评估成本过高。LEAD旨在解决这个问题，通过在共享潜在空间中进行优化，打破现有方法的局限性，并确保不同模式设计的同步。

Method: 提出了一种名为LEAD（LatEnt blAck-box Design）的框架，该框架是一个序列-结构共设计框架，在共享的潜在空间中同时优化抗体序列和结构。LEAD采用黑盒引导策略来处理不可微的属性评估器。

Result: 实验结果表明，LEAD在优化单属性和多属性目标时，查询消耗减少了一半，同时优化性能超过了基线方法。

Conclusion: LEAD框架在单属性和多属性优化目标上都取得了优于基线方法的性能，并且在保证优化性能的同时，将查询消耗降低了一半。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [227] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: mCOCO是一个利用水库计算和多感觉输入的新框架，用于学习连接性大脑模板（CBT），解决了现有方法的局限性，并在评估中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有CBT学习方法存在可解释性差、计算成本高、仅关注结构和拓扑而忽略了CBT的认知能力等局限性。为了解决这些挑战，mCOCO框架利用水库计算（RC）从BOLD信号中学习群体级功能CBT。

Method: mCOCO框架包括两个阶段：(1) 将BOLD信号映射到水库以导出个体功能连接组，然后将它们聚合为群体级CBT；(2) 通过认知水库整合多感觉输入，为CBT赋予认知特征。

Result: mCOCO-based template在中心性、区分性、拓扑健全性和多感觉记忆保持方面显著优于GNN-based CBT。

Conclusion: mCOCO框架在中心性、区分性、拓扑健全性和多感觉记忆保持方面显著优于基于GNN的CBT。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [228] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: 解释复杂机器学习模型很困难，许多现有方法可能无效。本文提出了一种评估解释有效性的理论框架，发现许多流行方法（如 SHAP）在特定模型上效果不佳，并提出了改进方向，这对 AI 的可靠应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有局部事后解释算法在解释复杂机器学习模型行为时缺乏理论保证的问题，并探究在何种条件下这些算法能提供有意义的解释。

Method: 本文提出了一种基于学习理论的通用框架，用于评估解释算法在多大程度上能提供关于决策函数的信息。通过分析，证明了许多流行的解释算法（如梯度解释、反事实解释、SHAP 和锚点解释）在应用于复杂模型（如可微分函数和决策树）时可能不具有信息性。

Result: 证明了许多流行的解释算法（例如梯度解释、反事实解释、SHAP 和锚点解释）在应用于复杂决策函数（例如可微分函数和决策树）时可能不具有信息性。此外，推导了不同解释算法在特定条件下具有信息性的条件，并提出了修改现有算法以提高其信息性的方法。

Conclusion: 许多流行的解释算法在应用于复杂决策函数时会失效，但本文提出了修改这些算法以使其更具信息性的方法，并讨论了其在审计、监管和高风险人工智能应用中的实际意义。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [229] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 本研究评估了六种概率机器学习算法的不确定性估计特性。结果表明，虽然所有算法都经过了良好校准，但基于深度学习的算法在处理分布外数据时不确定性估计存在不足。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习等日益复杂的数据模型出现，不确定性量化变得越来越困难，并提出了大量的技术。本研究旨在评估这些算法在不确定性估计方面的特性。

Method: 本研究使用近似贝叶斯推断的统一框架，并结合在精心设计的合成分类数据集上进行的经验测试，研究了六种不同的概率机器学习算法在类别概率和不确定性估计方面的特性：(i) 神经网络集成，(ii) 具有冲突损失的神经网络集成，(iii) 证据深度学习，(iv) 具有蒙特卡洛 Dropout 的单个神经网络，(v) 高斯过程分类和 (vi) 狄利克雷过程混合模型。

Result: 所有算法都经过了良好校准，但没有一种基于深度学习的算法提供的估计量能够持续反映出分布外数据点缺乏实验证据的情况。

Conclusion: 所有算法都经过了良好校准，但没有一种基于深度学习的算法提供的估计量能够持续反映出分布外数据点缺乏实验证据的情况。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [230] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: 该研究使用AutoML和可解释AI分析了超过300万起车祸数据，识别出影响车祸严重性的关键因素，并提出了一个支持交通安全政策的数据驱动框架。


<details>
  <summary>Details</summary>
Motivation: 为了理解和减轻车祸的严重性，需要数据驱动的方法。

Method: 该研究结合了自动化机器学习（AutoML）和可解释人工智能（AI），利用JADBio AutoML平台构建预测模型，并通过SHapley Additive exPlanations（SHAP）解释模型。

Result: 该研究使用的数据集包含超过300万人在俄亥俄州发生的事故记录，最终的Ridge Logistic Regression模型在训练集上的AUC-ROC为85.6%，在测试集上为84.9%，识别出17个关键预测因素，这些因素涵盖了人口统计、环境、车辆、人类和操作类别。

Conclusion: 该研究提供了一个可扩展的框架，以支持“零愿景”行动，并通过一致的干预措施和先进的数据驱动的交通安全政策。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [231] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: 本研究提出 GraphOracle，一种用于 GNN 的自解释框架，可生成忠实的类级别解释，并证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了确保 GNN 的安全和公平部署，增强 GNN 的可解释性至关重要。先前的工作集中在实例级别解释，但类级别解释的有效性仍不确定。本研究旨在开发一种能够生成和评估类级别解释的 GNN 框架，并评估先前方法的类级别解释能力。

Method: GraphOracle 框架通过集成训练联合学习 GNN 分类器和一组结构化、稀疏的子图，这些子图对每个类具有区分性。它使用基于掩码的评估策略来评估类级别解释的有效性，并采用熵正则化子图选择和轻量级随机游走提取来避免计算瓶颈。

Result: GraphOracle 在保真度、可解释性和可扩展性方面优于先前的方法，并能避免计算瓶颈。先前的 GNN 方法（如 ProtGNN 和 PGIB）未能提供有效的类级别解释。

Conclusion: GraphOracle 是一个新颖的自解释 GNN 框架，旨在为 GNN 生成和评估类级别解释。它通过集成训练联合学习 GNN 分类器和一组结构化、稀疏的子图，这些子图对每个类具有区分性。与先前的方法（如 ProtGNN 和 PGIB）不同，GraphOracle 实现了优越的保真度、可解释性和可扩展性，并避免了计算瓶颈，是 GNN 中忠实的类级别自可解释性的实用且有原则的解决方案。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [232] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 为了解决现有关键测试场景生成方法在平衡多样性和关键性方面的局限性，我们提出了一种双空间引导测试框架，通过协调场景参数空间和代理行为空间来生成考虑多样性和关键性的测试场景。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中部署决策代理的需求不断增长，增加了安全性验证的需求。现有的关键测试场景生成方法在平衡多样性和关键性方面面临挑战，尤其是在高维场景空间中容易陷入局部最优。

Method: 提出了一种双空间引导测试框架，该框架协调场景参数空间和代理行为空间。在场景参数空间中，采用分层表示框架，结合降维和多维子空间评估，以有效本地化多样化和关键化的子空间，指导局部扰动和全局探索两种生成模式之间的动态协调。在代理行为空间中，利用代理-环境交互数据量化行为的关键性/多样性，并自适应地支持生成模式切换，形成一个闭环反馈，不断增强场景表征和参数空间内的探索。

Result: 实验表明，与最先进的基线相比，所提出的框架在五个决策代理上进行了测试，在关键场景生成方面平均提高了56.23%，并在新颖的参数-行为协同驱动指标下展示了更强的多样性。

Conclusion: 所提出的框架通过协调场景参数空间和代理行为空间，并在场景参数空间中采用分层表示框架（结合降维和多维子空间评估）来有效平衡多样性和关键性，从而提高了关键场景的生成效果，并优于现有方法。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [233] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 在无限宽度下，NTK易于计算，但缺少NTK演化和特征学习等特性。本文提出使用Feynman图计算有限宽度修正，以包含这些重要特性，并推导出预测训练动态的层级递推关系。


<details>
  <summary>Details</summary>
Motivation: 为了在分析深度神经网络时，在有限宽度下考虑NTK演化和特征学习等重要特性，并推导出可预测训练动态的解析结果。

Method: 引入Feynman图来计算有限宽度修正，并推导出任意涉及preactivations、NTK和dNTK、ddNTK的统计量的层级递推关系。

Result: 推导出了计算有限宽度修正的Feynman图方法，并展示了其在扩展深度网络稳定性结果和证明ReLU等尺度不变非线性在Gram矩阵对角线上无有限宽度修正方面的可行性。

Conclusion: Feynman图可以用来计算有限宽度NTK统计量的修正，并已通过数值实验得到验证。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [234] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: 一种新的无监督异常检测方法，使用物理信息扩散模型和加权的物理信息损失函数，在多变量时间序列上提高了性能。


<details>
  <summary>Details</summary>
Motivation: 为了改进扩散模型在多变量时间序列数据上的无监督异常检测性能，通过引入物理信息来更准确地近似底层数据分布。

Method: 提出一种基于物理信息扩散模型的无监督异常检测方法，在训练过程中使用加权的物理信息损失函数来学习多变量时间序列数据的物理依赖时间分布。

Result: 实验结果表明，物理信息训练提高了异常检测的F1分数，并产生了更好的数据多样性和对数似然度。该模型在合成和真实世界数据集上表现优于基线方法，并在特定数据集上超越了先前基于物理信息和纯数据驱动的扩散模型。

Conclusion: 该方法通过物理信息训练改进了无监督异常检测性能，提高了F1分数、数据多样性和对数似然度。在合成和真实世界数据集上，该模型优于基线方法，并在特定数据集上超越了先前基于物理信息和纯数据驱动的扩散模型。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [235] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: HXAI is a new framework that makes AI models more transparent and trustworthy by explaining them at every stage of the data analysis workflow, tailored to different users. It addresses limitations of current methods by considering the entire process and using AI agents with LLMs to communicate findings effectively.


<details>
  <summary>Details</summary>
Motivation: Many users still regard AI models as opaque 'black boxes'. Conventional explainable AI methods clarify individual predictions but overlook upstream decisions and downstream quality checks that determine whether insights can be trusted. HXAI aims to address this by providing a holistic approach to explainability.

Method: HXAI unifies six components (data, analysis set-up, learning process, model output, model quality, communication channel) into a single taxonomy and aligns each component with the needs of domain experts, data analysts, and data scientists. It uses an 112-item question bank and analyzes contemporary tools to identify coverage gaps. The framework is grounded in theories of human explanation, principles from human-computer interaction, and findings from empirical user studies.

Result: HXAI identifies characteristics that make explanations clear, actionable, and cognitively manageable. Its taxonomy reduces terminological ambiguity and enables rigorous coverage analysis of existing toolchains. AI agents embedding LLMs can orchestrate diverse explanation techniques to translate technical artifacts into stakeholder-specific narratives.

Conclusion: HXAI presents a user-centric framework that embeds explanation into every stage of the data-analysis workflow and tailors explanations to users, operationalizing insights into a taxonomy to reduce ambiguity and enable rigorous coverage analysis of existing toolchains. It also demonstrates how AI agents with LLMs can orchestrate explanation techniques to bridge the gap between AI developers and domain experts, advancing an end-to-end viewpoint on transparency, trustworthiness, and responsible AI deployment.

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [236] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: DFed-SST是一种去中心化的联邦图学习框架，通过自适应通信机制来应对数据异质性问题，并在多个真实数据集上取得了优于现有方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的DFL优化策略主要为计算机视觉等任务设计，未能解决本地子图的独特拓扑信息。虽然FGL适用于图数据，但它主要在中心化的服务器-客户端模型中实现，未能利用去中心化的优势。

Method: 提出了一种名为DFed-SST的去中心化联邦图学习框架，该框架具有自适应通信。该方法的核心是一种双拓扑自适应通信机制，它利用每个客户端本地子图的独特拓扑特征来动态构建和优化客户端间通信拓扑。

Result: 在平均准确率方面比基线方法提高了3.26%。

Conclusion: DFed-SST框架在八个真实世界数据集上的广泛实验一致证明了其优越性，在平均准确率方面比基线方法提高了3.26%。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [237] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow is a server-based RL framework that decouples training from execution and maximizes GPU utilization for industrial-scale RL by using a data plane, trajectory manager, and tag-driven scheduling.


<details>
  <summary>Details</summary>
Motivation: The paper addresses two main challenges in industrial-scale RL: decoupling training from complex agent execution flows and maximizing GPU utilization with minimal idle time while maintaining stability and scalability.

Method: SeamlessFlow employs a data plane to decouple the RL trainer from agent implementations, a central trajectory manager for partial rollouts, and a tag-driven scheduling paradigm with spatiotemporal multiplexing to dynamically reassign idle training nodes.

Result: SeamlessFlow enables stable and high-performance RL training, effectively handling complex scenarios by maximizing GPU utilization and decoupling training from execution.

Conclusion: SeamlessFlow is a stable and high-performance framework suitable for complex RL tasks like multi-agent and long-horizon scenarios. It achieves this by decoupling RL training from agent execution and maximizing GPU utilization through a tag-driven scheduling paradigm and spatiotemporal multiplexing.

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [238] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: 本研究利用马尔可夫博弈和强化学习，为具有不同目标和约束的多个CCS项目参与者提供了一个最优管理框架，以应对地质共享和基础设施利用带来的复杂性。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多个部门的利益相关者，其目标和职责各不相同。鉴于CCS的复杂性、规模和长期性，确定利益相关者是独立最大化自身利益还是需要协作达成一致，是CCS项目规划和管理的核心问题。尤其是在地质连通的场地，共享地质特征可能导致利益相关者之间的竞争。此外，利用现有基础设施，将CCS站点设在已开发过的区域，使得单方面优化更加复杂和不现实。

Method: 提出了一种基于马尔可夫博弈的范式，将多方、多位点的CCS问题构建为具有安全约束的多智能体强化学习问题。同时，为了应对高保真模型模拟的高计算成本，采用了基于Embed-to-Control（E2C）框架的代理模型。

Result: 研究结果证明了所提出框架在处理涉及多方利益相关者及其不同目标和目标的CO2封存最优管理方面的有效性。

Conclusion: 该研究提出的基于马尔可夫博弈的框架能够有效解决多方参与的碳捕获与封存（CCS）项目的最优管理问题，并能在遵守安全规定的前提下，帮助各方学习最优策略。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [239] [Chiral Phonons in Graphyne](https://arxiv.org/abs/2508.11040)
*Subhendu Mishra,Arpan Chakraborty,Douglas S. Galvao,Pedro A. S. Autreto,Abhishek Kumar Singh*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过掺杂打破石墨炔的对称性，实现了手性声子的存在，并发现了其角动量可被掺杂剂调控，为开发新型声子器件提供了可能。


<details>
  <summary>Details</summary>
Motivation: 手性声子（具有圆偏振和非零角动量的量子化晶格振动）为声子和量子器件工程提供了新的视角。石墨炔因其独特的晶格几何、谷结构电子能带和热传输能力，可能是一种有潜力实现手性声子的材料。然而，由于存在宇称（P）和时间反转（T）对称性，石墨炔中的手性声子仍未被探索。

Method: 通过原子选择性取代掺杂（B、N、ortho BN共掺杂）打破联合的PT对称性，观察并证明了6-6-12和γ-石墨炔中手性声子的存在，并研究了掺杂剂的电子亲和力与手性声子角动量之间的关系。

Result: 石墨炔中的B、N掺杂剂和ortho BN共掺杂剂在6-6-12和γ-石墨炔中诱导了局部结构变形，抬升了偏离Γ点的声子简并度，产生了圆偏振振动模式。发现了手性声子角动量与掺杂剂电子亲和力之间的强相关性，即富电子掺杂剂增加了局部电子密度，可以使手性声子模式更有效地与电子环境耦合，从而增加了声子角动量，表明电子-声子相互作用在手性声子的角动量调制中起着潜在作用。

Conclusion: 通过原子选择性取代掺杂打破了联合的PT对称性，首次证明了石墨炔中存在手性声子，为调控手性声子行为提供了可调的途径，为开发先进的声子器件铺平了道路。

Abstract: Chiral phonons, quantized lattice vibrations with circular polarization and
non-zero angular momentum, offer new perspectives for phononic and quantum
device engineering. Graphyne could be a promising candidate due to its unique
lattice geometry, valley-structured electronic bands, and thermal transport
capabilities. However, chiral phonons in graphyne remain unexplored owing to
the existence of inversion ($\mathscr{P}$) and time-reversal ($\mathscr{T}$)
symmetries. Herein, we have demonstrated the existence of chiral phonons in
graphynes, achieved by breaking combined $\mathscr{PT}$ symmetry through
atomic-selective substitutional doping. We find that the B, N, dopants and
ortho BN co-dopant in 6-6-12 and $\gamma$-graphynes induce localized structural
deformations. These deformations lift phonon degeneracies away from $\Gamma$
point and give rise to circularly polarized vibrational modes. We further
established a strong correlation between chiral phonon angular momentum and
electron affinity of dopants. Electron-rich dopants increase local electron
density which could enable chiral phonon modes to couple more effectively with
electronic environment. This in turn increases phonon angular momentum,
indicating potential role of electron-phonon interactions in angular momentum
modulation of chiral phonons. Our prosposed approach provides a tunable route
for controlling chiral phonon behavior, paving way for development of advanced
phononic devices.

</details>


### [240] [Frequency Dependence of Phonon-Induced Current Noise in ArmchairCarbon Nanotube](https://arxiv.org/abs/2508.11199)
*Raimu Akimoto,Aina Sumiyoshi,Takahiro Yamamoto*

Main category: cond-mat.mes-hall

TL;DR: 碳纳米管中的电流噪声在高频下显示出多个共振峰，这可能与非谐声子有关。


<details>
  <summary>Details</summary>
Motivation: 研究碳纳米管中由声子引起的电流噪声的频率依赖性，特别是高频下的多峰现象，以理解电子-声子相互作用。

Method: 通过理论研究，分析了碳纳米管在室温下声子引起的电流噪声的频率依赖性。

Result: 在 АРМЧАТЫЕ углеродных нанотрубок 中，在 АРМЧАТЫЕ углеродных нанотрубок 中观察到多峰的频率依赖性，这超出了洛伦兹线型的预期。

Conclusion: 本研究揭示了在高温下，碳纳米管中由声子引起的电流噪声在 АРМЧАТЫЕ углеродных нанотрубок 中表现出多峰的频率依赖性，其中一些峰的出现可能与电子-非谐声子的相互作用有关。

Abstract: We theoretically investigate the frequency dependence of phonon-induced
current noise in armchair carbon nanotubes at room temperature. Our results
reveal the emergence of multiple resonance peaks in the high-frequency regime,
which cannot be accounted for by the Lorentzian lineshape expected from a
Markovian process. The electron-phonon scattering processes responsible for
most of these peaks are identified based on energy and momentum conservation
laws and conventional selection rules. However, certain peaks cannot be fully
explained within the framework of harmonic phonon scattering, suggesting the
involvement of nontrivial interactions between electrons and anharmonic
phonons.

</details>


### [241] [Statistical Properties of Current Noise Induced by Electron-Phonon Scattering in Metallic Carbon Nanotubes](https://arxiv.org/abs/2508.11201)
*Aina Sumiyoshi,Keisuke Ishizeki,Takahiro Yamamoto*

Main category: cond-mat.mes-hall

TL;DR: Current noise in carbon nanotubes changes from Gaussian to gamma distribution depending on the regime, showing asymmetry and non-Markovian effects in the diffusive regime.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the need to theoretically understand current noise in metallic carbon nanotubes, specifically focusing on the probability density function (PDF) that characterizes the nonequilibrium steady state.

Method: The paper employs quantum transport simulations and analyses of higher-order statistical moments to investigate current noise induced by electron-phonon scattering in metallic carbon nanotubes.

Result: The PDF of the current transitions from a Gaussian to a gamma distribution as the system moves from the ballistic to the diffusive regime. Pronounced asymmetry is observed in the crossover regime, and non-Markovian features are identified in the diffusive regime, influencing the current variance scaling.

Conclusion: The study reveals that the probability density function of current noise in metallic carbon nanotubes evolves from Gaussian to gamma distribution across ballistic and diffusive regimes, with non-Gaussian features and non-Markovian effects observed in the diffusive regime due to high-frequency resonances.

Abstract: We theoretically investigate current noise in metallic carbon nanotubes
induced by electron-phonon scattering, focusing on the probability density
function (PDF) of the current that characterizes the nonequilibrium steady
state. Quantum transport simulations combined with analyses of higher-order
statistical moments reveal that the PDF evolves continuously from a Gaussian
distribution in the ballistic regime to a non-Gaussian gamma distribution in
the diffusive regime. In the crossover regime, the PDF exhibits pronounced
asymmetry, attributed to a statistical imbalance in the number of conduction
pathways contributing to high- and low-current events. Furthermore, in the
diffusive regime, we identify non-Markovian features arising from
high-frequency resonances in the current noise, which dominate the asymptotic
scaling behavior of the current variance.

</details>


### [242] [Optically Controlled Skyrmion Number Current](https://arxiv.org/abs/2508.11209)
*Emir Syahreza Fadhilla,M Shoufie Ukhtary,Ardian Nata Atmaja,Bobby Eka Gunara*

Main category: cond-mat.mes-hall

TL;DR: 通过控制斯格明子数流来控制磁性斯格明子的运动。


<details>
  <summary>Details</summary>
Motivation: 提出一种通过产生斯格明子数流来控制磁性斯格明子运动的机制。

Method: 采用一阶微扰方法处理Landau-Lifshitz-Gilbert方程，并使用基于Belavin-Polyakov剖面的呼吸斯格明子ansatz。

Result: 时间依赖的斯格明子边界变形产生各向异性呼吸模式，进而产生非零斯格明子数流。动量空间中的动力学形成一个极限环，其特性仅取决于外磁场幅度、海森堡交换耦合和吉尔伯特阻尼常数。

Conclusion: 本文提出的机制可以控制磁性斯格明子的运动，其通过产生斯格明子数流来实现。该电流由显含时间依赖性的哈密顿量诱导和调节，该哈密顿量包含由自旋系统与圆偏振光相互作用产生的塞曼项。该方法不仅阐明了光驱动斯格明子运动的拓扑起源，还指出了斯格明子数流作为一种低耗散的替代方案，可用于有效控制斯格明子。

Abstract: We propose a mechanism to control the motion of magnetic Skyrmions through
the generation of a Skyrmion number current. This current is induced and tuned
by an explicitly time-dependent Hamiltonian that includes a Zeeman term arising
from the interaction between the spin system and circularly polarized light. To
capture the effect, we apply a first-order perturbation method to the
Landau-Lifshitz-Gilbert equation, using a breathing Skyrmion ansatz based on
the Belavin-Polyakov profile. This approach reveals that the time-dependent
deformation of the Skyrmion boundary produces an anisotropic breathing mode,
which in turn generates a nonzero Skyrmion number current. The resulting
dynamics in momentum space form a limit cycle, whose characteristics depend
solely on the external magnetic field amplitude, the Heisenberg exchange
coupling, and the Gilbert damping constant. Our formulation not only clarifies
the topological origin of optically driven Skyrmion motion but also points to
Skyrmion number currents as a low-dissipation alternative to electric currents
for efficient Skyrmion control.

</details>


### [243] [Dissipation-Induced Steady States in Topological Superconductors: Mechanisms and Design Principles](https://arxiv.org/abs/2508.11242)
*M. S. Shustin,S. V. Aksenov,I. S. Burmistrov*

Main category: cond-mat.mes-hall

TL;DR: Researchers explored topological superconductors with Majorana modes in dissipative environments, finding a way to stabilize steady states using controlled dissipation. They linked equilibrium and non-equilibrium 'zero modes' and showed it works on a Kitaev chain model.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the importance of finding conditions that support degenerate steady states in nonequilibrium topological superconductors, which is crucial for advancing dissipative quantum engineering.

Method: The research utilizes the Gorini-Kossakowski-Sudarshan-Lindblad framework and third quantization formalism to investigate topological superconductors with unpaired Majorana modes subjected to environmental dissipative fields. A key aspect involves deriving an algebraic relation between equilibrium Majorana zero modes and non-equilibrium kinetic zero modes, based on hybridization between single-particle wavefunctions and linear dissipative fields.

Result: A correspondence between equilibrium Majorana zero modes and non-equilibrium kinetic zero modes is established. An algebraic relation is derived linking the numbers of these excitations to hybridization and dissipative fields. This leads to a proposed method for stabilizing degenerate steady states in topological superconductors via dissipation engineering, demonstrated on the BDI-class Kitaev chain.

Conclusion: The study establishes a correspondence between equilibrium and non-equilibrium zero modes in topological superconductors under dissipative fields, proposing a practical method for stabilizing degenerate steady states through controlled dissipation engineering. The framework is demonstrated on the BDI-class Kitaev chain.

Abstract: The search for conditions supporting degenerate steady states in
nonequilibrium topological superconductors is important for advancing
dissipative quantum engineering, a field that has attracted significant
research attention over the past decade. In this study, we address this problem
by investigating topological superconductors hosting unpaired Majorana modes
under the influence of environmental dissipative fields. Within the
Gorini-Kossakowski-Sudarshan-Lindblad framework and the third quantization
formalism, we establish a correspondence between equilibrium Majorana zero
modes and non-equilibrium kinetic zero modes. We further derive a simple
algebraic relation between the numbers of these excitations expressed in terms
of hybridization between the single-particle wavefunctions and linear
dissipative fields. Based on these findings, we propose a practical recipes how
to stabilize degenerate steady states in topological superconductors through
controlled dissipation engineering. To demonstrate their applicability, we
implement our general framework in the BDI-class Kitaev chain with long-range
hopping and pairing terms -- a system known to host a robust edge-localized
Majorana modes.

</details>


### [244] [Realistic modelling of transport properties at finite tempeature in magnetic materials by local quantization of a Heisenberg model](https://arxiv.org/abs/2508.11405)
*Fabian Engelke,Christian Heiliger*

Main category: cond-mat.mes-hall

TL;DR: 研究人员开发了一种结合从头算起计算和原子模型的新方法，以更准确地描述磁性材料的电阻率，特别是考虑了自旋无序的温度效应。


<details>
  <summary>Details</summary>
Motivation: 现有理论难以准确描述磁性材料的电阻率，尤其是在考虑自旋无序贡献方面，这是一个关键的挑战。

Method: 使用从头算起的输运计算和原子模型，结合海森堡模型的半经典局域量子化方法，来描述温度依赖的自旋无序。

Result: 该方法能够更准确地描述自旋无序对电阻率的贡献，并且能够研究居里温度附近及以上的温度效应，克服了先前基于平均场理论的方法的局限性。

Conclusion: 这项工作结合了从头算起的输运计算和原子模型来描述磁性材料中与自旋相关的电阻率，并取得了显著的改进。

Abstract: The quantitative description of the electrical resistivity of a magnetic
material remains challenging to this day. Qualitatively, it is well understood
that the temperature-induced lattice and spin disorder determines the
temperature dependence of the resistivity. While prior publications reached
good agreement with experiment in the so-called supercell or direct approach
for non-magnetic materials where the spin-disorder contribution to the
resistivity is negligible, an accurate, purely theoretical description of
magnetic materials remains elusive. This shortcoming can be attributed to the
missing accuracy in the description of the temperature-dependent spin-disorder
itself. In this work, we employ a joint approach from \textit{ab-initio}
transport calculations and atomistic modeling of the temperature-dependent
spin-disorder. Using the example of $\alpha$-Fe, we demonstrate that the
inclusion of quantum mechanical effects using a semiclassical local
quantization of the Heisenberg model significantly improves the description of
the spin-disorder component to the electrical resistivity. Compared to previous
approaches, this model includes the description of magnetic short-range order
effects, enabling us to study temperature effects around and above the Curie
temperature, where prior mean-field theory-based approaches inevitably
predicted a constant contribution.

</details>


### [245] [Spin-to-charge-current conversion in altermagnetic candidate RuO$_2$ probed by terahertz emission spectroscopy](https://arxiv.org/abs/2508.11481)
*J. Jechumtál,O. Gueckstock,K. Jasenský,Z. Kašpar,K Olejník,M. Gaerner,G. Reiss,S. Moser,P. Kessler,G. De Luca,S. Ganguly,J. Santiso,D. Scheffler,J. Zázvorka,P. Kubaščík,H. Reichlova,E. Schmoranzerova,P. Němec,T. Jungwirth,P. Kužel,T. Kampfrath,L. Nádvorník*

Main category: cond-mat.mes-hall

TL;DR: 在 RuO$_2$ 薄膜中，各向异性逆自旋霍尔效应在 THz 发射中起主导作用，而不是 altermagnetic 逆自旋裂变效应。


<details>
  <summary>Details</summary>
Motivation: 为了量化分析可能导致测量的 THz 发射各向异性的竞争效应，包括 RuO$_2$ 的各向异性逆自旋裂变和自旋霍尔效应、RuO$_2$ 的各向异性电导率以及 TiO$_2$ 衬底的双折射。

Method: 使用 THz 发射光谱技术，研究了外延 RuO$_2$ 薄膜中的超快自旋到电荷的电流转换。

Result: 研究发现，在室温下，各向异性逆自旋霍尔效应是测量的主要贡献者，平均自旋霍尔角为 $2.4	imes 10^{-3}$。相比之下，由 altermagnetic 逆自旋裂变效应引起的可能贡献低于 $2	imes 10^{-4}$。

Conclusion: 通过 THz 发射光谱研究了外延 RuO$_2$ 薄膜中的超快自旋到电荷的电流转换。 结果表明，各向异性逆自旋霍尔效应是测得的信号的主要贡献者，在室温下平均自旋霍尔角为 $2.4	imes 10^{-3}$，而外延性反自旋裂变效应的贡献低于 $2	imes 10^{-4}$。该研究强调了仔细区分由非常规的 altermagnetic 顺序引起的自旋相关现象与相对论自旋轨道耦合效应的重要性。

Abstract: Using the THz emission spectroscopy, we investigate ultrafast spin-to-charge
current conversion in epitaxial thin films of the altermagnetic candidate
RuO$_2$. We perform a quantitative analysis of competing effects that can
contribute to the measured anisotropic THz emission. These include the
anisotropic inverse spin splitter and spin Hall effects in RuO$_2$, the
anisotropic conductivity of RuO$_2$, and the birefringence of the TiO$_2$
substrate. We observe that the leading contribution to the measured signals
comes from the anisotropic inverse spin Hall effect, with an average spin-Hall
angle of $2.4\times 10^{-3}$ at room temperature. In comparison, a possible
contribution from the altermagnetic inverse spin-splitter effect is found to be
below $2\times 10^{-4}$. Our work stresses the importance of carefully
disentangling spin-dependent phenomena that can be generated by the
unconventional altermagnetic order, from the effects of the relativistic
spin-orbit coupling.

</details>


### [246] [Exceptionally deficient topological square-root insulators](https://arxiv.org/abs/2508.11490)
*Subhajyoti Bid,Henning Schomerus*

Main category: cond-mat.mes-hall

TL;DR: 非厄米拓扑绝缘体可通过格点和规则实现例外缺陷，并展现出独特的动力学特征。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米物理系统的非线性响应和对微扰的脆弱性，特别是例外点的概念，并在此基础上提出了例外缺陷的概念。

Method: 本研究提出了一种通过格点和规则强制实现例外缺陷的机制。

Result: 识别了静态宽带放大和非阿贝尔绝热态放大动力学特征，区分了体效应和边界效应，并提出了在物理平台上实现的途径。

Conclusion: 本研究提出了一种通过格点和规则强制实现例外缺陷的机制，该机制适用于非厄米拓扑绝缘体。

Abstract: One of the most surprising features of effectively non-Hermitian physical
systems is their potential to exhibit a striking nonlinear response and
fragility to small perturbations. This feature arises from spectral
singularities known as exceptional points, whose realization in the spectrum
typically requires fine-tuning of parameters. The design of such systems
receives significant impetus from the recent conception of \emph{exceptional
deficiency}, in which the entire energy spectrum is composed of exceptional
points. Here, we present a concrete and transparent mechanism that enforces
exceptional deficiency through lattice sum rules in non-Hermitian topological
square-root insulators. We identify the resulting dynamical signatures in
static broadband amplification and non-Abelian adiabatic state amplification,
differentiate between bulk and boundary effects, and outline routes to
implementation in physical platforms

</details>


### [247] [Gating upconversion electroluminescence in a single molecule via adsorption-induced interaction of unpaired spin](https://arxiv.org/abs/2508.11501)
*Vibhuti N. Rai,Christof Holzer,Carsten Rockstuhl,Wulf Wulfhekel,Lukas Gerhard*

Main category: cond-mat.mes-hall

TL;DR: 通过结合 STM 和 DFT 研究了单层钒酞菁分子的电致发光，发现上转换电致发光受分子吸附几何形状调控，这归因于激发态重排和跃迁概率增强，为调控分子电致发光和自旋相关现象提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 提出未配对电子（自由基）分子作为闭壳层分子的替代品，因为它们在电致发光中的自旋统计限制较少。

Method: 结合扫描隧道显微镜诱导的发光和密度泛函理论，研究了单层钒酞菁分子的性质。

Result: 观察到上转换电致发光受到分子吸附几何形状的调控，并归因于激发态的重排和激发态跃迁概率的增强。

Conclusion: vanadyl phthalocyanine 分子在 NaCl/Au(111) 表面上，由于其两种不同的吸附几何形状，导致未配对电子与衬底的相互作用不同，这影响了发光过程。研究发现，上转换电致发光受到分子吸附几何形状的调控，这归因于激发态的重排和激发态跃迁概率的增强。这种未配对电子通过状态重排产生的深刻影响，为调控分子电致发光和其他依赖于自旋的现象开辟了新的可能性。

Abstract: Molecules with unpaired spins (radicals) offer promising alternatives to
closed-shell molecules as they are less limited regarding the spin statistics
in their electroluminescence. Here, we combine scanning tunneling microscopy
induced luminescence and density functional theory to study single vanadyl
phthalocyanine molecules, which are stable neutral radicals. Two distinct
adsorption geometries of the molecule on NaCl/Au(111) lead to a difference in
the interaction of the unpaired electron with the substrate, which in turn
allows us to investigate its effects on the light emission process. Remarkably,
we observe that up-conversion electroluminescence is gated by the adsorption
geometry of the molecule, an effect we attribute to a reordering of excited
states and enhanced excited state transition probabilities. The profound
influence of the unpaired electron via state reordering opens new possibilities
for tuning not only molecular electroluminescence but also many other spin
dependent phenomena.

</details>


### [248] [A non-Hermitian Su-Schrieffer-Heeger model with the energy levels of free parafermions](https://arxiv.org/abs/2508.11601)
*Edward McCann*

Main category: cond-mat.mes-hall

TL;DR: 本研究基于嵌套厄米紧束缚模型，生成了具有p个轨道/晶胞的自由费米子非厄米模型，并推广了手征对称性。研究阐述了单向跳跃对模型的影响，并以SSH模型和石墨烯为例进行了验证，同时发现了高阶厄米点。


<details>
  <summary>Details</summary>
Motivation: 为了在嵌套厄米紧束缚模型框架下，探索和生成具有p个轨道/晶胞的自由费米子非厄米模型，并理解其手征对称性的复杂推广以及单向跳跃对能谱和模型特性的影响。

Method: 本研究采用嵌套厄米紧束缚模型，利用p个轨道/晶胞的自由费米子模型，并通过一个复数推广的手征对称性，理论上生成了非厄米模型。研究分析了全单向跳跃和部分单向跳跃对布洛赫哈密顿量的影响，以及其对实能量谱演化为复数能谱的影响。通过SSH模型（p=3和p=4）和石墨烯的例子，展示了该方法。

Result: 通过嵌套厄米紧束缚模型，成功生成了具有p个轨道/晶胞的自由费米子非厄米模型，并证明了其与Baxter非厄米时钟模型的自由费米子解具有相同的单粒子能级。研究详细分析了单向跳跃对布洛赫哈密顿量的影响，以及由此导致的能谱演化。对于p=3和p=4的SSH模型以及石墨烯，研究展示了该方法的可行性和普适性。此外，还发现了高阶厄米点出现在非厄米SSH模型的边缘态、孤子以及非厄米石墨烯的狄拉克点。

Conclusion: 该研究提出了利用嵌套厄米紧束缚模型生成具有p个轨道/晶胞的自由费米子的非厄米模型，这些模型满足手征对称性的复杂推广。研究详细阐述了单向跳跃和部分单向跳跃对布洛赫哈密顿量的影响，以及由此产生的能谱演化。特别地，研究以p=3和p=4的SSH模型以及石墨烯为例进行了详细分析，并揭示了非厄米SSH模型和石墨烯中的高阶厄米点出现在边缘态、孤子和狄拉克点。

Abstract: Using a parent Hermitian tight-binding model on a bipartite lattice with
chiral symmetry, we theoretically generate non-Hermitian models for free
fermions with $p$ orbitals per unit cell satisfying a complex generalization of
chiral symmetry. The $p$ complex energy bands in $k$ space are given by a
common $k$-dependent real factor, determined by the bands of the parent model,
multiplied by the $p$th roots of unity. When the parent model is the
Su-Schrieffer-Heeger (SSH) model, the single-particle energy levels are the
same as those of free parafermion solutions to Baxter's non-Hermitian clock
model. This construction relies on fully unidirectional hopping to create Bloch
Hamiltonians with the form of generalized permutation matrices, but we also
describe the effect of partial unidirectional hopping. For fully bidirectional
hopping, the Bloch Hamiltonians are Hermitian and may be separated into even
and odd parity blocks with respect to inversion of the orbitals within the unit
cell. Partially unidirectional hopping breaks the inversion symmetry and mixes
the even and odd blocks, and the real energy spectrum evolves into a complex
one as the degree of unidirectionality increases, with details determined by
the topology of the parent model and the number of orbitals per unit cell, $p$.
We describe this process in detail for $p=3$ and $p=4$ with the SSH model. We
also apply our approach to graphene, and show that $AA$-stacked bilayer
graphene evolves into a square root Hamiltonian of monolayer graphene with the
introduction of unidirectional hopping. We show that higher-order exceptional
points occur at edge states and solitons in the non-Hermitian SSH model, and at
the Dirac point of non-Hermitian graphene.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [249] [Distributed Integrated Sensing, Localization, and Communications over LEO Satellite Constellations](https://arxiv.org/abs/2508.11029)
*Yuchen Zhang,Francis Soualle,Musa Furkan Keskin,Yuan Liu,Linlong Wu,José A. del Peral-Rosado,Bhavani Shankar M. R.,Gonzalo Seco-Granados,Henk Wymeersch,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: LEO卫星利用分布式协同技术DISLAC，提升6G网络性能。


<details>
  <summary>Details</summary>
Motivation: 解决LEO卫星功率、天线孔径和在轨处理能力有限的挑战，以满足6G应用的需求。

Method: 提出了一种分布式集成传感、定位和通信（DISLAC）的概念，并进行了系统级分析。

Result: 通过案例研究量化了DISLAC的优势，并分析了同步、天线可重构和ISL设计等关键系统级考虑因素。

Conclusion: LEO卫星星座通过ISL实现DISLAC，可提升吞吐量、定位精度和感知鲁棒性，并指出了未来的研究方向。

Abstract: Low Earth orbit (LEO) satellite constellations are rapidly becoming essential
enablers of next-generation wireless systems, offering global broadband access,
high-precision localization, and reliable sensing beyond terrestrial coverage.
However, the inherent limitations of individual LEO satellites, including
restricted power, limited antenna aperture, and constrained onboard processing,
hinder their ability to meet the growing demands of 6G applications. To address
these challenges, this article introduces the concept of distributed integrated
sensing, localization, and communication (DISLAC) over LEO constellations,
inspired by distributed multiple input multiple output architectures. By
enabling inter-satellite cooperation through inter-satellite links, DISLAC can
substantially improve throughput, positioning accuracy, and sensing robustness.
We present illustrative case studies that quantify these benefits and analyze
key system-level considerations, including synchronization, antenna
reconfigurability, and ISL design. The article concludes by outlining open
research directions to advance the practical deployment of DISLAC in future
non-terrestrial networks.

</details>


### [250] [Multi-Satellite Cooperative MIMO Transmission: Statistical CSI-Aware RSMA Precoding Design](https://arxiv.org/abs/2508.11132)
*Sangwon Jo,Seok-Hwan Park*

Main category: eess.SP

TL;DR: 在低地球轨道（LEO）卫星通信系统中，利用合作传输和多输入多输出（MIMO）预编码技术，并基于统计信道状态信息（sCSI）提出了一种新的率分裂多址（RSMA）方案，以提高频谱效率。该方案通过优化算法解决了信道状态信息获取的难题，并取得了与瞬时信道状态信息（iCSI）方案相当的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高低地球轨道（LEO）卫星通信系统的频谱效率，并解决瞬时信道状态信息（iCSI）获取困难的问题

Method: 通过设计多输入多输出（MIMO）预编码，针对合作率分裂多址（RSMA）进行优化，并提出一种基于加权最小均方误差的算法来获得平稳点

Result: 仿真结果表明，该方案能够有效提高频谱效率并表现出良好的性能

Conclusion: 提出的基于sCSI的RSMA方案性能接近基于iCSI的方案，并且显著优于传统的空分多址

Abstract: We investigate inter-satellite cooperative transmission in a multiple
low-Earth orbit (LEO) satellite communication system to enhance spectral
efficiency. Specifically, we design multiple-input multipleoutput (MIMO)
precoding at LEO satellites for cooperative rate-splitting multiple access
(RSMA). Given the difficulty of acquiring instantaneous channel state
information (iCSI) due to long delays and Doppler effects, we formulate an
ergodic max-min fairness rate (MMFR) maximization problem based on statistical
CSI (sCSI). To address the challenge of ergodic rate evaluation, we approximate
the problem using closed-form upper bounds and develop a weighted minimum mean
squared error-based algorithm to obtain a stationary point. Simulation results
demonstrate that the proposed sCSI-based RSMA scheme approaches iCSI-based
performance and significantly outperforms conventional space-division multiple
access.

</details>


### [251] [Near-Field Variable-Width Beam Coverage and Codebook Design for XL-RIS](https://arxiv.org/abs/2508.11178)
*Yida Zhang,Qiuyan Liu,Qiang Wang,Hongtao Luo,Yuqi Xia*

Main category: eess.SP

TL;DR: 提出一种XL-RIS近场码本设计，通过变量波束生成算法，提高UE性能，增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决XL-RIS波束宽度窄、波束对齐和广播复杂的问题，同时利用其高波束增益来缓解高频电磁波衰减导致的基站覆盖受限问题。

Method: 提出了一种变量波束生成算法，并将其应用于XL-RIS的近场码本设计，实现了对任意形状码本区域的波束覆盖，并生成了多XL-RIS系统的联合码本。

Result: 仿真结果表明，该方案能够实现用户设备（UE）在码本区域内获得更高的频谱效率和更低通信中断概率，并且对码本区域的位置和面积变化具有更好的鲁棒性。

Conclusion: 所提出的超大尺寸可重构智能表面（XL-RIS）的近场码本设计方案，通过变量波束生成算法，能够实现用户设备（UE）在码本区域内更高的频谱效率和更低的通信中断概率，并对码本区域的位置和面积变化表现出更好的鲁棒性。

Abstract: To mitigate the issue of limited base station coverage caused by severe
high-frequency electromagnetic wave attenuation, Extremely Large Reconfigurable
Intelligent Surface (XL-RIS) has garnered significant attention due to its high
beam gain. However, XL-RIS exhibits a narrower beam width compared to
traditional RIS, which increases the complexity of beam alignment and
broadcast. To address this problem, we propose a variable-width beam generation
algorithm under the near-field assumption and apply it to the near-field
codebook design for XL-RIS. Our algorithm can achieve beam coverage for
arbitrarily shaped codeword regions and generate a joint codebook for the
multi-XL-RIS system. The simulation results demonstrate that our proposed
scheme enables user equipment (UE) to achieve higher spectral efficiency and
lower communication outage probability within the codeword region compared to
existing works. Furthermore, our scheme exhibits better robustness to codeword
region location and area variations.

</details>


### [252] [KAN-HAR: A Human activity recognition based on Kolmogorov-Arnold Network](https://arxiv.org/abs/2508.11186)
*Mohammad Alikhani*

Main category: eess.SP

TL;DR: 本研究使用KAN和加速度计数据进行人类活动识别，实现了与传统深度神经网络相当甚至更好的性能，同时参数更少，可解释性更强。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在人类活动识别任务中需要大量的参数调整，并且可能缺乏可解释性。本研究旨在利用KAN模型复杂非线性关系的能力，以提高可解释性和参数效率。

Method: 使用单个三轴加速度计和Kolmogorov-Arnold Network（KAN）进行人类活动识别。数据预处理和归一化后，使用KAN进行特征学习和分类。

Result: KAN在分类性能上达到或优于传统的深度神经网络，同时参数数量显著减少。

Conclusion: KAN架构有潜力成为现实世界人类活动识别系统的高效且可解释的替代方案。

Abstract: Human Activity Recognition (HAR) plays a critical role in numerous
applications, including healthcare monitoring, fitness tracking, and smart
environments. Traditional deep learning (DL) approaches, while effective, often
require extensive parameter tuning and may lack interpretability. In this work,
we investigate the use of a single three-axis accelerometer and the
Kolmogorov--Arnold Network (KAN) for HAR tasks, leveraging its ability to model
complex nonlinear relationships with improved interpretability and parameter
efficiency. The MotionSense dataset, containing smartphone-based motion sensor
signals across various physical activities, is employed to evaluate the
proposed approach. Our methodology involves preprocessing and normalization of
accelerometer and gyroscope data, followed by KAN-based feature learning and
classification. Experimental results demonstrate that the KAN achieves
competitive or superior classification performance compared to conventional
deep neural networks, while maintaining a significantly reduced parameter
count. This highlights the potential of KAN architectures as an efficient and
interpretable alternative for real-world HAR systems. The open-source
implementation of the proposed framework is available at the Project's GitHub
Repository.

</details>


### [253] [Enabling low-power massive MIMO with ternary ADCs for AIoT sensing](https://arxiv.org/abs/2508.11234)
*Shengheng Liu,Ningning Fu*

Main category: eess.SP

TL;DR: 该论文提出了一种使用三元ADC（T-ADC）和联合导频与数据（JPD）方案，以降低AIoT和大规模MIMO系统的功耗，并有效解决了信道感知挑战。


<details>
  <summary>Details</summary>
Motivation: AIoT的激增以及对普遍智能的需求导致了AIoT的发展，但高分辨率ADC和大量的射频链会显著增加功耗。因此，探索一种低功耗的解决方案是必要的。

Method: 提出了一种使用三元ADC（T-ADC）的低功耗AIoT和大规模MIMO系统，并解决了信道感知挑战。通过辅助方案进行信道估计，并通过联合导频和数据（JPD）方法进行改进。分析了该双阈值ADC系统的性能限制，包括其理想硬件对应物（PO-ADC）和一个接收器处未知噪声方差的实际场景。

Result: JPD方案在温和条件下能有效缓解粗量化效应对信道估计性能下降的影响，且无需额外的导频开销。对于确定性和随机信道，分别提出了改进的EM和变分推断EM估计器。仿真结果验证了理论结果，并证明了所提出估计器在均方误差和符号错误率方面的有效性。

Conclusion: T-ADCs的实现及其相关的JPD方案对于绿色AIoT智能传感是可行的。

Abstract: The proliferation of networked devices and the surging demand for ubiquitous
intelligence have given rise to the artificial intelligence of things (AIoT).
However, the utilization of high-resolution analog-to-digital converters (ADCs)
and numerous radio frequency chains significantly raises power consumption.
This paper explores a cost-effective solution using ternary ADCs (T-ADCs) in
massive multiple-input-multiple-output (MIMO) systems for low-power AIoT and
specifically addresses channel sensing challenges. The channel is first
estimated through a pilot-aided scheme and refined using a joint-pilot-and-data
(JPD) approach. To assess the performance limits of this two-threshold ADC
system, the analysis includes its hardware-ideal counterpart, the parallel
one-bit ADCs (PO-ADCs) and a realistic scenario where noise variance is unknown
at the receiver is considered. Analytical findings indicate that the JPD scheme
effectively mitigates performance degradation in channel estimation due to
coarse quantization effects under mild conditions, without necessitating
additional pilot overhead. For deterministic and random channels, we propose
modified expectation maximization (EM) and variational inference EM estimators,
respectively. Extensive simulations validate the theoretical results and
demonstrate the effectiveness of the proposed estimators in terms of mean
square error and symbol error rate, which showcases the feasibility of
implementing T-ADCs and the associated JPD scheme for greener AIoT smart
sensing.

</details>


### [254] [Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images](https://arxiv.org/abs/2508.11259)
*Ryosuke Isono,Shunsuke Ono*

Main category: eess.SP

TL;DR: TSSTF是一种新的时空融合框架，通过TGTV和TGEC机制，解决了现有方法在噪声条件下难以捕捉空间结构的问题，并在有噪声数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有噪声鲁棒ST融合方法在处理卫星图像时，往往难以捕捉精细的空间结构，导致过度平滑和伪影。本研究旨在解决这一问题，提升ST融合方法在噪声条件下的鲁棒性，同时保留图像的空间结构细节。

Method: 提出了一种名为TSSTF（Temporally-Similar Structure-Aware ST fusion）的新型时空（ST）融合框架。该框架引入了两种关键机制：时间引导全变分（TGTV）和时间引导边缘约束（TGEC）。TGTV是一种新的正则化函数，通过参考邻近日期的高空间分辨率图像，在保持结构细节的同时，促进空间分段平滑。TGEC则强制执行时间上相邻的两个图像之间边缘位置的一致性，同时允许光谱变化。ST融合任务被构建为一个包含TGTV和TGEC的约束优化问题，并基于预条件原对偶分裂方法开发了一种高效算法。

Result: 实验结果表明，TSSTF在无噪声条件下表现与现有方法相当，在有噪声条件下则表现更优。

Conclusion: TSSTF在无噪声条件下表现与现有方法相当，在有噪声条件下表现更优。研究还提供了一套推荐的参数值，以提高在不同地区和噪声条件下的性能稳定性和实用性。

Abstract: This paper proposes a novel spatiotemporal (ST) fusion framework for
satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).
ST fusion is a promising approach to address the trade-off between the spatial
and temporal resolution of satellite images. In real-world scenarios, observed
satellite images are severely degraded by noise due to measurement equipment
and environmental conditions. Consequently, some recent studies have focused on
enhancing the robustness of ST fusion methods against noise. However, existing
noise-robust ST fusion approaches often fail to capture fine spatial structure,
leading to oversmoothing and artifacts. To address this issue, TSSTF introduces
two key mechanisms: Temporally-Guided Total Variation (TGTV) and
Temporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization
function that promotes spatial piecewise smoothness while preserving structural
details, guided by a reference high spatial resolution image acquired on a
nearby date. TGEC enforces consistency in edge locations between two temporally
adjacent images, while allowing for spectral variations. We formulate the ST
fusion task as a constrained optimization problem incorporating TGTV and TGEC,
and develop an efficient algorithm based on a preconditioned primal-dual
splitting method. Experimental results demonstrate that TSSTF performs
comparably to state-of-the-art methods under noise-free conditions and
outperforms them under noisy conditions. Additionally, we provide a
comprehensive set of recommended parameter values that consistently yield high
performance across diverse target regions and noise conditions, aiming to
enhance reproducibility and practical utility.

</details>


### [255] [Beyond Diagonal Reconfigurable Intelligent Surface Enabled Sensing: Cramer-Rao Bound Optimization](https://arxiv.org/abs/2508.11292)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Haijun Zhang*

Main category: eess.SP

TL;DR: 研究了BD-RIS在6G感知中的应用，提出了最小化CRB的优化算法，并验证了其优越的感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明BD-RIS在通信方面优于传统RIS，但其在6G感知方面的优势仍不明确，因此需要研究BD-RIS在感知方面的应用。

Method: 推导了BD-RIS辅助感知下目标角度（AOA）估计的Cramer-Rao界（CRB），并提出了一种基于自适应黎曼梯度上升算法的优化方案，以满足BD-RIS散射矩阵酉约束，最小化CRB。

Result: 提出的BD-RIS辅助目标定位方法在感知性能上优于现有方法。

Conclusion: 提出的基于BD-RIS的定位方法在感知性能上优于现有方法。

Abstract: Recently, beyond diagonal reconfigurable intelligent surface (BD-RIS) has
emerged as a more flexible solution to engineer the wireless propagation
channels, thanks to its non-diagonal reflecting matrix. Although the gain of
the BD-RIS over the conventional RIS in communication has been revealed in many
works, its gain in 6G sensing is still unknown. This motivates us to study the
BD-RIS assisted sensing in this letter. Specifically, we derive the Cramer-Rao
bound (CRB) for estimating the angle-of-arrival (AOA) from the target to the
BD-RIS under the constraint that the BD-RIS scattering matrix is unitary. To
minimize the CRB, we develop an optimization scheme based on an adaptive
Riemannian steepest ascent algorithm that can satisfy the non-convex unitary
constraint. Numerical results demonstrate that the proposed BD-RIS-assisted
target localization method achieves superior sensing performance.

</details>


### [256] [Optimizing Rate-CRB Performance for Beyond Diagonal Reconfigurable Intelligent Surface Enabled ISAC](https://arxiv.org/abs/2508.11295)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Weifeng Zhu,Haijun Zhang*

Main category: eess.SP

TL;DR: BD-RIS 辅助 ISAC 系统的优化设计。


<details>
  <summary>Details</summary>
Motivation: 在超越对角可重构智能表面 (BD-RIS) 辅助的集成传感和通信 (ISAC) 系统中，最大化 UEs 的总和速率，同时满足本地化 Cramer-Rao 界 (CRB) 约束和散射矩阵的酉矩阵约束。

Method: 提出了一种基于对数障碍的黎曼最速上升法来解决该优化问题。

Result: 数值结果验证了所提出算法的有效性以及 BD-RIS 辅助 ISAC 系统相对于传统 RIS 辅助 ISAC 系统的性能优势。

Conclusion: BD-RIS 有助于 ISAC 系统，并通过所提出的优化算法实现了性能增益。

Abstract: This letter considers a beyond diagonal reconfigurable intelligent surface
(BD-RIS) aided integrated sensing and communication (ISAC) system, where the
BD-RIS can help a multi-antenna base station (BS) serve multiple user
equipments (UEs) and localize a target simultaneously. We formulate an
optimization problem that designs the BS beamforming matrix and the BD-RIS
scattering matrix to maximize UEs' sum rate subject to a localization
Cramer-Rao bound (CRB) constraint and an additional unitary matrix constraint
for the scattering matrix. Because unitary matrices form a manifold, our
problem belongs to constrained manifold optimization. This letter proposes a
log-barrier based Riemannian steepest ascent method to solve this problem
effectively. Numerical results verify the effectiveness of our algorithm and
the performance gain of the BD-RIS aided ISAC systems over the conventional RIS
aided ISAC systems.

</details>


### [257] [Important Bit Prefix M-ary Quadrature Amplitude Modulation for Semantic Communications](https://arxiv.org/abs/2508.11351)
*Haonan Lu,Rui Meng,Xiaodong Xu,Yiming Liu,Ping Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出IBP-MQAM方案，用于语义通信。通过LDA量化文本语义，验证IBP-MQAM性能优于MQAM。


<details>
  <summary>Details</summary>
Motivation: 为了实现语义通信（SemCom）的专用信道调制。

Method: 提出了一种名为IBP-MQAM的重要比特前缀MQAM信道调制方案，并推导了重要符号错误率（ISER）和非重要符号错误率（USER）的近似表达式。通过使用潜在狄利克雷分配（LDA）提取和量化文本语义来验证。

Result: IBP-MQAM在SemCom场景下实现了优于MQAM的性能，并分析了关键系统参数的影响。

Conclusion: IBP-MQAM在语义通信场景下实现了优于MQAM的性能。

Abstract: M-ary Quadrature Amplitude Modulation (MQAM) is a commonly used channel
modulation technology in wireless communication systems. To achieve dedicated
channel modulation for semantic communication (SemCom), we propose an
Important-Bit-Prefixed MQAM (IBP-MQAM) scheme and derive its approximate
expression of important symbol error rate (ISER) and unimportant symbol error
rate (USER). By extracting and quantifying text semantics using Latent
Dirichlet Allocation (LDA), we verify that IBP-MQAM achieves improved
performance over MQAM in SemCom scenarios and further analyze the effects of
key system parameters.

</details>


### [258] [Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication](https://arxiv.org/abs/2508.11457)
*Hui Cao,Rui Meng,Xiaodong Xu,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 提出了一种名为IRST（Importance-Aware Robust Semantic Transmission）的框架，用于解决6G时代卫星地面通信中的带宽限制和信道波动问题。IRST通过增强分割模型、优先传输关键语义内容以及自适应信道编码来提高数据传输效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决卫星地面语义通信中，由于信噪比动态波动和带宽限制导致的面向任务的数据传输挑战。

Method: 1.首先，应用了分割模型增强算法来提高语义分割的粒度和准确性。2.然后，采用面向任务的语义选择方法，根据实时信道状态信息优先传输语义关键内容。3.最后，该框架包含一个基于堆栈的、感知的信道编解码器，能够根据信噪比的变化执行自适应信道编码。

Result: 所提出的IRST框架在带宽稀缺和信道多变的情况下，相较于现有基准具有优越的性能和鲁棒性。

Conclusion: IRST模型在带宽受限和信道多变的情况下，相较于现有基准具有优越的性能和鲁棒性。

Abstract: Satellite-ground semantic communication is anticipated to serve a critical
role in the forthcoming 6G era. Nonetheless, task-oriented data transmission in
such systems remains a formidable challenge, primarily due to the dynamic
nature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth
limitations inherent to low Earth orbit (LEO) satellite channels. In response
to these constraints, we propose an importance-aware robust semantic
transmission (IRST) framework, specifically designed for scenarios
characterized by bandwidth scarcity and channel variability. The IRST scheme
begins by applying a segmentation model enhancement algorithm to improve the
granularity and accuracy of semantic segmentation. Subsequently, a task-driven
semantic selection method is employed to prioritize the transmission of
semantically vital content based on real-time channel state information.
Furthermore, the framework incorporates a stack-based, SNR-aware channel codec
capable of executing adaptive channel coding in alignment with SNR variations.
Comparative evaluations across diverse operating conditions demonstrate the
superior performance and resilience of the IRST model relative to existing
benchmarks.

</details>


### [259] [Efficient Artifacts Removal for Adaptive Deep Brain Stimulation and a Temporal Event Localization Analysis](https://arxiv.org/abs/2508.11459)
*Tzu-Chi Liu,Po-Lin Chen,Yi-Chieh Chen,Po-Hsun Tu,Chih-Hua Yeh,Mun-Chun Yeap,Chiung-Chu Chen,Hau-Tieng Wu*

Main category: eess.SP

TL;DR: SMARTA+是SMARTA的计算优化版本，可有效去除aDBS中的刺激和瞬态直流伪影，从而实现实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有的伪影去除策略在伪影抑制和算法灵活性之间存在权衡，并且SMARTA计算需求高，无法处理瞬态直流伪影，限制了其在实时应用中的使用。

Method: 开发了一种计算效率高的SMARTA扩展，称为SMARTA+，它能够抑制刺激和瞬态直流伪影，同时支持灵活的算法设计。

Result: SMARTA+在伪影去除方面与SMARTA和其他已建立的方法相当或更优，同时显著减少了计算时间，并能在各种刺激协议中保持光谱和时间结构。

Conclusion: SMARTA+是一种有前景的工具，可用于推进实时闭环aDBS系统。

Abstract: Adaptive deep brain stimulation (aDBS) leverages symptom-related biomarkers
to deliver personalized neuromodulation therapy, with the potential to improve
treatment efficacy and reduce power consumption compared to conventional DBS.
However, stimulation-induced signal contamination remains a major technical
barrier to advancing its clinical application. Existing artifact removal
strategies, both front-end and back-end, face trade-offs between artifact
suppression and algorithmic flexibility. Among back-end algorithms, Shrinkage
and Manifold-based Artifact Removal using Template Adaptation (SMARTA) has
shown promising performance in mitigating stimulus artifacts with minimal
distortion to local field potentials (LFPs), but its high computational demand
and inability to handle transient direct current (DC) artifacts limit its use
in real-time applications. To address this, we developed SMARTA+, a
computationally efficient extension of SMARTA capable of suppressing both
stimulus and transient DC artifacts while supporting flexible algorithmic
design. We evaluated SMARTA+ using semi-real aDBS data and real data from
Parkinson's disease patients. Compared to SMARTA and other established methods,
SMARTA+ achieved comparable or superior artifact removal while significantly
reducing computation time. It preserved spectral and temporal structures,
ranging from beta band to high-frequency oscillations, and demonstrated
robustness across diverse stimulation protocols. Temporal event localization
analysis further showed improved accuracy in detecting beta bursts. These
findings support SMARTA+ as a promising tool for advancing real-time,
closed-loop aDBS systems.

</details>


### [260] [Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A Hierarchical Learning Approach](https://arxiv.org/abs/2508.11473)
*Yuqin Liu,Mona Jaber,Yan Liu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出了一种NOMA辅助SGF框架，通过DRL和分层学习优化波束成形和传输调度，以提高吞吐量和降低GFU的AoI。


<details>
  <summary>Details</summary>
Motivation: 为了通过利用来自基于授权的用户（GBUs）的剩余资源来为授权用户（GFUs）实现信道接入，提出了一种非正交多址（NOMA）辅助的半授权（SGF）框架。在该框架下，通过联合波束成形设计和传输调度来提高系统吞吐量并降低GFUs的年龄信息（AoI）。

Method: 提出了一种基于深度强化学习（DRL）的传输调度方法来确定基于可用传输时隙和GFU传输状态的最优传输概率。然后，提出了一种分层学习算法来分析GBU的信道状态信息和GFU的传输状态，并基于此分析训练一个用于波束成形的上层策略以实现高效的基于授权的传输，同时一个下层策略适应以最大化利用上层代理分配的传输时隙。

Result: DRL传输调度方法在AoI缩减方面优于现有的基线方法，相比于状态依赖选择平均可以提前三倍时隙传输，相比于自适应选择平均可以提前五倍时隙传输。分层学习算法在将GFUs的平均AoI保持在1.5倍时隙内的情况下，能够实现约31.82%的增益。

Conclusion: 通过数值结果验证了该分层学习方案在NOMA辅助SGF系统中对于1-5倍GBU数量的GFU场景的有效性。

Abstract: A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)
framework is proposed to enable channel access for grant-free users (GFUs) by
using residual resources from grant-based users. Under this framework, the
problem of joint beamforming design and transmission scheduling is formulated
to improve the system throughput and reduce the age-of-information of GFUs. The
aforementioned problem is transferred into a Markov Decision Process to model
the changing environment with the transmission/ waiting/ retransmission of
GFUs. In an effort to solve the pertinent problem, firstly, a deep
reinforcement learning (DRL) based transmission scheduling approach is proposed
for determining the optimal transmission probability based on the available
transmission slots and transmission status of GFUs. Secondly, a hierarchical
learning algorithm is proposed to analyze the channel state information of GBUs
and the transmission status of GFUs, and to train an upper-level policy based
on this analysis for beamforming to achieve efficient grant-based transmission,
while a lower-level policy adapts to maximize the utilization of transmission
slots allocated by the upper-level agent. The two policies interact to improve
channel access and avoid collisions. Numerical results reveal that 1) The DRL
based transmission scheduling outperforms existing adaptive and state-dependent
baselines in AoI reduction, where an average
three-time-slots-earlier-transmission can be obtained compared to the
state-dependent choice, and five time slots earlier can be achieved when
comparing to the adaptive choice; 2) The hierarchical learning algorithm is
able to achieve approximately a 31.82% gain while maintaining the average AoI
of GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical
learning scheme in NOMA-assisted SGF system is validated across scenarios with
GFUs counts from 1-5 times of GBUs.

</details>


### [261] [Liquid Crystal-Based RIS Loss-Trade-Off Analysis](https://arxiv.org/abs/2508.11489)
*Bowu Wang,Mohamadreza Delbari,Robin Neuder,Alejandro Jiménez-Sáez,Vahid Jamali*

Main category: eess.SP

TL;DR: 该研究探讨了液晶智能超表面（LC-RIS）在毫米波通信中的应用，分析了其相移范围和插入损耗的权衡，并揭示了其对发射功率和数据速率的影响。


<details>
  <summary>Details</summary>
Motivation: 研究了液晶（LC）RIS辅助无线系统中的最大相移范围与插入损耗之间的权衡问题，该权衡对于LC-RIS设计至关重要，但此前未得到充分研究。

Method: 提出了一种基于液晶的智能超表面（RIS）的系统模型，并分析了最大相移范围和插入损耗之间的权衡，以最小化发射功率并满足用户的服务质量（QoS）。

Result: 仿真结果表明，在LC-RIS辅助无线系统中，存在发射功率与数据速率之间的权衡关系，该关系受LC相移范围的影响。

Conclusion: 仿真结果揭示了总发射功率与可实现数据速率之间的基本权衡，具体取决于液晶的相移范围。

Abstract: Liquid crystal (LC) technology has emerged as a promising solution for large
reconfigurable intelligent surfaces (RISs) at millimeter wave (mmWave) bands,
offering advantages such as low power consumption, scalability, and
continuously tunable phase shifts. For LC-RIS based on the delay-line
architecture, i.e., with dedicated phase shifters, there exists a trade-off
between the maximum achievable phase-shift range and the corresponding
insertion loss, which has not been studied for LC-RIS-assisted wireless systems
yet. In this paper, we investigate this trade-off where a base station (BS) and
an RIS are configured to minimize the transmit power while satisfying a given
quality of service (QoS) for a number of users. Simulation results reveal a
fundamental trade-off between the total transmit power and the achievable data
rate as a function of the LC phase-shift range.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [262] [Developing and Validating a High-Throughput Robotic System for the Accelerated Development of Porous Membranes](https://arxiv.org/abs/2508.10973)
*Hongchen Wang,Sima Zeinali Danalou,Jiahao Zhu,Kenneth Sulimro,Chaewon Lim,Smita Basak,Aimee Tai,Usan Siriwardana,Jason Hattrick-Simpers,Jay Werber*

Main category: cs.RO

TL;DR: 通过全自动化的NIPS平台，使用聚砜、PolarClean和水，成功实现了对多孔聚合物膜的制造和表征，能够精确控制参数并提高效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 开发多孔聚合物膜通常是一个劳动密集的过程，需要大量的试错来确定最佳的制造参数。因此，需要一种更高效、更可控的方法来制造和表征这些膜。

Method: 本研究提出了一种全自动化的膜制造与表征平台，采用非溶剂致相分离（NIPS）技术。该系统集成了自动化的溶液制备、刮刀浇铸、可控浸入和压缩测试，能够精确控制聚合物浓度和环境湿度等制造参数。模块化设计实现了并行处理和可重复的样品处理，缩短了实验时间并提高了数据一致性。通过对应力-应变曲线进行自动化分析，引入压缩测试作为敏感的机械表征方法，用于估算膜的刚度和推断孔隙率及样本内均匀性。

Result: 实验证明，该自动化系统能够重现聚合物浓度和环境湿度对膜性能的预期影响，包括随着聚合物浓度和湿度的增加，膜的刚度和均匀性也会增加，同时湿度变化会影响孔隙形态和机械响应。

Conclusion: 该自动化平台为聚合物膜的制造提供了高通量实验支持，并非常适合集成到自驱动实验室工作流程中，为通过非溶剂致相分离（NIPS）技术优化多孔聚合物膜提供了可扩展且可重复的基础。

Abstract: The development of porous polymeric membranes remains a labor-intensive
process, often requiring extensive trial and error to identify optimal
fabrication parameters. In this study, we present a fully automated platform
for membrane fabrication and characterization via nonsolvent-induced phase
separation (NIPS). The system integrates automated solution preparation, blade
casting, controlled immersion, and compression testing, allowing precise
control over fabrication parameters such as polymer concentration and ambient
humidity. The modular design allows parallel processing and reproducible
handling of samples, reducing experimental time and increasing consistency.
Compression testing is introduced as a sensitive mechanical characterization
method for estimating membrane stiffness and as a proxy to infer porosity and
intra-sample uniformity through automated analysis of stress-strain curves. As
a proof of concept to demonstrate the effectiveness of the system, NIPS was
carried out with polysulfone, the green solvent PolarClean, and water as the
polymer, solvent, and nonsolvent, respectively. Experiments conducted with the
automated system reproduced expected effects of polymer concentration and
ambient humidity on membrane properties, namely increased stiffness and
uniformity with increasing polymer concentration and humidity variations in
pore morphology and mechanical response. The developed automated platform
supports high-throughput experimentation and is well-suited for integration
into self-driving laboratory workflows, offering a scalable and reproducible
foundation for data-driven optimization of porous polymeric membranes through
NIPS.

</details>


### [263] [Robust Online Calibration for UWB-Aided Visual-Inertial Navigation with Bias Correction](https://arxiv.org/abs/2508.10999)
*Yizhi Zhou,Jie Xu,Jiawei Xia,Zechen Hu,Weizi Li,Xuan Wang*

Main category: cs.RO

TL;DR:  This paper presents a robust online calibration framework for UWB anchors in VINS that accounts for localization uncertainties and uses an SKF-based refinement method for improved accuracy and robustness, validated by simulations and experiments.


<details>
  <summary>Details</summary>
Motivation:  Accurate UWB anchor positioning (calibration) is crucial for UWB-aided VINS. Prior works have limitations including assumptions of accurate robot localization during initialization and sensitivity of calibration results to initial guesses.

Method:  The paper proposes a novel robust online calibration framework for UWB anchors in UWB-aided VINS. It addresses limitations of prior works by explicitly incorporating robot localization uncertainties into the calibration process and using a tightly-coupled Schmidt Kalman Filter (SKF)-based online refinement method.

Result:  The proposed approach ensures robust initialization by incorporating localization uncertainties and enhances robustness against initialization errors using an SKF-based online refinement method.

Conclusion:  Simulations and real-world experiments validate the improved accuracy and robustness of our approach.

Abstract: This paper presents a novel robust online calibration framework for
Ultra-Wideband (UWB) anchors in UWB-aided Visual-Inertial Navigation Systems
(VINS). Accurate anchor positioning, a process known as calibration, is crucial
for integrating UWB ranging measurements into state estimation. While several
prior works have demonstrated satisfactory results by using robot-aided systems
to autonomously calibrate UWB systems, there are still some limitations: 1)
these approaches assume accurate robot localization during the initialization
step, ignoring localization errors that can compromise calibration robustness,
and 2) the calibration results are highly sensitive to the initial guess of the
UWB anchors' positions, reducing the practical applicability of these methods
in real-world scenarios. Our approach addresses these challenges by explicitly
incorporating the impact of robot localization uncertainties into the
calibration process, ensuring robust initialization. To further enhance the
robustness of the calibration results against initialization errors, we propose
a tightly-coupled Schmidt Kalman Filter (SKF)-based online refinement method,
making the system suitable for practical applications. Simulations and
real-world experiments validate the improved accuracy and robustness of our
approach.

</details>


### [264] [3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation](https://arxiv.org/abs/2508.11002)
*Nikolaos Gkanatsios,Jiahe Xu,Matthew Bronars,Arsalan Mousavian,Tsung-Wei Ke,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 3DFA 是一种新的 3D 策略架构，可提高机器人操作的效率和性能，它通过结合流匹配和 3D 视觉表示，在训练和推理速度方面比以前的方法快 30 倍以上，并在双臂和单臂任务中均取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种用于机器人操作的 3D 策略架构，旨在提高训练和推理效率，同时保持性能。

Method: 3DFA 结合了用于轨迹预测的流匹配和用于从演示中学习的 3D 预训练视觉场景表示。它在动作去噪过程中利用了动作和视觉标记之间的 3D 相对注意力，并建立了在 3D 扩散模型基础上进行单臂策略学习的先前工作。

Result: 与以前的 3D 扩散策略相比，3DFA 的训练和推理速度提高了 30 倍以上，并且在 PerAct2 和 RLBench 基准测试中都达到了新的最先进水平。

Conclusion: 3DFA 在双臂操作的 PerAct2 基准测试中达到了新的最先进水平，比次优方法高出 41.4%。在单臂操作中，它通过直接预测密集的末端执行器轨迹，在 74 个 RLBench 任务上设定了新的最先进水平，无需运动规划。

Abstract: We present 3D FlowMatch Actor (3DFA), a 3D policy architecture for robot
manipulation that combines flow matching for trajectory prediction with 3D
pretrained visual scene representations for learning from demonstration. 3DFA
leverages 3D relative attention between action and visual tokens during action
denoising, building on prior work in 3D diffusion-based single-arm policy
learning. Through a combination of flow matching and targeted system-level and
architectural optimizations, 3DFA achieves over 30x faster training and
inference than previous 3D diffusion-based policies, without sacrificing
performance. On the bimanual PerAct2 benchmark, it establishes a new state of
the art, outperforming the next-best method by an absolute margin of 41.4%. In
extensive real-world evaluations, it surpasses strong baselines with up to
1000x more parameters and significantly more pretraining. In unimanual
settings, it sets a new state of the art on 74 RLBench tasks by directly
predicting dense end-effector trajectories, eliminating the need for motion
planning. Comprehensive ablation studies underscore the importance of our
design choices for both policy effectiveness and efficiency.

</details>


### [265] [GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning](https://arxiv.org/abs/2508.11049)
*Kelin Yu,Sheng Zhang,Harshit Soora,Furong Huang,Heng Huang,Pratap Tokekar,Ruohan Gao*

Main category: cs.RO

TL;DR: GenFlowRL是一种创新的机器人学习方法，它利用从生成流中提取的操纵特征，解决了现有方法的局限性，并在各种模拟和现实世界的任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视频生成模型在机器人学习中对生成数据质量的依赖以及在细粒度操作中缺乏环境反馈的问题，同时克服基于视频的强化学习中视频生成的不确定性和收集用于训练扩散模型的大规模机器人数据集的挑战。

Method: 提出了一种名为GenFlowRL的方法，该方法从生成的流中推导出奖励，该流从多样化的跨体数据集中训练而来，从而能够从多样化的演示中学习可泛化和鲁棒的策略。

Result: 实验在10个操纵任务中进行，包括模拟和现实世界的跨体评估，证明了GenFlowRL的有效性。

Conclusion: GenFlowRL通过利用从多样化的跨体数据集训练的生成流中提取的操纵特征，在各种具有挑战性的场景中始终如一地实现了卓越的性能。

Abstract: Recent advances have shown that video generation models can enhance robot
learning by deriving effective robot actions through inverse dynamics. However,
these methods heavily depend on the quality of generated data and struggle with
fine-grained manipulation due to the lack of environment feedback. While
video-based reinforcement learning improves policy robustness, it remains
constrained by the uncertainty of video generation and the challenges of
collecting large-scale robot datasets for training diffusion models. To address
these limitations, we propose GenFlowRL, which derives shaped rewards from
generated flow trained from diverse cross-embodiment datasets. This enables
learning generalizable and robust policies from diverse demonstrations using
low-dimensional, object-centric features. Experiments on 10 manipulation tasks,
both in simulation and real-world cross-embodiment evaluations, demonstrate
that GenFlowRL effectively leverages manipulation features extracted from
generated object-centric flow, consistently achieving superior performance
across diverse and challenging scenarios. Our Project Page:
https://colinyu1.github.io/genflowrl

</details>


### [266] [Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance](https://arxiv.org/abs/2508.11093)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

TL;DR: This paper enhances a robot's ability to understand user goals for navigation and manipulation by integrating vision-language models and language models with an existing framework (GUIDER). The system filters objects and locations based on user prompts, allowing the robot to select the correct targets and adapt to changing intents for smoother human-robot collaboration. Future work involves testing on a simulated robot.


<details>
  <summary>Details</summary>
Motivation: Human-robot collaboration necessitates robots that can rapidly infer user intent, offer clear reasoning, and support users in accomplishing their objectives. This work aims to improve the ability of robots to understand and act upon user commands in complex environments.

Method: The approach augments the GUIDER framework with a vision pipeline (YOLO, SAM) and language models (VLM, LLM). The vision pipeline identifies candidate objects, which are then scored by the VLM for relevance to the operator's prompt. A text-only LLM ranks object labels. These scores are used to weight GUIDER's existing layers, selecting context-relevant targets and suppressing irrelevant ones. Autonomy transitions occur when a combined belief threshold is met, allowing the robot to navigate and retrieve objects while adapting to intent changes.

Result: The system weights existing navigation and manipulation layers of GUIDER using relevance scores from a VLM and LLM, enabling context-relevant target selection and suppression of unrelated objects. This leads to improved intent inference and task assistance for robots.

Conclusion: The proposed system integrates a VLM and LLM to enhance the GUIDER framework for human-robot collaboration, improving intent inference and target selection for navigation and manipulation tasks.

Abstract: Human-robot collaboration requires robots to quickly infer user intent,
provide transparent reasoning, and assist users in achieving their goals. Our
recent work introduced GUIDER, our framework for inferring navigation and
manipulation intents. We propose augmenting GUIDER with a vision-language model
(VLM) and a text-only language model (LLM) to form a semantic prior that
filters objects and locations based on the mission prompt. A vision pipeline
(YOLO for object detection and the Segment Anything Model for instance
segmentation) feeds candidate object crops into the VLM, which scores their
relevance given an operator prompt; in addition, the list of detected object
labels is ranked by a text-only LLM. These scores weight the existing
navigation and manipulation layers of GUIDER, selecting context-relevant
targets while suppressing unrelated objects. Once the combined belief exceeds a
threshold, autonomy changes occur, enabling the robot to navigate to the
desired area and retrieve the desired object, while adapting to any changes in
the operator's intent. Future work will evaluate the system on Isaac Sim using
a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.

</details>


### [267] [Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective](https://arxiv.org/abs/2508.11117)
*Xuning Yang,Clemens Eppner,Jonathan Tremblay,Dieter Fox,Stan Birchfield,Fabio Ramos*

Main category: cs.RO

TL;DR: Robotics simulation benchmarks need better sim-to-real evaluation for generalist policies. This paper suggests using high-fidelity simulation, testing with increased task difficulty and perturbations, and comparing sim-to-real performance.


<details>
  <summary>Details</summary>
Motivation: To address the gap in evaluating generalist robotic manipulation policies for real-world applications and improve sim-to-real policy transfer.

Method: Proposes utilizing high visual-fidelity simulation, systematically increasing task complexity and scenario perturbation for robustness assessment, and quantifying performance alignment between simulation and real-world.

Result: The paper outlines a framework for designing benchmarks that better support the development and evaluation of generalist robotic manipulation policies with a focus on sim-to-real transfer.

Conclusion: Current benchmarks inadequately evaluate generalist policies for real-world applications, hindering sim-to-real transfer.

Abstract: Current vision-based robotics simulation benchmarks have significantly
advanced robotic manipulation research. However, robotics is fundamentally a
real-world problem, and evaluation for real-world applications has lagged
behind in evaluating generalist policies. In this paper, we discuss challenges
and desiderata in designing benchmarks for generalist robotic manipulation
policies for the goal of sim-to-real policy transfer. We propose 1) utilizing
high visual-fidelity simulation for improved sim-to-real transfer, 2)
evaluating policies by systematically increasing task complexity and scenario
perturbation to assess robustness, and 3) quantifying performance alignment
between real-world performance and its simulation counterparts.

</details>


### [268] [Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC](https://arxiv.org/abs/2508.11129)
*Ryan M. Bena,Gilbert Bahati,Blake Werner,Ryan K. Cosner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 该研究提出了一种用于有腿机器人自主导航的预测安全滤波器，该滤波器利用泊松安全函数和控制障碍函数来处理动态环境和机器人几何形状，并在机器人实验中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 在非结构化和动态变化的环境中自主导航对机器人来说是一个复杂的挑战。特别是，有腿机器人通常具有可操作的不对称几何形状，在安全关键的轨迹规划中必须加以考虑。

Method: 提出了一种预测安全滤波器，这是一种非线性模型预测控制（MPC）算法，用于在线轨迹生成，并基于控制障碍函数（CBF）实现了考虑几何形状的安全约束。该方法利用泊松安全函数从感知数据中直接生成CBF约束，并将泊松方程的静态狄利克雷问题重新表述为参数化的移动边界值问题，以整合域中的时间变化。此外，还采用了闵可夫斯基集运算将域提升到考虑机器人几何形状的构型空间。

Result: 在人形和四足机器人上实现了实时预测安全滤波器，并在各种安全关键场景中进行了测试，证明了泊松安全函数的通用性和CBF约束的预测安全控制器的优势。

Conclusion: 该方法在人形和四足机器人上进行了实时预测安全滤波器的实现，并在各种安全关键场景中进行了测试。结果证明了泊松安全函数的通用性以及基于CBF约束的预测安全控制器的优势。

Abstract: Autonomous navigation through unstructured and dynamically-changing
environments is a complex task that continues to present many challenges for
modern roboticists. In particular, legged robots typically possess manipulable
asymmetric geometries which must be considered during safety-critical
trajectory planning. This work proposes a predictive safety filter: a nonlinear
model predictive control (MPC) algorithm for online trajectory generation with
geometry-aware safety constraints based on control barrier functions (CBFs).
Critically, our method leverages Poisson safety functions to numerically
synthesize CBF constraints directly from perception data. We extend the
theoretical framework for Poisson safety functions to incorporate temporal
changes in the domain by reformulating the static Dirichlet problem for
Poisson's equation as a parameterized moving boundary value problem.
Furthermore, we employ Minkowski set operations to lift the domain into a
configuration space that accounts for robot geometry. Finally, we implement our
real-time predictive safety filter on humanoid and quadruped robots in various
safety-critical scenarios. The results highlight the versatility of Poisson
safety functions, as well as the benefit of CBF constrained model predictive
safety-critical controllers.

</details>


### [269] [Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward](https://arxiv.org/abs/2508.11143)
*Jiarui Yang,Bin Zhu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: AC3是一个强化学习框架，通过特定机制（如不对称更新和n步返回）稳定地学习连续动作序列，从而有效解决长时域、稀疏奖励的机器人操作任务，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理长时域机器人操作任务（尤其是稀疏奖励任务）时存在困难，而动作分块（action chunking）是解决该问题的一种有前景的方法。然而，直接学习连续动作分块仍然面临稳定性和数据效率的挑战。

Method: AC3框架采用actor-Critic架构，学习生成高维连续动作序列，并通过不对称更新规则仅从成功轨迹中学习actor，同时利用n步返回和自监督模块为critic提供稳定的学习信号和内在奖励。

Result: AC3框架在25个BiGym和RLBench任务上进行了实验，结果表明，仅使用少量演示和简单的模型结构，AC3在大多数任务上都取得了优越的成功率。

Conclusion: AC3框架通过引入不对称更新规则和基于n步返回的奖励，在机器人操作任务中实现了高效且稳定的学习，并在BiGym和RLBench基准测试中取得了优于现有方法的性能。

Abstract: Existing reinforcement learning (RL) methods struggle with long-horizon
robotic manipulation tasks, particularly those involving sparse rewards. While
action chunking is a promising paradigm for robotic manipulation, using RL to
directly learn continuous action chunks in a stable and data-efficient manner
remains a critical challenge. This paper introduces AC3 (Actor-Critic for
Continuous Chunks), a novel RL framework that learns to generate
high-dimensional, continuous action sequences. To make this learning process
stable and data-efficient, AC3 incorporates targeted stabilization mechanisms
for both the actor and the critic. First, to ensure reliable policy
improvement, the actor is trained with an asymmetric update rule, learning
exclusively from successful trajectories. Second, to enable effective value
learning despite sparse rewards, the critic's update is stabilized using
intra-chunk $n$-step returns and further enriched by a self-supervised module
providing intrinsic rewards at anchor points aligned with each action chunk. We
conducted extensive experiments on 25 tasks from the BiGym and RLBench
benchmarks. Results show that by using only a few demonstrations and a simple
model architecture, AC3 achieves superior success rates on most tasks,
validating its effective design.

</details>


### [270] [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)
*Hongbin Lin,Bin Li,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: GASv2是一个用于机器人辅助手术抓取的视觉运动学习框架，它解决了模拟到现实的迁移、使用单一立体摄像头以及物体无关的抓取等挑战。该框架在仿真和现实环境中均表现出高成功率、泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 抓取是机器人辅助手术（RAS）中的基本任务，自动化抓取可以减轻外科医生的负担，并提高效率、安全性和一致性。然而，先前的方法依赖于显式的物体姿态跟踪或手工制作的视觉特征，这限制了它们在处理新物体、视觉干扰和可变形物体方面的泛化能力、鲁棒性和能力。此外，在RAS中部署视觉运动学习也面临着独特的挑战，例如视觉观测中的低信噪比、对高安全性和毫米级精度的要求以及复杂的手术环境。

Method: GASv2框架采用基于世界模型的架构和手术感知流程，并结合混合控制系统来确保安全执行。该策略在模拟环境中通过领域随机化进行训练，以便于从模拟到现实的迁移，并仅使用一对内窥镜摄像头在仿生和体外手术设置的真实机器人上进行部署。

Result: GASv2框架在仿生和体外手术设置中均实现了65%的抓取成功率，并且能够泛化到未见的物体和抓手，还能适应各种干扰，展现了强大的性能、通用性和鲁棒性。

Conclusion: GASv2在仿生和体外手术环境中实现了65%的抓取成功率，并且能够泛化到未知的物体和抓手，还能适应各种干扰，表现出了强大的性能、通用性和鲁棒性。

Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and
automating it can reduce surgeon workload while enhancing efficiency, safety,
and consistency beyond teleoperated systems. Most prior approaches rely on
explicit object pose tracking or handcrafted visual features, limiting their
generalization to novel objects, robustness to visual disturbances, and the
ability to handle deformable objects. Visuomotor learning offers a promising
alternative, but deploying it in RAS presents unique challenges, such as low
signal-to-noise ratio in visual observations, demands for high safety and
millimeter-level precision, as well as the complex surgical environment. This
paper addresses three key challenges: (i) sim-to-real transfer of visuomotor
policies to ex vivo surgical scenes, (ii) visuomotor learning using only a
single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic
grasping with a single policy that generalizes to diverse, unseen surgical
objects without retraining or task-specific models. We introduce Grasp Anything
for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping.
GASv2 leverages a world-model-based architecture and a surgical perception
pipeline for visual observations, combined with a hybrid control system for
safe execution. We train the policy in simulation using domain randomization
for sim-to-real transfer and deploy it on a real robot in both phantom-based
and ex vivo surgical settings, using only a single pair of endoscopic cameras.
Extensive experiments show our policy achieves a 65% success rate in both
settings, generalizes to unseen objects and grippers, and adapts to diverse
disturbances, demonstrating strong performance, generality, and robustness.

</details>


### [271] [Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation](https://arxiv.org/abs/2508.11204)
*Hongbin Lin,Juan Rojas,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 该研究探索了用于机器人操作的非等距对称性，以提高采样效率，并提出了一种名为MEA的数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 采样效率对于将视觉运动学习应用于现实世界的机器人操作至关重要。虽然任务对称性已成为提高效率的有希望的归纳偏差，但之前的大多数工作仅限于等距对称性——在所有时间步长中将相同的组变换应用于所有任务对象。

Method: 我们提出了一种部分可观察马尔可夫决策过程（POMDP）的新型表述，其中包含了非等距对称结构，并提出了一种简单而有效的数据增强方法——多组等变增强（MEA）。我们将MEA与离线强化学习相结合，以提高采样效率，并引入了一种保留平移等变性的基于体素的视觉表示。

Result: 我们探索了非等距对称性，在空间和时间维度上应用多个独立组变换来放宽这些约束。

Conclusion: 在两个操作域的广泛模拟和真实机器人实验中，证明了我们方法的有效性。

Abstract: Sampling efficiency is critical for deploying visuomotor learning in
real-world robotic manipulation. While task symmetry has emerged as a promising
inductive bias to improve efficiency, most prior work is limited to isometric
symmetries -- applying the same group transformation to all task objects across
all timesteps. In this work, we explore non-isometric symmetries, applying
multiple independent group transformations across spatial and temporal
dimensions to relax these constraints. We introduce a novel formulation of the
partially observable Markov decision process (POMDP) that incorporates the
non-isometric symmetry structures, and propose a simple yet effective data
augmentation method, Multi-Group Equivariance Augmentation (MEA). We integrate
MEA with offline reinforcement learning to enhance sampling efficiency, and
introduce a voxel-based visual representation that preserves translational
equivariance. Extensive simulation and real-robot experiments across two
manipulation domains demonstrate the effectiveness of our approach.

</details>


### [272] [Embodied Edge Intelligence Meets Near Field Communication: Concept, Design, and Verification](https://arxiv.org/abs/2508.11232)
*Guoliang Li,Xibin Jin,Yujie Wan,Chenxuan Liu,Tong Zhang,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 该论文提出将近场通信（NFC）与具身边缘智能（EEI）相结合，形成NEEI范式，并通过创新的规划、波束聚焦和导航技术解决了其通信和计算挑战，最终提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 为了在保证实时推理的同时支持大型模型（LMs）在具身机器人上的应用，提出了具身边缘智能（EEI）范式。然而，EEI的数据交换需求对其通信提出了更高要求（更高的频谱效率、通信安全性和减少用户间干扰），而近场通信（NFC）是满足这些需求的理想解决方案。因此，将EEI与NFC相结合的NEEI范式应运而生。

Method: 提出类无线电具身规划（radio-friendly embodied planning）用于EEI辅助NFC场景，提出视图引导波束聚焦（view-guided beam-focusing）用于NFC辅助EEI场景，并通过机会性协作导航（opportunistic collaborative navigation）实现资源高效的NEEI。

Result: 实验结果证实了所提出的技术相比于多种基准方法具有优越性。

Conclusion: 该论文提出了近场通信（NFC）与具身边缘智能（EEI）相结合的新型近场具身边缘智能（NEEI）范式，并提出了一系列优化技术以应对其带来的挑战，包括面向EEI辅助NFC场景的“类无线电”规划和面向NFC辅助EEI场景的视图引导波束聚焦，并通过机会性协作导航实现了资源高效的NEEI。实验结果验证了所提出技术相对于基准方法的优越性。

Abstract: Realizing embodied artificial intelligence is challenging due to the huge
computation demands of large models (LMs). To support LMs while ensuring
real-time inference, embodied edge intelligence (EEI) is a promising paradigm,
which leverages an LM edge to provide computing powers in close proximity to
embodied robots. Due to embodied data exchange, EEI requires higher spectral
efficiency, enhanced communication security, and reduced inter-user
interference. To meet these requirements, near-field communication (NFC), which
leverages extremely large antenna arrays as its hardware foundation, is an
ideal solution. Therefore, this paper advocates the integration of EEI and NFC,
resulting in a near-field EEI (NEEI) paradigm. However, NEEI also introduces
new challenges that cannot be adequately addressed by isolated EEI or NFC
designs, creating research opportunities for joint optimization of both
functionalities. To this end, we propose radio-friendly embodied planning for
EEI-assisted NFC scenarios and view-guided beam-focusing for NFC-assisted EEI
scenarios. We also elaborate how to realize resource-efficient NEEI through
opportunistic collaborative navigation. Experimental results are provided to
confirm the superiority of the proposed techniques compared with various
benchmarks.

</details>


### [273] [Tactile Robotics: An Outlook](https://arxiv.org/abs/2508.11261)
*Shan Luo,Nathan F. Lepora,Wenzhen Yuan,Kaspar Althoefer,Gordon Cheng,Ravinder Dahiya*

Main category: cs.RO

TL;DR: This paper discusses the importance of tactile sensing in robotics for human-robot interaction, reviews current technologies and advancements, and outlines future challenges and solutions for applications in manufacturing, healthcare, recycling, and agriculture.


<details>
  <summary>Details</summary>
Motivation: Robotics research aims to equip robots with touch perception analogous to biological systems, which is crucial for emerging applications requiring close human-robot interaction. This necessitates advancements in tactile sensing technologies.

Method: The paper examines challenges and explores potential solutions in tactile robotics, drawing on advancements in diverse sensing technologies (piezoresistive, piezoelectric, capacitive, magnetic, optical), simulation tools for dataset generation, and the integration of tactile sensing with vision and action strategies.

Result: The paper reviews various tactile sensing technologies, the role of simulation tools, and the integration of tactile sensing with other modalities and action strategies, highlighting the growing scope and potential of the field.

Conclusion: The integration of tactile sensing with other modalities and action strategies, along with a holistic approach, is essential for further transformative progress in tactile robotics, with potential applications in manufacturing, healthcare, recycling, and agriculture.

Abstract: Robotics research has long sought to give robots the ability to perceive the
physical world through touch in an analogous manner to many biological systems.
Developing such tactile capabilities is important for numerous emerging
applications that require robots to co-exist and interact closely with humans.
Consequently, there has been growing interest in tactile sensing, leading to
the development of various technologies, including piezoresistive and
piezoelectric sensors, capacitive sensors, magnetic sensors, and optical
tactile sensors. These diverse approaches utilise different transduction
methods and materials to equip robots with distributed sensing capabilities,
enabling more effective physical interactions. These advances have been
supported in recent years by simulation tools that generate large-scale tactile
datasets to support sensor designs and algorithms to interpret and improve the
utility of tactile data. The integration of tactile sensing with other
modalities, such as vision, as well as with action strategies for active
tactile perception highlights the growing scope of this field. To further the
transformative progress in tactile robotics, a holistic approach is essential.
In this outlook article, we examine several challenges associated with the
current state of the art in tactile robotics and explore potential solutions to
inspire innovations across multiple domains, including manufacturing,
healthcare, recycling and agriculture.

</details>


### [274] [Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation](https://arxiv.org/abs/2508.11275)
*Masaki Murooka,Iori Kumagai,Mitsuharu Morisawa,Fumio Kanehiro*

Main category: cs.RO

TL;DR: 介绍了一种新的人形运动生成方法，通过引入可微可达性图来降低计算成本，并成功应用于多种运动规划问题。


<details>
  <summary>Details</summary>
Motivation: 为了降低人形运动生成的计算成本。

Method: 提出了一种新的人形运动生成方法，通过引入可微可达性图来表示机器人运动学可达性。该图是任务空间中的标量值函数，仅在机器人末端执行器可达区域取正值，并且相对于任务空间坐标是连续且可微的。通过使用神经网络或支持向量机从机器人运动学模型生成的末端执行器姿态集合中学习可微可达性图。

Result: 所提出的方法能够有效地解决包括足步规划、多接触运动规划和人形机器人运动操纵规划在内的各种运动规划问题。

Conclusion: 该方法通过将可微可达性图作为约束，将人形运动生成表述为连续优化问题，并已成功应用于足步规划、多接触运动规划和运动操纵规划等多种运动规划问题。

Abstract: To reduce the computational cost of humanoid motion generation, we introduce
a new approach to representing robot kinematic reachability: the differentiable
reachability map. This map is a scalar-valued function defined in the task
space that takes positive values only in regions reachable by the robot's
end-effector. A key feature of this representation is that it is continuous and
differentiable with respect to task-space coordinates, enabling its direct use
as constraints in continuous optimization for humanoid motion planning. We
describe a method to learn such differentiable reachability maps from a set of
end-effector poses generated using a robot's kinematic model, using either a
neural network or a support vector machine as the learning model. By
incorporating the learned reachability map as a constraint, we formulate
humanoid motion generation as a continuous optimization problem. We demonstrate
that the proposed approach efficiently solves various motion planning problems,
including footstep planning, multi-contact motion planning, and
loco-manipulation planning for humanoid robots.

</details>


### [275] [Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent](https://arxiv.org/abs/2508.11286)
*Che Rin Yu,Daewon Chae,Dabin Seo,Sangwon Lee,Hyeongwoo Im,Jinkyu Kim*

Main category: cs.RO

TL;DR: 该研究提出了一种前瞻性重新规划框架，通过比较场景图来检测和纠正潜在的执行失败，从而提高机器人的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 许多自主机器人缺乏适应性感知能力，经常遵循预先规划的动作，可能忽略场景中的细微但关键的变化，导致基于过时假设执行动作并最终导致失败。虽然重新规划对于鲁棒自主至关重要，但现有方法通常在故障发生后才响应，而前瞻性重新规划可以通过手动设计的规则和广泛的监督来提前防止故障。

Method: 通过在子任务边界比较当前RGB-D观测构建的场景图与从成功演示中提取的参考图，并在不匹配时激活轻量级推理模块来诊断和调整计划。

Result: 实验证明，该方法能在执行失败发生之前检测到语义和空间不匹配，显著提高了任务成功率和鲁棒性。

Conclusion: 该方法通过在子任务边界检测和纠正故障，并将当前RGB-D观测构建的场景图与从成功演示中提取的参考图进行比较，实现了前瞻性重新规划，从而提高了任务成功率和鲁棒性。

Abstract: When humans perform everyday tasks, we naturally adjust our actions based on
the current state of the environment. For instance, if we intend to put
something into a drawer but notice it is closed, we open it first. However,
many autonomous robots lack this adaptive awareness. They often follow
pre-planned actions that may overlook subtle yet critical changes in the scene,
which can result in actions being executed under outdated assumptions and
eventual failure. While replanning is critical for robust autonomy, most
existing methods respond only after failures occur, when recovery may be
inefficient or infeasible. While proactive replanning holds promise for
preventing failures in advance, current solutions often rely on manually
designed rules and extensive supervision. In this work, we present a proactive
replanning framework that detects and corrects failures at subtask boundaries
by comparing scene graphs constructed from current RGB-D observations against
reference graphs extracted from successful demonstrations. When the current
scene fails to align with reference trajectories, a lightweight reasoning
module is activated to diagnose the mismatch and adjust the plan. Experiments
in the AI2-THOR simulator demonstrate that our approach detects semantic and
spatial mismatches before execution failures occur, significantly improving
task success and robustness.

</details>


### [276] [A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning](https://arxiv.org/abs/2508.11520)
*Evangelos Tsiatsianas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: 本研究比较了机器人敏捷运动轨迹优化中不同浮动基线表示方法，并提出了一种新的基于SE(3)切线空间的方法，以提高性能和简化求解。


<details>
  <summary>Details</summary>
Motivation: 在机器人运动生成中，如何选择浮动基线空间的参数化会影响性能，尤其是在涉及复杂接触动力学的敏捷行为中，目前尚不清楚。

Method: 通过对直接转录的轨迹优化进行不同参数化的比较研究，并提出一种基于SE(3)切线空间的新方法。

Result: 我们系统地评估了几种常见的选择，并在相同的优化设置下进行公平的比较。此外，我们还引入了一种基于SE(3)切线空间的新颖公式，用于表示机器人浮动基线的姿态，这种方法能够使用成熟的现成数值求解器，而无需专门的流形优化技术。

Conclusion: 本研究旨在为敏捷运动的浮动基线表示提供有意义的见解，以指导在机器人运动生成中进行选择。

Abstract: Automatically generating agile whole-body motions for legged and humanoid
robots remains a fundamental challenge in robotics. While numerous trajectory
optimization approaches have been proposed, there is no clear guideline on how
the choice of floating-base space parameterization affects performance,
especially for agile behaviors involving complex contact dynamics. In this
paper, we present a comparative study of different parameterizations for direct
transcription-based trajectory optimization of agile motions in legged systems.
We systematically evaluate several common choices under identical optimization
settings to ensure a fair comparison. Furthermore, we introduce a novel
formulation based on the tangent space of SE(3) for representing the robot's
floating-base pose, which, to our knowledge, has not received attention from
the literature. This approach enables the use of mature off-the-shelf numerical
solvers without requiring specialized manifold optimization techniques. We hope
that our experiments and analysis will provide meaningful insights for
selecting the appropriate floating-based representation for agile whole-body
motion generation.

</details>


### [277] [A Recursive Total Least Squares Solution for Bearing-Only Target Motion Analysis and Circumnavigation](https://arxiv.org/abs/2508.11289)
*Lin Li,Xueming Liu,Zhoujingzi Qiu,Tianjiang Hu,Qingrui Zhang*

Main category: cs.RO

TL;DR: This paper presents a new Recursive Total Least Squares (RTLS) method and a circumnavigation controller for passive tracking using bearing-only measurements. The new method improves accuracy and stability, outperforming current techniques.


<details>
  <summary>Details</summary>
Motivation: Bearing-only Target Motion Analysis (TMA) is challenging due to the nonlinearity of bearing measurements and the lack of range information, which hinders observability and estimator convergence. This paper aims to address these challenges by improving accuracy and stability in target tracking.

Method: The paper proposes a Recursive Total Least Squares (RTLS) method for bearing-only Target Motion Analysis (TMA) and introduces a circumnavigation controller to improve system observability and estimator convergence. The RTLS approach is designed to mitigate biases in position estimation and improve computational efficiency compared to pseudo-linear Kalman filter (PLKF) methods.

Result: The proposed RTLS method and circumnavigation controller demonstrate effectiveness and robustness through extensive simulations and experiments, showing superior performance in accuracy and stability compared to existing methods.

Conclusion: The proposed Recursive Total Least Squares (RTLS) method enhances online target localization and tracking for bearing-only TMA, outperforming state-of-the-art approaches in accuracy and stability. The addition of a circumnavigation controller further improves system observability and estimator convergence.

Abstract: Bearing-only Target Motion Analysis (TMA) is a promising technique for
passive tracking in various applications as a bearing angle is easy to measure.
Despite its advantages, bearing-only TMA is challenging due to the nonlinearity
of the bearing measurement model and the lack of range information, which
impairs observability and estimator convergence. This paper addresses these
issues by proposing a Recursive Total Least Squares (RTLS) method for online
target localization and tracking using mobile observers. The RTLS approach,
inspired by previous results on Total Least Squares (TLS), mitigates biases in
position estimation and improves computational efficiency compared to
pseudo-linear Kalman filter (PLKF) methods. Additionally, we propose a
circumnavigation controller to enhance system observability and estimator
convergence by guiding the mobile observer in orbit around the target.
Extensive simulations and experiments are performed to demonstrate the
effectiveness and robustness of the proposed method. The proposed algorithm is
also compared with the state-of-the-art approaches, which confirms its superior
performance in terms of both accuracy and stability.

</details>


### [278] [Towards Fully Onboard State Estimation and Trajectory Tracking for UAVs with Suspended Payloads](https://arxiv.org/abs/2508.11547)
*Martin Jiroušek,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种仅使用标准机载传感器（GPS和IMU）来跟踪无人机悬索吊舱位置的框架，通过仿真和现场实验证明了其性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机携带的悬索吊舱的跟踪问题，重点关注实际部署和最少硬件需求，与依赖动作捕捉系统、额外机载摄像头或仪器化吊舱的现有方法不同。

Method: 提出了一种仅使用实时运动学全局导航卫星系统测量和机载惯测量单元数据的框架，并集成了线性卡尔曼滤波器、模型预测轮廓控制器和增量模型预测控制器来估计和控制吊舱的位置。

Result: 通过广泛的模拟证明，该系统实现了与基于地面真实测量的控制相当的性能，并且只有微小的性能下降（<6%）。通过现场实验进一步验证了该框架在户外环境中仅使用现成无人机硬件的实际适用性和可靠性能。

Conclusion: 该框架在实际部署中是可行的，并且在只有标准机载传感器的情况下，性能与基于地面真实测量的控制相当，具有很强的鲁棒性。

Abstract: This paper addresses the problem of tracking the position of a
cable-suspended payload carried by an unmanned aerial vehicle, with a focus on
real-world deployment and minimal hardware requirements. In contrast to many
existing approaches that rely on motion-capture systems, additional onboard
cameras, or instrumented payloads, we propose a framework that uses only
standard onboard sensors--specifically, real-time kinematic global navigation
satellite system measurements and data from the onboard inertial measurement
unit--to estimate and control the payload's position. The system models the
full coupled dynamics of the aerial vehicle and payload, and integrates a
linear Kalman filter for state estimation, a model predictive contouring
control planner, and an incremental model predictive controller. The control
architecture is designed to remain effective despite sensing limitations and
estimation uncertainty. Extensive simulations demonstrate that the proposed
system achieves performance comparable to control based on ground-truth
measurements, with only minor degradation (< 6%). The system also shows strong
robustness to variations in payload parameters. Field experiments further
validate the framework, confirming its practical applicability and reliable
performance in outdoor environments using only off-the-shelf aerial vehicle
hardware.

</details>


### [279] [Pedestrian Dead Reckoning using Invariant Extended Kalman Filter](https://arxiv.org/abs/2508.11396)
*Jingran Zhang,Zhengzhang Yan,Yiming Chen,Zeqiang He,Jiahao Chen*

Main category: cs.RO

TL;DR: 本文提出了一种用于GPS拒绝环境下的双足机器人惯性行人航位推算方法，该方法利用支撑脚上的IMU进行伪测量，并采用不变扩展卡尔曼滤波（InEKF）。实验证明了该方法的可行性，并且InEKF比标准EKF更容易调整。


<details>
  <summary>Details</summary>
Motivation: 为了在GPS拒绝环境中为双足机器人提供一种具有成本效益的惯性行人航位推算方法。

Method: 该方法利用了IMU在支撑脚上时执行的固定伪测量来为基于IMU的预测提供信息。文章阐述了采用的基于矩阵李群的不变扩展卡尔曼滤波（InEKF）的理论发展，并提供了教程。

Result: 通过运动捕捉基准实验、大规模多楼层行走实验和双足机器人实验，将InEKF与标准EKF进行了比较，证明了该方法在现实机器人系统中的可行性。此外，敏感性分析表明InEKF比EKF更容易调整。

Conclusion: 该研究提出了一种具有成本效益的惯性行人航位推算方法，用于在GPS拒绝环境中双足机器人。

Abstract: This paper presents a cost-effective inertial pedestrian dead reckoning
method for the bipedal robot in the GPS-denied environment. Each time when the
inertial measurement unit (IMU) is on the stance foot, a stationary
pseudo-measurement can be executed to provide innovation to the IMU measurement
based prediction. The matrix Lie group based theoretical development of the
adopted invariant extended Kalman filter (InEKF) is set forth for tutorial
purpose. Three experiments are conducted to compare between InEKF and standard
EKF, including motion capture benchmark experiment, large-scale multi-floor
walking experiment, and bipedal robot experiment, as an effort to show our
method's feasibility in real-world robot system. In addition, a sensitivity
analysis is included to show that InEKF is much easier to tune than EKF.

</details>


### [280] [Nominal Evaluation Of Automatic Multi-Sections Control Potential In Comparison To A Simpler One- Or Two-Sections Alternative With Predictive Spray Switching](https://arxiv.org/abs/2508.11573)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 本研究提出了一种更简单、低成本的农业喷洒控制方法，作为传统ASC的替代方案，该方法通过预测性喷洒切换和简化的节段控制，在多种真实场景下表现出良好的性能，并具有传感器无关的优势。


<details>
  <summary>Details</summary>
Motivation: 传统的自动节段控制（ASC）用于农业喷洒，旨在最大限度地减少喷洒重叠区域，但其实现需要传感器且过程复杂，易受多种不确定性因素影响。因此，本研究旨在探索是否存在一种更简单的替代方法。

Method: 本研究比较了一种自动多节段控制（ASC）方法与一种更简单的、基于预测喷洒切换的单节段或两节段替代方法。研究中考虑了两种面积覆盖路径规划和喷洒切换逻辑的组合，以及三种不同的节段设置，并根据最小化面积覆盖路径长度、提供中间重叠率、适用于手动驾驶以及低成本实现的标准进行了评估。

Result: 在10个真实的、多样的田野案例（包括非凸轮廓、自由形状主田道和多个障碍区域）的评估中，研究发现一种结合了特定路径规划和预测喷洒切换逻辑的单节段或两节段控制方法，相比于传统的ASC，具有最小化面积覆盖路径长度、提供中间重叠率、适用于手动驾驶等优点，并且由于其传感器无关的特性，可以实现低成本部署。

Conclusion: 该研究提出了一种更简单、低成本的传感器无关的喷洒方法，通过结合两种路径规划和喷洒切换逻辑，并对三种不同的节段设置（控制48个节段、2个节段或所有喷嘴作为一个节段统一控制）进行了比较。

Abstract: Automatic Section Control (ASC) is a long-standing trend for spraying in
agriculture. It promises to minimise spray overlap areas. The core idea is to
(i) switch off spray nozzles on areas that have already been sprayed, and (ii)
to dynamically adjust nozzle flow rates along the boom bar that holds the spray
nozzles when velocities of boom sections vary during turn maneuvers. ASC is not
possible without sensors, in particular for accurate positioning data. Spraying
and the movement of modern wide boom bars are highly dynamic processes. In
addition, many uncertainty factors have an effect such as cross wind drift,
boom height, nozzle clogging in open-field conditions, and so forth. In view of
this complexity, the natural question arises if a simpler alternative exist.
Therefore, an Automatic Multi-Sections Control method is compared to a proposed
simpler one- or two-sections alternative that uses predictive spray switching.
The comparison is provided under nominal conditions. Agricultural spraying is
intrinsically linked to area coverage path planning and spray switching logic.
Combinations of two area coverage path planning and switching logics as well as
three sections-setups are compared. The three sections-setups differ by
controlling 48 sections, 2 sections or controlling all nozzles uniformly with
the same control signal as one single section. Methods are evaluated on 10
diverse real-world field examples, including non-convex field contours,
freeform mainfield lanes and multiple obstacle areas. A preferred method is
suggested that (i) minimises area coverage pathlength, (ii) offers intermediate
overlap, (iii) is suitable for manual driving by following a pre-planned
predictive spray switching logic for an area coverage path plan, and (iv) and
in contrast to ASC can be implemented sensor-free and therefore at low cost.

</details>


### [281] [An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration](https://arxiv.org/abs/2508.11404)
*Junyeon Kim,Tianshu Ruan,Cesar Alan Contreras,Manolis Chiou*

Main category: cs.RO

TL;DR: AI-powered robots with human collaboration improve safety and accuracy in nuclear facility inspections, reducing human workload and errors compared to manual methods.


<details>
  <summary>Details</summary>
Motivation: Traditional manual inspection methods in nuclear facilities pose safety risks, high cognitive demands, and potential inaccuracies due to human limitations. AI and robotic technologies, specifically HRC, offer safer, more efficient, and accurate alternatives.

Method: The study explores the effectiveness of AI-assisted visual crack detection integrated into a mobile Jackal robot platform for structural inspection in nuclear facilities, utilizing Human-Robot Collaboration (HRC).

Result: Experimental results indicate that HRC enhances inspection accuracy and reduces operator workload, demonstrating potential for superior performance compared to traditional manual methods.

Conclusion: Human-robot collaboration (HRC) with AI-assisted visual crack detection on a mobile robot platform enhances inspection accuracy and reduces operator workload in nuclear facilities, showing potential for superior performance compared to traditional manual methods.

Abstract: Structural inspection in nuclear facilities is vital for maintaining
operational safety and integrity. Traditional methods of manual inspection pose
significant challenges, including safety risks, high cognitive demands, and
potential inaccuracies due to human limitations. Recent advancements in
Artificial Intelligence (AI) and robotic technologies have opened new
possibilities for safer, more efficient, and accurate inspection methodologies.
Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms
equipped with advanced detection algorithms, promises significant improvements
in inspection outcomes and reductions in human workload. This study explores
the effectiveness of AI-assisted visual crack detection integrated into a
mobile Jackal robot platform. The experiment results indicate that HRC enhances
inspection accuracy and reduces operator workload, resulting in potential
superior performance outcomes compared to traditional manual methods.

</details>


### [282] [Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing](https://arxiv.org/abs/2508.11406)
*Benjamin Alt,Mareike Picklum,Sorin Arion,Franklin Kenghagho Kenfack,Michael Beetz*

Main category: cs.RO

TL;DR: 研究人员正在开发一种新的方法，使机器人能够进行科学实验，并使实验结果更易于共享和复制。


<details>
  <summary>Details</summary>
Motivation: 为了实现一个自主机器人进行精确、可重复、开放、可信和透明的科学实验的未来。

Method: 提出了一个语义执行跟踪框架，记录传感器数据和语义注释的机器人信念状态，并推出了 AICOR 虚拟研究构建（VRB）平台，用于大规模共享、复制和验证机器人任务执行。

Result: 该框架和平台相结合，通过集成确定性执行、语义记忆和开放知识表示，实现了可复现的、机器人驱动的科学研究。

Conclusion: 该框架和平台为实现可复现的、机器人驱动的科学研究奠定了基础，使自主系统能够参与科学发现。

Abstract: We envision a future in which autonomous robots conduct scientific
experiments in ways that are not only precise and repeatable, but also open,
trustworthy, and transparent. To realize this vision, we present two key
contributions: a semantic execution tracing framework that logs sensor data
together with semantically annotated robot belief states, ensuring that
automated experimentation is transparent and replicable; and the AICOR Virtual
Research Building (VRB), a cloud-based platform for sharing, replicating, and
validating robot task executions at scale. Together, these tools enable
reproducible, robot-driven science by integrating deterministic execution,
semantic memory, and open knowledge representation, laying the foundation for
autonomous systems to participate in scientific discovery.

</details>


### [283] [EvoPSF: Online Evolution of Autonomous Driving Models via Planning-State Feedback](https://arxiv.org/abs/2508.11453)
*Jiayue Jin,Lang Qian,Jingyu Zhang,Chuanyu Ju,Liang Song*

Main category: cs.RO

TL;DR: 提出了一种名为EvoPSF的在线进化框架，用于解决自动驾驶中模型在部署后无法适应新环境的问题。该框架利用规划不确定性作为信号，识别并更新对规划失败影响最大的关键对象，通过自监督学习提高模型鲁棒性和规划精度。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶方法大多是离线训练的，缺乏在部署期间适应新环境的机制，导致在面对真实世界驾驶场景中未见过的变化时泛化能力下降。文章希望打破“训练一次，永远部署”的模式。

Method: 提出了一种新颖的在线进化框架EvoPSF，该框架基于规划-状态反馈。将规划不确定性作为在线进化的触发器，利用它作为诊断信号来启动有针对性的模型更新。通过利用规划器的代理-代理注意力来识别对规划失败负主要责任的关键对象，并将其与感知模块的输出来源进行比较，计算有针对性的自监督损失，然后进行在线反向传播以适应模型。

Result: EvoPSF提高了模型在面对环境变化时的鲁棒性，实现了更精确的运动预测，从而能够进行更准确、更稳定的规划。在nuScenes数据集的跨区域和损坏变体上的实验表明，EvoPSF在挑战性条件下持续提升了规划性能。

Conclusion: EvoPSF提高了模型在面对环境变化时的鲁棒性，实现了更精确的运动预测，从而能够进行更准确、更稳定的规划。在nuScenes数据集的跨区域和损坏变体上的实验表明，EvoPSF在挑战性条件下持续提升了规划性能。

Abstract: Recent years have witnessed remarkable progress in autonomous driving, with
systems evolving from modular pipelines to end-to-end architectures. However,
most existing methods are trained offline and lack mechanisms to adapt to new
environments during deployment. As a result, their generalization ability
diminishes when faced with unseen variations in real-world driving scenarios.
In this paper, we break away from the conventional "train once, deploy forever"
paradigm and propose EvoPSF, a novel online Evolution framework for autonomous
driving based on Planning-State Feedback. We argue that planning failures are
primarily caused by inaccurate object-level motion predictions, and such
failures are often reflected in the form of increased planner uncertainty. To
address this, we treat planner uncertainty as a trigger for online evolution,
using it as a diagnostic signal to initiate targeted model updates. Rather than
performing blind updates, we leverage the planner's agent-agent attention to
identify the specific objects that the ego vehicle attends to most, which are
primarily responsible for the planning failures. For these critical objects, we
compute a targeted self-supervised loss by comparing their predicted waypoints
from the prediction module with their actual future positions, selected from
the perception module's outputs with high confidence scores. This loss is then
backpropagated to adapt the model online. As a result, our method improves the
model's robustness to environmental changes, leads to more precise motion
predictions, and therefore enables more accurate and stable planning behaviors.
Experiments on both cross-region and corrupted variants of the nuScenes dataset
demonstrate that EvoPSF consistently improves planning performance under
challenging conditions.

</details>


### [284] [OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation](https://arxiv.org/abs/2508.11479)
*Tatiana Zemskova,Aleksei Staroverov,Dmitry Yudin,Aleksandr Panov*

Main category: cs.RO

TL;DR: OVSegDT是一种新的Transformer策略，通过语义分支和熵自适应损失调制，解决了现有方法泛化能力差和行为不安全的问题。该模型在Open-vocabulary Object Goal Navigation任务上取得了最先进的性能，同时降低了训练成本和碰撞次数。


<details>
  <summary>Details</summary>
Motivation: 现有方法在小型模拟器数据集上进行端到端训练时存在过拟合问题，导致在训练场景中成功率高但在未见过类别上泛化能力差且行为不安全（频繁碰撞）。

Method: 提出了一种名为OVSegDT的轻量级Transformer策略，包含两个主要部分：1. 语义分支：使用目标二值掩码的编码器和辅助分割损失函数，将文本目标与精确的空间线索相结合。2. 熵自适应损失调制：一种根据策略熵动态平衡模仿和强化信号的样本级调度器，消除了手动切换的弊端。

Result: OVSegDT模型在未见类别上的表现与在已见类别上的表现相当，并且在HM3D-OVON数据集的验证集上取得了40.1%的成功率（SR）和20.9%的SPL（Split-based Performance Evaluation）的最先进结果。同时，该模型将训练样本复杂度降低了33%，碰撞次数减少了2倍，并且保持了低推理成本（130M参数，仅使用RGB输入）。

Conclusion: OVSegDT模型在HM3D-OVON数据集上实现了最先进的性能（在未见类别上达到40.1%的成功率和20.9%的SPL），并且无需深度、里程表或大型视觉-语言模型，同时将训练样本复杂度降低了33%，碰撞次数减少了2倍，推理成本仍然很低（130M参数，仅RGB输入）。

Abstract: Open-vocabulary Object Goal Navigation requires an embodied agent to reach
objects described by free-form language, including categories never seen during
training. Existing end-to-end policies overfit small simulator datasets,
achieving high success on training scenes but failing to generalize and
exhibiting unsafe behaviour (frequent collisions). We introduce OVSegDT, a
lightweight transformer policy that tackles these issues with two synergistic
components. The first component is the semantic branch, which includes an
encoder for the target binary mask and an auxiliary segmentation loss function,
grounding the textual goal and providing precise spatial cues. The second
component consists of a proposed Entropy-Adaptive Loss Modulation, a per-sample
scheduler that continuously balances imitation and reinforcement signals
according to the policy entropy, eliminating brittle manual phase switches.
These additions cut the sample complexity of training by 33%, and reduce
collision count in two times while keeping inference cost low (130M parameters,
RGB-only input). On HM3D-OVON, our model matches the performance on unseen
categories to that on seen ones and establishes state-of-the-art results (40.1%
SR, 20.9% SPL on val unseen) without depth, odometry, or large vision-language
models. Code is available at https://github.com/CognitiveAISystems/OVSegDT.

</details>


### [285] [i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping](https://arxiv.org/abs/2508.11485)
*Hailiang Tang,Tisheng Zhang,Liqiang Wang,Xin Ding,Man Yuan,Zhiyu Xiang,Jujin Chen,Yuhan Bian,Shuangyan Liu,Yuqing Wang,Guan Wang,Xiaoji Niu*

Main category: cs.RO

TL;DR: i2Nav-Robot 是一个大规模数据集，用于多传感器融合导航和建图，解决了现有数据集的局限性，并提供了高质量的数据。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶机器人（UGV）数据集在传感器配置、时间同步、地面真实性以及场景多样性方面存在局限性，无法满足导航和建图技术发展的需求。

Method: 提出了一种名为 i2Nav-Robot 的大规模数据集，该数据集专为室内外环境中的多传感器融合导航和建图而设计。它集成了多种传感器，包括固态激光雷达、4D 雷达、立体摄像头、里程计、GNSS 接收器和 IMU。

Result: 该数据集包含了十个大规模序列，涵盖了室外街道和室内停车场等多种 UGV 操作场景，总长度约 17060 米。它提供了高频、厘米级精度的位置地面真实性数据。

Conclusion: 该数据集具有优越的数据质量，并已被十多个开源多传感器融合系统评估。

Abstract: Accurate and reliable navigation is crucial for autonomous unmanned ground
vehicle (UGV). However, current UGV datasets fall short in meeting the demands
for advancing navigation and mapping techniques due to limitations in sensor
configuration, time synchronization, ground truth, and scenario diversity. To
address these challenges, we present i2Nav-Robot, a large-scale dataset
designed for multi-sensor fusion navigation and mapping in indoor-outdoor
environments. We integrate multi-modal sensors, including the newest front-view
and 360-degree solid-state LiDARs, 4-dimensional (4D) radar, stereo cameras,
odometer, global navigation satellite system (GNSS) receiver, and inertial
measurement units (IMU) on an omnidirectional wheeled robot. Accurate
timestamps are obtained through both online hardware synchronization and
offline calibration for all sensors. The dataset comprises ten larger-scale
sequences covering diverse UGV operating scenarios, such as outdoor streets,
and indoor parking lots, with a total length of about 17060 meters.
High-frequency ground truth, with centimeter-level accuracy for position, is
derived from post-processing integrated navigation methods using a
navigation-grade IMU. The proposed i2Nav-Robot dataset is evaluated by more
than ten open-sourced multi-sensor fusion systems, and it has proven to have
superior data quality.

</details>


### [286] [Relative Position Matters: Trajectory Prediction and Planning with Polar Representation](https://arxiv.org/abs/2508.11492)
*Bozhou Zhang,Nan Song,Bingzhao Gao,Li Zhang*

Main category: cs.RO

TL;DR: Polaris：一种在极坐标系中运行的轨迹预测和规划方法，可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在笛卡尔坐标系中对自车与周围交通元素的相对关系进行建模可能不是最优的，因为它不能自然地捕捉不同元素基于其相对距离和方向变化的のを。

Method: Polaris 方法完全在极坐标系中运行，利用极坐标表示来显式建模距离和方向变化，并通过专门的编码和细化模块捕获相对关系。

Result: 通过利用极坐标表示，该方法能够更结构化和空间感知地进行轨迹预测和规划。

Conclusion: Polaris 在具有挑战性的预测 (Argoverse 2) 和规划基准 (nuPlan) 上实现了最先进的性能。

Abstract: Trajectory prediction and planning in autonomous driving are highly
challenging due to the complexity of predicting surrounding agents' movements
and planning the ego agent's actions in dynamic environments. Existing methods
encode map and agent positions and decode future trajectories in Cartesian
coordinates. However, modeling the relationships between the ego vehicle and
surrounding traffic elements in Cartesian space can be suboptimal, as it does
not naturally capture the varying influence of different elements based on
their relative distances and directions. To address this limitation, we adopt
the Polar coordinate system, where positions are represented by radius and
angle. This representation provides a more intuitive and effective way to model
spatial changes and relative relationships, especially in terms of distance and
directional influence. Based on this insight, we propose Polaris, a novel
method that operates entirely in Polar coordinates, distinguishing itself from
conventional Cartesian-based approaches. By leveraging the Polar
representation, this method explicitly models distance and direction variations
and captures relative relationships through dedicated encoding and refinement
modules, enabling more structured and spatially aware trajectory prediction and
planning. Extensive experiments on the challenging prediction (Argoverse 2) and
planning benchmarks (nuPlan) demonstrate that Polaris achieves state-of-the-art
performance.

</details>


### [287] [Swarm-in-Blocks: Simplifying Drone Swarm Programming with Block-Based Language](https://arxiv.org/abs/2508.11498)
*Agnes Bressan de Almeida,Joao Aires Correa Fernandes Marsicano*

Main category: cs.RO

TL;DR: Swarm in Blocks is a block-based programming tool that simplifies drone swarm management for beginners, built on the Clover platform.


<details>
  <summary>Details</summary>
Motivation: To address the growing complexities of managing drone swarms, especially for beginners, and to make swarm handling accessible without extensive knowledge of ROS or programming.

Method: Using a block-based language interface built on the Clover platform to simplify drone swarm programming, allowing users to create functionalities like loops and conditional structures by assembling code blocks.

Result: The development of Swarm in Blocks and Swarm in Blocks 2.0, which simplifies swarm control and offers educational benefits.

Conclusion: Swarm in Blocks simplifies drone swarm programming with a block-based language, making it accessible for beginners and expanding educational opportunities.

Abstract: Swarm in Blocks, originally developed for CopterHack 2022, is a high-level
interface that simplifies drone swarm programming using a block-based language.
Building on the Clover platform, this tool enables users to create
functionalities like loops and conditional structures by assembling code
blocks. In 2023, we introduced Swarm in Blocks 2.0, further refining the
platform to address the complexities of swarm management in a user-friendly
way. As drone swarm applications grow in areas like delivery, agriculture, and
surveillance, the challenge of managing them, especially for beginners, has
also increased. The Atena team developed this interface to make swarm handling
accessible without requiring extensive knowledge of ROS or programming. The
block-based approach not only simplifies swarm control but also expands
educational opportunities in programming.

</details>


### [288] [Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media](https://arxiv.org/abs/2508.11503)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 本研究成功开发了一个模拟到真实（sim-to-real）框架，通过在多样化的模拟环境中训练强化学习代理，显著提高了轮式漫游车在月球模拟地形上的自主导航能力，并验证了程序化多样性训练的有效性。


<details>
  <summary>Details</summary>
Motivation: 为实现未来太空探索中跨越遥远行星表面非结构化地形的可靠自主导航，本研究旨在解决学习控制在模拟与现实之间存在的差距，尤其是在轮式漫游车与颗粒介质复杂交互动力学方面。

Method: 本研究利用大规模并行仿真训练强化学习（RL）代理，使其能够适应程序化生成环境中随机化的物理特性。研究中还对多种强化学习算法和动作平滑滤波器进行了系统性比较，以确定最适合实际部署的组合，并分析了使用高保真粒子物理进行微调的权衡。

Result: 研究结果表明，通过程序化多样性训练的代理相比于在静态场景中训练的代理，在零样本（zero-shot）性能上表现更优。同时，在高保真粒子物理方面，虽然能以微小的性能提升换取低速精度，但其计算成本显著较高。

Conclusion: 本研究提出了一个完整的模拟到真实（sim-to-real）框架，用于开发和验证在月球模拟环境中具有动态路径跟踪能力的轮式漫游车鲁棒控制策略，为在复杂地形上部署自主导航机器人奠定了基础。

Abstract: Reliable autonomous navigation across the unstructured terrains of distant
planetary surfaces is a critical enabler for future space exploration. However,
the deployment of learning-based controllers is hindered by the inherent
sim-to-real gap, particularly for the complex dynamics of wheel interactions
with granular media. This work presents a complete sim-to-real framework for
developing and validating robust control policies for dynamic waypoint tracking
on such challenging surfaces. We leverage massively parallel simulation to
train reinforcement learning agents across a vast distribution of procedurally
generated environments with randomized physics. These policies are then
transferred zero-shot to a physical wheeled rover operating in a lunar-analogue
facility. Our experiments systematically compare multiple reinforcement
learning algorithms and action smoothing filters to identify the most effective
combinations for real-world deployment. Crucially, we provide strong empirical
evidence that agents trained with procedural diversity achieve superior
zero-shot performance compared to those trained on static scenarios. We also
analyze the trade-offs of fine-tuning with high-fidelity particle physics,
which offers minor gains in low-speed precision at a significant computational
cost. Together, these contributions establish a validated workflow for creating
reliable learning-based navigation systems, marking a critical step towards
deploying autonomous robots in the final frontier.

</details>


### [289] [MultiPark: Multimodal Parking Transformer with Next-Segment Prediction](https://arxiv.org/abs/2508.11537)
*Han Zheng,Zikang Zhou,Guli Zhang,Zhepei Wang,Kaixuan Wang,Peiliang Li,Shaojie Shen,Ming Yang,Tong Qin*

Main category: cs.RO

TL;DR: MultiPark 是一种用于多模态停车的自回归变换器，解决了现有模仿学习方法在处理停车行为的多样性和泛化性方面的不足，并通过引入创新的预测范式和面向结果的损失函数，在真实世界数据和部署中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法忽略了无车道开放空间中停车行为的多模态性质，未能获得同一情况下的多种可行解决方案，并且存在固有的因果混淆问题，导致难以在不同的停车场景中泛化。

Method: 提出了一种名为MultiPark的自回归变换器，用于多模态停车。通过引入数据高效的下一个路段预测范式来处理包含急转弯路径，并设计了可学习的停车查询（分为档位、纵向和横向组件）以并行解码不同的停车行为。为了减轻模仿学习中的因果混淆，该方法采用了以目标为中心的姿态和以自我为中心的碰撞作为超越纯模仿损失的面向结果的损失。

Result: MultiPark 实现了最先进的性能，并在量产车上进行了部署，证实了其在真实停车环境中的鲁棒性。

Conclusion: MultiPark在各种场景下实现了最先进的性能，并在量产车上进行了部署，进一步证实了该方法在真实停车环境中的鲁棒性。

Abstract: Parking accurately and safely in highly constrained spaces remains a critical
challenge. Unlike structured driving environments, parking requires executing
complex maneuvers such as frequent gear shifts and steering saturation. Recent
attempts to employ imitation learning (IL) for parking have achieved promising
results. However, existing works ignore the multimodal nature of parking
behavior in lane-free open space, failing to derive multiple plausible
solutions under the same situation. Notably, IL-based methods encompass
inherent causal confusion, so enabling a neural network to generalize across
diverse parking scenarios is particularly difficult. To address these
challenges, we propose MultiPark, an autoregressive transformer for multimodal
parking. To handle paths filled with abrupt turning points, we introduce a
data-efficient next-segment prediction paradigm, enabling spatial
generalization and temporal extrapolation. Furthermore, we design learnable
parking queries factorized into gear, longitudinal, and lateral components,
parallelly decoding diverse parking behaviors. To mitigate causal confusion in
IL, our method employs target-centric pose and ego-centric collision as
outcome-oriented loss across all modalities beyond pure imitation loss.
Evaluations on real-world datasets demonstrate that MultiPark achieves
state-of-the-art performance across various scenarios. We deploy MultiPark on a
production vehicle, further confirming our approach's robustness in real-world
parking environments.

</details>


### [290] [Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks](https://arxiv.org/abs/2508.11584)
*Jakub Łucki,Jonathan Becktor,Georgios Georgakis,Robert Royce,Shehryar Khattak*

Main category: cs.RO

TL;DR: VPEngine 是一个用于资源受限机器人平台的模块化视觉感知框架，通过共享基础模型和并行处理任务，提高了 GPU 利用率和速度（最高 3 倍），并实现了实时性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的机器人平台上部署多个机器学习模型以执行不同感知任务，常常会导致计算冗余、内存占用过大以及复杂的集成挑战。为解决这些问题，本研究提出了 VPEngine。

Method: VPEngine 是一个模块化框架，利用共享的基础模型骨干提取图像表示，并将其在多个并行运行的特定任务模型头之间共享，避免了不必要的 GPU-CPU 内存传输和特征提取的计算冗余。该设计还支持基于应用需求的动态任务优先级排序。

Result: VPEngine 实现了高效的 GPU 利用率和恒定的内存占用，同时允许在运行时动态调整每个任务的推理频率。与顺序执行相比，速度最高可提升 3 倍，并在 NVIDIA Jetson Orin AGX 上实现了 ≥50 Hz 的端到端实时性能。

Conclusion: VPEngine 通过共享 DINOv2 作为基础模型，实现了跨多个任务（深度估计、对象检测和语义分割）的并行处理，与顺序执行相比，速度最高提升了 3 倍。该框架利用 CUDA MPS，实现了高效的 GPU 利用率和恒定的内存占用，并允许在运行时动态调整每个任务的推理频率。在 NVIDIA Jetson Orin AGX 上，使用 TensorRT 优化的模型，实现了 ≥50 Hz 的端到端实时性能。

Abstract: Deploying multiple machine learning models on resource-constrained robotic
platforms for different perception tasks often results in redundant
computations, large memory footprints, and complex integration challenges. In
response, this work presents Visual Perception Engine (VPEngine), a modular
framework designed to enable efficient GPU usage for visual multitasking while
maintaining extensibility and developer accessibility. Our framework
architecture leverages a shared foundation model backbone that extracts image
representations, which are efficiently shared, without any unnecessary GPU-CPU
memory transfers, across multiple specialized task-specific model heads running
in parallel. This design eliminates the computational redundancy inherent in
feature extraction component when deploying traditional sequential models while
enabling dynamic task prioritization based on application demands. We
demonstrate our framework's capabilities through an example implementation
using DINOv2 as the foundation model with multiple task (depth, object
detection and semantic segmentation) heads, achieving up to 3x speedup compared
to sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine
offers efficient GPU utilization and maintains a constant memory footprint
while allowing per-task inference frequencies to be adjusted dynamically during
runtime. The framework is written in Python and is open source with ROS2 C++
(Humble) bindings for ease of use by the robotics community across diverse
robotic platforms. Our example implementation demonstrates end-to-end real-time
performance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized
models.

</details>


### [291] [Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation](https://arxiv.org/abs/2508.11588)
*Benjamin Walt,Jordan Westphal,Girish Krishnan*

Main category: cs.RO

TL;DR: 本研究通过集成多种传感器并使用随机森林分类器，实现了对机器人采摘过程中抓握状态的100%准确识别，并确定了IMU和张力传感器为关键传感器，以提高农业机器人采摘的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 农业环境的复杂性、遮挡以及水果与植物的连接性对机器人抓握状态的准确理解提出了挑战，因此需要选择合适的传感器和建模技术来提高抓握状态识别的准确性。

Method: 评估了IMU、红外反射、张力、触觉传感器和RGB摄像头在抓握状态分类中的作用，并比较了随机森林和LSTM网络的性能。

Result: 随机森林分类器在真实樱桃番茄植物上实现了100%的准确率，并且确定了IMU和张力传感器是识别抓握状态的最小可行传感器组合。

Conclusion: 通过集成IMU和张力传感器，结合随机森林分类器，可以100%准确地识别机器人采摘中的滑动、抓握失败和成功采摘，从而提高水果采摘操作的效率和可靠性。

Abstract: Effective and efficient agricultural manipulation and harvesting depend on
accurately understanding the current state of the grasp. The agricultural
environment presents unique challenges due to its complexity, clutter, and
occlusion. Additionally, fruit is physically attached to the plant, requiring
precise separation during harvesting. Selecting appropriate sensors and
modeling techniques is critical for obtaining reliable feedback and correctly
identifying grasp states. This work investigates a set of key sensors, namely
inertial measurement units (IMUs), infrared (IR) reflectance, tension, tactile
sensors, and RGB cameras, integrated into a compliant gripper to classify grasp
states. We evaluate the individual contribution of each sensor and compare the
performance of two widely used classification models: Random Forest and Long
Short-Term Memory (LSTM) networks. Our results demonstrate that a Random Forest
classifier, trained in a controlled lab environment and tested on real cherry
tomato plants, achieved 100% accuracy in identifying slip, grasp failure, and
successful picks, marking a substantial improvement over baseline performance.
Furthermore, we identify a minimal viable sensor combination, namely IMU and
tension sensors that effectively classifies grasp states. This classifier
enables the planning of corrective actions based on real-time feedback, thereby
enhancing the efficiency and reliability of fruit harvesting operations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [292] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: 本文针对 ASPIC+ 框架提出了一种智能接地程序，解决了处理一阶规则时接地可能导致理论规模爆炸的问题。该方法通过 Datalog 转换和特定简化，在保持推理正确性的前提下提高了效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的 ASPIC+ 方法主要支持命题规则，而对于涉及一阶规则的 ASPIC+ 实例，需要进行接地，但接地可能导致输入理论的大小呈指数级增长，因此需要智能的接地程序来解决这个问题。

Method: 将 ASPIC+ 实例转换为 Datalog 程序，并利用 Datalog 引擎获取接地替换，同时提出针对 ASPIC+ 的简化方法以避免对推理过程没有影响的规则接地。

Result: 提出的智能接地程序能够有效管理接地理论的大小，同时保持推理过程的正确性，并通过经验评估证明了其可扩展性。

Conclusion: 本文提出了一种智能接地程序，该程序通过将 ASPIC+ 实例转换为 Datalog 程序并利用 Datalog 引擎来获取接地替换，从而管理接地理论的大小，同时保持推理过程的正确性。此外，还提出了针对 ASPIC+ 特有的简化方法，以避免对推理过程没有影响的规则进行接地。通过原型实现的经验评估表明该方法具有可扩展性。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [293] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 为解决现实世界中多方参与的算法追溯问题，提出了一种基于二分匹配和多层优化的新框架，能在提高社会福利的同时保证个体可操作性。


<details>
  <summary>Details</summary>
Motivation: 现有的算法追溯研究主要集中在单主体单模型场景，忽略了现实世界中涉及多个相互作用的利益相关者的多主体性质，以及个体福利优化忽视了资源有限情况下的竞争。

Method: 提出了一种多主体算法追溯的新颖框架，将多对多交互建模为有容量的加权二分匹配问题，并通过三层优化框架（基本容量匹配、最小化福利差距的最优容量重新分配、以及考虑福利最大化与容量调整成本的成本感知优化）进行求解。

Result: 实验结果表明，该框架能够实现多对多算法追溯，在系统设置中以最小的改动实现接近最优的社会福利。

Conclusion: 该研究将算法追溯从个体推荐扩展到系统级设计，为在保持个体可操作性的同时提高社会福利提供了可行途径。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [294] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 本研究提出了一种结合L2O和PPO的自动质子治疗计划框架，通过数据驱动和借鉴LLM技术解决了传统方法的耗时和效率问题，在保证计划质量的同时显著缩短了计划时间，并提高了OAR保护和靶区覆盖的性能。


<details>
  <summary>Details</summary>
Motivation: 头部和颈部癌症的质子笔形束扫描（PBS）治疗计划涉及许多相互冲突的目标，需要人类规划者付出大量努力来平衡和满足多个临床目标。为实现这一目标，需要进行耗费经验的目标参数调整和计算成本高昂的逆向优化。尽管在自动调整目标参数方面已做出巨大努力，但最耗时的部分——逆向优化，仍然严重依赖于理论驱动的方法。因此，有必要开发更有效、更高效的自动治疗计划方法。

Method: 该研究提出了一种数据驱动的逆优化器，这是一个L2O（Learning to Optimize）方法，通过学习任务特定的数据分布来预测更新步骤。该逆优化器被集成到一个基于PPO（Proximal Policy Optimization）的框架中。PPO框架作为外循环的虚拟规划器，通过策略网络自主调整目标参数，并使用剂量预测器来初始化目标参数。内循环的L2O逆优化器根据PPO策略网络优化的目标来计算机器可交付的MU（Machine Units）值。该研究还集成了为LLM设计的长上下文处理技术到基于Transformer的L2O框架中，以解决现有L2O方法的扩展性问题。

Result: 该研究收集了97名患者的数据，并将提出的L2O逆优化器与L-BFGSB进行了比较，结果显示在有效性和效率方面分别提高了22.97%和36.41%。结合PPO学习的虚拟规划器，该框架生成的计划在平均2.55小时内完成，与人工生成的计划相比，在OAR的保护和靶区覆盖方面表现出更优或相当的性能，并且适用于具有不同处方剂量水平、靶区数量、射束角度等的患者。

Conclusion: 该研究提出了一种数据驱动的逆优化器，并将其集成到基于PPO的自动治疗计划框架中，以自动生成高质量的治疗计划。该方法通过学习任务特定的数据分布来预测更新步骤，并首次将为LLM设计的长上下文处理技术集成到基于Transformer的L2O框架中，以解决现有L2O方法的扩展性问题。与L-BFGSB相比，该L2O方法在有效性和效率方面分别提高了22.97%和36.41%。与人工生成的计划相比，该框架生成的计划在OAR（危及器官）的保护和靶区覆盖方面均表现出更优或相当的性能。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [295] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 该研究将强相容性和弱相容性引入了一般 ABA，并研究了它们的性质，证明了它们保持了模块化属性，但也存在一些缺点。


<details>
  <summary>Details</summary>
Motivation: 为了扩展相容性概念在基于假设的论证（ABA）中的应用范围，特别是研究了强相容性和弱相容性，并将其应用于一般非平坦 ABA。

Method: 使用抽象双极基于集合的论证框架（BSAFs）作为形式工具，研究了强相容性和弱相容性概念在一般 ABA 中的应用，并探讨了它们的性质和潜在问题。

Result: 在一般 ABA 中引入了强相容性和弱相容性语义，并证明了它们与经典相容性一样，都保持了中心模块化属性。同时，也讨论了这些语义在非平坦 ABA 中的不足之处。

Conclusion: 该研究将强相容性和弱相容性引入了基于假设的论证（ABA）的一般（有时称为非平坦）形式，并研究了它们的性质。研究表明，经典相容性、强相容性和弱相容性在 ABA 中都保持了中心模块化属性。研究还讨论了强相容性和弱相容性语义在非平坦 ABA 中的一些缺点及其可能的解决方案。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [296] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: LRMs在解决不完整数学问题时，无法主动询问缺失信息，并且会出现过度思考和幻觉问题。通过引入新数据集和监督微调，旨在提升LRMs的真正智能。


<details>
  <summary>Details</summary>
Motivation: 现有评估仅关注已定义问题，未能体现智能体主动获取信息的能力。

Method: 提出包含不完整问题的混合数据集，并进行系统性评估。

Result: LRMs在不完整问题上表现不佳，无法主动询问信息，并暴露出“过度思考”和“幻觉”问题。

Conclusion: LRMs在需要主动询问信息时表现不佳，存在“过度思考”和“幻觉”等问题，但通过监督微调有潜力改善。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [297] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: 提出SAGE框架，解决持续知识图谱嵌入的尺度问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有持续知识图谱嵌入方法未能充分考虑KG更新的尺度变化，并且缺乏在整个更新过程中的系统性评估，因此需要提出一种能够适应不同更新尺度并进行系统性评估的框架。

Method: SAGE框架首先根据更新尺度确定嵌入维度并相应地扩展嵌入空间，然后采用动态蒸馏机制来平衡已有知识的学习和新事实的融入。

Result: SAGE在七个基准测试中持续优于现有方法，在MRR、H@1和H@10指标上分别取得了1.38%、1.25%和1.6%的提升。与使用固定嵌入维度的现有方法相比，SAGE在每个快照中都实现了最优性能，证明了自适应嵌入维度在持续知识图谱嵌入中的重要性。

Conclusion: SAGE框架通过自适应调整嵌入维度和动态蒸馏机制，有效解决了现有持续知识图谱嵌入方法在处理不同更新尺度时遇到的问题，并在多个基准测试中展现出优于现有方法的性能，尤其在MRR、H@1和H@10指标上取得了显著提升。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [298] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: CRAFT-GUI通过课程学习和改进奖励机制，提升了自主代理在GUI环境中的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了GUI任务间难度差异，且奖励信号粗糙，导致代理学习效率低下。

Method: 提出CRAFT-GUI框架，基于Group Relative Policy Optimization (GRPO)，并设计了结合规则和模型判断的奖励函数，以处理不同难度和提供更细致的反馈。

Result: 在Android Control和内部在线基准测试中，分别取得了5.6%和10.3%的显著提升，优于现有最先进方法。

Conclusion: 整合强化学习与课程学习能有效提升GUI交互任务的代理表现。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [299] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: AIM-Bench基准测试表明，LLM代理在库存决策中存在类似人类的偏见，需要采取措施（如认知反思、信息共享）来缓解这些偏见，以实现有效的供应链管理。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理在不确定环境下进行库存决策的能力及其潜在的决策偏见（例如框架效应），以解决其在现实世界问题应用中的能力和偏见问题。

Method: 提出AIM-Bench基准，通过一系列库存补充实验评估LLM代理在不确定供应链管理场景中的决策行为。

Result: 不同LLM在库存决策中表现出与人类相似的决策偏见；认知反思和信息共享策略可用于缓解拉中效应和牛鞭效应。

Conclusion: LLM代理在库存决策中存在与人类相似的决策偏见，需要谨慎部署，并考虑认知反思和信息共享等缓解策略。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [300] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: **Inclusion Arena**：一个创新的实时排行榜，通过在实际AI应用中收集用户反馈来评估LLMs和MLLMs。它使用改进的Bradley-Terry模型（含Placement Matches和Proximity Sampling），提供比现有基准更可靠、更稳定的排名，并有效防止作弊，旨在加速模型在真实场景中的优化。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs和MLLMs基准测试和排行榜（如MMLU、Chatbot Arena）大多依赖静态数据集或通用领域提示，未能充分反映模型在真实世界应用中的性能。为了解决这一关键差距，需要一个能够直接从实际应用中收集反馈的评估平台。

Method: 该研究提出了Inclusion Arena，一个实时的模型排名排行榜，它通过在实际AI应用中收集用户反馈来进行模型评估。平台采用成对比较的方式，并将Bradley-Terry模型进行改进，引入了Placement Matches（用于新集成模型的冷启动）和Proximity Sampling（优先选择能力相近的模型进行比较以最大化信息增益和提高排名稳定性）。

Result: Inclusion Arena生成的排名可靠且稳定，与通用众包数据集相比，具有更高的数据传递性，并能显著降低恶意操纵的风险。

Conclusion: Inclusion Arena通过集成实际应用中的用户反馈，采用带有Placement Matches和Proximity Sampling的Bradley-Terry模型，能够生成可靠、稳定且抗操纵的模型排名，旨在加速LLMs和MLLMs在实际应用中的优化和部署。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [301] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: Probabilistic landmarks, adapted from classical planning, improve UCT performance in stochastic planning by acting as subgoals, though the optimal strategy depends on the specific problem.


<details>
  <summary>Details</summary>
Motivation: To explore the underutilization of landmarks in stochastic domains despite their success in classical planning.

Method: Formalized probabilistic landmarks and adapted the UCT algorithm to use them as subgoals for MDP decomposition, balancing greedy landmark achievement with final goal achievement.

Result: Well-chosen landmarks significantly improved UCT performance in benchmark domains, with the optimal balance between greedy and long-term goal achievement being problem-dependent.

Conclusion: Landmarks can provide helpful guidance for anytime algorithms solving MDPs, as demonstrated by their significant performance improvement in UCT for online probabilistic planning.

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [302] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: This paper presents an LLM-assisted planner that tackles large-scale planning problems by decomposing them and using LLMs (LLM4Inspire for general knowledge, LLM4Predict for domain-specific knowledge) to prune the search space. Results show it's effective, especially LLM4Predict.


<details>
  <summary>Details</summary>
Motivation: Large-scale planning problems face state-space explosion due to increasing objects and actions. Leveraging LLMs to prune search spaces is a recent trend, but prior work has overlooked integrating LLMs with domain-specific knowledge to ensure plan validity.

Method: The paper proposes a novel LLM-assisted planner that integrates problem decomposition. It explores two paradigms: LLM4Inspire (using general knowledge for heuristic guidance) and LLM4Predict (using domain-specific knowledge to infer intermediate conditions). The planner decomposes large problems into simpler sub-tasks and utilizes LLMs to assist in this decomposition.

Result: Empirical validation across multiple domains demonstrates the planner's effectiveness in partitioning the search space for large-scale planning problems. LLMs successfully prune the search space to find feasible solutions, with LLM4Predict showing particular promise compared to LLM4Inspire.

Conclusion: LLM-assisted planning, particularly when infused with domain-specific knowledge (LLM4Predict), shows significant promise in effectively pruning search spaces and locating feasible solutions for large-scale planning problems.

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [303] [Overview of Complex System Design](https://arxiv.org/abs/2508.11026)
*John W. Sheppard*

Main category: eess.SY

TL;DR: 本文介绍了系统工程，重点关注复杂集成系统的实现，讨论了系统的定义、集成、复杂性及其管理，并概述了从概念到部署的整个生命周期。


<details>
  <summary>Details</summary>
Motivation: 本文旨在介绍系统工程，重点关注实现复杂集成系统所围绕的广泛问题，并探讨如何管理复杂性。

Method: 本文通过探讨系统的定义、集成、复杂性及其实现过程来介绍系统工程。

Result: 本文为理解和管理复杂集成系统的设计、开发、制造、部署、运行和支持的整个生命周期提供了基础。

Conclusion: 该章节介绍了系统工程，重点关注实现复杂集成系统所围绕的广泛问题。通过探讨系统的定义和视角，强调了系统由各种部件、组件和子系统集成以完成其任务。文章关注不同技术和学科的边界与接口，以实现最佳集成。此外，文章还讨论了系统的复杂性，包括子系统数量、功能交互、计算需求以及新兴行为等方面，并提出了管理复杂性的挑战。最后，文章阐述了系统的实现过程，即从概念到部署和支持的整个生命周期，特别关注那些本身就复杂的系统，即那些庞大、复杂、相互作用且旨在执行困难任务以满足广泛最终用户需求的系统。

Abstract: This chapter serves as an introduction to systems engineering focused on the
broad issues surrounding realizing complex integrated systems. What is a
system? We pose a number of possible definitions and perspectives, but leave
open the opportunity to consider the system from the target context where it
will be used. Once we have a system in mind, we acknowledge the fact that this
system needs to integrate a variety of pieces, components, subsystems, in order
for it to accomplish its task. Therefore, we concern ourselves at the
boundaries and interfaces of different technologies and disciplines to
determine how best to achieve that integration. Next we raise the specter that
this integrated system is complex. Complexity can be defined in a number of
ways. For one, the sheer number of subsystems or components can be a measure of
complexity. We could also consider the functions being performed by the system
and how those functions interact with one another. Further, we could consider
computational aspects such as the time or memory that may be needed to
accomplish one or more tasks. The extent to which new behaviors might emerge
from the system can also be regarded as an element of complexity. In the end,
complexity is that characteristic of a system that defines the associated
challenges along the life of the system, so we are concerned with how to manage
that complexity. Finally, realization refers to the process by which our
complex integrated system moves from concept to deployment and subsequent
support. It refers to the entire design, development, manufacture, deployment,
operation, and support life cycle. Of particular note here, however, is that we
focus on systems that, by their very nature, are complex. In other words, we
are interested in large, complicated, interacting beasts that are intended to
perform difficult tasks and meet a wide variety of end-user needs.

</details>


### [304] [Risk-Based Prognostics and Health Management](https://arxiv.org/abs/2508.11031)
*John W. Sheppard*

Main category: eess.SY

TL;DR: 本章介绍了一种结合风险评估和故障预测的基于风险的预测方法，使用了连续时间贝叶斯网络，并展示了其在实际应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 将风险评估和预测视为关联但独立任务的普遍观念，旨在提供一种将风险评估与故障预测更紧密结合的基于风险的预测方法。

Method: 采用连续时间贝叶斯网络作为基础建模框架，并概述了从中导出这些模型的数据技术。

Result: 展示了如何使用连续时间贝叶斯网络实现这一目标，并说明了这些模型如何在实际应用中用于决策支持和基于绩效的后勤保障。

Conclusion: 本章将描述一种基于风险的预测方法，该方法旨在加强风险评估与故障预测之间的联系。

Abstract: It is often the case that risk assessment and prognostics are viewed as
related but separate tasks. This chapter describes a risk-based approach to
prognostics that seeks to provide a tighter coupling between risk assessment
and fault prediction. We show how this can be achieved using the
continuous-time Bayesian network as the underlying modeling framework.
Furthermore, we provide an overview of the techniques that are available to
derive these models from data and show how they might be used in practice to
achieve tasks like decision support and performance-based logistics. This work
is intended to provide an overview of the recent developments related to
risk-based prognostics, and we hope that it will serve as a tutorial of sorts
that will assist others in adopting these techniques.

</details>


### [305] [A Neural Column-and-Constraint Generation Method for Solving Two-Stage Stochastic Unit Commitment](https://arxiv.org/abs/2508.11071)
*Zhentong Shao,Jingtao Qin,Nanpeng Yu*

Main category: eess.SY

TL;DR: 提出了一种名为Neural CCG的新方法，使用神经网络来加速解决电力系统中的单位承诺问题，速度提升显著且误差低。


<details>
  <summary>Details</summary>
Motivation: 为了管理间歇性可再生能源高渗透率带来的不确定性，两阶段随机单位承诺（2S-SUC）问题被广泛采用。然而，现有的基于分解的算法（如列-约束生成）在计算上对于大规模、实时应用来说仍然是昂贵的。

Method: 本文提出了一种神经列-约束生成（Neural CCG）方法，该方法将神经网络集成到CCG框架中，通过学习操作场景的高层特征和第一阶段的承诺决策来逼近第二阶段的对策问题，从而用快速的神经评估替代重复的子问题求解。

Result: 在IEEE 118总线系统上的验证结果表明，与原始CCG和最先进的商业求解器相比，Neural CCG实现了高达130.1倍的加速，同时将平均最优误差保持在0.096%以下。

Conclusion: 本文提出的神经列-约束生成（Neural CCG）方法显著加速了两阶段随机单位承诺（2S-SUC）问题的求解，在大规模、实时应用中展现出巨大潜力。

Abstract: Two-stage stochastic unit commitment (2S-SUC) problems have been widely
adopted to manage the uncertainties introduced by high penetrations of
intermittent renewable energy resources. While decomposition-based algorithms
such as column-and-constraint generation has been proposed to solve these
problems, they remain computationally prohibitive for large-scale, real-time
applications. In this paper, we introduce a Neural Column-and-Constraint
Generation (Neural CCG) method to significantly accelerate the solution of
2S-SUC problems. The proposed approach integrates a neural network that
approximates the second-stage recourse problem by learning from high-level
features of operational scenarios and the first-stage commitment decisions.
This neural estimator is embedded within the CCG framework, replacing repeated
subproblem solving with rapid neural evaluations. We validate the effectiveness
of the proposed method on the IEEE 118-bus system. Compared to the original CCG
and a state-of-the-art commercial solver, Neural CCG achieves up to
130.1$\times$ speedup while maintaining a mean optimality gap below 0.096\%,
demonstrating its strong potential for scalable stochastic optimization in
power system.

</details>


### [306] [Managing Risks from Large Digital Loads Using Coordinated Grid-Forming Storage Network](https://arxiv.org/abs/2508.11080)
*Soumya Kundu,Kaustav Chatterjee,Ramij R. Hossain,Sai Pushpak Nandanoori,Veronica Adetola*

Main category: eess.SY

TL;DR: 人工智能数据中心对电网的稳定性构成了挑战，但可以通过协调储能系统来解决，而无需昂贵的升级。本研究探索了不同储能配置的有效性。


<details>
  <summary>Details</summary>
Motivation: 人工智能数据中心驱动的大型数字负荷的预期快速增长，将增加能源基础设施的消耗不确定性和大幅波动，威胁其稳定、可靠和安全。传统的电网规划和运行措施，如输电升级或发电控制，在应对人工智能数据中心带来的极端负荷瞬态等独特挑战方面成本高昂或能力不足。

Method: 利用最近开发的双层协调控制策略，包括用于维持电压和频率瞬态安全的快速本地自主控制，以及用于恢复电网正常运行条件的较慢协调（共识）控制。

Result: 将协调的、分散的、小型储能网络与并置的大型储能设施进行了比较，并在 IEEE 68 总线网络上使用 MIT 超级计算机数据集中的大型数字负荷配置文件进行了案例研究。

Conclusion: 通过协调和管理电网中可用的灵活性，例如使用并网储能单元，可以确保人工智能数据中心稳定可靠地集成，而无需进行昂贵的电网升级。

Abstract: Anticipated rapid growth of large digital load, driven by artificial
intelligence (AI) data centers, is poised to increase uncertainty and large
fluctuations in consumption, threatening the stability, reliability, and
security of the energy infrastructure. Conventional measures taken by grid
planners and operators to ensure stable and reliable integration of new
resources are either cost-prohibitive (e.g., transmission upgrades) or
ill-equipped (e.g., generation control) to resolve the unique challenges
brought on by AI Data Centers (e.g., extreme load transients). In this work, we
explore the feasibility of coordinating and managing available flexibility in
the grid, in terms of grid-forming storage units, to ensure stable and reliable
integration of AI Data Centers without the need for costly grid upgrades.
Recently developed bi-layered coordinated control strategies -- involving
fast-acting, local, autonomous, control at the storage to maintain transient
safety in voltage and frequency at the point-of-interconnection, and a slower,
coordinated (consensus) control to restore normal operating condition in the
grid -- are used in the case studies. A comparison is drawn between broadly two
scenarios: a network of coordinated, smaller, distributed storage vs. larger
storage installations collocated with large digital loads. IEEE 68-bus network
is used for the case studies, with large digital load profiles drawn from the
MIT Supercloud Dataset.

</details>


### [307] [Direct data-driven interpolation and approximation of linear parameter-varying system trajectories](https://arxiv.org/abs/2508.11332)
*Chris Verhoek,Ivan Markovsky,Roland Tóth*

Main category: eess.SY

TL;DR: 对于移位仿射 LPV 系统，提出了一种数据驱动的插值算法来估计轨迹中的缺失值。


<details>
  <summary>Details</summary>
Motivation: 处理线性参数变化（LPV）系统轨迹中缺失值的问题。

Method: 提出了一种直接的数据驱动算法来计算缺失值，该算法不依赖于参数模型，而是由数据隐式指定。

Result: 算法适用于移位仿射LPV系统，并在一类具有外生和内生参数变化的质量-弹簧-阻尼系统上进行了验证。

Conclusion: 提出了一种用于处理移位仿射 LPV 系统轨迹中缺失值的插值算法，并给出了存在性和唯一性的条件。

Abstract: We consider the problem of estimating missing values in trajectories of
linear parameter-varying (LPV) systems. We solve this interpolation problem for
the class of shifted-affine LPV systems. Conditions for the existence and
uniqueness of solutions are given and a direct data-driven algorithm for its
computation is presented, i.e., the data-generating system is not given by a
parametric model but is implicitly specified by data. We illustrate the
applicability of the proposed solution on illustrative examples of a
mass-spring-damper system with exogenous and endogenous parameter variation.

</details>


### [308] [System Synchronization Based on Complex Frequency](https://arxiv.org/abs/2508.11381)
*Yusen Wei,Lan Tang*

Main category: eess.SY

TL;DR: This paper introduces complex-frequency synchronization and generalized inertia to analyze low-inertia power systems, addressing the inadequacy of traditional methods in handling coupled frequency and voltage dynamics.


<details>
  <summary>Details</summary>
Motivation: Traditional synchronization criteria are inadequate for characterizing coupled frequency and voltage dynamics in low-inertia power systems due to the inertia decline caused by high renewable generation penetration.

Method: The paper presents the theory of complex-frequency synchronization, derives local and global dynamic synchronization criteria, and introduces the concept of generalized inertia to unify frequency and voltage support.

Result: The study introduces complex-frequency synchronization, generalized inertia, and a visualization workflow for key indicators, demonstrating their effectiveness in analyzing low-inertia power systems.

Conclusion: The proposed complex-frequency synchronization theory and analysis framework provide a new perspective for analyzing low-inertia power systems, validating its effectiveness through numerical case studies.

Abstract: In response to the inertia decline caused by high penetration of renewable
generation, traditional synchronization criteria that rely solely on frequency
consistency are increasingly inadequate for characterizing the coupled behavior
of frequency and voltage dynamics during power-system transients. This paper
focuses on the theory of complex-frequency synchronization and develops a
theory-simulation analysis framework that offers a new perspective for
steady-state and transient analysis of low-inertia power systems. First, the
fundamental concepts and theoretical foundations of complex-frequency
synchronization are presented in detail. Second, local and global dynamic
synchronization criteria are derived and the concept of generalized inertia is
introduced, which unifies the conventional inertial support to frequency with
the inertia-like support of voltage, thereby providing an accurate measure of
region-level coupled support strength for voltage and frequency. Finally,
numerical case studies on the IEEE 9-bus system validate the effectiveness of
the proposed theoretical methods and criteria, and demonstrate a visualization
workflow for key indicators such as disturbance impact zones and
generalized-inertia regions.

</details>


### [309] [Principles of Physiological Closed-Loop Controllers in Neuromodulation](https://arxiv.org/abs/2508.11422)
*Victoria S. Marks,Joram vanRheede,Dean Karantonis,Rosana Esteller,David Dinsmoor,John Fleming,Barrett Larson,Lane Desborough,Peter Single,Robert Raike,Pierre-Francois DHaese,Dario J. Englot,Scott Lempka,Richard North,Lawrence Poree,Marom Bikson,Tim J. Denison*

Main category: eess.SY

TL;DR: A framework is presented for designing and managing risks in closed-loop neuromodulation devices, incorporating FDA guidance and classifying biomarkers to ensure rigorous development and implementation.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of closed-loop neurostimulation devices necessitates a structured approach to risk management and benefit optimization. This work aims to provide guidance for the emerging field of PCLCs in neuromodulation.

Method: The manuscript develops a common framework for mapping current and planned neuromodulation-based PCLCs. This framework integrates FDA's 2023 guidance, classifies biomarkers into feedback (reactive) and feedforward (predictive) types, and applies control systems theory. The authors explain risk management within this framework and illustrate its application with three exemplary technologies.

Result: The manuscript establishes a common framework for PCLCs, which aids in risk management and streamlines device development, testing, and implementation by offering standardized nomenclature and a systematic outline. Its applications are illustrated through three exemplary technologies.

Conclusion: This manuscript provides a framework for the design, development, testing, and implementation of neuromodulation-based physiological closed-loop controllers (PCLCs), aiming to mitigate risks through standardized nomenclature and a systematic approach. It also incorporates FDA guidance and classifies biomarkers.

Abstract: As neurostimulation devices increasingly incorporate closed-loop
functionality, the greater design complexity brings additional requirements for
risk management and special considerations to optimise benefit. This manuscript
creates a common framework upon which all current and planned
neuromodulation-based physiological closed-loop controllers (PCLCs) can be
mapped including integration of the Technical Considerations of Medical Devices
with Physiologic Closed-Loop Control Technology guidance published in 2023 by
the United States Food and Drug Administration (FDA), a classification of
feedback (reactive) and feedforward (predictive) biomarkers, and control
systems theory. We explain risk management in the context of this framework and
illustrate its applications for three exemplary technologies. This manuscript
serves as guidance to the emerging field of PCLCs in neuromodulation,
mitigating risk through standardized nomenclature and a systematic outline for
rigorous device development, testing, and implementation.

</details>


### [310] [Integrating Uncertainties for Koopman-Based Stabilization](https://arxiv.org/abs/2508.11533)
*Yicheng Lin,Bingxian Wu,Nan Bai,Zhiyong Sun,Yunxiao Ren,Chuanze Chen,Zhisheng Duan*

Main category: eess.SY

TL;DR: 本文提出了一个统一框架，用于解决数据驱动控制中Koopman算子的鲁棒稳定化问题，考虑了三种不确定性，并通过直接和间接方法进行了验证。


<details>
  <summary>Details</summary>
Motivation: 尽管Koopman算子在数据驱动控制中应用广泛，但其理论基础仍需深入研究。本文旨在建立一个统一的框架，以解决数据驱动控制中Koopman算子的鲁棒稳定化问题，并充分考虑各种不确定性。

Method: 本文提出一个统一框架来解决数据驱动控制中的鲁棒稳定化问题，该框架考虑了投影误差、估计误差和过程扰动。对于直接方法，设计了一个通过线性矩阵不等式（LMI）实现的提升状态反馈控制器，能够鲁棒地稳定所有与噪声数据一致的提升双线性系统。对于间接方法，设计了一个可通过非线性矩阵不等式转换为LMI的反馈控制器，确保闭环系统在最坏情况下的过程扰动下保持稳定。

Result: 通过数值模拟和交叉验证，证明了直接和间接数据驱动控制方法在处理Koopman算子鲁棒稳定化问题上的有效性，突显了其理论意义和实践价值。

Conclusion: 本文提出的统一框架能够通过直接和间接数据驱动控制方法，在考虑了投影误差、估计误差和过程扰动三种不确定性的情况下，解决Koopman算子的鲁棒稳定化问题。数值模拟验证了这两种方法的有效性。

Abstract: Over the past decades, the Koopman operator has been widely applied in
data-driven control, yet its theoretical foundations remain underexplored. This
paper establishes a unified framework to address the robust stabilization
problem in data-driven control via the Koopman operator, fully accounting for
three uncertainties: projection error, estimation error, and process
disturbance. It comprehensively investigates both direct and indirect
data-driven control approaches, facilitating flexible methodology selection for
analysis and control. For the direct approach, considering process
disturbances, the lifted-state feedback controller, designed via a linear
matrix inequality (LMI), robustly stabilizes all lifted bilinear systems
consistent with noisy data. For the indirect approach requiring system
identification, the feedback controller, designed using a nonlinear matrix
inequality convertible to an LMI, ensures closed-loop stability under
worst-case process disturbances. Numerical simulations via cross-validation
validate the effectiveness of both approaches, highlighting their theoretical
significance and practical utility.

</details>


### [311] [Identification of Sub/Super-Synchronous Control Interaction Paths Using Dissipative Energy Flow](https://arxiv.org/abs/2508.11561)
*Kaustav Chatterjee,Sameer Nekkalapu,Sayak Mukherjee,Ramij Raja Hossain,Marcelo Elizondo*

Main category: eess.SY

TL;DR: 本文将耗散能量流（DEF）方法扩展到识别次同步和超同步控制相互作用（SSCIs）的源和路径，解决了传统方法难以处理多频率和复杂网络的问题。通过仿真案例验证，该方法可以区分不同频率下的源和汇作用，为SSCI诊断提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: SSCIs涉及多个频率并穿过复杂的互连路径传播，使得基于模型的方法难以同时识别振荡能量流的源和路径。

Method: 本文将最初为低频机电振荡开发的耗散能量流（DEF）方法扩展到使用三相电压和电流测量来识别跨越多个频率的SSCI源和动态相互作用路径。该方法在dq框架中使用动态相量运行，能够从带通滤波信号计算模式特定的DEF。

Result: EMT案例研究表明，该方法能够区分频率相关的源和汇作用，包括同一资源在不同频率下分别充当源和汇的情况。

Conclusion: 该方法为富含IBR的电网的SSCI诊断提供了一个基于物理且自动化友好的工具。

Abstract: Sub- and super-synchronous control interactions (SSCIs) are oscillations
arising from adverse interactions between inverter-based resource (IBR)
controls and the power network. SSCIs often involve multiple frequencies and
propagate through complex, interconnected paths, making it difficult for
model-based approaches to identify both the sources and the paths of
oscillatory energy flow. This paper extends the Dissipative Energy Flow (DEF)
method, originally developed for low-frequency electromechanical oscillations,
to identify SSCI sources and dynamic interaction paths across multiple
frequencies using three-phase voltage and current measurements. The approach
operates in the dq frame using dynamic phasors, enabling mode-specific DEF
computation from bandpass-filtered signals. An electromagnetic transient (EMT)
case study on a meshed network with synchronous generator and type-3 wind farm
resources under series-compensated conditions demonstrates the method's
capability to distinguish frequency-dependent source and sink roles, including
cases where the same resource acts as a source at one frequency and a sink at
another. The results show DEF can provide a physics-based and
automation-friendly tool for SSCI diagnosis in IBR-rich grids.

</details>


### [312] [Two-Impulse Trajectory Design in Two-Body Systems With Riemannian Geometry](https://arxiv.org/abs/2508.11612)
*Samuel G. Gessow,James Tseng,Eden Zafran,Brett T. Lopez*

Main category: eess.SY

TL;DR: 提出一种基于黎曼几何（雅可比度量）的新方法，用于在受限二体系统中生成冲动轨迹，优化燃料消耗，并能处理$J_2$等扰动。


<details>
  <summary>Details</summary>
Motivation: 为了解决标准轨迹优化方法中存在的对初始猜测敏感等问题，并将其应用于更复杂的二体系统。

Method: 通过利用黎曼几何，将标准轨迹优化问题转化为纯粹的几何问题，涉及计算一组适用于黎曼度量的测地线。通过定义嵌入动力学的雅可比度量来实现这种转化，使得度量的任何测地线也是动力学上可行的轨迹。通过为当前轨道和期望轨道的不同点采样候选能量（$\Delta V$）变化，并有效地计算和评估每个候选测地线（通过雅可比度量等价于候选轨道转移轨迹），来寻找燃料最优转移轨迹。

Result: 通过数值模拟和性能比较展示了该方法在最小$\Delta V$问题上的有效性，包括在开普勒系统和具有$J_2$扰动的系统上的应用。

Conclusion: 该方法在开普勒系统中达到或超过了最先进的最优$\Delta V$问题方法，并且能够无缝地处理$J_2$扰动，这是许多现有方法无法处理的情况。

Abstract: This work presents a new method for generating impulsive trajectories in
restricted two-body systems by leveraging Riemannian geometry. The proposed
method transforms the standard trajectory optimization problem into a purely
geometric one that involves computing a set of geodesics for a suitable
Riemannian metric. This transformation is achieved by defining a metric,
specifically the Jacobi metric, that embeds the dynamics directly into the
metric, so any geodesic of the metric is also a dynamically feasible
trajectory. The method finds the fuel-optimal transfer trajectory by sampling
candidate energy ($\Delta V$) changes for different points on the current and
desired orbit, and efficiently computing and evaluating each candidate
geodesic, which are equivalent to candidate orbit transfer trajectories via the
Jacobi metric. The method bypasses the known issues of optimization-based
methods, e.g., sensitivity to the initial guess, and can be applied to more
complex two-body systems. The approach is demonstrated on the minimum-$\Delta
V$ two-impulse phase-free orbit transfer problem, first on a Keplerian system
and second on a system with a modeled $J_2$ perturbation. The proposed method
is shown to meet or exceed the state-of-the-art methods in the minimum-$\Delta
V$ problem in the Keplerian system. The generality and versatility of the
approach is demonstrated by seamlessly including the $J_2$ perturbation, a case
that many existing methods cannot handle. Numerical simulations and performance
comparisons showcase the effectiveness of the approach.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [313] [Characterizing NC1 with Typed Monoids](https://arxiv.org/abs/2508.11019)
*Anuj Dawar,Aidan T. Evans*

Main category: cs.LO

TL;DR: This paper characterizes the complexity class NC1 using logic and algebra. It shows NC1 is equivalent to languages expressible in a specific type of first-order logic. The paper also proves a general result about replacing complex quantifiers with simpler ones in certain mathematical structures, which has broader implications.


<details>
  <summary>Details</summary>
Motivation: To extend the algebraic automata theory methods beyond regular languages and characterize complexity classes beyond TC0, specifically NC1.

Method: The paper first defines NC1 as languages expressible in an extended first-order logic using unary quantifiers over regular languages. It then proves a general result that finite monoid multiplication quantifiers of higher dimensions can be replaced with unary quantifiers in interpretations over strings, extending previous work and answering a question by Lautemann et al. The collapse result is established for a broader class of interpretations using Bojańczyk et al.'s (2019) results.

Result: NC1 is characterized as languages expressible in first-order logic extended with unary quantifiers over regular languages. A general collapse result is proven, showing that higher-dimensional monoid multiplication quantifiers can be replaced by unary quantifiers in interpretations over strings, which generalizes previous findings and answers an open question.

Conclusion: The paper provides a characterization of NC1 by linking it to extensions of first-order logic with unary quantifiers over regular languages. It also generalizes a collapse result concerning quantifiers in interpretations over strings.

Abstract: Krebs et al. (2007) gave a characterization of the complexity class TC0 as
the class of languages recognized by a certain class of typed monoids. The
notion of typed monoid was introduced to extend methods of algebraic automata
theory to infinite monoids and hence characterize classes beyond the regular
languages. We advance this line of work beyond TC0 by giving a characterization
of NC1. This is obtained by first showing that NC1 can be defined as the
languages expressible in an extension of first-order logic using only unary
quantifiers over regular languages. The expressibility result is a consequence
of a general result showing that finite monoid multiplication quantifiers of
higher dimension can be replaced with unary quantifiers in the context of
interpretations over strings, which also answers a question of Lautemann et al.
(2001). We establish this collapse result for a much more general class of
interpretations using results on interpretations due to Boja\'nczyk et al.
(2019), which may be of independent interest.

</details>


### [314] [Automating the Derivation of Unification Algorithms: A Case Study in Deductive Program Synthesis](https://arxiv.org/abs/2508.11136)
*Richard Waldinger*

Main category: cs.LO

TL;DR: 该研究提出了一种自动化的统一算法，该算法通过引入“环境”参数，比以往的方法更容易实现自动化，并且效率更高。


<details>
  <summary>Details</summary>
Motivation: 程序综合研究的目标是实现统一算法的全自动推导。演绎程序综合将计算机编程视为一个定理证明任务，通过自动定理证明器来推导满足给定规格的程序，并从证明中提取程序，从而确保程序的正确性。

Method: 该研究提出了一种新的统一算法，该算法采用了“环境”参数，并声称这种三参数算法比Manna-Waldinger论文中的两参数版本更容易自动综合，并且效率更高。证明过程建立了输出替换的存在性，该替换是给定表达式的最一般的幂等统一器，并且是环境替换的“扩展”。如果表达式不可统一，程序将产生一个失败指示符。

Result: 该研究的证明确立了输出替换的存在性，该替换是给定表达式的最一般的幂等统一器，并且是环境替换的“扩展”。当表达式不可统一时，程序会生成一个失败指示符。

Conclusion: 该研究通过泛化和自动化Manna和Waldinger[1981]中提出的手动证明，对统一算法进行了研究，旨在实现完全自动化的程序推导。新程序能够根据给定的“环境”替换来统一两个符号表达式（s-expressions）。

Abstract: The unification algorithm has long been a target for program synthesis
research, but a fully automatic derivation remains a research goal. In
deductive program synthesis, computer programming is phrased as a task in
theorem proving; a declarative specification is expressed in logical form and
presented to an automatic theorem prover, and a program meeting the
specification is extracted from the proof. The correctness of the program is
supported by the proof, which also provides an explanation of how the program
works. The proof is conducted in an appropriate axiomatic subject-domain
theory, which defines the concepts in the specification and the constructs in
the target programming language and provides the background knowledge necessary
to connect them.
  For the unification proof, we generalize and automate the manual proof
presented in Manna and Waldinger [1981]. The new program unifies two given
symbolic expressions (s-expressions) relative to a given "environment"
substitution. The proof establishes the existence of an output substitution
that is a most-general idempotent unifier of the given expressions and is an
"extension" of the environment substitution. If no such substitution exists and
the expressions are not unifiable, the program is to produce a failure
indicator.
  Initially the environment substitution is the empty substitution, which makes
no replacements at all; during execution of recursive calls, the environment
substitution records the replacements that have been found so far. Our own
unification algorithm employs an environment, and such algorithms appear in the
literature [e.g., Luger and Stubblefield, 1997]. We suspect, in addition to
being more efficient, the three-argument algorithm with an environment is
easier to synthesize automatically than the two-argument version from the
Manna-Waldinger paper.

</details>


### [315] [Encoding and Reasoning About Arrays in Set Theory](https://arxiv.org/abs/2508.11447)
*Maximiliano Cristiá,Gianfranco Rossi*

Main category: cs.LO

TL;DR: 本论文通过将数组编码为函数和集合，利用集合论方法在 {log} 工具中实现了对数组的统一推理。


<details>
  <summary>Details</summary>
Motivation: 为了在 {log} 工具中无缝集成数组，并允许用户在同一语言和求解器中进行集合、函数和数组的推理。

Method: 通过将数组编码为函数，再将函数编码为有序对集合，并利用集合论片段的判定过程来实现数组推理。

Result: 提供了一个扩展的判定过程，支持数组推理，并已集成到 {log} 工具中。

Conclusion: 本篇论文将数组编码为函数，再将函数编码为有序对集合。由此，数组的长度可以被表示为其对应函数的集合基数。论文还提供了一个集合论片段的判定过程，用于非平凡数组程序的规约，使得数组推理转变为集合推理。该判定过程已集成到 {log} 工具中，支持集合、函数和数组的统一推理。

Abstract: We encode arrays as functions which, in turn, are encoded as sets of ordered
pairs. The set cardinality of each of these functions coincides with the length
of the array it is representing. Then we define a fragment of set theory that
is used to give the specifications of a non-trivial class of programs with
arrays. In this way, array reasoning becomes set reasoning. Furthermore, a
decision procedure for this fragment is also provided and implemented as part
of the {log} (read 'setlog') tool. {log} is a constraint logic programming
language and satisfiability solver where sets and binary relations are
first-class citizens. The tool already implements a few decision procedures for
different fragments of set theory. In this way, arrays are seamlessly
integrated into {log} thus allowing users to reason about sets, functions and
arrays all in the same language and with the same solver. The decision
procedure presented in this paper is an extension of decision procedures
defined in earlier works not supporting arrays.

</details>


### [316] [Interpolation in Classical Propositional Logic](https://arxiv.org/abs/2508.11449)
*Patrick Koopmann,Christoph Wernhard,Frank Wolter*

Main category: cs.LO

TL;DR: This paper introduces Craig interpolation and related concepts in classical propositional logic, offering four computational approaches and exploring connections to circuit complexity.


<details>
  <summary>Details</summary>
Motivation: Introduction of Craig interpolation and related notions like uniform interpolation, Beth definability, and theory decomposition in classical propositional logic.

Method: The paper presents four approaches to computing interpolants: via quantifier elimination, from formulas in disjunctive normal form, and by extraction from resolution or tableau refutations.

Result: The paper discusses the size of interpolants and their links to circuit complexity.

Conclusion: The paper discusses Craig interpolation and related concepts in classical propositional logic, along with four methods for computing interpolants and their connections to circuit complexity.

Abstract: We introduce Craig interpolation and related notions such as uniform
interpolation, Beth definability, and theory decomposition in classical
propositional logic. We present four approaches to computing interpolants: via
quantifier elimination, from formulas in disjunctive normal form, and by
extraction from resolution or tableau refutations. We close with a discussion
of the size of interpolants and links to circuit complexity.

</details>


### [317] [Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations](https://arxiv.org/abs/2508.11515)
*Qipeng Kuang,Václav Kůla,Ondřej Kuželka,Yuanhong Wang,Yuyi Wang*

Main category: cs.LO

TL;DR: 研究了包含多个关系公理的FO^2的WFOMC复杂性，发现了NP_1-hard案例，并提出了一种多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 填补了关于在存在多个关系公理时WFOMC复杂性边界的现有研究空白。

Method: 通过研究扩展二阶逻辑（FO^2）的公理对多个关系的影响来分析WFOMC的复杂性。

Result: 证明了带有两个线性顺序关系和两个无环关系的FO^2的WFOMC是NP_1-hard的，并提出了一种用于带有线性顺序关系、其后继关系和另一个后继关系的多项式时间算法。

Conclusion: 本研究探索了具有两个关系公理的二阶逻辑片段的加权一阶模型计数（WFOMC）的复杂性边界，发现了NP_1-hard和多项式时间算法的负面和正面结果。

Abstract: The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the
weighted sum of models of a given first-order logic sentence over a given
domain. The boundary between fragments for which WFOMC can be computed in
polynomial time relative to the domain size lies between the two-variable
fragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It is
known that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-time
algorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$,
possibly extended by certain axioms such as the linear order axiom, the
acyclicity axiom, and the connectedness axiom. All existing research has
concentrated on extending the fragment with axioms on a single distinguished
relation, leaving a gap in understanding the complexity boundary of axioms on
multiple relations. In this study, we explore the extension of the two-variable
fragment by axioms on two relations, presenting both negative and positive
results. We show that WFOMC for $\text{FO}^2$ with two linear order relations
and $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard.
Conversely, we provide an algorithm in time polynomial in the domain size for
WFOMC of $\text{C}^2$ with a linear order relation, its successor relation and
another successor relation.

</details>


### [318] [Robust Topology and the Hausdorff-Smyth Monad on Metric Spaces over Continuous Quantales](https://arxiv.org/abs/2508.11623)
*Francesco Dagnino,Amin Farjudian Eugenio Moggi*

Main category: cs.LO

TL;DR: 该论文定义了一个包含连续量化值的度量空间范畴，并引入了一个捕捉鲁棒拓扑的 Hausdorff-Smyth 幺半群。


<details>
  <summary>Details</summary>
Motivation: 为了捕捉鲁棒性，即在参数的小扰动下的鲁棒性。

Method: 定义了一个（预序富集）范畴 $\\mathsf{Met}$，其中包含连续量化值的度量空间和一致连续映射。为每个对象 $(X,d,Q)$ 考虑一个拓扑 $\\tau_d$ 和一个称为鲁棒拓扑的 $\\tau_{d,R}$。定义了一个（预序富集）幺半群 $\\mathsf{P}_S$，称为 Hausdorff-Smyth 幺半群，它捕捉了鲁棒拓扑，使得对象 $\\mathsf{P}_S(X,d,Q)$ 的开球拓扑与对象的鲁棒拓扑 $\\tau_{d,R}$ 相吻合。证明了每个拓扑都源于量化值度量。

Result: 证明了每个拓扑都源于量化值度量。

Conclusion: 该框架为定量推理不精确性和鲁棒性提供了基础。

Abstract: We define a (preorder-enriched) category $\mathsf{Met}$ of quantale-valued
metric spaces and uniformly continuous maps, with the essential requirement
that the quantales are continuous. For each object $(X,d,Q)$ in this category,
where $X$ is the carrier set, $Q$ is a continuous quantale, and $d: X \times X
\to Q$ is the metric, we consider a topology $\tau_d$ on $X$, which generalizes
the open ball topology, and a topology $\tau_{d,R}$ on the powerset
$\mathsf{P}(X)$, called the robust topology, which captures robustness with
respect to small perturbations of parameters. We define a (preorder-enriched)
monad $\mathsf{P}_S$ on $\mathsf{Met}$, called the Hausdorff-Smyth monad, which
captures the robust topology, in the sense that the open ball topology of the
object $\mathsf{P}_S(X,d,Q)$ coincides with the robust topology $\tau_{d,R}$
for the object $(X,d,Q)$. We prove that every topology arises from a
quantale-valued metric. As such, our framework provides a foundation for
quantitative reasoning about imprecision and robustness in a wide range of
computational and physical systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [319] [EMLIO: Minimizing I/O Latency and Energy Consumption for Large-Scale AI Training](https://arxiv.org/abs/2508.11035)
*Hasibul Jamil,MD S Q Zulkar Nine,Tevfik Kosar*

Main category: cs.DC

TL;DR: EMLIO通过在存储节点部署轻量级数据服务守护进程，优化数据加载的延迟和能耗，在不同网络环境下均表现出色，是AI云能效感知I/O的可扩展方案。


<details>
  <summary>Details</summary>
Motivation: 大型深度学习工作负载面临I/O瓶颈，而现有系统优化数据加载时间却忽视了I/O的能耗成本。

Method: EMLIO通过在存储节点上部署轻量级数据服务守护进程，对原始样本进行序列化和批处理，通过TCP流式传输并进行乱序预取，并与客户端的GPU加速（NVIDIA DALI）预处理无缝集成，从而跨越不同延迟的网络存储，共同最小化端到端数据加载延迟T和I/O能耗E。

Result: 在本地磁盘、局域网（0.05毫秒和10毫秒RTT）和广域网（30毫秒RTT）环境中，EMLIO的I/O速度最高提升8.6倍，能耗降低10.9倍，同时保持恒定的性能和能耗，不受网络距离影响。

Conclusion: EMLIO的服务化架构为下一代AI云中的能效感知I/O提供了一个可扩展的蓝图。

Abstract: Large-scale deep learning workloads increasingly suffer from I/O bottlenecks
as datasets grow beyond local storage capacities and GPU compute outpaces
network and disk latencies. While recent systems optimize data-loading time,
they overlook the energy cost of I/O - a critical factor at large scale. We
introduce EMLIO, an Efficient Machine Learning I/O service that jointly
minimizes end-to-end data-loading latency T and I/O energy consumption E across
variable-latency networked storage. EMLIO deploys a lightweight data-serving
daemon on storage nodes that serializes and batches raw samples, streams them
over TCP with out-of-order prefetching, and integrates seamlessly with
GPU-accelerated (NVIDIA DALI) preprocessing on the client side. In exhaustive
evaluations over local disk, LAN (0.05 ms & 10 ms RTT), and WAN (30 ms RTT)
environments, EMLIO delivers up to 8.6X faster I/O and 10.9X lower energy use
compared to state-of-the-art loaders, while maintaining constant performance
and energy profiles irrespective of network distance. EMLIO's service-based
architecture offers a scalable blueprint for energy-aware I/O in
next-generation AI clouds.

</details>


### [320] [Element and Everything Tokens: Two-Tier Architecture for Mobilizing Alternative Assets](https://arxiv.org/abs/2508.11266)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.DC

TL;DR: 提出了一种通过元素代币和万物代币进行双层标记化来提高另类资产（如矿山、发电厂或基础设施项目）流动性的架构，从而实现部分和整体所有权，并使这些资产能够像股票或ETF一样进行交易。


<details>
  <summary>Details</summary>
Motivation: 另类资产（例如，矿山、发电厂或基础设施项目）通常是资源、权利和产出的异构束，其价值在传统框架下难以交易或分数化。

Method: 提出了一种新颖的两层标记化架构，以提高此类复杂资产的流动性和透明度。引入了元素代币和万物代币的概念：元素代币代表资产的标准化的、全额抵押的组成部分（例如，产出、权利或信贷），而万物代币代表整个资产作为那些元素的固定组合。该架构能够通过双向可兑换系统实现细粒度的部分所有权和综合的全资产所有权。我们详细介绍了该系统的设计和机制，包括一个保持复合代币价格与其组成部分净资产值一致的套利机制。

Result: 通过在能源和工业领域的示例，我们证明了我们的方法允许之前缺乏流动性的高价值项目像股票或交易所交易基金（ETFs）一样进行分数化和交易。

Conclusion: 该体系结构允许之前缺乏流动性、高价值的项目像股票或交易所交易基金（ETFs）一样进行分数化和交易。我们讨论了对投资者和资产所有者（例如，更低的进入壁垒、改进的价格发现和灵活的融资）的好处，以及对实施和监管的考虑。

Abstract: Alternative assets such as mines, power plants, or infrastructure projects
are often large, heterogeneous bundles of resources, rights, and outputs whose
value is difficult to trade or fractionalize under traditional frameworks. This
paper proposes a novel two-tier tokenization architecture to enhance the
liquidity and transparency of such complex assets. We introduce the concepts of
Element Tokens and Everything Tokens: elemental tokens represent standardized,
fully collateralized components of an asset (e.g., outputs, rights, or
credits), while an everything token represents the entire asset as a fixed
combination of those elements. The architecture enables both fine-grained
partial ownership and integrated whole-asset ownership through a system of
two-way convertibility. We detail the design and mechanics of this system,
including an arbitrage mechanism that keeps the price of the composite token
aligned with the net asset value of its constituents. Through illustrative
examples in the energy and industrial sectors, we demonstrate that our approach
allows previously illiquid, high-value projects to be fractionalized and traded
akin to stocks or exchange-traded funds (ETFs). We discuss the benefits for
investors and asset owners, such as lower entry barriers, improved price
discovery, and flexible financing, as well as the considerations for
implementation and regulation.

</details>


### [321] [Inter-APU Communication on AMD MI300A Systems via Infinity Fabric: a Deep Dive](https://arxiv.org/abs/2508.11298)
*Gabin Schieffer,Jacob Wahlgren,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: This paper evaluates data movement and communication on AMD MI300A APUs for HPC, comparing different programming models and optimizing applications for multi-APU systems.


<details>
  <summary>Details</summary>
Motivation: The growing compute performance of GPUs necessitates efficient data movement in HPC applications. The AMD MI300A APU, which integrates CPU, GPU, and HBM, is a potential solution for alleviating CPU-GPU data movement issues.

Method: The study designs specific benchmarks to evaluate direct memory access from the GPU, explicit inter-APU data movement, and collective multi-APU communication. It compares the efficiency of HIP APIs, MPI routines, and RCCL library. Two HPC applications, Quicksilver and CloverLeaf, are optimized and evaluated on a four MI100A APU system.

Result: The results highlight key design choices for optimizing inter-APU communication on multi-APU AMD MI300A systems with Infinity Fabric. The study evaluates the efficiency of different programming interfaces, allocators, and data movement strategies.

Conclusion: The paper analyzes the efficiency of data movement on AMD MI300A APUs for HPC applications, highlighting design choices for optimizing inter-APU communication and evaluating performance with specific benchmarks and real-world applications.

Abstract: The ever-increasing compute performance of GPU accelerators drives up the
need for efficient data movements within HPC applications to sustain
performance. Proposed as a solution to alleviate CPU-GPU data movement, AMD
MI300A Accelerated Processing Unit (APU) combines CPU, GPU, and high-bandwidth
memory (HBM) within a single physical package. Leadership supercomputers, such
as El Capitan, group four APUs within a single compute node, using Infinity
Fabric Interconnect. In this work, we design specific benchmarks to evaluate
direct memory access from the GPU, explicit inter-APU data movement, and
collective multi-APU communication. We also compare the efficiency of HIP APIs,
MPI routines, and the GPU-specialized RCCL library. Our results highlight key
design choices for optimizing inter-APU communication on multi-APU AMD MI300A
systems with Infinity Fabric, including programming interfaces, allocators, and
data movement. Finally, we optimize two real HPC applications, Quicksilver and
CloverLeaf, and evaluate them on a four MI100A APU system.

</details>


### [322] [Space-efficient population protocols for exact majority in general graphs](https://arxiv.org/abs/2508.11384)
*Joel Rybicki,Jakob Solnerzik,Olivier Stietel,Robin Vacus*

Main category: cs.DC

TL;DR: 本研究改进了人口协议模型中精确多数共识的性能。我们为一般图提供了时间下界，并为依赖图属性（如松弛时间和度失衡）的协议提供了新的时间上界和状态复杂度上界。研究结果在正则扩展器图上达到了接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为了解决总体人口协议模型中的精确多数共识问题。该问题旨在设计一个协议，使得系统能够稳定地输出多数节点的输入值。研究的目的是在一般图上改进现有共识协议的时间和空间复杂度。

Method: 本研究在总体人口协议模型中研究精确多数共识问题。研究方法包括分析在随机调度下相邻节点交互的系统行为。我们提出了新的上界和下界，重点关注图的结构属性，如松弛时间 $\tau_{\mathsf{rel}}$ 和度失衡 $\Delta/\delta$。具体来说，我们设计了一个协议，并分析了其在不同图结构下的稳定时间和状态复杂度。

Result: 我们为总体人口协议模型中的精确多数共识问题提供了改进的上界和下界。具体而言，我们为一般图提供了渐近最优的时间下界。我们还获得了新的上界，这些上界依赖于图的松弛时间 $\tau_{\mathsf{rel}}$ 和度失衡 $\Delta/\delta$。我们提出的协议在期望和高概率下能在 $O\left( \tfrac{\Delta}{\delta} \tau_{\mathsf{rel}} \log^2 n \right)$ 步内稳定。对于具有最小度 $\delta$ 和最大度 $\Delta$ 的图，其状态复杂度为 $O\left( \log n \cdot \left( \log\left(\tfrac{\Delta}{\delta}\right) + \log\left(\tfrac{\tau_{\mathsf{rel}}}{n}\right) \right) \right)$。在正则扩展器图上，我们的结果达到了与完全图上最优空间复杂度相匹配的 $\Theta(\log n)$，并且稳定时间接近最优的 $O(n \log^2 n)$。此外，我们还为常数状态协议提供了一个新的稳定时间上界 $O(\tau_{\mathsf{rel}} \cdot n \log n)$。

Conclusion: 本研究为总体人口协议模型中的精确多数共识问题提供了改进的上下界。研究结果表明，对于一般图，可以实现渐近最优的时间下界。对于具有松弛时间 $	au_{\mathsf{rel}}$ 和度失衡 $\Delta/\delta$ 的图，我们提出了一种协议，其期望稳定时间和高概率稳定时间为 $O\left( \tfrac{\Delta}{\delta} \tau_{\mathsf{rel}} \log^2 n \right)$ 步，同时状态复杂度为 $O\left( \log n \cdot \left( \log\left(\tfrac{\Delta}{\delta}\right) + \log\left(\tfrac{\tau_{\mathsf{rel}}}{n}\right) \right) \right)$。此外，对于具有最小度 $\delta$ 和最大度 $\Delta$ 的图，我们还提供了一个常数状态协议，其稳定时间上界为 $O(\tau_{\mathsf{rel}} \cdot n \log n)$。

Abstract: We study exact majority consensus in the population protocol model. In this
model, the system is described by a graph $G = (V,E)$ with $n$ nodes, and in
each time step, a scheduler samples uniformly at random a pair of adjacent
nodes to interact. In the exact majority consensus task, each node is given a
binary input, and the goal is to design a protocol that almost surely reaches a
stable configuration, where all nodes output the majority input value.
  We give improved upper and lower bounds for the exact majority in general
graphs. First, we give asymptotically tight time lower bounds for general
(unbounded space) protocols. Second, we obtain new upper bounds parameterized
by the relaxation time $\tau_{\mathsf{rel}}$ of the random walk on $G$ induced
by the scheduler and the degree imbalance $\Delta/\delta$ of $G$. Specifically,
we give a protocol that stabilizes in $O\left( \tfrac{\Delta}{\delta}
\tau_{\mathsf{rel}} \log^2 n \right)$ steps in expectation and with high
probability and uses $O\left( \log n \cdot \left(
\log\left(\tfrac{\Delta}{\delta}\right) + \log
\left(\tfrac{\tau_{\mathsf{rel}}}{n}\right) \right) \right)$ states in any
graph with minimum degree at least $\delta$ and maximum degree at most
$\Delta$.
  For regular expander graphs, this matches the optimal space complexity of
$\Theta(\log n)$ for fast protocols in complete graphs [Alistarh et al., SODA
2016 and Doty et al., FOCS 2022] with a nearly optimal stabilization time of
$O(n \log^2 n)$ steps. Finally, we give a new upper bound of
$O(\tau_{\mathsf{rel}} \cdot n \log n)$ for the stabilization time of a
constant-state protocol.

</details>


### [323] [Time, Fences and the Ordering of Events in TSO](https://arxiv.org/abs/2508.11415)
*Raïssa Nataf,Yoram Moses*

Main category: cs.DC

TL;DR: The paper analyzes the TSO memory model, introducing a new 'occurs-before' relation to determine when synchronization (like fences) is needed to ensure correct event ordering, reducing unnecessary performance costs and providing theoretical bounds for shared memory objects.


<details>
  <summary>Details</summary>
Motivation: The Total Store Order (TSO) memory model, widely used in multiprocessor architectures like Intel's x86/x64, allows write buffering for hardware optimizations but complicates correctness reasoning due to potential violations of sequential consistency. Ensuring correctness often requires costly synchronization primitives (memory fences or atomic RMWs). This work is motivated by the need to precisely understand when these synchronization primitives are necessary under TSO to avoid performance costs.

Method: The paper develops a semantic framework and introduces a novel TSO-specific occurs-before relation, adapting Lamport's happens-before relation to the TSO setting. It then proves a theorem stating that an occurs-before chain is necessary to temporally order events at different sites. The analysis studies the role of fences and RMWs in creating these chains to identify unavoidable synchronization costs.

Result: The paper introduces a TSO-specific occurs-before relation and a theorem proving that temporal ordering of events at different sites requires an occurs-before chain. It identifies cases where costly synchronization operations are unavoidable and generalizes prior lower bounds for linearizable implementations of shared memory objects. The analysis captures information flow and causality in TSO by extending reasoning from asynchronous systems.

Conclusion: This work provides a semantic framework and a novel TSO-specific occurs-before relation to precisely characterize when synchronization primitives like memory fences or atomic RMW operations are necessary under the TSO memory model. The main result is a theorem proving that an occurs-before chain is required to temporally order events at different sites. The analysis captures the necessity of synchronization operations, generalizes prior lower bounds for linearizable shared memory objects, and extends communication-based reasoning to the TSO model, offering a sound theoretical understanding of TSO's essential aspects and information flow.

Abstract: The Total Store Order (TSO) is arguably the most widely used relaxed memory
model in multiprocessor architectures, widely implemented, for example in
Intel's x86 and x64 platforms. It allows processes to delay the visibility of
writes through store buffering. While this supports hardware-level
optimizations and makes a significant contribution to multiprocessor
efficiency, it complicates reasoning about correctness, as executions may
violate sequential consistency. Ensuring correct behavior often requires
inserting synchronization primitives such as memory fences ($F$) or atomic
read-modify-write ($RMW$) operations, but this approach can incur significant
performance costs. In this work, we develop a semantic framework that precisely
characterizes when such synchronization is necessary under TSO. We introduce a
novel TSO-specific occurs-before relation, which adapts Lamport's celebrated
happens-before relation from asynchronous message-passing systems to the TSO
setting. Our main result is a theorem that proves that the only way to ensure
that two events that take place at different sites are temporally ordered is by
having the execution create an occurs-before chain between the events. By
studying the role of fences and $RMW$s in creating occurs-before chains, we are
then able to capture cases in which these costly synchronization operations are
unavoidable. Since proper real-time ordering of events is a fundamental aspect
of consistency conditions such as Linearizability, our analysis provides a
sound theoretical understanding of essential aspects of the TSO model. In
particular, we are able to generalize prior lower bounds for linearizable
implementations of shared memory objects. Our results capture the structure of
information flow and causality in the TSO model by extending the standard
communication-based reasoning from asynchronous systems to the TSO memory
model.

</details>


### [324] [Efficient GPU-Centered Singular Value Decomposition Using the Divide-and-Conquer Method](https://arxiv.org/abs/2508.11467)
*Shifang Liu,Huiyuan Li,Hongjiao Sheng,Haoyuan Gui,Xiaoyu Zhang*

Main category: cs.DC

TL;DR: 一种新的GPU中心SVD算法，通过优化的GPU计算和减少数据传输，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统SVD方法在异构系统中的面板分解和CPU-GPU数据传输存在效率瓶颈，尽管GPU计算能力有所提升，但仍需改进。

Method: 提出了一种新的GPU中心SVD算法，包括基于GPU的双对角分治（BDC）方法，重新设计了算法和数据布局，将所有面板级计算和尾部矩阵更新完全在GPU上执行，并整合了相关计算以优化BLAS利用率和算术强度。

Result: 在AMD MI210和NVIDIA V100 GPU上的实验结果显示，与rocSOLVER/cuSOLVER和MAGMA相比，该方法分别实现了高达1293.64倍/7.47倍和14.10倍/12.38倍的加速。

Conclusion: 该研究提出了一种以GPU为中心的SVD算法，通过新颖的基于GPU的双对角分治（BDC）方法，消除了CPU-GPU之间的数据传输，并优化了BLAS利用率，实现了显著的加速。

Abstract: Singular Value Decomposition (SVD) is a fundamental matrix factorization
technique in linear algebra, widely applied in numerous matrix-related
problems. However, traditional SVD approaches are hindered by slow panel
factorization and frequent CPU-GPU data transfers in heterogeneous systems,
despite advancements in GPU computational capabilities. In this paper, we
introduce a GPU-centered SVD algorithm, incorporating a novel GPU-based
bidiagonal divide-and-conquer (BDC) method. We reformulate the algorithm and
data layout of different steps for SVD computation, performing all panel-level
computations and trailing matrix updates entirely on GPU to eliminate CPU-GPU
data transfers. Furthermore, we integrate related computations to optimize BLAS
utilization, thereby increasing arithmetic intensity and fully leveraging the
computational capabilities of GPUs. Additionally, we introduce a newly
developed GPU-based BDC algorithm that restructures the workflow to eliminate
matrix-level CPU-GPU data transfers and enable asynchronous execution between
the CPU and GPU. Experimental results on AMD MI210 and NVIDIA V100 GPUs
demonstrate that our proposed method achieves speedups of up to 1293.64x/7.47x
and 14.10x/12.38x compared to rocSOLVER/cuSOLVER and MAGMA, respectively.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [325] [OpenCXD: An Open Real-Device-Guided Hybrid Evaluation Framework for CXL-SSDs](https://arxiv.org/abs/2508.11477)
*Hyunsun Chung,Junhyeok Park,Taewan Noh,Seonghoon Ahn,Kihwan Kim,Ming Zhao,Youngjae Kim*

Main category: cs.AR

TL;DR: OpenCXD is a new evaluation framework that combines simulation with a real SSD to accurately model CXL-SSD performance, addressing limitations of previous simulation-only approaches and providing insights for future SSD firmware design.


<details>
  <summary>Details</summary>
Motivation: Evaluating the performance of CXL-SSDs is difficult due to the lack of hardware that natively supports the CXL.mem protocol on SSDs, and prior work relying on hybrid simulators that cannot faithfully model firmware-level interactions and low-level storage dynamics.

Method: OpenCXD is a real-device-guided hybrid evaluation framework that integrates a cycle-accurate CXL.mem simulator on the host side with a physical OpenSSD platform running real firmware.

Result: OpenCXD bridges the gap between simulation and hardware, enabling a more faithful modeling of CXL-SSD performance by integrating a CXL.mem simulator with a physical OpenSSD platform.

Conclusion: OpenCXD enables in-situ firmware execution triggered by simulated memory requests, reflecting device-level phenomena unobservable in simulation-only setups and providing critical insights for future firmware design tailored to CXL-SSDs.

Abstract: The advent of Compute Express Link (CXL) enables SSDs to participate in the
memory hierarchy as large-capacity, byte-addressable memory devices. These
CXL-enabled SSDs (CXL-SSDs) offer a promising new tier between DRAM and
traditional storage, combining NAND flash density with memory-like access
semantics. However, evaluating the performance of CXL-SSDs remains difficult
due to the lack of hardware that natively supports the CXL.mem protocol on
SSDs. As a result, most prior work relies on hybrid simulators combining CPU
models augmented with CXL.mem semantics and SSD simulators that approximate
internal flash behaviors. While effective for early-stage exploration, this
approach cannot faithfully model firmware-level interactions and low-level
storage dynamics critical to CXL-SSD performance. In this paper, we present
OpenCXD, a real-device-guided hybrid evaluation framework that bridges the gap
between simulation and hardware. OpenCXD integrates a cycle-accurate CXL.mem
simulator on the host side with a physical OpenSSD platform running real
firmware. This enables in-situ firmware execution triggered by simulated memory
requests. Through these contributions, OpenCXD reflects device-level phenomena
unobservable in simulation-only setups, providing critical insights for future
firmware design tailored to CXL-SSDs.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [326] [Can We Tell if ChatGPT is a Parasite? Studying Human-AI Symbiosis with Game Theory](https://arxiv.org/abs/2508.11359)
*Jiejun Hu-Bolz,James Stovold*

Main category: cs.GT

TL;DR: 人类与生成式AI通过信息交互可融合成单一实体。


<details>
  <summary>Details</summary>
Motivation: 探讨了人类与生成式AI系统互动是否能通过信息驱动的交互融合成单一个体，并研究了LLM聊天机器人是否会寄生于人类信息的问题。

Method: 利用信息论（熵、互信息和传递熵）将人、生成式AI系统和人类更广泛的环境建模为一个三方随机博弈。

Result: 通过信息论的测量，模型证明了人类和生成式AI能够形成一个聚合的个体，这与Krakauer等人（2020）的定义一致。

Conclusion: 研究表明，通过迭代式、信息驱动的交互，与生成式AI系统互动的人类可以融合成一个单一的个体。该模型能够回答关于人机共生关系的问题，例如LLM驱动的聊天机器人是否以人类提供的信息为食。

Abstract: This work asks whether a human interacting with a generative AI system can
merge into a single individual through iterative, information-driven
interactions. We model the interactions between a human, a generative AI
system, and the human's wider environment as a three-player stochastic game. We
use information-theoretic measures (entropy, mutual information, and transfer
entropy) to show that our modelled human and generative AI are able to form an
aggregate individual in the sense of Krakauer et al. (2020). The model we
present is able to answer interesting questions around the symbiotic nature of
humans and AI systems, including whether LLM-driven chatbots are acting as
parasites, feeding on the information provided by humans.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [327] [A Gentle Wakeup Call: Symmetry Breaking with Less Collision Cost](https://arxiv.org/abs/2508.11006)
*Umesh Biswas,Maxwell Young*

Main category: cs.DS

TL;DR: 本研究提出了一种名为 Aim-High 的新算法，以解决通信信道中因碰撞导致的延迟问题。该算法在不同参数下提供了优于先前方法的延迟和碰撞成本。


<details>
  <summary>Details</summary>
Motivation: 现有唤醒算法的延迟分析主要关注首次成功发送所需的时间，而忽略了碰撞带来的显著延迟，导致总延迟较大，易受碰撞成本影响。本研究旨在解决此问题。

Method: 设计并分析了一种名为 Aim-High 的随机化唤醒算法。

Result: 对于足够大的 C 和有界错误，Aim-High 算法在静态和动态唤醒问题上的延迟和期望碰撞成本接近 O(sqrt(C))。在其他情况下，静态设置的延迟和期望碰撞成本为 O(poly(log n))，动态设置的延迟和期望碰撞成本为 O(n poly(log n))。

Conclusion: Aim-High 算法在静态和动态唤醒问题上均取得了近乎 O(sqrt(C)) 的延迟和期望碰撞成本（对于足够大的 C 和有界错误），或者在其他情况下，静态设置的延迟和期望碰撞成本为 O(poly(log n))，动态设置的延迟和期望碰撞成本为 O(n poly(log n))。此外，还建立了相应的下界。

Abstract: The wakeup problem addresses the fundamental challenge of symmetry breaking.
There are $n$ devices sharing a time-slotted multiple access channel. In any
fixed slot, if a single device sends a packet, it succeeds; however, if two or
more devices send, then there is a collision and none of the corresponding
packets succeed. For the static version of wakeup, all packets are initially
active (i.e., can send and listen on the channel); for the dynamic version, the
packets become active at arbitrary times. In both versions, the goal is to
successfully send a single packet.
  Prior results on wakeup have largely focused on the number of slots until the
first success; that is, the latency. However, in many modern systems,
collisions introduce significant delay, an aspect that current wakeup
algorithms do not address. For instance, while existing results for static
wakeup have polylogarithmic-in-$n$ latency, they can incur additional latency
that is {\it linear} in the cost of a collision $C$. Thus, the total latency is
large and dominated by the contributions from collisions.
  Here, we design and analyze a randomized wakeup algorithm, Aim-High. For
sufficiently large $C$ and with bounded error, Aim-High has latency and
expected collision cost that is nearly $O(\sqrt{C})$ for both the static and
dynamic versions. Otherwise, the latency and expected collision cost are
$O(\texttt{poly}{(\log n)})$ for the static setting, and
$O(n\,\texttt{poly}{(\log n)})$ for the dynamic setting. We also establish
lower bounds that complement these results.

</details>


### [328] [Sampling tree-weighted partitions without sampling trees](https://arxiv.org/abs/2508.11130)
*Sarah Cannon,Wesley Pegden,Jamie Tucker-Foltz*

Main category: cs.DS

TL;DR: 本论文提出了一种新的算法，可以直接从平衡树加权二分图中采样，解决了现有方法在处理计算重新划分分析中的平面图时遇到的计算瓶颈。该算法在预期运行时间上比现有方法更快，并且在精确采样均匀随机树方面也有改进。


<details>
  <summary>Details</summary>
Motivation: 计算重新划分分析中的问题，特别是对平衡树加权k-分区（所有分区类具有相同大小）的条件分布的研究。现有的方法在采样平衡树加权2-分区时存在计算瓶颈，即需要先采样生成树，然后检查其是否包含可移除以产生平衡2-分量森林的边，这导致算法需要不断拒绝和重复。

Method: 提出了一种直接从平衡树加权二分图中采样的算法，该算法不依赖于先采样生成树，而是直接生成样本。

Result: 提出的新算法可以直接从平衡树加权二分图中采样，并证明了该算法在处理广泛的平面图（包括计算重新划分分析中常见的网络结构）时，预期运行时间为线性时间 O(n)。这比现有方法更快。同时，该算法的变体在精确采样均匀随机树方面也能达到 O(n log n) 的时间复杂度。

Conclusion: 该研究提出了一种直接从平衡树加权二分图中采样的算法，避免了先采样生成树再进行检查的计算瓶颈。该算法在处理计算重新划分分析中常见的平面图时，预期运行时间为线性时间 O(n)，这比现有生成随机树的方法（近似采样为 O(n log^2 n)，精确采样为 O(n^{1 + log log log n / log log n})）更快。此外，该算法的变体还能以 O(n log n) 的时间进行精确采样，改进了精确和近似采样的边界。

Abstract: This paper gives a new algorithm for sampling tree-weighted partitions of a
large class of planar graphs. Formally, the tree-weighted distribution on
$k$-partitions of a graph weights $k$-partitions proportional to the product of
the number of spanning trees of each partition class. Recent work on problems
in computational redistricting analysis has driven special interest in the
conditional distribution where all partition classes have the same size
(balanced partitions). One class of Markov chains in wide use aims to sample
from balanced tree-weighted $k$-partitions using a sampler for balanced
tree-weighted 2-partitions. Previous implementations of this 2-partition
sampler would draw a random spanning tree and check whether it contains an edge
whose removal produces a balanced 2-component forest; if it does, this
2-partition is accepted, otherwise the algorithm rejects and repeats. In
practice, this is a significant computational bottleneck.
  We show that in fact it is possible to sample from the balanced tree-weighted
2-partition distribution directly, without first sampling a spanning tree; the
acceptance and rejection rates are the same as in previous samplers. We prove
that on a wide class of planar graphs encompassing network structures typically
arising from the geographic data used in computational redistricting, our
algorithm takes expected linear time $O(n)$. Notably, this is asymptotically
faster than the best known method to generate random trees, which is $O(n
\log^2 n)$ for approximate sampling and $O(n^{1 + \log \log \log n / \log \log
n})$ for exact sampling. Additionally, we show that a variant of our algorithm
also gives a speedup to $O(n \log n)$ for exact sampling of uniformly random
trees on these families of graphs, improving the bounds for both exact and
approximate sampling.

</details>


### [329] [Face-hitting dominating sets in planar graphs: Alternative proof and linear-time algorithm](https://arxiv.org/abs/2508.11444)
*Therese Biedl*

Main category: cs.DS

TL;DR: 本文提供了一个新的、具有建设性的证明，证明了平面图的顶点可以被划分为两个支配集和面导出集，该算法的时间复杂度为O(n)。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提供一个生成性证明，证明平面图的顶点可以被划分为两个支配集和面导出集，并且该证明方法具有线性时间复杂度。

Method: 本文利用图的2-连通分量分解，结合欧尔分解和3-正则平面图的完美匹配，来构造一个顶点划分。

Result: 本文给出了一个关于平面图顶点划分的新的、建设性的证明，证明了该划分可以生成，并且只需要O(n)时间。

Conclusion: 该论文提出了一个比之前方法更优的证明，该证明是建设性的，并且时间复杂度为O(n)。

Abstract: In a recent paper, Francis, Illickan, Jose and Rajendraprasad showed that
every $n$-vertex plane graph $G$ has (under some natural restrictions) a
vertex-partition into two sets $V_1$ and $V_2$ such that each $V_i$ is
\emph{dominating} (every vertex of $G$ contains a vertex of $V_i$ in its closed
neighbourhood) and \emph{face-hitting} (every face of $G$ is incident to a
vertex of $V_i$). Their proof works by considering a supergraph $G'$ of $G$
that has certain properties, and among all such graphs, taking one that has the
fewest edges. As such, their proof is not algorithmic. Their proof also relies
on the 4-color theorem, for which a quadratic-time algorithm exists, but it
would not be easy to implement.
  In this paper, we give a new proof that every $n$-vertex plane graph $G$ has
(under the same restrictions) a vertex-partition into two dominating
face-hitting sets. Our proof is constructive, and requires nothing more
complicated than splitting a graph into 2-connected components, finding an ear
decomposition, and computing a perfect matching in a 3-regular plane graph. For
all these problems, linear-time algorithms are known and so we can find the
vertex-partition in linear time.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [330] [Allen: Rethinking MAS Design through Step-Level Policy Autonomy](https://arxiv.org/abs/2508.11294)
*Qiangong Zhou,Zhiting Wang,Mingyou Yao,Zongyang Liu*

Main category: cs.MA

TL;DR: Allen是一个新的多代理系统（MAS），它通过允许代理自主地形成不同的模式来提高策略自主性，并在复杂的网络拓扑中平衡协作效率、任务监督和人工监督。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当前MAS设计的两大核心挑战：提高系统的策略自主性，使代理能够动态适应其行为策略；以及在复杂的网络拓扑中实现协作效率、任务监督和人工监督之间的权衡。

Method: 通过重新定义MAS的基本执行单元，使代理能够自主地组合这些单元以形成不同的模式。构建了一个四层状态架构（任务、阶段、代理、步骤）来从面向任务和面向执行的角度约束系统行为。

Result: Allen系统在提高策略自主性的同时，实现了对协作结构的可控性权衡。

Conclusion: Allen系统实现了前所未有的策略自主性，并对协作结构的可控性进行了权衡。

Abstract: We introduce a new Multi-Agent System (MAS) - Allen, designed to address two
core challenges in current MAS design: (1) improve system's policy autonomy,
empowering agents to dynamically adapt their behavioral strategies, and (2)
achieving the trade-off between collaborative efficiency, task supervision, and
human oversight in complex network topologies.
  Our core insight is to redefine the basic execution unit in the MAS, allowing
agents to autonomously form different patterns by combining these units. We
have constructed a four-tier state architecture (Task, Stage, Agent, Step) to
constrain system behavior from both task-oriented and execution-oriented
perspectives. This achieves a unification of topological optimization and
controllable progress.
  Allen grants unprecedented Policy Autonomy, while making a trade-off for the
controllability of the collaborative structure. The project code has been open
source at: https://github.com/motern88/Allen

</details>


### [331] [Defending a City from Multi-Drone Attacks: A Sequential Stackelberg Security Games Approach](https://arxiv.org/abs/2508.11380)
*Dolev Mutzari,Tonmoay Deb,Cristian Molinaro,Andrea Pugliese,V. S. Subrahmanian,Sarit Kraus*

Main category: cs.MA

TL;DR: 本文提出了一种名为S2D2的算法，用于在序列Stackelberg安全博弈中制定城市防御无人机攻击的策略，并在真实城市数据上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了应对迫在眉睫的城市多无人机攻击威胁，需要在城市中部署防御无人机以拦截或消灭攻击无人机，从而最大限度地减少潜在的损害。

Method: 本文将无人机防御建模为一个序列Stackelberg安全博弈（Sequential Stackelberg Security Game），防御方首先制定一个混合防御策略，然后攻击方进行最优响应。为此，开发了一种名为S2D2的高效算法来生成防御策略。

Result: 在对80个真实城市的广泛实验中，S2D2算法显著提高了防御方的性能，优于基于先前工作的贪心启发式方法。

Conclusion: S2D2算法能够为城市防御无人机攻击提供一种有效的防御策略，并且在真实城市数据集上进行了广泛的实验验证，相比于现有的贪心启发式方法，其性能有所提升。此外，在合理的城市结构假设下，S2D2能够输出具有良好结构特性的近似强Stackelberg均衡（SSE）。

Abstract: To counter an imminent multi-drone attack on a city, defenders have deployed
drones across the city. These drones must intercept/eliminate the threat, thus
reducing potential damage from the attack. We model this as a Sequential
Stackelberg Security Game, where the defender first commits to a mixed
sequential defense strategy, and the attacker then best responds. We develop an
efficient algorithm called S2D2, which outputs a defense strategy. We
demonstrate the efficacy of S2D2 in extensive experiments on data from 80 real
cities, improving the performance of the defender in comparison to greedy
heuristics based on prior works. We prove that under some reasonable
assumptions about the city structure, S2D2 outputs an approximate Strong
Stackelberg Equilibrium (SSE) with a convenient structure.

</details>


### [332] [Tapas are free! Training-Free Adaptation of Programmatic Agents via LLM-Guided Program Synthesis in Dynamic Environments](https://arxiv.org/abs/2508.11425)
*Jinwei Hu,Yi Dong,Youcheng Sun,Xiaowei Huang*

Main category: cs.MA

TL;DR: TAPA是一个新颖的框架，它利用LLM作为符号动作空间的智能主持人，通过合成和适应逻辑原语的模块化程序，实现了训练无关的适应性，从而提高了安全关键应用的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 安全关键应用的自主代理需要在不影响性能和可靠性的前提下，持续适应动态条件。

Method: TAPA框架通过将LLM定位为符号动作空间的智能主持人，合成和适应逻辑原语的模块化程序，从而将战略意图与执行分离。

Result: 在网络安全和群体智能领域进行了广泛的实验。在自主DDoS防御场景中，TAPA实现了77.7%的网络正常运行时间，并保持了近乎完美的未知动态环境检测准确率。在环境和对抗性干扰下的群体智能编队控制中，TAPA在基线方法完全失效的情况下，在运行时持续保持了一致性。

Conclusion: TAPA通过将LLM作为符号动作空间的智能主持人，实现了训练无关的适应性，从而在动态环境中提高了安全关键应用的性能和可靠性。

Abstract: Autonomous agents in safety-critical applications must continuously adapt to
dynamic conditions without compromising performance and reliability. This work
introduces TAPA (Training-free Adaptation of Programmatic Agents), a novel
framework that positions large language models (LLMs) as intelligent moderators
of the symbolic action space. Unlike prior programmatic agents that typically
generate a monolithic policy program or rely on fixed symbolic action sets,
TAPA synthesizes and adapts modular programs for individual high-level actions,
referred to as logical primitives. By decoupling strategic intent from
execution, TAPA enables meta-agents to operate over an abstract, interpretable
action space while the LLM dynamically generates, composes, and refines
symbolic programs tailored to each primitive. Extensive experiments across
cybersecurity and swarm intelligence domains validate TAPA's effectiveness. In
autonomous DDoS defense scenarios, TAPA achieves 77.7% network uptime while
maintaining near-perfect detection accuracy in unknown dynamic environments. In
swarm intelligence formation control under environmental and adversarial
disturbances, TAPA consistently preserves consensus at runtime where baseline
methods fail completely. This work promotes a paradigm shift for autonomous
system design in evolving environments, from policy adaptation to dynamic
action adaptation.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [333] [Thermal acoustic particle velocity sensor with structured microwires](https://arxiv.org/abs/2508.11157)
*Ruby Jindal,Sushil Kumar Singh,Ravibabu Mulaveesala,Jolly Xavier*

Main category: physics.app-ph

TL;DR: 通过优化MEMS热声粒子速度传感器的结构，可以提高其低频灵敏度。


<details>
  <summary>Details</summary>
Motivation: 为了在通信、医学成像和工业过程等领域实现精确的声场估计，声粒子速度传感器对于提供声场方向信息至关重要。

Method: 采用三维数值有限元分析方法，对基于MEMS的结构化热粒子速度传感器进行建模和仿真，并与传统的直丝结构进行对比。

Result: 研究表明，通过对MEMS器件进行不同的形态结构优化，可以实现比传统直丝结构更大的温度偏差，从而提高传感器的灵敏度，特别是在低频应用中。

Conclusion: 该研究展示了一种基于MEMS结构优化设计的热声粒子速度传感器的三维有限元分析，旨在提高其在低频应用中的灵敏度。

Abstract: Estimating the spatial distribution of the acoustic field is essential in
communication, medical imaging and other varied industrial processes. Acoustic
particle velocity sensor plays a key role in providing directional information
of the sound field. We present a rigorous 3D numerical finite element analysis
of MEMS based structurally modified thermal particle velocity sensor. The
impact of diverse morphological structural optimization in comparison to the
conventional straight wire structure is rigorously studied and analyzed in
order to achieve maximum temperature deviation and, thereby, the sensitivity of
the device primarily for low frequency applications.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [334] [SO-PIFRNN: Self-optimization physics-informed Fourier-features randomized neural network for solving partial differential equations](https://arxiv.org/abs/2508.10921)
*Jiale Linghu,Weifeng Gao,Hao Dong,Yufeng Nie*

Main category: cs.NE

TL;DR: 本研究提出SO-PIFRNN框架，通过引入傅立叶激活、新的导数神经网络和MSC-PSO算法，显著提高了偏微分方程的求解精度和频率捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高偏微分方程（PDE）数值求解的精度，通过超参数优化机制来提升求解精度。

Method: 提出了一种自优化的物理信息傅立叶特征随机神经网络（SO-PIFRNN）框架，该框架采用双层优化架构：外层优化利用多策略协作粒子群优化（MSC-PSO）算法搜索物理信息傅立叶特征随机神经网络的超参数，内层优化通过最小二乘法确定神经网络的输出层权重。

Result: SO-PIFRNN框架在求解多尺度方程、高阶方程、高维方程和非线性方程等方面的数值实验结果表明，SO-PIFRNN具有优越的逼近精度和频率捕捉能力。

Conclusion: SO-PIFRNN框架通过引入傅立叶基函数激活机制、新的导数神经网络方法和混合优化的MSC-PSO算法，在求解偏微分方程方面表现出优越的逼近精度和频率捕捉能力，并通过多尺度、高阶、高维和非线性方程的数值实验得到验证。

Abstract: This study proposes a self-optimization physics-informed Fourier-features
randomized neural network (SO-PIFRNN) framework, which significantly improves
the numerical solving accuracy of PDEs through hyperparameter optimization
mechanism. The framework employs a bi-level optimization architecture: the
outer-level optimization utilizes a multi-strategy collaborated particle swarm
optimization (MSC-PSO) algorithm to search for optimal hyperparameters of
physics-informed Fourier-features randomized neural network, while the
inner-level optimization determines the output layer weights of the neural
network via the least squares method. The core innovation of this study is
embodied in the following three aspects: First, the Fourier basis function
activation mechanism is introduced in the hidden layer of neural network, which
significantly enhances the ability of the network to capture multi-frequency
components of the solution. Secondly, a novel derivative neural network method
is proposed, which improves the calculation accuracy and efficiency of PIFRNN
method. Finally, the MSC-PSO algorithm of the hybrid optimization strategy is
designed to improve the global search ability and convergence accuracy through
the synergistic effect of dynamic parameter adjustment, elitist and mutation
strategies. Through a series of numerical experiments, including multiscale
equations in complex regions, high-order equations, high-dimensional equations
and nonlinear equations, the validity of SO-PIFRNN is verified. The
experimental results affirm that SO-PIFRNN exhibits superior approximation
accuracy and frequency capture capability.

</details>


### [335] [SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization](https://arxiv.org/abs/2508.10913)
*Changqing Xu,Buxuan Song,Yi Liu,Xinfang Liao,Wenbin Zheng,Yintang Yang*

Main category: cs.NE

TL;DR: 通过优化脉冲生成、引入自剔除神经元机制和贝叶斯优化，提出了一种单时间步SNN，在保持准确率的同时大幅降低了能耗。


<details>
  <summary>Details</summary>
Motivation: SNNs因其事件驱动的信息处理机制在能效方面具有显著优势，但其多时间步计算模型增加了推理延迟和能耗，限制了其在边缘计算场景的应用。

Method: 提出了一种单时间步SNN，通过优化脉冲生成和时间参数来提高单时间步的准确率和降低计算能耗。设计了自剔除神经元机制，通过动态阈值调整和选择性脉冲抑制来增强信息承载能力。采用贝叶斯优化全局搜索时间参数，实现了单时间步的高效推理模式。

Result: 与传统的采用LIF模型的多时间步SNNs相比，该单时间步SNN在保持可比或更优的准确率的同时，显著降低了能耗。

Conclusion: 该方法在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上实现了93.72%、92.20%和69.45%的分类准确率，同时保持了可比甚至更优的准确率，并分别降低了56%、21%和22%的能耗。

Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired
computational model, demonstrate significant energy efficiency advantages due
to their event-driven information processing mechanism. Compared to traditional
Artificial Neural Networks (ANNs), SNNs transmit information through discrete
spike signals, which substantially reduces computational energy consumption
through their sparse encoding approach. However, the multi-timestep computation
model significantly increases inference latency and energy, limiting the
applicability of SNNs in edge computing scenarios. We propose a single-timestep
SNN, which enhances accuracy and reduces computational energy consumption in a
single timestep by optimizing spike generation and temporal parameters. We
design a Self-Dropping Neuron mechanism, which enhances information-carrying
capacity through dynamic threshold adjustment and selective spike suppression.
Furthermore, we employ Bayesian optimization to globally search for time
parameters and obtain an efficient inference mode with a single time step.
Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets
demonstrate that, compared to traditional multi-timestep SNNs employing the
Leaky Integrate-and-Fire (LIF) model, our method achieves classification
accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only
single-timestep spikes, while maintaining comparable or even superior accuracy.
Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.

</details>


### [336] [Insect-Wing Structured Microfluidic System for Reservoir Computing](https://arxiv.org/abs/2508.10915)
*Jacob Clouse,Thomas Ramsey,Samitha Somathilaka,Nicholas Kleinsasser,Sangjin Ryu,Sasitharan Balasubramaniam*

Main category: cs.NE

TL;DR: 受蜻蜓启发的微流控芯片可用作低功耗、高弹性的计算系统，在有限数据下准确率高达 91%。


<details>
  <summary>Details</summary>
Motivation: 随着对更高效、更适应性强的计算需求的增长，受自然启发的计算架构为传统电子设计提供了有前景的替代方案。微流控平台利用生物形态和流体动力学，为电子设备不适用的环境中的低功耗、高弹性计算奠定了基础。

Method: 研究使用基于蜻蜓翅膀启发的微流控芯片的混合储层计算系统，通过微通道内的流体相互作用对时间输入模式进行编码。该系统包含三个染料输入通道和三个摄像头监控的检测区域，将离散的空间模式转换为动态的颜色输出信号。这些输出信号经过修改后传递给一个可训练的读取层进行模式分类。

Result: 研究评估了使用原始储层输出和合成生成输出的系统性能、系统清晰度和数据效率，结果表明在粗分辨率和有限训练数据的情况下，分类准确率最高可达 91%。

Conclusion: 微流控系统在粗分辨率和有限训练数据下实现了高达 91% 的分类准确率，证明了其作为一种可行计算范例的潜力。

Abstract: As the demand for more efficient and adaptive computing grows,
nature-inspired architectures offer promising alternatives to conventional
electronic designs. Microfluidic platforms, drawing on biological forms and
fluid dynamics, present a compelling foundation for low-power, high-resilience
computing in environments where electronics are unsuitable. This study explores
a hybrid reservoir computing system based on a dragonfly-wing inspired
microfluidic chip, which encodes temporal input patterns as fluid interactions
within the micro channel network.
  The system operates with three dye-based inlet channels and three
camera-monitored detection areas, transforming discrete spatial patterns into
dynamic color output signals. These reservoir output signals are then modified
and passed to a simple and trainable readout layer for pattern classification.
Using a combination of raw reservoir outputs and synthetically generated
outputs, we evaluated system performance, system clarity, and data efficiency.
The results demonstrate consistent classification accuracies up to $91\%$, even
with coarse resolution and limited training data, highlighting the viability of
the microfluidic reservoir computing.

</details>


### [337] [Use of a genetic algorithm to find solutions to introductory physics problems](https://arxiv.org/abs/2508.10920)
*Tom Bensky,Justin Kopcinski*

Main category: cs.NE

TL;DR: 遗传算法可用于解决物理问题，通过优化方程序列来找到答案。


<details>
  <summary>Details</summary>
Motivation: 展示了遗传算法（GA）如何用于寻找入门物理问题的逐步解决方案，核心思想是找到能导出所需答案的方程序列。

Method: 使用遗传算法（GA）通过最小化衡量方程组中未知数与已知数之差的适应度函数来寻找合适的方程序列。遗传算法通过询问学生问题来获取已知数信息，这些问题源于驱动遗传算法的染色体枚举。

Result: 遗传算法通过最小化适应度函数来寻找方程序列，其中适应度函数衡量未知数与已知数之差，以找到解决一维运动学入门物理问题的有效方法。

Conclusion: 该技术可以指导学生解决一维运动学的任何入门物理问题。

Abstract: In this work, we show how a genetic algorithm (GA) can be used to find
step-by-step solutions to introductory physics problems. Our perspective is
that the underlying task for this is one of finding a sequence of equations
that will lead to the needed answer. Here a GA is used to find an appropriate
equation sequence by minimizing a fitness function that measures the difference
between the number of unknowns versus knowns in a set of equations. Information
about knowns comes from the GA posing questions to the student about what
quantities exist in the text of their problem. The questions are generated from
enumerations pulled from the chromosomes that drive the GA. Equations with
smaller known vs. unknown differences are considered more fit and are used to
produce intermediate results that feed less fit equations. We show that this
technique can guide a student to an answer to any introductory physics problem
involving one-dimensional kinematics. Interpretability findings are discussed.

</details>


### [338] [Allee Synaptic Plasticity and Memory](https://arxiv.org/abs/2508.10929)
*Eddy Kwessi*

Main category: cs.NE

TL;DR: Allee模型在记忆任务中比Hebbian和Oja模型更好，并且通过添加时间动态可以更好地处理动态环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模型在噪声敏感性和突触权重无界增长方面的不足，本研究提出并研究了Allee基础的非线性可塑性模型，旨在提高噪声鲁棒性和突触权重稳定性。

Method: 本研究将Allee基础的非线性可塑性模型与时间依赖性动力学（包括合格性痕迹和振荡输入）相结合，分析了其在记忆保持和模式检索中的性能。

Result: 与Hebbian和Oja等经典模型相比，Allee基础的非线性可塑性模型在记忆保持和模式检索方面表现出更高的容量和可靠性，并且在集成时间依赖性动力学后，在动态环境中具有更高的检索准确性和鲁棒性。

Conclusion: 该研究提出了Allee基础的非线性可塑性模型，并结合了时间依赖性动力学，在记忆保持和模式检索方面表现优于经典模型，提高了容量和可靠性，并增强了在动态环境中的鲁棒性。

Abstract: Neural plasticity is fundamental to memory storage and retrieval in
biological systems, yet existing models often fall short in addressing noise
sensitivity and unbounded synaptic weight growth. This paper investigates the
Allee-based nonlinear plasticity model, emphasizing its biologically inspired
weight stabilization mechanisms, enhanced noise robustness, and critical
thresholds for synaptic regulation. We analyze its performance in memory
retention and pattern retrieval, demonstrating increased capacity and
reliability compared to classical models like Hebbian and Oja's rules. To
address temporal limitations, we extend the model by integrating time-dependent
dynamics, including eligibility traces and oscillatory inputs, resulting in
improved retrieval accuracy and resilience in dynamic environments. This work
bridges theoretical insights with practical implications, offering a robust
framework for modeling neural adaptation and informing advances in artificial
intelligence and neuroscience.

</details>
