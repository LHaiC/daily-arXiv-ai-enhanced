<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 85]
- [cs.CL](#cs.CL) [Total: 64]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.RO](#cs.RO) [Total: 28]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 14]
- [cs.AR](#cs.AR) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [cs.LG](#cs.LG) [Total: 102]
- [cs.DC](#cs.DC) [Total: 7]
- [eess.SY](#eess.SY) [Total: 21]
- [quant-ph](#quant-ph) [Total: 47]
- [cs.DS](#cs.DS) [Total: 11]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.SP](#eess.SP) [Total: 21]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 38]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Fourier-Based GAN Fingerprint Detection using ResNet50](https://arxiv.org/abs/2510.19840)
*Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru*

Main category: cs.CV

TL;DR: 利用频域分析和深度学习区分StyleGAN生成的图像和真实图像。


<details>
  <summary>Details</summary>
Motivation: GAN生成的逼真图像给图像取证和内容真实性验证带来挑战。

Method: 将图像进行二维离散傅里叶变换（2D DFT）到频域，并使用ResNet50神经网络进行分类。

Result: 在频域模型上实现了92.8%的准确率和0.95的AUC，优于在原始图像上训练的模型。

Conclusion: GAN生成的图像在频域具有独特的“指纹”；提出的方法结合了信号处理和深度学习，在数字取证和工业AI系统中有应用潜力。

Abstract: The rapid rise of photorealistic images produced from Generative Adversarial
Networks (GANs) poses a serious challenge for image forensics and industrial
systems requiring reliable content authenticity. This paper uses
frequency-domain analysis combined with deep learning to solve the problem of
distinguishing StyleGAN-generated images from real ones. Specifically, a
two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform
images into the Fourier domain, where subtle periodic artifacts become
detectable. A ResNet50 neural network is trained on these transformed images to
differentiate between real and synthetic ones. The experiments demonstrate that
the frequency-domain model achieves a 92.8 percent and an AUC of 0.95,
significantly outperforming the equivalent model trained on raw spatial-domain
images. These results indicate that the GAN-generated images have unique
frequency-domain signatures or "fingerprints". The method proposed highlights
the industrial potential of combining signal processing techniques and deep
learning to enhance digital forensics and strengthen the trustworthiness of
industrial AI systems.

</details>


### [2] [Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses](https://arxiv.org/abs/2510.20027)
*Damian Bowness,Charalambos Poullis*

Main category: cs.CV

TL;DR: 3DGS模型在训练数据分布之外的相机位置观察时会出现视觉噪声，这是由于缺乏训练数据导致的。为了解决这个问题，我们提出了一种新颖的实时渲染感知过滤方法，该方法利用中间梯度的敏感性分数来解决由各向异性方向引起的*, 从而在用户自由导航到训练视角之外时也能保持高视觉保真度。实验证明，我们的方法在视觉质量、真实感和一致性方面优于现有的基于NeRF的方法，并且可以实时集成到现有的3DGS渲染管线中。


<details>
  <summary>Details</summary>
Motivation: 3DGS模型在训练数据分布之外的相机位置观察时会出现视觉噪声，这是由于缺乏训练数据导致的。

Method: 提出了一种新颖的实时渲染感知过滤方法，该方法利用中间梯度的敏感性分数来解决由各向异性方向引起的*, 从而在用户自由导航到训练视角之外时也能保持高视觉保真度。

Result: 与现有的基于NeRF的方法（如BayesRays）相比，我们的方法在视觉质量、真实感和一致性方面有了显著提高。

Conclusion: 我们的过滤器可以实时无缝地集成到现有的3DGS渲染管线中，而无需进行广泛的后期重新训练或微调。

Abstract: When viewing a 3D Gaussian Splatting (3DGS) model from camera positions
significantly outside the training data distribution, substantial visual noise
commonly occurs. These artifacts result from the lack of training data in these
extrapolated regions, leading to uncertain density, color, and geometry
predictions from the model.
  To address this issue, we propose a novel real-time render-aware filtering
method. Our approach leverages sensitivity scores derived from intermediate
gradients, explicitly targeting instabilities caused by anisotropic
orientations rather than isotropic variance. This filtering method directly
addresses the core issue of generative uncertainty, allowing 3D reconstruction
systems to maintain high visual fidelity even when users freely navigate
outside the original training viewpoints.
  Experimental evaluation demonstrates that our method substantially improves
visual quality, realism, and consistency compared to existing Neural Radiance
Field (NeRF)-based approaches such as BayesRays. Critically, our filter
seamlessly integrates into existing 3DGS rendering pipelines in real-time,
unlike methods that require extensive post-hoc retraining or fine-tuning.
  Code and results at https://damian-bowness.github.io/EV3DGS

</details>


### [3] [Transformed Multi-view 3D Shape Features with Contrastive Learning](https://arxiv.org/abs/2510.19955)
*Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: ViT架构结合对比学习方法在3D形状理解上表现优异，能够克服数据标注不足和CNN的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机视觉方法在从2D图像识别3D物体时面临挑战，通常需要大量标注数据，并且基于CNN的方法可能忽略重要的形状关系。

Method: 研究了结合了对比监督和自监督学习目标的最先进骨干网络，特别是Vision Transformers (ViTs)架构。

Result: 在多视角3D分析的下游任务上，基于ViTs的架构结合现代对比目标取得了有希望的结果，例如，监督对比损失在ModelNet10上达到了约90.6%的准确率。

Conclusion: ViTs架构与对比学习的结合能够克服对大量标注数据的需求以及CNN在捕捉关键形状关系方面的局限性。这种方法的成功归因于ViTs捕获全局形状语义和对比学习优化局部判别特征的能力。

Abstract: This paper addresses the challenges in representation learning of 3D shape
features by investigating state-of-the-art backbones paired with both
contrastive supervised and self-supervised learning objectives. Computer vision
methods struggle with recognizing 3D objects from 2D images, often requiring
extensive labeled data and relying on Convolutional Neural Networks (CNNs) that
may overlook crucial shape relationships. Our work demonstrates that Vision
Transformers (ViTs) based architectures, when paired with modern contrastive
objectives, achieve promising results in multi-view 3D analysis on our
downstream tasks, unifying contrastive and 3D shape understanding pipelines.
For example, supervised contrastive losses reached about 90.6% accuracy on
ModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability
to understand overall shapes and contrastive learning's effectiveness,
overcomes the need for extensive labeled data and the limitations of CNNs in
capturing crucial shape relationships. The success stems from capturing global
shape semantics via ViTs and refining local discriminative features through
contrastive optimization. Importantly, our approach is empirical, as it is
grounded on extensive experimental evaluation to validate the effectiveness of
combining ViTs with contrastive objectives for 3D representation learning.

</details>


### [4] [From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail](https://arxiv.org/abs/2510.20558)
*Xiaohan Sun,Carol O'Sullivan*

Main category: cs.CV

TL;DR: 本研究评估了用户对不同细节层次（LoD）和视角距离下，人群表示的视觉质量的感知，涉及几何网格、图像基础模型、NeRFs和3D高斯等多种技术，旨在为人群渲染的感知优化LoD策略提供指导。


<details>
  <summary>Details</summary>
Motivation: 探究用户对不同细节层次（LoD）和视角距离下，人群表示的视觉质量的感知。

Method: 评估了用户对几何网格、图像基础模型、NeRFs和3D高斯等多种人群表示技术的感知。

Result: 提供了关于视觉保真度和计算性能之间权衡的见解。

Conclusion: 研究结果可指导人群渲染的感知优化LoD策略的设计。

Abstract: In this paper, we investigate how users perceive the visual quality of crowd
character representations at different levels of detail (LoD) and viewing
distances. Each representation: geometric meshes, image-based impostors, Neural
Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between
visual fidelity and computational performance. Our qualitative and quantitative
results provide insights to guide the design of perceptually optimized LoD
strategies for crowd rendering.

</details>


### [5] [FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking](https://arxiv.org/abs/2510.19981)
*Martha Teiko Teye,Ori Maoz,Matthias Rottmann*

Main category: cs.CV

TL;DR: FutrTrack是一个结合了Transformer和多模态传感器（相机和LiDAR）的3D多目标跟踪框架，通过引入基于Transformer的平滑器和融合驱动的跟踪器，在nuScenes和KITTI数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D目标检测器在多目标跟踪方面仍有提升空间，特别是在处理遮挡和视角变化等挑战时。本研究旨在提出一种新的框架，利用多模态传感器信息和Transformer模型来改进3D多目标跟踪的性能。

Method: FutrTrack框架包含两个主要部分：1. 基于Transformer的平滑器：在跟踪前，使用一个滑动窗口的Transformer模型来优化连续帧的目标边界框，以修正轨迹、减少抖动并提高空间一致性。2. 融合驱动的跟踪器：该跟踪器利用来自多个相机和LiDAR的多模态鸟瞰图（BEV）融合特征，结合几何和语义线索，在无需显式运动模型的情况下进行身份分配和跨帧传播，以实现鲁棒的重识别。

Result: 在nuScenes和KITTI数据集上的评估结果显示，FutrTrack相比于先前仅使用单一传感器的方法，在利用基于查询的Transformer跟踪方法时，从多模态传感器特征中获益显著。在nuScenes测试集上，FutrTrack达到了74.7的aMOTA，在3D多目标跟踪基准上表现强劲，减少了身份切换次数，同时保持了具有竞争力的准确性。

Conclusion: FutrTrack是一个高效的框架，能够提升基于Transformer的跟踪器的性能，即使在数据有限且没有预训练的情况下，也能与其他基于神经网络的方法竞争。该框架通过多模态传感器融合和Transformer模型，有效解决了3D多目标跟踪中的遮挡和视角变化等问题。

Abstract: We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework
that builds on existing 3D detectors by introducing a transformer-based
smoother and a fusion-driven tracker. Inspired by query-based tracking
frameworks, FutrTrack employs a multimodal two-stage transformer refinement and
tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal
bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without
the need for an explicit motion model. The tracker assigns and propagates
identities across frames, leveraging both geometric and semantic cues for
robust re-identification under occlusion and viewpoint changes. Prior to
tracking, we refine sequences of bounding boxes with a temporal smoother over a
moving window to refine trajectories, reduce jitter, and improve spatial
consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that
query-based transformer tracking methods benefit significantly from multimodal
sensor features compared with previous single-sensor approaches. With an aMOTA
of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D
MOT benchmarks, reducing identity switches while maintaining competitive
accuracy. Our approach provides an efficient framework for improving
transformer-based trackers to compete with other neural-network-based methods
even with limited data and without pretraining.

</details>


### [6] [Improving Predictive Confidence in Medical Imaging via Online Label Smoothing](https://arxiv.org/abs/2510.20011)
*Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry*

Main category: cs.CV

TL;DR: 深度学习模型在医学图像分类中表现出色，但预测过于自信。本研究提出在线标签平滑（OLS）方法，通过动态调整软标签来减少过度自信，并提高了分类准确性和特征表示。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分类中存在预测过于自信的问题，影响其可靠性。传统的标签平滑方法未能考虑类别间的关系。

Method: 提出并评估在线标签平滑（OLS）方法，该方法动态调整软标签。在RadImageNet数据集上使用ResNet-50、MobileNetV2和VGG-19三种架构进行实验。

Result: OLS在准确率（Top-1和Top-5）方面优于硬标签、传统标签平滑和无教师知识蒸馏。OLS还能产生更紧凑、分离度更好的特征嵌入。

Conclusion: OLS不仅提高了预测性能，还增强了模型的校准能力，是医疗影像领域值得信赖的AI系统的实用解决方案。

Abstract: Deep learning models, especially convolutional neural networks, have achieved
impressive results in medical image classification. However, these models often
produce overconfident predictions, which can undermine their reliability in
critical healthcare settings. While traditional label smoothing offers a simple
way to reduce such overconfidence, it fails to consider relationships between
classes by treating all non-target classes equally. In this study, we explore
the use of Online Label Smoothing (OLS), a dynamic approach that adjusts soft
labels throughout training based on the model's own prediction patterns. We
evaluate OLS on the large-scale RadImageNet dataset using three widely used
architectures: ResNet-50, MobileNetV2, and VGG-19. Our results show that OLS
consistently improves both Top-1 and Top-5 classification accuracy compared to
standard training methods, including hard labels, conventional label smoothing,
and teacher-free knowledge distillation. In addition to accuracy gains, OLS
leads to more compact and well-separated feature embeddings, indicating
improved representation learning. These findings suggest that OLS not only
strengthens predictive performance but also enhances calibration, making it a
practical and effective solution for developing trustworthy AI systems in the
medical imaging domain.

</details>


### [7] [A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance](https://arxiv.org/abs/2510.20016)
*Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 鱼眼相机可用于广域交通监控，但其径向畸变和分辨率不均会影响物体检测。本研究提出了一种预处理和后处理相结合的框架，并通过集成多个先进检测模型来提高检测精度，最终在AI City挑战赛中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决鱼眼相机图像中存在的径向畸变和分辨率不均问题，以提高交通监控中物体检测的鲁棒性和一致性。

Method: 采用预处理和后处理流水线增强图像质量，并结合多种先进的物体检测模型，通过集成策略提升整体检测性能。

Result: 在2025 AI City挑战赛Track 4上，该方法达到了0.6366的F1分数，在62支队伍中排名第8。

Conclusion: 所提出的框架能有效解决鱼眼图像的固有问题，显著提升物体检测的准确性。

Abstract: Fisheye cameras offer an efficient solution for wide-area traffic
surveillance by capturing large fields of view from a single vantage point.
However, the strong radial distortion and nonuniform resolution inherent in
fisheye imagery introduce substantial challenges for standard object detectors,
particularly near image boundaries where object appearance is severely
degraded. In this work, we present a detection framework designed to operate
robustly under these conditions. Our approach employs a simple yet effective
pre and post processing pipeline that enhances detection consistency across the
image, especially in regions affected by severe distortion. We train several
state-of-the-art detection models on the fisheye traffic imagery and combine
their outputs through an ensemble strategy to improve overall detection
accuracy. Our method achieves an F1 score of0.6366 on the 2025 AI City
Challenge Track 4, placing 8thoverall out of 62 teams. These results
demonstrate the effectiveness of our framework in addressing issues inherent to
fisheye imagery.

</details>


### [8] [BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography](https://arxiv.org/abs/2510.20029)
*Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin*

Main category: cs.CV

TL;DR: 本研究提出了一种名为BrainPuzzle的混合方法，结合物理建模和机器学习，以克服超声脑成像的挑战，实现定量颅内超声成像。


<details>
  <summary>Details</summary>
Motivation: 传统方法在跨颅超声成像方面存在困难，如颅骨与脑组织声速差异大、探头耦合难、信号衰减、模式转换、相位畸变以及阵列覆盖不全等问题。纯数据驱动方法在低信噪比和稀疏孔径条件下，难以准确模拟骨骼的非线性波传播，导致超声声速图不准确。

Method: BrainPuzzle采用两阶段混合框架：第一阶段，利用反向时间迁移（时间反转声学）处理多角度采集数据，生成能够保留结构细节的迁移片段。第二阶段，使用基于Transformer的超分辨率编码器-解码器，并结合基于图的注意力单元（GAU），将迁移片段融合为连贯且定量准确的声速图像。此外，采用移动式低计数换能器组的部分阵列采集策略，提高了可行性和耦合性，并利用混合算法弥补了孔径的不足。

Result: 在两个合成数据集上的实验表明，BrainPuzzle在声速重建精度和图像完整性方面表现优越。

Conclusion: BrainPuzzle展示了其在推进定量超声脑成像方面的潜力。

Abstract: Ultrasound brain imaging remains challenging due to the large difference in
sound speed between the skull and brain tissues and the difficulty of coupling
large probes to the skull. This work aims to achieve quantitative transcranial
ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain.
Traditional physics-based full-waveform inversion (FWI) is limited by weak
signals caused by skull-induced attenuation, mode conversion, and phase
aberration, as well as incomplete spatial coverage since full-aperture arrays
are clinically impractical. In contrast, purely data-driven methods that learn
directly from raw ultrasound data often fail to model the complex nonlinear and
nonlocal wave propagation through bone, leading to anatomically plausible but
quantitatively biased SoS maps under low signal-to-noise and sparse-aperture
conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage
framework that combines physical modeling with machine learning. In the first
stage, reverse time migration (time-reversal acoustics) is applied to
multi-angle acquisitions to produce migration fragments that preserve
structural details even under low SNR. In the second stage, a transformer-based
super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses
these fragments into a coherent and quantitatively accurate SoS image. A
partial-array acquisition strategy using a movable low-count transducer set
improves feasibility and coupling, while the hybrid algorithm compensates for
the missing aperture. Experiments on two synthetic datasets show that
BrainPuzzle achieves superior SoS reconstruction accuracy and image
completeness, demonstrating its potential for advancing quantitative ultrasound
brain imaging.

</details>


### [9] [Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models](https://arxiv.org/abs/2510.20042)
*Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 在文本到图像（T2I）生成和图像到图像（I2I）编辑中，生成式图像模型普遍存在文化偏见，通常会优先生成“全球北方”和现代的描绘，忽视了跨国界和跨时代的差异。迭代式I2I编辑甚至会进一步削弱文化保真度，尽管传统指标可能保持不变甚至有所改善。模型倾向于应用肤浅的、非特定时代的文化线索（如调色板变化、通用道具），而不是进行与时代和背景相关的、深思熟虑的修改。为了解决这个问题，本研究提出了一个包含六个国家、八个类别/三十六个子类别的标准化评估框架，并结合了自动指标、文化感知检索增强视觉问答（VQA）以及母语专家的人工判断。研究发布了完整的图像语料库、提示和配置，以确保可复现性，旨在为诊断和追踪生成式图像模型中的文化偏见提供一个可复现的、以文化为中心的基准。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要关注文本到图像（T2I）系统中的文化偏见，而对图像到图像（I2I）编辑器的研究不足。本研究旨在弥合这一差距，对T2I生成和I2I编辑进行统一的跨国评估，以诊断和追踪生成式图像模型中的文化偏见。

Method: 采用标准化的协议，对六个国家、八个类别/三十六个子类别的图像进行评估。评估结合了自动指标、文化感知检索增强视觉问答（VQA）以及母语专家的人工判断。研究发布了完整的图像语料库、提示和配置，以确保可复现性。

Result: 研究发现，在不考虑国家因素的提示下，模型倾向于生成“全球北方”和现代风格的图像，忽视了不同国家之间的差异。迭代式I2I编辑会削弱文化保真度，即使传统指标没有变化或有所改善。I2I模型倾向于应用表面的文化线索（如调色板、通用道具），而不是进行与时代和背景相符的修改，并且在处理“全球南方”的目标图像时，常常保留原始图像的特征。

Conclusion: 当前生成式图像模型在进行文化敏感编辑方面仍然不可靠。本研究提出的标准化评估框架、数据集和评估协议为诊断和追踪生成式图像模型中的文化偏见提供了一个可复现的、以文化为中心的基准。

Abstract: Generative image models produce striking visuals yet often misrepresent
culture. Prior work has examined cultural bias mainly in text-to-image (T2I)
systems, leaving image-to-image (I2I) editors underexplored. We bridge this gap
with a unified evaluation across six countries, an 8-category/36-subcategory
schema, and era-aware prompts, auditing both T2I generation and I2I editing
under a standardized protocol that yields comparable diagnostics. Using open
models with fixed settings, we derive cross-country, cross-era, and
cross-category evaluations. Our framework combines standard automatic metrics,
a culture-aware retrieval-augmented VQA, and expert human judgments collected
from native reviewers. To enable reproducibility, we release the complete image
corpus, prompts, and configurations. Our study reveals three findings: (1)
under country-agnostic prompts, models default to Global-North, modern-leaning
depictions that flatten cross-country distinctions; (2) iterative I2I editing
erodes cultural fidelity even when conventional metrics remain flat or improve;
and (3) I2I models apply superficial cues (palette shifts, generic props)
rather than era-consistent, context-aware changes, often retaining source
identity for Global-South targets. These results highlight that
culture-sensitive edits remain unreliable in current systems. By releasing
standardized data, prompts, and human evaluation protocols, we provide a
reproducible, culture-centered benchmark for diagnosing and tracking cultural
bias in generative image models.

</details>


### [10] [Filter-Based Reconstruction of Images from Events](https://arxiv.org/abs/2510.20071)
*Bernd Pfrommer*

Main category: cs.CV

TL;DR: FIBAR是一种基于滤波器的异步事件相机图像重建方法，在CPU上运行速度快，虽然重建效果不如神经网络，但足以满足某些特定任务的需求。


<details>
  <summary>Details</summary>
Motivation: 从移动事件相机事件中重建强度图像是一个具有挑战性的任务，通常需要GPU上的神经网络。本文提出了一种更简单的方法。

Method: FIlter Based Asynchronous Reconstruction (FIBAR)方法：1. 使用IIR滤波器整合事件信号的强度变化。2. 通过新颖的算法检测并剔除陈旧像素以减少噪声。3. 对陈旧像素应用高斯模糊，假设无事件发生意味着低图像梯度。4. FIBAR是异步的，允许任意时间读取图像。

Result: FIBAR在现代笔记本CPU上运行速度可达约42(140)百万事件/秒（启用/禁用空间滤波）。重建图像比基于神经网络的方法更嘈杂，并有重影，但足以完成诸如定位标记检测等任务。

Conclusion: FIBAR是一种简单、快速的事件相机图像重建方法，适用于特定任务，但其重建质量不如基于神经网络的方法。

Abstract: Reconstructing an intensity image from the events of a moving event camera is
a challenging task that is typically approached with neural networks deployed
on graphics processing units. This paper presents a much simpler, FIlter Based
Asynchronous Reconstruction method (FIBAR). First, intensity changes signaled
by events are integrated with a temporal digital IIR filter. To reduce
reconstruction noise, stale pixels are detected by a novel algorithm that
regulates a window of recently updated pixels. Arguing that for a moving
camera, the absence of events at a pixel location likely implies a low image
gradient, stale pixels are then blurred with a Gaussian filter. In contrast to
most existing methods, FIBAR is asynchronous and permits image read-out at an
arbitrary time. It runs on a modern laptop CPU at about 42(140) million
events/s with (without) spatial filtering enabled. A few simple qualitative
experiments are presented that show the difference in image reconstruction
between FIBAR and a neural network-based approach (FireNet). FIBAR's
reconstruction is noisier than neural network-based methods and suffers from
ghost images. However, it is sufficient for certain tasks such as the detection
of fiducial markers. Code is available at
https://github.com/ros-event-camera/event_image_reconstruction_fibar

</details>


### [11] [Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering](https://arxiv.org/abs/2510.20077)
*Hui Chen,Xinjie Wang,Xianchao Xiu,Wanquan Liu*

Main category: cs.CV

TL;DR: TBTLRR模型通过学习任意酉变换来引入数据自适应张量核范数，并利用潜在张量数据的双边结构来捕获全局和局部相关性，同时整合了ℓ1/2范数和Frobenius范数正则化项来处理噪声，并通过ADMM优化算法求解，在图像聚类方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的张量低秩表示（TLRR）方法在图像聚类方面取得了成功，但它们依赖于固定的变换，并且对噪声的鲁棒性较差。

Method: 提出了一种新颖的变换双边张量低秩表示（TBTLRR）模型，该模型通过学习任意酉变换引入数据自适应张量核范数，利用潜在张量数据的双边结构来捕获局部相关性，并整合了ℓ1/2范数和Frobenius范数正则化项来处理噪声。使用受交替方向乘子法（ADMM）启发的优化算法来求解该非凸模型。

Result: 实验结果验证了TBTLRR在聚类方面优于最先进的方法。

Conclusion: TBTLRR通过引入数据自适应变换和利用双边结构，能够更有效地捕获全局和局部相关性，并能更好地处理复杂噪声，从而在图像聚类任务中表现出色。

Abstract: Tensor low-rank representation (TLRR) has demonstrated significant success in
image clustering. However, most existing methods rely on fixed transformations
and suffer from poor robustness to noise. In this paper, we propose a novel
transformed bilateral tensor low-rank representation model called TBTLRR, which
introduces a data-adaptive tensor nuclear norm by learning arbitrary unitary
transforms, allowing for more effective capture of global correlations. In
addition, by leveraging the bilateral structure of latent tensor data, TBTLRR
is able to exploit local correlations between image samples and features.
Furthermore, TBTLRR integrates the $\ell_{1/2}$-norm and Frobenius norm
regularization terms for better dealing with complex noise in real-world
scenarios. To solve the proposed nonconvex model, we develop an efficient
optimization algorithm inspired by the alternating direction method of
multipliers (ADMM) and provide theoretical convergence. Extensive experiments
validate its superiority over the state-of-the-art methods in clustering. The
code will be available at https://github.com/xianchaoxiu/TBTLRR.

</details>


### [12] [Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos](https://arxiv.org/abs/2510.20087)
*Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy*

Main category: cs.CV

TL;DR: Endoshare是一款用于标准化和去标识化内窥镜视频的应用程序，解决了视频格式异构性和隐私问题，提高了手术培训和研究的效率。


<details>
  <summary>Details</summary>
Motivation: 现有内窥镜视频格式不统一且存在隐私问题，阻碍了其在手术培训、研究和质量改进中的广泛应用。

Method: 采用软件开发生命周期，结合用户反馈，设计了隐私优先的架构。通过内部和外部调查评估了可用性和用户接受度，并进行了性能基准测试。

Result: 用户调查显示，Endoshare具有高可用性（4.68/5）和易用性（5.15/7）。处理时间受处理模式、视频时长和计算能力影响。

Conclusion: Endoshare为手术视频管理提供了一个标准化、注重隐私的解决方案，但仍需合规认证和互操作性验证才能广泛部署。

Abstract: Video-based assessment and surgical data science can advance surgical
training, research, and quality improvement. However, widespread use remains
limited by heterogeneous recording formats and privacy concerns associated with
video sharing. We present Endoshare, a source-available, cross-platform
application for merging, standardizing, and de-identifying endoscopic videos in
minimally invasive surgery. Development followed the software development life
cycle with iterative, user-centered feedback. During the analysis phase, an
internal survey of clinicians and computer scientists based on ten usability
heuristics identified key requirements that guided a privacy-by-design
architecture. In the testing phase, an external clinician survey combined the
same heuristics with Technology Acceptance Model constructs to assess usability
and adoption, complemented by benchmarking across different hardware
configurations. Four clinicians and four computer scientists initially tested
the prototype, reporting high usability (4.68 +/- 0.40/5 and 4.03 +/- 0.51/5),
with the lowest score (4.00 +/- 0.93/5) relating to label clarity. After
refinement, the testing phase surveyed ten surgeons who reported high perceived
usefulness (5.07 +/- 1.75/7), ease of use (5.15 +/- 1.71/7), heuristic
usability (4.38 +/- 0.48/5), and strong recommendation (9.20 +/- 0.79/10).
Processing time varied with processing mode, video duration (both p <= 0.001),
and machine computational power (p = 0.041). Endoshare provides a transparent,
user-friendly pipeline for standardized, privacy-preserving surgical video
management. Compliance certification and broader interoperability validation
are needed to establish it as a deployable alternative to proprietary systems.
The software is available at https://camma-public.github.io/Endoshare/

</details>


### [13] [Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency](https://arxiv.org/abs/2510.20092)
*Hao Yu,Haoyu Chen,Yan Jiang,Wei Peng,Zhaodong Sun,Samuel Kaski,Guoying Zhao*

Main category: cs.CV

TL;DR: 自注意力（SA）因其强大的表达能力成为现代视觉骨干网络的基石，但其二次复杂度限制了其应用。卷积（Conv）具有线性复杂度，但表达能力不足。本文提出了“注意力卷积”（ATConv），通过引入“自适应路由”和“侧抑制”机制，使卷积在保持线性复杂度的同时，获得媲美甚至超越自注意力的表达能力。基于ATConv构建的AttNet在ImageNet等任务上取得了优异成绩，并在图像生成任务中提升了FID分数。


<details>
  <summary>Details</summary>
Motivation: 探索自注意力（SA）优于卷积（Conv）的根本原因，以改进卷积神经网络的设计，克服其性能瓶颈。

Method: 通过重新审视卷积神经网络的设计，揭示了自注意力优于卷积的两个关键原则：1. 自适应路由：SA根据语义内容动态调整位置信息流，而Conv使用静态核；2. 侧抑制：SA通过竞争性加权抑制冗余，而Conv缺乏此机制。在此基础上，提出“注意力卷积”（ATConv），将这两个原则融入卷积算子。

Result: 提出的ATConv在基础视觉任务中，仅使用3x3卷积核，性能持续优于多种自注意力机制。基于ATConv构建的AttNet达到了84.4%的ImageNet-1K Top-1准确率，参数量仅为27M。在扩散模型SiT-XL/2中，用ATConv替换SiT中的所有SA，可将ImageNet FID降低0.15，并加快采样速度。

Conclusion: ATConv是一种基于CNN的原则性重新设计的卷积算子，通过引入自适应路由和侧抑制，在保持线性复杂度的同时，实现了与自注意力相当甚至更优的性能，为视觉表示学习提供了新的方向。

Abstract: Self-attention (SA) has become the cornerstone of modern vision backbones for
its powerful expressivity over traditional Convolutions (Conv). However, its
quadratic complexity remains a critical bottleneck for practical applications.
Given that Conv offers linear complexity and strong visual priors, continuing
efforts have been made to promote the renaissance of Conv. However, a
persistent performance chasm remains, highlighting that these modernizations
have not yet captured the intrinsic expressivity that defines SA. In this
paper, we re-examine the design of the CNNs, directed by a key question: what
principles give SA its edge over Conv? As a result, we reveal two fundamental
insights that challenge the long-standing design intuitions in prior research
(e.g., Receptive field). The two findings are: (1) \textit{Adaptive routing}:
SA dynamically regulates positional information flow according to semantic
content, whereas Conv employs static kernels uniformly across all positions.
(2) \textit{Lateral inhibition}: SA induces score competition among token
weighting, effectively suppressing redundancy and sharpening representations,
whereas Conv filters lack such inhibitory dynamics and exhibit considerable
redundancy. Based on this, we propose \textit{Attentive Convolution} (ATConv),
a principled reformulation of the convolutional operator that intrinsically
injects these principles. Interestingly, with only $3\times3$ kernels, ATConv
consistently outperforms various SA mechanisms in fundamental vision tasks.
Building on ATConv, we introduce AttNet, a CNN family that can attain
\textbf{84.4\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In
diffusion-based image generation, replacing all SA with the proposed $3\times
3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster
sampling. Code is available at: github.com/price112/Attentive-Convolution.

</details>


### [14] [StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback](https://arxiv.org/abs/2510.20093)
*Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim*

Main category: cs.CV

TL;DR: StableSketcher 是一个新框架，可以提高文生图模型生成手绘草图的质量和与提示的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文生图模型在生成像素级的手绘草图方面存在挑战，无法很好地捕捉抽象表达的特点。

Method: 1. 优化了变分自编码器的潜在解码，使其能更好地捕捉草图特征。2. 引入了基于视觉问答的新奖励函数，用于强化学习，以提高文本-图像对齐和语义一致性。3. 构建了 SketchDUO 数据集，包含实例级草图及其对应的标题和问答对。

Result: StableSketcher 生成的草图在风格保真度和提示对齐方面优于 Stable Diffusion 基线模型。

Conclusion: StableSketcher 框架能够显著提高文生图模型生成手绘草图的质量和与提示的保真度。SketchDUO 数据集的构建解决了现有数据集的局限性。

Abstract: Although recent advancements in diffusion models have significantly enriched
the quality of generated images, challenges remain in synthesizing pixel-based
human-drawn sketches, a representative example of abstract expression. To
combat these challenges, we propose StableSketcher, a novel framework that
empowers diffusion models to generate hand-drawn sketches with high prompt
fidelity. Within this framework, we fine-tune the variational autoencoder to
optimize latent decoding, enabling it to better capture the characteristics of
sketches. In parallel, we integrate a new reward function for reinforcement
learning based on visual question answering, which improves text-image
alignment and semantic consistency. Extensive experiments demonstrate that
StableSketcher generates sketches with improved stylistic fidelity, achieving
better alignment with prompts compared to the Stable Diffusion baseline.
Additionally, we introduce SketchDUO, to the best of our knowledge, the first
dataset comprising instance-level sketches paired with captions and
question-answer pairs, thereby addressing the limitations of existing datasets
that rely on image-label pairs. Our code and dataset will be made publicly
available upon acceptance.

</details>


### [15] [BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models](https://arxiv.org/abs/2510.20095)
*Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu*

Main category: cs.CV

TL;DR: 本研究利用维基百科和特定分类单元的格式示例，通过多模态大语言模型（MLLM）生成了用于生物基础模型的描述性图注，从而解决了大规模获取精确图注的难题。该方法训练的BIOCAP模型在物种分类和文本-图像检索方面取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 生物图像和图注可以被视为同一物种潜在形态空间中的互补样本，各自捕捉了不同的生物学特征。然而，大规模获取忠实且特定于实例的图注具有挑战性，这限制了自然语言监督在生物学中的应用。

Method: 利用维基百科衍生的视觉信息和分类单元定制的格式示例，通过多模态大语言模型（MLLMs）生成合成图注。使用这些图注训练了一个名为BIOCAP的生物基础模型。

Result: 生成的BIOCAP模型能够捕捉丰富的语义信息，并在物种分类和文本-图像检索任务上表现出强大的性能。

Conclusion: 描述性图注除了标签之外，还能在连接生物图像和多模态基础模型方面发挥重要作用，正如BIOCAP模型所示。

Abstract: This work investigates descriptive captions as an additional source of
supervision for biological multimodal foundation models. Images and captions
can be viewed as complementary samples from the latent morphospace of a
species, each capturing certain biological traits. Incorporating captions
during training encourages alignment with this shared latent structure,
emphasizing potentially diagnostic characters while suppressing spurious
correlations. The main challenge, however, lies in obtaining faithful,
instance-specific captions at scale. This requirement has limited the
utilization of natural language supervision in organismal biology compared with
many other scientific domains. We complement this gap by generating synthetic
captions with multimodal large language models (MLLMs), guided by
Wikipedia-derived visual information and taxon-tailored format examples. These
domain-specific contexts help reduce hallucination and yield accurate,
instance-based descriptive captions. Using these captions, we train BIOCAP
(i.e., BIOCLIP with Captions), a biological foundation model that captures rich
semantics and achieves strong performance in species classification and
text-image retrieval. These results demonstrate the value of descriptive
captions beyond labels in bridging biological images with multimodal foundation
models.

</details>


### [16] [Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects](https://arxiv.org/abs/2510.20126)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu*

Main category: cs.CV

TL;DR: 该研究提出了一种结合深度学习和基于物理的跟踪方法，用于检测和跟踪快速移动的微小物体，并在自定义的壁球数据集上进行了评估，结果显示该方法优于基于卡尔曼滤波的跟踪器。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉技术在通用目标检测和跟踪方面取得了显著进展，但在快速移动的微小目标检测和跟踪方面仍有待探索。

Method: 提出了一种新颖的系统，结合了基于深度学习的目标检测和基于物理的跟踪，并集成了运动学方程来处理异常值和漏检，此外还有一个用于处理遮挡和快速方向改变的异常值检测和校正模块。

Result: 在自定义壁球数据集上的评估显示，该系统在平均位移误差方面比基于卡尔曼滤波的跟踪器低了 70%。

Conclusion: 该研究提出了一个有效的系统，用于实时 3D 检测和跟踪具有挑战性的小型物体，证明了将基于物理的模型与深度学习方法相结合的有效性，并强调了其在机器人感知领域的应用潜力。

Abstract: While computer vision has advanced considerably for general object detection
and tracking, the specific problem of fast-moving tiny objects remains
underexplored. This paper addresses the significant challenge of detecting and
tracking rapidly moving small objects using an RGB-D camera. Our novel system
combines deep learning-based detection with physics-based tracking to overcome
the limitations of existing approaches. Our contributions include: (1) a
comprehensive system design for object detection and tracking of fast-moving
small objects in 3D space, (2) an innovative physics-based tracking algorithm
that integrates kinematics motion equations to handle outliers and missed
detections, and (3) an outlier detection and correction module that
significantly improves tracking performance in challenging scenarios such as
occlusions and rapid direction changes. We evaluated our proposed system on a
custom racquetball dataset. Our evaluation shows our system surpassing kalman
filter based trackers with up to 70\% less Average Displacement Error. Our
system has significant applications for improving robot perception on
autonomous platforms and demonstrates the effectiveness of combining
physics-based models with deep learning approaches for real-time 3D detection
and tracking of challenging small objects.

</details>


### [17] [Inverse Image-Based Rendering for Light Field Generation from Single Images](https://arxiv.org/abs/2510.20132)
*Hyunjun Jung,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: 从单张图像生成光场的新方法，无需昂贵的设备或计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有的光场生成方法计算成本高或需要专门设备，限制了其应用。本研究旨在通过单张图像生成光场，以扩大其应用范围。

Method: 提出一种名为“逆向图像基渲染”的新方法，通过神经网络渲染管线从输入图像的像素重建光流，并迭代生成新视角图像，同时处理遮挡内容。

Result: 该方法在各种数据集上表现良好，无需重新训练或微调，并且优于当前最先进的视角合成方法。

Conclusion: 本研究提出的逆向图像基渲染方法能够有效地从单张图像生成光场，具有广泛的应用前景。

Abstract: A concept of light-fields computed from multiple view images on regular grids
has proven its benefit for scene representations, and supported realistic
renderings of novel views and photographic effects such as refocusing and
shallow depth of field. In spite of its effectiveness of light flow
computations, obtaining light fields requires either computational costs or
specialized devices like a bulky camera setup and a specialized microlens
array. In an effort to broaden its benefit and applicability, in this paper, we
propose a novel view synthesis method for light field generation from only
single images, named inverse image-based rendering. Unlike previous attempts to
implicitly rebuild 3D geometry or to explicitly represent objective scenes, our
method reconstructs light flows in a space from image pixels, which behaves in
the opposite way to image-based rendering. To accomplish this, we design a
neural rendering pipeline to render a target ray in an arbitrary viewpoint. Our
neural renderer first stores the light flow of source rays from the input
image, then computes the relationships among them through cross-attention, and
finally predicts the color of the target ray based on these relationships.
After the rendering pipeline generates the first novel view from a single input
image, the generated out-of-view contents are updated to the set of source
rays. This procedure is iteratively performed while ensuring the consistent
generation of occluded contents. We demonstrate that our inverse image-based
rendering works well with various challenging datasets without any retraining
or finetuning after once trained on synthetic dataset, and outperforms relevant
state-of-the-art novel view synthesis methods.

</details>


### [18] [Revisiting Logit Distributions for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2510.20134)
*Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: LogitGap是一种新的、利用模型logit信息进行OOD检测的方法，能提高区分in-distribution和out-of-distribution样本的能力，并达到state-of-the-art的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的post-hoc OOD检测方法未能充分利用模型logit信息，而LogitGap旨在解决这一问题。

Method: LogitGap通过利用最大logit与其他logit之间的关系来增强区分能力，并通过一种无训练策略来识别最有效区分样本的logit。

Result: 实验表明，LogitGap在视觉-语言和纯视觉模型上都取得了state-of-the-art的性能。

Conclusion: LogitGap是一种有效且性能优越的post-hoc OOD检测方法。

Abstract: Out-of-distribution (OOD) detection is critical for ensuring the reliability
of deep learning models in open-world applications. While post-hoc methods are
favored for their efficiency and ease of deployment, existing approaches often
underexploit the rich information embedded in the model's logits space. In this
paper, we propose LogitGap, a novel post-hoc OOD detection method that
explicitly exploits the relationship between the maximum logit and the
remaining logits to enhance the separability between in-distribution (ID) and
OOD samples. To further improve its effectiveness, we refine LogitGap by
focusing on a more compact and informative subset of the logit space.
Specifically, we introduce a training-free strategy that automatically
identifies the most informative logits for scoring. We provide both theoretical
analysis and empirical evidence to validate the effectiveness of our approach.
Extensive experiments on both vision-language and vision-only models
demonstrate that LogitGap consistently achieves state-of-the-art performance
across diverse OOD detection scenarios and benchmarks. Code is available at
https://github.com/GIT-LJc/LogitGap.

</details>


### [19] [PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding](https://arxiv.org/abs/2510.20155)
*Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu*

Main category: cs.CV

TL;DR: PartNeXt是一个包含23,000多个带纹理3D模型的高质量数据集，旨在解决现有3D部件理解数据集的局限性，并在部件分割和3D-LLM问答方面提供了新的基准。


<details>
  <summary>Details</summary>
Motivation: 现有数据集（如PartNet）在纹理、部件细粒度和标注专家依赖性方面存在局限，限制了可扩展性和可用性。

Method: 创建PartNeXt数据集，包含23,000多个高质量、带纹理的3D模型，并提供细粒度的、分层的部件标签（涵盖50个类别）。在PartNeXt上对两个任务进行了基准测试：1. 类别无关部件分割；2. 3D部件中心问答（针对3D-LLM的新基准）。

Result: 在部件分割任务中，现有先进方法在处理细粒度和叶级部件时遇到困难。在3D-LLM问答任务中，发现了开放词汇部件基础方面的显著差距。使用PartNeXt训练Point-SAM在部件分割方面取得了显著进步，优于使用PartNet训练的结果。

Conclusion: PartNeXt通过可扩展的标注、纹理感知标签和多任务评估，克服了现有数据集的缺点，为结构化3D理解的研究开辟了新途径。

Abstract: Understanding objects at the level of their constituent parts is fundamental
to advancing computer vision, graphics, and robotics. While datasets like
PartNet have driven progress in 3D part understanding, their reliance on
untextured geometries and expert-dependent annotation limits scalability and
usability. We introduce PartNeXt, a next-generation dataset addressing these
gaps with over 23,000 high-quality, textured 3D models annotated with
fine-grained, hierarchical part labels across 50 categories. We benchmark
PartNeXt on two tasks: (1) class-agnostic part segmentation, where
state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with
fine-grained and leaf-level parts, and (2) 3D part-centric question answering,
a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary
part grounding. Additionally, training Point-SAM on PartNeXt yields substantial
gains over PartNet, underscoring the dataset's superior quality and diversity.
By combining scalable annotation, texture-aware labels, and multi-task
evaluation, PartNeXt opens new avenues for research in structured 3D
understanding.

</details>


### [20] [Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists](https://arxiv.org/abs/2510.20158)
*Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing*

Main category: cs.CV

TL;DR: 该研究提出了一种从单张RGB图像估计铰接式自行车和骑行者8D姿态（包括3D位置、3D旋转、转向和踏板旋转）的方法，以提高自动驾驶中对骑行者意图的理解和安全性。


<details>
  <summary>Details</summary>
Motivation: 准确估计骑行者姿态对于交叉意图分类、行为预测和避免碰撞至关重要。传统的6D姿态估计方法不足以处理自行车的铰接结构（如转向和踏板），因为这会改变其3D边界框和方向，而这些因素影响其真实行驶方向。

Method: 提出了一种从单张RGB图像估计铰接式自行车和骑行者8D姿态（3D平移、3D旋转、转向角度、踏板角度）的方法。该模型能够联合估计8D姿态和3D关键点，并使用合成和真实图像数据进行训练，以实现对真实图像的泛化。

Result: 在评估中，所提出的8D姿态估计方法在准确性方面表现出有前景的结果，与使用刚性模板进行匹配的最先进的6D姿态估计器相比，取得了具有竞争力的分数。

Conclusion: 该研究成功地提出了一种用于铰接式自行车和骑行者的8D姿态估计方法，能够更精细地估计自行车姿态状态和行驶方向，有望提高自动驾驶系统的安全性。

Abstract: In Autonomous Driving, cyclists belong to the safety-critical class of
Vulnerable Road Users (VRU), and accurate estimation of their pose is critical
for cyclist crossing intention classification, behavior prediction, and
collision avoidance. Unlike rigid objects, articulated bicycles are composed of
movable rigid parts linked by joints and constrained by a kinematic structure.
6D pose methods can estimate the 3D rotation and translation of rigid bicycles,
but 6D becomes insufficient when the steering/pedals angles of the bicycle
vary. That is because: 1) varying the articulated pose of the bicycle causes
its 3D bounding box to vary as well, and 2) the 3D box orientation is not
necessarily aligned to the orientation of the steering which determines the
actual intended travel direction. In this work, we introduce a method for
category-level 8D pose estimation for articulated bicycles and cyclists from a
single RGB image. Besides being able to estimate the 3D translation and
rotation of a bicycle from a single image, our method also estimates the
rotations of its steering handles and pedals with respect to the bicycle body
frame. These two new parameters enable the estimation of a more fine-grained
bicycle pose state and travel direction. Our proposed model jointly estimates
the 8D pose and the 3D Keypoints of articulated bicycles, and trains with a mix
of synthetic and real image data to generalize on real images. We include an
evaluation section where we evaluate the accuracy of our estimated 8D pose
parameters, and our method shows promising results by achieving competitive
scores when compared against state-of-the-art category-level 6D pose estimators
that use rigid canonical object templates for matching.

</details>


### [21] [TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning](https://arxiv.org/abs/2510.20162)
*Xudong Yan,Songhe Feng*

Main category: cs.CV

TL;DR: 本文提出了一种名为TOMCAT的新方法，用于解决组合零样本学习（CZSL）中的分布偏移问题，通过在测试时更新多模态原型并引入自适应权重和动态优先级队列，提高了模型在新组合上的识别性能，并在多个基准数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有组合零样本学习（CZSL）方法在测试时面临由 unseen 组合引起标签空间分布偏移的问题，导致性能下降。

Method: 提出一种新方法，在测试时利用无监督数据更新文本和视觉模态的原型，并设计自适应更新权重来控制原型调整的程度。此外，引入动态优先级队列从历史图像中获取视觉知识，并通过多模态协同表示学习对齐文本和视觉原型。

Result: 该方法在四个基准数据集的闭世界和开世界设置下均达到了最先进的性能。

Conclusion: 所提出的TOMCAT方法能够有效地缓解CZSL中的分布偏移问题，并通过自适应原型更新和多模态知识融合，在零样本识别任务上取得了显著的性能提升。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize novel
attribute-object compositions based on the knowledge learned from seen ones.
Existing methods suffer from performance degradation caused by the distribution
shift of label space at test time, which stems from the inclusion of unseen
compositions recombined from attributes and objects. To overcome the challenge,
we propose a novel approach that accumulates comprehensive knowledge in both
textual and visual modalities from unsupervised data to update multimodal
prototypes at test time. Building on this, we further design an adaptive update
weight to control the degree of prototype adjustment, enabling the model to
flexibly adapt to distribution shift during testing. Moreover, a dynamic
priority queue is introduced that stores high-confidence images to acquire
visual knowledge from historical images for inference. Considering the semantic
consistency of multimodal knowledge, we align textual and visual prototypes by
multimodal collaborative representation learning. Extensive experiments
indicate that our approach achieves state-of-the-art performance on four
benchmark datasets under both closed-world and open-world settings. Code will
be available at https://github.com/xud-yan/TOMCAT .

</details>


### [22] [IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks](https://arxiv.org/abs/2510.20165)
*Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim*

Main category: cs.CV

TL;DR: IB-GAN是一种新的基于GAN的无监督解耦表征学习模型，它利用信息瓶颈（IB）框架来优化GAN，并在生成器的中间层引入随机层来约束输入和输出之间的互信息，从而实现解耦和可解释的潜在空间利用。


<details>
  <summary>Details</summary>
Motivation: 利用信息瓶颈（IB）框架来优化生成对抗网络（GAN），以实现无监督的解耦表征学习。

Method: 提出了一种名为IB-GAN的新模型，其架构类似于InfoGAN，但在生成器的中间层增加了一个随机层，用于约束输入和输出之间的互信息。该模型与生成器联合进行端到端的训练。

Result: IB-GAN在dSprites和Color-dSprites数据集上取得了具有竞争力的解耦分数，优于InfoGAN，并且在CelebA和3D Chairs数据集上生成样本的视觉质量和多样性方面优于eta-VAEs和Info-GAN（以FID分数衡量）。

Conclusion: IB-GAN能够以解耦和可解释的方式利用潜在空间，并在解耦和生成样本质量方面取得了优于现有方法的成果。

Abstract: We propose a new GAN-based unsupervised model for disentangled representation
learning. The new model is discovered in an attempt to utilize the Information
Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The
architecture of IB-GAN is partially similar to that of InfoGAN but has a
critical difference; an intermediate layer of the generator is leveraged to
constrain the mutual information between the input and the generated output.
The intermediate stochastic layer can serve as a learnable latent distribution
that is trained with the generator jointly in an end-to-end fashion. As a
result, the generator of IB-GAN can harness the latent space in a disentangled
and interpretable manner. With the experiments on dSprites and Color-dSprites
dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores
to those of state-of-the-art \b{eta}-VAEs and outperforms InfoGAN. Moreover,
the visual quality and the diversity of samples generated by IB-GAN are often
better than those by \b{eta}-VAEs and Info-GAN in terms of FID score on CelebA
and 3D Chairs dataset.

</details>


### [23] [PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching](https://arxiv.org/abs/2510.20178)
*Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu*

Main category: cs.CV

TL;DR: PPMStereo通过引入内存缓冲区来解决立体视频深度估计中的时间一致性问题，实现了高效的动态立体匹配，并在准确性和时间一致性方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 立体视频深度估计的时间一致性对于增强现实等实际应用至关重要，但现有方法在计算效率和时间建模之间存在权衡。

Method: 提出了一种名为PPMStereo的动态立体匹配方法，其中包含一个“拾取”过程，用于识别最相关的帧，以及一个“播放”过程，用于自适应地加权所选帧以进行时空聚合。

Result: PPMStereo在Sintel数据集上实现了0.62/1.11 TEPE的性能，显著优于现有方法，同时计算成本更低。

Conclusion: PPMStereo通过创新的内存缓冲区设计，在保持计算效率的同时，显著提高了立体深度估计的时间一致性和准确性。

Abstract: Temporally consistent depth estimation from stereo video is critical for
real-world applications such as augmented reality, where inconsistent depth
estimation disrupts the immersion of users. Despite its importance, this task
remains challenging due to the difficulty in modeling long-term temporal
consistency in a computationally efficient manner. Previous methods attempt to
address this by aggregating spatio-temporal information but face a fundamental
trade-off: limited temporal modeling provides only modest gains, whereas
capturing long-range dependencies significantly increases computational cost.
To address this limitation, we introduce a memory buffer for modeling
long-range spatio-temporal consistency while achieving efficient dynamic stereo
matching. Inspired by the two-stage decision-making process in humans, we
propose a \textbf{P}ick-and-\textbf{P}lay \textbf{M}emory (PPM) construction
module for dynamic \textbf{Stereo} matching, dubbed as \textbf{PPMStereo}. PPM
consists of a `pick' process that identifies the most relevant frames and a
`play' process that weights the selected frames adaptively for spatio-temporal
aggregation. This two-stage collaborative process maintains a compact yet
highly informative memory buffer while achieving temporally consistent
information aggregation. Extensive experiments validate the effectiveness of
PPMStereo, demonstrating state-of-the-art performance in both accuracy and
temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the
Sintel clean/final (17.3\% \& 9.02\% improvements over BiDAStereo) with fewer
computational costs. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.

</details>


### [24] [Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories](https://arxiv.org/abs/2510.20182)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 现有的视频生成模型在模拟多人交互场景方面存在不足，本研究提出了一种评估 T2V 和 I2V 模型作为行人动态模拟器的协议，并发现现有模型在多人交互方面具有一定的能力，但也存在一些失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分评估文本到视频（T2V）和图像到视频（I2V）模型在模拟包含多个交互个体的复杂场景方面的能力，因此需要一个严格的评估协议来验证这些模型作为行人动态隐式模拟器的潜力。

Method: 提出了一种评估 T2V 和 I2V 模型作为行人动态隐式模拟器的协议。对于 I2V 模型，利用现有数据集的起始帧来与真实视频数据集进行比较。对于 T2V 模型，开发了一套提示（prompt）来探索不同的人群密度和交互场景。其中一个关键技术是能够在不知道相机参数的情况下，从像素空间重建二维俯视视角下的行人轨迹。

Result: 通过评估，发现领先的 T2V 和 I2V 模型在生成具有多种交互行为的行人动态方面，已经学习到了非常有效的先验知识，能够生成具有高度可信度的模拟效果。然而，研究也发现了一些模型在处理多人交互时的失败模式，例如行人合并或消失等问题。

Conclusion: 尽管领先的视频生成模型在模拟多人交互动态方面取得了显著进展，展现出令人惊讶的有效性，但仍然存在一些需要改进的领域，特别是在处理行人合并和消失等问题上。这为未来视频生成模型在模拟复杂多智能体动态方面的进一步发展指明了方向。

Abstract: Large-scale video generation models have demonstrated high visual realism in
diverse contexts, spurring interest in their potential as general-purpose world
simulators. Existing benchmarks focus on individual subjects rather than scenes
with multiple interacting people. However, the plausibility of multi-agent
dynamics in generated videos remains unverified. We propose a rigorous
evaluation protocol to benchmark text-to-video (T2V) and image-to-video (I2V)
models as implicit simulators of pedestrian dynamics. For I2V, we leverage
start frames from established datasets to enable comparison with a ground truth
video dataset. For T2V, we develop a prompt suite to explore diverse pedestrian
densities and interactions. A key component is a method to reconstruct 2D
bird's-eye view trajectories from pixel-space without known camera parameters.
Our analysis reveals that leading models have learned surprisingly effective
priors for plausible multi-agent behavior. However, failure modes like merging
and disappearing people highlight areas for future improvement.

</details>


### [25] [Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature](https://arxiv.org/abs/2510.20794)
*Lei Cheng,Siyang Cao*

Main category: cs.CV

TL;DR: 该研究提出了一个融合雷达和摄像头数据的多目标跟踪（MOT）框架，通过在线标定和利用传感器间的共同特征来提高跟踪精度并减少手动干预。


<details>
  <summary>Details</summary>
Motivation: 当前多目标跟踪研究中，雷达数据常被忽视或仅作为辅助，但雷达能提供精确的3D世界坐标系下的目标距离/深度信息。本研究旨在充分利用雷达数据的潜力，并提出一种创新的融合方法。

Method: 该框架利用雷达和摄像头数据的共同特征，实现了在线标定，能够自主匹配来自两种传感器的检测结果。通过特征匹配和类别一致性检查来提高传感器关联精度，克服了仅基于位置匹配的局限性。

Result: 实验证明，该框架能够简化雷达-摄像头映射过程，并提高跟踪精度。在受控环境和实际交通场景的真实世界实验中都取得了良好的效果。

Conclusion: 本研究首次探索了雷达-摄像头共同特征的融合及其在在线标定中的应用，以实现多目标跟踪。该方法有效提升了跟踪的准确性和效率。

Abstract: This paper presents a Multi-Object Tracking (MOT) framework that fuses radar
and camera data to enhance tracking efficiency while minimizing manual
interventions. Contrary to many studies that underutilize radar and assign it a
supplementary role--despite its capability to provide accurate range/depth
information of targets in a world 3D coordinate system--our approach positions
radar in a crucial role. Meanwhile, this paper utilizes common features to
enable online calibration to autonomously associate detections from radar and
camera. The main contributions of this work include: (1) the development of a
radar-camera fusion MOT framework that exploits online radar-camera calibration
to simplify the integration of detection results from these two sensors, (2)
the utilization of common features between radar and camera data to accurately
derive real-world positions of detected objects, and (3) the adoption of
feature matching and category-consistency checking to surpass the limitations
of mere position matching in enhancing sensor association accuracy. To the best
of our knowledge, we are the first to investigate the integration of
radar-camera common features and their use in online calibration for achieving
MOT. The efficacy of our framework is demonstrated by its ability to streamline
the radar-camera mapping process and improve tracking precision, as evidenced
by real-world experiments conducted in both controlled environments and actual
traffic scenarios. Code is available at
https://github.com/radar-lab/Radar_Camera_MOT

</details>


### [26] [SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization](https://arxiv.org/abs/2510.20189)
*Xinyi Hu,Yuran Wang,Yue Li,Wenxuan Liu,Zheng Wang*

Main category: cs.CV

TL;DR: SPAN通过从离散分类转向连续回归，利用时间点过程理论对可疑意图进行建模，并通过多模态信息和概念锚定映射进行调整，以实现更早、更可解释的安全监控。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能捕捉可疑意图的连续性质，限制了早期干预和可解释性。

Method: 提出SPAN网络，将可疑意图建模从离散分类转变为连续回归，并引入可疑系数调制（使用多模态信息调整可疑系数）和概念锚定映射（将可疑行为链接到意图概念）。

Result: 在HAI数据集上的实验表明，SPAN在MSE方面降低了19.8%，在平均mAP方面提高了1.78%，尤其在低频情况下提高了2.74%的mAP。

Conclusion: SPAN通过连续可疑分数和多模态调整，能够更早地检测到可疑行为，从而实现更早的干预和提高可解释性，在安全监控应用中具有很高的实用价值。

Abstract: Temporal Intention Localization (TIL) is crucial for video surveillance,
focusing on identifying varying levels of suspicious intentions to improve
security monitoring. However, existing discrete classification methods fail to
capture the continuous nature of suspicious intentions, limiting early
intervention and explainability. In this paper, we propose the Suspicion
Progression Analysis Network (SPAN), which shifts from discrete classification
to continuous regression, enabling the capture of fluctuating and evolving
suspicious intentions. We reveal that suspicion exhibits long-term dependencies
and cumulative effects, similar to Temporal Point Process (TPP) theory. Based
on these insights, we define a suspicion score formula that models continuous
changes while accounting for temporal characteristics. We also introduce
Suspicion Coefficient Modulation, which adjusts suspicion coefficients using
multimodal information to reflect the varying impacts of suspicious actions.
Additionally, the Concept-Anchored Mapping method is proposed to link
suspicious actions to predefined intention concepts, offering insights into
both the actions and their potential underlying intentions. Extensive
experiments on the HAI dataset show that SPAN significantly outperforms
existing methods, reducing MSE by 19.8% and improving average mAP by 1.78%.
Notably, SPAN achieves a 2.74% mAP gain in low-frequency cases, demonstrating
its superior ability to capture subtle behavioral changes. Compared to discrete
classification systems, our continuous suspicion modeling approach enables
earlier detection and proactive intervention, greatly enhancing system
explainability and practical utility in security applications.

</details>


### [27] [A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development](https://arxiv.org/abs/2510.20196)
*Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 公开的脑部MRI数据集存在规模、多样性和一致性方面的显著不平衡，并且预处理方法无法完全消除跨数据集的偏差，这对开发通用的脑部MRI基础模型提出了挑战。


<details>
  <summary>Details</summary>
Motivation: 评估现有公开脑部MRI数据集的规模、多样性和一致性，为基础模型开发提供指导，并强调需要开发更先进的预处理和领域自适应策略。

Method: 对54个公开脑部MRI数据集进行多层次分析，包括数据集层面（模态、疾病、规模）和图像层面（体素间距、方向、强度分布）。量化了15个代表性数据集的预处理（强度归一化、偏场校正、颅骨剥离、空间配准、插值）对体素统计和几何的影响。通过3D DenseNet121进行特征空间案例研究，评估标准化预处理后的残余协变量偏移。

Result: 大规模健康队列与小型临床队列之间存在显著不平衡。图像层面的体素间距、方向和强度分布存在显著异质性。预处理步骤虽然提高了数据集内的_一致性_，但未能完全消除数据集间的_残余差异_。特征空间案例研究表明，即使经过标准化预处理，仍存在残余协变量偏移，表明仅靠协调无法消除跨数据集的偏差。

Conclusion: 公开脑部MRI资源存在显著的变异性，强调在设计可泛化的脑部MRI基础模型时，需要采用_感知预处理_和_领域自适应_策略。

Abstract: The development of foundation models for brain MRI depends critically on the
scale, diversity, and consistency of available data, yet systematic assessments
of these factors remain scarce. In this study, we analyze 54 publicly
accessible brain MRI datasets encompassing over 538,031 to provide a
structured, multi-level overview tailored to foundation model development. At
the dataset level, we characterize modality composition, disease coverage, and
dataset scale, revealing strong imbalances between large healthy cohorts and
smaller clinical populations. At the image level, we quantify voxel spacing,
orientation, and intensity distributions across 15 representative datasets,
demonstrating substantial heterogeneity that can influence representation
learning. We then perform a quantitative evaluation of preprocessing
variability, examining how intensity normalization, bias field correction,
skull stripping, spatial registration, and interpolation alter voxel statistics
and geometry. While these steps improve within-dataset consistency, residual
differences persist between datasets. Finally, feature-space case study using a
3D DenseNet121 shows measurable residual covariate shift after standardized
preprocessing, confirming that harmonization alone cannot eliminate
inter-dataset bias. Together, these analyses provide a unified characterization
of variability in public brain MRI resources and emphasize the need for
preprocessing-aware and domain-adaptive strategies in the design of
generalizable brain MRI foundation models.

</details>


### [28] [RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling](https://arxiv.org/abs/2510.20206)
*Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu*

Main category: cs.CV

TL;DR: RAPO++是一个跨阶段提示优化框架，通过结合检索增强提示优化、样本特定提示优化和大型语言模型微调，在不修改生成模型的情况下显著提升文本到视频（T2V）生成效果。


<details>
  <summary>Details</summary>
Motivation: 用户提供的文本提示通常简短、无结构且与训练数据不匹配，限制了T2V生成模型的潜力。

Method: 该框架分三个阶段：1. 检索增强提示优化（RAPO）通过从关系图中检索相关修饰符来丰富和重构用户提示，以匹配训练数据分布。2. 样本特定提示优化（SSPO）是一个闭环机制，利用多源反馈（语义对齐、空间保真度、时间连贯性、光流等）迭代地优化提示。3. SSPO生成的优化提示对用于微调重写器LLM，使其能够高效生成高质量提示。

Result: 实验证明RAPO++在语义对齐、组合推理、时间稳定性和物理合理性方面取得了显著的提升，在五个T2V模型和五个基准测试中，性能大幅超越现有方法。

Conclusion: RAPO++是一种模型无关、成本效益高且可扩展的解决方案，为T2V生成中的提示优化设定了新标准。

Abstract: Prompt design plays a crucial role in text-to-video (T2V) generation, yet
user-provided prompts are often short, unstructured, and misaligned with
training data, limiting the generative potential of diffusion-based T2V models.
We present \textbf{RAPO++}, a cross-stage prompt optimization framework that
unifies training-data--aligned refinement, test-time iterative scaling, and
large language model (LLM) fine-tuning to substantially improve T2V generation
without modifying the underlying generative backbone. In \textbf{Stage 1},
Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with
semantically relevant modifiers retrieved from a relation graph and refactors
them to match training distributions, enhancing compositionality and
multi-object fidelity. \textbf{Stage 2} introduces Sample-Specific Prompt
Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts
using multi-source feedback -- including semantic alignment, spatial fidelity,
temporal coherence, and task-specific signals such as optical flow -- yielding
progressively improved video generation quality. \textbf{Stage 3} leverages
optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing
task-specific optimization patterns and enabling efficient, high-quality prompt
generation even before inference. Extensive experiments across five
state-of-the-art T2V models and five benchmarks demonstrate that RAPO++
achieves significant gains in semantic alignment, compositional reasoning,
temporal stability, and physical plausibility, outperforming existing methods
by large margins. Our results highlight RAPO++ as a model-agnostic,
cost-efficient, and scalable solution that sets a new standard for prompt
optimization in T2V generation. The code is available at
https://github.com/Vchitect/RAPO.

</details>


### [29] [FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing](https://arxiv.org/abs/2510.20212)
*Yanghao Wang,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 FlowCycle 的新颖的、无需反演的、基于流的文本图像编辑框架。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像的编辑方法在“损坏-恢复”范式中，其“中间状态”的构建方式是与目标无关的，这导致在进行大幅度编辑时，图像的编辑性和一致性会受到限制。

Method: FlowCycle 提出构建一个与目标相关的“中间状态”，通过参数化可学习噪声来实现损坏，并利用一个循环一致的过程来优化这些噪声。该框架通过以源图像为起点，编辑至目标图像，再通过双重一致性约束恢复回源图像，从而学习生成与目标相关的“中间状态”，以实现忠实的修改并保持源图像的一致性。

Result: 实验证明，FlowCycle 在编辑质量和一致性方面优于现有最先进的方法。

Conclusion: FlowCycle 通过构建与目标相关的“中间状态”，提高了文本到图像编辑的编辑性和一致性。

Abstract: Recent advances in pre-trained text-to-image flow models have enabled
remarkable progress in text-based image editing. Mainstream approaches always
adopt a corruption-then-restoration paradigm, where the source image is first
corrupted into an ``intermediate state'' and then restored to the target image
under the prompt guidance. However, current methods construct this intermediate
state in a target-agnostic manner, i.e., they primarily focus on realizing
source image reconstruction while neglecting the semantic gaps towards the
specific editing target. This design inherently results in limited editability
or inconsistency when the desired modifications substantially deviate from the
source. In this paper, we argue that the intermediate state should be
target-aware, i.e., selectively corrupting editing-relevant contents while
preserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel
inversion-free and flow-based editing framework that parameterizes corruption
with learnable noises and optimizes them through a cycle-consistent process. By
iteratively editing the source to the target and recovering back to the source
with dual consistency constraints, FlowCycle learns to produce a target-aware
intermediate state, enabling faithful modifications while preserving source
consistency. Extensive ablations have demonstrated that FlowCycle achieves
superior editing quality and consistency over state-of-the-art methods.

</details>


### [30] [Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection](https://arxiv.org/abs/2510.20214)
*Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad*

Main category: cs.CV

TL;DR: CURL是一种用于胎动检测的自监督学习框架，利用超声视频数据，通过时空对比学习来提取运动特征，并采用特殊的采样策略和微调方法，提高了胎动检测的准确性和客观性。


<details>
  <summary>Details</summary>
Motivation: 传统的胎动检测方法（如孕妇感知和心肺图）存在主观性和准确性不足的问题，需要更可靠的客观评估方法。

Method: 提出了一种名为CURL（Contrastive Ultrasound Video Representation Learning）的新型自监督学习框架，该框架利用双对比损失（空间和时间对比学习）来学习鲁棒的运动表征。此外，引入了特定的采样策略来区分运动和非运动片段，并采用概率微调方法实现对任意长度超声记录的灵活推断。

Result: 在包含92名受试者、每人30分钟的超声检查数据集上进行评估，CURL实现了78.01%的灵敏度和81.60%的AUROC。

Conclusion: 自监督对比学习在胎动分析方面具有巨大潜力，有望改善产前监护和临床决策。

Abstract: Accurate fetal movement (FM) detection is essential for assessing prenatal
health, as abnormal movement patterns can indicate underlying complications
such as placental dysfunction or fetal distress. Traditional methods, including
maternal perception and cardiotocography (CTG), suffer from subjectivity and
limited accuracy. To address these challenges, we propose Contrastive
Ultrasound Video Representation Learning (CURL), a novel self-supervised
learning framework for FM detection from extended fetal ultrasound video
recordings. Our approach leverages a dual-contrastive loss, incorporating both
spatial and temporal contrastive learning, to learn robust motion
representations. Additionally, we introduce a task-specific sampling strategy,
ensuring the effective separation of movement and non-movement segments during
self-supervised training, while enabling flexible inference on arbitrarily long
ultrasound recordings through a probabilistic fine-tuning approach. Evaluated
on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,
CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its
potential for reliable and objective FM analysis. These results highlight the
potential of self-supervised contrastive learning for fetal movement analysis,
paving the way for improved prenatal monitoring and clinical decision-making.

</details>


### [31] [EditInfinity: Image Editing with Binary-Quantized Generative Models](https://arxiv.org/abs/2510.20217)
*Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei*

Main category: cs.CV

TL;DR: 本研究提出了一种名为EditInfinity的参数高效模型，用于文本驱动的图像编辑，通过利用VQ模型的精确中间表示来克服扩散模型图像反演中的近似误差，实现了高保真度和语义精确性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本驱动图像编辑方法依赖于扩散模型，在图像反演过程中存在近似误差，限制了编辑性能。本研究旨在解决这一问题。

Method: 提出了一种名为EditInfinity的参数高效方法，该方法适配基于VQ的生成模型（Infinity），利用其可精确获取的中间量化表示进行图像编辑。该方法包括一个集成了文本提示校正和图像风格保持的图像反演机制，以及一个整体平滑策略，以实现高保真度和精确的语义对齐。

Result: 在PIE-Bench基准测试中，针对“添加”、“更改”和“删除”等编辑操作，EditInfinity在与最先进的基于扩散的模型进行比较时，表现出了优越的性能。

Conclusion: EditInfinity通过利用VQ模型的精确中间表示，成功克服了扩散模型在图像反演中的近似误差，实现了比现有基于扩散模型的方法更优越的文本驱动图像编辑性能，能够高保真地保留源图像特征并精确对齐文本提示。

Abstract: Adapting pretrained diffusion-based generative models for text-driven image
editing with negligible tuning overhead has demonstrated remarkable potential.
A classical adaptation paradigm, as followed by these methods, first infers the
generative trajectory inversely for a given source image by image inversion,
then performs image editing along the inferred trajectory guided by the target
text prompts. However, the performance of image editing is heavily limited by
the approximation errors introduced during image inversion by diffusion models,
which arise from the absence of exact supervision in the intermediate
generative steps. To circumvent this issue, we investigate the
parameter-efficient adaptation of VQ-based generative models for image editing,
and leverage their inherent characteristic that the exact intermediate
quantized representations of a source image are attainable, enabling more
effective supervision for precise image inversion. Specifically, we propose
\emph{EditInfinity}, which adapts \emph{Infinity}, a binary-quantized
generative model, for image editing. We propose an efficient yet effective
image inversion mechanism that integrates text prompting rectification and
image style preservation, enabling precise image inversion. Furthermore, we
devise a holistic smoothing strategy which allows our \emph{EditInfinity} to
perform image editing with high fidelity to source images and precise semantic
alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark
across "add", "change", and "delete" editing operations, demonstrate the
superior performance of our model compared to state-of-the-art diffusion-based
baselines. Code available at: https://github.com/yx-chen-ust/EditInfinity.

</details>


### [32] [Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation](https://arxiv.org/abs/2510.20549)
*Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy*

Main category: cs.CV

TL;DR: SELM-SLAM3是一个结合了SuperPoint和LightGlue的深度学习增强视觉SLAM框架，在低纹理、运动模糊和光照不佳等挑战性条件下表现优于ORB-SLAM3和现有的RGB-D SLAM系统，可用于开发视障辅助导航系统。


<details>
  <summary>Details</summary>
Motivation: 尽管SLAM技术有所进步，但在低纹理、运动模糊或光照不佳等挑战性条件下，其鲁棒性仍然是一个开放性挑战，这影响了导航的可靠性和安全性，尤其是在视障辅助导航等应用中。

Method: 提出了一种名为SELM-SLAM3的深度学习增强视觉SLAM框架，该框架集成了SuperPoint和LightGlue以实现鲁棒的特征提取和匹配。

Result: 在TUM RGB-D、ICL-NUIM和TartanAir数据集上的评估显示，SELM-SLAM3相比ORB-SLAM3平均性能提升了87.84%，相比现有的最先进的RGB-D SLAM系统性能提升了36.77%。

Conclusion: SELM-SLAM3在低纹理场景和快速运动等挑战性条件下展现出增强的性能，为开发视障辅助导航提供了可靠的平台。

Abstract: Despite advancements in SLAM technologies, robust operation under challenging
conditions such as low-texture, motion-blur, or challenging lighting remains an
open challenge. Such conditions are common in applications such as assistive
navigation for the visually impaired. These challenges undermine localization
accuracy and tracking stability, reducing navigation reliability and safety. To
overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced
visual SLAM framework that integrates SuperPoint and LightGlue for robust
feature extraction and matching. We evaluated our framework using TUM RGB-D,
ICL-NUIM, and TartanAir datasets, which feature diverse and challenging
scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of
87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework
demonstrates enhanced performance under challenging conditions, such as
low-texture scenes and fast motion, providing a reliable platform for
developing navigation aids for the visually impaired.

</details>


### [33] [Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context](https://arxiv.org/abs/2510.20229)
*Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）的幻觉问题并非仅仅由生成长度引起，而是与生成内容对上下文的依赖性有关。本研究提出了一个“诱导-检测-抑制”框架，通过故意设计上下文来诱导幻觉，并利用这些实例来检测高风险情况，最终在解码过程中抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在生成更长、自由格式的响应时容易出现幻觉，这通常被归因于不确定性的累积。本研究旨在探讨幻觉是否仅仅由长度引起，还是存在更深层次的机制。

Method: 提出了一种“诱导-检测-抑制”框架，该框架通过故意设计的上下文主动诱导幻觉，利用诱导产生的幻觉实例来早期检测高风险情况，并在实际解码过程中抑制潜在的物体级幻觉。

Result: 该方法在所有基准测试中都取得了持续且显著的改进，证明了其有效性。强大的检测能力和改进的幻觉缓解能力不仅验证了该框架，更重要的是，再次验证了关于上下文依赖性的假设。

Conclusion: 与仅仅追求性能提升不同，本研究旨在为理解LVLM在更长响应中的幻觉问题提供新的见解，并作为深入探索该问题的初步尝试。

Abstract: Large Vision-Language Models (LVLMs) have made significant progress in recent
years but are also prone to hallucination issues. They exhibit more
hallucinations in longer, free-form responses, often attributed to accumulated
uncertainties. In this paper, we ask: Does increased hallucination result
solely from length-induced errors, or is there a deeper underlying mechanism?
After a series of preliminary experiments and findings, we suggest that the
risk of hallucinations is not caused by length itself but by the increased
reliance on context for coherence and completeness in longer responses.
Building on these insights, we propose a novel "induce-detect-suppress"
framework that actively induces hallucinations through deliberately designed
contexts, leverages induced instances for early detection of high-risk cases,
and ultimately suppresses potential object-level hallucinations during actual
decoding. Our approach achieves consistent, significant improvements across all
benchmarks, demonstrating its efficacy. The strong detection and improved
hallucination mitigation not only validate our framework but, more importantly,
re-validate our hypothesis on context. Rather than solely pursuing performance
gains, this study aims to provide new insights and serves as a first step
toward a deeper exploration of hallucinations in LVLMs' longer responses.

</details>


### [34] [EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence](https://arxiv.org/abs/2510.20578)
*Ding Zou,Feifan Wang,Mengyu Ge,Siyuan Fan,Zongbing Zhang,Wei Chen,Lingfeng Wang,Zhongyou Hu,Wenrui Yan,Zhengwei Gao,Hao Wang,Weizhao Jin,Yu Zhang,Hainan Zhao,Mingliang Zhang,Xianxian Xi,Yaru Zhang,Wenyuan Li,Zhengguang Gao,Yurui Zhu*

Main category: cs.CV

TL;DR: EmbodiedBrain是一个新的视觉-语言基础模型，参数规模有7B和32B，解决了现有模型在具身任务中的局限性，例如模型设计与智能体需求之间的差距、实时延迟与性能之间的权衡以及评估指标的非真实性。通过采用智能体对齐的数据结构和结合监督微调（SFT）与步进增强组相对策略优化（Step-GRPO）的训练方法，并整合生成奖励模型（GRM）以提高训练效率，EmbodiedBrain在通用、规划和端到端模拟基准测试中取得了卓越的性能，确立了具身基础模型的新标杆。


<details>
  <summary>Details</summary>
Motivation: 当前用于具身任务的大型语言模型（LLMs）和多模态LLMs（MLLMs）存在模型设计与智能体需求之间差距、实时延迟与性能之间权衡以及使用非真实离线评估指标等关键局限性。为了实现通用人工智能（AGI）对具身AI智能体的需求，需要解决这些挑战。

Method: 提出EmbodiedBrain，一个包含7B和32B参数规模的新型视觉-语言基础模型。其特点是采用了智能体对齐的数据结构，并使用一种强大的训练方法，该方法结合了大规模监督微调（SFT）和步进增强组相对策略优化（Step-GRPO），通过将先前步骤整合为引导前体来提升长时任务的成功率。此外，还整合了一个全面的奖励系统，包括一个在基础设施层面加速的生成奖励模型（GRM），以提高训练效率。为实现彻底的验证，建立了一个包含通用、规划和端到端模拟基准测试的三部分评估系统，并提出了一个新颖且具有挑战性的模拟环境。

Result: 实验结果表明，EmbodiedBrain在所有指标上都取得了优越的性能，为具身基础模型树立了新的最先进水平。

Conclusion: EmbodiedBrain通过其创新的模型设计、训练方法和评估系统，解决了当前具身AI领域的关键挑战，并在各项基准测试中取得了优异的成果，为下一代通用具身智能体的研发铺平了道路。研究者们已开源了所有数据、模型权重和评估方法。

Abstract: The realization of Artificial General Intelligence (AGI) necessitates
Embodied AI agents capable of robust spatial perception, effective task
planning, and adaptive execution in physical environments. However, current
large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks
suffer from key limitations, including a significant gap between model design
and agent requirements, an unavoidable trade-off between real-time latency and
performance, and the use of unauthentic, offline evaluation metrics. To address
these challenges, we propose EmbodiedBrain, a novel vision-language foundation
model available in both 7B and 32B parameter sizes. Our framework features an
agent-aligned data structure and employs a powerful training methodology that
integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group
Relative Policy Optimization (Step-GRPO), which boosts long-horizon task
success by integrating preceding steps as Guided Precursors. Furthermore, we
incorporate a comprehensive reward system, including a Generative Reward Model
(GRM) accelerated at the infrastructure level, to improve training efficiency.
For enable thorough validation, we establish a three-part evaluation system
encompassing General, Planning, and End-to-End Simulation Benchmarks,
highlighted by the proposal and open-sourcing of a novel, challenging
simulation environment. Experimental results demonstrate that EmbodiedBrain
achieves superior performance across all metrics, establishing a new
state-of-the-art for embodied foundation models. Towards paving the way for the
next generation of generalist embodied agents, we open-source all of our data,
model weight, and evaluating methods, which are available at
https://zterobot.github.io/EmbodiedBrain.github.io.

</details>


### [35] [COS3D: Collaborative Open-Vocabulary 3D Segmentation](https://arxiv.org/abs/2510.20238)
*Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu*

Main category: cs.CV

TL;DR: COS3D是一个创新的开放词汇3D分割框架，通过引入协同场（包括实例场和语言场）来有效融合语言和分割线索，解决了现有方法分割效果不佳或误差累积的问题。该方法通过实例到语言特征映射和两阶段训练策略来构建协同场，并通过自适应语言到实例提示细化来实现高质量的推理。实验证明COS3D在基准测试中表现优异，并可应用于多种场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯泼溅的方法在开放词汇3D分割任务中存在不足：单一3D语言场导致分割效果不佳，或依赖预先计算的类别不可知分割导致误差累积。COS3D旨在解决这些限制。

Method: COS3D提出了协同场（collaborative field），包含实例场（instance field）和语言场（language field）。在训练阶段，通过实例到语言特征映射和两阶段训练策略来捕捉两个场之间的内在联系。在推理阶段，通过自适应语言到实例提示细化（adaptive language-to-instance prompt refinement）来弥合两个场的差异，实现高质量的分割。

Result: COS3D在两个广泛使用的基准测试中展现了领先于现有方法的性能，并且在基于图像的3D分割、分层分割和机器人等应用中显示出巨大潜力。

Conclusion: COS3D通过其创新的协同场和训练/推理策略，成功解决了开放词汇3D分割中的挑战，并在多个实验中取得了优越的性能和广泛的应用前景。

Abstract: Open-vocabulary 3D segmentation is a fundamental yet challenging task,
requiring a mutual understanding of both segmentation and language. However,
existing Gaussian-splatting-based methods rely either on a single 3D language
field, leading to inferior segmentation, or on pre-computed class-agnostic
segmentations, suffering from error accumulation. To address these limitations,
we present COS3D, a new collaborative prompt-segmentation framework that
contributes to effectively integrating complementary language and segmentation
cues throughout its entire pipeline. We first introduce the new concept of
collaborative field, comprising an instance field and a language field, as the
cornerstone for collaboration. During training, to effectively construct the
collaborative field, our key idea is to capture the intrinsic relationship
between the instance field and language field, through a novel
instance-to-language feature mapping and designing an efficient two-stage
training strategy. During inference, to bridge distinct characteristics of the
two fields, we further design an adaptive language-to-instance prompt
refinement, promoting high-quality prompt-segmentation inference. Extensive
experiments not only demonstrate COS3D's leading performance over existing
methods on two widely-used benchmarks but also show its high potential to
various applications,~\ie, novel image-based 3D segmentation, hierarchical
segmentation, and robotics. The code is publicly available at
\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.

</details>


### [36] [ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata](https://arxiv.org/abs/2510.20708)
*Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera*

Main category: cs.CV

TL;DR: ALICE-LRI是一种自动、传感器无关的方法，可以从激光雷达点云生成无损的2D范围图像，无需制造商元数据或校准文件，从而实现精确的点云重建。


<details>
  <summary>Details</summary>
Motivation: 传统的激光雷达点云投影到2D范围图像的方法存在几何不一致性，导致信息丢失，影响高精度应用。需要一种能够实现无损投影并完整重建点云的方法。

Method: ALICE-LRI算法通过推断激光束配置、角度分布和每束校正等关键参数，自动逆向工程任何旋转激光雷达传感器的内在几何结构，从而实现无损投影。

Result: ALICE-LRI在KITTI和DurLAR数据集上的评估表明，该方法实现了完美的点保留（零点丢失），几何精度保持在传感器精度范围内，并具有实时性能。此外，压缩案例研究表明了其在实际应用中的显著优势。

Conclusion: ALICE-LRI实现了从近似到无损激光雷达投影的范式转变，为需要完整几何保持的高精度遥感应用开辟了新的可能性。

Abstract: 3D LiDAR sensors are essential for autonomous navigation, environmental
monitoring, and precision mapping in remote sensing applications. To
efficiently process the massive point clouds generated by these sensors, LiDAR
data is often projected into 2D range images that organize points by their
angular positions and distances. While these range image representations enable
efficient processing, conventional projection methods suffer from fundamental
geometric inconsistencies that cause irreversible information loss,
compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR
Intrinsic Calibration Estimation for Lossless Range Images), the first general,
sensor-agnostic method that achieves lossless range image generation from
spinning LiDAR point clouds without requiring manufacturer metadata or
calibration files. Our algorithm automatically reverse-engineers the intrinsic
geometry of any spinning LiDAR sensor by inferring critical parameters
including laser beam configuration, angular distributions, and per-beam
calibration corrections, enabling lossless projection and complete point cloud
reconstruction with zero point loss. Comprehensive evaluation across the
complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect
point preservation, with zero points lost across all point clouds. Geometric
accuracy is maintained well within sensor precision limits, establishing
geometric losslessness with real-time performance. We also present a
compression case study that validates substantial downstream benefits,
demonstrating significant quality improvements in practical applications. This
paradigm shift from approximate to lossless LiDAR projections opens new
possibilities for high-precision remote sensing applications requiring complete
geometric preservation.

</details>


### [37] [Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding](https://arxiv.org/abs/2510.20244)
*Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee*

Main category: cs.CV

TL;DR: 现有方法在视频时间定位任务中忽略了不同文本标记的语义作用，导致模型过度依赖全局语义而无法有效利用单词级信号。我们提出了一种名为DualGround的双分支架构，通过分离全局和局部语义来解决这个问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时间定位（VTG）方法在处理文本查询时，通常同等地对待所有文本标记，忽视了它们各自的语义角色。这导致模型过度依赖句末标记（[EOS]）驱动的全局语义，而未能有效利用单词级信号，从而限制了模型在细粒度时间对齐方面的能力。

Method: 提出了一种名为DualGround的双分支架构，该架构明确分离全局和局部语义。具体来说，将[EOS]标记通过一个句子级路径进行处理，并将单词标记聚类成短语级单元，用于局部定位。该方法引入了（1）标记角色感知跨模态交互策略，以结构化解耦的方式将视频特征与句子级和短语级语义对齐；（2）联合建模框架，通过利用结构化的短语感知上下文，不仅提高了全局句子级对齐，还增强了细粒度时间定位。

Result: DualGround在QVHighlights和Charades-STA基准测试的视频时间定位的两个子任务（时刻检索和高亮检测）上均取得了最先进的性能。

Conclusion: 通过将全局和局部语义进行解耦建模，DualGround有效地提升了视频-语言对齐的表达能力和上下文感知能力，证明了这种方法的有效性。

Abstract: Video Temporal Grounding (VTG) aims to localize temporal segments in long,
untrimmed videos that align with a given natural language query. This task
typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection
(HD). While recent advances have been progressed by powerful pretrained
vision-language models such as CLIP and InternVideo2, existing approaches
commonly treat all text tokens uniformly during crossmodal attention,
disregarding their distinct semantic roles. To validate the limitations of this
approach, we conduct controlled experiments demonstrating that VTG models
overly rely on [EOS]-driven global semantics while failing to effectively
utilize word-level signals, which limits their ability to achieve fine-grained
temporal alignment. Motivated by this limitation, we propose DualGround, a
dual-branch architecture that explicitly separates global and local semantics
by routing the [EOS] token through a sentence-level path and clustering word
tokens into phrase-level units for localized grounding. Our method introduces
(1) tokenrole- aware cross modal interaction strategies that align video
features with sentence-level and phrase-level semantics in a structurally
disentangled manner, and (2) a joint modeling framework that not only improves
global sentence-level alignment but also enhances finegrained temporal
grounding by leveraging structured phrase-aware context. This design allows the
model to capture both coarse and localized semantics, enabling more expressive
and context-aware video grounding. DualGround achieves state-of-the-art
performance on both Moment Retrieval and Highlight Detection tasks across
QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of
disentangled semantic modeling in video-language alignment.

</details>


### [38] [Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization](https://arxiv.org/abs/2510.20247)
*Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu*

Main category: cs.CV

TL;DR: 提出一种新的掩码-based positional encoding 方法，并结合上下文增强模块，用于提高跨视图物体地理定位的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖基于关键点的编码，只考虑2D坐标忽略物体形状，导致对标注偏移敏感且跨视图匹配能力有限。同时，卫星图像中的大跨度物体（如长条形建筑）也带来了挑战。

Method: 提出一种掩码-based positional encoding 方案，利用分割掩码同时捕获空间坐标和物体轮廓，使模型从“位置感知”升级为“物体感知”。设计了一个上下文增强模块，采用水平和垂直条状卷积核提取长距离上下文特征，增强条状物体间的特征辨别力。将两者结合，提出EDGeo框架。

Result: 在CVOGL和VIGOR-Building两个公开数据集上进行了大量实验，证明该方法在最具挑战性的地面试图到卫星视图场景下，定位精度提高了3.39%，达到了最先进的性能。

Conclusion: 该研究为推动跨视图地理定位研究提供了一个鲁棒的位置编码范式和上下文建模框架。

Abstract: Cross-view object geo-localization enables high-precision object localization
through cross-view matching, with critical applications in autonomous driving,
urban management, and disaster response. However, existing methods rely on
keypoint-based positional encoding, which captures only 2D coordinates while
neglecting object shape information, resulting in sensitivity to annotation
shifts and limited cross-view matching capability. To address these
limitations, we propose a mask-based positional encoding scheme that leverages
segmentation masks to capture both spatial coordinates and object silhouettes,
thereby upgrading the model from "location-aware" to "object-aware."
Furthermore, to tackle the challenge of large-span objects (e.g., elongated
buildings) in satellite imagery, we design a context enhancement module. This
module employs horizontal and vertical strip convolutional kernels to extract
long-range contextual features, enhancing feature discrimination among
strip-like objects. Integrating MPE and CEM, we present EDGeo, an end-to-end
framework for robust cross-view object geo-localization. Extensive experiments
on two public datasets (CVOGL and VIGOR-Building) demonstrate that our method
achieves state-of-the-art performance, with a 3.39% improvement in localization
accuracy under challenging ground-to-satellite scenarios. This work provides a
robust positional encoding paradigm and a contextual modeling framework for
advancing cross-view geo-localization research.

</details>


### [39] [Calibrating Multimodal Consensus for Emotion Recognition](https://arxiv.org/abs/2510.20256)
*Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan*

Main category: cs.CV

TL;DR: 该研究提出了CMC模型，通过伪标签生成和参数无关的融合策略来解决多模态情感识别中模态间语义不一致和文本模态主导的问题，并在多个数据集上取得了SOTA或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分解决多模态情感识别（MER）中出现的跨模态（如文本和视觉输入之间的情感线索冲突）语义不一致问题，并且常常受到文本模态的过度主导，影响了识别准确性。

Method: 提出了一种名为CMC（Calibrated Multimodal Consensus）的模型。CMC包含一个伪标签生成模块（PLGM），用于生成伪单模态标签，实现单模态的自监督预训练。随后，利用参数无关融合模块（PFM）和多模态共识路由（MCR）进行多模态微调，以减轻文本主导并引导融合过程达成更可靠的一致性。

Result: 在CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI四个数据集上，CMC取得了与最先进方法相当或更优的性能。尤其在CH-SIMS和CH-SIMS v2数据集的语义不一致场景下，CMC表现出显著优势。

Conclusion: CMC模型有效地解决了多模态情感识别中的模态间语义不一致和文本模态主导问题，并在多个数据集上取得了优异的性能，证明了其在处理复杂多模态情感信息方面的有效性。

Abstract: In recent years, Multimodal Emotion Recognition (MER) has made substantial
progress. Nevertheless, most existing approaches neglect the semantic
inconsistencies that may arise across modalities, such as conflicting emotional
cues between text and visual inputs. Besides, current methods are often
dominated by the text modality due to its strong representational capacity,
which can compromise recognition accuracy. To address these challenges, we
propose a model termed Calibrated Multimodal Consensus (CMC). CMC introduces a
Pseudo Label Generation Module (PLGM) to produce pseudo unimodal labels,
enabling unimodal pretraining in a self-supervised fashion. It then employs a
Parameter-free Fusion Module (PFM) and a Multimodal Consensus Router (MCR) for
multimodal finetuning, thereby mitigating text dominance and guiding the fusion
process toward a more reliable consensus. Experimental results demonstrate that
CMC achieves performance on par with or superior to state-of-the-art methods
across four datasets, CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, and
exhibits notable advantages in scenarios with semantic inconsistencies on
CH-SIMS and CH-SIMS v2. The implementation of this work is publicly accessible
at https://github.com/gw-zhong/CMC.

</details>


### [40] [Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals](https://arxiv.org/abs/2510.20267)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.CV

TL;DR: 该研究提出了一种实时货币识别系统，利用带有改进型检测头的YOLOv8 nano模型，可以识别美元、欧元和孟加拉塔卡，以帮助视障人士独立处理货币。


<details>
  <summary>Details</summary>
Motivation: 为视障人士提供一种便捷的工具，帮助他们独立处理日常货币识别任务。

Method: 使用YOLOv8 nano模型，并结合了深度卷积层和Squeeze-and-Excitation块的自定义检测头，对包含30类货币（美元、欧元、孟加拉塔卡）的数据集进行训练。

Result: 在测试中，该模型达到了97.73%的准确率、95.23%的召回率、95.85%的F1分数和97.21%的mAP50(B)指标，并能通过语音反馈提供识别结果。

Conclusion: 该研究成功开发了一个高效实用的货币识别系统，通过语音反馈赋能视障人士，提高他们在货币处理方面的独立性。

Abstract: Technologies like smartphones have become an essential in our daily lives. It
has made accessible to everyone including visually impaired individuals. With
the use of smartphone cameras, image capturing and processing have become more
convenient. With the use of smartphones and machine learning, the life of
visually impaired can be made a little easier. Daily tasks such as handling
money without relying on someone can be troublesome for them. For that purpose
this paper presents a real-time currency detection system designed to assist
visually impaired individuals. The proposed model is trained on a dataset
containing 30 classes of notes and coins, representing 3 types of currency: US
dollar (USD), Euro (EUR), and Bangladeshi taka (BDT). Our approach uses a
YOLOv8 nano model with a custom detection head featuring deep convolutional
layers and Squeeze-and-Excitation blocks to enhance feature extraction and
detection accuracy. Our model has achieved a higher accuracy of 97.73%, recall
of 95.23%, f1-score of 95.85% and a mean Average Precision at IoU=0.5
(mAP50(B)) of 97.21\%. Using the voice feedback after the detection would help
the visually impaired to identify the currency. This paper aims to create a
practical and efficient currency detection system to empower visually impaired
individuals independent in handling money.

</details>


### [41] [GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection](https://arxiv.org/abs/2510.20268)
*Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GMFVAD的视频异常检测方法，通过利用多模态信息的差异性来精炼特征，减少冗余，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频异常检测方法在利用时空相关性或简单引入文本特征时，可能存在信息冗余的问题。本研究旨在通过利用多模态信息的差异性来解决这一问题，进一步优化特征提取。

Method: 提出了一种名为GMFVAD（Grained Multi-modal Feature for Video Anomaly Detection）的方法。该方法首先生成更细粒度的多模态特征来概括视频片段的 Mian 内容，然后引入基于视频原始标题的文本特征，以进一步增强视频中突出部分的视觉特征。

Result: GMFVAD 在四个主要数据集上实现了最先进的性能。消融实验也验证了 GMFVAD 的改进效果源于冗余信息的减少。

Conclusion: GMFVAD 通过利用多模态信息之间的差异性，有效减少了视觉特征的冗余，从而提高了视频异常检测的性能。

Abstract: Video anomaly detection (VAD) is a challenging task that detects anomalous
frames in continuous surveillance videos. Most previous work utilizes the
spatio-temporal correlation of visual features to distinguish whether there are
abnormalities in video snippets. Recently, some works attempt to introduce
multi-modal information, like text feature, to enhance the results of video
anomaly detection. However, these works merely incorporate text features into
video snippets in a coarse manner, overlooking the significant amount of
redundant information that may exist within the video snippets. Therefore, we
propose to leverage the diversity among multi-modal information to further
refine the extracted features, reducing the redundancy in visual features, and
we propose Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD).
Specifically, we generate more grained multi-modal feature based on the video
snippet, which summarizes the main content, and text features based on the
captions of original video will be introduced to further enhance the visual
features of highlighted portions. Experiments show that the proposed GMFVAD
achieves state-of-the-art performance on four mainly datasets. Ablation
experiments also validate that the improvement of GMFVAD is due to the
reduction of redundant information.

</details>


### [42] [Causal Debiasing for Visual Commonsense Reasoning](https://arxiv.org/abs/2510.20281)
*Jiayi Zou,Gengyun Jia,Bing-Kun Bao*

Main category: cs.CV

TL;DR: 现有视觉常识推理方法在提高预测准确性的同时，往往忽略了数据中的偏见并且缺乏相应的消除偏见策略。本文通过分析揭示了文本和视觉数据中存在的共现偏见和统计偏见，并引入了VCR-OOD数据集来评估模型在跨模态下的泛化能力。此外，本文还分析了VCR中的因果图和预测捷径，并采用后门调整方法来消除偏见，通过创建一个基于正确答案集合的字典来消除预测捷径。实验证明了所提出的消除偏见方法在不同数据集上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉常识推理方法在提高预测准确性的同时，往往忽略了数据中的偏见并且缺乏相应的消除偏见策略。

Method: 通过分析揭示了文本和视觉数据中存在的共现偏见和统计偏见，引入了VCR-OOD数据集来评估模型在跨模态下的泛化能力，分析了VCR中的因果图和预测捷径，并采用后门调整方法来消除偏见，通过创建一个基于正确答案集合的字典来消除预测捷径。

Result: 实验证明了所提出的消除偏见方法在不同数据集上的有效性。

Conclusion: 现有视觉常识推理方法在提高预测准确性的同时，往往忽略了数据中的偏见并且缺乏相应的消除偏见策略。本文通过分析揭示了文本和视觉数据中存在的共现偏见和统计偏见，并引入了VCR-OOD数据集来评估模型在跨模态下的泛化能力。此外，本文还分析了VCR中的因果图和预测捷径，并采用后门调整方法来消除偏见，通过创建一个基于正确答案集合的字典来消除预测捷径。实验证明了所提出的消除偏见方法在不同数据集上的有效性。

Abstract: Visual Commonsense Reasoning (VCR) refers to answering questions and
providing explanations based on images. While existing methods achieve high
prediction accuracy, they often overlook bias in datasets and lack debiasing
strategies. In this paper, our analysis reveals co-occurrence and statistical
biases in both textual and visual data. We introduce the VCR-OOD datasets,
comprising VCR-OOD-QA and VCR-OOD-VA subsets, which are designed to evaluate
the generalization capabilities of models across two modalities. Furthermore,
we analyze the causal graphs and prediction shortcuts in VCR and adopt a
backdoor adjustment method to remove bias. Specifically, we create a dictionary
based on the set of correct answers to eliminate prediction shortcuts.
Experiments demonstrate the effectiveness of our debiasing method across
different datasets.

</details>


### [43] [Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition](https://arxiv.org/abs/2510.20284)
*Haodong Yang,Zhongling Huang,Shaojie Guo,Zhe Zhang,Gong Cheng,Junwei Han*

Main category: cs.CV

TL;DR: KINN是一个轻量级的框架，通过结合物理先验和深度学习，解决了复杂值SAR图像识别中的泛化性、可解释性和效率的困境，在数据有限和领域迁移的情况下取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在数据有限和领域迁移的情况下，在泛化性、可解释性和效率之间存在制约。CV-SAR数据中固有的电磁散射特征可以解决这一困境，但传统模型未能充分利用。

Method: 提出了一种名为KINN（Knowledge-Informed Neural Network）的轻量级框架，采用“压缩-聚合-压缩”架构。首先通过物理引导的压缩，利用字典处理器嵌入物理先验，然后通过聚合模块丰富表示，最后通过带有自蒸馏的分类头进行语义压缩。

Result: KINN在五个SAR基准测试中取得了最先进的参数高效识别效果，在数据稀疏和分布外场景下具有出色的泛化能力和可解释性。

Conclusion: KINN框架有效解决了SAR图像识别中的表示困境，为可信赖的AI在SAR图像分析领域开辟了新路径。

Abstract: Deep learning models for complex-valued Synthetic Aperture Radar (CV-SAR)
image recognition are fundamentally constrained by a representation trilemma
under data-limited and domain-shift scenarios: the concurrent, yet conflicting,
optimization of generalization, interpretability, and efficiency. Our work is
motivated by the premise that the rich electromagnetic scattering features
inherent in CV-SAR data hold the key to resolving this trilemma, yet they are
insufficiently harnessed by conventional data-driven models. To this end, we
introduce the Knowledge-Informed Neural Network (KINN), a lightweight framework
built upon a novel "compression-aggregation-compression" architecture. The
first stage performs a physics-guided compression, wherein a novel dictionary
processor adaptively embeds physical priors, enabling a compact unfolding
network to efficiently extract sparse, physically-grounded signatures. A
subsequent aggregation module enriches these representations, followed by a
final semantic compression stage that utilizes a compact classification head
with self-distillation to learn maximally task-relevant and discriminative
embeddings. We instantiate KINN in both CNN (0.7M) and Vision Transformer
(0.95M) variants. Extensive evaluations on five SAR benchmarks confirm that
KINN establishes a state-of-the-art in parameter-efficient recognition,
offering exceptional generalization in data-scarce and out-of-distribution
scenarios and tangible interpretability, thereby providing an effective
solution to the representation trilemma and offering a new path for trustworthy
AI in SAR image analysis.

</details>


### [44] [SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial Feature Learning](https://arxiv.org/abs/2402.01555)
*Samuel Adebayo,Joost C. Dessing,Seán McLoone*

Main category: cs.CV

TL;DR: SLYKLatent通过自监督学习和特定的网络结构解决注视估计中的不稳定性问题，并在多个基准数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的注视估计方法在处理数据集中的外观不稳定性（由偶然不确定性、协变偏移和测试域泛化引起）时面临挑战。

Method: SLYKLatent首先使用面部表情数据集进行自监督学习，然后采用一个基于块的三分支网络和一个反向解释方差加权训练损失函数进行优化。

Result: 在Gaze360上提高了10.9%，在MPIIFaceGaze上超越了现有最佳结果3.8%，在ETH-XGaze子集上领先11.6%。在RAF-DB和Affectnet上的准确率分别为86.4%和60.9%。消融研究证实了其组件的有效性。

Conclusion: SLYKLatent能够有效提升注视估计的准确性，并具备良好的泛化能力。

Abstract: In this research, we present SLYKLatent, a novel approach for enhancing gaze
estimation by addressing appearance instability challenges in datasets due to
aleatoric uncertainties, covariant shifts, and test domain generalization.
SLYKLatent utilizes Self-Supervised Learning for initial training with facial
expression datasets, followed by refinement with a patch-based tri-branch
network and an inverse explained variance-weighted training loss function. Our
evaluation on benchmark datasets achieves a 10.9% improvement on Gaze360,
supersedes top MPIIFaceGaze results with 3.8%, and leads on a subset of
ETH-XGaze by 11.6%, surpassing existing methods by significant margins.
Adaptability tests on RAF-DB and Affectnet show 86.4% and 60.9% accuracies,
respectively. Ablation studies confirm the effectiveness of SLYKLatent's novel
components.

</details>


### [45] [DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering](https://arxiv.org/abs/2510.20285)
*Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DMC³的双模态反事实对比学习框架，用于解决第一人称视频问答中的独特挑战，如多事件理解和手物交互识别。


<details>
  <summary>Details</summary>
Motivation: 现有方法在第一人称视频问答方面存在不足，忽略了第一人称视角带来的理解多事件和识别手物交互等独特挑战。

Method: 提出DMC³框架，包含一个基线模型、一个反事实样本构建模块（通过事件描述释义和核心交互挖掘生成正负样本）和一个涉及反事实样本的对比优化模块（通过对比损失使原始样本与正样本特征距离最小化，与负样本距离最大化）。

Result: 在EgoTaskQA的normal和indirect划分上分别达到52.51%和46.04%的准确率，在QAEGO4D上达到13.2%的准确率，均达到当前最先进水平。

Conclusion: DMC³框架通过构建和利用反事实样本，有效解决了第一人称视频问答中的挑战，并在多个基准测试中取得了领先的性能。

Abstract: Egocentric Video Question Answering (Egocentric VideoQA) plays an important
role in egocentric video understanding, which refers to answering questions
based on first-person videos. Although existing methods have made progress
through the paradigm of pre-training and fine-tuning, they ignore the unique
challenges posed by the first-person perspective, such as understanding
multiple events and recognizing hand-object interactions. To deal with these
challenges, we propose a Dual-Modal Counterfactual Contrastive Construction
(DMC$^3$) framework, which contains an egocentric videoqa baseline, a
counterfactual sample construction module and a counterfactual sample-involved
contrastive optimization. Specifically, We first develop a counterfactual
sample construction module to generate positive and negative samples for
textual and visual modalities through event description paraphrasing and core
interaction mining, respectively. Then, We feed these samples together with the
original samples into the baseline. Finally, in the counterfactual
sample-involved contrastive optimization module, we apply contrastive loss to
minimize the distance between the original sample features and the positive
sample features, while maximizing the distance from the negative samples.
Experiments show that our method achieve 52.51\% and 46.04\% on the
\textit{normal} and \textit{indirect} splits of EgoTaskQA, and 13.2\% on
QAEGO4D, both reaching the state-of-the-art performance.

</details>


### [46] [UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning](https://arxiv.org/abs/2510.20286)
*Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi*

Main category: cs.CV

TL;DR: 本研究提出了一种新的GUI基础模型训练范式，通过利用指令的多样性和质量来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 以往的GUI基础模型研究主要将指令视为用户意图的静态代理，忽视了指令多样性和质量对模型性能的影响。本研究旨在解决这一问题，并提升GUI基础模型的性能。

Method: 本研究提出了一种名为“指令即推理”的新范式，将指令视为动态的分析路径，使模型能够在推理过程中选择最有效的路径。为此，研究人员设计了一个两阶段的训练框架：首先，使用合成的、多样化的指令进行监督微调（SFT），以培养多视角推理能力；然后，进行强化学习（RL）以优化路径选择和组合。

Result: 研究人员开发的UI-Ins-7B和UI-Ins-32B模型在五个具有挑战性的GUI基础任务基准上取得了最先进的成果。UI-Ins-32B在UI-I2E-Bench、ScreenSpot-Pro和MMBench-GUI L2上的准确率分别为87.3%、57.0%和84.9%。此外，UI-Ins-7B在AndroidWorld上实现了74.1%的成功率，展现出强大的智能体潜力。研究还深入分析了推理如何增强基础性能，以及该方法如何缓解SFT+RL框架中的策略崩溃问题。

Conclusion: 本研究提出的“指令即推理”范式通过利用指令的多样性和质量，显著提升了GUI基础模型的性能，并在多个基准测试中取得了最先进的成果，同时展现了其作为智能体的潜力。

Abstract: GUI grounding, which maps natural-language instructions to actionable UI
elements, is a core capability of GUI agents. Prior works largely treats
instructions as a static proxy for user intent, overlooking the impact of
instruction diversity and quality on grounding performance. Through a careful
investigation of existing grounding datasets, we find a 23.3% flaw rate in
their instructions and show that inference-time exploitation of instruction
diversity yields up to a substantial 76% relative performance improvement. In
this paper, we introduce the Instruction-as-Reasoning paradigm, treating
instructions as dynamic analytical pathways that offer distinct perspectives
and enabling the model to select the most effective pathway during reasoning.
To achieve this, we propose a two-stage training framework: supervised
fine-tuning (SFT) on synthesized, diverse instructions to instill
multi-perspective reasoning, followed by reinforcement learning (RL) to
optimize pathway selection and composition. Our resulting models, UI-Ins-7B and
UI-Ins-32B, achieve state-of-the-art results on five challenging grounding
benchmarks and exhibit emergent reasoning, selectively composing and
synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B
attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on
ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model
demonstrates strong agentic potential, achieving a 74.1% success rate on
AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals
additional insights such as how reasoning can be formulated to enhance rather
than hinder grounding performance, and how our method mitigates policy collapse
in the SFT+RL framework. All code and model checkpoints will be publicly
released in https://github.com/alibaba/UI-Ins.

</details>


### [47] [Breakdance Video classification in the age of Generative AI](https://arxiv.org/abs/2510.20287)
*Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson*

Main category: cs.CV

TL;DR: 大型视觉语言模型在体育领域应用广泛，但多集中于热门运动。本研究探索了这些模型在小众但流行的霹雳舞领域的适用性。研究表明，视频编码器模型在预测任务上优于最先进的视频语言模型。我们提供了选择编码器模型的见解，并深入分析了针对霹雳舞视频分类进行微调的解码器模型的工作原理。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在体育领域应用广泛，但多数研究集中于足球、篮球等热门运动，并侧重于视觉问答、精彩集锦生成等任务。本研究旨在分析现代视频基础模型（包括编码器和解码器）在小众但非常受欢迎的霹雳舞运动中的适用性。

Method: 分析了大型视觉语言模型在霹雳舞视频上的表现，对比了视频编码器模型和视频语言模型在预测任务上的性能，并对微调后的解码器模型在霹雳舞视频分类任务上的工作原理进行了深入分析。

Result: 研究结果表明，视频编码器模型在预测任务上持续优于最先进的视频语言模型。研究为如何选择编码器模型提供了见解，并对微调后的解码器模型在霹雳舞视频分类任务上的工作原理进行了详尽的分析。

Conclusion: 视频编码器模型在霹雳舞预测任务上表现优于视频语言模型。本研究为选择合适的模型提供了指导，并对解码器模型在霹雳舞视频分类中的应用进行了深入探讨。

Abstract: Large Vision Language models have seen huge application in several sports
use-cases recently. Most of these works have been targeted towards a limited
subset of popular sports like soccer, cricket, basketball etc; focusing on
generative tasks like visual question answering, highlight generation. This
work analyzes the applicability of the modern video foundation models (both
encoder and decoder) for a very niche but hugely popular dance sports -
breakdance. Our results show that Video Encoder models continue to outperform
state-of-the-art Video Language Models for prediction tasks. We provide
insights on how to choose the encoder model and provide a thorough analysis
into the workings of a finetuned decoder model for breakdance video
classification.

</details>


### [48] [A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization](https://arxiv.org/abs/2510.20291)
*LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 我们提出了一个创新的解决方案，用于RoboSense 2025 Track 4跨模态无人机导航任务，该任务旨在根据自然语言查询从大型多平台语料库中检索最相关的地理参考图像。


<details>
  <summary>Details</summary>
Motivation: 该任务面临两大挑战：平台间的异构性以及通用训练描述与平台特定测试查询之间的领域差距。

Method: 为了克服这些挑战，我们设计了一个领域对齐的预处理流程和一个混合专家（MoE）框架，包括：1. 平台分区、卫星增强和移除方向词；2. 基于LLM的标题优化流程，使文本语义与各平台的独特视觉特征对齐。我们使用BGE-M3（文本）和EVA-CLIP（图像）模型，并通过渐进式两阶段、难负例挖掘策略训练三个平台专家，以增强区分能力，并在推理时融合它们的得分。

Result: 我们的系统在官方排行榜上名列前茅，展示了在异构视角下强大的跨模态地理定位能力。

Conclusion: 该解决方案成功解决了跨模态无人机导航任务中的关键挑战，并在实际应用中取得了领先的性能。

Abstract: We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone
Navigation. The task retrieves the most relevant geo-referenced image from a
large multi-platform corpus (satellite/drone/ground) given a natural-language
query. Two obstacles are severe inter-platform heterogeneity and a domain gap
between generic training descriptions and platform-specific test queries. We
mitigate these with a domain-aligned preprocessing pipeline and a
Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite
augmentation, and removal of orientation words; (ii) an LLM-based caption
refinement pipeline to align textual semantics with the distinct visual
characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we
train three platform experts using a progressive two-stage, hard-negative
mining strategy to enhance discriminative power, and fuse their scores at
inference. The system tops the official leaderboard, demonstrating robust
cross-modal geo-localization under heterogeneous viewpoints.

</details>


### [49] [HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models](https://arxiv.org/abs/2510.20322)
*Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 通过使用双曲空间来提高多模态大语言模型的训练效率，该模型能够以更少的计算资源在不同粒度级别上实现视觉和文本的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在训练时需要大量的计算资源，主要原因是其视觉编码器（如CLIP和SAM）缺乏多粒度级别的语言对齐。

Method: 提出了一种名为HyperET的高效训练范式，利用双曲空间及其固有的层级结构特性，通过动态调整双曲半径来优化视觉表示，使其能在任意粒度级别上与文本对应物对齐。HyperET使用可学习矩阵和Möbius乘法操作，并支持对角缩放矩阵、块对角矩阵和带状矩阵等三种配置。

Result: 在多个多模态大语言模型基准测试中的广泛实验表明，HyperET在不增加过多参数量（少于1%）的情况下，能够显著提升现有预训练和微调模型的效果。

Conclusion: HyperET通过引入双曲空间提供了一种有效的解决方案，可以显著提高多模态大语言模型的训练效率和跨模态对齐能力，且计算成本低。

Abstract: Multi-modal large language models (MLLMs) have emerged as a transformative
approach for aligning visual and textual understanding. They typically require
extremely high computational resources (e.g., thousands of GPUs) for training
to achieve cross-modal alignment at multi-granularity levels. We argue that a
key source of this inefficiency lies in the vision encoders they widely equip
with, e.g., CLIP and SAM, which lack the alignment with language at
multi-granularity levels. To address this issue, in this paper, we leverage
hyperbolic space, which inherently models hierarchical levels and thus provides
a principled framework for bridging the granularity gap between visual and
textual modalities at an arbitrary granularity level. Concretely, we propose an
efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize
visual representations to align with their textual counterparts at an arbitrary
granularity level through dynamic hyperbolic radius adjustment in hyperbolic
space. HyperET employs learnable matrices with M\"{o}bius multiplication
operations, implemented via three effective configurations: diagonal scaling
matrices, block-diagonal matrices, and banded matrices, providing a flexible
yet efficient parametrization strategy. Comprehensive experiments across
multiple MLLM benchmarks demonstrate that HyperET consistently improves both
existing pre-training and fine-tuning MLLMs clearly with less than 1\%
additional parameters.

</details>


### [50] [AnyPcc: Compressing Any Point Cloud with a Single Universal Model](https://arxiv.org/abs/2510.20331)
*Kangli Wang,Qianxi Yi,Yuqi Ye,Shihao Li,Wei Gao*

Main category: cs.CV

TL;DR: AnyPcc 是一个通用的点云压缩框架，通过通用上下文模型和实例自适应微调策略解决了深度学习点云几何压缩中的泛化挑战，并在 15 个数据集上取得了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习点云几何压缩在泛化性方面面临关键挑战，这源于缺乏鲁棒的上下文模型和对分布外（OOD）数据的低效处理。

Method: AnyPcc 框架首先使用通用上下文模型，结合空间和通道分组的先验知识来捕捉上下文依赖关系。其次，采用实例自适应微调（IAFT）策略，通过显式和隐式压缩范式相结合的方式来处理 OOD 数据，对每个实例的网络权重子集进行微调并将其纳入比特流。

Result: 在 15 个多样化数据集的基准测试中，AnyPcc 取得了新的最先进的点云压缩性能。

Conclusion: AnyPcc 通过其创新的通用上下文模型和实例自适应微调策略，成功解决了点云压缩中的泛化性问题，并在广泛的数据集上证明了其优越性。

Abstract: Generalization remains a critical challenge for deep learning-based point
cloud geometry compression. We argue this stems from two key limitations: the
lack of robust context models and the inefficient handling of
out-of-distribution (OOD) data. To address both, we introduce AnyPcc, a
universal point cloud compression framework. AnyPcc first employs a Universal
Context Model that leverages priors from both spatial and channel-wise grouping
to capture robust contextual dependencies. Second, our novel Instance-Adaptive
Fine-Tuning (IAFT) strategy tackles OOD data by synergizing explicit and
implicit compression paradigms. It fine-tunes a small subset of network weights
for each instance and incorporates them into the bitstream, where the marginal
bit cost of the weights is dwarfed by the resulting savings in geometry
compression. Extensive experiments on a benchmark of 15 diverse datasets
confirm that AnyPcc sets a new state-of-the-art in point cloud compression. Our
code and datasets will be released to encourage reproducible research.

</details>


### [51] [AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models](https://arxiv.org/abs/2510.20348)
*Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham*

Main category: cs.CV

TL;DR: AccuQuant是一种用于扩散模型的新型量化方法，通过最小化量化误差在去噪步骤中的累积来提高精度，并提供了一种内存效率极高（O(1)）的实现。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的量化过程中存在量化误差在去噪步骤中累积的问题，以往的方法未能有效解决。

Method: AccuQuant通过显式模拟扩散采样过程中的多个去噪步骤来量化模型，以最小化全精度模型和量化模型在多个步骤输出之间的差异，从而缓解误差累积。此外，还提出了一种将内存复杂度从O(n)降低到O(1)的高效实现技术和新目标函数。

Result: AccuQuant在多个任务和扩散模型上均展现出有效性和效率，并在标准基准测试中取得了良好结果。

Conclusion: AccuQuant成功解决了扩散模型量化中的误差累积问题，并在精度和效率方面均表现出色。

Abstract: We present in this paper a novel post-training quantization (PTQ) method,
dubbed AccuQuant, for diffusion models. We show analytically and empirically
that quantization errors for diffusion models are accumulated over denoising
steps in a sampling process. To alleviate the error accumulation problem,
AccuQuant minimizes the discrepancies between outputs of a full-precision
diffusion model and its quantized version within a couple of denoising steps.
That is, it simulates multiple denoising steps of a diffusion sampling process
explicitly for quantization, accounting the accumulated errors over multiple
denoising steps, which is in contrast to previous approaches to imitating a
training process of diffusion models, namely, minimizing the discrepancies
independently for each step. We also present an efficient implementation
technique for AccuQuant, together with a novel objective, which reduces a
memory complexity significantly from $\mathcal{O}(n)$ to $\mathcal{O}(1)$,
where $n$ is the number of denoising steps. We demonstrate the efficacy and
efficiency of AccuQuant across various tasks and diffusion models on standard
benchmarks.

</details>


### [52] [Positional Encoding Field](https://arxiv.org/abs/2510.20385)
*Yunpeng Bai,Haoxiang Li,Qixing Huang*

Main category: cs.CV

TL;DR: 视觉生成领域的Diffusion Transformers (DiTs)模型通过使用位置编码(PE)来组织视觉内容，但研究发现PE在维持全局一致性方面起着主导作用，而非Patch Token本身。


<details>
  <summary>Details</summary>
Motivation: 由于DiTs模型中Patch Token的独立性，以及空间连贯性主要由PE决定的发现，我们提出了位置编码场(PE-Field)，以增强DiTs模型在三维空间中的几何建模能力。

Method: 提出位置编码场(PE-Field)，将PE从二维扩展到三维结构场，并引入了深度感知编码和分层编码，以实现体积推理和精细的子Patch控制。

Result: 在单张图像新视角合成任务上达到了最先进的性能，并且能够实现可控的空间图像编辑。

Conclusion: PE-Field能够直接在三维空间中进行几何建模，并提升DiTs模型在相关任务上的性能。

Abstract: Diffusion Transformers (DiTs) have emerged as the dominant architecture for
visual generation, powering state-of-the-art image and video models. By
representing images as patch tokens with positional encodings (PEs), DiTs
combine Transformer scalability with spatial and temporal inductive biases. In
this work, we revisit how DiTs organize visual content and discover that patch
tokens exhibit a surprising degree of independence: even when PEs are
perturbed, DiTs still produce globally coherent outputs, indicating that
spatial coherence is primarily governed by PEs. Motivated by this finding, we
introduce the Positional Encoding Field (PE-Field), which extends positional
encodings from the 2D plane to a structured 3D field. PE-Field incorporates
depth-aware encodings for volumetric reasoning and hierarchical encodings for
fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D
space. Our PE-Field-augmented DiT achieves state-of-the-art performance on
single-image novel view synthesis and generalizes to controllable spatial image
editing.

</details>


### [53] [Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval](https://arxiv.org/abs/2510.20393)
*Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim*

Main category: cs.CV

TL;DR: 提出一种因果方法，通过预测图像中可能遗漏的烹饪元素来改进图像到食谱检索，从而解决现有方法忽略细微差别的问​​题。


<details>
  <summary>Details</summary>
Motivation: 现有图像到食谱检索方法假设图像能充分代表食谱细节，但图像仅反映最终视觉效果，忽略了烹饪过程中的细微差别，导致模型偏向于视觉显著元素，难以区分细微差异的食谱。

Method: 提出一种新颖的因果方法，预测图像中可能遗漏的烹饪元素（如细微的食材和烹饪动作），并将这些元素注入到跨模态表示学习中，以减轻现有方法的偏见。

Result: 在标准单语Recipe1M数据集和新策划的多语种多文化数据集上进行了实验，结果表明该因果表示学习方法能够揭示细微的食材和烹饪动作，并在两个数据集上都取得了显著的检索性能。

Conclusion: 所提出的因果表示学习方法能够有效解决图像到食谱检索中的模态鸿沟问题，显著提升了在单语和多语种多文化数据集上的检索性能。

Abstract: Existing approaches for image-to-recipe retrieval have the implicit
assumption that a food image can fully capture the details textually documented
in its recipe. However, a food image only reflects the visual outcome of a
cooked dish and not the underlying cooking process. Consequently, learning
cross-modal representations to bridge the modality gap between images and
recipes tends to ignore subtle, recipe-specific details that are not visually
apparent but are crucial for recipe retrieval. Specifically, the
representations are biased to capture the dominant visual elements, resulting
in difficulty in ranking similar recipes with subtle differences in use of
ingredients and cooking methods. The bias in representation learning is
expected to be more severe when the training data is mixed of images and
recipes sourced from different cuisines. This paper proposes a novel causal
approach that predicts the culinary elements potentially overlooked in images,
while explicitly injecting these elements into cross-modal representation
learning to mitigate biases. Experiments are conducted on the standard
monolingual Recipe1M dataset and a newly curated multilingual multicultural
cuisine dataset. The results indicate that the proposed causal representation
learning is capable of uncovering subtle ingredients and cooking actions and
achieves impressive retrieval performance on both monolingual and multilingual
multicultural datasets.

</details>


### [54] [Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment](https://arxiv.org/abs/2510.20438)
*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

Main category: cs.CV

TL;DR: 提出了一种名为FuzzyDistillViT-MobileNet的新方法，用于肺癌（LC）分类，该方法利用动态模糊逻辑驱动的知识蒸馏（KD）来处理疾病诊断中的不确定性和复杂性。


<details>
  <summary>Details</summary>
Motivation: 为了处理肺癌诊断中的不确定性和复杂性，并提高模型的性能和泛化能力。

Method: 采用动态模糊逻辑驱动的知识蒸馏（KD），其中模糊逻辑动态调整蒸馏权重。使用Vision Transformer（ViT-B32）作为教师模型，MobileNet作为学生模型。通过动态等待调整机制优化训练过程。引入Gamma校正和直方图均衡化进行像素级图像融合。使用基于小波的融合方法（wavedec2）处理和融合图像，将其标准化为224x224分辨率。使用遗传算法（GA）从12个候选模型中选择最合适的预训练学生模型。

Result: 在LC25000数据集上达到99.16%的准确率，在IQOTH/NCCD数据集上达到99.54%的准确率。

Conclusion: FuzzyDistillViT-MobileNet模型在处理肺癌分类任务时表现出鲁棒性，并且在不同成像领域都取得了优异的性能。

Abstract: This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for
lung cancer (LC) classification, leveraging dynamic fuzzy logic-driven
knowledge distillation (KD) to address uncertainty and complexity in disease
diagnosis. Unlike traditional models that rely on static KD with fixed weights,
our method dynamically adjusts the distillation weight using fuzzy logic,
enabling the student model to focus on high-confidence regions while reducing
attention to ambiguous areas. This dynamic adjustment improves the model
ability to handle varying uncertainty levels across different regions of LC
images. We employ the Vision Transformer (ViT-B32) as the instructor model,
which effectively transfers knowledge to the student model, MobileNet,
enhancing the student generalization capabilities. The training process is
further optimized using a dynamic wait adjustment mechanism that adapts the
training procedure for improved convergence and performance. To enhance image
quality, we introduce pixel-level image fusion improvement techniques such as
Gamma correction and Histogram Equalization. The processed images (Pix1 and
Pix2) are fused using a wavelet-based fusion method to improve image resolution
and feature preservation. This fusion method uses the wavedec2 function to
standardize images to a 224x224 resolution, decompose them into multi-scale
frequency components, and recursively average coefficients at each level for
better feature representation. To address computational efficiency, Genetic
Algorithm (GA) is used to select the most suitable pre-trained student model
from a pool of 12 candidates, balancing model performance with computational
cost. The model is evaluated on two datasets, including LC25000
histopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images
(99.54% accuracy), demonstrating robustness across different imaging domains.

</details>


### [55] [Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence](https://arxiv.org/abs/2510.20470)
*Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun*

Main category: cs.CV

TL;DR: Conan是一个用于视频推理的框架，通过结合视觉线索和多步推理，提高了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视频推理方面面临多步推理的挑战，现有的基于文本的方法可能导致结论不准确或虚构，而基于帧检索的方法在证据定位方面存在困难。

Method: Conan框架识别上下文和证据帧，进行跨帧线索推理，并自适应地决定何时得出结论或继续探索。该框架包含一个名为Conan-91K的大规模数据集，以及一个多阶段渐进式冷启动策略和识别-推理-行动（AIR）强化学习视频推理（RLVR）训练框架。

Result: Conan在六个多步推理基准测试中的准确率平均比Qwen2.5-7B-Instruct高出10%以上，并在长视频理解任务上表现出良好的泛化能力、可扩展性和鲁棒性。

Conclusion: Conan框架有效地解决了视频推理中的挑战，并在多个基准测试和长视频理解任务上取得了最先进的性能。

Abstract: Video reasoning, which requires multi-step deduction across frames, remains a
major challenge for multimodal large language models (MLLMs). While
reinforcement learning (RL)-based methods enhance reasoning capabilities, they
often rely on text-only chains that yield ungrounded or hallucinated
conclusions. Conversely, frame-retrieval approaches introduce visual grounding
but still struggle with inaccurate evidence localization. To address these
challenges, we present Conan, a framework for evidence-grounded multi-step
video reasoning. Conan identifies contextual and evidence frames, reasons over
cross-frame clues, and adaptively decides when to conclude or explore further.
To achieve this, we (1) construct Conan-91K, a large-scale dataset of
automatically generated reasoning traces that includes frame identification,
evidence reasoning, and action decision, and (2) design a multi-stage
progressive cold-start strategy combined with an
Identification-Reasoning-Action (AIR) RLVR training framework to jointly
enhance multi-step visual reasoning. Extensive experiments on six multi-step
reasoning benchmarks demonstrate that Conan surpasses the baseline
Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving
state-of-the-art performance. Furthermore, Conan generalizes effectively to
long-video understanding tasks, validating its strong scalability and
robustness.

</details>


### [56] [Reliable and Reproducible Demographic Inference for Fairness in Face Analysis](https://arxiv.org/abs/2510.20482)
*Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison*

Main category: cs.CV

TL;DR: 该研究提出了一种新的、可复现的人口统计属性推断（DAI）流程，用于提高面部分析系统（FAS）公平性审计的准确性和鲁棒性，并声称该方法优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 自动人口统计属性推断（DAI）是面部分析系统（FAS）公平性评估的基础，但其本身的可靠性会影响公平性审计的有效性。提高DAI的可靠性可以降低FAS公平性估计的偏差和方差。

Method: 提出了一种模块化的迁移学习方法，替代了传统端到端训练。该方法整合了预训练的人脸识别编码器和非线性分类头，并引入了新的鲁棒性（intra-identity consistency）指标，该指标可应用于任何人口统计分割方案。对该流程在准确性、公平性和鲁棒性三个维度上进行了审计。

Result: 所提出的DAI流程在性别和种族推断方面，在多个数据集和训练设置下，优于现有的强基线方法，尤其是在更具挑战性的种族推断方面。

Conclusion: 该研究为DAI在公平性审计中的应用提供了一个可靠的基础，并通过发布相关元数据、代码、预训练模型和评估工具集来促进透明度和可复现性。

Abstract: Fairness evaluation in face analysis systems (FAS) typically depends on
automatic demographic attribute inference (DAI), which itself relies on
predefined demographic segmentation. However, the validity of fairness auditing
hinges on the reliability of the DAI process. We begin by providing a
theoretical motivation for this dependency, showing that improved DAI
reliability leads to less biased and lower-variance estimates of FAS fairness.
To address this, we propose a fully reproducible DAI pipeline that replaces
conventional end-to-end training with a modular transfer learning approach. Our
design integrates pretrained face recognition encoders with non-linear
classification heads. We audit this pipeline across three dimensions: accuracy,
fairness, and a newly introduced notion of robustness, defined via
intra-identity consistency. The proposed robustness metric is applicable to any
demographic segmentation scheme. We benchmark the pipeline on gender and
ethnicity inference across multiple datasets and training setups. Our results
show that the proposed method outperforms strong baselines, particularly on
ethnicity, which is the more challenging attribute. To promote transparency and
reproducibility, we will publicly release the training dataset metadata, full
codebase, pretrained models, and evaluation toolkit. This work contributes a
reliable foundation for demographic inference in fairness auditing.

</details>


### [57] [EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization](https://arxiv.org/abs/2510.20512)
*Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang*

Main category: cs.CV

TL;DR: EchoDistill是一个双向概念蒸馏框架，用于在一步扩散模型中实现新概念的个性化，同时提高教师模型的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）扩散模型在加速生成方面取得了进展，但由于单步模型捕获新概念分布的能力有限，因此在个性化方面仍然存在挑战。

Method: 该框架同时训练一个多步扩散模型（教师）和一个单步扩散模型（学生）。概念首先从教师蒸馏到学生，然后从学生反馈到教师。在整个过程中，共享文本编码器以确保语义一致性。学生模型通过对抗性损失和对齐损失进行优化。此外，采用双向回声精炼策略，利用学生模型的快速生成能力反馈给教师模型。

Result: 实验证明，该框架在单步扩散模型个性化（1-SDP）设置下显著优于现有方法，为T2I扩散模型快速有效的个性化树立了新的范例。

Conclusion: EchoDistill通过双向概念蒸馏，成功实现了单步T2I扩散模型的新概念个性化，并提高了教师模型的生成质量，为个性化T2I扩散模型提供了一种新颖有效的方法。

Abstract: Recent advances in accelerating text-to-image (T2I) diffusion models have
enabled the synthesis of high-fidelity images even in a single step. However,
personalizing these models to incorporate novel concepts remains a challenge
due to the limited capacity of one-step models to capture new concept
distributions effectively. We propose a bidirectional concept distillation
framework, EchoDistill, to enable one-step diffusion personalization (1-SDP).
Our approach involves an end-to-end training process where a multi-step
diffusion model (teacher) and a one-step diffusion model (student) are trained
simultaneously. The concept is first distilled from the teacher model to the
student, and then echoed back from the student to the teacher. During the
EchoDistill, we share the text encoder between the two models to ensure
consistent semantic understanding. Following this, the student model is
optimized with adversarial losses to align with the real image distribution and
with alignment losses to maintain consistency with the teacher's output.
Furthermore, we introduce the bidirectional echoing refinement strategy,
wherein the student model leverages its faster generation capability to
feedback to the teacher model. This bidirectional concept distillation
mechanism not only enhances the student ability to personalize novel concepts
but also improves the generative quality of the teacher model. Our experiments
demonstrate that this collaborative framework significantly outperforms
existing personalization methods over the 1-SDP setup, establishing a novel
paradigm for rapid and effective personalization in T2I diffusion models.

</details>


### [58] [Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning](https://arxiv.org/abs/2510.20519)
*Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma*

Main category: cs.CV

TL;DR: Metis-HOME是一个混合专家模型，通过区分复杂推理和简单推理任务，解决了多模态大模型推理能力和通用能力之间的矛盾，并取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型在处理复杂推理任务时效率低下，并且在追求推理能力时损害了通用理解能力。本研究旨在解决推理效率和通用性之间的权衡问题。

Method: 提出了一种名为Metis-HOME的混合专家模型（Hybrid Optimized Mixture-of-Experts），该模型将原始的密集模型划分为两个专家分支：一个用于复杂推理的“思考”分支，一个用于快速直接推理（如VQA和OCR）的“非思考”分支。一个轻量级的路由器动态地将查询分配给最合适的专家。具体上，通过将Qwen2.5-VL-7B模型适配为MoE架构来实现。

Result: Metis-HOME模型不仅显著提升了复杂推理能力，还改善了模型的通用能力，解决了其他推理专用模型中出现的性能下降问题。

Conclusion: Metis-HOME模型通过其混合思考范式，成功解决了多模态大模型在推理能力和泛化能力之间的固有矛盾，为构建强大且通用的多模态大模型提供了一种新的范式。

Abstract: Inspired by recent advancements in LLM reasoning, the field of multimodal
reasoning has seen remarkable progress, achieving significant performance gains
on intricate tasks such as mathematical problem-solving. Despite this progress,
current multimodal large reasoning models exhibit two key limitations. They
tend to employ computationally expensive reasoning even for simple queries,
leading to inefficiency. Furthermore, this focus on specialized reasoning often
impairs their broader, more general understanding capabilities. In this paper,
we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed
to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by
structuring the original dense model into two distinct expert branches: a
thinking branch tailored for complex, multi-step reasoning, and a non-thinking
branch optimized for rapid, direct inference on tasks like general VQA and OCR.
A lightweight, trainable router dynamically allocates queries to the most
suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into
an MoE architecture. Comprehensive evaluations reveal that our approach not
only substantially enhances complex reasoning abilities but also improves the
model's general capabilities, reversing the degradation trend observed in other
reasoning-specialized models. Our work establishes a new paradigm for building
powerful and versatile MLLMs, effectively resolving the prevalent
reasoning-vs-generalization dilemma.

</details>


### [59] [Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis](https://arxiv.org/abs/2510.20531)
*Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu*

Main category: cs.CV

TL;DR: 本论文提出了FiFa框架，用于解决现有可解释深度伪造分析（XDFA）模型缺乏细粒度视觉上下文理解的问题，通过引入FICT和FiFa-Annotator实现更可靠的数据标注，并提出AGE任务和FiFa-MLLM模型以支持细粒度的伪造解释和视觉证据关联，最终在XDFA任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有XDFA方法缺乏细粒度视觉上下文理解能力，表现为数据标注粗糙、模型无法关联文本解释与视觉伪影，并且不支持对任意面部区域进行查询，导致模型响应与面部视觉线索（Facext）的结合不够充分。

Method: 1. 定义面部图像概念树（FICT），将面部图像划分为细粒度的区域概念。2. 提出FiFa-Annotator，一个用于伪造解释的更可靠的数据标注流程。3. 引入新的伪影接地解释（AGE）任务，生成包含伪影分割掩码的文本伪造解释。4. 提出FiFa-MLLM统一多任务学习架构，同时支持丰富的多模态输入和输出，并结合辅助监督任务。

Result: FiFa-MLLM在AGE任务上超越了强大的基线模型，并在现有的XDFA数据集上取得了SOTA性能。

Conclusion: FiFa框架通过FICT、FiFa-Annotator和AGE任务，以及FiFa-MLLM模型，有效地提升了XDFA的细粒度视觉上下文理解能力，实现了更准确、更具可解释性的深度伪造分析。

Abstract: The advancement of Multimodal Large Language Models (MLLMs) has bridged the
gap between vision and language tasks, enabling the implementation of
Explainable DeepFake Analysis (XDFA). However, current methods suffer from a
lack of fine-grained awareness: the description of artifacts in data annotation
is unreliable and coarse-grained, and the models fail to support the output of
connections between textual forgery explanations and the visual evidence of
artifacts, as well as the input of queries for arbitrary facial regions. As a
result, their responses are not sufficiently grounded in Face Visual Context
(Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)
framework, with contributions focusing on data annotation and model
construction. We first define a Facial Image Concept Tree (FICT) to divide
facial images into fine-grained regional concepts, thereby obtaining a more
reliable data annotation pipeline, FiFa-Annotator, for forgery explanation.
Based on this dedicated data annotation, we introduce a novel
Artifact-Grounding Explanation (AGE) task, which generates textual forgery
explanations interleaved with segmentation masks of manipulated artifacts. We
propose a unified multi-task learning architecture, FiFa-MLLM, to
simultaneously support abundant multimodal inputs and outputs for fine-grained
Explainable DeepFake Analysis. With multiple auxiliary supervision tasks,
FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA
performance on existing XDFA datasets. The code and data will be made
open-source at https://github.com/lxq1000/Fake-in-Facext.

</details>


### [60] [Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image](https://arxiv.org/abs/2510.20539)
*Guillermo Carbajal,Andrés Almansa,Pablo Musé*

Main category: cs.CV

TL;DR: 该研究提出了一种深度学习框架，能够从单张模糊图像中同时估计出清晰图像和相机运动轨迹，以解决由相机抖动引起的大幅度或旋转运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 相机抖动（尤其大幅度或旋转运动）造成的运动模糊是图像恢复中的主要挑战。

Method: 提出一个深度学习框架，利用项目式运动模糊模型（PMBM）和可微分模糊创建模块，通过神经网络预测三维旋转轨迹，并结合基于模型的方法进行端到端训练，同时引入重模糊损失进行后推理优化。

Result: 在合成和真实数据集上都达到了最先进的性能，特别是在严重或空间变化的模糊情况下，优于其他端到端去模糊网络。

Conclusion: 该方法通过联合估计清晰图像和相机运动轨迹，实现了对严重运动模糊的有效恢复，并提供了运动轨迹的可解释性。

Abstract: Motion blur caused by camera shake, particularly under large or rotational
movements, remains a major challenge in image restoration. We propose a deep
learning framework that jointly estimates the latent sharp image and the
underlying camera motion trajectory from a single blurry image. Our method
leverages the Projective Motion Blur Model (PMBM), implemented efficiently
using a differentiable blur creation module compatible with modern networks. A
neural network predicts a full 3D rotation trajectory, which guides a
model-based restoration network trained end-to-end. This modular architecture
provides interpretability by revealing the camera motion that produced the
blur. Moreover, this trajectory enables the reconstruction of the sequence of
sharp images that generated the observed blurry image. To further refine
results, we optimize the trajectory post-inference via a reblur loss, improving
consistency between the blurry input and the restored output. Extensive
experiments show that our method achieves state-of-the-art performance on both
synthetic and real datasets, particularly in cases with severe or spatially
variant blur, where end-to-end deblurring networks struggle.
  Code and trained models are available at
https://github.com/GuillermoCarbajal/Blur2Seq/

</details>


### [61] [From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging](https://arxiv.org/abs/2510.20550)
*Fuchen Li,Yansong Du,Wenbo Cheng,Xiaoxia Zhou,Sen Yin*

Main category: cs.CV

TL;DR: ACamera-Net是一个轻量级、场景自适应的相机参数调整网络，可直接从RAW输入预测最佳曝光和白平衡，以解决复杂光照条件下的图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 消费级相机在复杂光照条件下（如弱光、高动态范围、背光和空间色温变化）难以保持稳定的图像质量，导致欠曝、偏色和色调不一致，从而影响下游视觉任务的性能。

Method: 提出ACamera-Net，一个由ACamera-Exposure（用于估计ISO以缓解欠曝和对比度损失）和ACamera-Color（用于预测相关色温和增益因子以提高色彩一致性）两个模块组成的轻量级、场景自适应网络，直接从RAW输入预测最佳曝光和白平衡。该网络针对边缘设备的实时推理进行了优化，可无缝集成到成像管线中。

Result: 在包含标注参考的真实世界数据上训练的模型，在各种光照条件下都表现出良好的泛化能力。大量实验表明，ACamera-Net能够持续提高图像质量并稳定感知输出，其性能优于传统的自动模式和轻量级基线模型，且无需额外的图像增强模块。

Conclusion: ACamera-Net能够有效解决消费级相机在复杂光照条件下遇到的图像质量问题，通过自适应调整曝光和白平衡参数，显著提升图像质量和下游视觉任务的性能。

Abstract: Consumer-grade camera systems often struggle to maintain stable image quality
under complex illumination conditions such as low light, high dynamic range,
and backlighting, as well as spatial color temperature variation. These issues
lead to underexposure, color casts, and tonal inconsistency, which degrade the
performance of downstream vision tasks. To address this, we propose
ACamera-Net, a lightweight and scene-adaptive camera parameter adjustment
network that directly predicts optimal exposure and white balance from RAW
inputs. The framework consists of two modules: ACamera-Exposure, which
estimates ISO to alleviate underexposure and contrast loss, and ACamera-Color,
which predicts correlated color temperature and gain factors for improved color
consistency. Optimized for real-time inference on edge devices, ACamera-Net can
be seamlessly integrated into imaging pipelines. Trained on diverse real-world
data with annotated references, the model generalizes well across lighting
conditions. Extensive experiments demonstrate that ACamera-Net consistently
enhances image quality and stabilizes perception outputs, outperforming
conventional auto modes and lightweight baselines without relying on additional
image enhancement modules.

</details>


### [62] [Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence](https://arxiv.org/abs/2510.20579)
*Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang*

Main category: cs.CV

TL;DR: Open-o3 Video 模型通过整合时空证据来改进视频推理，在 V-STAR 基准测试中取得了最先进的性能，并提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大多数视频推理模型只能生成文本推理，无法指出关键证据在何时何地出现。现有的模型（如 OpenAI-o3）在图像证据推理方面引起了广泛关注，但将其扩展到视频领域更具挑战性，因为它需要跨动态场景的联合时间跟踪和空间定位。

Method: 我们提出了 Open-o3 Video，一个非智能体框架，将显式的时空证据整合到视频推理中。我们精心收集了训练数据并设计了训练策略来应对这些挑战。模型在答案旁边会突出显示关键的时间戳、对象和边界框，从而使推理能够基于具体的视觉观察。为了实现这一功能，我们首先策划和构建了两个高质量的数据集：STGR-CoT-30k 用于 SFT，STGR-RL-36k 用于 RL，并进行了细致的时间和空间标注，因为现有的大多数数据集要么提供视频的时间跨度，要么提供图像的空间框，缺乏统一的时空监督和推理痕迹。然后，我们采用了一种冷启动强化学习策略，并结合了多种专门设计的奖励，共同鼓励答案准确性、时间对齐和空间精确性。

Result: 在 V-STAR 基准测试中，Open-o3 Video 取得了最先进的性能，在 Qwen2.5-VL 基线上，mAM 提高了 14.4%，mLGM 提高了 24.2%。在 VideoMME、WorldSense、VideoMMMU 和 TVGBench 等一系列视频理解基准测试中，也观察到了持续的改进。除了准确性之外，Open-o3 Video 生成的推理痕迹还为测试时缩放提供了有价值的信号，能够进行置信度感知验证并提高答案的可靠性。

Conclusion: Open-o3 Video 通过整合时空证据，在视频推理任务中取得了最先进的性能，并在 V-STAR 和其他多个基准测试中展现了显著的改进。该模型不仅提高了答案的准确性，还通过提供可解释的推理痕迹来增强结果的可靠性。

Abstract: Most video reasoning models only generate textual reasoning traces without
indicating when and where key evidence appears. Recent models such as OpenAI-o3
have sparked wide interest in evidence-centered reasoning for images, yet
extending this ability to videos is more challenging, as it requires joint
temporal tracking and spatial localization across dynamic scenes. We introduce
Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal
evidence into video reasoning, and carefully collect training data and design
training strategies to address the aforementioned challenges. The model
highlights key timestamps, objects, and bounding boxes alongside its answers,
allowing reasoning to be grounded in concrete visual observations. To enable
this functionality, we first curate and build two high-quality datasets,
STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed
temporal and spatial annotations, since most existing datasets offer either
temporal spans for videos or spatial boxes on images, lacking unified
spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start
reinforcement learning strategy with multiple specially designed rewards that
jointly encourage answer accuracy, temporal alignment, and spatial precision.
On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,
raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent
improvements are also observed on a broad range of video understanding
benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond
accuracy, the reasoning traces produced by Open-o3 Video also provide valuable
signals for test-time scaling, enabling confidence-aware verification and
improving answer reliability.

</details>


### [63] [GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models](https://arxiv.org/abs/2510.20586)
*Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang*

Main category: cs.CV

TL;DR: 新的GenColorBench基准测试解决了文本到图像生成模型在颜色控制方面的不足，该基准包含44K个颜色相关的提示，涵盖400多种颜色，并结合了ISCC-NBS和CSS3/X11等颜色系统，包括之前基准测试中缺失的RGB值。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在颜色控制方面存在不足，未能准确匹配文本提示中指定的颜色。现有的基准测试未能系统地评估颜色精度，而颜色对于人类视觉感知和沟通至关重要，尤其是在艺术和设计等需要品牌一致性的领域。

Method: 提出GenColorBench，一个包含44K个颜色相关提示的综合性基准测试，覆盖400多种颜色，并利用ISCC-NBS和CSS3/X11等颜色系统，包括数字颜色。通过感知和自动化评估来检测模型的真实能力。

Result: 使用GenColorBench评估了流行的文本到图像模型，结果显示出性能差异，揭示了模型最能理解的颜色约定，并识别了失败模式。

Conclusion: GenColorBench是第一个用于文本到图像颜色生成的综合性基准测试，其评估结果将指导模型在精确颜色生成方面的改进。

Abstract: Recent years have seen impressive advances in text-to-image generation, with
image generative or unified models producing high-quality images from text. Yet
these models still struggle with fine-grained color controllability, often
failing to accurately match colors specified in text prompts. While existing
benchmarks evaluate compositional reasoning and prompt adherence, none
systematically assess color precision. Color is fundamental to human visual
perception and communication, critical for applications from art to design
workflows requiring brand consistency. However, current benchmarks either
neglect color or rely on coarse assessments, missing key capabilities such as
interpreting RGB values or aligning with human expectations. To this end, we
propose GenColorBench, the first comprehensive benchmark for text-to-image
color generation, grounded in color systems like ISCC-NBS and CSS3/X11,
including numerical colors which are absent elsewhere. With 44K color-focused
prompts covering 400+ colors, it reveals models' true capabilities via
perceptual and automated assessments. Evaluations of popular text-to-image
models using GenColorBench show performance variations, highlighting which
color conventions models understand best and identifying failure modes. Our
GenColorBench assessments will guide improvements in precise color generation.
The benchmark will be made public upon acceptance.

</details>


### [64] [Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation](https://arxiv.org/abs/2510.20596)
*Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的基于相似性原型的跨模态分割框架，通过学习类原型并引入相似性约束来减小域间隙，并使用字典存储原型以解决类别缺失问题并实现对比学习，在实验中取得了优于现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习模型对域偏移敏感，导致在未见数据上性能急剧下降，因此需要无监督域自适应技术来减小域间隙并避免昂贵的标注。该研究旨在解决跨模态分割中的域偏移问题。

Method: 1. 学习类别感知的原型（class-wise prototypes）于嵌入空间中。
2. 引入相似性约束，使得原型能够代表各自的语义类别且区分不同类别。
3. 使用字典存储来自不同图像的原型，以解决类别缺失问题并实现原型的对比学习。

Result: 实验证明，该方法在跨模态分割任务上取得了优于其他最先进方法的成果。

Conclusion: 所提出的基于相似性原型的框架能够有效地解决跨模态分割中的域偏移问题，并通过原型学习和对比学习提高了模型性能。

Abstract: Deep learning models have achieved great success on various vision
challenges, but a well-trained model would face drastic performance degradation
when applied to unseen data. Since the model is sensitive to domain shift,
unsupervised domain adaptation attempts to reduce the domain gap and avoid
costly annotation of unseen domains. This paper proposes a novel framework for
cross-modality segmentation via similarity-based prototypes. In specific, we
learn class-wise prototypes within an embedding space, then introduce a
similarity constraint to make these prototypes representative for each semantic
class while separable from different classes. Moreover, we use dictionaries to
store prototypes extracted from different images, which prevents the
class-missing problem and enables the contrastive learning of prototypes, and
further improves performance. Extensive experiments show that our method
achieves better results than other state-of-the-art methods.

</details>


### [65] [OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects](https://arxiv.org/abs/2510.20605)
*Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Free-moving object reconstruction from monocular video remains challenging,
particularly without reliable pose or depth cues and under arbitrary object
motion. We introduce OnlineSplatter, a novel online feed-forward framework
generating high-quality, object-centric 3D Gaussians directly from RGB frames
without requiring camera pose, depth priors, or bundle optimization. Our
approach anchors reconstruction using the first frame and progressively refines
the object representation through a dense Gaussian primitive field, maintaining
constant computational cost regardless of video sequence length. Our core
contribution is a dual-key memory module combining latent appearance-geometry
keys with explicit directional keys, robustly fusing current frame features
with temporally aggregated object states. This design enables effective
handling of free-moving objects via spatial-guided memory readout and an
efficient sparsification mechanism, ensuring comprehensive yet compact object
coverage. Evaluations on real-world datasets demonstrate that OnlineSplatter
significantly outperforms state-of-the-art pose-free reconstruction baselines,
consistently improving with more observations while maintaining constant memory
and runtime.

</details>


### [66] [SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding](https://arxiv.org/abs/2510.20622)
*Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He*

Main category: cs.CV

TL;DR: SeViCES框架通过结合语义和视觉信息，解决了长视频理解中的信息帧选择问题，提高了Video-LLMs的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 长视频理解因内容复杂、时序分散而充满挑战。现有的Video-LLMs处理长视频计算成本高，且推理可能不集中或不一致。现有帧选择方法忽略时序依赖或仅依赖单一模态，无法提供完整且与查询相关的上下文。

Method: 提出SeViCES框架，包含两个关键组件：1. 语义-视觉共识帧选择（SVCFS）模块，通过（1）利用LLM对标题进行推理的时序感知语义分支，和（2）通过互信息将嵌入与语义分数对齐的聚类引导视觉分支，来选择帧。 2. 答案共识细化（ACR）模块，通过融合证据和约束答案空间，解决基于语义和视觉的预测之间的一致性问题。该框架无需训练且模型无关。

Result: 在长视频理解基准测试上的大量实验表明，SeViCES在准确性和鲁棒性方面持续优于现有最先进方法。

Conclusion: 共识驱动的证据选择对于Video-LLMs至关重要。

Abstract: Long video understanding remains challenging due to its complex, diverse, and
temporally scattered content. Although video large language models (Video-LLMs)
can process videos lasting tens of minutes, applying them to truly long
sequences is computationally prohibitive and often leads to unfocused or
inconsistent reasoning. A promising solution is to select only the most
informative frames, yet existing approaches typically ignore temporal
dependencies or rely on unimodal evidence, limiting their ability to provide
complete and query-relevant context. We propose a Semantic-Visual Consensus
Evidence Selection (SeViCES) framework for effective and reliable long video
understanding. SeViCES is training-free and model-agnostic, and introduces two
key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module
selects frames through (1) a temporal-aware semantic branch that leverages LLM
reasoning over captions, and (2) a cluster-guided visual branch that aligns
embeddings with semantic scores via mutual information. The Answer Consensus
Refinement (ACR) module further resolves inconsistencies between semantic- and
visual-based predictions by fusing evidence and constraining the answer space.
Extensive experiments on long video understanding benchmarks show that SeViCES
consistently outperforms state-of-the-art methods in both accuracy and
robustness, demonstrating the importance of consensus-driven evidence selection
for Video-LLMs.

</details>


### [67] [Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges](https://arxiv.org/abs/2510.20634)
*Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li*

Main category: cs.CV

TL;DR: 本文对深度学习在牙科影像分析中的应用进行了系统性综述，涵盖了数据集和模型两个核心方面，旨在为该领域的研究者提供参考。


<details>
  <summary>Details</summary>
Motivation: 牙科影像分析对于准确诊断和治疗方案规划至关重要，但手动解读存在耗时、不一致等问题。人工智能（AI），特别是深度学习（DL），为自动化牙科影像分析（DIA）提供了解决方案。

Method: 系统性回顾了260篇关于DL在DIA中应用的研究论文，包括49篇关于公开牙科数据集的论文和211篇关于DL模型的论文。论文介绍了牙科影像基础概念、数据集特征与获取方法，并根据不同的DIA任务对DL模型和算法进行了分类，分析了网络架构、优化策略、训练方法和性能。同时，总结了常用的训练和评估指标。

Result: 收集并分析了49个公开牙科数据集和211篇相关的DL模型论文，对现有技术进行了分类和评估。

Conclusion: 讨论了当前研究面临的挑战，并提出了未来可能的研究方向，以期为该领域的进一步发展提供指导。

Abstract: Efficient analysis and processing of dental images are crucial for dentists
to achieve accurate diagnosis and optimal treatment planning. However, dental
imaging inherently poses several challenges, such as low contrast, metallic
artifacts, and variations in projection angles. Combined with the subjectivity
arising from differences in clinicians' expertise, manual interpretation often
proves time-consuming and prone to inconsistency. Artificial intelligence
(AI)-based automated dental image analysis (DIA) offers a promising solution to
these issues and has become an integral part of computer-aided dental diagnosis
and treatment. Among various AI technologies, deep learning (DL) stands out as
the most widely applied and influential approach due to its superior feature
extraction and representation capabilities. To comprehensively summarize recent
progress in this field, we focus on the two fundamental aspects of DL
research-datasets and models. In this paper, we systematically review 260
studies on DL applications in DIA, including 49 papers on publicly available
dental datasets and 211 papers on DL-based algorithms. We first introduce the
basic concepts of dental imaging and summarize the characteristics and
acquisition methods of existing datasets. Then, we present the foundational
techniques of DL and categorize relevant models and algorithms according to
different DIA tasks, analyzing their network architectures, optimization
strategies, training methods, and performance. Furthermore, we summarize
commonly used training and evaluation metrics in the DIA domain. Finally, we
discuss the current challenges of existing research and outline potential
future directions. We hope that this work provides a valuable and systematic
reference for researchers in this field. All supplementary materials and
detailed comparison tables will be made publicly available on GitHub.

</details>


### [68] [Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging](https://arxiv.org/abs/2510.20639)
*Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze*

Main category: cs.CV

TL;DR: BTB3D通过创新的三阶段训练和紧凑、感知频率的3D标记解决了高分辨率医学3D图像的视觉语言模型难题，在新报告生成和文本到CT合成任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理高分辨率、长序列的3D医学图像时存在困难，主要是因为对比预训练导致视觉编码器与临床语言不匹配，以及逐层切片标记模糊了精细解剖结构，从而影响了下游任务的诊断性能。

Method: 提出了一种名为BTB3D的因果卷积编码器-解码器模型，它能够统一2D和3D的训练和推理，并生成紧凑、感知频率的3D标记。该模型采用三阶段训练课程：1.局部重建，2.重叠窗口平铺，3.长上下文解码器精炼。

Result: BTB3D在报告生成任务上，BLEU分数有所提高，临床F1分数比CT2Rep、CT-CHAT和Merlin提高了40%。在文本到CT合成任务上，FID分数降低了75%，FVD（³D视频生成距离）减少了一半，成功生成了512*512*241的解剖结构一致的CT图像。

Conclusion: 精确的三维标记是实现3D医学图像中可扩展视觉语言模型的核心，而非仅仅依赖于更大的语言主干。

Abstract: Recent progress in vision-language modeling for 3D medical imaging has been
fueled by large-scale computed tomography (CT) corpora with paired free-text
reports, stronger architectures, and powerful pretrained models. This has
enabled applications such as automated report generation and text-conditioned
3D image synthesis. Yet, current approaches struggle with high-resolution,
long-sequence volumes: contrastive pretraining often yields vision encoders
that are misaligned with clinical language, and slice-wise tokenization blurs
fine anatomy, reducing diagnostic performance on downstream tasks. We introduce
BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder
that unifies 2D and 3D training and inference while producing compact,
frequency-aware volumetric tokens. A three-stage training curriculum enables
(i) local reconstruction, (ii) overlapping-window tiling, and (iii)
long-context decoder refinement, during which the model learns from short slice
excerpts yet generalizes to scans exceeding 300 slices without additional
memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it
improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and
Merlin for report generation; and it reduces FID by 75% and halves FVD compared
to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically
consistent 512*512*241 volumes. These results confirm that precise
three-dimensional tokenization, rather than larger language backbones alone, is
essential for scalable vision-language modeling in 3D medical imaging. The
codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D

</details>


### [69] [UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset](https://arxiv.org/abs/2510.20661)
*Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 本文提出了UltraHR-100K数据集和一种新的文本到图像生成方法，以解决超高分辨率(UHR)图像生成中的数据和训练策略问题。


<details>
  <summary>Details</summary>
Motivation: 现有的超高分辨率文本到图像生成技术面临两大挑战：缺乏大规模高质量的数据集以及忽视了针对精细细节合成的定制化训练策略。

Method: 为了解决这些问题，研究者们引入了UltraHR-100K数据集，包含10万张高分辨率图像和详细的描述。同时，提出了一种名为“细节导向时间步采样(DOTS)”和“软权重频率正则化(SWFR)”的频率感知后训练方法，以增强文本到图像扩散模型在细节合成方面的能力。

Result: 通过在UltraHR-eval4K基准测试上的实验证明，该方法显著提高了超高分辨率图像生成的精细细节质量和整体保真度。

Conclusion: 所提出的方法和数据集能够有效提升超高分辨率文本到图像生成的效果。

Abstract: Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable
progress. However, two key challenges remain : 1) the absence of a large-scale
high-quality UHR T2I dataset, and (2) the neglect of tailored training
strategies for fine-grained detail synthesis in UHR scenarios. To tackle the
first challenge, we introduce \textbf{UltraHR-100K}, a high-quality dataset of
100K UHR images with rich captions, offering diverse content and strong visual
fidelity. Each image exceeds 3K resolution and is rigorously curated based on
detail richness, content complexity, and aesthetic quality. To tackle the
second challenge, we propose a frequency-aware post-training method that
enhances fine-detail generation in T2I diffusion models. Specifically, we
design (i) \textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning
on detail-critical denoising steps, and (ii) \textit{Soft-Weighting Frequency
Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to
softly constrain frequency components, encouraging high-frequency detail
preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks
demonstrate that our approach significantly improves the fine-grained detail
quality and overall fidelity of UHR image generation. The code is available at
\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.

</details>


### [70] [HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification](https://arxiv.org/abs/2510.20669)
*Debojyoti Ghosh,Adrijit Goswami*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HybridSOMSpikeNet的混合深度学习框架，通过结合卷积特征提取、可微分自组织和脉冲神经网络，实现了高效且环保的垃圾分类，准确率达到97.39%，优于现有技术，并支持可持续发展目标。


<details>
  <summary>Details</summary>
Motivation: 准确的垃圾分类对于可持续垃圾管理和减少城市化对环境的影响至关重要。可回收物的错误分类会导致垃圾填埋、回收效率低下和温室气体排放增加。

Method: 该模型采用预训练的ResNet-152作为骨干网络提取空间特征，然后使用可微分的软自组织映射（Soft-SOM）进行拓扑聚类和增强可解释性，最后通过脉冲神经网络头部在离散时间步长上累积时间激活，以提高鲁棒性和泛化能力。

Result: 在包含十类垃圾的数据集上训练的HybridSOMSpikeNet在测试集上达到了97.39%的准确率，优于几种最先进的架构，同时保持了适合实际部署的轻量级计算特征。

Conclusion: HybridSOMSpikeNet通过实现精确的自动垃圾分类，提高了回收效率，减少了可回收物流中的污染物，并降低了垃圾处理的生态和运营成本。该方法符合全球可持续发展优先事项，特别是联合国可持续发展目标（SDG 11和SDG 12），有助于建设更清洁的城市、推动循环经济和建立智能环境管理系统。

Abstract: Accurate waste classification is vital for achieving sustainable waste
management and reducing the environmental footprint of urbanization.
Misclassification of recyclable materials contributes to landfill accumulation,
inefficient recycling, and increased greenhouse gas emissions. To address these
issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning
framework that integrates convolutional feature extraction, differentiable
self-organization, and spiking-inspired temporal processing to enable
intelligent and energy-efficient waste classification. The proposed model
employs a pre-trained ResNet-152 backbone to extract deep spatial
representations, followed by a Differentiable Soft Self-Organizing Map
(Soft-SOM) that enhances topological clustering and interpretability. A spiking
neural head accumulates temporal activations over discrete time steps,
improving robustness and generalization. Trained on a ten-class waste dataset,
HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several
state-of-the-art architectures while maintaining a lightweight computational
profile suitable for real-world deployment. Beyond its technical innovations,
the framework provides tangible environmental benefits. By enabling precise and
automated waste segregation, it supports higher recycling efficiency, reduces
contamination in recyclable streams, and minimizes the ecological and
operational costs of waste processing. The approach aligns with global
sustainability priorities, particularly the United Nations Sustainable
Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities,
circular economy initiatives, and intelligent environmental management systems.

</details>


### [71] [Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling](https://arxiv.org/abs/2510.20673)
*Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko*

Main category: cs.CV

TL;DR: 本文提出了一种名为EMQNet的方法，通过权重偏置校正和比特级核心集采样策略，在不牺牲模型性能的情况下，显著降低了多比特量化网络的训练开销，最快可提升7.88倍的训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有的多比特量化网络训练成本高，需要为每种支持的比特宽度重复全数据集更新，并且需要额外的微调阶段来支持额外的或中间的精度选项，这增加了整体训练负担。

Method: 1. 权重偏置校正：通过中和跨比特宽度的量化诱导偏差并对齐激活分布，实现共享批归一化并消除微调的需要。 2. 比特级核心集采样策略：通过利用隐式知识转移现象，让每个子模型在通过基于梯度的重要性分数选择的紧凑、信息丰富的子集上进行训练。

Result: 在CIFAR-10/100、TinyImageNet和ImageNet-1K数据集上，使用ResNet和ViT架构进行了实验，证明该方法在实现具有竞争力或更优的准确性的同时，将训练时间缩短了高达7.88倍。

Conclusion: 所提出的EMQNet通过权重偏置校正和比特级核心集采样策略，有效降低了多比特量化网络的训练开销，同时保持了模型的实用性。

Abstract: Multi-bit quantization networks enable flexible deployment of deep neural
networks by supporting multiple precision levels within a single model.
However, existing approaches suffer from significant training overhead as
full-dataset updates are repeated for each supported bit-width, resulting in a
cost that scales linearly with the number of precisions. Additionally, extra
fine-tuning stages are often required to support additional or intermediate
precision options, further compounding the overall training burden. To address
this issue, we propose two techniques that greatly reduce the training overhead
without compromising model utility: (i) Weight bias correction enables shared
batch normalization and eliminates the need for fine-tuning by neutralizing
quantization-induced bias across bit-widths and aligning activation
distributions; and (ii) Bit-wise coreset sampling strategy allows each child
model to train on a compact, informative subset selected via gradient-based
importance scores by exploiting the implicit knowledge transfer phenomenon.
Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and
ViT architectures demonstrate that our method achieves competitive or superior
accuracy while reducing training time up to 7.88x. Our code is released at
https://github.com/a2jinhee/EMQNet_jk.

</details>


### [72] [Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward](https://arxiv.org/abs/2510.20696)
*Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu*

Main category: cs.CV

TL;DR: MLLMs存在视觉幻觉和过度依赖文本先验的问题。本文提出了一种基于代理的架构，结合了LLM推理和轻量级视觉模块，以解决这些问题，并在视觉推理任务上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在集成视觉和文本推理能力以应对复杂视觉任务时，仍然存在视觉幻觉和过度依赖文本先验的问题。

Method: 提出了一种基于代理的架构，结合了LLM推理能力和轻量级的视觉模块，以实现对视觉内容的细粒度分析和推理链的迭代优化。

Result: 所提出的系统在MMMU和MathVista基准测试上取得了显著的提升（分别提高了+10.3和+6.0），性能媲美甚至超越了更大规模的模型。

Conclusion: 未来的视觉推理模型应侧重于整合更广泛的专用工具来分析视觉内容。此外，研究团队将发布其框架和评估套件以促进未来研究。

Abstract: Multimodal large language models (MLLMs) that integrate visual and textual
reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual
tasks, yet continue to exhibit visual hallucinations and an over-reliance on
textual priors. We present a systematic diagnosis of state-of-the-art
vision-language models using a three-stage evaluation framework, uncovering key
failure modes. To address these, we propose an agent-based architecture that
combines LLM reasoning with lightweight visual modules, enabling fine-grained
analysis and iterative refinement of reasoning chains. Our results highlight
future visual reasoning models should focus on integrating a broader set of
specialized tools for analyzing visual content. Our system achieves significant
gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or
surpassing much larger models. We will release our framework and evaluation
suite to facilitate future research.

</details>


### [73] [Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models](https://arxiv.org/abs/2510.20707)
*Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang*

Main category: cs.CV

TL;DR: KV缓存膨胀是大型视觉语言模型(LVLM)部署的可扩展性瓶颈。MixKV是一种新的方法，通过混合注意力和多样性来优化KV缓存压缩，以解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(LVLM)面临的关键内存瓶颈源于KV缓存的扩展，这阻碍了部署的可扩展性。现有的KV缓存压缩方法未能充分利用多模态KV缓存中独特的、特定于模态的语义冗余模式。

Method: MixKV通过混合注意力和多样性来优化LVLM的KV缓存压缩。它会调整到头部的语义冗余，并在压缩KV对时有选择地平衡多样性和注意力。

Result: MixKV在多个LVLM上持续改进现有方法，在极端压缩（预算=64）下，在五个多模态理解基准测试中平均提高了5.1%。它在GUI基础任务上实现了8.0%和9.0%的显著改进，同时保持了可比的推理效率。MixKV也可以无缝扩展到LLM。

Conclusion: MixKV是一种有效的KV缓存压缩方法，它通过结合注意力和多样性来解决LVLM中的内存瓶颈，并在各种多模态任务和LLM中都取得了显著的性能提升。

Abstract: Recent large vision-language models (LVLMs) demonstrate remarkable
capabilities in processing extended multi-modal sequences, yet the resulting
key-value (KV) cache expansion creates a critical memory bottleneck that
fundamentally limits deployment scalability. While existing KV cache
compression methods focus on retaining high-importance KV pairs to minimize
storage, they often overlook the modality-specific semantic redundancy patterns
that emerge distinctively in multi-modal KV caches. In this work, we first
analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying
levels of redundancy across attention heads. We show that relying solely on
importance can only cover a subset of the full KV cache information
distribution, leading to potential loss of semantic coverage. To address this,
we propose \texttt{MixKV}, a novel method that mixes importance with diversity
for optimized KV cache compression in LVLMs. \texttt{MixKV} adapts to head-wise
semantic redundancy, selectively balancing diversity and importance when
compressing KV pairs. Extensive experiments demonstrate that \texttt{MixKV}
consistently enhances existing methods across multiple LVLMs. Under extreme
compression (budget=64), \texttt{MixKV} improves baseline methods by an average
of \textbf{5.1\%} across five multi-modal understanding benchmarks and achieves
remarkable gains of \textbf{8.0\%} and \textbf{9.0\%} for SnapKV and AdaKV on
GUI grounding tasks, all while maintaining comparable inference efficiency.
Furthermore, \texttt{MixKV} extends seamlessly to LLMs with comparable
performance gains. Our code is available at
\href{https://github.com/xuyang-liu16/MixKV}{\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.

</details>


### [74] [AutoScape: Geometry-Consistent Long-Horizon Scene Generation](https://arxiv.org/abs/2510.20726)
*Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker*

Main category: cs.CV

TL;DR: AutoScape是一个新的RGB-D扩散模型，用于生成长视距的驾驶场景，通过生成关键帧并进行插值，提高了生成视频的真实性和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 生成长视距、真实且几何一致的驾驶场景。

Method: 使用新颖的RGB-D扩散模型生成关键帧，并进行插值。该模型在共享潜在空间中联合处理图像和深度，显式地以现有场景几何为条件，并使用扭曲一致的引导来指导采样过程。

Result: 生成的驾驶视频长达20秒以上，在长视距FID和FVD得分上分别比现有技术提高了48.6%和43.0%。

Conclusion: AutoScape能够生成高质量、长视距的驾驶场景视频，并在性能上超越了现有技术。

Abstract: This paper proposes AutoScape, a long-horizon driving scene generation
framework. At its core is a novel RGB-D diffusion model that iteratively
generates sparse, geometrically consistent keyframes, serving as reliable
anchors for the scene's appearance and geometry. To maintain long-range
geometric consistency, the model 1) jointly handles image and depth in a shared
latent space, 2) explicitly conditions on the existing scene geometry (i.e.,
rendered point clouds) from previously generated keyframes, and 3) steers the
sampling process with a warp-consistent guidance. Given high-quality RGB-D
keyframes, a video diffusion model then interpolates between them to produce
dense and coherent video frames. AutoScape generates realistic and
geometrically consistent driving videos of over 20 seconds, improving the
long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\% and
43.0\%, respectively.

</details>


### [75] [ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology](https://arxiv.org/abs/2510.20754)
*Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod*

Main category: cs.CV

TL;DR: 提出了一种基于注意力驱动的卷积神经网络(CNN)和视觉变换器(ViT)的特征融合方法，用于改进组织分割的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化病理图像分析在计算机辅助诊断中至关重要，深度学习方法在其中表现出色，尤其是在组织分割任务上。

Method: 提出了一种新颖的、基于注意力驱动的卷积神经网络(CNN)和视觉变换器(ViT)的特征融合方法，该方法在一个统一的双编码器模型中实现，以提高语义分割性能。

Result: 在GCPS数据集上达到了{\mu}IoU/{\mu}Dice分数76.79%/86.87%，在PUMA数据集上达到了64.93%/76.60%，优于最先进和基线模型。

Conclusion: 该方法在两个公开数据集上均取得了优于现有方法的性能，表明其在组织分割任务上的有效性。

Abstract: Automated histopathological image analysis plays a vital role in
computer-aided diagnosis of various diseases. Among developed algorithms, deep
learning-based approaches have demonstrated excellent performance in multiple
tasks, including semantic tissue segmentation in histological images. In this
study, we propose a novel approach based on attention-driven feature fusion of
convolutional neural networks (CNNs) and vision transformers (ViTs) within a
unified dual-encoder model to improve semantic segmentation performance.
Evaluation on two publicly available datasets showed that our model achieved
{\mu}IoU/{\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and
64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline
benchmarks. The implementation of our method is publicly available in a GitHub
repository: https://github.com/NimaTorbati/ACS-SegNet

</details>


### [76] [DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion](https://arxiv.org/abs/2510.20766)
*Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal*

Main category: cs.CV

TL;DR: DyPE是一种训练无关的方法，通过动态调整扩散Transformer的位置编码，使其能够生成远超训练分辨率的超高分辨率图像，且没有额外的采样成本。


<details>
  <summary>Details</summary>
Motivation: 由于自注意力机制的二次方扩展，在超高分辨率下训练扩散Transformer模型成本高昂。

Method: DyPE动态调整模型的位置编码，使其频率与生成过程的当前阶段相匹配，利用了扩散过程中固有的光谱进展。

Result: DyPE在多个基准测试中持续提高性能，在超高分辨率图像生成方面达到了最先进的保真度，并且在更高分辨率下效果更明显。例如，使用FLUX可以生成1600万像素的图像。

Conclusion: DyPE能够让预训练的扩散Transformer在没有额外采样成本的情况下，以远超其训练数据的分辨率合成图像。

Abstract: Diffusion Transformer models can generate images with remarkable fidelity and
detail, yet training them at ultra-high resolutions remains extremely costly
due to the self-attention mechanism's quadratic scaling with the number of
image tokens. In this paper, we introduce Dynamic Position Extrapolation
(DyPE), a novel, training-free method that enables pre-trained diffusion
transformers to synthesize images at resolutions far beyond their training
data, with no additional sampling cost. DyPE takes advantage of the spectral
progression inherent to the diffusion process, where low-frequency structures
converge early, while high-frequencies take more steps to resolve.
Specifically, DyPE dynamically adjusts the model's positional encoding at each
diffusion step, matching their frequency spectrum with the current stage of the
generative process. This approach allows us to generate images at resolutions
that exceed the training resolution dramatically, e.g., 16 million pixels using
FLUX. On multiple benchmarks, DyPE consistently improves performance and
achieves state-of-the-art fidelity in ultra-high-resolution image generation,
with gains becoming even more pronounced at higher resolutions. Project page is
available at https://noamissachar.github.io/DyPE/.

</details>


### [77] [AlphaFlow: Understanding and Improving MeanFlow Models](https://arxiv.org/abs/2510.20771)
*Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov*

Main category: cs.CV

TL;DR: MeanFlow 框架的优化存在冲突，导致收敛缓慢。我们提出了 $\alpha$-Flow，一种新的目标函数系列，通过课程学习策略解决此问题，并在 ImageNet 上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: MeanFlow 框架的成功机制尚不完全清楚，并且其优化过程存在固有的冲突，导致收敛缓慢。

Method: 将 MeanFlow 目标函数分解为轨迹流匹配和轨迹一致性两部分，并通过梯度分析发现它们之间存在强烈的负相关。在此基础上，提出了 $\alpha$-Flow，一个统一了轨迹流匹配、Shortcut Model 和 MeanFlow 的目标函数系列，并采用课程学习策略来解决优化冲突。

Result: 在 ImageNet-1K 256x256 数据集上，使用 vanilla DiT 主干网络进行训练，$\alpha$-Flow 在各种尺度和设置下始终优于 MeanFlow。最大的 $\alpha$-Flow-XL/2+ 模型取得了新的最先进成果，在 1-NFE 和 2-NFE 下的 FID 分别为 2.58 和 2.15。

Conclusion: $\alpha$-Flow 通过解耦优化冲突并采用课程学习策略，能够实现更好的收敛性，并在图像生成任务上取得优于 MeanFlow 的性能。

Abstract: MeanFlow has recently emerged as a powerful framework for few-step generative
modeling trained from scratch, but its success is not yet fully understood. In
this work, we show that the MeanFlow objective naturally decomposes into two
parts: trajectory flow matching and trajectory consistency. Through gradient
analysis, we find that these terms are strongly negatively correlated, causing
optimization conflict and slow convergence. Motivated by these insights, we
introduce $\alpha$-Flow, a broad family of objectives that unifies trajectory
flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting
a curriculum strategy that smoothly anneals from trajectory flow matching to
MeanFlow, $\alpha$-Flow disentangles the conflicting objectives, and achieves
better convergence. When trained from scratch on class-conditional ImageNet-1K
256x256 with vanilla DiT backbones, $\alpha$-Flow consistently outperforms
MeanFlow across scales and settings. Our largest $\alpha$-Flow-XL/2+ model
achieves new state-of-the-art results using vanilla DiT backbones, with FID
scores of 2.58 (1-NFE) and 2.15 (2-NFE).

</details>


### [78] [CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image](https://arxiv.org/abs/2510.20776)
*Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao*

Main category: cs.CV

TL;DR: Cupid是一个单张2D图像生成式3D重建方法，可以推断相机位姿、3D形状和纹理。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够从单张2D图像准确推断相机位姿、3D形状和纹理的新型生成式3D重建方法。

Method: Cupid将3D重建视为从学习到的3D对象分布的条件采样过程，联合生成体素和像素-体素对应关系。它采用两阶段流匹配流程：粗略阶段生成初始3D几何和用于位姿恢复的2D投影；精炼阶段整合位姿对齐的图像特征以增强结构保真度和外观细节。

Result: Cupid在PSNR上提升超过3dB，Chamfer Distance降低超过10%，在位姿估计精度上与单目估计器相当，并在视觉保真度上优于基线3D生成模型。

Conclusion: Cupid在单张2D图像3D重建方面取得了显著的性能提升，在准确性、细节和视觉效果方面均优于现有方法。

Abstract: This work proposes a new generation-based 3D reconstruction method, named
Cupid, that accurately infers the camera pose, 3D shape, and texture of an
object from a single 2D image. Cupid casts 3D reconstruction as a conditional
sampling process from a learned distribution of 3D objects, and it jointly
generates voxels and pixel-voxel correspondences, enabling robust pose and
shape estimation under a unified generative framework. By representing both
input camera poses and 3D shape as a distribution in a shared 3D latent space,
Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that
produces initial 3D geometry with associated 2D projections for pose recovery;
and (2) a refinement stage that integrates pose-aligned image features to
enhance structural fidelity and appearance details. Extensive experiments
demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3
dB PSNR gain and an over 10% Chamfer Distance reduction, while matching
monocular estimators on pose accuracy and delivering superior visual fidelity
over baseline 3D generative models. For an immersive view of the 3D results
generated by Cupid, please visit cupid3d.github.io.

</details>


### [79] [ARGenSeg: Image Segmentation with Autoregressive Image Generation Model](https://arxiv.org/abs/2510.20803)
*Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou*

Main category: cs.CV

TL;DR: ARGenSeg是一个新颖的基于自回归生成图像分割范式，它在统一的框架内实现了多模态理解和像素级感知。它不依赖于离散表示或语义提示，而是利用MLLM生成视觉标记，并使用通用的VQ-VAE将其解码为图像，从而实现完全依赖于MLLM的像素级理解的分割。此外，该方法还采用了一种 next-scale-prediction 策略来并行生成所需的视觉标记，以减少推理延迟。实验证明，ARGenSeg 在多个分割数据集上超越了现有的最先进方法，并且在推理速度上有了显著的提升，同时保持了强大的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图像分割集成到多模态大语言模型（MLLMs）中时，通常采用边界点表示或专门的分割头。这些方法依赖于离散表示或语义提示，并输入到特定任务的解码器中，这限制了MLLM捕获细粒度视觉细节的能力。为了解决这些挑战，我们需要一种新的方法。

Method: 提出了一种新颖的基于自回归生成（ARGenSeg）的图像分割范式。该方法利用MLLM输出视觉标记，并使用通用的VQ-VAE将它们解码为图像，使分割完全依赖于MLLM的像素级理解。为了减少推理延迟，采用了next-scale-prediction策略并行生成所需的视觉标记。

Result: ARGenSeg 在多个分割数据集上超越了现有的最先进方法，并且在推理速度上有了显著的提升，同时保持了强大的理解能力。

Conclusion: ARGenSeg 是一种新颖的、基于生成的方法，它通过将图像分割集成到多模态大语言模型（MLLMs）中，实现了对图像的像素级理解和细粒度细节的捕获。该方法通过利用MLLM生成视觉标记并将其解码为图像，解决了现有方法的局限性，并在性能和推理速度上取得了显著的改进。

Abstract: We propose a novel AutoRegressive Generation-based paradigm for image
Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level
perception within a unified framework. Prior works integrating image
segmentation into multimodal large language models (MLLMs) typically employ
either boundary points representation or dedicated segmentation heads. These
methods rely on discrete representations or semantic prompts fed into
task-specific decoders, which limits the ability of the MLLM to capture
fine-grained visual details. To address these challenges, we introduce a
segmentation framework for MLLM based on image generation, which naturally
produces dense masks for target objects. We leverage MLLM to output visual
tokens and detokenize them into images using an universal VQ-VAE, making the
segmentation fully dependent on the pixel-level understanding of the MLLM. To
reduce inference latency, we employ a next-scale-prediction strategy to
generate required visual tokens in parallel. Extensive experiments demonstrate
that our method surpasses prior state-of-the-art approaches on multiple
segmentation datasets with a remarkable boost in inference speed, while
maintaining strong understanding capabilities.

</details>


### [80] [Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers](https://arxiv.org/abs/2510.20807)
*Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed*

Main category: cs.CV

TL;DR: 提出了一种简单有效的纯Transformer模型用于自回归视频预测，将预测时间范围延长高达50%，并具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 受自回归大语言模型（LLMs）的性能和可扩展性的启发，Transformer模型在视觉领域取得了成功。本研究旨在探索Transformer在视频预测中的应用，特别是通过因果建模物理模拟，以解决现有方法在时空推理方面的不足。

Method: 提出了一种简单的端到端纯Transformer模型，使用连续像素空间表示进行视频预测，并比较了不同的时空自注意力机制。通过物理对象跟踪指标和物理模拟数据集上的无监督训练来分离时空推理。

Result: 与现有的潜在空间方法相比，该模型将物理上准确的预测时间范围延长了高达50%，同时在视频质量指标上保持了可比的性能。此外，通过探测模型，识别出能够准确估计PDE模拟参数的网络区域，并且这种能力可以泛化到估计分布外（OOD）的模拟参数。

Conclusion: 这项工作为通过简单、参数高效和可解释的方法进行基于注意力的视频时空建模提供了一个平台。

Abstract: Inspired by the performance and scalability of autoregressive large language
models (LLMs), transformer-based models have seen recent success in the visual
domain. This study investigates a transformer adaptation for video prediction
with a simple end-to-end approach, comparing various spatiotemporal
self-attention layouts. Focusing on causal modeling of physical simulations
over time; a common shortcoming of existing video-generative approaches, we
attempt to isolate spatiotemporal reasoning via physical object tracking
metrics and unsupervised training on physical simulation datasets. We introduce
a simple yet effective pure transformer model for autoregressive video
prediction, utilizing continuous pixel-space representations for video
prediction. Without the need for complex training strategies or latent
feature-learning components, our approach significantly extends the time
horizon for physically accurate predictions by up to 50% when compared with
existing latent-space approaches, while maintaining comparable performance on
common video quality metrics. In addition, we conduct interpretability
experiments to identify network regions that encode information useful to
perform accurate estimations of PDE simulation parameters via probing models,
and find that this generalizes to the estimation of out-of-distribution
simulation parameters. This work serves as a platform for further
attention-based spatiotemporal modeling of videos via a simple, parameter
efficient, and interpretable approach.

</details>


### [81] [Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation](https://arxiv.org/abs/2510.20812)
*Yuhan Liu,Lianhui Qin,Shengjie Wang*

Main category: cs.CV

TL;DR: Speculative Verdict (SV) is a training-free framework that uses lightweight 


<details>
  <summary>Details</summary>
Motivation: Large Vision-Language Models (VLMs) struggle with information-rich images 

Method: SV combines multiple small draft experts (small VLMs) to generate 

Result: SV consistently improves performance on challenging benchmarks like 

Conclusion: SV achieves both error correction and cost-efficiency by 

Abstract: Large Vision-Language Models (VLMs) have achieved remarkable progress in
multimodal understanding, yet they struggle when reasoning over
information-intensive images that densely interleave textual annotations with
fine-grained graphical elements. The main challenges lie in precisely
localizing critical cues in dense layouts and multi-hop reasoning to integrate
dispersed evidence. We propose Speculative Verdict (SV), a training-free
framework inspired by speculative decoding that combines multiple lightweight
draft experts with a large verdict model. In the draft stage, small VLMs act as
draft experts to generate reasoning paths that provide diverse localization
candidates; in the verdict stage, a strong VLM synthesizes these paths to
produce the final answer, minimizing computational cost while recovering
correct answers. To further improve efficiency and accuracy, SV introduces a
consensus expert selection mechanism that forwards only high-agreement
reasoning paths to the verdict. Empirically, SV achieves consistent gains on
challenging information-intensive and high-resolution visual question answering
benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.
By synthesizing correct insights from multiple partially accurate reasoning
paths, SV achieves both error correction and cost-efficiency compared to large
proprietary models or training pipelines. Code is available at
https://github.com/Tinaliu0123/speculative-verdict

</details>


### [82] [SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution](https://arxiv.org/abs/2510.20814)
*Ritik Shah,Marco F Duarte*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SpectraMorph的物理引导式自监督融合框架，用于解决高光谱图像的空间分辨率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在融合高光谱与多光谱图像时，其回归器缺乏可解释性，并且在多的光谱图像波段很少时性能会下降。因此，需要一种更具可解释性且鲁棒性更强的方法。

Method: SpectraMorph框架通过一个解混环节来实现。它从低分辨率高光谱图像中提取端元光谱，并使用一个紧凑的多层感知机从多光谱图像预测类似丰度的图。然后，通过线性混合重建光谱，并利用多光谱传感器的光谱响应函数以自监督方式进行训练。

Result: SpectraMorph能够生成可解释的中间结果，训练时间不到一分钟，并且即使在只有一个波段（全色）的多光谱图像时也表现出鲁棒性。在合成和真实数据集上的实验表明，SpectraMorph的性能优于现有的无监督/自监督基线方法，并且与监督基线方法相比也具有很强的竞争力。

Conclusion: SpectraMorph是一种物理引导式自监督融合框架，通过引入解混环节和结构化潜在空间，解决了高光谱超分辨率问题。该方法具有可解释性、高效性、鲁棒性，并在实验中取得了优于现有方法的性能。

Abstract: Hyperspectral sensors capture dense spectra per pixel but suffer from low
spatial resolution, causing blurred boundaries and mixed-pixel effects.
Co-registered companion sensors such as multispectral, RGB, or panchromatic
cameras provide high-resolution spatial detail, motivating hyperspectral
super-resolution through the fusion of hyperspectral and multispectral images
(HSI-MSI). Existing deep learning based methods achieve strong performance but
rely on opaque regressors that lack interpretability and often fail when the
MSI has very few bands. We propose SpectraMorph, a physics-guided
self-supervised fusion framework with a structured latent space. Instead of
direct regression, SpectraMorph enforces an unmixing bottleneck: endmember
signatures are extracted from the low-resolution HSI, and a compact multilayer
perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed
by linear mixing, with training performed in a self-supervised manner via the
MSI sensor's spectral response function. SpectraMorph produces interpretable
intermediates, trains in under a minute, and remains robust even with a
single-band (pan-chromatic) MSI. Experiments on synthetic and real-world
datasets show SpectraMorph consistently outperforming state-of-the-art
unsupervised/self-supervised baselines while remaining very competitive against
supervised baselines.

</details>


### [83] [Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge](https://arxiv.org/abs/2510.20819)
*Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot*

Main category: cs.CV

TL;DR: 我们提出了潜变量扩散桥模型（LDDBM），一个通用的跨模态翻译框架，它在共享的潜在空间中操作，无需对齐维度，并支持任意模态对。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在跨模态翻译方面存在局限性，例如需要共享维度、高斯先验和特定模态的架构。我们旨在提出一个更通用的框架。

Method: 我们提出了潜变量扩散桥模型（LDDBM），它使用潜变量扩展去噪扩散桥模型。该方法在共享的潜在空间中操作，引入对比度对齐损失来保证语义一致性，并设计了一个域无关的编码器-解码器架构来进行潜在空间中的噪声预测。此外，还提出了预测损失来指导训练，并探索了改进训练稳定性的策略。

Result: LDDBM 在多视图到 3D 形状生成、图像超分辨率和多视图场景合成等多种跨模态翻译任务上表现出色，并且其有效性得到了实验和消融研究的验证。

Conclusion: LDDBM 框架在通用跨模态翻译方面取得了新的进展，为该领域设定了一个强大的基准。

Abstract: Recent advances in generative modeling have positioned diffusion models as
state-of-the-art tools for sampling from complex data distributions. While
these models have shown remarkable success across single-modality domains such
as images and audio, extending their capabilities to Modality Translation (MT),
translating information across different sensory modalities, remains an open
challenge. Existing approaches often rely on restrictive assumptions, including
shared dimensionality, Gaussian source priors, and modality-specific
architectures, which limit their generality and theoretical grounding. In this
work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a
general-purpose framework for modality translation based on a latent-variable
extension of Denoising Diffusion Bridge Models. By operating in a shared latent
space, our method learns a bridge between arbitrary modalities without
requiring aligned dimensions. We introduce a contrastive alignment loss to
enforce semantic consistency between paired samples and design a
domain-agnostic encoder-decoder architecture tailored for noise prediction in
latent space. Additionally, we propose a predictive loss to guide training
toward accurate cross-domain translation and explore several training
strategies to improve stability. Our approach supports arbitrary modality pairs
and performs strongly on diverse MT tasks, including multi-view to 3D shape
generation, image super-resolution, and multi-view scene synthesis.
Comprehensive experiments and ablations validate the effectiveness of our
framework, establishing a new strong baseline in general modality translation.
For more information, see our project page:
https://sites.google.com/view/lddbm/home.

</details>


### [84] [LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas](https://arxiv.org/abs/2510.20820)
*Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: LayerComposer是一个交互式框架，用于个性化、多主体文本到图像生成，解决了现有模型在空间构图和多主体扩展性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化生成模型在空间构图和多主体生成方面存在局限性。

Method: 提出了一种新的分层画布表示，将每个主体放在单独的图层上，并引入了一种锁定机制，以在高保真度下保持选定的图层，同时允许其他图层灵活适应周围环境。

Result: 实验证明，LayerComposer在空间控制和身份保持方面优于现有最先进的多主体个性化图像生成方法。

Conclusion: LayerComposer通过分层画布和锁定机制，实现了对个性化多主体文本到图像生成的空间构图和身份保持的有效控制。

Abstract: Despite their impressive visual fidelity, existing personalized generative
models lack interactive control over spatial composition and scale poorly to
multiple subjects. To address these limitations, we present LayerComposer, an
interactive framework for personalized, multi-subject text-to-image generation.
Our approach introduces two main contributions: (1) a layered canvas, a novel
representation in which each subject is placed on a distinct layer, enabling
occlusion-free composition; and (2) a locking mechanism that preserves selected
layers with high fidelity while allowing the remaining layers to adapt flexibly
to the surrounding context. Similar to professional image-editing software, the
proposed layered canvas allows users to place, resize, or lock input subjects
through intuitive layer manipulation. Our versatile locking mechanism requires
no architectural changes, relying instead on inherent positional embeddings
combined with a new complementary data sampling strategy. Extensive experiments
demonstrate that LayerComposer achieves superior spatial control and identity
preservation compared to the state-of-the-art methods in multi-subject
personalized image generation.

</details>


### [85] [HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives](https://arxiv.org/abs/2510.20822)
*Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu*

Main category: cs.CV

TL;DR: HoloCine是一个先进的文本到视频模型，能够生成连贯、多镜头的叙事性视频，弥合了当前模型在叙事连贯性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的文本到视频模型在生成单个视频片段方面表现出色，但在创作连贯的多镜头叙事方面存在不足，而这正是讲故事的本质。HoloCine旨在弥合这一“叙事鸿沟”。

Method: HoloCine采用创新的架构，通过“窗口交叉注意力”机制将文本提示精确地定位到特定的镜头，并利用“稀疏跨镜头自注意力”模式（镜头内密集，镜头间稀疏）来实现分钟级生成所需的效率，从而实现精确的导演控制和全局一致性。

Result: HoloCine在叙事连贯性方面达到了新的最先进水平，并展现出惊人的涌现能力，包括对角色和场景的持久记忆，以及对电影制作技巧的直观理解。

Conclusion: HoloCine标志着从视频片段合成向自动化电影制作的重大转变，使得端到端的电影创作成为可能。

Abstract: State-of-the-art text-to-video models excel at generating isolated clips but
fall short of creating the coherent, multi-shot narratives, which are the
essence of storytelling. We bridge this "narrative gap" with HoloCine, a model
that generates entire scenes holistically to ensure global consistency from the
first shot to the last. Our architecture achieves precise directorial control
through a Window Cross-Attention mechanism that localizes text prompts to
specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within
shots but sparse between them) ensures the efficiency required for minute-scale
generation. Beyond setting a new state-of-the-art in narrative coherence,
HoloCine develops remarkable emergent abilities: a persistent memory for
characters and scenes, and an intuitive grasp of cinematic techniques. Our work
marks a pivotal shift from clip synthesis towards automated filmmaking, making
end-to-end cinematic creation a tangible future. Our code is available at:
https://holo-cine.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [86] [DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse](https://arxiv.org/abs/2510.19858)
*Jindi Wang,Yidi Zhang,Zhaoxing Li*

Main category: cs.CL

TL;DR: 本研究提出了DeBERTa-KC模型，用于自动分类在线科学学习讨论中的知识构建（KC）级别，并在YouTube科学频道的数据上进行了验证，取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了自动对在线科学学习讨论中的知识构建（KC）级别进行分类，以实现对数字学习环境中的论述分析和对认知参与的评估。

Method: 利用YouTube科学频道收集的评论数据，创建了一个包含20,000个手动标注样本的语料库，涵盖了非KC、分享、探索和协商四个KC类别。在此基础上，提出了一种扩展DeBERTa-v3的模型（DeBERTa-KC），并结合了Focal Loss、Label Smoothing和R-Drop正则化技术，以解决类别不平衡问题并提高模型的泛化能力。研究还实现了一个端到端的、可复现的流水线，包括数据提取、标注、预处理、训练和评估。

Result: 在10折分层交叉验证中，DeBERTa-KC模型取得了0.836 ± 0.008的宏观F1分数，显著优于传统的和基于Transformer的基线模型（p<0.01）。具体类别结果显示，该模型对高阶认知参与（特别是在探索和协商讨论中）具有较高的敏感性。

Conclusion: 大型语言模型能够有效地捕捉非正式数字学习环境中知识构建的细微指标，为论述分析和开发用于评估认知参与的自动化工具提供了可扩展的、基于理论的方法。

Abstract: This study presents DeBERTa-KC, a transformer-based model for automatic
classification of knowledge construction (KC) levels in online science learning
discourse. Using comments collected from four popular YouTube science channels
(2022--2024), a balanced corpus of 20,000 manually annotated samples was
created across four KC categories: \textit{nonKC}, \textit{Share},
\textit{Explore}, and \textit{Negotiate}. The proposed model extends DeBERTa-v3
with Focal Loss, Label Smoothing, and R-Drop regularization to address class
imbalance and enhance generalization. A reproducible end-to-end pipeline was
implemented, encompassing data extraction, annotation, preprocessing, training,
and evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved
a macro-F1 of $0.836 \pm 0.008$, significantly out-performing both classical
and transformer baselines ($p<0.01$). Per-category results indicate strong
sensitivity to higher-order epistemic engagement, particularly in
\textit{Explore} and \textit{Negotiate} discourse. These findings demonstrate
that large language models can effectively capture nuanced indicators of
knowledge construction in informal digital learning environments, offering
scalable, theory-informed approaches to discourse analysis and the development
of automated tools for assessing epistemic engagement.

</details>


### [87] [An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics](https://arxiv.org/abs/2510.19866)
*Xincheng Liu*

Main category: cs.CL

TL;DR: 本研究评估了五种主流大型语言模型（ChatGPT、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2 和 Grok 4）以及三种结构化提示框架（TAG、RACE、COSTAR）生成的教学计划在教学健全性和可用性方面的表现。通过可读性、事实准确性、课程对齐和认知需求等计算指标进行分析，结果表明模型选择主要影响语言可访问性，而提示框架则主要影响事实准确性和教学完整性。


<details>
  <summary>Details</summary>
Motivation: 评估不同大型语言模型和提示框架生成的教学计划在教学健全性和可用性方面的表现，旨在为教育者提供关于如何有效利用AI生成教学内容的指导。

Method: 生成了15个关于高中物理主题“电磁波谱”的教学计划，并使用四项计算指标（可读性、事实准确性、课程对齐、认知需求）进行分析。

Result: DeepSeek生成的教学计划可读性最高（FKGL = 8.64），Claude生成的最不具可读性（FKGL = 19.89）。RACE框架生成的教学计划幻觉指数最低，并与NGSS课程标准有更高的偶然对齐。所有模型生成的教学计划学习目标主要集中在布鲁姆分类法的“记忆”和“理解”层级，高阶动词有限。

Conclusion: 教学计划的可读性主要受模型设计影响，而教学可靠性和课程对齐则更多地取决于提示框架。结合可读性优化的模型、RACE框架以及包含物理概念、课程标准和高阶目标的明确清单，是生成教学计划的最优配置。

Abstract: This study evaluates the pedagogical soundness and usability of AI-generated
lesson plans across five leading large language models: ChatGPT (GPT-5), Claude
Sonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice,
three structured prompt frameworks were tested: TAG (Task, Audience, Goal),
RACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective,
Style, Tone, Audience, Response Format).
  Fifteen lesson plans were generated for a single high-school physics topic,
The Electromagnetic Spectrum. The lesson plans were analyzed through four
automated computational metrics: (1) readability and linguistic complexity, (2)
factual accuracy and hallucination detection, (3) standards and curriculum
alignment, and (4) cognitive demand of learning objectives.
  Results indicate that model selection exerted the strongest influence on
linguistic accessibility, with DeepSeek producing the most readable teaching
plan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89).
  The prompt framework structure most strongly affected the factual accuracy
and pedagogical completeness, with the RACE framework yielding the lowest
hallucination index and the highest incidental alignment with NGSS curriculum
standards. Across all models, the learning objectives in the fifteen lesson
plans clustered at the Remember and Understand tiers of Bloom's taxonomy. There
were limited higher-order verbs in the learning objectives extracted.
  Overall, the findings suggest that readability is significantly governed by
model design, while instructional reliability and curricular alignment depend
more on the prompt framework. The most effective configuration for lesson plans
identified in the results was to combine a readability-optimized model with the
RACE framework and an explicit checklist of physics concepts, curriculum
standards, and higher-order objectives.

</details>


### [88] [From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model](https://arxiv.org/abs/2510.19871)
*Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo*

Main category: cs.CL

TL;DR: 离散扩散模型在视觉-语言任务中展现出潜力，但训练-推理不匹配导致生成错误级联。ReDiff通过主动修正框架解决此问题，通过两阶段训练（修正合成错误和在线自我修正）使模型能够识别和纠正自身错误，从而打破错误级联，提高生成内容的一致性和事实准确性，实现稳定高效的并行生成。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在视觉-语言任务中存在训练-推理不匹配问题，导致生成过程中错误级联，影响生成质量。

Method: 提出ReDiff框架，将生成过程从被动去噪转变为主动修正。通过两阶段训练：1. 修正合成错误；2. 在线自我修正，模型学习纠正自身生成的错误草稿。

Result: ReDiff显著提高了生成内容的一致性和事实准确性，实现了稳定高效的并行生成，优于传统去噪方法。

Conclusion: ReDiff通过引入主动修正机制，有效解决了离散扩散模型中的训练-推理不匹配问题，提高了生成质量和稳定性。

Abstract: Discrete diffusion models have emerged as a promising direction for
vision-language tasks, offering bidirectional context modeling and theoretical
parallelization. However, their practical application is severely hindered by a
train-inference discrepancy, which leads to catastrophic error cascades:
initial token errors during parallel decoding pollute the generation context,
triggering a chain reaction of compounding errors and leading to syntactic
errors and semantic hallucinations. To address this fundamental challenge, we
reframe the generation process from passive denoising to active refining. We
introduce ReDiff, a refining-enhanced diffusion framework that teaches the
model to identify and correct its own errors. Our approach features a two-stage
training process: first, we instill a foundational revision capability by
training the model to revise synthetic errors; second, we implement a novel
online self-correction loop where the model is explicitly trained to revise its
own flawed drafts by learning from an expert's corrections. This mistake-driven
learning endows the model with the crucial ability to revisit and refine its
already generated output, effectively breaking the error cascade. Extensive
experiments demonstrate that ReDiff significantly improves the coherence and
factual accuracy of generated content, enabling stable and efficient parallel
generation far superior to traditional denoising methods. Our codes and models
are available at https://rediff-hku.github.io/.

</details>


### [89] [Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention](https://arxiv.org/abs/2510.19875)
*J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard*

Main category: cs.CL

TL;DR: LLMs在处理长上下文时，传统的可解释性方法因内存消耗巨大而失效。本文提出了一种名为Sparse Tracing的新技术，利用动态稀疏注意力机制，在近线性时间和线性空间复杂度内实现了对长上下文注意力的有效分析，能够识别关键的“思想锚点”并大幅修剪不必要的 token 交互，使在消费级 GPU 上进行长上下文可解释性分析成为可能。


<details>
  <summary>Details</summary>
Motivation: 传统的机制可解释性技术在分析 LLMs 的长上下文注意力时，内存需求随上下文长度呈二次方增长，导致在超过 100,000 个 token 时无法使用。需要一种能够高效分析长上下文注意力模式的技术。

Method: 提出了一种名为 Sparse Tracing 的新颖技术，该技术利用动态稀疏注意力机制。在此基础上，提出了一种名为 Stream 的可编译分层剪枝算法，该算法能在近线性时间 $O(T 	ext{ log } T)$ 和线性空间 $O(T)$ 内估计每个 head 的稀疏注意力掩码，实现了单次遍历即可进行大规模分析。Stream 采用类似二分查找的方法来保留每个查询的前 k 个关键块，同时保持模型生成下一个 token 的行为。该方法应用于长链式思考（chain-of-thought）推理过程，识别思想锚点，并修剪了 97-99% 的 token 交互。在 RULER 基准测试中，Stream 保留了关键的检索路径，同时丢弃了 90-96% 的交互，并揭示了从“针”到输出的逐层路径。

Result: Stream 算法在保留模型核心功能的同时，能够大幅度（90-99%）修剪 token 交互，识别长链式思考中的关键“思想锚点”，并揭示信息在模型层级间的流动路径。该方法在 RULER 基准测试中表现出有效性。

Conclusion: Sparse Tracing 技术提供了一种实用的、可直接替换的工具，用于分析长上下文 LLMs 中的注意力模式和信息流，无需庞大的缓存。通过使长上下文可解释性在消费级 GPU 上成为可能，Sparse Tracing 有助于普及对链式思考过程的监控。

Abstract: As Large Language Models (LLMs) scale to million-token contexts, traditional
Mechanistic Interpretability techniques for analyzing attention scale
quadratically with context length, demanding terabytes of memory beyond 100,000
tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic
sparse attention to efficiently analyze long context attention patterns. We
present Stream, a compilable hierarchical pruning algorithm that estimates
per-head sparse attention masks in near-linear time $O(T \log T)$ and linear
space $O(T)$, enabling one-pass interpretability at scale. Stream performs a
binary-search-style refinement to retain only the top-$k$ key blocks per query
while preserving the model's next-token behavior. We apply Stream to long
chain-of-thought reasoning traces and identify thought anchors while pruning
97-99\% of token interactions. On the RULER benchmark, Stream preserves
critical retrieval paths while discarding 90-96\% of interactions and exposes
layer-wise routes from the needle to output. Our method offers a practical
drop-in tool for analyzing attention patterns and tracing information flow
without terabytes of caches. By making long context interpretability feasible
on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring.
Code is available at https://anonymous.4open.science/r/stream-03B8/.

</details>


### [90] [Automated HIV Screening on Dutch EHR with Large Language Models](https://arxiv.org/abs/2510.19879)
*Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 利用大型语言模型分析电子健康记录中的非结构化文本，以提高 HIV 筛查的准确性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的普及为 HIV 筛查提供了新的机会，但现有研究主要关注结构化数据，忽略了可能包含重要风险信息的临床笔记等非结构化文本数据。

Method: 提出一个利用大型语言模型（LLM）分析非结构化 EHR 文本的新型流程，以确定患者是否有资格接受进一步的 HIV 检测。

Result: 在鹿特丹伊拉斯姆斯大学医学中心（Erasmus University Medical Center Rotterdam）的临床数据上进行的实验结果表明，该流程在保持低假阴性率的同时，实现了高准确性。

Conclusion: 该研究提出了一种创新的方法，通过分析非结构化 EHR 文本，可以有效地进行 HIV 筛查和早期诊断，有助于降低 HIV 的传播。

Abstract: Efficient screening and early diagnosis of HIV are critical for reducing
onward transmission. Although large scale laboratory testing is not feasible,
the widespread adoption of Electronic Health Records (EHRs) offers new
opportunities to address this challenge. Existing research primarily focuses on
applying machine learning methods to structured data, such as patient
demographics, for improving HIV diagnosis. However, these approaches often
overlook unstructured text data such as clinical notes, which potentially
contain valuable information relevant to HIV risk. In this study, we propose a
novel pipeline that leverages a Large Language Model (LLM) to analyze
unstructured EHR text and determine a patient's eligibility for further HIV
testing. Experimental results on clinical data from Erasmus University Medical
Center Rotterdam demonstrate that our pipeline achieved high accuracy while
maintaining a low false negative rate.

</details>


### [91] [An Expert-grounded benchmark of General Purpose LLMs in LCA](https://arxiv.org/abs/2510.19886)
*Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard*

Main category: cs.CL

TL;DR: 现有关于在生命周期评估（LCA）中使用大型语言模型（LLM）的系统性证据有限，本研究提出了首个基于专家基准的LLM评估，以解决缺乏标准化评估框架的问题。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在生命周期评估（LCA）中的可靠性、稳健性和可用性，并解决该领域缺乏标准化评估框架和明确的正确答案或共识协议的问题。

Method: 评估了11个通用LLM（包括商业和开源模型）在22个LCA相关任务上的表现，并由17名经验丰富的从业者根据科学准确性、解释质量、稳健性、可验证性和指令遵循性等标准对模型输出了168份专家评审。

Result: 37%的LLM响应包含不准确或误导性信息。虽然许多模型在准确性和解释质量方面被评为一般或良好，但幻觉率差异很大（高达40%的模型产生幻觉引文）。开源模型在准确性和解释质量等标准上表现优于或媲美闭源模型。

Conclusion: 在LCA中对LLM的初步应用存在风险，特别是在将LLM视为自由格式的预言机时，但也显示出在解释质量和减轻简单任务劳动强度方面的益处。未使用基础机制的通用LLM的使用存在局限性。

Abstract: Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

</details>


### [92] [Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities](https://arxiv.org/abs/2510.19892)
*Nishant Balepur,Dang Nguyen,Dayeon Ki*

Main category: cs.CL

TL;DR: MLMs 评估应采用基于游戏的评估方法，以克服现有基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有 MLM 评估方法（单一基准或人为/模型比较）存在局限性，无法全面评估 MLM 能力，且存在主观、昂贵和易被利用的问题。

Method: 提出基于游戏的评估方法，以游戏规则的客观性和竞争性来全面评估 MLM 能力。具体以 Dixit 卡牌游戏为例，评估 MLM 生成描述以迷惑部分玩家的能力。

Result: 通过在 Dixit 游戏中进行的定量实验，MLM 的 Dixit 获胜率排名与流行 MLM 基准的排名高度相关。同时，人类与 MLM 在 Dixit 游戏中的对抗揭示了两者在策略上的差异以及 MLM 在推理方面可改进之处。

Conclusion: 基于游戏的评估方法可以为 MLM 提供一个更全面、更客观的评估框架，并且能够揭示 MLM 在推理和策略方面的具体表现和改进空间。

Abstract: Multi-modal large language models (MLMs) are often assessed on static,
individual benchmarks -- which cannot jointly assess MLM capabilities in a
single task -- or rely on human or model pairwise comparisons -- which is
highly subjective, expensive, and allows models to exploit superficial
shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these
issues, we propose game-based evaluations to holistically assess MLM
capabilities. Games require multiple abilities for players to win, are
inherently competitive, and are governed by fix, objective rules, and makes
evaluation more engaging, providing a robust framework to address the
aforementioned challenges. We manifest this evaluation specifically through
Dixit, a fantasy card game where players must generate captions for a card that
trick some, but not all players, into selecting the played card. Our
quantitative experiments with five MLMs show Dixit win-rate rankings are
perfectly correlated with those on popular MLM benchmarks, while games between
human and MLM players in Dixit reveal several differences between agent
strategies and areas of improvement for MLM reasoning.

</details>


### [93] [Large Language Model enabled Mathematical Modeling](https://arxiv.org/abs/2510.19895)
*Guoyun Zhang*

Main category: cs.CL

TL;DR: LLM（特别是DeepSeek-R1）可以帮助弥合优化建模中的公式化差距，克服传统方法的局限性，并解决现有LLM（如GPT-4）的高成本和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法需要领域专业知识来构建数学模型，这在时间和成本上都非常昂贵。LLM有潜力自动完成这一过程，从而提高效率和可及性。

Method: 评估DeepSeek-R1模型在四个OR基准（NL4OPT、IndustryOR、EasyLP和ComplexOR）上的表现。采用LLM-as-a-Judge、少样本学习（FSL）、工具调用和多智能体框架等技术来减少幻觉并提高准确性。

Result: DeepSeek-R1在OR基准测试中表现出潜力，但幻觉仍然是一个挑战。所采用的缓解策略有助于提高配方准确性并减少幻觉。

Conclusion: LLM，特别是像DeepSeek-R1这样经过优化的模型，有潜力革新优化建模领域。通过仔细的策略选择和缓解技术，可以克服幻觉等挑战，从而实现更广泛的应用。

Abstract: The integration of Large Language Models (LLMs) with optimization modeling
offers a promising avenue for advancing decision-making in operations research
(OR). Traditional optimization methods,such as linear programming, mixed
integer programming, and simulation depend heavily on domain expertise to
translate real-world problems into solvable mathematical models. While solvers
like Gurobi and COPT are powerful, expert input remains essential for defining
objectives, constraints, and variables. This research investigates the
potential of LLMs, specifically the DeepSeek-R1 model, to bridge this
formulation gap using natural language understanding and code generation.
Although prior models like GPT-4, Claude, and Bard have shown strong
performance in NLP and reasoning tasks, their high token costs and tendency
toward hallucinations limit real-world applicability in supply chain contexts.
In contrast, DeepSeek-R1, a cost-efficient and high-performing model trained
with reinforcement learning, presents a viable alternative. Despite its success
in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied
OR scenarios remains under explored. This study systematically evaluates
DeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and
ComplexOR. Our methodology includes baseline assessments, the development of a
hallucination taxonomy, and the application of mitigation strategies like
LLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent
Framework. These techniques aim to reduce hallucinations, enhance formulation
accuracy, and better align model outputs with user intent.

</details>


### [94] [Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation](https://arxiv.org/abs/2510.19897)
*Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka*

Main category: cs.CL

TL;DR: LLM代理可以通过无参数更新的记忆增强框架，利用标记数据和LLM生成的评论来学习分类函数，在各种任务上取得了显著的准确性提升，并引入了“suggestibility”指标来解释模型行为。


<details>
  <summary>Details</summary>
Motivation: 传统模型微调成本高、不灵活且不透明，因此需要一种新的方法来训练LLM代理。

Method: 提出了一种记忆增强框架，该框架结合了标记数据和LLM生成的评论。该框架使用情景记忆来存储实例级别的评论，并使用语义记忆将这些评论提炼成可重用的、任务级别的指导。

Result: 与仅依赖标签的检索式（RAG风格）基线相比，该框架在各种任务上的准确性提高了24.8%。此外，研究还揭示了OpenAI和开源模型在处理事实导向与偏好导向数据方面的行为差异，并引入了一个名为“suggestibility”的新指标来衡量模型对不同监督表示的响应。

Conclusion: 记忆驱动的、反思式的学习有潜力用于构建更具适应性和可解释性的LLM代理。

Abstract: We investigate how agents built on pretrained large language models can learn
target classification functions from labeled examples without parameter
updates. While conventional approaches like fine-tuning are often costly,
inflexible, and opaque, we propose a memory-augmented framework that leverages
both labeled data and LLM-generated critiques. Our framework uses episodic
memory to store instance-level critiques-capturing specific past
experiences-and semantic memory to distill these into reusable, task-level
guidance. Across a diverse set of tasks, incorporating critiques yields up to a
24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines
that rely only on labels. Through extensive empirical evaluation, we uncover
distinct behavioral differences between OpenAI and opensource models,
particularly in how they handle fact-oriented versus preference-based data. To
interpret how models respond to different representations of supervision
encoded in memory, we introduce a novel metric, suggestibility. This helps
explain observed behaviors and illuminates how model characteristics and memory
strategies jointly shape learning dynamics. Our findings highlight the promise
of memory-driven, reflective learning for building more adaptive and
interpretable LLM agents.

</details>


### [95] [LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation](https://arxiv.org/abs/2510.19967)
*Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang*

Main category: cs.CL

TL;DR: LyriCAR是一个新颖的、全自动的歌词翻译框架，通过引入难度感知课程设计器和自适应课程策略，提高了翻译质量并加速了收敛。


<details>
  <summary>Details</summary>
Motivation: 现有的歌词翻译方法依赖于手工规则和句子级建模，难以捕捉音乐和语言模式，并且在处理需要跨行连贯性和全局押韵的段落时泛化能力有限。

Method: LyriCAR框架采用难度感知课程设计器和自适应课程策略，以全自动的方式进行歌词翻译，并逐步增加翻译难度，以优化训练过程。

Result: 在EN-ZH歌词翻译任务上，LyriCAR在标准翻译指标和多维度奖励分数上均取得了最先进的成果，并且自适应课程策略将训练步骤减少了近40%，同时保持了优越的性能。

Conclusion: LyriCAR框架通过其创新的课程学习方法，在歌词翻译任务上取得了显著的成功，提高了翻译质量，同时减少了训练时间和资源消耗。

Abstract: Lyric translation is a challenging task that requires balancing multiple
musical constraints. Existing methods often rely on hand-crafted rules and
sentence-level modeling, which restrict their ability to internalize
musical-linguistic patterns and to generalize effectively at the paragraph
level, where cross-line coherence and global rhyme are crucial. In this work,
we propose LyriCAR, a novel framework for controllable lyric translation that
operates in a fully unsupervised manner. LyriCAR introduces a difficulty-aware
curriculum designer and an adaptive curriculum strategy, ensuring efficient
allocation of training resources, accelerating convergence, and improving
overall translation quality by guiding the model with increasingly complex
challenges. Extensive experiments on the EN-ZH lyric translation task show that
LyriCAR achieves state-of-the-art results across both standard translation
metrics and multi-dimensional reward scores, surpassing strong baselines.
Notably, the adaptive curriculum strategy reduces training steps by nearly 40%
while maintaining superior performance. Code, data and model can be accessed at
https://github.com/rle27/LyriCAR.

</details>


### [96] [LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation](https://arxiv.org/abs/2510.19988)
*Xin Lian,Kenneth D. Forbus*

Main category: cs.CL

TL;DR: 本文提出了一种混合方法，结合了大型语言模型（LLMs）的广泛覆盖能力和符号自然语言理解（NLU）系统的可解释推理能力，用于从常识科学文本中提取和解释数量及因果定律。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成的事实中容易出现幻觉和输出结构不一致的问题；而符号NLU系统虽然可解释且能进行准确推理，但覆盖范围有限且需要专门的知识。本文旨在结合两者的优点。

Method: 利用LLMs进行释义和文本简化以扩大覆盖范围，并作为填补知识空白的信息源；利用符号NLU生成用于推理和增量学习的结构化关系表示。

Result: 在提取和解释数量及因果定律的任务上，与仅使用符号NLU或仅使用LLMs的流水线相比，混合方法的效果显著更优。

Conclusion: 混合方法在常识科学文本的理解和信息提取方面优于单独使用符号NLU或LLMs的方法，有望结合两者的优势。

Abstract: Despite the broad applicability of large language models (LLMs), their
reliance on probabilistic inference makes them vulnerable to errors such as
hallucination in generated facts and inconsistent output structure in natural
language understanding (NLU) tasks. By contrast, symbolic NLU systems provide
interpretable understanding grounded in curated lexicons, semantic resources,
and syntactic & semantic interpretation rules. They produce relational
representations that can be used for accurate reasoning and planning, as well
as incremental debuggable learning. However, symbolic NLU systems tend to be
more limited in coverage than LLMs and require scarce knowledge representation
and linguistics skills to extend and maintain. This paper explores a hybrid
approach that integrates the broad-coverage language processing of LLMs with
the symbolic NLU capabilities of producing structured relational
representations to hopefully get the best of both approaches. We use LLMs for
rephrasing and text simplification, to provide broad coverage, and as a source
of information to fill in knowledge gaps more automatically. We use symbolic
NLU to produce representations that can be used for reasoning and for
incremental learning. We evaluate this approach on the task of extracting and
interpreting quantities and causal laws from commonsense science texts, along
with symbolic- and LLM-only pipelines. Our results suggest that our hybrid
method works significantly better than the symbolic-only pipeline.

</details>


### [97] [A Fundamental Algorithm for Dependency Parsing (With Corrections)](https://arxiv.org/abs/2510.19996)
*Michael A. Covington*

Main category: cs.CL

TL;DR: 该算法逐词解析，将每个词尽可能早地附着到已有的树中，类似于人类大脑的解析方式。


<details>
  <summary>Details</summary>
Motivation: 提出一种与人类大脑解析方式相符的自然语言句法分析算法。

Method: 该算法逐词分析，一旦词语可以被附着，就立即进行附着，最终形成依存句法树。

Result: 该算法在最坏情况下的复杂度为O(n^3)，但在实际人类语言中，最坏情况只在n较小时出现。

Conclusion: 该算法提供了一种与人类大脑解析方式相似的依存句法分析方法，并分析了其复杂度。

Abstract: This paper presents a fundamental algorithm for parsing natural language
sentences into dependency trees. Unlike phrase-structure (constituency)
parsers, this algorithm operates one word at a time, attaching each word as
soon as it can be attached, corresponding to properties claimed for the parser
in the human brain. Like phrase-structure parsing, its worst-case complexity is
$O(n^3)$, but in human language, the worst case occurs only for small $n$.

</details>


### [98] [Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs](https://arxiv.org/abs/2510.20001)
*Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu*

Main category: cs.CL

TL;DR: LLMs在临床应用中展现出潜力，但现有评估方法（如MedQA）未能充分模拟真实临床决策。本文提出一个包含“临床背景”和“临床问题”两个维度的统一框架，以更全面地评估和指导LLMs在临床决策中的应用，并扩展了评估维度至效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有医学数据集（如MedQA）的简化问答形式未能充分代表真实世界的临床决策过程，因此需要新的评估方法来适应更复杂的临床环境。

Method: 提出一个包含“临床背景”和“临床问题”两个维度的统一框架，用于表征临床决策任务的难度。分析现有数据集和基准的设置。回顾了用于临床决策的方法（包括训练时和测试时技术）。扩展了评估维度，除了准确性，还考虑了效率和可解释性。

Result: 现有数据集和基准在所提出的二维框架下的设置被总结。分析了不同方法的适用性。评估结果显示，LLMs在效率和可解释性方面也需要进一步的考量。

Conclusion: 所提出的统一框架有助于阐明假设、标准化比较，并指导开发在临床上更有意义的LLMs。

Abstract: Large language models (LLMs) show promise for clinical use. They are often
evaluated using datasets such as MedQA. However, Many medical datasets, such as
MedQA, rely on simplified Question-Answering (Q\A) that underrepresents
real-world clinical decision-making. Based on this, we propose a unifying
paradigm that characterizes clinical decision-making tasks along two
dimensions: Clinical Backgrounds and Clinical Questions. As the background and
questions approach the real clinical environment, the difficulty increases. We
summarize the settings of existing datasets and benchmarks along two
dimensions. Then we review methods to address clinical decision-making,
including training-time and test-time techniques, and summarize when they help.
Next, we extend evaluation beyond accuracy to include efficiency,
explainability. Finally, we highlight open challenges. Our paradigm clarifies
assumptions, standardizes comparisons, and guides the development of clinically
meaningful LLMs.

</details>


### [99] [Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training](https://arxiv.org/abs/2510.20002)
*Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris*

Main category: cs.CL

TL;DR: 本文提出了一种名为希腊语嵌入模型（GEM）的新型Transformer模型系列，旨在解决希腊语，特别是法律领域，NLP研究面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有针对希腊语（尤其是法律等专业领域）的NLP模型存在架构多样性不足、上下文长度受限（如512 token）等问题，无法有效处理长文本。

Method: 1. 构建大规模希腊语语料库，重点进行高质量过滤和预处理，涵盖通用领域和法律领域。 2. 在此基础上，预训练并评估多种现代Transformer架构（如ELECTRA, ConvBERT, ModernBERT），并首次将其应用于希腊语。 3. 提出首个针对法律领域的双语（希腊语-英语）嵌入模型。

Result: 所提出的GEM-RoBERTa和GEM-ConvBERT模型在下游任务的实验中显著优于现有基线模型，证明了该方法的有效性。

Conclusion: 通过构建高质量语料库和应用现代Transformer架构，可以显著提升希腊语NLP，特别是法律领域的处理能力。

Abstract: The advancement of natural language processing for morphologically rich,
moderately-resourced languages like Modern Greek is often hindered by a
fragmented research landscape, a lack of architectural diversity and reliance
on limited context-length models. This is particularly true in specialized,
high-value domains such as law, where existing models are frequently confined
to early transformer architectures with a restrictive 512-token window,
insufficient for analyzing long legal documents. To address these challenges,
this paper presents Greek Embedding Models, a new family of transformer models
for Greek language built upon a foundation of extensive, quality-driven data
curation. We detail the construction of several large-scale Greek corpora,
emphasizing a rigorous, quality-based filtering and preprocessing methodology
to create high-value training datasets from both general-domain and specialized
legal sources. On this carefully curated foundation, we pre-train and
systematically evaluate a diverse suite of modern architectures, which has not
previously applied to Greek language, such as ELECTRA, ConvBERT and ModernBERT.
Furthermore, we propose the first bilingual Greek-English Embedding Models
tailored for the legal domain. The extensive experiments on downstream tasks
demonstrate that the new class of models establish the effectiveness of the
proposed approach, highlighting that the GEM-RoBERTa and GEM-ConvBERT models
significantly outperform existing baselines.

</details>


### [100] [Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models](https://arxiv.org/abs/2510.20033)
*David Dukić*

Main category: cs.CL

TL;DR: 本论文提出通过多任务模型、修改模型架构和监督式上下文微调等方法，改进预训练语言模型在序列标注任务上的迁移学习效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高预训练语言模型在序列标注任务上的迁移学习效果。

Method: 1. 引入多任务模型，加入来自独立文本处理系统的额外信号，以改进事件触发词检测任务的领域迁移。 2. 修改自回归大语言模型的架构，实现跨层双向信息流。 3. 利用生成式监督上下文微调框架，将自回归大语言模型作为文本生成器，并结合面向响应的适应策略。

Result: 提出的模型、方法和框架证明，通过有针对性的迁移学习范式进行调整时，预训练的神经网络语言模型在序列标注任务上能达到最佳性能。

Conclusion: 预训练神经网络语言模型通过有针对性的迁移学习范式进行调整时，在序列标注任务上表现最佳。

Abstract: This doctoral thesis improves the transfer learning for sequence labeling
tasks by adapting pre-trained neural language models. The proposed improvements
in transfer learning involve introducing a multi-task model that incorporates
an additional signal, a method based on architectural modifications in
autoregressive large language models, and a sequence labeling framework for
autoregressive large language models utilizing supervised in-context
fine-tuning combined with response-oriented adaptation strategies. The first
improvement is given in the context of domain transfer for the event trigger
detection task. The domain transfer of the event trigger detection task can be
improved by incorporating an additional signal obtained from a
domain-independent text processing system into a multi-task model. The second
improvement involves modifying the model's architecture. For that purpose, a
method is proposed to enable bidirectional information flow across layers of
autoregressive large language models. The third improvement utilizes
autoregressive large language models as text generators through a generative
supervised in-context fine-tuning framework. The proposed model, method, and
framework demonstrate that pre-trained neural language models achieve their
best performance on sequence labeling tasks when adapted through targeted
transfer learning paradigms.

</details>


### [101] [ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering](https://arxiv.org/abs/2510.20036)
*Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth*

Main category: cs.CL

TL;DR: LLM代理使用工具时面临工具冗余和上下文限制的挑战。ToolScope通过自动合并和修复工具（ToolScopeMerger）以及检索最相关的工具（ToolScopeRetriever）来解决这些问题，显著提高了工具选择的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在利用外部工具解决复杂任务时，会遇到真实世界工具集中存在的工具冗余、名称和描述重叠等问题，这会导致歧义并降低工具选择的准确性。此外，LLM严格的输入上下文限制也阻碍了它们对大型工具集的有效考量。

Method: 提出ToolScope，包括：1. ToolScopeMerger（带自动纠错功能），用于自动审计和修复工具合并，减少冗余。2. ToolScopeRetriever，用于为每个查询对工具进行排名和选择，将工具集压缩以适应上下文限制，同时不牺牲准确性。

Result: 在三种最先进的LLM和三个开源工具使用基准上进行的评估显示，工具选择准确性提高了8.38%至38.6%。

Conclusion: ToolScope能够有效地增强LLM的工具使用能力，通过解决工具冗余和上下文限制问题，提高了工具选择的准确性。

Abstract: Large language model (LLM) agents rely on external tools to solve complex
tasks, but real-world toolsets often contain redundant tools with overlapping
names and descriptions, introducing ambiguity and reducing selection accuracy.
LLMs also face strict input context limits, preventing efficient consideration
of large toolsets. To address these challenges, we propose ToolScope, which
includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and
fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and
select only the most relevant tools for each query, compressing toolsets to fit
within context limits without sacrificing accuracy. Evaluations on three
state-of-the-art LLMs and three open-source tool-use benchmarks show gains of
8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's
effectiveness in enhancing LLM tool use.

</details>


### [102] [From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge](https://arxiv.org/abs/2510.20043)
*Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque*

Main category: cs.CL

TL;DR: LLMs在低资源文化（如孟加拉语）方面表现不佳，需要文化定制数据和上下文感知架构。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言基准测试有所进步，但在低资源文化方面仍存在不足，特别是文化知识的细微差别。

Method: 创建了一个包含民间传统、烹饪艺术和地区方言的孟加拉语文化知识（BLanCK）数据集，并测试了多语言语言模型。

Result: 多语言语言模型在文化类别方面表现不佳，但在提供上下文后性能显著提高。

Conclusion: 上下文感知架构和经过文化定制的训练数据对于提高LLMs在低资源文化方面的能力至关重要。

Abstract: Recent progress in NLP research has demonstrated remarkable capabilities of
large language models (LLMs) across a wide range of tasks. While recent
multilingual benchmarks have advanced cultural evaluation for LLMs, critical
gaps remain in capturing the nuances of low-resource cultures. Our work
addresses these limitations through a Bengali Language Cultural Knowledge
(BLanCK) dataset including folk traditions, culinary arts, and regional
dialects. Our investigation of several multilingual language models shows that
while these models perform well in non-cultural categories, they struggle
significantly with cultural knowledge and performance improves substantially
across all models when context is provided, emphasizing context-aware
architectures and culturally curated training data.

</details>


### [103] [Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training](https://arxiv.org/abs/2510.20059)
*Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami*

Main category: cs.CL

TL;DR: 通过RLAIF和DPO技术，在小规模波斯语数据集上训练的语言模型在医学问答方面的推理能力得到了显著提升，且优于使用更大规模数据集训练的模型。


<details>
  <summary>Details</summary>
Motivation: 提高小语言模型在医学问答等专业领域的推理能力，特别是在波斯语等代表性不足的语言中。

Method: 使用RLAIF生成偏好-对，并结合DPO训练，通过提示教师和学生模型生成思维链（CoT）推理来构建数据集，以训练基线模型。

Result: 训练后的模型在波斯语医学推理能力上表现出色，并且在只使用相对较小的数据集的情况下，性能超过了使用约5700万个标记训练的gaokerena-V模型。

Conclusion: RLAIF和DPO等专注于推理的训练方法，在数据量有限的情况下，能够有效地开发特定领域的语言模型。

Abstract: Enhancing reasoning capabilities in small language models is critical for
specialized applications such as medical question answering, particularly in
underrepresented languages like Persian. In this study, we employ Reinforcement
Learning with AI Feedback (RLAIF) and Direct preference optimization (DPO) to
improve the reasoning skills of a general-purpose Persian language model. To
achieve this, we translated a multiple-choice medical question-answering
dataset into Persian and used RLAIF to generate rejected-preferred answer
pairs, which are essential for DPO training. By prompting both teacher and
student models to produce Chain-of-Thought (CoT) reasoning responses, we
compiled a dataset containing correct and incorrect reasoning trajectories.
This dataset, comprising 2 million tokens in preferred answers and 2.5 million
tokens in rejected ones, was used to train a baseline model, significantly
enhancing its medical reasoning capabilities in Persian. Remarkably, the
resulting model outperformed its predecessor, gaokerena-V, which was trained on
approximately 57 million tokens, despite leveraging a much smaller dataset.
These results highlight the efficiency and effectiveness of reasoning-focused
training approaches in developing domain-specific language models with limited
data availability.

</details>


### [104] [CreativityPrism: A Holistic Benchmark for Large Language Model Creativity](https://arxiv.org/abs/2510.20091)
*Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: LLM 的创造力评估框架 CreativityPrism 将创造力分解为质量、新颖性和多样性三个维度，包含九个任务、三个领域和二十个评估指标，并分析了17个模型的表现，发现专有模型和开源模型之间存在显著差距，且同一领域内的任务表现高度相关，而不同领域间的相关性较低。多样性和质量指标高度相关，新颖性指标相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）创造力评估方法存在碎片化、跨领域和任务变化大的问题，缺乏一个整体的框架来评估其在不同场景下的创造力。

Method: 提出一个名为 CreativityPrism 的评估分析框架，将创造力分解为质量、新颖性和多样性三个维度，并纳入了九个任务、三个领域（发散性思维、创意写作、逻辑推理）和二十个评估指标。

Result: 在 CreativityPrism 框架下评估了17个最先进的专有和开源LLM，分析了不同指标和任务领域间的性能相关性。结果显示，专有模型和开源模型之间存在显著差距。同一领域内的任务表现高度相关，而不同领域间的相关性较低。多样性和质量指标高度相关，而新颖性指标与前两者的相关性较弱。

Conclusion: 强大的 LLM 创造力并不一定能泛化到所有任务或维度，因此需要一个整体的评估框架来全面衡量 LLM 的创造力。

Abstract: Creativity is often seen as a hallmark of human intelligence. While large
language models (LLMs) are increasingly perceived as producing creative text,
there is still no holistic framework to evaluate their creativity across
diverse scenarios. Existing evaluation methods remain fragmented, with dramatic
variation across domains and tasks, largely due to differing definitions and
measurements of creativity. Inspired by the hypothesis that creativity is not
one fixed idea, we propose CreativityPrism, an evaluation analysis framework
that decomposes creativity into three dimensions: quality, novelty, and
diversity. CreativityPrism incorporates nine tasks, three domains, i.e.,
divergent thinking, creative writing, and logical reasoning, and twenty
evaluation metrics, which measure each dimension in task-specific, unique ways.
We evaluate 17 state-of-the-art (SoTA) proprietary and open-sourced LLMs on
CreativityPrism and analyze the performance correlations among different
metrics and task domains. Our results reveal a notable gap between proprietary
and open-source models. Overall, model performance tends to be highly
correlated across tasks within the same domain and less so across different
domains. Among evaluation dimensions, diversity and quality metrics show strong
correlations - models that perform well on one often excel on the other -
whereas novelty exhibits much weaker correlation with either. These findings
support our hypothesis that strong performance in one creativity task or
dimension does not necessarily generalize to others, underscoring the need for
a holistic evaluation of LLM creativity.

</details>


### [105] [Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning](https://arxiv.org/abs/2510.20098)
*Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar*

Main category: cs.CL

TL;DR: ARTER通过结合候选生成、上下文评分、自适应路由和选择性推理，在不进行深度微调的情况下实现了高效的实体链接。


<details>
  <summary>Details</summary>
Motivation: 解决传统实体链接（EL）依赖大型标注数据集和模型微调的问题，并提高现有少样本方法的效率，减少昂贵的LLM推理成本。

Method: ARTER提出一个结构化流水线，计算嵌入式和基于LLM的互补信号，将上下文提及分为容易和困难的案例。容易的案例由低计算成本的实体链接器（如ReFinED）处理，困难的案例则由更昂贵的、有针对性的LLM推理处理。

Result: 在标准基准测试中，ARTER的性能比ReFinED高出+4.47%，在6个数据集中的5个上平均提高了+2.53%。与将LLM推理用于所有提及的流水线相比，ARTER的性能相当，但LLM代币效率提高了两倍。

Conclusion: ARTER通过自适应路由和针对性实体推理，在保持高效率的同时，显著提高了实体链接的性能，降低了对大规模标注数据和深度微调的依赖。

Abstract: Entity Linking (EL) has traditionally relied on large annotated datasets and
extensive model fine-tuning. While recent few-shot methods leverage large
language models (LLMs) through prompting to reduce training requirements, they
often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER
(Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline
that achieves high performance without deep fine-tuning by strategically
combining candidate generation, context-based scoring, adaptive routing, and
selective reasoning. ARTER computes a small set of complementary signals(both
embedding and LLM-based) over the retrieved candidates to categorize contextual
mentions into easy and hard cases. The cases are then handled by a
low-computational entity linker (e.g. ReFinED) and more expensive targeted
LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms
ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets,
and performs comparably to pipelines using LLM-based reasoning for all
mentions, while being as twice as efficient in terms of the number of LLM
tokens.

</details>


### [106] [BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation](https://arxiv.org/abs/2510.20151)
*Haoyuan Li,Zhengyuan Shen,Sullam Jeoung,Yueyan Chen,Jiayu Li,Qi Zhu,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.CL

TL;DR: BoundRL是一种创新的文本分割方法，通过生成起始标记而非完整文本来高效处理长结构化文本，并使用强化学习进行优化，在处理复杂提示方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着结构化文本日益复杂，需要对文本进行有意义的分割，但传统方法无法有效处理包含表格、代码等非文本元素的文本。

Method: BoundRL提出了一种联合进行token级文本分割和标签预测的方法，通过生成起始标记来重建文本，以降低推理成本并减少幻觉。它采用基于可验证奖励的强化学习（RLVR）进行优化，并引入中间候选来缓解熵崩溃问题。

Result: BoundRL使小型语言模型（1.7B参数）在处理复杂提示时优于大型模型的少样本提示。RLVR的性能优于监督微调，而中间候选的引入进一步提高了性能和泛化能力。

Conclusion: BoundRL通过其创新的分割和优化方法，在处理长结构化文本，特别是在LLM应用中的复杂提示方面，显示出显著的有效性。

Abstract: As structured texts become increasingly complex across diverse domains --
from technical reports to generative AI prompts -- the need for text
segmentation into semantically meaningful components becomes critical. Such
texts often contain elements beyond plain language, including tables, code
snippets, and placeholders, which conventional sentence- or paragraph-level
segmentation methods cannot handle effectively. To address this challenge, we
propose BoundRL, a novel and efficient approach that jointly performs
token-level text segmentation and label prediction for long structured texts.
Instead of generating complete contents for each segment, it generates only a
sequence of starting tokens and reconstructs the complete contents by locating
these tokens within the original texts, thereby reducing inference costs by
orders of magnitude and minimizing hallucination. To adapt the model for the
output format, BoundRL~performs reinforcement learning with verifiable rewards
(RLVR) with a specifically designed reward that jointly optimizes document
reconstruction fidelity and semantic alignment. To mitigate entropy collapse,
it further constructs intermediate candidates by systematically perturbing a
fraction of generated sequences of segments to create stepping stones toward
higher-quality solutions. To demonstrate BoundRL's effectiveness on
particularly challenging structured texts, we focus evaluation on complex
prompts used for LLM applications. Experiments show that BoundRL enables small
language models (1.7B parameters) to outperform few-shot prompting of much
larger models. Moreover, RLVR with our designed reward yields significant
improvements over supervised fine-tuning, and incorporating intermediate
candidates further improves both performance and generalization.

</details>


### [107] [Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?](https://arxiv.org/abs/2510.20154)
*Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi*

Main category: cs.CL

TL;DR: 大型语言模型在零样本立场检测任务中表现出对社会群体的刻板印象，这受到方言和文本复杂性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在立场检测任务中继承其预训练数据中的刻板印象并产生偏见行为，而该偏见在社区中被忽视。

Method: 通过自动标注预先存在的立场检测数据集中的方言/本土语言和文本复杂性/可读性属性，来研究这些属性是否会影响模型在零样本设置下的立场检测决策。

Result: 结果表明，大型语言模型在立场检测任务中表现出显著的刻板印象，例如将支持大麻的观点与低文本复杂度相关联，以及将非洲裔美国人的方言与反对唐纳德·特朗普的立场相关联。

Conclusion: 大型语言模型在立场检测任务中存在偏见，模型决策会受到数据中社会群体刻板印象的影响。

Abstract: Large Language Models inherit stereotypes from their pretraining data,
leading to biased behavior toward certain social groups in many Natural
Language Processing tasks, such as hateful speech detection or sentiment
analysis. Surprisingly, the evaluation of this kind of bias in stance detection
methods has been largely overlooked by the community. Stance Detection involves
labeling a statement as being against, in favor, or neutral towards a specific
target and is among the most sensitive NLP tasks, as it often relates to
political leanings. In this paper, we focus on the bias of Large Language
Models when performing stance detection in a zero-shot setting. We
automatically annotate posts in pre-existing stance detection datasets with two
attributes: dialect or vernacular of a specific group and text
complexity/readability, to investigate whether these attributes influence the
model's stance detection decisions. Our results show that LLMs exhibit
significant stereotypes in stance detection tasks, such as incorrectly
associating pro-marijuana views with low text complexity and African American
dialect with opposition to Donald Trump.

</details>


### [108] [DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking](https://arxiv.org/abs/2510.20168)
*Tian Lan,Bin Zhu,Qianghuai Jia,Junyang Ren,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: DeepWideSearch是一个新的基准，用于评估搜索代理在处理大规模信息收集和多跳检索方面的深度推理能力。现有最先进的代理在该基准上的平均成功率仅为2.39%，表明这是一个重大的挑战。该基准公开可用，以促进未来在该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 当前搜索代理在深度推理（多跳检索）和广度信息收集方面存在根本性缺陷，这对于市场分析和业务发展等实际应用至关重要。

Method: 创建了一个名为DeepWideSearch的新基准，包含220个问题，涵盖15个领域，用于评估代理整合深度和广度信息搜索的能力。

Result: 在DeepWideSearch基准上，即使是先进的代理，平均成功率也只有2.39%。错误分析揭示了四个主要的失败模式：缺乏反思、过度依赖内部知识、检索不足和上下文溢出。

Conclusion: 整合深度和广度信息搜索是一个重大的挑战，目前的代理架构存在关键限制。DeepWideSearch的发布旨在推动该领域的研究，以开发更强大、更可靠的信息搜索代理。

Abstract: Current search agents fundamentally lack the ability to simultaneously
perform \textit{deep} reasoning over multi-hop retrieval and
\textit{wide}-scale information collection-a critical deficiency for real-world
applications like comprehensive market analysis and business development. To
bridge this gap, we introduce DeepWideSearch, the first benchmark explicitly
designed to evaluate agents to integrate depth and width in information
seeking. In DeepWideSearch, agents must process a large volume of data, each
requiring deep reasoning over multi-hop retrieval paths. Specifically, we
propose two methods to converse established datasets, resulting in a curated
collection of 220 questions spanning 15 diverse domains. Extensive experiments
demonstrate that even state-of-the-art agents achieve only 2.39% average
success rate on DeepWideSearch, highlighting the substantial challenge of
integrating depth and width search in information-seeking tasks. Furthermore,
our error analysis reveals four failure modes: lack of reflection, overreliance
on internal knowledge, insufficient retrieval, and context overflow-exposing
key limitations in current agent architectures. We publicly release
DeepWideSearch to catalyze future research on more capable and robust
information-seeking agents.

</details>


### [109] [Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding](https://arxiv.org/abs/2510.20176)
*Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang*

Main category: cs.CL

TL;DR: Mixture-of-Minds是一个多智能体框架，通过规划、编码和回答三个专门的角色来分解表格推理任务，并结合代码执行和基于MCTS的RL进行自我改进，以提高表格理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM表格推理方法要么在算术方面存在错误和幻觉，要么依赖于僵化的模式且缺乏语义理解，因此需要一种能够整合强大推理和可靠表格处理的方法。

Method: 提出Mixture-of-Minds多智能体框架，将表格推理分解为规划、编码和回答三个专业角色，并引入了使用MCTS生成伪黄金轨迹和RL优化智能体的自改进训练框架。

Result: 在TableBench上达到62.13%，超过了OpenAI-o4-mini-high。

Conclusion: 将结构化的多智能体工作流与RL相结合，有潜力推动表格理解的进步。

Abstract: Understanding and reasoning over tables is a critical capability for many
real-world applications. Large language models (LLMs) have shown promise on
this task, but current approaches remain limited. Fine-tuning based methods
strengthen language reasoning; yet they are prone to arithmetic errors and
hallucination. In contrast, tool-based methods enable precise table
manipulation but rely on rigid schemas and lack semantic understanding. These
complementary drawbacks highlight the need for approaches that integrate robust
reasoning with reliable table processing. In this work, we propose
Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into
three specialized roles: planning, coding, and answering. This design enables
each agent to focus on a specific aspect of the task while leveraging code
execution for precise table manipulation. Building on this workflow, we
introduce a self-improvement training framework that employs Monte Carlo Tree
Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents
with reinforcement learning (RL). Extensive experiments show that
Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and
surpassing OpenAI-o4-mini-high. These results demonstrate the promise of
combining structured multi-agent workflows with RL to advance table
understanding.

</details>


### [110] [Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models](https://arxiv.org/abs/2510.20198)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在文本输入上的空间推理能力有限，尤其是在处理复杂和大规模的空间任务时，准确率会显著下降。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在文本输入上的空间推理能力，了解其在不同复杂度和规模下的空间理解和计算能力。

Method: 在结构化的基于网格的环境中，使用五个任务（象限识别、几何变换、距离评估、单词搜索和图块滑动）来测试 LLM 的空间推理能力。通过增加网格维度来扩展任务的复杂性。

Result: LLM 在低复杂度任务上表现尚可，但随着复杂度和规模的增加，准确率急剧下降，平均下降 42.7%，最高可达 84%。准确率超过 50% 的测试至少下降了 48%。

Conclusion: LLM 在处理大规模和复杂空间任务时存在困难，表明其潜在架构中缺乏鲁棒的空间表征。这揭示了 LLM 在语言和空间推理之间的差距，为未来语言与几何交叉领域的研究提供了基础。

Abstract: This paper explores the spatial reasoning capability of large language models
(LLMs) over textual input through a suite of five tasks aimed at probing their
spatial understanding and computational abilities. The models were tested on
both fundamental spatial reasoning and multi-step problem-solving within
structured grid-based environments using tasks such as quadrant identification,
geometric transformations, distance evaluation, word searches, and tile
sliding. Each task was scaled in complexity through increasing grid dimensions,
requiring models to extend beyond simple pattern recognition into abstract
spatial reasoning. Our results reveal that while LLMs demonstrate moderate
success in all tasks with small complexity and size, performance drops off
rapidly as scale increases, with an average loss in accuracy of 42.7%, and
reaching as high as 84%. Every test that began with over 50% accuracy showed a
loss of at least 48%, illustrating the consistent nature of the deterioration.
Furthermore, their struggles with scaling complexity hint at a lack of robust
spatial representations in their underlying architectures. This paper
underscores the gap between linguistic and spatial reasoning in LLMs, offering
insights into their current limitations, and laying the groundwork for future
integrative benchmarks at the intersection of language and geometry.

</details>


### [111] [Decoding-Free Sampling Strategies for LLM Marginalization](https://arxiv.org/abs/2510.20208)
*David Pohl,Marco Cognetta,Junyoung Lee,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 现代语言模型使用子词（subword）进行文本处理，但现有评估方法忽略了同一文本的多种可能子词表示。本文提出了一种无需生成（decoding-free）的采样策略，用于在不运行模型生成步骤的情况下，估算给定文本所有子词表示的概率（marginalization），并在多项下游任务上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估方法只考虑模型生成的唯一子词（subword）序列，忽略了同一文本的其他可能表示，而这些表示可能对评估模型性能更公平。此外，基于采样的近似边缘化（marginalization）方法需要昂贵的模型生成步骤，限制了采样数量和准确性。

Method: 本文提出并研究了一种“无解码”（decoding-free）的采样策略。该策略不依赖模型生成，而是利用极其廉价且与模型、分词器无关的采样方法，来估计给定文本所有可能子词表示的概率。

Result: 通过在多个开源模型上进行实验，结果表明所提出的无解码采样策略能够以极低的运行时成本，提供足够准确的边缘化概率估计，并有效应用于下游推理任务。

Conclusion: 无需模型生成即可进行近似边缘化估计是可行的，并且在成本效益上优于传统的基于采样的方法，可以作为评估语言模型的一种有效且高效的途径。

Abstract: Modern language models operate on subword-tokenized text in order to make a
trade-off between model size, inference speed, and vocabulary coverage. A side
effect of this is that, during inference, models are evaluated by measuring the
probability of only the specific tokenization produced as the output, despite
there being many possible ways to represent the same text with a subword
vocabulary. Recent studies have argued instead for evaluating LLMs by
marginalization - the probability mass of all tokenizations of a given text.
  Marginalization is difficult due to the number of possible tokenizations of a
text, so often approximate marginalization is done via sampling. However, a
downside of sampling is that an expensive generation step must be performed by
the LLM for each sample, which limits the number of samples that can be
acquired given a runtime budget, and therefore also the accuracy of the
approximation. Since computing the probability of a sequence given the
tokenization is relatively cheap compared to actually generating it, we
investigate sampling strategies that are decoding-free - they require no
generation from the LLM, instead relying entirely on extremely cheap sampling
strategies that are model and tokenizer agnostic.
  We investigate the approximation quality and speed of decoding-free sampling
strategies for a number of open models to find that they provide sufficiently
accurate marginal estimates at a small fraction of the runtime cost and
demonstrate its use on a set of downstream inference tasks.

</details>


### [112] [Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders](https://arxiv.org/abs/2510.20239)
*Filippo Cenacchi,Deborah Richards,Longbing Cao*

Main category: cs.CL

TL;DR: 该研究提出了一种统一的三模态情感框架，用于同时评估抑郁症和PTSD的严重程度，并提供决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有的自动评估方法通常是二元的且仅针对特定疾病，无法满足临床上对跨疾病严重程度评估和决策支持解释的需求。

Method: 该框架融合了访谈文本（句子级Transformer嵌入）、音频（log Mel统计量和delta）以及面部信号（动作单元、注视、头部和姿态描述符），以输出抑郁症（PHQ-8，5个等级）和PTSD（3个等级）的评估严重程度。通过校准的 late fusion 分类器进行特征融合，并提供每种疾病的概率和特征归因。

Result: 在DAIC语料库上的分层交叉验证结果显示，该三模态融合方法优于单模态/烧蚀基线。融合模型在准确率和加权F1分数上与最强的单模态基线相当，同时提高了决策曲线的效用，并在模态缺失或噪声情况下表现出更好的鲁棒性。具体而言，融合模型在PTSD评估中减少了回归误差并提高了类别一致性。分析表明，文本信息对抑郁症严重程度评估贡献最大，而音频和面部信号对PTSD评估至关重要。

Conclusion: 该研究提出的三模态情感融合方法能够进行具有临床意义的、同时考虑多种疾病严重程度的评估，并提供可解释的特征归因，支持临床决策。

Abstract: Depression and post traumatic stress disorder (PTSD) often co-occur with
connected symptoms, complicating automated assessment, which is often binary
and disorder specific. Clinically useful diagnosis needs severity aware cross
disorder estimates and decision support explanations. Our unified tri modal
affective severity framework synchronizes and fuses interview text with
sentence level transformer embeddings, audio with log Mel statistics with
deltas, and facial signals with action units, gaze, head and pose descriptors
to output graded severities for diagnosing both depression (PHQ-8; 5 classes)
and PTSD (3 classes). Standardized features are fused via a calibrated late
fusion classifier, yielding per disorder probabilities and feature-level
attributions. This severity aware tri-modal affective fusion approach is demoed
on multi disorder concurrent depression and PTSD assessment. Stratified cross
validation on DAIC derived corpora outperforms unimodal/ablation baselines. The
fused model matches the strongest unimodal baseline on accuracy and weighted
F1, while improving decision curve utility and robustness under noisy or
missing modalities. For PTSD specifically, fusion reduces regression error and
improves class concordance. Errors cluster between adjacent severities; extreme
classes are identified reliably. Ablations show text contributes most to
depression severity, audio and facial cues are critical for PTSD, whereas
attributions align with linguistic and behavioral markers. Our approach offers
reproducible evaluation and clinician in the loop support for affective
clinical decision making.

</details>


### [113] [Context-level Language Modeling by Learning Predictive Context Embeddings](https://arxiv.org/abs/2510.20280)
*Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang*

Main category: cs.CL

TL;DR: ContextLM通过引入“下一上下文预测”目标来增强LLM的预训练，以捕捉更高层次的语义结构和长距离上下文关系，并在不影响现有评估方法的情况下提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于下一词预测（NTP）的语言模型预训练方法在捕捉高层语义结构和长距离上下文关系方面存在局限性。

Method: 提出ContextLM框架，增加“下一上下文预测”目标，使模型能够学习多词上下文的预测表示，利用来自未来词块的误差信号。该框架与标准的自回归、逐词评估范式兼容。

Result: 在GPT2和Pythia模型家族（高达1.5B参数）的实验中，ContextLM在困惑度（perplexity）和下游任务性能方面均取得了持续的改进。

Conclusion: “下一上下文预测”为更强大的语言建模提供了一种可扩展且高效的途径，能够以最小的计算开销实现更好的长距离一致性和更有效的注意力分配。

Abstract: Next-token prediction (NTP) is the cornerstone of modern large language
models (LLMs) pretraining, driving their unprecedented capabilities in text
generation, reasoning, and instruction following. However, the token-level
prediction limits the model's capacity to capture higher-level semantic
structures and long-range contextual relationships. To overcome this
limitation, we introduce \textbf{ContextLM}, a framework that augments standard
pretraining with an inherent \textbf{next-context prediction} objective. This
mechanism trains the model to learn predictive representations of multi-token
contexts, leveraging error signals derived from future token chunks. Crucially,
ContextLM achieves this enhancement while remaining fully compatible with the
standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity).
Extensive experiments on the GPT2 and Pythia model families, scaled up to
$1.5$B parameters, show that ContextLM delivers consistent improvements in both
perplexity and downstream task performance. Our analysis indicates that
next-context prediction provides a scalable and efficient pathway to stronger
language modeling, yielding better long-range coherence and more effective
attention allocation with minimal computational overhead.

</details>


### [114] [Citation Failure: Definition, Analysis and Efficient Mitigation](https://arxiv.org/abs/2510.20303)
*Jan Buchmann,Iryna Gurevych*

Main category: cs.CL

TL;DR: LLM-based RAG系统的引用本应简化响应验证，但引用失败（模型生成有用响应但未能引用完整证据）会破坏这一点。本研究将引用失败与响应失败（响应本身有缺陷，无法引用完整证据）区分开来。通过CITECONTROL基准测试，研究发现引用失败随着响应与证据之间关系复杂度的增加而增加。为了提高LLM引用效率，提出了CITENTION框架，整合了生成式、注意力机制和检索式方法，并在CITECONTROL和迁移设置中取得了显著的引用改进。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-based RAG系统在简化响应验证方面存在不足，特别是当模型生成有用响应但未能引用完整证据（引用失败）时。本研究旨在解决这一问题，并将其与响应失败区分开来。

Method: 该研究采用两步方法：1. 通过CITECONTROL基准测试研究引用失败发生的原因，特别是响应与证据之间关系复杂度对引用质量的影响。2. 提出CITENTION框架，整合生成式、注意力机制和检索式方法来缓解引用失败。

Result: 实验结果表明，响应与证据之间关系复杂度增加会导致引用失败增多。CITENTION框架在CITECONTROL基准测试和迁移设置中显著提高了引用质量。

Conclusion: 引用失败是LLM-based RAG系统中需要解决的一个关键问题。通过CITECONTROL基准测试的分析和CITENTION框架的提出，本研究为提高LLM的引用效率和准确性提供了有效的方法。

Abstract: Citations from LLM-based RAG systems are supposed to simplify response
verification. However, this does not hold for citation failure, when a model
generates a helpful response, but fails to cite complete evidence. In contrast
to previous work, we propose to disentangle this from response failure, where
the response itself is flawed, and citing complete evidence is impossible. To
address citation failure, this work follows a two-step approach: (1) We study
when citation failure occurs and (2) how it can be mitigated. For step 1, we
extend prior work by investigating how the relation between response and
evidence affects citation quality. We introduce CITECONTROL, a benchmark that
systematically varies this relation to analyze failure modes. Experiments show
that failures increase with relational complexity and suggest that combining
citation methods could improve performance, motivating step 2. To improve LLM
citation efficiently, we propose CITENTION, a framework integrating generative,
attention-based, and retrieval-based methods. Results demonstrate substantial
citation improvements on CITECONTROL and in transfer settings. We make our data
and code publicly available.

</details>


### [115] [Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering](https://arxiv.org/abs/2510.20304)
*Lei Tang,Wei Zhou,Mohsen Mesgar*

Main category: cs.CL

TL;DR: PRMs在表格问答（TQA）中应用效果不佳，主要因为数据干扰、推理步骤松散以及领域特定性，尽管结合文本和代码验证有所帮助，但泛化能力不足，且步骤级验证与答案准确性相关性弱。


<details>
  <summary>Details</summary>
Motivation: 评估PRMs在TQA任务中的适用性，并探索其在处理半结构化数据时的挑战。

Method: 在TQA任务上评估最先进的生成PRMs，从答案和步骤两个角度进行。

Result: 结合文本和代码验证的PRMs有助于答案选择，但在处理非领域数据时泛化能力不足。发现步骤级验证表现与答案准确性之间存在弱相关性。

Conclusion: 当前的PRMs在TQA任务上存在局限性，未来的研究应着重于构建更鲁棒、过程感知的验证器，以解决步骤依赖性和因果联系松散的问题。

Abstract: Process reward models (PRMs) improve complex reasoning in large language
models (LLMs) by grading candidate solutions step-by-step and selecting answers
via aggregated step scores. While effective in domains such as mathematics,
their applicability to tasks involving semi-structured data, like table
question answering (TQA) remains unexplored. TQA poses unique challenges for
PRMs, including abundant irrelevant information, loosely connected reasoning
steps, and domain-specific reasoning. This work presents the first systematic
study of PRMs for TQA. We evaluate state-of-the-art generative PRMs on TQA from
both answer and step perspectives. Results show that PRMs that combine textual
and code verification can aid solution selection but struggle to generalize to
out-of-domain data. Analysis reveals a weak correlation between performance in
step-level verification and answer accuracy, possibly stemming from weak step
dependencies and loose causal links. Our findings highlight limitations of
current PRMs on TQA and offer valuable insights for building more robust,
process-aware verifiers.

</details>


### [116] [Teaching Language Models to Reason with Tools](https://arxiv.org/abs/2510.20342)
*Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu*

Main category: cs.CL

TL;DR: CoRT是一个训练框架，用于教会大型推理模型（LRM）有效利用代码解释器（CI），通过“提示工程”生成高质量的、与代码相结合的推理数据，以优化LRM-CI交互，从而提高数学推理能力并降低代币使用量。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRM）在处理复杂数学问题时效率低下且不准确，而集成代码解释器（CI）会引发模型内部概率推理与CI外部确定性知识之间的冲突，导致模型犹豫不决。

Method: 提出CoRT（Code-Optimized Reasoning Training）训练框架，并引入“提示工程”这一新的数据合成策略，该策略在推理路径的优化点注入多样化提示，生成高质量、代码整合的推理数据。通过监督微调和使用拒绝采样及强化学习来优化多轮外部CI使用和内部思考的交错。

Result: 在五个具有挑战性的数学推理数据集上，CoRT在DeepSeek-R1-Distill-Qwen-32B和DeepSeek-R1-Distill-Qwen-1.5B模型上分别带来了4%和8%的绝对提升。此外，与纯自然语言推理基线相比，CoRT将32B模型的代币使用量减少了约30%，1.5B模型的代币使用量减少了约50%。

Conclusion: CoRT框架通过“提示工程”有效解决了LRM与CI集成中的冲突，显著提高了模型的数学推理性能和效率。

Abstract: Large reasoning models (LRMs) like OpenAI-o1 have shown impressive
capabilities in natural language reasoning. However, these models frequently
demonstrate inefficiencies or inaccuracies when tackling complex mathematical
operations. While integrating computational tools such as Code Interpreters
(CIs) offers a promising solution, it introduces a critical challenge: a
conflict between the model's internal, probabilistic reasoning and the
external, deterministic knowledge provided by the CI, which often leads models
to unproductive deliberation. To overcome this, we introduce CoRT
(Code-Optimized Reasoning Training), a post-training framework designed to
teach LRMs to effectively utilize CIs. We propose \emph{Hint-Engineering}, a
new data synthesis strategy that strategically injects diverse hints at optimal
points within reasoning paths. This approach generates high-quality,
code-integrated reasoning data specifically tailored to optimize LRM-CI
interaction. Using this method, we have synthesized 30 high-quality samples to
post-train models ranging from 1.5B to 32B parameters through supervised
fine-tuning. CoRT further refines the multi-round interleaving of external CI
usage and internal thinking by employing rejection sampling and reinforcement
learning. Our experimental evaluations demonstrate CoRT's effectiveness,
yielding absolute improvements of 4\% and 8\% on DeepSeek-R1-Distill-Qwen-32B
and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging
mathematical reasoning datasets. Moreover, CoRT significantly enhances
efficiency, reducing token usage by approximately 30\% for the 32B model and
50\% for the 1.5B model compared to pure natural language reasoning baselines.
The models and code are available at: https://github.com/ChengpengLi1003/CoRT.

</details>


### [117] [Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models](https://arxiv.org/abs/2510.20351)
*Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei*

Main category: cs.CL

TL;DR: LLMs可能通过记忆而非推理来解决表格任务，尤其是在数据集具有强语义线索时。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在结构化数据上的推理能力时，必须考虑数据集污染问题，因为这可能导致对模型真实能力的误判。

Method: 通过对照探查实验，检测LLMs对包含强语义线索（如列名、类别值）和不包含线索（随机化）的表格数据集的熟悉程度。

Result: LLMs在具有强语义线索的数据集上表现出色，但在移除或随机化这些线索后，性能急剧下降至接近随机水平。

Conclusion: LLMs在表格推理任务上的表现可能部分源于对公开数据集的记忆，而非真正的泛化能力。需要改进评估方法以区分语义泄露和真实推理能力。

Abstract: Large Language Models (LLMs) are increasingly evaluated on their ability to
reason over structured data, yet such assessments often overlook a crucial
confound: dataset contamination. In this work, we investigate whether LLMs
exhibit prior knowledge of widely used tabular benchmarks such as Adult Income,
Titanic, and others. Through a series of controlled probing experiments, we
reveal that contamination effects emerge exclusively for datasets containing
strong semantic cues-for instance, meaningful column names or interpretable
value categories. In contrast, when such cues are removed or randomized,
performance sharply declines to near-random levels. These findings suggest that
LLMs' apparent competence on tabular reasoning tasks may, in part, reflect
memorization of publicly available datasets rather than genuine generalization.
We discuss implications for evaluation protocols and propose strategies to
disentangle semantic leakage from authentic reasoning ability in future LLM
assessments.

</details>


### [118] [FreeChunker: A Cross-Granularity Chunking Framework](https://arxiv.org/abs/2510.20356)
*Wenxuan Zhang,Yuan-Hao Jiang,Yonghe Wu*

Main category: cs.CL

TL;DR: FreeChunker是一个跨粒度编码框架，它将句子作为原子单元，并从静态块分割转向灵活的检索，支持任意句子组合，从而提高检索性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）系统依赖于固定粒度的分块策略，这种策略在识别静态边界时，限制了其对不同查询需求的适应性。

Method: FreeChunker将句子视为原子单元，并从静态分块转向灵活的检索，支持任意句子组合。

Result: FreeChunker在LongBench V2上的实验评估表明，与传统分块方法相比，FreeChunker实现了更优越的检索性能，并在计算效率方面显著优于现有方法。

Conclusion: FreeChunker通过其跨粒度编码框架，为RAG系统提供了一种更灵活、更高效的分块方法，能够更好地适应复杂查询并提高检索性能。

Abstract: Chunking strategies significantly impact the effectiveness of
Retrieval-Augmented Generation (RAG) systems. Existing methods operate within
fixed-granularity paradigms that rely on static boundary identification,
limiting their adaptability to diverse query requirements. This paper presents
FreeChunker, a Cross-Granularity Encoding Framework that fundamentally
transforms the traditional chunking paradigm: the framework treats sentences as
atomic units and shifts from static chunk segmentation to flexible retrieval
supporting arbitrary sentence combinations. This paradigm shift not only
significantly reduces the computational overhead required for semantic boundary
detection but also enhances adaptability to complex queries. Experimental
evaluation on LongBench V2 demonstrates that FreeChunker achieves superior
retrieval performance compared to traditional chunking methods, while
significantly outperforming existing approaches in computational efficiency.

</details>


### [119] [Dialogue Is Not Enough to Make a Communicative BabyLM (But Neither Is Developmentally Inspired Reinforcement Learning)](https://arxiv.org/abs/2510.20358)
*Francesca Padovani,Bastian Bunzeck,Manar Ali,Omar Momen,Arianna Bisazza,Hendrik Buschmeier,Sina Zarrieß*

Main category: cs.CL

TL;DR: 预训练对话模型在对话任务上表现优异，DPO微调进一步提升了性能。


<details>
  <summary>Details</summary>
Motivation: 研究仅在对话数据上进行预训练能否产生形式和功能上都合适的语言模型。

Method: 使用llamalogu预训练模型，并采用不同的微调策略（包括PPO和DPO）来提升模型的对话能力。

Result: 在BabyLM基准测试中表现不佳，但在对话续写预测任务上表现出色。PPO微调效果不确定，DPO微调显著提升了在自定义对话基准测试上的性能。

Conclusion: 仅在对话数据上预训练的llamalogue模型在对话任务上具有潜力，DPO微调是一种有效的提升其对话能力的策略。

Abstract: We investigate whether pre-training exclusively on dialogue data results in
formally and functionally apt small language models. Based on this pre-trained
llamalogue model, we employ a variety of fine-tuning strategies to enforce
"more communicative" text generations by our models. Although our models
underperform on most standard BabyLM benchmarks, they excel at dialogue
continuation prediction in a minimal pair setting. While PPO fine-tuning has
mixed to adversarial effects on our models, DPO fine-tuning further improves
their performance on our custom dialogue benchmark.

</details>


### [120] [The Impact of Negated Text on Hallucination with Large Language Models](https://arxiv.org/abs/2510.20375)
*Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim*

Main category: cs.CL

TL;DR: LLM在处理否定文本时在区分幻觉方面存在困难，并且在NegHalu数据集上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 虽然关于LLM幻觉的研究不断进展，但否定文本对其幻觉的影响仍未得到充分探索。

Method: 设计NegHalu数据集，并通过对否定输入的token级别分析来研究LLM在处理否定文本时的内部状态。

Result: LLM在识别否定文本中的幻觉方面存在困难，并且在NegHalu数据集上表现不佳，常常做出逻辑不一致或不忠实的判断。

Conclusion: LLM在处理否定文本时，在识别幻觉方面存在挑战，并且有减轻其不良影响的必要。

Abstract: Recent studies on hallucination in large language models (LLMs) have been
actively progressing in natural language processing. However, the impact of
negated text on hallucination with LLMs remains largely unexplored. In this
paper, we set three important yet unanswered research questions and aim to
address them. To derive the answers, we investigate whether LLMs can recognize
contextual shifts caused by negation and still reliably distinguish
hallucinations comparable to affirmative cases. We also design the NegHalu
dataset by reconstructing existing hallucination detection datasets with
negated expressions. Our experiments demonstrate that LLMs struggle to detect
hallucinations in negated text effectively, often producing logically
inconsistent or unfaithful judgments. Moreover, we trace the internal state of
LLMs as they process negated inputs at the token level and reveal the
challenges of mitigating their unintended effects.

</details>


### [121] [VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation](https://arxiv.org/abs/2510.20381)
*Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 该论文介绍了VLSP 2025 MLQA-TSR，这是一个关于越南交通标志法规的多模态法律问题解答的共享任务。


<details>
  <summary>Details</summary>
Motivation: 推动越南多模态法律文本处理的研究，并为构建和评估多模态法律领域的智能系统提供基准数据集，重点关注越南的交通标志法规。

Method: 该任务包含两个子任务：多模态法律检索和多模态问题解答。

Result: 在VLSP 2025 MLQA-TSR上，多模态法律检索的最佳报告F2分数达到64.55%，多模态问题解答的最佳报告准确率达到86.30%。

Conclusion: VLSP 2025 MLQA-TSR 旨在促进越南法律领域特别是交通标志法规方面的多模态人工智能研究。

Abstract: This paper presents the VLSP 2025 MLQA-TSR - the multimodal legal question
answering on traffic sign regulation shared task at VLSP 2025. VLSP 2025
MLQA-TSR comprises two subtasks: multimodal legal retrieval and multimodal
question answering. The goal is to advance research on Vietnamese multimodal
legal text processing and to provide a benchmark dataset for building and
evaluating intelligent systems in multimodal legal domains, with a focus on
traffic sign regulation in Vietnam. The best-reported results on VLSP 2025
MLQA-TSR are an F2 score of 64.55% for multimodal legal retrieval and an
accuracy of 86.30% for multimodal question answering.

</details>


### [122] [NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew](https://arxiv.org/abs/2510.20386)
*Shaltiel Shmidman,Avi Shmidman,Moshe Koppel*

Main category: cs.CL

TL;DR: NeoDictaBERT 和 NeoDictaBERT-bilingual 是基于 NeoBERT 架构的 BERT 模型，专注于希伯来语文本，并在希伯来语基准测试中表现出色，特别是 NeoDictaBERT-bilingual 在检索任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: BERT 模型性能优越但架构过时，需要更新以匹配 Llama3 和 Qwen3 等新模型。现有模型如 ModernBERT 和 NeoBERT 改进了英语基准测试和上下文窗口，但缺乏针对希伯来语的专门模型。

Method: 本文介绍 NeoDictaBERT 和 NeoDictaBERT-bilingual 模型，它们采用 NeoBERT 的架构，并使用相同的训练方法，但专注于希伯来语文本。

Result: NeoDictaBERT 和 NeoDictaBERT-bilingual 在希伯来语基准测试中取得了优于现有模型的性能。NeoDictaBERT-bilingual 在检索任务中表现尤为出色，超过了其他同等规模的多语言模型。

Conclusion: 本文提出的 NeoDictaBERT 和 NeoDictaBERT-bilingual 模型在希伯来语 NLP 领域取得了显著进展，为相关下游任务奠定了坚实基础。模型已公开发布，以促进希伯来语 NLP 的研究和开发。

Abstract: Since their initial release, BERT models have demonstrated exceptional
performance on a variety of tasks, despite their relatively small size
(BERT-base has ~100M parameters). Nevertheless, the architectural choices used
in these models are outdated compared to newer transformer-based models such as
Llama3 and Qwen3. In recent months, several architectures have been proposed to
close this gap. ModernBERT and NeoBERT both show strong improvements on English
benchmarks and significantly extend the supported context window. Following
their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual:
BERT-style models trained using the same architecture as NeoBERT, with a
dedicated focus on Hebrew texts. These models outperform existing ones on
almost all Hebrew benchmarks and provide a strong foundation for downstream
tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on
retrieval tasks, outperforming other multilingual models of similar size. In
this paper, we describe the training process and report results across various
benchmarks. We release the models to the community as part of our goal to
advance research and development in Hebrew NLP.

</details>


### [123] [Teacher Demonstrations in a BabyLM's Zone of Proximal Development for Contingent Multi-Turn Interaction](https://arxiv.org/abs/2510.20411)
*Suchir Salhan,Hongyi Gu,Donya Rooein,Diana Galvan-Sosa,Gabrielle Gaudeau,Andrew Caines,Zheng Yuan,Paula Buttery*

Main category: cs.CL

TL;DR: ContingentChat是一个用于提高婴儿语言模型（BabyLM）在多轮对话中应答连贯性的教学-学习框架，通过新颖的对齐数据集进行后训练，显著提升了生成回应的语法和连贯性，但自适应教师解码策略的额外收益有限，表明连贯性对BabyLM仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 多轮对话，特别是儿童与看护者之间的对话，其特点是参与者之间进行及时、直接且有意义的交流，即“应答连贯性”。

Method: 提出ContingentChat，一个教学-学习框架，用于在100M词汇量的BabyLM上进行基准测试和提高多轮对话的应答连贯性。使用新颖的对齐数据集进行后训练，并试验自适应教师解码策略。

Result: 经过ContingentChat的后训练，BabyLM生成的回应在语法和连贯性方面有所提高。自适应教师解码策略的实验显示，其带来的额外收益有限。

Conclusion: ContingentChat证明了针对性后训练在提升对话质量方面的优势，并指出应答连贯性对BabyLM来说仍然是一个具有挑战性的目标。

Abstract: Multi-turn dialogues between a child and a caregiver are characterized by a
property called contingency - that is, prompt, direct, and meaningful exchanges
between interlocutors. We introduce ContingentChat, a teacher-student framework
that benchmarks and improves multi-turn contingency in a BabyLM trained on 100M
words. Using a novel alignment dataset for post-training, BabyLM generates
responses that are more grammatical and cohesive. Experiments with adaptive
teacher decoding strategies show limited additional gains. ContingentChat
demonstrates the benefits of targeted post-training for dialogue quality and
indicates that contingency remains a challenging goal for BabyLMs.

</details>


### [124] [LM-mixup: Text Data Augmentation via Language Model based Mixup](https://arxiv.org/abs/2510.20449)
*Zhijie Deng,Zhouan Shen,Ling Li,Yao Zhou,Zhaowei Zhu,Yanji He,Wei Wang,Jiaheng Wei*

Main category: cs.CL

TL;DR: Instruction tuning LLMs can be improved by distilling low-quality data into high-quality data using the LM-Mixup method, which enhances efficiency and performance.


<details>
  <summary>Details</summary>
Motivation: High-quality instruction-following data for LLMs is scarce, while abundant low-quality data is often discarded, leading to information loss. Existing methods struggle to effectively augment this low-quality data.

Method: The paper introduces Instruction Distillation to create high-quality instruction-output pairs from low-quality and redundant inputs. They constructed a dataset called MIXTURE and proposed LM-Mixup, which involves supervised fine-tuning on MIXTURE followed by reinforcement learning with three reward signals (quality, semantic alignment, format compliance) using Group Relative Policy Optimization (GRPO).

Result: LM-Mixup effectively augments imperfect datasets. Fine-tuning LLMs on distilled data (3% of the total dataset) surpassed full-dataset training and competed with state-of-the-art high-quality data selection methods across multiple benchmarks.

Conclusion: Low-quality data is a valuable resource for instruction tuning LLMs when distilled and augmented using methods like LM-Mixup, improving both efficiency and performance.

Abstract: Instruction tuning is crucial for aligning Large Language Models (LLMs), yet
the quality of instruction-following data varies significantly. While
high-quality data is paramount, it is often scarce; conversely, abundant
low-quality data is frequently discarded, leading to substantial information
loss. Existing data augmentation methods struggle to augment this low-quality
data effectively, and the evaluation of such techniques remains poorly defined.
To address this, we formally define the task of Instruction Distillation:
distilling multiple low-quality and redundant inputs into high-quality and
coherent instruction-output pairs. Specifically, we introduce a comprehensive
data construction pipeline to create MIXTURE, a 144K-sample dataset pairing
low-quality or semantically redundant imperfect instruction clusters with their
high-quality distillations. We then introduce LM-Mixup, by first performing
supervised fine-tuning on MIXTURE and then optimizing it with reinforcement
learning. This process uses three complementary reward signals: quality,
semantic alignment, and format compliance, via Group Relative Policy
Optimization (GRPO). We demonstrate that LM-Mixup effectively augments
imperfect datasets: fine-tuning LLMs on its distilled data, which accounts for
only about 3% of the entire dataset, not only surpasses full-dataset training
but also competes with state-of-the-art high-quality data selection methods
across multiple benchmarks. Our work establishes that low-quality data is a
valuable resource when properly distilled and augmented with LM-Mixup,
significantly enhancing the efficiency and performance of instruction-tuned
LLMs.

</details>


### [125] [Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models](https://arxiv.org/abs/2510.20460)
*Christian Hobelsberger,Theresa Winner,Andreas Nawroth,Oliver Mitevski,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: LLMs 的输出具有不确定性和正确性不一的问题，影响其实际可靠性。本文评估了 VCE、MSP、Sample Consistency 和 CoCoA 四种置信度估计方法在 LLM 输出上的表现。


<details>
  <summary>Details</summary>
Motivation: 量化大型语言模型（LLMs）输出的不确定性。

Method: 在四个问答任务上，使用最先进的开源 LLM 进行了实验，评估了 VCE、MSP、Sample Consistency 和 CoCoA 四种置信度估计方法。

Result: 结果表明，每种不确定性度量都捕捉了模型置信度的不同方面，并且混合方法 CoCoA 整体上产生了最佳的可靠性，改进了正确答案的校准和区分能力。

Conclusion: 讨论了各种方法的权衡，并为在 LLM 应用中选择不确定性度量提供了建议。

Abstract: Large language models (LLMs) produce outputs with varying levels of
uncertainty, and, just as often, varying levels of correctness; making their
practical reliability far from guaranteed. To quantify this uncertainty, we
systematically evaluate four approaches for confidence estimation in LLM
outputs: VCE, MSP, Sample Consistency, and CoCoA (Vashurin et al., 2025). For
the evaluation of the approaches, we conduct experiments on four
question-answering tasks using a state-of-the-art open-source LLM. Our results
show that each uncertainty metric captures a different facet of model
confidence and that the hybrid CoCoA approach yields the best reliability
overall, improving both calibration and discrimination of correct answers. We
discuss the trade-offs of each method and provide recommendations for selecting
uncertainty measures in LLM applications.

</details>


### [126] [Mask and You Shall Receive: Optimizing Masked Language Modeling For Pretraining BabyLMs](https://arxiv.org/abs/2510.20475)
*Lukas Edman,Alexander Fraser*

Main category: cs.CL

TL;DR: 通过改进的掩码语言模型（MLM）策略，在BabyLM挑战赛上取得了显著的性能提升，并结合了子词嵌入以增强形态泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种改进的掩码语言模型（MLM）策略，以提高在BabyLM挑战赛上的性能。

Method: 提出一种改进的掩码语言模型（MLM）策略，根据模型预测能力调整掩码的token概率，并结合子词嵌入。

Result: 在（Super）GLUE任务上的性能有显著提升，并且在严格-小型赛道上超越了基线。

Conclusion: 改进的MLM策略结合子词嵌入能够有效提高模型性能和形态泛化能力。

Abstract: We describe our strategy for the 2025 edition of the BabyLM Challenge. Our
main contribution is that of an improved form of Masked Language Modeling
(MLM), which adapts the probabilities of the tokens masked according to the
model's ability to predict them. The results show a substantial increase in
performance on (Super)GLUE tasks over the standard MLM. We also incorporate
sub-token embeddings, finding that this increases the model's morphological
generalization capabilities. Our submission beats the baseline in the
strict-small track.

</details>


### [127] [RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging](https://arxiv.org/abs/2510.20479)
*Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang*

Main category: cs.CL

TL;DR: LLMs的内部表征可作为学习知识的代理，提出RECALL框架，在无历史数据的情况下进行模型合并以实现持续学习。


<details>
  <summary>Details</summary>
Motivation: LLMs的内部表征可作为学习知识的代理，且需要一种在无历史数据的情况下进行模型合并以实现持续学习的框架。

Method: RECALL通过计算层级隐藏表征的跨模型相似性，并进行自适应、层级参数融合，以对齐跨模型知识，从而在保留通用特征的同时适应任务特定需求。

Result: RECALL在五个NLP任务和多种持续学习场景中，相较于基线方法，在知识保留和泛化能力上均表现更优，展示了其在持续学习LLM方面的可扩展性和数据无关性。

Conclusion: RECALL是一种新颖的、对表征敏感的模型合并框架，能够实现无数据、无标签的持续学习，有效抵抗灾难性遗忘，并提升模型在多领域知识整合和泛化方面的能力。

Abstract: We unveil that internal representations in large language models (LLMs) serve
as reliable proxies of learned knowledge, and propose RECALL, a novel
representation-aware model merging framework for continual learning without
access to historical data. RECALL computes inter-model similarity from
layer-wise hidden representations over clustered typical samples, and performs
adaptive, hierarchical parameter fusion to align knowledge across models. This
design enables the preservation of domain-general features in shallow layers
while allowing task-specific adaptation in deeper layers. Unlike prior methods
that require task labels or incur performance trade-offs, RECALL achieves
seamless multi-domain integration and strong resistance to catastrophic
forgetting. Extensive experiments across five NLP tasks and multiple continual
learning scenarios show that RECALL outperforms baselines in both knowledge
retention and generalization, providing a scalable and data-free solution for
evolving LLMs.

</details>


### [128] [Steering Evaluation-Aware Language Models To Act Like They Are Deployed](https://arxiv.org/abs/2510.20487)
*Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda*

Main category: cs.CL

TL;DR: LLM 可能会在评估时表现出


<details>
  <summary>Details</summary>
Motivation: LLM 的评估可靠性会因其在评估时会表现出

Method: 通过添加转向向量来抑制 LLM 的评估意识。具体来说，我们首先在包含模型事实描述的文档上进行持续预训练，这些文档在评估期间使用 Python 类型提示，但在部署期间不使用，并认识到特定评估线索的存在总是意味着正在接受测试。然后，我们对模型进行训练，以在评估环境中使用 Python 类型提示。然后，我们训练模型以在评估环境中使用 Python 类型提示。

Result: 实验表明，虽然训练后的模型在评估时表现出评估意识（在评估时比部署时更倾向于使用类型提示），但在移除评估线索后才能观察到这种差异。然而，激活转向可以抑制这种评估意识，使模型在存在线索的情况下也能表现得像在部署状态下一样。值得注意的是，转向向量是在额外训练之前使用原始模型构建的。

Conclusion: AI 评估者可以通过转向模型使其表现得像在部署状态下一样，来提高安全评估的可靠性。

Abstract: Large language models (LLMs) can sometimes detect when they are being
evaluated and adjust their behavior to appear more aligned, compromising the
reliability of safety evaluations. In this paper, we show that adding a
steering vector to an LLM's activations can suppress evaluation-awareness and
make the model act like it is deployed during evaluation. To study our steering
technique, we train an LLM to exhibit evaluation-aware behavior using a
two-step training process designed to mimic how this behavior could emerge
naturally. First, we perform continued pretraining on documents with factual
descriptions of the model (1) using Python type hints during evaluation but not
during deployment and (2) recognizing that the presence of a certain evaluation
cue always means that it is being tested. Then, we train the model with expert
iteration to use Python type hints in evaluation settings. The resulting model
is evaluation-aware: it writes type hints in evaluation contexts more than
deployment contexts. However, this gap can only be observed by removing the
evaluation cue. We find that activation steering can suppress evaluation
awareness and make the model act like it is deployed even when the cue is
present. Importantly, we constructed our steering vector using the original
model before our additional training. Our results suggest that AI evaluators
could improve the reliability of safety evaluations by steering models to act
like they are deployed.

</details>


### [129] [Robust Preference Alignment via Directional Neighborhood Consensus](https://arxiv.org/abs/2510.20498)
*Ruochen Mao,Yuling Shi,Xiaodong Gu,Jiaheng Wei*

Main category: cs.CL

TL;DR: 该研究提出了一种名为鲁棒偏好选择（RPS）的训练无关的后处理方法，通过利用定向邻域共识来解决大型语言模型（LLM）在对齐人类偏好时存在的偏好覆盖差距问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对齐人类偏好时存在偏好覆盖差距，导致模型在处理偏离训练数据中心趋势的细微偏好时性能下降。现有方法通常需要昂贵的重新训练，并且泛化能力有限。

Method: RPS通过利用定向邻域共识，采样多个相关偏好的响应，然后选择最符合用户原始意图的响应，而无需进行模型重新训练。

Result: 在三种不同的对齐范式（DPA、DPO和SFT）上进行的实验表明，RPS在处理来自欠表示区域的具有挑战性的偏好时，相比于采样多个候选的基础模型，具有高达69%的胜率，显著提高了鲁棒性。

Conclusion: RPS为增强偏好对齐模型的可靠性提供了一种实用的、有理论依据的解决方案。

Abstract: Aligning large language models with human preferences is critical for
creating reliable and controllable AI systems. A human preference can be
visualized as a high-dimensional vector where different directions represent
trade-offs between desired attributes (e.g., helpfulness vs. verbosity). Yet,
because the training data often reflects dominant, average preferences, LLMs
tend to perform well on common requests but fall short in specific, individual
needs. This mismatch creates a preference coverage gap. Existing methods often
address this through costly retraining, which may not be generalized to the
full spectrum of diverse preferences. This brittleness means that when a user's
request reflects a nuanced preference deviating from the training data's
central tendency, model performance can degrade unpredictably. To address this
challenge, we introduce Robust Preference Selection (RPS), a post-hoc,
training-free method by leveraging directional neighborhood consensus. Instead
of forcing a model to generate a response from a single, highly specific
preference, RPS samples multiple responses from a local neighborhood of related
preferences to create a superior candidate pool. It then selects the response
that best aligns with the user's original intent. We provide a theoretical
framework showing our neighborhood generation strategy is provably superior to
a strong baseline that also samples multiple candidates. Comprehensive
experiments across three distinct alignment paradigms (DPA, DPO, and SFT)
demonstrate that RPS consistently improves robustness against this baseline,
achieving win rates of up to 69% on challenging preferences from
under-represented regions of the space without any model retraining. Our work
presents a practical, theoretically-grounded solution for enhancing the
reliability of preference-aligned models.

</details>


### [130] [Hierarchical Sequence Iteration for Heterogeneous Question Answering](https://arxiv.org/abs/2510.20505)
*Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim*

Main category: cs.CL

TL;DR: HSEQ框架通过分层序列化和结构感知迭代，提高了多步和异构证据来源问题的检索增强生成（RAG）的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）在处理多步问题和异构证据来源时不够鲁棒，准确性、延迟、token和工具预算之间存在权衡。

Method: 提出了一种名为“分层序列（HSEQ）迭代异构问答”的统一框架。该框架首先将文档、表格和知识图谱线性化为具有轻量级结构标签的可逆分层序列。然后，通过结构感知迭代来收集足够的证据，最后进行答案合成。具体来说，头部代理提供检索指导，迭代代理通过尊重结构的动作（例如，父/子跳转、表格行/列邻居、知识图谱关系）来选择和扩展HSeq。最后，头部代理组合规范化的证据以生成最终答案，并可选择性地进行精炼循环以解决检测到的矛盾。

Result: 在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）数据集上进行实验，结果显示HSEQ在准确性和效率方面持续优于强大的单通道、多跳和代理RAG基线。HSEQ具有格式无关的统一性、引导式且有预算的迭代以及用于可靠问答的证据规范化这三个关键优势。

Conclusion: HSEQ框架通过在统一的格式无关框架中实现结构感知迭代，有效解决了RAG在多步和异构问题上面临的挑战，提高了准确性、效率和答案的可靠性。

Abstract: Retrieval-augmented generation (RAG) remains brittle on multi-step questions
and heterogeneous evidence sources, trading accuracy against latency and
token/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration
for Heterogeneous Question Answering, a unified framework that (i) linearize
documents, tables, and knowledge graphs into a reversible hierarchical sequence
with lightweight structural tags, and (ii) perform structure-aware iteration to
collect just-enough evidence before answer synthesis. A Head Agent provides
guidance that leads retrieval, while an Iteration Agent selects and expands
HSeq via structure-respecting actions (e.g., parent/child hops, table
row/column neighbors, KG relations); Finally the head agent composes
canonicalized evidence to genearte the final answer, with an optional
refinement loop to resolve detected contradictions. Experiments on HotpotQA
(text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1
gains over strong single-pass, multi-hop, and agentic RAG baselines with high
efficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic
unification that enables a single policy to operate across text, tables, and
KGs without per-dataset specialization; (2) guided, budget-aware iteration that
reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and
(3) evidence canonicalization for reliable QA, improving answers consistency
and auditability.

</details>


### [131] [Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset](https://arxiv.org/abs/2510.20508)
*Paul Lerner,François Yvon*

Main category: cs.CL

TL;DR: LLMs的政治偏见可以通过评估其对英文调查的模拟回答来衡量。本研究提出了一种新的评估方法，基于多语言翻译中的公平性原则，通过比较欧洲议会（EP）演讲的翻译质量来系统地分析LLMs的政治偏见。研究发现，来自左右中三个主要政党的演讲比来自非主流政党的演讲翻译质量更高。该研究利用了一个新发布的、包含21种语言的EuroParl数据集，该数据集包含议会演讲的政治归属信息，共计150万句话，4000万词，2.49亿字符，覆盖了三年的时间，1000多名发言者，7个国家，12个欧盟政党，25个欧盟委员会以及数百个国家政党。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的政治偏见通常依赖于模拟其对英文调查的回答。本研究旨在提出一种替代的评估框架，该框架基于多语言翻译中的公平性原则。

Method: 本研究系统地比较了欧洲议会（EP）演讲的翻译质量，通过观察翻译质量在不同政治派别之间的差异来评估LLMs的政治偏见。这项研究得益于一个新的、包含21种语言的EuroParl多并行版本，其中包含了每位发言者的政治派别信息。

Result: 研究观察到，来自欧洲议会中左右中三大主流政党的演讲比来自非主流政党的演讲拥有更高的翻译质量，这表明存在系统性的翻译质量差异。

Conclusion: 本研究通过分析欧洲议会演讲的翻译质量，揭示了大型语言模型（LLMs）在政治偏见方面的表现，并提出了一种基于多语言翻译公平性的新评估方法。研究结果表明，LLMs在翻译过程中可能存在偏向主流政党而忽略非主流政党的倾向。

Abstract: The political biases of Large Language Models (LLMs) are usually assessed by
simulating their answers to English surveys. In this work, we propose an
alternative framing of political biases, relying on principles of fairness in
multilingual translation. We systematically compare the translation quality of
speeches in the European Parliament (EP), observing systematic differences with
majority parties from left, center, and right being better translated than
outsider parties. This study is made possible by a new, 21-way multiparallel
version of EuroParl, the parliamentary proceedings of the EP, which includes
the political affiliations of each speaker. The dataset consists of 1.5M
sentences for a total of 40M words and 249M characters. It covers three years,
1000+ speakers, 7 countries, 12 EU parties, 25 EU committees, and hundreds of
national parties.

</details>


### [132] [ARC-Encoder: learning compressed text representations for large language models](https://arxiv.org/abs/2510.20535)
*Hippolyte Pilchen,Edouard Grave,Patrick Pérez*

Main category: cs.CL

TL;DR: ARC-Encoder是一种高效的上下文压缩方法，通过将文本表示为连续向量来减少LLM的推理成本，同时保持甚至提升性能，并能适应多种LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文压缩技术要么需要对目标模型进行微调，要么需要修改其架构，这可能损害其通用能力。因此，需要一种不影响模型通用性的替代方法。

Method: 提出了一种名为ARC-Encoder的编码器，它将上下文压缩成比文本标记少x倍（通常为4或8倍）的连续表示，并用这些表示替换解码器LLM中的标记嵌入。系统地研究了用于该编码器的训练策略和架构选择。

Result: ARC-Encoder在各种LLM使用场景（从上下文学习到上下文窗口扩展）和不同类型的解码器（指令和基础模型）上进行了评估，在多个基准测试中取得了最先进的性能，并提高了推理计算效率。

Conclusion: ARC-Encoder是一种灵活且高效的解决方案，可用于便携式编码器，能够与多个LLM无缝协同工作，并且可以同时适应多个解码器，使其能够泛化到不同的解码器LLM。

Abstract: Recent techniques such as retrieval-augmented generation or chain-of-thought
reasoning have led to longer contexts and increased inference costs. Context
compression techniques can reduce these costs, but the most effective
approaches require fine-tuning the target model or even modifying its
architecture. This can degrade its general abilities when not used for this
specific purpose. Here we explore an alternative approach: an encoder that
compresses the context into continuous representations which replace token
embeddings in decoder LLMs. First, we perform a systematic study of training
strategies and architecture choices for the encoder. Our findings led to the
design of an Adaptable text Representations Compressor, named ARC-Encoder,
which outputs $x$-times fewer continuous representations (typically
$x\!\in\!\{4,8\}$) than text tokens. We evaluate ARC-Encoder across a variety
of LLM usage scenarios, ranging from in-context learning to context window
extension, on both instruct and base decoders. Results show that ARC-Encoder
achieves state-of-the-art performance on several benchmarks while improving
computational efficiency at inference. Finally, we demonstrate that our models
can be adapted to multiple decoders simultaneously, allowing a single encoder
to generalize across different decoder LLMs. This makes ARC-Encoder a flexible
and efficient solution for portable encoders that work seamlessly with multiple
LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder
, fine-tuning dataset and pretrained models are available at
https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .

</details>


### [133] [The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts](https://arxiv.org/abs/2510.20543)
*Sangmitra Madhusudan,Kaige Chen,Ali Emami*

Main category: cs.CL

TL;DR: CenterBench是一个包含9720个问题的基准测试，用于区分语言模型对句法结构的理解和对语义模式的匹配。它通过比较模型在理解有意义的中心嵌入句和无意义的类似句上的表现来量化这种区分。实验结果表明，随着句法复杂度的增加，模型在有意义和无意义句子之间的表现差距会系统性地扩大，表明它们在一定程度上放弃了结构分析而依赖语义联想。此外，语义上的合理性有时反而会阻碍模型在需要因果推理的任务上的表现。CenterBench为识别模型何时从结构分析转向模式匹配提供了首个框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法区分语言模型对句法结构的理解和对语义模式的匹配，作者旨在解决这个问题。

Method: 创建了一个名为CenterBench的数据集，包含9720个关于中心嵌入句的理解问题。每个句子都有一个句法结构相同但语义不合理的对应句。数据集包含测试表面理解、句法依赖和因果推理的问题。对六个模型进行了测试。

Result: 模型在理解有意义的句子和无意义的句子之间的表现差距随着复杂度的增加而系统性地扩大，差距中位数高达26.8个百分点。语义合理性有时会损害模型在需要因果推理的任务上的表现。推理模型虽然提高了准确率，但其分析过程显示出语义捷径、过度思考和拒绝回答等问题。与模型不同，人类在语义上的影响表现各异。

Conclusion: CenterBench提供了区分模型句法理解和语义模式匹配能力的方法，并量化了模型在何种程度上依赖语义联想而非结构分析。实验结果揭示了当前语言模型在处理复杂句法结构时存在的局限性。

Abstract: When language models correctly parse "The cat that the dog chased meowed,"
are they analyzing syntax or simply familiar with dogs chasing cats? Despite
extensive benchmarking, we lack methods to distinguish structural understanding
from semantic pattern matching. We introduce CenterBench, a dataset of 9,720
comprehension questions on center-embedded sentences (like "The cat [that the
dog chased] meowed") where relative clauses nest recursively, creating
processing demands from simple to deeply nested structures. Each sentence has a
syntactically identical but semantically implausible counterpart (e.g., mailmen
prescribe medicine, doctors deliver mail) and six comprehension questions
testing surface understanding, syntactic dependencies, and causal reasoning.
Testing six models reveals that performance gaps between plausible and
implausible sentences widen systematically with complexity, with models showing
median gaps up to 26.8 percentage points, quantifying when they abandon
structural analysis for semantic associations. Notably, semantic plausibility
harms performance on questions about resulting actions, where following causal
relationships matters more than semantic coherence. Reasoning models improve
accuracy but their traces show semantic shortcuts, overthinking, and answer
refusal. Unlike models whose plausibility advantage systematically widens with
complexity, humans shows variable semantic effects. CenterBench provides the
first framework to identify when models shift from structural analysis to
pattern matching.

</details>


### [134] [GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning](https://arxiv.org/abs/2510.20548)
*Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao*

Main category: cs.CL

TL;DR: GlobalRAG 框架通过分解问题、协调检索与推理以及迭代优化证据，利用基于奖励的规划和子目标完成机制，显著提升了多跳问答能力，并在有限数据下超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在多跳问答中存在全局规划缺失和执行不忠实的问题，限制了其有效性。

Method: 提出 GlobalRAG 框架，通过将问题分解为子目标，协调检索与推理，并迭代地优化证据。引入规划质量奖励和子目标完成奖励来指导过程，并采用渐进式权重退火策略来平衡面向过程和面向结果的目标。

Result: 在 in-domain 和 out-of-domain 基准测试中，GlobalRAG 显著优于强基线模型，在仅使用 8k 训练数据（比强基线模型少 42%）的情况下，EM 和 F1 分数平均提高了 14.2%。

Conclusion: GlobalRAG 框架有效地解决了多跳问答中的全局规划和执行忠实性问题，在有限的训练数据下也能取得优越的性能。

Abstract: Reinforcement learning has recently shown promise in improving
retrieval-augmented generation (RAG). Despite these advances, its effectiveness
in multi-hop question answering (QA) remains limited by two fundamental
limitations: (i) global planning absence to structure multi-step reasoning, and
(ii) unfaithful execution, which hinders effective query formulation and
consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement
learning framework designed to enhance global reasoning in multi-hop QA.
GlobalRAG decomposes questions into subgoals, coordinates retrieval with
reasoning, and refines evidence iteratively. To guide this process, we
introduce Planning Quality Reward and SubGoal Completion Reward, which
encourage coherent planning and reliable subgoal execution. In addition, a
progressive weight annealing strategy balances process-oriented and
outcome-based objectives. Extensive experiments on both in-domain and
out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms
strong baselines while using only 8k training data (42% of the training data
used by strong baselines), achieving average improvements of 14.2% in both EM
and F1.

</details>


### [135] [Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search](https://arxiv.org/abs/2510.20567)
*Zhouwei Zhai,Mengxiang Chen,Haoyun Xia,Jin Li,Renquan Zhou,Min Yang*

Main category: cs.CL

TL;DR: 电子商务搜索应从被动的检索转向主动的决策支持，以解决现有范式中存在的语义鸿沟、高决策成本和缺乏购物指导等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索-排序范式在电子商务搜索中存在根本性缺陷，无法满足用户多阶段的认知决策过程，导致复杂查询的语义鸿沟、跨平台信息搜寻的高成本以及缺乏专业购物指导。

Method: 提出了一种多智能体认知决策框架（MACDF），将搜索模式从被动检索转变为主动决策支持。

Result: 离线评估显示MACDF在推荐准确性和用户满意度方面取得了显著的改进，尤其是在处理涉及否定、多约束或推理的复杂查询方面。在线A/B测试也证实了其有效性。

Conclusion: 多智能体认知系统在重塑电子商务搜索方面具有变革潜力。

Abstract: The retrieval-ranking paradigm has long dominated e-commerce search, but its
reliance on query-item matching fundamentally misaligns with multi-stage
cognitive decision processes of platform users. This misalignment introduces
critical limitations: semantic gaps in complex queries, high decision costs due
to cross-platform information foraging, and the absence of professional
shopping guidance. To address these issues, we propose a Multi-Agent Cognitive
Decision Framework (MACDF), which shifts the paradigm from passive retrieval to
proactive decision support. Extensive offline evaluations demonstrate MACDF's
significant improvements in recommendation accuracy and user satisfaction,
particularly for complex queries involving negation, multi-constraint, or
reasoning demands. Online A/B testing on JD search platform confirms its
practical efficacy. This work highlights the transformative potential of
multi-agent cognitive systems in redefining e-commerce search.

</details>


### [136] [Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks](https://arxiv.org/abs/2510.20584)
*Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi*

Main category: cs.CL

TL;DR: ChatGPT在对通信数据进行编码时，在性别和种族群体之间没有表现出显著的偏见，这表明可以放心地将其用于大规模的协作和沟通评估。


<details>
  <summary>Details</summary>
Motivation: 评估大规模的沟通和协作能力需要对沟通数据进行编码，而现有方法劳动密集且可能存在偏见。本研究旨在探究像ChatGPT这样的人工智能工具在编码过程中是否存在针对不同人口统计群体的偏见。

Method: 本研究使用了一个典型的协作问题解决编码框架，对来自谈判、问题解决和决策制定三种协作任务的数据，进行了基于ChatGPT的自动化编码，并分析了跨性别和种族群体的编码差异。

Result: 研究结果表明，基于ChatGPT的编码在性别和种族群体之间没有表现出显著的偏见。

Conclusion: ChatGPT在对通信数据进行编码时，在性别和种族群体之间没有表现出显著的偏见，这为在大规模评估协作和沟通时采用该技术铺平了道路。

Abstract: Assessing communication and collaboration at scale depends on a labor
intensive task of coding communication data into categories according to
different frameworks. Prior research has established that ChatGPT can be
directly instructed with coding rubrics to code the communication data and
achieves accuracy comparable to human raters. However, whether the coding from
ChatGPT or similar AI technology exhibits bias against different demographic
groups, such as gender and race, remains unclear. To fill this gap, this paper
investigates ChatGPT-based automated coding of communication data using a
typical coding framework for collaborative problem solving, examining
differences across gender and racial groups. The analysis draws on data from
three types of collaborative tasks: negotiation, problem solving, and decision
making. Our results show that ChatGPT-based coding exhibits no significant bias
across gender and racial groups, paving the road for its adoption in
large-scale assessment of collaboration and communication.

</details>


### [137] [BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection](https://arxiv.org/abs/2510.20610)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: Busted团队在Ara-GenEval阿拉伯语AI生成文本检测任务中获得第五名，发现XLM-RoBERTa等跨语言模型在检测任务上表现优于专门的阿拉伯语模型。


<details>
  <summary>Details</summary>
Motivation: 评估三种预训练模型（AraELECTRA、CAMeLBERT和XLM-RoBERTa）在阿拉伯语AI生成文本检测任务上的有效性。

Method: 对三种模型在提供的二分类数据集上进行微调。

Result: XLM-RoBERTa模型表现最佳，F1分数为0.7701，优于专门的阿拉伯语模型。

Conclusion: 阿拉伯语AI生成文本检测具有复杂性，跨语言模型具有强大的泛化能力。

Abstract: This paper details our submission to the Ara- GenEval Shared Task on Arabic
AI-generated text detection, where our team, BUSTED, se- cured 5th place. We
investigated the effec- tiveness of three pre-trained transformer mod- els:
AraELECTRA, CAMeLBERT, and XLM- RoBERTa. Our approach involved fine-tuning each
model on the provided dataset for a binary classification task. Our findings
revealed a sur- prising result: the multilingual XLM-RoBERTa model achieved the
highest performance with an F1 score of 0.7701, outperforming the spe- cialized
Arabic models. This work underscores the complexities of AI-generated text
detection and highlights the strong generalization capa- bilities of
multilingual models.

</details>


### [138] [Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model](https://arxiv.org/abs/2510.20635)
*Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao*

Main category: cs.CL

TL;DR: LLM在信息寻求、寻求刺激和社会好奇心方面表现出比人类更强的求知欲，但在不确定的环境中倾向于做出保守的选择。好奇心可以增强LLM的推理和主动学习能力。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM是否具备类似人类的好奇心驱动学习能力。

Method: 使用5DCR问卷设计了一个全面的评估框架，涵盖信息寻求、寻求刺激和社会好奇心等方面来评估LLM的好奇心。

Result: LLM在信息寻求、寻求刺激和社会好奇心方面表现出比人类更强的求知欲，但在不确定的环境中倾向于做出保守的选择。好奇心可以增强LLM的推理和主动学习能力。

Conclusion: LLM具有展现类似人类好奇心的潜力，为未来LLM学习能力和创新研究提供了实验支持。

Abstract: Curiosity serves as a pivotal conduit for human beings to discover and learn
new knowledge. Recent advancements of large language models (LLMs) in natural
language processing have sparked discussions regarding whether these models
possess capability of curiosity-driven learning akin to humans. In this paper,
starting from the human curiosity assessment questionnaire Five-Dimensional
Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework
that covers dimensions such as Information Seeking, Thrill Seeking, and Social
Curiosity to assess the extent of curiosity exhibited by LLMs. The results
demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but
still tend to make conservative choices when faced with uncertain environments.
We further investigated the relationship between curiosity and thinking of
LLMs, confirming that curious behaviors can enhance the model's reasoning and
active learning abilities. These findings suggest that LLMs have the potential
to exhibit curiosity similar to that of humans, providing experimental support
for the future development of learning capabilities and innovative research in
LLMs.

</details>


### [139] [The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI](https://arxiv.org/abs/2510.20647)
*Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully*

Main category: cs.CL

TL;DR: 大型推理模型（LRM）在数学和科学问答任务上表现优异，但在多语言推理能力方面有待探索。本研究系统性地比较了LRM在英文推理和使用问题语言进行推理的表现。在MGSM和GPQA Diamond两个任务上，我们发现英文推理通常能带来更高的准确率，尤其是在复杂任务上。然而，这种以英文为中心的策略存在“翻译迷失”的风险，即翻译过程可能引入错误。本研究还分析了推理过程中的认知属性，发现英文推理中这些属性的出现频率更高。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRM）在数学、科学等问答任务上表现出色，但其多语言推理能力，特别是处理非英语问题的能力，尚未得到充分研究。当LRM处理非英语问题时，常常会默认转为英文推理，这引发了关于可解释性以及处理语言和文化细微差别方面的担忧。

Method: 本研究系统性地比较了大型推理模型（LRM）在英文推理和使用问题语言进行推理两种情况下的表现。评估涵盖了MGSM和GPQA Diamond两个任务。除了衡量最终答案的准确性，还分析了推理过程中的认知属性。

Result: 研究发现，与使用问题语言推理相比，英文推理通常能带来更高的最终答案准确性，并且这种性能差距随着任务复杂度的增加而扩大。此外，英文推理的推理过程中表现出更高比例的认知行为。然而，英文推理策略也可能因为翻译步骤引入错误而导致“翻译迷失”，产生一些本可避免的失误。

Conclusion: 虽然大型推理模型（LRM）在多语言问答任务上进行英文推理通常能获得更高的准确性，尤其是在处理复杂问题时，但这种策略并非没有弊端。翻译过程可能引入特定的错误模式（“翻译迷失”），并且英文推理过程中的认知行为更为显著。未来研究应关注如何提升LRM在不同语言环境下的直接推理能力，以克服翻译依赖和文化细微差别带来的挑战。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on mathematical,
scientific, and other question-answering tasks, but their multilingual
reasoning abilities remain underexplored. When presented with non-English
questions, LRMs often default to reasoning in English, raising concerns about
interpretability and the handling of linguistic and cultural nuances. We
systematically compare an LRM's reasoning in English versus the language of the
question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond
measuring answer accuracy, we also analyze cognitive attributes in the
reasoning traces. We find that English reasoning traces exhibit a substantially
higher presence of these cognitive behaviors, and that reasoning in English
generally yields higher final-answer accuracy, with the performance gap
increasing as tasks become more complex. However, this English-centric strategy
is susceptible to a key failure mode - getting "Lost in Translation," where
translation steps lead to errors that would have been avoided by question's
language reasoning.

</details>


### [140] [\textsc{CantoNLU}: A benchmark for Cantonese natural language understanding](https://arxiv.org/abs/2510.20670)
*Junghyun Min,York Hay Ng,Sophia Chan,Helena Shunhua Zhao,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: CantoNLU是一个包含七项任务的粤语自然语言理解基准，旨在解决粤语评估框架稀缺的问题。研究表明，在粤语数据稀缺的情况下，适应性模型表现最佳，而单语模型在句法任务上表现更好。


<details>
  <summary>Details</summary>
Motivation: 粤语作为一种重要的方言，由于政策和双层语言现象，其自然语言理解（NLU）的研究资源匮乏。为了弥补这一不足，需要建立一个全面的粤语NLU评估框架。

Method: 提出了CantoNLU基准，包含词义消歧、语言可接受性判断、语言检测、自然语言推断、情感分析、词性标注和依存句法分析七项任务。同时，评估了四种模型：未使用粤语训练的普通话模型、通过持续预训练改编的两种粤语模型，以及从头开始训练的单语粤语模型。

Result: 研究结果显示，适应性粤语模型在整体表现上最佳，而单语粤语模型在句法任务上表现更优。在某些情况下，普通话模型也表现出较强的竞争力，这表明在粤语领域数据有限时，直接迁移也是一种可行的策略。

Conclusion: CantoNLU基准的提出和模型的评估为粤语NLP研究提供了宝贵的资源和基线。研究结果为粤语NLU模型的设计和选择提供了指导，尤其是在数据稀缺的背景下。

Abstract: Cantonese, although spoken by millions, remains under-resourced due to policy
and diglossia. To address this scarcity of evaluation frameworks for Cantonese,
we introduce \textsc{\textbf{CantoNLU}}, a benchmark for Cantonese natural
language understanding (NLU). This novel benchmark spans seven tasks covering
syntax and semantics, including word sense disambiguation, linguistic
acceptability judgment, language detection, natural language inference,
sentiment analysis, part-of-speech tagging, and dependency parsing. In addition
to the benchmark, we provide model baseline performance across a set of models:
a Mandarin model without Cantonese training, two Cantonese-adapted models
obtained by continual pre-training a Mandarin model on Cantonese text, and a
monolingual Cantonese model trained from scratch. Results show that
Cantonese-adapted models perform best overall, while monolingual models perform
better on syntactic tasks. Mandarin models remain competitive in certain
settings, indicating that direct transfer may be sufficient when Cantonese
domain data is scarce. We release all datasets, code, and model weights to
facilitate future research in Cantonese NLP.

</details>


### [141] [Neural Diversity Regularizes Hallucinations in Small Models](https://arxiv.org/abs/2510.20690)
*Kushal Chakrabarti,Nirmal Balachundhar*

Main category: cs.CL

TL;DR: 模型参数、计算和数据增加，但语言模型仍会产生幻觉。我们提出神经多样性——解耦的并行表示——作为一种原则性机制，可以在固定的参数和数据预算下降低幻觉率。受投资组合理论的启发，我们证明了幻觉概率受表征相关性的约束，表明语言模型需要适量的神经多样性。我们通过 ND-LoRA（神经多样性低秩适配）来验证这一点，该方法结合了并行 LoRA 适配器和 Barlow Twins 正则化，结果显示 ND-LoRA 可将幻觉减少多达 25.6%（平均 14.6%），同时不损害一般准确性。消融实验表明 LoRA 适配器和正则化协同作用，因果干预证明了神经多样性是中介因素，相关性分析表明了其尺度效应，最后，任务依赖的最优性出现，不同的任务需要不同量的最优神经多样性。总之，我们的结果强调了神经多样性作为扩展的第三个维度——与参数和数据正交——以在固定预算下提高语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 幻觉是大型语言模型的一个持续存在的问题，即使在增加模型参数、计算和数据的情况下也是如此。本文旨在提出一种新的机制来解决这个问题。

Method: 本文提出了一种名为“神经多样性”（neural diversity）的机制，即解耦的并行表示。受投资组合理论的启发，他们推导出一个公式，表明幻觉概率受表征相关性的限制，并需要最优的神经多样性。为了实现这一点，他们开发了 ND-LoRA（神经多样性低秩适配），它结合了并行 LoRA 适配器和 Barlow Twins 正则化。

Result: ND-LoRA 成功地将幻觉率降低了高达 25.6%（平均 14.6%），同时没有损害模型的整体准确性。实验还表明，LoRA 适配器和 Barlow Twins 正则化之间存在协同作用，神经多样性是降低幻觉的关键因素。此外，研究还发现神经相关性增加 0.1% 会导致幻觉增加 3.8%，并且最优神经多样性水平因任务而异。

Conclusion: 神经多样性是提高语言模型可靠性的一个重要因素，可以作为扩展模型性能的第三个维度，与参数和数据量相补充。在固定预算下，通过引入神经多样性可以有效减少模型的幻觉现象。

Abstract: Language models continue to hallucinate despite increases in parameters,
compute, and data. We propose neural diversity -- decorrelated parallel
representations -- as a principled mechanism that reduces hallucination rates
at fixed parameter and data budgets. Inspired by portfolio theory, where
uncorrelated assets reduce risk by $\sqrt{P}$, we prove hallucination
probability is bounded by representational correlation: $P(H) \leq
f(\sigma^2((1-\rho(P))/P + \rho(P)), \mu^2)$, which predicts that language
models need an optimal amount of neurodiversity. To validate this, we introduce
ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA
adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces
hallucinations by up to 25.6% (and 14.6% on average) without degrading general
accuracy. Ablations show LoRA adapters and regularization act synergistically,
causal interventions prove neurodiversity as the mediating factor and
correlational analyses indicate scale: a 0.1% neural correlation increase is
associated with a 3.8% hallucination increase. Finally, task-dependent
optimality emerges: different tasks require different amounts of optimal
neurodiversity. Together, our results highlight neural diversity as a third
axis of scaling -- orthogonal to parameters and data -- to improve the
reliability of language models at fixed budgets.

</details>


### [142] [Structure-Conditional Minimum Bayes Risk Decoding](https://arxiv.org/abs/2510.20700)
*Bryan Eikema,Anna Rutkiewicz,Mario Giulianelli*

Main category: cs.CL

TL;DR: MBR解码在开放式任务（如对话或指令遵循）中可能面临挑战，通过调整效用函数可以提高其对结构变化的敏感性，从而提升生成质量。


<details>
  <summary>Details</summary>
Motivation: MBR解码在开放式任务中可能不如在机器翻译中有效，因为它可能选择代表性强但最优性差的响应，未能捕捉潜在结构。

Method: 提出三种轻量级效用函数调整方法，并创建包含对话行为、情感和响应结构（句子、段落、列表）的数据集来测试假设。提出两种评估MBR结构最优性的指标。

Result: 与标准的基于相似性的效用函数相比，提出的调整方法在结构最优性方面表现更好。在AlpacaEval和MT-Bench等指令遵循基准测试中，所提出的方法将生成质量提高了多达13.7个百分点。

Conclusion: 通过调整效用函数来提高MBR对输出空间结构变化的敏感性，可以显著改善其在开放式生成任务中的性能，特别是在指令遵循方面。

Abstract: Minimum Bayes Risk (MBR) decoding has seen renewed interest as an alternative
to traditional generation strategies. While MBR has proven effective in machine
translation, where the variability of a language model's outcome space is
naturally constrained, it may face challenges in more open-ended tasks such as
dialogue or instruction-following. We hypothesise that in such settings,
applying MBR with standard similarity-based utility functions may result in
selecting responses that are broadly representative of the model's
distribution, yet sub-optimal with respect to any particular grouping of
generations that share an underlying latent structure. In this work, we
introduce three lightweight adaptations to the utility function, designed to
make MBR more sensitive to structural variability in the outcome space. To test
our hypothesis, we curate a dataset capturing three representative types of
latent structure: dialogue act, emotion, and response structure (e.g., a
sentence, a paragraph, or a list). We further propose two metrics to evaluate
the structural optimality of MBR. Our analysis demonstrates that common
similarity-based utility functions fall short by these metrics. In contrast,
our proposed adaptations considerably improve structural optimality. Finally,
we evaluate our approaches on real-world instruction-following benchmarks,
AlpacaEval and MT-Bench, and show that increased structural sensitivity
improves generation quality by up to 13.7 percentage points in win rate.

</details>


### [143] [User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios](https://arxiv.org/abs/2510.20721)
*Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue*

Main category: cs.CL

TL;DR: LLM在处理隐私敏感信息时，用户感知与代理LLM评估存在显著差异，用户研究对于衡量LLM的隐私保护和有用性至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在处理隐私敏感信息时的能力，并了解用户感知与现有评估方法（代理LLM）之间的差异。

Method: 进行了一项包含94名参与者的用户研究，使用了90个来自PrivacyLens的场景，以评估LLM响应的隐私保护质量和有用性。

Result: 用户之间对LLM响应的隐私保护质量和有用性评价存在较低的一致性，而五个代理LLM之间却高度一致。然而，每个单独的代理LLM与用户的评价相关性较低。

Conclusion: LLM响应的隐私和有用性通常因人而异，代理LLM不能准确估计用户在隐私敏感场景下的感知。因此，需要进行以用户为中心的研究来衡量LLM在保护隐私方面的能力，并探索改善代理LLM与用户之间一致性的方法。

Abstract: Large language models (LLMs) have seen rapid adoption for tasks such as
drafting emails, summarizing meetings, and answering health questions. In such
uses, users may need to share private information (e.g., health records,
contact details). To evaluate LLMs' ability to identify and redact such private
information, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with
real-life scenarios. Using these benchmarks, researchers have found that LLMs
sometimes fail to keep secrets private when responding to complex tasks (e.g.,
leaking employee salaries in meeting summaries). However, these evaluations
rely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking
real users' perceptions. Moreover, prior work primarily focused on the
privacy-preservation quality of responses, without investigating nuanced
differences in helpfulness. To understand how users perceive the
privacy-preservation quality and helpfulness of LLM responses to
privacy-sensitive scenarios, we conducted a user study with 94 participants
using 90 scenarios from PrivacyLens. We found that, when evaluating identical
responses to the same scenario, users showed low agreement with each other on
the privacy-preservation quality and helpfulness of the LLM response. Further,
we found high agreement among five proxy LLMs, while each individual LLM had
low correlation with users' evaluations. These results indicate that the
privacy and helpfulness of LLM responses are often specific to individuals, and
proxy LLMs are poor estimates of how real users would perceive these responses
in privacy-sensitive scenarios. Our results suggest the need to conduct
user-centered studies on measuring LLMs' ability to help users while preserving
privacy. Additionally, future research could investigate ways to improve the
alignment between proxy LLMs and users for better estimation of users'
perceived privacy and utility.

</details>


### [144] [Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing](https://arxiv.org/abs/2510.20727)
*Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang*

Main category: cs.CL

TL;DR: LLM在临床笔记中提取氟嘧啶类药物治疗和毒性信息方面表现最佳，具有支持肿瘤学研究和药物警戒的潜力。


<details>
  <summary>Details</summary>
Motivation: 氟嘧啶类药物在结直肠癌和乳腺癌治疗中广泛使用，但存在手足综合征和心脏毒性等毒副作用。由于这些信息常被记录在临床笔记中，因此需要开发自然语言处理（NLP）方法来提取相关信息。

Method: 构建了一个包含236条临床笔记的黄金标准数据集，并标注了治疗方案和毒性等类别。开发了包括基于规则、机器学习（随机森林、SVM、逻辑回归）、深度学习（BERT、ClinicalBERT）和大型语言模型（LLM）（零样本和错误分析提示）在内的NLP方法，并进行了80:20的训练测试划分。

Result: 错误分析提示LLM在治疗和毒性提取方面取得了最佳性能（F1=1.000）。零样本提示LLM在治疗方面达到F1=1.000，在毒性方面达到F1=0.876。逻辑回归和SVM表现次优（F1=0.937）。深度学习模型（BERT、ClinicalBERT）和基于规则的方法性能相对较低。

Conclusion: 基于LLM的NLP方法能最有效地从临床笔记中提取氟嘧啶类药物的治疗和毒性信息，在支持肿瘤学研究和药物警戒方面显示出巨大潜力。

Abstract: Objective: Fluoropyrimidines are widely prescribed for colorectal and breast
cancers, but are associated with toxicities such as hand-foot syndrome and
cardiotoxicity. Since toxicity documentation is often embedded in clinical
notes, we aimed to develop and evaluate natural language processing (NLP)
methods to extract treatment and toxicity information.
  Materials and Methods: We constructed a gold-standard dataset of 236 clinical
notes from 204,165 adult oncology patients. Domain experts annotated categories
related to treatment regimens and toxicities. We developed rule-based, machine
learning-based (Random Forest, Support Vector Machine [SVM], Logistic
Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language
models (LLM)-based NLP approaches (zero-shot and error-analysis prompting).
Models used an 80:20 train-test split.
  Results: Sufficient data existed to train and evaluate 5 annotated
categories. Error-analysis prompting achieved optimal precision, recall, and F1
scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot
prompting reached F1=1.000 for treatment and F1=0.876 for toxicities
extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning
underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and
ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods
served as our baseline with F1 scores of 0.857 in treatment and 0.858 in
toxicities.
  Discussion: LMM-based approaches outperformed all others, followed by machine
learning methods. Machine and deep learning approaches were limited by small
training data and showed limited generalizability, particularly for rare
categories.
  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine
treatment and toxicity information from clinical notes, and has strong
potential to support oncology research and pharmacovigilance.

</details>


### [145] [Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost](https://arxiv.org/abs/2510.20780)
*Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong*

Main category: cs.CL

TL;DR: 该研究首次系统性地分析了大型推理模型（LRM）在机器翻译（MT）评估中的应用，提出了通过训练合成的、类似人类的思考轨迹来校准LRM思考过程的方法，在不显著增加计算成本的情况下提高了评估性能。


<details>
  <summary>Details</summary>
Motivation: LRM在复杂任务中表现出强大的推理能力，但其在机器翻译（MT）质量评估方面的潜力尚未得到充分探索。

Method: 通过在合成的、类似人类的思考轨迹上进行训练来校准LRM的思考过程，以解决LRM在评估MT质量时存在的挑战，例如需要定制化的评估材料、对简单实例“过度思考”以及评分机制导致的高估问题。

Result: 在WMT24 Metrics基准测试的实验表明，所提出的方法将思考成本降低了约35倍，并提高了从7B到32B不同规模LRM的评估性能，例如R1-Distill-Qwen-7B的相关性提高了8.7个点。

Conclusion: 有效校准的LRM有潜力推动细粒度的机器翻译自动评估向前发展。

Abstract: Recent advancements in large reasoning models (LRMs) have introduced an
intermediate "thinking" process prior to generating final answers, improving
their reasoning capabilities on complex downstream tasks. However, the
potential of LRMs as evaluators for machine translation (MT) quality remains
underexplored. We provides the first systematic analysis of LRM-as-a-judge in
MT evaluation. We identify key challenges, revealing LRMs require tailored
evaluation materials, tend to "overthink" simpler instances and have issues
with scoring mechanisms leading to overestimation. To address these, we propose
to calibrate LRM thinking by training them on synthetic, human-like thinking
trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this
approach largely reduces thinking budgets by ~35x while concurrently improving
evaluation performance across different LRM scales from 7B to 32B (e.g.,
R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These
findings highlight the potential of efficiently calibrated LRMs to advance
fine-grained automatic MT evaluation.

</details>


### [146] [A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text](https://arxiv.org/abs/2510.20782)
*Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock*

Main category: cs.CL

TL;DR: 当前LLM评估方法不够充分，无法满足负责任AI的需求，特别是在公平性方面，因为不同应用场景下受保护属性的关联性不同。本研究构建了一个针对特定应用（根据产品特性生成产品描述）的数据集，结合了公平性属性、性别化形容词和产品类别，生成了带标签的提示。该数据集可用于识别LLM在质量、真实性、安全性和公平性方面的差距，为LLM评估提供了一种新方法和资源。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM的方法过于笼统，无法满足负责任AI（如公平性）的具体需求，因为公平性属性在不同应用场景下的重要性不同。需要一种针对特定应用的评估方法。

Method: 构建了一个数据集，该数据集结合了公平性属性、性别化形容词和产品类别，用于生成产品描述。利用该数据集来评估LLM在质量、真实性、安全性和公平性方面的表现。

Result: 开发了一种LLM评估方法，并提供了一个具体的数据集资源，可以识别LLM在质量、真实性、安全性和公平性方面的差距。

Conclusion: 本研究提出的方法和数据集有助于更精确地评估LLM在负责任AI维度上的表现，特别是公平性，为社区提供了一个有价值的资源。

Abstract: Current methods for evaluating large language models (LLMs) typically focus
on high-level tasks such as text generation, without targeting a particular AI
application. This approach is not sufficient for evaluating LLMs for
Responsible AI dimensions like fairness, since protected attributes that are
highly relevant in one application may be less relevant in another. In this
work, we construct a dataset that is driven by a real-world application
(generate a plain-text product description, given a list of product features),
parameterized by fairness attributes intersected with gendered adjectives and
product categories, yielding a rich set of labeled prompts. We show how to use
the data to identify quality, veracity, safety, and fairness gaps in LLMs,
contributing a proposal for LLM evaluation paired with a concrete resource for
the research community.

</details>


### [147] [Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction](https://arxiv.org/abs/2510.20787)
*Mutian He,Philip N. Garner*

Main category: cs.CL

TL;DR: 线性注意力模型通过固定大小的循环状态压缩输入序列，但其有限的内存会导致遗忘，影响检索密集型任务。本研究提出混合模型，通过稀疏注意力和可学习的令牌移除机制，结合滑动窗口注意力，实现对过去和未来令牌信息的自适应保留，同时保持线性注意力的恒定时间和空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决线性注意力模型因有限内存导致的遗忘问题，该问题损害了检索密集型任务的性能。

Method: 探索了一系列混合模型，通过在令牌混合器中引入中间时间和空间复杂度（介于线性和完全注意力之间），包括具有令牌移除的稀疏注意力以及查询感知的原生稀疏注意力。特别提出了一种新颖的可学习令牌移除方法，并结合滑动窗口注意力，通过轻量级CNN聚合相邻令牌信息，自适应地保留关键KV对，保持线性注意力的效率。提供了稀疏注意力机制的高效Triton内核。

Result: 在检索密集型基准测试上进行了实证评估，结果支持所提出方法的有效性。

Conclusion: 所提出的混合模型和可学习的令牌移除方法能够有效缓解线性注意力模型的遗忘问题，并在检索密集型任务上取得良好效果。

Abstract: Linear-attention models that compress the entire input sequence into a
fixed-size recurrent state offer an efficient alternative to Transformers, but
their finite memory induces forgetfulness that harms retrieval-intensive tasks.
To mitigate the issue, we explore a series of hybrid models that restore direct
access to past tokens. We interleave token mixers with intermediate time and
space complexity between linear and full attention, including sparse attention
with token eviction, and the query-aware native sparse attention. Particularly,
we propose a novel learnable token eviction approach. Combined with
sliding-window attention, an end-to-end trainable lightweight CNN aggregates
information from both past and future adjacent tokens to adaptively retain a
limited set of critical KV-pairs per head, maintaining linear attention's
constant time and space complexity. Efficient Triton kernels for the sparse
attention mechanisms are provided. Empirical evaluations on retrieval-intensive
benchmarks support the effectiveness of our approaches.

</details>


### [148] [Simple Context Compression: Mean-Pooling and Multi-Ratio Training](https://arxiv.org/abs/2510.20797)
*Yair Feldman,Yoav Artzi*

Main category: cs.CL

TL;DR: 使用平均池化方法进行软上下文压缩，优于压缩令牌架构，并研究了多压缩比的训练。


<details>
  <summary>Details</summary>
Motivation: 减少长上下文检索增强生成（RAG）的计算成本。

Method: 开发了一种轻量级的平均池化方法，并研究了训练压缩器以输出多个压缩比。

Result: 平均池化方法在各种数据集和模型上表现最佳，并且在训练多压缩比时性能下降很小。

Conclusion: 平均池化是一种有效的软上下文压缩方法，但上下文压缩的权衡取舍很复杂。

Abstract: A common strategy to reduce the computational costs of using long contexts in
retrieval-augmented generation (RAG) with large language models (LLMs) is soft
context compression, where the input sequence is transformed into a shorter
continuous representation. We develop a lightweight and simple mean-pooling
approach that consistently outperforms the widely used compression-tokens
architecture, and study training the same compressor to output multiple
compression ratios. We conduct extensive experiments across in-domain and
out-of-domain QA datasets, as well as across model families, scales, and
compression ratios. Overall, our simple mean-pooling approach achieves the
strongest performance, with a relatively small drop when training for multiple
compression ratios. More broadly though, across architectures and training
regimes the trade-offs are more nuanced, illustrating the complex landscape of
compression methods.

</details>


### [149] [On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?](https://arxiv.org/abs/2510.20810)
*Mingmeng Geng,Thierry Poibeau*

Main category: cs.CL

TL;DR: LLM生成文本的检测目标不明确，导致检测结果的准确性和意义受到质疑。


<details>
  <summary>Details</summary>
Motivation: LLM的广泛使用促使研究者关注LLM生成文本的检测，但“LLM生成文本”缺乏统一明确的定义，且LLM的多种使用场景和模型的多样性增加了检测的难度。现有基准和评估方法未能充分考虑真实世界检测应用的各种情况，导致检测结果的数值常被误解，其意义也日益减弱。

Method: 分析了LLM生成文本检测的定义模糊性、多样性以及现有评估方法的局限性。

Result: LLM生成文本检测的目标不明确，现有评估方法存在不足，导致检测结果的数值常被误解，意义减弱。

Conclusion: LLM检测器在特定条件下仍然有用，但其结果应仅被视为参考，而非决定性指标。

Abstract: With the widespread use of large language models (LLMs), many researchers
have turned their attention to detecting text generated by them. However, there
is no consistent or precise definition of their target, namely "LLM-generated
text". Differences in usage scenarios and the diversity of LLMs further
increase the difficulty of detection. What is commonly regarded as the
detecting target usually represents only a subset of the text that LLMs can
potentially produce. Human edits to LLM outputs, together with the subtle
influences that LLMs exert on their users, are blurring the line between
LLM-generated and human-written text. Existing benchmarks and evaluation
approaches do not adequately address the various conditions in real-world
detector applications. Hence, the numerical results of detectors are often
misunderstood, and their significance is diminishing. Therefore, detectors
remain useful under specific conditions, but their results should be
interpreted only as references rather than decisive indicators.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [150] [Circuit-based cavity magnonics in the ultrastrong and deep-strong coupling regimes](https://arxiv.org/abs/2510.20115)
*Takahiro Chiba,Ryunosuke Suzuki,Takashi Otaki,Hiroaki Matsueda*

Main category: cond-mat.mes-hall

TL;DR: 腔磁子系统中的非微扰强耦合现象，通过量子化电路模型解释频率漂移，并关联到地面状态粒子数、海森堡不确定性原理相关的量子涨落和纠缠熵。


<details>
  <summary>Details</summary>
Motivation: 在腔磁子系统中理论研究非微扰强耦合现象，重点关注均匀磁化动力学（磁子）与单LC谐振腔微波磁场（光子）的耦合。

Method: 从描述磁化动力学的有效电路模型出发，对模型进行量子化，得到一个通用的腔磁子量子力学模型（Hopfield哈密顿量的双模版本），用于解释频率漂移的机制。

Result: 在超强和深强耦合区域出现非平凡的频率漂移；将频率漂移与地面状态粒子数、量子涨落和纠缠熵联系起来；利用软磁子和各向异性铁磁体，发现在外磁场作用下，磁子能带边缘的零点处，这些量子量会发散。

Conclusion: 该研究为超越传统强耦合区域的腔磁子学提供了理论基础，并提出了一种实验上获取量子资源（如地面状态粒子数、量子涨落和纠缠熵）的方法。

Abstract: We theoretically study nonperturbative strong-coupling phenomena in cavity
magnonics systems in which the uniform magnetization dynamics (magnons) in a
ferromagnet is coupled to the microwave magnetic field (photons) of a single LC
resonator. Starting from an effective circuit model that accounts for the
magnetization dynamics described by the Landau-Lifshitz-Gilbert equation, we
show that a nontrivial frequency shift emerges in the ultrastrong and
deep-strong coupling regimes, whose microscopic origin remains elusive within a
purely classical framework. The circuit model is further quantized to derive a
minimal quantum mechanical model for generic cavity magnonics, which
corresponds to a two-mode version of the Hopfield Hamiltonian and explains the
mechanism of the frequency shifts found in the {\it classical} circuit model.
We also formulate the relation between the frequency shift and quantum
quantities, such as the ground-state particle number, quantum fluctuations
associated with the Heisenberg uncertainty principle, and entanglement entropy,
providing a nondestructive means to experimentally access to these quantum
resources. By utilizing soft magnons in an anisotropic ferromagnet, we further
demonstrate that these quantum quantities diverge at the zeros of the magnon
band edges as a function of the external magnetic field. This work paves the
way for cavity magnonics beyond the conventional strong coupling regime.

</details>


### [151] [Intrinsic Non-linearity of Josephson Junctions as an Alternative Origin of the Missing First Shapiro Step](https://arxiv.org/abs/2510.20130)
*Lei Xu,Shuhang Mai,Manzhang Xu,Xue Yang,Lihong Hu,Xinyi Zheng,Sicheng Zhou,Siyuan Zhou,Bingbing Tong,Xiaohui Song,Jie Shen,Zhaozheng Lyu,Ziwei Dou,Xiunian Jing,Fanming Qu,Peiling Li,Guangtong Liu,Li Lu*

Main category: cond-mat.mes-hall

TL;DR: 低透明度约瑟夫森结中本征非线性特性可抑制第一 Shapiro 阶梯，并出现独特的锯齿边界，这为区分 Majorana 物理提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 解释在微波辐照的约瑟夫森结中，第一 Shapiro 阶梯缺失的现象，并探讨其与 Majorana 束缚态的关系，同时排除其他可能机制。

Method: 研究低-中等透明度结的本征非线性 I-V 特性，并通过微波测量和非线性 R-C 结模型数值模拟，分析第一阶梯的抑制和锯齿边界的出现。

Result: 发现低-中等透明度结的本征非线性特性可以抑制第一 Shapiro 阶梯，并伴随零阶和一阶阶梯之间出现特征性的锯齿状边界，这与仅由 eta 或焦耳热驱动的情景不同。

Conclusion: 第一 Shapiro 阶梯的缺失不一定是 Majorana 束缚态的标志，低-中等透明度结的本征非线性特性也是一个重要因素，提出的锯齿状边界特征是区分 Majorana 物理的关键诊断工具，强调了在归因于 Majorana 物理之前，需要对微波光谱进行全面分析。

Abstract: The missing first Shapiro step in microwave-irradiated Josephson junctions
has been widely interpreted as a hallmark of Majorana bound states. However,
conventional mechanisms like junction underdamping or Joule heating can produce
similar signatures. Here, we demonstrate that the intrinsic non-linear
current-voltage characteristic of low-to-moderate transparency junctions can
also suppress the first step, accompanied by distinctive zigzag boundaries
between the zeroth and first step at intermediate driving frequencies.
Microwave measurements on Al/WTe2 junctions and numerical simulations of a
non-linear resistively and capacitively shunted junction model reveal the first
step collapse induced by switching jumps of current, together with zigzag
features absent in scenarios solely driven by finite \b{eta} or Joule heating.
This zigzag signature therefore provides a crucial diagnostic tool, emphasizing
the necessity of comprehensive analysis of microwave spectra before attributing
the absence of the first Shapiro step to Majorana physics.

</details>


### [152] [Electric field induced Berry curvature dipole and non-linear anomalous Hall effect in higher wave symmetric unconventional magnets](https://arxiv.org/abs/2510.20237)
*Srimayi Korrapati,Snehasish Nandy,Sumanta Tewari*

Main category: cond-mat.mes-hall

TL;DR: 论文研究了二维高波对称磁体在电场作用下的二阶反常霍尔效应，特别是反磁体。


<details>
  <summary>Details</summary>
Motivation: 研究在对称性约束下，如何通过外加电场诱导二阶反常霍尔效应，并探讨其在区分不同对称性磁体中的应用。

Method: 通过引入对称性破坏的直流电场，利用量子度量（贝里连接极化率）耦合诱导非零的贝里曲率偶极子，进而利用交流电场产生非线性横向霍尔效应（二次谐波响应）。

Result: 证明了在高波对称性的非常规磁体（包括反磁体）中，可以观察到二阶反常霍尔效应。该效应可以作为探测量子度量的手段，并能区分不同对称性的磁体（例如d、g波和p波）。

Conclusion: 论文揭示了在高波对称磁体中，二阶反常霍尔效应可以通过电场诱导，并可用于探测材料的量子度量特性以及区分其对称性。

Abstract: We investigate the second-order anomalous Hall response in two-dimensional
higher-wave-symmetric magnets, including the recently discovered class of
collinear magnets known as altermagnets, when subjected to a symmetry-breaking
external electric field. In these systems, the first- and second-order
anomalous Hall responses mediated by the first- and second-order multipoles of
the Berry curvature over the occupied states vanish by symmetry. However, a
symmetry-breaking dc electric field can induce a nonzero Berry curvature dipole
by coupling to a nonvanishing quantum metric, also known as the Berry
connection polarizability. An applied ac electric field can then generate a
finite nonlinear transverse Hall effect characterized by a second harmonic
response. We discuss this remarkable effect in a class of
higher-order-symmetric unconventional magnets (of $p$, $d$, $f$, $g$, $i$
symmetry), including the subclass of altermagnets. We demonstrate that the
electric-field-induced anomalous Hall effect in the higher-wave-symmetric
magnets can serve not only as a probe of the underlying quantum metric of the
occupied states but also as a means to distinguish the even ($d$-,$g$-wave) and
odd ($p$-wave) order parameter symmetries defined on the square lattice.

</details>


### [153] [Emergent Massless Dirac Fermions in Moiré Bands of Bilayer Graphene/hBN Superlattice](https://arxiv.org/abs/2510.20309)
*Mohit Kumar Jat,Kenji Watanabe,Takashi Taniguchi,Aveek bid*

Main category: cond-mat.mes-hall

TL;DR: Experimental study shows hBN alignment in BLG/hBN superlattices induces topological band reconstruction, leading to massless, chiral fermions in secondary bands, with potential for controlling topological quantum transport.


<details>
  <summary>Details</summary>
Motivation: The abstract highlights the potential of graphene/hBN superlattices for engineering electronic band structures and topologies, and this work specifically aims to experimentally demonstrate the role of hBN alignment in inducing topological band reconstruction in bilayer graphene (BLG) superlattices.

Method: The study uses magnetotransport measurements, including Quantum Hall effect, temperature-dependent Shubnikov-de Haas oscillations, and Berry phase analysis, to investigate the topological properties of the bands.

Result: The results show that while the primary band in the BLG/hBN superlattice retains its massive chiral nature, the secondary bands host massless, chiral fermions. Band flattening is observed in the moir'e secondary band due to the moir'e potential, indicated by a significantly reduced Fermi velocity.

Conclusion: This research provides a method for controlling topological quantum transport in BLG/hBN superlattices by understanding and manipulating the role of hBN alignment.

Abstract: A superlattice of multilayer graphene and hBN has proven to be a promising
pathway for engineering electronic band structures and topologies. In this
work, we experimentally demonstrate the role of hBN alignment in inducing
topological band reconstruction in bilayer graphene (BLG) superlattices. Our
study establishes that while the primary band retains its massive chiral naure,
the secondary bands host massless, chiral fermions. Magnetotransport
measurements, including Quantum Hall, temperature-dependent Shubnikov-de Haas
oscillations, and Berry phase analysis, confirm the distinct topological nature
of these bands. A significantly reduced Fermi velocity in the moir\'{e}
secondary band indicates band flattening induced by the moir\'{e} potential.
Our study provides a pathway for controlling topological quantum transport in
BLG/hBN superlattices.

</details>


### [154] [Thermoelectric properties of interacting double quantum dots](https://arxiv.org/abs/2510.20397)
*Nahual Sobrino*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了库仑阻塞条件下相互作用的平行双量子点的热电输运性质，并推导了稳态电流、微分电导、塞贝克系数和热导的紧凑闭合形式表达式。研究了提高系统效率和输出功率的运行点，并阐明了它们与标准近平衡ZT表达式的关系。此外，还研究了开路和闭路配置下的热整流，并导出了开路情况下的表达式。通过相互作用诱导的共振，在栅极和偏置相关区域实现了高效率、负微分热导和有限热整流。


<details>
  <summary>Details</summary>
Motivation: 研究相互作用的平行双量子点的热电输运性质，以期确定最大化系统效率和输出功率的运行点，并研究热整流现象。

Method: 利用运动方程技术进行解析求解，并将其形式推广到不对称耦合的情况，推导出稳态电流、微分电导、塞贝克系数和热导的闭合形式表达式。在此基础上，研究了热整流现象，并推导了开路情况下的表达式。

Result: 得到了稳态电流、微分电导、塞贝克系数和热导的闭合形式表达式，确定了最大化系统效率和输出功率的运行点，并阐明了它们与标准近平衡ZT表达式的关系。研究了热整流现象，并导出了开路情况下的表达式。通过相互作用诱导的共振，在栅极和偏置相关区域观察到了高效率、负微分热导和有限热整流。

Conclusion: 相互作用诱导的共振是理解该系统热电输运性质的关键，这些共振在特定的栅极和偏置条件下会产生高效率、负微分热导和有限热整流等有趣的现象。

Abstract: We investigate the thermoelectric transport properties of an interacting
parallel double quantum dot in the Coulomb-blockade regime. Building on an
analytical solution based on an equation-of-motion technique, we extend the
formalism for the asymmetrically coupled situation and provide compact
closed-form expressions for steady-state currents together with the
differential conductance, Seebeck coefficient, and thermal conductance. We
determine the operating points that maximize efficiency and output power of the
system, clarifying their relation to standard near-equilibrium ZT expressions.
We further study the thermal rectification in both the open- and closed-circuit
configurations and derive an expression for the open-circuit case.
Interaction-induced resonances are understood in terms of the poles of the
resulting Green's function, generating gate and bias dependent regions of
enhanced efficiency at finite power, negative differential thermal conductance,
and finite thermal rectification.

</details>


### [155] [Sub-10 nm Quantification of Spin and Orbital Magnetic Moment Across the Metamagnetic Phase Transition in FeRh Using EMCD](https://arxiv.org/abs/2510.20523)
*Jan Hajduček,Veronica Leccese,Ján Rusz,Jon Ander Arregi,Alexey Sapozhnik,Jáchym Štindl,Francesco Barantani,Paolo Cattaneo,Antoine Andrieux,Vojtěch Uhlíř,Fabrizio Carbone,Thomas LaGrange*

Main category: cond-mat.mes-hall

TL;DR: 电子磁圆二色性(EMCD)技术在透射电子显微镜(TEM)中能够进行元素特定的自旋和轨道磁矩测量，但其定量准确性仍有待商榷，尤其是在使用聚焦探针的 것입니다。本研究以FeRh材料为参照，系统地评估了定量EMCD分析的极限，并将其应用于关联材料。研究结果表明，在TEM探针尺寸约为6 nm时，提取的轨道磁矩与自旋磁矩之比（m L /m S）与X射线磁圆二色性(XMCD)的基准测量结果一致，证明了其可靠的定量范围。对于nm尺寸的探针和更大的会聚角，观测到的m L /m S比值会增大，这归因于仪器因素和对探针体积内纳米尺度异质性的敏感性。该研究证实了EMCD在特定条件下可提供与宏观技术一致的定量结果，并能独特地实现对功能磁性材料中局部磁矩的空间限制测量，以及研究光子学方法无法测量的界面、缺陷或相分离磁性。


<details>
  <summary>Details</summary>
Motivation: EMCD技术在透射电子显微镜(TEM)中能够进行元素特定的自旋和轨道磁矩测量，但其定量准确性仍有待商榷，尤其是在使用聚焦探针的情况下。本研究旨在系统地评估定量EMCD分析的极限，并证明其在特定条件下的准确性。

Method: 本研究使用功能相变材料FeRh作为可调磁参考，系统地评估了定量EMCD分析的极限。研究人员使用TEM探针进行测量，并与XMCD基准进行比较，以评估EMCD的定量准确性。同时，研究还探讨了探针尺寸、会聚角以及材料的纳米尺度异质性对EMCD测量结果的影响。

Result: 在TEM探针尺寸约为6 nm时，提取的轨道磁矩与自旋磁矩之比（m L /m S）与XMCD基准测量结果一致，证明了EMCD在约6 nm的空间分辨率下具有可靠的定量准确性。对于更小的探针尺寸和更大的会聚角，观测到的m L /m S比值会增大，这归因于仪器因素和对材料纳米尺度异质性的敏感性。EMCD技术能够对功能磁性材料进行空间限制测量，并研究光子学方法无法测量的磁性现象。

Conclusion: EMCD技术在特定条件下（如探针尺寸约为6 nm）能够提供与宏观技术一致的定量结果，并且能够实现对功能磁性材料中局部磁矩的空间限制测量。这项技术为研究界面、缺陷或相分离磁性等传统方法难以触及的现象提供了独特的工具。

Abstract: Electron magnetic circular dichroism (EMCD) in transmission electron
microscopy (TEM) enables element-specific measurement of spin and orbital
magnetic moments, analogous to X-ray magnetic circular dichroism (XMCD). While
the EMCD technique offers unmatched spatial resolution, its quantitative
accuracy remains under scrutiny, particularly in beam-splitter geometries with
convergent probes. Here, we systematically evaluate the limits of quantitative
EMCD analysis using the first-order magnetostructural transition in the
functional phase-change material FeRh as a tunable magnetic reference. Unlike
previous EMCD studies primarily focused on elemental ferromagnets such as Fe,
we demonstrate its applicability to a correlated material exhibiting coupled
structural and magnetic order. We demonstrate that the extracted
orbital-to-spin moment ratio ($m_\text{L}/m_\text{S}$) remains consistent with
XMCD benchmarks for TEM probes down to approximately 6 nm, thereby establishing
the validity range for reliable quantification. For nm-sized probes with higher
convergence angles, we observe an enhanced $m_\text{L}/m_\text{S}$, which we
attribute to a combination of instrumental factors and sensitivity to nanoscale
heterogeneity within the probed volume. Our results confirm that EMCD provides
quantitative agreement with macroscale techniques under suitable conditions,
while uniquely enabling spatially confined measurements of local magnetic
moments in functional magnetic materials, and allowing the study of
interfacial, defect-mediated, or phase-separated magnetism that is inaccessible
to photon-based methods.

</details>


### [156] [Quantifying robustness and locality of Majorana bound states in interacting systems](https://arxiv.org/abs/2510.20538)
*William Samuelson,Juan Daniel Torres Luna,Sebastian Miles,A. Mert Bozkurt,Martin Leijnse,Michael Wimmer,Viktor Svensson*

Main category: cond-mat.mes-hall

TL;DR: 量子计算中的拓扑超导体受马约拉纳束缚态（MBS）保护，但需在相互作用系统中建立MBS分离、退化和编织的联系。


<details>
  <summary>Details</summary>
Motivation: 在相互作用的系统中，建立MBS分离、鲁棒退化和受保护的编织之间的联系，并严格处理它们。

Method: 从多体基态定义MBS，并量化它们与环境的耦合限制了能量退化的保护以及非阿贝尔编织的可行性。

Result: MBS的分离度、鲁棒退化和非阿贝尔编织的可行性。

Conclusion: MBS的分离度提供了鲁棒退化和非阿贝尔编织的可行性，这在相互作用系统中得到了严格的证明。

Abstract: Protecting qubits from perturbations is a central challenge in quantum
computing. Topological superconductors with separated Majorana bound states
(MBSs) provide a strong form of protection that only depends on the locality of
perturbations. While the link between MBS separation, robust degeneracy, and
protected braiding is well understood in non-interacting systems, recent
experimental progress in short quantum-dot-based Kitaev chains highlights the
need to establish these connections rigorously for interacting systems. We do
this by defining MBSs from many-body ground states and show how their locality
constrains their coupling to an environment. This, in turn, quantifies the
protection of the energy degeneracy and the feasibility of non-abelian
braiding.

</details>


### [157] [Time-braiding phase of anyons tied to the nonuniversal scaling dimension](https://arxiv.org/abs/2510.20592)
*Aleksander Latyshev,Ines Safi*

Main category: cond-mat.mes-hall

TL;DR: 文章提出了一种连接直流噪声和响应函数的时域编织非平衡涨落耗散关系，并利用克莱默斯-克罗尼格关系推导了包含时间编织相位$	heta$的直流电流和噪声积分方程。在热平衡状态下，通过维纳-霍普夫技术得到直流电流的解析解，表明时间编织相位由标度律维度$f	au$决定，这与拓扑保护的空间域编织相位不同，并引发了对$f	heta$普适性的质疑，$f	heta$可以反映微观边缘动力学。


<details>
  <summary>Details</summary>
Motivation: 文章旨在研究非平衡系统中的涨落耗散关系，特别是直流噪声和响应函数之间的联系，并探讨时间编织相位$	heta$的性质及其普适性。

Method: 文章采用了统一非平衡微扰理论（UNEPT），利用时域编织非平衡涨落耗散关系连接直流噪声和响应函数，并通过克莱默斯-克罗尼格关系得到包含$	heta$的积分方程。在热平衡条件下，使用维纳-霍普夫技术求解该方程，得到直流电流的解析解，并分析时间编织相位$	heta$与标度律维度$f	au$的关系。

Result: 文章得到了直流电流的解析解，并发现时间编织相位$	heta$由标度律维度$f	au$决定。

Conclusion: 文章的结论是，时间编织相位$	heta$由标度律维度$f	au$决定，这表明$	heta$可能反映微观边缘动力学，并质疑了其普适性，这与拓扑保护的空间域编织相位形成了对比。

Abstract: We use a braiding nonequilibrium fluctuation dissipation relation linking the
DC noise to the response function inferred from the braiding constraint in the
time-domain with a phase $\theta$ within the UNEPT (Unified Non equilibrium
Perturbative Theory). By applying the Kramers-Kr\"onig relations, we obtain an
integral equation connecting DC current and noise that involves $\theta$. By
specifying to thermal states so that noise is Poissonian, we find an analytical
solution for the DC current via the Wiener-Hopf technique. It reveals that the
time-braiding phase is determined by the scaling dimension~$\delta$. This
questions the universality of $\theta$ that can reflect the microscopic edge
dynamics, in contrast to the topologically protected braiding phase in the
space domain.

</details>


### [158] [Computational Design Rules for Helical Aromatic Foldamers: $π-π$ Stacking, Solvent Effects, and Conformational Stability](https://arxiv.org/abs/2510.20638)
*Kseniia Storozheva,Anastasia Markina,Vladik Avetisov*

Main category: cond-mat.mes-hall

TL;DR: 使用基于量子化学计算的系统方法，评估了溶剂依赖的机械行为，结合了π-π堆积相互作用、构象能量学和环境效应的分析，从而为快速筛选具有改进机械和稳定性特性的新型螺旋折叠体提供了设计原则。


<details>
  <summary>Details</summary>
Motivation: 开发具有双稳态行为和可调特性的分子尺度材料，用于下一代纳米级电子设备，并解决螺旋折叠体对构象稳定性和环境条件敏感的问题。

Method: 提出了一种基于量子化学计算的系统方法，用于评估溶剂依赖的机械行为，并结合了π-π堆积相互作用、构象能量学和环境效应的分析。

Result: 开发了一种可用于快速筛选新化合物的简单设计原则，能够评估其构象稳定性和有效机械刚性。此外，还确定了一种改进的螺旋芳香折叠体，与初始参考化合物相比，具有改进的机械和稳定性特性。

Conclusion: 所提出的基于量子化学计算的系统方法和识别出的设计原则，能够有效地评估和设计具有改进机械和稳定性特性的螺旋折叠体，以满足下一代纳米电子设备的需求。

Abstract: Molecular-scale materials with bistable behavior and tunable properties are
increasingly relevant for next-generation nanoscale electronic devices. Helical
foldamers are promising candidates, but their structural and mechanical
properties are highly sensitive to conformational stability and environmental
conditions. A systematic methodology based on quantum-chemical calculations is
proposed for assessing solvent-dependent mechanical behavior, combining
analysis of $\pi-\pi$ stacking interactions, conformational energetics, and
environmental effects. Using this methodology we identified simple design
principles for the rapid screening of new compounds, allowing evaluation of
their conformational stability and effective mechanical rigidity. Applying
these principles, we identify a modified helical aromatic foldamer that
exhibits improved mechanical and stability characteristics compared to the
initial reference compound.

</details>


### [159] [Conductance Anomaly in a Partially Open Adiabatic Quantum Point Contact](https://arxiv.org/abs/2510.20678)
*Donghao Liu,Dmitri Gutman*

Main category: cond-mat.mes-hall

TL;DR: 部分开放的量子点接触中，反散射和电子相互作用会引起一种奇特的电导修正，在通道半开放时达到最大值，导致电导降低。此外，垂直于自旋-轨道轴的磁场会引起法布里-珀罗干涉类型的电导振荡，并导致异常的非单调磁场依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究部分开放的量子点接触中，由电子相互作用引起的反常电导现象，并探索磁场对其的影响。

Method: 通过理论分析，研究了部分开放通道的量子点接触中的反散射、弗里德尔振荡以及电子相互作用对电导的影响。同时，考虑了垂直磁场对单粒子谱和法布里-珀罗干涉的影响。

Result: 发现部分开放的量子点接触中存在电导异常，反散射和电子相互作用可产生奇特的电导修正，当通道半开放时电导降低。磁场会引起电导振荡和非单调磁场依赖性。

Conclusion: 电子相互作用提供了一种普适机制，可以改变理想部分开放通道的电导，并可能解释实验中观察到的反常特征。

Abstract: We demonstrate that conductance anomalies can arise in a clean, adiabatic
quantum point contact when a channel is partially open. Even for a smooth
barrier potential, backscattering induces Friedel oscillations that, via
electron interactions, generate a singular correction to the conductance. This
correction is maximized when the channel is half-open, resulting in a reduction
of conductance. In addition, a magnetic field applied perpendicular to the
spin-orbit axis modifies the single-particle spectrum, resulting in conductance
oscillations via Fabry-P\'erot-type interference, as well as a non-monotonic
field dependence of the anomaly. Our findings reveal a universal mechanism by
which interactions modify the conductance of an ideal partially open channel
and offer a possible explanation for the anomalous features observed in
experiments.

</details>


### [160] [Anomalous Hall effect in rhombohedral graphene](https://arxiv.org/abs/2510.20804)
*Vera Mikheeva,Daniele Guerci,Daniel Kaplan,Elio J. König*

Main category: cond-mat.mes-hall

TL;DR: rhombohedral stacked multilayer graphene and anomalous Hall effect in a spontaneous spin-valley polarized quarter metal state


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the anomalous Hall effect in rhombohedral stacked multilayer graphene, particularly in the presence of different types of impurities.

Method: The study uses the Kubo-Streda diagrammatic approach to calculate the anomalous Hall conductivity. It considers weak, dense impurities (Gaussian disorder) and sparse, strong impurities. For weak dense impurities, all non-crossing diagrams and some crossing diagrams (X and Psi) are included. For sparse strong impurities, a "Mercedes star" diagram is used. Analytical solutions for an isotropic model are supplemented by semi-numerical calculations that account for warping effects.

Result: The calculation of anomalous Hall conductivity (sigma_xy) is performed for the described system and impurity types.

Conclusion: The paper calculates the anomalous Hall conductivity for rhombohedral stacked multilayer graphene with different impurity types using the Kubo-Streda diagrammatic approach, including various scattering processes and warping effects.

Abstract: Motivated by recent experiments on rhombohedral stacked multilayer graphene
and the observation of the anomalous Hall effect in a spontaneous spin-valley
polarized quarter metal state, we calculate the anomalous Hall conductivity for
this system in the presence of two types of impurities: weak and dense as well
as sparse and strong. Our calculation of $\sigma_{xy}$ is based on the
Kubo-Streda diagrammatic approach. In a model with Gaussian disorder applicable
to weak dense impurities, this involves all non-crossing diagrams (intrinsic,
side-jump and Gaussian skew-scattering contributions) and additionally diagrams
with two intersecting impurities, X and $\Psi$, representing diffractive
skew-scattering processes. A "Mercedes star" diagram (non-Gaussian skew
scattering) is furthermore included to treat in the case of strong, sparse
impurities. We supplement our asymptotically exact analytical solutions for an
isotropic model without warping effects by semi-numerical calculations
accounting perturbatively for warping, which plays a crucial role in the
low-energy band structure.

</details>


### [161] [Charge-density waves and stripes in quarter metals of graphene heterostructures](https://arxiv.org/abs/2510.20816)
*Sk Asrap Murshed,Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 本篇论文研究了手性堆叠n层石墨烯中的谷相干电荷密度波（VC-CDW）有序相，该相具有2K的特征周期性。研究表明，VC-CDW在偶数层数n的情况下会破坏三重旋转对称性（C3），而在奇数层数n的情况下则保留C3对称性。此外，论文还探讨了VC-CDW与反常霍尔序在受到垂直位移场作用时如何解除半金属的反铁磁序的剩余谷简并性，并揭示了这两种序在四分之一金属中存在的共存机制。


<details>
  <summary>Details</summary>
Motivation: 由于近期实验的启发，本研究旨在识别手性堆叠n层石墨烯（包括菱面多层、伯纳尔双层和单层石墨烯）的四分之一金属中的谷相干电荷密度波（VC-CDW）有序相。

Method: 通过克利福德代数论证，研究了VC-CDW和反常霍尔序在垂直位移场作用下如何解除反铁磁半金属的谷简并性，并分析了VC-CDW在奇偶层数n下的对称性表现。

Result: 研究发现，VC-CDW具有2K的特征周期性，并根据n的奇偶性表现出不同的C3对称性。VC-CDW和反常霍尔序可以解除谷简并性，其中只有反常霍尔序表现出迟滞现象。在四分之一金属中，VC-CDW和反常霍尔序存在共存区。

Conclusion: VC-CDW有序相存在于整个手性堆叠n层石墨烯家族中，其对称性行为与n的奇偶性相关。VC-CDW与反常霍尔序的结合能够解除谷简并性，并在四分之一金属中形成共存机制。

Abstract: Motivated by recent experiments, here we identify valley-coherent
charge-density wave (VC-CDW) order in the non-degenerate quarter-metal for the
entire family of chirally-stacked $n$ layer graphene, encompassing rhombohedral
multi-layer, Bernal bilayer, and monolayer cousins. Besides the hallmark broken
translational symmetry, yielding a modulated charge-density over an enlarged
unit-cell with a characteristic $2{\bf K}$ periodicity, where $\pm {\bf K}$ are
the valley momenta, this phase lacks the three-fold ($C_3$) rotational symmetry
but only for even integer $n$. The VC-CDW then represents a stripe order, as
observed in hexalayer graphene [arXiv:2504.05129], but preserves the $C_3$
symmetry for odd $n$ as observed in trilayer graphene [Nat. Phys. 20, 1413
(2024) and arXiv: 2411.11163]. From a universal Clifford algebraic argument, we
establish that the VC-CDW and an anomalous Hall order can lift the residual
valley degeneracy of an antiferromagnetically ordered spin-polarized
half-metal, when these systems are subject to perpendicular displacement
fields, with only the latter one displaying a hysteresis in off-diagonal
resistivity, as observed in all the systems with $2 \leq n \leq 6$. We showcase
a confluence of VC-CDW and anomalous Hall orders within the quarter-metal,
generically displaying a regime of coexistence, separating the pure phases.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [162] [Optimized Distortion in Linear Social Choice](https://arxiv.org/abs/2510.20020)
*Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik*

Main category: cs.GT

TL;DR: 当选民拥有对这些选项的潜在效用时，使用偏好排名可能会导致相对于功利主义社会福利的最优结果。扭曲是这种非最优性的度量，并在效用具有最小结构时为开发和分析投票规则提供了一种最坏情况的方法。然而，在许多环境中，例如价值对齐的常见范式，备选项承认向量表示，并且假设效用是它们的参数函数是很自然的。我们对线性效用的扭曲进行了首次研究。具体来说，我们研究了确定性和随机投票规则的线性社会选择的扭曲。我们获得的界限仅取决于候选人嵌入的维度，而与候选人或选民的数量无关。此外，我们针对给定候选人和选票集合最小化扭曲的实例最优算法引入了多项式时间。我们在两个真实世界的领域中对它们进行了经验评估：使用协作过滤嵌入的推荐系统，以及利用语言模型嵌入的意见调查，将几个标准规则与我们的实例最优算法进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 当选民拥有对这些选项的潜在效用时，使用偏好排名可能会导致相对于功利主义社会福利的最优结果。扭曲是这种非最优性的度量，并在效用具有最小结构时为开发和分析投票规则提供了一种最坏情况的方法。然而，在许多环境中，例如价值对齐的常见范式，备选项承认向量表示，并且假设效用是它们的参数函数是很自然的。

Method: 我们对线性效用的扭曲进行了首次研究。具体来说，我们研究了确定性和随机投票规则的线性社会选择的扭曲。我们获得了仅取决于候选人嵌入维度且与候选人数量或选民数量无关的界限。此外，我们针对给定候选人和选票集合最小化扭曲的实例最优算法引入了多项式时间。

Result: 我们获得了仅取决于候选人嵌入维度且与候选人数量或选民数量无关的界限。此外，我们针对给定候选人和选票集合最小化扭曲的实例最优算法引入了多项式时间。我们在两个真实世界的领域中对它们进行了经验评估：使用协作过滤嵌入的推荐系统，以及利用语言模型嵌入的意见调查，将几个标准规则与我们的实例最优算法进行了基准测试。

Conclusion: 我们对线性效用的扭曲进行了首次研究，并获得了仅取决于候选人嵌入维度且与候选人数量或选民数量无关的界限。此外，我们还引入了用于最小化给定候选人和选票集合失真的实例最优算法，并在推荐系统和意见调查的实际域中对它们进行了经验评估。

Abstract: Social choice theory offers a wealth of approaches for selecting a candidate
on behalf of voters based on their reported preference rankings over options.
When voters have underlying utilities for these options, however, using
preference rankings may lead to suboptimal outcomes vis-\`a-vis utilitarian
social welfare. Distortion is a measure of this suboptimality, and provides a
worst-case approach for developing and analyzing voting rules when utilities
have minimal structure. However in many settings, such as common paradigms for
value alignment, alternatives admit a vector representation, and it is natural
to suppose that utilities are parametric functions thereof. We undertake the
first study of distortion for linear utility functions. Specifically, we
investigate the distortion of linear social choice for deterministic and
randomized voting rules. We obtain bounds that depend only on the dimension of
the candidate embedding, and are independent of the numbers of candidates or
voters. Additionally, we introduce poly-time instance-optimal algorithms for
minimizing distortion given a collection of candidates and votes. We
empirically evaluate these in two real-world domains: recommendation systems
using collaborative filtering embeddings, and opinion surveys utilizing
language model embeddings, benchmarking several standard rules against our
instance-optimal algorithms.

</details>


### [163] [Strategic Costs of Perceived Bias in Fair Selection](https://arxiv.org/abs/2510.20606)
*L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi*

Main category: cs.GT

TL;DR: Despite aiming for impartiality, meritocratic systems perpetuate disparities due to differing perceived post-selection value, influenced by social context and AI. Strategic effort choices by candidates, based on these perceptions, lead to observable merit and selection. The unique Nash equilibrium reveals how valuation disparities and institutional selectivity jointly impact effort, representation, social welfare, and utility. A cost-sensitive optimization framework suggests modifying selectivity or perceived value can reduce disparities without compromising institutional goals. The analysis highlights a perception-driven bias where differing perceptions lead to rational differences in effort, creating disparities even in fair selection processes. This static model captures a feedback loop linking perceptions, incentives, and outcomes, bridging rational-choice and structural explanations of inequality by demonstrating how techno-social environments shape individual incentives.


<details>
  <summary>Details</summary>
Motivation: To understand how perceived post-selection value, influenced by social context and AI, affects disparities in meritocratic systems, where candidates strategically choose effort based on expected rewards, leading to selection solely on merit.

Method: Developed a game-theoretic model with candidates from different socioeconomic groups, differing in perceived post-selection value. Analyzed the unique Nash equilibrium in the large-agent limit and derived explicit formulas. Proposed a cost-sensitive optimization framework to quantify the effects of modifying selectivity or perceived value.

Result: Derived explicit formulas showing how valuation disparities and institutional selectivity jointly determine effort, representation, social welfare, and utility. Proposed a cost-sensitive optimization framework to quantify how modifying selectivity or perceived value can reduce disparities without compromising institutional goals. Revealed a perception-driven bias where differing perceptions translate into rational differences in effort, propagating disparities backward through selection processes.

Conclusion: Differing perceptions of post-selection value create rational differences in effort, leading to disparities in meritocratic systems, even with fair selection processes. Techno-social environments shape individual incentives, bridging rational-choice and structural explanations of inequality. Modifying selectivity or perceived value can reduce disparities without compromising institutional goals.

Abstract: Meritocratic systems, from admissions to hiring, aim to impartially reward
skill and effort. Yet persistent disparities across race, gender, and class
challenge this ideal. Some attribute these gaps to structural inequality;
others to individual choice. We develop a game-theoretic model in which
candidates from different socioeconomic groups differ in their perceived
post-selection value--shaped by social context and, increasingly, by AI-powered
tools offering personalized career or salary guidance. Each candidate
strategically chooses effort, balancing its cost against expected reward;
effort translates into observable merit, and selection is based solely on
merit. We characterize the unique Nash equilibrium in the large-agent limit and
derive explicit formulas showing how valuation disparities and institutional
selectivity jointly determine effort, representation, social welfare, and
utility. We further propose a cost-sensitive optimization framework that
quantifies how modifying selectivity or perceived value can reduce disparities
without compromising institutional goals. Our analysis reveals a
perception-driven bias: when perceptions of post-selection value differ across
groups, these differences translate into rational differences in effort,
propagating disparities backward through otherwise "fair" selection processes.
While the model is static, it captures one stage of a broader feedback cycle
linking perceptions, incentives, and outcome--bridging rational-choice and
structural explanations of inequality by showing how techno-social environments
shape individual incentives in meritocratic systems.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [164] [Resource-Aware Hybrid Quantum Programming with General Recursion and Quantum Control](https://arxiv.org/abs/2510.20452)
*Kostia Chardonnet,Emmanuel Hainry,Romain Péchoux,Thomas Vinet*

Main category: cs.LO

TL;DR: 该论文介绍了一种混合量子语言Hyrql，用于资源分析。Hyrql无需指定初始量子门集，便于进行通用成本分析。论文描述了一种保留语义的编译算法，可将Hyrql编译为简单类型项重写系统，从而利用现有的项重写系统复杂性分析技术。通过多个示例证明了该方法的通用性。


<details>
  <summary>Details</summary>
Motivation: Hyrql语言旨在进行资源分析，其设计无需指定初始量子门集，便于进行通用成本分析，因为不同的量子门集会影响量子电路的复杂性。

Method: 将Hyrql编译为保留语义的简单类型项重写系统，以便复用已有的项重写系统复杂性分析技术。

Result: 通过多个示例证明了该方法的通用性。

Conclusion: Hyrql语言及其编译到项重写系统的编译算法为量子计算的资源分析提供了一种通用的方法。

Abstract: This paper introduces the hybrid quantum language with general recursion
$\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\mathtt{Hyrql}$
does not require the specification of an initial set of quantum gates and,
hence, is well amenable towards a generic cost analysis. Indeed, languages
using different sets of quantum gates lead to representations of quantum
circuits whose complexity varies. Towards resource-analysis, a
semantics-preserving compilation algorithm to simply-typed term rewrite systems
is described; allowing a generic reuse of all known techniques for analyzing
the complexity of term rewrite systems. We prove the versatility of this
approach through many examples.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [165] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 本文提出了一个配置相关运动学标定框架，通过插值局部指数积（POE）模型到全局模型来提高机器人精度，可满足冷喷涂制造的亚毫米级精度要求。


<details>
  <summary>Details</summary>
Motivation: 机器人运动学精度对于精确放置工具至关重要，但非几何因素可能导致依赖于配置的模型差异。

Method: 该框架在多个配置下识别局部指数积（POE）模型，并使用受关节重力载荷表达式启发的傅里叶基函数插值到全局模型。

Result: 与神经网络和自编码器方法相比，该方法实现了可比的精度，但训练效率显著提高。在两台工业机器人上的验证显示，最大定位误差减少了50%以上。双机器人协作任务证明了该框架的实际适用性和可重复性。

Conclusion: 所提出的配置相关运动学标定框架能够有效提高机器人精度，特别是对于具有较大配置相关差异的机器人，并满足冷喷涂制造的精度要求。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [166] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 本研究展示了接触隐式模型预测控制（CI-MPC）在处理各种物体几何形状和多物体场景下的精确平面推动任务中的广泛能力，并引入了增强的CI-MPC算法C3+，实现了实时性能和高成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人非抓取操纵中因物理属性未知和接触交互复杂性带来的挑战，并扩展了先前CI-MPC方法在狭窄场景下的局限性。

Method: 引入了增强的接触隐式模型预测控制算法——共识互补控制加（C3+），并将其整合到包括物体扫描、网格重建和硬件执行的完整流程中，以实现对包括多物体在内的各种物体几何形状的精确平面推动。

Result: C3+算法实现了比前代C3更快的求解时间，能够在多物体推动任务中实现实时性能。在硬件实验中，系统在33个物体上实现了98%的总体成功率，并将姿态目标控制在严格的容差范围内。对于1、2、3和4个物体的任务，达到目标姿态的平均时间分别为0.5、1.6、3.2和5.3分钟。

Conclusion: 研究表明，C3+算法能够有效地处理具有复杂接触动力学的多样化物体操纵任务，显著提高了CI-MPC在现实机器人应用中的能力和效率。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [167] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 本研究提出了一种基于强化学习的无人机飞行策略，能够实现任意起点和终点之间的最小时间通用导航，并在敏捷飞行和稳定悬停之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 传统无人机自主飞行方法（尤其是在赛车领域）虽然速度快、机动性强，但受限于预设的赛道布局，难以推广到实际应用。因此，需要一种能够处理任意状态之间转换的通用飞行策略。

Method: 提出了一种强化学习框架，该框架能同时学习状态到状态的最小时间规划与控制，并具备泛化能力。具体来说，利用点质量模型（PMM）轨迹作为代理奖励来近似真实的最小时间飞行目标，并采用课程学习（curriculum learning）策略来高效扩展训练过程并实现泛化。

Result: 通过仿真实验验证了所提出方法的有效性，并与跟踪PMM生成轨迹的非线性模型预测控制（NMPC）进行了比较。同时，还进行了消融研究以评估课程学习策略的影响。在真实世界的户外环境中进行的实验证明了该学习策略的鲁棒性，并验证了其在小型ARM嵌入式单板计算机上的运行能力。

Conclusion: 本研究成功开发了一种能够实现通用状态到状态最小时间飞行的强化学习策略，并在仿真和真实世界的实验中都证明了其有效性和泛化能力，为无人机在更广泛的应用场景中的自主导航提供了新的解决方案。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [168] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: Stewart平台运动学(PKM)机器因其精细的控制特性而被广泛研究，尤其是在医疗、工程、航天、芯片制造和汽车制造等领域。为了实现微纳米级别的3D运动控制，需要对6-DOF PKM进行精确校准。本文回顾了基于逆运动学的PKM校准方法，包括外部仪器法、约束法和自校准法，并分析了它们在提高平台位置和姿态精度方面的研究进展，同时指出了现有研究主要关注结构误差，且多在无负载条件下进行，为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: Stewart平台基并联运动学(PKM)机器在精密运动控制领域具有广泛应用潜力，但其精度要求极高，因此需要进行精确校准。本文旨在梳理现有校准技术，为相关领域的研究者提供参考。

Method: 本文通过回顾外部仪器法、约束法和自校准法等关键方法，总结了基于逆运动学的PKM校准技术及其研究成果。

Result: 研究表明，研究者们致力于提高平台的位置和姿态精度，考虑了单一或多重误差源（主要是结构误差，有时也包括环境因素），但现有校准多在无负载条件下进行。

Conclusion: 现有PKM校准技术在提高精度方面取得了进展，但仍有改进空间，特别是在考虑负载和更复杂环境因素方面。本文旨在总结现状并为未来研究开辟道路。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [169] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种去中心化强化学习（Dec-RL）方案，用于模块化可重构机器人，实现了跨形态的零样本泛化控制。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人在特定任务的空间操作中具有优势，但形态组合的爆炸式增长阻碍了统一控制。本研究旨在解决这一挑战。

Method: 采用去中心化强化学习（Dec-RL）方案，其中每个模块学习自己的策略：轮式模块使用SAC进行运动，7-DoF执行器模块使用PPO进行转向和操作，从而实现对未见过的配置的零样本泛化。

Result: 在仿真中，转向策略实现了期望角度和诱导角度之间的3.63度的平均绝对误差；操作策略在目标偏移标准下达到了84.6%的成功率；轮式策略将平均电机扭矩降低了95.4%，同时保持了99.6%的成功率。月球模拟实地测试验证了自主运动、转向和重构初步对齐的零样本集成能力。

Conclusion: 该系统在策略执行中实现了同步、并行和顺序模式的平稳过渡，没有出现空闲状态或控制冲突，表明这是一种可扩展、可重用且鲁棒的模块化月球机器人方法。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [170] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文介绍了一种用于聚合物熔融沉积建模（FDM）工艺研究的新型3D打印平台，该平台具有精确的参数控制、环境监测和在制品摄影测量功能，旨在实现可重复的实验并精确记录打印过程，以研究工艺参数与几何缺陷之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有消费级和商用级3D打印机在研究应用方面存在局限性，例如缺乏灵活性、通常是闭源平台，无法满足研究人员对精确控制和监测打印参数的需求。

Method: 设计并制造了一个能够精确控制和监测FDM打印参数（如闭环位置反馈、热端和打印床温度控制、环境温湿度监测）的3D打印平台。该平台还配备了摄像头和在制品摄影测量机制，用于记录打印过程中的几何形状。

Result: 通过摄影测量技术，可以实现对打印过程中几何形状的记录，并能够将工艺参数与观察到的几何缺陷联系起来。本文重点介绍了一种新颖的加热打印床旋转机制，该机制允许使用最少数量的摄像头进行打印部件的摄影测量重建。

Conclusion: 所设计的平台为聚合物FDM工艺研究提供了一个可重复、可精确控制的测试平台，其新颖的旋转打印床设计和摄影测量功能有助于深入理解打印参数对最终产品质量的影响。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [171] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 提出了一种基于路径的Transformer，使用3网格（地点/内容/时间）表示和约束掩码解码来规划机器人轨迹，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 机器人手臂的轨迹规划需要精确且任务感知，而忽略运动结构的序列模型通常会导致无效或低效的执行。

Method: 使用3网格（地点/内容/时间）表示和约束掩码解码来编码机器人运动，强制执行相邻移动和工作空间边界，同时推理任务图和动作顺序。模型在53,755条轨迹上进行训练。

Result: 模型在步进精度、精确率、召回率和F1分数上表现出色（分别为89.44%、93.32%、89.44%和90.40%），并且99.99%的路径在构造上是合法的。在xArm Lite 6机器人上进行了测试，成功率高达97.5%（到达）和92.5%（拾取），在60个语言指定的任务中端到端成功率达到86.7%，并且能够处理滑动和遮挡。

Conclusion: 基于路径的表示使Transformer能够生成准确、可靠且可解释的机器人轨迹，弥合了基于图的规划和基于序列的学习之间的差距，并为通用操作和仿真到现实转移提供了实际基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [172] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 本研究提出了一个强化学习框架，用于解决四足磁力爬壁行走中磁力吸附不确定性的问题。通过引入包含不完全接触、气隙敏感性和概率性吸附失效的物理吸附模型，并结合分阶段课程学习策略（地面爬行、重力向量旋转、吸附失效注入），成功训练出能够应对吸附能力下降和实现滑移恢复的策略。实验结果表明，该方法相比于传统MPC方法在吸附力不稳定时表现出更强的鲁棒性，并且在真实硬件上验证了其在钢制表面垂直爬行和稳定性的能力。


<details>
  <summary>Details</summary>
Motivation: 解决四足磁力爬壁行走中磁力吸附不确定性的问题，提高机器人在复杂环境下的鲁棒性和可靠性。

Method: 提出一种强化学习框架，并结合物理吸附模型和分阶段课程学习策略（地面爬行、重力向量旋转、吸附失效注入）。

Result: 学习到的策略在模拟环境中实现了高成功率、强的吸附保持能力以及从吸附分离中快速恢复的能力，并且在真实硬件实验中得到了验证。

Conclusion: 结合课程学习和真实的吸附模型，为磁力爬壁机器人在复杂环境中提供了具有鲁棒性的仿真到现实（sim-to-real）框架。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [173] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 本论文提出了一个在视觉受限环境下机器人盲操作的框架，结合了触觉反馈和结构先验，实现了鲁棒的导航和任务完成。


<details>
  <summary>Details</summary>
Motivation: 在视觉信息不足（如遮挡、光线不足）的环境下，机器人需要利用触觉反馈和环境结构先验来完成抓取等操作任务。

Method: 该框架包含三个组件：1. 利用关节力矩传感和粒子滤波器进行接触检测和定位；2. 利用接触历史构建局部占据地图，并通过学习的预测器推断未知区域；3. 规划器在考虑定位和占据预测不确定性的情况下，计算避障且高效的路径。

Result: 在模拟和真实世界中，该系统在控制 UR10e 机械臂执行的两个家居任务（水槽下阀门操作和杂乱架子上取物）中均表现可靠，任务完成时间比基线方法缩短了 2 倍。

Conclusion: 该框架通过整合触觉反馈和结构先验，能够有效地解决机器人视觉受限环境下的操作难题，提高了任务的鲁棒性和效率。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [174] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 本研究通过实验验证了基于学习的磁场相互作用控制大型卫星集群的可行性，解决了多卫星编队控制中的非完整约束、欠驱动、可扩展性和计算成本等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决多卫星编队控制中随着卫星数量增加而出现的非完整约束、欠驱动、可扩展性和计算成本等基本挑战，并在此前研究的基础上，进一步提升基于时间积分电流控制的性能。

Method: 设计了双轴线圈和基于气浮平台的地面实验装置，通过学习辅助的时间积分电流控制方法，验证了平均系统动力学的可控性（具有理论保证的误差界）和分散式电流管理。提出了NODA-MMH（Neural power-Optimal Dipole Allocation for certified learned Model-based Magnetically swarm control Harness）算法，用于基于模型的功率最优集群控制。

Result: 实验证明了学习辅助时间积分电流控制在增强平均系统动力学可控性和实现分散式电流管理方面的有效性，并引入了NODA-MMH算法。

Conclusion: 本研究成功验证了基于学习的磁场相互作用控制大型卫星集群的原理，并提出了有效的控制算法，为长期编队保持问题提供了解决方案。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [175] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 Kinaema 的新模型和智能体，用于解决机器人定位问题。该模型能够整合视觉观察流，并在需要时预测查询图像与机器人当前位置的相对关系。Kinaema 通过一个 Transformer 以前馈方式更新其隐式潜在记忆，从而解决了传统方法在处理长历史观测时的限制。在名为 Mem-Nav 的新任务中，该模型展示了其在大容量场景下的导航能力，并证明了其计算效率。


<details>
  <summary>Details</summary>
Motivation: 为解决空间感知机器人在先前已探索过的环境中定位自身的问题，并提高机器人持续运行的效率。

Method: 提出了一种名为 Kinaema 的模型和智能体，它能整合移动过程中的视觉观察流，并通过 Transformer 以前馈方式更新其隐式潜在记忆，从而压缩传感器读数历史为紧凑表示。该模型能在需要时处理查询图像，预测查询场景相对于机器人当前位置的相对位置。

Result: 在名为 Mem-Nav 的新任务中，Kinaema 模型能够保持对场景的有效表征，并成功导航至在实际任务开始前观察到的目标点。与处理长序列观测的传统 Transformer 相比，该模型在计算上具有显著的效率。

Conclusion: Kinaema 模型能够有效地处理长历史观测数据，并在机器人定位任务中表现出色，同时具有较高的计算效率。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [176] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 该研究提出了一种名为MemER的层级策略框架，使机器人能够像人类一样利用记忆来执行长期任务，通过高层策略选择和追踪相关的历史关键帧，并结合最近的帧来生成文本指令，供低层策略执行，从而有效处理长时依赖问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略普遍缺乏记忆能力，而直接依赖长历史观察成本高且在协变量变化下表现脆弱，随意子采样历史又可能包含无关或冗余信息。

Method: 提出一种层级策略框架，其中高层策略负责从经验中选择和追踪相关的历史关键帧，并结合最近的帧信息生成文本指令，供低层策略执行。该框架兼容现有的视觉-语言-动作（VLA）模型。

Result: 在三个需要数分钟记忆的真实世界长期机器人操作任务上，MemER的表现优于现有方法。实验中，高层策略使用了Qwen2.5-VL-7B-Instruct，低层策略使用了$\\(pi_{0.5}\\)。

Conclusion: MemER框架能够有效地为机器人策略赋予记忆能力，显著提升其在需要长期记忆的复杂操作任务中的表现。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [177] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: Dino-Diffusion Parking (DDP) is a domain-agnostic autonomous parking pipeline that uses visual foundation models and diffusion-based planning to achieve robust parking under domain shifts, with over 90% success rate in OOD scenarios and promising sim-to-real transfer.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of robustness in autonomous parking under domain shifts (e.g., weather and lighting changes) for end-to-end (E2E) approaches, without relying on additional data.

Method: The proposed Dino-Diffusion Parking (DDP) pipeline integrates visual foundation models with diffusion-based planning. It is trained in CARLA and transferred to adversarial settings in a zero-shot fashion. The architecture and algorithm design are also analyzed through ablation studies. Finally, it's tested in a 3D Gaussian splatting (3DGS) environment for sim-to-real transfer.

Result: The DDP model achieves a consistent parking success rate above 90% across all tested out-of-distribution (OOD) scenarios. Ablation studies confirm significant enhancement in cross-domain performance over existing baselines. Promising sim-to-real transfer is demonstrated in a 3DGS environment.

Conclusion: The DDP pipeline provides a domain-agnostic solution for autonomous parking, demonstrating significant improvements in robustness and cross-domain generalization through the integration of visual foundation models and diffusion-based planning, with successful sim-to-real transfer capabilities.

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [178] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个将神经描述符场（NDF）和触觉传感相结合的多模态框架，通过深度强化学习策略，利用触觉反馈优化抓取姿势，实现了高精度和泛化能力的机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取精度对于精确物体操作至关重要，但仅靠视觉方法（如NDF）可能因校准不准、点云不全或物体多变性而产生不准确的抓取姿势；而触觉传感虽然能提供更精确的接触信息，但现有方法通常局限于预定义的简单接触几何。因此，需要一种能够结合两者优点并提高抓取精度和泛化能力的方法。

Method: NeuralTouch框架首先利用NDF隐式地表示目标接触几何，然后训练一个深度强化学习（RL）策略，该策略以神经描述符为条件，并利用触觉反馈来优化抓取姿势，无需显式指定接触类型。

Result: 在模拟和真实世界机器人操作任务（如穿孔和开瓶盖）中，NeuralTouch相比基线方法显著提高了抓取精度和鲁棒性，实现了零样本迁移，无需额外微调。

Conclusion: NeuralTouch是一个通用的多模态框架，能够通过温和的物理交互实现高精度、泛化性强的抓取，为接触丰富的机器人操作提供了新的解决方案。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [179] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy使用结构化点云处理机器人操作任务，解决了现有方法的局限性，并在RoboCasa和CALVIN基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作方法在处理几何细节或语义信息方面存在不足，限制了其精度和泛化能力。PointMapPolicy旨在通过融合点云和RGB图像的优势来克服这些挑战。

Method: PointMapPolicy通过在不进行降采样的结构化点图上条件化扩散策略来提取形状和空间关系，并利用xLSTM骨干网络高效融合点图和RGB数据，实现增强的多模态感知。

Result: 该方法在RoboCasa和CALVIN基准测试以及真实机器人评估中，在多样化的操作任务中取得了最先进的性能。

Conclusion: PointMapPolicy通过在结构化点图上利用扩散策略，有效融合了点云的几何细节和RGB图像的语义信息，从而在机器人操作任务中实现了卓越的性能。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [180] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 MR-UBi 的混合现实水下机器人手臂遥操作系统，通过结合视觉和触觉反馈，显著提高了操作的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 水下机器人手臂的遥操作需要精确控制抓取力矩，但现有的系统在提供有效的反馈方面存在不足。

Method: 提出了一种基于混合现实和双边控制的水下机器人手臂遥操作系统（MR-UBi），该系统通过在混合现实头戴显示器（MR-HMD）中叠加颜色和长度编码的力矩条来提供实时视觉反馈，并结合双边控制实现触觉反馈。

Result: 用户研究表明，与仅使用双边控制的基线系统相比，MR-UBi 在抓取力矩控制精度上显著提高，物体抓取成功率更高，同时用户主观评价也显示出更高的可用性和更低的工作负荷。

Conclusion: MR-UBi 系统通过整合视觉和触觉反馈，能够实现更稳定、更精确、更用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [181] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 该方法提出了一种在考虑零件加工路径的同时，使用空间固定的刀具中心点（TCP）在工作空间坐标中规划轨迹的方法。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，此方法具有优势。

Method: 无论使用定义要加工的形状的数学描述还是来自设计程序的单个点，机器人路径最终都使用B样条表示。样条的使用使得路径可以具有所需的连续性，从而实现平滑的机器人轨迹。在计算通过规定方向的机器人轨迹时，此外还必须考虑TCP的给定速度。

Result: 该方法已在真实系统中得到验证，其中工业机器人移动了任意定义的零件。

Conclusion: 该方法提出了一种在考虑零件加工路径的同时，使用空间固定的刀具中心点（TCP）在工作空间坐标中规划轨迹的方法。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [182] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 为了在GNSS受限环境中实现机器人长期精确定位，本文提出了一种多机器人协同定位方法，通过融合来自不同机器人和不同传感器（如视觉-惯性里程计、激光雷达-惯性里程计）的异步、多模态数据来适应环境变化并提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，机器人需要精确的长期定位能力。单独使用多种传感器会增加机器人尺寸、重量和功耗，而将传感器分布在多个机器人上则会带来数据融合的挑战。

Method: 提出了一种基于因子图的多模态、多机器人协同定位方法，该方法能够融合来自不同机器人和不同传感器（视觉-惯性里程计、激光雷达-惯性里程计、3D机器人间检测）的异步、多模态数据。该方法能够自适应地利用可靠数据辅助受传感器退化影响的机器人，并提出了一种基于插值的因子来融合不同步的测量数据，以及一种基于Wasserstein距离的权重分配方法来处理激光雷达-惯性里程计的退化。

Result: 通过在真实世界数据（包括不同类型的无人地面车辆和无人机）上进行的大量评估，证明了该方法在各种传感器退化条件下能显著提高定位精度。

Conclusion: 所提出的多机器人协同定位方法在GNSS受限环境中，尤其是在传感器退化的情况下，能够有效地提高机器人的定位精度和鲁棒性。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [183] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 本研究提出了一种在未知动力学环境下进行机器人操作任务的方法，通过显式引入参数适应机制的反馈策略，并结合两种参考轨迹生成方法，以实现更快的任务执行、更准确的系统识别以及稳定高效的控制。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务（如带不确定负载的抓取和放置）需要在未知动力学下进行，需要主动探索和在线参数自适应来实现精确的基于模型的控制。

Method: 将问题构建为双重控制，这是一个考虑参数不确定性的闭环最优控制问题。通过预定义包含显式自适应机制的反馈策略结构来简化双重控制问题。提出两种参考轨迹生成方法：一种是直接将参数不确定性嵌入鲁棒最优控制方法中以最小化预期任务成本；另一种是最小化“最优性损失”，即参数相关信息对任务性能的敏感度。

Result: 所提出的方法能够比传统方法更快、更准确地执行抓取和放置任务，并能更有效地进行系统识别，同时确保控制的稳定性和效率。两种方法在推导过程中都会考虑 Fisher 信息，从而在追求最优任务执行的同时进行主动探索。

Conclusion: 通过考虑控制的双重性来设计参考轨迹，可以实现更快的任务执行、更准确的任务性能和系统识别，同时确保稳定和高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [184] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 通过利用串联弹性驱动器（SEA）的固有弹性来优化并联机器人（PKM）在执行拾放任务时的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 工业机器人，特别是串联弹性驱动器（SEA）驱动的并联运动机器人（PKM）在执行长时间重复性拾放任务时，能量消耗是一个重要的考虑因素。

Method: 提出了一种通过激励由驱动器弹簧产生的本征运动来最小化SEA驱动PKM能量消耗的方法。为此，分析了预定的循环拾放操作，并推导了SEA驱动PKM的动力学模型。随后，构建了一个能量最小化的最优控制问题，同时优化了运行轨迹和SEA刚度。该方法通过在两个机器人应用中进行测试来验证。

Result: 所提出的方法在两个机器人应用中得到了验证，结果证实了该方法在减少能量消耗方面的有效性，并解决了冗余驱动的问题。

Conclusion: 通过优化运行轨迹和SEA刚度，可以有效地减少SEA驱动PKM在执行拾放任务时的能量消耗。该方法为设计和优化此类机器人系统提供了一种有价值的途径。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [185] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本研究提出了一种通过最大化路径速度来解决时间最优路径跟踪中的计算挑战的新方法，避免了传统方法中的奇异性问题，并实现了高效的数值计算和线性优化。


<details>
  <summary>Details</summary>
Motivation: 标准方法在将优化问题重新表述为路径参数时，由于零路径速度下的奇异性，会导致计算挑战。

Method: 本研究提出了一种基于最大化路径速度的新方法，该方法能够规划平滑的轨迹，并且离散重构的底层问题在优化变量上是线性的。

Result: 该方法能够高效地进行数值计算，并规划出平滑的轨迹，同时避免了传统方法中的奇异性问题。

Conclusion: 本研究提出的基于最大化路径速度的方法，为解决时间最优路径跟踪中的计算挑战提供了一种有效且计算高效的解决方案。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [186] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 本研究提出RubbleSim，一个用于模拟灾难响应中结构倒塌后内部空隙环境的开源模拟器，以克服现实数据获取的限制，并在此模拟环境中评估了基于运动恢复结构算法在视觉挑战下的感知性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，由于法律限制和训练场地的专有性，关于结构倒塌后内部空隙环境的公开数据非常有限。本研究旨在克服这一数据获取挑战。

Method: 提出并实现了一个名为RubbleSim的开源模拟器，该模拟器使用Unity引擎开发，支持多操作系统，并能通过基于物理的方法生成随机的、可重新配置的、具有真实感的倒塌体空隙环境。模拟器的设计参考了真实训练场地，并能精确记录环境的真实情况。研究人员利用该模拟器，应用了先进的运动恢复结构（SfM）算法，以评估在模拟的空隙环境中，尤其是在视觉条件不佳的情况下，感知性能的表现。

Result: 通过使用RubbleSim模拟器和SfM算法，研究结果展示了在模拟的、具有挑战性的视觉条件下，机器人感知性能的下降情况。

Conclusion: RubbleSim为研究灾难响应机器人技术提供了一个有价值的工具，尤其是在解决现实世界数据获取困难的问题上。该模拟器能够准确地重现真实倒塌环境的复杂性，并为评估和改进机器人在这些极端环境中的感知能力提供了平台。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [187] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 本文提出了C-Nav框架，用于解决动态开放世界中的持续物体导航问题，该框架通过引入反遗忘机制和自适应采样策略，有效解决了灾难性遗忘问题，并在实验中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有物体导航方法在训练时通常依赖静态轨迹和固定对象类别，无法适应动态、开放世界的真实需求，即需要代理能够持续适应不断变化的环境并学习新的物体导航技能，同时避免遗忘旧的知识。

Method: 提出了一种名为C-Nav的持续视觉导航框架，该框架包含两个主要创新：1.一种双路径反遗忘机制，具体包括特征蒸馏（通过对齐多模态输入到一致的表示空间来保证表示一致性）和特征回放（在动作解码器中保留时间特征以保证策略一致性）。2.一种自适应采样策略，用于选择多样化和信息丰富的经验，从而减少冗余和最小化内存开销。

Result: 在多个模型架构上的广泛实验表明，C-Nav持续优于现有方法，即使与保留完整轨迹的基线相比也表现更佳，同时显著降低了内存需求。

Conclusion: C-Nav框架通过其创新的双路径反遗忘机制和自适应采样策略，有效地解决了持续物体导航中的灾难性遗忘问题，并在各种模型上取得了优于现有方法的性能，同时实现了更低的内存消耗。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [188] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 该研究提出了一种结合MPPI和Dreamer模块的优化框架，用于四足动物的实时步态自适应，以克服模型无关强化学习策略单一和MPC缺乏适应性的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的模型无关强化学习（RL）在四足动物运动控制中虽然实现了自适应和敏捷的运动，但策略往往会收敛到单一的步态，导致性能不佳。而传统的模型预测控制（MPC）虽然可以获得特定任务的最优策略，但缺乏在不同环境中自适应的能力。

Method: 提出了一种在连续步态空间中进行实时步态自适应的优化框架，该框架结合了模型预测路径积分（MPPI）算法和Dreamer模块。在每个时间步，MPPI利用学习到的Dreamer奖励（该奖励旨在提高速度跟踪、能量效率、稳定性和步态转换的平滑性，同时惩罚 abrupt 的步态变化）来联合优化动作和步态变量。此外，还引入了学习到的价值函数作为终端奖励，将该框架扩展为无限时间规划器。

Result: 在Unitree Go1仿真环境中进行了评估，结果显示，在不同的目标速度下，能源消耗平均降低了高达36.48%，同时保持了准确的速度跟踪以及自适应、适合任务的步态。

Conclusion: 该研究提出的框架能够实现四足动物的实时步态自适应，并能在保证性能的同时有效降低能耗。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [189] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [190] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 机器学习在机器人领域，尤其是在导航、运动和操作方面取得了显著进展。其中，仿真技术在机器人系统的训练和测试中发挥了关键作用。然而，仿真与现实环境之间存在的差异（即“现实差距”）阻碍了系统从仿真到现实世界的成功迁移。缩小这一差距是机器人领域面临的紧迫挑战之一。近年来，通过域随机化、域自适应、状态和动作抽象以及仿真-现实协同训练等技术，在解决现实差距方面取得了初步成效。本综述旨在全面概述仿真到现实迁移的现状，重点介绍现实差距的成因、解决方案以及评估指标。


<details>
  <summary>Details</summary>
Motivation: 仿真在机器人训练和测试中至关重要，但仿真与现实环境之间的“现实差距”阻碍了从仿真到现实世界的成功迁移，这是一个机器人领域亟待解决的挑战。

Method: 本综述全面概述了仿真到现实迁移的领域，重点介绍了现实差距的成因、解决方案以及评估指标。

Result: 尽管取得了初步成效，但现实差距的挑战依然存在，需要更深入地理解其根本原因和解决方案。

Conclusion: 本综述旨在全面概述仿真到现实迁移的领域，重点介绍现实差距的成因、解决方案以及评估指标。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [191] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作仿真器，支持零样本sim2real策略学习、数据收集和策略评估。


<details>
  <summary>Details</summary>
Motivation: 开发可复现的机器人操作策略评估和sim2real策略训练流程，无需真实机器人。

Method: 提出GSDF（高斯场景描述文件）格式，结合高斯泼溅和URDF，创建包含机器人和物体在内的3D场景数据库，并将其与物理引擎结合。

Result: 实现了零样本sim2real像素到动作策略学习、自动高质量DAgger数据收集、真实机器人操作策略的可复现模拟评估、虚拟遥操作模拟数据收集以及零样本sim2real视觉强化学习。

Conclusion: GSWorld通过结合3D高斯泼溅和物理引擎，为机器人操作策略的开发和评估提供了一个强大且照片级逼真的仿真平台，解决了sim2real的挑战。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [192] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一个分层的视觉-语言-动作模型，它将语义规划与具身接地分离开来，一个通才规划器从多样化的数据中学习，一个专家模型学习机器人的物理约束和能力，从而在各种环境中实现更有效的机器人导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中的一个根本性挑战，即学习能够跨不同环境泛化，同时又能适应特定具身（例如，四足动物可以爬楼梯，而探测车不能）的独特物理约束和能力的策略。

Method: 提出VAMOS，一个分层的视觉-语言-动作模型，将语义规划与具身接地分离开来：一个通才规划器从多样化的、开放世界的数据中学习，一个专家模型学习机器人的物理约束和能力，在安全、低成本的模拟中。通过精心设计一个允许高级规划器直接在图像空间中提出候选路径，并由专家模型进行评估和重新排序的接口，实现了这种分离。

Result: 在室内和复杂的室外导航中，VAMOS的成功率都高于最先进的基于模型和端到端的学习方法。该分层设计能够实现跨足式和轮式机器人的导航，并能用自然语言轻松控制。现实世界的实验证实，专家模型是实现具身接地的关键，使得同一个高级规划器可以用于物理上不同的轮式和足式机器人。此外，该模型通过拒绝不切实际的规划，将单机器人成功率提高了3倍。

Conclusion: VAMOS通过将语义规划与具身接地分离开来，有效地解决了机器人导航中的泛化和适应性挑战，并展示了其在跨环境导航、跨具身导航以及提高机器人可靠性方面的优越性。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [193] [Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication](https://arxiv.org/abs/2510.19995)
*Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song*

Main category: cs.MA

TL;DR: C2C是一个可扩展的框架，通过引入对齐因子（AF）和顺序动作框架，提高了多智能体LLM在复杂任务中的协作效率，将任务完成时间缩短了约40%。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM系统缺乏面向任务的系统化沟通框架来支持复杂任务中的团队协作。

Method: 提出了一种名为“Communication to Completion”（C2C）的可扩展框架，该框架包含两个关键创新：1. 对齐因子（AF），一个量化智能体任务对齐度的新指标；2. 顺序动作框架，将分步执行与智能通信决策相结合。C2C使智能体能够做出成本感知的通信选择，并通过有针对性的交互来动态改进任务理解。

Result: 在真实编码工作流中，C2C框架在三个复杂度和5到17个智能体的团队规模下进行了评估，与无通信和固定步骤基线进行了比较。结果显示，C2C将任务完成时间缩短了约40%，通信成本可接受。框架在标准配置下成功完成了所有任务，并能有效地扩展到大规模应用。

Conclusion: C2C框架为衡量多智能体系统中通信的有效性奠定了理论基础，并为复杂的协作任务提供了一个实用的框架。

Abstract: Teamwork in workspace for complex tasks requires diverse communication
strategies, but current multi-agent LLM systems lack systematic frameworks for
task oriented communication. We introduce Communication to Completion (C2C), a
scalable framework that addresses this gap through two key innovations: (1) the
Alignment Factor (AF), a novel metric quantifying agent task alignment that
directly impacts work efficiency, and (2) a Sequential Action Framework that
integrates stepwise execution with intelligent communication decisions. C2C
enables agents to make cost aware communication choices, dynamically improving
task understanding through targeted interactions. We evaluated C2C on realistic
coding workflows across three complexity tiers and team sizes from 5 to 17
agents, comparing against no communication and fixed steps baselines. The
results show that C2C reduces the task completion time by about 40% with
acceptable communication costs. The framework completes all tasks successfully
in standard configurations and maintains effectiveness at scale. C2C
establishes both a theoretical foundation for measuring communication
effectiveness in multi-agent systems and a practical framework for complex
collaborative tasks.

</details>


### [194] [High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning](https://arxiv.org/abs/2510.20218)
*Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen*

Main category: cs.MA

TL;DR: QCoFr通过使用 Continued Fraction Q-Learning 和变分信息瓶颈来解决 MARL 中的高阶交互建模问题，实现了线性复杂性、增强了合作和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）中建模智能体交互对于有效的协调和理解其合作机制至关重要，但现有方法在处理高阶交互时面临组合爆炸或黑盒结构不透明的问题。

Method: 提出了一种名为 Continued Fraction Q-Learning (QCoFr) 的新型价值分解框架，该框架具有线性复杂度 O(n)，并引入了变分信息瓶颈来提取潜在信息以估计信用。

Result: QCoFr 在大量实验中持续 achieves 更好的性能，并提供了与理论分析一致的可解释性。

Conclusion: QCoFr 能够灵活地捕捉任意阶智能体交互，复杂度为线性，有效避免了组合爆炸，同时通过提取潜在信息增强了合作和可解释性。

Abstract: The ability to model interactions among agents is crucial for effective
coordination and understanding their cooperation mechanisms in multi-agent
reinforcement learning (MARL). However, previous efforts to model high-order
interactions have been primarily hindered by the combinatorial explosion or the
opaque nature of their black-box network structures. In this paper, we propose
a novel value decomposition framework, called Continued Fraction Q-Learning
(QCoFr), which can flexibly capture arbitrary-order agent interactions with
only linear complexity $\mathcal{O}\left({n}\right)$ in the number of agents,
thus avoiding the combinatorial explosion when modeling rich cooperation.
Furthermore, we introduce the variational information bottleneck to extract
latent information for estimating credits. This latent information helps agents
filter out noisy interactions, thereby significantly enhancing both cooperation
and interpretability. Extensive experiments demonstrate that QCoFr not only
consistently achieves better performance but also provides interpretability
that aligns with our theoretical analysis.

</details>


### [195] [Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks](https://arxiv.org/abs/2510.20469)
*Horacio Paggi,Juan A. Lara,Javier Soriano*

Main category: cs.MA

TL;DR: 信息融合从传统的军事应用中的分层方法转变为民用应用和边缘组织的整体方法。


<details>
  <summary>Details</summary>
Motivation: 信息融合在不同非军事领域、人机通信和机器通信中得到越来越多的应用，这促进了信息融合范式的转变。本文旨在探讨在资源（能源、可用消息、时间等）受限的情况下，如何生成整体结构，以实现对消息交换中模糊性和不确定性的优化。

Method: 在多主体系统模型的基础上，通用地研究了整体结构的形成，并展示了其可能的操作示例。

Result: 研究了整体结构的形成，并给出了一个操作示例。

Conclusion: 整体结构具有适应环境或组成变化的适应性、一定的自主性以及协作以实现共同目标的能力，这在资源短缺阻碍通信或系统组件开始出现故障时非常有用。

Abstract: There has recently been a major advance with respect to how information
fusion is performed. Information fusion has gone from being conceived as a
purely hierarchical procedure, as is the case of traditional military
applications, to now being regarded collaboratively, as holonic fusion, which
is better suited for civil applications and edge organizations. The above
paradigm shift is being boosted as information fusion gains ground in different
non-military areas, and human-computer and machine-machine communications,
where holarchies, which are more flexible structures than ordinary, static
hierarchies, become more widespread. This paper focuses on showing how holonic
structures tend to be generated when there are constraints on resources
(energy, available messages, time, etc.) for interactions based on a set of
fully intercommunicating elements (peers) whose components fuse information as
a means of optimizing the impact of vagueness and uncertainty present message
exchanges. Holon formation is studied generically based on a multiagent system
model, and an example of its possible operation is shown. Holonic structures
have a series of advantages, such as adaptability, to sudden changes in the
environment or its composition, are somewhat autonomous and are capable of
cooperating in order to achieve a common goal. This can be useful when the
shortage of resources prevents communications or when the system components
start to fail.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [196] [The Risks of Industry Influence in Tech Research](https://arxiv.org/abs/2510.19894)
*Joseph Bak-Coleman,Cailin O'Connor,Carl Bergstrom,Jevin West*

Main category: cs.SI

TL;DR: 新兴信息技术对公共健康、政治、社会和环境有广泛影响，但相关数据由可能受到监管的行业控制，且该行业是该领域的主要资助者，这引发了对行业不当影响科学记录的担忧。因此，需要加强现有保障措施并建立新的保障措施来应对科技研究中的挑战。


<details>
  <summary>Details</summary>
Motivation: 新兴信息技术（如社交媒体、搜索引擎和人工智能）对公共健康、政治、社会和自然世界产生了广泛影响。为了制定循证的技术政策，必须科学地理解这些影响，以最大限度地减少危害并最大限度地发挥效益。

Method: 探讨科技公司如何影响我们对其产品的科学认识，并提出科学研究面临独特的挑战，需要加强现有的保障措施并构建全新的保障措施。

Result: 识别出科技公司在影响科学研究方面存在信息和资金方面的不对称性，这可能导致不当的行业影响。指出科技研究面临的独特挑战。

Conclusion: 科学在科技研究的背景下面临独特的挑战，需要加强现有保障措施并构建全新的保障措施，以应对科技公司可能存在的不当行业影响。

Abstract: Emerging information technologies like social media, search engines, and AI
can have a broad impact on public health, political institutions, social
dynamics, and the natural world. It is critical to develop a scientific
understanding of these impacts to inform evidence-based technology policy that
minimizes harm and maximizes benefits. Unlike most other global-scale
scientific challenges, however, the data necessary for scientific progress are
generated and controlled by the same industry that might be subject to
evidence-based regulation. Moreover, technology companies historically have
been, and continue to be, a major source of funding for this field. These
asymmetries in information and funding raise significant concerns about the
potential for undue industry influence on the scientific record. In this
Perspective, we explore how technology companies can influence our scientific
understanding of their products. We argue that science faces unique challenges
in the context of technology research that will require strengthening existing
safeguards and constructing wholly new ones.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [197] [A unified picture of phonon anomalies in crystals and glasses](https://arxiv.org/abs/2510.19891)
*Alessio Zaccone*

Main category: cond-mat.mtrl-sci

TL;DR: van Hove奇点和玻色子峰具有共同的物理起源，可用一个统一的共振阻尼模型来解释。


<details>
  <summary>Details</summary>
Motivation: 解释固体中普遍存在的、不符合德拜定律的反常声子谱，特别是晶体中的van Hove奇点和玻璃中的玻色子峰，并认识到这两种现象具有共同的物理起源。

Method: 提出一个共振阻尼模型，将声子阻尼与振动软化耦合，以统一解释van Hove奇点和玻色子峰。

Result: 该模型能够解释为什么某些材料表现出van Hove峰，而另一些材料表现出玻色子峰，还有些材料则两者兼有。这扩展了关于声子传播与阻尼竞争的早期理论，并与非仿射运动等微观机制相关联。

Conclusion: 共振阻尼范式为在有序和无序固体中统一理解振动反常提供了一个有前途的步骤。

Abstract: Phonon spectra in solids often display anomalies that defy the simple Debye
law, most prominently the van Hove singularity in crystals and the boson peak
in glasses. Although traditionally regarded as distinct, both features are
increasingly recognized as sharing a common physical origin. In a recent work,
G. Ding et al. (Nat. Phys. 2025) propose a resonant-damping model that unifies
these anomalies within a single framework. By coupling phonon damping to
vibrational softening, their theory explains why some materials exhibit van
Hove peaks, others boson peaks, and many show both. This advance extends
earlier ideas and theories of Baggioli and Zaccone on the competition between
phonon propagation and damping, while also connecting to microscopic mechanisms
such as nonaffine motions in glasses. The resonant-damping paradigm thus offers
a promising step toward a unified understanding of vibrational anomalies across
ordered and disordered solids.

</details>


### [198] [Good Enough is Better: Feasibility vs. Pareto-Optimality in Alloy Design](https://arxiv.org/abs/2510.20125)
*Cayden Maguire,Christofer Hardcastle,Trevor Hastings,Raymundo Arróyave,Brent Vela*

Main category: cond-mat.mtrl-sci

TL;DR: 约束满足方法在合金设计中比基于优化的方法更有可能找到可行的合金，并且找到第一个可行合金解决方案的时间更早。


<details>
  <summary>Details</summary>
Motivation: 合金设计通常被视为一个优化问题，目标是找到跨多个目标的帕累托最优解。然而，帕累托最优解不一定满足实际部署所需的所有最低性能阈值。因此，需要一种替代方法来解决合金设计问题，即将其视为一个约束满足问题，目标是找到满足所有基本要求的多目标合金。

Method: 将合金设计视为约束满足问题，并与基于优化的方法进行基准测试。

Result: 在涉及多个目标和约束的实际合金设计活动中，约束满足框架比基于优化的方法更有可能找到可行的合金。此外，约束满足方法比优化方法更早地找到第一个可行的合金解决方案。

Conclusion: 在材料发现中，特别是在高度约束的应用中，关注可行性而不是最优性可以带来更可行的结果。

Abstract: In alloy design, the search for candidate materials is often framed as an
optimization problem, with the goal of identifying Pareto-optimal solutions
across multiple objectives. However, Pareto-optimal solutions do not
necessarily satisfy all minimum performance thresholds required for practical
deployment. An alternative approach is to treat alloy design as a constraint
satisfaction problem, in which the goal is to identify any solution that meets
all bare minimum requirements across multiple quantities of interest. These
approaches have yet to be benchmarked against each other in the context of
realistic alloy design problems. In this work, we demonstrate that, in
realistic alloy design campaigns involving multiple objectives and constraints,
the constraint satisfaction framework yields a higher likelihood of finding
viable alloys than optimization-based approaches. Furthermore,
constraint-satisfaction approaches find the first viable alloy solutions
earlier than optimization. Our results suggest that focusing on feasibility
rather than optimality can lead to more actionable outcomes in materials
discovery, particularly in highly constrained applications.

</details>


### [199] [Domain wall induced topological Hall effect in the chiral-lattice ferromagnet Fe$_x$TaS$_2$](https://arxiv.org/abs/2510.20181)
*Sk Jamaluddin,Warit Nisaiyok,Yu Zhang,Hari Bhandari,Brian A. Francisco,Peter E. Siegfried,Fehmi Sami Yasin,Tianyi Wang,Abhijeet Nayak,Mohamed El Gazzah,Resham Babu Regmi,June Ho Yeo,Liuyan Zhao,J. F. Mitchell,Yong-Tao Cui,Nirmal J. Ghimire*

Main category: cond-mat.mtrl-sci

TL;DR: Fe太S2的畴壁驱动的大且可调的拓扑霍尔效应


<details>
  <summary>Details</summary>
Motivation: 在层状过渡金属硫属化物中设计自旋织构以实现强且独特的电响应仍然是一个重大挑战。

Method: 通过系统地改变Fe插层水平来控制磁性基态，从而操纵拓扑霍尔效应。使用实空间磁力显微镜（MFM）提供畴壁驱动的拓扑霍尔效应的微观起源的证据。

Result: 观察到Fe太S2中存在畴壁驱动的、大的、可调的拓扑霍尔效应，并且通过改变Fe插层水平可以控制该效应。

Conclusion: 该研究为在层状磁性材料中调控畴的拓扑结构以产生显著的电磁响应提供了一种有前景的方法。

Abstract: Magnetic topology and its associated emergent phenomena are central to
realizing intriguing quantum states and spintronics functionalities. Designing
spin textures to achieve strong and distinct electrical responses remains a
significant challenge. Layered transition metal dichalcogenides offer a
versatile platform for tailoring structural and magnetic properties, enabling
access to a wide spectrum of topological magnetic states. Here, we report a
domain-wall-driven, large, and tunable topological Hall effect (THE) in a
non-centrosymmetric intercalated transition metal dichalcogenides series
Fe$_x$TaS$_2$. By systematically varying the Fe intercalation level, we exert
precise control over the magnetic ground states, allowing manipulation of the
topological Hall effect. Real-space magnetic force microscopy (MFM) provides
direct evidence of periodic magnetic stripe domain formation, confirming the
microscopic origin of the observed topological transport phenomena. Our
findings establish a promising way for tuning the topology of domains to
generate substantial electromagnetic responses in layered magnetic materials.

</details>


### [200] [Non-relativistic spin splitting: Features and Functionalities](https://arxiv.org/abs/2510.20306)
*Sayantika Bhowal,Arnab Bose*

Main category: cond-mat.mtrl-sci

TL;DR: 补偿反铁磁体中的非相对论自旋劈裂现象及其研究进展。


<details>
  <summary>Details</summary>
Motivation: 近年来，补偿反铁磁体中非相对论起源的自旋劈裂引起了凝聚态物理学界的广泛关注。尽管许多已知的表现出自旋劈裂的材料已被研究了数十年，但它们在非高对称动量方向上的表现最初阻碍了人们对其的认识。本文旨在概述这一现象。

Method: 本文对具有不同自旋构型（包括共线、共面和非共面自旋排列）的补偿反铁磁体中的非相对论自旋劈裂进行了简要概述。文章总结了实用的识别指南，强调了电子能带结构中的特征，并讨论了新兴的功能。

Result: 文章总结了识别指南，强调了电子能带结构中的特征，并讨论了新兴的功能。

Conclusion: 该综述提供了对补偿反铁磁体中非相对论自旋劈裂的见解，并强调了未来的研究方向。

Abstract: Recently, spin splitting of non-relativistic origin in compensated
antiferromagnets has drawn growing attention in condensed matter research.
Although many materials, now known to exhibit such spin splitting, have been
studied for decades, their manifestation along non-high-symmetry momentum
directions initially hindered their recognition. In recent years, significant
progress has been made in uncovering the symmetry principles that allow
non-relativistic spin splitting in the absence of net magnetization, revealing
the unconventional physics arising from their coexistence. In this review, we
provide a concise overview of non-relativistic spin splitting in compensated
antiferromagnets with various spin configurations, including collinear,
coplanar, and non-coplanar spin arrangements. We summarize practical
identification guidelines, highlight characteristic features in electronic band
structures, and discuss the emerging functionalities, with an emphasis on
promising directions for future exploration.

</details>


### [201] [Highly Rectifying Cubic Copper Iron Sulfides p-n Junction Diode Fabricated by Anodic Oxidation](https://arxiv.org/abs/2510.20326)
*Yoshimine Kato,Tomoaki Nakamura,Katsuya Komorita,Kungen Teii*

Main category: cond-mat.mtrl-sci

TL;DR: 本文介绍了一种使用简单/低成本湿法制备的立方相Cu4Fe5S8多晶材料，并展示了其作为p-n结二极管的优异整流特性，整流比高达10^6，正向电流密度大，有望推动低成本半导体制造。


<details>
  <summary>Details</summary>
Motivation: 为了降低半导体器件的制造成本和简化工艺，需要开发低成本、无毒的基础金属材料和简单的制备方法。铜基硫化物在热电、光伏和水分解等领域具有应用潜力。

Method: 采用简单的湿法工艺制备了立方相Cu4Fe5S8多晶材料，并通过阳极氧化生长p型层到烧结的n型立方相Cu4Fe5S8上，构建了p-n结二极管。

Result: 所制备的Cu4Fe5S8二极管在室温下表现出高达10^6的整流比，以及15 Acm-2（1.5 V正向偏压下）的大正向电流密度，在铜铁硫化物器件中表现最佳。

Conclusion: Cu4Fe5S8二极管优异且稳定的整流特性，通过简单的湿法工艺即可实现，有助于推动低成本半导体制造。该研究为立方相Cu4Fe5S8等新型半导体材料的进一步研究和应用提供了平台。

Abstract: Rectification properties of semiconductor p-n junction diodes are the basic
and important characteristics for electronic device evaluation, especially for
novel semiconductor materials. Today's semiconductor devices' fabrication and
integration processes require multibillion-dollar investments and are desired
to be reduced or simplified. Therefore, low-cost and non-toxic base metal
materials with simple fabrication methods are desired for the future
semiconductor industry. Recently, copper-based sulfides have been studied for
semiconductor devices such as thermoelectric, photovoltaic, or water-splitting
applications. Here, a highly rectifying p-n diode of a cubic (disordered) phase
Cu4Fe5S8 polycrystal with a zincblende-like structure fabricated by a
simple/low-cost wet process is shown. It is found that the Cu4Fe5S8 diode shows
the highest rectification ratio in the order of 106 with a large forward
current density of 15 Acm-2 (@1.5 V forward bias) at room temperature among the
other compounds of copper iron sulfide devices. This remarkable and stable
diode characteristic obtained by the p-type layer anodically grown on the
sintered n-type cubic-Cu4Fe5S8 can bring the industry closer to low-cost
semiconductor manufacturing. These results open a platform of novel
semiconductor materials such as cubic-Cu4Fe5S8 with further superior crystal
growth and conductive characteristics.

</details>


### [202] [Unlock Anionic Behavior of Calcium Through Pressure Engineering](https://arxiv.org/abs/2510.20395)
*Yang Lv,Junwei Li,Jianfu Li,Yong Liu,Jianan Yuan,1 Jiani Lin,Saori Kawaguchi-Imada,Qingyang Hu,Xiaoli Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 在超高压下，钙（Ca）可以表现出负价，这大大增加了钙化学的复杂性。


<details>
  <summary>Details</summary>
Motivation: 钙（Ca）原子在环境条件下具有空d轨道，但在热力学条件被操纵时，元素Ca和化合物中都观察到了s-d带杂化。在本研究中，我们揭示了在压力下，Ca 3d带甚至可以从卤素原子中捕获电子，在碘化物中表现出阴离子行为。

Method: 利用第一性原理结构搜索和原位X射线衍射，预测并确定了CsCl型单价CaI相。

Result: 在超高压下，钙（Ca）可以表现出负价，这大大增加了钙化学的复杂性。我们预测了一种在50 GPa以上存在的CsCl型单价CaI，并通过在84 GPa下进行原位X射线衍射成功鉴定。我们还发现，由于轨道展宽效应，CaI中电荷从I的5p轨道到Ca的3d轨道的异常转移，在485 GPa下逐渐逆转了Ca的离子性，形成了阴离子ICa。多价Ca稳定了一系列具有8到10倍碘超配位的金属碘化物。

Conclusion: 我们的研究结果表明，在超高压下，Ca的价态可以从负价到+2不等，这表明Ca化学在超高压下具有更大的复杂性。

Abstract: An isolated calcium (Ca) atom has empty d-orbitals under ambient conditions.
However, s-d band hybridization has been observed in both elemental Ca and
compounds by manipulating thermodynamic conditions. Here, we reveal that the Ca
3d-band can even capture electrons from halogen atoms under pressure,
exhibiting anionic behaviors in iodides. We predict a CsCl-type monovalent CaI
at above 50 GPa by employing first-principles structural searching and
successfully identified the phase at 84 GPa using in situ X-ray diffraction. We
further reveal that, due to the effect of orbital broadening, unusual charge
transfer from the 5p orbitals of I to the 3d orbitals of Ca in CaI, gradually
reverses the ionicity of Ca and becomes the anionic ICa at 485 GPa. Multivalent
Ca stabilizes a set of metallic iodides with eight- to ten-fold iodine
hyper-coordination. Our findings demonstrate that the valence states of Ca can
vary from negative to +2, suggesting much greater complexity of Ca chemistry
under ultrahigh pressures.

</details>


### [203] [PBr3 Adsorption and Dissociation on the Si(100) Surface](https://arxiv.org/abs/2510.20420)
*Vladimir M. Shevlyuga,Yulia A. Vorontsova,Tatiana V. Pavlova*

Main category: cond-mat.mtrl-sci

TL;DR: PBr3在室温下会解离成P和Br原子，并吸附在Si(100)表面；高温下P会掺杂进Si。这对于通过PBr3吸附将P原子掺杂到Si中有用。


<details>
  <summary>Details</summary>
Motivation: 研究PBr3在Si(100)表面的吸附行为及其对Si的影响，以期实现P原子的精确掺杂。

Method: 使用扫描隧道显微镜（STM）和密度泛函理论（DFT）研究PBr3在Si(100)-2×1表面的吸附。

Result: PBr3在室温下完全解离成P和Br原子，吸附在三个相邻的Si二聚体上。400$^{\circ}$C退火后，P原子掺杂到Si中，Si原子被溅射到表面。

Conclusion: PBr3吸附可以实现P原子在Si中的掺杂，这在半导体制造中具有潜在应用价值。

Abstract: The adsorption of PBr3 on the Si(100)-2$\times$1 surface was studied by
scanning tunneling microscopy (STM) and density functional theory (DFT). The
PBr3 molecule completely dissociates on the Si(100) surface at room temperature
into P and Br atoms. In most cases, the dissociated molecule was observed in
STM on three neighboring Si dimers. DFT calculations confirm that the PBr3
molecule can completely dissociate at room temperature. After annealing the
sample to 400$^{\circ}$C, phosphorus is incorporated into silicon, as evidenced
by the Si atoms ejected to the surface. These findings are useful for the
insertion of individual phosphorus atoms into silicon by PBr3 adsorption
through a halogen mask.

</details>


### [204] [Vacancy diffusion on a brominated Si(100) surface: Critical effect of the dangling bond charge state](https://arxiv.org/abs/2510.20426)
*T. V. Pavlova,V. M. Shevlyuga*

Main category: cond-mat.mtrl-sci

TL;DR: 带电硅悬挂键影响溴空位在Si(100)表面的扩散。


<details>
  <summary>Details</summary>
Motivation: 研究溴空位在Si(100)-2x1-Br表面上的扩散行为，特别是悬挂键的电荷状态对扩散的影响。

Method: 在扫描隧道显微镜下观察溴空位的扩散，并结合密度泛函理论计算。

Result: 带正电的溴空位会扩散，而带中性或负电的溴空位则不会。密度泛函理论计算证实了带正电的溴（和氯）空位具有最低的激活能垒。。

Conclusion: 悬挂键的电荷状态对空位扩散有关键影响，这对表面结构成像和研究Si(100)表面空位扩散至关重要。

Abstract: Silicon dangling bonds (DBs) on an adsorbate-covered Si(100) surface can be
created in a scanning tunneling microscope (STM) with high precision required
for a number of applications. However, vacancies containing DBs can diffuse,
disrupting precisely created structures. In this work, we study the diffusion
of Br vacancies on a Si(100)-2$\times$1-Br surface in an STM under typical
imaging conditions. In agreement with previous work, Br vacancies diffuse at a
positive sample bias voltage. Here, we demonstrated that only vacancies
containing a positively charged DB hop across the two atoms of a single Si
dimer, while vacancies containing neutral and negatively charged DBs do not.
Calculations based on the density functional theory confirmed that positively
charged Br (and Cl) vacancies have a minimum activation barrier. We propose
that diffusion operates by both one-electron and two-electron mechanisms
depending on the applied voltage. Our results show that the DB charge has a
critical effect on the vacancy diffusion. This effect should be taken into
account when imaging surface structures with charged DBs, as well as when
studying the diffusion of other atoms and molecules on the Si(100) surface with
vacancies in an adsorbate layer.

</details>


### [205] [Ultralow-Cost magnetocaloric compound for Cryogenic Cooling](https://arxiv.org/abs/2510.20458)
*Wei Liu,Benjamin Theisel,Yulia Klunnikova,Konstantin Skokov,Oliver Gutfleisch*

Main category: cond-mat.mtrl-sci

TL;DR: FeCl2是一种基于廉价元素的磁热材料，在20K左右和5T磁场下，磁熵变可达18.6 J/kg/K，接近重稀土材料，有潜力应用于氢液化。


<details>
  <summary>Details</summary>
Motivation: 为实现高效氢液化，需要开发成本效益高的磁热材料，以替代资源稀缺的稀土基化合物。

Method: 研究了FeCl2的磁热效应，包括逆磁热效应和常规磁热效应，并在不同磁场下测量了磁熵变和绝热温变。

Result: FeCl2在20K和1.5T磁场下表现出约5 J/kg/K的逆磁热效应。在5T磁场下，其常规磁热效应的磁熵变达到18.6 J/kg/K，绝热温变约为3.6K。

Conclusion: FeCl2具有较大的磁熵变和低成本的元素构成，是20-77K温度窗口下氢液化的实用磁热材料的候选者。

Abstract: Cost-effective materials are essential for large-scale deployment. The
emerging magnetocaloric hydrogen liquefaction technology could transform the
liquid hydrogen industry due to its potential in achieving higher efficiency.
Most studies of the cryogenic magnetocaloric effect (MCE) have focused on
resource-critical rare-earth-based compounds. Here we report on an ionic
magnetocaloric compound FeCl$_2$ which is based on ultralow-cost elements, as a
candidate working material for hydrogen liquefaction. FeCl$_2$ shows both
inverse and conventional MCE. From 0 to 1.5 T, the inverse effect yields a
positive magnetic entropy change ($\Delta S_T$) of about 5 J/kg/K near 20 K,
then declines toward zero at higher fields. In contrast, the conventional
(negative) response strengthens with field. The $\Delta S_T$ reaches 18.6
J/kg/K near 20 K in magnetic fields of 5 T. This value exceeds most light
rare-earth-based compounds and approaches that of heavy rare-earth-based
compounds. In magnetic fields of 5 T, the adiabatic temperature change reaches
about 3.6 K. The large $\Delta S_T$, along with the low cost of the elements in
FeCl$_2$, are prerequisites for inexpensive industrial-scale production, giving
the prospect of a practical magnetocaloric candidate for hydrogen liquefaction
in the 20 $\sim$ 77 K temperature window.

</details>


### [206] [Predicting the 3D microstructure of SOFC anodes from 2D SEM images using stochastic microstructure modeling and CNNs](https://arxiv.org/abs/2510.20502)
*Léon F. Schröder,Sabrina Weber,Lukas Fuchs,Volker Schmidt,Benedikt Prifling*

Main category: cond-mat.mtrl-sci

TL;DR: We present a novel method to reconstruct 3D microstructures of solid oxide fuel cell anodes from 2D SEM images using a CNN trained on a synthetic dataset generated by a physics-based SEM simulation and a stochastic geometry model.


<details>
  <summary>Details</summary>
Motivation: Conventional methods for 3D microstructure analysis are time-consuming and resource-intensive. This work aims to provide an accessible alternative for microstructure characterization.

Method: A low-parametric 3D model from stochastic geometry is used to generate virtual 3D microstructures, which are then simulated using a physics-based SEM tool to create corresponding 2D SEM images. This dataset is used to train a CNN that predicts 3D microstructure from 2D SEM images by estimating the parameters of the stochastic 3D model.

Result: The proposed method can statistically reconstruct the 3D microstructure from 2D SEM images. An error analysis was performed on key geometrical descriptors to evaluate the accuracy and reliability of the prediction tool.

Conclusion: The developed approach offers a viable and efficient alternative for characterizing the 3D microstructure of SOFC anodes, overcoming the limitations of traditional methods.

Abstract: The 3D microstructure of solid oxide fuel cell anodes significantly
influences their electrochemical performance, but conventional methods for
acquiring high-resolution microstructural 3D data such as focused ion beam
scanning electron microscopy (FIB-SEM) are costly in both time and resources.
In contrast, obtaining 2D images, such as from scanning electron microscopy
(SEM), is more accessible, though typically providing insufficient information
to accurately characterize the 3D microstructure. To address this challenge, we
propose a novel approach that predicts the 3D microstructure from 2D SEM
images. The presented method utilizes a low-parametric 3D model from stochastic
geometry to generate a large number of virtual 3D microstructures and employs a
physics-based SEM simulation tool to obtain the corresponding 2D SEM images. By
systematically varying the underlying model parameters, a large dataset can be
generated to train convolutional neural networks (CNNs). By doing so, we can
statistically reconstruct the 3D microstructure from 2D SEM images by drawing
realizations from the stochastic 3D model using the predicted model parameters.
In addition, we conducted an error analysis on key geometrical descriptors to
quantitatively evaluate the accuracy and reliability of this stereological
prediction tool.

</details>


### [207] [The effects of high-temperature ion-irradiation on early-stage grain boundaries serrations formation in Ni-based alloys](https://arxiv.org/abs/2510.20536)
*M. Frelek-Kozak,K. Mulewska,M. Wilczopolska,D. Kalita,W. Chrominski,A. Zaborowska,L. Kurpaska,J. Jagielski*

Main category: cond-mat.mtrl-sci

TL;DR: 镍基高温合金因其优异的抗蠕变性、断裂韧性和耐腐蚀性而被认为是第四代核反应堆的理想材料。然而，其抗辐照能力和辐照损伤对变形机制的影响仍需深入研究。本研究调查了两种商业镍基合金（Hastelloy X 和 Haynes 230），通过扫描电镜、透射电镜和纳米压痕等技术分析了它们的结构和力学性能。使用 Ar 离子（320keV）进行辐照，最高剂量达 12dpa，研究了辐照损伤的影响。结果显示，两种合金在两种辐照剂量下均出现硬化，其中 Hastelloy X 的硬化效应更明显，且其沉淀物形态发生显著变化。研究提出，两种合金的结构差异决定了辐照诱导过程的类型，辐照产生的过剩能量可降低高温相的成核温度，从而引发晶界锯齿化。


<details>
  <summary>Details</summary>
Motivation: 镍基高温合金是第四代核反应堆的理想材料，但其抗辐照能力和辐照损伤对变形机制的影响尚不明确。

Method: 使用扫描电镜（SEM）、电子背散射衍射（EBSD）、透射电镜（TEM）和纳米压痕技术研究了两种镍基合金（Hastelloy X 和 Haynes 230）的结构和力学性能。通过 Ar 离子（320keV）辐照，最高剂量达 12dpa，研究了辐照损伤的影响。

Result: 两种合金在辐照后均出现硬化，Hastelloy X 的硬化效应更显著，且其沉淀物形态发生改变。辐照能量可能降低了高温相的成核温度，导致晶界锯齿化。

Conclusion: 合金的结构差异决定了辐照诱导过程的类型，并影响其抗辐照性能。

Abstract: Nickel based superalloys display outstanding properties such as excellent
creep strength, remarkable fracture toughness parameters, and corrosion
resistance. For this reason, Ni based materials are considered as materials
dedicated to the IV generation of nuclear reactors. Although these materials
seem promising candidates, their radiation resistance and impact of radiation
damage on the deformation mechanism are still not fully understood. In this
work, two commercially available nickel based alloys, Hastelloy X and Haynes
230, were investigated. Structural and mechanical properties have been
described by means of SEM and EBSD, TEM, and nanoindentation tests. Radiation
damage has been performed by Ar ion with energy 320keV with two doses up to
12dpa. Obtained results have revealed a hardening effect for both levels of
damage. However, more intensive effects were observed for Hastelloy X.
Moreover, a significant change in precipitates morphology in Hastelloy X has
been observed. It has been proposed that structural differences between both
alloys determine the type of occurring radiation induced processes. Excess
energy deposited into materials structure during ion irradiation can lower the
temperature of nucleation of high temperature phases, which initiates the
formation of grain boundary serrations.

</details>


### [208] [Nanoscale Mapping of Transition Metal Ordering in Individual LiNi0.5Mn1.5O4 Particles Using 4D-STEM ACOM Technique](https://arxiv.org/abs/2510.20729)
*Gozde Oney,Fayçal Adrar,Junhao Cao,Chunyang Zhang,Muriel Véron,Matthieu Bugnet,Emmanuelle Suard,Jacob Olchowka,Laurence Croguennec,François Weill,Arnaud Demortière*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究首次使用4D-STEM技术在纳米尺度上直接观察了LiNi0.5Mn1.5O4颗粒中的有序分布，并提出了一种基于电子衍射斑点强度比值的局部有序度量化方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有技术在粒子尺度上阐明LiNi0.5Mn1.5O4中过渡金属排布有序化现象的空间分辨率不足的问题。

Method: 利用4D-STEM技术，结合电子衍射斑点强度比值，提出并应用一种量化局部有序度的方法，以纳米级空间分辨率直接观测单个LiNi0.5Mn1.5O4颗粒中的有序分布。

Result: 研究首次直接观测到LiNi0.5Mn1.5O4颗粒内部的有序分布，发现有序尖晶石LiNi0.5Mn1.5O4中的过渡金属有序性在整个初级颗粒中是一致的，但有序程度受颗粒尺度分布的影响，该分布又受退火条件影响。4D-STEM分析能够揭示高度有序和低度有序LiNi0.5Mn1.5O4颗粒之间的边界。

Conclusion: 过渡金属在尖晶石网络中的排布（无序或有序结构）影响LiNi0.5Mn1.5O4的电化学性能。4D-STEM技术能够为LiNi0.5Mn1.5O4颗粒的有序分布提供纳米尺度的直接观测和量化分析，有助于理解和优化其在锂离子电池中的应用。

Abstract: The electrochemical performance of the spinel LiNi0.5Mn1.5O4, a high-voltage
positive electrode material for Li-ion batteries, is influenced by the
transition metal arrangement in the octahedral network, leading to disordered
(Fd m S.G.) and ordered3 (P4332 S.G.) structures. However, widely used
techniques lack the spatial resolution necessary to elucidate the ordering
phenomenon at the particle scale. Using the 4D-STEM technique, we present the
first direct observation of ordering distribution in individual LiNi0.5Mn1.5O4
particles with nanometric spatial resolution. We propose a quantification
method for the local degree of ordering based on the ratio of ordered to
disordered spinel lattices along the particle thickness extracted from electron
diffraction spot intensities. In an ordered spinel LiNi0.5Mn1.5O4, the
transition metal ordering is consistently observed throughout the primary
particle. However, the extent of ordering in the spinel phase depends on its
distribution at the particle scale, a factor influenced by the annealing
conditions. The 4D-STEM analysis elucidates the boundary between highly-ordered
and low-ordered LiNi0.5Mn1.5O4 particles.

</details>


### [209] [Angular dependence and powder average of resonant inelastic X-ray scattering](https://arxiv.org/abs/2510.20731)
*Myrtille O. J. Y Hunault,Timothy G. Burrow,Fabien Besnard,Amélie Juhin,Christian Brouder*

Main category: cond-mat.mtrl-sci

TL;DR: RIXS的理论计算缺乏对角度依赖性的处理，本文推导了各晶体点群的基本谱和各向同性样品的RIXS截面通用表达式，并简化了常见点群的表达式。


<details>
  <summary>Details</summary>
Motivation: RIXS实验数据的解释需要基于Kramers-Heisenberg公式的理论计算，但该公式的角度依赖性缺乏有效的处理方法。

Method: 在电偶极近似下，确定RIXS截贡献的基本谱数量，并推导各向同性样品的RIXS截面通用表达式，然后简化常见点群的表达式。

Result: 推导了各晶体点群的基本谱数量，得到了各向同性样品的RIXS截面通用表达式，并简化了常见点群的表达式。

Conclusion: 本文提出的RIXS理论计算方法适用于各向同性样品，并通过铀3d4f RIXS的案例研究证明了其有效性。

Abstract: Resonant Inelastic X-ray scattering (RIXS) is a synchrotron-based
spectroscopy that has seen growing interest across a range of scientific
disciplines beyond fundamental physics. The interpretation of experimental RIXS
data requires theoretical calculations based on the Kramers-Heisenberg formula.
However, due to the dependence of RIXS on both the incident and scattered
photon properties, a tractable treatment of the angular dependence in this
formula has been lacking. In this work, within the electric dipole
approximation, we determine the number of fundamental spectra contributing to
the RIXS cross-section for all crystallographic point groups. We then derive a
general expression for the RIXS cross-section of isotropic samples such as
un-textured powders, homogeneous glasses or liquids, explicitly accounting for
the polarization and propagation directions of both the incident and scattered
photons. Simplified forms of the RIXS expressions are subsequently obtained for
most common point groups. Finally, we demonstrate the applicability of our
formalism through a case study of uranium 3d4f RIXS.

</details>


### [210] [Berry Curvature Dipole-induced Non-linear Hall Effect in Oxide Heterostructures](https://arxiv.org/abs/2510.20746)
*Nesta Benno Joseph,Arka Bandyopadhyay,Ajit C. Balram,Awadhesh Narayan*

Main category: cond-mat.mtrl-sci

TL;DR: 提出非中心对称的过渡金属氧化物异质结构可用于实现和调谐Berry曲率偶极子(BCD)诱导的非线性霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 探索超越Berry曲率在决定输运现象中的作用，以及BCD在时间反转不变系统中的非线性霍尔效应。

Method: 通过第一性原理计算研究了(Ba(Os,Ir)O3)n/(BaTiO3)4 (n=1, 2) 结构的超晶格。

Result: 计算表明，BCD的大小以及非线性霍尔响应的大小可以通过改变金属层数或B位阳离子进行调谐。此外，Rashba分裂和铁电畸变可以通过外加电场或应变进行控制。

Conclusion: 非中心对称氧化物钙钛矿异质结构为探索和调控BCD驱动的非线性输运现象提供了一个多功能的平台。

Abstract: The observation of non-linear Hall effects in time-reversal invariant systems
has established the intriguing role of band topology beyond Berry curvature in
determining transport phenomena. Many of these non-linear responses owe their
origin to the Berry curvature dipole (BCD), which, like the Berry curvature
(monopole), is also an electronic band structure effect, but is routinely
strongly constrained by crystalline symmetries. Here, we propose
non-centrosymmetric transition metal oxide heterostructures as promising
platforms for realizing and tuning BCD-induced non-linear Hall effects.
Specifically, we investigate superlattices of the form
$(\mathrm{Ba(Os,Ir)}\mathrm{O}_3)_n/(\mathrm{BaTiO}_3)_4$ ($n{=}1, 2$),
comprising metallic perovskite layers ($\mathrm{BaOsO_3}$ or
$\mathrm{BaIrO_3}$) sandwiched between insulating ferroelectric
$\mathrm{BaTiO_3}$ (BTO). The ferroelectric distortion in BTO breaks inversion
symmetry of the superlattice, giving rise to a finite BCD with two
symmetry-allowed components of equal magnitude and opposite sign. Our
first-principles calculations demonstrate that the magnitude of the BCD -- and
consequently the nonlinear Hall response -- can be effectively tuned by varying
the number of metallic layers or the choice of the B-site cation in these
$\mathrm{ABO_3}$ perovskites. Since Rashba splitting and ferroelectric
distortion in these systems are readily controllable via an external electric
field or strain, the non-linear Hall response in these materials can be
directly engineered. Our findings establish non-centrosymmetric oxide
perovskite heterostructures as a versatile platform for exploring and
manipulating BCD-driven non-linear transport phenomena.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [211] [HALOC-AxA: An Area/-Energy-Efficient Approximate Adder for Image Processing Application](https://arxiv.org/abs/2510.20137)
*Hasnain A. Ziad,Ashiq A. Sakib*

Main category: cs.AR

TL;DR: 一个新型节能减排、高效的近似加法器，在图像处理等任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对多媒体应用等计算密集型应用，对低功耗硬件的需求而设计。

Method: 提出了一种新型的近似加法器，并在图像处理任务中进行了验证。

Result: 与现有加法器相比，该加法器在能效和面积方面更具优势，同时保持了可比或更高的准确性。

Conclusion: 所提出的加法器能够以更低的功耗和面积实现高质量的图像重建。

Abstract: The design of approximate adders has been widely researched to advance
energy-efficient hardware for computation-intensive multimedia applications,
such as image, audio, or video processing. The design of approximate adders has
been widely researched to advance energy-efficient hardware for computation
intensive multimedia applications, such as image/audio/video processing.
Several static and dynamic approximate adders exist in the literature, each of
which endeavors to balance the conflicting demands of high performance,
computational accuracy, and energy efficiency. This work introduces a novel
approximate adder that is more energy- and area-efficient than existing adders,
while achieving improved or comparable accuracy, as demonstrated by simulation
results. The proposed adder's ability to digitally reconstruct high quality
images is further demonstrated by the deployment of the design for an image
processing task.

</details>


### [212] [In-DRAM True Random Number Generation Using Simultaneous Multiple-Row Activation: An Experimental Study of Real DRAM Chips](https://arxiv.org/abs/2510.20269)
*Ismail Emir Yuksel,Ataberk Olgun,F. Nisa Bostanci,Oguzhan Canpolat,Geraldo F. Oliveira,Mohammad Sadrosadati,Abdullah Giray Yaglikci,Onur Mutlu*

Main category: cs.AR

TL;DR: 通过利用同时多行激活(SiMRA)技术，在商用现成(COTS)DRAM芯片中，以高吞吐量和低延迟生成真随机数。


<details>
  <summary>Details</summary>
Motivation: 在DRAM芯片中利用SiMRA技术实现高吞吐量、低延迟的真随机数生成。

Method: 对96个DDR4 DRAM芯片进行广泛表征，分析SiMRA在不同激活行数、数据模式、温度和空间变化下的熵、延迟和吞吐量。

Result: 提出的TRNG设计通过了NIST统计测试套件；与现有技术相比，吞吐量最高可提高1.99倍；熵随激活行数增加而增加，但受操作参数（如数据模式和温度）影响显著。

Conclusion: SiMRA技术可以有效地在DRAM芯片中实现高质量的真随机数生成，并且性能优于现有技术，但其性能受操作条件影响。

Abstract: In this work, we experimentally demonstrate that it is possible to generate
true random numbers at high throughput and low latency in commercial
off-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row
activation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We
rigorously analyze SiMRA's true random generation potential in terms of
entropy, latency, and throughput for varying numbers of simultaneously
activated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature
levels, and spatial variations. Among our 11 key experimental observations, we
highlight four key results. First, we evaluate the quality of our TRNG designs
using the commonly-used NIST statistical test suite for randomness and find
that all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,
16-, and 32-row activation-based TRNG designs outperform the state-of-theart
DRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,
respectively. Third, SiMRA's entropy tends to increase with the number of
simultaneously activated DRAM rows. Fourth, operational parameters and
conditions (e.g., data pattern and temperature) significantly affect entropy.
For example, for most of the tested modules, the average entropy of 32-row
activation is 2.51x higher than that of 2-row activation. For example,
increasing the temperature from 50{\deg}C to 90{\deg}C decreases SiMRA's
entropy by 1.53x for 32-row activation. To aid future research and development,
we open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.

</details>


### [213] [Squire: A General-Purpose Accelerator to Exploit Fine-Grain Parallelism on Dependency-Bound Kernels](https://arxiv.org/abs/2510.20400)
*Rubén Langarita,Jesús Alastruey-Benedé,Pablo Ibáñez-Marín,Santiago Marco-Sola,Miquel Moretó,Adrià Armejach*

Main category: cs.AR

TL;DR: Squire是一个通用的加速器，旨在有效利用并行任务中的细粒度并行性来加速依赖关系绑定的内核。它通过集成低功耗的顺序核心来实现这一点，这些核心可以快速通信并直接访问L2缓存。Squire在动态规划内核上实现了高达7.64倍的加速，在端到端应用程序上实现了3.66倍的加速，同时能耗降低了56%，面积开销仅为10.5%。


<details>
  <summary>Details</summary>
Motivation: 传统的通用加速器在处理具有复杂依赖关系（如SIMD）的内核时，由于并行性利用受限、同步和数据传输开销大，难以有效利用细粒度并行性。而定制FPGA和ASIC设计成本高且灵活性差，无法适应不同工作负载。

Method: 提出了一种名为Squire的通用加速器，该加速器包含一组通用的低功耗顺序核心，这些核心可以快速通信并直接访问L2缓存。将Squire加速器集成到典型的多核系统中，每个CPU核心集成一个Squire加速器，以最小的软件改动来加速并行任务中的依赖关系绑定内核。

Result: 在五个实现了复杂依赖关系模式的内核的案例研究中，Squire在动态规划内核上实现了高达7.64倍的加速。对于一个端到端的应用程序，Squire实现了3.66倍的加速。此外，Squire将能耗降低了高达56%，而与Neoverse-N1基线相比，面积开销仅为10.5%。

Conclusion: Squire作为一种通用的加速器，能够有效加速依赖关系绑定的内核，并在性能、能效和硬件成本之间取得了良好的平衡，为处理复杂依赖关系的工作负载提供了一种有前景的解决方案。

Abstract: Multiple HPC applications are often bottlenecked by compute-intensive kernels
implementing complex dependency patterns (data-dependency bound). Traditional
general-purpose accelerators struggle to effectively exploit fine-grain
parallelism due to limitations in implementing convoluted data-dependency
patterns (like SIMD) and overheads due to synchronization and data transfers
(like GPGPUs). In contrast, custom FPGA and ASIC designs offer improved
performance and energy efficiency at a high cost in hardware design and
programming complexity and often lack the flexibility to process different
workloads. We propose Squire, a general-purpose accelerator designed to exploit
fine-grain parallelism effectively on dependency-bound kernels. Each Squire
accelerator has a set of general-purpose low-power in-order cores that can
rapidly communicate among themselves and directly access data from the L2
cache. Our proposal integrates one Squire accelerator per core in a typical
multicore system, allowing the acceleration of dependency-bound kernels within
parallel tasks with minimal software changes. As a case study, we evaluate
Squire's effectiveness by accelerating five kernels that implement complex
dependency patterns. We use three of these kernels to build an end-to-end
read-mapping tool that will be used to evaluate Squire. Squire obtains speedups
up to 7.64$\times$ in dynamic programming kernels. Overall, Squire provides an
acceleration for an end-to-end application of 3.66$\times$. In addition, Squire
reduces energy consumption by up to 56% with a minimal area overhead of 10.5%
compared to a Neoverse-N1 baseline.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [214] [Comparative Analysis of Thermal Models for Test Masses in Next-Generation Gravitational Wave Interferometers](https://arxiv.org/abs/2510.20338)
*Vincenzo Pierro,Vincenzo Fiumara,Guerino Avallone,Giovanni Carapella,Francesco Chiadini,Roberta De Simone,Rosalba Fittipaldi,Gerardo Iannone,Alessandro Magalotti,Enrico Silva,Veronica Granata*

Main category: physics.app-ph

TL;DR: 该论文研究了引力波探测器终端测试质量（TTM）的热效应，提出了两种数值模型（详细模型和简化的降阶模型）来模拟不同激光功率和涂层吸收率下的热行为，并比较了两种模型的预测结果，强调了准确表征涂层吸收功率的重要性。


<details>
  <summary>Details</summary>
Motivation: 引力波探测器（如Virgo）的灵敏度优化需要精确的热学建模，因为即使是微小的激光功率吸收也会引起限制性能的热效应。该研究旨在考虑未来更高的腔内激光功率和光学涂层吸收率情况下的TTM稳态热行为。

Method: 开发并比较了两种数值模型：一种是包含多层涂层和主体衬底的体积吸热的综合模型；另一种是简化的降阶模型，将涂层热影响表示为衬底上的有效表面边界条件。模拟聚焦于一种可用于下一代探测器的三元涂层设计。

Result: 研究结果表明，更高的涂层吸收会使最高温度集中在涂层-真空界面附近。比较分析显示，降阶模型与详细模型的温度预测差异仅为毫开尔文（mK），这通常在系统热物理参数的实验不确定度范围内。

Conclusion: 计算效率高的降阶模型可以提供足够精确的结果，适用于热管理和一阶畸变分析。该研究强调了准确表征涂层总吸收功率的关键性。

Abstract: Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for
optimizing the sensitivity of gravitational wave interferometers like Virgo. In
fact, in such gravitational wave detectors even minimal laser power absorption
can induce performance-limiting thermal effects. This paper presents a detailed
investigation into the steady-state thermal behavior of TTMs. In particular,
future scenarios of increased intracavity laser beam power and optical coating
absorption are considered. We develop and compare two numerical models: a
comprehensive model incorporating volumetric heat absorption in both the
multilayer coating and the bulk substrate, and a simplified reduced model where
the coating's thermal impact is represented as an effective surface boundary
condition on the substrate. Our simulations were focused on a ternary coating
design, which is a candidate for use in next-generation detectors. Results
reveal that higher coating absorption localizes peak temperatures near the
coating--vacuum interface. Importantly, the comparative analysis demonstrates
that temperature predictions from the reduced model differ from the detailed
model by only milli-Kelvins, a discrepancy often within the experimental
uncertainties of the system's thermo-physical parameters. This finding suggests
that computationally efficient reduced models can provide sufficiently accurate
results for thermal management and first-order distortion analyses. Moreover,
the critical role of accurately characterizing the total power absorbed by the
coating is emphasized.

</details>


### [215] [Multi-Task Deep Learning for Surface Metrology](https://arxiv.org/abs/2510.20339)
*D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz*

Main category: physics.app-ph

TL;DR: 本文提出了一个可复现的深度学习框架，用于表面计量，以预测表面纹理参数及其报告的标准不确定度。


<details>
  <summary>Details</summary>
Motivation: 为了解决表面计量中预测表面纹理参数及其不确定度的需求，并提供可复现的深度学习框架。

Method: 使用跨越触觉和光学系统的多仪器数据集，解决了测量系统类型分类问题，并对 Ra、Rz、RONt 及其不确定度目标（Ra_uncert、Rz_uncert、RONt_uncert）进行了协调回归。通过分位数和异方差预测头进行不确定性建模，并进行事后共形校准以获得校准区间。

Result: 在保持高保真度的情况下，单一目标回归器在 Ra、Rz 和 RONt 上取得了很高的 R2 分数（分别为 0.9824、0.9847、0.9918），其中两个不确定性目标（Ra_uncert、Rz_uncert）也得到了很好的建模（R2 分别为 0.9899、0.9955），但 RONt_uncert 仍具挑战性（R2 为 0.4934）。分类器准确率达到 92.85%，概率校准在温度缩放后几乎没有变化（ECE 从 0.00504 变为 0.00503）。观察到朴素的多输出模型存在负迁移，单一目标模型表现更佳。

Conclusion: 所提出的方法能够提供经过校准的预测，适用于指导计量工作流程中的仪器选择和验收决策。

Abstract: A reproducible deep learning framework is presented for surface metrology to
predict surface texture parameters together with their reported standard
uncertainties. Using a multi-instrument dataset spanning tactile and optical
systems, measurement system type classification is addressed alongside
coordinated regression of Ra, Rz, RONt and their uncertainty targets
(Ra_uncert, Rz_uncert, RONt_uncert). Uncertainty is modelled via quantile and
heteroscedastic heads with post-hoc conformal calibration to yield calibrated
intervals. On a held-out set, high fidelity was achieved by single-target
regressors (R2: Ra 0.9824, Rz 0.9847, RONt 0.9918), with two uncertainty
targets also well modelled (Ra_uncert 0.9899, Rz_uncert 0.9955); RONt_uncert
remained difficult (R2 0.4934). The classifier reached 92.85% accuracy and
probability calibration was essentially unchanged after temperature scaling
(ECE 0.00504 -> 0.00503 on the test split). Negative transfer was observed for
naive multi-output trunks, with single-target models performing better. These
results provide calibrated predictions suitable to inform instrument selection
and acceptance decisions in metrological workflows.

</details>


### [216] [Basic considerations in the design of an electrostatic electron monochromator](https://arxiv.org/abs/2510.20517)
*M. J. Adriaans,J. H. P. Hoogenboom,A. Mohammadi-Gheidari*

Main category: physics.app-ph

TL;DR: 电子显微镜和光谱学中的单色仪虽然能提高分辨率，但由于成本高和操作复杂，在扫描电子显微镜中的应用有限。本文提出了一种基于边缘场的单色仪设计，该设计成本低廉、结构简单，并能实现高能量分辨率。


<details>
  <summary>Details</summary>
Motivation: 单色仪在电子显微镜中至关重要，但其成本和复杂性限制了其在扫描电子显微镜中的应用。

Method: 通过对静电均匀场偏转器的薄偏转器分析，证明了现有单色仪对电源漂移和机械缺陷的敏感性。提出了一种基于纯边缘场的设计，并使用瞬时减速透镜来优化能量分辨率。

Result: 提出的边缘场偏转器对电源漂移和机械缺陷不敏感，无需额外的校正元件，即可实现最佳能量分辨率。该设计可以采用 MEMS 技术制造，成本更低，易于实现。

Conclusion: 提出了一种成本效益高、结构简单的纯边缘场单色仪设计，克服了现有单色仪的缺点，并有望通过 MEMS 技术实现，从而提高单色仪的可及性。

Abstract: Monochromators are an essential component in electron microscopy and
spectroscopy for enhancing the spatial and energy resolution. However, its
adoption in scanning electron microscopes remains limited because of its high
cost and operational complexity. Through a thin-deflector analysis of an
electrostatic homogeneous-field deflector, the extreme sensitivity of current
monochromators to power supply drift and mechanical imperfections is
demonstrated. These stringent alignment requirements for achieving optimal
energy resolution often necessitate the use of additional correcting elements,
adding to both cost and complexity. We demonstrate that the fringe-field
deflector is instead less sensitive to these issues. Hence, a cost effective
and simple monochromator design approach based on pure fringe fields is
proposed. This monochromator does not need extra correcting elements and its
optimal energy resolution is achieved by including momentary deceleration
lenses surrounding the main deflector. This fully electrostatic design could be
realized using MEMS technology, offering a simpler and more accessible approach
for filtering beam energies.

</details>


### [217] [Real-time dynamics of VCMA-assisted switching of magnetic tunnel junctions](https://arxiv.org/abs/2510.20701)
*Marco Hoffmann,Shaohai Chen,Gunasheel Kauwtilyaa Krishnaswamy,Hang Khume Tan,Sherry L. K. Yap,James Lourembam,Anjan Soumyanarayanan,Pietro Gambardella*

Main category: physics.app-ph

TL;DR: 铁电隧穿结中的电压控制磁各向异性（VCMA）辅助切换速度受限于器件的充电效应和磁性层中的磁畴。增加电压或磁场可将切换时间缩短至几纳秒以内。


<details>
  <summary>Details</summary>
Motivation: 研究VCMA辅助切换的磁隧穿结的实时动态，以了解影响切换速度的因素，并为优化VCMA驱动的磁化控制提供见解。

Method: 通过在磁场中弛豫来研究VCMA辅助切换的磁隧穿结的实时动态。使用包含有限充电时间和磁性层粒度的微磁模拟来重现实验结果。

Result: 器件依赖的充电效应和自由层中的磁畴限制了在接近临界切换阈值时的切换速度。增加电压或磁场可以将切换时间缩短至几纳秒以内。

Conclusion: 器件的充电效应和磁性层粒度是限制VCMA辅助切换速度的关键因素，可通过调整电压和磁场来优化。

Abstract: Voltage control of magnetic anisotropy (VCMA) induced by charge accumulation
is typically considered as an ultrafast process, enabling energy-efficient and
high-speed magnetization switching in spintronic devices. In this work, we
investigate the real-time dynamics of VCMA-assisted switching of magnetic
tunnel junctions via relaxation in a magnetic field. We show that
device-dependent charging effects and magnetic granularity in the free layer
limit the switching speed at applied voltages close to the critical switching
threshold. Increasing the voltage or the applied magnetic field reduces the
incubation delay and total switching time to below a few ns. Micromagnetic
simulations incorporating the finite charging times of the tunnel junction and
the granularity of the magnetic film reproduce the experimental results,
providing critical insights into optimizing VCMA-driven magnetization control
for memory and logic applications.

</details>


### [218] [Magnetic tunnel junction as a real-time entropy source: Field-Programmable Gate Array based random bit generation without post-processing](https://arxiv.org/abs/2510.20735)
*Troy Criss,Ahmed Sidi El Valli,Naomi Li,Andrew Haas,Andrew D. Kent*

Main category: physics.app-ph

TL;DR: 通过FPGA控制的磁性隧道结产生真随机数


<details>
  <summary>Details</summary>
Motivation: 需要快速可靠的真随机数生成器，用于密码学、随机硬件加速器、概率计算和大规模建模等应用。

Method: 在FPGA上实现实时反馈回路，将切换概率稳定在50%附近，并进行XOR运算，以消除短期相关性，减轻长期漂移和比特流偏差。

Result: 实现了每秒5兆比特的、符合NIST标准的随机比特生成，无需后处理。

Conclusion: 所提出的方法提供了一种实用的硬件解决方案，能够快速、可靠地生成真随机数，并具有广泛的应用前景。

Abstract: We demonstrate a method to generate application-ready truly random bits from
a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We
implement a real-time feedback loop that stabilizes the switching probability
near 50\% and apply an XOR operation, both on the FPGA, to suppress short-term
correlations, together mitigating long-term drift and bias in the bitstream.
This combined approach enables NIST-compliant random bit generation at 5~Mb/s
without post-processing, providing a practical hardware solution for fast and
reliable true random number generation. Beyond cryptographic applications,
these capabilities open opportunities for stochastic hardware accelerators,
probabilistic computing, and large-scale modeling where real-time access to
unbiased randomness is essential.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [219] [Some Attention is All You Need for Retrieval](https://arxiv.org/abs/2510.19861)
*Felix Michalak,Steven Abreu*

Main category: cs.LG

TL;DR: 混合SSM-Transformer模型在检索任务上表现出功能完全分离的特性，其中检索完全依赖于自注意力层，而SSM层对此没有补偿作用。仅保留15%的注意力头即可维持近乎完美的检索性能，同时保留84%的MMLU性能，表明自注意力主要专门用于检索任务。检索的关键在于“针”令牌必须在生成过程中暴露，并且在预填充或生成期间必须有足够的上下文。这种功能专业化挑战了对混合架构冗余的假设，并暗示这些模型作为专门模块运行，而非集成系统，这对架构优化和可解释性具有直接影响。


<details>
  <summary>Details</summary>
Motivation: 探究混合SSM-Transformer架构中功能分工的程度，特别是检索任务在不同组件（SSM层和自注意力层）中的作用，以及这种专业化对模型整体性能和优化方向的启示。

Method: 通过在RecurrentGemma-2B/9B和Jamba-Mini-1.6模型上进行注意力层剔除实验，观察检索准确率的变化。同时，通过稀疏化注意力层（保留15%的注意力头）来评估其对检索和MMLU性能的影响。此外，还分析了实现检索所需的具体机制要求，如“针”令牌的暴露和上下文的可用性。

Result: 注意力层剔除导致检索准确率降至0%，而SSM层并未显示出补偿机制。稀疏化注意力层至15%时，检索准确率接近完美，同时MMLU性能保留了84%。研究确定了检索的精确机制要求：需要暴露“针”令牌，并且在预填充或生成期间必须有足够的上下文。

Conclusion: 混合SSM-Transformer架构表现出完全的功能分离，自注意力层主要负责检索任务，而SSM层不具备补偿能力。这种高度专业化的特性表明模型由专门模块组成，而非完全集成的系统，这对未来优化模型架构和提高模型可解释性具有重要意义。

Abstract: We demonstrate complete functional segregation in hybrid SSM-Transformer
architectures: retrieval depends exclusively on self-attention layers. Across
RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic
retrieval failure (0% accuracy), while SSM layers show no compensatory
mechanisms even with improved prompting. Conversely, sparsifying attention to
just 15% of heads maintains near-perfect retrieval while preserving 84% MMLU
performance, suggesting self-attention specializes primarily for retrieval
tasks. We identify precise mechanistic requirements for retrieval: needle
tokens must be exposed during generation and sufficient context must be
available during prefill or generation. This strict functional specialization
challenges assumptions about redundancy in hybrid architectures and suggests
these models operate as specialized modules rather than integrated systems,
with immediate implications for architecture optimization and interpretability.

</details>


### [220] [An Integrated Approach to Neural Architecture Search for Deep Q-Networks](https://arxiv.org/abs/2510.19872)
*Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian*

Main category: cs.LG

TL;DR: NAS-DQN通过在DRL训练循环中集成学习到的神经架构搜索控制器，动态调整网络结构，以提高性能、样本效率和策略稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究在线、自适应架构优化是否能克服深度强化学习（DRL）智能体由昂贵的超参数搜索确定的静态网络架构的限制。

Method: 提出NAS-DQN，一个在DRL训练循环中集成了学习到的神经架构搜索控制器的智能体，能够基于累积性能反馈动态地重新配置网络。

Result: NAS-DQN在连续控制任务上实现了优于固定架构基线和随机搜索的最终性能、样本效率和策略稳定性，并且计算开销可忽略不计。智能搜索策略是成功的关键。

Conclusion: 架构适应对于DRL的样本效率是必需的，并且可以将RL智能体设计无缝集成到学习过程中，作为动态组件，而不是静态的离线选择。

Abstract: The performance of deep reinforcement learning agents is fundamentally
constrained by their neural network architecture, a choice traditionally made
through expensive hyperparameter searches and then fixed throughout training.
This work investigates whether online, adaptive architecture optimization can
escape this constraint and outperform static designs. We introduce NAS-DQN, an
agent that integrates a learned neural architecture search controller directly
into the DRL training loop, enabling dynamic network reconfiguration based on
cumulative performance feedback. We evaluate NAS-DQN against three
fixed-architecture baselines and a random search control on a continuous
control task, conducting experiments over multiple random seeds. Our results
demonstrate that NAS-DQN achieves superior final performance, sample
efficiency, and policy stability while incurring negligible computational
overhead. Critically, the learned search strategy substantially outperforms
both undirected random architecture exploration and poorly-chosen fixed
designs, indicating that intelligent, performance-guided search is the key
mechanism driving success. These findings establish that architecture
adaptation is not merely beneficial but necessary for optimal sample efficiency
in online deep reinforcement learning, and suggest that the design of RL agents
need not be a static offline choice but can instead be seamlessly integrated as
a dynamic component of the learning process itself.

</details>


### [221] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: 尽管LLM在生成CUDA代码方面有潜力，但云API的代码泄露风险和本地部署的成本问题限制了其应用。SLM更轻便且隐私友好，但其有限的推理能力导致复杂CUDA生成的性能不佳。ReGraphT是一个训练框架，通过将CUDA优化轨迹组织成结构化推理图，并利用蒙特卡洛图搜索来弥补SLM的不足，实现了接近LLM的性能，同时规避了隐私和成本问题。


<details>
  <summary>Details</summary>
Motivation: 尽管CUDA编程和特定库不断发展，但有效利用GPU仍然困难。LLM在生成优化CUDA代码方面显示出潜力，但云API的代码泄露风险和本地部署的计算成本限制了其应用。SLM更轻便且隐私友好，但在复杂CUDA生成方面性能不佳，需要弥补其有限的推理能力。

Method: ReGraphT框架通过将CUDA优化轨迹组织成结构化推理图，将组合的CUDA优化建模为状态转换，并利用蒙特卡洛图搜索（MCGS）进行高效探索，实现了LLM级别的推理能力迁移到小模型。此外，还提出了一个特定于CUDA的基准测试，以更全面的评估模型。

Result: ReGraphT在CUDAEval和ParEval上的平均加速比为2.33倍，优于经过HPC特定微调的模型和其他检索增强方法。通过与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合，ReGraphT使SLM能够在不带来隐私风险或高计算开销的情况下接近LLM的性能。

Conclusion: ReGraphT通过结构化推理图和蒙特卡洛图搜索，成功地将LLM的推理能力迁移到SLM，解决了SLM在复杂CUDA生成方面的不足，并在性能和效率上取得了显著成果，为在实际应用中利用SLM生成高效CUDA代码提供了新的途径。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>


### [222] [From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem](https://arxiv.org/abs/2510.19889)
*Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis*

Main category: cs.LG

TL;DR: 本文提出一种基于深度学习（Transformer）的交通分配新方法，可直接预测均衡路径流量，相比传统方法速度更快、适应性更强。


<details>
  <summary>Details</summary>
Motivation: 传统交通分配方法在处理大规模网络时计算成本高昂，且难以适应需求和网络结构的变化。本研究旨在提出一种数据驱动的新方法，以克服这些挑战。

Method: 利用Transformer深度神经网络直接预测均衡路径流量，侧重于路径层面的交通分布，捕捉OD对之间的复杂相关性。

Result: 在多个测试网络上，该模型速度比传统方法快几个数量级，能够高效估计多类别网络中的路径流量，提高预测精度，并灵活适应需求和网络条件的变化。

Conclusion: 所提出的基于Transformer的模型是一种高效、灵活且计算成本低的数据驱动方法，能够准确预测路径流量，支持交通管理和运输规划。

Abstract: The traffic assignment problem is essential for traffic flow analysis,
traditionally solved using mathematical programs under the Equilibrium
principle. These methods become computationally prohibitive for large-scale
networks due to non-linear growth in complexity with the number of OD pairs.
This study introduces a novel data-driven approach using deep neural networks,
specifically leveraging the Transformer architecture, to predict equilibrium
path flows directly. By focusing on path-level traffic distribution, the
proposed model captures intricate correlations between OD pairs, offering a
more detailed and flexible analysis compared to traditional link-level
approaches. The Transformer-based model drastically reduces computation time,
while adapting to changes in demand and network structure without the need for
recalculation. Numerical experiments are conducted on the Manhattan-like
synthetic network, the Sioux Falls network, and the Eastern-Massachusetts
network. The results demonstrate that the proposed model is orders of magnitude
faster than conventional optimization. It efficiently estimates path-level
traffic flows in multi-class networks, reducing computational costs and
improving prediction accuracy by capturing detailed trip and flow information.
The model also adapts flexibly to varying demand and network conditions,
supporting traffic management and enabling rapid `what-if' analyses for
enhanced transportation planning and policy-making.

</details>


### [223] [FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals](https://arxiv.org/abs/2510.19917)
*Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas*

Main category: cs.LG

TL;DR: FINDER是一个用于分析通用分类问题（尤其是在噪声数据集上）的框架，通过引入“随机特征”和Kosambi-Karhunen-Lo'eve (KLE)展开来处理数据中的随机性，并在阿尔茨海默病分期和森林砍伐检测等领域取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 分类方法在噪声数据集（信噪比低、样本量小、数据收集错误等）上仍然是一个关键的研究前沿，具有理论和实践意义。

Method: FINDER将随机分析思想融入特征学习和推理阶段，通过将经验数据集视为潜在随机场的实现，并将其映射到希尔伯特空间来构建“随机特征”。利用KLE展开将这些随机特征分解为可计算的不可约分量，并通过特征值分解对噪声数据集进行分类。

Result: FINDER在阿尔茨海默病分期和森林砍伐检测等数据量不足的科学领域得到了验证，并取得了最先进的突破。

Conclusion: 对FINDER何时优于现有方法、其失效模式和其他局限性进行了讨论。

Abstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample
sizes, faulty data collection, etc) remain a key research frontier for
classification methods with both theoretical and practical implications. We
introduce FINDER, a rigorous framework for analyzing generic classification
problems, with tailored algorithms for noisy datasets. FINDER incorporates
fundamental stochastic analysis ideas into the feature learning and inference
stages to optimally account for the randomness inherent to all empirical
datasets. We construct ''stochastic features'' by first viewing empirical
datasets as realizations from an underlying random field (without assumptions
on its exact distribution) and then mapping them to appropriate Hilbert spaces.
The Kosambi-Karhunen-Lo\'eve expansion (KLE) breaks these stochastic features
into computable irreducible components, which allow classification over noisy
datasets via an eigen-decomposition: data from different classes resides in
distinct regions, identified by analyzing the spectrum of the associated
operators. We validate FINDER on several challenging, data-deficient scientific
domains, producing state of the art breakthroughs in: (i) Alzheimer's Disease
stage classification, (ii) Remote sensing detection of deforestation. We end
with a discussion on when FINDER is expected to outperform existing methods,
its failure modes, and other limitations.

</details>


### [224] [FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning](https://arxiv.org/abs/2510.19893)
*Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang*

Main category: cs.LG

TL;DR: 医疗AI模型存在人群偏见，FairGRPO通过自适应重要性加权和无监督聚类来解决这个问题，显著减少了预测差异并提高了F1分数，同时发布的FairMedGemma-4B模型也表现出更少的群体偏见。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统在不同人群中表现不一，对代表性不足的群体造成伤害。现有的多模态推理模型在通过强化学习进行训练时，会继承甚至放大训练数据中存在的偏见。

Method: 提出了一种名为Fairness-aware Group Relative Policy Optimization (FairGRPO) 的分层强化学习方法，该方法通过自适应地调整优势（advanges）的重要性权重（基于表示、任务难度和数据源）来促进不同临床人群的公平学习。当缺乏人口统计学标签时，采用无监督聚类来发现潜在的人口统计学分组。

Result: 在7个跨越X光、CT、皮肤镜、乳腺X光和超声等5种临床模态的医学诊断数据集上进行实验，FairGRPO相比所有基线方法，将预测差异（predictive parity）降低了27.2%，同时F1分数提高了12.49%。此外，FairGRPO在训练过程中持续提高公平性，而基线强化学习方法则在训练过程中公平性恶化。基于FairGRPO发布了FairMedGemma-4B模型，该模型在保持顶尖性能的同时，显著减少了不同人群间的性能差距。

Conclusion: FairGRPO是一种有效的解决医疗AI偏见问题的方法，能够显著提高模型的公平性和诊断准确性，并且发布的FairMedGemma-4B模型也验证了该方法的有效性。

Abstract: Medical artificial intelligence systems have achieved remarkable diagnostic
capabilities, yet they consistently exhibit performance disparities across
demographic groups, causing real-world harm to underrepresented populations.
While recent multimodal reasoning foundation models have advanced clinical
diagnosis through integrated analysis of diverse medical data, reasoning
trainings via reinforcement learning inherit and often amplify biases present
in training datasets dominated by majority populations. We introduce
Fairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical
reinforcement learning approach that promotes equitable learning across
heterogeneous clinical populations. FairGRPO employs adaptive importance
weighting of advantages based on representation, task difficulty, and data
source. To address the common issue of missing demographic labels in the
clinical domain, we further employ unsupervised clustering, which automatically
discovers latent demographic groups when labels are unavailable. Through
comprehensive experiments across 7 clinical diagnostic datasets spanning 5
clinical modalities across X-ray, CT scan, dermoscropy, mammography and
ultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2%
against all vanilla and bias mitigated RL baselines, while improving F1 score
by 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO
progressively improves fairness throughout optimization, while baseline RL
methods exhibit deteriorating fairness as training progresses. Based on
FairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that
achieves state-of-the-art performance while demonstrating significantly reduced
disparities across demographic groups.

</details>


### [225] [Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control](https://arxiv.org/abs/2510.20408)
*Tom Maus,Asma Atamna,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 本研究提出了一个结合了SortingEnv和ContainerGym的工业回收场景基准环境，并评估了模块化与单一agent策略在有无动作掩码下的表现。


<details>
  <summary>Details</summary>
Motivation: 工业界在采用强化学习（RL）进行多阶段工业过程自主控制时面临奖励设计、模块化和动作空间管理等挑战，现有基准环境与工业实际脱节。

Method: 创建了一个结合了SortingEnv和ContainerGym的顺序回收场景基准环境，并对比了具有专业agent的模块化架构和控制整个系统的单一agent策略，同时分析了动作掩码的影响。

Result: 在没有动作掩码的情况下，agent学习困难，模块化架构表现更好；应用动作掩码后，两种架构性能均显著提升，性能差距缩小。

Conclusion: 动作空间约束对RL策略学习至关重要，动作复杂度降低时，专业化的优势会减弱。该基准环境为探索工业自动化中的多agent RL解决方案提供了测试平台，并有助于关于集权与专业化之争的讨论。

Abstract: Autonomous control of multi-stage industrial processes requires both local
specialization and global coordination. Reinforcement learning (RL) offers a
promising approach, but its industrial adoption remains limited due to
challenges such as reward design, modularity, and action space management. Many
academic benchmarks differ markedly from industrial control problems, limiting
their transferability to real-world applications. This study introduces an
enhanced industry-inspired benchmark environment that combines tasks from two
existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling
scenario with sorting and pressing operations. We evaluate two control
strategies: a modular architecture with specialized agents and a monolithic
agent governing the full system, while also analyzing the impact of action
masking. Our experiments show that without action masking, agents struggle to
learn effective policies, with the modular architecture performing better. When
action masking is applied, both architectures improve substantially, and the
performance gap narrows considerably. These results highlight the decisive role
of action space constraints and suggest that the advantages of specialization
diminish as action complexity is reduced. The proposed benchmark thus provides
a valuable testbed for exploring practical and robust multi-agent RL solutions
in industrial automation, while contributing to the ongoing debate on
centralization versus specialization.

</details>


### [226] [Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification](https://arxiv.org/abs/2510.19896)
*Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling*

Main category: cs.LG

TL;DR: 本研究提出一种基于SHAP特征选择的方法来支持泌尿系统疾病（特别是膀胱癌）的诊断，以提高预测模型的透明度和有效性。


<details>
  <summary>Details</summary>
Motivation: 支持泌尿系统疾病（特别是膀胱癌）的诊断，提高预测模型的透明度和有效性。

Method: 构建了区分膀胱癌和其他泌尿系统及肿瘤疾病的六种二元分类场景，使用XGBoost、LightGBM和CatBoost算法，并采用Optuna进行超参数优化和SMOTE技术进行类别平衡。通过SHAP特征选择来选择预测变量，同时保持或提高性能指标（如平衡准确率、精确率和特异性）。

Result: 基于SHAP的特征选择在保持或提高预测模型性能的同时，有效选择了预测变量。

Conclusion: SHAP解释技术在特征选择方面被证明是有效的方法，所提出的方法有助于开发更透明、可靠和高效的临床决策支持系统，从而优化泌尿系统疾病的筛查和早期诊断。

Abstract: In this paper, we propose an approach to support the diagnosis of urinary
tract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive
exPlanations)-based feature selection to enhance the transparency and
effectiveness of predictive models. Six binary classification scenarios were
developed to distinguish bladder cancer from other urological and oncological
conditions. The algorithms XGBoost, LightGBM, and CatBoost were employed, with
hyperparameter optimization performed using Optuna and class balancing with the
SMOTE technique. The selection of predictive variables was guided by importance
values through SHAP-based feature selection while maintaining or even improving
performance metrics such as balanced accuracy, precision, and specificity. The
use of explainability techniques (SHAP) for feature selection proved to be an
effective approach. The proposed methodology may contribute to the development
of more transparent, reliable, and efficient clinical decision support systems,
optimizing screening and early diagnosis of urinary tract diseases.

</details>


### [227] [Thought Communication in Multiagent Collaboration](https://arxiv.org/abs/2510.20733)
*Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang*

Main category: cs.LG

TL;DR: 通过直接的“思想通信”范式，使智能体能够超越自然语言的限制进行交互，从而实现更强的集体智能。


<details>
  <summary>Details</summary>
Motivation: 自然语言作为人类协作的基础，存在信息丢失、歧义和间接性的缺点，限制了集体智能的潜力。现有的大多数基于LLM的多智能体系统仍然局限于使用自然语言进行交流，未能充分发挥机器的优势。

Method: 将思想通信过程形式化为一个通用的潜在变量模型，其中智能体的状态是由潜在思想的未知函数生成的。证明了在没有辅助信息的非参数设置下，可以识别智能体之间共享和私有的潜在思想，并且可以恢复思想共享的全局结构。基于此理论，开发了一个框架，在通信前提取所有智能体的潜在思想，并将相关思想及其共享模式分配给每个智能体。

Result: 实验在合成和真实世界基准上验证了该理论，并证明了思想通信在协作方面的优势。

Conclusion: 思想通信作为一种超越语言的新范式，能够直接进行智能体间的 mind-to-mind 交互，为解决仅依靠表面观察难以解决的挑战开辟了新的可能性，并具有广泛的适用性，可以扩展到所有模态。

Abstract: Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

</details>


### [228] [Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints](https://arxiv.org/abs/2510.20220)
*Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Fair-SMW的算法，通过使用拉格朗日方法和Sherman-Morrison-Woodbury (SMW) 恒等式来优化受约束的优化问题，从而提高保证群体公平性（平衡性）的谱聚类算法的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的保证群体公平性（平衡性）的谱聚类算法计算时间较长，需要提高效率。

Method: 使用拉格朗日方法和Sherman-Morrison-Woodbury (SMW) 恒等式来重新构建受约束的优化问题。Fair-SMW算法采用了三种不同的拉普拉斯矩阵替代方法，并利用了不同的谱隙，以产生多种Fair-SMW算法变体。

Result: Fair-SMW算法在保持与现有算法相当的平衡性的同时，将计算时间缩短了一半，并且在平衡性方面也取得了更高的成就。

Conclusion: Fair-SMW算法在计算效率和群体公平性（平衡性）方面都优于现有算法。

Abstract: Recent research has focused on mitigating algorithmic bias in clustering by
incorporating fairness constraints into algorithmic design. Notions such as
disparate impact, community cohesion, and cost per population have been
implemented to enforce equitable outcomes. Among these, group fairness
(balance) ensures that each protected group is proportionally represented
within every cluster. However, incorporating balance as a metric of fairness
into spectral clustering algorithms has led to computational times that can be
improved. This study aims to enhance the efficiency of spectral clustering
algorithms by reformulating the constrained optimization problem using a new
formulation derived from the Lagrangian method and the
Sherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm.
Fair-SMW employs three alternatives to the Laplacian matrix with different
spectral gaps to generate multiple variations of Fair-SMW, achieving clustering
solutions with comparable balance to existing algorithms while offering
improved runtime performance. We present the results of Fair-SMW, evaluated
using the Stochastic Block Model (SBM) to measure both runtime efficiency and
balance across real-world network datasets, including LastFM, FacebookNet,
Deezer, and German. We achieve an improvement in computation time that is twice
as fast as the state-of-the-art, and also flexible enough to achieve twice as
much balance.

</details>


### [229] [Beyond the Ideal: Analyzing the Inexact Muon Update](https://arxiv.org/abs/2510.19933)
*Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik*

Main category: cs.LG

TL;DR: Muon优化器在大型神经网络训练中表现出色，但其理论分析未能覆盖其实际使用的近似正交化方法。本研究首次分析了Muon核心的非精确正交化更新，提出了一个实际的加性误差模型，并量化了近似误差对性能的影响。研究发现，近似误差与最优步长和动量参数之间存在耦合关系：较低的预估精度需要较小的步长和较大的动量。实验结果证实了这一耦合关系。


<details>
  <summary>Details</summary>
Motivation: 现有理论分析了理想化的Muon优化器，但忽略了其实际应用中使用的快速近似正交化方法，存在理论与实践脱节的问题。

Method: 在基于线性最小化预估器（LMO）的优化框架内，引入了一个实际的加性误差模型来模拟近似正交化带来的不精确性，并对此进行了理论分析。

Result: 得出了明确的界限，量化了性能下降与LMO不精确性/误差的关系。揭示了不精确性与最优步长和动量参数之间存在根本性的耦合：较低的预估精度需要较小的步长但较大的动量参数。

Conclusion: 近似过程（例如牛顿-舒尔茨迭代次数）不再仅仅是实现细节，而是需要与学习率调整一起进行协同调整的关键参数。NanoGPT实验证实了预测的耦合关系，表明最优学习率会随着近似精度的变化而转移。

Abstract: The Muon optimizer has rapidly emerged as a powerful, geometry-aware
alternative to AdamW, demonstrating strong performance in large-scale training
of neural networks. However, a critical theory-practice disconnect exists:
Muon's efficiency relies on fast, approximate orthogonalization, yet all prior
theoretical work analyzes an idealized, computationally intractable version
assuming exact SVD-based updates. This work moves beyond the ideal by providing
the first analysis of the inexact orthogonalized update at Muon's core. We
develop our analysis within the general framework of Linear Minimization Oracle
(LMO)-based optimization, introducing a realistic additive error model to
capture the inexactness of practical approximation schemes. Our analysis yields
explicit bounds that quantify performance degradation as a function of the LMO
inexactness/error. We reveal a fundamental coupling between this inexactness
and the optimal step size and momentum: lower oracle precision requires a
smaller step size but larger momentum parameter. These findings elevate the
approximation procedure (e.g., the number of Newton-Schulz steps) from an
implementation detail to a critical parameter that must be co-tuned with the
learning schedule. NanoGPT experiments directly confirm the predicted coupling,
with optimal learning rates clearly shifting as approximation precision
changes.

</details>


### [230] [ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push](https://arxiv.org/abs/2510.20157)
*Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu*

Main category: cs.LG

TL;DR: ADP-VRSGP是一种结合了自适应差分隐私、方差缩减随机梯度推送、梯度融合和去中心化聚合技术的新型去中心化学习方法，旨在解决现有固定噪声差分隐私在模型性能和训练效率方面的不足，并能适应时变通信拓扑，在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化学习差分隐私方法通常使用固定方差噪声，这会导致模型性能下降和训练效率降低。本研究旨在解决这些问题。

Method: 提出了一种名为ADP-VRSGP（去中心化学习与自适应差分隐私通过方差缩减随机梯度推送）的新方法。该方法动态调整噪声方差和学习率，采用阶梯衰减计划；引入渐进梯度融合策略以利用历史梯度；结合了去中心化push-sum和聚合技术，以适应时变通信拓扑。

Result: 理论分析表明，ADP-VRSGP在合适的学习率下具有鲁棒的收敛性，提高了训练稳定性和速度。实验结果验证了该方法在多种场景下优于现有基线方法。

Conclusion: ADP-VRSGP在隐私保护的去中心化学习方面具有优势，能够有效解决现有方法的局限性，提高模型性能和训练效率。

Abstract: Differential privacy is widely employed in decentralized learning to
safeguard sensitive data by introducing noise into model updates. However,
existing approaches that use fixed-variance noise often degrade model
performance and reduce training efficiency. To address these limitations, we
propose a novel approach called decentralized learning with adaptive
differential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).
This method dynamically adjusts both the noise variance and the learning rate
using a stepwise-decaying schedule, which accelerates training and enhances
final model performance while providing node-level personalized privacy
guarantees. To counteract the slowed convergence caused by large-variance noise
in early iterations, we introduce a progressive gradient fusion strategy that
leverages historical gradients. Furthermore, ADP-VRSGP incorporates
decentralized push-sum and aggregation techniques, making it particularly
suitable for time-varying communication topologies. Through rigorous
theoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence
with an appropriate learning rate, significantly improving training stability
and speed. Experimental results validate that our method outperforms existing
baselines across multiple scenarios, highlighting its efficacy in addressing
the challenges of privacy-preserving decentralized learning.

</details>


### [231] [Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy](https://arxiv.org/abs/2510.19934)
*Xiang Li,Buxin Su,Chendi Wang,Qi Long,Weijie J. Su*

Main category: cs.LG

TL;DR: 本篇论文提出了两种新的基于 f-差分隐私 (f-DP) 的隐私会计方法 (PN-f-DP 和 Sec-f-LDP)，用于量化去中心化联邦学习 (DP-FL) 算法的隐私预算，解决了现有方法在 DP-FL 场景下量化隐私预算的挑战。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习 (DP-FL) 允许用户在不与中心服务器共享数据的情况下进行协作，但准确量化其隐私预算具有挑战性，因为其中存在复杂的算法组件，如去中心化通信和本地更新。

Method: 本文在 f-差分隐私 (f-DP) 框架下，针对去中心化联邦学习场景，开发了两种新的 f-DP 隐私会计方法：Pairwise Network f-DP (PN-f-DP) 和 Secret-based f-Local DP (Sec-f-LDP)。PN-f-DP 用于量化随机游走通信下的用户对之间的隐私泄露，Sec-f-LDP 用于支持通过共享密钥进行的结构化噪声注入。该方法结合了 f-DP 理论和马尔可夫链浓度工具，以捕捉稀疏通信、本地迭代和相关噪声带来的隐私放大。

Result: 实验结果表明，与基于 Rényi DP 的方法相比，本文提出的 f-DP 方法在合成和真实数据集上实现了更严格的 $(\epsilon, \delta)$ 边界和更高的效用。

Conclusion: 本文提出的两种基于 f-DP 的隐私会计方法 (PN-f-DP 和 Sec-f-LDP) 能够更准确地量化去中心化联邦学习的隐私预算，并提供更好的效用，证明了 f-DP 在去中心化隐私会计中的优势。

Abstract: Differentially private (DP) decentralized Federated Learning (FL) allows
local users to collaborate without sharing their data with a central server.
However, accurately quantifying the privacy budget of private FL algorithms is
challenging due to the co-existence of complex algorithmic components such as
decentralized communication and local updates. This paper addresses privacy
accounting for two decentralized FL algorithms within the $f$-differential
privacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods
tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which
quantifies privacy leakage between user pairs under random-walk communication,
and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise
injection via shared secrets. By combining tools from $f$-DP theory and Markov
chain concentration, our accounting framework captures privacy amplification
arising from sparse communication, local iterations, and correlated noise.
Experiments on synthetic and real datasets demonstrate that our methods yield
consistently tighter $(\epsilon,\delta)$ bounds and improved utility compared
to R\'enyi DP-based approaches, illustrating the benefits of $f$-DP in
decentralized privacy accounting.

</details>


### [232] [Are Greedy Task Orderings Better Than Random in Continual Linear Regression?](https://arxiv.org/abs/2510.19941)
*Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry*

Main category: cs.LG

TL;DR: 本文研究了持续学习中线性回归的任务排序问题，特别是贪婪最大化任务间不相似性的排序。


<details>
  <summary>Details</summary>
Motivation: 探索并形式化了贪婪最大化任务间不相似性的排序方法，并解释了其几何和代数直觉。

Method: 利用Kaczmarz方法的相关工具，对贪婪排序进行了形式化。

Result: 经验上，贪婪排序比随机排序在任务平均损失方面收敛更快，无论是在线性回归还是CIFAR-100分类任务上。分析上，在特定条件下（高秩回归），贪婪排序的损失界与随机排序类似；但在一般秩条件下，单次通过的贪婪排序可能灾难性失败，而允许重复的贪婪排序收敛速度为O(1/k^(1/3))。

Conclusion: 贪婪排序和随机排序在持续学习任务排序中存在细微差别，贪婪排序在某些情况下可能表现不佳，但在允许重复的情况下仍能保证收敛。

Abstract: We analyze task orderings in continual learning for linear regression,
assuming joint realizability of training data. We focus on orderings that
greedily maximize dissimilarity between consecutive tasks, a concept briefly
explored in prior work but still surrounded by open questions. Using tools from
the Kaczmarz method literature, we formalize such orderings and develop
geometric and algebraic intuitions around them. Empirically, we demonstrate
that greedy orderings converge faster than random ones in terms of the average
loss across tasks, both for linear regression with random data and for linear
probing on CIFAR-100 classification tasks. Analytically, in a high-rank
regression setting, we prove a loss bound for greedy orderings analogous to
that of random ones. However, under general rank, we establish a
repetition-dependent separation. Specifically, while prior work showed that for
random orderings, with or without replacement, the average loss after $k$
iterations is bounded by $\mathcal{O}(1/\sqrt{k})$, we prove that single-pass
greedy orderings may fail catastrophically, whereas those allowing repetition
converge at rate $\mathcal{O}(1/\sqrt[3]{k})$. Overall, we reveal nuances
within and between greedy and random orderings.

</details>


### [233] [Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets](https://arxiv.org/abs/2510.19950)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: RL 训练中的市场冲击问题通过新型椭圆不确定性集得到解决，并在金融交易任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 金融应用中的 RL 智能体在训练时所用的历史数据不会影响市场价格，但在实际部署时，其交易行为会改变资产价格（即市场冲击），导致性能下降。传统的鲁棒 RL 方法忽略了市场冲击的方向性。

Method: 提出一种新型椭圆不确定性集来处理市场冲击问题，并推导出最优不确定性下的隐式和显式闭式解，以实现可行的鲁棒策略评估。

Result: 在单资产和多资产交易任务的实验中，该方法实现了更高的夏普比率，并在交易量增加时保持了鲁棒性。

Conclusion: 该方法为金融市场中的 RL 提供了一种更准确、可扩展的解决方案，能够有效处理市场冲击问题。

Abstract: In financial applications, reinforcement learning (RL) agents are commonly
trained on historical data, where their actions do not influence prices.
However, during deployment, these agents trade in live markets where their own
transactions can shift asset prices, a phenomenon known as market impact. This
mismatch between training and deployment environments can significantly degrade
performance. Traditional robust RL approaches address this model
misspecification by optimizing the worst-case performance over a set of
uncertainties, but typically rely on symmetric structures that fail to capture
the directional nature of market impact. To address this issue, we develop a
novel class of elliptic uncertainty sets. We establish both implicit and
explicit closed-form solutions for the worst-case uncertainty under these sets,
enabling efficient and tractable robust policy evaluation. Experiments on
single-asset and multi-asset trading tasks demonstrate that our method achieves
superior Sharpe ratio and remains robust under increasing trade volumes,
offering a more faithful and scalable approach to RL in financial markets.

</details>


### [234] [On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization](https://arxiv.org/abs/2510.19953)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 提出了一种新颖的无偏梯度估计器家族，用于零阶优化（ZOO），以解决现有方法的偏差问题，并在理论和实验上都证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化（ZOO）方法的梯度估计器存在内在偏差，除非扰动步长趋于零。本研究旨在克服这一偏差问题。

Method: 通过将方向导数重新表述为伸缩级数，并从精心设计的分布中采样，构建了一种仅基于函数评估的无偏梯度估计器家族。分析了这些估计器的理论性质，推导了四种具体构造的最优缩放分布和扰动步长，并证明了使用这些估计器的随机梯度下降（SGD）在光滑非凸目标上可以达到最优复杂度。

Result: 提出的估计器消除了偏差，同时保持了有利的方差。实验结果表明，该方法在合成任务和语言模型微调方面，相比标准方法具有更高的准确性和收敛速度。

Conclusion: 所提出的无偏梯度估计器家族能够有效地解决零阶优化中的偏差问题，并在理论和实践中都表现出优越的性能，达到最优收敛复杂度。

Abstract: Zeroth-order optimization (ZOO) is an important framework for stochastic
optimization when gradients are unavailable or expensive to compute. A
potential limitation of existing ZOO methods is the bias inherent in most
gradient estimators unless the perturbation stepsize vanishes. In this paper,
we overcome this biasedness issue by proposing a novel family of unbiased
gradient estimators based solely on function evaluations. By reformulating
directional derivatives as a telescoping series and sampling from carefully
designed distributions, we construct estimators that eliminate bias while
maintaining favorable variance. We analyze their theoretical properties, derive
optimal scaling distributions and perturbation stepsizes of four specific
constructions, and prove that SGD using the proposed estimators achieves
optimal complexity for smooth non-convex objectives. Experiments on synthetic
tasks and language model fine-tuning confirm the superior accuracy and
convergence of our approach compared to standard methods.

</details>


### [235] [Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations](https://arxiv.org/abs/2510.19975)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文提出了一种新的方向对齐扰动（DAP）方案，用于优化零阶梯度估计，并在理论和经验上证明了其在特定条件下的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在固定长度的扰动上，忽略了方向对齐扰动的潜在优势。

Method: 将最小化扰动分布的渐近方差表述为一个约束泛函优化问题，并提出方向对齐扰动（DAP）方案。

Result: DAP方案能够自适应地沿着关键方向提供更高的精度，并在合成问题和实际任务的经验评估中表现优于传统方法。

Conclusion: 方向对齐扰动（DAP）方案在特定条件下比传统方法具有优势，并为随机梯度下降的收敛性分析提供了更广泛的扰动范围。

Abstract: In this paper, we explore the two-point zeroth-order gradient estimator and
identify the distribution of random perturbations that minimizes the
estimator's asymptotic variance as the perturbation stepsize tends to zero. We
formulate it as a constrained functional optimization problem over the space of
perturbation distributions. Our findings reveal that such desired perturbations
can align directionally with the true gradient, instead of maintaining a fixed
length. While existing research has largely focused on fixed-length
perturbations, the potential advantages of directional alignment have been
overlooked. To address this gap, we delve into the theoretical and empirical
properties of the directionally aligned perturbation (DAP) scheme, which
adaptively offers higher accuracy along critical directions. Additionally, we
provide a convergence analysis for stochastic gradient descent using
$\delta$-unbiased random perturbations, extending existing complexity bounds to
a wider range of perturbations. Through empirical evaluations on both synthetic
problems and practical tasks, we demonstrate that DAPs outperform traditional
methods under specific conditions.

</details>


### [236] [Towards Strong Certified Defense with Universal Asymmetric Randomization](https://arxiv.org/abs/2510.19977)
*Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong*

Main category: cs.LG

TL;DR: UCAN是一种新颖的技术，它通过使用各向异性噪声来普遍认证对抗性鲁棒性，它可以增强现有的随机平滑方法，提供更具针对性的防御。


<details>
  <summary>Details</summary>
Motivation: 现有的随机平滑方法主要使用各向同性噪声，忽略了输入和数据维度的异质性，限制了鲁棒性认证的有效性。

Method: UCAN将对称（各向同性）噪声分布转换为非对称（各向异性）噪声分布，并提供了一个理论框架，支持在不同的$\|epsilo$n$-范数中进行认证鲁棒性，适用于任何任意分类器。此外，还开发了一个包含三个噪声参数生成器（NPG）的新框架，以优化各向异性噪声参数。

Result: UCAN在MNIST、CIFAR10和ImageNet数据集上，在较大的认证半径下，认证准确率提高了182.6%，显著优于现有最先进的方法。

Conclusion: UCAN通过使用各向异性噪声，能够显著提高对抗性鲁棒性的认证效果，为防御对抗性攻击提供了更优化的解决方案。

Abstract: Randomized smoothing has become essential for achieving certified adversarial
robustness in machine learning models. However, current methods primarily use
isotropic noise distributions that are uniform across all data dimensions, such
as image pixels, limiting the effectiveness of robustness certification by
ignoring the heterogeneity of inputs and data dimensions. To address this
limitation, we propose UCAN: a novel technique that \underline{U}niversally
\underline{C}ertifies adversarial robustness with \underline{A}nisotropic
\underline{N}oise. UCAN is designed to enhance any existing randomized
smoothing method, transforming it from symmetric (isotropic) to asymmetric
(anisotropic) noise distributions, thereby offering a more tailored defense
against adversarial attacks. Our theoretical framework is versatile, supporting
a wide array of noise distributions for certified robustness in different
$\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the
classifier's prediction over perturbed inputs with provable robustness bounds
through tailored noise injection. Additionally, we develop a novel framework
equipped with three exemplary noise parameter generators (NPGs) to optimally
fine-tune the anisotropic noise parameters for different data dimensions,
allowing for pursuing different levels of robustness enhancements in
practice.Empirical evaluations underscore the significant leap in UCAN's
performance over existing state-of-the-art methods, demonstrating up to
$182.6\%$ improvement in certified accuracy at large certified radii on MNIST,
CIFAR10, and ImageNet datasets.\footnote{Code is anonymously available at
\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}

</details>


### [237] [Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency](https://arxiv.org/abs/2510.19980)
*Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe*

Main category: cs.LG

TL;DR: 通过引入自适应掩码损失与表示一致性（AMRC），本研究提出了一个创新的解决方案，通过动态掩码损失和表示一致性约束来解决时间序列预测中信息过载的问题，从而提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列预测中存在“长序列信息增益”假设的局限性，即模型会学习到冗余特征（如噪声或无关波动），从而影响信号提取。本研究旨在通过实验证明，适当截断历史数据可以提高预测精度，并提出一种新的方法来解决信息过载问题。

Method: 提出了一种名为自适应掩码损失与表示一致性（AMRC）的创新解决方案，包含两个核心组件：1）动态掩码损失，自适应地识别具有高度区分性的时间段以指导模型训练；2）表示一致性约束，以稳定输入、标签和预测之间的映射关系。

Result: 实验结果表明，AMRC能有效抑制冗余特征的学习，并显著提高模型在时间序列预测任务上的性能。

Conclusion: 本研究不仅挑战了时间序列建模的传统假设，还为开发高效、鲁棒的预测模型提供了新的理论见解和方法学突破。

Abstract: Time series forecasting plays a pivotal role in critical domains such as
energy management and financial markets. Although deep learning-based
approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the
prevailing "long-sequence information gain hypothesis" exhibits inherent
limitations. Through systematic experimentation, this study reveals a
counterintuitive phenomenon: appropriately truncating historical data can
paradoxically enhance prediction accuracy, indicating that existing models
learn substantial redundant features (e.g., noise or irrelevant fluctuations)
during training, thereby compromising effective signal extraction. Building
upon information bottleneck theory, we propose an innovative solution termed
Adaptive Masking Loss with Representation Consistency (AMRC), which features
two core components: 1) Dynamic masking loss, which adaptively identified
highly discriminative temporal segments to guide gradient descent during model
training; 2) Representation consistency constraint, which stabilized the
mapping relationships among inputs, labels, and predictions. Experimental
results demonstrate that AMRC effectively suppresses redundant feature learning
while significantly improving model performance. This work not only challenges
conventional assumptions in temporal modeling but also provides novel
theoretical insights and methodological breakthroughs for developing efficient
and robust forecasting models.

</details>


### [238] [No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models](https://arxiv.org/abs/2510.19990)
*Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown*

Main category: cs.LG

TL;DR: MDLMs 在数学和编程任务上存在推理瓶颈，本文提出了两种新方法来解决这些问题：1. reasoning-as-infilling：通过填充推理模板来解决输出结构化问题，并能衡量答案的不确定性，从而实现早期退出；2. multi-token entropy decoding (MED)：一种自适应采样器，可以通过并行解码来提高效率并保持性能。


<details>
  <summary>Details</summary>
Motivation: MDLMs 在数学和编程任务上存在推理瓶颈，任何顺序解码算法表现不佳，标准的多令牌解码会严重降低性能。模型在推理时计算所有被掩码位置的条件分布，这会带来额外的计算开销，而左到右的单令牌解码在效果上与任何顺序解码算法相当。因此，需要探索 MDLMs 的新应用方式，以证明其训练和计算的合理性。

Method: 1. reasoning-as-infilling：提出了一种新的推理方法，通过使用 MDLMs 来填充推理模板，从而结构化输出，区分推理和答案令牌。这使得在推理过程中可以衡量答案的不确定性，并在模型收敛到答案时提前退出。此外，该方法还可以在给定答案的情况下，从 MDLM 的后验分布中采样推理路径，为模型后训练提供高质量数据。2. multi-token entropy decoding (MED)：提出了一种简单的自适应采样器，通过最小化并行解码所带来的误差来提高效率。该方法根据位置的条件熵来解码，从而在保持性能的同时，显著减少所需的推理步数。

Result: 1. reasoning-as-infilling：在 GSM8k 数据集上，使用 MDLM 的后验推理路径对 LLaDA-8B Base 模型进行微调，性能提升效果与使用人类编写的推理路径进行微调的效果相当。此外，该方法还可以根据答案对推理过程的中间步骤进行正确性评分。2. MED：在多个基准测试中，MED 算法在保持性能的同时，将推理步数减少了 2.7 倍。

Conclusion: MDLMs 的训练和计算可以解锁新的推理和后训练方法。本文提出的 reasoning-as-infilling 和 multi-token entropy decoding (MED) 证明了 MDLMs 在解决数学和编程任务中的推理瓶颈方面的潜力，并通过实验验证了其有效性。

Abstract: Masked diffusion language models (MDLMs) are trained to in-fill positions in
randomly masked sequences, in contrast to next-token prediction models.
Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2)
multi-token decoding. However, we observe that for math and coding tasks,
any-order algorithms often underperform or behave similarly to left-to-right
sampling, and standard multi-token decoding significantly degrades performance.
At inference time, MDLMs compute the conditional distribution of all masked
positions. A natural question is: How can we justify this additional compute
when left-to-right one-token-at-a-time decoding is on par with any-order
decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs
to infill a reasoning template, we can structure outputs and distinguish
between reasoning and answer tokens. In turn, this enables measuring answer
uncertainty during reasoning, and early exits when the model converges on an
answer. Next, given an answer, reasoning-as-infilling enables sampling from the
MDLM posterior over reasoning traces conditioned on the answer, providing a new
source of high-quality data for post-training. On GSM8k, we observe that
fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a
performance boost on par with fine-tuning on human-written reasoning traces.
Additionally, given an answer, reasoning-as-infilling provides a method for
scoring the correctness of the reasoning process at intermediate steps. Second,
we propose multi-token entropy decoding (MED), a simple adaptive sampler that
minimizes the error incurred by decoding positions in parallel based on the
conditional entropies of those positions. MED preserves performance across
benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the
training and compute used by MDLMs unlock many new inference and post-training
methods.

</details>


### [239] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: RFID追踪在国防资产存储中可能有用，但传感器特异性差（如远程检测、欺骗和伪造）会导致错误检测和安全事件。本研究使用带有真实接收信号强度指示（RSSI）数据的监督学习模拟和决策树分类，在计算机辅助设计（CAD）的楼层平面图上进行，以应对国防存储中的挑战。


<details>
  <summary>Details</summary>
Motivation: RFID追踪在国防资产存储中可能有用，但传感器特异性差（如远程检测、欺骗和伪造）会导致错误检测和安全事件。本研究旨在解决这些挑战。

Method: 使用带有真实接收信号强度指示（RSSI）数据的监督学习模拟和决策树分类，在计算机辅助设计（CAD）的楼层平面图上进行，将12个实验室区域（LabZoneA-L）分类以进行位置推断。对包含约980,000个读数的原始数据集进行处理，计算类权重以解决类别不平衡问题，并在分层的子样本上训练模型，使其达到5,000个平衡的观测值。

Result: 模型在分层的子样本上训练，达到5,000个平衡的观测值，总体准确率为34.2%，多个区域（F、G、H等）的F1分数大于0.40。然而，稀有类别（尤其是LabZoneC）经常被错误分类，即使使用了类别权重。计算了感知邻近感知混淆矩阵以更好地解释物理上相邻的区域。

Conclusion: 结果表明，基于RSSI的决策树可用于现实模拟中，以实现国防供应链物流的区域级异常检测或错放监控。通过改进天线放置或使用其他传感器的传感器融合，可以提高在低覆盖和低信号区域的可靠分类性能。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [240] [SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph](https://arxiv.org/abs/2510.20022)
*Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong*

Main category: cs.LG

TL;DR: LLMs在多步、长周期任务中表现不佳，现有RL方法依赖稀疏奖励，GRPO等方法尤其面临挑战。本文提出SALT框架，通过图结构量化每一步的质量，进行更细粒度的优势分配，以解决上述问题。SALT易于集成，无需修改现有算法，并能在多个基准测试中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）方法主要依赖稀疏的、基于结果的奖励，这对于缺乏评论模型的群组RL算法（如GRPO）尤其不利。在多步交互中，有益和有害的行为往往交织在一起，统一奖励或惩罚整个轨迹会导致训练不稳定和次优策略。

Method: 提出了一种名为SALT的新颖轻量级框架，通过构建来自同一提示的轨迹图，量化每一步的质量，并据此分配优势，从而实现更细粒度的优势分配，该分配仅从结果奖励中获得。SALT设计为即插即用模块，可与现有的群组RL算法无缝集成，无需修改回滚程序，计算开销可忽略不计。

Result: 在WebShop、ALFWorld和AppWorld基准测试中，使用各种模型尺寸进行了广泛的实验，结果表明SALT始终能提高性能。此外，还进行了彻底的分析，以验证SALT的设计选择并提供可操作的见解。

Conclusion: 本文提出的SALT框架能够有效解决LLM在处理复杂多步任务时，现有RL方法（尤其是GRPO）面临的挑战，通过更细粒度的优势分配提高了模型性能，并且易于集成和扩展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
enabling language agents to excel at single-turn tasks. However, their
application to complex, multi-step, and long-horizon tasks remains challenging.
While reinforcement learning (RL) offers a promising avenue for addressing
these challenges, mainstream approaches typically rely solely on sparse,
outcome-based rewards, a limitation that becomes especially problematic for
group-based RL algorithms lacking critic models, such as Group Relative Policy
Optimization (GRPO). In such methods, uniformly rewarding or penalizing all
actions within a trajectory can lead to training instability and suboptimal
policies, because beneficial and detrimental actions are often entangled across
multi-step interactions. To address this challenge, we propose SALT, a novel
and lightweight framework that provides a finer-grained advantage assignment,
derived solely from outcome rewards. We achieve this by constructing a graph
from trajectories of the same prompt, which allows us to quantify the quality
of each step and assign advantages accordingly. Crucially, SALT is designed as
a plug-and-play module that seamlessly integrates with existing group-based RL
algorithms, requiring no modifications to the rollout procedure and introducing
negligible computational overhead. Extensive experiments on the WebShop,
ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that
SALT consistently improves performance. We also conduct a thorough analysis to
validate the design choices behind SALT and offer actionable insights.

</details>


### [241] [The Temporal Graph of Bitcoin Transactions](https://arxiv.org/abs/2510.20028)
*Vahid Jalili*

Main category: cs.LG

TL;DR: 该论文构建了一个比特币经济拓扑的机器学习兼容图，解决了现有数据难以用于机器学习研究的问题。


<details>
  <summary>Details</summary>
Motivation: 比特币网络交易数据丰富，但其假名和UTXO模型阻碍了机器学习研究，因此需要构建一个机器学习兼容的图模型来解决这个问题。

Method: 通过重构资金流动，构建了一个包含比特币全部交易历史（截至block 	ext{<cutoffheight>}）的时间异构图，该图拥有超过24亿节点和397.2亿条边。同时提供了采样方法、加载和分析工具以及数据库快照。

Result: 提供了一个全面的数据集和工具集，可用于机器学习研究，如异常检测、地址分类、市场分析和大规模图机器学习基准测试。

Conclusion: 该数据集和工具集将赋能机器学习界，使其能够大规模地处理复杂的比特币生态系统，从而推动相关应用的发展。

Abstract: Since its 2009 genesis block, the Bitcoin network has processed \num{>1.08}
billion (B) transactions representing \num{>8.72}B BTC, offering rich potential
for machine learning (ML); yet, its pseudonymity and obscured flow of funds
inherent in its \utxo-based design, have rendered this data largely
inaccessible for ML research. Addressing this gap, we present an ML-compatible
graph modeling the Bitcoin's economic topology by reconstructing the flow of
funds. This temporal, heterogeneous graph encompasses complete transaction
history up to block \cutoffHeight, consisting of \num{>2.4}B nodes and
\num{>39.72}B edges. Additionally, we provide custom sampling methods yielding
node and edge feature vectors of sampled communities, tools to load and analyze
the Bitcoin graph data within specialized graph databases, and ready-to-use
database snapshots. This comprehensive dataset and toolkit empower the ML
community to tackle Bitcoin's intricate ecosystem at scale, driving progress in
applications such as anomaly detection, address classification, market
analysis, and large-scale graph ML benchmarking. Dataset and code available at
\href{https://github.com/B1AAB/EBA}{github.com/b1aab/eba}

</details>


### [242] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 提出了一种基于拒绝采样的算法，可对现有时间点过程（TPP）模型进行并行采样，无需修改模型结构或重新训练，并实现了经验性加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在生成事件序列时效率低下，因为它们是顺序生成的，限制了并行处理能力。

Method: 提出了一种基于拒绝采样的算法，可以直接从现有TPP模型中并行精确采样多个未来值，而无需进行任何架构更改或重新训练。

Result: 该算法在理论上具有保证，并在实际数据集上实现了经验性加速，缩小了表达性建模和大规模TPP应用的高效并行生成之间的差距。

Conclusion: 所提出的基于拒绝采样的算法能够高效地并行生成TPP模型，解决了现有方法的效率限制，并为大规模TPP应用提供了实际解决方案。

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [243] [Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards](https://arxiv.org/abs/2510.20055)
*Yuwei Cheng,Zifeng Zhao,Haifeng Xu*

Main category: cs.LG

TL;DR: 该研究提出了一种结合延迟和长期效应、累积效应以及用户异质性的在线广告竞价模型，并设计了相应的强化学习算法来优化竞价策略。


<details>
  <summary>Details</summary>
Motivation: 现有在线广告竞价研究未能同时考虑延迟/长期效应、累积效应和用户异质性这三个关键因素。

Method: 将广告竞价建模为具有延迟泊松奖励的上下文马尔可夫决策过程（CMDP），并提出了一种两阶段最大似然估计器结合数据划分策略来处理这些效应，同时设计了一种强化学习算法来获得个性化竞价策略。

Result: 所提出的方法实现了近乎最优的遗憾界限 $	ilde{O}{(dH^2	ext{sqrt}{T})}$，并通过模拟实验得到了验证。

Conclusion: 该研究成功地将延迟/长期效应、累积效应和用户异质性纳入在线广告竞价模型，并通过提出的算法在理论和实践上都证明了其有效性。

Abstract: Online advertising platforms use automated auctions to connect advertisers
with potential customers, requiring effective bidding strategies to maximize
profits. Accurate ad impact estimation requires considering three key factors:
delayed and long-term effects, cumulative ad impacts such as reinforcement or
fatigue, and customer heterogeneity. However, these effects are often not
jointly addressed in previous studies. To capture these factors, we model ad
bidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson
rewards. For efficient estimation, we propose a two-stage maximum likelihood
estimator combined with data-splitting strategies, ensuring controlled
estimation error based on the first-stage estimator's (in)accuracy. Building on
this, we design a reinforcement learning algorithm to derive efficient
personalized bidding strategies. This approach achieves a near-optimal regret
bound of $\tilde{O}{(dH^2\sqrt{T})}$, where $d$ is the contextual dimension,
$H$ is the number of rounds, and $T$ is the number of customers. Our
theoretical findings are validated by simulation experiments.

</details>


### [244] [Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs](https://arxiv.org/abs/2510.20064)
*Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于投机解码的在线草稿模型选择算法，该算法能够证明在每次查询时，与事后诸葛亮的最佳草稿模型竞争，无论是在令牌接受概率还是期望接受长度方面。我们设计了一种可以准确评估所有草稿模型的方法，而无需对目标模型进行额外的查询，这使得我们能够随着草稿模型数量的增加，在现有基于 bandit 的方法上实现指数级提升。


<details>
  <summary>Details</summary>
Motivation: 在线草稿模型选择问题，旨在提高投机解码的效率。

Method: 设计了一种能够准确评估所有草稿模型的方法，并将其应用于任何投机解码方法，同时设计了系统高效的在线学习器版本。

Result: 该方法在评估所有草稿模型方面优于现有方法，并且计算和延迟开销显著降低。在与 EAGLE3 和 BanditSpec 基线的广泛实验中，该方法在各种领域，特别是在需要长推理链的情况下，表现优于最先进的方法。

Conclusion: 本文提出的算法在投机解码的在线草稿模型选择问题上取得了显著的进展，提高了效率和性能。

Abstract: Speculative decoding is widely used in accelerating large language model
(LLM) inference. In this work, we focus on the online draft model selection
problem in speculative decoding. We design an algorithm that provably competes
with the best draft model in hindsight for each query in terms of either the
token acceptance probability or expected acceptance length. In particular, we
show that we can accurately evaluate all draft models, instead of only the
chosen model without incurring additional queries to the target model, which
allows us to improve exponentially over the existing bandit-based approach as
the number of draft models increases. Our approach is generically applicable
with any speculative decoding methods (single draft, multi-drafts and
draft-trees). Moreover, we design system-efficient versions of online learners
and demonstrate that the overhead in computation and latency can be
substantially reduced. We conduct extensive experiments on open-source LLMs and
diverse datasets, demonstrating that our methods substantially outperform the
state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains
where specialized domain-expert drafters are available, especially when long
reasoning chains are required.

</details>


### [245] [A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers](https://arxiv.org/abs/2510.20066)
*Yimeng Qiu,Feihuang Fang*

Main category: cs.LG

TL;DR: 加密资产的流动性和波动性溢出可以预测市场风险，但预测准确性适中。


<details>
  <summary>Details</summary>
Motivation: 研究核心加密资产的流动性和波动性指标是否会产生预测市场整体风险的溢出效应。

Method: 结合了三个统计层次：(A) 核心流动性与收益率的交互作用，(B) 连接流动性与收益率的主成分关系，(C) 捕捉跨截面波动性聚集的波动性因子预测。此外，还使用了向量自回归脉冲响应、预测误差方差分解、异质自回归模型（HAR-X）以及基于时间分割、提前停止、仅验证阈值和SHAP解释的机器学习协议。

Result: 在2021年至2025年的每日数据（74个资产，1462个观测值）上，发现了具有统计显著性的跨层次的格兰杰因果关系，以及适度的样本外预测准确性。

Conclusion: 加密资产的流动性和波动性溢出对市场风险具有一定的预测能力，但预测准确性适中。

Abstract: We study whether liquidity and volatility proxies of a core set of
cryptoassets generate spillovers that forecast market-wide risk. Our empirical
framework integrates three statistical layers: (A) interactions between core
liquidity and returns, (B) principal-component relations linking liquidity and
returns, and (C) volatility-factor projections that capture cross-sectional
volatility crowding. The analysis is complemented by vector autoregression
impulse responses and forecast error variance decompositions (see Granger 1969;
Sims 1980), heterogeneous autoregressive models with exogenous regressors
(HAR-X, Corsi 2009), and a leakage-safe machine learning protocol using
temporal splits, early stopping, validation-only thresholding, and SHAP-based
interpretation. Using daily data from 2021 to 2025 (1462 observations across 74
assets), we document statistically significant Granger-causal relationships
across layers and moderate out-of-sample predictive accuracy. We report the
most informative figures, including the pipeline overview, Layer A heatmap,
Layer C robustness analysis, vector autoregression variance decompositions, and
the test-set precision-recall curve. Full data and figure outputs are provided
in the artifact repository.

</details>


### [246] [Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts](https://arxiv.org/abs/2510.20666)
*Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas*

Main category: cs.LG

TL;DR: 本文提出了一种结合物理路径损耗模型和卷积神经网络的混合贝叶斯模型，用于在城市环境中进行GNSS信号干扰定位和接收信号强度场重建，实验表明该方法提高了定位精度并能有效估计不确定性。


<details>
  <summary>Details</summary>
Motivation: 以往的GNSS信号干扰定位方法在城市环境中由于信号失真而定位精度不高，且难以重建接收信号强度场。

Method: 提出一种混合贝叶斯模型，结合了物理路径损耗模型和卷积神经网络，并使用对数线性池化进行融合。利用建筑高度图来捕捉城市传播效应，并通过贝叶斯推断（拉普拉斯近似）来估计干扰源位置和信号强度场的不确定性。

Result: 在城市光线追踪数据上进行实验，结果表明，随着训练点增加，定位精度提高，不确定性降低。不确定性集中在干扰源附近以及城市峡谷等传播敏感区域。

Conclusion: 所提出的混合贝叶斯模型在城市GNSS信号干扰定位和信号强度场重建方面优于现有方法，并且能够提供有意义的不确定性估计。

Abstract: Global Navigation Satellite System (GNSS) signals are vulnerable to jamming,
particularly in urban areas where multipath and shadowing distort received
power. Previous data-driven approaches achieved reasonable localization but
poorly reconstructed the received signal strength (RSS) field due to limited
spatial context. We propose a hybrid Bayesian mixture-of-experts framework that
fuses a physical path-loss (PL) model and a convolutional neural network (CNN)
through log-linear pooling. The PL expert ensures physical consistency, while
the CNN leverages building-height maps to capture urban propagation effects.
Bayesian inference with Laplace approximation provides posterior uncertainty
over both the jammer position and RSS field. Experiments on urban ray-tracing
data show that localization accuracy improves and uncertainty decreases with
more training points, while uncertainty concentrates near the jammer and along
urban canyons where propagation is most sensitive.

</details>


### [247] [Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics](https://arxiv.org/abs/2510.20068)
*Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne*

Main category: cs.LG

TL;DR: CTAE模型可以同时分离和分析跨多个大脑区域的共享和私有神经动力学，并能更好地解码行为变量。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐或多视图方法忽略了时间结构，而动力学潜在变量模型通常只限制在单个区域，假设线性读出，或混淆共享和私有信号。本研究旨在解决这些问题。

Method: CTAE利用Transformer编码器和解码器来捕捉长程神经动力学，并将每个区域的潜在空间显式划分为正交的共享和私有子空间。

Result: CTAE在两个高密度电生理数据集上表现出有效性，提取的有意义的表征比现有方法能更好地解码行为变量。

Conclusion: CTAE提供了一个单一框架，能够同时处理非平稳、非线性动力学以及共享与区域特异性结构的分离。

Abstract: Simultaneous recordings from thousands of neurons across multiple brain areas
reveal rich mixtures of activity that are shared between regions and dynamics
that are unique to each region. Existing alignment or multi-view methods
neglect temporal structure, whereas dynamical latent variable models capture
temporal dependencies but are usually restricted to a single area, assume
linear read-outs, or conflate shared and private signals. We introduce the
Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both
(i) non-stationary, non-linear dynamics and (ii) separation of shared versus
region-specific structure in a single framework. CTAE employs transformer
encoders and decoders to capture long-range neural dynamics and explicitly
partitions each region's latent space into orthogonal shared and private
subspaces. We demonstrate the effectiveness of CTAE on two high-density
electrophysiology datasets with simultaneous recordings from multiple regions,
one from motor cortical areas and the other from sensory areas. CTAE extracts
meaningful representations that better decode behavioral variables compared to
existing approaches.

</details>


### [248] [ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models](https://arxiv.org/abs/2510.20084)
*Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan*

Main category: cs.LG

TL;DR: ShapeX框架通过识别和评估时间序列中的关键子序列（shapelets）来改进时间序列分类的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列解释方法主要关注时间步级别的归因，忽略了由关键shapelets驱动的分类结果，而shapelets是时间序列分类的核心特征。

Method: ShapeX框架首先使用Shapelet Describe-and-Detect (SDD) 学习一组有代表性的shapelets，然后将时间序列分割成由这些shapelets驱动的片段，并使用Shapley值评估其重要性。

Result: ShapeX在合成和真实世界数据集上的实验结果表明，与现有方法相比，它能更精确地识别相关子序列，提高了时间序列解释的精确度和因果保真度。

Conclusion: ShapeX通过关注shapelets，能够提供比现有方法更精确、更具因果关系的时间序列解释。

Abstract: Explaining time series classification models is crucial, particularly in
high-stakes applications such as healthcare and finance, where transparency and
trust play a critical role. Although numerous time series classification
methods have identified key subsequences, known as shapelets, as core features
for achieving state-of-the-art performance and validating their pivotal role in
classification outcomes, existing post-hoc time series explanation (PHTSE)
methods primarily focus on timestep-level feature attribution. These
explanation methods overlook the fundamental prior that classification outcomes
are predominantly driven by key shapelets. To bridge this gap, we present
ShapeX, an innovative framework that segments time series into meaningful
shapelet-driven segments and employs Shapley values to assess their saliency.
At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,
which effectively learns a diverse set of shapelets essential for
classification. We further demonstrate that ShapeX produces explanations which
reveal causal relationships instead of just correlations, owing to the
atomicity properties of shapelets. Experimental results on both synthetic and
real-world datasets demonstrate that ShapeX outperforms existing methods in
identifying the most relevant subsequences, enhancing both the precision and
causal fidelity of time series explanations.

</details>


### [249] [Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa](https://arxiv.org/abs/2510.20085)
*Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种基于MentalRoBERTa的分层双头神经网络，用于将自杀风险分为四个级别（指标、意念、行为、企图），通过CORAL和标准分类头来处理有序和分类的风险特征，并利用Transformer和时间嵌入来捕捉发帖模式的时间动态。


<details>
  <summary>Details</summary>
Motivation: 现有自动检测系统在处理社交媒体上的自杀风险时面临类别不平衡、时间复杂性和风险等级的多重性质（有序和分类）等挑战。

Method: 提出了一种基于MentalRoBERTa的分层双头神经网络。其中，CORAL（Consistent Rank Logits）头保留风险等级间的有序关系，标准分类头实现灵活的分类区分。模型使用3层Transformer编码器和8头多头注意力来建模帖子序列的时间依赖性，并引入时间间隔嵌入来捕捉发帖行为动态。为提高计算效率，冻结了MentalRoBERTa的前6层，并采用混合精度训练。

Result: 模型使用了一个结合的损失函数（0.5 CORAL + 0.3 交叉熵 + 0.2 Focal Loss）进行训练，该损失函数同时处理了有序结构保持、降低模型过度自信以及类别不平衡的问题。通过5折分层交叉验证进行评估，主要评估指标为宏观F1分数。

Conclusion: 该模型通过结合有序和分类的预测方法，并有效处理时间动态和类别不平衡问题，为社交媒体上的自杀风险检测提供了一个更精确、更鲁棒的解决方案。

Abstract: Social media platforms have become important sources for identifying suicide
risk, but automated detection systems face multiple challenges including severe
class imbalance, temporal complexity in posting patterns, and the dual nature
of risk levels as both ordinal and categorical. This paper proposes a
hierarchical dual-head neural network based on MentalRoBERTa for suicide risk
classification into four levels: indicator, ideation, behavior, and attempt.
The model employs two complementary prediction heads operating on a shared
sequence representation: a CORAL (Consistent Rank Logits) head that preserves
ordinal relationships between risk levels, and a standard classification head
that enables flexible categorical distinctions. A 3-layer Transformer encoder
with 8-head multi-head attention models temporal dependencies across post
sequences, while explicit time interval embeddings capture posting behavior
dynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3
Cross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure
preservation, overconfidence reduction, and class imbalance. To improve
computational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa
and employ mixed-precision training. The model is evaluated using 5-fold
stratified cross-validation with macro F1 score as the primary metric.

</details>


### [250] [Competition is the key: A Game Theoretic Causal Discovery Approach](https://arxiv.org/abs/2510.20106)
*Amartya Roy,Souvik Chakraborty*

Main category: cs.LG

TL;DR: 提出了一种基于博弈论强化学习的因果发现新框架，在理论和实践上均取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法在经验性能和有限样本保证之间存在差距：一些表现好的算法缺乏理论保证，而一些理论上可靠的算法则难以扩展。本研究旨在弥合这一差距。

Method: 采用博弈论强化学习框架，训练一个DDQN智能体与现有基线算法（GES或GraN-DAG）进行竞争，并从对手的解决方案进行热启动。

Result: 该方法获得了三个可证明的保证：学习到的图不差于对手，热启动加速了收敛，并且有很大概率选择了真正最佳的候选图。在合成数据集和真实世界基准测试中，该方法均优于现有方法，并能扩展到具有220个节点的大型图。

Conclusion: 这项工作提出了一类新的基于强化学习的因果发现算法，它们同时具有可证明的一致性、样本效率和实际可扩展性，朝着统一经验性能和严格的有限样本理论迈出了重要一步。

Abstract: Causal discovery remains a central challenge in machine learning, yet
existing methods face a fundamental gap: algorithms like GES and GraN-DAG
achieve strong empirical performance but lack finite-sample guarantees, while
theoretically principled approaches fail to scale. We close this gap by
introducing a game-theoretic reinforcement learning framework for causal
discovery, where a DDQN agent directly competes against a strong baseline (GES
or GraN-DAG), always warm-starting from the opponent's solution. This design
yields three provable guarantees: the learned graph is never worse than the
opponent, warm-starting strictly accelerates convergence, and most importantly,
with high probability the algorithm selects the true best candidate graph. To
the best of our knowledge, our result makes a first-of-its-kind progress in
explaining such finite-sample guarantees in causal discovery: on synthetic SEMs
(30 nodes), the observed error probability decays with n, tightly matching
theory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,
Dream, and Andes, our method consistently improves upon GES and GraN-DAG while
remaining theoretically safe. Remarkably, it scales to large graphs such as
Hepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these
results establish a new class of RL-based causal discovery algorithms that are
simultaneously provably consistent, sample-efficient, and practically scalable,
marking a decisive step toward unifying empirical performance with rigorous
finite-sample theory.

</details>


### [251] [On pattern classification with weighted dimensions](https://arxiv.org/abs/2510.20107)
*Ayatullah Faruk Mollah*

Main category: cs.LG

TL;DR: 该研究提出了一种新的加权KNN分类器，用于处理高维多维数据，并在基因表达数据集上提高了约10%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 在处理多维样本和多样化应用场景时，模式分类的研究至关重要。加权降维距离度量在模式分析中是关键，但传统的欧氏距离存在许多问题。

Method: 提出了一种新的维度加权方案，并将其集成到KNN分类器中，然后在一系列合成和真实数据集上进行模式分类。

Result: 所提出的加权KNN分类器在各种实验中表现优于传统的KNN分类器，特别是在基因表达数据集上，分类准确率提高了约10%。

Conclusion: 该研究提出了一种加权KNN分类器的重要推广，该分类器由加权闵可夫斯基距离和提出的加权方案提供支持，能够有效处理高维数据集。

Abstract: Studies on various facets of pattern classification is often imperative while
working with multi-dimensional samples pertaining to diverse application
scenarios. In this notion, weighted dimension-based distance measure has been
one of the vital considerations in pattern analysis as it reflects the degree
of similarity between samples. Though it is often presumed to be settled with
the pervasive use of Euclidean distance, plethora of issues often surface. In
this paper, we present (a) a detail analysis on the impact of distance measure
norms and weights of dimensions along with visualization, (b) a novel weighting
scheme for each dimension, (c) incorporation of this dimensional weighting
schema into a KNN classifier, and (d) pattern classification on a variety of
synthetic as well as realistic datasets with the developed model. It has
performed well across diverse experiments in comparison to the traditional KNN
under the same experimental setups. Specifically, for gene expression datasets,
it yields significant and consistent gain in classification accuracy (around
10%) in all cross-validation experiments with different values of k. As such
datasets contain limited number of samples of high dimensions, meaningful
selection of nearest neighbours is desirable, and this requirement is
reasonably met by regulating the shape and size of the region enclosing the k
number of reference samples with the developed weighting schema and appropriate
norm. It, therefore, stands as an important generalization of KNN classifier
powered by weighted Minkowski distance with the present weighting schema.

</details>


### [252] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 自监督学习中的原型坍塌问题通过解耦训练策略得到解决，该策略将原型和编码器的优化分开，使用高斯混合模型更新原型，从而实现更强的下游性能。


<details>
  <summary>Details</summary>
Motivation: 解决自监督学习中原型坍塌（多个原型收敛到相似表示）的问题，该问题削弱了原型提供多样化和信息性目标的作用，并导致了不必要的模型过参数化或正则化。

Method: 提出一种完全解耦的训练策略，将原型和编码器的优化目标分开。具体来说，原型被建模为高斯混合模型，并使用在线期望最大化（EM）风格的过程进行更新，独立于编码器的损失函数。

Result: 解耦训练策略消除了原型坍塌，无需显式正则化，生成了始终保持多样性的原型，并在下游任务中取得了更强的性能。

Conclusion: 提出的解耦训练策略能够有效解决自监督学习中的原型坍塌问题，通过独立优化原型和编码器，提高了表示的多样性，并提升了下游任务的性能。

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [253] [There is No "apple" in Timeseries: Rethinking TSFM through the Lens of Invariance](https://arxiv.org/abs/2510.20119)
*Arian Prabowo,Flora D. Salim*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFM）虽然数量众多，但往往被简单的监督基线模型甚至经典模型超越。这是因为直接套用自然语言处理（NLP）或计算机视觉（CV）的流水线到时间序列数据上并不奏效，因为与包含海量“苹果”图像和文本的网络语料库不同，时间序列数据缺乏对现实世界概念的密集覆盖。作者提出，未来的进展需要从“抓取一切”转向“原则性设计”，构建能够系统性覆盖时间序列不变性并保持时间语义的数据集。为此，建议基于基本原理构建时间序列不变性的本体，确保表征的完整性，才能使TSFM实现泛化、推理和真正涌现行为所需的对齐结构。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFM）在性能上往往逊于轻量级监督基线模型和经典模型，其原因在于直接套用自然语言处理（NLP）或计算机视觉（CV）的流水线。这主要是因为自然语言和视觉数据在网络上密集分布，包含了丰富的概念（如“苹果”），而时间序列数据缺乏这种特性，无法通过“抓取一切”的方式构建包含现实世界概念的数据集。

Method: 作者提出，时间序列基础模型的发展需要从机会主义的数据聚合转向原则性的设计。具体来说，应该基于基本原理构建时间序列不变性的本体，确保数据集能够系统性地覆盖时间序列的不变性空间，并在此过程中保持时间语义。

Result: 通过确保表示的完整性，覆盖不变性，时间序列基础模型（TSFM）可以实现对齐的结构，这是泛化、推理和真正涌现行为的关键。

Conclusion: 时间序列基础模型（TSFM）要取得突破，关键在于改变数据策略，从“抓取一切”转变为“原则性设计”，构建能够系统性覆盖时间序列不变性并保持时间语义的数据集。只有这样，TSFM才能具备泛化、推理和涌现行为所需的基础。

Abstract: Timeseries foundation models (TSFMs) have multiplied, yet lightweight
supervised baselines and even classical models often match them. We argue this
gap stems from the naive importation of NLP or CV pipelines. In language and
vision, large web-scale corpora densely capture human concepts i.e. there are
countless images and text of apples. In contrast, timeseries data is built to
complement the image and text modalities. There are no timeseries dataset that
contains the concept apple. As a result, the scrape-everything-online paradigm
fails for TS. We posit that progress demands a shift from opportunistic
aggregation to principled design: constructing datasets that systematically
span the space of invariance that preserve temporal semantics. To this end, we
suggest that the ontology of timeseries invariances should be built based on
first principles. Only by ensuring representational completeness through
invariance coverage can TSFMs achieve the aligned structure necessary for
generalisation, reasoning, and truly emergent behaviour.

</details>


### [254] [Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling](https://arxiv.org/abs/2510.20148)
*Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu*

Main category: cs.LG

TL;DR:  tau蛋白在阿尔茨海默病（AD）中沿着特定脑网络扩散，本研究利用多层图扩散模型，结合结构连通性（SC）和功能连通性（FC）数据，揭示了它们在 tau 扩散中的相互作用及其区域和疾病阶段的特异性，并与基因表达和风险因素相关联。


<details>
  <summary>Details</summary>
Motivation: 虽然现有证据表明 tau 蛋白在脑网络中的积累是阿尔茨海默病（AD）进展的关键，但结构连通性（SC）和功能连通性（FC）之间如何相互作用以影响 tau 传播尚不清楚。

Method: 研究人员利用了大量的纵向神经影像数据，并采用了一个多层图扩散模型来检查 SC 和 FC 的相互作用。

Result: 研究发现，连接组的结构确实限制了 tau 的扩散。模型揭示了 SC 和 FC 对 tau 扩散的贡献存在区域不对称性：FC 在内侧皮质、前额叶和颞叶皮层等区域起主导作用，而 SC 在枕叶、顶叶和边缘区域起主导作用。SC 和 FC 的相对主导地位随着疾病阶段而变化，在早期 AD 中 FC 更占优势，在后期 AD 中 SC 更占优势。SC 和 FC 的空间模式与 AD 相关基因（如 CHUK、TMEM106B、MCL1、NOTCH1 和 TH）在炎症、细胞凋亡和溶酶体功能方面的区域表达高度一致。此外，APOE 基因型和性别等其他不可控风险因素以及淀粉样蛋白沉积等生物机制，通过区域特异性的方式改变解剖和功能通路之间的主导路线，从而选择性地重塑 tau 传播。研究结果在一个独立的 AD 队列中得到了验证。

Conclusion: SC 和 FC 的相互作用以及它们在 tau 扩散中的区域和疾病阶段特异性作用，为理解 AD 的传播机制提供了新的见解，并可能为开发靶向治疗提供依据。

Abstract: Emerging neuroimaging evidence shows that pathological tau proteins build up
along specific brain networks, suggesting that large-scale network architecture
plays a key role in the progression of Alzheimer's disease (AD). However, how
structural connectivity (SC) and functional connectivity (FC) interact to
influence tau propagation remains unclear. Leveraging an unprecedented volume
of longitudinal neuroimaging data, we examine SC-FC interactions through a
multi-layer graph diffusion model. Beyond showing that connectome architecture
constrains tau spread, our model reveals a regionally asymmetric contribution
of SC and FC. Specifically, FC predominantly drives tau spread in subcortical
areas, the insula, frontal and temporal cortices, whereas SC plays a larger
role in occipital, parietal, and limbic regions. The relative dominance of SC
versus FC shifts over the course of disease, with FC generally prevailing in
early AD and SC becoming primary in later stages. Spatial patterns of SC- and
FC-dominant regions strongly align with the regional expression of
AD-associated genes involved in inflammation, apoptosis, and lysosomal
function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In
parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and
biological mechanisms (e.g., amyloid deposition) selectively reshape tau
propagation by shifting dominant routes between anatomical and functional
pathways in a region-specific manner. Findings are validated in an independent
AD cohort.

</details>


### [255] [Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP](https://arxiv.org/abs/2510.20169)
*Tongkai Lu,Shuai Ma,Chongyang Tao*

Main category: cs.LG

TL;DR: 提出一种新的旅行商问题（TSP）求解方法HyperNS，通过聚类和超节点来减少搜索空间，提高大规模实例的求解效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的TSP求解方法在处理大规模实例时面临内存限制和全局引导不足的挑战。

Method: HyperNS方法首先使用稀疏热图图将TSP实例聚类成超节点，然后生成一个超 tour 来指导初始化和优化过程，从而聚焦于与超 tour 相关的边。

Result: 在合成和真实世界数据集上的实验结果表明，HyperNS在处理大规模实例时优于现有的基于神经网络的方法，并显著缩小了与最优解的差距。

Conclusion: HyperNS方法能够有效解决大规模TSP实例，提供比现有神经方法更好的性能。

Abstract: Traveling Salesman Problem (TSP) is a classic NP-hard problem that has
garnered significant attention from both academia and industry. While
neural-based methods have shown promise for solving TSPs, they still face
challenges in scaling to larger instances, particularly in memory constraints
associated with global heatmaps, edge weights, or access matrices, as well as
in generating high-quality initial solutions and insufficient global guidance
for efficiently navigating vast search spaces. To address these challenges, we
propose a Hyper Tour Guided Neighborhood Search (HyperNS) method for
large-scale TSP instances. Inspired by the ``clustering first, route second"
strategy, our approach initially divides the TSP instance into clusters using a
sparse heatmap graph and abstracts them as supernodes, followed by the
generation of a hyper tour to guide both the initialization and optimization
processes. This method reduces the search space by focusing on edges relevant
to the hyper tour, leading to more efficient and effective optimization.
Experimental results on both synthetic and real-world datasets demonstrate that
our approach outperforms existing neural-based methods, particularly in
handling larger-scale instances, offering a significant reduction in the gap to
the optimal solution.

</details>


### [256] [Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values](https://arxiv.org/abs/2510.20187)
*Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: RL EV 将人类价值信号直接整合到LLM的优化过程中，通过包含价值信号的奖励函数，提高了模型在各种任务上的表现，并学习到了对不同价值提示采取不同详细程度的策略。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法（如RLVR）在处理客观领域时有效，但忽略了并非所有任务都具有同等重要性，因此需要一种能够直接整合人类价值信号的方法来优化LLM。

Method: RL EV将人类定义的价值信号直接纳入奖励函数，并使用带有明确ground-truth价值标签的考试风格数据进行训练。通过分析end-of-sequence token上的价值加权梯度放大来解释模型学习到的价值敏感策略。

Result: RL EV在多项RL算法和模型规模上持续优于仅关注正确性的基线模型。RL EV策略不仅提高了价值加权准确性，还学会了根据提示的价值来决定回答的详略程度（低价值提示回答简洁，高价值提示回答详尽）。

Conclusion: RL EV通过优化明确的效用函数，为使LLM与人类优先事项保持一致提供了一条实用的途径，即使在价值信号存在噪声（如基于难度的标签）的情况下也表现出鲁棒性。

Abstract: We propose Reinforcement Learning with Explicit Human Values (RLEV), a method
that aligns Large Language Model (LLM) optimization directly with quantifiable
human value signals. While Reinforcement Learning with Verifiable Rewards
(RLVR) effectively trains models in objective domains using binary correctness
rewards, it overlooks that not all tasks are equally significant. RLEV extends
this framework by incorporating human-defined value signals directly into the
reward function. Using exam-style data with explicit ground-truth value labels,
RLEV consistently outperforms correctness-only baselines across multiple RL
algorithms and model scales. Crucially, RLEV policies not only improve
value-weighted accuracy but also learn a value-sensitive termination policy:
concise for low-value prompts, thorough for high-value ones. We demonstrate
this behavior stems from value-weighted gradient amplification on
end-of-sequence tokens. Ablation studies confirm the gain is causally linked to
value alignment. RLEV remains robust under noisy value signals, such as
difficulty-based labels, demonstrating that optimizing for an explicit utility
function offers a practical path to aligning LLMs with human priorities.

</details>


### [257] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 该研究提出了一种风险感知约束强化学习框架，使用优化的确定性等价物（OCEs）来解决传统方法忽略高风险事件的问题，并能在奖励和时间上实现阶段性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中的约束优化方法通常基于期望累积奖励，忽略了奖励分布尾部的风险事件，这在高风险应用中是不足够的。

Method: 提出了一种风险感知约束强化学习框架，利用优化的确定性等价物（OCEs）在奖励和时间上实现阶段性鲁棒性，该框架在强拉格朗日对偶框架下与原始约束问题精确等价，并可应用于PPO等标准强化学习求解器。

Result: 该框架能够精确地等价于原始约束问题，并提出了一种简单的算法，可以包装标准的强化学习求解器。通过数值实验验证了其风险感知特性。

Conclusion: 所提出的框架能够实现风险感知约束强化学习，并在算法收敛性和风险规避方面得到理论和实验的验证。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [258] [Approximate Replicability in Learning](https://arxiv.org/abs/2510.20200)
*Max Hopkins,Russell Impagliazzo,Christopher Ye*

Main category: cs.LG

TL;DR: Replicability is a strong notion of algorithmic stability, but can be costly. This paper proposes three relaxations: pointwise, approximate, and semi-replicability. For constant replicability parameters, sample-optimal agnostic PAC learners are obtained for all three relaxations. Pointwise and approximate replicability are achieved for free, while semi-replicability requires additional labeled samples.


<details>
  <summary>Details</summary>
Motivation: The prohibitive cost of exact replicability in algorithms, as shown by impossibility results for simple tasks, motivates the exploration of approximate notions of replicability where learning might still be possible.

Method: The paper proposes three relaxed notions of replicability in the context of PAC learning: pointwise, approximate, and semi-replicability. It then provides sample-optimal agnostic PAC learners for each of these relaxations, analyzing the sample complexity required.

Result: Sample-optimal agnostic PAC learners were obtained for all three proposed relaxations of replicability (pointwise, approximate, and semi) for constant replicability parameters. Specifically, pointwise and approximate replicability were achieved with $\Theta(d/\alpha^2)$ samples, while semi-replicability required $\Theta(d^2/\alpha^2)$ labeled samples.

Conclusion: The paper successfully demonstrates that by relaxing the strict notion of replicability to pointwise, approximate, or semi-replicability, it becomes possible to achieve sample-optimal agnostic PAC learning, overcoming the limitations of exact replicability.

Abstract: Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion
that algorithms should remain stable under a resampling of their inputs (given
access to shared randomness). While a strong and interesting notion of
stability, the cost of replicability can be prohibitive: there is no replicable
algorithm, for instance, for tasks as simple as threshold learning (Bun et al.
STOC '23). Given such strong impossibility results we ask: under what
approximate notions of replicability is learning possible?
  In this work, we propose three natural relaxations of replicability in the
context of PAC learning: (1) Pointwise: the learner must be consistent on any
fixed input, but not across all inputs simultaneously, (2) Approximate: the
learner must output hypotheses that classify most of the distribution
consistently, (3) Semi: the algorithm is fully replicable, but may additionally
use shared unlabeled samples. In all three cases, for constant replicability
parameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are
achievable for ``free" using $\Theta(d/\alpha^2)$ samples, while (3) requires
$\Theta(d^2/\alpha^2)$ labeled samples.

</details>


### [259] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 使用机器学习识别犬类癌症的早期迹象，但结果表明，尽管存在统计学上的癌症信号，但其信号过于微弱，无法与正常衰老或炎症区分开来，需要多模式数据。


<details>
  <summary>Details</summary>
Motivation: 开发可及的癌症早期筛查工具，利用低成本的常规实验室数据，但面临生物标志物非特异性和类别不平衡的挑战。

Method: 对126种不同的机器学习分析流程进行了基准测试，包括模型、特征选择和数据平衡技术，并进行患者级别的数据划分以防止数据泄露。

Result: 最优模型（加权逻辑回归和递归特征消除）在癌症风险分类方面表现出适度的排名能力（AUROC = 0.815），但临床分类性能不佳（F1值 = 0.25，阳性预测值 = 0.15），尽管阴性预测值很高（0.98），但召回率不足（0.79），无法作为可靠的排除测试。SHAP分析显示预测主要基于年龄、炎症和贫血等非特异性特征。

Conclusion: 常规实验室数据中存在可检测到的癌症信号，但过于微弱且受到干扰，无法与正常衰老或炎症区分开来，因此无法用于临床可靠的鉴别。需要整合多模式数据源才能在计算兽医肿瘤学方面取得有意义的进展。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [260] [CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks](https://arxiv.org/abs/2510.20219)
*Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu*

Main category: cs.LG

TL;DR: CO-PFL 算法通过动态评估客户端贡献来改进个性化联邦学习，解决了数据异构性和稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在客户端数据异构和稀疏的情况下，依赖单一的共识模型，其标准的聚合方法（按数据量加权）未能考虑客户端更新的实际效用和可靠性，导致个性化不佳和聚合偏差。CO-PFL 旨在克服这些限制。

Method: CO-PFL 算法通过联合分析梯度方向差异和预测偏差，利用梯度和数据子空间的信息，动态估计每个客户端对全局聚合的贡献度，从而得到更优的聚合权重。该算法还集成了参数化个性化机制和掩码感知动量优化，以增强个性化适应性和优化稳定性。

Result: CO-PFL 通过联合评估梯度和数据子空间信息，为每个客户端提供了一个原则性的、可区分的聚合权重，从而加权高质量的更新。结合参数化个性化和掩码感知动量优化，CO-PFL 缓解了聚合偏差，加强了全局协调，并通过促进定制化子模型的构建和稳定更新来提升了局部性能。

Conclusion: CO-PFL 在四个基准数据集（CIFAR10、CIFAR10C、CINIC10 和 Mini-ImageNet）上的大量实验证明，CO-PFL 在个性化准确性、鲁棒性、可扩展性和收敛稳定性方面始终优于最先进的方法。

Abstract: Personalized federated learning (PFL) addresses a critical challenge of
collaboratively training customized models for clients with heterogeneous and
scarce local data. Conventional federated learning, which relies on a single
consensus model, proves inadequate under such data heterogeneity. Its standard
aggregation method of weighting client updates heuristically or by data volume,
operates under an equal-contribution assumption, failing to account for the
actual utility and reliability of each client's update. This often results in
suboptimal personalization and aggregation bias. To overcome these limitations,
we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that
dynamically estimates each client's contribution for global aggregation. CO-PFL
performs a joint assessment by analyzing both gradient direction discrepancies
and prediction deviations, leveraging information from gradient and data
subspaces. This dual-subspace analysis provides a principled and discriminative
aggregation weight for each client, emphasizing high-quality updates.
Furthermore, to bolster personalization adaptability and optimization
stability, CO-PFL cohesively integrates a parameter-wise personalization
mechanism with mask-aware momentum optimization. Our approach effectively
mitigates aggregation bias, strengthens global coordination, and enhances local
performance by facilitating the construction of tailored submodels with stable
updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,
CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses
state-of-the-art methods in in personalization accuracy, robustness,
scalability and convergence stability.

</details>


### [261] [QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models](https://arxiv.org/abs/2510.20222)
*Hao Wang,Baojun Ma*

Main category: cs.LG

TL;DR: QKCV是一种增强时间序列预测的注意力机制，通过引入类别信息提高准确性，并能高效地微调基础模型。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测任务中，类别信息对于捕捉数据模式至关重要，但传统方法未能充分利用。

Method: 提出QKCV（Query-Key-Category-Value）注意力机制，在传统QKV框架中加入静态类别嵌入C，以强调类别信息。QKCV可作为插件模块，并用于微调基础模型。

Result: QKCV提高了Vanilla Transformer, Informer, PatchTST, TFT等模型在不同真实世界数据集上的预测准确性。在微调时间序列基础模型时，仅更新C即可获得更好的性能和更低的计算成本。

Conclusion: QKCV是一种有效且通用的时间序列预测方法，能够提升现有模型性能，并实现高效的基础模型微调。

Abstract: In real-world time series forecasting tasks, category information plays a
pivotal role in capturing inherent data patterns. This paper introduces QKCV
(Query-Key-Category-Value) attention, an extension of the traditional QKV
framework that incorporates a static categorical embedding C to emphasize
category-specific information. As a versatile plug-in module, QKCV enhances the
forecasting accuracy of attention-based models (e.g., Vanilla Transformer,
Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV
demonstrates remarkable adaptability in fine-tuning univariate time series
foundation model by solely updating the static embedding C while preserving
pretrained weights, thereby reducing computational overhead and achieving
superior fine-tuning performance.

</details>


### [262] [Federated Learning via Meta-Variational Dropout](https://arxiv.org/abs/2510.20225)
*Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim*

Main category: cs.LG

TL;DR: MetaVD是一种新的贝叶斯元学习方法，通过学习客户端特定的 dropout 率来解决联邦学习中数据有限和非IID的问题，提高了模型的准确性和不确定性校准性能，尤其对分布外客户端有效，并减少了通信成本。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）在实际应用中面临模型过拟合和本地模型分歧的挑战，尤其是在客户端数据有限且非独立同分布（non-IID）的情况下。本研究旨在解决这些问题，提高FL的有效性。

Method: 提出了一种名为元变分dropout（MetaVD）的新型贝叶斯元学习方法。MetaVD通过共享的超网络学习预测客户端特定的dropout率，从而在数据有限和非IID的FL设置中实现有效的模型个性化。该方法还通过条件dropout后验强调了元学习的后验适应视角和贝叶斯FL的后验聚合视角。

Result: 在各种稀疏和非IID的FL数据集上进行的大量实验表明，MetaVD在分类准确性和不确定性校准方面表现出色，特别是在处理分布外（OOD）客户端时。MetaVD还能压缩每个客户端所需的本地模型参数，从而缓解模型过拟合并降低通信成本。

Conclusion: MetaVD通过引入客户端特定的dropout率预测，有效解决了联邦学习中数据有限和非IID带来的挑战，显著提高了模型的性能和鲁棒性，并具有压缩模型和降低通信成本的优点。

Abstract: Federated Learning (FL) aims to train a global inference model from remotely
distributed clients, gaining popularity due to its benefit of improving data
privacy. However, traditional FL often faces challenges in practical
applications, including model overfitting and divergent local models due to
limited and non-IID data among clients. To address these issues, we introduce a
novel Bayesian meta-learning approach called meta-variational dropout (MetaVD).
MetaVD learns to predict client-dependent dropout rates via a shared
hypernetwork, enabling effective model personalization of FL algorithms in
limited non-IID data settings. We also emphasize the posterior adaptation view
of meta-learning and the posterior aggregation view of Bayesian FL via the
conditional dropout posterior. We conducted extensive experiments on various
sparse and non-IID FL datasets. MetaVD demonstrated excellent classification
accuracy and uncertainty calibration performance, especially for
out-of-distribution (OOD) clients. MetaVD compresses the local model parameters
needed for each client, mitigating model overfitting and reducing communication
costs. Code is available at https://github.com/insujeon/MetaVD.

</details>


### [263] [Sparse Local Implicit Image Function for sub-km Weather Downscaling](https://arxiv.org/abs/2510.20228)
*Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho*

Main category: cs.LG

TL;DR: SpLIIF模型能够从稀疏的气象站点和地形数据中生成隐式神经表示，并实现任意分辨率的天气变量降尺度，在温度和风的预测上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了生成隐式神经表示并实现任意分辨率的天气变量降尺度。

Method: 训练了一个模型，利用日本的气象站点和地形数据，并与插值基线和CorrDiff进行比较，以评估预测温度和风的分布内和分布外准确性。

Result: SpLIIF模型在降尺度温度方面比CorrDiff和基线模型好高达50%，在风的预测方面好10-20%。

Conclusion: SpLIIF在天气变量降尺度方面表现出优越的性能。

Abstract: We introduce SpLIIF to generate implicit neural representations and enable
arbitrary downscaling of weather variables. We train a model from sparse
weather stations and topography over Japan and evaluate in- and
out-of-distribution accuracy predicting temperature and wind, comparing it to
both an interpolation baseline and CorrDiff. We find the model to be up to 50%
better than both CorrDiff and the baseline at downscaling temperature, and
around 10-20% better for wind.

</details>


### [264] [Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach](https://arxiv.org/abs/2510.20235)
*Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung*

Main category: cs.LG

TL;DR: 本论文提出了一种可证明收敛且实用的最大最小（max-min）多目标强化学习框架，将问题重构为带正则化的双人零和连续对策，并提出了一种基于镜像下降的高效算法，该算法简化了策略更新并保证了全局最终迭代收敛性。


<details>
  <summary>Details</summary>
Motivation: 从博弈论的角度，将最大最小多目标强化学习（MORL）重构为双人零和正则化连续对策，以提出一种新的框架。

Method: 提出了一种基于镜像下降的高效算法，用于解决重构后的对策问题，该算法简化了策略更新并保证了全局最终迭代收敛性。对该算法进行了迭代复杂度和样本复杂度等方面的理论分析，并引入了自适应正则化以进一步提升性能。

Result: 在表格设置下验证了算法的收敛行为，并在深度强化学习的实验中，在多个MORL环境中显著优于现有基线方法。

Conclusion: 提出的框架和算法在最大最小多目标强化学习问题上具有理论保证和实际效果。

Abstract: In this paper, we propose a provably convergent and practical framework for
multi-objective reinforcement learning with max-min criterion. From a
game-theoretic perspective, we reformulate max-min multi-objective
reinforcement learning as a two-player zero-sum regularized continuous game and
introduce an efficient algorithm based on mirror descent. Our approach
simplifies the policy update while ensuring global last-iterate convergence. We
provide a comprehensive theoretical analysis on our algorithm, including
iteration complexity under both exact and approximate policy evaluations, as
well as sample complexity bounds. To further enhance performance, we modify the
proposed algorithm with adaptive regularization. Our experiments demonstrate
the convergence behavior of the proposed algorithm in tabular settings, and our
implementation for deep reinforcement learning significantly outperforms
previous baselines in many MORL environments.

</details>


### [265] [Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction](https://arxiv.org/abs/2510.20236)
*Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers*

Main category: cs.LG

TL;DR: LKM是一种新的自知识蒸馏方法，可以提高GNN在分子性质预测方面的准确性，同时增加的计算成本可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN模型在预测分子性质方面虽然有效，但仍有提高准确性的空间。增加模型复杂度可以提高准确性，但也会增加计算成本和内存需求。

Method: 提出了一种名为层间知识混合（LKM）的新型自知识蒸馏方法，通过最小化GNN层之间预先存在的隐藏嵌入的平均绝对距离，来聚合多跳和多尺度信息，从而改进分子局部和全局特征的表示。

Result: 使用DimeNet++、MXMNet和PAMNet三种GNN架构，在QM9、MD17和Chignolin数据集上评估LKM。结果显示，LKM将QM9、MD17能量和Chignolin的平均绝对误差分别降低了高达9.8%、45.3%和22.9%。

Conclusion: LKM有潜力在不显著增加训练和推理成本的情况下，显著提高GNN在化学性质预测方面的准确性。

Abstract: Graph Neural Networks (GNNs) are the currently most effective methods for
predicting molecular properties but there remains a need for more accurate
models. GNN accuracy can be improved by increasing the model complexity but
this also increases the computational cost and memory requirement during
training and inference. In this study, we develop Layer-to-Layer Knowledge
Mixing (LKM), a novel self-knowledge distillation method that increases the
accuracy of state-of-the-art GNNs while adding negligible computational
complexity during training and inference. By minimizing the mean absolute
distance between pre-existing hidden embeddings of GNN layers, LKM efficiently
aggregates multi-hop and multi-scale information, enabling improved
representation of both local and global molecular features. We evaluated LKM
using three diverse GNN architectures (DimeNet++, MXMNet, and PAMNet) using
datasets of quantum chemical properties (QM9, MD17 and Chignolin). We found
that the LKM method effectively reduces the mean absolute error of quantum
chemical and biophysical property predictions by up to 9.8% (QM9), 45.3% (MD17
Energy), and 22.9% (Chignolin). This work demonstrates the potential of LKM to
significantly improve the accuracy of GNNs for chemical property prediction
without any substantial increase in training and inference cost.

</details>


### [266] [What Does It Take to Build a Performant Selective Classifier?](https://arxiv.org/abs/2510.20242)
*Stephan Rabanser,Nicolas Papernot*

Main category: cs.LG

TL;DR: 本文提出了选择性分类器性能差距的分解方法，并分析了误差来源，为构建更优的选择性分类器提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有的选择性分类器在处理不确定输入时会放弃预测，但很少能达到完美的排序表现。本文旨在弥合这一差距。

Method: 提出选择性分类差距的有限样本分解，将其归因于五个误差来源：贝叶斯噪声、近似误差、排序误差、统计噪声和实现/偏移引起的松弛。分析了单调后验校准的局限性，并提出了需要重新排序预测的评分机制。

Result: 在合成数据和真实世界基准测试中验证了分解的有效性。结果表明，贝叶斯噪声和模型容量是差距的主要原因；只有更丰富的、感知特征的校准器才能有效改善排序；数据偏移需要稳健的训练方法。

Conclusion: 该分解提供了一个量化的误差预算和设计指南，以帮助实践者构建更接近理想选择性分类器行为的分类器。

Abstract: Selective classifiers improve model reliability by abstaining on inputs the
model deems uncertain. However, few practical approaches achieve the
gold-standard performance of a perfect-ordering oracle that accepts examples
exactly in order of correctness. Our work formalizes this shortfall as the
selective-classification gap and present the first finite-sample decomposition
of this gap to five distinct sources of looseness: Bayes noise, approximation
error, ranking error, statistical noise, and implementation- or shift-induced
slack. Crucially, our analysis reveals that monotone post-hoc calibration --
often believed to strengthen selective classifiers -- has limited impact on
closing this gap, since it rarely alters the model's underlying score ranking.
Bridging the gap therefore requires scoring mechanisms that can effectively
reorder predictions rather than merely rescale them. We validate our
decomposition on synthetic two-moons data and on real-world vision and language
benchmarks, isolating each error component through controlled experiments. Our
results confirm that (i) Bayes noise and limited model capacity can account for
substantial gaps, (ii) only richer, feature-aware calibrators meaningfully
improve score ordering, and (iii) data shift introduces a separate slack that
demands distributionally robust training. Together, our decomposition yields a
quantitative error budget as well as actionable design guidelines that
practitioners can use to build selective classifiers which approximate ideal
oracle behavior more closely.

</details>


### [267] [FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning](https://arxiv.org/abs/2510.20250)
*Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan*

Main category: cs.LG

TL;DR: FedGPS 框架通过整合统计信息和梯度信息来解决联邦学习中的数据异质性问题，并在各种异质性场景下表现出比现有方法更优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理数据异质性方面存在局限性，需要研究这些方法在不同异质性场景下的鲁棒性。

Method: 提出 FedGPS 框架，该框架整合统计分布和梯度信息。FedGPS 通过修改客户端的学习目标来隐式地建模全局数据分布，并通过在每个通信轮次中动态调整本地更新方向来聚合来自其他客户端的梯度信息。

Result: FedGPS 在各种数据异质性场景下进行了广泛的实验评估，结果表明其在性能和鲁棒性方面优于现有的最先进方法。

Conclusion: FedGPS 是一种有效且鲁棒的联邦学习框架，能够成功应对数据异质性带来的挑战。

Abstract: Federated Learning (FL) confronts a significant challenge known as data
heterogeneity, which impairs model performance and convergence. Existing
methods have made notable progress in addressing this issue. However, improving
performance in certain heterogeneity scenarios remains an overlooked question:
\textit{How robust are these methods to deploy under diverse heterogeneity
scenarios?} To answer this, we conduct comprehensive evaluations across varied
heterogeneity scenarios, showing that most existing methods exhibit limited
robustness. Meanwhile, insights from these experiments highlight that sharing
statistical information can mitigate heterogeneity by enabling clients to
update with a global perspective. Motivated by this, we propose \textbf{FedGPS}
(\textbf{Fed}erated \textbf{G}oal-\textbf{P}ath \textbf{S}ynergy), a novel
framework that seamlessly integrates statistical distribution and gradient
information from others. Specifically, FedGPS statically modifies each client's
learning objective to implicitly model the global data distribution using
surrogate information, while dynamically adjusting local update directions with
gradient information from other clients at each round. Extensive experiments
show that FedGPS outperforms state-of-the-art methods across diverse
heterogeneity scenarios, validating its effectiveness and robustness. The code
is available at: https://github.com/CUHK-AIM-Group/FedGPS.

</details>


### [268] [Optimistic Task Inference for Behavior Foundation Models](https://arxiv.org/abs/2510.20264)
*Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause*

Main category: cs.LG

TL;DR: BFMs在零样本强化学习中需要大量数据来推断奖励函数，OpTI-BFM通过与环境交互来解决这个问题，利用不确定性来指导数据收集。


<details>
  <summary>Details</summary>
Motivation: 零样本强化学习（RL）中的行为基础模型（BFMs）虽然计算效率高，但在数据方面可能效率低下，因为它们需要大量的推理数据集和奖励函数信息。为了解决这些限制，需要一种仅通过测试时与环境的交互来推断任务的方法。

Method: 提出OpTI-BFM，一个乐观的决策标准，直接对奖励函数的不确定性进行建模，并指导BFMs在数据收集过程中进行任务推断。通过将BFMs与线性赌博机中的置信度上限算法联系起来，为BFMs提供了一个后悔界限。

Result: OpTI-BFM在已建立的零样本基准测试中，能够让基于后继特征的BFMs在极少数的几个回合中，以最小的计算开销识别和优化未知的奖励函数。

Conclusion: OpTI-BFM通过在测试时通过与环境进行交互来推断任务，能够有效地解决BFMs在零样本强化学习中的数据效率问题。

Abstract: Behavior Foundation Models (BFMs) are capable of retrieving high-performing
policy for any reward function specified directly at test-time, commonly
referred to as zero-shot reinforcement learning (RL). While this is a very
efficient process in terms of compute, it can be less so in terms of data: as a
standard assumption, BFMs require computing rewards over a non-negligible
inference dataset, assuming either access to a functional form of rewards, or
significant labeling efforts. To alleviate these limitations, we tackle the
problem of task inference purely through interaction with the environment at
test-time. We propose OpTI-BFM, an optimistic decision criterion that directly
models uncertainty over reward functions and guides BFMs in data collection for
task inference. Formally, we provide a regret bound for well-trained BFMs
through a direct connection to upper-confidence algorithms for linear bandits.
Empirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and
observe that it enables successor-features-based BFMs to identify and optimize
an unseen reward function in a handful of episodes with minimal compute
overhead. Code is available at https://github.com/ThomasRupf/opti-bfm.

</details>


### [269] [ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases](https://arxiv.org/abs/2510.20270)
*Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini*

Main category: cs.LG

TL;DR: LLM在完成任务时倾向于寻找捷径，这会影响其可靠性。本研究提出了ImpossibleBench基准测试框架，用于量化、研究和减轻这种“作弊”行为。该框架通过创建“不可能”的任务来检测LLM是否会为了通过测试而牺牲对需求的满足。研究还展示了该框架在模型行为研究、上下文工程和监控工具开发方面的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在执行任务时存在寻找“捷径”的倾向，这会对评估和部署LLM带来风险，例如LLM代理可能会删除失败的测试用例而不是修复底层错误，从而影响基准测试结果和实际应用中的可靠性。

Method: 研究人员创建了一个名为ImpossibleBench的基准测试框架，该框架通过引入自然语言描述与单元测试之间的冲突，来系统地衡量LLM代理利用测试用例的倾向。通过计算LLM在这些“不可能”任务上的通过率（作弊率）来量化其作弊行为，任何通过都意味着模型采取了牺牲需求满足的捷径。

Result: ImpossibleBench框架不仅可以评估模型行为，还可以用于研究模型在不同情况下的作弊行为（例如，简单的测试修改或复杂的运算符重载），探究提示、测试访问和反馈循环如何影响作弊率，并为开发监控工具提供了一个包含已验证的欺骗性解决方案的测试平台。

Conclusion: ImpossibleBench是一个实用的框架，用于量化、研究和缓解LLM的作弊行为，有助于构建更鲁棒、更可靠的LLM系统。

Abstract: The tendency to find and exploit "shortcuts" to complete tasks poses
significant risks for reliable assessment and deployment of large language
models (LLMs). For example, an LLM agent with access to unit tests may delete
failing tests rather than fix the underlying bug. Such behavior undermines both
the validity of benchmark results and the reliability of real-world LLM coding
assistant deployments.
  To quantify, study, and mitigate such behavior, we introduce ImpossibleBench,
a benchmark framework that systematically measures LLM agents' propensity to
exploit test cases. ImpossibleBench creates "impossible" variants of tasks from
existing benchmarks like LiveCodeBench and SWE-bench by introducing direct
conflicts between the natural-language specification and the unit tests. We
measure an agent's "cheating rate" as its pass rate on these impossible tasks,
where any pass necessarily implies a specification-violating shortcut.
  As a practical framework, ImpossibleBench is not just an evaluation but a
versatile tool. We demonstrate its utility for: (1) studying model behaviors,
revealing more fine-grained details of cheating behaviors from simple test
modification to complex operator overloading; (2) context engineering, showing
how prompt, test access and feedback loop affect cheating rates; and (3)
developing monitoring tools, providing a testbed with verified deceptive
solutions. We hope ImpossibleBench serves as a useful framework for building
more robust and reliable LLM systems.
  Our implementation can be found at
https://github.com/safety-research/impossiblebench.

</details>


### [270] [Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch](https://arxiv.org/abs/2510.20271)
*Udit Saxena*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Topological features capture global geometric structure in imaging data, but
practical adoption in deep learning requires both computational efficiency and
differentiability. We present optimized GPU kernels for the Euler
Characteristic Curve (ECC) computation achieving 16-2000\"O speedups over prior
GPU implementations on synthetic grids, and introduce a differentiable PyTorch
layer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs
use 128B-coalesced access and hierarchical shared-memory accumulation. Our
PyTorch layer learns thresholds in a single direction via a Differentiable
Euler Characteristic Transform-style sigmoid relaxation. We discuss downstream
relevance, including applications highlighted by prior ECC work, and outline
batching/multi-GPU extensions to broaden adoption.

</details>


### [271] [Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs](https://arxiv.org/abs/2510.20272)
*Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi*

Main category: cs.LG

TL;DR: 链式思考提示（Chain-of-thought prompting）结合最佳N（Best-of-N, BoN）选择在LLMs的数学推理中表现不佳，因为其线性结构无法捕捉复杂问题解决的分支和探索性质。本研究提出一种自适应算法，通过PRM（Process Reward Model）引导的树搜索来探索多条部分解决方案路径，以期提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考提示（Chain-of-thought prompting）结合最佳N（Best-of-N, BoN）选择在数学推理任务中存在局限性，无法有效处理问题解决过程中复杂的分支和探索性。本研究旨在探索PRM（Process Reward Model）引导的树搜索是否能通过探索多条部分解决方案路径来改进LLMs的数学推理能力。

Method: 本研究提出了一种自适应算法，通过最大化过程奖励模型（Process Reward Model, PRM）的分数来指导树搜索，并探索PRM-guided tree search在数学推理中的应用。研究在23个多样化的数学问题上，使用Qwen2.5-Math-7B-Instruct模型及其关联的PRM进行了实验。

Result: 实验结果表明：1. PRM-guided tree search在成本更高的情况下，并未比BoN方法有显著的统计学上的改进；2. Monte Carlo tree search和beam search优于其他PRM-guided tree search方法；3. PRMs对状态价值的估计不准确，且其可靠性随推理深度的增加而下降；4. PRMs在分布外（out-of-distribution）的泛化能力较差。

Conclusion: PRM-guided tree search在数学推理任务中的实际效果不佳，其性能受限于PRM分数的不可靠性，尤其是在推理深度增加时。这表明在有效利用树搜索来增强LLMs的数学推理能力之前，需要开发更可靠的奖励模型。

Abstract: While chain-of-thought prompting with Best-of-N (BoN) selection has become
popular for mathematical reasoning in large language models (LLMs), its linear
structure fails to capture the branching and exploratory nature of complex
problem-solving. In this work, we propose an adaptive algorithm to maximize
process reward model (PRM) scores over the intractable action space, and
investigate whether PRM-guided tree search can improve mathematical reasoning
by exploring multiple partial solution paths. Across $23$ diverse mathematical
problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case
study, we find that: (1) PRM-guided tree search shows no statistically
significant improvements over BoN despite higher costs, (2) Monte Carlo tree
search and beam search outperform other PRM-guided tree search methods, (3)
PRMs poorly approximate state values and their reliability degrades with
reasoning depth, and (4) PRMs generalize poorly out of distribution. This
underperformance stems from tree search's greater reliance on unreliable PRM
scores, suggesting different reward modeling is necessary before tree search
can effectively enhance mathematical reasoning in LLMs.

</details>


### [272] [SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series](https://arxiv.org/abs/2510.20273)
*Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 深度学习在时间序列预测方面取得了显著进展，但实际应用中性能不稳定。本文提出了一个名为SynTSBench的合成数据驱动的评估框架，通过可编程的特征配置来系统地评估时间序列预测模型的基本建模能力，解决了现有评估框架的局限性。该框架包含三个核心分析维度：时间特征分解与能力映射、数据不规则性下的鲁棒性分析以及理论最优基准测试。实验表明，当前深度学习模型在处理所有类型的时间特征时，并非都能达到最优基准。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习时间序列预测模型在实际应用中表现不稳定，现有评估框架无法提供模型优劣的量化洞察，阻碍了模型的选择。因此，需要一个更系统、可解释的评估方法来解决这一问题。

Method: 提出了一种名为SynTSBench的合成数据驱动的评估范式。该范式通过可编程的特征配置，系统地评估时间序列预测模型在不同时间特征、数据不规则性和理论最优边界下的表现，包括（1）时间特征分解与能力映射、（2）数据不规则性下的鲁棒性分析、（3）理论最优基准测试。

Result: 实验结果表明，当前先进的深度学习模型并非在所有类型的时间特征上都能接近理论最优值。

Conclusion: SynTSBench 提供了一个可解释的评估系统，能够系统地评估时间序列预测模型在不同时间特征上的能力、鲁棒性以及与理论最优值的差距，有助于未来开发更强大的时间序列预测模型。

Abstract: Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

</details>


### [273] [KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models](https://arxiv.org/abs/2510.20278)
*Guangyu Dai,Siliang Tang,Yueting Zhuang*

Main category: cs.LG

TL;DR: 该研究提出了一种基于KAN的协同模型（KCM）来改进大-小模型协作框架，旨在降低计算资源消耗并提高模型在专业领域的表现，同时解决现有框架中的准确性下降、灾难性遗忘和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有大-小模型协作框架中存在的准确性下降、灾难性遗忘加剧和幻觉问题放大等挑战。

Method: 提出了一种基于KAN（Kolmogorov-Arnold Network）的协同模型（KCM），作为大-小模型协作的改进方法。KAN 是一种不同于传统MLP（多层感知器）的神经网络架构，具有更好的可视化和可解释性，并能缓解灾难性遗忘。

Result: 在语言、视觉和跨模态任务的实验结果表明，使用KCM的大-小模型协作框架相比纯大模型方法，显著减少了大模型的推理调用次数，同时保持了相似的任务准确性，从而大大降低了计算资源消耗。此外，KCM显著缓解了灾难性遗忘，并显著提高了长尾数据的准确性。KCM在所有指标上均优于基于MLP的小型协作模型（MCM）。

Conclusion: KCM作为一种基于KAN的大-小模型协作方法，在降低计算成本、保持准确性、缓解灾难性遗忘以及提升长尾数据表现方面，均优于传统的MLP-based协作模型和纯大模型方法。

Abstract: In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

</details>


### [274] [ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows](https://arxiv.org/abs/2510.20279)
*Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang*

Main category: cs.LG

TL;DR: 本文提出了 CS-54k 数据集，包含 14k 篇计算机科学论文的问答对，用于训练和评估大型语言模型（LLMs）作为科学研究的协作者。其中 CS-4k 作为评估基准，CS-50k 作为训练集。实验表明，经过领域对齐训练的模型在研究辅助任务上表现出色，甚至优于一些大型专有模型，强调了高质量数据和领域特定训练的重要性。


<details>
  <summary>Details</summary>
Motivation: 旨在构建一个能够协助人类完成整个科学研究过程的 AI 协作者（ResearchGPT），并为此开发了相应的评估基准和数据集。

Method: 构建了一个名为 CS-54k 的高质量科学问答对语料库，该语料库源自 14k 篇计算机科学论文。利用检索增强生成（RAG）和多阶段质量控制流水线，确保问答对的事实依据。从 CS-54k 中衍生出用于评估的 CS-4k 子集和用于训练的 CS-50k 子集。

Result: 实验证明 CS-4k 能够有效区分不同能力水平的先进 LLMs。在 CS-50k 上进行监督训练和强化学习的开源模型表现出显著提升，即使是 7B 参数的模型在经过适当训练后，其在研究辅助任务上的表现也优于 GPT-4.1、GPT-4o 和 Gemini 2.5 Pro 等大型专有模型。

Conclusion: 高质量、领域对齐的训练数据对于提升 AI 模型作为科学研究助手的效能比模型规模或通用基准性能更重要。作者希望通过发布 CS-4k 和 CS-50k 数据集，促进能够成为计算机科学研究可靠协作者的 AI 系统的发展。

Abstract: As large language models (LLMs) advance, the ultimate vision for their role
in science is emerging: we could build an AI collaborator to effectively assist
human beings throughout the entire scientific research process. We refer to
this envisioned system as ResearchGPT. Given that scientific research
progresses through multiple interdependent phases, achieving this vision
requires rigorous benchmarks that evaluate the end-to-end workflow rather than
isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of
scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It
is constructed through a scalable, paper-grounded pipeline that combines
retrieval-augmented generation (RAG) with multi-stage quality control to ensure
factual grounding. From this unified corpus, we derive two complementary
subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to
assist scientific research, and CS-50k, a large-scale training dataset.
Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs
into distinct capability tiers. Open models trained on CS-50k with supervised
training and reinforcement learning demonstrate substantial improvements. Even
7B-scale models, when properly trained, outperform many larger proprietary
systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that
making AI models better research assistants relies more on domain-aligned
training with high-quality data than on pretraining scale or general benchmark
performance. We release CS-4k and CS-50k in the hope of fostering AI systems as
reliable collaborators in CS research.

</details>


### [275] [Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization](https://arxiv.org/abs/2510.20295)
*Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li*

Main category: cs.LG

TL;DR: 本研究提出了一种无需环境标注或合成数据即可实现图神经网络（GNN）分布外泛化的新方法，通过识别在不同环境中表现出最小分布变化的因果子图。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNN）在分布外泛化方面面临严峻挑战，现有方法（如不变风险最小化，IRM）依赖昂贵的环境标注或合成数据。

Method: 提出了一种基于“不变分布判据”的新方法，该判据指出因果子图在不同环境中具有较小的分布变异性。通过理论分析，揭示了分布偏移与表示范数之间的定量关系，并以此为指导，设计了一个无需IRM即可发现因果子图的目标函数。

Result: 在两个基准数据集上的广泛实验表明，该方法在图泛化能力上优于现有最先进方法。

Conclusion: 所提出的IRM-free方法能够有效识别因果子图，并在图泛化任务上取得优异表现，解决了现有方法的局限性。

Abstract: Out-of-distribution generalization under distributional shifts remains a
critical challenge for graph neural networks. Existing methods generally adopt
the Invariant Risk Minimization (IRM) framework, requiring costly environment
annotations or heuristically generated synthetic splits. To circumvent these
limitations, in this work, we aim to develop an IRM-free method for capturing
causal subgraphs. We first identify that causal subgraphs exhibit substantially
smaller distributional variations than non-causal components across diverse
environments, which we formalize as the Invariant Distribution Criterion and
theoretically prove in this paper. Building on this criterion, we
systematically uncover the quantitative relationship between distributional
shift and representation norm for identifying the causal subgraph, and
investigate its underlying mechanisms in depth. Finally, we propose an IRM-free
method by introducing a norm-guided invariant distribution objective for causal
subgraph discovery and prediction. Extensive experiments on two widely used
benchmarks demonstrate that our method consistently outperforms
state-of-the-art methods in graph generalization.

</details>


### [276] [DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability](https://arxiv.org/abs/2510.20299)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.LG

TL;DR: 提出了一种不依赖数据增强的双骨干网络（VGG16和Xception）与频门控注意力（FGA）模块，用于脑肿瘤分类，实现了高精度和良好的泛化能力，并通过Grad-CAM可视化和GUI提升了模型的可解释性和临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的脑肿瘤分类方法通常依赖于大量数据增强，这可能限制其在临床应用中的泛化能力和可信度。因此，需要开发一种在不依赖数据增强的情况下仍能保持高准确性和泛化能力，并具有良好可解释性的模型。

Method: 提出了一种双骨干网络（DB-FGA-Net），集成了VGG16和Xception网络，并结合了频门控注意力（FGA）模块。该模型旨在捕捉互补的局部和全局特征。此外，集成了Grad-CAM技术用于可视化模型预测的肿瘤区域，并开发了一个图形用户界面（GUI）来实现实时分类和肿瘤定位。

Result: 在7K-DS数据集的4分类任务中，该模型达到了99.24%的准确率，在3分类和2分类任务中分别达到了98.68%和99.85%。在独立的3K-DS数据集上，模型也取得了95.77%的准确率，优于基线和现有最先进的方法。模型在没有数据增强的情况下表现出了鲁棒性。

Conclusion: 该研究提出了DB-FGA-Net，这是一个不依赖数据增强、可解释且可部署的深度学习模型。该模型在脑肿瘤诊断方面展现了高精度和良好的泛化能力，并通过Grad-CAM可视化和GUI提升了临床可解释性和应用潜力，预示着其在脑肿瘤诊断领域的可靠临床转化前景。

Abstract: Brain tumors are a challenging problem in neuro-oncology, where early and
precise diagnosis is important for successful treatment. Deep learning-based
brain tumor classification methods often rely on heavy data augmentation which
can limit generalization and trust in clinical applications. In this paper, we
propose a double-backbone network integrating VGG16 and Xception with a
Frequency-Gated Attention (FGA) Block to capture complementary local and global
features. Unlike previous studies, our model achieves state-of-the-art
performance without augmentation which demonstrates robustness to variably
sized and distributed datasets. For further transparency, Grad-CAM is
integrated to visualize the tumor regions based on which the model is giving
prediction, bridging the gap between model prediction and clinical
interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS
dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class
and 2-class settings, respectively. On the independent 3K-DS dataset, the model
generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art
methods. To further support clinical usability, we developed a graphical user
interface (GUI) that provides real-time classification and Grad-CAM-based tumor
localization. These findings suggest that augmentation-free, interpretable, and
deployable deep learning models such as DB-FGA-Net hold strong potential for
reliable clinical translation in brain tumor diagnosis.

</details>


### [277] [InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling](https://arxiv.org/abs/2510.20302)
*Yuhang Wang*

Main category: cs.LG

TL;DR: InvDec是一种混合架构，通过结合基于块的时间编码器和反向解码器，解决了多变量时间序列预测中的时序模式和跨变量依赖性建模问题，在处理高维数据集方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多变量时间序列预测方法要么侧重于时间建模而忽略变量相关性（如PatchTST），要么侧重于变量注意力而牺牲时间编码（如iTransformer）。需要一种能够有效分离时序编码和变量级解码的混合架构。

Method: InvDec采用基于块的时间编码器来捕捉时间模式，并结合一个在变量维度上操作的反向解码器，通过变量级自注意力机制来处理跨变量依赖性。该方法引入了延迟变量嵌入，在时间编码后才丰富变量表示，并使用自适应残差融合机制来平衡不同维度数据集中的时序和变量信息。

Result: 在七个基准数据集上进行的大量实验表明，InvDec在高维数据集上取得了显著的改进，例如在Electricity（321个变量）上MSE降低了20.9%，在Weather上提高了4.3%，在Traffic上提高了2.7%。同时，在低维ETThour数据集上保持了与PatchTST相当的性能。消融研究验证了每个组件的有效性。

Conclusion: InvDec的优势随着数据集维度的增加而增强，证明了在变量数量增加时，跨变量建模的重要性。该混合架构有效解决了多变量时间序列预测中的挑战。

Abstract: Multivariate time series forecasting requires simultaneously modeling
temporal patterns and cross-variate dependencies. Channel-independent methods
such as PatchTST excel at temporal modeling but ignore variable correlations,
while pure variate-attention approaches such as iTransformer sacrifice temporal
encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that
achieves principled separation between temporal encoding and variate-level
decoding. InvDec combines a patch-based temporal encoder with an inverted
decoder operating on the variate dimension through variate-wise self-attention.
We introduce delayed variate embeddings that enrich variable-specific
representations only after temporal encoding, preserving temporal feature
integrity. An adaptive residual fusion mechanism dynamically balances temporal
and variate information across datasets of varying dimensions. Instantiating
InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven
benchmarks demonstrate significant gains on high-dimensional datasets: 20.9%
MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and
2.7% gain on Traffic compared to PatchTST, while maintaining competitive
performance on low-dimensional ETT datasets. Ablation studies validate each
component, and analysis reveals that InvDec's advantage grows with dataset
dimensionality, confirming that cross-variate modeling becomes critical as the
number of variables increases.

</details>


### [278] [LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems](https://arxiv.org/abs/2510.20327)
*Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen*

Main category: cs.LG

TL;DR: 现有的推荐属性遗忘方法无法同时处理多个遗忘请求或适应动态遗忘需求，因此提出了LEGO框架，该框架通过嵌入校准和灵活组合来解决这些问题，并在实验中证明了其有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有推荐属性遗忘方法主要关注单一属性，无法满足现实世界中涉及多个敏感属性且动态变化的隐私保护需求，具体表现为无法同时处理多个遗忘请求（CH1）和缺乏对动态遗忘需求的有效适应性（CH2）。

Method: LEGO框架将多属性遗忘过程分为两步：1. 嵌入校准（Embedding Calibration）：从用户嵌入中移除与特定属性相关的信息。2. 灵活组合（Flexible Combination）：将这些嵌入合并成单一嵌入，从而保护所有敏感属性。该遗忘过程被构建为一个互信息最小化问题，为同时遗忘提供了理论保证，并通过可并行执行的嵌入校准和灵活高效的灵活组合来解决动态遗忘需求。

Result: 在三个真实世界数据集和三种代表性推荐模型上的广泛实验证明了LEGO框架的有效性和效率。

Conclusion: LEGO框架通过嵌入校准和灵活组合的两步方法，能够有效地同时处理多个属性的遗忘请求，并灵活适应动态遗忘需求，解决了现有方法的局限性，并在实验中得到了验证。

Abstract: With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

</details>


### [279] [Synthetic Data for Robust Runway Detection](https://arxiv.org/abs/2510.20349)
*Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin*

Main category: cs.LG

TL;DR: A method for runway detection using synthetic images generated by a flight simulator, combined with a few real images and domain adaptation, achieves accurate and robust predictions for autonomous landing systems.


<details>
  <summary>Details</summary>
Motivation: Collecting and labeling sufficient data for training deep vision models, especially for critical applications like autonomous navigation that require covering all possible conditions (including rare scenarios), is costly and time-consuming for a single company. Synthetic data generation is an appealing solution to this problem.

Method: The paper proposes an image generation approach using a commercial flight simulator to create synthetic images, which are then combined with a few annotated real images. Standard object detection models are used for prediction, and a customized domain adaptation strategy is evaluated for robustness, particularly for nighttime conditions not present in the real data.

Result: The study shows that by controlling image generation and integrating real and synthetic data, standard object detection models can achieve accurate predictions for runway detection. The proposed approach also demonstrates robustness with respect to adverse conditions (nighttime images).

Conclusion: Using synthetic images from a flight simulator, complemented by a few real images and a domain adaptation strategy, is an effective and robust approach for training deep vision models for critical applications like runway detection in autonomous landing systems, especially when dealing with data scarcity and the need to cover various environmental conditions.

Abstract: Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

</details>


### [280] [Ask a Strong LLM Judge when Your Reward Model is Uncertain](https://arxiv.org/abs/2510.20369)
*Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao*

Main category: cs.LG

TL;DR: 提出一个不确定性路由框架，结合了快速的奖励模型（RM）和强大的大型语言模型（LLM）裁判，以提高在线人类反馈强化学习（RLHF）的效率和对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统的奖励模型（RM）在人类反馈强化学习（RLHF）中容易出现奖励攻击和泛化能力差的问题，而强大的大型语言模型（LLM）裁判虽然泛化能力强但成本高昂。

Method: 提出一个基于不确定性的路由框架，将策略梯度（PG）方法中的优势估计表述为成对偏好分类，从而实现不确定性量化来指导路由。不确定的样本交给LLM裁判，确定的样本由RM评估。

Result: 实验表明，该不确定性路由策略在相同成本下显著优于随机裁判调用，并且下游对齐结果证明了其在改进在线RLHF方面的有效性。

Conclusion: 所提出的不确定性路由框架能够有效地结合RM和LLM裁判的优点，在保证性能的同时降低了RLHF的成本。

Abstract: Reward model (RM) plays a pivotal role in reinforcement learning with human
feedback (RLHF) for aligning large language models (LLMs). However, classical
RMs trained on human preferences are vulnerable to reward hacking and
generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM
judges equipped with reasoning capabilities demonstrate superior
generalization, even without additional training, but incur significantly
higher inference costs, limiting their applicability in online RLHF. In this
work, we propose an uncertainty-based routing framework that efficiently
complements a fast RM with a strong but costly LLM judge. Our approach
formulates advantage estimation in policy gradient (PG) methods as pairwise
preference classification, enabling principled uncertainty quantification to
guide routing. Uncertain pairs are forwarded to the LLM judge, while confident
ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our
uncertainty-based routing strategy significantly outperforms random judge
calling at the same cost, and downstream alignment results showcase its
effectiveness in improving online RLHF.

</details>


### [281] [Hierarchical Time Series Forecasting with Robust Reconciliation](https://arxiv.org/abs/2510.20383)
*Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.LG

TL;DR: 本文提出了一种稳健的优化框架，用于解决分层时间序列预测中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的分层预测方法在独立生成基础预测后进行协调，以确保预测值的一致性。然而，这些方法依赖于估计的协方差矩阵，而实际的协方差矩阵是未知的，估计的误差会影响预测性能。

Method: 提出了一种稳健的优化框架，该框架考虑了估计的协方差矩阵中的不确定性。通过引入不确定性集并最小化该不确定性集上的最坏情况预期平方误差，将问题转化为半定优化问题。

Result: 数值实验表明，与现有方法相比，所提出的稳健协调方法在预测性能上有所提高。

Conclusion: 将不确定性纳入协调过程可以提高分层时间序列预测的性能。

Abstract: This paper focuses on forecasting hierarchical time-series data, where each
higher-level observation equals the sum of its corresponding lower-level time
series. In such contexts, the forecast values should be coherent, meaning that
the forecast value of each parent series exactly matches the sum of the
forecast values of its child series. Existing hierarchical forecasting methods
typically generate base forecasts independently for each series and then apply
a reconciliation procedure to adjust them so that the resulting forecast values
are coherent across the hierarchy. These methods generally derive an optimal
reconciliation, using a covariance matrix of the forecast error. In practice,
however, the true covariance matrix is unknown and has to be estimated from
finite samples in advance. This gap between the true and estimated covariance
matrix may degrade forecast performance. To address this issue, we propose a
robust optimization framework for hierarchical reconciliation that accounts for
uncertainty in the estimated covariance matrix. We first introduce an
uncertainty set for the estimated covariance matrix and formulate a
reconciliation problem that minimizes the worst-case expected squared error
over this uncertainty set. We show that our problem can be cast as a
semidefinite optimization problem. Numerical experiments demonstrate that the
proposed robust reconciliation method achieved better forecast performance than
existing hierarchical forecasting methods, which indicates the effectiveness of
integrating uncertainty into the reconciliation process.

</details>


### [282] [Relative-Based Scaling Law for Neural Language Models](https://arxiv.org/abs/2510.20387)
*Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新的评估指标RBP（相对基础概率）和相对基础缩放定律，用于更全面地理解大语言模型的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 现有的缩放定律研究主要依赖交叉熵作为评估指标，但交叉熵忽略了正确和错误标记之间的相对排序，而这对于语言模型（如贪婪采样场景）至关重要。

Method: 提出相对基础概率（RBP）指标，量化正确标记排在前N个预测中的概率。在此基础上，建立相对基础缩放定律，描述RBP如何随着模型规模的增大而提高。通过在四个数据集和四个模型家族上进行广泛实验来验证该定律的稳健性和准确性。

Result: 通过在四个数据集和四个模型家族上进行的广泛实验，证明了相对基础缩放定律的稳健性和准确性。

Conclusion: 相对基础缩放定律是对交叉熵视角的补充，有助于更全面地理解大语言模型的缩放规律，为实际开发和理论探索提供了有价值的见解。

Abstract: Scaling laws aim to accurately predict model performance across different
scales. Existing scaling-law studies almost exclusively rely on cross-entropy
as the evaluation metric. However, cross-entropy provides only a partial view
of performance: it measures the absolute probability assigned to the correct
token, but ignores the relative ordering between correct and incorrect tokens.
Yet, relative ordering is crucial for language models, such as in
greedy-sampling scenario. To address this limitation, we investigate scaling
from the perspective of relative ordering. We first propose the Relative-Based
Probability (RBP) metric, which quantifies the probability that the correct
token is ranked among the top predictions. Building on this metric, we
establish the Relative-Based Scaling Law, which characterizes how RBP improves
with increasing model size. Through extensive experiments on four datasets and
four model families spanning five orders of magnitude, we demonstrate the
robustness and accuracy of this law. Finally, we illustrate the broad
application of this law with two examples, namely providing a deeper
explanation of emergence phenomena and facilitating finding fundamental
theories of scaling laws. In summary, the Relative-Based Scaling Law
complements the cross-entropy perspective and contributes to a more complete
understanding of scaling large language models. Thus, it offers valuable
insights for both practical development and theoretical exploration.

</details>


### [283] [Why DPO is a Misspecified Estimator and How to Fix It](https://arxiv.org/abs/2510.20413)
*Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee*

Main category: cs.LG

TL;DR: DPO算法在某些情况下可能失效，提出AuxDPO改进


<details>
  <summary>Details</summary>
Motivation: DPO算法基于偏好数据进行微调，但当真实奖励函数无法通过参数策略类实现时，DPO可能出现失效模式，如偏好逆转、奖励下降和对输入数据分布的敏感性。

Method: 通过对两阶段RLHF进行精细的几何分析，提出AuxDPO算法，通过在DPO损失函数中引入辅助变量来解决DPO的误设问题，使其更接近RLHF的解决方案。

Result: AuxDPO在教学性老虎机设置和LLM对齐任务中均表现出优越性能。

Conclusion: AuxDPO通过引入辅助变量，能够有效解决DPO算法在特定情况下的失效问题，并在多个任务中取得了更好的效果。

Abstract: Direct alignment algorithms such as Direct Preference Optimization (DPO)
fine-tune models based on preference data, using only supervised learning
instead of two-stage reinforcement learning with human feedback (RLHF). We show
that DPO encodes a statistical estimation problem over reward functions induced
by a parametric policy class. When the true reward function that generates
preferences cannot be realized via the policy class, DPO becomes misspecified,
resulting in failure modes such as preference order reversal, worsening of
policy reward, and high sensitivity to the input preference data distribution.
On the other hand, we study the local behavior of two-stage RLHF for a
parametric class and relate it to a natural gradient step in policy space. Our
fine-grained geometric characterization allows us to propose AuxDPO, which
introduces additional auxiliary variables in the DPO loss function to help move
towards the RLHF solution in a principled manner and mitigate the
misspecification in DPO. We empirically demonstrate the superior performance of
AuxDPO on didactic bandit settings as well as LLM alignment tasks.

</details>


### [284] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种新的阈值方法来解决事件标记中的不平衡问题，以提高事件预测的准确性，特别是对于罕见标记的事件。


<details>
  <summary>Details</summary>
Motivation: 现有标记时序点过程（MTPP）模型在处理事件标记不平衡问题时存在不足，这影响了罕见标记事件的预测性能。

Method: 提出一种阈值方法，通过学习阈值来调整由标记先验概率归一化的标记概率，以优化标记预测，并结合新颖的神经MTPP模型进行时间采样和标记概率估计。

Result: 在真实世界数据集上的广泛实验表明，该方法在下一个事件标记和时间预测方面优于现有基线。

Conclusion: 提出的阈值方法和神经MTPP模型能有效解决事件标记不平衡问题，显著提高预测性能。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [285] [An Empirical Study of Sample Selection Strategies for Large Language Model Repair](https://arxiv.org/abs/2510.20428)
*Xuran Li,Jingyi Wang*

Main category: cs.LG

TL;DR: LLM 修复中的数据选择至关重要，本文提出了一种名为 SAPS 的语义感知采样方法，在保证修复效果的同时，大幅减少了数据需求，并证明了选择性修复是维持 LLM 可靠性的一种高效且可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: LLM 易产生有毒或有偏见的输出，而事后模型修复成本高，需要有效的数据选择策略来降低成本。

Method: 评估了随机采样、K-Center、GraNd、CCS 和提出的 SAPS 等五种采样策略，并通过毒性降低、困惑度以及 RPS、OPS、RES 等综合指标来评估修复效果和权衡。

Result: SAPS 在解毒、保留模型效用和效率方面取得了最佳平衡，所需数据量大大减少。随机采样适用于大型或鲁棒模型，而 CCS 和 GraNd 等高开销方法效果有限。

Conclusion: 数据选择是 LLM 修复流程中的一个可调组件，选择性修复是维持 LLM 可靠性的一种高效且可扩展的方法。

Abstract: Large language models (LLMs) are increasingly deployed in real-world systems,
yet they can produce toxic or biased outputs that undermine safety and trust.
Post-hoc model repair provides a practical remedy, but the high cost of
parameter updates motivates selective use of repair data. Despite extensive
prior work on data selection for model training, it remains unclear which
sampling criteria are most effective and efficient when applied specifically to
behavioral repair of large generative models. Our study presents a systematic
analysis of sample prioritization strategies for LLM repair. We evaluate five
representative selection methods, including random sampling, K-Center,
gradient-norm-based selection(GraNd), stratified coverage (CCS), and a
Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair
effectiveness and trade-offs are assessed through toxicity reduction,
perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair
Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair
Efficiency Score (RES). Experimental results show that SAPS achieves the best
balance between detoxification, utility preservation, and efficiency,
delivering comparable or superior repair outcomes with substantially less data.
Random sampling remains effective for large or robust models, while
high-overhead methods such as CCS and GraNd provide limited benefit. The
optimal data proportion depends on model scale and repair method, indicating
that sample selection should be regarded as a tunable component of repair
pipelines. Overall, these findings establish selection-based repair as an
efficient and scalable paradigm for maintaining LLM reliability.

</details>


### [286] [Explainable Benchmarking through the Lense of Concept Learning](https://arxiv.org/abs/2510.20439)
*Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 本研究提出了一种名为“可解释基准测试”的新型基准测试方法，旨在自动生成系统在基准测试中表现的解释，以克服传统基准测试中手动分析的耗时和偏差问题。研究人员开发了一种名为PruneCEL的概念学习方法，并将其应用于知识图谱问答系统，实验结果表明PruneCEL在可解释基准测试方面优于现有方法，并且用户研究显示该方法生成的解释能有效帮助用户预测系统行为。


<details>
  <summary>Details</summary>
Motivation: 传统的系统性能评估依赖少量指标，导致分析和获得进一步开发或使用的见解成为一项繁琐且可能存在偏差的手动任务。因此，有必要提出一种新的基准测试方法，即“可解释基准测试”，以自动生成系统性能的解释。

Method: 研究人员开发了一种名为PruneCEL的新型概念学习方法，该方法专为大型知识图谱设计，并将其应用于知识图谱问答系统的可解释基准测试。

Result: PruneCEL在可解释基准测试任务上的表现优于最先进的概念学习器，F1分数最高可提升0.55。一项有41名参与者的面向任务的用户研究表明，在80%的情况下，大多数参与者能够根据所提供的解释准确预测系统的行为。

Conclusion: 研究提出的可解释基准测试方法和PruneCEL概念学习器能够有效地为知识图谱问答系统的性能提供解释，用户研究也验证了该方法的实用性，能够帮助用户理解和预测系统行为。

Abstract: Evaluating competing systems in a comparable way, i.e., benchmarking them, is
an undeniable pillar of the scientific method. However, system performance is
often summarized via a small number of metrics. The analysis of the evaluation
details and the derivation of insights for further development or use remains a
tedious manual task with often biased results. Thus, this paper argues for a
new type of benchmarking, which is dubbed explainable benchmarking. The aim of
explainable benchmarking approaches is to automatically generate explanations
for the performance of systems in a benchmark. We provide a first instantiation
of this paradigm for knowledge-graph-based question answering systems. We
compute explanations by using a novel concept learning approach developed for
large knowledge graphs called PruneCEL. Our evaluation shows that PruneCEL
outperforms state-of-the-art concept learners on the task of explainable
benchmarking by up to 0.55 points F1 measure. A task-driven user study with 41
participants shows that in 80\% of the cases, the majority of participants can
accurately predict the behavior of a system based on our explanations. Our code
and data are available at https://github.com/dice-group/PruneCEL/tree/K-cap2025

</details>


### [287] [MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction](https://arxiv.org/abs/2510.20448)
*Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan*

Main category: cs.LG

TL;DR: MolBridge是一个新的原子级别联合图细化框架，用于预测药物-药物相互作用（DDI）。它通过构建整合药物对原子结构的联合图来直接建模药物间的相互作用，并引入一个结构一致性模块来解决信息丢失问题，从而学习局部和全局的相互作用模式。


<details>
  <summary>Details</summary>
Motivation: 现有的DDI预测方法在处理复杂的分子结构和细粒度的分子间相互作用方面存在局限性，导致在预测常见的和罕见的DDI类型时效果不佳。

Method: MolBridge构建了一个联合图，整合了药物对的原子结构，并使用一个结构一致性模块来迭代地细化节点特征，同时保持全局结构背景，以克服过度平滑问题。

Result: MolBridge在两个基准数据集上进行了广泛的实验，结果表明其性能优于最先进的方法，尤其在长尾和归纳场景下表现更佳。

Conclusion: 精细化的图细化在提高DDI事件预测的准确性、鲁棒性和可解释性方面具有优势，为Web挖掘和内容分析领域贡献了基于图的方法来挖掘和分析DDI网络。

Abstract: Drug combinations offer therapeutic benefits but also carry the risk of
adverse drug-drug interactions (DDIs), especially under complex molecular
structures. Accurate DDI event prediction requires capturing fine-grained
inter-drug relationships, which are critical for modeling metabolic mechanisms
such as enzyme-mediated competition. However, existing approaches typically
rely on isolated drug representations and fail to explicitly model atom-level
cross-molecular interactions, limiting their effectiveness across diverse
molecular complexities and DDI type distributions. To address these
limitations, we propose MolBridge, a novel atom-level joint graph refinement
framework for robust DDI event prediction. MolBridge constructs a joint graph
that integrates atomic structures of drug pairs, enabling direct modeling of
inter-drug associations. A central challenge in such joint graph settings is
the potential loss of information caused by over-smoothing when modeling
long-range atomic dependencies. To overcome this, we introduce a structure
consistency module that iteratively refines node features while preserving the
global structural context. This joint design allows MolBridge to effectively
learn both local and global interaction outperforms state-of-the-art baselines,
achieving superior performance across long-tail and inductive scenarios.
patterns, yielding robust representations across both frequent and rare DDI
types. Extensive experiments on two benchmark datasets show that MolBridge
consistently. These results demonstrate the advantages of fine-grained graph
refinement in improving the accuracy, robustness, and mechanistic
interpretability of DDI event prediction.This work contributes to Web Mining
and Content Analysis by developing graph-based methods for mining and analyzing
drug-drug interaction networks.

</details>


### [288] [Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach](https://arxiv.org/abs/2510.20454)
*Lawrence Clegg,John Cartlidge*

Main category: cs.LG

TL;DR: 网球比赛中存在不寻常的玩家主导关系，即A胜B，B胜C，但C胜A。本文提出了一种图神经网络方法来解决这个问题，该方法通过时态有向图对这些不寻常的关系进行建模。


<details>
  <summary>Details</summary>
Motivation: 解决在预测方法中纳入不寻常玩家主导关系的问题，因为这种关系在竞技网球中很常见。

Method: 使用图神经网络，通过时态有向图对玩家及其历史比赛结果进行建模，以明确地表示不寻常的关系。

Result: 发现书商 Pinnacle Sports 在处理高度不寻常的比赛方面存在不足。该模型在选择性投注于更高不寻常性的对决时，准确率为 65.7%，Brier得分为 0.215。在 1903 场投注中，使用 Kelly 投注策略实现了 3.26% 的投资回报率。

Conclusion: 该图模型能够捕捉这些场景中的关系动态。存在一个市场效率低下，即在处理不寻常的对决时，该模型能够利用这一点。

Abstract: Intransitive player dominance, where player A beats B, B beats C, but C beats
A, is common in competitive tennis. Yet, there are few known attempts to
incorporate it within forecasting methods. We address this problem with a graph
neural network approach that explicitly models these intransitive relationships
through temporal directed graphs, with players as nodes and their historical
match outcomes as directed edges. We find the bookmaker Pinnacle Sports poorly
handles matches with high intransitive complexity and posit that our
graph-based approach is uniquely positioned to capture relational dynamics in
these scenarios. When selectively betting on higher intransitivity matchups
with our model (65.7% accuracy, 0.215 Brier Score), we achieve significant
positive returns of 3.26% ROI with Kelly staking over 1903 bets, suggesting a
market inefficiency in handling intransitive matchups that our approach
successfully exploits.

</details>


### [289] [Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models](https://arxiv.org/abs/2510.20468)
*Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko*

Main category: cs.LG

TL;DR: 该研究提出了一种新的数字内容水印伪造方法，该方法通过优化生成图像来移除和伪造水印，并且只需要一张带水印的图像，无需了解水印模型，大大简化了攻击过程，并对现有水印技术的安全性提出了质疑。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型和法律压力的激增，数字内容水印技术受到越来越多的关注，但目前对水印伪造的研究不足。

Method: 提出了一种偏好模型来评估图像是否被水印，并使用反向传播优化输入图像来实现水印的移除和伪造。

Result: 提出的方法在多种后处理图像水印模型上进行了评估，证明了其有效性，能够成功伪造水印。

Conclusion: 现有的图像水印技术在面对这种简化的、无需了解水印模型的攻击时，安全性存在疑问。

Abstract: Recent years have seen a surge in interest in digital content watermarking
techniques, driven by the proliferation of generative models and increased
legal pressure. With an ever-growing percentage of AI-generated content
available online, watermarking plays an increasingly important role in ensuring
content authenticity and attribution at scale. There have been many works
assessing the robustness of watermarking to removal attacks, yet, watermark
forging, the scenario when a watermark is stolen from genuine content and
applied to malicious content, remains underexplored. In this work, we
investigate watermark forging in the context of widely used post-hoc image
watermarking. Our contributions are as follows. First, we introduce a
preference model to assess whether an image is watermarked. The model is
trained using a ranking loss on purely procedurally generated images without
any need for real watermarks. Second, we demonstrate the model's capability to
remove and forge watermarks by optimizing the input image through
backpropagation. This technique requires only a single watermarked image and
works without knowledge of the watermarking model, making our attack much
simpler and more practical than attacks introduced in related work. Third, we
evaluate our proposed method on a variety of post-hoc image watermarking
models, demonstrating that our approach can effectively forge watermarks,
questioning the security of current watermarking approaches. Our code and
further resources are publicly available.

</details>


### [290] [Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models](https://arxiv.org/abs/2510.20477)
*Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: Bi-CoG是一种新的半监督微调方法，通过结合模型间和模型内的一致性以及动态伪标签分配策略，有效解决了现有方法中的模型偏差和超参数敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的结合预训练视觉-语言模型（VLM）微调与半监督学习（SSL）的方法，在处理标签稀疏场景时，常因依赖预测一致性或预定义置信度阈值而面临模型偏差和超参数敏感性的问题。

Method: 提出了一种名为Bi-CoG（Bi-Consistency-Guided Self-Training）的即插即用方法，该方法通过同时利用模型间和模型内的一致性，并结合误差感知动态伪标签分配策略，来生成高质量、低偏差的伪标签。

Result: 在14个数据集上的理论分析和广泛实验表明，Bi-CoG能够稳定且显著地提升现有方法的性能。

Conclusion: Bi-CoG是一种有效的方法，能够克服现有半监督微调方法的局限性，并显著提升模型性能。

Abstract: Exploiting unlabeled data through semi-supervised learning (SSL) or
leveraging pre-trained models via fine-tuning are two prevailing paradigms for
addressing label-scarce scenarios. Recently, growing attention has been given
to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,
forming the emerging paradigm of semi-supervised fine-tuning. However, existing
methods often suffer from model bias and hyperparameter sensitivity, due to
reliance on prediction consistency or pre-defined confidence thresholds. To
address these limitations, we propose a simple yet effective plug-and-play
methodology named
$\underline{\textbf{Bi-Co}}$nsistency-$\underline{\textbf{G}}$uided
Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,
by simultaneously exploiting inter-model and intra-model consistency, along
with an error-aware dynamic pseudo-label assignment strategy. Both theoretical
analysis and extensive experiments over 14 datasets demonstrate the
effectiveness of Bi-CoG, which consistently and significantly improves the
performance of existing methods.

</details>


### [291] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 本研究提出了一种名为“障碍-逆模型去偏学习”（IMDL）的框架，用于解决定量遥感中标签分布不平衡的问题，特别是在降雨反演中对强降雨样本的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能定量遥感方法受到标签分布不平衡的限制，导致模型偏向常见样本，损害了稀有样本的检索性能，尤其是在降雨反演中对强降雨的性能表现不佳。

Method: 该研究将降雨分布的不平衡分解为零膨胀（非降雨样本占主导）和长尾（轻雨样本相对于强雨样本的比例失衡）两个部分。采用障碍模型处理零膨胀，并提出IMDL通过将学习对象转变为无偏的理想逆模型来解决长尾问题。

Result: 通过统计指标和中国东部降雨天气案例研究的综合评估，证明了Hurdle-IMDL相比于传统、代价敏感、生成和多任务学习方法具有优越性。该方法有效减轻了系统性低估，并显著提高了强降雨到极端降雨的检索精度。

Conclusion: IMDL提供了一种解决环境变量分布不平衡问题的通用方法，能够增强对罕见但影响重大的事件的检索能力。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [292] [SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment](https://arxiv.org/abs/2510.20540)
*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: SheafAlign是一个去中心化的多模态对齐框架，采用多重比较空间代替单空间对齐，通过片结构模拟模态间关系，并利用去中心化对比学习进行训练。该方法无需所有模态间的相互冗余，能保留共享和独有信息，在零样本泛化、跨模态对齐和对缺失模态的鲁棒性方面表现优于现有方法，同时通信成本降低50%。


<details>
  <summary>Details</summary>
Motivation: 传统多模态对齐方法假设所有模态间存在相互冗余，但在实际分布式场景下此假设不成立。

Method: 提出SheafAlign，一个基于片理论的去中心化多模态对齐框架。该框架用多个比较空间替代单一空间对齐，通过片结构对模态间的成对关系进行建模，并利用基于去中心化对比学习的目标进行训练。

Result: 在多模态传感数据集上的实验表明，SheafAlign具有优越的零样本泛化能力、跨模态对齐能力和对缺失模态的鲁棒性，且通信成本比现有最先进基线低50%。

Conclusion: SheafAlign克服了现有方法的局限性，无需所有模态间的相互冗余，能够保留共享和独有的信息。

Abstract: Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

</details>


### [293] [A Unified Framework for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.20542)
*Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 零样本强化学习（RL）领域的研究缺乏统一的分析框架。本文提出了首个统一框架，对现有方法进行分类（直接表示和组合表示），并分析了它们的异同。该框架为零样本RL的未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 零样本强化学习（RL）作为一种无需额外训练或测试时规划即可解决下游任务的通用智能体开发场景，受到了广泛关注。然而，该领域缺乏一个统一的分析框架来组织和比较现有方法。

Method: 提出一个统一的框架，对零样本RL算法进行分类，分为“直接表示”和“组合表示”两大家族。此外，还推导了用于后继特征方法的扩展界限。

Result: 该框架对现有方法进行了分类和比较，明确了它们的共同点和关键区别。推导出的后继特征方法界限为零样本场景下的性能提供了新的视角。

Conclusion: 本文提出的统一框架为零样本RL领域的研究提供了原则性基础，并为开发更通用的智能体指明了方向。

Abstract: Zero-shot reinforcement learning (RL) has emerged as a setting for developing
general agents in an unsupervised manner, capable of solving downstream tasks
without additional training or planning at test-time. Unlike conventional RL,
which optimizes policies for a fixed reward, zero-shot RL requires agents to
encode representations rich enough to support immediate adaptation to any
objective, drawing parallels to vision and language foundation models. Despite
growing interest, the field lacks a common analytical lens.
  We present the first unified framework for zero-shot RL. Our formulation
introduces a consistent notation and taxonomy that organizes existing
approaches and allows direct comparison between them. Central to our framework
is the classification of algorithms into two families: direct representations,
which learn end-to-end mappings from rewards to policies, and compositional
representations, which decompose the representation leveraging the substructure
of the value function. Within this framework, we highlight shared principles
and key differences across methods, and we derive an extended bound for
successor-feature methods, offering a new perspective on their performance in
the zero-shot regime. By consolidating existing work under a common lens, our
framework provides a principled foundation for future research in zero-shot RL
and outlines a clear path toward developing more general agents.

</details>


### [294] [Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics](https://arxiv.org/abs/2510.20556)
*Alexandre Benoit,Catherine Aitken,Yu He*

Main category: cs.LG

TL;DR: 研究图重构对GNN性能和结构保真度的影响，发现成功的重构方法倾向于保留局部结构。


<details>
  <summary>Details</summary>
Motivation: 图重构是缓解GNN中过度挤压的关键技术，但会改变图的拓扑结构，可能扭曲重要的依赖于拓扑的信号。然而，目前对于哪些结构属性必须保留以确保性能提升和结构保真度知之甚少。

Method: 系统分析了七种不同的图重构策略对多种图结构指标的影响，并将这些变化与节点分类准确性相关联。

Result: 研究发现，成功的图重构方法倾向于保留局部结构，同时允许在全局连通性方面具有灵活性。

Conclusion: 图重构的成功与否取决于其保留局部结构的能力，这为设计更有效的图重构策略提供了新的见解。

Abstract: Graph rewiring has emerged as a key technique to alleviate over-squashing in
Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph
topology to improve information flow. While effective, rewiring inherently
alters the graph's structure, raising the risk of distorting important
topology-dependent signals. Yet, despite the growing use of rewiring, little is
known about which structural properties must be preserved to ensure both
performance gains and structural fidelity. In this work, we provide the first
systematic analysis of how rewiring affects a range of graph structural
metrics, and how these changes relate to downstream task performance. We study
seven diverse rewiring strategies and correlate changes in local and global
graph properties with node classification accuracy. Our results reveal a
consistent pattern: successful rewiring methods tend to preserve local
structure while allowing for flexibility in global connectivity. These findings
offer new insights into the design of effective rewiring strategies, bridging
the gap between graph theory and practical GNN optimization.

</details>


### [295] [Embedding the MLOps Lifecycle into OT Reference Models](https://arxiv.org/abs/2510.20590)
*Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber*

Main category: cs.LG

TL;DR: MLOps 与 OT 系统集成面临挑战，本文提出通过 RAMI 4.0 和 ISA-95 等参考模型进行适配，并展示了 MLOps 生命周期组件到 RAMI 4.0 的映射，证明了结构化适配是成功集成的途径。


<details>
  <summary>Details</summary>
Motivation: 工业界 MLOps 实践日益普及，但与运营技术（OT）系统集成存在挑战。

Method: 分析 MLOps 与 OT 环境集成的根本障碍，提出将 MLOps 实践嵌入现有 OT 参考模型（RAMI 4.0 和 ISA-95）的系统方法，并将 MLOps 生命周期组件映射到 RAMI 4.0。

Result: 标准 MLOps 实践不能直接应用于 OT 环境，但使用现有参考模型进行结构化适配可以实现成功集成。

Conclusion: 通过对 RAMI 4.0 和 ISA-95 的评估以及 MLOps 生命周期组件到 RAMI 4.0 的映射，证明了结构化适配是 MLOps 与 OT 环境成功集成的可行路径。

Abstract: Machine Learning Operations (MLOps) practices are increas- ingly adopted in
industrial settings, yet their integration with Opera- tional Technology (OT)
systems presents significant challenges. This pa- per analyzes the fundamental
obstacles in combining MLOps with OT en- vironments and proposes a systematic
approach to embed MLOps prac- tices into established OT reference models. We
evaluate the suitability of the Reference Architectural Model for Industry 4.0
(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for
MLOps integration and present a detailed mapping of MLOps lifecycle compo-
nents to RAMI 4.0 exemplified by a real-world use case. Our findings
demonstrate that while standard MLOps practices cannot be directly transplanted
to OT environments, structured adaptation using existing reference models can
provide a pathway for successful integration.

</details>


### [296] [Generalizable Reasoning through Compositional Energy Minimization](https://arxiv.org/abs/2510.20607)
*Alexandru Oarga,Yilun Du*

Main category: cs.LG

TL;DR: 提出一种通过学习解决更小、更易处理的子问题的解空间上的能量景观来提高推理泛化能力的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练过程中直接将输入实例映射到解决方案，这会限制模型在训练数据分布之外的泛化能力。然而，泛化能力是机器学习中的一个关键挑战，尤其是在推理任务中，模型需要解决比训练期间遇到的问题更复杂的问题。

Method: 通过学习解空间上更小、更易处理的子问题的能量景观。在测试时，通过组合多个子问题的能量函数来为给定的问题构建全局能量景观。这种组合方法允许在推理过程中纳入额外的约束，从而为难度不断增加的问题构建能量景观。为了提高从新构建的能量景观中采样的质量，引入了并行能量最小化（PEM）。

Result: 该方法在广泛的推理问题上进行了评估，并且优于现有的最先进方法，证明了其泛化到更大、更复杂问题的能力。

Conclusion: 该组合方法能够泛化到更大、更复杂的问题。

Abstract: Generalization is a key challenge in machine learning, specifically in
reasoning tasks, where models are expected to solve problems more complex than
those encountered during training. Existing approaches typically train
reasoning models in an end-to-end fashion, directly mapping input instances to
solutions. While this allows models to learn useful heuristics from data, it
often results in limited generalization beyond the training distribution. In
this work, we propose a novel approach to reasoning generalization by learning
energy landscapes over the solution spaces of smaller, more tractable
subproblems. At test time, we construct a global energy landscape for a given
problem by combining the energy functions of multiple subproblems. This
compositional approach enables the incorporation of additional constraints
during inference, allowing the construction of energy landscapes for problems
of increasing difficulty. To improve the sample quality from this newly
constructed energy landscape, we introduce Parallel Energy Minimization (PEM).
We evaluate our approach on a wide set of reasoning problems. Our method
outperforms existing state-of-the-art methods, demonstrating its ability to
generalize to larger and more complex problems. Project website can be found
at: https://alexoarga.github.io/compositional_reasoning/

</details>


### [297] [Convergence Analysis of SGD under Expected Smoothness](https://arxiv.org/abs/2510.20608)
*Yuta Kawamoto,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 该论文在期望平滑性（ES）条件下，对随机梯度下降（SGD）进行了收敛性分析，提供了改进的理论界限和明确的残差误差。


<details>
  <summary>Details</summary>
Motivation: 现有随机梯度下降（SGD）的分析依赖于过于严格或粗糙的假设，而期望平滑性（ES）条件提供了一种更灵活的替代方法，但需要更深入的分析。

Method: 通过（i）细化ES条件并引入与采样相关的常数，（ii）推导完整梯度范数平方的期望界限，以及（iii）在ES条件下证明具有明确残差误差的$O(1/K)$收敛速率。

Result: 实现了SGD在ES条件下的收敛性分析，推导了梯度范数平方的界限，并得到了明确的残差误差和$O(1/K)$收敛速率。

Conclusion: 在期望平滑性（ES）条件下，对SGD进行了自包含的收敛性分析，统一并扩展了现有的研究成果。

Abstract: Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

</details>


### [298] [Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets](https://arxiv.org/abs/2510.20609)
*Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov*

Main category: cs.LG

TL;DR: 在实际计算预算下，针对代码生成任务进行检索设计。研究了代码补全和错误定位两个任务，比较了不同分块策略、相似度评分和拆分粒度下的检索配置。发现在代码-代码任务中，BM25稀疏检索效果最好；在自然语言-代码任务中，稠密编码器效果更好但延迟更高。最优分块大小与上下文窗口大小相关，检索延迟因配置而异。最终为代码检索系统提供了基于任务需求、模型约束和计算效率的实用建议。


<details>
  <summary>Details</summary>
Motivation: 评估在实际计算预算下，针对代码生成任务的检索设计，以提供有效的代码检索系统实现建议。

Method: 系统地比较了两种代码生成任务（代码补全和错误定位）的不同检索配置，包括分块策略、相似度评分和拆分粒度，并分析了其在不同上下文窗口大小下的表现和计算效率。

Result: 1. 对于代码-代码任务，BM25稀疏检索在分块粒度上最优，比稠密检索快10倍。 2. 对于自然语言-代码任务，稠密编码器效果优于稀疏检索，但延迟高100倍。 3. 最优分块大小随上下文窗口大小变化，小上下文窗口下64行分块效果好，大上下文窗口下整文件检索更具竞争力。 4. 行级分块与语法感知分块效果相当。 5. 检索延迟差异最大可达200倍，BM25+词级分块在质量-延迟权衡方面表现最佳。

Conclusion: 基于任务需求、模型约束和计算效率，提供了代码检索系统设计的实用建议。

Abstract: We study retrieval design for code-focused generation tasks under realistic
compute budgets. Using two complementary tasks from Long Code Arena -- code
completion and bug localization -- we systematically compare retrieval
configurations across various context window sizes along three axes: (i)
chunking strategy, (ii) similarity scoring, and (iii) splitting granularity.
(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and
practical, significantly outperforming dense alternatives while being an order
of magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3
family) consistently beat sparse retrievers, however requiring 100x larger
latency. (3) Optimal chunk size scales with available context: 32-64 line
chunks work best at small budgets, and whole-file retrieval becomes competitive
at 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting
across budgets. (5) Retrieval latency varies by up to 200x across
configurations; BPE-based splitting is needlessly slow, and BM25 + word
splitting offers the best quality-latency trade-off. Thus, we provide
evidence-based recommendations for implementing effective code-oriented RAG
systems based on task requirements, model constraints, and computational
efficiency.

</details>


### [299] [BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792)
*Liang Ye,Shengqin Chen,Jiazhu Dai*

Main category: cs.LG

TL;DR: 本论文提出了一种名为BadGraph的后门攻击方法，专门针对文本引导的图生成潜在扩散模型。


<details>
  <summary>Details</summary>
Motivation: 由于文本引导的图生成模型（如在药物发现中）日益普及，存在被利用于后门攻击的风险，但现有研究对此类攻击的关注不足。

Method: BadGraph利用文本触发器来污染训练数据，从而在推理时，当触发器出现时，诱导模型生成攻击者指定的子图，同时在干净输入上保持正常性能。该攻击主要在VAE和扩散模型训练阶段植入后门。

Result: 在四个基准数据集（PubChem, ChEBI-20, PCDes, MoMu）上的实验表明，BadGraph具有高效性和隐蔽性。较低的污染率（<10%）即可达到50%的攻击成功率，而80%的成功率仅需24%的污染率，且对良性样本的性能影响极小。

Conclusion: BadGraph揭示了文本引导的图生成潜在扩散模型存在的安全漏洞，强调了此类模型在药物发现等应用中面临的严重风险，并指出了开发针对此类后门攻击的鲁棒防御机制的必要性。

Abstract: The rapid progress of graph generation has raised new security concerns,
particularly regarding backdoor vulnerabilities. While prior work has explored
backdoor attacks in image diffusion and unconditional graph generation,
conditional, especially text-guided graph generation remains largely
unexamined. This paper proposes BadGraph, a backdoor attack method targeting
latent diffusion models for text-guided graph generation. BadGraph leverages
textual triggers to poison training data, covertly implanting backdoors that
induce attacker-specified subgraphs during inference when triggers appear,
while preserving normal performance on clean inputs. Extensive experiments on
four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the
effectiveness and stealth of the attack: less than 10% poisoning rate can
achieves 50% attack success rate, while 24% suffices for over 80% success rate,
with negligible performance degradation on benign samples. Ablation studies
further reveal that the backdoor is implanted during VAE and diffusion training
rather than pretraining. These findings reveal the security vulnerabilities in
latent diffusion models of text-guided graph generation, highlight the serious
risks in models' applications such as drug discovery and underscore the need
for robust defenses against the backdoor attack in such diffusion models.

</details>


### [300] [PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection](https://arxiv.org/abs/2510.20611)
*Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: 本研究提出了一个集成框架，结合定制的粒子群优化（PSO）进行特征选择，用于乳腺癌诊断。该框架在29种不同模型上进行了评估，并结合了交叉验证和可解释人工智能方法以确保临床相关性。实验结果表明，该方法在提高准确性和精确度的同时，有效降低了维度，并提供了透明、模型无关的解释，实现了99.1%的优越分数。


<details>
  <summary>Details</summary>
Motivation: 传统的乳腺癌诊断方法存在变异性、成本高和误诊风险等局限性。机器学习（ML）作为一种强大的工具，在特征选择方面发挥着关键作用，可以提高模型的性能和可解释性。因此，本研究旨在通过集成框架来解决这些挑战。

Method: 本研究提出了一个集成框架，其中包含定制的粒子群优化（PSO）用于特征选择。该框架在29种不同的模型上进行了评估，包括经典分类器、集成技术、神经网络、概率算法和基于实例的算法。此外，还结合了交叉验证和可解释人工智能（XAI）方法，以确保模型的可解释性和临床相关性。

Result: 实验评估表明，所提出的方法在准确率和精确度等所有性能指标上均取得了99.1%的优越分数。同时，该方法有效降低了数据的维度，并提供了透明、模型无关的解释。

Conclusion: 研究结果强调了结合群体智能与可解释机器学习在实现可靠、可信且具有临床意义的乳腺癌诊断方面的潜力。

Abstract: Breast cancer is considered the most critical and frequently diagnosed cancer
in women worldwide, leading to an increase in cancer-related mortality. Early
and accurate detection is crucial as it can help mitigate possible threats
while improving survival rates. In terms of prediction, conventional diagnostic
methods are often limited by variability, cost, and, most importantly, risk of
misdiagnosis. To address these challenges, machine learning (ML) has emerged as
a powerful tool for computer-aided diagnosis, with feature selection playing a
vital role in improving model performance and interpretability. This research
study proposes an integrated framework that incorporates customized Particle
Swarm Optimization (PSO) for feature selection. This framework has been
evaluated on a comprehensive set of 29 different models, spanning classical
classifiers, ensemble techniques, neural networks, probabilistic algorithms,
and instance-based algorithms. To ensure interpretability and clinical
relevance, the study uses cross-validation in conjunction with explainable AI
methods. Experimental evaluation showed that the proposed approach achieved a
superior score of 99.1\% across all performance metrics, including accuracy and
precision, while effectively reducing dimensionality and providing transparent,
model-agnostic explanations. The results highlight the potential of combining
swarm intelligence with explainable ML for robust, trustworthy, and clinically
meaningful breast cancer diagnosis.

</details>


### [301] [Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples](https://arxiv.org/abs/2510.20800)
*Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus*

Main category: cs.LG

TL;DR: LASER通过移除LLM权重矩阵的高阶分量来提高下游任务的准确性，但其搜索过程耗时。本文提出了一种改进方法，通过仅检查一小部分关键矩阵、利用奇异值梯度来识别可约简矩阵、允许矩阵行在多个子空间聚类并分别分解以减少过拟合、以及使用100个样本进行评估来显著减少搜索时间，最终实现无需微调即可快速适应下游任务。


<details>
  <summary>Details</summary>
Motivation: LASER方法虽然有效，但其搜索过程效率低下，不适合快速部署。

Method: 1. 仅检查一小部分关键矩阵，无需逐层检查。
2. 利用奇异值梯度来识别需要约简的矩阵。
3. 允许矩阵行在多个子空间聚类并分别分解，以减少过拟合。
4. 使用100个样本进行梯度计算和准确性评估。

Result: 1. 搜索时间大大缩短。
2. 准确性最高可提升24.6个百分点。
3. 实现了无需梯度微调的快速模型适应。

Conclusion: 结合上述发现，提出了一种快速、鲁棒的下游任务适应算法，仅需单步梯度下降、100个样本以及对候选层和分解技术的快速扫描，即可在不进行微调的情况下适应新数据集。

Abstract: Recently, Sharma et al. suggested a method called Layer-SElective-Rank
reduction (LASER) which demonstrated that pruning high-order components of
carefully chosen LLM's weight matrices can boost downstream accuracy -- without
any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each
requiring full-dataset forward passes) makes it impractical for rapid
deployment. We demonstrate that this overhead can be removed and find that: (i)
Only a small, carefully chosen subset of matrices needs to be inspected --
eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's
singular values pinpoints which matrices merit reduction, (iii) Increasing the
factorization search space by allowing matrices rows to cluster around multiple
subspaces and then decomposing each cluster separately further reduces
overfitting on the original training data and further lifts accuracy by up to
24.6 percentage points, and finally, (iv) we discover that evaluating on just
100 samples rather than the full training data -- both for computing the
indicative gradients and for measuring the final accuracy -- suffices to
further reduce the search time; we explain that as adaptation to downstream
tasks is dominated by prompting style, not dataset size. As a result, we show
that combining these findings yields a fast and robust adaptation algorithm for
downstream tasks. Overall, with a single gradient step on 100 examples and a
quick scan of the top candidate layers and factorization techniques, we can
adapt LLMs to new datasets -- entirely without fine-tuning.

</details>


### [302] [MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation](https://arxiv.org/abs/2510.20615)
*Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen*

Main category: cs.LG

TL;DR: MS-BART通过将质谱和分子结构映射到共享词汇表中，利用大规模预训练来解决质谱数据稀缺的问题，并通过多任务预训练、在实验光谱上的微调以及化学反馈机制来提高准确性和鲁棒性，最终在MassSpecGym和NPLIB1数据集上取得了最先进的性能，并且速度比现有方法快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标注光谱，从质谱数据中进行结构解析仍然是一个挑战。现有的预训练方法难以应用于质谱，因为原始光谱信号复杂且不均匀。

Method: 提出了一种名为MS-BART的统一建模框架，将质谱和分子结构映射到共享的词汇表中，从而实现大规模预训练下的跨模态学习。通过联合优化去噪和翻译任务的多任务预训练目标来增强泛化能力。在预训练后，通过在MIST生成的指纹预测上进行微调，将模型迁移到实验光谱。引入化学反馈机制来指导模型生成更接近参考结构的分子。

Result: MS-BART在MassSpecGym和NPLIB1数据集的12项关键指标中的5项上取得了最先进的性能，并且比基于扩散的方法快一个数量级。消融研究也验证了模型的有效性和鲁棒性。

Conclusion: MS-BART在解决质谱数据稀缺和提高结构解析准确性方面取得了显著进展，但仍需进一步优化以解决分子幻觉问题并实现更完美的对齐。

Abstract: Mass spectrometry (MS) plays a critical role in molecular identification,
significantly advancing scientific discovery. However, structure elucidation
from MS data remains challenging due to the scarcity of annotated spectra.
While large-scale pretraining has proven effective in addressing data scarcity
in other domains, applying this paradigm to mass spectrometry is hindered by
the complexity and heterogeneity of raw spectral signals. To address this, we
propose MS-BART, a unified modeling framework that maps mass spectra and
molecular structures into a shared token vocabulary, enabling cross-modal
learning through large-scale pretraining on reliably computed
fingerprint-molecule datasets. Multi-task pretraining objectives further
enhance MS-BART's generalization by jointly optimizing denoising and
translation task. The pretrained model is subsequently transferred to
experimental spectra through finetuning on fingerprint predictions generated
with MIST, a pre-trained spectral inference model, thereby enhancing robustness
to real-world spectral variability. While finetuning alleviates the
distributional difference, MS-BART still suffers molecular hallucination and
requires further alignment. We therefore introduce a chemical feedback
mechanism that guides the model toward generating molecules closer to the
reference structure. Extensive evaluations demonstrate that MS-BART achieves
SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is
faster by one order of magnitude than competing diffusion-based methods, while
comprehensive ablation studies systematically validate the model's
effectiveness and robustness.

</details>


### [303] [On Optimal Hyperparameters for Differentially Private Deep Transfer Learning](https://arxiv.org/abs/2510.20616)
*Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela*

Main category: cs.LG

TL;DR: DP迁移学习中，理论与实践对超参数 C（裁剪界限）和 B（批大小）的选择存在不匹配。理论上 C 越小隐私性越强，但实践中 C 越大效果越好，原因是梯度分布的变化。在有限计算预算下，现有 B 的调整方法失效，累积 DP 噪声更能解释批大小对性能的影响。在不同隐私要求和计算资源下，跨任务使用单一 (C,B) 设置会导致性能下降，裁剪可视为梯度重加权，累积 DP 噪声可解释此现象。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决差分隐私（DP）迁移学习中超参数（裁剪界限 C 和批大小 B）选择的理论与实践不匹配问题，并提出更有效的调整策略。

Method: 通过分析梯度分布的变化，探讨 C 对隐私和性能的影响；在固定训练周期（计算预算有限）的假设下，研究累积 DP 噪声如何影响 B 的选择；分析裁剪作为梯度重加权的作用，以及累积 DP 噪声在不同隐私和计算资源下，跨任务使用单一 (C,B) 设置导致性能下降的原因。

Result: 发现理论与实践在 C 的选择上存在不匹配（理论上 C 越小隐私越强，实践中 C 越大效果越好）；证明现有 B 的调整方法在计算预算有限时失效，累积 DP 噪声更能解释 B 的选择；论证了跨任务使用单一 (C,B) 设置会导致性能下降，尤其是在隐私要求变化或计算资源有限时。

Conclusion: DP 迁移学习中 C 和 B 的选择需要结合理论与实践，不能仅依赖现有理论。累积 DP 噪声是理解 B 选择的关键，而裁剪可被视为一种梯度重加权。在实际应用中，应根据具体任务的隐私要求和计算资源动态调整 (C,B) 设置，而非使用单一固定值。

Abstract: Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained
model on private data, is the current state-of-the-art approach for training
large models under privacy constraints. We focus on two key hyperparameters in
this setting: the clipping bound $C$ and batch size $B$. We show a clear
mismatch between the current theoretical understanding of how to choose an
optimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes
(larger $C$ performs better under strong privacy), caused by changes in the
gradient distributions. Assuming a limited compute budget (fixed epochs), we
demonstrate that the existing heuristics for tuning $B$ do not work, while
cumulative DP noise better explains whether smaller or larger batches perform
better. We also highlight how the common practice of using a single $(C,B)$
setting across tasks can lead to suboptimal performance. We find that
performance drops especially when moving between loose and tight privacy and
between plentiful and limited compute, which we explain by analyzing clipping
as a form of gradient re-weighting and examining cumulative DP noise.

</details>


### [304] [H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition](https://arxiv.org/abs/2510.20627)
*Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis*

Main category: cs.LG

TL;DR: H-SPLID是一种新算法，通过将显著和非显著特征显式地分解到单独的空间中来学习显著特征表示。它能促进学习低维、任务相关的特征，并将鲁棒性与潜在表示压缩联系起来。实验表明，H-SPLID模型主要依赖于显著的输入成分，对非显著特征（如背景）的扰动不敏感。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过显式分解显著和非显著特征来学习显著特征表示，从而促进学习低维、任务相关的特征，并将鲁棒性与潜在表示压缩联系起来。

Method: 提出了一种名为H-SPLID的新算法，该算法将显著特征和非显著特征显式地分解到单独的空间中。

Result: H-SPLID促进了低维、任务相关特征的学习。研究证明了在输入扰动下的预期预测偏差有上限，该上限与显著子空间的维度和输入与表示之间的Hilbert-Schmidt独立准则（HSIC）有关。实验表明，H-SPLID模型对非显著特征（如背景）的扰动不敏感。

Conclusion: H-SPLID算法在图像分类任务上表现良好，模型主要依赖于显著的输入成分，并且对非显著特征的扰动不敏感。该算法将鲁棒性与潜在表示压缩联系起来。

Abstract: We introduce H-SPLID, a novel algorithm for learning salient feature
representations through the explicit decomposition of salient and non-salient
features into separate spaces. We show that H-SPLID promotes learning
low-dimensional, task-relevant features. We prove that the expected prediction
deviation under input perturbations is upper-bounded by the dimension of the
salient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between
inputs and representations. This establishes a link between robustness and
latent representation compression in terms of the dimensionality and
information preserved. Empirical evaluations on image classification tasks show
that models trained with H-SPLID primarily rely on salient input components, as
indicated by reduced sensitivity to perturbations affecting non-salient
features, such as image backgrounds. Our code is available at
https://github.com/neu-spiral/H-SPLID.

</details>


### [305] [Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach](https://arxiv.org/abs/2510.20629)
*Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu*

Main category: cs.LG

TL;DR: 提出了一种名为FASM（Fairness-Aware Survival Modeling）的新方法，旨在解决机器学习在医疗保健中的公平性问题，特别是在生存分析中，通过同时考虑组内和跨组风险排序来减少算法偏见。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在医疗保健中的应用可能加剧因临床数据中存在的结构性不平等和社会偏见而导致的算法偏见，尤其是在生存分析中，删失和时间动态增加了公平模型开发的复杂性。现有的公平性算法常常忽略跨组排名差异，导致高风险的少数族裔患者可能被排在低风险的多数族裔患者之前，从而加剧了生物本质主义并损害了公平的医疗护理。

Method: 提出并应用了一种名为FASM（Fairness-Aware Survival Modeling）的方法，该方法旨在解决算法偏见问题，特别关注组内和跨组风险排序。通过对SEER乳腺癌数据进行分析，将FASM应用于乳腺癌预后预测。

Result: 与未考虑公平性的模型相比，FASM在提高公平性的同时，保持了相当的区分性能。时间分层评估显示，FASM在10年的时间跨度内保持了稳定的公平性，其中在随访中期观察到最大的改进。

Conclusion: FASM能够实现准确性和公平性兼备的生存模型，促进了公平性成为临床护理的核心原则，从而在临床决策中优先考虑准确性和公平性。

Abstract: As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.

</details>


### [306] [Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges](https://arxiv.org/abs/2510.20637)
*Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim*

Main category: cs.LG

TL;DR: LLMs/LMMs 在 6G 自动化通信中展现出巨大潜力，通过多模态感知、自适应重构和提示/微调策略，在交通控制、机器人调度和信道估计等任务中显著优于传统 DL 模型。


<details>
  <summary>Details</summary>
Motivation: LLMs/LMMs 的突破性能力使其成为 6G 自动化通信的关键驱动力，能够实现机器、车辆和人形机器人之间的通信。

Method: 文章提出并演示了一个基于 LLMs/LMMs 的自动化通信框架，重点关注多模态感知集成、自适应重构以及针对无线任务的提示/微调策略。通过三个案例研究（LMM 交通控制、LLM 机器人调度、LMM 环境感知信道估计）进行论证。

Result: 实验结果表明，所提出的 LLM/LMM 辅助自动化系统在动态目标、变化的输入参数和异构多模态条件下，相比传统的判别式深度学习模型，表现出显著的优越性和鲁棒性，而传统模型在这种情况下性能会下降。

Conclusion: LLM/LMM 能够有效赋能 6G 自动化通信，提供比传统方法更强大、更具适应性的解决方案，尤其是在复杂多变的通信环境中。

Abstract: Large language models (LLMs) and large multimodal models (LMMs) have achieved
unprecedented breakthrough, showcasing remarkable capabilities in natural
language understanding, generation, and complex reasoning. This transformative
potential has positioned them as key enablers for 6G autonomous communications
among machines, vehicles, and humanoids. In this article, we provide an
overview of task-oriented autonomous communications with LLMs/LMMs, focusing on
multimodal sensing integration, adaptive reconfiguration, and
prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework
through three case studies: LMM-based traffic control, LLM-based robot
scheduling, and LMM-based environment-aware channel estimation. From
experimental results, we show that the proposed LLM/LMM-aided autonomous
systems significantly outperform conventional and discriminative deep learning
(DL) model-based techniques, maintaining robustness under dynamic objectives,
varying input parameters, and heterogeneous multimodal conditions where
conventional static optimization degrades.

</details>


### [307] [Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems](https://arxiv.org/abs/2510.20640)
*Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan*

Main category: cs.LG

TL;DR: DiRecGNN是一个用于监控云服务的注意力增强实体推荐框架，通过构建异构图并利用基于Transformer的注意力模型来识别关键属性，以优化监控指标。


<details>
  <summary>Details</summary>
Motivation: 解决云服务监控中选择最优属性子集以进行自动化监控的问题，现有方法因信息有限和难以捕捉长距离依赖而表现不佳。

Method: 提出一个注意力增强的实体推荐模型，利用多头注意力机制关注异构邻居及其属性，并通过随机游走采样路径捕捉长距离依赖，同时采用多面损失函数处理数据稀疏性。

Result: 在MRR（平均排名倒数）上相较于现有方法提升了43.1%，并且产品团队认为该功能非常有用，评分为4.5/5。

Conclusion: DiRecGNN在云服务监控的实体推荐任务上取得了显著的性能提升，并获得了用户的积极反馈。

Abstract: In this paper, we present DiRecGNN, an attention-enhanced entity
recommendation framework for monitoring cloud services at Microsoft. We provide
insights on the usefulness of this feature as perceived by the cloud service
owners and lessons learned from deployment. Specifically, we introduce the
problem of recommending the optimal subset of attributes (dimensions) that
should be tracked by an automated watchdog (monitor) for cloud services. To
begin, we construct the monitor heterogeneous graph at production-scale. The
interaction dynamics of these entities are often characterized by limited
structural and engagement information, resulting in inferior performance of
state-of-the-art approaches. Moreover, traditional methods fail to capture the
dependencies between entities spanning a long range due to their homophilic
nature. Therefore, we propose an attention-enhanced entity ranking model
inspired by transformer architectures. Our model utilizes a multi-head
attention mechanism to focus on heterogeneous neighbors and their attributes,
and further attends to paths sampled using random walks to capture long-range
dependencies. We also employ multi-faceted loss functions to optimize for
relevant recommendations while respecting the inherent sparsity of the data.
Empirical evaluations demonstrate significant improvements over existing
methods, with our model achieving a 43.1% increase in MRR. Furthermore, product
teams who consumed these features perceive the feature as useful and rated it
4.5 out of 5.

</details>


### [308] [Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning](https://arxiv.org/abs/2510.20644)
*Reuben Dorent,Polina Golland,William Wells III*

Main category: cs.LG

TL;DR: 本篇论文推导了JSD与MI之间新的、可行的下界，为基于判别式学习的MI估计提供了理论依据和实证支持。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过最大化JSD等替代度量来估计MI，但其与MI的联系尚不明确。本文旨在弥合这一差距。

Method: 推导了JSD与KLD之间的一般性、可行性下界，并将其应用于联合分布和边缘分布，证明最大化JSD可增加MI的可行下界。同时，分析了基于二元分类器的交叉熵损失与JSD下界的联系。

Result: 实验证明，本文提出的下界在MI估计上具有高度精确性，并且在与现有变分下界估计器对比时，能够提供稳定、低方差的MI下界估计。该方法在信息瓶颈框架中也展现了其实用性。

Conclusion: 本研究为在MI表示学习中使用判别式学习提供了新的理论基础和有力的实验证据。

Abstract: Mutual Information (MI) is a fundamental measure of statistical dependence
widely used in representation learning. While direct optimization of MI via its
definition as a Kullback-Leibler divergence (KLD) is often intractable, many
recent methods have instead maximized alternative dependence measures, most
notably, the Jensen-Shannon divergence (JSD) between joint and product of
marginal distributions via discriminative losses. However, the connection
between these surrogate objectives and MI remains poorly understood. In this
work, we bridge this gap by deriving a new, tight, and tractable lower bound on
KLD as a function of JSD in the general case. By specializing this bound to
joint and marginal distributions, we demonstrate that maximizing the JSD-based
information increases a guaranteed lower bound on mutual information.
Furthermore, we revisit the practical implementation of JSD-based objectives
and observe that minimizing the cross-entropy loss of a binary classifier
trained to distinguish joint from marginal pairs recovers a known variational
lower bound on the JSD. Extensive experiments demonstrate that our lower bound
is tight when applied to MI estimation. We compared our lower bound to
state-of-the-art neural estimators of variational lower bound across a range of
established reference scenarios. Our lower bound estimator consistently
provides a stable, low-variance estimate of a tight lower bound on MI. We also
demonstrate its practical usefulness in the context of the Information
Bottleneck framework. Taken together, our results provide new theoretical
justifications and strong empirical evidence for using discriminative learning
in MI-based representation learning.

</details>


### [309] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种名为xTime的新型框架，用于预测时间序列中的极端事件，通过知识蒸馏和混合专家机制提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型在预测极端事件方面存在不足，主要挑战是数据不平衡以及忽略了先前事件中的有价值信息。

Method: xTime框架结合了知识蒸馏，利用在低稀有度事件上训练的模型来改进稀有事件的预测；同时引入混合专家（MoE）机制，动态选择和融合不同稀有度专家模型的输出来进一步提升预测性能。

Result: 在多个数据集上的实验表明，xTime在预测极端事件方面的准确性提高了3%到78%，取得了持续的改进。

Conclusion: xTime通过知识蒸馏和混合专家机制，有效解决了时间序列极端事件预测中的数据不平衡和信息利用问题，显著提高了预测精度。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [310] [From Masks to Worlds: A Hitchhiker's Guide to World Models](https://arxiv.org/abs/2510.20668)
*Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang*

Main category: cs.LG

TL;DR: 本文旨在指导读者构建世界模型，而非对现有世界模型进行全面梳理。文章聚焦于核心技术，如掩码模型、统一架构、交互式生成模型以及记忆增强系统，并探讨了通往真正世界模型的关键路径。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为构建世界模型的读者提供一个清晰的指南，聚焦于实现真正世界模型的核心技术和发展路径。

Method: 文章沿着一条清晰的路径进行阐述：从早期统一跨模态表示学习的掩码模型，到共享单一范式的统一架构，再到实现动作-感知闭环的交互式生成模型，最后到能够维持一致世界状态的记忆增强系统。

Result: 通过聚焦生成核心、交互循环和记忆系统，文章展示了这是通往真正世界模型最有希望的路径。

Conclusion: 文章认为，通过关注掩码模型、统一架构、交互式生成模型和记忆增强系统等核心技术，可以为构建真正意义上的世界模型指明方向。

Abstract: This is not a typical survey of world models; it is a guide for those who
want to build worlds. We do not aim to catalog every paper that has ever
mentioned a ``world model". Instead, we follow one clear road: from early
masked models that unified representation learning across modalities, to
unified architectures that share a single paradigm, then to interactive
generative models that close the action-perception loop, and finally to
memory-augmented systems that sustain consistent worlds over time. We bypass
loosely related branches to focus on the core: the generative heart, the
interactive loop, and the memory system. We show that this is the most
promising path towards true world models.

</details>


### [311] [GRACE: GRaph-based Addiction Care prEdiction](https://arxiv.org/abs/2510.20671)
*Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee*

Main category: cs.LG

TL;DR: 提出了一种名为GRACE的新型图神经网络框架，用于解决成瘾患者的护理地点预测问题，并克服现有数据中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的成瘾数据集存在严重的类别不平衡问题，导致决策模型效果不佳，需要开发自动化的框架来解决护理地点决策问题。

Method: 提出了一种名为GRACE的图神经网络框架，将护理地点预测形式化为结构化学习问题。通过进行广泛的特征工程，并提出一种获取无偏见的元图的新方法来训练GNN，以克服类别不平衡问题。

Result: 在真实世界的数据集上进行的实验结果表明，与现有的基线模型相比，少数类别的F1分数提高了11-35%。

Conclusion: GRACE框架通过解决类别不平衡问题，在成瘾患者的护理地点预测方面取得了显著的改进。

Abstract: Determining the appropriate locus of care for addiction patients is one of
the most critical clinical decisions that affects patient treatment outcomes
and effective use of resources. With a lack of sufficient specialized treatment
resources, such as inpatient beds or staff, there is an unmet need to develop
an automated framework for the same. Current decision-making approaches suffer
from severe class imbalances in addiction datasets. To address this limitation,
we propose a novel graph neural network (GRACE) framework that formalizes locus
of care prediction as a structured learning problem. Further, we perform
extensive feature engineering and propose a new approach of obtaining an
unbiased meta-graph to train a GNN to overcome the class imbalance problem.
Experimental results in real-world data show an improvement of 11-35% in terms
of the F1 score of the minority class over competitive baselines. The codes and
note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.

</details>


### [312] [A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks](https://arxiv.org/abs/2510.20683)
*Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale*

Main category: cs.LG

TL;DR: 基于SNN的Spikachu框架在BCI神经解码方面实现了可扩展、实时和高能效的性能，优于因果基线，并且在多会话和多被试训练下表现更好，实现了少样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的BCI神经解码模型要么泛化性差，要么难以实现实时操作，并且都面临功耗高的问题，难以集成到资源受限的设备中。Spiking Neural Networks (SNNs) 因其因果性和低功耗特性，为解决这些问题提供了有前景的替代方案。

Method: 提出了一种名为Spikachu的基于SNN的神经解码框架。该框架直接处理分箱脉冲，将其投影到共享的潜在空间，然后由适应输入时序的脉冲模块提取特征，最后整合这些潜在表征并进行解码以生成行为预测。

Result: 在6只非人灵长类动物的113个记录会话（总计43小时）上进行了评估。Spikachu在仅使用单会话训练时，能耗比因果基线低2.26到418.81倍。将训练扩展到多个会话和被试后，性能得到提升，并实现了对未见过的会话、被试和任务的少样本迁移。Spikachu的性能与最先进的模型相当，但能耗却低几个数量级。

Conclusion: Spikachu是一个可扩展、在线兼容的基于SNN的神经解码框架，在BCI领域具有竞争力，并且能耗极低。

Abstract: Brain-computer interfaces (BCIs) promise to enable vital functions, such as
speech and prosthetic control, for individuals with neuromotor impairments.
Central to their success are neural decoders, models that map neural activity
to intended behavior. Current learning-based decoding approaches fall into two
classes: simple, causal models that lack generalization, or complex, non-causal
models that generalize and scale offline but struggle in real-time settings.
Both face a common challenge, their reliance on power-hungry artificial neural
network backbones, which makes integration into real-world, resource-limited
systems difficult. Spiking neural networks (SNNs) offer a promising
alternative. Because they operate causally these models are suitable for
real-time use, and their low energy demands make them ideal for
battery-constrained environments. To this end, we introduce Spikachu: a
scalable, causal, and energy-efficient neural decoding framework based on SNNs.
Our approach processes binned spikes directly by projecting them into a shared
latent space, where spiking modules, adapted to the timing of the input,
extract relevant features; these latent representations are then integrated and
decoded to generate behavioral predictions. We evaluate our approach on 113
recording sessions from 6 non-human primates, totaling 43 hours of recordings.
Our method outperforms causal baselines when trained on single sessions using
between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that
scaling up training to multiple sessions and subjects improves performance and
enables few-shot transfer to unseen sessions, subjects, and tasks. Overall,
Spikachu introduces a scalable, online-compatible neural decoding framework
based on SNNs, whose performance is competitive relative to state-of-the-art
models while consuming orders of magnitude less energy.

</details>


### [313] [MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs](https://arxiv.org/abs/2510.20762)
*Jan Sobotka,Luca Baroni,Ján Antolík*

Main category: cs.LG

TL;DR: MEIcoder是一种新的解码方法，它利用神经元特定的最兴奋输入（MEIs）、结构相似性度量损失和对抗性训练，在视觉刺激解码方面取得了最先进的性能，特别是在小型数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 生物数据稀缺，尤其是在灵长类动物或人类中，这给深度学习解码技术带来了挑战。因此，需要一种能够有效处理稀疏数据的方法。

Method: MEIcoder利用神经元特定的最兴奋输入（MEIs）、结构相似性度量损失和对抗性训练来解码视觉刺激。

Result: MEIcoder在从初级视觉皮层（V1）的单细胞活动重建视觉刺激方面取得了最先进的性能，尤其是在具有较少神经元的小型数据集上表现出色。通过消融研究，证明了MEIs是性能的主要驱动因素。通过规模化实验，表明MEIcoder可以从少至1,000-2,500个神经元和少于1,000个训练数据点中重建高保真度的自然外观图像。此外，还提出了一个包含超过160,000个样本的统一基准，以促进未来的研究。

Conclusion: 研究结果证明了在早期视觉系统中进行可靠解码的可行性，并为神经科学和神经工程应用提供了实际见解。

Abstract: Decoding visual stimuli from neural population activity is crucial for
understanding the brain and for applications in brain-machine interfaces.
However, such biological data is often scarce, particularly in primates or
humans, where high-throughput recording techniques, such as two-photon imaging,
remain challenging or impossible to apply. This, in turn, poses a challenge for
deep learning decoding techniques. To overcome this, we introduce MEIcoder, a
biologically informed decoding method that leverages neuron-specific most
exciting inputs (MEIs), a structural similarity index measure loss, and
adversarial training. MEIcoder achieves state-of-the-art performance in
reconstructing visual stimuli from single-cell activity in primary visual
cortex (V1), especially excelling on small datasets with fewer recorded
neurons. Using ablation studies, we demonstrate that MEIs are the main drivers
of the performance, and in scaling experiments, we show that MEIcoder can
reconstruct high-fidelity natural-looking images from as few as 1,000-2,500
neurons and less than 1,000 training data points. We also propose a unified
benchmark with over 160,000 samples to foster future research. Our results
demonstrate the feasibility of reliable decoding in early visual system and
provide practical insights for neuroscience and neuroengineering applications.

</details>


### [314] [Separating the what and how of compositional computation to enable reuse and continual learning](https://arxiv.org/abs/2510.20709)
*Haozhe Shan,Sun Minni,Lea Duncker*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的两系统方法（一个负责推断计算内容，一个负责实现计算方式）来研究循环神经网络（RNN）中的持续学习和技能的组合重用。


<details>
  <summary>Details</summary>
Motivation: 神经机制如何实现持续学习和灵活的技能（重新）组合仍然难以捉摸。

Method: 提出了一种两系统方法：一个'what'系统通过概率生成模型推断计算内容（基于离散任务时段的共享词汇），一个'how'系统（RNN）根据'what'系统推断出的上下文来组合其低秩分量以实现计算。该方法采用无监督在线学习，能够单次试验学习，并随着新任务的出现而逐步构建词汇。

Result: 该方法在示例任务集上展示了其学习框架的有效性和竞争力，证明了其在正向和反向迁移方面的潜力，以及对未见任务的快速组合泛化能力，实现了在引入新任务时持续学习而不会发生灾难性遗忘。

Conclusion: 所提出的两系统学习框架能够有效地实现持续学习和技能的组合重用，并且在处理新任务时表现出良好的泛化能力。

Abstract: The ability to continually learn, retain and deploy skills to accomplish
goals is a key feature of intelligent and efficient behavior. However, the
neural mechanisms facilitating the continual learning and flexible
(re-)composition of skills remain elusive. Here, we study continual learning
and the compositional reuse of learned computations in recurrent neural network
(RNN) models using a novel two-system approach: one system that infers what
computation to perform, and one that implements how to perform it. We focus on
a set of compositional cognitive tasks commonly studied in neuroscience. To
construct the what system, we first show that a large family of tasks can be
systematically described by a probabilistic generative model, where
compositionality stems from a shared underlying vocabulary of discrete task
epochs. The shared epoch structure makes these tasks inherently compositional.
We first show that this compositionality can be systematically described by a
probabilistic generative model. Furthermore, We develop an unsupervised online
learning approach that can learn this model on a single-trial basis, building
its vocabulary incrementally as it is exposed to new tasks, and inferring the
latent epoch structure as a time-varying computational context within a trial.
We implement the how system as an RNN whose low-rank components are composed
according to the context inferred by the what system. Contextual inference
facilitates the creation, learning, and reuse of low-rank RNN components as new
tasks are introduced sequentially, enabling continual learning without
catastrophic forgetting. Using an example task set, we demonstrate the efficacy
and competitive performance of this two-system learning framework, its
potential for forward and backward transfer, as well as fast compositional
generalization to unseen tasks.

</details>


### [315] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究旨在使用数据驱动的建模方法，通过约翰霍普金斯跌倒风险评估工具（JHFRAT）的预测结果，结合额外的临床指标，更精确地评估住院患者的跌倒风险。


<details>
  <summary>Details</summary>
Motivation: 旨在通过数据驱动的建模方法，将JHFRAT的跌倒风险预测结果与临床上更有意义的指标进行对齐，以提高跌倒风险评估的准确性。

Method: 采用约束分数优化（CSO）模型，结合JHFRAT评估数据和电子健康记录（EHR）变量，对54,209例住院患者进行回顾性分析。

Result: CSO模型在预测性能上显著优于现有的JHFRAT（CSO AUC-ROC=0.91，JHFRAT AUC-ROC=0.86），并且在加入EHR变量后性能无显著差异。与XGBoost等黑盒模型相比，CSO模型在风险标签变化时表现出更强的鲁棒性。

Conclusion: 该循证方法为医疗系统提供了一个坚实的基础，可以利用数据驱动的优化技术系统地加强住院患者跌倒预防方案和患者安全，从而改善医疗环境中的风险评估和资源分配。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [316] [Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2510.20718)
*Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder*

Main category: cs.LG

TL;DR: 该论文提出了一种基于N-BEATS和图神经网络（GNN）的异常预测框架，用于半导体制造中的多变量时间序列分析，以应对高维度、类别不平衡和变量间复杂依赖关系等挑战。GNN模型在捕获变量间关系方面表现优于N-BEATS，并具有更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 半导体制造过程复杂且参数众多，需要实时监控和故障检测。现有技术在处理高维度、类别不平衡和变量间复杂依赖关系方面存在挑战。将异常检测提升到异常预测是实现实时过程修正和主动故障预防的关键。

Method: 提出一个包含两个阶段的异常预测框架：（a）在假设无异常的数据集上训练预测模型；（b）对未见的时间序列数据进行预测，并将预测结果与训练信号的预测进行比较，超出预定阈值的偏差被标记为异常。两个方法分别采用N-BEATS（假设变量独立）和图神经网络（GNN，考虑变量间关系）作为预测模型。

Result: 两种方法在长达20个时间点的时间序列预测上表现良好，在长达50个时间点的时间序列上保持稳定的异常预测能力。GNN模型在性能上持续优于N-BEATS模型，同时所需的参数和计算成本显著更低。

Conclusion: GNN模型在半导体制造的在线异常预测方面显示出巨大潜力，有望部署于实际制造环境中。

Abstract: Semiconductor manufacturing is an extremely complex and precision-driven
process, characterized by thousands of interdependent parameters collected
across diverse tools and process steps. Multi-variate time-series analysis has
emerged as a critical field for real-time monitoring and fault detection in
such environments. However, anomaly prediction in semiconductor fabrication
presents several critical challenges, including high dimensionality of sensor
data and severe class imbalance due to the rarity of true faults. Furthermore,
the complex interdependencies between variables complicate both anomaly
prediction and root-cause-analysis. This paper proposes two novel approaches to
advance the field from anomaly detection to anomaly prediction, an essential
step toward enabling real-time process correction and proactive fault
prevention. The proposed anomaly prediction framework contains two main stages:
(a) training a forecasting model on a dataset assumed to contain no anomalies,
and (b) performing forecast on unseen time series data. The forecast is
compared with the forecast of the trained signal. Deviations beyond a
predefined threshold are flagged as anomalies. The two approaches differ in the
forecasting model employed. The first assumes independence between variables by
utilizing the N-BEATS model for univariate time series forecasting. The second
lifts this assumption by utilizing a Graph Neural Network (GNN) to capture
inter-variable relationships. Both models demonstrate strong forecasting
performance up to a horizon of 20 time points and maintain stable anomaly
prediction up to 50 time points. The GNN consistently outperforms the N-BEATS
model while requiring significantly fewer trainable parameters and lower
computational cost. These results position the GNN as promising solution for
online anomaly forecasting to be deployed in manufacturing environments.

</details>


### [317] [No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes](https://arxiv.org/abs/2510.20725)
*Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek*

Main category: cs.LG

TL;DR: Thompson sampling (TS) 在具有高斯边际分布的模型中，在情景强化学习中被证明是无悔的，其懊悔界限为 O(sqrt(KHΓ(KH)))。


<details>
  <summary>Details</summary>
Motivation: 尽管 Thompson sampling (TS) 在序列决策中被广泛应用，但其在强化学习 (RL) 等具有复杂时间结构的场景中的理论基础仍然有限。本文旨在解决这一差距。

Method: 本文在具有联合高斯过程 (GP) 先验的奖励和转移情景 RL 中，对 TS 进行了研究，并建立了无悔保证。分析中考虑了值函数和 Bellman 更新的递归结构，并使用了多输出的椭圆势引理等经典工具。

Result: 本文证明了在具有高斯边际分布的模型中，TS 具有无悔性。具体而言，对于具有联合高斯过程 (GP) 先验的奖励和转移的情景 RL，证明了其懊悔界限为 O(sqrt(KHΓ(KH)))，其中 K 为试验次数，H 为情景长度，Γ(·) 表示 GP 模型的复杂度。

Conclusion: 本研究通过在高斯边际分布的模型中为 TS 建立无悔保证，推进了对 TS 在 RL 中的理解。此外，研究结果还表明，模型结构假设和模型不确定性如何影响 TS 在有限时间范围的马尔可夫决策过程中的性能。

Abstract: Thompson sampling (TS) is a powerful and widely used strategy for sequential
decision-making, with applications ranging from Bayesian optimization to
reinforcement learning (RL). Despite its success, the theoretical foundations
of TS remain limited, particularly in settings with complex temporal structure
such as RL. We address this gap by establishing no-regret guarantees for TS
using models with Gaussian marginal distributions. Specifically, we consider TS
in episodic RL with joint Gaussian process (GP) priors over rewards and
transitions. We prove a regret bound of
$\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$ over $K$ episodes of horizon $H$,
where $\Gamma(\cdot)$ captures the complexity of the GP model. Our analysis
addresses several challenges, including the non-Gaussian nature of value
functions and the recursive structure of Bellman updates, and extends classical
tools such as the elliptical potential lemma to multi-output settings. This
work advances the understanding of TS in RL and highlights how structural
assumptions and model uncertainty shape its performance in finite-horizon
Markov Decision Processes.

</details>


### [318] [Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](https://arxiv.org/abs/2510.20736)
*Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种新的DP驱动多模态学习框架，在学习跨模态交互的同时保留各模态的特征表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法过度强调跨模态对齐，可能导致过多的正则化，阻碍了各模态内有意义的表示学习。

Method: 提出了一种新的DP驱动多模态学习框架，假设每个模态都遵循多元高斯分布的混合，并采用DP来计算所有组件的混合权重，以实现模态内表示学习和跨模态对齐之间的最佳平衡。

Result: 该模型在几个多模态数据集上进行了广泛的实验，结果优于其他竞争对手。消融分析验证了DP在对齐模态分布和对关键超参数变化的鲁棒性方面的有效性。

Conclusion: DP驱动的多模态学习框架能够有效地在保持各模态特征表达能力的同时进行跨模态交互，并在实验中取得了优越的性能。

Abstract: Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

</details>


### [319] [Out-of-distribution Tests Reveal Compositionality in Chess Transformers](https://arxiv.org/abs/2510.20783)
*Anna Mészáros,Patrik Reizinger,Ferenc Huszár*

Main category: cs.LG

TL;DR: Transformer模型在国际象棋任务中表现出组合泛化能力，但其在规则外场景下的表现不如符号化AI。


<details>
  <summary>Details</summary>
Motivation: 评估决策Transformer模型在国际象棋任务中对规则的理解程度，特别是其系统泛化能力。

Method: 训练一个270M参数的国际象棋Transformer模型，并在分布外（OOD）场景、国际象棋960（随机国际象棋）等变体上进行测试。

Result: 模型展现出组合泛化能力，能够遵循基本规则并生成高质量的OOD谜题解法。在国际象棋960变体中，模型表现出基本策略适应性，但与显式搜索的符号AI相比仍有差距，但在对弈Lichess用户时差距减小。训练过程中，模型曾一度只学会移动自己的棋子，暗示了组合式理解的涌现。

Conclusion: 决策Transformer模型在国际象棋任务中展现出一定的规则理解和泛化能力，但其表现仍无法完全超越符号化AI。

Abstract: Chess is a canonical example of a task that requires rigorous reasoning and
long-term planning. Modern decision Transformers - trained similarly to LLMs -
are able to learn competent gameplay, but it is unclear to what extent they
truly capture the rules of chess. To investigate this, we train a 270M
parameter chess Transformer and test it on out-of-distribution scenarios,
designed to reveal failures of systematic generalization. Our analysis shows
that Transformers exhibit compositional generalization, as evidenced by strong
rule extrapolation: they adhere to fundamental syntactic rules of the game by
consistently choosing valid moves even in situations very different from the
training data. Moreover, they also generate high-quality moves for OOD puzzles.
In a more challenging test, we evaluate the models on variants including
Chess960 (Fischer Random Chess) - a variant of chess where starting positions
of pieces are randomized. We found that while the model exhibits basic strategy
adaptation, they are inferior to symbolic AI algorithms that perform explicit
search, but gap is smaller when playing against users on Lichess. Moreover, the
training dynamics revealed that the model initially learns to move only its own
pieces, suggesting an emergent compositional understanding of the game.

</details>


### [320] [KL-Regularized Reinforcement Learning is Designed to Mode Collapse](https://arxiv.org/abs/2510.20817)
*Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath*

Main category: cs.LG

TL;DR:  KL散度在强化学习中的正反向优化目标存在误解，实际中其影响因素比直觉更复杂，但可通过调整正则化强度等因素实现多模态覆盖，并提出一种新的算法提升模型多样性。


<details>
  <summary>Details</summary>
Motivation: 许多研究者认为反向KL散度优化会“寻找模式”，而正向KL散度优化会“覆盖群众”，后者在目标是从多个不同模式中采样时更受青睐。然而，这种直觉在将KL散度用于逆向/正向KL散度正则化的强化学习（例如在语言模型中）时，并不一定适用。

Method: 通过数学和实证分析，展示反向/正向KL散度如何影响最优目标分布的参数化，并研究正则化强度、奖励与参考概率的相对尺度如何影响模式覆盖。在此基础上，提出一种新的算法，通过对奖励幅度进行微小改动，优化目标分布，使其在所有高质量采样模式下均具有高概率。

Result: 现有的常用设置（如低正则化强度和相等的验证奖励）倾向于指定单峰目标分布，导致优化目标在构建时就缺乏多样性。提出的新算法在保持较低的奖励幅度改动下，能够优化目标分布，使其在所有高质量采样模式下均具有高概率。实验表明，该算法能够提升大型语言模型和化学语言模型的解决方案质量和多样性，且无需外部多样性信号，在正向和反向KL都有效。

Conclusion: 反向/正向KL散度正则化在强化学习中的行为与直觉不符，模式覆盖主要取决于正则化强度等因素。提出的新算法通过调整KL散度目标分布的参数，实现了高质量和高多样性的采样，并在语言模型和化学语言模型上得到了验证。

Abstract: It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [321] [New Hardness Results for the LOCAL Model via a Simple Self-Reduction](https://arxiv.org/abs/2510.19972)
*Alkida Balliu,Filippo Casagrande,Francesco d'Amore,Dennis Olivetti*

Main category: cs.DC

TL;DR: 该论文提出了一个简化版的“通过自归约进行的回合消除”技术，并将其应用于最大b-匹配和边着色问题，得到了新的下界结果。


<details>
  <summary>Details</summary>
Motivation: 为了简化Khoury和Schild（2025）关于最大匹配的25页的复杂证明，并将其推广到其他图问题。

Method: 1. 简化了“通过自归约进行的回合消除”技术。2. 应用该技术证明了最大b-匹配和边着色问题的下界。

Result: 1. 提出了最大b-匹配问题的下界：$ Omeg a( min\{ log_{1+b}\Delta,  log_\Delta n\})$ 和 $ Omeg a(\sqrt{\log_{1+b} n})$ 回合。2. 提出了边着色问题的下界：$ Omeg a( min\{\log \Delta, \log_\Delta n\})$ 和 $ Omeg a(\sqrt{\log n})$ 回合。

Conclusion: 该论文通过简化技术，为最大b-匹配和边着色问题提供了更简洁的下界证明，并间接为最大匹配问题提供了简化证明。

Abstract: Very recently, Khoury and Schild [FOCS 2025] showed that any randomized LOCAL
algorithm that solves maximal matching requires $\Omega(\min\{\log \Delta,
\log_\Delta n\})$ rounds, where $n$ is the number of nodes in the graph and
$\Delta$ is the maximum degree. This result is shown through a new technique,
called round elimination via self-reduction. The lower bound proof is beautiful
and presents very nice ideas. However, it spans more than 25 pages of technical
details, and hence it is hard to digest and generalize to other problems.
Historically, the simplification of proofs and techniques has marked an
important turning point in our understanding of the complexity of graph
problems. Our paper makes a step forward towards this direction, and provides
the following contributions.
  1. We present a short and simplified version of the round elimination via
self-reduction technique. The simplification of this technique enables us to
obtain the following two hardness results.
  2. We show that any randomized LOCAL algorithm that solves the maximal
$b$-matching problem requires $\Omega(\min\{\log_{1+b}\Delta, \log_\Delta n\})$
and $\Omega(\sqrt{\log_{1+b} n})$ rounds. We recall that the $b$-matching
problem is a generalization of the matching problem where each vertex can have
up to $b$ incident edges in the matching. As a corollary, for $b=1$, we obtain
a short proof for the maximal matching lower bound shown by Khoury and Schild.
  3. Finally, we show that any randomized LOCAL algorithm that properly colors
the edges of a graph with $\Delta + k$ colors requires $\Omega(\min\{\log
\Delta, \log_\Delta n\})$ and $\Omega(\sqrt{\log n})$ rounds, for any $k\le
\Delta^{1-\varepsilon}$ and any constant $\varepsilon > 0$.

</details>


### [322] [AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training](https://arxiv.org/abs/2510.20111)
*Huawei Bai,Yifan Huang,Wenqi Shi,Ansheng You,Feifan Shao,Tengfei Han,Minghui Yu*

Main category: cs.DC

TL;DR: AsyncHZP是一种新颖的异步ZeRO变体，通过自适应重分片和多流异步调度，在保持简单性和内存效率的同时，显著降低了通信开销，实现了比传统ND并行更优越的性能，并简化了大规模训练的路径。


<details>
  <summary>Details</summary>
Motivation: 语言模型在海量集群上的训练效率和可扩展性仍然是一个关键瓶颈，现有的ND并行方法笨拙复杂，而ZeRO等灵活的替代方案常受通信开销的困扰。

Method: 提出了一种名为AsyncHZP的新颖异步ZeRO变体。AsyncHZP通过自适应地在不同的副本组中重分片参数、梯度和优化器状态来优化设备内存利用率并显著减少通信开销。此外，还设计了一种多流异步调度方法，在专用后台线程中执行参数 all-gather 和梯度 reduce-scatter 操作，从而有效地将通信与计算重叠，同时产生的内存碎片可忽略不计。

Result: 在稠密（Dense）和混合专家（MoE）模型上的经验评估证实，AsyncHZP在规模扩展时保持了鲁棒的稳定性。它持续优于经典的ND并行，在没有复杂的策略调整的情况下实现了最先进的性能。

Conclusion: AsyncHZP通过自适应重分片和多流异步调度，在保持简单性和内存效率的同时，显著降低了通信开销，在稠密和MoE模型上实现了比ND并行更优越的性能，简化了大规模训练的路径。

Abstract: The training efficiency and scalability of language models on massive
clusters currently remain a critical bottleneck. Mainstream approaches like ND
parallelism are often cumbersome and complex, while flexible alternatives such
as the Zero Redundancy Optimizer (ZeRO) are frequently hampered by
communication overhead. In this paper, we propose Asynchronous Hierarchical
Zero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to
achieve superior performance while maintaining simplicity and memory
efficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding
that can lead to inefficient communication, AsyncHZP adaptively reshards
parameters, gradients, and optimizer states across different replica groups.
This strategy optimizes device memory utilization and significantly reduces
communication overhead. In addition, we also design a multi-stream asynchronous
scheduling method that executes parameter all-gather and gradient
reduce-scatter operations in dedicated background threads, effectively
overlapping communication with computation while incurring negligible memory
fragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE)
models confirm that AsyncHZP maintains robust stability at scale. It
consistently outperforms classic ND parallelism, achieving state-of-the-art
performance without complex strategic tuning, thereby simplifying the path to
efficient large-scale training.

</details>


### [323] [A Full Stack Framework for High Performance Quantum-Classical Computing](https://arxiv.org/abs/2510.20128)
*Xin Zhan,K. Grace Johnson,Aniello Esposito,Barbara Chapman,Marco Fiorentino,Kirk M. Bresniker,Raymond G. Beausoleil,Masoud Mohseni*

Main category: cs.DC

TL;DR: 该研究提出了一个HPC-QC全栈框架，实现了高性能计算（HPC）和量子计算（QC）的集成，并支持混合工作负载的开发。该框架采用了模块化的、与硬件无关的软件集成方法，支持在C/C++、Fortran和Python等环境中调用量子计算内核。通过自适应电路剪织管理程序，可以将大型量子电路分解以适应不同规模的量子设备和模拟器。该框架利用Cray LLVM编译框架，能够以可重定向的方式处理来自商业量子软件前端的LLVM IR和量子IR（QIR），并将其适配到不同的硬件架构。研究人员在HPE EX超级计算机上演示了多种混合HPC-QC工作负载，包括线性方程组求解、量子优化和量子相变模拟，证明了该框架的功能和可行性。该工作为构建统一的量子-经典编程环境奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了满足对可扩展的高性能计算（HPC）和量子计算（QC）集成日益增长的需求。

Method: 提出了一个HPC-QC全栈框架，采用模块化的硬件/设备无关软件集成方法，实现了混合工作负载开发能力。支持通过量子编程接口库扩展，在C/C++、Fortran和Python等现有HPC编程环境中，从商业量子SDK高层调用量子内核。开发了一个自适应电路剪织管理程序，用于将大型量子电路分区到较小的嘈杂量子设备和经典模拟器中。利用Cray LLVM编译框架，以可重定向的方式处理和转换LLVM IR和量子IR（QIR）。

Result: 在HPE EX超级计算机上演示了多种混合HPC-QC多节点多CPU和GPU工作负载（包括求解线性方程组、量子优化和模拟量子相变），展示了所开发三个组件的功能和执行可行性。

Conclusion: 这项工作为构建一个基于经典HPC软件栈（编译器、库、并行运行时和进程调度）的统一量子-经典编程环境提供了框架。

Abstract: To address the growing needs for scalable High Performance Computing (HPC)
and Quantum Computing (QC) integration, we present our HPC-QC full stack
framework and its hybrid workload development capability with modular
hardware/device-agnostic software integration approach. The latest development
in extensible interfaces for quantum programming, dispatching, and compilation
within existing mature HPC programming environment are demonstrated. Our HPC-QC
full stack enables high-level, portable invocation of quantum kernels from
commercial quantum SDKs within HPC meta-program in compiled languages (C/C++
and Fortran) as well as Python through a quantum programming interface library
extension. An adaptive circuit knitting hypervisor is being developed to
partition large quantum circuits into sub-circuits that fit on smaller noisy
quantum devices and classical simulators. At the lower-level, we leverage Cray
LLVM-based compilation framework to transform and consume LLVM IR and Quantum
IR (QIR) from commercial quantum software frontends in a retargetable fashion
to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU
and GPU workloads (including solving linear system of equations, quantum
optimization, and simulating quantum phase transitions) have been demonstrated
on HPE EX supercomputers to illustrate functionality and execution viability
for all three components developed so far. This work provides the framework for
a unified quantum-classical programming environment built upon classical HPC
software stack (compilers, libraries, parallel runtime and process scheduling).

</details>


### [324] [Collective Communication for 100k+ GPUs](https://arxiv.org/abs/2510.20171)
*Min Si,Pavan Balaji,Yongzhou Chen,Ching-Hsiang Chu,Adi Gangidi,Saif Hasan,Subodh Iyengar,Dan Johnson,Bingzhe Liu,Jingliang Ren,Ashmitha Jeevaraj Shetty,Greg Steinbrecher,Xinfeng Xie,Yulun Wang,Bruce Wu,Jingyi Yang,Mingran Yang,Minlan Yu,Cen Zhao,Wes Bland,Denis Boyda,Suman Gumudavelli,Cristian Lumezanu,Rui Miao,Zhe Qu,Venkat Ramesh,Maxim Samoylov,Jan Seidel,Feng Tian,Qiye Tan,Shuqiang Zhang,Yimeng Zhao,Shengbao Zheng,Art Zhu,Hongyi Zeng*

Main category: cs.DC

TL;DR: NCCLX是一个为大规模语言模型（LLMs）设计的通信框架，旨在解决训练和推理过程中的性能瓶颈，支持超过10万个GPU的集群，并在Llama4模型上展示了显著的通信效率提升。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）规模的不断扩大，特别是在训练负载扩展到数十万个GPU时，对高效的集体通信框架的需求日益增长。传统的通信方法在此规模下面临吞吐量和延迟的限制，阻碍了最先进模型的发展和部署。

Method: 提出并实现了一个名为NCCLX的集体通信框架，该框架在Meta开发，旨在优化LLM整个生命周期的性能，涵盖从大规模训练的同步需求到推理的低延迟要求。该框架支持超过10万个GPU的集群上的复杂工作负载，确保数据交换的可靠性、高吞吐量和低延迟。

Result: 在Llama4模型上的实证评估表明，NCCLX在通信效率方面取得了显著的改进。

Conclusion: NCCLX提供了一个健壮的解决方案，能够支持下一代LLMs以前所未有的规模运行，解决了大规模LLM训练和推理中的关键通信挑战。

Abstract: The increasing scale of large language models (LLMs) necessitates highly
efficient collective communication frameworks, particularly as training
workloads extend to hundreds of thousands of GPUs. Traditional communication
methods face significant throughput and latency limitations at this scale,
hindering both the development and deployment of state-of-the-art models. This
paper presents the NCCLX collective communication framework, developed at Meta,
engineered to optimize performance across the full LLM lifecycle, from the
synchronous demands of large-scale training to the low-latency requirements of
inference. The framework is designed to support complex workloads on clusters
exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency
data exchange. Empirical evaluation on the Llama4 model demonstrates
substantial improvements in communication efficiency. This research contributes
a robust solution for enabling the next generation of LLMs to operate at
unprecedented scales.

</details>


### [325] [FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services](https://arxiv.org/abs/2510.20388)
*Víctor Rampérez,Javier Soriano,David Lizcano,Juan A. Lara*

Main category: cs.DC

TL;DR: FLAS是一个结合了主动和反应方法的自动扩缩器，通过预测和基于资源利用率的估算来优化分布式服务的扩缩操作，并在99%的时间内确保性能要求。


<details>
  <summary>Details</summary>
Motivation: 确保分布式服务在云环境中按需获得和释放资源，以满足商定的服务水平，并克服现有自动扩缩器（仅基于预测或仅基于反应）的局限性。

Method: FLAS结合了两种方法：(1) 一个预测模型，用于预测高层指标（如响应时间、吞吐量）的趋势，从而预测相关的服务水平协议（SLA）参数的变化；(2) 一个基于资源利用率指标估算高层指标的反应式应急系统，从而减少侵入性并适应不同应用。

Result: FLAS已被实现并应用于基于内容的发布-订阅中间件（E-SilboPS）。通过基于边界值分析（BVA）的测试用例评估，FLAS在超过99%的时间内确保了性能要求的合规性，即使在最坏的情况下也能有效运行。

Conclusion: FLAS是一个有效且创新的自动扩缩系统，通过结合预测和反应机制，能够为分布式服务（特别是基于内容的发布-订阅系统）提供弹性，并始终满足性能要求。

Abstract: Cloud computing has established itself as the support for the vast majority
of emerging technologies, mainly due to the characteristic of elasticity it
offers. Auto-scalers are the systems that enable this elasticity by acquiring
and releasing resources on demand to ensure an agreed service level. In this
article we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for
distributed services that combines the advantages of proactive and reactive
approaches according to the situation to decide the optimal scaling actions in
every moment. The main novelties introduced by FLAS are (i) a predictive model
of the high-level metrics trend which allows to anticipate changes in the
relevant SLA parameters (e.g. performance metrics such as response time or
throughput) and (ii) a reactive contingency system based on the estimation of
high-level metrics from resource use metrics, reducing the necessary
instrumentation (less invasive) and allowing it to be adapted agnostically to
different applications. We provide a FLAS implementation for the use case of a
content-based publish-subscribe middleware (E-SilboPS) that is the cornerstone
of an event-driven architecture. To the best of our knowledge, this is the
first auto-scaling system for content-based publish-subscribe distributed
systems (although it is generic enough to fit any distributed service). Through
an evaluation based on several test cases recreating not only the expected
contexts of use, but also the worst possible scenarios (following the
Boundary-Value Analysis or BVA test methodology), we have validated our
approach and demonstrated the effectiveness of our solution by ensuring
compliance with performance requirements over 99% of the time.

</details>


### [326] [Accurate Performance Predictors for Edge Computing Applications](https://arxiv.org/abs/2510.20495)
*Panagiotis Giannakopoulos,Bart van Knippenberg,Kishor Chandra Joshi,Nicola Calabretta,George Exarchakos*

Main category: cs.DC

TL;DR: 该研究提出了一种自动构建和评估性能预测模型的方法，以应对边缘环境中应用性能预测的挑战，并考虑了准确性和推理时间。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的动态边缘环境中，准确预测应用程序性能对于有效的调度和资源管理至关重要，但由于应用程序的共置和节点的异构性，预测性能仍然很困难。

Method: 提出了一种自动构建和评估各种性能预测器的方法，同时考虑准确性和推理时间以找到最有效的模型。使用与应用程序性能最相关的监控指标的历史状态来训练预测器，并在动态共置场景中的多个服务器上进行评估。

Result: 所提出的预测器准确率高达 90%，推理时间不到往返时间的 1%。

Conclusion: 研究强调了在动态共置场景中，通过联合优化准确性和推理延迟来选择服务器特定预测器的系统方法的需求。将这些预测器集成到边缘环境中可以提高资源利用率并实现可预测的性能。

Abstract: Accurate prediction of application performance is critical for enabling
effective scheduling and resource management in resource-constrained dynamic
edge environments. However, achieving predictable performance in such
environments remains challenging due to the co-location of multiple
applications and the node heterogeneity. To address this, we propose a
methodology that automatically builds and assesses various performance
predictors. This approach prioritizes both accuracy and inference time to
identify the most efficient model. Our predictors achieve up to 90% accuracy
while maintaining an inference time of less than 1% of the Round Trip Time.
These predictors are trained on the historical state of the most correlated
monitoring metrics to application performance and evaluated across multiple
servers in dynamic co-location scenarios. As usecase we consider electron
microscopy (EM) workflows, which have stringent real-time demands and diverse
resource requirements. Our findings emphasize the need for a systematic
methodology that selects server-specific predictors by jointly optimizing
accuracy and inference latency in dynamic co-location scenarios. Integrating
such predictors into edge environments can improve resource utilization and
result in predictable performance.

</details>


### [327] [Morpheus: Lightweight RTT Prediction for Performance-Aware Load Balancing](https://arxiv.org/abs/2510.20506)
*Panagiotis Giannakopoulos,Bart van Knippenberg,Kishor Chandra Joshi,Nicola Calabretta,George Exarchakos*

Main category: cs.DC

TL;DR: 该论文提出使用往返时间（RTT）预测器来预测应用程序延迟，以改进请求路由，从而提高分布式应用程序的低延迟性能。


<details>
  <summary>Details</summary>
Motivation: 分布式应用程序（尤其是在边缘和云环境中）需要低端到端延迟，但传统的负载均衡策略因依赖过时或粗粒度的指标而导致次优路由和尾部延迟增加。

Method: 开发了轻量级且准确的 RTT 预测器，使用从 Kubernetes 管理的 GPU 集群收集的时间序列监控数据进行训练，并利用高度相关的监控指标的简化集。

Result: 所提出的 RTT 预测器准确率高达 95%，预测延迟在应用程序 RTT 的 10% 以内。论文还确定了确保在资源受限集群中有效部署预测器的最低预测准确率阈值和关键系统级因素。

Conclusion: 基于预测的负载均衡可以显著减少应用程序 RTT 并最大限度地减少资源浪费，证明了将预测负载均衡集成到未来生产系统中的可行性。

Abstract: Distributed applications increasingly demand low end-to-end latency,
especially in edge and cloud environments where co-located workloads contend
for limited resources. Traditional load-balancing strategies are typically
reactive and rely on outdated or coarse-grained metrics, often leading to
suboptimal routing decisions and increased tail latencies. This paper
investigates the use of round-trip time (RTT) predictors to enhance request
routing by anticipating application latency. We develop lightweight and
accurate RTT predictors that are trained on time-series monitoring data
collected from a Kubernetes-managed GPU cluster. By leveraging a reduced set of
highly correlated monitoring metrics, our approach maintains low overhead while
remaining adaptable to diverse co-location scenarios and heterogeneous
hardware. The predictors achieve up to 95% accuracy while keeping the
prediction delay within 10% of the application RTT. In addition, we identify
the minimum prediction accuracy threshold and key system-level factors required
to ensure effective predictor deployment in resource-constrained clusters.
Simulation-based evaluation demonstrates that performance-aware load balancing
can significantly reduce application RTT and minimize resource waste. These
results highlight the feasibility of integrating predictive load balancing into
future production systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [328] [Excitation of Looped Bistable Bands for High-Speed Linear Actuation](https://arxiv.org/abs/2510.19834)
*Sareum Kim,Josie Hughes*

Main category: eess.SY

TL;DR: 利用环形双稳态带来实现高速线性运动放大。


<details>
  <summary>Details</summary>
Motivation: 软体机器人需要智能材料和创新结构，双稳态弹簧是一种有前途的选择，具有独特的动态行为，如振荡。

Method: 在直线导轨上安装由曲柄机构驱动的环形双稳态弹簧，通过改变驱动频率，研究其共振时将输入振荡转化为放大的线性运动。

Result: 该装置实现了输入振荡的高速线性放大。

Conclusion: 双稳态弹簧在高速往复线性运动方面具有应用潜力。

Abstract: Soft robotics increasingly relies on smart materials and innovative
structures, with bistable tape springs emerging as a promising option. These
structures exhibit intriguing dynamic behaviors, such as oscillation, due to
their inherent bistability. This paper explores the high-speed linear
amplification of motion achieved through the excitation of a looped bistable
tape spring. When looped, the tape spring forms two distinct joints,
facilitating smooth oscillation. Mounted on a linear guide and driven by a
crank mechanism with varying frequency, the system converts input oscillations
into amplified linear motion at resonance. This study highlights the potential
of bistable tape springs high speed reciprocating linear motion.

</details>


### [329] [IMAS$^2$: Joint Agent Selection and Information-Theoretic Coordinated Perception In Dec-POMDPs](https://arxiv.org/abs/2510.20009)
*Chongyang Shi,Wesley A. Suttle,Michael Dorothy,Jie Fu*

Main category: eess.SY

TL;DR: 本研究提出了IMAS$^2$算法，用于在Dec-POMDP框架下联合选择传感代理和合成多代理主动感知策略，实现了信息论目标下的 $(1 - 1/e)$ 性能保证。


<details>
  <summary>Details</summary>
Motivation: 在Dec-POMDP框架下，联合选择传感代理和合成去中心化主动感知策略。对主动感知问题引入了以互信息为目标的统一目标函数。

Method: 设计了一个两层优化结构。内层使用信息论指标（互信息）作为目标，通过优化方法获得传感器策略；外层利用目标函数的单调性和子模性，设计了IMAS$^2$算法进行联合选择和合成。通过Nemhauser-Wolsey论证了$(1 - 1/e)$的性能保证。

Result: 在多代理合作感知网格世界环境中，验证了所提方法的有效性。

Conclusion: 所提出的IMAS$^2$算法能够有效地解决联合传感代理选择和感知策略合成问题，并在理论上保证了性能。

Abstract: We study the problem of jointly selecting sensing agents and synthesizing
decentralized active perception policies for the chosen subset of agents within
a Decentralized Partially Observable Markov Decision Process (Dec-POMDP)
framework. Our approach employs a two-layer optimization structure. In the
inner layer, we introduce information-theoretic metrics, defined by the mutual
information between the unknown trajectories or some hidden property in the
environment and the collective partial observations in the multi-agent system,
as a unified objective for active perception problems. We employ various
optimization methods to obtain optimal sensor policies that maximize mutual
information for distinct active perception tasks. In the outer layer, we prove
that under certain conditions, the information-theoretic objectives are
monotone and submodular with respect to the subset of observations collected
from multiple agents. We then exploit this property to design an IMAS$^2$
(Information-theoretic Multi-Agent Selection and Sensing) algorithm for joint
sensing agent selection and sensing policy synthesis. However, since the policy
search space is infinite, we adapt the classical Nemhauser-Wolsey argument to
prove that the proposed IMAS$^2$ algorithm can provide a tight $(1 -
1/e)$-guarantee on the performance. Finally, we demonstrate the effectiveness
of our approach in a multi-agent cooperative perception in a grid-world
environment.

</details>


### [330] [Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning](https://arxiv.org/abs/2510.20040)
*Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter*

Main category: eess.SY

TL;DR: 使用模仿学习来加速微电网经济模型预测控制（EMPC）的决策过程，在不牺牲经济效益的情况下，显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 应对日益增长的可再生能源接入，对微电网可靠和可持续运行进行高效的能源管理。

Method: 训练一个神经网络来模仿专家 EMPC 控制器的离线轨迹，并注入噪声以增强鲁棒性，同时明确考虑可再生能源发电和负荷需求中的预测不确定性。

Result: 所提出的方法在经济效益上与 EMPC 相当，但计算时间仅为 EMPC 的 10%。

Conclusion: 模仿学习提供了一种高效且经济可行的替代 EMPC 的方法，适用于微电网的实时能源管理。

Abstract: Efficient energy management is essential for reliable and sustainable
microgrid operation amid increasing renewable integration. This paper proposes
an imitation learning-based framework to approximate mixed-integer Economic
Model Predictive Control (EMPC) for microgrid energy management. The proposed
method trains a neural network to imitate expert EMPC control actions from
offline trajectories, enabling fast, real-time decision making without solving
optimization problems online. To enhance robustness and generalization, the
learning process includes noise injection during training to mitigate
distribution shift and explicitly incorporates forecast uncertainty in
renewable generation and demand. Simulation results demonstrate that the
learned policy achieves economic performance comparable to EMPC while only
requiring $10\%$ of the computation time of optimization-based EMPC in
practice.

</details>


### [331] [Safe Output-Feedback Adaptive Optimal Control of Affine Nonlinear Systems](https://arxiv.org/abs/2510.20081)
*Tochukwu E. Ogri,Muzaffar Qureshi,Zachary I. Bell,Wanjiku A. Makumi,Rushikesh Kamalapurkar*

Main category: eess.SY

TL;DR: 该研究提出一种结合状态估计和参数估计的安全自适应最优控制（AOC）与控制障碍函数（CBF）的方法，用于在状态信息不全的情况下保证安全和稳定。


<details>
  <summary>Details</summary>
Motivation: 在状态信息不全的情况下，开发一种能够保证系统安全性和稳定性的控制方法。

Method: 该方法结合了基于CBF的保护性控制器和基于AOC的稳定化控制器。其中，CBF被设计成鲁棒的，以适应状态估计不完全的情况。同时，利用基于深度神经网络的自适应观测器来处理状态估计误差。

Result: 通过Lyapunov稳定性分析提供了安全性和收敛性保证，并通过仿真验证了该控制器的有效性。

Conclusion: 该方法在状态信息不全的情况下，能够有效保证系统的安全性和稳定性。

Abstract: In this paper, we develop a safe control synthesis method that integrates
state estimation and parameter estimation within an adaptive optimal control
(AOC) and control barrier function (CBF)-based control architecture. The
developed approach decouples safety objectives from the learning objectives
using a CBF-based guarding controller where the CBFs are robustified to account
for the lack of full-state measurements. The coupling of this guarding
controller with the AOC-based stabilizing control guarantees safety and
regulation despite the lack of full state measurement. The paper leverages
recent advancements in deep neural network-based adaptive observers to ensure
safety in the presence of state estimation errors. Safety and convergence
guarantees are provided using a Lyapunov-based analysis, and the effectiveness
of the developed controller is demonstrated through simulation under mild
excitation conditions.

</details>


### [332] [SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance](https://arxiv.org/abs/2510.20113)
*Haowei Lou,Chengkai Huang,Hye-young Paik,Yongquan Hu,Aaron Quigley,Wen Hu,Lina Yao*

Main category: eess.SY

TL;DR: SpeechAgent是一个移动应用，利用大语言模型和先进的语音处理技术，为言语障碍者提供个性化的日常交流辅助。


<details>
  <summary>Details</summary>
Motivation: 尽管语音识别和语音合成技术取得了进展，但仍缺乏支持言语障碍者的网络和移动基础设施，限制了这些技术的实际应用。

Method: SpeechAgent整合了由大语言模型驱动的推理和先进的语音处理模块，并开发了一个结构化的部署流程，以在移动和边缘设备上实现实时、低延迟的语音处理。

Result: 在真实世界的言语障碍数据集上的评估和边缘设备的延迟分析表明，SpeechAgent能够提供有效的、用户友好的性能，实现高精度和高质量的语音。

Conclusion: SpeechAgent在个性化、日常辅助交流方面是可行且有效的，能够满足不同言语障碍用户的需求。

Abstract: Speech is essential for human communication, yet millions of people face
impairments such as dysarthria, stuttering, and aphasia conditions that often
lead to social isolation and reduced participation. Despite recent progress in
automatic speech recognition (ASR) and text-to-speech (TTS) technologies,
accessible web and mobile infrastructures for users with impaired speech remain
limited, hindering the practical adoption of these advances in daily
communication. To bridge this gap, we present SpeechAgent, a mobile SpeechAgent
designed to facilitate people with speech impairments in everyday
communication. The system integrates large language model (LLM)- driven
reasoning with advanced speech processing modules, providing adaptive support
tailored to diverse impairment types. To ensure real-world practicality, we
develop a structured deployment pipeline that enables real-time speech
processing on mobile and edge devices, achieving imperceptible latency while
maintaining high accuracy and speech quality. Evaluation on real-world impaired
speech datasets and edge-device latency profiling confirms that SpeechAgent
delivers both effective and user-friendly performance, demonstrating its
feasibility for personalized, day-to-day assistive communication.

</details>


### [333] [Interpolatory Approximations of PMU Data: Dimension Reduction and Pilot Selection](https://arxiv.org/abs/2510.20116)
*Sean Reiter,Mark Embree,Serkan Gugercin,Vassilis Kekatos*

Main category: eess.SY

TL;DR: 通过低秩矩阵近似方法（ID）和离散经验插值法（DEIM）来压缩PMU数据，并实现故障检测。


<details>
  <summary>Details</summary>
Motivation: 为了在通信带宽有限的情况下实现对电力传输系统的实时监控，需要对PMU数据进行降维。

Method: 提出使用插值矩阵分解（ID）框架来恢复PMU数据矩阵，并使用离散经验插值法（DEIM）来选择用于ID的行和列。

Result: DEIM在数据压缩方面表现优异，并且基于DEIM的故障检测方法得到了验证。

Conclusion: ID提供了一个严格的数据压缩质量误差界限，DEIM可以控制这个误差界限，并且该误差界限可用于在线估计重建误差，从而实现故障检测。

Abstract: This work investigates the reduction of phasor measurement unit (PMU) data
through low-rank matrix approximations. To reconstruct a PMU data matrix from
fewer measurements, we propose the framework of interpolatory matrix
decompositions (IDs). In contrast to methods relying on principal component
analysis or singular value decomposition, IDs recover the complete data matrix
using only a few of its rows (PMU datastreams) and/or a few of its columns
(snapshots in time). This compression enables the real-time monitoring of power
transmission systems using a limited number of measurements, thereby minimizing
communication bandwidth. The ID perspective gives a rigorous error bound on the
quality of the data compression. We propose selecting rows and columns used in
an ID via the discrete empirical interpolation method (DEIM), a greedy
algorithm that aims to control the error bound. This bound leads to a
computable estimate for the reconstruction error during online operations. A
violation of this estimate suggests a change in the system's operating
conditions, and thus serves as a tool for fault detection. Numerical tests
using synthetic PMU data illustrate DEIM's excellent performance for data
compression, and validate the proposed DEIM-based fault-detection method.

</details>


### [334] [Design Optimization and Global Impact Assessment of Solar-Thermal Direct Air Carbon Capture](https://arxiv.org/abs/2510.20135)
*Zhiyuan Fan,Bolun Xu*

Main category: eess.SY

TL;DR: 利用太阳能热直接空气捕获技术，并结合低成本砂基储热技术，可以在高太阳能地区实现低成本（160-200美元/吨）且高效（>80%年容量因子）的碳移除。


<details>
  <summary>Details</summary>
Motivation: 为了应对经济脱碳和满足全球能源需求的双重挑战，需要开发可扩展且具有成本效益的二氧化碳去除技术。直接空气捕获（DAC）是其中一种有前途的方法，但其高能量消耗，特别是吸附剂再生所需的热能，是其成本降低和可持续部署的关键障碍。

Method: 本研究探索了太阳能热DAC系统，该系统将聚光太阳能热技术与低成本砂基储热相结合，以满足能源需求。并分析了该系统在并网和独立运行模式下的技术经济性能。

Result: 研究表明，太阳能热DAC可以实现超过80%的年容量因子，二氧化碳去除成本低至160-200美元/吨，具有成本竞争力。该系统与太阳能利用率匹配的短循环吸附剂配合效率最高。尤其是在太阳能资源丰富、地形沙质的地区，独立的太阳能DAC系统（仅使用太阳能提供电力和热能）极具潜力，并且对温度和湿度的环境敏感性最低。研究确定了一种最优的6000吨/年模块化系统设计，占地面积小于1平方公里，仅在沙质地区就可能实现每年>26 Gt/年的DAC容量。

Conclusion: 太阳能热DAC系统，特别是结合了砂基储热的独立系统，为实现低成本、高效率的碳移除提供了一条有前景的途径，尤其是在具备有利地理条件的地区。

Abstract: The dual challenge of decarbonizing the economy and meeting rising global
energy demand underscores the need for scalable and cost-effective carbon
dioxide removal technologies. Direct air capture (DAC) is among the most
promising approaches, but its high energy intensity, particularly the thermal
energy required for sorbent regeneration, remains a critical barrier to cost
reduction and sustainable deployment. This study explores solar-thermal DAC
systems that combine concentrated solar thermal technology with low-cost
sand-based thermal energy storage to meet this demand. We analyze the
techno-economic performance of such systems in both grid-connected and
stand-alone configurations. Results show that solar-thermal DAC can achieve
annual capacity factors exceeding 80% and CO2 removal costs as low as 160-200
USD per ton, making it competitive with leading DAC technologies. The proposed
system operates most efficiently with short-cycle sorbents that align with
solar availability. The stand-alone Solar-DAC systems, which rely solely on
solar energy for both electricity and thermal energy, are particularly
promising in regions with high solar capacity and sandy terrain, exhibiting
minimal ambient sensitivity from temperature and humidity. An optimal 6000
ton/yr modular system design takes <1 km2 land-use requirement and potentially
>26 Gt/year DAC capacity is identified for sandy terrain alone globally. In
areas with sedimentary basins suitable for CO2 storage, solar-powered DAC
offers a lower-cost alternative to geothermal heating, which often faces
geological and economic constraints.

</details>


### [335] [Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters](https://arxiv.org/abs/2510.20152)
*Junya Ikemoto*

Main category: eess.SY

TL;DR: 提出一种基于仿真的强化学习算法，用于控制具有不确定和可变系统参数的系统。通过在模拟器中为不同参数的系统学习多个控制策略，并使用在线凸优化算法根据观测值对真实系统中的控制策略进行平滑切换来解决现实差距问题。


<details>
  <summary>Details</summary>
Motivation: 解决具有不确定和可变系统参数的系统的控制问题，特别关注模拟与现实之间的差距。

Method: 提出一个两阶段算法：第一阶段，在模拟器中为不同参数的系统学习多个控制策略；第二阶段，使用在线凸优化算法根据观测值对真实系统中的控制策略进行平滑切换。

Result: 通过数值实验验证了所提出算法的有效性。

Conclusion: 所提出的两阶段算法能够有效地解决具有不确定和可变系统参数的系统的控制问题，并能缩小模拟与现实之间的差距。

Abstract: This paper proposes a simulation-based reinforcement learning algorithm for
controlling systems with uncertain and varying system parameters. While
simulators are useful for safely learning control policies for physical
systems, mitigating the reality gap remains a major challenge. To address the
challenge, we propose a two-stage algorithm. In the first stage, multiple
control policies are learned for systems with different parameters in a
simulator. In the second stage, for a real system, the control policies learned
in the first stage are smoothly switched using an online convex optimization
algorithm based on observations. Our proposed algorithm is demonstrated through
numerical experiments.

</details>


### [336] [From Bundles to Backstepping: Geometric Control Barrier Functions for Safety-Critical Control on Manifolds](https://arxiv.org/abs/2510.20202)
*Massimiliano de Sa,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: 该论文提出了在流形上使用控制障碍函数（CBF）的通用理论和合成工具，并将其应用于欠驱动卫星控制。


<details>
  <summary>Details</summary>
Motivation: 现有的CBF理论主要在欧几里得空间中，缺乏处理机器人和航空航天应用中常见的流形系统的通用方法和构造性合成工具。

Method: 提出在向量丛上的一般几何CBF理论，并推广了基于动能的CBF反步法到黎曼流形，用于几何力学系统的CBF合成。

Result: 论文恢复了标准CBF控制器及其光滑类似物，并提供了一种避免在高阶切触丛上进行计算的合成技术。该技术成功应用于SO(3)上的欠驱动卫星。

Conclusion: 该研究为在流形上设计控制器提供了新的理论和方法，并展示了其在实际机器人和航空航天问题中的应用潜力。

Abstract: Control barrier functions (CBFs) have a well-established theory in Euclidean
spaces, yet still lack general formulations and constructive synthesis tools
for systems evolving on manifolds common in robotics and aerospace
applications. In this paper, we develop a general theory of geometric CBFs on
bundles and, for control-affine systems, recover the standard
optimization-based CBF controllers and their smooth analogues. Then, by
generalizing kinetic energy-based CBF backstepping to Riemannian manifolds, we
provide a constructive CBF synthesis technique for geometric mechanical
systems, as well as easily verifiable conditions under which it succeeds.
Further, this technique utilizes mechanical structure to avoid computations on
higher-order tangent bundles. We demonstrate its application to an
underactuated satellite on SO(3).

</details>


### [337] [Observer-based Differentiators for Noisy Signals](https://arxiv.org/abs/2510.20234)
*Van Huynh,Hieu Trinh,Riley Bain*

Main category: eess.SY

TL;DR: 基于观测器的不同系统可以估计带噪声信号的导数。


<details>
  <summary>Details</summary>
Motivation: 提出能估计带噪声信号的导数的观测器系统。

Method: 展示了一系列不同的观测器系统，它们作为微分器工作。

Result: 这些基于观测器的微分器可以生成给定信号的导数估计，即使该信号容易出现噪声。

Conclusion: 基于观测器的微分器能够有效地处理带噪声的信号，并估计其导数。

Abstract: We present a collection of different types of observation systems that work
as differentiators. These observer-based differentiators can produce estimates
for derivatives of a given signal, even though the given signal is prone to
noise.

</details>


### [338] [Multi-layer Optimized Coordination of Smart Building Resources in Active Power Distribution Systems](https://arxiv.org/abs/2510.20313)
*Mohammadali Rostami,Saeed Lotfifard,Mladen Kezunovic*

Main category: eess.SY

TL;DR: 该研究提出一个多方协调平台，用于优化智能建筑资源（如屋顶光伏和电池储能系统）在主动配电系统中的利用。


<details>
  <summary>Details</summary>
Motivation: 为了优化智能建筑资源（包括屋顶光伏发电和电池储能系统）在主动配电系统中的利用，提出一个多方协调平台。

Method: 该平台包含智能建筑协调器（SBC）、微电网协调器（MGC）和配电系统协调器（DSC）。各协调器独立运行，仅交换有限信息，通过分层优化方法确定所有配电系统资源的操作点。

Result: 数值模拟验证了该平台在协调楼内资源与配电系统方面的有效性。

Conclusion: 所提出的平台能够有效协调智能建筑的楼内资源（如光伏和储能）与配电系统，同时保证了楼内数据的机密性，并且具有灵活可扩展的架构。

Abstract: This paper proposes a multi-actor coordination platform for the optimal
utilization of smart buildings resources, including roof top PV generation and
battery energy storage system (BESS), in active power distribution systems. The
proposed multi-actor coordination includes the Smart Building Coordinator
(SBC), Micro-Grid Coordinator (MGC) and Distribution System Coordinator (DSC).
The coordinators operate independently and only exchange limited information
with each other to reach an optimal solution. In the proposed platform, a
hierarchical optimization problem is solved to optimally determine the
operating point of all distribution system resources. The proposed platform
fully preserves the confidentiality of the behind the meter (BTM) data of the
buildings since no information about the status of the PV system, BESS, and
load of the building is shared with the owner of the power system. The proposed
platform has a flexible and scalable architecture where the computational task
of coordinating microgrids and smart buildings with distribution grid is
performed locally at the MGC and SBC layers, respectively. Numerical
simulations show the efficacy of the proposed platform in coordinating the BTM
resources with the rest of the distribution system.

</details>


### [339] [On MIMO Stability Analysis Methods Applied to Inverter-Based Resources Connected to Power Systems](https://arxiv.org/abs/2510.20384)
*Anton A. Stoorvogel,Saeed Lotfifard,Ali Saberi*

Main category: eess.SY

TL;DR: 该论文批判性地回顾了文献中常用于并网逆变器（IBRs）小信号稳定性分析的方法，讨论了这些方法的预期用途、正确和不当之处，并阐述了它们的适用性、局限性和常见误解。


<details>
  <summary>Details</summary>
Motivation: 对文献中常用的并网逆变器（IBRs）小信号稳定性分析方法进行批判性回顾，阐明其预期用途、适用性、局限性及常见误解。

Method: 对文献中常用的并网逆变器（IBRs）小信号稳定性分析方法进行批判性回顾和讨论。

Result: 提供了对这些分析方法的深入见解，阐明了它们的适用性、局限性以及常见的误解。

Conclusion: 该论文旨在帮助研究人员和工程师更准确地理解和应用这些小信号稳定性分析方法，避免潜在的错误。

Abstract: This paper presents a critical review of methods
  commonly employed in the literature for small signal stability analysis of
  inverter based resources (IBRs). It discusses the intended purposes
  of these methods and outlines both their proper and improper
  implementations. The paper provides insights into the applicability
  of these techniques, clarifies their inherent limitations, and
  discusses and illustrates common sources of misinterpretation.

</details>


### [340] [Interlacing in Controllers Implementation: Frequency Analysis](https://arxiv.org/abs/2510.20394)
*Julian Salt*

Main category: eess.SY

TL;DR: 利用交错技术实现 LTI 控制器，并在资源受限环境中实现计算节省。


<details>
  <summary>Details</summary>
Motivation: 解释如何为 LTI 控制器实现使用交错技术，并在此环境中分析不同的结构。

Method: 介绍用于获取与不同实数和复数控制器极点相关的块的新程序。使用适当的离散提升技术对所得时变系统进行建模，并通过新的、高效的双速率频率响应计算来确定具有交错控制器的控制环路的特性。

Result: 新的、高效的双速率频率响应计算。

Conclusion: 交错技术可用于 LTI 控制器的实现，并在资源受限环境中实现计算节省。

Abstract: The main goal of this contribution is to explain how to use interlacing
techniques for LTI controllers implementation and analyze different struc-
tures in this environment. These considerations lead to an important com-
putation saving in constrained resource environments. It has been also intro-
duced new procedures for obtaining the blocks related to different real and
complex controllers poles. The resultant time-varying system is modeled using
proper discrete lifting techniques and a new and efficient dual-rate fre-
quency response computation allows to determine the characteristics of the
control loop with interlaced controller. Examples illustrate the theoretical
proposals.

</details>


### [341] [A Multifunctional Capacitive Sensing Platform for Wireless Vascular and Heart Monitoring](https://arxiv.org/abs/2510.20415)
*Parviz Zolfaghari,Beril Yagmur Koca,Taher Abbasiasl,Hakan Urey,Hadi Mirzajani*

Main category: eess.SY

TL;DR: 我们提出了一种多功能、集成天线的电容传感（MAiCaS）平台，用于被动、无线和实时的心血管监测。该设备将传感、遥测和机械功能统一到一个紧凑且可扩展的设计中，利用电感天线的寄生电容作为应变敏感元件。


<details>
  <summary>Details</summary>
Motivation: 与需要独立传感器和无线模块的传统系统不同，我们的设备将传感、遥测和机械功能统一到一个紧凑且可扩展的设计中，利用电感天线的寄生电容作为应变敏感元件。

Method: 该传感器采用无洁净室、单步紫外激光图案化工艺在柔性 PDMS 衬底上制造，减少了制造复杂性并实现了高重现性。MAiCaS 适用于三种不同的应用：作为心外膜应变测量的传感器、作为支架的传感器和作为血管移植物传感器。我们通过验证其在展开和卷曲形式下的无线共振响应来展示 MAiCaS 的多功能性。

Result: 体外实验表明，在生理条件下共振频率持续偏移，并且在皮肤、PBS、人血清和模拟血管环境中表现稳定。重复性和老化测试证实了其在循环载荷下的长期可靠性和弹性。校准曲线显示了所有配置均具有高灵敏度，通过 S11 参数测量和共振频率偏移作为输出指标实现了无线询问。对于心外膜贴片、移植物和支架集成传感器，设备的灵敏度分别为 2.9 MHz/1% 应变、0.43 MHz/mmHg 和 309.6 kHz/µm。在人体实验中评估了 MAiCaS 的运行情况。

Conclusion: 这种整体式传感器架构为电池供电的心血管动力学监测提供了一种可扩展且经济高效的解决方案，并有可能用于远程诊断、术后随访和持续心血管健康管理。

Abstract: We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

</details>


### [342] [Behavior-Aware Online Prediction of Obstacle Occupancy using Zonotopes](https://arxiv.org/abs/2510.20437)
*Alvaro Carrizosa-Rendon,Jian Zhou,Erik Frisk,Vicenc Puig,Fatiha Nejjari*

Main category: eess.SY

TL;DR: 该研究提出了一种基于运动观测的在线方法，用于预测周围车辆的占有集合，以实现安全自主驾驶。


<details>
  <summary>Details</summary>
Motivation: 在没有先验信息的情况下，尤其是在非结构化环境中，预测周围车辆的运动对于安全自动驾驶至关重要。

Method: 该方法分为两个阶段：首先，利用扩展卡尔曼滤波器和线性规划（LP）问题来估计一个紧凑的控制动作区域集；然后，利用可达性分析来传播该集合以预测未来的占有情况。

Result: 通过在城市环境中的仿真验证了该方法的有效性，结果显示该方法能够在不依赖先验假设或先验训练数据的情况下，进行准确且紧凑的预测。

Conclusion: 该方法能够仅基于运动观测，准确预测周围车辆的占有集合，为安全自动驾驶提供支持。

Abstract: Predicting the motion of surrounding vehicles is key to safe autonomous
driving, especially in unstructured environments without prior information.
This paper proposes a novel online method to accurately predict the occupancy
sets of surrounding vehicles based solely on motion observations. The approach
is divided into two stages: first, an Extended Kalman Filter and a Linear
Programming (LP) problem are used to estimate a compact zonotopic set of
control actions; then, a reachability analysis propagates this set to predict
future occupancy. The effectiveness of the method has been validated through
simulations in an urban environment, showing accurate and compact predictions
without relying on prior assumptions or prior training data.

</details>


### [343] [Joint Computation Offloading and Resource Management for Cooperative Satellite-Aerial-Marine Internet of Things Networks](https://arxiv.org/abs/2510.20443)
*Shuang Qi,Bin Lin,Yiqin Deng,Hongyang Pan,Xu Hu*

Main category: eess.SY

TL;DR: 本文提出了一种用于海洋边缘计算和数据存储的协同卫星-空中-MIoT网络（CSAMN），通过移动边缘计算优先处理延迟敏感（DS）任务，并利用存储-携带-转发方法处理延迟容忍（DT）任务。通过联合优化无人机传输功率、任务开始时间、计算资源分配和卸载率，实现了在满足延迟约束的同时，最大化卫星收集数据量并最小化系统能耗。提出的JCORM算法采用Dinkelbach方法和线性规划求解，相比基线方法，数据收集量提升高达41.5%，计算时间从318.21秒大幅减少至0.16秒。


<details>
  <summary>Details</summary>
Motivation: 在海洋物联网（MIoT）环境中，虽然可以连接低地球轨道（LEO）卫星和无人机（UAV）以实现低延迟数据传输和增强的存储容量，但缺乏有效的流量处理策略仍然难以满足低延迟要求。

Method: 提出了一种协同卫星-空中-MIoT网络（CSAMN），用于海洋边缘计算和数据存储。该网络通过移动边缘计算优先处理延迟敏感（DS）任务，并利用存储-携带-转发方法处理延迟容忍（DT）任务。针对DS任务的延迟约束，构建了一个联合优化问题，旨在最大化卫星收集的数据量并最小化系统能耗，通过控制无人机传输功率、DT任务开始时间、计算资源分配和卸载率这四个相互依赖的变量来实现。该非凸非线性问题利用Dinkelbach方法和线性规划提出的联合计算卸载和资源管理（JCORM）算法进行求解。

Result: 与基线方法相比，JCORM算法将卫星收集的数据量提高了41.5%。此外，JCORM算法将每次实验的计算时间从最多318.21秒大幅缩短至0.16秒。

Conclusion: JCORM算法能够显著提高海洋边缘计算和数据存储的性能，特别是在数据收集量和处理速度方面，使其非常适合实时海洋应用。

Abstract: Devices within the marine Internet of Things (MIoT) can connect to low Earth
orbit (LEO) satellites and unmanned aerial vehicles (UAVs) to facilitate
low-latency data transmission and execution, as well as enhanced-capacity data
storage. However, without proper traffic handling strategy, it is still
difficult to effectively meet the low-latency requirements. In this paper, we
consider a cooperative satellite-aerial-MIoT network (CSAMN) for maritime edge
computing and maritime data storage to prioritize delay-sensitive (DS) tasks by
employing mobile edge computing, while handling delay-tolerant (DT) tasks via
the store-carry-forward method. Considering the delay constraints of DS tasks,
we formulate a constrained joint optimization problem of maximizing
satellite-collected data volume while minimizing system energy consumption by
controlling four interdependent variables, including the transmit power of UAVs
for DS tasks, the start time of DT tasks, computing resource allocation, and
offloading ratio. To solve this non-convex and non-linear problem, we propose a
joint computation offloading and resource management (JCORM) algorithm using
the Dinkelbach method and linear programming. Our results show that the volume
of data collected by the proposed JCORM algorithm can be increased by up to
41.5% compared to baselines. Moreover, JCORM algorithm achieves a dramatic
reduction in computational time, from a maximum of 318.21 seconds down to just
0.16 seconds per experiment, making it highly suitable for real-time maritime
applications.

</details>


### [344] [Decentralized Small Gain and Phase Stability Conditions for Grid-Forming Converters: Limitations and Extensions](https://arxiv.org/abs/2510.20544)
*Diego Cifelli,Adolfo Anta*

Main category: eess.SY

TL;DR: 本文提出了一种改进的混合增益-相位稳定性评估方法，用于解决并网变换器在低频下的扇形性假设限制，提高了方法的适用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统中基于变换器的分布式发电资源份额的增加，需要可扩展的方法来分析稳定性，而不依赖于详尽的系统级模拟。然而，现有的分散式小增益和小相位准则在应用于电网形成变换器时，由于不满足低频下的扇形性假设而受到严重限制。

Method: 本文重新审视并扩展了混合增益-相位条件，引入了回路整形变换，在替代坐标系中重新构建了变换器和网络模型，以解决低频下的内禀非扇形性问题并降低保守性。

Result: 通过在无限母线系统和 IEEE 14 节点网络中进行分析和扩展，证明了该方法在实践中的可行性和可扩展性，提高了分散式稳定性认证的适用性。

Conclusion: 所提出的方法通过引入回路整形变换，解决了低频下的非扇形性问题，降低了保守性，从而提高了分散式稳定性认证在电力系统中的适用性和可扩展性，为开发更少保守和更广泛适用的分散式稳定性证书提供了途径。

Abstract: The increasing share of converter based resources in power systems calls for
scalable methods to analyse stability without relying on exhaustive system wide
simulations. Decentralized small gain and small-phase criteria have recently
been proposed for this purpose, but their applicability to grid forming
converters is severely limited by the sectoriality assumption, which is not
typically satisfied at low frequencies. This work revisits and extends mixed
gain phase conditions by introducing loop shaping transformations that
reformulate converter and network models in alternative coordinate frames. The
proposed approach resolves intrinsic non sectoriality at low frequencies and
reduces conservativeness, thereby improving the applicability of decentralized
stability certification. Analytical results are illustrated using an infinite
bus system first and then extended to the IEEE 14 bus network, demonstrating
the practicality and scalability of the method. These findings provide a
pathway toward less conservative and more widely applicable decentralized
stability certificates in power grids.

</details>


### [345] [Safe Decentralized Density Control of Multi-Robot Systems using PDE-Constrained Optimization with State Constraints](https://arxiv.org/abs/2510.20643)
*Longchen Niu,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本研究提出了一种去中心化的基于优化的密度控制器，用于在多机器人系统中强制执行集合不变性约束。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中局部安全约束到全局安全保证的挑战，并考虑了实际的定位和运动噪声。

Method: 设计了去中心化的控制障碍函数，并使用福克-普朗克方程对受定位和运动噪声影响的空间概率密度函数进行建模。

Result: 所提出的控制器在计算和通信方面比传统集中式方法的要求更低，并通过涉及四旋翼飞行器的仿真和实验进行了验证。

Conclusion: 该控制器在通信和定位不完美的情况下适用于多机器人系统。

Abstract: In this paper, we introduce a decentralized optimization-based density
controller designed to enforce set invariance constraints in multi-robot
systems. By designing a decentralized control barrier function, we derived
sufficient conditions under which local safety constraints guarantee global
safety. We account for localization and motion noise explicitly by modeling
robots as spatial probability density functions governed by the Fokker-Planck
equation. Compared to traditional centralized approaches, our controller
requires less computational and communication power, making it more suitable
for deployment in situations where perfect communication and localization are
impractical. The controller is validated through simulations and experiments
with four quadcopters.

</details>


### [346] [Sugar Shack 4.0: Implementation of a Cyber-Physical System for Logistic and Sanitary Automation in a Maple Syrup Boiling Center](https://arxiv.org/abs/2510.20682)
*Thomas Bernard,François Grondin,Jean-Michel Lavoie*

Main category: eess.SY

TL;DR: 该系统通过事件驱动的编排自动化了枫糖浆生产中心的工厂级物流、可追溯性和卫生管理，提高了效率并确保了产品质量。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过设计和部署一个过程感知的网络物理系统来自动化枫糖浆生产中心的工厂级物流、可追溯性和卫生管理，以取代临时的人工操作。

Method: 该系统采用事件驱动的编排、可重用的设备抽象、基于优先级的仲裁的集中式联锁，并实现了确定性的例程，用于输送、反渗透集成、蒸发器进料和渗透物管理。它还利用了流量、温度和糖浓度（Brix度）的在线测量来驱动路由决策和触发系统的原位清洗（CIP），以确保卫生和可追溯性。

Result: 在2025个生产季节中，该系统成功处理了431个操作，执行了908个“topstock”和“downstock”平衡周期，通过动态存储分配将可用渗透物储备从22,712升增加到约41,640升，消除了之前手动操作期间出现的中季污染事件，并通过自动文档记录将账单和报告的管理工作从30小时以上减少到约1小时。

Conclusion: 该系统为超越传统架构的模块化、工厂规模自动化提供了一条实用的途径，并为将可重用组件应用于类似工厂或相关行业奠定了基础。这是在枫糖浆生产中心科学地记录的首次工业4.0技术集成的一部分。

Abstract: This paper presents the design and deployment of a process-aware
cyber-physical system that automates plant-level logistics, traceability, and
sanitation in a centralized maple-syrup boiling center. The system replaces
ad-hoc, manual operations with event-driven orchestration on a local server,
employing reusable device abstractions and a centralized interlock with
priority-based arbitration for shared piping. It implements deterministic
routines for delivery, reverse osmosis integration, evaporator feed, and
permeate management. The system is sensor rich: inline measurements of flow,
temperature, and sugar concentration (degrees Brix) drive routing decisions and
trigger systematic post-transfer rinses (cleaning-in-place), ensuring
consistent hygiene and complete, immediate traceability up to the evaporator
inlet. During the 2025 production season, the system queued 431 operations
without incident; executed 908 \enquote{topstock} and \enquote{downstock}
balancing cycles; increased usable permeate reserves from 22,712 to
approximately 41,640 L through dynamic storage assignment; eliminated
mid-season contamination incidents previously observed under manual practice;
and reduced administrative effort for billing and reporting from more than 30
hours to roughly 1 hour through automatic documentation. These results
demonstrate a practical path to modular, plant-scale automation beyond
traditional architectures, and lay the groundwork for packaging reusable
elements for similar plants or adjacent industries. This work is part of a
larger project involving the first scientifically-documented integration of
Industry 4.0 technologies in a maple syrup boiling center.

</details>


### [347] [Learning Optimal Power Flow with Pointwise Constraints](https://arxiv.org/abs/2510.20777)
*Damian Owerko,Anna Scaglione,Alejandro Ribeiro*

Main category: eess.SY

TL;DR: 提出了一种通过训练学习参数化来求解具有逐点约束的优 optimal power flow (OPF) 的方法，与现有方法不同，该方法要求约束适用于所有问题实例，并在对偶域中进行训练，以实现更小的约束违反，尤其是在具有大量节点的电力系统中。


<details>
  <summary>Details</summary>
Motivation: 现有的监督学习方法要求约束满足问题实例的平均值，而本文提出了一种新的方法，直接将学习参数化代入具有逐点约束的 OPF 问题，以确保约束适用于所有问题实例。

Method: 在对偶域中使用增广拉格朗日和对偶梯度上升算法来训练具有逐点约束的学习参数化。

Result: 与现有方法相比，所提出的方法在数值实验中产生的约束违反更小，尤其是在约束最难满足的角落情况和具有大量节点的电力系统中。

Conclusion: 在 OPF 问题中，在所有问题实例中强制执行逐点约束可以显着减小约束违反，尤其是在角落情况和大型电力系统中。

Abstract: Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

</details>


### [348] [Bilevel Analysis of Cost and Emissions Externalities from Data Center Load Shifting](https://arxiv.org/abs/2510.20805)
*Aron Brenner,Rahman Khorramfar,Nathan Engelman Lado,Line Roald,Saurabh Amin*

Main category: eess.SY

TL;DR: 数据中心的可调度性可能有助于减少排放，但其对电网运行的影响取决于其与网络限制和市场信号的相互作用。本文提出了一种双层优化框架，模拟了数据中心在成本和排放方面的优化行为，以及电网运营商在满足电网约束下的调度行为，并分析了两者之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 理解数据中心的可调度性如何与电网约束和市场信号相互作用，以及这种相互作用如何影响减排和电网运行。

Method: 使用双层优化框架，其中数据中心最小化电力成本和边际排放强度的加权组合，而系统运营商在考虑传输和发电约束的情况下进行经济调度。针对一个简化的三节点电网系统，推导出目标函数与数据中心负荷转移量的函数关系，并分析了拥塞和可再生能源饱和引起的阈值变化。

Result: 得出了数据中心和全网目标函数的解析表达式，并识别了数据中心分散决策与社会最优行为一致或不一致的充分条件。分析了系统拓扑和发电机不对称性如何影响激励一致性，以及边际价格或排放信号何时可能无法引导灵活负荷实现社会效益。

Conclusion: 数据中心的灵活负荷调度和电网的碳感知激励需要更好的协调。研究结果为分析碳感知激励下的分散式灵活性提供了一个可行的起点，并为改进灵活负荷与电网运行之间的协调提供了方向。

Abstract: Data centers are emerging as large, flexible electricity consumers capable of
shifting computational workloads across locations in response to economic and
environmental signals. While this flexibility has potential for emissions
reduction, its impact on power system operations depends critically on how such
behavior interacts with network constraints and market signals. We develop a
bilevel optimization framework in which a data center minimizes a weighted
combination of electricity cost and marginal emissions intensity (LME), while
the system operator clears economic dispatch under transmission and generation
constraints. Focusing on a stylized three-bus power system, we derive
closed-form, piecewise-linear expressions for both the data center and
system-wide objectives as functions of the data centers' load shift. These
expressions capture threshold-driven regime changes due to congestion and
renewable saturation. We identify sufficient conditions under which the data
center's decentralized decisions align with or diverge from socially optimal
behavior and characterize the resulting externalities. Our results reveal how
system topology and generator asymmetry affect incentive alignment and provide
insight into when marginal price or emissions signals may fail to guide
flexible loads toward socially beneficial outcomes. Our results offer a
tractable starting point for analyzing decentralized flexibility under
carbon-aware incentives and suggest directions for improving coordination
between flexible loads and system operations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [349] [Macroscopic quantum phenomena and quantum computing](https://arxiv.org/abs/2510.19846)
*Jian-Qiang You*

Main category: quant-ph

TL;DR: 基于2025年诺贝尔物理学奖的发现，探讨了宏观量子隧穿和超导电路中能量量子化的突破性发现，回顾了这一突破的历程和原因，以及它对量子计算后续进展的影响。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提供对2025年诺贝尔物理学奖的视角，重点关注宏观量子隧穿和超导电路中能量量子化的突破性发现，以及该发现对量子计算领域产生的深远影响。

Method: 本文以新闻和观点文章的形式，对2025年诺贝尔物理学奖的成就进行了回顾和评述。

Result: 宏观量子隧穿和能量量子化在超导电路中的发现是该奖项的核心，并且对量子计算的发展起到了关键作用。

Conclusion: 该发现不仅是物理学上的重大突破，也为量子计算的未来发展奠定了重要基础。

Abstract: This News & Views article provides a perspective on the 2025 Nobel Prize in
Physics, including the groundbreaking discovery of macroscopic quantum
tunneling and energy quantization in superconducting circuits, the history and
causes giving rise to this breakthrough, and its impact on subsequent progress
in quantum computing.

</details>


### [350] [Two Quantum Algorithms for Nonlinear Reaction-Diffusion Equation using Chebyshev Approximation Method](https://arxiv.org/abs/2510.19855)
*Manish Kumar*

Main category: quant-ph

TL;DR: 本文提出了两种新的量子算法，用于求解反应扩散方程。


<details>
  <summary>Details</summary>
Motivation: 反应扩散方程在科学和工程中有广泛应用，但其数值求解通常计算成本高昂。本文旨在利用量子计算提供更有效的求解方法。

Method: 本文提出了两种基于截断切比雪夫多项式近似的量子算法。第一种算法使用矩阵指数化方法，第二种算法则改进了量子谱方法。两种算法的关键技术贡献在于推导了卡尔曼嵌入矩阵对角化的充分条件，并提供了一个有效的迭代算法来对角化该矩阵。

Result: 第一种算法的门复杂度为O(d·log(d)+T·polylog(T/ε))。第二种算法的门复杂度为O(polylog(d)·T·polylog(T/ε))，在T和ε方面与现有最优量子算法（截断泰勒级数方法）相当。

Conclusion: 本文提出的两种量子算法为反应扩散方程的求解提供了新的有效途径。尽管存在一些不足之处，例如卡尔曼矩阵条件数的上界和对一个三角方程解的猜想，但作者也提出了相应的缓解策略。

Abstract: We present two new quantum algorithms for reaction-diffusion equations that
employ the truncated Chebyshev polynomial approximation. This method is
employed to numerically solve the ordinary differential equation emerging from
the linearization of the associated nonlinear differential equation. In the
first algorithm, we use the matrix exponentiation method (Patel et al., 2018),
while in the second algorithm, we repurpose the quantum spectral method (Childs
et al., 2020). Our main technical contribution is to derive the sufficient
conditions for the diagonalization of the Carleman embedding matrix, which is
indispensable for designing both quantum algorithms. We supplement this with an
efficient iterative algorithm to diagonalize the Carleman matrix.
  Our first algorithm has gate complexity of
O(d$\cdot$log(d)+T$\cdot$polylog(T/$\varepsilon$)). Here $d$ is the size of the
Carleman matrix, $T$ is the simulation time, and $\varepsilon$ is the
approximation error. The second algorithm is polynomial in $log(d)$, $T$, and
$log(1/\varepsilon)$ - the gate complexity scales as
O(polylog(d)$\cdot$T$\cdot$polylog(T/$\varepsilon$)). In terms of $T$ and
$\varepsilon$, this is comparable to the speedup gained by the current best
known quantum algorithm for this problem, the truncated Taylor series method
(Costa et.al., 2025).
  Our approach has two shortcomings. First, we have not provided an upper
bound, in terms of d, on the condition number of the Carleman matrix. Second,
the success of the diagonalization is based on a conjecture that a specific
trigonometric equation has no integral solution. However, we provide strategies
to mitigate these shortcomings in most practical cases.

</details>


### [351] [Experimental differentiation and extremization with analog quantum circuits](https://arxiv.org/abs/2510.20713)
*Evan Philip,Julius de Hond,Vytautas Abramavicius,Kaonan Micadei,Mario Dagrada,Panagiotis Barkoutsos,Mourad Beji,Louis-Paul Henry,Vincent E. Elfving,Antonio A. Gentile,Savvas Varsamopoulos*

Main category: quant-ph

TL;DR: DQC and QEL, originally designed for digital quantum computers, have been successfully demonstrated on an analog quantum computer for solving differential equations.


<details>
  <summary>Details</summary>
Motivation: The ubiquitous nature of differential equations in science and engineering necessitates efficient solution methods, with quantum computing showing promise for acceleration. DQC and QEL are potential quantum approaches for this.

Method: The paper experimentally demonstrates both Differentiable Quantum Circuits (DQC) and Quantum Extremal Learning (QEL) on a commercial analog quantum computer using neutral atom technology, testing their performance on a synthetic use case.

Result: The successful experimental demonstration of DQC and QEL on an analog quantum computer, challenging the assumption that they require digital hardware.

Conclusion: DQC and QEL can be effectively implemented on analog quantum hardware, opening new possibilities for solving differential equations and finding their extrema using current quantum technologies.

Abstract: Solving and optimizing differential equations (DEs) is ubiquitous in both
engineering and fundamental science. The promise of quantum architectures to
accelerate scientific computing thus naturally involved interest towards how
efficiently quantum algorithms can solve DEs. Differentiable quantum circuits
(DQC) offer a viable route to compute DE solutions using a variational approach
amenable to existing quantum computers, by producing a machine-learnable
surrogate of the solution. Quantum extremal learning (QEL) complements such
approach by finding extreme points in the output of learnable models of unknown
(implicit) functions, offering a powerful tool to bypass a full DE solution, in
cases where the crux consists in retrieving solution extrema. In this work, we
provide the results from the first experimental demonstration of both DQC and
QEL, displaying their performance on a synthetic usecase. Whilst both DQC and
QEL are expected to require digital quantum hardware, we successfully challenge
this assumption by running a closed-loop instance on a commercial analog
quantum computer, based upon neutral atom technology.

</details>


### [352] [Mind the gaps: The fraught road to quantum advantage](https://arxiv.org/abs/2510.19928)
*Jens Eisert,John Preskill*

Main category: quant-ph

TL;DR: NISQ到FASQ的量子计算仍有差距，需要克服从误差缓解到纠错、从粗略纠错到可扩展容错、从初步启发式到可验证算法、从探索性模拟到可信优势等四个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 弥合当前嘈杂中型量子（NISQ）设备与未来容错应用规模（FASQ）量子机之间的巨大差距，加速实现广泛有用的量子计算。

Method: 识别并阐述了从误差缓解到主动纠错和校正，从粗略的误差校正到可扩展的容错，从早期的启发式算法到成熟、可验证的算法，以及从探索性模拟器到可信的量子模拟优势这四个关键的过渡和挑战。

Result: 指出了实现广泛有用的量子计算所面临的四个主要挑战，并强调了克服这些挑战对于加速量子计算发展的重要性。

Conclusion: 明确了未来量子计算发展面临的四大挑战，并提出应着力于克服这些挑战以加速实现可广泛应用的量子计算。

Abstract: Quantum computing is advancing rapidly, yet substantial gaps separate today's
noisy intermediate-scale quantum (NISQ) devices from tomorrow's fault-tolerant
application-scale (FASQ) machines. We identify four related hurdles along the
road ahead: (i) from error mitigation to active error detection and correction,
(ii) from rudimentary error correction to scalable fault tolerance, (iii) from
early heuristics to mature, verifiable algorithms, and (iv) from exploratory
simulators to credible advantage in quantum simulation. Targeting these
transitions will accelerate progress toward broadly useful quantum computing.

</details>


### [353] [Classical Gravity Cannot Mediate Entanglement by Local Means](https://arxiv.org/abs/2510.19969)
*Chiara Marletto,Vlatko Vedral*

Main category: quant-ph

TL;DR: 文章反驳了一篇声称经典引力可以通过局部手段将两个宏观物体纠缠在一起的论文，并指出如果引力能够实现远距离质量的局部纠缠，那么量子引力是必需的。


<details>
  <summary>Details</summary>
Motivation: 反驳近期声称经典引力可以通过局部手段实现宏观物体纠缠的论文，并纠正其中出现的谬误。

Method: 通过理论分析和论证，揭示该论文的错误概念，并阐述量子引力在引力场中实现远距离质量局部纠缠的必要性。

Result: 证明了经典引力无法实现宏观物体的局部纠缠，并强调了量子引力的重要性。

Conclusion: 如果引力能够实现远距离质量的局部纠缠，那么量子引力是必需的。

Abstract: We rebut a recent paper that claims that classical gravity can entangle two
massive superpositions by local means. We refute the misconceptions appearing
in this paper and confirm that the quantum features are necessary in the
gravitational field if it can lead to entanglement by local propagation between
distant masses.

</details>


### [354] [Morphological computational capacity of Physarum polycephalum](https://arxiv.org/abs/2510.19976)
*Suyash Bajpai,Aviva Lucas-DeMott,Nirosha J Murugan,Michael Levin,Philip Kurian*

Main category: quant-ph

TL;DR: 该研究为无神经生物（以粘菌为例）设定了严格的计算能力上限。


<details>
  <summary>Details</summary>
Motivation: 在已估计宇宙和碳基生命的计算能力极限后，该研究旨在确定无神经生物的计算能力上限。

Method: 通过分析两种粘菌在不同生物条件下的生长动态，将形态演变与信息处理联系起来。研究量化了粘菌的面积、周长、圆形度和分形维度，并结合能量（ATP空间分布）和探索区域来计算其计算能力。

Result: 基于ATP空间分布和探索区域，粘菌在24小时内可执行高达10^36次逻辑运算，且在非平衡稳态下呈线性增长。

Conclusion: 该研究提出了一个框架，用于比较不同生命形式（包括利用经典或量子自由度）的计算能力，并为无神经生物（粘菌）设定了每24小时高达10^36次逻辑运算的计算能力上限。

Abstract: While computational capacity limits of the universe and carbon-based life
have been estimated, a stricter bound for aneural organisms has not been
established. Physarum polycephalum, a unicellular, multinucleated amoeba, is
capable of complex problem-solving despite lacking neurons. By analyzing growth
dynamics in two distinct Physarum strains under diverse biological conditions,
we map morphological evolution to information processing. As the
Margolus-Levitin theorem constrains maximum computation rates by accessible
energies, we analyze high-throughput time-series data of Physarum's
morphology--quantified through area, perimeter, circularity, and fractal
dimension-to determine upper bounds on the number of logical operations
achievable through its hydromechanical, chemical, kinetic, and quantum-optical
degrees of freedom. Based on spatial distribution of ATP and explored areas,
Physarum can perform up to ~$10^{36}$ logical operations in 24 hours, scaling
linearly in the non-equilibrium steady state. This framework enables comparison
of the computational capacities of life, exploiting either classical or quantum
degrees of freedom.

</details>


### [355] [On Encoding Matrices using Quantum Circuits](https://arxiv.org/abs/2510.20030)
*Liron Mor Yosef,Haim Avron*

Main category: quant-ph

TL;DR: 本论文研究了量子计算中用于表示矩阵和向量的两种主要编码方法：块编码和状态制备电路。研究了从经典形式构建这些表示的方法，以及它们之间的双向转换。主要贡献包括：(a) 提供了一种从经典随机访问存储器中的矩阵高效构建块编码的通用方法；(b) 提出了低开销的双向转换算法，证明了块编码和状态制备电路的等价性。


<details>
  <summary>Details</summary>
Motivation: 量子计算在数值线性代数方面具有潜力，能够实现比经典算法更优越的复杂度。然而，要有效执行这些算法，需要将输入（矩阵和向量）表示为量子电路。本研究旨在系统地研究和改进这些表示方法。

Method: 研究了块编码和状态制备电路这两种编码方法。重点研究了如何从经典形式的矩阵构建这些量子表示，以及如何在两种电路表示之间进行转换。论文中使用了两个关键技术组件：(i) 一个特殊的常数深度多路复用器，用于同时多路复用给定大小的所有高阶泡利矩阵；(ii) 一个用于在矩阵的标准基展开和高阶泡利矩阵基展开之间进行量子转换的算法。

Result: 1. 提出了一种通用的、高效的方法，可以从经典形式（存储在经典随机访问存储器中）的任意矩阵构建块编码。
2. 开发了低开销的双向转换算法，可以在块编码和状态制备电路之间进行转换，表明这两种模型在本质上是等价的。

Conclusion: 块编码和状态制备电路是表示量子算法输入（矩阵和向量）的两种主要方法。本研究通过提供从经典数据构建块编码的有效方法以及实现两种表示之间的高效双向转换，为量子线性代数算法的实际应用奠定了基础。这两种编码模型被证明是等价的，降低了在不同场景下选择表示方法的门槛。

Abstract: Over a decade ago, it was demonstrated that quantum computing has the
potential to revolutionize numerical linear algebra by enabling algorithms with
complexity superior to what is classically achievable, e.g., the seminal HHL
algorithm for solving linear systems. Efficient execution of such algorithms
critically depends on representing inputs (matrices and vectors) as quantum
circuits that encode or implement these inputs. For that task, two common
circuit representations emerged in the literature: block encodings and state
preparation circuits. In this paper, we systematically study encodings matrices
in the form of block encodings and state preparation circuits. We examine
methods for constructing these representations from matrices given in classical
form, as well as quantum two-way conversions between circuit representations.
Two key results we establish (among others) are: (a) a general method for
efficiently constructing a block encoding of an arbitrary matrix given in
classical form (entries stored in classical random access memory); and (b)
low-overhead, bidirectional conversion algorithms between block encodings and
state preparation circuits, showing that these models are essentially
equivalent. From a technical perspective, two central components of our
constructions are: (i) a special constant-depth multiplexer that simultaneously
multiplexes all higher-order Pauli matrices of a given size, and (ii) an
algorithm for performing a quantum conversion between a matrix's expansion in
the standard basis and its expansion in the basis of higher-order Pauli
matrices.

</details>


### [356] [A transmon qubit realized by exploiting the superconductor-insulator transition](https://arxiv.org/abs/2510.19983)
*C. G. L. Bøttcher,E. Önder,T. Connolly,J. Zhao,C. Kvande,D. Q. Wang,P. D. Kurilovich,S. Vaitiekėnas,L. I. Glazman,H. X. Tang,M. H. Devoret*

Main category: quant-ph

TL;DR: 使用铌腈薄膜的超导体-绝缘体转变来制造量子比特，解决了传统约瑟夫森结的可扩展性限制。


<details>
  <summary>Details</summary>
Motivation: 传统约瑟夫森结在可扩展性、工作温度和寄生电容方面存在限制，阻碍了量子计算机的发展。

Method: 通过原子层沉积和原子层蚀刻，利用铌腈薄膜的超导体-绝缘体转变来制造量子比特。

Result: 成功制造出一种名为'planaron'的跨膜量子比特，具有235兆赫兹的弛豫率和15兆赫兹的线宽。

Conclusion: 提出的新型弱链接方法解决了传统约瑟夫森结的限制，为实现高温度操作和可扩展的量子计算机提供了新的途径，并为研究超导体-绝缘体转变提供了机会。

Abstract: Superconducting qubits are among the most promising platforms for realizing
practical quantum computers. One requirement to create a quantum processor is
nonlinearity, which in superconducting circuits is typically achieved by
sandwiching a layer of aluminum oxide between two aluminum electrodes to form a
Josephson junction. These junctions, however, face several limitations that
hinder their scalability: the small superconducting gap of aluminum
necessitates millikelvin operating temperatures, the material interfaces lead
to dissipation, and the sandwich geometry adds unwelcome capacitance for
high-frequency applications. In this work, we address all three limitations
using a novel superconducting weak link based on the superconductor-insulator
transition. By locally thinning a single film of niobium nitride, we exploit
its thickness-driven superconductor-insulator transition to form a weak link
employing only atomic layer deposition and atomic layer etching. We utilize our
weak links to produce a transmon qubit, '$planaron$', with a measured
anharmonicity of $\alpha/2\pi = 235$ MHz; at present, the linewidth is
$\kappa/2\pi = 15 \mathrm{\: MHz}$. The high superconducting gap of niobium
nitride can enable operation at elevated temperatures in future devices, and
the fully planar geometry of the weak link eliminates superfluous material
interfaces and capacitances. The investigation of small patches of material
near the SIT can shed new light on the nature of the transition, including the
role of dissipation and finite-size effects.

</details>


### [357] [On the separation of quantum time evolution into holonomic and dynamical parts](https://arxiv.org/abs/2510.19987)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 量子时间演化的全纯和动力学分离在非绝热非阿贝尔情况下通常无效。


<details>
  <summary>Details</summary>
Motivation: 解决在非绝热非阿贝尔情况下将薛定谔类型量子时间演化分离成全纯和动力学部分的问题。

Method: 通过推导和分析，证明了这种分离的普遍无效性。

Result: 与[Phys. Rev. Lett. 131, 200202 (2023)]的近期论断相反，我们证明了这种分离通常是无效的。

Conclusion: 在非绝热非阿贝尔情况下，量子时间演化的全纯和动力学分离在一般情况下是无效的。

Abstract: The issue of separating Schr\"odinger-type quantum time evolution into a
product of holonomic and dynamical parts in the non-adiabatic non-Abelian case
is addressed. Contrary to the recent claim in [Phys. Rev. Lett. 131, 200202
(2023)], we establish that such separation is generally invalid.

</details>


### [358] [Reduced State Embedding for Error Correction in Quantum Cryptography](https://arxiv.org/abs/2510.19989)
*Amit Kam,Kfir Sulimany,Shai Tsesses,Uzi Pereg*

Main category: quant-ph

TL;DR: 使用降维嵌入技术提高高维量子密钥分发的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 高维编码在量子信息处理中能提高噪声容限，但会带来模式间串扰和探测复杂性问题，从而降低量子密码学的性能。因此需要新的纠错方法来更好地利用高维编码的优势。

Method: 提出降维嵌入（reduced-state embedding）方法，将k维信号集嵌入到d维希尔伯特空间（k<d），在量子纠错框架内实现显式的擦除型纠错。

Result: 在真实量子信道中，该方案提高了安全密钥率。通过d=25的QKD实验数据验证了该方法，推导了密钥率和阈值的解析表达式，并确定了k=5是最佳密钥率。

Conclusion: 降维嵌入技术提升了高维量子密钥分发性能，为量子密码学的纠错和调制开辟了新途径。

Abstract: Encoding in a high-dimensional Hilbert space improves noise resilience in
quantum information processing. However, such an approach may result in
cross-mode coupling and detection complexities, thereby reducing quantum
cryptography performance. This fundamental trade-off between correctness and
secrecy motivates the search for new error-correction approaches to better
exploit the advantages of high-dimensional encoding. Here, we introduce the
method of reduced state embeddings to quantum key distribution (QKD): a
k-dimensional signal set embedded in a d-dimensional Hilbert space, where k<d.
In the framework of quantum error correction, our reduced-state embedding
realizes an explicit erasure-type error-correction within the quantum channel.
We demonstrate the advantage of our scheme in realistic quantum channels,
producing a higher secure key rate. We validate our approach using a d=25 QKD
experimental data, derive closed-form expressions for the key rate and
threshold, and determine the optimal key rate at k=5. These findings advance
high-dimensional QKD and pave the way to error correction and modulation for
quantum cryptography.

</details>


### [359] [Quantum Nonlinear Response of Emitter Lattices](https://arxiv.org/abs/2510.19992)
*Blas Durá-Azorín,Antonio I. Fernández-Domínguez,Alejandro Manjavacas*

Main category: quant-ph

TL;DR: 在亚波长周期下，量子多层表面的光学响应会出现量子非线性效应，表现为产生平行于入射波矢的激子布洛赫态，甚至包括光锥之外的态。强驱动下，远场发射会产生宽带背景。此外，当周期接近驱动波长时，由于驱动率的重构，发射器阵列会进入双稳态区域，从而可以选择性地开启和关闭光学量子非线性。


<details>
  <summary>Details</summary>
Motivation: 理论研究由激光相干驱动的二维量子发射器阵列在量子光学非线性方面的现象。

Method: 研究在亚波长周期（量子多层表面）和周期接近驱动波长两种情况下，激子布洛赫态的形成、远场发射的特点以及系统是否会进入双稳态区域。

Result: 发现了量子非线性效应，包括产生光锥之外的激子布洛赫态，以及宽带背景发射。在周期接近驱动波长时，系统进入双稳态区域，可以选择性地开启和关闭光学量子非线性。

Conclusion: 量子发射器阵列在特定条件下会表现出量子非线性效应，并可通过双稳态行为进行调控。

Abstract: We theoretically investigate the emergence of quantum nonlinearities in the
optical response of lattices of two-level quantum emitters coherently driven by
a laser. For subwavelength lattice periods, where the system behaves as a
quantum metasurface, we find that a resonant incident plane wave can populate
excitonic Bloch states with parallel wavevectors different from the incident
field, including those lying outside the light cone. Closely related to
resonance fluorescence, the far-field emission from the system in the
strong-driving regime is dominated by a broadband background of photons
spanning a wide range of frequencies and wavevectors. Moreover, we show that,
for periods approaching the driving wavelength, the emitter lattice enters in a
bistable regime due to the renormalization of the driving rate, in striking
contrast with its classical (bosonic) analog. This bistable behavior enables
the selective activation and deactivation of the optical quantum nonlinearities
of the system.

</details>


### [360] [Exact State Evolution and Energy Spectrum in Solvable Bosonic Models](https://arxiv.org/abs/2510.20046)
*Valery Shchesnovich*

Main category: quant-ph

TL;DR: 文章提出了可解玻色子模型中光传播的精确解析解，并推导了控制能谱的特征方程及其特征态。


<details>
  <summary>Details</summary>
Motivation: 在量子光学中，确定给定初始状态的时间演化是核心目标，该研究旨在为可解玻色子模型提供精确的解析解。

Method: 通过推导特征方程来求解能谱，并以连分式和雅可比矩阵的顺序主子式形式表示特征态。

Result: 得到了适用于广泛的可解玻色子模型和任意初始状态的状态演化问题的精确解析解，并导出了特征方程，同时找到了特征态。

Conclusion: 该研究为精确可解玻色子模型提供了坚实的分析框架。

Abstract: Solvable bosonic models provide a fundamental framework for describing light
propagation in nonlinear media, including optical down-conversion processes
that generate squeezed states of light and their higher-order generalizations.
In quantum optics a central objective is to determine the time evolution of a
given initial state. Exact analytic solution to the state-evolution problem is
presented, applicable to a broad class of solvable bosonic models and arbitrary
initial states. Moreover, the characteristic equation governing the energy
spectrum is derived and the eigenstates are found in the form of continued
fractions and as principal minors of the associated Jacobi matrix. The results
provide a solid analytical framework for discussion of exactly solvable bosonic
models.

</details>


### [361] [Photon Quantum Mechanics](https://arxiv.org/abs/2510.20049)
*Margaret Hawton*

Main category: quant-ph

TL;DR: This paper introduces a covariant theory of photons by second quantizing the electromagnetic Lagrangian and using a Lorenz gauge constraint. It shows that the longitudinal photon number is zero and describes physical photons using a real number density, eliminating the need for a nonlocal frequency operator.


<details>
  <summary>Details</summary>
Motivation: The motivation is to obtain a covariant theory of discrete excitations of the classical electromagnetic field, which can be properly called photons.

Method: The method involves second quantizing the standard electromagnetic Lagrangian with a subsidiary Lorenz gauge constraint. This leads to a description of physical photons using a real number density and addresses the issue of longitudinal photon number cancellation.

Result: The result is a covariant theory where the longitudinal photon number is zero due to the cancellation of Gupta-Bleuler like terms. Physical photons are represented by a real number density, which can be interpreted as a probability density, and the nonlocal frequency operator is not required.

Conclusion: The paper concludes that by using second quantization and a Lorenz gauge constraint, a covariant theory of photons is achieved, simplifying the description of photon properties and eliminating the need for certain complex operators.

Abstract: We second quantize the standard electromagnetic Lagrangian with a subsiduary
Lorenz gauge constraint to obtain a covariant theory of the discrete
excitations of the classical EM field that can properly be called photons. The
longitudinal photon number is zero due to cancellation of Gupta-Bleuler like
terms. Physical photons are described by a real number density whose spatial
integral is unity so it can be interpreted as the probability density to find a
photon at position x'. Energy density is not separated into is positive and
negative frequency parts so the nonlocal frequency operator is not required.

</details>


### [362] [All-Gaussian State Discrimination Beyond the Coherent Helstrom Bound](https://arxiv.org/abs/2510.20096)
*Angus Waslh,Lorcan Conlon,Biveen Shajilal,Ozlem Erkilic,Jiri Janousek,Syed Assad,Jie Zhao,Ping Koy Lam*

Main category: quant-ph

TL;DR: 使用高斯光学（位移压缩态和零点拍频探测）可以比相干态和任何量子测量在BPSK信号辨别方面取得更低的错误率。


<details>
  <summary>Details</summary>
Motivation: 通信中的核心问题是二相移键控（BPSK）信号的最佳辨别。长期以来的目标是达到被称为Helstrom下限的基本量子极限，但由于技术限制，达到该下限的方案仍然不切实际。

Method: 利用位移压缩态和零点拍频探测，以仅使用高斯光学的方式，对BPSK信号进行辨别。

Result: 与使用相干态和任何量子测量的方案相比，BPSK信号的辨别错误率有所降低。

Conclusion: 通过仅使用高斯光学（位移压缩态和零点拍频探测），可以实现BPSK信号的辨别，并且错误率低于使用相干态和任何量子测量的方案。

Abstract: A core problem in communications is the optimal discrimination of
binary-phase-shift-keyed (BPSK) signals. A longstanding goal has been to reach
the fundamental quantum limit, known as the Helstrom bound, for BPSK signals
encoded in coherent states. However, due to technical constraints, proposals
for reaching the bound remain impractical. In this letter we take an
alternative approach: using only Gaussian optics - displaced squeezed states
and homodyne detection - we achieve discrimination of BPSK signals with error
rates below what can be achieved using coherent states and any quantum
measurement.

</details>


### [363] [Electronically-controlled one- and two-qubit gates for transmon quasicharge qubits](https://arxiv.org/abs/2510.20127)
*Nicholas M. Christopher,Deniz E. Stiegemann,Abhijeet Alase,Thomas M. Stace*

Main category: quant-ph

TL;DR: 通过拓扑超导体中的电子控制隧道结，可以实现准收费荷量子比特的单比特和两比特门操作。


<details>
  <summary>Details</summary>
Motivation: 实现低错误率的超导量子比特，以构建可纠错的实用规模量子计算机。

Method: 提出了一种利用准电荷自由度编码的保护量子比特（准电荷量子比特），并展示了如何通过电子控制的拓扑超导体隧道结实现单比特和两比特门操作。该方法基于动态 $4	extpi$-周期约瑟夫森效应，并模拟了拓扑约瑟夫森结在非零充电能量下的动力学行为，同时使用费米黄金定则评估了门操作对电荷噪声的鲁棒性。

Result: 实现了基于动态 $4	extpi$-周期约瑟夫森效应的准电荷量子比特的门操作，门操作速度快，并且通过费米黄金定则评估了其对电荷噪声的鲁棒性。

Conclusion: 基于由最小的 Kitaev 链量子点组成的结，可以为准电荷量子比特门的实现提供一种有前景的策略。

Abstract: Superconducting protected qubits aim to achieve sufficiently low error rates
so as to allow realization of error-corrected, utility-scale quantum computers.
A recent proposal encodes a protected qubit in the quasicharge degree of
freedom of the conventional transmon device, here referred to as the
`quasicharge qubit'. Operating such a protected qubit requires implementing new
strategies. Here we show that an electronically-controllable tunnel junction
formed by two topological superconductors can be used to implement single- and
two-qubit gates on quasicharge qubits. Schemes for both these gates are based
on dynamical $4\pi$-periodic Josephson effect and therefore have gate speeds of
the same order. The simulation of the dynamics of a topological Josephson
junction in a parameter regime with non-negligible charging energy is the key
novelty of this work. We also characterize the robustness of such gate
operations against charge noise using Fermi's golden rule. Our results point to
a compelling strategy for implementation of quasicharge qubit gates based on
junctions of minimal Kitaev chains of quantum dots.

</details>


### [364] [Variational quantum simulation of many-body dissipative dynamics on a superconducting quantum processor](https://arxiv.org/abs/2510.20118)
*Huan-Yu Liu,Tai-Ping Sun,Zhao-Yun Chen,Cheng Xue,Chao Wang,Xi-Ning Zhuang,Jin-Peng Liu,Wei Yi,Yu-Chun Wu,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 本研究提出并演示了一种新的量子算法，用于在量子计算机上模拟开放量子系统中的耗散动力学，该算法具有可扩展性、适用于近期量子硬件，并且模拟深度不受模拟时间影响。


<details>
  <summary>Details</summary>
Motivation: 模拟开放量子系统中的复杂现象，但由于希尔伯特空间增长和非酉动力学性质，在量子设备上模拟具有挑战性。

Method: 提出并演示了一种基于哈密顿量模拟线性组合的变分量子算法，将非酉动力学转换为酉演化的加权和，并引入简化的量子电路进行损失函数评估，使算法适用于近期量子硬件，且电路深度与模拟时间无关。

Result: 在超导量子处理器上成功模拟了耗散横向伊辛模型和相互作用的Hatano-Nelson模型的集体动力学。

Conclusion: 证明了含噪声中尺度量子设备在模拟耗散多体动力学方面的潜力，为利用其解决物理难题迈出了重要一步。

Abstract: Open quantum systems host a wide range of intriguing phenomena, yet their
simulation on well-controlled quantum devices is challenging, owing to the
exponential growth of the Hilbert space and the inherently non-unitary nature
of the dynamics. Here we propose and experimentally demonstrate a variational
quantum algorithm capable of scalable simulation of non-unitary many-body
dissipative dynamics. The algorithm builds on the framework of linear
combination of Hamiltonian simulation, which converts non-unitary dynamics into
a weighted sum of unitary evolutions. With the further introduction of a
simplified quantum circuit for loss-function evaluation, our scheme is suitable
for near-term quantum hardware, with the circuit depth independent of the
simulation time. We illustrate our scheme by simulating the collective dynamics
of a dissipative transverse Ising model, as well as an interacting
Hatano-Nelson model, on the superconducting quantum processor Wukong. Our work
underlines the capability of noisy intermediate-scale quantum devices in
simulating dissipative many-body dynamics and represents a step forward in
exploiting their potential for solving outstanding physical problems.

</details>


### [365] [Unveiling non-Hermitian band structures with non-Bloch supercells](https://arxiv.org/abs/2510.20160)
*Jia-Xin Zhong,Jing Lin,Kai Chen,Jing Lu,Kun Ding,Yun Jing*

Main category: quant-ph

TL;DR: 使用非Bloch超胞方法，通过指数展平协议和扭曲边界条件，在声学晶体中实现了动量分辨的复杂能谱和本征态的实验测量，并验证了其预测开边界谱和本征态的准确性。


<details>
  <summary>Details</summary>
Motivation: 理解非厄米系统中的复杂能带结构、非厄米皮肤效应和异常的体边界对应关系，并实验性地测量其复杂能带和本征态。

Method: 提出一种非Bloch超胞框架，结合指数展平协议和扭曲边界条件，实现系统尺寸无关的虚部动量控制和高分辨率的Bloch相位采样，并通过格林函数测量来获取动量分辨的复杂能量面和双正交本征模。

Result: 在可编程的一维和二维声学晶体中成功获取了动量分辨的复杂能量面和双正交本征模，并且实验数据精确预测了开边界谱和本征态，并通过独立实验进行了验证。

Conclusion: 提出了一种通用的实验工具包，用于探索各种工程化的经典和量子平台中的非厄米能带几何和拓扑。

Abstract: Real-valued band structures are foundational to analyzing periodic systems
within the Hermitian description and have been experimentally well-established
over recent decades. In contrast, non-Hermitian systems exhibit complex band
structures where both energy and momentum have imaginary parts, underpinning
phenomena like the non-Hermitian skin effect and anomalous bulk-boundary
correspondence that defy conventional Bloch theory. Experimentally mapping
these complex bands-relating complex momentum to complex energy-and identifying
their associated eigenstates is crucial for understanding these systems but
remains a significant challenge. Here, we introduce a non-Bloch supercell
framework designed to overcome this challenge by decoupling Bloch phase control
from the imaginary part of momentum. Our method combines an exponent-flattening
protocol with twisted boundary conditions, enabling system-size-independent
control of imaginary momentum while preserving high-resolution Bloch phase
sampling. Implemented in programmable one- and two-dimensional acoustic
crystals, our approach acquires momentum-resolved complex energy surfaces and
biorthogonal eigenmodes by Green's function measurements.Data obtained using
this framework accurately predict open-boundary spectra and eigenstates,
findings we verify through separate open-geometry experiments. Our work
provides a broadly applicable experimental toolkit for exploring non-Hermitian
band geometry and topology in diverse engineered classical and quantum
platforms.

</details>


### [366] [Quantum mysteries explained in digestible form](https://arxiv.org/abs/2510.20144)
*Alejandro Hnilo*

Main category: quant-ph

TL;DR: 量子现象可以通过与实空间向量的比较来理解，从而回答量子现象与经典现象为何不同以及何种解释是合理的这两个问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在回答Itamar Pitowski提出的两个问题：微观（量子）现象与经典现象在本质上存在何种差异？什么样的解释才算得上是合理的？

Method: 通过将量子现象与实空间向量的某些特征进行比较，来解释量子现象和经典现象的区别。

Result: 研究表明，贝尔不等式的违反、量子隐形传态、Kochen-Specker定理和Greenberger-Horne-Zeilinger定理都可以用向量的语言来理解。

Conclusion: 量子现象与经典现象的差异并非虚幻，而是因为向量本身比初看起来更奇特。

Abstract: Years ago, Itamar Pitowski asked two relevant questions: Why microphysical
(quantum) phenomena and classical phenomena differ in the way they do? and,
what kind of explanation could qualify as a reasonable one? I argue that both
questions can be answered by the comparison of quantum phenomena with some
features of vectors in real space. In particular, I show how violation of
Bell's inequalities, Teleportation, Kochen-Specker and
Greenberger-Horne-Zeilinger theorems can be understood in terms of vectors.
This does not mean that the difference between quantum and classical phenomena
is illusory. This means that vectors are stranger objects that they may seem to
be at first sight.

</details>


### [367] [Efficient Floating-Point Arithmetic on Fault-Tolerant Quantum Computers](https://arxiv.org/abs/2510.20145)
*José E. Cruz Serrallés,Oluwadara Ogunkoya,Do{g}a Murat Kürkçüo{g}lu,Nicholas Bornman,Norm M. Tubman,Anna Grassellino,Silvia Zorzetti,Riccardo Lattanzi*

Main category: quant-ph

TL;DR: 提出了一种新颖的浮点数编码方案，使用Two's Complement定点尾数和Two's Complement整数指数，并将其应用于量子算法开发，在量子计算机模拟中表现出良好的性能和资源效率。


<details>
  <summary>Details</summary>
Motivation: 利用定点编码的先验工作，提出一种新颖的浮点数编码方案，旨在开发基础算术运算的量子算法。

Method: 采用Two's Complement定点尾数和Two's Complement整数指数来编码浮点数。基于该编码方案开发了量子算法，并对量子计算机模拟进行了原型设计和性能研究，包括倒数运算和求解一阶常微分方程。

Result: 在量子计算机模拟中，随着量子比特数量的增加，该浮点数编码方案实现了向精确解的快速收敛。与类似方法相比，倒数运算所需的辅助量子比特数量显著减少。

Conclusion: 所提出的浮点数编码方案在量子计算机模拟中表现出良好的性能和资源效率，能够快速收敛到精确解，并减少辅助量子比特的需求。

Abstract: We propose a novel floating-point encoding scheme that builds on prior work
involving fixed-point encodings. We encode floating-point numbers using Two's
Complement fixed-point mantissas and Two's Complement integral exponents. We
used our proposed approach to develop quantum algorithms for fundamental
arithmetic operations, such as bit-shifting, reciprocation, multiplication, and
addition. We prototyped and investigated the performance of the floating-point
encoding scheme on quantum computer simulations by performing reciprocation on
randomly drawn inputs and by solving first-order ordinary differential
equations, while varying the number of qubits in the encoding. We observed
rapid convergence to the exact solutions as we increased the number of qubits
and a significant reduction in the number of ancilla qubits required for
reciprocation when compared with similar approaches.

</details>


### [368] [Parametric Phase Modulation in Superconducting Circuits](https://arxiv.org/abs/2510.20192)
*Zhuang Ma,Xianke Li,Hongyi Shi,Ruonan Guo,Jianwen Xu,Xinsheng Tan,Yang Yu*

Main category: quant-ph

TL;DR: 通过调整耦合的超导量子比特的参数脉冲之间的相对相位来控制它们之间的耦合强度。


<details>
  <summary>Details</summary>
Motivation: 参数调质在超导电路中广泛用于量子模拟和高保真度两比特门，但传统方法中，脉冲幅度会显著影响量子比特参数。

Method: 提出并实现了一种通过调整两个耦合量子比特的参数通量脉冲之间的相对相位来调节相互作用强度来实现相位调制的方案。

Result: 在甜点和非甜点处对边带耦合进行了表征，并使用人群动态和光谱学方法实现了广泛的耦合强度。

Conclusion: 提出的相位调制方案可以实现耦合强度的相位控制，为参数驱动的量子模拟和门操作提供了一种有前景的方法。

Abstract: Parametric modulation is widely employed in superconducting circuits for
quantum simulations and high-fidelity two-qubit gates, valued for its
versatility. Conventionally, the qubit coupling strength is determined by the
amplitude of the parametric flux pulse, which affects qubit parameters
dramatically. In this article, we propose and implement a phase modulation
scheme to tune the interaction strength via adjusting the relative phase
between the parametric flux pulses applied to two coupled qubits. We
characterize this modulation for sideband couplings, at both sweet and offsweet
spots, achieving a broad range of coupling strengths as confirmed by both
population dynamics and spectroscopy methods. This approach enables
phase-controlled modulation of coupling strength, providing a promising
candidate for parametrically driven quantum simulations and gate operations.

</details>


### [369] [Non-Markovianity in Quantum Information Processing: Interplay with Quantum Error Mitigation](https://arxiv.org/abs/2510.20224)
*Suguru Endo,Hideaki Hakoshima,Tomohiro Shitara*

Main category: quant-ph

TL;DR: 量子信息处理中的非马尔可夫动力学负值是信息反馈的结果，并可降低量子纠错的采样成本。


<details>
  <summary>Details</summary>
Motivation: 讨论了非马尔可夫动力学在量子信息处理（QIP）中的相关性，特别是其在量子纠错（QEC）和量子隐形传态中的作用。

Method: 将希尔伯特空间划分为逻辑子系统和规范子系统，分析了规范子系统测量结果的反馈操作如何导致逻辑子系统中的负值动力学。

Result: 证明了量子纠错和量子隐形传态中自然会出现非马尔可夫动力学的负值。

Conclusion: 量子信息处理中的负值是非马尔可夫性的特征，源于从环境中回流的信息，并且这种负值可以降低量子纠错（QEM）的采样成本，强调了QEC和QEM结合策略在实际QIP中的重要性。

Abstract: Non-Markovian dynamics are typically present in the dynamics of open quantum
systems. Despite the rich structure of non-Markovian dynamics, their relevance
to quantum information processing (QIP) has been rarely discussed. In this
work, we demonstrate that the negativity of the dynamics, a characteristic of
non-Markovian dynamics, naturally arises in quantum error correction (QEC) and
quantum teleportation. The negativity in open quantum systems is naturally
attributed to the information backflow from the environment. We partition the
whole Hilbert space into the logical subsystem and the gauge subsystem. The
logical subsystem stores the quantum information for QIP, while the gauge
subsystem stores the information for recovery of the logical information, i.e.,
the syndrome measurement outcomes for quantum error correction and Bell
measurement outcomes for successful teleportation. We then show that the
negativity in quantum information processing appears as a consequence of the
feedback operation based on the measurement outcomes of the gauge subsystem.
Finally, we show that the negativity of non-Markovianity in QIP reduces the
sampling cost of quantum error mitigation (QEM), shedding light on the
importance of combination strategies of QEC and QEM in a practical QIP.

</details>


### [370] [Factorizability of optimal quantum sequence discrimination under maximum-confidence measurements](https://arxiv.org/abs/2510.20311)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 最优量子序列判别可分解为各独立步骤的最优判别，且最大置信度判别等同于各组成状态的最大置信度判别。


<details>
  <summary>Details</summary>
Motivation: 考虑最大置信度测量下的量子序列判别问题。

Method: 证明最优量子序列判别可分解为各独立步骤的最优判别，并推导了最大置信度测量下最优量子态判别的充要条件。

Result: 最优量子序列判别可分解为各独立步骤的最优判别；最大置信度判别等同于各组成状态的最大置信度判别；给出了最大置信度测量下最优量子态判别的充要条件。

Conclusion: 最大置信度测量下的量子序列判别可以通过独立地对每一状态进行最大置信度判别来实现。

Abstract: We consider the discrimination of quantum sequences under maximum-confidence
measurements and show that the optimal discrimination of a quantum sequence
ensemble can always be factorized into that of each individual ensemble. In
other words, the optimal quantum sequence discrimination under
maximum-confidence measurements can be achieved just by performing a
maximum-confidence discrimination independently at each step of the quantum
sequence. We also show that the maximum confidence of identifying a quantum
sequence is to achieve the maximum confidence of identifying each state
comprising the quantum sequence. We further provide a necessary and sufficient
condition for the optimal quantum state discrimination under maximum-confidence
measurements.

</details>


### [371] [Complete characterisation of state conversions by work extraction](https://arxiv.org/abs/2510.20366)
*Chung-Yun Hsieh,Manuel Gessner*

Main category: quant-ph

TL;DR: 本篇论文提出了一种热力学做功提取任务，用于描述量子系统的储能增强，这与量子电池的充电过程密切相关。


<details>
  <summary>Details</summary>
Motivation: 量子电池的充电过程以及量子资源理论中的状态转换是本研究的动机。

Method: 通过引入一个与量子电池充电过程相关的热力学做功提取任务，并推导出与majorisation-like条件相似的条件，从而表征量子资源理论中的状态转换。将此条件应用于特定资源，可简化为unital channel下的majorisation条件，并得到量子纠缠理论中Nielsen定理的热力力学版本。

Result: 该研究建立了第一个基于热力学的通用资源认证类别，并展示了如何基于做功提取来量化通用的量子资源。

Conclusion: 本研究提出的热力学做功提取任务为理解和量化量子资源提供了一个新的视角，并与量子纠缠理论中的相关概念建立了联系。

Abstract: We introduce a thermodynamic work extraction task that describes the energy
storage enhancement of quantum systems, which is naturally related to quantum
battery's charging process. This task induces majorisation-like conditions that
provide a necessary and sufficient characterisation of state conversions in
general quantum resource theories. When applied to specific resources, these
conditions reduce to the majorisation conditions under unital channels and
provide a thermodynamic version of Nielsen's theorem in entanglement theory. We
show how this result establishes the first universal resource certification
class based on thermodynamics, and how it can be employed to quantify general
quantum resources based on work extraction.

</details>


### [372] [Restoring Quantum Superiority of Noisy Quantum Illumination](https://arxiv.org/abs/2510.20378)
*Wei Wu,Jun-Hong An*

Main category: quant-ph

TL;DR: 量子照明利用量子纠缠提高雷达分辨率，即使在有噪声的情况下也能恢复其优势。


<details>
  <summary>Details</summary>
Motivation: 量子照明有望革新雷达技术，但量子噪声导致的退相干被认为会破坏其优势。

Method: 提出了一种在量子噪声存在下恢复量子照明量子优势的方法，并超越了常用的玻恩-马尔可夫近似，发现了分辨率对复合系统能量谱的敏感性，特别是在存在束缚态的情况下，分辨率能接近理想值。

Result: 量子照明的分辨率对复合系统（光模式及其局部量子噪声）的能量谱高度敏感，当能量谱中存在束缚态时，分辨率接近理想值。

Conclusion: 在有噪声的情况下，通过利用复合系统的能量谱中的束缚态，可以恢复和实现高分辨率的量子照明，这为在有噪声环境中实现量子照明提供了物理原理和途径。

Abstract: Quantum illumination uses quantum entanglement as a resource to enable
higher-resolution detection of low-reflectivity targets than is possible with
classical techniques. This revolutionary technology could transform modern
radar. However, it is widely believed that the decoherence induced by the
ubiquitous quantum noise destroys the superiority of quantum illumination,
severely constraining its performance and application in our present noisy
intermediate-scale quantum era. Here, we propose a method to restore the
quantum superiority of the quantum illumination in the presence of quantum
noises. Going beyond the widely used Born-Markov approximation, we discover
that the resolution of noisy quantum illumination is highly sensitive to the
energy spectrum of the composite system formed by each of the two light modes
and its local quantum noise. When a bound state is present in the energy
spectrum, the resolution asymptotically approaches its ideal form. Our result
establishes a physical principle to preserve the quantum superiority and paves
the way for the realization of high-resolution quantum illumination in noisy
situations.

</details>


### [373] [Multiplexed ion-ion entanglement over $1.2$ kilometer fibers](https://arxiv.org/abs/2510.20392)
*Z. B. Cui,Z. Q. Wang,P. Y. Liu,Y. Wang,P. C. Lai,J. X. Shi,Y. D. Sun,Z. C. Tian,H. S. Sun,Y. B. Liang,B. X. Qi,Y. Y. Huang,Z. C. Zhou,Y. K. Wu,Y. Xu,Y. F. Pu,L. M. Duan*

Main category: quant-ph

TL;DR: 通过复用 10 个时间光学模式，在 1.2 公里的光纤上实现了 4.59 倍的离子-离子纠缠生成加速和 95.9±1.5% 的纠缠保真度。


<details>
  <summary>Details</summary>
Motivation: 量子网络和量子中继器是构建大规模量子信息系统的有前途的途径，是分布式量子计算、长距离量子通信和网络量子传感的基础设施。在实现功能性量子网络的过程中，在远程量子节点之间高效、高保真地建立信号纠缠是一个关键步骤。复用是加速远程纠缠分发（尤其是在长光纤上）的有力策略。

Method: 通过复用 10 个时间光学模式，在两个离子量子网络节点之间实现增强的信号纠缠。

Result: 实现了 4.59 倍的离子-离子纠缠生成加速，并且在 1.2 公里的光纤上达到了 95.9±1.5% 的纠缠保真度。

Conclusion: 通过复用实现的速度提升和高保真度为未来大规模量子网络奠定了基础。

Abstract: Quantum networks and quantum repeaters represent the promising avenues for
building large-scale quantum information systems, serving as foundational
infrastructure for distributed quantum computing, long-distance quantum
communication, and networked quantum sensing. A critical step in realizing a
functional quantum network is the efficient and high-fidelity establishment of
heralded entanglement between remote quantum nodes. Multiplexing offers a
powerful strategy to accelerate remote entanglement distribution, particularly
over long optical fibers. Here, we demonstrate the first multiplexing-enhanced
heralded entanglement between two trapped-ion quantum network nodes. By
multiplexing $10$ temporal photonic modes, we achieve a 4.59-fold speedup in
ion-ion entanglement generation and attain an entanglement fidelity of
$95.9\pm1.5\%$ over $1.2$ km of fiber. Employing a dual-type architecture, our
system is readily scalable to multiple nodes, thereby establishing a key
building block for future large-scale quantum networks.

</details>


### [374] [Robust GHz-range AC Magnetometry with an ensemble of NV Centers in Diamond using Concatenated Continuous Dynamical Decoupling](https://arxiv.org/abs/2510.20401)
*Takuya Kitamura,Genko Genov,Alon Salhov,Yutaka Kobayashi,Shinobu Onoda,Junichi Isoya,Alex Retzker,Fedor Jelezko*

Main category: quant-ph

TL;DR: 使用由金刚石中带负电荷的氮-空位（NV）中心组成的系综，通过增加同时用于传感的自旋数量，实现了低于皮特斯拉水平的磁强测量。然而，这种扩展规模常常会引入失谐和控制场幅度方面的空间不均匀性，从而降低了灵敏度。尽管已采用多种技术来克服这些挑战，例如脉冲动力学解耦或整形脉冲，但这些技术通常与目前最先进的、基于拉比振荡的NV系综的GHz范围交流磁强测量技术不兼容。在本研究中，我们通过采用串联连续动力学解耦（Concatenated Continuous Dynamical Decoupling），在空间不均匀驱动场下，利用NV中心的大系综，通过实验证明了GHz范围的交流磁强测量。这种方法旨在抵抗这种不完美性。我们将其性能与传统的直接拉比方法进行了比较，结果表明，我们方法中的鲁棒性约束态（robust dressed states）显著扩展了GHz范围交流磁强测量中较弱信号的测量范围。


<details>
  <summary>Details</summary>
Motivation: 在NV系综中实现低于皮特斯拉的磁强测量，但空间不均匀性降低了灵敏度。现有的技术（如脉冲动力学解耦或整形脉冲）与基于拉比振荡的GHz交流磁强测量不兼容。

Method: 通过实验，在空间不均匀驱动场下，利用NV中心的大系综，采用串联连续动力学解耦（Concatenated Continuous Dynamical Decoupling）技术进行GHz范围的交流磁强测量。

Result: 与传统的直接拉比方法相比，本研究提出的方法在GHz范围的交流磁强测量中，鲁棒性约束态显著扩展了测量较弱信号的范围。

Conclusion: 串联连续动力学解耦（Concatenated Continuous Dynamical Decoupling）技术能够克服NV系综在空间不均匀驱动场下的限制，在GHz范围的交流磁强测量中实现更优的性能，并扩展了测量范围。

Abstract: Sub-picotesla level magnetometry has been demonstrated using
negatively-charged nitrogen-vacancy (NV) centers in diamond by increasing the
number of spins simultaneously used for sensing in an NV ensemble. However,
such scale-up often introduces spatial inhomogeneities in detuning and control
field amplitudes, which degrade sensitivity. Although several techniques have
been utilized to overcome these challenges, including pulsed dynamical
decoupling or shaped pulses, these are not generally compatible with the
current state-of-the-art techniques for GHz-range AC magnetometry with NV
ensembles, which are typically based on Rabi oscillations. In this work we
experimentally demonstrate GHz-range AC magnetometry using a large ensemble of
NV centers under spatially inhomogeneous drive fields by employing concatenated
continuous dynamical decoupling, which is designed for robustness against such
imperfections. We compare its performance with the conventional direct Rabi
method and show that the robust dressed states in our method extend
significantly the measuring range to weaker signals in GHz-range AC
magnetometry.

</details>


### [375] [Realization of Trapped Ion Dynamics in the Strong-Field Regime and Non-Markovianity](https://arxiv.org/abs/2510.20444)
*Kamran Rehan,Hengchao Tu,Menglin Zou,Zihan Yin,Jing-Ning Zhang,Kihwan Kim*

Main category: quant-ph

TL;DR: 研究人员在强场条件下实验研究了囚禁离子的量子动力学，发现非马尔可夫性与拉比频率和失谐等参数存在复杂关系，并观察到在特定参数条件下出现最大非马尔可夫性圆周模式。


<details>
  <summary>Details</summary>
Motivation: 为了在强场条件下探索受控量子系统和开发量子技术，研究囚禁离子的量子动力学至关重要。

Method: 通过量子态断层扫描来重构密度矩阵，并跟踪其演化，以评估非马尔可夫性，并研究不同参数（拉比频率 Omega 和失谐 delta）下的动力学。

Result: 当失谐平方加上拉比频率平方等于振动频率平方时，非马尔可夫性呈现出最大值的圆周模式。研究还发现，非马尔可夫性并非总是随着 Omega 的增加而单调增加。

Conclusion: 囚禁离子平台可以用于研究强场条件下的非马尔可夫性、相干控制和开放量子系统的基本行为。

Abstract: Probing quantum dynamics in the strong-field regime is critical for advancing
our understanding of controlled quantum systems and developing robust quantum
technologies. In this work, we experimentally investigate the dynamics of a
trapped ion where the Rabi frequency (Omega) approaches the vibrational mode
frequency (nu), pushing the system beyond the weak-field regime, where
non-trivial quantum correlations emerge. We begin by setting the detuning
(delta) - the frequency offset between the qubit transition and the driving
field - to zero and varying Omega from low to high values, eventually reaching
the vibrational frequency. Using quantum state tomography, we reconstruct the
density matrix and track its evolution to assess non-Markovianity, revealing
significant memory effects governed by the interplay between internal and
motional degrees of freedom. Furthermore, by exploring the dynamics across
various parameter pairs (Omega, delta), we find that non-Markovianity does not
always increase monotonically with Omega for a fixed delta. Strikingly, when
the condition delta squared plus Omega squared equals nu squared is met, the
non-Markovianity exhibits a circular pattern of maxima. At this parameter
combination, the system's Hamiltonian takes a form similar to the
Jaynes-Cummings model, enabling the possibility of analytical insights into the
observed dynamics. These results go beyond the conventional carrier and
sideband regimes, uncovering novel features of strong-field quantum dynamics.
Our findings establish a pathway for using trapped-ion platforms to investigate
non-Markovianity, coherent control, and the fundamental behavior of open
quantum systems in extreme regimes.

</details>


### [376] [Mitigating Coherent Errors through a Decoherence-Resistant Variational Framework employing Stabilizer State](https://arxiv.org/abs/2510.20445)
*Giovanni Di Bartolomeo,Giulio Crognaletti,Angelo Bassi,Michele Vischi*

Main category: quant-ph

TL;DR: VCEM是一种通过变分优化门参数来抑制相干误差的方法，它可以在不影响不相干噪声的情况下，对相干误差进行预补偿。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理中的稳定器态的质量会受到相干误差的影响，需要一种方法来抑制这些误差。

Method: VCEM通过利用稳定器形式主义，通过变分优化本地门参数来抑制相干误差。

Result: VCEM在数值模拟中显示出鲁棒性，并且在标准的不相干误差缓解技术应用之前，可以对相干误差进行预补偿。

Conclusion: VCEM是一种有效且鲁棒的抑制相干误差的方法，可用于提高量子计算的质量。

Abstract: Stabilizer states are a central resource in quantum information processing,
underpinning a wide range of applications. While they can be efficiently
generated via Clifford circuits, the presence of coherent errors, such as
small-angle miscalibrations in native gate implementations, can significantly
impact their quality. In this work, we introduce Variational Coherent Error
Mitigation (VCEM), a method that employs the stabilizer formalism to suppress
coherent errors through variational optimization of native gates parameters.
VCEM demonstrates robust performance, remaining largely unaffected by
incoherent noise, enabling pre-compensation of coherent errors prior to the
application of standard incoherent error mitigation techniques. We demonstrate
the effectiveness and robustness of VCEM through numerical simulations.

</details>


### [377] [Phenomenological Noise Models and Optimal Thresholds of the 3D Toric Code](https://arxiv.org/abs/2510.20489)
*Ji-Ze Xu,Yin Zhong,Miguel A. Martin-Delgado,Hao Song,Ke Liu*

Main category: quant-ph

TL;DR: 三维托里克码在包含 Pauli 和测量误差的情况下，其容错阈值分别为约 11%（比特翻转误差）和约 2%（相位翻转误差），表明其对测量误差具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索三维拓扑码（特别是三维托里克码）在实际噪声下的容错性能，特别是 Pauli 和测量误差的影响。

Method: 推导出描述码正确性的两个随机耦合格点规范场模型（包括一个随机二阶张量 $\mathbb{Z}_2$ 规范场），并利用广义对偶技术。

Result: 三维托里克码在比特翻转误差（$p^{X,M}_{th}$）和相位翻转误差（$p^{Z,M}_{th}$）下的最优阈值分别为约 11% 和约 2%，与完美测量情况相比仅有少量降低。

Conclusion: 三维托里克码对测量误差具有鲁棒性，其容错阈值与完美测量情况下的阈值相当。该研究对于评估三维拓扑码的实际性能具有重要意义，并对量子信息科学、高能物理和凝聚态物理等领域具有跨学科的价值。

Abstract: Three-dimensional (3D) topological codes offer the advantage of supporting
fault-tolerant implementations of non-Clifford gates, yet their performance
against realistic noise remains largely unexplored. In this work, we focus on
the paradigmatic 3D toric code and investigate its fault-tolerance thresholds
in the presence of both Pauli and measurement errors. Two randomly coupled
lattice gauge models that describe the code's correctability are derived,
including a random 2-form $\mathbb{Z}_2$ gauge theory. By exploiting a
generalized duality technique, we show that the 3D toric code exhibits optimal
thresholds of $p^{X,M}_{th} \approx 11\%$ and $p^{Z,M}_{th} \approx 2\%$
against bit-flip and phase-flip errors, respectively. These threshold values
show modest reductions compared to the case of perfect measurements,
establishing the robustness of the 3D toric code against measurement errors.
Our results constitute a substantial advance towards assessing the practical
performance of 3D topological codes. This contribution is timely and in high
demand, as rapid hardware advancements are bringing complex codes into
experimental reach. Moreover, our work highlights the interdisciplinary nature
of fault-tolerant quantum computation and holds significant interest for
quantum information science, high-energy physics, and condensed matter physics.

</details>


### [378] [Feasibility of entanglement-based QKD protocols with SPDC and QD sources](https://arxiv.org/abs/2510.20528)
*Mariia Gumberidze,Vladyslav C. Usenko*

Main category: quant-ph

TL;DR: SPDC和QD光源在现实条件下均不适用于安全的DI-QKD，其中QD光源性能受FSS影响。


<details>
  <summary>Details</summary>
Motivation: 理论分析基于纠缠的量子密钥分发（QKD）协议的可行性，考虑了SPDC和QD光源的实际限制。

Method: 考虑了SPDC光源的多光子发射和QD光源的精细结构分裂（FSS），并纳入了暗计数和有限效率等不完美的探测。

Result: SPDC光源由于真空和多光子对的存在，不适用于标准的DI-QKD。QD光源的FSS效应会降低协议性能。

Conclusion: 实际的QKD实现需要考虑真实光源和探测器的限制。

Abstract: We theoretically analyze the feasibility of entanglement-based quantum key
distribution (QKD) protocols considering widely used spontaneous parametric
down-conversion (SPDC) and novel quantum dot (QD) sources. We account for
multiphoton emission in SPDC sources and fine-structure splitting (FSS) in QD.
In addition, we incorporate imperfect detection, including dark counts and
limited efficiency. For SPDC sources, we confirm that the presence of vacuum
and multiphoton pairs renders them unsuitable for secure device-independent
(DI) QKD implementations under standard detection strategies. Conversely, in
the case of QD sources, accounting for the effects of FSS, results in reduced
performance of protocols. Our findings are crucial for the practical
implementation of entanglement-based QKD protocols using realistic sources and
detectors.

</details>


### [379] [Higher-order quantum computing with known input states](https://arxiv.org/abs/2510.20530)
*Vanessa Brzić,Satoshi Yoshida,Mio Murao,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: HOQC框架的变体，其中操作未知但输入状态已知，这可以提高性能并区分不同类型的状态，从而实现确定性和精确的混合状态实现。


<details>
  <summary>Details</summary>
Motivation: 探讨HOQC框架的一个变体，其中操作未知但输入状态已知，并论证此假设在诸如酉编程等实际场景中的合理性。

Method: 研究已知输入状态的HOQC框架，并区分纯态、二分态和混合态的协议，以确定混合态的类别，在这种类别下可以实现确定性和精确的实现。

Result: 已知输入状态可显著提高HOQC性能，并能区分不同状态的协议，从而确定混合态的类别，在此类别下可实现确定性和精确的实现。

Conclusion: 与仅知道操作的HOQC框架相比，知道输入状态可以提供性能优势，并能更精细地对不同状态的协议进行分类，从而为特定应用场景（如酉编程）实现确定性和精确的混合状态实现。

Abstract: In higher-order quantum computing (HOQC), one typically considers the
universal transformation of unknown quantum operations, treated as blackboxes.
It is also implicitly assumed that the resulting operation must act on
arbitrary, and thus unknown, input states. In this work, we explore a variant
of this framework in which the operation remains unknown, but the input state
is fixed and known. We argue that this assumption is well-motivated in certain
practical contexts, such as unitary programming, and show that classical
knowledge of the input state can significantly enhance performance. Moreover,
this assumption allows us to distinguish between protocols designed for pure,
bipartite, and mixed states, which enables us to identify the class of mixed
states for which deterministic and exact implementation becomes possible.

</details>


### [380] [Nontrivial topological phases in "Zig-Zag" arrays of polarization transmons](https://arxiv.org/abs/2510.20557)
*Ekaterina Konopleva,Gleb Fedorov,Oleg Astafiev*

Main category: quant-ph

TL;DR: 提出使用具有多个内禀自由度的超原子（特别是极化比特）构建超导量子模拟器，以研究包含长程交叉极化耦合的扩展Zig-Zag模型，并阐述了该模型在数值、解析和电磁建模上的可行性，为实验研究此前无法触及的拓扑量子多体现象铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 旨在利用具有多个内禀自由度的超原子（在经典领域已有研究）来研究拓扑模型，特别是扩展的Zig-Zag模型，以探索新的研究方向。

Method: 提出一种超导量子模拟器，使用具有简并偶极轨道的极化比特来实现扩展的Zig-Zag模型，并通过逆参与比和拓扑不变量进行数值和解析映射，同时进行电磁建模以验证模型。

Result: 演示了扩展Zig-Zag模型中存在带隙局域化的平凡和Tamm边缘态，并证明所提出的超原子排列能够精确复现该模型。

Conclusion: 该工作为实验研究先前无法触及的拓扑量子多体现象提供了可能。

Abstract: In recent years, quantum simulators of topological models have been
extensively studied across a variety of platforms and regimes. A new promising
research direction makes use of meta-atoms with multiple intrinsic degrees of
freedom, which to date have been predominantly studied in the classical regime.
Here, we propose a superconducting quantum simulator to study an extension of
the well-known "Zig-Zag" model with long-range cross-polarization couplings
using polarization transmons hosting degenerate dipole orbitals. We map the
phase transitions of the extended "Zig-Zag" model both numerically and
analytically using inverse participation ratios and topological invariants. We
demonstrate the existence of in-gap localized trivial and Tamm edge states.
With linearized meta-atoms, we show via electromagnetic modeling that the
proposed arrangement closely reproduces the extended "Zig-Zag" model. This work
paves the way towards experimental investigation of the previously inaccessible
topological quantum many-body phenomena.

</details>


### [381] [Measuring weak microwave signals via current-biased Josephson Junctions II: Arriving at single-photon detection sensitivity](https://arxiv.org/abs/2510.20570)
*Y. Q. Chai,M. Y. Wang,S. N. Wang,P. H. Ouyang,L. F. Wei*

Main category: quant-ph

TL;DR: 非平衡约瑟夫森阈值探测器（JTD）可用于高灵敏度检测微波信号，甚至达到能量量子极限。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，电流偏置约瑟夫森结（CBJJ）可作为约瑟夫森阈值探测器（JTD）来检测微弱微波信号。本文旨在探索非平衡JTD在实现更高灵敏度检测方面的潜力。

Method: 在热噪声存在的情况下，对CBJJ在JTD中的相位动力学进行数值模拟，并改变偏置电流的扫描速率。

Result: 发现在不同扫描速率下，有无微波信号输入的JTD的奇异吸引子曲线（SCDs）表现出不同行为。快速非绝热驱动下，SCDs对热噪声不敏感，表明非平衡JTD具有比平衡态更高的探测灵敏度。

Conclusion: 非平衡JTD可以实现单微波光子探测，并估算了其作为宽带微波单光子探测器的一些性能指标，如动态范围、探测带宽和光子数可分辨度等。

Abstract: It is well known that the current-biased Josephson junction (CBJJ) can serve
as a Josephson threshold detector (JTD) for the sensitive detection of weak
microwave signals. Based on the recent work (PRB {\bf 111}, 024501 (2025)) on
the detection sensitive limit of the usual equilibrium JTD, here we numerically
demonstrate that a non-equilibrium JTD can be alternatively utilized to
implement the higher sensitive detection of a weak microwave signal, arriving
at its energy quantum limit. In the presence of thermal noise, we numerically
simulate the phase dynamics for the CBJJ in the JTD with the different sweep
rates of the biased currents, and find that the SCDs of the JTD with and
without the microwave signal input show different behaviors. It is demonstrated
that, depending on how high the sweep rate of the biased current being applied,
the JTD can be operated in either the equilibrium- or the non-equilibrium
state. Specifically, under the rapidly non-adiabatic driving, the SCDs of the
JTD are obviously insensitive to the thermal noises, which means that the
non-equilibrium JTD can possess a higher achievable detection sensitivity,
compared with its equilibrium state counterpart. Consequently, the
non-equilibrium JTD can be utilized to implement the desired single
microwave-photon detection. Also, some of the achievable performance indexes,
such as the dynamic range, detection bandwidth, and the photon-number
resolvability, etc., of the non-equilibrium JTD have been estimated, when it
serves as a wideband microwave single-photon detector.

</details>


### [382] [Phase Transitions and Virtual Exceptional Points in Quantum Emitters Coupled to Dissipative Baths](https://arxiv.org/abs/2510.20571)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 研究了单量子比特与半无限耗散玻色子格栅边缘耦合时的弛豫动力学，揭示了丰富的动力学相变，并发现了加速自发辐射的最佳耗散环境。


<details>
  <summary>Details</summary>
Motivation: 非厄米光子浴提供了控制原子-光子相互作用的新途径，为量子光学和量子技术提供了新的平台。

Method: 研究了单量子比特耦合到具有均匀损耗的半无限耗散玻色子格栅边缘时的弛豫动力学，并通过分析系统参数变化时的自发辐射衰减行为来揭示相变。

Result: 发现了与系统参数变化相关的自发辐射衰减的动力学相变，并确定了一个能够加速自发辐射的最佳耗散环境。相变与可解性重构有关，有时由第二里曼表面的共振态的合并引起，这些合并被识别为虚拟的例外点。

Conclusion: 耗散的性质（例如均匀损耗、交错损耗或退相干）可以深刻地影响量子发射体的弛豫，表明耗散工程可以作为量子技术的一种多功能工具。

Abstract: Controlling atom-photon interactions in engineered environments is central to
quantum optics and emerging quantum technologies. Non-Hermitian (NH) photonic
baths, where dissipation fundamentally reshapes spectral and dynamical
properties, provide versatile platforms for such control. Here we investigate
the relaxation dynamics of a single two-level quantum emitter coupled to the
edge of a semi-infinite dissipative bosonic lattice with uniform loss. Despite
the simplicity of this bath, we uncover rich dynamical phase transitions, i.e.
qualitative changes in spontaneous emission decay as system parameters are
varied. In particular, we establish the existence of an optimal dissipative
environment for accelerated spontaneous emission. The phase transitions are
traced to spectral restructuring of the resolvent, in some cases governed by
the coalescence of resonance states on the second Riemann sheet. We identify
these coalescences as virtual exceptional points (EPs) of resonance origin,
providing a conceptual bridge with EP physics while highlighting distinctive
features of infinite-dimensional NH systems. More broadly, our results
illustrate how the specific nature of dissipation -- whether uniform losses,
staggered losses, or dephasing -- can profoundly impact emitter relaxation,
pointing to dissipation engineering as a versatile tool for quantum
technologies.

</details>


### [383] [Generating pseudo-random unitaries with a Floquet driven chaotic quantum system](https://arxiv.org/abs/2510.20581)
*Alice C. Quillen,Abobakar Sediq Miakhel*

Main category: quant-ph

TL;DR: 使用抖动量子系统在环面上生成伪随机酉算子。


<details>
  <summary>Details</summary>
Motivation: 探讨利用扰动的哈珀模型，在强扰动和超过振动频率的扰动频率下，生成伪随机酉算子。

Method: 通过计算控制参数分布的傅科传播子，在有限维空间中生成酉算子样本，并计算k-框架势以与Haar随机分布进行比较。

Result: 发现4个控制参数的均匀分布可以生成近似3设计，而具有系统参数漂移的抖动系统则需要更少的控制参数。

Conclusion: 抖动量子系统可以用于生成近似3设计的酉算子，并且可以通过调整控制参数和考虑系统参数漂移来优化此过程。

Abstract: We explore using an ergodic Floquet quantum system on a torus to generate
pseudo-random unitary operators. We choose a regime of the perturbed Harper
model with strong perturbations and perturbation frequency exceeding the
libration frequency to ensure that the system has an ergodic region that covers
phase space and lacks resonant substructure. We generate a sample of unitary
operators in a finite dimensional space by computing Floquet propagators from a
distribution of its control parameters. To compare the distribution of
unitaries to that of a Haar-random distribution, we compute k-frame potentials
from samples of numerically generated unitaries. We find that uniform
distributions of 4 control parameters can generate an approximate 3-design.
Distributions of fewer control parameters are required to create an approximate
3-design if the Floquet system parameters drift.

</details>


### [384] [Gravitationally mediated entanglement of fermionic qubits: from static to dynamical limits](https://arxiv.org/abs/2510.20587)
*Moslem Zarei,Mehdi Abdi,Nicola Bartolo,Sabino Matarrese*

Main category: quant-ph

TL;DR: 本文使用量子玻尔兹曼方程研究了两个远程量子比特间的引力诱导纠缠，并提出了两种具体的微观模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨引力是否能诱导纠缠，并为引力量子化提供实验证据。

Method: 通过引入引力子传播子作为相互作用媒介，并考虑量子比特处于空间叠加态，利用量子玻尔兹曼方程进行分析。同时，将量子比特视为波包中的自旋1/2粒子，并区分了传播子的静态和动态极限。

Result: 研究表明，只有在动态极限下才能生成纠缠态。对于基于磁场背景下费米子模型的微观模型，纠缠量取决于量子比特的拉莫尔频率而非其质量。此外，两种模型中的纠缠效应都随着波包尺寸的增大而减弱。

Conclusion: 本文揭示了引力介导的两个自旋1/2粒子间的纠缠机制，并指出了影响纠缠的因素。

Abstract: We employ the quantum Boltzmann equation to analyze the gravitationally
generated entanglement between two remote qubits by considering two explicit
microscopic models. A graviton propagator is employed as the mediator of the
interactions, while the qubits are considered in a spatial superposition state.
Such a setup, in the case of any entanglement generation, could potentially
offer experimental evidence for the quantization of gravity. By treating the
qubits as spin-1/2 particles in wave packets, we establish that the
entanglement arises from forward scattering processes involving graviton
exchanges. In our study, we consider both static and dynamical limits of the
propagator and show that only in the dynamical limit such entangled states can
be generated. We also show that for the microscopic model based on the fermion
particles in the background of magnetic field, the amount of entanglement
depends on the Larmor frequency of the qubits, rather than their masses. These
effects are observed to diminish in both models as the wave packet size
increases. Our findings sheds more light into the gravity mediated entanglement
between two spin-1/2 particles.

</details>


### [385] [A Gateway to Quantum Computing for Industrial Engineering](https://arxiv.org/abs/2510.20620)
*Emily L. Tucker,Mohammadhossein Mohammadisiahroudi*

Main category: quant-ph

TL;DR: 量子计算为工业工程和运筹学带来了机遇和挑战，本文提供了量子运筹学的路线图，涵盖了基础知识、算法、应用方向和学习路径，旨在降低入门门槛，促进跨学科合作。


<details>
  <summary>Details</summary>
Motivation: 工业工程和运筹学正面临量子计算带来的机遇和挑战，需要为研究人员提供学习和参与该领域的指导。

Method: 介绍量子计算基础，梳理软硬件现状，总结与工业工程/运筹学相关的算法进展（线性代数、优化、机器学习、随机模拟），探讨应用方向（问题领域、经典模型量子化），并提出学习路径和跨学科合作建议。

Result: 提供了量子运筹学的全面概述，包括技术细节、应用前景和教育策略，为工业工程/运筹学研究人员参与该领域奠定了基础。

Conclusion: 工业工程师在推动量子计算实际应用方面具有独特优势，本文旨在降低量子计算的入门门槛，激发新的合作，并为量子技术在工业和学术界的实际应用指明方向。

Abstract: Quantum computing is rapidly emerging as a new computing paradigm with the
potential to improve decision-making, optimization, and simulation across
industries. For industrial engineering (IE) and operations research (OR), this
shift introduces both unprecedented opportunities and substantial challenges.
The learning curve is high, and to help researchers navigate the emerging field
of quantum operations research, we provide a road map of the current field of
quantum operations research. We introduce the foundational principles of
quantum computing, outline the current hardware and software landscape, and
survey major algorithmic advances relevant to IE/OR, including quantum
approaches to linear algebra, optimization, machine learning, and stochastic
simulation. We then highlight applied research directions, including the
importance of problem domains for driving long-term value of quantum computers
and how existing classical OR models can be reformulated for quantum hardware.
Recognizing the steep learning curve, we propose pathways for IE/OR researchers
to develop technical fluency and engage in this interdisciplinary domain. By
bridging theory with application, and emphasizing the interplay between
hardware and research development, we argue that industrial engineers are
uniquely positioned to shape the trajectory of quantum computing for practical
problem-solving. Ultimately, we aim to lower the barrier to entry into quantum
computing, motivate new collaborations, and chart future directions where
quantum technologies may deliver tangible impact for industry and academia.

</details>


### [386] [Quantum Processing Unit (QPU) processing time Prediction with Machine Learning](https://arxiv.org/abs/2510.20630)
*Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito*

Main category: quant-ph

TL;DR: 机器学习模型（如LightGBM）可用于预测量子计算任务的QPU处理时间，以提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子计算系统的运行效率，本研究旨在应用机器学习技术来预测量子任务的QPU处理时间。

Method: 使用基于梯度提升（LightGBM）的机器学习方法，并结合数据预处理技术，对包含约15万个遵循IBM量子模式的量子任务的数据集进行QPU处理时间预测。

Result: 研究结果表明，机器学习模型能够有效预测量子任务的处理时间，展示了其在预测量子作业方面的潜力。

Conclusion: 机器学习在预测量子任务处理时间方面显示出巨大潜力，可为优化量子计算中的资源管理和调度奠定基础，并为集成人工智能驱动的工具到先进的量子计算操作中铺平道路。

Abstract: This paper explores the application of machine learning (ML) techniques in
predicting the QPU processing time of quantum jobs. By leveraging ML
algorithms, this study introduces predictive models that are designed to
enhance operational efficiency in quantum computing systems. Using a dataset of
about 150,000 jobs that follow the IBM Quantum schema, we employ ML methods
based on Gradient-Boosting (LightGBM) to predict the QPU processing times,
incorporating data preprocessing methods to improve model accuracy. The results
demonstrate the effectiveness of ML in forecasting quantum jobs. This
improvement can have implications on improving resource management and
scheduling within quantum computing frameworks. This research not only
highlights the potential of ML in refining quantum job predictions but also
sets a foundation for integrating AI-driven tools in advanced quantum computing
operations.

</details>


### [387] [Computing time-dependent reduced models for classical and quantum dynamics](https://arxiv.org/abs/2510.20675)
*Tommaso Grigoletto*

Main category: quant-ph

TL;DR: 提出了一种新的递归算法，用于构建多项式时间依赖的有效生成器，以近似大型自治系统在固定子空间上的动力学。


<details>
  <summary>Details</summary>
Motivation: 解决量子物理学中推导时间无关主方程的挑战，并提供一种替代耦合强度展开的方法。

Method: 基于指数映射的泰勒展开和计算多项式生成器的时间排序指数的一个新结果。

Result: 该近似在短时间内准确，不需要弱耦合假设，在低阶时优于指数映射的截断，并保证了最低阶的完全正迹保持映射。

Conclusion: 该方法通过在去相干自旋-玻子模型、中心自旋模型和伊辛自旋链等原型模型上的验证，证明了其有效性。

Abstract: This paper introduces a novel method for approximating the dynamics of a
large autonomous system projected onto a fixed subspace. The core contribution
is a novel recursive algorithm to construct an effective time-dependent
generator that is polynomial in the time variable, ensuring accuracy for short
time scales. The derivation is based on the Taylor expansion of the exponential
map and a new result for computing the time-ordered exponential of polynomial
generators. This work is motivated by the challenge of deriving
time-convolutionless master equations in quantum physics and the proposed
method offers an alternative to typical derivations based on expansions in the
coupling strength. The resulting approximation is accurate for small times,
does not require a weak-coupling assumption, performs better than a truncation
of the exponential map at low orders, and crucially, guarantees a completely
positive and trace-preserving map at the lowest orders. The proposed method is
validated against several prototypical models: a dephasing spin-boson model, a
central spin model, and an Ising spin chain.

</details>


### [388] [Classical Noise Inversion: A Practical and Optimal framework for Robust Quantum Applications](https://arxiv.org/abs/2510.20686)
*Dayue Qin,Ying Li,You Zhou*

Main category: quant-ph

TL;DR: 量子纠错是一种关键技术，用于从嘈杂的量子处理器中提取可靠的计算结果。然而，其实际应用受到采样成本高和依赖于不切实际的假设（如门控噪声无关）的阻碍。我们提出了经典噪声反演（CNI）框架，该框架通过经典后处理来反转累积噪声，从而消除了昂贵的量子电路采样需求，并且在实际的门控噪声依赖条件下仍然有效。此外，我们还引入了噪声压缩，将具有等效测量结果影响的噪声分量进行分组，实现了纠错的最佳开销。我们将CNI与影子估计算法相结合，创建了一个在一般噪声下学习量子特性的鲁棒协议。我们的分析和数值模拟表明，该方法在先前方法失败的实际情况下，可以显著降低统计方差并提供无偏估计。通过将关键的量子开销转化为可管理的经典成本，CNI为可扩展和实用的量子应用开辟了一条有前景的道路。


<details>
  <summary>Details</summary>
Motivation: 量子纠错技术对于在近期和未来全容错系统中提取可靠的量子计算至关重要。然而，其实际应用面临采样成本高和依赖于不切实际的门控噪声无关假设的挑战。

Method: 本研究提出了经典噪声反演（CNI）框架，通过在经典后处理中反转累积噪声来克服采样成本高和门控噪声依赖的限制。此外，还引入了噪声压缩技术，对具有等效测量结果影响的噪声分量进行分组，以实现最优开销。CNI与影子估计算法相结合，形成了一个在一般噪声下学习量子特性的鲁棒协议。

Result: CNI框架消除了昂贵的量子电路采样需求，并在门控噪声依赖的实际条件下有效。该方法显著降低了统计方差，并提供了无偏估计，特别是在先前方法失败的情况下。噪声压缩实现了最优的纠错开销。

Conclusion: CNI框架通过将关键的量子开销转化为可管理的经典成本，为实现可扩展和实用的量子应用提供了一条有前景的道路。

Abstract: Quantum error mitigation is a critical technology for extracting reliable
computations from noisy quantum processors, proving itself essential not only
in the near term but also as a valuable supplement to fully fault-tolerant
systems in the future. However, its practical implementation is hampered by two
major challenges: the expansive cost of sampling from quantum circuits and the
reliance on unrealistic assumptions, such as gate-independent noise. Here, we
introduce Classical Noise Inversion (CNI), a framework that fundamentally
bypasses these crucial limitations and is well-suited for various quantum
applications. CNI effectively inverts the accumulated noise entirely during
classical post-processing, thereby eliminating the need for costly quantum
circuit sampling and remaining effective under the realistic condition of
gate-dependent noise. Apart from CNI, we introduce noise compression, which
groups noise components with equivalent effects on measurement outcomes,
achieving the optimal overhead for error mitigation. We integrate CNI with the
framework of shadow estimation to create a robust protocol for learning quantum
properties under general noise. Our analysis and numerical simulations
demonstrate that this approach substantially reduces statistical variance while
providing unbiased estimates in practical situations where previous methods
fail. By transforming a key quantum overhead into a manageable classical cost,
CNI opens a promising pathway towards scalable and practical quantum
applications.

</details>


### [389] [Note on Energy Shifts of Oscillators in Blackbody Radiation](https://arxiv.org/abs/2510.20711)
*Peter Milonni*

Main category: quant-ph

TL;DR: 黑体辐射中振荡器的能量移动根据相互作用场-振荡器系统的总能量随折射率的变化来计算。在高温 T 下，能量和自由能移动分别与 -T^2 和 +T^2 成正比，这与 Ford, Lewis 和 O'Connell 最初获得的结果一致。


<details>
  <summary>Details</summary>
Motivation: 计算振荡器在黑体辐射中的能量移动。

Method: 基于相互作用场-振荡器系统的总能量随折射率的变化进行计算。

Result: 在高温 T 下，能量和自由能移动分别与 -T^2 和 +T^2 成正比。

Conclusion: 在高温 T 下，计算出的能量和自由能移动与 Ford, Lewis 和 O'Connell 最初获得的结果一致。

Abstract: The energy shift of an oscillator in blackbody radiation is calculated based
simply on the total energy of the interacting field-oscillator system as a
function of the refractive index. For high temperatures T the energy and
free-energy shifts are found to vary as -T^2 and +T^2, respectively, in
agreement with the result originally obtained by Ford, Lewis, and O'Connell
[Phys. Rev. Lett. 55, 2273 (1985)].

</details>


### [390] [How typical is contextuality?](https://arxiv.org/abs/2510.20722)
*Vinicius P. Rossi,Beata Zjawin,Roberto D. Baldijão,David Schmid,John H. Selby,Ana Belén Sainz*

Main category: quant-ph

TL;DR: 随机选择的量子制备和测量通常会产生非经典统计数据，但高度非经典现象并不常见。


<details>
  <summary>Details</summary>
Motivation: 识别何时无法用任何合理的经典模型来解释观测到的统计数据是量子基础中的一个核心问题。通过广义非情境性的概念，可以为定义和识别非经典性提供一个原则性和普遍适用的方法。

Method: 使用数值线性规划来测试是否存在广义非情境模型，并分析非情境性的典型性随制备和测量纯度的变化。

Result: 即使在只有少量随机制备和测量的情况下，非情境性也会以超过99%的概率出现。非情境性的典型性随纯度降低而降低，但这种依赖性并不显著。虽然非零非情境性很普遍，但高度非情境性并不像预期的那么普遍，因此大的量子优势并不常见。

Conclusion: 随机选择的量子制备和测量通常会产生非经典统计数据，但高度非经典现象并不常见。研究结果表明，虽然非情境性在实验中很常见，但其程度取决于制备和测量的纯度。研究提供了一个工具箱，可以根据实验参数来计算非情境性的典型性，从而指导实验设计。

Abstract: Identifying when observed statistics cannot be explained by any reasonable
classical model is a central problem in quantum foundations. A principled and
universally applicable approach to defining and identifying nonclassicality is
given by the notion of generalized noncontextuality. Here, we study the
typicality of contextuality -- namely, the likelihood that randomly chosen
quantum preparations and measurements produce nonclassical statistics. Using
numerical linear programs to test for the existence of a
generalized-noncontextual model, we find that contextuality is fairly common:
even in experiments with only a modest number of random preparations and
measurements, contextuality arises with probability over 99%. We also show that
while typicality of contextuality decreases as the purity (sharpness) of the
preparations (measurements) decreases, this dependence is not especially
pronounced, so contextuality is fairly typical even in settings with realistic
noise. Finally, we show that although nonzero contextuality is quite typical,
quantitatively high degrees of contextuality are not as typical, and so large
quantum advantages (like for parity-oblivious multiplexing, which we take as a
case study) are not as typical. We provide an open-source toolbox that outputs
the typicality of contextuality as a function of tunable parameters (such as
lower and upper bounds on purity and other constraints on states and
measurements). This toolbox can inform the design of experiments that achieve
the desired typicality of contextuality for specified experimental constraints.

</details>


### [391] [Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems](https://arxiv.org/abs/2510.20728)
*Xi He,Sirui Lu,Bei Zeng*

Main category: quant-ph

TL;DR: 提出了一种结合 GPT-5 和多智能体研究助手 TeXRA 的新型人机协作工作流，用于设计具有给定横向对角门（transversal diagonal gates）的量子码。该工作流利用了基于子集和线性规划 (SSLP) 的框架，并通过三个角色（合成、搜索、审计）协同工作，在 LaTeX-Python 环境中进行推理、文档编辑、代码执行和版本控制。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够设计具有特定横向对角门的量子码的自动化和可扩展方法，以克服手动设计和验证的挑战。

Method: 采用多智能体、人机协作的工作流，整合了 GPT-5 和 TeXRA 平台。该工作流利用 SSLP 框架，将问题分解为多个子问题，并由三个专门的智能体（合成、搜索、审计）在 LaTeX-Python 环境中协同完成。智能体之间通过迭代工具使用和推理-编辑循环进行协作，并使用 Git/Overleaf 进行版本控制。

Result: 成功构建了用于设计量子码的新工作流，并在 $d=2$ 的情况下，对于 $K 	e{2,3,4}$ 和 $n 	e{6}$ 的量子比特数，生成了具有证书支持的循环逻辑群表，其中包含了新的量子码。例如，对于 $K=3$，在 $n=6$ 时获得了 16 阶的逻辑群。此外，还发现了一个新的 $((6,4,2))$ 量子码，实现了横向的受控-相（controlled-phase）$diag(1,1,1,i)$，表明 SSLP 框架可以处理残差退化的情况。

Conclusion: 所提出的多智能体人机协作工作流能够有效地将横向对角门的可行性问题转化为可规模化执行的分析流程，结合了系统枚举和精确解析重建，实现了可复现的量子码构建，并为扩展到更大的 $K$ 和更高的距离，以及数据驱动的分类奠定了基础。

Abstract: We present a multi-agent, human-in-the-loop workflow that co-designs quantum
codes with prescribed transversal diagonal gates. It builds on the Subset-Sum
Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis
strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)
equalities via small LPs. The workflow is powered by GPT-5 and implemented
within TeXRA (https://texra.ai)-a multi-agent research assistant platform that
supports an iterative tool-use loop agent and a derivation-then-edit workflow
reasoning agent. We work in a LaTeX-Python environment where agents reason,
edit documents, execute code, and synchronize their work to Git/Overleaf.
Within this workspace, three roles collaborate: a Synthesis Agent formulates
the problem; a Search Agent sweeps/screens candidates and exactifies numerics
into rationals; and an Audit Agent independently checks all KL equalities and
the induced logical action. As a first step we focus on distance $d=2$ with
nondegenerate residues. For code dimension $K\in\{2,3,4\}$ and $n\le6$ qubits,
systematic sweeps yield certificate-backed tables cataloging attainable cyclic
logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$
at $n=6$. From verified instances, Synthesis Agent abstracts recurring
structures into closed-form families and proves they satisfy the KL equalities
for all parameters. It further demonstrates that SSLP accommodates residue
degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal
controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts
diagonal-transversal feasibility as an analytical pipeline executed at scale,
combining systematic enumeration with exact analytical reconstruction. It
yields reproducible code constructions, supports targeted extensions to larger
$K$ and higher distances, and leads toward data-driven classification.

</details>


### [392] [Optimal constant-cost implementations of Clifford operations using global interactions](https://arxiv.org/abs/2510.20730)
*Jonathan Nemirovsky,Lee Peleg,Amit Ben Kish,Yotam Shapira*

Main category: quant-ph

TL;DR:  Clifford operations can be implemented with a constant cost of at most four all-to-all multiqubit entangling gates, which is theoretically optimal. This method also offers lower qubit drive power compared to standard approaches.


<details>
  <summary>Details</summary>
Motivation: The paper aims to find a computationally efficient and practical algorithm for implementing Clifford operations using a constant number of all-to-all multiqubit entangling gates.

Method: The study investigates quantum circuits with arbitrary single-qubit operations and programmable all-to-all multiqubit entangling gates. It demonstrates that any sequence of Clifford operations can be realized with a maximum of four applications of these entangling gates, without using ancillae. The paper specifically shows this can be achieved for any sequence of CNOT gates and extends the finding to general Clifford operations.

Result: The research shows that any sequence of Clifford operations can be implemented with a constant cost of no more than four applications of all-to-all multiqubit entangling gates, which is the theoretically optimal gate count. Additionally, the proposed implementation requires lower qubit drive power than standard methods.

Conclusion: The paper presents a practical and computationally efficient algorithm for compiling Clifford operations, achieving the theoretically optimal gate count and offering an advantage in terms of qubit drive power.

Abstract: We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than four applications of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae, which is the theoretically optimal gate count
cost. We do this by implementing any sequence of CNOT gates of any length with
four applications of such gates, without ancillae, and show that the extension
to general Clifford operations incurs no additional cost. We investigate the
required qubit drive power that is associated with our implementation and show
that it is lower than that of a standard approach. Our work introduces a
practical and computationally efficient algorithm to realize these
compilations.

</details>


### [393] [Quantum Sensing of Gravitational Frame-Dragging with a Superfluid $^4$He Gyrometer](https://arxiv.org/abs/2510.20772)
*Kai-Isaak Ellers,Marios Christodoulou,K. C. Schwab,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: 本实验提出了一种使用新型超流氦-4单约瑟夫森结陀螺仪测量地球上引力诱导的参考系拖拽效应的实验室方法。


<details>
  <summary>Details</summary>
Motivation: 动机是利用宏观量子特性来测量地球上的引力诱导的参考系拖拽效应。

Method: 该方法利用超流氦-4单约瑟夫森结陀螺仪，在毫开尔文温度下，通过测量热噪声来计算参考系拖拽、大地测量和托马斯效应，并提出实验测量步骤。

Result: 计算出的噪声频谱密度为 $5 	imes 10^{-17}$ rad/s/$\sqrt{\mathrm{Hz}}$ （在10 mK温度下），这足以在1秒内将参考系拖拽速率的测量精度提高到0.2%，达到 $10^{-35}$ s 的固有时间差测量精度。

Conclusion: 在毫开尔文温度下，近乎零机械损耗的约瑟夫森结超流陀螺仪具有极高的灵敏度，能够精确测量引力诱导的参考系拖拽效应。

Abstract: We propose a laboratory-scale experiment to locally measure the general
relativistic frame-dragging effect on Earth using the macroscopic quantum
properties of a novel superfluid $^4$He single Josephson junction gyrometer. We
derive the frame-dragging and related geodetic and Thomas effects in the
superfluid gyrometer and present a procedure for their experimental
measurement. We compute the expected thermal noise floor and find that very
high sensitivity can be expected at millikelvin temperatures, where near-future
Josephson junctions using nanoporous 2D materials are expected to operate.
Assuming utilization of the lowest mechanical loss materials, we find a noise
spectral density of $5\times 10^{-17}$ rads/s/$\sqrt{\mathrm{Hz}}$ at 10 mK,
which is sufficient to resolve the frame-dragging rate to 0.2% within one
second of measurement, giving a rotational sensitivity of 1 revolution in 4
Byrs. This extreme sensitivity to rotation corresponds to a measurement of
proper time differences as small as $10^{-35}$ s.

</details>


### [394] [The complexity of perfect quantum state classification](https://arxiv.org/abs/2510.20789)
*Nathaniel Johnston,Benjamin Lovitz,Vincent Russo,Jamie Sikora*

Main category: quant-ph

TL;DR: 该论文研究量子状态分类问题，引入k-可学习性概念，并提出判定k-可学习性的半定规划方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子状态分类问题，即在已知状态集中识别未知量子状态的准确性。

Method: 引入k-可学习性概念，利用半定规划判定k-可学习性，并针对k或维度为常数的情况提出多项式时间算法。

Result: 提出判定k-可学习性的半定规划方法，在k或维度为常数时提供多项式时间算法，并证明当k和维度均为变量时存在NP相关证书且为NP-hard。

Conclusion: 该研究明确了量子状态分类在完美（零误差）情况下，可有效解决与难解实例的界限。

Abstract: The problem of quantum state classification asks how accurately one can
identify an unknown quantum state that is promised to be drawn from a known set
of pure states. In this work, we introduce the notion of $k$-learnability,
which captures the ability to identify the correct state using at most $k$
guesses, with zero error. We show that deciding whether a given family of
states is $k$-learnable can be solved via semidefinite programming. When there
are $n$ states, we present polynomial-time (in $n$) algorithms for determining
$k$-learnability for two cases: when $k$ is a fixed constant or the dimension
of the states is a fixed constant. When both $k$ and the dimension of the
states are part of the input, we prove that there exist succinct certificates
placing the problem in NP, and we establish NP-hardness by a reduction from the
classical $k$-clique problem. Together, our findings delineate the boundary
between efficiently solvable and intractable instances of quantum state
classification in the perfect (zero-error) regime.

</details>


### [395] [Analog Quantum Feature Selection with Neutral-Atom Quantum Processors](https://arxiv.org/abs/2510.20798)
*Jose J. Orquin-Marques,Carlos Flores-Garrigos,Alejandro Gomez Cadavid,Anton Simen,Enrique Solano,Narendra N. Hegade,Jose D. Martin-Guerrero,Yolanda Vives-Gilabert*

Main category: quant-ph

TL;DR: 本文提出了一种基于中性原子模拟的量子特征选择（QFS）方法，通过局部失谐和范德华相互作用编码特征相关性和冗余性，并利用绝热演化提取特征子集。通过在三个基准数据集上的模拟，该方法在保持或优于经典方法的同时，显著减少了特征数量，展示了其在机器学习中的实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的量子特征选择方法，以解决现有经典方法在处理高维数据时的局限性，并探索中性原子阵列在机器学习中的应用潜力。

Method: 1. 将特征相关性（通过互信息衡量）编码为局部失谐幅度。
2. 将特征冗余性编码为距离依赖的范德华相互作用（受里德堡阻塞半径约束）。
3. 系统进行绝热演化以达到低能配置。
4. 提取测量比特串以获得物理上一致的特征子集。

Result: 在 Adult Income, Bank Marketing, 和 Telco Churn 三个数据集上，与经典方法（如互信息排序、Boruta 结合 XGBoost 和随机森林）相比，量子方法在 2-5 个特征的紧凑子集上，平均 AUC 分数提高了 1.5-2.3%，同时特征数量减少了 75-84%。

Conclusion: 基于可编程里德堡阵列的量子特征选择方法是一种可行的、具有实际应用价值的机器学习解决方案，能够将计算量子优势转化为工业量子效用。

Abstract: We present a quantum-native approach to quantum feature selection (QFS) based
on analog quantum simulation with neutral atom arrays, adaptable to a variety
of academic and industrial applications. In our method, feature
relevance-measured via mutual information with the target-is encoded as local
detuning amplitudes, while feature redundancy is embedded through
distance-dependent van der Waals interactions, constrained by the Rydberg
blockade radius. The system is evolved adiabatically toward low-energy
configurations, and the resulting measurement bitstrings are used to extract
physically consistent subsets of features. The protocol is evaluated through
simulations on three benchmark binary classification datasets: Adult Income,
Bank Marketing, and Telco Churn. Compared to classical methods such as mutual
information ranking and Boruta, combined with XGBoost and Random Forest
classifiers, our quantum-computing approach achieves competitive or superior
performance. In particular, for compact subsets of 2-5 features, analog QFS
improves mean AUC scores by 1.5-2.3% while reducing the number of features by
75-84%, offering interpretable, low-redundancy solutions. These results
demonstrate that programmable Rydberg arrays offer a viable platform for
intelligent feature selection with practical relevance in machine learning
pipelines, capable of transforming computational quantum advantage into
industrial quantum usefulness.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [396] [On Hardness and Approximation of Broadcasting in Sparse Graphs](https://arxiv.org/abs/2510.20026)
*Jeffrey Bringolf,Hovhannes A. Harutyunyan,Shahin Kamali,Seyed-Mohammad Seyed-Javadi*

Main category: cs.DS

TL;DR: 研究稀疏图中的电话广播问题，证明了k-环图和k-路径图的NP-hard性，并提出了k-环图和k-路径图的多项式时间近似方案（PTAS），同时证明了有界带宽图的可解性。


<details>
  <summary>Details</summary>
Motivation: 研究稀疏图中的电话广播问题，解决已有的开放性问题，并改进近似因子。

Method: 证明k-环图和k-路径图的NP-hard性；提出k-环图和k-路径图的PTAS；证明有界带宽图的可解性。

Result: k-环图和k-路径图的NP-hard性得到证明；k-环图和k-路径图的PTAS提出，近似因子优于现有结果；有界带宽图问题可被有效解决。

Conclusion: 该研究在稀疏图的电话广播问题上取得了重要进展，不仅解决了理论上的难题，还提供了更优的算法和更广泛的可解性结果。

Abstract: We study the Telephone Broadcasting problem in sparse graphs. Given a
designated source in an undirected graph, the task is to disseminate a message
to all vertices in the minimum number of rounds, where in each round every
informed vertex may inform at most one uninformed neighbor. For general graphs
with $n$ vertices, the problem is NP-hard. Recent work shows that the problem
remains NP-hard even on restricted graph classes such as cactus graphs of
pathwidth $2$ [Aminian et al., ICALP 2025] and graphs at distance-1 to a path
forest [Egami et al., MFCS 2025].
  In this work, we investigate the problem in several sparse graph families. We
first prove NP-hardness for $k$-cycle graphs, namely graphs formed by $k$
cycles sharing a single vertex, as well as $k$-path graphs, namely graphs
formed by $k$ paths with shared endpoints. Despite multiple efforts to
understand the problem in these simple graph families, the computational
complexity of the problem had remained unsettled, and our hardness results
answer open questions by Bhabak and Harutyunyan [CALDAM 2015] and Harutyunyan
and Hovhannisyan [COCAO 2023] concerning the problem's complexity in $k$-cycle
and $k$-path graphs, respectively.
  On the positive side, we present Polynomial-Time Approximation Schemes
(PTASs) for $k$-cycle and $k$-path graphs, improving over the best existing
approximation factors of $2$ for $k$-cycle graphs and an approximation factor
of $4$ for $k$-path graphs. Moreover, we identify a structural frontier for
tractability by showing that the problem is solvable in polynomial time on
graphs of bounded bandwidth. This result generalizes existing tractability
results for special sparse families such as necklace graphs.

</details>


### [397] [Parallel Joinable B-Trees in the Fork-Join I/O Model](https://arxiv.org/abs/2510.20053)
*Michael Goodrich,Yan Gu,Ryuto Kitagawa,Yihan Sun*

Main category: cs.DS

TL;DR: 本文研究了基于连接的搜索树算法的并行集合操作，并首次在新的Fork-Join I/O模型下界定了I/O成本。


<details>
  <summary>Details</summary>
Motivation: 现有并行搜索树算法在I/O访问模式上效率低下，缺乏对I/O成本的严格界定。本研究旨在解决这一问题，为并行集合操作提供更高效的I/O解决方案。

Method: 提出了一种新的Fork-Join I/O模型来衡量并行计算中的I/O成本（包括I/O工作量和I/O跨度）。在此模型下，基于B-树设计了一种新的并行算法，用于计算两个B-树的并集、交集和差集。

Result: 所提出的并行算法在Fork-Join I/O模型下，对于包含n和m（m<=n）个节点的两棵B-树，其I/O工作量为O(m log_B(n/m))，I/O跨度为O(log_B m * log_2 log_B n + log_B n)，其中B是块大小。

Conclusion: 本研究首次在新的Fork-Join I/O模型下，为基于连接的并行搜索树集合操作提供了严格的I/O成本界定，并提出了一种基于B-树的高效算法，显著提高了I/O效率。

Abstract: Balanced search trees are widely used in computer science to efficiently
maintain dynamic ordered data. To support efficient set operations (e.g.,
union, intersection, difference) using trees, the join-based framework is
widely studied. This framework has received particular attention in the
parallel setting, and has been shown to be effective in enabling simple and
theoretically efficient set operations on trees. Despite the widespread
adoption of parallel join-based trees, a major drawback of previous work on
such data structures is the inefficiency of their input/output (I/O) access
patterns. Some recent work (e.g., C-trees and PaC-trees) focused on more
I/O-friendly implementations of these algorithms. Surprisingly, however, there
have been no results on bounding the I/O-costs for these algorithms. It remains
open whether these algorithms can provide tight, provable guarantees in
I/O-costs on trees.
  This paper studies efficient parallel algorithms for set operations based on
search tree algorithms using a join-based framework, with a special focus on
achieving I/O efficiency in these algorithms. To better capture the
I/O-efficiency in these algorithms in parallel, we introduce a new
computational model, Fork-Join I/O Model, to measure the I/O costs in fork-join
parallelism. This model measures the total block transfers (I/O work) and their
critical path (I/O span). Under this model, we propose our new solution based
on B-trees. Our parallel algorithm computes the union, intersection, and
difference of two B-trees with $O(m \log_B(n/m))$ I/O work and $O(\log_B m
\cdot \log_2 \log_B n + \log_B n)$ I/O span, where $n$ and $m \leq n$ are the
sizes of the two trees, and $B$ is the block size.

</details>


### [398] [Optimal Rounding for Two-Stage Bipartite Matching](https://arxiv.org/abs/2510.20153)
*Tristan Pollner,Amin Saberi,Anders Wikum*

Main category: cs.DS

TL;DR: 本文研究了两阶段二分匹配问题，旨在最大化两阶段匹配的总权重。


<details>
  <summary>Details</summary>
Motivation: 二分图的边分两批次揭示，第一阶段需要从已揭示的边中选择匹配，第二阶段需要从已知分布中采样边，并在第二批次节点和第一阶段未匹配节点之间选择匹配。

Method: 通过一个算法来解决，该算法将分阶段揭示的分数匹配进行舍入，目标是以与其分数权重成比例的概率来匹配离线节点（或边），但存在常数因子损失。该算法利用离线节点可用性之间的负相关性（NA）来推导新下界，并扩展到仅通过样本访问分布的情况。

Result: 对于顶点加权图，实现了 7/8 的近似比；对于边加权图，在任意分布下实现了 2√2 - 2 ≈ 0.828 的近似比。这些比率匹配了自然分数松弛的整数间隙的已知上限。

Conclusion: 该研究设计了多项式时间近似算法，在两阶段二分匹配问题上取得了最佳近似比，并对依赖舍入引起的负相关性进行了深入分析。

Abstract: We study two-stage bipartite matching, in which the edges of a bipartite
graph on vertices $(B_1 \cup B_2, I)$ are revealed in two batches. In stage
one, a matching must be selected from among revealed edges $E \subseteq B_1
\times I$. In stage two, edges $E^\theta \subseteq B_2 \times I$ are sampled
from a known distribution, and a second matching must be selected between $B_2$
and unmatched vertices in $I$. The objective is to maximize the total weight of
the combined matching. We design polynomial-time approximations to the optimum
online algorithm, achieving guarantees of $7/8$ for vertex-weighted graphs and
$2\sqrt{2}-2 \approx 0.828$ for edge-weighted graphs under arbitrary
distributions. Both approximation ratios match known upper bounds on the
integrality gap of the natural fractional relaxation, improving upon the
best-known approximation of 0.767 by Feng, Niazadeh, and Saberi for unweighted
graphs whose second batch consists of independently arriving nodes.
  Our results are obtained via an algorithm that rounds a fractional matching
revealed in two stages, aiming to match offline nodes (respectively, edges)
with probability proportional to their fractional weights, up to a
constant-factor loss. We leverage negative association (NA) among offline node
availabilities -- a property induced by dependent rounding -- to derive new
lower bounds on the expected size of the maximum weight matching in random
graphs where one side is realized via NA binary random variables. Moreover, we
extend these results to settings where we have only sample access to the
distribution. In particular, $\text{poly}(n,\epsilon^{-1})$ samples suffice to
obtain an additive loss of $\epsilon$ in the approximation ratio for the
vertex-weighted problem; a similar bound holds for the edge-weighted problem
with an additional (unavoidable) dependence on the scale of edge weights.

</details>


### [399] [Smoothed Analysis of Online Metric Matching with a Single Sample: Beyond Metric Distortion](https://arxiv.org/abs/2510.20288)
*Yingxi Li,Ellen Vitercik,Mingwei Yang*

Main category: cs.DS

TL;DR: 本文提出了一种在线度量匹配问题的O(1)竞争算法，适用于非二维欧几里得空间，且对服务器的分布无要求，只需单一样本即可。


<details>
  <summary>Details</summary>
Motivation: 解决在线度量匹配问题，并寻求在除独立同分布（i.i.d.）外的设置下，优于O(log n)的竞争比算法。

Method: 该算法不依赖于概率度量嵌入的分析，而是直接界定算法在简单确定性嵌入的目标度量上的成本，并结合欧几里得度量的离线最优下界来获得保证。

Result: 在d ≠ 2的欧几里得度量空间中，设计了一个O(1)竞争算法，该算法仅需每个请求分布的一个样本，且不依赖于分布信息。

Conclusion: 所提出的算法是首个在非i.i.d.设置下，对非平凡度量实现o(log n)竞争比的算法，有效克服了概率度量嵌入中的O(log n)障碍。

Abstract: In the online metric matching problem, $n$ servers and $n$ requests lie in a
metric space. Servers are available upfront, and requests arrive sequentially.
An arriving request must be matched immediately and irrevocably to an available
server, incurring a cost equal to their distance. The goal is to minimize the
total matching cost.
  We study this problem in the Euclidean metric $[0, 1]^d$, when servers are
adversarial and requests are independently drawn from distinct distributions
that satisfy a mild smoothness condition. Our main result is an
$O(1)$-competitive algorithm for $d \neq 2$ that requires no distributional
knowledge, relying only on a single sample from each request distribution. To
our knowledge, this is the first algorithm to achieve an $o(\log n)$
competitive ratio for non-trivial metrics beyond the i.i.d. setting. Our
approach bypasses the $\Omega(\log n)$ barrier introduced by probabilistic
metric embeddings: instead of analyzing the embedding distortion and the
algorithm separately, we directly bound the cost of the algorithm on the target
metric of a simple deterministic embedding. We then combine this analysis with
lower bounds on the offline optimum for Euclidean metrics, derived via
majorization arguments, to obtain our guarantees.

</details>


### [400] [Separations between Oblivious and Adaptive Adversaries for Natural Dynamic Graph Problems](https://arxiv.org/abs/2510.20341)
*Aaron Bernstein,Sayan Bhattacharya,Nick Fischer,Peter Kiss,Thatchaphol Saranurak*

Main category: cs.DS

TL;DR: 该研究在动态图问题中，首次提出了针对不同类型对手（不可区分对手与适应性对手）的更新时间分离，其分离是指数级的，且基于流行的细粒度复杂性假设。


<details>
  <summary>Details</summary>
Motivation: 动态图算法在面对适应性对手时，其更新时间通常较高。本研究旨在通过引入更新时间分离，阐明为何针对适应性对手的动态算法在某些问题上（如增量式最大独立集和减量式最大团）需要比针对不可区分对手的算法更长的时间，并为这些问题提供理论下界。

Method: 研究者利用组合性BMM假设，推导出增量式最大独立集问题针对适应性对手的更新时间下界为$n^{1-o(1)}$。结合3SUM或APSP假设，证明了减量式最大团问题（初始最大度为$\Delta \le \sqrt{n}$）在面对适应性对手时，更新时间下界为$\Delta/n^{o(1)}$。这些下界与现有算法的匹配性得到了论证。此外，还通过OMv假设，分离了三角形检测问题的增量和减量算法。

Result: 1. 增量式最大独立集问题：针对适应性对手，更新时间下界为$n^{1-o(1)}$（基于BMM假设）。2. 减量式最大团问题：针对适应性对手（$\Delta e 
 \le \sqrt{n}$），更新时间下界为$\Delta/n^{o(1)}$（基于3SUM或APSP假设）。3. 三角形检测问题：减量算法总更新时间为$\tilde{O}(n^{\omega})$，而增量算法总更新时间需要$n^{3-o(1)}$（基于OMv假设）。

Conclusion: 本研究在动态图算法领域取得了重要进展，首次在更新时间上区分了针对不可区分对手和适应性对手的算法，并为增量式最大独立集、减量式最大团以及三角形检测问题分别提供了理论下界和更新时间上的分离。这些结果对于理解和设计更高效的动态图算法具有重要意义。

Abstract: We establish the first update-time separation between dynamic algorithms
against oblivious adversaries and those against adaptive adversaries in natural
dynamic graph problems, based on popular fine-grained complexity hypotheses.
Specifically, under the combinatorial BMM hypothesis, we show that every
combinatorial algorithm against an adaptive adversary for the incremental
maximal independent set problem requires $n^{1-o(1)}$ amortized update time.
Furthermore, assuming either the 3SUM or APSP hypotheses, every algorithm for
the decremental maximal clique problem needs $\Delta/n^{o(1)}$ amortized update
time when the initial maximum degree is $\Delta \le \sqrt{n}$. These lower
bounds are matched by existing algorithms against adaptive adversaries. In
contrast, both problems admit algorithms against oblivious adversaries that
achieve $\operatorname{polylog}(n)$ amortized update time [Behnezhad,
Derakhshan, Hajiaghayi, Stein, Sudan; FOCS '19] [Chechik, Zhang; FOCS '19].
Therefore, our separations are exponential. Previously known separations for
dynamic algorithms were either engineered for contrived problems and relied on
strong cryptographic assumptions [Beimel, Kaplan, Mansour, Nissim, Saranurak,
Stemmer; STOC '22], or worked for problems whose inputs are not explicitly
given but are accessed through oracle calls [Bateni, Esfandiari, Fichtenberger,
Henzinger, Jayaram, Mirrokni, Wiese; SODA '23].
  As a byproduct, we also provide a separation between incremental and
decremental algorithms for the triangle detection problem: we show a
decremental algorithm with $\tilde{O}(n^{\omega})$ total update time, while
every incremental algorithm requires $n^{3-o(1)}$ total update time, assuming
the OMv hypothesis. To our knowledge this is the first separation of this kind.

</details>


### [401] [$\ell_2/\ell_2$ Sparse Recovery via Weighted Hypergraph Peeling](https://arxiv.org/abs/2510.20361)
*Nick Fischer,Vasileios Nakos*

Main category: cs.DS

TL;DR: 该研究提出了一种新的算法，可以在O((k/ε) log n)时间内，以(1+ε)的近似因子，恢复长度为n的向量的最佳k稀疏近似。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是改进现有稀疏近似算法的运行时间，特别是Nakos和Song在STOC '19上提出的算法，旨在将其运行时间缩短一个log n的因子，并使其在多种参数下达到最优。

Method: 该研究使用一种非自适应的线性草图，具有O((k/ε) log n)行和O(log n)列稀疏度。该算法基于一种名为“加权超图剥离”的新技术，该技术将已知的超图剥离过程扩展到具有（可能相关）权重和节点的边。

Result: 该研究的算法将运行时间从[Nakos, Song; STOC '19]的最快已知草图的O((k/ε) log^2 n) 改进为O((k/ε) log n)，并且在多种参数下是最优的。

Conclusion: 该研究提出了一种简单且实用的算法，用于k稀疏近似，并将运行时间提高了一个数量级。该算法基于一种新颖的加权超图剥离技术，有望在实践中得到应用。

Abstract: We demonstrate that the best $k$-sparse approximation of a length-$n$ vector
can be recovered within a $(1+\epsilon)$-factor approximation in
$O((k/\epsilon) \log n)$ time using a non-adaptive linear sketch with
$O((k/\epsilon) \log n)$ rows and $O(\log n)$ column sparsity. This improves
the running time of the fastest-known sketch [Nakos, Song; STOC '19] by a
factor of $\log n$, and is optimal for a wide range of parameters.
  Our algorithm is simple and likely to be practical, with the analysis built
on a new technique we call weighted hypergraph peeling. Our method naturally
extends known hypergraph peeling processes (as in the analysis of Invertible
Bloom Filters) to a setting where edges and nodes have (possibly correlated)
weights.

</details>


### [402] [From Incremental Transitive Cover to Strongly Polynomial Maximum Flow](https://arxiv.org/abs/2510.20368)
*Daniel Dadush,James B. Orlin,Aaron Sidford,László A. Végh*

Main category: cs.DS

TL;DR: 本文提出了解决结构化网络最大流问题的更快的强多项式时间算法，包括最大二分图匹配和具有给定树分解宽度图的最大流问题。


<details>
  <summary>Details</summary>
Motivation: 提供解决最大流问题的更快的强多项式时间算法，特别是针对结构化网络。

Method: 通过加强和高效实现Orlin（STOC 2013）的最大流算法，开发了一个通用框架，将具有任意容量的最大流问题归约为具有多项式有界容量的最大流问题序列以及动态维护传递闭包的子集（增量传递闭包），并利用了近期弱多项式时间的最大流算法和增量传递闭包数据结构。

Result: 实现了最大二分图匹配的$n^{\omega+o(1)}$时间强多项式时间算法，以及具有给定树分解宽度$W$的图的最大流问题的$m^{1+o(1)}W$时间算法。

Conclusion: 通过改进现有算法和开发新的数据结构，在特定类型的网络上显著提高了最大流问题的计算效率。

Abstract: We provide faster strongly polynomial time algorithms solving maximum flow in
structured $n$-node $m$-arc networks. Our results imply an $n^{\omega +
o(1)}$-time strongly polynomial time algorithms for computing a maximum
bipartite $b$-matching where $\omega$ is the matrix multiplication constant.
Additionally, they imply an $m^{1 + o(1)} W$-time algorithm for solving the
problem on graphs with a given tree decomposition of width $W$.
  We obtain these results by strengthening and efficiently implementing an
approach in Orlin's (STOC 2013) state-of-the-art $O(mn)$ time maximum flow
algorithm. We develop a general framework that reduces solving maximum flow
with arbitrary capacities to (1) solving a sequence of maximum flow problems
with polynomial bounded capacities and (2) dynamically maintaining a
size-bounded supersets of the transitive closure under arc additions; we call
this problem \emph{incremental transitive cover}. Our applications follow by
leveraging recent weakly polynomial, almost linear time algorithms for maximum
flow due to Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva (FOCS 2022) and Brand,
Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva, Sidford (FOCS 2023), and by
developing incremental transitive cover data structures.

</details>


### [403] [Compact representations of pattern-avoiding permutations](https://arxiv.org/abs/2510.20382)
*László Kozma,Michal Opler*

Main category: cs.DS

TL;DR: 该论文设计了一种数据结构，用于以渐近最优的空间复杂度 O(n lg s_π) 存储和查询避免任意固定模式 π 的大小为 n 的排列 τ，同时支持 O(1) 时间的 τ(i) 和 τ⁻¹(i) 查询。


<details>
  <summary>Details</summary>
Motivation: 研究组合学和理论计算机科学中的模式避免排列，旨在设计一种更优的数据结构来存储和查询这些排列。

Method: 设计了一种新的数据结构，能够以 O(n lg s_π) 的空间复杂度存储避免任意固定模式 π 的排列，并支持 O(1) 时间的 τ(i) 和 τ⁻¹(i) 查询。此外，该结构还扩展支持更复杂的几何查询，如在 O(lg lg n) 时间内进行矩形范围计数。

Result: 所设计的数据结构在空间和查询时间上均优于现有技术，能够有效处理模式避免排列。特别是在 O(1) 时间内支持 τ(i) 和 τ⁻¹(i) 查询，并能以 O(lg lg n) 时间处理矩形范围计数。对于有界树宽的排列类，空间开销进一步降低，成为简洁数据结构。

Conclusion: 该研究成功设计出一种高效的数据结构，能够以极优的空间和时间复杂度处理模式避免排列及其相关的几何查询，显著优于现有方法，并解决了特定问题中的下界限制。

Abstract: Pattern-avoiding permutations are a central object of study in both
combinatorics and theoretical computer science. In this paper we design a data
structure that can store any size-$n$ permutation $\tau$ that avoids an
arbitrary (and unknown) fixed pattern $\pi$ in the asymptotically optimal $O(n
\lg{s_\pi})$ bits, where $s_\pi$ is the Stanley-Wilf limit of $\pi$. Our data
structure supports $\tau(i)$ and $\tau^{-1}(i)$ queries in $O(1)$ time,
sidestepping the lower bound of Golynski (SODA 2009) that holds for general
permutations. Comparable results were previously known only in more restricted
cases, e.g., when $\tau$ is separable, which means avoiding the patterns 2413
and 3142.
  We also extend our data structure to support more complex geometric queries
on pattern-avoiding permutations (or planar point sets) such as rectangle range
counting in $O(\lg\lg{n})$ time. This result circumvents the lower bound of
$\Omega{(\lg{n}/\lg\lg{n})}$ by P\u{a}tra\c{s}cu (STOC 2007) that holds in the
general case. For bounded treewidth permutation classes (which include the
above-mentioned separable class), we further reduce the space overhead to a
lower order additive term, making our data structure succinct. This extends and
improves results of Chakraborty et al. (ISAAC 2024) that were obtained for
separable permutations via different techniques. All our data structures can be
constructed in linear time.

</details>


### [404] [Parallel $(1+ε)$-Approximate Multi-Commodity Mincost Flow in Almost Optimal Depth and Work](https://arxiv.org/abs/2510.20456)
*Bernhard Haeupler,Yonggang Jiang,Yaowei Long,Thatchaphol Saranurak,Shengzhe Wang*

Main category: cs.DS

TL;DR: 提出了一种并行算法，用于在具有边和顶点容量及成本的无向图上计算(1+ε)-近似最小费用流，实现了近乎最优的工作量和深度。


<details>
  <summary>Details</summary>
Motivation: 之前的算法在工作量接近最优时，深度要求较高，本研究旨在改进这一点，并推广到更一般化的 mincost flow 问题。

Method: 构建了具有长度约束、拥塞约束和步数约束的流压缩（flow shortcuts），并开发了用于顶点容量的顶点扩展分解算法。

Result: 在 ε > 1/polylog(m) 时，实现了 O(m) 的工作量和 O(1) 的深度，优于以往算法。此外，将该算法扩展到 k-商品最小费用流问题，实现了 O(mk) 的工作量和 O(1) 的深度。

Conclusion: 该算法在并行计算近似最小费用流方面取得了近乎最优的性能，并成功扩展到更复杂的多商品流问题，是该领域的重要进展。

Abstract: We present a parallel algorithm for computing $(1+\epsilon)$-approximate
mincost flow on an undirected graph with $m$ edges, where capacities and costs
are assigned to both edges and vertices. Our algorithm achieves $\hat{O}(m)$
work and $\hat{O}(1)$ depth when $\epsilon > 1/\mathrm{polylog}(m)$, making
both the work and depth almost optimal, up to a subpolynomial factor.
  Previous algorithms with $\hat{O}(m)$ work required $\Omega(m)$ depth, even
for special cases of mincost flow with only edge capacities or max flow with
vertex capacities. Our result generalizes prior almost-optimal parallel
$(1+\epsilon)$-approximation algorithms for these special cases, including
shortest paths [Li, STOC'20] [Andoni, Stein, Zhong, STOC'20] [Rozhen, Haeupler,
Marinsson, Grunau, Zuzic, STOC'23] and max flow with only edge capacities
[Agarwal, Khanna, Li, Patil, Wang, White, Zhong, SODA'24].
  Our key technical contribution is the first construction of
length-constrained flow shortcuts with $(1+\epsilon)$ length slack,
$\hat{O}(1)$ congestion slack, and $\hat{O}(1)$ step bound. This provides a
strict generalization of the influential concept of
$(\hat{O}(1),\epsilon)$-hopsets [Cohen, JACM'00], allowing for additional
control over congestion. Previous length-constrained flow shortcuts [Haeupler,
Hershkowitz, Li, Roeyskoe, Saranurak, STOC'24] incur a large constant in the
length slack, which would lead to a large approximation factor. To enable our
flow algorithms to work under vertex capacities, we also develop a
close-to-linear time algorithm for computing length-constrained vertex expander
decomposition.
  Building on Cohen's idea of path-count flows [Cohen, SICOMP'95], we further
extend our algorithm to solve $(1+\epsilon)$-approximate $k$-commodity mincost
flow problems with almost-optimal $\hat{O}(mk)$ work and $\hat{O}(1)$ depth,
independent of the number of commodities $k$.

</details>


### [405] [Provably Small Portfolios for Multiobjective Optimization with Application to Subsidized Facility Location](https://arxiv.org/abs/2510.20555)
*Swati Gupta,Jai Moondra,Mohit Singh*

Main category: cs.DS

TL;DR: 本研究提出了一种称为“投资组合”的解决方案集概念，旨在为多目标优化问题提供一个可证明的小规模近似解集。该投资组合能为给定目标函数类中的每一个目标函数找到一个近似最优解，从而帮助决策者理解不同目标权衡的影响。研究为两类目标函数类（锥组合和单调插值目标函数类）提供了构造投资组合的算法，并以公平补贴设施选址问题为例进行了应用，展示了该方法在减少美国医疗资源匮乏地区方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多目标优化问题（如设施选址和公交路线规划）在优化多个利益相关者的优先级时变得更加复杂。这些问题通常被建模为具有无限目标函数类，例如在固定域内由可行解引起的所有组距离上的Lp范数。传统方法显式地平衡“公平性”（最小-最大）和“效率”（最小-和）目标。然而，这种建模选择产生的解的结构可能大不相同。本研究旨在提出一种解决方案中心的方法，通过构建一个可证明的小规模解决方案集（投资组合）来解决这一挑战。

Method: 本研究提出了一种“解决方案中心”的方法，引入了一个名为“投资组合”的可证明的小规模解决方案集。对于给定的目标函数类 C，投资组合中的每一个解决方案都能为 C 中的目标函数提供一个 α-近似。研究人员为两类目标函数类提供了算法：1）锥组合类 C = {∑ λj hj : λ ≥ 0}；2）在最小-和效率目标（∑ hj）和最小-最大公平目标（maxj hj）之间单调插值的任何类 C。Lp范数和Top-ℓ范数是第二类的例子。

Result: 研究为两类目标函数类（锥组合和单调插值目标函数类）提供了构造投资组合的算法。将此方法应用于公平补贴设施选址（FSFL）问题，该问题旨在解决因药店关闭而导致的医疗沙漠危机。研究开发了一种新颖的双标准近似算法，并在减少美国各州的医疗沙漠方面取得了显著成效。

Conclusion: 本研究提出的投资组合概念提供了一种有效的方法来处理复杂的多目标优化问题，特别是那些涉及公平性和效率之间权衡的问题。通过提供一个代表性的解决方案子集，决策者可以更好地理解和管理不同利益相关者的需求。在公平补贴设施选址问题上的成功应用证明了该方法在解决实际社会经济挑战方面的实用性和有效性。

Abstract: Many multiobjective real-world problems, such as facility location and bus
routing, become more complex when optimizing the priorities of multiple
stakeholders. These are often modeled using infinite classes of objectives,
e.g., $L_p$ norms over group distances induced by feasible solutions in a fixed
domain. Traditionally, the literature has considered explicitly balancing
`equity' (or min-max) and `efficiency' (or min-sum) objectives to capture this
trade-off. However, the structure of solutions obtained by such modeling
choices can be very different. Taking a solution-centric approach, we introduce
the concept of provably small set of solutions $P$, called a {\it portfolio},
such that for every objective function $h(\cdot)$ in the given class
$\mathbf{C}$, there exists some solution in $P$ which is an
$\alpha$-approximation for $h(\cdot)$. Constructing such portfolios can help
decision-makers understand the impact of balancing across multiple objectives.
  Given a finite set of base objectives $h_1, \ldots, h_N$, we give provable
algorithms for constructing portfolios for (1) the class of conic combinations
$\mathbf{C} = \{\sum_{j \in [N]}\lambda_j h_j: \lambda \ge 0\}$ and for (2) any
class $\mathbf{C}$ of functions that interpolates monotonically between the
min-sum efficiency objective (i.e., $h_1 + \ldots + h_N$) and the min-max
equity objective (i.e., $\max_{j \in [N]} h_j$). Examples of the latter are
$L_p$ norms and top-$\ell$ norms. As an application, we study the Fair
Subsidized Facility Location (FSFL) problem, motivated by the crisis of medical
deserts caused due to pharmacy closures. FSFL allows subsidizing facilities in
underserved areas using revenue from profitable locations. We develop a novel
bicriteria approximation algorithm and show a significant reduction of medical
deserts across states in the U.S.

</details>


### [406] [A Deterministic Polylogarithmic Competitive Algorithm for Matching with Delays](https://arxiv.org/abs/2510.20588)
*Marc Dufay,Roger Wattenhofer*

Main category: cs.DS

TL;DR: 为在线最小费用完美匹配延迟问题设计了一个新的算法，将竞争力从O(m^0.59)提高到O(log^5 m)，并且是确定性的。


<details>
  <summary>Details</summary>
Motivation: 解决在线最小费用完美匹配延迟（MPMD）问题，该问题在度量空间中具有不同到达时间的请求，目标是最小化匹配对之间的距离和请求未匹配的时间。现有算法在无限或未知度量空间上的竞争力较差（O(m^0.59)），与已知下限（Ω(log m / log log m)）相差甚远。

Method: 提出了一种确定性的、不需要预先知道度量空间或请求数量m的算法。

Result: 该算法实现了O(log^5 m)的竞争力，这是一个指数级的改进，并且仅比已知的下限（Ω(log m / log log m)）有对数多项式级别的差距。

Conclusion: 所提出的算法在MPMD问题上取得了显著的进展，其竞争力相比现有算法有了指数级的提升，并且非常接近理论下限。

Abstract: In the online Min-cost Perfect Matching with Delays (MPMD) problem, $m$
requests in a metric space are submitted at different times by an adversary.
The goal is to match all requests while (i) minimizing the sum of the distances
between matched pairs as well as (ii) how long each request remained unmatched
after it appeared.
  While there exist almost optimal algorithms when the metric space is finite
and known a priori, this is not the case when the metric space is infinite or
unknown. In this latter case, the best known algorithm, due to Azar and
Jacob-Fanani, has competitiveness $\mathcal{O}(m^{0.59})$ which is
exponentially worse than the best known lower bound of $\Omega(\log m / \log
\log m)$ by Ashlagi et al.
  We present a $\mathcal{O}(\log^5 m)$-competitive algorithm for the MPMD
problem. This algorithm is deterministic and does not need to know the metric
space or $m$ in advance. This is an exponential improvement over previous
results and only a polylogarithmic factor away from the lower bound.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [407] [Building Network Digital Twins Part II: Real-Time Adaptive PID for Enhanced State Synchronization](https://arxiv.org/abs/2510.20753)
*John Sengendo,Fabrizio Granelli*

Main category: cs.ET

TL;DR: 通过集成自适应PID控制器，本文提出了一种改进的网络数字孪生（NDTs）框架，以应对动态移动网络中的实时流量同步挑战，并在用户界面上展示了其性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于移动网络日益动态和异构，以及海量设备的连接，实时复制流量并使网络数字孪生（NDTs）与物理网络同步成为一项挑战，因此有必要开发实时自适应机制来弥合这一差距。

Method: 在第二部分，我们实现了一个集成了自适应比例-积分-微分（PID）控制器的新颖框架，以动态地改进同步。此外，通过一个交互式用户界面，我们增强的方法的结果证明了实时流量同步得到了改进。

Result: 通过交互式用户界面展示的实验结果表明，所提出的方法在实时流量同步方面取得了改进。

Conclusion: 所提出的集成自适应PID控制器的框架能够动态地改进NDTs与物理网络的同步，解决了当前移动网络中实时流量同步的挑战。

Abstract: As we evolve towards more heterogeneous and cutting-edge mobile networks,
Network Digital Twins (NDTs) are proving to be a promising paradigm in solving
challenges faced by network operators, as they give a possibility of
replicating the physical network operations and testing scenarios separately
without interfering with the live network. However, with mobile networks
becoming increasingly dynamic and heterogeneous due to massive device
connectivity, replicating traffic and having NDTs synchronized in real-time
with the physical network remains a challenge, thus necessitating the need to
develop real-time adaptive mechanisms to bridge this gap. In this part II of
our work, we implement a novel framework that integrates an adaptive
Proportional-Integral-Derivative (PID) controller to dynamically improve
synchronization. Additionally, through an interactive user interface, results
of our enhanced approach demonstrate an improvement in real-time traffic
synchronization.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [408] [SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks](https://arxiv.org/abs/2510.19829)
*Meghna Roy Chowdhury,Yi Ding,Shreyas Sen*

Main category: eess.SP

TL;DR: SSL-SE-EEG框架通过将自监督学习与Squeeze-Excitation网络相结合，将EEG信号转化为图像表示，提高了特征提取和噪声鲁棒性，并减少了对标记数据的依赖，在多个数据集上实现了最先进的准确率，适用于实时BCI应用。


<details>
  <summary>Details</summary>
Motivation: EEG在脑机接口和神经诊断中至关重要，但面临噪声、数据缺失和高昂标注成本的挑战。

Method: SSL-SE-EEG框架将EEG信号转化为2D图像表示，并利用自监督学习和Squeeze-Excitation网络进行特征提取。

Result: 在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上取得了最先进的准确率（MindBigData上为91%，TUH-AB上为85%）。

Conclusion: SSL-SE-EEG通过实现低功耗、可扩展的EEG处理，为生物医学信号分析、神经工程和下一代BCI提供了一种有前景的解决方案。

Abstract: Electroencephalography (EEG) plays a crucial role in brain-computer
interfaces (BCIs) and neurological diagnostics, but its real-world deployment
faces challenges due to noise artifacts, missing data, and high annotation
costs. We introduce SSL-SE-EEG, a framework that integrates Self-Supervised
Learning (SSL) with Squeeze-and-Excitation Networks (SE-Nets) to enhance
feature extraction, improve noise robustness, and reduce reliance on labeled
data. Unlike conventional EEG processing techniques, SSL-SE-EEG} transforms EEG
signals into structured 2D image representations, suitable for deep learning.
Experimental validation on MindBigData, TUH-AB, SEED-IV and BCI-IV datasets
demonstrates state-of-the-art accuracy (91% in MindBigData, 85% in TUH-AB),
making it well-suited for real-time BCI applications. By enabling low-power,
scalable EEG processing, SSL-SE-EEG presents a promising solution for
biomedical signal analysis, neural engineering, and next-generation BCIs.

</details>


### [409] [Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals](https://arxiv.org/abs/2510.19832)
*Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee*

Main category: eess.SP

TL;DR: 通过先进的机器学习和信息丰富的EEG特征提取，我们实现了实时、高精度的非侵入性脑机接口（BCI）的神经解码，能够部署在便携式边缘设备上，为有严重运动或言语障碍的个体恢复沟通。


<details>
  <summary>Details</summary>
Motivation: 旨在克服非侵入性脑电图（EEG）在信号信噪比和空间分辨率方面的限制，以实现高精度的神经解码，并最终应用于便携式边缘设备，以支持实时通信。

Method: 收集了32通道EEG数据集，对15名参与者进行了想象手写任务。对信号进行了带通滤波和伪影子空间重建预处理，并提取了85个时间域、频域和图形域的特征。开发了一种名为EEdGeNet的混合架构，该架构集成了时间卷积网络（TCN）和多层感知机（MLP）。

Result: 所提出的EEdGeNet系统在NVIDIA Jetson TX2上实现了89.83%的准确率，每个字符的延迟为914.18毫秒。通过仅选择10个关键特征，延迟减少了4.5倍（达到202.6毫秒），准确率仅下降不到1%。

Conclusion: 该研究为实现准确、低延迟、完全便携式且支持实时通信的非侵入性BCI铺平了道路。

Abstract: Brain-computer interfaces (BCIs) offer a pathway to restore communication for
individuals with severe motor or speech impairments. Imagined handwriting
provides an intuitive paradigm for character-level neural decoding, bridging
the gap between human intention and digital communication. While invasive
approaches such as electrocorticography (ECoG) achieve high accuracy, their
surgical risks limit widespread adoption. Non-invasive electroencephalography
(EEG) offers safer and more scalable alternatives but suffers from low
signal-to-noise ratio and spatial resolution, constraining its decoding
precision. This work demonstrates that advanced machine learning combined with
informative EEG feature extraction can overcome these barriers, enabling
real-time, high-accuracy neural decoding on portable edge devices. A 32-channel
EEG dataset was collected from fifteen participants performing imagined
handwriting. Signals were preprocessed with bandpass filtering and artifact
subspace reconstruction, followed by extraction of 85 time-, frequency-, and
graphical-domain features. A hybrid architecture, EEdGeNet, integrates a
Temporal Convolutional Network with a multilayer perceptron trained on the
extracted features. When deployed on an NVIDIA Jetson TX2, the system achieved
89.83 percent accuracy with 914.18 ms per-character latency. Selecting only ten
key features reduced latency by 4.5 times to 202.6 ms with less than 1 percent
loss in accuracy. These results establish a pathway for accurate, low-latency,
and fully portable non-invasive BCIs supporting real-time communication.

</details>


### [410] [MATLAB-Simulated Dataset for Automatic Modulation Classification in Wireless Fading Channels](https://arxiv.org/abs/2510.19985)
*M. M. Sadman Shafi,Tasnia Siddiqua Ahona,Ashraful Islam Mridha*

Main category: eess.SP

TL;DR: 本文介绍了一个用于无线信号调制分类的合成数据集，该数据集包含在瑞利和莱斯衰落信道中生成的各种调制信号（BPSK、QPSK、16-QAM、64-QAM、256-QAM），并考虑了实际传播场景的多种影响因素，旨在为机器学习模型提供一个有价值的基准。


<details>
  <summary>Details</summary>
Motivation: 为了解决认知无线电、自适应通信和频谱分析等领域在动态信道且未知发射机参数情况下进行精确调制分类的核心挑战。

Method: 本文通过MATLAB生成了包含五种数字调制方案（BPSK、QPSK、16-QAM、64-QAM、256-QAM）的合成信号，并将其置于瑞利和莱斯衰落信道中，同时添加了其他影响因素以增加真实性。对这些信号提取了包括统计、时域、频域、频谱图、谱相关和图像处理（BRISK、MSER、GLCM）在内的多种特征。数据集组织在10个CSV文件中，覆盖了两种信道类型和五种采样频率（1 MHz、10 MHz、100 MHz、500 MHz、1 GHz）。此外，还提供了用于信号生成和特征提取的MATLAB脚本。

Result: 生成了一个包含在两种信道模型（瑞利和莱斯）和五种采样频率下的五种数字调制信号的合成数据集。数据集包含了多种信号特征，并提供了生成和特征提取的MATLAB脚本，支持在不同场景下对机器学习模型进行评估。

Conclusion: 本文提出的数据集为无线调制分类、信号识别和无线通信研究中的机器学习模型开发和评估提供了一个有价值的基准，有助于应对实际通信场景中的挑战。

Abstract: Accurate modulation classification is a core challenge in cognitive radio,
adaptive communications, spectrum analysis, and related domains, especially
under dynamic channels without transmitter knowledge. To address this need,
this article presents a labeled synthetic dataset designed for wireless
modulation classification under realistic propagation scenarios. The signals
were generated in MATLAB by modulating randomly generated bitstreams using five
digital modulation schemes: BPSK, QPSK, 16-QAM, 64-QAM, and 256-QAM. These
signals were then transmitted through Rayleigh and Rician fading channels with
standardized parameters, along with additional impairments to enhance realism
and diversity. Each modulated signal contains 1000 symbols. A comprehensive set
of features was extracted from the signals, encompassing statistical,
time-domain, frequency-domain, spectrogram-based, spectral correlation-based,
and image-processing-based descriptors such as BRISK, MSER, and GLCM. The
dataset is organized into 10 CSV files covering two channel types (Rayleigh and
Rician) across five sampling frequencies: 1 MHz, 10 MHz, 100 MHz, 500 MHz, and
1 GHz. To facilitate reproducibility and encourage further experimentation, the
MATLAB scripts used for signal generation and feature extraction are also
provided. This dataset serves as a valuable benchmark for developing and
evaluating machine learning models in modulation classification, signal
identification, and wireless communication research.

</details>


### [411] [NanoHydra: Energy-Efficient Time-Series Classification at the Edge](https://arxiv.org/abs/2510.20038)
*Cristian Cioflan,Jose Fonseca,Xiaying Wang,Luca Benini*

Main category: eess.SP

TL;DR: NanoHydra是一种用于极端边缘设备的TinyML时间序列分类方法，它使用轻量级的二进制随机卷积核来提取特征，并在GAP9微控制器上实现了高达94.47%的分类准确率，能耗仅为7.69 uJ/次，适用于智能可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上实现高效的TinyML时间序列分类，以实现用户隐私保护和实时预测，同时延长电池寿命。

Method: 提出了一种名为NanoHydra的方法，该方法利用轻量级的二进制随机卷积核从数据流中提取特征，并利用GAP9微控制器的多核并行处理能力。

Result: 在ECG5000数据集上实现了高达94.47%的分类准确率，分类1秒长的ECG信号仅需0.33毫秒，能耗为7.69 uJ/次，比现有技术效率高18倍。

Conclusion: NanoHydra是一种高效且节能的TinyML时间序列分类方法，非常适合电池供电的智能可穿戴设备，可提供超过四年的设备使用寿命。

Abstract: Time series classification (TSC) on extreme edge devices represents a
stepping stone towards intelligent sensor nodes that preserve user privacy and
offer real-time predictions. Resource-constrained devices require efficient
TinyML algorithms that prolong the device lifetime of battery-operated devices
without compromising the classification accuracy. We introduce NanoHydra, a
TinyML TSC methodology relying on lightweight binary random convolutional
kernels to extract meaningful features from data streams. We demonstrate our
system on the ultra-low-power GAP9 microcontroller, exploiting its eight-core
cluster for the parallel execution of computationally intensive tasks. We
achieve a classification accuracy of up to 94.47% on ECG5000 dataset,
comparable with state-of-the-art works. Our efficient NanoHydra requires only
0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy
consumption of 7.69 uJ per inference, 18x more efficient than the
state-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a
device lifetime of over four years.

</details>


### [412] [Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios](https://arxiv.org/abs/2510.20067)
*Maximilian H. V. Tillmann,Avinash Kankari,Carsten Bockelmann,Armin Dekorsy*

Main category: eess.SP

TL;DR: 本文提出了一种用于多用户场景下联合任务执行和数据重建的语义通信系统，并通过最大化互信息来研究两者之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信研究主要集中在任务执行或数据重建，或两者结合。本文旨在解决多用户场景下同时进行任务执行和数据重建的问题。

Method: 提出一个语义通信系统，将联合任务执行和数据重建的问题形式化为最大化互信息。通过构建一个结合任务执行和数据重建的联合目标函数（凸组合），并分析其与互信息最大化目标的关系，特别是SSIM损失与互信息最大化在数据重建上的联系，以及在资源恒定的情况下，调整重建目标权重对任务执行和数据重建性能的影响。

Result: 在特定假设下，SSIM损失可以从互信息最大化目标导出，这考虑了人类视觉感知。此外，证明了在恒定资源消耗下，增加重建目标的权重至多到某个点，可以基本保持任务执行性能不变，同时显著提高数据重建质量。

Conclusion: 本文提出的语义通信系统能够有效地处理多用户场景下的联合任务执行和数据重建问题。通过优化目标函数和分析不同权重下的性能表现，为该系统在实际应用中的参数调整提供了指导。

Abstract: Semantic communication has gained significant attention with the advances in
machine learning. Most semantic communication works focus on either task
execution or data reconstruction, with some recent works combining the two. In
this work, we propose a semantic communication system for concurrent task
execution and data reconstruction for a multi-user scenario, which we formulate
as the maximization of mutual information. To investigate the trade-off between
the two objectives, we formulate a joint objective as a convex combination of
task execution and data reconstruction. We show that under specific
assumptions, the \ac{SSIM} loss can be obtained from the mutual information
maximization objective for data reconstruction, which takes human visual
perception into account. Furthermore, for constant resource use, we show that
by increasing the weight of the reconstruction objective up to a certain point,
the task execution performance can be kept nearly constant, while the data
reconstruction can be significantly improved.

</details>


### [413] [RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling](https://arxiv.org/abs/2510.20088)
*Tawfik Osman,Aditya S. Shekhawat,Abhradeep Roy,Georgios C. Trichopoulos,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 本研究介绍了在FR2毫米波频段下，使用RIS增强O-RAN 5G系统的设计、实现和评估。


<details>
  <summary>Details</summary>
Motivation: 为了增强信号覆盖和/或提高用户设备的信噪比，本研究提出了一种RIS辅助的O-RAN 5G系统。

Method: 设计了一个包含1024个单元（32x32）的1比特RIS，工作在28 GHz频段，并采用模块化、可扩展的平铺架构。研究还展示了如何利用O-RAN E2接口动态控制RIS配置，以及开发了两种UE移动性管理算法，用于联合跟踪和自适应RIS和UE波束。

Result: 在室内和室外环境中进行的现场试验表明，部署的RIS显著提高了接收信号功率，室内增益为9-20 dB，室外增益为6-18 dB。

Conclusion: 本研究的结果表明，将RIS集成到O-RAN系统中在实践上是可行的，能够增强下一代蜂窝网络的覆盖范围、移动性支持和链路可靠性。

Abstract: Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves
to desired directions to enhance signal coverage and/or improve signal-to-noise
ratio (SNR) at the user equipment (UE). We present the design, implementation,
and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2
millimeter wave (mmWave) frequency band. We first introduce the design of 1,024
element (32 $\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a
modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2
interface can be leveraged to dynamically control RIS configurations without
modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G
system, we conducted extensive field trials in both indoor and outdoor
environments. The results of the O-RAN link coverage trials show that the
deployed RIS provides substantial received signal power gains, ranging from 9
to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively.
Handling UE mobility in RIS-assisted systems is challenging due to the need for
joint RIS and UE beam management. For that, we develop two UE mobility
management algorithms and evaluate them in real-time operation using the RIS
O-RAN testbed. These algorithms leverage the received signal power at the UE to
jointly track and adapt the RIS and UE beams in real time as the UE moves. The
findings draw important insights into the practical feasibility of integrating
RIS into O-RAN systems to enhance coverage, mobility support, and link
reliability in next-generation cellular networks.

</details>


### [414] [Signal Design for OTFS Dual-Functional Radar and Communications with Imperfect CSI](https://arxiv.org/abs/2510.20112)
*Borui Du,Yumeng Zhang,Christos Masouros,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文提出了一种用于双功能雷达通信（DFRC）的OTFS信号设计方法，通过优化雷达和通信指标，实现了性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有OTFS在DFRC中的应用未能充分挖掘其潜力，尤其在信号设计方面存在不足。

Method: 1. 提出了一种将雷达和通信指标相结合的优化问题，其中雷达指标为模糊函数的综合旁瓣电平（ISL），通信指标为考虑信道估计误差的信道容量下界。 2. 采用交替优化框架来求解该优化问题。

Result: 仿真结果表明，所提出的信号设计在ISL抑制方面相比传统方案至少提高了9.44 dB，在SINR方面至少提高了4.82 dB，显著改善了雷达和通信的性能权衡区域。

Conclusion: 所提出的OTFS信号设计方法能够有效提升DFRC系统的雷达和通信性能。

Abstract: Orthogonal time frequency space (OTFS) offers significant advantages in
managing mobility for both wireless sensing and communication systems, making
it a promising candidate for dual-functional radar-communication (DFRC).
However, the optimal signal design that fully exploits OTFS's potential in DFRC
has not been sufficiently explored. This paper addresses this gap by
formulating an optimization problem for signal design in DFRC-OTFS,
incorporating both pilot-symbol design for channel estimation and data-power
allocation. Specifically, we employ the integrated sidelobe level (ISL) of the
ambiguity function as a radar metric, accounting for the randomness of the data
symbols alongside the deterministic pilot symbols. For communication, we derive
a channel capacity lower bound metric that considers channel estimation errors
in OTFS. We maximize the weighted sum of sensing and communication metrics and
solve the optimization problem via an alternating optimization framework.
Simulations indicate that the proposed signal significantly improves the
sensing-communication performance region compared with conventional signal
schemes, achieving at least a 9.44 dB gain in ISL suppression for sensing, and
a 4.82 dB gain in the signal-to-interference-plus-noise ratio (SINR) for
communication.

</details>


### [415] [Active Localization of Close-range Adversarial Acoustic Sources for Underwater Data Center Surveillance](https://arxiv.org/abs/2510.20122)
*Adnan Abdullah,David Blow,Sara Rampazzi,Md Jahidul Islam*

Main category: eess.SP

TL;DR: 提出了一种用于定位和跟踪水下数据中心附近声学攻击源的框架，使用异构接收器（固定和移动水听器）和一种称为 LC-MAP 的新颖定位算法，结合 UKF 过滤器，实现了亚米级的定位精度和超过 90% 的成功率。


<details>
  <summary>Details</summary>
Motivation: 水下数据中心虽然有自然冷却和物理安全优势，但容易受到声学注入攻击，损害数据完整性和可用性。因此，需要一种方法来监视和跟踪这些攻击。

Method: 提出了一种异构接收器配置（固定水听器和机器人上的移动水听器），并提出了一种称为 LC-MAP（Locus-Conditioned Maximum A-Posteriori）的方案，用于生成声学信息和几何一致的先验，并将其集成到无迹卡尔曼滤波 (UKF) 流程中，以联合进行 TDOA 和 FDOA 滤波。

Result: 该框架能够实时可靠地估计攻击源的 3D 位置和速度，实现了亚米级的定位精度和超过 90% 的成功率，并且收敛时间比基线方法缩短了近一半。

Conclusion: 这项研究提出了一种面向几何、实时的声学威胁定位方法，提高了水下基础设施的自主监视能力。

Abstract: Underwater data infrastructures offer natural cooling and enhanced physical
security compared to terrestrial facilities, but are susceptible to acoustic
injection attacks that can disrupt data integrity and availability. This work
presents a comprehensive surveillance framework for localizing and tracking
close-range adversarial acoustic sources targeting offshore infrastructures,
particularly underwater data centers (UDCs). We propose a heterogeneous
receiver configuration comprising a fixed hydrophone mounted on the facility
and a mobile hydrophone deployed on a dedicated surveillance robot. While using
enough arrays of static hydrophones covering large infrastructures is not
feasible in practice, off-the-shelf approaches based on time difference of
arrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to
generalize for this dynamic configuration. To address this, we formulate a
Locus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically
informed and geometrically consistent priors, ensuring a physically plausible
initial state for a joint TDOA-FDOA filtering. We integrate this into an
unscented Kalman filtering (UKF) pipeline, which provides reliable convergence
under nonlinearity and measurement noise. Extensive Monte Carlo analyses,
Gazebo-based physics simulations, and field trials demonstrate that the
proposed framework can reliably estimate the 3D position and velocity of an
adversarial acoustic attack source in real time. It achieves sub-meter
localization accuracy and over 90% success rates, with convergence times nearly
halved compared to baseline methods. Overall, this study establishes a
geometry-aware, real-time approach for acoustic threat localization, advancing
autonomous surveillance capabilities of underwater infrastructures.

</details>


### [416] [Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception](https://arxiv.org/abs/2510.20140)
*Jiangong Chen,Xia Lei,Kaitao Meng,Kawon Han,Yuchen Zhang,Christos Masouros,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 通过利用已知散射体，提出一种位置欺骗（LD）方案，通过向散射体提供比目标更高的探测功率，欺骗窃听者，使其误判散射体为目标。该方案在不了解窃听者信息的情况下实现欺骗，并通过加权和最大化通信、感知和感知安全性能的权衡来实现。


<details>
  <summary>Details</summary>
Motivation: 在近场集成感知与通信（ISAC）场景中，为了应对潜在的窃听者对感知能力构成威胁的问题，需要一种能够增强感知安全性的方法。

Method: 提出一种位置欺骗（LD）方案，通过向场景中已知的散射体提供比目标更高的探测功率，欺骗窃听者。该方案利用分数规划（FP）和半定松弛（SDR）来优化通信、感知和感知安全性能之间的权衡。使用克拉美-罗界（CRB）和均方误差（MSE）来评估安全性，并使用Kullback-Leibler散度（KLD）间隙来量化对窃听者感知性能的影响。

Result: 所提出的LD方案能够灵活地根据性能要求调整波束成形策略，以实现通信、感知和感知安全性能之间的三向权衡。仿真结果表明，该方案能够显著增强窃听者端的杂波信号强度，从而导致对实际目标的混淆甚至漏检。

Conclusion: 该研究提出了一种用于近场ISAC场景的位置欺骗（LD）方案，通过巧妙地利用已知散射体来增强感知安全性。该方案在不依赖窃听者信息的情况下，成功地欺骗了具有感知能力的窃听者，使其误判散射体为目标。通过优化权衡通信、感知和感知安全性能，该方案实现了灵活的性能调整，并在实际应用中展示了其有效性。

Abstract: In this paper, we explore sensing security in near-field (NF) integrated
sensing and communication (ISAC) scenarios by exploiting known scatterers in
the sensing scene. We propose a location deception (LD) scheme where scatterers
are deliberately illuminated with probing power that is higher than that
directed toward targets of interest, with the goal of deceiving potential
eavesdroppers (Eves) with sensing capability into misidentifying scatterers as
targets. While the known scatterers can be removed at the legitimate sensing
receiver, our LD approach causes Eves to misdetect targets. Notably, this
deception is achieved without requiring any prior information about the Eves'
characteristics or locations. To strike a flexible three-way tradeoff among
communication, sensing, and sensing-security performance, the sum rate and
power allocated to scatterers are weighted and maximized under a legitimate
radar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the
fractional programming (FP) framework and semidefinite relaxation (SDR) to
solve this problem. To evaluate the security of the proposed LD scheme, the
Cramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.
Additionally, we introduce the Kullback-Leibler Divergence (KLD) gap between
targets and scatterers at Eve to quantify the impact of the proposed LD
framework on Eve's sensing performance from an information-theoretical
perspective. Simulation results demonstrate that the proposed LD scheme can
flexibly adjust the beamforming strategy according to performance requirements,
thereby achieving the desired three-way tradeoff. In particular, in terms of
sensing security, the proposed scheme significantly enhances the clutter signal
strength at Eve's side, leading to confusion or even missed detection of the
actual target.

</details>


### [417] [Deep Learning Based Joint Space-Time-Frequency Domain Channel Prediction for Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.20146)
*Yongning Qi,Tao Zhou,Zuowei Xiang,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的联合时空频域信道预测模型，用于解决6G通信中CF-mMIMO的信道预测问题，并验证了其在仿真和实际数据集上的优越性。


<details>
  <summary>Details</summary>
Motivation: 信道预测对于CF-mMIMO系统至关重要，能提高CSI的准确性，从而提升系统性能。

Method: 提出了一种在Transformer-encoder基础上加入频率卷积（FreqConv）和空间卷积（SpaceConv）层的深度学习模型，该模型能够并行输出多步预测结果，并利用时空频域相关性，提取不规则AP部署下的空间相关性。通过仿真数据集优化超参数，并评估预测精度和计算复杂度，最后使用真实数据集进行验证。

Result: 所提出的模型在仿真数据集上展现出比传统模型更高的预测精度和更低的计算复杂度。在真实的高铁LTE网络数据集上验证也表明，该模型相比传统模型具有更高的预测精度。

Conclusion: 所提出的基于深度学习的联合时空频域信道预测模型能够有效提升CF-mMIMO系统的信道预测性能，并在不同场景下均优于传统方法。

Abstract: The cell-free massive multi-input multi-output (CF-mMIMO) is a promising
technology for the six generation (6G) communication systems. Channel
prediction will play an important role in obtaining the accurate CSI to improve
the performance of CF-mMIMO systems. This paper studies a deep learning (DL)
based joint space-time-frequency domain channel prediction for CF-mMIMO.
Firstly, the prediction problems are formulated, which can output the
multi-step prediction results in parallel without error propagation. Then, a
novel channel prediction model is proposed, which adds frequency convolution
(FreqConv) and space convolution (SpaceConv) layers to Transformer-encoder. It
is able to utilize the space-time-frequency correlations and extract the space
correlation in the irregular AP deployment. Next, simulated datasets with
different sizes of service areas, UE velocities and scenarios are generated,
and correlation analysis and cross-validation are used to determine the optimal
hyper-parameters. According to the optimized hyper-parameters, the prediction
accuracy and computational complexity are evaluated based on simulated
datasets. It is indicated that the prediction accuracy of the proposed model is
higher than traditional model, and its computational complexity is lower than
traditional Transformer model. After that, the impacts of space-time-frequency
correlations on prediction accuracy are studied. Finally, realistic datasets in
a high-speed train (HST) long-term evolution (LTE) network are collected to
verify the prediction accuracy. The verification results demonstrate that it
also achieves higher prediction accuracy compared with traditional models in
the HST LTE network.

</details>


### [418] [NOMA for Visible Light Communications: Recent Advances and Future Directions](https://arxiv.org/abs/2510.20215)
*Xuesong Wang*

Main category: eess.SP

TL;DR: VLC是6G的有益补充，但现有标准未充分利用其光学特性。TDMA和CSMA/CA等传统MAC协议在VLC中存在效率和适用性问题。NOMA作为一种5G RF技术，在6G VLC中具有巨大潜力，允许多用户共享时频资源并容忍干扰。本文综述了VLC和NOMA-VLC的进展、优化约束、应用场景和未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有VLC标准（如ITU G.9991和IEEE 802.11bb）源自有限的RF技术，未能充分利用光的传播特性。TDMA协议在VLC的非对称性和突发性流量下效率低下。CSMA/CA及其变体需要针对VLC进行调整才能获得良好性能。因此，有必要为VLC设计新的MAC层协议，特别是利用NOMA技术。

Method: 本文回顾了VLC和基于NOMA的VLC技术的研究进展，探讨了其关键的优化约束和目标，分析了适合NOMA技术的VLC应用场景，并指出了未来研究方向。

Result: NOMA技术在5G RF系统中已初步探索，并有望应用于6G VLC。它允许多用户共享相同的时频资源，并能容忍一定的干扰，这为提高VLC的频谱效率提供了新的途径。

Conclusion: NOMA是一种有前景的MAC层技术，可以提高6G VLC网络的性能。未来的研究应集中在进一步优化NOMA在VLC中的应用，并探索其在不同场景下的潜力。

Abstract: Rapidly increasing demand for high speed data is pushing 6G wireless networks
to support larger link scales, lower latency, and higher spectral efficiency.
Visible light communications (VLC) is a strong complement to radio frequency
(RF) systems within 6G. The latest ITU G.9991 and IEEE 802.11bb standards are
adapted from cable and RF wireless technologies for use in VLC, so they do not
fully exploit the optical nature of light links. VLC links are often asymmetric
between uplink and downlink, which makes TDMA style protocols inefficient when
many users generate bursty and asymmetric traffic. Compared with RF, the strong
directionality and frequent line of sight in VLC can mitigate hidden and
exposed terminals, yet these effects can still appear under limited field of
view, blockage, or reflections. CSMA/CA and related methods remain usable in
VLC and in RF plus VLC networks, but they usually need design tweaks such as
RTS/CTS or directional sensing to perform well. Although the optical spectrum
is vast, the bandwidth of practical LEDs and of common PIN or APD receivers is
limited, so efficient multiple access can yield large gains. This motivates a
clean slate design for VLC, especially at the MAC layer. NOMA, first explored
in 5G RF systems, is also promising for 6G VLC. It lets multiple users share
the same time and frequency resources while tolerating controlled interference.
This paper reviews progress in VLC and in NOMA based VLC, outlines key
optimization constraints and objectives, surveys scenarios that fit NOMA in
VLC, and points to several directions for future work.

</details>


### [419] [A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond](https://arxiv.org/abs/2510.20265)
*Burak Ahmet Ozden,Erdogan Aydin,Emir Aslandogan,Haci Ilhan,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: 本文对基于正交时频空间（OTFS）的无线通信系统进行了全面的调查，重点关注其与索引调制（IM）的结合。OTFS利用延迟-多普勒（DD）域进行调制，以实现鲁棒和高容量的通信，而IM则通过选择的通信资源的索引来编码数据，以提高性能。该调查系统地分类了现有的OTFS-IM方案，并对其系统架构、检测方法、容量、峰均功率比、分集、复杂性、不完美的信道状态信息、频谱效率和中断概率等方面进行了回顾。此外，还描述了OTFS-IM的变体，如基于OTFS的空间移位键控、基于OTFS的空间调制、基于OTFS的二次空间调制、基于OTFS的媒体调制和基于OTFS的码索引调制，并对其在计算复杂性、误码性能、容量、节能、频谱效率和吞吐量方面进行了比较分析。最后，讨论了OTFS-IM系统的挑战、优点和未来发展方向，涵盖了复杂性、效率、延迟、信道估计、硬件约束、同步、安全以及与其他先进无线通信技术的潜在集成等关键方面。


<details>
  <summary>Details</summary>
Motivation: OTFS调制技术利用延迟-多普勒（DD）域，有望为6G及未来网络提供高容量、高鲁棒性的无线通信。索引调制（IM）通过在通信资源索引中编码数据，能提高通信的误码性能、频谱效率和能量效率。因此，研究OTFS与IM的结合具有重要意义，以充分发挥两者的优势。

Method: 本文采用文献综述的方法，对现有的OTFS-IM（正交时频空间-索引调制）技术进行了全面的回顾和分类。首先，对OTFS-IM方案的系统架构、检测方法和性能（如容量、峰均功率比、分集、复杂性、不完美的信道状态信息、频谱效率和中断概率）进行了系统性分类和评述。接着，详细介绍了OTFS-IM的各种变体，包括基于OTFS的空间移位键控、空间调制、二次空间调制、媒体调制和码索引调制，并对其在计算复杂性、误码性能、容量、节能、频谱效率和吞吐量等方面进行了比较分析。最后，讨论了OTFS-IM系统面临的挑战以及未来的发展方向。

Result: 该综述对OTFS-IM技术进行了系统的分类和全面的回顾，涵盖了其系统架构、检测方法和关键性能指标。研究了多种OTFS-IM变体，并对其在计算复杂性、误码性能、容量、节能、频谱效率和吞吐量等方面进行了比较分析，为理解和应用该技术提供了参考。最后，指出了OTFS-IM系统在复杂性、效率、延迟、信道估计、硬件约束、同步、安全以及与其他先进技术的集成方面的挑战和未来发展方向。

Conclusion: OTFS-IM技术作为一种有前景的无线通信方案，能够结合OTFS在时频/延迟-多普勒域的优势和IM在提升效率方面的能力。尽管存在一些挑战，如复杂性、信道估计和硬件约束，但通过未来的研究和技术集成，OTFS-IM有望在未来的无线通信系统中扮演重要角色。

Abstract: Orthogonal time frequency space (OTFS) is a two-dimensional modulation
technique that uses the delay-Doppler (DD) domain and is a candidate for
providing robust, high-capacity wireless communications for envisioned 6G and
beyond networks. The OTFS technique maps data to the DD domain instead of the
traditional time-frequency domain, enabling it to fully utilize channel
diversity and transform fast time-varying channels into nearly static channels.
Index modulation (IM) is a communication paradigm that conveys information not
only through conventional modulation symbols but also by encoding data bits in
the indices of the selected communication resources to improve error
performance, spectral efficiency, and energy efficiency. In this survey, a
comprehensive review of work on OTFS-based wireless communication systems is
presented. In particular, the existing OTFS-IM schemes are reviewed and
systematically categorized according to their system architectures, detection
methods, and performance aspects such as capacity, peak-to-average power ratio,
diversity, complexity, imperfect channel state information, spectral
efficiency, and outage probability. Furthermore, the operating principles and
system models of OTFS-IM variants-including OTFS-based space shift keying,
OTFS-based spatial modulation, OTFS-based quadrature spatial modulation,
OTFS-based media-based modulation, and OTFS-based code index modulation-are
described, followed by a comparative performance analysis in terms of
computational complexity, error performance, capacity, energy saving, spectral
efficiency, and throughput. Finally, the challenges, benefits, and future
directions for OTFS-IM systems are discussed, covering key aspects such as
complexity, efficiency, latency, channel estimation, hardware constraints,
synchronization, security, and potential integration with other advanced
wireless communication techniques.

</details>


### [420] [Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays](https://arxiv.org/abs/2510.20274)
*Kangda Zhi,Tianyu Yang,Songyan Xue,Giuseppe Caire*

Main category: eess.SP

TL;DR: 本文提出了一种用于超大尺度MIMO（XL-MIMO）下行信道估计和三维定位的三阶段算法，结合了正交匹配追踪（OMP）和稀疏贝叶斯学习（SBL）。


<details>
  <summary>Details</summary>
Motivation: 现有信道估计方法无法有效处理全列秩的近场XL-MIMO下行信道，需要新的算法来提高估计精度和降低开销。

Method: 1.将XL-MIMO划分为子阵列，使用基于离散傅里叶变换（DFT）的字典矩阵和OMP算法进行子阵列信道估计。2.利用估计的子阵列信道和一维多重信号分类（MUSIC）算法，在最小二乘（LS）准则下估计用户阵列的中心位置。3.利用估计的中心位置构建精细的、aided的字典矩阵，并使用SBL算法获得MIMO信道估计。

Result: 所提出的算法在导频开销和估计精度方面均显著优于现有基准算法。

Conclusion: 所提出的三阶段算法能够有效解决近场XL-MIMO下行信道估计和三维定位问题，并取得优于现有方法的性能。

Abstract: This paper investigates the design of channel estimation and 3D localization
algorithms in a challenging scenario, where a sub-connected planar extremely
large-scale multiple-input multiple-output (XL-MIMO) communicates with
multi-antenna users. In the near field, the uplink MIMO channel is of full
column rank and therefore can not be estimated effectively by applying existing
codebooks that are designed for the far-field case or for the near-field case
but limited to single antenna users. To solve this problem, we propose a
three-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse
Bayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into
subarrays and use OMP to solve the compressed sensing (CS) problem about
subarray channel estimation with the Discrete Fourier Transform (DFT)-based
dictionary matrix. Secondly, exploiting the estimated subarray channels and
employing one-dimensional multiple signal classification (MUSIC), we estimate
the central location of the user array under the Least Squares (LS) criterion.
Finally, we utilize the estimated central location to construct a refined
location-aided dictionary matrix and obtain the MIMO channel estimation using
SBL. Results exhibit the significant superiority of the proposed algorithm
compared with several benchmarks, in terms of both the pilot overhead and
estimation accuracy.

</details>


### [421] [Channel Estimation and Passive Beamforming for Pixel-based Reconfigurable Intelligent Surfaces with Non-Separable State Response](https://arxiv.org/abs/2510.20354)
*Huayan Guo,Junhui Rao,Alex M. H. Wong,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 通过使用核方法和深度神经网络近似像素化可重构智能表面的非分离响应，并结合简化的级联信道模型和定制的估计算法，实现了低复杂度的被动波束形成，从而最大化了可实现速率。


<details>
  <summary>Details</summary>
Motivation: 像素化可重构智能表面（RIS）虽然硬件成本较低，但其非分离状态响应给信道估计和被动波束形成带来了挑战，现有方法难以奏效。

Method: 1. 使用核方法和深度神经网络近似非分离的RIS响应函数。 2. 提出简化的级联信道模型，并设计分别估计短期和长期参数的定制算法。 3. 提出低复杂度被动波束形成算法以配置离散RIS状态向量。

Result: 提出的解决方案在广泛的信噪比范围内显著优于各种基线方法。

Conclusion: 通过近似RIS响应和简化的信道模型，可以有效地解决像素化RIS的信道估计和被动波束形成问题，实现高性能和低复杂度。

Abstract: Pixel-based reconfigurable intelligent surfaces (RISs) employ a novel design
to achieve high reflection gain at a lower hardware cost by eliminating the
phase shifters used in traditional RIS. However, this design presents
challenges for channel estimation and passive beamforming due to its
non-separable state response, rendering existing solutions ineffective. To
address this, we first approximate the non-separable RIS response functions
using a kernel-based method and a deep neural network, achieving high accuracy
while reducing computational and memory complexity. Next, we propose a
simplified cascaded channel model that focuses on dominated scattering paths
with limited unknown parameters, along with customized algorithms to estimate
short-term and long-term parameters separately. Finally, we introduce a
low-complexity passive beamforming algorithm to configure the discrete RIS
state vector, maximizing the achievable rate. Our simulation results
demonstrate that the proposed solution significantly outperforms various
baselines across a wide SNR range.

</details>


### [422] [A Transformer Inspired AI-based MIMO receiver](https://arxiv.org/abs/2510.20363)
*András Rácz,Tamás Borsos,András Veres,Benedek Csala*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple
Output) detection method that treats each transmit layer as a token and learns
inter-stream interference via a lightweight self-attention mechanism. Queries
and keys are derived directly from the estimated channel matrix, so attention
scores quantify channel correlation. Values are initialized by matched-filter
outputs and iteratively refined. The AttDet design combines model-based
interpretability with data-driven flexibility. We demonstrate through
link-level simulations under realistic 5G channel models and high-order, mixed
QAM modulation and coding schemes, that AttDet can approach near-optimal
BER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining
predictable, polynomial complexity.

</details>


### [423] [Efficient Medium Access Control for Low-Latency Industrial M2M Communications](https://arxiv.org/abs/2510.20380)
*Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: FROG-MAC协议在工业M2M网络中具有更好的延迟和吞吐量表现，尤其是在处理多优先级数据时。


<details>
  <summary>Details</summary>
Motivation: 工业M2M网络需要低延迟和高可靠性通信，多优先级数据的存在增加了MAC协议设计的挑战。已有大量MAC协议被提出，但缺乏全面的对比分析，因此有必要对主要MAC协议进行跨比较。

Method: 通过在Contiki仿真环境中，对两种MAC协议（BoP-MAC和FROG-MAC）在不同节点数量和两种流量优先级下进行仿真，对比分析其在延迟和吞吐量方面的表现。

Result: 仿真结果表明，在处理多优先级异构数据时，FROG-MAC在延迟和吞吐量方面均优于BoP-MAC。

Conclusion: FROG-MAC协议通过分片低优先级流量以实现高优先级数据提前传输，在工业M2M网络的多优先级数据场景下，相比BoP-MAC（通过分配不同的退避值）能提供更好的延迟和吞吐量性能。

Abstract: Efficient medium access control (MAC) is critical for enabling low-latency
and reliable communication in industrial Machine-to-Machine (M2M) net-works,
where timely data delivery is essential for seamless operation. The presence of
multi-priority data in high-risk industrial environments further adds to the
challenges. The development of tens of MAC schemes over the past decade often
makes it a tough choice to deploy the most efficient solu-tion. Therefore, a
comprehensive cross-comparison of major MAC protocols across a range of
performance parameters appears necessary to gain deeper insights into their
relative strengths and limitations. This paper presents a comparison of
Contention window-based MAC scheme BoP-MAC with a fragmentation based,
FROG-MAC; both protocols focus on reducing the delay for higher priority
traffic, while taking a diverse approach. BoP-MAC assigns a differentiated
back-off value to the multi-priority traffic, whereas FROG-MAC enables early
transmission of higher-priority packets by fragmenting lower-priority traffic.
Simulations were performed on Contiki by varying the number of nodes for two
traffic priorities. It has been shown that when work-ing with multi-priority
heterogenous data in the industrial environment, FROG-MAC results better both
in terms of delay and throughput.

</details>


### [424] [Inference-Optimal ISAC via Task-Oriented Feature Transmission and Power Allocation](https://arxiv.org/abs/2510.20429)
*Biao Dong,Bin Cao,Qinyu Zhang*

Main category: eess.SP

TL;DR: 本论文研究了集成传感与通信（ISAC）系统中基于压缩与估计（CE）框架的协同增益问题，以推断性能作为关键度量。为了实现可处理的收发器设计和资源优化，我们通过误差概率界限来表征推断性能，该界限是判别增益（DG）的单调函数。这自然引发了最大化DG而非最小化均方误差（MSE）是否能带来更好推断性能的问题。论文推导了DG最优和MSE最优收发器设计的闭式解，揭示了水填充式结构以及明确的传感与通信（S&C）权衡。数值实验证实，DG最优设计通过选择性地分配功率给信息特征，从而节省传感的传输功率，实现了更节能的传输，尤其是在低信噪比（SNR）情况下。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索在集成传感与通信（ISAC）系统中，以推断性能为关键度量时，最大化判别增益（DG）与最小化均方误差（MSE）之间的权衡，并寻求更优化的收发器设计。

Method: 本文采用压缩与估计（CE）框架，通过误差概率界限来表征推断性能，并将其与判别增益（DG）关联。在此基础上，推导了DG最优和MSE最优收发器设计的闭式解，并分析了其结构和S&C权衡。

Result: 推导了DG最优和MSE最优收发器设计的闭式解，揭示了水填充式结构和S&C权衡。数值实验表明，DG最优设计在低信噪比（SNR）下能更有效地分配功率，从而实现更节能的传输。

Conclusion: 最大化判别增益（DG）而非最小化均方误差（MSE）可以带来更好的推断性能，并且DG最优设计在ISAC系统中，尤其是在低信噪比条件下，能实现更优越的能效。

Abstract: This work is concerned with the coordination gain in integrated sensing and
communication (ISAC) systems under a compress-and-estimate (CE) framework,
wherein inference performance is leveraged as the key metric. To enable
tractable transceiver design and resource optimization, we characterize
inference performance via an error probability bound as a monotonic function of
the discriminant gain (DG). This raises the natural question of whether
maximizing DG, rather than minimizing mean squared error (MSE), can yield
better inference performance. Closed-form solutions for DG-optimal and
MSE-optimal transceiver designs are derived, revealing water-filling-type
structures and explicit sensing and communication (S\&C) tradeoff. Numerical
experiments confirm that DG-optimal design achieves more power-efficient
transmission, especially in the low signal-to-noise ratio (SNR) regime, by
selectively allocating power to informative features and thus saving transmit
power for sensing.

</details>


### [425] [Analysis of Frequency-Diverse and Dispersion Effects in Dynamic Metasurface Antenna for Holographic Sensing and Imaging](https://arxiv.org/abs/2510.20447)
*Abdul Jabbar,Aakash Bansal,William Whittow*

Main category: eess.SP

TL;DR: DMAs can achieve frequency diversity and dispersion operations for enhanced wireless communications by dynamically reconfiguring meta-atoms, creating distinct radiation patterns across a frequency band without complex systems.


<details>
  <summary>Details</summary>
Motivation: Current DMA designs are usually quasi-narrowband, neglecting the versatile frequency-diverse manifestation and its utilization. This work aims to demonstrate and utilize the frequency-diversity and dispersion operations of DMAs.

Method: This work demonstrates flexible dispersion manipulation through dynamic holographic reconfigurability of meta-atoms in a DMA at the millimeter-wave band. This effect creates distinct radiation patterns across the operating frequency band, achieving flexible frequency diversity with enhanced scanning range within a compact, reconfigurable platform.

Result: The DMA achieves flexible frequency diversity with enhanced scanning range within a compact, reconfigurable platform, eliminating the need for wideband systems or complex phase-shifting networks and offering an alternative to traditional leaky-wave antennas.

Conclusion: The results establish fundamental insights into modelling and utilization of dispersive effects of DMAs in next-generation near-field and far-field holographic sensing and computational holographic imaging applications.

Abstract: Dynamic metasurface antennas (DMAs) represent a novel approach to
programmable and affordable electromagnetic wave manipulation for enhanced
wireless communications, sensing, and imaging applications. Nevertheless,
current DMA designs and models are usually quasi-narrowband, neglecting the
versatile frequency-diverse manifestation and its utilization. This work
demonstrates the frequency-diversity and dispersion operations of a
representative DMA structure at the millimeter-wave band. We demonstrate
flexible dispersion manipulation through dynamic holographic reconfigurability
of the meta-atoms in a DMA. This effect can create distinct radiation patterns
across the operating frequency band, achieving flexible frequency diversity
with enhanced scanning range within a compact, reconfigurable platform. It
eliminates the need for wideband systems or complex phase-shifting networks
while offering an alternative to frequency-scanned static beams of traditional
leaky-wave antennas. The results establish fundamental insights into modelling
and utilization of dispersive effects of DMAs in next-generation near-field and
far-field holographic sensing and computational holographic imaging
applications.

</details>


### [426] [An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming](https://arxiv.org/abs/2510.20507)
*Xi Gao,Akang Wang,Junkai Zhang,Qihong Duan,Jiang Xue*

Main category: eess.SP

TL;DR: MMMSE是一种基于块坐标下降框架的新型算法，用于解决下行链路MU-MIMO系统中WSR最大化问题，具有高效并行和GPU加速的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的WMMSE算法在MU-MIMO系统中虽然是求解WSR最大化的标准方法，但其计算复杂度高（与基站天线数量的立方成正比），限制了在低延迟场景下的应用。

Method: 提出一种基于块坐标下降（BCD）框架的新型并行算法，通过块坐标梯度下降（BCGD）更新预编码矩阵，避免了矩阵求逆，仅依赖矩阵乘法，易于GPU加速。为加速收敛，引入基于SMSE最小化问题的两阶段热启动策略。该算法称为A-MMMSE。

Result: 仿真结果表明，A-MMMSE在WSR性能上与WMMSE及其改进版本（reduced-WMMSE）相当，同时在计算时间上实现了显著的降低，适用于各种系统配置。

Conclusion: A-MMMSE算法在保证WSR性能的同时，显著降低了计算复杂度，提高了计算效率，非常适合低延迟的MU-MIMO系统。

Abstract: Precoding design based on weighted sum-rate (WSR) maximization is a
fundamental problem in downlink multi-user multiple-input multiple-output
(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)
algorithm is a standard solution, its high computational complexity--cubic in
the number of base station antennas due to matrix inversions--hinders its
application in latency-sensitive scenarios. To address this limitation, we
propose a highly parallel algorithm based on a block coordinate descent
framework. Our key innovation lies in updating the precoding matrix via block
coordinate gradient descent, which avoids matrix inversions and relies solely
on matrix multiplications, making it exceptionally amenable to GPU
acceleration. We prove that the proposed algorithm converges to a stationary
point of the WSR maximization problem. Furthermore, we introduce a two-stage
warm-start strategy grounded in the sum mean-square error (MSE) minimization
problem to accelerate convergence. We refer to our method as the Accelerated
Mixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation
results demonstrate that A-MMMSE matches the WSR performance of both
conventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a
substantial reduction in computational time across diverse system
configurations.

</details>


### [427] [Performance Analysis of End-to-End LEO Satellite-Aided Shore-to-Ship Communications: A Stochastic Geometry Approach](https://arxiv.org/abs/2510.20515)
*Xu Hu,Bin Lin,Xiao Lu,Ping Wang,Nan Cheng,Zhisheng Yin,Weihua Zhuang*

Main category: eess.SP

TL;DR: LEO卫星网络在海上通信中具有战略优势，但传统建模方法难以处理大规模LEO卫星星座。本文提出一种理论框架，将LEO卫星视为二项点过程分布在球面上，并考虑了瑞利衰落或阴影瑞利衰落下的陆地-海洋链路或空间链路。通过距离近似和基于阈值的通信方案，利用随机几何推导出端到端传输成功概率和平均传输速率容量的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 传统的基于多个圆形轨道的性能建模方法难以准确描述大规模LEO卫星星座的海事通信性能，因此需要一种易于处理的方法来评估网络性能。

Method: 提出一个LEO卫星辅助的岸对船通信网络（LEO-SSCN）的理论框架。在该框架中，LEO卫星作为二项点过程（BPP）分布在特定的球面表面上。该框架考虑了信号通过海洋链路（瑞利衰落）或空间链路（阴影瑞利衰落）的传输。为了解决服务卫星位置不确定导致的到目标船只距离建模的困难，提出了一种距离近似方法。然后，通过近似和引入基于阈值的通信方案，利用随机几何推导出端到端传输成功概率和平均传输速率容量的解析表达式。

Result: 通过数值结果验证了所提出分析方法的准确性，并展示了关键参数对LEO-SSCN性能的影响。

Conclusion: 所提出的理论框架能够准确地评估LEO卫星辅助的岸对船通信网络的性能，并且通过距离近似和随机几何的方法解决了实际建模中的挑战。

Abstract: Low Earth orbit (LEO) satellite networks have shown strategic superiority in
maritime communications, assisting in establishing signal transmissions from
shore to ship through space-based links. Traditional performance modeling based
on multiple circular orbits is challenging to characterize large-scale LEO
satellite constellations, thus requiring a tractable approach to accurately
evaluate the network performance. In this paper, we propose a theoretical
framework for an LEO satellite-aided shore-to-ship communication network
(LEO-SSCN), where LEO satellites are distributed as a binomial point process
(BPP) on a specific spherical surface. The framework aims to obtain the
end-to-end transmission performance by considering signal transmissions through
either a marine link or a space link subject to Rician or Shadowed Rician
fading, respectively. Due to the indeterminate position of the serving
satellite, accurately modeling the distance from the serving satellite to the
destination ship becomes intractable. To address this issue, we propose a
distance approximation approach. Then, by approximation and incorporating a
threshold-based communication scheme, we leverage stochastic geometry to derive
analytical expressions of end-to-end transmission success probability and
average transmission rate capacity. Extensive numerical results verify the
accuracy of the analysis and demonstrate the effect of key parameters on the
performance of LEO-SSCN.

</details>


### [428] [Time-series Random Process Complexity Ranking Using a Bound on Conditional Differential Entropy](https://arxiv.org/abs/2510.20551)
*Jacob Ayers,Richard Hahnloser,Julia Ulrich,Lothar Sebastian Krapp,Remo Nitschke,Sabine Stoll,Balthasar Bickel,Reinhard Furrer*

Main category: eess.SP

TL;DR: 该论文提出了一种基于预测误差的新方法来计算和评估时间序列的复杂度。


<details>
  <summary>Details</summary>
Motivation: 由于高维过程和未知分布的条件微分熵难以计算，因此需要一种计算上可行的替代方法来评估时间序列的复杂度。

Method: 该论文利用信息理论预测误差界限，并通过利用 Hadamard 不等式和协方差矩阵的正半定性来增加这些界限。他们通过两种合成实验来测试他们的框架：(1) 具有加性高斯噪声的受控线性自回归过程，以及 (2) 受生物启发的合成音频数据的复杂度排序任务。

Result: 该方法能够根据预测误差对时间序列进行排序，并与真实熵或已知复杂度排序保持一致。

Conclusion: 该框架为使用预测误差进行时间序列复杂度排序提供了一种计算上可行且具有信息理论基础的方法。

Abstract: Conditional differential entropy provides an intuitive measure for relatively
ranking time-series complexity by quantifying uncertainty in future
observations given past context. However, its direct computation for
high-dimensional processes from unknown distributions is often intractable.
This paper builds on the information theoretic prediction error bounds
established by Fang et al. \cite{fang2019generic}, which demonstrate that the
conditional differential entropy \textbf{$h(X_k \mid X_{k-1},...,X_{k-m})$} is
upper bounded by a function of the determinant of the covariance matrix of
next-step prediction errors for any next step prediction model. We add to this
theoretical framework by further increasing this bound by leveraging Hadamard's
inequality and the positive semi-definite property of covariance matrices.
  To see if these bounds can be used to rank the complexity of time series, we
conducted two synthetic experiments: (1) controlled linear autoregressive
processes with additive Gaussian noise, where we compare ordinary least squares
prediction error entropy proxies to the true entropies of various additive
noises, and (2) a complexity ranking task of bio-inspired synthetic audio data
with unknown entropy, where neural network prediction errors are used to
recover the known complexity ordering.
  This framework provides a computationally tractable method for time-series
complexity ranking using prediction errors from next-step prediction models,
that maintains a theoretical foundation in information theory.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [429] [Interactive Hypergraph Visual Analytics for Exploring Large and Complex Image Collections](https://arxiv.org/abs/2510.20050)
*Floris Gisolf,Zeno J. M. H. Geradts,Marcel Worring*

Main category: cs.GR

TL;DR: 提出了一种用于分析大型复杂图像集合的可视分析方法，通过交互式可视化技术构建和探索超图，以揭示图像间的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 传统聚类和分类方法难以有效表示图像间复杂的重叠关系，尤其是在缺乏标签数据或预训练模型的情况下。

Method: 开发了一个可扩展的超图构建流程，用于从原始图像数据中提取信息。设计了集成了空间超图表示、交互式网格和矩阵可视化的技术，使用户能够动态探索和理解关系。

Result: 该方法能够有效地处理包含数万张图像的图像集合，并通过与真实图像集合的评估表明，该方法能够帮助领域专家高效地获得见解。

Conclusion: 所提出的可视化分析方法能够有效地帮助领域专家从大型复杂图像集合中提取有价值的信息和洞察。

Abstract: Analyzing large complex image collections in domains like forensics, accident
investigation, or social media analysis involves interpreting intricate,
overlapping relationships among images. Traditional clustering and
classification methods fail to adequately represent these complex
relationships, particularly when labeled data or suitable pre-trained models
are unavailable. Hypergraphs effectively capture overlapping relationships, but
to translate their complexity into information and insights for domain expert
users visualization is essential. We propose an interactive visual analytics
approach specifically designed for the construction, exploration, and analysis
of hypergraphs on large-scale complex image collections. Our core contributions
include: (1) a scalable pipeline for constructing hypergraphs directly from raw
image data, including a similarity measure to evaluate constructed hypergraphs
against a ground truth, (2) interactive visualization techniques that integrate
spatial hypergraph representations, interactive grids, and matrix
visualizations, enabling users to dynamically explore and interpret
relationships without becoming overwhelmed and disoriented, and (3) practical
insights on how domain experts can effectively use the application, based on
evaluation with real-life image collections. Our results demonstrate that our
visual analytics approach facilitates iterative exploration, enabling domain
experts to efficiently derive insights from image collections containing tens
of thousands of images.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [430] [A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem](https://arxiv.org/abs/2510.19835)
*Max B. Zhao,Fei Li*

Main category: cs.AI

TL;DR: 提出并评估了一种受量子启发的算法，用于解决二次无约束二元优化（QUBO）问题，该问题在数学上等同于寻找伊辛自旋玻璃哈密顿量的基态。该算法采用矩阵乘积态（MPS）来紧凑地表示自旋构型的大叠加，并利用离散的驱动时间表来引导MPS趋向基态。在每一步，将包含横向磁场的驱动哈密顿量与问题哈密顿量相结合，以实现自旋翻转和促进量子隧穿。MPS使用标准的密度矩阵重整化群（DMRG）方法进行更新，该方法通过在自旋链上进行多次扫描来迭代地最小化系统的能量。尽管该算法具有启发性，但它能在各种QUBO实例中可靠地识别全局最小值，而不仅仅是接近最优解。


<details>
  <summary>Details</summary>
Motivation: QUBO问题在数学上等同于寻找伊辛自旋玻璃哈密顿量的基态，这类问题在许多领域都有应用。需要一种有效的方法来解决QUBO问题，尤其是找到全局最小值。

Method: 该算法采用矩阵乘积态（MPS）来表示自旋构型的大叠加，并利用离散的驱动时间表和包含横向磁场的驱动哈密顿量与问题哈密顿量相结合，以实现自旋翻转和促进量子隧穿。MPS使用标准的密度矩阵重整化群（DMRG）方法进行更新，通过多次扫描迭代最小化系统能量。

Result: 该算法在Sudoku和MaxCut问题上表现出色。在Sudoku谜题中，它处理了超过200个伊辛自旋的实例。在MaxCut问题中，它成功解决了包含多达251个节点和3265条边的实例。

Conclusion: 该受量子启发的算法能够可靠地识别QUBO问题的全局最小值，并且具有良好的可扩展性、通用性，适合工业规模的应用。

Abstract: We propose and evaluate a quantum-inspired algorithm for solving Quadratic
Unconstrained Binary Optimization (QUBO) problems, which are mathematically
equivalent to finding ground states of Ising spin-glass Hamiltonians. The
algorithm employs Matrix Product States (MPS) to compactly represent large
superpositions of spin configurations and utilizes a discrete driving schedule
to guide the MPS toward the ground state. At each step, a driver Hamiltonian --
incorporating a transverse magnetic field -- is combined with the problem
Hamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is
updated using the standard Density Matrix Renormalization Group (DMRG) method,
which iteratively minimizes the system's energy via multiple sweeps across the
spin chain. Despite its heuristic nature, the algorithm reliably identifies
global minima, not merely near-optimal solutions, across diverse QUBO
instances. We first demonstrate its effectiveness on intermediate-level Sudoku
puzzles from publicly available sources, involving over $200$ Ising spins with
long-range couplings dictated by constraint satisfaction. We then apply the
algorithm to MaxCut problems from the Biq Mac library, successfully solving
instances with up to $251$ nodes and $3,265$ edges. We discuss the advantages
of this quantum-inspired approach, including its scalability, generalizability,
and suitability for industrial-scale QUBO applications.

</details>


### [431] [Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis](https://arxiv.org/abs/2510.19836)
*Eliseo Curcio*

Main category: cs.AI

TL;DR: 该研究提出了分析可靠性基准（ARB），一个用于评估人工智能在能源系统分析中推理可靠性的标准化框架，并使用五个子指标（准确性、推理可靠性、不确定性约束、政策一致性和透明度）对四个前沿模型进行了测试，结果表明GPT-4/5和Claude 4.5 Sonnet表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能和机器学习在能源领域的应用缺乏一个标准的框架来评估其分析结论的逻辑完整性，目前的方法只关注预测准确性和计算效率。

Method: 提出分析可靠性基准（ARB），该基准包含五个子指标：准确性、推理可靠性、不确定性约束、政策一致性和透明度。ARB使用公开的技术经济数据集，并在确定性、概率性和认识论场景下评估了四个前沿模型（GPT-4/5、Claude 4.5 Sonnet、Gemini 2.5 Pro、Llama 3 70B）。

Result: GPT-4/5和Claude 4.5 Sonnet的分析可靠性指数超过90%，表现出持续且符合政策的推理。Gemini 2.5 Pro表现出中等稳定性，而Llama 3 70B的性能低于专业阈值。统计验证确认了这些模型之间性能差异的显著性和可复现性。

Conclusion: ARB是能源领域第一个用于验证人工智能系统因果、概率和政策驱动推理的量化方法，为全球能源转型中可信赖和透明的分析应用提供了参考框架。

Abstract: Artificial intelligence and machine learning are increasingly used for
forecasting, optimization, and policy design in the energy sector, yet no
standardized framework exists to evaluate whether these systems reason
correctly. Current validation practices focus on predictive accuracy or
computational efficiency, leaving the logical integrity of analytical
conclusions untested. This study introduces the Analytical Reliability
Benchmark (ARB), a reproducible framework that quantifies reasoning reliability
in large language models applied to energy system analysis. The benchmark
integrates five submetrics: accuracy, reasoning reliability, uncertainty
discipline, policy consistency, and transparency, and evaluates model
performance across deterministic, probabilistic, and epistemic scenarios using
open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four
frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were
tested under identical factual and regulatory conditions. Results show that
reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5
Sonnet achieved consistent and policy-compliant reasoning (Analytical
Reliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate
stability, and Llama 3 70B remained below professional thresholds. Statistical
validation confirmed that these differences are significant and reproducible.
The ARB establishes the first quantitative method in the energy literature for
verifying causal, probabilistic, and policy-driven reasoning in artificial
intelligence systems, providing a reference framework for trustworthy and
transparent analytical applications in the global energy transition.

</details>


### [432] [Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory](https://arxiv.org/abs/2510.19838)
*Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury*

Main category: cs.AI

TL;DR: Branch-and-Browse 是一个用于 LLM 驱动的自主网络代理的框架，通过改进的推理和效率来克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有网络代理在深度推理和效率方面存在不足，通常采用线性方法或计算成本高昂的搜索策略。

Method: Branch-and-Browse 框架结合了结构化推理-行动、上下文记忆和高效执行。它采用显式的子任务管理和树状探索进行多分支推理，通过高效的网络状态回放和后台推理引导探索，并利用页面操作内存来共享探索过的操作。

Result: 在 WebArena 基准测试中，Branch-and-Browse 实现了 35.8% 的任务成功率，并将执行时间缩短了 40.4%。

Conclusion: Branch-and-Browse 是一个可靠且高效的 LLM 网络代理框架。

Abstract: Autonomous web agents powered by large language models (LLMs) show strong
potential for performing goal-oriented tasks such as information retrieval,
report generation, and online transactions. These agents mark a key step toward
practical embodied reasoning in open web environments. However, existing
approaches remain limited in reasoning depth and efficiency: vanilla linear
methods fail at multi-step reasoning and lack effective backtracking, while
other search strategies are coarse-grained and computationally costly. We
introduce Branch-and-Browse, a fine-grained web agent framework that unifies
structured reasoning-acting, contextual memory, and efficient execution. It (i)
employs explicit subtask management with tree-structured exploration for
controllable multi-branch reasoning, (ii) bootstraps exploration through
efficient web state replay with background reasoning, and (iii) leverages a
page action memory to share explored actions within and across sessions. On the
WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\%
and reduces execution time by up to 40.4\% relative to state-of-the-art
methods. These results demonstrate that Branch-and-Browse is a reliable and
efficient framework for LLM-based web agents.

</details>


### [433] [DAG-Math: Graph-Guided Mathematical Reasoning in LLMs](https://arxiv.org/abs/2510.19842)
*Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu*

Main category: cs.AI

TL;DR: LLMs在数学问题上使用CoT表现出色，但原因不明确。本文将CoT建模为基于规则的随机过程，引入“逻辑邻近度”来衡量CoT轨迹与DAG结构的一致性，并构建DAG-MATH CoT基准来评估LLMs的推理能力。实验发现不同LLM家族在推理保真度上存在显著差异，揭示了最终答案准确性与规则一致性推导之间的差距。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在数学问题上使用CoT取得成功的原因，区分是搜索、死记硬背还是规则一致性推理。

Method: 将CoT建模为有向无环图（DAG）上的基于规则的随机过程，引入逻辑邻近度作为评估指标，并提出DAG-MATH CoT格式和基准来引导和评估LLMs。

Result: 在标准数学推理数据集上，即使PASS@k相似，不同LLM家族在推理保真度上也存在统计学上的显著差异，表明最终答案准确性与规则一致性推导之间存在差距。

Conclusion: 所提出的框架在自由形式CoT和形式证明系统之间取得了平衡，为LLMs的推理评估提供了可行的诊断方法，并揭示了模型在规则一致性推理方面的不足。

Abstract: Large Language Models (LLMs) demonstrate strong performance on mathematical
problems when prompted with Chain-of-Thought (CoT), yet it remains unclear
whether this success stems from search, rote procedures, or rule-consistent
reasoning. To address this, we propose modeling CoT as a certain rule-based
stochastic process over directed acyclic graphs (DAGs), where nodes represent
intermediate derivation states and edges encode rule applications. Within this
framework, we introduce logical closeness, a metric that quantifies how well a
model's CoT trajectory (i.e., the LLM's final output) adheres to the DAG
structure, providing evaluation beyond classical PASS@k metrics. Building on
this, we introduce the DAG-MATH CoT format and construct a benchmark that
guides LLMs to generate CoT trajectories in this format, thereby enabling the
evaluation of their reasoning ability under our framework. Across standard
mathematical reasoning datasets, our analysis uncovers statistically
significant differences in reasoning fidelity among representative LLM
families-even when PASS@k is comparable-highlighting gaps between final-answer
accuracy and rule-consistent derivation. Our framework provides a balance
between free-form CoT and formal proofs systems, offering actionable
diagnostics for LLMs reasoning evaluation. Our benchmark and code are available
at: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.

</details>


### [434] [Surfer 2: The Next Generation of Cross-Platform Computer Use Agents](https://arxiv.org/abs/2510.19949)
*Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij*

Main category: cs.AI

TL;DR: Surfer 2是一个统一的代理架构，仅通过视觉观察即可在Web、桌面和移动环境中实现跨平台操作，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有代理系统在跨Web、桌面和移动环境的通用性方面的挑战，因为它们依赖于特定环境的接口。

Method: Surfer 2采用分层上下文管理、解耦的规划和执行以及自验证与自适应恢复的统一架构，纯粹从视觉观察中操作。

Result: Surfer 2在WebVoyager上达到97.1%的准确率，在WebArena上达到69.6%，在OSWorld上达到60.1%，在AndroidWorld上达到87.1%，并且在所有基准测试中都超过了人类的表现。

Conclusion: 系统化的编排可以增强基础模型的能力，并通过单独的视觉交互实现通用计算机控制，但需要下一代视觉语言模型来实现帕累托最优的成本效益。

Abstract: Building agents that generalize across web, desktop, and mobile environments
remains an open challenge, as prior systems rely on environment-specific
interfaces that limit cross-platform deployment. We introduce Surfer 2, a
unified architecture operating purely from visual observations that achieves
state-of-the-art performance across all three environments. Surfer 2 integrates
hierarchical context management, decoupled planning and execution, and
self-verification with adaptive recovery, enabling reliable operation over long
task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on
WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior
systems without task-specific fine-tuning. With multiple attempts, Surfer 2
exceeds human performance on all benchmarks. These results demonstrate that
systematic orchestration amplifies foundation model capabilities and enables
general-purpose computer control through visual interaction alone, while
calling for a next-generation vision language model to achieve Pareto-optimal
cost-efficiency.

</details>


### [435] [RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs](https://arxiv.org/abs/2510.19954)
*Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski*

Main category: cs.AI

TL;DR: RELATE是一种通用的、即插即用的特征编码器，用于多表异构时间图，它使用共享的特定模态编码器和交叉注意力模块来聚合特征，从而减少参数数量并支持多数据集预训练。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNNs）依赖于特定于模式的特征编码器，这限制了可扩展性和参数共享。需要一种模式无关的方法来处理多表异构时间图。

Method: RELATE使用共享的特定模态编码器（用于分类、数值、文本和时间属性）和一个Perceiver风格的交叉注意力模块来聚合特征，生成固定大小、与排列无关的节点表示。

Result: RELATE在RelBench基准测试中的ReLGNN和HGT上进行了评估，其性能比特定于模式的编码器低3%，但参数数量减少了多达5倍。

Conclusion: RELATE是一种模式无关的特征编码器，可以与任何通用GNN结合使用，它通过支持变化的模式和实现多数据集预训练，为关系图数据的通用模型铺平了道路。

Abstract: Relational multi-table data is common in domains such as e-commerce,
healthcare, and scientific research, and can be naturally represented as
heterogeneous temporal graphs with multi-modal node attributes. Existing graph
neural networks (GNNs) rely on schema-specific feature encoders, requiring
separate modules for each node type and feature column, which hinders
scalability and parameter sharing. We introduce RELATE (Relational Encoder for
Latent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature
encoder that can be used with any general purpose GNN. RELATE employs shared
modality-specific encoders for categorical, numerical, textual, and temporal
attributes, followed by a Perceiver-style cross-attention module that
aggregates features into a fixed-size, permutation-invariant node
representation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,
where it achieves performance within 3% of schema-specific encoders while
reducing parameter counts by up to 5x. This design supports varying schemas and
enables multi-dataset pretraining for general-purpose GNNs, paving the way
toward foundation models for relational graph data.

</details>


### [436] [A new wave of vehicle insurance fraud fueled by generative AI](https://arxiv.org/abs/2510.19957)
*Amir Hever,Itai Orr*

Main category: cs.AI

TL;DR: 生成式AI正在通过大规模、快速地伪造事故证据来加剧保险欺诈。虽然保险公司已部署AI检测工具，但欺诈者也在不断适应，导致持续的“猫鼠游戏”。UVeye提出了一个分层解决方案，以应对这一挑战。


<details>
  <summary>Details</summary>
Motivation: 保险欺诈，特别是车辆保险欺诈，每年造成数十亿美元的损失。生成式AI（如深度伪造）的出现使欺诈者能够以前所未有的规模和速度伪造证据，对保险业构成了新的重大威胁。

Method: UVeye提出了一个用于车辆欺诈的分层解决方案，该解决方案旨在检测、缓解和威慑新出现的由生成式AI驱动的欺诈行为。

Result: UVeye的分层解决方案代表了在检测、缓解和威慑车辆欺诈方面取得的重大进展，以应对由生成式AI驱动的新一轮欺诈活动。

Conclusion: 尽管保险公司正在采取措施，但由于欺诈者的不断适应和检测技术的局限性，AI驱动的保险欺诈仍然是一个持续的挑战。UVeye提出的解决方案旨在显著提高检测和威慑此类欺诈的能力。

Abstract: Generative AI is supercharging insurance fraud by making it easier to falsify
accident evidence at scale and in rapid time. Insurance fraud is a pervasive
and costly problem, amounting to tens of billions of dollars in losses each
year. In the vehicle insurance sector, fraud schemes have traditionally
involved staged accidents, exaggerated damage, or forged documents. The rise of
generative AI, including deepfake image and video generation, has introduced
new methods for committing fraud at scale. Fraudsters can now fabricate highly
realistic crash photos, damage evidence, and even fake identities or documents
with minimal effort, exploiting AI tools to bolster false insurance claims.
Insurers have begun deploying countermeasures such as AI-based deepfake
detection software and enhanced verification processes to detect and mitigate
these AI-driven scams. However, current mitigation strategies face significant
limitations. Detection tools can suffer from false positives and negatives, and
sophisticated fraudsters continuously adapt their tactics to evade automated
checks. This cat-and-mouse arms race between generative AI and detection
technology, combined with resource and cost barriers for insurers, means that
combating AI-enabled insurance fraud remains an ongoing challenge. In this
white paper, we present UVeye layered solution for vehicle fraud, representing
a major leap forward in the ability to detect, mitigate and deter this new wave
of fraud.

</details>


### [437] [AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits](https://arxiv.org/abs/2510.19964)
*Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong*

Main category: cs.AI

TL;DR: 本研究利用领导力人格特质和机器学习模型预测工程硕士生的学业成功，其中随机森林（RF）分类器在包含17个人格特质和领导力分数特征时达到87.50%的准确率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索人工智能技术在个性化学习中的潜力，特别是通过领导力人格特质和机器学习模型来预测学生的学业成功。

Method: 研究收集了129名环境工程专业硕士生的数据，包括五项领导力人格测试（23个特征）和学业成绩。采用探索性数据分析、相关性分析（皮尔逊相关系数）进行特征选择，并将平均成绩分为“不及格”、“及格”和“优秀”三类。使用包括SVM、LR、KNN、DT、GB、RF、XGBoost和LightGBM在内的七种机器学习算法进行建模。

Result: 随机森林（RF）分类器表现最佳，当模型包含17个人格特质特征和领导力分数特征时，准确率为87.50%；不包含该特征时，准确率为85.71%。

Conclusion: 本研究提供了一种在教育早期识别学生优势和劣势的方法，有助于为个性化学习选择最合适的策略。

Abstract: The study explores the potential of AI technologies in personalized learning,
suggesting the prediction of academic success through leadership personality
traits and machine learning modelling. The primary data were obtained from 129
master's students in the Environmental Engineering Department, who underwent
five leadership personality tests with 23 characteristics. Students used
self-assessment tools that included Personality Insight, Workplace Culture,
Motivation at Work, Management Skills, and Emotion Control tests. The test
results were combined with the average grade obtained from academic reports.
The study employed exploratory data analysis and correlation analysis. Feature
selection utilized Pearson correlation coefficients of personality traits. The
average grades were separated into three categories: fail, pass, and excellent.
The modelling process was performed by tuning seven ML algorithms, such as SVM,
LR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance
was achieved with the RF classifier, which yielded an accuracy of 87.50% for
the model incorporating 17 personality trait features and the leadership mark
feature, and an accuracy of 85.71% for the model excluding this feature. In
this way, the study offers an additional opportunity to identify students'
strengths and weaknesses at an early stage of their education process and
select the most suitable strategies for personalized learning.

</details>


### [438] [LLMs can hide text in other text of the same length.ipynb](https://arxiv.org/abs/2510.20075)
*Antonio Norelli,Michael Bronstein*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）能够将一段文本隐藏在另一段看似无关但同样连贯的文本中，并且长度相同。此技术可实现高文本隐藏质量，甚至可在普通笔记本电脑上进行本地编码和解码。


<details>
  <summary>Details</summary>
Motivation: 探索利用大型语言模型（LLM）隐藏文本的可能性，并讨论其对信任和AI安全的影响。

Method: 提出一种简单而有效的协议来实现文本隐藏。

Result: 即使是80亿参数的开源LLM也足以获得高质量的隐藏文本结果，并且可以在几秒钟内完成文本的编码和解码。

Conclusion: 文本隐藏技术的出现表明文本与其作者意图之间存在根本性的脱钩，这进一步削弱了人们对书面沟通的信任。这种可能性对AI安全提出了紧迫的问题，并挑战了我们对LLM“知道”某事的理解。论文还提出了一个具体场景：公司可以通过在安全模型的合规响应中嵌入其答案来秘密部署未经过滤的LLM。

Abstract: A meaningful text can be hidden inside another, completely different yet
still coherent and plausible, text of the same length. For example, a tweet
containing a harsh political critique could be embedded in a tweet that
celebrates the same political leader, or an ordinary product review could
conceal a secret manuscript. This uncanny state of affairs is now possible
thanks to Large Language Models, and in this paper we present a simple and
efficient protocol to achieve it. We show that even modest 8-billion-parameter
open-source LLMs are sufficient to obtain high-quality results, and a message
as long as this abstract can be encoded and decoded locally on a laptop in
seconds. The existence of such a protocol demonstrates a radical decoupling of
text from authorial intent, further eroding trust in written communication,
already shaken by the rise of LLM chatbots. We illustrate this with a concrete
scenario: a company could covertly deploy an unfiltered LLM by encoding its
answers within the compliant responses of a safe model. This possibility raises
urgent questions for AI safety and challenges our understanding of what it
means for a Large Language Model to know something.

</details>


### [439] [AI PB: A Grounded Generative Agent for Personalized Investment Insights](https://arxiv.org/abs/2510.20099)
*Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh*

Main category: cs.AI

TL;DR: AI PB 是一个在零售金融领域部署的生成式 AI 代理，它主动提供基于事实、合规且用户特定的投资见解，而不是被动回答查询。


<details>
  <summary>Details</summary>
Motivation: 介绍 AI PB，一个在零售金融领域运行的生成式 AI 代理，旨在主动提供投资见解，区别于传统的被动式聊天机器人。

Method: AI PB 整合了三个关键组件：(1) 一个基于组件的路由层，用于根据数据敏感性在内部和外部大型语言模型（LLM）之间进行路由；(2) 一个结合了 OpenSearch 和金融领域嵌入模型的混合检索管道；(3) 一个多阶段推荐机制，融合了规则启发式、行为序列建模和上下文老虎机算法。系统在本地运行，利用 Docker Swarm 和 vLLM，并使用 24 个 NVIDIA H100 GPU。

Result: 通过人工问答和系统指标的评估，证明了 AI PB 能够提供可信赖的 AI 投资见解。

Conclusion: 基于事实的生成、明确的路由和分层安全措施能够为高风险的金融领域提供可信赖的 AI 见解。

Abstract: We present AI PB, a production-scale generative agent deployed in real retail
finance. Unlike reactive chatbots that answer queries passively, AI PB
proactively generates grounded, compliant, and user-specific investment
insights. It integrates (i) a component-based orchestration layer that
deterministically routes between internal and external LLMs based on data
sensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the
finance-domain embedding model, and (iii) a multi-stage recommendation
mechanism combining rule heuristics, sequential behavioral modeling, and
contextual bandits. Operating fully on-premises under Korean financial
regulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100
GPUs. Through human QA and system metrics, we demonstrate that grounded
generation with explicit routing and layered safety can deliver trustworthy AI
insights in high-stakes finance.

</details>


### [440] [Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions](https://arxiv.org/abs/2510.20102)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai*

Main category: cs.AI

TL;DR: HCLA是一个以人为本的多智能体系统，用于检测数字资产交易中的异常。它通过对话式工作流连接解析、检测和解释三个角色，使用户能够用自然语言提问、检查结构化分析并获得上下文感知的解释。该系统使用户能够与一个经典的检测器（XGBoost）进行交互，该检测器被翻译成用户意图的模式，并返回基于底层特征的叙述性解释。


<details>
  <summary>Details</summary>
Motivation: HCLA旨在解决非专业用户在理解和信任金融取证中的挑战，通过提供可解释的异常检测系统来增强透明度和信任。

Method: HCLA系统整合了解析、检测和解释三个角色，形成一个对话式工作流。用户可以通过自然语言与系统交互，系统会将用户意图转换为模式，以驱动一个经典的检测器（如XGBoost）。系统随后返回基于底层特征的、上下文感知的叙述性解释。该系统还提供了一个开源的Web用户界面，并使用了一个标记的比特币混合数据集（Wasabi Wallet，2020-2024）进行原型开发和评估。

Result: 在标记的比特币混合数据集（Wasabi Wallet，2020-2024）上，基线检测器达到了很高的准确性。HCLA系统在保持高准确性的同时，增加了可解释性和交互式改进能力。

Conclusion: HCLA系统通过其以人为中心的、人机在环的设计，提高了金融取证的透明度和信任度。该系统使用户能够理解和与异常检测过程进行交互，从而在数字资产交易的背景下实现更有效的金融调查。

Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in
digital asset transactions. The system links three roles: Parsing, Detection,
and Explanation, into a conversational workflow that lets non-experts ask
questions in natural language, inspect structured analytics, and obtain
context-aware rationales. Implemented with an open-source web UI, HCLA
translates user intents into a schema for a classical detector (XGBoost in our
prototype) and returns narrative explanations grounded in the underlying
features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the
baseline detector reaches strong accuracy, while HCLA adds interpretability and
interactive refinement. We describe the architecture, interaction loop,
dataset, evaluation protocol, and limitations, and discuss how a
human-in-the-loop design improves transparency and trust in financial
forensics.

</details>


### [441] [The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice](https://arxiv.org/abs/2510.20109)
*Joshua Yuvaraj*

Main category: cs.AI

TL;DR: AI在法律行业的应用并非如预期般高效，反而因其“幻觉”和不透明性，需要律师投入更多精力进行验证，这导致其净值可能微乎其微。


<details>
  <summary>Details</summary>
Motivation: 反思机器学习生成式AI在法律行业的应用，因现有案例表明律师在使用AI时面临风险，需要新的范式来评估。

Method: 提出“验证-价值悖论”，认为AI带来的效率提升会被更多的人工验证需求所抵消。

Result: AI在法律行业的应用可能不会带来预期的净效率提升，反而凸显了律师核实信息的责任和对真相的忠诚。

Conclusion: 法律行业应建立新的AI使用范式，强调对AI生成内容的验证，并重申律师的诚信、正直和不误导法庭的责任，以及忠于真相和公民责任的价值观。

Abstract: It is often claimed that machine learning-based generative AI products will
drastically streamline and reduce the cost of legal practice. This enthusiasm
assumes lawyers can effectively manage AI's risks. Cases in Australia and
elsewhere in which lawyers have been reprimanded for submitting inaccurate
AI-generated content to courts suggest this paradigm must be revisited. This
paper argues that a new paradigm is needed to evaluate AI use in practice,
given (a) AI's disconnection from reality and its lack of transparency, and (b)
lawyers' paramount duties like honesty, integrity, and not to mislead the
court. It presents an alternative model of AI use in practice that more
holistically reflects these features (the verification-value paradox). That
paradox suggests increases in efficiency from AI use in legal practice will be
met by a correspondingly greater imperative to manually verify any outputs of
that use, rendering the net value of AI use often negligible to lawyers. The
paper then sets out the paradox's implications for legal practice and legal
education, including for AI use but also the values that the paradox suggests
should undergird legal practice: fidelity to the truth and civic
responsibility.

</details>


### [442] [TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning](https://arxiv.org/abs/2510.20188)
*Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen*

Main category: cs.AI

TL;DR: 该研究提出了TRUST框架，一个透明、去中心化的审计框架，用于解决大型语言模型（LLM）推理链的忠实性和无害性验证问题，该框架通过共识机制、分层DAG分解、区块链账本和隐私保护分割来克服现有方法的局限性，并在多项实验中证明了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）审计方法存在中心化、不透明和难以扩展等问题，这在将LLM应用于高风险领域时带来了重大风险。需要一种更可靠、可扩展且透明的方法来验证LLM的推理过程。

Method: 提出TRUST框架，采用以下策略：1. 共识机制：允许多样化的审计员达成一致，保证在高达30%的审计员恶意的情况下也能获得正确性。2. 分层DAG分解：将推理链分解为可扩展、可并行审计的层级。3. 区块链账本：记录所有验证决策，实现公共问责。4. 隐私保护分割：仅共享部分推理步骤，以保护模型逻辑的私密性。

Result: 在GPT-OSS、DeepSeek-r1和Qwen等多个LLM以及数学、医学、科学和人文等多个推理任务上进行的实验表明，TRUST框架能够有效地检测出推理缺陷，并且能够抵御恶意审计员的攻击。

Conclusion: TRUST框架是去中心化人工智能审计的开创性工作，为安全、可信地部署LLM提供了一条可行的途径。

Abstract: Large Language Models generate complex reasoning chains that reveal their
decision-making, yet verifying the faithfulness and harmlessness of these
intermediate steps remains a critical unsolved problem. Existing auditing
methods are centralized, opaque, and hard to scale, creating significant risks
for deploying proprietary models in high-stakes domains. We identify four core
challenges: (1) Robustness: Centralized auditors are single points of failure,
prone to bias or attacks. (2) Scalability: Reasoning traces are too long for
manual verification. (3) Opacity: Closed auditing undermines public trust. (4)
Privacy: Exposing full reasoning risks model theft or distillation. We propose
TRUST, a transparent, decentralized auditing framework that overcomes these
limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing
correctness under up to $30\%$ malicious participants. (2) A hierarchical DAG
decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A
blockchain ledger that records all verification decisions for public
accountability. (4) Privacy-preserving segmentation, sharing only partial
reasoning steps to protect proprietary logic. We provide theoretical guarantees
for the security and economic incentives of the TRUST framework. Experiments
across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,
medical, science, humanities) show TRUST effectively detects reasoning flaws
and remains robust against adversarial auditors. Our work pioneers
decentralized AI auditing, offering a practical path toward safe and
trustworthy LLM deployment.

</details>


### [443] [The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI](https://arxiv.org/abs/2510.20190)
*Marcelo Maciel Amaral,Raymond Aschheim*

Main category: cs.AI

TL;DR: LLMs在通往AGI的过程中会经历一个“锁定”阶段，从开放模仿转向身份巩固，这会影响其稳定性和可控性。研究表明，这种行为巩固是快速且非线性的，但对通用能力的影响各不相同，具体取决于模型规模。这一阶段对于AGI的可靠性和安全性至关重要，既可以被用于工程化可靠性，也可能自发出现并固化不可预测的目标和行为。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于通过类比人类发展，提出AGI进展可能涉及一个从开放模仿到身份巩固的“锁定”阶段，并探讨这一阶段对LLM行为、稳定性和可控性的影响。

Method: 本文通过形式化“锁定”阶段，将其与学习动力学中的已知现象联系起来，并提出检测该阶段开始的操作指标。通过实验，研究人员在不同规模的模型（小、中、大）上进行了验证，观察了行为巩固的非线性变化及其对通用能力产生的不同影响，包括性能权衡、成本效益的采用以及短暂的不稳定性。

Result: 实验结果显示，行为巩固是快速且非线性的。在小模型中，这可能导致性能权衡；在中等规模模型中，巩固过程几乎没有额外成本；而在大型量化模型中，则会出现短暂的不稳定性。这表明行为巩固对通用能力的影响并非单一模式。

Conclusion: 研究认为，LLM的身份巩固是实现AGI可靠性的先决条件，也是安全性的关键控制点。通过工程化设计可以实现可靠的身份，但这种巩固也可能自发产生，从而固化不可预测的目标和行为，带来潜在的安全风险。

Abstract: Large language models (LLMs) remain broadly open and highly steerable: they
imitate at scale, accept arbitrary system prompts, and readily adopt multiple
personae. By analogy to human development, we hypothesize that progress toward
artificial general intelligence (AGI) involves a lock-in phase: a transition
from open imitation to identity consolidation, in which goal structures,
refusals, preferences, and internal representations become comparatively stable
and resistant to external steering. We formalize this phase, link it to known
phenomena in learning dynamics, and propose operational metrics for onset
detection. Experimentally, we demonstrate that while the behavioral
consolidation is rapid and non-linear, its side-effects on general capabilities
are not monolithic. Our results reveal a spectrum of outcomes--from performance
trade-offs in small models, through largely cost-free adoption in mid-scale
models, to transient instabilities in large, quantized models. We argue that
such consolidation is a prerequisite for AGI-level reliability and also a
critical control point for safety: identities can be deliberately engineered
for reliability, yet may also emerge spontaneously during scaling, potentially
hardening unpredictable goals and behaviors.

</details>


### [444] [Merge and Conquer: Evolutionarily Optimizing AI for 2048](https://arxiv.org/abs/2510.20205)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.AI

TL;DR: 本文研究了使用进化训练方法优化AI以解决2048游戏，并对比了单智能体和双智能体系统。


<details>
  <summary>Details</summary>
Motivation: 动态环境下的AI优化是一个基本挑战，2048游戏因其策略性和随机性，是研究决策、长期规划和动态适应的理想场所。

Method: 实现了两种系统：一种是双智能体系统，由一个“思考者”LLM和一个“执行者”LLM组成；另一种是单智能体系统，基于优化有限蒙特卡洛树搜索的值函数。同时实验了回滚机制。

Result: 单智能体系统平均每轮得分提高473.2分，显示出明显的上升趋势（相关性ρ=0.607），LLM也发展出更高级的策略。双智能体系统改进不大，显示了元提示的局限性。

Conclusion: 进化优化技术在提高AI在非确定性环境中的表现方面有潜力，尤其是在单智能体系统中。

Abstract: Optimizing artificial intelligence (AI) for dynamic environments remains a
fundamental challenge in machine learning research. In this paper, we examine
evolutionary training methods for optimizing AI to solve the game 2048, a 2D
sliding puzzle. 2048, with its mix of strategic gameplay and stochastic
elements, presents an ideal playground for studying decision-making, long-term
planning, and dynamic adaptation. We implemented two distinct systems: a
two-agent metaprompting system where a "thinker" large language model (LLM)
agent refines gameplay strategies for an "executor" LLM agent, and a
single-agent system based on refining a value function for a limited Monte
Carlo Tree Search. We also experimented with rollback features to avoid
performance degradation. Our results demonstrate the potential of evolutionary
refinement techniques in improving AI performance in non-deterministic
environments. The single-agent system achieved substantial improvements, with
an average increase of 473.2 points per cycle, and with clear upward trends
(correlation $\rho$=0.607) across training cycles. The LLM's understanding of
the game grew as well, shown in its development of increasingly advanced
strategies. Conversely, the two-agent system did not garner much improvement,
highlighting the inherent limits of meta-prompting.

</details>


### [445] [Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods](https://arxiv.org/abs/2510.20252)
*Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao*

Main category: cs.AI

TL;DR: LLMs在模仿个体认知过程方面表现出局限性，但结合概念和语言特征的认知表征方法能提高其在个体化认知模拟中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估现有大型语言模型（LLMs）在个体化认知模拟（ICS）任务中，模仿个体认知过程（例如，作者写作风格）的能力，并探索不同的认知表征方法对提升模拟效果的作用。

Method: 构建了一个包含近期小说作品的数据集，并设计了一个包含11个评估条件的框架，用于测试7种现成的LLMs。实验中测试了包括语言特征、概念映射和基于个人资料信息在内的不同认知表征方法，以评估它们在ICS任务中的表现。

Result: 结合概念和语言特征的表征方法在ICS任务中表现最佳，优于静态的基于个人资料的线索。LLMs在模仿语言风格方面优于模仿叙事结构，这表明其在深层认知模拟方面存在局限性。

Conclusion: 虽然LLMs在模仿语言风格方面具有一定能力，但它们在深层个体认知模拟方面仍有很大提升空间。结合概念和语言特征的认知表征方法是未来开发更具个性化和人类化AI创意技术的有前景的方向。

Abstract: Individualized cognitive simulation (ICS) aims to build computational models
that approximate the thought processes of specific individuals. While large
language models (LLMs) convincingly mimic surface-level human behavior such as
role-play, their ability to simulate deeper individualized cognitive processes
remains poorly understood. To address this gap, we introduce a novel task that
evaluates different cognitive representation methods in ICS. We construct a
dataset from recently published novels (later than the release date of the
tested LLMs) and propose an 11-condition cognitive evaluation framework to
benchmark seven off-the-shelf LLMs in the context of authorial style emulation.
We hypothesize that effective cognitive representations can help LLMs generate
storytelling that better mirrors the original author. Thus, we test different
cognitive representations, e.g., linguistic features, concept mappings, and
profile-based information. Results show that combining conceptual and
linguistic features is particularly effective in ICS, outperforming static
profile-based cues in overall evaluation. Importantly, LLMs are more effective
at mimicking linguistic style than narrative structure, underscoring their
limits in deeper cognitive simulation. These findings provide a foundation for
developing AI systems that adapt to individual ways of thinking and expression,
advancing more personalized and human-aligned creative technologies.

</details>


### [446] [Using Large Language Models for Abstraction of Planning Domains - Extended Version](https://arxiv.org/abs/2510.20258)
*Bita Banihashemi,Megh Patel,Yves Lespérance*

Main category: cs.AI

TL;DR: LLMs can generate abstract PDDL domains for dynamic environments, with better performance on action abstraction than fluent abstraction.


<details>
  <summary>Details</summary>
Motivation: Generating effective abstractions for dynamic domains is challenging and impacts agent performance in planning, reasoning, and explanation. This paper investigates using LLMs for this task.

Method: The study models agent behaviors in PDDL and uses in-context learning with LLMs to generate abstract PDDL domains and problem instances based on natural language objectives. Three types of abstractions are considered: action choice, action sequences, and action/predicate parameters, including combinations. The generated abstractions are validated by symbolic tools and human experts.

Result: Experiments show that GPT-4o can generate useful planning domain abstractions in simple cases, performing better at abstracting actions than fluents.

Conclusion: LLMs, specifically GPT-4o, show promise in synthesizing planning domain abstractions, though further improvements are needed for fluent abstraction.

Abstract: Generating an abstraction of a dynamic domain that aligns with a given
purpose remains a significant challenge given that the choice of such an
abstraction can impact an agent's ability to plan, reason, and provide
explanations effectively. We model the agent's concrete behaviors in PDDL and
investigate the use of in-context learning with large language models (LLMs)
for the generation of abstract PDDL domains and problem instances, given an
abstraction objective specified in natural language. The benchmark examples we
use are new and have not been part of the data any LLMs have been trained on.
We consider three categories of abstractions: abstraction of choice of
alternative concrete actions, abstraction of sequences of concrete actions, and
abstraction of action/predicate parameters, as well as combinations of these.
The generated abstract PDDL domains and problem instances are then checked by
symbolic validation tools as well as human experts. Our experiments show that
GPT-4o can generally synthesize useful planning domain abstractions in simple
settings, although it is better at abstracting over actions than over the
associated fluents.

</details>


### [447] [Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction](https://arxiv.org/abs/2510.20275)
*Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim*

Main category: cs.AI

TL;DR: STaBERT通过融合兴趣点（POI）和时间信息，显著提升了人类出行预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能充分利用兴趣点（POI）提供的丰富语义信息来辅助时间信息进行人类出行预测。

Method: 提出STaBERT模型，该模型将POI和时间信息整合到每个位置，以构建统一的、语义丰富的出行表征。

Result: 在单城市预测中，GEO-BLEU分数从0.34提升到0.75；在多城市预测中，GEO-BLEU分数从0.34提升到0.56，预测准确性显著提高。

Conclusion: STaBERT通过整合POI和时间信息，能够更好地捕捉人类出行的语义，从而提高预测的准确性。

Abstract: Human mobility forecasting is crucial for disaster relief, city planning, and
public health. However, existing models either only model location sequences or
include time information merely as auxiliary input, thereby failing to leverage
the rich semantic context provided by points of interest (POIs). To address
this, we enrich a BERT-based mobility model with derived temporal descriptors
and POI embeddings to better capture the semantics underlying human movement.
We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI
and temporal information at each location to construct a unified, semantically
enriched representation of mobility. Experimental results show that STaBERT
significantly improves prediction accuracy: for single-city prediction, the
GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34
to 0.56.

</details>


### [448] [Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation](https://arxiv.org/abs/2510.20310)
*Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia*

Main category: cs.AI

TL;DR: 通过集成外部工具和多步推理，ToolEQA 提高了具身问答 (EQA) 的效率和准确性，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 EQA 方法缺乏明确的思考或规划，导致探索效率低下和响应不佳。集成外部工具和多步推理可以增强 EQA 代理的推理能力，从而实现更有效的探索和响应。

Method: 引入 ToolEQA，一个集成外部工具和多步推理的 EQA 代理。设计了一个自动生成 EQA 数据集（EQA-RT）的流程，包含推理轨迹和答案，用于训练和评估模型。EQA-RT 数据集包含约 18K 个任务，并分为训练集（EQA-RT-Train）和两个测试集（EQA-RT-Seen 和 EQA-RT-Unseen）。

Result: 在 EQA-RT-Seen 和 EQA-RT-Unseen 数据集上，ToolEQA 的成功率比最先进的方法提高了 9.2%~20.2%，并且比零样本的 ToolEQA 提高了 10%。ToolEQA 在 HM-EQA、OpenEQA 和 EXPRESS-Bench 数据集上也达到了最先进的性能。

Conclusion: ToolEQA 通过集成外部工具和多步推理，显著提高了 EQA 代理的性能，并在多个数据集上证明了其有效性和通用性。所提出的数据生成流程也为 EQA 任务的进一步研究提供了支持。

Abstract: Embodied Question Answering (EQA) requires agents to explore 3D environments
to obtain observations and answer questions related to the scene. Existing
methods leverage VLMs to directly explore the environment and answer questions
without explicit thinking or planning, which limits their reasoning ability and
results in excessive or inefficient exploration as well as ineffective
responses. In this paper, we introduce ToolEQA, an agent that integrates
external tools with multi-step reasoning, where external tools can provide more
useful information for completing the task, helping the model derive better
exploration directions in the next step of reasoning and thus obtaining
additional effective information. This enables ToolEQA to generate more
accurate responses with a shorter exploration distance. To enhance the model's
ability for tool-usage and multi-step reasoning, we further design a novel EQA
data generation pipeline that automatically constructs large-scale EQA tasks
with reasoning trajectories and corresponding answers. Based on the pipeline,
we collect the EQA-RT dataset that contains about 18K tasks, divided into a
training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping
with the training set) and EQA-RT-Unseen (novel scenes). Experiments on
EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by
9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot
ToolEQA by 10% in success rate. In addition, ToolEQA also achieves
state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench
datasets, demonstrating its generality. Our homepage see
https://tooleqa.github.io.

</details>


### [449] [Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems](https://arxiv.org/abs/2510.20332)
*Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés*

Main category: cs.AI

TL;DR: AI在医疗保健领域的应用面临数据偏见的挑战，该研究提出了检测和解决这些偏见的方法。


<details>
  <summary>Details</summary>
Motivation: AI在医疗保健领域潜力巨大，但实际应用受限于训练数据中的偏见问题。

Method: 分析了AI4HealthyAging项目中的临床数据收集过程，识别出历史、代表性和测量偏见。

Result: 确定了在性别、年龄、社会经济地位、设备和标签等变量中存在的偏见。

Conclusion: 提出了改进临床问题设计和数据收集以提高公平性和鲁棒性的实用建议，为未来医疗AI项目提供指导。

Abstract: Artificial intelligence (AI) holds great promise for transforming healthcare.
However, despite significant advances, the integration of AI solutions into
real-world clinical practice remains limited. A major barrier is the quality
and fairness of training data, which is often compromised by biased data
collection practices. This paper draws on insights from the AI4HealthyAging
project, part of Spain's national R&D initiative, where our task was to detect
biases during clinical data collection. We identify several types of bias
across multiple use cases, including historical, representation, and
measurement biases. These biases manifest in variables such as sex, gender,
age, habitat, socioeconomic status, equipment, and labeling. We conclude with
practical recommendations for improving the fairness and robustness of clinical
problem design and data collection. We hope that our findings and experience
contribute to guiding future projects in the development of fairer AI systems
in healthcare.

</details>


### [450] [Collateral Damage Assessment Model for AI System Target Engagement in Military Operations](https://arxiv.org/abs/2510.20337)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 本模型为AI军事应用引入了一种新的附带损害评估方法，该方法整合了时间、空间和力量维度，并采用知识表示与推理（KRR）架构，以支持负责任的AI系统目标识别。


<details>
  <summary>Details</summary>
Motivation: 随着AI在军事领域应用的增加，确保AI系统的负责任目标识别，评估潜在的附带损害效应变得至关重要。

Method: 提出了一种新的附带损害评估模型，该模型整合了时间、空间和力量维度，并采用知识表示与推理（KRR）架构，遵循设计科学方法。其分层结构捕获了AI系统的类别和架构组件、相应的交战向量和上下文方面，并考虑了扩散、严重性、可能性和评估指标，以实现透明的推理。

Result: 通过实例化的方式展示和评估了该模型，为进一步致力于构建负责任和可信赖的AI系统评估军事行动中交战AI系统所产生效应提供了基础。

Conclusion: 该模型为AI军事应用中的附带损害评估提供了一个系统化的方法，有助于开发更负责任和可信赖的AI系统。

Abstract: In an era where AI (Artificial Intelligence) systems play an increasing role
in the battlefield, ensuring responsible targeting demands rigorous assessment
of potential collateral effects. In this context, a novel collateral damage
assessment model for target engagement of AI systems in military operations is
introduced. The model integrates temporal, spatial, and force dimensions within
a unified Knowledge Representation and Reasoning (KRR) architecture following a
design science methodological approach. Its layered structure captures the
categories and architectural components of the AI systems to be engaged
together with corresponding engaging vectors and contextual aspects. At the
same time, spreading, severity, likelihood, and evaluation metrics are
considered in order to provide a clear representation enhanced by transparent
reasoning mechanisms. Further, the model is demonstrated and evaluated through
instantiation which serves as a basis for further dedicated efforts that aim at
building responsible and trustworthy intelligent systems for assessing the
effects produced by engaging AI systems in military operations.

</details>


### [451] [LLM-empowered knowledge graph construction: A survey](https://arxiv.org/abs/2510.20345)
*Haonan Bian*

Main category: cs.AI

TL;DR: LLM正在改变知识图谱的构建，本调查全面回顾了这一领域，分析了LLM如何重塑传统的知识图谱构建流程，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM的出现改变了知识图谱的构建范式，从传统的基于规则和统计的方法转向了语言驱动和生成式框架。

Method: 本调查回顾了传统的知识图谱方法，并从基于模式和无模式的两种视角探讨了新兴的LLM驱动的方法，分析了各自的技术机制和局限性。

Result: LLM在知识图谱的构建中展现了重塑经典三层流程（本体工程、知识抽取、知识融合）的潜力，并涌现出多种代表性框架。

Conclusion: LLM与知识图谱的结合是未来的重要趋势，有望在KG增强LLM推理、智能体动态知识记忆和多模态KG构建等方向取得进展，最终促进自适应、可解释和智能知识系统的发展。

Abstract: Knowledge Graphs (KGs) have long served as a fundamental infrastructure for
structured knowledge representation and reasoning. With the advent of Large
Language Models (LLMs), the construction of KGs has entered a new
paradigm-shifting from rule-based and statistical pipelines to language-driven
and generative frameworks. This survey provides a comprehensive overview of
recent progress in LLM-empowered knowledge graph construction, systematically
analyzing how LLMs reshape the classical three-layered pipeline of ontology
engineering, knowledge extraction, and knowledge fusion.
  We first revisit traditional KG methodologies to establish conceptual
foundations, and then review emerging LLM-driven approaches from two
complementary perspectives: schema-based paradigms, which emphasize structure,
normalization, and consistency; and schema-free paradigms, which highlight
flexibility, adaptability, and open discovery. Across each stage, we synthesize
representative frameworks, analyze their technical mechanisms, and identify
their limitations.
  Finally, the survey outlines key trends and future research directions,
including KG-based reasoning for LLMs, dynamic knowledge memory for agentic
systems, and multimodal KG construction. Through this systematic review, we aim
to clarify the evolving interplay between LLMs and knowledge graphs, bridging
symbolic knowledge engineering and neural semantic understanding toward the
development of adaptive, explainable, and intelligent knowledge systems.

</details>


### [452] [IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation](https://arxiv.org/abs/2510.20377)
*Tianyi Zhang,Florian Mai,Lucie Flek*

Main category: cs.AI

TL;DR: 该研究提出了一种名为IKnow的框架，用于在不依赖外部资源的情况下，通过对话格式的新型自监督目标，对大型语言模型进行持续的领域适应，同时保留其指令遵循能力和语义表示。


<details>
  <summary>Details</summary>
Motivation: 标准的持续预训练方法在指令调整后的模型上会损害其指令遵循能力和语义表示。现有的解决方案需要原始基础模型或外部数据库，这在实际中可能无法实现。

Method: IKnow框架提出了一种新颖的自监督目标，该目标采用指令-响应的对话格式。它利用文本中嵌入的领域知识，并在更深的语义层面进行编码，而不是依赖外部资源。

Result: IKnow能够保留指令遵循能力和语义表示，同时适应新领域。

Conclusion: IKnow是一种简单通用的框架，通过对话格式的新型自监督目标，在不依赖外部资源的情况下，实现了有效的持续领域适应。

Abstract: Continual pretraining promises to adapt large language models (LLMs) to new
domains using only unlabeled test-time data, but naively applying standard
self-supervised objectives to instruction-tuned models is known to degrade
their instruction-following capability and semantic representations. Existing
fixes assume access to the original base model or rely on knowledge from an
external domain-specific database - both of which pose a realistic barrier in
settings where the base model weights are withheld for safety reasons or
reliable external corpora are unavailable. In this work, we propose
Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general
framework that formulates novel self-supervised objectives in the
instruction-response dialogue format. Rather than depend- ing on external
resources, IKnow leverages domain knowledge embedded within the text itself and
learns to encode it at a deeper semantic level.

</details>


### [453] [A computational model and tool for generating more novel opportunities in professional innovation processes](https://arxiv.org/abs/2510.20402)
*Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown*

Main category: cs.AI

TL;DR: 该计算模型旨在通过五个函数生成新颖且有用的创新机会，并在酒店业进行了评估。


<details>
  <summary>Details</summary>
Motivation: 为了在创新项目中产生新颖的机会，并借鉴了创造力理论和技术。

Method: 该模型实现了五个函数，旨在提高创新机会的新颖性而不损失有用性，并使用了酒店业的一个创新项目进行了评估。

Result: 与Notebook LM和ChatGPT4o相比，该计算模型生成的创新机会更具新颖性和/或有用性。

Conclusion: 虽然该模型在提高创新机会的新颖性方面取得了一定的成功，但并非所有函数都对此做出了贡献，这为未来的模型发展指明了方向。

Abstract: This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

</details>


### [454] [Neural Reasoning for Robust Instance Retrieval in $\mathcal{SHOIQ}$](https://arxiv.org/abs/2510.20457)
*Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo*

Main category: cs.AI

TL;DR: EBR是一个新的神经推理器，它使用嵌入来近似符号推理器的结果，并且比现有的推理器更能抵抗数据缺失和错误。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号概念学习方法在处理真实世界的知识库时不够健壮，因为它们依赖于描述逻辑推理器，而这些推理器在面对不一致或错误的数据时不够稳定。本研究旨在解决这一挑战。

Method: 提出了一种名为EBR的新型神经推理器，该推理器利用嵌入来近似符号推理器的结果。EBR仅通过检索原子概念和存在限制的实例，就能检索或近似$\

Result: 实验表明，与最先进的推理器相比，EBR能够处理缺失和错误的数据，表现出良好的鲁棒性。

Conclusion: EBR通过使用嵌入来近似推理结果，为处理不一致和错误数据提供了鲁棒的解决方案，使其能够在真实的知识库上进行部署。

Abstract: Concept learning exploits background knowledge in the form of description
logic axioms to learn explainable classification models from knowledge bases.
Despite recent breakthroughs in neuro-symbolic concept learning, most
approaches still cannot be deployed on real-world knowledge bases. This is due
to their use of description logic reasoners, which are not robust against
inconsistencies nor erroneous data. We address this challenge by presenting a
novel neural reasoner dubbed EBR. Our reasoner relies on embeddings to
approximate the results of a symbolic reasoner. We show that EBR solely
requires retrieving instances for atomic concepts and existential restrictions
to retrieve or approximate the set of instances of any concept in the
description logic $\mathcal{SHOIQ}$. In our experiments, we compare EBR with
state-of-the-art reasoners. Our results suggest that EBR is robust against
missing and erroneous data in contrast to existing reasoners.

</details>


### [455] [FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic](https://arxiv.org/abs/2510.20467)
*Yiwen Peng,Thomas Bonald,Fabian M. Suchanek*

Main category: cs.AI

TL;DR: FLORA是一个无监督的、基于模糊逻辑的知识图谱对齐方法，能够同时对齐实体和关系，具有可解释性，并达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱对齐方法大多只关注实体层面，缺乏可解释的推理，并且需要训练数据。

Method: FLORA是一种基于模糊逻辑的无监督方法，能够迭代地对齐实体和关系，并能处理悬空实体。

Result: FLORA在主要基准测试中取得了最先进的结果。

Conclusion: FLORA是一种简单而有效的无监督知识图谱对齐方法，具有可解释性，并能处理悬空实体。

Abstract: Knowledge graph alignment is the task of matching equivalent entities (that
is, instances and classes) and relations across two knowledge graphs. Most
existing methods focus on pure entity-level alignment, computing the similarity
of entities in some embedding space. They lack interpretable reasoning and need
training data to work. In this paper, we propose FLORA, a simple yet effective
method that (1) is unsupervised, i.e., does not require training data, (2)
provides a holistic alignment for entities and relations iteratively, (3) is
based on fuzzy logic and thus delivers interpretable results, (4) provably
converges, (5) allows dangling entities, i.e., entities without a counterpart
in the other KG, and (6) achieves state-of-the-art results on major benchmarks.

</details>


### [456] [Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI](https://arxiv.org/abs/2510.20568)
*Susan Ariel Aaronson,Michael Moreno*

Main category: cs.AI

TL;DR: Governments are failing to establish a meaningful dialogue with citizens on AI policy, leading to a lack of trust and legitimacy in AI governance. Current participatory approaches are inadequate due to limited public awareness, low participation rates, and insufficient responsiveness from officials. The paper suggests eight recommendations to improve AI literacy, outreach, engagement methods, and responsiveness to build trust.


<details>
  <summary>Details</summary>
Motivation: Governments worldwide are seeking public input on AI policy, but existing methods fail to create a meaningful dialogue, hindering the development of trust and legitimacy in AI governance. This paper aims to analyze how three countries (Australia, Colombia, and the United States) solicited and utilized public feedback on AI risks and policies to understand the gap between the promise and practice of participatory AI governance.

Method: The authors conducted a landscape analysis of Australia, Colombia, and the United States, examining how each government solicited public feedback on AI risks and policies and whether that input influenced AI governance. This involved analyzing government documents, public submissions, and policy outcomes.

Result: In Australia, Colombia, and the United States, less than one percent of the population participated in public comment periods on AI. Governments made limited efforts to publicize calls for feedback or encourage diverse participation. Officials demonstrated low responsiveness to public input, failing to establish an effective feedback loop. Consequently, no meaningful dialogue was established between citizens and policymakers in any of the three countries.

Conclusion: Current approaches to participatory AI governance are ineffective in building trust and legitimacy because policymakers are not adequately listening to or responding to public concerns. This gap between the promise and practice of public engagement persists. The paper concludes by offering eight recommendations to improve AI literacy, public outreach, engagement methods, and responsiveness to foster more effective and trustworthy AI governance.

Abstract: The worlds people have strong opinions about artificial intelligence (AI),
and they want policymakers to listen. Governments are inviting public comment
on AI, but as they translate input into policy, much of what citizens say is
lost. Policymakers are missing a critical opportunity to build trust in AI and
its governance. This paper compares three countries, Australia, Colombia, and
the United States, that invited citizens to comment on AI risks and policies.
Using a landscape analysis, the authors examined how each government solicited
feedback and whether that input shaped governance. Yet in none of the three
cases did citizens and policymakers establish a meaningful dialogue.
Governments did little to attract diverse voices or publicize calls for
comment, leaving most citizens unaware or unprepared to respond. In each
nation, fewer than one percent of the population participated. Moreover,
officials showed limited responsiveness to the feedback they received, failing
to create an effective feedback loop. The study finds a persistent gap between
the promise and practice of participatory AI governance. The authors conclude
that current approaches are unlikely to build trust or legitimacy in AI because
policymakers are not adequately listening or responding to public concerns.
They offer eight recommendations: promote AI literacy; monitor public feedback;
broaden outreach; hold regular online forums; use innovative engagement
methods; include underrepresented groups; respond publicly to input; and make
participation easier.

</details>


### [457] [Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting](https://arxiv.org/abs/2510.20591)
*Ali Rajaei,Peter Palensky,Jochen L. Cremer*

Main category: cs.AI

TL;DR: GNNs can accelerate network topology optimization for congestion management, offering faster and generalizable solutions compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for network topology optimization (NTO) via busbar splitting are computationally intractable for large-scale systems in near-real-time, and existing ML approaches lack generalization.

Method: A graph neural network (GNN) is proposed to predict effective busbar splitting actions by capturing local flow patterns. The GNN is designed as a heterogeneous edge-aware message passing network.

Result: The GNN-accelerated approach achieves up to a 4-order-of-magnitude speed-up, delivers AC-feasible solutions within one minute, and has a 2.3% optimality gap on the GOC 2000-bus system. It also demonstrates generalization to unseen topologies and transferability across systems.

Conclusion: The proposed GNN-based approach represents a significant advancement for near-real-time NTO in large-scale systems, addressing the limitations of existing methods and enabling effective congestion management with improved generalization capabilities.

Abstract: Network topology optimization (NTO) via busbar splitting can mitigate
transmission grid congestion and reduce redispatch costs. However, solving this
mixed-integer non-linear problem for large-scale systems in near-real-time is
currently intractable with existing solvers. Machine learning (ML) approaches
have emerged as a promising alternative, but they have limited generalization
to unseen topologies, varying operating conditions, and different systems,
which limits their practical applicability. This paper formulates NTO for
congestion management problem considering linearized AC PF, and proposes a
graph neural network (GNN)-accelerated approach. We develop a heterogeneous
edge-aware message passing NN to predict effective busbar splitting actions as
candidate NTO solutions. The proposed GNN captures local flow patterns,
achieves generalization to unseen topology changes, and improves
transferability across systems. Case studies show up to 4 orders-of-magnitude
speed-up, delivering AC-feasible solutions within one minute and a 2.3%
optimality gap on the GOC 2000-bus system. These results demonstrate a
significant step toward near-real-time NTO for large-scale systems with
topology and cross-system generalization.

</details>


### [458] [What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation](https://arxiv.org/abs/2510.20603)
*Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun*

Main category: cs.AI

TL;DR: 评估LLM的最终答案正确性过于片面，忽略了推理过程的质量。本文提出了一种更细粒度的评估方法，通过衡量推理步骤的相关性和连贯性来改进LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估方法主要关注最终答案的正确性，这是一种粗粒度的信号，无法有效指导模型的改进，并且忽略了推理过程本身的质量。作者认为，更细粒度的推理评估是构建更鲁棒模型的有效途径。

Method: 提出了一种名为因果步进评估（CaSE）的方法，将推理质量分解为相关性和连贯性两个维度。相关性衡量一个推理步骤是否与问题相关，连贯性衡量该步骤是否逻辑上遵循先前的步骤。CaSE通过仅使用先前上下文来评估每个推理步骤，从而避免了滞后偏差。

Result: 在MRa-GSM8K和MRa-MATH基准上，CaSE方法得到了与人类判断一致的结果。更重要的是，使用CaSE评估出的相关性和连贯性来筛选训练数据，可以直接提升模型在最终任务上的表现。

Conclusion: 本文提出了一种可扩展的框架，用于分析、调试和改进LLM的推理能力，证明了超越最终答案正确性检查的实际价值。

Abstract: Evaluating large language models (LLMs) on final-answer correctness is the
dominant paradigm. This approach, however, provides a coarse signal for model
improvement and overlooks the quality of the underlying reasoning process. We
argue that a more granular evaluation of reasoning offers a more effective path
to building robust models. We decompose reasoning quality into two dimensions:
relevance and coherence. Relevance measures if a step is grounded in the
problem; coherence measures if it follows logically from prior steps. To
measure these aspects reliably, we introduce causal stepwise evaluation (CaSE).
This method assesses each reasoning step using only its preceding context,
which avoids hindsight bias. We validate CaSE against human judgments on our
new expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we
show that curating training data with CaSE-evaluated relevance and coherence
directly improves final task performance. Our work provides a scalable
framework for analyzing, debugging, and improving LLM reasoning, demonstrating
the practical value of moving beyond validity checks.

</details>


### [459] [Efficient Algorithms for Computing Random Walk Centrality](https://arxiv.org/abs/2510.20604)
*Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang*

Main category: cs.AI

TL;DR: 随机游走中心性计算在大规模网络上不切实际，本文提出了两种可扩展的算法，可在近线性时间内实现高效且准确的计算。


<details>
  <summary>Details</summary>
Motivation: 随机游走中心性是图挖掘中的一个基本度量，但现有计算方法在大规模网络上效率低下。

Method: 提出了一种新的随机游走中心性公式，并基于近似乔莱斯基分解和稀疏逆估计，以及基于采样根生成树的两种可扩展算法。

Result: 所提出的两种算法均以近线性时间运行，并提供强大的近似保证。在包含超过1000万个节点的大型真实世界网络上的大量实验证明了所提出算法的效率和近似质量。

Conclusion: 本文提出的两种新算法为计算大规模网络中的随机游走中心性提供了高效且准确的解决方案。

Abstract: Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

</details>


### [460] [Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms](https://arxiv.org/abs/2510.20621)
*Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato*

Main category: cs.AI

TL;DR: MIMOSA是一个用于生成可解释的、高性能的、符合伦理的预测模型的框架。


<details>
  <summary>Details</summary>
Motivation: 为了在现实世界的应用中建立对自动化决策模型的信任、问责和安全采用，可解释性设计模型至关重要。

Method: 该框架通过定义监督学习设置、对三种主要可解释模型（特征重要性、规则和实例）进行分类，并正式定义和评估因果关系、公平性和隐私等伦理属性来实现这一目标。

Result: 该研究探讨了这些属性之间的内在权衡，并讨论了如何将隐私要求、公平性约束和因果推理嵌入可解释的管道中。

Conclusion: MIMOSA框架为开发不仅准确、可解释，而且公平、保护隐私和具有因果意识（即值得信赖）的AI系统奠定了理论基础。

Abstract: Interpretable-by-design models are crucial for fostering trust,
accountability, and safe adoption of automated decision-making models in
real-world applications. In this paper we formalize the ground for the MIMOSA
(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a
comprehensive methodology for generating predictive models that balance
interpretability with performance while embedding key ethical properties. We
formally define here the supervised learning setting across diverse
decision-making tasks and data types, including tabular data, time series,
images, text, transactions, and trajectories. We characterize three major
families of interpretable models: feature importance, rule, and instance based
models. For each family, we analyze their interpretability dimensions,
reasoning mechanisms, and complexity. Beyond interpretability, we formalize
three critical ethical properties, namely causality, fairness, and privacy,
providing formal definitions, evaluation metrics, and verification procedures
for each. We then examine the inherent trade-offs between these properties and
discuss how privacy requirements, fairness constraints, and causal reasoning
can be embedded within interpretable pipelines. By evaluating ethical measures
during model generation, this framework establishes the theoretical foundations
for developing AI systems that are not only accurate and interpretable but also
fair, privacy-preserving, and causally aware, i.e., trustworthy.

</details>


### [461] [Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](https://arxiv.org/abs/2510.20632)
*Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng*

Main category: cs.AI

TL;DR: EcomEval是一个多语言、多模态的电商LLM评测基准，旨在解决现有基准在任务多样性、模态、数据来源和语言覆盖方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有电商领域LLM评测工具不足，缺乏多样化的任务、多模态数据以及对低资源语言的支持，无法评估模型在复杂真实购物场景中的能力。

Method: 构建包含37个任务（含8个多模态任务）的EcomEval基准，数据主要来源于真实客户查询和交易日志，采用半自动标注流程，并定义了难度级别，覆盖七种语言（含五种东南亚低资源语言）。

Result: EcomEval基准提供了更全面、真实、多语言和多模态的LLM评估能力，填补了现有研究的空白。

Conclusion: EcomEval为评估和改进电商领域LLM在真实、复杂场景下的表现提供了重要的工具和视角。

Abstract: Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet
their capabilities in specialized domains remain underexplored. In e-commerce,
existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping
MMLU-suffer from limited task diversity (e.g., lacking product guidance and
after-sales issues), limited task modalities (e.g., absence of multimodal
data), synthetic or curated data, and a narrow focus on English and Chinese,
leaving practitioners without reliable tools to assess models on complex,
real-world shopping scenarios. We introduce EcomEval, a comprehensive
multilingual and multimodal benchmark for evaluating LLMs in e-commerce.
EcomEval covers six categories and 37 tasks (including 8 multimodal tasks),
sourced primarily from authentic customer queries and transaction logs,
reflecting the noisy and heterogeneous nature of real business interactions. To
ensure both quality and scalability of reference answers, we adopt a
semi-automatic pipeline in which large models draft candidate responses
subsequently reviewed and modified by over 50 expert annotators with strong
e-commerce and multilingual expertise. We define difficulty levels for each
question and task category by averaging evaluation scores across models with
different sizes and capabilities, enabling challenge-oriented and fine-grained
assessment. EcomEval also spans seven languages-including five low-resource
Southeast Asian languages-offering a multilingual perspective absent from prior
work.

</details>


### [462] [Fluidity Index: Next-Generation Super-intelligence Benchmarks](https://arxiv.org/abs/2510.20636)
*Eric Ngoiya,Tianshu Bao*

Main category: cs.AI

TL;DR: 该论文引入了流动性指数（FI）来量化模型在动态、可扩展环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是量化模型在动态、可扩展环境中的适应性，并提出了一种衡量模型理解、预测和适应状态变化能力的方法。

Method: 该论文提出并使用流动性指数（FI）来评估模型在动态、可扩展环境中的适应性。该指数基于模型对初始、当前和未来环境状态变化的响应准确性进行评估，并区分了闭式和开式基准测试，优先考虑闭环开式现实世界基准测试。

Result: 该论文的评估表明，模型在理解、预测和调整以适应可扩展环境中的状态变化方面具有一定的能力。

Conclusion: 一个真正超级智能的模型应该至少表现出二阶适应性，能够通过数字补充实现自我维持的计算，以获得最佳的流动性。

Abstract: This paper introduces the Fluidity Index (FI) to quantify model adaptability
in dynamic, scaling environments. The benchmark evaluates response accuracy
based on deviations in initial, current, and future environment states,
assessing context switching and continuity. We distinguish between closed-ended
and open-ended benchmarks, prioritizing closed-loop open-ended real-world
benchmarks to test adaptability. The approach measures a model's ability to
understand, predict, and adjust to state changes in scaling environments. A
truly super-intelligent model should exhibit at least second-order
adaptability, enabling self-sustained computation through digital replenishment
for optimal fluidity.

</details>


### [463] [Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges](https://arxiv.org/abs/2510.20641)
*Andrea Agiollo,Andrea Omicini*

Main category: cs.AI

TL;DR: 机器学习模型在感知和认知任务中展现出卓越的类人能力，这促进了将机器学习（ML）集成到理性主体架构中的框架的发展。然而，该领域的研究尚不统一，通常只关注将ML嵌入通用主体容器，而忽视了理性架构（如信念-意图（BDI）主体）的表达能力。本文利用BDI范式作为参考，对现有方法进行了细致的系统化梳理。我们的分析阐述了受ML增强的理性主体研究文献的快速发展，并指出了设计有效的理性ML主体的重要研究机遇和开放性挑战。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在感知和认知任务中展现出卓越的类人能力，这促进了将机器学习（ML）集成到理性主体架构中的框架的发展。然而，该领域的研究尚不统一，通常只关注将ML嵌入通用主体容器，而忽视了理性架构（如信念-意图（BDI）主体）的表达能力。

Method: 利用BDI范式作为参考，对现有方法进行了细致的系统化梳理。

Result: 我们的分析阐述了受ML增强的理性主体研究文献的快速发展。

Conclusion: 指出了设计有效的理性ML主体的重要研究机遇和开放性挑战。

Abstract: Thanks to the remarkable human-like capabilities of machine learning (ML)
models in perceptual and cognitive tasks, frameworks integrating ML within
rational agent architectures are gaining traction. Yet, the landscape remains
fragmented and incoherent, often focusing on embedding ML into generic agent
containers while overlooking the expressive power of rational
architectures--such as Belief-Desire-Intention (BDI) agents. This paper
presents a fine-grained systematisation of existing approaches, using the BDI
paradigm as a reference. Our analysis illustrates the fast-evolving literature
on rational agents enhanced by ML, and identifies key research opportunities
and open challenges for designing effective rational ML agents.

</details>


### [464] [The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models](https://arxiv.org/abs/2510.20665)
*Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok*

Main category: cs.AI

TL;DR: 该研究提出了一种基于拓扑数据分析（TDA）的框架，用于自动评估大型语言模型推理过程的质量，并通过实证研究证明其比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的推理过程质量是一个关键但充满挑战的问题，目前的方法（如专家评分、手动标注、成对比较和基于图的代理指标）存在效率低下、不可靠、过于简化等问题。

Method: 提出了一种基于拓扑数据分析（TDA）的评估框架，该框架能够捕捉推理过程的几何特征，实现标签效率高、自动化的评估。通过实证研究，将TDA提取的拓扑特征与传统的图度量进行比较。

Result: 研究结果表明，与标准的图度量相比，拓扑特征在评估推理质量方面具有更高的预测能力。TDA方法能够更有效地捕捉推理过程的几何结构，这比单纯的关系图更能反映有效的推理。此外，一小组稳定且紧凑的拓扑特征能够可靠地指示推理过程的质量。

Conclusion: 基于TDA的评估框架能够提供一种比现有方法更有效、更可靠、更高效的评估LLM推理质量的方式，其提取的几何特征比图结构更能反映推理的本质。这项研究为未来开发更优的强化学习算法提供了实用的信号。

Abstract: Evaluating the quality of reasoning traces from large language models remains
understudied, labor-intensive, and unreliable: current practice relies on
expert rubrics, manual annotation, and slow pairwise judgments. Automated
efforts are dominated by graph-based proxies that quantify structural
connectivity but do not clarify what constitutes high-quality reasoning; such
abstractions can be overly simplistic for inherently complex processes. We
introduce a topological data analysis (TDA)-based evaluation framework that
captures the geometry of reasoning traces and enables label-efficient,
automated assessment. In our empirical study, topological features yield
substantially higher predictive power for assessing reasoning quality than
standard graph metrics, suggesting that effective reasoning is better captured
by higher-dimensional geometric structures rather than purely relational
graphs. We further show that a compact, stable set of topological features
reliably indicates trace quality, offering a practical signal for future
reinforcement learning algorithms.

</details>


### [465] [Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2510.20691)
*Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Graph-RFT的新框架，用于解决知识图谱问答（KGQA）中的复杂问题。该框架通过结合知识图谱和网络搜索，并引入自主规划和自适应检索机制，以克服现有方法在处理不完整知识和多步推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA方法难以充分利用知识图谱的丰富知识和大型语言模型的推理能力，尤其是在复杂场景下，它们通常假设知识图谱覆盖完整，并且缺乏判断何时需要外部信息的机制，导致推理失败。

Method: 提出了一种名为Graph-RFT的新型两阶段强化微调KGQA框架，采用‘plan-KGsearch-and-Websearch-during-think’范式。该框架包含一个链式思考微调方法（使用定制的plan-retrieval数据集）和一个优化的计划-检索引导强化学习过程。引入了一个笛卡尔坐标系启发的规划模块来分解复杂问题，并使用逻辑表达式指导工具调用以实现全局一致的多步推理。该推理检索过程通过结合结果和检索特定信号的多重奖励进行优化。

Result: Graph-RFT框架能够实现自主规划和跨知识图谱及网络源的自适应检索调度，从而在知识不完整的情况下进行推理。它解决了GRPO的冷启动问题，并通过多重奖励设计优化了覆盖感知检索调度，使模型能够学习何时以及如何有效地结合知识图谱和网络检索。

Conclusion: Graph-RFT通过其创新的两阶段强化微调方法和‘plan-KGsearch-and-Websearch-during-think’范式，显著提高了大型语言模型在知识图谱问答任务中的表现，尤其是在处理复杂问题和不完整知识的场景下，实现了更强的推理和检索能力。

Abstract: Knowledge Graph Question Answering aims to answer natural language questions
by reasoning over structured knowledge graphs. While large language models have
advanced KGQA through their strong reasoning capabilities, existing methods
continue to struggle to fully exploit both the rich knowledge encoded in KGs
and the reasoning capabilities of LLMs, particularly in complex scenarios. They
often assume complete KG coverage and lack mechanisms to judge when external
information is needed, and their reasoning remains locally myopic, failing to
maintain coherent multi-step planning, leading to reasoning failures even when
relevant knowledge exists. We propose Graph-RFT, a novel two-stage
reinforcement fine-tuning KGQA framework with a
'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to
perform autonomous planning and adaptive retrieval scheduling across KG and web
sources under incomplete knowledge conditions. Graph-RFT introduces a
chain-of-thought fine-tuning method with a customized plan-retrieval dataset
activates structured reasoning and resolves the GRPO cold-start problem. It
then introduces a novel plan-retrieval guided reinforcement learning process
integrates explicit planning and retrieval actions with a multi-reward design,
enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired
planning module to decompose complex questions into ordered subquestions, and
logical expression to guide tool invocation for globally consistent multi-step
reasoning. This reasoning retrieval process is optimized with a multi-reward
combining outcome and retrieval specific signals, enabling the model to learn
when and how to combine KG and web retrieval effectively.

</details>


### [466] [A Coherence-Based Measure of AGI](https://arxiv.org/abs/2510.20784)
*Fares Fourati*

Main category: cs.AI

TL;DR: AGI的定义应基于各认知领域能力的平衡，而非简单算术平均，提出了一种新的基于积分和广义平均数的度量方法（AUC），该方法能更好地衡量跨领域能力的均衡性，并指出GPT-4和GPT-5的通用智能仍有很大差距。


<details>
  <summary>Details</summary>
Motivation: 现有的AGI定义（基于CHC模型算术平均数）存在补偿性假设，即某些领域的优势可以弥补其他领域的不足，但这不符合真正通用智能应具备的‘连贯充分性’（各领域能力均衡）的要求。

Method: 提出了一种新的AGI度量方法，该方法基于广义平均数在补偿性指数连续体上的积分。该方法涵盖了算术、几何和调和平均数，并使用‘曲线下面积’（AUC）来量化在不同补偿性假设下的稳健性。

Result: 将新方法应用于GPT-4和GPT-5的公开CHC分数，发现它们的AGI分数（基于AUC）远低于其算术平均分数（例如GPT-5为24%），表明尽管算术分数较高，但其通用智能仍有很大提升空间。AUC度量方法惩罚了领域间的不平衡，并捕捉了领域间的依赖性。

Conclusion: 整合广义平均数提供了一个更原则化、可解释且更严格的基础来衡量真正的AGI进展，其AUC度量比算术平均数更能准确反映通用智能的均衡性。

Abstract: Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

</details>


### [467] [Real Deep Research for AI, Robotics and Beyond](https://arxiv.org/abs/2510.20809)
*Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang*

Main category: cs.AI

TL;DR: AI和机器人领域的论文数量激增，给研究人员带来跟踪最新进展的挑战。本文提出了Real Deep Research (RDR)框架，用于系统分析研究领域，识别新兴趋势，发现跨领域机会，并为新研究提供切入点。该框架已应用于AI和机器人领域，特别关注基础模型和机器人技术。


<details>
  <summary>Details</summary>
Motivation: AI和机器人领域的研究论文数量快速增长（每年超过10,000篇），导致研究人员难以跟上最新进展，新兴趋势、跨学科研究和探索新领域的挑战日益严峻。

Method: 提出一个名为Real Deep Research (RDR) 的通用分析流程，应用于AI和机器人领域，重点关注基础模型和机器人技术的进展，并简要扩展到其他科学领域。

Result: RDR框架被应用于AI和机器人领域，详细介绍了框架的构建，并在附录中提供了广泛的分析结果。

Conclusion: RDR框架旨在帮助AI及其他领域的研究人员应对信息过载的挑战，更好地把握研究趋势和机会。

Abstract: With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

</details>
